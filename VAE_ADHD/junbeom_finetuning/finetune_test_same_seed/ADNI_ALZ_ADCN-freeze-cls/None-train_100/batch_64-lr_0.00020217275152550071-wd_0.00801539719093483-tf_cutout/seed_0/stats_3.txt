"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 80.83118510246277, "training_acc": 28.0, "val_loss": 19.103164970874786, "val_acc": 28.0}
{"epoch": 1, "training_loss": 75.83072757720947, "training_acc": 28.0, "val_loss": 17.951804399490356, "val_acc": 28.0}
{"epoch": 2, "training_loss": 71.04354572296143, "training_acc": 28.0, "val_loss": 17.003144323825836, "val_acc": 28.0}
{"epoch": 3, "training_loss": 67.48476123809814, "training_acc": 72.0, "val_loss": 16.24322086572647, "val_acc": 28.0}
{"epoch": 4, "training_loss": 64.41497111320496, "training_acc": 72.0, "val_loss": 15.67017138004303, "val_acc": 28.0}
{"epoch": 5, "training_loss": 62.436893701553345, "training_acc": 72.0, "val_loss": 15.262211859226227, "val_acc": 72.0}
{"epoch": 6, "training_loss": 60.75385117530823, "training_acc": 72.0, "val_loss": 15.003608167171478, "val_acc": 72.0}
{"epoch": 7, "training_loss": 60.06433463096619, "training_acc": 72.0, "val_loss": 14.858724176883698, "val_acc": 72.0}
{"epoch": 8, "training_loss": 59.30796027183533, "training_acc": 72.0, "val_loss": 14.801773428916931, "val_acc": 72.0}
{"epoch": 9, "training_loss": 59.42014741897583, "training_acc": 72.0, "val_loss": 14.799834787845612, "val_acc": 72.0}
{"epoch": 10, "training_loss": 59.168243646621704, "training_acc": 72.0, "val_loss": 14.82594609260559, "val_acc": 72.0}
{"epoch": 11, "training_loss": 59.42588925361633, "training_acc": 72.0, "val_loss": 14.863520860671997, "val_acc": 72.0}
{"epoch": 12, "training_loss": 59.51296877861023, "training_acc": 72.0, "val_loss": 14.895904064178467, "val_acc": 72.0}
{"epoch": 13, "training_loss": 59.655468463897705, "training_acc": 72.0, "val_loss": 14.91987258195877, "val_acc": 72.0}
{"epoch": 14, "training_loss": 59.69781410694122, "training_acc": 72.0, "val_loss": 14.928492903709412, "val_acc": 72.0}
{"epoch": 15, "training_loss": 59.75854706764221, "training_acc": 72.0, "val_loss": 14.933133125305176, "val_acc": 72.0}
{"epoch": 16, "training_loss": 59.72423481941223, "training_acc": 72.0, "val_loss": 14.924202859401703, "val_acc": 72.0}
{"epoch": 17, "training_loss": 59.708277463912964, "training_acc": 72.0, "val_loss": 14.903482794761658, "val_acc": 72.0}
{"epoch": 18, "training_loss": 59.59786534309387, "training_acc": 72.0, "val_loss": 14.879457652568817, "val_acc": 72.0}
{"epoch": 19, "training_loss": 59.56327176094055, "training_acc": 72.0, "val_loss": 14.851686358451843, "val_acc": 72.0}
{"epoch": 20, "training_loss": 59.40107083320618, "training_acc": 72.0, "val_loss": 14.830510318279266, "val_acc": 72.0}
{"epoch": 21, "training_loss": 59.36415982246399, "training_acc": 72.0, "val_loss": 14.814063906669617, "val_acc": 72.0}
{"epoch": 22, "training_loss": 59.303027868270874, "training_acc": 72.0, "val_loss": 14.803390204906464, "val_acc": 72.0}
{"epoch": 23, "training_loss": 59.22441029548645, "training_acc": 72.0, "val_loss": 14.798137545585632, "val_acc": 72.0}
{"epoch": 24, "training_loss": 59.249149560928345, "training_acc": 72.0, "val_loss": 14.795392751693726, "val_acc": 72.0}
{"epoch": 25, "training_loss": 59.231350898742676, "training_acc": 72.0, "val_loss": 14.79467898607254, "val_acc": 72.0}
{"epoch": 26, "training_loss": 59.24391186237335, "training_acc": 72.0, "val_loss": 14.794574677944183, "val_acc": 72.0}
{"epoch": 27, "training_loss": 59.22856616973877, "training_acc": 72.0, "val_loss": 14.79450911283493, "val_acc": 72.0}
{"epoch": 28, "training_loss": 59.20772123336792, "training_acc": 72.0, "val_loss": 14.794474840164185, "val_acc": 72.0}
{"epoch": 29, "training_loss": 59.228970527648926, "training_acc": 72.0, "val_loss": 14.794537425041199, "val_acc": 72.0}
{"epoch": 30, "training_loss": 59.230324029922485, "training_acc": 72.0, "val_loss": 14.794895052909851, "val_acc": 72.0}
{"epoch": 31, "training_loss": 59.22080969810486, "training_acc": 72.0, "val_loss": 14.795120060443878, "val_acc": 72.0}
{"epoch": 32, "training_loss": 59.21314334869385, "training_acc": 72.0, "val_loss": 14.795444905757904, "val_acc": 72.0}
{"epoch": 33, "training_loss": 59.21761703491211, "training_acc": 72.0, "val_loss": 14.795851707458496, "val_acc": 72.0}
{"epoch": 34, "training_loss": 59.2278528213501, "training_acc": 72.0, "val_loss": 14.796291291713715, "val_acc": 72.0}
{"epoch": 35, "training_loss": 59.25241208076477, "training_acc": 72.0, "val_loss": 14.797107875347137, "val_acc": 72.0}
{"epoch": 36, "training_loss": 59.21803402900696, "training_acc": 72.0, "val_loss": 14.797502756118774, "val_acc": 72.0}
{"epoch": 37, "training_loss": 59.212830543518066, "training_acc": 72.0, "val_loss": 14.797499775886536, "val_acc": 72.0}
{"epoch": 38, "training_loss": 59.21715426445007, "training_acc": 72.0, "val_loss": 14.79601263999939, "val_acc": 72.0}
{"epoch": 39, "training_loss": 59.216341495513916, "training_acc": 72.0, "val_loss": 14.795367419719696, "val_acc": 72.0}
{"epoch": 40, "training_loss": 59.212703466415405, "training_acc": 72.0, "val_loss": 14.794570207595825, "val_acc": 72.0}
{"epoch": 41, "training_loss": 59.23550486564636, "training_acc": 72.0, "val_loss": 14.793691039085388, "val_acc": 72.0}
{"epoch": 42, "training_loss": 59.21345281600952, "training_acc": 72.0, "val_loss": 14.79356735944748, "val_acc": 72.0}
{"epoch": 43, "training_loss": 59.252047061920166, "training_acc": 72.0, "val_loss": 14.79400247335434, "val_acc": 72.0}
{"epoch": 44, "training_loss": 59.21687364578247, "training_acc": 72.0, "val_loss": 14.793968200683594, "val_acc": 72.0}
{"epoch": 45, "training_loss": 59.23662877082825, "training_acc": 72.0, "val_loss": 14.793974161148071, "val_acc": 72.0}
{"epoch": 46, "training_loss": 59.197264671325684, "training_acc": 72.0, "val_loss": 14.794215559959412, "val_acc": 72.0}
{"epoch": 47, "training_loss": 59.25602412223816, "training_acc": 72.0, "val_loss": 14.795148372650146, "val_acc": 72.0}
{"epoch": 48, "training_loss": 59.257094621658325, "training_acc": 72.0, "val_loss": 14.794984459877014, "val_acc": 72.0}
{"epoch": 49, "training_loss": 59.235992431640625, "training_acc": 72.0, "val_loss": 14.795465767383575, "val_acc": 72.0}
{"epoch": 50, "training_loss": 59.23081302642822, "training_acc": 72.0, "val_loss": 14.79668915271759, "val_acc": 72.0}
{"epoch": 51, "training_loss": 59.22211194038391, "training_acc": 72.0, "val_loss": 14.797668159008026, "val_acc": 72.0}
{"epoch": 52, "training_loss": 59.21267890930176, "training_acc": 72.0, "val_loss": 14.79823887348175, "val_acc": 72.0}
{"epoch": 53, "training_loss": 59.26753854751587, "training_acc": 72.0, "val_loss": 14.798399806022644, "val_acc": 72.0}
{"epoch": 54, "training_loss": 59.26925301551819, "training_acc": 72.0, "val_loss": 14.797012507915497, "val_acc": 72.0}
{"epoch": 55, "training_loss": 59.2214572429657, "training_acc": 72.0, "val_loss": 14.796225726604462, "val_acc": 72.0}
{"epoch": 56, "training_loss": 59.2017548084259, "training_acc": 72.0, "val_loss": 14.79538381099701, "val_acc": 72.0}
{"epoch": 57, "training_loss": 59.25953483581543, "training_acc": 72.0, "val_loss": 14.7954061627388, "val_acc": 72.0}
{"epoch": 58, "training_loss": 59.207791328430176, "training_acc": 72.0, "val_loss": 14.79625403881073, "val_acc": 72.0}
{"epoch": 59, "training_loss": 59.2078537940979, "training_acc": 72.0, "val_loss": 14.796289801597595, "val_acc": 72.0}
{"epoch": 60, "training_loss": 59.28045988082886, "training_acc": 72.0, "val_loss": 14.795421063899994, "val_acc": 72.0}
{"epoch": 61, "training_loss": 59.18473935127258, "training_acc": 72.0, "val_loss": 14.797136187553406, "val_acc": 72.0}
