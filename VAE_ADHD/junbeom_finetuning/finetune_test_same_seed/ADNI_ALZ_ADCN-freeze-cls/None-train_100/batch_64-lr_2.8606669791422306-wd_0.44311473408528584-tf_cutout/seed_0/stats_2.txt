"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 14780.017475128174, "training_acc": 40.0, "val_loss": 9097.852325439453, "val_acc": 28.0}
{"epoch": 1, "training_loss": 34526.00634765625, "training_acc": 38.0, "val_loss": 100.0708818435669, "val_acc": 28.0}
{"epoch": 2, "training_loss": 6207.97216796875, "training_acc": 42.0, "val_loss": 1030.4967880249023, "val_acc": 72.0}
{"epoch": 3, "training_loss": 3358.833106994629, "training_acc": 72.0, "val_loss": 975.5481719970703, "val_acc": 28.0}
{"epoch": 4, "training_loss": 4897.812347412109, "training_acc": 46.0, "val_loss": 385.93287467956543, "val_acc": 72.0}
{"epoch": 5, "training_loss": 1283.8484725952148, "training_acc": 56.0, "val_loss": 1817.8983688354492, "val_acc": 72.0}
{"epoch": 6, "training_loss": 4711.47395324707, "training_acc": 72.0, "val_loss": 476.5187740325928, "val_acc": 28.0}
{"epoch": 7, "training_loss": 3847.6038513183594, "training_acc": 42.0, "val_loss": 323.87163639068604, "val_acc": 72.0}
{"epoch": 8, "training_loss": 858.9294891357422, "training_acc": 72.0, "val_loss": 1679.9585342407227, "val_acc": 28.0}
{"epoch": 9, "training_loss": 7147.233795166016, "training_acc": 36.0, "val_loss": 433.689546585083, "val_acc": 28.0}
{"epoch": 10, "training_loss": 3665.2378540039062, "training_acc": 42.0, "val_loss": 387.66186237335205, "val_acc": 72.0}
{"epoch": 11, "training_loss": 1196.623566865921, "training_acc": 50.0, "val_loss": 1014.4657135009766, "val_acc": 72.0}
{"epoch": 12, "training_loss": 2421.7825241088867, "training_acc": 72.0, "val_loss": 1045.1394081115723, "val_acc": 28.0}
{"epoch": 13, "training_loss": 4604.611328125, "training_acc": 42.0, "val_loss": 85.08160710334778, "val_acc": 72.0}
{"epoch": 14, "training_loss": 781.676441192627, "training_acc": 58.0, "val_loss": 1211.5082740783691, "val_acc": 72.0}
{"epoch": 15, "training_loss": 3409.5472984313965, "training_acc": 72.0, "val_loss": 245.5782175064087, "val_acc": 28.0}
{"epoch": 16, "training_loss": 2743.639907836914, "training_acc": 42.0, "val_loss": 266.62285327911377, "val_acc": 72.0}
{"epoch": 17, "training_loss": 746.5897789001465, "training_acc": 72.0, "val_loss": 1639.8109436035156, "val_acc": 28.0}
{"epoch": 18, "training_loss": 5284.263656616211, "training_acc": 46.0, "val_loss": 68.03970336914062, "val_acc": 28.0}
{"epoch": 19, "training_loss": 2016.8336791992188, "training_acc": 46.0, "val_loss": 455.7260036468506, "val_acc": 72.0}
{"epoch": 20, "training_loss": 1343.8655452728271, "training_acc": 72.0, "val_loss": 840.5299186706543, "val_acc": 28.0}
{"epoch": 21, "training_loss": 3528.275665283203, "training_acc": 46.0, "val_loss": 170.72492837905884, "val_acc": 72.0}
{"epoch": 22, "training_loss": 818.5618782043457, "training_acc": 58.0, "val_loss": 1238.553237915039, "val_acc": 72.0}
{"epoch": 23, "training_loss": 3637.4944400787354, "training_acc": 72.0, "val_loss": 60.683900117874146, "val_acc": 28.0}
{"epoch": 24, "training_loss": 1993.0976104736328, "training_acc": 44.0, "val_loss": 305.194091796875, "val_acc": 72.0}
{"epoch": 25, "training_loss": 1328.4030838012695, "training_acc": 50.0, "val_loss": 1469.7053909301758, "val_acc": 72.0}
{"epoch": 26, "training_loss": 4240.0776443481445, "training_acc": 72.0, "val_loss": 69.89372372627258, "val_acc": 72.0}
{"epoch": 27, "training_loss": 1904.886703491211, "training_acc": 52.0, "val_loss": 1162.140941619873, "val_acc": 72.0}
{"epoch": 28, "training_loss": 3164.2449474334717, "training_acc": 72.0, "val_loss": 379.3847322463989, "val_acc": 28.0}
{"epoch": 29, "training_loss": 2280.929733276367, "training_acc": 48.0, "val_loss": 314.9578094482422, "val_acc": 72.0}
{"epoch": 30, "training_loss": 1073.3870944976807, "training_acc": 54.0, "val_loss": 1397.6762771606445, "val_acc": 72.0}
{"epoch": 31, "training_loss": 4467.5679931640625, "training_acc": 72.0, "val_loss": 160.91684103012085, "val_acc": 72.0}
{"epoch": 32, "training_loss": 2276.4506072998047, "training_acc": 50.0, "val_loss": 1228.6690711975098, "val_acc": 72.0}
{"epoch": 33, "training_loss": 3393.8614234924316, "training_acc": 72.0, "val_loss": 268.85998249053955, "val_acc": 28.0}
{"epoch": 34, "training_loss": 2996.0074310302734, "training_acc": 40.0, "val_loss": 215.6520128250122, "val_acc": 72.0}
{"epoch": 35, "training_loss": 899.8699951171875, "training_acc": 54.0, "val_loss": 1352.5705337524414, "val_acc": 72.0}
{"epoch": 36, "training_loss": 4175.209415435791, "training_acc": 72.0, "val_loss": 98.5084056854248, "val_acc": 72.0}
{"epoch": 37, "training_loss": 1860.4873962402344, "training_acc": 54.0, "val_loss": 1122.6122856140137, "val_acc": 72.0}
{"epoch": 38, "training_loss": 3141.549427986145, "training_acc": 72.0, "val_loss": 350.57764053344727, "val_acc": 28.0}
{"epoch": 39, "training_loss": 3141.5033416748047, "training_acc": 40.0, "val_loss": 181.3679337501526, "val_acc": 72.0}
{"epoch": 40, "training_loss": 780.1867027282715, "training_acc": 56.0, "val_loss": 1294.2292213439941, "val_acc": 72.0}
{"epoch": 41, "training_loss": 3743.559196472168, "training_acc": 72.0, "val_loss": 23.552730679512024, "val_acc": 28.0}
{"epoch": 42, "training_loss": 1218.7310600280762, "training_acc": 44.0, "val_loss": 14.806580543518066, "val_acc": 72.0}
{"epoch": 43, "training_loss": 465.1401481628418, "training_acc": 72.0, "val_loss": 1167.3090934753418, "val_acc": 28.0}
{"epoch": 44, "training_loss": 5079.459564208984, "training_acc": 40.0, "val_loss": 14.97555524110794, "val_acc": 72.0}
{"epoch": 45, "training_loss": 380.36356353759766, "training_acc": 72.0, "val_loss": 1090.1745796203613, "val_acc": 28.0}
{"epoch": 46, "training_loss": 3395.4870376586914, "training_acc": 52.0, "val_loss": 222.1656084060669, "val_acc": 72.0}
{"epoch": 47, "training_loss": 436.63810777664185, "training_acc": 72.0, "val_loss": 204.9586057662964, "val_acc": 28.0}
{"epoch": 48, "training_loss": 2356.1038513183594, "training_acc": 44.0, "val_loss": 279.967999458313, "val_acc": 72.0}
{"epoch": 49, "training_loss": 854.7108192443848, "training_acc": 56.0, "val_loss": 1371.9600677490234, "val_acc": 72.0}
{"epoch": 50, "training_loss": 4238.315052032471, "training_acc": 72.0, "val_loss": 96.85909152030945, "val_acc": 72.0}
{"epoch": 51, "training_loss": 1379.0550384521484, "training_acc": 60.0, "val_loss": 1052.226161956787, "val_acc": 72.0}
{"epoch": 52, "training_loss": 2459.6626625061035, "training_acc": 72.0, "val_loss": 925.8059501647949, "val_acc": 28.0}
{"epoch": 53, "training_loss": 4272.730056762695, "training_acc": 42.0, "val_loss": 94.12862062454224, "val_acc": 72.0}
{"epoch": 54, "training_loss": 505.3045845031738, "training_acc": 62.0, "val_loss": 1152.9966354370117, "val_acc": 72.0}
{"epoch": 55, "training_loss": 3134.5974197387695, "training_acc": 72.0, "val_loss": 403.5113334655762, "val_acc": 28.0}
{"epoch": 56, "training_loss": 3923.508026123047, "training_acc": 36.0, "val_loss": 128.8924217224121, "val_acc": 72.0}
{"epoch": 57, "training_loss": 859.624137878418, "training_acc": 54.0, "val_loss": 1334.8705291748047, "val_acc": 72.0}
{"epoch": 58, "training_loss": 4080.5700759887695, "training_acc": 72.0, "val_loss": 59.48607325553894, "val_acc": 72.0}
{"epoch": 59, "training_loss": 1407.0558776855469, "training_acc": 60.0, "val_loss": 1019.2254066467285, "val_acc": 72.0}
{"epoch": 60, "training_loss": 3007.4900074005127, "training_acc": 52.0, "val_loss": 1610.2964401245117, "val_acc": 72.0}
{"epoch": 61, "training_loss": 5381.308387756348, "training_acc": 72.0, "val_loss": 320.49665451049805, "val_acc": 72.0}
