"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 1244.0733947753906, "training_acc": 42.0, "val_loss": 611.7148399353027, "val_acc": 72.0}
{"epoch": 1, "training_loss": 1820.9906120300293, "training_acc": 72.0, "val_loss": 627.5710105895996, "val_acc": 28.0}
{"epoch": 2, "training_loss": 2225.551383972168, "training_acc": 28.0, "val_loss": 137.86449432373047, "val_acc": 72.0}
{"epoch": 3, "training_loss": 781.083911895752, "training_acc": 72.0, "val_loss": 343.2647705078125, "val_acc": 72.0}
{"epoch": 4, "training_loss": 1304.4277076721191, "training_acc": 72.0, "val_loss": 176.56610012054443, "val_acc": 72.0}
{"epoch": 5, "training_loss": 634.4797554016113, "training_acc": 48.0, "val_loss": 19.659338891506195, "val_acc": 72.0}
{"epoch": 6, "training_loss": 76.05722188949585, "training_acc": 56.0, "val_loss": 41.377654671669006, "val_acc": 72.0}
{"epoch": 7, "training_loss": 145.7666358947754, "training_acc": 72.0, "val_loss": 22.64508754014969, "val_acc": 72.0}
{"epoch": 8, "training_loss": 104.23507690429688, "training_acc": 58.0, "val_loss": 79.23168540000916, "val_acc": 72.0}
{"epoch": 9, "training_loss": 322.22096157073975, "training_acc": 72.0, "val_loss": 47.095829248428345, "val_acc": 72.0}
{"epoch": 10, "training_loss": 290.65432929992676, "training_acc": 56.0, "val_loss": 27.78085172176361, "val_acc": 72.0}
{"epoch": 11, "training_loss": 122.60245513916016, "training_acc": 72.0, "val_loss": 35.45490205287933, "val_acc": 28.0}
{"epoch": 12, "training_loss": 164.7288122177124, "training_acc": 46.0, "val_loss": 69.12617087364197, "val_acc": 72.0}
{"epoch": 13, "training_loss": 233.05418050289154, "training_acc": 72.0, "val_loss": 83.28640460968018, "val_acc": 28.0}
{"epoch": 14, "training_loss": 354.9255084991455, "training_acc": 40.0, "val_loss": 105.48672676086426, "val_acc": 72.0}
{"epoch": 15, "training_loss": 378.396014213562, "training_acc": 72.0, "val_loss": 24.06858056783676, "val_acc": 28.0}
{"epoch": 16, "training_loss": 87.87485218048096, "training_acc": 40.0, "val_loss": 18.388186395168304, "val_acc": 28.0}
{"epoch": 17, "training_loss": 80.6966245174408, "training_acc": 50.0, "val_loss": 27.620598673820496, "val_acc": 72.0}
{"epoch": 18, "training_loss": 131.6570053100586, "training_acc": 62.0, "val_loss": 54.64884638786316, "val_acc": 72.0}
{"epoch": 19, "training_loss": 218.2056074142456, "training_acc": 72.0, "val_loss": 18.501946330070496, "val_acc": 72.0}
{"epoch": 20, "training_loss": 274.50428199768066, "training_acc": 54.0, "val_loss": 26.231753826141357, "val_acc": 72.0}
{"epoch": 21, "training_loss": 160.92603397369385, "training_acc": 72.0, "val_loss": 16.074691712856293, "val_acc": 72.0}
{"epoch": 22, "training_loss": 233.0757656097412, "training_acc": 56.0, "val_loss": 34.00292098522186, "val_acc": 72.0}
{"epoch": 23, "training_loss": 157.31371402740479, "training_acc": 72.0, "val_loss": 19.2176416516304, "val_acc": 72.0}
{"epoch": 24, "training_loss": 239.3594970703125, "training_acc": 56.0, "val_loss": 29.77335751056671, "val_acc": 72.0}
{"epoch": 25, "training_loss": 150.61289882659912, "training_acc": 72.0, "val_loss": 14.940576255321503, "val_acc": 72.0}
{"epoch": 26, "training_loss": 200.4005126953125, "training_acc": 54.0, "val_loss": 57.55043625831604, "val_acc": 72.0}
{"epoch": 27, "training_loss": 273.9382572174072, "training_acc": 72.0, "val_loss": 61.56114339828491, "val_acc": 72.0}
{"epoch": 28, "training_loss": 239.8281488418579, "training_acc": 54.0, "val_loss": 43.348488211631775, "val_acc": 72.0}
{"epoch": 29, "training_loss": 172.40973043441772, "training_acc": 72.0, "val_loss": 30.396097898483276, "val_acc": 28.0}
{"epoch": 30, "training_loss": 109.41569447517395, "training_acc": 50.0, "val_loss": 38.10594081878662, "val_acc": 72.0}
{"epoch": 31, "training_loss": 101.40267276763916, "training_acc": 64.0, "val_loss": 24.030515551567078, "val_acc": 28.0}
{"epoch": 32, "training_loss": 134.64396381378174, "training_acc": 48.0, "val_loss": 82.65419006347656, "val_acc": 72.0}
{"epoch": 33, "training_loss": 277.3299193382263, "training_acc": 72.0, "val_loss": 116.872239112854, "val_acc": 28.0}
{"epoch": 34, "training_loss": 364.170627117157, "training_acc": 40.0, "val_loss": 32.75164067745209, "val_acc": 72.0}
{"epoch": 35, "training_loss": 151.74728298187256, "training_acc": 56.0, "val_loss": 63.61631155014038, "val_acc": 72.0}
{"epoch": 36, "training_loss": 269.62050437927246, "training_acc": 72.0, "val_loss": 37.81433701515198, "val_acc": 72.0}
{"epoch": 37, "training_loss": 189.03329181671143, "training_acc": 64.0, "val_loss": 19.531555473804474, "val_acc": 72.0}
{"epoch": 38, "training_loss": 89.93160820007324, "training_acc": 72.0, "val_loss": 53.92160415649414, "val_acc": 28.0}
{"epoch": 39, "training_loss": 307.3291320800781, "training_acc": 36.0, "val_loss": 88.68719935417175, "val_acc": 72.0}
{"epoch": 40, "training_loss": 286.48278999328613, "training_acc": 72.0, "val_loss": 123.39270114898682, "val_acc": 28.0}
{"epoch": 41, "training_loss": 345.2269241809845, "training_acc": 42.0, "val_loss": 41.2062406539917, "val_acc": 72.0}
{"epoch": 42, "training_loss": 133.15045404434204, "training_acc": 72.0, "val_loss": 82.97283053398132, "val_acc": 28.0}
{"epoch": 43, "training_loss": 269.1943197250366, "training_acc": 48.0, "val_loss": 92.59082078933716, "val_acc": 72.0}
{"epoch": 44, "training_loss": 334.8002290725708, "training_acc": 72.0, "val_loss": 24.040743708610535, "val_acc": 28.0}
