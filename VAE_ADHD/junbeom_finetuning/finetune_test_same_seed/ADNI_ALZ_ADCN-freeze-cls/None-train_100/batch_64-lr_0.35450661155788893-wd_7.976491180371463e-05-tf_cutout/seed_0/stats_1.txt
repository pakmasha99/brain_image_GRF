"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 2128.8237228393555, "training_acc": 72.0, "val_loss": 817.9423332214355, "val_acc": 72.0}
{"epoch": 1, "training_loss": 2589.76153755188, "training_acc": 52.0, "val_loss": 219.70882415771484, "val_acc": 72.0}
{"epoch": 2, "training_loss": 928.9695663452148, "training_acc": 72.0, "val_loss": 47.039398550987244, "val_acc": 72.0}
{"epoch": 3, "training_loss": 1174.919090270996, "training_acc": 58.0, "val_loss": 501.0540008544922, "val_acc": 28.0}
{"epoch": 4, "training_loss": 1700.4612007141113, "training_acc": 40.0, "val_loss": 444.4662570953369, "val_acc": 72.0}
{"epoch": 5, "training_loss": 1834.1420211791992, "training_acc": 72.0, "val_loss": 454.93717193603516, "val_acc": 72.0}
{"epoch": 6, "training_loss": 1596.5321617126465, "training_acc": 72.0, "val_loss": 25.436127185821533, "val_acc": 72.0}
{"epoch": 7, "training_loss": 1571.5888214111328, "training_acc": 44.0, "val_loss": 803.172492980957, "val_acc": 28.0}
{"epoch": 8, "training_loss": 2219.077173233032, "training_acc": 28.0, "val_loss": 386.5511417388916, "val_acc": 72.0}
{"epoch": 9, "training_loss": 1869.6433334350586, "training_acc": 72.0, "val_loss": 889.2862319946289, "val_acc": 72.0}
{"epoch": 10, "training_loss": 3632.6389923095703, "training_acc": 72.0, "val_loss": 968.1435585021973, "val_acc": 72.0}
{"epoch": 11, "training_loss": 3708.0475158691406, "training_acc": 72.0, "val_loss": 681.5007209777832, "val_acc": 72.0}
{"epoch": 12, "training_loss": 2371.580951690674, "training_acc": 72.0, "val_loss": 118.54064464569092, "val_acc": 72.0}
{"epoch": 13, "training_loss": 1201.2223587036133, "training_acc": 56.0, "val_loss": 888.1211280822754, "val_acc": 28.0}
{"epoch": 14, "training_loss": 3013.0681228637695, "training_acc": 28.0, "val_loss": 102.35470533370972, "val_acc": 72.0}
{"epoch": 15, "training_loss": 733.0413208007812, "training_acc": 72.0, "val_loss": 453.5705089569092, "val_acc": 72.0}
{"epoch": 16, "training_loss": 1809.5845832824707, "training_acc": 72.0, "val_loss": 411.6925239562988, "val_acc": 72.0}
{"epoch": 17, "training_loss": 1517.531753540039, "training_acc": 72.0, "val_loss": 59.518325328826904, "val_acc": 72.0}
{"epoch": 18, "training_loss": 915.0112762451172, "training_acc": 54.0, "val_loss": 529.4588088989258, "val_acc": 28.0}
{"epoch": 19, "training_loss": 1361.6108219623566, "training_acc": 31.0, "val_loss": 297.0844030380249, "val_acc": 72.0}
{"epoch": 20, "training_loss": 1387.6159858703613, "training_acc": 72.0, "val_loss": 577.4747848510742, "val_acc": 72.0}
{"epoch": 21, "training_loss": 2297.6811904907227, "training_acc": 72.0, "val_loss": 496.5792655944824, "val_acc": 72.0}
{"epoch": 22, "training_loss": 1696.2109909057617, "training_acc": 72.0, "val_loss": 86.5787923336029, "val_acc": 72.0}
{"epoch": 23, "training_loss": 939.9743957519531, "training_acc": 58.0, "val_loss": 687.4669075012207, "val_acc": 28.0}
{"epoch": 24, "training_loss": 2119.6761054992676, "training_acc": 28.0, "val_loss": 233.74426364898682, "val_acc": 72.0}
{"epoch": 25, "training_loss": 1265.0630722045898, "training_acc": 72.0, "val_loss": 602.8958797454834, "val_acc": 72.0}
