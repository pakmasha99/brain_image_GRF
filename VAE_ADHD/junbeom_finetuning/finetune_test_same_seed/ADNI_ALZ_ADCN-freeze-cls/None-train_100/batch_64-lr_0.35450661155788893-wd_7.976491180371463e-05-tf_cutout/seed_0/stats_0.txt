"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 1617.1853637695312, "training_acc": 42.0, "val_loss": 975.4738807678223, "val_acc": 72.0}
{"epoch": 1, "training_loss": 3238.709098815918, "training_acc": 72.0, "val_loss": 64.79663848876953, "val_acc": 72.0}
{"epoch": 2, "training_loss": 2644.1595306396484, "training_acc": 50.0, "val_loss": 1489.5176887512207, "val_acc": 28.0}
{"epoch": 3, "training_loss": 4899.4775314331055, "training_acc": 28.0, "val_loss": 168.14180612564087, "val_acc": 72.0}
{"epoch": 4, "training_loss": 1164.7096939086914, "training_acc": 72.0, "val_loss": 677.0176887512207, "val_acc": 72.0}
{"epoch": 5, "training_loss": 2693.8683853149414, "training_acc": 72.0, "val_loss": 719.4130897521973, "val_acc": 72.0}
{"epoch": 6, "training_loss": 2686.8908462524414, "training_acc": 72.0, "val_loss": 455.06229400634766, "val_acc": 72.0}
{"epoch": 7, "training_loss": 1540.7116374969482, "training_acc": 72.0, "val_loss": 195.1363205909729, "val_acc": 28.0}
{"epoch": 8, "training_loss": 902.0405197143555, "training_acc": 28.0, "val_loss": 34.578534960746765, "val_acc": 72.0}
{"epoch": 9, "training_loss": 180.8262243270874, "training_acc": 72.0, "val_loss": 76.83616280555725, "val_acc": 72.0}
{"epoch": 10, "training_loss": 217.96625542640686, "training_acc": 63.0, "val_loss": 15.805909037590027, "val_acc": 44.0}
{"epoch": 11, "training_loss": 127.25414752960205, "training_acc": 69.0, "val_loss": 43.52410137653351, "val_acc": 72.0}
{"epoch": 12, "training_loss": 297.8308448791504, "training_acc": 54.0, "val_loss": 53.62347960472107, "val_acc": 72.0}
{"epoch": 13, "training_loss": 213.78996467590332, "training_acc": 72.0, "val_loss": 25.206074118614197, "val_acc": 72.0}
{"epoch": 14, "training_loss": 261.34910774230957, "training_acc": 60.0, "val_loss": 20.157407224178314, "val_acc": 72.0}
{"epoch": 15, "training_loss": 122.30398368835449, "training_acc": 72.0, "val_loss": 27.520188689231873, "val_acc": 28.0}
{"epoch": 16, "training_loss": 200.69855403900146, "training_acc": 40.0, "val_loss": 62.770748138427734, "val_acc": 72.0}
{"epoch": 17, "training_loss": 284.689847946167, "training_acc": 50.0, "val_loss": 78.70750427246094, "val_acc": 72.0}
{"epoch": 18, "training_loss": 377.5839252471924, "training_acc": 72.0, "val_loss": 63.550978899002075, "val_acc": 72.0}
{"epoch": 19, "training_loss": 438.29944610595703, "training_acc": 50.0, "val_loss": 14.419738948345184, "val_acc": 72.0}
{"epoch": 20, "training_loss": 92.65343999862671, "training_acc": 72.0, "val_loss": 17.410695552825928, "val_acc": 72.0}
{"epoch": 21, "training_loss": 166.17997360229492, "training_acc": 62.0, "val_loss": 48.895078897476196, "val_acc": 72.0}
{"epoch": 22, "training_loss": 213.99881076812744, "training_acc": 72.0, "val_loss": 16.683660447597504, "val_acc": 72.0}
{"epoch": 23, "training_loss": 319.50000953674316, "training_acc": 54.0, "val_loss": 14.92265909910202, "val_acc": 72.0}
{"epoch": 24, "training_loss": 119.67003726959229, "training_acc": 72.0, "val_loss": 34.74184274673462, "val_acc": 72.0}
{"epoch": 25, "training_loss": 247.0612449645996, "training_acc": 58.0, "val_loss": 38.541677594184875, "val_acc": 72.0}
{"epoch": 26, "training_loss": 160.1292290687561, "training_acc": 72.0, "val_loss": 14.12317007780075, "val_acc": 56.0}
{"epoch": 27, "training_loss": 60.758801221847534, "training_acc": 64.0, "val_loss": 12.43676170706749, "val_acc": 76.0}
{"epoch": 28, "training_loss": 55.144033432006836, "training_acc": 76.0, "val_loss": 32.093510031700134, "val_acc": 72.0}
{"epoch": 29, "training_loss": 103.18528366088867, "training_acc": 67.0, "val_loss": 32.398855686187744, "val_acc": 72.0}
{"epoch": 30, "training_loss": 138.47332954406738, "training_acc": 53.0, "val_loss": 83.21301341056824, "val_acc": 72.0}
{"epoch": 31, "training_loss": 384.48991775512695, "training_acc": 72.0, "val_loss": 43.72152090072632, "val_acc": 72.0}
{"epoch": 32, "training_loss": 478.3892822265625, "training_acc": 52.0, "val_loss": 71.06703519821167, "val_acc": 28.0}
{"epoch": 33, "training_loss": 386.092679977417, "training_acc": 48.0, "val_loss": 322.9933977127075, "val_acc": 72.0}
{"epoch": 34, "training_loss": 1373.3337783813477, "training_acc": 72.0, "val_loss": 364.0794038772583, "val_acc": 72.0}
{"epoch": 35, "training_loss": 1294.566707611084, "training_acc": 72.0, "val_loss": 117.43031740188599, "val_acc": 72.0}
{"epoch": 36, "training_loss": 648.0690269470215, "training_acc": 54.0, "val_loss": 236.46562099456787, "val_acc": 28.0}
{"epoch": 37, "training_loss": 823.0528964996338, "training_acc": 36.0, "val_loss": 143.4065818786621, "val_acc": 72.0}
{"epoch": 38, "training_loss": 551.2780990600586, "training_acc": 72.0, "val_loss": 59.04669761657715, "val_acc": 72.0}
{"epoch": 39, "training_loss": 299.9004783630371, "training_acc": 64.0, "val_loss": 57.784295082092285, "val_acc": 28.0}
{"epoch": 40, "training_loss": 444.530481338501, "training_acc": 40.0, "val_loss": 266.0306930541992, "val_acc": 72.0}
{"epoch": 41, "training_loss": 1075.9182815551758, "training_acc": 72.0, "val_loss": 238.3115291595459, "val_acc": 72.0}
{"epoch": 42, "training_loss": 775.9516477584839, "training_acc": 72.0, "val_loss": 105.1834225654602, "val_acc": 28.0}
{"epoch": 43, "training_loss": 413.78192138671875, "training_acc": 28.0, "val_loss": 149.77264404296875, "val_acc": 72.0}
{"epoch": 44, "training_loss": 729.1035919189453, "training_acc": 72.0, "val_loss": 283.8385820388794, "val_acc": 72.0}
{"epoch": 45, "training_loss": 1047.252613067627, "training_acc": 72.0, "val_loss": 134.72411632537842, "val_acc": 72.0}
{"epoch": 46, "training_loss": 504.9255266189575, "training_acc": 52.0, "val_loss": 25.849434733390808, "val_acc": 44.0}
