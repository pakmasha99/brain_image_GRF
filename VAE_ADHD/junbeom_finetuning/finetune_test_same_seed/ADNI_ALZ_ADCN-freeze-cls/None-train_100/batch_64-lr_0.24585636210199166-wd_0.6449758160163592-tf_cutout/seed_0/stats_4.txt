"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 1721.874855041504, "training_acc": 32.0, "val_loss": 478.40142250061035, "val_acc": 72.0}
{"epoch": 1, "training_loss": 1327.0820713043213, "training_acc": 72.0, "val_loss": 821.8554496765137, "val_acc": 28.0}
{"epoch": 2, "training_loss": 2905.993797302246, "training_acc": 28.0, "val_loss": 78.3154308795929, "val_acc": 72.0}
{"epoch": 3, "training_loss": 542.0537796020508, "training_acc": 72.0, "val_loss": 208.13021659851074, "val_acc": 72.0}
{"epoch": 4, "training_loss": 714.1645812988281, "training_acc": 72.0, "val_loss": 34.850677847862244, "val_acc": 28.0}
{"epoch": 5, "training_loss": 144.0003161430359, "training_acc": 42.0, "val_loss": 20.507700741291046, "val_acc": 28.0}
{"epoch": 6, "training_loss": 174.6075143814087, "training_acc": 36.0, "val_loss": 20.743337273597717, "val_acc": 72.0}
{"epoch": 7, "training_loss": 211.93456077575684, "training_acc": 62.0, "val_loss": 33.78891050815582, "val_acc": 72.0}
{"epoch": 8, "training_loss": 139.24444484710693, "training_acc": 72.0, "val_loss": 34.37725007534027, "val_acc": 28.0}
{"epoch": 9, "training_loss": 139.05868482589722, "training_acc": 50.0, "val_loss": 67.47482419013977, "val_acc": 72.0}
{"epoch": 10, "training_loss": 206.79044818878174, "training_acc": 72.0, "val_loss": 141.76952838897705, "val_acc": 28.0}
{"epoch": 11, "training_loss": 462.8280792236328, "training_acc": 38.0, "val_loss": 45.4619824886322, "val_acc": 72.0}
{"epoch": 12, "training_loss": 163.726731300354, "training_acc": 54.0, "val_loss": 46.43869996070862, "val_acc": 72.0}
{"epoch": 13, "training_loss": 166.18780064582825, "training_acc": 72.0, "val_loss": 61.69383525848389, "val_acc": 28.0}
{"epoch": 14, "training_loss": 202.29788494110107, "training_acc": 50.0, "val_loss": 78.05308103561401, "val_acc": 72.0}
{"epoch": 15, "training_loss": 263.2238254547119, "training_acc": 72.0, "val_loss": 91.74810647964478, "val_acc": 28.0}
{"epoch": 16, "training_loss": 318.73626804351807, "training_acc": 40.0, "val_loss": 42.82819330692291, "val_acc": 72.0}
{"epoch": 17, "training_loss": 137.15871477127075, "training_acc": 58.0, "val_loss": 27.573847770690918, "val_acc": 72.0}
{"epoch": 18, "training_loss": 127.38300943374634, "training_acc": 48.0, "val_loss": 68.19607615470886, "val_acc": 72.0}
{"epoch": 19, "training_loss": 273.0415849685669, "training_acc": 72.0, "val_loss": 27.794039249420166, "val_acc": 72.0}
{"epoch": 20, "training_loss": 264.16415214538574, "training_acc": 56.0, "val_loss": 20.09778618812561, "val_acc": 72.0}
{"epoch": 21, "training_loss": 130.55643463134766, "training_acc": 72.0, "val_loss": 22.93553501367569, "val_acc": 28.0}
{"epoch": 22, "training_loss": 91.07863664627075, "training_acc": 46.0, "val_loss": 14.789710938930511, "val_acc": 72.0}
{"epoch": 23, "training_loss": 61.685662269592285, "training_acc": 62.0, "val_loss": 30.909505486488342, "val_acc": 72.0}
{"epoch": 24, "training_loss": 105.65489983558655, "training_acc": 72.0, "val_loss": 15.058192610740662, "val_acc": 72.0}
{"epoch": 25, "training_loss": 59.600653409957886, "training_acc": 72.0, "val_loss": 15.488630533218384, "val_acc": 72.0}
{"epoch": 26, "training_loss": 60.05494403839111, "training_acc": 72.0, "val_loss": 16.201195120811462, "val_acc": 72.0}
{"epoch": 27, "training_loss": 68.71367359161377, "training_acc": 58.0, "val_loss": 44.58431005477905, "val_acc": 72.0}
{"epoch": 28, "training_loss": 151.71485090255737, "training_acc": 72.0, "val_loss": 83.04429650306702, "val_acc": 28.0}
{"epoch": 29, "training_loss": 365.3500566482544, "training_acc": 38.0, "val_loss": 85.63557267189026, "val_acc": 72.0}
{"epoch": 30, "training_loss": 287.0451626777649, "training_acc": 72.0, "val_loss": 124.43493604660034, "val_acc": 28.0}
{"epoch": 31, "training_loss": 320.9026052951813, "training_acc": 50.0, "val_loss": 45.89703679084778, "val_acc": 72.0}
{"epoch": 32, "training_loss": 144.73289847373962, "training_acc": 72.0, "val_loss": 49.64878857135773, "val_acc": 28.0}
{"epoch": 33, "training_loss": 271.1512794494629, "training_acc": 42.0, "val_loss": 112.71610260009766, "val_acc": 72.0}
{"epoch": 34, "training_loss": 395.5702257156372, "training_acc": 72.0, "val_loss": 29.100677371025085, "val_acc": 28.0}
{"epoch": 35, "training_loss": 115.57737398147583, "training_acc": 42.0, "val_loss": 20.20578682422638, "val_acc": 28.0}
{"epoch": 36, "training_loss": 141.24197578430176, "training_acc": 38.0, "val_loss": 18.455226719379425, "val_acc": 72.0}
{"epoch": 37, "training_loss": 193.94552612304688, "training_acc": 58.0, "val_loss": 47.17860221862793, "val_acc": 72.0}
{"epoch": 38, "training_loss": 207.92821979522705, "training_acc": 72.0, "val_loss": 19.048748910427094, "val_acc": 72.0}
{"epoch": 39, "training_loss": 296.807580947876, "training_acc": 52.0, "val_loss": 29.027950763702393, "val_acc": 72.0}
{"epoch": 40, "training_loss": 140.63505029678345, "training_acc": 72.0, "val_loss": 14.723500609397888, "val_acc": 72.0}
{"epoch": 41, "training_loss": 195.88101768493652, "training_acc": 48.0, "val_loss": 87.17832565307617, "val_acc": 72.0}
{"epoch": 42, "training_loss": 379.7871026992798, "training_acc": 72.0, "val_loss": 103.35713624954224, "val_acc": 72.0}
{"epoch": 43, "training_loss": 315.1215214729309, "training_acc": 72.0, "val_loss": 165.9614086151123, "val_acc": 28.0}
{"epoch": 44, "training_loss": 470.8112645149231, "training_acc": 28.0, "val_loss": 93.48772764205933, "val_acc": 72.0}
{"epoch": 45, "training_loss": 401.54158210754395, "training_acc": 72.0, "val_loss": 73.54992628097534, "val_acc": 72.0}
{"epoch": 46, "training_loss": 254.51532125473022, "training_acc": 54.0, "val_loss": 36.53188347816467, "val_acc": 72.0}
{"epoch": 47, "training_loss": 128.57794380187988, "training_acc": 72.0, "val_loss": 93.4194028377533, "val_acc": 28.0}
{"epoch": 48, "training_loss": 311.2269411087036, "training_acc": 44.0, "val_loss": 64.16893601417542, "val_acc": 72.0}
{"epoch": 49, "training_loss": 200.3900933265686, "training_acc": 72.0, "val_loss": 130.6749701499939, "val_acc": 28.0}
{"epoch": 50, "training_loss": 410.6597728729248, "training_acc": 40.0, "val_loss": 41.12786054611206, "val_acc": 72.0}
{"epoch": 51, "training_loss": 143.3812255859375, "training_acc": 56.0, "val_loss": 41.126617789268494, "val_acc": 72.0}
{"epoch": 52, "training_loss": 142.09500908851624, "training_acc": 72.0, "val_loss": 71.33832573890686, "val_acc": 28.0}
{"epoch": 53, "training_loss": 199.8436803817749, "training_acc": 54.0, "val_loss": 85.67939400672913, "val_acc": 72.0}
{"epoch": 54, "training_loss": 310.58919048309326, "training_acc": 72.0, "val_loss": 43.39253604412079, "val_acc": 28.0}
{"epoch": 55, "training_loss": 161.96338415145874, "training_acc": 44.0, "val_loss": 24.53315258026123, "val_acc": 72.0}
{"epoch": 56, "training_loss": 200.00586414337158, "training_acc": 54.0, "val_loss": 58.48360061645508, "val_acc": 72.0}
{"epoch": 57, "training_loss": 266.9886827468872, "training_acc": 72.0, "val_loss": 38.02598416805267, "val_acc": 72.0}
{"epoch": 58, "training_loss": 244.01502227783203, "training_acc": 58.0, "val_loss": 25.258424878120422, "val_acc": 72.0}
{"epoch": 59, "training_loss": 106.5176305770874, "training_acc": 72.0, "val_loss": 44.783374667167664, "val_acc": 28.0}
