"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 1311.318759918213, "training_acc": 40.0, "val_loss": 519.1989421844482, "val_acc": 72.0}
{"epoch": 1, "training_loss": 1545.6118144989014, "training_acc": 72.0, "val_loss": 872.7120399475098, "val_acc": 28.0}
{"epoch": 2, "training_loss": 2979.2836532592773, "training_acc": 28.0, "val_loss": 123.46711158752441, "val_acc": 72.0}
{"epoch": 3, "training_loss": 762.7456283569336, "training_acc": 72.0, "val_loss": 288.5448932647705, "val_acc": 72.0}
{"epoch": 4, "training_loss": 1040.4021835327148, "training_acc": 72.0, "val_loss": 70.75619101524353, "val_acc": 72.0}
{"epoch": 5, "training_loss": 580.3537712097168, "training_acc": 56.0, "val_loss": 137.95819282531738, "val_acc": 28.0}
{"epoch": 6, "training_loss": 547.9665451049805, "training_acc": 44.0, "val_loss": 218.92099380493164, "val_acc": 72.0}
{"epoch": 7, "training_loss": 885.9236755371094, "training_acc": 72.0, "val_loss": 157.0933222770691, "val_acc": 72.0}
{"epoch": 8, "training_loss": 447.4128465652466, "training_acc": 72.0, "val_loss": 247.11825847625732, "val_acc": 28.0}
{"epoch": 9, "training_loss": 853.7927570343018, "training_acc": 28.0, "val_loss": 96.12136483192444, "val_acc": 72.0}
{"epoch": 10, "training_loss": 429.5229387283325, "training_acc": 72.0, "val_loss": 156.7981243133545, "val_acc": 72.0}
{"epoch": 11, "training_loss": 554.646427154541, "training_acc": 72.0, "val_loss": 21.115760505199432, "val_acc": 72.0}
{"epoch": 12, "training_loss": 427.7075004577637, "training_acc": 56.0, "val_loss": 150.86088180541992, "val_acc": 28.0}
{"epoch": 13, "training_loss": 521.6968059539795, "training_acc": 44.0, "val_loss": 163.6467456817627, "val_acc": 72.0}
{"epoch": 14, "training_loss": 649.3394412994385, "training_acc": 72.0, "val_loss": 115.4889702796936, "val_acc": 72.0}
{"epoch": 15, "training_loss": 326.69817781448364, "training_acc": 72.0, "val_loss": 208.42022895812988, "val_acc": 28.0}
{"epoch": 16, "training_loss": 685.2779970169067, "training_acc": 28.0, "val_loss": 102.37090587615967, "val_acc": 72.0}
{"epoch": 17, "training_loss": 500.01445960998535, "training_acc": 72.0, "val_loss": 150.43123960494995, "val_acc": 72.0}
{"epoch": 18, "training_loss": 509.66348457336426, "training_acc": 72.0, "val_loss": 16.81901514530182, "val_acc": 28.0}
{"epoch": 19, "training_loss": 184.97678756713867, "training_acc": 58.0, "val_loss": 46.95380926132202, "val_acc": 72.0}
{"epoch": 20, "training_loss": 244.73661422729492, "training_acc": 72.0, "val_loss": 30.64241111278534, "val_acc": 72.0}
{"epoch": 21, "training_loss": 287.3093738555908, "training_acc": 54.0, "val_loss": 15.731638669967651, "val_acc": 72.0}
{"epoch": 22, "training_loss": 84.74149656295776, "training_acc": 72.0, "val_loss": 19.844253361225128, "val_acc": 72.0}
{"epoch": 23, "training_loss": 137.88901233673096, "training_acc": 60.0, "val_loss": 49.153536558151245, "val_acc": 72.0}
{"epoch": 24, "training_loss": 200.97763633728027, "training_acc": 72.0, "val_loss": 19.72029209136963, "val_acc": 72.0}
{"epoch": 25, "training_loss": 300.0737495422363, "training_acc": 48.0, "val_loss": 30.277317762374878, "val_acc": 72.0}
{"epoch": 26, "training_loss": 155.8102912902832, "training_acc": 72.0, "val_loss": 19.430585205554962, "val_acc": 72.0}
{"epoch": 27, "training_loss": 196.61785697937012, "training_acc": 58.0, "val_loss": 31.060409545898438, "val_acc": 72.0}
{"epoch": 28, "training_loss": 148.6451005935669, "training_acc": 72.0, "val_loss": 17.513060569763184, "val_acc": 28.0}
{"epoch": 29, "training_loss": 76.96850252151489, "training_acc": 28.0, "val_loss": 68.60582828521729, "val_acc": 72.0}
{"epoch": 30, "training_loss": 282.5523099899292, "training_acc": 72.0, "val_loss": 30.5192768573761, "val_acc": 72.0}
{"epoch": 31, "training_loss": 265.1970329284668, "training_acc": 56.0, "val_loss": 16.76081120967865, "val_acc": 72.0}
{"epoch": 32, "training_loss": 109.60360336303711, "training_acc": 72.0, "val_loss": 14.957499504089355, "val_acc": 72.0}
{"epoch": 33, "training_loss": 93.92227363586426, "training_acc": 56.0, "val_loss": 75.71398615837097, "val_acc": 72.0}
{"epoch": 34, "training_loss": 308.87294912338257, "training_acc": 72.0, "val_loss": 58.5810124874115, "val_acc": 72.0}
{"epoch": 35, "training_loss": 151.78439497947693, "training_acc": 62.0, "val_loss": 34.179189801216125, "val_acc": 28.0}
{"epoch": 36, "training_loss": 253.49482536315918, "training_acc": 38.0, "val_loss": 97.21740484237671, "val_acc": 72.0}
{"epoch": 37, "training_loss": 325.28721809387207, "training_acc": 72.0, "val_loss": 72.47951626777649, "val_acc": 28.0}
{"epoch": 38, "training_loss": 207.04080533981323, "training_acc": 48.0, "val_loss": 31.411293148994446, "val_acc": 72.0}
{"epoch": 39, "training_loss": 118.10681867599487, "training_acc": 58.0, "val_loss": 45.86607217788696, "val_acc": 72.0}
{"epoch": 40, "training_loss": 175.01869535446167, "training_acc": 72.0, "val_loss": 46.25425636768341, "val_acc": 28.0}
{"epoch": 41, "training_loss": 236.15641498565674, "training_acc": 38.0, "val_loss": 53.84901762008667, "val_acc": 72.0}
{"epoch": 42, "training_loss": 176.18210411071777, "training_acc": 54.0, "val_loss": 20.049165189266205, "val_acc": 72.0}
{"epoch": 43, "training_loss": 73.74665522575378, "training_acc": 58.0, "val_loss": 22.92460948228836, "val_acc": 72.0}
{"epoch": 44, "training_loss": 99.78866481781006, "training_acc": 54.0, "val_loss": 56.58462643623352, "val_acc": 72.0}
{"epoch": 45, "training_loss": 230.8732500076294, "training_acc": 72.0, "val_loss": 16.416774690151215, "val_acc": 28.0}
{"epoch": 46, "training_loss": 69.52777862548828, "training_acc": 62.0, "val_loss": 39.11341726779938, "val_acc": 72.0}
{"epoch": 47, "training_loss": 131.1222014427185, "training_acc": 72.0, "val_loss": 79.20534610748291, "val_acc": 28.0}
{"epoch": 48, "training_loss": 256.3049087524414, "training_acc": 48.0, "val_loss": 79.08732295036316, "val_acc": 72.0}
{"epoch": 49, "training_loss": 267.82408237457275, "training_acc": 72.0, "val_loss": 80.73810935020447, "val_acc": 28.0}
{"epoch": 50, "training_loss": 255.61241340637207, "training_acc": 44.0, "val_loss": 35.2558434009552, "val_acc": 72.0}
{"epoch": 51, "training_loss": 148.26347398757935, "training_acc": 56.0, "val_loss": 57.818603515625, "val_acc": 72.0}
