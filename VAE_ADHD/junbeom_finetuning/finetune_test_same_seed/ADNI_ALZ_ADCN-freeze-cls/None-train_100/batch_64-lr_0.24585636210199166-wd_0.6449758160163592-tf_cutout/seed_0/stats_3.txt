"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 886.6358642578125, "training_acc": 48.0, "val_loss": 554.3274879455566, "val_acc": 72.0}
{"epoch": 1, "training_loss": 1533.7896366119385, "training_acc": 72.0, "val_loss": 989.4012451171875, "val_acc": 28.0}
{"epoch": 2, "training_loss": 3388.2824325561523, "training_acc": 28.0, "val_loss": 110.99472045898438, "val_acc": 72.0}
{"epoch": 3, "training_loss": 632.5126533508301, "training_acc": 72.0, "val_loss": 282.07387924194336, "val_acc": 72.0}
{"epoch": 4, "training_loss": 1026.7038459777832, "training_acc": 72.0, "val_loss": 79.42051291465759, "val_acc": 72.0}
{"epoch": 5, "training_loss": 540.2651100158691, "training_acc": 60.0, "val_loss": 165.97256660461426, "val_acc": 28.0}
{"epoch": 6, "training_loss": 566.7329750061035, "training_acc": 46.0, "val_loss": 199.01695251464844, "val_acc": 72.0}
{"epoch": 7, "training_loss": 809.9737586975098, "training_acc": 72.0, "val_loss": 131.59213066101074, "val_acc": 72.0}
{"epoch": 8, "training_loss": 337.2936339378357, "training_acc": 72.0, "val_loss": 316.6604518890381, "val_acc": 28.0}
{"epoch": 9, "training_loss": 1112.9715766906738, "training_acc": 28.0, "val_loss": 85.64753532409668, "val_acc": 72.0}
{"epoch": 10, "training_loss": 481.0005168914795, "training_acc": 72.0, "val_loss": 163.01629543304443, "val_acc": 72.0}
{"epoch": 11, "training_loss": 580.1136236190796, "training_acc": 72.0, "val_loss": 15.093295276165009, "val_acc": 72.0}
{"epoch": 12, "training_loss": 336.50279235839844, "training_acc": 54.0, "val_loss": 19.829948246479034, "val_acc": 28.0}
{"epoch": 13, "training_loss": 208.08158683776855, "training_acc": 44.0, "val_loss": 144.14089918136597, "val_acc": 72.0}
{"epoch": 14, "training_loss": 537.4913063049316, "training_acc": 72.0, "val_loss": 43.57789158821106, "val_acc": 72.0}
{"epoch": 15, "training_loss": 349.5996265411377, "training_acc": 56.0, "val_loss": 38.04132640361786, "val_acc": 28.0}
{"epoch": 16, "training_loss": 233.1636085510254, "training_acc": 48.0, "val_loss": 185.0728988647461, "val_acc": 72.0}
{"epoch": 17, "training_loss": 737.3131427764893, "training_acc": 72.0, "val_loss": 124.50608015060425, "val_acc": 72.0}
{"epoch": 18, "training_loss": 360.4030842781067, "training_acc": 72.0, "val_loss": 239.1357421875, "val_acc": 28.0}
{"epoch": 19, "training_loss": 813.0928058624268, "training_acc": 28.0, "val_loss": 98.4442949295044, "val_acc": 72.0}
{"epoch": 20, "training_loss": 476.03841972351074, "training_acc": 72.0, "val_loss": 165.450119972229, "val_acc": 72.0}
{"epoch": 21, "training_loss": 589.1243286132812, "training_acc": 72.0, "val_loss": 28.98920476436615, "val_acc": 72.0}
{"epoch": 22, "training_loss": 398.9428520202637, "training_acc": 56.0, "val_loss": 121.57397270202637, "val_acc": 28.0}
{"epoch": 23, "training_loss": 410.8240623474121, "training_acc": 48.0, "val_loss": 171.9570279121399, "val_acc": 72.0}
{"epoch": 24, "training_loss": 711.3526458740234, "training_acc": 72.0, "val_loss": 129.09692525863647, "val_acc": 72.0}
{"epoch": 25, "training_loss": 374.89012575149536, "training_acc": 72.0, "val_loss": 212.08093166351318, "val_acc": 28.0}
{"epoch": 26, "training_loss": 741.8099460601807, "training_acc": 28.0, "val_loss": 98.03251624107361, "val_acc": 72.0}
{"epoch": 27, "training_loss": 465.057165145874, "training_acc": 72.0, "val_loss": 170.43944597244263, "val_acc": 72.0}
{"epoch": 28, "training_loss": 625.7368021011353, "training_acc": 72.0, "val_loss": 44.16140615940094, "val_acc": 72.0}
{"epoch": 29, "training_loss": 348.50764656066895, "training_acc": 56.0, "val_loss": 52.89978384971619, "val_acc": 28.0}
{"epoch": 30, "training_loss": 265.2164030075073, "training_acc": 48.0, "val_loss": 185.26153564453125, "val_acc": 72.0}
