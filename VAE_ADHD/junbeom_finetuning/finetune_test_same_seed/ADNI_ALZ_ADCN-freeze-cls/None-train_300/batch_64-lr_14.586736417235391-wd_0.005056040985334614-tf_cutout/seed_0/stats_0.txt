"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 300 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 302333.49017333984, "training_acc": 54.666666666666664, "val_loss": 66279.87634277344, "val_acc": 26.666666666666668}
{"epoch": 1, "training_loss": 195757.33374023438, "training_acc": 64.0, "val_loss": 27193.832611083984, "val_acc": 73.33333333333333}
{"epoch": 2, "training_loss": 59608.99206542969, "training_acc": 54.666666666666664, "val_loss": 1477.983018875122, "val_acc": 73.33333333333333}
{"epoch": 3, "training_loss": 31205.188354492188, "training_acc": 64.0, "val_loss": 4798.466339111328, "val_acc": 73.33333333333333}
{"epoch": 4, "training_loss": 43468.95950317383, "training_acc": 60.666666666666664, "val_loss": 29044.95489501953, "val_acc": 26.666666666666668}
{"epoch": 5, "training_loss": 123476.43823242188, "training_acc": 52.0, "val_loss": 41114.21643066406, "val_acc": 73.33333333333333}
{"epoch": 6, "training_loss": 172669.0538330078, "training_acc": 52.666666666666664, "val_loss": 4454.991561889648, "val_acc": 26.666666666666668}
{"epoch": 7, "training_loss": 185785.69311523438, "training_acc": 64.66666666666667, "val_loss": 63857.31555175781, "val_acc": 73.33333333333333}
{"epoch": 8, "training_loss": 168760.994140625, "training_acc": 66.0, "val_loss": 68020.80303955078, "val_acc": 26.666666666666668}
{"epoch": 9, "training_loss": 178641.95166015625, "training_acc": 50.666666666666664, "val_loss": 54975.07424926758, "val_acc": 73.33333333333333}
{"epoch": 10, "training_loss": 158241.201171875, "training_acc": 64.66666666666667, "val_loss": 43838.04797363281, "val_acc": 26.666666666666668}
{"epoch": 11, "training_loss": 80731.8773803711, "training_acc": 61.333333333333336, "val_loss": 16505.963409423828, "val_acc": 26.666666666666668}
{"epoch": 12, "training_loss": 87607.35302734375, "training_acc": 55.333333333333336, "val_loss": 33159.4600982666, "val_acc": 73.33333333333333}
{"epoch": 13, "training_loss": 123879.37133789062, "training_acc": 56.666666666666664, "val_loss": 1198.5625505447388, "val_acc": 73.33333333333333}
{"epoch": 14, "training_loss": 30361.091552734375, "training_acc": 57.333333333333336, "val_loss": 17449.001953125, "val_acc": 73.33333333333333}
{"epoch": 15, "training_loss": 47973.265625, "training_acc": 62.666666666666664, "val_loss": 18747.798629760742, "val_acc": 73.33333333333333}
{"epoch": 16, "training_loss": 100191.43655395508, "training_acc": 72.0, "val_loss": 30024.4619140625, "val_acc": 26.666666666666668}
{"epoch": 17, "training_loss": 103440.08813476562, "training_acc": 53.333333333333336, "val_loss": 25252.587287902832, "val_acc": 73.33333333333333}
{"epoch": 18, "training_loss": 63696.885192871094, "training_acc": 56.666666666666664, "val_loss": 30830.02850341797, "val_acc": 73.33333333333333}
{"epoch": 19, "training_loss": 102207.72207641602, "training_acc": 72.0, "val_loss": 63590.580322265625, "val_acc": 26.666666666666668}
{"epoch": 20, "training_loss": 171810.15747070312, "training_acc": 45.333333333333336, "val_loss": 62370.03869628906, "val_acc": 73.33333333333333}
{"epoch": 21, "training_loss": 210190.25854492188, "training_acc": 72.0, "val_loss": 8479.5947265625, "val_acc": 26.666666666666668}
{"epoch": 22, "training_loss": 73496.06787109375, "training_acc": 51.333333333333336, "val_loss": 18020.334442138672, "val_acc": 73.33333333333333}
{"epoch": 23, "training_loss": 104342.09219360352, "training_acc": 53.333333333333336, "val_loss": 17406.03045654297, "val_acc": 73.33333333333333}
{"epoch": 24, "training_loss": 52684.7536315918, "training_acc": 63.333333333333336, "val_loss": 5021.517631530762, "val_acc": 73.33333333333333}
{"epoch": 25, "training_loss": 24245.08826828003, "training_acc": 64.66666666666667, "val_loss": 28056.802215576172, "val_acc": 26.666666666666668}
{"epoch": 26, "training_loss": 41670.10543823242, "training_acc": 53.333333333333336, "val_loss": 15651.364196777344, "val_acc": 73.33333333333333}
{"epoch": 27, "training_loss": 35942.03650665283, "training_acc": 61.333333333333336, "val_loss": 22829.76791381836, "val_acc": 26.666666666666668}
{"epoch": 28, "training_loss": 40308.510009765625, "training_acc": 51.333333333333336, "val_loss": 16922.73304748535, "val_acc": 73.33333333333333}
{"epoch": 29, "training_loss": 76758.7197265625, "training_acc": 57.333333333333336, "val_loss": 13934.162292480469, "val_acc": 73.33333333333333}
{"epoch": 30, "training_loss": 82882.59655761719, "training_acc": 72.0, "val_loss": 32710.147003173828, "val_acc": 26.666666666666668}
{"epoch": 31, "training_loss": 116835.470703125, "training_acc": 52.0, "val_loss": 29440.37417602539, "val_acc": 73.33333333333333}
{"epoch": 32, "training_loss": 122547.39611816406, "training_acc": 58.0, "val_loss": 10819.741470336914, "val_acc": 26.666666666666668}
