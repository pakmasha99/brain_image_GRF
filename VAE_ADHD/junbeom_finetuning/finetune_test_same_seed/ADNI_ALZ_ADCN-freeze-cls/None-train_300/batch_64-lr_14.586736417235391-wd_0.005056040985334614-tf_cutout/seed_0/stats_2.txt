"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 300 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 272880.8375816345, "training_acc": 59.666666666666664, "val_loss": 78069.29553222656, "val_acc": 28.0}
{"epoch": 1, "training_loss": 221362.5128173828, "training_acc": 63.0, "val_loss": 29354.12678527832, "val_acc": 72.0}
{"epoch": 2, "training_loss": 162364.4747314453, "training_acc": 49.666666666666664, "val_loss": 46824.77014160156, "val_acc": 72.0}
{"epoch": 3, "training_loss": 293154.5400390625, "training_acc": 72.33333333333333, "val_loss": 66323.97314453125, "val_acc": 72.0}
{"epoch": 4, "training_loss": 209102.82763671875, "training_acc": 53.666666666666664, "val_loss": 11238.712646484375, "val_acc": 28.0}
{"epoch": 5, "training_loss": 196721.56494140625, "training_acc": 62.333333333333336, "val_loss": 68138.32830810547, "val_acc": 72.0}
{"epoch": 6, "training_loss": 178762.45056152344, "training_acc": 64.33333333333333, "val_loss": 91070.8095703125, "val_acc": 28.0}
{"epoch": 7, "training_loss": 236081.4267578125, "training_acc": 48.333333333333336, "val_loss": 59620.86703491211, "val_acc": 72.0}
{"epoch": 8, "training_loss": 153235.60546875, "training_acc": 68.33333333333333, "val_loss": 53842.35485839844, "val_acc": 28.0}
{"epoch": 9, "training_loss": 74469.3261642456, "training_acc": 59.666666666666664, "val_loss": 39238.30126953125, "val_acc": 28.0}
{"epoch": 10, "training_loss": 122896.74841308594, "training_acc": 51.666666666666664, "val_loss": 32632.942016601562, "val_acc": 72.0}
{"epoch": 11, "training_loss": 126279.57470703125, "training_acc": 55.666666666666664, "val_loss": 1981.6134777069092, "val_acc": 72.0}
{"epoch": 12, "training_loss": 35425.93524169922, "training_acc": 67.66666666666667, "val_loss": 6511.298210144043, "val_acc": 72.0}
{"epoch": 13, "training_loss": 37954.21112060547, "training_acc": 63.666666666666664, "val_loss": 12396.639907836914, "val_acc": 72.0}
{"epoch": 14, "training_loss": 31187.581115722656, "training_acc": 56.333333333333336, "val_loss": 9705.92610168457, "val_acc": 72.0}
{"epoch": 15, "training_loss": 32344.54443359375, "training_acc": 66.33333333333333, "val_loss": 8531.183654785156, "val_acc": 72.0}
{"epoch": 16, "training_loss": 44579.10778808594, "training_acc": 55.666666666666664, "val_loss": 43372.588623046875, "val_acc": 72.0}
{"epoch": 17, "training_loss": 152752.802734375, "training_acc": 72.33333333333333, "val_loss": 27175.559936523438, "val_acc": 28.0}
{"epoch": 18, "training_loss": 87277.6157836914, "training_acc": 53.0, "val_loss": 16452.055206298828, "val_acc": 72.0}
{"epoch": 19, "training_loss": 77014.69140625, "training_acc": 57.0, "val_loss": 26028.573516845703, "val_acc": 72.0}
{"epoch": 20, "training_loss": 81845.91723632812, "training_acc": 65.66666666666667, "val_loss": 12688.035537719727, "val_acc": 28.0}
{"epoch": 21, "training_loss": 116376.46008300781, "training_acc": 61.0, "val_loss": 17914.36492919922, "val_acc": 72.0}
{"epoch": 22, "training_loss": 45563.835052490234, "training_acc": 50.333333333333336, "val_loss": 21356.456115722656, "val_acc": 72.0}
{"epoch": 23, "training_loss": 83675.7900390625, "training_acc": 51.666666666666664, "val_loss": 23332.354614257812, "val_acc": 72.0}
{"epoch": 24, "training_loss": 133867.19580078125, "training_acc": 72.33333333333333, "val_loss": 9510.2734375, "val_acc": 72.0}
{"epoch": 25, "training_loss": 81309.421875, "training_acc": 55.666666666666664, "val_loss": 19013.84930419922, "val_acc": 72.0}
{"epoch": 26, "training_loss": 44603.499084472656, "training_acc": 61.0, "val_loss": 15299.332534790039, "val_acc": 28.0}
{"epoch": 27, "training_loss": 36123.108947753906, "training_acc": 59.666666666666664, "val_loss": 2892.1083030700684, "val_acc": 72.0}
{"epoch": 28, "training_loss": 31924.837524414062, "training_acc": 62.333333333333336, "val_loss": 4561.639024734497, "val_acc": 72.0}
{"epoch": 29, "training_loss": 73054.19006347656, "training_acc": 52.333333333333336, "val_loss": 50814.21307373047, "val_acc": 72.0}
{"epoch": 30, "training_loss": 146255.00427246094, "training_acc": 62.333333333333336, "val_loss": 6010.304904937744, "val_acc": 28.0}
