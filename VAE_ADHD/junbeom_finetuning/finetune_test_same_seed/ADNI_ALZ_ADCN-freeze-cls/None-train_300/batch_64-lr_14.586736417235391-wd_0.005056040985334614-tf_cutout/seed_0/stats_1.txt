"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 300 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 268740.4806289673, "training_acc": 69.0, "val_loss": 60760.05810546875, "val_acc": 28.0}
{"epoch": 1, "training_loss": 185101.24279785156, "training_acc": 64.33333333333333, "val_loss": 18145.787200927734, "val_acc": 72.0}
{"epoch": 2, "training_loss": 106964.7626953125, "training_acc": 56.333333333333336, "val_loss": 54614.076904296875, "val_acc": 72.0}
{"epoch": 3, "training_loss": 113614.46311950684, "training_acc": 63.0, "val_loss": 2103.72540473938, "val_acc": 28.0}
{"epoch": 4, "training_loss": 72854.37030029297, "training_acc": 63.666666666666664, "val_loss": 16250.069869995117, "val_acc": 28.0}
{"epoch": 5, "training_loss": 43556.406799316406, "training_acc": 55.0, "val_loss": 24197.891143798828, "val_acc": 72.0}
{"epoch": 6, "training_loss": 50828.69659423828, "training_acc": 61.666666666666664, "val_loss": 1065.6863594055176, "val_acc": 28.0}
{"epoch": 7, "training_loss": 35465.41882324219, "training_acc": 59.0, "val_loss": 5843.329116821289, "val_acc": 72.0}
{"epoch": 8, "training_loss": 32196.84423828125, "training_acc": 64.33333333333333, "val_loss": 9619.929962158203, "val_acc": 72.0}
{"epoch": 9, "training_loss": 53945.0732421875, "training_acc": 59.666666666666664, "val_loss": 7093.2617111206055, "val_acc": 28.0}
{"epoch": 10, "training_loss": 42068.0502243042, "training_acc": 48.333333333333336, "val_loss": 4630.065803527832, "val_acc": 72.0}
{"epoch": 11, "training_loss": 46443.6181640625, "training_acc": 55.0, "val_loss": 43335.26089477539, "val_acc": 72.0}
{"epoch": 12, "training_loss": 156499.88732910156, "training_acc": 72.33333333333333, "val_loss": 10042.642036437988, "val_acc": 28.0}
{"epoch": 13, "training_loss": 94675.697265625, "training_acc": 47.0, "val_loss": 22941.674598693848, "val_acc": 72.0}
{"epoch": 14, "training_loss": 98828.82321166992, "training_acc": 53.666666666666664, "val_loss": 18319.12872314453, "val_acc": 72.0}
{"epoch": 15, "training_loss": 74348.09619140625, "training_acc": 67.0, "val_loss": 35443.474670410156, "val_acc": 28.0}
{"epoch": 16, "training_loss": 86929.53051757812, "training_acc": 65.0, "val_loss": 5030.5751876831055, "val_acc": 72.0}
{"epoch": 17, "training_loss": 90873.63171386719, "training_acc": 52.333333333333336, "val_loss": 28933.575469970703, "val_acc": 72.0}
{"epoch": 18, "training_loss": 62288.59211730957, "training_acc": 64.33333333333333, "val_loss": 11743.974487304688, "val_acc": 28.0}
{"epoch": 19, "training_loss": 54999.94110107422, "training_acc": 62.333333333333336, "val_loss": 24925.453735351562, "val_acc": 28.0}
{"epoch": 20, "training_loss": 101204.26867675781, "training_acc": 51.666666666666664, "val_loss": 31167.184448242188, "val_acc": 72.0}
{"epoch": 21, "training_loss": 49507.18593597412, "training_acc": 62.333333333333336, "val_loss": 28817.24380493164, "val_acc": 28.0}
{"epoch": 22, "training_loss": 51622.65026855469, "training_acc": 55.0, "val_loss": 12020.374267578125, "val_acc": 28.0}
{"epoch": 23, "training_loss": 118686.92578125, "training_acc": 61.0, "val_loss": 23927.09130859375, "val_acc": 72.0}
{"epoch": 24, "training_loss": 105560.85223388672, "training_acc": 53.666666666666664, "val_loss": 14866.472259521484, "val_acc": 72.0}
{"epoch": 25, "training_loss": 43434.32415008545, "training_acc": 66.33333333333333, "val_loss": 890.9304904937744, "val_acc": 72.0}
{"epoch": 26, "training_loss": 46617.28674316406, "training_acc": 61.0, "val_loss": 10723.538131713867, "val_acc": 28.0}
{"epoch": 27, "training_loss": 41379.36779785156, "training_acc": 55.666666666666664, "val_loss": 8215.139549255371, "val_acc": 28.0}
{"epoch": 28, "training_loss": 109884.11071777344, "training_acc": 63.0, "val_loss": 20953.688751220703, "val_acc": 72.0}
{"epoch": 29, "training_loss": 131135.0064239502, "training_acc": 49.0, "val_loss": 11852.642890930176, "val_acc": 72.0}
{"epoch": 30, "training_loss": 36825.27896118164, "training_acc": 64.33333333333333, "val_loss": 1523.0001258850098, "val_acc": 72.0}
{"epoch": 31, "training_loss": 31713.924102783203, "training_acc": 55.0, "val_loss": 13847.752182006836, "val_acc": 72.0}
{"epoch": 32, "training_loss": 61406.302734375, "training_acc": 65.66666666666667, "val_loss": 16283.091888427734, "val_acc": 28.0}
{"epoch": 33, "training_loss": 114640.98071289062, "training_acc": 61.666666666666664, "val_loss": 19328.465393066406, "val_acc": 72.0}
{"epoch": 34, "training_loss": 111230.81309509277, "training_acc": 47.0, "val_loss": 38336.63098144531, "val_acc": 72.0}
{"epoch": 35, "training_loss": 247478.474609375, "training_acc": 72.33333333333333, "val_loss": 55282.70733642578, "val_acc": 72.0}
{"epoch": 36, "training_loss": 152568.52905273438, "training_acc": 55.666666666666664, "val_loss": 6456.847854614258, "val_acc": 28.0}
{"epoch": 37, "training_loss": 185573.60302734375, "training_acc": 61.0, "val_loss": 59865.558837890625, "val_acc": 72.0}
{"epoch": 38, "training_loss": 141940.345703125, "training_acc": 67.66666666666667, "val_loss": 84266.09753417969, "val_acc": 28.0}
{"epoch": 39, "training_loss": 194191.58544921875, "training_acc": 52.333333333333336, "val_loss": 49662.69464111328, "val_acc": 72.0}
{"epoch": 40, "training_loss": 137482.59619140625, "training_acc": 66.33333333333333, "val_loss": 57922.448791503906, "val_acc": 28.0}
{"epoch": 41, "training_loss": 170931.30078125, "training_acc": 51.666666666666664, "val_loss": 70147.21655273438, "val_acc": 72.0}
{"epoch": 42, "training_loss": 187719.5948791504, "training_acc": 63.666666666666664, "val_loss": 2876.6982917785645, "val_acc": 28.0}
{"epoch": 43, "training_loss": 85621.62390136719, "training_acc": 64.33333333333333, "val_loss": 9597.80209350586, "val_acc": 72.0}
{"epoch": 44, "training_loss": 77620.23815917969, "training_acc": 54.333333333333336, "val_loss": 28103.195587158203, "val_acc": 72.0}
