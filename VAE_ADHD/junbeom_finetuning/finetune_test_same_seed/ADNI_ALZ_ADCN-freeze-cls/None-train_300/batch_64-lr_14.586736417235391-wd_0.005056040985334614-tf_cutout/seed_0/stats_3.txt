"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 300 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 305540.22523498535, "training_acc": 57.0, "val_loss": 93454.17041015625, "val_acc": 28.0}
{"epoch": 1, "training_loss": 189382.9815673828, "training_acc": 63.0, "val_loss": 20024.23828125, "val_acc": 72.0}
{"epoch": 2, "training_loss": 99179.80358886719, "training_acc": 52.333333333333336, "val_loss": 53182.834411621094, "val_acc": 72.0}
{"epoch": 3, "training_loss": 164503.5087890625, "training_acc": 63.666666666666664, "val_loss": 53054.125915527344, "val_acc": 28.0}
{"epoch": 4, "training_loss": 110042.55041503906, "training_acc": 61.0, "val_loss": 1104.4785947799683, "val_acc": 72.0}
{"epoch": 5, "training_loss": 98208.12548828125, "training_acc": 55.0, "val_loss": 31488.601684570312, "val_acc": 72.0}
{"epoch": 6, "training_loss": 97337.60668945312, "training_acc": 58.333333333333336, "val_loss": 13830.4019241333, "val_acc": 72.0}
{"epoch": 7, "training_loss": 74377.89826202393, "training_acc": 72.33333333333333, "val_loss": 41116.65740966797, "val_acc": 28.0}
{"epoch": 8, "training_loss": 141955.34985351562, "training_acc": 48.333333333333336, "val_loss": 31639.19158935547, "val_acc": 72.0}
{"epoch": 9, "training_loss": 70969.07421875, "training_acc": 53.0, "val_loss": 35965.27835083008, "val_acc": 72.0}
{"epoch": 10, "training_loss": 110481.62878417969, "training_acc": 65.0, "val_loss": 2822.7845420837402, "val_acc": 72.0}
{"epoch": 11, "training_loss": 23162.767852783203, "training_acc": 66.33333333333333, "val_loss": 7494.663780212402, "val_acc": 28.0}
{"epoch": 12, "training_loss": 51875.408142089844, "training_acc": 61.666666666666664, "val_loss": 43743.115966796875, "val_acc": 28.0}
{"epoch": 13, "training_loss": 133985.87670898438, "training_acc": 51.0, "val_loss": 31750.900390625, "val_acc": 72.0}
{"epoch": 14, "training_loss": 55299.76431655884, "training_acc": 57.0, "val_loss": 18518.790130615234, "val_acc": 72.0}
{"epoch": 15, "training_loss": 81221.10949707031, "training_acc": 72.33333333333333, "val_loss": 50036.59167480469, "val_acc": 28.0}
{"epoch": 16, "training_loss": 102373.8060913086, "training_acc": 55.666666666666664, "val_loss": 9278.543357849121, "val_acc": 72.0}
{"epoch": 17, "training_loss": 35181.657958984375, "training_acc": 54.333333333333336, "val_loss": 11318.634094238281, "val_acc": 72.0}
{"epoch": 18, "training_loss": 64741.652099609375, "training_acc": 65.66666666666667, "val_loss": 22823.19891357422, "val_acc": 28.0}
{"epoch": 19, "training_loss": 85146.93627929688, "training_acc": 65.0, "val_loss": 11482.663864135742, "val_acc": 72.0}
{"epoch": 20, "training_loss": 65729.0673828125, "training_acc": 54.333333333333336, "val_loss": 39429.332458496094, "val_acc": 72.0}
{"epoch": 21, "training_loss": 127497.45166015625, "training_acc": 64.33333333333333, "val_loss": 49232.52587890625, "val_acc": 28.0}
{"epoch": 22, "training_loss": 59816.2643737793, "training_acc": 65.66666666666667, "val_loss": 20972.61651611328, "val_acc": 28.0}
{"epoch": 23, "training_loss": 38940.56618499756, "training_acc": 55.666666666666664, "val_loss": 10176.886177062988, "val_acc": 72.0}
