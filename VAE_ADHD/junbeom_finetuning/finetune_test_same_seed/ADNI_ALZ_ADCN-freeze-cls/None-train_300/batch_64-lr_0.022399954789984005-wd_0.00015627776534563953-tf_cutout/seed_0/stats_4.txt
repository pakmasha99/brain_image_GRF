"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 300 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 525.4772300720215, "training_acc": 54.333333333333336, "val_loss": 78.84921479225159, "val_acc": 28.0}
{"epoch": 1, "training_loss": 252.47149324417114, "training_acc": 65.66666666666667, "val_loss": 45.89842176437378, "val_acc": 72.0}
{"epoch": 2, "training_loss": 207.09315729141235, "training_acc": 54.333333333333336, "val_loss": 54.980788469314575, "val_acc": 72.0}
{"epoch": 3, "training_loss": 196.9439594745636, "training_acc": 72.66666666666667, "val_loss": 45.034536480903625, "val_acc": 72.0}
{"epoch": 4, "training_loss": 185.55457758903503, "training_acc": 72.33333333333333, "val_loss": 48.547698974609375, "val_acc": 28.0}
{"epoch": 5, "training_loss": 184.51406455039978, "training_acc": 72.33333333333333, "val_loss": 45.807609021663666, "val_acc": 72.0}
{"epoch": 6, "training_loss": 175.98569703102112, "training_acc": 72.33333333333333, "val_loss": 44.286907970905304, "val_acc": 72.0}
{"epoch": 7, "training_loss": 177.63102102279663, "training_acc": 72.33333333333333, "val_loss": 45.5213623046875, "val_acc": 72.0}
{"epoch": 8, "training_loss": 179.89167666435242, "training_acc": 72.33333333333333, "val_loss": 44.327144742012024, "val_acc": 72.0}
{"epoch": 9, "training_loss": 178.21246314048767, "training_acc": 72.33333333333333, "val_loss": 44.99260348081589, "val_acc": 72.0}
{"epoch": 10, "training_loss": 180.75149130821228, "training_acc": 72.33333333333333, "val_loss": 44.4572833776474, "val_acc": 72.0}
{"epoch": 11, "training_loss": 194.02917194366455, "training_acc": 65.0, "val_loss": 44.41043496131897, "val_acc": 72.0}
{"epoch": 12, "training_loss": 206.67250037193298, "training_acc": 71.66666666666667, "val_loss": 59.17539322376251, "val_acc": 28.0}
{"epoch": 13, "training_loss": 203.16726112365723, "training_acc": 61.0, "val_loss": 44.49538069963455, "val_acc": 72.0}
{"epoch": 14, "training_loss": 176.2495894432068, "training_acc": 72.33333333333333, "val_loss": 49.44353151321411, "val_acc": 72.0}
{"epoch": 15, "training_loss": 201.2920913696289, "training_acc": 72.33333333333333, "val_loss": 62.100620448589325, "val_acc": 72.0}
{"epoch": 16, "training_loss": 223.36008405685425, "training_acc": 61.0, "val_loss": 56.00240993499756, "val_acc": 72.0}
{"epoch": 17, "training_loss": 227.83278608322144, "training_acc": 61.0, "val_loss": 53.19413584470749, "val_acc": 72.0}
{"epoch": 18, "training_loss": 206.8117687702179, "training_acc": 72.33333333333333, "val_loss": 44.60160452127457, "val_acc": 72.0}
{"epoch": 19, "training_loss": 192.01546573638916, "training_acc": 72.33333333333333, "val_loss": 55.33078569173813, "val_acc": 28.0}
{"epoch": 20, "training_loss": 221.3149869441986, "training_acc": 60.333333333333336, "val_loss": 63.00344109535217, "val_acc": 28.0}
{"epoch": 21, "training_loss": 212.89871549606323, "training_acc": 56.333333333333336, "val_loss": 52.15313273668289, "val_acc": 72.0}
{"epoch": 22, "training_loss": 195.09194540977478, "training_acc": 72.66666666666667, "val_loss": 53.53343588113785, "val_acc": 72.0}
{"epoch": 23, "training_loss": 193.6924569606781, "training_acc": 73.0, "val_loss": 43.677983045578, "val_acc": 72.0}
{"epoch": 24, "training_loss": 179.74495792388916, "training_acc": 72.33333333333333, "val_loss": 63.784214437007904, "val_acc": 28.0}
{"epoch": 25, "training_loss": 205.7804205417633, "training_acc": 61.0, "val_loss": 43.64905005693436, "val_acc": 72.0}
{"epoch": 26, "training_loss": 180.05928540229797, "training_acc": 72.33333333333333, "val_loss": 43.52862924337387, "val_acc": 72.0}
{"epoch": 27, "training_loss": 179.09587454795837, "training_acc": 72.33333333333333, "val_loss": 43.82322418689728, "val_acc": 72.0}
{"epoch": 28, "training_loss": 180.57280588150024, "training_acc": 72.33333333333333, "val_loss": 43.998770743608475, "val_acc": 72.0}
{"epoch": 29, "training_loss": 174.7816481590271, "training_acc": 72.33333333333333, "val_loss": 43.837433487176895, "val_acc": 72.0}
{"epoch": 30, "training_loss": 178.3240737915039, "training_acc": 72.33333333333333, "val_loss": 43.426114320755005, "val_acc": 72.0}
{"epoch": 31, "training_loss": 201.26331663131714, "training_acc": 69.33333333333333, "val_loss": 43.43143844604492, "val_acc": 72.0}
{"epoch": 32, "training_loss": 187.23573398590088, "training_acc": 63.666666666666664, "val_loss": 46.68850564956665, "val_acc": 72.0}
{"epoch": 33, "training_loss": 200.40322256088257, "training_acc": 63.333333333333336, "val_loss": 58.429674714803696, "val_acc": 72.0}
{"epoch": 34, "training_loss": 197.55939769744873, "training_acc": 63.666666666666664, "val_loss": 49.620709002017975, "val_acc": 72.0}
{"epoch": 35, "training_loss": 209.3464183807373, "training_acc": 72.0, "val_loss": 45.71480190753937, "val_acc": 72.0}
{"epoch": 36, "training_loss": 187.96361899375916, "training_acc": 72.66666666666667, "val_loss": 44.783945083618164, "val_acc": 68.0}
{"epoch": 37, "training_loss": 183.3337380886078, "training_acc": 72.33333333333333, "val_loss": 48.081039130687714, "val_acc": 28.0}
{"epoch": 38, "training_loss": 182.18224596977234, "training_acc": 73.66666666666667, "val_loss": 44.06220853328705, "val_acc": 77.33333333333333}
{"epoch": 39, "training_loss": 182.12752747535706, "training_acc": 72.33333333333333, "val_loss": 43.09201580286026, "val_acc": 72.0}
{"epoch": 40, "training_loss": 183.4589385986328, "training_acc": 68.0, "val_loss": 45.39391800761223, "val_acc": 72.0}
{"epoch": 41, "training_loss": 189.16559028625488, "training_acc": 72.33333333333333, "val_loss": 43.444954097270966, "val_acc": 72.0}
{"epoch": 42, "training_loss": 179.05406975746155, "training_acc": 72.33333333333333, "val_loss": 42.95086604356766, "val_acc": 72.0}
{"epoch": 43, "training_loss": 183.6206362247467, "training_acc": 72.0, "val_loss": 44.09150767326355, "val_acc": 72.0}
{"epoch": 44, "training_loss": 179.51027250289917, "training_acc": 72.33333333333333, "val_loss": 43.41825547814369, "val_acc": 72.0}
{"epoch": 45, "training_loss": 183.26850867271423, "training_acc": 72.66666666666667, "val_loss": 46.91714492440224, "val_acc": 72.0}
{"epoch": 46, "training_loss": 191.17506003379822, "training_acc": 69.66666666666667, "val_loss": 44.21089220046997, "val_acc": 72.0}
{"epoch": 47, "training_loss": 182.7026562690735, "training_acc": 73.33333333333333, "val_loss": 57.68871486186981, "val_acc": 72.0}
{"epoch": 48, "training_loss": 227.27842259407043, "training_acc": 51.0, "val_loss": 71.13077855110168, "val_acc": 72.0}
{"epoch": 49, "training_loss": 260.335077047348, "training_acc": 60.333333333333336, "val_loss": 57.61347246170044, "val_acc": 72.0}
{"epoch": 50, "training_loss": 236.22281408309937, "training_acc": 67.0, "val_loss": 67.69616663455963, "val_acc": 28.0}
{"epoch": 51, "training_loss": 226.67891097068787, "training_acc": 63.666666666666664, "val_loss": 47.01583671569824, "val_acc": 28.0}
{"epoch": 52, "training_loss": 209.34586715698242, "training_acc": 64.0, "val_loss": 43.343833446502686, "val_acc": 72.0}
{"epoch": 53, "training_loss": 194.37193417549133, "training_acc": 66.0, "val_loss": 50.38888669013977, "val_acc": 72.0}
{"epoch": 54, "training_loss": 185.48453974723816, "training_acc": 72.33333333333333, "val_loss": 42.97734063863754, "val_acc": 72.0}
{"epoch": 55, "training_loss": 171.97506427764893, "training_acc": 72.33333333333333, "val_loss": 43.43422031402588, "val_acc": 81.33333333333333}
{"epoch": 56, "training_loss": 182.89885807037354, "training_acc": 72.33333333333333, "val_loss": 44.15682244300842, "val_acc": 68.0}
{"epoch": 57, "training_loss": 187.876855134964, "training_acc": 72.0, "val_loss": 43.84515380859375, "val_acc": 74.66666666666667}
{"epoch": 58, "training_loss": 191.28324961662292, "training_acc": 72.33333333333333, "val_loss": 57.80863565206528, "val_acc": 28.0}
{"epoch": 59, "training_loss": 220.51639199256897, "training_acc": 59.666666666666664, "val_loss": 63.305341958999634, "val_acc": 28.0}
{"epoch": 60, "training_loss": 242.46736240386963, "training_acc": 53.666666666666664, "val_loss": 46.12818914651871, "val_acc": 72.0}
{"epoch": 61, "training_loss": 184.3085401058197, "training_acc": 66.66666666666667, "val_loss": 45.3867349922657, "val_acc": 72.0}
