"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 300 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 3402.493396759033, "training_acc": 57.666666666666664, "val_loss": 157.2400779724121, "val_acc": 28.0}
{"epoch": 1, "training_loss": 2812.829933166504, "training_acc": 63.0, "val_loss": 666.3507709503174, "val_acc": 72.0}
{"epoch": 2, "training_loss": 2100.2865278720856, "training_acc": 43.666666666666664, "val_loss": 411.9106636047363, "val_acc": 72.0}
{"epoch": 3, "training_loss": 2755.048267364502, "training_acc": 72.33333333333333, "val_loss": 424.4094126224518, "val_acc": 72.0}
{"epoch": 4, "training_loss": 2305.56138420105, "training_acc": 46.333333333333336, "val_loss": 352.7034397125244, "val_acc": 72.0}
{"epoch": 5, "training_loss": 3075.8728561401367, "training_acc": 72.33333333333333, "val_loss": 833.1728858947754, "val_acc": 72.0}
{"epoch": 6, "training_loss": 1875.8105030059814, "training_acc": 57.0, "val_loss": 44.33813428878784, "val_acc": 73.33333333333333}
{"epoch": 7, "training_loss": 992.5880680084229, "training_acc": 72.33333333333333, "val_loss": 85.38025403022766, "val_acc": 28.0}
{"epoch": 8, "training_loss": 706.4741888046265, "training_acc": 52.333333333333336, "val_loss": 116.55857753753662, "val_acc": 72.0}
{"epoch": 9, "training_loss": 518.4459991455078, "training_acc": 63.333333333333336, "val_loss": 71.19024306535721, "val_acc": 72.0}
{"epoch": 10, "training_loss": 575.3702421188354, "training_acc": 61.666666666666664, "val_loss": 187.6033514738083, "val_acc": 72.0}
{"epoch": 11, "training_loss": 931.2180595397949, "training_acc": 53.0, "val_loss": 397.157235622406, "val_acc": 72.0}
{"epoch": 12, "training_loss": 1503.6943068504333, "training_acc": 72.33333333333333, "val_loss": 396.94660806655884, "val_acc": 28.0}
{"epoch": 13, "training_loss": 1057.7514867782593, "training_acc": 54.333333333333336, "val_loss": 183.68121123313904, "val_acc": 72.0}
{"epoch": 14, "training_loss": 581.8471384048462, "training_acc": 52.333333333333336, "val_loss": 199.77805185317993, "val_acc": 72.0}
{"epoch": 15, "training_loss": 867.1473722457886, "training_acc": 51.0, "val_loss": 432.1398344039917, "val_acc": 72.0}
{"epoch": 16, "training_loss": 1380.8400509357452, "training_acc": 72.33333333333333, "val_loss": 608.2786855697632, "val_acc": 28.0}
{"epoch": 17, "training_loss": 1441.1704559326172, "training_acc": 50.333333333333336, "val_loss": 170.09413254261017, "val_acc": 72.0}
{"epoch": 18, "training_loss": 546.7899198532104, "training_acc": 59.333333333333336, "val_loss": 143.27403950691223, "val_acc": 72.0}
{"epoch": 19, "training_loss": 499.3014678955078, "training_acc": 63.0, "val_loss": 70.76786434650421, "val_acc": 72.0}
{"epoch": 20, "training_loss": 333.3667733669281, "training_acc": 67.0, "val_loss": 47.57661122083664, "val_acc": 29.333333333333332}
{"epoch": 21, "training_loss": 200.82858419418335, "training_acc": 65.66666666666667, "val_loss": 58.920224249362946, "val_acc": 72.0}
{"epoch": 22, "training_loss": 292.60850763320923, "training_acc": 55.666666666666664, "val_loss": 79.77834850549698, "val_acc": 72.0}
{"epoch": 23, "training_loss": 282.2470223903656, "training_acc": 62.0, "val_loss": 82.24929487705231, "val_acc": 72.0}
{"epoch": 24, "training_loss": 295.1727042198181, "training_acc": 61.666666666666664, "val_loss": 147.19056355953217, "val_acc": 28.0}
{"epoch": 25, "training_loss": 414.2066698074341, "training_acc": 60.333333333333336, "val_loss": 60.53463125228882, "val_acc": 72.0}
{"epoch": 26, "training_loss": 240.10021042823792, "training_acc": 64.33333333333333, "val_loss": 42.10641783475876, "val_acc": 72.0}
{"epoch": 27, "training_loss": 434.0571174621582, "training_acc": 63.0, "val_loss": 62.2206974029541, "val_acc": 28.0}
{"epoch": 28, "training_loss": 310.69369888305664, "training_acc": 57.333333333333336, "val_loss": 229.92452430725098, "val_acc": 28.0}
{"epoch": 29, "training_loss": 658.813925743103, "training_acc": 55.0, "val_loss": 64.38709098100662, "val_acc": 72.0}
{"epoch": 30, "training_loss": 249.89308881759644, "training_acc": 62.333333333333336, "val_loss": 55.01437050104141, "val_acc": 28.0}
{"epoch": 31, "training_loss": 388.3437783718109, "training_acc": 54.333333333333336, "val_loss": 163.95090609788895, "val_acc": 72.0}
{"epoch": 32, "training_loss": 471.1106643676758, "training_acc": 64.33333333333333, "val_loss": 133.88958191871643, "val_acc": 72.0}
{"epoch": 33, "training_loss": 787.3724536895752, "training_acc": 49.666666666666664, "val_loss": 541.5037927627563, "val_acc": 72.0}
{"epoch": 34, "training_loss": 2190.1655893325806, "training_acc": 72.33333333333333, "val_loss": 43.732697546482086, "val_acc": 52.0}
{"epoch": 35, "training_loss": 1286.1172351837158, "training_acc": 51.333333333333336, "val_loss": 575.5783219337463, "val_acc": 72.0}
{"epoch": 36, "training_loss": 1555.4039497375488, "training_acc": 67.66666666666667, "val_loss": 291.94300985336304, "val_acc": 28.0}
{"epoch": 37, "training_loss": 792.2178573608398, "training_acc": 66.33333333333333, "val_loss": 85.71666383743286, "val_acc": 28.0}
{"epoch": 38, "training_loss": 274.57167863845825, "training_acc": 54.666666666666664, "val_loss": 104.61191129684448, "val_acc": 72.0}
{"epoch": 39, "training_loss": 444.3045902252197, "training_acc": 64.33333333333333, "val_loss": 120.9973373413086, "val_acc": 72.0}
{"epoch": 40, "training_loss": 504.2409977912903, "training_acc": 62.333333333333336, "val_loss": 127.67944741249084, "val_acc": 72.0}
{"epoch": 41, "training_loss": 371.2411689758301, "training_acc": 61.666666666666664, "val_loss": 148.73413467407227, "val_acc": 28.0}
{"epoch": 42, "training_loss": 555.9635992050171, "training_acc": 56.333333333333336, "val_loss": 64.04801511764526, "val_acc": 28.0}
{"epoch": 43, "training_loss": 605.1999607086182, "training_acc": 53.0, "val_loss": 54.431796967983246, "val_acc": 72.0}
{"epoch": 44, "training_loss": 338.85472869873047, "training_acc": 62.666666666666664, "val_loss": 163.64696311950684, "val_acc": 72.0}
{"epoch": 45, "training_loss": 539.5639219284058, "training_acc": 64.0, "val_loss": 236.39494252204895, "val_acc": 72.0}
