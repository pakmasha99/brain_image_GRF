"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 300 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 3035.6282844543457, "training_acc": 70.33333333333333, "val_loss": 1062.283031463623, "val_acc": 28.0}
{"epoch": 1, "training_loss": 2556.526653289795, "training_acc": 63.0, "val_loss": 345.686203956604, "val_acc": 72.0}
{"epoch": 2, "training_loss": 1244.4584846496582, "training_acc": 49.0, "val_loss": 484.3449306488037, "val_acc": 72.0}
{"epoch": 3, "training_loss": 1655.6674194335938, "training_acc": 55.0, "val_loss": 67.52769923210144, "val_acc": 72.0}
{"epoch": 4, "training_loss": 661.1705827713013, "training_acc": 72.33333333333333, "val_loss": 468.24085569381714, "val_acc": 28.0}
{"epoch": 5, "training_loss": 1672.595027923584, "training_acc": 49.666666666666664, "val_loss": 452.87207794189453, "val_acc": 72.0}
{"epoch": 6, "training_loss": 1609.6066799163818, "training_acc": 55.666666666666664, "val_loss": 45.33409744501114, "val_acc": 62.666666666666664}
{"epoch": 7, "training_loss": 1165.7548580169678, "training_acc": 72.33333333333333, "val_loss": 177.71863842010498, "val_acc": 72.0}
{"epoch": 8, "training_loss": 943.4563846588135, "training_acc": 49.666666666666664, "val_loss": 370.55678963661194, "val_acc": 72.0}
{"epoch": 9, "training_loss": 834.8581275939941, "training_acc": 59.666666666666664, "val_loss": 100.42400419712067, "val_acc": 72.0}
{"epoch": 10, "training_loss": 597.223952293396, "training_acc": 69.0, "val_loss": 126.19436705112457, "val_acc": 28.0}
{"epoch": 11, "training_loss": 1017.2428941726685, "training_acc": 63.0, "val_loss": 106.59176552295685, "val_acc": 72.0}
{"epoch": 12, "training_loss": 1134.7826290130615, "training_acc": 51.0, "val_loss": 368.51960587501526, "val_acc": 72.0}
{"epoch": 13, "training_loss": 852.4921255111694, "training_acc": 68.33333333333333, "val_loss": 70.3775789141655, "val_acc": 28.0}
{"epoch": 14, "training_loss": 1038.5108184814453, "training_acc": 62.333333333333336, "val_loss": 95.72172617912292, "val_acc": 72.0}
{"epoch": 15, "training_loss": 1112.4724349975586, "training_acc": 50.333333333333336, "val_loss": 361.26158332824707, "val_acc": 72.0}
{"epoch": 16, "training_loss": 894.8774743080139, "training_acc": 56.333333333333336, "val_loss": 188.50972533226013, "val_acc": 72.0}
{"epoch": 17, "training_loss": 937.7776725292206, "training_acc": 65.0, "val_loss": 170.1269919872284, "val_acc": 28.0}
{"epoch": 18, "training_loss": 509.55040168762207, "training_acc": 66.33333333333333, "val_loss": 255.1098575592041, "val_acc": 28.0}
{"epoch": 19, "training_loss": 637.7447271347046, "training_acc": 52.333333333333336, "val_loss": 62.985111474990845, "val_acc": 72.0}
{"epoch": 20, "training_loss": 393.5690622329712, "training_acc": 63.0, "val_loss": 91.4683940410614, "val_acc": 72.0}
{"epoch": 21, "training_loss": 346.7897582054138, "training_acc": 64.33333333333333, "val_loss": 46.818227887153625, "val_acc": 41.333333333333336}
{"epoch": 22, "training_loss": 383.8925483226776, "training_acc": 61.333333333333336, "val_loss": 240.39197492599487, "val_acc": 28.0}
{"epoch": 23, "training_loss": 428.47821855545044, "training_acc": 56.333333333333336, "val_loss": 87.32755610346794, "val_acc": 72.0}
{"epoch": 24, "training_loss": 469.44084072113037, "training_acc": 59.0, "val_loss": 148.43650603294373, "val_acc": 72.0}
{"epoch": 25, "training_loss": 374.02122592926025, "training_acc": 66.33333333333333, "val_loss": 89.6680873632431, "val_acc": 72.0}
