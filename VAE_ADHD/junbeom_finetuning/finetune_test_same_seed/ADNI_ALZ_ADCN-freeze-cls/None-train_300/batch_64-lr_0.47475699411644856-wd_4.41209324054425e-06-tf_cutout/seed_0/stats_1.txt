"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 300 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 13662.037780761719, "training_acc": 57.0, "val_loss": 1682.203950881958, "val_acc": 28.0}
{"epoch": 1, "training_loss": 11933.701385498047, "training_acc": 57.666666666666664, "val_loss": 2846.310209274292, "val_acc": 72.0}
{"epoch": 2, "training_loss": 8816.728927612305, "training_acc": 59.666666666666664, "val_loss": 2186.7584705352783, "val_acc": 28.0}
{"epoch": 3, "training_loss": 10147.607177734375, "training_acc": 59.666666666666664, "val_loss": 2762.799515724182, "val_acc": 72.0}
{"epoch": 4, "training_loss": 7713.145172119141, "training_acc": 52.333333333333336, "val_loss": 119.94443953037262, "val_acc": 28.0}
{"epoch": 5, "training_loss": 7955.907287597656, "training_acc": 61.0, "val_loss": 2702.92560005188, "val_acc": 72.0}
{"epoch": 6, "training_loss": 5976.33048248291, "training_acc": 55.666666666666664, "val_loss": 319.9155297279358, "val_acc": 72.0}
{"epoch": 7, "training_loss": 1785.5161781311035, "training_acc": 66.0, "val_loss": 139.0510761141777, "val_acc": 69.33333333333333}
{"epoch": 8, "training_loss": 1141.9496240615845, "training_acc": 64.66666666666667, "val_loss": 153.65724980831146, "val_acc": 69.33333333333333}
{"epoch": 9, "training_loss": 1692.903434753418, "training_acc": 64.33333333333333, "val_loss": 200.39943099021912, "val_acc": 28.0}
{"epoch": 10, "training_loss": 1343.5240573883057, "training_acc": 50.0, "val_loss": 247.7342185974121, "val_acc": 72.0}
{"epoch": 11, "training_loss": 875.2720499038696, "training_acc": 60.666666666666664, "val_loss": 379.1560163497925, "val_acc": 72.0}
{"epoch": 12, "training_loss": 1306.4678039550781, "training_acc": 65.66666666666667, "val_loss": 154.88656103610992, "val_acc": 70.66666666666667}
{"epoch": 13, "training_loss": 936.0356860160828, "training_acc": 66.33333333333333, "val_loss": 1128.2596292495728, "val_acc": 28.0}
{"epoch": 14, "training_loss": 4322.905380249023, "training_acc": 54.666666666666664, "val_loss": 1486.1276206970215, "val_acc": 72.0}
{"epoch": 15, "training_loss": 2309.822401404381, "training_acc": 62.0, "val_loss": 82.21873760223389, "val_acc": 66.66666666666667}
{"epoch": 16, "training_loss": 208.3050193786621, "training_acc": 76.66666666666667, "val_loss": 127.46005356311798, "val_acc": 46.666666666666664}
{"epoch": 17, "training_loss": 1641.882942199707, "training_acc": 59.666666666666664, "val_loss": 90.0742384493351, "val_acc": 72.0}
{"epoch": 18, "training_loss": 1130.6758918762207, "training_acc": 64.66666666666667, "val_loss": 403.79983472824097, "val_acc": 72.0}
{"epoch": 19, "training_loss": 1174.8441445827484, "training_acc": 63.0, "val_loss": 833.8285913467407, "val_acc": 28.0}
{"epoch": 20, "training_loss": 2205.7054007053375, "training_acc": 60.666666666666664, "val_loss": 1543.754921913147, "val_acc": 28.0}
{"epoch": 21, "training_loss": 5239.253723144531, "training_acc": 52.333333333333336, "val_loss": 2004.4591693878174, "val_acc": 72.0}
{"epoch": 22, "training_loss": 4663.163425445557, "training_acc": 57.666666666666664, "val_loss": 601.0926179885864, "val_acc": 72.0}
{"epoch": 23, "training_loss": 3280.6983523368835, "training_acc": 72.66666666666667, "val_loss": 1838.3133220672607, "val_acc": 28.0}
{"epoch": 24, "training_loss": 4467.519916534424, "training_acc": 53.0, "val_loss": 878.5645341873169, "val_acc": 72.0}
{"epoch": 25, "training_loss": 3479.468198776245, "training_acc": 56.0, "val_loss": 1286.1736869812012, "val_acc": 72.0}
{"epoch": 26, "training_loss": 4517.216010093689, "training_acc": 63.666666666666664, "val_loss": 133.1395002603531, "val_acc": 56.0}
{"epoch": 27, "training_loss": 1556.1628456115723, "training_acc": 62.666666666666664, "val_loss": 142.76763397455215, "val_acc": 57.333333333333336}
{"epoch": 28, "training_loss": 3272.153232574463, "training_acc": 65.33333333333333, "val_loss": 471.3789095878601, "val_acc": 28.0}
{"epoch": 29, "training_loss": 2089.2176723480225, "training_acc": 59.666666666666664, "val_loss": 127.57510805130005, "val_acc": 68.0}
{"epoch": 30, "training_loss": 1256.6668424606323, "training_acc": 67.0, "val_loss": 175.0070229768753, "val_acc": 54.666666666666664}
{"epoch": 31, "training_loss": 1013.8136291503906, "training_acc": 57.666666666666664, "val_loss": 879.5575733184814, "val_acc": 72.0}
{"epoch": 32, "training_loss": 3541.4121742248535, "training_acc": 52.333333333333336, "val_loss": 920.9124755859375, "val_acc": 72.0}
{"epoch": 33, "training_loss": 6317.493217468262, "training_acc": 72.33333333333333, "val_loss": 785.1270380020142, "val_acc": 72.0}
{"epoch": 34, "training_loss": 2895.9582176208496, "training_acc": 54.333333333333336, "val_loss": 996.8804988861084, "val_acc": 72.0}
