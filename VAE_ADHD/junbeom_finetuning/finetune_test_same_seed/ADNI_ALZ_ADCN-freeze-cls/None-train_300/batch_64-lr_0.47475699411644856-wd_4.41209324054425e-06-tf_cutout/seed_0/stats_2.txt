"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 300 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 10216.994415283203, "training_acc": 64.33333333333333, "val_loss": 3390.0585289001465, "val_acc": 28.0}
{"epoch": 1, "training_loss": 6989.436939239502, "training_acc": 53.666666666666664, "val_loss": 939.9755477905273, "val_acc": 72.0}
{"epoch": 2, "training_loss": 2336.230722427368, "training_acc": 59.666666666666664, "val_loss": 1508.5324630737305, "val_acc": 72.0}
{"epoch": 3, "training_loss": 4922.710224509239, "training_acc": 73.0, "val_loss": 1538.6927890777588, "val_acc": 28.0}
{"epoch": 4, "training_loss": 4256.9053382873535, "training_acc": 53.666666666666664, "val_loss": 1384.1614685058594, "val_acc": 72.0}
{"epoch": 5, "training_loss": 4095.00825881958, "training_acc": 55.0, "val_loss": 348.09491300582886, "val_acc": 72.0}
{"epoch": 6, "training_loss": 1989.8055334091187, "training_acc": 64.33333333333333, "val_loss": 145.68843793869019, "val_acc": 72.0}
{"epoch": 7, "training_loss": 963.4626884460449, "training_acc": 64.33333333333333, "val_loss": 117.8241813480854, "val_acc": 72.0}
{"epoch": 8, "training_loss": 2728.3186950683594, "training_acc": 54.333333333333336, "val_loss": 1357.0227222442627, "val_acc": 72.0}
{"epoch": 9, "training_loss": 3795.307373046875, "training_acc": 66.33333333333333, "val_loss": 1298.279483795166, "val_acc": 28.0}
{"epoch": 10, "training_loss": 2229.3633308410645, "training_acc": 62.0, "val_loss": 772.1528100967407, "val_acc": 28.0}
{"epoch": 11, "training_loss": 2579.205852508545, "training_acc": 56.666666666666664, "val_loss": 685.0956878662109, "val_acc": 72.0}
{"epoch": 12, "training_loss": 2929.413694381714, "training_acc": 51.0, "val_loss": 805.3390283584595, "val_acc": 72.0}
{"epoch": 13, "training_loss": 2360.3146057128906, "training_acc": 69.66666666666667, "val_loss": 574.4392418861389, "val_acc": 28.0}
{"epoch": 14, "training_loss": 2438.1819744110107, "training_acc": 63.0, "val_loss": 113.26422071456909, "val_acc": 69.33333333333333}
{"epoch": 15, "training_loss": 3216.216453552246, "training_acc": 47.666666666666664, "val_loss": 1133.4346361160278, "val_acc": 72.0}
{"epoch": 16, "training_loss": 3345.870429992676, "training_acc": 66.0, "val_loss": 1540.2765789031982, "val_acc": 28.0}
{"epoch": 17, "training_loss": 2734.422384262085, "training_acc": 61.333333333333336, "val_loss": 87.40985983610153, "val_acc": 62.666666666666664}
{"epoch": 18, "training_loss": 1759.4415817260742, "training_acc": 59.666666666666664, "val_loss": 1044.0994548797607, "val_acc": 72.0}
{"epoch": 19, "training_loss": 2301.8111181259155, "training_acc": 57.666666666666664, "val_loss": 567.8009662628174, "val_acc": 72.0}
{"epoch": 20, "training_loss": 2572.2506160736084, "training_acc": 72.33333333333333, "val_loss": 767.7968273162842, "val_acc": 28.0}
{"epoch": 21, "training_loss": 3076.826030731201, "training_acc": 51.0, "val_loss": 930.7033710479736, "val_acc": 72.0}
{"epoch": 22, "training_loss": 2513.696207046509, "training_acc": 51.0, "val_loss": 1016.7687892913818, "val_acc": 72.0}
{"epoch": 23, "training_loss": 3286.6078567504883, "training_acc": 65.0, "val_loss": 296.0892757177353, "val_acc": 34.666666666666664}
{"epoch": 24, "training_loss": 2667.1668243408203, "training_acc": 65.0, "val_loss": 417.68603467941284, "val_acc": 72.0}
{"epoch": 25, "training_loss": 1757.7290306091309, "training_acc": 57.0, "val_loss": 747.5393714904785, "val_acc": 72.0}
{"epoch": 26, "training_loss": 1585.945291519165, "training_acc": 60.0, "val_loss": 547.8128161430359, "val_acc": 72.0}
{"epoch": 27, "training_loss": 1397.3099555969238, "training_acc": 60.666666666666664, "val_loss": 300.24970722198486, "val_acc": 73.33333333333333}
{"epoch": 28, "training_loss": 1000.8286361694336, "training_acc": 64.66666666666667, "val_loss": 208.91852229833603, "val_acc": 70.66666666666667}
{"epoch": 29, "training_loss": 693.8870038986206, "training_acc": 66.33333333333333, "val_loss": 197.73808336257935, "val_acc": 49.333333333333336}
{"epoch": 30, "training_loss": 952.8826656341553, "training_acc": 57.333333333333336, "val_loss": 201.24385356903076, "val_acc": 69.33333333333333}
{"epoch": 31, "training_loss": 1186.9100952148438, "training_acc": 66.33333333333333, "val_loss": 120.70488214492798, "val_acc": 64.0}
{"epoch": 32, "training_loss": 1089.2932300567627, "training_acc": 67.33333333333333, "val_loss": 127.3668942451477, "val_acc": 65.33333333333333}
{"epoch": 33, "training_loss": 1039.9644985198975, "training_acc": 66.33333333333333, "val_loss": 123.24604201316833, "val_acc": 64.0}
{"epoch": 34, "training_loss": 488.8369598388672, "training_acc": 67.66666666666667, "val_loss": 260.5820553302765, "val_acc": 73.33333333333333}
{"epoch": 35, "training_loss": 648.1055192947388, "training_acc": 66.33333333333333, "val_loss": 138.86762940883636, "val_acc": 66.66666666666667}
{"epoch": 36, "training_loss": 712.0766596794128, "training_acc": 67.0, "val_loss": 329.9207549095154, "val_acc": 36.0}
