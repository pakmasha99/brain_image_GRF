"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 300 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 8981.08902835846, "training_acc": 62.0, "val_loss": 5887.585174560547, "val_acc": 26.666666666666668}
{"epoch": 1, "training_loss": 14006.083450317383, "training_acc": 45.333333333333336, "val_loss": 2841.575273513794, "val_acc": 73.33333333333333}
{"epoch": 2, "training_loss": 11326.938743591309, "training_acc": 72.0, "val_loss": 989.5043182373047, "val_acc": 73.33333333333333}
{"epoch": 3, "training_loss": 3821.4364166259766, "training_acc": 44.0, "val_loss": 1677.0323162078857, "val_acc": 73.33333333333333}
{"epoch": 4, "training_loss": 8390.684471130371, "training_acc": 72.0, "val_loss": 1080.1961669921875, "val_acc": 73.33333333333333}
{"epoch": 5, "training_loss": 6596.498908996582, "training_acc": 48.0, "val_loss": 239.19160509109497, "val_acc": 73.33333333333333}
{"epoch": 6, "training_loss": 2856.6064453125, "training_acc": 72.0, "val_loss": 220.49386775493622, "val_acc": 73.33333333333333}
{"epoch": 7, "training_loss": 2744.2358169555664, "training_acc": 51.333333333333336, "val_loss": 622.0099716186523, "val_acc": 73.33333333333333}
{"epoch": 8, "training_loss": 2837.74178314209, "training_acc": 55.333333333333336, "val_loss": 215.87250590324402, "val_acc": 73.33333333333333}
{"epoch": 9, "training_loss": 2268.1272225379944, "training_acc": 72.0, "val_loss": 1205.1263046264648, "val_acc": 26.666666666666668}
{"epoch": 10, "training_loss": 2802.3917350769043, "training_acc": 57.333333333333336, "val_loss": 540.0538511276245, "val_acc": 73.33333333333333}
{"epoch": 11, "training_loss": 2034.8157768249512, "training_acc": 54.0, "val_loss": 938.948543548584, "val_acc": 73.33333333333333}
{"epoch": 12, "training_loss": 2961.4003562927246, "training_acc": 66.66666666666667, "val_loss": 546.3103008270264, "val_acc": 26.666666666666668}
{"epoch": 13, "training_loss": 2917.1251792907715, "training_acc": 61.333333333333336, "val_loss": 284.99770855903625, "val_acc": 73.33333333333333}
{"epoch": 14, "training_loss": 2316.435390472412, "training_acc": 54.666666666666664, "val_loss": 782.5587158203125, "val_acc": 73.33333333333333}
{"epoch": 15, "training_loss": 1524.9377918243408, "training_acc": 64.66666666666667, "val_loss": 349.8472776412964, "val_acc": 73.33333333333333}
{"epoch": 16, "training_loss": 1875.3026275634766, "training_acc": 63.333333333333336, "val_loss": 82.85391193628311, "val_acc": 53.333333333333336}
{"epoch": 17, "training_loss": 2789.958972930908, "training_acc": 67.66666666666667, "val_loss": 363.21148550510406, "val_acc": 73.33333333333333}
{"epoch": 18, "training_loss": 2083.6701049804688, "training_acc": 53.333333333333336, "val_loss": 824.992733001709, "val_acc": 73.33333333333333}
{"epoch": 19, "training_loss": 1698.7886791229248, "training_acc": 61.666666666666664, "val_loss": 393.6298553943634, "val_acc": 73.33333333333333}
{"epoch": 20, "training_loss": 2207.551425933838, "training_acc": 62.666666666666664, "val_loss": 357.68385553359985, "val_acc": 26.666666666666668}
{"epoch": 21, "training_loss": 2905.112014770508, "training_acc": 65.33333333333333, "val_loss": 674.1835021972656, "val_acc": 73.33333333333333}
{"epoch": 22, "training_loss": 2951.839067220688, "training_acc": 56.0, "val_loss": 440.11151790618896, "val_acc": 73.33333333333333}
{"epoch": 23, "training_loss": 1754.8813095092773, "training_acc": 64.66666666666667, "val_loss": 43.6783601641655, "val_acc": 80.0}
{"epoch": 24, "training_loss": 812.7977352142334, "training_acc": 66.66666666666667, "val_loss": 136.85344791412354, "val_acc": 74.66666666666667}
{"epoch": 25, "training_loss": 1557.249698638916, "training_acc": 67.33333333333333, "val_loss": 869.5659694671631, "val_acc": 26.666666666666668}
{"epoch": 26, "training_loss": 3261.273204803467, "training_acc": 59.333333333333336, "val_loss": 204.77708053588867, "val_acc": 73.33333333333333}
{"epoch": 27, "training_loss": 2414.8443756103516, "training_acc": 52.0, "val_loss": 923.2386503219604, "val_acc": 73.33333333333333}
{"epoch": 28, "training_loss": 2278.155640602112, "training_acc": 56.666666666666664, "val_loss": 405.5219671726227, "val_acc": 73.33333333333333}
{"epoch": 29, "training_loss": 2122.145727157593, "training_acc": 68.0, "val_loss": 190.52955508232117, "val_acc": 38.666666666666664}
{"epoch": 30, "training_loss": 1347.0141806602478, "training_acc": 63.0, "val_loss": 620.0242357254028, "val_acc": 26.666666666666668}
{"epoch": 31, "training_loss": 1152.4282059669495, "training_acc": 61.333333333333336, "val_loss": 603.5055456161499, "val_acc": 26.666666666666668}
{"epoch": 32, "training_loss": 1392.8289127349854, "training_acc": 54.0, "val_loss": 74.03533613681793, "val_acc": 77.33333333333333}
{"epoch": 33, "training_loss": 452.90013456344604, "training_acc": 68.33333333333333, "val_loss": 61.831787168979645, "val_acc": 73.33333333333333}
{"epoch": 34, "training_loss": 579.5026435852051, "training_acc": 61.333333333333336, "val_loss": 227.13497042655945, "val_acc": 73.33333333333333}
{"epoch": 35, "training_loss": 1383.7362518310547, "training_acc": 64.33333333333333, "val_loss": 113.09491240978241, "val_acc": 77.33333333333333}
{"epoch": 36, "training_loss": 937.5673217773438, "training_acc": 63.333333333333336, "val_loss": 168.2383096218109, "val_acc": 74.66666666666667}
{"epoch": 37, "training_loss": 854.5278844833374, "training_acc": 62.0, "val_loss": 51.22093069553375, "val_acc": 78.66666666666667}
{"epoch": 38, "training_loss": 1618.6180896759033, "training_acc": 57.333333333333336, "val_loss": 58.66213059425354, "val_acc": 74.66666666666667}
{"epoch": 39, "training_loss": 2441.6080360412598, "training_acc": 51.333333333333336, "val_loss": 1363.591552734375, "val_acc": 73.33333333333333}
{"epoch": 40, "training_loss": 3802.948034286499, "training_acc": 69.0, "val_loss": 690.9505763053894, "val_acc": 26.666666666666668}
{"epoch": 41, "training_loss": 1281.5230221748352, "training_acc": 66.0, "val_loss": 404.2145309448242, "val_acc": 28.0}
{"epoch": 42, "training_loss": 1089.870403289795, "training_acc": 56.666666666666664, "val_loss": 64.6185587644577, "val_acc": 78.66666666666667}
