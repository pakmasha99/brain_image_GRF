"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 300 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 18573.80405807495, "training_acc": 57.0, "val_loss": 391.85514307022095, "val_acc": 72.0}
{"epoch": 1, "training_loss": 6382.605930328369, "training_acc": 72.33333333333333, "val_loss": 342.61367416381836, "val_acc": 28.0}
{"epoch": 2, "training_loss": 1519.4206008911133, "training_acc": 54.333333333333336, "val_loss": 593.1848540306091, "val_acc": 72.0}
{"epoch": 3, "training_loss": 2674.1164894104004, "training_acc": 60.0, "val_loss": 1488.2991275787354, "val_acc": 72.0}
{"epoch": 4, "training_loss": 5780.532989501953, "training_acc": 57.666666666666664, "val_loss": 123.61789393424988, "val_acc": 72.0}
{"epoch": 5, "training_loss": 3291.863105773926, "training_acc": 72.0, "val_loss": 2017.683500289917, "val_acc": 28.0}
{"epoch": 6, "training_loss": 5580.405479431152, "training_acc": 49.666666666666664, "val_loss": 1089.061954498291, "val_acc": 72.0}
{"epoch": 7, "training_loss": 2397.385810852051, "training_acc": 58.333333333333336, "val_loss": 1138.5684518814087, "val_acc": 72.0}
{"epoch": 8, "training_loss": 3570.7075519561768, "training_acc": 54.333333333333336, "val_loss": 1056.0262775421143, "val_acc": 72.0}
{"epoch": 9, "training_loss": 7039.969429016113, "training_acc": 72.33333333333333, "val_loss": 620.6888122558594, "val_acc": 72.0}
{"epoch": 10, "training_loss": 3974.7467212677, "training_acc": 53.0, "val_loss": 699.4254479408264, "val_acc": 72.0}
{"epoch": 11, "training_loss": 1875.3605461120605, "training_acc": 60.666666666666664, "val_loss": 101.06736481189728, "val_acc": 42.666666666666664}
{"epoch": 12, "training_loss": 1234.9383449554443, "training_acc": 55.0, "val_loss": 477.98510360717773, "val_acc": 72.0}
{"epoch": 13, "training_loss": 3125.286117553711, "training_acc": 49.333333333333336, "val_loss": 2118.102460861206, "val_acc": 72.0}
{"epoch": 14, "training_loss": 8460.312759399414, "training_acc": 72.33333333333333, "val_loss": 223.61056685447693, "val_acc": 72.0}
{"epoch": 15, "training_loss": 5293.791198730469, "training_acc": 48.333333333333336, "val_loss": 2608.456901550293, "val_acc": 72.0}
{"epoch": 16, "training_loss": 11634.786430358887, "training_acc": 72.33333333333333, "val_loss": 1814.8969707489014, "val_acc": 72.0}
{"epoch": 17, "training_loss": 7508.637878417969, "training_acc": 45.666666666666664, "val_loss": 1114.8917236328125, "val_acc": 72.0}
{"epoch": 18, "training_loss": 10080.352798461914, "training_acc": 72.33333333333333, "val_loss": 2572.0839862823486, "val_acc": 72.0}
{"epoch": 19, "training_loss": 7032.737930297852, "training_acc": 58.333333333333336, "val_loss": 1503.6547222137451, "val_acc": 28.0}
{"epoch": 20, "training_loss": 6575.267768859863, "training_acc": 62.333333333333336, "val_loss": 2066.233730316162, "val_acc": 72.0}
{"epoch": 21, "training_loss": 6719.14143371582, "training_acc": 55.666666666666664, "val_loss": 398.1824531555176, "val_acc": 29.333333333333332}
{"epoch": 22, "training_loss": 9918.849487304688, "training_acc": 61.0, "val_loss": 3738.076427459717, "val_acc": 72.0}
{"epoch": 23, "training_loss": 9576.233871459961, "training_acc": 63.666666666666664, "val_loss": 2078.595157623291, "val_acc": 28.0}
{"epoch": 24, "training_loss": 6395.75456237793, "training_acc": 57.333333333333336, "val_loss": 2486.374034881592, "val_acc": 72.0}
{"epoch": 25, "training_loss": 6614.597717285156, "training_acc": 65.0, "val_loss": 3128.869037628174, "val_acc": 28.0}
{"epoch": 26, "training_loss": 7102.606201171875, "training_acc": 57.666666666666664, "val_loss": 3306.237289428711, "val_acc": 72.0}
{"epoch": 27, "training_loss": 10002.080387115479, "training_acc": 72.33333333333333, "val_loss": 1076.8306646347046, "val_acc": 28.0}
{"epoch": 28, "training_loss": 3585.300525665283, "training_acc": 50.333333333333336, "val_loss": 180.57301568984985, "val_acc": 72.0}
{"epoch": 29, "training_loss": 3005.3798065185547, "training_acc": 55.0, "val_loss": 1973.9427757263184, "val_acc": 72.0}
{"epoch": 30, "training_loss": 5996.728942871094, "training_acc": 63.0, "val_loss": 2143.3001861572266, "val_acc": 28.0}
