"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 300 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 193.70165514945984, "training_acc": 72.33333333333333, "val_loss": 48.007525742053986, "val_acc": 28.0}
{"epoch": 1, "training_loss": 190.51775908470154, "training_acc": 72.33333333333333, "val_loss": 47.287919878959656, "val_acc": 28.0}
{"epoch": 2, "training_loss": 187.72900533676147, "training_acc": 72.33333333333333, "val_loss": 46.658541560173035, "val_acc": 28.0}
{"epoch": 3, "training_loss": 185.32425451278687, "training_acc": 72.33333333333333, "val_loss": 46.12694263458252, "val_acc": 28.0}
{"epoch": 4, "training_loss": 183.2356195449829, "training_acc": 72.33333333333333, "val_loss": 45.696425795555115, "val_acc": 72.0}
{"epoch": 5, "training_loss": 181.625741481781, "training_acc": 72.33333333333333, "val_loss": 45.35569554567337, "val_acc": 72.0}
{"epoch": 6, "training_loss": 180.32809114456177, "training_acc": 72.33333333333333, "val_loss": 45.0891056060791, "val_acc": 72.0}
{"epoch": 7, "training_loss": 179.31923055648804, "training_acc": 72.33333333333333, "val_loss": 44.88630369305611, "val_acc": 72.0}
{"epoch": 8, "training_loss": 178.6630096435547, "training_acc": 72.33333333333333, "val_loss": 44.737681448459625, "val_acc": 72.0}
{"epoch": 9, "training_loss": 178.00515937805176, "training_acc": 72.33333333333333, "val_loss": 44.6401190161705, "val_acc": 72.0}
{"epoch": 10, "training_loss": 177.63336658477783, "training_acc": 72.33333333333333, "val_loss": 44.57242351770401, "val_acc": 72.0}
{"epoch": 11, "training_loss": 177.3436770439148, "training_acc": 72.33333333333333, "val_loss": 44.52687394618988, "val_acc": 72.0}
{"epoch": 12, "training_loss": 177.13951754570007, "training_acc": 72.33333333333333, "val_loss": 44.49743837118149, "val_acc": 72.0}
{"epoch": 13, "training_loss": 177.07493710517883, "training_acc": 72.33333333333333, "val_loss": 44.474203407764435, "val_acc": 72.0}
{"epoch": 14, "training_loss": 176.94130969047546, "training_acc": 72.33333333333333, "val_loss": 44.46238154172897, "val_acc": 72.0}
{"epoch": 15, "training_loss": 176.94563245773315, "training_acc": 72.33333333333333, "val_loss": 44.4546155333519, "val_acc": 72.0}
{"epoch": 16, "training_loss": 176.86993551254272, "training_acc": 72.33333333333333, "val_loss": 44.45128107070923, "val_acc": 72.0}
{"epoch": 17, "training_loss": 176.86247205734253, "training_acc": 72.33333333333333, "val_loss": 44.450124859809875, "val_acc": 72.0}
{"epoch": 18, "training_loss": 176.84108304977417, "training_acc": 72.33333333333333, "val_loss": 44.449778854846954, "val_acc": 72.0}
{"epoch": 19, "training_loss": 176.87087202072144, "training_acc": 72.33333333333333, "val_loss": 44.449741542339325, "val_acc": 72.0}
{"epoch": 20, "training_loss": 176.8867588043213, "training_acc": 72.33333333333333, "val_loss": 44.449834048748016, "val_acc": 72.0}
{"epoch": 21, "training_loss": 176.8038866519928, "training_acc": 72.33333333333333, "val_loss": 44.45002508163452, "val_acc": 72.0}
{"epoch": 22, "training_loss": 176.85069251060486, "training_acc": 72.33333333333333, "val_loss": 44.45053946971893, "val_acc": 72.0}
{"epoch": 23, "training_loss": 176.81879496574402, "training_acc": 72.33333333333333, "val_loss": 44.45086732506752, "val_acc": 72.0}
{"epoch": 24, "training_loss": 176.87179470062256, "training_acc": 72.33333333333333, "val_loss": 44.45040321350098, "val_acc": 72.0}
{"epoch": 25, "training_loss": 176.8594753742218, "training_acc": 72.33333333333333, "val_loss": 44.450551986694336, "val_acc": 72.0}
{"epoch": 26, "training_loss": 176.84143114089966, "training_acc": 72.33333333333333, "val_loss": 44.45177090167999, "val_acc": 72.0}
{"epoch": 27, "training_loss": 176.8390007019043, "training_acc": 72.33333333333333, "val_loss": 44.452043771743774, "val_acc": 72.0}
{"epoch": 28, "training_loss": 176.87216424942017, "training_acc": 72.33333333333333, "val_loss": 44.4521210193634, "val_acc": 72.0}
{"epoch": 29, "training_loss": 176.8253881931305, "training_acc": 72.33333333333333, "val_loss": 44.452440559864044, "val_acc": 72.0}
{"epoch": 30, "training_loss": 176.83150732517242, "training_acc": 72.33333333333333, "val_loss": 44.452718913555145, "val_acc": 72.0}
{"epoch": 31, "training_loss": 176.8684206008911, "training_acc": 72.33333333333333, "val_loss": 44.45437532663345, "val_acc": 72.0}
{"epoch": 32, "training_loss": 176.86149382591248, "training_acc": 72.33333333333333, "val_loss": 44.45438528060913, "val_acc": 72.0}
{"epoch": 33, "training_loss": 176.83996772766113, "training_acc": 72.33333333333333, "val_loss": 44.45315933227539, "val_acc": 72.0}
{"epoch": 34, "training_loss": 176.84045457839966, "training_acc": 72.33333333333333, "val_loss": 44.4512677192688, "val_acc": 72.0}
{"epoch": 35, "training_loss": 176.87919187545776, "training_acc": 72.33333333333333, "val_loss": 44.451844692230225, "val_acc": 72.0}
{"epoch": 36, "training_loss": 176.88310623168945, "training_acc": 72.33333333333333, "val_loss": 44.450921297073364, "val_acc": 72.0}
{"epoch": 37, "training_loss": 176.83779120445251, "training_acc": 72.33333333333333, "val_loss": 44.45150953531265, "val_acc": 72.0}
{"epoch": 38, "training_loss": 176.86856126785278, "training_acc": 72.33333333333333, "val_loss": 44.45258992910385, "val_acc": 72.0}
