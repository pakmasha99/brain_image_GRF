"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 300 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 2323.289523124695, "training_acc": 57.666666666666664, "val_loss": 67.47278988361359, "val_acc": 28.0}
{"epoch": 1, "training_loss": 827.6811275482178, "training_acc": 55.666666666666664, "val_loss": 45.579754054546356, "val_acc": 72.0}
{"epoch": 2, "training_loss": 361.28801798820496, "training_acc": 62.333333333333336, "val_loss": 76.61093898117542, "val_acc": 72.0}
{"epoch": 3, "training_loss": 364.66677701473236, "training_acc": 61.0, "val_loss": 66.40012413263321, "val_acc": 28.0}
{"epoch": 4, "training_loss": 277.22020053863525, "training_acc": 53.0, "val_loss": 67.9374088048935, "val_acc": 72.0}
{"epoch": 5, "training_loss": 243.98226261138916, "training_acc": 57.666666666666664, "val_loss": 93.74277263879776, "val_acc": 72.0}
{"epoch": 6, "training_loss": 412.6632614135742, "training_acc": 61.0, "val_loss": 63.48001527786255, "val_acc": 72.0}
{"epoch": 7, "training_loss": 398.14566016197205, "training_acc": 63.0, "val_loss": 81.695317029953, "val_acc": 28.0}
{"epoch": 8, "training_loss": 322.00493574142456, "training_acc": 56.333333333333336, "val_loss": 43.721048295497894, "val_acc": 72.0}
{"epoch": 9, "training_loss": 400.27829122543335, "training_acc": 57.0, "val_loss": 136.8477656841278, "val_acc": 72.0}
{"epoch": 10, "training_loss": 405.44772720336914, "training_acc": 64.33333333333333, "val_loss": 121.96505361795425, "val_acc": 72.0}
{"epoch": 11, "training_loss": 327.42369174957275, "training_acc": 53.666666666666664, "val_loss": 56.30466312170029, "val_acc": 72.0}
{"epoch": 12, "training_loss": 283.00257539749146, "training_acc": 55.0, "val_loss": 47.24528568983078, "val_acc": 28.0}
{"epoch": 13, "training_loss": 294.17756628990173, "training_acc": 61.333333333333336, "val_loss": 89.75752493739128, "val_acc": 72.0}
{"epoch": 14, "training_loss": 325.338990688324, "training_acc": 61.0, "val_loss": 46.53090023994446, "val_acc": 30.666666666666668}
{"epoch": 15, "training_loss": 330.955584526062, "training_acc": 63.333333333333336, "val_loss": 108.59008145332336, "val_acc": 28.0}
{"epoch": 16, "training_loss": 419.7090983390808, "training_acc": 57.666666666666664, "val_loss": 54.088133454322815, "val_acc": 72.0}
{"epoch": 17, "training_loss": 490.4499931335449, "training_acc": 63.333333333333336, "val_loss": 121.88958930969238, "val_acc": 72.0}
{"epoch": 18, "training_loss": 427.4538917541504, "training_acc": 55.0, "val_loss": 152.74952340126038, "val_acc": 72.0}
{"epoch": 19, "training_loss": 684.9111404418945, "training_acc": 52.333333333333336, "val_loss": 383.28302001953125, "val_acc": 72.0}
{"epoch": 20, "training_loss": 1600.1401529312134, "training_acc": 72.33333333333333, "val_loss": 126.63938534259796, "val_acc": 28.0}
{"epoch": 21, "training_loss": 532.6634120941162, "training_acc": 57.0, "val_loss": 78.55314218997955, "val_acc": 72.0}
{"epoch": 22, "training_loss": 455.4907512664795, "training_acc": 60.333333333333336, "val_loss": 51.50460433959961, "val_acc": 72.0}
{"epoch": 23, "training_loss": 429.1410222053528, "training_acc": 62.333333333333336, "val_loss": 43.047731429338455, "val_acc": 73.33333333333333}
{"epoch": 24, "training_loss": 378.60362005233765, "training_acc": 61.666666666666664, "val_loss": 103.10787653923035, "val_acc": 28.0}
{"epoch": 25, "training_loss": 271.733717918396, "training_acc": 56.333333333333336, "val_loss": 51.25569832324982, "val_acc": 72.0}
{"epoch": 26, "training_loss": 271.495774269104, "training_acc": 64.33333333333333, "val_loss": 92.64376544952393, "val_acc": 72.0}
{"epoch": 27, "training_loss": 283.0368344783783, "training_acc": 63.0, "val_loss": 43.07346826791763, "val_acc": 72.0}
{"epoch": 28, "training_loss": 228.2368130683899, "training_acc": 57.0, "val_loss": 79.45824408531189, "val_acc": 72.0}
{"epoch": 29, "training_loss": 370.09608912467957, "training_acc": 62.333333333333336, "val_loss": 99.49089694023132, "val_acc": 72.0}
{"epoch": 30, "training_loss": 312.9694290161133, "training_acc": 64.33333333333333, "val_loss": 48.63375759124756, "val_acc": 72.0}
{"epoch": 31, "training_loss": 261.46658515930176, "training_acc": 64.33333333333333, "val_loss": 147.0438470840454, "val_acc": 28.0}
{"epoch": 32, "training_loss": 332.3972020149231, "training_acc": 59.0, "val_loss": 46.204848408699036, "val_acc": 72.0}
{"epoch": 33, "training_loss": 342.31549072265625, "training_acc": 60.333333333333336, "val_loss": 126.63591456413269, "val_acc": 72.0}
{"epoch": 34, "training_loss": 449.2200622558594, "training_acc": 63.0, "val_loss": 93.66040110588074, "val_acc": 72.0}
{"epoch": 35, "training_loss": 271.19550013542175, "training_acc": 61.0, "val_loss": 61.70801484584808, "val_acc": 28.0}
{"epoch": 36, "training_loss": 325.0240707397461, "training_acc": 57.666666666666664, "val_loss": 47.654820024967194, "val_acc": 30.666666666666668}
{"epoch": 37, "training_loss": 411.76929569244385, "training_acc": 68.0, "val_loss": 97.70953321456909, "val_acc": 28.0}
{"epoch": 38, "training_loss": 499.4871594905853, "training_acc": 57.666666666666664, "val_loss": 89.35762655735016, "val_acc": 28.0}
{"epoch": 39, "training_loss": 496.0368461608887, "training_acc": 52.333333333333336, "val_loss": 47.301853239536285, "val_acc": 72.0}
{"epoch": 40, "training_loss": 211.90724754333496, "training_acc": 73.0, "val_loss": 58.899425983428955, "val_acc": 72.0}
{"epoch": 41, "training_loss": 293.0656168460846, "training_acc": 53.333333333333336, "val_loss": 60.21432721614838, "val_acc": 72.0}
{"epoch": 42, "training_loss": 215.2985119819641, "training_acc": 62.333333333333336, "val_loss": 63.466303169727325, "val_acc": 28.0}
