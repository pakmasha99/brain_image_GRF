"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 300 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 2436.1034622192383, "training_acc": 54.666666666666664, "val_loss": 195.29861187934875, "val_acc": 26.666666666666668}
{"epoch": 1, "training_loss": 1707.0563316345215, "training_acc": 64.0, "val_loss": 396.24049067497253, "val_acc": 73.33333333333333}
{"epoch": 2, "training_loss": 1155.559829711914, "training_acc": 54.0, "val_loss": 175.6949963569641, "val_acc": 73.33333333333333}
{"epoch": 3, "training_loss": 724.0165505409241, "training_acc": 51.333333333333336, "val_loss": 173.27637267112732, "val_acc": 73.33333333333333}
{"epoch": 4, "training_loss": 1097.3353900909424, "training_acc": 72.0, "val_loss": 48.462823033332825, "val_acc": 26.666666666666668}
{"epoch": 5, "training_loss": 761.5760402679443, "training_acc": 54.0, "val_loss": 322.75467109680176, "val_acc": 73.33333333333333}
{"epoch": 6, "training_loss": 979.0391736030579, "training_acc": 52.666666666666664, "val_loss": 122.47599601745605, "val_acc": 73.33333333333333}
{"epoch": 7, "training_loss": 670.7621593475342, "training_acc": 72.0, "val_loss": 268.6733901500702, "val_acc": 26.666666666666668}
{"epoch": 8, "training_loss": 914.9185466766357, "training_acc": 50.666666666666664, "val_loss": 238.26235580444336, "val_acc": 73.33333333333333}
{"epoch": 9, "training_loss": 738.7219161987305, "training_acc": 53.333333333333336, "val_loss": 163.41952419281006, "val_acc": 73.33333333333333}
{"epoch": 10, "training_loss": 1134.1806535720825, "training_acc": 72.0, "val_loss": 109.69653046131134, "val_acc": 73.33333333333333}
{"epoch": 11, "training_loss": 666.701135635376, "training_acc": 50.0, "val_loss": 182.64035660028458, "val_acc": 73.33333333333333}
{"epoch": 12, "training_loss": 583.5857257843018, "training_acc": 50.0, "val_loss": 189.5330457687378, "val_acc": 73.33333333333333}
{"epoch": 13, "training_loss": 581.4779357910156, "training_acc": 56.666666666666664, "val_loss": 64.84707498550415, "val_acc": 73.33333333333333}
{"epoch": 14, "training_loss": 335.15014719963074, "training_acc": 57.333333333333336, "val_loss": 48.72383050620556, "val_acc": 73.33333333333333}
{"epoch": 15, "training_loss": 179.90421390533447, "training_acc": 73.66666666666667, "val_loss": 41.84663289785385, "val_acc": 73.33333333333333}
{"epoch": 16, "training_loss": 209.5506911277771, "training_acc": 61.333333333333336, "val_loss": 84.94368088245392, "val_acc": 73.33333333333333}
{"epoch": 17, "training_loss": 332.46422481536865, "training_acc": 60.666666666666664, "val_loss": 42.631944358348846, "val_acc": 73.33333333333333}
{"epoch": 18, "training_loss": 334.666535615921, "training_acc": 59.333333333333336, "val_loss": 95.24666702747345, "val_acc": 26.666666666666668}
{"epoch": 19, "training_loss": 382.04127502441406, "training_acc": 54.0, "val_loss": 51.47588086128235, "val_acc": 26.666666666666668}
{"epoch": 20, "training_loss": 414.95868968963623, "training_acc": 58.0, "val_loss": 42.310451328754425, "val_acc": 73.33333333333333}
{"epoch": 21, "training_loss": 199.84199595451355, "training_acc": 72.0, "val_loss": 42.34225821495056, "val_acc": 76.0}
{"epoch": 22, "training_loss": 179.2945854663849, "training_acc": 72.0, "val_loss": 41.4493647813797, "val_acc": 73.33333333333333}
{"epoch": 23, "training_loss": 223.45515990257263, "training_acc": 55.0, "val_loss": 41.519020318984985, "val_acc": 73.33333333333333}
{"epoch": 24, "training_loss": 208.84424495697021, "training_acc": 70.66666666666667, "val_loss": 68.08367198705673, "val_acc": 26.666666666666668}
{"epoch": 25, "training_loss": 447.9367799758911, "training_acc": 50.666666666666664, "val_loss": 117.92729377746582, "val_acc": 26.666666666666668}
{"epoch": 26, "training_loss": 1114.6652612686157, "training_acc": 59.333333333333336, "val_loss": 148.6783788204193, "val_acc": 73.33333333333333}
{"epoch": 27, "training_loss": 562.9563322067261, "training_acc": 52.0, "val_loss": 131.33263206481934, "val_acc": 73.33333333333333}
{"epoch": 28, "training_loss": 475.3701810836792, "training_acc": 54.0, "val_loss": 212.58724796772003, "val_acc": 73.33333333333333}
{"epoch": 29, "training_loss": 624.7238388061523, "training_acc": 57.333333333333336, "val_loss": 84.85429799556732, "val_acc": 73.33333333333333}
{"epoch": 30, "training_loss": 458.7848320007324, "training_acc": 58.0, "val_loss": 57.36260139942169, "val_acc": 73.33333333333333}
{"epoch": 31, "training_loss": 250.34420251846313, "training_acc": 60.666666666666664, "val_loss": 72.3960171341896, "val_acc": 26.666666666666668}
{"epoch": 32, "training_loss": 282.25122833251953, "training_acc": 54.0, "val_loss": 77.35949867963791, "val_acc": 73.33333333333333}
{"epoch": 33, "training_loss": 354.1763427257538, "training_acc": 63.333333333333336, "val_loss": 80.04026222229004, "val_acc": 73.33333333333333}
{"epoch": 34, "training_loss": 261.29201900959015, "training_acc": 62.0, "val_loss": 47.01378893852234, "val_acc": 73.33333333333333}
{"epoch": 35, "training_loss": 224.23140954971313, "training_acc": 64.0, "val_loss": 44.039323925971985, "val_acc": 49.333333333333336}
{"epoch": 36, "training_loss": 179.25681805610657, "training_acc": 72.33333333333333, "val_loss": 49.34504050016403, "val_acc": 73.33333333333333}
{"epoch": 37, "training_loss": 256.9525158405304, "training_acc": 60.666666666666664, "val_loss": 64.95595020055771, "val_acc": 26.666666666666668}
{"epoch": 38, "training_loss": 298.47236251831055, "training_acc": 58.666666666666664, "val_loss": 40.12892270088196, "val_acc": 73.33333333333333}
{"epoch": 39, "training_loss": 176.7242500782013, "training_acc": 72.33333333333333, "val_loss": 41.18324115872383, "val_acc": 73.33333333333333}
{"epoch": 40, "training_loss": 172.0195119380951, "training_acc": 72.33333333333333, "val_loss": 41.70441496372223, "val_acc": 73.33333333333333}
{"epoch": 41, "training_loss": 168.97470378875732, "training_acc": 72.33333333333333, "val_loss": 50.80523896217346, "val_acc": 73.33333333333333}
{"epoch": 42, "training_loss": 197.43254113197327, "training_acc": 69.66666666666667, "val_loss": 41.83697319030762, "val_acc": 68.0}
{"epoch": 43, "training_loss": 273.0075430870056, "training_acc": 62.0, "val_loss": 49.345363080501556, "val_acc": 73.33333333333333}
{"epoch": 44, "training_loss": 197.56170773506165, "training_acc": 66.0, "val_loss": 97.85292255878448, "val_acc": 26.666666666666668}
{"epoch": 45, "training_loss": 272.01037764549255, "training_acc": 60.666666666666664, "val_loss": 45.274063408374786, "val_acc": 73.33333333333333}
{"epoch": 46, "training_loss": 175.75429892539978, "training_acc": 71.66666666666667, "val_loss": 42.17268943786621, "val_acc": 73.33333333333333}
{"epoch": 47, "training_loss": 174.00821018218994, "training_acc": 72.33333333333333, "val_loss": 55.73918855190277, "val_acc": 26.666666666666668}
{"epoch": 48, "training_loss": 234.45455169677734, "training_acc": 57.666666666666664, "val_loss": 60.907626152038574, "val_acc": 73.33333333333333}
{"epoch": 49, "training_loss": 273.08510065078735, "training_acc": 60.666666666666664, "val_loss": 42.58519196510315, "val_acc": 54.666666666666664}
{"epoch": 50, "training_loss": 265.9236207008362, "training_acc": 60.333333333333336, "val_loss": 43.70836812257767, "val_acc": 49.333333333333336}
{"epoch": 51, "training_loss": 216.41581392288208, "training_acc": 67.0, "val_loss": 95.08782386779785, "val_acc": 73.33333333333333}
{"epoch": 52, "training_loss": 345.8307554721832, "training_acc": 60.333333333333336, "val_loss": 98.76014739274979, "val_acc": 73.33333333333333}
{"epoch": 53, "training_loss": 475.6007719039917, "training_acc": 61.333333333333336, "val_loss": 84.01310929656029, "val_acc": 73.33333333333333}
{"epoch": 54, "training_loss": 290.80888080596924, "training_acc": 61.666666666666664, "val_loss": 61.74383008480072, "val_acc": 73.33333333333333}
{"epoch": 55, "training_loss": 249.048602104187, "training_acc": 64.0, "val_loss": 69.43210470676422, "val_acc": 26.666666666666668}
{"epoch": 56, "training_loss": 295.4639220237732, "training_acc": 57.333333333333336, "val_loss": 70.84834063053131, "val_acc": 73.33333333333333}
{"epoch": 57, "training_loss": 384.0202941894531, "training_acc": 60.666666666666664, "val_loss": 50.43335819244385, "val_acc": 73.33333333333333}
