"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 300 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 219.88812351226807, "training_acc": 27.666666666666668, "val_loss": 53.72295415401459, "val_acc": 28.0}
{"epoch": 1, "training_loss": 211.9112331867218, "training_acc": 27.666666666666668, "val_loss": 51.897603154182434, "val_acc": 28.0}
{"epoch": 2, "training_loss": 205.3875012397766, "training_acc": 70.33333333333333, "val_loss": 50.297257363796234, "val_acc": 28.0}
{"epoch": 3, "training_loss": 199.03859615325928, "training_acc": 72.33333333333333, "val_loss": 48.98271328210831, "val_acc": 28.0}
{"epoch": 4, "training_loss": 193.72345399856567, "training_acc": 72.33333333333333, "val_loss": 47.90977615118027, "val_acc": 28.0}
{"epoch": 5, "training_loss": 189.82591485977173, "training_acc": 72.33333333333333, "val_loss": 47.014341831207275, "val_acc": 28.0}
{"epoch": 6, "training_loss": 186.73165345191956, "training_acc": 72.33333333333333, "val_loss": 46.292436838150024, "val_acc": 28.0}
{"epoch": 7, "training_loss": 183.84110069274902, "training_acc": 72.33333333333333, "val_loss": 45.77315545082092, "val_acc": 72.0}
{"epoch": 8, "training_loss": 181.89268159866333, "training_acc": 72.33333333333333, "val_loss": 45.372929096221924, "val_acc": 72.0}
{"epoch": 9, "training_loss": 180.32631278038025, "training_acc": 72.33333333333333, "val_loss": 45.0766144990921, "val_acc": 72.0}
{"epoch": 10, "training_loss": 179.40462350845337, "training_acc": 72.33333333333333, "val_loss": 44.85943990945816, "val_acc": 72.0}
{"epoch": 11, "training_loss": 178.30926609039307, "training_acc": 72.33333333333333, "val_loss": 44.726715445518494, "val_acc": 72.0}
{"epoch": 12, "training_loss": 177.9122769832611, "training_acc": 72.33333333333333, "val_loss": 44.62456172704697, "val_acc": 72.0}
{"epoch": 13, "training_loss": 177.50464248657227, "training_acc": 72.33333333333333, "val_loss": 44.56004458665848, "val_acc": 72.0}
{"epoch": 14, "training_loss": 177.22525000572205, "training_acc": 72.33333333333333, "val_loss": 44.51598733663559, "val_acc": 72.0}
{"epoch": 15, "training_loss": 177.0494737625122, "training_acc": 72.33333333333333, "val_loss": 44.48968690633774, "val_acc": 72.0}
{"epoch": 16, "training_loss": 177.00550723075867, "training_acc": 72.33333333333333, "val_loss": 44.470259606838226, "val_acc": 72.0}
{"epoch": 17, "training_loss": 176.97698783874512, "training_acc": 72.33333333333333, "val_loss": 44.46140468120575, "val_acc": 72.0}
{"epoch": 18, "training_loss": 176.84012961387634, "training_acc": 72.33333333333333, "val_loss": 44.45901930332184, "val_acc": 72.0}
{"epoch": 19, "training_loss": 176.86822128295898, "training_acc": 72.33333333333333, "val_loss": 44.4582661986351, "val_acc": 72.0}
{"epoch": 20, "training_loss": 176.8466739654541, "training_acc": 72.33333333333333, "val_loss": 44.45864164829254, "val_acc": 72.0}
{"epoch": 21, "training_loss": 176.86626982688904, "training_acc": 72.33333333333333, "val_loss": 44.46019673347473, "val_acc": 72.0}
{"epoch": 22, "training_loss": 176.81861662864685, "training_acc": 72.33333333333333, "val_loss": 44.46045833826065, "val_acc": 72.0}
{"epoch": 23, "training_loss": 176.82592105865479, "training_acc": 72.33333333333333, "val_loss": 44.46001523733139, "val_acc": 72.0}
{"epoch": 24, "training_loss": 176.78123259544373, "training_acc": 72.33333333333333, "val_loss": 44.46064031124115, "val_acc": 72.0}
{"epoch": 25, "training_loss": 176.767986536026, "training_acc": 72.33333333333333, "val_loss": 44.460664212703705, "val_acc": 72.0}
{"epoch": 26, "training_loss": 176.8487946987152, "training_acc": 72.33333333333333, "val_loss": 44.460036754608154, "val_acc": 72.0}
{"epoch": 27, "training_loss": 176.82810997962952, "training_acc": 72.33333333333333, "val_loss": 44.46061897277832, "val_acc": 72.0}
{"epoch": 28, "training_loss": 176.83081221580505, "training_acc": 72.33333333333333, "val_loss": 44.460612773895264, "val_acc": 72.0}
{"epoch": 29, "training_loss": 176.82021355628967, "training_acc": 72.33333333333333, "val_loss": 44.46147605776787, "val_acc": 72.0}
{"epoch": 30, "training_loss": 176.86477994918823, "training_acc": 72.33333333333333, "val_loss": 44.459873259067535, "val_acc": 72.0}
{"epoch": 31, "training_loss": 176.7782552242279, "training_acc": 72.33333333333333, "val_loss": 44.45992863178253, "val_acc": 72.0}
{"epoch": 32, "training_loss": 176.8212776184082, "training_acc": 72.33333333333333, "val_loss": 44.46056270599365, "val_acc": 72.0}
{"epoch": 33, "training_loss": 176.7961494922638, "training_acc": 72.33333333333333, "val_loss": 44.45978716015816, "val_acc": 72.0}
{"epoch": 34, "training_loss": 176.80909729003906, "training_acc": 72.33333333333333, "val_loss": 44.46055853366852, "val_acc": 72.0}
{"epoch": 35, "training_loss": 176.7791142463684, "training_acc": 72.33333333333333, "val_loss": 44.46134325861931, "val_acc": 72.0}
{"epoch": 36, "training_loss": 176.82670426368713, "training_acc": 72.33333333333333, "val_loss": 44.46262341737747, "val_acc": 72.0}
{"epoch": 37, "training_loss": 176.80800127983093, "training_acc": 72.33333333333333, "val_loss": 44.46113383769989, "val_acc": 72.0}
{"epoch": 38, "training_loss": 176.79848217964172, "training_acc": 72.33333333333333, "val_loss": 44.46125319600105, "val_acc": 72.0}
