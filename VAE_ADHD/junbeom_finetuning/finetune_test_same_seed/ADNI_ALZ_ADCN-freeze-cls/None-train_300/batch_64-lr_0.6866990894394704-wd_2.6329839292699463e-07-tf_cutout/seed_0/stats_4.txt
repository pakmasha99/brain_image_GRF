"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 300 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 14201.596900939941, "training_acc": 65.66666666666667, "val_loss": 6510.096786499023, "val_acc": 28.0}
{"epoch": 1, "training_loss": 16828.019958496094, "training_acc": 51.666666666666664, "val_loss": 7596.3102951049805, "val_acc": 72.0}
{"epoch": 2, "training_loss": 26914.14077758789, "training_acc": 72.33333333333333, "val_loss": 3285.6437644958496, "val_acc": 72.0}
{"epoch": 3, "training_loss": 14855.4189453125, "training_acc": 44.333333333333336, "val_loss": 44.07288086414337, "val_acc": 72.0}
{"epoch": 4, "training_loss": 7379.365333557129, "training_acc": 72.33333333333333, "val_loss": 1893.3674507141113, "val_acc": 72.0}
{"epoch": 5, "training_loss": 5560.7005034685135, "training_acc": 55.666666666666664, "val_loss": 838.8526964187622, "val_acc": 72.0}
{"epoch": 6, "training_loss": 3780.8257064819336, "training_acc": 65.0, "val_loss": 924.9266214370728, "val_acc": 28.0}
{"epoch": 7, "training_loss": 5796.073928833008, "training_acc": 62.333333333333336, "val_loss": 1407.9410076141357, "val_acc": 72.0}
{"epoch": 8, "training_loss": 5648.650820732117, "training_acc": 49.666666666666664, "val_loss": 753.2941415309906, "val_acc": 72.0}
{"epoch": 9, "training_loss": 2236.05161857605, "training_acc": 63.666666666666664, "val_loss": 252.95021438598633, "val_acc": 72.0}
{"epoch": 10, "training_loss": 2067.890552520752, "training_acc": 61.666666666666664, "val_loss": 81.04939723014832, "val_acc": 72.0}
{"epoch": 11, "training_loss": 4924.1640625, "training_acc": 51.0, "val_loss": 1623.3647537231445, "val_acc": 72.0}
{"epoch": 12, "training_loss": 3432.492105484009, "training_acc": 62.333333333333336, "val_loss": 330.96785974502563, "val_acc": 28.0}
{"epoch": 13, "training_loss": 2627.7463779449463, "training_acc": 63.666666666666664, "val_loss": 848.6039743423462, "val_acc": 28.0}
{"epoch": 14, "training_loss": 1083.8300914764404, "training_acc": 58.0, "val_loss": 97.49927002191544, "val_acc": 72.0}
{"epoch": 15, "training_loss": 1535.5562047958374, "training_acc": 63.666666666666664, "val_loss": 1396.6880741119385, "val_acc": 28.0}
{"epoch": 16, "training_loss": 6323.89582824707, "training_acc": 50.333333333333336, "val_loss": 2420.620958328247, "val_acc": 72.0}
{"epoch": 17, "training_loss": 6451.447364807129, "training_acc": 66.33333333333333, "val_loss": 3899.4598541259766, "val_acc": 28.0}
{"epoch": 18, "training_loss": 8799.265258789062, "training_acc": 54.333333333333336, "val_loss": 2949.863540649414, "val_acc": 72.0}
{"epoch": 19, "training_loss": 8224.501441955566, "training_acc": 72.33333333333333, "val_loss": 3344.178524017334, "val_acc": 28.0}
{"epoch": 20, "training_loss": 9908.942474365234, "training_acc": 43.666666666666664, "val_loss": 2621.3711948394775, "val_acc": 72.0}
{"epoch": 21, "training_loss": 9801.68977355957, "training_acc": 72.33333333333333, "val_loss": 318.6789665222168, "val_acc": 72.0}
{"epoch": 22, "training_loss": 9047.945663452148, "training_acc": 43.666666666666664, "val_loss": 1659.1145668029785, "val_acc": 72.0}
