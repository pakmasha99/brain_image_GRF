"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 300 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 13925.712097167969, "training_acc": 54.666666666666664, "val_loss": 1080.5909461975098, "val_acc": 26.666666666666668}
{"epoch": 1, "training_loss": 10272.331405639648, "training_acc": 64.0, "val_loss": 2566.6394023895264, "val_acc": 73.33333333333333}
{"epoch": 2, "training_loss": 5721.240261077881, "training_acc": 54.0, "val_loss": 1415.0570621490479, "val_acc": 73.33333333333333}
{"epoch": 3, "training_loss": 4256.619215965271, "training_acc": 59.333333333333336, "val_loss": 161.287757396698, "val_acc": 73.33333333333333}
{"epoch": 4, "training_loss": 2445.655445098877, "training_acc": 60.666666666666664, "val_loss": 120.88522243499756, "val_acc": 26.666666666666668}
{"epoch": 5, "training_loss": 1604.2285079956055, "training_acc": 49.333333333333336, "val_loss": 277.48878955841064, "val_acc": 73.33333333333333}
{"epoch": 6, "training_loss": 1390.9898128509521, "training_acc": 64.66666666666667, "val_loss": 623.7093858718872, "val_acc": 26.666666666666668}
{"epoch": 7, "training_loss": 1277.4721183776855, "training_acc": 56.666666666666664, "val_loss": 658.694314956665, "val_acc": 73.33333333333333}
{"epoch": 8, "training_loss": 3282.534748315811, "training_acc": 66.0, "val_loss": 491.1144895553589, "val_acc": 26.666666666666668}
{"epoch": 9, "training_loss": 3690.2182388305664, "training_acc": 59.333333333333336, "val_loss": 604.7151412963867, "val_acc": 26.666666666666668}
{"epoch": 10, "training_loss": 2272.670852661133, "training_acc": 50.0, "val_loss": 1333.7423458099365, "val_acc": 73.33333333333333}
{"epoch": 11, "training_loss": 3235.642074584961, "training_acc": 60.666666666666664, "val_loss": 777.8493556976318, "val_acc": 73.33333333333333}
{"epoch": 12, "training_loss": 3625.1493167877197, "training_acc": 72.0, "val_loss": 1818.866039276123, "val_acc": 26.666666666666668}
{"epoch": 13, "training_loss": 5098.839752197266, "training_acc": 52.0, "val_loss": 989.850811958313, "val_acc": 73.33333333333333}
{"epoch": 14, "training_loss": 4445.122692108154, "training_acc": 51.333333333333336, "val_loss": 1160.0924072265625, "val_acc": 73.33333333333333}
{"epoch": 15, "training_loss": 4280.813726425171, "training_acc": 72.0, "val_loss": 3017.591320037842, "val_acc": 26.666666666666668}
{"epoch": 16, "training_loss": 8290.93701171875, "training_acc": 46.666666666666664, "val_loss": 2933.406520843506, "val_acc": 73.33333333333333}
{"epoch": 17, "training_loss": 11503.985870361328, "training_acc": 72.0, "val_loss": 653.0452971458435, "val_acc": 73.33333333333333}
{"epoch": 18, "training_loss": 6021.484279632568, "training_acc": 44.0, "val_loss": 2217.139533996582, "val_acc": 73.33333333333333}
{"epoch": 19, "training_loss": 12084.547836303711, "training_acc": 72.0, "val_loss": 1636.2609195709229, "val_acc": 73.33333333333333}
{"epoch": 20, "training_loss": 9070.083129882812, "training_acc": 47.333333333333336, "val_loss": 617.6523532867432, "val_acc": 73.33333333333333}
{"epoch": 21, "training_loss": 6532.953742980957, "training_acc": 72.0, "val_loss": 1374.7523250579834, "val_acc": 73.33333333333333}
{"epoch": 22, "training_loss": 4496.645506858826, "training_acc": 54.666666666666664, "val_loss": 554.8099822998047, "val_acc": 73.33333333333333}
{"epoch": 23, "training_loss": 3065.2950477600098, "training_acc": 54.666666666666664, "val_loss": 890.9812602996826, "val_acc": 73.33333333333333}
