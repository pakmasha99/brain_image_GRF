"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 300 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 122969750.20767212, "training_acc": 66.33333333333333, "val_loss": 67499986.5, "val_acc": 28.0}
{"epoch": 1, "training_loss": 156652087.5, "training_acc": 55.666666666666664, "val_loss": 69025804.625, "val_acc": 72.0}
{"epoch": 2, "training_loss": 237604112.25, "training_acc": 72.33333333333333, "val_loss": 23235921.21875, "val_acc": 72.0}
{"epoch": 3, "training_loss": 95455301.453125, "training_acc": 35.0, "val_loss": 19876809.78125, "val_acc": 72.0}
{"epoch": 4, "training_loss": 149269421.75, "training_acc": 72.33333333333333, "val_loss": 45379537.484375, "val_acc": 72.0}
{"epoch": 5, "training_loss": 106443950.65625, "training_acc": 65.0, "val_loss": 16103161.8125, "val_acc": 28.0}
{"epoch": 6, "training_loss": 57619513.75, "training_acc": 53.666666666666664, "val_loss": 26627422.5, "val_acc": 72.0}
{"epoch": 7, "training_loss": 69461661.4375, "training_acc": 65.66666666666667, "val_loss": 14320238.609375, "val_acc": 28.0}
{"epoch": 8, "training_loss": 19525164.009765625, "training_acc": 65.0, "val_loss": 10430872.453125, "val_acc": 28.0}
{"epoch": 9, "training_loss": 13317702.078125, "training_acc": 58.333333333333336, "val_loss": 571676.04296875, "val_acc": 65.33333333333333}
{"epoch": 10, "training_loss": 16865948.84375, "training_acc": 62.0, "val_loss": 7099443.1171875, "val_acc": 28.0}
{"epoch": 11, "training_loss": 10739908.796875, "training_acc": 60.0, "val_loss": 6196173.5390625, "val_acc": 72.0}
{"epoch": 12, "training_loss": 15580375.671875, "training_acc": 62.333333333333336, "val_loss": 800572.7036132812, "val_acc": 54.666666666666664}
{"epoch": 13, "training_loss": 8792956.5, "training_acc": 64.66666666666667, "val_loss": 2784848.578125, "val_acc": 72.0}
{"epoch": 14, "training_loss": 25640218.5625, "training_acc": 58.0, "val_loss": 18532690.84375, "val_acc": 72.0}
{"epoch": 15, "training_loss": 55877784.625, "training_acc": 63.666666666666664, "val_loss": 21630864.4375, "val_acc": 28.0}
{"epoch": 16, "training_loss": 36911549.046875, "training_acc": 59.333333333333336, "val_loss": 6059407.9765625, "val_acc": 28.0}
{"epoch": 17, "training_loss": 11684514.09375, "training_acc": 58.0, "val_loss": 4658919.3828125, "val_acc": 72.0}
{"epoch": 18, "training_loss": 17351309.5, "training_acc": 62.333333333333336, "val_loss": 6973893.53125, "val_acc": 72.0}
{"epoch": 19, "training_loss": 32610390.953125, "training_acc": 72.66666666666667, "val_loss": 17037557.09375, "val_acc": 28.0}
{"epoch": 20, "training_loss": 44114439.46875, "training_acc": 51.666666666666664, "val_loss": 7139000.9453125, "val_acc": 72.0}
{"epoch": 21, "training_loss": 25647089.8125, "training_acc": 54.333333333333336, "val_loss": 14333614.81640625, "val_acc": 72.0}
{"epoch": 22, "training_loss": 41568910.4375, "training_acc": 68.33333333333333, "val_loss": 6385989.90625, "val_acc": 28.0}
{"epoch": 23, "training_loss": 48278985.9375, "training_acc": 59.666666666666664, "val_loss": 6974503.6171875, "val_acc": 72.0}
{"epoch": 24, "training_loss": 18330401.890625, "training_acc": 59.0, "val_loss": 6057088.46484375, "val_acc": 72.0}
{"epoch": 25, "training_loss": 24586190.8125, "training_acc": 58.666666666666664, "val_loss": 14861948.984375, "val_acc": 72.0}
{"epoch": 26, "training_loss": 52974077.8125, "training_acc": 72.33333333333333, "val_loss": 11613404.0625, "val_acc": 28.0}
{"epoch": 27, "training_loss": 39900648.5625, "training_acc": 49.333333333333336, "val_loss": 6779951.40625, "val_acc": 72.0}
{"epoch": 28, "training_loss": 19623401.875, "training_acc": 62.666666666666664, "val_loss": 9705882.875, "val_acc": 72.0}
