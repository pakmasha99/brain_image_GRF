"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 300 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 193.67871356010437, "training_acc": 72.33333333333333, "val_loss": 47.993530213832855, "val_acc": 28.0}
{"epoch": 1, "training_loss": 190.44343733787537, "training_acc": 72.33333333333333, "val_loss": 47.263683795928955, "val_acc": 28.0}
{"epoch": 2, "training_loss": 187.6182131767273, "training_acc": 72.33333333333333, "val_loss": 46.62740075588226, "val_acc": 28.0}
{"epoch": 3, "training_loss": 185.1903247833252, "training_acc": 72.33333333333333, "val_loss": 46.09217393398285, "val_acc": 28.0}
{"epoch": 4, "training_loss": 183.09027242660522, "training_acc": 72.33333333333333, "val_loss": 45.660990715026855, "val_acc": 72.0}
{"epoch": 5, "training_loss": 181.48018407821655, "training_acc": 72.33333333333333, "val_loss": 45.321880877017975, "val_acc": 72.0}
{"epoch": 6, "training_loss": 180.1921305656433, "training_acc": 72.33333333333333, "val_loss": 45.05850690603256, "val_acc": 72.0}
{"epoch": 7, "training_loss": 179.19717812538147, "training_acc": 72.33333333333333, "val_loss": 44.85991105437279, "val_acc": 72.0}
{"epoch": 8, "training_loss": 178.55871605873108, "training_acc": 72.33333333333333, "val_loss": 44.71593028306961, "val_acc": 72.0}
{"epoch": 9, "training_loss": 177.918518781662, "training_acc": 72.33333333333333, "val_loss": 44.62281554937363, "val_acc": 72.0}
{"epoch": 10, "training_loss": 177.56406259536743, "training_acc": 72.33333333333333, "val_loss": 44.55914953351021, "val_acc": 72.0}
{"epoch": 11, "training_loss": 177.29038429260254, "training_acc": 72.33333333333333, "val_loss": 44.517022371292114, "val_acc": 72.0}
{"epoch": 12, "training_loss": 177.10008025169373, "training_acc": 72.33333333333333, "val_loss": 44.49033260345459, "val_acc": 72.0}
{"epoch": 13, "training_loss": 177.04483842849731, "training_acc": 72.33333333333333, "val_loss": 44.46955734491348, "val_acc": 72.0}
{"epoch": 14, "training_loss": 176.92088270187378, "training_acc": 72.33333333333333, "val_loss": 44.45942783355713, "val_acc": 72.0}
{"epoch": 15, "training_loss": 176.9308180809021, "training_acc": 72.33333333333333, "val_loss": 44.45303624868393, "val_acc": 72.0}
{"epoch": 16, "training_loss": 176.8605179786682, "training_acc": 72.33333333333333, "val_loss": 44.45056068897247, "val_acc": 72.0}
{"epoch": 17, "training_loss": 176.85634994506836, "training_acc": 72.33333333333333, "val_loss": 44.44987630844116, "val_acc": 72.0}
{"epoch": 18, "training_loss": 176.83692932128906, "training_acc": 72.33333333333333, "val_loss": 44.449823796749115, "val_acc": 72.0}
{"epoch": 19, "training_loss": 176.86974477767944, "training_acc": 72.33333333333333, "val_loss": 44.44981050491333, "val_acc": 72.0}
{"epoch": 20, "training_loss": 176.88552069664001, "training_acc": 72.33333333333333, "val_loss": 44.44996476173401, "val_acc": 72.0}
{"epoch": 21, "training_loss": 176.8034770488739, "training_acc": 72.33333333333333, "val_loss": 44.450179398059845, "val_acc": 72.0}
{"epoch": 22, "training_loss": 176.850022315979, "training_acc": 72.33333333333333, "val_loss": 44.45072793960571, "val_acc": 72.0}
{"epoch": 23, "training_loss": 176.81851887702942, "training_acc": 72.33333333333333, "val_loss": 44.45103761553764, "val_acc": 72.0}
{"epoch": 24, "training_loss": 176.87281966209412, "training_acc": 72.33333333333333, "val_loss": 44.45048636198044, "val_acc": 72.0}
{"epoch": 25, "training_loss": 176.85985374450684, "training_acc": 72.33333333333333, "val_loss": 44.45061492919922, "val_acc": 72.0}
{"epoch": 26, "training_loss": 176.84129118919373, "training_acc": 72.33333333333333, "val_loss": 44.45186257362366, "val_acc": 72.0}
{"epoch": 27, "training_loss": 176.83926939964294, "training_acc": 72.33333333333333, "val_loss": 44.45210725069046, "val_acc": 72.0}
{"epoch": 28, "training_loss": 176.87228775024414, "training_acc": 72.33333333333333, "val_loss": 44.45215559005737, "val_acc": 72.0}
{"epoch": 29, "training_loss": 176.82536220550537, "training_acc": 72.33333333333333, "val_loss": 44.452467024326324, "val_acc": 72.0}
{"epoch": 30, "training_loss": 176.83166933059692, "training_acc": 72.33333333333333, "val_loss": 44.45273515582085, "val_acc": 72.0}
{"epoch": 31, "training_loss": 176.86858367919922, "training_acc": 72.33333333333333, "val_loss": 44.45442980527878, "val_acc": 72.0}
{"epoch": 32, "training_loss": 176.8615391254425, "training_acc": 72.33333333333333, "val_loss": 44.45441710948944, "val_acc": 72.0}
{"epoch": 33, "training_loss": 176.8396987915039, "training_acc": 72.33333333333333, "val_loss": 44.4531455039978, "val_acc": 72.0}
{"epoch": 34, "training_loss": 176.8404324054718, "training_acc": 72.33333333333333, "val_loss": 44.451202034950256, "val_acc": 72.0}
{"epoch": 35, "training_loss": 176.87984609603882, "training_acc": 72.33333333333333, "val_loss": 44.45178681612015, "val_acc": 72.0}
{"epoch": 36, "training_loss": 176.88313162326813, "training_acc": 72.33333333333333, "val_loss": 44.450846403837204, "val_acc": 72.0}
{"epoch": 37, "training_loss": 176.83771967887878, "training_acc": 72.33333333333333, "val_loss": 44.4514474272728, "val_acc": 72.0}
{"epoch": 38, "training_loss": 176.8686182498932, "training_acc": 72.33333333333333, "val_loss": 44.452555537223816, "val_acc": 72.0}
