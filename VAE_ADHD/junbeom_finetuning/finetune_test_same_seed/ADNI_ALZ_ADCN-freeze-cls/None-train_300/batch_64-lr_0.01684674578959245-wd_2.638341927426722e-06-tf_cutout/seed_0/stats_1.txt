"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 300 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 399.9873011112213, "training_acc": 72.33333333333333, "val_loss": 166.56885159015656, "val_acc": 28.0}
{"epoch": 1, "training_loss": 413.34225130081177, "training_acc": 56.333333333333336, "val_loss": 123.34906220436096, "val_acc": 72.0}
{"epoch": 2, "training_loss": 374.02860045433044, "training_acc": 63.666666666666664, "val_loss": 78.33270704746246, "val_acc": 28.0}
{"epoch": 3, "training_loss": 220.92632699012756, "training_acc": 55.666666666666664, "val_loss": 68.45861285924911, "val_acc": 72.0}
{"epoch": 4, "training_loss": 217.7282111644745, "training_acc": 72.33333333333333, "val_loss": 62.299564599990845, "val_acc": 28.0}
{"epoch": 5, "training_loss": 205.31354594230652, "training_acc": 55.0, "val_loss": 54.940679132938385, "val_acc": 72.0}
{"epoch": 6, "training_loss": 196.84132599830627, "training_acc": 72.33333333333333, "val_loss": 47.176463305950165, "val_acc": 28.0}
{"epoch": 7, "training_loss": 182.5728361606598, "training_acc": 72.33333333333333, "val_loss": 46.079888969659805, "val_acc": 72.0}
{"epoch": 8, "training_loss": 185.36228346824646, "training_acc": 72.33333333333333, "val_loss": 45.587619334459305, "val_acc": 72.0}
{"epoch": 9, "training_loss": 189.71072340011597, "training_acc": 72.33333333333333, "val_loss": 51.802487671375275, "val_acc": 28.0}
{"epoch": 10, "training_loss": 205.11732292175293, "training_acc": 70.33333333333333, "val_loss": 44.58403617143631, "val_acc": 72.0}
{"epoch": 11, "training_loss": 186.28689432144165, "training_acc": 72.33333333333333, "val_loss": 50.06069043278694, "val_acc": 72.0}
{"epoch": 12, "training_loss": 189.47445702552795, "training_acc": 72.33333333333333, "val_loss": 44.61699068546295, "val_acc": 72.0}
{"epoch": 13, "training_loss": 178.2739715576172, "training_acc": 72.33333333333333, "val_loss": 44.41595321893692, "val_acc": 72.0}
{"epoch": 14, "training_loss": 180.78889918327332, "training_acc": 72.33333333333333, "val_loss": 46.46066105365753, "val_acc": 72.0}
{"epoch": 15, "training_loss": 182.86156392097473, "training_acc": 72.33333333333333, "val_loss": 44.454721957445145, "val_acc": 72.0}
{"epoch": 16, "training_loss": 177.55215907096863, "training_acc": 72.33333333333333, "val_loss": 46.5820751786232, "val_acc": 72.0}
{"epoch": 17, "training_loss": 185.31826043128967, "training_acc": 72.33333333333333, "val_loss": 47.19787082076073, "val_acc": 72.0}
{"epoch": 18, "training_loss": 184.8767683506012, "training_acc": 72.33333333333333, "val_loss": 63.725725531578064, "val_acc": 28.0}
{"epoch": 19, "training_loss": 209.75242066383362, "training_acc": 55.0, "val_loss": 51.5534029006958, "val_acc": 72.0}
{"epoch": 20, "training_loss": 188.4353940486908, "training_acc": 64.33333333333333, "val_loss": 45.91767060756683, "val_acc": 72.0}
{"epoch": 21, "training_loss": 197.59655261039734, "training_acc": 72.33333333333333, "val_loss": 57.855717062950134, "val_acc": 28.0}
{"epoch": 22, "training_loss": 214.67294883728027, "training_acc": 61.0, "val_loss": 44.18035310506821, "val_acc": 72.0}
{"epoch": 23, "training_loss": 178.82810842990875, "training_acc": 72.33333333333333, "val_loss": 54.75767731666565, "val_acc": 72.0}
{"epoch": 24, "training_loss": 205.59187769889832, "training_acc": 69.0, "val_loss": 55.1269114613533, "val_acc": 28.0}
{"epoch": 25, "training_loss": 222.65441608428955, "training_acc": 65.0, "val_loss": 44.69609707593918, "val_acc": 72.0}
{"epoch": 26, "training_loss": 227.85047507286072, "training_acc": 46.333333333333336, "val_loss": 54.8396360874176, "val_acc": 72.0}
{"epoch": 27, "training_loss": 220.04044675827026, "training_acc": 60.333333333333336, "val_loss": 49.40548339486122, "val_acc": 72.0}
{"epoch": 28, "training_loss": 229.6735861301422, "training_acc": 72.33333333333333, "val_loss": 62.59169244766235, "val_acc": 28.0}
{"epoch": 29, "training_loss": 197.0049831867218, "training_acc": 57.0, "val_loss": 62.52489298582077, "val_acc": 72.0}
{"epoch": 30, "training_loss": 226.96693801879883, "training_acc": 62.0, "val_loss": 46.17836195230484, "val_acc": 72.0}
{"epoch": 31, "training_loss": 206.6360354423523, "training_acc": 72.33333333333333, "val_loss": 56.00059616565704, "val_acc": 28.0}
{"epoch": 32, "training_loss": 209.38216161727905, "training_acc": 52.333333333333336, "val_loss": 45.560599625110626, "val_acc": 72.0}
{"epoch": 33, "training_loss": 177.58521056175232, "training_acc": 72.33333333333333, "val_loss": 45.362260699272156, "val_acc": 72.0}
{"epoch": 34, "training_loss": 182.14941930770874, "training_acc": 72.33333333333333, "val_loss": 44.25781583786011, "val_acc": 72.0}
{"epoch": 35, "training_loss": 177.99148774147034, "training_acc": 72.33333333333333, "val_loss": 44.50987583398819, "val_acc": 72.0}
{"epoch": 36, "training_loss": 181.9659390449524, "training_acc": 72.33333333333333, "val_loss": 44.26181501150131, "val_acc": 72.0}
{"epoch": 37, "training_loss": 175.19556593894958, "training_acc": 72.33333333333333, "val_loss": 44.56449770927429, "val_acc": 72.0}
{"epoch": 38, "training_loss": 178.5370819568634, "training_acc": 72.33333333333333, "val_loss": 45.02350044250488, "val_acc": 72.0}
{"epoch": 39, "training_loss": 177.76816749572754, "training_acc": 72.33333333333333, "val_loss": 47.022443652153015, "val_acc": 28.0}
{"epoch": 40, "training_loss": 173.85202741622925, "training_acc": 72.33333333333333, "val_loss": 51.49691420793533, "val_acc": 72.0}
{"epoch": 41, "training_loss": 188.0511531829834, "training_acc": 72.33333333333333, "val_loss": 44.5393208861351, "val_acc": 72.0}
