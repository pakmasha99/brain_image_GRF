"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 300 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 341.01545810699463, "training_acc": 69.66666666666667, "val_loss": 108.84289646148682, "val_acc": 28.0}
{"epoch": 1, "training_loss": 302.7476501464844, "training_acc": 65.0, "val_loss": 84.75956523418427, "val_acc": 72.0}
{"epoch": 2, "training_loss": 296.5690097808838, "training_acc": 52.333333333333336, "val_loss": 47.50896352529526, "val_acc": 28.0}
{"epoch": 3, "training_loss": 214.8817481994629, "training_acc": 72.33333333333333, "val_loss": 50.64433616399765, "val_acc": 72.0}
{"epoch": 4, "training_loss": 192.4939444065094, "training_acc": 72.33333333333333, "val_loss": 44.834893226623535, "val_acc": 72.0}
{"epoch": 5, "training_loss": 182.11077308654785, "training_acc": 72.33333333333333, "val_loss": 44.37490504980087, "val_acc": 72.0}
{"epoch": 6, "training_loss": 178.56128406524658, "training_acc": 72.33333333333333, "val_loss": 44.64655137062073, "val_acc": 72.0}
{"epoch": 7, "training_loss": 180.5440821647644, "training_acc": 72.33333333333333, "val_loss": 44.50511983036995, "val_acc": 72.0}
{"epoch": 8, "training_loss": 176.4575355052948, "training_acc": 72.33333333333333, "val_loss": 44.157763957977295, "val_acc": 72.0}
{"epoch": 9, "training_loss": 178.7555558681488, "training_acc": 72.33333333333333, "val_loss": 46.708036720752716, "val_acc": 28.0}
{"epoch": 10, "training_loss": 188.53567481040955, "training_acc": 72.33333333333333, "val_loss": 45.816961228847504, "val_acc": 57.333333333333336}
{"epoch": 11, "training_loss": 181.38322234153748, "training_acc": 72.66666666666667, "val_loss": 48.18435862660408, "val_acc": 72.0}
{"epoch": 12, "training_loss": 183.05934166908264, "training_acc": 72.33333333333333, "val_loss": 43.89677757024765, "val_acc": 70.66666666666667}
{"epoch": 13, "training_loss": 173.99364137649536, "training_acc": 72.33333333333333, "val_loss": 44.29927748441696, "val_acc": 73.33333333333333}
{"epoch": 14, "training_loss": 176.1518292427063, "training_acc": 72.66666666666667, "val_loss": 45.15504741668701, "val_acc": 72.0}
{"epoch": 15, "training_loss": 177.0156626701355, "training_acc": 72.33333333333333, "val_loss": 44.26135370135307, "val_acc": 72.0}
{"epoch": 16, "training_loss": 174.68417358398438, "training_acc": 72.33333333333333, "val_loss": 45.85439443588257, "val_acc": 72.0}
{"epoch": 17, "training_loss": 179.6787073612213, "training_acc": 72.66666666666667, "val_loss": 45.55344471335411, "val_acc": 72.0}
{"epoch": 18, "training_loss": 178.29540395736694, "training_acc": 72.33333333333333, "val_loss": 62.48237627744675, "val_acc": 28.0}
{"epoch": 19, "training_loss": 202.58127975463867, "training_acc": 58.666666666666664, "val_loss": 51.986603766679764, "val_acc": 72.0}
{"epoch": 20, "training_loss": 184.65445566177368, "training_acc": 68.66666666666667, "val_loss": 44.10937303304672, "val_acc": 69.33333333333333}
{"epoch": 21, "training_loss": 192.89992690086365, "training_acc": 72.33333333333333, "val_loss": 57.36653345823288, "val_acc": 28.0}
{"epoch": 22, "training_loss": 205.5683560371399, "training_acc": 63.333333333333336, "val_loss": 43.77870446443558, "val_acc": 69.33333333333333}
{"epoch": 23, "training_loss": 173.39252746105194, "training_acc": 75.0, "val_loss": 53.22379910945892, "val_acc": 72.0}
{"epoch": 24, "training_loss": 203.63466477394104, "training_acc": 72.33333333333333, "val_loss": 59.36143600940704, "val_acc": 28.0}
{"epoch": 25, "training_loss": 227.29461193084717, "training_acc": 63.0, "val_loss": 48.429980516433716, "val_acc": 72.0}
{"epoch": 26, "training_loss": 206.52108788490295, "training_acc": 59.333333333333336, "val_loss": 49.24808996915817, "val_acc": 72.0}
{"epoch": 27, "training_loss": 198.22013092041016, "training_acc": 70.33333333333333, "val_loss": 43.378234058618546, "val_acc": 72.0}
{"epoch": 28, "training_loss": 189.48978781700134, "training_acc": 72.66666666666667, "val_loss": 51.531104028224945, "val_acc": 28.0}
{"epoch": 29, "training_loss": 172.32057118415833, "training_acc": 71.33333333333333, "val_loss": 55.91512721776962, "val_acc": 72.0}
{"epoch": 30, "training_loss": 202.95814967155457, "training_acc": 69.0, "val_loss": 43.350124299526215, "val_acc": 72.0}
{"epoch": 31, "training_loss": 182.8906512260437, "training_acc": 72.33333333333333, "val_loss": 50.66800606250763, "val_acc": 32.0}
{"epoch": 32, "training_loss": 188.18221282958984, "training_acc": 70.33333333333333, "val_loss": 44.71765226125717, "val_acc": 69.33333333333333}
{"epoch": 33, "training_loss": 165.52830290794373, "training_acc": 73.0, "val_loss": 43.44854360818863, "val_acc": 72.0}
{"epoch": 34, "training_loss": 168.8462038040161, "training_acc": 72.66666666666667, "val_loss": 43.56477642059326, "val_acc": 66.66666666666667}
{"epoch": 35, "training_loss": 164.77231216430664, "training_acc": 72.33333333333333, "val_loss": 44.59630137681961, "val_acc": 69.33333333333333}
{"epoch": 36, "training_loss": 174.80059003829956, "training_acc": 71.0, "val_loss": 43.25665736198425, "val_acc": 73.33333333333333}
{"epoch": 37, "training_loss": 165.96732997894287, "training_acc": 73.33333333333333, "val_loss": 45.27035242319107, "val_acc": 56.0}
{"epoch": 38, "training_loss": 164.4138058423996, "training_acc": 73.66666666666667, "val_loss": 45.22704493999481, "val_acc": 69.33333333333333}
{"epoch": 39, "training_loss": 166.381742477417, "training_acc": 74.33333333333333, "val_loss": 45.51164165139198, "val_acc": 58.666666666666664}
{"epoch": 40, "training_loss": 160.56923687458038, "training_acc": 75.33333333333333, "val_loss": 48.383696138858795, "val_acc": 70.66666666666667}
{"epoch": 41, "training_loss": 171.1190357208252, "training_acc": 73.66666666666667, "val_loss": 43.19963884353638, "val_acc": 72.0}
{"epoch": 42, "training_loss": 164.80094242095947, "training_acc": 73.33333333333333, "val_loss": 46.372798442840576, "val_acc": 57.333333333333336}
{"epoch": 43, "training_loss": 170.90239143371582, "training_acc": 75.0, "val_loss": 43.76117318868637, "val_acc": 72.0}
{"epoch": 44, "training_loss": 161.5755877494812, "training_acc": 72.66666666666667, "val_loss": 43.43033969402313, "val_acc": 73.33333333333333}
{"epoch": 45, "training_loss": 180.78913617134094, "training_acc": 73.66666666666667, "val_loss": 52.73015904426575, "val_acc": 32.0}
{"epoch": 46, "training_loss": 183.9408609867096, "training_acc": 68.66666666666667, "val_loss": 43.245613634586334, "val_acc": 72.0}
{"epoch": 47, "training_loss": 165.96755027770996, "training_acc": 73.66666666666667, "val_loss": 45.73300766944885, "val_acc": 69.33333333333333}
{"epoch": 48, "training_loss": 180.3198127746582, "training_acc": 70.0, "val_loss": 43.771655917167664, "val_acc": 74.66666666666667}
{"epoch": 49, "training_loss": 181.89149260520935, "training_acc": 72.0, "val_loss": 55.09182584285736, "val_acc": 32.0}
{"epoch": 50, "training_loss": 188.651025056839, "training_acc": 64.0, "val_loss": 51.9726197719574, "val_acc": 70.66666666666667}
{"epoch": 51, "training_loss": 180.78208947181702, "training_acc": 74.66666666666667, "val_loss": 46.36536556482315, "val_acc": 69.33333333333333}
{"epoch": 52, "training_loss": 181.71078062057495, "training_acc": 73.33333333333333, "val_loss": 50.13365191221237, "val_acc": 49.333333333333336}
{"epoch": 53, "training_loss": 173.96125984191895, "training_acc": 72.66666666666667, "val_loss": 43.4757861495018, "val_acc": 66.66666666666667}
{"epoch": 54, "training_loss": 159.2814793586731, "training_acc": 73.66666666666667, "val_loss": 46.16819679737091, "val_acc": 69.33333333333333}
{"epoch": 55, "training_loss": 166.64839339256287, "training_acc": 74.0, "val_loss": 43.46708723902702, "val_acc": 72.0}
{"epoch": 56, "training_loss": 164.92367553710938, "training_acc": 73.0, "val_loss": 44.5852375626564, "val_acc": 64.0}
{"epoch": 57, "training_loss": 165.7857415676117, "training_acc": 74.66666666666667, "val_loss": 44.20998656749725, "val_acc": 62.666666666666664}
{"epoch": 58, "training_loss": 170.5717258453369, "training_acc": 72.66666666666667, "val_loss": 45.54381251335144, "val_acc": 72.0}
{"epoch": 59, "training_loss": 164.36292004585266, "training_acc": 75.66666666666667, "val_loss": 46.84199959039688, "val_acc": 69.33333333333333}
{"epoch": 60, "training_loss": 172.48336029052734, "training_acc": 72.33333333333333, "val_loss": 51.50158351659775, "val_acc": 48.0}
