"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 300 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 18968.668197631836, "training_acc": 66.33333333333333, "val_loss": 6306.712196350098, "val_acc": 28.0}
{"epoch": 1, "training_loss": 13416.728561401367, "training_acc": 67.0, "val_loss": 2364.705722808838, "val_acc": 72.0}
{"epoch": 2, "training_loss": 15250.59967803955, "training_acc": 43.666666666666664, "val_loss": 2176.9547290802, "val_acc": 72.0}
{"epoch": 3, "training_loss": 21741.115173339844, "training_acc": 72.33333333333333, "val_loss": 6102.619590759277, "val_acc": 72.0}
{"epoch": 4, "training_loss": 15666.243621826172, "training_acc": 66.33333333333333, "val_loss": 7324.487846374512, "val_acc": 28.0}
{"epoch": 5, "training_loss": 13257.919700622559, "training_acc": 53.666666666666664, "val_loss": 2112.190685272217, "val_acc": 72.0}
{"epoch": 6, "training_loss": 4479.642439842224, "training_acc": 59.666666666666664, "val_loss": 1252.6353168487549, "val_acc": 72.0}
{"epoch": 7, "training_loss": 7510.774765014648, "training_acc": 72.33333333333333, "val_loss": 609.9784498214722, "val_acc": 28.0}
{"epoch": 8, "training_loss": 4301.409294128418, "training_acc": 53.666666666666664, "val_loss": 1602.9520511627197, "val_acc": 72.0}
{"epoch": 9, "training_loss": 3854.288131713867, "training_acc": 54.333333333333336, "val_loss": 2187.3961296081543, "val_acc": 72.0}
{"epoch": 10, "training_loss": 6624.490819692612, "training_acc": 72.33333333333333, "val_loss": 3884.040309906006, "val_acc": 28.0}
{"epoch": 11, "training_loss": 11362.50375366211, "training_acc": 44.333333333333336, "val_loss": 4747.194610595703, "val_acc": 72.0}
{"epoch": 12, "training_loss": 18525.082092285156, "training_acc": 72.33333333333333, "val_loss": 2146.5214653015137, "val_acc": 72.0}
{"epoch": 13, "training_loss": 14551.392364501953, "training_acc": 45.666666666666664, "val_loss": 280.7626190185547, "val_acc": 72.0}
{"epoch": 14, "training_loss": 6565.46891784668, "training_acc": 72.33333333333333, "val_loss": 688.4225797653198, "val_acc": 72.0}
{"epoch": 15, "training_loss": 5513.097923278809, "training_acc": 51.0, "val_loss": 1801.4650382995605, "val_acc": 72.0}
{"epoch": 16, "training_loss": 3485.590307235718, "training_acc": 66.0, "val_loss": 95.28685164451599, "val_acc": 72.0}
{"epoch": 17, "training_loss": 2229.2669105529785, "training_acc": 66.33333333333333, "val_loss": 107.99274098873138, "val_acc": 72.0}
{"epoch": 18, "training_loss": 6117.464950561523, "training_acc": 51.666666666666664, "val_loss": 2157.652069091797, "val_acc": 72.0}
{"epoch": 19, "training_loss": 6496.073699951172, "training_acc": 65.66666666666667, "val_loss": 3849.792366027832, "val_acc": 28.0}
{"epoch": 20, "training_loss": 13972.898040771484, "training_acc": 48.333333333333336, "val_loss": 5626.9743576049805, "val_acc": 72.0}
{"epoch": 21, "training_loss": 17931.907608032227, "training_acc": 72.33333333333333, "val_loss": 672.1883544921875, "val_acc": 72.0}
{"epoch": 22, "training_loss": 13410.0706949234, "training_acc": 44.333333333333336, "val_loss": 1368.715675354004, "val_acc": 72.0}
{"epoch": 23, "training_loss": 5578.3752784729, "training_acc": 72.33333333333333, "val_loss": 2004.5479793548584, "val_acc": 28.0}
{"epoch": 24, "training_loss": 7644.704635620117, "training_acc": 47.0, "val_loss": 1564.1352577209473, "val_acc": 72.0}
{"epoch": 25, "training_loss": 4895.911178588867, "training_acc": 55.0, "val_loss": 1520.0357646942139, "val_acc": 72.0}
{"epoch": 26, "training_loss": 5136.800048828125, "training_acc": 65.66666666666667, "val_loss": 899.7169561386108, "val_acc": 28.0}
{"epoch": 27, "training_loss": 6878.699645996094, "training_acc": 61.666666666666664, "val_loss": 1341.8647270202637, "val_acc": 72.0}
{"epoch": 28, "training_loss": 7462.482387542725, "training_acc": 47.0, "val_loss": 2140.9297828674316, "val_acc": 72.0}
{"epoch": 29, "training_loss": 16046.362686157227, "training_acc": 72.33333333333333, "val_loss": 4522.661407470703, "val_acc": 72.0}
{"epoch": 30, "training_loss": 11895.806610107422, "training_acc": 63.0, "val_loss": 6066.815559387207, "val_acc": 28.0}
{"epoch": 31, "training_loss": 12159.659652709961, "training_acc": 53.666666666666664, "val_loss": 2767.8856563568115, "val_acc": 72.0}
{"epoch": 32, "training_loss": 7446.427909851074, "training_acc": 67.66666666666667, "val_loss": 3233.90470123291, "val_acc": 28.0}
{"epoch": 33, "training_loss": 11174.222274780273, "training_acc": 52.333333333333336, "val_loss": 4942.674751281738, "val_acc": 72.0}
{"epoch": 34, "training_loss": 14842.365158081055, "training_acc": 72.33333333333333, "val_loss": 1333.4973773956299, "val_acc": 28.0}
{"epoch": 35, "training_loss": 3872.132402420044, "training_acc": 52.0, "val_loss": 593.899890422821, "val_acc": 28.0}
{"epoch": 36, "training_loss": 2743.9043502807617, "training_acc": 55.666666666666664, "val_loss": 58.56029760837555, "val_acc": 73.33333333333333}
{"epoch": 37, "training_loss": 1307.0279121398926, "training_acc": 62.666666666666664, "val_loss": 826.3967046737671, "val_acc": 72.0}
{"epoch": 38, "training_loss": 2114.6532258987427, "training_acc": 63.0, "val_loss": 646.6868658065796, "val_acc": 28.0}
{"epoch": 39, "training_loss": 3395.6509799957275, "training_acc": 60.333333333333336, "val_loss": 2082.316785812378, "val_acc": 28.0}
{"epoch": 40, "training_loss": 6843.31819152832, "training_acc": 55.0, "val_loss": 2148.6248474121094, "val_acc": 72.0}
{"epoch": 41, "training_loss": 7447.822906494141, "training_acc": 57.0, "val_loss": 147.79370141029358, "val_acc": 30.666666666666668}
{"epoch": 42, "training_loss": 12258.451049804688, "training_acc": 64.0, "val_loss": 4671.596809387207, "val_acc": 72.0}
{"epoch": 43, "training_loss": 12017.998641967773, "training_acc": 65.66666666666667, "val_loss": 3497.1897888183594, "val_acc": 28.0}
{"epoch": 44, "training_loss": 10236.50015258789, "training_acc": 52.333333333333336, "val_loss": 4194.32470703125, "val_acc": 72.0}
{"epoch": 45, "training_loss": 11652.382117271423, "training_acc": 72.33333333333333, "val_loss": 4045.8496475219727, "val_acc": 28.0}
{"epoch": 46, "training_loss": 12799.610122680664, "training_acc": 41.666666666666664, "val_loss": 3473.3726081848145, "val_acc": 72.0}
{"epoch": 47, "training_loss": 11790.684997558594, "training_acc": 72.33333333333333, "val_loss": 361.2998585700989, "val_acc": 28.0}
{"epoch": 48, "training_loss": 2717.34171295166, "training_acc": 57.666666666666664, "val_loss": 659.7174243927002, "val_acc": 72.0}
{"epoch": 49, "training_loss": 2052.7353324890137, "training_acc": 53.333333333333336, "val_loss": 794.4619445800781, "val_acc": 72.0}
{"epoch": 50, "training_loss": 3566.1549224853516, "training_acc": 66.33333333333333, "val_loss": 142.2749091386795, "val_acc": 34.666666666666664}
{"epoch": 51, "training_loss": 5804.072937011719, "training_acc": 64.66666666666667, "val_loss": 961.962610244751, "val_acc": 72.0}
{"epoch": 52, "training_loss": 3597.825355529785, "training_acc": 55.0, "val_loss": 2340.9241981506348, "val_acc": 72.0}
{"epoch": 53, "training_loss": 7136.768371582031, "training_acc": 65.0, "val_loss": 3331.0496940612793, "val_acc": 28.0}
{"epoch": 54, "training_loss": 4882.465042114258, "training_acc": 61.0, "val_loss": 476.47220849990845, "val_acc": 28.0}
{"epoch": 55, "training_loss": 1936.743881225586, "training_acc": 59.666666666666664, "val_loss": 216.43398916721344, "val_acc": 28.0}
