"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 300 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 20466.452617645264, "training_acc": 55.666666666666664, "val_loss": 5241.9450607299805, "val_acc": 28.0}
{"epoch": 1, "training_loss": 14437.268173217773, "training_acc": 60.333333333333336, "val_loss": 2545.4465370178223, "val_acc": 72.0}
{"epoch": 2, "training_loss": 8523.848096847534, "training_acc": 54.333333333333336, "val_loss": 1271.314640045166, "val_acc": 72.0}
{"epoch": 3, "training_loss": 4780.515213012695, "training_acc": 69.0, "val_loss": 2090.6972103118896, "val_acc": 28.0}
{"epoch": 4, "training_loss": 5824.843921661377, "training_acc": 64.33333333333333, "val_loss": 325.400728225708, "val_acc": 72.0}
{"epoch": 5, "training_loss": 5892.558242797852, "training_acc": 53.666666666666664, "val_loss": 2085.250087738037, "val_acc": 72.0}
{"epoch": 6, "training_loss": 4452.530767917633, "training_acc": 57.0, "val_loss": 1220.8717937469482, "val_acc": 72.0}
{"epoch": 7, "training_loss": 6605.277732849121, "training_acc": 72.33333333333333, "val_loss": 1458.3363189697266, "val_acc": 28.0}
{"epoch": 8, "training_loss": 4755.245506286621, "training_acc": 53.666666666666664, "val_loss": 781.2288980484009, "val_acc": 72.0}
{"epoch": 9, "training_loss": 1664.4354584217072, "training_acc": 63.0, "val_loss": 1164.0506381988525, "val_acc": 28.0}
{"epoch": 10, "training_loss": 3215.570050239563, "training_acc": 59.666666666666664, "val_loss": 2513.9339561462402, "val_acc": 28.0}
{"epoch": 11, "training_loss": 7659.028625488281, "training_acc": 52.333333333333336, "val_loss": 2506.8331985473633, "val_acc": 72.0}
{"epoch": 12, "training_loss": 8250.289138793945, "training_acc": 54.333333333333336, "val_loss": 399.10218238830566, "val_acc": 72.0}
{"epoch": 13, "training_loss": 3218.724937438965, "training_acc": 72.33333333333333, "val_loss": 2586.173858642578, "val_acc": 28.0}
{"epoch": 14, "training_loss": 7673.665618896484, "training_acc": 51.666666666666664, "val_loss": 1574.0764198303223, "val_acc": 72.0}
{"epoch": 15, "training_loss": 4960.119998931885, "training_acc": 54.333333333333336, "val_loss": 1802.433240890503, "val_acc": 72.0}
{"epoch": 16, "training_loss": 5952.5437932014465, "training_acc": 72.33333333333333, "val_loss": 3813.287010192871, "val_acc": 28.0}
{"epoch": 17, "training_loss": 10196.033027648926, "training_acc": 46.333333333333336, "val_loss": 4527.2319412231445, "val_acc": 72.0}
{"epoch": 18, "training_loss": 18448.23878479004, "training_acc": 72.33333333333333, "val_loss": 2178.4669342041016, "val_acc": 72.0}
{"epoch": 19, "training_loss": 12463.945236206055, "training_acc": 48.333333333333336, "val_loss": 500.3095598220825, "val_acc": 72.0}
{"epoch": 20, "training_loss": 7553.235061645508, "training_acc": 72.33333333333333, "val_loss": 1350.2707061767578, "val_acc": 72.0}
{"epoch": 21, "training_loss": 2469.3790130615234, "training_acc": 51.0, "val_loss": 1331.841199874878, "val_acc": 72.0}
{"epoch": 22, "training_loss": 4176.134046554565, "training_acc": 55.0, "val_loss": 1421.957721710205, "val_acc": 72.0}
{"epoch": 23, "training_loss": 8292.021911621094, "training_acc": 72.33333333333333, "val_loss": 435.4217224121094, "val_acc": 72.0}
