"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 300 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 18369.226989746094, "training_acc": 54.666666666666664, "val_loss": 1426.8179321289062, "val_acc": 26.666666666666668}
{"epoch": 1, "training_loss": 13559.476501464844, "training_acc": 64.0, "val_loss": 3387.3445014953613, "val_acc": 73.33333333333333}
{"epoch": 2, "training_loss": 7554.857482910156, "training_acc": 54.0, "val_loss": 1866.9611206054688, "val_acc": 73.33333333333333}
{"epoch": 3, "training_loss": 5618.306503295898, "training_acc": 59.333333333333336, "val_loss": 211.86933588981628, "val_acc": 73.33333333333333}
{"epoch": 4, "training_loss": 3225.012638092041, "training_acc": 60.666666666666664, "val_loss": 160.62183451652527, "val_acc": 26.666666666666668}
{"epoch": 5, "training_loss": 1979.407844543457, "training_acc": 49.333333333333336, "val_loss": 788.5094747543335, "val_acc": 73.33333333333333}
{"epoch": 6, "training_loss": 4707.56880569458, "training_acc": 49.333333333333336, "val_loss": 2301.111463546753, "val_acc": 73.33333333333333}
{"epoch": 7, "training_loss": 9595.431045532227, "training_acc": 72.0, "val_loss": 415.39850187301636, "val_acc": 26.666666666666668}
{"epoch": 8, "training_loss": 4469.966819763184, "training_acc": 50.666666666666664, "val_loss": 1365.7214078903198, "val_acc": 73.33333333333333}
{"epoch": 9, "training_loss": 4377.887369155884, "training_acc": 57.333333333333336, "val_loss": 1308.5402240753174, "val_acc": 73.33333333333333}
{"epoch": 10, "training_loss": 5337.509460449219, "training_acc": 64.66666666666667, "val_loss": 2121.2631969451904, "val_acc": 26.666666666666668}
{"epoch": 11, "training_loss": 7162.244415283203, "training_acc": 61.333333333333336, "val_loss": 1000.0421600341797, "val_acc": 73.33333333333333}
{"epoch": 12, "training_loss": 4808.246635437012, "training_acc": 50.0, "val_loss": 2058.4112453460693, "val_acc": 73.33333333333333}
{"epoch": 13, "training_loss": 4914.964141845703, "training_acc": 57.0, "val_loss": 691.3860669136047, "val_acc": 73.33333333333333}
{"epoch": 14, "training_loss": 3713.753349304199, "training_acc": 66.66666666666667, "val_loss": 872.609260559082, "val_acc": 26.666666666666668}
{"epoch": 15, "training_loss": 9621.904434204102, "training_acc": 59.333333333333336, "val_loss": 2125.874620437622, "val_acc": 73.33333333333333}
{"epoch": 16, "training_loss": 5436.475257873535, "training_acc": 55.333333333333336, "val_loss": 959.9583606719971, "val_acc": 73.33333333333333}
{"epoch": 17, "training_loss": 2823.9392881393433, "training_acc": 64.0, "val_loss": 100.99399399757385, "val_acc": 73.33333333333333}
{"epoch": 18, "training_loss": 2109.5714733600616, "training_acc": 59.333333333333336, "val_loss": 1527.7617235183716, "val_acc": 26.666666666666668}
{"epoch": 19, "training_loss": 3134.298355102539, "training_acc": 54.0, "val_loss": 60.154386937618256, "val_acc": 38.666666666666664}
{"epoch": 20, "training_loss": 4113.140836715698, "training_acc": 67.0, "val_loss": 180.92067122459412, "val_acc": 26.666666666666668}
{"epoch": 21, "training_loss": 2492.266502380371, "training_acc": 51.333333333333336, "val_loss": 1553.2598304748535, "val_acc": 73.33333333333333}
{"epoch": 22, "training_loss": 6248.602355957031, "training_acc": 56.666666666666664, "val_loss": 302.0629053115845, "val_acc": 73.33333333333333}
{"epoch": 23, "training_loss": 2750.208625793457, "training_acc": 66.0, "val_loss": 302.7365221977234, "val_acc": 73.33333333333333}
{"epoch": 24, "training_loss": 2335.4083938598633, "training_acc": 58.666666666666664, "val_loss": 330.34179639816284, "val_acc": 73.33333333333333}
{"epoch": 25, "training_loss": 2843.340057373047, "training_acc": 60.666666666666664, "val_loss": 1195.1716842651367, "val_acc": 26.666666666666668}
{"epoch": 26, "training_loss": 1594.4643247127533, "training_acc": 54.666666666666664, "val_loss": 541.7014122009277, "val_acc": 73.33333333333333}
{"epoch": 27, "training_loss": 2367.2839756011963, "training_acc": 64.66666666666667, "val_loss": 223.48885345458984, "val_acc": 73.33333333333333}
{"epoch": 28, "training_loss": 2625.7822799682617, "training_acc": 62.666666666666664, "val_loss": 136.213698387146, "val_acc": 73.33333333333333}
{"epoch": 29, "training_loss": 5419.702049255371, "training_acc": 53.333333333333336, "val_loss": 1882.1665573120117, "val_acc": 73.33333333333333}
{"epoch": 30, "training_loss": 6430.05952835083, "training_acc": 51.333333333333336, "val_loss": 1182.2866592407227, "val_acc": 73.33333333333333}
{"epoch": 31, "training_loss": 8201.759010314941, "training_acc": 72.0, "val_loss": 532.4504880905151, "val_acc": 73.33333333333333}
{"epoch": 32, "training_loss": 5279.473922729492, "training_acc": 52.666666666666664, "val_loss": 811.6869125366211, "val_acc": 73.33333333333333}
{"epoch": 33, "training_loss": 3787.68367767334, "training_acc": 53.333333333333336, "val_loss": 2288.575927734375, "val_acc": 73.33333333333333}
{"epoch": 34, "training_loss": 9677.47342300415, "training_acc": 72.0, "val_loss": 877.2394037246704, "val_acc": 26.666666666666668}
{"epoch": 35, "training_loss": 5072.874717712402, "training_acc": 52.0, "val_loss": 1544.7561016082764, "val_acc": 73.33333333333333}
{"epoch": 36, "training_loss": 3961.998561859131, "training_acc": 55.333333333333336, "val_loss": 1703.254716873169, "val_acc": 73.33333333333333}
{"epoch": 37, "training_loss": 5831.4416217803955, "training_acc": 69.33333333333333, "val_loss": 1009.5794706344604, "val_acc": 26.666666666666668}
{"epoch": 38, "training_loss": 2969.1215057373047, "training_acc": 64.66666666666667, "val_loss": 2326.8404273986816, "val_acc": 26.666666666666668}
