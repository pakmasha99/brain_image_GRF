"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 300 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 2431.6548652648926, "training_acc": 68.33333333333333, "val_loss": 482.2118673324585, "val_acc": 28.0}
{"epoch": 1, "training_loss": 1808.5986347198486, "training_acc": 62.333333333333336, "val_loss": 322.8708608150482, "val_acc": 72.0}
{"epoch": 2, "training_loss": 1499.2940554618835, "training_acc": 45.0, "val_loss": 306.0974178314209, "val_acc": 72.0}
{"epoch": 3, "training_loss": 2199.572576522827, "training_acc": 72.33333333333333, "val_loss": 533.6853756904602, "val_acc": 72.0}
{"epoch": 4, "training_loss": 1149.484302520752, "training_acc": 61.0, "val_loss": 55.850624084472656, "val_acc": 28.0}
{"epoch": 5, "training_loss": 714.4849967956543, "training_acc": 61.666666666666664, "val_loss": 62.66406100988388, "val_acc": 72.0}
{"epoch": 6, "training_loss": 694.0516033172607, "training_acc": 51.666666666666664, "val_loss": 278.25969290731916, "val_acc": 72.0}
{"epoch": 7, "training_loss": 729.2019424438477, "training_acc": 65.66666666666667, "val_loss": 120.06577408313751, "val_acc": 28.0}
{"epoch": 8, "training_loss": 1110.9339504241943, "training_acc": 60.333333333333336, "val_loss": 245.47647714614868, "val_acc": 72.0}
{"epoch": 9, "training_loss": 964.724862575531, "training_acc": 51.0, "val_loss": 151.37731742858887, "val_acc": 72.0}
{"epoch": 10, "training_loss": 581.0901622772217, "training_acc": 67.0, "val_loss": 149.86864495277405, "val_acc": 28.0}
{"epoch": 11, "training_loss": 756.6113958358765, "training_acc": 65.0, "val_loss": 114.50941205024719, "val_acc": 72.0}
{"epoch": 12, "training_loss": 332.8011064529419, "training_acc": 58.333333333333336, "val_loss": 85.209392786026, "val_acc": 72.0}
{"epoch": 13, "training_loss": 303.40158462524414, "training_acc": 61.666666666666664, "val_loss": 44.05285578966141, "val_acc": 72.0}
{"epoch": 14, "training_loss": 244.56284642219543, "training_acc": 61.666666666666664, "val_loss": 143.25128889083862, "val_acc": 28.0}
{"epoch": 15, "training_loss": 415.16501092910767, "training_acc": 53.0, "val_loss": 46.81150680780411, "val_acc": 72.0}
{"epoch": 16, "training_loss": 260.8000576496124, "training_acc": 62.333333333333336, "val_loss": 49.95583534240723, "val_acc": 72.0}
{"epoch": 17, "training_loss": 183.42767786979675, "training_acc": 72.33333333333333, "val_loss": 43.718924552202225, "val_acc": 72.0}
{"epoch": 18, "training_loss": 194.77522683143616, "training_acc": 70.66666666666667, "val_loss": 52.615866243839264, "val_acc": 72.0}
{"epoch": 19, "training_loss": 309.3676438331604, "training_acc": 60.333333333333336, "val_loss": 83.36662685871124, "val_acc": 72.0}
{"epoch": 20, "training_loss": 272.73637557029724, "training_acc": 60.333333333333336, "val_loss": 48.94928365945816, "val_acc": 28.0}
{"epoch": 21, "training_loss": 194.64534950256348, "training_acc": 72.0, "val_loss": 45.484672367572784, "val_acc": 45.333333333333336}
{"epoch": 22, "training_loss": 180.30757117271423, "training_acc": 72.33333333333333, "val_loss": 59.26030761003494, "val_acc": 28.0}
{"epoch": 23, "training_loss": 195.7716748714447, "training_acc": 65.66666666666667, "val_loss": 45.56847757101059, "val_acc": 44.0}
{"epoch": 24, "training_loss": 192.42260766029358, "training_acc": 70.33333333333333, "val_loss": 46.8696046769619, "val_acc": 72.0}
{"epoch": 25, "training_loss": 193.3357813358307, "training_acc": 72.66666666666667, "val_loss": 44.00365072488785, "val_acc": 73.33333333333333}
{"epoch": 26, "training_loss": 178.22673797607422, "training_acc": 72.33333333333333, "val_loss": 46.882170140743256, "val_acc": 72.0}
{"epoch": 27, "training_loss": 210.53907537460327, "training_acc": 56.333333333333336, "val_loss": 54.44436699897051, "val_acc": 72.0}
{"epoch": 28, "training_loss": 201.743989944458, "training_acc": 72.66666666666667, "val_loss": 67.9576758146286, "val_acc": 72.0}
{"epoch": 29, "training_loss": 226.64338421821594, "training_acc": 65.0, "val_loss": 47.52313840389252, "val_acc": 29.333333333333332}
{"epoch": 30, "training_loss": 277.3715019226074, "training_acc": 62.0, "val_loss": 110.71433022618294, "val_acc": 72.0}
{"epoch": 31, "training_loss": 364.33442640304565, "training_acc": 61.0, "val_loss": 65.27187490463257, "val_acc": 28.0}
{"epoch": 32, "training_loss": 208.00461530685425, "training_acc": 59.333333333333336, "val_loss": 67.6666288971901, "val_acc": 72.0}
{"epoch": 33, "training_loss": 211.08765649795532, "training_acc": 71.0, "val_loss": 70.94269382953644, "val_acc": 28.0}
{"epoch": 34, "training_loss": 354.5953826904297, "training_acc": 49.0, "val_loss": 173.87256288528442, "val_acc": 72.0}
{"epoch": 35, "training_loss": 599.8924641609192, "training_acc": 56.333333333333336, "val_loss": 221.24943459033966, "val_acc": 72.0}
{"epoch": 36, "training_loss": 1363.2682209014893, "training_acc": 72.33333333333333, "val_loss": 69.55732744932175, "val_acc": 72.0}
