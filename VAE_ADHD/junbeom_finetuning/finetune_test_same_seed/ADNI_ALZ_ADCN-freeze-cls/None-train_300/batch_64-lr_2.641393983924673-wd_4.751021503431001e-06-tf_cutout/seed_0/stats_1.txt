"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 300 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 62679.31198883057, "training_acc": 62.333333333333336, "val_loss": 32646.4501953125, "val_acc": 28.0}
{"epoch": 1, "training_loss": 85835.54089355469, "training_acc": 47.0, "val_loss": 27169.5771484375, "val_acc": 72.0}
{"epoch": 2, "training_loss": 96103.0396118164, "training_acc": 72.33333333333333, "val_loss": 10285.339416503906, "val_acc": 72.0}
{"epoch": 3, "training_loss": 52079.009216308594, "training_acc": 47.0, "val_loss": 1630.3515338897705, "val_acc": 28.0}
{"epoch": 4, "training_loss": 50625.16650390625, "training_acc": 61.666666666666664, "val_loss": 22195.574310302734, "val_acc": 72.0}
{"epoch": 5, "training_loss": 73139.76473999023, "training_acc": 72.33333333333333, "val_loss": 4614.987609863281, "val_acc": 72.0}
{"epoch": 6, "training_loss": 27288.328384399414, "training_acc": 41.0, "val_loss": 6774.487060546875, "val_acc": 72.0}
{"epoch": 7, "training_loss": 31738.188919067383, "training_acc": 72.33333333333333, "val_loss": 1416.8959197998047, "val_acc": 72.0}
{"epoch": 8, "training_loss": 20345.87469482422, "training_acc": 45.0, "val_loss": 10960.71656036377, "val_acc": 72.0}
{"epoch": 9, "training_loss": 55641.32635498047, "training_acc": 72.33333333333333, "val_loss": 9834.690464019775, "val_acc": 72.0}
{"epoch": 10, "training_loss": 15616.368629455566, "training_acc": 55.666666666666664, "val_loss": 2477.683059692383, "val_acc": 72.0}
{"epoch": 11, "training_loss": 5592.895130157471, "training_acc": 63.666666666666664, "val_loss": 1195.9498271942139, "val_acc": 28.0}
{"epoch": 12, "training_loss": 7321.197662353516, "training_acc": 57.666666666666664, "val_loss": 905.3121643066406, "val_acc": 72.0}
{"epoch": 13, "training_loss": 4593.5871658325195, "training_acc": 66.33333333333333, "val_loss": 2074.6473655700684, "val_acc": 72.0}
{"epoch": 14, "training_loss": 11578.499105453491, "training_acc": 53.666666666666664, "val_loss": 7621.662551879883, "val_acc": 72.0}
{"epoch": 15, "training_loss": 28883.402587890625, "training_acc": 72.33333333333333, "val_loss": 1557.4169330596924, "val_acc": 28.0}
{"epoch": 16, "training_loss": 15019.042175292969, "training_acc": 51.0, "val_loss": 5274.358299255371, "val_acc": 72.0}
{"epoch": 17, "training_loss": 12942.873962402344, "training_acc": 49.666666666666664, "val_loss": 6312.150032043457, "val_acc": 72.0}
{"epoch": 18, "training_loss": 19535.3083486557, "training_acc": 72.33333333333333, "val_loss": 11526.161392211914, "val_acc": 28.0}
{"epoch": 19, "training_loss": 36996.14697265625, "training_acc": 41.0, "val_loss": 13168.148712158203, "val_acc": 72.0}
{"epoch": 20, "training_loss": 48060.89123535156, "training_acc": 72.33333333333333, "val_loss": 3542.2107696533203, "val_acc": 72.0}
{"epoch": 21, "training_loss": 11544.181816101074, "training_acc": 57.666666666666664, "val_loss": 1190.6393270492554, "val_acc": 72.0}
{"epoch": 22, "training_loss": 5711.6130294799805, "training_acc": 64.33333333333333, "val_loss": 1735.436113357544, "val_acc": 28.0}
{"epoch": 23, "training_loss": 7239.601379394531, "training_acc": 55.666666666666664, "val_loss": 2019.7008152008057, "val_acc": 28.0}
{"epoch": 24, "training_loss": 23660.10678100586, "training_acc": 63.0, "val_loss": 6918.06978225708, "val_acc": 72.0}
{"epoch": 25, "training_loss": 16289.353332519531, "training_acc": 51.0, "val_loss": 4782.956676483154, "val_acc": 72.0}
{"epoch": 26, "training_loss": 16968.120208740234, "training_acc": 63.666666666666664, "val_loss": 3883.497829437256, "val_acc": 28.0}
{"epoch": 27, "training_loss": 19324.07305908203, "training_acc": 63.666666666666664, "val_loss": 4062.504081726074, "val_acc": 72.0}
{"epoch": 28, "training_loss": 21927.156929016113, "training_acc": 47.666666666666664, "val_loss": 6419.105125427246, "val_acc": 72.0}
{"epoch": 29, "training_loss": 47198.935791015625, "training_acc": 72.33333333333333, "val_loss": 13162.061172485352, "val_acc": 72.0}
{"epoch": 30, "training_loss": 34877.56994628906, "training_acc": 65.0, "val_loss": 18360.8663482666, "val_acc": 28.0}
{"epoch": 31, "training_loss": 33589.767349243164, "training_acc": 54.333333333333336, "val_loss": 7191.526008605957, "val_acc": 72.0}
