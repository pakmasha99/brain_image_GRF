"main_optuna.py --pretrained_path None --mode finetuning --train_num 300 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc --eval_mode False"
{"epoch": 0, "training_loss": 297.4730429649353, "training_acc": 54.666666666666664, "val_loss": 71.01146030426025, "val_acc": 26.666666666666668}
{"epoch": 1, "training_loss": 222.25268578529358, "training_acc": 64.0, "val_loss": 51.509673058986664, "val_acc": 73.33333333333333}
{"epoch": 2, "training_loss": 195.69660234451294, "training_acc": 72.0, "val_loss": 43.7433962225914, "val_acc": 73.33333333333333}
{"epoch": 3, "training_loss": 180.3536355495453, "training_acc": 72.0, "val_loss": 43.42832392454147, "val_acc": 73.33333333333333}
{"epoch": 4, "training_loss": 177.65422940254211, "training_acc": 72.0, "val_loss": 45.149201691150665, "val_acc": 73.33333333333333}
{"epoch": 5, "training_loss": 182.99887537956238, "training_acc": 72.0, "val_loss": 43.436150908470154, "val_acc": 73.33333333333333}
{"epoch": 6, "training_loss": 188.184734582901, "training_acc": 72.0, "val_loss": 48.28965237736702, "val_acc": 73.33333333333333}
{"epoch": 7, "training_loss": 193.22606468200684, "training_acc": 72.0, "val_loss": 47.00878423452377, "val_acc": 26.666666666666668}
{"epoch": 8, "training_loss": 188.2414288520813, "training_acc": 72.0, "val_loss": 43.41151660680771, "val_acc": 73.33333333333333}
{"epoch": 9, "training_loss": 180.06428265571594, "training_acc": 72.0, "val_loss": 43.658162623643875, "val_acc": 73.33333333333333}
{"epoch": 10, "training_loss": 182.6637077331543, "training_acc": 72.0, "val_loss": 43.72938150167465, "val_acc": 73.33333333333333}
{"epoch": 11, "training_loss": 182.17585563659668, "training_acc": 72.0, "val_loss": 45.821425676345825, "val_acc": 26.666666666666668}
{"epoch": 12, "training_loss": 198.77037858963013, "training_acc": 60.666666666666664, "val_loss": 51.226148039102554, "val_acc": 73.33333333333333}
{"epoch": 13, "training_loss": 195.21158027648926, "training_acc": 65.66666666666667, "val_loss": 43.6196414232254, "val_acc": 73.33333333333333}
{"epoch": 14, "training_loss": 183.6939241886139, "training_acc": 72.0, "val_loss": 43.638688653707504, "val_acc": 73.33333333333333}
{"epoch": 15, "training_loss": 183.20823311805725, "training_acc": 72.0, "val_loss": 45.03100150823593, "val_acc": 80.0}
{"epoch": 16, "training_loss": 179.37955403327942, "training_acc": 72.0, "val_loss": 44.49188822507858, "val_acc": 73.33333333333333}
{"epoch": 17, "training_loss": 179.33990621566772, "training_acc": 72.0, "val_loss": 44.08582717180252, "val_acc": 73.33333333333333}
{"epoch": 18, "training_loss": 180.5595989227295, "training_acc": 72.0, "val_loss": 43.015310406684875, "val_acc": 73.33333333333333}
{"epoch": 19, "training_loss": 179.37016010284424, "training_acc": 72.0, "val_loss": 48.45444142818451, "val_acc": 26.666666666666668}
{"epoch": 20, "training_loss": 186.58635985851288, "training_acc": 72.0, "val_loss": 43.80638784170151, "val_acc": 73.33333333333333}
{"epoch": 21, "training_loss": 189.34459328651428, "training_acc": 72.0, "val_loss": 45.65490359067917, "val_acc": 73.33333333333333}
{"epoch": 22, "training_loss": 182.972318649292, "training_acc": 72.0, "val_loss": 44.06430673599243, "val_acc": 73.33333333333333}
