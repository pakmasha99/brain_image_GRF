"main_optuna.py --pretrained_path None --mode finetuning --train_num 300 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc --eval_mode False"
{"epoch": 0, "training_loss": 290.826771736145, "training_acc": 54.666666666666664, "val_loss": 69.99495333433151, "val_acc": 26.666666666666668}
{"epoch": 1, "training_loss": 219.98697876930237, "training_acc": 64.0, "val_loss": 51.46876347064972, "val_acc": 73.33333333333333}
{"epoch": 2, "training_loss": 194.75410056114197, "training_acc": 72.0, "val_loss": 43.96493208408356, "val_acc": 73.33333333333333}
{"epoch": 3, "training_loss": 179.75888895988464, "training_acc": 72.0, "val_loss": 43.48207753896713, "val_acc": 73.33333333333333}
{"epoch": 4, "training_loss": 177.3654317855835, "training_acc": 72.0, "val_loss": 45.220108687877655, "val_acc": 73.33333333333333}
{"epoch": 5, "training_loss": 182.95480370521545, "training_acc": 72.0, "val_loss": 43.42202925682068, "val_acc": 73.33333333333333}
{"epoch": 6, "training_loss": 188.24582958221436, "training_acc": 72.0, "val_loss": 48.216011852025986, "val_acc": 73.33333333333333}
{"epoch": 7, "training_loss": 193.17123532295227, "training_acc": 72.0, "val_loss": 47.16196966171265, "val_acc": 26.666666666666668}
{"epoch": 8, "training_loss": 188.0303771495819, "training_acc": 72.0, "val_loss": 43.332858979701996, "val_acc": 73.33333333333333}
{"epoch": 9, "training_loss": 180.26036620140076, "training_acc": 72.0, "val_loss": 43.56601855158806, "val_acc": 73.33333333333333}
{"epoch": 10, "training_loss": 182.5101134777069, "training_acc": 72.0, "val_loss": 43.795604169368744, "val_acc": 73.33333333333333}
{"epoch": 11, "training_loss": 182.26887035369873, "training_acc": 72.0, "val_loss": 45.27647399902344, "val_acc": 64.0}
{"epoch": 12, "training_loss": 197.36758399009705, "training_acc": 60.666666666666664, "val_loss": 50.72584870457649, "val_acc": 73.33333333333333}
{"epoch": 13, "training_loss": 194.24830222129822, "training_acc": 65.66666666666667, "val_loss": 43.97147572040558, "val_acc": 73.33333333333333}
{"epoch": 14, "training_loss": 183.12092399597168, "training_acc": 72.0, "val_loss": 43.36018434166908, "val_acc": 73.33333333333333}
{"epoch": 15, "training_loss": 181.4464693069458, "training_acc": 72.0, "val_loss": 44.982717514038086, "val_acc": 78.66666666666667}
{"epoch": 16, "training_loss": 179.07860255241394, "training_acc": 72.0, "val_loss": 44.18563687801361, "val_acc": 73.33333333333333}
{"epoch": 17, "training_loss": 178.81011724472046, "training_acc": 72.0, "val_loss": 44.04970559477806, "val_acc": 73.33333333333333}
{"epoch": 18, "training_loss": 180.2795000076294, "training_acc": 72.0, "val_loss": 42.99381494522095, "val_acc": 73.33333333333333}
{"epoch": 19, "training_loss": 179.09240341186523, "training_acc": 72.0, "val_loss": 48.510125160217285, "val_acc": 26.666666666666668}
{"epoch": 20, "training_loss": 186.53764939308167, "training_acc": 72.0, "val_loss": 43.85695844888687, "val_acc": 73.33333333333333}
{"epoch": 21, "training_loss": 189.24244022369385, "training_acc": 72.0, "val_loss": 45.5047532916069, "val_acc": 73.33333333333333}
{"epoch": 22, "training_loss": 182.81009030342102, "training_acc": 72.0, "val_loss": 44.32231855392456, "val_acc": 74.66666666666667}
