"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 300 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 425.40462493896484, "training_acc": 53.666666666666664, "val_loss": 78.41372776031494, "val_acc": 28.0}
{"epoch": 1, "training_loss": 274.4728350639343, "training_acc": 60.333333333333336, "val_loss": 47.1317338347435, "val_acc": 72.0}
{"epoch": 2, "training_loss": 201.10374641418457, "training_acc": 61.0, "val_loss": 51.02451801300049, "val_acc": 72.0}
{"epoch": 3, "training_loss": 199.50347805023193, "training_acc": 72.33333333333333, "val_loss": 46.79806309938431, "val_acc": 28.0}
{"epoch": 4, "training_loss": 197.11053466796875, "training_acc": 72.33333333333333, "val_loss": 45.124156296253204, "val_acc": 72.0}
{"epoch": 5, "training_loss": 187.0955240726471, "training_acc": 72.33333333333333, "val_loss": 51.34941506385803, "val_acc": 72.0}
{"epoch": 6, "training_loss": 187.99399304389954, "training_acc": 72.33333333333333, "val_loss": 51.32051342725754, "val_acc": 28.0}
{"epoch": 7, "training_loss": 199.4111452102661, "training_acc": 72.33333333333333, "val_loss": 44.472092628479004, "val_acc": 72.0}
{"epoch": 8, "training_loss": 188.42619681358337, "training_acc": 72.66666666666667, "val_loss": 50.92520785331726, "val_acc": 72.0}
{"epoch": 9, "training_loss": 186.74252009391785, "training_acc": 72.33333333333333, "val_loss": 49.41461765766144, "val_acc": 28.0}
{"epoch": 10, "training_loss": 194.8804943561554, "training_acc": 72.33333333333333, "val_loss": 44.78724151849747, "val_acc": 72.0}
{"epoch": 11, "training_loss": 176.67040061950684, "training_acc": 72.33333333333333, "val_loss": 47.45627996325493, "val_acc": 72.0}
{"epoch": 12, "training_loss": 183.5801899433136, "training_acc": 72.33333333333333, "val_loss": 44.398442566394806, "val_acc": 72.0}
{"epoch": 13, "training_loss": 183.6555576324463, "training_acc": 72.33333333333333, "val_loss": 45.04254603385925, "val_acc": 72.0}
{"epoch": 14, "training_loss": 175.64169478416443, "training_acc": 72.33333333333333, "val_loss": 45.474312245845795, "val_acc": 72.0}
{"epoch": 15, "training_loss": 176.1496295928955, "training_acc": 72.33333333333333, "val_loss": 47.10785657167435, "val_acc": 28.0}
{"epoch": 16, "training_loss": 178.89840006828308, "training_acc": 72.33333333333333, "val_loss": 45.57312208414078, "val_acc": 72.0}
{"epoch": 17, "training_loss": 179.93624567985535, "training_acc": 72.33333333333333, "val_loss": 44.81444802880287, "val_acc": 72.0}
{"epoch": 18, "training_loss": 178.1221354007721, "training_acc": 72.33333333333333, "val_loss": 44.41303014755249, "val_acc": 72.0}
{"epoch": 19, "training_loss": 176.4478988647461, "training_acc": 72.33333333333333, "val_loss": 44.72926253080368, "val_acc": 72.0}
{"epoch": 20, "training_loss": 187.11489725112915, "training_acc": 62.666666666666664, "val_loss": 59.08216202259064, "val_acc": 72.0}
{"epoch": 21, "training_loss": 211.23485207557678, "training_acc": 63.666666666666664, "val_loss": 45.92351654171944, "val_acc": 72.0}
{"epoch": 22, "training_loss": 201.85064911842346, "training_acc": 66.66666666666667, "val_loss": 45.990591049194336, "val_acc": 46.666666666666664}
{"epoch": 23, "training_loss": 189.08808207511902, "training_acc": 72.33333333333333, "val_loss": 49.98484122753143, "val_acc": 28.0}
{"epoch": 24, "training_loss": 185.60822534561157, "training_acc": 72.33333333333333, "val_loss": 44.486811876297, "val_acc": 72.0}
{"epoch": 25, "training_loss": 193.43362092971802, "training_acc": 73.0, "val_loss": 50.53560650348663, "val_acc": 72.0}
{"epoch": 26, "training_loss": 194.5013551712036, "training_acc": 63.666666666666664, "val_loss": 53.712837874889374, "val_acc": 72.0}
{"epoch": 27, "training_loss": 234.9465787410736, "training_acc": 72.33333333333333, "val_loss": 73.63195806741714, "val_acc": 28.0}
{"epoch": 28, "training_loss": 233.07834315299988, "training_acc": 55.0, "val_loss": 59.289021015167236, "val_acc": 72.0}
{"epoch": 29, "training_loss": 185.94564175605774, "training_acc": 64.66666666666667, "val_loss": 45.41972464323044, "val_acc": 72.0}
{"epoch": 30, "training_loss": 213.2156698703766, "training_acc": 72.33333333333333, "val_loss": 68.22442638874054, "val_acc": 28.0}
{"epoch": 31, "training_loss": 198.64627277851105, "training_acc": 62.333333333333336, "val_loss": 50.70612406730652, "val_acc": 72.0}
