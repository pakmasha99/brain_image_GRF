"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 300 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 66618.22053527832, "training_acc": 53.666666666666664, "val_loss": 8827.068656921387, "val_acc": 28.0}
{"epoch": 1, "training_loss": 52840.09716796875, "training_acc": 61.0, "val_loss": 12901.452682495117, "val_acc": 72.0}
{"epoch": 2, "training_loss": 48690.053619384766, "training_acc": 57.0, "val_loss": 14156.72412109375, "val_acc": 28.0}
{"epoch": 3, "training_loss": 33909.71612548828, "training_acc": 61.666666666666664, "val_loss": 9060.544677734375, "val_acc": 72.0}
{"epoch": 4, "training_loss": 29172.09649658203, "training_acc": 58.333333333333336, "val_loss": 1003.6849193572998, "val_acc": 28.0}
{"epoch": 5, "training_loss": 46022.297912597656, "training_acc": 61.0, "val_loss": 17396.8263092041, "val_acc": 72.0}
{"epoch": 6, "training_loss": 42205.3593788147, "training_acc": 72.33333333333333, "val_loss": 17602.419509887695, "val_acc": 28.0}
{"epoch": 7, "training_loss": 51596.18299865723, "training_acc": 41.666666666666664, "val_loss": 6279.606826782227, "val_acc": 72.0}
{"epoch": 8, "training_loss": 17650.61296081543, "training_acc": 58.333333333333336, "val_loss": 1374.6178359985352, "val_acc": 72.0}
{"epoch": 9, "training_loss": 6348.189582824707, "training_acc": 63.666666666666664, "val_loss": 1012.8481845855713, "val_acc": 28.0}
{"epoch": 10, "training_loss": 7050.578598022461, "training_acc": 57.666666666666664, "val_loss": 593.9259595870972, "val_acc": 72.0}
{"epoch": 11, "training_loss": 5218.608505249023, "training_acc": 65.66666666666667, "val_loss": 2487.2451972961426, "val_acc": 72.0}
{"epoch": 12, "training_loss": 13930.251907348633, "training_acc": 55.666666666666664, "val_loss": 6286.815830230713, "val_acc": 72.0}
{"epoch": 13, "training_loss": 22238.71127319336, "training_acc": 72.33333333333333, "val_loss": 7941.064407348633, "val_acc": 28.0}
{"epoch": 14, "training_loss": 21201.38850402832, "training_acc": 50.333333333333336, "val_loss": 2132.60693359375, "val_acc": 72.0}
{"epoch": 15, "training_loss": 6082.343952178955, "training_acc": 55.666666666666664, "val_loss": 2834.614757537842, "val_acc": 72.0}
{"epoch": 16, "training_loss": 13759.476623535156, "training_acc": 64.33333333333333, "val_loss": 104.14274597167969, "val_acc": 72.0}
{"epoch": 17, "training_loss": 5501.762237548828, "training_acc": 63.0, "val_loss": 542.9840207099915, "val_acc": 72.0}
{"epoch": 18, "training_loss": 15930.844360351562, "training_acc": 52.333333333333336, "val_loss": 11042.956817626953, "val_acc": 72.0}
{"epoch": 19, "training_loss": 33035.29443359375, "training_acc": 72.33333333333333, "val_loss": 8474.510749816895, "val_acc": 28.0}
{"epoch": 20, "training_loss": 29506.977264404297, "training_acc": 44.333333333333336, "val_loss": 13068.733032226562, "val_acc": 72.0}
{"epoch": 21, "training_loss": 50044.328125, "training_acc": 72.33333333333333, "val_loss": 4016.866767883301, "val_acc": 72.0}
{"epoch": 22, "training_loss": 19579.197235107422, "training_acc": 45.0, "val_loss": 10949.0048828125, "val_acc": 72.0}
{"epoch": 23, "training_loss": 49827.94305419922, "training_acc": 72.33333333333333, "val_loss": 7230.951965332031, "val_acc": 72.0}
{"epoch": 24, "training_loss": 31638.34716796875, "training_acc": 43.0, "val_loss": 5318.159004211426, "val_acc": 72.0}
{"epoch": 25, "training_loss": 47638.76318359375, "training_acc": 72.33333333333333, "val_loss": 11890.570541381836, "val_acc": 72.0}
{"epoch": 26, "training_loss": 22180.6446685791, "training_acc": 60.333333333333336, "val_loss": 618.2147121429443, "val_acc": 72.0}
{"epoch": 27, "training_loss": 5478.211835861206, "training_acc": 63.666666666666664, "val_loss": 589.5405373573303, "val_acc": 72.0}
{"epoch": 28, "training_loss": 7766.590480804443, "training_acc": 62.333333333333336, "val_loss": 597.7999401092529, "val_acc": 28.0}
{"epoch": 29, "training_loss": 8366.380292892456, "training_acc": 61.0, "val_loss": 9596.36215209961, "val_acc": 28.0}
{"epoch": 30, "training_loss": 22448.47280883789, "training_acc": 53.666666666666664, "val_loss": 3033.6063957214355, "val_acc": 72.0}
{"epoch": 31, "training_loss": 16232.831619262695, "training_acc": 53.0, "val_loss": 5110.929824829102, "val_acc": 72.0}
{"epoch": 32, "training_loss": 19421.664355278015, "training_acc": 72.33333333333333, "val_loss": 12094.056457519531, "val_acc": 28.0}
{"epoch": 33, "training_loss": 34252.84069824219, "training_acc": 45.0, "val_loss": 15464.106231689453, "val_acc": 72.0}
{"epoch": 34, "training_loss": 62176.57067871094, "training_acc": 72.33333333333333, "val_loss": 7616.283935546875, "val_acc": 72.0}
{"epoch": 35, "training_loss": 47179.16375732422, "training_acc": 44.333333333333336, "val_loss": 1149.1794815063477, "val_acc": 72.0}
