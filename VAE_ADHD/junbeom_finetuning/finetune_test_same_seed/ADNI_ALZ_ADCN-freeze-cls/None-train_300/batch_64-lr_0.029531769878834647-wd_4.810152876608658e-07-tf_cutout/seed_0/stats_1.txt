"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 300 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 626.8021793365479, "training_acc": 65.66666666666667, "val_loss": 250.8105010986328, "val_acc": 28.0}
{"epoch": 1, "training_loss": 614.6152772903442, "training_acc": 63.666666666666664, "val_loss": 189.19756984710693, "val_acc": 72.0}
{"epoch": 2, "training_loss": 461.4874038696289, "training_acc": 67.66666666666667, "val_loss": 117.69326770305634, "val_acc": 28.0}
{"epoch": 3, "training_loss": 348.7616729736328, "training_acc": 65.0, "val_loss": 98.3213939666748, "val_acc": 72.0}
{"epoch": 4, "training_loss": 322.44066095352173, "training_acc": 44.333333333333336, "val_loss": 49.54142880439758, "val_acc": 72.0}
{"epoch": 5, "training_loss": 284.81631422042847, "training_acc": 72.33333333333333, "val_loss": 46.0054617524147, "val_acc": 57.333333333333336}
{"epoch": 6, "training_loss": 209.32945442199707, "training_acc": 59.666666666666664, "val_loss": 69.80530059337616, "val_acc": 72.0}
{"epoch": 7, "training_loss": 242.46527910232544, "training_acc": 65.33333333333333, "val_loss": 45.25816011428833, "val_acc": 72.0}
{"epoch": 8, "training_loss": 223.51123547554016, "training_acc": 72.33333333333333, "val_loss": 59.780231952667236, "val_acc": 28.0}
{"epoch": 9, "training_loss": 232.80493593215942, "training_acc": 51.0, "val_loss": 50.063782811164856, "val_acc": 72.0}
{"epoch": 10, "training_loss": 212.55594182014465, "training_acc": 50.333333333333336, "val_loss": 64.4473996758461, "val_acc": 72.0}
{"epoch": 11, "training_loss": 230.02330827713013, "training_acc": 67.0, "val_loss": 52.74775457382202, "val_acc": 28.0}
{"epoch": 12, "training_loss": 196.86975193023682, "training_acc": 65.66666666666667, "val_loss": 44.402984619140625, "val_acc": 72.0}
{"epoch": 13, "training_loss": 203.79063987731934, "training_acc": 61.666666666666664, "val_loss": 52.44346675276756, "val_acc": 72.0}
{"epoch": 14, "training_loss": 194.35799026489258, "training_acc": 72.33333333333333, "val_loss": 46.31044736504555, "val_acc": 72.0}
{"epoch": 15, "training_loss": 183.6769688129425, "training_acc": 72.33333333333333, "val_loss": 44.228115916252136, "val_acc": 72.0}
{"epoch": 16, "training_loss": 190.5402796268463, "training_acc": 72.33333333333333, "val_loss": 51.9047577381134, "val_acc": 28.0}
{"epoch": 17, "training_loss": 203.30570316314697, "training_acc": 69.0, "val_loss": 53.052695631980896, "val_acc": 28.0}
{"epoch": 18, "training_loss": 230.84628081321716, "training_acc": 46.666666666666664, "val_loss": 45.38057899475098, "val_acc": 74.66666666666667}
{"epoch": 19, "training_loss": 189.63643503189087, "training_acc": 72.33333333333333, "val_loss": 44.17466765642166, "val_acc": 72.0}
{"epoch": 20, "training_loss": 184.695867061615, "training_acc": 72.33333333333333, "val_loss": 45.381952702999115, "val_acc": 72.0}
{"epoch": 21, "training_loss": 190.21206045150757, "training_acc": 72.66666666666667, "val_loss": 50.26588064432144, "val_acc": 72.0}
{"epoch": 22, "training_loss": 183.37819123268127, "training_acc": 72.33333333333333, "val_loss": 44.53920120000839, "val_acc": 72.0}
{"epoch": 23, "training_loss": 178.43030953407288, "training_acc": 72.33333333333333, "val_loss": 44.21995586156845, "val_acc": 72.0}
{"epoch": 24, "training_loss": 182.42931032180786, "training_acc": 72.33333333333333, "val_loss": 44.96352136135101, "val_acc": 72.0}
{"epoch": 25, "training_loss": 183.83516645431519, "training_acc": 72.33333333333333, "val_loss": 47.098164677619934, "val_acc": 28.0}
{"epoch": 26, "training_loss": 180.32267594337463, "training_acc": 72.33333333333333, "val_loss": 45.56804984807968, "val_acc": 58.666666666666664}
{"epoch": 27, "training_loss": 173.43165063858032, "training_acc": 72.33333333333333, "val_loss": 54.707218408584595, "val_acc": 72.0}
{"epoch": 28, "training_loss": 187.51210474967957, "training_acc": 72.33333333333333, "val_loss": 44.35953977704048, "val_acc": 72.0}
{"epoch": 29, "training_loss": 183.92802119255066, "training_acc": 72.33333333333333, "val_loss": 46.96759617328644, "val_acc": 28.0}
{"epoch": 30, "training_loss": 193.07815217971802, "training_acc": 72.33333333333333, "val_loss": 55.42626577615738, "val_acc": 28.0}
{"epoch": 31, "training_loss": 225.75726056098938, "training_acc": 65.66666666666667, "val_loss": 50.45047861337662, "val_acc": 28.0}
{"epoch": 32, "training_loss": 210.9718635082245, "training_acc": 66.66666666666667, "val_loss": 61.40224635601044, "val_acc": 72.0}
{"epoch": 33, "training_loss": 224.14338517189026, "training_acc": 61.0, "val_loss": 62.25259184837341, "val_acc": 72.0}
{"epoch": 34, "training_loss": 217.13593077659607, "training_acc": 60.333333333333336, "val_loss": 53.67529797554016, "val_acc": 72.0}
{"epoch": 35, "training_loss": 222.60292029380798, "training_acc": 55.0, "val_loss": 48.58144122362137, "val_acc": 72.0}
{"epoch": 36, "training_loss": 204.76479935646057, "training_acc": 65.66666666666667, "val_loss": 56.33477234840393, "val_acc": 28.0}
{"epoch": 37, "training_loss": 223.32937383651733, "training_acc": 60.333333333333336, "val_loss": 57.15883654356003, "val_acc": 28.0}
{"epoch": 38, "training_loss": 211.15545964241028, "training_acc": 59.0, "val_loss": 46.5500745177269, "val_acc": 32.0}
