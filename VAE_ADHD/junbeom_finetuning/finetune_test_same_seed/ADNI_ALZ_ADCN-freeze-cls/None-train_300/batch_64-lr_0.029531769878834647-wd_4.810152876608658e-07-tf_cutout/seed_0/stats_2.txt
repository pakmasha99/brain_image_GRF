"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 300 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 672.5863275527954, "training_acc": 55.666666666666664, "val_loss": 101.14454710483551, "val_acc": 28.0}
{"epoch": 1, "training_loss": 272.5172920227051, "training_acc": 63.0, "val_loss": 54.907220005989075, "val_acc": 28.0}
{"epoch": 2, "training_loss": 225.52022218704224, "training_acc": 61.0, "val_loss": 51.9232936501503, "val_acc": 28.0}
{"epoch": 3, "training_loss": 188.2871913909912, "training_acc": 71.66666666666667, "val_loss": 48.331954300403595, "val_acc": 72.0}
{"epoch": 4, "training_loss": 187.58902835845947, "training_acc": 72.33333333333333, "val_loss": 45.8474343419075, "val_acc": 72.0}
{"epoch": 5, "training_loss": 179.09962224960327, "training_acc": 72.33333333333333, "val_loss": 47.78236681222916, "val_acc": 72.0}
{"epoch": 6, "training_loss": 182.89846062660217, "training_acc": 72.33333333333333, "val_loss": 54.91400581598282, "val_acc": 72.0}
{"epoch": 7, "training_loss": 195.16782879829407, "training_acc": 72.33333333333333, "val_loss": 44.42511188983917, "val_acc": 72.0}
{"epoch": 8, "training_loss": 180.8122136592865, "training_acc": 72.33333333333333, "val_loss": 45.11967569589615, "val_acc": 72.0}
{"epoch": 9, "training_loss": 194.74873733520508, "training_acc": 62.333333333333336, "val_loss": 54.4016078710556, "val_acc": 72.0}
{"epoch": 10, "training_loss": 216.4792845249176, "training_acc": 61.0, "val_loss": 48.02757501602173, "val_acc": 72.0}
{"epoch": 11, "training_loss": 205.41858911514282, "training_acc": 63.666666666666664, "val_loss": 46.28905689716339, "val_acc": 72.0}
{"epoch": 12, "training_loss": 223.47392106056213, "training_acc": 67.66666666666667, "val_loss": 53.1299746632576, "val_acc": 28.0}
{"epoch": 13, "training_loss": 214.22569108009338, "training_acc": 62.333333333333336, "val_loss": 79.75232028961182, "val_acc": 28.0}
{"epoch": 14, "training_loss": 225.26855444908142, "training_acc": 59.0, "val_loss": 45.65846759080887, "val_acc": 72.0}
{"epoch": 15, "training_loss": 201.67351913452148, "training_acc": 57.333333333333336, "val_loss": 54.87428617477417, "val_acc": 72.0}
{"epoch": 16, "training_loss": 195.07892203330994, "training_acc": 65.0, "val_loss": 54.89475840330124, "val_acc": 72.0}
{"epoch": 17, "training_loss": 191.81284499168396, "training_acc": 66.66666666666667, "val_loss": 60.530744791030884, "val_acc": 72.0}
{"epoch": 18, "training_loss": 236.43782925605774, "training_acc": 66.33333333333333, "val_loss": 44.60414677858353, "val_acc": 72.0}
{"epoch": 19, "training_loss": 197.36472272872925, "training_acc": 72.33333333333333, "val_loss": 60.40230178833008, "val_acc": 28.0}
{"epoch": 20, "training_loss": 197.01336669921875, "training_acc": 64.33333333333333, "val_loss": 49.530715465545654, "val_acc": 28.0}
{"epoch": 21, "training_loss": 199.20961022377014, "training_acc": 73.0, "val_loss": 52.38941389322281, "val_acc": 28.0}
{"epoch": 22, "training_loss": 195.97136735916138, "training_acc": 59.0, "val_loss": 45.38975262641907, "val_acc": 72.0}
{"epoch": 23, "training_loss": 209.3723316192627, "training_acc": 58.0, "val_loss": 58.06514656543732, "val_acc": 72.0}
{"epoch": 24, "training_loss": 203.7250566482544, "training_acc": 65.0, "val_loss": 62.92706608772278, "val_acc": 72.0}
{"epoch": 25, "training_loss": 215.08108830451965, "training_acc": 60.333333333333336, "val_loss": 55.17815488576889, "val_acc": 72.0}
{"epoch": 26, "training_loss": 195.27715015411377, "training_acc": 72.66666666666667, "val_loss": 45.47453862428665, "val_acc": 72.0}
