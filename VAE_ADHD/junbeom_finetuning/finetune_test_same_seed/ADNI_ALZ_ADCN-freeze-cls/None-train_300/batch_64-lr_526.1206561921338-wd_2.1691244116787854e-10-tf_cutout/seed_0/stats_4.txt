"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 300 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 7812201.463432312, "training_acc": 62.333333333333336, "val_loss": 145867.58569335938, "val_acc": 72.0}
{"epoch": 1, "training_loss": 2928296.26171875, "training_acc": 60.333333333333336, "val_loss": 478571.24560546875, "val_acc": 28.0}
{"epoch": 2, "training_loss": 1646715.353515625, "training_acc": 53.0, "val_loss": 387215.345703125, "val_acc": 72.0}
{"epoch": 3, "training_loss": 1283852.0068359375, "training_acc": 63.0, "val_loss": 134321.4620361328, "val_acc": 28.0}
{"epoch": 4, "training_loss": 1756902.2041015625, "training_acc": 61.0, "val_loss": 1436048.830078125, "val_acc": 28.0}
{"epoch": 5, "training_loss": 3847217.03515625, "training_acc": 53.666666666666664, "val_loss": 891890.6606445312, "val_acc": 72.0}
{"epoch": 6, "training_loss": 2321900.17578125, "training_acc": 53.666666666666664, "val_loss": 1173810.052734375, "val_acc": 72.0}
{"epoch": 7, "training_loss": 3704214.3295898438, "training_acc": 72.66666666666667, "val_loss": 1948915.53515625, "val_acc": 28.0}
{"epoch": 8, "training_loss": 5621316.0703125, "training_acc": 45.0, "val_loss": 2633931.125, "val_acc": 72.0}
{"epoch": 9, "training_loss": 10209021.25, "training_acc": 72.33333333333333, "val_loss": 1088692.1630859375, "val_acc": 72.0}
{"epoch": 10, "training_loss": 3298204.359375, "training_acc": 41.666666666666664, "val_loss": 1786385.75390625, "val_acc": 72.0}
{"epoch": 11, "training_loss": 8807596.484375, "training_acc": 72.33333333333333, "val_loss": 1328118.90234375, "val_acc": 72.0}
{"epoch": 12, "training_loss": 6309760.953125, "training_acc": 45.0, "val_loss": 620331.705078125, "val_acc": 72.0}
{"epoch": 13, "training_loss": 5631200.359375, "training_acc": 72.33333333333333, "val_loss": 1320836.767578125, "val_acc": 72.0}
{"epoch": 14, "training_loss": 3742383.8154296875, "training_acc": 51.0, "val_loss": 458068.578125, "val_acc": 72.0}
{"epoch": 15, "training_loss": 1951837.2321777344, "training_acc": 55.666666666666664, "val_loss": 652950.052734375, "val_acc": 72.0}
{"epoch": 16, "training_loss": 3664766.07421875, "training_acc": 72.33333333333333, "val_loss": 610236.65234375, "val_acc": 28.0}
{"epoch": 17, "training_loss": 2883878.90625, "training_acc": 54.333333333333336, "val_loss": 786446.078125, "val_acc": 72.0}
{"epoch": 18, "training_loss": 2318155.296875, "training_acc": 53.666666666666664, "val_loss": 962760.958984375, "val_acc": 72.0}
{"epoch": 19, "training_loss": 3566277.953125, "training_acc": 62.333333333333336, "val_loss": 809943.3681640625, "val_acc": 28.0}
{"epoch": 20, "training_loss": 2844090.1796875, "training_acc": 65.66666666666667, "val_loss": 443252.97265625, "val_acc": 72.0}
{"epoch": 21, "training_loss": 2511670.76953125, "training_acc": 51.666666666666664, "val_loss": 1163788.4931640625, "val_acc": 72.0}
{"epoch": 22, "training_loss": 3078361.0078125, "training_acc": 68.33333333333333, "val_loss": 1764195.599609375, "val_acc": 28.0}
