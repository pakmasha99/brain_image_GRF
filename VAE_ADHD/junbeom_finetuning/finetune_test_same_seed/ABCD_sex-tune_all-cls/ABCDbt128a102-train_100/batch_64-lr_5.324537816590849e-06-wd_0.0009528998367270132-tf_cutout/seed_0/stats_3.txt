"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/BT_weights/BT_weights_no_norm5//ABCDbt128a102.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 69.22947716712952, "training_acc": 52.0, "val_loss": 17.34626740217209, "val_acc": 52.0}
{"epoch": 1, "training_loss": 69.21053814888, "training_acc": 53.0, "val_loss": 17.327529191970825, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.11358213424683, "training_acc": 53.0, "val_loss": 17.329201102256775, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.14008736610413, "training_acc": 53.0, "val_loss": 17.31559783220291, "val_acc": 52.0}
{"epoch": 4, "training_loss": 68.89052653312683, "training_acc": 53.0, "val_loss": 17.319640517234802, "val_acc": 52.0}
{"epoch": 5, "training_loss": 68.849369764328, "training_acc": 53.0, "val_loss": 17.294907569885254, "val_acc": 52.0}
{"epoch": 6, "training_loss": 68.69678449630737, "training_acc": 53.0, "val_loss": 17.285285890102386, "val_acc": 52.0}
{"epoch": 7, "training_loss": 68.65593123435974, "training_acc": 53.0, "val_loss": 17.27469563484192, "val_acc": 52.0}
{"epoch": 8, "training_loss": 68.63229656219482, "training_acc": 53.0, "val_loss": 17.26595312356949, "val_acc": 52.0}
{"epoch": 9, "training_loss": 68.40190386772156, "training_acc": 55.0, "val_loss": 17.278708517551422, "val_acc": 52.0}
{"epoch": 10, "training_loss": 68.46506237983704, "training_acc": 53.0, "val_loss": 17.292150855064392, "val_acc": 52.0}
{"epoch": 11, "training_loss": 68.36389422416687, "training_acc": 55.0, "val_loss": 17.311464250087738, "val_acc": 52.0}
{"epoch": 12, "training_loss": 68.14867544174194, "training_acc": 57.0, "val_loss": 17.30530560016632, "val_acc": 52.0}
{"epoch": 13, "training_loss": 68.04565906524658, "training_acc": 56.0, "val_loss": 17.321571707725525, "val_acc": 52.0}
{"epoch": 14, "training_loss": 67.9224009513855, "training_acc": 57.0, "val_loss": 17.284171283245087, "val_acc": 52.0}
{"epoch": 15, "training_loss": 67.81841373443604, "training_acc": 59.0, "val_loss": 17.27055013179779, "val_acc": 52.0}
{"epoch": 16, "training_loss": 67.73570823669434, "training_acc": 59.0, "val_loss": 17.293904721736908, "val_acc": 52.0}
{"epoch": 17, "training_loss": 67.54336547851562, "training_acc": 59.0, "val_loss": 17.303939163684845, "val_acc": 52.0}
{"epoch": 18, "training_loss": 67.45414686203003, "training_acc": 59.0, "val_loss": 17.298264801502228, "val_acc": 52.0}
{"epoch": 19, "training_loss": 67.30512690544128, "training_acc": 59.0, "val_loss": 17.28803962469101, "val_acc": 52.0}
{"epoch": 20, "training_loss": 67.28831839561462, "training_acc": 62.0, "val_loss": 17.262527346611023, "val_acc": 52.0}
{"epoch": 21, "training_loss": 67.1843409538269, "training_acc": 63.0, "val_loss": 17.288078367710114, "val_acc": 52.0}
{"epoch": 22, "training_loss": 67.38805198669434, "training_acc": 60.0, "val_loss": 17.317713797092438, "val_acc": 52.0}
{"epoch": 23, "training_loss": 66.9493944644928, "training_acc": 63.0, "val_loss": 17.306777834892273, "val_acc": 52.0}
{"epoch": 24, "training_loss": 66.99857449531555, "training_acc": 63.0, "val_loss": 17.297793924808502, "val_acc": 52.0}
{"epoch": 25, "training_loss": 67.09876990318298, "training_acc": 66.0, "val_loss": 17.29331612586975, "val_acc": 52.0}
{"epoch": 26, "training_loss": 66.89405179023743, "training_acc": 64.0, "val_loss": 17.275558412075043, "val_acc": 52.0}
{"epoch": 27, "training_loss": 66.57722067832947, "training_acc": 66.0, "val_loss": 17.309266328811646, "val_acc": 52.0}
{"epoch": 28, "training_loss": 66.67420959472656, "training_acc": 70.0, "val_loss": 17.327557504177094, "val_acc": 52.0}
{"epoch": 29, "training_loss": 66.43913984298706, "training_acc": 67.0, "val_loss": 17.278476059436798, "val_acc": 52.0}
{"epoch": 30, "training_loss": 66.39580273628235, "training_acc": 66.0, "val_loss": 17.27994829416275, "val_acc": 52.0}
{"epoch": 31, "training_loss": 66.3993809223175, "training_acc": 69.0, "val_loss": 17.316660284996033, "val_acc": 52.0}
{"epoch": 32, "training_loss": 66.44406247138977, "training_acc": 66.0, "val_loss": 17.30009615421295, "val_acc": 52.0}
{"epoch": 33, "training_loss": 66.04494452476501, "training_acc": 71.0, "val_loss": 17.328357696533203, "val_acc": 52.0}
{"epoch": 34, "training_loss": 66.01178812980652, "training_acc": 70.0, "val_loss": 17.294791340827942, "val_acc": 52.0}
{"epoch": 35, "training_loss": 66.07036280632019, "training_acc": 71.0, "val_loss": 17.27067530155182, "val_acc": 52.0}
{"epoch": 36, "training_loss": 65.93743062019348, "training_acc": 71.0, "val_loss": 17.351672053337097, "val_acc": 52.0}
{"epoch": 37, "training_loss": 65.66164183616638, "training_acc": 71.0, "val_loss": 17.300383746623993, "val_acc": 52.0}
{"epoch": 38, "training_loss": 66.02505493164062, "training_acc": 68.0, "val_loss": 17.25555509328842, "val_acc": 52.0}
{"epoch": 39, "training_loss": 65.73203158378601, "training_acc": 73.0, "val_loss": 17.33870655298233, "val_acc": 52.0}
{"epoch": 40, "training_loss": 65.71934866905212, "training_acc": 72.0, "val_loss": 17.348428070545197, "val_acc": 52.0}
{"epoch": 41, "training_loss": 65.55195927619934, "training_acc": 72.0, "val_loss": 17.268268764019012, "val_acc": 52.0}
{"epoch": 42, "training_loss": 65.46376729011536, "training_acc": 72.0, "val_loss": 17.31478124856949, "val_acc": 52.0}
{"epoch": 43, "training_loss": 65.38790225982666, "training_acc": 74.0, "val_loss": 17.35110878944397, "val_acc": 52.0}
{"epoch": 44, "training_loss": 65.73201060295105, "training_acc": 72.0, "val_loss": 17.30048358440399, "val_acc": 52.0}
{"epoch": 45, "training_loss": 65.27313542366028, "training_acc": 72.0, "val_loss": 17.310328781604767, "val_acc": 52.0}
{"epoch": 46, "training_loss": 65.61191654205322, "training_acc": 72.0, "val_loss": 17.291389405727386, "val_acc": 52.0}
{"epoch": 47, "training_loss": 65.19799947738647, "training_acc": 76.0, "val_loss": 17.35002100467682, "val_acc": 52.0}
{"epoch": 48, "training_loss": 65.27655363082886, "training_acc": 76.0, "val_loss": 17.307743430137634, "val_acc": 52.0}
{"epoch": 49, "training_loss": 65.25443649291992, "training_acc": 74.0, "val_loss": 17.289340496063232, "val_acc": 52.0}
{"epoch": 50, "training_loss": 65.2755286693573, "training_acc": 73.0, "val_loss": 17.33318120241165, "val_acc": 52.0}
{"epoch": 51, "training_loss": 64.76900601387024, "training_acc": 76.0, "val_loss": 17.385472357273102, "val_acc": 52.0}
{"epoch": 52, "training_loss": 65.2527117729187, "training_acc": 75.0, "val_loss": 17.31073558330536, "val_acc": 52.0}
{"epoch": 53, "training_loss": 64.92685389518738, "training_acc": 76.0, "val_loss": 17.31242835521698, "val_acc": 52.0}
{"epoch": 54, "training_loss": 64.96104121208191, "training_acc": 74.0, "val_loss": 17.35951155424118, "val_acc": 52.0}
{"epoch": 55, "training_loss": 65.11964416503906, "training_acc": 77.0, "val_loss": 17.36760437488556, "val_acc": 52.0}
{"epoch": 56, "training_loss": 64.42641043663025, "training_acc": 77.0, "val_loss": 17.349903285503387, "val_acc": 52.0}
{"epoch": 57, "training_loss": 64.57511568069458, "training_acc": 77.0, "val_loss": 17.263957858085632, "val_acc": 52.0}
