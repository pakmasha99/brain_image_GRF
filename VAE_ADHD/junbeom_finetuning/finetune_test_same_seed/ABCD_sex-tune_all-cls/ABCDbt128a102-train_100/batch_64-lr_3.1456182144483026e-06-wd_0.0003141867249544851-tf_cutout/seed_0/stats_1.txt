"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/BT_weights/BT_weights_no_norm5//ABCDbt128a102.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 69.46130037307739, "training_acc": 46.0, "val_loss": 17.41901785135269, "val_acc": 52.0}
{"epoch": 1, "training_loss": 69.32672834396362, "training_acc": 48.0, "val_loss": 17.410609126091003, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.24681735038757, "training_acc": 47.0, "val_loss": 17.378929257392883, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.26601195335388, "training_acc": 49.0, "val_loss": 17.375755310058594, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.08965587615967, "training_acc": 52.0, "val_loss": 17.377829551696777, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.08128881454468, "training_acc": 55.0, "val_loss": 17.38855540752411, "val_acc": 52.0}
{"epoch": 6, "training_loss": 68.90258812904358, "training_acc": 61.0, "val_loss": 17.39632934331894, "val_acc": 52.0}
{"epoch": 7, "training_loss": 68.9158890247345, "training_acc": 65.0, "val_loss": 17.39320009946823, "val_acc": 52.0}
{"epoch": 8, "training_loss": 68.76306509971619, "training_acc": 69.0, "val_loss": 17.396169900894165, "val_acc": 52.0}
{"epoch": 9, "training_loss": 68.6587393283844, "training_acc": 73.0, "val_loss": 17.37683415412903, "val_acc": 52.0}
{"epoch": 10, "training_loss": 68.60430192947388, "training_acc": 73.0, "val_loss": 17.382723093032837, "val_acc": 52.0}
{"epoch": 11, "training_loss": 68.40752100944519, "training_acc": 74.0, "val_loss": 17.415934801101685, "val_acc": 52.0}
{"epoch": 12, "training_loss": 68.35840368270874, "training_acc": 76.0, "val_loss": 17.42680072784424, "val_acc": 52.0}
{"epoch": 13, "training_loss": 68.36735534667969, "training_acc": 76.0, "val_loss": 17.408521473407745, "val_acc": 52.0}
{"epoch": 14, "training_loss": 68.21280241012573, "training_acc": 75.0, "val_loss": 17.363570630550385, "val_acc": 52.0}
{"epoch": 15, "training_loss": 68.33747839927673, "training_acc": 72.0, "val_loss": 17.360854148864746, "val_acc": 52.0}
{"epoch": 16, "training_loss": 68.01832365989685, "training_acc": 74.0, "val_loss": 17.401376366615295, "val_acc": 52.0}
{"epoch": 17, "training_loss": 68.07015132904053, "training_acc": 76.0, "val_loss": 17.415815591812134, "val_acc": 52.0}
{"epoch": 18, "training_loss": 68.04862952232361, "training_acc": 77.0, "val_loss": 17.397621273994446, "val_acc": 52.0}
{"epoch": 19, "training_loss": 67.85552954673767, "training_acc": 76.0, "val_loss": 17.37601011991501, "val_acc": 52.0}
{"epoch": 20, "training_loss": 67.72363758087158, "training_acc": 84.0, "val_loss": 17.377842962741852, "val_acc": 52.0}
{"epoch": 21, "training_loss": 67.69380497932434, "training_acc": 79.0, "val_loss": 17.405715584754944, "val_acc": 52.0}
{"epoch": 22, "training_loss": 67.55687379837036, "training_acc": 79.0, "val_loss": 17.406637966632843, "val_acc": 52.0}
{"epoch": 23, "training_loss": 67.74164509773254, "training_acc": 76.0, "val_loss": 17.37865060567856, "val_acc": 52.0}
{"epoch": 24, "training_loss": 67.58481335639954, "training_acc": 77.0, "val_loss": 17.34381765127182, "val_acc": 52.0}
{"epoch": 25, "training_loss": 67.4976692199707, "training_acc": 79.0, "val_loss": 17.374198138713837, "val_acc": 52.0}
{"epoch": 26, "training_loss": 67.33494544029236, "training_acc": 80.0, "val_loss": 17.404939234256744, "val_acc": 52.0}
{"epoch": 27, "training_loss": 67.30126881599426, "training_acc": 76.0, "val_loss": 17.41192638874054, "val_acc": 52.0}
{"epoch": 28, "training_loss": 67.24000120162964, "training_acc": 81.0, "val_loss": 17.402607202529907, "val_acc": 52.0}
{"epoch": 29, "training_loss": 67.37032675743103, "training_acc": 76.0, "val_loss": 17.39521026611328, "val_acc": 52.0}
{"epoch": 30, "training_loss": 66.91840744018555, "training_acc": 81.0, "val_loss": 17.374321818351746, "val_acc": 52.0}
{"epoch": 31, "training_loss": 67.19914937019348, "training_acc": 78.0, "val_loss": 17.3885777592659, "val_acc": 52.0}
{"epoch": 32, "training_loss": 67.00835847854614, "training_acc": 80.0, "val_loss": 17.402751743793488, "val_acc": 52.0}
{"epoch": 33, "training_loss": 66.93837094306946, "training_acc": 77.0, "val_loss": 17.41347908973694, "val_acc": 52.0}
{"epoch": 34, "training_loss": 66.81983757019043, "training_acc": 83.0, "val_loss": 17.40395277738571, "val_acc": 52.0}
{"epoch": 35, "training_loss": 66.98567628860474, "training_acc": 81.0, "val_loss": 17.388571798801422, "val_acc": 52.0}
{"epoch": 36, "training_loss": 66.68106460571289, "training_acc": 84.0, "val_loss": 17.406898736953735, "val_acc": 52.0}
{"epoch": 37, "training_loss": 66.75561428070068, "training_acc": 79.0, "val_loss": 17.408503592014313, "val_acc": 52.0}
{"epoch": 38, "training_loss": 66.58365821838379, "training_acc": 83.0, "val_loss": 17.395196855068207, "val_acc": 52.0}
{"epoch": 39, "training_loss": 66.54128837585449, "training_acc": 80.0, "val_loss": 17.418357729911804, "val_acc": 52.0}
{"epoch": 40, "training_loss": 66.37050652503967, "training_acc": 80.0, "val_loss": 17.39768534898758, "val_acc": 52.0}
{"epoch": 41, "training_loss": 66.27566766738892, "training_acc": 80.0, "val_loss": 17.39495098590851, "val_acc": 52.0}
{"epoch": 42, "training_loss": 66.29268383979797, "training_acc": 80.0, "val_loss": 17.38245189189911, "val_acc": 52.0}
{"epoch": 43, "training_loss": 66.63996434211731, "training_acc": 79.0, "val_loss": 17.38952398300171, "val_acc": 52.0}
