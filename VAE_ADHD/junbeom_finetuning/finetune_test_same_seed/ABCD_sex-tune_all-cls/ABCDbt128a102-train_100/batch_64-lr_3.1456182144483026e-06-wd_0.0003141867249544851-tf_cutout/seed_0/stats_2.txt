"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/BT_weights/BT_weights_no_norm5//ABCDbt128a102.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 69.04117703437805, "training_acc": 53.0, "val_loss": 17.340466380119324, "val_acc": 52.0}
{"epoch": 1, "training_loss": 69.13845133781433, "training_acc": 53.0, "val_loss": 17.342090606689453, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.02789855003357, "training_acc": 53.0, "val_loss": 17.326508462429047, "val_acc": 52.0}
{"epoch": 3, "training_loss": 68.94238018989563, "training_acc": 53.0, "val_loss": 17.33330935239792, "val_acc": 52.0}
{"epoch": 4, "training_loss": 68.91436052322388, "training_acc": 53.0, "val_loss": 17.337948083877563, "val_acc": 52.0}
{"epoch": 5, "training_loss": 68.82482266426086, "training_acc": 53.0, "val_loss": 17.313699424266815, "val_acc": 52.0}
{"epoch": 6, "training_loss": 68.76238989830017, "training_acc": 53.0, "val_loss": 17.305073142051697, "val_acc": 52.0}
{"epoch": 7, "training_loss": 68.69660997390747, "training_acc": 53.0, "val_loss": 17.324845492839813, "val_acc": 52.0}
{"epoch": 8, "training_loss": 68.6236925125122, "training_acc": 53.0, "val_loss": 17.33374148607254, "val_acc": 52.0}
{"epoch": 9, "training_loss": 68.55802536010742, "training_acc": 53.0, "val_loss": 17.345035076141357, "val_acc": 52.0}
{"epoch": 10, "training_loss": 68.48624801635742, "training_acc": 53.0, "val_loss": 17.3366978764534, "val_acc": 52.0}
{"epoch": 11, "training_loss": 68.58398103713989, "training_acc": 53.0, "val_loss": 17.329135537147522, "val_acc": 52.0}
{"epoch": 12, "training_loss": 68.33396935462952, "training_acc": 53.0, "val_loss": 17.29467511177063, "val_acc": 52.0}
{"epoch": 13, "training_loss": 68.32725977897644, "training_acc": 53.0, "val_loss": 17.288997769355774, "val_acc": 52.0}
{"epoch": 14, "training_loss": 68.3308744430542, "training_acc": 53.0, "val_loss": 17.303676903247833, "val_acc": 52.0}
{"epoch": 15, "training_loss": 68.08340835571289, "training_acc": 53.0, "val_loss": 17.325572669506073, "val_acc": 52.0}
{"epoch": 16, "training_loss": 68.10553407669067, "training_acc": 53.0, "val_loss": 17.308394610881805, "val_acc": 52.0}
{"epoch": 17, "training_loss": 68.23047375679016, "training_acc": 53.0, "val_loss": 17.314746975898743, "val_acc": 52.0}
{"epoch": 18, "training_loss": 68.04186749458313, "training_acc": 53.0, "val_loss": 17.31569766998291, "val_acc": 52.0}
{"epoch": 19, "training_loss": 67.94118046760559, "training_acc": 53.0, "val_loss": 17.29763150215149, "val_acc": 52.0}
{"epoch": 20, "training_loss": 67.81193995475769, "training_acc": 53.0, "val_loss": 17.298074066638947, "val_acc": 52.0}
{"epoch": 21, "training_loss": 67.77686834335327, "training_acc": 53.0, "val_loss": 17.315660417079926, "val_acc": 52.0}
{"epoch": 22, "training_loss": 67.73465728759766, "training_acc": 53.0, "val_loss": 17.32618808746338, "val_acc": 52.0}
{"epoch": 23, "training_loss": 67.60570073127747, "training_acc": 53.0, "val_loss": 17.308707535266876, "val_acc": 52.0}
{"epoch": 24, "training_loss": 67.54248881340027, "training_acc": 53.0, "val_loss": 17.29872077703476, "val_acc": 52.0}
{"epoch": 25, "training_loss": 67.63855624198914, "training_acc": 53.0, "val_loss": 17.30611026287079, "val_acc": 52.0}
{"epoch": 26, "training_loss": 67.36920595169067, "training_acc": 53.0, "val_loss": 17.316456139087677, "val_acc": 52.0}
{"epoch": 27, "training_loss": 67.4464647769928, "training_acc": 53.0, "val_loss": 17.31572300195694, "val_acc": 52.0}
{"epoch": 28, "training_loss": 67.33954310417175, "training_acc": 53.0, "val_loss": 17.305469512939453, "val_acc": 52.0}
{"epoch": 29, "training_loss": 67.32081246376038, "training_acc": 53.0, "val_loss": 17.30584055185318, "val_acc": 52.0}
{"epoch": 30, "training_loss": 66.98268461227417, "training_acc": 53.0, "val_loss": 17.29460507631302, "val_acc": 52.0}
{"epoch": 31, "training_loss": 67.07401657104492, "training_acc": 53.0, "val_loss": 17.307348549365997, "val_acc": 52.0}
{"epoch": 32, "training_loss": 66.97047448158264, "training_acc": 53.0, "val_loss": 17.312337458133698, "val_acc": 52.0}
