"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/BT_weights/BT_weights_no_norm5//ABCDbt128a102.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 78.78285622596741, "training_acc": 48.0, "val_loss": 2915.780258178711, "val_acc": 48.0}
{"epoch": 1, "training_loss": 8437.333724975586, "training_acc": 51.0, "val_loss": 35.72637140750885, "val_acc": 52.0}
{"epoch": 2, "training_loss": 251.70963096618652, "training_acc": 53.0, "val_loss": 18.15616637468338, "val_acc": 52.0}
{"epoch": 3, "training_loss": 74.43796610832214, "training_acc": 55.0, "val_loss": 17.594406008720398, "val_acc": 52.0}
{"epoch": 4, "training_loss": 67.53271842002869, "training_acc": 59.0, "val_loss": 17.371410131454468, "val_acc": 52.0}
{"epoch": 5, "training_loss": 75.391672372818, "training_acc": 47.0, "val_loss": 34.77412462234497, "val_acc": 52.0}
{"epoch": 6, "training_loss": 124.53772687911987, "training_acc": 53.0, "val_loss": 17.47152805328369, "val_acc": 52.0}
{"epoch": 7, "training_loss": 70.57146072387695, "training_acc": 47.0, "val_loss": 17.32441335916519, "val_acc": 52.0}
{"epoch": 8, "training_loss": 68.85461902618408, "training_acc": 53.0, "val_loss": 17.882029712200165, "val_acc": 52.0}
{"epoch": 9, "training_loss": 71.05224680900574, "training_acc": 53.0, "val_loss": 17.315325140953064, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.72536396980286, "training_acc": 51.0, "val_loss": 17.710290849208832, "val_acc": 52.0}
{"epoch": 11, "training_loss": 71.54859852790833, "training_acc": 42.0, "val_loss": 17.313283681869507, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.10282230377197, "training_acc": 53.0, "val_loss": 17.35934615135193, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.20608234405518, "training_acc": 53.0, "val_loss": 17.414824664592743, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.37101697921753, "training_acc": 53.0, "val_loss": 17.347072064876556, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.1647834777832, "training_acc": 53.0, "val_loss": 17.320890724658966, "val_acc": 52.0}
{"epoch": 16, "training_loss": 70.96570944786072, "training_acc": 37.0, "val_loss": 17.321977019309998, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.90860557556152, "training_acc": 53.0, "val_loss": 17.4515038728714, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.85214447975159, "training_acc": 53.0, "val_loss": 17.417609691619873, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.21655750274658, "training_acc": 53.0, "val_loss": 17.31158345937729, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.49766564369202, "training_acc": 47.0, "val_loss": 17.374026775360107, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.53362989425659, "training_acc": 47.0, "val_loss": 17.327718436717987, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.22132515907288, "training_acc": 53.0, "val_loss": 17.31395274400711, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.09511542320251, "training_acc": 53.0, "val_loss": 17.364846169948578, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.25028324127197, "training_acc": 53.0, "val_loss": 17.392002046108246, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.37150502204895, "training_acc": 53.0, "val_loss": 17.389212548732758, "val_acc": 52.0}
{"epoch": 26, "training_loss": 69.25090861320496, "training_acc": 53.0, "val_loss": 17.326270043849945, "val_acc": 52.0}
{"epoch": 27, "training_loss": 69.62980437278748, "training_acc": 53.0, "val_loss": 17.31136292219162, "val_acc": 52.0}
{"epoch": 28, "training_loss": 69.1694564819336, "training_acc": 53.0, "val_loss": 17.311003804206848, "val_acc": 52.0}
{"epoch": 29, "training_loss": 69.12275576591492, "training_acc": 53.0, "val_loss": 17.320190370082855, "val_acc": 52.0}
{"epoch": 30, "training_loss": 69.1877224445343, "training_acc": 53.0, "val_loss": 17.344510555267334, "val_acc": 52.0}
{"epoch": 31, "training_loss": 69.28216552734375, "training_acc": 53.0, "val_loss": 17.343340814113617, "val_acc": 52.0}
{"epoch": 32, "training_loss": 69.25784468650818, "training_acc": 53.0, "val_loss": 17.31639802455902, "val_acc": 52.0}
{"epoch": 33, "training_loss": 69.09024000167847, "training_acc": 53.0, "val_loss": 17.326156795024872, "val_acc": 52.0}
{"epoch": 34, "training_loss": 69.32210993766785, "training_acc": 51.0, "val_loss": 17.35944002866745, "val_acc": 52.0}
{"epoch": 35, "training_loss": 69.46021771430969, "training_acc": 47.0, "val_loss": 17.34604835510254, "val_acc": 52.0}
{"epoch": 36, "training_loss": 69.36385607719421, "training_acc": 49.0, "val_loss": 17.31553226709366, "val_acc": 52.0}
{"epoch": 37, "training_loss": 69.15536999702454, "training_acc": 53.0, "val_loss": 17.31666475534439, "val_acc": 52.0}
{"epoch": 38, "training_loss": 69.08497738838196, "training_acc": 53.0, "val_loss": 17.34987199306488, "val_acc": 52.0}
{"epoch": 39, "training_loss": 69.19620108604431, "training_acc": 53.0, "val_loss": 17.390254139900208, "val_acc": 52.0}
{"epoch": 40, "training_loss": 69.31464791297913, "training_acc": 53.0, "val_loss": 17.39051192998886, "val_acc": 52.0}
{"epoch": 41, "training_loss": 69.4124481678009, "training_acc": 53.0, "val_loss": 17.369212210178375, "val_acc": 52.0}
{"epoch": 42, "training_loss": 69.15677762031555, "training_acc": 53.0, "val_loss": 17.317648231983185, "val_acc": 52.0}
{"epoch": 43, "training_loss": 69.3433735370636, "training_acc": 53.0, "val_loss": 17.315450310707092, "val_acc": 52.0}
{"epoch": 44, "training_loss": 69.25512790679932, "training_acc": 53.0, "val_loss": 17.318618297576904, "val_acc": 52.0}
{"epoch": 45, "training_loss": 69.269113779068, "training_acc": 53.0, "val_loss": 17.324596643447876, "val_acc": 52.0}
{"epoch": 46, "training_loss": 69.32512378692627, "training_acc": 53.0, "val_loss": 17.314834892749786, "val_acc": 52.0}
{"epoch": 47, "training_loss": 69.13192868232727, "training_acc": 53.0, "val_loss": 17.315925657749176, "val_acc": 52.0}
