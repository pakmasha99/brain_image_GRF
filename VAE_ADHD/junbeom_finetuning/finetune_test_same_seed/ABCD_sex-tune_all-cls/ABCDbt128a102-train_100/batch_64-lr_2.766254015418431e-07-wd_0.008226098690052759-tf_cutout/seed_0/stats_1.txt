"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/BT_weights/BT_weights_no_norm5//ABCDbt128a102.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 69.55264782905579, "training_acc": 47.0, "val_loss": 17.350029945373535, "val_acc": 52.0}
{"epoch": 1, "training_loss": 69.60681653022766, "training_acc": 47.0, "val_loss": 17.348691821098328, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.52430844306946, "training_acc": 47.0, "val_loss": 17.34873503446579, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.51708459854126, "training_acc": 47.0, "val_loss": 17.347989976406097, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.50634121894836, "training_acc": 47.0, "val_loss": 17.347589135169983, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.36798286437988, "training_acc": 47.0, "val_loss": 17.34646111726761, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.52282786369324, "training_acc": 47.0, "val_loss": 17.345134913921356, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.46318435668945, "training_acc": 47.0, "val_loss": 17.343896627426147, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.42215824127197, "training_acc": 47.0, "val_loss": 17.34255701303482, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.48096132278442, "training_acc": 47.0, "val_loss": 17.341458797454834, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.38444352149963, "training_acc": 47.0, "val_loss": 17.340388894081116, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.38782477378845, "training_acc": 47.0, "val_loss": 17.34035760164261, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.45874047279358, "training_acc": 47.0, "val_loss": 17.340803146362305, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.42885541915894, "training_acc": 47.0, "val_loss": 17.340604960918427, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.34319615364075, "training_acc": 47.0, "val_loss": 17.3408180475235, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.45834565162659, "training_acc": 47.0, "val_loss": 17.34084039926529, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.39374351501465, "training_acc": 47.0, "val_loss": 17.34149158000946, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.28218722343445, "training_acc": 47.0, "val_loss": 17.3411026597023, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.38948035240173, "training_acc": 47.0, "val_loss": 17.340567708015442, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.33535051345825, "training_acc": 47.0, "val_loss": 17.338576912879944, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.43799948692322, "training_acc": 47.0, "val_loss": 17.337428033351898, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.35008215904236, "training_acc": 47.0, "val_loss": 17.336612939834595, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.28312516212463, "training_acc": 47.0, "val_loss": 17.335307598114014, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.2831962108612, "training_acc": 47.0, "val_loss": 17.334099113941193, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.29339146614075, "training_acc": 47.0, "val_loss": 17.333194613456726, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.30832362174988, "training_acc": 47.0, "val_loss": 17.33199805021286, "val_acc": 52.0}
{"epoch": 26, "training_loss": 69.27696990966797, "training_acc": 47.0, "val_loss": 17.3313170671463, "val_acc": 52.0}
{"epoch": 27, "training_loss": 69.25227093696594, "training_acc": 47.0, "val_loss": 17.33151078224182, "val_acc": 52.0}
{"epoch": 28, "training_loss": 69.25432133674622, "training_acc": 47.0, "val_loss": 17.331580817699432, "val_acc": 52.0}
{"epoch": 29, "training_loss": 69.24741291999817, "training_acc": 47.0, "val_loss": 17.331701517105103, "val_acc": 52.0}
{"epoch": 30, "training_loss": 69.15282583236694, "training_acc": 47.0, "val_loss": 17.332085967063904, "val_acc": 52.0}
{"epoch": 31, "training_loss": 69.19060826301575, "training_acc": 47.0, "val_loss": 17.33221709728241, "val_acc": 52.0}
{"epoch": 32, "training_loss": 69.16510057449341, "training_acc": 47.0, "val_loss": 17.332397401332855, "val_acc": 52.0}
{"epoch": 33, "training_loss": 69.17682075500488, "training_acc": 47.0, "val_loss": 17.333436012268066, "val_acc": 52.0}
{"epoch": 34, "training_loss": 69.19862842559814, "training_acc": 47.0, "val_loss": 17.33495444059372, "val_acc": 52.0}
{"epoch": 35, "training_loss": 69.16603708267212, "training_acc": 47.0, "val_loss": 17.3368901014328, "val_acc": 52.0}
{"epoch": 36, "training_loss": 69.15403485298157, "training_acc": 47.0, "val_loss": 17.33919084072113, "val_acc": 52.0}
{"epoch": 37, "training_loss": 69.12268495559692, "training_acc": 47.0, "val_loss": 17.340995371341705, "val_acc": 52.0}
{"epoch": 38, "training_loss": 69.1372606754303, "training_acc": 47.0, "val_loss": 17.342214286327362, "val_acc": 52.0}
{"epoch": 39, "training_loss": 69.07618045806885, "training_acc": 47.0, "val_loss": 17.342792451381683, "val_acc": 52.0}
{"epoch": 40, "training_loss": 69.14827013015747, "training_acc": 47.0, "val_loss": 17.34212040901184, "val_acc": 52.0}
{"epoch": 41, "training_loss": 69.08846187591553, "training_acc": 47.0, "val_loss": 17.341887950897217, "val_acc": 52.0}
{"epoch": 42, "training_loss": 69.12508034706116, "training_acc": 47.0, "val_loss": 17.34124720096588, "val_acc": 52.0}
{"epoch": 43, "training_loss": 69.11007165908813, "training_acc": 47.0, "val_loss": 17.339658737182617, "val_acc": 52.0}
{"epoch": 44, "training_loss": 69.0695264339447, "training_acc": 47.0, "val_loss": 17.338427901268005, "val_acc": 52.0}
{"epoch": 45, "training_loss": 69.15660548210144, "training_acc": 48.0, "val_loss": 17.336943745613098, "val_acc": 52.0}
