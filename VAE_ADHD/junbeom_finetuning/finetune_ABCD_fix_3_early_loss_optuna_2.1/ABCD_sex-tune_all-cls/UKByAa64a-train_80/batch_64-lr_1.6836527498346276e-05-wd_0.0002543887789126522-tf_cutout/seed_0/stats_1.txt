"main_optuna_fix_3.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3_early_loss --binary_class True --run_where lab --early_criteria loss"
{"epoch": 0, "training_loss": 55.28119468688965, "training_acc": 53.75, "val_loss": 14.002623558044434, "val_acc": 50.0, "val_auroc": 0.52, "time": 10.0}
{"epoch": 1, "training_loss": 55.670576095581055, "training_acc": 53.75, "val_loss": 13.909271955490112, "val_acc": 50.0, "val_auroc": 0.66, "time": 21.11}
{"epoch": 2, "training_loss": 55.21784019470215, "training_acc": 53.75, "val_loss": 13.97994875907898, "val_acc": 50.0, "val_auroc": 0.58, "time": 30.67}
{"epoch": 3, "training_loss": 55.224114418029785, "training_acc": 53.75, "val_loss": 13.950423002243042, "val_acc": 50.0, "val_auroc": 0.55, "time": 39.67}
{"epoch": 4, "training_loss": 55.238816261291504, "training_acc": 53.75, "val_loss": 13.86617660522461, "val_acc": 50.0, "val_auroc": 0.59, "time": 49.06}
{"epoch": 5, "training_loss": 55.047701835632324, "training_acc": 53.75, "val_loss": 13.839691877365112, "val_acc": 50.0, "val_auroc": 0.53, "time": 58.37}
{"epoch": 6, "training_loss": 54.96485900878906, "training_acc": 55.0, "val_loss": 13.918014764785767, "val_acc": 50.0, "val_auroc": 0.48, "time": 67.38}
{"epoch": 7, "training_loss": 54.65224647521973, "training_acc": 53.75, "val_loss": 14.055454730987549, "val_acc": 50.0, "val_auroc": 0.47, "time": 76.45}
{"epoch": 8, "training_loss": 54.70615005493164, "training_acc": 53.75, "val_loss": 13.878085613250732, "val_acc": 50.0, "val_auroc": 0.51, "time": 85.53}
{"epoch": 9, "training_loss": 54.25840377807617, "training_acc": 53.75, "val_loss": 13.812564611434937, "val_acc": 50.0, "val_auroc": 0.53, "time": 94.83}
{"epoch": 10, "training_loss": 54.88546657562256, "training_acc": 52.5, "val_loss": 13.814945220947266, "val_acc": 50.0, "val_auroc": 0.49, "time": 104.12}
{"epoch": 11, "training_loss": 54.31790542602539, "training_acc": 65.0, "val_loss": 14.002121686935425, "val_acc": 50.0, "val_auroc": 0.53, "time": 113.63}
{"epoch": 12, "training_loss": 54.686004638671875, "training_acc": 53.75, "val_loss": 14.268674850463867, "val_acc": 50.0, "val_auroc": 0.53, "time": 122.77}
{"epoch": 13, "training_loss": 54.736873626708984, "training_acc": 53.75, "val_loss": 13.922624588012695, "val_acc": 50.0, "val_auroc": 0.51, "time": 131.64}
{"epoch": 14, "training_loss": 54.68112659454346, "training_acc": 56.25, "val_loss": 13.939549922943115, "val_acc": 50.0, "val_auroc": 0.53, "time": 140.44}
{"epoch": 15, "training_loss": 53.825843811035156, "training_acc": 56.25, "val_loss": 14.18824553489685, "val_acc": 50.0, "val_auroc": 0.55, "time": 149.27}
{"epoch": 16, "training_loss": 55.358591079711914, "training_acc": 53.75, "val_loss": 13.891487121582031, "val_acc": 50.0, "val_auroc": 0.58, "time": 158.22}
{"epoch": 17, "training_loss": 54.03100776672363, "training_acc": 53.75, "val_loss": 13.819299936294556, "val_acc": 50.0, "val_auroc": 0.59, "time": 166.84}
{"epoch": 18, "training_loss": 54.28287315368652, "training_acc": 53.75, "val_loss": 13.812566995620728, "val_acc": 50.0, "val_auroc": 0.57, "time": 175.82}
{"epoch": 19, "training_loss": 53.44977283477783, "training_acc": 62.5, "val_loss": 13.719595670700073, "val_acc": 50.0, "val_auroc": 0.55, "time": 184.84}
{"epoch": 20, "training_loss": 53.80216026306152, "training_acc": 61.25, "val_loss": 13.760827779769897, "val_acc": 50.0, "val_auroc": 0.53, "time": 195.15}
{"epoch": 21, "training_loss": 53.7213020324707, "training_acc": 60.0, "val_loss": 14.073108434677124, "val_acc": 50.0, "val_auroc": 0.59, "time": 203.92}
{"epoch": 22, "training_loss": 52.89793586730957, "training_acc": 57.5, "val_loss": 14.92078423500061, "val_acc": 50.0, "val_auroc": 0.59, "time": 213.21}
{"epoch": 23, "training_loss": 52.47467231750488, "training_acc": 60.0, "val_loss": 13.696354627609253, "val_acc": 50.0, "val_auroc": 0.59, "time": 222.49}
{"epoch": 24, "training_loss": 52.02749538421631, "training_acc": 62.5, "val_loss": 13.618837594985962, "val_acc": 50.0, "val_auroc": 0.58, "time": 231.75}
{"epoch": 25, "training_loss": 51.23373794555664, "training_acc": 70.0, "val_loss": 14.055200815200806, "val_acc": 50.0, "val_auroc": 0.58, "time": 240.92}
{"epoch": 26, "training_loss": 52.332096099853516, "training_acc": 56.25, "val_loss": 14.064744710922241, "val_acc": 50.0, "val_auroc": 0.58, "time": 249.9}
{"epoch": 27, "training_loss": 52.172874450683594, "training_acc": 55.0, "val_loss": 13.511189222335815, "val_acc": 50.0, "val_auroc": 0.63, "time": 259.46}
{"epoch": 28, "training_loss": 52.26424026489258, "training_acc": 63.75, "val_loss": 13.401848077774048, "val_acc": 50.0, "val_auroc": 0.64, "time": 268.75}
{"epoch": 29, "training_loss": 51.072547912597656, "training_acc": 76.25, "val_loss": 13.56712818145752, "val_acc": 50.0, "val_auroc": 0.69, "time": 277.66}
{"epoch": 30, "training_loss": 50.217780113220215, "training_acc": 66.25, "val_loss": 16.765129566192627, "val_acc": 50.0, "val_auroc": 0.68, "time": 286.56}
{"epoch": 31, "training_loss": 57.02809524536133, "training_acc": 53.75, "val_loss": 13.866413831710815, "val_acc": 50.0, "val_auroc": 0.67, "time": 295.44}
{"epoch": 32, "training_loss": 47.19973564147949, "training_acc": 67.5, "val_loss": 13.734655380249023, "val_acc": 50.0, "val_auroc": 0.69, "time": 304.41}
{"epoch": 33, "training_loss": 54.28963661193848, "training_acc": 50.0, "val_loss": 13.517259359359741, "val_acc": 50.0, "val_auroc": 0.7, "time": 313.08}
{"epoch": 34, "training_loss": 51.321624755859375, "training_acc": 62.5, "val_loss": 14.18961763381958, "val_acc": 50.0, "val_auroc": 0.73, "time": 322.35}
{"epoch": 35, "training_loss": 50.26598834991455, "training_acc": 62.5, "val_loss": 14.191293716430664, "val_acc": 50.0, "val_auroc": 0.72, "time": 332.86}
{"epoch": 36, "training_loss": 48.9154691696167, "training_acc": 62.5, "val_loss": 13.526195287704468, "val_acc": 60.0, "val_auroc": 0.73, "time": 342.13}
{"epoch": 37, "training_loss": 52.470659255981445, "training_acc": 61.25, "val_loss": 14.443068504333496, "val_acc": 55.0, "val_auroc": 0.75, "time": 350.92}
{"epoch": 38, "training_loss": 57.34012794494629, "training_acc": 46.25, "val_loss": 13.902009725570679, "val_acc": 50.0, "val_auroc": 0.75, "time": 359.66}
{"epoch": 39, "training_loss": 54.742204666137695, "training_acc": 50.0, "val_loss": 13.586500883102417, "val_acc": 50.0, "val_auroc": 0.71, "time": 368.4}
{"epoch": 40, "training_loss": 52.00607109069824, "training_acc": 58.75, "val_loss": 14.374048709869385, "val_acc": 50.0, "val_auroc": 0.71, "time": 377.22}
{"epoch": 41, "training_loss": 53.3669376373291, "training_acc": 53.75, "val_loss": 14.576311111450195, "val_acc": 50.0, "val_auroc": 0.69, "time": 386.29}
{"epoch": 42, "training_loss": 53.634620666503906, "training_acc": 53.75, "val_loss": 13.698161840438843, "val_acc": 50.0, "val_auroc": 0.71, "time": 394.98}
{"epoch": 43, "training_loss": 50.14795780181885, "training_acc": 68.75, "val_loss": 13.490544557571411, "val_acc": 50.0, "val_auroc": 0.68, "time": 404.17}
{"epoch": 44, "training_loss": 49.4833402633667, "training_acc": 81.25, "val_loss": 13.443292379379272, "val_acc": 50.0, "val_auroc": 0.67, "time": 412.87}
{"epoch": 45, "training_loss": 50.09883785247803, "training_acc": 66.25, "val_loss": 13.77670168876648, "val_acc": 50.0, "val_auroc": 0.66, "time": 421.42}
{"epoch": 46, "training_loss": 48.29652214050293, "training_acc": 58.75, "val_loss": 13.735077381134033, "val_acc": 55.0, "val_auroc": 0.66, "time": 430.16}
{"epoch": 47, "training_loss": 47.092933654785156, "training_acc": 66.25, "val_loss": 13.622064590454102, "val_acc": 55.0, "val_auroc": 0.64, "time": 438.86}
