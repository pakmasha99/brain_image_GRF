"main_optuna_fix_3.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3_early_loss --binary_class True --run_where lab --early_criteria loss"
{"epoch": 0, "training_loss": 56.01457214355469, "training_acc": 53.75, "val_loss": 13.929833173751831, "val_acc": 50.0, "val_auroc": 0.78, "time": 17.73}
{"epoch": 1, "training_loss": 56.5444393157959, "training_acc": 43.75, "val_loss": 13.987665176391602, "val_acc": 50.0, "val_auroc": 0.17, "time": 26.98}
{"epoch": 2, "training_loss": 55.275020599365234, "training_acc": 53.75, "val_loss": 13.881818056106567, "val_acc": 50.0, "val_auroc": 0.63, "time": 36.79}
{"epoch": 3, "training_loss": 55.28982353210449, "training_acc": 53.75, "val_loss": 13.874725103378296, "val_acc": 50.0, "val_auroc": 0.72, "time": 46.81}
{"epoch": 4, "training_loss": 55.310184478759766, "training_acc": 53.75, "val_loss": 13.87865662574768, "val_acc": 50.0, "val_auroc": 0.53, "time": 56.4}
{"epoch": 5, "training_loss": 55.3835563659668, "training_acc": 53.75, "val_loss": 13.865004777908325, "val_acc": 50.0, "val_auroc": 0.48, "time": 66.17}
{"epoch": 6, "training_loss": 55.40087127685547, "training_acc": 51.25, "val_loss": 13.874701261520386, "val_acc": 50.0, "val_auroc": 0.27, "time": 75.61}
{"epoch": 7, "training_loss": 55.44841957092285, "training_acc": 53.75, "val_loss": 13.893119096755981, "val_acc": 50.0, "val_auroc": 0.65, "time": 85.07}
{"epoch": 8, "training_loss": 55.237897872924805, "training_acc": 53.75, "val_loss": 13.871973752975464, "val_acc": 50.0, "val_auroc": 0.33, "time": 94.18}
{"epoch": 9, "training_loss": 55.309560775756836, "training_acc": 53.75, "val_loss": 13.870313167572021, "val_acc": 50.0, "val_auroc": 0.56, "time": 103.32}
{"epoch": 10, "training_loss": 55.31037616729736, "training_acc": 53.75, "val_loss": 13.903454542160034, "val_acc": 50.0, "val_auroc": 0.43, "time": 112.77}
{"epoch": 11, "training_loss": 55.190064430236816, "training_acc": 53.75, "val_loss": 14.039397239685059, "val_acc": 50.0, "val_auroc": 0.31, "time": 122.0}
{"epoch": 12, "training_loss": 55.33259201049805, "training_acc": 53.75, "val_loss": 14.21407699584961, "val_acc": 50.0, "val_auroc": 0.34, "time": 133.75}
{"epoch": 13, "training_loss": 55.77495574951172, "training_acc": 53.75, "val_loss": 14.296313524246216, "val_acc": 50.0, "val_auroc": 0.38, "time": 143.2}
{"epoch": 14, "training_loss": 56.039669036865234, "training_acc": 53.75, "val_loss": 14.40015435218811, "val_acc": 50.0, "val_auroc": 0.51, "time": 152.08}
{"epoch": 15, "training_loss": 56.20386028289795, "training_acc": 53.75, "val_loss": 14.400573968887329, "val_acc": 50.0, "val_auroc": 0.47, "time": 161.73}
{"epoch": 16, "training_loss": 56.225494384765625, "training_acc": 53.75, "val_loss": 14.195177555084229, "val_acc": 50.0, "val_auroc": 0.48, "time": 170.88}
{"epoch": 17, "training_loss": 55.60495948791504, "training_acc": 53.75, "val_loss": 13.96704912185669, "val_acc": 50.0, "val_auroc": 0.58, "time": 179.96}
{"epoch": 18, "training_loss": 55.39680480957031, "training_acc": 53.75, "val_loss": 13.88124704360962, "val_acc": 50.0, "val_auroc": 0.56, "time": 189.72}
{"epoch": 19, "training_loss": 55.37269401550293, "training_acc": 53.75, "val_loss": 13.863420486450195, "val_acc": 50.0, "val_auroc": 0.56, "time": 199.22}
{"epoch": 20, "training_loss": 55.36536407470703, "training_acc": 56.25, "val_loss": 13.892583847045898, "val_acc": 50.0, "val_auroc": 0.47, "time": 208.51}
{"epoch": 21, "training_loss": 55.99355220794678, "training_acc": 46.25, "val_loss": 13.879728317260742, "val_acc": 50.0, "val_auroc": 0.36, "time": 218.15}
{"epoch": 22, "training_loss": 55.55998516082764, "training_acc": 46.25, "val_loss": 13.904672861099243, "val_acc": 50.0, "val_auroc": 0.39, "time": 227.91}
{"epoch": 23, "training_loss": 55.33037185668945, "training_acc": 53.75, "val_loss": 14.133923053741455, "val_acc": 50.0, "val_auroc": 0.27, "time": 237.51}
{"epoch": 24, "training_loss": 55.59911918640137, "training_acc": 53.75, "val_loss": 14.172444343566895, "val_acc": 50.0, "val_auroc": 0.32, "time": 246.9}
{"epoch": 25, "training_loss": 55.58915710449219, "training_acc": 53.75, "val_loss": 14.021611213684082, "val_acc": 50.0, "val_auroc": 0.31, "time": 256.18}
{"epoch": 26, "training_loss": 55.33989143371582, "training_acc": 53.75, "val_loss": 13.906066417694092, "val_acc": 50.0, "val_auroc": 0.64, "time": 265.15}
{"epoch": 27, "training_loss": 55.3099365234375, "training_acc": 53.75, "val_loss": 13.88471245765686, "val_acc": 50.0, "val_auroc": 0.52, "time": 274.59}
{"epoch": 28, "training_loss": 55.30378532409668, "training_acc": 53.75, "val_loss": 13.88898491859436, "val_acc": 50.0, "val_auroc": 0.66, "time": 283.59}
{"epoch": 29, "training_loss": 55.258734703063965, "training_acc": 53.75, "val_loss": 13.88630747795105, "val_acc": 50.0, "val_auroc": 0.45, "time": 293.33}
{"epoch": 30, "training_loss": 55.2491569519043, "training_acc": 53.75, "val_loss": 13.908601999282837, "val_acc": 50.0, "val_auroc": 0.39, "time": 302.85}
{"epoch": 31, "training_loss": 55.24766445159912, "training_acc": 53.75, "val_loss": 13.9364755153656, "val_acc": 50.0, "val_auroc": 0.45, "time": 312.4}
{"epoch": 32, "training_loss": 55.23519706726074, "training_acc": 53.75, "val_loss": 13.925838470458984, "val_acc": 50.0, "val_auroc": 0.29, "time": 322.25}
{"epoch": 33, "training_loss": 55.267173767089844, "training_acc": 53.75, "val_loss": 13.923401832580566, "val_acc": 50.0, "val_auroc": 0.34, "time": 331.39}
{"epoch": 34, "training_loss": 55.21687889099121, "training_acc": 53.75, "val_loss": 13.977464437484741, "val_acc": 50.0, "val_auroc": 0.39, "time": 340.73}
{"epoch": 35, "training_loss": 55.366065979003906, "training_acc": 53.75, "val_loss": 14.00760293006897, "val_acc": 50.0, "val_auroc": 0.4, "time": 349.97}
{"epoch": 36, "training_loss": 55.283607482910156, "training_acc": 53.75, "val_loss": 13.929675817489624, "val_acc": 50.0, "val_auroc": 0.4, "time": 358.82}
{"epoch": 37, "training_loss": 55.16366767883301, "training_acc": 53.75, "val_loss": 13.867005109786987, "val_acc": 50.0, "val_auroc": 0.56, "time": 367.55}
{"epoch": 38, "training_loss": 55.42137813568115, "training_acc": 51.25, "val_loss": 13.873485326766968, "val_acc": 50.0, "val_auroc": 0.5, "time": 376.82}
