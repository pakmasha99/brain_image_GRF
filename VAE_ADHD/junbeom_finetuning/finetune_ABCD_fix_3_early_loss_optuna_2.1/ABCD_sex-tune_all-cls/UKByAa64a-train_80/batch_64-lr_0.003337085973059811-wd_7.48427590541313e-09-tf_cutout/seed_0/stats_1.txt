"main_optuna_fix_3.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3_early_loss --binary_class True --run_where lab --early_criteria loss"
{"epoch": 0, "training_loss": 115.02525329589844, "training_acc": 53.75, "val_loss": 62350.6103515625, "val_acc": 50.0, "val_auroc": 0.34, "time": 10.19}
{"epoch": 1, "training_loss": 359744.8125, "training_acc": 46.25, "val_loss": 62.32964515686035, "val_acc": 50.0, "val_auroc": 0.69, "time": 19.16}
{"epoch": 2, "training_loss": 229.25308227539062, "training_acc": 46.25, "val_loss": 15.855987071990967, "val_acc": 50.0, "val_auroc": 0.38, "time": 27.9}
{"epoch": 3, "training_loss": 73.671630859375, "training_acc": 53.75, "val_loss": 130.90853691101074, "val_acc": 50.0, "val_auroc": 0.34, "time": 37.06}
{"epoch": 4, "training_loss": 406.04156494140625, "training_acc": 53.75, "val_loss": 73.22290897369385, "val_acc": 50.0, "val_auroc": 0.67, "time": 45.88}
{"epoch": 5, "training_loss": 277.0669803619385, "training_acc": 46.25, "val_loss": 14.322662353515625, "val_acc": 50.0, "val_auroc": 0.47, "time": 54.77}
{"epoch": 6, "training_loss": 55.96120262145996, "training_acc": 53.75, "val_loss": 14.179277420043945, "val_acc": 50.0, "val_auroc": 0.53, "time": 63.74}
{"epoch": 7, "training_loss": 68.27736282348633, "training_acc": 51.25, "val_loss": 31.670682430267334, "val_acc": 50.0, "val_auroc": 0.42, "time": 73.04}
{"epoch": 8, "training_loss": 108.08651733398438, "training_acc": 53.75, "val_loss": 14.18044924736023, "val_acc": 50.0, "val_auroc": 0.7, "time": 82.26}
{"epoch": 9, "training_loss": 58.0272741317749, "training_acc": 46.25, "val_loss": 14.112132787704468, "val_acc": 50.0, "val_auroc": 0.68, "time": 91.95}
{"epoch": 10, "training_loss": 57.16180229187012, "training_acc": 48.75, "val_loss": 13.893388509750366, "val_acc": 50.0, "val_auroc": 0.69, "time": 100.88}
{"epoch": 11, "training_loss": 55.75306034088135, "training_acc": 48.75, "val_loss": 15.61642050743103, "val_acc": 50.0, "val_auroc": 0.58, "time": 109.62}
{"epoch": 12, "training_loss": 62.106651306152344, "training_acc": 51.25, "val_loss": 14.72895860671997, "val_acc": 50.0, "val_auroc": 0.56, "time": 118.18}
{"epoch": 13, "training_loss": 57.1370735168457, "training_acc": 53.75, "val_loss": 14.091914892196655, "val_acc": 50.0, "val_auroc": 0.63, "time": 127.15}
{"epoch": 14, "training_loss": 57.27187156677246, "training_acc": 46.25, "val_loss": 14.841536283493042, "val_acc": 50.0, "val_auroc": 0.56, "time": 135.9}
{"epoch": 15, "training_loss": 57.48956108093262, "training_acc": 53.75, "val_loss": 14.698936939239502, "val_acc": 50.0, "val_auroc": 0.48, "time": 145.03}
{"epoch": 16, "training_loss": 57.76483154296875, "training_acc": 48.75, "val_loss": 13.859844207763672, "val_acc": 50.0, "val_auroc": 0.6, "time": 154.36}
{"epoch": 17, "training_loss": 55.85178565979004, "training_acc": 53.75, "val_loss": 13.913729190826416, "val_acc": 50.0, "val_auroc": 0.73, "time": 163.33}
{"epoch": 18, "training_loss": 55.4290657043457, "training_acc": 51.25, "val_loss": 13.8605797290802, "val_acc": 50.0, "val_auroc": 0.73, "time": 172.14}
{"epoch": 19, "training_loss": 55.833024978637695, "training_acc": 53.75, "val_loss": 13.862322568893433, "val_acc": 50.0, "val_auroc": 0.68, "time": 181.24}
{"epoch": 20, "training_loss": 55.36821937561035, "training_acc": 53.75, "val_loss": 13.86203408241272, "val_acc": 50.0, "val_auroc": 0.7, "time": 189.82}
{"epoch": 21, "training_loss": 55.43766689300537, "training_acc": 51.25, "val_loss": 14.505199193954468, "val_acc": 50.0, "val_auroc": 0.71, "time": 198.83}
{"epoch": 22, "training_loss": 56.611148834228516, "training_acc": 53.75, "val_loss": 14.417846202850342, "val_acc": 50.0, "val_auroc": 0.72, "time": 207.78}
{"epoch": 23, "training_loss": 56.434813499450684, "training_acc": 53.75, "val_loss": 14.072240591049194, "val_acc": 50.0, "val_auroc": 0.7, "time": 216.42}
{"epoch": 24, "training_loss": 55.58758354187012, "training_acc": 53.75, "val_loss": 14.045177698135376, "val_acc": 50.0, "val_auroc": 0.71, "time": 224.94}
{"epoch": 25, "training_loss": 55.3817024230957, "training_acc": 53.75, "val_loss": 14.029381275177002, "val_acc": 50.0, "val_auroc": 0.72, "time": 234.26}
{"epoch": 26, "training_loss": 55.33369064331055, "training_acc": 53.75, "val_loss": 13.909046649932861, "val_acc": 50.0, "val_auroc": 0.72, "time": 243.01}
{"epoch": 27, "training_loss": 55.26576042175293, "training_acc": 53.75, "val_loss": 13.899470567703247, "val_acc": 50.0, "val_auroc": 0.72, "time": 251.89}
{"epoch": 28, "training_loss": 55.59315872192383, "training_acc": 53.75, "val_loss": 13.863154649734497, "val_acc": 50.0, "val_auroc": 0.7, "time": 260.77}
{"epoch": 29, "training_loss": 55.529958724975586, "training_acc": 51.25, "val_loss": 13.8784658908844, "val_acc": 50.0, "val_auroc": 0.7, "time": 269.41}
{"epoch": 30, "training_loss": 55.69526672363281, "training_acc": 46.25, "val_loss": 13.894809484481812, "val_acc": 50.0, "val_auroc": 0.72, "time": 277.97}
{"epoch": 31, "training_loss": 55.20376110076904, "training_acc": 53.75, "val_loss": 14.186294078826904, "val_acc": 50.0, "val_auroc": 0.55, "time": 287.04}
{"epoch": 32, "training_loss": 55.809757232666016, "training_acc": 53.75, "val_loss": 14.101438522338867, "val_acc": 50.0, "val_auroc": 0.62, "time": 298.13}
{"epoch": 33, "training_loss": 55.442782402038574, "training_acc": 53.75, "val_loss": 13.879257440567017, "val_acc": 50.0, "val_auroc": 0.69, "time": 307.14}
{"epoch": 34, "training_loss": 55.29099464416504, "training_acc": 53.75, "val_loss": 13.897355794906616, "val_acc": 50.0, "val_auroc": 0.58, "time": 315.57}
{"epoch": 35, "training_loss": 55.7098331451416, "training_acc": 53.75, "val_loss": 13.87568712234497, "val_acc": 50.0, "val_auroc": 0.77, "time": 324.24}
