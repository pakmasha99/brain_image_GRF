"main_optuna_fix_3.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3_early_loss --binary_class True --run_where lab --early_criteria loss"
{"epoch": 0, "training_loss": 111.2275161743164, "training_acc": 45.0, "val_loss": 29571327.5, "val_acc": 55.0, "val_auroc": 0.596, "time": 10.34}
{"epoch": 1, "training_loss": 106267566.49487305, "training_acc": 45.0, "val_loss": 15473.62548828125, "val_acc": 55.0, "val_auroc": 0.616, "time": 19.77}
{"epoch": 2, "training_loss": 9847985.578125, "training_acc": 45.0, "val_loss": 920.7830810546875, "val_acc": 45.0, "val_auroc": 0.364, "time": 29.09}
{"epoch": 3, "training_loss": 2917.4310913085938, "training_acc": 47.5, "val_loss": 281.170654296875, "val_acc": 55.0, "val_auroc": 0.697, "time": 38.46}
{"epoch": 4, "training_loss": 1181.5581970214844, "training_acc": 52.5, "val_loss": 13.87776494026184, "val_acc": 55.0, "val_auroc": 0.803, "time": 47.9}
{"epoch": 5, "training_loss": 600.4386825561523, "training_acc": 52.5, "val_loss": 113.50113868713379, "val_acc": 45.0, "val_auroc": 0.384, "time": 56.7}
{"epoch": 6, "training_loss": 725.9125671386719, "training_acc": 50.0, "val_loss": 375.5809020996094, "val_acc": 55.0, "val_auroc": 0.626, "time": 65.92}
{"epoch": 7, "training_loss": 1369.1693115234375, "training_acc": 52.5, "val_loss": 14.008592367172241, "val_acc": 55.0, "val_auroc": 0.485, "time": 74.89}
{"epoch": 8, "training_loss": 73.81168174743652, "training_acc": 46.25, "val_loss": 16.299701929092407, "val_acc": 55.0, "val_auroc": 0.687, "time": 83.64}
{"epoch": 9, "training_loss": 82.45506477355957, "training_acc": 45.0, "val_loss": 39.59110975265503, "val_acc": 55.0, "val_auroc": 0.616, "time": 92.39}
{"epoch": 10, "training_loss": 150.42792129516602, "training_acc": 52.5, "val_loss": 26.314220428466797, "val_acc": 45.0, "val_auroc": 0.414, "time": 101.48}
{"epoch": 11, "training_loss": 95.3985824584961, "training_acc": 47.5, "val_loss": 17.266536951065063, "val_acc": 55.0, "val_auroc": 0.566, "time": 112.47}
{"epoch": 12, "training_loss": 72.32728576660156, "training_acc": 52.5, "val_loss": 13.839939832687378, "val_acc": 55.0, "val_auroc": 0.737, "time": 122.06}
{"epoch": 13, "training_loss": 56.88486099243164, "training_acc": 53.75, "val_loss": 14.578021764755249, "val_acc": 55.0, "val_auroc": 0.737, "time": 130.97}
{"epoch": 14, "training_loss": 61.790268898010254, "training_acc": 42.5, "val_loss": 14.044374227523804, "val_acc": 55.0, "val_auroc": 0.626, "time": 139.91}
{"epoch": 15, "training_loss": 57.24728584289551, "training_acc": 47.5, "val_loss": 13.76827359199524, "val_acc": 55.0, "val_auroc": 0.707, "time": 149.47}
{"epoch": 16, "training_loss": 54.32888984680176, "training_acc": 52.5, "val_loss": 17.71816611289978, "val_acc": 55.0, "val_auroc": 0.646, "time": 158.21}
{"epoch": 17, "training_loss": 70.18893432617188, "training_acc": 52.5, "val_loss": 16.965343952178955, "val_acc": 45.0, "val_auroc": 0.444, "time": 167.37}
{"epoch": 18, "training_loss": 64.96730613708496, "training_acc": 47.5, "val_loss": 13.944653272628784, "val_acc": 55.0, "val_auroc": 0.657, "time": 176.53}
{"epoch": 19, "training_loss": 56.274269104003906, "training_acc": 45.0, "val_loss": 13.771337270736694, "val_acc": 55.0, "val_auroc": 0.576, "time": 185.4}
{"epoch": 20, "training_loss": 55.51519298553467, "training_acc": 52.5, "val_loss": 13.854764699935913, "val_acc": 55.0, "val_auroc": 0.545, "time": 194.28}
{"epoch": 21, "training_loss": 55.474740982055664, "training_acc": 45.0, "val_loss": 13.787055015563965, "val_acc": 55.0, "val_auroc": 0.495, "time": 203.5}
{"epoch": 22, "training_loss": 55.39536666870117, "training_acc": 52.5, "val_loss": 13.758105039596558, "val_acc": 55.0, "val_auroc": 0.556, "time": 212.64}
{"epoch": 23, "training_loss": 55.61712646484375, "training_acc": 52.5, "val_loss": 13.76139760017395, "val_acc": 55.0, "val_auroc": 0.485, "time": 221.51}
{"epoch": 24, "training_loss": 55.53020477294922, "training_acc": 52.5, "val_loss": 13.76500129699707, "val_acc": 55.0, "val_auroc": 0.455, "time": 230.67}
{"epoch": 25, "training_loss": 55.86124324798584, "training_acc": 50.0, "val_loss": 13.762532472610474, "val_acc": 55.0, "val_auroc": 0.475, "time": 239.76}
{"epoch": 26, "training_loss": 55.353299140930176, "training_acc": 52.5, "val_loss": 13.840492963790894, "val_acc": 55.0, "val_auroc": 0.505, "time": 248.63}
{"epoch": 27, "training_loss": 55.92878532409668, "training_acc": 52.5, "val_loss": 13.761539459228516, "val_acc": 55.0, "val_auroc": 0.505, "time": 257.72}
{"epoch": 28, "training_loss": 55.37107276916504, "training_acc": 50.0, "val_loss": 14.071944952011108, "val_acc": 55.0, "val_auroc": 0.424, "time": 266.74}
{"epoch": 29, "training_loss": 56.39569664001465, "training_acc": 47.5, "val_loss": 13.816055059432983, "val_acc": 55.0, "val_auroc": 0.576, "time": 275.86}
{"epoch": 30, "training_loss": 55.52293014526367, "training_acc": 52.5, "val_loss": 13.941487073898315, "val_acc": 55.0, "val_auroc": 0.505, "time": 284.83}
{"epoch": 31, "training_loss": 56.7731351852417, "training_acc": 52.5, "val_loss": 13.791942596435547, "val_acc": 55.0, "val_auroc": 0.596, "time": 293.65}
{"epoch": 32, "training_loss": 56.06316089630127, "training_acc": 52.5, "val_loss": 13.884830474853516, "val_acc": 55.0, "val_auroc": 0.737, "time": 302.63}
{"epoch": 33, "training_loss": 55.51360321044922, "training_acc": 47.5, "val_loss": 13.937013149261475, "val_acc": 55.0, "val_auroc": 0.657, "time": 311.81}
{"epoch": 34, "training_loss": 55.58707809448242, "training_acc": 47.5, "val_loss": 13.808897733688354, "val_acc": 55.0, "val_auroc": 0.616, "time": 320.49}
{"epoch": 35, "training_loss": 55.31497764587402, "training_acc": 52.5, "val_loss": 13.763620853424072, "val_acc": 55.0, "val_auroc": 0.697, "time": 329.38}
{"epoch": 36, "training_loss": 55.52400207519531, "training_acc": 52.5, "val_loss": 13.802412748336792, "val_acc": 55.0, "val_auroc": 0.616, "time": 338.57}
{"epoch": 37, "training_loss": 55.87569618225098, "training_acc": 52.5, "val_loss": 13.81531834602356, "val_acc": 55.0, "val_auroc": 0.657, "time": 347.35}
{"epoch": 38, "training_loss": 55.957794189453125, "training_acc": 52.5, "val_loss": 13.763707876205444, "val_acc": 55.0, "val_auroc": 0.727, "time": 356.21}
{"epoch": 39, "training_loss": 55.65090274810791, "training_acc": 52.5, "val_loss": 13.769370317459106, "val_acc": 55.0, "val_auroc": 0.778, "time": 365.46}
{"epoch": 40, "training_loss": 55.38394546508789, "training_acc": 52.5, "val_loss": 13.769683837890625, "val_acc": 55.0, "val_auroc": 0.747, "time": 374.34}
{"epoch": 41, "training_loss": 55.34816551208496, "training_acc": 52.5, "val_loss": 13.78652572631836, "val_acc": 55.0, "val_auroc": 0.727, "time": 383.01}
