"main_optuna_fix_3.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3_early_loss --binary_class True --run_where lab --early_criteria loss"
{"epoch": 0, "training_loss": 115.58232498168945, "training_acc": 50.0, "val_loss": 20381.91650390625, "val_acc": 55.0, "val_auroc": 0.414, "time": 10.45}
{"epoch": 1, "training_loss": 164743.3125, "training_acc": 45.0, "val_loss": 31.11832857131958, "val_acc": 45.0, "val_auroc": 0.556, "time": 20.34}
{"epoch": 2, "training_loss": 105.88407707214355, "training_acc": 47.5, "val_loss": 69.13017272949219, "val_acc": 55.0, "val_auroc": 0.525, "time": 29.65}
{"epoch": 3, "training_loss": 292.76269912719727, "training_acc": 52.5, "val_loss": 16.719566583633423, "val_acc": 55.0, "val_auroc": 0.566, "time": 38.6}
{"epoch": 4, "training_loss": 68.4003849029541, "training_acc": 52.5, "val_loss": 32.17479705810547, "val_acc": 45.0, "val_auroc": 0.576, "time": 47.9}
{"epoch": 5, "training_loss": 120.66518974304199, "training_acc": 50.0, "val_loss": 19.970474243164062, "val_acc": 55.0, "val_auroc": 0.434, "time": 56.76}
{"epoch": 6, "training_loss": 78.72805595397949, "training_acc": 52.5, "val_loss": 15.010074377059937, "val_acc": 45.0, "val_auroc": 0.626, "time": 66.08}
{"epoch": 7, "training_loss": 58.596317291259766, "training_acc": 47.5, "val_loss": 14.312407970428467, "val_acc": 55.0, "val_auroc": 0.404, "time": 75.75}
{"epoch": 8, "training_loss": 56.17006301879883, "training_acc": 57.5, "val_loss": 25.280468463897705, "val_acc": 45.0, "val_auroc": 0.596, "time": 84.7}
{"epoch": 9, "training_loss": 89.22322750091553, "training_acc": 47.5, "val_loss": 14.402580261230469, "val_acc": 55.0, "val_auroc": 0.384, "time": 93.34}
{"epoch": 10, "training_loss": 58.87202453613281, "training_acc": 52.5, "val_loss": 13.850353956222534, "val_acc": 55.0, "val_auroc": 0.475, "time": 102.75}
{"epoch": 11, "training_loss": 56.69422721862793, "training_acc": 47.5, "val_loss": 14.029338359832764, "val_acc": 55.0, "val_auroc": 0.727, "time": 111.55}
{"epoch": 12, "training_loss": 56.738075256347656, "training_acc": 52.5, "val_loss": 14.861387014389038, "val_acc": 55.0, "val_auroc": 0.646, "time": 120.25}
{"epoch": 13, "training_loss": 58.233909606933594, "training_acc": 47.5, "val_loss": 13.96296739578247, "val_acc": 55.0, "val_auroc": 0.434, "time": 129.24}
{"epoch": 14, "training_loss": 57.73983955383301, "training_acc": 52.5, "val_loss": 13.816956281661987, "val_acc": 55.0, "val_auroc": 0.556, "time": 138.31}
{"epoch": 15, "training_loss": 57.41571807861328, "training_acc": 45.0, "val_loss": 13.934236764907837, "val_acc": 55.0, "val_auroc": 0.545, "time": 147.06}
{"epoch": 16, "training_loss": 54.76882743835449, "training_acc": 57.5, "val_loss": 14.8345947265625, "val_acc": 55.0, "val_auroc": 0.424, "time": 156.06}
{"epoch": 17, "training_loss": 60.90288257598877, "training_acc": 52.5, "val_loss": 13.863292932510376, "val_acc": 55.0, "val_auroc": 0.525, "time": 165.02}
{"epoch": 18, "training_loss": 55.76693153381348, "training_acc": 52.5, "val_loss": 13.943562507629395, "val_acc": 55.0, "val_auroc": 0.485, "time": 174.03}
{"epoch": 19, "training_loss": 55.647841453552246, "training_acc": 47.5, "val_loss": 14.182937145233154, "val_acc": 55.0, "val_auroc": 0.394, "time": 184.83}
{"epoch": 20, "training_loss": 56.13662910461426, "training_acc": 47.5, "val_loss": 13.763827085494995, "val_acc": 55.0, "val_auroc": 0.687, "time": 194.61}
{"epoch": 21, "training_loss": 55.69399070739746, "training_acc": 52.5, "val_loss": 13.80172848701477, "val_acc": 55.0, "val_auroc": 0.677, "time": 203.41}
{"epoch": 22, "training_loss": 55.649067878723145, "training_acc": 50.0, "val_loss": 13.913079500198364, "val_acc": 55.0, "val_auroc": 0.697, "time": 212.77}
{"epoch": 23, "training_loss": 55.442800521850586, "training_acc": 50.0, "val_loss": 13.782732486724854, "val_acc": 55.0, "val_auroc": 0.374, "time": 221.9}
{"epoch": 24, "training_loss": 55.943246841430664, "training_acc": 52.5, "val_loss": 13.825064897537231, "val_acc": 55.0, "val_auroc": 0.424, "time": 231.08}
{"epoch": 25, "training_loss": 56.02804756164551, "training_acc": 52.5, "val_loss": 13.946981430053711, "val_acc": 55.0, "val_auroc": 0.414, "time": 240.13}
{"epoch": 26, "training_loss": 56.72204399108887, "training_acc": 52.5, "val_loss": 13.855403661727905, "val_acc": 55.0, "val_auroc": 0.404, "time": 249.26}
{"epoch": 27, "training_loss": 56.12989616394043, "training_acc": 52.5, "val_loss": 13.764816522598267, "val_acc": 55.0, "val_auroc": 0.444, "time": 258.19}
{"epoch": 28, "training_loss": 55.256309509277344, "training_acc": 52.5, "val_loss": 13.978922367095947, "val_acc": 55.0, "val_auroc": 0.616, "time": 267.84}
{"epoch": 29, "training_loss": 55.86004638671875, "training_acc": 47.5, "val_loss": 14.098023176193237, "val_acc": 55.0, "val_auroc": 0.606, "time": 277.17}
{"epoch": 30, "training_loss": 56.018948554992676, "training_acc": 47.5, "val_loss": 13.84528636932373, "val_acc": 55.0, "val_auroc": 0.566, "time": 286.85}
{"epoch": 31, "training_loss": 55.932058334350586, "training_acc": 52.5, "val_loss": 13.800246715545654, "val_acc": 55.0, "val_auroc": 0.515, "time": 295.76}
{"epoch": 32, "training_loss": 55.34456729888916, "training_acc": 52.5, "val_loss": 13.894450664520264, "val_acc": 55.0, "val_auroc": 0.586, "time": 304.52}
{"epoch": 33, "training_loss": 55.53853416442871, "training_acc": 47.5, "val_loss": 13.886836767196655, "val_acc": 55.0, "val_auroc": 0.596, "time": 313.99}
{"epoch": 34, "training_loss": 55.45842456817627, "training_acc": 50.0, "val_loss": 13.77820372581482, "val_acc": 55.0, "val_auroc": 0.414, "time": 323.41}
{"epoch": 35, "training_loss": 55.639169692993164, "training_acc": 52.5, "val_loss": 13.765586614608765, "val_acc": 55.0, "val_auroc": 0.394, "time": 332.61}
{"epoch": 36, "training_loss": 55.52992820739746, "training_acc": 52.5, "val_loss": 13.80467414855957, "val_acc": 55.0, "val_auroc": 0.444, "time": 342.67}
{"epoch": 37, "training_loss": 55.36759567260742, "training_acc": 52.5, "val_loss": 13.797463178634644, "val_acc": 55.0, "val_auroc": 0.414, "time": 351.76}
{"epoch": 38, "training_loss": 55.35496234893799, "training_acc": 52.5, "val_loss": 13.786413669586182, "val_acc": 55.0, "val_auroc": 0.424, "time": 360.88}
{"epoch": 39, "training_loss": 55.346306800842285, "training_acc": 52.5, "val_loss": 13.770750761032104, "val_acc": 55.0, "val_auroc": 0.424, "time": 370.51}
