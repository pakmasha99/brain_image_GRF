"main_optuna_fix_3.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3_early_loss --binary_class True --run_where lab --early_criteria loss"
{"epoch": 0, "training_loss": 55.28670692443848, "training_acc": 53.75, "val_loss": 14.003657102584839, "val_acc": 50.0, "val_auroc": 0.52, "time": 10.11}
{"epoch": 1, "training_loss": 55.68154716491699, "training_acc": 53.75, "val_loss": 13.89860987663269, "val_acc": 50.0, "val_auroc": 0.71, "time": 20.32}
{"epoch": 2, "training_loss": 55.181034088134766, "training_acc": 53.75, "val_loss": 13.985228538513184, "val_acc": 50.0, "val_auroc": 0.51, "time": 29.59}
{"epoch": 3, "training_loss": 55.204124450683594, "training_acc": 53.75, "val_loss": 13.943569660186768, "val_acc": 50.0, "val_auroc": 0.53, "time": 38.06}
{"epoch": 4, "training_loss": 55.21580219268799, "training_acc": 53.75, "val_loss": 13.88437032699585, "val_acc": 50.0, "val_auroc": 0.54, "time": 47.2}
{"epoch": 5, "training_loss": 55.10145092010498, "training_acc": 53.75, "val_loss": 13.847659826278687, "val_acc": 50.0, "val_auroc": 0.53, "time": 57.01}
{"epoch": 6, "training_loss": 54.95652484893799, "training_acc": 53.75, "val_loss": 13.928804397583008, "val_acc": 50.0, "val_auroc": 0.48, "time": 65.91}
{"epoch": 7, "training_loss": 54.75744152069092, "training_acc": 53.75, "val_loss": 14.076852798461914, "val_acc": 50.0, "val_auroc": 0.54, "time": 74.26}
{"epoch": 8, "training_loss": 54.78451919555664, "training_acc": 53.75, "val_loss": 13.827126026153564, "val_acc": 50.0, "val_auroc": 0.53, "time": 83.39}
{"epoch": 9, "training_loss": 54.11948585510254, "training_acc": 61.25, "val_loss": 13.82591962814331, "val_acc": 50.0, "val_auroc": 0.51, "time": 92.44}
{"epoch": 10, "training_loss": 55.02947235107422, "training_acc": 56.25, "val_loss": 13.853342533111572, "val_acc": 50.0, "val_auroc": 0.48, "time": 101.02}
{"epoch": 11, "training_loss": 54.04657173156738, "training_acc": 63.75, "val_loss": 14.404810667037964, "val_acc": 50.0, "val_auroc": 0.48, "time": 109.82}
{"epoch": 12, "training_loss": 55.163923263549805, "training_acc": 55.0, "val_loss": 14.225609302520752, "val_acc": 50.0, "val_auroc": 0.48, "time": 118.75}
{"epoch": 13, "training_loss": 54.25901222229004, "training_acc": 56.25, "val_loss": 13.877851963043213, "val_acc": 50.0, "val_auroc": 0.49, "time": 127.7}
{"epoch": 14, "training_loss": 54.622535705566406, "training_acc": 50.0, "val_loss": 13.935847282409668, "val_acc": 50.0, "val_auroc": 0.5, "time": 136.47}
{"epoch": 15, "training_loss": 53.556907653808594, "training_acc": 56.25, "val_loss": 14.447152614593506, "val_acc": 50.0, "val_auroc": 0.47, "time": 145.35}
{"epoch": 16, "training_loss": 55.721675872802734, "training_acc": 53.75, "val_loss": 14.05444860458374, "val_acc": 50.0, "val_auroc": 0.53, "time": 154.36}
{"epoch": 17, "training_loss": 54.16659641265869, "training_acc": 53.75, "val_loss": 13.93946647644043, "val_acc": 50.0, "val_auroc": 0.47, "time": 163.74}
{"epoch": 18, "training_loss": 54.490121841430664, "training_acc": 53.75, "val_loss": 13.823187351226807, "val_acc": 50.0, "val_auroc": 0.55, "time": 172.95}
{"epoch": 19, "training_loss": 53.450249671936035, "training_acc": 55.0, "val_loss": 13.87202501296997, "val_acc": 50.0, "val_auroc": 0.54, "time": 182.05}
{"epoch": 20, "training_loss": 53.47268295288086, "training_acc": 53.75, "val_loss": 13.945233821868896, "val_acc": 50.0, "val_auroc": 0.57, "time": 191.07}
{"epoch": 21, "training_loss": 52.971341133117676, "training_acc": 57.5, "val_loss": 13.947162628173828, "val_acc": 50.0, "val_auroc": 0.61, "time": 199.83}
{"epoch": 22, "training_loss": 52.38818359375, "training_acc": 60.0, "val_loss": 13.565939664840698, "val_acc": 50.0, "val_auroc": 0.64, "time": 208.88}
{"epoch": 23, "training_loss": 50.474496841430664, "training_acc": 70.0, "val_loss": 14.893602132797241, "val_acc": 50.0, "val_auroc": 0.64, "time": 219.74}
{"epoch": 24, "training_loss": 52.72926139831543, "training_acc": 52.5, "val_loss": 13.533624410629272, "val_acc": 50.0, "val_auroc": 0.66, "time": 229.41}
{"epoch": 25, "training_loss": 49.6350040435791, "training_acc": 68.75, "val_loss": 13.7511146068573, "val_acc": 50.0, "val_auroc": 0.64, "time": 238.79}
{"epoch": 26, "training_loss": 50.359914779663086, "training_acc": 61.25, "val_loss": 15.06290078163147, "val_acc": 50.0, "val_auroc": 0.65, "time": 247.69}
{"epoch": 27, "training_loss": 52.39024066925049, "training_acc": 56.25, "val_loss": 13.316125869750977, "val_acc": 50.0, "val_auroc": 0.66, "time": 256.66}
{"epoch": 28, "training_loss": 52.369479179382324, "training_acc": 66.25, "val_loss": 13.280502557754517, "val_acc": 50.0, "val_auroc": 0.67, "time": 265.72}
{"epoch": 29, "training_loss": 49.89406776428223, "training_acc": 75.0, "val_loss": 13.575667142868042, "val_acc": 50.0, "val_auroc": 0.65, "time": 274.58}
{"epoch": 30, "training_loss": 48.6614875793457, "training_acc": 66.25, "val_loss": 17.462135553359985, "val_acc": 50.0, "val_auroc": 0.69, "time": 283.48}
{"epoch": 31, "training_loss": 58.92182731628418, "training_acc": 55.0, "val_loss": 15.256437063217163, "val_acc": 50.0, "val_auroc": 0.69, "time": 292.67}
{"epoch": 32, "training_loss": 49.35386276245117, "training_acc": 61.25, "val_loss": 13.535537719726562, "val_acc": 50.0, "val_auroc": 0.67, "time": 301.5}
{"epoch": 33, "training_loss": 52.96269130706787, "training_acc": 58.75, "val_loss": 13.975046873092651, "val_acc": 55.0, "val_auroc": 0.67, "time": 310.43}
{"epoch": 34, "training_loss": 54.86372947692871, "training_acc": 46.25, "val_loss": 13.360515832901001, "val_acc": 50.0, "val_auroc": 0.69, "time": 319.1}
{"epoch": 35, "training_loss": 50.37234115600586, "training_acc": 71.25, "val_loss": 13.99911880493164, "val_acc": 50.0, "val_auroc": 0.68, "time": 327.95}
{"epoch": 36, "training_loss": 50.8878755569458, "training_acc": 56.25, "val_loss": 13.714677095413208, "val_acc": 50.0, "val_auroc": 0.71, "time": 337.0}
{"epoch": 37, "training_loss": 49.070311546325684, "training_acc": 63.75, "val_loss": 13.3134925365448, "val_acc": 50.0, "val_auroc": 0.72, "time": 346.34}
{"epoch": 38, "training_loss": 50.904075622558594, "training_acc": 67.5, "val_loss": 13.45656156539917, "val_acc": 50.0, "val_auroc": 0.71, "time": 355.0}
{"epoch": 39, "training_loss": 49.29513072967529, "training_acc": 70.0, "val_loss": 13.850847482681274, "val_acc": 50.0, "val_auroc": 0.69, "time": 363.63}
{"epoch": 40, "training_loss": 46.28644561767578, "training_acc": 66.25, "val_loss": 14.912505149841309, "val_acc": 50.0, "val_auroc": 0.69, "time": 372.72}
{"epoch": 41, "training_loss": 46.99432182312012, "training_acc": 65.0, "val_loss": 13.298171758651733, "val_acc": 50.0, "val_auroc": 0.68, "time": 381.8}
{"epoch": 42, "training_loss": 48.922677993774414, "training_acc": 72.5, "val_loss": 14.406291246414185, "val_acc": 55.0, "val_auroc": 0.64, "time": 390.47}
{"epoch": 43, "training_loss": 51.45728302001953, "training_acc": 60.0, "val_loss": 14.437097311019897, "val_acc": 50.0, "val_auroc": 0.68, "time": 399.46}
{"epoch": 44, "training_loss": 44.69444942474365, "training_acc": 68.75, "val_loss": 15.829743146896362, "val_acc": 50.0, "val_auroc": 0.68, "time": 408.5}
{"epoch": 45, "training_loss": 48.55856704711914, "training_acc": 63.75, "val_loss": 13.381892442703247, "val_acc": 50.0, "val_auroc": 0.65, "time": 417.09}
{"epoch": 46, "training_loss": 45.75610637664795, "training_acc": 76.25, "val_loss": 13.781250715255737, "val_acc": 60.0, "val_auroc": 0.61, "time": 425.76}
{"epoch": 47, "training_loss": 47.40668773651123, "training_acc": 68.75, "val_loss": 15.224932432174683, "val_acc": 50.0, "val_auroc": 0.63, "time": 435.05}
