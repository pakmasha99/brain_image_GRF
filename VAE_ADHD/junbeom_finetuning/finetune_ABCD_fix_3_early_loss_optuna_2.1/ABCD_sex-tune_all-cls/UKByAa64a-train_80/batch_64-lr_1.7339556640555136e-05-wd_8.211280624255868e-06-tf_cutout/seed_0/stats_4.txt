"main_optuna_fix_3.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3_early_loss --binary_class True --run_where lab --early_criteria loss"
{"epoch": 0, "training_loss": 55.23738193511963, "training_acc": 52.5, "val_loss": 13.790158033370972, "val_acc": 55.0, "val_auroc": 0.596, "time": 10.32}
{"epoch": 1, "training_loss": 55.33978748321533, "training_acc": 50.0, "val_loss": 14.023120403289795, "val_acc": 55.0, "val_auroc": 0.414, "time": 19.29}
{"epoch": 2, "training_loss": 56.23474407196045, "training_acc": 52.5, "val_loss": 14.191830158233643, "val_acc": 55.0, "val_auroc": 0.414, "time": 28.14}
{"epoch": 3, "training_loss": 55.79465293884277, "training_acc": 52.5, "val_loss": 13.815230131149292, "val_acc": 55.0, "val_auroc": 0.414, "time": 37.04}
{"epoch": 4, "training_loss": 55.103882789611816, "training_acc": 52.5, "val_loss": 13.851298093795776, "val_acc": 55.0, "val_auroc": 0.475, "time": 46.17}
{"epoch": 5, "training_loss": 55.22379112243652, "training_acc": 58.75, "val_loss": 13.902647495269775, "val_acc": 55.0, "val_auroc": 0.505, "time": 55.04}
{"epoch": 6, "training_loss": 55.38663864135742, "training_acc": 51.25, "val_loss": 13.89337420463562, "val_acc": 55.0, "val_auroc": 0.535, "time": 63.81}
{"epoch": 7, "training_loss": 55.51604080200195, "training_acc": 45.0, "val_loss": 13.834317922592163, "val_acc": 55.0, "val_auroc": 0.606, "time": 72.87}
{"epoch": 8, "training_loss": 54.94670104980469, "training_acc": 55.0, "val_loss": 13.728574514389038, "val_acc": 55.0, "val_auroc": 0.525, "time": 82.25}
{"epoch": 9, "training_loss": 55.0272216796875, "training_acc": 55.0, "val_loss": 13.72733473777771, "val_acc": 55.0, "val_auroc": 0.566, "time": 91.54}
{"epoch": 10, "training_loss": 55.047719955444336, "training_acc": 52.5, "val_loss": 13.749531507492065, "val_acc": 55.0, "val_auroc": 0.576, "time": 100.76}
{"epoch": 11, "training_loss": 55.35267162322998, "training_acc": 53.75, "val_loss": 13.794224262237549, "val_acc": 55.0, "val_auroc": 0.586, "time": 110.02}
{"epoch": 12, "training_loss": 55.418813705444336, "training_acc": 52.5, "val_loss": 13.8107430934906, "val_acc": 55.0, "val_auroc": 0.596, "time": 120.51}
{"epoch": 13, "training_loss": 55.42063331604004, "training_acc": 55.0, "val_loss": 13.747395277023315, "val_acc": 55.0, "val_auroc": 0.626, "time": 129.52}
{"epoch": 14, "training_loss": 53.853097915649414, "training_acc": 60.0, "val_loss": 13.731683492660522, "val_acc": 55.0, "val_auroc": 0.636, "time": 138.47}
{"epoch": 15, "training_loss": 55.13321876525879, "training_acc": 48.75, "val_loss": 13.803490400314331, "val_acc": 55.0, "val_auroc": 0.576, "time": 147.19}
{"epoch": 16, "training_loss": 55.38529586791992, "training_acc": 53.75, "val_loss": 13.761552572250366, "val_acc": 55.0, "val_auroc": 0.626, "time": 156.35}
{"epoch": 17, "training_loss": 54.61081600189209, "training_acc": 55.0, "val_loss": 13.70684266090393, "val_acc": 55.0, "val_auroc": 0.626, "time": 165.77}
{"epoch": 18, "training_loss": 54.1212739944458, "training_acc": 58.75, "val_loss": 13.741753101348877, "val_acc": 55.0, "val_auroc": 0.616, "time": 174.74}
{"epoch": 19, "training_loss": 53.50424385070801, "training_acc": 56.25, "val_loss": 13.709770441055298, "val_acc": 55.0, "val_auroc": 0.576, "time": 183.66}
{"epoch": 20, "training_loss": 54.1096076965332, "training_acc": 53.75, "val_loss": 13.998981714248657, "val_acc": 55.0, "val_auroc": 0.535, "time": 192.59}
{"epoch": 21, "training_loss": 55.24099063873291, "training_acc": 48.75, "val_loss": 13.896023035049438, "val_acc": 55.0, "val_auroc": 0.545, "time": 201.34}
{"epoch": 22, "training_loss": 53.81425857543945, "training_acc": 63.75, "val_loss": 13.71809720993042, "val_acc": 55.0, "val_auroc": 0.586, "time": 210.51}
{"epoch": 23, "training_loss": 54.4482479095459, "training_acc": 52.5, "val_loss": 13.776884078979492, "val_acc": 55.0, "val_auroc": 0.566, "time": 219.62}
{"epoch": 24, "training_loss": 52.780635833740234, "training_acc": 55.0, "val_loss": 13.741425275802612, "val_acc": 55.0, "val_auroc": 0.556, "time": 228.69}
{"epoch": 25, "training_loss": 51.62584114074707, "training_acc": 67.5, "val_loss": 13.736962080001831, "val_acc": 55.0, "val_auroc": 0.556, "time": 237.44}
{"epoch": 26, "training_loss": 52.412527084350586, "training_acc": 60.0, "val_loss": 13.848421573638916, "val_acc": 55.0, "val_auroc": 0.576, "time": 246.21}
{"epoch": 27, "training_loss": 49.61164093017578, "training_acc": 66.25, "val_loss": 13.740278482437134, "val_acc": 55.0, "val_auroc": 0.586, "time": 254.97}
{"epoch": 28, "training_loss": 51.76685333251953, "training_acc": 65.0, "val_loss": 14.32070016860962, "val_acc": 55.0, "val_auroc": 0.606, "time": 264.39}
{"epoch": 29, "training_loss": 51.75521278381348, "training_acc": 63.75, "val_loss": 15.335406064987183, "val_acc": 55.0, "val_auroc": 0.616, "time": 273.13}
{"epoch": 30, "training_loss": 56.045780181884766, "training_acc": 52.5, "val_loss": 13.594532012939453, "val_acc": 55.0, "val_auroc": 0.636, "time": 282.64}
{"epoch": 31, "training_loss": 49.55292510986328, "training_acc": 67.5, "val_loss": 14.342855215072632, "val_acc": 55.0, "val_auroc": 0.657, "time": 291.53}
{"epoch": 32, "training_loss": 48.59473896026611, "training_acc": 72.5, "val_loss": 17.58005142211914, "val_acc": 55.0, "val_auroc": 0.667, "time": 300.54}
{"epoch": 33, "training_loss": 65.68800258636475, "training_acc": 48.75, "val_loss": 14.479776620864868, "val_acc": 55.0, "val_auroc": 0.646, "time": 309.03}
{"epoch": 34, "training_loss": 52.31969356536865, "training_acc": 60.0, "val_loss": 14.99940276145935, "val_acc": 60.0, "val_auroc": 0.606, "time": 318.0}
{"epoch": 35, "training_loss": 54.83827209472656, "training_acc": 48.75, "val_loss": 14.484285116195679, "val_acc": 60.0, "val_auroc": 0.606, "time": 326.75}
{"epoch": 36, "training_loss": 51.71588897705078, "training_acc": 60.0, "val_loss": 13.592613935470581, "val_acc": 55.0, "val_auroc": 0.636, "time": 335.91}
{"epoch": 37, "training_loss": 51.07792091369629, "training_acc": 58.75, "val_loss": 14.413988590240479, "val_acc": 55.0, "val_auroc": 0.626, "time": 344.58}
{"epoch": 38, "training_loss": 54.55445098876953, "training_acc": 52.5, "val_loss": 14.683886766433716, "val_acc": 55.0, "val_auroc": 0.626, "time": 353.53}
{"epoch": 39, "training_loss": 54.26813507080078, "training_acc": 53.75, "val_loss": 14.00760293006897, "val_acc": 55.0, "val_auroc": 0.616, "time": 362.46}
{"epoch": 40, "training_loss": 53.14422035217285, "training_acc": 51.25, "val_loss": 13.595119714736938, "val_acc": 55.0, "val_auroc": 0.636, "time": 371.63}
{"epoch": 41, "training_loss": 51.216562271118164, "training_acc": 62.5, "val_loss": 13.609007596969604, "val_acc": 55.0, "val_auroc": 0.646, "time": 380.6}
{"epoch": 42, "training_loss": 52.628411293029785, "training_acc": 68.75, "val_loss": 13.700248003005981, "val_acc": 55.0, "val_auroc": 0.636, "time": 389.88}
{"epoch": 43, "training_loss": 52.26354694366455, "training_acc": 76.25, "val_loss": 13.53602647781372, "val_acc": 55.0, "val_auroc": 0.636, "time": 398.95}
{"epoch": 44, "training_loss": 50.71928310394287, "training_acc": 66.25, "val_loss": 13.532854318618774, "val_acc": 55.0, "val_auroc": 0.646, "time": 407.96}
{"epoch": 45, "training_loss": 49.0868034362793, "training_acc": 67.5, "val_loss": 13.497159481048584, "val_acc": 55.0, "val_auroc": 0.646, "time": 417.61}
{"epoch": 46, "training_loss": 50.17490768432617, "training_acc": 62.5, "val_loss": 13.598593473434448, "val_acc": 55.0, "val_auroc": 0.657, "time": 427.84}
{"epoch": 47, "training_loss": 48.89911079406738, "training_acc": 76.25, "val_loss": 13.552879095077515, "val_acc": 55.0, "val_auroc": 0.646, "time": 436.67}
{"epoch": 48, "training_loss": 46.31173610687256, "training_acc": 77.5, "val_loss": 14.917707443237305, "val_acc": 55.0, "val_auroc": 0.646, "time": 445.45}
{"epoch": 49, "training_loss": 53.09078598022461, "training_acc": 50.0, "val_loss": 13.732808828353882, "val_acc": 55.0, "val_auroc": 0.636, "time": 453.84}
{"epoch": 50, "training_loss": 44.3115291595459, "training_acc": 77.5, "val_loss": 14.94155764579773, "val_acc": 55.0, "val_auroc": 0.626, "time": 462.59}
{"epoch": 51, "training_loss": 48.36604404449463, "training_acc": 66.25, "val_loss": 14.103492498397827, "val_acc": 55.0, "val_auroc": 0.616, "time": 471.28}
{"epoch": 52, "training_loss": 41.88646697998047, "training_acc": 78.75, "val_loss": 15.078963041305542, "val_acc": 55.0, "val_auroc": 0.616, "time": 480.51}
{"epoch": 53, "training_loss": 43.46413326263428, "training_acc": 71.25, "val_loss": 15.496395826339722, "val_acc": 55.0, "val_auroc": 0.626, "time": 489.38}
{"epoch": 54, "training_loss": 49.50913047790527, "training_acc": 62.5, "val_loss": 14.322950839996338, "val_acc": 60.0, "val_auroc": 0.626, "time": 498.52}
{"epoch": 55, "training_loss": 38.32048559188843, "training_acc": 77.5, "val_loss": 18.89093041419983, "val_acc": 55.0, "val_auroc": 0.626, "time": 507.29}
{"epoch": 56, "training_loss": 49.94825744628906, "training_acc": 66.25, "val_loss": 14.635447263717651, "val_acc": 65.0, "val_auroc": 0.596, "time": 515.75}
{"epoch": 57, "training_loss": 42.20500564575195, "training_acc": 77.5, "val_loss": 14.27320122718811, "val_acc": 65.0, "val_auroc": 0.616, "time": 524.59}
{"epoch": 58, "training_loss": 37.10763931274414, "training_acc": 87.5, "val_loss": 18.951631784439087, "val_acc": 55.0, "val_auroc": 0.626, "time": 533.71}
{"epoch": 59, "training_loss": 49.78326463699341, "training_acc": 62.5, "val_loss": 16.29637360572815, "val_acc": 50.0, "val_auroc": 0.586, "time": 542.3}
{"epoch": 60, "training_loss": 43.78385353088379, "training_acc": 70.0, "val_loss": 15.234655141830444, "val_acc": 70.0, "val_auroc": 0.606, "time": 551.49}
{"epoch": 61, "training_loss": 31.657461643218994, "training_acc": 80.0, "val_loss": 15.8188796043396, "val_acc": 70.0, "val_auroc": 0.606, "time": 559.97}
{"epoch": 62, "training_loss": 30.05860996246338, "training_acc": 86.25, "val_loss": 16.418176889419556, "val_acc": 60.0, "val_auroc": 0.596, "time": 569.13}
{"epoch": 63, "training_loss": 32.830326080322266, "training_acc": 80.0, "val_loss": 16.535171270370483, "val_acc": 65.0, "val_auroc": 0.636, "time": 577.87}
{"epoch": 64, "training_loss": 27.572062015533447, "training_acc": 85.0, "val_loss": 17.136141061782837, "val_acc": 65.0, "val_auroc": 0.636, "time": 587.16}
