"main_optuna_fix_3.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3_early_loss --binary_class True --run_where lab --early_criteria loss"
{"epoch": 0, "training_loss": 55.7106237411499, "training_acc": 41.25, "val_loss": 13.813116550445557, "val_acc": 50.0, "val_auroc": 0.76, "time": 9.65}
{"epoch": 1, "training_loss": 55.50515365600586, "training_acc": 48.75, "val_loss": 13.851619958877563, "val_acc": 50.0, "val_auroc": 0.77, "time": 18.56}
{"epoch": 2, "training_loss": 55.21941566467285, "training_acc": 53.75, "val_loss": 14.08205270767212, "val_acc": 50.0, "val_auroc": 0.67, "time": 27.86}
{"epoch": 3, "training_loss": 55.47531986236572, "training_acc": 53.75, "val_loss": 14.125386476516724, "val_acc": 50.0, "val_auroc": 0.68, "time": 36.61}
{"epoch": 4, "training_loss": 55.253618240356445, "training_acc": 53.75, "val_loss": 13.911653757095337, "val_acc": 50.0, "val_auroc": 0.56, "time": 45.18}
{"epoch": 5, "training_loss": 55.27617931365967, "training_acc": 53.75, "val_loss": 13.864351511001587, "val_acc": 50.0, "val_auroc": 0.52, "time": 54.08}
{"epoch": 6, "training_loss": 54.993144035339355, "training_acc": 55.0, "val_loss": 13.871716260910034, "val_acc": 50.0, "val_auroc": 0.54, "time": 63.6}
{"epoch": 7, "training_loss": 55.0807466506958, "training_acc": 53.75, "val_loss": 13.930383920669556, "val_acc": 50.0, "val_auroc": 0.57, "time": 72.0}
{"epoch": 8, "training_loss": 55.109803199768066, "training_acc": 53.75, "val_loss": 13.993346691131592, "val_acc": 50.0, "val_auroc": 0.54, "time": 80.85}
{"epoch": 9, "training_loss": 54.88779067993164, "training_acc": 53.75, "val_loss": 13.90659213066101, "val_acc": 50.0, "val_auroc": 0.5, "time": 89.7}
{"epoch": 10, "training_loss": 55.01572513580322, "training_acc": 55.0, "val_loss": 13.842225074768066, "val_acc": 50.0, "val_auroc": 0.53, "time": 98.17}
{"epoch": 11, "training_loss": 54.87833786010742, "training_acc": 57.5, "val_loss": 13.831901550292969, "val_acc": 50.0, "val_auroc": 0.56, "time": 106.96}
{"epoch": 12, "training_loss": 54.57146453857422, "training_acc": 62.5, "val_loss": 13.918780088424683, "val_acc": 50.0, "val_auroc": 0.51, "time": 116.21}
{"epoch": 13, "training_loss": 54.655760765075684, "training_acc": 53.75, "val_loss": 14.131797552108765, "val_acc": 50.0, "val_auroc": 0.49, "time": 124.71}
{"epoch": 14, "training_loss": 54.401432037353516, "training_acc": 53.75, "val_loss": 14.371730089187622, "val_acc": 50.0, "val_auroc": 0.46, "time": 133.81}
{"epoch": 15, "training_loss": 54.93233299255371, "training_acc": 53.75, "val_loss": 14.07734751701355, "val_acc": 50.0, "val_auroc": 0.54, "time": 142.85}
{"epoch": 16, "training_loss": 54.4096622467041, "training_acc": 56.25, "val_loss": 13.842306137084961, "val_acc": 50.0, "val_auroc": 0.54, "time": 151.8}
{"epoch": 17, "training_loss": 54.11771011352539, "training_acc": 71.25, "val_loss": 13.831347227096558, "val_acc": 50.0, "val_auroc": 0.53, "time": 160.24}
{"epoch": 18, "training_loss": 53.59209442138672, "training_acc": 70.0, "val_loss": 13.83942723274231, "val_acc": 50.0, "val_auroc": 0.58, "time": 169.07}
{"epoch": 19, "training_loss": 53.461304664611816, "training_acc": 53.75, "val_loss": 13.756295442581177, "val_acc": 50.0, "val_auroc": 0.58, "time": 178.18}
{"epoch": 20, "training_loss": 52.686283111572266, "training_acc": 73.75, "val_loss": 14.038958549499512, "val_acc": 55.0, "val_auroc": 0.56, "time": 186.92}
{"epoch": 21, "training_loss": 52.81914520263672, "training_acc": 56.25, "val_loss": 14.57301139831543, "val_acc": 50.0, "val_auroc": 0.63, "time": 195.66}
{"epoch": 22, "training_loss": 54.764235496520996, "training_acc": 53.75, "val_loss": 14.76399302482605, "val_acc": 50.0, "val_auroc": 0.59, "time": 204.68}
{"epoch": 23, "training_loss": 55.64076232910156, "training_acc": 53.75, "val_loss": 14.30241346359253, "val_acc": 50.0, "val_auroc": 0.64, "time": 213.33}
{"epoch": 24, "training_loss": 54.780330657958984, "training_acc": 53.75, "val_loss": 14.010392427444458, "val_acc": 50.0, "val_auroc": 0.66, "time": 221.99}
{"epoch": 25, "training_loss": 54.31417465209961, "training_acc": 53.75, "val_loss": 13.887546062469482, "val_acc": 50.0, "val_auroc": 0.62, "time": 230.88}
{"epoch": 26, "training_loss": 53.96245765686035, "training_acc": 53.75, "val_loss": 13.861416578292847, "val_acc": 50.0, "val_auroc": 0.59, "time": 239.61}
{"epoch": 27, "training_loss": 53.12708282470703, "training_acc": 53.75, "val_loss": 13.88452410697937, "val_acc": 50.0, "val_auroc": 0.58, "time": 248.17}
{"epoch": 28, "training_loss": 52.28309917449951, "training_acc": 53.75, "val_loss": 13.751647472381592, "val_acc": 50.0, "val_auroc": 0.64, "time": 257.44}
{"epoch": 29, "training_loss": 52.61288833618164, "training_acc": 65.0, "val_loss": 13.823188543319702, "val_acc": 50.0, "val_auroc": 0.63, "time": 266.38}
{"epoch": 30, "training_loss": 52.604753494262695, "training_acc": 58.75, "val_loss": 14.891918897628784, "val_acc": 50.0, "val_auroc": 0.63, "time": 277.89}
{"epoch": 31, "training_loss": 53.87618827819824, "training_acc": 53.75, "val_loss": 13.81229281425476, "val_acc": 50.0, "val_auroc": 0.63, "time": 286.65}
{"epoch": 32, "training_loss": 48.671542167663574, "training_acc": 71.25, "val_loss": 14.411619901657104, "val_acc": 60.0, "val_auroc": 0.67, "time": 295.94}
{"epoch": 33, "training_loss": 55.09135341644287, "training_acc": 47.5, "val_loss": 13.443480730056763, "val_acc": 50.0, "val_auroc": 0.69, "time": 304.86}
{"epoch": 34, "training_loss": 49.18119812011719, "training_acc": 78.75, "val_loss": 15.578703880310059, "val_acc": 50.0, "val_auroc": 0.66, "time": 313.67}
{"epoch": 35, "training_loss": 51.48437690734863, "training_acc": 53.75, "val_loss": 13.950446844100952, "val_acc": 60.0, "val_auroc": 0.71, "time": 322.58}
{"epoch": 36, "training_loss": 52.165048599243164, "training_acc": 50.0, "val_loss": 16.08407974243164, "val_acc": 50.0, "val_auroc": 0.67, "time": 331.29}
{"epoch": 37, "training_loss": 61.18551254272461, "training_acc": 46.25, "val_loss": 14.160727262496948, "val_acc": 70.0, "val_auroc": 0.69, "time": 339.98}
{"epoch": 38, "training_loss": 53.152814865112305, "training_acc": 51.25, "val_loss": 13.607494831085205, "val_acc": 50.0, "val_auroc": 0.69, "time": 348.79}
{"epoch": 39, "training_loss": 50.972384452819824, "training_acc": 72.5, "val_loss": 14.668902158737183, "val_acc": 50.0, "val_auroc": 0.67, "time": 357.59}
{"epoch": 40, "training_loss": 52.81963920593262, "training_acc": 53.75, "val_loss": 14.910852909088135, "val_acc": 50.0, "val_auroc": 0.67, "time": 366.33}
{"epoch": 41, "training_loss": 50.996469497680664, "training_acc": 53.75, "val_loss": 13.675304651260376, "val_acc": 50.0, "val_auroc": 0.67, "time": 375.23}
{"epoch": 42, "training_loss": 49.631818771362305, "training_acc": 71.25, "val_loss": 13.765208721160889, "val_acc": 50.0, "val_auroc": 0.68, "time": 384.07}
{"epoch": 43, "training_loss": 51.72189712524414, "training_acc": 58.75, "val_loss": 13.980934619903564, "val_acc": 60.0, "val_auroc": 0.62, "time": 392.71}
{"epoch": 44, "training_loss": 51.15313529968262, "training_acc": 57.5, "val_loss": 13.576843738555908, "val_acc": 50.0, "val_auroc": 0.6, "time": 401.69}
{"epoch": 45, "training_loss": 45.99249076843262, "training_acc": 85.0, "val_loss": 14.085334539413452, "val_acc": 50.0, "val_auroc": 0.58, "time": 410.42}
{"epoch": 46, "training_loss": 45.02507400512695, "training_acc": 71.25, "val_loss": 13.565733432769775, "val_acc": 45.0, "val_auroc": 0.61, "time": 419.04}
{"epoch": 47, "training_loss": 39.810938358306885, "training_acc": 90.0, "val_loss": 14.39088225364685, "val_acc": 50.0, "val_auroc": 0.61, "time": 427.87}
{"epoch": 48, "training_loss": 44.807647705078125, "training_acc": 61.25, "val_loss": 15.399535894393921, "val_acc": 50.0, "val_auroc": 0.65, "time": 437.12}
{"epoch": 49, "training_loss": 41.36184024810791, "training_acc": 71.25, "val_loss": 20.204334259033203, "val_acc": 50.0, "val_auroc": 0.63, "time": 445.83}
{"epoch": 50, "training_loss": 50.39677047729492, "training_acc": 57.5, "val_loss": 22.66486883163452, "val_acc": 50.0, "val_auroc": 0.67, "time": 454.48}
{"epoch": 51, "training_loss": 59.214378356933594, "training_acc": 58.75, "val_loss": 18.17949891090393, "val_acc": 55.0, "val_auroc": 0.65, "time": 463.77}
{"epoch": 52, "training_loss": 52.16933250427246, "training_acc": 60.0, "val_loss": 14.818710088729858, "val_acc": 65.0, "val_auroc": 0.68, "time": 472.44}
