"main_optuna_fix_3.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3_early_loss --binary_class True --run_where lab --early_criteria loss"
{"epoch": 0, "training_loss": 55.60849189758301, "training_acc": 52.5, "val_loss": 13.771882057189941, "val_acc": 55.0, "val_auroc": 0.424, "time": 10.03}
{"epoch": 1, "training_loss": 55.9741792678833, "training_acc": 51.25, "val_loss": 13.788872957229614, "val_acc": 55.0, "val_auroc": 0.495, "time": 18.81}
{"epoch": 2, "training_loss": 55.22017478942871, "training_acc": 52.5, "val_loss": 13.75422716140747, "val_acc": 55.0, "val_auroc": 0.475, "time": 28.23}
{"epoch": 3, "training_loss": 55.565303802490234, "training_acc": 52.5, "val_loss": 13.80113959312439, "val_acc": 55.0, "val_auroc": 0.394, "time": 37.37}
{"epoch": 4, "training_loss": 55.48887825012207, "training_acc": 52.5, "val_loss": 13.804738521575928, "val_acc": 55.0, "val_auroc": 0.455, "time": 46.03}
{"epoch": 5, "training_loss": 55.3665771484375, "training_acc": 52.5, "val_loss": 13.788479566574097, "val_acc": 55.0, "val_auroc": 0.525, "time": 54.71}
{"epoch": 6, "training_loss": 55.265435218811035, "training_acc": 51.25, "val_loss": 13.911075592041016, "val_acc": 55.0, "val_auroc": 0.515, "time": 64.05}
{"epoch": 7, "training_loss": 55.16020965576172, "training_acc": 52.5, "val_loss": 13.81583571434021, "val_acc": 55.0, "val_auroc": 0.505, "time": 72.99}
{"epoch": 8, "training_loss": 55.23715400695801, "training_acc": 50.0, "val_loss": 13.82232666015625, "val_acc": 55.0, "val_auroc": 0.485, "time": 82.09}
{"epoch": 9, "training_loss": 55.41157913208008, "training_acc": 50.0, "val_loss": 13.853414058685303, "val_acc": 55.0, "val_auroc": 0.495, "time": 90.96}
{"epoch": 10, "training_loss": 54.7559814453125, "training_acc": 57.5, "val_loss": 13.810657262802124, "val_acc": 55.0, "val_auroc": 0.505, "time": 99.91}
{"epoch": 11, "training_loss": 54.71361541748047, "training_acc": 53.75, "val_loss": 13.963865041732788, "val_acc": 55.0, "val_auroc": 0.545, "time": 108.78}
{"epoch": 12, "training_loss": 55.46780967712402, "training_acc": 52.5, "val_loss": 13.844174146652222, "val_acc": 55.0, "val_auroc": 0.545, "time": 117.58}
{"epoch": 13, "training_loss": 54.77251148223877, "training_acc": 52.5, "val_loss": 13.769327402114868, "val_acc": 55.0, "val_auroc": 0.626, "time": 126.4}
{"epoch": 14, "training_loss": 55.429351806640625, "training_acc": 52.5, "val_loss": 13.746490478515625, "val_acc": 55.0, "val_auroc": 0.545, "time": 135.75}
{"epoch": 15, "training_loss": 55.09184551239014, "training_acc": 52.5, "val_loss": 13.773000240325928, "val_acc": 55.0, "val_auroc": 0.677, "time": 144.64}
{"epoch": 16, "training_loss": 54.98454570770264, "training_acc": 53.75, "val_loss": 13.76129150390625, "val_acc": 55.0, "val_auroc": 0.576, "time": 153.51}
{"epoch": 17, "training_loss": 54.589077949523926, "training_acc": 52.5, "val_loss": 13.916419744491577, "val_acc": 55.0, "val_auroc": 0.545, "time": 162.4}
{"epoch": 18, "training_loss": 54.802825927734375, "training_acc": 52.5, "val_loss": 13.870971202850342, "val_acc": 55.0, "val_auroc": 0.525, "time": 171.68}
{"epoch": 19, "training_loss": 54.08980369567871, "training_acc": 52.5, "val_loss": 13.774341344833374, "val_acc": 55.0, "val_auroc": 0.596, "time": 180.6}
{"epoch": 20, "training_loss": 54.37192153930664, "training_acc": 65.0, "val_loss": 13.883678913116455, "val_acc": 55.0, "val_auroc": 0.616, "time": 189.46}
{"epoch": 21, "training_loss": 55.2445182800293, "training_acc": 48.75, "val_loss": 13.936057090759277, "val_acc": 55.0, "val_auroc": 0.616, "time": 198.64}
{"epoch": 22, "training_loss": 54.90525722503662, "training_acc": 48.75, "val_loss": 13.890479803085327, "val_acc": 55.0, "val_auroc": 0.545, "time": 208.12}
{"epoch": 23, "training_loss": 55.007158279418945, "training_acc": 53.75, "val_loss": 13.821041584014893, "val_acc": 55.0, "val_auroc": 0.545, "time": 217.17}
{"epoch": 24, "training_loss": 53.93756675720215, "training_acc": 63.75, "val_loss": 13.767063617706299, "val_acc": 55.0, "val_auroc": 0.545, "time": 226.01}
{"epoch": 25, "training_loss": 53.07391834259033, "training_acc": 63.75, "val_loss": 13.88858437538147, "val_acc": 55.0, "val_auroc": 0.535, "time": 237.66}
{"epoch": 26, "training_loss": 54.10244369506836, "training_acc": 55.0, "val_loss": 14.250572919845581, "val_acc": 55.0, "val_auroc": 0.556, "time": 246.93}
{"epoch": 27, "training_loss": 52.603675842285156, "training_acc": 56.25, "val_loss": 13.892024755477905, "val_acc": 55.0, "val_auroc": 0.545, "time": 255.83}
{"epoch": 28, "training_loss": 53.60931587219238, "training_acc": 61.25, "val_loss": 14.17969822883606, "val_acc": 55.0, "val_auroc": 0.535, "time": 264.87}
{"epoch": 29, "training_loss": 54.781723976135254, "training_acc": 55.0, "val_loss": 13.831926584243774, "val_acc": 55.0, "val_auroc": 0.566, "time": 273.97}
{"epoch": 30, "training_loss": 52.152567863464355, "training_acc": 62.5, "val_loss": 14.42826509475708, "val_acc": 55.0, "val_auroc": 0.586, "time": 283.23}
{"epoch": 31, "training_loss": 52.541860580444336, "training_acc": 55.0, "val_loss": 14.185056686401367, "val_acc": 55.0, "val_auroc": 0.586, "time": 292.21}
{"epoch": 32, "training_loss": 54.15610122680664, "training_acc": 55.0, "val_loss": 14.190583229064941, "val_acc": 55.0, "val_auroc": 0.535, "time": 301.24}
{"epoch": 33, "training_loss": 55.46236324310303, "training_acc": 47.5, "val_loss": 13.910197019577026, "val_acc": 55.0, "val_auroc": 0.556, "time": 310.31}
