"main_optuna_fix_3.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3_early_loss --binary_class True --run_where lab --early_criteria loss"
{"epoch": 0, "training_loss": 55.44083213806152, "training_acc": 52.5, "val_loss": 13.78348708152771, "val_acc": 55.0, "val_auroc": 0.626, "time": 10.3}
{"epoch": 1, "training_loss": 55.454689025878906, "training_acc": 52.5, "val_loss": 13.820469379425049, "val_acc": 55.0, "val_auroc": 0.394, "time": 19.51}
{"epoch": 2, "training_loss": 55.411956787109375, "training_acc": 52.5, "val_loss": 13.788045644760132, "val_acc": 55.0, "val_auroc": 0.505, "time": 28.86}
{"epoch": 3, "training_loss": 55.25445079803467, "training_acc": 52.5, "val_loss": 13.823158740997314, "val_acc": 55.0, "val_auroc": 0.495, "time": 37.5}
{"epoch": 4, "training_loss": 55.31118965148926, "training_acc": 52.5, "val_loss": 13.789643049240112, "val_acc": 55.0, "val_auroc": 0.515, "time": 46.38}
{"epoch": 5, "training_loss": 55.326913833618164, "training_acc": 52.5, "val_loss": 13.770835399627686, "val_acc": 55.0, "val_auroc": 0.515, "time": 55.9}
{"epoch": 6, "training_loss": 55.278061866760254, "training_acc": 52.5, "val_loss": 13.773049116134644, "val_acc": 55.0, "val_auroc": 0.434, "time": 65.32}
{"epoch": 7, "training_loss": 55.19258785247803, "training_acc": 52.5, "val_loss": 13.770685195922852, "val_acc": 55.0, "val_auroc": 0.485, "time": 74.42}
{"epoch": 8, "training_loss": 55.19675254821777, "training_acc": 52.5, "val_loss": 13.82021188735962, "val_acc": 55.0, "val_auroc": 0.424, "time": 83.72}
{"epoch": 9, "training_loss": 55.422494888305664, "training_acc": 51.25, "val_loss": 13.838413953781128, "val_acc": 55.0, "val_auroc": 0.495, "time": 92.81}
{"epoch": 10, "training_loss": 55.28438377380371, "training_acc": 53.75, "val_loss": 13.791385889053345, "val_acc": 55.0, "val_auroc": 0.434, "time": 101.81}
{"epoch": 11, "training_loss": 55.19161033630371, "training_acc": 52.5, "val_loss": 13.739790916442871, "val_acc": 55.0, "val_auroc": 0.586, "time": 111.21}
{"epoch": 12, "training_loss": 55.34067916870117, "training_acc": 52.5, "val_loss": 13.738172054290771, "val_acc": 55.0, "val_auroc": 0.707, "time": 120.98}
{"epoch": 13, "training_loss": 55.381266593933105, "training_acc": 52.5, "val_loss": 13.738870620727539, "val_acc": 55.0, "val_auroc": 0.707, "time": 129.97}
{"epoch": 14, "training_loss": 55.31950855255127, "training_acc": 52.5, "val_loss": 13.748070001602173, "val_acc": 55.0, "val_auroc": 0.667, "time": 138.88}
{"epoch": 15, "training_loss": 55.36125183105469, "training_acc": 52.5, "val_loss": 13.772300481796265, "val_acc": 55.0, "val_auroc": 0.535, "time": 147.92}
{"epoch": 16, "training_loss": 55.355106353759766, "training_acc": 52.5, "val_loss": 13.760740756988525, "val_acc": 55.0, "val_auroc": 0.525, "time": 156.95}
{"epoch": 17, "training_loss": 55.341485023498535, "training_acc": 52.5, "val_loss": 13.759583234786987, "val_acc": 55.0, "val_auroc": 0.535, "time": 165.91}
{"epoch": 18, "training_loss": 55.3724479675293, "training_acc": 52.5, "val_loss": 13.759183883666992, "val_acc": 55.0, "val_auroc": 0.515, "time": 175.25}
{"epoch": 19, "training_loss": 55.19551467895508, "training_acc": 52.5, "val_loss": 13.792188167572021, "val_acc": 55.0, "val_auroc": 0.455, "time": 186.78}
{"epoch": 20, "training_loss": 55.150031089782715, "training_acc": 52.5, "val_loss": 13.857557773590088, "val_acc": 55.0, "val_auroc": 0.444, "time": 195.83}
{"epoch": 21, "training_loss": 55.33946228027344, "training_acc": 57.5, "val_loss": 13.879145383834839, "val_acc": 55.0, "val_auroc": 0.434, "time": 204.58}
{"epoch": 22, "training_loss": 55.28768539428711, "training_acc": 56.25, "val_loss": 13.837451934814453, "val_acc": 55.0, "val_auroc": 0.404, "time": 213.48}
{"epoch": 23, "training_loss": 55.123398780822754, "training_acc": 52.5, "val_loss": 13.784583806991577, "val_acc": 55.0, "val_auroc": 0.434, "time": 222.34}
{"epoch": 24, "training_loss": 54.973999977111816, "training_acc": 52.5, "val_loss": 13.749496936798096, "val_acc": 55.0, "val_auroc": 0.525, "time": 231.16}
{"epoch": 25, "training_loss": 54.91582775115967, "training_acc": 52.5, "val_loss": 13.747966289520264, "val_acc": 55.0, "val_auroc": 0.495, "time": 240.07}
{"epoch": 26, "training_loss": 55.184706687927246, "training_acc": 52.5, "val_loss": 13.766838312149048, "val_acc": 55.0, "val_auroc": 0.485, "time": 249.26}
{"epoch": 27, "training_loss": 54.58188247680664, "training_acc": 52.5, "val_loss": 13.788599967956543, "val_acc": 55.0, "val_auroc": 0.424, "time": 258.17}
{"epoch": 28, "training_loss": 54.97768974304199, "training_acc": 52.5, "val_loss": 13.842216730117798, "val_acc": 55.0, "val_auroc": 0.455, "time": 266.97}
{"epoch": 29, "training_loss": 55.17810916900635, "training_acc": 55.0, "val_loss": 13.830897808074951, "val_acc": 55.0, "val_auroc": 0.475, "time": 276.06}
{"epoch": 30, "training_loss": 55.20162868499756, "training_acc": 52.5, "val_loss": 13.76924991607666, "val_acc": 55.0, "val_auroc": 0.586, "time": 285.53}
{"epoch": 31, "training_loss": 55.19902801513672, "training_acc": 52.5, "val_loss": 13.777188062667847, "val_acc": 55.0, "val_auroc": 0.505, "time": 294.03}
