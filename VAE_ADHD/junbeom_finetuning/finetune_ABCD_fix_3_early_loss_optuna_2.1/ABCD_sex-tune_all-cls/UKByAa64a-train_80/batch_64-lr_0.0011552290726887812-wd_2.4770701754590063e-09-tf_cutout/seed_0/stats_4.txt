"main_optuna_fix_3.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3_early_loss --binary_class True --run_where lab --early_criteria loss"
{"epoch": 0, "training_loss": 63.04694747924805, "training_acc": 52.5, "val_loss": 93.92443656921387, "val_acc": 55.0, "val_auroc": 0.626, "time": 10.21}
{"epoch": 1, "training_loss": 852.871826171875, "training_acc": 45.0, "val_loss": 22.360312938690186, "val_acc": 45.0, "val_auroc": 0.384, "time": 19.71}
{"epoch": 2, "training_loss": 78.11505889892578, "training_acc": 47.5, "val_loss": 35.4632830619812, "val_acc": 55.0, "val_auroc": 0.636, "time": 28.82}
{"epoch": 3, "training_loss": 126.07608890533447, "training_acc": 52.5, "val_loss": 21.521995067596436, "val_acc": 45.0, "val_auroc": 0.364, "time": 38.12}
{"epoch": 4, "training_loss": 76.9935359954834, "training_acc": 47.5, "val_loss": 13.820894956588745, "val_acc": 55.0, "val_auroc": 0.404, "time": 47.58}
{"epoch": 5, "training_loss": 55.60532188415527, "training_acc": 52.5, "val_loss": 13.803703784942627, "val_acc": 55.0, "val_auroc": 0.616, "time": 56.77}
{"epoch": 6, "training_loss": 55.9291467666626, "training_acc": 52.5, "val_loss": 13.786025047302246, "val_acc": 55.0, "val_auroc": 0.586, "time": 65.96}
{"epoch": 7, "training_loss": 55.3393669128418, "training_acc": 52.5, "val_loss": 13.982706069946289, "val_acc": 55.0, "val_auroc": 0.394, "time": 75.12}
{"epoch": 8, "training_loss": 56.36326217651367, "training_acc": 42.5, "val_loss": 14.090068340301514, "val_acc": 55.0, "val_auroc": 0.384, "time": 84.13}
{"epoch": 9, "training_loss": 56.928582191467285, "training_acc": 47.5, "val_loss": 13.778713941574097, "val_acc": 55.0, "val_auroc": 0.545, "time": 93.0}
{"epoch": 10, "training_loss": 55.34074592590332, "training_acc": 52.5, "val_loss": 13.88874888420105, "val_acc": 55.0, "val_auroc": 0.616, "time": 104.02}
{"epoch": 11, "training_loss": 56.66565132141113, "training_acc": 52.5, "val_loss": 13.831930160522461, "val_acc": 55.0, "val_auroc": 0.616, "time": 112.95}
{"epoch": 12, "training_loss": 56.161094665527344, "training_acc": 52.5, "val_loss": 13.753536939620972, "val_acc": 55.0, "val_auroc": 0.626, "time": 122.54}
{"epoch": 13, "training_loss": 55.62968063354492, "training_acc": 52.5, "val_loss": 13.820006847381592, "val_acc": 55.0, "val_auroc": 0.626, "time": 131.8}
{"epoch": 14, "training_loss": 55.42175483703613, "training_acc": 52.5, "val_loss": 13.920172452926636, "val_acc": 55.0, "val_auroc": 0.646, "time": 140.54}
{"epoch": 15, "training_loss": 55.78071117401123, "training_acc": 47.5, "val_loss": 13.940280675888062, "val_acc": 55.0, "val_auroc": 0.737, "time": 149.68}
{"epoch": 16, "training_loss": 55.474748611450195, "training_acc": 47.5, "val_loss": 13.780794143676758, "val_acc": 55.0, "val_auroc": 0.616, "time": 158.69}
{"epoch": 17, "training_loss": 55.42630672454834, "training_acc": 52.5, "val_loss": 13.770182132720947, "val_acc": 55.0, "val_auroc": 0.606, "time": 167.54}
{"epoch": 18, "training_loss": 55.736764907836914, "training_acc": 52.5, "val_loss": 13.775078058242798, "val_acc": 55.0, "val_auroc": 0.606, "time": 176.34}
{"epoch": 19, "training_loss": 55.646324157714844, "training_acc": 52.5, "val_loss": 13.757600784301758, "val_acc": 55.0, "val_auroc": 0.606, "time": 185.42}
{"epoch": 20, "training_loss": 55.423288345336914, "training_acc": 52.5, "val_loss": 13.78584623336792, "val_acc": 55.0, "val_auroc": 0.616, "time": 194.2}
{"epoch": 21, "training_loss": 55.388068199157715, "training_acc": 52.5, "val_loss": 13.83293628692627, "val_acc": 55.0, "val_auroc": 0.556, "time": 202.96}
{"epoch": 22, "training_loss": 55.39848709106445, "training_acc": 52.5, "val_loss": 13.847907781600952, "val_acc": 55.0, "val_auroc": 0.283, "time": 212.0}
{"epoch": 23, "training_loss": 55.43937873840332, "training_acc": 52.5, "val_loss": 13.829044103622437, "val_acc": 55.0, "val_auroc": 0.212, "time": 220.68}
{"epoch": 24, "training_loss": 55.393531799316406, "training_acc": 52.5, "val_loss": 13.793691396713257, "val_acc": 55.0, "val_auroc": 0.212, "time": 229.12}
{"epoch": 25, "training_loss": 55.33306121826172, "training_acc": 52.5, "val_loss": 13.77115249633789, "val_acc": 55.0, "val_auroc": 0.283, "time": 238.04}
{"epoch": 26, "training_loss": 55.361878395080566, "training_acc": 52.5, "val_loss": 13.76320481300354, "val_acc": 55.0, "val_auroc": 0.566, "time": 246.73}
{"epoch": 27, "training_loss": 55.502875328063965, "training_acc": 52.5, "val_loss": 13.766677379608154, "val_acc": 55.0, "val_auroc": 0.586, "time": 255.16}
{"epoch": 28, "training_loss": 55.55472946166992, "training_acc": 52.5, "val_loss": 13.762760162353516, "val_acc": 55.0, "val_auroc": 0.616, "time": 264.21}
{"epoch": 29, "training_loss": 55.558013916015625, "training_acc": 52.5, "val_loss": 13.762381076812744, "val_acc": 55.0, "val_auroc": 0.616, "time": 272.66}
{"epoch": 30, "training_loss": 55.43338203430176, "training_acc": 52.5, "val_loss": 13.763092756271362, "val_acc": 55.0, "val_auroc": 0.586, "time": 281.18}
{"epoch": 31, "training_loss": 55.406840324401855, "training_acc": 52.5, "val_loss": 13.768744468688965, "val_acc": 55.0, "val_auroc": 0.596, "time": 290.22}
