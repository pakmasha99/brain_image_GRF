"main_optuna_fix_3.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3_early_loss --binary_class True --run_where lab --early_criteria loss"
{"epoch": 0, "training_loss": 56.18519687652588, "training_acc": 51.25, "val_loss": 13.8246488571167, "val_acc": 55.0, "val_auroc": 0.354, "time": 10.03}
{"epoch": 1, "training_loss": 56.34744834899902, "training_acc": 46.25, "val_loss": 35.732972621917725, "val_acc": 55.0, "val_auroc": 0.596, "time": 18.79}
{"epoch": 2, "training_loss": 139.25302696228027, "training_acc": 52.5, "val_loss": 13.851221799850464, "val_acc": 55.0, "val_auroc": 0.283, "time": 28.05}
{"epoch": 3, "training_loss": 55.11303901672363, "training_acc": 55.0, "val_loss": 15.97760796546936, "val_acc": 45.0, "val_auroc": 0.384, "time": 37.18}
{"epoch": 4, "training_loss": 60.09190654754639, "training_acc": 47.5, "val_loss": 13.788037300109863, "val_acc": 55.0, "val_auroc": 0.404, "time": 46.39}
{"epoch": 5, "training_loss": 55.8521671295166, "training_acc": 52.5, "val_loss": 13.791296482086182, "val_acc": 55.0, "val_auroc": 0.374, "time": 55.06}
{"epoch": 6, "training_loss": 55.71057891845703, "training_acc": 52.5, "val_loss": 13.938268423080444, "val_acc": 55.0, "val_auroc": 0.333, "time": 64.15}
{"epoch": 7, "training_loss": 55.43293762207031, "training_acc": 48.75, "val_loss": 13.862773180007935, "val_acc": 55.0, "val_auroc": 0.364, "time": 73.31}
{"epoch": 8, "training_loss": 55.67849540710449, "training_acc": 52.5, "val_loss": 14.025046825408936, "val_acc": 55.0, "val_auroc": 0.364, "time": 82.89}
{"epoch": 9, "training_loss": 56.85979461669922, "training_acc": 47.5, "val_loss": 13.841265439987183, "val_acc": 55.0, "val_auroc": 0.384, "time": 91.63}
{"epoch": 10, "training_loss": 55.23985195159912, "training_acc": 52.5, "val_loss": 13.817218542098999, "val_acc": 55.0, "val_auroc": 0.384, "time": 100.35}
{"epoch": 11, "training_loss": 55.96512794494629, "training_acc": 52.5, "val_loss": 13.847001791000366, "val_acc": 55.0, "val_auroc": 0.434, "time": 109.44}
{"epoch": 12, "training_loss": 56.131500244140625, "training_acc": 52.5, "val_loss": 13.791223764419556, "val_acc": 55.0, "val_auroc": 0.404, "time": 118.65}
{"epoch": 13, "training_loss": 55.76867866516113, "training_acc": 52.5, "val_loss": 13.79367709159851, "val_acc": 55.0, "val_auroc": 0.394, "time": 127.46}
{"epoch": 14, "training_loss": 55.25172996520996, "training_acc": 52.5, "val_loss": 13.96494746208191, "val_acc": 55.0, "val_auroc": 0.424, "time": 136.39}
{"epoch": 15, "training_loss": 55.91239929199219, "training_acc": 47.5, "val_loss": 14.03551459312439, "val_acc": 55.0, "val_auroc": 0.434, "time": 145.45}
{"epoch": 16, "training_loss": 55.601569175720215, "training_acc": 47.5, "val_loss": 13.78965139389038, "val_acc": 55.0, "val_auroc": 0.434, "time": 154.14}
{"epoch": 17, "training_loss": 55.42386722564697, "training_acc": 52.5, "val_loss": 13.81412386894226, "val_acc": 55.0, "val_auroc": 0.404, "time": 162.85}
{"epoch": 18, "training_loss": 56.00193786621094, "training_acc": 52.5, "val_loss": 13.815305233001709, "val_acc": 55.0, "val_auroc": 0.424, "time": 172.01}
{"epoch": 19, "training_loss": 55.79432201385498, "training_acc": 52.5, "val_loss": 13.76815676689148, "val_acc": 55.0, "val_auroc": 0.364, "time": 181.47}
{"epoch": 20, "training_loss": 55.358802795410156, "training_acc": 52.5, "val_loss": 13.854984045028687, "val_acc": 55.0, "val_auroc": 0.354, "time": 191.06}
{"epoch": 21, "training_loss": 55.49238586425781, "training_acc": 50.0, "val_loss": 13.94382357597351, "val_acc": 55.0, "val_auroc": 0.374, "time": 199.77}
{"epoch": 22, "training_loss": 55.60860252380371, "training_acc": 47.5, "val_loss": 13.899606466293335, "val_acc": 55.0, "val_auroc": 0.374, "time": 208.63}
{"epoch": 23, "training_loss": 55.46935272216797, "training_acc": 47.5, "val_loss": 13.82201075553894, "val_acc": 55.0, "val_auroc": 0.414, "time": 217.7}
{"epoch": 24, "training_loss": 55.38655662536621, "training_acc": 52.5, "val_loss": 13.770500421524048, "val_acc": 55.0, "val_auroc": 0.414, "time": 226.74}
{"epoch": 25, "training_loss": 55.319223403930664, "training_acc": 52.5, "val_loss": 13.765461444854736, "val_acc": 55.0, "val_auroc": 0.424, "time": 235.42}
{"epoch": 26, "training_loss": 55.50503349304199, "training_acc": 52.5, "val_loss": 13.787758350372314, "val_acc": 55.0, "val_auroc": 0.354, "time": 244.37}
{"epoch": 27, "training_loss": 55.67684078216553, "training_acc": 52.5, "val_loss": 13.784939050674438, "val_acc": 55.0, "val_auroc": 0.374, "time": 253.21}
{"epoch": 28, "training_loss": 55.67509078979492, "training_acc": 52.5, "val_loss": 13.766155242919922, "val_acc": 55.0, "val_auroc": 0.354, "time": 264.47}
{"epoch": 29, "training_loss": 55.59291076660156, "training_acc": 52.5, "val_loss": 13.77745509147644, "val_acc": 55.0, "val_auroc": 0.354, "time": 273.71}
{"epoch": 30, "training_loss": 55.33890342712402, "training_acc": 52.5, "val_loss": 13.783206939697266, "val_acc": 55.0, "val_auroc": 0.333, "time": 282.28}
{"epoch": 31, "training_loss": 55.332176208496094, "training_acc": 52.5, "val_loss": 13.802826404571533, "val_acc": 55.0, "val_auroc": 0.343, "time": 290.97}
{"epoch": 32, "training_loss": 55.382487297058105, "training_acc": 52.5, "val_loss": 13.8219153881073, "val_acc": 55.0, "val_auroc": 0.343, "time": 299.88}
{"epoch": 33, "training_loss": 55.35941505432129, "training_acc": 52.5, "val_loss": 13.808972835540771, "val_acc": 55.0, "val_auroc": 0.384, "time": 308.37}
{"epoch": 34, "training_loss": 55.331894874572754, "training_acc": 52.5, "val_loss": 13.796241283416748, "val_acc": 55.0, "val_auroc": 0.414, "time": 317.42}
{"epoch": 35, "training_loss": 55.30738544464111, "training_acc": 52.5, "val_loss": 13.780450820922852, "val_acc": 55.0, "val_auroc": 0.414, "time": 326.56}
{"epoch": 36, "training_loss": 55.28899574279785, "training_acc": 52.5, "val_loss": 13.768366575241089, "val_acc": 55.0, "val_auroc": 0.364, "time": 335.33}
{"epoch": 37, "training_loss": 55.35411357879639, "training_acc": 52.5, "val_loss": 13.76834511756897, "val_acc": 55.0, "val_auroc": 0.343, "time": 344.21}
{"epoch": 38, "training_loss": 55.47735118865967, "training_acc": 52.5, "val_loss": 13.779081106185913, "val_acc": 55.0, "val_auroc": 0.343, "time": 353.75}
{"epoch": 39, "training_loss": 55.601253509521484, "training_acc": 52.5, "val_loss": 13.782769441604614, "val_acc": 55.0, "val_auroc": 0.333, "time": 362.58}
{"epoch": 40, "training_loss": 55.63731002807617, "training_acc": 52.5, "val_loss": 13.778645992279053, "val_acc": 55.0, "val_auroc": 0.364, "time": 371.32}
{"epoch": 41, "training_loss": 55.564101219177246, "training_acc": 52.5, "val_loss": 13.76774787902832, "val_acc": 55.0, "val_auroc": 0.394, "time": 380.55}
{"epoch": 42, "training_loss": 55.47149848937988, "training_acc": 52.5, "val_loss": 13.7735116481781, "val_acc": 55.0, "val_auroc": 0.404, "time": 390.58}
{"epoch": 43, "training_loss": 55.38509559631348, "training_acc": 52.5, "val_loss": 13.790541887283325, "val_acc": 55.0, "val_auroc": 0.414, "time": 400.11}
{"epoch": 44, "training_loss": 55.32264232635498, "training_acc": 52.5, "val_loss": 13.80355954170227, "val_acc": 55.0, "val_auroc": 0.414, "time": 409.57}
