"main_optuna_fix_3.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3_early_loss --binary_class True --run_where lab --early_criteria loss"
{"epoch": 0, "training_loss": 56.02582550048828, "training_acc": 46.25, "val_loss": 13.893259763717651, "val_acc": 50.0, "val_auroc": 0.41, "time": 10.33}
{"epoch": 1, "training_loss": 55.61290740966797, "training_acc": 43.75, "val_loss": 13.904783725738525, "val_acc": 50.0, "val_auroc": 0.31, "time": 19.18}
{"epoch": 2, "training_loss": 55.432366371154785, "training_acc": 55.0, "val_loss": 13.924740552902222, "val_acc": 50.0, "val_auroc": 0.32, "time": 28.13}
{"epoch": 3, "training_loss": 55.1524600982666, "training_acc": 53.75, "val_loss": 13.939846754074097, "val_acc": 50.0, "val_auroc": 0.43, "time": 36.88}
{"epoch": 4, "training_loss": 55.19267559051514, "training_acc": 53.75, "val_loss": 13.941086530685425, "val_acc": 50.0, "val_auroc": 0.45, "time": 45.8}
{"epoch": 5, "training_loss": 55.23843479156494, "training_acc": 53.75, "val_loss": 13.918609619140625, "val_acc": 50.0, "val_auroc": 0.56, "time": 54.61}
{"epoch": 6, "training_loss": 55.18783950805664, "training_acc": 53.75, "val_loss": 13.896328210830688, "val_acc": 50.0, "val_auroc": 0.57, "time": 63.27}
{"epoch": 7, "training_loss": 55.202049255371094, "training_acc": 53.75, "val_loss": 13.891030550003052, "val_acc": 50.0, "val_auroc": 0.56, "time": 72.68}
{"epoch": 8, "training_loss": 55.0906867980957, "training_acc": 53.75, "val_loss": 13.88116717338562, "val_acc": 50.0, "val_auroc": 0.58, "time": 82.16}
{"epoch": 9, "training_loss": 55.086992263793945, "training_acc": 53.75, "val_loss": 13.88156771659851, "val_acc": 50.0, "val_auroc": 0.57, "time": 91.0}
{"epoch": 10, "training_loss": 55.11515712738037, "training_acc": 53.75, "val_loss": 13.895978927612305, "val_acc": 50.0, "val_auroc": 0.56, "time": 100.02}
{"epoch": 11, "training_loss": 54.89494228363037, "training_acc": 53.75, "val_loss": 13.939937353134155, "val_acc": 50.0, "val_auroc": 0.52, "time": 109.07}
{"epoch": 12, "training_loss": 54.908915519714355, "training_acc": 53.75, "val_loss": 14.002388715744019, "val_acc": 50.0, "val_auroc": 0.48, "time": 117.94}
{"epoch": 13, "training_loss": 54.87845993041992, "training_acc": 53.75, "val_loss": 14.086936712265015, "val_acc": 50.0, "val_auroc": 0.49, "time": 127.42}
{"epoch": 14, "training_loss": 54.90120220184326, "training_acc": 53.75, "val_loss": 14.19196367263794, "val_acc": 50.0, "val_auroc": 0.53, "time": 137.39}
{"epoch": 15, "training_loss": 55.06904315948486, "training_acc": 53.75, "val_loss": 14.301837682723999, "val_acc": 50.0, "val_auroc": 0.52, "time": 146.45}
{"epoch": 16, "training_loss": 55.5749568939209, "training_acc": 53.75, "val_loss": 14.355767965316772, "val_acc": 50.0, "val_auroc": 0.41, "time": 155.16}
{"epoch": 17, "training_loss": 55.36169910430908, "training_acc": 53.75, "val_loss": 14.311546087265015, "val_acc": 50.0, "val_auroc": 0.36, "time": 163.97}
{"epoch": 18, "training_loss": 55.20737648010254, "training_acc": 53.75, "val_loss": 14.231065511703491, "val_acc": 50.0, "val_auroc": 0.25, "time": 172.92}
{"epoch": 19, "training_loss": 54.87717056274414, "training_acc": 53.75, "val_loss": 14.084110260009766, "val_acc": 50.0, "val_auroc": 0.25, "time": 182.1}
{"epoch": 20, "training_loss": 54.698781967163086, "training_acc": 53.75, "val_loss": 13.953837156295776, "val_acc": 50.0, "val_auroc": 0.29, "time": 190.85}
{"epoch": 21, "training_loss": 55.155019760131836, "training_acc": 55.0, "val_loss": 13.855464458465576, "val_acc": 50.0, "val_auroc": 0.43, "time": 200.18}
{"epoch": 22, "training_loss": 55.15826606750488, "training_acc": 60.0, "val_loss": 13.859893083572388, "val_acc": 50.0, "val_auroc": 0.52, "time": 208.98}
{"epoch": 23, "training_loss": 55.292755126953125, "training_acc": 56.25, "val_loss": 13.876055479049683, "val_acc": 50.0, "val_auroc": 0.69, "time": 217.44}
{"epoch": 24, "training_loss": 55.19727039337158, "training_acc": 53.75, "val_loss": 13.902337551116943, "val_acc": 50.0, "val_auroc": 0.74, "time": 226.34}
{"epoch": 25, "training_loss": 54.834675788879395, "training_acc": 53.75, "val_loss": 13.933664560317993, "val_acc": 50.0, "val_auroc": 0.76, "time": 235.35}
{"epoch": 26, "training_loss": 55.155029296875, "training_acc": 53.75, "val_loss": 13.968836069107056, "val_acc": 50.0, "val_auroc": 0.76, "time": 243.72}
{"epoch": 27, "training_loss": 55.38808727264404, "training_acc": 53.75, "val_loss": 13.99714708328247, "val_acc": 50.0, "val_auroc": 0.74, "time": 252.64}
{"epoch": 28, "training_loss": 55.12636756896973, "training_acc": 53.75, "val_loss": 14.005444049835205, "val_acc": 50.0, "val_auroc": 0.72, "time": 261.5}
{"epoch": 29, "training_loss": 54.92219161987305, "training_acc": 53.75, "val_loss": 13.968913555145264, "val_acc": 50.0, "val_auroc": 0.61, "time": 269.92}
{"epoch": 30, "training_loss": 54.78927230834961, "training_acc": 53.75, "val_loss": 13.961267471313477, "val_acc": 50.0, "val_auroc": 0.55, "time": 278.91}
{"epoch": 31, "training_loss": 54.880611419677734, "training_acc": 53.75, "val_loss": 13.962429761886597, "val_acc": 50.0, "val_auroc": 0.55, "time": 287.89}
{"epoch": 32, "training_loss": 54.70122146606445, "training_acc": 53.75, "val_loss": 13.959075212478638, "val_acc": 50.0, "val_auroc": 0.55, "time": 296.55}
{"epoch": 33, "training_loss": 54.919358253479004, "training_acc": 53.75, "val_loss": 13.962851762771606, "val_acc": 50.0, "val_auroc": 0.53, "time": 305.39}
{"epoch": 34, "training_loss": 54.843984603881836, "training_acc": 53.75, "val_loss": 13.987239599227905, "val_acc": 50.0, "val_auroc": 0.59, "time": 314.42}
{"epoch": 35, "training_loss": 54.7573766708374, "training_acc": 53.75, "val_loss": 14.007242918014526, "val_acc": 50.0, "val_auroc": 0.62, "time": 323.12}
{"epoch": 36, "training_loss": 54.80225372314453, "training_acc": 53.75, "val_loss": 13.988783359527588, "val_acc": 50.0, "val_auroc": 0.67, "time": 331.89}
{"epoch": 37, "training_loss": 54.86131286621094, "training_acc": 53.75, "val_loss": 13.951596021652222, "val_acc": 50.0, "val_auroc": 0.61, "time": 340.75}
{"epoch": 38, "training_loss": 54.79090404510498, "training_acc": 53.75, "val_loss": 13.921194076538086, "val_acc": 50.0, "val_auroc": 0.55, "time": 349.37}
{"epoch": 39, "training_loss": 54.75799369812012, "training_acc": 56.25, "val_loss": 13.918888568878174, "val_acc": 50.0, "val_auroc": 0.51, "time": 358.22}
{"epoch": 40, "training_loss": 54.6673469543457, "training_acc": 61.25, "val_loss": 13.926714658737183, "val_acc": 50.0, "val_auroc": 0.51, "time": 367.02}
