"main_optuna_fix_3.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3_early_loss --binary_class True --run_where lab --early_criteria loss"
{"epoch": 0, "training_loss": 56.02539539337158, "training_acc": 46.25, "val_loss": 13.893436193466187, "val_acc": 50.0, "val_auroc": 0.41, "time": 10.22}
{"epoch": 1, "training_loss": 55.612117767333984, "training_acc": 43.75, "val_loss": 13.90420913696289, "val_acc": 50.0, "val_auroc": 0.3, "time": 19.09}
{"epoch": 2, "training_loss": 55.43849182128906, "training_acc": 55.0, "val_loss": 13.92362117767334, "val_acc": 50.0, "val_auroc": 0.33, "time": 27.9}
{"epoch": 3, "training_loss": 55.159661293029785, "training_acc": 53.75, "val_loss": 13.943532705307007, "val_acc": 50.0, "val_auroc": 0.37, "time": 37.17}
{"epoch": 4, "training_loss": 55.19360542297363, "training_acc": 53.75, "val_loss": 13.951002359390259, "val_acc": 50.0, "val_auroc": 0.43, "time": 46.15}
{"epoch": 5, "training_loss": 55.25284194946289, "training_acc": 53.75, "val_loss": 13.93819808959961, "val_acc": 50.0, "val_auroc": 0.44, "time": 54.9}
{"epoch": 6, "training_loss": 55.18217849731445, "training_acc": 53.75, "val_loss": 13.913544416427612, "val_acc": 50.0, "val_auroc": 0.54, "time": 63.82}
{"epoch": 7, "training_loss": 55.16856002807617, "training_acc": 53.75, "val_loss": 13.899401426315308, "val_acc": 50.0, "val_auroc": 0.56, "time": 73.91}
{"epoch": 8, "training_loss": 55.07118797302246, "training_acc": 53.75, "val_loss": 13.87712836265564, "val_acc": 50.0, "val_auroc": 0.62, "time": 83.17}
{"epoch": 9, "training_loss": 55.06687355041504, "training_acc": 53.75, "val_loss": 13.871105909347534, "val_acc": 50.0, "val_auroc": 0.64, "time": 92.5}
{"epoch": 10, "training_loss": 55.13379669189453, "training_acc": 53.75, "val_loss": 13.883956670761108, "val_acc": 50.0, "val_auroc": 0.57, "time": 103.82}
{"epoch": 11, "training_loss": 54.908172607421875, "training_acc": 53.75, "val_loss": 13.920868635177612, "val_acc": 50.0, "val_auroc": 0.55, "time": 112.64}
{"epoch": 12, "training_loss": 54.913705825805664, "training_acc": 53.75, "val_loss": 13.98586392402649, "val_acc": 50.0, "val_auroc": 0.49, "time": 121.12}
{"epoch": 13, "training_loss": 54.854658126831055, "training_acc": 53.75, "val_loss": 14.071941375732422, "val_acc": 50.0, "val_auroc": 0.47, "time": 130.42}
{"epoch": 14, "training_loss": 54.85685634613037, "training_acc": 53.75, "val_loss": 14.187935590744019, "val_acc": 50.0, "val_auroc": 0.47, "time": 139.44}
{"epoch": 15, "training_loss": 55.03240394592285, "training_acc": 53.75, "val_loss": 14.308212995529175, "val_acc": 50.0, "val_auroc": 0.5, "time": 148.97}
{"epoch": 16, "training_loss": 55.53104114532471, "training_acc": 53.75, "val_loss": 14.362398386001587, "val_acc": 50.0, "val_auroc": 0.42, "time": 157.54}
{"epoch": 17, "training_loss": 55.32019805908203, "training_acc": 53.75, "val_loss": 14.317744970321655, "val_acc": 50.0, "val_auroc": 0.36, "time": 166.29}
{"epoch": 18, "training_loss": 55.14479064941406, "training_acc": 53.75, "val_loss": 14.241862297058105, "val_acc": 50.0, "val_auroc": 0.24, "time": 174.97}
{"epoch": 19, "training_loss": 54.820034980773926, "training_acc": 53.75, "val_loss": 14.101866483688354, "val_acc": 50.0, "val_auroc": 0.25, "time": 184.42}
{"epoch": 20, "training_loss": 54.673495292663574, "training_acc": 53.75, "val_loss": 13.948806524276733, "val_acc": 50.0, "val_auroc": 0.3, "time": 193.1}
{"epoch": 21, "training_loss": 55.11636161804199, "training_acc": 55.0, "val_loss": 13.86456847190857, "val_acc": 50.0, "val_auroc": 0.44, "time": 202.87}
{"epoch": 22, "training_loss": 55.11064529418945, "training_acc": 57.5, "val_loss": 13.866351842880249, "val_acc": 50.0, "val_auroc": 0.48, "time": 212.31}
{"epoch": 23, "training_loss": 55.20261764526367, "training_acc": 56.25, "val_loss": 13.88522744178772, "val_acc": 50.0, "val_auroc": 0.61, "time": 221.67}
{"epoch": 24, "training_loss": 55.168134689331055, "training_acc": 55.0, "val_loss": 13.90952467918396, "val_acc": 50.0, "val_auroc": 0.67, "time": 230.77}
{"epoch": 25, "training_loss": 54.8571081161499, "training_acc": 53.75, "val_loss": 13.93109917640686, "val_acc": 50.0, "val_auroc": 0.7, "time": 239.74}
{"epoch": 26, "training_loss": 55.16513442993164, "training_acc": 53.75, "val_loss": 13.96005630493164, "val_acc": 50.0, "val_auroc": 0.72, "time": 248.69}
{"epoch": 27, "training_loss": 55.31250762939453, "training_acc": 53.75, "val_loss": 13.991231918334961, "val_acc": 50.0, "val_auroc": 0.74, "time": 258.35}
{"epoch": 28, "training_loss": 55.1158971786499, "training_acc": 53.75, "val_loss": 14.007176160812378, "val_acc": 50.0, "val_auroc": 0.69, "time": 267.29}
{"epoch": 29, "training_loss": 54.89326190948486, "training_acc": 53.75, "val_loss": 13.972448110580444, "val_acc": 50.0, "val_auroc": 0.57, "time": 276.88}
{"epoch": 30, "training_loss": 54.794410705566406, "training_acc": 53.75, "val_loss": 13.961852788925171, "val_acc": 50.0, "val_auroc": 0.52, "time": 286.32}
{"epoch": 31, "training_loss": 54.87115478515625, "training_acc": 53.75, "val_loss": 13.960355520248413, "val_acc": 50.0, "val_auroc": 0.51, "time": 295.66}
{"epoch": 32, "training_loss": 54.737056732177734, "training_acc": 53.75, "val_loss": 13.95592451095581, "val_acc": 50.0, "val_auroc": 0.51, "time": 305.31}
{"epoch": 33, "training_loss": 54.909358978271484, "training_acc": 53.75, "val_loss": 13.962833881378174, "val_acc": 50.0, "val_auroc": 0.51, "time": 314.94}
{"epoch": 34, "training_loss": 54.88338851928711, "training_acc": 53.75, "val_loss": 14.00469183921814, "val_acc": 50.0, "val_auroc": 0.56, "time": 323.8}
{"epoch": 35, "training_loss": 54.81649971008301, "training_acc": 53.75, "val_loss": 14.042938947677612, "val_acc": 50.0, "val_auroc": 0.6, "time": 332.59}
{"epoch": 36, "training_loss": 54.804969787597656, "training_acc": 53.75, "val_loss": 14.021408557891846, "val_acc": 50.0, "val_auroc": 0.6, "time": 342.1}
{"epoch": 37, "training_loss": 54.752113342285156, "training_acc": 53.75, "val_loss": 13.964028358459473, "val_acc": 50.0, "val_auroc": 0.53, "time": 351.43}
{"epoch": 38, "training_loss": 54.68092632293701, "training_acc": 53.75, "val_loss": 13.917236328125, "val_acc": 50.0, "val_auroc": 0.49, "time": 360.94}
{"epoch": 39, "training_loss": 54.80952072143555, "training_acc": 58.75, "val_loss": 13.91330599784851, "val_acc": 50.0, "val_auroc": 0.47, "time": 370.44}
{"epoch": 40, "training_loss": 54.69949817657471, "training_acc": 68.75, "val_loss": 13.92969012260437, "val_acc": 50.0, "val_auroc": 0.47, "time": 379.31}
