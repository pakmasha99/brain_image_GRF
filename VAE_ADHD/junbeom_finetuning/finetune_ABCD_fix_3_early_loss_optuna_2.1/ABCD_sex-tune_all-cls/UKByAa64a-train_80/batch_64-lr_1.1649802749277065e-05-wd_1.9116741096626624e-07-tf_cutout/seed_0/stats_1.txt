"main_optuna_fix_3.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3_early_loss --binary_class True --run_where lab --early_criteria loss"
{"epoch": 0, "training_loss": 55.22618293762207, "training_acc": 53.75, "val_loss": 13.99497389793396, "val_acc": 50.0, "val_auroc": 0.52, "time": 11.04}
{"epoch": 1, "training_loss": 55.570444107055664, "training_acc": 53.75, "val_loss": 13.927555084228516, "val_acc": 50.0, "val_auroc": 0.62, "time": 21.56}
{"epoch": 2, "training_loss": 55.27589416503906, "training_acc": 53.75, "val_loss": 13.975965976715088, "val_acc": 50.0, "val_auroc": 0.68, "time": 31.56}
{"epoch": 3, "training_loss": 55.286943435668945, "training_acc": 53.75, "val_loss": 13.965864181518555, "val_acc": 50.0, "val_auroc": 0.64, "time": 41.61}
{"epoch": 4, "training_loss": 55.134172439575195, "training_acc": 53.75, "val_loss": 13.900059461593628, "val_acc": 50.0, "val_auroc": 0.64, "time": 51.98}
{"epoch": 5, "training_loss": 54.9674654006958, "training_acc": 53.75, "val_loss": 13.897082805633545, "val_acc": 50.0, "val_auroc": 0.49, "time": 62.36}
{"epoch": 6, "training_loss": 55.114906311035156, "training_acc": 53.75, "val_loss": 13.868328332901001, "val_acc": 50.0, "val_auroc": 0.55, "time": 73.18}
{"epoch": 7, "training_loss": 54.81778144836426, "training_acc": 53.75, "val_loss": 13.892441987991333, "val_acc": 50.0, "val_auroc": 0.52, "time": 84.64}
{"epoch": 8, "training_loss": 54.78133583068848, "training_acc": 53.75, "val_loss": 13.895775079727173, "val_acc": 50.0, "val_auroc": 0.49, "time": 94.7}
{"epoch": 9, "training_loss": 54.52017307281494, "training_acc": 53.75, "val_loss": 13.87581467628479, "val_acc": 50.0, "val_auroc": 0.49, "time": 104.66}
{"epoch": 10, "training_loss": 54.926475524902344, "training_acc": 55.0, "val_loss": 13.805550336837769, "val_acc": 50.0, "val_auroc": 0.63, "time": 115.0}
{"epoch": 11, "training_loss": 54.79177188873291, "training_acc": 57.5, "val_loss": 13.820793628692627, "val_acc": 50.0, "val_auroc": 0.66, "time": 125.0}
{"epoch": 12, "training_loss": 54.90774345397949, "training_acc": 53.75, "val_loss": 13.931375741958618, "val_acc": 50.0, "val_auroc": 0.61, "time": 135.01}
{"epoch": 13, "training_loss": 54.8887939453125, "training_acc": 53.75, "val_loss": 14.240096807479858, "val_acc": 50.0, "val_auroc": 0.48, "time": 144.93}
{"epoch": 14, "training_loss": 55.14668655395508, "training_acc": 53.75, "val_loss": 14.651721715927124, "val_acc": 50.0, "val_auroc": 0.49, "time": 154.85}
{"epoch": 15, "training_loss": 55.66667175292969, "training_acc": 53.75, "val_loss": 14.49779748916626, "val_acc": 50.0, "val_auroc": 0.52, "time": 164.7}
{"epoch": 16, "training_loss": 56.56142997741699, "training_acc": 53.75, "val_loss": 13.93532395362854, "val_acc": 50.0, "val_auroc": 0.54, "time": 174.59}
{"epoch": 17, "training_loss": 54.16715621948242, "training_acc": 53.75, "val_loss": 13.77153992652893, "val_acc": 50.0, "val_auroc": 0.63, "time": 185.12}
{"epoch": 18, "training_loss": 54.60377311706543, "training_acc": 65.0, "val_loss": 13.764718770980835, "val_acc": 50.0, "val_auroc": 0.7, "time": 195.34}
{"epoch": 19, "training_loss": 54.57499313354492, "training_acc": 66.25, "val_loss": 13.76659631729126, "val_acc": 50.0, "val_auroc": 0.59, "time": 205.08}
{"epoch": 20, "training_loss": 54.770071029663086, "training_acc": 53.75, "val_loss": 13.823422193527222, "val_acc": 50.0, "val_auroc": 0.59, "time": 214.74}
{"epoch": 21, "training_loss": 54.11678886413574, "training_acc": 55.0, "val_loss": 13.934435844421387, "val_acc": 50.0, "val_auroc": 0.57, "time": 224.56}
{"epoch": 22, "training_loss": 54.30125713348389, "training_acc": 53.75, "val_loss": 14.254124164581299, "val_acc": 50.0, "val_auroc": 0.56, "time": 234.3}
{"epoch": 23, "training_loss": 53.61851692199707, "training_acc": 55.0, "val_loss": 14.370241165161133, "val_acc": 50.0, "val_auroc": 0.57, "time": 244.19}
{"epoch": 24, "training_loss": 54.931861877441406, "training_acc": 52.5, "val_loss": 14.023408889770508, "val_acc": 50.0, "val_auroc": 0.57, "time": 253.99}
{"epoch": 25, "training_loss": 53.119845390319824, "training_acc": 55.0, "val_loss": 13.83523941040039, "val_acc": 50.0, "val_auroc": 0.62, "time": 263.86}
{"epoch": 26, "training_loss": 54.02891254425049, "training_acc": 55.0, "val_loss": 13.744701147079468, "val_acc": 50.0, "val_auroc": 0.58, "time": 273.94}
{"epoch": 27, "training_loss": 53.93919372558594, "training_acc": 53.75, "val_loss": 13.780906200408936, "val_acc": 50.0, "val_auroc": 0.61, "time": 283.71}
{"epoch": 28, "training_loss": 53.83462715148926, "training_acc": 60.0, "val_loss": 13.785120248794556, "val_acc": 50.0, "val_auroc": 0.59, "time": 293.53}
{"epoch": 29, "training_loss": 52.733619689941406, "training_acc": 62.5, "val_loss": 13.642429113388062, "val_acc": 50.0, "val_auroc": 0.62, "time": 303.66}
{"epoch": 30, "training_loss": 53.0502872467041, "training_acc": 67.5, "val_loss": 13.768758773803711, "val_acc": 50.0, "val_auroc": 0.62, "time": 313.41}
{"epoch": 31, "training_loss": 52.715365409851074, "training_acc": 60.0, "val_loss": 14.69502329826355, "val_acc": 50.0, "val_auroc": 0.6, "time": 323.1}
{"epoch": 32, "training_loss": 52.92991065979004, "training_acc": 56.25, "val_loss": 14.045006036758423, "val_acc": 50.0, "val_auroc": 0.62, "time": 332.79}
{"epoch": 33, "training_loss": 53.27943229675293, "training_acc": 60.0, "val_loss": 13.573356866836548, "val_acc": 50.0, "val_auroc": 0.67, "time": 342.83}
{"epoch": 34, "training_loss": 52.79869747161865, "training_acc": 65.0, "val_loss": 13.588050603866577, "val_acc": 50.0, "val_auroc": 0.64, "time": 352.68}
{"epoch": 35, "training_loss": 51.48433303833008, "training_acc": 67.5, "val_loss": 13.854788541793823, "val_acc": 50.0, "val_auroc": 0.65, "time": 362.55}
{"epoch": 36, "training_loss": 51.47747230529785, "training_acc": 58.75, "val_loss": 13.444799184799194, "val_acc": 50.0, "val_auroc": 0.69, "time": 372.9}
{"epoch": 37, "training_loss": 51.69858360290527, "training_acc": 71.25, "val_loss": 13.968335390090942, "val_acc": 50.0, "val_auroc": 0.69, "time": 384.32}
{"epoch": 38, "training_loss": 55.439218521118164, "training_acc": 47.5, "val_loss": 13.746834993362427, "val_acc": 50.0, "val_auroc": 0.65, "time": 394.31}
{"epoch": 39, "training_loss": 53.7802619934082, "training_acc": 53.75, "val_loss": 13.698509931564331, "val_acc": 50.0, "val_auroc": 0.68, "time": 404.1}
{"epoch": 40, "training_loss": 51.72108745574951, "training_acc": 58.75, "val_loss": 14.664844274520874, "val_acc": 50.0, "val_auroc": 0.67, "time": 414.1}
{"epoch": 41, "training_loss": 53.54290771484375, "training_acc": 53.75, "val_loss": 14.124099016189575, "val_acc": 50.0, "val_auroc": 0.62, "time": 423.99}
{"epoch": 42, "training_loss": 52.59919357299805, "training_acc": 53.75, "val_loss": 13.635506629943848, "val_acc": 50.0, "val_auroc": 0.62, "time": 433.99}
{"epoch": 43, "training_loss": 52.33258056640625, "training_acc": 67.5, "val_loss": 13.834623098373413, "val_acc": 50.0, "val_auroc": 0.6, "time": 443.95}
{"epoch": 44, "training_loss": 52.34804916381836, "training_acc": 57.5, "val_loss": 13.625324964523315, "val_acc": 50.0, "val_auroc": 0.6, "time": 453.85}
{"epoch": 45, "training_loss": 51.127275466918945, "training_acc": 68.75, "val_loss": 14.829648733139038, "val_acc": 50.0, "val_auroc": 0.61, "time": 463.8}
{"epoch": 46, "training_loss": 52.50647830963135, "training_acc": 50.0, "val_loss": 14.045342206954956, "val_acc": 55.0, "val_auroc": 0.58, "time": 473.82}
{"epoch": 47, "training_loss": 50.26969242095947, "training_acc": 60.0, "val_loss": 13.70477557182312, "val_acc": 55.0, "val_auroc": 0.56, "time": 483.84}
{"epoch": 48, "training_loss": 50.08201789855957, "training_acc": 67.5, "val_loss": 13.913658857345581, "val_acc": 50.0, "val_auroc": 0.56, "time": 493.84}
{"epoch": 49, "training_loss": 50.84334754943848, "training_acc": 60.0, "val_loss": 14.505844116210938, "val_acc": 50.0, "val_auroc": 0.58, "time": 504.06}
{"epoch": 50, "training_loss": 49.36557388305664, "training_acc": 56.25, "val_loss": 13.609144687652588, "val_acc": 50.0, "val_auroc": 0.56, "time": 514.08}
{"epoch": 51, "training_loss": 48.26875972747803, "training_acc": 73.75, "val_loss": 13.55993390083313, "val_acc": 45.0, "val_auroc": 0.56, "time": 524.31}
{"epoch": 52, "training_loss": 46.72469520568848, "training_acc": 72.5, "val_loss": 14.148668050765991, "val_acc": 55.0, "val_auroc": 0.6, "time": 534.54}
{"epoch": 53, "training_loss": 44.177395820617676, "training_acc": 70.0, "val_loss": 14.165786504745483, "val_acc": 55.0, "val_auroc": 0.61, "time": 544.76}
{"epoch": 54, "training_loss": 45.50302028656006, "training_acc": 68.75, "val_loss": 13.676155805587769, "val_acc": 50.0, "val_auroc": 0.59, "time": 555.45}
{"epoch": 55, "training_loss": 44.447776794433594, "training_acc": 68.75, "val_loss": 13.85318636894226, "val_acc": 50.0, "val_auroc": 0.56, "time": 566.13}
