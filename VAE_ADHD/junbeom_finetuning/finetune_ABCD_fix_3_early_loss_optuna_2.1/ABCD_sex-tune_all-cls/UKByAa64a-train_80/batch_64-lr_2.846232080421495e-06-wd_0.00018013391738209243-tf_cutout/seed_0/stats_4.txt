"main_optuna_fix_3.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3_early_loss --binary_class True --run_where lab --early_criteria loss"
{"epoch": 0, "training_loss": 55.69002723693848, "training_acc": 45.0, "val_loss": 13.958338499069214, "val_acc": 55.0, "val_auroc": 0.455, "time": 13.05}
{"epoch": 1, "training_loss": 55.76409149169922, "training_acc": 47.5, "val_loss": 13.931734561920166, "val_acc": 55.0, "val_auroc": 0.475, "time": 22.38}
{"epoch": 2, "training_loss": 55.543561935424805, "training_acc": 50.0, "val_loss": 13.880128860473633, "val_acc": 55.0, "val_auroc": 0.455, "time": 31.66}
{"epoch": 3, "training_loss": 55.47942543029785, "training_acc": 52.5, "val_loss": 13.840410709381104, "val_acc": 55.0, "val_auroc": 0.455, "time": 41.13}
{"epoch": 4, "training_loss": 55.29247856140137, "training_acc": 52.5, "val_loss": 13.819917440414429, "val_acc": 55.0, "val_auroc": 0.475, "time": 50.68}
{"epoch": 5, "training_loss": 55.4103422164917, "training_acc": 52.5, "val_loss": 13.805652856826782, "val_acc": 55.0, "val_auroc": 0.495, "time": 59.39}
{"epoch": 6, "training_loss": 55.31047821044922, "training_acc": 52.5, "val_loss": 13.798259496688843, "val_acc": 55.0, "val_auroc": 0.465, "time": 68.72}
{"epoch": 7, "training_loss": 55.281490325927734, "training_acc": 52.5, "val_loss": 13.792771100997925, "val_acc": 55.0, "val_auroc": 0.455, "time": 77.75}
{"epoch": 8, "training_loss": 55.21577453613281, "training_acc": 52.5, "val_loss": 13.789585828781128, "val_acc": 55.0, "val_auroc": 0.444, "time": 87.0}
{"epoch": 9, "training_loss": 55.29121017456055, "training_acc": 52.5, "val_loss": 13.78552794456482, "val_acc": 55.0, "val_auroc": 0.434, "time": 95.9}
{"epoch": 10, "training_loss": 55.27430248260498, "training_acc": 52.5, "val_loss": 13.77747893333435, "val_acc": 55.0, "val_auroc": 0.455, "time": 104.9}
{"epoch": 11, "training_loss": 55.233981132507324, "training_acc": 52.5, "val_loss": 13.768621683120728, "val_acc": 55.0, "val_auroc": 0.505, "time": 113.92}
{"epoch": 12, "training_loss": 55.21877098083496, "training_acc": 52.5, "val_loss": 13.753461837768555, "val_acc": 55.0, "val_auroc": 0.556, "time": 123.85}
{"epoch": 13, "training_loss": 55.252909660339355, "training_acc": 52.5, "val_loss": 13.748769760131836, "val_acc": 55.0, "val_auroc": 0.586, "time": 132.83}
{"epoch": 14, "training_loss": 55.10117721557617, "training_acc": 52.5, "val_loss": 13.74863862991333, "val_acc": 55.0, "val_auroc": 0.596, "time": 141.95}
{"epoch": 15, "training_loss": 55.25535774230957, "training_acc": 52.5, "val_loss": 13.754585981369019, "val_acc": 55.0, "val_auroc": 0.556, "time": 150.47}
{"epoch": 16, "training_loss": 55.335716247558594, "training_acc": 52.5, "val_loss": 13.760296106338501, "val_acc": 55.0, "val_auroc": 0.525, "time": 159.46}
{"epoch": 17, "training_loss": 55.25629425048828, "training_acc": 52.5, "val_loss": 13.767702579498291, "val_acc": 55.0, "val_auroc": 0.485, "time": 168.51}
{"epoch": 18, "training_loss": 55.12535095214844, "training_acc": 52.5, "val_loss": 13.776804208755493, "val_acc": 55.0, "val_auroc": 0.465, "time": 177.75}
{"epoch": 19, "training_loss": 54.922447204589844, "training_acc": 52.5, "val_loss": 13.785924911499023, "val_acc": 55.0, "val_auroc": 0.485, "time": 186.48}
{"epoch": 20, "training_loss": 55.060346603393555, "training_acc": 52.5, "val_loss": 13.792427778244019, "val_acc": 55.0, "val_auroc": 0.465, "time": 195.47}
{"epoch": 21, "training_loss": 55.20305919647217, "training_acc": 52.5, "val_loss": 13.797836303710938, "val_acc": 55.0, "val_auroc": 0.465, "time": 204.72}
{"epoch": 22, "training_loss": 54.998863220214844, "training_acc": 52.5, "val_loss": 13.80275845527649, "val_acc": 55.0, "val_auroc": 0.465, "time": 213.67}
{"epoch": 23, "training_loss": 55.124558448791504, "training_acc": 52.5, "val_loss": 13.807251453399658, "val_acc": 55.0, "val_auroc": 0.455, "time": 222.4}
{"epoch": 24, "training_loss": 55.014084815979004, "training_acc": 52.5, "val_loss": 13.81237268447876, "val_acc": 55.0, "val_auroc": 0.455, "time": 231.81}
{"epoch": 25, "training_loss": 54.76837730407715, "training_acc": 52.5, "val_loss": 13.80610704421997, "val_acc": 55.0, "val_auroc": 0.465, "time": 240.65}
{"epoch": 26, "training_loss": 54.96748447418213, "training_acc": 52.5, "val_loss": 13.783680200576782, "val_acc": 55.0, "val_auroc": 0.475, "time": 249.38}
{"epoch": 27, "training_loss": 54.50994873046875, "training_acc": 52.5, "val_loss": 13.771535158157349, "val_acc": 55.0, "val_auroc": 0.495, "time": 258.27}
{"epoch": 28, "training_loss": 54.94002151489258, "training_acc": 52.5, "val_loss": 13.769779205322266, "val_acc": 55.0, "val_auroc": 0.495, "time": 267.54}
{"epoch": 29, "training_loss": 54.88013172149658, "training_acc": 52.5, "val_loss": 13.771146535873413, "val_acc": 55.0, "val_auroc": 0.505, "time": 276.43}
{"epoch": 30, "training_loss": 54.951924324035645, "training_acc": 52.5, "val_loss": 13.774718046188354, "val_acc": 55.0, "val_auroc": 0.505, "time": 285.44}
{"epoch": 31, "training_loss": 54.97647476196289, "training_acc": 52.5, "val_loss": 13.786828517913818, "val_acc": 55.0, "val_auroc": 0.495, "time": 294.49}
{"epoch": 32, "training_loss": 54.36870098114014, "training_acc": 52.5, "val_loss": 13.800954818725586, "val_acc": 55.0, "val_auroc": 0.485, "time": 303.07}
{"epoch": 33, "training_loss": 54.77546691894531, "training_acc": 52.5, "val_loss": 13.811870813369751, "val_acc": 55.0, "val_auroc": 0.485, "time": 312.71}
