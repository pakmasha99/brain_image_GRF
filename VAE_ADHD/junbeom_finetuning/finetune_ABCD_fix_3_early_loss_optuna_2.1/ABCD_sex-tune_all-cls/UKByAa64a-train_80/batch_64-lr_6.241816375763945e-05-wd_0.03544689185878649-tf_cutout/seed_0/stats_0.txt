"main_optuna_fix_3.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3_early_loss --binary_class True --run_where lab --early_criteria loss"
{"epoch": 0, "training_loss": 55.51709461212158, "training_acc": 53.75, "val_loss": 13.927357196807861, "val_acc": 50.0, "val_auroc": 0.15, "time": 9.98}
{"epoch": 1, "training_loss": 55.42959976196289, "training_acc": 53.75, "val_loss": 13.892096281051636, "val_acc": 50.0, "val_auroc": 0.61, "time": 19.29}
{"epoch": 2, "training_loss": 55.26631736755371, "training_acc": 53.75, "val_loss": 13.894580602645874, "val_acc": 50.0, "val_auroc": 0.62, "time": 28.2}
{"epoch": 3, "training_loss": 55.24333572387695, "training_acc": 53.75, "val_loss": 13.89493703842163, "val_acc": 50.0, "val_auroc": 0.52, "time": 37.54}
{"epoch": 4, "training_loss": 55.11950492858887, "training_acc": 53.75, "val_loss": 13.89955759048462, "val_acc": 50.0, "val_auroc": 0.49, "time": 46.57}
{"epoch": 5, "training_loss": 55.19979476928711, "training_acc": 53.75, "val_loss": 13.887195587158203, "val_acc": 50.0, "val_auroc": 0.46, "time": 55.62}
{"epoch": 6, "training_loss": 55.209327697753906, "training_acc": 53.75, "val_loss": 13.893197774887085, "val_acc": 50.0, "val_auroc": 0.43, "time": 64.59}
{"epoch": 7, "training_loss": 55.21749019622803, "training_acc": 53.75, "val_loss": 13.907513618469238, "val_acc": 50.0, "val_auroc": 0.51, "time": 73.65}
{"epoch": 8, "training_loss": 55.080796241760254, "training_acc": 53.75, "val_loss": 13.886032104492188, "val_acc": 50.0, "val_auroc": 0.5, "time": 82.99}
{"epoch": 9, "training_loss": 55.09885120391846, "training_acc": 53.75, "val_loss": 13.900035619735718, "val_acc": 50.0, "val_auroc": 0.57, "time": 91.94}
{"epoch": 10, "training_loss": 55.059391021728516, "training_acc": 53.75, "val_loss": 13.945471048355103, "val_acc": 50.0, "val_auroc": 0.57, "time": 100.64}
{"epoch": 11, "training_loss": 54.9981803894043, "training_acc": 53.75, "val_loss": 14.044049978256226, "val_acc": 50.0, "val_auroc": 0.32, "time": 109.67}
{"epoch": 12, "training_loss": 55.12442207336426, "training_acc": 53.75, "val_loss": 14.109420776367188, "val_acc": 50.0, "val_auroc": 0.42, "time": 118.8}
{"epoch": 13, "training_loss": 55.23978233337402, "training_acc": 53.75, "val_loss": 14.1454017162323, "val_acc": 50.0, "val_auroc": 0.53, "time": 127.68}
{"epoch": 14, "training_loss": 55.18375015258789, "training_acc": 53.75, "val_loss": 14.315118789672852, "val_acc": 50.0, "val_auroc": 0.59, "time": 136.44}
{"epoch": 15, "training_loss": 55.44211769104004, "training_acc": 53.75, "val_loss": 14.31592345237732, "val_acc": 50.0, "val_auroc": 0.26, "time": 145.95}
{"epoch": 16, "training_loss": 55.73870277404785, "training_acc": 53.75, "val_loss": 14.097145795822144, "val_acc": 50.0, "val_auroc": 0.29, "time": 154.99}
{"epoch": 17, "training_loss": 55.18819999694824, "training_acc": 53.75, "val_loss": 13.967287540435791, "val_acc": 50.0, "val_auroc": 0.41, "time": 163.98}
{"epoch": 18, "training_loss": 55.11645317077637, "training_acc": 53.75, "val_loss": 13.968900442123413, "val_acc": 50.0, "val_auroc": 0.47, "time": 172.75}
{"epoch": 19, "training_loss": 55.27735710144043, "training_acc": 53.75, "val_loss": 13.901512622833252, "val_acc": 50.0, "val_auroc": 0.52, "time": 181.87}
{"epoch": 20, "training_loss": 55.14895057678223, "training_acc": 53.75, "val_loss": 13.868979215621948, "val_acc": 50.0, "val_auroc": 0.49, "time": 191.17}
{"epoch": 21, "training_loss": 55.352264404296875, "training_acc": 51.25, "val_loss": 13.88351321220398, "val_acc": 50.0, "val_auroc": 0.55, "time": 200.23}
{"epoch": 22, "training_loss": 55.159542083740234, "training_acc": 53.75, "val_loss": 13.994768857955933, "val_acc": 50.0, "val_auroc": 0.59, "time": 209.04}
{"epoch": 23, "training_loss": 55.22474002838135, "training_acc": 53.75, "val_loss": 14.032621383666992, "val_acc": 50.0, "val_auroc": 0.33, "time": 217.97}
{"epoch": 24, "training_loss": 55.087242126464844, "training_acc": 53.75, "val_loss": 13.940260410308838, "val_acc": 50.0, "val_auroc": 0.39, "time": 227.31}
{"epoch": 25, "training_loss": 55.10476589202881, "training_acc": 53.75, "val_loss": 13.906139135360718, "val_acc": 50.0, "val_auroc": 0.36, "time": 236.45}
{"epoch": 26, "training_loss": 55.14982604980469, "training_acc": 53.75, "val_loss": 13.933626413345337, "val_acc": 50.0, "val_auroc": 0.38, "time": 245.38}
{"epoch": 27, "training_loss": 55.22297191619873, "training_acc": 53.75, "val_loss": 14.008346796035767, "val_acc": 50.0, "val_auroc": 0.39, "time": 254.45}
{"epoch": 28, "training_loss": 55.218398094177246, "training_acc": 53.75, "val_loss": 13.990399837493896, "val_acc": 50.0, "val_auroc": 0.4, "time": 263.48}
{"epoch": 29, "training_loss": 55.16964817047119, "training_acc": 53.75, "val_loss": 13.938803672790527, "val_acc": 50.0, "val_auroc": 0.35, "time": 274.83}
{"epoch": 30, "training_loss": 55.14095878601074, "training_acc": 53.75, "val_loss": 13.95067811012268, "val_acc": 50.0, "val_auroc": 0.34, "time": 283.64}
{"epoch": 31, "training_loss": 55.145965576171875, "training_acc": 53.75, "val_loss": 13.951177597045898, "val_acc": 50.0, "val_auroc": 0.36, "time": 292.07}
{"epoch": 32, "training_loss": 55.02028465270996, "training_acc": 53.75, "val_loss": 13.923934698104858, "val_acc": 50.0, "val_auroc": 0.38, "time": 301.07}
{"epoch": 33, "training_loss": 55.11436176300049, "training_acc": 53.75, "val_loss": 13.944305181503296, "val_acc": 50.0, "val_auroc": 0.44, "time": 310.47}
{"epoch": 34, "training_loss": 55.04342174530029, "training_acc": 53.75, "val_loss": 14.054419994354248, "val_acc": 50.0, "val_auroc": 0.43, "time": 319.18}
{"epoch": 35, "training_loss": 55.15862274169922, "training_acc": 53.75, "val_loss": 14.056274890899658, "val_acc": 50.0, "val_auroc": 0.34, "time": 327.8}
{"epoch": 36, "training_loss": 55.02633857727051, "training_acc": 53.75, "val_loss": 13.923066854476929, "val_acc": 50.0, "val_auroc": 0.32, "time": 336.49}
{"epoch": 37, "training_loss": 55.030029296875, "training_acc": 53.75, "val_loss": 13.872488737106323, "val_acc": 50.0, "val_auroc": 0.43, "time": 344.61}
{"epoch": 38, "training_loss": 55.30843448638916, "training_acc": 60.0, "val_loss": 13.875536918640137, "val_acc": 50.0, "val_auroc": 0.4, "time": 353.2}
{"epoch": 39, "training_loss": 55.51315975189209, "training_acc": 46.25, "val_loss": 13.874849081039429, "val_acc": 50.0, "val_auroc": 0.35, "time": 362.0}
