"main_optuna_fix_3.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3_early_loss --binary_class True --run_where lab --early_criteria loss"
{"epoch": 0, "training_loss": 310.9883689880371, "training_acc": 45.0, "val_loss": 11601664000.0, "val_acc": 55.0, "val_auroc": 0.414, "time": 10.47}
{"epoch": 1, "training_loss": 41761618121.125, "training_acc": 45.0, "val_loss": 17166078.75, "val_acc": 45.0, "val_auroc": 0.616, "time": 19.91}
{"epoch": 2, "training_loss": 76794152.0, "training_acc": 50.0, "val_loss": 53113.92578125, "val_acc": 55.0, "val_auroc": 0.384, "time": 29.13}
{"epoch": 3, "training_loss": 646584.390625, "training_acc": 52.5, "val_loss": 82886.533203125, "val_acc": 45.0, "val_auroc": 0.576, "time": 38.13}
{"epoch": 4, "training_loss": 253395.64453125, "training_acc": 47.5, "val_loss": 769.7427368164062, "val_acc": 55.0, "val_auroc": 0.374, "time": 47.74}
{"epoch": 5, "training_loss": 101513.64428710938, "training_acc": 50.0, "val_loss": 934.3637847900391, "val_acc": 45.0, "val_auroc": 0.354, "time": 56.71}
{"epoch": 6, "training_loss": 18323.12451171875, "training_acc": 50.0, "val_loss": 4761.3751220703125, "val_acc": 45.0, "val_auroc": 0.566, "time": 65.77}
{"epoch": 7, "training_loss": 20443.52880859375, "training_acc": 47.5, "val_loss": 1260.999526977539, "val_acc": 55.0, "val_auroc": 0.626, "time": 74.58}
{"epoch": 8, "training_loss": 15009.55908203125, "training_acc": 57.5, "val_loss": 1331.1558532714844, "val_acc": 45.0, "val_auroc": 0.646, "time": 83.59}
{"epoch": 9, "training_loss": 56423.031005859375, "training_acc": 47.5, "val_loss": 4435.612487792969, "val_acc": 55.0, "val_auroc": 0.465, "time": 92.43}
{"epoch": 10, "training_loss": 16828.230834960938, "training_acc": 52.5, "val_loss": 426.1451721191406, "val_acc": 45.0, "val_auroc": 0.515, "time": 102.11}
{"epoch": 11, "training_loss": 3334.84033203125, "training_acc": 52.5, "val_loss": 28163.28125, "val_acc": 45.0, "val_auroc": 0.495, "time": 110.95}
{"epoch": 12, "training_loss": 89876.8486328125, "training_acc": 45.0, "val_loss": 14221.341552734375, "val_acc": 45.0, "val_auroc": 0.586, "time": 119.84}
{"epoch": 13, "training_loss": 47588.2431640625, "training_acc": 50.0, "val_loss": 1467.392578125, "val_acc": 45.0, "val_auroc": 0.606, "time": 128.6}
{"epoch": 14, "training_loss": 218387.1650390625, "training_acc": 45.0, "val_loss": 4513100.9375, "val_acc": 45.0, "val_auroc": 0.455, "time": 137.32}
{"epoch": 15, "training_loss": 12579343.51953125, "training_acc": 47.5, "val_loss": 6752.933349609375, "val_acc": 45.0, "val_auroc": 0.313, "time": 146.15}
{"epoch": 16, "training_loss": 22058.374633789062, "training_acc": 57.5, "val_loss": 3693.6166381835938, "val_acc": 45.0, "val_auroc": 0.404, "time": 155.4}
{"epoch": 17, "training_loss": 196858.765625, "training_acc": 45.0, "val_loss": 395384.4921875, "val_acc": 45.0, "val_auroc": 0.535, "time": 164.11}
{"epoch": 18, "training_loss": 1264620.59375, "training_acc": 45.0, "val_loss": 38496.36474609375, "val_acc": 45.0, "val_auroc": 0.596, "time": 173.17}
{"epoch": 19, "training_loss": 1156647.828125, "training_acc": 45.0, "val_loss": 80163.8916015625, "val_acc": 45.0, "val_auroc": 0.727, "time": 182.08}
{"epoch": 20, "training_loss": 254758.6328125, "training_acc": 50.0, "val_loss": 342967.7734375, "val_acc": 45.0, "val_auroc": 0.606, "time": 190.7}
{"epoch": 21, "training_loss": 1362809.59375, "training_acc": 47.5, "val_loss": 881328.75, "val_acc": 45.0, "val_auroc": 0.424, "time": 199.4}
{"epoch": 22, "training_loss": 2650518.5234375, "training_acc": 50.0, "val_loss": 49777.5634765625, "val_acc": 45.0, "val_auroc": 0.485, "time": 208.61}
{"epoch": 23, "training_loss": 324435.140625, "training_acc": 50.0, "val_loss": 69108.173828125, "val_acc": 55.0, "val_auroc": 0.495, "time": 217.32}
{"epoch": 24, "training_loss": 259815.001953125, "training_acc": 45.0, "val_loss": 47806.0400390625, "val_acc": 55.0, "val_auroc": 0.333, "time": 226.33}
{"epoch": 25, "training_loss": 252410.53125, "training_acc": 45.0, "val_loss": 12562.90283203125, "val_acc": 45.0, "val_auroc": 0.485, "time": 235.2}
{"epoch": 26, "training_loss": 39383.95458984375, "training_acc": 52.5, "val_loss": 28525.64453125, "val_acc": 45.0, "val_auroc": 0.626, "time": 243.77}
{"epoch": 27, "training_loss": 112301.15234375, "training_acc": 47.5, "val_loss": 1155765.0, "val_acc": 55.0, "val_auroc": 0.687, "time": 252.36}
{"epoch": 28, "training_loss": 353004643.0, "training_acc": 57.5, "val_loss": 16218.929443359375, "val_acc": 45.0, "val_auroc": 0.253, "time": 261.3}
{"epoch": 29, "training_loss": 606294.6484375, "training_acc": 50.0, "val_loss": 30158.17138671875, "val_acc": 55.0, "val_auroc": 0.566, "time": 272.8}
