"main_optuna_fix_3.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3_early_loss --binary_class True --run_where lab --early_criteria loss"
{"epoch": 0, "training_loss": 297.77418518066406, "training_acc": 40.0, "val_loss": 2.933158525796352e+16, "val_acc": 50.0, "val_auroc": 0.32, "time": 10.3}
{"epoch": 1, "training_loss": 9.199773562562245e+16, "training_acc": 46.25, "val_loss": 52732445.0, "val_acc": 50.0, "val_auroc": 0.7, "time": 19.58}
{"epoch": 2, "training_loss": 215103416.0, "training_acc": 46.25, "val_loss": 187513.8671875, "val_acc": 50.0, "val_auroc": 0.69, "time": 28.98}
{"epoch": 3, "training_loss": 1814582.625, "training_acc": 46.25, "val_loss": 602974.3359375, "val_acc": 50.0, "val_auroc": 0.35, "time": 38.09}
{"epoch": 4, "training_loss": 1725237.740234375, "training_acc": 53.75, "val_loss": 2560405.3125, "val_acc": 50.0, "val_auroc": 0.6, "time": 49.62}
{"epoch": 5, "training_loss": 8732709.234375, "training_acc": 46.25, "val_loss": 1598744.21875, "val_acc": 50.0, "val_auroc": 0.42, "time": 58.54}
{"epoch": 6, "training_loss": 5105321.1875, "training_acc": 53.75, "val_loss": 257277.36328125, "val_acc": 50.0, "val_auroc": 0.41, "time": 67.43}
{"epoch": 7, "training_loss": 773399.322265625, "training_acc": 53.75, "val_loss": 253241.85546875, "val_acc": 50.0, "val_auroc": 0.57, "time": 76.08}
{"epoch": 8, "training_loss": 914484.2890625, "training_acc": 46.25, "val_loss": 16703.035888671875, "val_acc": 50.0, "val_auroc": 0.35, "time": 85.38}
{"epoch": 9, "training_loss": 66938.5302734375, "training_acc": 43.75, "val_loss": 204883.41796875, "val_acc": 50.0, "val_auroc": 0.48, "time": 94.43}
{"epoch": 10, "training_loss": 720331.73046875, "training_acc": 48.75, "val_loss": 56831.064453125, "val_acc": 50.0, "val_auroc": 0.33, "time": 102.8}
{"epoch": 11, "training_loss": 209454.671875, "training_acc": 53.75, "val_loss": 10305.438232421875, "val_acc": 50.0, "val_auroc": 0.47, "time": 111.98}
{"epoch": 12, "training_loss": 134911.44140625, "training_acc": 48.75, "val_loss": 24970.37841796875, "val_acc": 50.0, "val_auroc": 0.47, "time": 120.98}
{"epoch": 13, "training_loss": 484998.46875, "training_acc": 48.75, "val_loss": 37025.49560546875, "val_acc": 50.0, "val_auroc": 0.55, "time": 129.35}
{"epoch": 14, "training_loss": 148028.60546875, "training_acc": 46.25, "val_loss": 1892201.25, "val_acc": 50.0, "val_auroc": 0.36, "time": 138.04}
{"epoch": 15, "training_loss": 6120459.453125, "training_acc": 53.75, "val_loss": 218619.58984375, "val_acc": 50.0, "val_auroc": 0.66, "time": 147.13}
{"epoch": 16, "training_loss": 676895.0258789062, "training_acc": 53.75, "val_loss": 81942.685546875, "val_acc": 50.0, "val_auroc": 0.7, "time": 155.53}
{"epoch": 17, "training_loss": 360028.3515625, "training_acc": 46.25, "val_loss": 338.0923080444336, "val_acc": 55.0, "val_auroc": 0.58, "time": 164.63}
{"epoch": 18, "training_loss": 191492.4052734375, "training_acc": 42.5, "val_loss": 174825.15625, "val_acc": 50.0, "val_auroc": 0.74, "time": 173.93}
{"epoch": 19, "training_loss": 661180.6953125, "training_acc": 46.25, "val_loss": 15272.14111328125, "val_acc": 50.0, "val_auroc": 0.44, "time": 182.98}
{"epoch": 20, "training_loss": 182079.23046875, "training_acc": 53.75, "val_loss": 6820.0457763671875, "val_acc": 50.0, "val_auroc": 0.28, "time": 191.37}
{"epoch": 21, "training_loss": 44599.357421875, "training_acc": 48.75, "val_loss": 40907.72216796875, "val_acc": 50.0, "val_auroc": 0.34, "time": 200.45}
{"epoch": 22, "training_loss": 127404.20635986328, "training_acc": 52.5, "val_loss": 28830.48095703125, "val_acc": 50.0, "val_auroc": 0.42, "time": 209.59}
{"epoch": 23, "training_loss": 137908.28515625, "training_acc": 51.25, "val_loss": 9850.331420898438, "val_acc": 50.0, "val_auroc": 0.3, "time": 218.3}
{"epoch": 24, "training_loss": 59768.599609375, "training_acc": 48.75, "val_loss": 12357.030029296875, "val_acc": 50.0, "val_auroc": 0.4, "time": 227.28}
{"epoch": 25, "training_loss": 63839.34375, "training_acc": 51.25, "val_loss": 30630.53466796875, "val_acc": 50.0, "val_auroc": 0.41, "time": 236.13}
{"epoch": 26, "training_loss": 93839.14929199219, "training_acc": 51.25, "val_loss": 14588.13232421875, "val_acc": 50.0, "val_auroc": 0.39, "time": 245.01}
{"epoch": 27, "training_loss": 83107.71484375, "training_acc": 48.75, "val_loss": 36320.54443359375, "val_acc": 50.0, "val_auroc": 0.41, "time": 253.83}
{"epoch": 28, "training_loss": 104802.48828125, "training_acc": 58.75, "val_loss": 22618.4423828125, "val_acc": 50.0, "val_auroc": 0.51, "time": 262.61}
{"epoch": 29, "training_loss": 89220.7705078125, "training_acc": 48.75, "val_loss": 19408.123779296875, "val_acc": 50.0, "val_auroc": 0.44, "time": 271.63}
{"epoch": 30, "training_loss": 76742.056640625, "training_acc": 48.75, "val_loss": 6434.830322265625, "val_acc": 50.0, "val_auroc": 0.42, "time": 281.05}
{"epoch": 31, "training_loss": 44779.5859375, "training_acc": 48.75, "val_loss": 42618.740234375, "val_acc": 50.0, "val_auroc": 0.43, "time": 289.68}
{"epoch": 32, "training_loss": 140135.669921875, "training_acc": 53.75, "val_loss": 16998.45703125, "val_acc": 50.0, "val_auroc": 0.47, "time": 298.43}
{"epoch": 33, "training_loss": 77531.80078125, "training_acc": 46.25, "val_loss": 5313.61328125, "val_acc": 50.0, "val_auroc": 0.49, "time": 307.48}
{"epoch": 34, "training_loss": 32914.3876953125, "training_acc": 48.75, "val_loss": 28852.1875, "val_acc": 50.0, "val_auroc": 0.42, "time": 316.54}
{"epoch": 35, "training_loss": 100198.9609375, "training_acc": 53.75, "val_loss": 6144.8236083984375, "val_acc": 50.0, "val_auroc": 0.62, "time": 325.23}
{"epoch": 36, "training_loss": 26634.115234375, "training_acc": 58.75, "val_loss": 22418.53271484375, "val_acc": 50.0, "val_auroc": 0.6, "time": 334.09}
