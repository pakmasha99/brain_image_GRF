"main_optuna_fix_3.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3_early_loss --binary_class True --run_where lab --early_criteria loss"
{"epoch": 0, "training_loss": 174.91404724121094, "training_acc": 50.0, "val_loss": 302400531333120.0, "val_acc": 45.0, "val_auroc": 0.404, "time": 10.56}
{"epoch": 1, "training_loss": 831638281707133.5, "training_acc": 55.0, "val_loss": 583609600.0, "val_acc": 55.0, "val_auroc": 0.606, "time": 20.23}
{"epoch": 2, "training_loss": 2464236096.0, "training_acc": 45.0, "val_loss": 877423200.0, "val_acc": 55.0, "val_auroc": 0.586, "time": 29.71}
{"epoch": 3, "training_loss": 2885669480.0, "training_acc": 52.5, "val_loss": 43332730.0, "val_acc": 55.0, "val_auroc": 0.606, "time": 39.23}
{"epoch": 4, "training_loss": 153334711.0, "training_acc": 52.5, "val_loss": 837679.296875, "val_acc": 55.0, "val_auroc": 0.545, "time": 48.68}
{"epoch": 5, "training_loss": 4883676.75, "training_acc": 52.5, "val_loss": 2860829.0625, "val_acc": 55.0, "val_auroc": 0.455, "time": 57.63}
{"epoch": 6, "training_loss": 10764711.75, "training_acc": 52.5, "val_loss": 8039140.625, "val_acc": 45.0, "val_auroc": 0.343, "time": 66.56}
{"epoch": 7, "training_loss": 25645130.125, "training_acc": 47.5, "val_loss": 239324.6875, "val_acc": 55.0, "val_auroc": 0.606, "time": 76.01}
{"epoch": 8, "training_loss": 2087729.125, "training_acc": 57.5, "val_loss": 8764944.375, "val_acc": 55.0, "val_auroc": 0.586, "time": 85.48}
{"epoch": 9, "training_loss": 33344118.5, "training_acc": 52.5, "val_loss": 84385.25390625, "val_acc": 45.0, "val_auroc": 0.505, "time": 94.93}
{"epoch": 10, "training_loss": 4568006.875, "training_acc": 51.25, "val_loss": 1549175.78125, "val_acc": 45.0, "val_auroc": 0.566, "time": 104.3}
{"epoch": 11, "training_loss": 4953257.0, "training_acc": 47.5, "val_loss": 1062085.546875, "val_acc": 55.0, "val_auroc": 0.667, "time": 113.13}
{"epoch": 12, "training_loss": 3836645.5625, "training_acc": 52.5, "val_loss": 1271950720.0, "val_acc": 55.0, "val_auroc": 0.525, "time": 122.16}
{"epoch": 13, "training_loss": 4311548355.5703125, "training_acc": 50.0, "val_loss": 42619.716796875, "val_acc": 45.0, "val_auroc": 0.495, "time": 131.58}
{"epoch": 14, "training_loss": 578828.28125, "training_acc": 47.5, "val_loss": 3015332.1875, "val_acc": 45.0, "val_auroc": 0.525, "time": 141.13}
{"epoch": 15, "training_loss": 9826684.3125, "training_acc": 52.5, "val_loss": 106898730.0, "val_acc": 45.0, "val_auroc": 0.495, "time": 150.21}
{"epoch": 16, "training_loss": 744401760.0, "training_acc": 47.5, "val_loss": 1857296480.0, "val_acc": 55.0, "val_auroc": 0.384, "time": 159.32}
{"epoch": 17, "training_loss": 9309399552.0, "training_acc": 52.5, "val_loss": 269753036800.0, "val_acc": 45.0, "val_auroc": 0.414, "time": 168.33}
{"epoch": 18, "training_loss": 842848713728.0, "training_acc": 45.0, "val_loss": 243348200.0, "val_acc": 55.0, "val_auroc": 0.535, "time": 177.49}
{"epoch": 19, "training_loss": 1018291632.0, "training_acc": 52.5, "val_loss": 146369090.0, "val_acc": 55.0, "val_auroc": 0.727, "time": 186.42}
{"epoch": 20, "training_loss": 656187424.0, "training_acc": 52.5, "val_loss": 27791235.0, "val_acc": 55.0, "val_auroc": 0.515, "time": 195.58}
{"epoch": 21, "training_loss": 13483803328.0, "training_acc": 52.5, "val_loss": 403581720.0, "val_acc": 55.0, "val_auroc": 0.566, "time": 204.62}
{"epoch": 22, "training_loss": 2251326592.0, "training_acc": 52.5, "val_loss": 475821560.0, "val_acc": 45.0, "val_auroc": 0.455, "time": 213.99}
{"epoch": 23, "training_loss": 1420840188.0, "training_acc": 47.5, "val_loss": 25242657.5, "val_acc": 55.0, "val_auroc": 0.657, "time": 222.75}
{"epoch": 24, "training_loss": 89271014.5, "training_acc": 52.5, "val_loss": 102376.064453125, "val_acc": 50.0, "val_auroc": 0.434, "time": 231.47}
{"epoch": 25, "training_loss": 4077971.5, "training_acc": 57.5, "val_loss": 707698.046875, "val_acc": 55.0, "val_auroc": 0.636, "time": 240.4}
{"epoch": 26, "training_loss": 32791097.0, "training_acc": 50.0, "val_loss": 17520213.75, "val_acc": 45.0, "val_auroc": 0.434, "time": 249.69}
{"epoch": 27, "training_loss": 55397890.25, "training_acc": 47.5, "val_loss": 33841887.5, "val_acc": 55.0, "val_auroc": 0.283, "time": 258.49}
{"epoch": 28, "training_loss": 114926801.5, "training_acc": 52.5, "val_loss": 17673218.75, "val_acc": 55.0, "val_auroc": 0.343, "time": 267.54}
{"epoch": 29, "training_loss": 66914801.0, "training_acc": 45.0, "val_loss": 1525286.71875, "val_acc": 55.0, "val_auroc": 0.495, "time": 276.53}
{"epoch": 30, "training_loss": 7107048.25, "training_acc": 52.5, "val_loss": 1744366.25, "val_acc": 55.0, "val_auroc": 0.677, "time": 286.02}
{"epoch": 31, "training_loss": 6125689.8125, "training_acc": 52.5, "val_loss": 2016242.03125, "val_acc": 45.0, "val_auroc": 0.364, "time": 297.24}
{"epoch": 32, "training_loss": 7017997.25, "training_acc": 47.5, "val_loss": 397859.84375, "val_acc": 55.0, "val_auroc": 0.586, "time": 305.84}
