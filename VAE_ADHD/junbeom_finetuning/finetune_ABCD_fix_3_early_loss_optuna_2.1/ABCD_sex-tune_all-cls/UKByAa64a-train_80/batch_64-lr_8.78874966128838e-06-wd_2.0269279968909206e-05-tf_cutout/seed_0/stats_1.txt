"main_optuna_fix_3.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3_early_loss --binary_class True --run_where lab --early_criteria loss"
{"epoch": 0, "training_loss": 55.44611930847168, "training_acc": 53.75, "val_loss": 13.845701217651367, "val_acc": 50.0, "val_auroc": 0.61, "time": 10.35}
{"epoch": 1, "training_loss": 55.4227294921875, "training_acc": 51.25, "val_loss": 13.850739002227783, "val_acc": 50.0, "val_auroc": 0.62, "time": 19.64}
{"epoch": 2, "training_loss": 55.13089847564697, "training_acc": 53.75, "val_loss": 13.917087316513062, "val_acc": 50.0, "val_auroc": 0.65, "time": 28.88}
{"epoch": 3, "training_loss": 55.20575714111328, "training_acc": 53.75, "val_loss": 13.992273807525635, "val_acc": 50.0, "val_auroc": 0.74, "time": 38.5}
{"epoch": 4, "training_loss": 55.137474060058594, "training_acc": 53.75, "val_loss": 13.991224765777588, "val_acc": 50.0, "val_auroc": 0.75, "time": 47.79}
{"epoch": 5, "training_loss": 55.204689025878906, "training_acc": 53.75, "val_loss": 13.96277666091919, "val_acc": 50.0, "val_auroc": 0.68, "time": 57.17}
{"epoch": 6, "training_loss": 55.21204376220703, "training_acc": 53.75, "val_loss": 13.933507204055786, "val_acc": 50.0, "val_auroc": 0.62, "time": 66.52}
{"epoch": 7, "training_loss": 54.8460750579834, "training_acc": 53.75, "val_loss": 13.911234140396118, "val_acc": 50.0, "val_auroc": 0.69, "time": 76.2}
{"epoch": 8, "training_loss": 54.90940761566162, "training_acc": 53.75, "val_loss": 13.889166116714478, "val_acc": 50.0, "val_auroc": 0.76, "time": 85.84}
{"epoch": 9, "training_loss": 54.83675289154053, "training_acc": 53.75, "val_loss": 13.863095045089722, "val_acc": 50.0, "val_auroc": 0.74, "time": 95.56}
{"epoch": 10, "training_loss": 55.17226314544678, "training_acc": 53.75, "val_loss": 13.843640089035034, "val_acc": 50.0, "val_auroc": 0.74, "time": 105.41}
{"epoch": 11, "training_loss": 54.68572235107422, "training_acc": 53.75, "val_loss": 13.839699029922485, "val_acc": 50.0, "val_auroc": 0.85, "time": 115.07}
{"epoch": 12, "training_loss": 54.6908016204834, "training_acc": 53.75, "val_loss": 13.848603963851929, "val_acc": 50.0, "val_auroc": 0.69, "time": 124.52}
{"epoch": 13, "training_loss": 54.73805809020996, "training_acc": 53.75, "val_loss": 13.889707326889038, "val_acc": 50.0, "val_auroc": 0.72, "time": 135.04}
{"epoch": 14, "training_loss": 54.628618240356445, "training_acc": 53.75, "val_loss": 13.95262598991394, "val_acc": 50.0, "val_auroc": 0.78, "time": 144.75}
{"epoch": 15, "training_loss": 54.513349533081055, "training_acc": 53.75, "val_loss": 14.063470363616943, "val_acc": 50.0, "val_auroc": 0.73, "time": 154.21}
{"epoch": 16, "training_loss": 55.03381061553955, "training_acc": 53.75, "val_loss": 14.160953760147095, "val_acc": 50.0, "val_auroc": 0.71, "time": 164.17}
{"epoch": 17, "training_loss": 54.99123573303223, "training_acc": 53.75, "val_loss": 14.00821566581726, "val_acc": 50.0, "val_auroc": 0.7, "time": 174.04}
{"epoch": 18, "training_loss": 54.405696868896484, "training_acc": 53.75, "val_loss": 13.851522207260132, "val_acc": 50.0, "val_auroc": 0.69, "time": 183.53}
{"epoch": 19, "training_loss": 54.20773792266846, "training_acc": 55.0, "val_loss": 13.828881978988647, "val_acc": 50.0, "val_auroc": 0.64, "time": 193.0}
{"epoch": 20, "training_loss": 54.75188446044922, "training_acc": 57.5, "val_loss": 13.833593130111694, "val_acc": 50.0, "val_auroc": 0.68, "time": 202.2}
{"epoch": 21, "training_loss": 54.520830154418945, "training_acc": 77.5, "val_loss": 13.823330402374268, "val_acc": 50.0, "val_auroc": 0.62, "time": 211.67}
{"epoch": 22, "training_loss": 53.824161529541016, "training_acc": 53.75, "val_loss": 14.016269445419312, "val_acc": 50.0, "val_auroc": 0.67, "time": 220.77}
{"epoch": 23, "training_loss": 54.408902168273926, "training_acc": 53.75, "val_loss": 14.267328977584839, "val_acc": 50.0, "val_auroc": 0.69, "time": 229.82}
{"epoch": 24, "training_loss": 55.113731384277344, "training_acc": 53.75, "val_loss": 14.302057027816772, "val_acc": 50.0, "val_auroc": 0.7, "time": 239.93}
{"epoch": 25, "training_loss": 55.12142562866211, "training_acc": 53.75, "val_loss": 14.064291715621948, "val_acc": 50.0, "val_auroc": 0.67, "time": 251.23}
{"epoch": 26, "training_loss": 54.69853210449219, "training_acc": 53.75, "val_loss": 13.800382614135742, "val_acc": 50.0, "val_auroc": 0.67, "time": 260.82}
{"epoch": 27, "training_loss": 53.950387954711914, "training_acc": 60.0, "val_loss": 13.743925094604492, "val_acc": 50.0, "val_auroc": 0.71, "time": 270.34}
{"epoch": 28, "training_loss": 53.93587875366211, "training_acc": 72.5, "val_loss": 13.699172735214233, "val_acc": 50.0, "val_auroc": 0.72, "time": 280.06}
{"epoch": 29, "training_loss": 53.29124641418457, "training_acc": 78.75, "val_loss": 13.718150854110718, "val_acc": 50.0, "val_auroc": 0.69, "time": 289.82}
{"epoch": 30, "training_loss": 53.2609281539917, "training_acc": 55.0, "val_loss": 14.052661657333374, "val_acc": 50.0, "val_auroc": 0.7, "time": 299.34}
{"epoch": 31, "training_loss": 54.071929931640625, "training_acc": 53.75, "val_loss": 13.929673433303833, "val_acc": 50.0, "val_auroc": 0.71, "time": 308.71}
{"epoch": 32, "training_loss": 52.71285820007324, "training_acc": 55.0, "val_loss": 13.644601106643677, "val_acc": 50.0, "val_auroc": 0.73, "time": 318.07}
{"epoch": 33, "training_loss": 53.9803581237793, "training_acc": 56.25, "val_loss": 13.660995960235596, "val_acc": 50.0, "val_auroc": 0.71, "time": 327.56}
{"epoch": 34, "training_loss": 53.53372287750244, "training_acc": 57.5, "val_loss": 13.800764083862305, "val_acc": 50.0, "val_auroc": 0.77, "time": 336.59}
{"epoch": 35, "training_loss": 52.529253005981445, "training_acc": 53.75, "val_loss": 13.906062841415405, "val_acc": 50.0, "val_auroc": 0.8, "time": 346.12}
{"epoch": 36, "training_loss": 52.24843215942383, "training_acc": 52.5, "val_loss": 13.539899587631226, "val_acc": 50.0, "val_auroc": 0.76, "time": 355.63}
{"epoch": 37, "training_loss": 52.239044189453125, "training_acc": 68.75, "val_loss": 13.888746500015259, "val_acc": 50.0, "val_auroc": 0.72, "time": 365.13}
{"epoch": 38, "training_loss": 54.56825828552246, "training_acc": 47.5, "val_loss": 13.483437299728394, "val_acc": 50.0, "val_auroc": 0.75, "time": 375.27}
{"epoch": 39, "training_loss": 50.90349292755127, "training_acc": 77.5, "val_loss": 14.045230150222778, "val_acc": 50.0, "val_auroc": 0.73, "time": 384.72}
{"epoch": 40, "training_loss": 52.67385005950928, "training_acc": 53.75, "val_loss": 14.23555612564087, "val_acc": 50.0, "val_auroc": 0.72, "time": 394.28}
{"epoch": 41, "training_loss": 52.16187572479248, "training_acc": 53.75, "val_loss": 13.462413549423218, "val_acc": 50.0, "val_auroc": 0.75, "time": 404.11}
{"epoch": 42, "training_loss": 50.647361755371094, "training_acc": 83.75, "val_loss": 13.987704515457153, "val_acc": 65.0, "val_auroc": 0.69, "time": 413.2}
{"epoch": 43, "training_loss": 54.08353137969971, "training_acc": 46.25, "val_loss": 13.501957654953003, "val_acc": 50.0, "val_auroc": 0.74, "time": 422.11}
{"epoch": 44, "training_loss": 50.94983959197998, "training_acc": 73.75, "val_loss": 13.67848515510559, "val_acc": 50.0, "val_auroc": 0.75, "time": 431.11}
{"epoch": 45, "training_loss": 50.84001350402832, "training_acc": 56.25, "val_loss": 14.02727484703064, "val_acc": 50.0, "val_auroc": 0.78, "time": 440.42}
{"epoch": 46, "training_loss": 51.480488777160645, "training_acc": 53.75, "val_loss": 13.62672209739685, "val_acc": 50.0, "val_auroc": 0.75, "time": 449.75}
{"epoch": 47, "training_loss": 48.70977973937988, "training_acc": 70.0, "val_loss": 13.344125747680664, "val_acc": 50.0, "val_auroc": 0.75, "time": 459.34}
{"epoch": 48, "training_loss": 49.62010478973389, "training_acc": 77.5, "val_loss": 13.425146341323853, "val_acc": 50.0, "val_auroc": 0.74, "time": 468.57}
{"epoch": 49, "training_loss": 48.80931282043457, "training_acc": 71.25, "val_loss": 13.56955885887146, "val_acc": 50.0, "val_auroc": 0.7, "time": 477.61}
{"epoch": 50, "training_loss": 47.035573959350586, "training_acc": 68.75, "val_loss": 13.409808874130249, "val_acc": 50.0, "val_auroc": 0.71, "time": 487.07}
{"epoch": 51, "training_loss": 46.45225524902344, "training_acc": 78.75, "val_loss": 13.19652795791626, "val_acc": 50.0, "val_auroc": 0.71, "time": 497.43}
{"epoch": 52, "training_loss": 44.74491024017334, "training_acc": 83.75, "val_loss": 13.220834732055664, "val_acc": 60.0, "val_auroc": 0.71, "time": 506.78}
{"epoch": 53, "training_loss": 43.24544715881348, "training_acc": 83.75, "val_loss": 13.579604625701904, "val_acc": 50.0, "val_auroc": 0.73, "time": 516.22}
{"epoch": 54, "training_loss": 43.337368965148926, "training_acc": 68.75, "val_loss": 12.736295461654663, "val_acc": 65.0, "val_auroc": 0.73, "time": 526.0}
{"epoch": 55, "training_loss": 38.187509536743164, "training_acc": 88.75, "val_loss": 13.09810996055603, "val_acc": 75.0, "val_auroc": 0.72, "time": 535.35}
{"epoch": 56, "training_loss": 40.99122428894043, "training_acc": 82.5, "val_loss": 13.39642882347107, "val_acc": 60.0, "val_auroc": 0.7, "time": 544.53}
{"epoch": 57, "training_loss": 37.55964374542236, "training_acc": 81.25, "val_loss": 14.433481693267822, "val_acc": 50.0, "val_auroc": 0.71, "time": 556.68}
{"epoch": 58, "training_loss": 39.1805419921875, "training_acc": 67.5, "val_loss": 16.01784110069275, "val_acc": 55.0, "val_auroc": 0.71, "time": 566.35}
{"epoch": 59, "training_loss": 45.63977241516113, "training_acc": 67.5, "val_loss": 12.946662902832031, "val_acc": 55.0, "val_auroc": 0.73, "time": 575.74}
{"epoch": 60, "training_loss": 37.39971351623535, "training_acc": 76.25, "val_loss": 12.054928541183472, "val_acc": 65.0, "val_auroc": 0.75, "time": 585.56}
{"epoch": 61, "training_loss": 32.92401313781738, "training_acc": 80.0, "val_loss": 13.022011518478394, "val_acc": 70.0, "val_auroc": 0.77, "time": 594.91}
{"epoch": 62, "training_loss": 32.827627182006836, "training_acc": 85.0, "val_loss": 12.514427900314331, "val_acc": 60.0, "val_auroc": 0.79, "time": 603.87}
{"epoch": 63, "training_loss": 30.73319149017334, "training_acc": 86.25, "val_loss": 14.253830909729004, "val_acc": 60.0, "val_auroc": 0.79, "time": 613.29}
{"epoch": 64, "training_loss": 33.47775077819824, "training_acc": 85.0, "val_loss": 11.063382625579834, "val_acc": 65.0, "val_auroc": 0.8, "time": 623.04}
{"epoch": 65, "training_loss": 26.375295162200928, "training_acc": 87.5, "val_loss": 12.862080335617065, "val_acc": 70.0, "val_auroc": 0.8, "time": 632.42}
{"epoch": 66, "training_loss": 29.66595697402954, "training_acc": 82.5, "val_loss": 10.812360048294067, "val_acc": 80.0, "val_auroc": 0.81, "time": 642.09}
{"epoch": 67, "training_loss": 26.379257678985596, "training_acc": 87.5, "val_loss": 12.016305923461914, "val_acc": 55.0, "val_auroc": 0.81, "time": 651.69}
{"epoch": 68, "training_loss": 23.756035804748535, "training_acc": 90.0, "val_loss": 17.264341115951538, "val_acc": 55.0, "val_auroc": 0.8, "time": 661.46}
{"epoch": 69, "training_loss": 36.210633516311646, "training_acc": 78.75, "val_loss": 16.89898133277893, "val_acc": 50.0, "val_auroc": 0.82, "time": 671.14}
{"epoch": 70, "training_loss": 34.37172532081604, "training_acc": 73.75, "val_loss": 16.47405982017517, "val_acc": 60.0, "val_auroc": 0.8, "time": 680.09}
{"epoch": 71, "training_loss": 29.18026900291443, "training_acc": 85.0, "val_loss": 12.434772253036499, "val_acc": 60.0, "val_auroc": 0.82, "time": 689.04}
{"epoch": 72, "training_loss": 23.027711629867554, "training_acc": 83.75, "val_loss": 10.161584615707397, "val_acc": 80.0, "val_auroc": 0.82, "time": 698.66}
{"epoch": 73, "training_loss": 18.15289545059204, "training_acc": 93.75, "val_loss": 10.416871309280396, "val_acc": 70.0, "val_auroc": 0.83, "time": 707.91}
{"epoch": 74, "training_loss": 14.144684076309204, "training_acc": 96.25, "val_loss": 10.931531190872192, "val_acc": 80.0, "val_auroc": 0.8, "time": 717.17}
{"epoch": 75, "training_loss": 14.932362079620361, "training_acc": 93.75, "val_loss": 14.997786283493042, "val_acc": 55.0, "val_auroc": 0.82, "time": 726.8}
{"epoch": 76, "training_loss": 21.023372173309326, "training_acc": 85.0, "val_loss": 21.02621078491211, "val_acc": 60.0, "val_auroc": 0.79, "time": 735.7}
{"epoch": 77, "training_loss": 27.671507835388184, "training_acc": 82.5, "val_loss": 20.995073318481445, "val_acc": 50.0, "val_auroc": 0.81, "time": 744.52}
{"epoch": 78, "training_loss": 29.633485317230225, "training_acc": 80.0, "val_loss": 12.051070928573608, "val_acc": 70.0, "val_auroc": 0.79, "time": 753.5}
{"epoch": 79, "training_loss": 12.578010559082031, "training_acc": 96.25, "val_loss": 10.79635500907898, "val_acc": 80.0, "val_auroc": 0.79, "time": 762.85}
{"epoch": 80, "training_loss": 12.175089836120605, "training_acc": 95.0, "val_loss": 19.29863214492798, "val_acc": 45.0, "val_auroc": 0.8, "time": 771.89}
{"epoch": 81, "training_loss": 23.740463733673096, "training_acc": 85.0, "val_loss": 16.677712202072144, "val_acc": 65.0, "val_auroc": 0.79, "time": 781.14}
{"epoch": 82, "training_loss": 20.10122859477997, "training_acc": 91.25, "val_loss": 14.863344430923462, "val_acc": 60.0, "val_auroc": 0.8, "time": 790.1}
{"epoch": 83, "training_loss": 18.674866676330566, "training_acc": 88.75, "val_loss": 11.109873056411743, "val_acc": 80.0, "val_auroc": 0.8, "time": 799.27}
{"epoch": 84, "training_loss": 15.193155288696289, "training_acc": 92.5, "val_loss": 14.4717276096344, "val_acc": 60.0, "val_auroc": 0.8, "time": 808.65}
{"epoch": 85, "training_loss": 28.148990631103516, "training_acc": 86.25, "val_loss": 11.233112812042236, "val_acc": 80.0, "val_auroc": 0.8, "time": 817.98}
{"epoch": 86, "training_loss": 9.751138687133789, "training_acc": 97.5, "val_loss": 30.786240100860596, "val_acc": 50.0, "val_auroc": 0.75, "time": 827.25}
{"epoch": 87, "training_loss": 60.21517848968506, "training_acc": 70.0, "val_loss": 19.305267333984375, "val_acc": 50.0, "val_auroc": 0.79, "time": 836.56}
{"epoch": 88, "training_loss": 36.56515884399414, "training_acc": 78.75, "val_loss": 16.15602135658264, "val_acc": 60.0, "val_auroc": 0.78, "time": 845.48}
{"epoch": 89, "training_loss": 21.65159559249878, "training_acc": 85.0, "val_loss": 30.453648567199707, "val_acc": 50.0, "val_auroc": 0.75, "time": 856.2}
{"epoch": 90, "training_loss": 74.0315055847168, "training_acc": 56.25, "val_loss": 17.597090005874634, "val_acc": 60.0, "val_auroc": 0.78, "time": 866.81}
{"epoch": 91, "training_loss": 21.849395275115967, "training_acc": 88.75, "val_loss": 21.850497722625732, "val_acc": 50.0, "val_auroc": 0.81, "time": 876.01}
