"main_optuna_fix_3.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3_early_loss --binary_class True --run_where lab --early_criteria loss"
{"epoch": 0, "training_loss": 55.815956115722656, "training_acc": 53.75, "val_loss": 13.861504793167114, "val_acc": 50.0, "val_auroc": 0.56, "time": 9.85}
{"epoch": 1, "training_loss": 55.556203842163086, "training_acc": 46.25, "val_loss": 14.209498167037964, "val_acc": 50.0, "val_auroc": 0.45, "time": 18.87}
{"epoch": 2, "training_loss": 55.65989971160889, "training_acc": 53.75, "val_loss": 13.868229389190674, "val_acc": 50.0, "val_auroc": 0.42, "time": 28.31}
{"epoch": 3, "training_loss": 56.07264995574951, "training_acc": 45.0, "val_loss": 13.861258029937744, "val_acc": 50.0, "val_auroc": 0.5, "time": 37.53}
{"epoch": 4, "training_loss": 55.51539993286133, "training_acc": 42.5, "val_loss": 13.937782049179077, "val_acc": 50.0, "val_auroc": 0.29, "time": 45.99}
{"epoch": 5, "training_loss": 55.27175712585449, "training_acc": 53.75, "val_loss": 14.15465235710144, "val_acc": 50.0, "val_auroc": 0.43, "time": 55.14}
{"epoch": 6, "training_loss": 55.44632530212402, "training_acc": 53.75, "val_loss": 13.96899938583374, "val_acc": 50.0, "val_auroc": 0.5, "time": 64.03}
{"epoch": 7, "training_loss": 54.93522834777832, "training_acc": 53.75, "val_loss": 13.909980058670044, "val_acc": 50.0, "val_auroc": 0.49, "time": 72.34}
{"epoch": 8, "training_loss": 54.81982707977295, "training_acc": 53.75, "val_loss": 13.851083517074585, "val_acc": 50.0, "val_auroc": 0.52, "time": 81.47}
{"epoch": 9, "training_loss": 54.514944076538086, "training_acc": 51.25, "val_loss": 13.797061443328857, "val_acc": 50.0, "val_auroc": 0.5, "time": 90.69}
{"epoch": 10, "training_loss": 55.89376258850098, "training_acc": 51.25, "val_loss": 13.771647214889526, "val_acc": 50.0, "val_auroc": 0.49, "time": 99.72}
{"epoch": 11, "training_loss": 54.120938301086426, "training_acc": 62.5, "val_loss": 14.54676628112793, "val_acc": 50.0, "val_auroc": 0.46, "time": 108.45}
{"epoch": 12, "training_loss": 55.73034381866455, "training_acc": 53.75, "val_loss": 13.78633737564087, "val_acc": 50.0, "val_auroc": 0.52, "time": 117.23}
{"epoch": 13, "training_loss": 54.77414512634277, "training_acc": 53.75, "val_loss": 13.832148313522339, "val_acc": 50.0, "val_auroc": 0.54, "time": 126.05}
{"epoch": 14, "training_loss": 54.46917724609375, "training_acc": 53.75, "val_loss": 14.526546001434326, "val_acc": 50.0, "val_auroc": 0.52, "time": 134.49}
{"epoch": 15, "training_loss": 55.91686534881592, "training_acc": 53.75, "val_loss": 14.554213285446167, "val_acc": 50.0, "val_auroc": 0.57, "time": 143.53}
{"epoch": 16, "training_loss": 56.67495059967041, "training_acc": 53.75, "val_loss": 13.936086893081665, "val_acc": 50.0, "val_auroc": 0.62, "time": 152.49}
{"epoch": 17, "training_loss": 54.49394607543945, "training_acc": 53.75, "val_loss": 13.784157037734985, "val_acc": 50.0, "val_auroc": 0.68, "time": 162.01}
{"epoch": 18, "training_loss": 54.64789009094238, "training_acc": 65.0, "val_loss": 13.730748891830444, "val_acc": 50.0, "val_auroc": 0.67, "time": 170.83}
{"epoch": 19, "training_loss": 54.97844982147217, "training_acc": 60.0, "val_loss": 13.721567392349243, "val_acc": 50.0, "val_auroc": 0.64, "time": 179.74}
{"epoch": 20, "training_loss": 54.78779602050781, "training_acc": 55.0, "val_loss": 13.68518590927124, "val_acc": 50.0, "val_auroc": 0.63, "time": 189.07}
{"epoch": 21, "training_loss": 53.97536087036133, "training_acc": 66.25, "val_loss": 14.08687949180603, "val_acc": 50.0, "val_auroc": 0.69, "time": 199.99}
{"epoch": 22, "training_loss": 54.340911865234375, "training_acc": 55.0, "val_loss": 14.403395652770996, "val_acc": 50.0, "val_auroc": 0.65, "time": 208.84}
{"epoch": 23, "training_loss": 53.77108383178711, "training_acc": 55.0, "val_loss": 13.769015073776245, "val_acc": 50.0, "val_auroc": 0.73, "time": 217.68}
{"epoch": 24, "training_loss": 53.71224403381348, "training_acc": 50.0, "val_loss": 13.652844429016113, "val_acc": 50.0, "val_auroc": 0.75, "time": 226.8}
{"epoch": 25, "training_loss": 52.6912202835083, "training_acc": 58.75, "val_loss": 13.782914876937866, "val_acc": 50.0, "val_auroc": 0.75, "time": 235.79}
{"epoch": 26, "training_loss": 53.68992042541504, "training_acc": 55.0, "val_loss": 13.462516069412231, "val_acc": 50.0, "val_auroc": 0.78, "time": 245.36}
{"epoch": 27, "training_loss": 52.835089683532715, "training_acc": 56.25, "val_loss": 13.724201917648315, "val_acc": 50.0, "val_auroc": 0.77, "time": 254.1}
{"epoch": 28, "training_loss": 53.49395942687988, "training_acc": 57.5, "val_loss": 14.160854816436768, "val_acc": 60.0, "val_auroc": 0.82, "time": 262.85}
{"epoch": 29, "training_loss": 57.360857009887695, "training_acc": 47.5, "val_loss": 13.755820989608765, "val_acc": 50.0, "val_auroc": 0.73, "time": 272.02}
{"epoch": 30, "training_loss": 53.850229263305664, "training_acc": 61.25, "val_loss": 15.817118883132935, "val_acc": 50.0, "val_auroc": 0.64, "time": 281.02}
{"epoch": 31, "training_loss": 59.26813316345215, "training_acc": 53.75, "val_loss": 13.874753713607788, "val_acc": 50.0, "val_auroc": 0.84, "time": 289.91}
{"epoch": 32, "training_loss": 54.531368255615234, "training_acc": 55.0, "val_loss": 13.786686658859253, "val_acc": 50.0, "val_auroc": 0.84, "time": 299.01}
{"epoch": 33, "training_loss": 55.39337635040283, "training_acc": 50.0, "val_loss": 13.788374662399292, "val_acc": 50.0, "val_auroc": 0.83, "time": 307.74}
{"epoch": 34, "training_loss": 55.29715156555176, "training_acc": 46.25, "val_loss": 13.86505126953125, "val_acc": 50.0, "val_auroc": 0.8, "time": 316.46}
{"epoch": 35, "training_loss": 55.05971717834473, "training_acc": 53.75, "val_loss": 13.938913345336914, "val_acc": 50.0, "val_auroc": 0.74, "time": 325.41}
{"epoch": 36, "training_loss": 54.813233375549316, "training_acc": 53.75, "val_loss": 13.803138732910156, "val_acc": 50.0, "val_auroc": 0.67, "time": 334.07}
{"epoch": 37, "training_loss": 55.09797286987305, "training_acc": 58.75, "val_loss": 13.993692398071289, "val_acc": 50.0, "val_auroc": 0.56, "time": 342.78}
{"epoch": 38, "training_loss": 56.77438926696777, "training_acc": 46.25, "val_loss": 13.981919288635254, "val_acc": 50.0, "val_auroc": 0.57, "time": 351.87}
{"epoch": 39, "training_loss": 56.19589042663574, "training_acc": 46.25, "val_loss": 13.828701972961426, "val_acc": 50.0, "val_auroc": 0.62, "time": 360.38}
{"epoch": 40, "training_loss": 55.08261013031006, "training_acc": 61.25, "val_loss": 13.946231603622437, "val_acc": 50.0, "val_auroc": 0.75, "time": 369.31}
{"epoch": 41, "training_loss": 55.16551113128662, "training_acc": 53.75, "val_loss": 13.991632461547852, "val_acc": 50.0, "val_auroc": 0.84, "time": 378.44}
{"epoch": 42, "training_loss": 55.228567123413086, "training_acc": 53.75, "val_loss": 13.868592977523804, "val_acc": 50.0, "val_auroc": 0.9, "time": 387.17}
{"epoch": 43, "training_loss": 54.74994468688965, "training_acc": 53.75, "val_loss": 13.818035125732422, "val_acc": 50.0, "val_auroc": 0.9, "time": 395.97}
{"epoch": 44, "training_loss": 54.764556884765625, "training_acc": 53.75, "val_loss": 13.801292181015015, "val_acc": 50.0, "val_auroc": 0.89, "time": 404.61}
{"epoch": 45, "training_loss": 54.96160316467285, "training_acc": 56.25, "val_loss": 13.810144662857056, "val_acc": 50.0, "val_auroc": 0.81, "time": 413.61}
