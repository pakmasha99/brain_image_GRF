"main_optuna_fix_3.py --pretrained_path None --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3 --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 227.70394897460938, "training_acc": 50.0, "val_loss": 304009.375, "val_acc": 55.0}
{"epoch": 1, "training_loss": 1217619.4765625, "training_acc": 45.0, "val_loss": 382.5503921508789, "val_acc": 45.0}
{"epoch": 2, "training_loss": 1221.1649780273438, "training_acc": 47.5, "val_loss": 20.028624534606934, "val_acc": 45.0}
{"epoch": 3, "training_loss": 82.19146156311035, "training_acc": 47.5, "val_loss": 14.34092402458191, "val_acc": 55.0}
{"epoch": 4, "training_loss": 118.7271957397461, "training_acc": 47.5, "val_loss": 14.530924558639526, "val_acc": 55.0}
{"epoch": 5, "training_loss": 61.09441947937012, "training_acc": 52.5, "val_loss": 15.498930215835571, "val_acc": 55.0}
{"epoch": 6, "training_loss": 62.62063694000244, "training_acc": 52.5, "val_loss": 14.449890851974487, "val_acc": 55.0}
{"epoch": 7, "training_loss": 57.17057132720947, "training_acc": 47.5, "val_loss": 14.70518946647644, "val_acc": 55.0}
{"epoch": 8, "training_loss": 60.14767360687256, "training_acc": 42.5, "val_loss": 14.095227718353271, "val_acc": 55.0}
{"epoch": 9, "training_loss": 56.13909149169922, "training_acc": 47.5, "val_loss": 14.22832727432251, "val_acc": 55.0}
{"epoch": 10, "training_loss": 55.82234001159668, "training_acc": 53.75, "val_loss": 13.917230367660522, "val_acc": 55.0}
{"epoch": 11, "training_loss": 56.63242530822754, "training_acc": 52.5, "val_loss": 14.18865442276001, "val_acc": 55.0}
{"epoch": 12, "training_loss": 56.90681743621826, "training_acc": 52.5, "val_loss": 15.463051795959473, "val_acc": 45.0}
{"epoch": 13, "training_loss": 59.223073959350586, "training_acc": 47.5, "val_loss": 13.77484679222107, "val_acc": 55.0}
{"epoch": 14, "training_loss": 55.73647499084473, "training_acc": 52.5, "val_loss": 15.995358228683472, "val_acc": 45.0}
{"epoch": 15, "training_loss": 58.80030155181885, "training_acc": 55.0, "val_loss": 14.855341911315918, "val_acc": 55.0}
{"epoch": 16, "training_loss": 61.28634071350098, "training_acc": 52.5, "val_loss": 14.44108247756958, "val_acc": 55.0}
{"epoch": 17, "training_loss": 58.549458503723145, "training_acc": 52.5, "val_loss": 13.763649463653564, "val_acc": 55.0}
{"epoch": 18, "training_loss": 55.06686592102051, "training_acc": 55.0, "val_loss": 15.32565951347351, "val_acc": 45.0}
{"epoch": 19, "training_loss": 59.705607414245605, "training_acc": 47.5, "val_loss": 13.894881010055542, "val_acc": 55.0}
{"epoch": 20, "training_loss": 55.377960205078125, "training_acc": 50.0, "val_loss": 13.84004831314087, "val_acc": 55.0}
{"epoch": 21, "training_loss": 56.046457290649414, "training_acc": 52.5, "val_loss": 13.763396739959717, "val_acc": 55.0}
{"epoch": 22, "training_loss": 55.517831802368164, "training_acc": 52.5, "val_loss": 13.783682584762573, "val_acc": 55.0}
{"epoch": 23, "training_loss": 55.363046646118164, "training_acc": 52.5, "val_loss": 13.762619495391846, "val_acc": 55.0}
{"epoch": 24, "training_loss": 55.878488540649414, "training_acc": 52.5, "val_loss": 13.800733089447021, "val_acc": 55.0}
{"epoch": 25, "training_loss": 55.86612129211426, "training_acc": 52.5, "val_loss": 13.936691284179688, "val_acc": 55.0}
{"epoch": 26, "training_loss": 56.68958759307861, "training_acc": 52.5, "val_loss": 13.844761848449707, "val_acc": 55.0}
{"epoch": 27, "training_loss": 56.07833194732666, "training_acc": 52.5, "val_loss": 13.76354455947876, "val_acc": 55.0}
{"epoch": 28, "training_loss": 55.367523193359375, "training_acc": 52.5, "val_loss": 13.81691575050354, "val_acc": 55.0}
{"epoch": 29, "training_loss": 55.43667984008789, "training_acc": 50.0, "val_loss": 13.905277252197266, "val_acc": 55.0}
{"epoch": 30, "training_loss": 55.545888900756836, "training_acc": 47.5, "val_loss": 13.87744665145874, "val_acc": 55.0}
{"epoch": 31, "training_loss": 55.63210868835449, "training_acc": 42.5, "val_loss": 13.87341022491455, "val_acc": 55.0}
{"epoch": 32, "training_loss": 55.47340774536133, "training_acc": 47.5, "val_loss": 13.921709060668945, "val_acc": 55.0}
{"epoch": 33, "training_loss": 55.57373237609863, "training_acc": 47.5, "val_loss": 13.863695859909058, "val_acc": 55.0}
{"epoch": 34, "training_loss": 55.41984176635742, "training_acc": 48.75, "val_loss": 13.786090612411499, "val_acc": 55.0}
{"epoch": 35, "training_loss": 55.44845008850098, "training_acc": 52.5, "val_loss": 13.771027326583862, "val_acc": 55.0}
{"epoch": 36, "training_loss": 55.46933364868164, "training_acc": 52.5, "val_loss": 13.776499032974243, "val_acc": 55.0}
{"epoch": 37, "training_loss": 55.36206245422363, "training_acc": 52.5, "val_loss": 13.778918981552124, "val_acc": 55.0}
{"epoch": 38, "training_loss": 55.36111640930176, "training_acc": 52.5, "val_loss": 13.776897192001343, "val_acc": 55.0}
{"epoch": 39, "training_loss": 55.355122566223145, "training_acc": 52.5, "val_loss": 13.775414228439331, "val_acc": 55.0}
{"epoch": 40, "training_loss": 55.58646583557129, "training_acc": 52.5, "val_loss": 13.803647756576538, "val_acc": 55.0}
{"epoch": 41, "training_loss": 55.34354782104492, "training_acc": 52.5, "val_loss": 13.840513229370117, "val_acc": 55.0}
{"epoch": 42, "training_loss": 55.43316841125488, "training_acc": 52.5, "val_loss": 13.854248523712158, "val_acc": 55.0}
