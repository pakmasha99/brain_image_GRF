"main_optuna_fix_3.py --pretrained_path None --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3 --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 152.28377532958984, "training_acc": 51.25, "val_loss": 1399596.09375, "val_acc": 45.0}
{"epoch": 1, "training_loss": 3881000.0996398926, "training_acc": 55.0, "val_loss": 1324.1828918457031, "val_acc": 45.0}
{"epoch": 2, "training_loss": 5091.2899169921875, "training_acc": 55.0, "val_loss": 256.80273056030273, "val_acc": 55.0}
{"epoch": 3, "training_loss": 937.8468170166016, "training_acc": 52.5, "val_loss": 16.15186333656311, "val_acc": 55.0}
{"epoch": 4, "training_loss": 85.18659591674805, "training_acc": 50.0, "val_loss": 19.627827405929565, "val_acc": 55.0}
{"epoch": 5, "training_loss": 75.58672332763672, "training_acc": 52.5, "val_loss": 14.168680906295776, "val_acc": 55.0}
{"epoch": 6, "training_loss": 57.51627254486084, "training_acc": 50.0, "val_loss": 21.166627407073975, "val_acc": 45.0}
{"epoch": 7, "training_loss": 76.31087303161621, "training_acc": 47.5, "val_loss": 13.902883529663086, "val_acc": 55.0}
{"epoch": 8, "training_loss": 56.32028579711914, "training_acc": 52.5, "val_loss": 16.21299982070923, "val_acc": 45.0}
{"epoch": 9, "training_loss": 60.88261032104492, "training_acc": 47.5, "val_loss": 14.48947548866272, "val_acc": 55.0}
{"epoch": 10, "training_loss": 59.60858726501465, "training_acc": 52.5, "val_loss": 13.840938806533813, "val_acc": 55.0}
{"epoch": 11, "training_loss": 57.09326648712158, "training_acc": 45.0, "val_loss": 13.864582777023315, "val_acc": 55.0}
{"epoch": 12, "training_loss": 56.28042030334473, "training_acc": 52.5, "val_loss": 13.766167163848877, "val_acc": 55.0}
{"epoch": 13, "training_loss": 55.668779373168945, "training_acc": 50.0, "val_loss": 13.812121152877808, "val_acc": 55.0}
{"epoch": 14, "training_loss": 56.30890083312988, "training_acc": 52.5, "val_loss": 13.960405588150024, "val_acc": 55.0}
{"epoch": 15, "training_loss": 56.016098976135254, "training_acc": 47.5, "val_loss": 13.864452838897705, "val_acc": 55.0}
{"epoch": 16, "training_loss": 55.40941143035889, "training_acc": 57.5, "val_loss": 14.180200099945068, "val_acc": 55.0}
{"epoch": 17, "training_loss": 57.55343055725098, "training_acc": 52.5, "val_loss": 13.785109519958496, "val_acc": 55.0}
{"epoch": 18, "training_loss": 55.5677490234375, "training_acc": 52.5, "val_loss": 13.990868330001831, "val_acc": 55.0}
{"epoch": 19, "training_loss": 55.768463134765625, "training_acc": 47.5, "val_loss": 14.168075323104858, "val_acc": 55.0}
{"epoch": 20, "training_loss": 56.16833305358887, "training_acc": 47.5, "val_loss": 13.761333227157593, "val_acc": 55.0}
{"epoch": 21, "training_loss": 55.874152183532715, "training_acc": 50.0, "val_loss": 13.779126405715942, "val_acc": 55.0}
{"epoch": 22, "training_loss": 55.43946647644043, "training_acc": 52.5, "val_loss": 13.75861406326294, "val_acc": 55.0}
{"epoch": 23, "training_loss": 55.67070960998535, "training_acc": 52.5, "val_loss": 13.799396753311157, "val_acc": 55.0}
{"epoch": 24, "training_loss": 55.40475368499756, "training_acc": 52.5, "val_loss": 13.767908811569214, "val_acc": 55.0}
{"epoch": 25, "training_loss": 55.63786602020264, "training_acc": 52.5, "val_loss": 13.758491277694702, "val_acc": 55.0}
{"epoch": 26, "training_loss": 55.47691535949707, "training_acc": 52.5, "val_loss": 13.785637617111206, "val_acc": 55.0}
{"epoch": 27, "training_loss": 55.62374019622803, "training_acc": 52.5, "val_loss": 13.760219812393188, "val_acc": 55.0}
{"epoch": 28, "training_loss": 55.419036865234375, "training_acc": 52.5, "val_loss": 13.89222502708435, "val_acc": 55.0}
{"epoch": 29, "training_loss": 55.9422082901001, "training_acc": 47.5, "val_loss": 13.77573013305664, "val_acc": 55.0}
{"epoch": 30, "training_loss": 56.606910705566406, "training_acc": 52.5, "val_loss": 13.855336904525757, "val_acc": 55.0}
{"epoch": 31, "training_loss": 55.3424186706543, "training_acc": 55.0, "val_loss": 14.353294372558594, "val_acc": 55.0}
{"epoch": 32, "training_loss": 56.79688739776611, "training_acc": 47.5, "val_loss": 13.842952251434326, "val_acc": 55.0}
{"epoch": 33, "training_loss": 55.6830358505249, "training_acc": 52.5, "val_loss": 13.767610788345337, "val_acc": 55.0}
{"epoch": 34, "training_loss": 55.61670684814453, "training_acc": 52.5, "val_loss": 13.838247060775757, "val_acc": 55.0}
