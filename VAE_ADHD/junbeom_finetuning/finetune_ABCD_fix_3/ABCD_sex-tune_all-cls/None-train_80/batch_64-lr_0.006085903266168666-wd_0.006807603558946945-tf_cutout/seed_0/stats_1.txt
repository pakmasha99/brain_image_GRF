"main_optuna_fix_3.py --pretrained_path None --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3 --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 284.5051956176758, "training_acc": 41.25, "val_loss": 6963734400.0, "val_acc": 50.0}
{"epoch": 1, "training_loss": 21804253237.311302, "training_acc": 53.75, "val_loss": 112481.89453125, "val_acc": 50.0}
{"epoch": 2, "training_loss": 438604.109375, "training_acc": 46.25, "val_loss": 4492.5885009765625, "val_acc": 50.0}
{"epoch": 3, "training_loss": 18263.27099609375, "training_acc": 46.25, "val_loss": 299.0773582458496, "val_acc": 50.0}
{"epoch": 4, "training_loss": 6398.4134521484375, "training_acc": 53.75, "val_loss": 1885.7368469238281, "val_acc": 50.0}
{"epoch": 5, "training_loss": 6438.8636474609375, "training_acc": 46.25, "val_loss": 806.112060546875, "val_acc": 50.0}
{"epoch": 6, "training_loss": 2703.1233520507812, "training_acc": 53.75, "val_loss": 51.474127769470215, "val_acc": 50.0}
{"epoch": 7, "training_loss": 479.9418640136719, "training_acc": 51.25, "val_loss": 1221.810073852539, "val_acc": 50.0}
{"epoch": 8, "training_loss": 3883.006622314453, "training_acc": 53.75, "val_loss": 107.49567985534668, "val_acc": 50.0}
{"epoch": 9, "training_loss": 431.92803955078125, "training_acc": 56.25, "val_loss": 55.52468776702881, "val_acc": 50.0}
{"epoch": 10, "training_loss": 255.96239471435547, "training_acc": 48.75, "val_loss": 20.590479373931885, "val_acc": 50.0}
{"epoch": 11, "training_loss": 152.15953063964844, "training_acc": 48.75, "val_loss": 27.606089115142822, "val_acc": 50.0}
{"epoch": 12, "training_loss": 295.6225128173828, "training_acc": 51.25, "val_loss": 57.72160053253174, "val_acc": 50.0}
{"epoch": 13, "training_loss": 214.33423042297363, "training_acc": 51.25, "val_loss": 22.43283987045288, "val_acc": 50.0}
{"epoch": 14, "training_loss": 173.24372100830078, "training_acc": 46.25, "val_loss": 107.3863410949707, "val_acc": 50.0}
{"epoch": 15, "training_loss": 339.065975189209, "training_acc": 48.75, "val_loss": 45.52243709564209, "val_acc": 50.0}
{"epoch": 16, "training_loss": 184.0494270324707, "training_acc": 48.75, "val_loss": 19.467391967773438, "val_acc": 50.0}
{"epoch": 17, "training_loss": 72.42401885986328, "training_acc": 53.75, "val_loss": 35.94897508621216, "val_acc": 50.0}
{"epoch": 18, "training_loss": 139.46712493896484, "training_acc": 46.25, "val_loss": 64.33727264404297, "val_acc": 50.0}
{"epoch": 19, "training_loss": 201.53263092041016, "training_acc": 53.75, "val_loss": 13.861745595932007, "val_acc": 50.0}
{"epoch": 20, "training_loss": 60.80570983886719, "training_acc": 52.5, "val_loss": 15.931552648544312, "val_acc": 50.0}
{"epoch": 21, "training_loss": 66.3744010925293, "training_acc": 48.75, "val_loss": 15.666950941085815, "val_acc": 50.0}
{"epoch": 22, "training_loss": 60.324357986450195, "training_acc": 53.75, "val_loss": 15.698460340499878, "val_acc": 50.0}
{"epoch": 23, "training_loss": 60.72110176086426, "training_acc": 48.75, "val_loss": 14.357771873474121, "val_acc": 50.0}
{"epoch": 24, "training_loss": 58.063944816589355, "training_acc": 46.25, "val_loss": 14.744741916656494, "val_acc": 50.0}
{"epoch": 25, "training_loss": 57.34097671508789, "training_acc": 53.75, "val_loss": 14.768513441085815, "val_acc": 50.0}
{"epoch": 26, "training_loss": 56.707834243774414, "training_acc": 53.75, "val_loss": 13.930665254592896, "val_acc": 50.0}
{"epoch": 27, "training_loss": 56.531869888305664, "training_acc": 46.25, "val_loss": 13.865495920181274, "val_acc": 50.0}
