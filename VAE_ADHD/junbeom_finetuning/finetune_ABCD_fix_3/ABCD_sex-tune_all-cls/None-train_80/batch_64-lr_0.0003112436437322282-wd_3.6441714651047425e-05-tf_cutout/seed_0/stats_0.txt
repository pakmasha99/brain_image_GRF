"main_optuna_fix_3.py --pretrained_path None --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3 --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 55.72454261779785, "training_acc": 53.75, "val_loss": 16.846593618392944, "val_acc": 50.0}
{"epoch": 1, "training_loss": 62.24059295654297, "training_acc": 56.25, "val_loss": 21.32676362991333, "val_acc": 50.0}
{"epoch": 2, "training_loss": 75.09910297393799, "training_acc": 53.75, "val_loss": 13.860069513320923, "val_acc": 50.0}
{"epoch": 3, "training_loss": 55.59945869445801, "training_acc": 46.25, "val_loss": 13.960741758346558, "val_acc": 50.0}
{"epoch": 4, "training_loss": 56.33385372161865, "training_acc": 46.25, "val_loss": 13.871644735336304, "val_acc": 50.0}
{"epoch": 5, "training_loss": 55.676185607910156, "training_acc": 43.75, "val_loss": 13.866358995437622, "val_acc": 50.0}
{"epoch": 6, "training_loss": 55.34486961364746, "training_acc": 53.75, "val_loss": 13.887001276016235, "val_acc": 50.0}
{"epoch": 7, "training_loss": 55.36364269256592, "training_acc": 53.75, "val_loss": 13.906888961791992, "val_acc": 50.0}
{"epoch": 8, "training_loss": 55.21978759765625, "training_acc": 53.75, "val_loss": 13.874526023864746, "val_acc": 50.0}
{"epoch": 9, "training_loss": 55.29193115234375, "training_acc": 53.75, "val_loss": 13.867623805999756, "val_acc": 50.0}
{"epoch": 10, "training_loss": 55.38762664794922, "training_acc": 53.75, "val_loss": 13.875491619110107, "val_acc": 50.0}
{"epoch": 11, "training_loss": 55.22941207885742, "training_acc": 53.75, "val_loss": 13.949109315872192, "val_acc": 50.0}
{"epoch": 12, "training_loss": 55.17799949645996, "training_acc": 53.75, "val_loss": 14.135812520980835, "val_acc": 50.0}
{"epoch": 13, "training_loss": 55.62037181854248, "training_acc": 53.75, "val_loss": 14.301222562789917, "val_acc": 50.0}
{"epoch": 14, "training_loss": 56.143083572387695, "training_acc": 53.75, "val_loss": 14.369150400161743, "val_acc": 50.0}
{"epoch": 15, "training_loss": 56.21943187713623, "training_acc": 53.75, "val_loss": 14.312556982040405, "val_acc": 50.0}
{"epoch": 16, "training_loss": 56.080124855041504, "training_acc": 53.75, "val_loss": 14.118971824645996, "val_acc": 50.0}
{"epoch": 17, "training_loss": 55.48967361450195, "training_acc": 53.75, "val_loss": 13.976672887802124, "val_acc": 50.0}
{"epoch": 18, "training_loss": 55.36721229553223, "training_acc": 53.75, "val_loss": 13.9035165309906, "val_acc": 50.0}
{"epoch": 19, "training_loss": 55.230525970458984, "training_acc": 53.75, "val_loss": 13.876882791519165, "val_acc": 50.0}
{"epoch": 20, "training_loss": 55.22966384887695, "training_acc": 53.75, "val_loss": 13.865457773208618, "val_acc": 50.0}
{"epoch": 21, "training_loss": 55.5718297958374, "training_acc": 46.25, "val_loss": 13.870080709457397, "val_acc": 50.0}
{"epoch": 22, "training_loss": 55.53257751464844, "training_acc": 46.25, "val_loss": 13.864704370498657, "val_acc": 50.0}
{"epoch": 23, "training_loss": 55.40155601501465, "training_acc": 53.75, "val_loss": 13.876476287841797, "val_acc": 50.0}
{"epoch": 24, "training_loss": 55.292537689208984, "training_acc": 53.75, "val_loss": 13.889384269714355, "val_acc": 50.0}
{"epoch": 25, "training_loss": 55.25638961791992, "training_acc": 53.75, "val_loss": 13.897849321365356, "val_acc": 50.0}
{"epoch": 26, "training_loss": 55.23830986022949, "training_acc": 53.75, "val_loss": 13.905781507492065, "val_acc": 50.0}
{"epoch": 27, "training_loss": 55.23452377319336, "training_acc": 53.75, "val_loss": 13.924795389175415, "val_acc": 50.0}
{"epoch": 28, "training_loss": 55.26454162597656, "training_acc": 53.75, "val_loss": 13.944714069366455, "val_acc": 50.0}
{"epoch": 29, "training_loss": 55.23020076751709, "training_acc": 53.75, "val_loss": 13.942912817001343, "val_acc": 50.0}
{"epoch": 30, "training_loss": 55.22585201263428, "training_acc": 53.75, "val_loss": 13.943705558776855, "val_acc": 50.0}
