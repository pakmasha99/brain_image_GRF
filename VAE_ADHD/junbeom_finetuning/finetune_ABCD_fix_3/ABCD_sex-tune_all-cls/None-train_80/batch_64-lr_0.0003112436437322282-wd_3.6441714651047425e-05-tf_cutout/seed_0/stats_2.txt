"main_optuna_fix_3.py --pretrained_path None --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3 --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 60.8437385559082, "training_acc": 51.25, "val_loss": 14.689931869506836, "val_acc": 55.0}
{"epoch": 1, "training_loss": 73.93681335449219, "training_acc": 45.0, "val_loss": 14.750126600265503, "val_acc": 55.0}
{"epoch": 2, "training_loss": 57.3466157913208, "training_acc": 47.5, "val_loss": 13.874311447143555, "val_acc": 55.0}
{"epoch": 3, "training_loss": 56.02275085449219, "training_acc": 52.5, "val_loss": 13.81822943687439, "val_acc": 55.0}
{"epoch": 4, "training_loss": 55.534056663513184, "training_acc": 52.5, "val_loss": 14.11237120628357, "val_acc": 55.0}
{"epoch": 5, "training_loss": 56.0289945602417, "training_acc": 47.5, "val_loss": 13.800654411315918, "val_acc": 55.0}
{"epoch": 6, "training_loss": 55.59604835510254, "training_acc": 52.5, "val_loss": 14.06467318534851, "val_acc": 55.0}
{"epoch": 7, "training_loss": 57.08232593536377, "training_acc": 52.5, "val_loss": 13.954623937606812, "val_acc": 55.0}
{"epoch": 8, "training_loss": 55.807613372802734, "training_acc": 52.5, "val_loss": 13.929988145828247, "val_acc": 55.0}
{"epoch": 9, "training_loss": 55.5378999710083, "training_acc": 47.5, "val_loss": 14.362576007843018, "val_acc": 55.0}
{"epoch": 10, "training_loss": 56.823781967163086, "training_acc": 47.5, "val_loss": 14.046030044555664, "val_acc": 55.0}
{"epoch": 11, "training_loss": 55.651803970336914, "training_acc": 47.5, "val_loss": 13.78466010093689, "val_acc": 55.0}
{"epoch": 12, "training_loss": 55.457359313964844, "training_acc": 52.5, "val_loss": 13.817675113677979, "val_acc": 55.0}
{"epoch": 13, "training_loss": 55.723694801330566, "training_acc": 52.5, "val_loss": 13.78580927848816, "val_acc": 55.0}
{"epoch": 14, "training_loss": 55.393073081970215, "training_acc": 52.5, "val_loss": 13.820161819458008, "val_acc": 55.0}
{"epoch": 15, "training_loss": 55.53649711608887, "training_acc": 52.5, "val_loss": 13.839892148971558, "val_acc": 55.0}
{"epoch": 16, "training_loss": 55.33694648742676, "training_acc": 52.5, "val_loss": 13.793025016784668, "val_acc": 55.0}
{"epoch": 17, "training_loss": 55.46798515319824, "training_acc": 52.5, "val_loss": 13.784173727035522, "val_acc": 55.0}
{"epoch": 18, "training_loss": 55.45094394683838, "training_acc": 52.5, "val_loss": 13.784042596817017, "val_acc": 55.0}
{"epoch": 19, "training_loss": 55.37967872619629, "training_acc": 52.5, "val_loss": 13.798121213912964, "val_acc": 55.0}
{"epoch": 20, "training_loss": 55.36872673034668, "training_acc": 52.5, "val_loss": 13.828542232513428, "val_acc": 55.0}
{"epoch": 21, "training_loss": 55.381422996520996, "training_acc": 52.5, "val_loss": 13.837937116622925, "val_acc": 55.0}
{"epoch": 22, "training_loss": 55.38443183898926, "training_acc": 52.5, "val_loss": 13.827705383300781, "val_acc": 55.0}
{"epoch": 23, "training_loss": 55.34790897369385, "training_acc": 52.5, "val_loss": 13.808749914169312, "val_acc": 55.0}
{"epoch": 24, "training_loss": 55.31573677062988, "training_acc": 52.5, "val_loss": 13.787981271743774, "val_acc": 55.0}
{"epoch": 25, "training_loss": 55.32884216308594, "training_acc": 52.5, "val_loss": 13.780558109283447, "val_acc": 55.0}
{"epoch": 26, "training_loss": 55.407833099365234, "training_acc": 52.5, "val_loss": 13.792814016342163, "val_acc": 55.0}
{"epoch": 27, "training_loss": 55.58256721496582, "training_acc": 52.5, "val_loss": 13.819214105606079, "val_acc": 55.0}
{"epoch": 28, "training_loss": 55.83834266662598, "training_acc": 52.5, "val_loss": 13.795185089111328, "val_acc": 55.0}
{"epoch": 29, "training_loss": 55.60206604003906, "training_acc": 52.5, "val_loss": 13.780052661895752, "val_acc": 55.0}
