"main_optuna_fix_3.py --pretrained_path None --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3 --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 309.3583679199219, "training_acc": 52.5, "val_loss": 9858055536640.0, "val_acc": 45.0}
{"epoch": 1, "training_loss": 27394784747558.0, "training_acc": 47.5, "val_loss": 2916077760.0, "val_acc": 55.0}
{"epoch": 2, "training_loss": 10500123044.5, "training_acc": 52.5, "val_loss": 381031120.0, "val_acc": 45.0}
{"epoch": 3, "training_loss": 1203340352.0, "training_acc": 45.0, "val_loss": 3434345.9375, "val_acc": 55.0}
{"epoch": 4, "training_loss": 11872605.75, "training_acc": 52.5, "val_loss": 710877.34375, "val_acc": 45.0}
{"epoch": 5, "training_loss": 10810331.5, "training_acc": 47.5, "val_loss": 1912509.84375, "val_acc": 55.0}
{"epoch": 6, "training_loss": 6679997.78125, "training_acc": 52.5, "val_loss": 5544699.375, "val_acc": 55.0}
{"epoch": 7, "training_loss": 21256562.0, "training_acc": 52.5, "val_loss": 1548678.28125, "val_acc": 55.0}
{"epoch": 8, "training_loss": 5561853.0625, "training_acc": 57.5, "val_loss": 2103609.53125, "val_acc": 55.0}
{"epoch": 9, "training_loss": 10870188.5, "training_acc": 45.0, "val_loss": 1118853.75, "val_acc": 55.0}
{"epoch": 10, "training_loss": 4212586.8125, "training_acc": 50.0, "val_loss": 365676.8359375, "val_acc": 55.0}
{"epoch": 11, "training_loss": 1504692.1875, "training_acc": 52.5, "val_loss": 55037.03125, "val_acc": 45.0}
{"epoch": 12, "training_loss": 622891.125, "training_acc": 47.5, "val_loss": 461550.390625, "val_acc": 45.0}
{"epoch": 13, "training_loss": 1645512.140625, "training_acc": 50.0, "val_loss": 107230.76171875, "val_acc": 55.0}
{"epoch": 14, "training_loss": 387872.23828125, "training_acc": 52.5, "val_loss": 34991.8994140625, "val_acc": 55.0}
{"epoch": 15, "training_loss": 942911.328125, "training_acc": 47.5, "val_loss": 47223.359375, "val_acc": 45.0}
{"epoch": 16, "training_loss": 129357.57568359375, "training_acc": 47.5, "val_loss": 47974.47265625, "val_acc": 55.0}
{"epoch": 17, "training_loss": 175812.453125, "training_acc": 52.5, "val_loss": 1556.6128540039062, "val_acc": 45.0}
{"epoch": 18, "training_loss": 16446.72705078125, "training_acc": 45.0, "val_loss": 15327.041015625, "val_acc": 45.0}
{"epoch": 19, "training_loss": 48970.179443359375, "training_acc": 46.25, "val_loss": 232000.56640625, "val_acc": 55.0}
{"epoch": 20, "training_loss": 57088242.75, "training_acc": 52.5, "val_loss": 86991.259765625, "val_acc": 45.0}
{"epoch": 21, "training_loss": 925199.4375, "training_acc": 47.5, "val_loss": 1738506.40625, "val_acc": 55.0}
{"epoch": 22, "training_loss": 27083282.5, "training_acc": 52.5, "val_loss": 18853756.25, "val_acc": 55.0}
{"epoch": 23, "training_loss": 119798828.0, "training_acc": 47.5, "val_loss": 22169585.0, "val_acc": 55.0}
{"epoch": 24, "training_loss": 84009912.0, "training_acc": 52.5, "val_loss": 81124095.0, "val_acc": 55.0}
{"epoch": 25, "training_loss": 296689950.0, "training_acc": 45.0, "val_loss": 76555505.0, "val_acc": 55.0}
{"epoch": 26, "training_loss": 687438000.0, "training_acc": 50.0, "val_loss": 45602170880.0, "val_acc": 55.0}
{"epoch": 27, "training_loss": 147583552662.5, "training_acc": 52.5, "val_loss": 300766780.0, "val_acc": 45.0}
{"epoch": 28, "training_loss": 1114646496.0, "training_acc": 47.5, "val_loss": 178177180.0, "val_acc": 45.0}
{"epoch": 29, "training_loss": 675144128.0, "training_acc": 47.5, "val_loss": 56251695.0, "val_acc": 55.0}
{"epoch": 30, "training_loss": 188771747.5, "training_acc": 52.5, "val_loss": 41301087.5, "val_acc": 45.0}
{"epoch": 31, "training_loss": 266342504.0, "training_acc": 45.0, "val_loss": 3347654.0625, "val_acc": 55.0}
{"epoch": 32, "training_loss": 46169388.0, "training_acc": 47.5, "val_loss": 46150795.0, "val_acc": 55.0}
{"epoch": 33, "training_loss": 152355667.375, "training_acc": 52.5, "val_loss": 1846077.96875, "val_acc": 55.0}
{"epoch": 34, "training_loss": 8419582.0, "training_acc": 52.5, "val_loss": 2652795.9375, "val_acc": 45.0}
{"epoch": 35, "training_loss": 7916054.875, "training_acc": 45.0, "val_loss": 2902173.4375, "val_acc": 55.0}
{"epoch": 36, "training_loss": 11896823.0, "training_acc": 52.5, "val_loss": 85894.86328125, "val_acc": 55.0}
{"epoch": 37, "training_loss": 1343827.5, "training_acc": 47.5, "val_loss": 751343.671875, "val_acc": 45.0}
{"epoch": 38, "training_loss": 7048312.5, "training_acc": 50.0, "val_loss": 81069.2138671875, "val_acc": 50.0}
{"epoch": 39, "training_loss": 12908181.4375, "training_acc": 38.75, "val_loss": 131208.505859375, "val_acc": 45.0}
