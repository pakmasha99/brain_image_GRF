"main_optuna_fix_3.py --pretrained_path None --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3 --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 90.31835556030273, "training_acc": 53.75, "val_loss": 1.8244940589156847e+22, "val_acc": 50.0}
{"epoch": 1, "training_loss": 5.570777549031799e+22, "training_acc": 46.25, "val_loss": 724615.78125, "val_acc": 50.0}
{"epoch": 2, "training_loss": 2997569.75, "training_acc": 46.25, "val_loss": 490022.421875, "val_acc": 50.0}
{"epoch": 3, "training_loss": 1864135.0, "training_acc": 46.25, "val_loss": 44974.619140625, "val_acc": 50.0}
{"epoch": 4, "training_loss": 298099.953125, "training_acc": 46.25, "val_loss": 90629.296875, "val_acc": 50.0}
{"epoch": 5, "training_loss": 309898.42578125, "training_acc": 53.75, "val_loss": 305290.625, "val_acc": 50.0}
{"epoch": 6, "training_loss": 1129155.71875, "training_acc": 48.75, "val_loss": 1045074.921875, "val_acc": 50.0}
{"epoch": 7, "training_loss": 3049649.578125, "training_acc": 53.75, "val_loss": 8592.0751953125, "val_acc": 50.0}
{"epoch": 8, "training_loss": 565640.9765625, "training_acc": 53.75, "val_loss": 5274.87548828125, "val_acc": 50.0}
{"epoch": 9, "training_loss": 290026.91796875, "training_acc": 46.25, "val_loss": 143185.46875, "val_acc": 50.0}
{"epoch": 10, "training_loss": 443889.44921875, "training_acc": 53.75, "val_loss": 157706.064453125, "val_acc": 50.0}
{"epoch": 11, "training_loss": 541681.53125, "training_acc": 51.25, "val_loss": 26879.97314453125, "val_acc": 50.0}
{"epoch": 12, "training_loss": 91756.484375, "training_acc": 48.75, "val_loss": 54779.3359375, "val_acc": 50.0}
{"epoch": 13, "training_loss": 177541.81298828125, "training_acc": 53.75, "val_loss": 2054.751434326172, "val_acc": 50.0}
{"epoch": 14, "training_loss": 40760.4208984375, "training_acc": 43.75, "val_loss": 26202.9296875, "val_acc": 50.0}
{"epoch": 15, "training_loss": 594927.6015625, "training_acc": 51.25, "val_loss": 2376557.03125, "val_acc": 50.0}
{"epoch": 16, "training_loss": 7722023.8681640625, "training_acc": 51.25, "val_loss": 32054.931640625, "val_acc": 50.0}
{"epoch": 17, "training_loss": 93390.90625, "training_acc": 52.5, "val_loss": 637970.1171875, "val_acc": 50.0}
{"epoch": 18, "training_loss": 2440322.28125, "training_acc": 51.25, "val_loss": 122999.08203125, "val_acc": 50.0}
{"epoch": 19, "training_loss": 8789642.0625, "training_acc": 61.25, "val_loss": 3078.0459594726562, "val_acc": 55.0}
{"epoch": 20, "training_loss": 1239614.18359375, "training_acc": 43.75, "val_loss": 213035.8984375, "val_acc": 50.0}
{"epoch": 21, "training_loss": 748312.2578125, "training_acc": 48.75, "val_loss": 5428540.0, "val_acc": 50.0}
{"epoch": 22, "training_loss": 17828844.3125, "training_acc": 53.75, "val_loss": 3772651.875, "val_acc": 50.0}
{"epoch": 23, "training_loss": 11250550.6875, "training_acc": 53.75, "val_loss": 699019.921875, "val_acc": 50.0}
{"epoch": 24, "training_loss": 2380893.5625, "training_acc": 53.75, "val_loss": 66091.1083984375, "val_acc": 50.0}
{"epoch": 25, "training_loss": 228778.99139404297, "training_acc": 46.25, "val_loss": 43010.6494140625, "val_acc": 50.0}
{"epoch": 26, "training_loss": 134090.54296875, "training_acc": 53.75, "val_loss": 88421.748046875, "val_acc": 50.0}
{"epoch": 27, "training_loss": 333358.4375, "training_acc": 46.25, "val_loss": 30280.52490234375, "val_acc": 50.0}
{"epoch": 28, "training_loss": 192999.8828125, "training_acc": 43.75, "val_loss": 48558.1640625, "val_acc": 50.0}
{"epoch": 29, "training_loss": 676792.90625, "training_acc": 51.25, "val_loss": 49065.966796875, "val_acc": 50.0}
{"epoch": 30, "training_loss": 190567.91796875, "training_acc": 48.75, "val_loss": 16978.460693359375, "val_acc": 50.0}
{"epoch": 31, "training_loss": 226747.11328125, "training_acc": 53.75, "val_loss": 7976.6497802734375, "val_acc": 50.0}
