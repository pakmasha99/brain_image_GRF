"main_optuna_fix_3.py --pretrained_path None --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3 --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 59.06416988372803, "training_acc": 52.5, "val_loss": 3.867699276469502e+20, "val_acc": 45.0}
{"epoch": 1, "training_loss": 1.0718443264155201e+21, "training_acc": 47.5, "val_loss": 693019120.0, "val_acc": 45.0}
{"epoch": 2, "training_loss": 6181139968.0, "training_acc": 55.0, "val_loss": 276288140.0, "val_acc": 55.0}
{"epoch": 3, "training_loss": 1029775200.0, "training_acc": 55.0, "val_loss": 55398825.0, "val_acc": 55.0}
{"epoch": 4, "training_loss": 205847456.0, "training_acc": 50.0, "val_loss": 1197697440.0, "val_acc": 55.0}
{"epoch": 5, "training_loss": 3981853620.0, "training_acc": 52.5, "val_loss": 266136060.0, "val_acc": 45.0}
{"epoch": 6, "training_loss": 1011945856.0, "training_acc": 50.0, "val_loss": 16027085.0, "val_acc": 45.0}
{"epoch": 7, "training_loss": 10807202236.0, "training_acc": 47.5, "val_loss": 138463700.0, "val_acc": 55.0}
{"epoch": 8, "training_loss": 41733282304.0, "training_acc": 52.5, "val_loss": 392599160.0, "val_acc": 55.0}
{"epoch": 9, "training_loss": 6510583040.0, "training_acc": 52.5, "val_loss": 1190560560.0, "val_acc": 55.0}
{"epoch": 10, "training_loss": 4105666624.0, "training_acc": 52.5, "val_loss": 57604100.0, "val_acc": 45.0}
{"epoch": 11, "training_loss": 440336368.0, "training_acc": 55.0, "val_loss": 104300670.0, "val_acc": 55.0}
{"epoch": 12, "training_loss": 861256032.0, "training_acc": 52.5, "val_loss": 818353280.0, "val_acc": 55.0}
{"epoch": 13, "training_loss": 3537704960.0, "training_acc": 50.0, "val_loss": 254744350720.0, "val_acc": 55.0}
{"epoch": 14, "training_loss": 773510010064.0, "training_acc": 57.5, "val_loss": 37567595520.0, "val_acc": 55.0}
{"epoch": 15, "training_loss": 132889571840.0, "training_acc": 52.5, "val_loss": 638409800.0, "val_acc": 45.0}
{"epoch": 16, "training_loss": 4361236096.0, "training_acc": 57.5, "val_loss": 12667155200.0, "val_acc": 45.0}
{"epoch": 17, "training_loss": 40606106752.0, "training_acc": 47.5, "val_loss": 2228122720.0, "val_acc": 45.0}
{"epoch": 18, "training_loss": 15575380480.0, "training_acc": 45.0, "val_loss": 5750299520.0, "val_acc": 55.0}
{"epoch": 19, "training_loss": 18095799032.0, "training_acc": 52.5, "val_loss": 1210328240.0, "val_acc": 45.0}
{"epoch": 20, "training_loss": 3854129408.0, "training_acc": 47.5, "val_loss": 877082640.0, "val_acc": 55.0}
{"epoch": 21, "training_loss": 4788941056.0, "training_acc": 50.0, "val_loss": 314030340.0, "val_acc": 45.0}
{"epoch": 22, "training_loss": 1603245056.0, "training_acc": 47.5, "val_loss": 54695270.0, "val_acc": 55.0}
{"epoch": 23, "training_loss": 191829168.0, "training_acc": 50.0, "val_loss": 37306100.0, "val_acc": 55.0}
{"epoch": 24, "training_loss": 132077075.0, "training_acc": 52.5, "val_loss": 124606510.0, "val_acc": 55.0}
{"epoch": 25, "training_loss": 532584784.0, "training_acc": 52.5, "val_loss": 951480960.0, "val_acc": 45.0}
{"epoch": 26, "training_loss": 2862003360.0, "training_acc": 47.5, "val_loss": 31600577.5, "val_acc": 45.0}
{"epoch": 27, "training_loss": 160437824.0, "training_acc": 47.5, "val_loss": 970857440.0, "val_acc": 55.0}
{"epoch": 28, "training_loss": 3391817792.0, "training_acc": 52.5, "val_loss": 4852184.0625, "val_acc": 55.0}
{"epoch": 29, "training_loss": 28395230.0, "training_acc": 45.0, "val_loss": 7739246.875, "val_acc": 55.0}
{"epoch": 30, "training_loss": 32548579.0, "training_acc": 52.5, "val_loss": 6506460.0, "val_acc": 55.0}
{"epoch": 31, "training_loss": 25589072.0, "training_acc": 52.5, "val_loss": 244568.57421875, "val_acc": 55.0}
{"epoch": 32, "training_loss": 7268158.25, "training_acc": 47.5, "val_loss": 4475643.125, "val_acc": 45.0}
{"epoch": 33, "training_loss": 14620901.1875, "training_acc": 47.5, "val_loss": 34375105.0, "val_acc": 45.0}
