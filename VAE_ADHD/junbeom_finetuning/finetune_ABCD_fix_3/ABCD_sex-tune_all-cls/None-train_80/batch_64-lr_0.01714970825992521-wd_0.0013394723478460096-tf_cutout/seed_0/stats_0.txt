"main_optuna_fix_3.py --pretrained_path None --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3 --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 95.69375228881836, "training_acc": 53.75, "val_loss": 2.3583935316816442e+24, "val_acc": 50.0}
{"epoch": 1, "training_loss": 7.44317462051377e+24, "training_acc": 46.25, "val_loss": 5.17653328911359e+20, "val_acc": 50.0}
{"epoch": 2, "training_loss": 1.7476795551144246e+21, "training_acc": 46.25, "val_loss": 6.539283558668698e+17, "val_acc": 50.0}
{"epoch": 3, "training_loss": 6.710508305438999e+18, "training_acc": 46.25, "val_loss": 8.267886261834875e+18, "val_acc": 50.0}
{"epoch": 4, "training_loss": 2.3639444370915066e+19, "training_acc": 53.75, "val_loss": 4209890369208320.0, "val_acc": 50.0}
{"epoch": 5, "training_loss": 1.5008139455758336e+16, "training_acc": 46.25, "val_loss": 112284821094400.0, "val_acc": 50.0}
{"epoch": 6, "training_loss": 445604022976512.0, "training_acc": 46.25, "val_loss": 52668473016320.0, "val_acc": 50.0}
{"epoch": 7, "training_loss": 189315425632256.0, "training_acc": 46.25, "val_loss": 14301804625920.0, "val_acc": 50.0}
{"epoch": 8, "training_loss": 42644842741760.0, "training_acc": 53.75, "val_loss": 9952209797120.0, "val_acc": 50.0}
{"epoch": 9, "training_loss": 9.016488172095275e+18, "training_acc": 53.75, "val_loss": 12921170821120.0, "val_acc": 50.0}
{"epoch": 10, "training_loss": 45909617410048.0, "training_acc": 48.75, "val_loss": 1.7047835446870016e+17, "val_acc": 50.0}
{"epoch": 11, "training_loss": 5.594913871505654e+17, "training_acc": 51.25, "val_loss": 421568404520960.0, "val_acc": 50.0}
{"epoch": 12, "training_loss": 1443930121961472.0, "training_acc": 53.75, "val_loss": 187551889489920.0, "val_acc": 50.0}
{"epoch": 13, "training_loss": 621450172039168.0, "training_acc": 53.75, "val_loss": 1550725289082880.0, "val_acc": 50.0}
{"epoch": 14, "training_loss": 4907321444532224.0, "training_acc": 46.25, "val_loss": 1847863206215680.0, "val_acc": 50.0}
{"epoch": 15, "training_loss": 7571169154695168.0, "training_acc": 53.75, "val_loss": 1638785540423680.0, "val_acc": 50.0}
{"epoch": 16, "training_loss": 5116851604422656.0, "training_acc": 53.75, "val_loss": 32910459535360.0, "val_acc": 50.0}
{"epoch": 17, "training_loss": 117270915842048.0, "training_acc": 46.25, "val_loss": 14407857602560.0, "val_acc": 50.0}
{"epoch": 18, "training_loss": 60599432118272.0, "training_acc": 51.25, "val_loss": 322807009280.0, "val_acc": 50.0}
{"epoch": 19, "training_loss": 1427170918400.0, "training_acc": 46.25, "val_loss": 3201164247040.0, "val_acc": 50.0}
{"epoch": 20, "training_loss": 28905095299072.0, "training_acc": 56.25, "val_loss": 77290620846080.0, "val_acc": 50.0}
{"epoch": 21, "training_loss": 1204750204796928.0, "training_acc": 53.75, "val_loss": 7941533859840.0, "val_acc": 50.0}
{"epoch": 22, "training_loss": 124523298947072.0, "training_acc": 46.25, "val_loss": 163366567936000.0, "val_acc": 50.0}
{"epoch": 23, "training_loss": 613240623071232.0, "training_acc": 46.25, "val_loss": 25994581770240.0, "val_acc": 50.0}
{"epoch": 24, "training_loss": 101372005449728.0, "training_acc": 46.25, "val_loss": 5160201420800.0, "val_acc": 50.0}
{"epoch": 25, "training_loss": 18887699988480.0, "training_acc": 46.25, "val_loss": 123608238080.0, "val_acc": 50.0}
{"epoch": 26, "training_loss": 538864025600.0, "training_acc": 53.75, "val_loss": 179812700160.0, "val_acc": 50.0}
{"epoch": 27, "training_loss": 11721758932992.0, "training_acc": 51.25, "val_loss": 4767319326720.0, "val_acc": 50.0}
{"epoch": 28, "training_loss": 16442949369856.0, "training_acc": 53.75, "val_loss": 5167878963200.0, "val_acc": 50.0}
{"epoch": 29, "training_loss": 18865113137152.0, "training_acc": 46.25, "val_loss": 2617733775360.0, "val_acc": 50.0}
{"epoch": 30, "training_loss": 9284906450944.0, "training_acc": 48.75, "val_loss": 1092969676800.0, "val_acc": 50.0}
