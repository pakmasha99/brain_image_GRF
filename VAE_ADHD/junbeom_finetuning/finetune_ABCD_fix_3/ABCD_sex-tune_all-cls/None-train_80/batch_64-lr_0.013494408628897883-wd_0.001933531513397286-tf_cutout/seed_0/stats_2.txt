"main_optuna_fix_3.py --pretrained_path None --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3 --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 538.6586036682129, "training_acc": 48.75, "val_loss": 22135174594560.0, "val_acc": 55.0}
{"epoch": 1, "training_loss": 79679488090240.0, "training_acc": 45.0, "val_loss": 159760056320.0, "val_acc": 45.0}
{"epoch": 2, "training_loss": 470324392448.0, "training_acc": 47.5, "val_loss": 47497.0166015625, "val_acc": 55.0}
{"epoch": 3, "training_loss": 509758236.765625, "training_acc": 50.0, "val_loss": 35877917.5, "val_acc": 55.0}
{"epoch": 4, "training_loss": 163361972.0, "training_acc": 52.5, "val_loss": 994676.484375, "val_acc": 55.0}
{"epoch": 5, "training_loss": 39849232.0, "training_acc": 52.5, "val_loss": 9868686.25, "val_acc": 45.0}
{"epoch": 6, "training_loss": 26681375.84375, "training_acc": 57.5, "val_loss": 6431555.0, "val_acc": 55.0}
{"epoch": 7, "training_loss": 22800923.5625, "training_acc": 52.5, "val_loss": 443276.09375, "val_acc": 55.0}
{"epoch": 8, "training_loss": 1355826.4736328125, "training_acc": 52.5, "val_loss": 3448484.6875, "val_acc": 45.0}
{"epoch": 9, "training_loss": 12190987.25, "training_acc": 47.5, "val_loss": 385077.7734375, "val_acc": 45.0}
{"epoch": 10, "training_loss": 1274478.8125, "training_acc": 47.5, "val_loss": 555227.3046875, "val_acc": 55.0}
{"epoch": 11, "training_loss": 2201100.015625, "training_acc": 52.5, "val_loss": 184422.3828125, "val_acc": 55.0}
{"epoch": 12, "training_loss": 793868.6875, "training_acc": 52.5, "val_loss": 203985.09765625, "val_acc": 55.0}
{"epoch": 13, "training_loss": 850526.875, "training_acc": 52.5, "val_loss": 58525.2197265625, "val_acc": 55.0}
{"epoch": 14, "training_loss": 1540226.578125, "training_acc": 52.5, "val_loss": 2234699.84375, "val_acc": 55.0}
{"epoch": 15, "training_loss": 11604442.75, "training_acc": 45.0, "val_loss": 1384857.96875, "val_acc": 45.0}
{"epoch": 16, "training_loss": 7063991.0, "training_acc": 55.0, "val_loss": 219115.3125, "val_acc": 55.0}
{"epoch": 17, "training_loss": 62772118987.25, "training_acc": 52.5, "val_loss": 3887551.5625, "val_acc": 45.0}
{"epoch": 18, "training_loss": 109690998.0, "training_acc": 47.5, "val_loss": 846163760.0, "val_acc": 45.0}
{"epoch": 19, "training_loss": 4387660544.0, "training_acc": 47.5, "val_loss": 225040180.0, "val_acc": 45.0}
{"epoch": 20, "training_loss": 698353420.0, "training_acc": 47.5, "val_loss": 76286945.0, "val_acc": 55.0}
{"epoch": 21, "training_loss": 308079272.0, "training_acc": 52.5, "val_loss": 1919647520.0, "val_acc": 45.0}
{"epoch": 22, "training_loss": 5670132064.0, "training_acc": 50.0, "val_loss": 493734040.0, "val_acc": 55.0}
{"epoch": 23, "training_loss": 1852855648.0, "training_acc": 52.5, "val_loss": 12370220.0, "val_acc": 55.0}
{"epoch": 24, "training_loss": 427699632.0, "training_acc": 45.0, "val_loss": 65952155.0, "val_acc": 45.0}
{"epoch": 25, "training_loss": 209553499.0, "training_acc": 47.5, "val_loss": 37852980.0, "val_acc": 55.0}
{"epoch": 26, "training_loss": 165111126.0, "training_acc": 52.5, "val_loss": 30351197.5, "val_acc": 55.0}
{"epoch": 27, "training_loss": 114398096.0, "training_acc": 52.5, "val_loss": 2354209.53125, "val_acc": 45.0}
{"epoch": 28, "training_loss": 14060883.5, "training_acc": 47.5, "val_loss": 118612110.0, "val_acc": 55.0}
{"epoch": 29, "training_loss": 418238212.0, "training_acc": 52.5, "val_loss": 16496717.5, "val_acc": 45.0}
{"epoch": 30, "training_loss": 62270908.0, "training_acc": 47.5, "val_loss": 5180986560.0, "val_acc": 45.0}
{"epoch": 31, "training_loss": 16978220544.0, "training_acc": 42.5, "val_loss": 498441240.0, "val_acc": 45.0}
{"epoch": 32, "training_loss": 1998438144.0, "training_acc": 47.5, "val_loss": 543449280.0, "val_acc": 45.0}
{"epoch": 33, "training_loss": 1867626944.0, "training_acc": 47.5, "val_loss": 57207245.0, "val_acc": 55.0}
{"epoch": 34, "training_loss": 8337197792.0, "training_acc": 50.0, "val_loss": 835867040.0, "val_acc": 55.0}
{"epoch": 35, "training_loss": 3032314880.0, "training_acc": 52.5, "val_loss": 117132110.0, "val_acc": 55.0}
{"epoch": 36, "training_loss": 838129472.0, "training_acc": 52.5, "val_loss": 14781248000.0, "val_acc": 45.0}
{"epoch": 37, "training_loss": 57848209408.0, "training_acc": 45.0, "val_loss": 1799182240.0, "val_acc": 55.0}
{"epoch": 38, "training_loss": 6382945728.0, "training_acc": 47.5, "val_loss": 33339409920.0, "val_acc": 45.0}
{"epoch": 39, "training_loss": 99388697856.0, "training_acc": 50.0, "val_loss": 439757840.0, "val_acc": 55.0}
{"epoch": 40, "training_loss": 3941152512.0, "training_acc": 52.5, "val_loss": 1385613760.0, "val_acc": 55.0}
{"epoch": 41, "training_loss": 4541405472.0, "training_acc": 52.5, "val_loss": 21591710.0, "val_acc": 55.0}
{"epoch": 42, "training_loss": 44045410064.0, "training_acc": 52.5, "val_loss": 3803775360.0, "val_acc": 55.0}
{"epoch": 43, "training_loss": 39113319424.0, "training_acc": 52.5, "val_loss": 16394899200.0, "val_acc": 45.0}
{"epoch": 44, "training_loss": 57482781696.0, "training_acc": 47.5, "val_loss": 47116095324160.0, "val_acc": 55.0}
