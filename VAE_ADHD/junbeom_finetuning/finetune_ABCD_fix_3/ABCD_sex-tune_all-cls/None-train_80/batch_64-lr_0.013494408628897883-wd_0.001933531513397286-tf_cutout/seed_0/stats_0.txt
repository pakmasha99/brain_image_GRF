"main_optuna_fix_3.py --pretrained_path None --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3 --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 84.76762008666992, "training_acc": 53.75, "val_loss": 7.448159386519732e+19, "val_acc": 50.0}
{"epoch": 1, "training_loss": 2.2757452417977496e+20, "training_acc": 46.25, "val_loss": 172077.59765625, "val_acc": 50.0}
{"epoch": 2, "training_loss": 1617931.4375, "training_acc": 46.25, "val_loss": 175496.62109375, "val_acc": 50.0}
{"epoch": 3, "training_loss": 542877.16015625, "training_acc": 53.75, "val_loss": 48970.9130859375, "val_acc": 50.0}
{"epoch": 4, "training_loss": 155483.7646484375, "training_acc": 53.75, "val_loss": 5011.291198730469, "val_acc": 50.0}
{"epoch": 5, "training_loss": 77424.3017578125, "training_acc": 56.25, "val_loss": 12674.75830078125, "val_acc": 50.0}
{"epoch": 6, "training_loss": 61398.8828125, "training_acc": 53.75, "val_loss": 77320.3759765625, "val_acc": 50.0}
{"epoch": 7, "training_loss": 224683.54296875, "training_acc": 53.75, "val_loss": 21860.703125, "val_acc": 50.0}
{"epoch": 8, "training_loss": 67568.87109375, "training_acc": 53.75, "val_loss": 1667.9469299316406, "val_acc": 50.0}
{"epoch": 9, "training_loss": 14170.169921875, "training_acc": 53.75, "val_loss": 3408.4381103515625, "val_acc": 50.0}
{"epoch": 10, "training_loss": 16366.5107421875, "training_acc": 51.25, "val_loss": 3173.2943725585938, "val_acc": 50.0}
{"epoch": 11, "training_loss": 12927.476318359375, "training_acc": 48.75, "val_loss": 131.56832695007324, "val_acc": 50.0}
{"epoch": 12, "training_loss": 6575.830474853516, "training_acc": 51.25, "val_loss": 10291.513671875, "val_acc": 50.0}
{"epoch": 13, "training_loss": 36035.74267578125, "training_acc": 53.75, "val_loss": 1237.3235321044922, "val_acc": 50.0}
{"epoch": 14, "training_loss": 4914.152099609375, "training_acc": 56.25, "val_loss": 1460.318603515625, "val_acc": 50.0}
{"epoch": 15, "training_loss": 11716.95166015625, "training_acc": 48.75, "val_loss": 188.763427734375, "val_acc": 50.0}
{"epoch": 16, "training_loss": 11585.366882324219, "training_acc": 48.75, "val_loss": 1535.5589294433594, "val_acc": 50.0}
{"epoch": 17, "training_loss": 22073.58740234375, "training_acc": 46.25, "val_loss": 8973.871459960938, "val_acc": 50.0}
{"epoch": 18, "training_loss": 27584.064422607422, "training_acc": 48.75, "val_loss": 3912.8292846679688, "val_acc": 50.0}
{"epoch": 19, "training_loss": 14483.525390625, "training_acc": 53.75, "val_loss": 64.97798442840576, "val_acc": 50.0}
{"epoch": 20, "training_loss": 12425.365844726562, "training_acc": 48.75, "val_loss": 5015.0274658203125, "val_acc": 50.0}
{"epoch": 21, "training_loss": 20482.29296875, "training_acc": 46.25, "val_loss": 1405.2027893066406, "val_acc": 50.0}
{"epoch": 22, "training_loss": 15940.158203125, "training_acc": 53.75, "val_loss": 9161.295776367188, "val_acc": 50.0}
{"epoch": 23, "training_loss": 32469.382446289062, "training_acc": 46.25, "val_loss": 4860.130920410156, "val_acc": 50.0}
{"epoch": 24, "training_loss": 16151.1484375, "training_acc": 53.75, "val_loss": 3658.7179565429688, "val_acc": 50.0}
{"epoch": 25, "training_loss": 14020.4560546875, "training_acc": 46.25, "val_loss": 308.13419342041016, "val_acc": 50.0}
{"epoch": 26, "training_loss": 2066.4750366210938, "training_acc": 51.25, "val_loss": 1050.279769897461, "val_acc": 50.0}
{"epoch": 27, "training_loss": 3589.193634033203, "training_acc": 53.75, "val_loss": 15083.19580078125, "val_acc": 50.0}
{"epoch": 28, "training_loss": 55248.52453613281, "training_acc": 46.25, "val_loss": 14289.140625, "val_acc": 50.0}
{"epoch": 29, "training_loss": 43788.915771484375, "training_acc": 51.25, "val_loss": 4611.376037597656, "val_acc": 50.0}
{"epoch": 30, "training_loss": 16166.8505859375, "training_acc": 51.25, "val_loss": 276.9897270202637, "val_acc": 50.0}
{"epoch": 31, "training_loss": 1477.150146484375, "training_acc": 53.75, "val_loss": 368.88912200927734, "val_acc": 50.0}
{"epoch": 32, "training_loss": 1308.3078002929688, "training_acc": 53.75, "val_loss": 1164.7191619873047, "val_acc": 50.0}
{"epoch": 33, "training_loss": 3998.8221893310547, "training_acc": 46.25, "val_loss": 2687.4984741210938, "val_acc": 50.0}
{"epoch": 34, "training_loss": 9692.127197265625, "training_acc": 53.75, "val_loss": 1392.4522399902344, "val_acc": 50.0}
{"epoch": 35, "training_loss": 4028.4164428710938, "training_acc": 53.75, "val_loss": 1621.2332153320312, "val_acc": 50.0}
{"epoch": 36, "training_loss": 6926.02392578125, "training_acc": 46.25, "val_loss": 54.4215726852417, "val_acc": 45.0}
{"epoch": 37, "training_loss": 355.32469940185547, "training_acc": 58.75, "val_loss": 2610.2880859375, "val_acc": 50.0}
{"epoch": 38, "training_loss": 7695.851470947266, "training_acc": 51.25, "val_loss": 13488.861083984375, "val_acc": 50.0}
{"epoch": 39, "training_loss": 41610.028564453125, "training_acc": 53.75, "val_loss": 822.2044372558594, "val_acc": 50.0}
{"epoch": 40, "training_loss": 3624.736328125, "training_acc": 46.25, "val_loss": 155.16913414001465, "val_acc": 50.0}
{"epoch": 41, "training_loss": 2969.7543334960938, "training_acc": 41.25, "val_loss": 550.7194137573242, "val_acc": 50.0}
{"epoch": 42, "training_loss": 3805.997802734375, "training_acc": 51.25, "val_loss": 1061.828842163086, "val_acc": 50.0}
{"epoch": 43, "training_loss": 3723.4017944335938, "training_acc": 46.25, "val_loss": 1384.6243286132812, "val_acc": 50.0}
{"epoch": 44, "training_loss": 5141.8175048828125, "training_acc": 53.75, "val_loss": 1454.6208190917969, "val_acc": 50.0}
{"epoch": 45, "training_loss": 5517.456237792969, "training_acc": 48.75, "val_loss": 1052.361831665039, "val_acc": 50.0}
{"epoch": 46, "training_loss": 3518.511016845703, "training_acc": 53.75, "val_loss": 162.44550704956055, "val_acc": 50.0}
{"epoch": 47, "training_loss": 3337.23193359375, "training_acc": 48.75, "val_loss": 315.7781410217285, "val_acc": 50.0}
{"epoch": 48, "training_loss": 2489.8264770507812, "training_acc": 51.25, "val_loss": 856.2273406982422, "val_acc": 50.0}
{"epoch": 49, "training_loss": 3238.085479736328, "training_acc": 46.25, "val_loss": 161.5565299987793, "val_acc": 50.0}
{"epoch": 50, "training_loss": 622.7217254638672, "training_acc": 53.75, "val_loss": 27.234656810760498, "val_acc": 50.0}
{"epoch": 51, "training_loss": 12762.03409576416, "training_acc": 50.0, "val_loss": 1796.2939453125, "val_acc": 50.0}
{"epoch": 52, "training_loss": 7540.82373046875, "training_acc": 46.25, "val_loss": 1092.2149658203125, "val_acc": 50.0}
{"epoch": 53, "training_loss": 3629.164505004883, "training_acc": 46.25, "val_loss": 1670.5177307128906, "val_acc": 50.0}
{"epoch": 54, "training_loss": 5354.392883300781, "training_acc": 53.75, "val_loss": 5906.7462158203125, "val_acc": 50.0}
{"epoch": 55, "training_loss": 20474.364486694336, "training_acc": 46.25, "val_loss": 1287.4066162109375, "val_acc": 50.0}
{"epoch": 56, "training_loss": 4728.341033935547, "training_acc": 41.25, "val_loss": 2568.9157104492188, "val_acc": 50.0}
{"epoch": 57, "training_loss": 9485.177978515625, "training_acc": 46.25, "val_loss": 1102.157211303711, "val_acc": 50.0}
{"epoch": 58, "training_loss": 3360.0850219726562, "training_acc": 53.75, "val_loss": 1539.8466491699219, "val_acc": 50.0}
{"epoch": 59, "training_loss": 6487.0701904296875, "training_acc": 46.25, "val_loss": 450.6966781616211, "val_acc": 50.0}
{"epoch": 60, "training_loss": 2010.872802734375, "training_acc": 51.25, "val_loss": 1332.7384948730469, "val_acc": 50.0}
{"epoch": 61, "training_loss": 4699.0203857421875, "training_acc": 53.75, "val_loss": 509.6084976196289, "val_acc": 50.0}
{"epoch": 62, "training_loss": 1671.0175476074219, "training_acc": 53.75, "val_loss": 362.57484436035156, "val_acc": 50.0}
{"epoch": 63, "training_loss": 1404.1491012573242, "training_acc": 43.75, "val_loss": 271.6463088989258, "val_acc": 50.0}
{"epoch": 64, "training_loss": 1092.5513381958008, "training_acc": 46.25, "val_loss": 124.84805107116699, "val_acc": 50.0}
{"epoch": 65, "training_loss": 475.2996520996094, "training_acc": 53.75, "val_loss": 129.09497261047363, "val_acc": 50.0}
{"epoch": 66, "training_loss": 552.491340637207, "training_acc": 46.25, "val_loss": 16.586246490478516, "val_acc": 50.0}
{"epoch": 67, "training_loss": 209.02442932128906, "training_acc": 46.25, "val_loss": 177.55504608154297, "val_acc": 50.0}
{"epoch": 68, "training_loss": 581.3212089538574, "training_acc": 53.75, "val_loss": 66.59067630767822, "val_acc": 50.0}
{"epoch": 69, "training_loss": 290.38148498535156, "training_acc": 46.25, "val_loss": 14.129090309143066, "val_acc": 50.0}
{"epoch": 70, "training_loss": 92.86589050292969, "training_acc": 61.25, "val_loss": 58.35311412811279, "val_acc": 50.0}
{"epoch": 71, "training_loss": 192.57272720336914, "training_acc": 51.25, "val_loss": 28.003039360046387, "val_acc": 50.0}
{"epoch": 72, "training_loss": 123.15862274169922, "training_acc": 46.25, "val_loss": 26.674277782440186, "val_acc": 50.0}
{"epoch": 73, "training_loss": 125.08002090454102, "training_acc": 43.75, "val_loss": 13.988505601882935, "val_acc": 50.0}
{"epoch": 74, "training_loss": 85.80915832519531, "training_acc": 48.75, "val_loss": 14.804909229278564, "val_acc": 55.0}
{"epoch": 75, "training_loss": 72.16864585876465, "training_acc": 41.25, "val_loss": 15.185327529907227, "val_acc": 50.0}
{"epoch": 76, "training_loss": 65.6156997680664, "training_acc": 52.5, "val_loss": 13.937208652496338, "val_acc": 50.0}
{"epoch": 77, "training_loss": 75.41426467895508, "training_acc": 35.0, "val_loss": 24.56556797027588, "val_acc": 50.0}
{"epoch": 78, "training_loss": 94.11579513549805, "training_acc": 53.75, "val_loss": 14.754723310470581, "val_acc": 55.0}
{"epoch": 79, "training_loss": 61.920265197753906, "training_acc": 47.5, "val_loss": 14.467376470565796, "val_acc": 60.0}
{"epoch": 80, "training_loss": 59.21542167663574, "training_acc": 53.75, "val_loss": 18.88983964920044, "val_acc": 50.0}
{"epoch": 81, "training_loss": 68.52761840820312, "training_acc": 53.75, "val_loss": 17.826416492462158, "val_acc": 50.0}
