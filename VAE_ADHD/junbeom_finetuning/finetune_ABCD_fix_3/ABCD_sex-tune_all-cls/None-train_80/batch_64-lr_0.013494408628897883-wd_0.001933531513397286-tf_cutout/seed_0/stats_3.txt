"main_optuna_fix_3.py --pretrained_path None --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3 --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 218.67009353637695, "training_acc": 52.5, "val_loss": 1.2420329234235392e+17, "val_acc": 45.0}
{"epoch": 1, "training_loss": 3.449572734068547e+17, "training_acc": 47.5, "val_loss": 3741608.125, "val_acc": 55.0}
{"epoch": 2, "training_loss": 18003590.0, "training_acc": 50.0, "val_loss": 629813.515625, "val_acc": 55.0}
{"epoch": 3, "training_loss": 2541798.71875, "training_acc": 52.5, "val_loss": 89686.025390625, "val_acc": 55.0}
{"epoch": 4, "training_loss": 373178.0546875, "training_acc": 47.5, "val_loss": 1245770.78125, "val_acc": 55.0}
{"epoch": 5, "training_loss": 4230156.00390625, "training_acc": 52.5, "val_loss": 33.20150375366211, "val_acc": 25.0}
{"epoch": 6, "training_loss": 60019.898193359375, "training_acc": 53.75, "val_loss": 254536.15234375, "val_acc": 45.0}
{"epoch": 7, "training_loss": 1121330.0625, "training_acc": 47.5, "val_loss": 6728895.0, "val_acc": 45.0}
{"epoch": 8, "training_loss": 170344012.0, "training_acc": 42.5, "val_loss": 3473716.5625, "val_acc": 55.0}
{"epoch": 9, "training_loss": 11795100.4375, "training_acc": 52.5, "val_loss": 1551337.03125, "val_acc": 45.0}
{"epoch": 10, "training_loss": 4505774.1328125, "training_acc": 52.5, "val_loss": 457891320.0, "val_acc": 55.0}
{"epoch": 11, "training_loss": 1598683528.75, "training_acc": 47.5, "val_loss": 46417.9150390625, "val_acc": 45.0}
{"epoch": 12, "training_loss": 107740861.0703125, "training_acc": 52.5, "val_loss": 113064980.0, "val_acc": 45.0}
{"epoch": 13, "training_loss": 377099552.0, "training_acc": 47.5, "val_loss": 21955087.5, "val_acc": 45.0}
{"epoch": 14, "training_loss": 71601824.75, "training_acc": 47.5, "val_loss": 1973824.84375, "val_acc": 45.0}
{"epoch": 15, "training_loss": 6237073.3125, "training_acc": 55.0, "val_loss": 1463843.28125, "val_acc": 55.0}
{"epoch": 16, "training_loss": 8603882.5, "training_acc": 42.5, "val_loss": 473608.046875, "val_acc": 55.0}
{"epoch": 17, "training_loss": 1761601.21875, "training_acc": 55.0, "val_loss": 975897.5, "val_acc": 55.0}
{"epoch": 18, "training_loss": 3385115.6875, "training_acc": 52.5, "val_loss": 282120.13671875, "val_acc": 55.0}
{"epoch": 19, "training_loss": 916976.47265625, "training_acc": 55.0, "val_loss": 29251.2890625, "val_acc": 55.0}
{"epoch": 20, "training_loss": 136129.91796875, "training_acc": 50.0, "val_loss": 8357.623291015625, "val_acc": 55.0}
{"epoch": 21, "training_loss": 110884.17578125, "training_acc": 53.75, "val_loss": 10864.7216796875, "val_acc": 55.0}
{"epoch": 22, "training_loss": 145269.1171875, "training_acc": 48.75, "val_loss": 45784.658203125, "val_acc": 55.0}
{"epoch": 23, "training_loss": 173916.65234375, "training_acc": 50.0, "val_loss": 105329.384765625, "val_acc": 55.0}
{"epoch": 24, "training_loss": 405183.75, "training_acc": 52.5, "val_loss": 63792.5439453125, "val_acc": 45.0}
{"epoch": 25, "training_loss": 204433.3203125, "training_acc": 47.5, "val_loss": 51233.0810546875, "val_acc": 55.0}
{"epoch": 26, "training_loss": 201260.21484375, "training_acc": 52.5, "val_loss": 31033.09814453125, "val_acc": 55.0}
{"epoch": 27, "training_loss": 116515.60546875, "training_acc": 52.5, "val_loss": 20176.875, "val_acc": 45.0}
{"epoch": 28, "training_loss": 1034540.30859375, "training_acc": 42.5, "val_loss": 25180.72021484375, "val_acc": 45.0}
{"epoch": 29, "training_loss": 120211.96484375, "training_acc": 47.5, "val_loss": 72712.265625, "val_acc": 45.0}
{"epoch": 30, "training_loss": 227721.8388671875, "training_acc": 47.5, "val_loss": 196476.38671875, "val_acc": 45.0}
{"epoch": 31, "training_loss": 650418.31640625, "training_acc": 42.5, "val_loss": 89064.16015625, "val_acc": 45.0}
{"epoch": 32, "training_loss": 303046.01171875, "training_acc": 47.5, "val_loss": 34735.703125, "val_acc": 45.0}
{"epoch": 33, "training_loss": 104986.6650390625, "training_acc": 50.0, "val_loss": 100049.296875, "val_acc": 55.0}
{"epoch": 34, "training_loss": 354443.1259765625, "training_acc": 52.5, "val_loss": 125267.802734375, "val_acc": 45.0}
{"epoch": 35, "training_loss": 519550.90625, "training_acc": 45.0, "val_loss": 53298.6279296875, "val_acc": 45.0}
{"epoch": 36, "training_loss": 163320.0166015625, "training_acc": 52.5, "val_loss": 2358.9012145996094, "val_acc": 45.0}
{"epoch": 37, "training_loss": 15610.8154296875, "training_acc": 45.0, "val_loss": 10293.653564453125, "val_acc": 45.0}
{"epoch": 38, "training_loss": 31522.982299804688, "training_acc": 50.0, "val_loss": 7272.5811767578125, "val_acc": 45.0}
{"epoch": 39, "training_loss": 27512.48291015625, "training_acc": 50.0, "val_loss": 169.46977615356445, "val_acc": 60.0}
{"epoch": 40, "training_loss": 9914.0361328125, "training_acc": 47.5, "val_loss": 1265.441665649414, "val_acc": 45.0}
{"epoch": 41, "training_loss": 20813.45751953125, "training_acc": 45.0, "val_loss": 13239.896240234375, "val_acc": 55.0}
{"epoch": 42, "training_loss": 47827.902099609375, "training_acc": 52.5, "val_loss": 15236.085205078125, "val_acc": 45.0}
{"epoch": 43, "training_loss": 60103.369140625, "training_acc": 47.5, "val_loss": 14249.534912109375, "val_acc": 45.0}
{"epoch": 44, "training_loss": 46990.063232421875, "training_acc": 47.5, "val_loss": 8357.185668945312, "val_acc": 55.0}
{"epoch": 45, "training_loss": 38884.283203125, "training_acc": 52.5, "val_loss": 10572.7099609375, "val_acc": 55.0}
{"epoch": 46, "training_loss": 38325.832275390625, "training_acc": 52.5, "val_loss": 6808.1976318359375, "val_acc": 45.0}
{"epoch": 47, "training_loss": 27880.40234375, "training_acc": 47.5, "val_loss": 7858.0377197265625, "val_acc": 45.0}
{"epoch": 48, "training_loss": 24781.50732421875, "training_acc": 47.5, "val_loss": 4196.347351074219, "val_acc": 55.0}
{"epoch": 49, "training_loss": 20032.14013671875, "training_acc": 52.5, "val_loss": 6243.189697265625, "val_acc": 55.0}
{"epoch": 50, "training_loss": 23823.43505859375, "training_acc": 52.5, "val_loss": 173.3900260925293, "val_acc": 55.0}
{"epoch": 51, "training_loss": 5226.66943359375, "training_acc": 50.0, "val_loss": 6919.549560546875, "val_acc": 45.0}
{"epoch": 52, "training_loss": 23587.0576171875, "training_acc": 47.5, "val_loss": 3025.1025390625, "val_acc": 55.0}
{"epoch": 53, "training_loss": 12845.521728515625, "training_acc": 52.5, "val_loss": 2065.4409790039062, "val_acc": 55.0}
{"epoch": 54, "training_loss": 7405.680969238281, "training_acc": 52.5, "val_loss": 1148.863754272461, "val_acc": 45.0}
{"epoch": 55, "training_loss": 3373.650115966797, "training_acc": 50.0, "val_loss": 1460.6999206542969, "val_acc": 55.0}
{"epoch": 56, "training_loss": 5957.818908691406, "training_acc": 52.5, "val_loss": 291.2748146057129, "val_acc": 55.0}
{"epoch": 57, "training_loss": 2438.9527587890625, "training_acc": 52.5, "val_loss": 2744.541015625, "val_acc": 45.0}
{"epoch": 58, "training_loss": 8880.378784179688, "training_acc": 47.5, "val_loss": 3036.1026000976562, "val_acc": 55.0}
{"epoch": 59, "training_loss": 12243.9521484375, "training_acc": 52.5, "val_loss": 1362.7249145507812, "val_acc": 55.0}
{"epoch": 60, "training_loss": 4539.291038513184, "training_acc": 56.25, "val_loss": 801.864013671875, "val_acc": 45.0}
{"epoch": 61, "training_loss": 2524.715606689453, "training_acc": 52.5, "val_loss": 720.792236328125, "val_acc": 45.0}
{"epoch": 62, "training_loss": 2077.333957672119, "training_acc": 51.25, "val_loss": 656.4883422851562, "val_acc": 55.0}
{"epoch": 63, "training_loss": 2710.7708740234375, "training_acc": 52.5, "val_loss": 446.9486618041992, "val_acc": 45.0}
{"epoch": 64, "training_loss": 1570.1751403808594, "training_acc": 47.5, "val_loss": 414.3746566772461, "val_acc": 55.0}
{"epoch": 65, "training_loss": 1762.9223327636719, "training_acc": 52.5, "val_loss": 457.88475036621094, "val_acc": 45.0}
{"epoch": 66, "training_loss": 1585.3617401123047, "training_acc": 47.5, "val_loss": 302.67065048217773, "val_acc": 55.0}
