"main_optuna_fix_3.py --pretrained_path None --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3 --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 55.33080863952637, "training_acc": 50.0, "val_loss": 13.829537630081177, "val_acc": 55.0}
{"epoch": 1, "training_loss": 55.3892707824707, "training_acc": 52.5, "val_loss": 13.828197717666626, "val_acc": 55.0}
{"epoch": 2, "training_loss": 55.35311317443848, "training_acc": 52.5, "val_loss": 13.824386596679688, "val_acc": 55.0}
{"epoch": 3, "training_loss": 55.38252353668213, "training_acc": 52.5, "val_loss": 13.819507360458374, "val_acc": 55.0}
{"epoch": 4, "training_loss": 55.33754348754883, "training_acc": 52.5, "val_loss": 13.815263509750366, "val_acc": 55.0}
{"epoch": 5, "training_loss": 55.356008529663086, "training_acc": 52.5, "val_loss": 13.812135457992554, "val_acc": 55.0}
{"epoch": 6, "training_loss": 55.3607292175293, "training_acc": 52.5, "val_loss": 13.809009790420532, "val_acc": 55.0}
{"epoch": 7, "training_loss": 55.34977054595947, "training_acc": 52.5, "val_loss": 13.804360628128052, "val_acc": 55.0}
{"epoch": 8, "training_loss": 55.374446868896484, "training_acc": 52.5, "val_loss": 13.80113959312439, "val_acc": 55.0}
{"epoch": 9, "training_loss": 55.3351936340332, "training_acc": 52.5, "val_loss": 13.799383640289307, "val_acc": 55.0}
{"epoch": 10, "training_loss": 55.347787857055664, "training_acc": 52.5, "val_loss": 13.798348903656006, "val_acc": 55.0}
{"epoch": 11, "training_loss": 55.327242851257324, "training_acc": 52.5, "val_loss": 13.797050714492798, "val_acc": 55.0}
{"epoch": 12, "training_loss": 55.37129211425781, "training_acc": 52.5, "val_loss": 13.795974254608154, "val_acc": 55.0}
{"epoch": 13, "training_loss": 55.3196907043457, "training_acc": 52.5, "val_loss": 13.795162439346313, "val_acc": 55.0}
{"epoch": 14, "training_loss": 55.33280944824219, "training_acc": 52.5, "val_loss": 13.794403076171875, "val_acc": 55.0}
{"epoch": 15, "training_loss": 55.302106857299805, "training_acc": 52.5, "val_loss": 13.79269003868103, "val_acc": 55.0}
{"epoch": 16, "training_loss": 55.336429595947266, "training_acc": 52.5, "val_loss": 13.789969682693481, "val_acc": 55.0}
{"epoch": 17, "training_loss": 55.35605239868164, "training_acc": 52.5, "val_loss": 13.787633180618286, "val_acc": 55.0}
{"epoch": 18, "training_loss": 55.311434745788574, "training_acc": 52.5, "val_loss": 13.786330223083496, "val_acc": 55.0}
{"epoch": 19, "training_loss": 55.34640979766846, "training_acc": 52.5, "val_loss": 13.785649538040161, "val_acc": 55.0}
{"epoch": 20, "training_loss": 55.33052635192871, "training_acc": 52.5, "val_loss": 13.78498911857605, "val_acc": 55.0}
{"epoch": 21, "training_loss": 55.311872482299805, "training_acc": 52.5, "val_loss": 13.783529996871948, "val_acc": 55.0}
{"epoch": 22, "training_loss": 55.27915859222412, "training_acc": 52.5, "val_loss": 13.781756162643433, "val_acc": 55.0}
{"epoch": 23, "training_loss": 55.302406311035156, "training_acc": 52.5, "val_loss": 13.779865503311157, "val_acc": 55.0}
{"epoch": 24, "training_loss": 55.27531814575195, "training_acc": 52.5, "val_loss": 13.777992725372314, "val_acc": 55.0}
{"epoch": 25, "training_loss": 55.300485610961914, "training_acc": 52.5, "val_loss": 13.775614500045776, "val_acc": 55.0}
{"epoch": 26, "training_loss": 55.266422271728516, "training_acc": 52.5, "val_loss": 13.773603439331055, "val_acc": 55.0}
{"epoch": 27, "training_loss": 55.329925537109375, "training_acc": 52.5, "val_loss": 13.77158522605896, "val_acc": 55.0}
{"epoch": 28, "training_loss": 55.318485260009766, "training_acc": 52.5, "val_loss": 13.770875930786133, "val_acc": 55.0}
{"epoch": 29, "training_loss": 55.34440612792969, "training_acc": 52.5, "val_loss": 13.770755529403687, "val_acc": 55.0}
{"epoch": 30, "training_loss": 55.30191421508789, "training_acc": 52.5, "val_loss": 13.77013087272644, "val_acc": 55.0}
{"epoch": 31, "training_loss": 55.337175369262695, "training_acc": 52.5, "val_loss": 13.769582509994507, "val_acc": 55.0}
{"epoch": 32, "training_loss": 55.22377967834473, "training_acc": 52.5, "val_loss": 13.769655227661133, "val_acc": 55.0}
{"epoch": 33, "training_loss": 55.31361675262451, "training_acc": 52.5, "val_loss": 13.770897388458252, "val_acc": 55.0}
{"epoch": 34, "training_loss": 55.30831336975098, "training_acc": 52.5, "val_loss": 13.773090839385986, "val_acc": 55.0}
{"epoch": 35, "training_loss": 55.270368576049805, "training_acc": 52.5, "val_loss": 13.774963617324829, "val_acc": 55.0}
{"epoch": 36, "training_loss": 55.24235725402832, "training_acc": 52.5, "val_loss": 13.77665400505066, "val_acc": 55.0}
{"epoch": 37, "training_loss": 55.331379890441895, "training_acc": 52.5, "val_loss": 13.778740167617798, "val_acc": 55.0}
{"epoch": 38, "training_loss": 55.31226348876953, "training_acc": 52.5, "val_loss": 13.780614137649536, "val_acc": 55.0}
{"epoch": 39, "training_loss": 55.31001853942871, "training_acc": 52.5, "val_loss": 13.781181573867798, "val_acc": 55.0}
{"epoch": 40, "training_loss": 55.26504898071289, "training_acc": 52.5, "val_loss": 13.781970739364624, "val_acc": 55.0}
{"epoch": 41, "training_loss": 55.318949699401855, "training_acc": 52.5, "val_loss": 13.783575296401978, "val_acc": 55.0}
{"epoch": 42, "training_loss": 55.31338882446289, "training_acc": 52.5, "val_loss": 13.785179853439331, "val_acc": 55.0}
{"epoch": 43, "training_loss": 55.34411334991455, "training_acc": 52.5, "val_loss": 13.786498308181763, "val_acc": 55.0}
{"epoch": 44, "training_loss": 55.26292610168457, "training_acc": 52.5, "val_loss": 13.788210153579712, "val_acc": 55.0}
{"epoch": 45, "training_loss": 55.29779815673828, "training_acc": 52.5, "val_loss": 13.790571689605713, "val_acc": 55.0}
{"epoch": 46, "training_loss": 55.325897216796875, "training_acc": 52.5, "val_loss": 13.792476654052734, "val_acc": 55.0}
{"epoch": 47, "training_loss": 55.31183910369873, "training_acc": 52.5, "val_loss": 13.794161081314087, "val_acc": 55.0}
{"epoch": 48, "training_loss": 55.28456687927246, "training_acc": 52.5, "val_loss": 13.794430494308472, "val_acc": 55.0}
{"epoch": 49, "training_loss": 55.278079986572266, "training_acc": 52.5, "val_loss": 13.79401445388794, "val_acc": 55.0}
{"epoch": 50, "training_loss": 55.283267974853516, "training_acc": 52.5, "val_loss": 13.793714046478271, "val_acc": 55.0}
{"epoch": 51, "training_loss": 55.2576789855957, "training_acc": 52.5, "val_loss": 13.793003559112549, "val_acc": 55.0}
