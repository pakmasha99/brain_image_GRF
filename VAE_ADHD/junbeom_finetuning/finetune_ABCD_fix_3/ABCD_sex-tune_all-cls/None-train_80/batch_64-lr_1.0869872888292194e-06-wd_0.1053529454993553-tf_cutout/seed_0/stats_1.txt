"main_optuna_fix_3.py --pretrained_path None --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3 --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 55.34492301940918, "training_acc": 53.75, "val_loss": 13.875864744186401, "val_acc": 50.0}
{"epoch": 1, "training_loss": 55.26783752441406, "training_acc": 53.75, "val_loss": 13.876248598098755, "val_acc": 50.0}
{"epoch": 2, "training_loss": 55.267374992370605, "training_acc": 53.75, "val_loss": 13.877989053726196, "val_acc": 50.0}
{"epoch": 3, "training_loss": 55.21339988708496, "training_acc": 53.75, "val_loss": 13.879965543746948, "val_acc": 50.0}
{"epoch": 4, "training_loss": 55.22026824951172, "training_acc": 53.75, "val_loss": 13.881391286849976, "val_acc": 50.0}
{"epoch": 5, "training_loss": 55.29206943511963, "training_acc": 53.75, "val_loss": 13.882627487182617, "val_acc": 50.0}
{"epoch": 6, "training_loss": 55.238226890563965, "training_acc": 53.75, "val_loss": 13.884093761444092, "val_acc": 50.0}
{"epoch": 7, "training_loss": 55.2300910949707, "training_acc": 53.75, "val_loss": 13.88562798500061, "val_acc": 50.0}
{"epoch": 8, "training_loss": 55.262943267822266, "training_acc": 53.75, "val_loss": 13.887162208557129, "val_acc": 50.0}
{"epoch": 9, "training_loss": 55.20895004272461, "training_acc": 53.75, "val_loss": 13.88819694519043, "val_acc": 50.0}
{"epoch": 10, "training_loss": 55.22933769226074, "training_acc": 53.75, "val_loss": 13.888765573501587, "val_acc": 50.0}
{"epoch": 11, "training_loss": 55.21490669250488, "training_acc": 53.75, "val_loss": 13.889806270599365, "val_acc": 50.0}
{"epoch": 12, "training_loss": 55.22753715515137, "training_acc": 53.75, "val_loss": 13.891090154647827, "val_acc": 50.0}
{"epoch": 13, "training_loss": 55.239715576171875, "training_acc": 53.75, "val_loss": 13.892878293991089, "val_acc": 50.0}
{"epoch": 14, "training_loss": 55.188167572021484, "training_acc": 53.75, "val_loss": 13.894685506820679, "val_acc": 50.0}
{"epoch": 15, "training_loss": 55.16142177581787, "training_acc": 53.75, "val_loss": 13.897494077682495, "val_acc": 50.0}
{"epoch": 16, "training_loss": 55.25654983520508, "training_acc": 53.75, "val_loss": 13.900734186172485, "val_acc": 50.0}
{"epoch": 17, "training_loss": 55.22885513305664, "training_acc": 53.75, "val_loss": 13.903331756591797, "val_acc": 50.0}
{"epoch": 18, "training_loss": 55.16750431060791, "training_acc": 53.75, "val_loss": 13.904945850372314, "val_acc": 50.0}
{"epoch": 19, "training_loss": 55.19831466674805, "training_acc": 53.75, "val_loss": 13.905891180038452, "val_acc": 50.0}
{"epoch": 20, "training_loss": 55.14678764343262, "training_acc": 53.75, "val_loss": 13.905285596847534, "val_acc": 50.0}
{"epoch": 21, "training_loss": 55.189693450927734, "training_acc": 53.75, "val_loss": 13.904824256896973, "val_acc": 50.0}
{"epoch": 22, "training_loss": 55.13956642150879, "training_acc": 53.75, "val_loss": 13.905231952667236, "val_acc": 50.0}
{"epoch": 23, "training_loss": 55.07443428039551, "training_acc": 53.75, "val_loss": 13.906846046447754, "val_acc": 50.0}
{"epoch": 24, "training_loss": 55.16961479187012, "training_acc": 53.75, "val_loss": 13.90957236289978, "val_acc": 50.0}
{"epoch": 25, "training_loss": 55.18172550201416, "training_acc": 53.75, "val_loss": 13.912986516952515, "val_acc": 50.0}
{"epoch": 26, "training_loss": 55.198055267333984, "training_acc": 53.75, "val_loss": 13.916093111038208, "val_acc": 50.0}
{"epoch": 27, "training_loss": 55.193434715270996, "training_acc": 53.75, "val_loss": 13.919222354888916, "val_acc": 50.0}
{"epoch": 28, "training_loss": 55.126118659973145, "training_acc": 53.75, "val_loss": 13.921147584915161, "val_acc": 50.0}
{"epoch": 29, "training_loss": 55.16637706756592, "training_acc": 53.75, "val_loss": 13.921563625335693, "val_acc": 50.0}
{"epoch": 30, "training_loss": 55.12433910369873, "training_acc": 53.75, "val_loss": 13.92231822013855, "val_acc": 50.0}
{"epoch": 31, "training_loss": 55.16994285583496, "training_acc": 53.75, "val_loss": 13.923368453979492, "val_acc": 50.0}
{"epoch": 32, "training_loss": 55.120460510253906, "training_acc": 53.75, "val_loss": 13.923705816268921, "val_acc": 50.0}
{"epoch": 33, "training_loss": 55.1481819152832, "training_acc": 53.75, "val_loss": 13.923535346984863, "val_acc": 50.0}
{"epoch": 34, "training_loss": 55.272592544555664, "training_acc": 53.75, "val_loss": 13.923227787017822, "val_acc": 50.0}
{"epoch": 35, "training_loss": 55.160752296447754, "training_acc": 53.75, "val_loss": 13.922604322433472, "val_acc": 50.0}
{"epoch": 36, "training_loss": 55.143653869628906, "training_acc": 53.75, "val_loss": 13.92018437385559, "val_acc": 50.0}
{"epoch": 37, "training_loss": 55.18553352355957, "training_acc": 53.75, "val_loss": 13.916805982589722, "val_acc": 50.0}
{"epoch": 38, "training_loss": 55.14348888397217, "training_acc": 53.75, "val_loss": 13.913697004318237, "val_acc": 50.0}
{"epoch": 39, "training_loss": 55.1678466796875, "training_acc": 53.75, "val_loss": 13.911179304122925, "val_acc": 50.0}
{"epoch": 40, "training_loss": 55.15284824371338, "training_acc": 53.75, "val_loss": 13.909461498260498, "val_acc": 50.0}
{"epoch": 41, "training_loss": 55.120574951171875, "training_acc": 53.75, "val_loss": 13.907079696655273, "val_acc": 50.0}
{"epoch": 42, "training_loss": 55.14849853515625, "training_acc": 53.75, "val_loss": 13.904342651367188, "val_acc": 50.0}
