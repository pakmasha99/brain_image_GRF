"main_optuna_fix_3.py --pretrained_path None --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3 --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 154.92734909057617, "training_acc": 50.0, "val_loss": 67405.9375, "val_acc": 55.0}
{"epoch": 1, "training_loss": 242500.9715576172, "training_acc": 45.0, "val_loss": 114.87137794494629, "val_acc": 45.0}
{"epoch": 2, "training_loss": 380.629940032959, "training_acc": 47.5, "val_loss": 16.35825753211975, "val_acc": 45.0}
{"epoch": 3, "training_loss": 61.641639709472656, "training_acc": 50.0, "val_loss": 15.042284727096558, "val_acc": 55.0}
{"epoch": 4, "training_loss": 66.87752151489258, "training_acc": 52.5, "val_loss": 14.235167503356934, "val_acc": 55.0}
{"epoch": 5, "training_loss": 58.612990379333496, "training_acc": 52.5, "val_loss": 14.208639860153198, "val_acc": 55.0}
{"epoch": 6, "training_loss": 56.66746711730957, "training_acc": 47.5, "val_loss": 39.300994873046875, "val_acc": 55.0}
{"epoch": 7, "training_loss": 143.54868030548096, "training_acc": 52.5, "val_loss": 13.818691968917847, "val_acc": 55.0}
{"epoch": 8, "training_loss": 55.09177780151367, "training_acc": 57.5, "val_loss": 25.57288408279419, "val_acc": 45.0}
{"epoch": 9, "training_loss": 91.50469207763672, "training_acc": 47.5, "val_loss": 14.361170530319214, "val_acc": 55.0}
{"epoch": 10, "training_loss": 56.28545951843262, "training_acc": 50.0, "val_loss": 13.972806930541992, "val_acc": 55.0}
{"epoch": 11, "training_loss": 56.945719718933105, "training_acc": 52.5, "val_loss": 13.805721998214722, "val_acc": 55.0}
{"epoch": 12, "training_loss": 55.70454216003418, "training_acc": 52.5, "val_loss": 14.470992088317871, "val_acc": 55.0}
{"epoch": 13, "training_loss": 57.0491943359375, "training_acc": 47.5, "val_loss": 13.782017230987549, "val_acc": 55.0}
{"epoch": 14, "training_loss": 55.54100036621094, "training_acc": 52.5, "val_loss": 14.210238456726074, "val_acc": 55.0}
{"epoch": 15, "training_loss": 56.43030548095703, "training_acc": 47.5, "val_loss": 14.085979461669922, "val_acc": 55.0}
{"epoch": 16, "training_loss": 57.36538887023926, "training_acc": 52.5, "val_loss": 14.373247623443604, "val_acc": 55.0}
{"epoch": 17, "training_loss": 58.280630111694336, "training_acc": 52.5, "val_loss": 13.774452209472656, "val_acc": 55.0}
{"epoch": 18, "training_loss": 55.468048095703125, "training_acc": 52.5, "val_loss": 13.965181112289429, "val_acc": 55.0}
{"epoch": 19, "training_loss": 55.68906593322754, "training_acc": 47.5, "val_loss": 14.02692437171936, "val_acc": 55.0}
{"epoch": 20, "training_loss": 55.8311185836792, "training_acc": 47.5, "val_loss": 13.905941247940063, "val_acc": 55.0}
{"epoch": 21, "training_loss": 55.489816665649414, "training_acc": 50.0, "val_loss": 13.808130025863647, "val_acc": 55.0}
{"epoch": 22, "training_loss": 55.330406188964844, "training_acc": 52.5, "val_loss": 13.766069412231445, "val_acc": 55.0}
{"epoch": 23, "training_loss": 55.38081741333008, "training_acc": 52.5, "val_loss": 13.762527704238892, "val_acc": 55.0}
{"epoch": 24, "training_loss": 55.547057151794434, "training_acc": 52.5, "val_loss": 13.763132095336914, "val_acc": 55.0}
