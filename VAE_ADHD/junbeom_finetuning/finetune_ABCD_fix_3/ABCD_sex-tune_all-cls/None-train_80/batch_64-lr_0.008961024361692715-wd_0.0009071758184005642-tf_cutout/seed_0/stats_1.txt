"main_optuna_fix_3.py --pretrained_path None --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3 --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 331.76651763916016, "training_acc": 53.75, "val_loss": 20999127040.0, "val_acc": 50.0}
{"epoch": 1, "training_loss": 65921828412.5, "training_acc": 46.25, "val_loss": 28922247.5, "val_acc": 50.0}
{"epoch": 2, "training_loss": 96706040.65625, "training_acc": 46.25, "val_loss": 12282.293701171875, "val_acc": 50.0}
{"epoch": 3, "training_loss": 43797.8203125, "training_acc": 46.25, "val_loss": 5289.874267578125, "val_acc": 50.0}
{"epoch": 4, "training_loss": 15037.883749008179, "training_acc": 48.75, "val_loss": 1221.195068359375, "val_acc": 50.0}
{"epoch": 5, "training_loss": 54907.687744140625, "training_acc": 48.75, "val_loss": 6992.705078125, "val_acc": 50.0}
{"epoch": 6, "training_loss": 21119.81219482422, "training_acc": 53.75, "val_loss": 1654.59228515625, "val_acc": 50.0}
{"epoch": 7, "training_loss": 6760.738525390625, "training_acc": 46.25, "val_loss": 470.9421920776367, "val_acc": 50.0}
{"epoch": 8, "training_loss": 1924.1085815429688, "training_acc": 46.25, "val_loss": 103.3021068572998, "val_acc": 50.0}
{"epoch": 9, "training_loss": 542.8157653808594, "training_acc": 56.25, "val_loss": 133.52459907531738, "val_acc": 50.0}
{"epoch": 10, "training_loss": 509.4527015686035, "training_acc": 48.75, "val_loss": 89.22525405883789, "val_acc": 50.0}
{"epoch": 11, "training_loss": 1452.3656005859375, "training_acc": 51.25, "val_loss": 34.41059112548828, "val_acc": 50.0}
{"epoch": 12, "training_loss": 604.7208862304688, "training_acc": 48.75, "val_loss": 374.39239501953125, "val_acc": 50.0}
{"epoch": 13, "training_loss": 1253.8504638671875, "training_acc": 53.75, "val_loss": 34.71314191818237, "val_acc": 50.0}
{"epoch": 14, "training_loss": 211.78841400146484, "training_acc": 46.25, "val_loss": 117.07330703735352, "val_acc": 50.0}
{"epoch": 15, "training_loss": 429.2981414794922, "training_acc": 48.75, "val_loss": 54.45679187774658, "val_acc": 50.0}
{"epoch": 16, "training_loss": 201.57047653198242, "training_acc": 48.75, "val_loss": 40.30064105987549, "val_acc": 50.0}
{"epoch": 17, "training_loss": 128.12018203735352, "training_acc": 53.75, "val_loss": 73.84667873382568, "val_acc": 50.0}
{"epoch": 18, "training_loss": 268.5229892730713, "training_acc": 46.25, "val_loss": 26.459534168243408, "val_acc": 50.0}
{"epoch": 19, "training_loss": 89.70598983764648, "training_acc": 53.75, "val_loss": 29.47434425354004, "val_acc": 50.0}
{"epoch": 20, "training_loss": 114.58953285217285, "training_acc": 47.5, "val_loss": 15.330677032470703, "val_acc": 50.0}
{"epoch": 21, "training_loss": 60.89128494262695, "training_acc": 51.25, "val_loss": 14.229592084884644, "val_acc": 50.0}
{"epoch": 22, "training_loss": 74.86803817749023, "training_acc": 48.75, "val_loss": 56.9530725479126, "val_acc": 50.0}
{"epoch": 23, "training_loss": 184.69988250732422, "training_acc": 53.75, "val_loss": 22.445759773254395, "val_acc": 50.0}
