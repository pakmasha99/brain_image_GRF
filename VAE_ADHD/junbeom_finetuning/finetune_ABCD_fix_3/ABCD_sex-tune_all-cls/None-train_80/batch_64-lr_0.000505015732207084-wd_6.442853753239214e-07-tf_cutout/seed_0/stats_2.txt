"main_optuna_fix_3.py --pretrained_path None --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3 --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 64.8628158569336, "training_acc": 48.75, "val_loss": 15.01548171043396, "val_acc": 55.0}
{"epoch": 1, "training_loss": 104.67950820922852, "training_acc": 45.0, "val_loss": 15.058988332748413, "val_acc": 45.0}
{"epoch": 2, "training_loss": 58.367427825927734, "training_acc": 47.5, "val_loss": 13.929866552352905, "val_acc": 55.0}
{"epoch": 3, "training_loss": 55.49924659729004, "training_acc": 50.0, "val_loss": 13.781728744506836, "val_acc": 55.0}
{"epoch": 4, "training_loss": 55.527061462402344, "training_acc": 52.5, "val_loss": 13.785823583602905, "val_acc": 55.0}
{"epoch": 5, "training_loss": 55.35844612121582, "training_acc": 52.5, "val_loss": 14.041271209716797, "val_acc": 55.0}
{"epoch": 6, "training_loss": 56.628684997558594, "training_acc": 47.5, "val_loss": 13.808059692382812, "val_acc": 55.0}
{"epoch": 7, "training_loss": 55.75023651123047, "training_acc": 52.5, "val_loss": 14.049803018569946, "val_acc": 55.0}
{"epoch": 8, "training_loss": 56.543169021606445, "training_acc": 52.5, "val_loss": 13.792022466659546, "val_acc": 55.0}
{"epoch": 9, "training_loss": 55.17991352081299, "training_acc": 55.0, "val_loss": 14.007635116577148, "val_acc": 55.0}
{"epoch": 10, "training_loss": 55.87915229797363, "training_acc": 47.5, "val_loss": 14.020284414291382, "val_acc": 55.0}
{"epoch": 11, "training_loss": 55.76279067993164, "training_acc": 47.5, "val_loss": 13.867372274398804, "val_acc": 55.0}
{"epoch": 12, "training_loss": 55.45038318634033, "training_acc": 51.25, "val_loss": 13.791162967681885, "val_acc": 55.0}
{"epoch": 13, "training_loss": 55.39004325866699, "training_acc": 52.5, "val_loss": 13.788394927978516, "val_acc": 55.0}
{"epoch": 14, "training_loss": 55.39587593078613, "training_acc": 52.5, "val_loss": 13.795195817947388, "val_acc": 55.0}
{"epoch": 15, "training_loss": 55.51181602478027, "training_acc": 52.5, "val_loss": 13.800464868545532, "val_acc": 55.0}
{"epoch": 16, "training_loss": 55.31613349914551, "training_acc": 52.5, "val_loss": 13.783191442489624, "val_acc": 55.0}
{"epoch": 17, "training_loss": 55.51572608947754, "training_acc": 52.5, "val_loss": 13.788948059082031, "val_acc": 55.0}
{"epoch": 18, "training_loss": 55.504173278808594, "training_acc": 52.5, "val_loss": 13.781909942626953, "val_acc": 55.0}
{"epoch": 19, "training_loss": 55.350772857666016, "training_acc": 52.5, "val_loss": 13.797271251678467, "val_acc": 55.0}
{"epoch": 20, "training_loss": 55.36823081970215, "training_acc": 52.5, "val_loss": 13.82386565208435, "val_acc": 55.0}
{"epoch": 21, "training_loss": 55.37917137145996, "training_acc": 52.5, "val_loss": 13.835108280181885, "val_acc": 55.0}
{"epoch": 22, "training_loss": 55.39068031311035, "training_acc": 52.5, "val_loss": 13.830519914627075, "val_acc": 55.0}
{"epoch": 23, "training_loss": 55.376437187194824, "training_acc": 52.5, "val_loss": 13.817188739776611, "val_acc": 55.0}
{"epoch": 24, "training_loss": 55.345208168029785, "training_acc": 52.5, "val_loss": 13.797520399093628, "val_acc": 55.0}
{"epoch": 25, "training_loss": 55.33556365966797, "training_acc": 52.5, "val_loss": 13.778735399246216, "val_acc": 55.0}
{"epoch": 26, "training_loss": 55.32748222351074, "training_acc": 52.5, "val_loss": 13.769868612289429, "val_acc": 55.0}
{"epoch": 27, "training_loss": 55.404775619506836, "training_acc": 52.5, "val_loss": 13.773659467697144, "val_acc": 55.0}
{"epoch": 28, "training_loss": 55.60630798339844, "training_acc": 52.5, "val_loss": 13.774477243423462, "val_acc": 55.0}
{"epoch": 29, "training_loss": 55.53804588317871, "training_acc": 52.5, "val_loss": 13.768415451049805, "val_acc": 55.0}
