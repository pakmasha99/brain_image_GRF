"main_optuna_fix_3.py --pretrained_path None --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3 --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 60.97940444946289, "training_acc": 53.75, "val_loss": 212571.5234375, "val_acc": 50.0}
{"epoch": 1, "training_loss": 654402.8165435791, "training_acc": 46.25, "val_loss": 16.33339762687683, "val_acc": 50.0}
{"epoch": 2, "training_loss": 61.38864707946777, "training_acc": 53.75, "val_loss": 202.59492874145508, "val_acc": 50.0}
{"epoch": 3, "training_loss": 737.3933868408203, "training_acc": 46.25, "val_loss": 29.088170528411865, "val_acc": 50.0}
{"epoch": 4, "training_loss": 97.81838798522949, "training_acc": 53.75, "val_loss": 13.924384117126465, "val_acc": 50.0}
{"epoch": 5, "training_loss": 57.0050163269043, "training_acc": 43.75, "val_loss": 14.416874647140503, "val_acc": 50.0}
{"epoch": 6, "training_loss": 58.15125846862793, "training_acc": 48.75, "val_loss": 14.631507396697998, "val_acc": 50.0}
{"epoch": 7, "training_loss": 55.53538513183594, "training_acc": 56.25, "val_loss": 15.877741575241089, "val_acc": 50.0}
{"epoch": 8, "training_loss": 65.31204223632812, "training_acc": 46.25, "val_loss": 14.76107120513916, "val_acc": 50.0}
{"epoch": 9, "training_loss": 56.60037612915039, "training_acc": 53.75, "val_loss": 13.902891874313354, "val_acc": 50.0}
{"epoch": 10, "training_loss": 55.87691307067871, "training_acc": 46.25, "val_loss": 14.700422286987305, "val_acc": 50.0}
{"epoch": 11, "training_loss": 57.32547664642334, "training_acc": 53.75, "val_loss": 13.908699750900269, "val_acc": 50.0}
{"epoch": 12, "training_loss": 55.1992301940918, "training_acc": 53.75, "val_loss": 14.188412427902222, "val_acc": 50.0}
{"epoch": 13, "training_loss": 55.76210117340088, "training_acc": 53.75, "val_loss": 14.483579397201538, "val_acc": 50.0}
{"epoch": 14, "training_loss": 56.72048759460449, "training_acc": 53.75, "val_loss": 14.56785798072815, "val_acc": 50.0}
{"epoch": 15, "training_loss": 56.60204219818115, "training_acc": 53.75, "val_loss": 14.278334379196167, "val_acc": 50.0}
{"epoch": 16, "training_loss": 56.006221771240234, "training_acc": 53.75, "val_loss": 14.019765853881836, "val_acc": 50.0}
{"epoch": 17, "training_loss": 55.29360008239746, "training_acc": 53.75, "val_loss": 13.902391195297241, "val_acc": 50.0}
{"epoch": 18, "training_loss": 55.35908031463623, "training_acc": 53.75, "val_loss": 13.892204761505127, "val_acc": 50.0}
{"epoch": 19, "training_loss": 55.71745681762695, "training_acc": 53.75, "val_loss": 13.886215686798096, "val_acc": 50.0}
{"epoch": 20, "training_loss": 55.214083671569824, "training_acc": 53.75, "val_loss": 13.86459231376648, "val_acc": 50.0}
{"epoch": 21, "training_loss": 55.40985298156738, "training_acc": 53.75, "val_loss": 13.865230083465576, "val_acc": 50.0}
{"epoch": 22, "training_loss": 55.31258964538574, "training_acc": 53.75, "val_loss": 13.913806676864624, "val_acc": 50.0}
{"epoch": 23, "training_loss": 55.30626106262207, "training_acc": 53.75, "val_loss": 14.050806760787964, "val_acc": 50.0}
{"epoch": 24, "training_loss": 55.35654830932617, "training_acc": 53.75, "val_loss": 13.971620798110962, "val_acc": 50.0}
{"epoch": 25, "training_loss": 55.21762752532959, "training_acc": 53.75, "val_loss": 13.91069769859314, "val_acc": 50.0}
{"epoch": 26, "training_loss": 55.2280912399292, "training_acc": 53.75, "val_loss": 13.890413045883179, "val_acc": 50.0}
{"epoch": 27, "training_loss": 55.288371086120605, "training_acc": 53.75, "val_loss": 13.913458585739136, "val_acc": 50.0}
{"epoch": 28, "training_loss": 55.31009101867676, "training_acc": 53.75, "val_loss": 13.925607204437256, "val_acc": 50.0}
{"epoch": 29, "training_loss": 55.23570156097412, "training_acc": 53.75, "val_loss": 13.894122838973999, "val_acc": 50.0}
{"epoch": 30, "training_loss": 55.234718322753906, "training_acc": 53.75, "val_loss": 13.902288675308228, "val_acc": 50.0}
{"epoch": 31, "training_loss": 55.25343418121338, "training_acc": 53.75, "val_loss": 13.9195716381073, "val_acc": 50.0}
{"epoch": 32, "training_loss": 55.21158409118652, "training_acc": 53.75, "val_loss": 13.91260027885437, "val_acc": 50.0}
{"epoch": 33, "training_loss": 55.26308250427246, "training_acc": 53.75, "val_loss": 13.918358087539673, "val_acc": 50.0}
{"epoch": 34, "training_loss": 55.22060298919678, "training_acc": 53.75, "val_loss": 13.985961675643921, "val_acc": 50.0}
{"epoch": 35, "training_loss": 55.4019832611084, "training_acc": 53.75, "val_loss": 13.989378213882446, "val_acc": 50.0}
{"epoch": 36, "training_loss": 55.245110511779785, "training_acc": 53.75, "val_loss": 13.909952640533447, "val_acc": 50.0}
{"epoch": 37, "training_loss": 55.19380569458008, "training_acc": 53.75, "val_loss": 13.867990970611572, "val_acc": 50.0}
{"epoch": 38, "training_loss": 55.36715602874756, "training_acc": 53.75, "val_loss": 13.865675926208496, "val_acc": 50.0}
{"epoch": 39, "training_loss": 55.30919361114502, "training_acc": 53.75, "val_loss": 13.992222547531128, "val_acc": 50.0}
{"epoch": 40, "training_loss": 55.27807426452637, "training_acc": 53.75, "val_loss": 14.111673831939697, "val_acc": 50.0}
{"epoch": 41, "training_loss": 55.61380958557129, "training_acc": 53.75, "val_loss": 13.87285590171814, "val_acc": 50.0}
{"epoch": 42, "training_loss": 55.39937973022461, "training_acc": 51.25, "val_loss": 13.867462873458862, "val_acc": 50.0}
{"epoch": 43, "training_loss": 55.590789794921875, "training_acc": 46.25, "val_loss": 13.862192630767822, "val_acc": 50.0}
{"epoch": 44, "training_loss": 55.650007247924805, "training_acc": 41.25, "val_loss": 13.865238428115845, "val_acc": 50.0}
{"epoch": 45, "training_loss": 55.369465827941895, "training_acc": 53.75, "val_loss": 13.868736028671265, "val_acc": 50.0}
{"epoch": 46, "training_loss": 55.26460838317871, "training_acc": 53.75, "val_loss": 14.037050008773804, "val_acc": 50.0}
{"epoch": 47, "training_loss": 55.35381889343262, "training_acc": 53.75, "val_loss": 14.165579080581665, "val_acc": 50.0}
{"epoch": 48, "training_loss": 55.59562873840332, "training_acc": 53.75, "val_loss": 13.92479419708252, "val_acc": 50.0}
{"epoch": 49, "training_loss": 55.26044273376465, "training_acc": 53.75, "val_loss": 13.904237747192383, "val_acc": 50.0}
{"epoch": 50, "training_loss": 55.22445297241211, "training_acc": 53.75, "val_loss": 13.959379196166992, "val_acc": 50.0}
