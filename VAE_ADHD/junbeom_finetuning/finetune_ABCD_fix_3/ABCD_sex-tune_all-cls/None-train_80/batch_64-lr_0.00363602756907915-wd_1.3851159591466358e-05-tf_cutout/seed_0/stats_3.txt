"main_optuna_fix_3.py --pretrained_path None --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3 --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 136.47672271728516, "training_acc": 52.5, "val_loss": 1576.4585876464844, "val_acc": 45.0}
{"epoch": 1, "training_loss": 4842.410308837891, "training_acc": 55.0, "val_loss": 32.86301374435425, "val_acc": 55.0}
{"epoch": 2, "training_loss": 124.10661697387695, "training_acc": 52.5, "val_loss": 14.103845357894897, "val_acc": 55.0}
{"epoch": 3, "training_loss": 56.10916519165039, "training_acc": 47.5, "val_loss": 13.824611902236938, "val_acc": 55.0}
{"epoch": 4, "training_loss": 55.21455097198486, "training_acc": 52.5, "val_loss": 22.111799716949463, "val_acc": 55.0}
{"epoch": 5, "training_loss": 86.39363288879395, "training_acc": 50.0, "val_loss": 15.170488357543945, "val_acc": 45.0}
{"epoch": 6, "training_loss": 59.17880725860596, "training_acc": 47.5, "val_loss": 14.148422479629517, "val_acc": 55.0}
{"epoch": 7, "training_loss": 56.1339168548584, "training_acc": 47.5, "val_loss": 13.850640058517456, "val_acc": 55.0}
{"epoch": 8, "training_loss": 55.793283462524414, "training_acc": 52.5, "val_loss": 13.80998969078064, "val_acc": 55.0}
{"epoch": 9, "training_loss": 55.36031723022461, "training_acc": 52.5, "val_loss": 13.907997608184814, "val_acc": 55.0}
{"epoch": 10, "training_loss": 55.57635498046875, "training_acc": 47.5, "val_loss": 13.79619836807251, "val_acc": 55.0}
{"epoch": 11, "training_loss": 55.242130279541016, "training_acc": 52.5, "val_loss": 13.793721199035645, "val_acc": 55.0}
{"epoch": 12, "training_loss": 55.98215293884277, "training_acc": 52.5, "val_loss": 13.765543699264526, "val_acc": 55.0}
{"epoch": 13, "training_loss": 55.55856704711914, "training_acc": 52.5, "val_loss": 13.8129723072052, "val_acc": 55.0}
{"epoch": 14, "training_loss": 55.37050437927246, "training_acc": 52.5, "val_loss": 13.86371374130249, "val_acc": 55.0}
{"epoch": 15, "training_loss": 55.68607139587402, "training_acc": 30.0, "val_loss": 13.834764957427979, "val_acc": 55.0}
{"epoch": 16, "training_loss": 55.31439685821533, "training_acc": 52.5, "val_loss": 13.764311075210571, "val_acc": 55.0}
{"epoch": 17, "training_loss": 55.84286022186279, "training_acc": 52.5, "val_loss": 13.762645721435547, "val_acc": 55.0}
{"epoch": 18, "training_loss": 55.26844596862793, "training_acc": 52.5, "val_loss": 14.133809804916382, "val_acc": 55.0}
{"epoch": 19, "training_loss": 56.20839881896973, "training_acc": 47.5, "val_loss": 13.933357000350952, "val_acc": 55.0}
{"epoch": 20, "training_loss": 55.566232681274414, "training_acc": 47.5, "val_loss": 13.811006546020508, "val_acc": 55.0}
{"epoch": 21, "training_loss": 55.39295196533203, "training_acc": 52.5, "val_loss": 13.77253532409668, "val_acc": 55.0}
{"epoch": 22, "training_loss": 55.35854530334473, "training_acc": 52.5, "val_loss": 13.76694917678833, "val_acc": 55.0}
{"epoch": 23, "training_loss": 55.38856601715088, "training_acc": 52.5, "val_loss": 13.764622211456299, "val_acc": 55.0}
{"epoch": 24, "training_loss": 55.4391393661499, "training_acc": 52.5, "val_loss": 13.76317024230957, "val_acc": 55.0}
{"epoch": 25, "training_loss": 55.437782287597656, "training_acc": 52.5, "val_loss": 13.77711296081543, "val_acc": 55.0}
{"epoch": 26, "training_loss": 55.64428520202637, "training_acc": 52.5, "val_loss": 13.814090490341187, "val_acc": 55.0}
{"epoch": 27, "training_loss": 55.93381690979004, "training_acc": 52.5, "val_loss": 13.796648979187012, "val_acc": 55.0}
{"epoch": 28, "training_loss": 55.7480354309082, "training_acc": 52.5, "val_loss": 13.76384973526001, "val_acc": 55.0}
{"epoch": 29, "training_loss": 55.50685501098633, "training_acc": 52.5, "val_loss": 13.7734854221344, "val_acc": 55.0}
