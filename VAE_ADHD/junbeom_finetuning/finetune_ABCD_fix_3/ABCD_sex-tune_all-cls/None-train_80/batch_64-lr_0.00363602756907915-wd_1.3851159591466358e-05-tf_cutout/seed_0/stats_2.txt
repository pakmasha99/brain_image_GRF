"main_optuna_fix_3.py --pretrained_path None --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3 --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 155.1034927368164, "training_acc": 51.25, "val_loss": 61637.7294921875, "val_acc": 55.0}
{"epoch": 1, "training_loss": 221839.33840942383, "training_acc": 45.0, "val_loss": 190.0612449645996, "val_acc": 45.0}
{"epoch": 2, "training_loss": 607.6349067687988, "training_acc": 47.5, "val_loss": 25.653984546661377, "val_acc": 55.0}
{"epoch": 3, "training_loss": 101.19871711730957, "training_acc": 50.0, "val_loss": 31.942336559295654, "val_acc": 55.0}
{"epoch": 4, "training_loss": 116.0403413772583, "training_acc": 52.5, "val_loss": 25.288689136505127, "val_acc": 45.0}
{"epoch": 5, "training_loss": 88.66574668884277, "training_acc": 47.5, "val_loss": 13.915901184082031, "val_acc": 55.0}
{"epoch": 6, "training_loss": 61.30063438415527, "training_acc": 42.5, "val_loss": 16.304123401641846, "val_acc": 55.0}
{"epoch": 7, "training_loss": 66.06642723083496, "training_acc": 52.5, "val_loss": 13.829469680786133, "val_acc": 55.0}
{"epoch": 8, "training_loss": 56.574005126953125, "training_acc": 52.5, "val_loss": 21.496975421905518, "val_acc": 45.0}
{"epoch": 9, "training_loss": 79.93349266052246, "training_acc": 45.0, "val_loss": 13.770188093185425, "val_acc": 55.0}
{"epoch": 10, "training_loss": 55.71659851074219, "training_acc": 50.0, "val_loss": 14.384645223617554, "val_acc": 55.0}
{"epoch": 11, "training_loss": 59.076398849487305, "training_acc": 52.5, "val_loss": 13.790085315704346, "val_acc": 55.0}
{"epoch": 12, "training_loss": 55.633362770080566, "training_acc": 52.5, "val_loss": 14.34876799583435, "val_acc": 55.0}
{"epoch": 13, "training_loss": 56.667235374450684, "training_acc": 47.5, "val_loss": 13.763490915298462, "val_acc": 55.0}
{"epoch": 14, "training_loss": 55.46396446228027, "training_acc": 52.5, "val_loss": 13.819644451141357, "val_acc": 55.0}
{"epoch": 15, "training_loss": 56.01756286621094, "training_acc": 45.0, "val_loss": 13.776792287826538, "val_acc": 55.0}
{"epoch": 16, "training_loss": 55.43385124206543, "training_acc": 52.5, "val_loss": 14.263873100280762, "val_acc": 55.0}
{"epoch": 17, "training_loss": 58.116764068603516, "training_acc": 52.5, "val_loss": 13.773965835571289, "val_acc": 55.0}
{"epoch": 18, "training_loss": 55.46948051452637, "training_acc": 52.5, "val_loss": 14.005430936813354, "val_acc": 55.0}
{"epoch": 19, "training_loss": 55.824331283569336, "training_acc": 47.5, "val_loss": 13.98327112197876, "val_acc": 55.0}
{"epoch": 20, "training_loss": 55.67355251312256, "training_acc": 47.5, "val_loss": 13.809765577316284, "val_acc": 55.0}
{"epoch": 21, "training_loss": 55.301307678222656, "training_acc": 52.5, "val_loss": 13.774150609970093, "val_acc": 55.0}
{"epoch": 22, "training_loss": 55.60722255706787, "training_acc": 52.5, "val_loss": 13.768764734268188, "val_acc": 55.0}
{"epoch": 23, "training_loss": 55.58036994934082, "training_acc": 52.5, "val_loss": 13.773398399353027, "val_acc": 55.0}
{"epoch": 24, "training_loss": 55.726789474487305, "training_acc": 45.0, "val_loss": 13.762587308883667, "val_acc": 55.0}
{"epoch": 25, "training_loss": 55.4439697265625, "training_acc": 52.5, "val_loss": 13.79717230796814, "val_acc": 55.0}
{"epoch": 26, "training_loss": 55.936710357666016, "training_acc": 52.5, "val_loss": 13.7835693359375, "val_acc": 55.0}
{"epoch": 27, "training_loss": 55.71122455596924, "training_acc": 52.5, "val_loss": 13.775800466537476, "val_acc": 55.0}
{"epoch": 28, "training_loss": 55.60165596008301, "training_acc": 52.5, "val_loss": 13.7662672996521, "val_acc": 55.0}
{"epoch": 29, "training_loss": 55.434736251831055, "training_acc": 52.5, "val_loss": 13.823665380477905, "val_acc": 55.0}
{"epoch": 30, "training_loss": 55.40021800994873, "training_acc": 52.5, "val_loss": 13.836644887924194, "val_acc": 55.0}
{"epoch": 31, "training_loss": 55.47945785522461, "training_acc": 52.5, "val_loss": 13.837083578109741, "val_acc": 55.0}
{"epoch": 32, "training_loss": 55.38833045959473, "training_acc": 52.5, "val_loss": 13.886806964874268, "val_acc": 55.0}
{"epoch": 33, "training_loss": 55.501394271850586, "training_acc": 47.5, "val_loss": 13.904632329940796, "val_acc": 55.0}
{"epoch": 34, "training_loss": 55.53402614593506, "training_acc": 47.5, "val_loss": 13.847582340240479, "val_acc": 55.0}
{"epoch": 35, "training_loss": 55.500200271606445, "training_acc": 52.5, "val_loss": 13.798966407775879, "val_acc": 55.0}
{"epoch": 36, "training_loss": 55.34767723083496, "training_acc": 52.5, "val_loss": 13.804651498794556, "val_acc": 55.0}
{"epoch": 37, "training_loss": 55.36979103088379, "training_acc": 52.5, "val_loss": 13.822344541549683, "val_acc": 55.0}
{"epoch": 38, "training_loss": 55.43504333496094, "training_acc": 52.5, "val_loss": 13.831608295440674, "val_acc": 55.0}
{"epoch": 39, "training_loss": 55.380889892578125, "training_acc": 52.5, "val_loss": 13.80055546760559, "val_acc": 55.0}
{"epoch": 40, "training_loss": 55.430795669555664, "training_acc": 52.5, "val_loss": 13.790329694747925, "val_acc": 55.0}
{"epoch": 41, "training_loss": 55.343443870544434, "training_acc": 52.5, "val_loss": 13.812408447265625, "val_acc": 55.0}
{"epoch": 42, "training_loss": 55.41752815246582, "training_acc": 52.5, "val_loss": 13.835396766662598, "val_acc": 55.0}
