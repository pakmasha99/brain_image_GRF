"main_optuna_fix_3.py --pretrained_path None --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3 --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 57.18739318847656, "training_acc": 53.75, "val_loss": 269.24869537353516, "val_acc": 50.0}
{"epoch": 1, "training_loss": 846.9760322570801, "training_acc": 46.25, "val_loss": 23.248302936553955, "val_acc": 50.0}
{"epoch": 2, "training_loss": 80.2045841217041, "training_acc": 53.75, "val_loss": 13.872097730636597, "val_acc": 50.0}
{"epoch": 3, "training_loss": 55.77468013763428, "training_acc": 46.25, "val_loss": 13.853777647018433, "val_acc": 50.0}
{"epoch": 4, "training_loss": 56.07293128967285, "training_acc": 53.75, "val_loss": 14.487377405166626, "val_acc": 50.0}
{"epoch": 5, "training_loss": 59.25593376159668, "training_acc": 46.25, "val_loss": 13.874826431274414, "val_acc": 50.0}
{"epoch": 6, "training_loss": 55.65367889404297, "training_acc": 48.75, "val_loss": 13.882925510406494, "val_acc": 50.0}
{"epoch": 7, "training_loss": 55.50191116333008, "training_acc": 53.75, "val_loss": 13.926340341567993, "val_acc": 50.0}
{"epoch": 8, "training_loss": 55.22995948791504, "training_acc": 53.75, "val_loss": 13.867957592010498, "val_acc": 50.0}
{"epoch": 9, "training_loss": 55.30110836029053, "training_acc": 53.75, "val_loss": 13.859986066818237, "val_acc": 50.0}
{"epoch": 10, "training_loss": 55.382638931274414, "training_acc": 53.75, "val_loss": 13.864688873291016, "val_acc": 50.0}
{"epoch": 11, "training_loss": 55.29249954223633, "training_acc": 53.75, "val_loss": 13.913280963897705, "val_acc": 50.0}
{"epoch": 12, "training_loss": 55.158090591430664, "training_acc": 53.75, "val_loss": 14.145549535751343, "val_acc": 50.0}
{"epoch": 13, "training_loss": 55.65345764160156, "training_acc": 53.75, "val_loss": 14.410651922225952, "val_acc": 50.0}
{"epoch": 14, "training_loss": 56.55002784729004, "training_acc": 53.75, "val_loss": 14.355552196502686, "val_acc": 50.0}
{"epoch": 15, "training_loss": 56.158103942871094, "training_acc": 53.75, "val_loss": 14.245436191558838, "val_acc": 50.0}
{"epoch": 16, "training_loss": 55.920955657958984, "training_acc": 53.75, "val_loss": 14.065455198287964, "val_acc": 50.0}
{"epoch": 17, "training_loss": 55.39975452423096, "training_acc": 53.75, "val_loss": 13.963466882705688, "val_acc": 50.0}
{"epoch": 18, "training_loss": 55.3247652053833, "training_acc": 53.75, "val_loss": 13.909673690795898, "val_acc": 50.0}
{"epoch": 19, "training_loss": 55.229493141174316, "training_acc": 53.75, "val_loss": 13.885061740875244, "val_acc": 50.0}
{"epoch": 20, "training_loss": 55.221784591674805, "training_acc": 53.75, "val_loss": 13.8656747341156, "val_acc": 50.0}
{"epoch": 21, "training_loss": 55.38646125793457, "training_acc": 53.75, "val_loss": 13.862446546554565, "val_acc": 50.0}
{"epoch": 22, "training_loss": 55.41171836853027, "training_acc": 53.75, "val_loss": 13.8648521900177, "val_acc": 50.0}
{"epoch": 23, "training_loss": 55.36844253540039, "training_acc": 53.75, "val_loss": 13.872156143188477, "val_acc": 50.0}
{"epoch": 24, "training_loss": 55.30922603607178, "training_acc": 53.75, "val_loss": 13.880817890167236, "val_acc": 50.0}
{"epoch": 25, "training_loss": 55.271474838256836, "training_acc": 53.75, "val_loss": 13.889329433441162, "val_acc": 50.0}
{"epoch": 26, "training_loss": 55.24469566345215, "training_acc": 53.75, "val_loss": 13.898934125900269, "val_acc": 50.0}
{"epoch": 27, "training_loss": 55.231842041015625, "training_acc": 53.75, "val_loss": 13.91750454902649, "val_acc": 50.0}
{"epoch": 28, "training_loss": 55.266231536865234, "training_acc": 53.75, "val_loss": 13.93730640411377, "val_acc": 50.0}
{"epoch": 29, "training_loss": 55.231523513793945, "training_acc": 53.75, "val_loss": 13.938230276107788, "val_acc": 50.0}
