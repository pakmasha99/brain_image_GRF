"main_optuna_fix_3.py --pretrained_path None --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3 --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 87.44530487060547, "training_acc": 51.25, "val_loss": 108.78766059875488, "val_acc": 55.0}
{"epoch": 1, "training_loss": 472.08433532714844, "training_acc": 45.0, "val_loss": 19.74463701248169, "val_acc": 45.0}
{"epoch": 2, "training_loss": 72.09407711029053, "training_acc": 47.5, "val_loss": 14.087320566177368, "val_acc": 55.0}
{"epoch": 3, "training_loss": 55.850908279418945, "training_acc": 47.5, "val_loss": 13.77379059791565, "val_acc": 55.0}
{"epoch": 4, "training_loss": 55.680816650390625, "training_acc": 52.5, "val_loss": 13.77475619316101, "val_acc": 55.0}
{"epoch": 5, "training_loss": 55.388553619384766, "training_acc": 52.5, "val_loss": 14.007667303085327, "val_acc": 55.0}
{"epoch": 6, "training_loss": 55.73331260681152, "training_acc": 47.5, "val_loss": 13.89316201210022, "val_acc": 55.0}
{"epoch": 7, "training_loss": 56.28967475891113, "training_acc": 52.5, "val_loss": 13.876155614852905, "val_acc": 55.0}
{"epoch": 8, "training_loss": 55.852373123168945, "training_acc": 52.5, "val_loss": 13.79257082939148, "val_acc": 55.0}
{"epoch": 9, "training_loss": 55.23322677612305, "training_acc": 52.5, "val_loss": 13.964757919311523, "val_acc": 55.0}
{"epoch": 10, "training_loss": 55.757816314697266, "training_acc": 47.5, "val_loss": 13.97594690322876, "val_acc": 55.0}
{"epoch": 11, "training_loss": 55.654008865356445, "training_acc": 47.5, "val_loss": 13.86899471282959, "val_acc": 55.0}
{"epoch": 12, "training_loss": 55.465707778930664, "training_acc": 47.5, "val_loss": 13.813356161117554, "val_acc": 55.0}
{"epoch": 13, "training_loss": 55.369964599609375, "training_acc": 52.5, "val_loss": 13.791898488998413, "val_acc": 55.0}
{"epoch": 14, "training_loss": 55.34999084472656, "training_acc": 52.5, "val_loss": 13.786628246307373, "val_acc": 55.0}
{"epoch": 15, "training_loss": 55.38252830505371, "training_acc": 52.5, "val_loss": 13.777941465377808, "val_acc": 55.0}
{"epoch": 16, "training_loss": 55.318443298339844, "training_acc": 52.5, "val_loss": 13.779926300048828, "val_acc": 55.0}
{"epoch": 17, "training_loss": 55.79193305969238, "training_acc": 52.5, "val_loss": 13.782821893692017, "val_acc": 55.0}
{"epoch": 18, "training_loss": 55.53647994995117, "training_acc": 52.5, "val_loss": 13.775337934494019, "val_acc": 55.0}
{"epoch": 19, "training_loss": 55.320624351501465, "training_acc": 52.5, "val_loss": 13.806456327438354, "val_acc": 55.0}
{"epoch": 20, "training_loss": 55.37973976135254, "training_acc": 52.5, "val_loss": 13.835266828536987, "val_acc": 55.0}
{"epoch": 21, "training_loss": 55.40558433532715, "training_acc": 52.5, "val_loss": 13.842157125473022, "val_acc": 55.0}
{"epoch": 22, "training_loss": 55.40893268585205, "training_acc": 52.5, "val_loss": 13.83547067642212, "val_acc": 55.0}
{"epoch": 23, "training_loss": 55.39554977416992, "training_acc": 52.5, "val_loss": 13.823566436767578, "val_acc": 55.0}
{"epoch": 24, "training_loss": 55.36428451538086, "training_acc": 52.5, "val_loss": 13.806450366973877, "val_acc": 55.0}
{"epoch": 25, "training_loss": 55.34658432006836, "training_acc": 52.5, "val_loss": 13.785914182662964, "val_acc": 55.0}
{"epoch": 26, "training_loss": 55.319217681884766, "training_acc": 52.5, "val_loss": 13.770506381988525, "val_acc": 55.0}
{"epoch": 27, "training_loss": 55.37520694732666, "training_acc": 52.5, "val_loss": 13.769749402999878, "val_acc": 55.0}
{"epoch": 28, "training_loss": 55.643259048461914, "training_acc": 52.5, "val_loss": 13.76677393913269, "val_acc": 55.0}
