"main_optuna_fix_3.py --pretrained_path None --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3 --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 384.9883804321289, "training_acc": 52.5, "val_loss": 3273208320.0, "val_acc": 45.0}
{"epoch": 1, "training_loss": 9132336538.375, "training_acc": 55.0, "val_loss": 482984.53125, "val_acc": 45.0}
{"epoch": 2, "training_loss": 48211339.25, "training_acc": 50.0, "val_loss": 417755.1171875, "val_acc": 55.0}
{"epoch": 3, "training_loss": 1417283.5859375, "training_acc": 52.5, "val_loss": 59222.880859375, "val_acc": 45.0}
{"epoch": 4, "training_loss": 256273.78125, "training_acc": 52.5, "val_loss": 13943.284912109375, "val_acc": 45.0}
{"epoch": 5, "training_loss": 254931.35546875, "training_acc": 50.0, "val_loss": 80377.9638671875, "val_acc": 45.0}
{"epoch": 6, "training_loss": 287495.48828125, "training_acc": 50.0, "val_loss": 28031.91162109375, "val_acc": 45.0}
{"epoch": 7, "training_loss": 86657.91149902344, "training_acc": 47.5, "val_loss": 36255.54443359375, "val_acc": 45.0}
{"epoch": 8, "training_loss": 160612.6953125, "training_acc": 42.5, "val_loss": 11624.598388671875, "val_acc": 45.0}
{"epoch": 9, "training_loss": 35579.54928588867, "training_acc": 47.5, "val_loss": 16511.461181640625, "val_acc": 55.0}
{"epoch": 10, "training_loss": 58028.44598388672, "training_acc": 52.5, "val_loss": 13976.844482421875, "val_acc": 45.0}
{"epoch": 11, "training_loss": 40938.72424316406, "training_acc": 52.5, "val_loss": 6100.86181640625, "val_acc": 45.0}
{"epoch": 12, "training_loss": 23758.96484375, "training_acc": 45.0, "val_loss": 5238.3251953125, "val_acc": 45.0}
{"epoch": 13, "training_loss": 27955.3173828125, "training_acc": 50.0, "val_loss": 5278.3782958984375, "val_acc": 45.0}
{"epoch": 14, "training_loss": 25515.4873046875, "training_acc": 45.0, "val_loss": 4853.445739746094, "val_acc": 45.0}
{"epoch": 15, "training_loss": 14300.030395507812, "training_acc": 47.5, "val_loss": 4514.508972167969, "val_acc": 55.0}
{"epoch": 16, "training_loss": 17005.105056762695, "training_acc": 52.5, "val_loss": 2382.5669860839844, "val_acc": 45.0}
{"epoch": 17, "training_loss": 7777.497344970703, "training_acc": 45.0, "val_loss": 1003.4932708740234, "val_acc": 45.0}
{"epoch": 18, "training_loss": 4484.2822265625, "training_acc": 45.0, "val_loss": 32273.72802734375, "val_acc": 45.0}
{"epoch": 19, "training_loss": 102804.81701660156, "training_acc": 47.5, "val_loss": 15405.155029296875, "val_acc": 55.0}
{"epoch": 20, "training_loss": 58363.86962890625, "training_acc": 52.5, "val_loss": 62430.107421875, "val_acc": 45.0}
{"epoch": 21, "training_loss": 190291.8740234375, "training_acc": 47.5, "val_loss": 1261.2224578857422, "val_acc": 45.0}
{"epoch": 22, "training_loss": 6121.533203125, "training_acc": 50.0, "val_loss": 292.8309440612793, "val_acc": 55.0}
{"epoch": 23, "training_loss": 2222.20458984375, "training_acc": 50.0, "val_loss": 2292.8176879882812, "val_acc": 55.0}
{"epoch": 24, "training_loss": 10716.48095703125, "training_acc": 45.0, "val_loss": 544.0952301025391, "val_acc": 45.0}
{"epoch": 25, "training_loss": 3204.8131103515625, "training_acc": 55.0, "val_loss": 1697.7830505371094, "val_acc": 55.0}
{"epoch": 26, "training_loss": 9290.54736328125, "training_acc": 47.5, "val_loss": 899.0016174316406, "val_acc": 55.0}
{"epoch": 27, "training_loss": 3165.377731323242, "training_acc": 52.5, "val_loss": 3604.8980712890625, "val_acc": 45.0}
{"epoch": 28, "training_loss": 12050.957885742188, "training_acc": 42.5, "val_loss": 75.30461311340332, "val_acc": 45.0}
{"epoch": 29, "training_loss": 272.59552001953125, "training_acc": 50.0, "val_loss": 31.21424436569214, "val_acc": 45.0}
{"epoch": 30, "training_loss": 160.61798477172852, "training_acc": 51.25, "val_loss": 213.29774856567383, "val_acc": 45.0}
{"epoch": 31, "training_loss": 730.1098327636719, "training_acc": 42.5, "val_loss": 850.6043243408203, "val_acc": 45.0}
{"epoch": 32, "training_loss": 2593.3236894607544, "training_acc": 52.5, "val_loss": 198.289794921875, "val_acc": 55.0}
{"epoch": 33, "training_loss": 748.8795166015625, "training_acc": 52.5, "val_loss": 148.11787605285645, "val_acc": 45.0}
{"epoch": 34, "training_loss": 457.74653244018555, "training_acc": 50.0, "val_loss": 214.5843505859375, "val_acc": 45.0}
{"epoch": 35, "training_loss": 707.1588859558105, "training_acc": 47.5, "val_loss": 390.25962829589844, "val_acc": 55.0}
{"epoch": 36, "training_loss": 1539.4508666992188, "training_acc": 52.5, "val_loss": 36.37434482574463, "val_acc": 55.0}
{"epoch": 37, "training_loss": 265.41016387939453, "training_acc": 52.5, "val_loss": 209.82616424560547, "val_acc": 45.0}
{"epoch": 38, "training_loss": 723.7813186645508, "training_acc": 47.5, "val_loss": 20.515224933624268, "val_acc": 55.0}
{"epoch": 39, "training_loss": 127.0611343383789, "training_acc": 53.75, "val_loss": 51.80247783660889, "val_acc": 55.0}
{"epoch": 40, "training_loss": 187.45626163482666, "training_acc": 51.25, "val_loss": 47.8298282623291, "val_acc": 45.0}
{"epoch": 41, "training_loss": 172.0997657775879, "training_acc": 47.5, "val_loss": 17.20383048057556, "val_acc": 55.0}
{"epoch": 42, "training_loss": 75.28799438476562, "training_acc": 51.25, "val_loss": 19.956120252609253, "val_acc": 45.0}
{"epoch": 43, "training_loss": 70.51968765258789, "training_acc": 48.75, "val_loss": 14.580248594284058, "val_acc": 55.0}
{"epoch": 44, "training_loss": 64.64757442474365, "training_acc": 51.25, "val_loss": 14.851857423782349, "val_acc": 60.0}
{"epoch": 45, "training_loss": 58.22430992126465, "training_acc": 48.75, "val_loss": 15.051528215408325, "val_acc": 50.0}
{"epoch": 46, "training_loss": 63.465271949768066, "training_acc": 46.25, "val_loss": 15.075886249542236, "val_acc": 55.0}
{"epoch": 47, "training_loss": 62.50048065185547, "training_acc": 48.75, "val_loss": 14.859369993209839, "val_acc": 60.0}
{"epoch": 48, "training_loss": 59.43388366699219, "training_acc": 45.0, "val_loss": 14.032096862792969, "val_acc": 55.0}
{"epoch": 49, "training_loss": 57.256038665771484, "training_acc": 55.0, "val_loss": 13.629766702651978, "val_acc": 55.0}
{"epoch": 50, "training_loss": 57.45908737182617, "training_acc": 51.25, "val_loss": 16.709688901901245, "val_acc": 45.0}
{"epoch": 51, "training_loss": 61.53557205200195, "training_acc": 48.75, "val_loss": 14.50717568397522, "val_acc": 55.0}
{"epoch": 52, "training_loss": 63.1791296005249, "training_acc": 52.5, "val_loss": 15.720347166061401, "val_acc": 55.0}
{"epoch": 53, "training_loss": 65.32782363891602, "training_acc": 52.5, "val_loss": 15.796980857849121, "val_acc": 45.0}
{"epoch": 54, "training_loss": 59.740756034851074, "training_acc": 48.75, "val_loss": 14.4111168384552, "val_acc": 55.0}
{"epoch": 55, "training_loss": 54.88359451293945, "training_acc": 51.25, "val_loss": 17.307742834091187, "val_acc": 55.0}
{"epoch": 56, "training_loss": 74.31482601165771, "training_acc": 52.5, "val_loss": 13.689801692962646, "val_acc": 55.0}
{"epoch": 57, "training_loss": 57.16769981384277, "training_acc": 55.0, "val_loss": 17.61132836341858, "val_acc": 45.0}
{"epoch": 58, "training_loss": 66.94296455383301, "training_acc": 47.5, "val_loss": 13.934962749481201, "val_acc": 55.0}
{"epoch": 59, "training_loss": 60.538700103759766, "training_acc": 53.75, "val_loss": 15.863301753997803, "val_acc": 55.0}
{"epoch": 60, "training_loss": 62.139902114868164, "training_acc": 56.25, "val_loss": 16.42695665359497, "val_acc": 45.0}
{"epoch": 61, "training_loss": 66.28435134887695, "training_acc": 47.5, "val_loss": 14.57889199256897, "val_acc": 55.0}
{"epoch": 62, "training_loss": 56.40410041809082, "training_acc": 51.25, "val_loss": 15.59674620628357, "val_acc": 55.0}
{"epoch": 63, "training_loss": 64.56316757202148, "training_acc": 52.5, "val_loss": 13.890948295593262, "val_acc": 55.0}
{"epoch": 64, "training_loss": 58.39816856384277, "training_acc": 47.5, "val_loss": 16.36754274368286, "val_acc": 45.0}
{"epoch": 65, "training_loss": 64.94787788391113, "training_acc": 47.5, "val_loss": 13.68420958518982, "val_acc": 55.0}
{"epoch": 66, "training_loss": 57.866024017333984, "training_acc": 52.5, "val_loss": 13.638911247253418, "val_acc": 55.0}
{"epoch": 67, "training_loss": 54.42728328704834, "training_acc": 55.0, "val_loss": 16.838163137435913, "val_acc": 45.0}
{"epoch": 68, "training_loss": 65.39659118652344, "training_acc": 47.5, "val_loss": 14.1143798828125, "val_acc": 55.0}
{"epoch": 69, "training_loss": 58.47638702392578, "training_acc": 47.5, "val_loss": 13.95969033241272, "val_acc": 55.0}
{"epoch": 70, "training_loss": 56.85388374328613, "training_acc": 50.0, "val_loss": 14.283757209777832, "val_acc": 55.0}
