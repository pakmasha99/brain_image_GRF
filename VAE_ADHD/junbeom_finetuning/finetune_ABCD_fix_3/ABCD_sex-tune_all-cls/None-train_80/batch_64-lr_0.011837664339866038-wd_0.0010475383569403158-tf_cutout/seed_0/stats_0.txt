"main_optuna_fix_3.py --pretrained_path None --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3 --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 80.3559684753418, "training_acc": 53.75, "val_loss": 3.4771962886619136e+17, "val_acc": 50.0}
{"epoch": 1, "training_loss": 1.0642634840129286e+18, "training_acc": 46.25, "val_loss": 33973.50341796875, "val_acc": 50.0}
{"epoch": 2, "training_loss": 410828.046875, "training_acc": 46.25, "val_loss": 48425.8447265625, "val_acc": 50.0}
{"epoch": 3, "training_loss": 165058.96484375, "training_acc": 53.75, "val_loss": 4100.411682128906, "val_acc": 50.0}
{"epoch": 4, "training_loss": 409837.33984375, "training_acc": 53.75, "val_loss": 274692.44140625, "val_acc": 50.0}
{"epoch": 5, "training_loss": 808717.234375, "training_acc": 53.75, "val_loss": 38364.23828125, "val_acc": 50.0}
{"epoch": 6, "training_loss": 158602.0078125, "training_acc": 53.75, "val_loss": 9283.749389648438, "val_acc": 50.0}
{"epoch": 7, "training_loss": 31096.9033203125, "training_acc": 53.75, "val_loss": 24899.40185546875, "val_acc": 50.0}
{"epoch": 8, "training_loss": 209893.2734375, "training_acc": 46.25, "val_loss": 2487.48046875, "val_acc": 50.0}
{"epoch": 9, "training_loss": 8261.839599609375, "training_acc": 53.75, "val_loss": 5669.8004150390625, "val_acc": 50.0}
{"epoch": 10, "training_loss": 20033.748046875, "training_acc": 53.75, "val_loss": 155475.46875, "val_acc": 50.0}
{"epoch": 11, "training_loss": 1831917.65625, "training_acc": 51.25, "val_loss": 30415.78125, "val_acc": 50.0}
{"epoch": 12, "training_loss": 110763.892578125, "training_acc": 46.25, "val_loss": 5510.145263671875, "val_acc": 50.0}
{"epoch": 13, "training_loss": 27761.978515625, "training_acc": 53.75, "val_loss": 147200.537109375, "val_acc": 50.0}
{"epoch": 14, "training_loss": 467234.6328125, "training_acc": 56.25, "val_loss": 23843.82568359375, "val_acc": 50.0}
{"epoch": 15, "training_loss": 193002.8984375, "training_acc": 48.75, "val_loss": 39964.05517578125, "val_acc": 50.0}
{"epoch": 16, "training_loss": 123839.45916748047, "training_acc": 48.75, "val_loss": 22378.046875, "val_acc": 50.0}
{"epoch": 17, "training_loss": 81921.58984375, "training_acc": 53.75, "val_loss": 11017.672119140625, "val_acc": 50.0}
{"epoch": 18, "training_loss": 34546.620056152344, "training_acc": 48.75, "val_loss": 3822.1929931640625, "val_acc": 50.0}
{"epoch": 19, "training_loss": 10253.666931152344, "training_acc": 53.75, "val_loss": 9690.7763671875, "val_acc": 50.0}
{"epoch": 20, "training_loss": 38620.7001953125, "training_acc": 46.25, "val_loss": 9255.822143554688, "val_acc": 50.0}
{"epoch": 21, "training_loss": 28930.80743408203, "training_acc": 48.75, "val_loss": 2915.3955078125, "val_acc": 50.0}
{"epoch": 22, "training_loss": 10113.213439941406, "training_acc": 53.75, "val_loss": 683.2067108154297, "val_acc": 50.0}
{"epoch": 23, "training_loss": 2636.761962890625, "training_acc": 46.25, "val_loss": 1548.4220886230469, "val_acc": 50.0}
{"epoch": 24, "training_loss": 5538.973434448242, "training_acc": 46.25, "val_loss": 1151.0829162597656, "val_acc": 50.0}
{"epoch": 25, "training_loss": 4219.152923583984, "training_acc": 46.25, "val_loss": 432.16896057128906, "val_acc": 50.0}
{"epoch": 26, "training_loss": 1659.2688751220703, "training_acc": 48.75, "val_loss": 13.509759902954102, "val_acc": 45.0}
{"epoch": 27, "training_loss": 172.01881408691406, "training_acc": 52.5, "val_loss": 989.9896240234375, "val_acc": 50.0}
{"epoch": 28, "training_loss": 3706.361083984375, "training_acc": 53.75, "val_loss": 303.44717025756836, "val_acc": 50.0}
{"epoch": 29, "training_loss": 1809.8984985351562, "training_acc": 51.25, "val_loss": 1193.1343078613281, "val_acc": 50.0}
{"epoch": 30, "training_loss": 4326.765319824219, "training_acc": 46.25, "val_loss": 1579.7239685058594, "val_acc": 50.0}
{"epoch": 31, "training_loss": 4937.014343261719, "training_acc": 53.75, "val_loss": 3943.0355834960938, "val_acc": 50.0}
{"epoch": 32, "training_loss": 14093.929077148438, "training_acc": 46.25, "val_loss": 1687.7334594726562, "val_acc": 50.0}
{"epoch": 33, "training_loss": 5930.679504394531, "training_acc": 53.75, "val_loss": 696.4102935791016, "val_acc": 50.0}
{"epoch": 34, "training_loss": 2283.0977935791016, "training_acc": 48.75, "val_loss": 195.39133071899414, "val_acc": 50.0}
{"epoch": 35, "training_loss": 917.47802734375, "training_acc": 43.75, "val_loss": 100.02532958984375, "val_acc": 50.0}
{"epoch": 36, "training_loss": 554.3596801757812, "training_acc": 53.75, "val_loss": 354.28001403808594, "val_acc": 50.0}
{"epoch": 37, "training_loss": 1434.630012512207, "training_acc": 41.25, "val_loss": 36.23915910720825, "val_acc": 50.0}
{"epoch": 38, "training_loss": 303.6902618408203, "training_acc": 53.75, "val_loss": 61.276140213012695, "val_acc": 50.0}
{"epoch": 39, "training_loss": 517.5735473632812, "training_acc": 48.75, "val_loss": 484.7466278076172, "val_acc": 50.0}
{"epoch": 40, "training_loss": 1592.327880859375, "training_acc": 53.75, "val_loss": 250.55810928344727, "val_acc": 50.0}
{"epoch": 41, "training_loss": 1006.4301300048828, "training_acc": 46.25, "val_loss": 261.14959716796875, "val_acc": 50.0}
{"epoch": 42, "training_loss": 817.6059799194336, "training_acc": 53.75, "val_loss": 308.3057975769043, "val_acc": 50.0}
{"epoch": 43, "training_loss": 1246.6661987304688, "training_acc": 46.25, "val_loss": 189.01742935180664, "val_acc": 50.0}
{"epoch": 44, "training_loss": 772.9829406738281, "training_acc": 53.75, "val_loss": 52.90095806121826, "val_acc": 50.0}
{"epoch": 45, "training_loss": 401.7794494628906, "training_acc": 51.25, "val_loss": 315.05847930908203, "val_acc": 50.0}
{"epoch": 46, "training_loss": 1054.0708503723145, "training_acc": 48.75, "val_loss": 421.22364044189453, "val_acc": 50.0}
{"epoch": 47, "training_loss": 1469.7895812988281, "training_acc": 53.75, "val_loss": 70.955491065979, "val_acc": 50.0}
{"epoch": 48, "training_loss": 336.1297912597656, "training_acc": 48.75, "val_loss": 275.6317710876465, "val_acc": 50.0}
{"epoch": 49, "training_loss": 927.4388732910156, "training_acc": 53.75, "val_loss": 107.5602912902832, "val_acc": 50.0}
{"epoch": 50, "training_loss": 464.83841705322266, "training_acc": 45.0, "val_loss": 184.2510223388672, "val_acc": 50.0}
{"epoch": 51, "training_loss": 697.0863647460938, "training_acc": 53.75, "val_loss": 55.018577575683594, "val_acc": 50.0}
{"epoch": 52, "training_loss": 373.61293029785156, "training_acc": 51.25, "val_loss": 283.82740020751953, "val_acc": 50.0}
{"epoch": 53, "training_loss": 1130.950927734375, "training_acc": 46.25, "val_loss": 59.43653106689453, "val_acc": 50.0}
