"main_optuna_fix_3.py --pretrained_path None --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3 --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 57.1391077041626, "training_acc": 53.75, "val_loss": 258.29702377319336, "val_acc": 50.0}
{"epoch": 1, "training_loss": 813.4321117401123, "training_acc": 46.25, "val_loss": 21.35357141494751, "val_acc": 50.0}
{"epoch": 2, "training_loss": 74.73154067993164, "training_acc": 53.75, "val_loss": 13.98989200592041, "val_acc": 50.0}
{"epoch": 3, "training_loss": 56.539934158325195, "training_acc": 46.25, "val_loss": 13.984675407409668, "val_acc": 50.0}
{"epoch": 4, "training_loss": 55.32798671722412, "training_acc": 53.75, "val_loss": 14.621332883834839, "val_acc": 50.0}
{"epoch": 5, "training_loss": 60.211753845214844, "training_acc": 43.75, "val_loss": 13.907322883605957, "val_acc": 50.0}
{"epoch": 6, "training_loss": 55.24734878540039, "training_acc": 53.75, "val_loss": 13.9087975025177, "val_acc": 50.0}
{"epoch": 7, "training_loss": 55.39838218688965, "training_acc": 53.75, "val_loss": 13.882551193237305, "val_acc": 50.0}
{"epoch": 8, "training_loss": 55.23840141296387, "training_acc": 53.75, "val_loss": 13.857473134994507, "val_acc": 50.0}
{"epoch": 9, "training_loss": 55.428778648376465, "training_acc": 53.75, "val_loss": 13.858498334884644, "val_acc": 50.0}
{"epoch": 10, "training_loss": 55.41592502593994, "training_acc": 53.75, "val_loss": 13.868628740310669, "val_acc": 50.0}
{"epoch": 11, "training_loss": 55.23673057556152, "training_acc": 53.75, "val_loss": 13.98287296295166, "val_acc": 50.0}
{"epoch": 12, "training_loss": 55.25955009460449, "training_acc": 53.75, "val_loss": 14.374545812606812, "val_acc": 50.0}
{"epoch": 13, "training_loss": 56.5197639465332, "training_acc": 53.75, "val_loss": 14.143340587615967, "val_acc": 50.0}
{"epoch": 14, "training_loss": 55.834611892700195, "training_acc": 53.75, "val_loss": 14.133772850036621, "val_acc": 50.0}
{"epoch": 15, "training_loss": 55.602736473083496, "training_acc": 53.75, "val_loss": 14.207721948623657, "val_acc": 50.0}
{"epoch": 16, "training_loss": 55.78790283203125, "training_acc": 53.75, "val_loss": 14.147651195526123, "val_acc": 50.0}
{"epoch": 17, "training_loss": 55.582908630371094, "training_acc": 53.75, "val_loss": 14.02452826499939, "val_acc": 50.0}
{"epoch": 18, "training_loss": 55.43007946014404, "training_acc": 53.75, "val_loss": 13.935900926589966, "val_acc": 50.0}
{"epoch": 19, "training_loss": 55.218871116638184, "training_acc": 53.75, "val_loss": 13.895643949508667, "val_acc": 50.0}
{"epoch": 20, "training_loss": 55.19464111328125, "training_acc": 53.75, "val_loss": 13.866595029830933, "val_acc": 50.0}
{"epoch": 21, "training_loss": 55.392242431640625, "training_acc": 53.75, "val_loss": 13.862358331680298, "val_acc": 50.0}
{"epoch": 22, "training_loss": 55.432329177856445, "training_acc": 53.75, "val_loss": 13.86367678642273, "val_acc": 50.0}
{"epoch": 23, "training_loss": 55.38266086578369, "training_acc": 53.75, "val_loss": 13.87115478515625, "val_acc": 50.0}
{"epoch": 24, "training_loss": 55.31463146209717, "training_acc": 53.75, "val_loss": 13.880518674850464, "val_acc": 50.0}
{"epoch": 25, "training_loss": 55.27109909057617, "training_acc": 53.75, "val_loss": 13.890303373336792, "val_acc": 50.0}
{"epoch": 26, "training_loss": 55.24058723449707, "training_acc": 53.75, "val_loss": 13.902157545089722, "val_acc": 50.0}
{"epoch": 27, "training_loss": 55.22953701019287, "training_acc": 53.75, "val_loss": 13.926396369934082, "val_acc": 50.0}
{"epoch": 28, "training_loss": 55.279720306396484, "training_acc": 53.75, "val_loss": 13.948779106140137, "val_acc": 50.0}
{"epoch": 29, "training_loss": 55.236952781677246, "training_acc": 53.75, "val_loss": 13.939127922058105, "val_acc": 50.0}
{"epoch": 30, "training_loss": 55.22854804992676, "training_acc": 53.75, "val_loss": 13.935825824737549, "val_acc": 50.0}
{"epoch": 31, "training_loss": 55.231977462768555, "training_acc": 53.75, "val_loss": 13.931540250778198, "val_acc": 50.0}
{"epoch": 32, "training_loss": 55.21863079071045, "training_acc": 53.75, "val_loss": 13.920706510543823, "val_acc": 50.0}
{"epoch": 33, "training_loss": 55.24137878417969, "training_acc": 53.75, "val_loss": 13.91433835029602, "val_acc": 50.0}
{"epoch": 34, "training_loss": 55.2316951751709, "training_acc": 53.75, "val_loss": 13.921458721160889, "val_acc": 50.0}
{"epoch": 35, "training_loss": 55.24494934082031, "training_acc": 53.75, "val_loss": 13.929077386856079, "val_acc": 50.0}
{"epoch": 36, "training_loss": 55.2202730178833, "training_acc": 53.75, "val_loss": 13.922703266143799, "val_acc": 50.0}
{"epoch": 37, "training_loss": 55.225396156311035, "training_acc": 53.75, "val_loss": 13.908644914627075, "val_acc": 50.0}
{"epoch": 38, "training_loss": 55.234493255615234, "training_acc": 53.75, "val_loss": 13.893316984176636, "val_acc": 50.0}
{"epoch": 39, "training_loss": 55.24975872039795, "training_acc": 53.75, "val_loss": 13.887137174606323, "val_acc": 50.0}
{"epoch": 40, "training_loss": 55.253835678100586, "training_acc": 53.75, "val_loss": 13.886193037033081, "val_acc": 50.0}
{"epoch": 41, "training_loss": 55.267027854919434, "training_acc": 53.75, "val_loss": 13.88509750366211, "val_acc": 50.0}
