"main_optuna_fix_3.py --pretrained_path None --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3 --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 55.37582206726074, "training_acc": 53.75, "val_loss": 13.879278898239136, "val_acc": 50.0}
{"epoch": 1, "training_loss": 56.90425682067871, "training_acc": 46.25, "val_loss": 14.010308980941772, "val_acc": 50.0}
{"epoch": 2, "training_loss": 55.86100196838379, "training_acc": 53.75, "val_loss": 14.576578140258789, "val_acc": 50.0}
{"epoch": 3, "training_loss": 56.56550598144531, "training_acc": 53.75, "val_loss": 13.943593502044678, "val_acc": 50.0}
{"epoch": 4, "training_loss": 55.182329177856445, "training_acc": 53.75, "val_loss": 13.8829505443573, "val_acc": 50.0}
{"epoch": 5, "training_loss": 55.74186134338379, "training_acc": 46.25, "val_loss": 13.93659234046936, "val_acc": 50.0}
{"epoch": 6, "training_loss": 56.15468788146973, "training_acc": 46.25, "val_loss": 13.888696432113647, "val_acc": 50.0}
{"epoch": 7, "training_loss": 55.86371994018555, "training_acc": 46.25, "val_loss": 13.866024017333984, "val_acc": 50.0}
{"epoch": 8, "training_loss": 55.36981391906738, "training_acc": 53.75, "val_loss": 13.889939785003662, "val_acc": 50.0}
{"epoch": 9, "training_loss": 55.26811408996582, "training_acc": 53.75, "val_loss": 13.919910192489624, "val_acc": 50.0}
{"epoch": 10, "training_loss": 55.235572814941406, "training_acc": 53.75, "val_loss": 13.93832802772522, "val_acc": 50.0}
{"epoch": 11, "training_loss": 55.250611305236816, "training_acc": 53.75, "val_loss": 13.966367244720459, "val_acc": 50.0}
{"epoch": 12, "training_loss": 55.24348068237305, "training_acc": 53.75, "val_loss": 14.021304845809937, "val_acc": 50.0}
{"epoch": 13, "training_loss": 55.326069831848145, "training_acc": 53.75, "val_loss": 14.100780487060547, "val_acc": 50.0}
{"epoch": 14, "training_loss": 55.47409915924072, "training_acc": 53.75, "val_loss": 14.233731031417847, "val_acc": 50.0}
{"epoch": 15, "training_loss": 55.782318115234375, "training_acc": 53.75, "val_loss": 14.354404211044312, "val_acc": 50.0}
{"epoch": 16, "training_loss": 56.19280815124512, "training_acc": 53.75, "val_loss": 14.30446982383728, "val_acc": 50.0}
{"epoch": 17, "training_loss": 55.9360933303833, "training_acc": 53.75, "val_loss": 14.142897129058838, "val_acc": 50.0}
{"epoch": 18, "training_loss": 55.605591773986816, "training_acc": 53.75, "val_loss": 13.988484144210815, "val_acc": 50.0}
{"epoch": 19, "training_loss": 55.18514633178711, "training_acc": 53.75, "val_loss": 13.904306888580322, "val_acc": 50.0}
{"epoch": 20, "training_loss": 55.138187408447266, "training_acc": 53.75, "val_loss": 13.870257139205933, "val_acc": 50.0}
{"epoch": 21, "training_loss": 55.47718620300293, "training_acc": 48.75, "val_loss": 13.877426385879517, "val_acc": 50.0}
{"epoch": 22, "training_loss": 55.60489273071289, "training_acc": 46.25, "val_loss": 13.87075662612915, "val_acc": 50.0}
{"epoch": 23, "training_loss": 55.49515151977539, "training_acc": 47.5, "val_loss": 13.867419958114624, "val_acc": 50.0}
{"epoch": 24, "training_loss": 55.36557197570801, "training_acc": 53.75, "val_loss": 13.87458324432373, "val_acc": 50.0}
{"epoch": 25, "training_loss": 55.25804901123047, "training_acc": 53.75, "val_loss": 13.888983726501465, "val_acc": 50.0}
{"epoch": 26, "training_loss": 55.21553421020508, "training_acc": 53.75, "val_loss": 13.90579104423523, "val_acc": 50.0}
{"epoch": 27, "training_loss": 55.24020576477051, "training_acc": 53.75, "val_loss": 13.930469751358032, "val_acc": 50.0}
{"epoch": 28, "training_loss": 55.276001930236816, "training_acc": 53.75, "val_loss": 13.952807188034058, "val_acc": 50.0}
{"epoch": 29, "training_loss": 55.22838592529297, "training_acc": 53.75, "val_loss": 13.9533531665802, "val_acc": 50.0}
{"epoch": 30, "training_loss": 55.213664054870605, "training_acc": 53.75, "val_loss": 13.954106569290161, "val_acc": 50.0}
{"epoch": 31, "training_loss": 55.22578430175781, "training_acc": 53.75, "val_loss": 13.947198390960693, "val_acc": 50.0}
{"epoch": 32, "training_loss": 55.2016658782959, "training_acc": 53.75, "val_loss": 13.929888010025024, "val_acc": 50.0}
{"epoch": 33, "training_loss": 55.228126525878906, "training_acc": 53.75, "val_loss": 13.919397592544556, "val_acc": 50.0}
{"epoch": 34, "training_loss": 55.19951820373535, "training_acc": 53.75, "val_loss": 13.927849531173706, "val_acc": 50.0}
{"epoch": 35, "training_loss": 55.2022647857666, "training_acc": 53.75, "val_loss": 13.937196731567383, "val_acc": 50.0}
{"epoch": 36, "training_loss": 55.16538047790527, "training_acc": 53.75, "val_loss": 13.928693532943726, "val_acc": 50.0}
{"epoch": 37, "training_loss": 55.202263832092285, "training_acc": 53.75, "val_loss": 13.908284902572632, "val_acc": 50.0}
{"epoch": 38, "training_loss": 55.1903018951416, "training_acc": 53.75, "val_loss": 13.888763189315796, "val_acc": 50.0}
{"epoch": 39, "training_loss": 55.26638603210449, "training_acc": 53.75, "val_loss": 13.884767293930054, "val_acc": 50.0}
{"epoch": 40, "training_loss": 55.23920917510986, "training_acc": 53.75, "val_loss": 13.887509107589722, "val_acc": 50.0}
{"epoch": 41, "training_loss": 55.287471771240234, "training_acc": 53.75, "val_loss": 13.890024423599243, "val_acc": 50.0}
{"epoch": 42, "training_loss": 55.2392578125, "training_acc": 53.75, "val_loss": 13.887428045272827, "val_acc": 50.0}
{"epoch": 43, "training_loss": 55.1915397644043, "training_acc": 53.75, "val_loss": 13.894416093826294, "val_acc": 50.0}
