"main_optuna_fix_3.py --pretrained_path None --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3 --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 56.351643562316895, "training_acc": 57.5, "val_loss": 14.141277074813843, "val_acc": 50.0}
{"epoch": 1, "training_loss": 57.3023738861084, "training_acc": 46.25, "val_loss": 13.887537717819214, "val_acc": 50.0}
{"epoch": 2, "training_loss": 55.23354530334473, "training_acc": 53.75, "val_loss": 14.45955753326416, "val_acc": 50.0}
{"epoch": 3, "training_loss": 56.218567848205566, "training_acc": 53.75, "val_loss": 14.195244312286377, "val_acc": 50.0}
{"epoch": 4, "training_loss": 55.468024253845215, "training_acc": 53.75, "val_loss": 13.887721300125122, "val_acc": 50.0}
{"epoch": 5, "training_loss": 55.34892463684082, "training_acc": 51.25, "val_loss": 13.866256475448608, "val_acc": 50.0}
{"epoch": 6, "training_loss": 55.588321685791016, "training_acc": 46.25, "val_loss": 13.860734701156616, "val_acc": 50.0}
{"epoch": 7, "training_loss": 55.44318771362305, "training_acc": 48.75, "val_loss": 13.887319564819336, "val_acc": 50.0}
{"epoch": 8, "training_loss": 55.29128074645996, "training_acc": 53.75, "val_loss": 13.958219289779663, "val_acc": 50.0}
{"epoch": 9, "training_loss": 55.26713466644287, "training_acc": 53.75, "val_loss": 13.970167636871338, "val_acc": 50.0}
{"epoch": 10, "training_loss": 55.23573303222656, "training_acc": 53.75, "val_loss": 13.922770023345947, "val_acc": 50.0}
{"epoch": 11, "training_loss": 55.20854187011719, "training_acc": 53.75, "val_loss": 13.908994197845459, "val_acc": 50.0}
{"epoch": 12, "training_loss": 55.209442138671875, "training_acc": 53.75, "val_loss": 13.921798467636108, "val_acc": 50.0}
{"epoch": 13, "training_loss": 55.195640563964844, "training_acc": 53.75, "val_loss": 13.970993757247925, "val_acc": 50.0}
{"epoch": 14, "training_loss": 55.15534019470215, "training_acc": 53.75, "val_loss": 14.104564189910889, "val_acc": 50.0}
{"epoch": 15, "training_loss": 55.333696365356445, "training_acc": 53.75, "val_loss": 14.306725263595581, "val_acc": 50.0}
{"epoch": 16, "training_loss": 55.924360275268555, "training_acc": 53.75, "val_loss": 14.340389966964722, "val_acc": 50.0}
{"epoch": 17, "training_loss": 55.8641357421875, "training_acc": 53.75, "val_loss": 14.141970872879028, "val_acc": 50.0}
{"epoch": 18, "training_loss": 55.449127197265625, "training_acc": 53.75, "val_loss": 13.946367502212524, "val_acc": 50.0}
{"epoch": 19, "training_loss": 55.08991718292236, "training_acc": 53.75, "val_loss": 13.880002498626709, "val_acc": 50.0}
{"epoch": 20, "training_loss": 55.30536937713623, "training_acc": 53.75, "val_loss": 13.86754035949707, "val_acc": 50.0}
{"epoch": 21, "training_loss": 55.57733154296875, "training_acc": 46.25, "val_loss": 13.867157697677612, "val_acc": 50.0}
{"epoch": 22, "training_loss": 55.541229248046875, "training_acc": 46.25, "val_loss": 13.865302801132202, "val_acc": 50.0}
{"epoch": 23, "training_loss": 55.363990783691406, "training_acc": 65.0, "val_loss": 13.879098892211914, "val_acc": 50.0}
{"epoch": 24, "training_loss": 55.245951652526855, "training_acc": 53.75, "val_loss": 13.919997215270996, "val_acc": 50.0}
{"epoch": 25, "training_loss": 55.189948081970215, "training_acc": 53.75, "val_loss": 13.990417718887329, "val_acc": 50.0}
{"epoch": 26, "training_loss": 55.23714733123779, "training_acc": 53.75, "val_loss": 14.058783054351807, "val_acc": 50.0}
{"epoch": 27, "training_loss": 55.37626838684082, "training_acc": 53.75, "val_loss": 14.089869260787964, "val_acc": 50.0}
{"epoch": 28, "training_loss": 55.429189682006836, "training_acc": 53.75, "val_loss": 14.030758142471313, "val_acc": 50.0}
{"epoch": 29, "training_loss": 55.2942419052124, "training_acc": 53.75, "val_loss": 13.937205076217651, "val_acc": 50.0}
{"epoch": 30, "training_loss": 55.23270606994629, "training_acc": 53.75, "val_loss": 13.905431032180786, "val_acc": 50.0}
{"epoch": 31, "training_loss": 55.216623306274414, "training_acc": 53.75, "val_loss": 13.901827335357666, "val_acc": 50.0}
{"epoch": 32, "training_loss": 55.217529296875, "training_acc": 53.75, "val_loss": 13.900148868560791, "val_acc": 50.0}
{"epoch": 33, "training_loss": 55.21843910217285, "training_acc": 53.75, "val_loss": 13.897327184677124, "val_acc": 50.0}
{"epoch": 34, "training_loss": 55.23534297943115, "training_acc": 53.75, "val_loss": 13.907185792922974, "val_acc": 50.0}
{"epoch": 35, "training_loss": 55.2377815246582, "training_acc": 53.75, "val_loss": 13.909696340560913, "val_acc": 50.0}
{"epoch": 36, "training_loss": 55.16979694366455, "training_acc": 53.75, "val_loss": 13.886831998825073, "val_acc": 50.0}
{"epoch": 37, "training_loss": 55.213608741760254, "training_acc": 53.75, "val_loss": 13.86670470237732, "val_acc": 50.0}
{"epoch": 38, "training_loss": 55.3930139541626, "training_acc": 51.25, "val_loss": 13.864558935165405, "val_acc": 50.0}
{"epoch": 39, "training_loss": 55.51984977722168, "training_acc": 46.25, "val_loss": 13.86607050895691, "val_acc": 50.0}
{"epoch": 40, "training_loss": 55.468523025512695, "training_acc": 48.75, "val_loss": 13.868534564971924, "val_acc": 50.0}
{"epoch": 41, "training_loss": 55.426700592041016, "training_acc": 53.75, "val_loss": 13.874877691268921, "val_acc": 50.0}
{"epoch": 42, "training_loss": 55.32768249511719, "training_acc": 53.75, "val_loss": 13.87865424156189, "val_acc": 50.0}
{"epoch": 43, "training_loss": 55.28676700592041, "training_acc": 53.75, "val_loss": 13.888086080551147, "val_acc": 50.0}
{"epoch": 44, "training_loss": 55.26465129852295, "training_acc": 53.75, "val_loss": 13.905963897705078, "val_acc": 50.0}
{"epoch": 45, "training_loss": 55.22688007354736, "training_acc": 53.75, "val_loss": 13.919106721878052, "val_acc": 50.0}
{"epoch": 46, "training_loss": 55.21132278442383, "training_acc": 53.75, "val_loss": 13.935234546661377, "val_acc": 50.0}
{"epoch": 47, "training_loss": 55.18004608154297, "training_acc": 53.75, "val_loss": 13.97370457649231, "val_acc": 50.0}
{"epoch": 48, "training_loss": 55.19602966308594, "training_acc": 53.75, "val_loss": 14.043351411819458, "val_acc": 50.0}
{"epoch": 49, "training_loss": 55.34239196777344, "training_acc": 53.75, "val_loss": 14.111543893814087, "val_acc": 50.0}
{"epoch": 50, "training_loss": 55.4189453125, "training_acc": 53.75, "val_loss": 14.093818664550781, "val_acc": 50.0}
{"epoch": 51, "training_loss": 55.37324237823486, "training_acc": 53.75, "val_loss": 14.020957946777344, "val_acc": 50.0}
{"epoch": 52, "training_loss": 55.21483135223389, "training_acc": 53.75, "val_loss": 13.934060335159302, "val_acc": 50.0}
{"epoch": 53, "training_loss": 55.25549125671387, "training_acc": 53.75, "val_loss": 13.896359205245972, "val_acc": 50.0}
{"epoch": 54, "training_loss": 55.22272777557373, "training_acc": 53.75, "val_loss": 13.892930746078491, "val_acc": 50.0}
{"epoch": 55, "training_loss": 55.23457622528076, "training_acc": 53.75, "val_loss": 13.89491081237793, "val_acc": 50.0}
{"epoch": 56, "training_loss": 55.240299224853516, "training_acc": 53.75, "val_loss": 13.893407583236694, "val_acc": 50.0}
{"epoch": 57, "training_loss": 55.2519588470459, "training_acc": 53.75, "val_loss": 13.889857530593872, "val_acc": 50.0}
