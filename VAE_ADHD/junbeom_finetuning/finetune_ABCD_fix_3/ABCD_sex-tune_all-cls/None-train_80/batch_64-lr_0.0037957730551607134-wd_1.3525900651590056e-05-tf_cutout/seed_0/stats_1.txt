"main_optuna_fix_3.py --pretrained_path None --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3 --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 178.80847549438477, "training_acc": 41.25, "val_loss": 55081.9873046875, "val_acc": 50.0}
{"epoch": 1, "training_loss": 173795.13786315918, "training_acc": 46.25, "val_loss": 150.99143981933594, "val_acc": 50.0}
{"epoch": 2, "training_loss": 864.510986328125, "training_acc": 51.25, "val_loss": 37.905235290527344, "val_acc": 50.0}
{"epoch": 3, "training_loss": 144.2379322052002, "training_acc": 46.25, "val_loss": 15.177757740020752, "val_acc": 50.0}
{"epoch": 4, "training_loss": 57.36508560180664, "training_acc": 53.75, "val_loss": 14.296691417694092, "val_acc": 50.0}
{"epoch": 5, "training_loss": 91.2464370727539, "training_acc": 48.75, "val_loss": 14.800800085067749, "val_acc": 50.0}
{"epoch": 6, "training_loss": 60.31616973876953, "training_acc": 46.25, "val_loss": 14.342883825302124, "val_acc": 50.0}
{"epoch": 7, "training_loss": 63.095947265625, "training_acc": 51.25, "val_loss": 15.226716995239258, "val_acc": 50.0}
{"epoch": 8, "training_loss": 57.60584259033203, "training_acc": 53.75, "val_loss": 15.716958045959473, "val_acc": 50.0}
{"epoch": 9, "training_loss": 65.83437728881836, "training_acc": 43.75, "val_loss": 14.116606712341309, "val_acc": 50.0}
{"epoch": 10, "training_loss": 55.9246826171875, "training_acc": 51.25, "val_loss": 13.95179271697998, "val_acc": 50.0}
{"epoch": 11, "training_loss": 55.2987756729126, "training_acc": 53.75, "val_loss": 14.270150661468506, "val_acc": 50.0}
{"epoch": 12, "training_loss": 55.88582992553711, "training_acc": 53.75, "val_loss": 13.868306875228882, "val_acc": 50.0}
{"epoch": 13, "training_loss": 55.30273246765137, "training_acc": 53.75, "val_loss": 14.889343976974487, "val_acc": 50.0}
{"epoch": 14, "training_loss": 57.8750057220459, "training_acc": 53.75, "val_loss": 14.408758878707886, "val_acc": 50.0}
{"epoch": 15, "training_loss": 56.24484443664551, "training_acc": 53.75, "val_loss": 14.102476835250854, "val_acc": 50.0}
{"epoch": 16, "training_loss": 55.6242151260376, "training_acc": 53.75, "val_loss": 14.002189636230469, "val_acc": 50.0}
{"epoch": 17, "training_loss": 55.43440532684326, "training_acc": 53.75, "val_loss": 13.890047073364258, "val_acc": 50.0}
{"epoch": 18, "training_loss": 55.40118408203125, "training_acc": 51.25, "val_loss": 13.863821029663086, "val_acc": 50.0}
{"epoch": 19, "training_loss": 55.889461517333984, "training_acc": 41.25, "val_loss": 13.865224123001099, "val_acc": 50.0}
{"epoch": 20, "training_loss": 55.35057830810547, "training_acc": 53.75, "val_loss": 13.863400220870972, "val_acc": 50.0}
{"epoch": 21, "training_loss": 55.52486038208008, "training_acc": 46.25, "val_loss": 13.923453092575073, "val_acc": 50.0}
{"epoch": 22, "training_loss": 55.09347152709961, "training_acc": 53.75, "val_loss": 14.35306429862976, "val_acc": 50.0}
{"epoch": 23, "training_loss": 56.028818130493164, "training_acc": 53.75, "val_loss": 14.391697645187378, "val_acc": 50.0}
{"epoch": 24, "training_loss": 56.162550926208496, "training_acc": 53.75, "val_loss": 14.141892194747925, "val_acc": 50.0}
