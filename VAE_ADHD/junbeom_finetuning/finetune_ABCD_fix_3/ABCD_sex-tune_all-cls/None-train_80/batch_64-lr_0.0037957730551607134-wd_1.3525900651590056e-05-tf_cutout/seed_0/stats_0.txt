"main_optuna_fix_3.py --pretrained_path None --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3 --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 61.326995849609375, "training_acc": 53.75, "val_loss": 395572.9296875, "val_acc": 50.0}
{"epoch": 1, "training_loss": 1215369.0063705444, "training_acc": 46.25, "val_loss": 13.931807279586792, "val_acc": 50.0}
{"epoch": 2, "training_loss": 143.30124282836914, "training_acc": 46.25, "val_loss": 18.595303297042847, "val_acc": 50.0}
{"epoch": 3, "training_loss": 78.68849182128906, "training_acc": 53.75, "val_loss": 16.04217767715454, "val_acc": 50.0}
{"epoch": 4, "training_loss": 62.29124641418457, "training_acc": 53.75, "val_loss": 14.002522230148315, "val_acc": 50.0}
{"epoch": 5, "training_loss": 55.1423282623291, "training_acc": 53.75, "val_loss": 18.194574117660522, "val_acc": 50.0}
{"epoch": 6, "training_loss": 72.43504333496094, "training_acc": 48.75, "val_loss": 16.3154399394989, "val_acc": 50.0}
{"epoch": 7, "training_loss": 60.24344539642334, "training_acc": 53.75, "val_loss": 13.86160135269165, "val_acc": 50.0}
{"epoch": 8, "training_loss": 55.550161361694336, "training_acc": 46.25, "val_loss": 13.910493850708008, "val_acc": 50.0}
{"epoch": 9, "training_loss": 56.0785608291626, "training_acc": 46.25, "val_loss": 14.037035703659058, "val_acc": 50.0}
{"epoch": 10, "training_loss": 55.38516426086426, "training_acc": 53.75, "val_loss": 13.917721509933472, "val_acc": 50.0}
{"epoch": 11, "training_loss": 55.339667320251465, "training_acc": 53.75, "val_loss": 14.218958616256714, "val_acc": 50.0}
{"epoch": 12, "training_loss": 55.74215793609619, "training_acc": 53.75, "val_loss": 14.34888243675232, "val_acc": 50.0}
{"epoch": 13, "training_loss": 56.39169216156006, "training_acc": 53.75, "val_loss": 14.126486778259277, "val_acc": 50.0}
{"epoch": 14, "training_loss": 55.744550704956055, "training_acc": 53.75, "val_loss": 14.347184896469116, "val_acc": 50.0}
{"epoch": 15, "training_loss": 55.99588394165039, "training_acc": 53.75, "val_loss": 14.497619867324829, "val_acc": 50.0}
{"epoch": 16, "training_loss": 56.544700622558594, "training_acc": 53.75, "val_loss": 14.114006757736206, "val_acc": 50.0}
{"epoch": 17, "training_loss": 55.40626907348633, "training_acc": 53.75, "val_loss": 13.918949365615845, "val_acc": 50.0}
{"epoch": 18, "training_loss": 55.33712196350098, "training_acc": 53.75, "val_loss": 13.890329599380493, "val_acc": 50.0}
{"epoch": 19, "training_loss": 55.65649604797363, "training_acc": 53.75, "val_loss": 13.87453556060791, "val_acc": 50.0}
{"epoch": 20, "training_loss": 55.23852729797363, "training_acc": 53.75, "val_loss": 13.877089023590088, "val_acc": 50.0}
{"epoch": 21, "training_loss": 55.770883560180664, "training_acc": 46.25, "val_loss": 13.862196207046509, "val_acc": 50.0}
{"epoch": 22, "training_loss": 55.2076473236084, "training_acc": 53.75, "val_loss": 14.953292608261108, "val_acc": 50.0}
{"epoch": 23, "training_loss": 57.068902015686035, "training_acc": 53.75, "val_loss": 13.96304965019226, "val_acc": 50.0}
{"epoch": 24, "training_loss": 55.19146537780762, "training_acc": 53.75, "val_loss": 13.86482834815979, "val_acc": 50.0}
{"epoch": 25, "training_loss": 55.359540939331055, "training_acc": 53.75, "val_loss": 13.863263130187988, "val_acc": 50.0}
{"epoch": 26, "training_loss": 55.32859706878662, "training_acc": 53.75, "val_loss": 14.119809865951538, "val_acc": 50.0}
{"epoch": 27, "training_loss": 55.93394088745117, "training_acc": 53.75, "val_loss": 14.067639112472534, "val_acc": 50.0}
{"epoch": 28, "training_loss": 55.62478065490723, "training_acc": 53.75, "val_loss": 13.888143301010132, "val_acc": 50.0}
{"epoch": 29, "training_loss": 55.304758071899414, "training_acc": 53.75, "val_loss": 13.862642049789429, "val_acc": 50.0}
{"epoch": 30, "training_loss": 55.44898319244385, "training_acc": 48.75, "val_loss": 13.870258331298828, "val_acc": 50.0}
{"epoch": 31, "training_loss": 55.35109901428223, "training_acc": 53.75, "val_loss": 13.91543984413147, "val_acc": 50.0}
{"epoch": 32, "training_loss": 55.23484134674072, "training_acc": 53.75, "val_loss": 13.903635740280151, "val_acc": 50.0}
{"epoch": 33, "training_loss": 55.33118152618408, "training_acc": 53.75, "val_loss": 13.950303792953491, "val_acc": 50.0}
{"epoch": 34, "training_loss": 55.20832633972168, "training_acc": 53.75, "val_loss": 14.20763611793518, "val_acc": 50.0}
{"epoch": 35, "training_loss": 55.838491439819336, "training_acc": 53.75, "val_loss": 13.973438739776611, "val_acc": 50.0}
{"epoch": 36, "training_loss": 55.188859939575195, "training_acc": 53.75, "val_loss": 13.869746923446655, "val_acc": 50.0}
{"epoch": 37, "training_loss": 55.31318759918213, "training_acc": 53.75, "val_loss": 13.863472938537598, "val_acc": 50.0}
{"epoch": 38, "training_loss": 55.51906967163086, "training_acc": 46.25, "val_loss": 13.867090940475464, "val_acc": 50.0}
{"epoch": 39, "training_loss": 55.56582164764404, "training_acc": 46.25, "val_loss": 13.863118886947632, "val_acc": 50.0}
{"epoch": 40, "training_loss": 55.39907455444336, "training_acc": 53.75, "val_loss": 13.886171579360962, "val_acc": 50.0}
{"epoch": 41, "training_loss": 55.45859336853027, "training_acc": 53.75, "val_loss": 13.912525177001953, "val_acc": 50.0}
{"epoch": 42, "training_loss": 55.24090766906738, "training_acc": 53.75, "val_loss": 13.89374852180481, "val_acc": 50.0}
{"epoch": 43, "training_loss": 55.25582981109619, "training_acc": 53.75, "val_loss": 13.909409046173096, "val_acc": 50.0}
{"epoch": 44, "training_loss": 55.39496040344238, "training_acc": 53.75, "val_loss": 13.91344428062439, "val_acc": 50.0}
{"epoch": 45, "training_loss": 55.25178146362305, "training_acc": 53.75, "val_loss": 13.883122205734253, "val_acc": 50.0}
{"epoch": 46, "training_loss": 55.27668571472168, "training_acc": 53.75, "val_loss": 13.88853669166565, "val_acc": 50.0}
{"epoch": 47, "training_loss": 55.23047065734863, "training_acc": 53.75, "val_loss": 13.93574595451355, "val_acc": 50.0}
{"epoch": 48, "training_loss": 55.22276782989502, "training_acc": 53.75, "val_loss": 14.027066230773926, "val_acc": 50.0}
{"epoch": 49, "training_loss": 55.348252296447754, "training_acc": 53.75, "val_loss": 14.012786149978638, "val_acc": 50.0}
{"epoch": 50, "training_loss": 55.360313415527344, "training_acc": 53.75, "val_loss": 13.987951278686523, "val_acc": 50.0}
{"epoch": 51, "training_loss": 55.260558128356934, "training_acc": 53.75, "val_loss": 14.002357721328735, "val_acc": 50.0}
{"epoch": 52, "training_loss": 55.29650688171387, "training_acc": 53.75, "val_loss": 13.98938775062561, "val_acc": 50.0}
{"epoch": 53, "training_loss": 55.31608963012695, "training_acc": 53.75, "val_loss": 13.980497121810913, "val_acc": 50.0}
{"epoch": 54, "training_loss": 55.28478813171387, "training_acc": 53.75, "val_loss": 13.990093469619751, "val_acc": 50.0}
{"epoch": 55, "training_loss": 55.27957630157471, "training_acc": 53.75, "val_loss": 13.964674472808838, "val_acc": 50.0}
{"epoch": 56, "training_loss": 55.22172927856445, "training_acc": 53.75, "val_loss": 13.907173871994019, "val_acc": 50.0}
{"epoch": 57, "training_loss": 55.22023582458496, "training_acc": 53.75, "val_loss": 13.87147068977356, "val_acc": 50.0}
{"epoch": 58, "training_loss": 55.292107582092285, "training_acc": 53.75, "val_loss": 13.863829374313354, "val_acc": 50.0}
{"epoch": 59, "training_loss": 55.43454360961914, "training_acc": 53.75, "val_loss": 13.863176107406616, "val_acc": 50.0}
{"epoch": 60, "training_loss": 55.42846870422363, "training_acc": 53.75, "val_loss": 13.863918781280518, "val_acc": 50.0}
{"epoch": 61, "training_loss": 55.39128589630127, "training_acc": 53.75, "val_loss": 13.866558074951172, "val_acc": 50.0}
{"epoch": 62, "training_loss": 55.35336399078369, "training_acc": 53.75, "val_loss": 13.871545791625977, "val_acc": 50.0}
{"epoch": 63, "training_loss": 55.32687759399414, "training_acc": 53.75, "val_loss": 13.876403570175171, "val_acc": 50.0}
{"epoch": 64, "training_loss": 55.293365478515625, "training_acc": 53.75, "val_loss": 13.876999616622925, "val_acc": 50.0}
{"epoch": 65, "training_loss": 55.30098819732666, "training_acc": 53.75, "val_loss": 13.872580528259277, "val_acc": 50.0}
