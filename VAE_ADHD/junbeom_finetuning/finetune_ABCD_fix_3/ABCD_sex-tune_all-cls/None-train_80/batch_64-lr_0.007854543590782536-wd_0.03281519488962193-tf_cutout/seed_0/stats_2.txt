"main_optuna_fix_3.py --pretrained_path None --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3 --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 294.22269439697266, "training_acc": 51.25, "val_loss": 9733093760.0, "val_acc": 55.0}
{"epoch": 1, "training_loss": 35076766315.87109, "training_acc": 45.0, "val_loss": 575106.5234375, "val_acc": 45.0}
{"epoch": 2, "training_loss": 1948199.09375, "training_acc": 47.5, "val_loss": 2040.6712341308594, "val_acc": 55.0}
{"epoch": 3, "training_loss": 16151.1298828125, "training_acc": 50.0, "val_loss": 25933.681640625, "val_acc": 55.0}
{"epoch": 4, "training_loss": 100595.25390625, "training_acc": 52.5, "val_loss": 97.49171257019043, "val_acc": 45.0}
{"epoch": 5, "training_loss": 2618.1165161132812, "training_acc": 47.5, "val_loss": 8511.879272460938, "val_acc": 45.0}
{"epoch": 6, "training_loss": 24067.733642578125, "training_acc": 47.5, "val_loss": 279.33780670166016, "val_acc": 55.0}
{"epoch": 7, "training_loss": 1128.287841796875, "training_acc": 52.5, "val_loss": 46.8084192276001, "val_acc": 45.0}
{"epoch": 8, "training_loss": 1023.548095703125, "training_acc": 42.5, "val_loss": 129.25959587097168, "val_acc": 55.0}
{"epoch": 9, "training_loss": 546.8263549804688, "training_acc": 55.0, "val_loss": 157.82645225524902, "val_acc": 45.0}
{"epoch": 10, "training_loss": 501.40649032592773, "training_acc": 50.0, "val_loss": 506.9564437866211, "val_acc": 45.0}
{"epoch": 11, "training_loss": 1493.1768608093262, "training_acc": 52.5, "val_loss": 140.58984756469727, "val_acc": 55.0}
{"epoch": 12, "training_loss": 475.93378829956055, "training_acc": 52.5, "val_loss": 195.75979232788086, "val_acc": 55.0}
{"epoch": 13, "training_loss": 657.1318168640137, "training_acc": 52.5, "val_loss": 190.64756393432617, "val_acc": 45.0}
{"epoch": 14, "training_loss": 589.5014419555664, "training_acc": 47.5, "val_loss": 151.29945755004883, "val_acc": 45.0}
{"epoch": 15, "training_loss": 471.07775115966797, "training_acc": 55.0, "val_loss": 15.895328521728516, "val_acc": 55.0}
{"epoch": 16, "training_loss": 346.53965759277344, "training_acc": 45.0, "val_loss": 48.57884407043457, "val_acc": 45.0}
{"epoch": 17, "training_loss": 304.8177185058594, "training_acc": 45.0, "val_loss": 154.44610595703125, "val_acc": 55.0}
{"epoch": 18, "training_loss": 550.3706169128418, "training_acc": 52.5, "val_loss": 61.439433097839355, "val_acc": 45.0}
{"epoch": 19, "training_loss": 212.86009979248047, "training_acc": 47.5, "val_loss": 13.818668127059937, "val_acc": 55.0}
{"epoch": 20, "training_loss": 59.367011070251465, "training_acc": 56.25, "val_loss": 18.833998441696167, "val_acc": 55.0}
{"epoch": 21, "training_loss": 73.0542984008789, "training_acc": 52.5, "val_loss": 22.11479663848877, "val_acc": 45.0}
{"epoch": 22, "training_loss": 98.93133163452148, "training_acc": 50.0, "val_loss": 15.412485599517822, "val_acc": 55.0}
{"epoch": 23, "training_loss": 73.01214218139648, "training_acc": 50.0, "val_loss": 18.980950117111206, "val_acc": 45.0}
{"epoch": 24, "training_loss": 68.60267066955566, "training_acc": 55.0, "val_loss": 16.283515691757202, "val_acc": 55.0}
{"epoch": 25, "training_loss": 67.73259735107422, "training_acc": 50.0, "val_loss": 17.11014986038208, "val_acc": 55.0}
{"epoch": 26, "training_loss": 79.29672813415527, "training_acc": 45.0, "val_loss": 14.003355503082275, "val_acc": 55.0}
{"epoch": 27, "training_loss": 58.324832916259766, "training_acc": 50.0, "val_loss": 15.465341806411743, "val_acc": 55.0}
{"epoch": 28, "training_loss": 59.1878776550293, "training_acc": 55.0, "val_loss": 18.214510679244995, "val_acc": 45.0}
