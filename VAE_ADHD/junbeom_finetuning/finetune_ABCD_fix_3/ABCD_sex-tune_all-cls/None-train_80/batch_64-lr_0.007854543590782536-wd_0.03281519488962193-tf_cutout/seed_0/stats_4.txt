"main_optuna_fix_3.py --pretrained_path None --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3 --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 102.98934555053711, "training_acc": 55.0, "val_loss": 11158990080.0, "val_acc": 55.0}
{"epoch": 1, "training_loss": 40404808285.08154, "training_acc": 52.5, "val_loss": 40497.49267578125, "val_acc": 45.0}
{"epoch": 2, "training_loss": 129192.546875, "training_acc": 47.5, "val_loss": 5764.522705078125, "val_acc": 55.0}
{"epoch": 3, "training_loss": 19101.275634765625, "training_acc": 55.0, "val_loss": 929.2024993896484, "val_acc": 45.0}
{"epoch": 4, "training_loss": 3830.09326171875, "training_acc": 50.0, "val_loss": 221.60833358764648, "val_acc": 45.0}
{"epoch": 5, "training_loss": 758.7311248779297, "training_acc": 47.5, "val_loss": 4710.292053222656, "val_acc": 45.0}
{"epoch": 6, "training_loss": 14457.724975585938, "training_acc": 47.5, "val_loss": 156.73296928405762, "val_acc": 55.0}
{"epoch": 7, "training_loss": 531.4127941131592, "training_acc": 52.5, "val_loss": 1108.2625579833984, "val_acc": 55.0}
{"epoch": 8, "training_loss": 3590.197509765625, "training_acc": 52.5, "val_loss": 545.4204177856445, "val_acc": 45.0}
{"epoch": 9, "training_loss": 1842.5474853515625, "training_acc": 55.0, "val_loss": 31.780211925506592, "val_acc": 45.0}
{"epoch": 10, "training_loss": 1057.5948104858398, "training_acc": 50.0, "val_loss": 459.77245330810547, "val_acc": 45.0}
{"epoch": 11, "training_loss": 2003.5115356445312, "training_acc": 47.5, "val_loss": 70.24510860443115, "val_acc": 45.0}
{"epoch": 12, "training_loss": 679.6427001953125, "training_acc": 47.5, "val_loss": 119.81595039367676, "val_acc": 55.0}
{"epoch": 13, "training_loss": 1257.6180725097656, "training_acc": 50.0, "val_loss": 273.5763931274414, "val_acc": 45.0}
{"epoch": 14, "training_loss": 920.1386337280273, "training_acc": 42.5, "val_loss": 18.401081562042236, "val_acc": 45.0}
{"epoch": 15, "training_loss": 66.98591995239258, "training_acc": 52.5, "val_loss": 24.052550792694092, "val_acc": 45.0}
{"epoch": 16, "training_loss": 93.3468189239502, "training_acc": 57.5, "val_loss": 15.774002075195312, "val_acc": 45.0}
{"epoch": 17, "training_loss": 161.53561401367188, "training_acc": 47.5, "val_loss": 345.9029769897461, "val_acc": 45.0}
{"epoch": 18, "training_loss": 1121.109848022461, "training_acc": 45.0, "val_loss": 34.21572923660278, "val_acc": 55.0}
{"epoch": 19, "training_loss": 174.24783325195312, "training_acc": 55.0, "val_loss": 99.71636772155762, "val_acc": 45.0}
{"epoch": 20, "training_loss": 315.69250297546387, "training_acc": 47.5, "val_loss": 66.56539916992188, "val_acc": 55.0}
{"epoch": 21, "training_loss": 240.92071914672852, "training_acc": 52.5, "val_loss": 85.04992485046387, "val_acc": 45.0}
{"epoch": 22, "training_loss": 271.86280059814453, "training_acc": 47.5, "val_loss": 65.86509704589844, "val_acc": 55.0}
{"epoch": 23, "training_loss": 245.227765083313, "training_acc": 52.5, "val_loss": 58.48062992095947, "val_acc": 45.0}
{"epoch": 24, "training_loss": 190.55010414123535, "training_acc": 47.5, "val_loss": 27.674970626831055, "val_acc": 55.0}
{"epoch": 25, "training_loss": 125.02916145324707, "training_acc": 45.0, "val_loss": 22.737107276916504, "val_acc": 55.0}
{"epoch": 26, "training_loss": 90.29773902893066, "training_acc": 52.5, "val_loss": 19.60159659385681, "val_acc": 45.0}
{"epoch": 27, "training_loss": 72.47091293334961, "training_acc": 47.5, "val_loss": 13.873661756515503, "val_acc": 55.0}
{"epoch": 28, "training_loss": 56.179182052612305, "training_acc": 52.5, "val_loss": 13.77249002456665, "val_acc": 55.0}
{"epoch": 29, "training_loss": 56.32661056518555, "training_acc": 45.0, "val_loss": 13.83252739906311, "val_acc": 55.0}
{"epoch": 30, "training_loss": 56.808650970458984, "training_acc": 52.5, "val_loss": 13.90406847000122, "val_acc": 55.0}
{"epoch": 31, "training_loss": 55.92300796508789, "training_acc": 55.0, "val_loss": 15.306624174118042, "val_acc": 45.0}
{"epoch": 32, "training_loss": 60.22200393676758, "training_acc": 47.5, "val_loss": 13.828779458999634, "val_acc": 55.0}
{"epoch": 33, "training_loss": 58.21320152282715, "training_acc": 52.5, "val_loss": 14.025118350982666, "val_acc": 55.0}
{"epoch": 34, "training_loss": 57.22927379608154, "training_acc": 50.0, "val_loss": 14.106000661849976, "val_acc": 55.0}
{"epoch": 35, "training_loss": 56.026615142822266, "training_acc": 48.75, "val_loss": 13.745430707931519, "val_acc": 55.0}
{"epoch": 36, "training_loss": 55.244168281555176, "training_acc": 52.5, "val_loss": 14.17528510093689, "val_acc": 55.0}
{"epoch": 37, "training_loss": 57.916622161865234, "training_acc": 52.5, "val_loss": 13.737293481826782, "val_acc": 55.0}
{"epoch": 38, "training_loss": 55.371235847473145, "training_acc": 50.0, "val_loss": 13.777022361755371, "val_acc": 55.0}
{"epoch": 39, "training_loss": 55.0473690032959, "training_acc": 57.5, "val_loss": 13.927422761917114, "val_acc": 55.0}
{"epoch": 40, "training_loss": 56.63494873046875, "training_acc": 52.5, "val_loss": 13.738607168197632, "val_acc": 55.0}
{"epoch": 41, "training_loss": 55.29612731933594, "training_acc": 56.25, "val_loss": 14.243555068969727, "val_acc": 55.0}
{"epoch": 42, "training_loss": 56.421308517456055, "training_acc": 47.5, "val_loss": 13.735402822494507, "val_acc": 55.0}
{"epoch": 43, "training_loss": 55.20393180847168, "training_acc": 52.5, "val_loss": 14.23853874206543, "val_acc": 55.0}
{"epoch": 44, "training_loss": 57.96417045593262, "training_acc": 52.5, "val_loss": 14.015895128250122, "val_acc": 55.0}
{"epoch": 45, "training_loss": 55.588632583618164, "training_acc": 47.5, "val_loss": 15.592588186264038, "val_acc": 45.0}
