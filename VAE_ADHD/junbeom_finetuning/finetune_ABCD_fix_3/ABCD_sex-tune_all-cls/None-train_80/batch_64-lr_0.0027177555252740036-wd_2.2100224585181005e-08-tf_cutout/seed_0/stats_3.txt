"main_optuna_fix_3.py --pretrained_path None --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3 --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 144.7558937072754, "training_acc": 42.5, "val_loss": 4846.04736328125, "val_acc": 55.0}
{"epoch": 1, "training_loss": 17701.486150741577, "training_acc": 45.0, "val_loss": 14.02476191520691, "val_acc": 55.0}
{"epoch": 2, "training_loss": 56.7724666595459, "training_acc": 50.0, "val_loss": 222.21689224243164, "val_acc": 45.0}
{"epoch": 3, "training_loss": 693.2346343994141, "training_acc": 47.5, "val_loss": 13.771156072616577, "val_acc": 55.0}
{"epoch": 4, "training_loss": 55.53032302856445, "training_acc": 52.5, "val_loss": 14.103634357452393, "val_acc": 55.0}
{"epoch": 5, "training_loss": 57.31482219696045, "training_acc": 52.5, "val_loss": 13.939859867095947, "val_acc": 55.0}
{"epoch": 6, "training_loss": 55.566161155700684, "training_acc": 47.5, "val_loss": 13.965682983398438, "val_acc": 55.0}
{"epoch": 7, "training_loss": 56.53601932525635, "training_acc": 52.5, "val_loss": 13.890730142593384, "val_acc": 55.0}
{"epoch": 8, "training_loss": 55.50935459136963, "training_acc": 47.5, "val_loss": 14.380165338516235, "val_acc": 55.0}
{"epoch": 9, "training_loss": 56.81110763549805, "training_acc": 47.5, "val_loss": 13.963634967803955, "val_acc": 55.0}
{"epoch": 10, "training_loss": 55.454803466796875, "training_acc": 52.5, "val_loss": 13.763751983642578, "val_acc": 55.0}
{"epoch": 11, "training_loss": 55.34542179107666, "training_acc": 52.5, "val_loss": 13.87679934501648, "val_acc": 55.0}
{"epoch": 12, "training_loss": 56.375267028808594, "training_acc": 52.5, "val_loss": 13.769279718399048, "val_acc": 55.0}
{"epoch": 13, "training_loss": 55.5819206237793, "training_acc": 52.5, "val_loss": 13.78835678100586, "val_acc": 55.0}
{"epoch": 14, "training_loss": 55.33728790283203, "training_acc": 52.5, "val_loss": 13.821009397506714, "val_acc": 55.0}
{"epoch": 15, "training_loss": 55.50781059265137, "training_acc": 47.5, "val_loss": 13.828071355819702, "val_acc": 55.0}
{"epoch": 16, "training_loss": 55.32649898529053, "training_acc": 52.5, "val_loss": 13.771445751190186, "val_acc": 55.0}
{"epoch": 17, "training_loss": 55.49367332458496, "training_acc": 52.5, "val_loss": 13.763418197631836, "val_acc": 55.0}
{"epoch": 18, "training_loss": 55.453325271606445, "training_acc": 52.5, "val_loss": 13.769737482070923, "val_acc": 55.0}
{"epoch": 19, "training_loss": 55.311750411987305, "training_acc": 52.5, "val_loss": 13.83573293685913, "val_acc": 55.0}
{"epoch": 20, "training_loss": 55.467756271362305, "training_acc": 50.0, "val_loss": 13.88750433921814, "val_acc": 55.0}
{"epoch": 21, "training_loss": 55.501654624938965, "training_acc": 47.5, "val_loss": 13.8467538356781, "val_acc": 55.0}
{"epoch": 22, "training_loss": 55.409048080444336, "training_acc": 52.5, "val_loss": 13.820000886917114, "val_acc": 55.0}
{"epoch": 23, "training_loss": 55.36565017700195, "training_acc": 52.5, "val_loss": 13.794338703155518, "val_acc": 55.0}
{"epoch": 24, "training_loss": 55.325804710388184, "training_acc": 52.5, "val_loss": 13.770948648452759, "val_acc": 55.0}
{"epoch": 25, "training_loss": 55.29991340637207, "training_acc": 52.5, "val_loss": 13.76737356185913, "val_acc": 55.0}
{"epoch": 26, "training_loss": 55.51309108734131, "training_acc": 52.5, "val_loss": 13.829185962677002, "val_acc": 55.0}
{"epoch": 27, "training_loss": 56.01095199584961, "training_acc": 52.5, "val_loss": 13.818038702011108, "val_acc": 55.0}
{"epoch": 28, "training_loss": 55.85891151428223, "training_acc": 52.5, "val_loss": 13.76333236694336, "val_acc": 55.0}
{"epoch": 29, "training_loss": 55.50070285797119, "training_acc": 52.5, "val_loss": 13.787412643432617, "val_acc": 55.0}
{"epoch": 30, "training_loss": 55.335832595825195, "training_acc": 52.5, "val_loss": 13.816136121749878, "val_acc": 55.0}
{"epoch": 31, "training_loss": 55.36395835876465, "training_acc": 52.5, "val_loss": 13.844354152679443, "val_acc": 55.0}
{"epoch": 32, "training_loss": 55.414852142333984, "training_acc": 52.5, "val_loss": 13.875020742416382, "val_acc": 55.0}
{"epoch": 33, "training_loss": 55.481475830078125, "training_acc": 47.5, "val_loss": 13.86825442314148, "val_acc": 55.0}
{"epoch": 34, "training_loss": 55.44974327087402, "training_acc": 50.0, "val_loss": 13.83495569229126, "val_acc": 55.0}
{"epoch": 35, "training_loss": 55.43039035797119, "training_acc": 52.5, "val_loss": 13.813270330429077, "val_acc": 55.0}
{"epoch": 36, "training_loss": 55.370361328125, "training_acc": 52.5, "val_loss": 13.802318572998047, "val_acc": 55.0}
{"epoch": 37, "training_loss": 55.36604118347168, "training_acc": 52.5, "val_loss": 13.783841133117676, "val_acc": 55.0}
{"epoch": 38, "training_loss": 55.345970153808594, "training_acc": 52.5, "val_loss": 13.772449493408203, "val_acc": 55.0}
