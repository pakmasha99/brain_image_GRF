"main_optuna_fix_3.py --pretrained_path None --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3 --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 55.4694709777832, "training_acc": 52.5, "val_loss": 13.790080547332764, "val_acc": 55.0}
{"epoch": 1, "training_loss": 55.39681434631348, "training_acc": 52.5, "val_loss": 13.784233331680298, "val_acc": 55.0}
{"epoch": 2, "training_loss": 55.40267467498779, "training_acc": 52.5, "val_loss": 13.766405582427979, "val_acc": 55.0}
{"epoch": 3, "training_loss": 55.36593818664551, "training_acc": 52.5, "val_loss": 13.761721849441528, "val_acc": 55.0}
{"epoch": 4, "training_loss": 55.396294593811035, "training_acc": 52.5, "val_loss": 13.760871887207031, "val_acc": 55.0}
{"epoch": 5, "training_loss": 55.40701484680176, "training_acc": 52.5, "val_loss": 13.760666847229004, "val_acc": 55.0}
{"epoch": 6, "training_loss": 55.40511703491211, "training_acc": 52.5, "val_loss": 13.760961294174194, "val_acc": 55.0}
{"epoch": 7, "training_loss": 55.40026664733887, "training_acc": 52.5, "val_loss": 13.76063346862793, "val_acc": 55.0}
{"epoch": 8, "training_loss": 55.33270454406738, "training_acc": 52.5, "val_loss": 13.767333030700684, "val_acc": 55.0}
{"epoch": 9, "training_loss": 55.30925941467285, "training_acc": 52.5, "val_loss": 13.790559768676758, "val_acc": 55.0}
{"epoch": 10, "training_loss": 55.37724685668945, "training_acc": 52.5, "val_loss": 13.809444904327393, "val_acc": 55.0}
{"epoch": 11, "training_loss": 55.36769962310791, "training_acc": 52.5, "val_loss": 13.805574178695679, "val_acc": 55.0}
{"epoch": 12, "training_loss": 55.33439826965332, "training_acc": 52.5, "val_loss": 13.795620203018188, "val_acc": 55.0}
{"epoch": 13, "training_loss": 55.28333282470703, "training_acc": 52.5, "val_loss": 13.791265487670898, "val_acc": 55.0}
{"epoch": 14, "training_loss": 55.31424427032471, "training_acc": 52.5, "val_loss": 13.78630518913269, "val_acc": 55.0}
{"epoch": 15, "training_loss": 55.33815670013428, "training_acc": 52.5, "val_loss": 13.780204057693481, "val_acc": 55.0}
{"epoch": 16, "training_loss": 55.2498254776001, "training_acc": 52.5, "val_loss": 13.764874935150146, "val_acc": 55.0}
{"epoch": 17, "training_loss": 55.39892101287842, "training_acc": 52.5, "val_loss": 13.755803108215332, "val_acc": 55.0}
{"epoch": 18, "training_loss": 55.33536148071289, "training_acc": 52.5, "val_loss": 13.754481077194214, "val_acc": 55.0}
{"epoch": 19, "training_loss": 55.37341499328613, "training_acc": 52.5, "val_loss": 13.757776021957397, "val_acc": 55.0}
{"epoch": 20, "training_loss": 55.34757041931152, "training_acc": 52.5, "val_loss": 13.764593601226807, "val_acc": 55.0}
{"epoch": 21, "training_loss": 55.33298110961914, "training_acc": 52.5, "val_loss": 13.771333694458008, "val_acc": 55.0}
{"epoch": 22, "training_loss": 55.29973220825195, "training_acc": 52.5, "val_loss": 13.77819299697876, "val_acc": 55.0}
{"epoch": 23, "training_loss": 55.29497528076172, "training_acc": 52.5, "val_loss": 13.778799772262573, "val_acc": 55.0}
{"epoch": 24, "training_loss": 55.30439758300781, "training_acc": 52.5, "val_loss": 13.770570755004883, "val_acc": 55.0}
{"epoch": 25, "training_loss": 55.201358795166016, "training_acc": 52.5, "val_loss": 13.757424354553223, "val_acc": 55.0}
{"epoch": 26, "training_loss": 55.31143379211426, "training_acc": 52.5, "val_loss": 13.754931688308716, "val_acc": 55.0}
{"epoch": 27, "training_loss": 55.27631378173828, "training_acc": 52.5, "val_loss": 13.75973105430603, "val_acc": 55.0}
{"epoch": 28, "training_loss": 55.56779098510742, "training_acc": 52.5, "val_loss": 13.761612176895142, "val_acc": 55.0}
{"epoch": 29, "training_loss": 55.42043113708496, "training_acc": 52.5, "val_loss": 13.759912252426147, "val_acc": 55.0}
{"epoch": 30, "training_loss": 55.28164291381836, "training_acc": 52.5, "val_loss": 13.76212477684021, "val_acc": 55.0}
{"epoch": 31, "training_loss": 55.31985855102539, "training_acc": 52.5, "val_loss": 13.776705265045166, "val_acc": 55.0}
{"epoch": 32, "training_loss": 55.24092388153076, "training_acc": 52.5, "val_loss": 13.80350947380066, "val_acc": 55.0}
{"epoch": 33, "training_loss": 55.32907772064209, "training_acc": 52.5, "val_loss": 13.821491003036499, "val_acc": 55.0}
{"epoch": 34, "training_loss": 55.349061012268066, "training_acc": 52.5, "val_loss": 13.826379776000977, "val_acc": 55.0}
{"epoch": 35, "training_loss": 55.35271644592285, "training_acc": 52.5, "val_loss": 13.821722269058228, "val_acc": 55.0}
{"epoch": 36, "training_loss": 55.32392406463623, "training_acc": 52.5, "val_loss": 13.813337087631226, "val_acc": 55.0}
{"epoch": 37, "training_loss": 55.3445930480957, "training_acc": 52.5, "val_loss": 13.796651363372803, "val_acc": 55.0}
{"epoch": 38, "training_loss": 55.255144119262695, "training_acc": 52.5, "val_loss": 13.785572052001953, "val_acc": 55.0}
{"epoch": 39, "training_loss": 55.24179649353027, "training_acc": 52.5, "val_loss": 13.776100873947144, "val_acc": 55.0}
{"epoch": 40, "training_loss": 55.30617427825928, "training_acc": 52.5, "val_loss": 13.770338296890259, "val_acc": 55.0}
{"epoch": 41, "training_loss": 55.24320983886719, "training_acc": 52.5, "val_loss": 13.77339243888855, "val_acc": 55.0}
{"epoch": 42, "training_loss": 55.31046104431152, "training_acc": 52.5, "val_loss": 13.780359029769897, "val_acc": 55.0}
{"epoch": 43, "training_loss": 55.222599029541016, "training_acc": 52.5, "val_loss": 13.788803815841675, "val_acc": 55.0}
{"epoch": 44, "training_loss": 55.34876823425293, "training_acc": 52.5, "val_loss": 13.80117416381836, "val_acc": 55.0}
{"epoch": 45, "training_loss": 55.159512519836426, "training_acc": 52.5, "val_loss": 13.82109522819519, "val_acc": 55.0}
