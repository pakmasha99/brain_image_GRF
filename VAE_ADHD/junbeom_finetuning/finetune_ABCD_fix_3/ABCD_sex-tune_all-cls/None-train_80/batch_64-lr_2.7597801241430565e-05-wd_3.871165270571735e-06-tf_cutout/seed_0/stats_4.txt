"main_optuna_fix_3.py --pretrained_path None --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3 --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 55.13458824157715, "training_acc": 52.5, "val_loss": 14.248508214950562, "val_acc": 55.0}
{"epoch": 1, "training_loss": 56.1743049621582, "training_acc": 47.5, "val_loss": 13.82597804069519, "val_acc": 55.0}
{"epoch": 2, "training_loss": 55.02876853942871, "training_acc": 52.5, "val_loss": 13.819448947906494, "val_acc": 55.0}
{"epoch": 3, "training_loss": 56.384345054626465, "training_acc": 52.5, "val_loss": 13.933817148208618, "val_acc": 55.0}
{"epoch": 4, "training_loss": 56.653597831726074, "training_acc": 52.5, "val_loss": 13.801790475845337, "val_acc": 55.0}
{"epoch": 5, "training_loss": 55.87849426269531, "training_acc": 52.5, "val_loss": 13.754351139068604, "val_acc": 55.0}
{"epoch": 6, "training_loss": 55.437808990478516, "training_acc": 52.5, "val_loss": 13.79062294960022, "val_acc": 55.0}
{"epoch": 7, "training_loss": 55.32278823852539, "training_acc": 52.5, "val_loss": 13.836783170700073, "val_acc": 55.0}
{"epoch": 8, "training_loss": 55.37396812438965, "training_acc": 52.5, "val_loss": 13.888657093048096, "val_acc": 55.0}
{"epoch": 9, "training_loss": 55.60873222351074, "training_acc": 47.5, "val_loss": 13.918627500534058, "val_acc": 55.0}
{"epoch": 10, "training_loss": 55.53728199005127, "training_acc": 47.5, "val_loss": 13.878439664840698, "val_acc": 55.0}
{"epoch": 11, "training_loss": 55.42022228240967, "training_acc": 53.75, "val_loss": 13.821876049041748, "val_acc": 55.0}
{"epoch": 12, "training_loss": 55.406192779541016, "training_acc": 52.5, "val_loss": 13.77706527709961, "val_acc": 55.0}
{"epoch": 13, "training_loss": 55.324052810668945, "training_acc": 52.5, "val_loss": 13.760179281234741, "val_acc": 55.0}
{"epoch": 14, "training_loss": 55.41564083099365, "training_acc": 52.5, "val_loss": 13.756450414657593, "val_acc": 55.0}
{"epoch": 15, "training_loss": 55.41591739654541, "training_acc": 52.5, "val_loss": 13.757275342941284, "val_acc": 55.0}
{"epoch": 16, "training_loss": 55.41728401184082, "training_acc": 52.5, "val_loss": 13.755378723144531, "val_acc": 55.0}
{"epoch": 17, "training_loss": 55.412099838256836, "training_acc": 52.5, "val_loss": 13.755143880844116, "val_acc": 55.0}
{"epoch": 18, "training_loss": 55.461936950683594, "training_acc": 52.5, "val_loss": 13.756874799728394, "val_acc": 55.0}
{"epoch": 19, "training_loss": 55.43192768096924, "training_acc": 52.5, "val_loss": 13.76189112663269, "val_acc": 55.0}
{"epoch": 20, "training_loss": 55.34901428222656, "training_acc": 52.5, "val_loss": 13.779470920562744, "val_acc": 55.0}
{"epoch": 21, "training_loss": 55.375258445739746, "training_acc": 52.5, "val_loss": 13.80308985710144, "val_acc": 55.0}
{"epoch": 22, "training_loss": 55.29067325592041, "training_acc": 52.5, "val_loss": 13.824741840362549, "val_acc": 55.0}
{"epoch": 23, "training_loss": 55.35769271850586, "training_acc": 52.5, "val_loss": 13.83499026298523, "val_acc": 55.0}
{"epoch": 24, "training_loss": 55.3565149307251, "training_acc": 52.5, "val_loss": 13.828155994415283, "val_acc": 55.0}
{"epoch": 25, "training_loss": 55.32683086395264, "training_acc": 52.5, "val_loss": 13.812856674194336, "val_acc": 55.0}
{"epoch": 26, "training_loss": 55.3104248046875, "training_acc": 52.5, "val_loss": 13.788777589797974, "val_acc": 55.0}
{"epoch": 27, "training_loss": 55.16950225830078, "training_acc": 52.5, "val_loss": 13.77395510673523, "val_acc": 55.0}
{"epoch": 28, "training_loss": 55.40954399108887, "training_acc": 52.5, "val_loss": 13.768447637557983, "val_acc": 55.0}
{"epoch": 29, "training_loss": 55.31181621551514, "training_acc": 52.5, "val_loss": 13.765041828155518, "val_acc": 55.0}
{"epoch": 30, "training_loss": 55.33069705963135, "training_acc": 52.5, "val_loss": 13.76267671585083, "val_acc": 55.0}
{"epoch": 31, "training_loss": 55.37192916870117, "training_acc": 52.5, "val_loss": 13.765429258346558, "val_acc": 55.0}
{"epoch": 32, "training_loss": 55.24326515197754, "training_acc": 52.5, "val_loss": 13.770841360092163, "val_acc": 55.0}
{"epoch": 33, "training_loss": 55.33921241760254, "training_acc": 52.5, "val_loss": 13.776438236236572, "val_acc": 55.0}
{"epoch": 34, "training_loss": 55.33590793609619, "training_acc": 52.5, "val_loss": 13.78244161605835, "val_acc": 55.0}
{"epoch": 35, "training_loss": 55.260926246643066, "training_acc": 52.5, "val_loss": 13.787487745285034, "val_acc": 55.0}
{"epoch": 36, "training_loss": 55.198974609375, "training_acc": 52.5, "val_loss": 13.786123991012573, "val_acc": 55.0}
