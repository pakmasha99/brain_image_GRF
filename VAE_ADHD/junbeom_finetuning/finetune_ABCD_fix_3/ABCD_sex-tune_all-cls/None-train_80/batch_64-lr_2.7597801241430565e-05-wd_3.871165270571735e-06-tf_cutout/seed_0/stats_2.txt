"main_optuna_fix_3.py --pretrained_path None --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3 --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 55.70968437194824, "training_acc": 51.25, "val_loss": 13.809889554977417, "val_acc": 55.0}
{"epoch": 1, "training_loss": 56.120293617248535, "training_acc": 52.5, "val_loss": 13.795381784439087, "val_acc": 55.0}
{"epoch": 2, "training_loss": 55.40766716003418, "training_acc": 52.5, "val_loss": 13.816465139389038, "val_acc": 55.0}
{"epoch": 3, "training_loss": 55.60365104675293, "training_acc": 52.5, "val_loss": 13.816789388656616, "val_acc": 55.0}
{"epoch": 4, "training_loss": 55.59020137786865, "training_acc": 52.5, "val_loss": 13.795455694198608, "val_acc": 55.0}
{"epoch": 5, "training_loss": 55.37334442138672, "training_acc": 52.5, "val_loss": 13.855645656585693, "val_acc": 55.0}
{"epoch": 6, "training_loss": 55.71993637084961, "training_acc": 42.5, "val_loss": 13.874104022979736, "val_acc": 55.0}
{"epoch": 7, "training_loss": 55.390546798706055, "training_acc": 58.75, "val_loss": 13.79603624343872, "val_acc": 55.0}
{"epoch": 8, "training_loss": 55.50118446350098, "training_acc": 52.5, "val_loss": 13.787405490875244, "val_acc": 55.0}
{"epoch": 9, "training_loss": 55.431288719177246, "training_acc": 52.5, "val_loss": 13.787815570831299, "val_acc": 55.0}
{"epoch": 10, "training_loss": 55.39608192443848, "training_acc": 52.5, "val_loss": 13.810137510299683, "val_acc": 55.0}
{"epoch": 11, "training_loss": 55.390621185302734, "training_acc": 52.5, "val_loss": 13.821839094161987, "val_acc": 55.0}
{"epoch": 12, "training_loss": 55.363487243652344, "training_acc": 52.5, "val_loss": 13.812633752822876, "val_acc": 55.0}
{"epoch": 13, "training_loss": 55.319740295410156, "training_acc": 52.5, "val_loss": 13.807992935180664, "val_acc": 55.0}
{"epoch": 14, "training_loss": 55.31551170349121, "training_acc": 52.5, "val_loss": 13.804718255996704, "val_acc": 55.0}
{"epoch": 15, "training_loss": 55.300960540771484, "training_acc": 52.5, "val_loss": 13.791059255599976, "val_acc": 55.0}
{"epoch": 16, "training_loss": 55.26221752166748, "training_acc": 52.5, "val_loss": 13.7827467918396, "val_acc": 55.0}
{"epoch": 17, "training_loss": 55.55668640136719, "training_acc": 52.5, "val_loss": 13.80047082901001, "val_acc": 55.0}
{"epoch": 18, "training_loss": 55.53617477416992, "training_acc": 52.5, "val_loss": 13.790935277938843, "val_acc": 55.0}
{"epoch": 19, "training_loss": 55.467318534851074, "training_acc": 52.5, "val_loss": 13.781174421310425, "val_acc": 55.0}
{"epoch": 20, "training_loss": 55.35189628601074, "training_acc": 52.5, "val_loss": 13.807090520858765, "val_acc": 55.0}
{"epoch": 21, "training_loss": 55.32297134399414, "training_acc": 52.5, "val_loss": 13.834551572799683, "val_acc": 55.0}
{"epoch": 22, "training_loss": 55.34342861175537, "training_acc": 52.5, "val_loss": 13.835947513580322, "val_acc": 55.0}
{"epoch": 23, "training_loss": 55.32370376586914, "training_acc": 52.5, "val_loss": 13.816455602645874, "val_acc": 55.0}
{"epoch": 24, "training_loss": 55.264570236206055, "training_acc": 52.5, "val_loss": 13.78616213798523, "val_acc": 55.0}
{"epoch": 25, "training_loss": 55.253374099731445, "training_acc": 52.5, "val_loss": 13.772786855697632, "val_acc": 55.0}
{"epoch": 26, "training_loss": 55.29206466674805, "training_acc": 52.5, "val_loss": 13.79360556602478, "val_acc": 55.0}
{"epoch": 27, "training_loss": 55.53782939910889, "training_acc": 52.5, "val_loss": 13.831729888916016, "val_acc": 55.0}
{"epoch": 28, "training_loss": 55.913347244262695, "training_acc": 52.5, "val_loss": 13.818705081939697, "val_acc": 55.0}
{"epoch": 29, "training_loss": 55.751426696777344, "training_acc": 52.5, "val_loss": 13.776415586471558, "val_acc": 55.0}
{"epoch": 30, "training_loss": 55.38008117675781, "training_acc": 52.5, "val_loss": 13.777397871017456, "val_acc": 55.0}
{"epoch": 31, "training_loss": 55.291924476623535, "training_acc": 52.5, "val_loss": 13.809270858764648, "val_acc": 55.0}
{"epoch": 32, "training_loss": 55.18966865539551, "training_acc": 52.5, "val_loss": 13.881820440292358, "val_acc": 55.0}
{"epoch": 33, "training_loss": 55.46227741241455, "training_acc": 47.5, "val_loss": 13.95565152168274, "val_acc": 55.0}
{"epoch": 34, "training_loss": 55.67679214477539, "training_acc": 47.5, "val_loss": 13.970330953598022, "val_acc": 55.0}
{"epoch": 35, "training_loss": 55.638715744018555, "training_acc": 47.5, "val_loss": 13.929266929626465, "val_acc": 55.0}
{"epoch": 36, "training_loss": 55.509864807128906, "training_acc": 47.5, "val_loss": 13.88706922531128, "val_acc": 55.0}
{"epoch": 37, "training_loss": 55.478915214538574, "training_acc": 51.25, "val_loss": 13.856124877929688, "val_acc": 55.0}
{"epoch": 38, "training_loss": 55.33426856994629, "training_acc": 60.0, "val_loss": 13.828848600387573, "val_acc": 55.0}
{"epoch": 39, "training_loss": 55.27448749542236, "training_acc": 52.5, "val_loss": 13.798192739486694, "val_acc": 55.0}
{"epoch": 40, "training_loss": 55.36491394042969, "training_acc": 52.5, "val_loss": 13.78711462020874, "val_acc": 55.0}
{"epoch": 41, "training_loss": 55.29857921600342, "training_acc": 52.5, "val_loss": 13.793190717697144, "val_acc": 55.0}
