"main_optuna_fix_3.py --pretrained_path None --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3 --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 55.32796859741211, "training_acc": 53.75, "val_loss": 13.931581974029541, "val_acc": 50.0}
{"epoch": 1, "training_loss": 56.04914474487305, "training_acc": 43.75, "val_loss": 13.893111944198608, "val_acc": 50.0}
{"epoch": 2, "training_loss": 55.3189697265625, "training_acc": 53.75, "val_loss": 14.088300466537476, "val_acc": 50.0}
{"epoch": 3, "training_loss": 55.55377006530762, "training_acc": 53.75, "val_loss": 14.088491201400757, "val_acc": 50.0}
{"epoch": 4, "training_loss": 55.43990707397461, "training_acc": 53.75, "val_loss": 13.94670844078064, "val_acc": 50.0}
{"epoch": 5, "training_loss": 55.128132820129395, "training_acc": 53.75, "val_loss": 13.869900703430176, "val_acc": 50.0}
{"epoch": 6, "training_loss": 55.3490104675293, "training_acc": 51.25, "val_loss": 13.877570629119873, "val_acc": 50.0}
{"epoch": 7, "training_loss": 55.59203338623047, "training_acc": 46.25, "val_loss": 13.882524967193604, "val_acc": 50.0}
{"epoch": 8, "training_loss": 55.63486862182617, "training_acc": 46.25, "val_loss": 13.876498937606812, "val_acc": 50.0}
{"epoch": 9, "training_loss": 55.55522918701172, "training_acc": 46.25, "val_loss": 13.868519067764282, "val_acc": 50.0}
{"epoch": 10, "training_loss": 55.33768844604492, "training_acc": 53.75, "val_loss": 13.886953592300415, "val_acc": 50.0}
{"epoch": 11, "training_loss": 55.17208480834961, "training_acc": 53.75, "val_loss": 13.95570158958435, "val_acc": 50.0}
{"epoch": 12, "training_loss": 55.184600830078125, "training_acc": 53.75, "val_loss": 14.080108404159546, "val_acc": 50.0}
{"epoch": 13, "training_loss": 55.421817779541016, "training_acc": 53.75, "val_loss": 14.224213361740112, "val_acc": 50.0}
{"epoch": 14, "training_loss": 55.78434371948242, "training_acc": 53.75, "val_loss": 14.373050928115845, "val_acc": 50.0}
{"epoch": 15, "training_loss": 56.18151378631592, "training_acc": 53.75, "val_loss": 14.453123807907104, "val_acc": 50.0}
{"epoch": 16, "training_loss": 56.43848705291748, "training_acc": 53.75, "val_loss": 14.353187084197998, "val_acc": 50.0}
{"epoch": 17, "training_loss": 56.03680896759033, "training_acc": 53.75, "val_loss": 14.158601760864258, "val_acc": 50.0}
{"epoch": 18, "training_loss": 55.6389102935791, "training_acc": 53.75, "val_loss": 13.990896940231323, "val_acc": 50.0}
{"epoch": 19, "training_loss": 55.14677429199219, "training_acc": 53.75, "val_loss": 13.90062689781189, "val_acc": 50.0}
{"epoch": 20, "training_loss": 55.12536811828613, "training_acc": 53.75, "val_loss": 13.875919580459595, "val_acc": 50.0}
{"epoch": 21, "training_loss": 55.60340118408203, "training_acc": 46.25, "val_loss": 13.901479244232178, "val_acc": 50.0}
{"epoch": 22, "training_loss": 55.80113220214844, "training_acc": 46.25, "val_loss": 13.885034322738647, "val_acc": 50.0}
{"epoch": 23, "training_loss": 55.60658264160156, "training_acc": 46.25, "val_loss": 13.872140645980835, "val_acc": 50.0}
{"epoch": 24, "training_loss": 55.35615253448486, "training_acc": 52.5, "val_loss": 13.884754180908203, "val_acc": 50.0}
{"epoch": 25, "training_loss": 55.21976280212402, "training_acc": 53.75, "val_loss": 13.90671968460083, "val_acc": 50.0}
{"epoch": 26, "training_loss": 55.1962251663208, "training_acc": 53.75, "val_loss": 13.932182788848877, "val_acc": 50.0}
{"epoch": 27, "training_loss": 55.213979721069336, "training_acc": 53.75, "val_loss": 13.961883783340454, "val_acc": 50.0}
{"epoch": 28, "training_loss": 55.27935028076172, "training_acc": 53.75, "val_loss": 13.984564542770386, "val_acc": 50.0}
{"epoch": 29, "training_loss": 55.253811836242676, "training_acc": 53.75, "val_loss": 13.97412657737732, "val_acc": 50.0}
{"epoch": 30, "training_loss": 55.22088432312012, "training_acc": 53.75, "val_loss": 13.962730169296265, "val_acc": 50.0}
{"epoch": 31, "training_loss": 55.21720218658447, "training_acc": 53.75, "val_loss": 13.94739031791687, "val_acc": 50.0}
{"epoch": 32, "training_loss": 55.1854772567749, "training_acc": 53.75, "val_loss": 13.927208185195923, "val_acc": 50.0}
{"epoch": 33, "training_loss": 55.196964263916016, "training_acc": 53.75, "val_loss": 13.914943933486938, "val_acc": 50.0}
{"epoch": 34, "training_loss": 55.2152624130249, "training_acc": 53.75, "val_loss": 13.921711444854736, "val_acc": 50.0}
{"epoch": 35, "training_loss": 55.20726490020752, "training_acc": 53.75, "val_loss": 13.930301666259766, "val_acc": 50.0}
{"epoch": 36, "training_loss": 55.143001556396484, "training_acc": 53.75, "val_loss": 13.923643827438354, "val_acc": 50.0}
{"epoch": 37, "training_loss": 55.18220329284668, "training_acc": 53.75, "val_loss": 13.907067775726318, "val_acc": 50.0}
{"epoch": 38, "training_loss": 55.168352127075195, "training_acc": 53.75, "val_loss": 13.889074325561523, "val_acc": 50.0}
{"epoch": 39, "training_loss": 55.227850914001465, "training_acc": 53.75, "val_loss": 13.884403705596924, "val_acc": 50.0}
{"epoch": 40, "training_loss": 55.19721508026123, "training_acc": 53.75, "val_loss": 13.887408971786499, "val_acc": 50.0}
{"epoch": 41, "training_loss": 55.24514198303223, "training_acc": 53.75, "val_loss": 13.890210390090942, "val_acc": 50.0}
{"epoch": 42, "training_loss": 55.18182373046875, "training_acc": 53.75, "val_loss": 13.888558149337769, "val_acc": 50.0}
{"epoch": 43, "training_loss": 55.16478157043457, "training_acc": 53.75, "val_loss": 13.896756172180176, "val_acc": 50.0}
{"epoch": 44, "training_loss": 55.226131439208984, "training_acc": 53.75, "val_loss": 13.907356262207031, "val_acc": 50.0}
{"epoch": 45, "training_loss": 55.15435791015625, "training_acc": 53.75, "val_loss": 13.906887769699097, "val_acc": 50.0}
{"epoch": 46, "training_loss": 55.143714904785156, "training_acc": 53.75, "val_loss": 13.915537595748901, "val_acc": 50.0}
{"epoch": 47, "training_loss": 55.11431121826172, "training_acc": 53.75, "val_loss": 13.937442302703857, "val_acc": 50.0}
