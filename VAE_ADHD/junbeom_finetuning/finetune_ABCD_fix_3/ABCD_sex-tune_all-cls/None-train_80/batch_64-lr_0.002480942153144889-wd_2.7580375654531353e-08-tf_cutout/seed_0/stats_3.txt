"main_optuna_fix_3.py --pretrained_path None --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3 --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 108.83876037597656, "training_acc": 53.75, "val_loss": 335.86536407470703, "val_acc": 45.0}
{"epoch": 1, "training_loss": 1458.096923828125, "training_acc": 55.0, "val_loss": 27.555959224700928, "val_acc": 55.0}
{"epoch": 2, "training_loss": 105.43750762939453, "training_acc": 52.5, "val_loss": 13.901443481445312, "val_acc": 55.0}
{"epoch": 3, "training_loss": 55.630953788757324, "training_acc": 47.5, "val_loss": 13.802908658981323, "val_acc": 55.0}
{"epoch": 4, "training_loss": 61.391197204589844, "training_acc": 47.5, "val_loss": 13.765201568603516, "val_acc": 55.0}
{"epoch": 5, "training_loss": 55.424110412597656, "training_acc": 52.5, "val_loss": 13.838270902633667, "val_acc": 55.0}
{"epoch": 6, "training_loss": 56.03202438354492, "training_acc": 52.5, "val_loss": 13.766787052154541, "val_acc": 55.0}
{"epoch": 7, "training_loss": 55.43408966064453, "training_acc": 52.5, "val_loss": 13.886271715164185, "val_acc": 55.0}
{"epoch": 8, "training_loss": 55.66414928436279, "training_acc": 42.5, "val_loss": 14.058283567428589, "val_acc": 55.0}
{"epoch": 9, "training_loss": 55.95250988006592, "training_acc": 47.5, "val_loss": 14.014540910720825, "val_acc": 55.0}
{"epoch": 10, "training_loss": 55.67381000518799, "training_acc": 47.5, "val_loss": 13.785735368728638, "val_acc": 55.0}
{"epoch": 11, "training_loss": 55.20265197753906, "training_acc": 52.5, "val_loss": 13.929938077926636, "val_acc": 55.0}
{"epoch": 12, "training_loss": 56.64108848571777, "training_acc": 52.5, "val_loss": 13.765347003936768, "val_acc": 55.0}
{"epoch": 13, "training_loss": 55.53245162963867, "training_acc": 52.5, "val_loss": 13.813004493713379, "val_acc": 55.0}
{"epoch": 14, "training_loss": 55.361202239990234, "training_acc": 52.5, "val_loss": 13.836091756820679, "val_acc": 55.0}
{"epoch": 15, "training_loss": 55.47612953186035, "training_acc": 52.5, "val_loss": 13.818645477294922, "val_acc": 55.0}
{"epoch": 16, "training_loss": 55.2830114364624, "training_acc": 52.5, "val_loss": 13.767282962799072, "val_acc": 55.0}
{"epoch": 17, "training_loss": 55.90299415588379, "training_acc": 52.5, "val_loss": 13.768384456634521, "val_acc": 55.0}
{"epoch": 18, "training_loss": 55.40229892730713, "training_acc": 52.5, "val_loss": 13.787038326263428, "val_acc": 55.0}
{"epoch": 19, "training_loss": 55.31468200683594, "training_acc": 52.5, "val_loss": 13.8289475440979, "val_acc": 55.0}
{"epoch": 20, "training_loss": 55.42004203796387, "training_acc": 52.5, "val_loss": 13.858722448348999, "val_acc": 55.0}
{"epoch": 21, "training_loss": 55.44485950469971, "training_acc": 52.5, "val_loss": 13.84600043296814, "val_acc": 55.0}
{"epoch": 22, "training_loss": 55.410940170288086, "training_acc": 52.5, "val_loss": 13.81201982498169, "val_acc": 55.0}
{"epoch": 23, "training_loss": 55.34807205200195, "training_acc": 52.5, "val_loss": 13.771603107452393, "val_acc": 55.0}
{"epoch": 24, "training_loss": 55.345004081726074, "training_acc": 52.5, "val_loss": 13.770906925201416, "val_acc": 55.0}
{"epoch": 25, "training_loss": 55.5422945022583, "training_acc": 52.5, "val_loss": 13.899197578430176, "val_acc": 55.0}
{"epoch": 26, "training_loss": 56.45447540283203, "training_acc": 52.5, "val_loss": 13.841527700424194, "val_acc": 55.0}
{"epoch": 27, "training_loss": 56.06085395812988, "training_acc": 52.5, "val_loss": 13.76878023147583, "val_acc": 55.0}
{"epoch": 28, "training_loss": 55.45737648010254, "training_acc": 52.5, "val_loss": 13.773294687271118, "val_acc": 55.0}
{"epoch": 29, "training_loss": 55.39484977722168, "training_acc": 52.5, "val_loss": 13.809480667114258, "val_acc": 55.0}
{"epoch": 30, "training_loss": 55.36026382446289, "training_acc": 52.5, "val_loss": 13.826521635055542, "val_acc": 55.0}
{"epoch": 31, "training_loss": 55.38389778137207, "training_acc": 52.5, "val_loss": 13.842698335647583, "val_acc": 55.0}
{"epoch": 32, "training_loss": 55.41569709777832, "training_acc": 52.5, "val_loss": 13.865681886672974, "val_acc": 55.0}
{"epoch": 33, "training_loss": 55.465396881103516, "training_acc": 47.5, "val_loss": 13.869994878768921, "val_acc": 55.0}
{"epoch": 34, "training_loss": 55.457518577575684, "training_acc": 47.5, "val_loss": 13.850685358047485, "val_acc": 55.0}
{"epoch": 35, "training_loss": 55.446685791015625, "training_acc": 52.5, "val_loss": 13.83086085319519, "val_acc": 55.0}
{"epoch": 36, "training_loss": 55.38837814331055, "training_acc": 52.5, "val_loss": 13.816114664077759, "val_acc": 55.0}
{"epoch": 37, "training_loss": 55.3778715133667, "training_acc": 52.5, "val_loss": 13.798167705535889, "val_acc": 55.0}
{"epoch": 38, "training_loss": 55.35149383544922, "training_acc": 52.5, "val_loss": 13.786312341690063, "val_acc": 55.0}
{"epoch": 39, "training_loss": 55.3450927734375, "training_acc": 52.5, "val_loss": 13.77567172050476, "val_acc": 55.0}
{"epoch": 40, "training_loss": 55.3708381652832, "training_acc": 52.5, "val_loss": 13.770041465759277, "val_acc": 55.0}
{"epoch": 41, "training_loss": 55.38335990905762, "training_acc": 52.5, "val_loss": 13.77202033996582, "val_acc": 55.0}
{"epoch": 42, "training_loss": 55.371235847473145, "training_acc": 52.5, "val_loss": 13.778704404830933, "val_acc": 55.0}
{"epoch": 43, "training_loss": 55.356186866760254, "training_acc": 52.5, "val_loss": 13.78421664237976, "val_acc": 55.0}
{"epoch": 44, "training_loss": 55.346675872802734, "training_acc": 52.5, "val_loss": 13.793011903762817, "val_acc": 55.0}
{"epoch": 45, "training_loss": 55.33925247192383, "training_acc": 52.5, "val_loss": 13.80724549293518, "val_acc": 55.0}
{"epoch": 46, "training_loss": 55.360114097595215, "training_acc": 52.5, "val_loss": 13.823093175888062, "val_acc": 55.0}
{"epoch": 47, "training_loss": 55.389960289001465, "training_acc": 52.5, "val_loss": 13.832415342330933, "val_acc": 55.0}
{"epoch": 48, "training_loss": 55.40192794799805, "training_acc": 52.5, "val_loss": 13.829383850097656, "val_acc": 55.0}
{"epoch": 49, "training_loss": 55.40075492858887, "training_acc": 52.5, "val_loss": 13.82145881652832, "val_acc": 55.0}
{"epoch": 50, "training_loss": 55.384891510009766, "training_acc": 52.5, "val_loss": 13.819611072540283, "val_acc": 55.0}
