"main_optuna_fix_3.py --pretrained_path None --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3 --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 96.61880111694336, "training_acc": 52.5, "val_loss": 1550.3434753417969, "val_acc": 45.0}
{"epoch": 1, "training_loss": 4338.6069412231445, "training_acc": 55.0, "val_loss": 20.576634407043457, "val_acc": 55.0}
{"epoch": 2, "training_loss": 83.10037231445312, "training_acc": 50.0, "val_loss": 13.83458137512207, "val_acc": 55.0}
{"epoch": 3, "training_loss": 60.52561950683594, "training_acc": 52.5, "val_loss": 15.511640310287476, "val_acc": 45.0}
{"epoch": 4, "training_loss": 60.87386131286621, "training_acc": 47.5, "val_loss": 14.411958456039429, "val_acc": 55.0}
{"epoch": 5, "training_loss": 56.6761531829834, "training_acc": 47.5, "val_loss": 13.776317834854126, "val_acc": 55.0}
{"epoch": 6, "training_loss": 55.37105941772461, "training_acc": 52.5, "val_loss": 13.906363248825073, "val_acc": 55.0}
{"epoch": 7, "training_loss": 56.20130920410156, "training_acc": 52.5, "val_loss": 13.930079936981201, "val_acc": 55.0}
{"epoch": 8, "training_loss": 55.585519790649414, "training_acc": 47.5, "val_loss": 14.227970838546753, "val_acc": 55.0}
{"epoch": 9, "training_loss": 56.42562484741211, "training_acc": 47.5, "val_loss": 14.052437543869019, "val_acc": 55.0}
{"epoch": 10, "training_loss": 55.74034881591797, "training_acc": 47.5, "val_loss": 13.804086446762085, "val_acc": 55.0}
{"epoch": 11, "training_loss": 55.22135925292969, "training_acc": 52.5, "val_loss": 13.790960311889648, "val_acc": 55.0}
{"epoch": 12, "training_loss": 55.979312896728516, "training_acc": 52.5, "val_loss": 13.772677183151245, "val_acc": 55.0}
{"epoch": 13, "training_loss": 55.61093997955322, "training_acc": 52.5, "val_loss": 13.776006698608398, "val_acc": 55.0}
{"epoch": 14, "training_loss": 55.33020210266113, "training_acc": 52.5, "val_loss": 13.822178840637207, "val_acc": 55.0}
{"epoch": 15, "training_loss": 55.54498100280762, "training_acc": 45.0, "val_loss": 13.842926025390625, "val_acc": 55.0}
{"epoch": 16, "training_loss": 55.36271858215332, "training_acc": 52.5, "val_loss": 13.783282041549683, "val_acc": 55.0}
{"epoch": 17, "training_loss": 55.45565319061279, "training_acc": 52.5, "val_loss": 13.76316785812378, "val_acc": 55.0}
{"epoch": 18, "training_loss": 55.45257759094238, "training_acc": 52.5, "val_loss": 13.764873743057251, "val_acc": 55.0}
{"epoch": 19, "training_loss": 55.37113380432129, "training_acc": 52.5, "val_loss": 13.779021501541138, "val_acc": 55.0}
{"epoch": 20, "training_loss": 55.375115394592285, "training_acc": 52.5, "val_loss": 13.798888921737671, "val_acc": 55.0}
{"epoch": 21, "training_loss": 55.35939979553223, "training_acc": 52.5, "val_loss": 13.807404041290283, "val_acc": 55.0}
{"epoch": 22, "training_loss": 55.3643913269043, "training_acc": 52.5, "val_loss": 13.807305097579956, "val_acc": 55.0}
{"epoch": 23, "training_loss": 55.357404708862305, "training_acc": 52.5, "val_loss": 13.790087699890137, "val_acc": 55.0}
{"epoch": 24, "training_loss": 55.34043502807617, "training_acc": 52.5, "val_loss": 13.766306638717651, "val_acc": 55.0}
{"epoch": 25, "training_loss": 55.293161392211914, "training_acc": 52.5, "val_loss": 13.804817199707031, "val_acc": 55.0}
{"epoch": 26, "training_loss": 55.82175254821777, "training_acc": 52.5, "val_loss": 13.901742696762085, "val_acc": 55.0}
{"epoch": 27, "training_loss": 56.31650257110596, "training_acc": 52.5, "val_loss": 13.782700300216675, "val_acc": 55.0}
{"epoch": 28, "training_loss": 55.548495292663574, "training_acc": 52.5, "val_loss": 13.768417835235596, "val_acc": 55.0}
{"epoch": 29, "training_loss": 55.40517616271973, "training_acc": 52.5, "val_loss": 13.802036046981812, "val_acc": 55.0}
{"epoch": 30, "training_loss": 55.363800048828125, "training_acc": 52.5, "val_loss": 13.82205843925476, "val_acc": 55.0}
{"epoch": 31, "training_loss": 55.38066482543945, "training_acc": 52.5, "val_loss": 13.847450017929077, "val_acc": 55.0}
{"epoch": 32, "training_loss": 55.43677234649658, "training_acc": 48.75, "val_loss": 13.883001804351807, "val_acc": 55.0}
{"epoch": 33, "training_loss": 55.49553680419922, "training_acc": 47.5, "val_loss": 13.873811960220337, "val_acc": 55.0}
{"epoch": 34, "training_loss": 55.453651428222656, "training_acc": 50.0, "val_loss": 13.83521556854248, "val_acc": 55.0}
{"epoch": 35, "training_loss": 55.43192005157471, "training_acc": 52.5, "val_loss": 13.812092542648315, "val_acc": 55.0}
{"epoch": 36, "training_loss": 55.37079906463623, "training_acc": 52.5, "val_loss": 13.800162076950073, "val_acc": 55.0}
{"epoch": 37, "training_loss": 55.36454105377197, "training_acc": 52.5, "val_loss": 13.784077167510986, "val_acc": 55.0}
{"epoch": 38, "training_loss": 55.349721908569336, "training_acc": 52.5, "val_loss": 13.77573013305664, "val_acc": 55.0}
{"epoch": 39, "training_loss": 55.35523223876953, "training_acc": 52.5, "val_loss": 13.768638372421265, "val_acc": 55.0}
{"epoch": 40, "training_loss": 55.3875617980957, "training_acc": 52.5, "val_loss": 13.76710295677185, "val_acc": 55.0}
{"epoch": 41, "training_loss": 55.38460636138916, "training_acc": 52.5, "val_loss": 13.776110410690308, "val_acc": 55.0}
