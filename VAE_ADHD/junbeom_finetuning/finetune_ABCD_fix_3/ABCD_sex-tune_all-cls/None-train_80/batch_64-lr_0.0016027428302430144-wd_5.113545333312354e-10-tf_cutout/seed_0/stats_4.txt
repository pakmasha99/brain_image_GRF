"main_optuna_fix_3.py --pretrained_path None --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3 --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 83.41923522949219, "training_acc": 52.5, "val_loss": 131.80508613586426, "val_acc": 45.0}
{"epoch": 1, "training_loss": 404.4785690307617, "training_acc": 55.0, "val_loss": 15.192626714706421, "val_acc": 55.0}
{"epoch": 2, "training_loss": 64.64462184906006, "training_acc": 45.0, "val_loss": 13.866192102432251, "val_acc": 55.0}
{"epoch": 3, "training_loss": 55.66410541534424, "training_acc": 45.0, "val_loss": 13.879739046096802, "val_acc": 55.0}
{"epoch": 4, "training_loss": 55.62981986999512, "training_acc": 47.5, "val_loss": 13.782713413238525, "val_acc": 55.0}
{"epoch": 5, "training_loss": 55.68409061431885, "training_acc": 52.5, "val_loss": 13.832241296768188, "val_acc": 55.0}
{"epoch": 6, "training_loss": 55.5056266784668, "training_acc": 50.0, "val_loss": 13.908666372299194, "val_acc": 55.0}
{"epoch": 7, "training_loss": 55.54536056518555, "training_acc": 47.5, "val_loss": 13.830258846282959, "val_acc": 55.0}
{"epoch": 8, "training_loss": 55.54069423675537, "training_acc": 52.5, "val_loss": 13.829174041748047, "val_acc": 55.0}
{"epoch": 9, "training_loss": 55.58007049560547, "training_acc": 45.0, "val_loss": 13.836427927017212, "val_acc": 55.0}
{"epoch": 10, "training_loss": 55.37852954864502, "training_acc": 52.5, "val_loss": 13.78221869468689, "val_acc": 55.0}
{"epoch": 11, "training_loss": 55.30386829376221, "training_acc": 52.5, "val_loss": 13.766717910766602, "val_acc": 55.0}
{"epoch": 12, "training_loss": 55.66552448272705, "training_acc": 52.5, "val_loss": 13.78165602684021, "val_acc": 55.0}
{"epoch": 13, "training_loss": 55.69501304626465, "training_acc": 52.5, "val_loss": 13.763468265533447, "val_acc": 55.0}
{"epoch": 14, "training_loss": 55.363054275512695, "training_acc": 52.5, "val_loss": 13.7865149974823, "val_acc": 55.0}
{"epoch": 15, "training_loss": 55.43178367614746, "training_acc": 52.5, "val_loss": 13.820704221725464, "val_acc": 55.0}
{"epoch": 16, "training_loss": 55.439175605773926, "training_acc": 52.5, "val_loss": 13.806437253952026, "val_acc": 55.0}
{"epoch": 17, "training_loss": 55.37209129333496, "training_acc": 52.5, "val_loss": 13.780444860458374, "val_acc": 55.0}
{"epoch": 18, "training_loss": 55.3806734085083, "training_acc": 52.5, "val_loss": 13.774820566177368, "val_acc": 55.0}
{"epoch": 19, "training_loss": 55.36014366149902, "training_acc": 52.5, "val_loss": 13.78184199333191, "val_acc": 55.0}
{"epoch": 20, "training_loss": 55.34696388244629, "training_acc": 52.5, "val_loss": 13.797118663787842, "val_acc": 55.0}
{"epoch": 21, "training_loss": 55.36519908905029, "training_acc": 52.5, "val_loss": 13.809584379196167, "val_acc": 55.0}
{"epoch": 22, "training_loss": 55.36310958862305, "training_acc": 52.5, "val_loss": 13.813432455062866, "val_acc": 55.0}
{"epoch": 23, "training_loss": 55.37837791442871, "training_acc": 52.5, "val_loss": 13.808475732803345, "val_acc": 55.0}
{"epoch": 24, "training_loss": 55.36594009399414, "training_acc": 52.5, "val_loss": 13.7949800491333, "val_acc": 55.0}
