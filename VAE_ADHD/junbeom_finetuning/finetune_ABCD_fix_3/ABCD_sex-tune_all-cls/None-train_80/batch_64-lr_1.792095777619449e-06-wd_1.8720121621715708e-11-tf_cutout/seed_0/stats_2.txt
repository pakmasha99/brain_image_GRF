"main_optuna_fix_3.py --pretrained_path None --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3 --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 55.356581687927246, "training_acc": 52.5, "val_loss": 13.77278208732605, "val_acc": 55.0}
{"epoch": 1, "training_loss": 55.35525417327881, "training_acc": 52.5, "val_loss": 13.772972822189331, "val_acc": 55.0}
{"epoch": 2, "training_loss": 55.35719871520996, "training_acc": 52.5, "val_loss": 13.771628141403198, "val_acc": 55.0}
{"epoch": 3, "training_loss": 55.30886459350586, "training_acc": 52.5, "val_loss": 13.76906156539917, "val_acc": 55.0}
{"epoch": 4, "training_loss": 55.34858798980713, "training_acc": 52.5, "val_loss": 13.767633438110352, "val_acc": 55.0}
{"epoch": 5, "training_loss": 55.36065101623535, "training_acc": 52.5, "val_loss": 13.768304586410522, "val_acc": 55.0}
{"epoch": 6, "training_loss": 55.35854911804199, "training_acc": 52.5, "val_loss": 13.768242597579956, "val_acc": 55.0}
{"epoch": 7, "training_loss": 55.373722076416016, "training_acc": 52.5, "val_loss": 13.766900300979614, "val_acc": 55.0}
{"epoch": 8, "training_loss": 55.378167152404785, "training_acc": 52.5, "val_loss": 13.766281604766846, "val_acc": 55.0}
{"epoch": 9, "training_loss": 55.33065891265869, "training_acc": 52.5, "val_loss": 13.76659631729126, "val_acc": 55.0}
{"epoch": 10, "training_loss": 55.36323833465576, "training_acc": 52.5, "val_loss": 13.767484426498413, "val_acc": 55.0}
{"epoch": 11, "training_loss": 55.31938648223877, "training_acc": 52.5, "val_loss": 13.768593072891235, "val_acc": 55.0}
{"epoch": 12, "training_loss": 55.36281108856201, "training_acc": 52.5, "val_loss": 13.77016305923462, "val_acc": 55.0}
{"epoch": 13, "training_loss": 55.327850341796875, "training_acc": 52.5, "val_loss": 13.771812915802002, "val_acc": 55.0}
{"epoch": 14, "training_loss": 55.348426818847656, "training_acc": 52.5, "val_loss": 13.773075342178345, "val_acc": 55.0}
{"epoch": 15, "training_loss": 55.33818435668945, "training_acc": 52.5, "val_loss": 13.772720098495483, "val_acc": 55.0}
{"epoch": 16, "training_loss": 55.34742832183838, "training_acc": 52.5, "val_loss": 13.771251440048218, "val_acc": 55.0}
{"epoch": 17, "training_loss": 55.37917137145996, "training_acc": 52.5, "val_loss": 13.770016431808472, "val_acc": 55.0}
{"epoch": 18, "training_loss": 55.302109718322754, "training_acc": 52.5, "val_loss": 13.769837617874146, "val_acc": 55.0}
{"epoch": 19, "training_loss": 55.31467247009277, "training_acc": 52.5, "val_loss": 13.77041220664978, "val_acc": 55.0}
{"epoch": 20, "training_loss": 55.32681465148926, "training_acc": 52.5, "val_loss": 13.77029299736023, "val_acc": 55.0}
{"epoch": 21, "training_loss": 55.30430793762207, "training_acc": 52.5, "val_loss": 13.769065141677856, "val_acc": 55.0}
{"epoch": 22, "training_loss": 55.331833839416504, "training_acc": 52.5, "val_loss": 13.767664432525635, "val_acc": 55.0}
{"epoch": 23, "training_loss": 55.30789756774902, "training_acc": 52.5, "val_loss": 13.766415119171143, "val_acc": 55.0}
{"epoch": 24, "training_loss": 55.29280471801758, "training_acc": 52.5, "val_loss": 13.765113353729248, "val_acc": 55.0}
{"epoch": 25, "training_loss": 55.3090124130249, "training_acc": 52.5, "val_loss": 13.762902021408081, "val_acc": 55.0}
{"epoch": 26, "training_loss": 55.30902576446533, "training_acc": 52.5, "val_loss": 13.76083254814148, "val_acc": 55.0}
{"epoch": 27, "training_loss": 55.28070068359375, "training_acc": 52.5, "val_loss": 13.758798837661743, "val_acc": 55.0}
{"epoch": 28, "training_loss": 55.343894958496094, "training_acc": 52.5, "val_loss": 13.757768869400024, "val_acc": 55.0}
{"epoch": 29, "training_loss": 55.30035591125488, "training_acc": 52.5, "val_loss": 13.757655620574951, "val_acc": 55.0}
{"epoch": 30, "training_loss": 55.259066581726074, "training_acc": 52.5, "val_loss": 13.75731110572815, "val_acc": 55.0}
{"epoch": 31, "training_loss": 55.35166072845459, "training_acc": 52.5, "val_loss": 13.757208585739136, "val_acc": 55.0}
{"epoch": 32, "training_loss": 55.26022911071777, "training_acc": 52.5, "val_loss": 13.757944107055664, "val_acc": 55.0}
{"epoch": 33, "training_loss": 55.335808753967285, "training_acc": 52.5, "val_loss": 13.759608268737793, "val_acc": 55.0}
{"epoch": 34, "training_loss": 55.348487854003906, "training_acc": 52.5, "val_loss": 13.762449026107788, "val_acc": 55.0}
{"epoch": 35, "training_loss": 55.23483943939209, "training_acc": 52.5, "val_loss": 13.76552939414978, "val_acc": 55.0}
{"epoch": 36, "training_loss": 55.259002685546875, "training_acc": 52.5, "val_loss": 13.768036365509033, "val_acc": 55.0}
{"epoch": 37, "training_loss": 55.27975940704346, "training_acc": 52.5, "val_loss": 13.77157211303711, "val_acc": 55.0}
{"epoch": 38, "training_loss": 55.26019477844238, "training_acc": 52.5, "val_loss": 13.77516508102417, "val_acc": 55.0}
{"epoch": 39, "training_loss": 55.24046325683594, "training_acc": 52.5, "val_loss": 13.777109384536743, "val_acc": 55.0}
{"epoch": 40, "training_loss": 55.28723907470703, "training_acc": 52.5, "val_loss": 13.779349327087402, "val_acc": 55.0}
{"epoch": 41, "training_loss": 55.312933921813965, "training_acc": 52.5, "val_loss": 13.783460855484009, "val_acc": 55.0}
{"epoch": 42, "training_loss": 55.327579498291016, "training_acc": 52.5, "val_loss": 13.78785490989685, "val_acc": 55.0}
{"epoch": 43, "training_loss": 55.26133346557617, "training_acc": 52.5, "val_loss": 13.791135549545288, "val_acc": 55.0}
{"epoch": 44, "training_loss": 55.28354835510254, "training_acc": 52.5, "val_loss": 13.794711828231812, "val_acc": 55.0}
{"epoch": 45, "training_loss": 55.263105392456055, "training_acc": 52.5, "val_loss": 13.798784017562866, "val_acc": 55.0}
{"epoch": 46, "training_loss": 55.3325138092041, "training_acc": 52.5, "val_loss": 13.8026762008667, "val_acc": 55.0}
{"epoch": 47, "training_loss": 55.31743240356445, "training_acc": 52.5, "val_loss": 13.805564641952515, "val_acc": 55.0}
{"epoch": 48, "training_loss": 55.26546669006348, "training_acc": 52.5, "val_loss": 13.805338144302368, "val_acc": 55.0}
{"epoch": 49, "training_loss": 55.24710464477539, "training_acc": 52.5, "val_loss": 13.803281784057617, "val_acc": 55.0}
{"epoch": 50, "training_loss": 55.32432460784912, "training_acc": 52.5, "val_loss": 13.801567554473877, "val_acc": 55.0}
{"epoch": 51, "training_loss": 55.25647735595703, "training_acc": 52.5, "val_loss": 13.799222707748413, "val_acc": 55.0}
