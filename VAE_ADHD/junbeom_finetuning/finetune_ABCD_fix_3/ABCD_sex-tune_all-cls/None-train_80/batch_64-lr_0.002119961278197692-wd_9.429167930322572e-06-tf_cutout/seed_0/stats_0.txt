"main_optuna_fix_3.py --pretrained_path None --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3 --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 58.29140663146973, "training_acc": 53.75, "val_loss": 3469.1336059570312, "val_acc": 50.0}
{"epoch": 1, "training_loss": 10730.258604049683, "training_acc": 46.25, "val_loss": 16.33519411087036, "val_acc": 50.0}
{"epoch": 2, "training_loss": 61.323330879211426, "training_acc": 53.75, "val_loss": 13.981417417526245, "val_acc": 50.0}
{"epoch": 3, "training_loss": 56.54185199737549, "training_acc": 46.25, "val_loss": 13.90090823173523, "val_acc": 50.0}
{"epoch": 4, "training_loss": 55.48267936706543, "training_acc": 53.75, "val_loss": 14.658844470977783, "val_acc": 50.0}
{"epoch": 5, "training_loss": 60.17691516876221, "training_acc": 43.75, "val_loss": 13.875844478607178, "val_acc": 50.0}
{"epoch": 6, "training_loss": 55.247406005859375, "training_acc": 53.75, "val_loss": 14.054750204086304, "val_acc": 50.0}
{"epoch": 7, "training_loss": 55.616355895996094, "training_acc": 53.75, "val_loss": 13.903555870056152, "val_acc": 50.0}
{"epoch": 8, "training_loss": 55.22114658355713, "training_acc": 53.75, "val_loss": 13.858927488327026, "val_acc": 50.0}
{"epoch": 9, "training_loss": 55.3767786026001, "training_acc": 53.75, "val_loss": 13.87036681175232, "val_acc": 50.0}
{"epoch": 10, "training_loss": 55.252174377441406, "training_acc": 53.75, "val_loss": 14.07983660697937, "val_acc": 50.0}
{"epoch": 11, "training_loss": 55.70453643798828, "training_acc": 53.75, "val_loss": 13.97370457649231, "val_acc": 50.0}
{"epoch": 12, "training_loss": 55.321372985839844, "training_acc": 53.75, "val_loss": 14.17949914932251, "val_acc": 50.0}
{"epoch": 13, "training_loss": 55.93702507019043, "training_acc": 53.75, "val_loss": 14.205163717269897, "val_acc": 50.0}
{"epoch": 14, "training_loss": 56.06441307067871, "training_acc": 53.75, "val_loss": 14.31300401687622, "val_acc": 50.0}
{"epoch": 15, "training_loss": 56.02893257141113, "training_acc": 53.75, "val_loss": 14.282585382461548, "val_acc": 50.0}
{"epoch": 16, "training_loss": 56.06147861480713, "training_acc": 53.75, "val_loss": 14.014047384262085, "val_acc": 50.0}
{"epoch": 17, "training_loss": 55.305137634277344, "training_acc": 53.75, "val_loss": 13.910716772079468, "val_acc": 50.0}
{"epoch": 18, "training_loss": 55.32478713989258, "training_acc": 53.75, "val_loss": 13.878008127212524, "val_acc": 50.0}
{"epoch": 19, "training_loss": 55.362924575805664, "training_acc": 53.75, "val_loss": 13.87069821357727, "val_acc": 50.0}
{"epoch": 20, "training_loss": 55.267706871032715, "training_acc": 53.75, "val_loss": 13.860759735107422, "val_acc": 50.0}
{"epoch": 21, "training_loss": 55.46634006500244, "training_acc": 48.75, "val_loss": 13.861758708953857, "val_acc": 50.0}
{"epoch": 22, "training_loss": 55.43950843811035, "training_acc": 53.75, "val_loss": 13.865718841552734, "val_acc": 50.0}
{"epoch": 23, "training_loss": 55.351935386657715, "training_acc": 53.75, "val_loss": 13.888195753097534, "val_acc": 50.0}
{"epoch": 24, "training_loss": 55.26553726196289, "training_acc": 53.75, "val_loss": 13.917127847671509, "val_acc": 50.0}
{"epoch": 25, "training_loss": 55.23934459686279, "training_acc": 53.75, "val_loss": 13.92435073852539, "val_acc": 50.0}
{"epoch": 26, "training_loss": 55.23259925842285, "training_acc": 53.75, "val_loss": 13.919036388397217, "val_acc": 50.0}
{"epoch": 27, "training_loss": 55.25467395782471, "training_acc": 53.75, "val_loss": 13.933659791946411, "val_acc": 50.0}
{"epoch": 28, "training_loss": 55.284361839294434, "training_acc": 53.75, "val_loss": 13.942463397979736, "val_acc": 50.0}
{"epoch": 29, "training_loss": 55.23947525024414, "training_acc": 53.75, "val_loss": 13.91705870628357, "val_acc": 50.0}
{"epoch": 30, "training_loss": 55.2275276184082, "training_acc": 53.75, "val_loss": 13.910294771194458, "val_acc": 50.0}
{"epoch": 31, "training_loss": 55.23319053649902, "training_acc": 53.75, "val_loss": 13.908442258834839, "val_acc": 50.0}
{"epoch": 32, "training_loss": 55.22370624542236, "training_acc": 53.75, "val_loss": 13.90066385269165, "val_acc": 50.0}
{"epoch": 33, "training_loss": 55.25039863586426, "training_acc": 53.75, "val_loss": 13.900072574615479, "val_acc": 50.0}
{"epoch": 34, "training_loss": 55.23086452484131, "training_acc": 53.75, "val_loss": 13.919702768325806, "val_acc": 50.0}
{"epoch": 35, "training_loss": 55.26841163635254, "training_acc": 53.75, "val_loss": 13.938463926315308, "val_acc": 50.0}
{"epoch": 36, "training_loss": 55.23189735412598, "training_acc": 53.75, "val_loss": 13.92924189567566, "val_acc": 50.0}
{"epoch": 37, "training_loss": 55.228943824768066, "training_acc": 53.75, "val_loss": 13.906774520874023, "val_acc": 50.0}
{"epoch": 38, "training_loss": 55.24150848388672, "training_acc": 53.75, "val_loss": 13.885574340820312, "val_acc": 50.0}
{"epoch": 39, "training_loss": 55.25998401641846, "training_acc": 53.75, "val_loss": 13.879976272583008, "val_acc": 50.0}
