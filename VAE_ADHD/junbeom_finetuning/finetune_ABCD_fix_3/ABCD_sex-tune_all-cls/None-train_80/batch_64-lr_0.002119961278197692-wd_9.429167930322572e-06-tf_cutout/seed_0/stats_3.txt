"main_optuna_fix_3.py --pretrained_path None --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3 --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 106.97961807250977, "training_acc": 50.0, "val_loss": 205.3960418701172, "val_acc": 45.0}
{"epoch": 1, "training_loss": 1230.695068359375, "training_acc": 55.0, "val_loss": 23.583707809448242, "val_acc": 55.0}
{"epoch": 2, "training_loss": 91.8390121459961, "training_acc": 52.5, "val_loss": 13.811910152435303, "val_acc": 55.0}
{"epoch": 3, "training_loss": 55.40390586853027, "training_acc": 52.5, "val_loss": 13.992124795913696, "val_acc": 55.0}
{"epoch": 4, "training_loss": 55.39131546020508, "training_acc": 52.5, "val_loss": 25.39449453353882, "val_acc": 45.0}
{"epoch": 5, "training_loss": 87.34757232666016, "training_acc": 50.0, "val_loss": 13.815956115722656, "val_acc": 55.0}
{"epoch": 6, "training_loss": 55.93663787841797, "training_acc": 52.5, "val_loss": 13.76354455947876, "val_acc": 55.0}
{"epoch": 7, "training_loss": 55.4307804107666, "training_acc": 52.5, "val_loss": 13.90570878982544, "val_acc": 55.0}
{"epoch": 8, "training_loss": 55.795681953430176, "training_acc": 42.5, "val_loss": 13.985593318939209, "val_acc": 55.0}
{"epoch": 9, "training_loss": 55.7506217956543, "training_acc": 47.5, "val_loss": 13.95343542098999, "val_acc": 55.0}
{"epoch": 10, "training_loss": 55.517337799072266, "training_acc": 47.5, "val_loss": 13.765554428100586, "val_acc": 55.0}
{"epoch": 11, "training_loss": 55.41068649291992, "training_acc": 52.5, "val_loss": 14.005402326583862, "val_acc": 55.0}
{"epoch": 12, "training_loss": 56.82609844207764, "training_acc": 52.5, "val_loss": 13.763586282730103, "val_acc": 55.0}
{"epoch": 13, "training_loss": 55.512733459472656, "training_acc": 52.5, "val_loss": 13.846874237060547, "val_acc": 55.0}
{"epoch": 14, "training_loss": 55.437110900878906, "training_acc": 52.5, "val_loss": 13.854116201400757, "val_acc": 55.0}
{"epoch": 15, "training_loss": 55.51003456115723, "training_acc": 45.0, "val_loss": 13.813514709472656, "val_acc": 55.0}
{"epoch": 16, "training_loss": 55.24533462524414, "training_acc": 52.5, "val_loss": 13.76657485961914, "val_acc": 55.0}
{"epoch": 17, "training_loss": 55.81973457336426, "training_acc": 52.5, "val_loss": 13.788907527923584, "val_acc": 55.0}
{"epoch": 18, "training_loss": 55.62270641326904, "training_acc": 52.5, "val_loss": 13.766998052597046, "val_acc": 55.0}
{"epoch": 19, "training_loss": 55.313100814819336, "training_acc": 52.5, "val_loss": 13.809798955917358, "val_acc": 55.0}
{"epoch": 20, "training_loss": 55.39249515533447, "training_acc": 52.5, "val_loss": 13.83765697479248, "val_acc": 55.0}
{"epoch": 21, "training_loss": 55.40690803527832, "training_acc": 52.5, "val_loss": 13.823606967926025, "val_acc": 55.0}
{"epoch": 22, "training_loss": 55.37419128417969, "training_acc": 52.5, "val_loss": 13.790701627731323, "val_acc": 55.0}
{"epoch": 23, "training_loss": 55.3375129699707, "training_acc": 52.5, "val_loss": 13.762876987457275, "val_acc": 55.0}
{"epoch": 24, "training_loss": 55.487932205200195, "training_acc": 52.5, "val_loss": 13.78366231918335, "val_acc": 55.0}
{"epoch": 25, "training_loss": 55.74820899963379, "training_acc": 52.5, "val_loss": 13.868201971054077, "val_acc": 55.0}
{"epoch": 26, "training_loss": 56.301764488220215, "training_acc": 52.5, "val_loss": 13.826929330825806, "val_acc": 55.0}
{"epoch": 27, "training_loss": 55.99286460876465, "training_acc": 52.5, "val_loss": 13.767080307006836, "val_acc": 55.0}
{"epoch": 28, "training_loss": 55.445302963256836, "training_acc": 52.5, "val_loss": 13.778311014175415, "val_acc": 55.0}
{"epoch": 29, "training_loss": 55.393972396850586, "training_acc": 52.5, "val_loss": 13.832601308822632, "val_acc": 55.0}
{"epoch": 30, "training_loss": 55.39179515838623, "training_acc": 52.5, "val_loss": 13.8609778881073, "val_acc": 55.0}
{"epoch": 31, "training_loss": 55.448856353759766, "training_acc": 53.75, "val_loss": 13.876274824142456, "val_acc": 55.0}
{"epoch": 32, "training_loss": 55.473753929138184, "training_acc": 47.5, "val_loss": 13.889354467391968, "val_acc": 55.0}
{"epoch": 33, "training_loss": 55.5122013092041, "training_acc": 47.5, "val_loss": 13.88440489768982, "val_acc": 55.0}
{"epoch": 34, "training_loss": 55.49162769317627, "training_acc": 47.5, "val_loss": 13.863002061843872, "val_acc": 55.0}
{"epoch": 35, "training_loss": 55.46569633483887, "training_acc": 52.5, "val_loss": 13.841499090194702, "val_acc": 55.0}
{"epoch": 36, "training_loss": 55.398343086242676, "training_acc": 52.5, "val_loss": 13.822773694992065, "val_acc": 55.0}
{"epoch": 37, "training_loss": 55.38907814025879, "training_acc": 52.5, "val_loss": 13.800392150878906, "val_acc": 55.0}
{"epoch": 38, "training_loss": 55.349504470825195, "training_acc": 52.5, "val_loss": 13.783801794052124, "val_acc": 55.0}
{"epoch": 39, "training_loss": 55.345011711120605, "training_acc": 52.5, "val_loss": 13.770946264266968, "val_acc": 55.0}
{"epoch": 40, "training_loss": 55.37990760803223, "training_acc": 52.5, "val_loss": 13.7661612033844, "val_acc": 55.0}
