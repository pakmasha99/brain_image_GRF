"main_optuna_fix_3.py --pretrained_path None --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3 --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 62.54736137390137, "training_acc": 41.25, "val_loss": 15.166863203048706, "val_acc": 50.0}
{"epoch": 1, "training_loss": 62.47073173522949, "training_acc": 46.25, "val_loss": 13.926931619644165, "val_acc": 50.0}
{"epoch": 2, "training_loss": 56.027987480163574, "training_acc": 48.75, "val_loss": 13.94099235534668, "val_acc": 50.0}
{"epoch": 3, "training_loss": 55.31351661682129, "training_acc": 53.75, "val_loss": 14.014959335327148, "val_acc": 50.0}
{"epoch": 4, "training_loss": 55.224897384643555, "training_acc": 53.75, "val_loss": 13.85769248008728, "val_acc": 50.0}
{"epoch": 5, "training_loss": 55.518646240234375, "training_acc": 50.0, "val_loss": 13.878611326217651, "val_acc": 50.0}
{"epoch": 6, "training_loss": 55.23665523529053, "training_acc": 53.75, "val_loss": 14.16987657546997, "val_acc": 50.0}
{"epoch": 7, "training_loss": 55.544992446899414, "training_acc": 53.75, "val_loss": 14.043039083480835, "val_acc": 50.0}
{"epoch": 8, "training_loss": 55.27628135681152, "training_acc": 53.75, "val_loss": 13.880738019943237, "val_acc": 50.0}
{"epoch": 9, "training_loss": 55.2457389831543, "training_acc": 53.75, "val_loss": 13.863743543624878, "val_acc": 50.0}
{"epoch": 10, "training_loss": 55.647329330444336, "training_acc": 46.25, "val_loss": 13.864792585372925, "val_acc": 50.0}
{"epoch": 11, "training_loss": 55.46586227416992, "training_acc": 48.75, "val_loss": 13.911689519882202, "val_acc": 50.0}
{"epoch": 12, "training_loss": 55.189308166503906, "training_acc": 53.75, "val_loss": 14.071015119552612, "val_acc": 50.0}
{"epoch": 13, "training_loss": 55.3697624206543, "training_acc": 53.75, "val_loss": 14.171713590621948, "val_acc": 50.0}
{"epoch": 14, "training_loss": 55.64139366149902, "training_acc": 53.75, "val_loss": 14.22031283378601, "val_acc": 50.0}
{"epoch": 15, "training_loss": 55.65764236450195, "training_acc": 53.75, "val_loss": 14.244886636734009, "val_acc": 50.0}
{"epoch": 16, "training_loss": 55.77299880981445, "training_acc": 53.75, "val_loss": 14.11794900894165, "val_acc": 50.0}
{"epoch": 17, "training_loss": 55.40488624572754, "training_acc": 53.75, "val_loss": 13.958462476730347, "val_acc": 50.0}
{"epoch": 18, "training_loss": 55.270538330078125, "training_acc": 53.75, "val_loss": 13.875943422317505, "val_acc": 50.0}
{"epoch": 19, "training_loss": 55.30287837982178, "training_acc": 53.75, "val_loss": 13.865255117416382, "val_acc": 50.0}
{"epoch": 20, "training_loss": 55.464651107788086, "training_acc": 46.25, "val_loss": 13.868000507354736, "val_acc": 50.0}
{"epoch": 21, "training_loss": 55.63122844696045, "training_acc": 46.25, "val_loss": 13.86256456375122, "val_acc": 50.0}
{"epoch": 22, "training_loss": 55.412431716918945, "training_acc": 51.25, "val_loss": 13.880990743637085, "val_acc": 50.0}
{"epoch": 23, "training_loss": 55.19395923614502, "training_acc": 53.75, "val_loss": 13.949955701828003, "val_acc": 50.0}
{"epoch": 24, "training_loss": 55.164276123046875, "training_acc": 53.75, "val_loss": 14.077961444854736, "val_acc": 50.0}
{"epoch": 25, "training_loss": 55.39887809753418, "training_acc": 53.75, "val_loss": 14.193376302719116, "val_acc": 50.0}
{"epoch": 26, "training_loss": 55.61978244781494, "training_acc": 53.75, "val_loss": 14.142836332321167, "val_acc": 50.0}
{"epoch": 27, "training_loss": 55.54533672332764, "training_acc": 53.75, "val_loss": 14.01849627494812, "val_acc": 50.0}
{"epoch": 28, "training_loss": 55.227782249450684, "training_acc": 53.75, "val_loss": 13.913525342941284, "val_acc": 50.0}
