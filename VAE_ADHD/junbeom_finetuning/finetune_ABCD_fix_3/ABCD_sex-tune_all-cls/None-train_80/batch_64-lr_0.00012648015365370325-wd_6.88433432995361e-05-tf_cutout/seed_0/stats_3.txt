"main_optuna_fix_3.py --pretrained_path None --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3 --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 57.42575263977051, "training_acc": 52.5, "val_loss": 13.811095952987671, "val_acc": 55.0}
{"epoch": 1, "training_loss": 59.1588020324707, "training_acc": 45.0, "val_loss": 13.947941064834595, "val_acc": 55.0}
{"epoch": 2, "training_loss": 55.43661880493164, "training_acc": 50.0, "val_loss": 13.808255195617676, "val_acc": 55.0}
{"epoch": 3, "training_loss": 55.89780044555664, "training_acc": 52.5, "val_loss": 13.77161979675293, "val_acc": 55.0}
{"epoch": 4, "training_loss": 55.75968933105469, "training_acc": 52.5, "val_loss": 13.808667659759521, "val_acc": 55.0}
{"epoch": 5, "training_loss": 55.34795379638672, "training_acc": 52.5, "val_loss": 13.77097487449646, "val_acc": 55.0}
{"epoch": 6, "training_loss": 55.36832237243652, "training_acc": 52.5, "val_loss": 13.772188425064087, "val_acc": 55.0}
{"epoch": 7, "training_loss": 55.51730537414551, "training_acc": 52.5, "val_loss": 13.773924112319946, "val_acc": 55.0}
{"epoch": 8, "training_loss": 55.25702095031738, "training_acc": 52.5, "val_loss": 13.93824815750122, "val_acc": 55.0}
{"epoch": 9, "training_loss": 55.65398120880127, "training_acc": 47.5, "val_loss": 14.140887260437012, "val_acc": 55.0}
{"epoch": 10, "training_loss": 56.10899639129639, "training_acc": 47.5, "val_loss": 13.943486213684082, "val_acc": 55.0}
{"epoch": 11, "training_loss": 55.4455680847168, "training_acc": 52.5, "val_loss": 13.779486417770386, "val_acc": 55.0}
{"epoch": 12, "training_loss": 55.520225524902344, "training_acc": 52.5, "val_loss": 13.772386312484741, "val_acc": 55.0}
{"epoch": 13, "training_loss": 55.54186534881592, "training_acc": 52.5, "val_loss": 13.771121501922607, "val_acc": 55.0}
{"epoch": 14, "training_loss": 55.464080810546875, "training_acc": 52.5, "val_loss": 13.775250911712646, "val_acc": 55.0}
{"epoch": 15, "training_loss": 55.52486991882324, "training_acc": 52.5, "val_loss": 13.792030811309814, "val_acc": 55.0}
{"epoch": 16, "training_loss": 55.37986183166504, "training_acc": 52.5, "val_loss": 13.776315450668335, "val_acc": 55.0}
{"epoch": 17, "training_loss": 55.45061206817627, "training_acc": 52.5, "val_loss": 13.76935362815857, "val_acc": 55.0}
{"epoch": 18, "training_loss": 55.44963073730469, "training_acc": 52.5, "val_loss": 13.769373893737793, "val_acc": 55.0}
{"epoch": 19, "training_loss": 55.37693405151367, "training_acc": 52.5, "val_loss": 13.786442279815674, "val_acc": 55.0}
{"epoch": 20, "training_loss": 55.378944396972656, "training_acc": 52.5, "val_loss": 13.816996812820435, "val_acc": 55.0}
{"epoch": 21, "training_loss": 55.37287521362305, "training_acc": 52.5, "val_loss": 13.83121132850647, "val_acc": 55.0}
{"epoch": 22, "training_loss": 55.39441967010498, "training_acc": 52.5, "val_loss": 13.831923007965088, "val_acc": 55.0}
{"epoch": 23, "training_loss": 55.385239601135254, "training_acc": 52.5, "val_loss": 13.815839290618896, "val_acc": 55.0}
{"epoch": 24, "training_loss": 55.34375858306885, "training_acc": 52.5, "val_loss": 13.788783550262451, "val_acc": 55.0}
{"epoch": 25, "training_loss": 55.2672061920166, "training_acc": 52.5, "val_loss": 13.766393661499023, "val_acc": 55.0}
{"epoch": 26, "training_loss": 55.37117576599121, "training_acc": 52.5, "val_loss": 13.779391050338745, "val_acc": 55.0}
{"epoch": 27, "training_loss": 55.61001968383789, "training_acc": 52.5, "val_loss": 13.809254169464111, "val_acc": 55.0}
{"epoch": 28, "training_loss": 55.93131446838379, "training_acc": 52.5, "val_loss": 13.783740997314453, "val_acc": 55.0}
{"epoch": 29, "training_loss": 55.6609001159668, "training_acc": 52.5, "val_loss": 13.76970648765564, "val_acc": 55.0}
{"epoch": 30, "training_loss": 55.365671157836914, "training_acc": 52.5, "val_loss": 13.786736726760864, "val_acc": 55.0}
{"epoch": 31, "training_loss": 55.31827163696289, "training_acc": 52.5, "val_loss": 13.819178342819214, "val_acc": 55.0}
{"epoch": 32, "training_loss": 55.367801666259766, "training_acc": 52.5, "val_loss": 13.859272003173828, "val_acc": 55.0}
{"epoch": 33, "training_loss": 55.455772399902344, "training_acc": 50.0, "val_loss": 13.872460126876831, "val_acc": 55.0}
{"epoch": 34, "training_loss": 55.46160316467285, "training_acc": 46.25, "val_loss": 13.849097490310669, "val_acc": 55.0}
{"epoch": 35, "training_loss": 55.447373390197754, "training_acc": 52.5, "val_loss": 13.821134567260742, "val_acc": 55.0}
{"epoch": 36, "training_loss": 55.361244201660156, "training_acc": 52.5, "val_loss": 13.797879219055176, "val_acc": 55.0}
{"epoch": 37, "training_loss": 55.37411117553711, "training_acc": 52.5, "val_loss": 13.774174451828003, "val_acc": 55.0}
{"epoch": 38, "training_loss": 55.354164123535156, "training_acc": 52.5, "val_loss": 13.766411542892456, "val_acc": 55.0}
{"epoch": 39, "training_loss": 55.393999099731445, "training_acc": 52.5, "val_loss": 13.764591217041016, "val_acc": 55.0}
{"epoch": 40, "training_loss": 55.439422607421875, "training_acc": 52.5, "val_loss": 13.76538872718811, "val_acc": 55.0}
