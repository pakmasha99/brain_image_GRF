"main_optuna_fix_3.py --pretrained_path None --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3 --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 58.80866622924805, "training_acc": 41.25, "val_loss": 14.500792026519775, "val_acc": 50.0}
{"epoch": 1, "training_loss": 58.63387203216553, "training_acc": 46.25, "val_loss": 13.862522840499878, "val_acc": 50.0}
{"epoch": 2, "training_loss": 55.51374626159668, "training_acc": 48.75, "val_loss": 14.02545690536499, "val_acc": 50.0}
{"epoch": 3, "training_loss": 55.3263635635376, "training_acc": 53.75, "val_loss": 14.062798023223877, "val_acc": 50.0}
{"epoch": 4, "training_loss": 55.26483631134033, "training_acc": 53.75, "val_loss": 13.908447027206421, "val_acc": 50.0}
{"epoch": 5, "training_loss": 55.297536849975586, "training_acc": 53.75, "val_loss": 13.86781096458435, "val_acc": 50.0}
{"epoch": 6, "training_loss": 55.354265213012695, "training_acc": 53.75, "val_loss": 13.883912563323975, "val_acc": 50.0}
{"epoch": 7, "training_loss": 55.23930644989014, "training_acc": 53.75, "val_loss": 13.965126276016235, "val_acc": 50.0}
{"epoch": 8, "training_loss": 55.30058288574219, "training_acc": 53.75, "val_loss": 14.028549194335938, "val_acc": 50.0}
{"epoch": 9, "training_loss": 55.26136875152588, "training_acc": 53.75, "val_loss": 13.924882411956787, "val_acc": 50.0}
{"epoch": 10, "training_loss": 55.25950813293457, "training_acc": 53.75, "val_loss": 13.870798349380493, "val_acc": 50.0}
{"epoch": 11, "training_loss": 55.350847244262695, "training_acc": 53.75, "val_loss": 13.872348070144653, "val_acc": 50.0}
{"epoch": 12, "training_loss": 55.32141971588135, "training_acc": 53.75, "val_loss": 13.9041268825531, "val_acc": 50.0}
{"epoch": 13, "training_loss": 55.20112228393555, "training_acc": 53.75, "val_loss": 13.994196653366089, "val_acc": 50.0}
{"epoch": 14, "training_loss": 55.16078186035156, "training_acc": 53.75, "val_loss": 14.2202627658844, "val_acc": 50.0}
{"epoch": 15, "training_loss": 55.59776496887207, "training_acc": 53.75, "val_loss": 14.44391131401062, "val_acc": 50.0}
{"epoch": 16, "training_loss": 56.24894332885742, "training_acc": 53.75, "val_loss": 14.298818111419678, "val_acc": 50.0}
{"epoch": 17, "training_loss": 55.71640586853027, "training_acc": 53.75, "val_loss": 14.037827253341675, "val_acc": 50.0}
{"epoch": 18, "training_loss": 55.335832595825195, "training_acc": 53.75, "val_loss": 13.893053531646729, "val_acc": 50.0}
{"epoch": 19, "training_loss": 55.188270568847656, "training_acc": 53.75, "val_loss": 13.86354923248291, "val_acc": 50.0}
{"epoch": 20, "training_loss": 55.39271926879883, "training_acc": 53.75, "val_loss": 13.860571384429932, "val_acc": 50.0}
{"epoch": 21, "training_loss": 55.5955810546875, "training_acc": 46.25, "val_loss": 13.857940435409546, "val_acc": 50.0}
{"epoch": 22, "training_loss": 55.46995830535889, "training_acc": 46.25, "val_loss": 13.864188194274902, "val_acc": 50.0}
{"epoch": 23, "training_loss": 55.24459743499756, "training_acc": 53.75, "val_loss": 13.906391859054565, "val_acc": 50.0}
{"epoch": 24, "training_loss": 55.160948753356934, "training_acc": 53.75, "val_loss": 14.001516103744507, "val_acc": 50.0}
{"epoch": 25, "training_loss": 55.247154235839844, "training_acc": 53.75, "val_loss": 14.127534627914429, "val_acc": 50.0}
{"epoch": 26, "training_loss": 55.46306610107422, "training_acc": 53.75, "val_loss": 14.162839651107788, "val_acc": 50.0}
{"epoch": 27, "training_loss": 55.59028244018555, "training_acc": 53.75, "val_loss": 14.074434041976929, "val_acc": 50.0}
{"epoch": 28, "training_loss": 55.32112121582031, "training_acc": 53.75, "val_loss": 13.953497409820557, "val_acc": 50.0}
{"epoch": 29, "training_loss": 55.2487678527832, "training_acc": 53.75, "val_loss": 13.881522417068481, "val_acc": 50.0}
{"epoch": 30, "training_loss": 55.346229553222656, "training_acc": 53.75, "val_loss": 13.87493371963501, "val_acc": 50.0}
{"epoch": 31, "training_loss": 55.296756744384766, "training_acc": 53.75, "val_loss": 13.893969058990479, "val_acc": 50.0}
{"epoch": 32, "training_loss": 55.28402519226074, "training_acc": 53.75, "val_loss": 13.913307189941406, "val_acc": 50.0}
{"epoch": 33, "training_loss": 55.215118408203125, "training_acc": 53.75, "val_loss": 13.916710615158081, "val_acc": 50.0}
{"epoch": 34, "training_loss": 55.235639572143555, "training_acc": 53.75, "val_loss": 13.9284086227417, "val_acc": 50.0}
{"epoch": 35, "training_loss": 55.27628707885742, "training_acc": 53.75, "val_loss": 13.917973041534424, "val_acc": 50.0}
{"epoch": 36, "training_loss": 55.147294998168945, "training_acc": 53.75, "val_loss": 13.87430191040039, "val_acc": 50.0}
{"epoch": 37, "training_loss": 55.235639572143555, "training_acc": 53.75, "val_loss": 13.861778974533081, "val_acc": 50.0}
{"epoch": 38, "training_loss": 55.57250690460205, "training_acc": 46.25, "val_loss": 13.871842622756958, "val_acc": 50.0}
{"epoch": 39, "training_loss": 55.69256019592285, "training_acc": 46.25, "val_loss": 13.864288330078125, "val_acc": 50.0}
