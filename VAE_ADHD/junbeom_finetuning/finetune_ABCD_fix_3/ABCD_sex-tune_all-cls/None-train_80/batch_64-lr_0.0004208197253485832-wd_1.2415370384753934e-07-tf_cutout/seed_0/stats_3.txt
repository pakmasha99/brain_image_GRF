"main_optuna_fix_3.py --pretrained_path None --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3 --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 62.46558380126953, "training_acc": 50.0, "val_loss": 14.379968643188477, "val_acc": 55.0}
{"epoch": 1, "training_loss": 55.91623020172119, "training_acc": 55.0, "val_loss": 16.65443778038025, "val_acc": 45.0}
{"epoch": 2, "training_loss": 62.883487701416016, "training_acc": 47.5, "val_loss": 13.971891403198242, "val_acc": 55.0}
{"epoch": 3, "training_loss": 55.68905735015869, "training_acc": 47.5, "val_loss": 13.815064430236816, "val_acc": 55.0}
{"epoch": 4, "training_loss": 55.40204048156738, "training_acc": 52.5, "val_loss": 13.763312101364136, "val_acc": 55.0}
{"epoch": 5, "training_loss": 55.415306091308594, "training_acc": 52.5, "val_loss": 13.798739910125732, "val_acc": 55.0}
{"epoch": 6, "training_loss": 55.82198905944824, "training_acc": 52.5, "val_loss": 13.763717412948608, "val_acc": 55.0}
{"epoch": 7, "training_loss": 55.38139533996582, "training_acc": 52.5, "val_loss": 13.915965557098389, "val_acc": 55.0}
{"epoch": 8, "training_loss": 55.67649269104004, "training_acc": 42.5, "val_loss": 14.076598882675171, "val_acc": 55.0}
{"epoch": 9, "training_loss": 55.996216773986816, "training_acc": 47.5, "val_loss": 13.98762822151184, "val_acc": 55.0}
{"epoch": 10, "training_loss": 55.61542797088623, "training_acc": 47.5, "val_loss": 13.800963163375854, "val_acc": 55.0}
{"epoch": 11, "training_loss": 55.26657676696777, "training_acc": 52.5, "val_loss": 13.762375116348267, "val_acc": 55.0}
{"epoch": 12, "training_loss": 55.600955963134766, "training_acc": 52.5, "val_loss": 13.762762546539307, "val_acc": 55.0}
{"epoch": 13, "training_loss": 55.50703144073486, "training_acc": 52.5, "val_loss": 13.789033889770508, "val_acc": 55.0}
{"epoch": 14, "training_loss": 55.34840393066406, "training_acc": 52.5, "val_loss": 13.828814029693604, "val_acc": 55.0}
{"epoch": 15, "training_loss": 55.54648685455322, "training_acc": 45.0, "val_loss": 13.83553147315979, "val_acc": 55.0}
{"epoch": 16, "training_loss": 55.32158660888672, "training_acc": 52.5, "val_loss": 13.770502805709839, "val_acc": 55.0}
{"epoch": 17, "training_loss": 55.56460094451904, "training_acc": 52.5, "val_loss": 13.772916793823242, "val_acc": 55.0}
{"epoch": 18, "training_loss": 55.55019474029541, "training_acc": 52.5, "val_loss": 13.767924308776855, "val_acc": 55.0}
{"epoch": 19, "training_loss": 55.30819511413574, "training_acc": 52.5, "val_loss": 13.828363418579102, "val_acc": 55.0}
{"epoch": 20, "training_loss": 55.44438076019287, "training_acc": 50.0, "val_loss": 13.896316289901733, "val_acc": 55.0}
{"epoch": 21, "training_loss": 55.52766418457031, "training_acc": 47.5, "val_loss": 13.874027729034424, "val_acc": 55.0}
{"epoch": 22, "training_loss": 55.46196460723877, "training_acc": 50.0, "val_loss": 13.831084966659546, "val_acc": 55.0}
{"epoch": 23, "training_loss": 55.375205993652344, "training_acc": 52.5, "val_loss": 13.79312515258789, "val_acc": 55.0}
{"epoch": 24, "training_loss": 55.31356620788574, "training_acc": 52.5, "val_loss": 13.768894672393799, "val_acc": 55.0}
{"epoch": 25, "training_loss": 55.309892654418945, "training_acc": 52.5, "val_loss": 13.764413595199585, "val_acc": 55.0}
{"epoch": 26, "training_loss": 55.47824287414551, "training_acc": 52.5, "val_loss": 13.786442279815674, "val_acc": 55.0}
{"epoch": 27, "training_loss": 55.7420654296875, "training_acc": 52.5, "val_loss": 13.802980184555054, "val_acc": 55.0}
{"epoch": 28, "training_loss": 55.87391185760498, "training_acc": 52.5, "val_loss": 13.77104640007019, "val_acc": 55.0}
{"epoch": 29, "training_loss": 55.599246978759766, "training_acc": 52.5, "val_loss": 13.767668008804321, "val_acc": 55.0}
{"epoch": 30, "training_loss": 55.36558151245117, "training_acc": 52.5, "val_loss": 13.790067434310913, "val_acc": 55.0}
{"epoch": 31, "training_loss": 55.31166648864746, "training_acc": 52.5, "val_loss": 13.828471899032593, "val_acc": 55.0}
{"epoch": 32, "training_loss": 55.39117240905762, "training_acc": 52.5, "val_loss": 13.883613348007202, "val_acc": 55.0}
{"epoch": 33, "training_loss": 55.515554428100586, "training_acc": 47.5, "val_loss": 13.897864818572998, "val_acc": 55.0}
{"epoch": 34, "training_loss": 55.51659393310547, "training_acc": 47.5, "val_loss": 13.863861560821533, "val_acc": 55.0}
{"epoch": 35, "training_loss": 55.47676181793213, "training_acc": 43.75, "val_loss": 13.833836317062378, "val_acc": 55.0}
{"epoch": 36, "training_loss": 55.388264656066895, "training_acc": 52.5, "val_loss": 13.815392255783081, "val_acc": 55.0}
{"epoch": 37, "training_loss": 55.37465476989746, "training_acc": 52.5, "val_loss": 13.796526193618774, "val_acc": 55.0}
{"epoch": 38, "training_loss": 55.34946823120117, "training_acc": 52.5, "val_loss": 13.784642219543457, "val_acc": 55.0}
{"epoch": 39, "training_loss": 55.3442907333374, "training_acc": 52.5, "val_loss": 13.775522708892822, "val_acc": 55.0}
{"epoch": 40, "training_loss": 55.36372756958008, "training_acc": 52.5, "val_loss": 13.770612478256226, "val_acc": 55.0}
{"epoch": 41, "training_loss": 55.375925064086914, "training_acc": 52.5, "val_loss": 13.77137541770935, "val_acc": 55.0}
{"epoch": 42, "training_loss": 55.36975288391113, "training_acc": 52.5, "val_loss": 13.776473999023438, "val_acc": 55.0}
