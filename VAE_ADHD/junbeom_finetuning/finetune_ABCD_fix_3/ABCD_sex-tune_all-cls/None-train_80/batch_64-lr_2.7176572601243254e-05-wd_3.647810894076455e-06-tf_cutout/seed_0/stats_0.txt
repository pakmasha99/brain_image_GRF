"main_optuna_fix_3.py --pretrained_path None --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3 --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 55.32838821411133, "training_acc": 53.75, "val_loss": 13.933343887329102, "val_acc": 50.0}
{"epoch": 1, "training_loss": 56.03757667541504, "training_acc": 43.75, "val_loss": 13.893797397613525, "val_acc": 50.0}
{"epoch": 2, "training_loss": 55.31549263000488, "training_acc": 53.75, "val_loss": 14.083963632583618, "val_acc": 50.0}
{"epoch": 3, "training_loss": 55.544511795043945, "training_acc": 53.75, "val_loss": 14.083751440048218, "val_acc": 50.0}
{"epoch": 4, "training_loss": 55.433189392089844, "training_acc": 53.75, "val_loss": 13.948860168457031, "val_acc": 50.0}
{"epoch": 5, "training_loss": 55.13275337219238, "training_acc": 53.75, "val_loss": 13.87352705001831, "val_acc": 50.0}
{"epoch": 6, "training_loss": 55.34083557128906, "training_acc": 51.25, "val_loss": 13.876889944076538, "val_acc": 50.0}
{"epoch": 7, "training_loss": 55.57646369934082, "training_acc": 46.25, "val_loss": 13.883113861083984, "val_acc": 50.0}
{"epoch": 8, "training_loss": 55.63070774078369, "training_acc": 46.25, "val_loss": 13.877681493759155, "val_acc": 50.0}
{"epoch": 9, "training_loss": 55.55832290649414, "training_acc": 46.25, "val_loss": 13.869723081588745, "val_acc": 50.0}
{"epoch": 10, "training_loss": 55.35108184814453, "training_acc": 56.25, "val_loss": 13.885537385940552, "val_acc": 50.0}
{"epoch": 11, "training_loss": 55.177350997924805, "training_acc": 53.75, "val_loss": 13.950636386871338, "val_acc": 50.0}
{"epoch": 12, "training_loss": 55.16882133483887, "training_acc": 53.75, "val_loss": 14.074305295944214, "val_acc": 50.0}
{"epoch": 13, "training_loss": 55.388376235961914, "training_acc": 53.75, "val_loss": 14.222872257232666, "val_acc": 50.0}
{"epoch": 14, "training_loss": 55.76437568664551, "training_acc": 53.75, "val_loss": 14.37947154045105, "val_acc": 50.0}
{"epoch": 15, "training_loss": 56.198699951171875, "training_acc": 53.75, "val_loss": 14.46427583694458, "val_acc": 50.0}
{"epoch": 16, "training_loss": 56.45465278625488, "training_acc": 53.75, "val_loss": 14.359939098358154, "val_acc": 50.0}
{"epoch": 17, "training_loss": 56.05614471435547, "training_acc": 53.75, "val_loss": 14.158819913864136, "val_acc": 50.0}
{"epoch": 18, "training_loss": 55.666561126708984, "training_acc": 53.75, "val_loss": 13.98990511894226, "val_acc": 50.0}
{"epoch": 19, "training_loss": 55.14809226989746, "training_acc": 53.75, "val_loss": 13.89765739440918, "val_acc": 50.0}
{"epoch": 20, "training_loss": 55.12160301208496, "training_acc": 53.75, "val_loss": 13.87217402458191, "val_acc": 50.0}
{"epoch": 21, "training_loss": 55.60284996032715, "training_acc": 46.25, "val_loss": 13.899532556533813, "val_acc": 50.0}
{"epoch": 22, "training_loss": 55.80521011352539, "training_acc": 46.25, "val_loss": 13.885984420776367, "val_acc": 50.0}
{"epoch": 23, "training_loss": 55.63012886047363, "training_acc": 46.25, "val_loss": 13.87008786201477, "val_acc": 50.0}
{"epoch": 24, "training_loss": 55.37652587890625, "training_acc": 52.5, "val_loss": 13.88121247291565, "val_acc": 50.0}
{"epoch": 25, "training_loss": 55.24495506286621, "training_acc": 53.75, "val_loss": 13.903801441192627, "val_acc": 50.0}
{"epoch": 26, "training_loss": 55.201148986816406, "training_acc": 53.75, "val_loss": 13.925522565841675, "val_acc": 50.0}
{"epoch": 27, "training_loss": 55.1927375793457, "training_acc": 53.75, "val_loss": 13.951873779296875, "val_acc": 50.0}
{"epoch": 28, "training_loss": 55.25815677642822, "training_acc": 53.75, "val_loss": 13.972463607788086, "val_acc": 50.0}
{"epoch": 29, "training_loss": 55.2250280380249, "training_acc": 53.75, "val_loss": 13.964341878890991, "val_acc": 50.0}
{"epoch": 30, "training_loss": 55.21892166137695, "training_acc": 53.75, "val_loss": 13.95710825920105, "val_acc": 50.0}
