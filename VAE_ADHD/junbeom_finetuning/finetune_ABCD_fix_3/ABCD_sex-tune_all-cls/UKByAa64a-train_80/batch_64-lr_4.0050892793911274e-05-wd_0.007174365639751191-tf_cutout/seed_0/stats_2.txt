"main_optuna_fix_3.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3 --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 55.47435760498047, "training_acc": 56.25, "val_loss": 13.786612749099731, "val_acc": 55.0}
{"epoch": 1, "training_loss": 56.00085639953613, "training_acc": 45.0, "val_loss": 13.7552011013031, "val_acc": 55.0}
{"epoch": 2, "training_loss": 55.42108726501465, "training_acc": 52.5, "val_loss": 13.779278993606567, "val_acc": 55.0}
{"epoch": 3, "training_loss": 55.628732681274414, "training_acc": 52.5, "val_loss": 13.764640092849731, "val_acc": 55.0}
{"epoch": 4, "training_loss": 55.48439025878906, "training_acc": 52.5, "val_loss": 13.780486583709717, "val_acc": 55.0}
{"epoch": 5, "training_loss": 55.36029529571533, "training_acc": 52.5, "val_loss": 13.885878324508667, "val_acc": 55.0}
{"epoch": 6, "training_loss": 55.75522708892822, "training_acc": 50.0, "val_loss": 13.82097601890564, "val_acc": 55.0}
{"epoch": 7, "training_loss": 55.257415771484375, "training_acc": 55.0, "val_loss": 13.73820424079895, "val_acc": 55.0}
{"epoch": 8, "training_loss": 55.72781753540039, "training_acc": 52.5, "val_loss": 13.754739761352539, "val_acc": 55.0}
{"epoch": 9, "training_loss": 55.40212821960449, "training_acc": 52.5, "val_loss": 13.749735355377197, "val_acc": 55.0}
{"epoch": 10, "training_loss": 55.379082679748535, "training_acc": 52.5, "val_loss": 13.838528394699097, "val_acc": 55.0}
{"epoch": 11, "training_loss": 55.44236946105957, "training_acc": 56.25, "val_loss": 13.81107211112976, "val_acc": 55.0}
{"epoch": 12, "training_loss": 55.36586380004883, "training_acc": 52.5, "val_loss": 13.756645917892456, "val_acc": 55.0}
{"epoch": 13, "training_loss": 55.270137786865234, "training_acc": 52.5, "val_loss": 13.753362894058228, "val_acc": 55.0}
{"epoch": 14, "training_loss": 55.252949714660645, "training_acc": 52.5, "val_loss": 13.78044605255127, "val_acc": 55.0}
{"epoch": 15, "training_loss": 55.364609718322754, "training_acc": 55.0, "val_loss": 13.772516250610352, "val_acc": 55.0}
{"epoch": 16, "training_loss": 55.11789321899414, "training_acc": 52.5, "val_loss": 13.733488321304321, "val_acc": 55.0}
{"epoch": 17, "training_loss": 55.56853008270264, "training_acc": 52.5, "val_loss": 13.772166967391968, "val_acc": 55.0}
{"epoch": 18, "training_loss": 55.41341495513916, "training_acc": 52.5, "val_loss": 13.72962474822998, "val_acc": 55.0}
{"epoch": 19, "training_loss": 55.04751396179199, "training_acc": 52.5, "val_loss": 13.782103061676025, "val_acc": 55.0}
{"epoch": 20, "training_loss": 55.18344688415527, "training_acc": 52.5, "val_loss": 13.863178491592407, "val_acc": 55.0}
{"epoch": 21, "training_loss": 55.3566951751709, "training_acc": 47.5, "val_loss": 13.837374448776245, "val_acc": 55.0}
{"epoch": 22, "training_loss": 55.247700691223145, "training_acc": 68.75, "val_loss": 13.779162168502808, "val_acc": 55.0}
{"epoch": 23, "training_loss": 55.01614570617676, "training_acc": 53.75, "val_loss": 13.745487928390503, "val_acc": 55.0}
{"epoch": 24, "training_loss": 55.113948822021484, "training_acc": 52.5, "val_loss": 13.753572702407837, "val_acc": 55.0}
{"epoch": 25, "training_loss": 55.328935623168945, "training_acc": 52.5, "val_loss": 13.791383504867554, "val_acc": 55.0}
{"epoch": 26, "training_loss": 55.60538101196289, "training_acc": 52.5, "val_loss": 13.80912184715271, "val_acc": 55.0}
