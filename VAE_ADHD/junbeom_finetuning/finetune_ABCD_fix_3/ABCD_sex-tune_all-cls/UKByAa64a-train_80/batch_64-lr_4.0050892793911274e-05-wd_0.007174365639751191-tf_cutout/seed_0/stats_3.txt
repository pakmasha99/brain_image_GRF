"main_optuna_fix_3.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3 --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 55.02012062072754, "training_acc": 52.5, "val_loss": 13.862545490264893, "val_acc": 55.0}
{"epoch": 1, "training_loss": 55.81420707702637, "training_acc": 52.5, "val_loss": 16.025888919830322, "val_acc": 55.0}
{"epoch": 2, "training_loss": 60.96098518371582, "training_acc": 52.5, "val_loss": 14.079831838607788, "val_acc": 55.0}
{"epoch": 3, "training_loss": 57.82621192932129, "training_acc": 52.5, "val_loss": 13.76470685005188, "val_acc": 55.0}
{"epoch": 4, "training_loss": 56.046743392944336, "training_acc": 52.5, "val_loss": 13.838826417922974, "val_acc": 55.0}
{"epoch": 5, "training_loss": 55.49663257598877, "training_acc": 51.25, "val_loss": 13.918507099151611, "val_acc": 55.0}
{"epoch": 6, "training_loss": 55.55456066131592, "training_acc": 47.5, "val_loss": 13.854635953903198, "val_acc": 55.0}
{"epoch": 7, "training_loss": 55.429869651794434, "training_acc": 47.5, "val_loss": 13.779549598693848, "val_acc": 55.0}
{"epoch": 8, "training_loss": 55.43612861633301, "training_acc": 52.5, "val_loss": 13.760305643081665, "val_acc": 55.0}
{"epoch": 9, "training_loss": 55.3138313293457, "training_acc": 52.5, "val_loss": 13.77795934677124, "val_acc": 55.0}
{"epoch": 10, "training_loss": 55.38475036621094, "training_acc": 52.5, "val_loss": 13.788045644760132, "val_acc": 55.0}
{"epoch": 11, "training_loss": 55.279693603515625, "training_acc": 52.5, "val_loss": 13.758829832077026, "val_acc": 55.0}
{"epoch": 12, "training_loss": 55.37690734863281, "training_acc": 52.5, "val_loss": 13.745567798614502, "val_acc": 55.0}
{"epoch": 13, "training_loss": 55.244550704956055, "training_acc": 52.5, "val_loss": 13.746881484985352, "val_acc": 55.0}
{"epoch": 14, "training_loss": 55.24093818664551, "training_acc": 52.5, "val_loss": 13.753198385238647, "val_acc": 55.0}
{"epoch": 15, "training_loss": 55.26884174346924, "training_acc": 52.5, "val_loss": 13.756535053253174, "val_acc": 55.0}
{"epoch": 16, "training_loss": 55.15302276611328, "training_acc": 52.5, "val_loss": 13.73835802078247, "val_acc": 55.0}
{"epoch": 17, "training_loss": 55.39108180999756, "training_acc": 52.5, "val_loss": 13.75907301902771, "val_acc": 55.0}
{"epoch": 18, "training_loss": 55.342817306518555, "training_acc": 52.5, "val_loss": 13.746979236602783, "val_acc": 55.0}
{"epoch": 19, "training_loss": 55.22490882873535, "training_acc": 52.5, "val_loss": 13.744561672210693, "val_acc": 55.0}
{"epoch": 20, "training_loss": 55.1885290145874, "training_acc": 52.5, "val_loss": 13.810421228408813, "val_acc": 55.0}
{"epoch": 21, "training_loss": 55.230268478393555, "training_acc": 55.0, "val_loss": 13.865435123443604, "val_acc": 55.0}
{"epoch": 22, "training_loss": 55.32777976989746, "training_acc": 47.5, "val_loss": 13.856457471847534, "val_acc": 55.0}
{"epoch": 23, "training_loss": 55.241302490234375, "training_acc": 50.0, "val_loss": 13.781890869140625, "val_acc": 55.0}
{"epoch": 24, "training_loss": 55.01068687438965, "training_acc": 60.0, "val_loss": 13.728669881820679, "val_acc": 55.0}
