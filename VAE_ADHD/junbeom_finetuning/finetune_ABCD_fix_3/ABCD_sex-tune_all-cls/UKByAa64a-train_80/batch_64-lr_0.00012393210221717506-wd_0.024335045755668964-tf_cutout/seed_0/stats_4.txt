"main_optuna_fix_3.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3 --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 55.33552551269531, "training_acc": 52.5, "val_loss": 13.847929239273071, "val_acc": 55.0}
{"epoch": 1, "training_loss": 55.27805137634277, "training_acc": 52.5, "val_loss": 13.757418394088745, "val_acc": 55.0}
{"epoch": 2, "training_loss": 55.77453804016113, "training_acc": 52.5, "val_loss": 13.769289255142212, "val_acc": 55.0}
{"epoch": 3, "training_loss": 55.67858028411865, "training_acc": 52.5, "val_loss": 13.759931325912476, "val_acc": 55.0}
{"epoch": 4, "training_loss": 55.44434833526611, "training_acc": 52.5, "val_loss": 13.78620982170105, "val_acc": 55.0}
{"epoch": 5, "training_loss": 55.378570556640625, "training_acc": 52.5, "val_loss": 13.791811466217041, "val_acc": 55.0}
{"epoch": 6, "training_loss": 55.36912536621094, "training_acc": 52.5, "val_loss": 13.78572940826416, "val_acc": 55.0}
{"epoch": 7, "training_loss": 55.35751914978027, "training_acc": 52.5, "val_loss": 13.777693510055542, "val_acc": 55.0}
{"epoch": 8, "training_loss": 55.40114688873291, "training_acc": 52.5, "val_loss": 13.826552629470825, "val_acc": 55.0}
{"epoch": 9, "training_loss": 55.645386695861816, "training_acc": 45.0, "val_loss": 13.845895528793335, "val_acc": 55.0}
{"epoch": 10, "training_loss": 55.37424278259277, "training_acc": 52.5, "val_loss": 13.775566816329956, "val_acc": 55.0}
{"epoch": 11, "training_loss": 55.32292366027832, "training_acc": 52.5, "val_loss": 13.765407800674438, "val_acc": 55.0}
{"epoch": 12, "training_loss": 55.57919979095459, "training_acc": 52.5, "val_loss": 13.776333332061768, "val_acc": 55.0}
{"epoch": 13, "training_loss": 55.65348243713379, "training_acc": 52.5, "val_loss": 13.76334547996521, "val_acc": 55.0}
{"epoch": 14, "training_loss": 55.458008766174316, "training_acc": 52.5, "val_loss": 13.782317638397217, "val_acc": 55.0}
{"epoch": 15, "training_loss": 55.491013526916504, "training_acc": 52.5, "val_loss": 13.828287124633789, "val_acc": 55.0}
{"epoch": 16, "training_loss": 55.45653247833252, "training_acc": 52.5, "val_loss": 13.784630298614502, "val_acc": 55.0}
{"epoch": 17, "training_loss": 55.38942241668701, "training_acc": 52.5, "val_loss": 13.762954473495483, "val_acc": 55.0}
{"epoch": 18, "training_loss": 55.47612762451172, "training_acc": 52.5, "val_loss": 13.764162063598633, "val_acc": 55.0}
{"epoch": 19, "training_loss": 55.363285064697266, "training_acc": 52.5, "val_loss": 13.796716928482056, "val_acc": 55.0}
{"epoch": 20, "training_loss": 55.34463977813721, "training_acc": 52.5, "val_loss": 13.858799934387207, "val_acc": 55.0}
{"epoch": 21, "training_loss": 55.46216106414795, "training_acc": 50.0, "val_loss": 13.859758377075195, "val_acc": 55.0}
{"epoch": 22, "training_loss": 55.45029258728027, "training_acc": 52.5, "val_loss": 13.821169137954712, "val_acc": 55.0}
{"epoch": 23, "training_loss": 55.3637056350708, "training_acc": 52.5, "val_loss": 13.78386378288269, "val_acc": 55.0}
{"epoch": 24, "training_loss": 55.3734769821167, "training_acc": 52.5, "val_loss": 13.764362335205078, "val_acc": 55.0}
{"epoch": 25, "training_loss": 55.43205261230469, "training_acc": 52.5, "val_loss": 13.763281106948853, "val_acc": 55.0}
{"epoch": 26, "training_loss": 55.48824405670166, "training_acc": 52.5, "val_loss": 13.774104118347168, "val_acc": 55.0}
{"epoch": 27, "training_loss": 55.63602828979492, "training_acc": 52.5, "val_loss": 13.767398595809937, "val_acc": 55.0}
{"epoch": 28, "training_loss": 55.52643966674805, "training_acc": 52.5, "val_loss": 13.765546083450317, "val_acc": 55.0}
{"epoch": 29, "training_loss": 55.53836631774902, "training_acc": 52.5, "val_loss": 13.779076337814331, "val_acc": 55.0}
{"epoch": 30, "training_loss": 55.3602409362793, "training_acc": 52.5, "val_loss": 13.77504825592041, "val_acc": 55.0}
{"epoch": 31, "training_loss": 55.367469787597656, "training_acc": 52.5, "val_loss": 13.789047002792358, "val_acc": 55.0}
{"epoch": 32, "training_loss": 55.41917705535889, "training_acc": 52.5, "val_loss": 13.805532455444336, "val_acc": 55.0}
{"epoch": 33, "training_loss": 55.363542556762695, "training_acc": 52.5, "val_loss": 13.79554033279419, "val_acc": 55.0}
{"epoch": 34, "training_loss": 55.351603507995605, "training_acc": 52.5, "val_loss": 13.786680698394775, "val_acc": 55.0}
{"epoch": 35, "training_loss": 55.34131622314453, "training_acc": 52.5, "val_loss": 13.77276062965393, "val_acc": 55.0}
{"epoch": 36, "training_loss": 55.34918403625488, "training_acc": 52.5, "val_loss": 13.763591051101685, "val_acc": 55.0}
{"epoch": 37, "training_loss": 55.40555000305176, "training_acc": 52.5, "val_loss": 13.766669034957886, "val_acc": 55.0}
{"epoch": 38, "training_loss": 55.540517807006836, "training_acc": 52.5, "val_loss": 13.775787353515625, "val_acc": 55.0}
{"epoch": 39, "training_loss": 55.65914726257324, "training_acc": 52.5, "val_loss": 13.775596618652344, "val_acc": 55.0}
{"epoch": 40, "training_loss": 55.65022087097168, "training_acc": 52.5, "val_loss": 13.770216703414917, "val_acc": 55.0}
{"epoch": 41, "training_loss": 55.57021427154541, "training_acc": 52.5, "val_loss": 13.762447834014893, "val_acc": 55.0}
{"epoch": 42, "training_loss": 55.464877128601074, "training_acc": 52.5, "val_loss": 13.775578737258911, "val_acc": 55.0}
{"epoch": 43, "training_loss": 55.41215896606445, "training_acc": 52.5, "val_loss": 13.790202140808105, "val_acc": 55.0}
{"epoch": 44, "training_loss": 55.36946105957031, "training_acc": 52.5, "val_loss": 13.795109987258911, "val_acc": 55.0}
{"epoch": 45, "training_loss": 55.33858776092529, "training_acc": 52.5, "val_loss": 13.830362558364868, "val_acc": 55.0}
{"epoch": 46, "training_loss": 55.392080307006836, "training_acc": 53.75, "val_loss": 13.891229629516602, "val_acc": 55.0}
