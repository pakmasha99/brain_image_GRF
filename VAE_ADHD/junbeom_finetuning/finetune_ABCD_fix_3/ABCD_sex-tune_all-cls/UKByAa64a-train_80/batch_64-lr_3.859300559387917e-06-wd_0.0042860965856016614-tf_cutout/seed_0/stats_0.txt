"main_optuna_fix_3.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3 --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 56.01750373840332, "training_acc": 46.25, "val_loss": 13.892911672592163, "val_acc": 50.0}
{"epoch": 1, "training_loss": 55.6169490814209, "training_acc": 43.75, "val_loss": 13.900091648101807, "val_acc": 50.0}
{"epoch": 2, "training_loss": 55.47876739501953, "training_acc": 52.5, "val_loss": 13.905991315841675, "val_acc": 50.0}
{"epoch": 3, "training_loss": 55.22291564941406, "training_acc": 53.75, "val_loss": 13.927754163742065, "val_acc": 50.0}
{"epoch": 4, "training_loss": 55.202688217163086, "training_acc": 53.75, "val_loss": 13.945358991622925, "val_acc": 50.0}
{"epoch": 5, "training_loss": 55.23673915863037, "training_acc": 53.75, "val_loss": 13.953649997711182, "val_acc": 50.0}
{"epoch": 6, "training_loss": 55.08657455444336, "training_acc": 53.75, "val_loss": 13.954329490661621, "val_acc": 50.0}
{"epoch": 7, "training_loss": 55.15874767303467, "training_acc": 53.75, "val_loss": 13.955819606781006, "val_acc": 50.0}
{"epoch": 8, "training_loss": 55.06184005737305, "training_acc": 53.75, "val_loss": 13.946644067764282, "val_acc": 50.0}
{"epoch": 9, "training_loss": 55.024288177490234, "training_acc": 53.75, "val_loss": 13.942018747329712, "val_acc": 50.0}
{"epoch": 10, "training_loss": 55.00212860107422, "training_acc": 53.75, "val_loss": 13.944772481918335, "val_acc": 50.0}
{"epoch": 11, "training_loss": 54.905497550964355, "training_acc": 53.75, "val_loss": 13.962942361831665, "val_acc": 50.0}
{"epoch": 12, "training_loss": 54.91683864593506, "training_acc": 53.75, "val_loss": 13.993666172027588, "val_acc": 50.0}
{"epoch": 13, "training_loss": 54.87363624572754, "training_acc": 53.75, "val_loss": 14.025627374649048, "val_acc": 50.0}
{"epoch": 14, "training_loss": 54.810001373291016, "training_acc": 53.75, "val_loss": 14.064220190048218, "val_acc": 50.0}
{"epoch": 15, "training_loss": 54.918389320373535, "training_acc": 53.75, "val_loss": 14.123188257217407, "val_acc": 50.0}
{"epoch": 16, "training_loss": 55.26254653930664, "training_acc": 53.75, "val_loss": 14.174628257751465, "val_acc": 50.0}
{"epoch": 17, "training_loss": 55.09500312805176, "training_acc": 53.75, "val_loss": 14.200053215026855, "val_acc": 50.0}
{"epoch": 18, "training_loss": 55.0172061920166, "training_acc": 53.75, "val_loss": 14.19474482536316, "val_acc": 50.0}
{"epoch": 19, "training_loss": 54.92154121398926, "training_acc": 53.75, "val_loss": 14.156068563461304, "val_acc": 50.0}
{"epoch": 20, "training_loss": 54.775391578674316, "training_acc": 53.75, "val_loss": 14.06481385231018, "val_acc": 50.0}
{"epoch": 21, "training_loss": 54.89654541015625, "training_acc": 53.75, "val_loss": 13.987926244735718, "val_acc": 50.0}
{"epoch": 22, "training_loss": 54.825361251831055, "training_acc": 53.75, "val_loss": 13.967541456222534, "val_acc": 50.0}
{"epoch": 23, "training_loss": 54.845290184020996, "training_acc": 53.75, "val_loss": 13.976272344589233, "val_acc": 50.0}
{"epoch": 24, "training_loss": 54.745609283447266, "training_acc": 53.75, "val_loss": 13.964587450027466, "val_acc": 50.0}
{"epoch": 25, "training_loss": 54.801148414611816, "training_acc": 53.75, "val_loss": 13.96993637084961, "val_acc": 50.0}
{"epoch": 26, "training_loss": 54.91822052001953, "training_acc": 53.75, "val_loss": 13.988221883773804, "val_acc": 50.0}
{"epoch": 27, "training_loss": 54.61865425109863, "training_acc": 53.75, "val_loss": 14.012932777404785, "val_acc": 50.0}
{"epoch": 28, "training_loss": 54.74858283996582, "training_acc": 53.75, "val_loss": 14.036355018615723, "val_acc": 50.0}
{"epoch": 29, "training_loss": 54.45083808898926, "training_acc": 53.75, "val_loss": 14.05272126197815, "val_acc": 50.0}
{"epoch": 30, "training_loss": 54.612083435058594, "training_acc": 53.75, "val_loss": 14.076679944992065, "val_acc": 50.0}
{"epoch": 31, "training_loss": 54.591158866882324, "training_acc": 53.75, "val_loss": 14.08765196800232, "val_acc": 50.0}
{"epoch": 32, "training_loss": 54.199750900268555, "training_acc": 53.75, "val_loss": 14.080429077148438, "val_acc": 50.0}
{"epoch": 33, "training_loss": 54.42973613739014, "training_acc": 53.75, "val_loss": 14.075897932052612, "val_acc": 50.0}
{"epoch": 34, "training_loss": 54.509992599487305, "training_acc": 53.75, "val_loss": 14.087334871292114, "val_acc": 50.0}
