"main_optuna_fix_3.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3 --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 56.19684410095215, "training_acc": 47.5, "val_loss": 13.859730958938599, "val_acc": 55.0}
{"epoch": 1, "training_loss": 55.802419662475586, "training_acc": 43.75, "val_loss": 13.811346292495728, "val_acc": 55.0}
{"epoch": 2, "training_loss": 55.444732666015625, "training_acc": 52.5, "val_loss": 13.773083686828613, "val_acc": 55.0}
{"epoch": 3, "training_loss": 55.330169677734375, "training_acc": 51.25, "val_loss": 13.735175132751465, "val_acc": 55.0}
{"epoch": 4, "training_loss": 55.33357620239258, "training_acc": 52.5, "val_loss": 13.713257312774658, "val_acc": 55.0}
{"epoch": 5, "training_loss": 55.36938953399658, "training_acc": 52.5, "val_loss": 13.704086542129517, "val_acc": 55.0}
{"epoch": 6, "training_loss": 55.39479064941406, "training_acc": 52.5, "val_loss": 13.702105283737183, "val_acc": 55.0}
{"epoch": 7, "training_loss": 55.1833553314209, "training_acc": 52.5, "val_loss": 13.695248365402222, "val_acc": 55.0}
{"epoch": 8, "training_loss": 55.27686023712158, "training_acc": 52.5, "val_loss": 13.690825700759888, "val_acc": 55.0}
{"epoch": 9, "training_loss": 55.168352127075195, "training_acc": 52.5, "val_loss": 13.698643445968628, "val_acc": 55.0}
{"epoch": 10, "training_loss": 55.45169162750244, "training_acc": 52.5, "val_loss": 13.710083961486816, "val_acc": 55.0}
{"epoch": 11, "training_loss": 55.20712757110596, "training_acc": 53.75, "val_loss": 13.713961839675903, "val_acc": 55.0}
{"epoch": 12, "training_loss": 55.21714782714844, "training_acc": 52.5, "val_loss": 13.715736865997314, "val_acc": 55.0}
{"epoch": 13, "training_loss": 55.075194358825684, "training_acc": 52.5, "val_loss": 13.716522455215454, "val_acc": 55.0}
{"epoch": 14, "training_loss": 55.21384334564209, "training_acc": 53.75, "val_loss": 13.713948726654053, "val_acc": 55.0}
{"epoch": 15, "training_loss": 54.72918510437012, "training_acc": 55.0, "val_loss": 13.695167303085327, "val_acc": 55.0}
{"epoch": 16, "training_loss": 55.152066230773926, "training_acc": 55.0, "val_loss": 13.666707277297974, "val_acc": 55.0}
{"epoch": 17, "training_loss": 55.09407424926758, "training_acc": 52.5, "val_loss": 13.656779527664185, "val_acc": 55.0}
{"epoch": 18, "training_loss": 54.951820373535156, "training_acc": 52.5, "val_loss": 13.652724027633667, "val_acc": 55.0}
{"epoch": 19, "training_loss": 54.820411682128906, "training_acc": 52.5, "val_loss": 13.645161390304565, "val_acc": 55.0}
{"epoch": 20, "training_loss": 55.13472557067871, "training_acc": 53.75, "val_loss": 13.634357452392578, "val_acc": 55.0}
{"epoch": 21, "training_loss": 55.07244110107422, "training_acc": 52.5, "val_loss": 13.624292612075806, "val_acc": 55.0}
{"epoch": 22, "training_loss": 54.83445167541504, "training_acc": 53.75, "val_loss": 13.614232540130615, "val_acc": 55.0}
{"epoch": 23, "training_loss": 54.470706939697266, "training_acc": 56.25, "val_loss": 13.60285758972168, "val_acc": 55.0}
{"epoch": 24, "training_loss": 54.77337455749512, "training_acc": 53.75, "val_loss": 13.589670658111572, "val_acc": 55.0}
{"epoch": 25, "training_loss": 54.6256685256958, "training_acc": 52.5, "val_loss": 13.58461856842041, "val_acc": 55.0}
{"epoch": 26, "training_loss": 54.78672409057617, "training_acc": 52.5, "val_loss": 13.590712547302246, "val_acc": 55.0}
{"epoch": 27, "training_loss": 55.07451820373535, "training_acc": 50.0, "val_loss": 13.604097366333008, "val_acc": 55.0}
{"epoch": 28, "training_loss": 55.166975021362305, "training_acc": 52.5, "val_loss": 13.55682373046875, "val_acc": 55.0}
{"epoch": 29, "training_loss": 54.555466651916504, "training_acc": 52.5, "val_loss": 13.556721210479736, "val_acc": 55.0}
{"epoch": 30, "training_loss": 53.9664306640625, "training_acc": 60.0, "val_loss": 13.5698401927948, "val_acc": 55.0}
{"epoch": 31, "training_loss": 54.61921215057373, "training_acc": 50.0, "val_loss": 13.558605909347534, "val_acc": 55.0}
{"epoch": 32, "training_loss": 53.92860794067383, "training_acc": 68.75, "val_loss": 13.536157608032227, "val_acc": 55.0}
{"epoch": 33, "training_loss": 54.76794242858887, "training_acc": 52.5, "val_loss": 13.509186506271362, "val_acc": 55.0}
{"epoch": 34, "training_loss": 54.044288635253906, "training_acc": 60.0, "val_loss": 13.46474289894104, "val_acc": 55.0}
{"epoch": 35, "training_loss": 53.41656684875488, "training_acc": 66.25, "val_loss": 13.468807935714722, "val_acc": 55.0}
{"epoch": 36, "training_loss": 53.790181159973145, "training_acc": 60.0, "val_loss": 13.436142206192017, "val_acc": 55.0}
{"epoch": 37, "training_loss": 54.35627555847168, "training_acc": 53.75, "val_loss": 13.510180711746216, "val_acc": 55.0}
{"epoch": 38, "training_loss": 54.169694900512695, "training_acc": 68.75, "val_loss": 13.465009927749634, "val_acc": 55.0}
{"epoch": 39, "training_loss": 53.10515213012695, "training_acc": 71.25, "val_loss": 13.475533723831177, "val_acc": 55.0}
{"epoch": 40, "training_loss": 53.27894592285156, "training_acc": 61.25, "val_loss": 13.514357805252075, "val_acc": 55.0}
{"epoch": 41, "training_loss": 53.78617477416992, "training_acc": 56.25, "val_loss": 13.436135053634644, "val_acc": 55.0}
{"epoch": 42, "training_loss": 54.30621337890625, "training_acc": 57.5, "val_loss": 13.773516416549683, "val_acc": 55.0}
