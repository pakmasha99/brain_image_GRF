"main_optuna_fix_3.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3 --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 55.87376403808594, "training_acc": 51.25, "val_loss": 13.764561414718628, "val_acc": 55.0}
{"epoch": 1, "training_loss": 56.149837493896484, "training_acc": 45.0, "val_loss": 16.569979190826416, "val_acc": 55.0}
{"epoch": 2, "training_loss": 67.09018516540527, "training_acc": 52.5, "val_loss": 13.780258893966675, "val_acc": 55.0}
{"epoch": 3, "training_loss": 55.43043899536133, "training_acc": 52.5, "val_loss": 14.180805683135986, "val_acc": 55.0}
{"epoch": 4, "training_loss": 56.32314682006836, "training_acc": 47.5, "val_loss": 13.952504396438599, "val_acc": 55.0}
{"epoch": 5, "training_loss": 55.582298278808594, "training_acc": 50.0, "val_loss": 13.763377666473389, "val_acc": 55.0}
{"epoch": 6, "training_loss": 55.34521293640137, "training_acc": 52.5, "val_loss": 13.779276609420776, "val_acc": 55.0}
{"epoch": 7, "training_loss": 55.68317222595215, "training_acc": 52.5, "val_loss": 13.758872747421265, "val_acc": 55.0}
{"epoch": 8, "training_loss": 55.435715675354004, "training_acc": 52.5, "val_loss": 13.781958818435669, "val_acc": 55.0}
{"epoch": 9, "training_loss": 55.339293479919434, "training_acc": 52.5, "val_loss": 13.991882801055908, "val_acc": 55.0}
{"epoch": 10, "training_loss": 55.878746032714844, "training_acc": 47.5, "val_loss": 13.98826003074646, "val_acc": 55.0}
{"epoch": 11, "training_loss": 55.629940032958984, "training_acc": 47.5, "val_loss": 13.793165683746338, "val_acc": 55.0}
{"epoch": 12, "training_loss": 55.48628902435303, "training_acc": 52.5, "val_loss": 13.743176460266113, "val_acc": 55.0}
{"epoch": 13, "training_loss": 55.37150955200195, "training_acc": 52.5, "val_loss": 13.743751049041748, "val_acc": 55.0}
{"epoch": 14, "training_loss": 55.47806739807129, "training_acc": 52.5, "val_loss": 13.740977048873901, "val_acc": 55.0}
{"epoch": 15, "training_loss": 55.57060241699219, "training_acc": 52.5, "val_loss": 13.753820657730103, "val_acc": 55.0}
{"epoch": 16, "training_loss": 55.335880279541016, "training_acc": 52.5, "val_loss": 13.740473985671997, "val_acc": 55.0}
{"epoch": 17, "training_loss": 55.432894706726074, "training_acc": 52.5, "val_loss": 13.743923902511597, "val_acc": 55.0}
{"epoch": 18, "training_loss": 55.4229850769043, "training_acc": 52.5, "val_loss": 13.736504316329956, "val_acc": 55.0}
{"epoch": 19, "training_loss": 55.2929801940918, "training_acc": 52.5, "val_loss": 13.751884698867798, "val_acc": 55.0}
{"epoch": 20, "training_loss": 55.27231979370117, "training_acc": 52.5, "val_loss": 13.814722299575806, "val_acc": 55.0}
{"epoch": 21, "training_loss": 55.28785228729248, "training_acc": 58.75, "val_loss": 13.852959871292114, "val_acc": 55.0}
{"epoch": 22, "training_loss": 55.34313201904297, "training_acc": 47.5, "val_loss": 13.842190504074097, "val_acc": 55.0}
{"epoch": 23, "training_loss": 55.2906494140625, "training_acc": 55.0, "val_loss": 13.788928985595703, "val_acc": 55.0}
{"epoch": 24, "training_loss": 55.15233039855957, "training_acc": 52.5, "val_loss": 13.745121955871582, "val_acc": 55.0}
{"epoch": 25, "training_loss": 55.003944396972656, "training_acc": 52.5, "val_loss": 13.759331703186035, "val_acc": 55.0}
{"epoch": 26, "training_loss": 55.493255615234375, "training_acc": 52.5, "val_loss": 13.834646940231323, "val_acc": 55.0}
{"epoch": 27, "training_loss": 55.91062545776367, "training_acc": 52.5, "val_loss": 13.865751028060913, "val_acc": 55.0}
{"epoch": 28, "training_loss": 56.17796230316162, "training_acc": 52.5, "val_loss": 13.778976202011108, "val_acc": 55.0}
{"epoch": 29, "training_loss": 55.62939262390137, "training_acc": 52.5, "val_loss": 13.758882284164429, "val_acc": 55.0}
