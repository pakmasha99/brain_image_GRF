"main_optuna_fix_3.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3 --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 56.5397310256958, "training_acc": 40.0, "val_loss": 13.892908096313477, "val_acc": 50.0}
{"epoch": 1, "training_loss": 55.97886085510254, "training_acc": 46.25, "val_loss": 14.03102993965149, "val_acc": 50.0}
{"epoch": 2, "training_loss": 55.24760055541992, "training_acc": 53.75, "val_loss": 13.984653949737549, "val_acc": 50.0}
{"epoch": 3, "training_loss": 55.14926528930664, "training_acc": 53.75, "val_loss": 13.890877962112427, "val_acc": 50.0}
{"epoch": 4, "training_loss": 55.16493034362793, "training_acc": 52.5, "val_loss": 14.045442342758179, "val_acc": 50.0}
{"epoch": 5, "training_loss": 56.49713325500488, "training_acc": 46.25, "val_loss": 13.928508758544922, "val_acc": 50.0}
{"epoch": 6, "training_loss": 55.182291984558105, "training_acc": 53.75, "val_loss": 14.172552824020386, "val_acc": 50.0}
{"epoch": 7, "training_loss": 55.43763732910156, "training_acc": 53.75, "val_loss": 13.947979211807251, "val_acc": 50.0}
{"epoch": 8, "training_loss": 55.1707878112793, "training_acc": 53.75, "val_loss": 13.886079788208008, "val_acc": 50.0}
{"epoch": 9, "training_loss": 55.48550891876221, "training_acc": 51.25, "val_loss": 13.893184661865234, "val_acc": 50.0}
{"epoch": 10, "training_loss": 55.559542655944824, "training_acc": 48.75, "val_loss": 13.93555998802185, "val_acc": 50.0}
{"epoch": 11, "training_loss": 55.148359298706055, "training_acc": 53.75, "val_loss": 14.395126104354858, "val_acc": 50.0}
{"epoch": 12, "training_loss": 55.81118583679199, "training_acc": 53.75, "val_loss": 13.947004079818726, "val_acc": 50.0}
{"epoch": 13, "training_loss": 55.328636169433594, "training_acc": 51.25, "val_loss": 13.929423093795776, "val_acc": 50.0}
{"epoch": 14, "training_loss": 55.0041618347168, "training_acc": 53.75, "val_loss": 14.365706443786621, "val_acc": 50.0}
{"epoch": 15, "training_loss": 55.9253044128418, "training_acc": 53.75, "val_loss": 14.627441167831421, "val_acc": 50.0}
{"epoch": 16, "training_loss": 56.68564414978027, "training_acc": 53.75, "val_loss": 14.186395406723022, "val_acc": 50.0}
{"epoch": 17, "training_loss": 55.38027763366699, "training_acc": 53.75, "val_loss": 13.87897253036499, "val_acc": 50.0}
{"epoch": 18, "training_loss": 55.30841636657715, "training_acc": 51.25, "val_loss": 13.850400447845459, "val_acc": 50.0}
{"epoch": 19, "training_loss": 55.75193977355957, "training_acc": 46.25, "val_loss": 13.851097822189331, "val_acc": 50.0}
{"epoch": 20, "training_loss": 55.73359394073486, "training_acc": 46.25, "val_loss": 13.832306861877441, "val_acc": 50.0}
{"epoch": 21, "training_loss": 55.38716697692871, "training_acc": 52.5, "val_loss": 13.884891271591187, "val_acc": 50.0}
{"epoch": 22, "training_loss": 54.91421127319336, "training_acc": 53.75, "val_loss": 14.267030954360962, "val_acc": 50.0}
{"epoch": 23, "training_loss": 55.398067474365234, "training_acc": 53.75, "val_loss": 14.507020711898804, "val_acc": 50.0}
{"epoch": 24, "training_loss": 56.28488731384277, "training_acc": 53.75, "val_loss": 14.279552698135376, "val_acc": 50.0}
{"epoch": 25, "training_loss": 55.5750675201416, "training_acc": 53.75, "val_loss": 13.97337555885315, "val_acc": 50.0}
{"epoch": 26, "training_loss": 55.151323318481445, "training_acc": 53.75, "val_loss": 13.861773014068604, "val_acc": 50.0}
{"epoch": 27, "training_loss": 55.35604953765869, "training_acc": 53.75, "val_loss": 13.855234384536743, "val_acc": 50.0}
{"epoch": 28, "training_loss": 55.31183052062988, "training_acc": 53.75, "val_loss": 13.859667778015137, "val_acc": 50.0}
{"epoch": 29, "training_loss": 55.134328842163086, "training_acc": 53.75, "val_loss": 13.845512866973877, "val_acc": 50.0}
{"epoch": 30, "training_loss": 55.00647449493408, "training_acc": 55.0, "val_loss": 13.899074792861938, "val_acc": 50.0}
{"epoch": 31, "training_loss": 54.99192523956299, "training_acc": 53.75, "val_loss": 14.082577228546143, "val_acc": 50.0}
{"epoch": 32, "training_loss": 55.08549880981445, "training_acc": 53.75, "val_loss": 14.07099962234497, "val_acc": 50.0}
{"epoch": 33, "training_loss": 55.220685958862305, "training_acc": 53.75, "val_loss": 13.882418870925903, "val_acc": 50.0}
{"epoch": 34, "training_loss": 55.17330360412598, "training_acc": 53.75, "val_loss": 13.831744194030762, "val_acc": 50.0}
{"epoch": 35, "training_loss": 54.900071144104004, "training_acc": 53.75, "val_loss": 13.817414045333862, "val_acc": 50.0}
{"epoch": 36, "training_loss": 55.00184154510498, "training_acc": 60.0, "val_loss": 13.830181360244751, "val_acc": 50.0}
{"epoch": 37, "training_loss": 55.667755126953125, "training_acc": 46.25, "val_loss": 13.897255659103394, "val_acc": 50.0}
{"epoch": 38, "training_loss": 56.04102420806885, "training_acc": 46.25, "val_loss": 13.843291997909546, "val_acc": 50.0}
{"epoch": 39, "training_loss": 55.47461414337158, "training_acc": 45.0, "val_loss": 13.904341459274292, "val_acc": 50.0}
