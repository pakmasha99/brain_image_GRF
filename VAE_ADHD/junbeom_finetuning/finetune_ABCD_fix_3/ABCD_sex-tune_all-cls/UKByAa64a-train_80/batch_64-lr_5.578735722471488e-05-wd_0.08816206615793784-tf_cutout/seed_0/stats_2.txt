"main_optuna_fix_3.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3 --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 56.354331970214844, "training_acc": 42.5, "val_loss": 13.828386068344116, "val_acc": 55.0}
{"epoch": 1, "training_loss": 55.78565788269043, "training_acc": 45.0, "val_loss": 13.742179870605469, "val_acc": 55.0}
{"epoch": 2, "training_loss": 55.697181701660156, "training_acc": 50.0, "val_loss": 14.9489164352417, "val_acc": 55.0}
{"epoch": 3, "training_loss": 60.42168998718262, "training_acc": 52.5, "val_loss": 13.754624128341675, "val_acc": 55.0}
{"epoch": 4, "training_loss": 55.47689247131348, "training_acc": 52.5, "val_loss": 13.79876971244812, "val_acc": 55.0}
{"epoch": 5, "training_loss": 55.35791778564453, "training_acc": 53.75, "val_loss": 13.91668438911438, "val_acc": 55.0}
{"epoch": 6, "training_loss": 55.75381851196289, "training_acc": 47.5, "val_loss": 13.815808296203613, "val_acc": 55.0}
{"epoch": 7, "training_loss": 55.264657974243164, "training_acc": 52.5, "val_loss": 13.751404285430908, "val_acc": 55.0}
{"epoch": 8, "training_loss": 55.76914405822754, "training_acc": 52.5, "val_loss": 13.747761249542236, "val_acc": 55.0}
{"epoch": 9, "training_loss": 55.341153144836426, "training_acc": 52.5, "val_loss": 13.819310665130615, "val_acc": 55.0}
{"epoch": 10, "training_loss": 55.461517333984375, "training_acc": 50.0, "val_loss": 13.89907956123352, "val_acc": 55.0}
{"epoch": 11, "training_loss": 55.508389472961426, "training_acc": 47.5, "val_loss": 13.794583082199097, "val_acc": 55.0}
{"epoch": 12, "training_loss": 55.39999485015869, "training_acc": 52.5, "val_loss": 13.754366636276245, "val_acc": 55.0}
{"epoch": 13, "training_loss": 55.38764190673828, "training_acc": 52.5, "val_loss": 13.75586986541748, "val_acc": 55.0}
{"epoch": 14, "training_loss": 55.36599063873291, "training_acc": 52.5, "val_loss": 13.765325546264648, "val_acc": 55.0}
{"epoch": 15, "training_loss": 55.456403732299805, "training_acc": 52.5, "val_loss": 13.768534660339355, "val_acc": 55.0}
{"epoch": 16, "training_loss": 55.23353958129883, "training_acc": 52.5, "val_loss": 13.74380350112915, "val_acc": 55.0}
{"epoch": 17, "training_loss": 55.579227447509766, "training_acc": 52.5, "val_loss": 13.759218454360962, "val_acc": 55.0}
{"epoch": 18, "training_loss": 55.58747863769531, "training_acc": 52.5, "val_loss": 13.747955560684204, "val_acc": 55.0}
{"epoch": 19, "training_loss": 55.35916519165039, "training_acc": 52.5, "val_loss": 13.772674798965454, "val_acc": 55.0}
{"epoch": 20, "training_loss": 55.343793869018555, "training_acc": 52.5, "val_loss": 13.847229480743408, "val_acc": 55.0}
{"epoch": 21, "training_loss": 55.38655662536621, "training_acc": 58.75, "val_loss": 13.848403692245483, "val_acc": 55.0}
{"epoch": 22, "training_loss": 55.326369285583496, "training_acc": 58.75, "val_loss": 13.792144060134888, "val_acc": 55.0}
{"epoch": 23, "training_loss": 55.193525314331055, "training_acc": 52.5, "val_loss": 13.753499984741211, "val_acc": 55.0}
{"epoch": 24, "training_loss": 55.205801010131836, "training_acc": 52.5, "val_loss": 13.742262125015259, "val_acc": 55.0}
{"epoch": 25, "training_loss": 55.34045600891113, "training_acc": 52.5, "val_loss": 13.766217231750488, "val_acc": 55.0}
{"epoch": 26, "training_loss": 55.60343360900879, "training_acc": 52.5, "val_loss": 13.793827295303345, "val_acc": 55.0}
{"epoch": 27, "training_loss": 55.77481174468994, "training_acc": 52.5, "val_loss": 13.802710771560669, "val_acc": 55.0}
{"epoch": 28, "training_loss": 55.83432960510254, "training_acc": 52.5, "val_loss": 13.746312856674194, "val_acc": 55.0}
{"epoch": 29, "training_loss": 55.446245193481445, "training_acc": 52.5, "val_loss": 13.764146566390991, "val_acc": 55.0}
{"epoch": 30, "training_loss": 55.19547176361084, "training_acc": 52.5, "val_loss": 13.822730779647827, "val_acc": 55.0}
