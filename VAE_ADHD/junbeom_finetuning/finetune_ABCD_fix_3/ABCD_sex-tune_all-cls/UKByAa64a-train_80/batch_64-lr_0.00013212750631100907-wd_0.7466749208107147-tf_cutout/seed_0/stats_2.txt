"main_optuna_fix_3.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3 --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 57.17435932159424, "training_acc": 42.5, "val_loss": 13.777822256088257, "val_acc": 55.0}
{"epoch": 1, "training_loss": 57.864853858947754, "training_acc": 45.0, "val_loss": 14.324370622634888, "val_acc": 55.0}
{"epoch": 2, "training_loss": 58.6795539855957, "training_acc": 50.0, "val_loss": 13.804855346679688, "val_acc": 55.0}
{"epoch": 3, "training_loss": 55.484971046447754, "training_acc": 52.5, "val_loss": 13.90047311782837, "val_acc": 55.0}
{"epoch": 4, "training_loss": 55.77669715881348, "training_acc": 52.5, "val_loss": 14.087351560592651, "val_acc": 55.0}
{"epoch": 5, "training_loss": 56.20821189880371, "training_acc": 47.5, "val_loss": 13.832546472549438, "val_acc": 55.0}
{"epoch": 6, "training_loss": 56.712127685546875, "training_acc": 42.5, "val_loss": 13.782060146331787, "val_acc": 55.0}
{"epoch": 7, "training_loss": 55.28569412231445, "training_acc": 52.5, "val_loss": 13.918935060501099, "val_acc": 55.0}
{"epoch": 8, "training_loss": 56.155985832214355, "training_acc": 52.5, "val_loss": 13.823314905166626, "val_acc": 55.0}
{"epoch": 9, "training_loss": 55.19449424743652, "training_acc": 55.0, "val_loss": 14.22852873802185, "val_acc": 55.0}
{"epoch": 10, "training_loss": 56.44596862792969, "training_acc": 47.5, "val_loss": 13.963593244552612, "val_acc": 55.0}
{"epoch": 11, "training_loss": 55.338494300842285, "training_acc": 52.5, "val_loss": 13.79381775856018, "val_acc": 55.0}
{"epoch": 12, "training_loss": 56.16141891479492, "training_acc": 52.5, "val_loss": 13.842663764953613, "val_acc": 55.0}
{"epoch": 13, "training_loss": 55.94932270050049, "training_acc": 52.5, "val_loss": 13.777183294296265, "val_acc": 55.0}
{"epoch": 14, "training_loss": 55.31230545043945, "training_acc": 52.5, "val_loss": 13.910363912582397, "val_acc": 55.0}
{"epoch": 15, "training_loss": 55.737985610961914, "training_acc": 47.5, "val_loss": 13.857749700546265, "val_acc": 55.0}
{"epoch": 16, "training_loss": 55.28111267089844, "training_acc": 52.5, "val_loss": 13.757028579711914, "val_acc": 55.0}
{"epoch": 17, "training_loss": 55.562889099121094, "training_acc": 52.5, "val_loss": 13.758083581924438, "val_acc": 55.0}
{"epoch": 18, "training_loss": 55.50299835205078, "training_acc": 52.5, "val_loss": 13.767662048339844, "val_acc": 55.0}
{"epoch": 19, "training_loss": 55.29919242858887, "training_acc": 52.5, "val_loss": 13.867206573486328, "val_acc": 55.0}
{"epoch": 20, "training_loss": 55.53898620605469, "training_acc": 47.5, "val_loss": 13.899577856063843, "val_acc": 55.0}
{"epoch": 21, "training_loss": 55.45774269104004, "training_acc": 50.0, "val_loss": 13.76051664352417, "val_acc": 55.0}
{"epoch": 22, "training_loss": 55.35383129119873, "training_acc": 52.5, "val_loss": 13.835134506225586, "val_acc": 55.0}
{"epoch": 23, "training_loss": 55.830379486083984, "training_acc": 52.5, "val_loss": 13.759725093841553, "val_acc": 55.0}
{"epoch": 24, "training_loss": 55.64525318145752, "training_acc": 52.5, "val_loss": 13.765643835067749, "val_acc": 55.0}
{"epoch": 25, "training_loss": 55.31793212890625, "training_acc": 52.5, "val_loss": 13.76106858253479, "val_acc": 55.0}
{"epoch": 26, "training_loss": 55.52503967285156, "training_acc": 52.5, "val_loss": 13.785775899887085, "val_acc": 55.0}
{"epoch": 27, "training_loss": 55.7055139541626, "training_acc": 52.5, "val_loss": 13.813034296035767, "val_acc": 55.0}
{"epoch": 28, "training_loss": 55.88693809509277, "training_acc": 52.5, "val_loss": 13.759881258010864, "val_acc": 55.0}
{"epoch": 29, "training_loss": 55.439781188964844, "training_acc": 52.5, "val_loss": 13.867591619491577, "val_acc": 55.0}
{"epoch": 30, "training_loss": 55.482778549194336, "training_acc": 47.5, "val_loss": 13.876948356628418, "val_acc": 55.0}
