"main_optuna_fix_3.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3 --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 56.72994804382324, "training_acc": 51.25, "val_loss": 13.682156801223755, "val_acc": 55.0}
{"epoch": 1, "training_loss": 55.55972862243652, "training_acc": 52.5, "val_loss": 51.11797332763672, "val_acc": 55.0}
{"epoch": 2, "training_loss": 185.05140686035156, "training_acc": 52.5, "val_loss": 14.579399824142456, "val_acc": 55.0}
{"epoch": 3, "training_loss": 57.74215507507324, "training_acc": 47.5, "val_loss": 14.395924806594849, "val_acc": 55.0}
{"epoch": 4, "training_loss": 56.53123092651367, "training_acc": 47.5, "val_loss": 13.784908056259155, "val_acc": 55.0}
{"epoch": 5, "training_loss": 55.32645320892334, "training_acc": 52.5, "val_loss": 13.845157623291016, "val_acc": 55.0}
{"epoch": 6, "training_loss": 55.99533271789551, "training_acc": 52.5, "val_loss": 13.766827583312988, "val_acc": 55.0}
{"epoch": 7, "training_loss": 55.32367134094238, "training_acc": 53.75, "val_loss": 14.130134582519531, "val_acc": 55.0}
{"epoch": 8, "training_loss": 56.83333778381348, "training_acc": 42.5, "val_loss": 13.828047513961792, "val_acc": 55.0}
{"epoch": 9, "training_loss": 55.344905853271484, "training_acc": 52.5, "val_loss": 13.905918598175049, "val_acc": 55.0}
{"epoch": 10, "training_loss": 55.575578689575195, "training_acc": 47.5, "val_loss": 13.779597282409668, "val_acc": 55.0}
{"epoch": 11, "training_loss": 55.18032646179199, "training_acc": 52.5, "val_loss": 13.818275928497314, "val_acc": 55.0}
{"epoch": 12, "training_loss": 56.09658432006836, "training_acc": 52.5, "val_loss": 13.804649114608765, "val_acc": 55.0}
{"epoch": 13, "training_loss": 55.92108726501465, "training_acc": 52.5, "val_loss": 13.771828413009644, "val_acc": 55.0}
{"epoch": 14, "training_loss": 55.270896911621094, "training_acc": 52.5, "val_loss": 13.92532229423523, "val_acc": 55.0}
{"epoch": 15, "training_loss": 55.904592514038086, "training_acc": 47.5, "val_loss": 13.931565284729004, "val_acc": 55.0}
{"epoch": 16, "training_loss": 55.344666481018066, "training_acc": 50.0, "val_loss": 13.766919374465942, "val_acc": 55.0}
{"epoch": 17, "training_loss": 55.55709171295166, "training_acc": 52.5, "val_loss": 13.786184787750244, "val_acc": 55.0}
{"epoch": 18, "training_loss": 55.742483139038086, "training_acc": 52.5, "val_loss": 13.773225545883179, "val_acc": 55.0}
{"epoch": 19, "training_loss": 55.53048324584961, "training_acc": 52.5, "val_loss": 13.773703575134277, "val_acc": 55.0}
{"epoch": 20, "training_loss": 55.39584922790527, "training_acc": 52.5, "val_loss": 13.868412971496582, "val_acc": 55.0}
{"epoch": 21, "training_loss": 55.4494686126709, "training_acc": 47.5, "val_loss": 13.910611867904663, "val_acc": 55.0}
{"epoch": 22, "training_loss": 55.534067153930664, "training_acc": 47.5, "val_loss": 13.861654996871948, "val_acc": 55.0}
{"epoch": 23, "training_loss": 55.387542724609375, "training_acc": 50.0, "val_loss": 13.78970980644226, "val_acc": 55.0}
{"epoch": 24, "training_loss": 55.2341194152832, "training_acc": 52.5, "val_loss": 13.759396076202393, "val_acc": 55.0}
{"epoch": 25, "training_loss": 55.28193378448486, "training_acc": 52.5, "val_loss": 13.790205717086792, "val_acc": 55.0}
{"epoch": 26, "training_loss": 55.73524284362793, "training_acc": 52.5, "val_loss": 13.853992223739624, "val_acc": 55.0}
{"epoch": 27, "training_loss": 56.1398401260376, "training_acc": 52.5, "val_loss": 13.862806558609009, "val_acc": 55.0}
{"epoch": 28, "training_loss": 56.180877685546875, "training_acc": 52.5, "val_loss": 13.790788650512695, "val_acc": 55.0}
{"epoch": 29, "training_loss": 55.75300884246826, "training_acc": 52.5, "val_loss": 13.767279386520386, "val_acc": 55.0}
{"epoch": 30, "training_loss": 55.293585777282715, "training_acc": 52.5, "val_loss": 13.839257955551147, "val_acc": 55.0}
{"epoch": 31, "training_loss": 55.34132480621338, "training_acc": 57.5, "val_loss": 13.95861029624939, "val_acc": 55.0}
{"epoch": 32, "training_loss": 55.645761489868164, "training_acc": 47.5, "val_loss": 14.041045904159546, "val_acc": 55.0}
{"epoch": 33, "training_loss": 55.8944091796875, "training_acc": 47.5, "val_loss": 13.955055475234985, "val_acc": 55.0}
{"epoch": 34, "training_loss": 55.609862327575684, "training_acc": 47.5, "val_loss": 13.838701248168945, "val_acc": 55.0}
{"epoch": 35, "training_loss": 55.4576530456543, "training_acc": 52.5, "val_loss": 13.780497312545776, "val_acc": 55.0}
{"epoch": 36, "training_loss": 55.29375648498535, "training_acc": 52.5, "val_loss": 13.763269186019897, "val_acc": 55.0}
{"epoch": 37, "training_loss": 55.39493751525879, "training_acc": 52.5, "val_loss": 13.75938892364502, "val_acc": 55.0}
{"epoch": 38, "training_loss": 55.42502975463867, "training_acc": 52.5, "val_loss": 13.759173154830933, "val_acc": 55.0}
{"epoch": 39, "training_loss": 55.42536544799805, "training_acc": 52.5, "val_loss": 13.758596181869507, "val_acc": 55.0}
{"epoch": 40, "training_loss": 55.37787055969238, "training_acc": 52.5, "val_loss": 13.763946294784546, "val_acc": 55.0}
{"epoch": 41, "training_loss": 55.29012489318848, "training_acc": 52.5, "val_loss": 13.792260885238647, "val_acc": 55.0}
{"epoch": 42, "training_loss": 55.35588073730469, "training_acc": 52.5, "val_loss": 13.843832015991211, "val_acc": 55.0}
{"epoch": 43, "training_loss": 55.368791580200195, "training_acc": 51.25, "val_loss": 13.858880996704102, "val_acc": 55.0}
{"epoch": 44, "training_loss": 55.43961143493652, "training_acc": 51.25, "val_loss": 13.860534429550171, "val_acc": 55.0}
{"epoch": 45, "training_loss": 55.40450477600098, "training_acc": 53.75, "val_loss": 13.869860172271729, "val_acc": 55.0}
