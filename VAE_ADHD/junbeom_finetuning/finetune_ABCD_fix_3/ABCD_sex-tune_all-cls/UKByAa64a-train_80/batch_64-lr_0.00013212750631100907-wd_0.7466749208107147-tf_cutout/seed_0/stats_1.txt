"main_optuna_fix_3.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3 --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 56.31398010253906, "training_acc": 52.5, "val_loss": 13.892151117324829, "val_acc": 50.0}
{"epoch": 1, "training_loss": 56.18075656890869, "training_acc": 45.0, "val_loss": 16.890209913253784, "val_acc": 50.0}
{"epoch": 2, "training_loss": 62.56690788269043, "training_acc": 53.75, "val_loss": 13.783094882965088, "val_acc": 50.0}
{"epoch": 3, "training_loss": 55.44474697113037, "training_acc": 52.5, "val_loss": 13.81041407585144, "val_acc": 50.0}
{"epoch": 4, "training_loss": 56.526649475097656, "training_acc": 46.25, "val_loss": 13.975454568862915, "val_acc": 50.0}
{"epoch": 5, "training_loss": 55.42208480834961, "training_acc": 52.5, "val_loss": 13.851603269577026, "val_acc": 50.0}
{"epoch": 6, "training_loss": 55.269700050354004, "training_acc": 53.75, "val_loss": 14.047415256500244, "val_acc": 50.0}
{"epoch": 7, "training_loss": 55.376718521118164, "training_acc": 53.75, "val_loss": 14.04201865196228, "val_acc": 50.0}
{"epoch": 8, "training_loss": 55.307254791259766, "training_acc": 53.75, "val_loss": 13.847966194152832, "val_acc": 50.0}
{"epoch": 9, "training_loss": 55.47097206115723, "training_acc": 43.75, "val_loss": 13.88457179069519, "val_acc": 50.0}
{"epoch": 10, "training_loss": 55.875532150268555, "training_acc": 46.25, "val_loss": 13.889039754867554, "val_acc": 50.0}
{"epoch": 11, "training_loss": 55.12795448303223, "training_acc": 53.75, "val_loss": 14.180611371994019, "val_acc": 50.0}
{"epoch": 12, "training_loss": 55.59067153930664, "training_acc": 53.75, "val_loss": 14.028528928756714, "val_acc": 50.0}
{"epoch": 13, "training_loss": 55.50372886657715, "training_acc": 53.75, "val_loss": 13.924177885055542, "val_acc": 50.0}
{"epoch": 14, "training_loss": 55.2311897277832, "training_acc": 53.75, "val_loss": 14.106190204620361, "val_acc": 50.0}
{"epoch": 15, "training_loss": 55.392024993896484, "training_acc": 53.75, "val_loss": 14.438447952270508, "val_acc": 50.0}
{"epoch": 16, "training_loss": 56.330013275146484, "training_acc": 53.75, "val_loss": 14.299317598342896, "val_acc": 50.0}
{"epoch": 17, "training_loss": 55.74207401275635, "training_acc": 53.75, "val_loss": 13.935606479644775, "val_acc": 50.0}
{"epoch": 18, "training_loss": 55.24737739562988, "training_acc": 53.75, "val_loss": 13.861808776855469, "val_acc": 50.0}
{"epoch": 19, "training_loss": 55.593796730041504, "training_acc": 46.25, "val_loss": 13.877284526824951, "val_acc": 50.0}
{"epoch": 20, "training_loss": 55.813682556152344, "training_acc": 46.25, "val_loss": 13.866732120513916, "val_acc": 50.0}
{"epoch": 21, "training_loss": 55.631521224975586, "training_acc": 46.25, "val_loss": 13.86418104171753, "val_acc": 50.0}
{"epoch": 22, "training_loss": 55.090301513671875, "training_acc": 53.75, "val_loss": 14.075113534927368, "val_acc": 50.0}
{"epoch": 23, "training_loss": 55.309993743896484, "training_acc": 53.75, "val_loss": 14.325400590896606, "val_acc": 50.0}
{"epoch": 24, "training_loss": 55.9789400100708, "training_acc": 53.75, "val_loss": 14.343503713607788, "val_acc": 50.0}
{"epoch": 25, "training_loss": 56.0107479095459, "training_acc": 53.75, "val_loss": 14.115122556686401, "val_acc": 50.0}
{"epoch": 26, "training_loss": 55.52517509460449, "training_acc": 53.75, "val_loss": 13.915646076202393, "val_acc": 50.0}
{"epoch": 27, "training_loss": 55.22372245788574, "training_acc": 53.75, "val_loss": 13.873180150985718, "val_acc": 50.0}
{"epoch": 28, "training_loss": 55.40584182739258, "training_acc": 53.75, "val_loss": 13.86765718460083, "val_acc": 50.0}
{"epoch": 29, "training_loss": 55.411176681518555, "training_acc": 51.25, "val_loss": 13.86832594871521, "val_acc": 50.0}
{"epoch": 30, "training_loss": 55.43351364135742, "training_acc": 53.75, "val_loss": 13.886189460754395, "val_acc": 50.0}
{"epoch": 31, "training_loss": 55.19379425048828, "training_acc": 53.75, "val_loss": 14.002606868743896, "val_acc": 50.0}
{"epoch": 32, "training_loss": 55.35902976989746, "training_acc": 53.75, "val_loss": 14.049444198608398, "val_acc": 50.0}
{"epoch": 33, "training_loss": 55.35438346862793, "training_acc": 53.75, "val_loss": 13.97059679031372, "val_acc": 50.0}
{"epoch": 34, "training_loss": 55.27844429016113, "training_acc": 53.75, "val_loss": 13.915876150131226, "val_acc": 50.0}
{"epoch": 35, "training_loss": 55.171810150146484, "training_acc": 53.75, "val_loss": 13.87413501739502, "val_acc": 50.0}
{"epoch": 36, "training_loss": 55.166354179382324, "training_acc": 53.75, "val_loss": 13.86569857597351, "val_acc": 50.0}
{"epoch": 37, "training_loss": 55.58892250061035, "training_acc": 46.25, "val_loss": 13.937157392501831, "val_acc": 50.0}
{"epoch": 38, "training_loss": 56.29695129394531, "training_acc": 46.25, "val_loss": 13.928104639053345, "val_acc": 50.0}
{"epoch": 39, "training_loss": 56.06569290161133, "training_acc": 46.25, "val_loss": 13.871903419494629, "val_acc": 50.0}
