"main_optuna_fix_3.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3 --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 56.202138900756836, "training_acc": 48.75, "val_loss": 13.736904859542847, "val_acc": 55.0}
{"epoch": 1, "training_loss": 55.031944274902344, "training_acc": 52.5, "val_loss": 17.001842260360718, "val_acc": 45.0}
{"epoch": 2, "training_loss": 61.51079273223877, "training_acc": 47.5, "val_loss": 14.105774164199829, "val_acc": 55.0}
{"epoch": 3, "training_loss": 57.27267074584961, "training_acc": 52.5, "val_loss": 14.061640501022339, "val_acc": 55.0}
{"epoch": 4, "training_loss": 56.186086654663086, "training_acc": 47.5, "val_loss": 13.828829526901245, "val_acc": 55.0}
{"epoch": 5, "training_loss": 55.57144737243652, "training_acc": 52.5, "val_loss": 13.75605821609497, "val_acc": 55.0}
{"epoch": 6, "training_loss": 55.73462963104248, "training_acc": 52.5, "val_loss": 13.812510967254639, "val_acc": 55.0}
{"epoch": 7, "training_loss": 55.33511543273926, "training_acc": 52.5, "val_loss": 13.86656403541565, "val_acc": 55.0}
{"epoch": 8, "training_loss": 55.58310508728027, "training_acc": 51.25, "val_loss": 13.990811109542847, "val_acc": 55.0}
{"epoch": 9, "training_loss": 56.341012954711914, "training_acc": 47.5, "val_loss": 13.869262933731079, "val_acc": 55.0}
{"epoch": 10, "training_loss": 55.2864933013916, "training_acc": 55.0, "val_loss": 13.788973093032837, "val_acc": 55.0}
{"epoch": 11, "training_loss": 55.75747871398926, "training_acc": 52.5, "val_loss": 13.857473134994507, "val_acc": 55.0}
{"epoch": 12, "training_loss": 56.31377601623535, "training_acc": 52.5, "val_loss": 13.797836303710938, "val_acc": 55.0}
{"epoch": 13, "training_loss": 55.904762268066406, "training_acc": 52.5, "val_loss": 13.783676624298096, "val_acc": 55.0}
{"epoch": 14, "training_loss": 55.31168174743652, "training_acc": 52.5, "val_loss": 13.911473751068115, "val_acc": 55.0}
{"epoch": 15, "training_loss": 55.728535652160645, "training_acc": 47.5, "val_loss": 13.984614610671997, "val_acc": 55.0}
{"epoch": 16, "training_loss": 55.589067459106445, "training_acc": 47.5, "val_loss": 13.81032943725586, "val_acc": 55.0}
{"epoch": 17, "training_loss": 55.39564037322998, "training_acc": 52.5, "val_loss": 13.774633407592773, "val_acc": 55.0}
{"epoch": 18, "training_loss": 55.6667423248291, "training_acc": 52.5, "val_loss": 13.784798383712769, "val_acc": 55.0}
{"epoch": 19, "training_loss": 55.6127233505249, "training_acc": 52.5, "val_loss": 13.764938116073608, "val_acc": 55.0}
{"epoch": 20, "training_loss": 55.35940170288086, "training_acc": 52.5, "val_loss": 13.821636438369751, "val_acc": 55.0}
{"epoch": 21, "training_loss": 55.42707443237305, "training_acc": 50.0, "val_loss": 13.891496658325195, "val_acc": 55.0}
{"epoch": 22, "training_loss": 55.505191802978516, "training_acc": 47.5, "val_loss": 13.878540992736816, "val_acc": 55.0}
{"epoch": 23, "training_loss": 55.45137405395508, "training_acc": 47.5, "val_loss": 13.814862966537476, "val_acc": 55.0}
{"epoch": 24, "training_loss": 55.38081455230713, "training_acc": 52.5, "val_loss": 13.7675142288208, "val_acc": 55.0}
