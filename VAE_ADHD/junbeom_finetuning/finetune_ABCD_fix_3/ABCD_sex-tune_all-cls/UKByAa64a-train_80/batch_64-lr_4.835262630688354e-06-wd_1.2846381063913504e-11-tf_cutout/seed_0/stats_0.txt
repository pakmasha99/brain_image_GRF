"main_optuna_fix_3.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3 --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 56.023298263549805, "training_acc": 46.25, "val_loss": 13.89347791671753, "val_acc": 50.0}
{"epoch": 1, "training_loss": 55.6137580871582, "training_acc": 43.75, "val_loss": 13.903893232345581, "val_acc": 50.0}
{"epoch": 2, "training_loss": 55.44564247131348, "training_acc": 55.0, "val_loss": 13.91919493675232, "val_acc": 50.0}
{"epoch": 3, "training_loss": 55.17197036743164, "training_acc": 53.75, "val_loss": 13.941646814346313, "val_acc": 50.0}
{"epoch": 4, "training_loss": 55.18924808502197, "training_acc": 53.75, "val_loss": 13.953417539596558, "val_acc": 50.0}
{"epoch": 5, "training_loss": 55.23907661437988, "training_acc": 53.75, "val_loss": 13.95207166671753, "val_acc": 50.0}
{"epoch": 6, "training_loss": 55.13233661651611, "training_acc": 53.75, "val_loss": 13.943439722061157, "val_acc": 50.0}
{"epoch": 7, "training_loss": 55.15960884094238, "training_acc": 53.75, "val_loss": 13.940962553024292, "val_acc": 50.0}
{"epoch": 8, "training_loss": 55.06049823760986, "training_acc": 53.75, "val_loss": 13.931905031204224, "val_acc": 50.0}
{"epoch": 9, "training_loss": 55.05970573425293, "training_acc": 53.75, "val_loss": 13.929072618484497, "val_acc": 50.0}
{"epoch": 10, "training_loss": 55.021820068359375, "training_acc": 53.75, "val_loss": 13.934919834136963, "val_acc": 50.0}
{"epoch": 11, "training_loss": 54.84860134124756, "training_acc": 53.75, "val_loss": 13.962239027023315, "val_acc": 50.0}
{"epoch": 12, "training_loss": 54.89478588104248, "training_acc": 53.75, "val_loss": 14.009561538696289, "val_acc": 50.0}
{"epoch": 13, "training_loss": 54.87215042114258, "training_acc": 53.75, "val_loss": 14.059193134307861, "val_acc": 50.0}
{"epoch": 14, "training_loss": 54.81606674194336, "training_acc": 53.75, "val_loss": 14.123908281326294, "val_acc": 50.0}
{"epoch": 15, "training_loss": 54.96308517456055, "training_acc": 53.75, "val_loss": 14.204232692718506, "val_acc": 50.0}
{"epoch": 16, "training_loss": 55.41447067260742, "training_acc": 53.75, "val_loss": 14.259756803512573, "val_acc": 50.0}
{"epoch": 17, "training_loss": 55.21719169616699, "training_acc": 53.75, "val_loss": 14.269027709960938, "val_acc": 50.0}
{"epoch": 18, "training_loss": 55.04063034057617, "training_acc": 53.75, "val_loss": 14.230951070785522, "val_acc": 50.0}
{"epoch": 19, "training_loss": 54.88971710205078, "training_acc": 53.75, "val_loss": 14.157344102859497, "val_acc": 50.0}
{"epoch": 20, "training_loss": 54.658084869384766, "training_acc": 53.75, "val_loss": 14.020079374313354, "val_acc": 50.0}
{"epoch": 21, "training_loss": 55.01080894470215, "training_acc": 55.0, "val_loss": 13.948801755905151, "val_acc": 50.0}
{"epoch": 22, "training_loss": 55.00464153289795, "training_acc": 57.5, "val_loss": 13.923066854476929, "val_acc": 50.0}
{"epoch": 23, "training_loss": 55.14160919189453, "training_acc": 56.25, "val_loss": 13.92762541770935, "val_acc": 50.0}
{"epoch": 24, "training_loss": 55.00638961791992, "training_acc": 56.25, "val_loss": 13.920267820358276, "val_acc": 50.0}
{"epoch": 25, "training_loss": 54.96253490447998, "training_acc": 55.0, "val_loss": 13.94665002822876, "val_acc": 50.0}
{"epoch": 26, "training_loss": 55.002607345581055, "training_acc": 53.75, "val_loss": 13.962219953536987, "val_acc": 50.0}
{"epoch": 27, "training_loss": 54.76977062225342, "training_acc": 53.75, "val_loss": 13.99173378944397, "val_acc": 50.0}
{"epoch": 28, "training_loss": 54.773128509521484, "training_acc": 53.75, "val_loss": 14.024896621704102, "val_acc": 50.0}
{"epoch": 29, "training_loss": 54.50428295135498, "training_acc": 53.75, "val_loss": 14.048707485198975, "val_acc": 50.0}
{"epoch": 30, "training_loss": 54.656776428222656, "training_acc": 53.75, "val_loss": 14.074815511703491, "val_acc": 50.0}
{"epoch": 31, "training_loss": 54.740617752075195, "training_acc": 53.75, "val_loss": 14.091802835464478, "val_acc": 50.0}
{"epoch": 32, "training_loss": 54.326507568359375, "training_acc": 53.75, "val_loss": 14.089142084121704, "val_acc": 50.0}
{"epoch": 33, "training_loss": 54.654998779296875, "training_acc": 53.75, "val_loss": 14.085052013397217, "val_acc": 50.0}
{"epoch": 34, "training_loss": 54.625186920166016, "training_acc": 53.75, "val_loss": 14.101780652999878, "val_acc": 50.0}
