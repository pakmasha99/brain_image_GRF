"main_optuna_fix_3.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3 --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 56.20262145996094, "training_acc": 47.5, "val_loss": 13.854788541793823, "val_acc": 55.0}
{"epoch": 1, "training_loss": 55.7899112701416, "training_acc": 41.25, "val_loss": 13.80022406578064, "val_acc": 55.0}
{"epoch": 2, "training_loss": 55.42651557922363, "training_acc": 52.5, "val_loss": 13.75643253326416, "val_acc": 55.0}
{"epoch": 3, "training_loss": 55.328514099121094, "training_acc": 52.5, "val_loss": 13.723591566085815, "val_acc": 55.0}
{"epoch": 4, "training_loss": 55.32246494293213, "training_acc": 52.5, "val_loss": 13.70556116104126, "val_acc": 55.0}
{"epoch": 5, "training_loss": 55.33958721160889, "training_acc": 52.5, "val_loss": 13.699840307235718, "val_acc": 55.0}
{"epoch": 6, "training_loss": 55.428470611572266, "training_acc": 52.5, "val_loss": 13.695499897003174, "val_acc": 55.0}
{"epoch": 7, "training_loss": 55.18730926513672, "training_acc": 52.5, "val_loss": 13.685238361358643, "val_acc": 55.0}
{"epoch": 8, "training_loss": 55.24970054626465, "training_acc": 52.5, "val_loss": 13.68051528930664, "val_acc": 55.0}
{"epoch": 9, "training_loss": 55.150872230529785, "training_acc": 52.5, "val_loss": 13.68008017539978, "val_acc": 55.0}
{"epoch": 10, "training_loss": 55.440762519836426, "training_acc": 52.5, "val_loss": 13.692905902862549, "val_acc": 55.0}
{"epoch": 11, "training_loss": 55.1420841217041, "training_acc": 52.5, "val_loss": 13.699744939804077, "val_acc": 55.0}
{"epoch": 12, "training_loss": 55.11921787261963, "training_acc": 52.5, "val_loss": 13.694415092468262, "val_acc": 55.0}
{"epoch": 13, "training_loss": 54.95987796783447, "training_acc": 52.5, "val_loss": 13.680148124694824, "val_acc": 55.0}
{"epoch": 14, "training_loss": 55.12095642089844, "training_acc": 52.5, "val_loss": 13.66237759590149, "val_acc": 55.0}
{"epoch": 15, "training_loss": 54.48837661743164, "training_acc": 52.5, "val_loss": 13.6452317237854, "val_acc": 55.0}
{"epoch": 16, "training_loss": 55.225510597229004, "training_acc": 53.75, "val_loss": 13.645519018173218, "val_acc": 55.0}
{"epoch": 17, "training_loss": 55.0976619720459, "training_acc": 52.5, "val_loss": 13.613425493240356, "val_acc": 55.0}
{"epoch": 18, "training_loss": 54.771270751953125, "training_acc": 52.5, "val_loss": 13.601604700088501, "val_acc": 55.0}
{"epoch": 19, "training_loss": 54.491010665893555, "training_acc": 55.0, "val_loss": 13.610644340515137, "val_acc": 55.0}
{"epoch": 20, "training_loss": 54.95715808868408, "training_acc": 53.75, "val_loss": 13.617051839828491, "val_acc": 55.0}
{"epoch": 21, "training_loss": 54.85115909576416, "training_acc": 53.75, "val_loss": 13.569625616073608, "val_acc": 55.0}
{"epoch": 22, "training_loss": 54.474042892456055, "training_acc": 52.5, "val_loss": 13.5312020778656, "val_acc": 55.0}
{"epoch": 23, "training_loss": 54.11777687072754, "training_acc": 61.25, "val_loss": 13.530410528182983, "val_acc": 55.0}
{"epoch": 24, "training_loss": 54.555039405822754, "training_acc": 55.0, "val_loss": 13.508683443069458, "val_acc": 55.0}
{"epoch": 25, "training_loss": 54.20921516418457, "training_acc": 53.75, "val_loss": 13.499674797058105, "val_acc": 55.0}
{"epoch": 26, "training_loss": 54.478057861328125, "training_acc": 51.25, "val_loss": 13.505635261535645, "val_acc": 55.0}
{"epoch": 27, "training_loss": 54.76881217956543, "training_acc": 52.5, "val_loss": 13.516347408294678, "val_acc": 55.0}
{"epoch": 28, "training_loss": 54.83077430725098, "training_acc": 52.5, "val_loss": 13.435019254684448, "val_acc": 55.0}
{"epoch": 29, "training_loss": 53.903517723083496, "training_acc": 53.75, "val_loss": 13.567131757736206, "val_acc": 55.0}
{"epoch": 30, "training_loss": 53.92357063293457, "training_acc": 76.25, "val_loss": 13.517979383468628, "val_acc": 55.0}
{"epoch": 31, "training_loss": 54.33135986328125, "training_acc": 63.75, "val_loss": 13.389164209365845, "val_acc": 55.0}
{"epoch": 32, "training_loss": 53.054640769958496, "training_acc": 68.75, "val_loss": 13.339996337890625, "val_acc": 55.0}
{"epoch": 33, "training_loss": 54.12963390350342, "training_acc": 53.75, "val_loss": 13.297672271728516, "val_acc": 55.0}
{"epoch": 34, "training_loss": 52.99556541442871, "training_acc": 58.75, "val_loss": 13.272045850753784, "val_acc": 55.0}
{"epoch": 35, "training_loss": 52.10407066345215, "training_acc": 66.25, "val_loss": 13.247238397598267, "val_acc": 55.0}
