"main_optuna_fix_3.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3 --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 55.43278503417969, "training_acc": 57.5, "val_loss": 13.835704326629639, "val_acc": 55.0}
{"epoch": 1, "training_loss": 55.49433898925781, "training_acc": 52.5, "val_loss": 13.820806741714478, "val_acc": 55.0}
{"epoch": 2, "training_loss": 55.317458152770996, "training_acc": 52.5, "val_loss": 13.794937133789062, "val_acc": 55.0}
{"epoch": 3, "training_loss": 55.346601486206055, "training_acc": 52.5, "val_loss": 13.775495290756226, "val_acc": 55.0}
{"epoch": 4, "training_loss": 55.363351821899414, "training_acc": 52.5, "val_loss": 13.765817880630493, "val_acc": 55.0}
{"epoch": 5, "training_loss": 55.28627395629883, "training_acc": 52.5, "val_loss": 13.771699666976929, "val_acc": 55.0}
{"epoch": 6, "training_loss": 55.309600830078125, "training_acc": 52.5, "val_loss": 13.778918981552124, "val_acc": 55.0}
{"epoch": 7, "training_loss": 55.156240463256836, "training_acc": 52.5, "val_loss": 13.77681851387024, "val_acc": 55.0}
{"epoch": 8, "training_loss": 55.12122344970703, "training_acc": 52.5, "val_loss": 13.779453039169312, "val_acc": 55.0}
{"epoch": 9, "training_loss": 55.217214584350586, "training_acc": 52.5, "val_loss": 13.78832221031189, "val_acc": 55.0}
{"epoch": 10, "training_loss": 55.04447937011719, "training_acc": 52.5, "val_loss": 13.777070045471191, "val_acc": 55.0}
{"epoch": 11, "training_loss": 55.0384578704834, "training_acc": 52.5, "val_loss": 13.773221969604492, "val_acc": 55.0}
{"epoch": 12, "training_loss": 54.99557304382324, "training_acc": 52.5, "val_loss": 13.763240575790405, "val_acc": 55.0}
{"epoch": 13, "training_loss": 55.07577610015869, "training_acc": 52.5, "val_loss": 13.752788305282593, "val_acc": 55.0}
{"epoch": 14, "training_loss": 54.7039852142334, "training_acc": 52.5, "val_loss": 13.748070001602173, "val_acc": 55.0}
{"epoch": 15, "training_loss": 55.00331211090088, "training_acc": 52.5, "val_loss": 13.770920038223267, "val_acc": 55.0}
{"epoch": 16, "training_loss": 55.15938758850098, "training_acc": 52.5, "val_loss": 13.782793283462524, "val_acc": 55.0}
{"epoch": 17, "training_loss": 54.81981086730957, "training_acc": 52.5, "val_loss": 13.761541843414307, "val_acc": 55.0}
{"epoch": 18, "training_loss": 54.563344955444336, "training_acc": 52.5, "val_loss": 13.747314214706421, "val_acc": 55.0}
{"epoch": 19, "training_loss": 54.47283172607422, "training_acc": 52.5, "val_loss": 13.759644031524658, "val_acc": 55.0}
{"epoch": 20, "training_loss": 54.78753471374512, "training_acc": 52.5, "val_loss": 13.791581392288208, "val_acc": 55.0}
{"epoch": 21, "training_loss": 54.89663505554199, "training_acc": 56.25, "val_loss": 13.799253702163696, "val_acc": 55.0}
{"epoch": 22, "training_loss": 54.45067024230957, "training_acc": 55.0, "val_loss": 13.780937194824219, "val_acc": 55.0}
{"epoch": 23, "training_loss": 54.65663242340088, "training_acc": 57.5, "val_loss": 13.793835639953613, "val_acc": 55.0}
{"epoch": 24, "training_loss": 54.310211181640625, "training_acc": 60.0, "val_loss": 13.772670030593872, "val_acc": 55.0}
{"epoch": 25, "training_loss": 53.818251609802246, "training_acc": 61.25, "val_loss": 13.735458850860596, "val_acc": 55.0}
{"epoch": 26, "training_loss": 54.46660327911377, "training_acc": 57.5, "val_loss": 13.726288080215454, "val_acc": 55.0}
{"epoch": 27, "training_loss": 53.67521667480469, "training_acc": 62.5, "val_loss": 13.744921684265137, "val_acc": 55.0}
{"epoch": 28, "training_loss": 54.20383262634277, "training_acc": 58.75, "val_loss": 13.900375366210938, "val_acc": 55.0}
{"epoch": 29, "training_loss": 54.30513095855713, "training_acc": 67.5, "val_loss": 13.896266222000122, "val_acc": 55.0}
{"epoch": 30, "training_loss": 53.788493156433105, "training_acc": 67.5, "val_loss": 13.702448606491089, "val_acc": 55.0}
{"epoch": 31, "training_loss": 53.92302703857422, "training_acc": 55.0, "val_loss": 13.698031902313232, "val_acc": 55.0}
{"epoch": 32, "training_loss": 52.44577884674072, "training_acc": 66.25, "val_loss": 13.77036452293396, "val_acc": 55.0}
{"epoch": 33, "training_loss": 53.130632400512695, "training_acc": 62.5, "val_loss": 13.788069486618042, "val_acc": 55.0}
{"epoch": 34, "training_loss": 52.547428131103516, "training_acc": 65.0, "val_loss": 13.839932680130005, "val_acc": 55.0}
{"epoch": 35, "training_loss": 52.52783489227295, "training_acc": 68.75, "val_loss": 13.726290464401245, "val_acc": 55.0}
{"epoch": 36, "training_loss": 51.84857177734375, "training_acc": 66.25, "val_loss": 13.713606595993042, "val_acc": 55.0}
{"epoch": 37, "training_loss": 52.98824214935303, "training_acc": 58.75, "val_loss": 13.70073914527893, "val_acc": 55.0}
{"epoch": 38, "training_loss": 52.12779998779297, "training_acc": 57.5, "val_loss": 13.899277448654175, "val_acc": 55.0}
{"epoch": 39, "training_loss": 50.898468017578125, "training_acc": 78.75, "val_loss": 13.881851434707642, "val_acc": 55.0}
{"epoch": 40, "training_loss": 50.721280097961426, "training_acc": 71.25, "val_loss": 13.672417402267456, "val_acc": 55.0}
{"epoch": 41, "training_loss": 51.085947036743164, "training_acc": 65.0, "val_loss": 13.703880310058594, "val_acc": 55.0}
{"epoch": 42, "training_loss": 52.09479522705078, "training_acc": 61.25, "val_loss": 14.244626760482788, "val_acc": 55.0}
{"epoch": 43, "training_loss": 51.594594955444336, "training_acc": 67.5, "val_loss": 13.62573504447937, "val_acc": 55.0}
{"epoch": 44, "training_loss": 51.32226371765137, "training_acc": 58.75, "val_loss": 13.66654634475708, "val_acc": 55.0}
{"epoch": 45, "training_loss": 48.674553871154785, "training_acc": 71.25, "val_loss": 14.42802906036377, "val_acc": 55.0}
{"epoch": 46, "training_loss": 52.20559310913086, "training_acc": 65.0, "val_loss": 14.210714101791382, "val_acc": 55.0}
{"epoch": 47, "training_loss": 50.95780849456787, "training_acc": 66.25, "val_loss": 13.637475967407227, "val_acc": 55.0}
{"epoch": 48, "training_loss": 49.200684547424316, "training_acc": 73.75, "val_loss": 13.684886693954468, "val_acc": 55.0}
{"epoch": 49, "training_loss": 51.94703674316406, "training_acc": 56.25, "val_loss": 14.093087911605835, "val_acc": 55.0}
{"epoch": 50, "training_loss": 47.09206008911133, "training_acc": 77.5, "val_loss": 14.560421705245972, "val_acc": 55.0}
{"epoch": 51, "training_loss": 48.26372814178467, "training_acc": 76.25, "val_loss": 13.84251594543457, "val_acc": 55.0}
