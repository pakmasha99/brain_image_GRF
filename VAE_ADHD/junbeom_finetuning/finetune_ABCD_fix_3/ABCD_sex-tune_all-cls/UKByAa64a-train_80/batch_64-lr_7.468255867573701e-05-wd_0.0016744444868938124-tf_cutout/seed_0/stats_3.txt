"main_optuna_fix_3.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3 --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 56.70560264587402, "training_acc": 42.5, "val_loss": 13.81712794303894, "val_acc": 55.0}
{"epoch": 1, "training_loss": 56.08468055725098, "training_acc": 45.0, "val_loss": 13.776315450668335, "val_acc": 55.0}
{"epoch": 2, "training_loss": 55.55191993713379, "training_acc": 52.5, "val_loss": 13.79252314567566, "val_acc": 55.0}
{"epoch": 3, "training_loss": 55.62337112426758, "training_acc": 52.5, "val_loss": 13.89945387840271, "val_acc": 55.0}
{"epoch": 4, "training_loss": 55.70719528198242, "training_acc": 47.5, "val_loss": 13.771971464157104, "val_acc": 55.0}
{"epoch": 5, "training_loss": 55.588698387145996, "training_acc": 52.5, "val_loss": 13.77647876739502, "val_acc": 55.0}
{"epoch": 6, "training_loss": 55.63436412811279, "training_acc": 52.5, "val_loss": 13.800770044326782, "val_acc": 55.0}
{"epoch": 7, "training_loss": 55.35761547088623, "training_acc": 52.5, "val_loss": 13.814694881439209, "val_acc": 55.0}
{"epoch": 8, "training_loss": 55.71450710296631, "training_acc": 52.5, "val_loss": 13.896903991699219, "val_acc": 55.0}
{"epoch": 9, "training_loss": 55.54819297790527, "training_acc": 47.5, "val_loss": 14.003535509109497, "val_acc": 55.0}
{"epoch": 10, "training_loss": 55.69792175292969, "training_acc": 47.5, "val_loss": 13.760746717453003, "val_acc": 55.0}
{"epoch": 11, "training_loss": 55.23135471343994, "training_acc": 52.5, "val_loss": 13.891810178756714, "val_acc": 55.0}
{"epoch": 12, "training_loss": 56.422651290893555, "training_acc": 52.5, "val_loss": 13.786214590072632, "val_acc": 55.0}
{"epoch": 13, "training_loss": 55.723870277404785, "training_acc": 52.5, "val_loss": 13.803272247314453, "val_acc": 55.0}
{"epoch": 14, "training_loss": 55.29199981689453, "training_acc": 52.5, "val_loss": 13.894344568252563, "val_acc": 55.0}
{"epoch": 15, "training_loss": 55.70519256591797, "training_acc": 47.5, "val_loss": 13.866902589797974, "val_acc": 55.0}
{"epoch": 16, "training_loss": 55.23213195800781, "training_acc": 60.0, "val_loss": 13.768831491470337, "val_acc": 55.0}
{"epoch": 17, "training_loss": 55.7660436630249, "training_acc": 52.5, "val_loss": 13.838557004928589, "val_acc": 55.0}
{"epoch": 18, "training_loss": 55.957313537597656, "training_acc": 52.5, "val_loss": 13.76902461051941, "val_acc": 55.0}
{"epoch": 19, "training_loss": 55.35857963562012, "training_acc": 52.5, "val_loss": 13.874551057815552, "val_acc": 55.0}
{"epoch": 20, "training_loss": 55.63855838775635, "training_acc": 47.5, "val_loss": 14.044351577758789, "val_acc": 55.0}
{"epoch": 21, "training_loss": 55.87014198303223, "training_acc": 47.5, "val_loss": 13.904411792755127, "val_acc": 55.0}
{"epoch": 22, "training_loss": 55.442447662353516, "training_acc": 50.0, "val_loss": 13.787362575531006, "val_acc": 55.0}
{"epoch": 23, "training_loss": 55.28724193572998, "training_acc": 52.5, "val_loss": 13.773337602615356, "val_acc": 55.0}
{"epoch": 24, "training_loss": 55.5570125579834, "training_acc": 52.5, "val_loss": 13.808029890060425, "val_acc": 55.0}
{"epoch": 25, "training_loss": 55.820343017578125, "training_acc": 52.5, "val_loss": 13.872517347335815, "val_acc": 55.0}
{"epoch": 26, "training_loss": 56.2718620300293, "training_acc": 52.5, "val_loss": 13.868330717086792, "val_acc": 55.0}
