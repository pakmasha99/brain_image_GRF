"main_optuna_fix_3.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3 --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 56.208099365234375, "training_acc": 41.25, "val_loss": 13.744983673095703, "val_acc": 55.0}
{"epoch": 1, "training_loss": 56.81676387786865, "training_acc": 45.0, "val_loss": 13.773797750473022, "val_acc": 55.0}
{"epoch": 2, "training_loss": 55.32607460021973, "training_acc": 52.5, "val_loss": 13.797581195831299, "val_acc": 55.0}
{"epoch": 3, "training_loss": 55.736440658569336, "training_acc": 52.5, "val_loss": 13.763498067855835, "val_acc": 55.0}
{"epoch": 4, "training_loss": 55.28067588806152, "training_acc": 52.5, "val_loss": 13.888505697250366, "val_acc": 55.0}
{"epoch": 5, "training_loss": 55.50207710266113, "training_acc": 46.25, "val_loss": 13.832685947418213, "val_acc": 55.0}
{"epoch": 6, "training_loss": 55.7257194519043, "training_acc": 42.5, "val_loss": 13.80100131034851, "val_acc": 55.0}
{"epoch": 7, "training_loss": 55.65998458862305, "training_acc": 52.5, "val_loss": 13.993637561798096, "val_acc": 55.0}
{"epoch": 8, "training_loss": 56.402090072631836, "training_acc": 52.5, "val_loss": 13.76072645187378, "val_acc": 55.0}
{"epoch": 9, "training_loss": 55.15079879760742, "training_acc": 52.5, "val_loss": 13.990122079849243, "val_acc": 55.0}
{"epoch": 10, "training_loss": 55.850746154785156, "training_acc": 47.5, "val_loss": 14.055107831954956, "val_acc": 55.0}
{"epoch": 11, "training_loss": 55.73082733154297, "training_acc": 47.5, "val_loss": 13.796226978302002, "val_acc": 55.0}
{"epoch": 12, "training_loss": 55.43570613861084, "training_acc": 52.5, "val_loss": 13.758701086044312, "val_acc": 55.0}
{"epoch": 13, "training_loss": 55.53060531616211, "training_acc": 52.5, "val_loss": 13.758797645568848, "val_acc": 55.0}
{"epoch": 14, "training_loss": 55.378540992736816, "training_acc": 52.5, "val_loss": 13.8089120388031, "val_acc": 55.0}
{"epoch": 15, "training_loss": 55.64205360412598, "training_acc": 45.0, "val_loss": 13.82700800895691, "val_acc": 55.0}
{"epoch": 16, "training_loss": 55.253440856933594, "training_acc": 52.5, "val_loss": 13.755029439926147, "val_acc": 55.0}
{"epoch": 17, "training_loss": 55.647504806518555, "training_acc": 52.5, "val_loss": 13.789612054824829, "val_acc": 55.0}
{"epoch": 18, "training_loss": 55.70932388305664, "training_acc": 52.5, "val_loss": 13.76556396484375, "val_acc": 55.0}
{"epoch": 19, "training_loss": 55.43557834625244, "training_acc": 52.5, "val_loss": 13.770874738693237, "val_acc": 55.0}
{"epoch": 20, "training_loss": 55.37158393859863, "training_acc": 52.5, "val_loss": 13.845767974853516, "val_acc": 55.0}
{"epoch": 21, "training_loss": 55.42714309692383, "training_acc": 50.0, "val_loss": 13.871074914932251, "val_acc": 55.0}
{"epoch": 22, "training_loss": 55.42646503448486, "training_acc": 47.5, "val_loss": 13.820693492889404, "val_acc": 55.0}
{"epoch": 23, "training_loss": 55.26463031768799, "training_acc": 52.5, "val_loss": 13.760555982589722, "val_acc": 55.0}
{"epoch": 24, "training_loss": 55.2205867767334, "training_acc": 52.5, "val_loss": 13.756599426269531, "val_acc": 55.0}
{"epoch": 25, "training_loss": 55.47787380218506, "training_acc": 52.5, "val_loss": 13.818153142929077, "val_acc": 55.0}
{"epoch": 26, "training_loss": 55.93314075469971, "training_acc": 52.5, "val_loss": 13.840166330337524, "val_acc": 55.0}
{"epoch": 27, "training_loss": 56.040499687194824, "training_acc": 52.5, "val_loss": 13.811142444610596, "val_acc": 55.0}
{"epoch": 28, "training_loss": 55.78623580932617, "training_acc": 52.5, "val_loss": 13.749489784240723, "val_acc": 55.0}
{"epoch": 29, "training_loss": 55.4490270614624, "training_acc": 52.5, "val_loss": 13.812302350997925, "val_acc": 55.0}
{"epoch": 30, "training_loss": 55.35081100463867, "training_acc": 53.75, "val_loss": 13.878233432769775, "val_acc": 55.0}
{"epoch": 31, "training_loss": 55.469523429870605, "training_acc": 47.5, "val_loss": 13.903158903121948, "val_acc": 55.0}
{"epoch": 32, "training_loss": 55.471985816955566, "training_acc": 47.5, "val_loss": 13.939207792282104, "val_acc": 55.0}
{"epoch": 33, "training_loss": 55.61265850067139, "training_acc": 47.5, "val_loss": 13.940109014511108, "val_acc": 55.0}
{"epoch": 34, "training_loss": 55.58437156677246, "training_acc": 47.5, "val_loss": 13.874019384384155, "val_acc": 55.0}
{"epoch": 35, "training_loss": 55.46549606323242, "training_acc": 45.0, "val_loss": 13.808846473693848, "val_acc": 55.0}
{"epoch": 36, "training_loss": 55.27499008178711, "training_acc": 52.5, "val_loss": 13.785728216171265, "val_acc": 55.0}
{"epoch": 37, "training_loss": 55.351579666137695, "training_acc": 52.5, "val_loss": 13.786507844924927, "val_acc": 55.0}
{"epoch": 38, "training_loss": 55.30102252960205, "training_acc": 52.5, "val_loss": 13.790559768676758, "val_acc": 55.0}
{"epoch": 39, "training_loss": 55.25835990905762, "training_acc": 52.5, "val_loss": 13.771220445632935, "val_acc": 55.0}
{"epoch": 40, "training_loss": 55.35158920288086, "training_acc": 52.5, "val_loss": 13.768733739852905, "val_acc": 55.0}
{"epoch": 41, "training_loss": 55.20071792602539, "training_acc": 52.5, "val_loss": 13.819102048873901, "val_acc": 55.0}
