"main_optuna_fix_3.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3 --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 55.46430778503418, "training_acc": 52.5, "val_loss": 13.774360418319702, "val_acc": 55.0}
{"epoch": 1, "training_loss": 55.44321823120117, "training_acc": 52.5, "val_loss": 13.770025968551636, "val_acc": 55.0}
{"epoch": 2, "training_loss": 55.62029838562012, "training_acc": 52.5, "val_loss": 13.764302730560303, "val_acc": 55.0}
{"epoch": 3, "training_loss": 55.387067794799805, "training_acc": 52.5, "val_loss": 13.806008100509644, "val_acc": 55.0}
{"epoch": 4, "training_loss": 55.47694206237793, "training_acc": 52.5, "val_loss": 13.767914772033691, "val_acc": 55.0}
{"epoch": 5, "training_loss": 55.36466407775879, "training_acc": 52.5, "val_loss": 13.765500783920288, "val_acc": 55.0}
{"epoch": 6, "training_loss": 55.507774353027344, "training_acc": 52.5, "val_loss": 13.76296877861023, "val_acc": 55.0}
{"epoch": 7, "training_loss": 55.44378089904785, "training_acc": 52.5, "val_loss": 13.779386281967163, "val_acc": 55.0}
{"epoch": 8, "training_loss": 55.3336067199707, "training_acc": 52.5, "val_loss": 13.8742995262146, "val_acc": 55.0}
{"epoch": 9, "training_loss": 55.48109817504883, "training_acc": 47.5, "val_loss": 13.960037231445312, "val_acc": 55.0}
{"epoch": 10, "training_loss": 55.66532897949219, "training_acc": 47.5, "val_loss": 13.840688467025757, "val_acc": 55.0}
{"epoch": 11, "training_loss": 55.30631923675537, "training_acc": 52.5, "val_loss": 13.763593435287476, "val_acc": 55.0}
{"epoch": 12, "training_loss": 55.54883670806885, "training_acc": 52.5, "val_loss": 13.763890266418457, "val_acc": 55.0}
{"epoch": 13, "training_loss": 55.50054359436035, "training_acc": 52.5, "val_loss": 13.769234418869019, "val_acc": 55.0}
{"epoch": 14, "training_loss": 55.37345504760742, "training_acc": 52.5, "val_loss": 13.79481315612793, "val_acc": 55.0}
{"epoch": 15, "training_loss": 55.54237079620361, "training_acc": 52.5, "val_loss": 13.80791187286377, "val_acc": 55.0}
{"epoch": 16, "training_loss": 55.316518783569336, "training_acc": 52.5, "val_loss": 13.763725757598877, "val_acc": 55.0}
{"epoch": 17, "training_loss": 55.5698184967041, "training_acc": 52.5, "val_loss": 13.773869276046753, "val_acc": 55.0}
{"epoch": 18, "training_loss": 55.629079818725586, "training_acc": 52.5, "val_loss": 13.763489723205566, "val_acc": 55.0}
{"epoch": 19, "training_loss": 55.412522315979004, "training_acc": 52.5, "val_loss": 13.784564733505249, "val_acc": 55.0}
{"epoch": 20, "training_loss": 55.385732650756836, "training_acc": 52.5, "val_loss": 13.833385705947876, "val_acc": 55.0}
{"epoch": 21, "training_loss": 55.40724468231201, "training_acc": 52.5, "val_loss": 13.846025466918945, "val_acc": 55.0}
{"epoch": 22, "training_loss": 55.419312477111816, "training_acc": 52.5, "val_loss": 13.824934959411621, "val_acc": 55.0}
{"epoch": 23, "training_loss": 55.36880970001221, "training_acc": 52.5, "val_loss": 13.786886930465698, "val_acc": 55.0}
