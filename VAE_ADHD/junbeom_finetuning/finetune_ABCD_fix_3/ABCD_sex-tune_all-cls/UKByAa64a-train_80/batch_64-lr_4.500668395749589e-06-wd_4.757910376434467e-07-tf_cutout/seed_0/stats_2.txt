"main_optuna_fix_3.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3 --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 55.32270908355713, "training_acc": 52.5, "val_loss": 13.791345357894897, "val_acc": 55.0}
{"epoch": 1, "training_loss": 55.546213150024414, "training_acc": 52.5, "val_loss": 13.802803754806519, "val_acc": 55.0}
{"epoch": 2, "training_loss": 55.514883041381836, "training_acc": 52.5, "val_loss": 13.774994611740112, "val_acc": 55.0}
{"epoch": 3, "training_loss": 55.246347427368164, "training_acc": 52.5, "val_loss": 13.763664960861206, "val_acc": 55.0}
{"epoch": 4, "training_loss": 55.42012405395508, "training_acc": 52.5, "val_loss": 13.755197525024414, "val_acc": 55.0}
{"epoch": 5, "training_loss": 55.345388412475586, "training_acc": 52.5, "val_loss": 13.745994567871094, "val_acc": 55.0}
{"epoch": 6, "training_loss": 55.32803726196289, "training_acc": 52.5, "val_loss": 13.736082315444946, "val_acc": 55.0}
{"epoch": 7, "training_loss": 55.22207546234131, "training_acc": 52.5, "val_loss": 13.72637152671814, "val_acc": 55.0}
{"epoch": 8, "training_loss": 55.1967716217041, "training_acc": 52.5, "val_loss": 13.719452619552612, "val_acc": 55.0}
{"epoch": 9, "training_loss": 55.16301250457764, "training_acc": 52.5, "val_loss": 13.716375827789307, "val_acc": 55.0}
{"epoch": 10, "training_loss": 55.24483299255371, "training_acc": 52.5, "val_loss": 13.718599081039429, "val_acc": 55.0}
{"epoch": 11, "training_loss": 55.09744930267334, "training_acc": 52.5, "val_loss": 13.719972372055054, "val_acc": 55.0}
{"epoch": 12, "training_loss": 55.01530838012695, "training_acc": 52.5, "val_loss": 13.720219135284424, "val_acc": 55.0}
{"epoch": 13, "training_loss": 54.864519119262695, "training_acc": 52.5, "val_loss": 13.716639280319214, "val_acc": 55.0}
{"epoch": 14, "training_loss": 54.84732627868652, "training_acc": 52.5, "val_loss": 13.707045316696167, "val_acc": 55.0}
{"epoch": 15, "training_loss": 54.77111053466797, "training_acc": 52.5, "val_loss": 13.683948516845703, "val_acc": 55.0}
{"epoch": 16, "training_loss": 54.93270969390869, "training_acc": 52.5, "val_loss": 13.664321899414062, "val_acc": 55.0}
{"epoch": 17, "training_loss": 54.9924898147583, "training_acc": 52.5, "val_loss": 13.659433126449585, "val_acc": 55.0}
{"epoch": 18, "training_loss": 55.02363967895508, "training_acc": 52.5, "val_loss": 13.645786046981812, "val_acc": 55.0}
{"epoch": 19, "training_loss": 54.72451400756836, "training_acc": 52.5, "val_loss": 13.628933429718018, "val_acc": 55.0}
{"epoch": 20, "training_loss": 54.716264724731445, "training_acc": 52.5, "val_loss": 13.632978200912476, "val_acc": 55.0}
{"epoch": 21, "training_loss": 54.753926277160645, "training_acc": 52.5, "val_loss": 13.639271259307861, "val_acc": 55.0}
{"epoch": 22, "training_loss": 54.55325412750244, "training_acc": 52.5, "val_loss": 13.627798557281494, "val_acc": 55.0}
{"epoch": 23, "training_loss": 54.71205806732178, "training_acc": 52.5, "val_loss": 13.60494613647461, "val_acc": 55.0}
{"epoch": 24, "training_loss": 54.53952980041504, "training_acc": 52.5, "val_loss": 13.597694635391235, "val_acc": 55.0}
{"epoch": 25, "training_loss": 54.49490547180176, "training_acc": 52.5, "val_loss": 13.612384796142578, "val_acc": 55.0}
{"epoch": 26, "training_loss": 54.72873783111572, "training_acc": 52.5, "val_loss": 13.608659505844116, "val_acc": 55.0}
{"epoch": 27, "training_loss": 54.458595275878906, "training_acc": 52.5, "val_loss": 13.58786940574646, "val_acc": 55.0}
{"epoch": 28, "training_loss": 54.65535640716553, "training_acc": 52.5, "val_loss": 13.520182371139526, "val_acc": 55.0}
{"epoch": 29, "training_loss": 53.784305572509766, "training_acc": 52.5, "val_loss": 13.527066707611084, "val_acc": 55.0}
{"epoch": 30, "training_loss": 53.753265380859375, "training_acc": 57.5, "val_loss": 13.530112504959106, "val_acc": 55.0}
{"epoch": 31, "training_loss": 54.22198677062988, "training_acc": 55.0, "val_loss": 13.503804206848145, "val_acc": 55.0}
{"epoch": 32, "training_loss": 53.82697105407715, "training_acc": 57.5, "val_loss": 13.473236560821533, "val_acc": 55.0}
{"epoch": 33, "training_loss": 53.732513427734375, "training_acc": 63.75, "val_loss": 13.453329801559448, "val_acc": 55.0}
{"epoch": 34, "training_loss": 53.69723415374756, "training_acc": 61.25, "val_loss": 13.470019102096558, "val_acc": 55.0}
{"epoch": 35, "training_loss": 53.17503070831299, "training_acc": 58.75, "val_loss": 13.415695428848267, "val_acc": 55.0}
{"epoch": 36, "training_loss": 53.36970138549805, "training_acc": 65.0, "val_loss": 13.392292261123657, "val_acc": 55.0}
{"epoch": 37, "training_loss": 53.53843688964844, "training_acc": 67.5, "val_loss": 13.380289077758789, "val_acc": 55.0}
{"epoch": 38, "training_loss": 52.48006820678711, "training_acc": 78.75, "val_loss": 13.395813703536987, "val_acc": 55.0}
{"epoch": 39, "training_loss": 52.62055587768555, "training_acc": 58.75, "val_loss": 13.392640352249146, "val_acc": 55.0}
{"epoch": 40, "training_loss": 52.75506782531738, "training_acc": 60.0, "val_loss": 13.278106451034546, "val_acc": 55.0}
{"epoch": 41, "training_loss": 52.10299873352051, "training_acc": 73.75, "val_loss": 13.450876474380493, "val_acc": 55.0}
{"epoch": 42, "training_loss": 53.4838752746582, "training_acc": 66.25, "val_loss": 13.456658124923706, "val_acc": 55.0}
{"epoch": 43, "training_loss": 52.467994689941406, "training_acc": 67.5, "val_loss": 13.406355381011963, "val_acc": 55.0}
{"epoch": 44, "training_loss": 52.22041893005371, "training_acc": 61.25, "val_loss": 13.22456955909729, "val_acc": 55.0}
{"epoch": 45, "training_loss": 51.70771312713623, "training_acc": 77.5, "val_loss": 13.240083456039429, "val_acc": 55.0}
{"epoch": 46, "training_loss": 52.241981506347656, "training_acc": 75.0, "val_loss": 13.101961612701416, "val_acc": 55.0}
{"epoch": 47, "training_loss": 51.32870864868164, "training_acc": 80.0, "val_loss": 13.140791654586792, "val_acc": 55.0}
{"epoch": 48, "training_loss": 51.0267915725708, "training_acc": 67.5, "val_loss": 13.318575620651245, "val_acc": 55.0}
