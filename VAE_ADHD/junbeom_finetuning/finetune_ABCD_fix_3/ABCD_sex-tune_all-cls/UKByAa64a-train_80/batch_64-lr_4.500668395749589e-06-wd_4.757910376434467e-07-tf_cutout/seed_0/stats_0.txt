"main_optuna_fix_3.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3 --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 56.02131462097168, "training_acc": 46.25, "val_loss": 13.893381357192993, "val_acc": 50.0}
{"epoch": 1, "training_loss": 55.614070892333984, "training_acc": 43.75, "val_loss": 13.902953863143921, "val_acc": 50.0}
{"epoch": 2, "training_loss": 55.45629405975342, "training_acc": 57.5, "val_loss": 13.913204669952393, "val_acc": 50.0}
{"epoch": 3, "training_loss": 55.18713665008545, "training_acc": 53.75, "val_loss": 13.938294649124146, "val_acc": 50.0}
{"epoch": 4, "training_loss": 55.187116622924805, "training_acc": 53.75, "val_loss": 13.95328164100647, "val_acc": 50.0}
{"epoch": 5, "training_loss": 55.22216033935547, "training_acc": 53.75, "val_loss": 13.958377838134766, "val_acc": 50.0}
{"epoch": 6, "training_loss": 55.09036922454834, "training_acc": 53.75, "val_loss": 13.950328826904297, "val_acc": 50.0}
{"epoch": 7, "training_loss": 55.140480041503906, "training_acc": 53.75, "val_loss": 13.941967487335205, "val_acc": 50.0}
{"epoch": 8, "training_loss": 55.03223705291748, "training_acc": 53.75, "val_loss": 13.929203748703003, "val_acc": 50.0}
{"epoch": 9, "training_loss": 55.03374671936035, "training_acc": 53.75, "val_loss": 13.925493955612183, "val_acc": 50.0}
{"epoch": 10, "training_loss": 55.03383255004883, "training_acc": 53.75, "val_loss": 13.932108879089355, "val_acc": 50.0}
{"epoch": 11, "training_loss": 54.8875617980957, "training_acc": 53.75, "val_loss": 13.95376205444336, "val_acc": 50.0}
{"epoch": 12, "training_loss": 54.908305168151855, "training_acc": 53.75, "val_loss": 13.99165391921997, "val_acc": 50.0}
{"epoch": 13, "training_loss": 54.86471366882324, "training_acc": 53.75, "val_loss": 14.036182165145874, "val_acc": 50.0}
{"epoch": 14, "training_loss": 54.80181312561035, "training_acc": 53.75, "val_loss": 14.093166589736938, "val_acc": 50.0}
{"epoch": 15, "training_loss": 54.95048809051514, "training_acc": 53.75, "val_loss": 14.169949293136597, "val_acc": 50.0}
{"epoch": 16, "training_loss": 55.31669998168945, "training_acc": 53.75, "val_loss": 14.229058027267456, "val_acc": 50.0}
{"epoch": 17, "training_loss": 55.16833019256592, "training_acc": 53.75, "val_loss": 14.251363277435303, "val_acc": 50.0}
{"epoch": 18, "training_loss": 55.07312202453613, "training_acc": 53.75, "val_loss": 14.23257827758789, "val_acc": 50.0}
{"epoch": 19, "training_loss": 54.991600036621094, "training_acc": 53.75, "val_loss": 14.179267883300781, "val_acc": 50.0}
{"epoch": 20, "training_loss": 54.82687568664551, "training_acc": 53.75, "val_loss": 14.073925018310547, "val_acc": 50.0}
{"epoch": 21, "training_loss": 54.942044258117676, "training_acc": 53.75, "val_loss": 13.98977279663086, "val_acc": 50.0}
{"epoch": 22, "training_loss": 54.838995933532715, "training_acc": 53.75, "val_loss": 13.984389305114746, "val_acc": 50.0}
{"epoch": 23, "training_loss": 54.802696228027344, "training_acc": 53.75, "val_loss": 13.987400531768799, "val_acc": 50.0}
{"epoch": 24, "training_loss": 54.69207191467285, "training_acc": 53.75, "val_loss": 13.981727361679077, "val_acc": 50.0}
{"epoch": 25, "training_loss": 54.71513271331787, "training_acc": 53.75, "val_loss": 13.988407850265503, "val_acc": 50.0}
{"epoch": 26, "training_loss": 54.86997127532959, "training_acc": 53.75, "val_loss": 13.99857759475708, "val_acc": 50.0}
{"epoch": 27, "training_loss": 54.680559158325195, "training_acc": 53.75, "val_loss": 14.020804166793823, "val_acc": 50.0}
{"epoch": 28, "training_loss": 54.66088008880615, "training_acc": 53.75, "val_loss": 14.047722816467285, "val_acc": 50.0}
{"epoch": 29, "training_loss": 54.388206481933594, "training_acc": 53.75, "val_loss": 14.062894582748413, "val_acc": 50.0}
{"epoch": 30, "training_loss": 54.5114631652832, "training_acc": 53.75, "val_loss": 14.081404209136963, "val_acc": 50.0}
{"epoch": 31, "training_loss": 54.57271480560303, "training_acc": 53.75, "val_loss": 14.09022569656372, "val_acc": 50.0}
{"epoch": 32, "training_loss": 54.11500930786133, "training_acc": 53.75, "val_loss": 14.083245992660522, "val_acc": 50.0}
{"epoch": 33, "training_loss": 54.404906272888184, "training_acc": 53.75, "val_loss": 14.075268507003784, "val_acc": 50.0}
{"epoch": 34, "training_loss": 54.38230323791504, "training_acc": 53.75, "val_loss": 14.085463285446167, "val_acc": 50.0}
{"epoch": 35, "training_loss": 54.06864070892334, "training_acc": 53.75, "val_loss": 14.100167751312256, "val_acc": 50.0}
