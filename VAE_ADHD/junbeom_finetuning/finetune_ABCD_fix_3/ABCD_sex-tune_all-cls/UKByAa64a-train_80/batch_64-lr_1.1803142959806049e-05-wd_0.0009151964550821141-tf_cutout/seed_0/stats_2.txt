"main_optuna_fix_3.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3 --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 55.26253604888916, "training_acc": 52.5, "val_loss": 13.753317594528198, "val_acc": 55.0}
{"epoch": 1, "training_loss": 55.72816467285156, "training_acc": 52.5, "val_loss": 13.767082691192627, "val_acc": 55.0}
{"epoch": 2, "training_loss": 55.418752670288086, "training_acc": 52.5, "val_loss": 13.835395574569702, "val_acc": 55.0}
{"epoch": 3, "training_loss": 55.700387954711914, "training_acc": 52.5, "val_loss": 13.817318677902222, "val_acc": 55.0}
{"epoch": 4, "training_loss": 55.540648460388184, "training_acc": 52.5, "val_loss": 13.76529574394226, "val_acc": 55.0}
{"epoch": 5, "training_loss": 55.265780448913574, "training_acc": 52.5, "val_loss": 13.808690309524536, "val_acc": 55.0}
{"epoch": 6, "training_loss": 55.47664260864258, "training_acc": 43.75, "val_loss": 13.838865756988525, "val_acc": 55.0}
{"epoch": 7, "training_loss": 55.26785087585449, "training_acc": 55.0, "val_loss": 13.789645433425903, "val_acc": 55.0}
{"epoch": 8, "training_loss": 55.31760120391846, "training_acc": 52.5, "val_loss": 13.761606216430664, "val_acc": 55.0}
{"epoch": 9, "training_loss": 55.12287998199463, "training_acc": 52.5, "val_loss": 13.755863904953003, "val_acc": 55.0}
{"epoch": 10, "training_loss": 55.1835994720459, "training_acc": 52.5, "val_loss": 13.751916885375977, "val_acc": 55.0}
{"epoch": 11, "training_loss": 55.06265640258789, "training_acc": 52.5, "val_loss": 13.735142946243286, "val_acc": 55.0}
{"epoch": 12, "training_loss": 55.16205024719238, "training_acc": 52.5, "val_loss": 13.72196912765503, "val_acc": 55.0}
{"epoch": 13, "training_loss": 54.95793914794922, "training_acc": 52.5, "val_loss": 13.71680498123169, "val_acc": 55.0}
{"epoch": 14, "training_loss": 55.03310298919678, "training_acc": 52.5, "val_loss": 13.71585726737976, "val_acc": 55.0}
{"epoch": 15, "training_loss": 54.77191734313965, "training_acc": 52.5, "val_loss": 13.710432052612305, "val_acc": 55.0}
{"epoch": 16, "training_loss": 54.988789558410645, "training_acc": 52.5, "val_loss": 13.706434965133667, "val_acc": 55.0}
{"epoch": 17, "training_loss": 55.25087356567383, "training_acc": 52.5, "val_loss": 13.717851638793945, "val_acc": 55.0}
{"epoch": 18, "training_loss": 54.73298358917236, "training_acc": 52.5, "val_loss": 13.697590827941895, "val_acc": 55.0}
{"epoch": 19, "training_loss": 54.53907585144043, "training_acc": 52.5, "val_loss": 13.6885404586792, "val_acc": 55.0}
{"epoch": 20, "training_loss": 54.7685546875, "training_acc": 53.75, "val_loss": 13.721834421157837, "val_acc": 55.0}
{"epoch": 21, "training_loss": 54.93701457977295, "training_acc": 58.75, "val_loss": 13.724373579025269, "val_acc": 55.0}
{"epoch": 22, "training_loss": 54.71727180480957, "training_acc": 66.25, "val_loss": 13.684593439102173, "val_acc": 55.0}
{"epoch": 23, "training_loss": 54.43436145782471, "training_acc": 58.75, "val_loss": 13.663510084152222, "val_acc": 55.0}
{"epoch": 24, "training_loss": 54.42257213592529, "training_acc": 52.5, "val_loss": 13.717396259307861, "val_acc": 55.0}
{"epoch": 25, "training_loss": 54.907554626464844, "training_acc": 52.5, "val_loss": 13.798480033874512, "val_acc": 55.0}
{"epoch": 26, "training_loss": 55.4510440826416, "training_acc": 52.5, "val_loss": 13.757590055465698, "val_acc": 55.0}
{"epoch": 27, "training_loss": 54.87751770019531, "training_acc": 52.5, "val_loss": 13.677624464035034, "val_acc": 55.0}
{"epoch": 28, "training_loss": 54.39427375793457, "training_acc": 52.5, "val_loss": 13.625646829605103, "val_acc": 55.0}
{"epoch": 29, "training_loss": 54.238898277282715, "training_acc": 60.0, "val_loss": 13.770599365234375, "val_acc": 55.0}
{"epoch": 30, "training_loss": 54.63485622406006, "training_acc": 53.75, "val_loss": 13.789176940917969, "val_acc": 55.0}
{"epoch": 31, "training_loss": 54.921753883361816, "training_acc": 53.75, "val_loss": 13.726671934127808, "val_acc": 55.0}
{"epoch": 32, "training_loss": 54.217872619628906, "training_acc": 73.75, "val_loss": 13.662872314453125, "val_acc": 55.0}
{"epoch": 33, "training_loss": 54.39544677734375, "training_acc": 68.75, "val_loss": 13.614310026168823, "val_acc": 55.0}
{"epoch": 34, "training_loss": 53.97981357574463, "training_acc": 55.0, "val_loss": 13.61370325088501, "val_acc": 55.0}
{"epoch": 35, "training_loss": 53.44879913330078, "training_acc": 52.5, "val_loss": 13.629653453826904, "val_acc": 55.0}
{"epoch": 36, "training_loss": 53.608412742614746, "training_acc": 53.75, "val_loss": 13.601970672607422, "val_acc": 55.0}
{"epoch": 37, "training_loss": 53.45210933685303, "training_acc": 66.25, "val_loss": 13.666117191314697, "val_acc": 55.0}
{"epoch": 38, "training_loss": 53.51048469543457, "training_acc": 65.0, "val_loss": 13.611778020858765, "val_acc": 55.0}
{"epoch": 39, "training_loss": 52.85489082336426, "training_acc": 73.75, "val_loss": 13.691333532333374, "val_acc": 55.0}
{"epoch": 40, "training_loss": 53.90810203552246, "training_acc": 52.5, "val_loss": 13.616125583648682, "val_acc": 55.0}
