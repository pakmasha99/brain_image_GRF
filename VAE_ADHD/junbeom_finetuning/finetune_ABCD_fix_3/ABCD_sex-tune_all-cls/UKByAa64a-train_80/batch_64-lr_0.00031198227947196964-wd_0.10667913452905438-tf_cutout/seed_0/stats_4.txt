"main_optuna_fix_3.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3 --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 58.34885025024414, "training_acc": 45.0, "val_loss": 13.784925937652588, "val_acc": 55.0}
{"epoch": 1, "training_loss": 68.713134765625, "training_acc": 45.0, "val_loss": 13.753602504730225, "val_acc": 55.0}
{"epoch": 2, "training_loss": 55.89032173156738, "training_acc": 52.5, "val_loss": 189.35684204101562, "val_acc": 55.0}
{"epoch": 3, "training_loss": 617.8378210067749, "training_acc": 52.5, "val_loss": 14.694249629974365, "val_acc": 55.0}
{"epoch": 4, "training_loss": 57.58032512664795, "training_acc": 47.5, "val_loss": 13.830016851425171, "val_acc": 55.0}
{"epoch": 5, "training_loss": 55.56642436981201, "training_acc": 52.5, "val_loss": 13.789182901382446, "val_acc": 55.0}
{"epoch": 6, "training_loss": 55.82153511047363, "training_acc": 50.0, "val_loss": 13.774418830871582, "val_acc": 55.0}
{"epoch": 7, "training_loss": 55.8142147064209, "training_acc": 52.5, "val_loss": 13.91789197921753, "val_acc": 55.0}
{"epoch": 8, "training_loss": 55.41156005859375, "training_acc": 47.5, "val_loss": 16.17513656616211, "val_acc": 45.0}
{"epoch": 9, "training_loss": 60.09586238861084, "training_acc": 47.5, "val_loss": 13.935635089874268, "val_acc": 55.0}
{"epoch": 10, "training_loss": 56.90384769439697, "training_acc": 52.5, "val_loss": 14.090265035629272, "val_acc": 55.0}
{"epoch": 11, "training_loss": 57.79839515686035, "training_acc": 52.5, "val_loss": 13.791054487228394, "val_acc": 55.0}
{"epoch": 12, "training_loss": 55.70133686065674, "training_acc": 52.5, "val_loss": 13.783771991729736, "val_acc": 55.0}
{"epoch": 13, "training_loss": 55.44734573364258, "training_acc": 50.0, "val_loss": 13.8881254196167, "val_acc": 55.0}
{"epoch": 14, "training_loss": 55.63558864593506, "training_acc": 42.5, "val_loss": 13.9079749584198, "val_acc": 55.0}
{"epoch": 15, "training_loss": 55.68204975128174, "training_acc": 47.5, "val_loss": 13.887156248092651, "val_acc": 55.0}
{"epoch": 16, "training_loss": 55.31830978393555, "training_acc": 57.5, "val_loss": 13.763657808303833, "val_acc": 55.0}
{"epoch": 17, "training_loss": 55.53324317932129, "training_acc": 52.5, "val_loss": 13.825172185897827, "val_acc": 55.0}
{"epoch": 18, "training_loss": 56.02774620056152, "training_acc": 52.5, "val_loss": 13.78494143486023, "val_acc": 55.0}
{"epoch": 19, "training_loss": 55.55725383758545, "training_acc": 52.5, "val_loss": 13.793936967849731, "val_acc": 55.0}
{"epoch": 20, "training_loss": 55.332823753356934, "training_acc": 53.75, "val_loss": 13.950748443603516, "val_acc": 55.0}
{"epoch": 21, "training_loss": 55.701416015625, "training_acc": 47.5, "val_loss": 13.957725763320923, "val_acc": 55.0}
{"epoch": 22, "training_loss": 55.66408920288086, "training_acc": 47.5, "val_loss": 13.825092315673828, "val_acc": 55.0}
{"epoch": 23, "training_loss": 55.3140811920166, "training_acc": 52.5, "val_loss": 13.760738372802734, "val_acc": 55.0}
{"epoch": 24, "training_loss": 55.52203369140625, "training_acc": 52.5, "val_loss": 13.77856969833374, "val_acc": 55.0}
{"epoch": 25, "training_loss": 55.81396293640137, "training_acc": 52.5, "val_loss": 13.770872354507446, "val_acc": 55.0}
{"epoch": 26, "training_loss": 55.60038185119629, "training_acc": 52.5, "val_loss": 13.770939111709595, "val_acc": 55.0}
{"epoch": 27, "training_loss": 55.535640716552734, "training_acc": 52.5, "val_loss": 13.765201568603516, "val_acc": 55.0}
{"epoch": 28, "training_loss": 55.409170150756836, "training_acc": 52.5, "val_loss": 13.795630931854248, "val_acc": 55.0}
