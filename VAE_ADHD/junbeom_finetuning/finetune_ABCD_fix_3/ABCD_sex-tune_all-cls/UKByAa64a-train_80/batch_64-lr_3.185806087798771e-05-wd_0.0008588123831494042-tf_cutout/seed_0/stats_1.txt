"main_optuna_fix_3.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3 --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 55.44075584411621, "training_acc": 53.75, "val_loss": 13.853839635848999, "val_acc": 50.0}
{"epoch": 1, "training_loss": 55.47254180908203, "training_acc": 48.75, "val_loss": 13.998442888259888, "val_acc": 50.0}
{"epoch": 2, "training_loss": 55.22673511505127, "training_acc": 53.75, "val_loss": 14.34929370880127, "val_acc": 50.0}
{"epoch": 3, "training_loss": 55.75275897979736, "training_acc": 53.75, "val_loss": 13.983982801437378, "val_acc": 50.0}
{"epoch": 4, "training_loss": 54.99585151672363, "training_acc": 53.75, "val_loss": 13.859204053878784, "val_acc": 50.0}
{"epoch": 5, "training_loss": 55.30776596069336, "training_acc": 57.5, "val_loss": 13.842617273330688, "val_acc": 50.0}
{"epoch": 6, "training_loss": 55.26729393005371, "training_acc": 52.5, "val_loss": 13.913804292678833, "val_acc": 50.0}
{"epoch": 7, "training_loss": 55.06086349487305, "training_acc": 53.75, "val_loss": 14.132459163665771, "val_acc": 50.0}
{"epoch": 8, "training_loss": 55.45705986022949, "training_acc": 53.75, "val_loss": 14.0050208568573, "val_acc": 50.0}
{"epoch": 9, "training_loss": 54.779486656188965, "training_acc": 53.75, "val_loss": 13.83080005645752, "val_acc": 50.0}
{"epoch": 10, "training_loss": 55.422898292541504, "training_acc": 47.5, "val_loss": 13.836050033569336, "val_acc": 50.0}
{"epoch": 11, "training_loss": 55.35942459106445, "training_acc": 47.5, "val_loss": 13.827495574951172, "val_acc": 50.0}
{"epoch": 12, "training_loss": 55.08526802062988, "training_acc": 55.0, "val_loss": 13.924940824508667, "val_acc": 50.0}
{"epoch": 13, "training_loss": 54.9183406829834, "training_acc": 53.75, "val_loss": 14.075665473937988, "val_acc": 50.0}
{"epoch": 14, "training_loss": 55.172868728637695, "training_acc": 53.75, "val_loss": 14.255967140197754, "val_acc": 50.0}
{"epoch": 15, "training_loss": 55.45779228210449, "training_acc": 53.75, "val_loss": 14.35054063796997, "val_acc": 50.0}
{"epoch": 16, "training_loss": 56.34361267089844, "training_acc": 53.75, "val_loss": 14.154185056686401, "val_acc": 50.0}
{"epoch": 17, "training_loss": 55.30018997192383, "training_acc": 53.75, "val_loss": 13.943958282470703, "val_acc": 50.0}
{"epoch": 18, "training_loss": 55.056199073791504, "training_acc": 53.75, "val_loss": 13.83921504020691, "val_acc": 50.0}
{"epoch": 19, "training_loss": 55.00796604156494, "training_acc": 53.75, "val_loss": 13.829638957977295, "val_acc": 50.0}
{"epoch": 20, "training_loss": 55.32733726501465, "training_acc": 50.0, "val_loss": 13.837345838546753, "val_acc": 50.0}
{"epoch": 21, "training_loss": 55.44027233123779, "training_acc": 46.25, "val_loss": 13.806403875350952, "val_acc": 50.0}
{"epoch": 22, "training_loss": 54.90441131591797, "training_acc": 62.5, "val_loss": 13.950477838516235, "val_acc": 50.0}
{"epoch": 23, "training_loss": 54.450239181518555, "training_acc": 53.75, "val_loss": 14.313514232635498, "val_acc": 50.0}
{"epoch": 24, "training_loss": 55.54981231689453, "training_acc": 53.75, "val_loss": 14.441274404525757, "val_acc": 50.0}
{"epoch": 25, "training_loss": 55.53434371948242, "training_acc": 53.75, "val_loss": 14.15791392326355, "val_acc": 50.0}
{"epoch": 26, "training_loss": 55.37120342254639, "training_acc": 53.75, "val_loss": 13.931721448898315, "val_acc": 50.0}
{"epoch": 27, "training_loss": 55.10604667663574, "training_acc": 53.75, "val_loss": 13.87346625328064, "val_acc": 50.0}
{"epoch": 28, "training_loss": 55.02455711364746, "training_acc": 53.75, "val_loss": 13.860892057418823, "val_acc": 50.0}
{"epoch": 29, "training_loss": 55.077242851257324, "training_acc": 62.5, "val_loss": 13.856520652770996, "val_acc": 50.0}
{"epoch": 30, "training_loss": 54.975364685058594, "training_acc": 60.0, "val_loss": 13.847237825393677, "val_acc": 50.0}
{"epoch": 31, "training_loss": 54.74529457092285, "training_acc": 53.75, "val_loss": 14.076812267303467, "val_acc": 50.0}
{"epoch": 32, "training_loss": 54.74289321899414, "training_acc": 53.75, "val_loss": 14.120399951934814, "val_acc": 50.0}
{"epoch": 33, "training_loss": 55.12228202819824, "training_acc": 53.75, "val_loss": 13.881601095199585, "val_acc": 50.0}
{"epoch": 34, "training_loss": 54.686861991882324, "training_acc": 53.75, "val_loss": 13.836475610733032, "val_acc": 50.0}
{"epoch": 35, "training_loss": 54.499491691589355, "training_acc": 60.0, "val_loss": 13.817354440689087, "val_acc": 50.0}
