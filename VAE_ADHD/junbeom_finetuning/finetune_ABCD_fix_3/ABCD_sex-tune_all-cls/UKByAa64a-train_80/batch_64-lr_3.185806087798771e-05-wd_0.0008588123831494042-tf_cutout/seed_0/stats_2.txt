"main_optuna_fix_3.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3 --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 55.556589126586914, "training_acc": 52.5, "val_loss": 13.81616473197937, "val_acc": 55.0}
{"epoch": 1, "training_loss": 55.89256477355957, "training_acc": 45.0, "val_loss": 13.811076879501343, "val_acc": 55.0}
{"epoch": 2, "training_loss": 55.39509582519531, "training_acc": 52.5, "val_loss": 13.789037466049194, "val_acc": 55.0}
{"epoch": 3, "training_loss": 55.60026168823242, "training_acc": 52.5, "val_loss": 13.778022527694702, "val_acc": 55.0}
{"epoch": 4, "training_loss": 55.50936508178711, "training_acc": 52.5, "val_loss": 13.751169443130493, "val_acc": 55.0}
{"epoch": 5, "training_loss": 55.220685958862305, "training_acc": 52.5, "val_loss": 13.772413730621338, "val_acc": 55.0}
{"epoch": 6, "training_loss": 55.683420181274414, "training_acc": 43.75, "val_loss": 13.690334558486938, "val_acc": 55.0}
{"epoch": 7, "training_loss": 54.970109939575195, "training_acc": 52.5, "val_loss": 13.799439668655396, "val_acc": 55.0}
{"epoch": 8, "training_loss": 55.89546585083008, "training_acc": 52.5, "val_loss": 13.67161512374878, "val_acc": 55.0}
{"epoch": 9, "training_loss": 54.885658264160156, "training_acc": 52.5, "val_loss": 13.85654091835022, "val_acc": 55.0}
{"epoch": 10, "training_loss": 55.48939800262451, "training_acc": 46.25, "val_loss": 13.940423727035522, "val_acc": 55.0}
{"epoch": 11, "training_loss": 55.52183723449707, "training_acc": 47.5, "val_loss": 13.839113712310791, "val_acc": 55.0}
{"epoch": 12, "training_loss": 55.36607551574707, "training_acc": 51.25, "val_loss": 13.777697086334229, "val_acc": 55.0}
{"epoch": 13, "training_loss": 55.225996017456055, "training_acc": 52.5, "val_loss": 13.76099944114685, "val_acc": 55.0}
{"epoch": 14, "training_loss": 55.22510242462158, "training_acc": 52.5, "val_loss": 13.764605522155762, "val_acc": 55.0}
{"epoch": 15, "training_loss": 55.12721252441406, "training_acc": 52.5, "val_loss": 13.740075826644897, "val_acc": 55.0}
{"epoch": 16, "training_loss": 55.14851951599121, "training_acc": 52.5, "val_loss": 13.745620250701904, "val_acc": 55.0}
{"epoch": 17, "training_loss": 55.88156509399414, "training_acc": 52.5, "val_loss": 13.799188137054443, "val_acc": 55.0}
{"epoch": 18, "training_loss": 55.591126441955566, "training_acc": 52.5, "val_loss": 13.710076808929443, "val_acc": 55.0}
{"epoch": 19, "training_loss": 55.0581636428833, "training_acc": 52.5, "val_loss": 13.737558126449585, "val_acc": 55.0}
{"epoch": 20, "training_loss": 55.31152629852295, "training_acc": 45.0, "val_loss": 13.910404443740845, "val_acc": 55.0}
{"epoch": 21, "training_loss": 55.45395088195801, "training_acc": 47.5, "val_loss": 13.812121152877808, "val_acc": 55.0}
{"epoch": 22, "training_loss": 55.09687423706055, "training_acc": 50.0, "val_loss": 13.70320200920105, "val_acc": 55.0}
{"epoch": 23, "training_loss": 54.6348876953125, "training_acc": 57.5, "val_loss": 13.72102975845337, "val_acc": 55.0}
{"epoch": 24, "training_loss": 54.97578811645508, "training_acc": 52.5, "val_loss": 13.76887559890747, "val_acc": 55.0}
{"epoch": 25, "training_loss": 55.346131324768066, "training_acc": 52.5, "val_loss": 13.80763053894043, "val_acc": 55.0}
{"epoch": 26, "training_loss": 55.68547821044922, "training_acc": 52.5, "val_loss": 13.790696859359741, "val_acc": 55.0}
{"epoch": 27, "training_loss": 55.53708839416504, "training_acc": 52.5, "val_loss": 13.732624053955078, "val_acc": 55.0}
{"epoch": 28, "training_loss": 55.322787284851074, "training_acc": 52.5, "val_loss": 13.705065250396729, "val_acc": 55.0}
{"epoch": 29, "training_loss": 54.91918087005615, "training_acc": 52.5, "val_loss": 13.831052780151367, "val_acc": 55.0}
{"epoch": 30, "training_loss": 54.96300029754639, "training_acc": 60.0, "val_loss": 13.87518048286438, "val_acc": 55.0}
{"epoch": 31, "training_loss": 55.331153869628906, "training_acc": 51.25, "val_loss": 13.846222162246704, "val_acc": 55.0}
{"epoch": 32, "training_loss": 54.91670036315918, "training_acc": 51.25, "val_loss": 13.80595088005066, "val_acc": 55.0}
{"epoch": 33, "training_loss": 55.07583808898926, "training_acc": 55.0, "val_loss": 13.748412132263184, "val_acc": 55.0}
{"epoch": 34, "training_loss": 54.7639856338501, "training_acc": 67.5, "val_loss": 13.68175745010376, "val_acc": 55.0}
{"epoch": 35, "training_loss": 54.102816581726074, "training_acc": 63.75, "val_loss": 13.637644052505493, "val_acc": 55.0}
{"epoch": 36, "training_loss": 53.98830318450928, "training_acc": 60.0, "val_loss": 13.609002828598022, "val_acc": 55.0}
{"epoch": 37, "training_loss": 54.45271873474121, "training_acc": 55.0, "val_loss": 13.620940446853638, "val_acc": 55.0}
{"epoch": 38, "training_loss": 53.870094299316406, "training_acc": 67.5, "val_loss": 13.563476800918579, "val_acc": 55.0}
{"epoch": 39, "training_loss": 53.54465579986572, "training_acc": 57.5, "val_loss": 13.728107213973999, "val_acc": 55.0}
{"epoch": 40, "training_loss": 54.2381067276001, "training_acc": 55.0, "val_loss": 13.469552993774414, "val_acc": 55.0}
{"epoch": 41, "training_loss": 52.6588773727417, "training_acc": 68.75, "val_loss": 14.36536431312561, "val_acc": 55.0}
