"main_optuna_fix_3.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3 --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 55.70235633850098, "training_acc": 42.5, "val_loss": 13.745046854019165, "val_acc": 55.0}
{"epoch": 1, "training_loss": 55.757323265075684, "training_acc": 46.25, "val_loss": 13.908436298370361, "val_acc": 55.0}
{"epoch": 2, "training_loss": 56.881669998168945, "training_acc": 52.5, "val_loss": 14.48285460472107, "val_acc": 55.0}
{"epoch": 3, "training_loss": 57.72078609466553, "training_acc": 52.5, "val_loss": 13.747222423553467, "val_acc": 55.0}
{"epoch": 4, "training_loss": 55.77301025390625, "training_acc": 52.5, "val_loss": 13.814573287963867, "val_acc": 55.0}
{"epoch": 5, "training_loss": 55.300761222839355, "training_acc": 57.5, "val_loss": 13.827414512634277, "val_acc": 55.0}
{"epoch": 6, "training_loss": 55.3393440246582, "training_acc": 57.5, "val_loss": 13.776873350143433, "val_acc": 55.0}
{"epoch": 7, "training_loss": 55.229576110839844, "training_acc": 52.5, "val_loss": 13.742125034332275, "val_acc": 55.0}
{"epoch": 8, "training_loss": 55.371707916259766, "training_acc": 52.5, "val_loss": 13.779748678207397, "val_acc": 55.0}
{"epoch": 9, "training_loss": 55.67350959777832, "training_acc": 45.0, "val_loss": 13.864425420761108, "val_acc": 55.0}
{"epoch": 10, "training_loss": 55.376492500305176, "training_acc": 48.75, "val_loss": 13.770551681518555, "val_acc": 55.0}
{"epoch": 11, "training_loss": 55.15238857269287, "training_acc": 52.5, "val_loss": 13.765085935592651, "val_acc": 55.0}
{"epoch": 12, "training_loss": 55.51776313781738, "training_acc": 52.5, "val_loss": 13.812370300292969, "val_acc": 55.0}
{"epoch": 13, "training_loss": 55.7882137298584, "training_acc": 52.5, "val_loss": 13.776086568832397, "val_acc": 55.0}
{"epoch": 14, "training_loss": 55.29664611816406, "training_acc": 52.5, "val_loss": 13.755978345870972, "val_acc": 55.0}
{"epoch": 15, "training_loss": 55.365373611450195, "training_acc": 52.5, "val_loss": 13.84773850440979, "val_acc": 55.0}
{"epoch": 16, "training_loss": 55.49963188171387, "training_acc": 47.5, "val_loss": 13.838685750961304, "val_acc": 55.0}
{"epoch": 17, "training_loss": 55.23660755157471, "training_acc": 57.5, "val_loss": 13.762779235839844, "val_acc": 55.0}
{"epoch": 18, "training_loss": 55.12349796295166, "training_acc": 52.5, "val_loss": 13.742998838424683, "val_acc": 55.0}
{"epoch": 19, "training_loss": 55.070669174194336, "training_acc": 52.5, "val_loss": 13.752988576889038, "val_acc": 55.0}
{"epoch": 20, "training_loss": 55.00697040557861, "training_acc": 52.5, "val_loss": 13.785227537155151, "val_acc": 55.0}
{"epoch": 21, "training_loss": 55.22206115722656, "training_acc": 53.75, "val_loss": 13.810795545578003, "val_acc": 55.0}
{"epoch": 22, "training_loss": 55.01606845855713, "training_acc": 57.5, "val_loss": 13.793829679489136, "val_acc": 55.0}
{"epoch": 23, "training_loss": 55.10410118103027, "training_acc": 50.0, "val_loss": 13.747856616973877, "val_acc": 55.0}
{"epoch": 24, "training_loss": 54.87343978881836, "training_acc": 52.5, "val_loss": 13.727450370788574, "val_acc": 55.0}
