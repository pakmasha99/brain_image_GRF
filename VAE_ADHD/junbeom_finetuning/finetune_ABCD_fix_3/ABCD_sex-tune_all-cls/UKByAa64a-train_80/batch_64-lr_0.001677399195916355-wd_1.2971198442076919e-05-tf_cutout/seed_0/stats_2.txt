"main_optuna_fix_3.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3 --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 60.912967681884766, "training_acc": 52.5, "val_loss": 5685.396728515625, "val_acc": 45.0}
{"epoch": 1, "training_loss": 16772.322509765625, "training_acc": 55.0, "val_loss": 25.35360336303711, "val_acc": 55.0}
{"epoch": 2, "training_loss": 118.24225234985352, "training_acc": 50.0, "val_loss": 27.095401287078857, "val_acc": 55.0}
{"epoch": 3, "training_loss": 102.56954765319824, "training_acc": 50.0, "val_loss": 14.93143081665039, "val_acc": 55.0}
{"epoch": 4, "training_loss": 60.08716011047363, "training_acc": 47.5, "val_loss": 16.809990406036377, "val_acc": 45.0}
{"epoch": 5, "training_loss": 63.7318172454834, "training_acc": 47.5, "val_loss": 14.150192737579346, "val_acc": 55.0}
{"epoch": 6, "training_loss": 58.32223415374756, "training_acc": 52.5, "val_loss": 14.100315570831299, "val_acc": 55.0}
{"epoch": 7, "training_loss": 57.04361152648926, "training_acc": 52.5, "val_loss": 13.845527172088623, "val_acc": 55.0}
{"epoch": 8, "training_loss": 55.24542045593262, "training_acc": 52.5, "val_loss": 14.593812227249146, "val_acc": 55.0}
{"epoch": 9, "training_loss": 57.634334564208984, "training_acc": 47.5, "val_loss": 14.451318979263306, "val_acc": 55.0}
{"epoch": 10, "training_loss": 56.84784984588623, "training_acc": 47.5, "val_loss": 13.793104887008667, "val_acc": 55.0}
{"epoch": 11, "training_loss": 55.14313316345215, "training_acc": 52.5, "val_loss": 14.260997772216797, "val_acc": 55.0}
{"epoch": 12, "training_loss": 57.70273685455322, "training_acc": 52.5, "val_loss": 13.782213926315308, "val_acc": 55.0}
{"epoch": 13, "training_loss": 55.343926429748535, "training_acc": 52.5, "val_loss": 13.988960981369019, "val_acc": 55.0}
{"epoch": 14, "training_loss": 55.766329765319824, "training_acc": 47.5, "val_loss": 13.971244096755981, "val_acc": 55.0}
{"epoch": 15, "training_loss": 55.60023593902588, "training_acc": 47.5, "val_loss": 13.774633407592773, "val_acc": 55.0}
{"epoch": 16, "training_loss": 55.13225173950195, "training_acc": 52.5, "val_loss": 14.129072427749634, "val_acc": 55.0}
{"epoch": 17, "training_loss": 57.71636962890625, "training_acc": 52.5, "val_loss": 13.81333589553833, "val_acc": 55.0}
{"epoch": 18, "training_loss": 55.598151206970215, "training_acc": 52.5, "val_loss": 13.920429944992065, "val_acc": 55.0}
{"epoch": 19, "training_loss": 55.52788734436035, "training_acc": 47.5, "val_loss": 14.059193134307861, "val_acc": 55.0}
{"epoch": 20, "training_loss": 55.96279525756836, "training_acc": 47.5, "val_loss": 13.999273777008057, "val_acc": 55.0}
{"epoch": 21, "training_loss": 55.72942066192627, "training_acc": 47.5, "val_loss": 13.821624517440796, "val_acc": 55.0}
{"epoch": 22, "training_loss": 55.32590866088867, "training_acc": 52.5, "val_loss": 13.771768808364868, "val_acc": 55.0}
{"epoch": 23, "training_loss": 55.573909759521484, "training_acc": 52.5, "val_loss": 13.773393630981445, "val_acc": 55.0}
{"epoch": 24, "training_loss": 55.78207778930664, "training_acc": 52.5, "val_loss": 13.770027160644531, "val_acc": 55.0}
{"epoch": 25, "training_loss": 55.444576263427734, "training_acc": 52.5, "val_loss": 13.779544830322266, "val_acc": 55.0}
{"epoch": 26, "training_loss": 55.66254806518555, "training_acc": 52.5, "val_loss": 13.785876035690308, "val_acc": 55.0}
{"epoch": 27, "training_loss": 55.66453742980957, "training_acc": 52.5, "val_loss": 13.793514966964722, "val_acc": 55.0}
{"epoch": 28, "training_loss": 55.73397636413574, "training_acc": 52.5, "val_loss": 13.767999410629272, "val_acc": 55.0}
{"epoch": 29, "training_loss": 55.460984230041504, "training_acc": 52.5, "val_loss": 13.866132497787476, "val_acc": 55.0}
{"epoch": 30, "training_loss": 55.51730155944824, "training_acc": 45.0, "val_loss": 13.862929344177246, "val_acc": 55.0}
{"epoch": 31, "training_loss": 55.51264190673828, "training_acc": 51.25, "val_loss": 13.851956129074097, "val_acc": 55.0}
{"epoch": 32, "training_loss": 55.40915489196777, "training_acc": 55.0, "val_loss": 13.897901773452759, "val_acc": 55.0}
{"epoch": 33, "training_loss": 55.51895618438721, "training_acc": 47.5, "val_loss": 13.921594619750977, "val_acc": 55.0}
{"epoch": 34, "training_loss": 55.54959487915039, "training_acc": 47.5, "val_loss": 13.875219821929932, "val_acc": 55.0}
{"epoch": 35, "training_loss": 55.50705528259277, "training_acc": 47.5, "val_loss": 13.82398009300232, "val_acc": 55.0}
{"epoch": 36, "training_loss": 55.3809928894043, "training_acc": 52.5, "val_loss": 13.812628984451294, "val_acc": 55.0}
{"epoch": 37, "training_loss": 55.38692665100098, "training_acc": 52.5, "val_loss": 13.8152015209198, "val_acc": 55.0}
{"epoch": 38, "training_loss": 55.40446472167969, "training_acc": 52.5, "val_loss": 13.811604976654053, "val_acc": 55.0}
