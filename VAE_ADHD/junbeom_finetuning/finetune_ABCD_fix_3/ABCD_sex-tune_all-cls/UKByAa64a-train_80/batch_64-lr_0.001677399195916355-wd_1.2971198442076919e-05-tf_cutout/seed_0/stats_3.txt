"main_optuna_fix_3.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3 --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 62.786048889160156, "training_acc": 52.5, "val_loss": 811.6346740722656, "val_acc": 45.0}
{"epoch": 1, "training_loss": 557999.8676757812, "training_acc": 55.0, "val_loss": 23.824760913848877, "val_acc": 55.0}
{"epoch": 2, "training_loss": 116.79541015625, "training_acc": 50.0, "val_loss": 22.204437255859375, "val_acc": 45.0}
{"epoch": 3, "training_loss": 131.06189346313477, "training_acc": 47.5, "val_loss": 67.79292583465576, "val_acc": 45.0}
{"epoch": 4, "training_loss": 230.57678985595703, "training_acc": 52.5, "val_loss": 155.9965419769287, "val_acc": 45.0}
{"epoch": 5, "training_loss": 510.9501190185547, "training_acc": 50.0, "val_loss": 26.322815418243408, "val_acc": 45.0}
{"epoch": 6, "training_loss": 122.43119049072266, "training_acc": 50.0, "val_loss": 18.41289520263672, "val_acc": 45.0}
{"epoch": 7, "training_loss": 71.75377082824707, "training_acc": 47.5, "val_loss": 33.78709554672241, "val_acc": 45.0}
{"epoch": 8, "training_loss": 135.11087036132812, "training_acc": 42.5, "val_loss": 16.073944568634033, "val_acc": 45.0}
{"epoch": 9, "training_loss": 62.99495315551758, "training_acc": 47.5, "val_loss": 14.322808980941772, "val_acc": 55.0}
{"epoch": 10, "training_loss": 58.64999961853027, "training_acc": 52.5, "val_loss": 13.814213275909424, "val_acc": 55.0}
{"epoch": 11, "training_loss": 58.407400131225586, "training_acc": 47.5, "val_loss": 14.009352922439575, "val_acc": 55.0}
{"epoch": 12, "training_loss": 58.46892738342285, "training_acc": 52.5, "val_loss": 13.878039121627808, "val_acc": 55.0}
{"epoch": 13, "training_loss": 57.32394218444824, "training_acc": 47.5, "val_loss": 14.245089292526245, "val_acc": 55.0}
{"epoch": 14, "training_loss": 57.5001745223999, "training_acc": 45.0, "val_loss": 13.945063352584839, "val_acc": 55.0}
{"epoch": 15, "training_loss": 57.5092887878418, "training_acc": 52.5, "val_loss": 13.757873773574829, "val_acc": 55.0}
{"epoch": 16, "training_loss": 55.75817680358887, "training_acc": 52.5, "val_loss": 13.95039439201355, "val_acc": 55.0}
{"epoch": 17, "training_loss": 57.10098457336426, "training_acc": 52.5, "val_loss": 13.765462636947632, "val_acc": 55.0}
{"epoch": 18, "training_loss": 55.09982872009277, "training_acc": 55.0, "val_loss": 15.365328788757324, "val_acc": 45.0}
{"epoch": 19, "training_loss": 59.94197463989258, "training_acc": 47.5, "val_loss": 13.947757482528687, "val_acc": 55.0}
{"epoch": 20, "training_loss": 55.46769714355469, "training_acc": 50.0, "val_loss": 13.862794637680054, "val_acc": 55.0}
{"epoch": 21, "training_loss": 56.32104969024658, "training_acc": 52.5, "val_loss": 13.789262771606445, "val_acc": 55.0}
{"epoch": 22, "training_loss": 55.82788848876953, "training_acc": 52.5, "val_loss": 13.864550590515137, "val_acc": 55.0}
{"epoch": 23, "training_loss": 55.50933837890625, "training_acc": 46.25, "val_loss": 13.8304603099823, "val_acc": 55.0}
{"epoch": 24, "training_loss": 55.29648780822754, "training_acc": 52.5, "val_loss": 13.860169649124146, "val_acc": 55.0}
{"epoch": 25, "training_loss": 56.16331100463867, "training_acc": 52.5, "val_loss": 14.169111251831055, "val_acc": 55.0}
{"epoch": 26, "training_loss": 57.83470058441162, "training_acc": 52.5, "val_loss": 13.832181692123413, "val_acc": 55.0}
{"epoch": 27, "training_loss": 56.03898620605469, "training_acc": 52.5, "val_loss": 13.812868595123291, "val_acc": 55.0}
{"epoch": 28, "training_loss": 55.40363121032715, "training_acc": 52.5, "val_loss": 14.168494939804077, "val_acc": 55.0}
{"epoch": 29, "training_loss": 56.4110631942749, "training_acc": 47.5, "val_loss": 13.956911563873291, "val_acc": 55.0}
{"epoch": 30, "training_loss": 55.75555896759033, "training_acc": 47.5, "val_loss": 13.787679672241211, "val_acc": 55.0}
{"epoch": 31, "training_loss": 56.062307357788086, "training_acc": 52.5, "val_loss": 13.777220249176025, "val_acc": 55.0}
{"epoch": 32, "training_loss": 55.37669563293457, "training_acc": 52.5, "val_loss": 14.122508764266968, "val_acc": 55.0}
{"epoch": 33, "training_loss": 56.07958793640137, "training_acc": 47.5, "val_loss": 13.943582773208618, "val_acc": 55.0}
{"epoch": 34, "training_loss": 55.5504674911499, "training_acc": 50.0, "val_loss": 13.775355815887451, "val_acc": 55.0}
{"epoch": 35, "training_loss": 55.52491474151611, "training_acc": 52.5, "val_loss": 13.760807514190674, "val_acc": 55.0}
{"epoch": 36, "training_loss": 55.54543876647949, "training_acc": 52.5, "val_loss": 13.772666454315186, "val_acc": 55.0}
{"epoch": 37, "training_loss": 55.38183403015137, "training_acc": 52.5, "val_loss": 13.767614364624023, "val_acc": 55.0}
{"epoch": 38, "training_loss": 55.38729286193848, "training_acc": 52.5, "val_loss": 13.773669004440308, "val_acc": 55.0}
{"epoch": 39, "training_loss": 55.385518074035645, "training_acc": 52.5, "val_loss": 13.76455545425415, "val_acc": 55.0}
{"epoch": 40, "training_loss": 55.43683910369873, "training_acc": 52.5, "val_loss": 13.769630193710327, "val_acc": 55.0}
{"epoch": 41, "training_loss": 55.35348033905029, "training_acc": 52.5, "val_loss": 13.915894031524658, "val_acc": 55.0}
