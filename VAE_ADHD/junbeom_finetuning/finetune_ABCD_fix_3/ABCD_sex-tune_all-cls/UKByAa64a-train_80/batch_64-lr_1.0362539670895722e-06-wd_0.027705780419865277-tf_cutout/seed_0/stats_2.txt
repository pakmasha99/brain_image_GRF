"main_optuna_fix_3.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3 --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 55.56190490722656, "training_acc": 55.0, "val_loss": 13.890079259872437, "val_acc": 55.0}
{"epoch": 1, "training_loss": 55.76415824890137, "training_acc": 47.5, "val_loss": 13.883353471755981, "val_acc": 55.0}
{"epoch": 2, "training_loss": 55.65510845184326, "training_acc": 47.5, "val_loss": 13.862202167510986, "val_acc": 55.0}
{"epoch": 3, "training_loss": 55.43728828430176, "training_acc": 47.5, "val_loss": 13.842124938964844, "val_acc": 55.0}
{"epoch": 4, "training_loss": 55.45957565307617, "training_acc": 47.5, "val_loss": 13.82089376449585, "val_acc": 55.0}
{"epoch": 5, "training_loss": 55.46830940246582, "training_acc": 50.0, "val_loss": 13.803600072860718, "val_acc": 55.0}
{"epoch": 6, "training_loss": 55.494022369384766, "training_acc": 48.75, "val_loss": 13.788753747940063, "val_acc": 55.0}
{"epoch": 7, "training_loss": 55.303741455078125, "training_acc": 52.5, "val_loss": 13.77163290977478, "val_acc": 55.0}
{"epoch": 8, "training_loss": 55.36367416381836, "training_acc": 52.5, "val_loss": 13.757011890411377, "val_acc": 55.0}
{"epoch": 9, "training_loss": 55.24266242980957, "training_acc": 52.5, "val_loss": 13.746277093887329, "val_acc": 55.0}
{"epoch": 10, "training_loss": 55.55387878417969, "training_acc": 53.75, "val_loss": 13.738173246383667, "val_acc": 55.0}
{"epoch": 11, "training_loss": 55.25234031677246, "training_acc": 52.5, "val_loss": 13.729413747787476, "val_acc": 55.0}
{"epoch": 12, "training_loss": 55.39612007141113, "training_acc": 52.5, "val_loss": 13.721970319747925, "val_acc": 55.0}
{"epoch": 13, "training_loss": 55.29782295227051, "training_acc": 52.5, "val_loss": 13.71694564819336, "val_acc": 55.0}
{"epoch": 14, "training_loss": 55.23337745666504, "training_acc": 52.5, "val_loss": 13.71389389038086, "val_acc": 55.0}
{"epoch": 15, "training_loss": 55.02678871154785, "training_acc": 52.5, "val_loss": 13.707857131958008, "val_acc": 55.0}
{"epoch": 16, "training_loss": 55.46168518066406, "training_acc": 53.75, "val_loss": 13.697160482406616, "val_acc": 55.0}
{"epoch": 17, "training_loss": 55.32109069824219, "training_acc": 52.5, "val_loss": 13.68729829788208, "val_acc": 55.0}
{"epoch": 18, "training_loss": 55.225749015808105, "training_acc": 52.5, "val_loss": 13.680260181427002, "val_acc": 55.0}
{"epoch": 19, "training_loss": 55.23672866821289, "training_acc": 52.5, "val_loss": 13.676300048828125, "val_acc": 55.0}
{"epoch": 20, "training_loss": 55.32198524475098, "training_acc": 51.25, "val_loss": 13.673878908157349, "val_acc": 55.0}
{"epoch": 21, "training_loss": 55.348639488220215, "training_acc": 52.5, "val_loss": 13.6700439453125, "val_acc": 55.0}
{"epoch": 22, "training_loss": 55.19146537780762, "training_acc": 52.5, "val_loss": 13.666428327560425, "val_acc": 55.0}
{"epoch": 23, "training_loss": 55.09651279449463, "training_acc": 52.5, "val_loss": 13.662153482437134, "val_acc": 55.0}
{"epoch": 24, "training_loss": 55.28523063659668, "training_acc": 52.5, "val_loss": 13.657864332199097, "val_acc": 55.0}
{"epoch": 25, "training_loss": 55.077948570251465, "training_acc": 52.5, "val_loss": 13.652150630950928, "val_acc": 55.0}
{"epoch": 26, "training_loss": 55.231157302856445, "training_acc": 52.5, "val_loss": 13.648428916931152, "val_acc": 55.0}
{"epoch": 27, "training_loss": 55.45795154571533, "training_acc": 52.5, "val_loss": 13.650158643722534, "val_acc": 55.0}
{"epoch": 28, "training_loss": 55.54685401916504, "training_acc": 52.5, "val_loss": 13.650175333023071, "val_acc": 55.0}
{"epoch": 29, "training_loss": 55.2342414855957, "training_acc": 52.5, "val_loss": 13.646191358566284, "val_acc": 55.0}
{"epoch": 30, "training_loss": 54.6704044342041, "training_acc": 52.5, "val_loss": 13.641852140426636, "val_acc": 55.0}
{"epoch": 31, "training_loss": 55.23138236999512, "training_acc": 52.5, "val_loss": 13.64014983177185, "val_acc": 55.0}
{"epoch": 32, "training_loss": 54.631985664367676, "training_acc": 52.5, "val_loss": 13.64557147026062, "val_acc": 55.0}
{"epoch": 33, "training_loss": 55.324307441711426, "training_acc": 52.5, "val_loss": 13.653719425201416, "val_acc": 55.0}
{"epoch": 34, "training_loss": 55.02421951293945, "training_acc": 53.75, "val_loss": 13.662006855010986, "val_acc": 55.0}
{"epoch": 35, "training_loss": 54.86198902130127, "training_acc": 52.5, "val_loss": 13.667194843292236, "val_acc": 55.0}
{"epoch": 36, "training_loss": 54.9585018157959, "training_acc": 52.5, "val_loss": 13.668619394302368, "val_acc": 55.0}
{"epoch": 37, "training_loss": 55.24641990661621, "training_acc": 55.0, "val_loss": 13.669480085372925, "val_acc": 55.0}
{"epoch": 38, "training_loss": 55.00546836853027, "training_acc": 53.75, "val_loss": 13.666590452194214, "val_acc": 55.0}
{"epoch": 39, "training_loss": 54.87544059753418, "training_acc": 55.0, "val_loss": 13.654063940048218, "val_acc": 55.0}
{"epoch": 40, "training_loss": 54.695706367492676, "training_acc": 56.25, "val_loss": 13.639715909957886, "val_acc": 55.0}
{"epoch": 41, "training_loss": 54.85737895965576, "training_acc": 55.0, "val_loss": 13.634563684463501, "val_acc": 55.0}
{"epoch": 42, "training_loss": 55.182016372680664, "training_acc": 43.75, "val_loss": 13.638067245483398, "val_acc": 55.0}
{"epoch": 43, "training_loss": 54.720590591430664, "training_acc": 51.25, "val_loss": 13.635218143463135, "val_acc": 55.0}
{"epoch": 44, "training_loss": 55.06772994995117, "training_acc": 51.25, "val_loss": 13.632584810256958, "val_acc": 55.0}
{"epoch": 45, "training_loss": 55.1948881149292, "training_acc": 52.5, "val_loss": 13.6306893825531, "val_acc": 55.0}
{"epoch": 46, "training_loss": 55.06666660308838, "training_acc": 45.0, "val_loss": 13.633140325546265, "val_acc": 55.0}
{"epoch": 47, "training_loss": 55.1173152923584, "training_acc": 51.25, "val_loss": 13.64079475402832, "val_acc": 55.0}
{"epoch": 48, "training_loss": 54.72808647155762, "training_acc": 60.0, "val_loss": 13.627023696899414, "val_acc": 55.0}
{"epoch": 49, "training_loss": 55.18157386779785, "training_acc": 46.25, "val_loss": 13.603523969650269, "val_acc": 55.0}
{"epoch": 50, "training_loss": 54.75204658508301, "training_acc": 53.75, "val_loss": 13.587566614151001, "val_acc": 55.0}
{"epoch": 51, "training_loss": 54.5374116897583, "training_acc": 53.75, "val_loss": 13.579615354537964, "val_acc": 55.0}
