"main_optuna_fix_3.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3 --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 56.39212703704834, "training_acc": 40.0, "val_loss": 13.740895986557007, "val_acc": 55.0}
{"epoch": 1, "training_loss": 56.387861251831055, "training_acc": 45.0, "val_loss": 15.413283109664917, "val_acc": 55.0}
{"epoch": 2, "training_loss": 61.10533332824707, "training_acc": 52.5, "val_loss": 13.78402590751648, "val_acc": 55.0}
{"epoch": 3, "training_loss": 55.37901210784912, "training_acc": 52.5, "val_loss": 13.781050443649292, "val_acc": 55.0}
{"epoch": 4, "training_loss": 55.46787452697754, "training_acc": 51.25, "val_loss": 13.759266138076782, "val_acc": 55.0}
{"epoch": 5, "training_loss": 55.32647705078125, "training_acc": 52.5, "val_loss": 13.758056163787842, "val_acc": 55.0}
{"epoch": 6, "training_loss": 55.539374351501465, "training_acc": 52.5, "val_loss": 13.753325939178467, "val_acc": 55.0}
{"epoch": 7, "training_loss": 55.4733190536499, "training_acc": 52.5, "val_loss": 13.764065504074097, "val_acc": 55.0}
{"epoch": 8, "training_loss": 55.186264991760254, "training_acc": 52.5, "val_loss": 13.958057165145874, "val_acc": 55.0}
{"epoch": 9, "training_loss": 55.68160820007324, "training_acc": 47.5, "val_loss": 14.155411720275879, "val_acc": 55.0}
{"epoch": 10, "training_loss": 56.14376735687256, "training_acc": 47.5, "val_loss": 13.889219760894775, "val_acc": 55.0}
{"epoch": 11, "training_loss": 55.1953010559082, "training_acc": 52.5, "val_loss": 13.763644695281982, "val_acc": 55.0}
{"epoch": 12, "training_loss": 55.71307373046875, "training_acc": 52.5, "val_loss": 13.809046745300293, "val_acc": 55.0}
{"epoch": 13, "training_loss": 55.81553649902344, "training_acc": 52.5, "val_loss": 13.756464719772339, "val_acc": 55.0}
{"epoch": 14, "training_loss": 55.39517402648926, "training_acc": 52.5, "val_loss": 13.8074791431427, "val_acc": 55.0}
{"epoch": 15, "training_loss": 55.7137508392334, "training_acc": 45.0, "val_loss": 13.846091032028198, "val_acc": 55.0}
{"epoch": 16, "training_loss": 55.291595458984375, "training_acc": 50.0, "val_loss": 13.751909732818604, "val_acc": 55.0}
{"epoch": 17, "training_loss": 55.56473922729492, "training_acc": 52.5, "val_loss": 13.78807544708252, "val_acc": 55.0}
{"epoch": 18, "training_loss": 55.63046836853027, "training_acc": 52.5, "val_loss": 13.75289797782898, "val_acc": 55.0}
{"epoch": 19, "training_loss": 55.3258113861084, "training_acc": 52.5, "val_loss": 13.784557580947876, "val_acc": 55.0}
{"epoch": 20, "training_loss": 55.37955570220947, "training_acc": 53.75, "val_loss": 13.86947512626648, "val_acc": 55.0}
{"epoch": 21, "training_loss": 55.43090629577637, "training_acc": 47.5, "val_loss": 13.879150152206421, "val_acc": 55.0}
{"epoch": 22, "training_loss": 55.413002014160156, "training_acc": 47.5, "val_loss": 13.834601640701294, "val_acc": 55.0}
{"epoch": 23, "training_loss": 55.294471740722656, "training_acc": 56.25, "val_loss": 13.774200677871704, "val_acc": 55.0}
{"epoch": 24, "training_loss": 55.2167329788208, "training_acc": 52.5, "val_loss": 13.758149147033691, "val_acc": 55.0}
{"epoch": 25, "training_loss": 55.27224159240723, "training_acc": 52.5, "val_loss": 13.80723237991333, "val_acc": 55.0}
{"epoch": 26, "training_loss": 55.85010528564453, "training_acc": 52.5, "val_loss": 13.882160186767578, "val_acc": 55.0}
{"epoch": 27, "training_loss": 56.24283027648926, "training_acc": 52.5, "val_loss": 13.867219686508179, "val_acc": 55.0}
