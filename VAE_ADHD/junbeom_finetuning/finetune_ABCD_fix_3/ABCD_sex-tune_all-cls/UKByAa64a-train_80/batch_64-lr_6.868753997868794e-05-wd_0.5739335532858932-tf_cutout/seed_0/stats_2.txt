"main_optuna_fix_3.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3 --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 55.8070011138916, "training_acc": 52.5, "val_loss": 13.77137541770935, "val_acc": 55.0}
{"epoch": 1, "training_loss": 56.04509925842285, "training_acc": 45.0, "val_loss": 17.499359846115112, "val_acc": 55.0}
{"epoch": 2, "training_loss": 68.58734130859375, "training_acc": 52.5, "val_loss": 13.811860084533691, "val_acc": 55.0}
{"epoch": 3, "training_loss": 55.37810039520264, "training_acc": 53.75, "val_loss": 13.746379613876343, "val_acc": 55.0}
{"epoch": 4, "training_loss": 55.43721103668213, "training_acc": 52.5, "val_loss": 13.735359907150269, "val_acc": 55.0}
{"epoch": 5, "training_loss": 55.31538963317871, "training_acc": 52.5, "val_loss": 13.823684453964233, "val_acc": 55.0}
{"epoch": 6, "training_loss": 56.07354164123535, "training_acc": 52.5, "val_loss": 13.75899076461792, "val_acc": 55.0}
{"epoch": 7, "training_loss": 55.14235591888428, "training_acc": 55.0, "val_loss": 13.825989961624146, "val_acc": 55.0}
{"epoch": 8, "training_loss": 56.33394145965576, "training_acc": 52.5, "val_loss": 13.75421404838562, "val_acc": 55.0}
{"epoch": 9, "training_loss": 55.32338047027588, "training_acc": 52.5, "val_loss": 14.082286357879639, "val_acc": 55.0}
{"epoch": 10, "training_loss": 56.25663375854492, "training_acc": 47.5, "val_loss": 14.119962453842163, "val_acc": 55.0}
{"epoch": 11, "training_loss": 55.87356185913086, "training_acc": 47.5, "val_loss": 13.787912130355835, "val_acc": 55.0}
{"epoch": 12, "training_loss": 55.37432098388672, "training_acc": 52.5, "val_loss": 13.74987244606018, "val_acc": 55.0}
{"epoch": 13, "training_loss": 55.31970691680908, "training_acc": 52.5, "val_loss": 13.756297826766968, "val_acc": 55.0}
{"epoch": 14, "training_loss": 55.33252429962158, "training_acc": 52.5, "val_loss": 13.783106803894043, "val_acc": 55.0}
{"epoch": 15, "training_loss": 55.44206619262695, "training_acc": 50.0, "val_loss": 13.767913579940796, "val_acc": 55.0}
{"epoch": 16, "training_loss": 55.245513916015625, "training_acc": 52.5, "val_loss": 13.73956561088562, "val_acc": 55.0}
{"epoch": 17, "training_loss": 55.70877742767334, "training_acc": 52.5, "val_loss": 13.778829574584961, "val_acc": 55.0}
{"epoch": 18, "training_loss": 55.70388603210449, "training_acc": 52.5, "val_loss": 13.752073049545288, "val_acc": 55.0}
{"epoch": 19, "training_loss": 55.450687408447266, "training_acc": 52.5, "val_loss": 13.760610818862915, "val_acc": 55.0}
{"epoch": 20, "training_loss": 55.38016319274902, "training_acc": 52.5, "val_loss": 13.841063976287842, "val_acc": 55.0}
{"epoch": 21, "training_loss": 55.40294170379639, "training_acc": 50.0, "val_loss": 13.8673996925354, "val_acc": 55.0}
{"epoch": 22, "training_loss": 55.41144943237305, "training_acc": 48.75, "val_loss": 13.819198608398438, "val_acc": 55.0}
{"epoch": 23, "training_loss": 55.214107513427734, "training_acc": 60.0, "val_loss": 13.762136697769165, "val_acc": 55.0}
{"epoch": 24, "training_loss": 55.172739028930664, "training_acc": 52.5, "val_loss": 13.74178171157837, "val_acc": 55.0}
{"epoch": 25, "training_loss": 55.31130504608154, "training_acc": 52.5, "val_loss": 13.774715662002563, "val_acc": 55.0}
{"epoch": 26, "training_loss": 55.65073585510254, "training_acc": 52.5, "val_loss": 13.812975883483887, "val_acc": 55.0}
{"epoch": 27, "training_loss": 55.88816452026367, "training_acc": 52.5, "val_loss": 13.818053007125854, "val_acc": 55.0}
{"epoch": 28, "training_loss": 55.94773483276367, "training_acc": 52.5, "val_loss": 13.74502420425415, "val_acc": 55.0}
{"epoch": 29, "training_loss": 55.4772891998291, "training_acc": 52.5, "val_loss": 13.766206502914429, "val_acc": 55.0}
{"epoch": 30, "training_loss": 55.14380645751953, "training_acc": 55.0, "val_loss": 13.84453296661377, "val_acc": 55.0}
{"epoch": 31, "training_loss": 55.40809154510498, "training_acc": 50.0, "val_loss": 13.901046514511108, "val_acc": 55.0}
{"epoch": 32, "training_loss": 55.336177825927734, "training_acc": 47.5, "val_loss": 13.955107927322388, "val_acc": 55.0}
{"epoch": 33, "training_loss": 55.703585624694824, "training_acc": 47.5, "val_loss": 13.932298421859741, "val_acc": 55.0}
{"epoch": 34, "training_loss": 55.5583438873291, "training_acc": 47.5, "val_loss": 13.849486112594604, "val_acc": 55.0}
{"epoch": 35, "training_loss": 55.251158714294434, "training_acc": 55.0, "val_loss": 13.790075778961182, "val_acc": 55.0}
{"epoch": 36, "training_loss": 55.12852668762207, "training_acc": 52.5, "val_loss": 13.774032592773438, "val_acc": 55.0}
{"epoch": 37, "training_loss": 55.2517147064209, "training_acc": 52.5, "val_loss": 13.773659467697144, "val_acc": 55.0}
{"epoch": 38, "training_loss": 55.190247535705566, "training_acc": 52.5, "val_loss": 13.77339243888855, "val_acc": 55.0}
{"epoch": 39, "training_loss": 55.122528076171875, "training_acc": 52.5, "val_loss": 13.757953643798828, "val_acc": 55.0}
{"epoch": 40, "training_loss": 55.18537712097168, "training_acc": 52.5, "val_loss": 13.753238916397095, "val_acc": 55.0}
{"epoch": 41, "training_loss": 55.05483913421631, "training_acc": 52.5, "val_loss": 13.791888952255249, "val_acc": 55.0}
{"epoch": 42, "training_loss": 55.33637619018555, "training_acc": 51.25, "val_loss": 13.860443830490112, "val_acc": 55.0}
