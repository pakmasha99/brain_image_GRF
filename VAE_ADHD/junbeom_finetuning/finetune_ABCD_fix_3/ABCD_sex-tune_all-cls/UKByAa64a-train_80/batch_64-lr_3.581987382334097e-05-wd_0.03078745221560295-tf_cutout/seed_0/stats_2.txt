"main_optuna_fix_3.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3 --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 55.510629653930664, "training_acc": 52.5, "val_loss": 13.823601007461548, "val_acc": 55.0}
{"epoch": 1, "training_loss": 55.54208946228027, "training_acc": 52.5, "val_loss": 13.807581663131714, "val_acc": 55.0}
{"epoch": 2, "training_loss": 55.4107666015625, "training_acc": 52.5, "val_loss": 13.79425048828125, "val_acc": 55.0}
{"epoch": 3, "training_loss": 55.257076263427734, "training_acc": 52.5, "val_loss": 13.774983882904053, "val_acc": 55.0}
{"epoch": 4, "training_loss": 55.36054611206055, "training_acc": 52.5, "val_loss": 13.79015326499939, "val_acc": 55.0}
{"epoch": 5, "training_loss": 55.366018295288086, "training_acc": 52.5, "val_loss": 13.805407285690308, "val_acc": 55.0}
{"epoch": 6, "training_loss": 55.4650764465332, "training_acc": 52.5, "val_loss": 13.787437677383423, "val_acc": 55.0}
{"epoch": 7, "training_loss": 55.28597354888916, "training_acc": 52.5, "val_loss": 13.770354986190796, "val_acc": 55.0}
{"epoch": 8, "training_loss": 55.34848403930664, "training_acc": 52.5, "val_loss": 13.770478963851929, "val_acc": 55.0}
{"epoch": 9, "training_loss": 55.246023178100586, "training_acc": 52.5, "val_loss": 13.793847560882568, "val_acc": 55.0}
{"epoch": 10, "training_loss": 55.27708053588867, "training_acc": 52.5, "val_loss": 13.822740316390991, "val_acc": 55.0}
{"epoch": 11, "training_loss": 55.322519302368164, "training_acc": 52.5, "val_loss": 13.809407949447632, "val_acc": 55.0}
{"epoch": 12, "training_loss": 55.391295433044434, "training_acc": 52.5, "val_loss": 13.788799047470093, "val_acc": 55.0}
{"epoch": 13, "training_loss": 55.305564880371094, "training_acc": 52.5, "val_loss": 13.779327869415283, "val_acc": 55.0}
{"epoch": 14, "training_loss": 55.37003707885742, "training_acc": 52.5, "val_loss": 13.77435564994812, "val_acc": 55.0}
{"epoch": 15, "training_loss": 55.33504104614258, "training_acc": 52.5, "val_loss": 13.765790462493896, "val_acc": 55.0}
{"epoch": 16, "training_loss": 55.46426582336426, "training_acc": 52.5, "val_loss": 13.761528730392456, "val_acc": 55.0}
{"epoch": 17, "training_loss": 55.515207290649414, "training_acc": 52.5, "val_loss": 13.763978481292725, "val_acc": 55.0}
{"epoch": 18, "training_loss": 55.398892402648926, "training_acc": 52.5, "val_loss": 13.759483098983765, "val_acc": 55.0}
{"epoch": 19, "training_loss": 55.15260601043701, "training_acc": 52.5, "val_loss": 13.765575885772705, "val_acc": 55.0}
{"epoch": 20, "training_loss": 55.35331439971924, "training_acc": 52.5, "val_loss": 13.782565593719482, "val_acc": 55.0}
{"epoch": 21, "training_loss": 55.423590660095215, "training_acc": 52.5, "val_loss": 13.77750277519226, "val_acc": 55.0}
{"epoch": 22, "training_loss": 55.230472564697266, "training_acc": 53.75, "val_loss": 13.768504858016968, "val_acc": 55.0}
{"epoch": 23, "training_loss": 55.03332042694092, "training_acc": 55.0, "val_loss": 13.761086463928223, "val_acc": 55.0}
{"epoch": 24, "training_loss": 55.34963417053223, "training_acc": 52.5, "val_loss": 13.751974105834961, "val_acc": 55.0}
{"epoch": 25, "training_loss": 55.34449005126953, "training_acc": 52.5, "val_loss": 13.758476972579956, "val_acc": 55.0}
{"epoch": 26, "training_loss": 55.50211524963379, "training_acc": 52.5, "val_loss": 13.762867450714111, "val_acc": 55.0}
{"epoch": 27, "training_loss": 55.4299955368042, "training_acc": 52.5, "val_loss": 13.761869668960571, "val_acc": 55.0}
{"epoch": 28, "training_loss": 55.55281448364258, "training_acc": 52.5, "val_loss": 13.750604391098022, "val_acc": 55.0}
{"epoch": 29, "training_loss": 55.281925201416016, "training_acc": 52.5, "val_loss": 13.78212571144104, "val_acc": 55.0}
{"epoch": 30, "training_loss": 55.30084228515625, "training_acc": 52.5, "val_loss": 13.791944980621338, "val_acc": 55.0}
{"epoch": 31, "training_loss": 55.33439826965332, "training_acc": 52.5, "val_loss": 13.812965154647827, "val_acc": 55.0}
{"epoch": 32, "training_loss": 55.295305252075195, "training_acc": 52.5, "val_loss": 13.848711252212524, "val_acc": 55.0}
{"epoch": 33, "training_loss": 55.44344711303711, "training_acc": 51.25, "val_loss": 13.896692991256714, "val_acc": 55.0}
{"epoch": 34, "training_loss": 55.41130065917969, "training_acc": 47.5, "val_loss": 13.894411325454712, "val_acc": 55.0}
{"epoch": 35, "training_loss": 55.42961120605469, "training_acc": 50.0, "val_loss": 13.831099271774292, "val_acc": 55.0}
{"epoch": 36, "training_loss": 55.319650650024414, "training_acc": 57.5, "val_loss": 13.799288272857666, "val_acc": 55.0}
{"epoch": 37, "training_loss": 55.27121448516846, "training_acc": 51.25, "val_loss": 13.78862738609314, "val_acc": 55.0}
{"epoch": 38, "training_loss": 55.205716133117676, "training_acc": 51.25, "val_loss": 13.779228925704956, "val_acc": 55.0}
{"epoch": 39, "training_loss": 54.920074462890625, "training_acc": 53.75, "val_loss": 13.761595487594604, "val_acc": 55.0}
{"epoch": 40, "training_loss": 55.018978118896484, "training_acc": 55.0, "val_loss": 13.783324956893921, "val_acc": 55.0}
