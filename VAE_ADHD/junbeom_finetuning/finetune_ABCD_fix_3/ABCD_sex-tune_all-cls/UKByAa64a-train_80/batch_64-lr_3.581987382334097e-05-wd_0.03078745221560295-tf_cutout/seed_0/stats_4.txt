"main_optuna_fix_3.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3 --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 55.461524963378906, "training_acc": 52.5, "val_loss": 13.771661520004272, "val_acc": 55.0}
{"epoch": 1, "training_loss": 55.49173927307129, "training_acc": 52.5, "val_loss": 13.782857656478882, "val_acc": 55.0}
{"epoch": 2, "training_loss": 55.36598777770996, "training_acc": 52.5, "val_loss": 13.7764310836792, "val_acc": 55.0}
{"epoch": 3, "training_loss": 55.57610511779785, "training_acc": 52.5, "val_loss": 13.758876323699951, "val_acc": 55.0}
{"epoch": 4, "training_loss": 55.455881118774414, "training_acc": 52.5, "val_loss": 13.763411045074463, "val_acc": 55.0}
{"epoch": 5, "training_loss": 55.322078704833984, "training_acc": 52.5, "val_loss": 13.780676126480103, "val_acc": 55.0}
{"epoch": 6, "training_loss": 55.27775192260742, "training_acc": 52.5, "val_loss": 13.777034282684326, "val_acc": 55.0}
{"epoch": 7, "training_loss": 55.21290111541748, "training_acc": 52.5, "val_loss": 13.774276971817017, "val_acc": 55.0}
{"epoch": 8, "training_loss": 55.17070388793945, "training_acc": 52.5, "val_loss": 13.800686597824097, "val_acc": 55.0}
{"epoch": 9, "training_loss": 55.409183502197266, "training_acc": 52.5, "val_loss": 13.828493356704712, "val_acc": 55.0}
{"epoch": 10, "training_loss": 55.22926712036133, "training_acc": 52.5, "val_loss": 13.79281997680664, "val_acc": 55.0}
{"epoch": 11, "training_loss": 55.165541648864746, "training_acc": 52.5, "val_loss": 13.757326602935791, "val_acc": 55.0}
{"epoch": 12, "training_loss": 55.325860023498535, "training_acc": 52.5, "val_loss": 13.762658834457397, "val_acc": 55.0}
{"epoch": 13, "training_loss": 55.42863082885742, "training_acc": 52.5, "val_loss": 13.770761489868164, "val_acc": 55.0}
{"epoch": 14, "training_loss": 55.34019660949707, "training_acc": 52.5, "val_loss": 13.775829076766968, "val_acc": 55.0}
{"epoch": 15, "training_loss": 55.33695411682129, "training_acc": 52.5, "val_loss": 13.785004615783691, "val_acc": 55.0}
{"epoch": 16, "training_loss": 55.338661193847656, "training_acc": 52.5, "val_loss": 13.772848844528198, "val_acc": 55.0}
{"epoch": 17, "training_loss": 55.287010192871094, "training_acc": 52.5, "val_loss": 13.769302368164062, "val_acc": 55.0}
{"epoch": 18, "training_loss": 55.37102127075195, "training_acc": 52.5, "val_loss": 13.774986267089844, "val_acc": 55.0}
{"epoch": 19, "training_loss": 55.16413497924805, "training_acc": 52.5, "val_loss": 13.795204162597656, "val_acc": 55.0}
{"epoch": 20, "training_loss": 55.235466957092285, "training_acc": 52.5, "val_loss": 13.831239938735962, "val_acc": 55.0}
{"epoch": 21, "training_loss": 55.332353591918945, "training_acc": 52.5, "val_loss": 13.84926438331604, "val_acc": 55.0}
{"epoch": 22, "training_loss": 55.35775184631348, "training_acc": 52.5, "val_loss": 13.84117841720581, "val_acc": 55.0}
{"epoch": 23, "training_loss": 55.267184257507324, "training_acc": 52.5, "val_loss": 13.814157247543335, "val_acc": 55.0}
{"epoch": 24, "training_loss": 55.118120193481445, "training_acc": 52.5, "val_loss": 13.779925107955933, "val_acc": 55.0}
{"epoch": 25, "training_loss": 55.04209804534912, "training_acc": 52.5, "val_loss": 13.759769201278687, "val_acc": 55.0}
{"epoch": 26, "training_loss": 55.22207546234131, "training_acc": 52.5, "val_loss": 13.75569224357605, "val_acc": 55.0}
{"epoch": 27, "training_loss": 54.93839073181152, "training_acc": 52.5, "val_loss": 13.762451410293579, "val_acc": 55.0}
{"epoch": 28, "training_loss": 55.31632041931152, "training_acc": 52.5, "val_loss": 13.778959512710571, "val_acc": 55.0}
{"epoch": 29, "training_loss": 55.195509910583496, "training_acc": 52.5, "val_loss": 13.791362047195435, "val_acc": 55.0}
{"epoch": 30, "training_loss": 55.05886459350586, "training_acc": 52.5, "val_loss": 13.779429197311401, "val_acc": 55.0}
