"main_optuna_fix_3.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3 --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 55.52698516845703, "training_acc": 52.5, "val_loss": 13.792768716812134, "val_acc": 55.0}
{"epoch": 1, "training_loss": 55.342177391052246, "training_acc": 52.5, "val_loss": 13.772274255752563, "val_acc": 55.0}
{"epoch": 2, "training_loss": 55.34276580810547, "training_acc": 52.5, "val_loss": 13.772506713867188, "val_acc": 55.0}
{"epoch": 3, "training_loss": 55.24781799316406, "training_acc": 52.5, "val_loss": 13.773837089538574, "val_acc": 55.0}
{"epoch": 4, "training_loss": 55.220415115356445, "training_acc": 52.5, "val_loss": 13.768844604492188, "val_acc": 55.0}
{"epoch": 5, "training_loss": 55.270851135253906, "training_acc": 52.5, "val_loss": 13.77038836479187, "val_acc": 55.0}
{"epoch": 6, "training_loss": 55.181660652160645, "training_acc": 52.5, "val_loss": 13.753141164779663, "val_acc": 55.0}
{"epoch": 7, "training_loss": 55.19875431060791, "training_acc": 52.5, "val_loss": 13.748348951339722, "val_acc": 55.0}
{"epoch": 8, "training_loss": 55.218801498413086, "training_acc": 52.5, "val_loss": 13.790518045425415, "val_acc": 55.0}
{"epoch": 9, "training_loss": 55.25775909423828, "training_acc": 52.5, "val_loss": 13.832091093063354, "val_acc": 55.0}
{"epoch": 10, "training_loss": 55.30966567993164, "training_acc": 51.25, "val_loss": 13.815256357192993, "val_acc": 55.0}
{"epoch": 11, "training_loss": 55.24408149719238, "training_acc": 51.25, "val_loss": 13.776072263717651, "val_acc": 55.0}
{"epoch": 12, "training_loss": 55.34821319580078, "training_acc": 52.5, "val_loss": 13.75827670097351, "val_acc": 55.0}
{"epoch": 13, "training_loss": 55.23849868774414, "training_acc": 52.5, "val_loss": 13.76555323600769, "val_acc": 55.0}
{"epoch": 14, "training_loss": 55.272976875305176, "training_acc": 52.5, "val_loss": 13.768881559371948, "val_acc": 55.0}
{"epoch": 15, "training_loss": 55.31813430786133, "training_acc": 52.5, "val_loss": 13.75245451927185, "val_acc": 55.0}
{"epoch": 16, "training_loss": 55.187992095947266, "training_acc": 52.5, "val_loss": 13.749315738677979, "val_acc": 55.0}
{"epoch": 17, "training_loss": 55.5555477142334, "training_acc": 52.5, "val_loss": 13.750734329223633, "val_acc": 55.0}
{"epoch": 18, "training_loss": 55.41108512878418, "training_acc": 52.5, "val_loss": 13.738241195678711, "val_acc": 55.0}
{"epoch": 19, "training_loss": 55.285423278808594, "training_acc": 52.5, "val_loss": 13.770546913146973, "val_acc": 55.0}
{"epoch": 20, "training_loss": 55.296974182128906, "training_acc": 52.5, "val_loss": 13.80570650100708, "val_acc": 55.0}
{"epoch": 21, "training_loss": 55.332762718200684, "training_acc": 52.5, "val_loss": 13.799548149108887, "val_acc": 55.0}
{"epoch": 22, "training_loss": 55.25974464416504, "training_acc": 52.5, "val_loss": 13.788207769393921, "val_acc": 55.0}
{"epoch": 23, "training_loss": 55.16336536407471, "training_acc": 52.5, "val_loss": 13.765357732772827, "val_acc": 55.0}
{"epoch": 24, "training_loss": 55.202144622802734, "training_acc": 52.5, "val_loss": 13.749665021896362, "val_acc": 55.0}
{"epoch": 25, "training_loss": 54.976348876953125, "training_acc": 52.5, "val_loss": 13.768205642700195, "val_acc": 55.0}
{"epoch": 26, "training_loss": 55.54313087463379, "training_acc": 52.5, "val_loss": 13.792232275009155, "val_acc": 55.0}
{"epoch": 27, "training_loss": 55.53806018829346, "training_acc": 52.5, "val_loss": 13.769885301589966, "val_acc": 55.0}
{"epoch": 28, "training_loss": 55.485124588012695, "training_acc": 52.5, "val_loss": 13.743242025375366, "val_acc": 55.0}
{"epoch": 29, "training_loss": 55.233160972595215, "training_acc": 52.5, "val_loss": 13.819178342819214, "val_acc": 55.0}
{"epoch": 30, "training_loss": 55.2606201171875, "training_acc": 52.5, "val_loss": 13.825737237930298, "val_acc": 55.0}
{"epoch": 31, "training_loss": 55.33403015136719, "training_acc": 52.5, "val_loss": 13.837274312973022, "val_acc": 55.0}
{"epoch": 32, "training_loss": 55.19548416137695, "training_acc": 61.25, "val_loss": 13.846150636672974, "val_acc": 55.0}
{"epoch": 33, "training_loss": 55.37182426452637, "training_acc": 63.75, "val_loss": 13.823772668838501, "val_acc": 55.0}
{"epoch": 34, "training_loss": 55.24298095703125, "training_acc": 51.25, "val_loss": 13.788536787033081, "val_acc": 55.0}
{"epoch": 35, "training_loss": 55.223981857299805, "training_acc": 52.5, "val_loss": 13.771146535873413, "val_acc": 55.0}
{"epoch": 36, "training_loss": 55.096845626831055, "training_acc": 52.5, "val_loss": 13.762754201889038, "val_acc": 55.0}
