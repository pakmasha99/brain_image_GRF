"main_optuna_fix_3.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3 --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 82.31355667114258, "training_acc": 43.75, "val_loss": 956.0549163818359, "val_acc": 55.0}
{"epoch": 1, "training_loss": 3521.4137420654297, "training_acc": 45.0, "val_loss": 35.532939434051514, "val_acc": 55.0}
{"epoch": 2, "training_loss": 138.502779006958, "training_acc": 50.0, "val_loss": 13.954123258590698, "val_acc": 55.0}
{"epoch": 3, "training_loss": 57.9441499710083, "training_acc": 47.5, "val_loss": 30.4520845413208, "val_acc": 45.0}
{"epoch": 4, "training_loss": 99.77446937561035, "training_acc": 52.5, "val_loss": 13.816696405410767, "val_acc": 55.0}
{"epoch": 5, "training_loss": 55.96966361999512, "training_acc": 52.5, "val_loss": 13.837307691574097, "val_acc": 55.0}
{"epoch": 6, "training_loss": 56.060625076293945, "training_acc": 52.5, "val_loss": 13.770339488983154, "val_acc": 55.0}
{"epoch": 7, "training_loss": 55.36286735534668, "training_acc": 52.5, "val_loss": 13.887103796005249, "val_acc": 55.0}
{"epoch": 8, "training_loss": 55.66809272766113, "training_acc": 42.5, "val_loss": 13.998717069625854, "val_acc": 55.0}
{"epoch": 9, "training_loss": 55.81314659118652, "training_acc": 47.5, "val_loss": 14.037548303604126, "val_acc": 55.0}
{"epoch": 10, "training_loss": 55.73477840423584, "training_acc": 47.5, "val_loss": 13.76522421836853, "val_acc": 55.0}
{"epoch": 11, "training_loss": 55.27988052368164, "training_acc": 52.5, "val_loss": 14.062976837158203, "val_acc": 55.0}
{"epoch": 12, "training_loss": 57.17947769165039, "training_acc": 52.5, "val_loss": 13.765032291412354, "val_acc": 55.0}
{"epoch": 13, "training_loss": 55.53064823150635, "training_acc": 52.5, "val_loss": 13.839281797409058, "val_acc": 55.0}
{"epoch": 14, "training_loss": 55.39791393280029, "training_acc": 52.5, "val_loss": 13.88694167137146, "val_acc": 55.0}
{"epoch": 15, "training_loss": 55.613911628723145, "training_acc": 47.5, "val_loss": 13.86979341506958, "val_acc": 55.0}
{"epoch": 16, "training_loss": 55.33933639526367, "training_acc": 57.5, "val_loss": 13.776168823242188, "val_acc": 55.0}
{"epoch": 17, "training_loss": 55.516334533691406, "training_acc": 52.5, "val_loss": 13.76591682434082, "val_acc": 55.0}
{"epoch": 18, "training_loss": 55.533369064331055, "training_acc": 52.5, "val_loss": 13.763374090194702, "val_acc": 55.0}
{"epoch": 19, "training_loss": 55.370492935180664, "training_acc": 52.5, "val_loss": 13.793232440948486, "val_acc": 55.0}
{"epoch": 20, "training_loss": 55.39651679992676, "training_acc": 52.5, "val_loss": 13.853764533996582, "val_acc": 55.0}
{"epoch": 21, "training_loss": 55.43419075012207, "training_acc": 56.25, "val_loss": 13.870285749435425, "val_acc": 55.0}
{"epoch": 22, "training_loss": 55.469178199768066, "training_acc": 47.5, "val_loss": 13.85316252708435, "val_acc": 55.0}
{"epoch": 23, "training_loss": 55.41785430908203, "training_acc": 52.5, "val_loss": 13.81769061088562, "val_acc": 55.0}
{"epoch": 24, "training_loss": 55.33676815032959, "training_acc": 52.5, "val_loss": 13.786489963531494, "val_acc": 55.0}
{"epoch": 25, "training_loss": 55.29436492919922, "training_acc": 52.5, "val_loss": 13.765575885772705, "val_acc": 55.0}
{"epoch": 26, "training_loss": 55.36276817321777, "training_acc": 52.5, "val_loss": 13.765836954116821, "val_acc": 55.0}
{"epoch": 27, "training_loss": 55.5255765914917, "training_acc": 52.5, "val_loss": 13.778008222579956, "val_acc": 55.0}
{"epoch": 28, "training_loss": 55.71738243103027, "training_acc": 52.5, "val_loss": 13.766578435897827, "val_acc": 55.0}
{"epoch": 29, "training_loss": 55.552711486816406, "training_acc": 52.5, "val_loss": 13.770427703857422, "val_acc": 55.0}
{"epoch": 30, "training_loss": 55.35142421722412, "training_acc": 52.5, "val_loss": 13.796707391738892, "val_acc": 55.0}
{"epoch": 31, "training_loss": 55.326072692871094, "training_acc": 52.5, "val_loss": 13.83604645729065, "val_acc": 55.0}
{"epoch": 32, "training_loss": 55.39891052246094, "training_acc": 52.5, "val_loss": 13.89534592628479, "val_acc": 55.0}
{"epoch": 33, "training_loss": 55.539992332458496, "training_acc": 47.5, "val_loss": 13.894919157028198, "val_acc": 55.0}
{"epoch": 34, "training_loss": 55.50139141082764, "training_acc": 47.5, "val_loss": 13.843109607696533, "val_acc": 55.0}
{"epoch": 35, "training_loss": 55.45320129394531, "training_acc": 52.5, "val_loss": 13.810722827911377, "val_acc": 55.0}
{"epoch": 36, "training_loss": 55.36414337158203, "training_acc": 52.5, "val_loss": 13.79601240158081, "val_acc": 55.0}
{"epoch": 37, "training_loss": 55.36196994781494, "training_acc": 52.5, "val_loss": 13.779491186141968, "val_acc": 55.0}
{"epoch": 38, "training_loss": 55.351640701293945, "training_acc": 52.5, "val_loss": 13.772042989730835, "val_acc": 55.0}
{"epoch": 39, "training_loss": 55.36518669128418, "training_acc": 52.5, "val_loss": 13.766974210739136, "val_acc": 55.0}
{"epoch": 40, "training_loss": 55.39531135559082, "training_acc": 52.5, "val_loss": 13.766449689865112, "val_acc": 55.0}
{"epoch": 41, "training_loss": 55.38762855529785, "training_acc": 52.5, "val_loss": 13.773488998413086, "val_acc": 55.0}
{"epoch": 42, "training_loss": 55.377132415771484, "training_acc": 52.5, "val_loss": 13.788206577301025, "val_acc": 55.0}
