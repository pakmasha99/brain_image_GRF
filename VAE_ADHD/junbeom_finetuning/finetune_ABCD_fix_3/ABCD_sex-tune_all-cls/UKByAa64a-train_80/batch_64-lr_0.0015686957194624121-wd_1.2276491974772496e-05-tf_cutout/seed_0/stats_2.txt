"main_optuna_fix_3.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3 --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 60.47722244262695, "training_acc": 52.5, "val_loss": 3707.6104736328125, "val_acc": 45.0}
{"epoch": 1, "training_loss": 10717.286499023438, "training_acc": 55.0, "val_loss": 35.789756774902344, "val_acc": 55.0}
{"epoch": 2, "training_loss": 138.02056503295898, "training_acc": 50.0, "val_loss": 23.816468715667725, "val_acc": 55.0}
{"epoch": 3, "training_loss": 95.56264877319336, "training_acc": 50.0, "val_loss": 14.732065200805664, "val_acc": 55.0}
{"epoch": 4, "training_loss": 60.328481674194336, "training_acc": 47.5, "val_loss": 13.784598112106323, "val_acc": 55.0}
{"epoch": 5, "training_loss": 56.03468322753906, "training_acc": 52.5, "val_loss": 14.768530130386353, "val_acc": 55.0}
{"epoch": 6, "training_loss": 56.428162574768066, "training_acc": 47.5, "val_loss": 15.284595489501953, "val_acc": 55.0}
{"epoch": 7, "training_loss": 62.55148887634277, "training_acc": 52.5, "val_loss": 13.957191705703735, "val_acc": 55.0}
{"epoch": 8, "training_loss": 55.697614669799805, "training_acc": 52.5, "val_loss": 14.031816720962524, "val_acc": 55.0}
{"epoch": 9, "training_loss": 55.82678031921387, "training_acc": 47.5, "val_loss": 14.401215314865112, "val_acc": 55.0}
{"epoch": 10, "training_loss": 56.94997787475586, "training_acc": 47.5, "val_loss": 14.126760959625244, "val_acc": 55.0}
{"epoch": 11, "training_loss": 55.88447093963623, "training_acc": 47.5, "val_loss": 13.806909322738647, "val_acc": 55.0}
{"epoch": 12, "training_loss": 55.431477546691895, "training_acc": 52.5, "val_loss": 13.78604769706726, "val_acc": 55.0}
{"epoch": 13, "training_loss": 55.60938549041748, "training_acc": 52.5, "val_loss": 13.77518892288208, "val_acc": 55.0}
{"epoch": 14, "training_loss": 55.36964797973633, "training_acc": 52.5, "val_loss": 13.842037916183472, "val_acc": 55.0}
{"epoch": 15, "training_loss": 55.648794174194336, "training_acc": 45.0, "val_loss": 13.8540518283844, "val_acc": 55.0}
{"epoch": 16, "training_loss": 55.28753662109375, "training_acc": 52.5, "val_loss": 13.772844076156616, "val_acc": 55.0}
{"epoch": 17, "training_loss": 55.58914852142334, "training_acc": 52.5, "val_loss": 13.786946535110474, "val_acc": 55.0}
{"epoch": 18, "training_loss": 55.60544776916504, "training_acc": 52.5, "val_loss": 13.770225048065186, "val_acc": 55.0}
{"epoch": 19, "training_loss": 55.4067964553833, "training_acc": 52.5, "val_loss": 13.782761096954346, "val_acc": 55.0}
{"epoch": 20, "training_loss": 55.385854721069336, "training_acc": 52.5, "val_loss": 13.829830884933472, "val_acc": 55.0}
{"epoch": 21, "training_loss": 55.40871810913086, "training_acc": 52.5, "val_loss": 13.8422691822052, "val_acc": 55.0}
{"epoch": 22, "training_loss": 55.40779495239258, "training_acc": 52.5, "val_loss": 13.819122314453125, "val_acc": 55.0}
{"epoch": 23, "training_loss": 55.3610954284668, "training_acc": 52.5, "val_loss": 13.788290023803711, "val_acc": 55.0}
{"epoch": 24, "training_loss": 55.324764251708984, "training_acc": 52.5, "val_loss": 13.767030239105225, "val_acc": 55.0}
