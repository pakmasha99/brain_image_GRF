"main_optuna_fix_3.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3 --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 55.30362129211426, "training_acc": 53.75, "val_loss": 13.88101577758789, "val_acc": 50.0}
{"epoch": 1, "training_loss": 55.2675666809082, "training_acc": 53.75, "val_loss": 13.915516138076782, "val_acc": 50.0}
{"epoch": 2, "training_loss": 55.292612075805664, "training_acc": 53.75, "val_loss": 13.910480737686157, "val_acc": 50.0}
{"epoch": 3, "training_loss": 55.242244720458984, "training_acc": 53.75, "val_loss": 13.930493593215942, "val_acc": 50.0}
{"epoch": 4, "training_loss": 55.157748222351074, "training_acc": 53.75, "val_loss": 13.915141820907593, "val_acc": 50.0}
{"epoch": 5, "training_loss": 55.2076416015625, "training_acc": 53.75, "val_loss": 13.9150869846344, "val_acc": 50.0}
{"epoch": 6, "training_loss": 55.103989601135254, "training_acc": 53.75, "val_loss": 13.916226625442505, "val_acc": 50.0}
{"epoch": 7, "training_loss": 55.05961513519287, "training_acc": 53.75, "val_loss": 13.915208578109741, "val_acc": 50.0}
{"epoch": 8, "training_loss": 55.03461933135986, "training_acc": 53.75, "val_loss": 13.924562931060791, "val_acc": 50.0}
{"epoch": 9, "training_loss": 55.0292329788208, "training_acc": 53.75, "val_loss": 13.911664485931396, "val_acc": 50.0}
{"epoch": 10, "training_loss": 55.16919231414795, "training_acc": 53.75, "val_loss": 13.91114354133606, "val_acc": 50.0}
{"epoch": 11, "training_loss": 54.83444404602051, "training_acc": 53.75, "val_loss": 13.906158208847046, "val_acc": 50.0}
{"epoch": 12, "training_loss": 54.92464351654053, "training_acc": 53.75, "val_loss": 13.909060955047607, "val_acc": 50.0}
{"epoch": 13, "training_loss": 54.92556190490723, "training_acc": 53.75, "val_loss": 13.916337490081787, "val_acc": 50.0}
{"epoch": 14, "training_loss": 54.919222831726074, "training_acc": 53.75, "val_loss": 13.926252126693726, "val_acc": 50.0}
{"epoch": 15, "training_loss": 54.67668056488037, "training_acc": 53.75, "val_loss": 13.959425687789917, "val_acc": 50.0}
{"epoch": 16, "training_loss": 55.140329360961914, "training_acc": 53.75, "val_loss": 13.971925973892212, "val_acc": 50.0}
{"epoch": 17, "training_loss": 54.82784843444824, "training_acc": 53.75, "val_loss": 13.947738409042358, "val_acc": 50.0}
{"epoch": 18, "training_loss": 54.79952144622803, "training_acc": 53.75, "val_loss": 13.9035165309906, "val_acc": 50.0}
{"epoch": 19, "training_loss": 54.70850372314453, "training_acc": 53.75, "val_loss": 13.891582489013672, "val_acc": 50.0}
{"epoch": 20, "training_loss": 54.958879470825195, "training_acc": 53.75, "val_loss": 13.890914916992188, "val_acc": 50.0}
{"epoch": 21, "training_loss": 54.86797332763672, "training_acc": 53.75, "val_loss": 13.881858587265015, "val_acc": 50.0}
{"epoch": 22, "training_loss": 54.74908447265625, "training_acc": 53.75, "val_loss": 13.85896921157837, "val_acc": 50.0}
{"epoch": 23, "training_loss": 54.497732162475586, "training_acc": 53.75, "val_loss": 13.88408899307251, "val_acc": 50.0}
{"epoch": 24, "training_loss": 54.47725772857666, "training_acc": 53.75, "val_loss": 13.92696738243103, "val_acc": 50.0}
{"epoch": 25, "training_loss": 54.45223522186279, "training_acc": 53.75, "val_loss": 13.950462341308594, "val_acc": 50.0}
{"epoch": 26, "training_loss": 54.939517974853516, "training_acc": 53.75, "val_loss": 13.968679904937744, "val_acc": 50.0}
{"epoch": 27, "training_loss": 54.988783836364746, "training_acc": 53.75, "val_loss": 13.950213193893433, "val_acc": 50.0}
{"epoch": 28, "training_loss": 54.557024002075195, "training_acc": 53.75, "val_loss": 13.916782140731812, "val_acc": 50.0}
{"epoch": 29, "training_loss": 54.52582263946533, "training_acc": 53.75, "val_loss": 13.895338773727417, "val_acc": 50.0}
{"epoch": 30, "training_loss": 54.63742542266846, "training_acc": 53.75, "val_loss": 13.877220153808594, "val_acc": 50.0}
{"epoch": 31, "training_loss": 54.644083976745605, "training_acc": 53.75, "val_loss": 13.875818252563477, "val_acc": 50.0}
{"epoch": 32, "training_loss": 54.26700210571289, "training_acc": 53.75, "val_loss": 13.86700987815857, "val_acc": 50.0}
{"epoch": 33, "training_loss": 54.60583019256592, "training_acc": 53.75, "val_loss": 13.8875150680542, "val_acc": 50.0}
{"epoch": 34, "training_loss": 54.62449932098389, "training_acc": 53.75, "val_loss": 13.905537128448486, "val_acc": 50.0}
{"epoch": 35, "training_loss": 54.18026161193848, "training_acc": 53.75, "val_loss": 13.881326913833618, "val_acc": 50.0}
{"epoch": 36, "training_loss": 54.2312068939209, "training_acc": 53.75, "val_loss": 13.840322494506836, "val_acc": 50.0}
{"epoch": 37, "training_loss": 54.38523483276367, "training_acc": 53.75, "val_loss": 13.853856325149536, "val_acc": 50.0}
{"epoch": 38, "training_loss": 54.63798522949219, "training_acc": 53.75, "val_loss": 13.878639936447144, "val_acc": 50.0}
{"epoch": 39, "training_loss": 54.67183971405029, "training_acc": 58.75, "val_loss": 13.883050680160522, "val_acc": 50.0}
{"epoch": 40, "training_loss": 54.6629524230957, "training_acc": 63.75, "val_loss": 13.853009939193726, "val_acc": 50.0}
{"epoch": 41, "training_loss": 54.5787410736084, "training_acc": 63.75, "val_loss": 13.82931113243103, "val_acc": 50.0}
{"epoch": 42, "training_loss": 54.17552185058594, "training_acc": 66.25, "val_loss": 13.81094217300415, "val_acc": 50.0}
{"epoch": 43, "training_loss": 54.15324401855469, "training_acc": 57.5, "val_loss": 13.809374570846558, "val_acc": 50.0}
{"epoch": 44, "training_loss": 53.90297508239746, "training_acc": 56.25, "val_loss": 13.825947046279907, "val_acc": 50.0}
{"epoch": 45, "training_loss": 54.0543270111084, "training_acc": 53.75, "val_loss": 13.816088438034058, "val_acc": 50.0}
{"epoch": 46, "training_loss": 53.79158020019531, "training_acc": 57.5, "val_loss": 13.825489282608032, "val_acc": 50.0}
{"epoch": 47, "training_loss": 53.892149925231934, "training_acc": 60.0, "val_loss": 13.838790655136108, "val_acc": 50.0}
{"epoch": 48, "training_loss": 53.997318267822266, "training_acc": 57.5, "val_loss": 13.845161199569702, "val_acc": 50.0}
{"epoch": 49, "training_loss": 54.14304065704346, "training_acc": 55.0, "val_loss": 13.906038999557495, "val_acc": 50.0}
{"epoch": 50, "training_loss": 53.996724128723145, "training_acc": 53.75, "val_loss": 13.8901948928833, "val_acc": 50.0}
{"epoch": 51, "training_loss": 53.67576503753662, "training_acc": 53.75, "val_loss": 13.813575506210327, "val_acc": 50.0}
