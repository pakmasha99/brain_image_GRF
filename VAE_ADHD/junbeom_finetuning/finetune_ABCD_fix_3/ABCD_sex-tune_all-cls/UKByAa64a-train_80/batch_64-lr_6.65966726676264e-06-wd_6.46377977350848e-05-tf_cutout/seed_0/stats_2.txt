"main_optuna_fix_3.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3 --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 55.405426025390625, "training_acc": 52.5, "val_loss": 13.794816732406616, "val_acc": 55.0}
{"epoch": 1, "training_loss": 55.397422790527344, "training_acc": 52.5, "val_loss": 13.776863813400269, "val_acc": 55.0}
{"epoch": 2, "training_loss": 55.273009300231934, "training_acc": 52.5, "val_loss": 13.785308599472046, "val_acc": 55.0}
{"epoch": 3, "training_loss": 55.26540756225586, "training_acc": 52.5, "val_loss": 13.769243955612183, "val_acc": 55.0}
{"epoch": 4, "training_loss": 55.19026565551758, "training_acc": 52.5, "val_loss": 13.751791715621948, "val_acc": 55.0}
{"epoch": 5, "training_loss": 55.1229248046875, "training_acc": 52.5, "val_loss": 13.742398023605347, "val_acc": 55.0}
{"epoch": 6, "training_loss": 55.16577434539795, "training_acc": 52.5, "val_loss": 13.733680248260498, "val_acc": 55.0}
{"epoch": 7, "training_loss": 55.08066940307617, "training_acc": 52.5, "val_loss": 13.719831705093384, "val_acc": 55.0}
{"epoch": 8, "training_loss": 55.13881492614746, "training_acc": 52.5, "val_loss": 13.719033002853394, "val_acc": 55.0}
{"epoch": 9, "training_loss": 55.03872776031494, "training_acc": 52.5, "val_loss": 13.721281290054321, "val_acc": 55.0}
{"epoch": 10, "training_loss": 55.16831588745117, "training_acc": 52.5, "val_loss": 13.712599277496338, "val_acc": 55.0}
{"epoch": 11, "training_loss": 54.986244201660156, "training_acc": 52.5, "val_loss": 13.700176477432251, "val_acc": 55.0}
{"epoch": 12, "training_loss": 55.127790451049805, "training_acc": 52.5, "val_loss": 13.713274002075195, "val_acc": 55.0}
{"epoch": 13, "training_loss": 54.797061920166016, "training_acc": 52.5, "val_loss": 13.73934030532837, "val_acc": 55.0}
{"epoch": 14, "training_loss": 54.93963813781738, "training_acc": 52.5, "val_loss": 13.744053840637207, "val_acc": 55.0}
{"epoch": 15, "training_loss": 54.85002899169922, "training_acc": 52.5, "val_loss": 13.713258504867554, "val_acc": 55.0}
{"epoch": 16, "training_loss": 54.96634864807129, "training_acc": 52.5, "val_loss": 13.694814443588257, "val_acc": 55.0}
{"epoch": 17, "training_loss": 54.963783264160156, "training_acc": 52.5, "val_loss": 13.688806295394897, "val_acc": 55.0}
{"epoch": 18, "training_loss": 54.73007106781006, "training_acc": 52.5, "val_loss": 13.72943639755249, "val_acc": 55.0}
{"epoch": 19, "training_loss": 54.75529861450195, "training_acc": 52.5, "val_loss": 13.749593496322632, "val_acc": 55.0}
{"epoch": 20, "training_loss": 54.89595890045166, "training_acc": 52.5, "val_loss": 13.743382692337036, "val_acc": 55.0}
{"epoch": 21, "training_loss": 54.96818733215332, "training_acc": 52.5, "val_loss": 13.702421188354492, "val_acc": 55.0}
{"epoch": 22, "training_loss": 54.712382316589355, "training_acc": 52.5, "val_loss": 13.702291250228882, "val_acc": 55.0}
{"epoch": 23, "training_loss": 54.69545936584473, "training_acc": 52.5, "val_loss": 13.704721927642822, "val_acc": 55.0}
{"epoch": 24, "training_loss": 54.747979164123535, "training_acc": 52.5, "val_loss": 13.701279163360596, "val_acc": 55.0}
{"epoch": 25, "training_loss": 54.81666564941406, "training_acc": 52.5, "val_loss": 13.6806321144104, "val_acc": 55.0}
{"epoch": 26, "training_loss": 54.97250938415527, "training_acc": 52.5, "val_loss": 13.68782639503479, "val_acc": 55.0}
{"epoch": 27, "training_loss": 54.77023983001709, "training_acc": 52.5, "val_loss": 13.666795492172241, "val_acc": 55.0}
{"epoch": 28, "training_loss": 54.88278007507324, "training_acc": 52.5, "val_loss": 13.661822080612183, "val_acc": 55.0}
{"epoch": 29, "training_loss": 54.62136745452881, "training_acc": 52.5, "val_loss": 13.68122935295105, "val_acc": 55.0}
{"epoch": 30, "training_loss": 54.543362617492676, "training_acc": 52.5, "val_loss": 13.678330183029175, "val_acc": 55.0}
{"epoch": 31, "training_loss": 54.5360050201416, "training_acc": 52.5, "val_loss": 13.666772842407227, "val_acc": 55.0}
{"epoch": 32, "training_loss": 54.184998512268066, "training_acc": 52.5, "val_loss": 13.648629188537598, "val_acc": 55.0}
{"epoch": 33, "training_loss": 54.63918113708496, "training_acc": 52.5, "val_loss": 13.649228811264038, "val_acc": 55.0}
{"epoch": 34, "training_loss": 54.26240348815918, "training_acc": 52.5, "val_loss": 13.654139041900635, "val_acc": 55.0}
{"epoch": 35, "training_loss": 53.94599151611328, "training_acc": 52.5, "val_loss": 13.64891529083252, "val_acc": 55.0}
{"epoch": 36, "training_loss": 54.16416645050049, "training_acc": 52.5, "val_loss": 13.651360273361206, "val_acc": 55.0}
{"epoch": 37, "training_loss": 53.99980545043945, "training_acc": 53.75, "val_loss": 13.681938648223877, "val_acc": 55.0}
{"epoch": 38, "training_loss": 53.92832851409912, "training_acc": 57.5, "val_loss": 13.652609586715698, "val_acc": 55.0}
{"epoch": 39, "training_loss": 53.76172161102295, "training_acc": 55.0, "val_loss": 13.627451658248901, "val_acc": 55.0}
{"epoch": 40, "training_loss": 53.86233901977539, "training_acc": 52.5, "val_loss": 13.63695502281189, "val_acc": 55.0}
{"epoch": 41, "training_loss": 53.51008224487305, "training_acc": 55.0, "val_loss": 13.719478845596313, "val_acc": 55.0}
{"epoch": 42, "training_loss": 54.116414070129395, "training_acc": 70.0, "val_loss": 13.733093738555908, "val_acc": 55.0}
{"epoch": 43, "training_loss": 53.75989818572998, "training_acc": 72.5, "val_loss": 13.606719970703125, "val_acc": 55.0}
{"epoch": 44, "training_loss": 53.60775184631348, "training_acc": 55.0, "val_loss": 13.649693727493286, "val_acc": 55.0}
{"epoch": 45, "training_loss": 53.51560306549072, "training_acc": 77.5, "val_loss": 13.659484386444092, "val_acc": 55.0}
{"epoch": 46, "training_loss": 53.5628547668457, "training_acc": 76.25, "val_loss": 13.618358373641968, "val_acc": 55.0}
