"main_optuna_fix_3.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3 --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 55.38796138763428, "training_acc": 53.75, "val_loss": 13.898088932037354, "val_acc": 50.0}
{"epoch": 1, "training_loss": 55.342740058898926, "training_acc": 53.75, "val_loss": 13.934261798858643, "val_acc": 50.0}
{"epoch": 2, "training_loss": 55.176984786987305, "training_acc": 53.75, "val_loss": 13.920644521713257, "val_acc": 50.0}
{"epoch": 3, "training_loss": 55.21289539337158, "training_acc": 53.75, "val_loss": 13.897254467010498, "val_acc": 50.0}
{"epoch": 4, "training_loss": 55.09040451049805, "training_acc": 53.75, "val_loss": 13.895524740219116, "val_acc": 50.0}
{"epoch": 5, "training_loss": 55.1398811340332, "training_acc": 53.75, "val_loss": 13.892616033554077, "val_acc": 50.0}
{"epoch": 6, "training_loss": 55.19196796417236, "training_acc": 53.75, "val_loss": 13.895906209945679, "val_acc": 50.0}
{"epoch": 7, "training_loss": 55.13326835632324, "training_acc": 53.75, "val_loss": 13.913325071334839, "val_acc": 50.0}
{"epoch": 8, "training_loss": 55.17311382293701, "training_acc": 53.75, "val_loss": 13.913511037826538, "val_acc": 50.0}
{"epoch": 9, "training_loss": 55.10799789428711, "training_acc": 53.75, "val_loss": 13.920185565948486, "val_acc": 50.0}
{"epoch": 10, "training_loss": 55.176626205444336, "training_acc": 53.75, "val_loss": 13.936376571655273, "val_acc": 50.0}
{"epoch": 11, "training_loss": 55.001437187194824, "training_acc": 53.75, "val_loss": 13.938809633255005, "val_acc": 50.0}
{"epoch": 12, "training_loss": 55.02208137512207, "training_acc": 53.75, "val_loss": 13.947474956512451, "val_acc": 50.0}
{"epoch": 13, "training_loss": 54.96043014526367, "training_acc": 53.75, "val_loss": 13.968700170516968, "val_acc": 50.0}
{"epoch": 14, "training_loss": 54.927452087402344, "training_acc": 53.75, "val_loss": 14.026985168457031, "val_acc": 50.0}
{"epoch": 15, "training_loss": 54.9129695892334, "training_acc": 53.75, "val_loss": 14.0208899974823, "val_acc": 50.0}
{"epoch": 16, "training_loss": 55.28537845611572, "training_acc": 53.75, "val_loss": 13.937069177627563, "val_acc": 50.0}
{"epoch": 17, "training_loss": 55.04443168640137, "training_acc": 53.75, "val_loss": 13.90446662902832, "val_acc": 50.0}
{"epoch": 18, "training_loss": 55.01386737823486, "training_acc": 53.75, "val_loss": 13.904608488082886, "val_acc": 50.0}
{"epoch": 19, "training_loss": 55.061161041259766, "training_acc": 53.75, "val_loss": 13.911600112915039, "val_acc": 50.0}
{"epoch": 20, "training_loss": 55.08133125305176, "training_acc": 53.75, "val_loss": 13.910356760025024, "val_acc": 50.0}
{"epoch": 21, "training_loss": 55.05064392089844, "training_acc": 53.75, "val_loss": 13.9157235622406, "val_acc": 50.0}
{"epoch": 22, "training_loss": 55.02158737182617, "training_acc": 53.75, "val_loss": 13.929370641708374, "val_acc": 50.0}
{"epoch": 23, "training_loss": 54.98495674133301, "training_acc": 53.75, "val_loss": 13.958754539489746, "val_acc": 50.0}
{"epoch": 24, "training_loss": 54.886531829833984, "training_acc": 53.75, "val_loss": 13.985048532485962, "val_acc": 50.0}
{"epoch": 25, "training_loss": 54.793813705444336, "training_acc": 53.75, "val_loss": 13.994232416152954, "val_acc": 50.0}
{"epoch": 26, "training_loss": 54.95419692993164, "training_acc": 53.75, "val_loss": 13.989429473876953, "val_acc": 50.0}
{"epoch": 27, "training_loss": 54.995338439941406, "training_acc": 53.75, "val_loss": 13.989509344100952, "val_acc": 50.0}
{"epoch": 28, "training_loss": 54.8367805480957, "training_acc": 53.75, "val_loss": 13.987948894500732, "val_acc": 50.0}
{"epoch": 29, "training_loss": 54.635009765625, "training_acc": 53.75, "val_loss": 13.98458480834961, "val_acc": 50.0}
{"epoch": 30, "training_loss": 54.60193920135498, "training_acc": 53.75, "val_loss": 14.06224012374878, "val_acc": 50.0}
{"epoch": 31, "training_loss": 54.642242431640625, "training_acc": 53.75, "val_loss": 14.130053520202637, "val_acc": 50.0}
{"epoch": 32, "training_loss": 54.26605224609375, "training_acc": 53.75, "val_loss": 14.145454168319702, "val_acc": 50.0}
