"main_optuna_fix_3.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3 --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 55.554001808166504, "training_acc": 52.5, "val_loss": 13.812559843063354, "val_acc": 55.0}
{"epoch": 1, "training_loss": 55.34555435180664, "training_acc": 52.5, "val_loss": 13.740248680114746, "val_acc": 55.0}
{"epoch": 2, "training_loss": 55.351786613464355, "training_acc": 52.5, "val_loss": 13.765705823898315, "val_acc": 55.0}
{"epoch": 3, "training_loss": 55.32417106628418, "training_acc": 52.5, "val_loss": 13.75635027885437, "val_acc": 55.0}
{"epoch": 4, "training_loss": 55.308584213256836, "training_acc": 52.5, "val_loss": 13.765419721603394, "val_acc": 55.0}
{"epoch": 5, "training_loss": 55.31760120391846, "training_acc": 52.5, "val_loss": 13.77728819847107, "val_acc": 55.0}
{"epoch": 6, "training_loss": 55.40265083312988, "training_acc": 52.5, "val_loss": 13.771483898162842, "val_acc": 55.0}
{"epoch": 7, "training_loss": 55.269357681274414, "training_acc": 52.5, "val_loss": 13.756569623947144, "val_acc": 55.0}
{"epoch": 8, "training_loss": 55.41561794281006, "training_acc": 52.5, "val_loss": 13.757997751235962, "val_acc": 55.0}
{"epoch": 9, "training_loss": 55.28750991821289, "training_acc": 52.5, "val_loss": 13.772802352905273, "val_acc": 55.0}
{"epoch": 10, "training_loss": 55.32158851623535, "training_acc": 52.5, "val_loss": 13.799407482147217, "val_acc": 55.0}
{"epoch": 11, "training_loss": 55.24164009094238, "training_acc": 52.5, "val_loss": 13.78315806388855, "val_acc": 55.0}
{"epoch": 12, "training_loss": 55.30674076080322, "training_acc": 52.5, "val_loss": 13.777161836624146, "val_acc": 55.0}
{"epoch": 13, "training_loss": 55.11984157562256, "training_acc": 52.5, "val_loss": 13.774291276931763, "val_acc": 55.0}
{"epoch": 14, "training_loss": 55.196311950683594, "training_acc": 52.5, "val_loss": 13.772403001785278, "val_acc": 55.0}
{"epoch": 15, "training_loss": 55.101009368896484, "training_acc": 52.5, "val_loss": 13.74521017074585, "val_acc": 55.0}
{"epoch": 16, "training_loss": 55.1677885055542, "training_acc": 52.5, "val_loss": 13.738329410552979, "val_acc": 55.0}
{"epoch": 17, "training_loss": 55.392730712890625, "training_acc": 52.5, "val_loss": 13.743889331817627, "val_acc": 55.0}
{"epoch": 18, "training_loss": 55.19281482696533, "training_acc": 52.5, "val_loss": 13.734655380249023, "val_acc": 55.0}
{"epoch": 19, "training_loss": 55.09841728210449, "training_acc": 52.5, "val_loss": 13.769528865814209, "val_acc": 55.0}
{"epoch": 20, "training_loss": 55.22908592224121, "training_acc": 52.5, "val_loss": 13.788273334503174, "val_acc": 55.0}
{"epoch": 21, "training_loss": 55.19833755493164, "training_acc": 51.25, "val_loss": 13.74324083328247, "val_acc": 55.0}
{"epoch": 22, "training_loss": 55.06794548034668, "training_acc": 52.5, "val_loss": 13.724849224090576, "val_acc": 55.0}
{"epoch": 23, "training_loss": 55.01422691345215, "training_acc": 52.5, "val_loss": 13.708670139312744, "val_acc": 55.0}
{"epoch": 24, "training_loss": 55.16945171356201, "training_acc": 52.5, "val_loss": 13.708839416503906, "val_acc": 55.0}
{"epoch": 25, "training_loss": 55.12224864959717, "training_acc": 52.5, "val_loss": 13.716259002685547, "val_acc": 55.0}
{"epoch": 26, "training_loss": 55.228872299194336, "training_acc": 52.5, "val_loss": 13.702936172485352, "val_acc": 55.0}
{"epoch": 27, "training_loss": 55.179017066955566, "training_acc": 52.5, "val_loss": 13.683278560638428, "val_acc": 55.0}
{"epoch": 28, "training_loss": 55.0966911315918, "training_acc": 52.5, "val_loss": 13.706212043762207, "val_acc": 55.0}
{"epoch": 29, "training_loss": 55.13856887817383, "training_acc": 52.5, "val_loss": 13.781193494796753, "val_acc": 55.0}
{"epoch": 30, "training_loss": 55.218905448913574, "training_acc": 52.5, "val_loss": 13.782376050949097, "val_acc": 55.0}
{"epoch": 31, "training_loss": 55.27958679199219, "training_acc": 52.5, "val_loss": 13.786495923995972, "val_acc": 55.0}
{"epoch": 32, "training_loss": 55.123456954956055, "training_acc": 52.5, "val_loss": 13.788512945175171, "val_acc": 55.0}
{"epoch": 33, "training_loss": 55.1622200012207, "training_acc": 52.5, "val_loss": 13.797632455825806, "val_acc": 55.0}
{"epoch": 34, "training_loss": 55.135053634643555, "training_acc": 60.0, "val_loss": 13.764982223510742, "val_acc": 55.0}
{"epoch": 35, "training_loss": 54.903106689453125, "training_acc": 53.75, "val_loss": 13.729515075683594, "val_acc": 55.0}
{"epoch": 36, "training_loss": 54.88429546356201, "training_acc": 52.5, "val_loss": 13.717712163925171, "val_acc": 55.0}
{"epoch": 37, "training_loss": 54.946006774902344, "training_acc": 52.5, "val_loss": 13.737881183624268, "val_acc": 55.0}
{"epoch": 38, "training_loss": 54.86997604370117, "training_acc": 60.0, "val_loss": 13.733490705490112, "val_acc": 55.0}
{"epoch": 39, "training_loss": 54.56307792663574, "training_acc": 60.0, "val_loss": 13.7115478515625, "val_acc": 55.0}
{"epoch": 40, "training_loss": 54.81638145446777, "training_acc": 52.5, "val_loss": 13.689826726913452, "val_acc": 55.0}
{"epoch": 41, "training_loss": 54.45607566833496, "training_acc": 52.5, "val_loss": 13.787622451782227, "val_acc": 55.0}
