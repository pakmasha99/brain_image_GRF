"main_optuna_fix_3.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3 --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 55.246849060058594, "training_acc": 53.75, "val_loss": 13.883670568466187, "val_acc": 50.0}
{"epoch": 1, "training_loss": 55.22294807434082, "training_acc": 53.75, "val_loss": 13.89850378036499, "val_acc": 50.0}
{"epoch": 2, "training_loss": 55.230552673339844, "training_acc": 53.75, "val_loss": 13.909435272216797, "val_acc": 50.0}
{"epoch": 3, "training_loss": 55.14649772644043, "training_acc": 53.75, "val_loss": 13.891328573226929, "val_acc": 50.0}
{"epoch": 4, "training_loss": 55.26054000854492, "training_acc": 53.75, "val_loss": 13.876094818115234, "val_acc": 50.0}
{"epoch": 5, "training_loss": 55.21481132507324, "training_acc": 53.75, "val_loss": 13.892321586608887, "val_acc": 50.0}
{"epoch": 6, "training_loss": 55.16344451904297, "training_acc": 53.75, "val_loss": 13.916361331939697, "val_acc": 50.0}
{"epoch": 7, "training_loss": 55.08275508880615, "training_acc": 53.75, "val_loss": 13.943907022476196, "val_acc": 50.0}
{"epoch": 8, "training_loss": 55.116543769836426, "training_acc": 53.75, "val_loss": 13.909143209457397, "val_acc": 50.0}
{"epoch": 9, "training_loss": 54.89873504638672, "training_acc": 53.75, "val_loss": 13.86783480644226, "val_acc": 50.0}
{"epoch": 10, "training_loss": 55.23215866088867, "training_acc": 53.75, "val_loss": 13.868225812911987, "val_acc": 50.0}
{"epoch": 11, "training_loss": 55.126075744628906, "training_acc": 53.75, "val_loss": 13.863486051559448, "val_acc": 50.0}
{"epoch": 12, "training_loss": 55.101200103759766, "training_acc": 53.75, "val_loss": 13.888143301010132, "val_acc": 50.0}
{"epoch": 13, "training_loss": 54.884209632873535, "training_acc": 53.75, "val_loss": 13.952692747116089, "val_acc": 50.0}
{"epoch": 14, "training_loss": 55.142282485961914, "training_acc": 53.75, "val_loss": 14.056637287139893, "val_acc": 50.0}
{"epoch": 15, "training_loss": 55.210561752319336, "training_acc": 53.75, "val_loss": 14.12843942642212, "val_acc": 50.0}
{"epoch": 16, "training_loss": 55.89174461364746, "training_acc": 53.75, "val_loss": 14.087648391723633, "val_acc": 50.0}
{"epoch": 17, "training_loss": 55.33667278289795, "training_acc": 53.75, "val_loss": 13.99544358253479, "val_acc": 50.0}
{"epoch": 18, "training_loss": 55.19443702697754, "training_acc": 53.75, "val_loss": 13.93969178199768, "val_acc": 50.0}
{"epoch": 19, "training_loss": 55.103227615356445, "training_acc": 53.75, "val_loss": 13.897206783294678, "val_acc": 50.0}
{"epoch": 20, "training_loss": 55.1450080871582, "training_acc": 53.75, "val_loss": 13.871344327926636, "val_acc": 50.0}
{"epoch": 21, "training_loss": 55.21687889099121, "training_acc": 53.75, "val_loss": 13.860864639282227, "val_acc": 50.0}
{"epoch": 22, "training_loss": 55.07188892364502, "training_acc": 53.75, "val_loss": 13.937495946884155, "val_acc": 50.0}
{"epoch": 23, "training_loss": 54.97617149353027, "training_acc": 53.75, "val_loss": 14.02274489402771, "val_acc": 50.0}
{"epoch": 24, "training_loss": 55.214691162109375, "training_acc": 53.75, "val_loss": 14.07650113105774, "val_acc": 50.0}
{"epoch": 25, "training_loss": 55.32534599304199, "training_acc": 53.75, "val_loss": 14.086074829101562, "val_acc": 50.0}
{"epoch": 26, "training_loss": 55.4102783203125, "training_acc": 53.75, "val_loss": 14.035228490829468, "val_acc": 50.0}
{"epoch": 27, "training_loss": 55.367286682128906, "training_acc": 53.75, "val_loss": 13.978537321090698, "val_acc": 50.0}
{"epoch": 28, "training_loss": 55.016533851623535, "training_acc": 53.75, "val_loss": 13.919271230697632, "val_acc": 50.0}
{"epoch": 29, "training_loss": 55.18269157409668, "training_acc": 53.75, "val_loss": 13.87874960899353, "val_acc": 50.0}
{"epoch": 30, "training_loss": 55.29220199584961, "training_acc": 53.75, "val_loss": 13.87637734413147, "val_acc": 50.0}
{"epoch": 31, "training_loss": 55.16434669494629, "training_acc": 53.75, "val_loss": 13.892959356307983, "val_acc": 50.0}
{"epoch": 32, "training_loss": 55.102989196777344, "training_acc": 53.75, "val_loss": 13.909395933151245, "val_acc": 50.0}
{"epoch": 33, "training_loss": 55.1309871673584, "training_acc": 53.75, "val_loss": 13.91053557395935, "val_acc": 50.0}
{"epoch": 34, "training_loss": 55.05877685546875, "training_acc": 53.75, "val_loss": 13.905479907989502, "val_acc": 50.0}
{"epoch": 35, "training_loss": 54.96464729309082, "training_acc": 53.75, "val_loss": 13.876278400421143, "val_acc": 50.0}
{"epoch": 36, "training_loss": 54.94509410858154, "training_acc": 53.75, "val_loss": 13.84935736656189, "val_acc": 50.0}
{"epoch": 37, "training_loss": 55.103403091430664, "training_acc": 56.25, "val_loss": 13.870900869369507, "val_acc": 50.0}
{"epoch": 38, "training_loss": 55.40425395965576, "training_acc": 50.0, "val_loss": 13.89022707939148, "val_acc": 50.0}
{"epoch": 39, "training_loss": 55.56207084655762, "training_acc": 47.5, "val_loss": 13.863334655761719, "val_acc": 50.0}
{"epoch": 40, "training_loss": 55.327903747558594, "training_acc": 53.75, "val_loss": 13.863886594772339, "val_acc": 50.0}
