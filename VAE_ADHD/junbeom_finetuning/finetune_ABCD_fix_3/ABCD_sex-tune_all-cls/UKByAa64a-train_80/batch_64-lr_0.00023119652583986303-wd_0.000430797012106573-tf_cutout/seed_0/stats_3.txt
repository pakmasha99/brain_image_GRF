"main_optuna_fix_3.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3 --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 57.403470039367676, "training_acc": 52.5, "val_loss": 13.902342319488525, "val_acc": 55.0}
{"epoch": 1, "training_loss": 61.36467742919922, "training_acc": 45.0, "val_loss": 13.767070770263672, "val_acc": 55.0}
{"epoch": 2, "training_loss": 55.35718059539795, "training_acc": 52.5, "val_loss": 14.155077934265137, "val_acc": 55.0}
{"epoch": 3, "training_loss": 57.20712661743164, "training_acc": 52.5, "val_loss": 14.276667833328247, "val_acc": 55.0}
{"epoch": 4, "training_loss": 55.801170349121094, "training_acc": 52.5, "val_loss": 14.475287199020386, "val_acc": 55.0}
{"epoch": 5, "training_loss": 58.999366760253906, "training_acc": 52.5, "val_loss": 13.765891790390015, "val_acc": 55.0}
{"epoch": 6, "training_loss": 55.5239143371582, "training_acc": 50.0, "val_loss": 13.80915641784668, "val_acc": 55.0}
{"epoch": 7, "training_loss": 55.374860763549805, "training_acc": 52.5, "val_loss": 13.762695789337158, "val_acc": 55.0}
{"epoch": 8, "training_loss": 55.43603324890137, "training_acc": 52.5, "val_loss": 13.916972875595093, "val_acc": 55.0}
{"epoch": 9, "training_loss": 55.6228084564209, "training_acc": 47.5, "val_loss": 14.14095163345337, "val_acc": 55.0}
{"epoch": 10, "training_loss": 56.00239086151123, "training_acc": 47.5, "val_loss": 13.823254108428955, "val_acc": 55.0}
{"epoch": 11, "training_loss": 55.206740379333496, "training_acc": 52.5, "val_loss": 13.78476619720459, "val_acc": 55.0}
{"epoch": 12, "training_loss": 55.896257400512695, "training_acc": 52.5, "val_loss": 13.784515857696533, "val_acc": 55.0}
{"epoch": 13, "training_loss": 55.70621871948242, "training_acc": 52.5, "val_loss": 13.775614500045776, "val_acc": 55.0}
{"epoch": 14, "training_loss": 55.31251335144043, "training_acc": 52.5, "val_loss": 13.861554861068726, "val_acc": 55.0}
{"epoch": 15, "training_loss": 55.73224639892578, "training_acc": 48.75, "val_loss": 13.862696886062622, "val_acc": 55.0}
{"epoch": 16, "training_loss": 55.2501106262207, "training_acc": 57.5, "val_loss": 13.762967586517334, "val_acc": 55.0}
{"epoch": 17, "training_loss": 55.678260803222656, "training_acc": 52.5, "val_loss": 13.78607988357544, "val_acc": 55.0}
{"epoch": 18, "training_loss": 55.67067909240723, "training_acc": 52.5, "val_loss": 13.806660175323486, "val_acc": 55.0}
{"epoch": 19, "training_loss": 55.2210807800293, "training_acc": 55.0, "val_loss": 14.511469602584839, "val_acc": 55.0}
{"epoch": 20, "training_loss": 56.8926420211792, "training_acc": 47.5, "val_loss": 13.811078071594238, "val_acc": 55.0}
{"epoch": 21, "training_loss": 55.429054260253906, "training_acc": 52.5, "val_loss": 13.764889240264893, "val_acc": 55.0}
{"epoch": 22, "training_loss": 55.47512245178223, "training_acc": 52.5, "val_loss": 13.762905597686768, "val_acc": 55.0}
{"epoch": 23, "training_loss": 55.46040344238281, "training_acc": 52.5, "val_loss": 13.763269186019897, "val_acc": 55.0}
{"epoch": 24, "training_loss": 55.51557922363281, "training_acc": 52.5, "val_loss": 13.76153826713562, "val_acc": 55.0}
{"epoch": 25, "training_loss": 55.38391590118408, "training_acc": 52.5, "val_loss": 13.781906366348267, "val_acc": 55.0}
{"epoch": 26, "training_loss": 55.68431091308594, "training_acc": 52.5, "val_loss": 13.840639591217041, "val_acc": 55.0}
{"epoch": 27, "training_loss": 56.05937957763672, "training_acc": 52.5, "val_loss": 13.828668594360352, "val_acc": 55.0}
{"epoch": 28, "training_loss": 55.93758487701416, "training_acc": 52.5, "val_loss": 13.766449689865112, "val_acc": 55.0}
{"epoch": 29, "training_loss": 55.53849792480469, "training_acc": 52.5, "val_loss": 13.792651891708374, "val_acc": 55.0}
{"epoch": 30, "training_loss": 55.336533546447754, "training_acc": 52.5, "val_loss": 13.848612308502197, "val_acc": 55.0}
{"epoch": 31, "training_loss": 55.40388870239258, "training_acc": 52.5, "val_loss": 13.91655683517456, "val_acc": 55.0}
{"epoch": 32, "training_loss": 55.577298164367676, "training_acc": 47.5, "val_loss": 13.983957767486572, "val_acc": 55.0}
{"epoch": 33, "training_loss": 55.7410888671875, "training_acc": 47.5, "val_loss": 13.930124044418335, "val_acc": 55.0}
