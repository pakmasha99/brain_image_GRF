"main_optuna_fix_3.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3 --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 58.479281425476074, "training_acc": 52.5, "val_loss": 13.710649013519287, "val_acc": 55.0}
{"epoch": 1, "training_loss": 56.77071189880371, "training_acc": 45.0, "val_loss": 62.677016258239746, "val_acc": 55.0}
{"epoch": 2, "training_loss": 223.82645225524902, "training_acc": 52.5, "val_loss": 15.441654920578003, "val_acc": 45.0}
{"epoch": 3, "training_loss": 59.85662841796875, "training_acc": 47.5, "val_loss": 13.777410984039307, "val_acc": 55.0}
{"epoch": 4, "training_loss": 55.60653591156006, "training_acc": 52.5, "val_loss": 13.772811889648438, "val_acc": 55.0}
{"epoch": 5, "training_loss": 55.34092712402344, "training_acc": 52.5, "val_loss": 14.094491004943848, "val_acc": 55.0}
{"epoch": 6, "training_loss": 55.22168254852295, "training_acc": 57.5, "val_loss": 15.300970077514648, "val_acc": 55.0}
{"epoch": 7, "training_loss": 61.766584396362305, "training_acc": 52.5, "val_loss": 13.815969228744507, "val_acc": 55.0}
{"epoch": 8, "training_loss": 55.311851501464844, "training_acc": 52.5, "val_loss": 14.446436166763306, "val_acc": 55.0}
{"epoch": 9, "training_loss": 57.14002799987793, "training_acc": 47.5, "val_loss": 14.165525436401367, "val_acc": 55.0}
{"epoch": 10, "training_loss": 56.0246639251709, "training_acc": 47.5, "val_loss": 13.767329454421997, "val_acc": 55.0}
{"epoch": 11, "training_loss": 55.28643226623535, "training_acc": 52.5, "val_loss": 13.92516016960144, "val_acc": 55.0}
{"epoch": 12, "training_loss": 56.52129936218262, "training_acc": 52.5, "val_loss": 13.805216550827026, "val_acc": 55.0}
{"epoch": 13, "training_loss": 55.62161445617676, "training_acc": 52.5, "val_loss": 13.890280723571777, "val_acc": 55.0}
{"epoch": 14, "training_loss": 55.538899421691895, "training_acc": 47.5, "val_loss": 14.047880172729492, "val_acc": 55.0}
{"epoch": 15, "training_loss": 55.926435470581055, "training_acc": 47.5, "val_loss": 13.813059329986572, "val_acc": 55.0}
{"epoch": 16, "training_loss": 55.08488655090332, "training_acc": 52.5, "val_loss": 13.839529752731323, "val_acc": 55.0}
{"epoch": 17, "training_loss": 56.35869216918945, "training_acc": 52.5, "val_loss": 13.857402801513672, "val_acc": 55.0}
{"epoch": 18, "training_loss": 55.9810905456543, "training_acc": 52.5, "val_loss": 13.792498111724854, "val_acc": 55.0}
{"epoch": 19, "training_loss": 55.22075939178467, "training_acc": 52.5, "val_loss": 14.10534143447876, "val_acc": 55.0}
{"epoch": 20, "training_loss": 56.11078357696533, "training_acc": 47.5, "val_loss": 13.984378576278687, "val_acc": 55.0}
{"epoch": 21, "training_loss": 55.61866855621338, "training_acc": 50.0, "val_loss": 13.783069849014282, "val_acc": 55.0}
{"epoch": 22, "training_loss": 55.314388275146484, "training_acc": 52.5, "val_loss": 13.76526951789856, "val_acc": 55.0}
{"epoch": 23, "training_loss": 55.5119514465332, "training_acc": 52.5, "val_loss": 13.774605989456177, "val_acc": 55.0}
{"epoch": 24, "training_loss": 55.687137603759766, "training_acc": 52.5, "val_loss": 13.77596139907837, "val_acc": 55.0}
{"epoch": 25, "training_loss": 55.62258434295654, "training_acc": 52.5, "val_loss": 13.778156042098999, "val_acc": 55.0}
{"epoch": 26, "training_loss": 55.7394323348999, "training_acc": 52.5, "val_loss": 13.771322965621948, "val_acc": 55.0}
{"epoch": 27, "training_loss": 55.599249839782715, "training_acc": 52.5, "val_loss": 13.769499063491821, "val_acc": 55.0}
{"epoch": 28, "training_loss": 55.596604347229004, "training_acc": 52.5, "val_loss": 13.764995336532593, "val_acc": 55.0}
