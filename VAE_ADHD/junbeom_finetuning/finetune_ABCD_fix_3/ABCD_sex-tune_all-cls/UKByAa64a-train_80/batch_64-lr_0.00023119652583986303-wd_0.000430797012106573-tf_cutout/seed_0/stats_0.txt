"main_optuna_fix_3.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3 --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 58.82046413421631, "training_acc": 41.25, "val_loss": 13.884719610214233, "val_acc": 50.0}
{"epoch": 1, "training_loss": 93.08301162719727, "training_acc": 43.75, "val_loss": 13.921114206314087, "val_acc": 50.0}
{"epoch": 2, "training_loss": 56.61369323730469, "training_acc": 46.25, "val_loss": 14.32395339012146, "val_acc": 50.0}
{"epoch": 3, "training_loss": 56.1602840423584, "training_acc": 53.75, "val_loss": 13.992304801940918, "val_acc": 50.0}
{"epoch": 4, "training_loss": 56.08748435974121, "training_acc": 53.75, "val_loss": 40.99132537841797, "val_acc": 50.0}
{"epoch": 5, "training_loss": 130.6331615447998, "training_acc": 56.25, "val_loss": 15.034083127975464, "val_acc": 50.0}
{"epoch": 6, "training_loss": 60.735965728759766, "training_acc": 46.25, "val_loss": 14.831044673919678, "val_acc": 50.0}
{"epoch": 7, "training_loss": 58.15484428405762, "training_acc": 53.75, "val_loss": 13.918708562850952, "val_acc": 50.0}
{"epoch": 8, "training_loss": 55.361494064331055, "training_acc": 53.75, "val_loss": 14.332720041275024, "val_acc": 50.0}
{"epoch": 9, "training_loss": 58.20567798614502, "training_acc": 46.25, "val_loss": 13.889448642730713, "val_acc": 50.0}
{"epoch": 10, "training_loss": 55.19450759887695, "training_acc": 53.75, "val_loss": 14.401968717575073, "val_acc": 50.0}
{"epoch": 11, "training_loss": 56.309579849243164, "training_acc": 53.75, "val_loss": 14.190034866333008, "val_acc": 50.0}
{"epoch": 12, "training_loss": 55.80974578857422, "training_acc": 53.75, "val_loss": 13.975881338119507, "val_acc": 50.0}
{"epoch": 13, "training_loss": 55.47348499298096, "training_acc": 53.75, "val_loss": 13.993520736694336, "val_acc": 50.0}
{"epoch": 14, "training_loss": 55.265987396240234, "training_acc": 53.75, "val_loss": 14.29036259651184, "val_acc": 50.0}
{"epoch": 15, "training_loss": 55.92703056335449, "training_acc": 53.75, "val_loss": 14.58964228630066, "val_acc": 50.0}
{"epoch": 16, "training_loss": 56.760581970214844, "training_acc": 53.75, "val_loss": 14.3156898021698, "val_acc": 50.0}
{"epoch": 17, "training_loss": 55.85507583618164, "training_acc": 53.75, "val_loss": 13.973662853240967, "val_acc": 50.0}
{"epoch": 18, "training_loss": 55.45247173309326, "training_acc": 53.75, "val_loss": 13.871524333953857, "val_acc": 50.0}
{"epoch": 19, "training_loss": 55.3845272064209, "training_acc": 53.75, "val_loss": 13.874293565750122, "val_acc": 50.0}
{"epoch": 20, "training_loss": 55.50338554382324, "training_acc": 46.25, "val_loss": 13.918355703353882, "val_acc": 50.0}
{"epoch": 21, "training_loss": 56.03874206542969, "training_acc": 46.25, "val_loss": 13.892126083374023, "val_acc": 50.0}
{"epoch": 22, "training_loss": 55.524986267089844, "training_acc": 46.25, "val_loss": 13.902153968811035, "val_acc": 50.0}
{"epoch": 23, "training_loss": 55.283090591430664, "training_acc": 53.75, "val_loss": 14.077434539794922, "val_acc": 50.0}
{"epoch": 24, "training_loss": 55.458680152893066, "training_acc": 53.75, "val_loss": 14.135197401046753, "val_acc": 50.0}
{"epoch": 25, "training_loss": 55.51918411254883, "training_acc": 53.75, "val_loss": 14.037526845932007, "val_acc": 50.0}
{"epoch": 26, "training_loss": 55.35682487487793, "training_acc": 53.75, "val_loss": 13.935558795928955, "val_acc": 50.0}
{"epoch": 27, "training_loss": 55.29839324951172, "training_acc": 53.75, "val_loss": 13.902726173400879, "val_acc": 50.0}
{"epoch": 28, "training_loss": 55.24336910247803, "training_acc": 53.75, "val_loss": 13.897379636764526, "val_acc": 50.0}
{"epoch": 29, "training_loss": 55.22304725646973, "training_acc": 53.75, "val_loss": 13.886332511901855, "val_acc": 50.0}
{"epoch": 30, "training_loss": 55.249985694885254, "training_acc": 53.75, "val_loss": 13.90093207359314, "val_acc": 50.0}
{"epoch": 31, "training_loss": 55.233680725097656, "training_acc": 53.75, "val_loss": 13.925646543502808, "val_acc": 50.0}
{"epoch": 32, "training_loss": 55.18236446380615, "training_acc": 53.75, "val_loss": 13.930083513259888, "val_acc": 50.0}
{"epoch": 33, "training_loss": 55.21245765686035, "training_acc": 53.75, "val_loss": 13.937238454818726, "val_acc": 50.0}
