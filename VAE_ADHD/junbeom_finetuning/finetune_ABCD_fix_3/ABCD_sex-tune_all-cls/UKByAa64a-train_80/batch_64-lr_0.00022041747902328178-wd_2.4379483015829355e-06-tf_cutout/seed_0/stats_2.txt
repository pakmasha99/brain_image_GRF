"main_optuna_fix_3.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3 --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 58.19829559326172, "training_acc": 41.25, "val_loss": 14.073036909103394, "val_acc": 55.0}
{"epoch": 1, "training_loss": 59.735915184020996, "training_acc": 45.0, "val_loss": 14.135586023330688, "val_acc": 55.0}
{"epoch": 2, "training_loss": 55.846900939941406, "training_acc": 50.0, "val_loss": 15.166858434677124, "val_acc": 45.0}
{"epoch": 3, "training_loss": 59.864030838012695, "training_acc": 50.0, "val_loss": 13.872195482254028, "val_acc": 55.0}
{"epoch": 4, "training_loss": 55.85311508178711, "training_acc": 52.5, "val_loss": 14.258335828781128, "val_acc": 55.0}
{"epoch": 5, "training_loss": 56.430227279663086, "training_acc": 47.5, "val_loss": 13.757482767105103, "val_acc": 55.0}
{"epoch": 6, "training_loss": 56.50160789489746, "training_acc": 42.5, "val_loss": 13.869155645370483, "val_acc": 55.0}
{"epoch": 7, "training_loss": 56.284067153930664, "training_acc": 52.5, "val_loss": 13.901523351669312, "val_acc": 55.0}
{"epoch": 8, "training_loss": 55.9481315612793, "training_acc": 52.5, "val_loss": 13.869848251342773, "val_acc": 55.0}
{"epoch": 9, "training_loss": 55.32705879211426, "training_acc": 51.25, "val_loss": 14.354337453842163, "val_acc": 55.0}
{"epoch": 10, "training_loss": 56.80766201019287, "training_acc": 47.5, "val_loss": 14.054937362670898, "val_acc": 55.0}
{"epoch": 11, "training_loss": 55.599711418151855, "training_acc": 52.5, "val_loss": 13.785980939865112, "val_acc": 55.0}
{"epoch": 12, "training_loss": 55.7935791015625, "training_acc": 52.5, "val_loss": 13.851648569107056, "val_acc": 55.0}
{"epoch": 13, "training_loss": 55.93170928955078, "training_acc": 52.5, "val_loss": 13.769664764404297, "val_acc": 55.0}
{"epoch": 14, "training_loss": 55.34639930725098, "training_acc": 52.5, "val_loss": 13.874951601028442, "val_acc": 55.0}
{"epoch": 15, "training_loss": 55.777116775512695, "training_acc": 45.0, "val_loss": 13.824368715286255, "val_acc": 55.0}
{"epoch": 16, "training_loss": 55.20490837097168, "training_acc": 52.5, "val_loss": 13.770748376846313, "val_acc": 55.0}
{"epoch": 17, "training_loss": 55.74493408203125, "training_acc": 52.5, "val_loss": 13.797016143798828, "val_acc": 55.0}
{"epoch": 18, "training_loss": 55.75043487548828, "training_acc": 52.5, "val_loss": 13.764573335647583, "val_acc": 55.0}
{"epoch": 19, "training_loss": 55.33289337158203, "training_acc": 52.5, "val_loss": 13.829747438430786, "val_acc": 55.0}
{"epoch": 20, "training_loss": 55.458754539489746, "training_acc": 50.0, "val_loss": 13.922297954559326, "val_acc": 55.0}
{"epoch": 21, "training_loss": 55.57184314727783, "training_acc": 47.5, "val_loss": 13.862121105194092, "val_acc": 55.0}
{"epoch": 22, "training_loss": 55.39875030517578, "training_acc": 63.75, "val_loss": 13.778280019760132, "val_acc": 55.0}
{"epoch": 23, "training_loss": 55.315080642700195, "training_acc": 52.5, "val_loss": 13.763991594314575, "val_acc": 55.0}
{"epoch": 24, "training_loss": 55.491257667541504, "training_acc": 52.5, "val_loss": 13.792232275009155, "val_acc": 55.0}
