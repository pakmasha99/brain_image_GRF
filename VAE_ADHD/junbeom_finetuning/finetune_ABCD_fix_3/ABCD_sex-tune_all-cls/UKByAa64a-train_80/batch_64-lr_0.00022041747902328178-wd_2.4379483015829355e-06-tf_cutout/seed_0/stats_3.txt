"main_optuna_fix_3.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3 --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 57.964776039123535, "training_acc": 43.75, "val_loss": 13.847531080245972, "val_acc": 55.0}
{"epoch": 1, "training_loss": 58.537715911865234, "training_acc": 45.0, "val_loss": 22.345964908599854, "val_acc": 55.0}
{"epoch": 2, "training_loss": 87.71374702453613, "training_acc": 52.5, "val_loss": 14.189032316207886, "val_acc": 55.0}
{"epoch": 3, "training_loss": 56.17277240753174, "training_acc": 48.75, "val_loss": 14.197157621383667, "val_acc": 55.0}
{"epoch": 4, "training_loss": 55.310248374938965, "training_acc": 52.5, "val_loss": 14.04637336730957, "val_acc": 55.0}
{"epoch": 5, "training_loss": 66.01546859741211, "training_acc": 50.0, "val_loss": 13.870985507965088, "val_acc": 55.0}
{"epoch": 6, "training_loss": 56.36084747314453, "training_acc": 52.5, "val_loss": 13.769115209579468, "val_acc": 55.0}
{"epoch": 7, "training_loss": 55.51004219055176, "training_acc": 52.5, "val_loss": 14.017305374145508, "val_acc": 55.0}
{"epoch": 8, "training_loss": 55.99612617492676, "training_acc": 47.5, "val_loss": 14.07785177230835, "val_acc": 55.0}
{"epoch": 9, "training_loss": 56.00071430206299, "training_acc": 47.5, "val_loss": 13.93638014793396, "val_acc": 55.0}
{"epoch": 10, "training_loss": 55.41587829589844, "training_acc": 52.5, "val_loss": 13.776414394378662, "val_acc": 55.0}
{"epoch": 11, "training_loss": 55.59947490692139, "training_acc": 52.5, "val_loss": 13.99393916130066, "val_acc": 55.0}
{"epoch": 12, "training_loss": 56.9167537689209, "training_acc": 52.5, "val_loss": 13.774875402450562, "val_acc": 55.0}
{"epoch": 13, "training_loss": 55.71629333496094, "training_acc": 52.5, "val_loss": 13.912267684936523, "val_acc": 55.0}
{"epoch": 14, "training_loss": 55.5336217880249, "training_acc": 47.5, "val_loss": 14.033035039901733, "val_acc": 55.0}
{"epoch": 15, "training_loss": 55.980467796325684, "training_acc": 47.5, "val_loss": 13.881313800811768, "val_acc": 55.0}
{"epoch": 16, "training_loss": 55.16182231903076, "training_acc": 57.5, "val_loss": 13.76421332359314, "val_acc": 55.0}
{"epoch": 17, "training_loss": 55.79933738708496, "training_acc": 52.5, "val_loss": 13.832865953445435, "val_acc": 55.0}
{"epoch": 18, "training_loss": 56.00338935852051, "training_acc": 52.5, "val_loss": 13.764359951019287, "val_acc": 55.0}
{"epoch": 19, "training_loss": 55.339619636535645, "training_acc": 52.5, "val_loss": 13.895418643951416, "val_acc": 55.0}
{"epoch": 20, "training_loss": 55.65633201599121, "training_acc": 47.5, "val_loss": 14.055894613265991, "val_acc": 55.0}
{"epoch": 21, "training_loss": 55.911681175231934, "training_acc": 47.5, "val_loss": 13.876765966415405, "val_acc": 55.0}
{"epoch": 22, "training_loss": 55.40158271789551, "training_acc": 50.0, "val_loss": 13.76731276512146, "val_acc": 55.0}
{"epoch": 23, "training_loss": 55.3337287902832, "training_acc": 52.5, "val_loss": 13.775348663330078, "val_acc": 55.0}
{"epoch": 24, "training_loss": 55.65560722351074, "training_acc": 52.5, "val_loss": 13.803730010986328, "val_acc": 55.0}
{"epoch": 25, "training_loss": 55.836151123046875, "training_acc": 52.5, "val_loss": 13.852629661560059, "val_acc": 55.0}
{"epoch": 26, "training_loss": 56.173001289367676, "training_acc": 52.5, "val_loss": 13.861044645309448, "val_acc": 55.0}
{"epoch": 27, "training_loss": 56.15582275390625, "training_acc": 52.5, "val_loss": 13.79193663597107, "val_acc": 55.0}
