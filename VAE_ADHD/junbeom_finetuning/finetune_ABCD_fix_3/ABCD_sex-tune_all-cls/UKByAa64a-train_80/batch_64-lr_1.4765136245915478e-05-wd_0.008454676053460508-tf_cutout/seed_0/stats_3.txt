"main_optuna_fix_3.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3 --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 56.174156188964844, "training_acc": 43.75, "val_loss": 13.892378807067871, "val_acc": 55.0}
{"epoch": 1, "training_loss": 55.65589714050293, "training_acc": 48.75, "val_loss": 13.812410831451416, "val_acc": 55.0}
{"epoch": 2, "training_loss": 55.323533058166504, "training_acc": 53.75, "val_loss": 13.767268657684326, "val_acc": 55.0}
{"epoch": 3, "training_loss": 55.326619148254395, "training_acc": 52.5, "val_loss": 13.777786493301392, "val_acc": 55.0}
{"epoch": 4, "training_loss": 55.42288780212402, "training_acc": 52.5, "val_loss": 13.758885860443115, "val_acc": 55.0}
{"epoch": 5, "training_loss": 55.409531593322754, "training_acc": 52.5, "val_loss": 13.760956525802612, "val_acc": 55.0}
{"epoch": 6, "training_loss": 55.20194625854492, "training_acc": 52.5, "val_loss": 13.744992017745972, "val_acc": 55.0}
{"epoch": 7, "training_loss": 54.985816955566406, "training_acc": 52.5, "val_loss": 13.75877857208252, "val_acc": 55.0}
{"epoch": 8, "training_loss": 55.04467010498047, "training_acc": 53.75, "val_loss": 13.861459493637085, "val_acc": 55.0}
{"epoch": 9, "training_loss": 55.327640533447266, "training_acc": 51.25, "val_loss": 13.962934017181396, "val_acc": 55.0}
{"epoch": 10, "training_loss": 55.595746994018555, "training_acc": 47.5, "val_loss": 13.772281408309937, "val_acc": 55.0}
{"epoch": 11, "training_loss": 55.00648498535156, "training_acc": 57.5, "val_loss": 13.746001720428467, "val_acc": 55.0}
{"epoch": 12, "training_loss": 55.4992094039917, "training_acc": 52.5, "val_loss": 13.788803815841675, "val_acc": 55.0}
{"epoch": 13, "training_loss": 55.0783052444458, "training_acc": 52.5, "val_loss": 13.710771799087524, "val_acc": 55.0}
{"epoch": 14, "training_loss": 55.106021881103516, "training_acc": 52.5, "val_loss": 13.70440125465393, "val_acc": 55.0}
{"epoch": 15, "training_loss": 55.10617256164551, "training_acc": 52.5, "val_loss": 13.757909536361694, "val_acc": 55.0}
{"epoch": 16, "training_loss": 55.12063503265381, "training_acc": 51.25, "val_loss": 13.72715950012207, "val_acc": 55.0}
{"epoch": 17, "training_loss": 55.076826095581055, "training_acc": 52.5, "val_loss": 13.712911605834961, "val_acc": 55.0}
{"epoch": 18, "training_loss": 54.849016189575195, "training_acc": 52.5, "val_loss": 13.70721697807312, "val_acc": 55.0}
{"epoch": 19, "training_loss": 54.70223045349121, "training_acc": 52.5, "val_loss": 13.703311681747437, "val_acc": 55.0}
{"epoch": 20, "training_loss": 54.79634475708008, "training_acc": 58.75, "val_loss": 13.739267587661743, "val_acc": 55.0}
{"epoch": 21, "training_loss": 54.96517467498779, "training_acc": 51.25, "val_loss": 13.744035959243774, "val_acc": 55.0}
{"epoch": 22, "training_loss": 54.80230712890625, "training_acc": 53.75, "val_loss": 13.709793090820312, "val_acc": 55.0}
{"epoch": 23, "training_loss": 54.52968978881836, "training_acc": 55.0, "val_loss": 13.686199188232422, "val_acc": 55.0}
{"epoch": 24, "training_loss": 54.596710205078125, "training_acc": 52.5, "val_loss": 13.745182752609253, "val_acc": 55.0}
{"epoch": 25, "training_loss": 54.19638442993164, "training_acc": 52.5, "val_loss": 13.946086168289185, "val_acc": 55.0}
{"epoch": 26, "training_loss": 55.651183128356934, "training_acc": 52.5, "val_loss": 13.950904607772827, "val_acc": 55.0}
{"epoch": 27, "training_loss": 54.81229209899902, "training_acc": 52.5, "val_loss": 13.6959707736969, "val_acc": 55.0}
{"epoch": 28, "training_loss": 54.50226879119873, "training_acc": 52.5, "val_loss": 13.733377456665039, "val_acc": 55.0}
