"main_optuna_fix_3.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3 --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 55.4964656829834, "training_acc": 51.25, "val_loss": 13.778246641159058, "val_acc": 55.0}
{"epoch": 1, "training_loss": 55.68114185333252, "training_acc": 51.25, "val_loss": 13.75101923942566, "val_acc": 55.0}
{"epoch": 2, "training_loss": 55.26348686218262, "training_acc": 52.5, "val_loss": 13.761147260665894, "val_acc": 55.0}
{"epoch": 3, "training_loss": 55.91682434082031, "training_acc": 52.5, "val_loss": 13.788708448410034, "val_acc": 55.0}
{"epoch": 4, "training_loss": 55.71445941925049, "training_acc": 52.5, "val_loss": 13.734743595123291, "val_acc": 55.0}
{"epoch": 5, "training_loss": 55.11756706237793, "training_acc": 52.5, "val_loss": 13.742774724960327, "val_acc": 55.0}
{"epoch": 6, "training_loss": 55.09269905090332, "training_acc": 52.5, "val_loss": 13.777910470962524, "val_acc": 55.0}
{"epoch": 7, "training_loss": 55.10964584350586, "training_acc": 52.5, "val_loss": 13.792718648910522, "val_acc": 55.0}
{"epoch": 8, "training_loss": 55.086381912231445, "training_acc": 52.5, "val_loss": 13.808348178863525, "val_acc": 55.0}
{"epoch": 9, "training_loss": 55.1342887878418, "training_acc": 60.0, "val_loss": 13.807529211044312, "val_acc": 55.0}
{"epoch": 10, "training_loss": 54.98636817932129, "training_acc": 68.75, "val_loss": 13.757274150848389, "val_acc": 55.0}
{"epoch": 11, "training_loss": 54.8387565612793, "training_acc": 53.75, "val_loss": 13.729168176651001, "val_acc": 55.0}
{"epoch": 12, "training_loss": 54.98007106781006, "training_acc": 52.5, "val_loss": 13.737883567810059, "val_acc": 55.0}
{"epoch": 13, "training_loss": 55.0882511138916, "training_acc": 52.5, "val_loss": 13.744077682495117, "val_acc": 55.0}
{"epoch": 14, "training_loss": 54.88104248046875, "training_acc": 52.5, "val_loss": 13.731743097305298, "val_acc": 55.0}
{"epoch": 15, "training_loss": 54.82887649536133, "training_acc": 52.5, "val_loss": 13.729696273803711, "val_acc": 55.0}
{"epoch": 16, "training_loss": 54.90197944641113, "training_acc": 52.5, "val_loss": 13.721790313720703, "val_acc": 55.0}
{"epoch": 17, "training_loss": 54.45186805725098, "training_acc": 52.5, "val_loss": 13.697296380996704, "val_acc": 55.0}
{"epoch": 18, "training_loss": 54.39595603942871, "training_acc": 52.5, "val_loss": 13.661235570907593, "val_acc": 55.0}
{"epoch": 19, "training_loss": 54.021562576293945, "training_acc": 53.75, "val_loss": 13.720699548721313, "val_acc": 55.0}
{"epoch": 20, "training_loss": 54.36421489715576, "training_acc": 71.25, "val_loss": 13.749076128005981, "val_acc": 55.0}
{"epoch": 21, "training_loss": 54.00214385986328, "training_acc": 67.5, "val_loss": 13.621155023574829, "val_acc": 55.0}
{"epoch": 22, "training_loss": 53.62183952331543, "training_acc": 57.5, "val_loss": 13.642863035202026, "val_acc": 55.0}
{"epoch": 23, "training_loss": 53.82784461975098, "training_acc": 57.5, "val_loss": 13.648000955581665, "val_acc": 55.0}
