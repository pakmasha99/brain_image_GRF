"main_optuna_fix_3.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3 --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 55.67639350891113, "training_acc": 41.25, "val_loss": 13.83435606956482, "val_acc": 55.0}
{"epoch": 1, "training_loss": 55.778573989868164, "training_acc": 38.75, "val_loss": 13.829851150512695, "val_acc": 55.0}
{"epoch": 2, "training_loss": 55.29597473144531, "training_acc": 52.5, "val_loss": 13.794406652450562, "val_acc": 55.0}
{"epoch": 3, "training_loss": 55.398834228515625, "training_acc": 52.5, "val_loss": 13.7697434425354, "val_acc": 55.0}
{"epoch": 4, "training_loss": 55.50520133972168, "training_acc": 52.5, "val_loss": 13.768513202667236, "val_acc": 55.0}
{"epoch": 5, "training_loss": 55.51898956298828, "training_acc": 52.5, "val_loss": 13.755110502243042, "val_acc": 55.0}
{"epoch": 6, "training_loss": 55.50214862823486, "training_acc": 52.5, "val_loss": 13.779438734054565, "val_acc": 55.0}
{"epoch": 7, "training_loss": 55.23028755187988, "training_acc": 52.5, "val_loss": 13.79817247390747, "val_acc": 55.0}
{"epoch": 8, "training_loss": 55.47477436065674, "training_acc": 52.5, "val_loss": 13.783515691757202, "val_acc": 55.0}
{"epoch": 9, "training_loss": 55.22689628601074, "training_acc": 52.5, "val_loss": 13.766987323760986, "val_acc": 55.0}
{"epoch": 10, "training_loss": 55.32108116149902, "training_acc": 52.5, "val_loss": 13.82022738456726, "val_acc": 55.0}
{"epoch": 11, "training_loss": 55.38705062866211, "training_acc": 57.5, "val_loss": 13.84363055229187, "val_acc": 55.0}
{"epoch": 12, "training_loss": 55.22566032409668, "training_acc": 51.25, "val_loss": 13.789209127426147, "val_acc": 55.0}
{"epoch": 13, "training_loss": 54.98559379577637, "training_acc": 67.5, "val_loss": 13.743070363998413, "val_acc": 55.0}
{"epoch": 14, "training_loss": 55.017767906188965, "training_acc": 55.0, "val_loss": 13.711957931518555, "val_acc": 55.0}
{"epoch": 15, "training_loss": 54.66107940673828, "training_acc": 53.75, "val_loss": 13.692419528961182, "val_acc": 55.0}
{"epoch": 16, "training_loss": 55.1114616394043, "training_acc": 52.5, "val_loss": 13.717435598373413, "val_acc": 55.0}
{"epoch": 17, "training_loss": 55.48098087310791, "training_acc": 52.5, "val_loss": 13.738181591033936, "val_acc": 55.0}
{"epoch": 18, "training_loss": 55.07622146606445, "training_acc": 52.5, "val_loss": 13.679741621017456, "val_acc": 55.0}
{"epoch": 19, "training_loss": 54.576422691345215, "training_acc": 52.5, "val_loss": 13.689950704574585, "val_acc": 55.0}
{"epoch": 20, "training_loss": 54.936686515808105, "training_acc": 57.5, "val_loss": 13.767112493515015, "val_acc": 55.0}
{"epoch": 21, "training_loss": 54.94515800476074, "training_acc": 58.75, "val_loss": 13.785730600357056, "val_acc": 55.0}
{"epoch": 22, "training_loss": 54.81654739379883, "training_acc": 72.5, "val_loss": 13.739192485809326, "val_acc": 55.0}
{"epoch": 23, "training_loss": 54.438499450683594, "training_acc": 68.75, "val_loss": 13.66654634475708, "val_acc": 55.0}
{"epoch": 24, "training_loss": 54.37441444396973, "training_acc": 52.5, "val_loss": 13.649002313613892, "val_acc": 55.0}
{"epoch": 25, "training_loss": 54.574951171875, "training_acc": 52.5, "val_loss": 13.737356662750244, "val_acc": 55.0}
{"epoch": 26, "training_loss": 55.29904747009277, "training_acc": 52.5, "val_loss": 13.776147365570068, "val_acc": 55.0}
{"epoch": 27, "training_loss": 55.01064872741699, "training_acc": 52.5, "val_loss": 13.732572793960571, "val_acc": 55.0}
{"epoch": 28, "training_loss": 55.078407287597656, "training_acc": 52.5, "val_loss": 13.655856847763062, "val_acc": 55.0}
{"epoch": 29, "training_loss": 54.285404205322266, "training_acc": 53.75, "val_loss": 13.81862759590149, "val_acc": 55.0}
{"epoch": 30, "training_loss": 54.41861915588379, "training_acc": 57.5, "val_loss": 13.845993280410767, "val_acc": 55.0}
{"epoch": 31, "training_loss": 54.77169227600098, "training_acc": 55.0, "val_loss": 13.759058713912964, "val_acc": 55.0}
{"epoch": 32, "training_loss": 54.01460933685303, "training_acc": 75.0, "val_loss": 13.66724967956543, "val_acc": 55.0}
{"epoch": 33, "training_loss": 54.150094985961914, "training_acc": 77.5, "val_loss": 13.629587888717651, "val_acc": 55.0}
{"epoch": 34, "training_loss": 53.672035217285156, "training_acc": 68.75, "val_loss": 13.618696928024292, "val_acc": 55.0}
{"epoch": 35, "training_loss": 52.96724319458008, "training_acc": 66.25, "val_loss": 13.627609014511108, "val_acc": 55.0}
{"epoch": 36, "training_loss": 53.26394081115723, "training_acc": 71.25, "val_loss": 13.639646768569946, "val_acc": 55.0}
{"epoch": 37, "training_loss": 53.0860710144043, "training_acc": 77.5, "val_loss": 13.605279922485352, "val_acc": 55.0}
{"epoch": 38, "training_loss": 52.40430164337158, "training_acc": 78.75, "val_loss": 13.550437688827515, "val_acc": 55.0}
{"epoch": 39, "training_loss": 52.07914924621582, "training_acc": 61.25, "val_loss": 13.556944131851196, "val_acc": 55.0}
{"epoch": 40, "training_loss": 52.03408622741699, "training_acc": 60.0, "val_loss": 14.222472906112671, "val_acc": 60.0}
{"epoch": 41, "training_loss": 53.94703674316406, "training_acc": 50.0, "val_loss": 14.259299039840698, "val_acc": 60.0}
{"epoch": 42, "training_loss": 53.779958724975586, "training_acc": 51.25, "val_loss": 13.556556701660156, "val_acc": 55.0}
{"epoch": 43, "training_loss": 52.889862060546875, "training_acc": 53.75, "val_loss": 13.861403465270996, "val_acc": 55.0}
{"epoch": 44, "training_loss": 54.76820659637451, "training_acc": 52.5, "val_loss": 13.573702573776245, "val_acc": 55.0}
{"epoch": 45, "training_loss": 53.336788177490234, "training_acc": 52.5, "val_loss": 13.59707236289978, "val_acc": 55.0}
{"epoch": 46, "training_loss": 53.51682472229004, "training_acc": 72.5, "val_loss": 13.91403079032898, "val_acc": 55.0}
{"epoch": 47, "training_loss": 53.62035083770752, "training_acc": 48.75, "val_loss": 13.594882488250732, "val_acc": 55.0}
{"epoch": 48, "training_loss": 51.713807106018066, "training_acc": 72.5, "val_loss": 13.891481161117554, "val_acc": 55.0}
{"epoch": 49, "training_loss": 54.51221466064453, "training_acc": 52.5, "val_loss": 13.855494260787964, "val_acc": 55.0}
{"epoch": 50, "training_loss": 52.63786697387695, "training_acc": 52.5, "val_loss": 14.232152700424194, "val_acc": 60.0}
{"epoch": 51, "training_loss": 51.79646110534668, "training_acc": 55.0, "val_loss": 13.474483489990234, "val_acc": 55.0}
