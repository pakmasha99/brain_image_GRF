"main_optuna_fix_3.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3 --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 55.833526611328125, "training_acc": 52.5, "val_loss": 13.824176788330078, "val_acc": 55.0}
{"epoch": 1, "training_loss": 55.91212463378906, "training_acc": 45.0, "val_loss": 15.353868007659912, "val_acc": 55.0}
{"epoch": 2, "training_loss": 62.50547218322754, "training_acc": 52.5, "val_loss": 13.772118091583252, "val_acc": 55.0}
{"epoch": 3, "training_loss": 55.388821601867676, "training_acc": 52.5, "val_loss": 13.797484636306763, "val_acc": 55.0}
{"epoch": 4, "training_loss": 55.34619617462158, "training_acc": 52.5, "val_loss": 13.858325481414795, "val_acc": 55.0}
{"epoch": 5, "training_loss": 55.298255920410156, "training_acc": 60.0, "val_loss": 13.822009563446045, "val_acc": 55.0}
{"epoch": 6, "training_loss": 55.22537422180176, "training_acc": 52.5, "val_loss": 13.762708902359009, "val_acc": 55.0}
{"epoch": 7, "training_loss": 55.187238693237305, "training_acc": 52.5, "val_loss": 13.769195079803467, "val_acc": 55.0}
{"epoch": 8, "training_loss": 55.206321716308594, "training_acc": 52.5, "val_loss": 13.8313889503479, "val_acc": 55.0}
{"epoch": 9, "training_loss": 55.792853355407715, "training_acc": 42.5, "val_loss": 13.973989486694336, "val_acc": 55.0}
{"epoch": 10, "training_loss": 55.332993507385254, "training_acc": 52.5, "val_loss": 13.79517674446106, "val_acc": 55.0}
{"epoch": 11, "training_loss": 55.00216484069824, "training_acc": 52.5, "val_loss": 13.802883625030518, "val_acc": 55.0}
{"epoch": 12, "training_loss": 55.76247978210449, "training_acc": 52.5, "val_loss": 13.863167762756348, "val_acc": 55.0}
{"epoch": 13, "training_loss": 55.93311405181885, "training_acc": 52.5, "val_loss": 13.767057657241821, "val_acc": 55.0}
{"epoch": 14, "training_loss": 55.22598648071289, "training_acc": 52.5, "val_loss": 13.781287670135498, "val_acc": 55.0}
{"epoch": 15, "training_loss": 55.4289436340332, "training_acc": 47.5, "val_loss": 13.92076849937439, "val_acc": 55.0}
{"epoch": 16, "training_loss": 55.52431297302246, "training_acc": 47.5, "val_loss": 13.81534457206726, "val_acc": 55.0}
{"epoch": 17, "training_loss": 55.19280433654785, "training_acc": 60.0, "val_loss": 13.753495216369629, "val_acc": 55.0}
{"epoch": 18, "training_loss": 55.26499938964844, "training_acc": 52.5, "val_loss": 13.766449689865112, "val_acc": 55.0}
{"epoch": 19, "training_loss": 55.12691688537598, "training_acc": 52.5, "val_loss": 13.788782358169556, "val_acc": 55.0}
{"epoch": 20, "training_loss": 55.026856422424316, "training_acc": 56.25, "val_loss": 13.907279968261719, "val_acc": 55.0}
{"epoch": 21, "training_loss": 55.519022941589355, "training_acc": 47.5, "val_loss": 13.889908790588379, "val_acc": 55.0}
{"epoch": 22, "training_loss": 55.15183067321777, "training_acc": 48.75, "val_loss": 13.782042264938354, "val_acc": 55.0}
{"epoch": 23, "training_loss": 55.07927703857422, "training_acc": 53.75, "val_loss": 13.747283220291138, "val_acc": 55.0}
{"epoch": 24, "training_loss": 55.14396667480469, "training_acc": 52.5, "val_loss": 13.760453462600708, "val_acc": 55.0}
{"epoch": 25, "training_loss": 55.145416259765625, "training_acc": 52.5, "val_loss": 13.770302534103394, "val_acc": 55.0}
{"epoch": 26, "training_loss": 55.237881660461426, "training_acc": 52.5, "val_loss": 13.779933452606201, "val_acc": 55.0}
{"epoch": 27, "training_loss": 54.46395969390869, "training_acc": 52.5, "val_loss": 13.734362125396729, "val_acc": 55.0}
{"epoch": 28, "training_loss": 55.09779739379883, "training_acc": 51.25, "val_loss": 13.860968351364136, "val_acc": 55.0}
{"epoch": 29, "training_loss": 55.21324157714844, "training_acc": 55.0, "val_loss": 13.835060596466064, "val_acc": 55.0}
{"epoch": 30, "training_loss": 54.822075843811035, "training_acc": 56.25, "val_loss": 13.747315406799316, "val_acc": 55.0}
{"epoch": 31, "training_loss": 55.12972068786621, "training_acc": 52.5, "val_loss": 13.74804973602295, "val_acc": 55.0}
{"epoch": 32, "training_loss": 54.30156326293945, "training_acc": 52.5, "val_loss": 13.743627071380615, "val_acc": 55.0}
