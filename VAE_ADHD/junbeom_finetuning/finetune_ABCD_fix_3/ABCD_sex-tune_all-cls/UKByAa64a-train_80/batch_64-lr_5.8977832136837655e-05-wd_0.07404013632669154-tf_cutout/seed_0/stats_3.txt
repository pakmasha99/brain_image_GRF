"main_optuna_fix_3.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3 --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 56.07765007019043, "training_acc": 38.75, "val_loss": 13.776932954788208, "val_acc": 55.0}
{"epoch": 1, "training_loss": 56.16361141204834, "training_acc": 45.0, "val_loss": 13.824647665023804, "val_acc": 55.0}
{"epoch": 2, "training_loss": 56.07613658905029, "training_acc": 52.5, "val_loss": 13.742531538009644, "val_acc": 55.0}
{"epoch": 3, "training_loss": 55.47467803955078, "training_acc": 52.5, "val_loss": 14.29222822189331, "val_acc": 55.0}
{"epoch": 4, "training_loss": 56.13737678527832, "training_acc": 46.25, "val_loss": 13.84623408317566, "val_acc": 55.0}
{"epoch": 5, "training_loss": 56.21401596069336, "training_acc": 52.5, "val_loss": 13.866350650787354, "val_acc": 55.0}
{"epoch": 6, "training_loss": 56.12155723571777, "training_acc": 52.5, "val_loss": 13.769429922103882, "val_acc": 55.0}
{"epoch": 7, "training_loss": 55.293771743774414, "training_acc": 52.5, "val_loss": 13.845504522323608, "val_acc": 55.0}
{"epoch": 8, "training_loss": 55.436100006103516, "training_acc": 52.5, "val_loss": 14.012383222579956, "val_acc": 55.0}
{"epoch": 9, "training_loss": 55.83403205871582, "training_acc": 47.5, "val_loss": 14.11098837852478, "val_acc": 55.0}
{"epoch": 10, "training_loss": 55.89328575134277, "training_acc": 47.5, "val_loss": 13.766076564788818, "val_acc": 55.0}
{"epoch": 11, "training_loss": 55.170326232910156, "training_acc": 52.5, "val_loss": 14.094442129135132, "val_acc": 55.0}
{"epoch": 12, "training_loss": 57.42307662963867, "training_acc": 52.5, "val_loss": 13.798929452896118, "val_acc": 55.0}
{"epoch": 13, "training_loss": 55.7830753326416, "training_acc": 52.5, "val_loss": 13.847674131393433, "val_acc": 55.0}
{"epoch": 14, "training_loss": 55.31127452850342, "training_acc": 53.75, "val_loss": 13.975732326507568, "val_acc": 55.0}
{"epoch": 15, "training_loss": 55.81106472015381, "training_acc": 47.5, "val_loss": 13.930414915084839, "val_acc": 55.0}
{"epoch": 16, "training_loss": 55.36770534515381, "training_acc": 48.75, "val_loss": 13.775296211242676, "val_acc": 55.0}
{"epoch": 17, "training_loss": 55.528136253356934, "training_acc": 52.5, "val_loss": 13.777272701263428, "val_acc": 55.0}
{"epoch": 18, "training_loss": 55.61949157714844, "training_acc": 52.5, "val_loss": 13.762487173080444, "val_acc": 55.0}
{"epoch": 19, "training_loss": 55.33009910583496, "training_acc": 52.5, "val_loss": 13.832336664199829, "val_acc": 55.0}
{"epoch": 20, "training_loss": 55.491933822631836, "training_acc": 48.75, "val_loss": 13.982723951339722, "val_acc": 55.0}
{"epoch": 21, "training_loss": 55.754374504089355, "training_acc": 47.5, "val_loss": 13.861509561538696, "val_acc": 55.0}
{"epoch": 22, "training_loss": 55.326815605163574, "training_acc": 53.75, "val_loss": 13.763735294342041, "val_acc": 55.0}
{"epoch": 23, "training_loss": 55.24332618713379, "training_acc": 52.5, "val_loss": 13.762409687042236, "val_acc": 55.0}
{"epoch": 24, "training_loss": 55.5373477935791, "training_acc": 52.5, "val_loss": 13.79456877708435, "val_acc": 55.0}
{"epoch": 25, "training_loss": 55.654123306274414, "training_acc": 52.5, "val_loss": 13.864339590072632, "val_acc": 55.0}
{"epoch": 26, "training_loss": 56.18033027648926, "training_acc": 52.5, "val_loss": 13.882193565368652, "val_acc": 55.0}
{"epoch": 27, "training_loss": 56.08746814727783, "training_acc": 52.5, "val_loss": 13.798733949661255, "val_acc": 55.0}
{"epoch": 28, "training_loss": 55.60968208312988, "training_acc": 52.5, "val_loss": 13.765391111373901, "val_acc": 55.0}
{"epoch": 29, "training_loss": 55.33956432342529, "training_acc": 52.5, "val_loss": 13.892096281051636, "val_acc": 55.0}
{"epoch": 30, "training_loss": 55.40754318237305, "training_acc": 47.5, "val_loss": 13.926066160202026, "val_acc": 55.0}
{"epoch": 31, "training_loss": 55.614699363708496, "training_acc": 47.5, "val_loss": 13.91168475151062, "val_acc": 55.0}
{"epoch": 32, "training_loss": 55.36419105529785, "training_acc": 47.5, "val_loss": 13.90588641166687, "val_acc": 55.0}
{"epoch": 33, "training_loss": 55.48680019378662, "training_acc": 47.5, "val_loss": 13.828409910202026, "val_acc": 55.0}
{"epoch": 34, "training_loss": 55.300655364990234, "training_acc": 56.25, "val_loss": 13.772138357162476, "val_acc": 55.0}
{"epoch": 35, "training_loss": 55.33389472961426, "training_acc": 52.5, "val_loss": 13.760803937911987, "val_acc": 55.0}
{"epoch": 36, "training_loss": 55.350467681884766, "training_acc": 52.5, "val_loss": 13.76264214515686, "val_acc": 55.0}
{"epoch": 37, "training_loss": 55.34479236602783, "training_acc": 52.5, "val_loss": 13.764880895614624, "val_acc": 55.0}
{"epoch": 38, "training_loss": 55.318092346191406, "training_acc": 52.5, "val_loss": 13.774473667144775, "val_acc": 55.0}
{"epoch": 39, "training_loss": 55.234389305114746, "training_acc": 52.5, "val_loss": 13.778455257415771, "val_acc": 55.0}
{"epoch": 40, "training_loss": 55.21283435821533, "training_acc": 52.5, "val_loss": 13.778830766677856, "val_acc": 55.0}
{"epoch": 41, "training_loss": 55.21143913269043, "training_acc": 52.5, "val_loss": 13.802427053451538, "val_acc": 55.0}
{"epoch": 42, "training_loss": 55.27896213531494, "training_acc": 51.25, "val_loss": 13.845077753067017, "val_acc": 55.0}
{"epoch": 43, "training_loss": 55.240041732788086, "training_acc": 58.75, "val_loss": 13.835582733154297, "val_acc": 55.0}
