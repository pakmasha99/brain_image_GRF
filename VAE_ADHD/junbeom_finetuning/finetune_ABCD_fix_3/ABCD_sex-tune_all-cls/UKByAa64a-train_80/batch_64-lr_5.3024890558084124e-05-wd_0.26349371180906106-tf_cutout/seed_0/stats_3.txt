"main_optuna_fix_3.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3 --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 55.49531173706055, "training_acc": 52.5, "val_loss": 13.79356861114502, "val_acc": 55.0}
{"epoch": 1, "training_loss": 55.52400779724121, "training_acc": 52.5, "val_loss": 13.79549503326416, "val_acc": 55.0}
{"epoch": 2, "training_loss": 55.51317024230957, "training_acc": 52.5, "val_loss": 13.817462921142578, "val_acc": 55.0}
{"epoch": 3, "training_loss": 55.392313957214355, "training_acc": 52.5, "val_loss": 13.803755044937134, "val_acc": 55.0}
{"epoch": 4, "training_loss": 55.293107986450195, "training_acc": 52.5, "val_loss": 13.776880502700806, "val_acc": 55.0}
{"epoch": 5, "training_loss": 55.30551528930664, "training_acc": 52.5, "val_loss": 13.768656253814697, "val_acc": 55.0}
{"epoch": 6, "training_loss": 55.35831642150879, "training_acc": 52.5, "val_loss": 13.771203756332397, "val_acc": 55.0}
{"epoch": 7, "training_loss": 55.32820701599121, "training_acc": 52.5, "val_loss": 13.781099319458008, "val_acc": 55.0}
{"epoch": 8, "training_loss": 55.39016151428223, "training_acc": 52.5, "val_loss": 13.808504343032837, "val_acc": 55.0}
{"epoch": 9, "training_loss": 55.31734371185303, "training_acc": 52.5, "val_loss": 13.854117393493652, "val_acc": 55.0}
{"epoch": 10, "training_loss": 55.44153594970703, "training_acc": 46.25, "val_loss": 13.816118240356445, "val_acc": 55.0}
{"epoch": 11, "training_loss": 55.371158599853516, "training_acc": 52.5, "val_loss": 13.764486312866211, "val_acc": 55.0}
{"epoch": 12, "training_loss": 55.460726737976074, "training_acc": 52.5, "val_loss": 13.759742975234985, "val_acc": 55.0}
{"epoch": 13, "training_loss": 55.40702438354492, "training_acc": 52.5, "val_loss": 13.769123554229736, "val_acc": 55.0}
{"epoch": 14, "training_loss": 55.35355186462402, "training_acc": 52.5, "val_loss": 13.78496766090393, "val_acc": 55.0}
{"epoch": 15, "training_loss": 55.46451187133789, "training_acc": 52.5, "val_loss": 13.79169225692749, "val_acc": 55.0}
{"epoch": 16, "training_loss": 55.326340675354004, "training_acc": 52.5, "val_loss": 13.763220310211182, "val_acc": 55.0}
{"epoch": 17, "training_loss": 55.493285179138184, "training_acc": 52.5, "val_loss": 13.76273512840271, "val_acc": 55.0}
{"epoch": 18, "training_loss": 55.47870063781738, "training_acc": 52.5, "val_loss": 13.761218786239624, "val_acc": 55.0}
{"epoch": 19, "training_loss": 55.358154296875, "training_acc": 52.5, "val_loss": 13.778575658798218, "val_acc": 55.0}
{"epoch": 20, "training_loss": 55.368757247924805, "training_acc": 52.5, "val_loss": 13.810960054397583, "val_acc": 55.0}
{"epoch": 21, "training_loss": 55.367422103881836, "training_acc": 52.5, "val_loss": 13.823120594024658, "val_acc": 55.0}
{"epoch": 22, "training_loss": 55.376747131347656, "training_acc": 52.5, "val_loss": 13.813620805740356, "val_acc": 55.0}
{"epoch": 23, "training_loss": 55.339959144592285, "training_acc": 52.5, "val_loss": 13.78747820854187, "val_acc": 55.0}
{"epoch": 24, "training_loss": 55.31895637512207, "training_acc": 52.5, "val_loss": 13.766483068466187, "val_acc": 55.0}
{"epoch": 25, "training_loss": 55.30716133117676, "training_acc": 52.5, "val_loss": 13.76994013786316, "val_acc": 55.0}
