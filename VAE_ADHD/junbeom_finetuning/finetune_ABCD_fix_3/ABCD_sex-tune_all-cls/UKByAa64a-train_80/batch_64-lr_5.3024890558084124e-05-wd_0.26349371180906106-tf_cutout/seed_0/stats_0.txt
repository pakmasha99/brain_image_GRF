"main_optuna_fix_3.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3 --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 55.51081466674805, "training_acc": 53.75, "val_loss": 13.92795443534851, "val_acc": 50.0}
{"epoch": 1, "training_loss": 55.38789749145508, "training_acc": 53.75, "val_loss": 13.890107870101929, "val_acc": 50.0}
{"epoch": 2, "training_loss": 55.21848106384277, "training_acc": 53.75, "val_loss": 13.892210721969604, "val_acc": 50.0}
{"epoch": 3, "training_loss": 55.29129219055176, "training_acc": 53.75, "val_loss": 13.891525268554688, "val_acc": 50.0}
{"epoch": 4, "training_loss": 55.15693473815918, "training_acc": 53.75, "val_loss": 13.890901803970337, "val_acc": 50.0}
{"epoch": 5, "training_loss": 55.312395095825195, "training_acc": 53.75, "val_loss": 13.871787786483765, "val_acc": 50.0}
{"epoch": 6, "training_loss": 55.19028282165527, "training_acc": 53.75, "val_loss": 13.876384496688843, "val_acc": 50.0}
{"epoch": 7, "training_loss": 55.4094123840332, "training_acc": 53.75, "val_loss": 13.89390230178833, "val_acc": 50.0}
{"epoch": 8, "training_loss": 55.2135009765625, "training_acc": 53.75, "val_loss": 13.8858163356781, "val_acc": 50.0}
{"epoch": 9, "training_loss": 55.22463798522949, "training_acc": 53.75, "val_loss": 13.894630670547485, "val_acc": 50.0}
{"epoch": 10, "training_loss": 55.28725242614746, "training_acc": 53.75, "val_loss": 13.90949010848999, "val_acc": 50.0}
{"epoch": 11, "training_loss": 55.06120014190674, "training_acc": 53.75, "val_loss": 13.967260122299194, "val_acc": 50.0}
{"epoch": 12, "training_loss": 55.07096290588379, "training_acc": 53.75, "val_loss": 14.063829183578491, "val_acc": 50.0}
{"epoch": 13, "training_loss": 55.16876411437988, "training_acc": 53.75, "val_loss": 14.167757034301758, "val_acc": 50.0}
{"epoch": 14, "training_loss": 55.515214920043945, "training_acc": 53.75, "val_loss": 14.308512210845947, "val_acc": 50.0}
{"epoch": 15, "training_loss": 55.72931098937988, "training_acc": 53.75, "val_loss": 14.369782209396362, "val_acc": 50.0}
{"epoch": 16, "training_loss": 56.10420608520508, "training_acc": 53.75, "val_loss": 14.241758584976196, "val_acc": 50.0}
{"epoch": 17, "training_loss": 55.685343742370605, "training_acc": 53.75, "val_loss": 14.064080715179443, "val_acc": 50.0}
{"epoch": 18, "training_loss": 55.4063777923584, "training_acc": 53.75, "val_loss": 13.970211744308472, "val_acc": 50.0}
{"epoch": 19, "training_loss": 55.192121505737305, "training_acc": 53.75, "val_loss": 13.904416561126709, "val_acc": 50.0}
{"epoch": 20, "training_loss": 55.112985610961914, "training_acc": 53.75, "val_loss": 13.867883682250977, "val_acc": 50.0}
{"epoch": 21, "training_loss": 55.45124816894531, "training_acc": 47.5, "val_loss": 13.873062133789062, "val_acc": 50.0}
{"epoch": 22, "training_loss": 55.32901191711426, "training_acc": 52.5, "val_loss": 13.899269104003906, "val_acc": 50.0}
{"epoch": 23, "training_loss": 55.19071960449219, "training_acc": 53.75, "val_loss": 13.951739072799683, "val_acc": 50.0}
{"epoch": 24, "training_loss": 55.22459030151367, "training_acc": 53.75, "val_loss": 13.960570096969604, "val_acc": 50.0}
{"epoch": 25, "training_loss": 55.232473373413086, "training_acc": 53.75, "val_loss": 13.931597471237183, "val_acc": 50.0}
{"epoch": 26, "training_loss": 55.20928478240967, "training_acc": 53.75, "val_loss": 13.90866994857788, "val_acc": 50.0}
{"epoch": 27, "training_loss": 55.3066463470459, "training_acc": 53.75, "val_loss": 13.92673373222351, "val_acc": 50.0}
{"epoch": 28, "training_loss": 55.256141662597656, "training_acc": 53.75, "val_loss": 13.940705060958862, "val_acc": 50.0}
{"epoch": 29, "training_loss": 55.203566551208496, "training_acc": 53.75, "val_loss": 13.931474685668945, "val_acc": 50.0}
{"epoch": 30, "training_loss": 55.213701248168945, "training_acc": 53.75, "val_loss": 13.948049545288086, "val_acc": 50.0}
{"epoch": 31, "training_loss": 55.155935287475586, "training_acc": 53.75, "val_loss": 13.950830698013306, "val_acc": 50.0}
{"epoch": 32, "training_loss": 55.04040336608887, "training_acc": 53.75, "val_loss": 13.932905197143555, "val_acc": 50.0}
{"epoch": 33, "training_loss": 55.17283058166504, "training_acc": 53.75, "val_loss": 13.931573629379272, "val_acc": 50.0}
{"epoch": 34, "training_loss": 55.2049617767334, "training_acc": 53.75, "val_loss": 13.988808393478394, "val_acc": 50.0}
{"epoch": 35, "training_loss": 55.2269401550293, "training_acc": 53.75, "val_loss": 14.01330828666687, "val_acc": 50.0}
{"epoch": 36, "training_loss": 55.11660957336426, "training_acc": 53.75, "val_loss": 13.93671989440918, "val_acc": 50.0}
{"epoch": 37, "training_loss": 55.03770637512207, "training_acc": 53.75, "val_loss": 13.874939680099487, "val_acc": 50.0}
{"epoch": 38, "training_loss": 55.26733589172363, "training_acc": 51.25, "val_loss": 13.871500492095947, "val_acc": 50.0}
{"epoch": 39, "training_loss": 55.483643531799316, "training_acc": 46.25, "val_loss": 13.868461847305298, "val_acc": 50.0}
{"epoch": 40, "training_loss": 55.33324909210205, "training_acc": 55.0, "val_loss": 13.896430730819702, "val_acc": 50.0}
{"epoch": 41, "training_loss": 55.345438957214355, "training_acc": 53.75, "val_loss": 13.93153190612793, "val_acc": 50.0}
{"epoch": 42, "training_loss": 55.17043972015381, "training_acc": 53.75, "val_loss": 13.91710638999939, "val_acc": 50.0}
