"main_optuna_fix_3.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3 --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 55.40939903259277, "training_acc": 52.5, "val_loss": 13.789321184158325, "val_acc": 55.0}
{"epoch": 1, "training_loss": 55.394524574279785, "training_acc": 52.5, "val_loss": 13.762677907943726, "val_acc": 55.0}
{"epoch": 2, "training_loss": 55.41100311279297, "training_acc": 52.5, "val_loss": 13.743208646774292, "val_acc": 55.0}
{"epoch": 3, "training_loss": 55.38220405578613, "training_acc": 52.5, "val_loss": 13.743652105331421, "val_acc": 55.0}
{"epoch": 4, "training_loss": 55.24049377441406, "training_acc": 52.5, "val_loss": 13.708267211914062, "val_acc": 55.0}
{"epoch": 5, "training_loss": 55.351091384887695, "training_acc": 52.5, "val_loss": 13.734091520309448, "val_acc": 55.0}
{"epoch": 6, "training_loss": 55.42821216583252, "training_acc": 52.5, "val_loss": 13.75335693359375, "val_acc": 55.0}
{"epoch": 7, "training_loss": 55.24465560913086, "training_acc": 52.5, "val_loss": 13.759087324142456, "val_acc": 55.0}
{"epoch": 8, "training_loss": 55.22863960266113, "training_acc": 52.5, "val_loss": 13.789232969284058, "val_acc": 55.0}
{"epoch": 9, "training_loss": 55.572635650634766, "training_acc": 43.75, "val_loss": 13.831696510314941, "val_acc": 55.0}
{"epoch": 10, "training_loss": 55.302310943603516, "training_acc": 53.75, "val_loss": 13.768819570541382, "val_acc": 55.0}
{"epoch": 11, "training_loss": 55.28554821014404, "training_acc": 51.25, "val_loss": 13.749258518218994, "val_acc": 55.0}
{"epoch": 12, "training_loss": 55.336320877075195, "training_acc": 52.5, "val_loss": 13.755251169204712, "val_acc": 55.0}
{"epoch": 13, "training_loss": 55.41573524475098, "training_acc": 52.5, "val_loss": 13.760478496551514, "val_acc": 55.0}
{"epoch": 14, "training_loss": 55.33502769470215, "training_acc": 52.5, "val_loss": 13.759740591049194, "val_acc": 55.0}
{"epoch": 15, "training_loss": 55.523600578308105, "training_acc": 52.5, "val_loss": 13.76450777053833, "val_acc": 55.0}
{"epoch": 16, "training_loss": 55.48408126831055, "training_acc": 52.5, "val_loss": 13.756859302520752, "val_acc": 55.0}
{"epoch": 17, "training_loss": 55.34223556518555, "training_acc": 52.5, "val_loss": 13.749837875366211, "val_acc": 55.0}
{"epoch": 18, "training_loss": 55.33346080780029, "training_acc": 52.5, "val_loss": 13.74380111694336, "val_acc": 55.0}
{"epoch": 19, "training_loss": 55.07480430603027, "training_acc": 52.5, "val_loss": 13.772263526916504, "val_acc": 55.0}
{"epoch": 20, "training_loss": 55.24248218536377, "training_acc": 52.5, "val_loss": 13.846114873886108, "val_acc": 55.0}
{"epoch": 21, "training_loss": 55.41328716278076, "training_acc": 55.0, "val_loss": 13.86607050895691, "val_acc": 55.0}
{"epoch": 22, "training_loss": 55.478251457214355, "training_acc": 37.5, "val_loss": 13.810596466064453, "val_acc": 55.0}
{"epoch": 23, "training_loss": 55.30932426452637, "training_acc": 53.75, "val_loss": 13.755240440368652, "val_acc": 55.0}
{"epoch": 24, "training_loss": 55.002854347229004, "training_acc": 52.5, "val_loss": 13.731067180633545, "val_acc": 55.0}
{"epoch": 25, "training_loss": 55.066049575805664, "training_acc": 52.5, "val_loss": 13.722270727157593, "val_acc": 55.0}
{"epoch": 26, "training_loss": 55.331419944763184, "training_acc": 52.5, "val_loss": 13.721115589141846, "val_acc": 55.0}
{"epoch": 27, "training_loss": 54.62807846069336, "training_acc": 52.5, "val_loss": 13.707728385925293, "val_acc": 55.0}
{"epoch": 28, "training_loss": 54.91629219055176, "training_acc": 52.5, "val_loss": 13.805572986602783, "val_acc": 55.0}
{"epoch": 29, "training_loss": 55.14821243286133, "training_acc": 53.75, "val_loss": 13.786652088165283, "val_acc": 55.0}
{"epoch": 30, "training_loss": 54.9731330871582, "training_acc": 51.25, "val_loss": 13.688586950302124, "val_acc": 55.0}
{"epoch": 31, "training_loss": 55.52756881713867, "training_acc": 52.5, "val_loss": 13.694614171981812, "val_acc": 55.0}
{"epoch": 32, "training_loss": 54.442054748535156, "training_acc": 52.5, "val_loss": 13.677068948745728, "val_acc": 55.0}
{"epoch": 33, "training_loss": 55.11840629577637, "training_acc": 51.25, "val_loss": 13.693132400512695, "val_acc": 55.0}
{"epoch": 34, "training_loss": 54.37107467651367, "training_acc": 57.5, "val_loss": 13.737223148345947, "val_acc": 55.0}
{"epoch": 35, "training_loss": 54.462242126464844, "training_acc": 62.5, "val_loss": 13.621898889541626, "val_acc": 55.0}
{"epoch": 36, "training_loss": 54.03382110595703, "training_acc": 56.25, "val_loss": 13.609493970870972, "val_acc": 55.0}
{"epoch": 37, "training_loss": 54.56199645996094, "training_acc": 51.25, "val_loss": 13.610118627548218, "val_acc": 55.0}
