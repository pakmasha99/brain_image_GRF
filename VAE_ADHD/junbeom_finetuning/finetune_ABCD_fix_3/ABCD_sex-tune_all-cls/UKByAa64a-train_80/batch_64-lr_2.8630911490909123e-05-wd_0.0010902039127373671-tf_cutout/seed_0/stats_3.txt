"main_optuna_fix_3.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3 --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 55.69220733642578, "training_acc": 52.5, "val_loss": 13.767598867416382, "val_acc": 55.0}
{"epoch": 1, "training_loss": 56.028282165527344, "training_acc": 45.0, "val_loss": 13.726588487625122, "val_acc": 55.0}
{"epoch": 2, "training_loss": 55.26362419128418, "training_acc": 52.5, "val_loss": 13.780397176742554, "val_acc": 55.0}
{"epoch": 3, "training_loss": 55.80449676513672, "training_acc": 52.5, "val_loss": 13.724724054336548, "val_acc": 55.0}
{"epoch": 4, "training_loss": 55.50043487548828, "training_acc": 52.5, "val_loss": 13.782436847686768, "val_acc": 55.0}
{"epoch": 5, "training_loss": 55.19163131713867, "training_acc": 52.5, "val_loss": 13.742183446884155, "val_acc": 55.0}
{"epoch": 6, "training_loss": 55.170753479003906, "training_acc": 52.5, "val_loss": 13.717167377471924, "val_acc": 55.0}
{"epoch": 7, "training_loss": 55.234009742736816, "training_acc": 52.5, "val_loss": 13.707047700881958, "val_acc": 55.0}
{"epoch": 8, "training_loss": 55.18277931213379, "training_acc": 52.5, "val_loss": 13.71969223022461, "val_acc": 55.0}
{"epoch": 9, "training_loss": 55.078277587890625, "training_acc": 56.25, "val_loss": 13.831814527511597, "val_acc": 55.0}
{"epoch": 10, "training_loss": 55.34306335449219, "training_acc": 52.5, "val_loss": 13.84839653968811, "val_acc": 55.0}
{"epoch": 11, "training_loss": 55.127596855163574, "training_acc": 55.0, "val_loss": 13.752942085266113, "val_acc": 55.0}
{"epoch": 12, "training_loss": 55.30172252655029, "training_acc": 52.5, "val_loss": 13.731553554534912, "val_acc": 55.0}
{"epoch": 13, "training_loss": 55.121232986450195, "training_acc": 52.5, "val_loss": 13.730067014694214, "val_acc": 55.0}
{"epoch": 14, "training_loss": 55.1004114151001, "training_acc": 52.5, "val_loss": 13.726054430007935, "val_acc": 55.0}
{"epoch": 15, "training_loss": 55.03077411651611, "training_acc": 52.5, "val_loss": 13.7384033203125, "val_acc": 55.0}
{"epoch": 16, "training_loss": 54.86391639709473, "training_acc": 53.75, "val_loss": 13.715986013412476, "val_acc": 55.0}
{"epoch": 17, "training_loss": 55.13164520263672, "training_acc": 52.5, "val_loss": 13.747907876968384, "val_acc": 55.0}
{"epoch": 18, "training_loss": 54.975379943847656, "training_acc": 52.5, "val_loss": 13.71393084526062, "val_acc": 55.0}
{"epoch": 19, "training_loss": 54.80632972717285, "training_acc": 52.5, "val_loss": 13.720219135284424, "val_acc": 55.0}
{"epoch": 20, "training_loss": 54.90487098693848, "training_acc": 58.75, "val_loss": 13.814924955368042, "val_acc": 55.0}
{"epoch": 21, "training_loss": 54.9851131439209, "training_acc": 57.5, "val_loss": 13.827104568481445, "val_acc": 55.0}
{"epoch": 22, "training_loss": 54.76664352416992, "training_acc": 55.0, "val_loss": 13.741706609725952, "val_acc": 55.0}
{"epoch": 23, "training_loss": 54.509117126464844, "training_acc": 68.75, "val_loss": 13.683772087097168, "val_acc": 55.0}
{"epoch": 24, "training_loss": 54.365769386291504, "training_acc": 53.75, "val_loss": 13.675585985183716, "val_acc": 55.0}
{"epoch": 25, "training_loss": 53.8637809753418, "training_acc": 52.5, "val_loss": 13.830342292785645, "val_acc": 55.0}
{"epoch": 26, "training_loss": 55.43783760070801, "training_acc": 52.5, "val_loss": 13.926361799240112, "val_acc": 55.0}
