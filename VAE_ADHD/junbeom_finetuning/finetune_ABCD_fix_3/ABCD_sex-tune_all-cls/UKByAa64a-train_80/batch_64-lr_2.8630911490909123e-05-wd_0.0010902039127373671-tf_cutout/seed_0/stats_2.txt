"main_optuna_fix_3.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3 --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 55.7998571395874, "training_acc": 42.5, "val_loss": 13.841581344604492, "val_acc": 55.0}
{"epoch": 1, "training_loss": 55.744245529174805, "training_acc": 47.5, "val_loss": 13.759598731994629, "val_acc": 55.0}
{"epoch": 2, "training_loss": 55.37339401245117, "training_acc": 52.5, "val_loss": 13.82693886756897, "val_acc": 55.0}
{"epoch": 3, "training_loss": 55.812652587890625, "training_acc": 52.5, "val_loss": 13.742426633834839, "val_acc": 55.0}
{"epoch": 4, "training_loss": 55.32547378540039, "training_acc": 52.5, "val_loss": 13.80366325378418, "val_acc": 55.0}
{"epoch": 5, "training_loss": 55.32494926452637, "training_acc": 52.5, "val_loss": 13.882831335067749, "val_acc": 55.0}
{"epoch": 6, "training_loss": 55.641902923583984, "training_acc": 47.5, "val_loss": 13.749768733978271, "val_acc": 55.0}
{"epoch": 7, "training_loss": 55.079824447631836, "training_acc": 52.5, "val_loss": 13.792614936828613, "val_acc": 55.0}
{"epoch": 8, "training_loss": 56.218796730041504, "training_acc": 52.5, "val_loss": 13.777185678482056, "val_acc": 55.0}
{"epoch": 9, "training_loss": 55.47114086151123, "training_acc": 52.5, "val_loss": 13.715049028396606, "val_acc": 55.0}
{"epoch": 10, "training_loss": 55.42696189880371, "training_acc": 52.5, "val_loss": 13.81317138671875, "val_acc": 55.0}
{"epoch": 11, "training_loss": 55.37836265563965, "training_acc": 52.5, "val_loss": 13.837934732437134, "val_acc": 55.0}
{"epoch": 12, "training_loss": 55.399850845336914, "training_acc": 53.75, "val_loss": 13.789771795272827, "val_acc": 55.0}
{"epoch": 13, "training_loss": 55.26489734649658, "training_acc": 52.5, "val_loss": 13.76113772392273, "val_acc": 55.0}
{"epoch": 14, "training_loss": 55.221065521240234, "training_acc": 52.5, "val_loss": 13.747882843017578, "val_acc": 55.0}
{"epoch": 15, "training_loss": 55.21211814880371, "training_acc": 52.5, "val_loss": 13.73377799987793, "val_acc": 55.0}
{"epoch": 16, "training_loss": 55.188042640686035, "training_acc": 52.5, "val_loss": 13.738887310028076, "val_acc": 55.0}
{"epoch": 17, "training_loss": 55.590375900268555, "training_acc": 52.5, "val_loss": 13.753728866577148, "val_acc": 55.0}
{"epoch": 18, "training_loss": 55.4198112487793, "training_acc": 52.5, "val_loss": 13.720041513442993, "val_acc": 55.0}
{"epoch": 19, "training_loss": 55.10236167907715, "training_acc": 52.5, "val_loss": 13.760455846786499, "val_acc": 55.0}
{"epoch": 20, "training_loss": 55.20393943786621, "training_acc": 55.0, "val_loss": 13.851598501205444, "val_acc": 55.0}
{"epoch": 21, "training_loss": 55.30876636505127, "training_acc": 48.75, "val_loss": 13.857046365737915, "val_acc": 55.0}
{"epoch": 22, "training_loss": 55.288086891174316, "training_acc": 48.75, "val_loss": 13.78771424293518, "val_acc": 55.0}
{"epoch": 23, "training_loss": 55.06515312194824, "training_acc": 62.5, "val_loss": 13.726609945297241, "val_acc": 55.0}
{"epoch": 24, "training_loss": 54.93517017364502, "training_acc": 52.5, "val_loss": 13.708080053329468, "val_acc": 55.0}
{"epoch": 25, "training_loss": 55.068593978881836, "training_acc": 52.5, "val_loss": 13.743975162506104, "val_acc": 55.0}
{"epoch": 26, "training_loss": 55.4160737991333, "training_acc": 52.5, "val_loss": 13.786475658416748, "val_acc": 55.0}
{"epoch": 27, "training_loss": 55.61385917663574, "training_acc": 52.5, "val_loss": 13.800181150436401, "val_acc": 55.0}
{"epoch": 28, "training_loss": 55.702138900756836, "training_acc": 52.5, "val_loss": 13.715285062789917, "val_acc": 55.0}
