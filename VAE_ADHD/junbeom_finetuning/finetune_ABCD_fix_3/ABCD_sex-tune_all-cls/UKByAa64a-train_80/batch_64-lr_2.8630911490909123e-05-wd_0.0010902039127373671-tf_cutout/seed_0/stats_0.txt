"main_optuna_fix_3.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3 --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 56.20465278625488, "training_acc": 42.5, "val_loss": 13.917602300643921, "val_acc": 50.0}
{"epoch": 1, "training_loss": 55.77461242675781, "training_acc": 43.75, "val_loss": 13.949346542358398, "val_acc": 50.0}
{"epoch": 2, "training_loss": 55.33246612548828, "training_acc": 53.75, "val_loss": 14.0890634059906, "val_acc": 50.0}
{"epoch": 3, "training_loss": 55.23720455169678, "training_acc": 53.75, "val_loss": 13.972808122634888, "val_acc": 50.0}
{"epoch": 4, "training_loss": 55.18565654754639, "training_acc": 53.75, "val_loss": 13.867186307907104, "val_acc": 50.0}
{"epoch": 5, "training_loss": 55.20249366760254, "training_acc": 53.75, "val_loss": 13.863003253936768, "val_acc": 50.0}
{"epoch": 6, "training_loss": 55.39123344421387, "training_acc": 55.0, "val_loss": 13.885613679885864, "val_acc": 50.0}
{"epoch": 7, "training_loss": 55.19151306152344, "training_acc": 58.75, "val_loss": 13.959764242172241, "val_acc": 50.0}
{"epoch": 8, "training_loss": 54.982476234436035, "training_acc": 53.75, "val_loss": 13.922550678253174, "val_acc": 50.0}
{"epoch": 9, "training_loss": 54.68081569671631, "training_acc": 55.0, "val_loss": 13.905346393585205, "val_acc": 50.0}
{"epoch": 10, "training_loss": 54.96695423126221, "training_acc": 55.0, "val_loss": 13.9986252784729, "val_acc": 50.0}
{"epoch": 11, "training_loss": 54.26613426208496, "training_acc": 53.75, "val_loss": 14.538582563400269, "val_acc": 50.0}
{"epoch": 12, "training_loss": 55.252163887023926, "training_acc": 53.75, "val_loss": 14.282112121582031, "val_acc": 50.0}
{"epoch": 13, "training_loss": 54.80714416503906, "training_acc": 53.75, "val_loss": 14.16202425956726, "val_acc": 50.0}
{"epoch": 14, "training_loss": 54.382259368896484, "training_acc": 55.0, "val_loss": 15.248106718063354, "val_acc": 50.0}
{"epoch": 15, "training_loss": 55.245412826538086, "training_acc": 53.75, "val_loss": 15.150676965713501, "val_acc": 50.0}
{"epoch": 16, "training_loss": 56.640563011169434, "training_acc": 52.5, "val_loss": 13.90387773513794, "val_acc": 50.0}
{"epoch": 17, "training_loss": 53.672061920166016, "training_acc": 61.25, "val_loss": 13.847264051437378, "val_acc": 50.0}
{"epoch": 18, "training_loss": 54.37510299682617, "training_acc": 67.5, "val_loss": 14.051308631896973, "val_acc": 50.0}
{"epoch": 19, "training_loss": 54.78354263305664, "training_acc": 55.0, "val_loss": 14.237741231918335, "val_acc": 50.0}
{"epoch": 20, "training_loss": 54.052955627441406, "training_acc": 55.0, "val_loss": 13.926891088485718, "val_acc": 50.0}
{"epoch": 21, "training_loss": 54.160940170288086, "training_acc": 73.75, "val_loss": 13.926256895065308, "val_acc": 50.0}
{"epoch": 22, "training_loss": 53.791823387145996, "training_acc": 61.25, "val_loss": 14.152406454086304, "val_acc": 50.0}
{"epoch": 23, "training_loss": 53.10384941101074, "training_acc": 62.5, "val_loss": 14.770612716674805, "val_acc": 50.0}
{"epoch": 24, "training_loss": 54.488304138183594, "training_acc": 53.75, "val_loss": 14.576412439346313, "val_acc": 50.0}
{"epoch": 25, "training_loss": 53.9369010925293, "training_acc": 53.75, "val_loss": 14.078210592269897, "val_acc": 50.0}
{"epoch": 26, "training_loss": 53.65252494812012, "training_acc": 55.0, "val_loss": 13.909401893615723, "val_acc": 50.0}
{"epoch": 27, "training_loss": 54.18057441711426, "training_acc": 70.0, "val_loss": 14.030189514160156, "val_acc": 50.0}
{"epoch": 28, "training_loss": 52.82779121398926, "training_acc": 66.25, "val_loss": 14.366189241409302, "val_acc": 50.0}
{"epoch": 29, "training_loss": 52.0384464263916, "training_acc": 56.25, "val_loss": 14.060169458389282, "val_acc": 50.0}
{"epoch": 30, "training_loss": 50.18045711517334, "training_acc": 76.25, "val_loss": 15.824730396270752, "val_acc": 50.0}
