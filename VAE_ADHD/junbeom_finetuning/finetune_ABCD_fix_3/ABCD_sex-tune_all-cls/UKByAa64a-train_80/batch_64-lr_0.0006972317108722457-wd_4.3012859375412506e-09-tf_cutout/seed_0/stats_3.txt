"main_optuna_fix_3.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3 --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 56.316341400146484, "training_acc": 52.5, "val_loss": 13.764495849609375, "val_acc": 55.0}
{"epoch": 1, "training_loss": 56.38530349731445, "training_acc": 45.0, "val_loss": 13.76477599143982, "val_acc": 55.0}
{"epoch": 2, "training_loss": 55.44408321380615, "training_acc": 52.5, "val_loss": 13.763824701309204, "val_acc": 55.0}
{"epoch": 3, "training_loss": 55.474483489990234, "training_acc": 52.5, "val_loss": 13.823922872543335, "val_acc": 55.0}
{"epoch": 4, "training_loss": 55.57406806945801, "training_acc": 47.5, "val_loss": 13.768224716186523, "val_acc": 55.0}
{"epoch": 5, "training_loss": 55.36382293701172, "training_acc": 52.5, "val_loss": 13.776663541793823, "val_acc": 55.0}
{"epoch": 6, "training_loss": 55.65804481506348, "training_acc": 52.5, "val_loss": 13.764015436172485, "val_acc": 55.0}
{"epoch": 7, "training_loss": 55.467323303222656, "training_acc": 52.5, "val_loss": 13.792433738708496, "val_acc": 55.0}
{"epoch": 8, "training_loss": 55.343976974487305, "training_acc": 52.5, "val_loss": 13.96208643913269, "val_acc": 55.0}
{"epoch": 9, "training_loss": 55.710195541381836, "training_acc": 47.5, "val_loss": 14.062330722808838, "val_acc": 55.0}
{"epoch": 10, "training_loss": 55.87790107727051, "training_acc": 47.5, "val_loss": 13.821808099746704, "val_acc": 55.0}
{"epoch": 11, "training_loss": 55.19982624053955, "training_acc": 52.5, "val_loss": 13.801745176315308, "val_acc": 55.0}
{"epoch": 12, "training_loss": 56.07473945617676, "training_acc": 52.5, "val_loss": 13.804950714111328, "val_acc": 55.0}
{"epoch": 13, "training_loss": 55.87079048156738, "training_acc": 52.5, "val_loss": 13.764762878417969, "val_acc": 55.0}
{"epoch": 14, "training_loss": 55.341583251953125, "training_acc": 52.5, "val_loss": 13.846691846847534, "val_acc": 55.0}
{"epoch": 15, "training_loss": 55.757954597473145, "training_acc": 45.0, "val_loss": 13.870375156402588, "val_acc": 55.0}
{"epoch": 16, "training_loss": 55.38881874084473, "training_acc": 57.5, "val_loss": 13.763723373413086, "val_acc": 55.0}
{"epoch": 17, "training_loss": 55.65586853027344, "training_acc": 52.5, "val_loss": 13.795292377471924, "val_acc": 55.0}
{"epoch": 18, "training_loss": 55.8239803314209, "training_acc": 52.5, "val_loss": 13.768867254257202, "val_acc": 55.0}
{"epoch": 19, "training_loss": 55.463130950927734, "training_acc": 52.5, "val_loss": 13.79993200302124, "val_acc": 55.0}
{"epoch": 20, "training_loss": 55.4344367980957, "training_acc": 50.0, "val_loss": 13.914724588394165, "val_acc": 55.0}
{"epoch": 21, "training_loss": 55.5686092376709, "training_acc": 47.5, "val_loss": 13.931444883346558, "val_acc": 55.0}
{"epoch": 22, "training_loss": 55.58731460571289, "training_acc": 47.5, "val_loss": 13.857972621917725, "val_acc": 55.0}
{"epoch": 23, "training_loss": 55.40241622924805, "training_acc": 52.5, "val_loss": 13.779525756835938, "val_acc": 55.0}
{"epoch": 24, "training_loss": 55.27701377868652, "training_acc": 52.5, "val_loss": 13.771780729293823, "val_acc": 55.0}
{"epoch": 25, "training_loss": 55.52258014678955, "training_acc": 52.5, "val_loss": 13.869860172271729, "val_acc": 55.0}
{"epoch": 26, "training_loss": 56.28964614868164, "training_acc": 52.5, "val_loss": 13.950353860855103, "val_acc": 55.0}
{"epoch": 27, "training_loss": 56.73850154876709, "training_acc": 52.5, "val_loss": 13.86898398399353, "val_acc": 55.0}
{"epoch": 28, "training_loss": 56.10301208496094, "training_acc": 52.5, "val_loss": 13.762816190719604, "val_acc": 55.0}
{"epoch": 29, "training_loss": 55.52528190612793, "training_acc": 52.5, "val_loss": 13.89782428741455, "val_acc": 55.0}
{"epoch": 30, "training_loss": 55.542999267578125, "training_acc": 47.5, "val_loss": 14.054349660873413, "val_acc": 55.0}
{"epoch": 31, "training_loss": 55.95010948181152, "training_acc": 47.5, "val_loss": 14.106979370117188, "val_acc": 55.0}
{"epoch": 32, "training_loss": 56.08183479309082, "training_acc": 47.5, "val_loss": 14.050626754760742, "val_acc": 55.0}
{"epoch": 33, "training_loss": 55.85488700866699, "training_acc": 47.5, "val_loss": 13.871053457260132, "val_acc": 55.0}
{"epoch": 34, "training_loss": 55.40031051635742, "training_acc": 50.0, "val_loss": 13.766859769821167, "val_acc": 55.0}
{"epoch": 35, "training_loss": 55.53803634643555, "training_acc": 52.5, "val_loss": 13.767461776733398, "val_acc": 55.0}
{"epoch": 36, "training_loss": 55.587138175964355, "training_acc": 52.5, "val_loss": 13.766114711761475, "val_acc": 55.0}
{"epoch": 37, "training_loss": 55.53876972198486, "training_acc": 52.5, "val_loss": 13.762842416763306, "val_acc": 55.0}
{"epoch": 38, "training_loss": 55.471351623535156, "training_acc": 52.5, "val_loss": 13.775005340576172, "val_acc": 55.0}
{"epoch": 39, "training_loss": 55.37833023071289, "training_acc": 52.5, "val_loss": 13.792480230331421, "val_acc": 55.0}
{"epoch": 40, "training_loss": 55.35233020782471, "training_acc": 52.5, "val_loss": 13.802167177200317, "val_acc": 55.0}
{"epoch": 41, "training_loss": 55.3632287979126, "training_acc": 52.5, "val_loss": 13.832062482833862, "val_acc": 55.0}
{"epoch": 42, "training_loss": 55.42846965789795, "training_acc": 50.0, "val_loss": 13.85934591293335, "val_acc": 55.0}
{"epoch": 43, "training_loss": 55.446189880371094, "training_acc": 52.5, "val_loss": 13.826735019683838, "val_acc": 55.0}
{"epoch": 44, "training_loss": 55.4304838180542, "training_acc": 52.5, "val_loss": 13.813350200653076, "val_acc": 55.0}
