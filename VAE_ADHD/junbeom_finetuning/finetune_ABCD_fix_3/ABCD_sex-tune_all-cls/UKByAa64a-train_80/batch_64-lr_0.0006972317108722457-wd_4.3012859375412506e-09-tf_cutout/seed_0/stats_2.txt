"main_optuna_fix_3.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3 --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 56.39764404296875, "training_acc": 52.5, "val_loss": 13.773337602615356, "val_acc": 55.0}
{"epoch": 1, "training_loss": 56.42339897155762, "training_acc": 45.0, "val_loss": 13.76320481300354, "val_acc": 55.0}
{"epoch": 2, "training_loss": 55.514366149902344, "training_acc": 52.5, "val_loss": 13.763984441757202, "val_acc": 55.0}
{"epoch": 3, "training_loss": 55.44925594329834, "training_acc": 52.5, "val_loss": 13.76568078994751, "val_acc": 55.0}
{"epoch": 4, "training_loss": 55.39759540557861, "training_acc": 52.5, "val_loss": 13.827071189880371, "val_acc": 55.0}
{"epoch": 5, "training_loss": 55.38333320617676, "training_acc": 52.5, "val_loss": 13.869398832321167, "val_acc": 55.0}
{"epoch": 6, "training_loss": 55.87308692932129, "training_acc": 47.5, "val_loss": 13.764201402664185, "val_acc": 55.0}
{"epoch": 7, "training_loss": 55.402207374572754, "training_acc": 52.5, "val_loss": 13.827093839645386, "val_acc": 55.0}
{"epoch": 8, "training_loss": 56.0742244720459, "training_acc": 52.5, "val_loss": 13.762797117233276, "val_acc": 55.0}
{"epoch": 9, "training_loss": 55.2899284362793, "training_acc": 52.5, "val_loss": 13.919286727905273, "val_acc": 55.0}
{"epoch": 10, "training_loss": 55.678043365478516, "training_acc": 47.5, "val_loss": 13.980605602264404, "val_acc": 55.0}
{"epoch": 11, "training_loss": 55.65174865722656, "training_acc": 47.5, "val_loss": 13.807915449142456, "val_acc": 55.0}
{"epoch": 12, "training_loss": 55.40179634094238, "training_acc": 52.5, "val_loss": 13.762861490249634, "val_acc": 55.0}
{"epoch": 13, "training_loss": 55.45576763153076, "training_acc": 52.5, "val_loss": 13.762954473495483, "val_acc": 55.0}
{"epoch": 14, "training_loss": 55.41407585144043, "training_acc": 52.5, "val_loss": 13.78290057182312, "val_acc": 55.0}
{"epoch": 15, "training_loss": 55.55172920227051, "training_acc": 52.5, "val_loss": 13.780860900878906, "val_acc": 55.0}
{"epoch": 16, "training_loss": 55.30216026306152, "training_acc": 52.5, "val_loss": 13.76940369606018, "val_acc": 55.0}
{"epoch": 17, "training_loss": 55.7697811126709, "training_acc": 52.5, "val_loss": 13.792632818222046, "val_acc": 55.0}
{"epoch": 18, "training_loss": 55.739718437194824, "training_acc": 52.5, "val_loss": 13.763006925582886, "val_acc": 55.0}
{"epoch": 19, "training_loss": 55.339205741882324, "training_acc": 52.5, "val_loss": 13.8402259349823, "val_acc": 55.0}
{"epoch": 20, "training_loss": 55.49654769897461, "training_acc": 50.0, "val_loss": 13.959182500839233, "val_acc": 55.0}
{"epoch": 21, "training_loss": 55.67410850524902, "training_acc": 47.5, "val_loss": 13.898630142211914, "val_acc": 55.0}
{"epoch": 22, "training_loss": 55.47800827026367, "training_acc": 50.0, "val_loss": 13.791899681091309, "val_acc": 55.0}
{"epoch": 23, "training_loss": 55.32338905334473, "training_acc": 52.5, "val_loss": 13.763118982315063, "val_acc": 55.0}
{"epoch": 24, "training_loss": 55.45176696777344, "training_acc": 52.5, "val_loss": 13.793807029724121, "val_acc": 55.0}
{"epoch": 25, "training_loss": 55.8133487701416, "training_acc": 52.5, "val_loss": 13.836374282836914, "val_acc": 55.0}
{"epoch": 26, "training_loss": 56.16163158416748, "training_acc": 52.5, "val_loss": 13.822060823440552, "val_acc": 55.0}
{"epoch": 27, "training_loss": 55.99195861816406, "training_acc": 52.5, "val_loss": 13.789622783660889, "val_acc": 55.0}
{"epoch": 28, "training_loss": 55.667781829833984, "training_acc": 52.5, "val_loss": 13.769786357879639, "val_acc": 55.0}
{"epoch": 29, "training_loss": 55.44493770599365, "training_acc": 52.5, "val_loss": 13.893365859985352, "val_acc": 55.0}
{"epoch": 30, "training_loss": 55.57254409790039, "training_acc": 47.5, "val_loss": 13.954797983169556, "val_acc": 55.0}
{"epoch": 31, "training_loss": 55.73128414154053, "training_acc": 47.5, "val_loss": 13.948897123336792, "val_acc": 55.0}
{"epoch": 32, "training_loss": 55.65603065490723, "training_acc": 47.5, "val_loss": 13.966039419174194, "val_acc": 55.0}
{"epoch": 33, "training_loss": 55.69048309326172, "training_acc": 47.5, "val_loss": 13.921680450439453, "val_acc": 55.0}
{"epoch": 34, "training_loss": 55.54519176483154, "training_acc": 47.5, "val_loss": 13.820275068283081, "val_acc": 55.0}
{"epoch": 35, "training_loss": 55.479801177978516, "training_acc": 52.5, "val_loss": 13.77220630645752, "val_acc": 55.0}
{"epoch": 36, "training_loss": 55.37317085266113, "training_acc": 52.5, "val_loss": 13.772653341293335, "val_acc": 55.0}
{"epoch": 37, "training_loss": 55.36308288574219, "training_acc": 52.5, "val_loss": 13.798017501831055, "val_acc": 55.0}
{"epoch": 38, "training_loss": 55.45350933074951, "training_acc": 52.5, "val_loss": 13.828495740890503, "val_acc": 55.0}
{"epoch": 39, "training_loss": 55.37860870361328, "training_acc": 52.5, "val_loss": 13.793338537216187, "val_acc": 55.0}
{"epoch": 40, "training_loss": 55.485594749450684, "training_acc": 52.5, "val_loss": 13.783458471298218, "val_acc": 55.0}
{"epoch": 41, "training_loss": 55.321988105773926, "training_acc": 52.5, "val_loss": 13.849989175796509, "val_acc": 55.0}
