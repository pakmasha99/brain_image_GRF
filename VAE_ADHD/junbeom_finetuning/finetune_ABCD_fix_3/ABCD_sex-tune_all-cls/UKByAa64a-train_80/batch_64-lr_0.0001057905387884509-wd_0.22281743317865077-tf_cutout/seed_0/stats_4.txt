"main_optuna_fix_3.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3 --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 55.4366340637207, "training_acc": 52.5, "val_loss": 13.751529455184937, "val_acc": 55.0}
{"epoch": 1, "training_loss": 55.510841369628906, "training_acc": 52.5, "val_loss": 13.763459920883179, "val_acc": 55.0}
{"epoch": 2, "training_loss": 55.72296619415283, "training_acc": 52.5, "val_loss": 13.774839639663696, "val_acc": 55.0}
{"epoch": 3, "training_loss": 55.754878997802734, "training_acc": 52.5, "val_loss": 13.756054639816284, "val_acc": 55.0}
{"epoch": 4, "training_loss": 55.48430824279785, "training_acc": 52.5, "val_loss": 13.785159587860107, "val_acc": 55.0}
{"epoch": 5, "training_loss": 55.38050937652588, "training_acc": 52.5, "val_loss": 13.81061315536499, "val_acc": 55.0}
{"epoch": 6, "training_loss": 55.40949821472168, "training_acc": 52.5, "val_loss": 13.798054456710815, "val_acc": 55.0}
{"epoch": 7, "training_loss": 55.35080814361572, "training_acc": 52.5, "val_loss": 13.778243064880371, "val_acc": 55.0}
{"epoch": 8, "training_loss": 55.38631057739258, "training_acc": 52.5, "val_loss": 13.811157941818237, "val_acc": 55.0}
{"epoch": 9, "training_loss": 55.60219097137451, "training_acc": 45.0, "val_loss": 13.837088346481323, "val_acc": 55.0}
{"epoch": 10, "training_loss": 55.36929702758789, "training_acc": 52.5, "val_loss": 13.77872347831726, "val_acc": 55.0}
{"epoch": 11, "training_loss": 55.309444427490234, "training_acc": 52.5, "val_loss": 13.762984275817871, "val_acc": 55.0}
{"epoch": 12, "training_loss": 55.512983322143555, "training_acc": 52.5, "val_loss": 13.773812055587769, "val_acc": 55.0}
{"epoch": 13, "training_loss": 55.6157341003418, "training_acc": 52.5, "val_loss": 13.766523599624634, "val_acc": 55.0}
{"epoch": 14, "training_loss": 55.51264476776123, "training_acc": 52.5, "val_loss": 13.767427206039429, "val_acc": 55.0}
{"epoch": 15, "training_loss": 55.486289978027344, "training_acc": 52.5, "val_loss": 13.798422813415527, "val_acc": 55.0}
{"epoch": 16, "training_loss": 55.469303131103516, "training_acc": 52.5, "val_loss": 13.782252073287964, "val_acc": 55.0}
{"epoch": 17, "training_loss": 55.38155746459961, "training_acc": 52.5, "val_loss": 13.76312255859375, "val_acc": 55.0}
{"epoch": 18, "training_loss": 55.433725357055664, "training_acc": 52.5, "val_loss": 13.763415813446045, "val_acc": 55.0}
{"epoch": 19, "training_loss": 55.354576110839844, "training_acc": 52.5, "val_loss": 13.781148195266724, "val_acc": 55.0}
{"epoch": 20, "training_loss": 55.33453845977783, "training_acc": 52.5, "val_loss": 13.831034898757935, "val_acc": 55.0}
{"epoch": 21, "training_loss": 55.42116355895996, "training_acc": 52.5, "val_loss": 13.853362798690796, "val_acc": 55.0}
{"epoch": 22, "training_loss": 55.43084716796875, "training_acc": 52.5, "val_loss": 13.833673000335693, "val_acc": 55.0}
{"epoch": 23, "training_loss": 55.386640548706055, "training_acc": 52.5, "val_loss": 13.797721862792969, "val_acc": 55.0}
{"epoch": 24, "training_loss": 55.3611421585083, "training_acc": 52.5, "val_loss": 13.770475387573242, "val_acc": 55.0}
{"epoch": 25, "training_loss": 55.36073112487793, "training_acc": 52.5, "val_loss": 13.761767148971558, "val_acc": 55.0}
{"epoch": 26, "training_loss": 55.425180435180664, "training_acc": 52.5, "val_loss": 13.76757025718689, "val_acc": 55.0}
{"epoch": 27, "training_loss": 55.56577491760254, "training_acc": 52.5, "val_loss": 13.766638040542603, "val_acc": 55.0}
