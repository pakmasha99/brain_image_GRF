"main_optuna_fix_3.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3 --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 55.56391525268555, "training_acc": 53.75, "val_loss": 13.847745656967163, "val_acc": 50.0}
{"epoch": 1, "training_loss": 55.46468925476074, "training_acc": 53.75, "val_loss": 13.919826745986938, "val_acc": 50.0}
{"epoch": 2, "training_loss": 55.219985008239746, "training_acc": 53.75, "val_loss": 13.901528120040894, "val_acc": 50.0}
{"epoch": 3, "training_loss": 55.25805187225342, "training_acc": 53.75, "val_loss": 13.885554075241089, "val_acc": 50.0}
{"epoch": 4, "training_loss": 55.24686908721924, "training_acc": 53.75, "val_loss": 13.887465000152588, "val_acc": 50.0}
{"epoch": 5, "training_loss": 55.33250617980957, "training_acc": 53.75, "val_loss": 13.869178295135498, "val_acc": 50.0}
{"epoch": 6, "training_loss": 55.3332405090332, "training_acc": 53.75, "val_loss": 13.867878913879395, "val_acc": 50.0}
{"epoch": 7, "training_loss": 55.424203872680664, "training_acc": 53.75, "val_loss": 13.883209228515625, "val_acc": 50.0}
{"epoch": 8, "training_loss": 55.25212097167969, "training_acc": 53.75, "val_loss": 13.876681327819824, "val_acc": 50.0}
{"epoch": 9, "training_loss": 55.28966236114502, "training_acc": 53.75, "val_loss": 13.87694239616394, "val_acc": 50.0}
{"epoch": 10, "training_loss": 55.28373336791992, "training_acc": 53.75, "val_loss": 13.899191617965698, "val_acc": 50.0}
{"epoch": 11, "training_loss": 55.16752529144287, "training_acc": 53.75, "val_loss": 13.980408906936646, "val_acc": 50.0}
{"epoch": 12, "training_loss": 55.2211971282959, "training_acc": 53.75, "val_loss": 14.09425139427185, "val_acc": 50.0}
{"epoch": 13, "training_loss": 55.44404411315918, "training_acc": 53.75, "val_loss": 14.198516607284546, "val_acc": 50.0}
{"epoch": 14, "training_loss": 55.71457481384277, "training_acc": 53.75, "val_loss": 14.314650297164917, "val_acc": 50.0}
{"epoch": 15, "training_loss": 55.949989318847656, "training_acc": 53.75, "val_loss": 14.363027811050415, "val_acc": 50.0}
{"epoch": 16, "training_loss": 56.111613273620605, "training_acc": 53.75, "val_loss": 14.241865873336792, "val_acc": 50.0}
{"epoch": 17, "training_loss": 55.72173309326172, "training_acc": 53.75, "val_loss": 14.048248529434204, "val_acc": 50.0}
{"epoch": 18, "training_loss": 55.44760513305664, "training_acc": 53.75, "val_loss": 13.941588401794434, "val_acc": 50.0}
{"epoch": 19, "training_loss": 55.260223388671875, "training_acc": 53.75, "val_loss": 13.888475894927979, "val_acc": 50.0}
{"epoch": 20, "training_loss": 55.18670463562012, "training_acc": 53.75, "val_loss": 13.864437341690063, "val_acc": 50.0}
{"epoch": 21, "training_loss": 55.6149263381958, "training_acc": 46.25, "val_loss": 13.865584135055542, "val_acc": 50.0}
{"epoch": 22, "training_loss": 55.49420166015625, "training_acc": 46.25, "val_loss": 13.877919912338257, "val_acc": 50.0}
{"epoch": 23, "training_loss": 55.3107852935791, "training_acc": 53.75, "val_loss": 13.950759172439575, "val_acc": 50.0}
{"epoch": 24, "training_loss": 55.25779342651367, "training_acc": 53.75, "val_loss": 13.980563879013062, "val_acc": 50.0}
{"epoch": 25, "training_loss": 55.27204895019531, "training_acc": 53.75, "val_loss": 13.952511548995972, "val_acc": 50.0}
{"epoch": 26, "training_loss": 55.2458381652832, "training_acc": 53.75, "val_loss": 13.923628330230713, "val_acc": 50.0}
{"epoch": 27, "training_loss": 55.26277732849121, "training_acc": 53.75, "val_loss": 13.930141925811768, "val_acc": 50.0}
{"epoch": 28, "training_loss": 55.28377819061279, "training_acc": 53.75, "val_loss": 13.93675446510315, "val_acc": 50.0}
{"epoch": 29, "training_loss": 55.240474700927734, "training_acc": 53.75, "val_loss": 13.909767866134644, "val_acc": 50.0}
{"epoch": 30, "training_loss": 55.233360290527344, "training_acc": 53.75, "val_loss": 13.90812873840332, "val_acc": 50.0}
{"epoch": 31, "training_loss": 55.23649215698242, "training_acc": 53.75, "val_loss": 13.912690877914429, "val_acc": 50.0}
{"epoch": 32, "training_loss": 55.22511672973633, "training_acc": 53.75, "val_loss": 13.90358567237854, "val_acc": 50.0}
{"epoch": 33, "training_loss": 55.26304626464844, "training_acc": 53.75, "val_loss": 13.90817642211914, "val_acc": 50.0}
{"epoch": 34, "training_loss": 55.20740222930908, "training_acc": 53.75, "val_loss": 13.960694074630737, "val_acc": 50.0}
{"epoch": 35, "training_loss": 55.328505516052246, "training_acc": 53.75, "val_loss": 13.996514081954956, "val_acc": 50.0}
{"epoch": 36, "training_loss": 55.275564193725586, "training_acc": 53.75, "val_loss": 13.949111700057983, "val_acc": 50.0}
{"epoch": 37, "training_loss": 55.19870471954346, "training_acc": 53.75, "val_loss": 13.890752792358398, "val_acc": 50.0}
{"epoch": 38, "training_loss": 55.281246185302734, "training_acc": 53.75, "val_loss": 13.865374326705933, "val_acc": 50.0}
{"epoch": 39, "training_loss": 55.39017677307129, "training_acc": 53.75, "val_loss": 13.86481761932373, "val_acc": 50.0}
{"epoch": 40, "training_loss": 55.3762903213501, "training_acc": 53.75, "val_loss": 13.874843120574951, "val_acc": 50.0}
