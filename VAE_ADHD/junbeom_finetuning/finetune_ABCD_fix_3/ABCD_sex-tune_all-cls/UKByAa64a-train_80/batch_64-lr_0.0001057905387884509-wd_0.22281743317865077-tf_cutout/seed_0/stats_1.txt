"main_optuna_fix_3.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3 --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 55.67767143249512, "training_acc": 53.75, "val_loss": 13.905298709869385, "val_acc": 50.0}
{"epoch": 1, "training_loss": 55.38118362426758, "training_acc": 53.75, "val_loss": 13.988969326019287, "val_acc": 50.0}
{"epoch": 2, "training_loss": 55.26451301574707, "training_acc": 53.75, "val_loss": 13.962205648422241, "val_acc": 50.0}
{"epoch": 3, "training_loss": 55.24445152282715, "training_acc": 53.75, "val_loss": 13.910081386566162, "val_acc": 50.0}
{"epoch": 4, "training_loss": 55.202157974243164, "training_acc": 53.75, "val_loss": 13.885622024536133, "val_acc": 50.0}
{"epoch": 5, "training_loss": 55.312076568603516, "training_acc": 53.75, "val_loss": 13.900423049926758, "val_acc": 50.0}
{"epoch": 6, "training_loss": 55.19419479370117, "training_acc": 53.75, "val_loss": 13.96478533744812, "val_acc": 50.0}
{"epoch": 7, "training_loss": 55.23122692108154, "training_acc": 53.75, "val_loss": 13.98898720741272, "val_acc": 50.0}
{"epoch": 8, "training_loss": 55.25913429260254, "training_acc": 53.75, "val_loss": 13.918980360031128, "val_acc": 50.0}
{"epoch": 9, "training_loss": 55.18476486206055, "training_acc": 53.75, "val_loss": 13.868931531906128, "val_acc": 50.0}
{"epoch": 10, "training_loss": 55.37589454650879, "training_acc": 50.0, "val_loss": 13.877862691879272, "val_acc": 50.0}
{"epoch": 11, "training_loss": 55.23224449157715, "training_acc": 53.75, "val_loss": 13.93555998802185, "val_acc": 50.0}
{"epoch": 12, "training_loss": 55.217750549316406, "training_acc": 53.75, "val_loss": 13.969457149505615, "val_acc": 50.0}
{"epoch": 13, "training_loss": 55.30664348602295, "training_acc": 53.75, "val_loss": 14.0253746509552, "val_acc": 50.0}
{"epoch": 14, "training_loss": 55.353681564331055, "training_acc": 53.75, "val_loss": 14.149612188339233, "val_acc": 50.0}
{"epoch": 15, "training_loss": 55.548492431640625, "training_acc": 53.75, "val_loss": 14.215492010116577, "val_acc": 50.0}
{"epoch": 16, "training_loss": 55.795836448669434, "training_acc": 53.75, "val_loss": 14.116324186325073, "val_acc": 50.0}
{"epoch": 17, "training_loss": 55.4688663482666, "training_acc": 53.75, "val_loss": 13.95543098449707, "val_acc": 50.0}
{"epoch": 18, "training_loss": 55.27408027648926, "training_acc": 53.75, "val_loss": 13.879660367965698, "val_acc": 50.0}
{"epoch": 19, "training_loss": 55.332597732543945, "training_acc": 53.75, "val_loss": 13.864353895187378, "val_acc": 50.0}
{"epoch": 20, "training_loss": 55.37266731262207, "training_acc": 53.75, "val_loss": 13.8637375831604, "val_acc": 50.0}
{"epoch": 21, "training_loss": 55.49606895446777, "training_acc": 46.25, "val_loss": 13.873703479766846, "val_acc": 50.0}
{"epoch": 22, "training_loss": 55.19324207305908, "training_acc": 53.75, "val_loss": 13.978266716003418, "val_acc": 50.0}
{"epoch": 23, "training_loss": 55.2147274017334, "training_acc": 53.75, "val_loss": 14.114694595336914, "val_acc": 50.0}
{"epoch": 24, "training_loss": 55.486846923828125, "training_acc": 53.75, "val_loss": 14.173930883407593, "val_acc": 50.0}
{"epoch": 25, "training_loss": 55.59094715118408, "training_acc": 53.75, "val_loss": 14.101042747497559, "val_acc": 50.0}
{"epoch": 26, "training_loss": 55.41365909576416, "training_acc": 53.75, "val_loss": 13.98361325263977, "val_acc": 50.0}
{"epoch": 27, "training_loss": 55.28945350646973, "training_acc": 53.75, "val_loss": 13.929460048675537, "val_acc": 50.0}
{"epoch": 28, "training_loss": 55.27180290222168, "training_acc": 53.75, "val_loss": 13.885008096694946, "val_acc": 50.0}
{"epoch": 29, "training_loss": 55.298983573913574, "training_acc": 53.75, "val_loss": 13.865035772323608, "val_acc": 50.0}
{"epoch": 30, "training_loss": 55.399353981018066, "training_acc": 53.75, "val_loss": 13.881291151046753, "val_acc": 50.0}
{"epoch": 31, "training_loss": 55.241947174072266, "training_acc": 53.75, "val_loss": 13.955235481262207, "val_acc": 50.0}
{"epoch": 32, "training_loss": 55.325157165527344, "training_acc": 53.75, "val_loss": 13.974072933197021, "val_acc": 50.0}
{"epoch": 33, "training_loss": 55.26249313354492, "training_acc": 53.75, "val_loss": 13.927851915359497, "val_acc": 50.0}
{"epoch": 34, "training_loss": 55.229013442993164, "training_acc": 53.75, "val_loss": 13.915115594863892, "val_acc": 50.0}
