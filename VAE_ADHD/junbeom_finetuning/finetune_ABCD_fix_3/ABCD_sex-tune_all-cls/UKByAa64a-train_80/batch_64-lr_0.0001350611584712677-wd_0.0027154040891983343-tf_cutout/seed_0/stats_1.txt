"main_optuna_fix_3.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3 --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 57.56614875793457, "training_acc": 41.25, "val_loss": 13.993643522262573, "val_acc": 50.0}
{"epoch": 1, "training_loss": 56.7860050201416, "training_acc": 46.25, "val_loss": 14.893978834152222, "val_acc": 50.0}
{"epoch": 2, "training_loss": 59.51468849182129, "training_acc": 51.25, "val_loss": 14.486469030380249, "val_acc": 50.0}
{"epoch": 3, "training_loss": 56.08768272399902, "training_acc": 53.75, "val_loss": 13.859448432922363, "val_acc": 50.0}
{"epoch": 4, "training_loss": 55.45811653137207, "training_acc": 52.5, "val_loss": 13.909440040588379, "val_acc": 50.0}
{"epoch": 5, "training_loss": 55.236061096191406, "training_acc": 53.75, "val_loss": 14.1604745388031, "val_acc": 50.0}
{"epoch": 6, "training_loss": 56.18759632110596, "training_acc": 51.25, "val_loss": 14.140788316726685, "val_acc": 50.0}
{"epoch": 7, "training_loss": 55.46922588348389, "training_acc": 53.75, "val_loss": 14.035916328430176, "val_acc": 50.0}
{"epoch": 8, "training_loss": 55.21317481994629, "training_acc": 53.75, "val_loss": 13.878105878829956, "val_acc": 50.0}
{"epoch": 9, "training_loss": 55.6868896484375, "training_acc": 43.75, "val_loss": 13.865113258361816, "val_acc": 50.0}
{"epoch": 10, "training_loss": 55.486796379089355, "training_acc": 50.0, "val_loss": 13.935455083847046, "val_acc": 50.0}
{"epoch": 11, "training_loss": 55.165353775024414, "training_acc": 53.75, "val_loss": 14.264391660690308, "val_acc": 50.0}
{"epoch": 12, "training_loss": 55.75008964538574, "training_acc": 53.75, "val_loss": 13.932739496231079, "val_acc": 50.0}
{"epoch": 13, "training_loss": 55.37864971160889, "training_acc": 53.75, "val_loss": 13.909565210342407, "val_acc": 50.0}
{"epoch": 14, "training_loss": 55.08593940734863, "training_acc": 53.75, "val_loss": 14.246286153793335, "val_acc": 50.0}
{"epoch": 15, "training_loss": 55.67589473724365, "training_acc": 53.75, "val_loss": 14.55401062965393, "val_acc": 50.0}
{"epoch": 16, "training_loss": 56.62611484527588, "training_acc": 53.75, "val_loss": 14.192732572555542, "val_acc": 50.0}
{"epoch": 17, "training_loss": 55.490848541259766, "training_acc": 53.75, "val_loss": 13.894315958023071, "val_acc": 50.0}
{"epoch": 18, "training_loss": 55.33059120178223, "training_acc": 51.25, "val_loss": 13.86690616607666, "val_acc": 50.0}
{"epoch": 19, "training_loss": 55.78248119354248, "training_acc": 46.25, "val_loss": 13.867738246917725, "val_acc": 50.0}
{"epoch": 20, "training_loss": 55.66334342956543, "training_acc": 46.25, "val_loss": 13.860777616500854, "val_acc": 50.0}
{"epoch": 21, "training_loss": 55.471181869506836, "training_acc": 51.25, "val_loss": 13.90623688697815, "val_acc": 50.0}
{"epoch": 22, "training_loss": 55.0507116317749, "training_acc": 53.75, "val_loss": 14.265098571777344, "val_acc": 50.0}
{"epoch": 23, "training_loss": 55.66630458831787, "training_acc": 53.75, "val_loss": 14.443817138671875, "val_acc": 50.0}
{"epoch": 24, "training_loss": 56.22188472747803, "training_acc": 53.75, "val_loss": 14.205402135848999, "val_acc": 50.0}
{"epoch": 25, "training_loss": 55.626681327819824, "training_acc": 53.75, "val_loss": 13.993085622787476, "val_acc": 50.0}
{"epoch": 26, "training_loss": 55.269612312316895, "training_acc": 53.75, "val_loss": 13.89533281326294, "val_acc": 50.0}
{"epoch": 27, "training_loss": 55.282118797302246, "training_acc": 53.75, "val_loss": 13.880692720413208, "val_acc": 50.0}
{"epoch": 28, "training_loss": 55.336408615112305, "training_acc": 53.75, "val_loss": 13.873676061630249, "val_acc": 50.0}
{"epoch": 29, "training_loss": 55.281723976135254, "training_acc": 53.75, "val_loss": 13.857930898666382, "val_acc": 50.0}
{"epoch": 30, "training_loss": 55.28254508972168, "training_acc": 53.75, "val_loss": 13.882979154586792, "val_acc": 50.0}
{"epoch": 31, "training_loss": 55.16697311401367, "training_acc": 53.75, "val_loss": 13.993886709213257, "val_acc": 50.0}
{"epoch": 32, "training_loss": 55.27255821228027, "training_acc": 53.75, "val_loss": 14.032566547393799, "val_acc": 50.0}
{"epoch": 33, "training_loss": 55.321537017822266, "training_acc": 53.75, "val_loss": 13.942022323608398, "val_acc": 50.0}
{"epoch": 34, "training_loss": 55.296433448791504, "training_acc": 53.75, "val_loss": 13.897457122802734, "val_acc": 50.0}
{"epoch": 35, "training_loss": 55.18070030212402, "training_acc": 53.75, "val_loss": 13.866726160049438, "val_acc": 50.0}
{"epoch": 36, "training_loss": 55.165635108947754, "training_acc": 53.75, "val_loss": 13.865693807601929, "val_acc": 50.0}
{"epoch": 37, "training_loss": 55.61905288696289, "training_acc": 46.25, "val_loss": 13.932585716247559, "val_acc": 50.0}
{"epoch": 38, "training_loss": 56.254587173461914, "training_acc": 46.25, "val_loss": 13.92377495765686, "val_acc": 50.0}
{"epoch": 39, "training_loss": 56.07670021057129, "training_acc": 46.25, "val_loss": 13.862621784210205, "val_acc": 50.0}
{"epoch": 40, "training_loss": 55.473130226135254, "training_acc": 46.25, "val_loss": 13.913664817810059, "val_acc": 50.0}
{"epoch": 41, "training_loss": 55.37682819366455, "training_acc": 53.75, "val_loss": 13.933368921279907, "val_acc": 50.0}
{"epoch": 42, "training_loss": 55.234371185302734, "training_acc": 53.75, "val_loss": 13.885942697525024, "val_acc": 50.0}
{"epoch": 43, "training_loss": 55.20876693725586, "training_acc": 53.75, "val_loss": 13.887348175048828, "val_acc": 50.0}
{"epoch": 44, "training_loss": 55.19932174682617, "training_acc": 53.75, "val_loss": 13.907588720321655, "val_acc": 50.0}
{"epoch": 45, "training_loss": 55.22744655609131, "training_acc": 53.75, "val_loss": 13.903635740280151, "val_acc": 50.0}
{"epoch": 46, "training_loss": 55.25418758392334, "training_acc": 53.75, "val_loss": 13.911619186401367, "val_acc": 50.0}
{"epoch": 47, "training_loss": 55.12722587585449, "training_acc": 53.75, "val_loss": 13.997739553451538, "val_acc": 50.0}
{"epoch": 48, "training_loss": 55.20185852050781, "training_acc": 53.75, "val_loss": 14.166276454925537, "val_acc": 50.0}
{"epoch": 49, "training_loss": 55.70807647705078, "training_acc": 53.75, "val_loss": 14.238252639770508, "val_acc": 50.0}
{"epoch": 50, "training_loss": 55.702911376953125, "training_acc": 53.75, "val_loss": 14.08101201057434, "val_acc": 50.0}
{"epoch": 51, "training_loss": 55.29757785797119, "training_acc": 53.75, "val_loss": 13.933757543563843, "val_acc": 50.0}
{"epoch": 52, "training_loss": 55.09201431274414, "training_acc": 53.75, "val_loss": 13.861111402511597, "val_acc": 50.0}
{"epoch": 53, "training_loss": 55.500871658325195, "training_acc": 48.75, "val_loss": 13.861387968063354, "val_acc": 50.0}
{"epoch": 54, "training_loss": 55.54164218902588, "training_acc": 46.25, "val_loss": 13.864673376083374, "val_acc": 50.0}
{"epoch": 55, "training_loss": 55.32807159423828, "training_acc": 53.75, "val_loss": 13.922842741012573, "val_acc": 50.0}
{"epoch": 56, "training_loss": 55.292259216308594, "training_acc": 53.75, "val_loss": 13.933504819869995, "val_acc": 50.0}
{"epoch": 57, "training_loss": 55.2282657623291, "training_acc": 53.75, "val_loss": 13.90243411064148, "val_acc": 50.0}
{"epoch": 58, "training_loss": 55.226369857788086, "training_acc": 53.75, "val_loss": 13.878377676010132, "val_acc": 50.0}
{"epoch": 59, "training_loss": 55.3874626159668, "training_acc": 53.75, "val_loss": 13.86869192123413, "val_acc": 50.0}
{"epoch": 60, "training_loss": 55.319074630737305, "training_acc": 53.75, "val_loss": 13.882607221603394, "val_acc": 50.0}
{"epoch": 61, "training_loss": 55.21818542480469, "training_acc": 53.75, "val_loss": 13.926151990890503, "val_acc": 50.0}
{"epoch": 62, "training_loss": 55.20595169067383, "training_acc": 53.75, "val_loss": 13.966072797775269, "val_acc": 50.0}
{"epoch": 63, "training_loss": 55.234779357910156, "training_acc": 53.75, "val_loss": 13.942121267318726, "val_acc": 50.0}
{"epoch": 64, "training_loss": 55.13570022583008, "training_acc": 53.75, "val_loss": 13.887306451797485, "val_acc": 50.0}
{"epoch": 65, "training_loss": 55.129883766174316, "training_acc": 53.75, "val_loss": 13.86212944984436, "val_acc": 50.0}
