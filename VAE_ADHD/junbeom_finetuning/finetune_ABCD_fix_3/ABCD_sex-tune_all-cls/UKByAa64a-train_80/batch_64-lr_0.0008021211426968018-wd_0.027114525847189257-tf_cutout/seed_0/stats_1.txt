"main_optuna_fix_3.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3 --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 56.28804683685303, "training_acc": 53.75, "val_loss": 13.977854251861572, "val_acc": 50.0}
{"epoch": 1, "training_loss": 56.50867462158203, "training_acc": 46.25, "val_loss": 13.935259580612183, "val_acc": 50.0}
{"epoch": 2, "training_loss": 55.24079513549805, "training_acc": 53.75, "val_loss": 14.045562744140625, "val_acc": 50.0}
{"epoch": 3, "training_loss": 55.324262619018555, "training_acc": 53.75, "val_loss": 13.864978551864624, "val_acc": 50.0}
{"epoch": 4, "training_loss": 55.382568359375, "training_acc": 53.75, "val_loss": 13.867443799972534, "val_acc": 50.0}
{"epoch": 5, "training_loss": 55.318970680236816, "training_acc": 53.75, "val_loss": 13.95977258682251, "val_acc": 50.0}
{"epoch": 6, "training_loss": 55.2453498840332, "training_acc": 53.75, "val_loss": 14.040670394897461, "val_acc": 50.0}
{"epoch": 7, "training_loss": 55.36400032043457, "training_acc": 53.75, "val_loss": 13.968693017959595, "val_acc": 50.0}
{"epoch": 8, "training_loss": 55.24386405944824, "training_acc": 53.75, "val_loss": 13.881714344024658, "val_acc": 50.0}
{"epoch": 9, "training_loss": 55.26736068725586, "training_acc": 53.75, "val_loss": 13.867300748825073, "val_acc": 50.0}
{"epoch": 10, "training_loss": 55.63187599182129, "training_acc": 46.25, "val_loss": 13.863897323608398, "val_acc": 50.0}
{"epoch": 11, "training_loss": 55.324764251708984, "training_acc": 53.75, "val_loss": 14.005775451660156, "val_acc": 50.0}
{"epoch": 12, "training_loss": 55.30690860748291, "training_acc": 53.75, "val_loss": 14.1157066822052, "val_acc": 50.0}
{"epoch": 13, "training_loss": 55.55768394470215, "training_acc": 53.75, "val_loss": 14.09040093421936, "val_acc": 50.0}
{"epoch": 14, "training_loss": 55.579092025756836, "training_acc": 53.75, "val_loss": 14.141019582748413, "val_acc": 50.0}
{"epoch": 15, "training_loss": 55.56071090698242, "training_acc": 53.75, "val_loss": 14.240275621414185, "val_acc": 50.0}
{"epoch": 16, "training_loss": 55.81415271759033, "training_acc": 53.75, "val_loss": 14.184900522232056, "val_acc": 50.0}
{"epoch": 17, "training_loss": 55.60708999633789, "training_acc": 53.75, "val_loss": 13.943861722946167, "val_acc": 50.0}
{"epoch": 18, "training_loss": 55.31278038024902, "training_acc": 53.75, "val_loss": 13.86426568031311, "val_acc": 50.0}
{"epoch": 19, "training_loss": 55.58021926879883, "training_acc": 41.25, "val_loss": 13.88762354850769, "val_acc": 50.0}
{"epoch": 20, "training_loss": 55.853684425354004, "training_acc": 46.25, "val_loss": 13.888014554977417, "val_acc": 50.0}
{"epoch": 21, "training_loss": 55.746846199035645, "training_acc": 46.25, "val_loss": 13.884038925170898, "val_acc": 50.0}
{"epoch": 22, "training_loss": 55.10495185852051, "training_acc": 53.75, "val_loss": 14.172528982162476, "val_acc": 50.0}
{"epoch": 23, "training_loss": 55.606621742248535, "training_acc": 53.75, "val_loss": 14.436261653900146, "val_acc": 50.0}
{"epoch": 24, "training_loss": 56.30719184875488, "training_acc": 53.75, "val_loss": 14.38555121421814, "val_acc": 50.0}
{"epoch": 25, "training_loss": 56.125290870666504, "training_acc": 53.75, "val_loss": 14.140523672103882, "val_acc": 50.0}
{"epoch": 26, "training_loss": 55.54769515991211, "training_acc": 53.75, "val_loss": 13.928794860839844, "val_acc": 50.0}
{"epoch": 27, "training_loss": 55.26354789733887, "training_acc": 53.75, "val_loss": 13.871692419052124, "val_acc": 50.0}
{"epoch": 28, "training_loss": 55.371826171875, "training_acc": 53.75, "val_loss": 13.863734006881714, "val_acc": 50.0}
{"epoch": 29, "training_loss": 55.56877517700195, "training_acc": 46.25, "val_loss": 13.869824409484863, "val_acc": 50.0}
{"epoch": 30, "training_loss": 55.56099891662598, "training_acc": 46.25, "val_loss": 13.891303539276123, "val_acc": 50.0}
{"epoch": 31, "training_loss": 55.207143783569336, "training_acc": 53.75, "val_loss": 14.105488061904907, "val_acc": 50.0}
{"epoch": 32, "training_loss": 55.66890907287598, "training_acc": 53.75, "val_loss": 14.135881662368774, "val_acc": 50.0}
{"epoch": 33, "training_loss": 55.53772163391113, "training_acc": 53.75, "val_loss": 13.940043449401855, "val_acc": 50.0}
{"epoch": 34, "training_loss": 55.26443099975586, "training_acc": 53.75, "val_loss": 13.876502513885498, "val_acc": 50.0}
{"epoch": 35, "training_loss": 55.32522964477539, "training_acc": 53.75, "val_loss": 13.863099813461304, "val_acc": 50.0}
{"epoch": 36, "training_loss": 55.42761993408203, "training_acc": 46.25, "val_loss": 13.912101984024048, "val_acc": 50.0}
{"epoch": 37, "training_loss": 56.056034088134766, "training_acc": 46.25, "val_loss": 13.987611532211304, "val_acc": 50.0}
{"epoch": 38, "training_loss": 56.62640380859375, "training_acc": 46.25, "val_loss": 13.915653228759766, "val_acc": 50.0}
{"epoch": 39, "training_loss": 55.94315147399902, "training_acc": 46.25, "val_loss": 13.897042274475098, "val_acc": 50.0}
{"epoch": 40, "training_loss": 55.34159469604492, "training_acc": 53.75, "val_loss": 14.142608642578125, "val_acc": 50.0}
{"epoch": 41, "training_loss": 55.7991361618042, "training_acc": 53.75, "val_loss": 14.116286039352417, "val_acc": 50.0}
{"epoch": 42, "training_loss": 55.50153923034668, "training_acc": 53.75, "val_loss": 13.908332586288452, "val_acc": 50.0}
