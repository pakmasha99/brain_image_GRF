"main_optuna_fix_3.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3 --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 56.65622520446777, "training_acc": 52.5, "val_loss": 13.762943744659424, "val_acc": 55.0}
{"epoch": 1, "training_loss": 56.75351619720459, "training_acc": 45.0, "val_loss": 13.76594066619873, "val_acc": 55.0}
{"epoch": 2, "training_loss": 55.44306945800781, "training_acc": 52.5, "val_loss": 13.763974905014038, "val_acc": 55.0}
{"epoch": 3, "training_loss": 55.40784454345703, "training_acc": 52.5, "val_loss": 13.816741704940796, "val_acc": 55.0}
{"epoch": 4, "training_loss": 55.543212890625, "training_acc": 47.5, "val_loss": 13.767174482345581, "val_acc": 55.0}
{"epoch": 5, "training_loss": 55.36960220336914, "training_acc": 52.5, "val_loss": 13.786970376968384, "val_acc": 55.0}
{"epoch": 6, "training_loss": 55.74281692504883, "training_acc": 52.5, "val_loss": 13.76446008682251, "val_acc": 55.0}
{"epoch": 7, "training_loss": 55.468637466430664, "training_acc": 52.5, "val_loss": 13.805694580078125, "val_acc": 55.0}
{"epoch": 8, "training_loss": 55.32727241516113, "training_acc": 52.5, "val_loss": 14.005460739135742, "val_acc": 55.0}
{"epoch": 9, "training_loss": 55.83131790161133, "training_acc": 47.5, "val_loss": 14.11349892616272, "val_acc": 55.0}
{"epoch": 10, "training_loss": 56.00474166870117, "training_acc": 47.5, "val_loss": 13.834681510925293, "val_acc": 55.0}
{"epoch": 11, "training_loss": 55.189165115356445, "training_acc": 52.5, "val_loss": 13.81103515625, "val_acc": 55.0}
{"epoch": 12, "training_loss": 56.215813636779785, "training_acc": 52.5, "val_loss": 13.860167264938354, "val_acc": 55.0}
{"epoch": 13, "training_loss": 56.20246505737305, "training_acc": 52.5, "val_loss": 13.762959241867065, "val_acc": 55.0}
{"epoch": 14, "training_loss": 55.33409309387207, "training_acc": 52.5, "val_loss": 13.872369527816772, "val_acc": 55.0}
{"epoch": 15, "training_loss": 55.87018966674805, "training_acc": 47.5, "val_loss": 13.94785761833191, "val_acc": 55.0}
{"epoch": 16, "training_loss": 55.49298095703125, "training_acc": 47.5, "val_loss": 13.770688772201538, "val_acc": 55.0}
{"epoch": 17, "training_loss": 55.673020362854004, "training_acc": 52.5, "val_loss": 13.819025754928589, "val_acc": 55.0}
{"epoch": 18, "training_loss": 56.02427673339844, "training_acc": 52.5, "val_loss": 13.788625001907349, "val_acc": 55.0}
{"epoch": 19, "training_loss": 55.62855243682861, "training_acc": 52.5, "val_loss": 13.778339624404907, "val_acc": 55.0}
{"epoch": 20, "training_loss": 55.43436622619629, "training_acc": 52.5, "val_loss": 13.91443133354187, "val_acc": 55.0}
{"epoch": 21, "training_loss": 55.573055267333984, "training_acc": 47.5, "val_loss": 13.978112936019897, "val_acc": 55.0}
{"epoch": 22, "training_loss": 55.71894836425781, "training_acc": 47.5, "val_loss": 13.911590576171875, "val_acc": 55.0}
{"epoch": 23, "training_loss": 55.5052604675293, "training_acc": 50.0, "val_loss": 13.799612522125244, "val_acc": 55.0}
{"epoch": 24, "training_loss": 55.24197578430176, "training_acc": 52.5, "val_loss": 13.766831159591675, "val_acc": 55.0}
{"epoch": 25, "training_loss": 55.42844486236572, "training_acc": 52.5, "val_loss": 13.878487348556519, "val_acc": 55.0}
{"epoch": 26, "training_loss": 56.337371826171875, "training_acc": 52.5, "val_loss": 13.996965885162354, "val_acc": 55.0}
{"epoch": 27, "training_loss": 56.998229026794434, "training_acc": 52.5, "val_loss": 13.928804397583008, "val_acc": 55.0}
{"epoch": 28, "training_loss": 56.42513370513916, "training_acc": 52.5, "val_loss": 13.770366907119751, "val_acc": 55.0}
{"epoch": 29, "training_loss": 55.63577842712402, "training_acc": 52.5, "val_loss": 13.874180316925049, "val_acc": 55.0}
{"epoch": 30, "training_loss": 55.49343490600586, "training_acc": 47.5, "val_loss": 14.092373847961426, "val_acc": 55.0}
