"main_optuna_fix_3.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3 --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 56.479220390319824, "training_acc": 52.5, "val_loss": 13.77359390258789, "val_acc": 55.0}
{"epoch": 1, "training_loss": 56.45074653625488, "training_acc": 45.0, "val_loss": 13.76551628112793, "val_acc": 55.0}
{"epoch": 2, "training_loss": 55.45859909057617, "training_acc": 52.5, "val_loss": 13.762705326080322, "val_acc": 55.0}
{"epoch": 3, "training_loss": 55.46946334838867, "training_acc": 52.5, "val_loss": 13.763128519058228, "val_acc": 55.0}
{"epoch": 4, "training_loss": 55.408814430236816, "training_acc": 52.5, "val_loss": 13.808766603469849, "val_acc": 55.0}
{"epoch": 5, "training_loss": 55.3615608215332, "training_acc": 52.5, "val_loss": 13.855857849121094, "val_acc": 55.0}
{"epoch": 6, "training_loss": 55.89780330657959, "training_acc": 42.5, "val_loss": 13.762682676315308, "val_acc": 55.0}
{"epoch": 7, "training_loss": 55.45368957519531, "training_acc": 52.5, "val_loss": 13.857660293579102, "val_acc": 55.0}
{"epoch": 8, "training_loss": 56.29088497161865, "training_acc": 52.5, "val_loss": 13.767837285995483, "val_acc": 55.0}
{"epoch": 9, "training_loss": 55.34805679321289, "training_acc": 52.5, "val_loss": 13.94207239151001, "val_acc": 55.0}
{"epoch": 10, "training_loss": 55.78895568847656, "training_acc": 47.5, "val_loss": 14.060133695602417, "val_acc": 55.0}
{"epoch": 11, "training_loss": 55.83712673187256, "training_acc": 47.5, "val_loss": 13.813847303390503, "val_acc": 55.0}
{"epoch": 12, "training_loss": 55.430317878723145, "training_acc": 52.5, "val_loss": 13.765920400619507, "val_acc": 55.0}
{"epoch": 13, "training_loss": 55.55788230895996, "training_acc": 52.5, "val_loss": 13.764419555664062, "val_acc": 55.0}
{"epoch": 14, "training_loss": 55.4761905670166, "training_acc": 52.5, "val_loss": 13.781193494796753, "val_acc": 55.0}
{"epoch": 15, "training_loss": 55.60610389709473, "training_acc": 52.5, "val_loss": 13.790100812911987, "val_acc": 55.0}
{"epoch": 16, "training_loss": 55.29034423828125, "training_acc": 52.5, "val_loss": 13.767598867416382, "val_acc": 55.0}
{"epoch": 17, "training_loss": 55.74024677276611, "training_acc": 52.5, "val_loss": 13.785114288330078, "val_acc": 55.0}
{"epoch": 18, "training_loss": 55.68036365509033, "training_acc": 52.5, "val_loss": 13.763699531555176, "val_acc": 55.0}
{"epoch": 19, "training_loss": 55.3321475982666, "training_acc": 52.5, "val_loss": 13.839501142501831, "val_acc": 55.0}
{"epoch": 20, "training_loss": 55.48959255218506, "training_acc": 50.0, "val_loss": 13.952044248580933, "val_acc": 55.0}
{"epoch": 21, "training_loss": 55.65798568725586, "training_acc": 47.5, "val_loss": 13.887389898300171, "val_acc": 55.0}
{"epoch": 22, "training_loss": 55.45238494873047, "training_acc": 50.0, "val_loss": 13.78394603729248, "val_acc": 55.0}
{"epoch": 23, "training_loss": 55.32683181762695, "training_acc": 52.5, "val_loss": 13.764656782150269, "val_acc": 55.0}
{"epoch": 24, "training_loss": 55.50896453857422, "training_acc": 52.5, "val_loss": 13.798340559005737, "val_acc": 55.0}
{"epoch": 25, "training_loss": 55.845964431762695, "training_acc": 52.5, "val_loss": 13.832502365112305, "val_acc": 55.0}
{"epoch": 26, "training_loss": 56.15618896484375, "training_acc": 52.5, "val_loss": 13.813124895095825, "val_acc": 55.0}
{"epoch": 27, "training_loss": 55.93366050720215, "training_acc": 52.5, "val_loss": 13.785972595214844, "val_acc": 55.0}
{"epoch": 28, "training_loss": 55.64554405212402, "training_acc": 52.5, "val_loss": 13.774205446243286, "val_acc": 55.0}
{"epoch": 29, "training_loss": 55.4471378326416, "training_acc": 52.5, "val_loss": 13.925080299377441, "val_acc": 55.0}
{"epoch": 30, "training_loss": 55.64448547363281, "training_acc": 47.5, "val_loss": 13.964307308197021, "val_acc": 55.0}
{"epoch": 31, "training_loss": 55.78243160247803, "training_acc": 47.5, "val_loss": 13.92948865890503, "val_acc": 55.0}
{"epoch": 32, "training_loss": 55.611738204956055, "training_acc": 47.5, "val_loss": 13.94119143486023, "val_acc": 55.0}
{"epoch": 33, "training_loss": 55.62765312194824, "training_acc": 47.5, "val_loss": 13.9052414894104, "val_acc": 55.0}
{"epoch": 34, "training_loss": 55.510061264038086, "training_acc": 47.5, "val_loss": 13.814209699630737, "val_acc": 55.0}
{"epoch": 35, "training_loss": 55.471445083618164, "training_acc": 52.5, "val_loss": 13.772410154342651, "val_acc": 55.0}
{"epoch": 36, "training_loss": 55.37085723876953, "training_acc": 52.5, "val_loss": 13.77481460571289, "val_acc": 55.0}
{"epoch": 37, "training_loss": 55.3544807434082, "training_acc": 52.5, "val_loss": 13.805625438690186, "val_acc": 55.0}
{"epoch": 38, "training_loss": 55.46571636199951, "training_acc": 52.5, "val_loss": 13.832911252975464, "val_acc": 55.0}
{"epoch": 39, "training_loss": 55.38080596923828, "training_acc": 52.5, "val_loss": 13.78919005393982, "val_acc": 55.0}
{"epoch": 40, "training_loss": 55.50712966918945, "training_acc": 52.5, "val_loss": 13.782581090927124, "val_acc": 55.0}
{"epoch": 41, "training_loss": 55.31695556640625, "training_acc": 52.5, "val_loss": 13.861751556396484, "val_acc": 55.0}
{"epoch": 42, "training_loss": 55.61518955230713, "training_acc": 47.5, "val_loss": 13.931139707565308, "val_acc": 55.0}
{"epoch": 43, "training_loss": 55.60046577453613, "training_acc": 47.5, "val_loss": 13.86623740196228, "val_acc": 55.0}
{"epoch": 44, "training_loss": 55.46138572692871, "training_acc": 47.5, "val_loss": 13.805687427520752, "val_acc": 55.0}
{"epoch": 45, "training_loss": 55.3742561340332, "training_acc": 52.5, "val_loss": 13.78033995628357, "val_acc": 55.0}
{"epoch": 46, "training_loss": 55.361717224121094, "training_acc": 52.5, "val_loss": 13.777914047241211, "val_acc": 55.0}
