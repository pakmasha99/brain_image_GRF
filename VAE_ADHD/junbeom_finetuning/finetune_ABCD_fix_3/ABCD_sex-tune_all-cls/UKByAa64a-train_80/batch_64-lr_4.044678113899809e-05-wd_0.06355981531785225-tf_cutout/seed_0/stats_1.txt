"main_optuna_fix_3.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3 --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 55.52890586853027, "training_acc": 53.75, "val_loss": 13.849834203720093, "val_acc": 50.0}
{"epoch": 1, "training_loss": 55.5230598449707, "training_acc": 46.25, "val_loss": 14.005087614059448, "val_acc": 50.0}
{"epoch": 2, "training_loss": 55.324049949645996, "training_acc": 53.75, "val_loss": 14.180001020431519, "val_acc": 50.0}
{"epoch": 3, "training_loss": 55.451011657714844, "training_acc": 53.75, "val_loss": 13.871641159057617, "val_acc": 50.0}
{"epoch": 4, "training_loss": 55.06110191345215, "training_acc": 53.75, "val_loss": 13.88135552406311, "val_acc": 50.0}
{"epoch": 5, "training_loss": 55.76681995391846, "training_acc": 51.25, "val_loss": 13.988405466079712, "val_acc": 50.0}
{"epoch": 6, "training_loss": 55.187684059143066, "training_acc": 53.75, "val_loss": 14.256796836853027, "val_acc": 50.0}
{"epoch": 7, "training_loss": 55.49586296081543, "training_acc": 53.75, "val_loss": 13.961338996887207, "val_acc": 50.0}
{"epoch": 8, "training_loss": 55.068227767944336, "training_acc": 53.75, "val_loss": 13.856445550918579, "val_acc": 50.0}
{"epoch": 9, "training_loss": 55.110145568847656, "training_acc": 53.75, "val_loss": 13.838812112808228, "val_acc": 50.0}
{"epoch": 10, "training_loss": 55.45026779174805, "training_acc": 57.5, "val_loss": 13.860249519348145, "val_acc": 50.0}
{"epoch": 11, "training_loss": 54.859914779663086, "training_acc": 57.5, "val_loss": 14.194527864456177, "val_acc": 50.0}
{"epoch": 12, "training_loss": 55.29945373535156, "training_acc": 53.75, "val_loss": 14.116142988204956, "val_acc": 50.0}
{"epoch": 13, "training_loss": 55.189348220825195, "training_acc": 53.75, "val_loss": 13.91574740409851, "val_acc": 50.0}
{"epoch": 14, "training_loss": 54.89035606384277, "training_acc": 53.75, "val_loss": 14.078187942504883, "val_acc": 50.0}
{"epoch": 15, "training_loss": 54.70488357543945, "training_acc": 53.75, "val_loss": 14.718047380447388, "val_acc": 50.0}
{"epoch": 16, "training_loss": 56.9146089553833, "training_acc": 53.75, "val_loss": 14.232590198516846, "val_acc": 50.0}
{"epoch": 17, "training_loss": 55.05049228668213, "training_acc": 53.75, "val_loss": 13.896994590759277, "val_acc": 50.0}
{"epoch": 18, "training_loss": 54.63835525512695, "training_acc": 55.0, "val_loss": 13.821403980255127, "val_acc": 50.0}
{"epoch": 19, "training_loss": 55.120927810668945, "training_acc": 61.25, "val_loss": 13.826154470443726, "val_acc": 50.0}
{"epoch": 20, "training_loss": 55.39432239532471, "training_acc": 46.25, "val_loss": 13.792864084243774, "val_acc": 50.0}
{"epoch": 21, "training_loss": 54.924269676208496, "training_acc": 57.5, "val_loss": 13.879468441009521, "val_acc": 50.0}
{"epoch": 22, "training_loss": 54.54404067993164, "training_acc": 55.0, "val_loss": 14.229297637939453, "val_acc": 50.0}
{"epoch": 23, "training_loss": 54.74250888824463, "training_acc": 53.75, "val_loss": 14.641438722610474, "val_acc": 50.0}
{"epoch": 24, "training_loss": 56.042649269104004, "training_acc": 53.75, "val_loss": 14.344990253448486, "val_acc": 50.0}
{"epoch": 25, "training_loss": 55.173316955566406, "training_acc": 53.75, "val_loss": 13.997764587402344, "val_acc": 50.0}
{"epoch": 26, "training_loss": 54.89919662475586, "training_acc": 53.75, "val_loss": 13.87893557548523, "val_acc": 50.0}
{"epoch": 27, "training_loss": 54.75477981567383, "training_acc": 52.5, "val_loss": 13.891551494598389, "val_acc": 50.0}
{"epoch": 28, "training_loss": 54.899033546447754, "training_acc": 53.75, "val_loss": 13.86771559715271, "val_acc": 50.0}
{"epoch": 29, "training_loss": 54.55991458892822, "training_acc": 53.75, "val_loss": 13.843849897384644, "val_acc": 50.0}
{"epoch": 30, "training_loss": 54.65243625640869, "training_acc": 55.0, "val_loss": 13.860574960708618, "val_acc": 50.0}
{"epoch": 31, "training_loss": 54.39397621154785, "training_acc": 53.75, "val_loss": 14.409371614456177, "val_acc": 50.0}
{"epoch": 32, "training_loss": 54.591004371643066, "training_acc": 53.75, "val_loss": 13.926572799682617, "val_acc": 50.0}
{"epoch": 33, "training_loss": 54.46780776977539, "training_acc": 57.5, "val_loss": 13.791117668151855, "val_acc": 50.0}
{"epoch": 34, "training_loss": 55.15473556518555, "training_acc": 55.0, "val_loss": 13.78582239151001, "val_acc": 50.0}
{"epoch": 35, "training_loss": 54.78462791442871, "training_acc": 52.5, "val_loss": 13.762556314468384, "val_acc": 50.0}
{"epoch": 36, "training_loss": 54.79202461242676, "training_acc": 61.25, "val_loss": 13.740772008895874, "val_acc": 50.0}
{"epoch": 37, "training_loss": 54.71713638305664, "training_acc": 61.25, "val_loss": 13.763046264648438, "val_acc": 50.0}
{"epoch": 38, "training_loss": 55.015825271606445, "training_acc": 48.75, "val_loss": 13.70871901512146, "val_acc": 50.0}
{"epoch": 39, "training_loss": 53.795223236083984, "training_acc": 66.25, "val_loss": 13.9745032787323, "val_acc": 50.0}
