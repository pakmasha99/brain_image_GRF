"main_optuna_fix_3.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3 --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 56.22706604003906, "training_acc": 42.5, "val_loss": 13.826764822006226, "val_acc": 55.0}
{"epoch": 1, "training_loss": 55.69279479980469, "training_acc": 45.0, "val_loss": 13.891915082931519, "val_acc": 55.0}
{"epoch": 2, "training_loss": 55.382718086242676, "training_acc": 53.75, "val_loss": 13.862934112548828, "val_acc": 55.0}
{"epoch": 3, "training_loss": 56.786996841430664, "training_acc": 50.0, "val_loss": 13.822051286697388, "val_acc": 55.0}
{"epoch": 4, "training_loss": 55.85526657104492, "training_acc": 52.5, "val_loss": 13.820728063583374, "val_acc": 55.0}
{"epoch": 5, "training_loss": 55.38364791870117, "training_acc": 52.5, "val_loss": 14.220293760299683, "val_acc": 55.0}
{"epoch": 6, "training_loss": 56.43273162841797, "training_acc": 47.5, "val_loss": 13.743832111358643, "val_acc": 55.0}
{"epoch": 7, "training_loss": 55.28467559814453, "training_acc": 52.5, "val_loss": 14.014071226119995, "val_acc": 55.0}
{"epoch": 8, "training_loss": 57.00927734375, "training_acc": 52.5, "val_loss": 13.884947299957275, "val_acc": 55.0}
{"epoch": 9, "training_loss": 55.94483184814453, "training_acc": 52.5, "val_loss": 13.779706954956055, "val_acc": 55.0}
{"epoch": 10, "training_loss": 55.35791778564453, "training_acc": 52.5, "val_loss": 13.897632360458374, "val_acc": 55.0}
{"epoch": 11, "training_loss": 55.50274085998535, "training_acc": 48.75, "val_loss": 13.932396173477173, "val_acc": 55.0}
{"epoch": 12, "training_loss": 55.45770072937012, "training_acc": 51.25, "val_loss": 13.848071098327637, "val_acc": 55.0}
{"epoch": 13, "training_loss": 55.33274459838867, "training_acc": 52.5, "val_loss": 13.79646897315979, "val_acc": 55.0}
{"epoch": 14, "training_loss": 55.33914089202881, "training_acc": 52.5, "val_loss": 13.77678394317627, "val_acc": 55.0}
{"epoch": 15, "training_loss": 55.34759521484375, "training_acc": 52.5, "val_loss": 13.755487203598022, "val_acc": 55.0}
{"epoch": 16, "training_loss": 55.31410598754883, "training_acc": 52.5, "val_loss": 13.753207921981812, "val_acc": 55.0}
{"epoch": 17, "training_loss": 55.672746658325195, "training_acc": 52.5, "val_loss": 13.766742944717407, "val_acc": 55.0}
{"epoch": 18, "training_loss": 55.569114685058594, "training_acc": 52.5, "val_loss": 13.740419149398804, "val_acc": 55.0}
{"epoch": 19, "training_loss": 55.37152671813965, "training_acc": 52.5, "val_loss": 13.749788999557495, "val_acc": 55.0}
{"epoch": 20, "training_loss": 55.30698871612549, "training_acc": 52.5, "val_loss": 13.82206916809082, "val_acc": 55.0}
{"epoch": 21, "training_loss": 55.333359718322754, "training_acc": 51.25, "val_loss": 13.846008777618408, "val_acc": 55.0}
{"epoch": 22, "training_loss": 55.28093910217285, "training_acc": 53.75, "val_loss": 13.806018829345703, "val_acc": 55.0}
{"epoch": 23, "training_loss": 55.14874839782715, "training_acc": 56.25, "val_loss": 13.754310607910156, "val_acc": 55.0}
{"epoch": 24, "training_loss": 55.14264392852783, "training_acc": 52.5, "val_loss": 13.73376727104187, "val_acc": 55.0}
{"epoch": 25, "training_loss": 55.171756744384766, "training_acc": 52.5, "val_loss": 13.759126663208008, "val_acc": 55.0}
{"epoch": 26, "training_loss": 55.46617031097412, "training_acc": 52.5, "val_loss": 13.792688846588135, "val_acc": 55.0}
{"epoch": 27, "training_loss": 55.65350532531738, "training_acc": 52.5, "val_loss": 13.79342794418335, "val_acc": 55.0}
{"epoch": 28, "training_loss": 55.68744659423828, "training_acc": 52.5, "val_loss": 13.74660611152649, "val_acc": 55.0}
{"epoch": 29, "training_loss": 55.143232345581055, "training_acc": 52.5, "val_loss": 13.936723470687866, "val_acc": 55.0}
{"epoch": 30, "training_loss": 55.63407516479492, "training_acc": 47.5, "val_loss": 13.886942863464355, "val_acc": 55.0}
{"epoch": 31, "training_loss": 55.598093032836914, "training_acc": 42.5, "val_loss": 13.798370361328125, "val_acc": 55.0}
{"epoch": 32, "training_loss": 55.18363857269287, "training_acc": 52.5, "val_loss": 13.810112476348877, "val_acc": 55.0}
{"epoch": 33, "training_loss": 55.24560356140137, "training_acc": 50.0, "val_loss": 13.850623369216919, "val_acc": 55.0}
{"epoch": 34, "training_loss": 55.32553482055664, "training_acc": 47.5, "val_loss": 13.845555782318115, "val_acc": 55.0}
{"epoch": 35, "training_loss": 55.159828186035156, "training_acc": 55.0, "val_loss": 13.798402547836304, "val_acc": 55.0}
{"epoch": 36, "training_loss": 54.987324714660645, "training_acc": 55.0, "val_loss": 13.785613775253296, "val_acc": 55.0}
{"epoch": 37, "training_loss": 55.05996513366699, "training_acc": 52.5, "val_loss": 13.852201700210571, "val_acc": 55.0}
{"epoch": 38, "training_loss": 55.19969940185547, "training_acc": 61.25, "val_loss": 13.82093071937561, "val_acc": 55.0}
{"epoch": 39, "training_loss": 54.849690437316895, "training_acc": 66.25, "val_loss": 13.726595640182495, "val_acc": 55.0}
{"epoch": 40, "training_loss": 55.2988805770874, "training_acc": 52.5, "val_loss": 13.725252151489258, "val_acc": 55.0}
{"epoch": 41, "training_loss": 55.04450798034668, "training_acc": 52.5, "val_loss": 13.775004148483276, "val_acc": 55.0}
{"epoch": 42, "training_loss": 55.28067207336426, "training_acc": 56.25, "val_loss": 13.99295449256897, "val_acc": 55.0}
{"epoch": 43, "training_loss": 55.12620735168457, "training_acc": 48.75, "val_loss": 13.834460973739624, "val_acc": 55.0}
