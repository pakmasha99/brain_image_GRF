"main_optuna_fix_3.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3 --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 55.80552673339844, "training_acc": 52.5, "val_loss": 13.788837194442749, "val_acc": 55.0}
{"epoch": 1, "training_loss": 56.03061294555664, "training_acc": 45.0, "val_loss": 13.778237104415894, "val_acc": 55.0}
{"epoch": 2, "training_loss": 55.27458667755127, "training_acc": 52.5, "val_loss": 13.737120628356934, "val_acc": 55.0}
{"epoch": 3, "training_loss": 55.44358253479004, "training_acc": 52.5, "val_loss": 13.743597269058228, "val_acc": 55.0}
{"epoch": 4, "training_loss": 55.46767044067383, "training_acc": 52.5, "val_loss": 13.752697706222534, "val_acc": 55.0}
{"epoch": 5, "training_loss": 55.30636024475098, "training_acc": 52.5, "val_loss": 13.773695230484009, "val_acc": 55.0}
{"epoch": 6, "training_loss": 55.429033279418945, "training_acc": 52.5, "val_loss": 13.727973699569702, "val_acc": 55.0}
{"epoch": 7, "training_loss": 55.10363960266113, "training_acc": 52.5, "val_loss": 13.759695291519165, "val_acc": 55.0}
{"epoch": 8, "training_loss": 55.12678050994873, "training_acc": 53.75, "val_loss": 13.910757303237915, "val_acc": 55.0}
{"epoch": 9, "training_loss": 55.52528095245361, "training_acc": 47.5, "val_loss": 13.984802961349487, "val_acc": 55.0}
{"epoch": 10, "training_loss": 55.63650321960449, "training_acc": 47.5, "val_loss": 13.703489303588867, "val_acc": 55.0}
{"epoch": 11, "training_loss": 54.92526626586914, "training_acc": 52.5, "val_loss": 14.097213745117188, "val_acc": 55.0}
{"epoch": 12, "training_loss": 57.01804065704346, "training_acc": 52.5, "val_loss": 13.773726224899292, "val_acc": 55.0}
{"epoch": 13, "training_loss": 55.65893363952637, "training_acc": 52.5, "val_loss": 13.749380111694336, "val_acc": 55.0}
{"epoch": 14, "training_loss": 55.12580108642578, "training_acc": 52.5, "val_loss": 13.816219568252563, "val_acc": 55.0}
{"epoch": 15, "training_loss": 55.50430107116699, "training_acc": 46.25, "val_loss": 13.830009698867798, "val_acc": 55.0}
{"epoch": 16, "training_loss": 55.16903305053711, "training_acc": 62.5, "val_loss": 13.747999668121338, "val_acc": 55.0}
{"epoch": 17, "training_loss": 55.542463302612305, "training_acc": 52.5, "val_loss": 13.793123960494995, "val_acc": 55.0}
{"epoch": 18, "training_loss": 55.68507194519043, "training_acc": 52.5, "val_loss": 13.754857778549194, "val_acc": 55.0}
{"epoch": 19, "training_loss": 55.28746700286865, "training_acc": 52.5, "val_loss": 13.816248178482056, "val_acc": 55.0}
{"epoch": 20, "training_loss": 55.45119285583496, "training_acc": 50.0, "val_loss": 13.981715440750122, "val_acc": 55.0}
{"epoch": 21, "training_loss": 55.69135284423828, "training_acc": 47.5, "val_loss": 13.913609981536865, "val_acc": 55.0}
{"epoch": 22, "training_loss": 55.41731643676758, "training_acc": 47.5, "val_loss": 13.810399770736694, "val_acc": 55.0}
{"epoch": 23, "training_loss": 55.20456886291504, "training_acc": 55.0, "val_loss": 13.753294944763184, "val_acc": 55.0}
{"epoch": 24, "training_loss": 55.15901565551758, "training_acc": 52.5, "val_loss": 13.768805265426636, "val_acc": 55.0}
{"epoch": 25, "training_loss": 55.262704849243164, "training_acc": 52.5, "val_loss": 13.854001760482788, "val_acc": 55.0}
{"epoch": 26, "training_loss": 56.10978603363037, "training_acc": 52.5, "val_loss": 13.91497015953064, "val_acc": 55.0}
{"epoch": 27, "training_loss": 56.102094650268555, "training_acc": 52.5, "val_loss": 13.84272575378418, "val_acc": 55.0}
{"epoch": 28, "training_loss": 55.8837833404541, "training_acc": 52.5, "val_loss": 13.745659589767456, "val_acc": 55.0}
