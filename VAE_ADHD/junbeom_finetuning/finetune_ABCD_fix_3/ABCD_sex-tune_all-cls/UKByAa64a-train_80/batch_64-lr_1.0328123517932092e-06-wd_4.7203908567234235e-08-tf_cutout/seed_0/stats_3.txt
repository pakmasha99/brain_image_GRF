"main_optuna_fix_3.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3 --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 55.40163612365723, "training_acc": 52.5, "val_loss": 13.832365274429321, "val_acc": 55.0}
{"epoch": 1, "training_loss": 55.39666557312012, "training_acc": 53.75, "val_loss": 13.829665184020996, "val_acc": 55.0}
{"epoch": 2, "training_loss": 55.34777641296387, "training_acc": 53.75, "val_loss": 13.819464445114136, "val_acc": 55.0}
{"epoch": 3, "training_loss": 55.39844512939453, "training_acc": 52.5, "val_loss": 13.814080953598022, "val_acc": 55.0}
{"epoch": 4, "training_loss": 55.29402542114258, "training_acc": 53.75, "val_loss": 13.812475204467773, "val_acc": 55.0}
{"epoch": 5, "training_loss": 55.380059242248535, "training_acc": 53.75, "val_loss": 13.81029725074768, "val_acc": 55.0}
{"epoch": 6, "training_loss": 55.3500280380249, "training_acc": 51.25, "val_loss": 13.805465698242188, "val_acc": 55.0}
{"epoch": 7, "training_loss": 55.364439964294434, "training_acc": 52.5, "val_loss": 13.79929780960083, "val_acc": 55.0}
{"epoch": 8, "training_loss": 55.250529289245605, "training_acc": 52.5, "val_loss": 13.792575597763062, "val_acc": 55.0}
{"epoch": 9, "training_loss": 55.22539138793945, "training_acc": 52.5, "val_loss": 13.790082931518555, "val_acc": 55.0}
{"epoch": 10, "training_loss": 55.40769004821777, "training_acc": 52.5, "val_loss": 13.78709077835083, "val_acc": 55.0}
{"epoch": 11, "training_loss": 55.280165672302246, "training_acc": 52.5, "val_loss": 13.782638311386108, "val_acc": 55.0}
{"epoch": 12, "training_loss": 55.210286140441895, "training_acc": 52.5, "val_loss": 13.77951979637146, "val_acc": 55.0}
{"epoch": 13, "training_loss": 55.15176200866699, "training_acc": 53.75, "val_loss": 13.776088953018188, "val_acc": 55.0}
{"epoch": 14, "training_loss": 55.20675468444824, "training_acc": 52.5, "val_loss": 13.773277997970581, "val_acc": 55.0}
{"epoch": 15, "training_loss": 55.160627365112305, "training_acc": 52.5, "val_loss": 13.770157098770142, "val_acc": 55.0}
{"epoch": 16, "training_loss": 55.219475746154785, "training_acc": 52.5, "val_loss": 13.768318891525269, "val_acc": 55.0}
{"epoch": 17, "training_loss": 55.18238925933838, "training_acc": 52.5, "val_loss": 13.765591382980347, "val_acc": 55.0}
{"epoch": 18, "training_loss": 55.10759925842285, "training_acc": 52.5, "val_loss": 13.761086463928223, "val_acc": 55.0}
{"epoch": 19, "training_loss": 55.146888732910156, "training_acc": 52.5, "val_loss": 13.76004934310913, "val_acc": 55.0}
{"epoch": 20, "training_loss": 55.264896392822266, "training_acc": 52.5, "val_loss": 13.760946989059448, "val_acc": 55.0}
{"epoch": 21, "training_loss": 55.254995346069336, "training_acc": 52.5, "val_loss": 13.762458562850952, "val_acc": 55.0}
{"epoch": 22, "training_loss": 55.109679222106934, "training_acc": 52.5, "val_loss": 13.764486312866211, "val_acc": 55.0}
{"epoch": 23, "training_loss": 55.206024169921875, "training_acc": 52.5, "val_loss": 13.765673637390137, "val_acc": 55.0}
{"epoch": 24, "training_loss": 55.22310161590576, "training_acc": 52.5, "val_loss": 13.766036033630371, "val_acc": 55.0}
{"epoch": 25, "training_loss": 54.93590259552002, "training_acc": 52.5, "val_loss": 13.765058517456055, "val_acc": 55.0}
{"epoch": 26, "training_loss": 55.074357986450195, "training_acc": 52.5, "val_loss": 13.760031461715698, "val_acc": 55.0}
{"epoch": 27, "training_loss": 54.995399475097656, "training_acc": 52.5, "val_loss": 13.751564025878906, "val_acc": 55.0}
{"epoch": 28, "training_loss": 55.24604415893555, "training_acc": 52.5, "val_loss": 13.747333288192749, "val_acc": 55.0}
{"epoch": 29, "training_loss": 55.052019119262695, "training_acc": 52.5, "val_loss": 13.743776082992554, "val_acc": 55.0}
{"epoch": 30, "training_loss": 54.88663673400879, "training_acc": 52.5, "val_loss": 13.741682767868042, "val_acc": 55.0}
{"epoch": 31, "training_loss": 55.06256866455078, "training_acc": 52.5, "val_loss": 13.7405526638031, "val_acc": 55.0}
{"epoch": 32, "training_loss": 54.720985412597656, "training_acc": 53.75, "val_loss": 13.738260269165039, "val_acc": 55.0}
{"epoch": 33, "training_loss": 55.064327239990234, "training_acc": 52.5, "val_loss": 13.740254640579224, "val_acc": 55.0}
{"epoch": 34, "training_loss": 54.977962493896484, "training_acc": 52.5, "val_loss": 13.74625563621521, "val_acc": 55.0}
{"epoch": 35, "training_loss": 54.882317543029785, "training_acc": 52.5, "val_loss": 13.741239309310913, "val_acc": 55.0}
{"epoch": 36, "training_loss": 54.940189361572266, "training_acc": 52.5, "val_loss": 13.743027448654175, "val_acc": 55.0}
{"epoch": 37, "training_loss": 54.97926616668701, "training_acc": 52.5, "val_loss": 13.745620250701904, "val_acc": 55.0}
{"epoch": 38, "training_loss": 55.036184310913086, "training_acc": 52.5, "val_loss": 13.751071691513062, "val_acc": 55.0}
{"epoch": 39, "training_loss": 54.77540588378906, "training_acc": 53.75, "val_loss": 13.748375177383423, "val_acc": 55.0}
{"epoch": 40, "training_loss": 54.83763122558594, "training_acc": 52.5, "val_loss": 13.740366697311401, "val_acc": 55.0}
{"epoch": 41, "training_loss": 54.998321533203125, "training_acc": 52.5, "val_loss": 13.729339838027954, "val_acc": 55.0}
{"epoch": 42, "training_loss": 54.81963634490967, "training_acc": 52.5, "val_loss": 13.725522756576538, "val_acc": 55.0}
{"epoch": 43, "training_loss": 54.89579105377197, "training_acc": 52.5, "val_loss": 13.729140758514404, "val_acc": 55.0}
{"epoch": 44, "training_loss": 54.893677711486816, "training_acc": 52.5, "val_loss": 13.733892440795898, "val_acc": 55.0}
{"epoch": 45, "training_loss": 54.90028667449951, "training_acc": 52.5, "val_loss": 13.73964786529541, "val_acc": 55.0}
{"epoch": 46, "training_loss": 54.94745445251465, "training_acc": 51.25, "val_loss": 13.741756677627563, "val_acc": 55.0}
{"epoch": 47, "training_loss": 54.990989685058594, "training_acc": 53.75, "val_loss": 13.738013505935669, "val_acc": 55.0}
{"epoch": 48, "training_loss": 54.97101306915283, "training_acc": 53.75, "val_loss": 13.725271224975586, "val_acc": 55.0}
{"epoch": 49, "training_loss": 54.925536155700684, "training_acc": 53.75, "val_loss": 13.71463656425476, "val_acc": 55.0}
{"epoch": 50, "training_loss": 54.80113220214844, "training_acc": 53.75, "val_loss": 13.713781833648682, "val_acc": 55.0}
{"epoch": 51, "training_loss": 54.59649467468262, "training_acc": 53.75, "val_loss": 13.721420764923096, "val_acc": 55.0}
