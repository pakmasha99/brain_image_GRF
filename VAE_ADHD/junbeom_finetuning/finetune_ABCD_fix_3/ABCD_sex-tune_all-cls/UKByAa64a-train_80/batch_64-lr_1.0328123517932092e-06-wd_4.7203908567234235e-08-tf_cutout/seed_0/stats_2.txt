"main_optuna_fix_3.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3 --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 55.443989753723145, "training_acc": 52.5, "val_loss": 13.752386569976807, "val_acc": 55.0}
{"epoch": 1, "training_loss": 55.39047622680664, "training_acc": 52.5, "val_loss": 13.754812479019165, "val_acc": 55.0}
{"epoch": 2, "training_loss": 55.328078269958496, "training_acc": 52.5, "val_loss": 13.751705884933472, "val_acc": 55.0}
{"epoch": 3, "training_loss": 55.375861167907715, "training_acc": 52.5, "val_loss": 13.74727725982666, "val_acc": 55.0}
{"epoch": 4, "training_loss": 55.300156593322754, "training_acc": 52.5, "val_loss": 13.745932579040527, "val_acc": 55.0}
{"epoch": 5, "training_loss": 55.25236129760742, "training_acc": 52.5, "val_loss": 13.746676445007324, "val_acc": 55.0}
{"epoch": 6, "training_loss": 55.452773094177246, "training_acc": 52.5, "val_loss": 13.748667240142822, "val_acc": 55.0}
{"epoch": 7, "training_loss": 55.33217430114746, "training_acc": 52.5, "val_loss": 13.746410608291626, "val_acc": 55.0}
{"epoch": 8, "training_loss": 55.33846473693848, "training_acc": 52.5, "val_loss": 13.744875192642212, "val_acc": 55.0}
{"epoch": 9, "training_loss": 55.26910877227783, "training_acc": 52.5, "val_loss": 13.743759393692017, "val_acc": 55.0}
{"epoch": 10, "training_loss": 55.3382043838501, "training_acc": 52.5, "val_loss": 13.74049425125122, "val_acc": 55.0}
{"epoch": 11, "training_loss": 55.22264862060547, "training_acc": 52.5, "val_loss": 13.737753629684448, "val_acc": 55.0}
{"epoch": 12, "training_loss": 55.24186325073242, "training_acc": 52.5, "val_loss": 13.73752236366272, "val_acc": 55.0}
{"epoch": 13, "training_loss": 55.119632720947266, "training_acc": 52.5, "val_loss": 13.739038705825806, "val_acc": 55.0}
{"epoch": 14, "training_loss": 55.251108169555664, "training_acc": 52.5, "val_loss": 13.736885786056519, "val_acc": 55.0}
{"epoch": 15, "training_loss": 54.97494316101074, "training_acc": 52.5, "val_loss": 13.734606504440308, "val_acc": 55.0}
{"epoch": 16, "training_loss": 55.26580047607422, "training_acc": 52.5, "val_loss": 13.730542659759521, "val_acc": 55.0}
{"epoch": 17, "training_loss": 55.20937156677246, "training_acc": 52.5, "val_loss": 13.726674318313599, "val_acc": 55.0}
{"epoch": 18, "training_loss": 54.96413326263428, "training_acc": 52.5, "val_loss": 13.72630000114441, "val_acc": 55.0}
{"epoch": 19, "training_loss": 55.08253860473633, "training_acc": 52.5, "val_loss": 13.724628686904907, "val_acc": 55.0}
{"epoch": 20, "training_loss": 55.16180419921875, "training_acc": 52.5, "val_loss": 13.72156023979187, "val_acc": 55.0}
{"epoch": 21, "training_loss": 55.19773769378662, "training_acc": 52.5, "val_loss": 13.718949556350708, "val_acc": 55.0}
{"epoch": 22, "training_loss": 55.11844825744629, "training_acc": 52.5, "val_loss": 13.718487024307251, "val_acc": 55.0}
{"epoch": 23, "training_loss": 55.090718269348145, "training_acc": 52.5, "val_loss": 13.715982437133789, "val_acc": 55.0}
{"epoch": 24, "training_loss": 55.11262130737305, "training_acc": 52.5, "val_loss": 13.716758489608765, "val_acc": 55.0}
{"epoch": 25, "training_loss": 55.0296106338501, "training_acc": 52.5, "val_loss": 13.71728777885437, "val_acc": 55.0}
{"epoch": 26, "training_loss": 55.04461860656738, "training_acc": 52.5, "val_loss": 13.7136971950531, "val_acc": 55.0}
{"epoch": 27, "training_loss": 55.124603271484375, "training_acc": 52.5, "val_loss": 13.707982301712036, "val_acc": 55.0}
{"epoch": 28, "training_loss": 55.10920524597168, "training_acc": 52.5, "val_loss": 13.70607614517212, "val_acc": 55.0}
{"epoch": 29, "training_loss": 54.97284507751465, "training_acc": 52.5, "val_loss": 13.705997467041016, "val_acc": 55.0}
{"epoch": 30, "training_loss": 54.84907913208008, "training_acc": 52.5, "val_loss": 13.705192804336548, "val_acc": 55.0}
{"epoch": 31, "training_loss": 54.949100494384766, "training_acc": 52.5, "val_loss": 13.706663846969604, "val_acc": 55.0}
{"epoch": 32, "training_loss": 54.79466533660889, "training_acc": 52.5, "val_loss": 13.709558248519897, "val_acc": 55.0}
{"epoch": 33, "training_loss": 55.07778358459473, "training_acc": 52.5, "val_loss": 13.71561050415039, "val_acc": 55.0}
{"epoch": 34, "training_loss": 54.810211181640625, "training_acc": 52.5, "val_loss": 13.724539279937744, "val_acc": 55.0}
{"epoch": 35, "training_loss": 54.8834171295166, "training_acc": 52.5, "val_loss": 13.728493452072144, "val_acc": 55.0}
{"epoch": 36, "training_loss": 54.99763107299805, "training_acc": 52.5, "val_loss": 13.720906972885132, "val_acc": 55.0}
{"epoch": 37, "training_loss": 54.96188926696777, "training_acc": 52.5, "val_loss": 13.720277547836304, "val_acc": 55.0}
{"epoch": 38, "training_loss": 54.96900272369385, "training_acc": 52.5, "val_loss": 13.720536231994629, "val_acc": 55.0}
{"epoch": 39, "training_loss": 54.83212184906006, "training_acc": 52.5, "val_loss": 13.713802099227905, "val_acc": 55.0}
{"epoch": 40, "training_loss": 54.906368255615234, "training_acc": 52.5, "val_loss": 13.705110549926758, "val_acc": 55.0}
{"epoch": 41, "training_loss": 54.79054260253906, "training_acc": 52.5, "val_loss": 13.703384399414062, "val_acc": 55.0}
{"epoch": 42, "training_loss": 54.89615345001221, "training_acc": 52.5, "val_loss": 13.711122274398804, "val_acc": 55.0}
{"epoch": 43, "training_loss": 54.620100021362305, "training_acc": 52.5, "val_loss": 13.712221384048462, "val_acc": 55.0}
{"epoch": 44, "training_loss": 54.9306526184082, "training_acc": 52.5, "val_loss": 13.714520931243896, "val_acc": 55.0}
{"epoch": 45, "training_loss": 54.89653778076172, "training_acc": 52.5, "val_loss": 13.718578815460205, "val_acc": 55.0}
{"epoch": 46, "training_loss": 54.79717254638672, "training_acc": 52.5, "val_loss": 13.719481229782104, "val_acc": 55.0}
{"epoch": 47, "training_loss": 54.75654315948486, "training_acc": 52.5, "val_loss": 13.720041513442993, "val_acc": 55.0}
{"epoch": 48, "training_loss": 54.875566482543945, "training_acc": 52.5, "val_loss": 13.715105056762695, "val_acc": 55.0}
{"epoch": 49, "training_loss": 54.84013652801514, "training_acc": 52.5, "val_loss": 13.70572566986084, "val_acc": 55.0}
{"epoch": 50, "training_loss": 54.763336181640625, "training_acc": 52.5, "val_loss": 13.705108165740967, "val_acc": 55.0}
{"epoch": 51, "training_loss": 54.709200859069824, "training_acc": 52.5, "val_loss": 13.705018758773804, "val_acc": 55.0}
{"epoch": 52, "training_loss": 54.70013236999512, "training_acc": 52.5, "val_loss": 13.698440790176392, "val_acc": 55.0}
{"epoch": 53, "training_loss": 54.89231204986572, "training_acc": 52.5, "val_loss": 13.692106008529663, "val_acc": 55.0}
{"epoch": 54, "training_loss": 54.988229751586914, "training_acc": 52.5, "val_loss": 13.683334589004517, "val_acc": 55.0}
{"epoch": 55, "training_loss": 54.784706115722656, "training_acc": 52.5, "val_loss": 13.681129217147827, "val_acc": 55.0}
{"epoch": 56, "training_loss": 54.78444290161133, "training_acc": 52.5, "val_loss": 13.6849045753479, "val_acc": 55.0}
{"epoch": 57, "training_loss": 54.94526290893555, "training_acc": 52.5, "val_loss": 13.698866367340088, "val_acc": 55.0}
{"epoch": 58, "training_loss": 54.86980724334717, "training_acc": 52.5, "val_loss": 13.715757131576538, "val_acc": 55.0}
{"epoch": 59, "training_loss": 54.70710372924805, "training_acc": 52.5, "val_loss": 13.72691035270691, "val_acc": 55.0}
{"epoch": 60, "training_loss": 54.75119495391846, "training_acc": 52.5, "val_loss": 13.731375932693481, "val_acc": 55.0}
