"main_optuna_fix_3.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3 --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 55.3689079284668, "training_acc": 53.75, "val_loss": 13.903564214706421, "val_acc": 50.0}
{"epoch": 1, "training_loss": 55.33371543884277, "training_acc": 53.75, "val_loss": 13.908798694610596, "val_acc": 50.0}
{"epoch": 2, "training_loss": 55.220152854919434, "training_acc": 53.75, "val_loss": 13.913931846618652, "val_acc": 50.0}
{"epoch": 3, "training_loss": 55.294837951660156, "training_acc": 53.75, "val_loss": 13.916324377059937, "val_acc": 50.0}
{"epoch": 4, "training_loss": 55.233144760131836, "training_acc": 53.75, "val_loss": 13.909109830856323, "val_acc": 50.0}
{"epoch": 5, "training_loss": 55.222307205200195, "training_acc": 53.75, "val_loss": 13.908917903900146, "val_acc": 50.0}
{"epoch": 6, "training_loss": 55.167070388793945, "training_acc": 53.75, "val_loss": 13.908884525299072, "val_acc": 50.0}
{"epoch": 7, "training_loss": 55.1394157409668, "training_acc": 53.75, "val_loss": 13.909225463867188, "val_acc": 50.0}
{"epoch": 8, "training_loss": 55.23618221282959, "training_acc": 53.75, "val_loss": 13.91264796257019, "val_acc": 50.0}
{"epoch": 9, "training_loss": 55.035762786865234, "training_acc": 53.75, "val_loss": 13.915224075317383, "val_acc": 50.0}
{"epoch": 10, "training_loss": 55.279574394226074, "training_acc": 53.75, "val_loss": 13.915910720825195, "val_acc": 50.0}
{"epoch": 11, "training_loss": 55.00701141357422, "training_acc": 53.75, "val_loss": 13.920031785964966, "val_acc": 50.0}
{"epoch": 12, "training_loss": 55.10687446594238, "training_acc": 53.75, "val_loss": 13.926113843917847, "val_acc": 50.0}
{"epoch": 13, "training_loss": 55.09366703033447, "training_acc": 53.75, "val_loss": 13.93229365348816, "val_acc": 50.0}
{"epoch": 14, "training_loss": 55.248005867004395, "training_acc": 53.75, "val_loss": 13.937538862228394, "val_acc": 50.0}
{"epoch": 15, "training_loss": 55.02895545959473, "training_acc": 53.75, "val_loss": 13.944010734558105, "val_acc": 50.0}
{"epoch": 16, "training_loss": 55.259521484375, "training_acc": 53.75, "val_loss": 13.948477506637573, "val_acc": 50.0}
{"epoch": 17, "training_loss": 54.91175937652588, "training_acc": 53.75, "val_loss": 13.95037293434143, "val_acc": 50.0}
{"epoch": 18, "training_loss": 54.89796829223633, "training_acc": 53.75, "val_loss": 13.952317237854004, "val_acc": 50.0}
{"epoch": 19, "training_loss": 55.07705879211426, "training_acc": 53.75, "val_loss": 13.95287275314331, "val_acc": 50.0}
{"epoch": 20, "training_loss": 55.141236305236816, "training_acc": 53.75, "val_loss": 13.954752683639526, "val_acc": 50.0}
{"epoch": 21, "training_loss": 55.0346622467041, "training_acc": 53.75, "val_loss": 13.95864486694336, "val_acc": 50.0}
{"epoch": 22, "training_loss": 54.9908971786499, "training_acc": 53.75, "val_loss": 13.96354079246521, "val_acc": 50.0}
{"epoch": 23, "training_loss": 54.945003509521484, "training_acc": 53.75, "val_loss": 13.970657587051392, "val_acc": 50.0}
{"epoch": 24, "training_loss": 54.82759666442871, "training_acc": 53.75, "val_loss": 13.978255987167358, "val_acc": 50.0}
{"epoch": 25, "training_loss": 54.93490982055664, "training_acc": 53.75, "val_loss": 13.979915380477905, "val_acc": 50.0}
{"epoch": 26, "training_loss": 54.92091941833496, "training_acc": 53.75, "val_loss": 13.981183767318726, "val_acc": 50.0}
