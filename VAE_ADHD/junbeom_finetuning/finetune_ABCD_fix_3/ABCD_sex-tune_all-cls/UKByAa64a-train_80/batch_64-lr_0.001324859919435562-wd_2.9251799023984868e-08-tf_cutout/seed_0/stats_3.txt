"main_optuna_fix_3.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3 --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 76.39395141601562, "training_acc": 48.75, "val_loss": 297.69460678100586, "val_acc": 55.0}
{"epoch": 1, "training_loss": 1109.494384765625, "training_acc": 45.0, "val_loss": 19.376710653305054, "val_acc": 55.0}
{"epoch": 2, "training_loss": 85.3553695678711, "training_acc": 50.0, "val_loss": 13.765652179718018, "val_acc": 55.0}
{"epoch": 3, "training_loss": 56.088088035583496, "training_acc": 52.5, "val_loss": 13.774789571762085, "val_acc": 55.0}
{"epoch": 4, "training_loss": 56.354140281677246, "training_acc": 47.5, "val_loss": 13.779840469360352, "val_acc": 55.0}
{"epoch": 5, "training_loss": 55.35253429412842, "training_acc": 52.5, "val_loss": 13.870352506637573, "val_acc": 55.0}
{"epoch": 6, "training_loss": 56.35013771057129, "training_acc": 52.5, "val_loss": 13.901411294937134, "val_acc": 55.0}
{"epoch": 7, "training_loss": 55.542757987976074, "training_acc": 47.5, "val_loss": 13.807545900344849, "val_acc": 55.0}
{"epoch": 8, "training_loss": 55.75336837768555, "training_acc": 52.5, "val_loss": 13.90945553779602, "val_acc": 55.0}
{"epoch": 9, "training_loss": 55.59243965148926, "training_acc": 47.5, "val_loss": 14.06248927116394, "val_acc": 55.0}
{"epoch": 10, "training_loss": 55.823516845703125, "training_acc": 47.5, "val_loss": 13.82625937461853, "val_acc": 55.0}
{"epoch": 11, "training_loss": 55.253458976745605, "training_acc": 52.5, "val_loss": 13.770060539245605, "val_acc": 55.0}
{"epoch": 12, "training_loss": 55.86637496948242, "training_acc": 52.5, "val_loss": 13.77029299736023, "val_acc": 55.0}
{"epoch": 13, "training_loss": 55.62178039550781, "training_acc": 52.5, "val_loss": 13.798283338546753, "val_acc": 55.0}
{"epoch": 14, "training_loss": 55.32616710662842, "training_acc": 52.5, "val_loss": 13.883777856826782, "val_acc": 55.0}
{"epoch": 15, "training_loss": 55.77888774871826, "training_acc": 47.5, "val_loss": 13.843790292739868, "val_acc": 55.0}
{"epoch": 16, "training_loss": 55.27792739868164, "training_acc": 52.5, "val_loss": 13.769696950912476, "val_acc": 55.0}
{"epoch": 17, "training_loss": 55.52451133728027, "training_acc": 52.5, "val_loss": 13.76744031906128, "val_acc": 55.0}
{"epoch": 18, "training_loss": 55.54203987121582, "training_acc": 52.5, "val_loss": 13.763338327407837, "val_acc": 55.0}
{"epoch": 19, "training_loss": 55.39850616455078, "training_acc": 52.5, "val_loss": 13.776501417160034, "val_acc": 55.0}
{"epoch": 20, "training_loss": 55.37987804412842, "training_acc": 52.5, "val_loss": 13.800719976425171, "val_acc": 55.0}
{"epoch": 21, "training_loss": 55.35636329650879, "training_acc": 52.5, "val_loss": 13.8134765625, "val_acc": 55.0}
{"epoch": 22, "training_loss": 55.3783073425293, "training_acc": 52.5, "val_loss": 13.814929723739624, "val_acc": 55.0}
{"epoch": 23, "training_loss": 55.36760330200195, "training_acc": 52.5, "val_loss": 13.799501657485962, "val_acc": 55.0}
{"epoch": 24, "training_loss": 55.34336280822754, "training_acc": 52.5, "val_loss": 13.775949478149414, "val_acc": 55.0}
{"epoch": 25, "training_loss": 55.297247886657715, "training_acc": 52.5, "val_loss": 13.764835596084595, "val_acc": 55.0}
