"main_optuna_fix_3.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3 --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 72.6336898803711, "training_acc": 41.25, "val_loss": 619.3624496459961, "val_acc": 50.0}
{"epoch": 1, "training_loss": 1972.1266250610352, "training_acc": 46.25, "val_loss": 32.39795446395874, "val_acc": 50.0}
{"epoch": 2, "training_loss": 781.7713165283203, "training_acc": 51.25, "val_loss": 15.027096271514893, "val_acc": 50.0}
{"epoch": 3, "training_loss": 61.8064022064209, "training_acc": 46.25, "val_loss": 14.64414358139038, "val_acc": 50.0}
{"epoch": 4, "training_loss": 56.3695125579834, "training_acc": 53.75, "val_loss": 14.242852926254272, "val_acc": 50.0}
{"epoch": 5, "training_loss": 57.52627182006836, "training_acc": 46.25, "val_loss": 15.14495849609375, "val_acc": 50.0}
{"epoch": 6, "training_loss": 57.99829292297363, "training_acc": 53.75, "val_loss": 13.864020109176636, "val_acc": 50.0}
{"epoch": 7, "training_loss": 55.66656970977783, "training_acc": 51.25, "val_loss": 13.870624303817749, "val_acc": 50.0}
{"epoch": 8, "training_loss": 55.52622699737549, "training_acc": 53.75, "val_loss": 14.13172721862793, "val_acc": 50.0}
{"epoch": 9, "training_loss": 55.381507873535156, "training_acc": 53.75, "val_loss": 13.867111206054688, "val_acc": 50.0}
{"epoch": 10, "training_loss": 55.89833450317383, "training_acc": 46.25, "val_loss": 13.895546197891235, "val_acc": 50.0}
{"epoch": 11, "training_loss": 55.769521713256836, "training_acc": 48.75, "val_loss": 13.995107412338257, "val_acc": 50.0}
{"epoch": 12, "training_loss": 55.28881645202637, "training_acc": 53.75, "val_loss": 14.289809465408325, "val_acc": 50.0}
{"epoch": 13, "training_loss": 55.88365364074707, "training_acc": 53.75, "val_loss": 14.181605577468872, "val_acc": 50.0}
{"epoch": 14, "training_loss": 55.746788024902344, "training_acc": 53.75, "val_loss": 14.099767208099365, "val_acc": 50.0}
{"epoch": 15, "training_loss": 55.41869354248047, "training_acc": 53.75, "val_loss": 14.132964611053467, "val_acc": 50.0}
{"epoch": 16, "training_loss": 55.579429626464844, "training_acc": 53.75, "val_loss": 14.119454622268677, "val_acc": 50.0}
{"epoch": 17, "training_loss": 55.49256706237793, "training_acc": 53.75, "val_loss": 13.976473808288574, "val_acc": 50.0}
{"epoch": 18, "training_loss": 55.27959632873535, "training_acc": 53.75, "val_loss": 13.873003721237183, "val_acc": 50.0}
{"epoch": 19, "training_loss": 55.3140983581543, "training_acc": 53.75, "val_loss": 13.865517377853394, "val_acc": 50.0}
{"epoch": 20, "training_loss": 55.51150321960449, "training_acc": 46.25, "val_loss": 13.87521743774414, "val_acc": 50.0}
{"epoch": 21, "training_loss": 55.69685459136963, "training_acc": 46.25, "val_loss": 13.863391876220703, "val_acc": 50.0}
{"epoch": 22, "training_loss": 55.38184452056885, "training_acc": 51.25, "val_loss": 13.911312818527222, "val_acc": 50.0}
{"epoch": 23, "training_loss": 55.104952812194824, "training_acc": 53.75, "val_loss": 14.170522689819336, "val_acc": 50.0}
{"epoch": 24, "training_loss": 55.56762981414795, "training_acc": 53.75, "val_loss": 14.410457611083984, "val_acc": 50.0}
{"epoch": 25, "training_loss": 56.137489318847656, "training_acc": 53.75, "val_loss": 14.179725646972656, "val_acc": 50.0}
{"epoch": 26, "training_loss": 55.58533573150635, "training_acc": 53.75, "val_loss": 13.975056409835815, "val_acc": 50.0}
{"epoch": 27, "training_loss": 55.291887283325195, "training_acc": 53.75, "val_loss": 13.908360004425049, "val_acc": 50.0}
{"epoch": 28, "training_loss": 55.24772834777832, "training_acc": 53.75, "val_loss": 13.883270025253296, "val_acc": 50.0}
