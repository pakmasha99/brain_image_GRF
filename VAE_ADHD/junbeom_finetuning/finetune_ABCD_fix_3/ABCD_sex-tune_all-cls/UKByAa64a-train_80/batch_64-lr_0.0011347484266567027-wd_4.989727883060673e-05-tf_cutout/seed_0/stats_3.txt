"main_optuna_fix_3.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3 --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 71.19834899902344, "training_acc": 48.75, "val_loss": 35.669803619384766, "val_acc": 55.0}
{"epoch": 1, "training_loss": 611.4735412597656, "training_acc": 45.0, "val_loss": 15.929616689682007, "val_acc": 45.0}
{"epoch": 2, "training_loss": 69.40310668945312, "training_acc": 50.0, "val_loss": 17.489712238311768, "val_acc": 45.0}
{"epoch": 3, "training_loss": 65.93486213684082, "training_acc": 47.5, "val_loss": 13.852440118789673, "val_acc": 55.0}
{"epoch": 4, "training_loss": 60.452449798583984, "training_acc": 47.5, "val_loss": 16.330912113189697, "val_acc": 55.0}
{"epoch": 5, "training_loss": 66.23103141784668, "training_acc": 52.5, "val_loss": 13.769057989120483, "val_acc": 55.0}
{"epoch": 6, "training_loss": 55.5036563873291, "training_acc": 50.0, "val_loss": 13.780447244644165, "val_acc": 55.0}
{"epoch": 7, "training_loss": 55.46808052062988, "training_acc": 52.5, "val_loss": 13.776229619979858, "val_acc": 55.0}
{"epoch": 8, "training_loss": 55.34138202667236, "training_acc": 52.5, "val_loss": 14.183858633041382, "val_acc": 55.0}
{"epoch": 9, "training_loss": 56.365861892700195, "training_acc": 47.5, "val_loss": 14.146870374679565, "val_acc": 55.0}
{"epoch": 10, "training_loss": 55.8640832901001, "training_acc": 47.5, "val_loss": 13.766897916793823, "val_acc": 55.0}
{"epoch": 11, "training_loss": 55.40746307373047, "training_acc": 52.5, "val_loss": 14.05436396598816, "val_acc": 55.0}
{"epoch": 12, "training_loss": 57.053070068359375, "training_acc": 52.5, "val_loss": 13.765493631362915, "val_acc": 55.0}
{"epoch": 13, "training_loss": 55.520050048828125, "training_acc": 52.5, "val_loss": 13.884614706039429, "val_acc": 55.0}
{"epoch": 14, "training_loss": 55.51922798156738, "training_acc": 45.0, "val_loss": 13.883754014968872, "val_acc": 55.0}
{"epoch": 15, "training_loss": 55.587961196899414, "training_acc": 47.5, "val_loss": 13.795818090438843, "val_acc": 55.0}
{"epoch": 16, "training_loss": 55.12971115112305, "training_acc": 52.5, "val_loss": 13.867684602737427, "val_acc": 55.0}
{"epoch": 17, "training_loss": 56.704288482666016, "training_acc": 52.5, "val_loss": 13.808907270431519, "val_acc": 55.0}
{"epoch": 18, "training_loss": 55.61750316619873, "training_acc": 52.5, "val_loss": 13.807567358016968, "val_acc": 55.0}
{"epoch": 19, "training_loss": 55.26891040802002, "training_acc": 55.0, "val_loss": 14.009699821472168, "val_acc": 55.0}
{"epoch": 20, "training_loss": 55.85379123687744, "training_acc": 47.5, "val_loss": 13.986598253250122, "val_acc": 55.0}
{"epoch": 21, "training_loss": 55.72603893280029, "training_acc": 47.5, "val_loss": 13.845434188842773, "val_acc": 55.0}
{"epoch": 22, "training_loss": 55.388609886169434, "training_acc": 52.5, "val_loss": 13.786228895187378, "val_acc": 55.0}
{"epoch": 23, "training_loss": 55.337416648864746, "training_acc": 52.5, "val_loss": 13.763545751571655, "val_acc": 55.0}
{"epoch": 24, "training_loss": 55.41708564758301, "training_acc": 52.5, "val_loss": 13.766263723373413, "val_acc": 55.0}
{"epoch": 25, "training_loss": 55.520286560058594, "training_acc": 52.5, "val_loss": 13.800941705703735, "val_acc": 55.0}
{"epoch": 26, "training_loss": 55.84612274169922, "training_acc": 52.5, "val_loss": 13.843319416046143, "val_acc": 55.0}
{"epoch": 27, "training_loss": 56.128241539001465, "training_acc": 52.5, "val_loss": 13.807229995727539, "val_acc": 55.0}
{"epoch": 28, "training_loss": 55.774213790893555, "training_acc": 52.5, "val_loss": 13.763542175292969, "val_acc": 55.0}
{"epoch": 29, "training_loss": 55.46585750579834, "training_acc": 52.5, "val_loss": 13.83339524269104, "val_acc": 55.0}
{"epoch": 30, "training_loss": 55.3945894241333, "training_acc": 52.5, "val_loss": 13.882590532302856, "val_acc": 55.0}
{"epoch": 31, "training_loss": 55.52399921417236, "training_acc": 46.25, "val_loss": 13.90885591506958, "val_acc": 55.0}
{"epoch": 32, "training_loss": 55.55781364440918, "training_acc": 47.5, "val_loss": 13.935927152633667, "val_acc": 55.0}
{"epoch": 33, "training_loss": 55.60075759887695, "training_acc": 47.5, "val_loss": 13.879183530807495, "val_acc": 55.0}
{"epoch": 34, "training_loss": 55.44933891296387, "training_acc": 50.0, "val_loss": 13.80664348602295, "val_acc": 55.0}
{"epoch": 35, "training_loss": 55.422996520996094, "training_acc": 52.5, "val_loss": 13.780103921890259, "val_acc": 55.0}
{"epoch": 36, "training_loss": 55.369174003601074, "training_acc": 52.5, "val_loss": 13.774229288101196, "val_acc": 55.0}
{"epoch": 37, "training_loss": 55.37374305725098, "training_acc": 52.5, "val_loss": 13.767515420913696, "val_acc": 55.0}
{"epoch": 38, "training_loss": 55.38612079620361, "training_acc": 52.5, "val_loss": 13.767988681793213, "val_acc": 55.0}
{"epoch": 39, "training_loss": 55.38217639923096, "training_acc": 52.5, "val_loss": 13.768209218978882, "val_acc": 55.0}
{"epoch": 40, "training_loss": 55.379865646362305, "training_acc": 52.5, "val_loss": 13.772257566452026, "val_acc": 55.0}
{"epoch": 41, "training_loss": 55.35013008117676, "training_acc": 52.5, "val_loss": 13.795843124389648, "val_acc": 55.0}
{"epoch": 42, "training_loss": 55.380937576293945, "training_acc": 52.5, "val_loss": 13.831918239593506, "val_acc": 55.0}
