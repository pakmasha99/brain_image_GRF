"main_optuna_fix_3.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3 --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 68.33059120178223, "training_acc": 52.5, "val_loss": 492.94078826904297, "val_acc": 55.0}
{"epoch": 1, "training_loss": 1848.2519073486328, "training_acc": 45.0, "val_loss": 15.17154335975647, "val_acc": 45.0}
{"epoch": 2, "training_loss": 61.487308502197266, "training_acc": 50.0, "val_loss": 94.78218078613281, "val_acc": 45.0}
{"epoch": 3, "training_loss": 293.5726385116577, "training_acc": 50.0, "val_loss": 15.045077800750732, "val_acc": 55.0}
{"epoch": 4, "training_loss": 60.36384582519531, "training_acc": 52.5, "val_loss": 13.941618204116821, "val_acc": 55.0}
{"epoch": 5, "training_loss": 55.67555618286133, "training_acc": 47.5, "val_loss": 13.934963941574097, "val_acc": 55.0}
{"epoch": 6, "training_loss": 55.31797981262207, "training_acc": 57.5, "val_loss": 14.88093376159668, "val_acc": 55.0}
{"epoch": 7, "training_loss": 60.692856788635254, "training_acc": 52.5, "val_loss": 13.827173709869385, "val_acc": 55.0}
{"epoch": 8, "training_loss": 55.381263732910156, "training_acc": 52.5, "val_loss": 13.976582288742065, "val_acc": 55.0}
{"epoch": 9, "training_loss": 55.68310737609863, "training_acc": 47.5, "val_loss": 14.26449179649353, "val_acc": 55.0}
{"epoch": 10, "training_loss": 56.52255916595459, "training_acc": 47.5, "val_loss": 14.067414999008179, "val_acc": 55.0}
{"epoch": 11, "training_loss": 55.76924133300781, "training_acc": 47.5, "val_loss": 13.805704116821289, "val_acc": 55.0}
{"epoch": 12, "training_loss": 55.41388702392578, "training_acc": 52.5, "val_loss": 13.767929077148438, "val_acc": 55.0}
{"epoch": 13, "training_loss": 55.554128646850586, "training_acc": 52.5, "val_loss": 13.768552541732788, "val_acc": 55.0}
{"epoch": 14, "training_loss": 55.47709846496582, "training_acc": 52.5, "val_loss": 13.776854276657104, "val_acc": 55.0}
{"epoch": 15, "training_loss": 55.530845642089844, "training_acc": 52.5, "val_loss": 13.794649839401245, "val_acc": 55.0}
{"epoch": 16, "training_loss": 55.339494705200195, "training_acc": 52.5, "val_loss": 13.770489692687988, "val_acc": 55.0}
{"epoch": 17, "training_loss": 55.471245765686035, "training_acc": 52.5, "val_loss": 13.765312433242798, "val_acc": 55.0}
{"epoch": 18, "training_loss": 55.4648323059082, "training_acc": 52.5, "val_loss": 13.765586614608765, "val_acc": 55.0}
{"epoch": 19, "training_loss": 55.406904220581055, "training_acc": 52.5, "val_loss": 13.77515435218811, "val_acc": 55.0}
{"epoch": 20, "training_loss": 55.38272666931152, "training_acc": 52.5, "val_loss": 13.799155950546265, "val_acc": 55.0}
{"epoch": 21, "training_loss": 55.36824607849121, "training_acc": 52.5, "val_loss": 13.813861608505249, "val_acc": 55.0}
{"epoch": 22, "training_loss": 55.37691688537598, "training_acc": 52.5, "val_loss": 13.812071084976196, "val_acc": 55.0}
{"epoch": 23, "training_loss": 55.365193367004395, "training_acc": 52.5, "val_loss": 13.799101114273071, "val_acc": 55.0}
{"epoch": 24, "training_loss": 55.341182708740234, "training_acc": 52.5, "val_loss": 13.779767751693726, "val_acc": 55.0}
{"epoch": 25, "training_loss": 55.34218978881836, "training_acc": 52.5, "val_loss": 13.76507043838501, "val_acc": 55.0}
{"epoch": 26, "training_loss": 55.37760353088379, "training_acc": 52.5, "val_loss": 13.76564621925354, "val_acc": 55.0}
{"epoch": 27, "training_loss": 55.514132499694824, "training_acc": 52.5, "val_loss": 13.778399229049683, "val_acc": 55.0}
{"epoch": 28, "training_loss": 55.7260799407959, "training_acc": 52.5, "val_loss": 13.772927522659302, "val_acc": 55.0}
{"epoch": 29, "training_loss": 55.60248374938965, "training_acc": 52.5, "val_loss": 13.764766454696655, "val_acc": 55.0}
