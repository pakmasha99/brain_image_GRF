"main_optuna_fix_3.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3 --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 55.4687614440918, "training_acc": 52.5, "val_loss": 13.761013746261597, "val_acc": 55.0}
{"epoch": 1, "training_loss": 55.69526290893555, "training_acc": 52.5, "val_loss": 13.770664930343628, "val_acc": 55.0}
{"epoch": 2, "training_loss": 55.44727325439453, "training_acc": 52.5, "val_loss": 13.768179416656494, "val_acc": 55.0}
{"epoch": 3, "training_loss": 55.407586097717285, "training_acc": 52.5, "val_loss": 13.765805959701538, "val_acc": 55.0}
{"epoch": 4, "training_loss": 55.414031982421875, "training_acc": 52.5, "val_loss": 13.790124654769897, "val_acc": 55.0}
{"epoch": 5, "training_loss": 55.34541320800781, "training_acc": 52.5, "val_loss": 13.836055994033813, "val_acc": 55.0}
{"epoch": 6, "training_loss": 55.710113525390625, "training_acc": 42.5, "val_loss": 13.782800436019897, "val_acc": 55.0}
{"epoch": 7, "training_loss": 55.315988540649414, "training_acc": 52.5, "val_loss": 13.765254020690918, "val_acc": 55.0}
{"epoch": 8, "training_loss": 55.6461067199707, "training_acc": 52.5, "val_loss": 13.764117956161499, "val_acc": 55.0}
{"epoch": 9, "training_loss": 55.31766414642334, "training_acc": 52.5, "val_loss": 13.839727640151978, "val_acc": 55.0}
{"epoch": 10, "training_loss": 55.45404624938965, "training_acc": 50.0, "val_loss": 13.874735832214355, "val_acc": 55.0}
{"epoch": 11, "training_loss": 55.44337463378906, "training_acc": 52.5, "val_loss": 13.797099590301514, "val_acc": 55.0}
{"epoch": 12, "training_loss": 55.39517593383789, "training_acc": 52.5, "val_loss": 13.765395879745483, "val_acc": 55.0}
{"epoch": 13, "training_loss": 55.40996742248535, "training_acc": 52.5, "val_loss": 13.765748739242554, "val_acc": 55.0}
{"epoch": 14, "training_loss": 55.38944435119629, "training_acc": 52.5, "val_loss": 13.78117561340332, "val_acc": 55.0}
{"epoch": 15, "training_loss": 55.48820781707764, "training_acc": 52.5, "val_loss": 13.782681226730347, "val_acc": 55.0}
{"epoch": 16, "training_loss": 55.316118240356445, "training_acc": 52.5, "val_loss": 13.762959241867065, "val_acc": 55.0}
{"epoch": 17, "training_loss": 55.567745208740234, "training_acc": 52.5, "val_loss": 13.76924753189087, "val_acc": 55.0}
{"epoch": 18, "training_loss": 55.565385818481445, "training_acc": 52.5, "val_loss": 13.76285433769226, "val_acc": 55.0}
{"epoch": 19, "training_loss": 55.391408920288086, "training_acc": 52.5, "val_loss": 13.786172866821289, "val_acc": 55.0}
{"epoch": 20, "training_loss": 55.387935638427734, "training_acc": 52.5, "val_loss": 13.836030960083008, "val_acc": 55.0}
{"epoch": 21, "training_loss": 55.41874408721924, "training_acc": 52.5, "val_loss": 13.844636678695679, "val_acc": 55.0}
{"epoch": 22, "training_loss": 55.40837574005127, "training_acc": 52.5, "val_loss": 13.812425136566162, "val_acc": 55.0}
{"epoch": 23, "training_loss": 55.34899711608887, "training_acc": 52.5, "val_loss": 13.779662847518921, "val_acc": 55.0}
{"epoch": 24, "training_loss": 55.32538986206055, "training_acc": 52.5, "val_loss": 13.76296877861023, "val_acc": 55.0}
{"epoch": 25, "training_loss": 55.43129825592041, "training_acc": 52.5, "val_loss": 13.773530721664429, "val_acc": 55.0}
{"epoch": 26, "training_loss": 55.62751007080078, "training_acc": 52.5, "val_loss": 13.790816068649292, "val_acc": 55.0}
