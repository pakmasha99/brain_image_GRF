"main_optuna_fix_3.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3 --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 55.473923683166504, "training_acc": 53.75, "val_loss": 13.898324966430664, "val_acc": 50.0}
{"epoch": 1, "training_loss": 55.397605895996094, "training_acc": 53.75, "val_loss": 13.912742137908936, "val_acc": 50.0}
{"epoch": 2, "training_loss": 55.31919860839844, "training_acc": 53.75, "val_loss": 13.924241065979004, "val_acc": 50.0}
{"epoch": 3, "training_loss": 55.26260471343994, "training_acc": 53.75, "val_loss": 13.89527440071106, "val_acc": 50.0}
{"epoch": 4, "training_loss": 55.23481750488281, "training_acc": 53.75, "val_loss": 13.87580394744873, "val_acc": 50.0}
{"epoch": 5, "training_loss": 55.33261775970459, "training_acc": 53.75, "val_loss": 13.89774203300476, "val_acc": 50.0}
{"epoch": 6, "training_loss": 55.206021308898926, "training_acc": 53.75, "val_loss": 13.983891010284424, "val_acc": 50.0}
{"epoch": 7, "training_loss": 55.278926849365234, "training_acc": 53.75, "val_loss": 13.991813659667969, "val_acc": 50.0}
{"epoch": 8, "training_loss": 55.255130767822266, "training_acc": 53.75, "val_loss": 13.909382820129395, "val_acc": 50.0}
{"epoch": 9, "training_loss": 55.198161125183105, "training_acc": 53.75, "val_loss": 13.866535425186157, "val_acc": 50.0}
{"epoch": 10, "training_loss": 55.41495990753174, "training_acc": 51.25, "val_loss": 13.866064548492432, "val_acc": 50.0}
{"epoch": 11, "training_loss": 55.30029487609863, "training_acc": 53.75, "val_loss": 13.919111490249634, "val_acc": 50.0}
{"epoch": 12, "training_loss": 55.211517333984375, "training_acc": 53.75, "val_loss": 14.001717567443848, "val_acc": 50.0}
{"epoch": 13, "training_loss": 55.29326820373535, "training_acc": 53.75, "val_loss": 14.052706956863403, "val_acc": 50.0}
{"epoch": 14, "training_loss": 55.43792724609375, "training_acc": 53.75, "val_loss": 14.140945672988892, "val_acc": 50.0}
{"epoch": 15, "training_loss": 55.544010162353516, "training_acc": 53.75, "val_loss": 14.220342636108398, "val_acc": 50.0}
{"epoch": 16, "training_loss": 55.76922607421875, "training_acc": 53.75, "val_loss": 14.16994333267212, "val_acc": 50.0}
{"epoch": 17, "training_loss": 55.59020233154297, "training_acc": 53.75, "val_loss": 13.999847173690796, "val_acc": 50.0}
{"epoch": 18, "training_loss": 55.323676109313965, "training_acc": 53.75, "val_loss": 13.881469964981079, "val_acc": 50.0}
{"epoch": 19, "training_loss": 55.24724006652832, "training_acc": 53.75, "val_loss": 13.862888813018799, "val_acc": 50.0}
{"epoch": 20, "training_loss": 55.46771049499512, "training_acc": 46.25, "val_loss": 13.874139785766602, "val_acc": 50.0}
{"epoch": 21, "training_loss": 55.67446708679199, "training_acc": 46.25, "val_loss": 13.864400386810303, "val_acc": 50.0}
{"epoch": 22, "training_loss": 55.26850509643555, "training_acc": 53.75, "val_loss": 13.952412605285645, "val_acc": 50.0}
{"epoch": 23, "training_loss": 55.1683349609375, "training_acc": 53.75, "val_loss": 14.109400510787964, "val_acc": 50.0}
{"epoch": 24, "training_loss": 55.48122596740723, "training_acc": 53.75, "val_loss": 14.209973812103271, "val_acc": 50.0}
{"epoch": 25, "training_loss": 55.70974922180176, "training_acc": 53.75, "val_loss": 14.16319727897644, "val_acc": 50.0}
{"epoch": 26, "training_loss": 55.58493614196777, "training_acc": 53.75, "val_loss": 14.024709463119507, "val_acc": 50.0}
{"epoch": 27, "training_loss": 55.35359001159668, "training_acc": 53.75, "val_loss": 13.934904336929321, "val_acc": 50.0}
{"epoch": 28, "training_loss": 55.208160400390625, "training_acc": 53.75, "val_loss": 13.880667686462402, "val_acc": 50.0}
{"epoch": 29, "training_loss": 55.309913635253906, "training_acc": 53.75, "val_loss": 13.86306643486023, "val_acc": 50.0}
{"epoch": 30, "training_loss": 55.42337608337402, "training_acc": 53.75, "val_loss": 13.872851133346558, "val_acc": 50.0}
{"epoch": 31, "training_loss": 55.27223873138428, "training_acc": 53.75, "val_loss": 13.936609029769897, "val_acc": 50.0}
{"epoch": 32, "training_loss": 55.327335357666016, "training_acc": 53.75, "val_loss": 13.979638814926147, "val_acc": 50.0}
{"epoch": 33, "training_loss": 55.27619552612305, "training_acc": 53.75, "val_loss": 13.950585126876831, "val_acc": 50.0}
{"epoch": 34, "training_loss": 55.24626159667969, "training_acc": 53.75, "val_loss": 13.932090997695923, "val_acc": 50.0}
{"epoch": 35, "training_loss": 55.26001262664795, "training_acc": 53.75, "val_loss": 13.899224996566772, "val_acc": 50.0}
