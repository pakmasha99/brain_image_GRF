"main_optuna_fix_3.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3 --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 55.334062576293945, "training_acc": 52.5, "val_loss": 13.819159269332886, "val_acc": 55.0}
{"epoch": 1, "training_loss": 55.34431076049805, "training_acc": 52.5, "val_loss": 13.775883913040161, "val_acc": 55.0}
{"epoch": 2, "training_loss": 55.57120227813721, "training_acc": 52.5, "val_loss": 13.77063274383545, "val_acc": 55.0}
{"epoch": 3, "training_loss": 55.610984802246094, "training_acc": 52.5, "val_loss": 13.76530408859253, "val_acc": 55.0}
{"epoch": 4, "training_loss": 55.43174362182617, "training_acc": 52.5, "val_loss": 13.793421983718872, "val_acc": 55.0}
{"epoch": 5, "training_loss": 55.36594772338867, "training_acc": 52.5, "val_loss": 13.797110319137573, "val_acc": 55.0}
{"epoch": 6, "training_loss": 55.36456775665283, "training_acc": 52.5, "val_loss": 13.779362440109253, "val_acc": 55.0}
{"epoch": 7, "training_loss": 55.37346267700195, "training_acc": 52.5, "val_loss": 13.77320647239685, "val_acc": 55.0}
{"epoch": 8, "training_loss": 55.395142555236816, "training_acc": 52.5, "val_loss": 13.825397491455078, "val_acc": 55.0}
{"epoch": 9, "training_loss": 55.64923858642578, "training_acc": 45.0, "val_loss": 13.835554122924805, "val_acc": 55.0}
{"epoch": 10, "training_loss": 55.35742473602295, "training_acc": 52.5, "val_loss": 13.77044677734375, "val_acc": 55.0}
{"epoch": 11, "training_loss": 55.34457778930664, "training_acc": 52.5, "val_loss": 13.766671419143677, "val_acc": 55.0}
{"epoch": 12, "training_loss": 55.59905242919922, "training_acc": 52.5, "val_loss": 13.781360387802124, "val_acc": 55.0}
{"epoch": 13, "training_loss": 55.693695068359375, "training_acc": 52.5, "val_loss": 13.764899969100952, "val_acc": 55.0}
{"epoch": 14, "training_loss": 55.462270736694336, "training_acc": 52.5, "val_loss": 13.778696060180664, "val_acc": 55.0}
{"epoch": 15, "training_loss": 55.481932640075684, "training_acc": 52.5, "val_loss": 13.821241855621338, "val_acc": 55.0}
{"epoch": 16, "training_loss": 55.44765090942383, "training_acc": 52.5, "val_loss": 13.78351092338562, "val_acc": 55.0}
{"epoch": 17, "training_loss": 55.38071823120117, "training_acc": 52.5, "val_loss": 13.763943910598755, "val_acc": 55.0}
{"epoch": 18, "training_loss": 55.471181869506836, "training_acc": 52.5, "val_loss": 13.764619827270508, "val_acc": 55.0}
{"epoch": 19, "training_loss": 55.376755714416504, "training_acc": 52.5, "val_loss": 13.791313171386719, "val_acc": 55.0}
{"epoch": 20, "training_loss": 55.34073257446289, "training_acc": 52.5, "val_loss": 13.84785532951355, "val_acc": 55.0}
{"epoch": 21, "training_loss": 55.449480056762695, "training_acc": 50.0, "val_loss": 13.862050771713257, "val_acc": 55.0}
{"epoch": 22, "training_loss": 55.44993782043457, "training_acc": 56.25, "val_loss": 13.832216262817383, "val_acc": 55.0}
{"epoch": 23, "training_loss": 55.384222984313965, "training_acc": 52.5, "val_loss": 13.791584968566895, "val_acc": 55.0}
{"epoch": 24, "training_loss": 55.3721981048584, "training_acc": 52.5, "val_loss": 13.76685619354248, "val_acc": 55.0}
{"epoch": 25, "training_loss": 55.39977264404297, "training_acc": 52.5, "val_loss": 13.762930631637573, "val_acc": 55.0}
{"epoch": 26, "training_loss": 55.45693397521973, "training_acc": 52.5, "val_loss": 13.770774602890015, "val_acc": 55.0}
{"epoch": 27, "training_loss": 55.60646629333496, "training_acc": 52.5, "val_loss": 13.769029378890991, "val_acc": 55.0}
{"epoch": 28, "training_loss": 55.55157470703125, "training_acc": 52.5, "val_loss": 13.763246536254883, "val_acc": 55.0}
{"epoch": 29, "training_loss": 55.542880058288574, "training_acc": 52.5, "val_loss": 13.771218061447144, "val_acc": 55.0}
