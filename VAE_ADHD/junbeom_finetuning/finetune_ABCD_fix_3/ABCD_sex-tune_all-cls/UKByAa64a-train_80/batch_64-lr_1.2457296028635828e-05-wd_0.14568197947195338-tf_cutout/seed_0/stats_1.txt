"main_optuna_fix_3.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3 --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 55.26313400268555, "training_acc": 53.75, "val_loss": 14.018009901046753, "val_acc": 50.0}
{"epoch": 1, "training_loss": 55.39580726623535, "training_acc": 53.75, "val_loss": 13.923028707504272, "val_acc": 50.0}
{"epoch": 2, "training_loss": 55.09144401550293, "training_acc": 53.75, "val_loss": 14.020264148712158, "val_acc": 50.0}
{"epoch": 3, "training_loss": 55.142062187194824, "training_acc": 53.75, "val_loss": 14.072902202606201, "val_acc": 50.0}
{"epoch": 4, "training_loss": 55.14153289794922, "training_acc": 53.75, "val_loss": 13.999961614608765, "val_acc": 50.0}
{"epoch": 5, "training_loss": 55.0444974899292, "training_acc": 53.75, "val_loss": 13.948019742965698, "val_acc": 50.0}
{"epoch": 6, "training_loss": 55.102195739746094, "training_acc": 53.75, "val_loss": 13.924839496612549, "val_acc": 50.0}
{"epoch": 7, "training_loss": 54.7186336517334, "training_acc": 53.75, "val_loss": 13.937631845474243, "val_acc": 50.0}
{"epoch": 8, "training_loss": 54.74402332305908, "training_acc": 53.75, "val_loss": 13.99088740348816, "val_acc": 50.0}
{"epoch": 9, "training_loss": 54.44133377075195, "training_acc": 52.5, "val_loss": 13.909810781478882, "val_acc": 50.0}
{"epoch": 10, "training_loss": 55.045631408691406, "training_acc": 50.0, "val_loss": 13.82373571395874, "val_acc": 50.0}
{"epoch": 11, "training_loss": 55.09400749206543, "training_acc": 57.5, "val_loss": 13.820782899856567, "val_acc": 50.0}
{"epoch": 12, "training_loss": 55.13656044006348, "training_acc": 65.0, "val_loss": 13.845065832138062, "val_acc": 50.0}
{"epoch": 13, "training_loss": 54.90921401977539, "training_acc": 53.75, "val_loss": 13.954564332962036, "val_acc": 50.0}
{"epoch": 14, "training_loss": 54.72575378417969, "training_acc": 53.75, "val_loss": 14.203647375106812, "val_acc": 50.0}
{"epoch": 15, "training_loss": 54.94873905181885, "training_acc": 53.75, "val_loss": 14.52059268951416, "val_acc": 50.0}
{"epoch": 16, "training_loss": 56.46828842163086, "training_acc": 53.75, "val_loss": 14.37883973121643, "val_acc": 50.0}
{"epoch": 17, "training_loss": 55.25797080993652, "training_acc": 53.75, "val_loss": 14.061585664749146, "val_acc": 50.0}
{"epoch": 18, "training_loss": 54.64975929260254, "training_acc": 53.75, "val_loss": 13.86481523513794, "val_acc": 50.0}
{"epoch": 19, "training_loss": 54.46617317199707, "training_acc": 53.75, "val_loss": 13.818150758743286, "val_acc": 50.0}
{"epoch": 20, "training_loss": 54.87998580932617, "training_acc": 56.25, "val_loss": 13.83175253868103, "val_acc": 50.0}
{"epoch": 21, "training_loss": 54.97878456115723, "training_acc": 51.25, "val_loss": 13.788018226623535, "val_acc": 50.0}
{"epoch": 22, "training_loss": 54.338693618774414, "training_acc": 63.75, "val_loss": 13.910797834396362, "val_acc": 50.0}
{"epoch": 23, "training_loss": 52.925411224365234, "training_acc": 61.25, "val_loss": 14.91297960281372, "val_acc": 50.0}
{"epoch": 24, "training_loss": 56.096248626708984, "training_acc": 51.25, "val_loss": 14.465150833129883, "val_acc": 50.0}
{"epoch": 25, "training_loss": 53.988027572631836, "training_acc": 55.0, "val_loss": 13.902392387390137, "val_acc": 50.0}
{"epoch": 26, "training_loss": 54.34482192993164, "training_acc": 52.5, "val_loss": 13.771988153457642, "val_acc": 50.0}
{"epoch": 27, "training_loss": 54.44247817993164, "training_acc": 55.0, "val_loss": 13.75522494316101, "val_acc": 50.0}
{"epoch": 28, "training_loss": 54.34507942199707, "training_acc": 58.75, "val_loss": 13.753511905670166, "val_acc": 50.0}
{"epoch": 29, "training_loss": 53.773834228515625, "training_acc": 63.75, "val_loss": 13.736313581466675, "val_acc": 50.0}
{"epoch": 30, "training_loss": 52.37247371673584, "training_acc": 71.25, "val_loss": 13.995015621185303, "val_acc": 50.0}
