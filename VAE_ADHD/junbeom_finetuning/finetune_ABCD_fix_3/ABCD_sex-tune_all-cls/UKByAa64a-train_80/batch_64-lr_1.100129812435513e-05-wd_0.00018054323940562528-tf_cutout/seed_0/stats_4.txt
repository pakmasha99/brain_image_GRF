"main_optuna_fix_3.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3 --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 55.48471641540527, "training_acc": 51.25, "val_loss": 13.77534031867981, "val_acc": 55.0}
{"epoch": 1, "training_loss": 55.614723205566406, "training_acc": 52.5, "val_loss": 13.76372218132019, "val_acc": 55.0}
{"epoch": 2, "training_loss": 55.24461650848389, "training_acc": 52.5, "val_loss": 13.751518726348877, "val_acc": 55.0}
{"epoch": 3, "training_loss": 55.79377746582031, "training_acc": 52.5, "val_loss": 13.78962516784668, "val_acc": 55.0}
{"epoch": 4, "training_loss": 55.686354637145996, "training_acc": 52.5, "val_loss": 13.760532140731812, "val_acc": 55.0}
{"epoch": 5, "training_loss": 55.29476070404053, "training_acc": 52.5, "val_loss": 13.736332654953003, "val_acc": 55.0}
{"epoch": 6, "training_loss": 55.07218551635742, "training_acc": 52.5, "val_loss": 13.759740591049194, "val_acc": 55.0}
{"epoch": 7, "training_loss": 55.10195446014404, "training_acc": 52.5, "val_loss": 13.773317337036133, "val_acc": 55.0}
{"epoch": 8, "training_loss": 55.060194969177246, "training_acc": 52.5, "val_loss": 13.798624277114868, "val_acc": 55.0}
{"epoch": 9, "training_loss": 55.137447357177734, "training_acc": 58.75, "val_loss": 13.821474313735962, "val_acc": 55.0}
{"epoch": 10, "training_loss": 55.024770736694336, "training_acc": 67.5, "val_loss": 13.78641128540039, "val_acc": 55.0}
{"epoch": 11, "training_loss": 54.972015380859375, "training_acc": 62.5, "val_loss": 13.748506307601929, "val_acc": 55.0}
{"epoch": 12, "training_loss": 54.92155456542969, "training_acc": 52.5, "val_loss": 13.729299306869507, "val_acc": 55.0}
{"epoch": 13, "training_loss": 54.9018440246582, "training_acc": 52.5, "val_loss": 13.723477125167847, "val_acc": 55.0}
{"epoch": 14, "training_loss": 54.86928653717041, "training_acc": 52.5, "val_loss": 13.703391551971436, "val_acc": 55.0}
{"epoch": 15, "training_loss": 54.791940689086914, "training_acc": 52.5, "val_loss": 13.705745935440063, "val_acc": 55.0}
{"epoch": 16, "training_loss": 54.8695011138916, "training_acc": 52.5, "val_loss": 13.71070384979248, "val_acc": 55.0}
{"epoch": 17, "training_loss": 54.61436080932617, "training_acc": 52.5, "val_loss": 13.715626001358032, "val_acc": 55.0}
{"epoch": 18, "training_loss": 54.505953788757324, "training_acc": 52.5, "val_loss": 13.674553632736206, "val_acc": 55.0}
{"epoch": 19, "training_loss": 54.20101356506348, "training_acc": 52.5, "val_loss": 13.701080083847046, "val_acc": 55.0}
{"epoch": 20, "training_loss": 54.36427688598633, "training_acc": 66.25, "val_loss": 13.777363300323486, "val_acc": 55.0}
{"epoch": 21, "training_loss": 54.35796546936035, "training_acc": 63.75, "val_loss": 13.678046464920044, "val_acc": 55.0}
{"epoch": 22, "training_loss": 53.87741661071777, "training_acc": 70.0, "val_loss": 13.696651458740234, "val_acc": 55.0}
{"epoch": 23, "training_loss": 54.21664619445801, "training_acc": 52.5, "val_loss": 13.692829608917236, "val_acc": 55.0}
{"epoch": 24, "training_loss": 54.06471920013428, "training_acc": 52.5, "val_loss": 13.668327331542969, "val_acc": 55.0}
