"main_optuna_fix_3.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3 --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 55.63795185089111, "training_acc": 41.25, "val_loss": 13.816076517105103, "val_acc": 50.0}
{"epoch": 1, "training_loss": 55.53881645202637, "training_acc": 47.5, "val_loss": 13.830788135528564, "val_acc": 50.0}
{"epoch": 2, "training_loss": 55.260138511657715, "training_acc": 53.75, "val_loss": 14.007041454315186, "val_acc": 50.0}
{"epoch": 3, "training_loss": 55.22620105743408, "training_acc": 53.75, "val_loss": 14.119212627410889, "val_acc": 50.0}
{"epoch": 4, "training_loss": 55.365506172180176, "training_acc": 53.75, "val_loss": 14.026312828063965, "val_acc": 50.0}
{"epoch": 5, "training_loss": 55.26950454711914, "training_acc": 53.75, "val_loss": 13.929303884506226, "val_acc": 50.0}
{"epoch": 6, "training_loss": 55.113905906677246, "training_acc": 53.75, "val_loss": 13.891754150390625, "val_acc": 50.0}
{"epoch": 7, "training_loss": 55.085049629211426, "training_acc": 53.75, "val_loss": 13.893202543258667, "val_acc": 50.0}
{"epoch": 8, "training_loss": 55.0518856048584, "training_acc": 53.75, "val_loss": 13.885964155197144, "val_acc": 50.0}
{"epoch": 9, "training_loss": 54.85902404785156, "training_acc": 53.75, "val_loss": 13.832744359970093, "val_acc": 50.0}
{"epoch": 10, "training_loss": 55.07693576812744, "training_acc": 53.75, "val_loss": 13.802841901779175, "val_acc": 50.0}
{"epoch": 11, "training_loss": 54.66591262817383, "training_acc": 53.75, "val_loss": 13.797861337661743, "val_acc": 50.0}
{"epoch": 12, "training_loss": 54.86933708190918, "training_acc": 53.75, "val_loss": 13.824794292449951, "val_acc": 50.0}
{"epoch": 13, "training_loss": 54.62351894378662, "training_acc": 55.0, "val_loss": 13.912094831466675, "val_acc": 50.0}
{"epoch": 14, "training_loss": 54.72098922729492, "training_acc": 53.75, "val_loss": 14.066470861434937, "val_acc": 50.0}
{"epoch": 15, "training_loss": 54.74281883239746, "training_acc": 53.75, "val_loss": 14.210233688354492, "val_acc": 50.0}
{"epoch": 16, "training_loss": 55.90443229675293, "training_acc": 53.75, "val_loss": 14.111039638519287, "val_acc": 50.0}
{"epoch": 17, "training_loss": 54.732704162597656, "training_acc": 53.75, "val_loss": 13.872345685958862, "val_acc": 50.0}
{"epoch": 18, "training_loss": 54.322054862976074, "training_acc": 53.75, "val_loss": 13.754489421844482, "val_acc": 50.0}
{"epoch": 19, "training_loss": 54.49352169036865, "training_acc": 63.75, "val_loss": 13.745096921920776, "val_acc": 50.0}
{"epoch": 20, "training_loss": 54.9520320892334, "training_acc": 58.75, "val_loss": 13.74388575553894, "val_acc": 50.0}
{"epoch": 21, "training_loss": 54.854957580566406, "training_acc": 56.25, "val_loss": 13.706362247467041, "val_acc": 50.0}
{"epoch": 22, "training_loss": 54.31002330780029, "training_acc": 65.0, "val_loss": 13.87272834777832, "val_acc": 50.0}
{"epoch": 23, "training_loss": 53.615939140319824, "training_acc": 53.75, "val_loss": 14.227811098098755, "val_acc": 50.0}
{"epoch": 24, "training_loss": 54.67984485626221, "training_acc": 53.75, "val_loss": 14.419649839401245, "val_acc": 50.0}
{"epoch": 25, "training_loss": 55.17869758605957, "training_acc": 53.75, "val_loss": 14.215253591537476, "val_acc": 50.0}
{"epoch": 26, "training_loss": 55.002906799316406, "training_acc": 53.75, "val_loss": 13.888683319091797, "val_acc": 50.0}
{"epoch": 27, "training_loss": 54.520212173461914, "training_acc": 53.75, "val_loss": 13.75102162361145, "val_acc": 50.0}
{"epoch": 28, "training_loss": 54.26468086242676, "training_acc": 58.75, "val_loss": 13.700436353683472, "val_acc": 50.0}
{"epoch": 29, "training_loss": 54.32639694213867, "training_acc": 72.5, "val_loss": 13.660956621170044, "val_acc": 50.0}
{"epoch": 30, "training_loss": 53.57215690612793, "training_acc": 75.0, "val_loss": 13.752411603927612, "val_acc": 50.0}
{"epoch": 31, "training_loss": 54.45100402832031, "training_acc": 55.0, "val_loss": 13.96715521812439, "val_acc": 50.0}
{"epoch": 32, "training_loss": 54.429887771606445, "training_acc": 53.75, "val_loss": 14.020870923995972, "val_acc": 50.0}
{"epoch": 33, "training_loss": 54.96193790435791, "training_acc": 53.75, "val_loss": 13.911104202270508, "val_acc": 50.0}
{"epoch": 34, "training_loss": 54.3730525970459, "training_acc": 53.75, "val_loss": 13.804076910018921, "val_acc": 50.0}
{"epoch": 35, "training_loss": 53.6033992767334, "training_acc": 57.5, "val_loss": 13.673347234725952, "val_acc": 50.0}
{"epoch": 36, "training_loss": 54.050490379333496, "training_acc": 57.5, "val_loss": 13.58695387840271, "val_acc": 50.0}
{"epoch": 37, "training_loss": 54.51685810089111, "training_acc": 53.75, "val_loss": 13.796552419662476, "val_acc": 50.0}
{"epoch": 38, "training_loss": 55.430885314941406, "training_acc": 46.25, "val_loss": 13.650016784667969, "val_acc": 50.0}
