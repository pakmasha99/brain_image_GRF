"main_optuna_fix_3.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3 --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 55.38191032409668, "training_acc": 52.5, "val_loss": 13.756110668182373, "val_acc": 55.0}
{"epoch": 1, "training_loss": 55.631775856018066, "training_acc": 52.5, "val_loss": 13.781547546386719, "val_acc": 55.0}
{"epoch": 2, "training_loss": 55.401838302612305, "training_acc": 52.5, "val_loss": 13.748434782028198, "val_acc": 55.0}
{"epoch": 3, "training_loss": 55.320533752441406, "training_acc": 52.5, "val_loss": 13.741633892059326, "val_acc": 55.0}
{"epoch": 4, "training_loss": 55.51042175292969, "training_acc": 52.5, "val_loss": 13.73148798942566, "val_acc": 55.0}
{"epoch": 5, "training_loss": 55.34571933746338, "training_acc": 52.5, "val_loss": 13.752366304397583, "val_acc": 55.0}
{"epoch": 6, "training_loss": 55.33194637298584, "training_acc": 52.5, "val_loss": 13.762502670288086, "val_acc": 55.0}
{"epoch": 7, "training_loss": 55.11431884765625, "training_acc": 52.5, "val_loss": 13.745502233505249, "val_acc": 55.0}
{"epoch": 8, "training_loss": 55.13503170013428, "training_acc": 52.5, "val_loss": 13.74071478843689, "val_acc": 55.0}
{"epoch": 9, "training_loss": 55.084516525268555, "training_acc": 52.5, "val_loss": 13.738144636154175, "val_acc": 55.0}
{"epoch": 10, "training_loss": 55.16830062866211, "training_acc": 52.5, "val_loss": 13.748674392700195, "val_acc": 55.0}
{"epoch": 11, "training_loss": 54.91862487792969, "training_acc": 52.5, "val_loss": 13.746700286865234, "val_acc": 55.0}
{"epoch": 12, "training_loss": 54.99262237548828, "training_acc": 52.5, "val_loss": 13.740381002426147, "val_acc": 55.0}
{"epoch": 13, "training_loss": 54.663347244262695, "training_acc": 52.5, "val_loss": 13.732010126113892, "val_acc": 55.0}
{"epoch": 14, "training_loss": 54.76860046386719, "training_acc": 52.5, "val_loss": 13.710829019546509, "val_acc": 55.0}
{"epoch": 15, "training_loss": 54.50519371032715, "training_acc": 52.5, "val_loss": 13.669322729110718, "val_acc": 55.0}
{"epoch": 16, "training_loss": 54.75933837890625, "training_acc": 52.5, "val_loss": 13.710882663726807, "val_acc": 55.0}
{"epoch": 17, "training_loss": 55.17245864868164, "training_acc": 52.5, "val_loss": 13.733898401260376, "val_acc": 55.0}
{"epoch": 18, "training_loss": 54.72360897064209, "training_acc": 52.5, "val_loss": 13.63594651222229, "val_acc": 55.0}
{"epoch": 19, "training_loss": 54.030367851257324, "training_acc": 52.5, "val_loss": 13.66445541381836, "val_acc": 55.0}
{"epoch": 20, "training_loss": 54.5994987487793, "training_acc": 65.0, "val_loss": 13.797155618667603, "val_acc": 55.0}
{"epoch": 21, "training_loss": 54.73308563232422, "training_acc": 50.0, "val_loss": 13.665913343429565, "val_acc": 55.0}
{"epoch": 22, "training_loss": 53.889949798583984, "training_acc": 73.75, "val_loss": 13.668476343154907, "val_acc": 55.0}
{"epoch": 23, "training_loss": 54.54706573486328, "training_acc": 52.5, "val_loss": 13.681381940841675, "val_acc": 55.0}
{"epoch": 24, "training_loss": 54.493794441223145, "training_acc": 52.5, "val_loss": 13.638031482696533, "val_acc": 55.0}
{"epoch": 25, "training_loss": 54.21596908569336, "training_acc": 52.5, "val_loss": 13.543447256088257, "val_acc": 55.0}
{"epoch": 26, "training_loss": 54.338090896606445, "training_acc": 55.0, "val_loss": 13.488250970840454, "val_acc": 55.0}
{"epoch": 27, "training_loss": 53.318634033203125, "training_acc": 52.5, "val_loss": 13.541474342346191, "val_acc": 55.0}
{"epoch": 28, "training_loss": 53.859957695007324, "training_acc": 52.5, "val_loss": 13.397712707519531, "val_acc": 55.0}
{"epoch": 29, "training_loss": 52.76119422912598, "training_acc": 60.0, "val_loss": 13.446532487869263, "val_acc": 55.0}
{"epoch": 30, "training_loss": 52.61087226867676, "training_acc": 80.0, "val_loss": 13.461160659790039, "val_acc": 55.0}
{"epoch": 31, "training_loss": 53.23433971405029, "training_acc": 52.5, "val_loss": 13.333271741867065, "val_acc": 55.0}
{"epoch": 32, "training_loss": 51.40321350097656, "training_acc": 82.5, "val_loss": 13.615868091583252, "val_acc": 55.0}
{"epoch": 33, "training_loss": 53.19700622558594, "training_acc": 60.0, "val_loss": 13.270653486251831, "val_acc": 55.0}
{"epoch": 34, "training_loss": 51.494850158691406, "training_acc": 63.75, "val_loss": 13.426672220230103, "val_acc": 55.0}
{"epoch": 35, "training_loss": 50.206828117370605, "training_acc": 63.75, "val_loss": 13.689305782318115, "val_acc": 55.0}
{"epoch": 36, "training_loss": 53.39696025848389, "training_acc": 51.25, "val_loss": 13.364042043685913, "val_acc": 55.0}
{"epoch": 37, "training_loss": 52.04945087432861, "training_acc": 66.25, "val_loss": 13.86903166770935, "val_acc": 55.0}
{"epoch": 38, "training_loss": 51.17288398742676, "training_acc": 57.5, "val_loss": 13.223937749862671, "val_acc": 55.0}
{"epoch": 39, "training_loss": 48.978464126586914, "training_acc": 78.75, "val_loss": 13.243249654769897, "val_acc": 55.0}
{"epoch": 40, "training_loss": 49.38348579406738, "training_acc": 73.75, "val_loss": 13.240083456039429, "val_acc": 55.0}
{"epoch": 41, "training_loss": 46.364699363708496, "training_acc": 78.75, "val_loss": 13.642075061798096, "val_acc": 60.0}
{"epoch": 42, "training_loss": 47.87370777130127, "training_acc": 67.5, "val_loss": 13.990926742553711, "val_acc": 55.0}
{"epoch": 43, "training_loss": 52.398860931396484, "training_acc": 52.5, "val_loss": 12.897341251373291, "val_acc": 55.0}
{"epoch": 44, "training_loss": 44.750810623168945, "training_acc": 83.75, "val_loss": 12.886117696762085, "val_acc": 65.0}
{"epoch": 45, "training_loss": 43.72517204284668, "training_acc": 81.25, "val_loss": 13.389837741851807, "val_acc": 55.0}
{"epoch": 46, "training_loss": 46.709617614746094, "training_acc": 66.25, "val_loss": 13.158150911331177, "val_acc": 65.0}
{"epoch": 47, "training_loss": 42.07584857940674, "training_acc": 78.75, "val_loss": 12.905137538909912, "val_acc": 55.0}
{"epoch": 48, "training_loss": 44.68346405029297, "training_acc": 75.0, "val_loss": 12.400797605514526, "val_acc": 55.0}
{"epoch": 49, "training_loss": 40.111881256103516, "training_acc": 90.0, "val_loss": 12.51876950263977, "val_acc": 65.0}
{"epoch": 50, "training_loss": 37.72927284240723, "training_acc": 86.25, "val_loss": 12.314696311950684, "val_acc": 55.0}
{"epoch": 51, "training_loss": 37.08889579772949, "training_acc": 85.0, "val_loss": 13.969430923461914, "val_acc": 70.0}
