"main_optuna_fix_3.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3 --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 56.143680572509766, "training_acc": 45.0, "val_loss": 13.906258344650269, "val_acc": 55.0}
{"epoch": 1, "training_loss": 55.688316345214844, "training_acc": 48.75, "val_loss": 13.833917379379272, "val_acc": 55.0}
{"epoch": 2, "training_loss": 55.34020519256592, "training_acc": 53.75, "val_loss": 13.729461431503296, "val_acc": 55.0}
{"epoch": 3, "training_loss": 55.366668701171875, "training_acc": 52.5, "val_loss": 13.775399923324585, "val_acc": 55.0}
{"epoch": 4, "training_loss": 55.17222023010254, "training_acc": 52.5, "val_loss": 13.783077001571655, "val_acc": 55.0}
{"epoch": 5, "training_loss": 55.56025218963623, "training_acc": 52.5, "val_loss": 13.799482583999634, "val_acc": 55.0}
{"epoch": 6, "training_loss": 55.4095573425293, "training_acc": 52.5, "val_loss": 13.760814666748047, "val_acc": 55.0}
{"epoch": 7, "training_loss": 55.09213447570801, "training_acc": 52.5, "val_loss": 13.796213865280151, "val_acc": 55.0}
{"epoch": 8, "training_loss": 55.14345455169678, "training_acc": 53.75, "val_loss": 13.91946792602539, "val_acc": 55.0}
{"epoch": 9, "training_loss": 55.51440906524658, "training_acc": 47.5, "val_loss": 13.97923469543457, "val_acc": 55.0}
{"epoch": 10, "training_loss": 55.610087394714355, "training_acc": 47.5, "val_loss": 13.829845190048218, "val_acc": 55.0}
{"epoch": 11, "training_loss": 55.105223655700684, "training_acc": 55.0, "val_loss": 13.766007423400879, "val_acc": 55.0}
{"epoch": 12, "training_loss": 55.33475303649902, "training_acc": 52.5, "val_loss": 13.786338567733765, "val_acc": 55.0}
{"epoch": 13, "training_loss": 55.03951072692871, "training_acc": 52.5, "val_loss": 13.772062063217163, "val_acc": 55.0}
{"epoch": 14, "training_loss": 54.90696620941162, "training_acc": 52.5, "val_loss": 13.782700300216675, "val_acc": 55.0}
{"epoch": 15, "training_loss": 55.04547119140625, "training_acc": 56.25, "val_loss": 13.7799072265625, "val_acc": 55.0}
{"epoch": 16, "training_loss": 55.168999671936035, "training_acc": 52.5, "val_loss": 13.749241828918457, "val_acc": 55.0}
{"epoch": 17, "training_loss": 55.1522274017334, "training_acc": 52.5, "val_loss": 13.751354217529297, "val_acc": 55.0}
{"epoch": 18, "training_loss": 54.94705390930176, "training_acc": 52.5, "val_loss": 13.764151334762573, "val_acc": 55.0}
{"epoch": 19, "training_loss": 54.7854642868042, "training_acc": 52.5, "val_loss": 13.752241134643555, "val_acc": 55.0}
{"epoch": 20, "training_loss": 55.075528144836426, "training_acc": 52.5, "val_loss": 13.753162622451782, "val_acc": 55.0}
{"epoch": 21, "training_loss": 55.12840461730957, "training_acc": 52.5, "val_loss": 13.763325214385986, "val_acc": 55.0}
{"epoch": 22, "training_loss": 54.82178592681885, "training_acc": 48.75, "val_loss": 13.767178058624268, "val_acc": 55.0}
{"epoch": 23, "training_loss": 54.6444206237793, "training_acc": 53.75, "val_loss": 13.759454488754272, "val_acc": 55.0}
{"epoch": 24, "training_loss": 54.72361087799072, "training_acc": 53.75, "val_loss": 13.764200210571289, "val_acc": 55.0}
{"epoch": 25, "training_loss": 53.890658378601074, "training_acc": 53.75, "val_loss": 13.89121413230896, "val_acc": 55.0}
{"epoch": 26, "training_loss": 55.16114807128906, "training_acc": 52.5, "val_loss": 14.069547653198242, "val_acc": 55.0}
{"epoch": 27, "training_loss": 54.91883087158203, "training_acc": 52.5, "val_loss": 13.896431922912598, "val_acc": 55.0}
{"epoch": 28, "training_loss": 55.05460262298584, "training_acc": 52.5, "val_loss": 13.737090826034546, "val_acc": 55.0}
