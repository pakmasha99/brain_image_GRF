"main_optuna_fix_3.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3 --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 55.298519134521484, "training_acc": 52.5, "val_loss": 13.750437498092651, "val_acc": 55.0}
{"epoch": 1, "training_loss": 55.94258117675781, "training_acc": 45.0, "val_loss": 13.799389600753784, "val_acc": 55.0}
{"epoch": 2, "training_loss": 55.34715557098389, "training_acc": 52.5, "val_loss": 13.84856104850769, "val_acc": 55.0}
{"epoch": 3, "training_loss": 55.805660247802734, "training_acc": 52.5, "val_loss": 13.798450231552124, "val_acc": 55.0}
{"epoch": 4, "training_loss": 55.47269058227539, "training_acc": 52.5, "val_loss": 13.876427412033081, "val_acc": 55.0}
{"epoch": 5, "training_loss": 55.39973258972168, "training_acc": 46.25, "val_loss": 13.998416662216187, "val_acc": 55.0}
{"epoch": 6, "training_loss": 55.71521854400635, "training_acc": 47.5, "val_loss": 13.766849040985107, "val_acc": 55.0}
{"epoch": 7, "training_loss": 55.1515998840332, "training_acc": 52.5, "val_loss": 13.799837827682495, "val_acc": 55.0}
{"epoch": 8, "training_loss": 56.01054573059082, "training_acc": 52.5, "val_loss": 13.811711072921753, "val_acc": 55.0}
{"epoch": 9, "training_loss": 55.75464057922363, "training_acc": 52.5, "val_loss": 13.751229047775269, "val_acc": 55.0}
{"epoch": 10, "training_loss": 55.5233154296875, "training_acc": 52.5, "val_loss": 13.793582916259766, "val_acc": 55.0}
{"epoch": 11, "training_loss": 55.33745288848877, "training_acc": 52.5, "val_loss": 13.831510543823242, "val_acc": 55.0}
{"epoch": 12, "training_loss": 55.48026657104492, "training_acc": 45.0, "val_loss": 13.810383081436157, "val_acc": 55.0}
{"epoch": 13, "training_loss": 55.24541473388672, "training_acc": 53.75, "val_loss": 13.785852193832397, "val_acc": 55.0}
{"epoch": 14, "training_loss": 55.274017333984375, "training_acc": 52.5, "val_loss": 13.765497207641602, "val_acc": 55.0}
{"epoch": 15, "training_loss": 55.188955307006836, "training_acc": 52.5, "val_loss": 13.731284141540527, "val_acc": 55.0}
{"epoch": 16, "training_loss": 55.258277893066406, "training_acc": 52.5, "val_loss": 13.738718032836914, "val_acc": 55.0}
{"epoch": 17, "training_loss": 55.75917625427246, "training_acc": 52.5, "val_loss": 13.774288892745972, "val_acc": 55.0}
{"epoch": 18, "training_loss": 55.442931175231934, "training_acc": 52.5, "val_loss": 13.724645376205444, "val_acc": 55.0}
{"epoch": 19, "training_loss": 55.171953201293945, "training_acc": 52.5, "val_loss": 13.723413944244385, "val_acc": 55.0}
{"epoch": 20, "training_loss": 55.16179847717285, "training_acc": 52.5, "val_loss": 13.787362575531006, "val_acc": 55.0}
{"epoch": 21, "training_loss": 55.22046947479248, "training_acc": 52.5, "val_loss": 13.814337253570557, "val_acc": 55.0}
{"epoch": 22, "training_loss": 55.257808685302734, "training_acc": 62.5, "val_loss": 13.790724277496338, "val_acc": 55.0}
{"epoch": 23, "training_loss": 55.18394088745117, "training_acc": 58.75, "val_loss": 13.744137287139893, "val_acc": 55.0}
{"epoch": 24, "training_loss": 55.03233814239502, "training_acc": 53.75, "val_loss": 13.708378076553345, "val_acc": 55.0}
{"epoch": 25, "training_loss": 55.02463340759277, "training_acc": 52.5, "val_loss": 13.704979419708252, "val_acc": 55.0}
{"epoch": 26, "training_loss": 55.19638442993164, "training_acc": 52.5, "val_loss": 13.732771873474121, "val_acc": 55.0}
{"epoch": 27, "training_loss": 55.36535930633545, "training_acc": 52.5, "val_loss": 13.76939058303833, "val_acc": 55.0}
{"epoch": 28, "training_loss": 55.66855239868164, "training_acc": 52.5, "val_loss": 13.73461127281189, "val_acc": 55.0}
{"epoch": 29, "training_loss": 55.36538887023926, "training_acc": 52.5, "val_loss": 13.703936338424683, "val_acc": 55.0}
{"epoch": 30, "training_loss": 54.892062187194824, "training_acc": 51.25, "val_loss": 13.757656812667847, "val_acc": 55.0}
{"epoch": 31, "training_loss": 55.017107009887695, "training_acc": 55.0, "val_loss": 13.807438611984253, "val_acc": 55.0}
{"epoch": 32, "training_loss": 54.882545471191406, "training_acc": 72.5, "val_loss": 13.874609470367432, "val_acc": 55.0}
{"epoch": 33, "training_loss": 55.30080795288086, "training_acc": 47.5, "val_loss": 13.841933012008667, "val_acc": 55.0}
{"epoch": 34, "training_loss": 55.13292121887207, "training_acc": 51.25, "val_loss": 13.73016357421875, "val_acc": 55.0}
{"epoch": 35, "training_loss": 54.621395111083984, "training_acc": 60.0, "val_loss": 13.682849407196045, "val_acc": 55.0}
{"epoch": 36, "training_loss": 54.62487602233887, "training_acc": 53.75, "val_loss": 13.67080569267273, "val_acc": 55.0}
{"epoch": 37, "training_loss": 54.81175994873047, "training_acc": 52.5, "val_loss": 13.675464391708374, "val_acc": 55.0}
{"epoch": 38, "training_loss": 54.643120765686035, "training_acc": 55.0, "val_loss": 13.691257238388062, "val_acc": 55.0}
{"epoch": 39, "training_loss": 54.37131690979004, "training_acc": 63.75, "val_loss": 13.654431104660034, "val_acc": 55.0}
{"epoch": 40, "training_loss": 54.52763557434082, "training_acc": 55.0, "val_loss": 13.637837171554565, "val_acc": 55.0}
{"epoch": 41, "training_loss": 53.97468376159668, "training_acc": 61.25, "val_loss": 13.879858255386353, "val_acc": 55.0}
{"epoch": 42, "training_loss": 55.079965591430664, "training_acc": 47.5, "val_loss": 13.949764966964722, "val_acc": 55.0}
{"epoch": 43, "training_loss": 54.991451263427734, "training_acc": 50.0, "val_loss": 13.599973917007446, "val_acc": 55.0}
{"epoch": 44, "training_loss": 54.06028175354004, "training_acc": 57.5, "val_loss": 13.616650104522705, "val_acc": 55.0}
{"epoch": 45, "training_loss": 54.50642681121826, "training_acc": 53.75, "val_loss": 13.573706150054932, "val_acc": 55.0}
