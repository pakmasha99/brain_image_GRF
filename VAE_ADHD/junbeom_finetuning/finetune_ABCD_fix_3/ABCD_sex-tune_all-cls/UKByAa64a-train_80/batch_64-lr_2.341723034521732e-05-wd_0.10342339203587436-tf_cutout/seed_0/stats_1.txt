"main_optuna_fix_3.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3 --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 55.8994140625, "training_acc": 37.5, "val_loss": 13.847869634628296, "val_acc": 50.0}
{"epoch": 1, "training_loss": 55.592058181762695, "training_acc": 45.0, "val_loss": 13.886035680770874, "val_acc": 50.0}
{"epoch": 2, "training_loss": 55.17838954925537, "training_acc": 53.75, "val_loss": 14.049478769302368, "val_acc": 50.0}
{"epoch": 3, "training_loss": 55.3450813293457, "training_acc": 53.75, "val_loss": 14.048126935958862, "val_acc": 50.0}
{"epoch": 4, "training_loss": 55.22748565673828, "training_acc": 53.75, "val_loss": 13.927736282348633, "val_acc": 50.0}
{"epoch": 5, "training_loss": 55.23930644989014, "training_acc": 53.75, "val_loss": 13.883188962936401, "val_acc": 50.0}
{"epoch": 6, "training_loss": 55.152127265930176, "training_acc": 53.75, "val_loss": 13.955193758010864, "val_acc": 50.0}
{"epoch": 7, "training_loss": 55.03017616271973, "training_acc": 53.75, "val_loss": 14.11664605140686, "val_acc": 50.0}
{"epoch": 8, "training_loss": 55.12885665893555, "training_acc": 53.75, "val_loss": 13.888918161392212, "val_acc": 50.0}
{"epoch": 9, "training_loss": 54.65242290496826, "training_acc": 55.0, "val_loss": 13.851432800292969, "val_acc": 50.0}
{"epoch": 10, "training_loss": 55.360283851623535, "training_acc": 52.5, "val_loss": 13.872607946395874, "val_acc": 50.0}
{"epoch": 11, "training_loss": 54.91348743438721, "training_acc": 56.25, "val_loss": 14.081803560256958, "val_acc": 50.0}
{"epoch": 12, "training_loss": 55.23854637145996, "training_acc": 53.75, "val_loss": 14.117344617843628, "val_acc": 50.0}
{"epoch": 13, "training_loss": 55.3422155380249, "training_acc": 53.75, "val_loss": 13.995553255081177, "val_acc": 50.0}
{"epoch": 14, "training_loss": 55.19718551635742, "training_acc": 53.75, "val_loss": 14.00583267211914, "val_acc": 50.0}
{"epoch": 15, "training_loss": 55.03575420379639, "training_acc": 53.75, "val_loss": 14.171675443649292, "val_acc": 50.0}
{"epoch": 16, "training_loss": 55.62874698638916, "training_acc": 53.75, "val_loss": 14.14730429649353, "val_acc": 50.0}
{"epoch": 17, "training_loss": 55.04598426818848, "training_acc": 53.75, "val_loss": 13.90095591545105, "val_acc": 50.0}
{"epoch": 18, "training_loss": 54.7072696685791, "training_acc": 53.75, "val_loss": 13.81115198135376, "val_acc": 50.0}
{"epoch": 19, "training_loss": 54.83658027648926, "training_acc": 62.5, "val_loss": 13.821464776992798, "val_acc": 50.0}
{"epoch": 20, "training_loss": 55.29621887207031, "training_acc": 48.75, "val_loss": 13.794788122177124, "val_acc": 50.0}
{"epoch": 21, "training_loss": 54.89750003814697, "training_acc": 56.25, "val_loss": 13.802804946899414, "val_acc": 50.0}
{"epoch": 22, "training_loss": 54.241172790527344, "training_acc": 56.25, "val_loss": 14.25784945487976, "val_acc": 50.0}
{"epoch": 23, "training_loss": 54.909945487976074, "training_acc": 53.75, "val_loss": 14.543453454971313, "val_acc": 50.0}
{"epoch": 24, "training_loss": 55.995046615600586, "training_acc": 53.75, "val_loss": 14.297468662261963, "val_acc": 50.0}
{"epoch": 25, "training_loss": 55.15542125701904, "training_acc": 53.75, "val_loss": 13.948079347610474, "val_acc": 50.0}
{"epoch": 26, "training_loss": 55.0349702835083, "training_acc": 53.75, "val_loss": 13.791805505752563, "val_acc": 50.0}
{"epoch": 27, "training_loss": 54.69119834899902, "training_acc": 55.0, "val_loss": 13.76095175743103, "val_acc": 50.0}
{"epoch": 28, "training_loss": 54.78507709503174, "training_acc": 60.0, "val_loss": 13.745297193527222, "val_acc": 50.0}
{"epoch": 29, "training_loss": 54.59506607055664, "training_acc": 71.25, "val_loss": 13.73224139213562, "val_acc": 50.0}
{"epoch": 30, "training_loss": 54.08983039855957, "training_acc": 73.75, "val_loss": 13.808743953704834, "val_acc": 50.0}
{"epoch": 31, "training_loss": 54.30780601501465, "training_acc": 53.75, "val_loss": 14.077706336975098, "val_acc": 50.0}
{"epoch": 32, "training_loss": 54.35837745666504, "training_acc": 53.75, "val_loss": 13.98693561553955, "val_acc": 50.0}
{"epoch": 33, "training_loss": 54.611000061035156, "training_acc": 53.75, "val_loss": 13.71857762336731, "val_acc": 50.0}
{"epoch": 34, "training_loss": 53.98256015777588, "training_acc": 66.25, "val_loss": 13.694895505905151, "val_acc": 50.0}
{"epoch": 35, "training_loss": 53.58833026885986, "training_acc": 68.75, "val_loss": 13.659400939941406, "val_acc": 50.0}
{"epoch": 36, "training_loss": 54.03280258178711, "training_acc": 67.5, "val_loss": 13.665876388549805, "val_acc": 50.0}
{"epoch": 37, "training_loss": 53.95246887207031, "training_acc": 62.5, "val_loss": 13.708034753799438, "val_acc": 50.0}
{"epoch": 38, "training_loss": 54.49650955200195, "training_acc": 51.25, "val_loss": 13.619979619979858, "val_acc": 50.0}
{"epoch": 39, "training_loss": 53.13142204284668, "training_acc": 78.75, "val_loss": 13.906902074813843, "val_acc": 50.0}
{"epoch": 40, "training_loss": 53.58815574645996, "training_acc": 53.75, "val_loss": 13.607537746429443, "val_acc": 50.0}
{"epoch": 41, "training_loss": 51.81685829162598, "training_acc": 70.0, "val_loss": 14.021024703979492, "val_acc": 55.0}
{"epoch": 42, "training_loss": 56.19919013977051, "training_acc": 47.5, "val_loss": 13.778524398803711, "val_acc": 50.0}
{"epoch": 43, "training_loss": 53.428266525268555, "training_acc": 55.0, "val_loss": 14.252909421920776, "val_acc": 50.0}
{"epoch": 44, "training_loss": 53.56857681274414, "training_acc": 53.75, "val_loss": 14.362964630126953, "val_acc": 50.0}
{"epoch": 45, "training_loss": 53.60042762756348, "training_acc": 53.75, "val_loss": 13.581845760345459, "val_acc": 50.0}
{"epoch": 46, "training_loss": 53.1666316986084, "training_acc": 71.25, "val_loss": 13.708175420761108, "val_acc": 50.0}
{"epoch": 47, "training_loss": 53.36957359313965, "training_acc": 58.75, "val_loss": 13.741210699081421, "val_acc": 50.0}
{"epoch": 48, "training_loss": 52.20075225830078, "training_acc": 57.5, "val_loss": 15.038626194000244, "val_acc": 50.0}
{"epoch": 49, "training_loss": 56.22792148590088, "training_acc": 53.75, "val_loss": 14.025977849960327, "val_acc": 50.0}
{"epoch": 50, "training_loss": 52.42325210571289, "training_acc": 55.0, "val_loss": 13.702863454818726, "val_acc": 50.0}
{"epoch": 51, "training_loss": 52.93254089355469, "training_acc": 63.75, "val_loss": 13.754581212997437, "val_acc": 50.0}
{"epoch": 52, "training_loss": 52.329182624816895, "training_acc": 63.75, "val_loss": 13.581622838973999, "val_acc": 50.0}
{"epoch": 53, "training_loss": 51.11747932434082, "training_acc": 72.5, "val_loss": 13.822157382965088, "val_acc": 50.0}
{"epoch": 54, "training_loss": 51.772891998291016, "training_acc": 53.75, "val_loss": 14.052923917770386, "val_acc": 50.0}
{"epoch": 55, "training_loss": 51.54755973815918, "training_acc": 60.0, "val_loss": 13.524395227432251, "val_acc": 50.0}
{"epoch": 56, "training_loss": 50.293678283691406, "training_acc": 68.75, "val_loss": 13.504500389099121, "val_acc": 50.0}
{"epoch": 57, "training_loss": 49.10567665100098, "training_acc": 73.75, "val_loss": 13.504602909088135, "val_acc": 50.0}
