"main_optuna_fix_3.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3 --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 55.533477783203125, "training_acc": 45.0, "val_loss": 13.78726601600647, "val_acc": 55.0}
{"epoch": 1, "training_loss": 55.461140632629395, "training_acc": 46.25, "val_loss": 13.806138038635254, "val_acc": 55.0}
{"epoch": 2, "training_loss": 55.422218322753906, "training_acc": 52.5, "val_loss": 13.822602033615112, "val_acc": 55.0}
{"epoch": 3, "training_loss": 55.383880615234375, "training_acc": 52.5, "val_loss": 13.759359121322632, "val_acc": 55.0}
{"epoch": 4, "training_loss": 55.45763683319092, "training_acc": 52.5, "val_loss": 13.779966831207275, "val_acc": 55.0}
{"epoch": 5, "training_loss": 55.33141326904297, "training_acc": 52.5, "val_loss": 13.83387804031372, "val_acc": 55.0}
{"epoch": 6, "training_loss": 55.4664249420166, "training_acc": 52.5, "val_loss": 13.75706434249878, "val_acc": 55.0}
{"epoch": 7, "training_loss": 54.85231590270996, "training_acc": 53.75, "val_loss": 13.755078315734863, "val_acc": 55.0}
{"epoch": 8, "training_loss": 54.859832763671875, "training_acc": 52.5, "val_loss": 13.800859451293945, "val_acc": 55.0}
{"epoch": 9, "training_loss": 54.95241165161133, "training_acc": 61.25, "val_loss": 13.780521154403687, "val_acc": 55.0}
{"epoch": 10, "training_loss": 54.90503120422363, "training_acc": 50.0, "val_loss": 14.03422236442566, "val_acc": 55.0}
{"epoch": 11, "training_loss": 56.05922508239746, "training_acc": 53.75, "val_loss": 13.855241537094116, "val_acc": 55.0}
{"epoch": 12, "training_loss": 54.6124153137207, "training_acc": 52.5, "val_loss": 13.887273073196411, "val_acc": 55.0}
{"epoch": 13, "training_loss": 54.979336738586426, "training_acc": 52.5, "val_loss": 14.147541522979736, "val_acc": 55.0}
{"epoch": 14, "training_loss": 56.264357566833496, "training_acc": 46.25, "val_loss": 13.962395191192627, "val_acc": 55.0}
{"epoch": 15, "training_loss": 54.82759666442871, "training_acc": 56.25, "val_loss": 13.7327241897583, "val_acc": 55.0}
{"epoch": 16, "training_loss": 54.335514068603516, "training_acc": 52.5, "val_loss": 14.310363531112671, "val_acc": 55.0}
{"epoch": 17, "training_loss": 57.23698806762695, "training_acc": 52.5, "val_loss": 14.326413869857788, "val_acc": 55.0}
{"epoch": 18, "training_loss": 55.397034645080566, "training_acc": 52.5, "val_loss": 13.73394250869751, "val_acc": 55.0}
{"epoch": 19, "training_loss": 54.084001541137695, "training_acc": 55.0, "val_loss": 13.867924213409424, "val_acc": 55.0}
{"epoch": 20, "training_loss": 55.39686965942383, "training_acc": 50.0, "val_loss": 14.106191396713257, "val_acc": 55.0}
{"epoch": 21, "training_loss": 55.84844779968262, "training_acc": 47.5, "val_loss": 14.080764055252075, "val_acc": 55.0}
{"epoch": 22, "training_loss": 55.80425453186035, "training_acc": 47.5, "val_loss": 13.941679000854492, "val_acc": 55.0}
{"epoch": 23, "training_loss": 55.34381675720215, "training_acc": 47.5, "val_loss": 13.814021348953247, "val_acc": 55.0}
{"epoch": 24, "training_loss": 54.901187896728516, "training_acc": 65.0, "val_loss": 13.741157054901123, "val_acc": 55.0}
{"epoch": 25, "training_loss": 54.34564971923828, "training_acc": 52.5, "val_loss": 13.76366376876831, "val_acc": 55.0}
{"epoch": 26, "training_loss": 54.88788604736328, "training_acc": 52.5, "val_loss": 13.841966390609741, "val_acc": 55.0}
{"epoch": 27, "training_loss": 54.640432357788086, "training_acc": 52.5, "val_loss": 13.841737508773804, "val_acc": 55.0}
{"epoch": 28, "training_loss": 55.28598117828369, "training_acc": 52.5, "val_loss": 13.673419952392578, "val_acc": 55.0}
{"epoch": 29, "training_loss": 54.783223152160645, "training_acc": 52.5, "val_loss": 13.772592544555664, "val_acc": 55.0}
{"epoch": 30, "training_loss": 55.43526268005371, "training_acc": 53.75, "val_loss": 13.825377225875854, "val_acc": 55.0}
{"epoch": 31, "training_loss": 55.234764099121094, "training_acc": 52.5, "val_loss": 13.890875577926636, "val_acc": 55.0}
{"epoch": 32, "training_loss": 55.36435317993164, "training_acc": 48.75, "val_loss": 13.901041746139526, "val_acc": 55.0}
{"epoch": 33, "training_loss": 55.21283721923828, "training_acc": 48.75, "val_loss": 13.752031326293945, "val_acc": 55.0}
{"epoch": 34, "training_loss": 54.6707649230957, "training_acc": 55.0, "val_loss": 13.754686117172241, "val_acc": 55.0}
{"epoch": 35, "training_loss": 54.82040596008301, "training_acc": 52.5, "val_loss": 13.77249002456665, "val_acc": 55.0}
{"epoch": 36, "training_loss": 54.854469299316406, "training_acc": 52.5, "val_loss": 13.688642978668213, "val_acc": 55.0}
{"epoch": 37, "training_loss": 53.966651916503906, "training_acc": 56.25, "val_loss": 13.655174970626831, "val_acc": 55.0}
{"epoch": 38, "training_loss": 53.409146308898926, "training_acc": 56.25, "val_loss": 13.809709548950195, "val_acc": 55.0}
{"epoch": 39, "training_loss": 52.43381214141846, "training_acc": 56.25, "val_loss": 13.716886043548584, "val_acc": 55.0}
{"epoch": 40, "training_loss": 51.30809211730957, "training_acc": 60.0, "val_loss": 13.505853414535522, "val_acc": 55.0}
{"epoch": 41, "training_loss": 53.03709316253662, "training_acc": 56.25, "val_loss": 13.773081302642822, "val_acc": 55.0}
{"epoch": 42, "training_loss": 54.002840995788574, "training_acc": 57.5, "val_loss": 13.378511667251587, "val_acc": 55.0}
{"epoch": 43, "training_loss": 51.2804651260376, "training_acc": 71.25, "val_loss": 14.042943716049194, "val_acc": 55.0}
{"epoch": 44, "training_loss": 52.329209327697754, "training_acc": 60.0, "val_loss": 14.208248853683472, "val_acc": 55.0}
{"epoch": 45, "training_loss": 54.500555992126465, "training_acc": 48.75, "val_loss": 13.882155418395996, "val_acc": 55.0}
{"epoch": 46, "training_loss": 52.661789894104004, "training_acc": 62.5, "val_loss": 14.15007472038269, "val_acc": 55.0}
{"epoch": 47, "training_loss": 53.126648902893066, "training_acc": 55.0, "val_loss": 13.092015981674194, "val_acc": 55.0}
{"epoch": 48, "training_loss": 50.706024169921875, "training_acc": 67.5, "val_loss": 12.969058752059937, "val_acc": 55.0}
{"epoch": 49, "training_loss": 50.22610664367676, "training_acc": 65.0, "val_loss": 13.220528364181519, "val_acc": 55.0}
{"epoch": 50, "training_loss": 47.61031723022461, "training_acc": 67.5, "val_loss": 13.903926610946655, "val_acc": 55.0}
