"main_optuna_fix_3.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3 --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 55.487871170043945, "training_acc": 52.5, "val_loss": 13.762015104293823, "val_acc": 55.0}
{"epoch": 1, "training_loss": 55.5968713760376, "training_acc": 52.5, "val_loss": 13.800785541534424, "val_acc": 55.0}
{"epoch": 2, "training_loss": 55.320637702941895, "training_acc": 52.5, "val_loss": 13.761570453643799, "val_acc": 55.0}
{"epoch": 3, "training_loss": 55.42374801635742, "training_acc": 52.5, "val_loss": 13.76908540725708, "val_acc": 55.0}
{"epoch": 4, "training_loss": 55.23513889312744, "training_acc": 52.5, "val_loss": 13.779391050338745, "val_acc": 55.0}
{"epoch": 5, "training_loss": 55.28203868865967, "training_acc": 52.5, "val_loss": 13.80136489868164, "val_acc": 55.0}
{"epoch": 6, "training_loss": 55.30925750732422, "training_acc": 52.5, "val_loss": 13.782457113265991, "val_acc": 55.0}
{"epoch": 7, "training_loss": 55.152363777160645, "training_acc": 52.5, "val_loss": 13.766621351242065, "val_acc": 55.0}
{"epoch": 8, "training_loss": 55.0936279296875, "training_acc": 52.5, "val_loss": 13.86414647102356, "val_acc": 55.0}
{"epoch": 9, "training_loss": 55.497732162475586, "training_acc": 53.75, "val_loss": 13.784341812133789, "val_acc": 55.0}
{"epoch": 10, "training_loss": 55.36526298522949, "training_acc": 52.5, "val_loss": 13.779733180999756, "val_acc": 55.0}
{"epoch": 11, "training_loss": 55.41804790496826, "training_acc": 52.5, "val_loss": 13.76409649848938, "val_acc": 55.0}
{"epoch": 12, "training_loss": 55.502288818359375, "training_acc": 52.5, "val_loss": 13.776108026504517, "val_acc": 55.0}
{"epoch": 13, "training_loss": 55.46803092956543, "training_acc": 52.5, "val_loss": 13.775628805160522, "val_acc": 55.0}
{"epoch": 14, "training_loss": 55.43156337738037, "training_acc": 52.5, "val_loss": 13.794974088668823, "val_acc": 55.0}
{"epoch": 15, "training_loss": 55.438066482543945, "training_acc": 52.5, "val_loss": 13.811910152435303, "val_acc": 55.0}
{"epoch": 16, "training_loss": 55.339552879333496, "training_acc": 52.5, "val_loss": 13.783009052276611, "val_acc": 55.0}
{"epoch": 17, "training_loss": 55.366966247558594, "training_acc": 52.5, "val_loss": 13.783994913101196, "val_acc": 55.0}
{"epoch": 18, "training_loss": 55.44017219543457, "training_acc": 52.5, "val_loss": 13.780006170272827, "val_acc": 55.0}
{"epoch": 19, "training_loss": 55.31302070617676, "training_acc": 52.5, "val_loss": 13.829946517944336, "val_acc": 55.0}
{"epoch": 20, "training_loss": 55.36043357849121, "training_acc": 52.5, "val_loss": 13.865382671356201, "val_acc": 55.0}
{"epoch": 21, "training_loss": 55.476552963256836, "training_acc": 45.0, "val_loss": 13.83787751197815, "val_acc": 55.0}
{"epoch": 22, "training_loss": 55.38615131378174, "training_acc": 52.5, "val_loss": 13.801406621932983, "val_acc": 55.0}
{"epoch": 23, "training_loss": 55.33853530883789, "training_acc": 52.5, "val_loss": 13.780827522277832, "val_acc": 55.0}
{"epoch": 24, "training_loss": 55.395700454711914, "training_acc": 52.5, "val_loss": 13.771001100540161, "val_acc": 55.0}
{"epoch": 25, "training_loss": 55.462568283081055, "training_acc": 52.5, "val_loss": 13.769586086273193, "val_acc": 55.0}
{"epoch": 26, "training_loss": 55.48785972595215, "training_acc": 52.5, "val_loss": 13.772433996200562, "val_acc": 55.0}
{"epoch": 27, "training_loss": 55.51124572753906, "training_acc": 52.5, "val_loss": 13.767849206924438, "val_acc": 55.0}
{"epoch": 28, "training_loss": 55.513118743896484, "training_acc": 52.5, "val_loss": 13.7729811668396, "val_acc": 55.0}
