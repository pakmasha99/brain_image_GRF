"main_optuna_fix_3.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3 --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 55.39934539794922, "training_acc": 53.75, "val_loss": 13.850654363632202, "val_acc": 50.0}
{"epoch": 1, "training_loss": 55.27681827545166, "training_acc": 53.75, "val_loss": 13.905909061431885, "val_acc": 50.0}
{"epoch": 2, "training_loss": 55.18095588684082, "training_acc": 53.75, "val_loss": 13.922061920166016, "val_acc": 50.0}
{"epoch": 3, "training_loss": 55.2059326171875, "training_acc": 53.75, "val_loss": 13.930596113204956, "val_acc": 50.0}
{"epoch": 4, "training_loss": 55.13005065917969, "training_acc": 53.75, "val_loss": 13.893600702285767, "val_acc": 50.0}
{"epoch": 5, "training_loss": 55.333749771118164, "training_acc": 53.75, "val_loss": 13.889487981796265, "val_acc": 50.0}
{"epoch": 6, "training_loss": 55.11179065704346, "training_acc": 53.75, "val_loss": 13.921760320663452, "val_acc": 50.0}
{"epoch": 7, "training_loss": 55.08607292175293, "training_acc": 53.75, "val_loss": 13.979326486587524, "val_acc": 50.0}
{"epoch": 8, "training_loss": 55.25510311126709, "training_acc": 53.75, "val_loss": 13.946336507797241, "val_acc": 50.0}
{"epoch": 9, "training_loss": 55.01900577545166, "training_acc": 53.75, "val_loss": 13.882274627685547, "val_acc": 50.0}
{"epoch": 10, "training_loss": 55.29325771331787, "training_acc": 53.75, "val_loss": 13.866291046142578, "val_acc": 50.0}
{"epoch": 11, "training_loss": 55.253872871398926, "training_acc": 53.75, "val_loss": 13.875610828399658, "val_acc": 50.0}
{"epoch": 12, "training_loss": 55.20105171203613, "training_acc": 53.75, "val_loss": 13.930332660675049, "val_acc": 50.0}
{"epoch": 13, "training_loss": 55.1759729385376, "training_acc": 53.75, "val_loss": 14.004518985748291, "val_acc": 50.0}
{"epoch": 14, "training_loss": 55.205299377441406, "training_acc": 53.75, "val_loss": 14.1096031665802, "val_acc": 50.0}
{"epoch": 15, "training_loss": 55.391940116882324, "training_acc": 53.75, "val_loss": 14.20379638671875, "val_acc": 50.0}
{"epoch": 16, "training_loss": 55.77553367614746, "training_acc": 53.75, "val_loss": 14.152945280075073, "val_acc": 50.0}
{"epoch": 17, "training_loss": 55.47430992126465, "training_acc": 53.75, "val_loss": 14.00858759880066, "val_acc": 50.0}
{"epoch": 18, "training_loss": 55.26706409454346, "training_acc": 53.75, "val_loss": 13.898670673370361, "val_acc": 50.0}
{"epoch": 19, "training_loss": 55.07284927368164, "training_acc": 53.75, "val_loss": 13.861093521118164, "val_acc": 50.0}
{"epoch": 20, "training_loss": 55.27298545837402, "training_acc": 51.25, "val_loss": 13.861585855484009, "val_acc": 50.0}
{"epoch": 21, "training_loss": 55.52989673614502, "training_acc": 47.5, "val_loss": 13.865537643432617, "val_acc": 50.0}
{"epoch": 22, "training_loss": 55.22875690460205, "training_acc": 53.75, "val_loss": 13.923171758651733, "val_acc": 50.0}
{"epoch": 23, "training_loss": 55.08304405212402, "training_acc": 53.75, "val_loss": 14.028381109237671, "val_acc": 50.0}
{"epoch": 24, "training_loss": 55.31612777709961, "training_acc": 53.75, "val_loss": 14.120129346847534, "val_acc": 50.0}
{"epoch": 25, "training_loss": 55.44606971740723, "training_acc": 53.75, "val_loss": 14.09954309463501, "val_acc": 50.0}
{"epoch": 26, "training_loss": 55.3291130065918, "training_acc": 53.75, "val_loss": 13.965396881103516, "val_acc": 50.0}
{"epoch": 27, "training_loss": 55.291321754455566, "training_acc": 53.75, "val_loss": 13.922741413116455, "val_acc": 50.0}
{"epoch": 28, "training_loss": 55.30851745605469, "training_acc": 53.75, "val_loss": 13.886297941207886, "val_acc": 50.0}
{"epoch": 29, "training_loss": 55.28107166290283, "training_acc": 53.75, "val_loss": 13.868974447250366, "val_acc": 50.0}
{"epoch": 30, "training_loss": 55.327040672302246, "training_acc": 53.75, "val_loss": 13.897432088851929, "val_acc": 50.0}
{"epoch": 31, "training_loss": 55.2327184677124, "training_acc": 53.75, "val_loss": 13.9637291431427, "val_acc": 50.0}
{"epoch": 32, "training_loss": 55.30617713928223, "training_acc": 53.75, "val_loss": 13.953802585601807, "val_acc": 50.0}
{"epoch": 33, "training_loss": 55.24805450439453, "training_acc": 53.75, "val_loss": 13.901941776275635, "val_acc": 50.0}
