"main_optuna_fix_3.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3 --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 55.51628494262695, "training_acc": 53.75, "val_loss": 13.931572437286377, "val_acc": 50.0}
{"epoch": 1, "training_loss": 55.44210147857666, "training_acc": 53.75, "val_loss": 13.920118808746338, "val_acc": 50.0}
{"epoch": 2, "training_loss": 55.210391998291016, "training_acc": 53.75, "val_loss": 13.887380361557007, "val_acc": 50.0}
{"epoch": 3, "training_loss": 55.24008560180664, "training_acc": 53.75, "val_loss": 13.913404941558838, "val_acc": 50.0}
{"epoch": 4, "training_loss": 55.189406394958496, "training_acc": 53.75, "val_loss": 13.900610208511353, "val_acc": 50.0}
{"epoch": 5, "training_loss": 55.28365898132324, "training_acc": 53.75, "val_loss": 13.880159854888916, "val_acc": 50.0}
{"epoch": 6, "training_loss": 55.2121524810791, "training_acc": 53.75, "val_loss": 13.882778882980347, "val_acc": 50.0}
{"epoch": 7, "training_loss": 55.23517990112305, "training_acc": 53.75, "val_loss": 13.898587226867676, "val_acc": 50.0}
{"epoch": 8, "training_loss": 55.1201171875, "training_acc": 53.75, "val_loss": 13.886603116989136, "val_acc": 50.0}
{"epoch": 9, "training_loss": 55.12562084197998, "training_acc": 53.75, "val_loss": 13.896410465240479, "val_acc": 50.0}
{"epoch": 10, "training_loss": 55.153085708618164, "training_acc": 53.75, "val_loss": 13.920198678970337, "val_acc": 50.0}
{"epoch": 11, "training_loss": 55.0006160736084, "training_acc": 53.75, "val_loss": 14.001420736312866, "val_acc": 50.0}
{"epoch": 12, "training_loss": 55.06107997894287, "training_acc": 53.75, "val_loss": 14.102424383163452, "val_acc": 50.0}
{"epoch": 13, "training_loss": 55.29610729217529, "training_acc": 53.75, "val_loss": 14.187815189361572, "val_acc": 50.0}
{"epoch": 14, "training_loss": 55.4508113861084, "training_acc": 53.75, "val_loss": 14.30418610572815, "val_acc": 50.0}
{"epoch": 15, "training_loss": 55.60216999053955, "training_acc": 53.75, "val_loss": 14.287182092666626, "val_acc": 50.0}
{"epoch": 16, "training_loss": 55.82697105407715, "training_acc": 53.75, "val_loss": 14.078712463378906, "val_acc": 50.0}
{"epoch": 17, "training_loss": 55.250205993652344, "training_acc": 53.75, "val_loss": 13.957502841949463, "val_acc": 50.0}
{"epoch": 18, "training_loss": 55.22415542602539, "training_acc": 53.75, "val_loss": 13.932698965072632, "val_acc": 50.0}
{"epoch": 19, "training_loss": 55.345805168151855, "training_acc": 53.75, "val_loss": 13.904784917831421, "val_acc": 50.0}
{"epoch": 20, "training_loss": 55.06169509887695, "training_acc": 53.75, "val_loss": 13.877853155136108, "val_acc": 50.0}
{"epoch": 21, "training_loss": 55.350297927856445, "training_acc": 52.5, "val_loss": 13.894132375717163, "val_acc": 50.0}
{"epoch": 22, "training_loss": 55.164663314819336, "training_acc": 53.75, "val_loss": 13.947690725326538, "val_acc": 50.0}
{"epoch": 23, "training_loss": 55.24954032897949, "training_acc": 53.75, "val_loss": 13.992500305175781, "val_acc": 50.0}
{"epoch": 24, "training_loss": 55.315537452697754, "training_acc": 53.75, "val_loss": 13.953717947006226, "val_acc": 50.0}
{"epoch": 25, "training_loss": 55.22791385650635, "training_acc": 53.75, "val_loss": 13.912937641143799, "val_acc": 50.0}
{"epoch": 26, "training_loss": 55.21232032775879, "training_acc": 53.75, "val_loss": 13.903526067733765, "val_acc": 50.0}
{"epoch": 27, "training_loss": 55.270647048950195, "training_acc": 53.75, "val_loss": 13.923410177230835, "val_acc": 50.0}
{"epoch": 28, "training_loss": 55.224679946899414, "training_acc": 53.75, "val_loss": 13.932579755783081, "val_acc": 50.0}
{"epoch": 29, "training_loss": 55.236562728881836, "training_acc": 53.75, "val_loss": 13.908432722091675, "val_acc": 50.0}
{"epoch": 30, "training_loss": 55.2689094543457, "training_acc": 53.75, "val_loss": 13.918211460113525, "val_acc": 50.0}
{"epoch": 31, "training_loss": 55.22226524353027, "training_acc": 53.75, "val_loss": 13.926044702529907, "val_acc": 50.0}
{"epoch": 32, "training_loss": 55.19142818450928, "training_acc": 53.75, "val_loss": 13.911994695663452, "val_acc": 50.0}
{"epoch": 33, "training_loss": 55.231003761291504, "training_acc": 53.75, "val_loss": 13.923598527908325, "val_acc": 50.0}
{"epoch": 34, "training_loss": 55.266496658325195, "training_acc": 53.75, "val_loss": 13.98259162902832, "val_acc": 50.0}
{"epoch": 35, "training_loss": 55.29518699645996, "training_acc": 53.75, "val_loss": 13.984097242355347, "val_acc": 50.0}
{"epoch": 36, "training_loss": 55.20713996887207, "training_acc": 53.75, "val_loss": 13.916219472885132, "val_acc": 50.0}
{"epoch": 37, "training_loss": 55.20594787597656, "training_acc": 53.75, "val_loss": 13.87407898902893, "val_acc": 50.0}
{"epoch": 38, "training_loss": 55.31283760070801, "training_acc": 53.75, "val_loss": 13.865275382995605, "val_acc": 50.0}
{"epoch": 39, "training_loss": 55.37969493865967, "training_acc": 53.75, "val_loss": 13.885558843612671, "val_acc": 50.0}
{"epoch": 40, "training_loss": 55.25181484222412, "training_acc": 53.75, "val_loss": 13.92862319946289, "val_acc": 50.0}
{"epoch": 41, "training_loss": 55.35741329193115, "training_acc": 53.75, "val_loss": 13.92157793045044, "val_acc": 50.0}
