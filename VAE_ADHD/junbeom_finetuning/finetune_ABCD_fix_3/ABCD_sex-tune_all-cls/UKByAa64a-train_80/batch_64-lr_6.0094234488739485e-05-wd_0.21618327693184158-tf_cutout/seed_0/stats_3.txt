"main_optuna_fix_3.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3 --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 55.58295822143555, "training_acc": 52.5, "val_loss": 13.825113773345947, "val_acc": 55.0}
{"epoch": 1, "training_loss": 55.46463108062744, "training_acc": 52.5, "val_loss": 13.797200918197632, "val_acc": 55.0}
{"epoch": 2, "training_loss": 55.40178871154785, "training_acc": 52.5, "val_loss": 13.80283236503601, "val_acc": 55.0}
{"epoch": 3, "training_loss": 55.34660625457764, "training_acc": 52.5, "val_loss": 13.76524806022644, "val_acc": 55.0}
{"epoch": 4, "training_loss": 55.37336349487305, "training_acc": 52.5, "val_loss": 13.760461807250977, "val_acc": 55.0}
{"epoch": 5, "training_loss": 55.34237575531006, "training_acc": 52.5, "val_loss": 13.75667691230774, "val_acc": 55.0}
{"epoch": 6, "training_loss": 55.33858585357666, "training_acc": 52.5, "val_loss": 13.760188817977905, "val_acc": 55.0}
{"epoch": 7, "training_loss": 55.32188606262207, "training_acc": 52.5, "val_loss": 13.771404027938843, "val_acc": 55.0}
{"epoch": 8, "training_loss": 55.311805725097656, "training_acc": 52.5, "val_loss": 13.829220533370972, "val_acc": 55.0}
{"epoch": 9, "training_loss": 55.36902618408203, "training_acc": 52.5, "val_loss": 13.887876272201538, "val_acc": 55.0}
{"epoch": 10, "training_loss": 55.48408603668213, "training_acc": 47.5, "val_loss": 13.837021589279175, "val_acc": 55.0}
{"epoch": 11, "training_loss": 55.30348777770996, "training_acc": 52.5, "val_loss": 13.767180442810059, "val_acc": 55.0}
{"epoch": 12, "training_loss": 55.50253963470459, "training_acc": 52.5, "val_loss": 13.76530647277832, "val_acc": 55.0}
{"epoch": 13, "training_loss": 55.399349212646484, "training_acc": 52.5, "val_loss": 13.771591186523438, "val_acc": 55.0}
{"epoch": 14, "training_loss": 55.35601806640625, "training_acc": 52.5, "val_loss": 13.788880109786987, "val_acc": 55.0}
{"epoch": 15, "training_loss": 55.48721504211426, "training_acc": 52.5, "val_loss": 13.79052996635437, "val_acc": 55.0}
{"epoch": 16, "training_loss": 55.28942012786865, "training_acc": 52.5, "val_loss": 13.76368522644043, "val_acc": 55.0}
{"epoch": 17, "training_loss": 55.549325942993164, "training_acc": 52.5, "val_loss": 13.770030736923218, "val_acc": 55.0}
{"epoch": 18, "training_loss": 55.54564094543457, "training_acc": 52.5, "val_loss": 13.762437105178833, "val_acc": 55.0}
{"epoch": 19, "training_loss": 55.34822463989258, "training_acc": 52.5, "val_loss": 13.787609338760376, "val_acc": 55.0}
{"epoch": 20, "training_loss": 55.35316276550293, "training_acc": 52.5, "val_loss": 13.836653232574463, "val_acc": 55.0}
{"epoch": 21, "training_loss": 55.41572380065918, "training_acc": 52.5, "val_loss": 13.84548306465149, "val_acc": 55.0}
{"epoch": 22, "training_loss": 55.4107780456543, "training_acc": 52.5, "val_loss": 13.825681209564209, "val_acc": 55.0}
{"epoch": 23, "training_loss": 55.34198760986328, "training_acc": 52.5, "val_loss": 13.790525197982788, "val_acc": 55.0}
