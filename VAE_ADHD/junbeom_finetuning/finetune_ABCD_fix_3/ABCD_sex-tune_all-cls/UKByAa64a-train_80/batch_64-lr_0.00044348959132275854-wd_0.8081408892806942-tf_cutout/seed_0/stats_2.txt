"main_optuna_fix_3.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3 --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 59.86844539642334, "training_acc": 50.0, "val_loss": 14.427541494369507, "val_acc": 55.0}
{"epoch": 1, "training_loss": 82.69790649414062, "training_acc": 45.0, "val_loss": 14.361686706542969, "val_acc": 55.0}
{"epoch": 2, "training_loss": 66.30553436279297, "training_acc": 50.0, "val_loss": 14.191715717315674, "val_acc": 55.0}
{"epoch": 3, "training_loss": 56.37540054321289, "training_acc": 47.5, "val_loss": 13.789619207382202, "val_acc": 55.0}
{"epoch": 4, "training_loss": 55.777130126953125, "training_acc": 52.5, "val_loss": 14.834502935409546, "val_acc": 55.0}
{"epoch": 5, "training_loss": 58.04072570800781, "training_acc": 47.5, "val_loss": 13.809455633163452, "val_acc": 55.0}
{"epoch": 6, "training_loss": 57.06442928314209, "training_acc": 42.5, "val_loss": 13.814384937286377, "val_acc": 55.0}
{"epoch": 7, "training_loss": 55.91225242614746, "training_acc": 52.5, "val_loss": 13.906244039535522, "val_acc": 55.0}
{"epoch": 8, "training_loss": 56.05836868286133, "training_acc": 52.5, "val_loss": 13.838592767715454, "val_acc": 55.0}
{"epoch": 9, "training_loss": 55.27085876464844, "training_acc": 55.0, "val_loss": 14.418283700942993, "val_acc": 55.0}
{"epoch": 10, "training_loss": 57.0303316116333, "training_acc": 47.5, "val_loss": 14.009120464324951, "val_acc": 55.0}
{"epoch": 11, "training_loss": 55.51182556152344, "training_acc": 52.5, "val_loss": 13.764076232910156, "val_acc": 55.0}
{"epoch": 12, "training_loss": 55.624600410461426, "training_acc": 52.5, "val_loss": 13.804556131362915, "val_acc": 55.0}
{"epoch": 13, "training_loss": 55.75571632385254, "training_acc": 52.5, "val_loss": 13.776376247406006, "val_acc": 55.0}
{"epoch": 14, "training_loss": 55.33306121826172, "training_acc": 52.5, "val_loss": 13.918379545211792, "val_acc": 55.0}
{"epoch": 15, "training_loss": 55.8538703918457, "training_acc": 47.5, "val_loss": 13.853679895401001, "val_acc": 55.0}
{"epoch": 16, "training_loss": 55.18531322479248, "training_acc": 52.5, "val_loss": 13.773161172866821, "val_acc": 55.0}
{"epoch": 17, "training_loss": 55.796690940856934, "training_acc": 52.5, "val_loss": 13.814109563827515, "val_acc": 55.0}
{"epoch": 18, "training_loss": 55.83173656463623, "training_acc": 52.5, "val_loss": 13.768784999847412, "val_acc": 55.0}
{"epoch": 19, "training_loss": 55.366580963134766, "training_acc": 52.5, "val_loss": 13.823890686035156, "val_acc": 55.0}
{"epoch": 20, "training_loss": 55.453439712524414, "training_acc": 50.0, "val_loss": 13.92155647277832, "val_acc": 55.0}
{"epoch": 21, "training_loss": 55.57909297943115, "training_acc": 47.5, "val_loss": 13.8676917552948, "val_acc": 55.0}
{"epoch": 22, "training_loss": 55.420766830444336, "training_acc": 50.0, "val_loss": 13.786476850509644, "val_acc": 55.0}
{"epoch": 23, "training_loss": 55.32304763793945, "training_acc": 52.5, "val_loss": 13.763103485107422, "val_acc": 55.0}
{"epoch": 24, "training_loss": 55.44197463989258, "training_acc": 52.5, "val_loss": 13.780320882797241, "val_acc": 55.0}
{"epoch": 25, "training_loss": 55.681312561035156, "training_acc": 52.5, "val_loss": 13.810127973556519, "val_acc": 55.0}
{"epoch": 26, "training_loss": 55.97338676452637, "training_acc": 52.5, "val_loss": 13.798989057540894, "val_acc": 55.0}
{"epoch": 27, "training_loss": 55.82242774963379, "training_acc": 52.5, "val_loss": 13.784903287887573, "val_acc": 55.0}
{"epoch": 28, "training_loss": 55.66186046600342, "training_acc": 52.5, "val_loss": 13.76463532447815, "val_acc": 55.0}
{"epoch": 29, "training_loss": 55.456485748291016, "training_acc": 52.5, "val_loss": 13.810067176818848, "val_acc": 55.0}
{"epoch": 30, "training_loss": 55.398921966552734, "training_acc": 52.5, "val_loss": 13.851150274276733, "val_acc": 55.0}
{"epoch": 31, "training_loss": 55.43800449371338, "training_acc": 52.5, "val_loss": 13.87169361114502, "val_acc": 55.0}
{"epoch": 32, "training_loss": 55.46366882324219, "training_acc": 47.5, "val_loss": 13.911796808242798, "val_acc": 55.0}
{"epoch": 33, "training_loss": 55.55183792114258, "training_acc": 47.5, "val_loss": 13.931388854980469, "val_acc": 55.0}
{"epoch": 34, "training_loss": 55.59163856506348, "training_acc": 47.5, "val_loss": 13.895622491836548, "val_acc": 55.0}
{"epoch": 35, "training_loss": 55.54763412475586, "training_acc": 45.0, "val_loss": 13.847105503082275, "val_acc": 55.0}
{"epoch": 36, "training_loss": 55.42321491241455, "training_acc": 52.5, "val_loss": 13.823925256729126, "val_acc": 55.0}
{"epoch": 37, "training_loss": 55.40324020385742, "training_acc": 52.5, "val_loss": 13.812885284423828, "val_acc": 55.0}
{"epoch": 38, "training_loss": 55.37405586242676, "training_acc": 52.5, "val_loss": 13.80428671836853, "val_acc": 55.0}
{"epoch": 39, "training_loss": 55.34774112701416, "training_acc": 52.5, "val_loss": 13.783657550811768, "val_acc": 55.0}
{"epoch": 40, "training_loss": 55.41957092285156, "training_acc": 52.5, "val_loss": 13.776674270629883, "val_acc": 55.0}
{"epoch": 41, "training_loss": 55.351694107055664, "training_acc": 52.5, "val_loss": 13.792002201080322, "val_acc": 55.0}
