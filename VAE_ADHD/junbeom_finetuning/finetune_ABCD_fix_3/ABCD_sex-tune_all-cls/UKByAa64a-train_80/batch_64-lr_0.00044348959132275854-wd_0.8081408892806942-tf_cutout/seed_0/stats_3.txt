"main_optuna_fix_3.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3 --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 61.16127014160156, "training_acc": 42.5, "val_loss": 13.989861011505127, "val_acc": 55.0}
{"epoch": 1, "training_loss": 65.6814193725586, "training_acc": 45.0, "val_loss": 64.94485378265381, "val_acc": 55.0}
{"epoch": 2, "training_loss": 232.57295513153076, "training_acc": 50.0, "val_loss": 14.618949890136719, "val_acc": 55.0}
{"epoch": 3, "training_loss": 68.53863906860352, "training_acc": 52.5, "val_loss": 13.937685489654541, "val_acc": 55.0}
{"epoch": 4, "training_loss": 56.67480659484863, "training_acc": 52.5, "val_loss": 14.049663543701172, "val_acc": 55.0}
{"epoch": 5, "training_loss": 57.21885108947754, "training_acc": 52.5, "val_loss": 13.892332315444946, "val_acc": 55.0}
{"epoch": 6, "training_loss": 55.426950454711914, "training_acc": 50.0, "val_loss": 14.073445796966553, "val_acc": 55.0}
{"epoch": 7, "training_loss": 56.87670135498047, "training_acc": 52.5, "val_loss": 14.898635149002075, "val_acc": 55.0}
{"epoch": 8, "training_loss": 59.692383766174316, "training_acc": 42.5, "val_loss": 13.869354724884033, "val_acc": 55.0}
{"epoch": 9, "training_loss": 55.474924087524414, "training_acc": 51.25, "val_loss": 13.951883316040039, "val_acc": 55.0}
{"epoch": 10, "training_loss": 55.56578254699707, "training_acc": 47.5, "val_loss": 13.765424489974976, "val_acc": 55.0}
{"epoch": 11, "training_loss": 55.45214653015137, "training_acc": 52.5, "val_loss": 13.984907865524292, "val_acc": 55.0}
{"epoch": 12, "training_loss": 56.88515090942383, "training_acc": 52.5, "val_loss": 13.763426542282104, "val_acc": 55.0}
{"epoch": 13, "training_loss": 55.624691009521484, "training_acc": 50.0, "val_loss": 14.047876596450806, "val_acc": 55.0}
{"epoch": 14, "training_loss": 55.92639350891113, "training_acc": 47.5, "val_loss": 14.02345061302185, "val_acc": 55.0}
{"epoch": 15, "training_loss": 55.82048988342285, "training_acc": 47.5, "val_loss": 13.82367491722107, "val_acc": 55.0}
{"epoch": 16, "training_loss": 55.043867111206055, "training_acc": 52.5, "val_loss": 13.800644874572754, "val_acc": 55.0}
{"epoch": 17, "training_loss": 56.191734313964844, "training_acc": 52.5, "val_loss": 13.897041082382202, "val_acc": 55.0}
{"epoch": 18, "training_loss": 56.32252502441406, "training_acc": 52.5, "val_loss": 13.766435384750366, "val_acc": 55.0}
{"epoch": 19, "training_loss": 55.3502254486084, "training_acc": 52.5, "val_loss": 13.895375728607178, "val_acc": 55.0}
{"epoch": 20, "training_loss": 55.67035675048828, "training_acc": 47.5, "val_loss": 14.06040072441101, "val_acc": 55.0}
{"epoch": 21, "training_loss": 55.935285568237305, "training_acc": 47.5, "val_loss": 13.916280269622803, "val_acc": 55.0}
{"epoch": 22, "training_loss": 55.506775856018066, "training_acc": 50.0, "val_loss": 13.786393404006958, "val_acc": 55.0}
{"epoch": 23, "training_loss": 55.32773685455322, "training_acc": 52.5, "val_loss": 13.76667857170105, "val_acc": 55.0}
{"epoch": 24, "training_loss": 55.56129169464111, "training_acc": 52.5, "val_loss": 13.796906471252441, "val_acc": 55.0}
{"epoch": 25, "training_loss": 55.83746528625488, "training_acc": 52.5, "val_loss": 13.852020502090454, "val_acc": 55.0}
{"epoch": 26, "training_loss": 56.20174980163574, "training_acc": 52.5, "val_loss": 13.858245611190796, "val_acc": 55.0}
{"epoch": 27, "training_loss": 56.230594635009766, "training_acc": 52.5, "val_loss": 13.789198398590088, "val_acc": 55.0}
{"epoch": 28, "training_loss": 55.612321853637695, "training_acc": 52.5, "val_loss": 13.771934509277344, "val_acc": 55.0}
{"epoch": 29, "training_loss": 55.4249849319458, "training_acc": 52.5, "val_loss": 13.869447708129883, "val_acc": 55.0}
{"epoch": 30, "training_loss": 55.471341133117676, "training_acc": 47.5, "val_loss": 13.921036720275879, "val_acc": 55.0}
{"epoch": 31, "training_loss": 55.608155250549316, "training_acc": 47.5, "val_loss": 13.939417600631714, "val_acc": 55.0}
{"epoch": 32, "training_loss": 55.625088691711426, "training_acc": 47.5, "val_loss": 13.94846796989441, "val_acc": 55.0}
{"epoch": 33, "training_loss": 55.63591766357422, "training_acc": 47.5, "val_loss": 13.894175291061401, "val_acc": 55.0}
{"epoch": 34, "training_loss": 55.484633445739746, "training_acc": 50.0, "val_loss": 13.816102743148804, "val_acc": 55.0}
{"epoch": 35, "training_loss": 55.44095230102539, "training_acc": 52.5, "val_loss": 13.77829909324646, "val_acc": 55.0}
{"epoch": 36, "training_loss": 55.35393238067627, "training_acc": 52.5, "val_loss": 13.768066167831421, "val_acc": 55.0}
{"epoch": 37, "training_loss": 55.397438049316406, "training_acc": 52.5, "val_loss": 13.763508796691895, "val_acc": 55.0}
{"epoch": 38, "training_loss": 55.42548751831055, "training_acc": 52.5, "val_loss": 13.764094114303589, "val_acc": 55.0}
{"epoch": 39, "training_loss": 55.42020320892334, "training_acc": 52.5, "val_loss": 13.765335083007812, "val_acc": 55.0}
{"epoch": 40, "training_loss": 55.40170478820801, "training_acc": 52.5, "val_loss": 13.769879341125488, "val_acc": 55.0}
{"epoch": 41, "training_loss": 55.35372352600098, "training_acc": 52.5, "val_loss": 13.790830373764038, "val_acc": 55.0}
{"epoch": 42, "training_loss": 55.37860679626465, "training_acc": 52.5, "val_loss": 13.828321695327759, "val_acc": 55.0}
