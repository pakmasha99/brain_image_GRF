"main_optuna_fix_3.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3 --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 56.64360332489014, "training_acc": 41.25, "val_loss": 13.952392339706421, "val_acc": 50.0}
{"epoch": 1, "training_loss": 56.691551208496094, "training_acc": 43.75, "val_loss": 13.859341144561768, "val_acc": 50.0}
{"epoch": 2, "training_loss": 55.42674255371094, "training_acc": 53.75, "val_loss": 14.033898115158081, "val_acc": 50.0}
{"epoch": 3, "training_loss": 55.213327407836914, "training_acc": 53.75, "val_loss": 13.86733889579773, "val_acc": 50.0}
{"epoch": 4, "training_loss": 55.2580623626709, "training_acc": 53.75, "val_loss": 13.864142894744873, "val_acc": 50.0}
{"epoch": 5, "training_loss": 55.59344482421875, "training_acc": 52.5, "val_loss": 13.865258693695068, "val_acc": 50.0}
{"epoch": 6, "training_loss": 55.51280403137207, "training_acc": 56.25, "val_loss": 13.873659372329712, "val_acc": 50.0}
{"epoch": 7, "training_loss": 55.4624080657959, "training_acc": 53.75, "val_loss": 13.943763971328735, "val_acc": 50.0}
{"epoch": 8, "training_loss": 55.07345771789551, "training_acc": 53.75, "val_loss": 13.872793912887573, "val_acc": 50.0}
{"epoch": 9, "training_loss": 55.18316173553467, "training_acc": 55.0, "val_loss": 13.883686065673828, "val_acc": 50.0}
{"epoch": 10, "training_loss": 55.19540023803711, "training_acc": 56.25, "val_loss": 14.017089605331421, "val_acc": 50.0}
{"epoch": 11, "training_loss": 54.90112495422363, "training_acc": 53.75, "val_loss": 14.461431503295898, "val_acc": 50.0}
{"epoch": 12, "training_loss": 55.913737297058105, "training_acc": 53.75, "val_loss": 14.230462312698364, "val_acc": 50.0}
{"epoch": 13, "training_loss": 55.64273452758789, "training_acc": 53.75, "val_loss": 14.112540483474731, "val_acc": 50.0}
{"epoch": 14, "training_loss": 55.07451248168945, "training_acc": 53.75, "val_loss": 14.522507190704346, "val_acc": 50.0}
{"epoch": 15, "training_loss": 55.82447814941406, "training_acc": 53.75, "val_loss": 14.733556509017944, "val_acc": 50.0}
{"epoch": 16, "training_loss": 56.83802032470703, "training_acc": 53.75, "val_loss": 14.230765104293823, "val_acc": 50.0}
{"epoch": 17, "training_loss": 55.20096015930176, "training_acc": 53.75, "val_loss": 13.926151990890503, "val_acc": 50.0}
{"epoch": 18, "training_loss": 55.043633460998535, "training_acc": 55.0, "val_loss": 13.887211084365845, "val_acc": 50.0}
{"epoch": 19, "training_loss": 55.37349319458008, "training_acc": 56.25, "val_loss": 13.89202356338501, "val_acc": 50.0}
{"epoch": 20, "training_loss": 55.174320220947266, "training_acc": 58.75, "val_loss": 13.910738229751587, "val_acc": 50.0}
{"epoch": 21, "training_loss": 55.57439994812012, "training_acc": 46.25, "val_loss": 13.895792961120605, "val_acc": 50.0}
{"epoch": 22, "training_loss": 54.876502990722656, "training_acc": 63.75, "val_loss": 14.051493406295776, "val_acc": 50.0}
{"epoch": 23, "training_loss": 54.906686782836914, "training_acc": 53.75, "val_loss": 14.395493268966675, "val_acc": 50.0}
{"epoch": 24, "training_loss": 55.63773155212402, "training_acc": 53.75, "val_loss": 14.223153591156006, "val_acc": 50.0}
{"epoch": 25, "training_loss": 55.3865442276001, "training_acc": 53.75, "val_loss": 13.948394060134888, "val_acc": 50.0}
{"epoch": 26, "training_loss": 55.15342330932617, "training_acc": 53.75, "val_loss": 13.868988752365112, "val_acc": 50.0}
{"epoch": 27, "training_loss": 55.277801513671875, "training_acc": 56.25, "val_loss": 13.87380599975586, "val_acc": 50.0}
{"epoch": 28, "training_loss": 55.20229911804199, "training_acc": 53.75, "val_loss": 13.927978277206421, "val_acc": 50.0}
{"epoch": 29, "training_loss": 54.968584060668945, "training_acc": 53.75, "val_loss": 13.952714204788208, "val_acc": 50.0}
{"epoch": 30, "training_loss": 54.92488670349121, "training_acc": 53.75, "val_loss": 14.011954069137573, "val_acc": 50.0}
{"epoch": 31, "training_loss": 54.92436408996582, "training_acc": 53.75, "val_loss": 14.035146236419678, "val_acc": 50.0}
{"epoch": 32, "training_loss": 54.530439376831055, "training_acc": 53.75, "val_loss": 14.011644124984741, "val_acc": 50.0}
{"epoch": 33, "training_loss": 54.851521492004395, "training_acc": 53.75, "val_loss": 14.093232154846191, "val_acc": 50.0}
