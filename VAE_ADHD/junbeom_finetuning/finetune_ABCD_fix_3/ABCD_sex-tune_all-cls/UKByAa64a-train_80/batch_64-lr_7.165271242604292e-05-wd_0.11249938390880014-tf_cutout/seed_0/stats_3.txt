"main_optuna_fix_3.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3 --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 56.31832218170166, "training_acc": 50.0, "val_loss": 13.80118727684021, "val_acc": 55.0}
{"epoch": 1, "training_loss": 56.65050506591797, "training_acc": 43.75, "val_loss": 13.799784183502197, "val_acc": 55.0}
{"epoch": 2, "training_loss": 55.77470397949219, "training_acc": 52.5, "val_loss": 13.803681135177612, "val_acc": 55.0}
{"epoch": 3, "training_loss": 55.443525314331055, "training_acc": 52.5, "val_loss": 13.910983800888062, "val_acc": 55.0}
{"epoch": 4, "training_loss": 55.7761287689209, "training_acc": 47.5, "val_loss": 13.783079385757446, "val_acc": 55.0}
{"epoch": 5, "training_loss": 55.215182304382324, "training_acc": 52.5, "val_loss": 13.855810165405273, "val_acc": 55.0}
{"epoch": 6, "training_loss": 56.03767395019531, "training_acc": 52.5, "val_loss": 13.763507604598999, "val_acc": 55.0}
{"epoch": 7, "training_loss": 55.26224136352539, "training_acc": 52.5, "val_loss": 13.838309049606323, "val_acc": 55.0}
{"epoch": 8, "training_loss": 55.390987396240234, "training_acc": 53.75, "val_loss": 13.987898826599121, "val_acc": 55.0}
{"epoch": 9, "training_loss": 55.75681686401367, "training_acc": 47.5, "val_loss": 14.051915407180786, "val_acc": 55.0}
{"epoch": 10, "training_loss": 55.764705657958984, "training_acc": 47.5, "val_loss": 13.762580156326294, "val_acc": 55.0}
{"epoch": 11, "training_loss": 55.37051582336426, "training_acc": 52.5, "val_loss": 14.118750095367432, "val_acc": 55.0}
{"epoch": 12, "training_loss": 56.89885425567627, "training_acc": 52.5, "val_loss": 13.760517835617065, "val_acc": 55.0}
{"epoch": 13, "training_loss": 55.39777088165283, "training_acc": 52.5, "val_loss": 13.863146305084229, "val_acc": 55.0}
{"epoch": 14, "training_loss": 55.409406661987305, "training_acc": 57.5, "val_loss": 13.892582654953003, "val_acc": 55.0}
{"epoch": 15, "training_loss": 55.60339832305908, "training_acc": 47.5, "val_loss": 13.829641342163086, "val_acc": 55.0}
{"epoch": 16, "training_loss": 55.200422286987305, "training_acc": 52.5, "val_loss": 13.764581680297852, "val_acc": 55.0}
{"epoch": 17, "training_loss": 55.7821159362793, "training_acc": 52.5, "val_loss": 13.827886581420898, "val_acc": 55.0}
{"epoch": 18, "training_loss": 55.88658428192139, "training_acc": 52.5, "val_loss": 13.763786554336548, "val_acc": 55.0}
{"epoch": 19, "training_loss": 55.27840232849121, "training_acc": 52.5, "val_loss": 13.862603902816772, "val_acc": 55.0}
{"epoch": 20, "training_loss": 55.53696537017822, "training_acc": 52.5, "val_loss": 14.049280881881714, "val_acc": 55.0}
{"epoch": 21, "training_loss": 55.85452651977539, "training_acc": 47.5, "val_loss": 13.971627950668335, "val_acc": 55.0}
{"epoch": 22, "training_loss": 55.58328628540039, "training_acc": 47.5, "val_loss": 13.830406665802002, "val_acc": 55.0}
{"epoch": 23, "training_loss": 55.29183769226074, "training_acc": 52.5, "val_loss": 13.766462802886963, "val_acc": 55.0}
{"epoch": 24, "training_loss": 55.311702728271484, "training_acc": 52.5, "val_loss": 13.798859119415283, "val_acc": 55.0}
{"epoch": 25, "training_loss": 55.60238456726074, "training_acc": 52.5, "val_loss": 13.904131650924683, "val_acc": 55.0}
{"epoch": 26, "training_loss": 56.365394592285156, "training_acc": 52.5, "val_loss": 13.935232162475586, "val_acc": 55.0}
{"epoch": 27, "training_loss": 56.41915798187256, "training_acc": 52.5, "val_loss": 13.838188648223877, "val_acc": 55.0}
{"epoch": 28, "training_loss": 55.89222526550293, "training_acc": 52.5, "val_loss": 13.762123584747314, "val_acc": 55.0}
{"epoch": 29, "training_loss": 55.47982978820801, "training_acc": 52.5, "val_loss": 13.819890022277832, "val_acc": 55.0}
{"epoch": 30, "training_loss": 55.2991886138916, "training_acc": 53.75, "val_loss": 13.897889852523804, "val_acc": 55.0}
{"epoch": 31, "training_loss": 55.52323818206787, "training_acc": 47.5, "val_loss": 13.954802751541138, "val_acc": 55.0}
{"epoch": 32, "training_loss": 55.5904483795166, "training_acc": 47.5, "val_loss": 13.98053765296936, "val_acc": 55.0}
