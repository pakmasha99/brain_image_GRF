"main_optuna_fix_3.py --pretrained_path None --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3 --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 120.83625030517578, "training_acc": 51.25, "val_loss": 3158.5064697265625, "val_acc": 55.0}
{"epoch": 1, "training_loss": 11443.351577758789, "training_acc": 45.0, "val_loss": 27.185540199279785, "val_acc": 45.0}
{"epoch": 2, "training_loss": 93.62426567077637, "training_acc": 47.5, "val_loss": 13.842971324920654, "val_acc": 55.0}
{"epoch": 3, "training_loss": 56.47915840148926, "training_acc": 50.0, "val_loss": 24.185621738433838, "val_acc": 55.0}
{"epoch": 4, "training_loss": 90.48317527770996, "training_acc": 52.5, "val_loss": 15.74636459350586, "val_acc": 45.0}
{"epoch": 5, "training_loss": 60.72305679321289, "training_acc": 47.5, "val_loss": 14.042823314666748, "val_acc": 55.0}
{"epoch": 6, "training_loss": 55.96994113922119, "training_acc": 47.5, "val_loss": 13.869098424911499, "val_acc": 55.0}
{"epoch": 7, "training_loss": 55.4336051940918, "training_acc": 50.0, "val_loss": 13.80894422531128, "val_acc": 55.0}
{"epoch": 8, "training_loss": 55.486029624938965, "training_acc": 52.5, "val_loss": 13.806828260421753, "val_acc": 55.0}
{"epoch": 9, "training_loss": 55.32442283630371, "training_acc": 52.5, "val_loss": 14.112977981567383, "val_acc": 55.0}
{"epoch": 10, "training_loss": 55.98749542236328, "training_acc": 47.5, "val_loss": 13.808889389038086, "val_acc": 55.0}
{"epoch": 11, "training_loss": 55.29172897338867, "training_acc": 52.5, "val_loss": 13.763208389282227, "val_acc": 55.0}
{"epoch": 12, "training_loss": 55.46554470062256, "training_acc": 52.5, "val_loss": 13.76463770866394, "val_acc": 55.0}
{"epoch": 13, "training_loss": 55.48100662231445, "training_acc": 52.5, "val_loss": 13.785620927810669, "val_acc": 55.0}
{"epoch": 14, "training_loss": 55.334187507629395, "training_acc": 52.5, "val_loss": 13.934754133224487, "val_acc": 55.0}
{"epoch": 15, "training_loss": 55.87631416320801, "training_acc": 47.5, "val_loss": 13.796776533126831, "val_acc": 55.0}
{"epoch": 16, "training_loss": 55.26689338684082, "training_acc": 52.5, "val_loss": 13.76273512840271, "val_acc": 55.0}
{"epoch": 17, "training_loss": 55.53912353515625, "training_acc": 52.5, "val_loss": 13.762871026992798, "val_acc": 55.0}
{"epoch": 18, "training_loss": 55.435561180114746, "training_acc": 52.5, "val_loss": 13.77076506614685, "val_acc": 55.0}
{"epoch": 19, "training_loss": 55.33363723754883, "training_acc": 52.5, "val_loss": 13.818702697753906, "val_acc": 55.0}
{"epoch": 20, "training_loss": 55.42800521850586, "training_acc": 50.0, "val_loss": 13.867648839950562, "val_acc": 55.0}
{"epoch": 21, "training_loss": 55.44929885864258, "training_acc": 50.0, "val_loss": 13.826059103012085, "val_acc": 55.0}
{"epoch": 22, "training_loss": 55.36316204071045, "training_acc": 52.5, "val_loss": 13.78389835357666, "val_acc": 55.0}
{"epoch": 23, "training_loss": 55.33108615875244, "training_acc": 52.5, "val_loss": 13.765171766281128, "val_acc": 55.0}
{"epoch": 24, "training_loss": 55.403303146362305, "training_acc": 52.5, "val_loss": 13.772646188735962, "val_acc": 55.0}
{"epoch": 25, "training_loss": 55.578054428100586, "training_acc": 52.5, "val_loss": 13.806148767471313, "val_acc": 55.0}
{"epoch": 26, "training_loss": 55.99386024475098, "training_acc": 52.5, "val_loss": 13.779834508895874, "val_acc": 55.0}
{"epoch": 27, "training_loss": 55.65092086791992, "training_acc": 52.5, "val_loss": 13.771883249282837, "val_acc": 55.0}
{"epoch": 28, "training_loss": 55.55949783325195, "training_acc": 52.5, "val_loss": 13.767560720443726, "val_acc": 55.0}
{"epoch": 29, "training_loss": 55.41518974304199, "training_acc": 52.5, "val_loss": 13.804700374603271, "val_acc": 55.0}
{"epoch": 30, "training_loss": 55.3710880279541, "training_acc": 52.5, "val_loss": 13.810667991638184, "val_acc": 55.0}
{"epoch": 31, "training_loss": 55.41169548034668, "training_acc": 52.5, "val_loss": 13.815134763717651, "val_acc": 55.0}
{"epoch": 32, "training_loss": 55.35508346557617, "training_acc": 52.5, "val_loss": 13.852843046188354, "val_acc": 55.0}
{"epoch": 33, "training_loss": 55.43282890319824, "training_acc": 52.5, "val_loss": 13.886662721633911, "val_acc": 55.0}
{"epoch": 34, "training_loss": 55.51071548461914, "training_acc": 47.5, "val_loss": 13.878735303878784, "val_acc": 55.0}
{"epoch": 35, "training_loss": 55.49921226501465, "training_acc": 45.0, "val_loss": 13.85862946510315, "val_acc": 55.0}
{"epoch": 36, "training_loss": 55.44335174560547, "training_acc": 52.5, "val_loss": 13.850477933883667, "val_acc": 55.0}
{"epoch": 37, "training_loss": 55.43458557128906, "training_acc": 52.5, "val_loss": 13.845924139022827, "val_acc": 55.0}
{"epoch": 38, "training_loss": 55.42399024963379, "training_acc": 52.5, "val_loss": 13.839409351348877, "val_acc": 55.0}
{"epoch": 39, "training_loss": 55.399192810058594, "training_acc": 52.5, "val_loss": 13.821369409561157, "val_acc": 55.0}
{"epoch": 40, "training_loss": 55.413923263549805, "training_acc": 52.5, "val_loss": 13.809641599655151, "val_acc": 55.0}
{"epoch": 41, "training_loss": 55.37415409088135, "training_acc": 52.5, "val_loss": 13.812841176986694, "val_acc": 55.0}
{"epoch": 42, "training_loss": 55.38312530517578, "training_acc": 52.5, "val_loss": 13.818601369857788, "val_acc": 55.0}
{"epoch": 43, "training_loss": 55.37997245788574, "training_acc": 52.5, "val_loss": 13.816040754318237, "val_acc": 55.0}
{"epoch": 44, "training_loss": 55.373435974121094, "training_acc": 52.5, "val_loss": 13.813761472702026, "val_acc": 55.0}
{"epoch": 45, "training_loss": 55.369272232055664, "training_acc": 52.5, "val_loss": 13.811858892440796, "val_acc": 55.0}
{"epoch": 46, "training_loss": 55.36943054199219, "training_acc": 52.5, "val_loss": 13.810319900512695, "val_acc": 55.0}
{"epoch": 47, "training_loss": 55.36649036407471, "training_acc": 52.5, "val_loss": 13.807406425476074, "val_acc": 55.0}
{"epoch": 48, "training_loss": 55.35911750793457, "training_acc": 52.5, "val_loss": 13.797903060913086, "val_acc": 55.0}
{"epoch": 49, "training_loss": 55.3630256652832, "training_acc": 52.5, "val_loss": 13.78480076789856, "val_acc": 55.0}
{"epoch": 50, "training_loss": 55.35652542114258, "training_acc": 52.5, "val_loss": 13.77763032913208, "val_acc": 55.0}
{"epoch": 51, "training_loss": 55.357337951660156, "training_acc": 52.5, "val_loss": 13.77507209777832, "val_acc": 55.0}
