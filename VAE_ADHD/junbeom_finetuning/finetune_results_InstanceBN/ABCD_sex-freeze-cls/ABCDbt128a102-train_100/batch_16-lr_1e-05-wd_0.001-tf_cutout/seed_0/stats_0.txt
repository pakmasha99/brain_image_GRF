"main_modify.py --pretrained_path /scratch/connectome/dyhan316/VAE_ADHD/barlowtwins/pretrain_results/ABCDbt128a102.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option BT_org --learning_rate 1e-5 --batch_size 16 --weight_decay 1e-3 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 0.6923147630691528, "training_acc": 52.0, "val_loss": 0.6884438371658326, "val_acc": 56.0}
{"epoch": 1, "training_loss": 0.692398362159729, "training_acc": 52.0, "val_loss": 0.6883300089836121, "val_acc": 56.0}
{"epoch": 2, "training_loss": 0.6924011707305908, "training_acc": 52.0, "val_loss": 0.688294837474823, "val_acc": 56.0}
{"epoch": 3, "training_loss": 0.6921694135665893, "training_acc": 52.0, "val_loss": 0.6880793738365173, "val_acc": 56.0}
{"epoch": 4, "training_loss": 0.6923665976524354, "training_acc": 52.0, "val_loss": 0.6881324124336242, "val_acc": 56.0}
{"epoch": 5, "training_loss": 0.6921550440788269, "training_acc": 52.0, "val_loss": 0.6880090308189392, "val_acc": 56.0}
{"epoch": 6, "training_loss": 0.6920297980308533, "training_acc": 52.0, "val_loss": 0.6879413747787475, "val_acc": 56.0}
{"epoch": 7, "training_loss": 0.6921340441703796, "training_acc": 52.0, "val_loss": 0.6879730367660523, "val_acc": 56.0}
{"epoch": 8, "training_loss": 0.6920341157913208, "training_acc": 52.0, "val_loss": 0.6878386640548706, "val_acc": 56.0}
{"epoch": 9, "training_loss": 0.6921355485916137, "training_acc": 52.0, "val_loss": 0.6878994250297547, "val_acc": 56.0}
{"epoch": 10, "training_loss": 0.6923233842849732, "training_acc": 52.0, "val_loss": 0.6880881810188293, "val_acc": 56.0}
{"epoch": 11, "training_loss": 0.691993932723999, "training_acc": 52.0, "val_loss": 0.6880669379234314, "val_acc": 56.0}
{"epoch": 12, "training_loss": 0.6926406216621399, "training_acc": 52.0, "val_loss": 0.6877791666984558, "val_acc": 56.0}
{"epoch": 13, "training_loss": 0.6919445943832397, "training_acc": 52.0, "val_loss": 0.6877234935760498, "val_acc": 56.0}
{"epoch": 14, "training_loss": 0.6922610878944397, "training_acc": 52.0, "val_loss": 0.687575147151947, "val_acc": 56.0}
{"epoch": 15, "training_loss": 0.6923425173759461, "training_acc": 52.0, "val_loss": 0.6875047707557678, "val_acc": 56.0}
{"epoch": 16, "training_loss": 0.6926982116699218, "training_acc": 52.0, "val_loss": 0.6872327494621276, "val_acc": 56.0}
{"epoch": 17, "training_loss": 0.6919695091247559, "training_acc": 52.0, "val_loss": 0.6872797012329102, "val_acc": 56.0}
{"epoch": 18, "training_loss": 0.6922938704490662, "training_acc": 52.0, "val_loss": 0.6873934197425843, "val_acc": 56.0}
{"epoch": 19, "training_loss": 0.6921395754814148, "training_acc": 52.0, "val_loss": 0.687569887638092, "val_acc": 56.0}
{"epoch": 20, "training_loss": 0.6923620080947877, "training_acc": 52.0, "val_loss": 0.687577064037323, "val_acc": 56.0}
{"epoch": 21, "training_loss": 0.6917435312271119, "training_acc": 52.0, "val_loss": 0.6876136445999146, "val_acc": 56.0}
{"epoch": 22, "training_loss": 0.6919286823272706, "training_acc": 52.0, "val_loss": 0.6875527501106262, "val_acc": 56.0}
{"epoch": 23, "training_loss": 0.6921296381950378, "training_acc": 52.0, "val_loss": 0.6875984525680542, "val_acc": 56.0}
{"epoch": 24, "training_loss": 0.6924573731422424, "training_acc": 52.0, "val_loss": 0.6874493193626404, "val_acc": 56.0}
{"epoch": 25, "training_loss": 0.6923246908187867, "training_acc": 52.0, "val_loss": 0.6875087690353393, "val_acc": 56.0}
{"epoch": 26, "training_loss": 0.6915784931182861, "training_acc": 52.0, "val_loss": 0.6874921536445617, "val_acc": 56.0}
{"epoch": 27, "training_loss": 0.6918025779724121, "training_acc": 52.0, "val_loss": 0.6875554966926575, "val_acc": 56.0}
{"epoch": 28, "training_loss": 0.6921243691444396, "training_acc": 52.0, "val_loss": 0.687575695514679, "val_acc": 56.0}
{"epoch": 29, "training_loss": 0.6922613644599914, "training_acc": 52.0, "val_loss": 0.6874777150154113, "val_acc": 56.0}
{"epoch": 30, "training_loss": 0.6920816707611084, "training_acc": 52.0, "val_loss": 0.6871957969665528, "val_acc": 56.0}
{"epoch": 31, "training_loss": 0.6920711088180542, "training_acc": 52.0, "val_loss": 0.6870624017715454, "val_acc": 56.0}
{"epoch": 32, "training_loss": 0.6919497489929199, "training_acc": 52.0, "val_loss": 0.6867713141441345, "val_acc": 56.0}
{"epoch": 33, "training_loss": 0.692393913269043, "training_acc": 52.0, "val_loss": 0.6866192698478699, "val_acc": 56.0}
{"epoch": 34, "training_loss": 0.692394700050354, "training_acc": 52.0, "val_loss": 0.6866366243362427, "val_acc": 56.0}
{"epoch": 35, "training_loss": 0.6918319153785706, "training_acc": 52.0, "val_loss": 0.6867582392692566, "val_acc": 56.0}
{"epoch": 36, "training_loss": 0.6925887250900269, "training_acc": 52.0, "val_loss": 0.6867553043365479, "val_acc": 56.0}
{"epoch": 37, "training_loss": 0.6927118253707886, "training_acc": 52.0, "val_loss": 0.6867101311683654, "val_acc": 56.0}
{"epoch": 38, "training_loss": 0.6924920797348022, "training_acc": 52.0, "val_loss": 0.6867591524124146, "val_acc": 56.0}
{"epoch": 39, "training_loss": 0.6925237822532654, "training_acc": 52.0, "val_loss": 0.6868182349205018, "val_acc": 56.0}
{"epoch": 40, "training_loss": 0.6924904727935791, "training_acc": 52.0, "val_loss": 0.686971971988678, "val_acc": 56.0}
{"epoch": 41, "training_loss": 0.6918868899345398, "training_acc": 52.0, "val_loss": 0.6870128083229065, "val_acc": 56.0}
{"epoch": 42, "training_loss": 0.6918675327301025, "training_acc": 52.0, "val_loss": 0.6870535302162171, "val_acc": 56.0}
{"epoch": 43, "training_loss": 0.6917112779617309, "training_acc": 52.0, "val_loss": 0.6870984935760498, "val_acc": 56.0}
{"epoch": 44, "training_loss": 0.6924174118041992, "training_acc": 52.0, "val_loss": 0.687311384677887, "val_acc": 56.0}
{"epoch": 45, "training_loss": 0.6920825147628784, "training_acc": 52.0, "val_loss": 0.6873850750923157, "val_acc": 56.0}
{"epoch": 46, "training_loss": 0.6918263483047485, "training_acc": 52.0, "val_loss": 0.687422001361847, "val_acc": 56.0}
{"epoch": 47, "training_loss": 0.6923211526870727, "training_acc": 52.0, "val_loss": 0.6873912119865417, "val_acc": 56.0}
{"epoch": 48, "training_loss": 0.6921751594543457, "training_acc": 52.0, "val_loss": 0.6873443150520324, "val_acc": 56.0}
{"epoch": 49, "training_loss": 0.6920414161682129, "training_acc": 52.0, "val_loss": 0.687414014339447, "val_acc": 56.0}
{"epoch": 50, "training_loss": 0.6924851655960083, "training_acc": 52.0, "val_loss": 0.6876107335090638, "val_acc": 56.0}
{"epoch": 51, "training_loss": 0.6924239444732666, "training_acc": 52.0, "val_loss": 0.6878164649009705, "val_acc": 56.0}
{"epoch": 52, "training_loss": 0.6922797107696533, "training_acc": 52.0, "val_loss": 0.6880551075935364, "val_acc": 56.0}
