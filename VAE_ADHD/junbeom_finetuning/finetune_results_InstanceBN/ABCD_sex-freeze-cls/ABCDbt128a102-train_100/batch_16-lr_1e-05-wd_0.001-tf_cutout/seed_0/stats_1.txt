"main_modify.py --pretrained_path /scratch/connectome/dyhan316/VAE_ADHD/barlowtwins/pretrain_results/ABCDbt128a102.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option BT_org --learning_rate 1e-5 --batch_size 16 --weight_decay 1e-3 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 0.7009784197807312, "training_acc": 47.0, "val_loss": 0.695843620300293, "val_acc": 48.0}
{"epoch": 1, "training_loss": 0.7003442692756653, "training_acc": 47.0, "val_loss": 0.6953341507911682, "val_acc": 48.0}
{"epoch": 2, "training_loss": 0.6993154501914978, "training_acc": 47.0, "val_loss": 0.6947975945472717, "val_acc": 48.0}
{"epoch": 3, "training_loss": 0.6992116928100586, "training_acc": 47.0, "val_loss": 0.6943401455879211, "val_acc": 48.0}
{"epoch": 4, "training_loss": 0.6984039521217347, "training_acc": 47.0, "val_loss": 0.693880763053894, "val_acc": 48.0}
{"epoch": 5, "training_loss": 0.6983745217323303, "training_acc": 47.0, "val_loss": 0.6933679676055908, "val_acc": 48.0}
{"epoch": 6, "training_loss": 0.6974209499359131, "training_acc": 47.0, "val_loss": 0.6930632805824279, "val_acc": 48.0}
{"epoch": 7, "training_loss": 0.6965183687210083, "training_acc": 47.0, "val_loss": 0.6926399397850037, "val_acc": 48.0}
{"epoch": 8, "training_loss": 0.696174476146698, "training_acc": 47.0, "val_loss": 0.6924245882034302, "val_acc": 48.0}
{"epoch": 9, "training_loss": 0.69612637758255, "training_acc": 47.0, "val_loss": 0.6920535278320312, "val_acc": 48.0}
{"epoch": 10, "training_loss": 0.6959665441513061, "training_acc": 47.0, "val_loss": 0.6918345141410828, "val_acc": 48.0}
{"epoch": 11, "training_loss": 0.6954300093650818, "training_acc": 47.0, "val_loss": 0.6916548609733582, "val_acc": 48.0}
{"epoch": 12, "training_loss": 0.6951513862609864, "training_acc": 47.0, "val_loss": 0.6913839054107666, "val_acc": 48.0}
{"epoch": 13, "training_loss": 0.6949724483489991, "training_acc": 47.0, "val_loss": 0.691144404411316, "val_acc": 48.0}
{"epoch": 14, "training_loss": 0.6943720984458923, "training_acc": 47.0, "val_loss": 0.6909217000007629, "val_acc": 52.0}
{"epoch": 15, "training_loss": 0.6942402696609498, "training_acc": 47.0, "val_loss": 0.6907110667228699, "val_acc": 48.0}
{"epoch": 16, "training_loss": 0.6935975790023804, "training_acc": 48.0, "val_loss": 0.6905072093009949, "val_acc": 48.0}
{"epoch": 17, "training_loss": 0.6939092063903809, "training_acc": 47.0, "val_loss": 0.6902742409706115, "val_acc": 80.0}
{"epoch": 18, "training_loss": 0.6935472345352173, "training_acc": 47.0, "val_loss": 0.6901092481613159, "val_acc": 76.0}
{"epoch": 19, "training_loss": 0.6926751184463501, "training_acc": 60.0, "val_loss": 0.690047082901001, "val_acc": 68.0}
{"epoch": 20, "training_loss": 0.6929078769683837, "training_acc": 56.0, "val_loss": 0.6899638605117798, "val_acc": 64.0}
{"epoch": 21, "training_loss": 0.692776026725769, "training_acc": 52.0, "val_loss": 0.6898921537399292, "val_acc": 52.0}
{"epoch": 22, "training_loss": 0.6924940204620361, "training_acc": 51.0, "val_loss": 0.6897942805290223, "val_acc": 60.0}
{"epoch": 23, "training_loss": 0.6922781491279602, "training_acc": 50.0, "val_loss": 0.6897410988807678, "val_acc": 52.0}
{"epoch": 24, "training_loss": 0.6924906897544861, "training_acc": 51.0, "val_loss": 0.6896980810165405, "val_acc": 52.0}
{"epoch": 25, "training_loss": 0.6926493406295776, "training_acc": 53.0, "val_loss": 0.6896072459220887, "val_acc": 52.0}
{"epoch": 26, "training_loss": 0.6921674299240113, "training_acc": 53.0, "val_loss": 0.689536771774292, "val_acc": 52.0}
{"epoch": 27, "training_loss": 0.6920162153244018, "training_acc": 53.0, "val_loss": 0.6895413899421692, "val_acc": 52.0}
{"epoch": 28, "training_loss": 0.6919742441177368, "training_acc": 53.0, "val_loss": 0.6895133185386658, "val_acc": 52.0}
{"epoch": 29, "training_loss": 0.6921590662002564, "training_acc": 53.0, "val_loss": 0.6894798302650451, "val_acc": 52.0}
{"epoch": 30, "training_loss": 0.6913535451889038, "training_acc": 53.0, "val_loss": 0.6894163155555725, "val_acc": 52.0}
{"epoch": 31, "training_loss": 0.6917513751983643, "training_acc": 53.0, "val_loss": 0.6894120502471924, "val_acc": 52.0}
{"epoch": 32, "training_loss": 0.6918774461746215, "training_acc": 53.0, "val_loss": 0.6893960499763488, "val_acc": 52.0}
{"epoch": 33, "training_loss": 0.6914923620223999, "training_acc": 53.0, "val_loss": 0.689379813671112, "val_acc": 52.0}
{"epoch": 34, "training_loss": 0.6916652464866638, "training_acc": 53.0, "val_loss": 0.6893745017051697, "val_acc": 52.0}
{"epoch": 35, "training_loss": 0.6918082642555237, "training_acc": 53.0, "val_loss": 0.6893654727935791, "val_acc": 52.0}
{"epoch": 36, "training_loss": 0.6920212554931641, "training_acc": 53.0, "val_loss": 0.6893673276901245, "val_acc": 52.0}
{"epoch": 37, "training_loss": 0.6914565801620484, "training_acc": 53.0, "val_loss": 0.6893650817871094, "val_acc": 52.0}
{"epoch": 38, "training_loss": 0.6917176008224487, "training_acc": 53.0, "val_loss": 0.6893642139434815, "val_acc": 52.0}
{"epoch": 39, "training_loss": 0.691230947971344, "training_acc": 53.0, "val_loss": 0.6893645977973938, "val_acc": 52.0}
{"epoch": 40, "training_loss": 0.6914478468894959, "training_acc": 53.0, "val_loss": 0.6893643760681152, "val_acc": 52.0}
{"epoch": 41, "training_loss": 0.6917274475097657, "training_acc": 53.0, "val_loss": 0.689367594718933, "val_acc": 52.0}
{"epoch": 42, "training_loss": 0.6912113523483276, "training_acc": 53.0, "val_loss": 0.6893681836128235, "val_acc": 52.0}
{"epoch": 43, "training_loss": 0.6917706370353699, "training_acc": 53.0, "val_loss": 0.6893801879882813, "val_acc": 52.0}
{"epoch": 44, "training_loss": 0.6916312456130982, "training_acc": 53.0, "val_loss": 0.6893720579147339, "val_acc": 52.0}
{"epoch": 45, "training_loss": 0.6916279935836792, "training_acc": 53.0, "val_loss": 0.6893632626533508, "val_acc": 52.0}
{"epoch": 46, "training_loss": 0.6912170362472534, "training_acc": 53.0, "val_loss": 0.6893607640266418, "val_acc": 52.0}
{"epoch": 47, "training_loss": 0.6912374687194824, "training_acc": 53.0, "val_loss": 0.6893661713600159, "val_acc": 52.0}
{"epoch": 48, "training_loss": 0.6916324353218078, "training_acc": 53.0, "val_loss": 0.6893646144866943, "val_acc": 52.0}
{"epoch": 49, "training_loss": 0.6918518590927124, "training_acc": 53.0, "val_loss": 0.6893595767021179, "val_acc": 52.0}
{"epoch": 50, "training_loss": 0.6912675070762634, "training_acc": 53.0, "val_loss": 0.6893580293655396, "val_acc": 52.0}
{"epoch": 51, "training_loss": 0.6913785004615783, "training_acc": 53.0, "val_loss": 0.6893572163581848, "val_acc": 52.0}
{"epoch": 52, "training_loss": 0.6913016033172608, "training_acc": 53.0, "val_loss": 0.6893563938140869, "val_acc": 52.0}
{"epoch": 53, "training_loss": 0.6916048836708069, "training_acc": 53.0, "val_loss": 0.6893565034866334, "val_acc": 52.0}
{"epoch": 54, "training_loss": 0.6910891056060791, "training_acc": 53.0, "val_loss": 0.6893549656867981, "val_acc": 52.0}
{"epoch": 55, "training_loss": 0.69139808177948, "training_acc": 53.0, "val_loss": 0.6893595576286315, "val_acc": 52.0}
{"epoch": 56, "training_loss": 0.6904863405227661, "training_acc": 53.0, "val_loss": 0.6893703842163086, "val_acc": 52.0}
{"epoch": 57, "training_loss": 0.6911898040771485, "training_acc": 53.0, "val_loss": 0.6893832778930664, "val_acc": 52.0}
{"epoch": 58, "training_loss": 0.6915879702568054, "training_acc": 53.0, "val_loss": 0.6893955254554749, "val_acc": 52.0}
{"epoch": 59, "training_loss": 0.6911054420471191, "training_acc": 53.0, "val_loss": 0.689394428730011, "val_acc": 52.0}
{"epoch": 60, "training_loss": 0.6916252398490905, "training_acc": 53.0, "val_loss": 0.6894021654129028, "val_acc": 52.0}
{"epoch": 61, "training_loss": 0.69129958152771, "training_acc": 53.0, "val_loss": 0.6893981623649598, "val_acc": 52.0}
{"epoch": 62, "training_loss": 0.6914504289627075, "training_acc": 53.0, "val_loss": 0.689395067691803, "val_acc": 52.0}
{"epoch": 63, "training_loss": 0.6913153004646301, "training_acc": 53.0, "val_loss": 0.6894048619270324, "val_acc": 52.0}
{"epoch": 64, "training_loss": 0.691242880821228, "training_acc": 53.0, "val_loss": 0.689417564868927, "val_acc": 52.0}
{"epoch": 65, "training_loss": 0.6907959842681884, "training_acc": 53.0, "val_loss": 0.6894243550300598, "val_acc": 52.0}
{"epoch": 66, "training_loss": 0.6911580467224121, "training_acc": 53.0, "val_loss": 0.689425060749054, "val_acc": 52.0}
{"epoch": 67, "training_loss": 0.6915320897102356, "training_acc": 53.0, "val_loss": 0.6894126105308532, "val_acc": 52.0}
{"epoch": 68, "training_loss": 0.6918144035339355, "training_acc": 53.0, "val_loss": 0.6894035744667053, "val_acc": 52.0}
{"epoch": 69, "training_loss": 0.6914319348335266, "training_acc": 53.0, "val_loss": 0.6894051599502563, "val_acc": 52.0}
{"epoch": 70, "training_loss": 0.6912784242630005, "training_acc": 53.0, "val_loss": 0.6893958449363708, "val_acc": 52.0}
{"epoch": 71, "training_loss": 0.6909512138366699, "training_acc": 53.0, "val_loss": 0.6893913412094116, "val_acc": 52.0}
{"epoch": 72, "training_loss": 0.6911792230606079, "training_acc": 53.0, "val_loss": 0.6893970561027527, "val_acc": 52.0}
{"epoch": 73, "training_loss": 0.6908793210983276, "training_acc": 53.0, "val_loss": 0.6894101405143738, "val_acc": 52.0}
