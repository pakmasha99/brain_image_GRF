"main_modify.py --pretrained_path /scratch/connectome/dyhan316/VAE_ADHD/barlowtwins/pretrain_results/ABCDbt128a102.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option BT_org --learning_rate 1e-5 --batch_size 16 --weight_decay 1e-3 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 0.6921806907653809, "training_acc": 53.0, "val_loss": 0.6930847907066345, "val_acc": 52.0}
{"epoch": 1, "training_loss": 0.6921237206459045, "training_acc": 53.0, "val_loss": 0.6930231976509095, "val_acc": 52.0}
{"epoch": 2, "training_loss": 0.6922376656532288, "training_acc": 53.0, "val_loss": 0.6928698468208313, "val_acc": 52.0}
{"epoch": 3, "training_loss": 0.6921623039245606, "training_acc": 53.0, "val_loss": 0.6927993774414063, "val_acc": 52.0}
{"epoch": 4, "training_loss": 0.69180988073349, "training_acc": 53.0, "val_loss": 0.6927820134162903, "val_acc": 52.0}
{"epoch": 5, "training_loss": 0.6915181517601013, "training_acc": 53.0, "val_loss": 0.6927560353279114, "val_acc": 52.0}
{"epoch": 6, "training_loss": 0.6918041515350342, "training_acc": 53.0, "val_loss": 0.6927556991577148, "val_acc": 52.0}
{"epoch": 7, "training_loss": 0.6921169924736023, "training_acc": 53.0, "val_loss": 0.6927741980552673, "val_acc": 52.0}
{"epoch": 8, "training_loss": 0.6917853331565857, "training_acc": 53.0, "val_loss": 0.6928823781013489, "val_acc": 52.0}
{"epoch": 9, "training_loss": 0.6923859548568726, "training_acc": 53.0, "val_loss": 0.6928766584396362, "val_acc": 52.0}
{"epoch": 10, "training_loss": 0.6915929889678956, "training_acc": 53.0, "val_loss": 0.6928119611740112, "val_acc": 52.0}
{"epoch": 11, "training_loss": 0.6920948719978333, "training_acc": 53.0, "val_loss": 0.6927681684494018, "val_acc": 52.0}
{"epoch": 12, "training_loss": 0.6913402891159057, "training_acc": 53.0, "val_loss": 0.6926801681518555, "val_acc": 52.0}
{"epoch": 13, "training_loss": 0.6918002939224244, "training_acc": 53.0, "val_loss": 0.6925910592079163, "val_acc": 52.0}
{"epoch": 14, "training_loss": 0.6919498443603516, "training_acc": 53.0, "val_loss": 0.6925844168663025, "val_acc": 52.0}
{"epoch": 15, "training_loss": 0.6919347333908081, "training_acc": 53.0, "val_loss": 0.6926228809356689, "val_acc": 52.0}
{"epoch": 16, "training_loss": 0.6915890264511109, "training_acc": 53.0, "val_loss": 0.6926494002342224, "val_acc": 52.0}
{"epoch": 17, "training_loss": 0.6920505189895629, "training_acc": 53.0, "val_loss": 0.6926268124580384, "val_acc": 52.0}
{"epoch": 18, "training_loss": 0.6917301917076111, "training_acc": 53.0, "val_loss": 0.6926098370552063, "val_acc": 52.0}
{"epoch": 19, "training_loss": 0.691539294719696, "training_acc": 53.0, "val_loss": 0.6925796222686768, "val_acc": 52.0}
{"epoch": 20, "training_loss": 0.6917120170593262, "training_acc": 53.0, "val_loss": 0.6925360894203186, "val_acc": 52.0}
{"epoch": 21, "training_loss": 0.6918184757232666, "training_acc": 53.0, "val_loss": 0.6925059151649475, "val_acc": 52.0}
{"epoch": 22, "training_loss": 0.6924689054489136, "training_acc": 53.0, "val_loss": 0.6924676465988159, "val_acc": 52.0}
{"epoch": 23, "training_loss": 0.691867642402649, "training_acc": 53.0, "val_loss": 0.6924745655059814, "val_acc": 52.0}
{"epoch": 24, "training_loss": 0.6915992879867554, "training_acc": 53.0, "val_loss": 0.6924862742424012, "val_acc": 52.0}
{"epoch": 25, "training_loss": 0.6919026899337769, "training_acc": 53.0, "val_loss": 0.6924803471565246, "val_acc": 52.0}
{"epoch": 26, "training_loss": 0.6921351194381714, "training_acc": 53.0, "val_loss": 0.6924698638916016, "val_acc": 52.0}
{"epoch": 27, "training_loss": 0.6918229246139527, "training_acc": 53.0, "val_loss": 0.6924523854255676, "val_acc": 52.0}
{"epoch": 28, "training_loss": 0.6916706252098084, "training_acc": 53.0, "val_loss": 0.692445228099823, "val_acc": 52.0}
{"epoch": 29, "training_loss": 0.6925549745559693, "training_acc": 53.0, "val_loss": 0.6924352312088012, "val_acc": 52.0}
{"epoch": 30, "training_loss": 0.6918101978302001, "training_acc": 53.0, "val_loss": 0.6924383521080018, "val_acc": 52.0}
{"epoch": 31, "training_loss": 0.6915577292442322, "training_acc": 53.0, "val_loss": 0.6924332046508789, "val_acc": 52.0}
{"epoch": 32, "training_loss": 0.6918111062049865, "training_acc": 53.0, "val_loss": 0.6924364280700683, "val_acc": 52.0}
{"epoch": 33, "training_loss": 0.6917051792144775, "training_acc": 53.0, "val_loss": 0.6924414825439453, "val_acc": 52.0}
{"epoch": 34, "training_loss": 0.6917194890975952, "training_acc": 53.0, "val_loss": 0.6924475049972534, "val_acc": 52.0}
{"epoch": 35, "training_loss": 0.691806435585022, "training_acc": 53.0, "val_loss": 0.6924547719955444, "val_acc": 52.0}
{"epoch": 36, "training_loss": 0.6921568608283997, "training_acc": 53.0, "val_loss": 0.6924567866325378, "val_acc": 52.0}
{"epoch": 37, "training_loss": 0.6921342873573303, "training_acc": 53.0, "val_loss": 0.6924738311767578, "val_acc": 52.0}
{"epoch": 38, "training_loss": 0.6917112684249878, "training_acc": 53.0, "val_loss": 0.6924629831314086, "val_acc": 52.0}
{"epoch": 39, "training_loss": 0.6923748564720154, "training_acc": 53.0, "val_loss": 0.6924735760688782, "val_acc": 52.0}
{"epoch": 40, "training_loss": 0.6917150354385376, "training_acc": 53.0, "val_loss": 0.6924632954597473, "val_acc": 52.0}
{"epoch": 41, "training_loss": 0.6919370484352112, "training_acc": 53.0, "val_loss": 0.6924658727645874, "val_acc": 52.0}
{"epoch": 42, "training_loss": 0.6917124509811401, "training_acc": 53.0, "val_loss": 0.6924492454528809, "val_acc": 52.0}
{"epoch": 43, "training_loss": 0.6919012689590454, "training_acc": 53.0, "val_loss": 0.6924351501464844, "val_acc": 52.0}
{"epoch": 44, "training_loss": 0.6916289591789245, "training_acc": 53.0, "val_loss": 0.6924381732940674, "val_acc": 52.0}
{"epoch": 45, "training_loss": 0.6919715595245362, "training_acc": 53.0, "val_loss": 0.6924522399902344, "val_acc": 52.0}
{"epoch": 46, "training_loss": 0.6913663363456726, "training_acc": 53.0, "val_loss": 0.692479932308197, "val_acc": 52.0}
{"epoch": 47, "training_loss": 0.691844048500061, "training_acc": 53.0, "val_loss": 0.692508020401001, "val_acc": 52.0}
{"epoch": 48, "training_loss": 0.6918151140213012, "training_acc": 53.0, "val_loss": 0.692538833618164, "val_acc": 52.0}
{"epoch": 49, "training_loss": 0.6917460584640502, "training_acc": 53.0, "val_loss": 0.6925511574745178, "val_acc": 52.0}
{"epoch": 50, "training_loss": 0.6923573899269104, "training_acc": 53.0, "val_loss": 0.6925591087341308, "val_acc": 52.0}
