"main_modify.py --pretrained_path /scratch/connectome/dyhan316/VAE_ADHD/barlowtwins/pretrain_results/ABCDbt128a102.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option BT_org --learning_rate 1e-5 --batch_size 16 --weight_decay 1e-3 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 0.6923812198638916, "training_acc": 53.0, "val_loss": 0.6956890892982482, "val_acc": 52.0}
{"epoch": 1, "training_loss": 0.6920027875900269, "training_acc": 53.0, "val_loss": 0.6954699063301086, "val_acc": 52.0}
{"epoch": 2, "training_loss": 0.6918643593788147, "training_acc": 53.0, "val_loss": 0.6952326130867005, "val_acc": 52.0}
{"epoch": 3, "training_loss": 0.6921254396438599, "training_acc": 53.0, "val_loss": 0.6951895689964295, "val_acc": 52.0}
{"epoch": 4, "training_loss": 0.6915046262741089, "training_acc": 53.0, "val_loss": 0.6950716900825501, "val_acc": 52.0}
{"epoch": 5, "training_loss": 0.6917135095596314, "training_acc": 53.0, "val_loss": 0.6949707627296448, "val_acc": 52.0}
{"epoch": 6, "training_loss": 0.6914286518096924, "training_acc": 53.0, "val_loss": 0.6949328541755676, "val_acc": 52.0}
{"epoch": 7, "training_loss": 0.6909775400161743, "training_acc": 53.0, "val_loss": 0.6948013401031494, "val_acc": 52.0}
{"epoch": 8, "training_loss": 0.6915619945526124, "training_acc": 53.0, "val_loss": 0.6945541715621948, "val_acc": 52.0}
{"epoch": 9, "training_loss": 0.6910114240646362, "training_acc": 53.0, "val_loss": 0.6943929243087769, "val_acc": 52.0}
{"epoch": 10, "training_loss": 0.6909772205352783, "training_acc": 53.0, "val_loss": 0.6942634558677674, "val_acc": 52.0}
{"epoch": 11, "training_loss": 0.6904906797409057, "training_acc": 53.0, "val_loss": 0.6941265869140625, "val_acc": 52.0}
{"epoch": 12, "training_loss": 0.6907043981552125, "training_acc": 53.0, "val_loss": 0.6939668393135071, "val_acc": 52.0}
{"epoch": 13, "training_loss": 0.6911006355285645, "training_acc": 53.0, "val_loss": 0.6938434624671936, "val_acc": 52.0}
{"epoch": 14, "training_loss": 0.6909394001960755, "training_acc": 53.0, "val_loss": 0.6937130331993103, "val_acc": 52.0}
{"epoch": 15, "training_loss": 0.6908768749237061, "training_acc": 53.0, "val_loss": 0.6936698317527771, "val_acc": 52.0}
{"epoch": 16, "training_loss": 0.6906959080696106, "training_acc": 53.0, "val_loss": 0.6935956954956055, "val_acc": 52.0}
{"epoch": 17, "training_loss": 0.6905036759376526, "training_acc": 53.0, "val_loss": 0.693630826473236, "val_acc": 52.0}
{"epoch": 18, "training_loss": 0.690807044506073, "training_acc": 53.0, "val_loss": 0.6936458539962769, "val_acc": 52.0}
{"epoch": 19, "training_loss": 0.6905788087844849, "training_acc": 53.0, "val_loss": 0.6936168360710144, "val_acc": 52.0}
{"epoch": 20, "training_loss": 0.6906413149833679, "training_acc": 53.0, "val_loss": 0.6936595487594605, "val_acc": 52.0}
{"epoch": 21, "training_loss": 0.6909066390991211, "training_acc": 53.0, "val_loss": 0.6936843490600586, "val_acc": 52.0}
{"epoch": 22, "training_loss": 0.6904740452766418, "training_acc": 53.0, "val_loss": 0.6935816526412963, "val_acc": 52.0}
{"epoch": 23, "training_loss": 0.6908338975906372, "training_acc": 53.0, "val_loss": 0.6935066723823547, "val_acc": 52.0}
{"epoch": 24, "training_loss": 0.6904785585403442, "training_acc": 53.0, "val_loss": 0.6934511947631836, "val_acc": 52.0}
{"epoch": 25, "training_loss": 0.6904151058197021, "training_acc": 53.0, "val_loss": 0.6934066438674926, "val_acc": 52.0}
{"epoch": 26, "training_loss": 0.6904640698432922, "training_acc": 53.0, "val_loss": 0.6933229446411133, "val_acc": 52.0}
{"epoch": 27, "training_loss": 0.6905714058876038, "training_acc": 53.0, "val_loss": 0.6933126163482666, "val_acc": 52.0}
{"epoch": 28, "training_loss": 0.6904872703552246, "training_acc": 53.0, "val_loss": 0.6932923936843872, "val_acc": 52.0}
{"epoch": 29, "training_loss": 0.6908039426803589, "training_acc": 53.0, "val_loss": 0.693272659778595, "val_acc": 52.0}
{"epoch": 30, "training_loss": 0.6903590607643127, "training_acc": 53.0, "val_loss": 0.6932560706138611, "val_acc": 52.0}
{"epoch": 31, "training_loss": 0.6908667802810669, "training_acc": 53.0, "val_loss": 0.6932541656494141, "val_acc": 52.0}
{"epoch": 32, "training_loss": 0.6907389998435974, "training_acc": 53.0, "val_loss": 0.6932721757888793, "val_acc": 52.0}
{"epoch": 33, "training_loss": 0.6905838990211487, "training_acc": 53.0, "val_loss": 0.6932868051528931, "val_acc": 52.0}
{"epoch": 34, "training_loss": 0.690254807472229, "training_acc": 53.0, "val_loss": 0.6932489490509033, "val_acc": 52.0}
{"epoch": 35, "training_loss": 0.6910366249084473, "training_acc": 53.0, "val_loss": 0.6932342958450317, "val_acc": 52.0}
{"epoch": 36, "training_loss": 0.6904830646514892, "training_acc": 53.0, "val_loss": 0.6932285499572753, "val_acc": 52.0}
{"epoch": 37, "training_loss": 0.6909280443191528, "training_acc": 53.0, "val_loss": 0.6932170271873475, "val_acc": 52.0}
{"epoch": 38, "training_loss": 0.6905638408660889, "training_acc": 53.0, "val_loss": 0.6932144522666931, "val_acc": 52.0}
{"epoch": 39, "training_loss": 0.6906283807754516, "training_acc": 53.0, "val_loss": 0.6932202172279358, "val_acc": 52.0}
{"epoch": 40, "training_loss": 0.690959849357605, "training_acc": 53.0, "val_loss": 0.6932299113273621, "val_acc": 52.0}
{"epoch": 41, "training_loss": 0.6904301738739014, "training_acc": 53.0, "val_loss": 0.6932657504081726, "val_acc": 52.0}
{"epoch": 42, "training_loss": 0.6903026533126831, "training_acc": 53.0, "val_loss": 0.6932647061347962, "val_acc": 52.0}
{"epoch": 43, "training_loss": 0.6905784082412719, "training_acc": 53.0, "val_loss": 0.693244812488556, "val_acc": 52.0}
{"epoch": 44, "training_loss": 0.6909744763374328, "training_acc": 53.0, "val_loss": 0.6932271385192871, "val_acc": 52.0}
{"epoch": 45, "training_loss": 0.6905061745643616, "training_acc": 53.0, "val_loss": 0.6932064199447632, "val_acc": 52.0}
{"epoch": 46, "training_loss": 0.691062421798706, "training_acc": 53.0, "val_loss": 0.6932085633277894, "val_acc": 52.0}
{"epoch": 47, "training_loss": 0.6901894187927247, "training_acc": 53.0, "val_loss": 0.6931958270072937, "val_acc": 52.0}
{"epoch": 48, "training_loss": 0.691243588924408, "training_acc": 53.0, "val_loss": 0.6931883096694946, "val_acc": 52.0}
{"epoch": 49, "training_loss": 0.6905330276489258, "training_acc": 53.0, "val_loss": 0.6931931686401367, "val_acc": 52.0}
{"epoch": 50, "training_loss": 0.6905343294143677, "training_acc": 53.0, "val_loss": 0.6932176518440246, "val_acc": 52.0}
{"epoch": 51, "training_loss": 0.6904713535308837, "training_acc": 53.0, "val_loss": 0.6932390189170837, "val_acc": 52.0}
{"epoch": 52, "training_loss": 0.6913563346862793, "training_acc": 53.0, "val_loss": 0.6932589554786682, "val_acc": 52.0}
{"epoch": 53, "training_loss": 0.6904811954498291, "training_acc": 53.0, "val_loss": 0.6932734370231628, "val_acc": 52.0}
{"epoch": 54, "training_loss": 0.6909875679016113, "training_acc": 53.0, "val_loss": 0.6933274149894715, "val_acc": 52.0}
{"epoch": 55, "training_loss": 0.6907863044738769, "training_acc": 53.0, "val_loss": 0.693404290676117, "val_acc": 52.0}
{"epoch": 56, "training_loss": 0.6907495355606079, "training_acc": 53.0, "val_loss": 0.6934373140335083, "val_acc": 52.0}
{"epoch": 57, "training_loss": 0.6904549169540405, "training_acc": 53.0, "val_loss": 0.6934831094741821, "val_acc": 52.0}
{"epoch": 58, "training_loss": 0.6902223062515259, "training_acc": 53.0, "val_loss": 0.693463327884674, "val_acc": 52.0}
{"epoch": 59, "training_loss": 0.6908247184753418, "training_acc": 53.0, "val_loss": 0.693386754989624, "val_acc": 52.0}
{"epoch": 60, "training_loss": 0.6909173345565796, "training_acc": 53.0, "val_loss": 0.6933599805831909, "val_acc": 52.0}
{"epoch": 61, "training_loss": 0.690421404838562, "training_acc": 53.0, "val_loss": 0.6933645343780518, "val_acc": 52.0}
{"epoch": 62, "training_loss": 0.6905280566215515, "training_acc": 53.0, "val_loss": 0.6933940529823304, "val_acc": 52.0}
{"epoch": 63, "training_loss": 0.6907250213623047, "training_acc": 53.0, "val_loss": 0.6934209871292114, "val_acc": 52.0}
{"epoch": 64, "training_loss": 0.6905085945129394, "training_acc": 53.0, "val_loss": 0.6934031772613526, "val_acc": 52.0}
{"epoch": 65, "training_loss": 0.6904313802719116, "training_acc": 53.0, "val_loss": 0.6934167528152466, "val_acc": 52.0}
{"epoch": 66, "training_loss": 0.6905662727355957, "training_acc": 53.0, "val_loss": 0.6934315252304077, "val_acc": 52.0}
{"epoch": 67, "training_loss": 0.6902590155601501, "training_acc": 53.0, "val_loss": 0.6934239649772644, "val_acc": 52.0}
