"main_modify.py --pretrained_path /scratch/connectome/dyhan316/VAE_ADHD/barlowtwins/pretrain_results/ABCDbt128a102.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option BT_org --learning_rate 1e-6 --batch_size 16 --weight_decay 1e-2 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 0.6922509002685547, "training_acc": 52.0, "val_loss": 0.6885158252716065, "val_acc": 56.0}
{"epoch": 1, "training_loss": 0.6923713040351868, "training_acc": 52.0, "val_loss": 0.6885036158561707, "val_acc": 56.0}
{"epoch": 2, "training_loss": 0.6923884630203248, "training_acc": 52.0, "val_loss": 0.6884990406036376, "val_acc": 56.0}
{"epoch": 3, "training_loss": 0.692123007774353, "training_acc": 52.0, "val_loss": 0.6884755754470825, "val_acc": 56.0}
{"epoch": 4, "training_loss": 0.6923734712600708, "training_acc": 52.0, "val_loss": 0.6884797215461731, "val_acc": 56.0}
{"epoch": 5, "training_loss": 0.6921837711334229, "training_acc": 52.0, "val_loss": 0.6884649991989136, "val_acc": 56.0}
{"epoch": 6, "training_loss": 0.6920616674423218, "training_acc": 52.0, "val_loss": 0.6884556317329407, "val_acc": 56.0}
{"epoch": 7, "training_loss": 0.6921636056900025, "training_acc": 52.0, "val_loss": 0.6884565854072571, "val_acc": 56.0}
{"epoch": 8, "training_loss": 0.6920010209083557, "training_acc": 52.0, "val_loss": 0.6884395575523377, "val_acc": 56.0}
{"epoch": 9, "training_loss": 0.6921641516685486, "training_acc": 52.0, "val_loss": 0.6884431076049805, "val_acc": 56.0}
{"epoch": 10, "training_loss": 0.692381522655487, "training_acc": 52.0, "val_loss": 0.6884604644775391, "val_acc": 56.0}
{"epoch": 11, "training_loss": 0.6920357036590576, "training_acc": 52.0, "val_loss": 0.6884559559822082, "val_acc": 56.0}
{"epoch": 12, "training_loss": 0.6925537657737731, "training_acc": 52.0, "val_loss": 0.688423080444336, "val_acc": 56.0}
{"epoch": 13, "training_loss": 0.6920079636573792, "training_acc": 52.0, "val_loss": 0.6884143209457397, "val_acc": 56.0}
{"epoch": 14, "training_loss": 0.6923296928405762, "training_acc": 52.0, "val_loss": 0.6883948063850402, "val_acc": 56.0}
{"epoch": 15, "training_loss": 0.6924197173118591, "training_acc": 52.0, "val_loss": 0.6883831334114074, "val_acc": 56.0}
{"epoch": 16, "training_loss": 0.6926696443557739, "training_acc": 52.0, "val_loss": 0.6883478093147278, "val_acc": 56.0}
{"epoch": 17, "training_loss": 0.6920346546173096, "training_acc": 52.0, "val_loss": 0.6883483052253723, "val_acc": 56.0}
{"epoch": 18, "training_loss": 0.6923757076263428, "training_acc": 52.0, "val_loss": 0.68835608959198, "val_acc": 56.0}
{"epoch": 19, "training_loss": 0.6921601223945618, "training_acc": 52.0, "val_loss": 0.6883709764480591, "val_acc": 56.0}
{"epoch": 20, "training_loss": 0.6924325823783875, "training_acc": 52.0, "val_loss": 0.6883671498298645, "val_acc": 56.0}
{"epoch": 21, "training_loss": 0.6917929410934448, "training_acc": 52.0, "val_loss": 0.6883668947219849, "val_acc": 56.0}
{"epoch": 22, "training_loss": 0.691957950592041, "training_acc": 52.0, "val_loss": 0.6883559513092041, "val_acc": 56.0}
{"epoch": 23, "training_loss": 0.6922150087356568, "training_acc": 52.0, "val_loss": 0.6883568120002747, "val_acc": 56.0}
{"epoch": 24, "training_loss": 0.6924657392501831, "training_acc": 52.0, "val_loss": 0.6883361387252808, "val_acc": 56.0}
{"epoch": 25, "training_loss": 0.6923988628387451, "training_acc": 52.0, "val_loss": 0.6883385157585145, "val_acc": 56.0}
{"epoch": 26, "training_loss": 0.6915854072570801, "training_acc": 52.0, "val_loss": 0.6883323574066162, "val_acc": 56.0}
{"epoch": 27, "training_loss": 0.6918686676025391, "training_acc": 52.0, "val_loss": 0.6883351302146912, "val_acc": 56.0}
{"epoch": 28, "training_loss": 0.6921701765060425, "training_acc": 52.0, "val_loss": 0.6883333063125611, "val_acc": 56.0}
{"epoch": 29, "training_loss": 0.6923461055755615, "training_acc": 52.0, "val_loss": 0.6883184385299682, "val_acc": 56.0}
{"epoch": 30, "training_loss": 0.6920380115509033, "training_acc": 52.0, "val_loss": 0.6882822775840759, "val_acc": 56.0}
{"epoch": 31, "training_loss": 0.6921746182441711, "training_acc": 52.0, "val_loss": 0.6882618427276611, "val_acc": 56.0}
{"epoch": 32, "training_loss": 0.6919823384284973, "training_acc": 52.0, "val_loss": 0.6882210302352906, "val_acc": 56.0}
{"epoch": 33, "training_loss": 0.692438383102417, "training_acc": 52.0, "val_loss": 0.6881953358650208, "val_acc": 56.0}
{"epoch": 34, "training_loss": 0.6923981595039368, "training_acc": 52.0, "val_loss": 0.6881903433799743, "val_acc": 56.0}
{"epoch": 35, "training_loss": 0.6918370532989502, "training_acc": 52.0, "val_loss": 0.6881980919837951, "val_acc": 56.0}
{"epoch": 36, "training_loss": 0.6926154351234436, "training_acc": 52.0, "val_loss": 0.6881901693344116, "val_acc": 56.0}
{"epoch": 37, "training_loss": 0.692737283706665, "training_acc": 52.0, "val_loss": 0.6881770396232605, "val_acc": 56.0}
{"epoch": 38, "training_loss": 0.6924602127075196, "training_acc": 52.0, "val_loss": 0.6881756520271302, "val_acc": 56.0}
{"epoch": 39, "training_loss": 0.6925748991966247, "training_acc": 52.0, "val_loss": 0.6881755828857422, "val_acc": 56.0}
{"epoch": 40, "training_loss": 0.6924904060363769, "training_acc": 52.0, "val_loss": 0.6881871747970582, "val_acc": 56.0}
{"epoch": 41, "training_loss": 0.6919221353530883, "training_acc": 52.0, "val_loss": 0.6881854653358459, "val_acc": 56.0}
{"epoch": 42, "training_loss": 0.6919394969940186, "training_acc": 52.0, "val_loss": 0.6881841135025024, "val_acc": 56.0}
{"epoch": 43, "training_loss": 0.691771399974823, "training_acc": 52.0, "val_loss": 0.6881833791732788, "val_acc": 56.0}
{"epoch": 44, "training_loss": 0.6924411678314208, "training_acc": 52.0, "val_loss": 0.6882022500038147, "val_acc": 56.0}
{"epoch": 45, "training_loss": 0.6921705627441406, "training_acc": 52.0, "val_loss": 0.6882055592536926, "val_acc": 56.0}
{"epoch": 46, "training_loss": 0.6919178462028504, "training_acc": 52.0, "val_loss": 0.6882051157951355, "val_acc": 56.0}
{"epoch": 47, "training_loss": 0.6923852062225342, "training_acc": 52.0, "val_loss": 0.6881974196434021, "val_acc": 56.0}
{"epoch": 48, "training_loss": 0.6922415208816528, "training_acc": 52.0, "val_loss": 0.6881879949569703, "val_acc": 56.0}
{"epoch": 49, "training_loss": 0.6921451473236084, "training_acc": 52.0, "val_loss": 0.6881916117668152, "val_acc": 56.0}
{"epoch": 50, "training_loss": 0.6925732254981994, "training_acc": 52.0, "val_loss": 0.6882091999053955, "val_acc": 56.0}
{"epoch": 51, "training_loss": 0.69254634141922, "training_acc": 52.0, "val_loss": 0.6882277393341064, "val_acc": 56.0}
{"epoch": 52, "training_loss": 0.6923064541816711, "training_acc": 52.0, "val_loss": 0.6882499289512635, "val_acc": 56.0}
{"epoch": 53, "training_loss": 0.6921753573417664, "training_acc": 52.0, "val_loss": 0.6882579374313355, "val_acc": 56.0}
{"epoch": 54, "training_loss": 0.6924763321876526, "training_acc": 52.0, "val_loss": 0.6882673692703247, "val_acc": 56.0}
{"epoch": 55, "training_loss": 0.6923313808441162, "training_acc": 52.0, "val_loss": 0.6882876396179199, "val_acc": 56.0}
{"epoch": 56, "training_loss": 0.6921663951873779, "training_acc": 52.0, "val_loss": 0.6883180522918702, "val_acc": 56.0}
{"epoch": 57, "training_loss": 0.6919707775115966, "training_acc": 52.0, "val_loss": 0.6883512330055237, "val_acc": 56.0}
{"epoch": 58, "training_loss": 0.6923975563049316, "training_acc": 52.0, "val_loss": 0.6883430123329163, "val_acc": 56.0}
