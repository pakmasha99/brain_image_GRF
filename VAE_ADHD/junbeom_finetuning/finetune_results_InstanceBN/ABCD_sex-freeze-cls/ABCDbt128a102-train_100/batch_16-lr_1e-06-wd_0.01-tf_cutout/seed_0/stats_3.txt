"main_modify.py --pretrained_path /scratch/connectome/dyhan316/VAE_ADHD/barlowtwins/pretrain_results/ABCDbt128a102.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option BT_org --learning_rate 1e-6 --batch_size 16 --weight_decay 1e-2 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 0.6926284074783325, "training_acc": 53.0, "val_loss": 0.6936646366119384, "val_acc": 52.0}
{"epoch": 1, "training_loss": 0.6923125219345093, "training_acc": 53.0, "val_loss": 0.6936682558059692, "val_acc": 52.0}
{"epoch": 2, "training_loss": 0.6922316932678223, "training_acc": 53.0, "val_loss": 0.6936676287651062, "val_acc": 52.0}
{"epoch": 3, "training_loss": 0.6922909760475159, "training_acc": 53.0, "val_loss": 0.6936620020866394, "val_acc": 52.0}
{"epoch": 4, "training_loss": 0.6924790358543396, "training_acc": 53.0, "val_loss": 0.6936506295204162, "val_acc": 52.0}
{"epoch": 5, "training_loss": 0.691879255771637, "training_acc": 53.0, "val_loss": 0.6936411762237549, "val_acc": 52.0}
{"epoch": 6, "training_loss": 0.6920506453514099, "training_acc": 53.0, "val_loss": 0.6936354875564575, "val_acc": 52.0}
{"epoch": 7, "training_loss": 0.6918492317199707, "training_acc": 53.0, "val_loss": 0.6936313486099244, "val_acc": 52.0}
{"epoch": 8, "training_loss": 0.6918920159339905, "training_acc": 53.0, "val_loss": 0.6936265563964844, "val_acc": 52.0}
{"epoch": 9, "training_loss": 0.6923141169548035, "training_acc": 53.0, "val_loss": 0.6936181735992432, "val_acc": 52.0}
{"epoch": 10, "training_loss": 0.6919920182228089, "training_acc": 53.0, "val_loss": 0.6936109662055969, "val_acc": 52.0}
{"epoch": 11, "training_loss": 0.6920317006111145, "training_acc": 53.0, "val_loss": 0.6935991311073303, "val_acc": 52.0}
{"epoch": 12, "training_loss": 0.6920045757293701, "training_acc": 53.0, "val_loss": 0.6935855078697205, "val_acc": 52.0}
{"epoch": 13, "training_loss": 0.6920580697059632, "training_acc": 53.0, "val_loss": 0.693579912185669, "val_acc": 52.0}
{"epoch": 14, "training_loss": 0.69197518825531, "training_acc": 53.0, "val_loss": 0.6935761785507202, "val_acc": 52.0}
{"epoch": 15, "training_loss": 0.6917563772201538, "training_acc": 53.0, "val_loss": 0.6935695004463196, "val_acc": 52.0}
{"epoch": 16, "training_loss": 0.6918193507194519, "training_acc": 53.0, "val_loss": 0.6935618543624877, "val_acc": 52.0}
{"epoch": 17, "training_loss": 0.6918467330932617, "training_acc": 53.0, "val_loss": 0.6935615468025208, "val_acc": 52.0}
{"epoch": 18, "training_loss": 0.6919208955764771, "training_acc": 53.0, "val_loss": 0.6935602140426635, "val_acc": 52.0}
{"epoch": 19, "training_loss": 0.6919412183761596, "training_acc": 53.0, "val_loss": 0.693557996749878, "val_acc": 52.0}
{"epoch": 20, "training_loss": 0.6919116258621216, "training_acc": 53.0, "val_loss": 0.6935521650314331, "val_acc": 52.0}
{"epoch": 21, "training_loss": 0.6920218968391418, "training_acc": 53.0, "val_loss": 0.693548059463501, "val_acc": 52.0}
{"epoch": 22, "training_loss": 0.6925425839424133, "training_acc": 53.0, "val_loss": 0.6935438919067383, "val_acc": 52.0}
{"epoch": 23, "training_loss": 0.6919565320014953, "training_acc": 53.0, "val_loss": 0.693535304069519, "val_acc": 52.0}
{"epoch": 24, "training_loss": 0.6917348551750183, "training_acc": 53.0, "val_loss": 0.6935234761238098, "val_acc": 52.0}
{"epoch": 25, "training_loss": 0.6918518733978272, "training_acc": 53.0, "val_loss": 0.6935166811943054, "val_acc": 52.0}
{"epoch": 26, "training_loss": 0.6918444490432739, "training_acc": 53.0, "val_loss": 0.6935157585144043, "val_acc": 52.0}
{"epoch": 27, "training_loss": 0.6918103981018067, "training_acc": 53.0, "val_loss": 0.6935126948356628, "val_acc": 52.0}
{"epoch": 28, "training_loss": 0.6918283605575561, "training_acc": 53.0, "val_loss": 0.6935084962844849, "val_acc": 52.0}
{"epoch": 29, "training_loss": 0.6920358085632324, "training_acc": 53.0, "val_loss": 0.6935063505172729, "val_acc": 52.0}
{"epoch": 30, "training_loss": 0.6915444040298462, "training_acc": 53.0, "val_loss": 0.6935031676292419, "val_acc": 52.0}
{"epoch": 31, "training_loss": 0.691916069984436, "training_acc": 53.0, "val_loss": 0.6934938526153565, "val_acc": 52.0}
{"epoch": 32, "training_loss": 0.692183210849762, "training_acc": 53.0, "val_loss": 0.6934847998619079, "val_acc": 52.0}
{"epoch": 33, "training_loss": 0.6920076966285705, "training_acc": 53.0, "val_loss": 0.6934791088104248, "val_acc": 52.0}
{"epoch": 34, "training_loss": 0.6918095874786377, "training_acc": 53.0, "val_loss": 0.6934753513336182, "val_acc": 52.0}
{"epoch": 35, "training_loss": 0.6914627313613891, "training_acc": 53.0, "val_loss": 0.6934721660614014, "val_acc": 52.0}
{"epoch": 36, "training_loss": 0.6918941855430603, "training_acc": 53.0, "val_loss": 0.6934697437286377, "val_acc": 52.0}
{"epoch": 37, "training_loss": 0.6916537594795227, "training_acc": 53.0, "val_loss": 0.6934696888923645, "val_acc": 52.0}
{"epoch": 38, "training_loss": 0.6923085880279541, "training_acc": 53.0, "val_loss": 0.6934737014770508, "val_acc": 52.0}
{"epoch": 39, "training_loss": 0.6915738797187805, "training_acc": 53.0, "val_loss": 0.693472855091095, "val_acc": 52.0}
{"epoch": 40, "training_loss": 0.6915795230865478, "training_acc": 53.0, "val_loss": 0.6934693002700806, "val_acc": 52.0}
{"epoch": 41, "training_loss": 0.6917271494865418, "training_acc": 53.0, "val_loss": 0.6934681439399719, "val_acc": 52.0}
{"epoch": 42, "training_loss": 0.6918090796470642, "training_acc": 53.0, "val_loss": 0.6934659934043884, "val_acc": 52.0}
{"epoch": 43, "training_loss": 0.6917134022712708, "training_acc": 53.0, "val_loss": 0.6934640550613403, "val_acc": 52.0}
{"epoch": 44, "training_loss": 0.6918821620941162, "training_acc": 53.0, "val_loss": 0.6934587454795837, "val_acc": 52.0}
{"epoch": 45, "training_loss": 0.6918342113494873, "training_acc": 53.0, "val_loss": 0.6934569120407105, "val_acc": 52.0}
{"epoch": 46, "training_loss": 0.6916118764877319, "training_acc": 53.0, "val_loss": 0.6934534311294556, "val_acc": 52.0}
{"epoch": 47, "training_loss": 0.6914143586158752, "training_acc": 53.0, "val_loss": 0.6934521222114562, "val_acc": 52.0}
{"epoch": 48, "training_loss": 0.691970191001892, "training_acc": 53.0, "val_loss": 0.6934473872184753, "val_acc": 52.0}
{"epoch": 49, "training_loss": 0.6918462038040161, "training_acc": 53.0, "val_loss": 0.6934408640861511, "val_acc": 52.0}
{"epoch": 50, "training_loss": 0.6917101573944092, "training_acc": 53.0, "val_loss": 0.6934352612495422, "val_acc": 52.0}
{"epoch": 51, "training_loss": 0.6914493608474731, "training_acc": 53.0, "val_loss": 0.6934319424629212, "val_acc": 52.0}
{"epoch": 52, "training_loss": 0.6917678928375244, "training_acc": 53.0, "val_loss": 0.6934283542633056, "val_acc": 52.0}
{"epoch": 53, "training_loss": 0.6919986438751221, "training_acc": 53.0, "val_loss": 0.6934254384040832, "val_acc": 52.0}
{"epoch": 54, "training_loss": 0.6916915512084961, "training_acc": 53.0, "val_loss": 0.6934207630157471, "val_acc": 52.0}
{"epoch": 55, "training_loss": 0.6917661356925965, "training_acc": 53.0, "val_loss": 0.6934143495559693, "val_acc": 52.0}
{"epoch": 56, "training_loss": 0.6913369750976562, "training_acc": 53.0, "val_loss": 0.6934094190597534, "val_acc": 52.0}
{"epoch": 57, "training_loss": 0.6916018629074097, "training_acc": 53.0, "val_loss": 0.6934043884277343, "val_acc": 52.0}
{"epoch": 58, "training_loss": 0.6911754107475281, "training_acc": 53.0, "val_loss": 0.693402099609375, "val_acc": 52.0}
{"epoch": 59, "training_loss": 0.6919731903076172, "training_acc": 53.0, "val_loss": 0.6933984422683716, "val_acc": 52.0}
{"epoch": 60, "training_loss": 0.691376600265503, "training_acc": 53.0, "val_loss": 0.693399167060852, "val_acc": 52.0}
{"epoch": 61, "training_loss": 0.6916205072402954, "training_acc": 53.0, "val_loss": 0.6933978152275085, "val_acc": 52.0}
{"epoch": 62, "training_loss": 0.6919366931915283, "training_acc": 53.0, "val_loss": 0.6933967161178589, "val_acc": 52.0}
{"epoch": 63, "training_loss": 0.6916425347328186, "training_acc": 53.0, "val_loss": 0.6933926033973694, "val_acc": 52.0}
{"epoch": 64, "training_loss": 0.6913874006271362, "training_acc": 53.0, "val_loss": 0.6933870267868042, "val_acc": 52.0}
{"epoch": 65, "training_loss": 0.6918864154815674, "training_acc": 53.0, "val_loss": 0.6933824706077576, "val_acc": 52.0}
{"epoch": 66, "training_loss": 0.6919072532653808, "training_acc": 53.0, "val_loss": 0.6933795642852784, "val_acc": 52.0}
{"epoch": 67, "training_loss": 0.6914001274108886, "training_acc": 53.0, "val_loss": 0.6933797764778137, "val_acc": 52.0}
{"epoch": 68, "training_loss": 0.6917807698249817, "training_acc": 53.0, "val_loss": 0.6933781027793884, "val_acc": 52.0}
{"epoch": 69, "training_loss": 0.6919235610961914, "training_acc": 53.0, "val_loss": 0.6933756422996521, "val_acc": 52.0}
{"epoch": 70, "training_loss": 0.6915164017677307, "training_acc": 53.0, "val_loss": 0.6933764362335205, "val_acc": 52.0}
{"epoch": 71, "training_loss": 0.6917453479766845, "training_acc": 53.0, "val_loss": 0.6933749842643738, "val_acc": 52.0}
{"epoch": 72, "training_loss": 0.6913598561286927, "training_acc": 53.0, "val_loss": 0.6933756303787232, "val_acc": 52.0}
{"epoch": 73, "training_loss": 0.6913782095909119, "training_acc": 53.0, "val_loss": 0.6933745193481445, "val_acc": 52.0}
{"epoch": 74, "training_loss": 0.6916467142105103, "training_acc": 53.0, "val_loss": 0.6933713865280151, "val_acc": 52.0}
{"epoch": 75, "training_loss": 0.6917430019378662, "training_acc": 53.0, "val_loss": 0.6933700156211853, "val_acc": 52.0}
{"epoch": 76, "training_loss": 0.6918138766288757, "training_acc": 53.0, "val_loss": 0.6933661770820617, "val_acc": 52.0}
{"epoch": 77, "training_loss": 0.6914299535751343, "training_acc": 53.0, "val_loss": 0.6933650517463684, "val_acc": 52.0}
{"epoch": 78, "training_loss": 0.6913374400138855, "training_acc": 53.0, "val_loss": 0.6933629751205445, "val_acc": 52.0}
{"epoch": 79, "training_loss": 0.6913203573226929, "training_acc": 53.0, "val_loss": 0.6933640623092652, "val_acc": 52.0}
{"epoch": 80, "training_loss": 0.6915962743759155, "training_acc": 53.0, "val_loss": 0.693364622592926, "val_acc": 52.0}
{"epoch": 81, "training_loss": 0.6913048791885376, "training_acc": 53.0, "val_loss": 0.6933653950691223, "val_acc": 52.0}
{"epoch": 82, "training_loss": 0.691717529296875, "training_acc": 53.0, "val_loss": 0.6933641910552979, "val_acc": 52.0}
{"epoch": 83, "training_loss": 0.6915649461746216, "training_acc": 53.0, "val_loss": 0.6933616352081299, "val_acc": 52.0}
{"epoch": 84, "training_loss": 0.6913944363594056, "training_acc": 53.0, "val_loss": 0.6933606314659119, "val_acc": 52.0}
{"epoch": 85, "training_loss": 0.6915561437606812, "training_acc": 53.0, "val_loss": 0.6933600783348084, "val_acc": 52.0}
{"epoch": 86, "training_loss": 0.6914134240150451, "training_acc": 53.0, "val_loss": 0.6933584523200989, "val_acc": 52.0}
{"epoch": 87, "training_loss": 0.691694188117981, "training_acc": 53.0, "val_loss": 0.6933561038970947, "val_acc": 52.0}
{"epoch": 88, "training_loss": 0.6917239546775817, "training_acc": 53.0, "val_loss": 0.6933534550666809, "val_acc": 52.0}
{"epoch": 89, "training_loss": 0.69166184425354, "training_acc": 53.0, "val_loss": 0.6933532071113586, "val_acc": 52.0}
{"epoch": 90, "training_loss": 0.6914106845855713, "training_acc": 53.0, "val_loss": 0.6933546113967896, "val_acc": 52.0}
{"epoch": 91, "training_loss": 0.6914349055290222, "training_acc": 53.0, "val_loss": 0.6933558917045594, "val_acc": 52.0}
{"epoch": 92, "training_loss": 0.6919827556610108, "training_acc": 53.0, "val_loss": 0.6933568429946899, "val_acc": 52.0}
{"epoch": 93, "training_loss": 0.6913443684577942, "training_acc": 53.0, "val_loss": 0.6933571171760559, "val_acc": 52.0}
{"epoch": 94, "training_loss": 0.6915551209449768, "training_acc": 53.0, "val_loss": 0.6933572554588318, "val_acc": 52.0}
{"epoch": 95, "training_loss": 0.6913479256629944, "training_acc": 53.0, "val_loss": 0.6933579182624817, "val_acc": 52.0}
{"epoch": 96, "training_loss": 0.6910466241836548, "training_acc": 53.0, "val_loss": 0.6933579778671265, "val_acc": 52.0}
{"epoch": 97, "training_loss": 0.6918517613410949, "training_acc": 53.0, "val_loss": 0.6933570504188538, "val_acc": 52.0}
{"epoch": 98, "training_loss": 0.6911569261550903, "training_acc": 53.0, "val_loss": 0.6933559918403626, "val_acc": 52.0}
{"epoch": 99, "training_loss": 0.691999683380127, "training_acc": 53.0, "val_loss": 0.693355324268341, "val_acc": 52.0}
