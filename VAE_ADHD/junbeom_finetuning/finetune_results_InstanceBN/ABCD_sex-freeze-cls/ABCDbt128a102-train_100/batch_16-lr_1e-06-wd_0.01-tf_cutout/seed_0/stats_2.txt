"main_modify.py --pretrained_path /scratch/connectome/dyhan316/VAE_ADHD/barlowtwins/pretrain_results/ABCDbt128a102.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option BT_org --learning_rate 1e-6 --batch_size 16 --weight_decay 1e-2 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 0.6923043918609619, "training_acc": 53.0, "val_loss": 0.6903330969810486, "val_acc": 52.0}
{"epoch": 1, "training_loss": 0.6924439978599548, "training_acc": 53.0, "val_loss": 0.6903258419036865, "val_acc": 52.0}
{"epoch": 2, "training_loss": 0.6922129702568054, "training_acc": 53.0, "val_loss": 0.6903231358528137, "val_acc": 52.0}
{"epoch": 3, "training_loss": 0.6922345018386841, "training_acc": 53.0, "val_loss": 0.6903115439414979, "val_acc": 52.0}
{"epoch": 4, "training_loss": 0.6922790765762329, "training_acc": 53.0, "val_loss": 0.690305335521698, "val_acc": 52.0}
{"epoch": 5, "training_loss": 0.6924486684799195, "training_acc": 53.0, "val_loss": 0.690301058292389, "val_acc": 52.0}
{"epoch": 6, "training_loss": 0.692547812461853, "training_acc": 53.0, "val_loss": 0.6902950334548951, "val_acc": 52.0}
{"epoch": 7, "training_loss": 0.6922846984863281, "training_acc": 53.0, "val_loss": 0.6902915000915527, "val_acc": 52.0}
{"epoch": 8, "training_loss": 0.6922590923309326, "training_acc": 53.0, "val_loss": 0.6902904009819031, "val_acc": 52.0}
{"epoch": 9, "training_loss": 0.6923280429840087, "training_acc": 53.0, "val_loss": 0.6902904224395752, "val_acc": 52.0}
{"epoch": 10, "training_loss": 0.6922362780570984, "training_acc": 53.0, "val_loss": 0.690296185016632, "val_acc": 52.0}
{"epoch": 11, "training_loss": 0.6925657987594604, "training_acc": 53.0, "val_loss": 0.690293447971344, "val_acc": 52.0}
{"epoch": 12, "training_loss": 0.6918096256256103, "training_acc": 53.0, "val_loss": 0.6902865242958068, "val_acc": 52.0}
{"epoch": 13, "training_loss": 0.6919848799705506, "training_acc": 53.0, "val_loss": 0.6902793979644776, "val_acc": 52.0}
{"epoch": 14, "training_loss": 0.6922938871383667, "training_acc": 53.0, "val_loss": 0.6902700519561767, "val_acc": 52.0}
{"epoch": 15, "training_loss": 0.6925774908065796, "training_acc": 53.0, "val_loss": 0.6902679109573364, "val_acc": 52.0}
{"epoch": 16, "training_loss": 0.6924968099594117, "training_acc": 53.0, "val_loss": 0.6902596783638001, "val_acc": 52.0}
{"epoch": 17, "training_loss": 0.6925063252449035, "training_acc": 53.0, "val_loss": 0.6902523803710937, "val_acc": 52.0}
{"epoch": 18, "training_loss": 0.6921664214134217, "training_acc": 53.0, "val_loss": 0.6902518081665039, "val_acc": 52.0}
{"epoch": 19, "training_loss": 0.6922203111648559, "training_acc": 53.0, "val_loss": 0.6902585315704346, "val_acc": 52.0}
{"epoch": 20, "training_loss": 0.692557110786438, "training_acc": 53.0, "val_loss": 0.6902617239952087, "val_acc": 52.0}
{"epoch": 21, "training_loss": 0.6923342609405517, "training_acc": 53.0, "val_loss": 0.6902638006210328, "val_acc": 52.0}
{"epoch": 22, "training_loss": 0.6920600175857544, "training_acc": 53.0, "val_loss": 0.6902644634246826, "val_acc": 52.0}
{"epoch": 23, "training_loss": 0.6924678325653076, "training_acc": 53.0, "val_loss": 0.6902722668647766, "val_acc": 52.0}
{"epoch": 24, "training_loss": 0.6926380848884582, "training_acc": 53.0, "val_loss": 0.6902821063995361, "val_acc": 52.0}
{"epoch": 25, "training_loss": 0.6927329659461975, "training_acc": 53.0, "val_loss": 0.6902849316596985, "val_acc": 52.0}
{"epoch": 26, "training_loss": 0.6921908640861512, "training_acc": 53.0, "val_loss": 0.6902893733978271, "val_acc": 52.0}
{"epoch": 27, "training_loss": 0.6926175355911255, "training_acc": 53.0, "val_loss": 0.6902859902381897, "val_acc": 52.0}
{"epoch": 28, "training_loss": 0.6922269010543823, "training_acc": 53.0, "val_loss": 0.6902748537063599, "val_acc": 52.0}
{"epoch": 29, "training_loss": 0.6921192741394043, "training_acc": 53.0, "val_loss": 0.6902696824073792, "val_acc": 52.0}
{"epoch": 30, "training_loss": 0.6918805646896362, "training_acc": 53.0, "val_loss": 0.6902691221237183, "val_acc": 52.0}
{"epoch": 31, "training_loss": 0.6918737578392029, "training_acc": 53.0, "val_loss": 0.6902721810340882, "val_acc": 52.0}
{"epoch": 32, "training_loss": 0.6925080728530884, "training_acc": 53.0, "val_loss": 0.6902745127677917, "val_acc": 52.0}
{"epoch": 33, "training_loss": 0.6918700242042541, "training_acc": 53.0, "val_loss": 0.6902708005905152, "val_acc": 52.0}
{"epoch": 34, "training_loss": 0.6924083256721496, "training_acc": 53.0, "val_loss": 0.6902716374397277, "val_acc": 52.0}
{"epoch": 35, "training_loss": 0.6923781752586364, "training_acc": 53.0, "val_loss": 0.6902726054191589, "val_acc": 52.0}
{"epoch": 36, "training_loss": 0.6925763893127441, "training_acc": 53.0, "val_loss": 0.6902705121040345, "val_acc": 52.0}
{"epoch": 37, "training_loss": 0.6925105237960816, "training_acc": 53.0, "val_loss": 0.6902771472930909, "val_acc": 52.0}
