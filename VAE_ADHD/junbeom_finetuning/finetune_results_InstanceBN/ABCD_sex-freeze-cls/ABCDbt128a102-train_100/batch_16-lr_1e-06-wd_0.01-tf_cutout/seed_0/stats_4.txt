"main_modify.py --pretrained_path /scratch/connectome/dyhan316/VAE_ADHD/barlowtwins/pretrain_results/ABCDbt128a102.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option BT_org --learning_rate 1e-6 --batch_size 16 --weight_decay 1e-2 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 0.6926542091369629, "training_acc": 53.0, "val_loss": 0.6956323027610779, "val_acc": 52.0}
{"epoch": 1, "training_loss": 0.6925438666343688, "training_acc": 53.0, "val_loss": 0.6956272459030152, "val_acc": 52.0}
{"epoch": 2, "training_loss": 0.692611141204834, "training_acc": 53.0, "val_loss": 0.6956084179878235, "val_acc": 52.0}
{"epoch": 3, "training_loss": 0.6925984334945678, "training_acc": 53.0, "val_loss": 0.6955848026275635, "val_acc": 52.0}
{"epoch": 4, "training_loss": 0.6929823303222656, "training_acc": 53.0, "val_loss": 0.6955658221244811, "val_acc": 52.0}
{"epoch": 5, "training_loss": 0.6930067586898804, "training_acc": 53.0, "val_loss": 0.6955577492713928, "val_acc": 52.0}
{"epoch": 6, "training_loss": 0.6926024913787842, "training_acc": 53.0, "val_loss": 0.6955409169197082, "val_acc": 52.0}
{"epoch": 7, "training_loss": 0.6925999784469604, "training_acc": 53.0, "val_loss": 0.6955163526535034, "val_acc": 52.0}
{"epoch": 8, "training_loss": 0.6925227499008179, "training_acc": 53.0, "val_loss": 0.6955040860176086, "val_acc": 52.0}
{"epoch": 9, "training_loss": 0.6925137901306152, "training_acc": 53.0, "val_loss": 0.6954831624031067, "val_acc": 52.0}
{"epoch": 10, "training_loss": 0.6932701349258423, "training_acc": 53.0, "val_loss": 0.6954511785507203, "val_acc": 52.0}
{"epoch": 11, "training_loss": 0.6929127740859985, "training_acc": 53.0, "val_loss": 0.6954259181022644, "val_acc": 52.0}
{"epoch": 12, "training_loss": 0.6924622106552124, "training_acc": 53.0, "val_loss": 0.6954109191894531, "val_acc": 52.0}
{"epoch": 13, "training_loss": 0.6922068500518799, "training_acc": 53.0, "val_loss": 0.695394549369812, "val_acc": 52.0}
{"epoch": 14, "training_loss": 0.6930908250808716, "training_acc": 53.0, "val_loss": 0.6953865170478821, "val_acc": 52.0}
{"epoch": 15, "training_loss": 0.6920118570327759, "training_acc": 53.0, "val_loss": 0.6953663372993469, "val_acc": 52.0}
{"epoch": 16, "training_loss": 0.6929259204864502, "training_acc": 53.0, "val_loss": 0.6953503370285035, "val_acc": 52.0}
{"epoch": 17, "training_loss": 0.6927353191375732, "training_acc": 53.0, "val_loss": 0.6953528165817261, "val_acc": 52.0}
{"epoch": 18, "training_loss": 0.6924732184410095, "training_acc": 53.0, "val_loss": 0.6953498077392578, "val_acc": 52.0}
{"epoch": 19, "training_loss": 0.6922434377670288, "training_acc": 53.0, "val_loss": 0.6953478264808655, "val_acc": 52.0}
{"epoch": 20, "training_loss": 0.6926948237419128, "training_acc": 53.0, "val_loss": 0.6953525948524475, "val_acc": 52.0}
{"epoch": 21, "training_loss": 0.6926869702339172, "training_acc": 53.0, "val_loss": 0.6953474855422974, "val_acc": 52.0}
{"epoch": 22, "training_loss": 0.692385311126709, "training_acc": 53.0, "val_loss": 0.695328631401062, "val_acc": 52.0}
{"epoch": 23, "training_loss": 0.6931310749053955, "training_acc": 53.0, "val_loss": 0.6953089332580566, "val_acc": 52.0}
{"epoch": 24, "training_loss": 0.6929692888259887, "training_acc": 53.0, "val_loss": 0.6953028917312623, "val_acc": 52.0}
{"epoch": 25, "training_loss": 0.6925049042701721, "training_acc": 53.0, "val_loss": 0.6952833557128906, "val_acc": 52.0}
{"epoch": 26, "training_loss": 0.6923950839042664, "training_acc": 53.0, "val_loss": 0.6952700805664063, "val_acc": 52.0}
{"epoch": 27, "training_loss": 0.6923546671867371, "training_acc": 53.0, "val_loss": 0.6952606630325318, "val_acc": 52.0}
{"epoch": 28, "training_loss": 0.6926393222808838, "training_acc": 53.0, "val_loss": 0.6952451801300049, "val_acc": 52.0}
{"epoch": 29, "training_loss": 0.6927053546905517, "training_acc": 53.0, "val_loss": 0.695226469039917, "val_acc": 52.0}
{"epoch": 30, "training_loss": 0.6926859664916992, "training_acc": 53.0, "val_loss": 0.6952174878120423, "val_acc": 52.0}
{"epoch": 31, "training_loss": 0.6925246334075927, "training_acc": 53.0, "val_loss": 0.6952179288864135, "val_acc": 52.0}
{"epoch": 32, "training_loss": 0.6927937388420105, "training_acc": 53.0, "val_loss": 0.6952063870429993, "val_acc": 52.0}
{"epoch": 33, "training_loss": 0.692400507926941, "training_acc": 53.0, "val_loss": 0.6952004909515381, "val_acc": 52.0}
{"epoch": 34, "training_loss": 0.6928007888793946, "training_acc": 53.0, "val_loss": 0.6951905012130737, "val_acc": 52.0}
{"epoch": 35, "training_loss": 0.6925078153610229, "training_acc": 53.0, "val_loss": 0.6951624202728272, "val_acc": 52.0}
{"epoch": 36, "training_loss": 0.6924486517906189, "training_acc": 53.0, "val_loss": 0.6951327443122863, "val_acc": 52.0}
{"epoch": 37, "training_loss": 0.6925233364105224, "training_acc": 53.0, "val_loss": 0.6951226449012756, "val_acc": 52.0}
{"epoch": 38, "training_loss": 0.692847661972046, "training_acc": 53.0, "val_loss": 0.6950879621505738, "val_acc": 52.0}
{"epoch": 39, "training_loss": 0.6921333169937134, "training_acc": 53.0, "val_loss": 0.6950634884834289, "val_acc": 52.0}
{"epoch": 40, "training_loss": 0.6924445748329162, "training_acc": 53.0, "val_loss": 0.6950343561172485, "val_acc": 52.0}
{"epoch": 41, "training_loss": 0.6923531007766723, "training_acc": 53.0, "val_loss": 0.6950198554992676, "val_acc": 52.0}
{"epoch": 42, "training_loss": 0.6924734902381897, "training_acc": 53.0, "val_loss": 0.6950083327293396, "val_acc": 52.0}
{"epoch": 43, "training_loss": 0.6926472187042236, "training_acc": 53.0, "val_loss": 0.6950023722648621, "val_acc": 52.0}
{"epoch": 44, "training_loss": 0.6924030494689941, "training_acc": 53.0, "val_loss": 0.6949850583076477, "val_acc": 52.0}
{"epoch": 45, "training_loss": 0.6918595266342163, "training_acc": 53.0, "val_loss": 0.6949719500541687, "val_acc": 52.0}
{"epoch": 46, "training_loss": 0.6926243662834167, "training_acc": 53.0, "val_loss": 0.694944965839386, "val_acc": 52.0}
{"epoch": 47, "training_loss": 0.6922526693344117, "training_acc": 53.0, "val_loss": 0.6949161314964294, "val_acc": 52.0}
{"epoch": 48, "training_loss": 0.6924104452133178, "training_acc": 53.0, "val_loss": 0.6948883938789367, "val_acc": 52.0}
{"epoch": 49, "training_loss": 0.6925141477584839, "training_acc": 53.0, "val_loss": 0.6948735761642456, "val_acc": 52.0}
{"epoch": 50, "training_loss": 0.6925135922431945, "training_acc": 53.0, "val_loss": 0.6948605227470398, "val_acc": 52.0}
{"epoch": 51, "training_loss": 0.6923217105865479, "training_acc": 53.0, "val_loss": 0.694839961528778, "val_acc": 52.0}
{"epoch": 52, "training_loss": 0.6920649075508117, "training_acc": 53.0, "val_loss": 0.6948192930221557, "val_acc": 52.0}
{"epoch": 53, "training_loss": 0.6921989130973816, "training_acc": 53.0, "val_loss": 0.694803581237793, "val_acc": 52.0}
{"epoch": 54, "training_loss": 0.6919772481918335, "training_acc": 53.0, "val_loss": 0.6947958469390869, "val_acc": 52.0}
{"epoch": 55, "training_loss": 0.6921787071228027, "training_acc": 53.0, "val_loss": 0.6947840189933777, "val_acc": 52.0}
{"epoch": 56, "training_loss": 0.6921345710754394, "training_acc": 53.0, "val_loss": 0.6947765755653381, "val_acc": 52.0}
{"epoch": 57, "training_loss": 0.6918971157073974, "training_acc": 53.0, "val_loss": 0.694789731502533, "val_acc": 52.0}
{"epoch": 58, "training_loss": 0.6923259115219116, "training_acc": 53.0, "val_loss": 0.6947972083091736, "val_acc": 52.0}
{"epoch": 59, "training_loss": 0.692270131111145, "training_acc": 53.0, "val_loss": 0.6948061585426331, "val_acc": 52.0}
{"epoch": 60, "training_loss": 0.6921200370788574, "training_acc": 53.0, "val_loss": 0.6947967100143433, "val_acc": 52.0}
{"epoch": 61, "training_loss": 0.6924064540863037, "training_acc": 53.0, "val_loss": 0.6947798418998719, "val_acc": 52.0}
{"epoch": 62, "training_loss": 0.6922250151634216, "training_acc": 53.0, "val_loss": 0.6947653841972351, "val_acc": 52.0}
{"epoch": 63, "training_loss": 0.6922474813461303, "training_acc": 53.0, "val_loss": 0.6947561764717102, "val_acc": 52.0}
{"epoch": 64, "training_loss": 0.6921462821960449, "training_acc": 53.0, "val_loss": 0.6947502565383911, "val_acc": 52.0}
{"epoch": 65, "training_loss": 0.6924818754196167, "training_acc": 53.0, "val_loss": 0.694757628440857, "val_acc": 52.0}
{"epoch": 66, "training_loss": 0.692625880241394, "training_acc": 53.0, "val_loss": 0.6947527027130127, "val_acc": 52.0}
{"epoch": 67, "training_loss": 0.6927111196517944, "training_acc": 53.0, "val_loss": 0.6947580003738403, "val_acc": 52.0}
{"epoch": 68, "training_loss": 0.6920717525482177, "training_acc": 53.0, "val_loss": 0.6947683453559875, "val_acc": 52.0}
{"epoch": 69, "training_loss": 0.6922216653823853, "training_acc": 53.0, "val_loss": 0.694781415462494, "val_acc": 52.0}
{"epoch": 70, "training_loss": 0.6919323420524597, "training_acc": 53.0, "val_loss": 0.6947767066955567, "val_acc": 52.0}
{"epoch": 71, "training_loss": 0.6924309349060058, "training_acc": 53.0, "val_loss": 0.694782269001007, "val_acc": 52.0}
{"epoch": 72, "training_loss": 0.6918038845062255, "training_acc": 53.0, "val_loss": 0.694792456626892, "val_acc": 52.0}
{"epoch": 73, "training_loss": 0.6919771337509155, "training_acc": 53.0, "val_loss": 0.6947917509078979, "val_acc": 52.0}
{"epoch": 74, "training_loss": 0.6919115066528321, "training_acc": 53.0, "val_loss": 0.6947848415374756, "val_acc": 52.0}
{"epoch": 75, "training_loss": 0.6925273370742798, "training_acc": 53.0, "val_loss": 0.6947837400436402, "val_acc": 52.0}
{"epoch": 76, "training_loss": 0.6925191497802734, "training_acc": 53.0, "val_loss": 0.6947780156135559, "val_acc": 52.0}
{"epoch": 77, "training_loss": 0.6924831128120422, "training_acc": 53.0, "val_loss": 0.6947721409797668, "val_acc": 52.0}
{"epoch": 78, "training_loss": 0.6919175839424133, "training_acc": 53.0, "val_loss": 0.6947540640830994, "val_acc": 52.0}
{"epoch": 79, "training_loss": 0.69201575756073, "training_acc": 53.0, "val_loss": 0.6947297358512878, "val_acc": 52.0}
{"epoch": 80, "training_loss": 0.6922835588455201, "training_acc": 53.0, "val_loss": 0.694701657295227, "val_acc": 52.0}
{"epoch": 81, "training_loss": 0.6920456552505493, "training_acc": 53.0, "val_loss": 0.6946964812278748, "val_acc": 52.0}
{"epoch": 82, "training_loss": 0.6927278375625611, "training_acc": 53.0, "val_loss": 0.6946815490722656, "val_acc": 52.0}
{"epoch": 83, "training_loss": 0.6921779251098633, "training_acc": 53.0, "val_loss": 0.6946747517585754, "val_acc": 52.0}
{"epoch": 84, "training_loss": 0.6916988611221313, "training_acc": 53.0, "val_loss": 0.6946644234657288, "val_acc": 52.0}
{"epoch": 85, "training_loss": 0.6921716046333313, "training_acc": 53.0, "val_loss": 0.6946624755859375, "val_acc": 52.0}
{"epoch": 86, "training_loss": 0.6923654413223267, "training_acc": 53.0, "val_loss": 0.6946531224250794, "val_acc": 52.0}
{"epoch": 87, "training_loss": 0.6919063353538513, "training_acc": 53.0, "val_loss": 0.6946326184272766, "val_acc": 52.0}
{"epoch": 88, "training_loss": 0.6920324420928955, "training_acc": 53.0, "val_loss": 0.694612603187561, "val_acc": 52.0}
{"epoch": 89, "training_loss": 0.6923925352096557, "training_acc": 53.0, "val_loss": 0.6945904445648193, "val_acc": 52.0}
{"epoch": 90, "training_loss": 0.6922490286827088, "training_acc": 53.0, "val_loss": 0.6945765376091003, "val_acc": 52.0}
{"epoch": 91, "training_loss": 0.6922413778305053, "training_acc": 53.0, "val_loss": 0.694566490650177, "val_acc": 52.0}
{"epoch": 92, "training_loss": 0.6920525503158569, "training_acc": 53.0, "val_loss": 0.6945550084114075, "val_acc": 52.0}
{"epoch": 93, "training_loss": 0.6920143938064576, "training_acc": 53.0, "val_loss": 0.6945447635650634, "val_acc": 52.0}
{"epoch": 94, "training_loss": 0.6919193172454834, "training_acc": 53.0, "val_loss": 0.6945343232154846, "val_acc": 52.0}
{"epoch": 95, "training_loss": 0.6918802857398987, "training_acc": 53.0, "val_loss": 0.694512529373169, "val_acc": 52.0}
{"epoch": 96, "training_loss": 0.6918367195129395, "training_acc": 53.0, "val_loss": 0.6945054388046265, "val_acc": 52.0}
{"epoch": 97, "training_loss": 0.692316653728485, "training_acc": 53.0, "val_loss": 0.6944933199882507, "val_acc": 52.0}
{"epoch": 98, "training_loss": 0.6917608666419983, "training_acc": 53.0, "val_loss": 0.6944737458229064, "val_acc": 52.0}
{"epoch": 99, "training_loss": 0.6922589564323425, "training_acc": 53.0, "val_loss": 0.6944596409797669, "val_acc": 52.0}
