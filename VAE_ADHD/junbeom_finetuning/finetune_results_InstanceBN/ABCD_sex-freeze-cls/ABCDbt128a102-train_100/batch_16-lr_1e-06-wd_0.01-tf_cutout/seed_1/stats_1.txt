"main_modify.py --pretrained_path /scratch/connectome/dyhan316/VAE_ADHD/barlowtwins/pretrain_results/ABCDbt128a102.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 1 --task ABCD_sex --input_option BT_org --learning_rate 1e-6 --batch_size 16 --weight_decay 1e-2 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 0.6921337866783142, "training_acc": 53.0, "val_loss": 0.6938998126983642, "val_acc": 52.0}
{"epoch": 1, "training_loss": 0.6924404025077819, "training_acc": 53.0, "val_loss": 0.6938961935043335, "val_acc": 52.0}
{"epoch": 2, "training_loss": 0.6923016357421875, "training_acc": 53.0, "val_loss": 0.6938929843902588, "val_acc": 52.0}
{"epoch": 3, "training_loss": 0.6922359800338745, "training_acc": 53.0, "val_loss": 0.693889000415802, "val_acc": 52.0}
{"epoch": 4, "training_loss": 0.6919552993774414, "training_acc": 53.0, "val_loss": 0.693883740901947, "val_acc": 52.0}
{"epoch": 5, "training_loss": 0.6921638250350952, "training_acc": 53.0, "val_loss": 0.6938816452026367, "val_acc": 52.0}
{"epoch": 6, "training_loss": 0.692497866153717, "training_acc": 53.0, "val_loss": 0.693879976272583, "val_acc": 52.0}
{"epoch": 7, "training_loss": 0.6928653311729431, "training_acc": 53.0, "val_loss": 0.6938800764083862, "val_acc": 52.0}
{"epoch": 8, "training_loss": 0.6923012351989746, "training_acc": 53.0, "val_loss": 0.6938753247261047, "val_acc": 52.0}
{"epoch": 9, "training_loss": 0.6920414924621582, "training_acc": 53.0, "val_loss": 0.6938726162910461, "val_acc": 52.0}
{"epoch": 10, "training_loss": 0.6922136235237122, "training_acc": 53.0, "val_loss": 0.6938718271255493, "val_acc": 52.0}
{"epoch": 11, "training_loss": 0.692339870929718, "training_acc": 53.0, "val_loss": 0.6938720393180847, "val_acc": 52.0}
{"epoch": 12, "training_loss": 0.6922802734375, "training_acc": 53.0, "val_loss": 0.6938730192184448, "val_acc": 52.0}
{"epoch": 13, "training_loss": 0.6926573419570923, "training_acc": 53.0, "val_loss": 0.6938696122169494, "val_acc": 52.0}
{"epoch": 14, "training_loss": 0.6923688340187073, "training_acc": 53.0, "val_loss": 0.6938672208786011, "val_acc": 52.0}
{"epoch": 15, "training_loss": 0.6921135544776916, "training_acc": 53.0, "val_loss": 0.6938668608665466, "val_acc": 52.0}
{"epoch": 16, "training_loss": 0.6923796319961548, "training_acc": 53.0, "val_loss": 0.693867335319519, "val_acc": 52.0}
{"epoch": 17, "training_loss": 0.6919570207595825, "training_acc": 53.0, "val_loss": 0.6938654065132142, "val_acc": 52.0}
{"epoch": 18, "training_loss": 0.6922244811058045, "training_acc": 53.0, "val_loss": 0.6938648653030396, "val_acc": 52.0}
{"epoch": 19, "training_loss": 0.6923841190338135, "training_acc": 53.0, "val_loss": 0.6938652729988098, "val_acc": 52.0}
{"epoch": 20, "training_loss": 0.6920768070220947, "training_acc": 53.0, "val_loss": 0.6938635993003845, "val_acc": 52.0}
{"epoch": 21, "training_loss": 0.6924607634544373, "training_acc": 53.0, "val_loss": 0.6938625049591064, "val_acc": 52.0}
{"epoch": 22, "training_loss": 0.692503764629364, "training_acc": 53.0, "val_loss": 0.6938596296310425, "val_acc": 52.0}
{"epoch": 23, "training_loss": 0.6922827649116516, "training_acc": 53.0, "val_loss": 0.6938589096069336, "val_acc": 52.0}
{"epoch": 24, "training_loss": 0.6921682262420654, "training_acc": 53.0, "val_loss": 0.6938573026657104, "val_acc": 52.0}
{"epoch": 25, "training_loss": 0.6922966742515564, "training_acc": 53.0, "val_loss": 0.6938558220863342, "val_acc": 52.0}
{"epoch": 26, "training_loss": 0.6923877787590027, "training_acc": 53.0, "val_loss": 0.6938543581962585, "val_acc": 52.0}
{"epoch": 27, "training_loss": 0.6917391347885132, "training_acc": 53.0, "val_loss": 0.6938515543937683, "val_acc": 52.0}
{"epoch": 28, "training_loss": 0.6921298027038574, "training_acc": 53.0, "val_loss": 0.6938516688346863, "val_acc": 52.0}
{"epoch": 29, "training_loss": 0.6925331807136536, "training_acc": 53.0, "val_loss": 0.6938499522209167, "val_acc": 52.0}
{"epoch": 30, "training_loss": 0.6926353049278259, "training_acc": 53.0, "val_loss": 0.6938499283790588, "val_acc": 52.0}
{"epoch": 31, "training_loss": 0.692391881942749, "training_acc": 53.0, "val_loss": 0.6938480758666992, "val_acc": 52.0}
{"epoch": 32, "training_loss": 0.692289092540741, "training_acc": 53.0, "val_loss": 0.6938455462455749, "val_acc": 52.0}
{"epoch": 33, "training_loss": 0.6923856306076049, "training_acc": 53.0, "val_loss": 0.6938447260856628, "val_acc": 52.0}
{"epoch": 34, "training_loss": 0.6922650504112243, "training_acc": 53.0, "val_loss": 0.6938438391685486, "val_acc": 52.0}
{"epoch": 35, "training_loss": 0.6925127840042115, "training_acc": 53.0, "val_loss": 0.6938431763648987, "val_acc": 52.0}
{"epoch": 36, "training_loss": 0.6922800254821777, "training_acc": 53.0, "val_loss": 0.6938434338569641, "val_acc": 52.0}
{"epoch": 37, "training_loss": 0.6924869656562805, "training_acc": 53.0, "val_loss": 0.6938417410850525, "val_acc": 52.0}
{"epoch": 38, "training_loss": 0.6924365329742431, "training_acc": 53.0, "val_loss": 0.6938396906852722, "val_acc": 52.0}
{"epoch": 39, "training_loss": 0.6922432518005371, "training_acc": 53.0, "val_loss": 0.6938384294509887, "val_acc": 52.0}
{"epoch": 40, "training_loss": 0.6924930953979492, "training_acc": 53.0, "val_loss": 0.6938384747505189, "val_acc": 52.0}
{"epoch": 41, "training_loss": 0.6920805263519287, "training_acc": 53.0, "val_loss": 0.6938379335403443, "val_acc": 52.0}
{"epoch": 42, "training_loss": 0.6921433591842652, "training_acc": 53.0, "val_loss": 0.6938373398780823, "val_acc": 52.0}
{"epoch": 43, "training_loss": 0.6924685096740723, "training_acc": 53.0, "val_loss": 0.6938352298736572, "val_acc": 52.0}
{"epoch": 44, "training_loss": 0.6922766876220703, "training_acc": 53.0, "val_loss": 0.6938335824012757, "val_acc": 52.0}
{"epoch": 45, "training_loss": 0.692165002822876, "training_acc": 53.0, "val_loss": 0.6938312077522277, "val_acc": 52.0}
{"epoch": 46, "training_loss": 0.6923528432846069, "training_acc": 53.0, "val_loss": 0.6938300347328186, "val_acc": 52.0}
{"epoch": 47, "training_loss": 0.6925504732131958, "training_acc": 53.0, "val_loss": 0.6938285541534424, "val_acc": 52.0}
{"epoch": 48, "training_loss": 0.6921774005889892, "training_acc": 53.0, "val_loss": 0.6938290333747864, "val_acc": 52.0}
{"epoch": 49, "training_loss": 0.6924902200698853, "training_acc": 53.0, "val_loss": 0.6938294982910156, "val_acc": 52.0}
{"epoch": 50, "training_loss": 0.6924917316436767, "training_acc": 53.0, "val_loss": 0.693829038143158, "val_acc": 52.0}
{"epoch": 51, "training_loss": 0.6922944355010986, "training_acc": 53.0, "val_loss": 0.6938286185264587, "val_acc": 52.0}
{"epoch": 52, "training_loss": 0.6921737003326416, "training_acc": 53.0, "val_loss": 0.6938287281990051, "val_acc": 52.0}
{"epoch": 53, "training_loss": 0.6919577360153198, "training_acc": 53.0, "val_loss": 0.6938290095329285, "val_acc": 52.0}
{"epoch": 54, "training_loss": 0.692158465385437, "training_acc": 53.0, "val_loss": 0.69382728099823, "val_acc": 52.0}
{"epoch": 55, "training_loss": 0.6922034215927124, "training_acc": 53.0, "val_loss": 0.6938263368606568, "val_acc": 52.0}
{"epoch": 56, "training_loss": 0.6924421501159668, "training_acc": 53.0, "val_loss": 0.6938248991966247, "val_acc": 52.0}
{"epoch": 57, "training_loss": 0.6921893262863159, "training_acc": 53.0, "val_loss": 0.6938253402709961, "val_acc": 52.0}
{"epoch": 58, "training_loss": 0.6922225880622864, "training_acc": 53.0, "val_loss": 0.6938251829147339, "val_acc": 52.0}
{"epoch": 59, "training_loss": 0.6918700313568116, "training_acc": 53.0, "val_loss": 0.6938251614570617, "val_acc": 52.0}
{"epoch": 60, "training_loss": 0.6921748542785644, "training_acc": 53.0, "val_loss": 0.693824851512909, "val_acc": 52.0}
{"epoch": 61, "training_loss": 0.6921400332450867, "training_acc": 53.0, "val_loss": 0.6938235783576965, "val_acc": 52.0}
{"epoch": 62, "training_loss": 0.6920507335662842, "training_acc": 53.0, "val_loss": 0.6938235783576965, "val_acc": 52.0}
{"epoch": 63, "training_loss": 0.6923062372207641, "training_acc": 53.0, "val_loss": 0.6938227009773255, "val_acc": 52.0}
{"epoch": 64, "training_loss": 0.6920528936386109, "training_acc": 53.0, "val_loss": 0.6938213014602661, "val_acc": 52.0}
{"epoch": 65, "training_loss": 0.6926364040374756, "training_acc": 53.0, "val_loss": 0.6938208317756653, "val_acc": 52.0}
{"epoch": 66, "training_loss": 0.6921519827842713, "training_acc": 53.0, "val_loss": 0.6938198900222778, "val_acc": 52.0}
{"epoch": 67, "training_loss": 0.6924246239662171, "training_acc": 53.0, "val_loss": 0.6938195347785949, "val_acc": 52.0}
{"epoch": 68, "training_loss": 0.6918977785110474, "training_acc": 53.0, "val_loss": 0.6938201236724854, "val_acc": 52.0}
{"epoch": 69, "training_loss": 0.6920395922660828, "training_acc": 53.0, "val_loss": 0.6938192701339722, "val_acc": 52.0}
{"epoch": 70, "training_loss": 0.6922707223892212, "training_acc": 53.0, "val_loss": 0.6938190531730651, "val_acc": 52.0}
{"epoch": 71, "training_loss": 0.6924025011062622, "training_acc": 53.0, "val_loss": 0.6938193321228028, "val_acc": 52.0}
{"epoch": 72, "training_loss": 0.6921889066696167, "training_acc": 53.0, "val_loss": 0.6938192105293274, "val_acc": 52.0}
{"epoch": 73, "training_loss": 0.692459979057312, "training_acc": 53.0, "val_loss": 0.6938189029693603, "val_acc": 52.0}
{"epoch": 74, "training_loss": 0.6924204182624817, "training_acc": 53.0, "val_loss": 0.6938189244270325, "val_acc": 52.0}
{"epoch": 75, "training_loss": 0.6925565648078919, "training_acc": 53.0, "val_loss": 0.6938190579414367, "val_acc": 52.0}
{"epoch": 76, "training_loss": 0.6920584130287171, "training_acc": 53.0, "val_loss": 0.6938190221786499, "val_acc": 52.0}
{"epoch": 77, "training_loss": 0.69239821434021, "training_acc": 53.0, "val_loss": 0.6938188290596008, "val_acc": 52.0}
{"epoch": 78, "training_loss": 0.6925432777404785, "training_acc": 53.0, "val_loss": 0.6938195133209228, "val_acc": 52.0}
{"epoch": 79, "training_loss": 0.6918527364730835, "training_acc": 53.0, "val_loss": 0.6938194680213928, "val_acc": 52.0}
{"epoch": 80, "training_loss": 0.6918643641471863, "training_acc": 53.0, "val_loss": 0.6938196086883545, "val_acc": 52.0}
{"epoch": 81, "training_loss": 0.6921409153938294, "training_acc": 53.0, "val_loss": 0.6938186311721801, "val_acc": 52.0}
{"epoch": 82, "training_loss": 0.6923122835159302, "training_acc": 53.0, "val_loss": 0.6938171672821045, "val_acc": 52.0}
{"epoch": 83, "training_loss": 0.6922708821296691, "training_acc": 53.0, "val_loss": 0.6938159108161926, "val_acc": 52.0}
{"epoch": 84, "training_loss": 0.6921282577514648, "training_acc": 53.0, "val_loss": 0.6938150143623352, "val_acc": 52.0}
{"epoch": 85, "training_loss": 0.6923105573654175, "training_acc": 53.0, "val_loss": 0.6938144612312317, "val_acc": 52.0}
{"epoch": 86, "training_loss": 0.6920693874359131, "training_acc": 53.0, "val_loss": 0.693814287185669, "val_acc": 52.0}
{"epoch": 87, "training_loss": 0.6922071576118469, "training_acc": 53.0, "val_loss": 0.6938140892982483, "val_acc": 52.0}
{"epoch": 88, "training_loss": 0.6921473741531372, "training_acc": 53.0, "val_loss": 0.6938140535354614, "val_acc": 52.0}
{"epoch": 89, "training_loss": 0.6925915884971618, "training_acc": 53.0, "val_loss": 0.6938139176368714, "val_acc": 52.0}
{"epoch": 90, "training_loss": 0.6919163417816162, "training_acc": 53.0, "val_loss": 0.6938140845298767, "val_acc": 52.0}
{"epoch": 91, "training_loss": 0.6920413970947266, "training_acc": 53.0, "val_loss": 0.6938137698173523, "val_acc": 52.0}
{"epoch": 92, "training_loss": 0.6921878981590271, "training_acc": 53.0, "val_loss": 0.6938134455680847, "val_acc": 52.0}
{"epoch": 93, "training_loss": 0.6921770358085633, "training_acc": 53.0, "val_loss": 0.6938129472732544, "val_acc": 52.0}
{"epoch": 94, "training_loss": 0.6923311257362366, "training_acc": 53.0, "val_loss": 0.6938124370574951, "val_acc": 52.0}
{"epoch": 95, "training_loss": 0.6924141788482666, "training_acc": 53.0, "val_loss": 0.6938122773170471, "val_acc": 52.0}
{"epoch": 96, "training_loss": 0.6921114563941956, "training_acc": 53.0, "val_loss": 0.6938118720054627, "val_acc": 52.0}
{"epoch": 97, "training_loss": 0.6920286178588867, "training_acc": 53.0, "val_loss": 0.6938115811347961, "val_acc": 52.0}
{"epoch": 98, "training_loss": 0.6925463056564332, "training_acc": 53.0, "val_loss": 0.6938115334510804, "val_acc": 52.0}
{"epoch": 99, "training_loss": 0.6923692941665649, "training_acc": 53.0, "val_loss": 0.6938114738464356, "val_acc": 52.0}
