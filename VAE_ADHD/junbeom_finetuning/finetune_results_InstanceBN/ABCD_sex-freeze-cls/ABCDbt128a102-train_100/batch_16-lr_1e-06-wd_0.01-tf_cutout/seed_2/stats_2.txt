"main_modify.py --pretrained_path /scratch/connectome/dyhan316/VAE_ADHD/barlowtwins/pretrain_results/ABCDbt128a102.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 2 --task ABCD_sex --input_option BT_org --learning_rate 1e-6 --batch_size 16 --weight_decay 1e-2 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 0.6929227375984192, "training_acc": 53.0, "val_loss": 0.6963754177093506, "val_acc": 52.0}
{"epoch": 1, "training_loss": 0.6925842833518981, "training_acc": 53.0, "val_loss": 0.6963548016548157, "val_acc": 52.0}
{"epoch": 2, "training_loss": 0.6934514331817627, "training_acc": 53.0, "val_loss": 0.6963442373275757, "val_acc": 52.0}
{"epoch": 3, "training_loss": 0.6930657625198364, "training_acc": 53.0, "val_loss": 0.6963234400749206, "val_acc": 52.0}
{"epoch": 4, "training_loss": 0.6927321004867554, "training_acc": 53.0, "val_loss": 0.6963189029693604, "val_acc": 52.0}
{"epoch": 5, "training_loss": 0.6927410554885864, "training_acc": 53.0, "val_loss": 0.6963158631324768, "val_acc": 52.0}
{"epoch": 6, "training_loss": 0.6926544570922851, "training_acc": 53.0, "val_loss": 0.6963265490531921, "val_acc": 52.0}
{"epoch": 7, "training_loss": 0.6922902917861938, "training_acc": 53.0, "val_loss": 0.6963358640670776, "val_acc": 52.0}
{"epoch": 8, "training_loss": 0.6925375461578369, "training_acc": 53.0, "val_loss": 0.6963276720046997, "val_acc": 52.0}
{"epoch": 9, "training_loss": 0.6926167058944702, "training_acc": 53.0, "val_loss": 0.6963179111480713, "val_acc": 52.0}
{"epoch": 10, "training_loss": 0.692752661705017, "training_acc": 53.0, "val_loss": 0.6962988114356995, "val_acc": 52.0}
{"epoch": 11, "training_loss": 0.6928355026245118, "training_acc": 53.0, "val_loss": 0.6962799191474914, "val_acc": 52.0}
{"epoch": 12, "training_loss": 0.6925172448158264, "training_acc": 53.0, "val_loss": 0.6962546133995056, "val_acc": 52.0}
{"epoch": 13, "training_loss": 0.6926382637023926, "training_acc": 53.0, "val_loss": 0.6962464737892151, "val_acc": 52.0}
{"epoch": 14, "training_loss": 0.6929334592819214, "training_acc": 53.0, "val_loss": 0.6962282657623291, "val_acc": 52.0}
{"epoch": 15, "training_loss": 0.6925716543197632, "training_acc": 53.0, "val_loss": 0.6962262773513794, "val_acc": 52.0}
{"epoch": 16, "training_loss": 0.692733154296875, "training_acc": 53.0, "val_loss": 0.6962155222892761, "val_acc": 52.0}
{"epoch": 17, "training_loss": 0.6927267241477967, "training_acc": 53.0, "val_loss": 0.6962141084671021, "val_acc": 52.0}
{"epoch": 18, "training_loss": 0.6929957365989685, "training_acc": 53.0, "val_loss": 0.696210343837738, "val_acc": 52.0}
{"epoch": 19, "training_loss": 0.6927639770507813, "training_acc": 53.0, "val_loss": 0.6962060165405274, "val_acc": 52.0}
{"epoch": 20, "training_loss": 0.692956132888794, "training_acc": 53.0, "val_loss": 0.696215181350708, "val_acc": 52.0}
{"epoch": 21, "training_loss": 0.6926657819747924, "training_acc": 53.0, "val_loss": 0.6962045383453369, "val_acc": 52.0}
{"epoch": 22, "training_loss": 0.6929759907722474, "training_acc": 53.0, "val_loss": 0.6961962819099426, "val_acc": 52.0}
{"epoch": 23, "training_loss": 0.6927509260177612, "training_acc": 53.0, "val_loss": 0.6961788535118103, "val_acc": 52.0}
{"epoch": 24, "training_loss": 0.6926843023300171, "training_acc": 53.0, "val_loss": 0.6961645984649658, "val_acc": 52.0}
{"epoch": 25, "training_loss": 0.6930796694755554, "training_acc": 53.0, "val_loss": 0.696150586605072, "val_acc": 52.0}
{"epoch": 26, "training_loss": 0.6921975708007813, "training_acc": 53.0, "val_loss": 0.6961469745635986, "val_acc": 52.0}
{"epoch": 27, "training_loss": 0.6926546764373779, "training_acc": 53.0, "val_loss": 0.6961468243598938, "val_acc": 52.0}
{"epoch": 28, "training_loss": 0.6921672058105469, "training_acc": 53.0, "val_loss": 0.6961470484733582, "val_acc": 52.0}
{"epoch": 29, "training_loss": 0.6930495405197143, "training_acc": 53.0, "val_loss": 0.696128785610199, "val_acc": 52.0}
{"epoch": 30, "training_loss": 0.6921542692184448, "training_acc": 53.0, "val_loss": 0.6961063432693482, "val_acc": 52.0}
{"epoch": 31, "training_loss": 0.6923689818382264, "training_acc": 53.0, "val_loss": 0.6960956025123596, "val_acc": 52.0}
{"epoch": 32, "training_loss": 0.6923849439620972, "training_acc": 53.0, "val_loss": 0.6960958456993103, "val_acc": 52.0}
{"epoch": 33, "training_loss": 0.692859230041504, "training_acc": 53.0, "val_loss": 0.6960944867134095, "val_acc": 52.0}
{"epoch": 34, "training_loss": 0.6928266501426696, "training_acc": 53.0, "val_loss": 0.696091377735138, "val_acc": 52.0}
{"epoch": 35, "training_loss": 0.6928020572662353, "training_acc": 53.0, "val_loss": 0.6960749340057373, "val_acc": 52.0}
{"epoch": 36, "training_loss": 0.6927833652496338, "training_acc": 53.0, "val_loss": 0.6960650563240052, "val_acc": 52.0}
{"epoch": 37, "training_loss": 0.6923197555541992, "training_acc": 53.0, "val_loss": 0.6960501170158386, "val_acc": 52.0}
{"epoch": 38, "training_loss": 0.6925423049926758, "training_acc": 53.0, "val_loss": 0.6960306286811828, "val_acc": 52.0}
{"epoch": 39, "training_loss": 0.6928089833259583, "training_acc": 53.0, "val_loss": 0.6960040378570557, "val_acc": 52.0}
{"epoch": 40, "training_loss": 0.6925864028930664, "training_acc": 53.0, "val_loss": 0.6959856629371644, "val_acc": 52.0}
{"epoch": 41, "training_loss": 0.6923419618606568, "training_acc": 53.0, "val_loss": 0.6959794163703918, "val_acc": 52.0}
{"epoch": 42, "training_loss": 0.693022518157959, "training_acc": 53.0, "val_loss": 0.6959786295890809, "val_acc": 52.0}
{"epoch": 43, "training_loss": 0.69252037525177, "training_acc": 53.0, "val_loss": 0.6959670472145081, "val_acc": 52.0}
{"epoch": 44, "training_loss": 0.6926741218566894, "training_acc": 53.0, "val_loss": 0.6959578251838684, "val_acc": 52.0}
{"epoch": 45, "training_loss": 0.6922178173065185, "training_acc": 53.0, "val_loss": 0.6959570693969727, "val_acc": 52.0}
{"epoch": 46, "training_loss": 0.6925191736221313, "training_acc": 53.0, "val_loss": 0.6959592461585998, "val_acc": 52.0}
{"epoch": 47, "training_loss": 0.6922502183914184, "training_acc": 53.0, "val_loss": 0.6959461402893067, "val_acc": 52.0}
{"epoch": 48, "training_loss": 0.6927457475662231, "training_acc": 53.0, "val_loss": 0.6959217429161072, "val_acc": 52.0}
{"epoch": 49, "training_loss": 0.6925600075721741, "training_acc": 53.0, "val_loss": 0.6959038519859314, "val_acc": 52.0}
{"epoch": 50, "training_loss": 0.6928416681289673, "training_acc": 53.0, "val_loss": 0.6958902716636658, "val_acc": 52.0}
{"epoch": 51, "training_loss": 0.6928039073944092, "training_acc": 53.0, "val_loss": 0.6958672833442688, "val_acc": 52.0}
{"epoch": 52, "training_loss": 0.6923775053024293, "training_acc": 53.0, "val_loss": 0.6958523511886596, "val_acc": 52.0}
{"epoch": 53, "training_loss": 0.692411880493164, "training_acc": 53.0, "val_loss": 0.6958450818061829, "val_acc": 52.0}
{"epoch": 54, "training_loss": 0.6923787879943848, "training_acc": 53.0, "val_loss": 0.6958322072029114, "val_acc": 52.0}
{"epoch": 55, "training_loss": 0.6925280213356018, "training_acc": 53.0, "val_loss": 0.69580735206604, "val_acc": 52.0}
{"epoch": 56, "training_loss": 0.6925544261932373, "training_acc": 53.0, "val_loss": 0.695789704322815, "val_acc": 52.0}
{"epoch": 57, "training_loss": 0.6919502735137939, "training_acc": 53.0, "val_loss": 0.6957826328277588, "val_acc": 52.0}
{"epoch": 58, "training_loss": 0.6925729298591614, "training_acc": 53.0, "val_loss": 0.6957847619056702, "val_acc": 52.0}
{"epoch": 59, "training_loss": 0.6923730945587159, "training_acc": 53.0, "val_loss": 0.695783998966217, "val_acc": 52.0}
{"epoch": 60, "training_loss": 0.6922381162643433, "training_acc": 53.0, "val_loss": 0.6957712411880493, "val_acc": 52.0}
{"epoch": 61, "training_loss": 0.6925875043869019, "training_acc": 53.0, "val_loss": 0.6957655763626098, "val_acc": 52.0}
{"epoch": 62, "training_loss": 0.692140805721283, "training_acc": 53.0, "val_loss": 0.695736358165741, "val_acc": 52.0}
{"epoch": 63, "training_loss": 0.6920286679267883, "training_acc": 53.0, "val_loss": 0.6957155013084412, "val_acc": 52.0}
{"epoch": 64, "training_loss": 0.6924489259719848, "training_acc": 53.0, "val_loss": 0.695695378780365, "val_acc": 52.0}
{"epoch": 65, "training_loss": 0.6924346899986267, "training_acc": 53.0, "val_loss": 0.6956841683387757, "val_acc": 52.0}
{"epoch": 66, "training_loss": 0.6921990871429443, "training_acc": 53.0, "val_loss": 0.6956787943840027, "val_acc": 52.0}
{"epoch": 67, "training_loss": 0.6914088320732117, "training_acc": 53.0, "val_loss": 0.6956766724586487, "val_acc": 52.0}
{"epoch": 68, "training_loss": 0.6922192573547363, "training_acc": 53.0, "val_loss": 0.6956739354133606, "val_acc": 52.0}
{"epoch": 69, "training_loss": 0.692333517074585, "training_acc": 53.0, "val_loss": 0.6956720924377442, "val_acc": 52.0}
{"epoch": 70, "training_loss": 0.6920349287986756, "training_acc": 53.0, "val_loss": 0.6956654071807862, "val_acc": 52.0}
{"epoch": 71, "training_loss": 0.6926567649841309, "training_acc": 53.0, "val_loss": 0.6956611680984497, "val_acc": 52.0}
{"epoch": 72, "training_loss": 0.6919101667404175, "training_acc": 53.0, "val_loss": 0.695645477771759, "val_acc": 52.0}
{"epoch": 73, "training_loss": 0.692300763130188, "training_acc": 53.0, "val_loss": 0.6956429243087768, "val_acc": 52.0}
{"epoch": 74, "training_loss": 0.6926309084892273, "training_acc": 53.0, "val_loss": 0.6956361746788025, "val_acc": 52.0}
{"epoch": 75, "training_loss": 0.69223717212677, "training_acc": 53.0, "val_loss": 0.6956216478347779, "val_acc": 52.0}
{"epoch": 76, "training_loss": 0.6924246954917908, "training_acc": 53.0, "val_loss": 0.6956209874153138, "val_acc": 52.0}
{"epoch": 77, "training_loss": 0.6920963287353515, "training_acc": 53.0, "val_loss": 0.6955981516838073, "val_acc": 52.0}
{"epoch": 78, "training_loss": 0.6922630882263183, "training_acc": 53.0, "val_loss": 0.6955978703498841, "val_acc": 52.0}
{"epoch": 79, "training_loss": 0.692131404876709, "training_acc": 53.0, "val_loss": 0.6956060647964477, "val_acc": 52.0}
{"epoch": 80, "training_loss": 0.6922356653213501, "training_acc": 53.0, "val_loss": 0.6955919027328491, "val_acc": 52.0}
{"epoch": 81, "training_loss": 0.691962537765503, "training_acc": 53.0, "val_loss": 0.695579218864441, "val_acc": 52.0}
{"epoch": 82, "training_loss": 0.6926668643951416, "training_acc": 53.0, "val_loss": 0.69555992603302, "val_acc": 52.0}
{"epoch": 83, "training_loss": 0.6924997091293335, "training_acc": 53.0, "val_loss": 0.6955452132225036, "val_acc": 52.0}
{"epoch": 84, "training_loss": 0.6925108671188355, "training_acc": 53.0, "val_loss": 0.6955251932144165, "val_acc": 52.0}
{"epoch": 85, "training_loss": 0.6923737382888794, "training_acc": 53.0, "val_loss": 0.6955231189727783, "val_acc": 52.0}
{"epoch": 86, "training_loss": 0.6922100758552552, "training_acc": 53.0, "val_loss": 0.6955163335800171, "val_acc": 52.0}
{"epoch": 87, "training_loss": 0.6922693920135498, "training_acc": 53.0, "val_loss": 0.6955077362060547, "val_acc": 52.0}
{"epoch": 88, "training_loss": 0.6918831825256347, "training_acc": 53.0, "val_loss": 0.6955000686645508, "val_acc": 52.0}
{"epoch": 89, "training_loss": 0.691942663192749, "training_acc": 53.0, "val_loss": 0.6954983186721801, "val_acc": 52.0}
{"epoch": 90, "training_loss": 0.6919906663894654, "training_acc": 53.0, "val_loss": 0.6954839015007019, "val_acc": 52.0}
{"epoch": 91, "training_loss": 0.6919924783706665, "training_acc": 53.0, "val_loss": 0.6954874110221863, "val_acc": 52.0}
{"epoch": 92, "training_loss": 0.6926161170005798, "training_acc": 53.0, "val_loss": 0.6954850339889527, "val_acc": 52.0}
{"epoch": 93, "training_loss": 0.6924958801269532, "training_acc": 53.0, "val_loss": 0.6954711675643921, "val_acc": 52.0}
{"epoch": 94, "training_loss": 0.6923168706893921, "training_acc": 53.0, "val_loss": 0.6954615497589112, "val_acc": 52.0}
{"epoch": 95, "training_loss": 0.6927580595016479, "training_acc": 53.0, "val_loss": 0.6954577279090881, "val_acc": 52.0}
{"epoch": 96, "training_loss": 0.6917129850387573, "training_acc": 53.0, "val_loss": 0.6954342770576477, "val_acc": 52.0}
{"epoch": 97, "training_loss": 0.6923983550071716, "training_acc": 53.0, "val_loss": 0.6954238772392273, "val_acc": 52.0}
{"epoch": 98, "training_loss": 0.6923095464706421, "training_acc": 53.0, "val_loss": 0.6954035520553589, "val_acc": 52.0}
{"epoch": 99, "training_loss": 0.6922857713699341, "training_acc": 53.0, "val_loss": 0.6953855538368225, "val_acc": 52.0}
