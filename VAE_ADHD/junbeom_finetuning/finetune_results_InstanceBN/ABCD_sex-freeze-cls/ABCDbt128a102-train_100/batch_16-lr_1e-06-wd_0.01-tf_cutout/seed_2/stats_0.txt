"main_modify.py --pretrained_path /scratch/connectome/dyhan316/VAE_ADHD/barlowtwins/pretrain_results/ABCDbt128a102.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 2 --task ABCD_sex --input_option BT_org --learning_rate 1e-6 --batch_size 16 --weight_decay 1e-2 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 0.6921871757507324, "training_acc": 53.0, "val_loss": 0.691352014541626, "val_acc": 52.0}
{"epoch": 1, "training_loss": 0.6918666267395019, "training_acc": 53.0, "val_loss": 0.6913437604904175, "val_acc": 52.0}
{"epoch": 2, "training_loss": 0.6918949842453003, "training_acc": 53.0, "val_loss": 0.6913249135017395, "val_acc": 52.0}
{"epoch": 3, "training_loss": 0.6916453075408936, "training_acc": 53.0, "val_loss": 0.6913166356086731, "val_acc": 52.0}
{"epoch": 4, "training_loss": 0.6915440964698791, "training_acc": 53.0, "val_loss": 0.6913157653808594, "val_acc": 52.0}
{"epoch": 5, "training_loss": 0.69134681224823, "training_acc": 53.0, "val_loss": 0.6913103389739991, "val_acc": 52.0}
{"epoch": 6, "training_loss": 0.6918952822685241, "training_acc": 53.0, "val_loss": 0.6912875413894654, "val_acc": 52.0}
{"epoch": 7, "training_loss": 0.6914012908935547, "training_acc": 53.0, "val_loss": 0.6912849450111389, "val_acc": 52.0}
{"epoch": 8, "training_loss": 0.6924638772010803, "training_acc": 53.0, "val_loss": 0.6912680101394654, "val_acc": 52.0}
{"epoch": 9, "training_loss": 0.691474552154541, "training_acc": 53.0, "val_loss": 0.6912518429756165, "val_acc": 52.0}
{"epoch": 10, "training_loss": 0.6918597078323364, "training_acc": 53.0, "val_loss": 0.6912424612045288, "val_acc": 52.0}
{"epoch": 11, "training_loss": 0.6918064093589783, "training_acc": 53.0, "val_loss": 0.6912279915809632, "val_acc": 52.0}
{"epoch": 12, "training_loss": 0.6915979909896851, "training_acc": 53.0, "val_loss": 0.6912199449539185, "val_acc": 52.0}
{"epoch": 13, "training_loss": 0.6917229318618774, "training_acc": 53.0, "val_loss": 0.691212043762207, "val_acc": 52.0}
{"epoch": 14, "training_loss": 0.6916195225715637, "training_acc": 53.0, "val_loss": 0.6912028980255127, "val_acc": 52.0}
{"epoch": 15, "training_loss": 0.691696560382843, "training_acc": 53.0, "val_loss": 0.6911980891227723, "val_acc": 52.0}
{"epoch": 16, "training_loss": 0.6916182231903076, "training_acc": 53.0, "val_loss": 0.6911891222000122, "val_acc": 52.0}
{"epoch": 17, "training_loss": 0.6916620326042175, "training_acc": 53.0, "val_loss": 0.6911775135993957, "val_acc": 52.0}
{"epoch": 18, "training_loss": 0.6913574361801147, "training_acc": 53.0, "val_loss": 0.6911814212799072, "val_acc": 52.0}
{"epoch": 19, "training_loss": 0.6916003847122192, "training_acc": 53.0, "val_loss": 0.6911751627922058, "val_acc": 52.0}
{"epoch": 20, "training_loss": 0.6917778134346009, "training_acc": 53.0, "val_loss": 0.6911659097671509, "val_acc": 52.0}
{"epoch": 21, "training_loss": 0.6915025591850281, "training_acc": 53.0, "val_loss": 0.691150586605072, "val_acc": 52.0}
{"epoch": 22, "training_loss": 0.6919509673118591, "training_acc": 53.0, "val_loss": 0.6911211729049682, "val_acc": 52.0}
{"epoch": 23, "training_loss": 0.6915888071060181, "training_acc": 53.0, "val_loss": 0.6911078214645385, "val_acc": 52.0}
{"epoch": 24, "training_loss": 0.6920409774780274, "training_acc": 53.0, "val_loss": 0.6910943245887756, "val_acc": 52.0}
{"epoch": 25, "training_loss": 0.6915960979461669, "training_acc": 53.0, "val_loss": 0.6910779500007629, "val_acc": 52.0}
{"epoch": 26, "training_loss": 0.6922962188720703, "training_acc": 53.0, "val_loss": 0.6910783100128174, "val_acc": 52.0}
{"epoch": 27, "training_loss": 0.691608190536499, "training_acc": 53.0, "val_loss": 0.6910795855522156, "val_acc": 52.0}
{"epoch": 28, "training_loss": 0.691478123664856, "training_acc": 53.0, "val_loss": 0.6910888981819153, "val_acc": 52.0}
{"epoch": 29, "training_loss": 0.691463053226471, "training_acc": 53.0, "val_loss": 0.6910761308670044, "val_acc": 52.0}
{"epoch": 30, "training_loss": 0.6914380693435669, "training_acc": 53.0, "val_loss": 0.6910714650154114, "val_acc": 52.0}
{"epoch": 31, "training_loss": 0.6913650846481323, "training_acc": 53.0, "val_loss": 0.6910590577125549, "val_acc": 52.0}
{"epoch": 32, "training_loss": 0.6915854787826539, "training_acc": 53.0, "val_loss": 0.6910497021675109, "val_acc": 52.0}
{"epoch": 33, "training_loss": 0.6916403865814209, "training_acc": 53.0, "val_loss": 0.6910438227653504, "val_acc": 52.0}
{"epoch": 34, "training_loss": 0.6915112447738647, "training_acc": 53.0, "val_loss": 0.6910511922836303, "val_acc": 52.0}
{"epoch": 35, "training_loss": 0.6917681312561035, "training_acc": 53.0, "val_loss": 0.6910596203804016, "val_acc": 52.0}
{"epoch": 36, "training_loss": 0.6911832094192505, "training_acc": 53.0, "val_loss": 0.6910555601119995, "val_acc": 52.0}
{"epoch": 37, "training_loss": 0.6915184235572815, "training_acc": 53.0, "val_loss": 0.6910410618782044, "val_acc": 52.0}
{"epoch": 38, "training_loss": 0.6913727045059204, "training_acc": 53.0, "val_loss": 0.6910156559944153, "val_acc": 52.0}
{"epoch": 39, "training_loss": 0.6918687152862549, "training_acc": 53.0, "val_loss": 0.6909963035583496, "val_acc": 52.0}
{"epoch": 40, "training_loss": 0.6919656658172607, "training_acc": 53.0, "val_loss": 0.6909779286384583, "val_acc": 52.0}
{"epoch": 41, "training_loss": 0.69124755859375, "training_acc": 53.0, "val_loss": 0.69097327709198, "val_acc": 52.0}
{"epoch": 42, "training_loss": 0.6915312886238099, "training_acc": 53.0, "val_loss": 0.6909623956680297, "val_acc": 52.0}
{"epoch": 43, "training_loss": 0.6918534994125366, "training_acc": 53.0, "val_loss": 0.6909531712532043, "val_acc": 52.0}
{"epoch": 44, "training_loss": 0.6914064788818359, "training_acc": 53.0, "val_loss": 0.6909396123886108, "val_acc": 52.0}
{"epoch": 45, "training_loss": 0.6914000749588013, "training_acc": 53.0, "val_loss": 0.6909180498123169, "val_acc": 52.0}
{"epoch": 46, "training_loss": 0.6912061262130738, "training_acc": 53.0, "val_loss": 0.6909093952178955, "val_acc": 52.0}
{"epoch": 47, "training_loss": 0.6916838407516479, "training_acc": 53.0, "val_loss": 0.6908996248245239, "val_acc": 52.0}
{"epoch": 48, "training_loss": 0.6916047501564025, "training_acc": 53.0, "val_loss": 0.6908959984779358, "val_acc": 52.0}
{"epoch": 49, "training_loss": 0.6912949824333191, "training_acc": 53.0, "val_loss": 0.6908819079399109, "val_acc": 52.0}
{"epoch": 50, "training_loss": 0.6913531017303467, "training_acc": 53.0, "val_loss": 0.6908662009239197, "val_acc": 52.0}
{"epoch": 51, "training_loss": 0.6913456249237061, "training_acc": 53.0, "val_loss": 0.6908678436279296, "val_acc": 52.0}
{"epoch": 52, "training_loss": 0.6914027118682862, "training_acc": 53.0, "val_loss": 0.6908595132827758, "val_acc": 52.0}
{"epoch": 53, "training_loss": 0.6913950872421265, "training_acc": 53.0, "val_loss": 0.6908373832702637, "val_acc": 52.0}
{"epoch": 54, "training_loss": 0.6914757776260376, "training_acc": 53.0, "val_loss": 0.6908276772499085, "val_acc": 52.0}
{"epoch": 55, "training_loss": 0.6916562652587891, "training_acc": 53.0, "val_loss": 0.6908185291290283, "val_acc": 52.0}
{"epoch": 56, "training_loss": 0.6916015863418579, "training_acc": 53.0, "val_loss": 0.6908087491989136, "val_acc": 52.0}
{"epoch": 57, "training_loss": 0.69136953830719, "training_acc": 53.0, "val_loss": 0.6908024644851685, "val_acc": 52.0}
{"epoch": 58, "training_loss": 0.6912216424942017, "training_acc": 53.0, "val_loss": 0.6907909440994263, "val_acc": 52.0}
{"epoch": 59, "training_loss": 0.6908342170715333, "training_acc": 53.0, "val_loss": 0.6907936787605286, "val_acc": 52.0}
{"epoch": 60, "training_loss": 0.6910280466079712, "training_acc": 53.0, "val_loss": 0.6907973408699035, "val_acc": 52.0}
{"epoch": 61, "training_loss": 0.6910190415382386, "training_acc": 53.0, "val_loss": 0.6907920074462891, "val_acc": 52.0}
{"epoch": 62, "training_loss": 0.6911342716217042, "training_acc": 53.0, "val_loss": 0.6907733845710754, "val_acc": 52.0}
{"epoch": 63, "training_loss": 0.691161732673645, "training_acc": 53.0, "val_loss": 0.6907522702217102, "val_acc": 52.0}
{"epoch": 64, "training_loss": 0.6912778091430664, "training_acc": 53.0, "val_loss": 0.6907426071166992, "val_acc": 52.0}
{"epoch": 65, "training_loss": 0.6913240599632263, "training_acc": 53.0, "val_loss": 0.6907184553146363, "val_acc": 52.0}
{"epoch": 66, "training_loss": 0.6910192704200745, "training_acc": 53.0, "val_loss": 0.6907108449935913, "val_acc": 52.0}
{"epoch": 67, "training_loss": 0.6909326910972595, "training_acc": 53.0, "val_loss": 0.6907117629051208, "val_acc": 52.0}
{"epoch": 68, "training_loss": 0.6915745162963867, "training_acc": 53.0, "val_loss": 0.6906986308097839, "val_acc": 52.0}
{"epoch": 69, "training_loss": 0.6907958030700684, "training_acc": 53.0, "val_loss": 0.6906884431838989, "val_acc": 52.0}
{"epoch": 70, "training_loss": 0.6912940096855164, "training_acc": 53.0, "val_loss": 0.6906771683692932, "val_acc": 52.0}
{"epoch": 71, "training_loss": 0.6912584781646729, "training_acc": 53.0, "val_loss": 0.6906743264198303, "val_acc": 52.0}
{"epoch": 72, "training_loss": 0.6912098956108094, "training_acc": 53.0, "val_loss": 0.6906644535064698, "val_acc": 52.0}
{"epoch": 73, "training_loss": 0.6912924909591674, "training_acc": 53.0, "val_loss": 0.6906448101997376, "val_acc": 52.0}
{"epoch": 74, "training_loss": 0.6916024899482727, "training_acc": 53.0, "val_loss": 0.6906289982795716, "val_acc": 52.0}
{"epoch": 75, "training_loss": 0.691425621509552, "training_acc": 53.0, "val_loss": 0.6906256580352783, "val_acc": 52.0}
{"epoch": 76, "training_loss": 0.6914278149604798, "training_acc": 53.0, "val_loss": 0.6906248807907105, "val_acc": 52.0}
{"epoch": 77, "training_loss": 0.691128568649292, "training_acc": 53.0, "val_loss": 0.6906237244606018, "val_acc": 52.0}
{"epoch": 78, "training_loss": 0.6912651467323303, "training_acc": 53.0, "val_loss": 0.6906171059608459, "val_acc": 52.0}
{"epoch": 79, "training_loss": 0.6907862424850464, "training_acc": 53.0, "val_loss": 0.690611002445221, "val_acc": 52.0}
{"epoch": 80, "training_loss": 0.691488082408905, "training_acc": 53.0, "val_loss": 0.6906048321723938, "val_acc": 52.0}
{"epoch": 81, "training_loss": 0.6917055177688599, "training_acc": 53.0, "val_loss": 0.690608274936676, "val_acc": 52.0}
{"epoch": 82, "training_loss": 0.6914231491088867, "training_acc": 53.0, "val_loss": 0.6906128334999084, "val_acc": 52.0}
{"epoch": 83, "training_loss": 0.6911775064468384, "training_acc": 53.0, "val_loss": 0.6906153535842896, "val_acc": 52.0}
{"epoch": 84, "training_loss": 0.6914568662643432, "training_acc": 53.0, "val_loss": 0.6906128168106079, "val_acc": 52.0}
{"epoch": 85, "training_loss": 0.6913500404357911, "training_acc": 53.0, "val_loss": 0.6906079077720642, "val_acc": 52.0}
{"epoch": 86, "training_loss": 0.6911354875564575, "training_acc": 53.0, "val_loss": 0.6906079006195068, "val_acc": 52.0}
{"epoch": 87, "training_loss": 0.6911788034439087, "training_acc": 53.0, "val_loss": 0.6905968189239502, "val_acc": 52.0}
{"epoch": 88, "training_loss": 0.6913786315917969, "training_acc": 53.0, "val_loss": 0.690583565235138, "val_acc": 52.0}
{"epoch": 89, "training_loss": 0.6916374897956848, "training_acc": 53.0, "val_loss": 0.6905772757530212, "val_acc": 52.0}
{"epoch": 90, "training_loss": 0.6913369822502137, "training_acc": 53.0, "val_loss": 0.6905764722824097, "val_acc": 52.0}
{"epoch": 91, "training_loss": 0.6904248619079589, "training_acc": 53.0, "val_loss": 0.6905797481536865, "val_acc": 52.0}
{"epoch": 92, "training_loss": 0.6908106899261475, "training_acc": 53.0, "val_loss": 0.6905773878097534, "val_acc": 52.0}
{"epoch": 93, "training_loss": 0.6912347888946533, "training_acc": 53.0, "val_loss": 0.690576524734497, "val_acc": 52.0}
{"epoch": 94, "training_loss": 0.6914990496635437, "training_acc": 53.0, "val_loss": 0.6905804753303528, "val_acc": 52.0}
{"epoch": 95, "training_loss": 0.6910667634010315, "training_acc": 53.0, "val_loss": 0.6905797958374024, "val_acc": 52.0}
{"epoch": 96, "training_loss": 0.6913434934616088, "training_acc": 53.0, "val_loss": 0.6905892777442932, "val_acc": 52.0}
{"epoch": 97, "training_loss": 0.6912338924407959, "training_acc": 53.0, "val_loss": 0.6905986404418946, "val_acc": 52.0}
{"epoch": 98, "training_loss": 0.6911447811126709, "training_acc": 53.0, "val_loss": 0.6905952501296997, "val_acc": 52.0}
{"epoch": 99, "training_loss": 0.6906710863113403, "training_acc": 53.0, "val_loss": 0.6905989956855774, "val_acc": 52.0}
