"main_modify.py --pretrained_path /scratch/connectome/dyhan316/VAE_ADHD/barlowtwins/pretrain_results/ABCDbt128a102.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 2 --task ABCD_sex --input_option BT_org --learning_rate 1e-4 --batch_size 16 --weight_decay 1e-2 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 0.693736047744751, "training_acc": 53.0, "val_loss": 0.6916800379753113, "val_acc": 52.0}
{"epoch": 1, "training_loss": 0.6926766920089722, "training_acc": 53.0, "val_loss": 0.6908623552322388, "val_acc": 52.0}
{"epoch": 2, "training_loss": 0.6921747350692748, "training_acc": 53.0, "val_loss": 0.6898651814460754, "val_acc": 52.0}
{"epoch": 3, "training_loss": 0.6914642906188965, "training_acc": 53.0, "val_loss": 0.6898138952255249, "val_acc": 52.0}
{"epoch": 4, "training_loss": 0.6910287165641784, "training_acc": 53.0, "val_loss": 0.6901545047760009, "val_acc": 52.0}
{"epoch": 5, "training_loss": 0.6916141867637634, "training_acc": 53.0, "val_loss": 0.6903387761116028, "val_acc": 52.0}
{"epoch": 6, "training_loss": 0.691972188949585, "training_acc": 53.0, "val_loss": 0.6897233486175537, "val_acc": 52.0}
{"epoch": 7, "training_loss": 0.6918050408363342, "training_acc": 53.0, "val_loss": 0.689948570728302, "val_acc": 52.0}
{"epoch": 8, "training_loss": 0.690952205657959, "training_acc": 53.0, "val_loss": 0.6897420144081116, "val_acc": 52.0}
{"epoch": 9, "training_loss": 0.6912251472473144, "training_acc": 53.0, "val_loss": 0.6896675896644592, "val_acc": 52.0}
{"epoch": 10, "training_loss": 0.6909646773338318, "training_acc": 53.0, "val_loss": 0.6897393488883972, "val_acc": 52.0}
{"epoch": 11, "training_loss": 0.6905681490898132, "training_acc": 53.0, "val_loss": 0.6897250199317932, "val_acc": 52.0}
{"epoch": 12, "training_loss": 0.6907882976531983, "training_acc": 53.0, "val_loss": 0.6898895454406738, "val_acc": 52.0}
{"epoch": 13, "training_loss": 0.6909611797332764, "training_acc": 53.0, "val_loss": 0.6900738835334778, "val_acc": 52.0}
{"epoch": 14, "training_loss": 0.6911159133911133, "training_acc": 53.0, "val_loss": 0.6901404523849487, "val_acc": 52.0}
{"epoch": 15, "training_loss": 0.6900517416000366, "training_acc": 53.0, "val_loss": 0.690393078327179, "val_acc": 52.0}
{"epoch": 16, "training_loss": 0.6912117743492127, "training_acc": 53.0, "val_loss": 0.6902981233596802, "val_acc": 52.0}
{"epoch": 17, "training_loss": 0.6913986682891846, "training_acc": 53.0, "val_loss": 0.6900348281860351, "val_acc": 52.0}
{"epoch": 18, "training_loss": 0.6923114919662475, "training_acc": 53.0, "val_loss": 0.6907522940635681, "val_acc": 52.0}
{"epoch": 19, "training_loss": 0.6912618160247803, "training_acc": 53.0, "val_loss": 0.69062983751297, "val_acc": 52.0}
{"epoch": 20, "training_loss": 0.6911336994171142, "training_acc": 53.0, "val_loss": 0.6902678751945496, "val_acc": 52.0}
{"epoch": 21, "training_loss": 0.6901950240135193, "training_acc": 53.0, "val_loss": 0.689801652431488, "val_acc": 52.0}
{"epoch": 22, "training_loss": 0.6924893283843994, "training_acc": 53.0, "val_loss": 0.6898682618141174, "val_acc": 52.0}
{"epoch": 23, "training_loss": 0.6913762617111207, "training_acc": 53.0, "val_loss": 0.6897925186157227, "val_acc": 52.0}
{"epoch": 24, "training_loss": 0.6907898497581482, "training_acc": 53.0, "val_loss": 0.6896998643875122, "val_acc": 52.0}
{"epoch": 25, "training_loss": 0.6911389780044556, "training_acc": 53.0, "val_loss": 0.6896803522109985, "val_acc": 52.0}
{"epoch": 26, "training_loss": 0.6898372173309326, "training_acc": 53.0, "val_loss": 0.6900071310997009, "val_acc": 52.0}
{"epoch": 27, "training_loss": 0.6896691703796387, "training_acc": 53.0, "val_loss": 0.6909519648551941, "val_acc": 52.0}
{"epoch": 28, "training_loss": 0.6936904191970825, "training_acc": 53.0, "val_loss": 0.69270742893219, "val_acc": 52.0}
