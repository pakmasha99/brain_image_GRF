"main_modify.py --pretrained_path /scratch/connectome/dyhan316/VAE_ADHD/barlowtwins/pretrain_results/ABCDbt128a102.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 2 --task ABCD_sex --input_option BT_org --learning_rate 1e-4 --batch_size 16 --weight_decay 1e-2 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 0.6932959127426147, "training_acc": 47.0, "val_loss": 0.690677993297577, "val_acc": 52.0}
{"epoch": 1, "training_loss": 0.6914967918395996, "training_acc": 53.0, "val_loss": 0.6906961822509765, "val_acc": 52.0}
{"epoch": 2, "training_loss": 0.69188307762146, "training_acc": 53.0, "val_loss": 0.6908051419258118, "val_acc": 52.0}
{"epoch": 3, "training_loss": 0.6914492082595826, "training_acc": 53.0, "val_loss": 0.69058758020401, "val_acc": 52.0}
{"epoch": 4, "training_loss": 0.6912921571731567, "training_acc": 53.0, "val_loss": 0.690621075630188, "val_acc": 52.0}
{"epoch": 5, "training_loss": 0.6909324383735657, "training_acc": 53.0, "val_loss": 0.6909385299682618, "val_acc": 52.0}
{"epoch": 6, "training_loss": 0.6917239546775817, "training_acc": 53.0, "val_loss": 0.6906587386131287, "val_acc": 52.0}
{"epoch": 7, "training_loss": 0.6907370615005494, "training_acc": 53.0, "val_loss": 0.6907180762290954, "val_acc": 52.0}
{"epoch": 8, "training_loss": 0.691008939743042, "training_acc": 53.0, "val_loss": 0.6910346221923828, "val_acc": 52.0}
{"epoch": 9, "training_loss": 0.6921003627777099, "training_acc": 53.0, "val_loss": 0.6916720342636108, "val_acc": 52.0}
{"epoch": 10, "training_loss": 0.6914257979393006, "training_acc": 53.0, "val_loss": 0.6912066292762756, "val_acc": 52.0}
{"epoch": 11, "training_loss": 0.6909937691688538, "training_acc": 53.0, "val_loss": 0.690950026512146, "val_acc": 52.0}
{"epoch": 12, "training_loss": 0.6907693243026733, "training_acc": 53.0, "val_loss": 0.6907063841819763, "val_acc": 52.0}
{"epoch": 13, "training_loss": 0.6919507694244384, "training_acc": 53.0, "val_loss": 0.6913448262214661, "val_acc": 52.0}
{"epoch": 14, "training_loss": 0.6909615159034729, "training_acc": 53.0, "val_loss": 0.691139144897461, "val_acc": 52.0}
{"epoch": 15, "training_loss": 0.6901779985427856, "training_acc": 53.0, "val_loss": 0.6906712579727173, "val_acc": 52.0}
{"epoch": 16, "training_loss": 0.6905432748794555, "training_acc": 53.0, "val_loss": 0.6903884363174438, "val_acc": 52.0}
{"epoch": 17, "training_loss": 0.6912205147743226, "training_acc": 53.0, "val_loss": 0.690511748790741, "val_acc": 52.0}
{"epoch": 18, "training_loss": 0.6911890244483948, "training_acc": 53.0, "val_loss": 0.6903253531455994, "val_acc": 52.0}
{"epoch": 19, "training_loss": 0.6907234048843384, "training_acc": 53.0, "val_loss": 0.6904107999801635, "val_acc": 52.0}
{"epoch": 20, "training_loss": 0.6930770754814148, "training_acc": 51.0, "val_loss": 0.6908209729194641, "val_acc": 60.0}
{"epoch": 21, "training_loss": 0.69097501039505, "training_acc": 54.0, "val_loss": 0.6903316974639893, "val_acc": 52.0}
{"epoch": 22, "training_loss": 0.690562539100647, "training_acc": 53.0, "val_loss": 0.6905124068260193, "val_acc": 52.0}
{"epoch": 23, "training_loss": 0.6907132196426392, "training_acc": 53.0, "val_loss": 0.6913084244728088, "val_acc": 52.0}
{"epoch": 24, "training_loss": 0.6912750053405762, "training_acc": 53.0, "val_loss": 0.690878643989563, "val_acc": 52.0}
{"epoch": 25, "training_loss": 0.6907558727264405, "training_acc": 53.0, "val_loss": 0.6916115069389344, "val_acc": 52.0}
{"epoch": 26, "training_loss": 0.691791033744812, "training_acc": 53.0, "val_loss": 0.6913160800933837, "val_acc": 52.0}
{"epoch": 27, "training_loss": 0.6909375143051147, "training_acc": 53.0, "val_loss": 0.6920800113677978, "val_acc": 52.0}
{"epoch": 28, "training_loss": 0.6923716306686402, "training_acc": 53.0, "val_loss": 0.6922802305221558, "val_acc": 52.0}
{"epoch": 29, "training_loss": 0.691443407535553, "training_acc": 53.0, "val_loss": 0.6903307652473449, "val_acc": 52.0}
{"epoch": 30, "training_loss": 0.6891120910644531, "training_acc": 53.0, "val_loss": 0.6901462650299073, "val_acc": 52.0}
{"epoch": 31, "training_loss": 0.6905988740921021, "training_acc": 53.0, "val_loss": 0.6901744389533997, "val_acc": 52.0}
{"epoch": 32, "training_loss": 0.6907302045822143, "training_acc": 53.0, "val_loss": 0.6905098342895508, "val_acc": 56.0}
{"epoch": 33, "training_loss": 0.6918975162506104, "training_acc": 58.0, "val_loss": 0.6906282925605773, "val_acc": 60.0}
{"epoch": 34, "training_loss": 0.6942729735374451, "training_acc": 52.0, "val_loss": 0.6900894856452942, "val_acc": 52.0}
{"epoch": 35, "training_loss": 0.6909725046157837, "training_acc": 53.0, "val_loss": 0.6900978350639343, "val_acc": 52.0}
{"epoch": 36, "training_loss": 0.6903168797492981, "training_acc": 53.0, "val_loss": 0.6904438757896423, "val_acc": 52.0}
{"epoch": 37, "training_loss": 0.6905519270896912, "training_acc": 53.0, "val_loss": 0.691400990486145, "val_acc": 52.0}
{"epoch": 38, "training_loss": 0.6911694431304931, "training_acc": 53.0, "val_loss": 0.6917264652252197, "val_acc": 52.0}
{"epoch": 39, "training_loss": 0.6911973857879639, "training_acc": 53.0, "val_loss": 0.6916950607299804, "val_acc": 52.0}
{"epoch": 40, "training_loss": 0.6914050531387329, "training_acc": 53.0, "val_loss": 0.6912626338005066, "val_acc": 52.0}
{"epoch": 41, "training_loss": 0.6925229573249817, "training_acc": 53.0, "val_loss": 0.6902265405654907, "val_acc": 52.0}
{"epoch": 42, "training_loss": 0.690724310874939, "training_acc": 53.0, "val_loss": 0.6900817131996155, "val_acc": 52.0}
{"epoch": 43, "training_loss": 0.6902644062042236, "training_acc": 53.0, "val_loss": 0.6900181365013123, "val_acc": 52.0}
{"epoch": 44, "training_loss": 0.6904046559333801, "training_acc": 53.0, "val_loss": 0.6901004481315612, "val_acc": 52.0}
{"epoch": 45, "training_loss": 0.6899904704093933, "training_acc": 53.0, "val_loss": 0.6899901127815247, "val_acc": 52.0}
{"epoch": 46, "training_loss": 0.6895303273200989, "training_acc": 53.0, "val_loss": 0.6899797320365906, "val_acc": 52.0}
{"epoch": 47, "training_loss": 0.6918477058410645, "training_acc": 56.0, "val_loss": 0.6905275321006775, "val_acc": 72.0}
{"epoch": 48, "training_loss": 0.6915110421180725, "training_acc": 57.0, "val_loss": 0.690018150806427, "val_acc": 52.0}
{"epoch": 49, "training_loss": 0.6902026224136353, "training_acc": 53.0, "val_loss": 0.6898804187774659, "val_acc": 52.0}
{"epoch": 50, "training_loss": 0.6908492422103882, "training_acc": 53.0, "val_loss": 0.6905345225334167, "val_acc": 52.0}
{"epoch": 51, "training_loss": 0.6906963396072388, "training_acc": 53.0, "val_loss": 0.6901478314399719, "val_acc": 52.0}
{"epoch": 52, "training_loss": 0.6897068357467652, "training_acc": 53.0, "val_loss": 0.6898961591720582, "val_acc": 52.0}
{"epoch": 53, "training_loss": 0.6911348223686218, "training_acc": 53.0, "val_loss": 0.6898014450073242, "val_acc": 52.0}
{"epoch": 54, "training_loss": 0.6903416609764099, "training_acc": 53.0, "val_loss": 0.6899139332771301, "val_acc": 52.0}
{"epoch": 55, "training_loss": 0.6913352966308594, "training_acc": 53.0, "val_loss": 0.6910790753364563, "val_acc": 52.0}
{"epoch": 56, "training_loss": 0.6908214259147644, "training_acc": 53.0, "val_loss": 0.6918791842460632, "val_acc": 52.0}
{"epoch": 57, "training_loss": 0.6918045663833619, "training_acc": 53.0, "val_loss": 0.6918431448936463, "val_acc": 52.0}
{"epoch": 58, "training_loss": 0.6909650325775146, "training_acc": 53.0, "val_loss": 0.6908290076255799, "val_acc": 52.0}
{"epoch": 59, "training_loss": 0.6908007001876831, "training_acc": 53.0, "val_loss": 0.6909983873367309, "val_acc": 52.0}
{"epoch": 60, "training_loss": 0.6918764710426331, "training_acc": 53.0, "val_loss": 0.6918193340301514, "val_acc": 52.0}
{"epoch": 61, "training_loss": 0.6910824012756348, "training_acc": 53.0, "val_loss": 0.6905191087722778, "val_acc": 52.0}
{"epoch": 62, "training_loss": 0.69018639087677, "training_acc": 53.0, "val_loss": 0.690421838760376, "val_acc": 52.0}
{"epoch": 63, "training_loss": 0.6901169729232788, "training_acc": 53.0, "val_loss": 0.6904878950119019, "val_acc": 52.0}
{"epoch": 64, "training_loss": 0.6908185887336731, "training_acc": 53.0, "val_loss": 0.6910607647895813, "val_acc": 52.0}
{"epoch": 65, "training_loss": 0.6901842021942138, "training_acc": 53.0, "val_loss": 0.6911770534515381, "val_acc": 52.0}
{"epoch": 66, "training_loss": 0.6907270884513855, "training_acc": 53.0, "val_loss": 0.690975456237793, "val_acc": 52.0}
{"epoch": 67, "training_loss": 0.6904671287536621, "training_acc": 53.0, "val_loss": 0.690383083820343, "val_acc": 52.0}
{"epoch": 68, "training_loss": 0.6904574155807495, "training_acc": 53.0, "val_loss": 0.6905452823638916, "val_acc": 52.0}
{"epoch": 69, "training_loss": 0.689808394908905, "training_acc": 53.0, "val_loss": 0.6901989555358887, "val_acc": 52.0}
{"epoch": 70, "training_loss": 0.6901393890380859, "training_acc": 53.0, "val_loss": 0.6901188015937805, "val_acc": 52.0}
{"epoch": 71, "training_loss": 0.6906656837463379, "training_acc": 53.0, "val_loss": 0.6898564457893371, "val_acc": 52.0}
{"epoch": 72, "training_loss": 0.6898173379898072, "training_acc": 53.0, "val_loss": 0.6898861694335937, "val_acc": 52.0}
