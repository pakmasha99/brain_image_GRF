"main_modify.py --pretrained_path /scratch/connectome/dyhan316/VAE_ADHD/barlowtwins/pretrain_results/ABCDbt128a102.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 1 --task ABCD_sex --input_option BT_org --learning_rate 1e-4 --batch_size 16 --weight_decay 1e-2 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 0.6931833696365356, "training_acc": 54.0, "val_loss": 0.692426815032959, "val_acc": 52.0}
{"epoch": 1, "training_loss": 0.6921338534355164, "training_acc": 53.0, "val_loss": 0.6927427959442138, "val_acc": 52.0}
{"epoch": 2, "training_loss": 0.6916416144371033, "training_acc": 53.0, "val_loss": 0.692944610118866, "val_acc": 52.0}
{"epoch": 3, "training_loss": 0.6918241882324219, "training_acc": 53.0, "val_loss": 0.6930468392372131, "val_acc": 52.0}
{"epoch": 4, "training_loss": 0.6917426800727844, "training_acc": 53.0, "val_loss": 0.693110179901123, "val_acc": 52.0}
{"epoch": 5, "training_loss": 0.6920363140106202, "training_acc": 53.0, "val_loss": 0.6929459667205811, "val_acc": 52.0}
{"epoch": 6, "training_loss": 0.6922016525268555, "training_acc": 53.0, "val_loss": 0.6924919223785401, "val_acc": 52.0}
{"epoch": 7, "training_loss": 0.6917047309875488, "training_acc": 53.0, "val_loss": 0.6924780225753784, "val_acc": 52.0}
{"epoch": 8, "training_loss": 0.6916297245025634, "training_acc": 53.0, "val_loss": 0.692654972076416, "val_acc": 52.0}
{"epoch": 9, "training_loss": 0.691992483139038, "training_acc": 53.0, "val_loss": 0.6935519862174988, "val_acc": 52.0}
{"epoch": 10, "training_loss": 0.6917484903335571, "training_acc": 53.0, "val_loss": 0.6932231950759887, "val_acc": 52.0}
{"epoch": 11, "training_loss": 0.691457839012146, "training_acc": 53.0, "val_loss": 0.692778024673462, "val_acc": 52.0}
{"epoch": 12, "training_loss": 0.6935235452651978, "training_acc": 53.0, "val_loss": 0.6924241828918457, "val_acc": 52.0}
{"epoch": 13, "training_loss": 0.6937758636474609, "training_acc": 53.0, "val_loss": 0.6928533959388733, "val_acc": 52.0}
{"epoch": 14, "training_loss": 0.6920901393890381, "training_acc": 53.0, "val_loss": 0.6930509400367737, "val_acc": 52.0}
{"epoch": 15, "training_loss": 0.6918431901931763, "training_acc": 53.0, "val_loss": 0.6926430869102478, "val_acc": 52.0}
{"epoch": 16, "training_loss": 0.6909536147117614, "training_acc": 53.0, "val_loss": 0.6924158978462219, "val_acc": 52.0}
{"epoch": 17, "training_loss": 0.6921026754379273, "training_acc": 53.0, "val_loss": 0.6926392102241516, "val_acc": 52.0}
{"epoch": 18, "training_loss": 0.6919877076148987, "training_acc": 53.0, "val_loss": 0.6924409365653992, "val_acc": 52.0}
{"epoch": 19, "training_loss": 0.6916041898727417, "training_acc": 53.0, "val_loss": 0.692671639919281, "val_acc": 52.0}
{"epoch": 20, "training_loss": 0.6915956544876098, "training_acc": 53.0, "val_loss": 0.6925260186195373, "val_acc": 52.0}
{"epoch": 21, "training_loss": 0.6919665908813477, "training_acc": 53.0, "val_loss": 0.6924158692359924, "val_acc": 52.0}
{"epoch": 22, "training_loss": 0.6919780254364014, "training_acc": 53.0, "val_loss": 0.6924480533599854, "val_acc": 52.0}
{"epoch": 23, "training_loss": 0.6913163852691651, "training_acc": 53.0, "val_loss": 0.6924244236946105, "val_acc": 52.0}
{"epoch": 24, "training_loss": 0.6916910409927368, "training_acc": 53.0, "val_loss": 0.6924348139762878, "val_acc": 52.0}
{"epoch": 25, "training_loss": 0.6914709711074829, "training_acc": 53.0, "val_loss": 0.692437219619751, "val_acc": 52.0}
{"epoch": 26, "training_loss": 0.6914619278907775, "training_acc": 53.0, "val_loss": 0.6924787878990173, "val_acc": 52.0}
{"epoch": 27, "training_loss": 0.6933982753753662, "training_acc": 53.0, "val_loss": 0.6928654789924622, "val_acc": 52.0}
{"epoch": 28, "training_loss": 0.6912800765037537, "training_acc": 53.0, "val_loss": 0.6926803326606751, "val_acc": 52.0}
{"epoch": 29, "training_loss": 0.6912026214599609, "training_acc": 53.0, "val_loss": 0.6927006173133851, "val_acc": 52.0}
{"epoch": 30, "training_loss": 0.6906467199325561, "training_acc": 53.0, "val_loss": 0.6927137899398804, "val_acc": 52.0}
{"epoch": 31, "training_loss": 0.6905100846290588, "training_acc": 53.0, "val_loss": 0.6927032780647278, "val_acc": 52.0}
{"epoch": 32, "training_loss": 0.6920488262176514, "training_acc": 53.0, "val_loss": 0.6931388878822327, "val_acc": 52.0}
{"epoch": 33, "training_loss": 0.6920639610290528, "training_acc": 53.0, "val_loss": 0.6925607800483704, "val_acc": 52.0}
{"epoch": 34, "training_loss": 0.6906502199172974, "training_acc": 53.0, "val_loss": 0.6926047611236572, "val_acc": 52.0}
{"epoch": 35, "training_loss": 0.6919499492645264, "training_acc": 53.0, "val_loss": 0.6924245142936707, "val_acc": 52.0}
{"epoch": 36, "training_loss": 0.6915304255485535, "training_acc": 53.0, "val_loss": 0.6925202298164368, "val_acc": 52.0}
{"epoch": 37, "training_loss": 0.6906149101257324, "training_acc": 53.0, "val_loss": 0.692961061000824, "val_acc": 52.0}
{"epoch": 38, "training_loss": 0.6909147930145264, "training_acc": 53.0, "val_loss": 0.6927969360351562, "val_acc": 52.0}
{"epoch": 39, "training_loss": 0.6915949654579162, "training_acc": 53.0, "val_loss": 0.6926701235771179, "val_acc": 52.0}
{"epoch": 40, "training_loss": 0.6905214476585388, "training_acc": 53.0, "val_loss": 0.692536461353302, "val_acc": 52.0}
{"epoch": 41, "training_loss": 0.6923847198486328, "training_acc": 53.0, "val_loss": 0.6924056935310364, "val_acc": 52.0}
{"epoch": 42, "training_loss": 0.6916619944572449, "training_acc": 53.0, "val_loss": 0.692471923828125, "val_acc": 52.0}
{"epoch": 43, "training_loss": 0.6916697788238525, "training_acc": 53.0, "val_loss": 0.6928305315971375, "val_acc": 52.0}
{"epoch": 44, "training_loss": 0.6910036897659302, "training_acc": 53.0, "val_loss": 0.692892062664032, "val_acc": 52.0}
{"epoch": 45, "training_loss": 0.6905024719238281, "training_acc": 53.0, "val_loss": 0.6924982261657715, "val_acc": 52.0}
{"epoch": 46, "training_loss": 0.690184257030487, "training_acc": 53.0, "val_loss": 0.6924251770973205, "val_acc": 52.0}
{"epoch": 47, "training_loss": 0.6919808554649353, "training_acc": 53.0, "val_loss": 0.6924137854576111, "val_acc": 52.0}
{"epoch": 48, "training_loss": 0.6909174680709839, "training_acc": 53.0, "val_loss": 0.6928076529502869, "val_acc": 52.0}
{"epoch": 49, "training_loss": 0.6911954021453858, "training_acc": 53.0, "val_loss": 0.6931889533996582, "val_acc": 52.0}
{"epoch": 50, "training_loss": 0.6914235162734985, "training_acc": 53.0, "val_loss": 0.694144515991211, "val_acc": 52.0}
{"epoch": 51, "training_loss": 0.6916258668899536, "training_acc": 53.0, "val_loss": 0.6938168430328369, "val_acc": 52.0}
{"epoch": 52, "training_loss": 0.6917496585845947, "training_acc": 53.0, "val_loss": 0.6937216544151306, "val_acc": 52.0}
{"epoch": 53, "training_loss": 0.6919170141220092, "training_acc": 53.0, "val_loss": 0.6925259923934937, "val_acc": 52.0}
{"epoch": 54, "training_loss": 0.6906675672531128, "training_acc": 53.0, "val_loss": 0.6924421215057373, "val_acc": 52.0}
{"epoch": 55, "training_loss": 0.6912205362319946, "training_acc": 53.0, "val_loss": 0.6924402832984924, "val_acc": 52.0}
{"epoch": 56, "training_loss": 0.69128408908844, "training_acc": 53.0, "val_loss": 0.692404625415802, "val_acc": 52.0}
{"epoch": 57, "training_loss": 0.6912058615684509, "training_acc": 53.0, "val_loss": 0.6924277091026306, "val_acc": 52.0}
{"epoch": 58, "training_loss": 0.6913527154922485, "training_acc": 53.0, "val_loss": 0.6924690055847168, "val_acc": 52.0}
{"epoch": 59, "training_loss": 0.6902676153182984, "training_acc": 53.0, "val_loss": 0.6925414061546326, "val_acc": 52.0}
{"epoch": 60, "training_loss": 0.6900079822540284, "training_acc": 53.0, "val_loss": 0.6928341603279113, "val_acc": 52.0}
{"epoch": 61, "training_loss": 0.6911301159858704, "training_acc": 53.0, "val_loss": 0.6934197950363159, "val_acc": 52.0}
{"epoch": 62, "training_loss": 0.6907910728454589, "training_acc": 53.0, "val_loss": 0.6925845313072204, "val_acc": 52.0}
{"epoch": 63, "training_loss": 0.6906279754638672, "training_acc": 53.0, "val_loss": 0.6924256539344787, "val_acc": 52.0}
{"epoch": 64, "training_loss": 0.6905563426017761, "training_acc": 53.0, "val_loss": 0.6923846101760864, "val_acc": 52.0}
{"epoch": 65, "training_loss": 0.6906128144264221, "training_acc": 53.0, "val_loss": 0.6923803043365478, "val_acc": 52.0}
{"epoch": 66, "training_loss": 0.6911281275749207, "training_acc": 53.0, "val_loss": 0.6925503039360046, "val_acc": 52.0}
{"epoch": 67, "training_loss": 0.6912177586555481, "training_acc": 53.0, "val_loss": 0.6924387860298157, "val_acc": 52.0}
{"epoch": 68, "training_loss": 0.6904367160797119, "training_acc": 53.0, "val_loss": 0.6926413750648499, "val_acc": 52.0}
{"epoch": 69, "training_loss": 0.6912972164154053, "training_acc": 53.0, "val_loss": 0.6932833528518677, "val_acc": 52.0}
{"epoch": 70, "training_loss": 0.6910156631469726, "training_acc": 53.0, "val_loss": 0.6930345630645752, "val_acc": 52.0}
{"epoch": 71, "training_loss": 0.6907382702827454, "training_acc": 53.0, "val_loss": 0.6932317733764648, "val_acc": 52.0}
{"epoch": 72, "training_loss": 0.6905420446395873, "training_acc": 53.0, "val_loss": 0.6928309631347657, "val_acc": 52.0}
{"epoch": 73, "training_loss": 0.6922022652626038, "training_acc": 53.0, "val_loss": 0.6923750662803649, "val_acc": 52.0}
{"epoch": 74, "training_loss": 0.6909838533401489, "training_acc": 53.0, "val_loss": 0.6924113011360169, "val_acc": 52.0}
{"epoch": 75, "training_loss": 0.6905100393295288, "training_acc": 53.0, "val_loss": 0.6923881268501282, "val_acc": 52.0}
{"epoch": 76, "training_loss": 0.6897504568099976, "training_acc": 53.0, "val_loss": 0.6923944973945617, "val_acc": 52.0}
{"epoch": 77, "training_loss": 0.6909350895881653, "training_acc": 53.0, "val_loss": 0.6923872828483582, "val_acc": 52.0}
{"epoch": 78, "training_loss": 0.6900819396972656, "training_acc": 53.0, "val_loss": 0.6923715710639954, "val_acc": 52.0}
{"epoch": 79, "training_loss": 0.6907068920135498, "training_acc": 53.0, "val_loss": 0.6923714017868042, "val_acc": 52.0}
{"epoch": 80, "training_loss": 0.6908229303359985, "training_acc": 53.0, "val_loss": 0.692388060092926, "val_acc": 52.0}
{"epoch": 81, "training_loss": 0.6905027532577515, "training_acc": 53.0, "val_loss": 0.6923797488212585, "val_acc": 52.0}
{"epoch": 82, "training_loss": 0.6909132266044616, "training_acc": 53.0, "val_loss": 0.6923689365386962, "val_acc": 52.0}
{"epoch": 83, "training_loss": 0.6905646514892578, "training_acc": 53.0, "val_loss": 0.692523045539856, "val_acc": 52.0}
{"epoch": 84, "training_loss": 0.6909831285476684, "training_acc": 53.0, "val_loss": 0.6924771642684937, "val_acc": 52.0}
{"epoch": 85, "training_loss": 0.6912810492515564, "training_acc": 53.0, "val_loss": 0.692450065612793, "val_acc": 52.0}
{"epoch": 86, "training_loss": 0.6890963411331177, "training_acc": 53.0, "val_loss": 0.6925030088424683, "val_acc": 52.0}
{"epoch": 87, "training_loss": 0.6899414253234863, "training_acc": 53.0, "val_loss": 0.6937728595733642, "val_acc": 52.0}
{"epoch": 88, "training_loss": 0.6907536792755127, "training_acc": 53.0, "val_loss": 0.6953688740730286, "val_acc": 52.0}
{"epoch": 89, "training_loss": 0.6919264101982117, "training_acc": 53.0, "val_loss": 0.6956687259674073, "val_acc": 52.0}
{"epoch": 90, "training_loss": 0.6917161273956299, "training_acc": 53.0, "val_loss": 0.694691915512085, "val_acc": 52.0}
{"epoch": 91, "training_loss": 0.6914146232604981, "training_acc": 53.0, "val_loss": 0.6933096385002137, "val_acc": 52.0}
{"epoch": 92, "training_loss": 0.6906327962875366, "training_acc": 53.0, "val_loss": 0.6926234865188599, "val_acc": 52.0}
{"epoch": 93, "training_loss": 0.6909594941139221, "training_acc": 53.0, "val_loss": 0.692380714416504, "val_acc": 52.0}
{"epoch": 94, "training_loss": 0.6902997970581055, "training_acc": 53.0, "val_loss": 0.692356960773468, "val_acc": 52.0}
{"epoch": 95, "training_loss": 0.69097323179245, "training_acc": 53.0, "val_loss": 0.692410147190094, "val_acc": 52.0}
{"epoch": 96, "training_loss": 0.6902762937545777, "training_acc": 53.0, "val_loss": 0.6923577880859375, "val_acc": 52.0}
{"epoch": 97, "training_loss": 0.6901051473617553, "training_acc": 53.0, "val_loss": 0.6924551510810852, "val_acc": 52.0}
{"epoch": 98, "training_loss": 0.6900088691711426, "training_acc": 53.0, "val_loss": 0.6929595017433167, "val_acc": 52.0}
{"epoch": 99, "training_loss": 0.6909143686294555, "training_acc": 53.0, "val_loss": 0.693967628479004, "val_acc": 52.0}
