"main_modify.py --pretrained_path /scratch/connectome/dyhan316/VAE_ADHD/barlowtwins/pretrain_results/ABCDbt128a102.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 1 --task ABCD_sex --input_option BT_org --learning_rate 1e-4 --batch_size 16 --weight_decay 1e-2 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 0.6938398551940917, "training_acc": 53.0, "val_loss": 0.6905966329574585, "val_acc": 52.0}
{"epoch": 1, "training_loss": 0.6922233152389526, "training_acc": 53.0, "val_loss": 0.6911253452301025, "val_acc": 52.0}
{"epoch": 2, "training_loss": 0.6915096378326416, "training_acc": 53.0, "val_loss": 0.6925215482711792, "val_acc": 52.0}
{"epoch": 3, "training_loss": 0.6929555869102478, "training_acc": 53.0, "val_loss": 0.6926729893684387, "val_acc": 52.0}
{"epoch": 4, "training_loss": 0.6933694195747375, "training_acc": 53.0, "val_loss": 0.6920863580703736, "val_acc": 52.0}
{"epoch": 5, "training_loss": 0.6931225490570069, "training_acc": 53.0, "val_loss": 0.692670865058899, "val_acc": 52.0}
{"epoch": 6, "training_loss": 0.6938902378082276, "training_acc": 53.0, "val_loss": 0.6928262758255005, "val_acc": 52.0}
{"epoch": 7, "training_loss": 0.69301335811615, "training_acc": 53.0, "val_loss": 0.6917335438728333, "val_acc": 52.0}
{"epoch": 8, "training_loss": 0.6919857454299927, "training_acc": 53.0, "val_loss": 0.6910939621925354, "val_acc": 52.0}
{"epoch": 9, "training_loss": 0.6922200536727905, "training_acc": 53.0, "val_loss": 0.6909957957267762, "val_acc": 52.0}
{"epoch": 10, "training_loss": 0.6926190996170044, "training_acc": 53.0, "val_loss": 0.6906529951095581, "val_acc": 52.0}
{"epoch": 11, "training_loss": 0.6919365930557251, "training_acc": 53.0, "val_loss": 0.6906154894828797, "val_acc": 52.0}
{"epoch": 12, "training_loss": 0.6923518919944763, "training_acc": 53.0, "val_loss": 0.6908710098266602, "val_acc": 52.0}
{"epoch": 13, "training_loss": 0.6929714059829712, "training_acc": 53.0, "val_loss": 0.6911942720413208, "val_acc": 52.0}
{"epoch": 14, "training_loss": 0.6924590682983398, "training_acc": 53.0, "val_loss": 0.6906628775596618, "val_acc": 52.0}
{"epoch": 15, "training_loss": 0.6927407884597778, "training_acc": 53.0, "val_loss": 0.6906903433799744, "val_acc": 52.0}
{"epoch": 16, "training_loss": 0.6921563720703126, "training_acc": 53.0, "val_loss": 0.6906044197082519, "val_acc": 52.0}
{"epoch": 17, "training_loss": 0.692249653339386, "training_acc": 53.0, "val_loss": 0.690666856765747, "val_acc": 52.0}
{"epoch": 18, "training_loss": 0.6922103834152221, "training_acc": 53.0, "val_loss": 0.6905829668045044, "val_acc": 52.0}
{"epoch": 19, "training_loss": 0.6917262268066406, "training_acc": 53.0, "val_loss": 0.690657434463501, "val_acc": 52.0}
{"epoch": 20, "training_loss": 0.6927786016464234, "training_acc": 53.0, "val_loss": 0.6909243130683899, "val_acc": 52.0}
{"epoch": 21, "training_loss": 0.6913922309875489, "training_acc": 53.0, "val_loss": 0.691528103351593, "val_acc": 52.0}
{"epoch": 22, "training_loss": 0.6927292537689209, "training_acc": 53.0, "val_loss": 0.6927793169021607, "val_acc": 52.0}
{"epoch": 23, "training_loss": 0.6929254770278931, "training_acc": 53.0, "val_loss": 0.6918164253234863, "val_acc": 52.0}
{"epoch": 24, "training_loss": 0.694791431427002, "training_acc": 53.0, "val_loss": 0.6908295822143554, "val_acc": 52.0}
{"epoch": 25, "training_loss": 0.6921467208862304, "training_acc": 53.0, "val_loss": 0.6909336543083191, "val_acc": 52.0}
{"epoch": 26, "training_loss": 0.691767065525055, "training_acc": 53.0, "val_loss": 0.6909864521026612, "val_acc": 52.0}
{"epoch": 27, "training_loss": 0.692895770072937, "training_acc": 53.0, "val_loss": 0.6916043543815613, "val_acc": 52.0}
{"epoch": 28, "training_loss": 0.6925653171539307, "training_acc": 53.0, "val_loss": 0.6906824827194213, "val_acc": 52.0}
{"epoch": 29, "training_loss": 0.6921863961219787, "training_acc": 53.0, "val_loss": 0.690802230834961, "val_acc": 52.0}
{"epoch": 30, "training_loss": 0.6919071960449219, "training_acc": 53.0, "val_loss": 0.690818452835083, "val_acc": 52.0}
{"epoch": 31, "training_loss": 0.6918313455581665, "training_acc": 53.0, "val_loss": 0.6907623124122619, "val_acc": 52.0}
{"epoch": 32, "training_loss": 0.6916031455993652, "training_acc": 53.0, "val_loss": 0.6906473898887634, "val_acc": 52.0}
{"epoch": 33, "training_loss": 0.6916816091537475, "training_acc": 53.0, "val_loss": 0.6908924221992493, "val_acc": 52.0}
{"epoch": 34, "training_loss": 0.6924584817886352, "training_acc": 53.0, "val_loss": 0.6920641350746155, "val_acc": 52.0}
{"epoch": 35, "training_loss": 0.69217942237854, "training_acc": 53.0, "val_loss": 0.6918280839920044, "val_acc": 52.0}
{"epoch": 36, "training_loss": 0.6912721753120422, "training_acc": 53.0, "val_loss": 0.6909149098396301, "val_acc": 52.0}
{"epoch": 37, "training_loss": 0.6912438321113586, "training_acc": 53.0, "val_loss": 0.6906346297264099, "val_acc": 52.0}
