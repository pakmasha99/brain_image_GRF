"main_modify.py --pretrained_path /scratch/connectome/dyhan316/VAE_ADHD/barlowtwins/pretrain_results/ABCDbt128a102.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 1 --task ABCD_sex --input_option BT_org --learning_rate 1e-4 --batch_size 16 --weight_decay 1e-2 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 0.7075997972488404, "training_acc": 47.0, "val_loss": 0.6981338572502136, "val_acc": 48.0}
{"epoch": 1, "training_loss": 0.6959770298004151, "training_acc": 47.0, "val_loss": 0.6956627392768859, "val_acc": 44.0}
{"epoch": 2, "training_loss": 0.6926142454147339, "training_acc": 51.0, "val_loss": 0.6946656632423401, "val_acc": 52.0}
{"epoch": 3, "training_loss": 0.6922392225265503, "training_acc": 53.0, "val_loss": 0.6946575164794921, "val_acc": 52.0}
{"epoch": 4, "training_loss": 0.6939038205146789, "training_acc": 53.0, "val_loss": 0.6964593195915222, "val_acc": 52.0}
{"epoch": 5, "training_loss": 0.6942374229431152, "training_acc": 53.0, "val_loss": 0.697122015953064, "val_acc": 52.0}
{"epoch": 6, "training_loss": 0.6923848390579224, "training_acc": 53.0, "val_loss": 0.6953171873092652, "val_acc": 52.0}
{"epoch": 7, "training_loss": 0.6920123386383057, "training_acc": 53.0, "val_loss": 0.6945541167259216, "val_acc": 52.0}
{"epoch": 8, "training_loss": 0.6917027735710144, "training_acc": 53.0, "val_loss": 0.6943696713447571, "val_acc": 52.0}
{"epoch": 9, "training_loss": 0.6922579956054687, "training_acc": 53.0, "val_loss": 0.6944499659538269, "val_acc": 52.0}
{"epoch": 10, "training_loss": 0.691986722946167, "training_acc": 53.0, "val_loss": 0.6946343946456909, "val_acc": 48.0}
{"epoch": 11, "training_loss": 0.6934393739700317, "training_acc": 48.0, "val_loss": 0.6950624871253968, "val_acc": 48.0}
{"epoch": 12, "training_loss": 0.6932173538208007, "training_acc": 47.0, "val_loss": 0.69497225522995, "val_acc": 44.0}
{"epoch": 13, "training_loss": 0.6930899095535278, "training_acc": 53.0, "val_loss": 0.6945228695869445, "val_acc": 52.0}
{"epoch": 14, "training_loss": 0.6923500490188599, "training_acc": 53.0, "val_loss": 0.6943540668487549, "val_acc": 52.0}
{"epoch": 15, "training_loss": 0.6915448260307312, "training_acc": 53.0, "val_loss": 0.6943867778778077, "val_acc": 52.0}
{"epoch": 16, "training_loss": 0.6923657417297363, "training_acc": 53.0, "val_loss": 0.6943247628211975, "val_acc": 52.0}
{"epoch": 17, "training_loss": 0.6916383504867554, "training_acc": 53.0, "val_loss": 0.6944369101524352, "val_acc": 52.0}
{"epoch": 18, "training_loss": 0.69218101978302, "training_acc": 53.0, "val_loss": 0.6943139839172363, "val_acc": 52.0}
{"epoch": 19, "training_loss": 0.6913021826744079, "training_acc": 53.0, "val_loss": 0.6943128204345703, "val_acc": 52.0}
{"epoch": 20, "training_loss": 0.6919263410568237, "training_acc": 53.0, "val_loss": 0.6942911219596862, "val_acc": 52.0}
{"epoch": 21, "training_loss": 0.6920893859863281, "training_acc": 53.0, "val_loss": 0.694444591999054, "val_acc": 52.0}
{"epoch": 22, "training_loss": 0.6922902488708496, "training_acc": 53.0, "val_loss": 0.6942666578292847, "val_acc": 52.0}
{"epoch": 23, "training_loss": 0.6928123259544372, "training_acc": 53.0, "val_loss": 0.6946511507034302, "val_acc": 52.0}
{"epoch": 24, "training_loss": 0.691017587184906, "training_acc": 53.0, "val_loss": 0.6946863150596618, "val_acc": 52.0}
{"epoch": 25, "training_loss": 0.691927547454834, "training_acc": 53.0, "val_loss": 0.694868381023407, "val_acc": 52.0}
{"epoch": 26, "training_loss": 0.6915955805778503, "training_acc": 53.0, "val_loss": 0.6945880627632142, "val_acc": 52.0}
{"epoch": 27, "training_loss": 0.6922577857971192, "training_acc": 53.0, "val_loss": 0.695310823917389, "val_acc": 52.0}
{"epoch": 28, "training_loss": 0.6919182801246643, "training_acc": 53.0, "val_loss": 0.6950238537788391, "val_acc": 52.0}
{"epoch": 29, "training_loss": 0.6911757469177247, "training_acc": 53.0, "val_loss": 0.6958952188491822, "val_acc": 52.0}
{"epoch": 30, "training_loss": 0.6917001724243164, "training_acc": 53.0, "val_loss": 0.6959762954711914, "val_acc": 52.0}
{"epoch": 31, "training_loss": 0.6916239643096924, "training_acc": 53.0, "val_loss": 0.6951350426673889, "val_acc": 52.0}
{"epoch": 32, "training_loss": 0.6909410238265992, "training_acc": 53.0, "val_loss": 0.6942640852928161, "val_acc": 52.0}
{"epoch": 33, "training_loss": 0.6916845035552979, "training_acc": 53.0, "val_loss": 0.6942756581306457, "val_acc": 52.0}
{"epoch": 34, "training_loss": 0.6919536876678467, "training_acc": 53.0, "val_loss": 0.6946788907051087, "val_acc": 40.0}
{"epoch": 35, "training_loss": 0.6931385803222656, "training_acc": 49.0, "val_loss": 0.694822416305542, "val_acc": 44.0}
{"epoch": 36, "training_loss": 0.6923415374755859, "training_acc": 52.0, "val_loss": 0.6941644310951233, "val_acc": 52.0}
{"epoch": 37, "training_loss": 0.6914997291564942, "training_acc": 53.0, "val_loss": 0.6941691946983337, "val_acc": 52.0}
{"epoch": 38, "training_loss": 0.693071494102478, "training_acc": 53.0, "val_loss": 0.6950681161880493, "val_acc": 52.0}
{"epoch": 39, "training_loss": 0.6928255987167359, "training_acc": 53.0, "val_loss": 0.6943254089355468, "val_acc": 52.0}
{"epoch": 40, "training_loss": 0.6911694240570069, "training_acc": 53.0, "val_loss": 0.6943946003913879, "val_acc": 52.0}
{"epoch": 41, "training_loss": 0.6927213144302368, "training_acc": 53.0, "val_loss": 0.6955461859703064, "val_acc": 52.0}
{"epoch": 42, "training_loss": 0.6922434520721436, "training_acc": 53.0, "val_loss": 0.694754445552826, "val_acc": 52.0}
{"epoch": 43, "training_loss": 0.6915736484527588, "training_acc": 53.0, "val_loss": 0.6950153160095215, "val_acc": 52.0}
{"epoch": 44, "training_loss": 0.6918177652359009, "training_acc": 53.0, "val_loss": 0.6946286725997924, "val_acc": 52.0}
{"epoch": 45, "training_loss": 0.6911490678787231, "training_acc": 53.0, "val_loss": 0.694341824054718, "val_acc": 52.0}
{"epoch": 46, "training_loss": 0.6903852558135987, "training_acc": 53.0, "val_loss": 0.6941001915931702, "val_acc": 52.0}
{"epoch": 47, "training_loss": 0.6915085411071777, "training_acc": 53.0, "val_loss": 0.6945141720771789, "val_acc": 48.0}
{"epoch": 48, "training_loss": 0.6921024417877197, "training_acc": 57.0, "val_loss": 0.6949288654327392, "val_acc": 32.0}
{"epoch": 49, "training_loss": 0.6933375334739685, "training_acc": 51.0, "val_loss": 0.6941015362739563, "val_acc": 52.0}
{"epoch": 50, "training_loss": 0.691642050743103, "training_acc": 53.0, "val_loss": 0.694058952331543, "val_acc": 52.0}
{"epoch": 51, "training_loss": 0.6908500981330872, "training_acc": 53.0, "val_loss": 0.6940737009048462, "val_acc": 52.0}
{"epoch": 52, "training_loss": 0.6909478950500488, "training_acc": 53.0, "val_loss": 0.6941256403923035, "val_acc": 52.0}
{"epoch": 53, "training_loss": 0.6904973196983337, "training_acc": 53.0, "val_loss": 0.6945095705986023, "val_acc": 52.0}
{"epoch": 54, "training_loss": 0.6911702394485474, "training_acc": 53.0, "val_loss": 0.6945820116996765, "val_acc": 52.0}
{"epoch": 55, "training_loss": 0.6908082914352417, "training_acc": 53.0, "val_loss": 0.6944102048873901, "val_acc": 52.0}
{"epoch": 56, "training_loss": 0.6907634329795838, "training_acc": 53.0, "val_loss": 0.6940271520614624, "val_acc": 52.0}
{"epoch": 57, "training_loss": 0.6909638261795044, "training_acc": 53.0, "val_loss": 0.6940531849861145, "val_acc": 52.0}
{"epoch": 58, "training_loss": 0.6915172576904297, "training_acc": 53.0, "val_loss": 0.6940584325790405, "val_acc": 52.0}
{"epoch": 59, "training_loss": 0.6911258172988891, "training_acc": 53.0, "val_loss": 0.6940051245689393, "val_acc": 52.0}
{"epoch": 60, "training_loss": 0.6912368535995483, "training_acc": 53.0, "val_loss": 0.6939986824989319, "val_acc": 52.0}
{"epoch": 61, "training_loss": 0.6908838987350464, "training_acc": 53.0, "val_loss": 0.6943659806251525, "val_acc": 52.0}
{"epoch": 62, "training_loss": 0.6908823347091675, "training_acc": 53.0, "val_loss": 0.694201431274414, "val_acc": 52.0}
{"epoch": 63, "training_loss": 0.6904950189590454, "training_acc": 53.0, "val_loss": 0.694453592300415, "val_acc": 52.0}
{"epoch": 64, "training_loss": 0.6904323005676269, "training_acc": 53.0, "val_loss": 0.6947136783599853, "val_acc": 52.0}
{"epoch": 65, "training_loss": 0.6917080473899841, "training_acc": 53.0, "val_loss": 0.6944159770011902, "val_acc": 52.0}
{"epoch": 66, "training_loss": 0.6911907696723938, "training_acc": 53.0, "val_loss": 0.6941689014434814, "val_acc": 52.0}
{"epoch": 67, "training_loss": 0.6904583883285522, "training_acc": 53.0, "val_loss": 0.6941342186927796, "val_acc": 52.0}
{"epoch": 68, "training_loss": 0.6908972215652466, "training_acc": 53.0, "val_loss": 0.6940007400512695, "val_acc": 52.0}
{"epoch": 69, "training_loss": 0.6903905630111694, "training_acc": 53.0, "val_loss": 0.6939505887031555, "val_acc": 52.0}
{"epoch": 70, "training_loss": 0.6904676556587219, "training_acc": 53.0, "val_loss": 0.6939437079429627, "val_acc": 52.0}
{"epoch": 71, "training_loss": 0.6919302344322205, "training_acc": 53.0, "val_loss": 0.694187273979187, "val_acc": 52.0}
{"epoch": 72, "training_loss": 0.6907455778121948, "training_acc": 53.0, "val_loss": 0.69403151512146, "val_acc": 52.0}
{"epoch": 73, "training_loss": 0.6907731914520263, "training_acc": 53.0, "val_loss": 0.6939921808242798, "val_acc": 52.0}
{"epoch": 74, "training_loss": 0.6914488220214844, "training_acc": 53.0, "val_loss": 0.6939957857131958, "val_acc": 52.0}
{"epoch": 75, "training_loss": 0.6911077642440796, "training_acc": 53.0, "val_loss": 0.6940055966377259, "val_acc": 52.0}
{"epoch": 76, "training_loss": 0.6911035251617431, "training_acc": 53.0, "val_loss": 0.6939342570304871, "val_acc": 52.0}
{"epoch": 77, "training_loss": 0.6903544425964355, "training_acc": 53.0, "val_loss": 0.6938823580741882, "val_acc": 52.0}
{"epoch": 78, "training_loss": 0.6904891014099122, "training_acc": 53.0, "val_loss": 0.694315721988678, "val_acc": 52.0}
{"epoch": 79, "training_loss": 0.6908894228935242, "training_acc": 53.0, "val_loss": 0.6948779630661011, "val_acc": 52.0}
{"epoch": 80, "training_loss": 0.690565357208252, "training_acc": 53.0, "val_loss": 0.6942209196090698, "val_acc": 52.0}
{"epoch": 81, "training_loss": 0.6913246965408325, "training_acc": 53.0, "val_loss": 0.6938512110710144, "val_acc": 52.0}
{"epoch": 82, "training_loss": 0.6904415988922119, "training_acc": 53.0, "val_loss": 0.6938830280303955, "val_acc": 52.0}
{"epoch": 83, "training_loss": 0.6899014949798584, "training_acc": 53.0, "val_loss": 0.6940288519859314, "val_acc": 52.0}
{"epoch": 84, "training_loss": 0.6902556681632995, "training_acc": 53.0, "val_loss": 0.6939952945709229, "val_acc": 52.0}
{"epoch": 85, "training_loss": 0.690373854637146, "training_acc": 53.0, "val_loss": 0.6938969779014588, "val_acc": 52.0}
{"epoch": 86, "training_loss": 0.6914142894744874, "training_acc": 53.0, "val_loss": 0.6938203120231629, "val_acc": 52.0}
{"epoch": 87, "training_loss": 0.6903410673141479, "training_acc": 53.0, "val_loss": 0.693884732723236, "val_acc": 52.0}
{"epoch": 88, "training_loss": 0.6910881304740906, "training_acc": 53.0, "val_loss": 0.6939014673233033, "val_acc": 52.0}
{"epoch": 89, "training_loss": 0.6906548118591309, "training_acc": 53.0, "val_loss": 0.6940871143341064, "val_acc": 52.0}
{"epoch": 90, "training_loss": 0.6908625721931457, "training_acc": 53.0, "val_loss": 0.6948895239830017, "val_acc": 52.0}
{"epoch": 91, "training_loss": 0.6907894325256347, "training_acc": 53.0, "val_loss": 0.6950458979606629, "val_acc": 52.0}
{"epoch": 92, "training_loss": 0.6904454517364502, "training_acc": 53.0, "val_loss": 0.6943882846832276, "val_acc": 52.0}
{"epoch": 93, "training_loss": 0.6924439811706543, "training_acc": 53.0, "val_loss": 0.6938773608207702, "val_acc": 52.0}
{"epoch": 94, "training_loss": 0.6950482654571534, "training_acc": 45.0, "val_loss": 0.6945827412605285, "val_acc": 40.0}
{"epoch": 95, "training_loss": 0.6922639322280884, "training_acc": 56.0, "val_loss": 0.6938418912887573, "val_acc": 52.0}
{"epoch": 96, "training_loss": 0.6905106019973755, "training_acc": 53.0, "val_loss": 0.6938937020301819, "val_acc": 52.0}
{"epoch": 97, "training_loss": 0.690399284362793, "training_acc": 53.0, "val_loss": 0.6937420201301575, "val_acc": 52.0}
{"epoch": 98, "training_loss": 0.69041512966156, "training_acc": 53.0, "val_loss": 0.6937392783164978, "val_acc": 52.0}
{"epoch": 99, "training_loss": 0.6904929518699646, "training_acc": 53.0, "val_loss": 0.693823869228363, "val_acc": 52.0}
