"main_modify.py --pretrained_path /scratch/connectome/dyhan316/VAE_ADHD/barlowtwins/pretrain_results/ABCDbt128a102.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option BT_org --learning_rate 1e-4 --batch_size 16 --weight_decay 1e-2 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 0.6934922790527344, "training_acc": 47.0, "val_loss": 0.6932215929031372, "val_acc": 52.0}
{"epoch": 1, "training_loss": 0.6914114427566528, "training_acc": 53.0, "val_loss": 0.693128502368927, "val_acc": 52.0}
{"epoch": 2, "training_loss": 0.6940147829055786, "training_acc": 53.0, "val_loss": 0.6940051007270813, "val_acc": 52.0}
{"epoch": 3, "training_loss": 0.6928563141822814, "training_acc": 53.0, "val_loss": 0.6940918445587159, "val_acc": 52.0}
{"epoch": 4, "training_loss": 0.6910224151611328, "training_acc": 53.0, "val_loss": 0.6931170773506165, "val_acc": 52.0}
{"epoch": 5, "training_loss": 0.6905392074584961, "training_acc": 53.0, "val_loss": 0.6929719114303589, "val_acc": 52.0}
{"epoch": 6, "training_loss": 0.6919086289405822, "training_acc": 53.0, "val_loss": 0.6930894970893859, "val_acc": 52.0}
{"epoch": 7, "training_loss": 0.6921266698837281, "training_acc": 53.0, "val_loss": 0.6929979848861695, "val_acc": 52.0}
{"epoch": 8, "training_loss": 0.6924327182769775, "training_acc": 53.0, "val_loss": 0.6929624605178833, "val_acc": 52.0}
{"epoch": 9, "training_loss": 0.6921112656593322, "training_acc": 53.0, "val_loss": 0.6933526515960693, "val_acc": 56.0}
{"epoch": 10, "training_loss": 0.6920046710968017, "training_acc": 53.0, "val_loss": 0.6929850316047669, "val_acc": 52.0}
{"epoch": 11, "training_loss": 0.6917666387557984, "training_acc": 53.0, "val_loss": 0.692916259765625, "val_acc": 52.0}
{"epoch": 12, "training_loss": 0.6910978507995605, "training_acc": 53.0, "val_loss": 0.6929270601272584, "val_acc": 52.0}
{"epoch": 13, "training_loss": 0.6908312773704529, "training_acc": 53.0, "val_loss": 0.693279459476471, "val_acc": 52.0}
{"epoch": 14, "training_loss": 0.691942458152771, "training_acc": 53.0, "val_loss": 0.6940904879570007, "val_acc": 52.0}
{"epoch": 15, "training_loss": 0.6908598041534424, "training_acc": 53.0, "val_loss": 0.6937832808494568, "val_acc": 52.0}
{"epoch": 16, "training_loss": 0.6911066579818725, "training_acc": 53.0, "val_loss": 0.6935016703605652, "val_acc": 52.0}
{"epoch": 17, "training_loss": 0.6922690272331238, "training_acc": 53.0, "val_loss": 0.6936960172653198, "val_acc": 52.0}
{"epoch": 18, "training_loss": 0.691833610534668, "training_acc": 53.0, "val_loss": 0.6935489535331726, "val_acc": 52.0}
{"epoch": 19, "training_loss": 0.6906816244125367, "training_acc": 53.0, "val_loss": 0.6930769920349121, "val_acc": 52.0}
{"epoch": 20, "training_loss": 0.6924658608436585, "training_acc": 53.0, "val_loss": 0.6928752470016479, "val_acc": 52.0}
{"epoch": 21, "training_loss": 0.6920121622085571, "training_acc": 53.0, "val_loss": 0.693462827205658, "val_acc": 52.0}
{"epoch": 22, "training_loss": 0.6910411882400512, "training_acc": 53.0, "val_loss": 0.6941408848762513, "val_acc": 52.0}
{"epoch": 23, "training_loss": 0.69407075881958, "training_acc": 53.0, "val_loss": 0.6960847568511963, "val_acc": 52.0}
{"epoch": 24, "training_loss": 0.692959520816803, "training_acc": 53.0, "val_loss": 0.6954568266868592, "val_acc": 52.0}
{"epoch": 25, "training_loss": 0.6923614621162415, "training_acc": 53.0, "val_loss": 0.6942654705047607, "val_acc": 52.0}
{"epoch": 26, "training_loss": 0.691323766708374, "training_acc": 53.0, "val_loss": 0.6935856223106385, "val_acc": 52.0}
{"epoch": 27, "training_loss": 0.6927076148986816, "training_acc": 53.0, "val_loss": 0.6938576054573059, "val_acc": 52.0}
{"epoch": 28, "training_loss": 0.6915782475471497, "training_acc": 53.0, "val_loss": 0.6939156413078308, "val_acc": 52.0}
{"epoch": 29, "training_loss": 0.6912713384628296, "training_acc": 53.0, "val_loss": 0.6937090277671814, "val_acc": 52.0}
{"epoch": 30, "training_loss": 0.6916494011878968, "training_acc": 53.0, "val_loss": 0.6943139696121216, "val_acc": 52.0}
{"epoch": 31, "training_loss": 0.6915726613998413, "training_acc": 53.0, "val_loss": 0.6939838862419129, "val_acc": 52.0}
{"epoch": 32, "training_loss": 0.6917501401901245, "training_acc": 53.0, "val_loss": 0.6943102359771729, "val_acc": 52.0}
{"epoch": 33, "training_loss": 0.6917693209648133, "training_acc": 53.0, "val_loss": 0.6947625017166138, "val_acc": 52.0}
{"epoch": 34, "training_loss": 0.6919881582260132, "training_acc": 53.0, "val_loss": 0.6936606192588806, "val_acc": 52.0}
{"epoch": 35, "training_loss": 0.6912077403068543, "training_acc": 53.0, "val_loss": 0.692863962650299, "val_acc": 52.0}
{"epoch": 36, "training_loss": 0.6905081677436828, "training_acc": 53.0, "val_loss": 0.6927943921089172, "val_acc": 52.0}
{"epoch": 37, "training_loss": 0.691388897895813, "training_acc": 53.0, "val_loss": 0.6928081560134888, "val_acc": 52.0}
{"epoch": 38, "training_loss": 0.691489291191101, "training_acc": 53.0, "val_loss": 0.693018548488617, "val_acc": 52.0}
{"epoch": 39, "training_loss": 0.6923773860931397, "training_acc": 52.0, "val_loss": 0.6931606411933899, "val_acc": 56.0}
{"epoch": 40, "training_loss": 0.6916076946258545, "training_acc": 53.0, "val_loss": 0.6929021573066712, "val_acc": 52.0}
{"epoch": 41, "training_loss": 0.6911300849914551, "training_acc": 53.0, "val_loss": 0.6927934789657593, "val_acc": 52.0}
{"epoch": 42, "training_loss": 0.6906339025497437, "training_acc": 53.0, "val_loss": 0.693023316860199, "val_acc": 52.0}
{"epoch": 43, "training_loss": 0.6908489274978638, "training_acc": 53.0, "val_loss": 0.6934117436408996, "val_acc": 52.0}
{"epoch": 44, "training_loss": 0.6908636736869812, "training_acc": 53.0, "val_loss": 0.6935016560554504, "val_acc": 52.0}
{"epoch": 45, "training_loss": 0.6923302364349365, "training_acc": 53.0, "val_loss": 0.6947013854980468, "val_acc": 52.0}
{"epoch": 46, "training_loss": 0.6914494061470031, "training_acc": 53.0, "val_loss": 0.6943996834754944, "val_acc": 52.0}
{"epoch": 47, "training_loss": 0.691386137008667, "training_acc": 53.0, "val_loss": 0.6932005763053894, "val_acc": 52.0}
{"epoch": 48, "training_loss": 0.6902668142318725, "training_acc": 53.0, "val_loss": 0.6929176807403564, "val_acc": 52.0}
{"epoch": 49, "training_loss": 0.6909375143051147, "training_acc": 53.0, "val_loss": 0.6927275848388672, "val_acc": 52.0}
{"epoch": 50, "training_loss": 0.69085768699646, "training_acc": 53.0, "val_loss": 0.6927139401435852, "val_acc": 52.0}
{"epoch": 51, "training_loss": 0.6908511424064636, "training_acc": 53.0, "val_loss": 0.692717833518982, "val_acc": 52.0}
{"epoch": 52, "training_loss": 0.6907569980621338, "training_acc": 53.0, "val_loss": 0.6927108073234558, "val_acc": 52.0}
{"epoch": 53, "training_loss": 0.6904722499847412, "training_acc": 53.0, "val_loss": 0.6927833890914917, "val_acc": 52.0}
{"epoch": 54, "training_loss": 0.6913767743110657, "training_acc": 53.0, "val_loss": 0.6927088522911071, "val_acc": 52.0}
{"epoch": 55, "training_loss": 0.6906060028076172, "training_acc": 53.0, "val_loss": 0.6931736707687378, "val_acc": 52.0}
{"epoch": 56, "training_loss": 0.6917020630836487, "training_acc": 53.0, "val_loss": 0.6934755373001099, "val_acc": 52.0}
{"epoch": 57, "training_loss": 0.6921724271774292, "training_acc": 53.0, "val_loss": 0.6938788723945618, "val_acc": 52.0}
{"epoch": 58, "training_loss": 0.690818326473236, "training_acc": 53.0, "val_loss": 0.6932549929618835, "val_acc": 52.0}
{"epoch": 59, "training_loss": 0.6908492088317871, "training_acc": 53.0, "val_loss": 0.6929249024391174, "val_acc": 52.0}
{"epoch": 60, "training_loss": 0.6905834007263184, "training_acc": 53.0, "val_loss": 0.6931316828727723, "val_acc": 52.0}
{"epoch": 61, "training_loss": 0.6918768215179444, "training_acc": 53.0, "val_loss": 0.6926915860176086, "val_acc": 52.0}
{"epoch": 62, "training_loss": 0.6911662721633911, "training_acc": 53.0, "val_loss": 0.6926476526260376, "val_acc": 52.0}
{"epoch": 63, "training_loss": 0.6909233689308166, "training_acc": 53.0, "val_loss": 0.6926614975929261, "val_acc": 52.0}
{"epoch": 64, "training_loss": 0.6907070589065551, "training_acc": 53.0, "val_loss": 0.6926896357536316, "val_acc": 52.0}
{"epoch": 65, "training_loss": 0.6902210545539856, "training_acc": 53.0, "val_loss": 0.6928255558013916, "val_acc": 52.0}
{"epoch": 66, "training_loss": 0.690341567993164, "training_acc": 53.0, "val_loss": 0.693141691684723, "val_acc": 52.0}
{"epoch": 67, "training_loss": 0.6935300731658935, "training_acc": 53.0, "val_loss": 0.6947087621688843, "val_acc": 52.0}
{"epoch": 68, "training_loss": 0.6920182037353516, "training_acc": 53.0, "val_loss": 0.6941506433486938, "val_acc": 52.0}
{"epoch": 69, "training_loss": 0.6904256963729858, "training_acc": 53.0, "val_loss": 0.6929799771308899, "val_acc": 52.0}
{"epoch": 70, "training_loss": 0.6898700833320618, "training_acc": 53.0, "val_loss": 0.6926400804519653, "val_acc": 52.0}
{"epoch": 71, "training_loss": 0.689135308265686, "training_acc": 53.0, "val_loss": 0.6928956270217895, "val_acc": 52.0}
{"epoch": 72, "training_loss": 0.6945777201652527, "training_acc": 44.0, "val_loss": 0.6939639973640442, "val_acc": 48.0}
{"epoch": 73, "training_loss": 0.6921139335632325, "training_acc": 55.0, "val_loss": 0.6930838394165039, "val_acc": 52.0}
{"epoch": 74, "training_loss": 0.6916962122917175, "training_acc": 53.0, "val_loss": 0.6926607871055603, "val_acc": 52.0}
{"epoch": 75, "training_loss": 0.6901294875144959, "training_acc": 53.0, "val_loss": 0.6932952713966369, "val_acc": 52.0}
{"epoch": 76, "training_loss": 0.690681164264679, "training_acc": 53.0, "val_loss": 0.6930517292022705, "val_acc": 52.0}
{"epoch": 77, "training_loss": 0.6907876920700073, "training_acc": 53.0, "val_loss": 0.6928120541572571, "val_acc": 52.0}
{"epoch": 78, "training_loss": 0.6904208135604858, "training_acc": 53.0, "val_loss": 0.6925873231887817, "val_acc": 52.0}
{"epoch": 79, "training_loss": 0.6905576181411743, "training_acc": 53.0, "val_loss": 0.6926954388618469, "val_acc": 52.0}
{"epoch": 80, "training_loss": 0.6908401346206665, "training_acc": 53.0, "val_loss": 0.6929266023635864, "val_acc": 52.0}
{"epoch": 81, "training_loss": 0.6932471680641175, "training_acc": 47.0, "val_loss": 0.693523018360138, "val_acc": 44.0}
{"epoch": 82, "training_loss": 0.6926153659820556, "training_acc": 50.0, "val_loss": 0.6926859784126281, "val_acc": 52.0}
{"epoch": 83, "training_loss": 0.6924105143547058, "training_acc": 53.0, "val_loss": 0.6925989961624146, "val_acc": 52.0}
{"epoch": 84, "training_loss": 0.6903057479858399, "training_acc": 53.0, "val_loss": 0.6926432967185974, "val_acc": 52.0}
{"epoch": 85, "training_loss": 0.6905680561065674, "training_acc": 53.0, "val_loss": 0.692573471069336, "val_acc": 52.0}
{"epoch": 86, "training_loss": 0.690632836818695, "training_acc": 53.0, "val_loss": 0.6925507092475891, "val_acc": 52.0}
{"epoch": 87, "training_loss": 0.6900919651985169, "training_acc": 53.0, "val_loss": 0.6925656294822693, "val_acc": 52.0}
{"epoch": 88, "training_loss": 0.691534833908081, "training_acc": 53.0, "val_loss": 0.692656774520874, "val_acc": 52.0}
{"epoch": 89, "training_loss": 0.6903944206237793, "training_acc": 53.0, "val_loss": 0.6925146079063416, "val_acc": 52.0}
{"epoch": 90, "training_loss": 0.6906540083885193, "training_acc": 53.0, "val_loss": 0.6925066900253296, "val_acc": 52.0}
{"epoch": 91, "training_loss": 0.6904362511634826, "training_acc": 53.0, "val_loss": 0.6925458240509034, "val_acc": 52.0}
{"epoch": 92, "training_loss": 0.6901194715499878, "training_acc": 53.0, "val_loss": 0.6926948285102844, "val_acc": 52.0}
{"epoch": 93, "training_loss": 0.6902959251403809, "training_acc": 53.0, "val_loss": 0.692846155166626, "val_acc": 52.0}
{"epoch": 94, "training_loss": 0.6905952143669128, "training_acc": 53.0, "val_loss": 0.6929325437545777, "val_acc": 52.0}
{"epoch": 95, "training_loss": 0.6907191753387452, "training_acc": 53.0, "val_loss": 0.6927946066856384, "val_acc": 52.0}
{"epoch": 96, "training_loss": 0.6903922009468079, "training_acc": 53.0, "val_loss": 0.6930470275878906, "val_acc": 52.0}
{"epoch": 97, "training_loss": 0.6910588264465332, "training_acc": 53.0, "val_loss": 0.6926006650924683, "val_acc": 52.0}
{"epoch": 98, "training_loss": 0.6905261015892029, "training_acc": 53.0, "val_loss": 0.6926733374595642, "val_acc": 52.0}
{"epoch": 99, "training_loss": 0.6907917070388794, "training_acc": 53.0, "val_loss": 0.692482213973999, "val_acc": 52.0}
