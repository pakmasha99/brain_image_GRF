"main_modify.py --pretrained_path /scratch/connectome/dyhan316/VAE_ADHD/barlowtwins/pretrain_results/ABCDbt128a102.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option BT_org --learning_rate 1e-4 --batch_size 16 --weight_decay 1e-2 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 0.6972092318534852, "training_acc": 37.0, "val_loss": 0.6910844540596008, "val_acc": 60.0}
{"epoch": 1, "training_loss": 0.6933633089065552, "training_acc": 53.0, "val_loss": 0.6907657480239868, "val_acc": 52.0}
{"epoch": 2, "training_loss": 0.6931768751144409, "training_acc": 53.0, "val_loss": 0.6905144691467285, "val_acc": 52.0}
{"epoch": 3, "training_loss": 0.6920291566848755, "training_acc": 53.0, "val_loss": 0.6907413172721862, "val_acc": 52.0}
{"epoch": 4, "training_loss": 0.6919467639923096, "training_acc": 53.0, "val_loss": 0.691061794757843, "val_acc": 52.0}
{"epoch": 5, "training_loss": 0.6917836189270019, "training_acc": 53.0, "val_loss": 0.6911096382141113, "val_acc": 52.0}
{"epoch": 6, "training_loss": 0.6915954232215882, "training_acc": 53.0, "val_loss": 0.691578299999237, "val_acc": 52.0}
{"epoch": 7, "training_loss": 0.6920032978057862, "training_acc": 53.0, "val_loss": 0.692093346118927, "val_acc": 52.0}
{"epoch": 8, "training_loss": 0.6920873713493347, "training_acc": 53.0, "val_loss": 0.6915711975097656, "val_acc": 52.0}
{"epoch": 9, "training_loss": 0.6926965546607972, "training_acc": 53.0, "val_loss": 0.692020390033722, "val_acc": 52.0}
{"epoch": 10, "training_loss": 0.6914381408691406, "training_acc": 53.0, "val_loss": 0.6911702632904053, "val_acc": 52.0}
{"epoch": 11, "training_loss": 0.6912593841552734, "training_acc": 53.0, "val_loss": 0.6907887578010559, "val_acc": 52.0}
{"epoch": 12, "training_loss": 0.6919176459312439, "training_acc": 53.0, "val_loss": 0.6905302405357361, "val_acc": 52.0}
{"epoch": 13, "training_loss": 0.694454174041748, "training_acc": 53.0, "val_loss": 0.6907982563972473, "val_acc": 52.0}
{"epoch": 14, "training_loss": 0.6917250776290893, "training_acc": 53.0, "val_loss": 0.6905178427696228, "val_acc": 52.0}
{"epoch": 15, "training_loss": 0.6916556310653686, "training_acc": 53.0, "val_loss": 0.6905095720291138, "val_acc": 52.0}
{"epoch": 16, "training_loss": 0.6927238082885743, "training_acc": 53.0, "val_loss": 0.6908952426910401, "val_acc": 52.0}
{"epoch": 17, "training_loss": 0.691862223148346, "training_acc": 53.0, "val_loss": 0.6910904097557068, "val_acc": 52.0}
{"epoch": 18, "training_loss": 0.6916198992729187, "training_acc": 53.0, "val_loss": 0.6909070324897766, "val_acc": 52.0}
{"epoch": 19, "training_loss": 0.6912646198272705, "training_acc": 53.0, "val_loss": 0.691033833026886, "val_acc": 52.0}
{"epoch": 20, "training_loss": 0.6913413882255555, "training_acc": 53.0, "val_loss": 0.6910053634643555, "val_acc": 52.0}
{"epoch": 21, "training_loss": 0.6912530708312988, "training_acc": 53.0, "val_loss": 0.6909746479988098, "val_acc": 52.0}
{"epoch": 22, "training_loss": 0.6913126993179322, "training_acc": 53.0, "val_loss": 0.6918434500694275, "val_acc": 52.0}
{"epoch": 23, "training_loss": 0.6940027737617492, "training_acc": 53.0, "val_loss": 0.692326979637146, "val_acc": 52.0}
{"epoch": 24, "training_loss": 0.6921551084518432, "training_acc": 53.0, "val_loss": 0.6908441138267517, "val_acc": 52.0}
{"epoch": 25, "training_loss": 0.691561622619629, "training_acc": 53.0, "val_loss": 0.6905013632774353, "val_acc": 52.0}
{"epoch": 26, "training_loss": 0.6919569253921509, "training_acc": 53.0, "val_loss": 0.6905384850502014, "val_acc": 52.0}
{"epoch": 27, "training_loss": 0.6923098421096802, "training_acc": 53.0, "val_loss": 0.6905405998229981, "val_acc": 52.0}
{"epoch": 28, "training_loss": 0.691226954460144, "training_acc": 53.0, "val_loss": 0.6905459141731263, "val_acc": 52.0}
{"epoch": 29, "training_loss": 0.6909152889251708, "training_acc": 53.0, "val_loss": 0.6910626697540283, "val_acc": 52.0}
{"epoch": 30, "training_loss": 0.6926101732254029, "training_acc": 53.0, "val_loss": 0.6921597266197205, "val_acc": 52.0}
{"epoch": 31, "training_loss": 0.6914344692230224, "training_acc": 53.0, "val_loss": 0.69166020154953, "val_acc": 52.0}
{"epoch": 32, "training_loss": 0.6918973731994629, "training_acc": 53.0, "val_loss": 0.69164226770401, "val_acc": 52.0}
{"epoch": 33, "training_loss": 0.6930004858970642, "training_acc": 53.0, "val_loss": 0.6906536173820496, "val_acc": 52.0}
{"epoch": 34, "training_loss": 0.6912471055984497, "training_acc": 53.0, "val_loss": 0.6905201268196106, "val_acc": 52.0}
{"epoch": 35, "training_loss": 0.6916382312774658, "training_acc": 53.0, "val_loss": 0.6905912971496582, "val_acc": 52.0}
{"epoch": 36, "training_loss": 0.6942264270782471, "training_acc": 57.0, "val_loss": 0.6913875913619996, "val_acc": 56.0}
{"epoch": 37, "training_loss": 0.693014748096466, "training_acc": 49.0, "val_loss": 0.6907456040382385, "val_acc": 52.0}
{"epoch": 38, "training_loss": 0.6918834400177002, "training_acc": 53.0, "val_loss": 0.6905631709098816, "val_acc": 52.0}
{"epoch": 39, "training_loss": 0.6916649127006531, "training_acc": 53.0, "val_loss": 0.6905110645294189, "val_acc": 52.0}
{"epoch": 40, "training_loss": 0.6927334976196289, "training_acc": 53.0, "val_loss": 0.6905701041221619, "val_acc": 52.0}
{"epoch": 41, "training_loss": 0.6911283493041992, "training_acc": 53.0, "val_loss": 0.6905000281333923, "val_acc": 52.0}
{"epoch": 42, "training_loss": 0.6914089322090149, "training_acc": 53.0, "val_loss": 0.6904926252365112, "val_acc": 52.0}
{"epoch": 43, "training_loss": 0.693406662940979, "training_acc": 53.0, "val_loss": 0.690785038471222, "val_acc": 52.0}
{"epoch": 44, "training_loss": 0.6910318851470947, "training_acc": 53.0, "val_loss": 0.6905305218696595, "val_acc": 52.0}
{"epoch": 45, "training_loss": 0.6917065095901489, "training_acc": 53.0, "val_loss": 0.6905016732215882, "val_acc": 52.0}
{"epoch": 46, "training_loss": 0.6921739053726196, "training_acc": 53.0, "val_loss": 0.6907414269447326, "val_acc": 52.0}
{"epoch": 47, "training_loss": 0.6905843877792358, "training_acc": 53.0, "val_loss": 0.6909242939949035, "val_acc": 52.0}
{"epoch": 48, "training_loss": 0.6928678798675537, "training_acc": 53.0, "val_loss": 0.6914947819709778, "val_acc": 52.0}
{"epoch": 49, "training_loss": 0.6912824845314026, "training_acc": 53.0, "val_loss": 0.690593147277832, "val_acc": 52.0}
{"epoch": 50, "training_loss": 0.6905932879447937, "training_acc": 53.0, "val_loss": 0.6905019116401673, "val_acc": 52.0}
{"epoch": 51, "training_loss": 0.6911261987686157, "training_acc": 53.0, "val_loss": 0.6906309795379638, "val_acc": 52.0}
{"epoch": 52, "training_loss": 0.691906394958496, "training_acc": 53.0, "val_loss": 0.6905114698410034, "val_acc": 52.0}
{"epoch": 53, "training_loss": 0.6907480239868165, "training_acc": 53.0, "val_loss": 0.6905188441276551, "val_acc": 52.0}
{"epoch": 54, "training_loss": 0.6912928295135498, "training_acc": 53.0, "val_loss": 0.6905015182495117, "val_acc": 52.0}
{"epoch": 55, "training_loss": 0.6907646036148072, "training_acc": 53.0, "val_loss": 0.6905971121788025, "val_acc": 52.0}
{"epoch": 56, "training_loss": 0.6913002467155457, "training_acc": 53.0, "val_loss": 0.6905130839347839, "val_acc": 52.0}
{"epoch": 57, "training_loss": 0.691165747642517, "training_acc": 53.0, "val_loss": 0.6905091166496277, "val_acc": 52.0}
{"epoch": 58, "training_loss": 0.6921008110046387, "training_acc": 53.0, "val_loss": 0.690535020828247, "val_acc": 52.0}
{"epoch": 59, "training_loss": 0.6923086643218994, "training_acc": 53.0, "val_loss": 0.6905022811889648, "val_acc": 52.0}
{"epoch": 60, "training_loss": 0.6925996613502502, "training_acc": 53.0, "val_loss": 0.6907759571075439, "val_acc": 52.0}
{"epoch": 61, "training_loss": 0.6918293404579162, "training_acc": 53.0, "val_loss": 0.6908214235305786, "val_acc": 52.0}
