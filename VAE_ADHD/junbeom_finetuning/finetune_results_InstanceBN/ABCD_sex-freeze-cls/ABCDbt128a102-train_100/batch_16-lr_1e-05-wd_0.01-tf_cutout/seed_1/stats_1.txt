"main_modify.py --pretrained_path /scratch/connectome/dyhan316/VAE_ADHD/barlowtwins/pretrain_results/ABCDbt128a102.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 1 --task ABCD_sex --input_option BT_org --learning_rate 1e-5 --batch_size 16 --weight_decay 1e-2 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 0.692249870300293, "training_acc": 53.0, "val_loss": 0.691057550907135, "val_acc": 52.0}
{"epoch": 1, "training_loss": 0.6919110107421875, "training_acc": 53.0, "val_loss": 0.6910571599006653, "val_acc": 52.0}
{"epoch": 2, "training_loss": 0.6923295688629151, "training_acc": 53.0, "val_loss": 0.6910570812225342, "val_acc": 52.0}
{"epoch": 3, "training_loss": 0.692156834602356, "training_acc": 53.0, "val_loss": 0.6910585689544678, "val_acc": 52.0}
{"epoch": 4, "training_loss": 0.6924388837814331, "training_acc": 53.0, "val_loss": 0.6910604500770569, "val_acc": 52.0}
{"epoch": 5, "training_loss": 0.6919996356964111, "training_acc": 53.0, "val_loss": 0.6910567021369934, "val_acc": 52.0}
{"epoch": 6, "training_loss": 0.6920330786705017, "training_acc": 53.0, "val_loss": 0.6910567355155944, "val_acc": 52.0}
{"epoch": 7, "training_loss": 0.6923483514785767, "training_acc": 53.0, "val_loss": 0.6910570931434631, "val_acc": 52.0}
{"epoch": 8, "training_loss": 0.6926614689826965, "training_acc": 53.0, "val_loss": 0.6910637378692627, "val_acc": 52.0}
{"epoch": 9, "training_loss": 0.6916236901283264, "training_acc": 53.0, "val_loss": 0.6910778713226319, "val_acc": 52.0}
{"epoch": 10, "training_loss": 0.6922856187820434, "training_acc": 53.0, "val_loss": 0.6910728478431701, "val_acc": 52.0}
{"epoch": 11, "training_loss": 0.6917955780029297, "training_acc": 53.0, "val_loss": 0.6910966300964355, "val_acc": 52.0}
{"epoch": 12, "training_loss": 0.6923397469520569, "training_acc": 53.0, "val_loss": 0.6910938239097595, "val_acc": 52.0}
{"epoch": 13, "training_loss": 0.6922273826599121, "training_acc": 53.0, "val_loss": 0.6911388325691223, "val_acc": 52.0}
{"epoch": 14, "training_loss": 0.6923303484916687, "training_acc": 53.0, "val_loss": 0.6911637187004089, "val_acc": 52.0}
{"epoch": 15, "training_loss": 0.6920334720611572, "training_acc": 53.0, "val_loss": 0.6912046575546265, "val_acc": 52.0}
{"epoch": 16, "training_loss": 0.6920689105987549, "training_acc": 53.0, "val_loss": 0.6912275576591491, "val_acc": 52.0}
{"epoch": 17, "training_loss": 0.6922484755516052, "training_acc": 53.0, "val_loss": 0.6912740755081177, "val_acc": 52.0}
{"epoch": 18, "training_loss": 0.6920216679573059, "training_acc": 53.0, "val_loss": 0.6912953591346741, "val_acc": 52.0}
{"epoch": 19, "training_loss": 0.6915479969978332, "training_acc": 53.0, "val_loss": 0.691299889087677, "val_acc": 52.0}
{"epoch": 20, "training_loss": 0.6921046543121337, "training_acc": 53.0, "val_loss": 0.6913067626953125, "val_acc": 52.0}
{"epoch": 21, "training_loss": 0.6919804954528809, "training_acc": 53.0, "val_loss": 0.6913190793991089, "val_acc": 52.0}
{"epoch": 22, "training_loss": 0.6922840738296508, "training_acc": 53.0, "val_loss": 0.6913204216957092, "val_acc": 52.0}
{"epoch": 23, "training_loss": 0.6918462181091308, "training_acc": 53.0, "val_loss": 0.6912888073921204, "val_acc": 52.0}
{"epoch": 24, "training_loss": 0.6919513010978698, "training_acc": 53.0, "val_loss": 0.6912829327583313, "val_acc": 52.0}
