"main_modify.py --pretrained_path /scratch/connectome/dyhan316/VAE_ADHD/barlowtwins/pretrain_results/ABCDbt128a102.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 1 --task ABCD_sex --input_option BT_org --learning_rate 1e-5 --batch_size 16 --weight_decay 1e-2 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 0.6958073163032532, "training_acc": 47.0, "val_loss": 0.6947594523429871, "val_acc": 48.0}
{"epoch": 1, "training_loss": 0.6959828662872315, "training_acc": 47.0, "val_loss": 0.6943622708320618, "val_acc": 48.0}
{"epoch": 2, "training_loss": 0.6954016661643982, "training_acc": 47.0, "val_loss": 0.6939331912994384, "val_acc": 48.0}
{"epoch": 3, "training_loss": 0.6949701738357544, "training_acc": 47.0, "val_loss": 0.6938014173507691, "val_acc": 48.0}
{"epoch": 4, "training_loss": 0.6945672464370728, "training_acc": 47.0, "val_loss": 0.693647882938385, "val_acc": 48.0}
{"epoch": 5, "training_loss": 0.6944521284103393, "training_acc": 47.0, "val_loss": 0.6934888458251953, "val_acc": 48.0}
{"epoch": 6, "training_loss": 0.69424898147583, "training_acc": 47.0, "val_loss": 0.6932259702682495, "val_acc": 48.0}
{"epoch": 7, "training_loss": 0.6946234917640686, "training_acc": 46.0, "val_loss": 0.6930133008956909, "val_acc": 48.0}
{"epoch": 8, "training_loss": 0.6942780184745788, "training_acc": 45.0, "val_loss": 0.6929174733161926, "val_acc": 48.0}
{"epoch": 9, "training_loss": 0.6938314461708068, "training_acc": 46.0, "val_loss": 0.6928996109962463, "val_acc": 48.0}
{"epoch": 10, "training_loss": 0.6937230563163758, "training_acc": 47.0, "val_loss": 0.6928315687179566, "val_acc": 48.0}
{"epoch": 11, "training_loss": 0.6936056280136108, "training_acc": 48.0, "val_loss": 0.6926517963409424, "val_acc": 48.0}
{"epoch": 12, "training_loss": 0.6935750579833985, "training_acc": 49.0, "val_loss": 0.6925457501411438, "val_acc": 52.0}
{"epoch": 13, "training_loss": 0.6930223631858826, "training_acc": 50.0, "val_loss": 0.6924039030075073, "val_acc": 64.0}
{"epoch": 14, "training_loss": 0.6931076860427856, "training_acc": 47.0, "val_loss": 0.692374427318573, "val_acc": 68.0}
{"epoch": 15, "training_loss": 0.6934481692314148, "training_acc": 49.0, "val_loss": 0.6922965669631957, "val_acc": 56.0}
{"epoch": 16, "training_loss": 0.6931066155433655, "training_acc": 53.0, "val_loss": 0.6921634531021118, "val_acc": 52.0}
{"epoch": 17, "training_loss": 0.6925984144210815, "training_acc": 58.0, "val_loss": 0.6920986914634705, "val_acc": 52.0}
{"epoch": 18, "training_loss": 0.6922026109695435, "training_acc": 57.0, "val_loss": 0.6920676469802857, "val_acc": 52.0}
{"epoch": 19, "training_loss": 0.6926743292808533, "training_acc": 54.0, "val_loss": 0.6919715118408203, "val_acc": 52.0}
{"epoch": 20, "training_loss": 0.6922198629379273, "training_acc": 53.0, "val_loss": 0.6919051742553711, "val_acc": 52.0}
{"epoch": 21, "training_loss": 0.6923836159706116, "training_acc": 53.0, "val_loss": 0.6918445324897766, "val_acc": 52.0}
{"epoch": 22, "training_loss": 0.6919931125640869, "training_acc": 53.0, "val_loss": 0.6917915964126586, "val_acc": 52.0}
{"epoch": 23, "training_loss": 0.691801483631134, "training_acc": 53.0, "val_loss": 0.6917552995681763, "val_acc": 52.0}
{"epoch": 24, "training_loss": 0.6919140815734863, "training_acc": 53.0, "val_loss": 0.6917467498779297, "val_acc": 52.0}
{"epoch": 25, "training_loss": 0.6917915296554565, "training_acc": 53.0, "val_loss": 0.6917470479011536, "val_acc": 52.0}
{"epoch": 26, "training_loss": 0.6924313330650329, "training_acc": 53.0, "val_loss": 0.6917102122306824, "val_acc": 52.0}
{"epoch": 27, "training_loss": 0.6916901683807373, "training_acc": 53.0, "val_loss": 0.6916985321044922, "val_acc": 52.0}
{"epoch": 28, "training_loss": 0.6914899563789367, "training_acc": 53.0, "val_loss": 0.6916937065124512, "val_acc": 52.0}
{"epoch": 29, "training_loss": 0.691613163948059, "training_acc": 53.0, "val_loss": 0.6916913652420044, "val_acc": 52.0}
{"epoch": 30, "training_loss": 0.6913816547393798, "training_acc": 53.0, "val_loss": 0.6916876149177551, "val_acc": 52.0}
{"epoch": 31, "training_loss": 0.6915822148323059, "training_acc": 53.0, "val_loss": 0.6916908049583435, "val_acc": 52.0}
{"epoch": 32, "training_loss": 0.6912510299682617, "training_acc": 53.0, "val_loss": 0.691694061756134, "val_acc": 52.0}
{"epoch": 33, "training_loss": 0.6916382575035095, "training_acc": 53.0, "val_loss": 0.6917045736312866, "val_acc": 52.0}
{"epoch": 34, "training_loss": 0.6912013339996338, "training_acc": 53.0, "val_loss": 0.6917205047607422, "val_acc": 52.0}
{"epoch": 35, "training_loss": 0.691048583984375, "training_acc": 53.0, "val_loss": 0.6917319440841675, "val_acc": 52.0}
{"epoch": 36, "training_loss": 0.6913230037689209, "training_acc": 53.0, "val_loss": 0.6917559123039245, "val_acc": 52.0}
{"epoch": 37, "training_loss": 0.6916405582427978, "training_acc": 53.0, "val_loss": 0.6917665600776672, "val_acc": 52.0}
{"epoch": 38, "training_loss": 0.6914064145088196, "training_acc": 53.0, "val_loss": 0.6917958807945251, "val_acc": 52.0}
{"epoch": 39, "training_loss": 0.6911851978302002, "training_acc": 53.0, "val_loss": 0.6918140435218811, "val_acc": 52.0}
{"epoch": 40, "training_loss": 0.6911722373962402, "training_acc": 53.0, "val_loss": 0.6918309164047242, "val_acc": 52.0}
{"epoch": 41, "training_loss": 0.6910711431503296, "training_acc": 53.0, "val_loss": 0.6918592286109925, "val_acc": 52.0}
{"epoch": 42, "training_loss": 0.6912239456176758, "training_acc": 53.0, "val_loss": 0.6919173407554626, "val_acc": 52.0}
{"epoch": 43, "training_loss": 0.6912815999984742, "training_acc": 53.0, "val_loss": 0.6919579696655274, "val_acc": 52.0}
{"epoch": 44, "training_loss": 0.6906098222732544, "training_acc": 53.0, "val_loss": 0.6919920778274536, "val_acc": 52.0}
{"epoch": 45, "training_loss": 0.6910814571380616, "training_acc": 53.0, "val_loss": 0.6920244288444519, "val_acc": 52.0}
{"epoch": 46, "training_loss": 0.6912719941139222, "training_acc": 53.0, "val_loss": 0.6919740271568299, "val_acc": 52.0}
{"epoch": 47, "training_loss": 0.6917744159698487, "training_acc": 53.0, "val_loss": 0.6919702529907227, "val_acc": 52.0}
{"epoch": 48, "training_loss": 0.6911152362823486, "training_acc": 53.0, "val_loss": 0.6919395422935486, "val_acc": 52.0}
{"epoch": 49, "training_loss": 0.6913020443916321, "training_acc": 53.0, "val_loss": 0.6918947148323059, "val_acc": 52.0}
