"main_modify.py --pretrained_path /scratch/connectome/dyhan316/VAE_ADHD/barlowtwins/pretrain_results/ABCDbt128a102.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 1 --task ABCD_sex --input_option BT_org --learning_rate 1e-5 --batch_size 16 --weight_decay 1e-2 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 0.7003154277801513, "training_acc": 47.0, "val_loss": 0.6978693723678588, "val_acc": 48.0}
{"epoch": 1, "training_loss": 0.6996175718307495, "training_acc": 47.0, "val_loss": 0.6969529676437378, "val_acc": 48.0}
{"epoch": 2, "training_loss": 0.698406171798706, "training_acc": 47.0, "val_loss": 0.6962661457061767, "val_acc": 48.0}
{"epoch": 3, "training_loss": 0.697805449962616, "training_acc": 47.0, "val_loss": 0.6957249021530152, "val_acc": 48.0}
{"epoch": 4, "training_loss": 0.6970364427566529, "training_acc": 47.0, "val_loss": 0.6953464126586915, "val_acc": 48.0}
{"epoch": 5, "training_loss": 0.6967955946922302, "training_acc": 47.0, "val_loss": 0.6950214624404907, "val_acc": 48.0}
{"epoch": 6, "training_loss": 0.6963368725776672, "training_acc": 47.0, "val_loss": 0.6945862483978271, "val_acc": 48.0}
{"epoch": 7, "training_loss": 0.6958260822296143, "training_acc": 47.0, "val_loss": 0.6941918110847474, "val_acc": 48.0}
{"epoch": 8, "training_loss": 0.6951274275779724, "training_acc": 47.0, "val_loss": 0.6939093112945557, "val_acc": 48.0}
{"epoch": 9, "training_loss": 0.6953178024291993, "training_acc": 46.0, "val_loss": 0.6936218404769897, "val_acc": 52.0}
{"epoch": 10, "training_loss": 0.6945321393013001, "training_acc": 47.0, "val_loss": 0.6935027742385864, "val_acc": 52.0}
{"epoch": 11, "training_loss": 0.6941589999198914, "training_acc": 47.0, "val_loss": 0.693265540599823, "val_acc": 56.0}
{"epoch": 12, "training_loss": 0.6944550752639771, "training_acc": 43.0, "val_loss": 0.6929999136924744, "val_acc": 52.0}
{"epoch": 13, "training_loss": 0.6930990743637085, "training_acc": 46.0, "val_loss": 0.6928932070732117, "val_acc": 48.0}
{"epoch": 14, "training_loss": 0.6935008358955383, "training_acc": 51.0, "val_loss": 0.6928120970726013, "val_acc": 48.0}
{"epoch": 15, "training_loss": 0.6933763432502746, "training_acc": 50.0, "val_loss": 0.6927850389480591, "val_acc": 48.0}
{"epoch": 16, "training_loss": 0.6933285474777222, "training_acc": 53.0, "val_loss": 0.6927325940132141, "val_acc": 52.0}
{"epoch": 17, "training_loss": 0.6931895017623901, "training_acc": 52.0, "val_loss": 0.6926819729804993, "val_acc": 52.0}
{"epoch": 18, "training_loss": 0.6931935024261474, "training_acc": 53.0, "val_loss": 0.6925975584983826, "val_acc": 52.0}
{"epoch": 19, "training_loss": 0.6929591751098633, "training_acc": 54.0, "val_loss": 0.6925476574897766, "val_acc": 52.0}
{"epoch": 20, "training_loss": 0.6929535365104675, "training_acc": 53.0, "val_loss": 0.6924899339675903, "val_acc": 52.0}
{"epoch": 21, "training_loss": 0.6923968768119813, "training_acc": 53.0, "val_loss": 0.6924228286743164, "val_acc": 52.0}
{"epoch": 22, "training_loss": 0.6921339583396912, "training_acc": 53.0, "val_loss": 0.6924110054969788, "val_acc": 52.0}
{"epoch": 23, "training_loss": 0.6924597835540771, "training_acc": 53.0, "val_loss": 0.6924315357208252, "val_acc": 52.0}
{"epoch": 24, "training_loss": 0.6922693777084351, "training_acc": 53.0, "val_loss": 0.6924235129356384, "val_acc": 52.0}
{"epoch": 25, "training_loss": 0.6926013326644898, "training_acc": 53.0, "val_loss": 0.6924177193641663, "val_acc": 52.0}
{"epoch": 26, "training_loss": 0.6924908971786499, "training_acc": 53.0, "val_loss": 0.6924197936058044, "val_acc": 52.0}
{"epoch": 27, "training_loss": 0.6924137210845948, "training_acc": 53.0, "val_loss": 0.6924290776252746, "val_acc": 52.0}
{"epoch": 28, "training_loss": 0.6924691581726075, "training_acc": 53.0, "val_loss": 0.6924106168746949, "val_acc": 52.0}
{"epoch": 29, "training_loss": 0.6922480821609497, "training_acc": 53.0, "val_loss": 0.6924004912376404, "val_acc": 52.0}
{"epoch": 30, "training_loss": 0.6922799205780029, "training_acc": 53.0, "val_loss": 0.6923708009719849, "val_acc": 52.0}
{"epoch": 31, "training_loss": 0.6926112222671509, "training_acc": 53.0, "val_loss": 0.6923590850830078, "val_acc": 52.0}
{"epoch": 32, "training_loss": 0.6925134444236756, "training_acc": 53.0, "val_loss": 0.692349660396576, "val_acc": 52.0}
{"epoch": 33, "training_loss": 0.69226083278656, "training_acc": 53.0, "val_loss": 0.6923474073410034, "val_acc": 52.0}
{"epoch": 34, "training_loss": 0.6925102496147155, "training_acc": 53.0, "val_loss": 0.6923422312736511, "val_acc": 52.0}
{"epoch": 35, "training_loss": 0.692734842300415, "training_acc": 53.0, "val_loss": 0.6923431444168091, "val_acc": 52.0}
{"epoch": 36, "training_loss": 0.6925044822692871, "training_acc": 53.0, "val_loss": 0.6923414659500122, "val_acc": 52.0}
{"epoch": 37, "training_loss": 0.6919921541213989, "training_acc": 53.0, "val_loss": 0.6923401784896851, "val_acc": 52.0}
{"epoch": 38, "training_loss": 0.6922710728645325, "training_acc": 53.0, "val_loss": 0.6923395895957947, "val_acc": 52.0}
{"epoch": 39, "training_loss": 0.692708683013916, "training_acc": 53.0, "val_loss": 0.69233882188797, "val_acc": 52.0}
{"epoch": 40, "training_loss": 0.6920109558105468, "training_acc": 53.0, "val_loss": 0.6923381352424621, "val_acc": 52.0}
{"epoch": 41, "training_loss": 0.6921107172966003, "training_acc": 53.0, "val_loss": 0.6923385357856751, "val_acc": 52.0}
{"epoch": 42, "training_loss": 0.6927047681808471, "training_acc": 53.0, "val_loss": 0.6923410034179688, "val_acc": 52.0}
{"epoch": 43, "training_loss": 0.692611825466156, "training_acc": 53.0, "val_loss": 0.6923395562171936, "val_acc": 52.0}
{"epoch": 44, "training_loss": 0.6924759578704834, "training_acc": 53.0, "val_loss": 0.6923382496833801, "val_acc": 52.0}
{"epoch": 45, "training_loss": 0.6924605441093444, "training_acc": 53.0, "val_loss": 0.6923454070091247, "val_acc": 52.0}
{"epoch": 46, "training_loss": 0.6922912502288818, "training_acc": 53.0, "val_loss": 0.6923481488227844, "val_acc": 52.0}
{"epoch": 47, "training_loss": 0.6923553538322449, "training_acc": 53.0, "val_loss": 0.6923582887649536, "val_acc": 52.0}
{"epoch": 48, "training_loss": 0.6923238277435303, "training_acc": 53.0, "val_loss": 0.692362642288208, "val_acc": 52.0}
{"epoch": 49, "training_loss": 0.6919090437889099, "training_acc": 53.0, "val_loss": 0.6923641848564148, "val_acc": 52.0}
{"epoch": 50, "training_loss": 0.6921084451675416, "training_acc": 53.0, "val_loss": 0.6923695707321167, "val_acc": 52.0}
{"epoch": 51, "training_loss": 0.6918798494338989, "training_acc": 53.0, "val_loss": 0.6923813557624817, "val_acc": 52.0}
{"epoch": 52, "training_loss": 0.6922324538230896, "training_acc": 53.0, "val_loss": 0.692414083480835, "val_acc": 52.0}
{"epoch": 53, "training_loss": 0.6918196630477905, "training_acc": 53.0, "val_loss": 0.6924125170707702, "val_acc": 52.0}
{"epoch": 54, "training_loss": 0.6917207908630371, "training_acc": 53.0, "val_loss": 0.6924422192573547, "val_acc": 52.0}
{"epoch": 55, "training_loss": 0.6916973495483398, "training_acc": 53.0, "val_loss": 0.6924993968009949, "val_acc": 52.0}
{"epoch": 56, "training_loss": 0.6920098829269409, "training_acc": 53.0, "val_loss": 0.6925834512710571, "val_acc": 52.0}
{"epoch": 57, "training_loss": 0.6920456624031067, "training_acc": 53.0, "val_loss": 0.6926084136962891, "val_acc": 52.0}
{"epoch": 58, "training_loss": 0.6925341510772705, "training_acc": 53.0, "val_loss": 0.6925753760337829, "val_acc": 52.0}
{"epoch": 59, "training_loss": 0.6922823572158814, "training_acc": 53.0, "val_loss": 0.6925595450401306, "val_acc": 52.0}
