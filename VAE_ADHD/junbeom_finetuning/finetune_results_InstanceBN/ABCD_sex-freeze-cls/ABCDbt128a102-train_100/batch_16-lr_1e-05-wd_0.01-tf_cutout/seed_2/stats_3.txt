"main_modify.py --pretrained_path /scratch/connectome/dyhan316/VAE_ADHD/barlowtwins/pretrain_results/ABCDbt128a102.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 2 --task ABCD_sex --input_option BT_org --learning_rate 1e-5 --batch_size 16 --weight_decay 1e-2 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 0.698570556640625, "training_acc": 47.0, "val_loss": 0.6967268705368042, "val_acc": 48.0}
{"epoch": 1, "training_loss": 0.6975492978096008, "training_acc": 47.0, "val_loss": 0.6961317372322082, "val_acc": 48.0}
{"epoch": 2, "training_loss": 0.6968944549560547, "training_acc": 47.0, "val_loss": 0.6959270811080933, "val_acc": 48.0}
{"epoch": 3, "training_loss": 0.6965362882614136, "training_acc": 47.0, "val_loss": 0.6955782437324524, "val_acc": 48.0}
{"epoch": 4, "training_loss": 0.6963357901573182, "training_acc": 47.0, "val_loss": 0.6951369905471801, "val_acc": 48.0}
{"epoch": 5, "training_loss": 0.6952319169044494, "training_acc": 47.0, "val_loss": 0.6947556376457215, "val_acc": 48.0}
{"epoch": 6, "training_loss": 0.6950812792778015, "training_acc": 47.0, "val_loss": 0.6944890689849853, "val_acc": 48.0}
{"epoch": 7, "training_loss": 0.6946006727218628, "training_acc": 47.0, "val_loss": 0.6941987490653991, "val_acc": 48.0}
{"epoch": 8, "training_loss": 0.694357407093048, "training_acc": 47.0, "val_loss": 0.6938994741439819, "val_acc": 48.0}
{"epoch": 9, "training_loss": 0.6940293931961059, "training_acc": 47.0, "val_loss": 0.6936789417266845, "val_acc": 48.0}
{"epoch": 10, "training_loss": 0.6940081024169922, "training_acc": 48.0, "val_loss": 0.693532075881958, "val_acc": 48.0}
{"epoch": 11, "training_loss": 0.6938301181793213, "training_acc": 44.0, "val_loss": 0.6933867955207824, "val_acc": 52.0}
{"epoch": 12, "training_loss": 0.6933961129188537, "training_acc": 47.0, "val_loss": 0.6933014345169067, "val_acc": 52.0}
{"epoch": 13, "training_loss": 0.69361887216568, "training_acc": 49.0, "val_loss": 0.693148159980774, "val_acc": 52.0}
{"epoch": 14, "training_loss": 0.6926463222503663, "training_acc": 52.0, "val_loss": 0.6930702304840088, "val_acc": 40.0}
{"epoch": 15, "training_loss": 0.6927328300476074, "training_acc": 50.0, "val_loss": 0.6930076265335083, "val_acc": 44.0}
{"epoch": 16, "training_loss": 0.692757306098938, "training_acc": 49.0, "val_loss": 0.6929606676101685, "val_acc": 44.0}
{"epoch": 17, "training_loss": 0.6924327969551086, "training_acc": 51.0, "val_loss": 0.6928310370445252, "val_acc": 48.0}
{"epoch": 18, "training_loss": 0.6919784903526306, "training_acc": 56.0, "val_loss": 0.6927688384056091, "val_acc": 56.0}
{"epoch": 19, "training_loss": 0.6920890522003174, "training_acc": 56.0, "val_loss": 0.6927213263511658, "val_acc": 52.0}
{"epoch": 20, "training_loss": 0.6923985338211059, "training_acc": 56.0, "val_loss": 0.6926602888107299, "val_acc": 52.0}
{"epoch": 21, "training_loss": 0.6924492883682251, "training_acc": 54.0, "val_loss": 0.6926275944709778, "val_acc": 52.0}
{"epoch": 22, "training_loss": 0.6919406890869141, "training_acc": 53.0, "val_loss": 0.6925514245033264, "val_acc": 52.0}
{"epoch": 23, "training_loss": 0.6914801216125488, "training_acc": 53.0, "val_loss": 0.6925219321250915, "val_acc": 52.0}
{"epoch": 24, "training_loss": 0.6919267463684082, "training_acc": 53.0, "val_loss": 0.6925032496452331, "val_acc": 52.0}
{"epoch": 25, "training_loss": 0.6918492317199707, "training_acc": 53.0, "val_loss": 0.6925076222419739, "val_acc": 52.0}
{"epoch": 26, "training_loss": 0.6919306802749634, "training_acc": 53.0, "val_loss": 0.6924975395202637, "val_acc": 52.0}
{"epoch": 27, "training_loss": 0.691795437335968, "training_acc": 53.0, "val_loss": 0.6924590635299682, "val_acc": 52.0}
{"epoch": 28, "training_loss": 0.6917512607574463, "training_acc": 53.0, "val_loss": 0.692447476387024, "val_acc": 52.0}
{"epoch": 29, "training_loss": 0.6910383367538452, "training_acc": 53.0, "val_loss": 0.6924405407905578, "val_acc": 52.0}
{"epoch": 30, "training_loss": 0.6916450619697571, "training_acc": 53.0, "val_loss": 0.6924149632453919, "val_acc": 52.0}
{"epoch": 31, "training_loss": 0.691210412979126, "training_acc": 53.0, "val_loss": 0.6924102449417114, "val_acc": 52.0}
{"epoch": 32, "training_loss": 0.6912637376785278, "training_acc": 53.0, "val_loss": 0.692416114807129, "val_acc": 52.0}
{"epoch": 33, "training_loss": 0.6917664718627929, "training_acc": 53.0, "val_loss": 0.6924129486083984, "val_acc": 52.0}
{"epoch": 34, "training_loss": 0.6916398978233338, "training_acc": 53.0, "val_loss": 0.6924162578582763, "val_acc": 52.0}
{"epoch": 35, "training_loss": 0.6917551183700561, "training_acc": 53.0, "val_loss": 0.6924018955230713, "val_acc": 52.0}
{"epoch": 36, "training_loss": 0.6913665866851807, "training_acc": 53.0, "val_loss": 0.6923969650268554, "val_acc": 52.0}
{"epoch": 37, "training_loss": 0.6911149668693543, "training_acc": 53.0, "val_loss": 0.692391128540039, "val_acc": 52.0}
{"epoch": 38, "training_loss": 0.6912044858932496, "training_acc": 53.0, "val_loss": 0.6923982954025268, "val_acc": 52.0}
{"epoch": 39, "training_loss": 0.6918818020820617, "training_acc": 53.0, "val_loss": 0.6923955845832824, "val_acc": 52.0}
{"epoch": 40, "training_loss": 0.6914509892463684, "training_acc": 53.0, "val_loss": 0.6923967027664184, "val_acc": 52.0}
{"epoch": 41, "training_loss": 0.6906317973136902, "training_acc": 53.0, "val_loss": 0.692422263622284, "val_acc": 52.0}
{"epoch": 42, "training_loss": 0.6904354906082153, "training_acc": 53.0, "val_loss": 0.6924389576911927, "val_acc": 52.0}
{"epoch": 43, "training_loss": 0.6906644153594971, "training_acc": 53.0, "val_loss": 0.6924368810653686, "val_acc": 52.0}
{"epoch": 44, "training_loss": 0.6907642531394959, "training_acc": 53.0, "val_loss": 0.6924632263183593, "val_acc": 52.0}
{"epoch": 45, "training_loss": 0.6909951663017273, "training_acc": 53.0, "val_loss": 0.6924688959121704, "val_acc": 52.0}
{"epoch": 46, "training_loss": 0.6908869123458863, "training_acc": 53.0, "val_loss": 0.6924935626983643, "val_acc": 52.0}
{"epoch": 47, "training_loss": 0.6905478858947753, "training_acc": 53.0, "val_loss": 0.6925090432167054, "val_acc": 52.0}
{"epoch": 48, "training_loss": 0.6907421064376831, "training_acc": 53.0, "val_loss": 0.692554018497467, "val_acc": 52.0}
{"epoch": 49, "training_loss": 0.6920247840881347, "training_acc": 53.0, "val_loss": 0.6925955867767334, "val_acc": 52.0}
{"epoch": 50, "training_loss": 0.6908923482894898, "training_acc": 53.0, "val_loss": 0.6925863957405091, "val_acc": 52.0}
{"epoch": 51, "training_loss": 0.6910617160797119, "training_acc": 53.0, "val_loss": 0.6925779390335083, "val_acc": 52.0}
{"epoch": 52, "training_loss": 0.690420196056366, "training_acc": 53.0, "val_loss": 0.6925925207138062, "val_acc": 52.0}
{"epoch": 53, "training_loss": 0.691218957901001, "training_acc": 53.0, "val_loss": 0.6925352740287781, "val_acc": 52.0}
{"epoch": 54, "training_loss": 0.6910442590713501, "training_acc": 53.0, "val_loss": 0.6925303363800048, "val_acc": 52.0}
{"epoch": 55, "training_loss": 0.6910961747169495, "training_acc": 53.0, "val_loss": 0.6925332069396972, "val_acc": 52.0}
{"epoch": 56, "training_loss": 0.6909422492980957, "training_acc": 53.0, "val_loss": 0.6925081562995911, "val_acc": 52.0}
