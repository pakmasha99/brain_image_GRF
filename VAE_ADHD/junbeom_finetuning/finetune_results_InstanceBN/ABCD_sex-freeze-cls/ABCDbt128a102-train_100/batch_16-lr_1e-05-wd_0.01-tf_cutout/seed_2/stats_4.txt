"main_modify.py --pretrained_path /scratch/connectome/dyhan316/VAE_ADHD/barlowtwins/pretrain_results/ABCDbt128a102.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 2 --task ABCD_sex --input_option BT_org --learning_rate 1e-5 --batch_size 16 --weight_decay 1e-2 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 0.6978881382942199, "training_acc": 48.0, "val_loss": 0.7030399942398071, "val_acc": 44.0}
{"epoch": 1, "training_loss": 0.697381567955017, "training_acc": 48.0, "val_loss": 0.7019877171516419, "val_acc": 44.0}
{"epoch": 2, "training_loss": 0.6963449335098266, "training_acc": 48.0, "val_loss": 0.701172924041748, "val_acc": 44.0}
{"epoch": 3, "training_loss": 0.6964094376564026, "training_acc": 48.0, "val_loss": 0.7001847195625305, "val_acc": 44.0}
{"epoch": 4, "training_loss": 0.6961793303489685, "training_acc": 48.0, "val_loss": 0.6992506980895996, "val_acc": 44.0}
{"epoch": 5, "training_loss": 0.6952616167068482, "training_acc": 48.0, "val_loss": 0.6983151292800903, "val_acc": 44.0}
{"epoch": 6, "training_loss": 0.6947276592254639, "training_acc": 48.0, "val_loss": 0.697870454788208, "val_acc": 44.0}
{"epoch": 7, "training_loss": 0.6947698783874512, "training_acc": 48.0, "val_loss": 0.697005672454834, "val_acc": 44.0}
{"epoch": 8, "training_loss": 0.6944790124893189, "training_acc": 48.0, "val_loss": 0.6964124655723571, "val_acc": 44.0}
{"epoch": 9, "training_loss": 0.6939627623558045, "training_acc": 48.0, "val_loss": 0.6961934161186218, "val_acc": 44.0}
{"epoch": 10, "training_loss": 0.6941532874107361, "training_acc": 49.0, "val_loss": 0.6959546399116516, "val_acc": 44.0}
{"epoch": 11, "training_loss": 0.6943279147148133, "training_acc": 48.0, "val_loss": 0.6958911991119385, "val_acc": 44.0}
{"epoch": 12, "training_loss": 0.6938534355163575, "training_acc": 48.0, "val_loss": 0.6958396983146667, "val_acc": 44.0}
{"epoch": 13, "training_loss": 0.6938817286491394, "training_acc": 48.0, "val_loss": 0.695565230846405, "val_acc": 44.0}
{"epoch": 14, "training_loss": 0.6934643793106079, "training_acc": 49.0, "val_loss": 0.6952243447303772, "val_acc": 44.0}
{"epoch": 15, "training_loss": 0.6930396223068237, "training_acc": 47.0, "val_loss": 0.6946823239326477, "val_acc": 40.0}
{"epoch": 16, "training_loss": 0.6936335897445679, "training_acc": 45.0, "val_loss": 0.6944081163406373, "val_acc": 44.0}
{"epoch": 17, "training_loss": 0.6930771613121033, "training_acc": 46.0, "val_loss": 0.6939675426483154, "val_acc": 48.0}
{"epoch": 18, "training_loss": 0.6931384325027465, "training_acc": 57.0, "val_loss": 0.693533136844635, "val_acc": 44.0}
{"epoch": 19, "training_loss": 0.693139317035675, "training_acc": 47.0, "val_loss": 0.6930435037612915, "val_acc": 48.0}
{"epoch": 20, "training_loss": 0.6929463601112366, "training_acc": 48.0, "val_loss": 0.6929204106330872, "val_acc": 52.0}
{"epoch": 21, "training_loss": 0.6929699897766113, "training_acc": 49.0, "val_loss": 0.6930093932151794, "val_acc": 48.0}
{"epoch": 22, "training_loss": 0.693228759765625, "training_acc": 50.0, "val_loss": 0.6931239652633667, "val_acc": 48.0}
{"epoch": 23, "training_loss": 0.6931771469116211, "training_acc": 51.0, "val_loss": 0.6933038449287414, "val_acc": 44.0}
{"epoch": 24, "training_loss": 0.6929144954681397, "training_acc": 54.0, "val_loss": 0.6933604049682617, "val_acc": 44.0}
{"epoch": 25, "training_loss": 0.6932741045951843, "training_acc": 49.0, "val_loss": 0.6930421113967895, "val_acc": 48.0}
{"epoch": 26, "training_loss": 0.693065721988678, "training_acc": 50.0, "val_loss": 0.6927174234390259, "val_acc": 52.0}
{"epoch": 27, "training_loss": 0.69304518699646, "training_acc": 52.0, "val_loss": 0.6927356719970703, "val_acc": 52.0}
{"epoch": 28, "training_loss": 0.6930262613296508, "training_acc": 49.0, "val_loss": 0.6926123857498169, "val_acc": 56.0}
{"epoch": 29, "training_loss": 0.692257559299469, "training_acc": 52.0, "val_loss": 0.6925672173500061, "val_acc": 56.0}
{"epoch": 30, "training_loss": 0.692748737335205, "training_acc": 50.0, "val_loss": 0.6926218461990357, "val_acc": 56.0}
{"epoch": 31, "training_loss": 0.6926822233200073, "training_acc": 50.0, "val_loss": 0.69223872423172, "val_acc": 52.0}
{"epoch": 32, "training_loss": 0.6929291415214539, "training_acc": 51.0, "val_loss": 0.6920462274551391, "val_acc": 56.0}
{"epoch": 33, "training_loss": 0.6931178045272827, "training_acc": 51.0, "val_loss": 0.6921653079986573, "val_acc": 52.0}
{"epoch": 34, "training_loss": 0.6930738663673401, "training_acc": 52.0, "val_loss": 0.69216956615448, "val_acc": 52.0}
{"epoch": 35, "training_loss": 0.6927677917480469, "training_acc": 52.0, "val_loss": 0.6921661877632141, "val_acc": 52.0}
{"epoch": 36, "training_loss": 0.6927895879745484, "training_acc": 52.0, "val_loss": 0.692393651008606, "val_acc": 52.0}
{"epoch": 37, "training_loss": 0.6923363161087036, "training_acc": 50.0, "val_loss": 0.6925424933433533, "val_acc": 56.0}
{"epoch": 38, "training_loss": 0.6929182028770446, "training_acc": 51.0, "val_loss": 0.6925468230247498, "val_acc": 56.0}
{"epoch": 39, "training_loss": 0.6925086855888367, "training_acc": 51.0, "val_loss": 0.692278323173523, "val_acc": 52.0}
{"epoch": 40, "training_loss": 0.6924099731445312, "training_acc": 51.0, "val_loss": 0.6922420835494996, "val_acc": 52.0}
{"epoch": 41, "training_loss": 0.6932215356826782, "training_acc": 51.0, "val_loss": 0.6921864056587219, "val_acc": 52.0}
{"epoch": 42, "training_loss": 0.6927058386802674, "training_acc": 52.0, "val_loss": 0.6919423532485962, "val_acc": 56.0}
{"epoch": 43, "training_loss": 0.6928024172782898, "training_acc": 52.0, "val_loss": 0.6918080186843872, "val_acc": 56.0}
{"epoch": 44, "training_loss": 0.6929529309272766, "training_acc": 52.0, "val_loss": 0.6915621304512024, "val_acc": 56.0}
{"epoch": 45, "training_loss": 0.6920863389968872, "training_acc": 52.0, "val_loss": 0.6914924883842468, "val_acc": 56.0}
{"epoch": 46, "training_loss": 0.6925972986221314, "training_acc": 52.0, "val_loss": 0.6914889788627625, "val_acc": 56.0}
{"epoch": 47, "training_loss": 0.6927569246292115, "training_acc": 52.0, "val_loss": 0.6913757681846618, "val_acc": 56.0}
{"epoch": 48, "training_loss": 0.6927083301544189, "training_acc": 52.0, "val_loss": 0.6913424444198608, "val_acc": 56.0}
{"epoch": 49, "training_loss": 0.6924310493469238, "training_acc": 52.0, "val_loss": 0.6911939239501953, "val_acc": 56.0}
{"epoch": 50, "training_loss": 0.6921645379066468, "training_acc": 52.0, "val_loss": 0.6912911486625671, "val_acc": 56.0}
{"epoch": 51, "training_loss": 0.6922335267066956, "training_acc": 52.0, "val_loss": 0.6912795948982239, "val_acc": 56.0}
{"epoch": 52, "training_loss": 0.6920649003982544, "training_acc": 52.0, "val_loss": 0.6912129664421082, "val_acc": 56.0}
{"epoch": 53, "training_loss": 0.6923958730697631, "training_acc": 52.0, "val_loss": 0.6910604786872864, "val_acc": 56.0}
{"epoch": 54, "training_loss": 0.6923763394355774, "training_acc": 52.0, "val_loss": 0.6909179711341857, "val_acc": 56.0}
{"epoch": 55, "training_loss": 0.6924541330337525, "training_acc": 52.0, "val_loss": 0.6906768155097961, "val_acc": 56.0}
{"epoch": 56, "training_loss": 0.6925852060317993, "training_acc": 52.0, "val_loss": 0.6903937816619873, "val_acc": 56.0}
{"epoch": 57, "training_loss": 0.6923700714111328, "training_acc": 52.0, "val_loss": 0.6903598237037659, "val_acc": 56.0}
{"epoch": 58, "training_loss": 0.6921310138702392, "training_acc": 52.0, "val_loss": 0.6902256965637207, "val_acc": 56.0}
{"epoch": 59, "training_loss": 0.6923945379257203, "training_acc": 52.0, "val_loss": 0.6901514673233032, "val_acc": 56.0}
{"epoch": 60, "training_loss": 0.6921229577064514, "training_acc": 52.0, "val_loss": 0.690123450756073, "val_acc": 56.0}
{"epoch": 61, "training_loss": 0.692379379272461, "training_acc": 52.0, "val_loss": 0.6902214884757996, "val_acc": 56.0}
{"epoch": 62, "training_loss": 0.6921666073799133, "training_acc": 52.0, "val_loss": 0.6902569699287414, "val_acc": 56.0}
{"epoch": 63, "training_loss": 0.6924567413330078, "training_acc": 52.0, "val_loss": 0.6901880764961242, "val_acc": 56.0}
{"epoch": 64, "training_loss": 0.6921517872810363, "training_acc": 52.0, "val_loss": 0.6901937890052795, "val_acc": 56.0}
{"epoch": 65, "training_loss": 0.6921987795829773, "training_acc": 52.0, "val_loss": 0.6900908017158508, "val_acc": 56.0}
{"epoch": 66, "training_loss": 0.6925298070907593, "training_acc": 52.0, "val_loss": 0.6900738787651062, "val_acc": 56.0}
{"epoch": 67, "training_loss": 0.6926080608367919, "training_acc": 52.0, "val_loss": 0.6899985241889953, "val_acc": 56.0}
{"epoch": 68, "training_loss": 0.6919801139831543, "training_acc": 52.0, "val_loss": 0.6899796509742737, "val_acc": 56.0}
{"epoch": 69, "training_loss": 0.6926304459571838, "training_acc": 52.0, "val_loss": 0.6899491024017333, "val_acc": 56.0}
{"epoch": 70, "training_loss": 0.6921077680587768, "training_acc": 52.0, "val_loss": 0.690039668083191, "val_acc": 56.0}
{"epoch": 71, "training_loss": 0.6926566457748413, "training_acc": 52.0, "val_loss": 0.689881706237793, "val_acc": 56.0}
{"epoch": 72, "training_loss": 0.6921460843086242, "training_acc": 52.0, "val_loss": 0.6898423480987549, "val_acc": 56.0}
{"epoch": 73, "training_loss": 0.6919721984863281, "training_acc": 52.0, "val_loss": 0.6900376653671265, "val_acc": 56.0}
{"epoch": 74, "training_loss": 0.6921678972244263, "training_acc": 52.0, "val_loss": 0.6903081631660462, "val_acc": 56.0}
{"epoch": 75, "training_loss": 0.6924661111831665, "training_acc": 52.0, "val_loss": 0.6903076338768005, "val_acc": 56.0}
{"epoch": 76, "training_loss": 0.6926961708068847, "training_acc": 52.0, "val_loss": 0.6904417324066162, "val_acc": 56.0}
{"epoch": 77, "training_loss": 0.6930395317077637, "training_acc": 52.0, "val_loss": 0.6904458928108216, "val_acc": 56.0}
{"epoch": 78, "training_loss": 0.6922378897666931, "training_acc": 52.0, "val_loss": 0.6903858542442322, "val_acc": 56.0}
{"epoch": 79, "training_loss": 0.692276816368103, "training_acc": 52.0, "val_loss": 0.690219693183899, "val_acc": 56.0}
{"epoch": 80, "training_loss": 0.6919107723236084, "training_acc": 52.0, "val_loss": 0.690173933506012, "val_acc": 56.0}
{"epoch": 81, "training_loss": 0.6926339626312256, "training_acc": 52.0, "val_loss": 0.6900954461097717, "val_acc": 56.0}
{"epoch": 82, "training_loss": 0.6922703075408936, "training_acc": 52.0, "val_loss": 0.6900276684761047, "val_acc": 56.0}
{"epoch": 83, "training_loss": 0.6925566864013671, "training_acc": 52.0, "val_loss": 0.6899371385574341, "val_acc": 56.0}
{"epoch": 84, "training_loss": 0.6927336549758911, "training_acc": 52.0, "val_loss": 0.6898903584480286, "val_acc": 56.0}
{"epoch": 85, "training_loss": 0.6922281742095947, "training_acc": 52.0, "val_loss": 0.6898050045967102, "val_acc": 56.0}
{"epoch": 86, "training_loss": 0.6921103596687317, "training_acc": 52.0, "val_loss": 0.6898312211036682, "val_acc": 56.0}
{"epoch": 87, "training_loss": 0.6923122692108155, "training_acc": 52.0, "val_loss": 0.6899403405189514, "val_acc": 56.0}
{"epoch": 88, "training_loss": 0.6923844766616821, "training_acc": 52.0, "val_loss": 0.6898514866828919, "val_acc": 56.0}
{"epoch": 89, "training_loss": 0.6919299840927124, "training_acc": 52.0, "val_loss": 0.6898883080482483, "val_acc": 56.0}
{"epoch": 90, "training_loss": 0.6923160696029663, "training_acc": 52.0, "val_loss": 0.6898478603363037, "val_acc": 56.0}
{"epoch": 91, "training_loss": 0.6924282693862915, "training_acc": 52.0, "val_loss": 0.689985704421997, "val_acc": 56.0}
{"epoch": 92, "training_loss": 0.6922874736785889, "training_acc": 52.0, "val_loss": 0.6902299427986145, "val_acc": 56.0}
{"epoch": 93, "training_loss": 0.692005774974823, "training_acc": 52.0, "val_loss": 0.6901611995697021, "val_acc": 56.0}
{"epoch": 94, "training_loss": 0.6922972059249878, "training_acc": 52.0, "val_loss": 0.6899519085884094, "val_acc": 56.0}
{"epoch": 95, "training_loss": 0.6923707842826843, "training_acc": 52.0, "val_loss": 0.6899001240730286, "val_acc": 56.0}
{"epoch": 96, "training_loss": 0.6927525639533997, "training_acc": 52.0, "val_loss": 0.6897933030128479, "val_acc": 56.0}
{"epoch": 97, "training_loss": 0.6924051475524903, "training_acc": 52.0, "val_loss": 0.6895965027809143, "val_acc": 56.0}
{"epoch": 98, "training_loss": 0.6919848465919495, "training_acc": 52.0, "val_loss": 0.6896815276145936, "val_acc": 56.0}
{"epoch": 99, "training_loss": 0.6924283456802368, "training_acc": 52.0, "val_loss": 0.6898841333389282, "val_acc": 56.0}
