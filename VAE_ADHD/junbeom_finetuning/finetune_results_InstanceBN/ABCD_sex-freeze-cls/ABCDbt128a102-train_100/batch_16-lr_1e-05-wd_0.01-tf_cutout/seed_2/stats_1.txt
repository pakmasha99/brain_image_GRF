"main_modify.py --pretrained_path /scratch/connectome/dyhan316/VAE_ADHD/barlowtwins/pretrain_results/ABCDbt128a102.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 2 --task ABCD_sex --input_option BT_org --learning_rate 1e-5 --batch_size 16 --weight_decay 1e-2 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 0.7034307718276978, "training_acc": 47.0, "val_loss": 0.7011090159416199, "val_acc": 48.0}
{"epoch": 1, "training_loss": 0.7021631908416748, "training_acc": 47.0, "val_loss": 0.7004914927482605, "val_acc": 48.0}
{"epoch": 2, "training_loss": 0.7008588647842408, "training_acc": 47.0, "val_loss": 0.6997068095207214, "val_acc": 48.0}
{"epoch": 3, "training_loss": 0.6999867224693298, "training_acc": 47.0, "val_loss": 0.6987464761734009, "val_acc": 48.0}
{"epoch": 4, "training_loss": 0.6990441584587097, "training_acc": 47.0, "val_loss": 0.6980476689338684, "val_acc": 48.0}
{"epoch": 5, "training_loss": 0.6979153347015381, "training_acc": 47.0, "val_loss": 0.6974077701568604, "val_acc": 48.0}
{"epoch": 6, "training_loss": 0.6970414066314697, "training_acc": 47.0, "val_loss": 0.6968992924690247, "val_acc": 48.0}
{"epoch": 7, "training_loss": 0.6967647433280945, "training_acc": 47.0, "val_loss": 0.6963809585571289, "val_acc": 48.0}
{"epoch": 8, "training_loss": 0.6959577798843384, "training_acc": 47.0, "val_loss": 0.6958666515350341, "val_acc": 48.0}
{"epoch": 9, "training_loss": 0.6956669855117797, "training_acc": 47.0, "val_loss": 0.6954737472534179, "val_acc": 48.0}
{"epoch": 10, "training_loss": 0.6955789971351624, "training_acc": 47.0, "val_loss": 0.6951525139808655, "val_acc": 48.0}
{"epoch": 11, "training_loss": 0.6946621227264405, "training_acc": 47.0, "val_loss": 0.6948326373100281, "val_acc": 48.0}
{"epoch": 12, "training_loss": 0.6941746711730957, "training_acc": 45.0, "val_loss": 0.694546890258789, "val_acc": 44.0}
{"epoch": 13, "training_loss": 0.6942710638046264, "training_acc": 42.0, "val_loss": 0.6943394017219543, "val_acc": 40.0}
{"epoch": 14, "training_loss": 0.6939028882980347, "training_acc": 43.0, "val_loss": 0.6941700744628906, "val_acc": 36.0}
{"epoch": 15, "training_loss": 0.6931816577911377, "training_acc": 49.0, "val_loss": 0.6941391158103943, "val_acc": 44.0}
{"epoch": 16, "training_loss": 0.6937843751907349, "training_acc": 46.0, "val_loss": 0.6941556859016419, "val_acc": 36.0}
{"epoch": 17, "training_loss": 0.6934394407272338, "training_acc": 56.0, "val_loss": 0.6941913938522339, "val_acc": 40.0}
{"epoch": 18, "training_loss": 0.6935722756385804, "training_acc": 49.0, "val_loss": 0.694242844581604, "val_acc": 36.0}
{"epoch": 19, "training_loss": 0.6933325743675232, "training_acc": 53.0, "val_loss": 0.6941345763206482, "val_acc": 44.0}
{"epoch": 20, "training_loss": 0.6932529640197754, "training_acc": 52.0, "val_loss": 0.6940163207054139, "val_acc": 48.0}
{"epoch": 21, "training_loss": 0.6931633996963501, "training_acc": 53.0, "val_loss": 0.6938615894317627, "val_acc": 52.0}
{"epoch": 22, "training_loss": 0.6927475571632385, "training_acc": 52.0, "val_loss": 0.6937519502639771, "val_acc": 52.0}
{"epoch": 23, "training_loss": 0.6926099634170533, "training_acc": 53.0, "val_loss": 0.6936802768707275, "val_acc": 52.0}
{"epoch": 24, "training_loss": 0.6926005411148072, "training_acc": 53.0, "val_loss": 0.6936061239242554, "val_acc": 52.0}
{"epoch": 25, "training_loss": 0.692297968864441, "training_acc": 53.0, "val_loss": 0.6935311913490295, "val_acc": 52.0}
{"epoch": 26, "training_loss": 0.692680675983429, "training_acc": 53.0, "val_loss": 0.6934907627105713, "val_acc": 52.0}
{"epoch": 27, "training_loss": 0.692271203994751, "training_acc": 53.0, "val_loss": 0.6934653353691101, "val_acc": 52.0}
{"epoch": 28, "training_loss": 0.6924250841140747, "training_acc": 53.0, "val_loss": 0.6934666013717652, "val_acc": 52.0}
{"epoch": 29, "training_loss": 0.69178719997406, "training_acc": 53.0, "val_loss": 0.6934574604034424, "val_acc": 52.0}
{"epoch": 30, "training_loss": 0.6919298982620239, "training_acc": 53.0, "val_loss": 0.6934330797195435, "val_acc": 52.0}
{"epoch": 31, "training_loss": 0.6924320530891418, "training_acc": 53.0, "val_loss": 0.6934236907958984, "val_acc": 52.0}
{"epoch": 32, "training_loss": 0.6924578428268433, "training_acc": 53.0, "val_loss": 0.6934231209754944, "val_acc": 52.0}
{"epoch": 33, "training_loss": 0.6918557715415955, "training_acc": 53.0, "val_loss": 0.6934284806251526, "val_acc": 52.0}
{"epoch": 34, "training_loss": 0.6920145916938781, "training_acc": 53.0, "val_loss": 0.6934246110916138, "val_acc": 52.0}
{"epoch": 35, "training_loss": 0.6921698331832886, "training_acc": 53.0, "val_loss": 0.6934184670448303, "val_acc": 52.0}
{"epoch": 36, "training_loss": 0.6920670986175537, "training_acc": 53.0, "val_loss": 0.6934173274040222, "val_acc": 52.0}
{"epoch": 37, "training_loss": 0.6920023036003112, "training_acc": 53.0, "val_loss": 0.6934176659584046, "val_acc": 52.0}
{"epoch": 38, "training_loss": 0.6916870832443237, "training_acc": 53.0, "val_loss": 0.693421573638916, "val_acc": 52.0}
{"epoch": 39, "training_loss": 0.6920273518562317, "training_acc": 53.0, "val_loss": 0.6934201407432556, "val_acc": 52.0}
{"epoch": 40, "training_loss": 0.6920558094978333, "training_acc": 53.0, "val_loss": 0.6934234714508056, "val_acc": 52.0}
{"epoch": 41, "training_loss": 0.6921114206314087, "training_acc": 53.0, "val_loss": 0.6934174489974976, "val_acc": 52.0}
{"epoch": 42, "training_loss": 0.6920489835739135, "training_acc": 53.0, "val_loss": 0.6934156131744384, "val_acc": 52.0}
{"epoch": 43, "training_loss": 0.6920056533813477, "training_acc": 53.0, "val_loss": 0.6934062147140503, "val_acc": 52.0}
{"epoch": 44, "training_loss": 0.6918984055519104, "training_acc": 53.0, "val_loss": 0.6934025692939758, "val_acc": 52.0}
{"epoch": 45, "training_loss": 0.6920118618011475, "training_acc": 53.0, "val_loss": 0.6934008479118348, "val_acc": 52.0}
{"epoch": 46, "training_loss": 0.6919995355606079, "training_acc": 53.0, "val_loss": 0.6934016895294189, "val_acc": 52.0}
{"epoch": 47, "training_loss": 0.6923394775390626, "training_acc": 53.0, "val_loss": 0.6934109926223755, "val_acc": 52.0}
{"epoch": 48, "training_loss": 0.6916102480888366, "training_acc": 53.0, "val_loss": 0.6934149098396302, "val_acc": 52.0}
{"epoch": 49, "training_loss": 0.6920580911636353, "training_acc": 53.0, "val_loss": 0.6934460878372193, "val_acc": 52.0}
{"epoch": 50, "training_loss": 0.6918730735778809, "training_acc": 53.0, "val_loss": 0.6934689474105835, "val_acc": 52.0}
{"epoch": 51, "training_loss": 0.6916321349143982, "training_acc": 53.0, "val_loss": 0.6935009670257568, "val_acc": 52.0}
{"epoch": 52, "training_loss": 0.692089695930481, "training_acc": 53.0, "val_loss": 0.6935420823097229, "val_acc": 52.0}
{"epoch": 53, "training_loss": 0.6917864656448365, "training_acc": 53.0, "val_loss": 0.6935379719734192, "val_acc": 52.0}
{"epoch": 54, "training_loss": 0.6914460992813111, "training_acc": 53.0, "val_loss": 0.6935192084312439, "val_acc": 52.0}
{"epoch": 55, "training_loss": 0.6919775223731994, "training_acc": 53.0, "val_loss": 0.6935048985481262, "val_acc": 52.0}
{"epoch": 56, "training_loss": 0.6917943453788757, "training_acc": 53.0, "val_loss": 0.6935221123695373, "val_acc": 52.0}
{"epoch": 57, "training_loss": 0.6918104887008667, "training_acc": 53.0, "val_loss": 0.6935356068611145, "val_acc": 52.0}
{"epoch": 58, "training_loss": 0.6913163876533508, "training_acc": 53.0, "val_loss": 0.6935201263427735, "val_acc": 52.0}
{"epoch": 59, "training_loss": 0.6913879585266113, "training_acc": 53.0, "val_loss": 0.6935201740264892, "val_acc": 52.0}
{"epoch": 60, "training_loss": 0.6921095871925353, "training_acc": 53.0, "val_loss": 0.6935540866851807, "val_acc": 52.0}
{"epoch": 61, "training_loss": 0.6915507292747498, "training_acc": 53.0, "val_loss": 0.6935707879066467, "val_acc": 52.0}
{"epoch": 62, "training_loss": 0.6918244934082032, "training_acc": 53.0, "val_loss": 0.6935667896270752, "val_acc": 52.0}
{"epoch": 63, "training_loss": 0.6916278028488159, "training_acc": 53.0, "val_loss": 0.6935804104804992, "val_acc": 52.0}
{"epoch": 64, "training_loss": 0.6916915273666382, "training_acc": 53.0, "val_loss": 0.6936024165153504, "val_acc": 52.0}
