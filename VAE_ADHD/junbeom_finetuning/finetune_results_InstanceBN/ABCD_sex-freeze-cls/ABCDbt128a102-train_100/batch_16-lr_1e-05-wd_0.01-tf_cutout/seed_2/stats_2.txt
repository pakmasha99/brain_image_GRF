"main_modify.py --pretrained_path /scratch/connectome/dyhan316/VAE_ADHD/barlowtwins/pretrain_results/ABCDbt128a102.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 2 --task ABCD_sex --input_option BT_org --learning_rate 1e-5 --batch_size 16 --weight_decay 1e-2 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 0.70338538646698, "training_acc": 53.0, "val_loss": 0.7093913006782532, "val_acc": 52.0}
{"epoch": 1, "training_loss": 0.7024234533309937, "training_acc": 53.0, "val_loss": 0.7079516720771789, "val_acc": 52.0}
{"epoch": 2, "training_loss": 0.7007377481460572, "training_acc": 53.0, "val_loss": 0.7066079831123352, "val_acc": 52.0}
{"epoch": 3, "training_loss": 0.7000057172775268, "training_acc": 53.0, "val_loss": 0.7050737047195434, "val_acc": 52.0}
{"epoch": 4, "training_loss": 0.6985834884643555, "training_acc": 53.0, "val_loss": 0.7038739609718323, "val_acc": 52.0}
{"epoch": 5, "training_loss": 0.697986147403717, "training_acc": 53.0, "val_loss": 0.7026538109779358, "val_acc": 52.0}
{"epoch": 6, "training_loss": 0.6965840816497803, "training_acc": 53.0, "val_loss": 0.7018658018112183, "val_acc": 52.0}
{"epoch": 7, "training_loss": 0.6959653496742249, "training_acc": 53.0, "val_loss": 0.7008837056159973, "val_acc": 52.0}
{"epoch": 8, "training_loss": 0.6952867078781128, "training_acc": 53.0, "val_loss": 0.6999492239952088, "val_acc": 52.0}
{"epoch": 9, "training_loss": 0.6947127604484558, "training_acc": 53.0, "val_loss": 0.699405152797699, "val_acc": 52.0}
{"epoch": 10, "training_loss": 0.6938046503067017, "training_acc": 53.0, "val_loss": 0.698879132270813, "val_acc": 52.0}
{"epoch": 11, "training_loss": 0.693833839893341, "training_acc": 53.0, "val_loss": 0.6982631945610046, "val_acc": 52.0}
{"epoch": 12, "training_loss": 0.6935339760780335, "training_acc": 53.0, "val_loss": 0.6979019808769226, "val_acc": 52.0}
{"epoch": 13, "training_loss": 0.6934980797767639, "training_acc": 53.0, "val_loss": 0.6975071382522583, "val_acc": 52.0}
{"epoch": 14, "training_loss": 0.6929246997833252, "training_acc": 53.0, "val_loss": 0.697330629825592, "val_acc": 52.0}
{"epoch": 15, "training_loss": 0.6927879428863526, "training_acc": 53.0, "val_loss": 0.6970371246337891, "val_acc": 52.0}
{"epoch": 16, "training_loss": 0.6922633028030396, "training_acc": 53.0, "val_loss": 0.6968325543403625, "val_acc": 52.0}
{"epoch": 17, "training_loss": 0.6925088500976563, "training_acc": 53.0, "val_loss": 0.6964160108566284, "val_acc": 52.0}
{"epoch": 18, "training_loss": 0.6923045063018799, "training_acc": 53.0, "val_loss": 0.6962332582473755, "val_acc": 52.0}
{"epoch": 19, "training_loss": 0.692147696018219, "training_acc": 53.0, "val_loss": 0.695878894329071, "val_acc": 52.0}
{"epoch": 20, "training_loss": 0.6920205521583557, "training_acc": 53.0, "val_loss": 0.6956158971786499, "val_acc": 52.0}
{"epoch": 21, "training_loss": 0.6916750526428223, "training_acc": 53.0, "val_loss": 0.6952526164054871, "val_acc": 52.0}
{"epoch": 22, "training_loss": 0.6911767792701721, "training_acc": 53.0, "val_loss": 0.6949342060089111, "val_acc": 52.0}
{"epoch": 23, "training_loss": 0.6911798477172851, "training_acc": 53.0, "val_loss": 0.6945816850662232, "val_acc": 52.0}
{"epoch": 24, "training_loss": 0.6907013297080994, "training_acc": 53.0, "val_loss": 0.6944541501998901, "val_acc": 52.0}
{"epoch": 25, "training_loss": 0.6909473299980163, "training_acc": 53.0, "val_loss": 0.6942169880867004, "val_acc": 52.0}
{"epoch": 26, "training_loss": 0.6909292793273926, "training_acc": 53.0, "val_loss": 0.6941224026679993, "val_acc": 52.0}
{"epoch": 27, "training_loss": 0.6908604907989502, "training_acc": 53.0, "val_loss": 0.6939865183830262, "val_acc": 52.0}
{"epoch": 28, "training_loss": 0.690305027961731, "training_acc": 53.0, "val_loss": 0.693906683921814, "val_acc": 52.0}
{"epoch": 29, "training_loss": 0.6907028150558472, "training_acc": 53.0, "val_loss": 0.6938542604446412, "val_acc": 52.0}
{"epoch": 30, "training_loss": 0.6904355382919312, "training_acc": 53.0, "val_loss": 0.6937093782424927, "val_acc": 52.0}
{"epoch": 31, "training_loss": 0.6904670000076294, "training_acc": 53.0, "val_loss": 0.693722755908966, "val_acc": 52.0}
{"epoch": 32, "training_loss": 0.6907647275924682, "training_acc": 53.0, "val_loss": 0.6936405563354492, "val_acc": 52.0}
{"epoch": 33, "training_loss": 0.6905776572227478, "training_acc": 53.0, "val_loss": 0.6935049510002136, "val_acc": 52.0}
{"epoch": 34, "training_loss": 0.6902564096450806, "training_acc": 53.0, "val_loss": 0.693434841632843, "val_acc": 52.0}
{"epoch": 35, "training_loss": 0.6905025291442871, "training_acc": 53.0, "val_loss": 0.6933890891075134, "val_acc": 52.0}
{"epoch": 36, "training_loss": 0.6900901699066162, "training_acc": 53.0, "val_loss": 0.6933583569526672, "val_acc": 52.0}
{"epoch": 37, "training_loss": 0.6905260014533997, "training_acc": 53.0, "val_loss": 0.6933750224113464, "val_acc": 52.0}
{"epoch": 38, "training_loss": 0.6895786857604981, "training_acc": 53.0, "val_loss": 0.6933649492263794, "val_acc": 52.0}
{"epoch": 39, "training_loss": 0.6900944757461548, "training_acc": 53.0, "val_loss": 0.6934112548828125, "val_acc": 52.0}
{"epoch": 40, "training_loss": 0.6903600215911865, "training_acc": 53.0, "val_loss": 0.693377480506897, "val_acc": 52.0}
{"epoch": 41, "training_loss": 0.6906343173980712, "training_acc": 53.0, "val_loss": 0.6933717608451844, "val_acc": 52.0}
{"epoch": 42, "training_loss": 0.6904824233055115, "training_acc": 53.0, "val_loss": 0.6932873249053955, "val_acc": 52.0}
{"epoch": 43, "training_loss": 0.6899824571609497, "training_acc": 53.0, "val_loss": 0.6932993578910828, "val_acc": 52.0}
{"epoch": 44, "training_loss": 0.6904315376281738, "training_acc": 53.0, "val_loss": 0.6933257293701172, "val_acc": 52.0}
{"epoch": 45, "training_loss": 0.6903466606140136, "training_acc": 53.0, "val_loss": 0.6934678626060485, "val_acc": 52.0}
{"epoch": 46, "training_loss": 0.690311324596405, "training_acc": 53.0, "val_loss": 0.6935966157913208, "val_acc": 52.0}
{"epoch": 47, "training_loss": 0.690396385192871, "training_acc": 53.0, "val_loss": 0.6935701274871826, "val_acc": 52.0}
{"epoch": 48, "training_loss": 0.6906418085098267, "training_acc": 53.0, "val_loss": 0.6935261845588684, "val_acc": 52.0}
{"epoch": 49, "training_loss": 0.6905947780609131, "training_acc": 53.0, "val_loss": 0.6933966064453125, "val_acc": 52.0}
{"epoch": 50, "training_loss": 0.6902017402648926, "training_acc": 53.0, "val_loss": 0.6932795000076294, "val_acc": 52.0}
{"epoch": 51, "training_loss": 0.6901936149597168, "training_acc": 53.0, "val_loss": 0.6931239342689515, "val_acc": 52.0}
{"epoch": 52, "training_loss": 0.6898522591590881, "training_acc": 53.0, "val_loss": 0.6931063771247864, "val_acc": 52.0}
{"epoch": 53, "training_loss": 0.6900886058807373, "training_acc": 53.0, "val_loss": 0.6930209136009217, "val_acc": 52.0}
{"epoch": 54, "training_loss": 0.6897975707054138, "training_acc": 53.0, "val_loss": 0.6930541348457336, "val_acc": 52.0}
{"epoch": 55, "training_loss": 0.6897382283210755, "training_acc": 53.0, "val_loss": 0.6930259418487549, "val_acc": 52.0}
{"epoch": 56, "training_loss": 0.6899966287612915, "training_acc": 53.0, "val_loss": 0.6930642318725586, "val_acc": 52.0}
{"epoch": 57, "training_loss": 0.689789559841156, "training_acc": 53.0, "val_loss": 0.6930871486663819, "val_acc": 52.0}
{"epoch": 58, "training_loss": 0.6904572868347167, "training_acc": 53.0, "val_loss": 0.6931062030792237, "val_acc": 52.0}
{"epoch": 59, "training_loss": 0.6899430060386658, "training_acc": 53.0, "val_loss": 0.6932249879837036, "val_acc": 52.0}
{"epoch": 60, "training_loss": 0.6902844905853271, "training_acc": 53.0, "val_loss": 0.6931918215751648, "val_acc": 52.0}
{"epoch": 61, "training_loss": 0.6905442523956299, "training_acc": 53.0, "val_loss": 0.6931767725944519, "val_acc": 52.0}
{"epoch": 62, "training_loss": 0.6901466560363769, "training_acc": 53.0, "val_loss": 0.6930936551094056, "val_acc": 52.0}
{"epoch": 63, "training_loss": 0.6901520133018494, "training_acc": 53.0, "val_loss": 0.69303861618042, "val_acc": 52.0}
{"epoch": 64, "training_loss": 0.6899874997138977, "training_acc": 53.0, "val_loss": 0.692988440990448, "val_acc": 52.0}
{"epoch": 65, "training_loss": 0.6898984384536743, "training_acc": 53.0, "val_loss": 0.6930122590065002, "val_acc": 52.0}
{"epoch": 66, "training_loss": 0.6899459552764893, "training_acc": 53.0, "val_loss": 0.6930608439445496, "val_acc": 52.0}
{"epoch": 67, "training_loss": 0.6902248930931091, "training_acc": 53.0, "val_loss": 0.6931117367744446, "val_acc": 52.0}
{"epoch": 68, "training_loss": 0.6901303243637085, "training_acc": 53.0, "val_loss": 0.6930314278602601, "val_acc": 52.0}
{"epoch": 69, "training_loss": 0.6900472974777222, "training_acc": 53.0, "val_loss": 0.6929269075393677, "val_acc": 52.0}
{"epoch": 70, "training_loss": 0.6903451180458069, "training_acc": 53.0, "val_loss": 0.6929036736488342, "val_acc": 52.0}
{"epoch": 71, "training_loss": 0.6898555111885071, "training_acc": 53.0, "val_loss": 0.692953712940216, "val_acc": 52.0}
{"epoch": 72, "training_loss": 0.68993727684021, "training_acc": 53.0, "val_loss": 0.6929934906959534, "val_acc": 52.0}
{"epoch": 73, "training_loss": 0.690107307434082, "training_acc": 53.0, "val_loss": 0.6930209946632385, "val_acc": 52.0}
{"epoch": 74, "training_loss": 0.6895827579498292, "training_acc": 53.0, "val_loss": 0.6929579615592957, "val_acc": 52.0}
{"epoch": 75, "training_loss": 0.689608120918274, "training_acc": 53.0, "val_loss": 0.692938323020935, "val_acc": 52.0}
{"epoch": 76, "training_loss": 0.6903733396530152, "training_acc": 53.0, "val_loss": 0.6928869152069091, "val_acc": 52.0}
{"epoch": 77, "training_loss": 0.6897556781768799, "training_acc": 53.0, "val_loss": 0.6928113842010498, "val_acc": 52.0}
{"epoch": 78, "training_loss": 0.6894988560676575, "training_acc": 53.0, "val_loss": 0.6927003049850464, "val_acc": 52.0}
{"epoch": 79, "training_loss": 0.6896833539009094, "training_acc": 53.0, "val_loss": 0.6926449489593506, "val_acc": 52.0}
{"epoch": 80, "training_loss": 0.6898417615890503, "training_acc": 53.0, "val_loss": 0.6926580405235291, "val_acc": 52.0}
{"epoch": 81, "training_loss": 0.689458270072937, "training_acc": 53.0, "val_loss": 0.6927019834518433, "val_acc": 52.0}
{"epoch": 82, "training_loss": 0.690076379776001, "training_acc": 53.0, "val_loss": 0.692686471939087, "val_acc": 52.0}
{"epoch": 83, "training_loss": 0.6900693511962891, "training_acc": 53.0, "val_loss": 0.6926850533485412, "val_acc": 52.0}
{"epoch": 84, "training_loss": 0.6903543257713318, "training_acc": 53.0, "val_loss": 0.6927309846878051, "val_acc": 52.0}
{"epoch": 85, "training_loss": 0.6902518248558045, "training_acc": 53.0, "val_loss": 0.6927944946289063, "val_acc": 52.0}
{"epoch": 86, "training_loss": 0.6901873254776001, "training_acc": 53.0, "val_loss": 0.6927659153938294, "val_acc": 52.0}
{"epoch": 87, "training_loss": 0.6895669221878051, "training_acc": 53.0, "val_loss": 0.6926749730110169, "val_acc": 52.0}
{"epoch": 88, "training_loss": 0.6900197172164917, "training_acc": 53.0, "val_loss": 0.6926256585121154, "val_acc": 52.0}
{"epoch": 89, "training_loss": 0.6898672676086426, "training_acc": 53.0, "val_loss": 0.6926017522811889, "val_acc": 52.0}
{"epoch": 90, "training_loss": 0.6897767615318299, "training_acc": 53.0, "val_loss": 0.6925342583656311, "val_acc": 52.0}
{"epoch": 91, "training_loss": 0.689976167678833, "training_acc": 53.0, "val_loss": 0.6925085043907165, "val_acc": 52.0}
{"epoch": 92, "training_loss": 0.6901243114471436, "training_acc": 53.0, "val_loss": 0.692520067691803, "val_acc": 52.0}
{"epoch": 93, "training_loss": 0.6901488542556763, "training_acc": 53.0, "val_loss": 0.6925061845779419, "val_acc": 52.0}
{"epoch": 94, "training_loss": 0.6895571565628051, "training_acc": 53.0, "val_loss": 0.6924393391609192, "val_acc": 52.0}
{"epoch": 95, "training_loss": 0.6901009440422058, "training_acc": 53.0, "val_loss": 0.692408709526062, "val_acc": 52.0}
{"epoch": 96, "training_loss": 0.6896448922157288, "training_acc": 53.0, "val_loss": 0.6924221038818359, "val_acc": 52.0}
{"epoch": 97, "training_loss": 0.6900435352325439, "training_acc": 53.0, "val_loss": 0.6924763512611389, "val_acc": 52.0}
{"epoch": 98, "training_loss": 0.6902946758270264, "training_acc": 53.0, "val_loss": 0.6925199890136718, "val_acc": 52.0}
{"epoch": 99, "training_loss": 0.6899764204025268, "training_acc": 53.0, "val_loss": 0.6925049638748169, "val_acc": 52.0}
