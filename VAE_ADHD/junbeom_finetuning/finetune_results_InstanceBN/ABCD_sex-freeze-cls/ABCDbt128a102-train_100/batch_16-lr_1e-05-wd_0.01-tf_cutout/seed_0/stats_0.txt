"main_modify.py --pretrained_path /scratch/connectome/dyhan316/VAE_ADHD/barlowtwins/pretrain_results/ABCDbt128a102.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option BT_org --learning_rate 1e-5 --batch_size 16 --weight_decay 1e-2 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 0.6923147487640381, "training_acc": 52.0, "val_loss": 0.6884439182281494, "val_acc": 56.0}
{"epoch": 1, "training_loss": 0.6923983502388, "training_acc": 52.0, "val_loss": 0.6883301281929016, "val_acc": 56.0}
{"epoch": 2, "training_loss": 0.6924011754989624, "training_acc": 52.0, "val_loss": 0.6882950305938721, "val_acc": 56.0}
{"epoch": 3, "training_loss": 0.6921694350242614, "training_acc": 52.0, "val_loss": 0.688079674243927, "val_acc": 56.0}
{"epoch": 4, "training_loss": 0.6923666167259216, "training_acc": 52.0, "val_loss": 0.6881327486038208, "val_acc": 56.0}
{"epoch": 5, "training_loss": 0.6921550726890564, "training_acc": 52.0, "val_loss": 0.6880094027519226, "val_acc": 56.0}
{"epoch": 6, "training_loss": 0.6920298552513122, "training_acc": 52.0, "val_loss": 0.687941825389862, "val_acc": 56.0}
{"epoch": 7, "training_loss": 0.6921340990066528, "training_acc": 52.0, "val_loss": 0.6879734849929809, "val_acc": 56.0}
{"epoch": 8, "training_loss": 0.6920341730117798, "training_acc": 52.0, "val_loss": 0.6878391695022583, "val_acc": 56.0}
{"epoch": 9, "training_loss": 0.6921355819702149, "training_acc": 52.0, "val_loss": 0.687899935245514, "val_acc": 56.0}
{"epoch": 10, "training_loss": 0.6923234176635742, "training_acc": 52.0, "val_loss": 0.6880887389183045, "val_acc": 56.0}
{"epoch": 11, "training_loss": 0.6919940423965454, "training_acc": 52.0, "val_loss": 0.688067615032196, "val_acc": 56.0}
{"epoch": 12, "training_loss": 0.6926405858993531, "training_acc": 52.0, "val_loss": 0.6877797842025757, "val_acc": 56.0}
{"epoch": 13, "training_loss": 0.6919446611404418, "training_acc": 52.0, "val_loss": 0.6877242064476013, "val_acc": 56.0}
{"epoch": 14, "training_loss": 0.6922611284255982, "training_acc": 52.0, "val_loss": 0.6875758457183838, "val_acc": 56.0}
{"epoch": 15, "training_loss": 0.6923424935340882, "training_acc": 52.0, "val_loss": 0.6875055074691773, "val_acc": 56.0}
{"epoch": 16, "training_loss": 0.6926981544494629, "training_acc": 52.0, "val_loss": 0.6872334671020508, "val_acc": 56.0}
{"epoch": 17, "training_loss": 0.6919695830345154, "training_acc": 52.0, "val_loss": 0.6872804617881775, "val_acc": 56.0}
{"epoch": 18, "training_loss": 0.6922938561439514, "training_acc": 52.0, "val_loss": 0.6873942565917969, "val_acc": 56.0}
{"epoch": 19, "training_loss": 0.6921396255493164, "training_acc": 52.0, "val_loss": 0.6875708055496216, "val_acc": 56.0}
{"epoch": 20, "training_loss": 0.6923619937896729, "training_acc": 52.0, "val_loss": 0.6875779747962951, "val_acc": 56.0}
{"epoch": 21, "training_loss": 0.6917437219619751, "training_acc": 52.0, "val_loss": 0.6876146245002747, "val_acc": 56.0}
{"epoch": 22, "training_loss": 0.6919287872314454, "training_acc": 52.0, "val_loss": 0.6875537967681885, "val_acc": 56.0}
{"epoch": 23, "training_loss": 0.6921297073364258, "training_acc": 52.0, "val_loss": 0.6875994610786438, "val_acc": 56.0}
{"epoch": 24, "training_loss": 0.6924573493003845, "training_acc": 52.0, "val_loss": 0.6874503827095032, "val_acc": 56.0}
{"epoch": 25, "training_loss": 0.6923246955871583, "training_acc": 52.0, "val_loss": 0.6875098299980164, "val_acc": 56.0}
{"epoch": 26, "training_loss": 0.6915787649154663, "training_acc": 52.0, "val_loss": 0.6874933218955994, "val_acc": 56.0}
{"epoch": 27, "training_loss": 0.6918027639389038, "training_acc": 52.0, "val_loss": 0.6875566411018371, "val_acc": 56.0}
{"epoch": 28, "training_loss": 0.6921244812011719, "training_acc": 52.0, "val_loss": 0.6875768685340882, "val_acc": 56.0}
{"epoch": 29, "training_loss": 0.6922613787651062, "training_acc": 52.0, "val_loss": 0.6874788784980774, "val_acc": 56.0}
{"epoch": 30, "training_loss": 0.6920817852020263, "training_acc": 52.0, "val_loss": 0.6871970105171203, "val_acc": 56.0}
{"epoch": 31, "training_loss": 0.6920712041854858, "training_acc": 52.0, "val_loss": 0.6870635986328125, "val_acc": 56.0}
{"epoch": 32, "training_loss": 0.6919498801231384, "training_acc": 52.0, "val_loss": 0.6867725324630737, "val_acc": 56.0}
{"epoch": 33, "training_loss": 0.6923938059806823, "training_acc": 52.0, "val_loss": 0.6866204643249512, "val_acc": 56.0}
{"epoch": 34, "training_loss": 0.6923946022987366, "training_acc": 52.0, "val_loss": 0.6866378808021545, "val_acc": 56.0}
{"epoch": 35, "training_loss": 0.6918320488929749, "training_acc": 52.0, "val_loss": 0.6867595672607422, "val_acc": 56.0}
{"epoch": 36, "training_loss": 0.6925885486602783, "training_acc": 52.0, "val_loss": 0.6867566299438477, "val_acc": 56.0}
{"epoch": 37, "training_loss": 0.6927115797996521, "training_acc": 52.0, "val_loss": 0.6867114973068237, "val_acc": 56.0}
{"epoch": 38, "training_loss": 0.6924919748306274, "training_acc": 52.0, "val_loss": 0.6867605304718017, "val_acc": 56.0}
{"epoch": 39, "training_loss": 0.6925236320495606, "training_acc": 52.0, "val_loss": 0.6868196773529053, "val_acc": 56.0}
{"epoch": 40, "training_loss": 0.692490394115448, "training_acc": 52.0, "val_loss": 0.6869735002517701, "val_acc": 56.0}
{"epoch": 41, "training_loss": 0.6918870401382446, "training_acc": 52.0, "val_loss": 0.687014353275299, "val_acc": 56.0}
{"epoch": 42, "training_loss": 0.6918676710128784, "training_acc": 52.0, "val_loss": 0.6870550179481506, "val_acc": 56.0}
{"epoch": 43, "training_loss": 0.6917115521430969, "training_acc": 52.0, "val_loss": 0.6871000599861145, "val_acc": 56.0}
{"epoch": 44, "training_loss": 0.6924173736572266, "training_acc": 52.0, "val_loss": 0.6873129773139953, "val_acc": 56.0}
{"epoch": 45, "training_loss": 0.6920826435089111, "training_acc": 52.0, "val_loss": 0.6873867106437683, "val_acc": 56.0}
{"epoch": 46, "training_loss": 0.6918266010284424, "training_acc": 52.0, "val_loss": 0.6874236130714416, "val_acc": 56.0}
{"epoch": 47, "training_loss": 0.6923211288452148, "training_acc": 52.0, "val_loss": 0.687392885684967, "val_acc": 56.0}
{"epoch": 48, "training_loss": 0.6921752142906189, "training_acc": 52.0, "val_loss": 0.6873460459709168, "val_acc": 56.0}
{"epoch": 49, "training_loss": 0.6920415663719177, "training_acc": 52.0, "val_loss": 0.6874158096313476, "val_acc": 56.0}
{"epoch": 50, "training_loss": 0.6924850726127625, "training_acc": 52.0, "val_loss": 0.6876125359535217, "val_acc": 56.0}
{"epoch": 51, "training_loss": 0.6924238538742066, "training_acc": 52.0, "val_loss": 0.6878182578086853, "val_acc": 56.0}
{"epoch": 52, "training_loss": 0.6922798252105713, "training_acc": 52.0, "val_loss": 0.688056948184967, "val_acc": 56.0}
