"main_modify.py --pretrained_path /scratch/connectome/dyhan316/VAE_ADHD/barlowtwins/pretrain_results/ABCDbt128a102.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option BT_org --learning_rate 1e-5 --batch_size 16 --weight_decay 1e-2 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 0.692180655002594, "training_acc": 53.0, "val_loss": 0.6930847048759461, "val_acc": 52.0}
{"epoch": 1, "training_loss": 0.6921235418319702, "training_acc": 53.0, "val_loss": 0.6930230951309204, "val_acc": 52.0}
{"epoch": 2, "training_loss": 0.6922375941276551, "training_acc": 53.0, "val_loss": 0.6928697204589844, "val_acc": 52.0}
{"epoch": 3, "training_loss": 0.6921622347831726, "training_acc": 53.0, "val_loss": 0.6927991914749145, "val_acc": 52.0}
{"epoch": 4, "training_loss": 0.6918097734451294, "training_acc": 53.0, "val_loss": 0.692781822681427, "val_acc": 52.0}
{"epoch": 5, "training_loss": 0.6915181159973145, "training_acc": 53.0, "val_loss": 0.6927558994293213, "val_acc": 52.0}
{"epoch": 6, "training_loss": 0.6918040323257446, "training_acc": 53.0, "val_loss": 0.6927555704116821, "val_acc": 52.0}
{"epoch": 7, "training_loss": 0.6921168351173401, "training_acc": 53.0, "val_loss": 0.6927740406990052, "val_acc": 52.0}
{"epoch": 8, "training_loss": 0.6917851948738098, "training_acc": 53.0, "val_loss": 0.6928821682929993, "val_acc": 52.0}
{"epoch": 9, "training_loss": 0.6923857164382935, "training_acc": 53.0, "val_loss": 0.6928764295578003, "val_acc": 52.0}
{"epoch": 10, "training_loss": 0.6915928506851197, "training_acc": 53.0, "val_loss": 0.6928117322921753, "val_acc": 52.0}
{"epoch": 11, "training_loss": 0.6920946025848389, "training_acc": 53.0, "val_loss": 0.6927679467201233, "val_acc": 52.0}
{"epoch": 12, "training_loss": 0.6913401699066162, "training_acc": 53.0, "val_loss": 0.6926799368858337, "val_acc": 52.0}
{"epoch": 13, "training_loss": 0.6918002939224244, "training_acc": 53.0, "val_loss": 0.6925909280776977, "val_acc": 52.0}
{"epoch": 14, "training_loss": 0.6919497203826904, "training_acc": 53.0, "val_loss": 0.6925841879844665, "val_acc": 52.0}
{"epoch": 15, "training_loss": 0.6919345855712891, "training_acc": 53.0, "val_loss": 0.6926226711273193, "val_acc": 52.0}
{"epoch": 16, "training_loss": 0.6915889358520508, "training_acc": 53.0, "val_loss": 0.6926492166519165, "val_acc": 52.0}
{"epoch": 17, "training_loss": 0.6920502996444702, "training_acc": 53.0, "val_loss": 0.6926266074180603, "val_acc": 52.0}
{"epoch": 18, "training_loss": 0.6917300534248352, "training_acc": 53.0, "val_loss": 0.6926096320152283, "val_acc": 52.0}
{"epoch": 19, "training_loss": 0.691539192199707, "training_acc": 53.0, "val_loss": 0.6925793814659119, "val_acc": 52.0}
{"epoch": 20, "training_loss": 0.6917118835449219, "training_acc": 53.0, "val_loss": 0.6925359582901001, "val_acc": 52.0}
{"epoch": 21, "training_loss": 0.6918183183670044, "training_acc": 53.0, "val_loss": 0.6925057578086853, "val_acc": 52.0}
{"epoch": 22, "training_loss": 0.6924686503410339, "training_acc": 53.0, "val_loss": 0.6924675083160401, "val_acc": 52.0}
{"epoch": 23, "training_loss": 0.6918675374984741, "training_acc": 53.0, "val_loss": 0.6924744391441345, "val_acc": 52.0}
{"epoch": 24, "training_loss": 0.6915992546081543, "training_acc": 53.0, "val_loss": 0.6924861192703247, "val_acc": 52.0}
{"epoch": 25, "training_loss": 0.6919025206565856, "training_acc": 53.0, "val_loss": 0.6924802160263062, "val_acc": 52.0}
{"epoch": 26, "training_loss": 0.6921348786354065, "training_acc": 53.0, "val_loss": 0.6924698185920716, "val_acc": 52.0}
{"epoch": 27, "training_loss": 0.6918228125572204, "training_acc": 53.0, "val_loss": 0.6924522709846497, "val_acc": 52.0}
{"epoch": 28, "training_loss": 0.6916705656051636, "training_acc": 53.0, "val_loss": 0.6924451184272766, "val_acc": 52.0}
{"epoch": 29, "training_loss": 0.6925545883178711, "training_acc": 53.0, "val_loss": 0.692435142993927, "val_acc": 52.0}
{"epoch": 30, "training_loss": 0.6918100786209106, "training_acc": 53.0, "val_loss": 0.6924382352828979, "val_acc": 52.0}
{"epoch": 31, "training_loss": 0.6915577530860901, "training_acc": 53.0, "val_loss": 0.6924330902099609, "val_acc": 52.0}
{"epoch": 32, "training_loss": 0.6918110179901124, "training_acc": 53.0, "val_loss": 0.692436339855194, "val_acc": 52.0}
{"epoch": 33, "training_loss": 0.6917050981521606, "training_acc": 53.0, "val_loss": 0.6924413704872131, "val_acc": 52.0}
{"epoch": 34, "training_loss": 0.6917193913459778, "training_acc": 53.0, "val_loss": 0.6924474263191223, "val_acc": 52.0}
{"epoch": 35, "training_loss": 0.6918062686920166, "training_acc": 53.0, "val_loss": 0.692454674243927, "val_acc": 52.0}
{"epoch": 36, "training_loss": 0.6921565294265747, "training_acc": 53.0, "val_loss": 0.6924566745758056, "val_acc": 52.0}
{"epoch": 37, "training_loss": 0.6921339273452759, "training_acc": 53.0, "val_loss": 0.692473738193512, "val_acc": 52.0}
{"epoch": 38, "training_loss": 0.6917111206054688, "training_acc": 53.0, "val_loss": 0.692462887763977, "val_acc": 52.0}
{"epoch": 39, "training_loss": 0.692374336719513, "training_acc": 53.0, "val_loss": 0.6924734258651734, "val_acc": 52.0}
{"epoch": 40, "training_loss": 0.6917148900032043, "training_acc": 53.0, "val_loss": 0.6924632000923157, "val_acc": 52.0}
{"epoch": 41, "training_loss": 0.6919367551803589, "training_acc": 53.0, "val_loss": 0.69246577501297, "val_acc": 52.0}
{"epoch": 42, "training_loss": 0.6917123079299927, "training_acc": 53.0, "val_loss": 0.6924491572380066, "val_acc": 52.0}
{"epoch": 43, "training_loss": 0.6919010090827942, "training_acc": 53.0, "val_loss": 0.6924350523948669, "val_acc": 52.0}
{"epoch": 44, "training_loss": 0.6916288638114929, "training_acc": 53.0, "val_loss": 0.6924380779266357, "val_acc": 52.0}
{"epoch": 45, "training_loss": 0.6919712543487548, "training_acc": 53.0, "val_loss": 0.6924521493911743, "val_acc": 52.0}
{"epoch": 46, "training_loss": 0.6913663816452026, "training_acc": 53.0, "val_loss": 0.6924797773361206, "val_acc": 52.0}
{"epoch": 47, "training_loss": 0.6918436741828918, "training_acc": 53.0, "val_loss": 0.6925078129768372, "val_acc": 52.0}
{"epoch": 48, "training_loss": 0.6918147659301758, "training_acc": 53.0, "val_loss": 0.692538640499115, "val_acc": 52.0}
{"epoch": 49, "training_loss": 0.6917457294464111, "training_acc": 53.0, "val_loss": 0.6925509595870971, "val_acc": 52.0}
{"epoch": 50, "training_loss": 0.692356686592102, "training_acc": 53.0, "val_loss": 0.6925588917732238, "val_acc": 52.0}
