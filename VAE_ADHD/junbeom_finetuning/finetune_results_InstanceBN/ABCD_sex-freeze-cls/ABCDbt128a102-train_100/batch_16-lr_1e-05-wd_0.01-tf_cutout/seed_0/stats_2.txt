"main_modify.py --pretrained_path /scratch/connectome/dyhan316/VAE_ADHD/barlowtwins/pretrain_results/ABCDbt128a102.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option BT_org --learning_rate 1e-5 --batch_size 16 --weight_decay 1e-2 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 0.6923821449279786, "training_acc": 53.0, "val_loss": 0.6956902265548706, "val_acc": 52.0}
{"epoch": 1, "training_loss": 0.6920036172866821, "training_acc": 53.0, "val_loss": 0.6954707884788514, "val_acc": 52.0}
{"epoch": 2, "training_loss": 0.6918649911880493, "training_acc": 53.0, "val_loss": 0.6952333950996399, "val_acc": 52.0}
{"epoch": 3, "training_loss": 0.6921260190010071, "training_acc": 53.0, "val_loss": 0.6951902341842652, "val_acc": 52.0}
{"epoch": 4, "training_loss": 0.691505184173584, "training_acc": 53.0, "val_loss": 0.6950722050666809, "val_acc": 52.0}
{"epoch": 5, "training_loss": 0.6917139434814453, "training_acc": 53.0, "val_loss": 0.6949711465835571, "val_acc": 52.0}
{"epoch": 6, "training_loss": 0.6914289855957031, "training_acc": 53.0, "val_loss": 0.6949331259727478, "val_acc": 52.0}
{"epoch": 7, "training_loss": 0.6909778618812561, "training_acc": 53.0, "val_loss": 0.6948015141487122, "val_acc": 52.0}
{"epoch": 8, "training_loss": 0.6915622639656067, "training_acc": 53.0, "val_loss": 0.694554238319397, "val_acc": 52.0}
{"epoch": 9, "training_loss": 0.6910116672515869, "training_acc": 53.0, "val_loss": 0.6943928861618042, "val_acc": 52.0}
{"epoch": 10, "training_loss": 0.6909773921966553, "training_acc": 53.0, "val_loss": 0.6942634081840515, "val_acc": 52.0}
{"epoch": 11, "training_loss": 0.6904908227920532, "training_acc": 53.0, "val_loss": 0.6941265058517456, "val_acc": 52.0}
{"epoch": 12, "training_loss": 0.6907046270370484, "training_acc": 53.0, "val_loss": 0.6939667177200317, "val_acc": 52.0}
{"epoch": 13, "training_loss": 0.6911008071899414, "training_acc": 53.0, "val_loss": 0.6938432884216309, "val_acc": 52.0}
{"epoch": 14, "training_loss": 0.690939667224884, "training_acc": 53.0, "val_loss": 0.6937128376960754, "val_acc": 52.0}
{"epoch": 15, "training_loss": 0.6908770632743836, "training_acc": 53.0, "val_loss": 0.6936696553230286, "val_acc": 52.0}
{"epoch": 16, "training_loss": 0.6906961250305176, "training_acc": 53.0, "val_loss": 0.6935954666137696, "val_acc": 52.0}
{"epoch": 17, "training_loss": 0.6905038833618165, "training_acc": 53.0, "val_loss": 0.6936306095123291, "val_acc": 52.0}
{"epoch": 18, "training_loss": 0.6908072113990784, "training_acc": 53.0, "val_loss": 0.6936455535888671, "val_acc": 52.0}
{"epoch": 19, "training_loss": 0.6905790662765503, "training_acc": 53.0, "val_loss": 0.6936165881156922, "val_acc": 52.0}
{"epoch": 20, "training_loss": 0.6906414961814881, "training_acc": 53.0, "val_loss": 0.6936591863632202, "val_acc": 52.0}
{"epoch": 21, "training_loss": 0.6909067964553833, "training_acc": 53.0, "val_loss": 0.6936839985847473, "val_acc": 52.0}
{"epoch": 22, "training_loss": 0.6904743146896363, "training_acc": 53.0, "val_loss": 0.6935812616348267, "val_acc": 52.0}
{"epoch": 23, "training_loss": 0.6908340549468994, "training_acc": 53.0, "val_loss": 0.6935062909126282, "val_acc": 52.0}
{"epoch": 24, "training_loss": 0.6904788851737976, "training_acc": 53.0, "val_loss": 0.6934508490562439, "val_acc": 52.0}
{"epoch": 25, "training_loss": 0.6904154109954834, "training_acc": 53.0, "val_loss": 0.6934062600135803, "val_acc": 52.0}
{"epoch": 26, "training_loss": 0.6904645323753357, "training_acc": 53.0, "val_loss": 0.6933226060867309, "val_acc": 52.0}
{"epoch": 27, "training_loss": 0.6905717992782593, "training_acc": 53.0, "val_loss": 0.6933122277259827, "val_acc": 52.0}
{"epoch": 28, "training_loss": 0.6904876518249512, "training_acc": 53.0, "val_loss": 0.6932920098304749, "val_acc": 52.0}
{"epoch": 29, "training_loss": 0.690804295539856, "training_acc": 53.0, "val_loss": 0.6932722473144531, "val_acc": 52.0}
{"epoch": 30, "training_loss": 0.6903595352172851, "training_acc": 53.0, "val_loss": 0.6932557773590088, "val_acc": 52.0}
{"epoch": 31, "training_loss": 0.6908671331405639, "training_acc": 53.0, "val_loss": 0.6932538414001465, "val_acc": 52.0}
{"epoch": 32, "training_loss": 0.690739426612854, "training_acc": 53.0, "val_loss": 0.693271746635437, "val_acc": 52.0}
{"epoch": 33, "training_loss": 0.690584373474121, "training_acc": 53.0, "val_loss": 0.693286440372467, "val_acc": 52.0}
{"epoch": 34, "training_loss": 0.6902554893493652, "training_acc": 53.0, "val_loss": 0.6932485699653625, "val_acc": 52.0}
{"epoch": 35, "training_loss": 0.691036868095398, "training_acc": 53.0, "val_loss": 0.6932338666915894, "val_acc": 52.0}
{"epoch": 36, "training_loss": 0.690483615398407, "training_acc": 53.0, "val_loss": 0.6932281851768494, "val_acc": 52.0}
{"epoch": 37, "training_loss": 0.690928430557251, "training_acc": 53.0, "val_loss": 0.6932166314125061, "val_acc": 52.0}
{"epoch": 38, "training_loss": 0.6905644035339356, "training_acc": 53.0, "val_loss": 0.6932140350341797, "val_acc": 52.0}
{"epoch": 39, "training_loss": 0.6906289315223694, "training_acc": 53.0, "val_loss": 0.693219804763794, "val_acc": 52.0}
{"epoch": 40, "training_loss": 0.6909602189064026, "training_acc": 53.0, "val_loss": 0.6932294917106628, "val_acc": 52.0}
{"epoch": 41, "training_loss": 0.6904308891296387, "training_acc": 53.0, "val_loss": 0.693265266418457, "val_acc": 52.0}
{"epoch": 42, "training_loss": 0.6903032970428467, "training_acc": 53.0, "val_loss": 0.6932642555236816, "val_acc": 52.0}
{"epoch": 43, "training_loss": 0.6905788993835449, "training_acc": 53.0, "val_loss": 0.693244321346283, "val_acc": 52.0}
{"epoch": 44, "training_loss": 0.6909748411178589, "training_acc": 53.0, "val_loss": 0.6932266545295716, "val_acc": 52.0}
{"epoch": 45, "training_loss": 0.6905067873001098, "training_acc": 53.0, "val_loss": 0.6932059526443481, "val_acc": 52.0}
{"epoch": 46, "training_loss": 0.6910628461837769, "training_acc": 53.0, "val_loss": 0.6932080888748169, "val_acc": 52.0}
{"epoch": 47, "training_loss": 0.6901902484893799, "training_acc": 53.0, "val_loss": 0.6931953072547913, "val_acc": 52.0}
{"epoch": 48, "training_loss": 0.6912440156936646, "training_acc": 53.0, "val_loss": 0.6931878447532653, "val_acc": 52.0}
{"epoch": 49, "training_loss": 0.6905337810516358, "training_acc": 53.0, "val_loss": 0.6931926679611206, "val_acc": 52.0}
{"epoch": 50, "training_loss": 0.6905349826812744, "training_acc": 53.0, "val_loss": 0.6932171678543091, "val_acc": 52.0}
{"epoch": 51, "training_loss": 0.6904720640182496, "training_acc": 53.0, "val_loss": 0.6932384610176087, "val_acc": 52.0}
{"epoch": 52, "training_loss": 0.6913564920425415, "training_acc": 53.0, "val_loss": 0.6932584190368652, "val_acc": 52.0}
{"epoch": 53, "training_loss": 0.6904818415641785, "training_acc": 53.0, "val_loss": 0.6932728338241577, "val_acc": 52.0}
{"epoch": 54, "training_loss": 0.6909879398345947, "training_acc": 53.0, "val_loss": 0.6933267521858215, "val_acc": 52.0}
{"epoch": 55, "training_loss": 0.690786805152893, "training_acc": 53.0, "val_loss": 0.6934035968780518, "val_acc": 52.0}
{"epoch": 56, "training_loss": 0.6907499122619629, "training_acc": 53.0, "val_loss": 0.6934365248680114, "val_acc": 52.0}
{"epoch": 57, "training_loss": 0.6904556035995484, "training_acc": 53.0, "val_loss": 0.6934823203086853, "val_acc": 52.0}
{"epoch": 58, "training_loss": 0.6902230787277222, "training_acc": 53.0, "val_loss": 0.6934625458717346, "val_acc": 52.0}
{"epoch": 59, "training_loss": 0.6908250260353088, "training_acc": 53.0, "val_loss": 0.6933860182762146, "val_acc": 52.0}
{"epoch": 60, "training_loss": 0.690917637348175, "training_acc": 53.0, "val_loss": 0.6933592581748962, "val_acc": 52.0}
{"epoch": 61, "training_loss": 0.6904221820831299, "training_acc": 53.0, "val_loss": 0.6933637714385986, "val_acc": 52.0}
{"epoch": 62, "training_loss": 0.6905286979675292, "training_acc": 53.0, "val_loss": 0.6933932518959045, "val_acc": 52.0}
{"epoch": 63, "training_loss": 0.6907254505157471, "training_acc": 53.0, "val_loss": 0.693420193195343, "val_acc": 52.0}
{"epoch": 64, "training_loss": 0.6905092430114746, "training_acc": 53.0, "val_loss": 0.6934023380279541, "val_acc": 52.0}
{"epoch": 65, "training_loss": 0.6904321503639221, "training_acc": 53.0, "val_loss": 0.6934159278869629, "val_acc": 52.0}
{"epoch": 66, "training_loss": 0.6905669331550598, "training_acc": 53.0, "val_loss": 0.693430666923523, "val_acc": 52.0}
{"epoch": 67, "training_loss": 0.6902598285675049, "training_acc": 53.0, "val_loss": 0.6934231162071228, "val_acc": 52.0}
