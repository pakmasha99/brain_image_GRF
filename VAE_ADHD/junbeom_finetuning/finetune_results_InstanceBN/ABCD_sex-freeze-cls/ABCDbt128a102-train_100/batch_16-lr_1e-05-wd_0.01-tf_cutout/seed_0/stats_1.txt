"main_modify.py --pretrained_path /scratch/connectome/dyhan316/VAE_ADHD/barlowtwins/pretrain_results/ABCDbt128a102.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option BT_org --learning_rate 1e-5 --batch_size 16 --weight_decay 1e-2 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 0.7009783601760864, "training_acc": 47.0, "val_loss": 0.6958435988426208, "val_acc": 48.0}
{"epoch": 1, "training_loss": 0.7003441476821899, "training_acc": 47.0, "val_loss": 0.6953340649604798, "val_acc": 48.0}
{"epoch": 2, "training_loss": 0.6993152356147766, "training_acc": 47.0, "val_loss": 0.6947974705696106, "val_acc": 48.0}
{"epoch": 3, "training_loss": 0.6992114543914795, "training_acc": 47.0, "val_loss": 0.6943400645256043, "val_acc": 48.0}
{"epoch": 4, "training_loss": 0.6984036445617676, "training_acc": 47.0, "val_loss": 0.6938806247711181, "val_acc": 48.0}
{"epoch": 5, "training_loss": 0.6983741760253906, "training_acc": 47.0, "val_loss": 0.693367850780487, "val_acc": 48.0}
{"epoch": 6, "training_loss": 0.6974205493927002, "training_acc": 47.0, "val_loss": 0.6930631303787231, "val_acc": 48.0}
{"epoch": 7, "training_loss": 0.6965179824829102, "training_acc": 47.0, "val_loss": 0.6926398515701294, "val_acc": 48.0}
{"epoch": 8, "training_loss": 0.6961740851402283, "training_acc": 47.0, "val_loss": 0.6924245572090149, "val_acc": 48.0}
{"epoch": 9, "training_loss": 0.6961259484291077, "training_acc": 47.0, "val_loss": 0.6920534706115723, "val_acc": 48.0}
{"epoch": 10, "training_loss": 0.6959660959243774, "training_acc": 47.0, "val_loss": 0.6918344616889953, "val_acc": 48.0}
{"epoch": 11, "training_loss": 0.69542955160141, "training_acc": 47.0, "val_loss": 0.6916548252105713, "val_acc": 48.0}
{"epoch": 12, "training_loss": 0.6951510047912598, "training_acc": 47.0, "val_loss": 0.6913839268684387, "val_acc": 48.0}
{"epoch": 13, "training_loss": 0.6949720335006714, "training_acc": 47.0, "val_loss": 0.6911444854736328, "val_acc": 48.0}
{"epoch": 14, "training_loss": 0.6943717265129089, "training_acc": 47.0, "val_loss": 0.6909218549728393, "val_acc": 52.0}
{"epoch": 15, "training_loss": 0.6942398619651794, "training_acc": 47.0, "val_loss": 0.6907112193107605, "val_acc": 48.0}
{"epoch": 16, "training_loss": 0.6935972738265991, "training_acc": 48.0, "val_loss": 0.6905074214935303, "val_acc": 48.0}
{"epoch": 17, "training_loss": 0.6939088296890259, "training_acc": 47.0, "val_loss": 0.6902745532989502, "val_acc": 80.0}
{"epoch": 18, "training_loss": 0.6935469102859497, "training_acc": 47.0, "val_loss": 0.6901095986366272, "val_acc": 76.0}
{"epoch": 19, "training_loss": 0.6926748895645142, "training_acc": 60.0, "val_loss": 0.6900474596023559, "val_acc": 68.0}
{"epoch": 20, "training_loss": 0.6929076647758484, "training_acc": 56.0, "val_loss": 0.6899642968177795, "val_acc": 64.0}
{"epoch": 21, "training_loss": 0.6927757692337037, "training_acc": 52.0, "val_loss": 0.6898926258087158, "val_acc": 52.0}
{"epoch": 22, "training_loss": 0.6924938559532166, "training_acc": 51.0, "val_loss": 0.6897948074340821, "val_acc": 60.0}
{"epoch": 23, "training_loss": 0.6922780442237854, "training_acc": 50.0, "val_loss": 0.6897416400909424, "val_acc": 52.0}
{"epoch": 24, "training_loss": 0.6924905347824096, "training_acc": 51.0, "val_loss": 0.6896987128257751, "val_acc": 52.0}
{"epoch": 25, "training_loss": 0.6926491117477417, "training_acc": 53.0, "val_loss": 0.6896079277992249, "val_acc": 52.0}
{"epoch": 26, "training_loss": 0.6921673440933227, "training_acc": 53.0, "val_loss": 0.6895374655723572, "val_acc": 52.0}
{"epoch": 27, "training_loss": 0.6920161700248718, "training_acc": 53.0, "val_loss": 0.6895421051979065, "val_acc": 52.0}
{"epoch": 28, "training_loss": 0.6919742059707642, "training_acc": 53.0, "val_loss": 0.6895141434669495, "val_acc": 52.0}
{"epoch": 29, "training_loss": 0.6921589493751525, "training_acc": 53.0, "val_loss": 0.689480676651001, "val_acc": 52.0}
{"epoch": 30, "training_loss": 0.6913537073135376, "training_acc": 53.0, "val_loss": 0.6894172096252441, "val_acc": 52.0}
{"epoch": 31, "training_loss": 0.6917513275146484, "training_acc": 53.0, "val_loss": 0.6894129943847657, "val_acc": 52.0}
{"epoch": 32, "training_loss": 0.6918773889541626, "training_acc": 53.0, "val_loss": 0.689397087097168, "val_acc": 52.0}
{"epoch": 33, "training_loss": 0.6914924001693725, "training_acc": 53.0, "val_loss": 0.6893807888031006, "val_acc": 52.0}
{"epoch": 34, "training_loss": 0.6916652345657348, "training_acc": 53.0, "val_loss": 0.6893755435943604, "val_acc": 52.0}
{"epoch": 35, "training_loss": 0.69180823802948, "training_acc": 53.0, "val_loss": 0.6893664956092834, "val_acc": 52.0}
{"epoch": 36, "training_loss": 0.692021198272705, "training_acc": 53.0, "val_loss": 0.6893684029579162, "val_acc": 52.0}
{"epoch": 37, "training_loss": 0.6914566469192505, "training_acc": 53.0, "val_loss": 0.6893661618232727, "val_acc": 52.0}
{"epoch": 38, "training_loss": 0.6917176008224487, "training_acc": 53.0, "val_loss": 0.6893653845787049, "val_acc": 52.0}
{"epoch": 39, "training_loss": 0.6912311244010926, "training_acc": 53.0, "val_loss": 0.6893657636642456, "val_acc": 52.0}
{"epoch": 40, "training_loss": 0.6914479660987854, "training_acc": 53.0, "val_loss": 0.6893655967712402, "val_acc": 52.0}
{"epoch": 41, "training_loss": 0.6917273902893066, "training_acc": 53.0, "val_loss": 0.6893688893318176, "val_acc": 52.0}
{"epoch": 42, "training_loss": 0.6912115240097045, "training_acc": 53.0, "val_loss": 0.6893695068359375, "val_acc": 52.0}
{"epoch": 43, "training_loss": 0.6917706465721131, "training_acc": 53.0, "val_loss": 0.6893814849853516, "val_acc": 52.0}
{"epoch": 44, "training_loss": 0.691631178855896, "training_acc": 53.0, "val_loss": 0.6893733930587769, "val_acc": 52.0}
{"epoch": 45, "training_loss": 0.6916279506683349, "training_acc": 53.0, "val_loss": 0.6893646788597106, "val_acc": 52.0}
{"epoch": 46, "training_loss": 0.6912172722816468, "training_acc": 53.0, "val_loss": 0.6893621778488159, "val_acc": 52.0}
{"epoch": 47, "training_loss": 0.6912377071380615, "training_acc": 53.0, "val_loss": 0.689367573261261, "val_acc": 52.0}
{"epoch": 48, "training_loss": 0.6916324234008789, "training_acc": 53.0, "val_loss": 0.6893660712242127, "val_acc": 52.0}
{"epoch": 49, "training_loss": 0.6918517565727234, "training_acc": 53.0, "val_loss": 0.6893610858917236, "val_acc": 52.0}
{"epoch": 50, "training_loss": 0.6912677192687988, "training_acc": 53.0, "val_loss": 0.6893596267700195, "val_acc": 52.0}
{"epoch": 51, "training_loss": 0.6913786840438843, "training_acc": 53.0, "val_loss": 0.6893588209152222, "val_acc": 52.0}
{"epoch": 52, "training_loss": 0.6913018012046814, "training_acc": 53.0, "val_loss": 0.6893580675125122, "val_acc": 52.0}
{"epoch": 53, "training_loss": 0.691605110168457, "training_acc": 53.0, "val_loss": 0.6893581795692444, "val_acc": 52.0}
{"epoch": 54, "training_loss": 0.6910894870758056, "training_acc": 53.0, "val_loss": 0.6893566870689392, "val_acc": 52.0}
{"epoch": 55, "training_loss": 0.6913982391357422, "training_acc": 53.0, "val_loss": 0.689361298084259, "val_acc": 52.0}
{"epoch": 56, "training_loss": 0.6904869604110718, "training_acc": 53.0, "val_loss": 0.6893721389770507, "val_acc": 52.0}
{"epoch": 57, "training_loss": 0.6911899876594544, "training_acc": 53.0, "val_loss": 0.6893850350379944, "val_acc": 52.0}
{"epoch": 58, "training_loss": 0.6915878939628601, "training_acc": 53.0, "val_loss": 0.6893972730636597, "val_acc": 52.0}
{"epoch": 59, "training_loss": 0.6911057472229004, "training_acc": 53.0, "val_loss": 0.6893962073326111, "val_acc": 52.0}
{"epoch": 60, "training_loss": 0.6916251683235168, "training_acc": 53.0, "val_loss": 0.6894039940834046, "val_acc": 52.0}
{"epoch": 61, "training_loss": 0.6912996649742127, "training_acc": 53.0, "val_loss": 0.6894000172615051, "val_acc": 52.0}
{"epoch": 62, "training_loss": 0.6914504623413086, "training_acc": 53.0, "val_loss": 0.6893968987464905, "val_acc": 52.0}
{"epoch": 63, "training_loss": 0.6913154006004334, "training_acc": 53.0, "val_loss": 0.6894068145751953, "val_acc": 52.0}
{"epoch": 64, "training_loss": 0.6912430429458618, "training_acc": 53.0, "val_loss": 0.6894195127487183, "val_acc": 52.0}
{"epoch": 65, "training_loss": 0.6907964253425598, "training_acc": 53.0, "val_loss": 0.6894263529777527, "val_acc": 52.0}
{"epoch": 66, "training_loss": 0.6911582851409912, "training_acc": 53.0, "val_loss": 0.6894270253181457, "val_acc": 52.0}
{"epoch": 67, "training_loss": 0.691531994342804, "training_acc": 53.0, "val_loss": 0.6894147205352783, "val_acc": 52.0}
{"epoch": 68, "training_loss": 0.6918141388893128, "training_acc": 53.0, "val_loss": 0.6894056606292724, "val_acc": 52.0}
{"epoch": 69, "training_loss": 0.6914319658279419, "training_acc": 53.0, "val_loss": 0.689407274723053, "val_acc": 52.0}
{"epoch": 70, "training_loss": 0.6912785530090332, "training_acc": 53.0, "val_loss": 0.6893980145454407, "val_acc": 52.0}
{"epoch": 71, "training_loss": 0.6909516668319702, "training_acc": 53.0, "val_loss": 0.6893935441970825, "val_acc": 52.0}
{"epoch": 72, "training_loss": 0.6911794805526733, "training_acc": 53.0, "val_loss": 0.6893992948532105, "val_acc": 52.0}
{"epoch": 73, "training_loss": 0.6908797883987426, "training_acc": 53.0, "val_loss": 0.6894123792648316, "val_acc": 52.0}
