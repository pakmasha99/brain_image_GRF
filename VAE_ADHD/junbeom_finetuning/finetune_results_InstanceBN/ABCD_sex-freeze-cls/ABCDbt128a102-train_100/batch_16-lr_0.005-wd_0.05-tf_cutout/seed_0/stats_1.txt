"main_modify.py --pretrained_path /scratch/connectome/dyhan316/VAE_ADHD/barlowtwins/pretrain_results/ABCDbt128a102.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option BT_org --learning_rate 5e-3 --batch_size 16 --weight_decay 5e-2 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 0.9126898622512818, "training_acc": 45.0, "val_loss": 0.6941319251060486, "val_acc": 48.0}
{"epoch": 1, "training_loss": 0.8476213669776916, "training_acc": 51.0, "val_loss": 0.691904673576355, "val_acc": 52.0}
{"epoch": 2, "training_loss": 0.8734071016311645, "training_acc": 43.0, "val_loss": 0.6945780515670776, "val_acc": 52.0}
{"epoch": 3, "training_loss": 0.7898604822158813, "training_acc": 53.0, "val_loss": 0.6999005126953125, "val_acc": 52.0}
{"epoch": 4, "training_loss": 0.6944224834442139, "training_acc": 53.0, "val_loss": 0.6930820322036744, "val_acc": 48.0}
{"epoch": 5, "training_loss": 0.6937096762657166, "training_acc": 48.0, "val_loss": 0.6917514085769654, "val_acc": 52.0}
{"epoch": 6, "training_loss": 0.7251204061508179, "training_acc": 37.0, "val_loss": 0.6922079586982727, "val_acc": 52.0}
{"epoch": 7, "training_loss": 0.7346601915359497, "training_acc": 53.0, "val_loss": 0.6947394514083862, "val_acc": 48.0}
{"epoch": 8, "training_loss": 0.7145615148544312, "training_acc": 39.0, "val_loss": 0.6917886471748352, "val_acc": 52.0}
{"epoch": 9, "training_loss": 0.7206453132629395, "training_acc": 53.0, "val_loss": 0.6947491025924682, "val_acc": 48.0}
{"epoch": 10, "training_loss": 0.7111665868759155, "training_acc": 49.0, "val_loss": 0.7234263920783996, "val_acc": 52.0}
{"epoch": 11, "training_loss": 0.7207670927047729, "training_acc": 51.0, "val_loss": 0.7131949234008789, "val_acc": 48.0}
{"epoch": 12, "training_loss": 0.7085191822052002, "training_acc": 51.0, "val_loss": 0.7235220742225646, "val_acc": 52.0}
{"epoch": 13, "training_loss": 0.7289135837554932, "training_acc": 39.0, "val_loss": 0.6954628109931946, "val_acc": 52.0}
{"epoch": 14, "training_loss": 0.7049108481407166, "training_acc": 53.0, "val_loss": 0.6910246133804321, "val_acc": 52.0}
{"epoch": 15, "training_loss": 0.6896209287643432, "training_acc": 53.0, "val_loss": 0.7024814295768738, "val_acc": 48.0}
{"epoch": 16, "training_loss": 0.7763022875785828, "training_acc": 45.0, "val_loss": 0.8032153367996215, "val_acc": 52.0}
{"epoch": 17, "training_loss": 0.7953786540031433, "training_acc": 41.0, "val_loss": 0.6933929181098938, "val_acc": 48.0}
{"epoch": 18, "training_loss": 0.7041144275665283, "training_acc": 47.0, "val_loss": 0.692088360786438, "val_acc": 52.0}
{"epoch": 19, "training_loss": 0.7837385559082031, "training_acc": 46.0, "val_loss": 0.7087614011764526, "val_acc": 52.0}
{"epoch": 20, "training_loss": 0.7265926074981689, "training_acc": 49.0, "val_loss": 0.6943730282783508, "val_acc": 48.0}
{"epoch": 21, "training_loss": 0.7095637011528015, "training_acc": 50.0, "val_loss": 0.6933349204063416, "val_acc": 52.0}
{"epoch": 22, "training_loss": 0.7026302623748779, "training_acc": 54.0, "val_loss": 0.7297361493110657, "val_acc": 48.0}
{"epoch": 23, "training_loss": 0.7396516942977905, "training_acc": 49.0, "val_loss": 0.7228343176841736, "val_acc": 52.0}
{"epoch": 24, "training_loss": 0.7182891941070557, "training_acc": 53.0, "val_loss": 0.6908066534996032, "val_acc": 52.0}
{"epoch": 25, "training_loss": 0.7227128458023071, "training_acc": 49.0, "val_loss": 0.6964983344078064, "val_acc": 52.0}
{"epoch": 26, "training_loss": 0.7018781089782715, "training_acc": 53.0, "val_loss": 0.6989859437942505, "val_acc": 52.0}
{"epoch": 27, "training_loss": 0.6990983939170837, "training_acc": 50.0, "val_loss": 0.6969628643989563, "val_acc": 48.0}
{"epoch": 28, "training_loss": 0.7252808380126953, "training_acc": 52.0, "val_loss": 0.7665544867515564, "val_acc": 52.0}
{"epoch": 29, "training_loss": 0.7478846883773804, "training_acc": 55.0, "val_loss": 0.7375166058540344, "val_acc": 48.0}
{"epoch": 30, "training_loss": 0.8258924341201782, "training_acc": 47.0, "val_loss": 0.8321112155914306, "val_acc": 52.0}
{"epoch": 31, "training_loss": 0.8333766365051269, "training_acc": 55.0, "val_loss": 0.811950740814209, "val_acc": 48.0}
{"epoch": 32, "training_loss": 0.8569937014579773, "training_acc": 47.0, "val_loss": 0.7356878566741943, "val_acc": 52.0}
{"epoch": 33, "training_loss": 0.7566772699356079, "training_acc": 54.0, "val_loss": 0.6987832856178283, "val_acc": 48.0}
{"epoch": 34, "training_loss": 0.7086267709732056, "training_acc": 45.0, "val_loss": 0.6905499958992004, "val_acc": 52.0}
{"epoch": 35, "training_loss": 0.6885683393478393, "training_acc": 51.0, "val_loss": 0.6906527686119079, "val_acc": 68.0}
{"epoch": 36, "training_loss": 0.6911254811286927, "training_acc": 58.0, "val_loss": 0.6935269093513489, "val_acc": 52.0}
{"epoch": 37, "training_loss": 0.688903923034668, "training_acc": 51.0, "val_loss": 0.6937940120697021, "val_acc": 52.0}
{"epoch": 38, "training_loss": 0.6892979717254639, "training_acc": 53.0, "val_loss": 0.7028240323066711, "val_acc": 52.0}
{"epoch": 39, "training_loss": 0.6959819746017456, "training_acc": 52.0, "val_loss": 0.6961904263496399, "val_acc": 48.0}
{"epoch": 40, "training_loss": 0.6887510633468628, "training_acc": 61.0, "val_loss": 0.6910314559936523, "val_acc": 64.0}
{"epoch": 41, "training_loss": 0.6983593225479126, "training_acc": 56.0, "val_loss": 0.6976433682441712, "val_acc": 52.0}
{"epoch": 42, "training_loss": 0.6913302898406982, "training_acc": 54.0, "val_loss": 0.6957231307029724, "val_acc": 48.0}
{"epoch": 43, "training_loss": 0.6918008542060852, "training_acc": 49.0, "val_loss": 0.7372562313079833, "val_acc": 52.0}
{"epoch": 44, "training_loss": 0.7361993551254272, "training_acc": 52.0, "val_loss": 0.7126092910766602, "val_acc": 48.0}
{"epoch": 45, "training_loss": 0.713867392539978, "training_acc": 51.0, "val_loss": 0.717163908481598, "val_acc": 52.0}
{"epoch": 46, "training_loss": 0.7084344291687011, "training_acc": 46.0, "val_loss": 0.6917653965950012, "val_acc": 52.0}
{"epoch": 47, "training_loss": 0.7145747470855713, "training_acc": 53.0, "val_loss": 0.6981413650512696, "val_acc": 48.0}
{"epoch": 48, "training_loss": 0.7463320732116699, "training_acc": 39.0, "val_loss": 0.6904233145713806, "val_acc": 52.0}
{"epoch": 49, "training_loss": 0.7511499214172364, "training_acc": 43.0, "val_loss": 0.7285435795783997, "val_acc": 52.0}
{"epoch": 50, "training_loss": 0.7172690582275391, "training_acc": 51.0, "val_loss": 0.6988495898246765, "val_acc": 48.0}
{"epoch": 51, "training_loss": 0.6981455659866334, "training_acc": 51.0, "val_loss": 0.762987310886383, "val_acc": 52.0}
{"epoch": 52, "training_loss": 0.8028008651733398, "training_acc": 53.0, "val_loss": 0.7765808176994323, "val_acc": 48.0}
{"epoch": 53, "training_loss": 0.9514782667160034, "training_acc": 49.0, "val_loss": 0.8053320550918579, "val_acc": 52.0}
{"epoch": 54, "training_loss": 0.892599925994873, "training_acc": 53.0, "val_loss": 0.7275234198570252, "val_acc": 48.0}
{"epoch": 55, "training_loss": 0.7529761862754821, "training_acc": 47.0, "val_loss": 0.7138098406791688, "val_acc": 52.0}
{"epoch": 56, "training_loss": 0.7043777990341187, "training_acc": 48.0, "val_loss": 0.6906991982460022, "val_acc": 60.0}
{"epoch": 57, "training_loss": 0.729486026763916, "training_acc": 56.0, "val_loss": 0.7082162523269653, "val_acc": 48.0}
{"epoch": 58, "training_loss": 0.8532009029388428, "training_acc": 47.0, "val_loss": 0.8008900308609008, "val_acc": 52.0}
{"epoch": 59, "training_loss": 0.8476634573936462, "training_acc": 53.0, "val_loss": 0.7552752232551575, "val_acc": 48.0}
{"epoch": 60, "training_loss": 0.7315706562995911, "training_acc": 49.0, "val_loss": 0.7103774738311768, "val_acc": 52.0}
{"epoch": 61, "training_loss": 0.6992459440231323, "training_acc": 59.0, "val_loss": 0.7128339385986329, "val_acc": 48.0}
{"epoch": 62, "training_loss": 0.6976198339462281, "training_acc": 49.0, "val_loss": 0.7779638981819152, "val_acc": 52.0}
{"epoch": 63, "training_loss": 0.7303335046768189, "training_acc": 56.0, "val_loss": 0.7383866572380066, "val_acc": 48.0}
{"epoch": 64, "training_loss": 0.7280753183364869, "training_acc": 49.0, "val_loss": 0.7628252100944519, "val_acc": 52.0}
{"epoch": 65, "training_loss": 0.7807298302650452, "training_acc": 55.0, "val_loss": 0.842573094367981, "val_acc": 48.0}
{"epoch": 66, "training_loss": 0.9073258399963379, "training_acc": 43.0, "val_loss": 0.7466528439521789, "val_acc": 52.0}
{"epoch": 67, "training_loss": 0.7089869165420533, "training_acc": 55.0, "val_loss": 0.7347108030319214, "val_acc": 48.0}
