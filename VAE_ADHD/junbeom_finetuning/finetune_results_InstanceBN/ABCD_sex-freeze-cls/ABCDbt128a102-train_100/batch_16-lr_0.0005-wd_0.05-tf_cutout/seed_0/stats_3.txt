"main_modify.py --pretrained_path /scratch/connectome/dyhan316/VAE_ADHD/barlowtwins/pretrain_results/ABCDbt128a102.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option BT_org --learning_rate 5e-4 --batch_size 16 --weight_decay 5e-2 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 0.7099729776382446, "training_acc": 39.0, "val_loss": 0.6944736814498902, "val_acc": 52.0}
{"epoch": 1, "training_loss": 0.6980751943588257, "training_acc": 53.0, "val_loss": 0.693067820072174, "val_acc": 52.0}
{"epoch": 2, "training_loss": 0.6927953410148621, "training_acc": 53.0, "val_loss": 0.6960720181465149, "val_acc": 52.0}
{"epoch": 3, "training_loss": 0.6965561628341674, "training_acc": 53.0, "val_loss": 0.6963236618041992, "val_acc": 52.0}
{"epoch": 4, "training_loss": 0.6935713243484497, "training_acc": 53.0, "val_loss": 0.692983934879303, "val_acc": 52.0}
{"epoch": 5, "training_loss": 0.6959634351730347, "training_acc": 53.0, "val_loss": 0.6939711117744446, "val_acc": 52.0}
{"epoch": 6, "training_loss": 0.6926912093162536, "training_acc": 53.0, "val_loss": 0.6929503202438354, "val_acc": 52.0}
{"epoch": 7, "training_loss": 0.6932113480567932, "training_acc": 53.0, "val_loss": 0.6929406476020813, "val_acc": 52.0}
{"epoch": 8, "training_loss": 0.6936570596694946, "training_acc": 53.0, "val_loss": 0.6930430030822754, "val_acc": 52.0}
{"epoch": 9, "training_loss": 0.7054937171936035, "training_acc": 43.0, "val_loss": 0.6970782256126404, "val_acc": 48.0}
{"epoch": 10, "training_loss": 0.6906964945793151, "training_acc": 57.0, "val_loss": 0.6955033040046692, "val_acc": 52.0}
{"epoch": 11, "training_loss": 0.6952583146095276, "training_acc": 53.0, "val_loss": 0.6974489903450012, "val_acc": 52.0}
{"epoch": 12, "training_loss": 0.6974762678146362, "training_acc": 53.0, "val_loss": 0.695818510055542, "val_acc": 52.0}
{"epoch": 13, "training_loss": 0.6908989405632019, "training_acc": 53.0, "val_loss": 0.6929231715202332, "val_acc": 52.0}
{"epoch": 14, "training_loss": 0.6949747562408447, "training_acc": 45.0, "val_loss": 0.6938834977149964, "val_acc": 44.0}
{"epoch": 15, "training_loss": 0.6923397874832153, "training_acc": 50.0, "val_loss": 0.6936359333992005, "val_acc": 52.0}
{"epoch": 16, "training_loss": 0.6921517944335938, "training_acc": 53.0, "val_loss": 0.6947798275947571, "val_acc": 52.0}
{"epoch": 17, "training_loss": 0.69332275390625, "training_acc": 53.0, "val_loss": 0.6936455178260803, "val_acc": 52.0}
{"epoch": 18, "training_loss": 0.6950926995277404, "training_acc": 53.0, "val_loss": 0.6981066489219665, "val_acc": 52.0}
{"epoch": 19, "training_loss": 0.7009351229667664, "training_acc": 53.0, "val_loss": 0.6948106765747071, "val_acc": 52.0}
{"epoch": 20, "training_loss": 0.6979570174217224, "training_acc": 50.0, "val_loss": 0.6996031022071838, "val_acc": 48.0}
{"epoch": 21, "training_loss": 0.7038548707962036, "training_acc": 47.0, "val_loss": 0.697012095451355, "val_acc": 48.0}
{"epoch": 22, "training_loss": 0.695945315361023, "training_acc": 45.0, "val_loss": 0.6933135604858398, "val_acc": 52.0}
{"epoch": 23, "training_loss": 0.6909463047981262, "training_acc": 53.0, "val_loss": 0.6953775382041931, "val_acc": 52.0}
{"epoch": 24, "training_loss": 0.6941182112693787, "training_acc": 53.0, "val_loss": 0.696898033618927, "val_acc": 52.0}
{"epoch": 25, "training_loss": 0.6939140033721923, "training_acc": 53.0, "val_loss": 0.6957327198982238, "val_acc": 52.0}
{"epoch": 26, "training_loss": 0.6956088542938232, "training_acc": 53.0, "val_loss": 0.6952008748054505, "val_acc": 52.0}
{"epoch": 27, "training_loss": 0.6900076484680175, "training_acc": 50.0, "val_loss": 0.6937049031257629, "val_acc": 52.0}
{"epoch": 28, "training_loss": 0.6948985266685486, "training_acc": 50.0, "val_loss": 0.6928852033615113, "val_acc": 52.0}
{"epoch": 29, "training_loss": 0.6960138845443725, "training_acc": 44.0, "val_loss": 0.6938712787628174, "val_acc": 40.0}
{"epoch": 30, "training_loss": 0.6943871784210205, "training_acc": 49.0, "val_loss": 0.6929221034049988, "val_acc": 52.0}
{"epoch": 31, "training_loss": 0.6916128277778626, "training_acc": 53.0, "val_loss": 0.6931280994415283, "val_acc": 52.0}
{"epoch": 32, "training_loss": 0.7027534580230713, "training_acc": 44.0, "val_loss": 0.6973996305465698, "val_acc": 48.0}
{"epoch": 33, "training_loss": 0.6929407739639282, "training_acc": 48.0, "val_loss": 0.694912600517273, "val_acc": 52.0}
{"epoch": 34, "training_loss": 0.6928308463096619, "training_acc": 53.0, "val_loss": 0.6948649191856384, "val_acc": 52.0}
{"epoch": 35, "training_loss": 0.6919039225578308, "training_acc": 53.0, "val_loss": 0.6928306007385254, "val_acc": 52.0}
{"epoch": 36, "training_loss": 0.6955892491340637, "training_acc": 53.0, "val_loss": 0.6929930424690247, "val_acc": 52.0}
{"epoch": 37, "training_loss": 0.6904957389831543, "training_acc": 52.0, "val_loss": 0.6944469738006592, "val_acc": 48.0}
{"epoch": 38, "training_loss": 0.6929059028625488, "training_acc": 47.0, "val_loss": 0.6931515955924987, "val_acc": 52.0}
{"epoch": 39, "training_loss": 0.7072169733047485, "training_acc": 54.0, "val_loss": 0.6990662789344788, "val_acc": 52.0}
{"epoch": 40, "training_loss": 0.6926686573028564, "training_acc": 53.0, "val_loss": 0.6930361938476562, "val_acc": 52.0}
{"epoch": 41, "training_loss": 0.6939890909194947, "training_acc": 54.0, "val_loss": 0.6939307713508606, "val_acc": 48.0}
{"epoch": 42, "training_loss": 0.6954918742179871, "training_acc": 51.0, "val_loss": 0.6957156324386596, "val_acc": 52.0}
{"epoch": 43, "training_loss": 0.6933953666687012, "training_acc": 53.0, "val_loss": 0.6952909207344056, "val_acc": 52.0}
{"epoch": 44, "training_loss": 0.6978501939773559, "training_acc": 53.0, "val_loss": 0.6947636723518371, "val_acc": 52.0}
{"epoch": 45, "training_loss": 0.6898365831375122, "training_acc": 51.0, "val_loss": 0.7001547741889954, "val_acc": 48.0}
{"epoch": 46, "training_loss": 0.7004515600204467, "training_acc": 47.0, "val_loss": 0.6949756288528443, "val_acc": 48.0}
{"epoch": 47, "training_loss": 0.692740707397461, "training_acc": 46.0, "val_loss": 0.6930631566047668, "val_acc": 52.0}
{"epoch": 48, "training_loss": 0.6937022233009338, "training_acc": 53.0, "val_loss": 0.6961730623245239, "val_acc": 52.0}
{"epoch": 49, "training_loss": 0.6897461152076722, "training_acc": 53.0, "val_loss": 0.6929601693153381, "val_acc": 52.0}
{"epoch": 50, "training_loss": 0.6907939195632935, "training_acc": 53.0, "val_loss": 0.6928069424629212, "val_acc": 52.0}
{"epoch": 51, "training_loss": 0.6902015924453735, "training_acc": 53.0, "val_loss": 0.6928952646255493, "val_acc": 52.0}
{"epoch": 52, "training_loss": 0.6942014217376709, "training_acc": 50.0, "val_loss": 0.6954563665390014, "val_acc": 48.0}
{"epoch": 53, "training_loss": 0.691533510684967, "training_acc": 51.0, "val_loss": 0.6927538418769836, "val_acc": 52.0}
{"epoch": 54, "training_loss": 0.6900539493560791, "training_acc": 53.0, "val_loss": 0.6929346776008606, "val_acc": 52.0}
{"epoch": 55, "training_loss": 0.6929058074951172, "training_acc": 53.0, "val_loss": 0.6931339645385742, "val_acc": 52.0}
{"epoch": 56, "training_loss": 0.7007703399658203, "training_acc": 41.0, "val_loss": 0.6973946499824524, "val_acc": 48.0}
{"epoch": 57, "training_loss": 0.6946312880516052, "training_acc": 47.0, "val_loss": 0.6938379693031311, "val_acc": 56.0}
{"epoch": 58, "training_loss": 0.6922573852539062, "training_acc": 48.0, "val_loss": 0.6930449104309082, "val_acc": 52.0}
{"epoch": 59, "training_loss": 0.6902367377281189, "training_acc": 53.0, "val_loss": 0.6968130397796631, "val_acc": 52.0}
{"epoch": 60, "training_loss": 0.6913099622726441, "training_acc": 53.0, "val_loss": 0.6940776562690735, "val_acc": 52.0}
{"epoch": 61, "training_loss": 0.6938146543502808, "training_acc": 54.0, "val_loss": 0.6963449454307556, "val_acc": 48.0}
{"epoch": 62, "training_loss": 0.695147271156311, "training_acc": 46.0, "val_loss": 0.6927855777740478, "val_acc": 52.0}
{"epoch": 63, "training_loss": 0.6911635303497314, "training_acc": 53.0, "val_loss": 0.6978440976142883, "val_acc": 52.0}
{"epoch": 64, "training_loss": 0.6986955547332764, "training_acc": 53.0, "val_loss": 0.7024119997024536, "val_acc": 52.0}
{"epoch": 65, "training_loss": 0.6891952443122864, "training_acc": 53.0, "val_loss": 0.6927853345870971, "val_acc": 52.0}
{"epoch": 66, "training_loss": 0.6886473155021667, "training_acc": 53.0, "val_loss": 0.6928213429450989, "val_acc": 52.0}
{"epoch": 67, "training_loss": 0.6909015989303589, "training_acc": 52.0, "val_loss": 0.6931759285926818, "val_acc": 44.0}
{"epoch": 68, "training_loss": 0.6882653331756592, "training_acc": 54.0, "val_loss": 0.693217842578888, "val_acc": 52.0}
{"epoch": 69, "training_loss": 0.6908492136001587, "training_acc": 53.0, "val_loss": 0.6974113631248474, "val_acc": 52.0}
{"epoch": 70, "training_loss": 0.6907404589653016, "training_acc": 53.0, "val_loss": 0.6927692914009094, "val_acc": 52.0}
{"epoch": 71, "training_loss": 0.6900253963470458, "training_acc": 53.0, "val_loss": 0.6931482315063476, "val_acc": 52.0}
{"epoch": 72, "training_loss": 0.6969574546813965, "training_acc": 53.0, "val_loss": 0.6968000483512878, "val_acc": 52.0}
