"main_modify.py --pretrained_path /scratch/connectome/dyhan316/VAE_ADHD/barlowtwins/pretrain_results/ABCDbt128a102.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option BT_org --learning_rate 5e-4 --batch_size 16 --weight_decay 5e-2 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 0.6903906798362732, "training_acc": 56.0, "val_loss": 0.6986236882209778, "val_acc": 52.0}
{"epoch": 1, "training_loss": 0.7182651877403259, "training_acc": 53.0, "val_loss": 0.7201542019844055, "val_acc": 52.0}
{"epoch": 2, "training_loss": 0.7150069808959961, "training_acc": 53.0, "val_loss": 0.6923830103874207, "val_acc": 52.0}
{"epoch": 3, "training_loss": 0.6941510462760925, "training_acc": 53.0, "val_loss": 0.6911321067810059, "val_acc": 52.0}
{"epoch": 4, "training_loss": 0.6951366233825683, "training_acc": 51.0, "val_loss": 0.6913565444946289, "val_acc": 52.0}
{"epoch": 5, "training_loss": 0.6941790676116943, "training_acc": 45.0, "val_loss": 0.6912320709228515, "val_acc": 52.0}
{"epoch": 6, "training_loss": 0.69494215965271, "training_acc": 53.0, "val_loss": 0.6938243198394776, "val_acc": 52.0}
{"epoch": 7, "training_loss": 0.694513919353485, "training_acc": 53.0, "val_loss": 0.6928442096710206, "val_acc": 52.0}
{"epoch": 8, "training_loss": 0.695708167552948, "training_acc": 53.0, "val_loss": 0.694954469203949, "val_acc": 48.0}
{"epoch": 9, "training_loss": 0.6983894729614257, "training_acc": 39.0, "val_loss": 0.6910715293884278, "val_acc": 52.0}
{"epoch": 10, "training_loss": 0.6933630180358886, "training_acc": 53.0, "val_loss": 0.6914377593994141, "val_acc": 52.0}
{"epoch": 11, "training_loss": 0.6931288838386536, "training_acc": 53.0, "val_loss": 0.6921307039260864, "val_acc": 52.0}
{"epoch": 12, "training_loss": 0.6949604487419129, "training_acc": 53.0, "val_loss": 0.6976682257652282, "val_acc": 52.0}
{"epoch": 13, "training_loss": 0.6943917369842529, "training_acc": 53.0, "val_loss": 0.6922126817703247, "val_acc": 52.0}
{"epoch": 14, "training_loss": 0.6991614246368408, "training_acc": 42.0, "val_loss": 0.6927603173255921, "val_acc": 48.0}
{"epoch": 15, "training_loss": 0.6964207506179809, "training_acc": 44.0, "val_loss": 0.6910406684875489, "val_acc": 52.0}
{"epoch": 16, "training_loss": 0.6967137145996094, "training_acc": 53.0, "val_loss": 0.6928534007072449, "val_acc": 52.0}
{"epoch": 17, "training_loss": 0.6950203990936279, "training_acc": 53.0, "val_loss": 0.6929681825637818, "val_acc": 52.0}
{"epoch": 18, "training_loss": 0.693288779258728, "training_acc": 53.0, "val_loss": 0.6910578083992004, "val_acc": 52.0}
{"epoch": 19, "training_loss": 0.6916870546340942, "training_acc": 53.0, "val_loss": 0.691531081199646, "val_acc": 52.0}
{"epoch": 20, "training_loss": 0.6913534736633301, "training_acc": 53.0, "val_loss": 0.6912719011306763, "val_acc": 52.0}
{"epoch": 21, "training_loss": 0.6949781751632691, "training_acc": 52.0, "val_loss": 0.6910688328742981, "val_acc": 52.0}
{"epoch": 22, "training_loss": 0.6899439477920533, "training_acc": 53.0, "val_loss": 0.6919492387771606, "val_acc": 52.0}
{"epoch": 23, "training_loss": 0.6945739126205445, "training_acc": 53.0, "val_loss": 0.6933026218414307, "val_acc": 52.0}
{"epoch": 24, "training_loss": 0.6993907451629638, "training_acc": 53.0, "val_loss": 0.6917189502716065, "val_acc": 60.0}
{"epoch": 25, "training_loss": 0.6952763509750366, "training_acc": 49.0, "val_loss": 0.6908784604072571, "val_acc": 52.0}
{"epoch": 26, "training_loss": 0.693196485042572, "training_acc": 53.0, "val_loss": 0.6926841068267823, "val_acc": 52.0}
{"epoch": 27, "training_loss": 0.6953874516487122, "training_acc": 52.0, "val_loss": 0.6929391288757324, "val_acc": 48.0}
{"epoch": 28, "training_loss": 0.6959468722343445, "training_acc": 47.0, "val_loss": 0.6916203784942627, "val_acc": 56.0}
{"epoch": 29, "training_loss": 0.695920376777649, "training_acc": 53.0, "val_loss": 0.6963488554954529, "val_acc": 52.0}
{"epoch": 30, "training_loss": 0.7041248655319214, "training_acc": 53.0, "val_loss": 0.6995123696327209, "val_acc": 52.0}
{"epoch": 31, "training_loss": 0.6920566606521606, "training_acc": 53.0, "val_loss": 0.6915677738189697, "val_acc": 60.0}
{"epoch": 32, "training_loss": 0.699859893321991, "training_acc": 43.0, "val_loss": 0.6920236945152283, "val_acc": 44.0}
{"epoch": 33, "training_loss": 0.6918668222427368, "training_acc": 56.0, "val_loss": 0.6909105706214905, "val_acc": 52.0}
{"epoch": 34, "training_loss": 0.6916104555130005, "training_acc": 53.0, "val_loss": 0.6914221286773682, "val_acc": 52.0}
{"epoch": 35, "training_loss": 0.6923391604423523, "training_acc": 53.0, "val_loss": 0.6939868235588074, "val_acc": 52.0}
{"epoch": 36, "training_loss": 0.6966514825820923, "training_acc": 53.0, "val_loss": 0.6909201216697692, "val_acc": 52.0}
{"epoch": 37, "training_loss": 0.6904101014137268, "training_acc": 53.0, "val_loss": 0.6910029172897338, "val_acc": 52.0}
{"epoch": 38, "training_loss": 0.6987163734436035, "training_acc": 47.0, "val_loss": 0.6912886905670166, "val_acc": 56.0}
{"epoch": 39, "training_loss": 0.6950118732452393, "training_acc": 53.0, "val_loss": 0.6918876004219056, "val_acc": 52.0}
{"epoch": 40, "training_loss": 0.6889489316940307, "training_acc": 53.0, "val_loss": 0.6907769012451171, "val_acc": 52.0}
{"epoch": 41, "training_loss": 0.6944165182113647, "training_acc": 45.0, "val_loss": 0.6917375206947327, "val_acc": 56.0}
{"epoch": 42, "training_loss": 0.6937758159637452, "training_acc": 53.0, "val_loss": 0.6912104296684265, "val_acc": 52.0}
{"epoch": 43, "training_loss": 0.691649169921875, "training_acc": 53.0, "val_loss": 0.6918934488296509, "val_acc": 52.0}
{"epoch": 44, "training_loss": 0.6910056829452514, "training_acc": 53.0, "val_loss": 0.6913388752937317, "val_acc": 52.0}
{"epoch": 45, "training_loss": 0.6904398036003113, "training_acc": 53.0, "val_loss": 0.6911734127998352, "val_acc": 52.0}
{"epoch": 46, "training_loss": 0.6896753263473511, "training_acc": 53.0, "val_loss": 0.6917990899085998, "val_acc": 52.0}
{"epoch": 47, "training_loss": 0.6904159450531006, "training_acc": 53.0, "val_loss": 0.6949242091178894, "val_acc": 52.0}
{"epoch": 48, "training_loss": 0.6911522197723389, "training_acc": 53.0, "val_loss": 0.6914921689033509, "val_acc": 52.0}
{"epoch": 49, "training_loss": 0.6926552391052246, "training_acc": 46.0, "val_loss": 0.6936045098304748, "val_acc": 48.0}
{"epoch": 50, "training_loss": 0.6930419921875, "training_acc": 50.0, "val_loss": 0.6912975335121154, "val_acc": 56.0}
{"epoch": 51, "training_loss": 0.689102292060852, "training_acc": 55.0, "val_loss": 0.6912856793403626, "val_acc": 52.0}
{"epoch": 52, "training_loss": 0.6895399904251098, "training_acc": 53.0, "val_loss": 0.6939825224876404, "val_acc": 52.0}
{"epoch": 53, "training_loss": 0.6903107404708863, "training_acc": 53.0, "val_loss": 0.6909080147743225, "val_acc": 52.0}
{"epoch": 54, "training_loss": 0.6922107696533203, "training_acc": 55.0, "val_loss": 0.6911553168296813, "val_acc": 52.0}
{"epoch": 55, "training_loss": 0.6900788688659668, "training_acc": 53.0, "val_loss": 0.6931661915779114, "val_acc": 52.0}
{"epoch": 56, "training_loss": 0.6947078943252564, "training_acc": 53.0, "val_loss": 0.693847324848175, "val_acc": 52.0}
{"epoch": 57, "training_loss": 0.6967095017433167, "training_acc": 53.0, "val_loss": 0.693913414478302, "val_acc": 48.0}
{"epoch": 58, "training_loss": 0.6935762739181519, "training_acc": 48.0, "val_loss": 0.6910712933540344, "val_acc": 52.0}
{"epoch": 59, "training_loss": 0.6882637763023376, "training_acc": 53.0, "val_loss": 0.6929072260856628, "val_acc": 52.0}
