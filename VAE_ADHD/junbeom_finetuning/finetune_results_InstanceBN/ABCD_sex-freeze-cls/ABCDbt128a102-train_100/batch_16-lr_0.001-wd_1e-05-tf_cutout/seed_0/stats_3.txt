"main_modify.py --pretrained_path /scratch/connectome/dyhan316/VAE_ADHD/barlowtwins/pretrain_results/ABCDbt128a102.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option BT_org --learning_rate 1e-3 --batch_size 16 --weight_decay 1e-5 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 0.7011636257171631, "training_acc": 56.0, "val_loss": 0.7042493653297425, "val_acc": 48.0}
{"epoch": 1, "training_loss": 0.7256951904296876, "training_acc": 47.0, "val_loss": 0.6931127119064331, "val_acc": 52.0}
{"epoch": 2, "training_loss": 0.7317250514030457, "training_acc": 53.0, "val_loss": 0.7246868848800659, "val_acc": 52.0}
{"epoch": 3, "training_loss": 0.7062730979919434, "training_acc": 49.0, "val_loss": 0.7089528656005859, "val_acc": 48.0}
{"epoch": 4, "training_loss": 0.7025169658660889, "training_acc": 49.0, "val_loss": 0.6932680749893189, "val_acc": 52.0}
{"epoch": 5, "training_loss": 0.7225496673583984, "training_acc": 53.0, "val_loss": 0.7160837531089783, "val_acc": 52.0}
{"epoch": 6, "training_loss": 0.6886996722221375, "training_acc": 49.0, "val_loss": 0.6966326093673706, "val_acc": 48.0}
{"epoch": 7, "training_loss": 0.7153433609008789, "training_acc": 42.0, "val_loss": 0.6938922166824341, "val_acc": 52.0}
{"epoch": 8, "training_loss": 0.6914949989318848, "training_acc": 54.0, "val_loss": 0.693132061958313, "val_acc": 52.0}
{"epoch": 9, "training_loss": 0.6957572269439697, "training_acc": 53.0, "val_loss": 0.6943166875839233, "val_acc": 52.0}
{"epoch": 10, "training_loss": 0.7019841861724854, "training_acc": 43.0, "val_loss": 0.7004500365257263, "val_acc": 48.0}
{"epoch": 11, "training_loss": 0.7029738807678223, "training_acc": 46.0, "val_loss": 0.6929049825668335, "val_acc": 52.0}
{"epoch": 12, "training_loss": 0.6895365452766419, "training_acc": 53.0, "val_loss": 0.6931512188911438, "val_acc": 52.0}
{"epoch": 13, "training_loss": 0.698918251991272, "training_acc": 53.0, "val_loss": 0.6964822149276734, "val_acc": 52.0}
{"epoch": 14, "training_loss": 0.694741849899292, "training_acc": 53.0, "val_loss": 0.6966329073905945, "val_acc": 52.0}
{"epoch": 15, "training_loss": 0.6863949370384216, "training_acc": 55.0, "val_loss": 0.6969200491905212, "val_acc": 48.0}
{"epoch": 16, "training_loss": 0.6972097063064575, "training_acc": 47.0, "val_loss": 0.6930333352088929, "val_acc": 52.0}
{"epoch": 17, "training_loss": 0.6862942171096802, "training_acc": 53.0, "val_loss": 0.7048915219306946, "val_acc": 52.0}
{"epoch": 18, "training_loss": 0.7006662034988403, "training_acc": 53.0, "val_loss": 0.6994614100456238, "val_acc": 52.0}
{"epoch": 19, "training_loss": 0.6899978590011596, "training_acc": 53.0, "val_loss": 0.6926202869415283, "val_acc": 52.0}
{"epoch": 20, "training_loss": 0.6993702316284179, "training_acc": 48.0, "val_loss": 0.7040346145629883, "val_acc": 48.0}
{"epoch": 21, "training_loss": 0.7053823900222779, "training_acc": 47.0, "val_loss": 0.697871675491333, "val_acc": 48.0}
{"epoch": 22, "training_loss": 0.6930495619773864, "training_acc": 48.0, "val_loss": 0.693036699295044, "val_acc": 52.0}
{"epoch": 23, "training_loss": 0.6893400812149048, "training_acc": 53.0, "val_loss": 0.6925528240203858, "val_acc": 52.0}
{"epoch": 24, "training_loss": 0.6947192859649658, "training_acc": 48.0, "val_loss": 0.6925869631767273, "val_acc": 52.0}
{"epoch": 25, "training_loss": 0.690141212940216, "training_acc": 53.0, "val_loss": 0.6926005625724793, "val_acc": 52.0}
{"epoch": 26, "training_loss": 0.6941811656951904, "training_acc": 47.0, "val_loss": 0.692968819141388, "val_acc": 48.0}
{"epoch": 27, "training_loss": 0.6906530213356018, "training_acc": 54.0, "val_loss": 0.6925905585289002, "val_acc": 52.0}
{"epoch": 28, "training_loss": 0.6903572320938111, "training_acc": 53.0, "val_loss": 0.6942282342910766, "val_acc": 52.0}
{"epoch": 29, "training_loss": 0.6884232735633851, "training_acc": 53.0, "val_loss": 0.6927603077888489, "val_acc": 52.0}
{"epoch": 30, "training_loss": 0.6898142838478089, "training_acc": 57.0, "val_loss": 0.6926705503463745, "val_acc": 52.0}
{"epoch": 31, "training_loss": 0.68613778591156, "training_acc": 53.0, "val_loss": 0.6956541800498962, "val_acc": 52.0}
{"epoch": 32, "training_loss": 0.6909216785430908, "training_acc": 53.0, "val_loss": 0.6929735922813416, "val_acc": 52.0}
{"epoch": 33, "training_loss": 0.6906982517242432, "training_acc": 55.0, "val_loss": 0.692553699016571, "val_acc": 52.0}
{"epoch": 34, "training_loss": 0.6886383318901061, "training_acc": 59.0, "val_loss": 0.6930482029914856, "val_acc": 52.0}
{"epoch": 35, "training_loss": 0.6892191171646118, "training_acc": 54.0, "val_loss": 0.6931688737869263, "val_acc": 52.0}
{"epoch": 36, "training_loss": 0.7043702983856202, "training_acc": 53.0, "val_loss": 0.7113543629646302, "val_acc": 52.0}
{"epoch": 37, "training_loss": 0.7070949029922485, "training_acc": 53.0, "val_loss": 0.6929102158546447, "val_acc": 52.0}
{"epoch": 38, "training_loss": 0.6925893020629883, "training_acc": 53.0, "val_loss": 0.6930076718330384, "val_acc": 52.0}
{"epoch": 39, "training_loss": 0.6919650220870972, "training_acc": 43.0, "val_loss": 0.69678147315979, "val_acc": 48.0}
{"epoch": 40, "training_loss": 0.6924621534347534, "training_acc": 48.0, "val_loss": 0.6926558327674865, "val_acc": 52.0}
{"epoch": 41, "training_loss": 0.6910150814056396, "training_acc": 50.0, "val_loss": 0.6925650429725647, "val_acc": 52.0}
{"epoch": 42, "training_loss": 0.685045621395111, "training_acc": 53.0, "val_loss": 0.6979162716865539, "val_acc": 52.0}
