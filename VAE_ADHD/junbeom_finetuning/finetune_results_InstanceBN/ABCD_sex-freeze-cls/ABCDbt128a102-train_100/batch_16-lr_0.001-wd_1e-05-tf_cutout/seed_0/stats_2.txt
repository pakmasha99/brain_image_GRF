"main_modify.py --pretrained_path /scratch/connectome/dyhan316/VAE_ADHD/barlowtwins/pretrain_results/ABCDbt128a102.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option BT_org --learning_rate 1e-3 --batch_size 16 --weight_decay 1e-5 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 0.7254640960693359, "training_acc": 47.0, "val_loss": 0.7133929848670959, "val_acc": 52.0}
{"epoch": 1, "training_loss": 0.7163239574432373, "training_acc": 53.0, "val_loss": 0.7025138330459595, "val_acc": 52.0}
{"epoch": 2, "training_loss": 0.6934687876701355, "training_acc": 53.0, "val_loss": 0.7066479516029358, "val_acc": 48.0}
{"epoch": 3, "training_loss": 0.7004032778739929, "training_acc": 47.0, "val_loss": 0.6973597717285156, "val_acc": 52.0}
{"epoch": 4, "training_loss": 0.6944771909713745, "training_acc": 53.0, "val_loss": 0.6928668022155762, "val_acc": 52.0}
{"epoch": 5, "training_loss": 0.6997113370895386, "training_acc": 47.0, "val_loss": 0.6931905651092529, "val_acc": 52.0}
{"epoch": 6, "training_loss": 0.6905989122390747, "training_acc": 51.0, "val_loss": 0.70266841173172, "val_acc": 52.0}
{"epoch": 7, "training_loss": 0.7104632830619813, "training_acc": 47.0, "val_loss": 0.6927768754959106, "val_acc": 52.0}
{"epoch": 8, "training_loss": 0.6901497340202332, "training_acc": 53.0, "val_loss": 0.7038720989227295, "val_acc": 52.0}
{"epoch": 9, "training_loss": 0.6989495396614075, "training_acc": 53.0, "val_loss": 0.6934862422943116, "val_acc": 52.0}
{"epoch": 10, "training_loss": 0.6876588940620423, "training_acc": 58.0, "val_loss": 0.6996355748176575, "val_acc": 48.0}
{"epoch": 11, "training_loss": 0.6964277410507203, "training_acc": 51.0, "val_loss": 0.6948233819007874, "val_acc": 52.0}
{"epoch": 12, "training_loss": 0.6953304481506347, "training_acc": 53.0, "val_loss": 0.7028128743171692, "val_acc": 52.0}
{"epoch": 13, "training_loss": 0.695661973953247, "training_acc": 53.0, "val_loss": 0.6943472027778625, "val_acc": 52.0}
{"epoch": 14, "training_loss": 0.6980686235427856, "training_acc": 53.0, "val_loss": 0.6944105982780456, "val_acc": 52.0}
{"epoch": 15, "training_loss": 0.7002032327651978, "training_acc": 43.0, "val_loss": 0.6975417804718017, "val_acc": 48.0}
{"epoch": 16, "training_loss": 0.6899300193786622, "training_acc": 56.0, "val_loss": 0.6950897526741028, "val_acc": 52.0}
{"epoch": 17, "training_loss": 0.6914907646179199, "training_acc": 53.0, "val_loss": 0.6948148322105407, "val_acc": 52.0}
{"epoch": 18, "training_loss": 0.6936229801177979, "training_acc": 53.0, "val_loss": 0.6966835904121399, "val_acc": 52.0}
{"epoch": 19, "training_loss": 0.6948306107521057, "training_acc": 53.0, "val_loss": 0.6936249661445618, "val_acc": 52.0}
{"epoch": 20, "training_loss": 0.6906264185905456, "training_acc": 53.0, "val_loss": 0.6942285966873168, "val_acc": 52.0}
{"epoch": 21, "training_loss": 0.6925839614868164, "training_acc": 53.0, "val_loss": 0.6935009026527404, "val_acc": 52.0}
{"epoch": 22, "training_loss": 0.6902315998077393, "training_acc": 55.0, "val_loss": 0.694105076789856, "val_acc": 48.0}
{"epoch": 23, "training_loss": 0.6962333250045777, "training_acc": 49.0, "val_loss": 0.6934708714485168, "val_acc": 52.0}
{"epoch": 24, "training_loss": 0.6837129831314087, "training_acc": 53.0, "val_loss": 0.7083453035354614, "val_acc": 52.0}
{"epoch": 25, "training_loss": 0.7092364931106567, "training_acc": 53.0, "val_loss": 0.6995605158805848, "val_acc": 52.0}
{"epoch": 26, "training_loss": 0.6843858146667481, "training_acc": 55.0, "val_loss": 0.6979061555862427, "val_acc": 48.0}
