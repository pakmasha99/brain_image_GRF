"main_modify.py --pretrained_path /scratch/connectome/dyhan316/VAE_ADHD/barlowtwins/pretrain_results/ABCDbt128a102.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option BT_org --learning_rate 1e-3 --batch_size 16 --weight_decay 1e-5 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 0.7075829696655274, "training_acc": 45.0, "val_loss": 0.6947102737426758, "val_acc": 52.0}
{"epoch": 1, "training_loss": 0.6918952989578248, "training_acc": 53.0, "val_loss": 0.7003020143508911, "val_acc": 52.0}
{"epoch": 2, "training_loss": 0.7087026643753052, "training_acc": 53.0, "val_loss": 0.696717529296875, "val_acc": 52.0}
{"epoch": 3, "training_loss": 0.702520694732666, "training_acc": 47.0, "val_loss": 0.7020114231109619, "val_acc": 48.0}
{"epoch": 4, "training_loss": 0.7032322931289673, "training_acc": 52.0, "val_loss": 0.7181076169013977, "val_acc": 52.0}
{"epoch": 5, "training_loss": 0.7034298181533813, "training_acc": 55.0, "val_loss": 0.6971868205070496, "val_acc": 48.0}
{"epoch": 6, "training_loss": 0.7143373322486878, "training_acc": 47.0, "val_loss": 0.6999458813667297, "val_acc": 48.0}
{"epoch": 7, "training_loss": 0.699108965396881, "training_acc": 45.0, "val_loss": 0.6985544347763062, "val_acc": 52.0}
{"epoch": 8, "training_loss": 0.6935474443435669, "training_acc": 53.0, "val_loss": 0.6976457858085632, "val_acc": 52.0}
{"epoch": 9, "training_loss": 0.6933289837837219, "training_acc": 55.0, "val_loss": 0.6971686840057373, "val_acc": 48.0}
{"epoch": 10, "training_loss": 0.6994226646423339, "training_acc": 47.0, "val_loss": 0.6947018647193909, "val_acc": 52.0}
{"epoch": 11, "training_loss": 0.6912179064750671, "training_acc": 53.0, "val_loss": 0.69434574842453, "val_acc": 52.0}
{"epoch": 12, "training_loss": 0.6931145787239075, "training_acc": 56.0, "val_loss": 0.6942355012893677, "val_acc": 52.0}
{"epoch": 13, "training_loss": 0.6951678085327149, "training_acc": 53.0, "val_loss": 0.7053718256950379, "val_acc": 52.0}
{"epoch": 14, "training_loss": 0.7089203786849976, "training_acc": 46.0, "val_loss": 0.6945009565353394, "val_acc": 52.0}
{"epoch": 15, "training_loss": 0.6913106679916382, "training_acc": 54.0, "val_loss": 0.700216863155365, "val_acc": 52.0}
{"epoch": 16, "training_loss": 0.698635733127594, "training_acc": 53.0, "val_loss": 0.6961154651641845, "val_acc": 52.0}
{"epoch": 17, "training_loss": 0.6999829864501953, "training_acc": 44.0, "val_loss": 0.6942084169387818, "val_acc": 52.0}
{"epoch": 18, "training_loss": 0.7123622560501098, "training_acc": 53.0, "val_loss": 0.7094251275062561, "val_acc": 52.0}
{"epoch": 19, "training_loss": 0.7023363447189331, "training_acc": 52.0, "val_loss": 0.6940939521789551, "val_acc": 52.0}
{"epoch": 20, "training_loss": 0.6994069004058838, "training_acc": 53.0, "val_loss": 0.7024093365669251, "val_acc": 52.0}
{"epoch": 21, "training_loss": 0.6969375944137574, "training_acc": 53.0, "val_loss": 0.6969106793403625, "val_acc": 52.0}
{"epoch": 22, "training_loss": 0.6912918567657471, "training_acc": 53.0, "val_loss": 0.6951870346069335, "val_acc": 52.0}
{"epoch": 23, "training_loss": 0.6873208856582642, "training_acc": 53.0, "val_loss": 0.6957982707023621, "val_acc": 48.0}
{"epoch": 24, "training_loss": 0.6938999962806701, "training_acc": 47.0, "val_loss": 0.6941522979736328, "val_acc": 52.0}
{"epoch": 25, "training_loss": 0.7197838211059571, "training_acc": 52.0, "val_loss": 0.7066342425346375, "val_acc": 52.0}
{"epoch": 26, "training_loss": 0.695544204711914, "training_acc": 47.0, "val_loss": 0.720723009109497, "val_acc": 48.0}
{"epoch": 27, "training_loss": 0.7178554844856262, "training_acc": 47.0, "val_loss": 0.6977784276008606, "val_acc": 48.0}
{"epoch": 28, "training_loss": 0.6901148748397827, "training_acc": 54.0, "val_loss": 0.697738528251648, "val_acc": 52.0}
{"epoch": 29, "training_loss": 0.6930091333389282, "training_acc": 53.0, "val_loss": 0.6964779806137085, "val_acc": 52.0}
{"epoch": 30, "training_loss": 0.6902868986129761, "training_acc": 53.0, "val_loss": 0.6945710444450378, "val_acc": 40.0}
{"epoch": 31, "training_loss": 0.7033612203598022, "training_acc": 48.0, "val_loss": 0.7104425144195556, "val_acc": 48.0}
{"epoch": 32, "training_loss": 0.6961714601516724, "training_acc": 50.0, "val_loss": 0.6949475479125976, "val_acc": 52.0}
{"epoch": 33, "training_loss": 0.6887517595291137, "training_acc": 53.0, "val_loss": 0.6965868306159974, "val_acc": 52.0}
{"epoch": 34, "training_loss": 0.6897411251068115, "training_acc": 53.0, "val_loss": 0.6973509335517883, "val_acc": 52.0}
{"epoch": 35, "training_loss": 0.6897457218170167, "training_acc": 53.0, "val_loss": 0.6956592869758605, "val_acc": 52.0}
{"epoch": 36, "training_loss": 0.7030341243743896, "training_acc": 53.0, "val_loss": 0.6964557957649231, "val_acc": 52.0}
{"epoch": 37, "training_loss": 0.6971675205230713, "training_acc": 49.0, "val_loss": 0.7010585737228393, "val_acc": 48.0}
{"epoch": 38, "training_loss": 0.6812704849243164, "training_acc": 57.0, "val_loss": 0.7017017221450805, "val_acc": 52.0}
