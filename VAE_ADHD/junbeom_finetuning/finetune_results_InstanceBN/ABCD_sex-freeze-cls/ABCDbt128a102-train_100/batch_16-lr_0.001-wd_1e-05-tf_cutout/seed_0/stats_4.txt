"main_modify.py --pretrained_path /scratch/connectome/dyhan316/VAE_ADHD/barlowtwins/pretrain_results/ABCDbt128a102.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option BT_org --learning_rate 1e-3 --batch_size 16 --weight_decay 1e-5 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 0.7072877192497253, "training_acc": 45.0, "val_loss": 0.696740562915802, "val_acc": 52.0}
{"epoch": 1, "training_loss": 0.7201307868957519, "training_acc": 53.0, "val_loss": 0.709330415725708, "val_acc": 52.0}
{"epoch": 2, "training_loss": 0.7050876331329345, "training_acc": 43.0, "val_loss": 0.7065658807754517, "val_acc": 48.0}
{"epoch": 3, "training_loss": 0.7016283702850342, "training_acc": 47.0, "val_loss": 0.6939024066925049, "val_acc": 52.0}
{"epoch": 4, "training_loss": 0.7104018640518188, "training_acc": 53.0, "val_loss": 0.7248691868782043, "val_acc": 52.0}
{"epoch": 5, "training_loss": 0.711852777004242, "training_acc": 53.0, "val_loss": 0.6945171546936035, "val_acc": 52.0}
{"epoch": 6, "training_loss": 0.6972984266281128, "training_acc": 44.0, "val_loss": 0.6939278841018677, "val_acc": 52.0}
{"epoch": 7, "training_loss": 0.7025005006790161, "training_acc": 53.0, "val_loss": 0.6997050595283508, "val_acc": 52.0}
{"epoch": 8, "training_loss": 0.6913922166824341, "training_acc": 53.0, "val_loss": 0.6936854720115662, "val_acc": 52.0}
{"epoch": 9, "training_loss": 0.6921993637084961, "training_acc": 56.0, "val_loss": 0.7004650998115539, "val_acc": 48.0}
{"epoch": 10, "training_loss": 0.6981550693511963, "training_acc": 47.0, "val_loss": 0.6946311926841736, "val_acc": 52.0}
{"epoch": 11, "training_loss": 0.7080309009552002, "training_acc": 53.0, "val_loss": 0.7069894766807556, "val_acc": 52.0}
{"epoch": 12, "training_loss": 0.7091095304489136, "training_acc": 45.0, "val_loss": 0.6977816867828369, "val_acc": 48.0}
{"epoch": 13, "training_loss": 0.6950642490386962, "training_acc": 45.0, "val_loss": 0.6937020468711853, "val_acc": 52.0}
{"epoch": 14, "training_loss": 0.7005648064613342, "training_acc": 53.0, "val_loss": 0.6974021530151367, "val_acc": 52.0}
{"epoch": 15, "training_loss": 0.6894764614105224, "training_acc": 53.0, "val_loss": 0.6945308375358582, "val_acc": 48.0}
{"epoch": 16, "training_loss": 0.694520287513733, "training_acc": 49.0, "val_loss": 0.6934797883033752, "val_acc": 52.0}
{"epoch": 17, "training_loss": 0.689406898021698, "training_acc": 53.0, "val_loss": 0.7072527623176574, "val_acc": 52.0}
{"epoch": 18, "training_loss": 0.7069501614570618, "training_acc": 53.0, "val_loss": 0.6980569052696228, "val_acc": 52.0}
{"epoch": 19, "training_loss": 0.6992666411399842, "training_acc": 51.0, "val_loss": 0.698980770111084, "val_acc": 48.0}
{"epoch": 20, "training_loss": 0.695855598449707, "training_acc": 47.0, "val_loss": 0.7004295468330384, "val_acc": 52.0}
{"epoch": 21, "training_loss": 0.6964178800582885, "training_acc": 53.0, "val_loss": 0.6942785048484802, "val_acc": 52.0}
{"epoch": 22, "training_loss": 0.6982707977294922, "training_acc": 49.0, "val_loss": 0.7105523276329041, "val_acc": 48.0}
{"epoch": 23, "training_loss": 0.7047148633003235, "training_acc": 47.0, "val_loss": 0.6932211756706238, "val_acc": 52.0}
{"epoch": 24, "training_loss": 0.7223458528518677, "training_acc": 53.0, "val_loss": 0.7095615863800049, "val_acc": 52.0}
{"epoch": 25, "training_loss": 0.700438163280487, "training_acc": 53.0, "val_loss": 0.7194250369071961, "val_acc": 48.0}
{"epoch": 26, "training_loss": 0.725710391998291, "training_acc": 45.0, "val_loss": 0.6934923267364502, "val_acc": 52.0}
{"epoch": 27, "training_loss": 0.6940408444404602, "training_acc": 46.0, "val_loss": 0.6934392809867859, "val_acc": 52.0}
{"epoch": 28, "training_loss": 0.6923055195808411, "training_acc": 53.0, "val_loss": 0.6973457837104797, "val_acc": 52.0}
{"epoch": 29, "training_loss": 0.6956059789657593, "training_acc": 53.0, "val_loss": 0.692867271900177, "val_acc": 52.0}
{"epoch": 30, "training_loss": 0.691383821964264, "training_acc": 53.0, "val_loss": 0.6929073309898377, "val_acc": 52.0}
{"epoch": 31, "training_loss": 0.6875984954833985, "training_acc": 58.0, "val_loss": 0.6958069133758545, "val_acc": 48.0}
{"epoch": 32, "training_loss": 0.6996842575073242, "training_acc": 41.0, "val_loss": 0.6925546169281006, "val_acc": 52.0}
{"epoch": 33, "training_loss": 0.6929765677452088, "training_acc": 51.0, "val_loss": 0.6966441297531127, "val_acc": 48.0}
{"epoch": 34, "training_loss": 0.6948936247825622, "training_acc": 47.0, "val_loss": 0.6951809620857239, "val_acc": 48.0}
{"epoch": 35, "training_loss": 0.6920069169998169, "training_acc": 51.0, "val_loss": 0.6923898077011108, "val_acc": 52.0}
{"epoch": 36, "training_loss": 0.6935068130493164, "training_acc": 53.0, "val_loss": 0.6963458442687989, "val_acc": 52.0}
{"epoch": 37, "training_loss": 0.6885309886932373, "training_acc": 53.0, "val_loss": 0.6923653388023376, "val_acc": 52.0}
{"epoch": 38, "training_loss": 0.6944147539138794, "training_acc": 45.0, "val_loss": 0.6966193127632141, "val_acc": 48.0}
{"epoch": 39, "training_loss": 0.6953789758682251, "training_acc": 51.0, "val_loss": 0.6930946707725525, "val_acc": 52.0}
{"epoch": 40, "training_loss": 0.6879369115829468, "training_acc": 53.0, "val_loss": 0.6979341149330139, "val_acc": 52.0}
{"epoch": 41, "training_loss": 0.6939739894866943, "training_acc": 53.0, "val_loss": 0.6939927315711976, "val_acc": 52.0}
{"epoch": 42, "training_loss": 0.6910518860816955, "training_acc": 48.0, "val_loss": 0.6930752563476562, "val_acc": 44.0}
{"epoch": 43, "training_loss": 0.686337661743164, "training_acc": 67.0, "val_loss": 0.6962474393844604, "val_acc": 52.0}
{"epoch": 44, "training_loss": 0.7149826836585998, "training_acc": 53.0, "val_loss": 0.7307217240333557, "val_acc": 52.0}
{"epoch": 45, "training_loss": 0.7167819690704346, "training_acc": 53.0, "val_loss": 0.6925173830986023, "val_acc": 52.0}
{"epoch": 46, "training_loss": 0.6890222835540771, "training_acc": 53.0, "val_loss": 0.6921164631843567, "val_acc": 52.0}
{"epoch": 47, "training_loss": 0.6950680232048034, "training_acc": 45.0, "val_loss": 0.6936655926704407, "val_acc": 48.0}
{"epoch": 48, "training_loss": 0.6950899648666382, "training_acc": 50.0, "val_loss": 0.6923137331008911, "val_acc": 48.0}
{"epoch": 49, "training_loss": 0.6870488500595093, "training_acc": 54.0, "val_loss": 0.6933211421966553, "val_acc": 52.0}
{"epoch": 50, "training_loss": 0.6891206288337708, "training_acc": 53.0, "val_loss": 0.6935395264625549, "val_acc": 52.0}
{"epoch": 51, "training_loss": 0.6913187313079834, "training_acc": 53.0, "val_loss": 0.6935851597785949, "val_acc": 52.0}
{"epoch": 52, "training_loss": 0.6938229155540466, "training_acc": 53.0, "val_loss": 0.7048990845680236, "val_acc": 52.0}
{"epoch": 53, "training_loss": 0.7072953009605407, "training_acc": 54.0, "val_loss": 0.6924787259101868, "val_acc": 56.0}
{"epoch": 54, "training_loss": 0.6931961965560913, "training_acc": 53.0, "val_loss": 0.6961948704719544, "val_acc": 52.0}
{"epoch": 55, "training_loss": 0.6997103953361511, "training_acc": 53.0, "val_loss": 0.7042620325088501, "val_acc": 52.0}
{"epoch": 56, "training_loss": 0.696127336025238, "training_acc": 53.0, "val_loss": 0.6947459053993225, "val_acc": 52.0}
{"epoch": 57, "training_loss": 0.7092236375808716, "training_acc": 39.0, "val_loss": 0.6969569396972656, "val_acc": 48.0}
{"epoch": 58, "training_loss": 0.689601902961731, "training_acc": 55.0, "val_loss": 0.7048781991004944, "val_acc": 52.0}
{"epoch": 59, "training_loss": 0.7142181468009948, "training_acc": 53.0, "val_loss": 0.7049453234672547, "val_acc": 52.0}
{"epoch": 60, "training_loss": 0.6882811260223388, "training_acc": 58.0, "val_loss": 0.6952613925933838, "val_acc": 48.0}
{"epoch": 61, "training_loss": 0.6941781878471375, "training_acc": 47.0, "val_loss": 0.6918206906318665, "val_acc": 52.0}
{"epoch": 62, "training_loss": 0.6886062812805176, "training_acc": 56.0, "val_loss": 0.7060321164131165, "val_acc": 52.0}
{"epoch": 63, "training_loss": 0.6905627059936523, "training_acc": 53.0, "val_loss": 0.6913593125343322, "val_acc": 52.0}
{"epoch": 64, "training_loss": 0.6848200988769532, "training_acc": 57.0, "val_loss": 0.6936483550071716, "val_acc": 48.0}
{"epoch": 65, "training_loss": 0.6963475346565247, "training_acc": 47.0, "val_loss": 0.6941965103149415, "val_acc": 48.0}
{"epoch": 66, "training_loss": 0.6896139574050903, "training_acc": 50.0, "val_loss": 0.6919342923164368, "val_acc": 56.0}
{"epoch": 67, "training_loss": 0.6912619495391845, "training_acc": 50.0, "val_loss": 0.6915402388572693, "val_acc": 52.0}
{"epoch": 68, "training_loss": 0.6927156877517701, "training_acc": 54.0, "val_loss": 0.7108717560768127, "val_acc": 52.0}
{"epoch": 69, "training_loss": 0.6932615566253663, "training_acc": 53.0, "val_loss": 0.6932593750953674, "val_acc": 48.0}
{"epoch": 70, "training_loss": 0.692812306880951, "training_acc": 45.0, "val_loss": 0.6910169887542724, "val_acc": 52.0}
{"epoch": 71, "training_loss": 0.6862034749984741, "training_acc": 54.0, "val_loss": 0.6911173987388611, "val_acc": 52.0}
{"epoch": 72, "training_loss": 0.6952917337417602, "training_acc": 53.0, "val_loss": 0.6937423896789551, "val_acc": 52.0}
{"epoch": 73, "training_loss": 0.6826286792755127, "training_acc": 55.0, "val_loss": 0.6940454411506652, "val_acc": 48.0}
{"epoch": 74, "training_loss": 0.7048825359344483, "training_acc": 47.0, "val_loss": 0.6963414001464844, "val_acc": 48.0}
{"epoch": 75, "training_loss": 0.6895303964614868, "training_acc": 53.0, "val_loss": 0.6918761897087097, "val_acc": 52.0}
{"epoch": 76, "training_loss": 0.6865496587753296, "training_acc": 54.0, "val_loss": 0.6907910346984864, "val_acc": 52.0}
{"epoch": 77, "training_loss": 0.6840944647789001, "training_acc": 54.0, "val_loss": 0.6908282136917114, "val_acc": 52.0}
{"epoch": 78, "training_loss": 0.6837596750259399, "training_acc": 53.0, "val_loss": 0.6912972855567933, "val_acc": 52.0}
{"epoch": 79, "training_loss": 0.6854399061203003, "training_acc": 55.0, "val_loss": 0.690641257762909, "val_acc": 52.0}
{"epoch": 80, "training_loss": 0.6834998941421508, "training_acc": 55.0, "val_loss": 0.6907570910453796, "val_acc": 52.0}
{"epoch": 81, "training_loss": 0.6829481267929077, "training_acc": 53.0, "val_loss": 0.6908050918579102, "val_acc": 52.0}
{"epoch": 82, "training_loss": 0.7089218568801879, "training_acc": 37.0, "val_loss": 0.6930953192710877, "val_acc": 48.0}
{"epoch": 83, "training_loss": 0.69263596534729, "training_acc": 53.0, "val_loss": 0.6991088008880615, "val_acc": 52.0}
{"epoch": 84, "training_loss": 0.6794546222686768, "training_acc": 53.0, "val_loss": 0.6917392253875733, "val_acc": 52.0}
{"epoch": 85, "training_loss": 0.6917118549346923, "training_acc": 48.0, "val_loss": 0.7014376544952392, "val_acc": 48.0}
{"epoch": 86, "training_loss": 0.693853211402893, "training_acc": 47.0, "val_loss": 0.6934157967567444, "val_acc": 52.0}
{"epoch": 87, "training_loss": 0.6849834728240967, "training_acc": 53.0, "val_loss": 0.6911998128890992, "val_acc": 52.0}
{"epoch": 88, "training_loss": 0.6800179529190064, "training_acc": 60.0, "val_loss": 0.691519844532013, "val_acc": 56.0}
{"epoch": 89, "training_loss": 0.6848802709579468, "training_acc": 59.0, "val_loss": 0.6914776968955993, "val_acc": 52.0}
{"epoch": 90, "training_loss": 0.6944862031936645, "training_acc": 53.0, "val_loss": 0.7055633473396301, "val_acc": 52.0}
{"epoch": 91, "training_loss": 0.6859743666648864, "training_acc": 55.0, "val_loss": 0.6915218687057495, "val_acc": 56.0}
{"epoch": 92, "training_loss": 0.6898764896392823, "training_acc": 50.0, "val_loss": 0.691423351764679, "val_acc": 52.0}
{"epoch": 93, "training_loss": 0.681251437664032, "training_acc": 66.0, "val_loss": 0.6936695218086243, "val_acc": 52.0}
{"epoch": 94, "training_loss": 0.687436785697937, "training_acc": 53.0, "val_loss": 0.6912177610397339, "val_acc": 52.0}
{"epoch": 95, "training_loss": 0.6848712158203125, "training_acc": 53.0, "val_loss": 0.6960392069816589, "val_acc": 52.0}
{"epoch": 96, "training_loss": 0.688372609615326, "training_acc": 53.0, "val_loss": 0.6935076522827148, "val_acc": 52.0}
{"epoch": 97, "training_loss": 0.6852971744537354, "training_acc": 53.0, "val_loss": 0.6929911518096924, "val_acc": 52.0}
{"epoch": 98, "training_loss": 0.695610589981079, "training_acc": 53.0, "val_loss": 0.6932013130187988, "val_acc": 52.0}
