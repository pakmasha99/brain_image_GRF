"main_modify.py --pretrained_path /scratch/connectome/dyhan316/VAE_ADHD/barlowtwins/pretrain_results/ABCDbt128a102.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 1 --task ABCD_sex --input_option BT_org --learning_rate 1e-3 --batch_size 16 --weight_decay 1e-5 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 0.7076517844200134, "training_acc": 47.0, "val_loss": 0.7106386613845825, "val_acc": 52.0}
{"epoch": 1, "training_loss": 0.7310206079483033, "training_acc": 53.0, "val_loss": 0.7053261709213257, "val_acc": 52.0}
{"epoch": 2, "training_loss": 0.7009311151504517, "training_acc": 53.0, "val_loss": 0.6908815121650695, "val_acc": 52.0}
{"epoch": 3, "training_loss": 0.7033920526504517, "training_acc": 41.0, "val_loss": 0.6911680150032044, "val_acc": 68.0}
{"epoch": 4, "training_loss": 0.6932764959335327, "training_acc": 48.0, "val_loss": 0.6921884632110595, "val_acc": 52.0}
{"epoch": 5, "training_loss": 0.7098131585121155, "training_acc": 53.0, "val_loss": 0.7096021318435669, "val_acc": 52.0}
{"epoch": 6, "training_loss": 0.703467493057251, "training_acc": 53.0, "val_loss": 0.6905016922950744, "val_acc": 52.0}
{"epoch": 7, "training_loss": 0.7056497430801392, "training_acc": 48.0, "val_loss": 0.6981501126289368, "val_acc": 48.0}
{"epoch": 8, "training_loss": 0.6941472268104554, "training_acc": 51.0, "val_loss": 0.6934376621246338, "val_acc": 52.0}
{"epoch": 9, "training_loss": 0.7044799828529358, "training_acc": 53.0, "val_loss": 0.6960535049438477, "val_acc": 52.0}
{"epoch": 10, "training_loss": 0.7032123255729675, "training_acc": 45.0, "val_loss": 0.6944945001602173, "val_acc": 48.0}
{"epoch": 11, "training_loss": 0.6934093236923218, "training_acc": 52.0, "val_loss": 0.6916461777687073, "val_acc": 52.0}
{"epoch": 12, "training_loss": 0.69775146484375, "training_acc": 53.0, "val_loss": 0.7025876855850219, "val_acc": 52.0}
{"epoch": 13, "training_loss": 0.692066740989685, "training_acc": 53.0, "val_loss": 0.6909860730171203, "val_acc": 64.0}
{"epoch": 14, "training_loss": 0.7126093149185181, "training_acc": 48.0, "val_loss": 0.7029962468147278, "val_acc": 48.0}
{"epoch": 15, "training_loss": 0.7237864542007446, "training_acc": 39.0, "val_loss": 0.6982476878166198, "val_acc": 52.0}
{"epoch": 16, "training_loss": 0.692023115158081, "training_acc": 53.0, "val_loss": 0.6904697036743164, "val_acc": 52.0}
{"epoch": 17, "training_loss": 0.6907200050354004, "training_acc": 53.0, "val_loss": 0.6904896235466004, "val_acc": 52.0}
{"epoch": 18, "training_loss": 0.6926852178573608, "training_acc": 47.0, "val_loss": 0.6913240790367127, "val_acc": 56.0}
{"epoch": 19, "training_loss": 0.6873274755477905, "training_acc": 56.0, "val_loss": 0.6955781507492066, "val_acc": 52.0}
{"epoch": 20, "training_loss": 0.7010938310623169, "training_acc": 53.0, "val_loss": 0.6924878692626953, "val_acc": 52.0}
{"epoch": 21, "training_loss": 0.6933301734924316, "training_acc": 53.0, "val_loss": 0.6920224380493164, "val_acc": 52.0}
{"epoch": 22, "training_loss": 0.6968610572814942, "training_acc": 53.0, "val_loss": 0.6956300592422485, "val_acc": 52.0}
{"epoch": 23, "training_loss": 0.6906381511688232, "training_acc": 54.0, "val_loss": 0.6987348556518554, "val_acc": 48.0}
{"epoch": 24, "training_loss": 0.7069660377502441, "training_acc": 47.0, "val_loss": 0.6906112027168274, "val_acc": 52.0}
{"epoch": 25, "training_loss": 0.6888832879066468, "training_acc": 53.0, "val_loss": 0.7221245551109314, "val_acc": 52.0}
{"epoch": 26, "training_loss": 0.7058367300033569, "training_acc": 53.0, "val_loss": 0.6908370327949523, "val_acc": 52.0}
{"epoch": 27, "training_loss": 0.6943870067596436, "training_acc": 53.0, "val_loss": 0.690438334941864, "val_acc": 52.0}
{"epoch": 28, "training_loss": 0.7144077920913696, "training_acc": 43.0, "val_loss": 0.7007568788528442, "val_acc": 48.0}
{"epoch": 29, "training_loss": 0.711604299545288, "training_acc": 45.0, "val_loss": 0.7060608577728271, "val_acc": 52.0}
{"epoch": 30, "training_loss": 0.6938691329956055, "training_acc": 53.0, "val_loss": 0.6906655049324035, "val_acc": 52.0}
{"epoch": 31, "training_loss": 0.6880726337432861, "training_acc": 61.0, "val_loss": 0.6941222310066223, "val_acc": 48.0}
{"epoch": 32, "training_loss": 0.6941670942306518, "training_acc": 51.0, "val_loss": 0.690592930316925, "val_acc": 52.0}
{"epoch": 33, "training_loss": 0.6972537326812744, "training_acc": 53.0, "val_loss": 0.7020979499816895, "val_acc": 52.0}
{"epoch": 34, "training_loss": 0.7019307804107666, "training_acc": 53.0, "val_loss": 0.697387866973877, "val_acc": 52.0}
{"epoch": 35, "training_loss": 0.6943420147895814, "training_acc": 50.0, "val_loss": 0.698535726070404, "val_acc": 48.0}
{"epoch": 36, "training_loss": 0.7016781377792358, "training_acc": 47.0, "val_loss": 0.692935643196106, "val_acc": 48.0}
{"epoch": 37, "training_loss": 0.6916299962997436, "training_acc": 45.0, "val_loss": 0.6908783864974976, "val_acc": 56.0}
{"epoch": 38, "training_loss": 0.6881269693374634, "training_acc": 56.0, "val_loss": 0.6937190628051758, "val_acc": 52.0}
{"epoch": 39, "training_loss": 0.6878736090660095, "training_acc": 53.0, "val_loss": 0.6911296105384827, "val_acc": 52.0}
{"epoch": 40, "training_loss": 0.6878481817245483, "training_acc": 56.0, "val_loss": 0.6916848826408386, "val_acc": 48.0}
{"epoch": 41, "training_loss": 0.6897270131111145, "training_acc": 53.0, "val_loss": 0.6907761335372925, "val_acc": 56.0}
{"epoch": 42, "training_loss": 0.6863555765151977, "training_acc": 54.0, "val_loss": 0.6936993432044983, "val_acc": 52.0}
{"epoch": 43, "training_loss": 0.6927010560035706, "training_acc": 52.0, "val_loss": 0.6905738544464112, "val_acc": 52.0}
{"epoch": 44, "training_loss": 0.6850965309143067, "training_acc": 53.0, "val_loss": 0.6922414326667785, "val_acc": 52.0}
{"epoch": 45, "training_loss": 0.6905400228500366, "training_acc": 53.0, "val_loss": 0.6957218408584595, "val_acc": 52.0}
{"epoch": 46, "training_loss": 0.7004296588897705, "training_acc": 50.0, "val_loss": 0.7022867703437805, "val_acc": 48.0}
