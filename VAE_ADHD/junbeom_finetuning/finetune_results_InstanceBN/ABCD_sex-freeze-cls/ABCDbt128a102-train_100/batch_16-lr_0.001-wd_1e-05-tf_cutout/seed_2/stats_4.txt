"main_modify.py --pretrained_path /scratch/connectome/dyhan316/VAE_ADHD/barlowtwins/pretrain_results/ABCDbt128a102.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 2 --task ABCD_sex --input_option BT_org --learning_rate 1e-3 --batch_size 16 --weight_decay 1e-5 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 0.7221312379837036, "training_acc": 46.0, "val_loss": 0.6910947513580322, "val_acc": 56.0}
{"epoch": 1, "training_loss": 0.7009164571762085, "training_acc": 52.0, "val_loss": 0.6884402418136597, "val_acc": 56.0}
{"epoch": 2, "training_loss": 0.7091615509986877, "training_acc": 52.0, "val_loss": 0.688918468952179, "val_acc": 56.0}
{"epoch": 3, "training_loss": 0.7056314325332642, "training_acc": 42.0, "val_loss": 0.7001455926895142, "val_acc": 44.0}
{"epoch": 4, "training_loss": 0.6962530946731568, "training_acc": 53.0, "val_loss": 0.6885791087150573, "val_acc": 56.0}
{"epoch": 5, "training_loss": 0.6954176640510559, "training_acc": 52.0, "val_loss": 0.6933394956588745, "val_acc": 44.0}
{"epoch": 6, "training_loss": 0.6950133943557739, "training_acc": 54.0, "val_loss": 0.708468611240387, "val_acc": 44.0}
{"epoch": 7, "training_loss": 0.6989151740074158, "training_acc": 48.0, "val_loss": 0.6868371438980102, "val_acc": 56.0}
{"epoch": 8, "training_loss": 0.7017032146453858, "training_acc": 49.0, "val_loss": 0.6924801301956177, "val_acc": 56.0}
{"epoch": 9, "training_loss": 0.6925862526893616, "training_acc": 49.0, "val_loss": 0.6886949276924134, "val_acc": 56.0}
{"epoch": 10, "training_loss": 0.7215705347061158, "training_acc": 52.0, "val_loss": 0.6889228296279907, "val_acc": 56.0}
{"epoch": 11, "training_loss": 0.6897232389450073, "training_acc": 59.0, "val_loss": 0.721016321182251, "val_acc": 44.0}
{"epoch": 12, "training_loss": 0.6947920489311218, "training_acc": 50.0, "val_loss": 0.6882006764411926, "val_acc": 56.0}
{"epoch": 13, "training_loss": 0.7122640585899354, "training_acc": 52.0, "val_loss": 0.6896430706977844, "val_acc": 56.0}
{"epoch": 14, "training_loss": 0.6956939744949341, "training_acc": 48.0, "val_loss": 0.7266504979133606, "val_acc": 44.0}
{"epoch": 15, "training_loss": 0.6984965181350709, "training_acc": 50.0, "val_loss": 0.689133677482605, "val_acc": 56.0}
{"epoch": 16, "training_loss": 0.6924358558654785, "training_acc": 52.0, "val_loss": 0.6873934650421143, "val_acc": 56.0}
{"epoch": 17, "training_loss": 0.69670161485672, "training_acc": 46.0, "val_loss": 0.694619529247284, "val_acc": 52.0}
{"epoch": 18, "training_loss": 0.6891885328292847, "training_acc": 56.0, "val_loss": 0.6881044626235961, "val_acc": 56.0}
{"epoch": 19, "training_loss": 0.6957159256935119, "training_acc": 52.0, "val_loss": 0.6907616806030273, "val_acc": 56.0}
{"epoch": 20, "training_loss": 0.6907922863960266, "training_acc": 58.0, "val_loss": 0.6923469805717468, "val_acc": 56.0}
{"epoch": 21, "training_loss": 0.68837895154953, "training_acc": 55.0, "val_loss": 0.6876116251945495, "val_acc": 56.0}
{"epoch": 22, "training_loss": 0.696260256767273, "training_acc": 52.0, "val_loss": 0.6882563257217407, "val_acc": 56.0}
{"epoch": 23, "training_loss": 0.6911740255355835, "training_acc": 53.0, "val_loss": 0.6963307237625123, "val_acc": 36.0}
{"epoch": 24, "training_loss": 0.691550350189209, "training_acc": 47.0, "val_loss": 0.6970779466629028, "val_acc": 40.0}
{"epoch": 25, "training_loss": 0.7018213129043579, "training_acc": 48.0, "val_loss": 0.7160673213005065, "val_acc": 44.0}
{"epoch": 26, "training_loss": 0.7131097507476807, "training_acc": 52.0, "val_loss": 0.6908470129966736, "val_acc": 56.0}
