"main_modify.py --pretrained_path /scratch/connectome/dyhan316/VAE_ADHD/barlowtwins/pretrain_results/ABCDbt128a102.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 2 --task ABCD_sex --input_option BT_org --learning_rate 1e-3 --batch_size 16 --weight_decay 1e-5 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 0.7257666110992431, "training_acc": 43.0, "val_loss": 0.6931812763214111, "val_acc": 52.0}
{"epoch": 1, "training_loss": 0.7104957485198975, "training_acc": 49.0, "val_loss": 0.7091239666938782, "val_acc": 52.0}
{"epoch": 2, "training_loss": 0.700674409866333, "training_acc": 53.0, "val_loss": 0.6918124532699585, "val_acc": 52.0}
{"epoch": 3, "training_loss": 0.692668685913086, "training_acc": 53.0, "val_loss": 0.6918758368492126, "val_acc": 52.0}
{"epoch": 4, "training_loss": 0.6925494980812072, "training_acc": 53.0, "val_loss": 0.6916957449913025, "val_acc": 52.0}
{"epoch": 5, "training_loss": 0.6910198998451232, "training_acc": 53.0, "val_loss": 0.6916210198402405, "val_acc": 52.0}
{"epoch": 6, "training_loss": 0.695714373588562, "training_acc": 48.0, "val_loss": 0.6928257799148559, "val_acc": 52.0}
{"epoch": 7, "training_loss": 0.7077153444290161, "training_acc": 53.0, "val_loss": 0.7200222015380859, "val_acc": 52.0}
{"epoch": 8, "training_loss": 0.706482515335083, "training_acc": 53.0, "val_loss": 0.6913168168067932, "val_acc": 52.0}
{"epoch": 9, "training_loss": 0.6927274799346924, "training_acc": 53.0, "val_loss": 0.6914323377609253, "val_acc": 52.0}
{"epoch": 10, "training_loss": 0.691272144317627, "training_acc": 49.0, "val_loss": 0.6920143604278565, "val_acc": 60.0}
{"epoch": 11, "training_loss": 0.6946422052383423, "training_acc": 47.0, "val_loss": 0.6912713146209717, "val_acc": 52.0}
{"epoch": 12, "training_loss": 0.6924447822570801, "training_acc": 53.0, "val_loss": 0.6973065686225891, "val_acc": 52.0}
{"epoch": 13, "training_loss": 0.7020921444892884, "training_acc": 43.0, "val_loss": 0.6930042028427124, "val_acc": 48.0}
{"epoch": 14, "training_loss": 0.7002428412437439, "training_acc": 47.0, "val_loss": 0.6929778218269348, "val_acc": 48.0}
{"epoch": 15, "training_loss": 0.6959887075424195, "training_acc": 51.0, "val_loss": 0.7036281156539917, "val_acc": 52.0}
{"epoch": 16, "training_loss": 0.6950809073448181, "training_acc": 53.0, "val_loss": 0.6909528231620788, "val_acc": 52.0}
{"epoch": 17, "training_loss": 0.6997947835922241, "training_acc": 45.0, "val_loss": 0.6940540337562561, "val_acc": 48.0}
{"epoch": 18, "training_loss": 0.6876761674880981, "training_acc": 59.0, "val_loss": 0.6941896677017212, "val_acc": 52.0}
{"epoch": 19, "training_loss": 0.7009118437767029, "training_acc": 53.0, "val_loss": 0.6933409571647644, "val_acc": 52.0}
{"epoch": 20, "training_loss": 0.7020870208740234, "training_acc": 47.0, "val_loss": 0.713303062915802, "val_acc": 48.0}
{"epoch": 21, "training_loss": 0.701601014137268, "training_acc": 51.0, "val_loss": 0.6918172883987427, "val_acc": 52.0}
{"epoch": 22, "training_loss": 0.6918656301498413, "training_acc": 53.0, "val_loss": 0.6952518987655639, "val_acc": 52.0}
{"epoch": 23, "training_loss": 0.6899948763847351, "training_acc": 58.0, "val_loss": 0.6929888844490051, "val_acc": 48.0}
{"epoch": 24, "training_loss": 0.6930797171592712, "training_acc": 48.0, "val_loss": 0.6903871512413025, "val_acc": 52.0}
{"epoch": 25, "training_loss": 0.6868734312057495, "training_acc": 53.0, "val_loss": 0.6930549550056457, "val_acc": 52.0}
{"epoch": 26, "training_loss": 0.6947323989868164, "training_acc": 50.0, "val_loss": 0.690404748916626, "val_acc": 56.0}
{"epoch": 27, "training_loss": 0.7003851842880249, "training_acc": 54.0, "val_loss": 0.696130211353302, "val_acc": 52.0}
{"epoch": 28, "training_loss": 0.6903005790710449, "training_acc": 53.0, "val_loss": 0.6936199474334717, "val_acc": 48.0}
{"epoch": 29, "training_loss": 0.6889782261848449, "training_acc": 50.0, "val_loss": 0.69295893907547, "val_acc": 52.0}
{"epoch": 30, "training_loss": 0.6915678215026856, "training_acc": 53.0, "val_loss": 0.6943906521797181, "val_acc": 52.0}
{"epoch": 31, "training_loss": 0.6877753591537475, "training_acc": 53.0, "val_loss": 0.6898723745346069, "val_acc": 52.0}
{"epoch": 32, "training_loss": 0.6883774852752685, "training_acc": 53.0, "val_loss": 0.6896473789215087, "val_acc": 52.0}
{"epoch": 33, "training_loss": 0.6909603905677796, "training_acc": 53.0, "val_loss": 0.690239450931549, "val_acc": 52.0}
{"epoch": 34, "training_loss": 0.6849387836456299, "training_acc": 53.0, "val_loss": 0.7000043892860413, "val_acc": 52.0}
{"epoch": 35, "training_loss": 0.6926941633224487, "training_acc": 53.0, "val_loss": 0.6929956126213074, "val_acc": 52.0}
{"epoch": 36, "training_loss": 0.6859117698669434, "training_acc": 55.0, "val_loss": 0.6895853734016418, "val_acc": 52.0}
{"epoch": 37, "training_loss": 0.6894967865943908, "training_acc": 54.0, "val_loss": 0.6921024703979493, "val_acc": 52.0}
{"epoch": 38, "training_loss": 0.6920158433914184, "training_acc": 53.0, "val_loss": 0.6890141439437866, "val_acc": 52.0}
{"epoch": 39, "training_loss": 0.6907948446273804, "training_acc": 48.0, "val_loss": 0.6889228391647338, "val_acc": 52.0}
{"epoch": 40, "training_loss": 0.6888098311424256, "training_acc": 53.0, "val_loss": 0.6950241112709046, "val_acc": 52.0}
{"epoch": 41, "training_loss": 0.7021234798431396, "training_acc": 53.0, "val_loss": 0.6918790698051452, "val_acc": 52.0}
{"epoch": 42, "training_loss": 0.6968523788452149, "training_acc": 45.0, "val_loss": 0.700086064338684, "val_acc": 48.0}
{"epoch": 43, "training_loss": 0.697628583908081, "training_acc": 49.0, "val_loss": 0.7014512300491333, "val_acc": 52.0}
{"epoch": 44, "training_loss": 0.6943307662010193, "training_acc": 53.0, "val_loss": 0.6939123463630676, "val_acc": 52.0}
{"epoch": 45, "training_loss": 0.6884691548347474, "training_acc": 53.0, "val_loss": 0.6890770745277405, "val_acc": 52.0}
{"epoch": 46, "training_loss": 0.688941102027893, "training_acc": 59.0, "val_loss": 0.6891926383972168, "val_acc": 52.0}
{"epoch": 47, "training_loss": 0.7189342403411865, "training_acc": 53.0, "val_loss": 0.6991214108467102, "val_acc": 52.0}
{"epoch": 48, "training_loss": 0.6907099413871766, "training_acc": 52.0, "val_loss": 0.7184871292114258, "val_acc": 48.0}
{"epoch": 49, "training_loss": 0.7100389742851257, "training_acc": 48.0, "val_loss": 0.6892316746711731, "val_acc": 52.0}
{"epoch": 50, "training_loss": 0.7001188802719116, "training_acc": 53.0, "val_loss": 0.6977616810798645, "val_acc": 52.0}
{"epoch": 51, "training_loss": 0.69901930809021, "training_acc": 53.0, "val_loss": 0.7048163723945617, "val_acc": 48.0}
{"epoch": 52, "training_loss": 0.6808880686759948, "training_acc": 57.0, "val_loss": 0.703906774520874, "val_acc": 52.0}
{"epoch": 53, "training_loss": 0.7394805693626404, "training_acc": 53.0, "val_loss": 0.7068043756484985, "val_acc": 52.0}
{"epoch": 54, "training_loss": 0.6973150777816772, "training_acc": 53.0, "val_loss": 0.7239014410972595, "val_acc": 48.0}
{"epoch": 55, "training_loss": 0.7219489765167236, "training_acc": 47.0, "val_loss": 0.6900088977813721, "val_acc": 52.0}
{"epoch": 56, "training_loss": 0.68246000289917, "training_acc": 56.0, "val_loss": 0.6972052478790283, "val_acc": 52.0}
{"epoch": 57, "training_loss": 0.6992089509963989, "training_acc": 53.0, "val_loss": 0.692352192401886, "val_acc": 52.0}
{"epoch": 58, "training_loss": 0.7278471422195435, "training_acc": 42.0, "val_loss": 0.7095063066482544, "val_acc": 48.0}
