"main_modify.py --pretrained_path /scratch/connectome/dyhan316/VAE_ADHD/barlowtwins/pretrain_results/ABCDbt128a102.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option BT_org --learning_rate 1e0 --batch_size 16 --weight_decay 1e-2 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 112.02381198883057, "training_acc": 46.0, "val_loss": 32.35738967895508, "val_acc": 56.0}
{"epoch": 1, "training_loss": 52.72098266601562, "training_acc": 50.0, "val_loss": 99.71509948730468, "val_acc": 44.0}
{"epoch": 2, "training_loss": 62.19143661499024, "training_acc": 50.0, "val_loss": 36.47474594116211, "val_acc": 56.0}
{"epoch": 3, "training_loss": 26.91867919921875, "training_acc": 42.0, "val_loss": 17.86543426513672, "val_acc": 44.0}
{"epoch": 4, "training_loss": 34.671288681030276, "training_acc": 50.0, "val_loss": 36.629222259521484, "val_acc": 56.0}
{"epoch": 5, "training_loss": 37.90139617919922, "training_acc": 48.0, "val_loss": 26.105002822875978, "val_acc": 56.0}
{"epoch": 6, "training_loss": 19.495418577194215, "training_acc": 46.0, "val_loss": 19.015773696899416, "val_acc": 44.0}
{"epoch": 7, "training_loss": 25.087853240966798, "training_acc": 52.0, "val_loss": 16.83240612030029, "val_acc": 44.0}
{"epoch": 8, "training_loss": 24.409629268646242, "training_acc": 46.0, "val_loss": 15.081738052368165, "val_acc": 44.0}
{"epoch": 9, "training_loss": 10.387801437377929, "training_acc": 60.0, "val_loss": 20.51543312072754, "val_acc": 44.0}
{"epoch": 10, "training_loss": 30.936896591186525, "training_acc": 46.0, "val_loss": 24.567568969726562, "val_acc": 44.0}
{"epoch": 11, "training_loss": 16.215310516357423, "training_acc": 52.0, "val_loss": 4.496142082214355, "val_acc": 56.0}
{"epoch": 12, "training_loss": 11.070431261062621, "training_acc": 52.0, "val_loss": 24.317800064086914, "val_acc": 44.0}
{"epoch": 13, "training_loss": 19.287298107147215, "training_acc": 52.0, "val_loss": 2.874278230667114, "val_acc": 56.0}
{"epoch": 14, "training_loss": 7.042498226165772, "training_acc": 54.0, "val_loss": 12.400589675903321, "val_acc": 56.0}
{"epoch": 15, "training_loss": 15.295680666279514, "training_acc": 54.0, "val_loss": 7.797099571228028, "val_acc": 44.0}
{"epoch": 16, "training_loss": 6.3592846488952635, "training_acc": 58.0, "val_loss": 16.1260391998291, "val_acc": 44.0}
{"epoch": 17, "training_loss": 15.083907165527343, "training_acc": 48.0, "val_loss": 4.1378160667419435, "val_acc": 44.0}
{"epoch": 18, "training_loss": 11.98136215209961, "training_acc": 44.0, "val_loss": 23.15873405456543, "val_acc": 44.0}
{"epoch": 19, "training_loss": 25.816133499145508, "training_acc": 46.0, "val_loss": 2.5441746711730957, "val_acc": 44.0}
{"epoch": 20, "training_loss": 24.107846832275392, "training_acc": 46.0, "val_loss": 0.6716902923583984, "val_acc": 72.0}
{"epoch": 21, "training_loss": 22.158288345336913, "training_acc": 55.0, "val_loss": 12.750939331054688, "val_acc": 56.0}
{"epoch": 22, "training_loss": 22.99309242248535, "training_acc": 56.0, "val_loss": 28.086770782470705, "val_acc": 44.0}
{"epoch": 23, "training_loss": 25.15858085632324, "training_acc": 48.0, "val_loss": 47.38563034057617, "val_acc": 44.0}
{"epoch": 24, "training_loss": 65.45890502929687, "training_acc": 44.0, "val_loss": 0.9938873267173767, "val_acc": 44.0}
{"epoch": 25, "training_loss": 22.373855381011964, "training_acc": 50.0, "val_loss": 49.73327850341797, "val_acc": 56.0}
{"epoch": 26, "training_loss": 29.963938522338868, "training_acc": 60.0, "val_loss": 1.4100583219528198, "val_acc": 44.0}
{"epoch": 27, "training_loss": 50.84086170196533, "training_acc": 46.0, "val_loss": 57.08798843383789, "val_acc": 44.0}
{"epoch": 28, "training_loss": 25.042547435760497, "training_acc": 54.0, "val_loss": 0.648130292892456, "val_acc": 68.0}
{"epoch": 29, "training_loss": 4.252393569946289, "training_acc": 53.0, "val_loss": 37.81662353515625, "val_acc": 56.0}
{"epoch": 30, "training_loss": 34.52956985473633, "training_acc": 60.0, "val_loss": 49.43038818359375, "val_acc": 44.0}
{"epoch": 31, "training_loss": 49.34506713867187, "training_acc": 54.0, "val_loss": 8.431925010681152, "val_acc": 56.0}
{"epoch": 32, "training_loss": 30.371451263427733, "training_acc": 48.0, "val_loss": 41.121287689208984, "val_acc": 56.0}
{"epoch": 33, "training_loss": 22.823276748657225, "training_acc": 46.0, "val_loss": 19.543008117675782, "val_acc": 56.0}
