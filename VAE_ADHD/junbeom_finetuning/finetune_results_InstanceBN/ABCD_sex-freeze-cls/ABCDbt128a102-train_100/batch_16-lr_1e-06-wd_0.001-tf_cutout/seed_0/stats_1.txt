"main_modify.py --pretrained_path /scratch/connectome/dyhan316/VAE_ADHD/barlowtwins/pretrain_results/ABCDbt128a102.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option BT_org --learning_rate 1e-6 --batch_size 16 --weight_decay 1e-3 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 0.7045204067230224, "training_acc": 47.0, "val_loss": 0.7034223580360413, "val_acc": 48.0}
{"epoch": 1, "training_loss": 0.7041088342666626, "training_acc": 47.0, "val_loss": 0.7033606910705567, "val_acc": 48.0}
{"epoch": 2, "training_loss": 0.7046673011779785, "training_acc": 47.0, "val_loss": 0.7033135199546814, "val_acc": 48.0}
{"epoch": 3, "training_loss": 0.7042947816848755, "training_acc": 47.0, "val_loss": 0.703219404220581, "val_acc": 48.0}
{"epoch": 4, "training_loss": 0.70444650888443, "training_acc": 47.0, "val_loss": 0.7031437373161316, "val_acc": 48.0}
{"epoch": 5, "training_loss": 0.7040674734115601, "training_acc": 47.0, "val_loss": 0.7030694437026977, "val_acc": 48.0}
{"epoch": 6, "training_loss": 0.7039804887771607, "training_acc": 47.0, "val_loss": 0.7029698252677917, "val_acc": 48.0}
{"epoch": 7, "training_loss": 0.704029426574707, "training_acc": 47.0, "val_loss": 0.70287273645401, "val_acc": 48.0}
{"epoch": 8, "training_loss": 0.7039667534828186, "training_acc": 47.0, "val_loss": 0.7027763104438782, "val_acc": 48.0}
{"epoch": 9, "training_loss": 0.7038034582138062, "training_acc": 47.0, "val_loss": 0.7026776337623596, "val_acc": 48.0}
{"epoch": 10, "training_loss": 0.7035939121246337, "training_acc": 47.0, "val_loss": 0.7025752997398377, "val_acc": 48.0}
{"epoch": 11, "training_loss": 0.7031132555007935, "training_acc": 47.0, "val_loss": 0.7024573636054993, "val_acc": 48.0}
{"epoch": 12, "training_loss": 0.703197898864746, "training_acc": 47.0, "val_loss": 0.702351233959198, "val_acc": 48.0}
{"epoch": 13, "training_loss": 0.7033050513267517, "training_acc": 47.0, "val_loss": 0.7022744870185852, "val_acc": 48.0}
{"epoch": 14, "training_loss": 0.7033592700958252, "training_acc": 47.0, "val_loss": 0.7021870160102844, "val_acc": 48.0}
{"epoch": 15, "training_loss": 0.7030023527145386, "training_acc": 47.0, "val_loss": 0.7021001696586608, "val_acc": 48.0}
{"epoch": 16, "training_loss": 0.7027152490615844, "training_acc": 47.0, "val_loss": 0.7019997119903565, "val_acc": 48.0}
{"epoch": 17, "training_loss": 0.702690954208374, "training_acc": 47.0, "val_loss": 0.7019155359268189, "val_acc": 48.0}
{"epoch": 18, "training_loss": 0.7028256678581237, "training_acc": 47.0, "val_loss": 0.7018326210975647, "val_acc": 48.0}
{"epoch": 19, "training_loss": 0.7023117566108703, "training_acc": 47.0, "val_loss": 0.7017216062545777, "val_acc": 48.0}
{"epoch": 20, "training_loss": 0.7019815874099732, "training_acc": 47.0, "val_loss": 0.7016140103340149, "val_acc": 48.0}
{"epoch": 21, "training_loss": 0.7022523736953735, "training_acc": 47.0, "val_loss": 0.7015523743629456, "val_acc": 48.0}
{"epoch": 22, "training_loss": 0.7023120021820068, "training_acc": 47.0, "val_loss": 0.7014676642417907, "val_acc": 48.0}
{"epoch": 23, "training_loss": 0.7023222255706787, "training_acc": 47.0, "val_loss": 0.7013772630691528, "val_acc": 48.0}
{"epoch": 24, "training_loss": 0.702069354057312, "training_acc": 47.0, "val_loss": 0.70125403881073, "val_acc": 48.0}
{"epoch": 25, "training_loss": 0.70204110622406, "training_acc": 47.0, "val_loss": 0.7011853885650635, "val_acc": 48.0}
{"epoch": 26, "training_loss": 0.7014546942710876, "training_acc": 47.0, "val_loss": 0.7011001515388489, "val_acc": 48.0}
{"epoch": 27, "training_loss": 0.7017579889297485, "training_acc": 47.0, "val_loss": 0.7010075044631958, "val_acc": 48.0}
{"epoch": 28, "training_loss": 0.7017684316635132, "training_acc": 47.0, "val_loss": 0.7009292244911194, "val_acc": 48.0}
{"epoch": 29, "training_loss": 0.7009942770004273, "training_acc": 47.0, "val_loss": 0.7008309316635132, "val_acc": 48.0}
{"epoch": 30, "training_loss": 0.7010431718826294, "training_acc": 47.0, "val_loss": 0.7007766461372376, "val_acc": 48.0}
{"epoch": 31, "training_loss": 0.7015810298919678, "training_acc": 47.0, "val_loss": 0.7006981992721557, "val_acc": 48.0}
{"epoch": 32, "training_loss": 0.7011727094650269, "training_acc": 47.0, "val_loss": 0.7006180238723755, "val_acc": 48.0}
{"epoch": 33, "training_loss": 0.7005145001411438, "training_acc": 47.0, "val_loss": 0.7005431842803955, "val_acc": 48.0}
{"epoch": 34, "training_loss": 0.7011097335815429, "training_acc": 47.0, "val_loss": 0.7004761457443237, "val_acc": 48.0}
{"epoch": 35, "training_loss": 0.7011542439460754, "training_acc": 47.0, "val_loss": 0.7003885126113891, "val_acc": 48.0}
{"epoch": 36, "training_loss": 0.7010012245178223, "training_acc": 47.0, "val_loss": 0.700320188999176, "val_acc": 48.0}
{"epoch": 37, "training_loss": 0.7009676480293274, "training_acc": 47.0, "val_loss": 0.7002255201339722, "val_acc": 48.0}
{"epoch": 38, "training_loss": 0.7011186337471008, "training_acc": 47.0, "val_loss": 0.7001752781867981, "val_acc": 48.0}
{"epoch": 39, "training_loss": 0.7007995867729186, "training_acc": 47.0, "val_loss": 0.7001371359825135, "val_acc": 48.0}
{"epoch": 40, "training_loss": 0.7009203362464905, "training_acc": 47.0, "val_loss": 0.700085813999176, "val_acc": 48.0}
{"epoch": 41, "training_loss": 0.7003472232818604, "training_acc": 47.0, "val_loss": 0.6999978756904602, "val_acc": 48.0}
{"epoch": 42, "training_loss": 0.7004039597511291, "training_acc": 47.0, "val_loss": 0.6999402976036072, "val_acc": 48.0}
{"epoch": 43, "training_loss": 0.7001362562179565, "training_acc": 47.0, "val_loss": 0.699900631904602, "val_acc": 48.0}
{"epoch": 44, "training_loss": 0.7000443863868714, "training_acc": 47.0, "val_loss": 0.6998461627960205, "val_acc": 48.0}
{"epoch": 45, "training_loss": 0.6997817897796631, "training_acc": 47.0, "val_loss": 0.699792160987854, "val_acc": 48.0}
{"epoch": 46, "training_loss": 0.7004382371902466, "training_acc": 47.0, "val_loss": 0.6997368335723877, "val_acc": 48.0}
{"epoch": 47, "training_loss": 0.6998503732681275, "training_acc": 47.0, "val_loss": 0.6996916151046753, "val_acc": 48.0}
{"epoch": 48, "training_loss": 0.6998832273483276, "training_acc": 47.0, "val_loss": 0.6996140313148499, "val_acc": 48.0}
{"epoch": 49, "training_loss": 0.6999823951721191, "training_acc": 47.0, "val_loss": 0.6995289564132691, "val_acc": 48.0}
{"epoch": 50, "training_loss": 0.6997402691841126, "training_acc": 47.0, "val_loss": 0.699445538520813, "val_acc": 48.0}
{"epoch": 51, "training_loss": 0.6996600270271301, "training_acc": 47.0, "val_loss": 0.6993675017356873, "val_acc": 48.0}
{"epoch": 52, "training_loss": 0.699523286819458, "training_acc": 47.0, "val_loss": 0.6992942142486572, "val_acc": 48.0}
{"epoch": 53, "training_loss": 0.6993705630302429, "training_acc": 47.0, "val_loss": 0.6992364931106567, "val_acc": 48.0}
{"epoch": 54, "training_loss": 0.699402756690979, "training_acc": 47.0, "val_loss": 0.6991691946983337, "val_acc": 48.0}
{"epoch": 55, "training_loss": 0.6997350358963013, "training_acc": 47.0, "val_loss": 0.699114408493042, "val_acc": 48.0}
{"epoch": 56, "training_loss": 0.6995247602462769, "training_acc": 47.0, "val_loss": 0.6990587902069092, "val_acc": 48.0}
{"epoch": 57, "training_loss": 0.6994963645935058, "training_acc": 47.0, "val_loss": 0.6989907121658325, "val_acc": 48.0}
{"epoch": 58, "training_loss": 0.6991137027740478, "training_acc": 47.0, "val_loss": 0.6989212131500244, "val_acc": 48.0}
{"epoch": 59, "training_loss": 0.6992755699157714, "training_acc": 47.0, "val_loss": 0.6988569235801697, "val_acc": 48.0}
{"epoch": 60, "training_loss": 0.6990988540649414, "training_acc": 47.0, "val_loss": 0.6987980341911316, "val_acc": 48.0}
{"epoch": 61, "training_loss": 0.6992969560623169, "training_acc": 47.0, "val_loss": 0.698749930858612, "val_acc": 48.0}
{"epoch": 62, "training_loss": 0.6987792491912842, "training_acc": 47.0, "val_loss": 0.6987002325057984, "val_acc": 48.0}
{"epoch": 63, "training_loss": 0.69868008852005, "training_acc": 47.0, "val_loss": 0.6986417722702026, "val_acc": 48.0}
{"epoch": 64, "training_loss": 0.6985778784751893, "training_acc": 47.0, "val_loss": 0.6985938596725464, "val_acc": 48.0}
{"epoch": 65, "training_loss": 0.6985796928405762, "training_acc": 47.0, "val_loss": 0.6985427832603455, "val_acc": 48.0}
{"epoch": 66, "training_loss": 0.6985331773757935, "training_acc": 47.0, "val_loss": 0.6984813165664673, "val_acc": 48.0}
{"epoch": 67, "training_loss": 0.6985375142097473, "training_acc": 47.0, "val_loss": 0.6984148979187011, "val_acc": 48.0}
{"epoch": 68, "training_loss": 0.6983329200744629, "training_acc": 47.0, "val_loss": 0.6983435821533203, "val_acc": 48.0}
{"epoch": 69, "training_loss": 0.6987262177467346, "training_acc": 47.0, "val_loss": 0.6982702994346619, "val_acc": 48.0}
{"epoch": 70, "training_loss": 0.698461377620697, "training_acc": 47.0, "val_loss": 0.6982131600379944, "val_acc": 48.0}
{"epoch": 71, "training_loss": 0.6981965470314025, "training_acc": 47.0, "val_loss": 0.6981688380241394, "val_acc": 48.0}
{"epoch": 72, "training_loss": 0.6983060169219971, "training_acc": 47.0, "val_loss": 0.6981318783760071, "val_acc": 48.0}
{"epoch": 73, "training_loss": 0.6984549188613891, "training_acc": 47.0, "val_loss": 0.6980657625198364, "val_acc": 48.0}
{"epoch": 74, "training_loss": 0.6983476090431213, "training_acc": 47.0, "val_loss": 0.6980099487304687, "val_acc": 48.0}
{"epoch": 75, "training_loss": 0.6980438947677612, "training_acc": 47.0, "val_loss": 0.6979261708259582, "val_acc": 48.0}
{"epoch": 76, "training_loss": 0.6976021194458008, "training_acc": 47.0, "val_loss": 0.6978649973869324, "val_acc": 48.0}
{"epoch": 77, "training_loss": 0.6977447652816773, "training_acc": 47.0, "val_loss": 0.6978172254562378, "val_acc": 48.0}
{"epoch": 78, "training_loss": 0.6977830624580383, "training_acc": 47.0, "val_loss": 0.6977763152122498, "val_acc": 48.0}
{"epoch": 79, "training_loss": 0.6974433016777039, "training_acc": 47.0, "val_loss": 0.6977306485176087, "val_acc": 48.0}
{"epoch": 80, "training_loss": 0.6974473667144775, "training_acc": 47.0, "val_loss": 0.6976737642288208, "val_acc": 48.0}
{"epoch": 81, "training_loss": 0.697540020942688, "training_acc": 47.0, "val_loss": 0.6976231479644776, "val_acc": 48.0}
{"epoch": 82, "training_loss": 0.696759798526764, "training_acc": 47.0, "val_loss": 0.6975644731521606, "val_acc": 48.0}
{"epoch": 83, "training_loss": 0.6982011985778809, "training_acc": 47.0, "val_loss": 0.6975106692314148, "val_acc": 48.0}
{"epoch": 84, "training_loss": 0.6975013399124146, "training_acc": 47.0, "val_loss": 0.6974507546424866, "val_acc": 48.0}
{"epoch": 85, "training_loss": 0.697543568611145, "training_acc": 47.0, "val_loss": 0.6974006152153015, "val_acc": 48.0}
{"epoch": 86, "training_loss": 0.6975422310829162, "training_acc": 47.0, "val_loss": 0.6973401761054993, "val_acc": 48.0}
{"epoch": 87, "training_loss": 0.6970123171806335, "training_acc": 47.0, "val_loss": 0.6972893118858338, "val_acc": 48.0}
{"epoch": 88, "training_loss": 0.697244598865509, "training_acc": 47.0, "val_loss": 0.6972486114501953, "val_acc": 48.0}
{"epoch": 89, "training_loss": 0.6971092295646667, "training_acc": 47.0, "val_loss": 0.697209186553955, "val_acc": 48.0}
{"epoch": 90, "training_loss": 0.6971403932571412, "training_acc": 47.0, "val_loss": 0.6971731328964234, "val_acc": 48.0}
{"epoch": 91, "training_loss": 0.6970254755020142, "training_acc": 47.0, "val_loss": 0.6971411180496215, "val_acc": 48.0}
{"epoch": 92, "training_loss": 0.6977530741691589, "training_acc": 47.0, "val_loss": 0.6971013212203979, "val_acc": 48.0}
{"epoch": 93, "training_loss": 0.6971429300308227, "training_acc": 47.0, "val_loss": 0.6970700907707215, "val_acc": 48.0}
{"epoch": 94, "training_loss": 0.6970264649391175, "training_acc": 47.0, "val_loss": 0.697035608291626, "val_acc": 48.0}
{"epoch": 95, "training_loss": 0.6966837358474731, "training_acc": 47.0, "val_loss": 0.6969799709320068, "val_acc": 48.0}
{"epoch": 96, "training_loss": 0.6968972778320313, "training_acc": 47.0, "val_loss": 0.6969321727752685, "val_acc": 48.0}
{"epoch": 97, "training_loss": 0.6964594078063965, "training_acc": 47.0, "val_loss": 0.6968795394897461, "val_acc": 48.0}
{"epoch": 98, "training_loss": 0.6966739201545715, "training_acc": 47.0, "val_loss": 0.6968315148353577, "val_acc": 48.0}
{"epoch": 99, "training_loss": 0.6965668177604676, "training_acc": 47.0, "val_loss": 0.6967922973632813, "val_acc": 48.0}
