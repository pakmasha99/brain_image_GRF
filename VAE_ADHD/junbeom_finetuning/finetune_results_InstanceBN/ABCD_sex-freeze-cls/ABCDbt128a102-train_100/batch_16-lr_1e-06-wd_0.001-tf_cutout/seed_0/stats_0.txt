"main_modify.py --pretrained_path /scratch/connectome/dyhan316/VAE_ADHD/barlowtwins/pretrain_results/ABCDbt128a102.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option BT_org --learning_rate 1e-6 --batch_size 16 --weight_decay 1e-3 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 0.6922509026527405, "training_acc": 52.0, "val_loss": 0.6885158252716065, "val_acc": 56.0}
{"epoch": 1, "training_loss": 0.6923713159561157, "training_acc": 52.0, "val_loss": 0.6885035562515259, "val_acc": 56.0}
{"epoch": 2, "training_loss": 0.6923884606361389, "training_acc": 52.0, "val_loss": 0.6884990406036376, "val_acc": 56.0}
{"epoch": 3, "training_loss": 0.6921229934692383, "training_acc": 52.0, "val_loss": 0.6884755921363831, "val_acc": 56.0}
{"epoch": 4, "training_loss": 0.6923734641075134, "training_acc": 52.0, "val_loss": 0.6884796619415283, "val_acc": 56.0}
{"epoch": 5, "training_loss": 0.6921837639808655, "training_acc": 52.0, "val_loss": 0.6884649395942688, "val_acc": 56.0}
{"epoch": 6, "training_loss": 0.6920616579055786, "training_acc": 52.0, "val_loss": 0.6884556317329407, "val_acc": 56.0}
{"epoch": 7, "training_loss": 0.6921636176109314, "training_acc": 52.0, "val_loss": 0.6884565687179566, "val_acc": 56.0}
{"epoch": 8, "training_loss": 0.6920009851455688, "training_acc": 52.0, "val_loss": 0.6884394931793213, "val_acc": 56.0}
{"epoch": 9, "training_loss": 0.6921641445159912, "training_acc": 52.0, "val_loss": 0.6884430646896362, "val_acc": 56.0}
{"epoch": 10, "training_loss": 0.6923815155029297, "training_acc": 52.0, "val_loss": 0.6884603452682495, "val_acc": 56.0}
{"epoch": 11, "training_loss": 0.6920356941223145, "training_acc": 52.0, "val_loss": 0.6884559345245361, "val_acc": 56.0}
{"epoch": 12, "training_loss": 0.6925537586212158, "training_acc": 52.0, "val_loss": 0.6884230160713196, "val_acc": 56.0}
{"epoch": 13, "training_loss": 0.6920079565048218, "training_acc": 52.0, "val_loss": 0.6884143161773681, "val_acc": 56.0}
{"epoch": 14, "training_loss": 0.6923296928405762, "training_acc": 52.0, "val_loss": 0.6883947849273682, "val_acc": 56.0}
{"epoch": 15, "training_loss": 0.6924197030067444, "training_acc": 52.0, "val_loss": 0.6883831071853638, "val_acc": 56.0}
{"epoch": 16, "training_loss": 0.6926696586608887, "training_acc": 52.0, "val_loss": 0.6883477711677551, "val_acc": 56.0}
{"epoch": 17, "training_loss": 0.6920346283912658, "training_acc": 52.0, "val_loss": 0.6883481931686402, "val_acc": 56.0}
{"epoch": 18, "training_loss": 0.6923757076263428, "training_acc": 52.0, "val_loss": 0.6883559536933899, "val_acc": 56.0}
{"epoch": 19, "training_loss": 0.6921601152420044, "training_acc": 52.0, "val_loss": 0.6883707809448242, "val_acc": 56.0}
{"epoch": 20, "training_loss": 0.6924325633049011, "training_acc": 52.0, "val_loss": 0.6883670425415039, "val_acc": 56.0}
{"epoch": 21, "training_loss": 0.691792905330658, "training_acc": 52.0, "val_loss": 0.6883667302131653, "val_acc": 56.0}
{"epoch": 22, "training_loss": 0.6919579458236694, "training_acc": 52.0, "val_loss": 0.6883557844161987, "val_acc": 56.0}
{"epoch": 23, "training_loss": 0.6922149896621704, "training_acc": 52.0, "val_loss": 0.6883567142486572, "val_acc": 56.0}
{"epoch": 24, "training_loss": 0.6924657344818115, "training_acc": 52.0, "val_loss": 0.6883360385894776, "val_acc": 56.0}
{"epoch": 25, "training_loss": 0.6923988604545593, "training_acc": 52.0, "val_loss": 0.6883384013175964, "val_acc": 56.0}
{"epoch": 26, "training_loss": 0.6915853595733643, "training_acc": 52.0, "val_loss": 0.6883321857452392, "val_acc": 56.0}
{"epoch": 27, "training_loss": 0.691868600845337, "training_acc": 52.0, "val_loss": 0.6883350110054016, "val_acc": 56.0}
{"epoch": 28, "training_loss": 0.6921701574325562, "training_acc": 52.0, "val_loss": 0.6883332085609436, "val_acc": 56.0}
{"epoch": 29, "training_loss": 0.6923460912704468, "training_acc": 52.0, "val_loss": 0.6883183789253234, "val_acc": 56.0}
{"epoch": 30, "training_loss": 0.6920379734039307, "training_acc": 52.0, "val_loss": 0.6882820844650268, "val_acc": 56.0}
{"epoch": 31, "training_loss": 0.6921745729446411, "training_acc": 52.0, "val_loss": 0.6882616424560547, "val_acc": 56.0}
{"epoch": 32, "training_loss": 0.6919822978973389, "training_acc": 52.0, "val_loss": 0.6882208442687988, "val_acc": 56.0}
{"epoch": 33, "training_loss": 0.6924383950233459, "training_acc": 52.0, "val_loss": 0.6881952309608459, "val_acc": 56.0}
{"epoch": 34, "training_loss": 0.6923981642723084, "training_acc": 52.0, "val_loss": 0.6881901979446411, "val_acc": 56.0}
{"epoch": 35, "training_loss": 0.6918370294570922, "training_acc": 52.0, "val_loss": 0.6881979417800903, "val_acc": 56.0}
{"epoch": 36, "training_loss": 0.6926154255867004, "training_acc": 52.0, "val_loss": 0.6881899952888488, "val_acc": 56.0}
{"epoch": 37, "training_loss": 0.6927372932434082, "training_acc": 52.0, "val_loss": 0.6881768345832825, "val_acc": 56.0}
{"epoch": 38, "training_loss": 0.6924601936340332, "training_acc": 52.0, "val_loss": 0.6881754803657532, "val_acc": 56.0}
{"epoch": 39, "training_loss": 0.69257493019104, "training_acc": 52.0, "val_loss": 0.6881754112243652, "val_acc": 56.0}
{"epoch": 40, "training_loss": 0.6924903964996338, "training_acc": 52.0, "val_loss": 0.6881869530677795, "val_acc": 56.0}
{"epoch": 41, "training_loss": 0.6919221091270447, "training_acc": 52.0, "val_loss": 0.6881852602958679, "val_acc": 56.0}
{"epoch": 42, "training_loss": 0.6919394755363464, "training_acc": 52.0, "val_loss": 0.6881838655471801, "val_acc": 56.0}
{"epoch": 43, "training_loss": 0.6917713737487793, "training_acc": 52.0, "val_loss": 0.6881831669807434, "val_acc": 56.0}
{"epoch": 44, "training_loss": 0.6924411535263062, "training_acc": 52.0, "val_loss": 0.6882020163536072, "val_acc": 56.0}
{"epoch": 45, "training_loss": 0.6921705579757691, "training_acc": 52.0, "val_loss": 0.6882053041458129, "val_acc": 56.0}
{"epoch": 46, "training_loss": 0.6919178247451783, "training_acc": 52.0, "val_loss": 0.6882048439979553, "val_acc": 56.0}
{"epoch": 47, "training_loss": 0.6923851895332337, "training_acc": 52.0, "val_loss": 0.6881972050666809, "val_acc": 56.0}
{"epoch": 48, "training_loss": 0.6922415113449096, "training_acc": 52.0, "val_loss": 0.6881877756118775, "val_acc": 56.0}
{"epoch": 49, "training_loss": 0.6921451568603516, "training_acc": 52.0, "val_loss": 0.6881913733482361, "val_acc": 56.0}
{"epoch": 50, "training_loss": 0.6925732278823853, "training_acc": 52.0, "val_loss": 0.6882089066505432, "val_acc": 56.0}
{"epoch": 51, "training_loss": 0.6925463461875916, "training_acc": 52.0, "val_loss": 0.6882274675369263, "val_acc": 56.0}
{"epoch": 52, "training_loss": 0.6923064637184143, "training_acc": 52.0, "val_loss": 0.6882497143745422, "val_acc": 56.0}
{"epoch": 53, "training_loss": 0.6921753358840942, "training_acc": 52.0, "val_loss": 0.6882576704025268, "val_acc": 56.0}
{"epoch": 54, "training_loss": 0.6924763178825378, "training_acc": 52.0, "val_loss": 0.6882670903205872, "val_acc": 56.0}
{"epoch": 55, "training_loss": 0.6923313474655152, "training_acc": 52.0, "val_loss": 0.688287365436554, "val_acc": 56.0}
{"epoch": 56, "training_loss": 0.6921663904190063, "training_acc": 52.0, "val_loss": 0.6883177208900452, "val_acc": 56.0}
{"epoch": 57, "training_loss": 0.6919707322120666, "training_acc": 52.0, "val_loss": 0.6883509659767151, "val_acc": 56.0}
{"epoch": 58, "training_loss": 0.6923975324630738, "training_acc": 52.0, "val_loss": 0.6883427286148072, "val_acc": 56.0}
