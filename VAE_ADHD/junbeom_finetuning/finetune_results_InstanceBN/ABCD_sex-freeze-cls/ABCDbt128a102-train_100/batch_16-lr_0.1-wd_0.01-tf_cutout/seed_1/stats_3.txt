"main_modify.py --pretrained_path /scratch/connectome/dyhan316/VAE_ADHD/barlowtwins/pretrain_results/ABCDbt128a102.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 1 --task ABCD_sex --input_option BT_org --learning_rate 1e-1 --batch_size 16 --weight_decay 1e-2 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 12.227915496826173, "training_acc": 43.0, "val_loss": 14.178798751831055, "val_acc": 48.0}
{"epoch": 1, "training_loss": 7.0172295570373535, "training_acc": 61.0, "val_loss": 9.132695693969726, "val_acc": 52.0}
{"epoch": 2, "training_loss": 5.532805604934692, "training_acc": 55.0, "val_loss": 0.8850348973274231, "val_acc": 48.0}
{"epoch": 3, "training_loss": 4.811451501846314, "training_acc": 53.0, "val_loss": 6.956366901397705, "val_acc": 48.0}
{"epoch": 4, "training_loss": 4.872164497375488, "training_acc": 53.0, "val_loss": 6.324888420104981, "val_acc": 52.0}
{"epoch": 5, "training_loss": 5.899617671966553, "training_acc": 45.0, "val_loss": 5.704225559234619, "val_acc": 52.0}
{"epoch": 6, "training_loss": 10.922661437988282, "training_acc": 53.0, "val_loss": 2.5990734577178953, "val_acc": 48.0}
{"epoch": 7, "training_loss": 4.95163553237915, "training_acc": 45.0, "val_loss": 4.664412803649903, "val_acc": 52.0}
{"epoch": 8, "training_loss": 2.4912854766845705, "training_acc": 47.0, "val_loss": 1.838420534133911, "val_acc": 52.0}
{"epoch": 9, "training_loss": 1.6545034909248353, "training_acc": 48.0, "val_loss": 1.1489101266860962, "val_acc": 48.0}
{"epoch": 10, "training_loss": 1.4034298992156982, "training_acc": 39.0, "val_loss": 2.2805917358398435, "val_acc": 52.0}
{"epoch": 11, "training_loss": 1.8268770217895507, "training_acc": 49.0, "val_loss": 2.144662313461304, "val_acc": 52.0}
{"epoch": 12, "training_loss": 1.193195834159851, "training_acc": 52.0, "val_loss": 0.7628685188293457, "val_acc": 48.0}
{"epoch": 13, "training_loss": 0.6970050144195556, "training_acc": 55.0, "val_loss": 0.792217800617218, "val_acc": 52.0}
{"epoch": 14, "training_loss": 1.0320754623413086, "training_acc": 47.0, "val_loss": 0.6730268263816833, "val_acc": 60.0}
{"epoch": 15, "training_loss": 0.7673113536834717, "training_acc": 60.0, "val_loss": 0.6916773581504821, "val_acc": 48.0}
{"epoch": 16, "training_loss": 0.7984768795967102, "training_acc": 46.0, "val_loss": 2.0415988159179688, "val_acc": 52.0}
{"epoch": 17, "training_loss": 1.4769244837760924, "training_acc": 51.0, "val_loss": 0.9798569059371949, "val_acc": 52.0}
{"epoch": 18, "training_loss": 1.0241971445083617, "training_acc": 47.0, "val_loss": 1.4348179054260255, "val_acc": 52.0}
{"epoch": 19, "training_loss": 0.8469237875938416, "training_acc": 58.0, "val_loss": 1.5056504154205321, "val_acc": 52.0}
{"epoch": 20, "training_loss": 1.6823603630065918, "training_acc": 47.0, "val_loss": 2.009256992340088, "val_acc": 48.0}
{"epoch": 21, "training_loss": 2.3682043242454527, "training_acc": 47.0, "val_loss": 4.143090429306031, "val_acc": 48.0}
{"epoch": 22, "training_loss": 3.0171214866638185, "training_acc": 53.0, "val_loss": 1.7381492280960082, "val_acc": 48.0}
{"epoch": 23, "training_loss": 1.4230878829956055, "training_acc": 46.0, "val_loss": 0.6756116223335266, "val_acc": 56.0}
{"epoch": 24, "training_loss": 0.6468021702766419, "training_acc": 65.0, "val_loss": 1.2551271677017213, "val_acc": 48.0}
{"epoch": 25, "training_loss": 1.9782439517974852, "training_acc": 45.0, "val_loss": 0.7477683758735657, "val_acc": 48.0}
{"epoch": 26, "training_loss": 2.4727002716064455, "training_acc": 47.0, "val_loss": 2.177964153289795, "val_acc": 52.0}
{"epoch": 27, "training_loss": 2.108293447494507, "training_acc": 57.0, "val_loss": 2.147699570655823, "val_acc": 52.0}
{"epoch": 28, "training_loss": 2.3957562828063965, "training_acc": 43.0, "val_loss": 3.4493227100372312, "val_acc": 52.0}
{"epoch": 29, "training_loss": 2.0726425361633303, "training_acc": 49.0, "val_loss": 1.1416358852386475, "val_acc": 52.0}
{"epoch": 30, "training_loss": 1.8210193347930907, "training_acc": 54.0, "val_loss": 3.9650516510009766, "val_acc": 48.0}
{"epoch": 31, "training_loss": 3.256540031368204, "training_acc": 59.0, "val_loss": 5.3298752403259275, "val_acc": 52.0}
{"epoch": 32, "training_loss": 3.0250537967681885, "training_acc": 51.0, "val_loss": 1.3231863832473756, "val_acc": 52.0}
{"epoch": 33, "training_loss": 1.3783613443374634, "training_acc": 49.0, "val_loss": 2.2563814163208007, "val_acc": 48.0}
