"main_modify.py --pretrained_path /scratch/connectome/dyhan316/VAE_ADHD/barlowtwins/pretrain_results/ABCDbt128a102.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 1 --task ABCD_sex --input_option BT_org --learning_rate 1e-1 --batch_size 16 --weight_decay 1e-2 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 6.455089912414551, "training_acc": 51.0, "val_loss": 4.513356895446777, "val_acc": 48.0}
{"epoch": 1, "training_loss": 2.7888816928863527, "training_acc": 47.0, "val_loss": 3.498259229660034, "val_acc": 52.0}
{"epoch": 2, "training_loss": 2.2677596044540405, "training_acc": 63.0, "val_loss": 1.7066250658035278, "val_acc": 52.0}
{"epoch": 3, "training_loss": 1.7431157779693605, "training_acc": 57.0, "val_loss": 1.664834966659546, "val_acc": 52.0}
{"epoch": 4, "training_loss": 1.098346164226532, "training_acc": 57.0, "val_loss": 2.919521255493164, "val_acc": 48.0}
{"epoch": 5, "training_loss": 3.288137674331665, "training_acc": 45.0, "val_loss": 4.293570919036865, "val_acc": 48.0}
{"epoch": 6, "training_loss": 5.00906337380409, "training_acc": 49.0, "val_loss": 9.35532974243164, "val_acc": 52.0}
{"epoch": 7, "training_loss": 6.288644142150879, "training_acc": 53.0, "val_loss": 7.4952631759643555, "val_acc": 48.0}
{"epoch": 8, "training_loss": 4.360546154975891, "training_acc": 52.0, "val_loss": 3.4803613090515135, "val_acc": 48.0}
{"epoch": 9, "training_loss": 4.337969722747803, "training_acc": 53.0, "val_loss": 4.269776659011841, "val_acc": 52.0}
{"epoch": 10, "training_loss": 5.032283892631531, "training_acc": 47.0, "val_loss": 4.780453243255615, "val_acc": 52.0}
{"epoch": 11, "training_loss": 6.304646720886231, "training_acc": 53.0, "val_loss": 8.960337066650391, "val_acc": 48.0}
{"epoch": 12, "training_loss": 7.067005882263183, "training_acc": 47.0, "val_loss": 5.4477206802368165, "val_acc": 52.0}
{"epoch": 13, "training_loss": 4.440654814243317, "training_acc": 43.0, "val_loss": 4.5912846660614015, "val_acc": 52.0}
{"epoch": 14, "training_loss": 2.747356629371643, "training_acc": 49.0, "val_loss": 1.5879633903503418, "val_acc": 52.0}
{"epoch": 15, "training_loss": 1.073470983505249, "training_acc": 59.0, "val_loss": 1.299380145072937, "val_acc": 52.0}
{"epoch": 16, "training_loss": 1.0303328466415405, "training_acc": 49.0, "val_loss": 0.7517427515983581, "val_acc": 52.0}
{"epoch": 17, "training_loss": 1.066943324804306, "training_acc": 48.0, "val_loss": 0.7110460019111633, "val_acc": 56.0}
{"epoch": 18, "training_loss": 0.8012088656425476, "training_acc": 67.0, "val_loss": 1.4385227584838867, "val_acc": 48.0}
{"epoch": 19, "training_loss": 1.5682643270492553, "training_acc": 56.0, "val_loss": 2.2506425619125365, "val_acc": 48.0}
{"epoch": 20, "training_loss": 1.2844234824180603, "training_acc": 55.0, "val_loss": 2.3613649940490724, "val_acc": 52.0}
{"epoch": 21, "training_loss": 2.3573145389556887, "training_acc": 49.0, "val_loss": 1.2150851392745972, "val_acc": 52.0}
{"epoch": 22, "training_loss": 1.108103220462799, "training_acc": 44.0, "val_loss": 1.4391682863235473, "val_acc": 52.0}
{"epoch": 23, "training_loss": 1.1273295950889588, "training_acc": 49.0, "val_loss": 2.319979386329651, "val_acc": 48.0}
{"epoch": 24, "training_loss": 1.6221115350723267, "training_acc": 47.0, "val_loss": 2.287180938720703, "val_acc": 52.0}
{"epoch": 25, "training_loss": 2.592787358760834, "training_acc": 49.0, "val_loss": 3.7223272800445555, "val_acc": 52.0}
{"epoch": 26, "training_loss": 3.153505549430847, "training_acc": 52.0, "val_loss": 1.7004311990737915, "val_acc": 52.0}
{"epoch": 27, "training_loss": 1.5834329581260682, "training_acc": 47.0, "val_loss": 1.079027647972107, "val_acc": 48.0}
{"epoch": 28, "training_loss": 1.4288585662841797, "training_acc": 59.0, "val_loss": 3.7162629890441896, "val_acc": 48.0}
{"epoch": 29, "training_loss": 3.9062304496765137, "training_acc": 47.0, "val_loss": 2.6819888401031493, "val_acc": 52.0}
{"epoch": 30, "training_loss": 3.2906057167053224, "training_acc": 53.0, "val_loss": 5.454945640563965, "val_acc": 52.0}
{"epoch": 31, "training_loss": 3.8745463371276854, "training_acc": 49.0, "val_loss": 3.15723680973053, "val_acc": 52.0}
{"epoch": 32, "training_loss": 4.47888370513916, "training_acc": 51.0, "val_loss": 5.9766198348999025, "val_acc": 48.0}
{"epoch": 33, "training_loss": 3.4556281089782717, "training_acc": 49.0, "val_loss": 4.749572544097901, "val_acc": 48.0}
{"epoch": 34, "training_loss": 4.027306356430054, "training_acc": 49.0, "val_loss": 2.136322298049927, "val_acc": 48.0}
{"epoch": 35, "training_loss": 2.1842993259429933, "training_acc": 47.0, "val_loss": 1.1025344133377075, "val_acc": 48.0}
{"epoch": 36, "training_loss": 0.857875783443451, "training_acc": 54.0, "val_loss": 2.835670566558838, "val_acc": 52.0}
