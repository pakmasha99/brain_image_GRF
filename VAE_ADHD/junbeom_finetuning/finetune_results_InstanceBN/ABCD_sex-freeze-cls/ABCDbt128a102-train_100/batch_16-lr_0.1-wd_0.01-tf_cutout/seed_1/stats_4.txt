"main_modify.py --pretrained_path /scratch/connectome/dyhan316/VAE_ADHD/barlowtwins/pretrain_results/ABCDbt128a102.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 1 --task ABCD_sex --input_option BT_org --learning_rate 1e-1 --batch_size 16 --weight_decay 1e-2 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 8.407399082183838, "training_acc": 60.0, "val_loss": 2.77158842086792, "val_acc": 44.0}
{"epoch": 1, "training_loss": 5.175623779296875, "training_acc": 48.0, "val_loss": 1.6043310260772705, "val_acc": 56.0}
{"epoch": 2, "training_loss": 5.042124404907226, "training_acc": 38.0, "val_loss": 3.11459135055542, "val_acc": 56.0}
{"epoch": 3, "training_loss": 2.303994617462158, "training_acc": 48.0, "val_loss": 0.9417223739624023, "val_acc": 56.0}
{"epoch": 4, "training_loss": 1.9588243675231933, "training_acc": 54.0, "val_loss": 1.3726303243637086, "val_acc": 56.0}
{"epoch": 5, "training_loss": 2.043572196960449, "training_acc": 48.0, "val_loss": 1.093825716972351, "val_acc": 44.0}
{"epoch": 6, "training_loss": 1.2887510251998902, "training_acc": 46.0, "val_loss": 0.7685808730125427, "val_acc": 56.0}
{"epoch": 7, "training_loss": 1.2098670649528502, "training_acc": 44.0, "val_loss": 0.8327830815315247, "val_acc": 56.0}
{"epoch": 8, "training_loss": 1.426033434867859, "training_acc": 54.0, "val_loss": 1.3420813608169555, "val_acc": 44.0}
{"epoch": 9, "training_loss": 1.282608575820923, "training_acc": 56.0, "val_loss": 2.227637166976929, "val_acc": 44.0}
{"epoch": 10, "training_loss": 1.4599674487113952, "training_acc": 50.0, "val_loss": 0.7340740513801575, "val_acc": 56.0}
{"epoch": 11, "training_loss": 0.9423586630821228, "training_acc": 54.0, "val_loss": 1.051731791496277, "val_acc": 44.0}
{"epoch": 12, "training_loss": 1.0583337593078612, "training_acc": 46.0, "val_loss": 1.2597306299209594, "val_acc": 44.0}
{"epoch": 13, "training_loss": 1.2986694884300232, "training_acc": 48.0, "val_loss": 0.6835519385337829, "val_acc": 56.0}
{"epoch": 14, "training_loss": 0.8421594786643982, "training_acc": 50.0, "val_loss": 1.1179776859283448, "val_acc": 44.0}
{"epoch": 15, "training_loss": 1.0798406744003295, "training_acc": 50.0, "val_loss": 0.6727877545356751, "val_acc": 56.0}
{"epoch": 16, "training_loss": 1.0225196433067323, "training_acc": 54.0, "val_loss": 1.516734652519226, "val_acc": 44.0}
{"epoch": 17, "training_loss": 0.8632042789459229, "training_acc": 55.0, "val_loss": 0.6661914563179017, "val_acc": 60.0}
{"epoch": 18, "training_loss": 0.9990872383117676, "training_acc": 53.0, "val_loss": 0.7969880819320678, "val_acc": 56.0}
{"epoch": 19, "training_loss": 0.6815783071517945, "training_acc": 57.0, "val_loss": 0.8162665605545044, "val_acc": 56.0}
{"epoch": 20, "training_loss": 0.739684751033783, "training_acc": 56.0, "val_loss": 1.0989776849746704, "val_acc": 44.0}
{"epoch": 21, "training_loss": 1.0738615131378173, "training_acc": 45.0, "val_loss": 2.0363551998138427, "val_acc": 44.0}
{"epoch": 22, "training_loss": 1.2177854251861573, "training_acc": 46.0, "val_loss": 1.0996461367607118, "val_acc": 56.0}
{"epoch": 23, "training_loss": 0.8579980087280273, "training_acc": 53.0, "val_loss": 0.7174555611610413, "val_acc": 44.0}
{"epoch": 24, "training_loss": 1.028991961479187, "training_acc": 58.0, "val_loss": 0.660566143989563, "val_acc": 56.0}
{"epoch": 25, "training_loss": 0.861236629486084, "training_acc": 55.0, "val_loss": 1.4974050998687745, "val_acc": 56.0}
{"epoch": 26, "training_loss": 1.7867548322677613, "training_acc": 54.0, "val_loss": 4.0579008293151855, "val_acc": 56.0}
{"epoch": 27, "training_loss": 3.931079149246216, "training_acc": 44.0, "val_loss": 3.9156475830078126, "val_acc": 56.0}
{"epoch": 28, "training_loss": 2.8536952209472655, "training_acc": 54.0, "val_loss": 3.1577857971191405, "val_acc": 56.0}
{"epoch": 29, "training_loss": 2.8029305076599123, "training_acc": 48.0, "val_loss": 3.474258260726929, "val_acc": 56.0}
{"epoch": 30, "training_loss": 2.820951614379883, "training_acc": 50.0, "val_loss": 2.143450517654419, "val_acc": 56.0}
{"epoch": 31, "training_loss": 1.615266809463501, "training_acc": 55.0, "val_loss": 3.7851571464538574, "val_acc": 44.0}
{"epoch": 32, "training_loss": 3.1629306793212892, "training_acc": 46.0, "val_loss": 2.296241645812988, "val_acc": 44.0}
{"epoch": 33, "training_loss": 1.7057189182937145, "training_acc": 54.0, "val_loss": 3.0087773609161377, "val_acc": 44.0}
{"epoch": 34, "training_loss": 1.498192253112793, "training_acc": 54.0, "val_loss": 0.6549456644058228, "val_acc": 52.0}
{"epoch": 35, "training_loss": 0.6364047765731812, "training_acc": 65.0, "val_loss": 0.8130031418800354, "val_acc": 56.0}
{"epoch": 36, "training_loss": 0.864799021333456, "training_acc": 58.0, "val_loss": 3.9581212520599367, "val_acc": 44.0}
{"epoch": 37, "training_loss": 3.089642572402954, "training_acc": 56.0, "val_loss": 3.0579550075531006, "val_acc": 44.0}
{"epoch": 38, "training_loss": 2.644214572906494, "training_acc": 48.0, "val_loss": 2.8863632583618166, "val_acc": 44.0}
{"epoch": 39, "training_loss": 1.5837685763835907, "training_acc": 58.0, "val_loss": 3.690997314453125, "val_acc": 44.0}
{"epoch": 40, "training_loss": 2.597238006591797, "training_acc": 48.0, "val_loss": 1.5867652845382691, "val_acc": 44.0}
{"epoch": 41, "training_loss": 1.9822080941917375, "training_acc": 59.0, "val_loss": 4.296182098388672, "val_acc": 44.0}
{"epoch": 42, "training_loss": 2.1117654180526735, "training_acc": 56.0, "val_loss": 1.4235674905776978, "val_acc": 44.0}
{"epoch": 43, "training_loss": 1.825418004989624, "training_acc": 48.0, "val_loss": 3.42510853767395, "val_acc": 56.0}
{"epoch": 44, "training_loss": 3.870577235221863, "training_acc": 47.0, "val_loss": 2.021839828491211, "val_acc": 56.0}
{"epoch": 45, "training_loss": 3.033388500213623, "training_acc": 40.0, "val_loss": 2.354188241958618, "val_acc": 56.0}
{"epoch": 46, "training_loss": 1.102901155948639, "training_acc": 53.0, "val_loss": 0.9663778972625733, "val_acc": 44.0}
{"epoch": 47, "training_loss": 1.477851734161377, "training_acc": 48.0, "val_loss": 1.2710835123062134, "val_acc": 56.0}
{"epoch": 48, "training_loss": 1.082551407814026, "training_acc": 55.0, "val_loss": 3.415654668807983, "val_acc": 44.0}
{"epoch": 49, "training_loss": 1.455525541305542, "training_acc": 47.0, "val_loss": 0.7040761971473694, "val_acc": 56.0}
{"epoch": 50, "training_loss": 1.8783089065551757, "training_acc": 42.0, "val_loss": 3.459820022583008, "val_acc": 44.0}
{"epoch": 51, "training_loss": 2.396070737838745, "training_acc": 48.0, "val_loss": 2.2787913608551027, "val_acc": 44.0}
{"epoch": 52, "training_loss": 1.526620397567749, "training_acc": 42.0, "val_loss": 2.6396052265167236, "val_acc": 56.0}
{"epoch": 53, "training_loss": 1.8554019355773925, "training_acc": 49.0, "val_loss": 2.706090879440308, "val_acc": 44.0}
