"main_modify.py --pretrained_path /scratch/connectome/dyhan316/VAE_ADHD/barlowtwins/pretrain_results/ABCDbt128a102.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option BT_org --learning_rate 1e-1 --batch_size 16 --weight_decay 1e-2 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 12.9972314453125, "training_acc": 47.0, "val_loss": 4.994016590118409, "val_acc": 52.0}
{"epoch": 1, "training_loss": 4.969856510162353, "training_acc": 49.0, "val_loss": 4.578496646881104, "val_acc": 52.0}
{"epoch": 2, "training_loss": 3.327796974182129, "training_acc": 47.0, "val_loss": 3.3180704307556153, "val_acc": 52.0}
{"epoch": 3, "training_loss": 3.7620347785949706, "training_acc": 37.0, "val_loss": 4.687008113861084, "val_acc": 52.0}
{"epoch": 4, "training_loss": 2.8541411781311035, "training_acc": 49.0, "val_loss": 3.56724214553833, "val_acc": 52.0}
{"epoch": 5, "training_loss": 3.0548875617980955, "training_acc": 45.0, "val_loss": 5.447679500579834, "val_acc": 52.0}
{"epoch": 6, "training_loss": 4.62174084186554, "training_acc": 49.0, "val_loss": 2.4912642002105714, "val_acc": 48.0}
{"epoch": 7, "training_loss": 1.422011188864708, "training_acc": 66.0, "val_loss": 5.48112533569336, "val_acc": 48.0}
{"epoch": 8, "training_loss": 4.019893046617496, "training_acc": 57.0, "val_loss": 7.438882446289062, "val_acc": 52.0}
{"epoch": 9, "training_loss": 4.099662928581238, "training_acc": 51.0, "val_loss": 2.0263180685043336, "val_acc": 52.0}
{"epoch": 10, "training_loss": 1.588279309272766, "training_acc": 49.0, "val_loss": 0.7330474996566773, "val_acc": 52.0}
{"epoch": 11, "training_loss": 0.7338470911979675, "training_acc": 55.0, "val_loss": 1.8638994646072389, "val_acc": 48.0}
{"epoch": 12, "training_loss": 1.4714941501617431, "training_acc": 51.0, "val_loss": 1.3762051033973695, "val_acc": 52.0}
{"epoch": 13, "training_loss": 1.6852659702301025, "training_acc": 47.0, "val_loss": 0.7407606625556946, "val_acc": 52.0}
{"epoch": 14, "training_loss": 1.4468419075012207, "training_acc": 49.0, "val_loss": 1.8138276433944702, "val_acc": 48.0}
{"epoch": 15, "training_loss": 1.107316243648529, "training_acc": 56.0, "val_loss": 1.7993948078155517, "val_acc": 52.0}
{"epoch": 16, "training_loss": 1.316949381828308, "training_acc": 49.0, "val_loss": 2.211700897216797, "val_acc": 48.0}
{"epoch": 17, "training_loss": 1.8710442447662354, "training_acc": 49.0, "val_loss": 3.5161900520324707, "val_acc": 48.0}
{"epoch": 18, "training_loss": 2.5208896732330324, "training_acc": 52.0, "val_loss": 2.7091066360473635, "val_acc": 48.0}
{"epoch": 19, "training_loss": 2.4731321430206297, "training_acc": 49.0, "val_loss": 2.737286958694458, "val_acc": 48.0}
{"epoch": 20, "training_loss": 1.6551420783996582, "training_acc": 55.0, "val_loss": 0.8639269161224366, "val_acc": 48.0}
{"epoch": 21, "training_loss": 1.984862208366394, "training_acc": 45.0, "val_loss": 3.48018217086792, "val_acc": 52.0}
{"epoch": 22, "training_loss": 3.5612650394439695, "training_acc": 51.0, "val_loss": 0.768337631225586, "val_acc": 52.0}
{"epoch": 23, "training_loss": 1.0390780562907458, "training_acc": 47.0, "val_loss": 2.7420125007629395, "val_acc": 52.0}
{"epoch": 24, "training_loss": 2.5694553661346435, "training_acc": 51.0, "val_loss": 6.199430637359619, "val_acc": 52.0}
{"epoch": 25, "training_loss": 3.6349162435531617, "training_acc": 50.0, "val_loss": 2.517305836677551, "val_acc": 52.0}
{"epoch": 26, "training_loss": 1.7325175189971924, "training_acc": 54.0, "val_loss": 0.7347427248954773, "val_acc": 52.0}
{"epoch": 27, "training_loss": 0.6557363605499268, "training_acc": 62.0, "val_loss": 0.7307387685775757, "val_acc": 44.0}
{"epoch": 28, "training_loss": 0.7249966597557068, "training_acc": 52.0, "val_loss": 1.6366105794906616, "val_acc": 52.0}
{"epoch": 29, "training_loss": 1.56331298828125, "training_acc": 52.0, "val_loss": 0.8371575975418091, "val_acc": 52.0}
{"epoch": 30, "training_loss": 1.2937371778488158, "training_acc": 58.0, "val_loss": 1.2453241491317748, "val_acc": 48.0}
{"epoch": 31, "training_loss": 1.0747215366363525, "training_acc": 46.0, "val_loss": 1.0728419017791748, "val_acc": 48.0}
{"epoch": 32, "training_loss": 0.7379479265213013, "training_acc": 58.0, "val_loss": 1.4500636196136474, "val_acc": 52.0}
{"epoch": 33, "training_loss": 0.9564851284027099, "training_acc": 55.0, "val_loss": 0.9118716001510621, "val_acc": 48.0}
{"epoch": 34, "training_loss": 0.7118895125389099, "training_acc": 56.0, "val_loss": 0.8690599942207337, "val_acc": 52.0}
{"epoch": 35, "training_loss": 0.7331019592285156, "training_acc": 50.0, "val_loss": 0.7620809173583984, "val_acc": 44.0}
{"epoch": 36, "training_loss": 0.951024489402771, "training_acc": 53.0, "val_loss": 1.8508983325958253, "val_acc": 52.0}
{"epoch": 37, "training_loss": 1.47286967754364, "training_acc": 51.0, "val_loss": 1.4836065578460693, "val_acc": 48.0}
{"epoch": 38, "training_loss": 1.2688268089294434, "training_acc": 43.0, "val_loss": 1.0090333604812622, "val_acc": 48.0}
{"epoch": 39, "training_loss": 0.9177765083312989, "training_acc": 50.0, "val_loss": 0.7813775038719177, "val_acc": 52.0}
{"epoch": 40, "training_loss": 0.9017794609069825, "training_acc": 52.0, "val_loss": 3.1391609001159666, "val_acc": 52.0}
{"epoch": 41, "training_loss": 2.762300715446472, "training_acc": 53.0, "val_loss": 1.8501529121398925, "val_acc": 52.0}
{"epoch": 42, "training_loss": 1.893689947128296, "training_acc": 57.0, "val_loss": 2.490465955734253, "val_acc": 52.0}
{"epoch": 43, "training_loss": 2.4667217254638674, "training_acc": 53.0, "val_loss": 1.585118489265442, "val_acc": 52.0}
{"epoch": 44, "training_loss": 1.6818699359893798, "training_acc": 47.0, "val_loss": 1.2159678649902343, "val_acc": 52.0}
{"epoch": 45, "training_loss": 1.4843722152709962, "training_acc": 54.0, "val_loss": 0.884259295463562, "val_acc": 48.0}
{"epoch": 46, "training_loss": 1.137944393157959, "training_acc": 47.0, "val_loss": 1.7753341865539551, "val_acc": 48.0}
