"main_modify.py --pretrained_path /scratch/connectome/dyhan316/VAE_ADHD/barlowtwins/pretrain_results/ABCDbt128a102.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option BT_org --learning_rate 1e-1 --batch_size 16 --weight_decay 1e-2 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 13.380551614761352, "training_acc": 49.0, "val_loss": 4.288563899993896, "val_acc": 52.0}
{"epoch": 1, "training_loss": 11.008580989837647, "training_acc": 41.0, "val_loss": 4.58093671798706, "val_acc": 52.0}
{"epoch": 2, "training_loss": 8.269551162719727, "training_acc": 53.0, "val_loss": 4.0353046226501466, "val_acc": 48.0}
{"epoch": 3, "training_loss": 5.068674240112305, "training_acc": 45.0, "val_loss": 7.3449178886413575, "val_acc": 52.0}
{"epoch": 4, "training_loss": 5.624706573486328, "training_acc": 45.0, "val_loss": 3.007016019821167, "val_acc": 48.0}
{"epoch": 5, "training_loss": 3.706384468078613, "training_acc": 43.0, "val_loss": 2.9321078395843507, "val_acc": 48.0}
{"epoch": 6, "training_loss": 1.7360828421264887, "training_acc": 57.0, "val_loss": 5.395776290893554, "val_acc": 48.0}
{"epoch": 7, "training_loss": 4.583318271636963, "training_acc": 49.0, "val_loss": 5.429658002853394, "val_acc": 52.0}
{"epoch": 8, "training_loss": 2.3203021717071532, "training_acc": 51.0, "val_loss": 1.980891966819763, "val_acc": 52.0}
{"epoch": 9, "training_loss": 1.7611774158477784, "training_acc": 54.0, "val_loss": 0.680694739818573, "val_acc": 52.0}
{"epoch": 10, "training_loss": 1.0264390802383423, "training_acc": 57.0, "val_loss": 0.7708224821090698, "val_acc": 52.0}
{"epoch": 11, "training_loss": 0.8148615503311157, "training_acc": 47.0, "val_loss": 0.7463362002372742, "val_acc": 52.0}
{"epoch": 12, "training_loss": 0.8174187421798706, "training_acc": 58.0, "val_loss": 1.0102131652832032, "val_acc": 48.0}
{"epoch": 13, "training_loss": 1.854473714828491, "training_acc": 33.0, "val_loss": 2.798175458908081, "val_acc": 52.0}
{"epoch": 14, "training_loss": 2.3105466604232787, "training_acc": 51.0, "val_loss": 1.9144643354415893, "val_acc": 52.0}
{"epoch": 15, "training_loss": 1.2500908184051513, "training_acc": 45.0, "val_loss": 0.9653466701507568, "val_acc": 48.0}
{"epoch": 16, "training_loss": 1.9563306999206542, "training_acc": 47.0, "val_loss": 1.6186132955551147, "val_acc": 52.0}
{"epoch": 17, "training_loss": 1.8976467514038087, "training_acc": 45.0, "val_loss": 1.1720691418647766, "val_acc": 52.0}
{"epoch": 18, "training_loss": 0.8219523525238037, "training_acc": 54.0, "val_loss": 1.0675507164001465, "val_acc": 52.0}
{"epoch": 19, "training_loss": 1.1473063945770263, "training_acc": 47.0, "val_loss": 2.5561486530303954, "val_acc": 48.0}
{"epoch": 20, "training_loss": 2.4760271406173704, "training_acc": 51.0, "val_loss": 1.4521585559844972, "val_acc": 48.0}
{"epoch": 21, "training_loss": 0.9877320456504822, "training_acc": 47.0, "val_loss": 0.730581328868866, "val_acc": 52.0}
{"epoch": 22, "training_loss": 0.72882408618927, "training_acc": 60.0, "val_loss": 1.9271956825256347, "val_acc": 48.0}
{"epoch": 23, "training_loss": 2.2486126470565795, "training_acc": 57.0, "val_loss": 2.1871684551239015, "val_acc": 48.0}
{"epoch": 24, "training_loss": 2.7666458749771117, "training_acc": 59.0, "val_loss": 4.9186189746856686, "val_acc": 52.0}
{"epoch": 25, "training_loss": 3.5957085943222045, "training_acc": 49.0, "val_loss": 3.9429045009613035, "val_acc": 52.0}
{"epoch": 26, "training_loss": 3.175889186859131, "training_acc": 45.0, "val_loss": 2.1821096420288084, "val_acc": 52.0}
{"epoch": 27, "training_loss": 1.31541090965271, "training_acc": 41.0, "val_loss": 1.075066750049591, "val_acc": 52.0}
{"epoch": 28, "training_loss": 1.003762068748474, "training_acc": 59.0, "val_loss": 0.9920695805549622, "val_acc": 52.0}
