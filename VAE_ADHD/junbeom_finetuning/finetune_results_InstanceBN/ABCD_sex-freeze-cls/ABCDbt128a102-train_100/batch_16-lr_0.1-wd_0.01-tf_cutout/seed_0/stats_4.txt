"main_modify.py --pretrained_path /scratch/connectome/dyhan316/VAE_ADHD/barlowtwins/pretrain_results/ABCDbt128a102.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option BT_org --learning_rate 1e-1 --batch_size 16 --weight_decay 1e-2 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 12.40598147392273, "training_acc": 51.0, "val_loss": 6.644405708312989, "val_acc": 52.0}
{"epoch": 1, "training_loss": 5.882205820083618, "training_acc": 49.0, "val_loss": 8.907299995422363, "val_acc": 52.0}
{"epoch": 2, "training_loss": 7.152958145141602, "training_acc": 45.0, "val_loss": 1.3404637050628663, "val_acc": 48.0}
{"epoch": 3, "training_loss": 5.766624340415001, "training_acc": 49.0, "val_loss": 5.991243896484375, "val_acc": 48.0}
{"epoch": 4, "training_loss": 6.309129524230957, "training_acc": 45.0, "val_loss": 8.434618816375732, "val_acc": 52.0}
{"epoch": 5, "training_loss": 5.41532304763794, "training_acc": 51.0, "val_loss": 3.535677099227905, "val_acc": 48.0}
{"epoch": 6, "training_loss": 2.152714533805847, "training_acc": 57.0, "val_loss": 3.7680442237854006, "val_acc": 48.0}
{"epoch": 7, "training_loss": 1.699738121032715, "training_acc": 51.0, "val_loss": 1.8376046466827392, "val_acc": 48.0}
{"epoch": 8, "training_loss": 1.244482021331787, "training_acc": 49.0, "val_loss": 2.9622274589538575, "val_acc": 52.0}
{"epoch": 9, "training_loss": 3.5081964111328126, "training_acc": 49.0, "val_loss": 0.6803809595108032, "val_acc": 60.0}
{"epoch": 10, "training_loss": 3.02813570022583, "training_acc": 50.0, "val_loss": 3.233328495025635, "val_acc": 48.0}
{"epoch": 11, "training_loss": 2.403261671066284, "training_acc": 53.0, "val_loss": 2.985233335494995, "val_acc": 48.0}
{"epoch": 12, "training_loss": 2.354070224761963, "training_acc": 47.0, "val_loss": 2.2020206165313723, "val_acc": 48.0}
{"epoch": 13, "training_loss": 1.3876199674606324, "training_acc": 49.0, "val_loss": 1.7456663417816163, "val_acc": 52.0}
{"epoch": 14, "training_loss": 1.7438475131988525, "training_acc": 53.0, "val_loss": 3.4115231895446776, "val_acc": 52.0}
{"epoch": 15, "training_loss": 1.9123610472679138, "training_acc": 59.0, "val_loss": 1.6179801177978517, "val_acc": 52.0}
{"epoch": 16, "training_loss": 1.603611273765564, "training_acc": 59.0, "val_loss": 0.8370320582389832, "val_acc": 52.0}
{"epoch": 17, "training_loss": 0.8488087630271912, "training_acc": 51.0, "val_loss": 0.750829746723175, "val_acc": 52.0}
{"epoch": 18, "training_loss": 0.9450407218933106, "training_acc": 57.0, "val_loss": 0.8977782678604126, "val_acc": 48.0}
{"epoch": 19, "training_loss": 0.7768625259399414, "training_acc": 50.0, "val_loss": 0.7642934393882751, "val_acc": 52.0}
{"epoch": 20, "training_loss": 0.8422925591468811, "training_acc": 49.0, "val_loss": 0.8358187985420227, "val_acc": 48.0}
{"epoch": 21, "training_loss": 0.7445926523208618, "training_acc": 61.0, "val_loss": 1.269447934627533, "val_acc": 48.0}
{"epoch": 22, "training_loss": 0.8761490786075592, "training_acc": 56.0, "val_loss": 2.7038188362121582, "val_acc": 52.0}
{"epoch": 23, "training_loss": 2.2208528995513914, "training_acc": 49.0, "val_loss": 3.049835386276245, "val_acc": 52.0}
{"epoch": 24, "training_loss": 2.102881851196289, "training_acc": 49.0, "val_loss": 1.853599739074707, "val_acc": 52.0}
{"epoch": 25, "training_loss": 1.5396014666557312, "training_acc": 57.0, "val_loss": 0.681747932434082, "val_acc": 56.0}
{"epoch": 26, "training_loss": 1.505252423286438, "training_acc": 39.0, "val_loss": 2.466831693649292, "val_acc": 52.0}
{"epoch": 27, "training_loss": 1.6671122550964355, "training_acc": 55.0, "val_loss": 0.7841069459915161, "val_acc": 48.0}
{"epoch": 28, "training_loss": 0.9486538743972779, "training_acc": 53.0, "val_loss": 1.2878088521957398, "val_acc": 52.0}
