"main_modify.py --pretrained_path /scratch/connectome/dyhan316/VAE_ADHD/barlowtwins/pretrain_results/ABCDbt128a102.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option BT_org --learning_rate 5e-5 --batch_size 16 --weight_decay 5e-2 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 0.6941620635986329, "training_acc": 53.0, "val_loss": 0.6920049285888672, "val_acc": 52.0}
{"epoch": 1, "training_loss": 0.6917881274223328, "training_acc": 53.0, "val_loss": 0.6917326855659485, "val_acc": 52.0}
{"epoch": 2, "training_loss": 0.6913387393951416, "training_acc": 53.0, "val_loss": 0.6917389750480651, "val_acc": 52.0}
{"epoch": 3, "training_loss": 0.6918790769577027, "training_acc": 53.0, "val_loss": 0.6917822575569152, "val_acc": 52.0}
{"epoch": 4, "training_loss": 0.690794231891632, "training_acc": 53.0, "val_loss": 0.691763961315155, "val_acc": 52.0}
{"epoch": 5, "training_loss": 0.6914728975296021, "training_acc": 53.0, "val_loss": 0.6918634366989136, "val_acc": 52.0}
{"epoch": 6, "training_loss": 0.6914680480957032, "training_acc": 53.0, "val_loss": 0.6919086456298829, "val_acc": 52.0}
{"epoch": 7, "training_loss": 0.6913860654830932, "training_acc": 53.0, "val_loss": 0.6919792199134827, "val_acc": 52.0}
{"epoch": 8, "training_loss": 0.6915652656555176, "training_acc": 53.0, "val_loss": 0.6919943571090699, "val_acc": 52.0}
{"epoch": 9, "training_loss": 0.6911412858963013, "training_acc": 53.0, "val_loss": 0.6921984815597534, "val_acc": 52.0}
{"epoch": 10, "training_loss": 0.6914690375328064, "training_acc": 53.0, "val_loss": 0.6924751210212707, "val_acc": 52.0}
{"epoch": 11, "training_loss": 0.6915219640731811, "training_acc": 53.0, "val_loss": 0.6924025845527649, "val_acc": 52.0}
{"epoch": 12, "training_loss": 0.6919664335250855, "training_acc": 53.0, "val_loss": 0.6927085518836975, "val_acc": 52.0}
{"epoch": 13, "training_loss": 0.6916187953948975, "training_acc": 53.0, "val_loss": 0.692410089969635, "val_acc": 52.0}
{"epoch": 14, "training_loss": 0.6911571407318116, "training_acc": 53.0, "val_loss": 0.6922177696228027, "val_acc": 52.0}
{"epoch": 15, "training_loss": 0.6911886596679687, "training_acc": 53.0, "val_loss": 0.6919728922843933, "val_acc": 52.0}
{"epoch": 16, "training_loss": 0.6931861448287964, "training_acc": 53.0, "val_loss": 0.6917264628410339, "val_acc": 52.0}
{"epoch": 17, "training_loss": 0.6914417099952698, "training_acc": 53.0, "val_loss": 0.6917470645904541, "val_acc": 52.0}
{"epoch": 18, "training_loss": 0.6912416338920593, "training_acc": 53.0, "val_loss": 0.6917720127105713, "val_acc": 52.0}
{"epoch": 19, "training_loss": 0.6919276404380799, "training_acc": 53.0, "val_loss": 0.6919010710716248, "val_acc": 52.0}
{"epoch": 20, "training_loss": 0.6913329362869263, "training_acc": 53.0, "val_loss": 0.6919614458084107, "val_acc": 52.0}
{"epoch": 21, "training_loss": 0.6912040638923646, "training_acc": 53.0, "val_loss": 0.6919229578971863, "val_acc": 52.0}
{"epoch": 22, "training_loss": 0.6908189177513122, "training_acc": 53.0, "val_loss": 0.6920055484771729, "val_acc": 52.0}
{"epoch": 23, "training_loss": 0.6912433719635009, "training_acc": 53.0, "val_loss": 0.6920343089103699, "val_acc": 52.0}
{"epoch": 24, "training_loss": 0.6911702346801758, "training_acc": 53.0, "val_loss": 0.6920559763908386, "val_acc": 52.0}
{"epoch": 25, "training_loss": 0.6909834837913513, "training_acc": 53.0, "val_loss": 0.6924428081512451, "val_acc": 52.0}
{"epoch": 26, "training_loss": 0.6921816992759705, "training_acc": 53.0, "val_loss": 0.6927207493782044, "val_acc": 52.0}
{"epoch": 27, "training_loss": 0.6913859462738037, "training_acc": 53.0, "val_loss": 0.6921602272987366, "val_acc": 52.0}
{"epoch": 28, "training_loss": 0.6911911988258361, "training_acc": 53.0, "val_loss": 0.6918694257736206, "val_acc": 52.0}
{"epoch": 29, "training_loss": 0.6913120365142822, "training_acc": 53.0, "val_loss": 0.6917747926712036, "val_acc": 52.0}
{"epoch": 30, "training_loss": 0.6913732385635376, "training_acc": 53.0, "val_loss": 0.6917436671257019, "val_acc": 52.0}
{"epoch": 31, "training_loss": 0.6907550191879273, "training_acc": 53.0, "val_loss": 0.6917968320846558, "val_acc": 52.0}
{"epoch": 32, "training_loss": 0.6908652567863465, "training_acc": 53.0, "val_loss": 0.691962502002716, "val_acc": 52.0}
{"epoch": 33, "training_loss": 0.6916456031799316, "training_acc": 53.0, "val_loss": 0.6923197674751281, "val_acc": 52.0}
{"epoch": 34, "training_loss": 0.6913961815834045, "training_acc": 53.0, "val_loss": 0.6922489142417908, "val_acc": 52.0}
{"epoch": 35, "training_loss": 0.6912672424316406, "training_acc": 53.0, "val_loss": 0.6923495388031006, "val_acc": 52.0}
