"main_modify.py --pretrained_path /scratch/connectome/dyhan316/VAE_ADHD/barlowtwins/pretrain_results/ABCDbt128a102.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option BT_org --learning_rate 5e-5 --batch_size 16 --weight_decay 5e-2 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 0.6999183917045593, "training_acc": 47.0, "val_loss": 0.6937276244163513, "val_acc": 48.0}
{"epoch": 1, "training_loss": 0.6974026417732239, "training_acc": 47.0, "val_loss": 0.6921153974533081, "val_acc": 48.0}
{"epoch": 2, "training_loss": 0.6949403524398804, "training_acc": 47.0, "val_loss": 0.6908367991447448, "val_acc": 52.0}
{"epoch": 3, "training_loss": 0.6940477371215821, "training_acc": 48.0, "val_loss": 0.6901559543609619, "val_acc": 76.0}
{"epoch": 4, "training_loss": 0.6929234790802002, "training_acc": 54.0, "val_loss": 0.6897175192832947, "val_acc": 52.0}
{"epoch": 5, "training_loss": 0.6928199577331543, "training_acc": 53.0, "val_loss": 0.6894198727607727, "val_acc": 52.0}
{"epoch": 6, "training_loss": 0.6920385074615478, "training_acc": 53.0, "val_loss": 0.6893924951553345, "val_acc": 52.0}
{"epoch": 7, "training_loss": 0.6912012958526611, "training_acc": 53.0, "val_loss": 0.6893673825263977, "val_acc": 52.0}
{"epoch": 8, "training_loss": 0.6918796634674073, "training_acc": 53.0, "val_loss": 0.6893613171577454, "val_acc": 52.0}
{"epoch": 9, "training_loss": 0.6917092609405517, "training_acc": 53.0, "val_loss": 0.6893940281867981, "val_acc": 52.0}
{"epoch": 10, "training_loss": 0.6915074396133423, "training_acc": 53.0, "val_loss": 0.6893811440467834, "val_acc": 52.0}
{"epoch": 11, "training_loss": 0.6917280626296997, "training_acc": 53.0, "val_loss": 0.6893625354766846, "val_acc": 52.0}
{"epoch": 12, "training_loss": 0.6915108609199524, "training_acc": 53.0, "val_loss": 0.6893843936920167, "val_acc": 52.0}
{"epoch": 13, "training_loss": 0.691595983505249, "training_acc": 53.0, "val_loss": 0.6894160103797913, "val_acc": 52.0}
{"epoch": 14, "training_loss": 0.6912807178497314, "training_acc": 53.0, "val_loss": 0.6894625210762024, "val_acc": 52.0}
{"epoch": 15, "training_loss": 0.6913944172859192, "training_acc": 53.0, "val_loss": 0.6895306777954101, "val_acc": 52.0}
{"epoch": 16, "training_loss": 0.6910296845436096, "training_acc": 53.0, "val_loss": 0.6896355557441711, "val_acc": 52.0}
{"epoch": 17, "training_loss": 0.6915782642364502, "training_acc": 53.0, "val_loss": 0.689924237728119, "val_acc": 52.0}
{"epoch": 18, "training_loss": 0.6916906023025513, "training_acc": 53.0, "val_loss": 0.6900448989868164, "val_acc": 52.0}
{"epoch": 19, "training_loss": 0.6910761833190918, "training_acc": 53.0, "val_loss": 0.6897495651245117, "val_acc": 52.0}
{"epoch": 20, "training_loss": 0.6911682510375976, "training_acc": 53.0, "val_loss": 0.6896248173713684, "val_acc": 52.0}
{"epoch": 21, "training_loss": 0.6913513994216919, "training_acc": 53.0, "val_loss": 0.6895330739021301, "val_acc": 52.0}
{"epoch": 22, "training_loss": 0.6911340355873108, "training_acc": 53.0, "val_loss": 0.6895764207839966, "val_acc": 52.0}
{"epoch": 23, "training_loss": 0.6909861230850219, "training_acc": 53.0, "val_loss": 0.6895141696929932, "val_acc": 52.0}
{"epoch": 24, "training_loss": 0.6914990973472596, "training_acc": 53.0, "val_loss": 0.6894563055038452, "val_acc": 52.0}
{"epoch": 25, "training_loss": 0.6915677881240845, "training_acc": 53.0, "val_loss": 0.6896040439605713, "val_acc": 52.0}
{"epoch": 26, "training_loss": 0.6916501379013061, "training_acc": 53.0, "val_loss": 0.6897704362869262, "val_acc": 52.0}
{"epoch": 27, "training_loss": 0.6915495896339416, "training_acc": 53.0, "val_loss": 0.6894922733306885, "val_acc": 52.0}
