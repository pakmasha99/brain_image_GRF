"main_modify.py --pretrained_path /scratch/connectome/dyhan316/VAE_ADHD/barlowtwins/pretrain_results/ABCDbt128a102.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option BT_org --learning_rate 5e-5 --batch_size 16 --weight_decay 5e-2 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 0.6926228618621826, "training_acc": 52.0, "val_loss": 0.6882311296463013, "val_acc": 56.0}
{"epoch": 1, "training_loss": 0.6925425410270691, "training_acc": 52.0, "val_loss": 0.6878021550178528, "val_acc": 56.0}
{"epoch": 2, "training_loss": 0.6925255632400513, "training_acc": 52.0, "val_loss": 0.6877774834632874, "val_acc": 56.0}
{"epoch": 3, "training_loss": 0.6924542784690857, "training_acc": 52.0, "val_loss": 0.6869564509391785, "val_acc": 56.0}
{"epoch": 4, "training_loss": 0.6925042033195495, "training_acc": 52.0, "val_loss": 0.6873658537864685, "val_acc": 56.0}
{"epoch": 5, "training_loss": 0.6921766805648804, "training_acc": 52.0, "val_loss": 0.6870172095298767, "val_acc": 56.0}
{"epoch": 6, "training_loss": 0.6920887994766235, "training_acc": 52.0, "val_loss": 0.6869427990913392, "val_acc": 56.0}
{"epoch": 7, "training_loss": 0.6922963404655457, "training_acc": 52.0, "val_loss": 0.6873039388656617, "val_acc": 56.0}
{"epoch": 8, "training_loss": 0.692301070690155, "training_acc": 52.0, "val_loss": 0.6869199466705322, "val_acc": 56.0}
{"epoch": 9, "training_loss": 0.6922574186325073, "training_acc": 52.0, "val_loss": 0.68740558385849, "val_acc": 56.0}
{"epoch": 10, "training_loss": 0.6922671699523926, "training_acc": 52.0, "val_loss": 0.6884899830818176, "val_acc": 56.0}
{"epoch": 11, "training_loss": 0.692031798362732, "training_acc": 52.0, "val_loss": 0.6884068608283996, "val_acc": 56.0}
{"epoch": 12, "training_loss": 0.6932592582702637, "training_acc": 52.0, "val_loss": 0.6870192694664001, "val_acc": 56.0}
{"epoch": 13, "training_loss": 0.6919266366958619, "training_acc": 52.0, "val_loss": 0.6868513607978821, "val_acc": 56.0}
{"epoch": 14, "training_loss": 0.6922832345962524, "training_acc": 52.0, "val_loss": 0.6863711833953857, "val_acc": 56.0}
{"epoch": 15, "training_loss": 0.6924378442764282, "training_acc": 52.0, "val_loss": 0.6862873196601867, "val_acc": 56.0}
{"epoch": 16, "training_loss": 0.6932317018508911, "training_acc": 52.0, "val_loss": 0.6855109095573425, "val_acc": 56.0}
{"epoch": 17, "training_loss": 0.6922789430618286, "training_acc": 52.0, "val_loss": 0.6859529805183411, "val_acc": 56.0}
{"epoch": 18, "training_loss": 0.6922655844688416, "training_acc": 52.0, "val_loss": 0.6867279481887817, "val_acc": 56.0}
{"epoch": 19, "training_loss": 0.692338981628418, "training_acc": 52.0, "val_loss": 0.6878204154968262, "val_acc": 56.0}
{"epoch": 20, "training_loss": 0.692315981388092, "training_acc": 52.0, "val_loss": 0.6879585003852844, "val_acc": 56.0}
{"epoch": 21, "training_loss": 0.6917925977706909, "training_acc": 52.0, "val_loss": 0.6881419730186462, "val_acc": 56.0}
{"epoch": 22, "training_loss": 0.6920931100845337, "training_acc": 52.0, "val_loss": 0.6877583360671997, "val_acc": 56.0}
{"epoch": 23, "training_loss": 0.692017879486084, "training_acc": 52.0, "val_loss": 0.687932596206665, "val_acc": 56.0}
{"epoch": 24, "training_loss": 0.6926764225959778, "training_acc": 52.0, "val_loss": 0.6871399641036987, "val_acc": 56.0}
{"epoch": 25, "training_loss": 0.6922382664680481, "training_acc": 52.0, "val_loss": 0.6874378991127014, "val_acc": 56.0}
{"epoch": 26, "training_loss": 0.6917948532104492, "training_acc": 52.0, "val_loss": 0.6873795390129089, "val_acc": 56.0}
{"epoch": 27, "training_loss": 0.6917498135566711, "training_acc": 52.0, "val_loss": 0.6877207803726196, "val_acc": 56.0}
{"epoch": 28, "training_loss": 0.6921648788452148, "training_acc": 52.0, "val_loss": 0.6878140377998352, "val_acc": 56.0}
{"epoch": 29, "training_loss": 0.6921277236938477, "training_acc": 52.0, "val_loss": 0.6872923064231873, "val_acc": 56.0}
{"epoch": 30, "training_loss": 0.6925569272041321, "training_acc": 52.0, "val_loss": 0.6860671782493591, "val_acc": 56.0}
{"epoch": 31, "training_loss": 0.692074761390686, "training_acc": 52.0, "val_loss": 0.6856762266159058, "val_acc": 56.0}
{"epoch": 32, "training_loss": 0.6924110794067383, "training_acc": 52.0, "val_loss": 0.6849156832695007, "val_acc": 56.0}
{"epoch": 33, "training_loss": 0.6931517887115478, "training_acc": 52.0, "val_loss": 0.6847286558151245, "val_acc": 56.0}
{"epoch": 34, "training_loss": 0.6931229066848755, "training_acc": 52.0, "val_loss": 0.6850394368171692, "val_acc": 56.0}
{"epoch": 35, "training_loss": 0.6922357726097107, "training_acc": 52.0, "val_loss": 0.6857872700691223, "val_acc": 56.0}
{"epoch": 36, "training_loss": 0.6927043890953064, "training_acc": 52.0, "val_loss": 0.6860683393478394, "val_acc": 56.0}
{"epoch": 37, "training_loss": 0.6927589368820191, "training_acc": 52.0, "val_loss": 0.6860948801040649, "val_acc": 56.0}
{"epoch": 38, "training_loss": 0.6927389574050903, "training_acc": 52.0, "val_loss": 0.6864924192428589, "val_acc": 56.0}
{"epoch": 39, "training_loss": 0.6923224401473999, "training_acc": 52.0, "val_loss": 0.6869003605842591, "val_acc": 56.0}
{"epoch": 40, "training_loss": 0.6925604057312011, "training_acc": 52.0, "val_loss": 0.6877589678764343, "val_acc": 56.0}
{"epoch": 41, "training_loss": 0.6918087816238403, "training_acc": 52.0, "val_loss": 0.6878977108001709, "val_acc": 56.0}
{"epoch": 42, "training_loss": 0.6917481279373169, "training_acc": 52.0, "val_loss": 0.6879680848121643, "val_acc": 56.0}
{"epoch": 43, "training_loss": 0.6916912579536438, "training_acc": 52.0, "val_loss": 0.688026852607727, "val_acc": 56.0}
{"epoch": 44, "training_loss": 0.6925278997421265, "training_acc": 52.0, "val_loss": 0.6890449023246765, "val_acc": 56.0}
{"epoch": 45, "training_loss": 0.6920705699920654, "training_acc": 52.0, "val_loss": 0.6891300368309021, "val_acc": 56.0}
{"epoch": 46, "training_loss": 0.691800389289856, "training_acc": 52.0, "val_loss": 0.6889360475540162, "val_acc": 56.0}
{"epoch": 47, "training_loss": 0.6922390556335449, "training_acc": 52.0, "val_loss": 0.6883641409873963, "val_acc": 56.0}
{"epoch": 48, "training_loss": 0.6921833658218384, "training_acc": 52.0, "val_loss": 0.6878077816963196, "val_acc": 56.0}
{"epoch": 49, "training_loss": 0.6918675231933594, "training_acc": 52.0, "val_loss": 0.6879771375656127, "val_acc": 56.0}
{"epoch": 50, "training_loss": 0.6923795890808105, "training_acc": 52.0, "val_loss": 0.6888830089569091, "val_acc": 56.0}
{"epoch": 51, "training_loss": 0.6923128294944764, "training_acc": 52.0, "val_loss": 0.6898213601112366, "val_acc": 56.0}
{"epoch": 52, "training_loss": 0.6927244114875794, "training_acc": 51.0, "val_loss": 0.690870487689972, "val_acc": 56.0}
