"main_modify.py --pretrained_path /scratch/connectome/dyhan316/VAE_ADHD/barlowtwins/pretrain_results/ABCDbt128a102.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 1 --task ABCD_sex --input_option BT_org --learning_rate 1e-2 --batch_size 16 --weight_decay 1e-2 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 0.8653193116188049, "training_acc": 52.0, "val_loss": 0.7003597331047058, "val_acc": 48.0}
{"epoch": 1, "training_loss": 0.8920956897735596, "training_acc": 47.0, "val_loss": 0.9228123569488526, "val_acc": 48.0}
{"epoch": 2, "training_loss": 0.8199147558212281, "training_acc": 51.0, "val_loss": 0.710198745727539, "val_acc": 48.0}
{"epoch": 3, "training_loss": 0.9301135063171386, "training_acc": 51.0, "val_loss": 1.2318079280853271, "val_acc": 52.0}
{"epoch": 4, "training_loss": 1.209149043560028, "training_acc": 55.0, "val_loss": 1.1403971910476685, "val_acc": 48.0}
{"epoch": 5, "training_loss": 1.040842193365097, "training_acc": 51.0, "val_loss": 1.2781323957443238, "val_acc": 52.0}
{"epoch": 6, "training_loss": 1.645524172782898, "training_acc": 53.0, "val_loss": 0.7892855525016784, "val_acc": 48.0}
{"epoch": 7, "training_loss": 1.1163489484786988, "training_acc": 49.0, "val_loss": 0.9041968560218812, "val_acc": 52.0}
{"epoch": 8, "training_loss": 1.1519691848754883, "training_acc": 54.0, "val_loss": 0.8370382809638977, "val_acc": 48.0}
{"epoch": 9, "training_loss": 0.9647378540039062, "training_acc": 41.0, "val_loss": 0.9395130443572998, "val_acc": 52.0}
{"epoch": 10, "training_loss": 0.9104893589019776, "training_acc": 53.0, "val_loss": 1.0003333473205567, "val_acc": 48.0}
{"epoch": 11, "training_loss": 0.8428752183914184, "training_acc": 49.0, "val_loss": 0.9186834216117858, "val_acc": 52.0}
{"epoch": 12, "training_loss": 0.7899198293685913, "training_acc": 49.0, "val_loss": 0.7266705846786499, "val_acc": 48.0}
{"epoch": 13, "training_loss": 0.7557439589500428, "training_acc": 49.0, "val_loss": 0.6960473155975342, "val_acc": 52.0}
{"epoch": 14, "training_loss": 0.6826685333251953, "training_acc": 58.0, "val_loss": 0.7113497853279114, "val_acc": 52.0}
{"epoch": 15, "training_loss": 0.6881402277946472, "training_acc": 53.0, "val_loss": 0.7067494702339172, "val_acc": 48.0}
{"epoch": 16, "training_loss": 0.6993464231491089, "training_acc": 48.0, "val_loss": 0.7162262916564941, "val_acc": 52.0}
{"epoch": 17, "training_loss": 0.7393669080734253, "training_acc": 51.0, "val_loss": 0.7045970153808594, "val_acc": 48.0}
{"epoch": 18, "training_loss": 0.6974309277534485, "training_acc": 53.0, "val_loss": 0.6995942020416259, "val_acc": 52.0}
{"epoch": 19, "training_loss": 0.6858274507522583, "training_acc": 58.0, "val_loss": 0.7632247090339661, "val_acc": 48.0}
{"epoch": 20, "training_loss": 0.7343846535682679, "training_acc": 44.0, "val_loss": 0.7020349979400635, "val_acc": 52.0}
{"epoch": 21, "training_loss": 0.6829901838302612, "training_acc": 59.0, "val_loss": 0.6935195565223694, "val_acc": 52.0}
{"epoch": 22, "training_loss": 0.687329866886139, "training_acc": 54.0, "val_loss": 0.8590164995193481, "val_acc": 52.0}
{"epoch": 23, "training_loss": 0.7783751845359802, "training_acc": 60.0, "val_loss": 1.0307097864151, "val_acc": 48.0}
{"epoch": 24, "training_loss": 0.8966346073150635, "training_acc": 43.0, "val_loss": 0.6978097534179688, "val_acc": 52.0}
{"epoch": 25, "training_loss": 0.7119729518890381, "training_acc": 53.0, "val_loss": 0.7073777413368225, "val_acc": 52.0}
{"epoch": 26, "training_loss": 0.672303957939148, "training_acc": 64.0, "val_loss": 0.7118962454795837, "val_acc": 48.0}
{"epoch": 27, "training_loss": 0.6927259659767151, "training_acc": 54.0, "val_loss": 0.835635962486267, "val_acc": 52.0}
{"epoch": 28, "training_loss": 0.7835915160179138, "training_acc": 51.0, "val_loss": 0.8565351605415344, "val_acc": 48.0}
{"epoch": 29, "training_loss": 0.7746474027633667, "training_acc": 51.0, "val_loss": 0.6985238647460937, "val_acc": 52.0}
{"epoch": 30, "training_loss": 0.8007781600952149, "training_acc": 49.0, "val_loss": 0.8642817759513854, "val_acc": 52.0}
{"epoch": 31, "training_loss": 0.8694051480293274, "training_acc": 45.0, "val_loss": 0.7208923292160034, "val_acc": 52.0}
{"epoch": 32, "training_loss": 0.8733728098869323, "training_acc": 57.0, "val_loss": 0.996286153793335, "val_acc": 48.0}
{"epoch": 33, "training_loss": 0.9111366176605225, "training_acc": 47.0, "val_loss": 0.8355376362800598, "val_acc": 52.0}
{"epoch": 34, "training_loss": 0.8665680146217346, "training_acc": 47.0, "val_loss": 0.8153556871414185, "val_acc": 52.0}
{"epoch": 35, "training_loss": 0.7388627576828003, "training_acc": 58.0, "val_loss": 0.7713402366638183, "val_acc": 48.0}
{"epoch": 36, "training_loss": 0.6806891870498657, "training_acc": 58.0, "val_loss": 0.7425640797615052, "val_acc": 52.0}
{"epoch": 37, "training_loss": 0.6811185646057129, "training_acc": 55.0, "val_loss": 0.9304977512359619, "val_acc": 48.0}
{"epoch": 38, "training_loss": 0.7805533194541932, "training_acc": 53.0, "val_loss": 0.839798493385315, "val_acc": 52.0}
{"epoch": 39, "training_loss": 0.874573004245758, "training_acc": 46.0, "val_loss": 0.7199351596832275, "val_acc": 52.0}
{"epoch": 40, "training_loss": 0.7028658866882325, "training_acc": 53.0, "val_loss": 0.7305399775505066, "val_acc": 48.0}
