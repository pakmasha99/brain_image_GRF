"main_modify.py --pretrained_path /scratch/connectome/dyhan316/VAE_ADHD/barlowtwins/pretrain_results/ABCDbt128a102.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 1 --task ABCD_sex --input_option BT_org --learning_rate 1e-2 --batch_size 16 --weight_decay 1e-2 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 1.2956594932079315, "training_acc": 47.0, "val_loss": 0.8906279373168945, "val_acc": 52.0}
{"epoch": 1, "training_loss": 0.8243430781364441, "training_acc": 53.0, "val_loss": 0.7912743353843689, "val_acc": 52.0}
{"epoch": 2, "training_loss": 0.9140237903594971, "training_acc": 53.0, "val_loss": 0.8127738928794861, "val_acc": 48.0}
{"epoch": 3, "training_loss": 0.9015107655525207, "training_acc": 47.0, "val_loss": 1.0270846176147461, "val_acc": 52.0}
{"epoch": 4, "training_loss": 0.9126601600646973, "training_acc": 41.0, "val_loss": 0.6927176642417908, "val_acc": 48.0}
{"epoch": 5, "training_loss": 0.8359522914886475, "training_acc": 55.0, "val_loss": 0.7215499138832092, "val_acc": 48.0}
{"epoch": 6, "training_loss": 0.7253003454208374, "training_acc": 47.0, "val_loss": 0.6937069749832153, "val_acc": 52.0}
{"epoch": 7, "training_loss": 0.7117981052398682, "training_acc": 43.0, "val_loss": 0.6994925665855408, "val_acc": 52.0}
{"epoch": 8, "training_loss": 0.6999414920806885, "training_acc": 49.0, "val_loss": 0.6904831671714783, "val_acc": 72.0}
{"epoch": 9, "training_loss": 0.7099011898040771, "training_acc": 58.0, "val_loss": 0.7477294278144836, "val_acc": 48.0}
{"epoch": 10, "training_loss": 0.7427991771697998, "training_acc": 51.0, "val_loss": 0.8197831654548645, "val_acc": 52.0}
{"epoch": 11, "training_loss": 0.766760368347168, "training_acc": 50.0, "val_loss": 0.7254702043533325, "val_acc": 52.0}
{"epoch": 12, "training_loss": 0.7572489929199219, "training_acc": 53.0, "val_loss": 0.7993492913246155, "val_acc": 48.0}
{"epoch": 13, "training_loss": 0.832231502532959, "training_acc": 39.0, "val_loss": 0.7215863919258118, "val_acc": 48.0}
{"epoch": 14, "training_loss": 0.862684497833252, "training_acc": 45.0, "val_loss": 0.9309493470191955, "val_acc": 52.0}
{"epoch": 15, "training_loss": 0.7495130872726441, "training_acc": 59.0, "val_loss": 1.070745551586151, "val_acc": 48.0}
{"epoch": 16, "training_loss": 0.9421031951904297, "training_acc": 45.0, "val_loss": 0.7377299904823303, "val_acc": 52.0}
{"epoch": 17, "training_loss": 0.7618796896934509, "training_acc": 46.0, "val_loss": 0.7121290946006775, "val_acc": 52.0}
{"epoch": 18, "training_loss": 0.7072061014175415, "training_acc": 51.0, "val_loss": 0.7002809619903565, "val_acc": 52.0}
{"epoch": 19, "training_loss": 0.7147679233551025, "training_acc": 53.0, "val_loss": 0.7079718494415284, "val_acc": 48.0}
{"epoch": 20, "training_loss": 0.7478439235687255, "training_acc": 44.0, "val_loss": 0.6908859992027283, "val_acc": 52.0}
{"epoch": 21, "training_loss": 0.6964230608940124, "training_acc": 49.0, "val_loss": 0.7204190754890442, "val_acc": 52.0}
{"epoch": 22, "training_loss": 0.7129210352897644, "training_acc": 55.0, "val_loss": 0.798728973865509, "val_acc": 48.0}
{"epoch": 23, "training_loss": 0.7456938600540162, "training_acc": 49.0, "val_loss": 0.6952536129951477, "val_acc": 52.0}
{"epoch": 24, "training_loss": 0.7630311536788941, "training_acc": 48.0, "val_loss": 1.0050407886505126, "val_acc": 52.0}
{"epoch": 25, "training_loss": 0.8481509494781494, "training_acc": 56.0, "val_loss": 0.7452607035636902, "val_acc": 48.0}
{"epoch": 26, "training_loss": 0.7158088445663452, "training_acc": 57.0, "val_loss": 0.7748550844192504, "val_acc": 52.0}
{"epoch": 27, "training_loss": 0.6868564438819885, "training_acc": 56.0, "val_loss": 0.810128755569458, "val_acc": 48.0}
