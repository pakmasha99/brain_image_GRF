"main_modify.py --pretrained_path /scratch/connectome/dyhan316/VAE_ADHD/barlowtwins/pretrain_results/ABCDbt128a102.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option BT_org --learning_rate 1e-2 --batch_size 16 --weight_decay 1e-2 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 1.1417961025238037, "training_acc": 55.0, "val_loss": 0.6946891379356385, "val_acc": 48.0}
{"epoch": 1, "training_loss": 0.8136411190032959, "training_acc": 39.0, "val_loss": 0.8397713041305542, "val_acc": 48.0}
{"epoch": 2, "training_loss": 0.8274423885345459, "training_acc": 47.0, "val_loss": 0.8709765219688416, "val_acc": 52.0}
{"epoch": 3, "training_loss": 0.7242600488662719, "training_acc": 59.0, "val_loss": 0.9260541105270386, "val_acc": 48.0}
{"epoch": 4, "training_loss": 0.8022403120994568, "training_acc": 49.0, "val_loss": 0.7450518727302551, "val_acc": 52.0}
{"epoch": 5, "training_loss": 0.7065736746788025, "training_acc": 54.0, "val_loss": 0.726617603302002, "val_acc": 48.0}
{"epoch": 6, "training_loss": 0.7280372428894043, "training_acc": 49.0, "val_loss": 0.7209256863594056, "val_acc": 52.0}
{"epoch": 7, "training_loss": 0.7194612646102905, "training_acc": 45.0, "val_loss": 0.7208312344551087, "val_acc": 52.0}
{"epoch": 8, "training_loss": 0.7173133063316345, "training_acc": 49.0, "val_loss": 0.7514771127700806, "val_acc": 48.0}
{"epoch": 9, "training_loss": 0.752179229259491, "training_acc": 49.0, "val_loss": 0.7804835605621337, "val_acc": 52.0}
{"epoch": 10, "training_loss": 0.7891981649398804, "training_acc": 41.0, "val_loss": 0.7467744541168213, "val_acc": 52.0}
{"epoch": 11, "training_loss": 0.7781540870666503, "training_acc": 41.0, "val_loss": 0.7229808044433593, "val_acc": 52.0}
{"epoch": 12, "training_loss": 0.6741062116622925, "training_acc": 59.0, "val_loss": 0.962130560874939, "val_acc": 48.0}
{"epoch": 13, "training_loss": 0.863241376876831, "training_acc": 55.0, "val_loss": 1.0453978514671325, "val_acc": 52.0}
{"epoch": 14, "training_loss": 0.7959445261955261, "training_acc": 53.0, "val_loss": 0.7035842537879944, "val_acc": 48.0}
{"epoch": 15, "training_loss": 0.8698079752922058, "training_acc": 53.0, "val_loss": 0.788454201221466, "val_acc": 48.0}
{"epoch": 16, "training_loss": 0.73005051612854, "training_acc": 49.0, "val_loss": 0.6948473191261292, "val_acc": 52.0}
{"epoch": 17, "training_loss": 0.6893722486495971, "training_acc": 49.0, "val_loss": 0.7106228184700012, "val_acc": 48.0}
{"epoch": 18, "training_loss": 0.7286939096450805, "training_acc": 49.0, "val_loss": 0.7498882555961609, "val_acc": 52.0}
{"epoch": 19, "training_loss": 0.7014567255973816, "training_acc": 49.0, "val_loss": 0.6927972722053528, "val_acc": 52.0}
{"epoch": 20, "training_loss": 0.7157081174850464, "training_acc": 50.0, "val_loss": 0.6991985821723938, "val_acc": 48.0}
{"epoch": 21, "training_loss": 0.715713472366333, "training_acc": 54.0, "val_loss": 0.8255684971809387, "val_acc": 48.0}
{"epoch": 22, "training_loss": 0.7505106019973755, "training_acc": 53.0, "val_loss": 0.7384904241561889, "val_acc": 52.0}
{"epoch": 23, "training_loss": 0.6966611170768737, "training_acc": 53.0, "val_loss": 0.7268672251701355, "val_acc": 48.0}
{"epoch": 24, "training_loss": 0.6827555608749389, "training_acc": 59.0, "val_loss": 0.6980386662483216, "val_acc": 52.0}
{"epoch": 25, "training_loss": 0.6864470481872559, "training_acc": 52.0, "val_loss": 0.743235399723053, "val_acc": 52.0}
{"epoch": 26, "training_loss": 0.7116021466255188, "training_acc": 55.0, "val_loss": 0.8435728001594544, "val_acc": 48.0}
{"epoch": 27, "training_loss": 0.7633156776428223, "training_acc": 51.0, "val_loss": 0.7900393080711364, "val_acc": 52.0}
{"epoch": 28, "training_loss": 0.75382089138031, "training_acc": 49.0, "val_loss": 0.7094850492477417, "val_acc": 52.0}
{"epoch": 29, "training_loss": 0.8485055637359619, "training_acc": 55.0, "val_loss": 1.3225654458999634, "val_acc": 48.0}
{"epoch": 30, "training_loss": 1.1248526000976562, "training_acc": 49.0, "val_loss": 0.9861754179000854, "val_acc": 52.0}
{"epoch": 31, "training_loss": 0.7671767520904541, "training_acc": 51.0, "val_loss": 0.6975088024139404, "val_acc": 48.0}
{"epoch": 32, "training_loss": 0.6892343425750732, "training_acc": 56.0, "val_loss": 0.7095205545425415, "val_acc": 52.0}
{"epoch": 33, "training_loss": 0.6766930603981018, "training_acc": 57.0, "val_loss": 0.6961452507972717, "val_acc": 56.0}
{"epoch": 34, "training_loss": 0.7209828400611877, "training_acc": 56.0, "val_loss": 0.8282146954536438, "val_acc": 48.0}
{"epoch": 35, "training_loss": 0.7452459335327148, "training_acc": 46.0, "val_loss": 0.6980223155021668, "val_acc": 52.0}
{"epoch": 36, "training_loss": 0.6858122158050537, "training_acc": 48.0, "val_loss": 0.693730673789978, "val_acc": 48.0}
{"epoch": 37, "training_loss": 0.6972604990005493, "training_acc": 54.0, "val_loss": 0.8073955845832824, "val_acc": 52.0}
{"epoch": 38, "training_loss": 0.9327539396286011, "training_acc": 53.0, "val_loss": 1.1078651332855225, "val_acc": 48.0}
