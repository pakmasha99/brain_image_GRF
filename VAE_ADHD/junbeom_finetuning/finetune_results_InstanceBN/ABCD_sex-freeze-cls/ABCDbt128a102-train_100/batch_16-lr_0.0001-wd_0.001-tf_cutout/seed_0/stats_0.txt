"main_modify.py --pretrained_path /scratch/connectome/dyhan316/VAE_ADHD/barlowtwins/pretrain_results/ABCDbt128a102.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option BT_org --learning_rate 1e-4 --batch_size 16 --weight_decay 1e-3 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 0.6930591917037964, "training_acc": 52.0, "val_loss": 0.6881514239311218, "val_acc": 56.0}
{"epoch": 1, "training_loss": 0.6926307892799377, "training_acc": 52.0, "val_loss": 0.6874862623214721, "val_acc": 56.0}
{"epoch": 2, "training_loss": 0.6926999235153198, "training_acc": 52.0, "val_loss": 0.6875799512863159, "val_acc": 56.0}
{"epoch": 3, "training_loss": 0.6926236724853516, "training_acc": 52.0, "val_loss": 0.6862013387680054, "val_acc": 56.0}
{"epoch": 4, "training_loss": 0.6924464774131774, "training_acc": 52.0, "val_loss": 0.6871346616744995, "val_acc": 56.0}
{"epoch": 5, "training_loss": 0.6922626638412476, "training_acc": 52.0, "val_loss": 0.6866440916061402, "val_acc": 56.0}
{"epoch": 6, "training_loss": 0.6921452379226685, "training_acc": 52.0, "val_loss": 0.6866528248786926, "val_acc": 56.0}
{"epoch": 7, "training_loss": 0.692697057723999, "training_acc": 52.0, "val_loss": 0.6875121760368347, "val_acc": 56.0}
{"epoch": 8, "training_loss": 0.692797749042511, "training_acc": 52.0, "val_loss": 0.6868063378334045, "val_acc": 56.0}
{"epoch": 9, "training_loss": 0.6924607634544373, "training_acc": 52.0, "val_loss": 0.6878396201133729, "val_acc": 56.0}
{"epoch": 10, "training_loss": 0.692192199230194, "training_acc": 52.0, "val_loss": 0.6901043701171875, "val_acc": 56.0}
{"epoch": 11, "training_loss": 0.6926912021636963, "training_acc": 55.0, "val_loss": 0.6894059181213379, "val_acc": 56.0}
{"epoch": 12, "training_loss": 0.6941515207290649, "training_acc": 52.0, "val_loss": 0.6862972664833069, "val_acc": 56.0}
{"epoch": 13, "training_loss": 0.6923402905464172, "training_acc": 52.0, "val_loss": 0.6860058665275574, "val_acc": 56.0}
{"epoch": 14, "training_loss": 0.6927300548553467, "training_acc": 52.0, "val_loss": 0.6854071760177612, "val_acc": 56.0}
{"epoch": 15, "training_loss": 0.6924523901939392, "training_acc": 52.0, "val_loss": 0.6855508017539979, "val_acc": 56.0}
{"epoch": 16, "training_loss": 0.6935681295394898, "training_acc": 52.0, "val_loss": 0.684661967754364, "val_acc": 56.0}
{"epoch": 17, "training_loss": 0.6924991655349731, "training_acc": 52.0, "val_loss": 0.6856694912910462, "val_acc": 56.0}
{"epoch": 18, "training_loss": 0.6920116353034973, "training_acc": 52.0, "val_loss": 0.6875921845436096, "val_acc": 56.0}
{"epoch": 19, "training_loss": 0.6925797939300538, "training_acc": 52.0, "val_loss": 0.6901190185546875, "val_acc": 56.0}
{"epoch": 20, "training_loss": 0.692253794670105, "training_acc": 53.0, "val_loss": 0.6897501707077026, "val_acc": 56.0}
{"epoch": 21, "training_loss": 0.6922564649581909, "training_acc": 52.0, "val_loss": 0.6893116974830628, "val_acc": 56.0}
{"epoch": 22, "training_loss": 0.6932095241546631, "training_acc": 52.0, "val_loss": 0.6878449702262879, "val_acc": 56.0}
{"epoch": 23, "training_loss": 0.6919160771369934, "training_acc": 52.0, "val_loss": 0.6878591799736022, "val_acc": 56.0}
{"epoch": 24, "training_loss": 0.6926692771911621, "training_acc": 52.0, "val_loss": 0.6862967801094055, "val_acc": 56.0}
{"epoch": 25, "training_loss": 0.691803297996521, "training_acc": 52.0, "val_loss": 0.6869524216651917, "val_acc": 56.0}
{"epoch": 26, "training_loss": 0.6922198247909546, "training_acc": 52.0, "val_loss": 0.687028214931488, "val_acc": 56.0}
{"epoch": 27, "training_loss": 0.6924959707260132, "training_acc": 52.0, "val_loss": 0.6878706502914429, "val_acc": 56.0}
{"epoch": 28, "training_loss": 0.6926748323440551, "training_acc": 52.0, "val_loss": 0.6880982995033265, "val_acc": 56.0}
{"epoch": 29, "training_loss": 0.6921520519256592, "training_acc": 52.0, "val_loss": 0.6869999718666077, "val_acc": 56.0}
{"epoch": 30, "training_loss": 0.6932016825675964, "training_acc": 52.0, "val_loss": 0.6850014352798461, "val_acc": 56.0}
{"epoch": 31, "training_loss": 0.6929933071136475, "training_acc": 52.0, "val_loss": 0.684664876461029, "val_acc": 56.0}
{"epoch": 32, "training_loss": 0.6935570573806763, "training_acc": 52.0, "val_loss": 0.6840983510017395, "val_acc": 56.0}
{"epoch": 33, "training_loss": 0.694705159664154, "training_acc": 52.0, "val_loss": 0.6841034603118896, "val_acc": 56.0}
{"epoch": 34, "training_loss": 0.6936173844337463, "training_acc": 52.0, "val_loss": 0.6847471618652343, "val_acc": 56.0}
{"epoch": 35, "training_loss": 0.6926504826545715, "training_acc": 52.0, "val_loss": 0.6866840314865112, "val_acc": 56.0}
{"epoch": 36, "training_loss": 0.6921091318130493, "training_acc": 52.0, "val_loss": 0.6873223757743836, "val_acc": 56.0}
{"epoch": 37, "training_loss": 0.6916707706451416, "training_acc": 52.0, "val_loss": 0.6870012259483338, "val_acc": 56.0}
{"epoch": 38, "training_loss": 0.6925619459152221, "training_acc": 52.0, "val_loss": 0.6874762082099914, "val_acc": 56.0}
{"epoch": 39, "training_loss": 0.6921562266349792, "training_acc": 52.0, "val_loss": 0.6879029178619385, "val_acc": 56.0}
{"epoch": 40, "training_loss": 0.6923530769348144, "training_acc": 52.0, "val_loss": 0.6893050312995911, "val_acc": 56.0}
{"epoch": 41, "training_loss": 0.6918538856506348, "training_acc": 52.0, "val_loss": 0.6888799452781678, "val_acc": 56.0}
{"epoch": 42, "training_loss": 0.6916872358322144, "training_acc": 52.0, "val_loss": 0.6884315514564514, "val_acc": 56.0}
{"epoch": 43, "training_loss": 0.6927034330368042, "training_acc": 52.0, "val_loss": 0.6881560158729553, "val_acc": 56.0}
{"epoch": 44, "training_loss": 0.6926586771011353, "training_acc": 54.0, "val_loss": 0.6899999809265137, "val_acc": 56.0}
{"epoch": 45, "training_loss": 0.6921673560142517, "training_acc": 52.0, "val_loss": 0.6897344970703125, "val_acc": 56.0}
{"epoch": 46, "training_loss": 0.6922830104827881, "training_acc": 52.0, "val_loss": 0.6889791226387024, "val_acc": 56.0}
{"epoch": 47, "training_loss": 0.6916916251182557, "training_acc": 52.0, "val_loss": 0.687697308063507, "val_acc": 56.0}
{"epoch": 48, "training_loss": 0.6918606925010681, "training_acc": 52.0, "val_loss": 0.6867789077758789, "val_acc": 56.0}
{"epoch": 49, "training_loss": 0.6919843244552613, "training_acc": 52.0, "val_loss": 0.6873419284820557, "val_acc": 56.0}
{"epoch": 50, "training_loss": 0.6914898252487183, "training_acc": 52.0, "val_loss": 0.6893944883346558, "val_acc": 56.0}
{"epoch": 51, "training_loss": 0.6919066405296326, "training_acc": 58.0, "val_loss": 0.6914308619499206, "val_acc": 64.0}
