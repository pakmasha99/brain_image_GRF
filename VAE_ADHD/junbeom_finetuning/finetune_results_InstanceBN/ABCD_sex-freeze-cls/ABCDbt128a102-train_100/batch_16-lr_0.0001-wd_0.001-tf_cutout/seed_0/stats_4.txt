"main_modify.py --pretrained_path /scratch/connectome/dyhan316/VAE_ADHD/barlowtwins/pretrain_results/ABCDbt128a102.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option BT_org --learning_rate 1e-4 --batch_size 16 --weight_decay 1e-3 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 0.6934940481185913, "training_acc": 47.0, "val_loss": 0.6932228207588196, "val_acc": 52.0}
{"epoch": 1, "training_loss": 0.6914036011695862, "training_acc": 53.0, "val_loss": 0.69312912940979, "val_acc": 52.0}
{"epoch": 2, "training_loss": 0.6940268754959107, "training_acc": 53.0, "val_loss": 0.694008252620697, "val_acc": 52.0}
{"epoch": 3, "training_loss": 0.6928506803512573, "training_acc": 53.0, "val_loss": 0.6940929746627807, "val_acc": 52.0}
{"epoch": 4, "training_loss": 0.6910238599777222, "training_acc": 53.0, "val_loss": 0.693118405342102, "val_acc": 52.0}
{"epoch": 5, "training_loss": 0.6905411434173584, "training_acc": 53.0, "val_loss": 0.6929736089706421, "val_acc": 52.0}
{"epoch": 6, "training_loss": 0.6919081163406372, "training_acc": 53.0, "val_loss": 0.6930910301208496, "val_acc": 52.0}
{"epoch": 7, "training_loss": 0.6921243739128112, "training_acc": 53.0, "val_loss": 0.6929999923706055, "val_acc": 52.0}
{"epoch": 8, "training_loss": 0.692430534362793, "training_acc": 53.0, "val_loss": 0.692963354587555, "val_acc": 52.0}
{"epoch": 9, "training_loss": 0.6921085810661316, "training_acc": 53.0, "val_loss": 0.6933545136451721, "val_acc": 56.0}
{"epoch": 10, "training_loss": 0.6920033049583435, "training_acc": 53.0, "val_loss": 0.6929869365692138, "val_acc": 52.0}
{"epoch": 11, "training_loss": 0.6917665100097656, "training_acc": 53.0, "val_loss": 0.692918393611908, "val_acc": 52.0}
{"epoch": 12, "training_loss": 0.6910956192016602, "training_acc": 53.0, "val_loss": 0.692928535938263, "val_acc": 52.0}
{"epoch": 13, "training_loss": 0.6908235692977905, "training_acc": 53.0, "val_loss": 0.6932808041572571, "val_acc": 52.0}
{"epoch": 14, "training_loss": 0.6919424629211426, "training_acc": 53.0, "val_loss": 0.6940939140319824, "val_acc": 52.0}
{"epoch": 15, "training_loss": 0.6908559656143188, "training_acc": 53.0, "val_loss": 0.693783769607544, "val_acc": 52.0}
{"epoch": 16, "training_loss": 0.6911098098754883, "training_acc": 53.0, "val_loss": 0.6935041308403015, "val_acc": 52.0}
{"epoch": 17, "training_loss": 0.6922690272331238, "training_acc": 53.0, "val_loss": 0.6936967921257019, "val_acc": 52.0}
{"epoch": 18, "training_loss": 0.6918389391899109, "training_acc": 53.0, "val_loss": 0.6935532784461975, "val_acc": 52.0}
{"epoch": 19, "training_loss": 0.6906804132461548, "training_acc": 53.0, "val_loss": 0.6930798029899597, "val_acc": 52.0}
{"epoch": 20, "training_loss": 0.6924658846855164, "training_acc": 53.0, "val_loss": 0.6928773164749146, "val_acc": 52.0}
{"epoch": 21, "training_loss": 0.6920128417015076, "training_acc": 53.0, "val_loss": 0.693463900089264, "val_acc": 52.0}
{"epoch": 22, "training_loss": 0.6910396862030029, "training_acc": 53.0, "val_loss": 0.694144356250763, "val_acc": 52.0}
{"epoch": 23, "training_loss": 0.694069709777832, "training_acc": 53.0, "val_loss": 0.6960901713371277, "val_acc": 52.0}
{"epoch": 24, "training_loss": 0.6929611635208129, "training_acc": 53.0, "val_loss": 0.6954596281051636, "val_acc": 52.0}
{"epoch": 25, "training_loss": 0.692362220287323, "training_acc": 53.0, "val_loss": 0.6942679905891418, "val_acc": 52.0}
{"epoch": 26, "training_loss": 0.6913255643844605, "training_acc": 53.0, "val_loss": 0.6935891819000244, "val_acc": 52.0}
{"epoch": 27, "training_loss": 0.6927012538909912, "training_acc": 53.0, "val_loss": 0.6938590788841248, "val_acc": 52.0}
{"epoch": 28, "training_loss": 0.6915799713134766, "training_acc": 53.0, "val_loss": 0.6939161252975464, "val_acc": 52.0}
{"epoch": 29, "training_loss": 0.6912662053108215, "training_acc": 53.0, "val_loss": 0.6937138056755066, "val_acc": 52.0}
{"epoch": 30, "training_loss": 0.6916424417495728, "training_acc": 53.0, "val_loss": 0.6943181300163269, "val_acc": 52.0}
{"epoch": 31, "training_loss": 0.6915734815597534, "training_acc": 53.0, "val_loss": 0.6939854550361634, "val_acc": 52.0}
{"epoch": 32, "training_loss": 0.69175377368927, "training_acc": 53.0, "val_loss": 0.6943115305900573, "val_acc": 52.0}
{"epoch": 33, "training_loss": 0.6917685747146607, "training_acc": 53.0, "val_loss": 0.6947665071487427, "val_acc": 52.0}
{"epoch": 34, "training_loss": 0.6919864511489868, "training_acc": 53.0, "val_loss": 0.6936664199829101, "val_acc": 52.0}
{"epoch": 35, "training_loss": 0.6912074637413025, "training_acc": 53.0, "val_loss": 0.6928676104545594, "val_acc": 52.0}
{"epoch": 36, "training_loss": 0.6905120706558228, "training_acc": 53.0, "val_loss": 0.692797703742981, "val_acc": 52.0}
{"epoch": 37, "training_loss": 0.6913875007629394, "training_acc": 53.0, "val_loss": 0.692811131477356, "val_acc": 52.0}
{"epoch": 38, "training_loss": 0.6914896821975708, "training_acc": 53.0, "val_loss": 0.6930217695236206, "val_acc": 52.0}
{"epoch": 39, "training_loss": 0.692377564907074, "training_acc": 52.0, "val_loss": 0.6931629085540771, "val_acc": 56.0}
{"epoch": 40, "training_loss": 0.6916050839424134, "training_acc": 53.0, "val_loss": 0.6929061198234558, "val_acc": 52.0}
{"epoch": 41, "training_loss": 0.6911297512054443, "training_acc": 53.0, "val_loss": 0.6927971625328064, "val_acc": 52.0}
{"epoch": 42, "training_loss": 0.6906330108642578, "training_acc": 53.0, "val_loss": 0.6930259799957276, "val_acc": 52.0}
{"epoch": 43, "training_loss": 0.690847053527832, "training_acc": 53.0, "val_loss": 0.6934155392646789, "val_acc": 52.0}
{"epoch": 44, "training_loss": 0.6908585619926453, "training_acc": 53.0, "val_loss": 0.6935058999061584, "val_acc": 52.0}
{"epoch": 45, "training_loss": 0.692327082157135, "training_acc": 53.0, "val_loss": 0.6947034573554993, "val_acc": 52.0}
{"epoch": 46, "training_loss": 0.691447777748108, "training_acc": 53.0, "val_loss": 0.69440349817276, "val_acc": 52.0}
{"epoch": 47, "training_loss": 0.6913867902755737, "training_acc": 53.0, "val_loss": 0.6932040047645569, "val_acc": 52.0}
{"epoch": 48, "training_loss": 0.6902576923370362, "training_acc": 53.0, "val_loss": 0.6929198479652405, "val_acc": 52.0}
{"epoch": 49, "training_loss": 0.6909370803833008, "training_acc": 53.0, "val_loss": 0.6927314686775208, "val_acc": 52.0}
{"epoch": 50, "training_loss": 0.6908555102348327, "training_acc": 53.0, "val_loss": 0.6927177143096924, "val_acc": 52.0}
{"epoch": 51, "training_loss": 0.6908495473861694, "training_acc": 53.0, "val_loss": 0.6927218556404113, "val_acc": 52.0}
{"epoch": 52, "training_loss": 0.6907526683807373, "training_acc": 53.0, "val_loss": 0.6927140879631043, "val_acc": 52.0}
{"epoch": 53, "training_loss": 0.6904702615737915, "training_acc": 53.0, "val_loss": 0.6927875542640686, "val_acc": 52.0}
{"epoch": 54, "training_loss": 0.6913728737831115, "training_acc": 53.0, "val_loss": 0.6927133560180664, "val_acc": 52.0}
{"epoch": 55, "training_loss": 0.6906071305274963, "training_acc": 53.0, "val_loss": 0.6931774735450744, "val_acc": 52.0}
{"epoch": 56, "training_loss": 0.6916980791091919, "training_acc": 53.0, "val_loss": 0.6934809589385986, "val_acc": 52.0}
{"epoch": 57, "training_loss": 0.6921739339828491, "training_acc": 53.0, "val_loss": 0.693883945941925, "val_acc": 52.0}
{"epoch": 58, "training_loss": 0.6908112788200378, "training_acc": 53.0, "val_loss": 0.6932601475715637, "val_acc": 52.0}
{"epoch": 59, "training_loss": 0.6908500289916992, "training_acc": 53.0, "val_loss": 0.6929296731948853, "val_acc": 52.0}
{"epoch": 60, "training_loss": 0.6905793380737305, "training_acc": 53.0, "val_loss": 0.6931361818313598, "val_acc": 52.0}
{"epoch": 61, "training_loss": 0.6918751406669617, "training_acc": 53.0, "val_loss": 0.6926958060264587, "val_acc": 52.0}
{"epoch": 62, "training_loss": 0.6911618113517761, "training_acc": 53.0, "val_loss": 0.6926517295837402, "val_acc": 52.0}
{"epoch": 63, "training_loss": 0.6909142398834228, "training_acc": 53.0, "val_loss": 0.6926654815673828, "val_acc": 52.0}
{"epoch": 64, "training_loss": 0.6907065224647522, "training_acc": 53.0, "val_loss": 0.6926934909820557, "val_acc": 52.0}
{"epoch": 65, "training_loss": 0.6902159881591797, "training_acc": 53.0, "val_loss": 0.6928312706947327, "val_acc": 52.0}
{"epoch": 66, "training_loss": 0.6903346967697144, "training_acc": 53.0, "val_loss": 0.6931460952758789, "val_acc": 52.0}
{"epoch": 67, "training_loss": 0.6935285329818726, "training_acc": 53.0, "val_loss": 0.6947174882888794, "val_acc": 52.0}
{"epoch": 68, "training_loss": 0.6920162868499756, "training_acc": 53.0, "val_loss": 0.6941539525985718, "val_acc": 52.0}
{"epoch": 69, "training_loss": 0.6904203033447266, "training_acc": 53.0, "val_loss": 0.6929848957061767, "val_acc": 52.0}
{"epoch": 70, "training_loss": 0.6898717498779297, "training_acc": 53.0, "val_loss": 0.6926448035240174, "val_acc": 52.0}
{"epoch": 71, "training_loss": 0.6891346120834351, "training_acc": 53.0, "val_loss": 0.6928988289833069, "val_acc": 52.0}
{"epoch": 72, "training_loss": 0.6945708608627319, "training_acc": 43.0, "val_loss": 0.6939644718170166, "val_acc": 48.0}
{"epoch": 73, "training_loss": 0.6921068835258484, "training_acc": 55.0, "val_loss": 0.6930889582633972, "val_acc": 52.0}
{"epoch": 74, "training_loss": 0.6916927909851074, "training_acc": 53.0, "val_loss": 0.6926652956008911, "val_acc": 52.0}
{"epoch": 75, "training_loss": 0.690124626159668, "training_acc": 53.0, "val_loss": 0.6933005571365356, "val_acc": 52.0}
{"epoch": 76, "training_loss": 0.6906822395324707, "training_acc": 53.0, "val_loss": 0.6930548429489136, "val_acc": 52.0}
{"epoch": 77, "training_loss": 0.6907830262184143, "training_acc": 53.0, "val_loss": 0.6928173804283142, "val_acc": 52.0}
{"epoch": 78, "training_loss": 0.6904203987121582, "training_acc": 53.0, "val_loss": 0.6925911951065064, "val_acc": 52.0}
{"epoch": 79, "training_loss": 0.6905533027648926, "training_acc": 53.0, "val_loss": 0.6926998233795166, "val_acc": 52.0}
{"epoch": 80, "training_loss": 0.6908343267440796, "training_acc": 53.0, "val_loss": 0.6929307103157043, "val_acc": 52.0}
{"epoch": 81, "training_loss": 0.6932378292083741, "training_acc": 47.0, "val_loss": 0.6935275220870971, "val_acc": 44.0}
{"epoch": 82, "training_loss": 0.6926138782501221, "training_acc": 50.0, "val_loss": 0.6926909279823303, "val_acc": 52.0}
{"epoch": 83, "training_loss": 0.6924054312705994, "training_acc": 53.0, "val_loss": 0.6926033401489258, "val_acc": 52.0}
{"epoch": 84, "training_loss": 0.6902997493743896, "training_acc": 53.0, "val_loss": 0.6926473808288575, "val_acc": 52.0}
{"epoch": 85, "training_loss": 0.690562252998352, "training_acc": 53.0, "val_loss": 0.6925784420967102, "val_acc": 52.0}
{"epoch": 86, "training_loss": 0.6906234407424927, "training_acc": 53.0, "val_loss": 0.692555136680603, "val_acc": 52.0}
{"epoch": 87, "training_loss": 0.6900816416740417, "training_acc": 53.0, "val_loss": 0.6925706553459168, "val_acc": 52.0}
{"epoch": 88, "training_loss": 0.6915315937995911, "training_acc": 53.0, "val_loss": 0.6926624584197998, "val_acc": 52.0}
{"epoch": 89, "training_loss": 0.6903840017318725, "training_acc": 53.0, "val_loss": 0.692519462108612, "val_acc": 52.0}
{"epoch": 90, "training_loss": 0.6906466865539551, "training_acc": 53.0, "val_loss": 0.6925114059448242, "val_acc": 52.0}
{"epoch": 91, "training_loss": 0.6904338788986206, "training_acc": 53.0, "val_loss": 0.6925507521629334, "val_acc": 52.0}
{"epoch": 92, "training_loss": 0.6901131868362427, "training_acc": 53.0, "val_loss": 0.6926987433433532, "val_acc": 52.0}
{"epoch": 93, "training_loss": 0.6902951884269715, "training_acc": 53.0, "val_loss": 0.6928515768051148, "val_acc": 52.0}
{"epoch": 94, "training_loss": 0.6905902862548828, "training_acc": 53.0, "val_loss": 0.6929361176490784, "val_acc": 52.0}
{"epoch": 95, "training_loss": 0.6907155442237854, "training_acc": 53.0, "val_loss": 0.6928002452850341, "val_acc": 52.0}
{"epoch": 96, "training_loss": 0.690385365486145, "training_acc": 53.0, "val_loss": 0.6930528378486633, "val_acc": 52.0}
{"epoch": 97, "training_loss": 0.691057767868042, "training_acc": 53.0, "val_loss": 0.6926057457923889, "val_acc": 52.0}
{"epoch": 98, "training_loss": 0.6905204916000366, "training_acc": 53.0, "val_loss": 0.6926776766777039, "val_acc": 52.0}
{"epoch": 99, "training_loss": 0.6907916569709778, "training_acc": 53.0, "val_loss": 0.6924871468544006, "val_acc": 52.0}
