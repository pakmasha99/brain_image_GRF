"main_modify.py --pretrained_path /scratch/connectome/dyhan316/VAE_ADHD/barlowtwins/pretrain_results/ABCDbt128a102.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option BT_org --learning_rate 1e-4 --batch_size 16 --weight_decay 1e-3 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 0.6972098302841186, "training_acc": 37.0, "val_loss": 0.6910834050178528, "val_acc": 60.0}
{"epoch": 1, "training_loss": 0.6933635902404786, "training_acc": 53.0, "val_loss": 0.6907647013664245, "val_acc": 52.0}
{"epoch": 2, "training_loss": 0.6931771945953369, "training_acc": 53.0, "val_loss": 0.6905137634277344, "val_acc": 52.0}
{"epoch": 3, "training_loss": 0.6920282125473023, "training_acc": 53.0, "val_loss": 0.6907399106025696, "val_acc": 52.0}
{"epoch": 4, "training_loss": 0.6919462442398071, "training_acc": 53.0, "val_loss": 0.6910609555244446, "val_acc": 52.0}
{"epoch": 5, "training_loss": 0.6917838811874389, "training_acc": 53.0, "val_loss": 0.6911067891120911, "val_acc": 52.0}
{"epoch": 6, "training_loss": 0.6915939593315125, "training_acc": 53.0, "val_loss": 0.691579327583313, "val_acc": 52.0}
{"epoch": 7, "training_loss": 0.6920030975341797, "training_acc": 53.0, "val_loss": 0.6920943450927735, "val_acc": 52.0}
{"epoch": 8, "training_loss": 0.6920935392379761, "training_acc": 53.0, "val_loss": 0.6915726137161254, "val_acc": 52.0}
{"epoch": 9, "training_loss": 0.69269846200943, "training_acc": 53.0, "val_loss": 0.6920197415351867, "val_acc": 52.0}
{"epoch": 10, "training_loss": 0.6914406442642211, "training_acc": 53.0, "val_loss": 0.6911688709259033, "val_acc": 52.0}
{"epoch": 11, "training_loss": 0.6912586569786072, "training_acc": 53.0, "val_loss": 0.6907862138748169, "val_acc": 52.0}
{"epoch": 12, "training_loss": 0.691916069984436, "training_acc": 53.0, "val_loss": 0.6905283808708191, "val_acc": 52.0}
{"epoch": 13, "training_loss": 0.694455976486206, "training_acc": 53.0, "val_loss": 0.6907954096794129, "val_acc": 52.0}
{"epoch": 14, "training_loss": 0.691723256111145, "training_acc": 53.0, "val_loss": 0.6905147910118103, "val_acc": 52.0}
{"epoch": 15, "training_loss": 0.6916582345962524, "training_acc": 53.0, "val_loss": 0.6905068469047546, "val_acc": 52.0}
{"epoch": 16, "training_loss": 0.6927297568321228, "training_acc": 53.0, "val_loss": 0.6908919167518616, "val_acc": 52.0}
{"epoch": 17, "training_loss": 0.6918632912635804, "training_acc": 53.0, "val_loss": 0.6910863924026489, "val_acc": 52.0}
{"epoch": 18, "training_loss": 0.691616313457489, "training_acc": 53.0, "val_loss": 0.6909017491340638, "val_acc": 52.0}
{"epoch": 19, "training_loss": 0.691265094280243, "training_acc": 53.0, "val_loss": 0.6910298943519593, "val_acc": 52.0}
{"epoch": 20, "training_loss": 0.6913399410247802, "training_acc": 53.0, "val_loss": 0.691003086566925, "val_acc": 52.0}
{"epoch": 21, "training_loss": 0.6912503004074096, "training_acc": 53.0, "val_loss": 0.6909716200828552, "val_acc": 52.0}
{"epoch": 22, "training_loss": 0.6913135886192322, "training_acc": 53.0, "val_loss": 0.6918388724327087, "val_acc": 52.0}
{"epoch": 23, "training_loss": 0.6940044450759888, "training_acc": 53.0, "val_loss": 0.692324984073639, "val_acc": 52.0}
{"epoch": 24, "training_loss": 0.6921573281288147, "training_acc": 53.0, "val_loss": 0.6908407616615295, "val_acc": 52.0}
{"epoch": 25, "training_loss": 0.6915666961669922, "training_acc": 53.0, "val_loss": 0.6904959511756897, "val_acc": 52.0}
{"epoch": 26, "training_loss": 0.6919597864151001, "training_acc": 53.0, "val_loss": 0.6905329036712646, "val_acc": 52.0}
{"epoch": 27, "training_loss": 0.6923136496543885, "training_acc": 53.0, "val_loss": 0.6905347394943238, "val_acc": 52.0}
{"epoch": 28, "training_loss": 0.6912275552749634, "training_acc": 53.0, "val_loss": 0.69054044008255, "val_acc": 52.0}
{"epoch": 29, "training_loss": 0.6909130334854126, "training_acc": 53.0, "val_loss": 0.6910570406913757, "val_acc": 52.0}
{"epoch": 30, "training_loss": 0.6926105976104736, "training_acc": 53.0, "val_loss": 0.6921572828292847, "val_acc": 52.0}
{"epoch": 31, "training_loss": 0.691433744430542, "training_acc": 53.0, "val_loss": 0.6916545152664184, "val_acc": 52.0}
{"epoch": 32, "training_loss": 0.6918974828720093, "training_acc": 53.0, "val_loss": 0.6916354298591614, "val_acc": 52.0}
{"epoch": 33, "training_loss": 0.6930009889602661, "training_acc": 53.0, "val_loss": 0.6906466913223267, "val_acc": 52.0}
{"epoch": 34, "training_loss": 0.6912441897392273, "training_acc": 53.0, "val_loss": 0.6905127763748169, "val_acc": 52.0}
{"epoch": 35, "training_loss": 0.6916400957107544, "training_acc": 53.0, "val_loss": 0.6905839562416076, "val_acc": 52.0}
{"epoch": 36, "training_loss": 0.6942256641387939, "training_acc": 58.0, "val_loss": 0.6913780832290649, "val_acc": 60.0}
{"epoch": 37, "training_loss": 0.6930189275741577, "training_acc": 49.0, "val_loss": 0.6907373738288879, "val_acc": 52.0}
{"epoch": 38, "training_loss": 0.6918812084197998, "training_acc": 53.0, "val_loss": 0.6905549693107605, "val_acc": 52.0}
{"epoch": 39, "training_loss": 0.6916630983352661, "training_acc": 53.0, "val_loss": 0.6905020570755005, "val_acc": 52.0}
{"epoch": 40, "training_loss": 0.6927298879623414, "training_acc": 53.0, "val_loss": 0.6905624127388, "val_acc": 52.0}
{"epoch": 41, "training_loss": 0.6911276888847351, "training_acc": 53.0, "val_loss": 0.6904908537864685, "val_acc": 52.0}
{"epoch": 42, "training_loss": 0.6914079236984253, "training_acc": 53.0, "val_loss": 0.6904837155342102, "val_acc": 52.0}
{"epoch": 43, "training_loss": 0.6934018468856812, "training_acc": 53.0, "val_loss": 0.6907746744155884, "val_acc": 52.0}
{"epoch": 44, "training_loss": 0.6910276222229004, "training_acc": 53.0, "val_loss": 0.6905219197273255, "val_acc": 52.0}
{"epoch": 45, "training_loss": 0.6917128849029541, "training_acc": 53.0, "val_loss": 0.690491898059845, "val_acc": 52.0}
{"epoch": 46, "training_loss": 0.6921780014038086, "training_acc": 53.0, "val_loss": 0.6907319021224976, "val_acc": 52.0}
{"epoch": 47, "training_loss": 0.6905783343315125, "training_acc": 53.0, "val_loss": 0.6909144783020019, "val_acc": 52.0}
{"epoch": 48, "training_loss": 0.6928646469116211, "training_acc": 53.0, "val_loss": 0.6914886736869812, "val_acc": 52.0}
{"epoch": 49, "training_loss": 0.6912860345840454, "training_acc": 53.0, "val_loss": 0.6905838894844055, "val_acc": 52.0}
{"epoch": 50, "training_loss": 0.6905917167663574, "training_acc": 53.0, "val_loss": 0.690491099357605, "val_acc": 52.0}
{"epoch": 51, "training_loss": 0.6911231803894043, "training_acc": 53.0, "val_loss": 0.6906194806098938, "val_acc": 52.0}
{"epoch": 52, "training_loss": 0.6919065809249878, "training_acc": 53.0, "val_loss": 0.6905008697509766, "val_acc": 52.0}
{"epoch": 53, "training_loss": 0.6907444763183593, "training_acc": 53.0, "val_loss": 0.6905075001716614, "val_acc": 52.0}
{"epoch": 54, "training_loss": 0.6912922430038452, "training_acc": 53.0, "val_loss": 0.6904901981353759, "val_acc": 52.0}
{"epoch": 55, "training_loss": 0.6907657885551453, "training_acc": 53.0, "val_loss": 0.6905853176116943, "val_acc": 52.0}
{"epoch": 56, "training_loss": 0.6912981224060059, "training_acc": 53.0, "val_loss": 0.6905010557174682, "val_acc": 52.0}
{"epoch": 57, "training_loss": 0.6911600160598755, "training_acc": 53.0, "val_loss": 0.6904973149299621, "val_acc": 52.0}
{"epoch": 58, "training_loss": 0.6921062874794006, "training_acc": 53.0, "val_loss": 0.6905223393440246, "val_acc": 52.0}
{"epoch": 59, "training_loss": 0.6923099970817566, "training_acc": 53.0, "val_loss": 0.6904898452758789, "val_acc": 52.0}
{"epoch": 60, "training_loss": 0.6925941777229309, "training_acc": 53.0, "val_loss": 0.6907620167732239, "val_acc": 52.0}
{"epoch": 61, "training_loss": 0.6918282461166382, "training_acc": 53.0, "val_loss": 0.690807716846466, "val_acc": 52.0}
