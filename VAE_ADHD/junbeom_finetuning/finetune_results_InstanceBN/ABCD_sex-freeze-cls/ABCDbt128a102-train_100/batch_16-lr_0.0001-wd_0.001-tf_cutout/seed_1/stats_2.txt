"main_modify.py --pretrained_path /scratch/connectome/dyhan316/VAE_ADHD/barlowtwins/pretrain_results/ABCDbt128a102.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 1 --task ABCD_sex --input_option BT_org --learning_rate 1e-4 --batch_size 16 --weight_decay 1e-3 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 0.6960980844497681, "training_acc": 47.0, "val_loss": 0.6937549304962158, "val_acc": 48.0}
{"epoch": 1, "training_loss": 0.6914995574951172, "training_acc": 56.0, "val_loss": 0.6925770044326782, "val_acc": 52.0}
{"epoch": 2, "training_loss": 0.691924774646759, "training_acc": 53.0, "val_loss": 0.6933224391937256, "val_acc": 52.0}
{"epoch": 3, "training_loss": 0.6907896852493286, "training_acc": 53.0, "val_loss": 0.6937714838981628, "val_acc": 52.0}
{"epoch": 4, "training_loss": 0.6914706087112427, "training_acc": 53.0, "val_loss": 0.6938075375556946, "val_acc": 52.0}
{"epoch": 5, "training_loss": 0.6916750574111938, "training_acc": 53.0, "val_loss": 0.6929009485244751, "val_acc": 52.0}
{"epoch": 6, "training_loss": 0.6915640258789062, "training_acc": 53.0, "val_loss": 0.6932613492012024, "val_acc": 52.0}
{"epoch": 7, "training_loss": 0.6913815665245057, "training_acc": 53.0, "val_loss": 0.6924842953681946, "val_acc": 52.0}
{"epoch": 8, "training_loss": 0.6909924578666687, "training_acc": 53.0, "val_loss": 0.692471513748169, "val_acc": 52.0}
{"epoch": 9, "training_loss": 0.6910274505615235, "training_acc": 53.0, "val_loss": 0.6924929618835449, "val_acc": 52.0}
{"epoch": 10, "training_loss": 0.6907956266403198, "training_acc": 53.0, "val_loss": 0.6924880146980286, "val_acc": 52.0}
{"epoch": 11, "training_loss": 0.6909485149383545, "training_acc": 53.0, "val_loss": 0.6924723434448242, "val_acc": 52.0}
{"epoch": 12, "training_loss": 0.6903527927398682, "training_acc": 53.0, "val_loss": 0.6924615168571472, "val_acc": 52.0}
{"epoch": 13, "training_loss": 0.690710129737854, "training_acc": 53.0, "val_loss": 0.6925002980232239, "val_acc": 52.0}
{"epoch": 14, "training_loss": 0.6903141593933105, "training_acc": 53.0, "val_loss": 0.6926375532150268, "val_acc": 52.0}
{"epoch": 15, "training_loss": 0.6905799579620361, "training_acc": 53.0, "val_loss": 0.6924934697151184, "val_acc": 52.0}
{"epoch": 16, "training_loss": 0.6909885835647583, "training_acc": 53.0, "val_loss": 0.6924328923225402, "val_acc": 52.0}
{"epoch": 17, "training_loss": 0.6910018849372864, "training_acc": 53.0, "val_loss": 0.6927112126350403, "val_acc": 52.0}
{"epoch": 18, "training_loss": 0.6911612224578857, "training_acc": 53.0, "val_loss": 0.6927201962471008, "val_acc": 52.0}
{"epoch": 19, "training_loss": 0.6911075329780578, "training_acc": 53.0, "val_loss": 0.6929704999923706, "val_acc": 52.0}
{"epoch": 20, "training_loss": 0.6905047655105591, "training_acc": 53.0, "val_loss": 0.6928190159797668, "val_acc": 52.0}
{"epoch": 21, "training_loss": 0.6902956295013428, "training_acc": 53.0, "val_loss": 0.6926024556159973, "val_acc": 52.0}
{"epoch": 22, "training_loss": 0.6906304907798767, "training_acc": 53.0, "val_loss": 0.6925657510757446, "val_acc": 52.0}
{"epoch": 23, "training_loss": 0.6903347826004028, "training_acc": 53.0, "val_loss": 0.692708580493927, "val_acc": 52.0}
{"epoch": 24, "training_loss": 0.6915750598907471, "training_acc": 53.0, "val_loss": 0.6934792399406433, "val_acc": 52.0}
{"epoch": 25, "training_loss": 0.6913227248191833, "training_acc": 53.0, "val_loss": 0.6929572391510009, "val_acc": 52.0}
{"epoch": 26, "training_loss": 0.6902561950683593, "training_acc": 53.0, "val_loss": 0.6933640432357788, "val_acc": 52.0}
{"epoch": 27, "training_loss": 0.6903890061378479, "training_acc": 53.0, "val_loss": 0.6945016884803772, "val_acc": 52.0}
{"epoch": 28, "training_loss": 0.6911492085456848, "training_acc": 53.0, "val_loss": 0.696188039779663, "val_acc": 52.0}
{"epoch": 29, "training_loss": 0.6920032215118408, "training_acc": 53.0, "val_loss": 0.695034658908844, "val_acc": 52.0}
{"epoch": 30, "training_loss": 0.690565242767334, "training_acc": 53.0, "val_loss": 0.6929613208770752, "val_acc": 52.0}
{"epoch": 31, "training_loss": 0.6894181132316589, "training_acc": 53.0, "val_loss": 0.6924110722541809, "val_acc": 52.0}
{"epoch": 32, "training_loss": 0.6905395698547363, "training_acc": 53.0, "val_loss": 0.692315673828125, "val_acc": 52.0}
{"epoch": 33, "training_loss": 0.6901490402221679, "training_acc": 53.0, "val_loss": 0.6927546262741089, "val_acc": 52.0}
{"epoch": 34, "training_loss": 0.6902753758430481, "training_acc": 53.0, "val_loss": 0.6932130837440491, "val_acc": 52.0}
{"epoch": 35, "training_loss": 0.6899860191345215, "training_acc": 53.0, "val_loss": 0.6925811338424682, "val_acc": 52.0}
{"epoch": 36, "training_loss": 0.6903078842163086, "training_acc": 53.0, "val_loss": 0.6925184321403504, "val_acc": 52.0}
{"epoch": 37, "training_loss": 0.6910173988342285, "training_acc": 53.0, "val_loss": 0.6924189496040344, "val_acc": 52.0}
{"epoch": 38, "training_loss": 0.6914170932769775, "training_acc": 53.0, "val_loss": 0.6922636914253235, "val_acc": 52.0}
{"epoch": 39, "training_loss": 0.6902455186843872, "training_acc": 53.0, "val_loss": 0.6922884368896485, "val_acc": 52.0}
{"epoch": 40, "training_loss": 0.6915677213668823, "training_acc": 53.0, "val_loss": 0.6926495456695556, "val_acc": 52.0}
{"epoch": 41, "training_loss": 0.6914342832565308, "training_acc": 53.0, "val_loss": 0.692250280380249, "val_acc": 52.0}
{"epoch": 42, "training_loss": 0.6902206420898438, "training_acc": 53.0, "val_loss": 0.6922780728340149, "val_acc": 52.0}
{"epoch": 43, "training_loss": 0.6897925806045532, "training_acc": 53.0, "val_loss": 0.692375295162201, "val_acc": 52.0}
{"epoch": 44, "training_loss": 0.68991548538208, "training_acc": 53.0, "val_loss": 0.6929409241676331, "val_acc": 52.0}
{"epoch": 45, "training_loss": 0.6907274341583252, "training_acc": 53.0, "val_loss": 0.6928750252723694, "val_acc": 52.0}
{"epoch": 46, "training_loss": 0.6904770994186401, "training_acc": 53.0, "val_loss": 0.6932885384559632, "val_acc": 52.0}
{"epoch": 47, "training_loss": 0.6912337160110473, "training_acc": 53.0, "val_loss": 0.6924481368064881, "val_acc": 52.0}
{"epoch": 48, "training_loss": 0.689921383857727, "training_acc": 53.0, "val_loss": 0.6924245643615723, "val_acc": 52.0}
{"epoch": 49, "training_loss": 0.6899349856376648, "training_acc": 53.0, "val_loss": 0.6922039890289307, "val_acc": 52.0}
{"epoch": 50, "training_loss": 0.689377121925354, "training_acc": 53.0, "val_loss": 0.6922681021690369, "val_acc": 52.0}
{"epoch": 51, "training_loss": 0.6904062032699585, "training_acc": 53.0, "val_loss": 0.6924623227119446, "val_acc": 52.0}
{"epoch": 52, "training_loss": 0.6908029174804687, "training_acc": 54.0, "val_loss": 0.6924165463447571, "val_acc": 52.0}
{"epoch": 53, "training_loss": 0.6919235253334045, "training_acc": 53.0, "val_loss": 0.6922234201431274, "val_acc": 52.0}
{"epoch": 54, "training_loss": 0.6896821403503418, "training_acc": 53.0, "val_loss": 0.6924072360992432, "val_acc": 52.0}
{"epoch": 55, "training_loss": 0.6904714679718018, "training_acc": 53.0, "val_loss": 0.6923284459114075, "val_acc": 52.0}
{"epoch": 56, "training_loss": 0.6915349578857422, "training_acc": 53.0, "val_loss": 0.6922498297691345, "val_acc": 52.0}
{"epoch": 57, "training_loss": 0.6907456254959107, "training_acc": 53.0, "val_loss": 0.6922443866729736, "val_acc": 52.0}
{"epoch": 58, "training_loss": 0.6910662984848023, "training_acc": 53.0, "val_loss": 0.6921405529975891, "val_acc": 52.0}
{"epoch": 59, "training_loss": 0.6903264260292054, "training_acc": 53.0, "val_loss": 0.6921534776687622, "val_acc": 52.0}
{"epoch": 60, "training_loss": 0.6901769757270813, "training_acc": 53.0, "val_loss": 0.6921652722358703, "val_acc": 52.0}
{"epoch": 61, "training_loss": 0.6907514715194703, "training_acc": 53.0, "val_loss": 0.6921112442016601, "val_acc": 52.0}
{"epoch": 62, "training_loss": 0.6903809833526612, "training_acc": 53.0, "val_loss": 0.6925898432731629, "val_acc": 52.0}
{"epoch": 63, "training_loss": 0.6899864649772645, "training_acc": 53.0, "val_loss": 0.6932242822647094, "val_acc": 52.0}
{"epoch": 64, "training_loss": 0.6894920253753662, "training_acc": 53.0, "val_loss": 0.6928932690620422, "val_acc": 52.0}
{"epoch": 65, "training_loss": 0.6906229305267334, "training_acc": 53.0, "val_loss": 0.6924504947662353, "val_acc": 52.0}
{"epoch": 66, "training_loss": 0.6895640993118286, "training_acc": 53.0, "val_loss": 0.6930342268943787, "val_acc": 52.0}
{"epoch": 67, "training_loss": 0.6923052644729615, "training_acc": 53.0, "val_loss": 0.6946981596946716, "val_acc": 52.0}
{"epoch": 68, "training_loss": 0.6913711714744568, "training_acc": 53.0, "val_loss": 0.6947240805625916, "val_acc": 52.0}
{"epoch": 69, "training_loss": 0.6911543321609497, "training_acc": 53.0, "val_loss": 0.69267982006073, "val_acc": 52.0}
{"epoch": 70, "training_loss": 0.6896296501159668, "training_acc": 53.0, "val_loss": 0.6920842099189758, "val_acc": 52.0}
{"epoch": 71, "training_loss": 0.6893210792541504, "training_acc": 53.0, "val_loss": 0.6920103406906128, "val_acc": 52.0}
{"epoch": 72, "training_loss": 0.6911282086372376, "training_acc": 53.0, "val_loss": 0.692117087841034, "val_acc": 52.0}
{"epoch": 73, "training_loss": 0.6903685474395752, "training_acc": 53.0, "val_loss": 0.6922400188446045, "val_acc": 52.0}
{"epoch": 74, "training_loss": 0.6915311193466187, "training_acc": 53.0, "val_loss": 0.6925783252716065, "val_acc": 48.0}
{"epoch": 75, "training_loss": 0.691114182472229, "training_acc": 62.0, "val_loss": 0.6924723196029663, "val_acc": 48.0}
{"epoch": 76, "training_loss": 0.6920108556747436, "training_acc": 53.0, "val_loss": 0.692079312801361, "val_acc": 52.0}
{"epoch": 77, "training_loss": 0.690520396232605, "training_acc": 53.0, "val_loss": 0.6919675922393799, "val_acc": 52.0}
{"epoch": 78, "training_loss": 0.6899527525901794, "training_acc": 53.0, "val_loss": 0.6919868803024292, "val_acc": 52.0}
{"epoch": 79, "training_loss": 0.6903407764434815, "training_acc": 53.0, "val_loss": 0.6920022511482239, "val_acc": 52.0}
{"epoch": 80, "training_loss": 0.6886726427078247, "training_acc": 53.0, "val_loss": 0.6921541905403137, "val_acc": 52.0}
{"epoch": 81, "training_loss": 0.6896777629852295, "training_acc": 53.0, "val_loss": 0.6919893670082092, "val_acc": 52.0}
{"epoch": 82, "training_loss": 0.6889590811729431, "training_acc": 53.0, "val_loss": 0.6919941353797913, "val_acc": 52.0}
{"epoch": 83, "training_loss": 0.6899963712692261, "training_acc": 53.0, "val_loss": 0.6919189381599427, "val_acc": 52.0}
{"epoch": 84, "training_loss": 0.6904005193710328, "training_acc": 53.0, "val_loss": 0.692022111415863, "val_acc": 52.0}
{"epoch": 85, "training_loss": 0.6901140308380127, "training_acc": 53.0, "val_loss": 0.6919052481651307, "val_acc": 52.0}
{"epoch": 86, "training_loss": 0.6905731177330017, "training_acc": 53.0, "val_loss": 0.6923923492431641, "val_acc": 52.0}
{"epoch": 87, "training_loss": 0.689487316608429, "training_acc": 53.0, "val_loss": 0.6924224901199341, "val_acc": 52.0}
{"epoch": 88, "training_loss": 0.6901889657974243, "training_acc": 53.0, "val_loss": 0.6926111960411072, "val_acc": 52.0}
{"epoch": 89, "training_loss": 0.6898929190635681, "training_acc": 53.0, "val_loss": 0.6923236393928528, "val_acc": 52.0}
{"epoch": 90, "training_loss": 0.6899266481399536, "training_acc": 53.0, "val_loss": 0.6931031036376953, "val_acc": 52.0}
{"epoch": 91, "training_loss": 0.6903105258941651, "training_acc": 53.0, "val_loss": 0.6928063821792603, "val_acc": 52.0}
{"epoch": 92, "training_loss": 0.6890756368637085, "training_acc": 53.0, "val_loss": 0.6937228417396546, "val_acc": 52.0}
{"epoch": 93, "training_loss": 0.6900237894058228, "training_acc": 53.0, "val_loss": 0.6937884306907653, "val_acc": 52.0}
{"epoch": 94, "training_loss": 0.6897052955627442, "training_acc": 53.0, "val_loss": 0.6929219508171082, "val_acc": 52.0}
{"epoch": 95, "training_loss": 0.6897015452384949, "training_acc": 53.0, "val_loss": 0.6919560766220093, "val_acc": 52.0}
{"epoch": 96, "training_loss": 0.6894905757904053, "training_acc": 53.0, "val_loss": 0.6918703961372376, "val_acc": 52.0}
{"epoch": 97, "training_loss": 0.6902829432487487, "training_acc": 52.0, "val_loss": 0.6921947240829468, "val_acc": 52.0}
{"epoch": 98, "training_loss": 0.6917723369598389, "training_acc": 56.0, "val_loss": 0.6923150753974915, "val_acc": 48.0}
{"epoch": 99, "training_loss": 0.6901192688941955, "training_acc": 52.0, "val_loss": 0.6918240380287171, "val_acc": 52.0}
