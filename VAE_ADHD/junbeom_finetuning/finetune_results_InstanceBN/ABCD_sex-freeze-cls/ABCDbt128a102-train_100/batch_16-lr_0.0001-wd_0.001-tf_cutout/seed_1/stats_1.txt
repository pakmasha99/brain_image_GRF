"main_modify.py --pretrained_path /scratch/connectome/dyhan316/VAE_ADHD/barlowtwins/pretrain_results/ABCDbt128a102.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 1 --task ABCD_sex --input_option BT_org --learning_rate 1e-4 --batch_size 16 --weight_decay 1e-3 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 0.6931856822967529, "training_acc": 54.0, "val_loss": 0.6924269437789917, "val_acc": 52.0}
{"epoch": 1, "training_loss": 0.6921333742141723, "training_acc": 53.0, "val_loss": 0.6927436828613281, "val_acc": 52.0}
{"epoch": 2, "training_loss": 0.6916430044174194, "training_acc": 53.0, "val_loss": 0.6929450297355652, "val_acc": 52.0}
{"epoch": 3, "training_loss": 0.6918224000930786, "training_acc": 53.0, "val_loss": 0.6930490970611572, "val_acc": 52.0}
{"epoch": 4, "training_loss": 0.6917397141456604, "training_acc": 53.0, "val_loss": 0.6931137013435363, "val_acc": 52.0}
{"epoch": 5, "training_loss": 0.6920418882369995, "training_acc": 53.0, "val_loss": 0.6929454755783081, "val_acc": 52.0}
{"epoch": 6, "training_loss": 0.6922017908096314, "training_acc": 53.0, "val_loss": 0.6924926495552063, "val_acc": 52.0}
{"epoch": 7, "training_loss": 0.6917063140869141, "training_acc": 53.0, "val_loss": 0.6924783730506897, "val_acc": 52.0}
{"epoch": 8, "training_loss": 0.6916296219825745, "training_acc": 53.0, "val_loss": 0.6926553606986999, "val_acc": 52.0}
{"epoch": 9, "training_loss": 0.6919946765899658, "training_acc": 53.0, "val_loss": 0.693552029132843, "val_acc": 52.0}
{"epoch": 10, "training_loss": 0.6917497658729553, "training_acc": 53.0, "val_loss": 0.6932230472564698, "val_acc": 52.0}
{"epoch": 11, "training_loss": 0.6914568042755127, "training_acc": 53.0, "val_loss": 0.6927796888351441, "val_acc": 52.0}
{"epoch": 12, "training_loss": 0.6935213994979859, "training_acc": 53.0, "val_loss": 0.6924247026443482, "val_acc": 52.0}
{"epoch": 13, "training_loss": 0.6937833714485169, "training_acc": 53.0, "val_loss": 0.6928532195091247, "val_acc": 52.0}
{"epoch": 14, "training_loss": 0.6920909643173218, "training_acc": 53.0, "val_loss": 0.6930499649047852, "val_acc": 52.0}
{"epoch": 15, "training_loss": 0.6918400406837464, "training_acc": 53.0, "val_loss": 0.6926442742347717, "val_acc": 52.0}
{"epoch": 16, "training_loss": 0.6909526252746582, "training_acc": 53.0, "val_loss": 0.6924162745475769, "val_acc": 52.0}
{"epoch": 17, "training_loss": 0.6921074986457825, "training_acc": 53.0, "val_loss": 0.6926379513740539, "val_acc": 52.0}
{"epoch": 18, "training_loss": 0.6919818758964539, "training_acc": 53.0, "val_loss": 0.692440996170044, "val_acc": 52.0}
{"epoch": 19, "training_loss": 0.6916057562828064, "training_acc": 53.0, "val_loss": 0.6926707196235656, "val_acc": 52.0}
{"epoch": 20, "training_loss": 0.6915912413597107, "training_acc": 53.0, "val_loss": 0.6925259447097778, "val_acc": 52.0}
{"epoch": 21, "training_loss": 0.6919657754898071, "training_acc": 53.0, "val_loss": 0.6924165177345276, "val_acc": 52.0}
{"epoch": 22, "training_loss": 0.6919773578643799, "training_acc": 53.0, "val_loss": 0.6924477839469909, "val_acc": 52.0}
{"epoch": 23, "training_loss": 0.6913181924819947, "training_acc": 53.0, "val_loss": 0.6924249553680419, "val_acc": 52.0}
{"epoch": 24, "training_loss": 0.6916951131820679, "training_acc": 53.0, "val_loss": 0.6924350452423096, "val_acc": 52.0}
{"epoch": 25, "training_loss": 0.6914673471450805, "training_acc": 53.0, "val_loss": 0.6924385094642639, "val_acc": 52.0}
{"epoch": 26, "training_loss": 0.6914610123634338, "training_acc": 53.0, "val_loss": 0.692480137348175, "val_acc": 52.0}
{"epoch": 27, "training_loss": 0.6934002590179443, "training_acc": 53.0, "val_loss": 0.6928657150268555, "val_acc": 52.0}
{"epoch": 28, "training_loss": 0.6912766909599304, "training_acc": 53.0, "val_loss": 0.6926813149452209, "val_acc": 52.0}
{"epoch": 29, "training_loss": 0.6911976480484009, "training_acc": 53.0, "val_loss": 0.6927023720741272, "val_acc": 52.0}
{"epoch": 30, "training_loss": 0.6906456017494201, "training_acc": 53.0, "val_loss": 0.6927129197120666, "val_acc": 52.0}
{"epoch": 31, "training_loss": 0.6905078363418579, "training_acc": 53.0, "val_loss": 0.6927035593986511, "val_acc": 52.0}
{"epoch": 32, "training_loss": 0.692050507068634, "training_acc": 53.0, "val_loss": 0.6931383323669433, "val_acc": 52.0}
{"epoch": 33, "training_loss": 0.6920622563362122, "training_acc": 53.0, "val_loss": 0.6925611114501953, "val_acc": 52.0}
{"epoch": 34, "training_loss": 0.6906486177444457, "training_acc": 53.0, "val_loss": 0.692604796886444, "val_acc": 52.0}
{"epoch": 35, "training_loss": 0.6919402837753296, "training_acc": 53.0, "val_loss": 0.692425730228424, "val_acc": 52.0}
