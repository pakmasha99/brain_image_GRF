"main_modify.py --pretrained_path /scratch/connectome/dyhan316/VAE_ADHD/barlowtwins/pretrain_results/ABCDbt128a102.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 1 --task ABCD_sex --input_option BT_org --learning_rate 1e-4 --batch_size 16 --weight_decay 1e-3 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 0.7014939975738526, "training_acc": 47.0, "val_loss": 0.6948140168190002, "val_acc": 48.0}
{"epoch": 1, "training_loss": 0.6940312838554382, "training_acc": 50.0, "val_loss": 0.6934869170188904, "val_acc": 52.0}
{"epoch": 2, "training_loss": 0.6921451330184937, "training_acc": 53.0, "val_loss": 0.693477807044983, "val_acc": 52.0}
{"epoch": 3, "training_loss": 0.693673222064972, "training_acc": 53.0, "val_loss": 0.694182550907135, "val_acc": 52.0}
{"epoch": 4, "training_loss": 0.692125940322876, "training_acc": 53.0, "val_loss": 0.6942050623893737, "val_acc": 52.0}
{"epoch": 5, "training_loss": 0.6923917293548584, "training_acc": 53.0, "val_loss": 0.6944805002212524, "val_acc": 52.0}
{"epoch": 6, "training_loss": 0.6936806344985962, "training_acc": 53.0, "val_loss": 0.6937489295005799, "val_acc": 52.0}
{"epoch": 7, "training_loss": 0.6923765897750854, "training_acc": 53.0, "val_loss": 0.6940081119537354, "val_acc": 52.0}
{"epoch": 8, "training_loss": 0.6924625873565674, "training_acc": 53.0, "val_loss": 0.6945592093467713, "val_acc": 52.0}
{"epoch": 9, "training_loss": 0.6920759344100952, "training_acc": 53.0, "val_loss": 0.6944269061088562, "val_acc": 52.0}
{"epoch": 10, "training_loss": 0.6925044584274292, "training_acc": 53.0, "val_loss": 0.6945522689819336, "val_acc": 52.0}
{"epoch": 11, "training_loss": 0.6924465274810792, "training_acc": 53.0, "val_loss": 0.6955393052101135, "val_acc": 52.0}
{"epoch": 12, "training_loss": 0.6932360982894897, "training_acc": 53.0, "val_loss": 0.6952350354194641, "val_acc": 52.0}
{"epoch": 13, "training_loss": 0.6929758477210999, "training_acc": 53.0, "val_loss": 0.6952094721794129, "val_acc": 52.0}
{"epoch": 14, "training_loss": 0.6933258891105651, "training_acc": 53.0, "val_loss": 0.695422203540802, "val_acc": 52.0}
{"epoch": 15, "training_loss": 0.6926631736755371, "training_acc": 53.0, "val_loss": 0.6942627835273742, "val_acc": 52.0}
{"epoch": 16, "training_loss": 0.6929716825485229, "training_acc": 53.0, "val_loss": 0.6944456553459167, "val_acc": 52.0}
{"epoch": 17, "training_loss": 0.691823844909668, "training_acc": 53.0, "val_loss": 0.6937357878684998, "val_acc": 52.0}
{"epoch": 18, "training_loss": 0.6917084646224976, "training_acc": 53.0, "val_loss": 0.6933451104164123, "val_acc": 52.0}
{"epoch": 19, "training_loss": 0.6919794416427613, "training_acc": 53.0, "val_loss": 0.6932892155647278, "val_acc": 52.0}
{"epoch": 20, "training_loss": 0.6922366762161255, "training_acc": 53.0, "val_loss": 0.6933350801467896, "val_acc": 52.0}
{"epoch": 21, "training_loss": 0.6925481724739074, "training_acc": 52.0, "val_loss": 0.6936574244499206, "val_acc": 44.0}
{"epoch": 22, "training_loss": 0.6933373832702636, "training_acc": 49.0, "val_loss": 0.6936323237419129, "val_acc": 44.0}
{"epoch": 23, "training_loss": 0.6933608484268189, "training_acc": 53.0, "val_loss": 0.693267457485199, "val_acc": 52.0}
{"epoch": 24, "training_loss": 0.6926242160797119, "training_acc": 53.0, "val_loss": 0.6936014485359192, "val_acc": 52.0}
{"epoch": 25, "training_loss": 0.6918365454673767, "training_acc": 53.0, "val_loss": 0.6939535522460938, "val_acc": 52.0}
{"epoch": 26, "training_loss": 0.6915977072715759, "training_acc": 53.0, "val_loss": 0.6933194732666016, "val_acc": 52.0}
{"epoch": 27, "training_loss": 0.6916943955421447, "training_acc": 53.0, "val_loss": 0.693214304447174, "val_acc": 52.0}
{"epoch": 28, "training_loss": 0.6921508455276489, "training_acc": 53.0, "val_loss": 0.6932043933868408, "val_acc": 52.0}
{"epoch": 29, "training_loss": 0.6921221971511841, "training_acc": 53.0, "val_loss": 0.693267982006073, "val_acc": 52.0}
{"epoch": 30, "training_loss": 0.6925493669509888, "training_acc": 53.0, "val_loss": 0.6932619500160218, "val_acc": 52.0}
{"epoch": 31, "training_loss": 0.6924456405639648, "training_acc": 53.0, "val_loss": 0.6932209300994873, "val_acc": 52.0}
{"epoch": 32, "training_loss": 0.6919563579559326, "training_acc": 53.0, "val_loss": 0.6933136463165284, "val_acc": 52.0}
{"epoch": 33, "training_loss": 0.6925853157043457, "training_acc": 53.0, "val_loss": 0.6931544995307922, "val_acc": 52.0}
{"epoch": 34, "training_loss": 0.6916778755187988, "training_acc": 53.0, "val_loss": 0.6931952357292175, "val_acc": 52.0}
{"epoch": 35, "training_loss": 0.6913486099243165, "training_acc": 53.0, "val_loss": 0.6935120725631714, "val_acc": 52.0}
{"epoch": 36, "training_loss": 0.6917412424087525, "training_acc": 53.0, "val_loss": 0.6949723196029663, "val_acc": 52.0}
{"epoch": 37, "training_loss": 0.6934436964988708, "training_acc": 53.0, "val_loss": 0.6956338238716125, "val_acc": 52.0}
{"epoch": 38, "training_loss": 0.6931362867355346, "training_acc": 53.0, "val_loss": 0.6938493394851685, "val_acc": 52.0}
{"epoch": 39, "training_loss": 0.6916211414337158, "training_acc": 53.0, "val_loss": 0.6933238911628723, "val_acc": 52.0}
{"epoch": 40, "training_loss": 0.6906328296661377, "training_acc": 53.0, "val_loss": 0.6931014919281006, "val_acc": 52.0}
{"epoch": 41, "training_loss": 0.6920113968849182, "training_acc": 54.0, "val_loss": 0.6934984135627746, "val_acc": 44.0}
{"epoch": 42, "training_loss": 0.692839150428772, "training_acc": 52.0, "val_loss": 0.6934479832649231, "val_acc": 44.0}
{"epoch": 43, "training_loss": 0.6925434970855713, "training_acc": 51.0, "val_loss": 0.6930799150466919, "val_acc": 52.0}
{"epoch": 44, "training_loss": 0.692889220714569, "training_acc": 53.0, "val_loss": 0.693142659664154, "val_acc": 52.0}
{"epoch": 45, "training_loss": 0.6916153454780578, "training_acc": 53.0, "val_loss": 0.6931587624549865, "val_acc": 52.0}
{"epoch": 46, "training_loss": 0.6916752219200134, "training_acc": 53.0, "val_loss": 0.6931290531158447, "val_acc": 52.0}
{"epoch": 47, "training_loss": 0.6913058805465698, "training_acc": 53.0, "val_loss": 0.6930952930450439, "val_acc": 52.0}
{"epoch": 48, "training_loss": 0.6918311142921447, "training_acc": 53.0, "val_loss": 0.6931579566001892, "val_acc": 52.0}
{"epoch": 49, "training_loss": 0.6914376258850098, "training_acc": 53.0, "val_loss": 0.6931321692466735, "val_acc": 52.0}
{"epoch": 50, "training_loss": 0.6910002827644348, "training_acc": 53.0, "val_loss": 0.6935420680046082, "val_acc": 52.0}
{"epoch": 51, "training_loss": 0.6905047059059143, "training_acc": 53.0, "val_loss": 0.6941202473640442, "val_acc": 52.0}
{"epoch": 52, "training_loss": 0.6913151121139527, "training_acc": 53.0, "val_loss": 0.694253432750702, "val_acc": 52.0}
{"epoch": 53, "training_loss": 0.6921171188354492, "training_acc": 53.0, "val_loss": 0.6947342014312744, "val_acc": 52.0}
{"epoch": 54, "training_loss": 0.6927324557304382, "training_acc": 53.0, "val_loss": 0.6945644903182984, "val_acc": 52.0}
{"epoch": 55, "training_loss": 0.6911916112899781, "training_acc": 53.0, "val_loss": 0.6932600331306458, "val_acc": 52.0}
{"epoch": 56, "training_loss": 0.691416482925415, "training_acc": 53.0, "val_loss": 0.6929643702507019, "val_acc": 52.0}
{"epoch": 57, "training_loss": 0.6916980147361755, "training_acc": 53.0, "val_loss": 0.6931428813934326, "val_acc": 52.0}
{"epoch": 58, "training_loss": 0.6924160099029542, "training_acc": 53.0, "val_loss": 0.6937478947639465, "val_acc": 52.0}
{"epoch": 59, "training_loss": 0.691779613494873, "training_acc": 53.0, "val_loss": 0.6940141296386719, "val_acc": 52.0}
{"epoch": 60, "training_loss": 0.6916598081588745, "training_acc": 53.0, "val_loss": 0.6939130139350891, "val_acc": 52.0}
{"epoch": 61, "training_loss": 0.6918505001068115, "training_acc": 53.0, "val_loss": 0.6933784222602845, "val_acc": 52.0}
{"epoch": 62, "training_loss": 0.6914676284790039, "training_acc": 53.0, "val_loss": 0.6937800192832947, "val_acc": 52.0}
{"epoch": 63, "training_loss": 0.6917089462280274, "training_acc": 53.0, "val_loss": 0.693686978816986, "val_acc": 52.0}
{"epoch": 64, "training_loss": 0.69117431640625, "training_acc": 53.0, "val_loss": 0.6934920954704284, "val_acc": 52.0}
{"epoch": 65, "training_loss": 0.6916057085990905, "training_acc": 53.0, "val_loss": 0.6934418916702271, "val_acc": 52.0}
{"epoch": 66, "training_loss": 0.6910428619384765, "training_acc": 53.0, "val_loss": 0.6930382204055786, "val_acc": 52.0}
{"epoch": 67, "training_loss": 0.6931062006950378, "training_acc": 53.0, "val_loss": 0.6928327560424805, "val_acc": 52.0}
{"epoch": 68, "training_loss": 0.6911824560165405, "training_acc": 53.0, "val_loss": 0.692968738079071, "val_acc": 52.0}
{"epoch": 69, "training_loss": 0.6926597452163696, "training_acc": 53.0, "val_loss": 0.694576370716095, "val_acc": 52.0}
{"epoch": 70, "training_loss": 0.6926351141929626, "training_acc": 53.0, "val_loss": 0.6960434699058533, "val_acc": 52.0}
{"epoch": 71, "training_loss": 0.6923506140708924, "training_acc": 53.0, "val_loss": 0.6960622119903564, "val_acc": 52.0}
{"epoch": 72, "training_loss": 0.6932711410522461, "training_acc": 53.0, "val_loss": 0.6961990356445312, "val_acc": 52.0}
{"epoch": 73, "training_loss": 0.6920142841339111, "training_acc": 53.0, "val_loss": 0.6949054431915284, "val_acc": 52.0}
{"epoch": 74, "training_loss": 0.6924532413482666, "training_acc": 53.0, "val_loss": 0.6943179059028626, "val_acc": 52.0}
{"epoch": 75, "training_loss": 0.6909504365921021, "training_acc": 53.0, "val_loss": 0.6932468414306641, "val_acc": 52.0}
{"epoch": 76, "training_loss": 0.6919412589073182, "training_acc": 53.0, "val_loss": 0.6929818081855774, "val_acc": 52.0}
{"epoch": 77, "training_loss": 0.6915849781036377, "training_acc": 53.0, "val_loss": 0.6930302906036377, "val_acc": 52.0}
{"epoch": 78, "training_loss": 0.691632616519928, "training_acc": 53.0, "val_loss": 0.6928573346138001, "val_acc": 52.0}
{"epoch": 79, "training_loss": 0.6906507015228271, "training_acc": 53.0, "val_loss": 0.6931668782234192, "val_acc": 52.0}
{"epoch": 80, "training_loss": 0.6911548089981079, "training_acc": 53.0, "val_loss": 0.6930475687980652, "val_acc": 52.0}
{"epoch": 81, "training_loss": 0.6913222742080688, "training_acc": 53.0, "val_loss": 0.6930278992652893, "val_acc": 52.0}
{"epoch": 82, "training_loss": 0.6907897305488586, "training_acc": 53.0, "val_loss": 0.6932947206497192, "val_acc": 52.0}
{"epoch": 83, "training_loss": 0.6911987113952637, "training_acc": 53.0, "val_loss": 0.6939116024971008, "val_acc": 52.0}
{"epoch": 84, "training_loss": 0.6912845802307129, "training_acc": 53.0, "val_loss": 0.6930947613716125, "val_acc": 52.0}
{"epoch": 85, "training_loss": 0.6914344620704651, "training_acc": 53.0, "val_loss": 0.6934811091423034, "val_acc": 52.0}
{"epoch": 86, "training_loss": 0.6909225177764893, "training_acc": 53.0, "val_loss": 0.6929373168945312, "val_acc": 52.0}
{"epoch": 87, "training_loss": 0.6909196877479553, "training_acc": 53.0, "val_loss": 0.6926754260063172, "val_acc": 52.0}
{"epoch": 88, "training_loss": 0.6915651798248291, "training_acc": 53.0, "val_loss": 0.692673990726471, "val_acc": 52.0}
{"epoch": 89, "training_loss": 0.6914740800857544, "training_acc": 53.0, "val_loss": 0.6927973532676697, "val_acc": 52.0}
{"epoch": 90, "training_loss": 0.6927140355110168, "training_acc": 51.0, "val_loss": 0.6930704855918884, "val_acc": 44.0}
{"epoch": 91, "training_loss": 0.6920521116256714, "training_acc": 52.0, "val_loss": 0.6926116466522216, "val_acc": 52.0}
{"epoch": 92, "training_loss": 0.6906261444091797, "training_acc": 53.0, "val_loss": 0.6928606629371643, "val_acc": 52.0}
{"epoch": 93, "training_loss": 0.6910608768463135, "training_acc": 53.0, "val_loss": 0.6930280661582947, "val_acc": 52.0}
{"epoch": 94, "training_loss": 0.6903647351264953, "training_acc": 53.0, "val_loss": 0.6928578686714172, "val_acc": 52.0}
{"epoch": 95, "training_loss": 0.6905568790435791, "training_acc": 53.0, "val_loss": 0.692975242137909, "val_acc": 52.0}
{"epoch": 96, "training_loss": 0.6909206366539001, "training_acc": 53.0, "val_loss": 0.6936375045776367, "val_acc": 52.0}
{"epoch": 97, "training_loss": 0.6929515147209168, "training_acc": 53.0, "val_loss": 0.6954432773590088, "val_acc": 52.0}
{"epoch": 98, "training_loss": 0.691658284664154, "training_acc": 53.0, "val_loss": 0.6942798209190368, "val_acc": 52.0}
{"epoch": 99, "training_loss": 0.693263771533966, "training_acc": 53.0, "val_loss": 0.6928036999702454, "val_acc": 52.0}
