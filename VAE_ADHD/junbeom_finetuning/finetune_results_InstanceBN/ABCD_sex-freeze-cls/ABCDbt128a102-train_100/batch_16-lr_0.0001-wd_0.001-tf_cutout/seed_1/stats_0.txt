"main_modify.py --pretrained_path /scratch/connectome/dyhan316/VAE_ADHD/barlowtwins/pretrain_results/ABCDbt128a102.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 1 --task ABCD_sex --input_option BT_org --learning_rate 1e-4 --batch_size 16 --weight_decay 1e-3 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 0.6938388586044312, "training_acc": 53.0, "val_loss": 0.6905969834327698, "val_acc": 52.0}
{"epoch": 1, "training_loss": 0.6922238779067993, "training_acc": 53.0, "val_loss": 0.6911246848106384, "val_acc": 52.0}
{"epoch": 2, "training_loss": 0.6915083026885986, "training_acc": 53.0, "val_loss": 0.6925208854675293, "val_acc": 52.0}
{"epoch": 3, "training_loss": 0.6929560852050781, "training_acc": 53.0, "val_loss": 0.6926765036582947, "val_acc": 52.0}
{"epoch": 4, "training_loss": 0.6933701467514038, "training_acc": 53.0, "val_loss": 0.692084391117096, "val_acc": 52.0}
{"epoch": 5, "training_loss": 0.693119649887085, "training_acc": 53.0, "val_loss": 0.692669334411621, "val_acc": 52.0}
{"epoch": 6, "training_loss": 0.6938904047012329, "training_acc": 53.0, "val_loss": 0.6928263187408448, "val_acc": 52.0}
{"epoch": 7, "training_loss": 0.6930184459686279, "training_acc": 53.0, "val_loss": 0.6917326378822327, "val_acc": 52.0}
{"epoch": 8, "training_loss": 0.6919883251190185, "training_acc": 53.0, "val_loss": 0.6910919952392578, "val_acc": 52.0}
{"epoch": 9, "training_loss": 0.6922282648086547, "training_acc": 53.0, "val_loss": 0.690994861125946, "val_acc": 52.0}
{"epoch": 10, "training_loss": 0.6926189136505126, "training_acc": 53.0, "val_loss": 0.6906519842147827, "val_acc": 52.0}
{"epoch": 11, "training_loss": 0.6919358253479004, "training_acc": 53.0, "val_loss": 0.6906135225296021, "val_acc": 52.0}
{"epoch": 12, "training_loss": 0.6923540782928467, "training_acc": 53.0, "val_loss": 0.6908697080612183, "val_acc": 52.0}
{"epoch": 13, "training_loss": 0.6929743790626526, "training_acc": 53.0, "val_loss": 0.691193585395813, "val_acc": 52.0}
{"epoch": 14, "training_loss": 0.6924577140808106, "training_acc": 53.0, "val_loss": 0.690660982131958, "val_acc": 52.0}
{"epoch": 15, "training_loss": 0.6927423453330994, "training_acc": 53.0, "val_loss": 0.6906870484352112, "val_acc": 52.0}
{"epoch": 16, "training_loss": 0.6921551346778869, "training_acc": 53.0, "val_loss": 0.6906009912490845, "val_acc": 52.0}
{"epoch": 17, "training_loss": 0.6922513914108276, "training_acc": 53.0, "val_loss": 0.6906642103195191, "val_acc": 52.0}
{"epoch": 18, "training_loss": 0.6922123956680298, "training_acc": 53.0, "val_loss": 0.6905795788764953, "val_acc": 52.0}
{"epoch": 19, "training_loss": 0.6917302560806274, "training_acc": 53.0, "val_loss": 0.690653121471405, "val_acc": 52.0}
{"epoch": 20, "training_loss": 0.6927799654006958, "training_acc": 53.0, "val_loss": 0.690919759273529, "val_acc": 52.0}
{"epoch": 21, "training_loss": 0.6913873338699341, "training_acc": 53.0, "val_loss": 0.6915208554267883, "val_acc": 52.0}
{"epoch": 22, "training_loss": 0.6927304863929749, "training_acc": 53.0, "val_loss": 0.6927748417854309, "val_acc": 52.0}
{"epoch": 23, "training_loss": 0.692928524017334, "training_acc": 53.0, "val_loss": 0.6918099164962769, "val_acc": 52.0}
{"epoch": 24, "training_loss": 0.6947978854179382, "training_acc": 53.0, "val_loss": 0.6908243870735169, "val_acc": 52.0}
{"epoch": 25, "training_loss": 0.6921445560455323, "training_acc": 53.0, "val_loss": 0.6909292364120483, "val_acc": 52.0}
{"epoch": 26, "training_loss": 0.6917700290679931, "training_acc": 53.0, "val_loss": 0.6909824013710022, "val_acc": 52.0}
{"epoch": 27, "training_loss": 0.6928966093063355, "training_acc": 53.0, "val_loss": 0.6916013145446778, "val_acc": 52.0}
{"epoch": 28, "training_loss": 0.6925687789916992, "training_acc": 53.0, "val_loss": 0.6906774139404297, "val_acc": 52.0}
{"epoch": 29, "training_loss": 0.6921874260902405, "training_acc": 53.0, "val_loss": 0.6907967090606689, "val_acc": 52.0}
{"epoch": 30, "training_loss": 0.6919057655334473, "training_acc": 53.0, "val_loss": 0.6908119511604309, "val_acc": 52.0}
{"epoch": 31, "training_loss": 0.6918294239044189, "training_acc": 53.0, "val_loss": 0.690757749080658, "val_acc": 52.0}
{"epoch": 32, "training_loss": 0.6916120362281799, "training_acc": 53.0, "val_loss": 0.6906402277946472, "val_acc": 52.0}
{"epoch": 33, "training_loss": 0.6916847062110901, "training_acc": 53.0, "val_loss": 0.6908866167068481, "val_acc": 52.0}
{"epoch": 34, "training_loss": 0.6924599385261536, "training_acc": 53.0, "val_loss": 0.6920562291145325, "val_acc": 52.0}
{"epoch": 35, "training_loss": 0.6921837115287781, "training_acc": 53.0, "val_loss": 0.6918228507041931, "val_acc": 52.0}
{"epoch": 36, "training_loss": 0.6912747359275818, "training_acc": 53.0, "val_loss": 0.6909079718589782, "val_acc": 52.0}
{"epoch": 37, "training_loss": 0.6912438011169434, "training_acc": 53.0, "val_loss": 0.6906265997886658, "val_acc": 52.0}
