"main_modify.py --pretrained_path /scratch/connectome/dyhan316/VAE_ADHD/barlowtwins/pretrain_results/ABCDbt128a102.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option BT_org --learning_rate 1e-3 --batch_size 16 --weight_decay 1e-4 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 0.7254640340805054, "training_acc": 47.0, "val_loss": 0.7133930516242981, "val_acc": 52.0}
{"epoch": 1, "training_loss": 0.7163238596916198, "training_acc": 53.0, "val_loss": 0.7025136303901672, "val_acc": 52.0}
{"epoch": 2, "training_loss": 0.6934688210487365, "training_acc": 53.0, "val_loss": 0.70664799451828, "val_acc": 48.0}
{"epoch": 3, "training_loss": 0.7004032206535339, "training_acc": 47.0, "val_loss": 0.6973598146438599, "val_acc": 52.0}
{"epoch": 4, "training_loss": 0.6944771766662597, "training_acc": 53.0, "val_loss": 0.6928667640686035, "val_acc": 52.0}
{"epoch": 5, "training_loss": 0.6997113466262818, "training_acc": 47.0, "val_loss": 0.6931904983520508, "val_acc": 52.0}
{"epoch": 6, "training_loss": 0.6905988574028015, "training_acc": 51.0, "val_loss": 0.7026683902740478, "val_acc": 52.0}
{"epoch": 7, "training_loss": 0.7104632472991943, "training_acc": 47.0, "val_loss": 0.692776837348938, "val_acc": 52.0}
{"epoch": 8, "training_loss": 0.6901497030258179, "training_acc": 53.0, "val_loss": 0.7038720440864563, "val_acc": 52.0}
{"epoch": 9, "training_loss": 0.6989494514465332, "training_acc": 53.0, "val_loss": 0.6934862112998963, "val_acc": 52.0}
{"epoch": 10, "training_loss": 0.6876588654518128, "training_acc": 58.0, "val_loss": 0.6996355700492859, "val_acc": 48.0}
{"epoch": 11, "training_loss": 0.6964277195930481, "training_acc": 51.0, "val_loss": 0.6948233437538147, "val_acc": 52.0}
{"epoch": 12, "training_loss": 0.695330445766449, "training_acc": 53.0, "val_loss": 0.7028127980232238, "val_acc": 52.0}
{"epoch": 13, "training_loss": 0.6956619310379029, "training_acc": 53.0, "val_loss": 0.6943471217155457, "val_acc": 52.0}
{"epoch": 14, "training_loss": 0.6980685925483704, "training_acc": 53.0, "val_loss": 0.694410560131073, "val_acc": 52.0}
{"epoch": 15, "training_loss": 0.7002032566070556, "training_acc": 43.0, "val_loss": 0.6975417113304139, "val_acc": 48.0}
{"epoch": 16, "training_loss": 0.689930009841919, "training_acc": 56.0, "val_loss": 0.6950896835327148, "val_acc": 52.0}
{"epoch": 17, "training_loss": 0.6914908123016358, "training_acc": 53.0, "val_loss": 0.6948147988319398, "val_acc": 52.0}
{"epoch": 18, "training_loss": 0.6936229872703552, "training_acc": 53.0, "val_loss": 0.6966835522651672, "val_acc": 52.0}
{"epoch": 19, "training_loss": 0.6948306703567505, "training_acc": 53.0, "val_loss": 0.6936248898506164, "val_acc": 52.0}
{"epoch": 20, "training_loss": 0.6906265044212341, "training_acc": 53.0, "val_loss": 0.6942284989356995, "val_acc": 52.0}
{"epoch": 21, "training_loss": 0.6925839591026306, "training_acc": 53.0, "val_loss": 0.6935008025169372, "val_acc": 52.0}
{"epoch": 22, "training_loss": 0.6902317476272583, "training_acc": 55.0, "val_loss": 0.6941049647331238, "val_acc": 48.0}
{"epoch": 23, "training_loss": 0.6962334346771241, "training_acc": 49.0, "val_loss": 0.6934707379341125, "val_acc": 52.0}
{"epoch": 24, "training_loss": 0.683713150024414, "training_acc": 53.0, "val_loss": 0.7083451199531555, "val_acc": 52.0}
{"epoch": 25, "training_loss": 0.7092365908622742, "training_acc": 53.0, "val_loss": 0.6995603156089782, "val_acc": 52.0}
{"epoch": 26, "training_loss": 0.684386031627655, "training_acc": 55.0, "val_loss": 0.6979059839248657, "val_acc": 48.0}
