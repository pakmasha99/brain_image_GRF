"main_modify.py --pretrained_path /scratch/connectome/dyhan316/VAE_ADHD/barlowtwins/pretrain_results/ABCDbt128a102.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option BT_org --learning_rate 1e-3 --batch_size 16 --weight_decay 1e-4 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 0.7075829577445983, "training_acc": 45.0, "val_loss": 0.69471031665802, "val_acc": 52.0}
{"epoch": 1, "training_loss": 0.6918953084945678, "training_acc": 53.0, "val_loss": 0.7003018951416016, "val_acc": 52.0}
{"epoch": 2, "training_loss": 0.7087026000022888, "training_acc": 53.0, "val_loss": 0.6967173838615417, "val_acc": 52.0}
{"epoch": 3, "training_loss": 0.7025207495689392, "training_acc": 47.0, "val_loss": 0.7020112991333007, "val_acc": 48.0}
{"epoch": 4, "training_loss": 0.7032323384284973, "training_acc": 52.0, "val_loss": 0.7181074333190918, "val_acc": 52.0}
{"epoch": 5, "training_loss": 0.7034299111366272, "training_acc": 55.0, "val_loss": 0.697186713218689, "val_acc": 48.0}
{"epoch": 6, "training_loss": 0.7143374562263489, "training_acc": 47.0, "val_loss": 0.6999456715583802, "val_acc": 48.0}
{"epoch": 7, "training_loss": 0.699109091758728, "training_acc": 45.0, "val_loss": 0.6985542345046997, "val_acc": 52.0}
{"epoch": 8, "training_loss": 0.6935475754737854, "training_acc": 53.0, "val_loss": 0.6976454281806945, "val_acc": 52.0}
{"epoch": 9, "training_loss": 0.6933291339874268, "training_acc": 55.0, "val_loss": 0.6971685123443604, "val_acc": 48.0}
{"epoch": 10, "training_loss": 0.6994228649139405, "training_acc": 47.0, "val_loss": 0.6947016167640686, "val_acc": 52.0}
{"epoch": 11, "training_loss": 0.691217999458313, "training_acc": 53.0, "val_loss": 0.6943454766273498, "val_acc": 52.0}
{"epoch": 12, "training_loss": 0.6931147384643555, "training_acc": 56.0, "val_loss": 0.6942352509498596, "val_acc": 52.0}
{"epoch": 13, "training_loss": 0.6951679182052612, "training_acc": 53.0, "val_loss": 0.7053714299201965, "val_acc": 52.0}
{"epoch": 14, "training_loss": 0.7089206004142761, "training_acc": 46.0, "val_loss": 0.6945005345344544, "val_acc": 52.0}
{"epoch": 15, "training_loss": 0.6913109970092773, "training_acc": 54.0, "val_loss": 0.7002164578437805, "val_acc": 52.0}
{"epoch": 16, "training_loss": 0.6986360096931458, "training_acc": 53.0, "val_loss": 0.69611492395401, "val_acc": 52.0}
{"epoch": 17, "training_loss": 0.6999833536148071, "training_acc": 44.0, "val_loss": 0.6942079377174377, "val_acc": 52.0}
{"epoch": 18, "training_loss": 0.7123626470565796, "training_acc": 53.0, "val_loss": 0.7094245672225952, "val_acc": 52.0}
{"epoch": 19, "training_loss": 0.7023366832733154, "training_acc": 52.0, "val_loss": 0.694093472957611, "val_acc": 52.0}
{"epoch": 20, "training_loss": 0.6994073629379273, "training_acc": 53.0, "val_loss": 0.702408721446991, "val_acc": 52.0}
{"epoch": 21, "training_loss": 0.6969378805160522, "training_acc": 53.0, "val_loss": 0.6969100189208984, "val_acc": 52.0}
{"epoch": 22, "training_loss": 0.6912923216819763, "training_acc": 53.0, "val_loss": 0.6951864933967591, "val_acc": 52.0}
{"epoch": 23, "training_loss": 0.6873212051391602, "training_acc": 53.0, "val_loss": 0.6957977676391601, "val_acc": 48.0}
{"epoch": 24, "training_loss": 0.6939003777503967, "training_acc": 47.0, "val_loss": 0.6941517186164856, "val_acc": 52.0}
{"epoch": 25, "training_loss": 0.7197844171524048, "training_acc": 52.0, "val_loss": 0.706633448600769, "val_acc": 52.0}
{"epoch": 26, "training_loss": 0.6955450010299683, "training_acc": 47.0, "val_loss": 0.720722668170929, "val_acc": 48.0}
{"epoch": 27, "training_loss": 0.7178560042381287, "training_acc": 47.0, "val_loss": 0.697777795791626, "val_acc": 48.0}
{"epoch": 28, "training_loss": 0.6901153492927551, "training_acc": 54.0, "val_loss": 0.6977378749847412, "val_acc": 52.0}
{"epoch": 29, "training_loss": 0.6930097150802612, "training_acc": 53.0, "val_loss": 0.6964771366119384, "val_acc": 52.0}
{"epoch": 30, "training_loss": 0.6902874636650086, "training_acc": 53.0, "val_loss": 0.6945704078674316, "val_acc": 40.0}
{"epoch": 31, "training_loss": 0.7033619618415833, "training_acc": 48.0, "val_loss": 0.7104417753219604, "val_acc": 48.0}
{"epoch": 32, "training_loss": 0.6961721658706665, "training_acc": 50.0, "val_loss": 0.6949467968940735, "val_acc": 52.0}
{"epoch": 33, "training_loss": 0.6887525463104248, "training_acc": 53.0, "val_loss": 0.6965860271453858, "val_acc": 52.0}
{"epoch": 34, "training_loss": 0.6897419428825379, "training_acc": 53.0, "val_loss": 0.6973500680923462, "val_acc": 52.0}
{"epoch": 35, "training_loss": 0.6897465372085572, "training_acc": 53.0, "val_loss": 0.6956584858894348, "val_acc": 52.0}
{"epoch": 36, "training_loss": 0.7030348920822144, "training_acc": 53.0, "val_loss": 0.696454894542694, "val_acc": 52.0}
{"epoch": 37, "training_loss": 0.6971685409545898, "training_acc": 49.0, "val_loss": 0.7010579538345337, "val_acc": 48.0}
{"epoch": 38, "training_loss": 0.6812716388702392, "training_acc": 57.0, "val_loss": 0.7017008948326111, "val_acc": 52.0}
