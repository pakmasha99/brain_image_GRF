"main_modify.py --pretrained_path /scratch/connectome/dyhan316/VAE_ADHD/barlowtwins/pretrain_results/ABCDbt128a102.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option BT_org --learning_rate 1e-3 --batch_size 16 --weight_decay 1e-4 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 0.7011636209487915, "training_acc": 56.0, "val_loss": 0.7042493867874146, "val_acc": 48.0}
{"epoch": 1, "training_loss": 0.725695013999939, "training_acc": 47.0, "val_loss": 0.693112690448761, "val_acc": 52.0}
{"epoch": 2, "training_loss": 0.7317250180244446, "training_acc": 53.0, "val_loss": 0.7246867108345032, "val_acc": 52.0}
{"epoch": 3, "training_loss": 0.7062731170654297, "training_acc": 49.0, "val_loss": 0.7089530181884766, "val_acc": 48.0}
{"epoch": 4, "training_loss": 0.702516942024231, "training_acc": 49.0, "val_loss": 0.6932680249214173, "val_acc": 52.0}
{"epoch": 5, "training_loss": 0.7225497484207153, "training_acc": 53.0, "val_loss": 0.7160837483406067, "val_acc": 52.0}
{"epoch": 6, "training_loss": 0.6886996364593506, "training_acc": 49.0, "val_loss": 0.6966326642036438, "val_acc": 48.0}
{"epoch": 7, "training_loss": 0.7153435063362121, "training_acc": 42.0, "val_loss": 0.6938922166824341, "val_acc": 52.0}
{"epoch": 8, "training_loss": 0.6914950132369995, "training_acc": 54.0, "val_loss": 0.6931319761276246, "val_acc": 52.0}
{"epoch": 9, "training_loss": 0.6957572507858276, "training_acc": 53.0, "val_loss": 0.6943166661262512, "val_acc": 52.0}
{"epoch": 10, "training_loss": 0.7019842720031738, "training_acc": 43.0, "val_loss": 0.7004499936103821, "val_acc": 48.0}
{"epoch": 11, "training_loss": 0.7029740166664123, "training_acc": 46.0, "val_loss": 0.6929049372673035, "val_acc": 52.0}
{"epoch": 12, "training_loss": 0.6895366525650024, "training_acc": 53.0, "val_loss": 0.6931511759757996, "val_acc": 52.0}
{"epoch": 13, "training_loss": 0.6989183521270752, "training_acc": 53.0, "val_loss": 0.6964821004867554, "val_acc": 52.0}
{"epoch": 14, "training_loss": 0.6947419881820679, "training_acc": 53.0, "val_loss": 0.6966328263282776, "val_acc": 52.0}
{"epoch": 15, "training_loss": 0.6863951396942138, "training_acc": 55.0, "val_loss": 0.6969199728965759, "val_acc": 48.0}
{"epoch": 16, "training_loss": 0.6972098207473755, "training_acc": 47.0, "val_loss": 0.6930332255363464, "val_acc": 52.0}
{"epoch": 17, "training_loss": 0.6862944555282593, "training_acc": 53.0, "val_loss": 0.7048914909362793, "val_acc": 52.0}
{"epoch": 18, "training_loss": 0.700666389465332, "training_acc": 53.0, "val_loss": 0.6994613122940063, "val_acc": 52.0}
{"epoch": 19, "training_loss": 0.6899980878829957, "training_acc": 53.0, "val_loss": 0.6926201939582824, "val_acc": 52.0}
{"epoch": 20, "training_loss": 0.6993704295158386, "training_acc": 48.0, "val_loss": 0.7040343904495239, "val_acc": 48.0}
{"epoch": 21, "training_loss": 0.7053826117515564, "training_acc": 47.0, "val_loss": 0.6978714561462402, "val_acc": 48.0}
{"epoch": 22, "training_loss": 0.6930498099327087, "training_acc": 48.0, "val_loss": 0.6930365824699402, "val_acc": 52.0}
{"epoch": 23, "training_loss": 0.6893404078483581, "training_acc": 53.0, "val_loss": 0.6925527119636535, "val_acc": 52.0}
{"epoch": 24, "training_loss": 0.6947196865081787, "training_acc": 48.0, "val_loss": 0.6925868844985962, "val_acc": 52.0}
{"epoch": 25, "training_loss": 0.6901417016983032, "training_acc": 53.0, "val_loss": 0.6926004767417908, "val_acc": 52.0}
{"epoch": 26, "training_loss": 0.6941815996170044, "training_acc": 47.0, "val_loss": 0.6929687166213989, "val_acc": 48.0}
{"epoch": 27, "training_loss": 0.6906534290313721, "training_acc": 54.0, "val_loss": 0.6925904631614686, "val_acc": 52.0}
{"epoch": 28, "training_loss": 0.6903577184677124, "training_acc": 53.0, "val_loss": 0.6942280888557434, "val_acc": 52.0}
{"epoch": 29, "training_loss": 0.6884239339828491, "training_acc": 53.0, "val_loss": 0.6927601599693298, "val_acc": 52.0}
{"epoch": 30, "training_loss": 0.6898148727416992, "training_acc": 57.0, "val_loss": 0.6926703929901123, "val_acc": 52.0}
{"epoch": 31, "training_loss": 0.6861385250091553, "training_acc": 53.0, "val_loss": 0.6956540846824646, "val_acc": 52.0}
{"epoch": 32, "training_loss": 0.6909223079681397, "training_acc": 53.0, "val_loss": 0.6929735255241394, "val_acc": 52.0}
{"epoch": 33, "training_loss": 0.6906988906860352, "training_acc": 55.0, "val_loss": 0.6925535535812378, "val_acc": 52.0}
{"epoch": 34, "training_loss": 0.6886389875411987, "training_acc": 59.0, "val_loss": 0.6930480217933654, "val_acc": 52.0}
{"epoch": 35, "training_loss": 0.6892198991775512, "training_acc": 54.0, "val_loss": 0.6931687450408935, "val_acc": 52.0}
{"epoch": 36, "training_loss": 0.7043711757659912, "training_acc": 53.0, "val_loss": 0.7113543725013733, "val_acc": 52.0}
{"epoch": 37, "training_loss": 0.7070958304405213, "training_acc": 53.0, "val_loss": 0.6929101133346558, "val_acc": 52.0}
{"epoch": 38, "training_loss": 0.6925903296470642, "training_acc": 53.0, "val_loss": 0.693007516860962, "val_acc": 52.0}
{"epoch": 39, "training_loss": 0.6919661808013916, "training_acc": 43.0, "val_loss": 0.6967812442779541, "val_acc": 48.0}
{"epoch": 40, "training_loss": 0.6924632430076599, "training_acc": 48.0, "val_loss": 0.6926556897163391, "val_acc": 52.0}
{"epoch": 41, "training_loss": 0.691016297340393, "training_acc": 50.0, "val_loss": 0.6925649261474609, "val_acc": 52.0}
{"epoch": 42, "training_loss": 0.6850469756126404, "training_acc": 53.0, "val_loss": 0.6979162216186523, "val_acc": 52.0}
