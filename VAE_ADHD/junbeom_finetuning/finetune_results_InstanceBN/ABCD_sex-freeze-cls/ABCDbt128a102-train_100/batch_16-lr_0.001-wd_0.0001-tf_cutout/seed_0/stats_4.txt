"main_modify.py --pretrained_path /scratch/connectome/dyhan316/VAE_ADHD/barlowtwins/pretrain_results/ABCDbt128a102.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option BT_org --learning_rate 1e-3 --batch_size 16 --weight_decay 1e-4 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 0.7072876811027526, "training_acc": 45.0, "val_loss": 0.696740562915802, "val_acc": 52.0}
{"epoch": 1, "training_loss": 0.7201307272911072, "training_acc": 53.0, "val_loss": 0.7093301892280579, "val_acc": 52.0}
{"epoch": 2, "training_loss": 0.7050876641273498, "training_acc": 43.0, "val_loss": 0.7065658593177795, "val_acc": 48.0}
{"epoch": 3, "training_loss": 0.7016283583641052, "training_acc": 47.0, "val_loss": 0.6939023280143738, "val_acc": 52.0}
{"epoch": 4, "training_loss": 0.7104018831253052, "training_acc": 53.0, "val_loss": 0.7248690342903137, "val_acc": 52.0}
{"epoch": 5, "training_loss": 0.7118526649475098, "training_acc": 53.0, "val_loss": 0.6945169949531556, "val_acc": 52.0}
{"epoch": 6, "training_loss": 0.6972983479499817, "training_acc": 44.0, "val_loss": 0.6939277863502502, "val_acc": 52.0}
{"epoch": 7, "training_loss": 0.7025005340576171, "training_acc": 53.0, "val_loss": 0.6997050166130065, "val_acc": 52.0}
{"epoch": 8, "training_loss": 0.6913921928405762, "training_acc": 53.0, "val_loss": 0.6936853575706482, "val_acc": 52.0}
{"epoch": 9, "training_loss": 0.6921994161605834, "training_acc": 56.0, "val_loss": 0.7004649758338928, "val_acc": 48.0}
{"epoch": 10, "training_loss": 0.6981550431251526, "training_acc": 47.0, "val_loss": 0.694631061553955, "val_acc": 52.0}
{"epoch": 11, "training_loss": 0.7080308818817138, "training_acc": 53.0, "val_loss": 0.7069892120361329, "val_acc": 52.0}
{"epoch": 12, "training_loss": 0.709109525680542, "training_acc": 45.0, "val_loss": 0.6977815389633178, "val_acc": 48.0}
{"epoch": 13, "training_loss": 0.6950642919540405, "training_acc": 45.0, "val_loss": 0.693701868057251, "val_acc": 52.0}
{"epoch": 14, "training_loss": 0.7005648326873779, "training_acc": 53.0, "val_loss": 0.6974018812179565, "val_acc": 52.0}
{"epoch": 15, "training_loss": 0.6894765067100525, "training_acc": 53.0, "val_loss": 0.6945306253433228, "val_acc": 48.0}
{"epoch": 16, "training_loss": 0.694520320892334, "training_acc": 49.0, "val_loss": 0.6934794950485229, "val_acc": 52.0}
{"epoch": 17, "training_loss": 0.6894069051742554, "training_acc": 53.0, "val_loss": 0.7072525072097778, "val_acc": 52.0}
{"epoch": 18, "training_loss": 0.7069500708580017, "training_acc": 53.0, "val_loss": 0.6980564951896667, "val_acc": 52.0}
{"epoch": 19, "training_loss": 0.699266746044159, "training_acc": 51.0, "val_loss": 0.6989805269241333, "val_acc": 48.0}
{"epoch": 20, "training_loss": 0.6958555650711059, "training_acc": 47.0, "val_loss": 0.7004293298721314, "val_acc": 52.0}
{"epoch": 21, "training_loss": 0.6964179825782776, "training_acc": 53.0, "val_loss": 0.6942781639099121, "val_acc": 52.0}
{"epoch": 22, "training_loss": 0.6982709503173828, "training_acc": 49.0, "val_loss": 0.7105521106719971, "val_acc": 48.0}
{"epoch": 23, "training_loss": 0.7047150182723999, "training_acc": 47.0, "val_loss": 0.6932208704948425, "val_acc": 52.0}
{"epoch": 24, "training_loss": 0.7223460817337036, "training_acc": 53.0, "val_loss": 0.7095611810684204, "val_acc": 52.0}
{"epoch": 25, "training_loss": 0.7004384708404541, "training_acc": 53.0, "val_loss": 0.7194248533248901, "val_acc": 48.0}
{"epoch": 26, "training_loss": 0.7257108259201049, "training_acc": 45.0, "val_loss": 0.6934919667243957, "val_acc": 52.0}
{"epoch": 27, "training_loss": 0.6940411162376404, "training_acc": 46.0, "val_loss": 0.6934389615058899, "val_acc": 52.0}
{"epoch": 28, "training_loss": 0.6923057603836059, "training_acc": 53.0, "val_loss": 0.6973453617095947, "val_acc": 52.0}
{"epoch": 29, "training_loss": 0.695606062412262, "training_acc": 53.0, "val_loss": 0.6928669404983521, "val_acc": 52.0}
{"epoch": 30, "training_loss": 0.6913841533660888, "training_acc": 53.0, "val_loss": 0.6929069876670837, "val_acc": 52.0}
{"epoch": 31, "training_loss": 0.6875988292694092, "training_acc": 58.0, "val_loss": 0.6958065509796143, "val_acc": 48.0}
{"epoch": 32, "training_loss": 0.6996846008300781, "training_acc": 41.0, "val_loss": 0.6925542855262756, "val_acc": 52.0}
{"epoch": 33, "training_loss": 0.6929770517349243, "training_acc": 51.0, "val_loss": 0.6966438484191895, "val_acc": 48.0}
{"epoch": 34, "training_loss": 0.6948940968513488, "training_acc": 47.0, "val_loss": 0.6951805520057678, "val_acc": 48.0}
{"epoch": 35, "training_loss": 0.6920073866844177, "training_acc": 51.0, "val_loss": 0.6923894190788269, "val_acc": 52.0}
{"epoch": 36, "training_loss": 0.6935073280334473, "training_acc": 53.0, "val_loss": 0.6963454389572143, "val_acc": 52.0}
{"epoch": 37, "training_loss": 0.6885315942764282, "training_acc": 53.0, "val_loss": 0.6923649621009826, "val_acc": 52.0}
{"epoch": 38, "training_loss": 0.6944152784347534, "training_acc": 45.0, "val_loss": 0.696619005203247, "val_acc": 48.0}
{"epoch": 39, "training_loss": 0.6953796100616455, "training_acc": 51.0, "val_loss": 0.6930943655967713, "val_acc": 52.0}
{"epoch": 40, "training_loss": 0.6879376077651977, "training_acc": 53.0, "val_loss": 0.6979337024688721, "val_acc": 52.0}
{"epoch": 41, "training_loss": 0.6939747524261475, "training_acc": 53.0, "val_loss": 0.6939922976493835, "val_acc": 52.0}
{"epoch": 42, "training_loss": 0.6910527682304383, "training_acc": 48.0, "val_loss": 0.6930749154090882, "val_acc": 44.0}
{"epoch": 43, "training_loss": 0.6863385915756226, "training_acc": 67.0, "val_loss": 0.6962470817565918, "val_acc": 52.0}
{"epoch": 44, "training_loss": 0.7149833941459656, "training_acc": 53.0, "val_loss": 0.7307210826873779, "val_acc": 52.0}
{"epoch": 45, "training_loss": 0.7167825841903687, "training_acc": 53.0, "val_loss": 0.6925170207023621, "val_acc": 52.0}
{"epoch": 46, "training_loss": 0.6890234851837158, "training_acc": 53.0, "val_loss": 0.6921161556243897, "val_acc": 52.0}
{"epoch": 47, "training_loss": 0.6950690746307373, "training_acc": 45.0, "val_loss": 0.6936652445793152, "val_acc": 48.0}
{"epoch": 48, "training_loss": 0.6950907897949219, "training_acc": 50.0, "val_loss": 0.6923134422302246, "val_acc": 48.0}
{"epoch": 49, "training_loss": 0.6870502424240112, "training_acc": 54.0, "val_loss": 0.6933207583427429, "val_acc": 52.0}
{"epoch": 50, "training_loss": 0.6891218709945679, "training_acc": 53.0, "val_loss": 0.6935392045974731, "val_acc": 52.0}
{"epoch": 51, "training_loss": 0.6913196420669556, "training_acc": 53.0, "val_loss": 0.6935848665237426, "val_acc": 52.0}
{"epoch": 52, "training_loss": 0.6938243055343628, "training_acc": 53.0, "val_loss": 0.704898681640625, "val_acc": 52.0}
{"epoch": 53, "training_loss": 0.7072965359687805, "training_acc": 54.0, "val_loss": 0.6924784684181213, "val_acc": 56.0}
{"epoch": 54, "training_loss": 0.6931975722312927, "training_acc": 53.0, "val_loss": 0.6961945581436157, "val_acc": 52.0}
{"epoch": 55, "training_loss": 0.69971186876297, "training_acc": 53.0, "val_loss": 0.7042617392539978, "val_acc": 52.0}
{"epoch": 56, "training_loss": 0.6961290311813354, "training_acc": 53.0, "val_loss": 0.6947455620765686, "val_acc": 52.0}
{"epoch": 57, "training_loss": 0.7092256283760071, "training_acc": 39.0, "val_loss": 0.6969569087028503, "val_acc": 48.0}
{"epoch": 58, "training_loss": 0.6896033811569214, "training_acc": 55.0, "val_loss": 0.7048779034614563, "val_acc": 52.0}
{"epoch": 59, "training_loss": 0.7142198753356933, "training_acc": 53.0, "val_loss": 0.7049450635910034, "val_acc": 52.0}
{"epoch": 60, "training_loss": 0.6882829213142395, "training_acc": 58.0, "val_loss": 0.6952612805366516, "val_acc": 48.0}
{"epoch": 61, "training_loss": 0.694179756641388, "training_acc": 47.0, "val_loss": 0.6918204593658447, "val_acc": 52.0}
{"epoch": 62, "training_loss": 0.6886081457138061, "training_acc": 56.0, "val_loss": 0.7060319519042969, "val_acc": 52.0}
{"epoch": 63, "training_loss": 0.6905647850036621, "training_acc": 53.0, "val_loss": 0.6913590717315674, "val_acc": 52.0}
{"epoch": 64, "training_loss": 0.684822006225586, "training_acc": 57.0, "val_loss": 0.6936483073234558, "val_acc": 48.0}
{"epoch": 65, "training_loss": 0.6963494062423706, "training_acc": 47.0, "val_loss": 0.6941963195800781, "val_acc": 48.0}
{"epoch": 66, "training_loss": 0.68961585521698, "training_acc": 50.0, "val_loss": 0.6919340896606445, "val_acc": 56.0}
{"epoch": 67, "training_loss": 0.6912641382217407, "training_acc": 50.0, "val_loss": 0.6915401005744934, "val_acc": 52.0}
{"epoch": 68, "training_loss": 0.692718288898468, "training_acc": 54.0, "val_loss": 0.71087144613266, "val_acc": 52.0}
{"epoch": 69, "training_loss": 0.6932638621330262, "training_acc": 53.0, "val_loss": 0.6932592844963074, "val_acc": 48.0}
{"epoch": 70, "training_loss": 0.6928146886825561, "training_acc": 45.0, "val_loss": 0.6910168385505676, "val_acc": 52.0}
{"epoch": 71, "training_loss": 0.6862060093879699, "training_acc": 54.0, "val_loss": 0.6911172604560852, "val_acc": 52.0}
{"epoch": 72, "training_loss": 0.6952946782112122, "training_acc": 53.0, "val_loss": 0.6937423491477966, "val_acc": 52.0}
{"epoch": 73, "training_loss": 0.6826310563087463, "training_acc": 55.0, "val_loss": 0.69404554605484, "val_acc": 48.0}
{"epoch": 74, "training_loss": 0.7048856401443482, "training_acc": 47.0, "val_loss": 0.6963414597511292, "val_acc": 48.0}
{"epoch": 75, "training_loss": 0.6895332908630372, "training_acc": 53.0, "val_loss": 0.6918760895729065, "val_acc": 52.0}
{"epoch": 76, "training_loss": 0.6865526938438415, "training_acc": 54.0, "val_loss": 0.6907910561561584, "val_acc": 52.0}
{"epoch": 77, "training_loss": 0.6840975546836853, "training_acc": 54.0, "val_loss": 0.6908281397819519, "val_acc": 52.0}
{"epoch": 78, "training_loss": 0.6837627816200257, "training_acc": 53.0, "val_loss": 0.6912972760200501, "val_acc": 52.0}
{"epoch": 79, "training_loss": 0.6854429507255554, "training_acc": 55.0, "val_loss": 0.6906412529945374, "val_acc": 52.0}
{"epoch": 80, "training_loss": 0.6835031414031982, "training_acc": 55.0, "val_loss": 0.6907571172714233, "val_acc": 52.0}
{"epoch": 81, "training_loss": 0.6829516744613647, "training_acc": 53.0, "val_loss": 0.6908051371574402, "val_acc": 52.0}
{"epoch": 82, "training_loss": 0.7089254760742187, "training_acc": 37.0, "val_loss": 0.6930954813957214, "val_acc": 48.0}
{"epoch": 83, "training_loss": 0.6926395654678345, "training_acc": 53.0, "val_loss": 0.6991087913513183, "val_acc": 52.0}
{"epoch": 84, "training_loss": 0.6794581127166748, "training_acc": 53.0, "val_loss": 0.6917393803596497, "val_acc": 52.0}
{"epoch": 85, "training_loss": 0.6917160201072693, "training_acc": 48.0, "val_loss": 0.7014379525184631, "val_acc": 48.0}
{"epoch": 86, "training_loss": 0.6938573026657104, "training_acc": 47.0, "val_loss": 0.6934159135818482, "val_acc": 52.0}
{"epoch": 87, "training_loss": 0.6849872255325318, "training_acc": 53.0, "val_loss": 0.6911998176574707, "val_acc": 52.0}
{"epoch": 88, "training_loss": 0.6800221037864685, "training_acc": 60.0, "val_loss": 0.6915201067924499, "val_acc": 56.0}
{"epoch": 89, "training_loss": 0.684884536266327, "training_acc": 59.0, "val_loss": 0.6914779686927796, "val_acc": 52.0}
{"epoch": 90, "training_loss": 0.6944905233383178, "training_acc": 53.0, "val_loss": 0.7055637311935424, "val_acc": 52.0}
{"epoch": 91, "training_loss": 0.6859785985946655, "training_acc": 55.0, "val_loss": 0.6915221405029297, "val_acc": 56.0}
{"epoch": 92, "training_loss": 0.6898807907104492, "training_acc": 50.0, "val_loss": 0.6914237451553344, "val_acc": 52.0}
{"epoch": 93, "training_loss": 0.6812560510635376, "training_acc": 66.0, "val_loss": 0.6936696219444275, "val_acc": 52.0}
{"epoch": 94, "training_loss": 0.6874415898323059, "training_acc": 53.0, "val_loss": 0.6912180781364441, "val_acc": 52.0}
{"epoch": 95, "training_loss": 0.6848754215240479, "training_acc": 53.0, "val_loss": 0.6960394787788391, "val_acc": 52.0}
{"epoch": 96, "training_loss": 0.6883774209022522, "training_acc": 53.0, "val_loss": 0.6935078024864196, "val_acc": 52.0}
{"epoch": 97, "training_loss": 0.6853018617630005, "training_acc": 53.0, "val_loss": 0.6929913711547852, "val_acc": 52.0}
{"epoch": 98, "training_loss": 0.6956158757209778, "training_acc": 53.0, "val_loss": 0.6932017636299134, "val_acc": 52.0}
