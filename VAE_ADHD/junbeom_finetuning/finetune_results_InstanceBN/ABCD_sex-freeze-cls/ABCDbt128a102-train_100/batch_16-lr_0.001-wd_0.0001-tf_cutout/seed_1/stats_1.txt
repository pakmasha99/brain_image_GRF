"main_modify.py --pretrained_path /scratch/connectome/dyhan316/VAE_ADHD/barlowtwins/pretrain_results/ABCDbt128a102.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 1 --task ABCD_sex --input_option BT_org --learning_rate 1e-3 --batch_size 16 --weight_decay 1e-4 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 0.7006801652908325, "training_acc": 47.0, "val_loss": 0.6936527585983276, "val_acc": 48.0}
{"epoch": 1, "training_loss": 0.6968129682540893, "training_acc": 50.0, "val_loss": 0.6928911328315734, "val_acc": 52.0}
{"epoch": 2, "training_loss": 0.6918246269226074, "training_acc": 52.0, "val_loss": 0.6926203203201294, "val_acc": 60.0}
{"epoch": 3, "training_loss": 0.7066346144676209, "training_acc": 46.0, "val_loss": 0.6921860218048096, "val_acc": 52.0}
{"epoch": 4, "training_loss": 0.7362388634681701, "training_acc": 53.0, "val_loss": 0.7271406626701356, "val_acc": 52.0}
{"epoch": 5, "training_loss": 0.68764151096344, "training_acc": 52.0, "val_loss": 0.698914840221405, "val_acc": 48.0}
{"epoch": 6, "training_loss": 0.710174388885498, "training_acc": 47.0, "val_loss": 0.7041226410865784, "val_acc": 48.0}
{"epoch": 7, "training_loss": 0.7002391719818115, "training_acc": 47.0, "val_loss": 0.693430302143097, "val_acc": 52.0}
{"epoch": 8, "training_loss": 0.6904059958457947, "training_acc": 53.0, "val_loss": 0.6923096966743469, "val_acc": 52.0}
{"epoch": 9, "training_loss": 0.7020409226417541, "training_acc": 53.0, "val_loss": 0.7021518611907959, "val_acc": 52.0}
{"epoch": 10, "training_loss": 0.6889076948165893, "training_acc": 53.0, "val_loss": 0.693321762084961, "val_acc": 52.0}
{"epoch": 11, "training_loss": 0.709286904335022, "training_acc": 46.0, "val_loss": 0.6960506772994995, "val_acc": 48.0}
{"epoch": 12, "training_loss": 0.6907728958129883, "training_acc": 48.0, "val_loss": 0.6922902989387513, "val_acc": 52.0}
{"epoch": 13, "training_loss": 0.7031298542022705, "training_acc": 53.0, "val_loss": 0.6980931568145752, "val_acc": 52.0}
{"epoch": 14, "training_loss": 0.6918601179122925, "training_acc": 54.0, "val_loss": 0.6947362017631531, "val_acc": 48.0}
{"epoch": 15, "training_loss": 0.7029210448265075, "training_acc": 47.0, "val_loss": 0.6932091331481933, "val_acc": 40.0}
{"epoch": 16, "training_loss": 0.687960033416748, "training_acc": 61.0, "val_loss": 0.7063725113868713, "val_acc": 52.0}
{"epoch": 17, "training_loss": 0.7013410019874573, "training_acc": 53.0, "val_loss": 0.6923143720626831, "val_acc": 56.0}
{"epoch": 18, "training_loss": 0.6960250234603882, "training_acc": 53.0, "val_loss": 0.6921746230125427, "val_acc": 52.0}
{"epoch": 19, "training_loss": 0.6935040307044983, "training_acc": 49.0, "val_loss": 0.6929273343086243, "val_acc": 40.0}
{"epoch": 20, "training_loss": 0.6895519423484803, "training_acc": 51.0, "val_loss": 0.6954627370834351, "val_acc": 52.0}
{"epoch": 21, "training_loss": 0.6888890647888184, "training_acc": 53.0, "val_loss": 0.693576967716217, "val_acc": 52.0}
{"epoch": 22, "training_loss": 0.6892093777656555, "training_acc": 52.0, "val_loss": 0.6921869277954101, "val_acc": 52.0}
{"epoch": 23, "training_loss": 0.6970023679733276, "training_acc": 53.0, "val_loss": 0.6940888619422912, "val_acc": 52.0}
{"epoch": 24, "training_loss": 0.7023909664154053, "training_acc": 50.0, "val_loss": 0.6985820889472961, "val_acc": 48.0}
{"epoch": 25, "training_loss": 0.6843332862854004, "training_acc": 56.0, "val_loss": 0.6984977340698242, "val_acc": 52.0}
{"epoch": 26, "training_loss": 0.6980666708946228, "training_acc": 48.0, "val_loss": 0.692540488243103, "val_acc": 56.0}
{"epoch": 27, "training_loss": 0.6874485683441162, "training_acc": 58.0, "val_loss": 0.6943666124343872, "val_acc": 52.0}
{"epoch": 28, "training_loss": 0.6913154172897339, "training_acc": 53.0, "val_loss": 0.6957580614089965, "val_acc": 52.0}
{"epoch": 29, "training_loss": 0.6935607528686524, "training_acc": 48.0, "val_loss": 0.6945405459403992, "val_acc": 48.0}
{"epoch": 30, "training_loss": 0.6900782227516175, "training_acc": 51.0, "val_loss": 0.6935475850105286, "val_acc": 52.0}
{"epoch": 31, "training_loss": 0.6867812991142273, "training_acc": 53.0, "val_loss": 0.6930111360549926, "val_acc": 52.0}
{"epoch": 32, "training_loss": 0.7059363532066345, "training_acc": 42.0, "val_loss": 0.6940556073188782, "val_acc": 48.0}
{"epoch": 33, "training_loss": 0.6923528170585632, "training_acc": 49.0, "val_loss": 0.6978841757774353, "val_acc": 52.0}
{"epoch": 34, "training_loss": 0.6947768378257752, "training_acc": 53.0, "val_loss": 0.6942425680160522, "val_acc": 52.0}
{"epoch": 35, "training_loss": 0.6829988384246826, "training_acc": 60.0, "val_loss": 0.6969315695762635, "val_acc": 48.0}
{"epoch": 36, "training_loss": 0.694688172340393, "training_acc": 47.0, "val_loss": 0.6953162479400635, "val_acc": 48.0}
{"epoch": 37, "training_loss": 0.687535662651062, "training_acc": 50.0, "val_loss": 0.696490375995636, "val_acc": 52.0}
