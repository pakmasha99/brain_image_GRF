"main_modify.py --pretrained_path /scratch/connectome/dyhan316/VAE_ADHD/barlowtwins/pretrain_results/ABCDbt128a102.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 2 --task ABCD_sex --input_option BT_org --learning_rate 1e-3 --batch_size 16 --weight_decay 1e-4 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 0.7257666254043579, "training_acc": 43.0, "val_loss": 0.6931812596321106, "val_acc": 52.0}
{"epoch": 1, "training_loss": 0.7104957342147827, "training_acc": 49.0, "val_loss": 0.7091238856315613, "val_acc": 52.0}
{"epoch": 2, "training_loss": 0.7006743764877319, "training_acc": 53.0, "val_loss": 0.6918124413490295, "val_acc": 52.0}
{"epoch": 3, "training_loss": 0.6926687455177307, "training_acc": 53.0, "val_loss": 0.6918758368492126, "val_acc": 52.0}
{"epoch": 4, "training_loss": 0.6925495338439941, "training_acc": 53.0, "val_loss": 0.6916957783699036, "val_acc": 52.0}
{"epoch": 5, "training_loss": 0.6910199451446534, "training_acc": 53.0, "val_loss": 0.6916210579872132, "val_acc": 52.0}
{"epoch": 6, "training_loss": 0.6957143878936768, "training_acc": 48.0, "val_loss": 0.6928258228302002, "val_acc": 52.0}
{"epoch": 7, "training_loss": 0.7077154207229615, "training_acc": 53.0, "val_loss": 0.7200221037864685, "val_acc": 52.0}
{"epoch": 8, "training_loss": 0.7064825248718262, "training_acc": 53.0, "val_loss": 0.6913168716430664, "val_acc": 52.0}
{"epoch": 9, "training_loss": 0.6927275824546814, "training_acc": 53.0, "val_loss": 0.69143239736557, "val_acc": 52.0}
{"epoch": 10, "training_loss": 0.6912722826004029, "training_acc": 49.0, "val_loss": 0.6920143818855286, "val_acc": 60.0}
{"epoch": 11, "training_loss": 0.6946424007415771, "training_acc": 47.0, "val_loss": 0.6912714791297913, "val_acc": 52.0}
{"epoch": 12, "training_loss": 0.6924449491500855, "training_acc": 53.0, "val_loss": 0.6973066234588623, "val_acc": 52.0}
{"epoch": 13, "training_loss": 0.702092387676239, "training_acc": 43.0, "val_loss": 0.6930043435096741, "val_acc": 48.0}
{"epoch": 14, "training_loss": 0.7002430057525635, "training_acc": 47.0, "val_loss": 0.692977967262268, "val_acc": 48.0}
{"epoch": 15, "training_loss": 0.6959889626502991, "training_acc": 51.0, "val_loss": 0.7036282658576966, "val_acc": 52.0}
{"epoch": 16, "training_loss": 0.6950811076164246, "training_acc": 53.0, "val_loss": 0.6909529900550843, "val_acc": 52.0}
{"epoch": 17, "training_loss": 0.6997951221466064, "training_acc": 45.0, "val_loss": 0.6940542101860047, "val_acc": 48.0}
{"epoch": 18, "training_loss": 0.6876764845848083, "training_acc": 59.0, "val_loss": 0.6941899585723877, "val_acc": 52.0}
{"epoch": 19, "training_loss": 0.7009122085571289, "training_acc": 53.0, "val_loss": 0.6933411407470703, "val_acc": 52.0}
{"epoch": 20, "training_loss": 0.7020875144004822, "training_acc": 47.0, "val_loss": 0.7133033657073975, "val_acc": 48.0}
{"epoch": 21, "training_loss": 0.7016014671325683, "training_acc": 51.0, "val_loss": 0.6918176341056824, "val_acc": 52.0}
{"epoch": 22, "training_loss": 0.6918661499023437, "training_acc": 53.0, "val_loss": 0.6952521443367005, "val_acc": 52.0}
{"epoch": 23, "training_loss": 0.6899954557418824, "training_acc": 58.0, "val_loss": 0.6929892158508301, "val_acc": 48.0}
{"epoch": 24, "training_loss": 0.6930804252624512, "training_acc": 48.0, "val_loss": 0.6903874635696411, "val_acc": 52.0}
{"epoch": 25, "training_loss": 0.6868740439414978, "training_acc": 53.0, "val_loss": 0.6930553150177002, "val_acc": 52.0}
{"epoch": 26, "training_loss": 0.6947330951690673, "training_acc": 50.0, "val_loss": 0.6904051589965821, "val_acc": 56.0}
{"epoch": 27, "training_loss": 0.7003859686851501, "training_acc": 54.0, "val_loss": 0.6961308026313782, "val_acc": 52.0}
{"epoch": 28, "training_loss": 0.6903013706207275, "training_acc": 53.0, "val_loss": 0.6936204051971435, "val_acc": 48.0}
{"epoch": 29, "training_loss": 0.6889792060852051, "training_acc": 50.0, "val_loss": 0.6929594159126282, "val_acc": 52.0}
{"epoch": 30, "training_loss": 0.6915685677528381, "training_acc": 53.0, "val_loss": 0.6943911933898925, "val_acc": 52.0}
{"epoch": 31, "training_loss": 0.687776255607605, "training_acc": 53.0, "val_loss": 0.689872899055481, "val_acc": 52.0}
{"epoch": 32, "training_loss": 0.6883784866333008, "training_acc": 53.0, "val_loss": 0.6896479463577271, "val_acc": 52.0}
{"epoch": 33, "training_loss": 0.6909615612030029, "training_acc": 53.0, "val_loss": 0.6902400636672974, "val_acc": 52.0}
{"epoch": 34, "training_loss": 0.6849398565292358, "training_acc": 53.0, "val_loss": 0.700005099773407, "val_acc": 52.0}
{"epoch": 35, "training_loss": 0.692695324420929, "training_acc": 53.0, "val_loss": 0.6929962086677551, "val_acc": 52.0}
{"epoch": 36, "training_loss": 0.6859130430221557, "training_acc": 55.0, "val_loss": 0.6895861220359802, "val_acc": 52.0}
{"epoch": 37, "training_loss": 0.6894980907440186, "training_acc": 54.0, "val_loss": 0.6921031546592712, "val_acc": 52.0}
{"epoch": 38, "training_loss": 0.6920171117782593, "training_acc": 53.0, "val_loss": 0.6890149569511413, "val_acc": 52.0}
{"epoch": 39, "training_loss": 0.6907963085174561, "training_acc": 48.0, "val_loss": 0.6889236426353454, "val_acc": 52.0}
{"epoch": 40, "training_loss": 0.6888114023208618, "training_acc": 53.0, "val_loss": 0.6950249886512756, "val_acc": 52.0}
{"epoch": 41, "training_loss": 0.7021247005462646, "training_acc": 53.0, "val_loss": 0.6918799257278443, "val_acc": 52.0}
{"epoch": 42, "training_loss": 0.6968540334701538, "training_acc": 45.0, "val_loss": 0.7000869464874268, "val_acc": 48.0}
{"epoch": 43, "training_loss": 0.6976304650306702, "training_acc": 49.0, "val_loss": 0.7014522123336792, "val_acc": 52.0}
{"epoch": 44, "training_loss": 0.6943326592445374, "training_acc": 53.0, "val_loss": 0.693913278579712, "val_acc": 52.0}
{"epoch": 45, "training_loss": 0.688471052646637, "training_acc": 53.0, "val_loss": 0.6890781164169312, "val_acc": 52.0}
{"epoch": 46, "training_loss": 0.6889429807662963, "training_acc": 59.0, "val_loss": 0.6891937255859375, "val_acc": 52.0}
{"epoch": 47, "training_loss": 0.7189362859725952, "training_acc": 53.0, "val_loss": 0.6991224765777588, "val_acc": 52.0}
{"epoch": 48, "training_loss": 0.6907123708724976, "training_acc": 52.0, "val_loss": 0.7184882402420044, "val_acc": 48.0}
{"epoch": 49, "training_loss": 0.7100410842895508, "training_acc": 48.0, "val_loss": 0.6892329740524292, "val_acc": 52.0}
{"epoch": 50, "training_loss": 0.7001211404800415, "training_acc": 53.0, "val_loss": 0.697762804031372, "val_acc": 52.0}
{"epoch": 51, "training_loss": 0.6990220952033996, "training_acc": 53.0, "val_loss": 0.704817898273468, "val_acc": 48.0}
{"epoch": 52, "training_loss": 0.6808904218673706, "training_acc": 57.0, "val_loss": 0.7039083409309387, "val_acc": 52.0}
{"epoch": 53, "training_loss": 0.7394839239120483, "training_acc": 53.0, "val_loss": 0.7068058776855469, "val_acc": 52.0}
{"epoch": 54, "training_loss": 0.6973178195953369, "training_acc": 53.0, "val_loss": 0.7239032483100891, "val_acc": 48.0}
{"epoch": 55, "training_loss": 0.7219519448280335, "training_acc": 47.0, "val_loss": 0.6900104236602783, "val_acc": 52.0}
{"epoch": 56, "training_loss": 0.6824630403518677, "training_acc": 56.0, "val_loss": 0.6972068905830383, "val_acc": 52.0}
{"epoch": 57, "training_loss": 0.6992120695114136, "training_acc": 53.0, "val_loss": 0.6923537492752075, "val_acc": 52.0}
{"epoch": 58, "training_loss": 0.7278502082824707, "training_acc": 42.0, "val_loss": 0.7095080327987671, "val_acc": 48.0}
