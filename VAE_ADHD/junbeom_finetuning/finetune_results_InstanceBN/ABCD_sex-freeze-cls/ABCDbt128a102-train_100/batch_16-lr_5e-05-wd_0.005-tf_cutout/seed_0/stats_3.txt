"main_modify.py --pretrained_path /scratch/connectome/dyhan316/VAE_ADHD/barlowtwins/pretrain_results/ABCDbt128a102.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option BT_org --learning_rate 5e-5 --batch_size 16 --weight_decay 5e-3 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 0.6916815376281739, "training_acc": 53.0, "val_loss": 0.6921052193641662, "val_acc": 52.0}
{"epoch": 1, "training_loss": 0.6927492928504944, "training_acc": 53.0, "val_loss": 0.69258633852005, "val_acc": 52.0}
{"epoch": 2, "training_loss": 0.6912772703170776, "training_acc": 53.0, "val_loss": 0.6925021982192994, "val_acc": 52.0}
{"epoch": 3, "training_loss": 0.6916935229301453, "training_acc": 53.0, "val_loss": 0.6926764941215515, "val_acc": 52.0}
{"epoch": 4, "training_loss": 0.6912101936340332, "training_acc": 53.0, "val_loss": 0.6925855278968811, "val_acc": 52.0}
{"epoch": 5, "training_loss": 0.6912938141822815, "training_acc": 53.0, "val_loss": 0.692529067993164, "val_acc": 52.0}
{"epoch": 6, "training_loss": 0.6919287085533142, "training_acc": 53.0, "val_loss": 0.6924126076698304, "val_acc": 52.0}
{"epoch": 7, "training_loss": 0.6912836694717407, "training_acc": 53.0, "val_loss": 0.6925640606880188, "val_acc": 52.0}
{"epoch": 8, "training_loss": 0.6910209846496582, "training_acc": 53.0, "val_loss": 0.6927908325195312, "val_acc": 52.0}
{"epoch": 9, "training_loss": 0.6910901141166687, "training_acc": 53.0, "val_loss": 0.692646918296814, "val_acc": 52.0}
{"epoch": 10, "training_loss": 0.6914604568481445, "training_acc": 53.0, "val_loss": 0.6929155850410461, "val_acc": 52.0}
{"epoch": 11, "training_loss": 0.6911491346359253, "training_acc": 53.0, "val_loss": 0.6925924301147461, "val_acc": 52.0}
{"epoch": 12, "training_loss": 0.6909034657478332, "training_acc": 53.0, "val_loss": 0.692394027709961, "val_acc": 52.0}
{"epoch": 13, "training_loss": 0.6910212349891662, "training_acc": 53.0, "val_loss": 0.6921596455574036, "val_acc": 52.0}
{"epoch": 14, "training_loss": 0.6923877382278443, "training_acc": 53.0, "val_loss": 0.6919514775276184, "val_acc": 52.0}
{"epoch": 15, "training_loss": 0.6911998295783996, "training_acc": 53.0, "val_loss": 0.6919641661643982, "val_acc": 52.0}
{"epoch": 16, "training_loss": 0.6913177299499512, "training_acc": 53.0, "val_loss": 0.6919844198226929, "val_acc": 52.0}
{"epoch": 17, "training_loss": 0.6911903715133667, "training_acc": 53.0, "val_loss": 0.6921023631095886, "val_acc": 52.0}
{"epoch": 18, "training_loss": 0.6910333108901977, "training_acc": 53.0, "val_loss": 0.6921597981452942, "val_acc": 52.0}
{"epoch": 19, "training_loss": 0.6910508489608764, "training_acc": 53.0, "val_loss": 0.6921241784095764, "val_acc": 52.0}
{"epoch": 20, "training_loss": 0.6910806488990784, "training_acc": 53.0, "val_loss": 0.6922066617012024, "val_acc": 52.0}
{"epoch": 21, "training_loss": 0.6913248085975647, "training_acc": 53.0, "val_loss": 0.6922379970550537, "val_acc": 52.0}
{"epoch": 22, "training_loss": 0.6910434699058533, "training_acc": 53.0, "val_loss": 0.6922598052024841, "val_acc": 52.0}
{"epoch": 23, "training_loss": 0.6909081721305848, "training_acc": 53.0, "val_loss": 0.6926430988311768, "val_acc": 52.0}
{"epoch": 24, "training_loss": 0.69206698179245, "training_acc": 53.0, "val_loss": 0.6929164481163025, "val_acc": 52.0}
{"epoch": 25, "training_loss": 0.6913339185714722, "training_acc": 53.0, "val_loss": 0.6923601841926574, "val_acc": 52.0}
{"epoch": 26, "training_loss": 0.6911820602416993, "training_acc": 53.0, "val_loss": 0.692076005935669, "val_acc": 52.0}
{"epoch": 27, "training_loss": 0.6908077788352966, "training_acc": 53.0, "val_loss": 0.6919876956939697, "val_acc": 52.0}
{"epoch": 28, "training_loss": 0.6911449241638183, "training_acc": 53.0, "val_loss": 0.6919597625732422, "val_acc": 52.0}
{"epoch": 29, "training_loss": 0.6915880084037781, "training_acc": 53.0, "val_loss": 0.6920045280456543, "val_acc": 52.0}
{"epoch": 30, "training_loss": 0.691142578125, "training_acc": 53.0, "val_loss": 0.6921543192863464, "val_acc": 52.0}
{"epoch": 31, "training_loss": 0.6913858628273011, "training_acc": 53.0, "val_loss": 0.6924951577186584, "val_acc": 52.0}
{"epoch": 32, "training_loss": 0.6909535932540893, "training_acc": 53.0, "val_loss": 0.6924276280403138, "val_acc": 52.0}
{"epoch": 33, "training_loss": 0.6910959386825561, "training_acc": 53.0, "val_loss": 0.6925246787071228, "val_acc": 52.0}
