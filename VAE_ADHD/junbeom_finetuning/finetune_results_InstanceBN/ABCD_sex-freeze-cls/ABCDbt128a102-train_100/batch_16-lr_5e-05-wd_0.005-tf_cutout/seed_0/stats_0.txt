"main_modify.py --pretrained_path /scratch/connectome/dyhan316/VAE_ADHD/barlowtwins/pretrain_results/ABCDbt128a102.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option BT_org --learning_rate 5e-5 --batch_size 16 --weight_decay 5e-3 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 0.6926230525970459, "training_acc": 52.0, "val_loss": 0.6882298898696899, "val_acc": 56.0}
{"epoch": 1, "training_loss": 0.6925427722930908, "training_acc": 52.0, "val_loss": 0.6877985763549804, "val_acc": 56.0}
{"epoch": 2, "training_loss": 0.692525544166565, "training_acc": 52.0, "val_loss": 0.6877724146842956, "val_acc": 56.0}
{"epoch": 3, "training_loss": 0.6924540543556214, "training_acc": 52.0, "val_loss": 0.6869505000114441, "val_acc": 56.0}
{"epoch": 4, "training_loss": 0.6925042390823364, "training_acc": 52.0, "val_loss": 0.6873589205741882, "val_acc": 56.0}
{"epoch": 5, "training_loss": 0.692176342010498, "training_acc": 52.0, "val_loss": 0.6870097446441651, "val_acc": 56.0}
{"epoch": 6, "training_loss": 0.69208829164505, "training_acc": 52.0, "val_loss": 0.6869346928596497, "val_acc": 56.0}
{"epoch": 7, "training_loss": 0.69229576587677, "training_acc": 52.0, "val_loss": 0.6872950053215027, "val_acc": 56.0}
{"epoch": 8, "training_loss": 0.6923001646995545, "training_acc": 52.0, "val_loss": 0.6869106340408325, "val_acc": 56.0}
{"epoch": 9, "training_loss": 0.6922567820549012, "training_acc": 52.0, "val_loss": 0.6873954892158508, "val_acc": 56.0}
{"epoch": 10, "training_loss": 0.6922666549682617, "training_acc": 52.0, "val_loss": 0.6884789419174194, "val_acc": 56.0}
{"epoch": 11, "training_loss": 0.6920295834541321, "training_acc": 52.0, "val_loss": 0.6883956527709961, "val_acc": 56.0}
{"epoch": 12, "training_loss": 0.693259711265564, "training_acc": 52.0, "val_loss": 0.6870083642005921, "val_acc": 56.0}
{"epoch": 13, "training_loss": 0.6919250345230102, "training_acc": 52.0, "val_loss": 0.6868400883674621, "val_acc": 56.0}
{"epoch": 14, "training_loss": 0.692283296585083, "training_acc": 52.0, "val_loss": 0.6863597083091736, "val_acc": 56.0}
{"epoch": 15, "training_loss": 0.6924384689331055, "training_acc": 52.0, "val_loss": 0.6862752532958984, "val_acc": 56.0}
{"epoch": 16, "training_loss": 0.6932340693473816, "training_acc": 52.0, "val_loss": 0.6854988837242126, "val_acc": 56.0}
{"epoch": 17, "training_loss": 0.6922781705856323, "training_acc": 52.0, "val_loss": 0.6859397864341736, "val_acc": 56.0}
{"epoch": 18, "training_loss": 0.6922663760185241, "training_acc": 52.0, "val_loss": 0.6867133665084839, "val_acc": 56.0}
{"epoch": 19, "training_loss": 0.6923373460769653, "training_acc": 52.0, "val_loss": 0.687804594039917, "val_acc": 56.0}
{"epoch": 20, "training_loss": 0.6923155379295349, "training_acc": 52.0, "val_loss": 0.6879423832893372, "val_acc": 56.0}
{"epoch": 21, "training_loss": 0.6917879652976989, "training_acc": 52.0, "val_loss": 0.6881256461143493, "val_acc": 56.0}
{"epoch": 22, "training_loss": 0.6920890998840332, "training_acc": 52.0, "val_loss": 0.6877420139312744, "val_acc": 56.0}
{"epoch": 23, "training_loss": 0.6920156478881836, "training_acc": 52.0, "val_loss": 0.6879160332679749, "val_acc": 56.0}
{"epoch": 24, "training_loss": 0.6926762843132019, "training_acc": 52.0, "val_loss": 0.6871235704421997, "val_acc": 56.0}
{"epoch": 25, "training_loss": 0.6922379493713379, "training_acc": 52.0, "val_loss": 0.6874209308624267, "val_acc": 56.0}
{"epoch": 26, "training_loss": 0.6917873811721802, "training_acc": 52.0, "val_loss": 0.6873620390892029, "val_acc": 56.0}
{"epoch": 27, "training_loss": 0.6917446088790894, "training_acc": 52.0, "val_loss": 0.6877027106285095, "val_acc": 56.0}
{"epoch": 28, "training_loss": 0.6921617317199708, "training_acc": 52.0, "val_loss": 0.6877955174446106, "val_acc": 56.0}
{"epoch": 29, "training_loss": 0.6921262741088867, "training_acc": 52.0, "val_loss": 0.687273554801941, "val_acc": 56.0}
{"epoch": 30, "training_loss": 0.6925531220436096, "training_acc": 52.0, "val_loss": 0.6860487747192383, "val_acc": 56.0}
{"epoch": 31, "training_loss": 0.69207266330719, "training_acc": 52.0, "val_loss": 0.6856573891639709, "val_acc": 56.0}
{"epoch": 32, "training_loss": 0.6924078607559204, "training_acc": 52.0, "val_loss": 0.6848970341682434, "val_acc": 56.0}
{"epoch": 33, "training_loss": 0.693154149055481, "training_acc": 52.0, "val_loss": 0.6847095799446106, "val_acc": 56.0}
{"epoch": 34, "training_loss": 0.6931253576278686, "training_acc": 52.0, "val_loss": 0.6850190782546997, "val_acc": 56.0}
{"epoch": 35, "training_loss": 0.6922313117980957, "training_acc": 52.0, "val_loss": 0.6857650780677795, "val_acc": 56.0}
{"epoch": 36, "training_loss": 0.6927072334289551, "training_acc": 52.0, "val_loss": 0.6860452747344971, "val_acc": 56.0}
{"epoch": 37, "training_loss": 0.692763307094574, "training_acc": 52.0, "val_loss": 0.6860712575912475, "val_acc": 56.0}
{"epoch": 38, "training_loss": 0.6927397632598877, "training_acc": 52.0, "val_loss": 0.6864679789543152, "val_acc": 56.0}
{"epoch": 39, "training_loss": 0.6923238611221314, "training_acc": 52.0, "val_loss": 0.686875262260437, "val_acc": 56.0}
{"epoch": 40, "training_loss": 0.6925602579116821, "training_acc": 52.0, "val_loss": 0.6877329587936402, "val_acc": 56.0}
{"epoch": 41, "training_loss": 0.6918014812469483, "training_acc": 52.0, "val_loss": 0.6878715991973877, "val_acc": 56.0}
{"epoch": 42, "training_loss": 0.6917405533790588, "training_acc": 52.0, "val_loss": 0.68794189453125, "val_acc": 56.0}
{"epoch": 43, "training_loss": 0.6916811442375184, "training_acc": 52.0, "val_loss": 0.6880007147789001, "val_acc": 56.0}
{"epoch": 44, "training_loss": 0.6925263643264771, "training_acc": 52.0, "val_loss": 0.689018292427063, "val_acc": 56.0}
{"epoch": 45, "training_loss": 0.6920649409294128, "training_acc": 52.0, "val_loss": 0.689103434085846, "val_acc": 56.0}
{"epoch": 46, "training_loss": 0.6917913055419922, "training_acc": 52.0, "val_loss": 0.6889094400405884, "val_acc": 56.0}
{"epoch": 47, "training_loss": 0.6922367548942566, "training_acc": 52.0, "val_loss": 0.6883376407623291, "val_acc": 56.0}
{"epoch": 48, "training_loss": 0.6921793627738952, "training_acc": 52.0, "val_loss": 0.6877810692787171, "val_acc": 56.0}
{"epoch": 49, "training_loss": 0.6918615317344665, "training_acc": 52.0, "val_loss": 0.687949640750885, "val_acc": 56.0}
{"epoch": 50, "training_loss": 0.6923795676231385, "training_acc": 52.0, "val_loss": 0.6888546776771546, "val_acc": 56.0}
{"epoch": 51, "training_loss": 0.6923127388954162, "training_acc": 52.0, "val_loss": 0.689792251586914, "val_acc": 56.0}
{"epoch": 52, "training_loss": 0.6927200245857239, "training_acc": 51.0, "val_loss": 0.6908409833908081, "val_acc": 56.0}
