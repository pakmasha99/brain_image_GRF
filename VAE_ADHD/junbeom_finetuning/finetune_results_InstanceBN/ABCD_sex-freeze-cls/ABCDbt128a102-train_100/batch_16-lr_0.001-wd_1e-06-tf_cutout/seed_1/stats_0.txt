"main_modify.py --pretrained_path /scratch/connectome/dyhan316/VAE_ADHD/barlowtwins/pretrain_results/ABCDbt128a102.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 1 --task ABCD_sex --input_option BT_org --learning_rate 1e-3 --batch_size 16 --weight_decay 1e-6 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 0.7076517748832702, "training_acc": 47.0, "val_loss": 0.7106386613845825, "val_acc": 52.0}
{"epoch": 1, "training_loss": 0.7310206031799317, "training_acc": 53.0, "val_loss": 0.7053261876106263, "val_acc": 52.0}
{"epoch": 2, "training_loss": 0.7009311056137085, "training_acc": 53.0, "val_loss": 0.6908815121650695, "val_acc": 52.0}
{"epoch": 3, "training_loss": 0.7033920526504517, "training_acc": 41.0, "val_loss": 0.6911680150032044, "val_acc": 68.0}
{"epoch": 4, "training_loss": 0.693276515007019, "training_acc": 48.0, "val_loss": 0.6921884417533875, "val_acc": 52.0}
{"epoch": 5, "training_loss": 0.7098131585121155, "training_acc": 53.0, "val_loss": 0.7096021318435669, "val_acc": 52.0}
{"epoch": 6, "training_loss": 0.7034675121307373, "training_acc": 53.0, "val_loss": 0.6905016922950744, "val_acc": 52.0}
{"epoch": 7, "training_loss": 0.7056497621536255, "training_acc": 48.0, "val_loss": 0.6981500911712647, "val_acc": 48.0}
{"epoch": 8, "training_loss": 0.6941472291946411, "training_acc": 51.0, "val_loss": 0.6934376406669617, "val_acc": 52.0}
{"epoch": 9, "training_loss": 0.7044799661636353, "training_acc": 53.0, "val_loss": 0.6960534834861756, "val_acc": 52.0}
{"epoch": 10, "training_loss": 0.7032122874259948, "training_acc": 45.0, "val_loss": 0.6944945001602173, "val_acc": 48.0}
{"epoch": 11, "training_loss": 0.6934093189239502, "training_acc": 52.0, "val_loss": 0.6916461777687073, "val_acc": 52.0}
{"epoch": 12, "training_loss": 0.6977514433860779, "training_acc": 53.0, "val_loss": 0.7025876641273499, "val_acc": 52.0}
{"epoch": 13, "training_loss": 0.6920667457580566, "training_acc": 53.0, "val_loss": 0.6909860348701478, "val_acc": 64.0}
{"epoch": 14, "training_loss": 0.7126093173027038, "training_acc": 48.0, "val_loss": 0.7029962468147278, "val_acc": 48.0}
{"epoch": 15, "training_loss": 0.7237864446640014, "training_acc": 39.0, "val_loss": 0.6982476282119751, "val_acc": 52.0}
{"epoch": 16, "training_loss": 0.692023115158081, "training_acc": 53.0, "val_loss": 0.6904696488380432, "val_acc": 52.0}
{"epoch": 17, "training_loss": 0.6907199668884277, "training_acc": 53.0, "val_loss": 0.6904895257949829, "val_acc": 52.0}
{"epoch": 18, "training_loss": 0.692685203552246, "training_acc": 47.0, "val_loss": 0.6913239598274231, "val_acc": 56.0}
{"epoch": 19, "training_loss": 0.6873274731636048, "training_acc": 56.0, "val_loss": 0.6955780911445618, "val_acc": 52.0}
{"epoch": 20, "training_loss": 0.7010937976837158, "training_acc": 53.0, "val_loss": 0.6924878478050231, "val_acc": 52.0}
{"epoch": 21, "training_loss": 0.6933301448822021, "training_acc": 53.0, "val_loss": 0.6920223617553711, "val_acc": 52.0}
{"epoch": 22, "training_loss": 0.6968610334396362, "training_acc": 53.0, "val_loss": 0.695629940032959, "val_acc": 52.0}
{"epoch": 23, "training_loss": 0.6906381297111511, "training_acc": 54.0, "val_loss": 0.6987347960472107, "val_acc": 48.0}
{"epoch": 24, "training_loss": 0.7069660329818725, "training_acc": 47.0, "val_loss": 0.690611126422882, "val_acc": 52.0}
{"epoch": 25, "training_loss": 0.6888832759857177, "training_acc": 53.0, "val_loss": 0.7221245169639587, "val_acc": 52.0}
{"epoch": 26, "training_loss": 0.7058366918563843, "training_acc": 53.0, "val_loss": 0.6908369565010071, "val_acc": 52.0}
{"epoch": 27, "training_loss": 0.6943869686126709, "training_acc": 53.0, "val_loss": 0.6904382705688477, "val_acc": 52.0}
{"epoch": 28, "training_loss": 0.7144077634811401, "training_acc": 43.0, "val_loss": 0.7007568621635437, "val_acc": 48.0}
{"epoch": 29, "training_loss": 0.7116042399406433, "training_acc": 45.0, "val_loss": 0.706060836315155, "val_acc": 52.0}
{"epoch": 30, "training_loss": 0.6938691067695618, "training_acc": 53.0, "val_loss": 0.6906654453277588, "val_acc": 52.0}
{"epoch": 31, "training_loss": 0.6880725860595703, "training_acc": 61.0, "val_loss": 0.6941221284866333, "val_acc": 48.0}
{"epoch": 32, "training_loss": 0.6941670227050781, "training_acc": 51.0, "val_loss": 0.690592908859253, "val_acc": 52.0}
{"epoch": 33, "training_loss": 0.6972536492347717, "training_acc": 53.0, "val_loss": 0.7020979070663452, "val_acc": 52.0}
{"epoch": 34, "training_loss": 0.7019307112693787, "training_acc": 53.0, "val_loss": 0.6973878240585327, "val_acc": 52.0}
{"epoch": 35, "training_loss": 0.6943419551849366, "training_acc": 50.0, "val_loss": 0.6985356068611145, "val_acc": 48.0}
{"epoch": 36, "training_loss": 0.7016780233383179, "training_acc": 47.0, "val_loss": 0.6929356217384338, "val_acc": 48.0}
{"epoch": 37, "training_loss": 0.6916298818588257, "training_acc": 45.0, "val_loss": 0.6908783650398255, "val_acc": 56.0}
{"epoch": 38, "training_loss": 0.6881269001960755, "training_acc": 56.0, "val_loss": 0.6937189602851868, "val_acc": 52.0}
{"epoch": 39, "training_loss": 0.6878735160827637, "training_acc": 53.0, "val_loss": 0.6911295294761658, "val_acc": 52.0}
{"epoch": 40, "training_loss": 0.6878480577468872, "training_acc": 56.0, "val_loss": 0.691684763431549, "val_acc": 48.0}
{"epoch": 41, "training_loss": 0.6897269034385681, "training_acc": 53.0, "val_loss": 0.6907761001586914, "val_acc": 56.0}
{"epoch": 42, "training_loss": 0.6863554835319519, "training_acc": 54.0, "val_loss": 0.693699300289154, "val_acc": 52.0}
{"epoch": 43, "training_loss": 0.6927009272575378, "training_acc": 52.0, "val_loss": 0.6905737686157226, "val_acc": 52.0}
{"epoch": 44, "training_loss": 0.6850963902473449, "training_acc": 53.0, "val_loss": 0.6922413563728332, "val_acc": 52.0}
{"epoch": 45, "training_loss": 0.6905398821830749, "training_acc": 53.0, "val_loss": 0.695721755027771, "val_acc": 52.0}
{"epoch": 46, "training_loss": 0.7004295086860657, "training_acc": 50.0, "val_loss": 0.7022866559028625, "val_acc": 48.0}
