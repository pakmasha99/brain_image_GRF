"main_modify.py --pretrained_path /scratch/connectome/dyhan316/VAE_ADHD/barlowtwins/pretrain_results/ABCDbt128a102.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option BT_org --learning_rate 1e-3 --batch_size 16 --weight_decay 1e-6 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 0.7011635971069335, "training_acc": 56.0, "val_loss": 0.7042493438720703, "val_acc": 48.0}
{"epoch": 1, "training_loss": 0.7256952095031738, "training_acc": 47.0, "val_loss": 0.6931127119064331, "val_acc": 52.0}
{"epoch": 2, "training_loss": 0.7317250657081604, "training_acc": 53.0, "val_loss": 0.7246869659423828, "val_acc": 52.0}
{"epoch": 3, "training_loss": 0.7062731075286866, "training_acc": 49.0, "val_loss": 0.7089528656005859, "val_acc": 48.0}
{"epoch": 4, "training_loss": 0.7025169849395752, "training_acc": 49.0, "val_loss": 0.6932680535316468, "val_acc": 52.0}
{"epoch": 5, "training_loss": 0.7225496625900268, "training_acc": 53.0, "val_loss": 0.7160837745666504, "val_acc": 52.0}
{"epoch": 6, "training_loss": 0.6886996698379516, "training_acc": 49.0, "val_loss": 0.6966325879096985, "val_acc": 48.0}
{"epoch": 7, "training_loss": 0.7153433704376221, "training_acc": 42.0, "val_loss": 0.6938922548294068, "val_acc": 52.0}
{"epoch": 8, "training_loss": 0.6914949989318848, "training_acc": 54.0, "val_loss": 0.693132061958313, "val_acc": 52.0}
{"epoch": 9, "training_loss": 0.695757200717926, "training_acc": 53.0, "val_loss": 0.6943167090415955, "val_acc": 52.0}
{"epoch": 10, "training_loss": 0.7019842076301575, "training_acc": 43.0, "val_loss": 0.7004500579833984, "val_acc": 48.0}
{"epoch": 11, "training_loss": 0.7029738903045655, "training_acc": 46.0, "val_loss": 0.692904999256134, "val_acc": 52.0}
{"epoch": 12, "training_loss": 0.6895365381240844, "training_acc": 53.0, "val_loss": 0.6931512188911438, "val_acc": 52.0}
{"epoch": 13, "training_loss": 0.698918240070343, "training_acc": 53.0, "val_loss": 0.6964821553230286, "val_acc": 52.0}
{"epoch": 14, "training_loss": 0.6947418427467347, "training_acc": 53.0, "val_loss": 0.6966329073905945, "val_acc": 52.0}
{"epoch": 15, "training_loss": 0.6863949179649353, "training_acc": 55.0, "val_loss": 0.6969200491905212, "val_acc": 48.0}
{"epoch": 16, "training_loss": 0.6972096920013428, "training_acc": 47.0, "val_loss": 0.693033356666565, "val_acc": 52.0}
{"epoch": 17, "training_loss": 0.6862942171096802, "training_acc": 53.0, "val_loss": 0.7048915219306946, "val_acc": 52.0}
{"epoch": 18, "training_loss": 0.7006661891937256, "training_acc": 53.0, "val_loss": 0.6994614481925965, "val_acc": 52.0}
{"epoch": 19, "training_loss": 0.6899978399276734, "training_acc": 53.0, "val_loss": 0.6926202869415283, "val_acc": 52.0}
{"epoch": 20, "training_loss": 0.6993702149391174, "training_acc": 48.0, "val_loss": 0.7040346527099609, "val_acc": 48.0}
{"epoch": 21, "training_loss": 0.7053823733329773, "training_acc": 47.0, "val_loss": 0.6978717136383057, "val_acc": 48.0}
{"epoch": 22, "training_loss": 0.6930495142936707, "training_acc": 48.0, "val_loss": 0.693036699295044, "val_acc": 52.0}
{"epoch": 23, "training_loss": 0.6893400526046753, "training_acc": 53.0, "val_loss": 0.6925528240203858, "val_acc": 52.0}
{"epoch": 24, "training_loss": 0.6947192287445069, "training_acc": 48.0, "val_loss": 0.6925869846343994, "val_acc": 52.0}
{"epoch": 25, "training_loss": 0.6901411867141723, "training_acc": 53.0, "val_loss": 0.6926005625724793, "val_acc": 52.0}
{"epoch": 26, "training_loss": 0.6941811227798462, "training_acc": 47.0, "val_loss": 0.6929688572883606, "val_acc": 48.0}
{"epoch": 27, "training_loss": 0.6906529712677002, "training_acc": 54.0, "val_loss": 0.6925905799865723, "val_acc": 52.0}
{"epoch": 28, "training_loss": 0.6903571701049804, "training_acc": 53.0, "val_loss": 0.6942282176017761, "val_acc": 52.0}
{"epoch": 29, "training_loss": 0.6884232044219971, "training_acc": 53.0, "val_loss": 0.6927603030204773, "val_acc": 52.0}
{"epoch": 30, "training_loss": 0.6898142385482788, "training_acc": 57.0, "val_loss": 0.6926705288887024, "val_acc": 52.0}
{"epoch": 31, "training_loss": 0.6861377501487732, "training_acc": 53.0, "val_loss": 0.6956541538238525, "val_acc": 52.0}
{"epoch": 32, "training_loss": 0.6909216260910034, "training_acc": 53.0, "val_loss": 0.6929736351966858, "val_acc": 52.0}
{"epoch": 33, "training_loss": 0.6906981945037842, "training_acc": 55.0, "val_loss": 0.6925536942481995, "val_acc": 52.0}
{"epoch": 34, "training_loss": 0.6886382865905761, "training_acc": 59.0, "val_loss": 0.6930482244491577, "val_acc": 52.0}
{"epoch": 35, "training_loss": 0.6892190504074097, "training_acc": 54.0, "val_loss": 0.6931688737869263, "val_acc": 52.0}
{"epoch": 36, "training_loss": 0.7043702125549316, "training_acc": 53.0, "val_loss": 0.7113543200492859, "val_acc": 52.0}
{"epoch": 37, "training_loss": 0.7070948243141174, "training_acc": 53.0, "val_loss": 0.6929102325439453, "val_acc": 52.0}
{"epoch": 38, "training_loss": 0.6925892257690429, "training_acc": 53.0, "val_loss": 0.6930076813697815, "val_acc": 52.0}
{"epoch": 39, "training_loss": 0.6919649481773377, "training_acc": 43.0, "val_loss": 0.6967814683914184, "val_acc": 48.0}
{"epoch": 40, "training_loss": 0.692462043762207, "training_acc": 48.0, "val_loss": 0.6926558709144592, "val_acc": 52.0}
{"epoch": 41, "training_loss": 0.6910149669647216, "training_acc": 50.0, "val_loss": 0.6925650644302368, "val_acc": 52.0}
{"epoch": 42, "training_loss": 0.685045485496521, "training_acc": 53.0, "val_loss": 0.6979162621498108, "val_acc": 52.0}
