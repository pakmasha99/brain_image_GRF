"main_modify.py --pretrained_path /scratch/connectome/dyhan316/VAE_ADHD/barlowtwins/pretrain_results/ABCDbt128a102.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option BT_org --learning_rate 1e-3 --batch_size 16 --weight_decay 1e-6 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 0.7254640865325928, "training_acc": 47.0, "val_loss": 0.7133929848670959, "val_acc": 52.0}
{"epoch": 1, "training_loss": 0.7163239884376525, "training_acc": 53.0, "val_loss": 0.7025138163566589, "val_acc": 52.0}
{"epoch": 2, "training_loss": 0.6934687876701355, "training_acc": 53.0, "val_loss": 0.7066479730606079, "val_acc": 48.0}
{"epoch": 3, "training_loss": 0.7004033041000366, "training_acc": 47.0, "val_loss": 0.6973597717285156, "val_acc": 52.0}
{"epoch": 4, "training_loss": 0.6944771790504456, "training_acc": 53.0, "val_loss": 0.6928668403625489, "val_acc": 52.0}
{"epoch": 5, "training_loss": 0.6997113561630249, "training_acc": 47.0, "val_loss": 0.6931905436515808, "val_acc": 52.0}
{"epoch": 6, "training_loss": 0.6905989122390747, "training_acc": 51.0, "val_loss": 0.70266841173172, "val_acc": 52.0}
{"epoch": 7, "training_loss": 0.7104632997512818, "training_acc": 47.0, "val_loss": 0.6927769136428833, "val_acc": 52.0}
{"epoch": 8, "training_loss": 0.6901497268676757, "training_acc": 53.0, "val_loss": 0.70387211561203, "val_acc": 52.0}
{"epoch": 9, "training_loss": 0.6989495706558227, "training_acc": 53.0, "val_loss": 0.6934862637519836, "val_acc": 52.0}
{"epoch": 10, "training_loss": 0.6876588845252991, "training_acc": 58.0, "val_loss": 0.6996355748176575, "val_acc": 48.0}
{"epoch": 11, "training_loss": 0.6964277291297912, "training_acc": 51.0, "val_loss": 0.6948233437538147, "val_acc": 52.0}
{"epoch": 12, "training_loss": 0.6953304600715637, "training_acc": 53.0, "val_loss": 0.7028129124641418, "val_acc": 52.0}
{"epoch": 13, "training_loss": 0.6956619715690613, "training_acc": 53.0, "val_loss": 0.6943471813201905, "val_acc": 52.0}
{"epoch": 14, "training_loss": 0.6980686330795288, "training_acc": 53.0, "val_loss": 0.6944105982780456, "val_acc": 52.0}
{"epoch": 15, "training_loss": 0.7002032375335694, "training_acc": 43.0, "val_loss": 0.6975418186187744, "val_acc": 48.0}
{"epoch": 16, "training_loss": 0.6899300384521484, "training_acc": 56.0, "val_loss": 0.6950897526741028, "val_acc": 52.0}
{"epoch": 17, "training_loss": 0.691490752696991, "training_acc": 53.0, "val_loss": 0.6948148322105407, "val_acc": 52.0}
{"epoch": 18, "training_loss": 0.6936229753494263, "training_acc": 53.0, "val_loss": 0.6966836285591126, "val_acc": 52.0}
{"epoch": 19, "training_loss": 0.6948305916786194, "training_acc": 53.0, "val_loss": 0.693625020980835, "val_acc": 52.0}
{"epoch": 20, "training_loss": 0.6906263995170593, "training_acc": 53.0, "val_loss": 0.694228618144989, "val_acc": 52.0}
{"epoch": 21, "training_loss": 0.6925839710235596, "training_acc": 53.0, "val_loss": 0.693500907421112, "val_acc": 52.0}
{"epoch": 22, "training_loss": 0.690231580734253, "training_acc": 55.0, "val_loss": 0.6941051363945008, "val_acc": 48.0}
{"epoch": 23, "training_loss": 0.6962333250045777, "training_acc": 49.0, "val_loss": 0.6934708714485168, "val_acc": 52.0}
{"epoch": 24, "training_loss": 0.6837129640579224, "training_acc": 53.0, "val_loss": 0.7083453035354614, "val_acc": 52.0}
{"epoch": 25, "training_loss": 0.7092364883422851, "training_acc": 53.0, "val_loss": 0.6995605587959289, "val_acc": 52.0}
{"epoch": 26, "training_loss": 0.6843857669830322, "training_acc": 55.0, "val_loss": 0.6979062104225159, "val_acc": 48.0}
