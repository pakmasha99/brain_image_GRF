"main_modify.py --pretrained_path /scratch/connectome/dyhan316/VAE_ADHD/barlowtwins/pretrain_results/ABCDbt128a102.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option BT_org --learning_rate 1e-3 --batch_size 16 --weight_decay 1e-6 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 0.7072877097129822, "training_acc": 45.0, "val_loss": 0.6967405414581299, "val_acc": 52.0}
{"epoch": 1, "training_loss": 0.7201307916641235, "training_acc": 53.0, "val_loss": 0.7093304753303528, "val_acc": 52.0}
{"epoch": 2, "training_loss": 0.7050876426696777, "training_acc": 43.0, "val_loss": 0.7065658593177795, "val_acc": 48.0}
{"epoch": 3, "training_loss": 0.7016283822059631, "training_acc": 47.0, "val_loss": 0.6939023900032043, "val_acc": 52.0}
{"epoch": 4, "training_loss": 0.7104018545150756, "training_acc": 53.0, "val_loss": 0.7248691868782043, "val_acc": 52.0}
{"epoch": 5, "training_loss": 0.7118528056144714, "training_acc": 53.0, "val_loss": 0.6945171761512756, "val_acc": 52.0}
{"epoch": 6, "training_loss": 0.6972984075546265, "training_acc": 44.0, "val_loss": 0.6939278841018677, "val_acc": 52.0}
{"epoch": 7, "training_loss": 0.7025005102157593, "training_acc": 53.0, "val_loss": 0.6997050976753235, "val_acc": 52.0}
{"epoch": 8, "training_loss": 0.6913922071456909, "training_acc": 53.0, "val_loss": 0.6936854934692382, "val_acc": 52.0}
{"epoch": 9, "training_loss": 0.6921993517875671, "training_acc": 56.0, "val_loss": 0.7004650998115539, "val_acc": 48.0}
{"epoch": 10, "training_loss": 0.6981550598144531, "training_acc": 47.0, "val_loss": 0.6946312308311462, "val_acc": 52.0}
{"epoch": 11, "training_loss": 0.7080309200286865, "training_acc": 53.0, "val_loss": 0.7069894981384277, "val_acc": 52.0}
{"epoch": 12, "training_loss": 0.7091095304489136, "training_acc": 45.0, "val_loss": 0.6977816820144653, "val_acc": 48.0}
{"epoch": 13, "training_loss": 0.6950642371177673, "training_acc": 45.0, "val_loss": 0.6937020468711853, "val_acc": 52.0}
{"epoch": 14, "training_loss": 0.7005647969245911, "training_acc": 53.0, "val_loss": 0.6974021530151367, "val_acc": 52.0}
{"epoch": 15, "training_loss": 0.6894764566421508, "training_acc": 53.0, "val_loss": 0.694530816078186, "val_acc": 48.0}
{"epoch": 16, "training_loss": 0.694520287513733, "training_acc": 49.0, "val_loss": 0.6934797883033752, "val_acc": 52.0}
{"epoch": 17, "training_loss": 0.6894069004058838, "training_acc": 53.0, "val_loss": 0.7072528004646301, "val_acc": 52.0}
{"epoch": 18, "training_loss": 0.7069502067565918, "training_acc": 53.0, "val_loss": 0.6980569219589233, "val_acc": 52.0}
{"epoch": 19, "training_loss": 0.6992666339874267, "training_acc": 51.0, "val_loss": 0.698980770111084, "val_acc": 48.0}
{"epoch": 20, "training_loss": 0.695855610370636, "training_acc": 47.0, "val_loss": 0.7004295468330384, "val_acc": 52.0}
{"epoch": 21, "training_loss": 0.6964178919792176, "training_acc": 53.0, "val_loss": 0.6942785263061524, "val_acc": 52.0}
{"epoch": 22, "training_loss": 0.6982707834243774, "training_acc": 49.0, "val_loss": 0.7105523490905762, "val_acc": 48.0}
{"epoch": 23, "training_loss": 0.704714879989624, "training_acc": 47.0, "val_loss": 0.6932212138175964, "val_acc": 52.0}
{"epoch": 24, "training_loss": 0.7223457717895507, "training_acc": 53.0, "val_loss": 0.7095616030693054, "val_acc": 52.0}
{"epoch": 25, "training_loss": 0.7004381275177002, "training_acc": 53.0, "val_loss": 0.7194250583648681, "val_acc": 48.0}
{"epoch": 26, "training_loss": 0.7257103419303894, "training_acc": 45.0, "val_loss": 0.6934924030303955, "val_acc": 52.0}
{"epoch": 27, "training_loss": 0.6940408086776734, "training_acc": 46.0, "val_loss": 0.6934393024444581, "val_acc": 52.0}
{"epoch": 28, "training_loss": 0.6923054933547974, "training_acc": 53.0, "val_loss": 0.697345860004425, "val_acc": 52.0}
{"epoch": 29, "training_loss": 0.6956059646606445, "training_acc": 53.0, "val_loss": 0.6928672933578491, "val_acc": 52.0}
{"epoch": 30, "training_loss": 0.6913837838172913, "training_acc": 53.0, "val_loss": 0.6929073739051819, "val_acc": 52.0}
{"epoch": 31, "training_loss": 0.6875984621047974, "training_acc": 58.0, "val_loss": 0.6958069348335266, "val_acc": 48.0}
{"epoch": 32, "training_loss": 0.6996841979026794, "training_acc": 41.0, "val_loss": 0.6925546550750732, "val_acc": 52.0}
{"epoch": 33, "training_loss": 0.6929765319824219, "training_acc": 51.0, "val_loss": 0.6966442108154297, "val_acc": 48.0}
{"epoch": 34, "training_loss": 0.6948935651779174, "training_acc": 47.0, "val_loss": 0.6951810050010682, "val_acc": 48.0}
{"epoch": 35, "training_loss": 0.6920068478584289, "training_acc": 51.0, "val_loss": 0.6923897910118103, "val_acc": 52.0}
{"epoch": 36, "training_loss": 0.6935067534446716, "training_acc": 53.0, "val_loss": 0.696345865726471, "val_acc": 52.0}
{"epoch": 37, "training_loss": 0.6885309243202209, "training_acc": 53.0, "val_loss": 0.6923653388023376, "val_acc": 52.0}
{"epoch": 38, "training_loss": 0.6944146919250488, "training_acc": 45.0, "val_loss": 0.6966193342208862, "val_acc": 48.0}
{"epoch": 39, "training_loss": 0.6953789234161377, "training_acc": 51.0, "val_loss": 0.6930946707725525, "val_acc": 52.0}
{"epoch": 40, "training_loss": 0.6879368257522583, "training_acc": 53.0, "val_loss": 0.697934136390686, "val_acc": 52.0}
{"epoch": 41, "training_loss": 0.6939738941192627, "training_acc": 53.0, "val_loss": 0.6939927744865417, "val_acc": 52.0}
{"epoch": 42, "training_loss": 0.6910518217086792, "training_acc": 48.0, "val_loss": 0.6930752515792846, "val_acc": 44.0}
{"epoch": 43, "training_loss": 0.6863375878334046, "training_acc": 67.0, "val_loss": 0.6962474608421325, "val_acc": 52.0}
{"epoch": 44, "training_loss": 0.7149826288223267, "training_acc": 53.0, "val_loss": 0.7307217836380004, "val_acc": 52.0}
{"epoch": 45, "training_loss": 0.7167819309234619, "training_acc": 53.0, "val_loss": 0.6925174260139465, "val_acc": 52.0}
{"epoch": 46, "training_loss": 0.6890221571922303, "training_acc": 53.0, "val_loss": 0.6921164846420288, "val_acc": 52.0}
{"epoch": 47, "training_loss": 0.6950679540634155, "training_acc": 45.0, "val_loss": 0.6936656308174133, "val_acc": 48.0}
{"epoch": 48, "training_loss": 0.6950898694992066, "training_acc": 50.0, "val_loss": 0.6923137331008911, "val_acc": 48.0}
{"epoch": 49, "training_loss": 0.6870486688613892, "training_acc": 54.0, "val_loss": 0.6933211970329285, "val_acc": 52.0}
{"epoch": 50, "training_loss": 0.6891205024719238, "training_acc": 53.0, "val_loss": 0.6935395908355713, "val_acc": 52.0}
{"epoch": 51, "training_loss": 0.6913186407089233, "training_acc": 53.0, "val_loss": 0.6935851645469665, "val_acc": 52.0}
{"epoch": 52, "training_loss": 0.6938227939605713, "training_acc": 53.0, "val_loss": 0.7048990893363952, "val_acc": 52.0}
{"epoch": 53, "training_loss": 0.7072951602935791, "training_acc": 54.0, "val_loss": 0.6924787640571595, "val_acc": 56.0}
{"epoch": 54, "training_loss": 0.693196063041687, "training_acc": 53.0, "val_loss": 0.6961949634552002, "val_acc": 52.0}
{"epoch": 55, "training_loss": 0.6997102212905884, "training_acc": 53.0, "val_loss": 0.7042620706558228, "val_acc": 52.0}
{"epoch": 56, "training_loss": 0.6961271429061889, "training_acc": 53.0, "val_loss": 0.6947459435462952, "val_acc": 52.0}
{"epoch": 57, "training_loss": 0.7092234516143798, "training_acc": 39.0, "val_loss": 0.6969569730758667, "val_acc": 48.0}
{"epoch": 58, "training_loss": 0.6896017694473267, "training_acc": 55.0, "val_loss": 0.7048782420158386, "val_acc": 52.0}
{"epoch": 59, "training_loss": 0.7142179441452027, "training_acc": 53.0, "val_loss": 0.7049452972412109, "val_acc": 52.0}
{"epoch": 60, "training_loss": 0.6882809567451477, "training_acc": 58.0, "val_loss": 0.6952613925933838, "val_acc": 48.0}
{"epoch": 61, "training_loss": 0.6941780281066895, "training_acc": 47.0, "val_loss": 0.6918207669258117, "val_acc": 52.0}
{"epoch": 62, "training_loss": 0.6886060857772827, "training_acc": 56.0, "val_loss": 0.7060321378707886, "val_acc": 52.0}
{"epoch": 63, "training_loss": 0.6905624699592591, "training_acc": 53.0, "val_loss": 0.6913593339920044, "val_acc": 52.0}
{"epoch": 64, "training_loss": 0.6848199224472046, "training_acc": 57.0, "val_loss": 0.6936483764648438, "val_acc": 48.0}
{"epoch": 65, "training_loss": 0.6963473629951477, "training_acc": 47.0, "val_loss": 0.6941965436935424, "val_acc": 48.0}
{"epoch": 66, "training_loss": 0.6896137905120849, "training_acc": 50.0, "val_loss": 0.6919342923164368, "val_acc": 56.0}
{"epoch": 67, "training_loss": 0.6912617301940918, "training_acc": 50.0, "val_loss": 0.6915402936935425, "val_acc": 52.0}
{"epoch": 68, "training_loss": 0.6927154302597046, "training_acc": 54.0, "val_loss": 0.7108717656135559, "val_acc": 52.0}
{"epoch": 69, "training_loss": 0.6932613301277161, "training_acc": 53.0, "val_loss": 0.6932593488693237, "val_acc": 48.0}
{"epoch": 70, "training_loss": 0.6928120994567871, "training_acc": 45.0, "val_loss": 0.6910169720649719, "val_acc": 52.0}
{"epoch": 71, "training_loss": 0.6862032437324523, "training_acc": 54.0, "val_loss": 0.6911173987388611, "val_acc": 52.0}
{"epoch": 72, "training_loss": 0.6952914237976074, "training_acc": 53.0, "val_loss": 0.693742401599884, "val_acc": 52.0}
{"epoch": 73, "training_loss": 0.6826284456253052, "training_acc": 55.0, "val_loss": 0.69404545545578, "val_acc": 48.0}
{"epoch": 74, "training_loss": 0.7048822450637817, "training_acc": 47.0, "val_loss": 0.6963413834571839, "val_acc": 48.0}
{"epoch": 75, "training_loss": 0.6895301127433777, "training_acc": 53.0, "val_loss": 0.6918761944770813, "val_acc": 52.0}
{"epoch": 76, "training_loss": 0.68654935836792, "training_acc": 54.0, "val_loss": 0.6907910561561584, "val_acc": 52.0}
{"epoch": 77, "training_loss": 0.6840941572189331, "training_acc": 54.0, "val_loss": 0.6908282136917114, "val_acc": 52.0}
{"epoch": 78, "training_loss": 0.6837593388557434, "training_acc": 53.0, "val_loss": 0.6912972688674927, "val_acc": 52.0}
{"epoch": 79, "training_loss": 0.6854396057128906, "training_acc": 55.0, "val_loss": 0.6906412672996521, "val_acc": 52.0}
{"epoch": 80, "training_loss": 0.6834995794296265, "training_acc": 55.0, "val_loss": 0.6907571458816528, "val_acc": 52.0}
{"epoch": 81, "training_loss": 0.6829477834701538, "training_acc": 53.0, "val_loss": 0.6908051013946533, "val_acc": 52.0}
{"epoch": 82, "training_loss": 0.7089214897155762, "training_acc": 37.0, "val_loss": 0.6930953121185303, "val_acc": 48.0}
{"epoch": 83, "training_loss": 0.6926356077194213, "training_acc": 53.0, "val_loss": 0.6991087722778321, "val_acc": 52.0}
{"epoch": 84, "training_loss": 0.679454255104065, "training_acc": 53.0, "val_loss": 0.6917391705513001, "val_acc": 52.0}
{"epoch": 85, "training_loss": 0.6917114496231079, "training_acc": 48.0, "val_loss": 0.7014376378059387, "val_acc": 48.0}
{"epoch": 86, "training_loss": 0.6938528156280518, "training_acc": 47.0, "val_loss": 0.6934157752990723, "val_acc": 52.0}
{"epoch": 87, "training_loss": 0.6849831175804139, "training_acc": 53.0, "val_loss": 0.6911998510360717, "val_acc": 52.0}
{"epoch": 88, "training_loss": 0.6800175142288208, "training_acc": 60.0, "val_loss": 0.6915198493003846, "val_acc": 56.0}
{"epoch": 89, "training_loss": 0.6848798441886902, "training_acc": 59.0, "val_loss": 0.6914776968955993, "val_acc": 52.0}
{"epoch": 90, "training_loss": 0.6944857859611511, "training_acc": 53.0, "val_loss": 0.7055633640289307, "val_acc": 52.0}
{"epoch": 91, "training_loss": 0.6859739589691162, "training_acc": 55.0, "val_loss": 0.6915218639373779, "val_acc": 56.0}
{"epoch": 92, "training_loss": 0.6898760437965393, "training_acc": 50.0, "val_loss": 0.69142333984375, "val_acc": 52.0}
{"epoch": 93, "training_loss": 0.681250991821289, "training_acc": 66.0, "val_loss": 0.6936694455146789, "val_acc": 52.0}
{"epoch": 94, "training_loss": 0.6874362993240356, "training_acc": 53.0, "val_loss": 0.691217770576477, "val_acc": 52.0}
{"epoch": 95, "training_loss": 0.6848707962036132, "training_acc": 53.0, "val_loss": 0.6960391592979431, "val_acc": 52.0}
{"epoch": 96, "training_loss": 0.6883721303939819, "training_acc": 53.0, "val_loss": 0.6935076522827148, "val_acc": 52.0}
{"epoch": 97, "training_loss": 0.6852966809272766, "training_acc": 53.0, "val_loss": 0.6929911470413208, "val_acc": 52.0}
{"epoch": 98, "training_loss": 0.6956100702285767, "training_acc": 53.0, "val_loss": 0.6932012629508972, "val_acc": 52.0}
