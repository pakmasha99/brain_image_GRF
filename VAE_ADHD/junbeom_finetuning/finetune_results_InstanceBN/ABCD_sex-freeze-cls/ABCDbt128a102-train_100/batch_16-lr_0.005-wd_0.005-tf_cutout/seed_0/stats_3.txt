"main_modify.py --pretrained_path /scratch/connectome/dyhan316/VAE_ADHD/barlowtwins/pretrain_results/ABCDbt128a102.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option BT_org --learning_rate 5e-3 --batch_size 16 --weight_decay 5e-3 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 0.8902557563781738, "training_acc": 47.0, "val_loss": 0.6982247257232665, "val_acc": 48.0}
{"epoch": 1, "training_loss": 0.7362593889236451, "training_acc": 57.0, "val_loss": 0.6970083451271057, "val_acc": 48.0}
{"epoch": 2, "training_loss": 0.7139928913116456, "training_acc": 51.0, "val_loss": 0.7457297658920288, "val_acc": 52.0}
{"epoch": 3, "training_loss": 0.7993058156967163, "training_acc": 53.0, "val_loss": 0.7373050689697266, "val_acc": 48.0}
{"epoch": 4, "training_loss": 0.7951985955238342, "training_acc": 39.0, "val_loss": 0.6928607583045959, "val_acc": 52.0}
{"epoch": 5, "training_loss": 0.7265515732765198, "training_acc": 43.0, "val_loss": 0.6969528245925903, "val_acc": 52.0}
{"epoch": 6, "training_loss": 0.6935587668418884, "training_acc": 53.0, "val_loss": 0.6929211020469666, "val_acc": 48.0}
{"epoch": 7, "training_loss": 0.7108100891113281, "training_acc": 46.0, "val_loss": 0.7028773045539856, "val_acc": 52.0}
{"epoch": 8, "training_loss": 0.7005685329437256, "training_acc": 49.0, "val_loss": 0.6985177564620971, "val_acc": 52.0}
{"epoch": 9, "training_loss": 0.7198443603515625, "training_acc": 51.0, "val_loss": 0.6931938552856445, "val_acc": 44.0}
{"epoch": 10, "training_loss": 0.686493604183197, "training_acc": 54.0, "val_loss": 0.7150107502937317, "val_acc": 52.0}
{"epoch": 11, "training_loss": 0.7118732237815857, "training_acc": 59.0, "val_loss": 0.7733503437042236, "val_acc": 48.0}
{"epoch": 12, "training_loss": 0.746549243927002, "training_acc": 47.0, "val_loss": 0.7236331510543823, "val_acc": 52.0}
{"epoch": 13, "training_loss": 0.7097522664070129, "training_acc": 55.0, "val_loss": 0.7750368547439576, "val_acc": 48.0}
{"epoch": 14, "training_loss": 0.8248673963546753, "training_acc": 47.0, "val_loss": 0.8472759938240051, "val_acc": 52.0}
{"epoch": 15, "training_loss": 0.7407464361190796, "training_acc": 55.0, "val_loss": 0.777376766204834, "val_acc": 48.0}
{"epoch": 16, "training_loss": 0.7863150596618652, "training_acc": 49.0, "val_loss": 0.7473262810707092, "val_acc": 52.0}
{"epoch": 17, "training_loss": 0.7666865539550781, "training_acc": 44.0, "val_loss": 0.6962802195549012, "val_acc": 52.0}
{"epoch": 18, "training_loss": 0.7423935532569885, "training_acc": 53.0, "val_loss": 0.6970493769645691, "val_acc": 48.0}
{"epoch": 19, "training_loss": 0.802185173034668, "training_acc": 45.0, "val_loss": 0.7412361264228821, "val_acc": 52.0}
{"epoch": 20, "training_loss": 0.7146038222312927, "training_acc": 50.0, "val_loss": 0.7083515882492065, "val_acc": 48.0}
{"epoch": 21, "training_loss": 0.7488182497024536, "training_acc": 47.0, "val_loss": 0.6927739977836609, "val_acc": 48.0}
{"epoch": 22, "training_loss": 0.7168531918525696, "training_acc": 57.0, "val_loss": 0.6926713633537293, "val_acc": 52.0}
{"epoch": 23, "training_loss": 0.7232449102401733, "training_acc": 53.0, "val_loss": 0.6928884196281433, "val_acc": 44.0}
{"epoch": 24, "training_loss": 0.7185982966423035, "training_acc": 56.0, "val_loss": 0.7287504935264587, "val_acc": 48.0}
{"epoch": 25, "training_loss": 0.7935078048706055, "training_acc": 47.0, "val_loss": 0.7472726559638977, "val_acc": 52.0}
{"epoch": 26, "training_loss": 0.7589578485488891, "training_acc": 45.0, "val_loss": 0.7156788396835327, "val_acc": 48.0}
{"epoch": 27, "training_loss": 0.729802029132843, "training_acc": 45.0, "val_loss": 0.6962756705284119, "val_acc": 52.0}
{"epoch": 28, "training_loss": 0.7100290536880494, "training_acc": 46.0, "val_loss": 0.6987469029426575, "val_acc": 52.0}
{"epoch": 29, "training_loss": 0.7583619499206543, "training_acc": 53.0, "val_loss": 0.7774236369132995, "val_acc": 48.0}
{"epoch": 30, "training_loss": 0.8633034396171569, "training_acc": 49.0, "val_loss": 0.7245958161354065, "val_acc": 52.0}
{"epoch": 31, "training_loss": 0.8156325435638427, "training_acc": 53.0, "val_loss": 0.7468320918083191, "val_acc": 48.0}
{"epoch": 32, "training_loss": 0.8180427145957947, "training_acc": 48.0, "val_loss": 0.7349105405807496, "val_acc": 52.0}
{"epoch": 33, "training_loss": 0.8149985504150391, "training_acc": 53.0, "val_loss": 0.7150725960731507, "val_acc": 48.0}
{"epoch": 34, "training_loss": 0.8179945135116578, "training_acc": 47.0, "val_loss": 0.720867235660553, "val_acc": 52.0}
{"epoch": 35, "training_loss": 0.7358463478088378, "training_acc": 53.0, "val_loss": 0.6933556747436523, "val_acc": 52.0}
{"epoch": 36, "training_loss": 0.6982683539390564, "training_acc": 55.0, "val_loss": 0.6975183629989624, "val_acc": 48.0}
{"epoch": 37, "training_loss": 0.6851668071746826, "training_acc": 53.0, "val_loss": 0.7208958244323731, "val_acc": 52.0}
{"epoch": 38, "training_loss": 0.6961098766326904, "training_acc": 56.0, "val_loss": 0.6933241963386536, "val_acc": 48.0}
{"epoch": 39, "training_loss": 0.7039588212966919, "training_acc": 53.0, "val_loss": 0.6999919629096985, "val_acc": 52.0}
{"epoch": 40, "training_loss": 0.6932038450241089, "training_acc": 55.0, "val_loss": 0.7499111390113831, "val_acc": 48.0}
{"epoch": 41, "training_loss": 0.8480773425102234, "training_acc": 45.0, "val_loss": 0.772672278881073, "val_acc": 52.0}
