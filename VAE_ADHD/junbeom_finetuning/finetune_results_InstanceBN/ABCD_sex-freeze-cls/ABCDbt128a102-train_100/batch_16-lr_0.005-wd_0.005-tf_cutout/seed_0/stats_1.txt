"main_modify.py --pretrained_path /scratch/connectome/dyhan316/VAE_ADHD/barlowtwins/pretrain_results/ABCDbt128a102.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option BT_org --learning_rate 5e-3 --batch_size 16 --weight_decay 5e-3 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 0.9126552319526673, "training_acc": 45.0, "val_loss": 0.6941283798217773, "val_acc": 48.0}
{"epoch": 1, "training_loss": 0.8477906394004822, "training_acc": 51.0, "val_loss": 0.6918907952308655, "val_acc": 52.0}
{"epoch": 2, "training_loss": 0.8735445594787598, "training_acc": 43.0, "val_loss": 0.6945103001594544, "val_acc": 52.0}
{"epoch": 3, "training_loss": 0.7898672366142273, "training_acc": 53.0, "val_loss": 0.7000139737129212, "val_acc": 52.0}
{"epoch": 4, "training_loss": 0.6944328165054321, "training_acc": 53.0, "val_loss": 0.6930780339241028, "val_acc": 48.0}
{"epoch": 5, "training_loss": 0.6937175416946411, "training_acc": 48.0, "val_loss": 0.691706817150116, "val_acc": 52.0}
{"epoch": 6, "training_loss": 0.7251623725891113, "training_acc": 37.0, "val_loss": 0.6921468663215637, "val_acc": 52.0}
{"epoch": 7, "training_loss": 0.7346446752548218, "training_acc": 53.0, "val_loss": 0.6945887422561645, "val_acc": 48.0}
{"epoch": 8, "training_loss": 0.7143160057067871, "training_acc": 39.0, "val_loss": 0.6917077231407166, "val_acc": 52.0}
{"epoch": 9, "training_loss": 0.7206243252754212, "training_acc": 53.0, "val_loss": 0.694583055973053, "val_acc": 48.0}
{"epoch": 10, "training_loss": 0.7110973381996155, "training_acc": 49.0, "val_loss": 0.7232828211784362, "val_acc": 52.0}
{"epoch": 11, "training_loss": 0.720686960220337, "training_acc": 51.0, "val_loss": 0.7128791975975036, "val_acc": 48.0}
{"epoch": 12, "training_loss": 0.7082587409019471, "training_acc": 51.0, "val_loss": 0.7233650088310242, "val_acc": 52.0}
{"epoch": 13, "training_loss": 0.7284879493713379, "training_acc": 39.0, "val_loss": 0.6953645467758178, "val_acc": 52.0}
{"epoch": 14, "training_loss": 0.7044935083389282, "training_acc": 53.0, "val_loss": 0.6908595752716065, "val_acc": 52.0}
{"epoch": 15, "training_loss": 0.6892467784881592, "training_acc": 53.0, "val_loss": 0.7022623562812805, "val_acc": 48.0}
{"epoch": 16, "training_loss": 0.775726535320282, "training_acc": 45.0, "val_loss": 0.8032665967941284, "val_acc": 52.0}
{"epoch": 17, "training_loss": 0.7947576904296875, "training_acc": 41.0, "val_loss": 0.6930937266349793, "val_acc": 48.0}
{"epoch": 18, "training_loss": 0.7034354424476623, "training_acc": 47.0, "val_loss": 0.691805477142334, "val_acc": 60.0}
{"epoch": 19, "training_loss": 0.7829735612869263, "training_acc": 46.0, "val_loss": 0.7084759879112243, "val_acc": 52.0}
{"epoch": 20, "training_loss": 0.7257976961135865, "training_acc": 49.0, "val_loss": 0.6939348959922791, "val_acc": 48.0}
{"epoch": 21, "training_loss": 0.7085764598846436, "training_acc": 51.0, "val_loss": 0.6929625940322875, "val_acc": 52.0}
{"epoch": 22, "training_loss": 0.7015371680259704, "training_acc": 54.0, "val_loss": 0.7288113379478455, "val_acc": 48.0}
{"epoch": 23, "training_loss": 0.7382717394828796, "training_acc": 49.0, "val_loss": 0.7224338555335998, "val_acc": 52.0}
{"epoch": 24, "training_loss": 0.7169830656051636, "training_acc": 53.0, "val_loss": 0.6903781890869141, "val_acc": 52.0}
{"epoch": 25, "training_loss": 0.7210814809799194, "training_acc": 49.0, "val_loss": 0.6960231947898865, "val_acc": 52.0}
{"epoch": 26, "training_loss": 0.7002917218208313, "training_acc": 53.0, "val_loss": 0.6986763882637024, "val_acc": 52.0}
{"epoch": 27, "training_loss": 0.6976445055007935, "training_acc": 50.0, "val_loss": 0.6963183975219727, "val_acc": 48.0}
{"epoch": 28, "training_loss": 0.7231795263290405, "training_acc": 52.0, "val_loss": 0.7661190915107727, "val_acc": 52.0}
{"epoch": 29, "training_loss": 0.7456229019165039, "training_acc": 55.0, "val_loss": 0.7364364457130432, "val_acc": 48.0}
{"epoch": 30, "training_loss": 0.823669126033783, "training_acc": 47.0, "val_loss": 0.8315858578681946, "val_acc": 52.0}
{"epoch": 31, "training_loss": 0.8315027141571045, "training_acc": 55.0, "val_loss": 0.8101187181472779, "val_acc": 48.0}
{"epoch": 32, "training_loss": 0.854000678062439, "training_acc": 47.0, "val_loss": 0.735003125667572, "val_acc": 52.0}
{"epoch": 33, "training_loss": 0.7540316820144654, "training_acc": 54.0, "val_loss": 0.6979107785224915, "val_acc": 48.0}
{"epoch": 34, "training_loss": 0.7058612895011902, "training_acc": 45.0, "val_loss": 0.6898226928710938, "val_acc": 52.0}
{"epoch": 35, "training_loss": 0.6858174967765808, "training_acc": 52.0, "val_loss": 0.6897950458526612, "val_acc": 64.0}
{"epoch": 36, "training_loss": 0.6882702350616455, "training_acc": 58.0, "val_loss": 0.6928404927253723, "val_acc": 52.0}
{"epoch": 37, "training_loss": 0.6858244419097901, "training_acc": 54.0, "val_loss": 0.6927993059158325, "val_acc": 52.0}
{"epoch": 38, "training_loss": 0.6857840323448181, "training_acc": 53.0, "val_loss": 0.702076416015625, "val_acc": 52.0}
{"epoch": 39, "training_loss": 0.6930134296417236, "training_acc": 52.0, "val_loss": 0.6950444483757019, "val_acc": 48.0}
{"epoch": 40, "training_loss": 0.6851577234268188, "training_acc": 62.0, "val_loss": 0.6898787236213684, "val_acc": 60.0}
{"epoch": 41, "training_loss": 0.6946037387847901, "training_acc": 58.0, "val_loss": 0.6964873909950257, "val_acc": 52.0}
{"epoch": 42, "training_loss": 0.6874312734603882, "training_acc": 54.0, "val_loss": 0.6941322445869446, "val_acc": 48.0}
{"epoch": 43, "training_loss": 0.6874093008041382, "training_acc": 50.0, "val_loss": 0.7353508162498474, "val_acc": 52.0}
{"epoch": 44, "training_loss": 0.7308358430862427, "training_acc": 54.0, "val_loss": 0.7105194425582886, "val_acc": 48.0}
{"epoch": 45, "training_loss": 0.7090415930747986, "training_acc": 52.0, "val_loss": 0.7157602643966675, "val_acc": 52.0}
{"epoch": 46, "training_loss": 0.7032648515701294, "training_acc": 46.0, "val_loss": 0.6904245305061341, "val_acc": 52.0}
{"epoch": 47, "training_loss": 0.7084593391418457, "training_acc": 53.0, "val_loss": 0.6963285040855408, "val_acc": 48.0}
{"epoch": 48, "training_loss": 0.7401921081542969, "training_acc": 39.0, "val_loss": 0.6890130591392517, "val_acc": 52.0}
{"epoch": 49, "training_loss": 0.7455144238471985, "training_acc": 45.0, "val_loss": 0.7282419466972351, "val_acc": 52.0}
{"epoch": 50, "training_loss": 0.7124493074417114, "training_acc": 52.0, "val_loss": 0.6977397108078003, "val_acc": 48.0}
{"epoch": 51, "training_loss": 0.6924416494369506, "training_acc": 51.0, "val_loss": 0.7627478742599487, "val_acc": 52.0}
{"epoch": 52, "training_loss": 0.7960891914367676, "training_acc": 53.0, "val_loss": 0.7751742482185364, "val_acc": 48.0}
{"epoch": 53, "training_loss": 0.9451028084754944, "training_acc": 49.0, "val_loss": 0.8049115109443664, "val_acc": 52.0}
{"epoch": 54, "training_loss": 0.8846418523788452, "training_acc": 53.0, "val_loss": 0.7266915130615235, "val_acc": 48.0}
{"epoch": 55, "training_loss": 0.7474919152259827, "training_acc": 47.0, "val_loss": 0.7134326386451721, "val_acc": 52.0}
{"epoch": 56, "training_loss": 0.6980288791656494, "training_acc": 51.0, "val_loss": 0.6890699672698974, "val_acc": 64.0}
{"epoch": 57, "training_loss": 0.722140326499939, "training_acc": 56.0, "val_loss": 0.7057027816772461, "val_acc": 48.0}
{"epoch": 58, "training_loss": 0.8437133622169495, "training_acc": 47.0, "val_loss": 0.7991199123859406, "val_acc": 52.0}
{"epoch": 59, "training_loss": 0.8377578830718995, "training_acc": 53.0, "val_loss": 0.7520594096183777, "val_acc": 48.0}
{"epoch": 60, "training_loss": 0.7235965490341186, "training_acc": 49.0, "val_loss": 0.7082945728302001, "val_acc": 52.0}
{"epoch": 61, "training_loss": 0.690277988910675, "training_acc": 60.0, "val_loss": 0.7099456858634948, "val_acc": 48.0}
{"epoch": 62, "training_loss": 0.6893274402618408, "training_acc": 49.0, "val_loss": 0.7745646786689758, "val_acc": 52.0}
{"epoch": 63, "training_loss": 0.7201442384719848, "training_acc": 57.0, "val_loss": 0.7346440505981445, "val_acc": 48.0}
{"epoch": 64, "training_loss": 0.7179719257354736, "training_acc": 49.0, "val_loss": 0.7599906587600708, "val_acc": 52.0}
{"epoch": 65, "training_loss": 0.7696009111404419, "training_acc": 55.0, "val_loss": 0.8391429376602173, "val_acc": 48.0}
{"epoch": 66, "training_loss": 0.8946344757080078, "training_acc": 43.0, "val_loss": 0.7454420256614686, "val_acc": 52.0}
{"epoch": 67, "training_loss": 0.6991332244873046, "training_acc": 56.0, "val_loss": 0.7317501950263977, "val_acc": 48.0}
