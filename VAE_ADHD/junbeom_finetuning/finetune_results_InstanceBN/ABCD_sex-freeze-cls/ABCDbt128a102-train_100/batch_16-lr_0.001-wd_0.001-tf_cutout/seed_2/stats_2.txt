"main_modify.py --pretrained_path /scratch/connectome/dyhan316/VAE_ADHD/barlowtwins/pretrain_results/ABCDbt128a102.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 2 --task ABCD_sex --input_option BT_org --learning_rate 1e-3 --batch_size 16 --weight_decay 1e-3 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 0.7405739879608154, "training_acc": 45.0, "val_loss": 0.6986672616004944, "val_acc": 52.0}
{"epoch": 1, "training_loss": 0.7242941904067993, "training_acc": 53.0, "val_loss": 0.7228335285186768, "val_acc": 52.0}
{"epoch": 2, "training_loss": 0.6957386207580566, "training_acc": 53.0, "val_loss": 0.6990318012237549, "val_acc": 48.0}
{"epoch": 3, "training_loss": 0.7066983985900879, "training_acc": 47.0, "val_loss": 0.6951175355911254, "val_acc": 48.0}
{"epoch": 4, "training_loss": 0.6997871685028076, "training_acc": 53.0, "val_loss": 0.7078939795494079, "val_acc": 52.0}
{"epoch": 5, "training_loss": 0.6966144347190857, "training_acc": 53.0, "val_loss": 0.6939903259277344, "val_acc": 40.0}
{"epoch": 6, "training_loss": 0.7232383871078492, "training_acc": 47.0, "val_loss": 0.6985659432411194, "val_acc": 48.0}
{"epoch": 7, "training_loss": 0.7155845594406128, "training_acc": 47.0, "val_loss": 0.7175587010383606, "val_acc": 52.0}
{"epoch": 8, "training_loss": 0.7066256523132324, "training_acc": 51.0, "val_loss": 0.6971859693527221, "val_acc": 48.0}
{"epoch": 9, "training_loss": 0.6977988409996033, "training_acc": 46.0, "val_loss": 0.6934155297279357, "val_acc": 56.0}
{"epoch": 10, "training_loss": 0.6940355920791625, "training_acc": 54.0, "val_loss": 0.6929864120483399, "val_acc": 52.0}
{"epoch": 11, "training_loss": 0.6956305027008056, "training_acc": 41.0, "val_loss": 0.6929410934448242, "val_acc": 52.0}
{"epoch": 12, "training_loss": 0.692138991355896, "training_acc": 53.0, "val_loss": 0.6997445750236512, "val_acc": 52.0}
{"epoch": 13, "training_loss": 0.6862019348144531, "training_acc": 53.0, "val_loss": 0.6949292039871215, "val_acc": 48.0}
{"epoch": 14, "training_loss": 0.7018697905540466, "training_acc": 47.0, "val_loss": 0.7015848851203919, "val_acc": 48.0}
{"epoch": 15, "training_loss": 0.6915473175048829, "training_acc": 55.0, "val_loss": 0.6950222086906434, "val_acc": 52.0}
{"epoch": 16, "training_loss": 0.6917514014244079, "training_acc": 53.0, "val_loss": 0.6930987215042115, "val_acc": 52.0}
{"epoch": 17, "training_loss": 0.6885751676559448, "training_acc": 53.0, "val_loss": 0.694302761554718, "val_acc": 52.0}
{"epoch": 18, "training_loss": 0.6921767663955688, "training_acc": 47.0, "val_loss": 0.6945708394050598, "val_acc": 48.0}
{"epoch": 19, "training_loss": 0.698764660358429, "training_acc": 48.0, "val_loss": 0.6942258548736572, "val_acc": 52.0}
{"epoch": 20, "training_loss": 0.6945443224906921, "training_acc": 43.0, "val_loss": 0.6987336707115174, "val_acc": 48.0}
{"epoch": 21, "training_loss": 0.6947576665878296, "training_acc": 48.0, "val_loss": 0.6927592182159423, "val_acc": 52.0}
{"epoch": 22, "training_loss": 0.6935450267791748, "training_acc": 53.0, "val_loss": 0.70705157995224, "val_acc": 52.0}
{"epoch": 23, "training_loss": 0.6957145309448243, "training_acc": 53.0, "val_loss": 0.6927445578575134, "val_acc": 52.0}
{"epoch": 24, "training_loss": 0.6862576103210449, "training_acc": 53.0, "val_loss": 0.6967477893829346, "val_acc": 52.0}
{"epoch": 25, "training_loss": 0.6979078197479248, "training_acc": 57.0, "val_loss": 0.6927181339263916, "val_acc": 52.0}
{"epoch": 26, "training_loss": 0.7017222356796264, "training_acc": 53.0, "val_loss": 0.6961676502227783, "val_acc": 52.0}
{"epoch": 27, "training_loss": 0.6836558437347412, "training_acc": 52.0, "val_loss": 0.6949850845336915, "val_acc": 48.0}
{"epoch": 28, "training_loss": 0.693253960609436, "training_acc": 49.0, "val_loss": 0.6933682560920715, "val_acc": 52.0}
{"epoch": 29, "training_loss": 0.6964906978607178, "training_acc": 51.0, "val_loss": 0.6931283926963806, "val_acc": 56.0}
{"epoch": 30, "training_loss": 0.6920596694946289, "training_acc": 50.0, "val_loss": 0.6941569471359252, "val_acc": 52.0}
{"epoch": 31, "training_loss": 0.6843270707130432, "training_acc": 52.0, "val_loss": 0.7008288550376892, "val_acc": 52.0}
{"epoch": 32, "training_loss": 0.6895257663726807, "training_acc": 53.0, "val_loss": 0.6946981549263, "val_acc": 52.0}
{"epoch": 33, "training_loss": 0.6886398077011109, "training_acc": 53.0, "val_loss": 0.6934157943725586, "val_acc": 52.0}
{"epoch": 34, "training_loss": 0.693292772769928, "training_acc": 49.0, "val_loss": 0.6939046859741211, "val_acc": 48.0}
{"epoch": 35, "training_loss": 0.686466224193573, "training_acc": 52.0, "val_loss": 0.6977072715759277, "val_acc": 52.0}
{"epoch": 36, "training_loss": 0.6892032098770141, "training_acc": 53.0, "val_loss": 0.6927668690681458, "val_acc": 52.0}
{"epoch": 37, "training_loss": 0.6918164896965027, "training_acc": 51.0, "val_loss": 0.6953387546539307, "val_acc": 48.0}
{"epoch": 38, "training_loss": 0.6933420848846436, "training_acc": 47.0, "val_loss": 0.6941253447532654, "val_acc": 52.0}
{"epoch": 39, "training_loss": 0.685145092010498, "training_acc": 53.0, "val_loss": 0.6949566841125489, "val_acc": 52.0}
{"epoch": 40, "training_loss": 0.6859760451316833, "training_acc": 53.0, "val_loss": 0.6965898060798645, "val_acc": 52.0}
{"epoch": 41, "training_loss": 0.6923056364059448, "training_acc": 53.0, "val_loss": 0.6932023286819458, "val_acc": 56.0}
{"epoch": 42, "training_loss": 0.6798814630508423, "training_acc": 62.0, "val_loss": 0.6968333053588868, "val_acc": 52.0}
{"epoch": 43, "training_loss": 0.6915253877639771, "training_acc": 53.0, "val_loss": 0.7010556149482727, "val_acc": 52.0}
{"epoch": 44, "training_loss": 0.6909615683555603, "training_acc": 59.0, "val_loss": 0.6940603566169739, "val_acc": 44.0}
