"main_modify.py --pretrained_path /scratch/connectome/dyhan316/VAE_ADHD/barlowtwins/pretrain_results/ABCDbt128a102.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 2 --task ABCD_sex --input_option BT_org --learning_rate 1e-3 --batch_size 16 --weight_decay 1e-3 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 0.7221307992935181, "training_acc": 46.0, "val_loss": 0.6910943531990051, "val_acc": 56.0}
{"epoch": 1, "training_loss": 0.7009166145324707, "training_acc": 52.0, "val_loss": 0.6884397625923157, "val_acc": 56.0}
{"epoch": 2, "training_loss": 0.7091599798202515, "training_acc": 52.0, "val_loss": 0.6889188265800477, "val_acc": 56.0}
{"epoch": 3, "training_loss": 0.705631206035614, "training_acc": 42.0, "val_loss": 0.7001446580886841, "val_acc": 44.0}
{"epoch": 4, "training_loss": 0.6962531352043152, "training_acc": 53.0, "val_loss": 0.6885789179801941, "val_acc": 56.0}
{"epoch": 5, "training_loss": 0.6954177784919738, "training_acc": 52.0, "val_loss": 0.6933400416374207, "val_acc": 44.0}
{"epoch": 6, "training_loss": 0.6950137376785278, "training_acc": 54.0, "val_loss": 0.7084675264358521, "val_acc": 44.0}
{"epoch": 7, "training_loss": 0.6989160394668579, "training_acc": 48.0, "val_loss": 0.6868366312980652, "val_acc": 56.0}
{"epoch": 8, "training_loss": 0.701704421043396, "training_acc": 49.0, "val_loss": 0.6924800419807434, "val_acc": 56.0}
{"epoch": 9, "training_loss": 0.6925872087478637, "training_acc": 49.0, "val_loss": 0.6886941313743591, "val_acc": 56.0}
{"epoch": 10, "training_loss": 0.7215713667869568, "training_acc": 52.0, "val_loss": 0.688921971321106, "val_acc": 56.0}
{"epoch": 11, "training_loss": 0.6897252130508423, "training_acc": 59.0, "val_loss": 0.7210160374641419, "val_acc": 44.0}
{"epoch": 12, "training_loss": 0.6947941422462464, "training_acc": 50.0, "val_loss": 0.6881993460655212, "val_acc": 56.0}
{"epoch": 13, "training_loss": 0.7122660589218139, "training_acc": 52.0, "val_loss": 0.6896418070793152, "val_acc": 56.0}
{"epoch": 14, "training_loss": 0.6956967377662658, "training_acc": 48.0, "val_loss": 0.7266507458686828, "val_acc": 44.0}
{"epoch": 15, "training_loss": 0.6984995794296265, "training_acc": 50.0, "val_loss": 0.6891318845748902, "val_acc": 56.0}
{"epoch": 16, "training_loss": 0.6924394416809082, "training_acc": 52.0, "val_loss": 0.6873920321464538, "val_acc": 56.0}
{"epoch": 17, "training_loss": 0.696704626083374, "training_acc": 46.0, "val_loss": 0.6946185255050659, "val_acc": 52.0}
{"epoch": 18, "training_loss": 0.6891935873031616, "training_acc": 56.0, "val_loss": 0.6881025838851929, "val_acc": 56.0}
{"epoch": 19, "training_loss": 0.6957206749916076, "training_acc": 52.0, "val_loss": 0.6907598924636841, "val_acc": 56.0}
{"epoch": 20, "training_loss": 0.6907956957817077, "training_acc": 58.0, "val_loss": 0.6923448419570923, "val_acc": 56.0}
{"epoch": 21, "training_loss": 0.6883837676048279, "training_acc": 55.0, "val_loss": 0.6876094317436219, "val_acc": 56.0}
{"epoch": 22, "training_loss": 0.6962657642364501, "training_acc": 52.0, "val_loss": 0.6882538866996765, "val_acc": 56.0}
{"epoch": 23, "training_loss": 0.6911800432205201, "training_acc": 53.0, "val_loss": 0.6963283109664917, "val_acc": 36.0}
{"epoch": 24, "training_loss": 0.6915572118759156, "training_acc": 47.0, "val_loss": 0.6970747971534729, "val_acc": 40.0}
{"epoch": 25, "training_loss": 0.7018291521072387, "training_acc": 48.0, "val_loss": 0.7160631918907165, "val_acc": 44.0}
{"epoch": 26, "training_loss": 0.7131184959411621, "training_acc": 52.0, "val_loss": 0.6908440923690796, "val_acc": 56.0}
