"main_modify.py --pretrained_path /scratch/connectome/dyhan316/VAE_ADHD/barlowtwins/pretrain_results/ABCDbt128a102.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 2 --task ABCD_sex --input_option BT_org --learning_rate 1e-3 --batch_size 16 --weight_decay 1e-3 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 0.7257668089866638, "training_acc": 43.0, "val_loss": 0.693181393146515, "val_acc": 52.0}
{"epoch": 1, "training_loss": 0.7104955005645752, "training_acc": 49.0, "val_loss": 0.7091233444213867, "val_acc": 52.0}
{"epoch": 2, "training_loss": 0.700674204826355, "training_acc": 53.0, "val_loss": 0.6918125915527343, "val_acc": 52.0}
{"epoch": 3, "training_loss": 0.6926691603660583, "training_acc": 53.0, "val_loss": 0.6918760561943054, "val_acc": 52.0}
{"epoch": 4, "training_loss": 0.6925499773025513, "training_acc": 53.0, "val_loss": 0.6916960644721984, "val_acc": 52.0}
{"epoch": 5, "training_loss": 0.6910205698013305, "training_acc": 53.0, "val_loss": 0.6916214489936828, "val_acc": 52.0}
{"epoch": 6, "training_loss": 0.6957146549224853, "training_acc": 48.0, "val_loss": 0.6928262805938721, "val_acc": 52.0}
{"epoch": 7, "training_loss": 0.7077157521247863, "training_acc": 53.0, "val_loss": 0.720021481513977, "val_acc": 52.0}
{"epoch": 8, "training_loss": 0.7064827966690064, "training_acc": 53.0, "val_loss": 0.6913175916671753, "val_acc": 52.0}
{"epoch": 9, "training_loss": 0.6927287530899048, "training_acc": 53.0, "val_loss": 0.6914332866668701, "val_acc": 52.0}
{"epoch": 10, "training_loss": 0.69127357006073, "training_acc": 49.0, "val_loss": 0.6920152950286865, "val_acc": 60.0}
{"epoch": 11, "training_loss": 0.6946440291404724, "training_acc": 47.0, "val_loss": 0.6912725114822388, "val_acc": 52.0}
{"epoch": 12, "training_loss": 0.6924467492103576, "training_acc": 53.0, "val_loss": 0.6973074913024903, "val_acc": 52.0}
{"epoch": 13, "training_loss": 0.7020948171615601, "training_acc": 43.0, "val_loss": 0.6930057716369629, "val_acc": 48.0}
{"epoch": 14, "training_loss": 0.7002447748184204, "training_acc": 47.0, "val_loss": 0.6929791617393494, "val_acc": 48.0}
{"epoch": 15, "training_loss": 0.6959915161132812, "training_acc": 51.0, "val_loss": 0.7036297082901001, "val_acc": 52.0}
{"epoch": 16, "training_loss": 0.6950831556320191, "training_acc": 53.0, "val_loss": 0.6909548783302307, "val_acc": 52.0}
{"epoch": 17, "training_loss": 0.6997982358932495, "training_acc": 45.0, "val_loss": 0.6940560173988343, "val_acc": 48.0}
{"epoch": 18, "training_loss": 0.6876794338226319, "training_acc": 59.0, "val_loss": 0.6941925382614136, "val_acc": 52.0}
{"epoch": 19, "training_loss": 0.7009153890609742, "training_acc": 53.0, "val_loss": 0.6933430504798889, "val_acc": 52.0}
{"epoch": 20, "training_loss": 0.7020925593376159, "training_acc": 47.0, "val_loss": 0.7133063912391663, "val_acc": 48.0}
{"epoch": 21, "training_loss": 0.7016056966781616, "training_acc": 51.0, "val_loss": 0.691820878982544, "val_acc": 52.0}
{"epoch": 22, "training_loss": 0.6918713474273681, "training_acc": 53.0, "val_loss": 0.6952546095848083, "val_acc": 52.0}
{"epoch": 23, "training_loss": 0.6900011038780213, "training_acc": 58.0, "val_loss": 0.6929926300048828, "val_acc": 48.0}
{"epoch": 24, "training_loss": 0.6930877017974854, "training_acc": 48.0, "val_loss": 0.6903909707069397, "val_acc": 52.0}
{"epoch": 25, "training_loss": 0.6868799161911011, "training_acc": 53.0, "val_loss": 0.6930587840080261, "val_acc": 52.0}
{"epoch": 26, "training_loss": 0.6947400522232056, "training_acc": 49.0, "val_loss": 0.6904091191291809, "val_acc": 56.0}
{"epoch": 27, "training_loss": 0.7003937244415284, "training_acc": 54.0, "val_loss": 0.6961359024047852, "val_acc": 52.0}
{"epoch": 28, "training_loss": 0.6903090190887451, "training_acc": 53.0, "val_loss": 0.693625180721283, "val_acc": 48.0}
{"epoch": 29, "training_loss": 0.6889886593818665, "training_acc": 50.0, "val_loss": 0.6929640936851501, "val_acc": 52.0}
{"epoch": 30, "training_loss": 0.6915759634971619, "training_acc": 53.0, "val_loss": 0.6943963170051575, "val_acc": 52.0}
{"epoch": 31, "training_loss": 0.6877851462364197, "training_acc": 53.0, "val_loss": 0.6898781609535217, "val_acc": 52.0}
{"epoch": 32, "training_loss": 0.6883885097503663, "training_acc": 53.0, "val_loss": 0.6896535348892212, "val_acc": 52.0}
{"epoch": 33, "training_loss": 0.6909732031822204, "training_acc": 53.0, "val_loss": 0.6902459359169006, "val_acc": 52.0}
{"epoch": 34, "training_loss": 0.6849504923820495, "training_acc": 53.0, "val_loss": 0.7000118541717529, "val_acc": 52.0}
{"epoch": 35, "training_loss": 0.6927067756652832, "training_acc": 53.0, "val_loss": 0.6930025720596313, "val_acc": 52.0}
{"epoch": 36, "training_loss": 0.6859257316589356, "training_acc": 55.0, "val_loss": 0.6895931220054626, "val_acc": 52.0}
{"epoch": 37, "training_loss": 0.6895109796524048, "training_acc": 54.0, "val_loss": 0.6921103453636169, "val_acc": 52.0}
{"epoch": 38, "training_loss": 0.6920299196243286, "training_acc": 53.0, "val_loss": 0.6890226054191589, "val_acc": 52.0}
{"epoch": 39, "training_loss": 0.6908109617233277, "training_acc": 48.0, "val_loss": 0.6889316987991333, "val_acc": 52.0}
{"epoch": 40, "training_loss": 0.688827166557312, "training_acc": 53.0, "val_loss": 0.6950331926345825, "val_acc": 52.0}
{"epoch": 41, "training_loss": 0.7021372365951538, "training_acc": 53.0, "val_loss": 0.6918881797790527, "val_acc": 52.0}
{"epoch": 42, "training_loss": 0.6968706035614014, "training_acc": 45.0, "val_loss": 0.7000957608222962, "val_acc": 48.0}
{"epoch": 43, "training_loss": 0.6976492547988892, "training_acc": 49.0, "val_loss": 0.701462185382843, "val_acc": 52.0}
{"epoch": 44, "training_loss": 0.6943518161773682, "training_acc": 53.0, "val_loss": 0.6939220261573792, "val_acc": 52.0}
{"epoch": 45, "training_loss": 0.6884901857376099, "training_acc": 53.0, "val_loss": 0.6890886354446412, "val_acc": 52.0}
{"epoch": 46, "training_loss": 0.6889619326591492, "training_acc": 60.0, "val_loss": 0.6892047214508057, "val_acc": 52.0}
{"epoch": 47, "training_loss": 0.7189567375183106, "training_acc": 53.0, "val_loss": 0.6991334867477417, "val_acc": 52.0}
{"epoch": 48, "training_loss": 0.6907364416122437, "training_acc": 52.0, "val_loss": 0.7184996676445007, "val_acc": 48.0}
{"epoch": 49, "training_loss": 0.7100621461868286, "training_acc": 48.0, "val_loss": 0.6892457747459412, "val_acc": 52.0}
{"epoch": 50, "training_loss": 0.7001437330245972, "training_acc": 53.0, "val_loss": 0.6977737951278686, "val_acc": 52.0}
{"epoch": 51, "training_loss": 0.699049768447876, "training_acc": 53.0, "val_loss": 0.7048330330848693, "val_acc": 48.0}
{"epoch": 52, "training_loss": 0.6809136581420898, "training_acc": 57.0, "val_loss": 0.7039241766929627, "val_acc": 52.0}
{"epoch": 53, "training_loss": 0.739517138004303, "training_acc": 53.0, "val_loss": 0.7068215084075927, "val_acc": 52.0}
{"epoch": 54, "training_loss": 0.6973450493812561, "training_acc": 53.0, "val_loss": 0.7239204144477844, "val_acc": 48.0}
{"epoch": 55, "training_loss": 0.7219815540313721, "training_acc": 47.0, "val_loss": 0.6900253224372864, "val_acc": 52.0}
{"epoch": 56, "training_loss": 0.6824931359291077, "training_acc": 56.0, "val_loss": 0.697223207950592, "val_acc": 52.0}
{"epoch": 57, "training_loss": 0.699243106842041, "training_acc": 53.0, "val_loss": 0.6923689699172973, "val_acc": 52.0}
{"epoch": 58, "training_loss": 0.7278808069229126, "training_acc": 42.0, "val_loss": 0.7095255708694458, "val_acc": 48.0}
