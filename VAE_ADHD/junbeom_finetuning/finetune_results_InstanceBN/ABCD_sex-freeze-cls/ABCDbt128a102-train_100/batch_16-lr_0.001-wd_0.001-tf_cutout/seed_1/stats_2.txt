"main_modify.py --pretrained_path /scratch/connectome/dyhan316/VAE_ADHD/barlowtwins/pretrain_results/ABCDbt128a102.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 1 --task ABCD_sex --input_option BT_org --learning_rate 1e-3 --batch_size 16 --weight_decay 1e-3 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 0.722285361289978, "training_acc": 45.0, "val_loss": 0.6924195504188537, "val_acc": 52.0}
{"epoch": 1, "training_loss": 0.695078444480896, "training_acc": 52.0, "val_loss": 0.697081298828125, "val_acc": 48.0}
{"epoch": 2, "training_loss": 0.699568419456482, "training_acc": 47.0, "val_loss": 0.6978465938568115, "val_acc": 52.0}
{"epoch": 3, "training_loss": 0.6952076148986817, "training_acc": 53.0, "val_loss": 0.6930768132209778, "val_acc": 52.0}
{"epoch": 4, "training_loss": 0.6984758853912354, "training_acc": 47.0, "val_loss": 0.6972032594680786, "val_acc": 48.0}
{"epoch": 5, "training_loss": 0.6927407455444335, "training_acc": 50.0, "val_loss": 0.6945679092407226, "val_acc": 52.0}
{"epoch": 6, "training_loss": 0.7018698167800903, "training_acc": 53.0, "val_loss": 0.7102305626869202, "val_acc": 52.0}
{"epoch": 7, "training_loss": 0.7062568187713623, "training_acc": 47.0, "val_loss": 0.6960200166702271, "val_acc": 48.0}
{"epoch": 8, "training_loss": 0.6990824365615844, "training_acc": 44.0, "val_loss": 0.6918476963043213, "val_acc": 52.0}
{"epoch": 9, "training_loss": 0.6916805744171143, "training_acc": 53.0, "val_loss": 0.6918681454658508, "val_acc": 52.0}
{"epoch": 10, "training_loss": 0.6923632001876832, "training_acc": 53.0, "val_loss": 0.6917607831954956, "val_acc": 52.0}
{"epoch": 11, "training_loss": 0.693182168006897, "training_acc": 53.0, "val_loss": 0.692460970878601, "val_acc": 52.0}
{"epoch": 12, "training_loss": 0.6923087763786316, "training_acc": 53.0, "val_loss": 0.6945017838478088, "val_acc": 52.0}
{"epoch": 13, "training_loss": 0.7035234689712524, "training_acc": 53.0, "val_loss": 0.6942698788642884, "val_acc": 52.0}
{"epoch": 14, "training_loss": 0.7141960287094116, "training_acc": 43.0, "val_loss": 0.6960422205924988, "val_acc": 48.0}
{"epoch": 15, "training_loss": 0.6882768726348877, "training_acc": 52.0, "val_loss": 0.708302149772644, "val_acc": 52.0}
{"epoch": 16, "training_loss": 0.7135307693481445, "training_acc": 53.0, "val_loss": 0.7055720210075378, "val_acc": 52.0}
{"epoch": 17, "training_loss": 0.6987620878219605, "training_acc": 53.0, "val_loss": 0.6928064250946044, "val_acc": 52.0}
{"epoch": 18, "training_loss": 0.6888246083259583, "training_acc": 52.0, "val_loss": 0.6976501655578613, "val_acc": 48.0}
{"epoch": 19, "training_loss": 0.7033515167236328, "training_acc": 47.0, "val_loss": 0.6930286002159118, "val_acc": 48.0}
{"epoch": 20, "training_loss": 0.7069890189170838, "training_acc": 49.0, "val_loss": 0.6957218766212463, "val_acc": 52.0}
{"epoch": 21, "training_loss": 0.6932320117950439, "training_acc": 53.0, "val_loss": 0.6917681074142457, "val_acc": 52.0}
{"epoch": 22, "training_loss": 0.6954732036590576, "training_acc": 53.0, "val_loss": 0.7005824422836304, "val_acc": 52.0}
{"epoch": 23, "training_loss": 0.6970411944389343, "training_acc": 53.0, "val_loss": 0.6907752704620361, "val_acc": 52.0}
{"epoch": 24, "training_loss": 0.6988499021530151, "training_acc": 47.0, "val_loss": 0.6993621897697448, "val_acc": 48.0}
{"epoch": 25, "training_loss": 0.690445876121521, "training_acc": 49.0, "val_loss": 0.6986164855957031, "val_acc": 52.0}
{"epoch": 26, "training_loss": 0.7001191210746766, "training_acc": 53.0, "val_loss": 0.692164089679718, "val_acc": 52.0}
{"epoch": 27, "training_loss": 0.7048089790344239, "training_acc": 41.0, "val_loss": 0.6932917833328247, "val_acc": 48.0}
{"epoch": 28, "training_loss": 0.684035770893097, "training_acc": 60.0, "val_loss": 0.6954001426696778, "val_acc": 52.0}
{"epoch": 29, "training_loss": 0.7109506821632385, "training_acc": 53.0, "val_loss": 0.6960456705093384, "val_acc": 52.0}
{"epoch": 30, "training_loss": 0.7197054243087768, "training_acc": 43.0, "val_loss": 0.7110758590698242, "val_acc": 48.0}
{"epoch": 31, "training_loss": 0.7054488039016724, "training_acc": 47.0, "val_loss": 0.6951767444610596, "val_acc": 52.0}
{"epoch": 32, "training_loss": 0.6964351081848145, "training_acc": 53.0, "val_loss": 0.6979261779785156, "val_acc": 52.0}
{"epoch": 33, "training_loss": 0.6925742673873901, "training_acc": 53.0, "val_loss": 0.6909122300148011, "val_acc": 52.0}
{"epoch": 34, "training_loss": 0.6986170768737793, "training_acc": 44.0, "val_loss": 0.6939254498481751, "val_acc": 48.0}
{"epoch": 35, "training_loss": 0.6939506340026855, "training_acc": 48.0, "val_loss": 0.6949223232269287, "val_acc": 52.0}
{"epoch": 36, "training_loss": 0.700620436668396, "training_acc": 46.0, "val_loss": 0.6922165489196778, "val_acc": 48.0}
{"epoch": 37, "training_loss": 0.6935577774047852, "training_acc": 53.0, "val_loss": 0.691840922832489, "val_acc": 52.0}
{"epoch": 38, "training_loss": 0.689909234046936, "training_acc": 53.0, "val_loss": 0.6909739661216736, "val_acc": 64.0}
{"epoch": 39, "training_loss": 0.6912566232681274, "training_acc": 52.0, "val_loss": 0.6985184144973755, "val_acc": 48.0}
{"epoch": 40, "training_loss": 0.6915556526184082, "training_acc": 54.0, "val_loss": 0.6900636029243469, "val_acc": 52.0}
{"epoch": 41, "training_loss": 0.68641676902771, "training_acc": 53.0, "val_loss": 0.693649377822876, "val_acc": 52.0}
{"epoch": 42, "training_loss": 0.701284601688385, "training_acc": 53.0, "val_loss": 0.7001314234733581, "val_acc": 52.0}
{"epoch": 43, "training_loss": 0.690661587715149, "training_acc": 57.0, "val_loss": 0.6936047482490539, "val_acc": 48.0}
{"epoch": 44, "training_loss": 0.6954114627838135, "training_acc": 50.0, "val_loss": 0.6936332869529724, "val_acc": 48.0}
{"epoch": 45, "training_loss": 0.7111458134651184, "training_acc": 47.0, "val_loss": 0.6947715497016906, "val_acc": 48.0}
{"epoch": 46, "training_loss": 0.6838641047477723, "training_acc": 58.0, "val_loss": 0.7019783020019531, "val_acc": 52.0}
{"epoch": 47, "training_loss": 0.6937448930740356, "training_acc": 53.0, "val_loss": 0.6892368412017822, "val_acc": 52.0}
{"epoch": 48, "training_loss": 0.6928509473800659, "training_acc": 54.0, "val_loss": 0.6996612548828125, "val_acc": 48.0}
{"epoch": 49, "training_loss": 0.6951463508605957, "training_acc": 48.0, "val_loss": 0.6890340828895569, "val_acc": 52.0}
{"epoch": 50, "training_loss": 0.6999842166900635, "training_acc": 53.0, "val_loss": 0.7039147758483887, "val_acc": 52.0}
{"epoch": 51, "training_loss": 0.6932942152023316, "training_acc": 53.0, "val_loss": 0.6903677272796631, "val_acc": 52.0}
{"epoch": 52, "training_loss": 0.6872538042068481, "training_acc": 53.0, "val_loss": 0.6889337921142578, "val_acc": 56.0}
{"epoch": 53, "training_loss": 0.6855791401863098, "training_acc": 65.0, "val_loss": 0.6898622131347656, "val_acc": 64.0}
{"epoch": 54, "training_loss": 0.6876318979263306, "training_acc": 62.0, "val_loss": 0.6893994855880737, "val_acc": 52.0}
{"epoch": 55, "training_loss": 0.7024069786071777, "training_acc": 53.0, "val_loss": 0.7067615342140198, "val_acc": 52.0}
{"epoch": 56, "training_loss": 0.7115479326248169, "training_acc": 53.0, "val_loss": 0.6934353613853455, "val_acc": 52.0}
{"epoch": 57, "training_loss": 0.6769981360435486, "training_acc": 60.0, "val_loss": 0.6962284064292907, "val_acc": 48.0}
{"epoch": 58, "training_loss": 0.7101201272010803, "training_acc": 47.0, "val_loss": 0.6976439595222473, "val_acc": 48.0}
{"epoch": 59, "training_loss": 0.6855915021896363, "training_acc": 60.0, "val_loss": 0.695153934955597, "val_acc": 52.0}
{"epoch": 60, "training_loss": 0.6900343227386475, "training_acc": 53.0, "val_loss": 0.6888736867904663, "val_acc": 52.0}
{"epoch": 61, "training_loss": 0.6995688486099243, "training_acc": 43.0, "val_loss": 0.6927425765991211, "val_acc": 48.0}
{"epoch": 62, "training_loss": 0.6884678077697753, "training_acc": 55.0, "val_loss": 0.6885689043998718, "val_acc": 52.0}
{"epoch": 63, "training_loss": 0.6889134216308593, "training_acc": 59.0, "val_loss": 0.6889761757850646, "val_acc": 64.0}
{"epoch": 64, "training_loss": 0.6843864059448242, "training_acc": 70.0, "val_loss": 0.6889310169219971, "val_acc": 52.0}
{"epoch": 65, "training_loss": 0.6926652526855469, "training_acc": 53.0, "val_loss": 0.6884704899787902, "val_acc": 52.0}
{"epoch": 66, "training_loss": 0.6834269642829895, "training_acc": 58.0, "val_loss": 0.6897699069976807, "val_acc": 52.0}
{"epoch": 67, "training_loss": 0.6890225458145142, "training_acc": 51.0, "val_loss": 0.6898947882652283, "val_acc": 56.0}
{"epoch": 68, "training_loss": 0.6953793263435364, "training_acc": 52.0, "val_loss": 0.6966845417022705, "val_acc": 52.0}
{"epoch": 69, "training_loss": 0.6903404307365417, "training_acc": 53.0, "val_loss": 0.6877743339538575, "val_acc": 52.0}
{"epoch": 70, "training_loss": 0.6991407537460327, "training_acc": 46.0, "val_loss": 0.6935988855361939, "val_acc": 48.0}
{"epoch": 71, "training_loss": 0.685555386543274, "training_acc": 55.0, "val_loss": 0.6907534742355347, "val_acc": 52.0}
{"epoch": 72, "training_loss": 0.6855658435821533, "training_acc": 53.0, "val_loss": 0.6882139253616333, "val_acc": 60.0}
{"epoch": 73, "training_loss": 0.6890602231025695, "training_acc": 54.0, "val_loss": 0.689408917427063, "val_acc": 48.0}
{"epoch": 74, "training_loss": 0.6882740426063537, "training_acc": 49.0, "val_loss": 0.6949638676643372, "val_acc": 52.0}
{"epoch": 75, "training_loss": 0.7031188130378723, "training_acc": 53.0, "val_loss": 0.694556918144226, "val_acc": 52.0}
{"epoch": 76, "training_loss": 0.6914923596382141, "training_acc": 52.0, "val_loss": 0.6963721203804016, "val_acc": 48.0}
{"epoch": 77, "training_loss": 0.7011974430084229, "training_acc": 42.0, "val_loss": 0.6886658382415771, "val_acc": 52.0}
{"epoch": 78, "training_loss": 0.682816526889801, "training_acc": 53.0, "val_loss": 0.688250207901001, "val_acc": 52.0}
{"epoch": 79, "training_loss": 0.6961771106719971, "training_acc": 53.0, "val_loss": 0.6955381417274475, "val_acc": 52.0}
{"epoch": 80, "training_loss": 0.6948138618469238, "training_acc": 52.0, "val_loss": 0.6889490437507629, "val_acc": 48.0}
{"epoch": 81, "training_loss": 0.6832334804534912, "training_acc": 57.0, "val_loss": 0.6972051453590393, "val_acc": 52.0}
{"epoch": 82, "training_loss": 0.6863549637794495, "training_acc": 53.0, "val_loss": 0.6873664450645447, "val_acc": 52.0}
{"epoch": 83, "training_loss": 0.6811539602279663, "training_acc": 57.0, "val_loss": 0.6923929572105407, "val_acc": 48.0}
{"epoch": 84, "training_loss": 0.6896325445175171, "training_acc": 47.0, "val_loss": 0.6891618990898132, "val_acc": 48.0}
{"epoch": 85, "training_loss": 0.6842921543121337, "training_acc": 58.0, "val_loss": 0.687023651599884, "val_acc": 52.0}
{"epoch": 86, "training_loss": 0.6823438501358032, "training_acc": 56.0, "val_loss": 0.6870355463027954, "val_acc": 60.0}
{"epoch": 87, "training_loss": 0.6868084239959716, "training_acc": 50.0, "val_loss": 0.6868879389762879, "val_acc": 52.0}
{"epoch": 88, "training_loss": 0.7005036616325379, "training_acc": 53.0, "val_loss": 0.7048603940010071, "val_acc": 52.0}
{"epoch": 89, "training_loss": 0.7113169956207276, "training_acc": 44.0, "val_loss": 0.6950862622261047, "val_acc": 48.0}
{"epoch": 90, "training_loss": 0.701265218257904, "training_acc": 56.0, "val_loss": 0.6987554168701172, "val_acc": 52.0}
{"epoch": 91, "training_loss": 0.7049488353729249, "training_acc": 44.0, "val_loss": 0.6954642796516418, "val_acc": 48.0}
{"epoch": 92, "training_loss": 0.6799867725372315, "training_acc": 57.0, "val_loss": 0.6915622138977051, "val_acc": 52.0}
{"epoch": 93, "training_loss": 0.7224265789985657, "training_acc": 53.0, "val_loss": 0.7167671203613282, "val_acc": 52.0}
{"epoch": 94, "training_loss": 0.7134662961959839, "training_acc": 47.0, "val_loss": 0.7076909971237183, "val_acc": 48.0}
{"epoch": 95, "training_loss": 0.6962020444869995, "training_acc": 49.0, "val_loss": 0.6884320449829101, "val_acc": 52.0}
{"epoch": 96, "training_loss": 0.6825673770904541, "training_acc": 53.0, "val_loss": 0.6886589431762695, "val_acc": 52.0}
{"epoch": 97, "training_loss": 0.6840384912490844, "training_acc": 53.0, "val_loss": 0.6862886786460877, "val_acc": 60.0}
{"epoch": 98, "training_loss": 0.6796998381614685, "training_acc": 63.0, "val_loss": 0.6970162630081177, "val_acc": 48.0}
{"epoch": 99, "training_loss": 0.6928382182121277, "training_acc": 48.0, "val_loss": 0.6878061032295227, "val_acc": 56.0}
