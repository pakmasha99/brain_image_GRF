"main_modify.py --pretrained_path /scratch/connectome/dyhan316/VAE_ADHD/barlowtwins/pretrain_results/ABCDbt128a102.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 1 --task ABCD_sex --input_option BT_org --learning_rate 1e-3 --batch_size 16 --weight_decay 1e-3 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 0.7076517248153686, "training_acc": 47.0, "val_loss": 0.7106387758255005, "val_acc": 52.0}
{"epoch": 1, "training_loss": 0.731019721031189, "training_acc": 53.0, "val_loss": 0.7053247785568237, "val_acc": 52.0}
{"epoch": 2, "training_loss": 0.700930118560791, "training_acc": 53.0, "val_loss": 0.6908818531036377, "val_acc": 52.0}
{"epoch": 3, "training_loss": 0.703391568660736, "training_acc": 41.0, "val_loss": 0.6911685490608215, "val_acc": 68.0}
{"epoch": 4, "training_loss": 0.693275933265686, "training_acc": 48.0, "val_loss": 0.6921894383430481, "val_acc": 52.0}
{"epoch": 5, "training_loss": 0.7098122501373291, "training_acc": 53.0, "val_loss": 0.7096015977859497, "val_acc": 52.0}
{"epoch": 6, "training_loss": 0.7034658765792847, "training_acc": 53.0, "val_loss": 0.6905029344558716, "val_acc": 52.0}
{"epoch": 7, "training_loss": 0.7056495690345764, "training_acc": 48.0, "val_loss": 0.6981509447097778, "val_acc": 48.0}
{"epoch": 8, "training_loss": 0.6941460537910461, "training_acc": 51.0, "val_loss": 0.6934397912025452, "val_acc": 52.0}
{"epoch": 9, "training_loss": 0.7044791746139526, "training_acc": 53.0, "val_loss": 0.6960542988777161, "val_acc": 52.0}
{"epoch": 10, "training_loss": 0.703212947845459, "training_acc": 45.0, "val_loss": 0.6944971418380738, "val_acc": 48.0}
{"epoch": 11, "training_loss": 0.6934089946746826, "training_acc": 52.0, "val_loss": 0.6916488385200501, "val_acc": 52.0}
{"epoch": 12, "training_loss": 0.6977515172958374, "training_acc": 53.0, "val_loss": 0.7025894165039063, "val_acc": 52.0}
{"epoch": 13, "training_loss": 0.6920654797554016, "training_acc": 53.0, "val_loss": 0.6909891510009766, "val_acc": 64.0}
{"epoch": 14, "training_loss": 0.7126098871231079, "training_acc": 48.0, "val_loss": 0.7029982662200928, "val_acc": 48.0}
{"epoch": 15, "training_loss": 0.7237872123718262, "training_acc": 39.0, "val_loss": 0.6982514953613281, "val_acc": 52.0}
{"epoch": 16, "training_loss": 0.6920242500305176, "training_acc": 53.0, "val_loss": 0.6904731225967408, "val_acc": 52.0}
{"epoch": 17, "training_loss": 0.690721468925476, "training_acc": 53.0, "val_loss": 0.690493266582489, "val_acc": 52.0}
{"epoch": 18, "training_loss": 0.6926854348182678, "training_acc": 47.0, "val_loss": 0.6913277721405029, "val_acc": 56.0}
{"epoch": 19, "training_loss": 0.6873287272453308, "training_acc": 56.0, "val_loss": 0.6955823636054993, "val_acc": 52.0}
{"epoch": 20, "training_loss": 0.7010953259468079, "training_acc": 53.0, "val_loss": 0.6924917936325073, "val_acc": 52.0}
{"epoch": 21, "training_loss": 0.6933326530456543, "training_acc": 53.0, "val_loss": 0.6920269560813904, "val_acc": 52.0}
{"epoch": 22, "training_loss": 0.6968633842468261, "training_acc": 53.0, "val_loss": 0.6956348037719726, "val_acc": 52.0}
{"epoch": 23, "training_loss": 0.6906408262252808, "training_acc": 54.0, "val_loss": 0.698740394115448, "val_acc": 48.0}
{"epoch": 24, "training_loss": 0.7069677209854126, "training_acc": 47.0, "val_loss": 0.6906163811683654, "val_acc": 52.0}
{"epoch": 25, "training_loss": 0.6888862705230713, "training_acc": 53.0, "val_loss": 0.7221292090415955, "val_acc": 52.0}
{"epoch": 26, "training_loss": 0.7058398318290711, "training_acc": 53.0, "val_loss": 0.6908424758911133, "val_acc": 52.0}
{"epoch": 27, "training_loss": 0.6943903231620788, "training_acc": 53.0, "val_loss": 0.690444347858429, "val_acc": 52.0}
{"epoch": 28, "training_loss": 0.7144101858139038, "training_acc": 43.0, "val_loss": 0.7007621312141419, "val_acc": 48.0}
{"epoch": 29, "training_loss": 0.7116092300415039, "training_acc": 45.0, "val_loss": 0.706067464351654, "val_acc": 52.0}
{"epoch": 30, "training_loss": 0.6938739585876464, "training_acc": 53.0, "val_loss": 0.6906719183921814, "val_acc": 52.0}
{"epoch": 31, "training_loss": 0.6880796527862549, "training_acc": 61.0, "val_loss": 0.694129250049591, "val_acc": 48.0}
{"epoch": 32, "training_loss": 0.6941744375228882, "training_acc": 51.0, "val_loss": 0.6906001210212708, "val_acc": 52.0}
{"epoch": 33, "training_loss": 0.6972619104385376, "training_acc": 53.0, "val_loss": 0.7021046423912048, "val_acc": 52.0}
{"epoch": 34, "training_loss": 0.7019368028640747, "training_acc": 53.0, "val_loss": 0.6973938465118408, "val_acc": 52.0}
{"epoch": 35, "training_loss": 0.6943512630462646, "training_acc": 50.0, "val_loss": 0.6985434937477112, "val_acc": 48.0}
{"epoch": 36, "training_loss": 0.7016849088668823, "training_acc": 47.0, "val_loss": 0.6929430150985718, "val_acc": 48.0}
{"epoch": 37, "training_loss": 0.6916396450996399, "training_acc": 45.0, "val_loss": 0.6908864736557007, "val_acc": 56.0}
{"epoch": 38, "training_loss": 0.6881361985206604, "training_acc": 56.0, "val_loss": 0.6937269592285156, "val_acc": 52.0}
{"epoch": 39, "training_loss": 0.6878822207450866, "training_acc": 53.0, "val_loss": 0.6911379837989807, "val_acc": 52.0}
{"epoch": 40, "training_loss": 0.6878597021102906, "training_acc": 56.0, "val_loss": 0.6916938400268555, "val_acc": 48.0}
{"epoch": 41, "training_loss": 0.6897370100021363, "training_acc": 53.0, "val_loss": 0.6907850289344788, "val_acc": 56.0}
{"epoch": 42, "training_loss": 0.6863667583465576, "training_acc": 54.0, "val_loss": 0.6937083792686463, "val_acc": 52.0}
{"epoch": 43, "training_loss": 0.6927132034301757, "training_acc": 52.0, "val_loss": 0.6905831122398376, "val_acc": 52.0}
{"epoch": 44, "training_loss": 0.6851138019561768, "training_acc": 53.0, "val_loss": 0.69225102186203, "val_acc": 52.0}
{"epoch": 45, "training_loss": 0.6905551171302795, "training_acc": 53.0, "val_loss": 0.6957304525375366, "val_acc": 52.0}
{"epoch": 46, "training_loss": 0.70044677734375, "training_acc": 50.0, "val_loss": 0.702298743724823, "val_acc": 48.0}
