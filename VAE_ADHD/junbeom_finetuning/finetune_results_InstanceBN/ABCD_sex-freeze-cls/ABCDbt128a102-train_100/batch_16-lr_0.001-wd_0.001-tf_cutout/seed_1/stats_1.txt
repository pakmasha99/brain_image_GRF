"main_modify.py --pretrained_path /scratch/connectome/dyhan316/VAE_ADHD/barlowtwins/pretrain_results/ABCDbt128a102.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 1 --task ABCD_sex --input_option BT_org --learning_rate 1e-3 --batch_size 16 --weight_decay 1e-3 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 0.700680341720581, "training_acc": 47.0, "val_loss": 0.6936528873443604, "val_acc": 48.0}
{"epoch": 1, "training_loss": 0.696813440322876, "training_acc": 50.0, "val_loss": 0.6928911232948303, "val_acc": 52.0}
{"epoch": 2, "training_loss": 0.6918249940872192, "training_acc": 52.0, "val_loss": 0.6926203751564026, "val_acc": 60.0}
{"epoch": 3, "training_loss": 0.7066352510452271, "training_acc": 46.0, "val_loss": 0.6921860241889953, "val_acc": 52.0}
{"epoch": 4, "training_loss": 0.7362398743629456, "training_acc": 53.0, "val_loss": 0.7271398544311524, "val_acc": 52.0}
{"epoch": 5, "training_loss": 0.6876415300369263, "training_acc": 52.0, "val_loss": 0.6989157104492187, "val_acc": 48.0}
{"epoch": 6, "training_loss": 0.7101771926879883, "training_acc": 47.0, "val_loss": 0.7041214895248413, "val_acc": 48.0}
{"epoch": 7, "training_loss": 0.7002405548095703, "training_acc": 47.0, "val_loss": 0.6934307026863098, "val_acc": 52.0}
{"epoch": 8, "training_loss": 0.6904087448120118, "training_acc": 53.0, "val_loss": 0.6923096847534179, "val_acc": 52.0}
{"epoch": 9, "training_loss": 0.702042601108551, "training_acc": 53.0, "val_loss": 0.7021516680717468, "val_acc": 52.0}
{"epoch": 10, "training_loss": 0.6889105701446533, "training_acc": 53.0, "val_loss": 0.6933216547966004, "val_acc": 52.0}
{"epoch": 11, "training_loss": 0.7092903137207032, "training_acc": 46.0, "val_loss": 0.6960501861572266, "val_acc": 48.0}
{"epoch": 12, "training_loss": 0.6907769870758057, "training_acc": 48.0, "val_loss": 0.6922903943061829, "val_acc": 52.0}
{"epoch": 13, "training_loss": 0.7031343460083008, "training_acc": 53.0, "val_loss": 0.698092827796936, "val_acc": 52.0}
{"epoch": 14, "training_loss": 0.6918650197982789, "training_acc": 54.0, "val_loss": 0.6947361755371094, "val_acc": 48.0}
{"epoch": 15, "training_loss": 0.7029261875152588, "training_acc": 47.0, "val_loss": 0.6932087540626526, "val_acc": 40.0}
{"epoch": 16, "training_loss": 0.687965350151062, "training_acc": 61.0, "val_loss": 0.7063732051849365, "val_acc": 52.0}
{"epoch": 17, "training_loss": 0.7013474321365356, "training_acc": 53.0, "val_loss": 0.6923143720626831, "val_acc": 56.0}
{"epoch": 18, "training_loss": 0.6960315203666687, "training_acc": 53.0, "val_loss": 0.6921746206283569, "val_acc": 52.0}
{"epoch": 19, "training_loss": 0.6935102415084838, "training_acc": 49.0, "val_loss": 0.6929269886016846, "val_acc": 40.0}
{"epoch": 20, "training_loss": 0.6895588374137879, "training_acc": 51.0, "val_loss": 0.6954630136489868, "val_acc": 52.0}
{"epoch": 21, "training_loss": 0.6888971996307373, "training_acc": 53.0, "val_loss": 0.693576967716217, "val_acc": 52.0}
{"epoch": 22, "training_loss": 0.6892175459861756, "training_acc": 52.0, "val_loss": 0.6921868634223938, "val_acc": 52.0}
{"epoch": 23, "training_loss": 0.6970116567611694, "training_acc": 53.0, "val_loss": 0.694089081287384, "val_acc": 52.0}
{"epoch": 24, "training_loss": 0.7024009799957276, "training_acc": 50.0, "val_loss": 0.6985816144943238, "val_acc": 48.0}
{"epoch": 25, "training_loss": 0.6843448972702026, "training_acc": 56.0, "val_loss": 0.6984985089302063, "val_acc": 52.0}
{"epoch": 26, "training_loss": 0.698077564239502, "training_acc": 48.0, "val_loss": 0.6925402402877807, "val_acc": 56.0}
{"epoch": 27, "training_loss": 0.6874604940414428, "training_acc": 58.0, "val_loss": 0.6943667006492614, "val_acc": 52.0}
{"epoch": 28, "training_loss": 0.691326470375061, "training_acc": 53.0, "val_loss": 0.6957584810256958, "val_acc": 52.0}
{"epoch": 29, "training_loss": 0.6935731458663941, "training_acc": 48.0, "val_loss": 0.6945399284362793, "val_acc": 48.0}
{"epoch": 30, "training_loss": 0.690091450214386, "training_acc": 51.0, "val_loss": 0.6935477590560913, "val_acc": 52.0}
{"epoch": 31, "training_loss": 0.686794970035553, "training_acc": 53.0, "val_loss": 0.6930112528800965, "val_acc": 52.0}
{"epoch": 32, "training_loss": 0.7059513473510742, "training_acc": 42.0, "val_loss": 0.6940550327301025, "val_acc": 48.0}
{"epoch": 33, "training_loss": 0.6923709344863892, "training_acc": 49.0, "val_loss": 0.6978854942321777, "val_acc": 52.0}
{"epoch": 34, "training_loss": 0.6947927045822143, "training_acc": 53.0, "val_loss": 0.6942426586151123, "val_acc": 52.0}
{"epoch": 35, "training_loss": 0.6830164170265198, "training_acc": 60.0, "val_loss": 0.6969309258460998, "val_acc": 48.0}
{"epoch": 36, "training_loss": 0.694706916809082, "training_acc": 47.0, "val_loss": 0.6953150177001953, "val_acc": 48.0}
{"epoch": 37, "training_loss": 0.6875551891326904, "training_acc": 50.0, "val_loss": 0.6964909291267395, "val_acc": 52.0}
