"main_modify.py --pretrained_path /scratch/connectome/dyhan316/VAE_ADHD/barlowtwins/pretrain_results/ABCDbt128a102.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option BT_org --learning_rate 1e-3 --batch_size 16 --weight_decay 1e-3 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 0.7108862924575806, "training_acc": 52.0, "val_loss": 0.6936055445671081, "val_acc": 52.0}
{"epoch": 1, "training_loss": 0.693745470046997, "training_acc": 53.0, "val_loss": 0.6963887691497803, "val_acc": 52.0}
{"epoch": 2, "training_loss": 0.6967792654037476, "training_acc": 47.0, "val_loss": 0.6990094113349915, "val_acc": 48.0}
{"epoch": 3, "training_loss": 0.7041061186790466, "training_acc": 47.0, "val_loss": 0.6986302566528321, "val_acc": 48.0}
{"epoch": 4, "training_loss": 0.6962282943725586, "training_acc": 46.0, "val_loss": 0.6973460793495179, "val_acc": 52.0}
{"epoch": 5, "training_loss": 0.6948110103607178, "training_acc": 53.0, "val_loss": 0.6929538369178772, "val_acc": 52.0}
{"epoch": 6, "training_loss": 0.6907495450973511, "training_acc": 54.0, "val_loss": 0.6943891263008117, "val_acc": 48.0}
{"epoch": 7, "training_loss": 0.7076149511337281, "training_acc": 47.0, "val_loss": 0.6929980444908143, "val_acc": 52.0}
{"epoch": 8, "training_loss": 0.6895160341262817, "training_acc": 53.0, "val_loss": 0.7145240712165832, "val_acc": 52.0}
{"epoch": 9, "training_loss": 0.7075480532646179, "training_acc": 53.0, "val_loss": 0.6967307686805725, "val_acc": 52.0}
{"epoch": 10, "training_loss": 0.6973862671852111, "training_acc": 55.0, "val_loss": 0.6927658319473267, "val_acc": 52.0}
{"epoch": 11, "training_loss": 0.6918909215927124, "training_acc": 57.0, "val_loss": 0.6935302019119263, "val_acc": 52.0}
{"epoch": 12, "training_loss": 0.6910218667984008, "training_acc": 53.0, "val_loss": 0.6933257389068603, "val_acc": 52.0}
{"epoch": 13, "training_loss": 0.7030438542366028, "training_acc": 43.0, "val_loss": 0.694164092540741, "val_acc": 48.0}
{"epoch": 14, "training_loss": 0.6922314453125, "training_acc": 49.0, "val_loss": 0.6949577450752258, "val_acc": 52.0}
{"epoch": 15, "training_loss": 0.6892566561698914, "training_acc": 53.0, "val_loss": 0.6931629180908203, "val_acc": 52.0}
{"epoch": 16, "training_loss": 0.6949301433563232, "training_acc": 51.0, "val_loss": 0.6922881627082824, "val_acc": 52.0}
{"epoch": 17, "training_loss": 0.6883310723304749, "training_acc": 53.0, "val_loss": 0.7011948728561401, "val_acc": 52.0}
{"epoch": 18, "training_loss": 0.6930868911743164, "training_acc": 53.0, "val_loss": 0.6921962380409241, "val_acc": 52.0}
{"epoch": 19, "training_loss": 0.690777907371521, "training_acc": 52.0, "val_loss": 0.6932152056694031, "val_acc": 44.0}
{"epoch": 20, "training_loss": 0.6930350637435914, "training_acc": 57.0, "val_loss": 0.6928777313232422, "val_acc": 52.0}
{"epoch": 21, "training_loss": 0.6898418831825256, "training_acc": 53.0, "val_loss": 0.692398750782013, "val_acc": 52.0}
{"epoch": 22, "training_loss": 0.6906366872787476, "training_acc": 55.0, "val_loss": 0.6921173167228699, "val_acc": 52.0}
{"epoch": 23, "training_loss": 0.6923861336708069, "training_acc": 53.0, "val_loss": 0.6943109393119812, "val_acc": 52.0}
{"epoch": 24, "training_loss": 0.6891788148880005, "training_acc": 57.0, "val_loss": 0.6938453197479248, "val_acc": 48.0}
{"epoch": 25, "training_loss": 0.6909524583816529, "training_acc": 50.0, "val_loss": 0.6925649738311768, "val_acc": 52.0}
{"epoch": 26, "training_loss": 0.691302490234375, "training_acc": 53.0, "val_loss": 0.6962120056152343, "val_acc": 52.0}
{"epoch": 27, "training_loss": 0.690070571899414, "training_acc": 53.0, "val_loss": 0.6925266313552857, "val_acc": 52.0}
{"epoch": 28, "training_loss": 0.6894128060340882, "training_acc": 53.0, "val_loss": 0.6933776497840881, "val_acc": 52.0}
{"epoch": 29, "training_loss": 0.6947674345970154, "training_acc": 53.0, "val_loss": 0.6929591369628906, "val_acc": 52.0}
{"epoch": 30, "training_loss": 0.6932259559631347, "training_acc": 50.0, "val_loss": 0.6927638339996338, "val_acc": 52.0}
{"epoch": 31, "training_loss": 0.6947768926620483, "training_acc": 47.0, "val_loss": 0.6920112609863281, "val_acc": 52.0}
{"epoch": 32, "training_loss": 0.694554443359375, "training_acc": 48.0, "val_loss": 0.6920994997024537, "val_acc": 52.0}
{"epoch": 33, "training_loss": 0.6951611113548278, "training_acc": 53.0, "val_loss": 0.7061792039871215, "val_acc": 52.0}
{"epoch": 34, "training_loss": 0.7032801818847656, "training_acc": 49.0, "val_loss": 0.6925049471855164, "val_acc": 52.0}
{"epoch": 35, "training_loss": 0.6972638988494873, "training_acc": 57.0, "val_loss": 0.7075421190261841, "val_acc": 52.0}
{"epoch": 36, "training_loss": 0.6814424180984497, "training_acc": 54.0, "val_loss": 0.6955361580848693, "val_acc": 48.0}
{"epoch": 37, "training_loss": 0.6955984687805176, "training_acc": 47.0, "val_loss": 0.6968821263313294, "val_acc": 48.0}
{"epoch": 38, "training_loss": 0.694927978515625, "training_acc": 49.0, "val_loss": 0.692305920124054, "val_acc": 52.0}
{"epoch": 39, "training_loss": 0.685744092464447, "training_acc": 53.0, "val_loss": 0.6957186055183411, "val_acc": 52.0}
{"epoch": 40, "training_loss": 0.6896725988388062, "training_acc": 53.0, "val_loss": 0.6926419615745545, "val_acc": 52.0}
{"epoch": 41, "training_loss": 0.6884342432022095, "training_acc": 59.0, "val_loss": 0.6921699643135071, "val_acc": 52.0}
{"epoch": 42, "training_loss": 0.6936112952232361, "training_acc": 59.0, "val_loss": 0.6998617339134217, "val_acc": 52.0}
{"epoch": 43, "training_loss": 0.6906209683418274, "training_acc": 53.0, "val_loss": 0.6919093728065491, "val_acc": 52.0}
{"epoch": 44, "training_loss": 0.6859309291839599, "training_acc": 53.0, "val_loss": 0.6925182294845581, "val_acc": 52.0}
{"epoch": 45, "training_loss": 0.6905960273742676, "training_acc": 57.0, "val_loss": 0.6916255187988282, "val_acc": 52.0}
{"epoch": 46, "training_loss": 0.694458875656128, "training_acc": 53.0, "val_loss": 0.6964897704124451, "val_acc": 52.0}
{"epoch": 47, "training_loss": 0.6932336068153382, "training_acc": 53.0, "val_loss": 0.6916060972213746, "val_acc": 52.0}
{"epoch": 48, "training_loss": 0.6879216861724854, "training_acc": 53.0, "val_loss": 0.693111801147461, "val_acc": 48.0}
{"epoch": 49, "training_loss": 0.6929265832901002, "training_acc": 50.0, "val_loss": 0.6927869915962219, "val_acc": 52.0}
{"epoch": 50, "training_loss": 0.6871234488487243, "training_acc": 53.0, "val_loss": 0.6914758443832397, "val_acc": 52.0}
{"epoch": 51, "training_loss": 0.6917455434799195, "training_acc": 48.0, "val_loss": 0.6921726107597351, "val_acc": 60.0}
{"epoch": 52, "training_loss": 0.6879318809509277, "training_acc": 59.0, "val_loss": 0.6954659461975098, "val_acc": 52.0}
{"epoch": 53, "training_loss": 0.6874017524719238, "training_acc": 54.0, "val_loss": 0.6919050526618957, "val_acc": 48.0}
{"epoch": 54, "training_loss": 0.688983702659607, "training_acc": 55.0, "val_loss": 0.6913912534713745, "val_acc": 52.0}
{"epoch": 55, "training_loss": 0.6926144862174988, "training_acc": 53.0, "val_loss": 0.7060506939888, "val_acc": 52.0}
{"epoch": 56, "training_loss": 0.6916546630859375, "training_acc": 50.0, "val_loss": 0.692494866847992, "val_acc": 60.0}
{"epoch": 57, "training_loss": 0.6866470575332642, "training_acc": 55.0, "val_loss": 0.6926311683654786, "val_acc": 52.0}
{"epoch": 58, "training_loss": 0.6882696413993835, "training_acc": 53.0, "val_loss": 0.6934733128547669, "val_acc": 52.0}
{"epoch": 59, "training_loss": 0.6819918990135193, "training_acc": 55.0, "val_loss": 0.6942904615402221, "val_acc": 48.0}
{"epoch": 60, "training_loss": 0.6903767228126526, "training_acc": 53.0, "val_loss": 0.6917798948287964, "val_acc": 60.0}
{"epoch": 61, "training_loss": 0.6886557865142823, "training_acc": 52.0, "val_loss": 0.6917580533027649, "val_acc": 60.0}
{"epoch": 62, "training_loss": 0.6842025375366211, "training_acc": 58.0, "val_loss": 0.6928848600387574, "val_acc": 52.0}
{"epoch": 63, "training_loss": 0.688133225440979, "training_acc": 53.0, "val_loss": 0.6938724184036255, "val_acc": 52.0}
{"epoch": 64, "training_loss": 0.7086582016944886, "training_acc": 53.0, "val_loss": 0.7115248918533326, "val_acc": 52.0}
{"epoch": 65, "training_loss": 0.6903655338287353, "training_acc": 53.0, "val_loss": 0.6919410657882691, "val_acc": 52.0}
{"epoch": 66, "training_loss": 0.687781982421875, "training_acc": 55.0, "val_loss": 0.6915506172180176, "val_acc": 52.0}
{"epoch": 67, "training_loss": 0.6835818290710449, "training_acc": 53.0, "val_loss": 0.6933149838447571, "val_acc": 52.0}
{"epoch": 68, "training_loss": 0.6965218234062195, "training_acc": 48.0, "val_loss": 0.6916041159629822, "val_acc": 56.0}
{"epoch": 69, "training_loss": 0.6772795963287354, "training_acc": 56.0, "val_loss": 0.7071241521835328, "val_acc": 52.0}
{"epoch": 70, "training_loss": 0.6991499519348144, "training_acc": 53.0, "val_loss": 0.6921782326698304, "val_acc": 52.0}
{"epoch": 71, "training_loss": 0.6830757999420166, "training_acc": 60.0, "val_loss": 0.6990359878540039, "val_acc": 48.0}
{"epoch": 72, "training_loss": 0.6949300146102906, "training_acc": 49.0, "val_loss": 0.6952136945724487, "val_acc": 52.0}
{"epoch": 73, "training_loss": 0.7070479393005371, "training_acc": 53.0, "val_loss": 0.7011541390419006, "val_acc": 52.0}
