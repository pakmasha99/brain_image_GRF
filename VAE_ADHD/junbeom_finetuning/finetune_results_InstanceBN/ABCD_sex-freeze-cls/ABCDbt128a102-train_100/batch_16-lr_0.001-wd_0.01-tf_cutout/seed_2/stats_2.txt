"main_modify.py --pretrained_path /scratch/connectome/dyhan316/VAE_ADHD/barlowtwins/pretrain_results/ABCDbt128a102.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 2 --task ABCD_sex --input_option BT_org --learning_rate 1e-3 --batch_size 16 --weight_decay 1e-2 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 0.7276139044761658, "training_acc": 33.0, "val_loss": 0.6968346452713012, "val_acc": 52.0}
{"epoch": 1, "training_loss": 0.696651611328125, "training_acc": 53.0, "val_loss": 0.6973179149627685, "val_acc": 52.0}
{"epoch": 2, "training_loss": 0.6940422964096069, "training_acc": 53.0, "val_loss": 0.6942240643501282, "val_acc": 52.0}
{"epoch": 3, "training_loss": 0.6977018284797668, "training_acc": 47.0, "val_loss": 0.6954792428016663, "val_acc": 48.0}
{"epoch": 4, "training_loss": 0.6859251499176026, "training_acc": 58.0, "val_loss": 0.7087832069396973, "val_acc": 52.0}
{"epoch": 5, "training_loss": 0.7071965193748474, "training_acc": 53.0, "val_loss": 0.7050880122184754, "val_acc": 52.0}
{"epoch": 6, "training_loss": 0.7021269989013672, "training_acc": 53.0, "val_loss": 0.7027218675613404, "val_acc": 52.0}
{"epoch": 7, "training_loss": 0.6945655775070191, "training_acc": 53.0, "val_loss": 0.6944327592849732, "val_acc": 52.0}
{"epoch": 8, "training_loss": 0.7007355213165283, "training_acc": 48.0, "val_loss": 0.6967327046394348, "val_acc": 48.0}
{"epoch": 9, "training_loss": 0.6924921655654908, "training_acc": 56.0, "val_loss": 0.6969338703155518, "val_acc": 52.0}
{"epoch": 10, "training_loss": 0.6965287399291992, "training_acc": 53.0, "val_loss": 0.6938881850242615, "val_acc": 52.0}
{"epoch": 11, "training_loss": 0.6931161093711853, "training_acc": 51.0, "val_loss": 0.6944851207733155, "val_acc": 60.0}
{"epoch": 12, "training_loss": 0.69899080991745, "training_acc": 51.0, "val_loss": 0.694229633808136, "val_acc": 40.0}
{"epoch": 13, "training_loss": 0.6971428442001343, "training_acc": 57.0, "val_loss": 0.7041416096687317, "val_acc": 52.0}
{"epoch": 14, "training_loss": 0.7031192255020141, "training_acc": 53.0, "val_loss": 0.694340374469757, "val_acc": 40.0}
{"epoch": 15, "training_loss": 0.686471848487854, "training_acc": 57.0, "val_loss": 0.6999018716812134, "val_acc": 52.0}
{"epoch": 16, "training_loss": 0.6981727027893067, "training_acc": 53.0, "val_loss": 0.6944321489334107, "val_acc": 52.0}
{"epoch": 17, "training_loss": 0.6938606715202331, "training_acc": 53.0, "val_loss": 0.6963069128990174, "val_acc": 52.0}
{"epoch": 18, "training_loss": 0.6907574391365051, "training_acc": 53.0, "val_loss": 0.6942585825920105, "val_acc": 52.0}
{"epoch": 19, "training_loss": 0.6942660975456237, "training_acc": 53.0, "val_loss": 0.6944691586494446, "val_acc": 52.0}
{"epoch": 20, "training_loss": 0.6999007654190064, "training_acc": 53.0, "val_loss": 0.7079214787483216, "val_acc": 52.0}
{"epoch": 21, "training_loss": 0.6961346459388733, "training_acc": 45.0, "val_loss": 0.6981436371803283, "val_acc": 48.0}
{"epoch": 22, "training_loss": 0.6943497371673584, "training_acc": 45.0, "val_loss": 0.6936352920532226, "val_acc": 52.0}
{"epoch": 23, "training_loss": 0.6897788763046264, "training_acc": 53.0, "val_loss": 0.6937525606155396, "val_acc": 52.0}
{"epoch": 24, "training_loss": 0.6882330250740051, "training_acc": 53.0, "val_loss": 0.6947869133949279, "val_acc": 52.0}
{"epoch": 25, "training_loss": 0.6895013356208801, "training_acc": 53.0, "val_loss": 0.6940035319328308, "val_acc": 52.0}
{"epoch": 26, "training_loss": 0.6899781656265259, "training_acc": 53.0, "val_loss": 0.6999294757843018, "val_acc": 52.0}
{"epoch": 27, "training_loss": 0.6927178001403809, "training_acc": 53.0, "val_loss": 0.6970416069030761, "val_acc": 52.0}
{"epoch": 28, "training_loss": 0.6896997547149658, "training_acc": 53.0, "val_loss": 0.6936538028717041, "val_acc": 52.0}
{"epoch": 29, "training_loss": 0.6936059951782226, "training_acc": 50.0, "val_loss": 0.7022510147094727, "val_acc": 48.0}
{"epoch": 30, "training_loss": 0.6952651405334472, "training_acc": 47.0, "val_loss": 0.6935439848899841, "val_acc": 52.0}
{"epoch": 31, "training_loss": 0.6831564021110534, "training_acc": 53.0, "val_loss": 0.7108795499801636, "val_acc": 52.0}
{"epoch": 32, "training_loss": 0.7058717322349548, "training_acc": 53.0, "val_loss": 0.6992852735519409, "val_acc": 52.0}
{"epoch": 33, "training_loss": 0.6901936864852906, "training_acc": 52.0, "val_loss": 0.6950116467475891, "val_acc": 48.0}
{"epoch": 34, "training_loss": 0.6926865744590759, "training_acc": 45.0, "val_loss": 0.6936096620559692, "val_acc": 52.0}
{"epoch": 35, "training_loss": 0.6865856862068176, "training_acc": 63.0, "val_loss": 0.6947422862052918, "val_acc": 56.0}
{"epoch": 36, "training_loss": 0.691483998298645, "training_acc": 45.0, "val_loss": 0.6958201432228088, "val_acc": 52.0}
{"epoch": 37, "training_loss": 0.6887802553176879, "training_acc": 53.0, "val_loss": 0.6935544967651367, "val_acc": 52.0}
{"epoch": 38, "training_loss": 0.6897683310508728, "training_acc": 57.0, "val_loss": 0.6947374677658081, "val_acc": 56.0}
{"epoch": 39, "training_loss": 0.6934794235229492, "training_acc": 48.0, "val_loss": 0.695152816772461, "val_acc": 48.0}
{"epoch": 40, "training_loss": 0.6832581090927125, "training_acc": 58.0, "val_loss": 0.6974920749664306, "val_acc": 52.0}
{"epoch": 41, "training_loss": 0.6925129556655883, "training_acc": 53.0, "val_loss": 0.7017057323455811, "val_acc": 52.0}
{"epoch": 42, "training_loss": 0.6891746997833252, "training_acc": 53.0, "val_loss": 0.6938621830940247, "val_acc": 52.0}
{"epoch": 43, "training_loss": 0.6955970335006714, "training_acc": 50.0, "val_loss": 0.6955105900764466, "val_acc": 48.0}
{"epoch": 44, "training_loss": 0.6838631248474121, "training_acc": 61.0, "val_loss": 0.697341730594635, "val_acc": 52.0}
{"epoch": 45, "training_loss": 0.6933069944381713, "training_acc": 53.0, "val_loss": 0.7034621167182923, "val_acc": 52.0}
{"epoch": 46, "training_loss": 0.6883744120597839, "training_acc": 53.0, "val_loss": 0.6936170983314515, "val_acc": 52.0}
{"epoch": 47, "training_loss": 0.6821818423271179, "training_acc": 59.0, "val_loss": 0.7037818622589112, "val_acc": 48.0}
{"epoch": 48, "training_loss": 0.7009795618057251, "training_acc": 47.0, "val_loss": 0.6949840354919433, "val_acc": 56.0}
{"epoch": 49, "training_loss": 0.6868920612335205, "training_acc": 54.0, "val_loss": 0.6991767525672913, "val_acc": 52.0}
{"epoch": 50, "training_loss": 0.6897545480728149, "training_acc": 53.0, "val_loss": 0.6932825398445129, "val_acc": 52.0}
{"epoch": 51, "training_loss": 0.6892631626129151, "training_acc": 53.0, "val_loss": 0.7032447862625122, "val_acc": 48.0}
{"epoch": 52, "training_loss": 0.6910887098312378, "training_acc": 49.0, "val_loss": 0.6970749640464783, "val_acc": 52.0}
{"epoch": 53, "training_loss": 0.6932956147193908, "training_acc": 53.0, "val_loss": 0.6992094850540161, "val_acc": 52.0}
{"epoch": 54, "training_loss": 0.6842565774917603, "training_acc": 55.0, "val_loss": 0.697659924030304, "val_acc": 48.0}
{"epoch": 55, "training_loss": 0.6945649290084839, "training_acc": 47.0, "val_loss": 0.702161250114441, "val_acc": 48.0}
{"epoch": 56, "training_loss": 0.6867450165748596, "training_acc": 53.0, "val_loss": 0.6996059083938598, "val_acc": 52.0}
{"epoch": 57, "training_loss": 0.6875220823287964, "training_acc": 53.0, "val_loss": 0.7070739722251892, "val_acc": 52.0}
{"epoch": 58, "training_loss": 0.6951360368728637, "training_acc": 53.0, "val_loss": 0.6948211646080017, "val_acc": 52.0}
{"epoch": 59, "training_loss": 0.683009524345398, "training_acc": 52.0, "val_loss": 0.6936767148971558, "val_acc": 36.0}
{"epoch": 60, "training_loss": 0.6827060389518738, "training_acc": 61.0, "val_loss": 0.6954281544685363, "val_acc": 48.0}
{"epoch": 61, "training_loss": 0.6940395212173462, "training_acc": 50.0, "val_loss": 0.6970432233810425, "val_acc": 52.0}
{"epoch": 62, "training_loss": 0.6932277631759644, "training_acc": 51.0, "val_loss": 0.7098356437683105, "val_acc": 48.0}
{"epoch": 63, "training_loss": 0.6996907472610474, "training_acc": 47.0, "val_loss": 0.6932424259185791, "val_acc": 52.0}
{"epoch": 64, "training_loss": 0.6827851271629334, "training_acc": 53.0, "val_loss": 0.694881284236908, "val_acc": 52.0}
{"epoch": 65, "training_loss": 0.6835432195663452, "training_acc": 53.0, "val_loss": 0.6939468121528626, "val_acc": 52.0}
{"epoch": 66, "training_loss": 0.6816487526893615, "training_acc": 53.0, "val_loss": 0.6937374448776246, "val_acc": 52.0}
{"epoch": 67, "training_loss": 0.6797619032859802, "training_acc": 53.0, "val_loss": 0.6943448686599731, "val_acc": 52.0}
{"epoch": 68, "training_loss": 0.6836098456382751, "training_acc": 53.0, "val_loss": 0.6930962777137757, "val_acc": 52.0}
{"epoch": 69, "training_loss": 0.6814608407020569, "training_acc": 53.0, "val_loss": 0.6931098341941834, "val_acc": 52.0}
{"epoch": 70, "training_loss": 0.684428870677948, "training_acc": 59.0, "val_loss": 0.693190643787384, "val_acc": 52.0}
{"epoch": 71, "training_loss": 0.6898220872879028, "training_acc": 53.0, "val_loss": 0.6932641363143921, "val_acc": 52.0}
{"epoch": 72, "training_loss": 0.6928025341033935, "training_acc": 45.0, "val_loss": 0.6948180270195007, "val_acc": 52.0}
{"epoch": 73, "training_loss": 0.6848889589309692, "training_acc": 56.0, "val_loss": 0.7038738489151001, "val_acc": 52.0}
{"epoch": 74, "training_loss": 0.6824740123748779, "training_acc": 53.0, "val_loss": 0.6928589820861817, "val_acc": 52.0}
{"epoch": 75, "training_loss": 0.6844822263717651, "training_acc": 52.0, "val_loss": 0.6970888543128967, "val_acc": 48.0}
{"epoch": 76, "training_loss": 0.6883331871032715, "training_acc": 56.0, "val_loss": 0.7047220802307129, "val_acc": 52.0}
{"epoch": 77, "training_loss": 0.6982707285881042, "training_acc": 49.0, "val_loss": 0.7021117758750915, "val_acc": 48.0}
{"epoch": 78, "training_loss": 0.6936881351470947, "training_acc": 47.0, "val_loss": 0.7039440703392029, "val_acc": 52.0}
{"epoch": 79, "training_loss": 0.7103451633453369, "training_acc": 53.0, "val_loss": 0.7050125551223755, "val_acc": 52.0}
{"epoch": 80, "training_loss": 0.6907516765594482, "training_acc": 52.0, "val_loss": 0.721434326171875, "val_acc": 48.0}
{"epoch": 81, "training_loss": 0.7035240793228149, "training_acc": 44.0, "val_loss": 0.6928266119956971, "val_acc": 52.0}
{"epoch": 82, "training_loss": 0.6781323361396789, "training_acc": 53.0, "val_loss": 0.6941314268112183, "val_acc": 52.0}
{"epoch": 83, "training_loss": 0.6768511819839478, "training_acc": 54.0, "val_loss": 0.6932546544075012, "val_acc": 40.0}
{"epoch": 84, "training_loss": 0.6969066429138183, "training_acc": 47.0, "val_loss": 0.6939754796028137, "val_acc": 52.0}
{"epoch": 85, "training_loss": 0.6873639345169067, "training_acc": 57.0, "val_loss": 0.7115076041221619, "val_acc": 52.0}
{"epoch": 86, "training_loss": 0.6858692979812622, "training_acc": 53.0, "val_loss": 0.6930238127708435, "val_acc": 40.0}
{"epoch": 87, "training_loss": 0.679850606918335, "training_acc": 60.0, "val_loss": 0.6959557557106018, "val_acc": 48.0}
{"epoch": 88, "training_loss": 0.6803246641159058, "training_acc": 55.0, "val_loss": 0.6964806771278381, "val_acc": 52.0}
{"epoch": 89, "training_loss": 0.6839551496505737, "training_acc": 53.0, "val_loss": 0.6985552310943604, "val_acc": 52.0}
{"epoch": 90, "training_loss": 0.6889646244049072, "training_acc": 51.0, "val_loss": 0.6994664096832275, "val_acc": 48.0}
{"epoch": 91, "training_loss": 0.7053874444961548, "training_acc": 47.0, "val_loss": 0.7042555975914001, "val_acc": 52.0}
{"epoch": 92, "training_loss": 0.6821667456626892, "training_acc": 53.0, "val_loss": 0.6928349113464356, "val_acc": 52.0}
{"epoch": 93, "training_loss": 0.6835630655288696, "training_acc": 55.0, "val_loss": 0.7024089121818542, "val_acc": 48.0}
{"epoch": 94, "training_loss": 0.6814189457893371, "training_acc": 60.0, "val_loss": 0.6954102921485901, "val_acc": 52.0}
{"epoch": 95, "training_loss": 0.6872828507423401, "training_acc": 53.0, "val_loss": 0.6979026770591736, "val_acc": 52.0}
{"epoch": 96, "training_loss": 0.6967380142211914, "training_acc": 52.0, "val_loss": 0.7184053611755371, "val_acc": 48.0}
{"epoch": 97, "training_loss": 0.7000312972068786, "training_acc": 49.0, "val_loss": 0.6951021242141724, "val_acc": 52.0}
{"epoch": 98, "training_loss": 0.67502920627594, "training_acc": 54.0, "val_loss": 0.6926622962951661, "val_acc": 48.0}
{"epoch": 99, "training_loss": 0.6734579658508301, "training_acc": 72.0, "val_loss": 0.6958133411407471, "val_acc": 56.0}
