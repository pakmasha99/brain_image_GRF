"main_modify.py --pretrained_path /scratch/connectome/dyhan316/VAE_ADHD/barlowtwins/pretrain_results/ABCDbt128a102.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 2 --task ABCD_sex --input_option BT_org --learning_rate 1e-3 --batch_size 16 --weight_decay 1e-2 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 0.7040628433227539, "training_acc": 49.0, "val_loss": 0.7039463496208191, "val_acc": 52.0}
{"epoch": 1, "training_loss": 0.7263452768325805, "training_acc": 39.0, "val_loss": 0.6906425738334656, "val_acc": 52.0}
{"epoch": 2, "training_loss": 0.7075163555145264, "training_acc": 55.0, "val_loss": 0.7210045170783996, "val_acc": 52.0}
{"epoch": 3, "training_loss": 0.7019978737831116, "training_acc": 53.0, "val_loss": 0.6911808323860168, "val_acc": 56.0}
{"epoch": 4, "training_loss": 0.7100452923774719, "training_acc": 47.0, "val_loss": 0.6997265625, "val_acc": 48.0}
{"epoch": 5, "training_loss": 0.7160365915298462, "training_acc": 49.0, "val_loss": 0.7126607465744018, "val_acc": 52.0}
{"epoch": 6, "training_loss": 0.7021726489067077, "training_acc": 53.0, "val_loss": 0.6901979851722717, "val_acc": 52.0}
{"epoch": 7, "training_loss": 0.6908577036857605, "training_acc": 53.0, "val_loss": 0.6900744581222534, "val_acc": 52.0}
{"epoch": 8, "training_loss": 0.6934297752380371, "training_acc": 51.0, "val_loss": 0.6914379811286926, "val_acc": 52.0}
{"epoch": 9, "training_loss": 0.6919993209838867, "training_acc": 53.0, "val_loss": 0.7039554190635681, "val_acc": 52.0}
{"epoch": 10, "training_loss": 0.6938277959823609, "training_acc": 53.0, "val_loss": 0.6898614573478699, "val_acc": 52.0}
{"epoch": 11, "training_loss": 0.6920995473861694, "training_acc": 53.0, "val_loss": 0.701667218208313, "val_acc": 48.0}
{"epoch": 12, "training_loss": 0.6990864562988282, "training_acc": 47.0, "val_loss": 0.6911433148384094, "val_acc": 52.0}
{"epoch": 13, "training_loss": 0.7012686538696289, "training_acc": 53.0, "val_loss": 0.6993161702156067, "val_acc": 52.0}
{"epoch": 14, "training_loss": 0.7225603103637696, "training_acc": 41.0, "val_loss": 0.7050989961624146, "val_acc": 48.0}
{"epoch": 15, "training_loss": 0.7060314416885376, "training_acc": 43.0, "val_loss": 0.6917476272583007, "val_acc": 52.0}
{"epoch": 16, "training_loss": 0.7001532244682313, "training_acc": 53.0, "val_loss": 0.6938969755172729, "val_acc": 52.0}
{"epoch": 17, "training_loss": 0.7091393446922303, "training_acc": 39.0, "val_loss": 0.6929125475883484, "val_acc": 48.0}
{"epoch": 18, "training_loss": 0.6890824317932129, "training_acc": 49.0, "val_loss": 0.6982244992256165, "val_acc": 52.0}
{"epoch": 19, "training_loss": 0.6965861320495605, "training_acc": 53.0, "val_loss": 0.7002314305305481, "val_acc": 52.0}
{"epoch": 20, "training_loss": 0.6963097620010376, "training_acc": 53.0, "val_loss": 0.6892130041122436, "val_acc": 52.0}
{"epoch": 21, "training_loss": 0.6976493740081787, "training_acc": 45.0, "val_loss": 0.6893572640419007, "val_acc": 60.0}
{"epoch": 22, "training_loss": 0.6915947008132934, "training_acc": 53.0, "val_loss": 0.6911822843551636, "val_acc": 52.0}
{"epoch": 23, "training_loss": 0.688075020313263, "training_acc": 54.0, "val_loss": 0.6908809614181518, "val_acc": 48.0}
{"epoch": 24, "training_loss": 0.6937881898880005, "training_acc": 47.0, "val_loss": 0.6916922402381896, "val_acc": 48.0}
{"epoch": 25, "training_loss": 0.699694995880127, "training_acc": 44.0, "val_loss": 0.6929922986030579, "val_acc": 52.0}
{"epoch": 26, "training_loss": 0.7286559534072876, "training_acc": 35.0, "val_loss": 0.6910815954208374, "val_acc": 48.0}
{"epoch": 27, "training_loss": 0.7139635801315307, "training_acc": 51.0, "val_loss": 0.7094001126289368, "val_acc": 52.0}
{"epoch": 28, "training_loss": 0.6992670893669128, "training_acc": 55.0, "val_loss": 0.6941972374916077, "val_acc": 48.0}
{"epoch": 29, "training_loss": 0.7047606801986694, "training_acc": 47.0, "val_loss": 0.7044174575805664, "val_acc": 48.0}
{"epoch": 30, "training_loss": 0.7029235172271728, "training_acc": 45.0, "val_loss": 0.689090473651886, "val_acc": 52.0}
{"epoch": 31, "training_loss": 0.69199640750885, "training_acc": 53.0, "val_loss": 0.6908946537971496, "val_acc": 52.0}
{"epoch": 32, "training_loss": 0.6949583911895751, "training_acc": 51.0, "val_loss": 0.6890406227111816, "val_acc": 52.0}
{"epoch": 33, "training_loss": 0.686667423248291, "training_acc": 56.0, "val_loss": 0.6949204587936402, "val_acc": 52.0}
{"epoch": 34, "training_loss": 0.6911335253715515, "training_acc": 53.0, "val_loss": 0.6895269775390624, "val_acc": 52.0}
{"epoch": 35, "training_loss": 0.6903430104255677, "training_acc": 59.0, "val_loss": 0.6907390213012695, "val_acc": 48.0}
{"epoch": 36, "training_loss": 0.6922855114936829, "training_acc": 48.0, "val_loss": 0.688383891582489, "val_acc": 52.0}
{"epoch": 37, "training_loss": 0.7188387989997864, "training_acc": 53.0, "val_loss": 0.6993719172477723, "val_acc": 52.0}
{"epoch": 38, "training_loss": 0.6827913475036621, "training_acc": 59.0, "val_loss": 0.6981181120872497, "val_acc": 48.0}
{"epoch": 39, "training_loss": 0.6989995312690734, "training_acc": 47.0, "val_loss": 0.6885781288146973, "val_acc": 56.0}
{"epoch": 40, "training_loss": 0.6897830104827881, "training_acc": 56.0, "val_loss": 0.7073883485794067, "val_acc": 52.0}
{"epoch": 41, "training_loss": 0.7035951519012451, "training_acc": 53.0, "val_loss": 0.6976126122474671, "val_acc": 52.0}
{"epoch": 42, "training_loss": 0.6867271041870118, "training_acc": 52.0, "val_loss": 0.6894523811340332, "val_acc": 56.0}
{"epoch": 43, "training_loss": 0.691189980506897, "training_acc": 48.0, "val_loss": 0.6883620190620422, "val_acc": 52.0}
{"epoch": 44, "training_loss": 0.6823658800125122, "training_acc": 54.0, "val_loss": 0.6961417007446289, "val_acc": 52.0}
{"epoch": 45, "training_loss": 0.693194386959076, "training_acc": 53.0, "val_loss": 0.689168438911438, "val_acc": 52.0}
{"epoch": 46, "training_loss": 0.6948869943618774, "training_acc": 52.0, "val_loss": 0.6888591909408569, "val_acc": 80.0}
{"epoch": 47, "training_loss": 0.7093371677398682, "training_acc": 50.0, "val_loss": 0.7041414093971252, "val_acc": 52.0}
{"epoch": 48, "training_loss": 0.6991494512557983, "training_acc": 54.0, "val_loss": 0.6883629965782165, "val_acc": 52.0}
{"epoch": 49, "training_loss": 0.690957498550415, "training_acc": 56.0, "val_loss": 0.6903633117675781, "val_acc": 52.0}
{"epoch": 50, "training_loss": 0.6920194339752197, "training_acc": 53.0, "val_loss": 0.6878253078460693, "val_acc": 52.0}
{"epoch": 51, "training_loss": 0.6914202952384949, "training_acc": 47.0, "val_loss": 0.6877489733695984, "val_acc": 52.0}
{"epoch": 52, "training_loss": 0.6849721455574036, "training_acc": 54.0, "val_loss": 0.699456353187561, "val_acc": 52.0}
{"epoch": 53, "training_loss": 0.6981582045555115, "training_acc": 53.0, "val_loss": 0.6924986267089843, "val_acc": 52.0}
{"epoch": 54, "training_loss": 0.6959004354476929, "training_acc": 56.0, "val_loss": 0.68824383020401, "val_acc": 52.0}
{"epoch": 55, "training_loss": 0.6848776125907898, "training_acc": 53.0, "val_loss": 0.6948522210121155, "val_acc": 52.0}
{"epoch": 56, "training_loss": 0.6878200149536133, "training_acc": 53.0, "val_loss": 0.6872203087806702, "val_acc": 52.0}
{"epoch": 57, "training_loss": 0.7062684774398804, "training_acc": 49.0, "val_loss": 0.6965722370147706, "val_acc": 48.0}
{"epoch": 58, "training_loss": 0.709318823814392, "training_acc": 46.0, "val_loss": 0.7021584224700927, "val_acc": 52.0}
{"epoch": 59, "training_loss": 0.7002204179763794, "training_acc": 53.0, "val_loss": 0.6911037349700928, "val_acc": 52.0}
{"epoch": 60, "training_loss": 0.6961929798126221, "training_acc": 44.0, "val_loss": 0.6963697957992554, "val_acc": 48.0}
{"epoch": 61, "training_loss": 0.6968135380744934, "training_acc": 48.0, "val_loss": 0.6869098758697509, "val_acc": 52.0}
{"epoch": 62, "training_loss": 0.704565634727478, "training_acc": 53.0, "val_loss": 0.7083971452713013, "val_acc": 52.0}
{"epoch": 63, "training_loss": 0.704610869884491, "training_acc": 49.0, "val_loss": 0.6910149693489075, "val_acc": 48.0}
{"epoch": 64, "training_loss": 0.6944717025756836, "training_acc": 47.0, "val_loss": 0.6866070938110351, "val_acc": 56.0}
{"epoch": 65, "training_loss": 0.6866522049903869, "training_acc": 53.0, "val_loss": 0.7076771116256714, "val_acc": 52.0}
{"epoch": 66, "training_loss": 0.6894729328155518, "training_acc": 53.0, "val_loss": 0.6863760018348694, "val_acc": 56.0}
{"epoch": 67, "training_loss": 0.6958642292022705, "training_acc": 51.0, "val_loss": 0.7073028206825256, "val_acc": 48.0}
{"epoch": 68, "training_loss": 0.6965366768836975, "training_acc": 53.0, "val_loss": 0.6884632992744446, "val_acc": 52.0}
{"epoch": 69, "training_loss": 0.6871373605728149, "training_acc": 53.0, "val_loss": 0.6888793516159057, "val_acc": 52.0}
{"epoch": 70, "training_loss": 0.6844034433364868, "training_acc": 53.0, "val_loss": 0.6861352467536926, "val_acc": 52.0}
{"epoch": 71, "training_loss": 0.6854817533493042, "training_acc": 63.0, "val_loss": 0.6864761304855347, "val_acc": 52.0}
{"epoch": 72, "training_loss": 0.6864811730384827, "training_acc": 62.0, "val_loss": 0.6878682041168213, "val_acc": 64.0}
{"epoch": 73, "training_loss": 0.6859182643890381, "training_acc": 55.0, "val_loss": 0.6877048897743225, "val_acc": 52.0}
{"epoch": 74, "training_loss": 0.6833204364776612, "training_acc": 53.0, "val_loss": 0.6859524655342102, "val_acc": 52.0}
{"epoch": 75, "training_loss": 0.6933137273788452, "training_acc": 53.0, "val_loss": 0.6895481061935425, "val_acc": 52.0}
{"epoch": 76, "training_loss": 0.6990908336639404, "training_acc": 48.0, "val_loss": 0.6940884137153626, "val_acc": 48.0}
{"epoch": 77, "training_loss": 0.6741579246520996, "training_acc": 64.0, "val_loss": 0.7008310008049011, "val_acc": 52.0}
{"epoch": 78, "training_loss": 0.7155440759658813, "training_acc": 53.0, "val_loss": 0.7042524456977844, "val_acc": 52.0}
{"epoch": 79, "training_loss": 0.6807123136520385, "training_acc": 53.0, "val_loss": 0.691351363658905, "val_acc": 48.0}
{"epoch": 80, "training_loss": 0.6929002380371094, "training_acc": 49.0, "val_loss": 0.6857503342628479, "val_acc": 56.0}
{"epoch": 81, "training_loss": 0.6817341899871826, "training_acc": 55.0, "val_loss": 0.6855751085281372, "val_acc": 52.0}
{"epoch": 82, "training_loss": 0.6814537119865417, "training_acc": 62.0, "val_loss": 0.6856855845451355, "val_acc": 52.0}
{"epoch": 83, "training_loss": 0.6843641805648804, "training_acc": 57.0, "val_loss": 0.6856470870971679, "val_acc": 52.0}
{"epoch": 84, "training_loss": 0.6823087525367737, "training_acc": 54.0, "val_loss": 0.6872210741043091, "val_acc": 52.0}
{"epoch": 85, "training_loss": 0.6831721878051757, "training_acc": 53.0, "val_loss": 0.6852761578559875, "val_acc": 56.0}
{"epoch": 86, "training_loss": 0.6911965656280518, "training_acc": 56.0, "val_loss": 0.7007919383049012, "val_acc": 48.0}
{"epoch": 87, "training_loss": 0.6907462692260742, "training_acc": 53.0, "val_loss": 0.6937669706344605, "val_acc": 52.0}
{"epoch": 88, "training_loss": 0.6908584022521973, "training_acc": 53.0, "val_loss": 0.6864520764350891, "val_acc": 52.0}
{"epoch": 89, "training_loss": 0.6847853660583496, "training_acc": 56.0, "val_loss": 0.6852126359939575, "val_acc": 52.0}
{"epoch": 90, "training_loss": 0.6787310934066773, "training_acc": 57.0, "val_loss": 0.6936950016021729, "val_acc": 52.0}
{"epoch": 91, "training_loss": 0.6950444674491882, "training_acc": 53.0, "val_loss": 0.6996892404556274, "val_acc": 52.0}
{"epoch": 92, "training_loss": 0.6899959492683411, "training_acc": 53.0, "val_loss": 0.6851709294319153, "val_acc": 56.0}
{"epoch": 93, "training_loss": 0.6949249887466431, "training_acc": 48.0, "val_loss": 0.6931689906120301, "val_acc": 48.0}
{"epoch": 94, "training_loss": 0.6902743053436279, "training_acc": 52.0, "val_loss": 0.695345995426178, "val_acc": 52.0}
{"epoch": 95, "training_loss": 0.6813500618934631, "training_acc": 53.0, "val_loss": 0.6852728223800659, "val_acc": 56.0}
{"epoch": 96, "training_loss": 0.685583963394165, "training_acc": 56.0, "val_loss": 0.6881034445762634, "val_acc": 52.0}
{"epoch": 97, "training_loss": 0.7008121967315674, "training_acc": 45.0, "val_loss": 0.6907400155067444, "val_acc": 48.0}
{"epoch": 98, "training_loss": 0.6826054191589356, "training_acc": 56.0, "val_loss": 0.6877696466445923, "val_acc": 52.0}
{"epoch": 99, "training_loss": 0.6843239378929138, "training_acc": 53.0, "val_loss": 0.686052827835083, "val_acc": 52.0}
