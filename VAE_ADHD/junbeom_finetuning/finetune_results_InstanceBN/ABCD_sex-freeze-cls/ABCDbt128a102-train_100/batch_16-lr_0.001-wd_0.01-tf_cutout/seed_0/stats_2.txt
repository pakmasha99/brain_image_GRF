"main_modify.py --pretrained_path /scratch/connectome/dyhan316/VAE_ADHD/barlowtwins/pretrain_results/ABCDbt128a102.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option BT_org --learning_rate 1e-3 --batch_size 16 --weight_decay 1e-2 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 0.7138803005218506, "training_acc": 45.0, "val_loss": 0.6973335719108582, "val_acc": 52.0}
{"epoch": 1, "training_loss": 0.693628282546997, "training_acc": 51.0, "val_loss": 0.6941113686561584, "val_acc": 48.0}
{"epoch": 2, "training_loss": 0.7053015661239624, "training_acc": 47.0, "val_loss": 0.6928836774826049, "val_acc": 52.0}
{"epoch": 3, "training_loss": 0.6907112193107605, "training_acc": 53.0, "val_loss": 0.7147538995742798, "val_acc": 52.0}
{"epoch": 4, "training_loss": 0.713461766242981, "training_acc": 53.0, "val_loss": 0.6994262385368347, "val_acc": 52.0}
{"epoch": 5, "training_loss": 0.6966370582580567, "training_acc": 48.0, "val_loss": 0.6972233891487122, "val_acc": 48.0}
{"epoch": 6, "training_loss": 0.695827088356018, "training_acc": 50.0, "val_loss": 0.6933240222930909, "val_acc": 52.0}
{"epoch": 7, "training_loss": 0.6922869563102723, "training_acc": 53.0, "val_loss": 0.6986383056640625, "val_acc": 52.0}
{"epoch": 8, "training_loss": 0.7140100717544555, "training_acc": 53.0, "val_loss": 0.7036658453941346, "val_acc": 52.0}
{"epoch": 9, "training_loss": 0.6969432282447815, "training_acc": 53.0, "val_loss": 0.6932527470588684, "val_acc": 52.0}
{"epoch": 10, "training_loss": 0.6934406447410584, "training_acc": 55.0, "val_loss": 0.6951254892349243, "val_acc": 48.0}
{"epoch": 11, "training_loss": 0.703795599937439, "training_acc": 50.0, "val_loss": 0.6974132513999939, "val_acc": 52.0}
{"epoch": 12, "training_loss": 0.6877733469009399, "training_acc": 53.0, "val_loss": 0.6967603302001953, "val_acc": 48.0}
{"epoch": 13, "training_loss": 0.7100040149688721, "training_acc": 47.0, "val_loss": 0.7080149340629578, "val_acc": 48.0}
{"epoch": 14, "training_loss": 0.7065465235710144, "training_acc": 43.0, "val_loss": 0.7012426853179932, "val_acc": 52.0}
{"epoch": 15, "training_loss": 0.7173990345001221, "training_acc": 53.0, "val_loss": 0.6973792767524719, "val_acc": 52.0}
{"epoch": 16, "training_loss": 0.6910632562637329, "training_acc": 53.0, "val_loss": 0.6927529239654541, "val_acc": 52.0}
{"epoch": 17, "training_loss": 0.6912046146392822, "training_acc": 53.0, "val_loss": 0.6928019070625305, "val_acc": 52.0}
{"epoch": 18, "training_loss": 0.6931070184707642, "training_acc": 49.0, "val_loss": 0.6939873504638672, "val_acc": 56.0}
{"epoch": 19, "training_loss": 0.708996229171753, "training_acc": 49.0, "val_loss": 0.6960656809806823, "val_acc": 52.0}
{"epoch": 20, "training_loss": 0.6951084589958191, "training_acc": 53.0, "val_loss": 0.6930658674240112, "val_acc": 52.0}
{"epoch": 21, "training_loss": 0.6978808450698852, "training_acc": 45.0, "val_loss": 0.6940976452827453, "val_acc": 48.0}
{"epoch": 22, "training_loss": 0.7056576633453369, "training_acc": 57.0, "val_loss": 0.7172083997726441, "val_acc": 52.0}
{"epoch": 23, "training_loss": 0.6957036828994752, "training_acc": 54.0, "val_loss": 0.6971884393692016, "val_acc": 48.0}
{"epoch": 24, "training_loss": 0.7104456996917725, "training_acc": 47.0, "val_loss": 0.7024860048294067, "val_acc": 48.0}
{"epoch": 25, "training_loss": 0.7015810203552246, "training_acc": 50.0, "val_loss": 0.7074711680412292, "val_acc": 52.0}
{"epoch": 26, "training_loss": 0.700020387172699, "training_acc": 53.0, "val_loss": 0.69642982006073, "val_acc": 52.0}
{"epoch": 27, "training_loss": 0.6786756229400634, "training_acc": 63.0, "val_loss": 0.7130401659011841, "val_acc": 48.0}
{"epoch": 28, "training_loss": 0.7101133990287781, "training_acc": 47.0, "val_loss": 0.6938826131820679, "val_acc": 48.0}
{"epoch": 29, "training_loss": 0.6863901329040527, "training_acc": 54.0, "val_loss": 0.7003744554519653, "val_acc": 52.0}
{"epoch": 30, "training_loss": 0.713729739189148, "training_acc": 53.0, "val_loss": 0.7165558958053588, "val_acc": 52.0}
{"epoch": 31, "training_loss": 0.6973089861869812, "training_acc": 56.0, "val_loss": 0.6978495383262634, "val_acc": 48.0}
{"epoch": 32, "training_loss": 0.693541259765625, "training_acc": 47.0, "val_loss": 0.6946428346633912, "val_acc": 44.0}
{"epoch": 33, "training_loss": 0.687004771232605, "training_acc": 57.0, "val_loss": 0.69516685962677, "val_acc": 52.0}
{"epoch": 34, "training_loss": 0.6881966996192932, "training_acc": 53.0, "val_loss": 0.6941853022575378, "val_acc": 52.0}
{"epoch": 35, "training_loss": 0.6879545259475708, "training_acc": 53.0, "val_loss": 0.6945361065864563, "val_acc": 52.0}
