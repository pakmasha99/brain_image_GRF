"main_modify.py --pretrained_path /scratch/connectome/dyhan316/VAE_ADHD/barlowtwins/pretrain_results/ABCDbt128a102.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option BT_org --learning_rate 1e-3 --batch_size 16 --weight_decay 1e-2 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 0.7108823013305664, "training_acc": 52.0, "val_loss": 0.6936032819747925, "val_acc": 52.0}
{"epoch": 1, "training_loss": 0.6937445974349976, "training_acc": 53.0, "val_loss": 0.6963857197761536, "val_acc": 52.0}
{"epoch": 2, "training_loss": 0.6967783784866333, "training_acc": 47.0, "val_loss": 0.6990078067779542, "val_acc": 48.0}
{"epoch": 3, "training_loss": 0.704105544090271, "training_acc": 47.0, "val_loss": 0.6986250805854798, "val_acc": 48.0}
{"epoch": 4, "training_loss": 0.6962263679504395, "training_acc": 46.0, "val_loss": 0.6973428821563721, "val_acc": 52.0}
{"epoch": 5, "training_loss": 0.6948117399215699, "training_acc": 53.0, "val_loss": 0.6929496002197265, "val_acc": 52.0}
{"epoch": 6, "training_loss": 0.6907557868957519, "training_acc": 54.0, "val_loss": 0.694386100769043, "val_acc": 48.0}
{"epoch": 7, "training_loss": 0.7076120352745057, "training_acc": 47.0, "val_loss": 0.6929930996894836, "val_acc": 52.0}
{"epoch": 8, "training_loss": 0.6895242023468018, "training_acc": 53.0, "val_loss": 0.7145099568367005, "val_acc": 52.0}
{"epoch": 9, "training_loss": 0.7075450420379639, "training_acc": 53.0, "val_loss": 0.6967155957221984, "val_acc": 52.0}
{"epoch": 10, "training_loss": 0.6973916697502136, "training_acc": 55.0, "val_loss": 0.6927612733840942, "val_acc": 52.0}
{"epoch": 11, "training_loss": 0.6918967151641846, "training_acc": 57.0, "val_loss": 0.6935256695747376, "val_acc": 52.0}
{"epoch": 12, "training_loss": 0.6910342764854431, "training_acc": 53.0, "val_loss": 0.6933168077468872, "val_acc": 52.0}
{"epoch": 13, "training_loss": 0.7030542802810669, "training_acc": 43.0, "val_loss": 0.69416184425354, "val_acc": 48.0}
{"epoch": 14, "training_loss": 0.692249174118042, "training_acc": 49.0, "val_loss": 0.6949525380134582, "val_acc": 52.0}
{"epoch": 15, "training_loss": 0.6892751979827881, "training_acc": 53.0, "val_loss": 0.693161084651947, "val_acc": 52.0}
{"epoch": 16, "training_loss": 0.6949511599540711, "training_acc": 51.0, "val_loss": 0.6922828650474548, "val_acc": 52.0}
{"epoch": 17, "training_loss": 0.6883541297912598, "training_acc": 53.0, "val_loss": 0.7011862587928772, "val_acc": 52.0}
{"epoch": 18, "training_loss": 0.6931091547012329, "training_acc": 53.0, "val_loss": 0.6921915602684021, "val_acc": 52.0}
{"epoch": 19, "training_loss": 0.6908004093170166, "training_acc": 52.0, "val_loss": 0.6932125520706177, "val_acc": 44.0}
{"epoch": 20, "training_loss": 0.6930591750144959, "training_acc": 57.0, "val_loss": 0.6928731155395508, "val_acc": 52.0}
{"epoch": 21, "training_loss": 0.6898828411102295, "training_acc": 53.0, "val_loss": 0.6923969507217407, "val_acc": 52.0}
{"epoch": 22, "training_loss": 0.6906738424301148, "training_acc": 55.0, "val_loss": 0.692114109992981, "val_acc": 52.0}
{"epoch": 23, "training_loss": 0.6924218487739563, "training_acc": 53.0, "val_loss": 0.6943044972419739, "val_acc": 52.0}
{"epoch": 24, "training_loss": 0.6892121028900147, "training_acc": 57.0, "val_loss": 0.69384681224823, "val_acc": 48.0}
{"epoch": 25, "training_loss": 0.6909964990615844, "training_acc": 50.0, "val_loss": 0.6925618481636048, "val_acc": 52.0}
{"epoch": 26, "training_loss": 0.6913554096221923, "training_acc": 53.0, "val_loss": 0.6962045073509217, "val_acc": 52.0}
{"epoch": 27, "training_loss": 0.6901251316070557, "training_acc": 53.0, "val_loss": 0.6925228953361511, "val_acc": 52.0}
{"epoch": 28, "training_loss": 0.689467306137085, "training_acc": 53.0, "val_loss": 0.6933724975585938, "val_acc": 52.0}
{"epoch": 29, "training_loss": 0.6948377966880799, "training_acc": 53.0, "val_loss": 0.6929550838470458, "val_acc": 52.0}
{"epoch": 30, "training_loss": 0.6932987308502198, "training_acc": 50.0, "val_loss": 0.6927671527862549, "val_acc": 56.0}
{"epoch": 31, "training_loss": 0.6948454880714416, "training_acc": 47.0, "val_loss": 0.6920127582550049, "val_acc": 52.0}
{"epoch": 32, "training_loss": 0.6946113181114196, "training_acc": 49.0, "val_loss": 0.6921000838279724, "val_acc": 52.0}
{"epoch": 33, "training_loss": 0.6952303504943848, "training_acc": 53.0, "val_loss": 0.7061602115631104, "val_acc": 52.0}
{"epoch": 34, "training_loss": 0.7033603525161743, "training_acc": 49.0, "val_loss": 0.6925114512443542, "val_acc": 52.0}
{"epoch": 35, "training_loss": 0.697374758720398, "training_acc": 57.0, "val_loss": 0.7075386929512024, "val_acc": 52.0}
{"epoch": 36, "training_loss": 0.6815416216850281, "training_acc": 54.0, "val_loss": 0.6955533647537231, "val_acc": 48.0}
{"epoch": 37, "training_loss": 0.6957203149795532, "training_acc": 47.0, "val_loss": 0.6968962240219116, "val_acc": 48.0}
{"epoch": 38, "training_loss": 0.6950507640838623, "training_acc": 49.0, "val_loss": 0.6923106050491333, "val_acc": 52.0}
{"epoch": 39, "training_loss": 0.6858768796920777, "training_acc": 53.0, "val_loss": 0.6957140302658081, "val_acc": 52.0}
{"epoch": 40, "training_loss": 0.6897971701622009, "training_acc": 53.0, "val_loss": 0.6926435971260071, "val_acc": 52.0}
{"epoch": 41, "training_loss": 0.6885775685310364, "training_acc": 60.0, "val_loss": 0.6921814846992492, "val_acc": 52.0}
{"epoch": 42, "training_loss": 0.6937320160865784, "training_acc": 58.0, "val_loss": 0.69986323595047, "val_acc": 52.0}
{"epoch": 43, "training_loss": 0.6907773852348328, "training_acc": 53.0, "val_loss": 0.6919161224365235, "val_acc": 52.0}
{"epoch": 44, "training_loss": 0.6860742735862732, "training_acc": 53.0, "val_loss": 0.6925228619575501, "val_acc": 52.0}
{"epoch": 45, "training_loss": 0.6907195806503296, "training_acc": 56.0, "val_loss": 0.6916373133659363, "val_acc": 52.0}
{"epoch": 46, "training_loss": 0.6946390390396118, "training_acc": 53.0, "val_loss": 0.6964836597442627, "val_acc": 52.0}
{"epoch": 47, "training_loss": 0.6934151911735534, "training_acc": 53.0, "val_loss": 0.6916175603866577, "val_acc": 52.0}
{"epoch": 48, "training_loss": 0.6880632162094116, "training_acc": 53.0, "val_loss": 0.6931299543380738, "val_acc": 48.0}
{"epoch": 49, "training_loss": 0.6930915069580078, "training_acc": 51.0, "val_loss": 0.6927977800369263, "val_acc": 52.0}
{"epoch": 50, "training_loss": 0.6873157787322998, "training_acc": 53.0, "val_loss": 0.6914961171150208, "val_acc": 52.0}
{"epoch": 51, "training_loss": 0.6919646549224854, "training_acc": 48.0, "val_loss": 0.692196671962738, "val_acc": 60.0}
{"epoch": 52, "training_loss": 0.6881239938735962, "training_acc": 57.0, "val_loss": 0.6954815244674682, "val_acc": 52.0}
{"epoch": 53, "training_loss": 0.6876247835159301, "training_acc": 54.0, "val_loss": 0.6919312238693237, "val_acc": 48.0}
{"epoch": 54, "training_loss": 0.6892106246948242, "training_acc": 56.0, "val_loss": 0.6914108943939209, "val_acc": 52.0}
{"epoch": 55, "training_loss": 0.6928562927246094, "training_acc": 53.0, "val_loss": 0.7060498547554016, "val_acc": 52.0}
{"epoch": 56, "training_loss": 0.6918776035308838, "training_acc": 50.0, "val_loss": 0.6925323176383972, "val_acc": 60.0}
{"epoch": 57, "training_loss": 0.6868878078460693, "training_acc": 53.0, "val_loss": 0.6926490807533264, "val_acc": 52.0}
{"epoch": 58, "training_loss": 0.6885263252258301, "training_acc": 53.0, "val_loss": 0.6934953379631043, "val_acc": 52.0}
{"epoch": 59, "training_loss": 0.6822698783874511, "training_acc": 55.0, "val_loss": 0.6943395709991456, "val_acc": 48.0}
{"epoch": 60, "training_loss": 0.690622181892395, "training_acc": 53.0, "val_loss": 0.6918159198760986, "val_acc": 60.0}
{"epoch": 61, "training_loss": 0.6888931703567505, "training_acc": 50.0, "val_loss": 0.6917983317375183, "val_acc": 60.0}
{"epoch": 62, "training_loss": 0.6844782423973084, "training_acc": 58.0, "val_loss": 0.6929067730903625, "val_acc": 52.0}
{"epoch": 63, "training_loss": 0.6884144449234009, "training_acc": 53.0, "val_loss": 0.6938919925689697, "val_acc": 52.0}
{"epoch": 64, "training_loss": 0.708968391418457, "training_acc": 53.0, "val_loss": 0.7115502095222473, "val_acc": 52.0}
{"epoch": 65, "training_loss": 0.6906999039649964, "training_acc": 53.0, "val_loss": 0.6919923520088196, "val_acc": 52.0}
{"epoch": 66, "training_loss": 0.6880901956558227, "training_acc": 55.0, "val_loss": 0.6915832161903381, "val_acc": 52.0}
{"epoch": 67, "training_loss": 0.6838988614082336, "training_acc": 53.0, "val_loss": 0.6933410596847535, "val_acc": 52.0}
{"epoch": 68, "training_loss": 0.6968561267852783, "training_acc": 48.0, "val_loss": 0.6916571497917176, "val_acc": 56.0}
{"epoch": 69, "training_loss": 0.6776192283630371, "training_acc": 56.0, "val_loss": 0.7071224641799927, "val_acc": 52.0}
{"epoch": 70, "training_loss": 0.6995056390762329, "training_acc": 53.0, "val_loss": 0.6922151970863343, "val_acc": 52.0}
{"epoch": 71, "training_loss": 0.6834618592262268, "training_acc": 60.0, "val_loss": 0.6991070199012757, "val_acc": 48.0}
{"epoch": 72, "training_loss": 0.6952987885475159, "training_acc": 49.0, "val_loss": 0.6952622556686401, "val_acc": 52.0}
{"epoch": 73, "training_loss": 0.7074431276321411, "training_acc": 53.0, "val_loss": 0.7011805510520935, "val_acc": 52.0}
