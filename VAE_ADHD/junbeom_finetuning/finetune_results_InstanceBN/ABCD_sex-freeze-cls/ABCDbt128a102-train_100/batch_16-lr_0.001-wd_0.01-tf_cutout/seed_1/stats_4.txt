"main_modify.py --pretrained_path /scratch/connectome/dyhan316/VAE_ADHD/barlowtwins/pretrain_results/ABCDbt128a102.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 1 --task ABCD_sex --input_option BT_org --learning_rate 1e-3 --batch_size 16 --weight_decay 1e-2 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 0.7170088958740234, "training_acc": 44.0, "val_loss": 0.6864663529396057, "val_acc": 56.0}
{"epoch": 1, "training_loss": 0.7151070165634156, "training_acc": 52.0, "val_loss": 0.6870158100128174, "val_acc": 56.0}
{"epoch": 2, "training_loss": 0.6957903385162354, "training_acc": 52.0, "val_loss": 0.6974109292030335, "val_acc": 44.0}
{"epoch": 3, "training_loss": 0.7017805695533752, "training_acc": 42.0, "val_loss": 0.69380366563797, "val_acc": 52.0}
{"epoch": 4, "training_loss": 0.7019256687164307, "training_acc": 48.0, "val_loss": 0.7031031513214111, "val_acc": 44.0}
{"epoch": 5, "training_loss": 0.6979047727584838, "training_acc": 50.0, "val_loss": 0.6853245115280151, "val_acc": 56.0}
{"epoch": 6, "training_loss": 0.7476337885856629, "training_acc": 30.0, "val_loss": 0.7098380374908447, "val_acc": 44.0}
{"epoch": 7, "training_loss": 0.6900847625732421, "training_acc": 54.0, "val_loss": 0.6852079486846924, "val_acc": 56.0}
{"epoch": 8, "training_loss": 0.6957379269599915, "training_acc": 52.0, "val_loss": 0.6854620361328125, "val_acc": 56.0}
{"epoch": 9, "training_loss": 0.6978998804092407, "training_acc": 46.0, "val_loss": 0.6956143951416016, "val_acc": 44.0}
{"epoch": 10, "training_loss": 0.6976564860343933, "training_acc": 48.0, "val_loss": 0.6933847713470459, "val_acc": 56.0}
{"epoch": 11, "training_loss": 0.6942309236526489, "training_acc": 49.0, "val_loss": 0.685093548297882, "val_acc": 56.0}
{"epoch": 12, "training_loss": 0.6935675048828125, "training_acc": 52.0, "val_loss": 0.694441921710968, "val_acc": 44.0}
{"epoch": 13, "training_loss": 0.6942156171798706, "training_acc": 50.0, "val_loss": 0.6913533639907837, "val_acc": 48.0}
{"epoch": 14, "training_loss": 0.6982779932022095, "training_acc": 37.0, "val_loss": 0.6863854002952575, "val_acc": 56.0}
{"epoch": 15, "training_loss": 0.7011255264282227, "training_acc": 52.0, "val_loss": 0.6848712968826294, "val_acc": 56.0}
{"epoch": 16, "training_loss": 0.6948450565338135, "training_acc": 52.0, "val_loss": 0.6847121357917786, "val_acc": 56.0}
{"epoch": 17, "training_loss": 0.6976261425018311, "training_acc": 52.0, "val_loss": 0.6845657229423523, "val_acc": 56.0}
{"epoch": 18, "training_loss": 0.6930173969268799, "training_acc": 53.0, "val_loss": 0.6951404690742493, "val_acc": 44.0}
{"epoch": 19, "training_loss": 0.698384747505188, "training_acc": 48.0, "val_loss": 0.69904066324234, "val_acc": 44.0}
{"epoch": 20, "training_loss": 0.6947957420349121, "training_acc": 50.0, "val_loss": 0.6845072531700134, "val_acc": 56.0}
{"epoch": 21, "training_loss": 0.7004235649108886, "training_acc": 52.0, "val_loss": 0.687417495250702, "val_acc": 56.0}
{"epoch": 22, "training_loss": 0.6978136229515076, "training_acc": 40.0, "val_loss": 0.6861860728263856, "val_acc": 56.0}
{"epoch": 23, "training_loss": 0.6928504395484925, "training_acc": 52.0, "val_loss": 0.6850180315971375, "val_acc": 56.0}
{"epoch": 24, "training_loss": 0.7011666774749756, "training_acc": 52.0, "val_loss": 0.684399311542511, "val_acc": 56.0}
{"epoch": 25, "training_loss": 0.6908882474899292, "training_acc": 52.0, "val_loss": 0.6937934088706971, "val_acc": 44.0}
{"epoch": 26, "training_loss": 0.7007532644271851, "training_acc": 48.0, "val_loss": 0.7019705271720886, "val_acc": 44.0}
{"epoch": 27, "training_loss": 0.6866350078582764, "training_acc": 55.0, "val_loss": 0.686941864490509, "val_acc": 56.0}
{"epoch": 28, "training_loss": 0.7008492612838745, "training_acc": 52.0, "val_loss": 0.6840751385688781, "val_acc": 56.0}
{"epoch": 29, "training_loss": 0.6926459550857544, "training_acc": 52.0, "val_loss": 0.6855624842643738, "val_acc": 56.0}
{"epoch": 30, "training_loss": 0.6931533145904542, "training_acc": 52.0, "val_loss": 0.6860553455352784, "val_acc": 56.0}
{"epoch": 31, "training_loss": 0.6923077964782715, "training_acc": 50.0, "val_loss": 0.685877640247345, "val_acc": 56.0}
{"epoch": 32, "training_loss": 0.6948049545288086, "training_acc": 52.0, "val_loss": 0.6849238657951355, "val_acc": 56.0}
{"epoch": 33, "training_loss": 0.7112541961669921, "training_acc": 43.0, "val_loss": 0.6910871863365173, "val_acc": 52.0}
{"epoch": 34, "training_loss": 0.6986546325683594, "training_acc": 52.0, "val_loss": 0.6869105243682861, "val_acc": 56.0}
{"epoch": 35, "training_loss": 0.7019785952568054, "training_acc": 52.0, "val_loss": 0.683595016002655, "val_acc": 56.0}
{"epoch": 36, "training_loss": 0.7241285920143128, "training_acc": 42.0, "val_loss": 0.7104952359199523, "val_acc": 44.0}
{"epoch": 37, "training_loss": 0.6877838802337647, "training_acc": 61.0, "val_loss": 0.6850341105461121, "val_acc": 56.0}
{"epoch": 38, "training_loss": 0.7287932777404785, "training_acc": 52.0, "val_loss": 0.690656554698944, "val_acc": 56.0}
{"epoch": 39, "training_loss": 0.699898693561554, "training_acc": 48.0, "val_loss": 0.7041898083686828, "val_acc": 44.0}
{"epoch": 40, "training_loss": 0.6973564457893372, "training_acc": 48.0, "val_loss": 0.6911051487922668, "val_acc": 60.0}
{"epoch": 41, "training_loss": 0.7027764415740967, "training_acc": 52.0, "val_loss": 0.683219826221466, "val_acc": 56.0}
{"epoch": 42, "training_loss": 0.6968628072738647, "training_acc": 45.0, "val_loss": 0.6903408527374267, "val_acc": 52.0}
{"epoch": 43, "training_loss": 0.6896907806396484, "training_acc": 54.0, "val_loss": 0.6833005094528198, "val_acc": 56.0}
{"epoch": 44, "training_loss": 0.7012231540679932, "training_acc": 52.0, "val_loss": 0.6846972894668579, "val_acc": 56.0}
{"epoch": 45, "training_loss": 0.7054742383956909, "training_acc": 48.0, "val_loss": 0.7312017035484314, "val_acc": 44.0}
{"epoch": 46, "training_loss": 0.6931554174423218, "training_acc": 50.0, "val_loss": 0.6830546450614929, "val_acc": 56.0}
{"epoch": 47, "training_loss": 0.705014419555664, "training_acc": 52.0, "val_loss": 0.6888101315498352, "val_acc": 56.0}
{"epoch": 48, "training_loss": 0.6947105264663697, "training_acc": 60.0, "val_loss": 0.7012314319610595, "val_acc": 44.0}
{"epoch": 49, "training_loss": 0.6947490191459655, "training_acc": 48.0, "val_loss": 0.6959796738624573, "val_acc": 44.0}
{"epoch": 50, "training_loss": 0.6920952010154724, "training_acc": 51.0, "val_loss": 0.6838663864135742, "val_acc": 56.0}
{"epoch": 51, "training_loss": 0.691361346244812, "training_acc": 52.0, "val_loss": 0.682736394405365, "val_acc": 56.0}
{"epoch": 52, "training_loss": 0.6897257137298584, "training_acc": 52.0, "val_loss": 0.6868197751045227, "val_acc": 56.0}
{"epoch": 53, "training_loss": 0.6887195777893066, "training_acc": 58.0, "val_loss": 0.6855943775177002, "val_acc": 56.0}
{"epoch": 54, "training_loss": 0.6894149565696717, "training_acc": 52.0, "val_loss": 0.6834023594856262, "val_acc": 56.0}
{"epoch": 55, "training_loss": 0.7012137460708618, "training_acc": 52.0, "val_loss": 0.6849045205116272, "val_acc": 56.0}
{"epoch": 56, "training_loss": 0.690351107120514, "training_acc": 54.0, "val_loss": 0.6920920753479004, "val_acc": 52.0}
{"epoch": 57, "training_loss": 0.706594865322113, "training_acc": 47.0, "val_loss": 0.6952026009559631, "val_acc": 44.0}
{"epoch": 58, "training_loss": 0.6990666580200195, "training_acc": 54.0, "val_loss": 0.6889762163162232, "val_acc": 56.0}
{"epoch": 59, "training_loss": 0.6971616435050965, "training_acc": 52.0, "val_loss": 0.6881002879142761, "val_acc": 60.0}
{"epoch": 60, "training_loss": 0.6872155141830444, "training_acc": 62.0, "val_loss": 0.6959717488288879, "val_acc": 44.0}
{"epoch": 61, "training_loss": 0.6883646082878113, "training_acc": 60.0, "val_loss": 0.6840335822105408, "val_acc": 56.0}
{"epoch": 62, "training_loss": 0.6956737327575684, "training_acc": 52.0, "val_loss": 0.6822222685813903, "val_acc": 56.0}
{"epoch": 63, "training_loss": 0.6866157412528991, "training_acc": 53.0, "val_loss": 0.7019143986701966, "val_acc": 44.0}
{"epoch": 64, "training_loss": 0.6989890718460083, "training_acc": 48.0, "val_loss": 0.6891672015190125, "val_acc": 60.0}
{"epoch": 65, "training_loss": 0.6910944962501526, "training_acc": 55.0, "val_loss": 0.6968918633460999, "val_acc": 44.0}
{"epoch": 66, "training_loss": 0.6909976887702942, "training_acc": 45.0, "val_loss": 0.6817776846885681, "val_acc": 56.0}
{"epoch": 67, "training_loss": 0.6922791147232056, "training_acc": 52.0, "val_loss": 0.6824121904373169, "val_acc": 56.0}
{"epoch": 68, "training_loss": 0.6890654230117798, "training_acc": 52.0, "val_loss": 0.6838114857673645, "val_acc": 56.0}
{"epoch": 69, "training_loss": 0.6899093294143677, "training_acc": 52.0, "val_loss": 0.6825218915939331, "val_acc": 56.0}
{"epoch": 70, "training_loss": 0.6866934490203858, "training_acc": 52.0, "val_loss": 0.6847722744941711, "val_acc": 56.0}
{"epoch": 71, "training_loss": 0.6934131336212158, "training_acc": 52.0, "val_loss": 0.684078414440155, "val_acc": 56.0}
{"epoch": 72, "training_loss": 0.6860635828971863, "training_acc": 54.0, "val_loss": 0.6950352954864502, "val_acc": 44.0}
{"epoch": 73, "training_loss": 0.690322949886322, "training_acc": 49.0, "val_loss": 0.6847624373435974, "val_acc": 56.0}
{"epoch": 74, "training_loss": 0.6904025101661682, "training_acc": 52.0, "val_loss": 0.6826711034774781, "val_acc": 56.0}
{"epoch": 75, "training_loss": 0.6871712517738342, "training_acc": 52.0, "val_loss": 0.6894157814979553, "val_acc": 60.0}
{"epoch": 76, "training_loss": 0.691374683380127, "training_acc": 49.0, "val_loss": 0.6971521306037903, "val_acc": 44.0}
{"epoch": 77, "training_loss": 0.6932398176193237, "training_acc": 53.0, "val_loss": 0.6814990639686584, "val_acc": 56.0}
{"epoch": 78, "training_loss": 0.6894167900085449, "training_acc": 53.0, "val_loss": 0.6874501848220825, "val_acc": 60.0}
{"epoch": 79, "training_loss": 0.6903521776199341, "training_acc": 49.0, "val_loss": 0.6906243968009949, "val_acc": 60.0}
{"epoch": 80, "training_loss": 0.6889996361732483, "training_acc": 53.0, "val_loss": 0.6827259564399719, "val_acc": 56.0}
{"epoch": 81, "training_loss": 0.6942081475257873, "training_acc": 52.0, "val_loss": 0.6838607788085938, "val_acc": 56.0}
{"epoch": 82, "training_loss": 0.68763742685318, "training_acc": 49.0, "val_loss": 0.6977344226837158, "val_acc": 44.0}
{"epoch": 83, "training_loss": 0.6959730172157288, "training_acc": 48.0, "val_loss": 0.6877062201499939, "val_acc": 52.0}
{"epoch": 84, "training_loss": 0.6887660837173462, "training_acc": 51.0, "val_loss": 0.6878294086456299, "val_acc": 56.0}
{"epoch": 85, "training_loss": 0.6921003603935242, "training_acc": 50.0, "val_loss": 0.6807015585899353, "val_acc": 56.0}
{"epoch": 86, "training_loss": 0.6886606860160828, "training_acc": 52.0, "val_loss": 0.6813120007514953, "val_acc": 56.0}
{"epoch": 87, "training_loss": 0.6849713802337647, "training_acc": 52.0, "val_loss": 0.6863459062576294, "val_acc": 60.0}
{"epoch": 88, "training_loss": 0.70713623046875, "training_acc": 55.0, "val_loss": 0.7187615966796875, "val_acc": 44.0}
{"epoch": 89, "training_loss": 0.6954705739021301, "training_acc": 51.0, "val_loss": 0.6831301999092102, "val_acc": 56.0}
{"epoch": 90, "training_loss": 0.6909554743766785, "training_acc": 52.0, "val_loss": 0.6829796934127808, "val_acc": 56.0}
{"epoch": 91, "training_loss": 0.6951203227043152, "training_acc": 55.0, "val_loss": 0.7324278450012207, "val_acc": 44.0}
{"epoch": 92, "training_loss": 0.7008073091506958, "training_acc": 46.0, "val_loss": 0.6804654002189636, "val_acc": 56.0}
{"epoch": 93, "training_loss": 0.6906561851501465, "training_acc": 52.0, "val_loss": 0.6810852432250977, "val_acc": 56.0}
{"epoch": 94, "training_loss": 0.6899468803405762, "training_acc": 52.0, "val_loss": 0.681639506816864, "val_acc": 56.0}
{"epoch": 95, "training_loss": 0.6816807270050049, "training_acc": 62.0, "val_loss": 0.6901224541664124, "val_acc": 56.0}
{"epoch": 96, "training_loss": 0.6849323320388794, "training_acc": 57.0, "val_loss": 0.6803961205482483, "val_acc": 56.0}
{"epoch": 97, "training_loss": 0.6912835288047791, "training_acc": 52.0, "val_loss": 0.6801696491241455, "val_acc": 56.0}
{"epoch": 98, "training_loss": 0.6848130702972413, "training_acc": 53.0, "val_loss": 0.6840784502029419, "val_acc": 56.0}
{"epoch": 99, "training_loss": 0.6923445463180542, "training_acc": 47.0, "val_loss": 0.6852203822135925, "val_acc": 60.0}
