"main_modify.py --pretrained_path /scratch/connectome/dyhan316/VAE_ADHD/barlowtwins/pretrain_results/ABCDbt128a102.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 1 --task ABCD_sex --input_option BT_org --learning_rate 1e-3 --batch_size 16 --weight_decay 1e-2 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 0.7076511716842652, "training_acc": 47.0, "val_loss": 0.7106396532058716, "val_acc": 52.0}
{"epoch": 1, "training_loss": 0.7310114669799804, "training_acc": 53.0, "val_loss": 0.7053123450279236, "val_acc": 52.0}
{"epoch": 2, "training_loss": 0.7009211683273315, "training_acc": 53.0, "val_loss": 0.6908847260475158, "val_acc": 52.0}
{"epoch": 3, "training_loss": 0.7033873081207276, "training_acc": 41.0, "val_loss": 0.691173210144043, "val_acc": 64.0}
{"epoch": 4, "training_loss": 0.6932706022262574, "training_acc": 48.0, "val_loss": 0.692198498249054, "val_acc": 52.0}
{"epoch": 5, "training_loss": 0.7098038339614868, "training_acc": 53.0, "val_loss": 0.7095965504646301, "val_acc": 52.0}
{"epoch": 6, "training_loss": 0.7034512424468994, "training_acc": 53.0, "val_loss": 0.6905144619941711, "val_acc": 52.0}
{"epoch": 7, "training_loss": 0.7056481313705444, "training_acc": 48.0, "val_loss": 0.6981586933135986, "val_acc": 48.0}
{"epoch": 8, "training_loss": 0.6941357445716858, "training_acc": 51.0, "val_loss": 0.6934586668014526, "val_acc": 52.0}
{"epoch": 9, "training_loss": 0.7044716739654541, "training_acc": 53.0, "val_loss": 0.6960616707801819, "val_acc": 52.0}
{"epoch": 10, "training_loss": 0.7032188749313355, "training_acc": 45.0, "val_loss": 0.694520308971405, "val_acc": 48.0}
{"epoch": 11, "training_loss": 0.6934062051773071, "training_acc": 52.0, "val_loss": 0.691672625541687, "val_acc": 52.0}
{"epoch": 12, "training_loss": 0.6977520394325256, "training_acc": 53.0, "val_loss": 0.7026051878929138, "val_acc": 52.0}
{"epoch": 13, "training_loss": 0.692054214477539, "training_acc": 53.0, "val_loss": 0.6910173106193542, "val_acc": 64.0}
{"epoch": 14, "training_loss": 0.7126147031784058, "training_acc": 48.0, "val_loss": 0.7030161643028259, "val_acc": 48.0}
{"epoch": 15, "training_loss": 0.7237939381599426, "training_acc": 39.0, "val_loss": 0.6982864594459534, "val_acc": 52.0}
{"epoch": 16, "training_loss": 0.6920347452163697, "training_acc": 53.0, "val_loss": 0.6905042314529419, "val_acc": 52.0}
{"epoch": 17, "training_loss": 0.6907348465919495, "training_acc": 53.0, "val_loss": 0.6905264043807984, "val_acc": 52.0}
{"epoch": 18, "training_loss": 0.6926876473426818, "training_acc": 47.0, "val_loss": 0.6913613939285278, "val_acc": 56.0}
{"epoch": 19, "training_loss": 0.6873398184776306, "training_acc": 56.0, "val_loss": 0.6956200575828553, "val_acc": 52.0}
{"epoch": 20, "training_loss": 0.7011090850830078, "training_acc": 53.0, "val_loss": 0.6925273871421814, "val_acc": 52.0}
{"epoch": 21, "training_loss": 0.6933551359176636, "training_acc": 53.0, "val_loss": 0.6920676493644714, "val_acc": 52.0}
{"epoch": 22, "training_loss": 0.6968843793869018, "training_acc": 53.0, "val_loss": 0.6956777739524841, "val_acc": 52.0}
{"epoch": 23, "training_loss": 0.690665111541748, "training_acc": 54.0, "val_loss": 0.698789987564087, "val_acc": 48.0}
{"epoch": 24, "training_loss": 0.706983003616333, "training_acc": 47.0, "val_loss": 0.6906635308265686, "val_acc": 52.0}
{"epoch": 25, "training_loss": 0.6889131689071655, "training_acc": 53.0, "val_loss": 0.722170524597168, "val_acc": 52.0}
{"epoch": 26, "training_loss": 0.7058680200576782, "training_acc": 53.0, "val_loss": 0.690891420841217, "val_acc": 52.0}
{"epoch": 27, "training_loss": 0.6944205403327942, "training_acc": 53.0, "val_loss": 0.6904977941513062, "val_acc": 52.0}
{"epoch": 28, "training_loss": 0.7144320154190064, "training_acc": 43.0, "val_loss": 0.7008092737197876, "val_acc": 48.0}
{"epoch": 29, "training_loss": 0.7116536855697632, "training_acc": 45.0, "val_loss": 0.7061266946792603, "val_acc": 52.0}
{"epoch": 30, "training_loss": 0.6939177513122559, "training_acc": 53.0, "val_loss": 0.6907293844223023, "val_acc": 52.0}
{"epoch": 31, "training_loss": 0.6881428265571594, "training_acc": 62.0, "val_loss": 0.6941922807693481, "val_acc": 48.0}
{"epoch": 32, "training_loss": 0.6942406415939331, "training_acc": 52.0, "val_loss": 0.6906645321846008, "val_acc": 52.0}
{"epoch": 33, "training_loss": 0.697335638999939, "training_acc": 53.0, "val_loss": 0.7021638321876525, "val_acc": 52.0}
{"epoch": 34, "training_loss": 0.7019911098480225, "training_acc": 53.0, "val_loss": 0.6974469804763794, "val_acc": 52.0}
{"epoch": 35, "training_loss": 0.694434506893158, "training_acc": 50.0, "val_loss": 0.6986131715774536, "val_acc": 48.0}
{"epoch": 36, "training_loss": 0.7017461371421814, "training_acc": 47.0, "val_loss": 0.6930083584785461, "val_acc": 48.0}
{"epoch": 37, "training_loss": 0.6917267608642578, "training_acc": 45.0, "val_loss": 0.6909580612182618, "val_acc": 56.0}
{"epoch": 38, "training_loss": 0.6882190942764282, "training_acc": 56.0, "val_loss": 0.6937973570823669, "val_acc": 52.0}
{"epoch": 39, "training_loss": 0.6879598641395569, "training_acc": 53.0, "val_loss": 0.6912122464179993, "val_acc": 52.0}
{"epoch": 40, "training_loss": 0.6879633092880248, "training_acc": 56.0, "val_loss": 0.691773750782013, "val_acc": 48.0}
{"epoch": 41, "training_loss": 0.6898272466659546, "training_acc": 53.0, "val_loss": 0.6908638858795166, "val_acc": 56.0}
{"epoch": 42, "training_loss": 0.6864672183990479, "training_acc": 54.0, "val_loss": 0.6937884449958801, "val_acc": 52.0}
{"epoch": 43, "training_loss": 0.692822449207306, "training_acc": 52.0, "val_loss": 0.6906659841537476, "val_acc": 52.0}
{"epoch": 44, "training_loss": 0.6852683353424073, "training_acc": 52.0, "val_loss": 0.6923360323905945, "val_acc": 52.0}
{"epoch": 45, "training_loss": 0.6906907153129578, "training_acc": 53.0, "val_loss": 0.6958068680763244, "val_acc": 52.0}
{"epoch": 46, "training_loss": 0.7006000471115112, "training_acc": 50.0, "val_loss": 0.7024045205116272, "val_acc": 48.0}
