"main_modify.py --pretrained_path /scratch/connectome/dyhan316/VAE_ADHD/barlowtwins/pretrain_results/ABCDbt128a102.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 1 --task ABCD_sex --input_option BT_org --learning_rate 1e-3 --batch_size 16 --weight_decay 1e-2 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 0.7222809076309205, "training_acc": 45.0, "val_loss": 0.6924191069602966, "val_acc": 52.0}
{"epoch": 1, "training_loss": 0.695080394744873, "training_acc": 52.0, "val_loss": 0.6970790982246399, "val_acc": 48.0}
{"epoch": 2, "training_loss": 0.6995682978630066, "training_acc": 47.0, "val_loss": 0.6978468227386475, "val_acc": 52.0}
{"epoch": 3, "training_loss": 0.6952063393592834, "training_acc": 53.0, "val_loss": 0.6930752635002136, "val_acc": 52.0}
{"epoch": 4, "training_loss": 0.6984773778915405, "training_acc": 47.0, "val_loss": 0.6972027564048767, "val_acc": 48.0}
{"epoch": 5, "training_loss": 0.6927372074127197, "training_acc": 51.0, "val_loss": 0.6945729637145996, "val_acc": 52.0}
{"epoch": 6, "training_loss": 0.7018681740760804, "training_acc": 53.0, "val_loss": 0.7102186584472656, "val_acc": 52.0}
{"epoch": 7, "training_loss": 0.7062517094612122, "training_acc": 47.0, "val_loss": 0.6960257291793823, "val_acc": 48.0}
{"epoch": 8, "training_loss": 0.6990859746932984, "training_acc": 45.0, "val_loss": 0.6918519139289856, "val_acc": 52.0}
{"epoch": 9, "training_loss": 0.6916834139823913, "training_acc": 53.0, "val_loss": 0.6918723273277283, "val_acc": 52.0}
{"epoch": 10, "training_loss": 0.6923694610595703, "training_acc": 53.0, "val_loss": 0.6917661452293395, "val_acc": 52.0}
{"epoch": 11, "training_loss": 0.6931889009475708, "training_acc": 53.0, "val_loss": 0.6924677014350891, "val_acc": 52.0}
{"epoch": 12, "training_loss": 0.6923139357566833, "training_acc": 53.0, "val_loss": 0.6945089602470398, "val_acc": 52.0}
{"epoch": 13, "training_loss": 0.7035302495956421, "training_acc": 53.0, "val_loss": 0.6942761397361755, "val_acc": 52.0}
{"epoch": 14, "training_loss": 0.7142099952697754, "training_acc": 43.0, "val_loss": 0.6960502934455871, "val_acc": 48.0}
{"epoch": 15, "training_loss": 0.6882850122451782, "training_acc": 52.0, "val_loss": 0.7083209586143494, "val_acc": 52.0}
{"epoch": 16, "training_loss": 0.7135471224784851, "training_acc": 53.0, "val_loss": 0.7055744194984436, "val_acc": 52.0}
{"epoch": 17, "training_loss": 0.6987716150283814, "training_acc": 53.0, "val_loss": 0.6928166341781616, "val_acc": 52.0}
{"epoch": 18, "training_loss": 0.6888513469696045, "training_acc": 51.0, "val_loss": 0.6976571369171143, "val_acc": 48.0}
{"epoch": 19, "training_loss": 0.7033664774894715, "training_acc": 47.0, "val_loss": 0.6930392217636109, "val_acc": 48.0}
{"epoch": 20, "training_loss": 0.7070085597038269, "training_acc": 49.0, "val_loss": 0.6957397246360779, "val_acc": 52.0}
{"epoch": 21, "training_loss": 0.6932601046562195, "training_acc": 53.0, "val_loss": 0.6917866134643554, "val_acc": 52.0}
{"epoch": 22, "training_loss": 0.6955032157897949, "training_acc": 53.0, "val_loss": 0.7006067395210266, "val_acc": 52.0}
{"epoch": 23, "training_loss": 0.6970745277404785, "training_acc": 53.0, "val_loss": 0.6907971596717835, "val_acc": 52.0}
{"epoch": 24, "training_loss": 0.6988982725143432, "training_acc": 47.0, "val_loss": 0.6993785715103149, "val_acc": 48.0}
{"epoch": 25, "training_loss": 0.6904833126068115, "training_acc": 49.0, "val_loss": 0.6986520004272461, "val_acc": 52.0}
{"epoch": 26, "training_loss": 0.7001562070846558, "training_acc": 53.0, "val_loss": 0.6921914482116699, "val_acc": 52.0}
{"epoch": 27, "training_loss": 0.7048625421524047, "training_acc": 41.0, "val_loss": 0.6933157682418823, "val_acc": 48.0}
{"epoch": 28, "training_loss": 0.6840898180007935, "training_acc": 60.0, "val_loss": 0.6954388236999511, "val_acc": 52.0}
{"epoch": 29, "training_loss": 0.7109895086288452, "training_acc": 53.0, "val_loss": 0.6960779237747192, "val_acc": 52.0}
{"epoch": 30, "training_loss": 0.7197722840309143, "training_acc": 43.0, "val_loss": 0.7110969471931458, "val_acc": 48.0}
{"epoch": 31, "training_loss": 0.7055206298828125, "training_acc": 47.0, "val_loss": 0.6952265763282776, "val_acc": 52.0}
{"epoch": 32, "training_loss": 0.6965177631378174, "training_acc": 53.0, "val_loss": 0.6979654693603515, "val_acc": 52.0}
{"epoch": 33, "training_loss": 0.6926322102546691, "training_acc": 53.0, "val_loss": 0.6909523916244507, "val_acc": 52.0}
{"epoch": 34, "training_loss": 0.6986770105361938, "training_acc": 44.0, "val_loss": 0.6939583539962768, "val_acc": 48.0}
{"epoch": 35, "training_loss": 0.6940429663658142, "training_acc": 48.0, "val_loss": 0.6949785566329956, "val_acc": 52.0}
{"epoch": 36, "training_loss": 0.7007046675682068, "training_acc": 46.0, "val_loss": 0.6922643232345581, "val_acc": 48.0}
{"epoch": 37, "training_loss": 0.6936527061462402, "training_acc": 53.0, "val_loss": 0.6918997550010682, "val_acc": 52.0}
{"epoch": 38, "training_loss": 0.6899934720993042, "training_acc": 53.0, "val_loss": 0.6910252332687378, "val_acc": 64.0}
{"epoch": 39, "training_loss": 0.6913576126098633, "training_acc": 52.0, "val_loss": 0.6985649490356445, "val_acc": 48.0}
{"epoch": 40, "training_loss": 0.6916365694999694, "training_acc": 54.0, "val_loss": 0.6901268863677978, "val_acc": 52.0}
{"epoch": 41, "training_loss": 0.6865188956260682, "training_acc": 53.0, "val_loss": 0.6937196850776672, "val_acc": 52.0}
{"epoch": 42, "training_loss": 0.7014000272750854, "training_acc": 53.0, "val_loss": 0.7002058935165405, "val_acc": 52.0}
{"epoch": 43, "training_loss": 0.6907815480232239, "training_acc": 58.0, "val_loss": 0.6936709427833557, "val_acc": 48.0}
{"epoch": 44, "training_loss": 0.6955341219902038, "training_acc": 50.0, "val_loss": 0.6936937141418457, "val_acc": 48.0}
{"epoch": 45, "training_loss": 0.7112542915344239, "training_acc": 47.0, "val_loss": 0.6948296284675598, "val_acc": 48.0}
{"epoch": 46, "training_loss": 0.6839988303184509, "training_acc": 58.0, "val_loss": 0.7020760273933411, "val_acc": 52.0}
{"epoch": 47, "training_loss": 0.6938766813278199, "training_acc": 53.0, "val_loss": 0.6893172478675842, "val_acc": 52.0}
{"epoch": 48, "training_loss": 0.6930155086517334, "training_acc": 54.0, "val_loss": 0.6997443509101867, "val_acc": 48.0}
{"epoch": 49, "training_loss": 0.6952923703193664, "training_acc": 48.0, "val_loss": 0.6891223025321961, "val_acc": 52.0}
{"epoch": 50, "training_loss": 0.7001227355003357, "training_acc": 53.0, "val_loss": 0.7040268111228943, "val_acc": 52.0}
{"epoch": 51, "training_loss": 0.6934488534927368, "training_acc": 53.0, "val_loss": 0.690463707447052, "val_acc": 52.0}
{"epoch": 52, "training_loss": 0.6874352359771728, "training_acc": 53.0, "val_loss": 0.6890283131599426, "val_acc": 56.0}
{"epoch": 53, "training_loss": 0.6857633900642395, "training_acc": 63.0, "val_loss": 0.6899502301216125, "val_acc": 64.0}
{"epoch": 54, "training_loss": 0.6878096294403077, "training_acc": 62.0, "val_loss": 0.6895097589492798, "val_acc": 52.0}
{"epoch": 55, "training_loss": 0.7026078510284424, "training_acc": 53.0, "val_loss": 0.7068891406059266, "val_acc": 52.0}
{"epoch": 56, "training_loss": 0.7117380452156067, "training_acc": 53.0, "val_loss": 0.6935462927818299, "val_acc": 52.0}
{"epoch": 57, "training_loss": 0.6771974182128906, "training_acc": 60.0, "val_loss": 0.6963294434547425, "val_acc": 48.0}
{"epoch": 58, "training_loss": 0.7103289270401001, "training_acc": 47.0, "val_loss": 0.6977390885353089, "val_acc": 48.0}
{"epoch": 59, "training_loss": 0.6858224487304687, "training_acc": 60.0, "val_loss": 0.6952933573722839, "val_acc": 52.0}
{"epoch": 60, "training_loss": 0.6902397418022156, "training_acc": 53.0, "val_loss": 0.689002718925476, "val_acc": 52.0}
{"epoch": 61, "training_loss": 0.6997882437705993, "training_acc": 43.0, "val_loss": 0.6928486013412476, "val_acc": 48.0}
{"epoch": 62, "training_loss": 0.6886926031112671, "training_acc": 55.0, "val_loss": 0.6886976766586304, "val_acc": 52.0}
{"epoch": 63, "training_loss": 0.6891344738006592, "training_acc": 59.0, "val_loss": 0.6891059923171997, "val_acc": 64.0}
{"epoch": 64, "training_loss": 0.684622232913971, "training_acc": 69.0, "val_loss": 0.6890829801559448, "val_acc": 52.0}
{"epoch": 65, "training_loss": 0.6929239082336426, "training_acc": 53.0, "val_loss": 0.6886191034317016, "val_acc": 52.0}
{"epoch": 66, "training_loss": 0.683713617324829, "training_acc": 58.0, "val_loss": 0.6899121499061585, "val_acc": 52.0}
{"epoch": 67, "training_loss": 0.6892874956130981, "training_acc": 51.0, "val_loss": 0.6900358486175537, "val_acc": 56.0}
{"epoch": 68, "training_loss": 0.6956791353225708, "training_acc": 52.0, "val_loss": 0.6968748211860657, "val_acc": 52.0}
{"epoch": 69, "training_loss": 0.6906619834899902, "training_acc": 53.0, "val_loss": 0.6879377388954162, "val_acc": 52.0}
{"epoch": 70, "training_loss": 0.6994589853286743, "training_acc": 46.0, "val_loss": 0.6937472176551819, "val_acc": 48.0}
{"epoch": 71, "training_loss": 0.6858921527862549, "training_acc": 55.0, "val_loss": 0.6909434938430786, "val_acc": 52.0}
{"epoch": 72, "training_loss": 0.685875985622406, "training_acc": 53.0, "val_loss": 0.6883825302124024, "val_acc": 60.0}
{"epoch": 73, "training_loss": 0.6893930768966675, "training_acc": 55.0, "val_loss": 0.6895775842666626, "val_acc": 48.0}
{"epoch": 74, "training_loss": 0.6886068367958069, "training_acc": 49.0, "val_loss": 0.695173499584198, "val_acc": 52.0}
{"epoch": 75, "training_loss": 0.7034824061393737, "training_acc": 53.0, "val_loss": 0.69478262424469, "val_acc": 52.0}
{"epoch": 76, "training_loss": 0.691852445602417, "training_acc": 52.0, "val_loss": 0.6965320324897766, "val_acc": 48.0}
{"epoch": 77, "training_loss": 0.7015770530700683, "training_acc": 42.0, "val_loss": 0.6888742756843567, "val_acc": 52.0}
{"epoch": 78, "training_loss": 0.6832266235351563, "training_acc": 53.0, "val_loss": 0.6884612011909484, "val_acc": 52.0}
{"epoch": 79, "training_loss": 0.6965659403800964, "training_acc": 53.0, "val_loss": 0.695779161453247, "val_acc": 52.0}
{"epoch": 80, "training_loss": 0.6952334880828858, "training_acc": 52.0, "val_loss": 0.6891389036178589, "val_acc": 48.0}
{"epoch": 81, "training_loss": 0.6836369132995606, "training_acc": 57.0, "val_loss": 0.6974718546867371, "val_acc": 52.0}
{"epoch": 82, "training_loss": 0.6867805886268615, "training_acc": 53.0, "val_loss": 0.68759441614151, "val_acc": 52.0}
{"epoch": 83, "training_loss": 0.6816214323043823, "training_acc": 57.0, "val_loss": 0.6925944256782531, "val_acc": 48.0}
{"epoch": 84, "training_loss": 0.6900678324699402, "training_acc": 47.0, "val_loss": 0.6893756985664368, "val_acc": 52.0}
{"epoch": 85, "training_loss": 0.6847429752349854, "training_acc": 58.0, "val_loss": 0.6872654271125793, "val_acc": 52.0}
{"epoch": 86, "training_loss": 0.6828386497497558, "training_acc": 56.0, "val_loss": 0.6872745823860168, "val_acc": 60.0}
{"epoch": 87, "training_loss": 0.6873138284683228, "training_acc": 50.0, "val_loss": 0.6871423649787903, "val_acc": 52.0}
{"epoch": 88, "training_loss": 0.70100750207901, "training_acc": 53.0, "val_loss": 0.7051847219467163, "val_acc": 52.0}
{"epoch": 89, "training_loss": 0.7118898439407348, "training_acc": 44.0, "val_loss": 0.6953150773048401, "val_acc": 48.0}
{"epoch": 90, "training_loss": 0.7018495202064514, "training_acc": 56.0, "val_loss": 0.6990896224975586, "val_acc": 52.0}
{"epoch": 91, "training_loss": 0.7055079984664917, "training_acc": 44.0, "val_loss": 0.6957213163375855, "val_acc": 48.0}
{"epoch": 92, "training_loss": 0.6805489206314087, "training_acc": 56.0, "val_loss": 0.6918667197227478, "val_acc": 52.0}
{"epoch": 93, "training_loss": 0.7230411005020142, "training_acc": 53.0, "val_loss": 0.7171898198127746, "val_acc": 52.0}
{"epoch": 94, "training_loss": 0.7140086388587952, "training_acc": 46.0, "val_loss": 0.7079185581207276, "val_acc": 48.0}
{"epoch": 95, "training_loss": 0.696730432510376, "training_acc": 49.0, "val_loss": 0.6887374258041382, "val_acc": 52.0}
{"epoch": 96, "training_loss": 0.6831277704238892, "training_acc": 53.0, "val_loss": 0.6889837193489075, "val_acc": 52.0}
{"epoch": 97, "training_loss": 0.684635944366455, "training_acc": 53.0, "val_loss": 0.6865873432159424, "val_acc": 64.0}
{"epoch": 98, "training_loss": 0.6803198862075805, "training_acc": 62.0, "val_loss": 0.6972768378257751, "val_acc": 48.0}
{"epoch": 99, "training_loss": 0.6934758496284484, "training_acc": 48.0, "val_loss": 0.6880924558639526, "val_acc": 56.0}
