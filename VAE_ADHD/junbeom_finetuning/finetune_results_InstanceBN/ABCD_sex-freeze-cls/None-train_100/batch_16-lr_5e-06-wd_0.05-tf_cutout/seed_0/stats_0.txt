"main_modify.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option BT_org --learning_rate 5e-6 --batch_size 16 --weight_decay 5e-2 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 0.6924394512176514, "training_acc": 52.0, "val_loss": 0.6899467754364014, "val_acc": 56.0}
{"epoch": 1, "training_loss": 0.6924967908859253, "training_acc": 52.0, "val_loss": 0.6898981070518494, "val_acc": 56.0}
{"epoch": 2, "training_loss": 0.6923362398147583, "training_acc": 52.0, "val_loss": 0.689878408908844, "val_acc": 56.0}
{"epoch": 3, "training_loss": 0.6923873567581177, "training_acc": 52.0, "val_loss": 0.6897656273841858, "val_acc": 56.0}
{"epoch": 4, "training_loss": 0.6923800325393676, "training_acc": 52.0, "val_loss": 0.6897913050651551, "val_acc": 56.0}
{"epoch": 5, "training_loss": 0.6922319197654724, "training_acc": 52.0, "val_loss": 0.6897235226631164, "val_acc": 56.0}
{"epoch": 6, "training_loss": 0.6924084234237671, "training_acc": 52.0, "val_loss": 0.6896869397163391, "val_acc": 56.0}
{"epoch": 7, "training_loss": 0.692293860912323, "training_acc": 52.0, "val_loss": 0.6897027587890625, "val_acc": 56.0}
{"epoch": 8, "training_loss": 0.6925004386901855, "training_acc": 52.0, "val_loss": 0.6896217274665832, "val_acc": 56.0}
{"epoch": 9, "training_loss": 0.6923819732666016, "training_acc": 52.0, "val_loss": 0.6896535897254944, "val_acc": 56.0}
{"epoch": 10, "training_loss": 0.6923305177688599, "training_acc": 52.0, "val_loss": 0.6897557139396667, "val_acc": 56.0}
{"epoch": 11, "training_loss": 0.6923730278015137, "training_acc": 52.0, "val_loss": 0.6897390413284302, "val_acc": 56.0}
{"epoch": 12, "training_loss": 0.6922904920578002, "training_acc": 52.0, "val_loss": 0.6895814943313598, "val_acc": 56.0}
{"epoch": 13, "training_loss": 0.6921234130859375, "training_acc": 52.0, "val_loss": 0.6895497083663941, "val_acc": 56.0}
{"epoch": 14, "training_loss": 0.6923764109611511, "training_acc": 52.0, "val_loss": 0.689460027217865, "val_acc": 56.0}
{"epoch": 15, "training_loss": 0.6922391772270202, "training_acc": 52.0, "val_loss": 0.6894187164306641, "val_acc": 56.0}
{"epoch": 16, "training_loss": 0.6923096299171447, "training_acc": 52.0, "val_loss": 0.6892559289932251, "val_acc": 56.0}
{"epoch": 17, "training_loss": 0.6923064708709716, "training_acc": 52.0, "val_loss": 0.6892743039131165, "val_acc": 56.0}
{"epoch": 18, "training_loss": 0.6923821973800659, "training_acc": 52.0, "val_loss": 0.6893288707733154, "val_acc": 56.0}
{"epoch": 19, "training_loss": 0.6922233200073242, "training_acc": 52.0, "val_loss": 0.6894143414497376, "val_acc": 56.0}
{"epoch": 20, "training_loss": 0.6923404264450074, "training_acc": 52.0, "val_loss": 0.6894093704223633, "val_acc": 56.0}
{"epoch": 21, "training_loss": 0.6925206041336059, "training_acc": 52.0, "val_loss": 0.6894190645217896, "val_acc": 56.0}
{"epoch": 22, "training_loss": 0.6923048186302185, "training_acc": 52.0, "val_loss": 0.6893785881996155, "val_acc": 56.0}
{"epoch": 23, "training_loss": 0.6925074291229248, "training_acc": 52.0, "val_loss": 0.6893957424163818, "val_acc": 56.0}
{"epoch": 24, "training_loss": 0.6924241018295288, "training_acc": 52.0, "val_loss": 0.6893130588531494, "val_acc": 56.0}
{"epoch": 25, "training_loss": 0.6924753880500794, "training_acc": 52.0, "val_loss": 0.6893377804756164, "val_acc": 56.0}
{"epoch": 26, "training_loss": 0.6924561357498169, "training_acc": 52.0, "val_loss": 0.6893225836753846, "val_acc": 56.0}
{"epoch": 27, "training_loss": 0.6922748422622681, "training_acc": 52.0, "val_loss": 0.689353837966919, "val_acc": 56.0}
{"epoch": 28, "training_loss": 0.6922561073303223, "training_acc": 52.0, "val_loss": 0.6893606376647949, "val_acc": 56.0}
{"epoch": 29, "training_loss": 0.6923036623001099, "training_acc": 52.0, "val_loss": 0.6893048048019409, "val_acc": 56.0}
{"epoch": 30, "training_loss": 0.6925353789329529, "training_acc": 52.0, "val_loss": 0.6891362786293029, "val_acc": 56.0}
{"epoch": 31, "training_loss": 0.6921900081634521, "training_acc": 52.0, "val_loss": 0.6890580177307128, "val_acc": 56.0}
{"epoch": 32, "training_loss": 0.6923517727851868, "training_acc": 52.0, "val_loss": 0.6888885879516602, "val_acc": 56.0}
{"epoch": 33, "training_loss": 0.6923683309555053, "training_acc": 52.0, "val_loss": 0.6887890672683716, "val_acc": 56.0}
{"epoch": 34, "training_loss": 0.6923252296447754, "training_acc": 52.0, "val_loss": 0.6887879991531372, "val_acc": 56.0}
{"epoch": 35, "training_loss": 0.6924727010726929, "training_acc": 52.0, "val_loss": 0.688836350440979, "val_acc": 56.0}
{"epoch": 36, "training_loss": 0.6924312353134155, "training_acc": 52.0, "val_loss": 0.6888221335411072, "val_acc": 56.0}
{"epoch": 37, "training_loss": 0.692350697517395, "training_acc": 52.0, "val_loss": 0.6887856745719909, "val_acc": 56.0}
{"epoch": 38, "training_loss": 0.6924518775939942, "training_acc": 52.0, "val_loss": 0.6888007283210754, "val_acc": 56.0}
{"epoch": 39, "training_loss": 0.6922748136520386, "training_acc": 52.0, "val_loss": 0.6888256120681763, "val_acc": 56.0}
{"epoch": 40, "training_loss": 0.6923718595504761, "training_acc": 52.0, "val_loss": 0.6889025235176086, "val_acc": 56.0}
{"epoch": 41, "training_loss": 0.692450442314148, "training_acc": 52.0, "val_loss": 0.6889187932014466, "val_acc": 56.0}
{"epoch": 42, "training_loss": 0.6922334718704224, "training_acc": 52.0, "val_loss": 0.6889295887947082, "val_acc": 56.0}
{"epoch": 43, "training_loss": 0.692298972606659, "training_acc": 52.0, "val_loss": 0.6889445233345032, "val_acc": 56.0}
{"epoch": 44, "training_loss": 0.6922430300712585, "training_acc": 52.0, "val_loss": 0.6890597748756409, "val_acc": 56.0}
{"epoch": 45, "training_loss": 0.6922797513008118, "training_acc": 52.0, "val_loss": 0.6890915274620056, "val_acc": 56.0}
{"epoch": 46, "training_loss": 0.6925542879104615, "training_acc": 52.0, "val_loss": 0.6891077923774719, "val_acc": 56.0}
{"epoch": 47, "training_loss": 0.6924380278587341, "training_acc": 52.0, "val_loss": 0.6890827798843384, "val_acc": 56.0}
{"epoch": 48, "training_loss": 0.6923866605758667, "training_acc": 52.0, "val_loss": 0.6890632700920105, "val_acc": 56.0}
{"epoch": 49, "training_loss": 0.6923215126991272, "training_acc": 52.0, "val_loss": 0.6890968322753906, "val_acc": 56.0}
{"epoch": 50, "training_loss": 0.6923788166046143, "training_acc": 52.0, "val_loss": 0.6891939091682434, "val_acc": 56.0}
{"epoch": 51, "training_loss": 0.6923121500015259, "training_acc": 52.0, "val_loss": 0.6893043231964111, "val_acc": 56.0}
{"epoch": 52, "training_loss": 0.69243337392807, "training_acc": 52.0, "val_loss": 0.6894292235374451, "val_acc": 56.0}
{"epoch": 53, "training_loss": 0.6923669576644897, "training_acc": 52.0, "val_loss": 0.6894795989990234, "val_acc": 56.0}
{"epoch": 54, "training_loss": 0.6922730708122253, "training_acc": 52.0, "val_loss": 0.6895382285118103, "val_acc": 56.0}
{"epoch": 55, "training_loss": 0.6922554135322571, "training_acc": 52.0, "val_loss": 0.6896545863151551, "val_acc": 56.0}
{"epoch": 56, "training_loss": 0.6921481704711914, "training_acc": 52.0, "val_loss": 0.6898185038566589, "val_acc": 56.0}
