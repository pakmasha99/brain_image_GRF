"main_modify.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option BT_org --learning_rate 5e-6 --batch_size 16 --weight_decay 5e-2 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 0.6928430628776551, "training_acc": 53.0, "val_loss": 0.6929307270050049, "val_acc": 52.0}
{"epoch": 1, "training_loss": 0.692738676071167, "training_acc": 53.0, "val_loss": 0.6928705143928527, "val_acc": 52.0}
{"epoch": 2, "training_loss": 0.6925881981849671, "training_acc": 53.0, "val_loss": 0.6928320002555847, "val_acc": 52.0}
{"epoch": 3, "training_loss": 0.6924218964576722, "training_acc": 53.0, "val_loss": 0.6928000211715698, "val_acc": 52.0}
{"epoch": 4, "training_loss": 0.6924720096588135, "training_acc": 53.0, "val_loss": 0.692757625579834, "val_acc": 52.0}
{"epoch": 5, "training_loss": 0.6923460483551025, "training_acc": 53.0, "val_loss": 0.6926892399787903, "val_acc": 52.0}
{"epoch": 6, "training_loss": 0.6923999238014221, "training_acc": 53.0, "val_loss": 0.6926354813575745, "val_acc": 52.0}
{"epoch": 7, "training_loss": 0.6920726203918457, "training_acc": 53.0, "val_loss": 0.6926078009605408, "val_acc": 52.0}
{"epoch": 8, "training_loss": 0.6921013307571411, "training_acc": 53.0, "val_loss": 0.6925896573066711, "val_acc": 52.0}
{"epoch": 9, "training_loss": 0.6920863580703736, "training_acc": 53.0, "val_loss": 0.6925736737251281, "val_acc": 52.0}
{"epoch": 10, "training_loss": 0.6919050741195679, "training_acc": 53.0, "val_loss": 0.6925448322296143, "val_acc": 52.0}
{"epoch": 11, "training_loss": 0.6919879055023194, "training_acc": 53.0, "val_loss": 0.6925224399566651, "val_acc": 52.0}
{"epoch": 12, "training_loss": 0.6918757390975953, "training_acc": 53.0, "val_loss": 0.692487645149231, "val_acc": 52.0}
{"epoch": 13, "training_loss": 0.6918801498413086, "training_acc": 53.0, "val_loss": 0.6924506640434265, "val_acc": 52.0}
{"epoch": 14, "training_loss": 0.6917032289505005, "training_acc": 53.0, "val_loss": 0.6924435257911682, "val_acc": 52.0}
{"epoch": 15, "training_loss": 0.6918285274505616, "training_acc": 53.0, "val_loss": 0.6924436140060425, "val_acc": 52.0}
{"epoch": 16, "training_loss": 0.6915468645095825, "training_acc": 53.0, "val_loss": 0.6924316048622131, "val_acc": 52.0}
{"epoch": 17, "training_loss": 0.6915514898300171, "training_acc": 53.0, "val_loss": 0.6924225974082947, "val_acc": 52.0}
{"epoch": 18, "training_loss": 0.6914666604995727, "training_acc": 53.0, "val_loss": 0.692431001663208, "val_acc": 52.0}
{"epoch": 19, "training_loss": 0.6915349316596985, "training_acc": 53.0, "val_loss": 0.6924275827407836, "val_acc": 52.0}
{"epoch": 20, "training_loss": 0.6917323541641235, "training_acc": 53.0, "val_loss": 0.6924252700805664, "val_acc": 52.0}
{"epoch": 21, "training_loss": 0.6918132162094116, "training_acc": 53.0, "val_loss": 0.6924249792098999, "val_acc": 52.0}
{"epoch": 22, "training_loss": 0.6916994476318359, "training_acc": 53.0, "val_loss": 0.6924201560020447, "val_acc": 52.0}
{"epoch": 23, "training_loss": 0.6915106749534607, "training_acc": 53.0, "val_loss": 0.6924205756187439, "val_acc": 52.0}
{"epoch": 24, "training_loss": 0.6917313122749329, "training_acc": 53.0, "val_loss": 0.6924193954467773, "val_acc": 52.0}
{"epoch": 25, "training_loss": 0.6916169166564942, "training_acc": 53.0, "val_loss": 0.6924202561378479, "val_acc": 52.0}
{"epoch": 26, "training_loss": 0.6916202831268311, "training_acc": 53.0, "val_loss": 0.6924269604682922, "val_acc": 52.0}
{"epoch": 27, "training_loss": 0.6916870236396789, "training_acc": 53.0, "val_loss": 0.6924253869056701, "val_acc": 52.0}
{"epoch": 28, "training_loss": 0.6912808966636658, "training_acc": 53.0, "val_loss": 0.6924270510673523, "val_acc": 52.0}
{"epoch": 29, "training_loss": 0.6915744614601135, "training_acc": 53.0, "val_loss": 0.6924291467666626, "val_acc": 52.0}
{"epoch": 30, "training_loss": 0.691564519405365, "training_acc": 53.0, "val_loss": 0.6924299931526184, "val_acc": 52.0}
{"epoch": 31, "training_loss": 0.6914742588996887, "training_acc": 53.0, "val_loss": 0.6924288272857666, "val_acc": 52.0}
{"epoch": 32, "training_loss": 0.6915077257156372, "training_acc": 53.0, "val_loss": 0.6924445033073425, "val_acc": 52.0}
{"epoch": 33, "training_loss": 0.69132981300354, "training_acc": 53.0, "val_loss": 0.6924595928192139, "val_acc": 52.0}
{"epoch": 34, "training_loss": 0.6914006614685059, "training_acc": 53.0, "val_loss": 0.6924752068519592, "val_acc": 52.0}
{"epoch": 35, "training_loss": 0.6915002346038819, "training_acc": 53.0, "val_loss": 0.69247563123703, "val_acc": 52.0}
{"epoch": 36, "training_loss": 0.6914504909515381, "training_acc": 53.0, "val_loss": 0.6924838924407959, "val_acc": 52.0}
{"epoch": 37, "training_loss": 0.691287236213684, "training_acc": 53.0, "val_loss": 0.6924847483634948, "val_acc": 52.0}
{"epoch": 38, "training_loss": 0.6913160896301269, "training_acc": 53.0, "val_loss": 0.6924767351150513, "val_acc": 52.0}
{"epoch": 39, "training_loss": 0.6913767886161805, "training_acc": 53.0, "val_loss": 0.692461633682251, "val_acc": 52.0}
{"epoch": 40, "training_loss": 0.6914793300628662, "training_acc": 53.0, "val_loss": 0.692451183795929, "val_acc": 52.0}
{"epoch": 41, "training_loss": 0.6913687992095947, "training_acc": 53.0, "val_loss": 0.6924605178833008, "val_acc": 52.0}
{"epoch": 42, "training_loss": 0.6913936805725097, "training_acc": 53.0, "val_loss": 0.6924558138847351, "val_acc": 52.0}
{"epoch": 43, "training_loss": 0.691367597579956, "training_acc": 53.0, "val_loss": 0.6924555945396423, "val_acc": 52.0}
