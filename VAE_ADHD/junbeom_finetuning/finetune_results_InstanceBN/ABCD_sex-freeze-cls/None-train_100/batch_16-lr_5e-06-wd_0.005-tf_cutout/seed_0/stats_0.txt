"main_modify.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option BT_org --learning_rate 5e-6 --batch_size 16 --weight_decay 5e-3 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 0.6924392986297607, "training_acc": 52.0, "val_loss": 0.6899432682991028, "val_acc": 56.0}
{"epoch": 1, "training_loss": 0.6924960660934448, "training_acc": 52.0, "val_loss": 0.6898990178108215, "val_acc": 56.0}
{"epoch": 2, "training_loss": 0.6923358392715454, "training_acc": 52.0, "val_loss": 0.6898812484741211, "val_acc": 56.0}
{"epoch": 3, "training_loss": 0.6923889636993408, "training_acc": 52.0, "val_loss": 0.6897608113288879, "val_acc": 56.0}
{"epoch": 4, "training_loss": 0.6923810863494873, "training_acc": 52.0, "val_loss": 0.6897876834869385, "val_acc": 56.0}
{"epoch": 5, "training_loss": 0.6922302412986755, "training_acc": 52.0, "val_loss": 0.6897250103950501, "val_acc": 56.0}
{"epoch": 6, "training_loss": 0.6924047422409058, "training_acc": 52.0, "val_loss": 0.6896864247322082, "val_acc": 56.0}
{"epoch": 7, "training_loss": 0.6922951364517211, "training_acc": 52.0, "val_loss": 0.68970134973526, "val_acc": 56.0}
{"epoch": 8, "training_loss": 0.6924977588653565, "training_acc": 52.0, "val_loss": 0.6896243810653686, "val_acc": 56.0}
{"epoch": 9, "training_loss": 0.6923800396919251, "training_acc": 52.0, "val_loss": 0.6896545839309692, "val_acc": 56.0}
{"epoch": 10, "training_loss": 0.6923321533203125, "training_acc": 52.0, "val_loss": 0.6897528028488159, "val_acc": 56.0}
{"epoch": 11, "training_loss": 0.6923722553253174, "training_acc": 52.0, "val_loss": 0.689735791683197, "val_acc": 56.0}
{"epoch": 12, "training_loss": 0.6922876071929932, "training_acc": 52.0, "val_loss": 0.6895823907852173, "val_acc": 56.0}
{"epoch": 13, "training_loss": 0.6921228170394897, "training_acc": 52.0, "val_loss": 0.6895460891723633, "val_acc": 56.0}
{"epoch": 14, "training_loss": 0.6923784112930298, "training_acc": 52.0, "val_loss": 0.6894596910476685, "val_acc": 56.0}
{"epoch": 15, "training_loss": 0.692239134311676, "training_acc": 52.0, "val_loss": 0.689416058063507, "val_acc": 56.0}
{"epoch": 16, "training_loss": 0.6923144721984863, "training_acc": 52.0, "val_loss": 0.6892516350746155, "val_acc": 56.0}
{"epoch": 17, "training_loss": 0.6923057579994202, "training_acc": 52.0, "val_loss": 0.6892707180976868, "val_acc": 56.0}
{"epoch": 18, "training_loss": 0.6923802757263183, "training_acc": 52.0, "val_loss": 0.689328088760376, "val_acc": 56.0}
{"epoch": 19, "training_loss": 0.6922231864929199, "training_acc": 52.0, "val_loss": 0.6894140267372131, "val_acc": 56.0}
{"epoch": 20, "training_loss": 0.6923394536972046, "training_acc": 52.0, "val_loss": 0.6894087243080139, "val_acc": 56.0}
{"epoch": 21, "training_loss": 0.6925206279754639, "training_acc": 52.0, "val_loss": 0.6894165372848511, "val_acc": 56.0}
{"epoch": 22, "training_loss": 0.6923050618171692, "training_acc": 52.0, "val_loss": 0.6893780732154846, "val_acc": 56.0}
{"epoch": 23, "training_loss": 0.6925058197975159, "training_acc": 52.0, "val_loss": 0.6893979001045227, "val_acc": 56.0}
{"epoch": 24, "training_loss": 0.6924243068695068, "training_acc": 52.0, "val_loss": 0.6893118309974671, "val_acc": 56.0}
{"epoch": 25, "training_loss": 0.6924735689163208, "training_acc": 52.0, "val_loss": 0.6893339228630065, "val_acc": 56.0}
{"epoch": 26, "training_loss": 0.692444519996643, "training_acc": 52.0, "val_loss": 0.6893202590942383, "val_acc": 56.0}
{"epoch": 27, "training_loss": 0.6922743678092956, "training_acc": 52.0, "val_loss": 0.6893505525588989, "val_acc": 56.0}
{"epoch": 28, "training_loss": 0.6922596740722656, "training_acc": 52.0, "val_loss": 0.6893566465377807, "val_acc": 56.0}
{"epoch": 29, "training_loss": 0.6923030519485474, "training_acc": 52.0, "val_loss": 0.6893031191825867, "val_acc": 56.0}
{"epoch": 30, "training_loss": 0.6925365591049194, "training_acc": 52.0, "val_loss": 0.6891356348991394, "val_acc": 56.0}
{"epoch": 31, "training_loss": 0.6921902084350586, "training_acc": 52.0, "val_loss": 0.6890554261207581, "val_acc": 56.0}
{"epoch": 32, "training_loss": 0.6923531246185303, "training_acc": 52.0, "val_loss": 0.6888837838172912, "val_acc": 56.0}
{"epoch": 33, "training_loss": 0.6923665833473206, "training_acc": 52.0, "val_loss": 0.688784294128418, "val_acc": 56.0}
{"epoch": 34, "training_loss": 0.6923245859146118, "training_acc": 52.0, "val_loss": 0.688784327507019, "val_acc": 56.0}
{"epoch": 35, "training_loss": 0.6924736022949218, "training_acc": 52.0, "val_loss": 0.688840446472168, "val_acc": 56.0}
{"epoch": 36, "training_loss": 0.6924321699142456, "training_acc": 52.0, "val_loss": 0.6888230276107788, "val_acc": 56.0}
{"epoch": 37, "training_loss": 0.6923529148101807, "training_acc": 52.0, "val_loss": 0.688783814907074, "val_acc": 56.0}
{"epoch": 38, "training_loss": 0.6924519538879395, "training_acc": 52.0, "val_loss": 0.6887984728813171, "val_acc": 56.0}
{"epoch": 39, "training_loss": 0.6922738313674927, "training_acc": 52.0, "val_loss": 0.6888271570205688, "val_acc": 56.0}
{"epoch": 40, "training_loss": 0.6923681712150573, "training_acc": 52.0, "val_loss": 0.688899040222168, "val_acc": 56.0}
{"epoch": 41, "training_loss": 0.6924520945549011, "training_acc": 52.0, "val_loss": 0.6889175343513488, "val_acc": 56.0}
{"epoch": 42, "training_loss": 0.6922341585159302, "training_acc": 52.0, "val_loss": 0.6889260888099671, "val_acc": 56.0}
{"epoch": 43, "training_loss": 0.6922978281974792, "training_acc": 52.0, "val_loss": 0.6889371085166931, "val_acc": 56.0}
{"epoch": 44, "training_loss": 0.692247543334961, "training_acc": 52.0, "val_loss": 0.689058063030243, "val_acc": 56.0}
{"epoch": 45, "training_loss": 0.6922787189483642, "training_acc": 52.0, "val_loss": 0.689089195728302, "val_acc": 56.0}
{"epoch": 46, "training_loss": 0.6925548553466797, "training_acc": 52.0, "val_loss": 0.6891085028648376, "val_acc": 56.0}
{"epoch": 47, "training_loss": 0.6924396276473999, "training_acc": 52.0, "val_loss": 0.6890792489051819, "val_acc": 56.0}
{"epoch": 48, "training_loss": 0.6923857116699219, "training_acc": 52.0, "val_loss": 0.6890610861778259, "val_acc": 56.0}
{"epoch": 49, "training_loss": 0.6923211908340454, "training_acc": 52.0, "val_loss": 0.6890938663482666, "val_acc": 56.0}
{"epoch": 50, "training_loss": 0.6923801469802856, "training_acc": 52.0, "val_loss": 0.6891899418830871, "val_acc": 56.0}
{"epoch": 51, "training_loss": 0.6923121094703675, "training_acc": 52.0, "val_loss": 0.6893041920661926, "val_acc": 56.0}
{"epoch": 52, "training_loss": 0.6924364519119263, "training_acc": 52.0, "val_loss": 0.6894277262687684, "val_acc": 56.0}
{"epoch": 53, "training_loss": 0.6923664999008179, "training_acc": 52.0, "val_loss": 0.6894754338264465, "val_acc": 56.0}
{"epoch": 54, "training_loss": 0.6922714090347291, "training_acc": 52.0, "val_loss": 0.6895306658744812, "val_acc": 56.0}
{"epoch": 55, "training_loss": 0.6922520303726196, "training_acc": 52.0, "val_loss": 0.6896510672569275, "val_acc": 56.0}
{"epoch": 56, "training_loss": 0.6921499514579773, "training_acc": 52.0, "val_loss": 0.6898119425773621, "val_acc": 56.0}
