"main_modify.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option BT_org --learning_rate 5e-6 --batch_size 16 --weight_decay 5e-3 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 0.6928448557853699, "training_acc": 53.0, "val_loss": 0.6929315543174743, "val_acc": 52.0}
{"epoch": 1, "training_loss": 0.692741310596466, "training_acc": 53.0, "val_loss": 0.6928701448440552, "val_acc": 52.0}
{"epoch": 2, "training_loss": 0.6925876545906067, "training_acc": 53.0, "val_loss": 0.6928320026397705, "val_acc": 52.0}
{"epoch": 3, "training_loss": 0.6924220275878906, "training_acc": 53.0, "val_loss": 0.692800567150116, "val_acc": 52.0}
{"epoch": 4, "training_loss": 0.6924678659439087, "training_acc": 53.0, "val_loss": 0.6927561521530151, "val_acc": 52.0}
{"epoch": 5, "training_loss": 0.6923499584197998, "training_acc": 53.0, "val_loss": 0.6926886105537414, "val_acc": 52.0}
{"epoch": 6, "training_loss": 0.692394552230835, "training_acc": 53.0, "val_loss": 0.6926359128952027, "val_acc": 52.0}
{"epoch": 7, "training_loss": 0.6920715713500977, "training_acc": 53.0, "val_loss": 0.6926071691513062, "val_acc": 52.0}
{"epoch": 8, "training_loss": 0.6921008348464965, "training_acc": 53.0, "val_loss": 0.6925903296470642, "val_acc": 52.0}
{"epoch": 9, "training_loss": 0.6920878601074218, "training_acc": 53.0, "val_loss": 0.6925745415687561, "val_acc": 52.0}
{"epoch": 10, "training_loss": 0.6919051504135132, "training_acc": 53.0, "val_loss": 0.6925442624092102, "val_acc": 52.0}
{"epoch": 11, "training_loss": 0.6919928884506226, "training_acc": 53.0, "val_loss": 0.6925226140022278, "val_acc": 52.0}
{"epoch": 12, "training_loss": 0.691874270439148, "training_acc": 53.0, "val_loss": 0.6924880290031433, "val_acc": 52.0}
{"epoch": 13, "training_loss": 0.691885986328125, "training_acc": 53.0, "val_loss": 0.6924511456489563, "val_acc": 52.0}
{"epoch": 14, "training_loss": 0.6917068338394166, "training_acc": 53.0, "val_loss": 0.6924435663223266, "val_acc": 52.0}
{"epoch": 15, "training_loss": 0.6918265438079834, "training_acc": 53.0, "val_loss": 0.6924434375762939, "val_acc": 52.0}
{"epoch": 16, "training_loss": 0.6915447998046875, "training_acc": 53.0, "val_loss": 0.6924313354492188, "val_acc": 52.0}
{"epoch": 17, "training_loss": 0.6915484237670898, "training_acc": 53.0, "val_loss": 0.6924224805831909, "val_acc": 52.0}
{"epoch": 18, "training_loss": 0.691467866897583, "training_acc": 53.0, "val_loss": 0.6924310231208801, "val_acc": 52.0}
{"epoch": 19, "training_loss": 0.6915365481376647, "training_acc": 53.0, "val_loss": 0.6924277853965759, "val_acc": 52.0}
{"epoch": 20, "training_loss": 0.6917349886894226, "training_acc": 53.0, "val_loss": 0.6924252676963806, "val_acc": 52.0}
{"epoch": 21, "training_loss": 0.6918121147155761, "training_acc": 53.0, "val_loss": 0.6924249577522278, "val_acc": 52.0}
{"epoch": 22, "training_loss": 0.6916997861862183, "training_acc": 53.0, "val_loss": 0.6924202394485474, "val_acc": 52.0}
{"epoch": 23, "training_loss": 0.6915103435516358, "training_acc": 53.0, "val_loss": 0.6924206852912903, "val_acc": 52.0}
{"epoch": 24, "training_loss": 0.6917294907569885, "training_acc": 53.0, "val_loss": 0.6924194645881653, "val_acc": 52.0}
{"epoch": 25, "training_loss": 0.6916219878196717, "training_acc": 53.0, "val_loss": 0.6924204492568969, "val_acc": 52.0}
{"epoch": 26, "training_loss": 0.6916126799583435, "training_acc": 53.0, "val_loss": 0.6924269986152649, "val_acc": 52.0}
{"epoch": 27, "training_loss": 0.6916880702972412, "training_acc": 53.0, "val_loss": 0.6924254202842712, "val_acc": 52.0}
{"epoch": 28, "training_loss": 0.6912801456451416, "training_acc": 53.0, "val_loss": 0.6924271321296692, "val_acc": 52.0}
{"epoch": 29, "training_loss": 0.6915740633010864, "training_acc": 53.0, "val_loss": 0.6924291348457337, "val_acc": 52.0}
{"epoch": 30, "training_loss": 0.6915612936019897, "training_acc": 53.0, "val_loss": 0.6924300479888916, "val_acc": 52.0}
{"epoch": 31, "training_loss": 0.6914764904975891, "training_acc": 53.0, "val_loss": 0.6924287486076355, "val_acc": 52.0}
{"epoch": 32, "training_loss": 0.6915079593658447, "training_acc": 53.0, "val_loss": 0.6924448370933532, "val_acc": 52.0}
{"epoch": 33, "training_loss": 0.6913312315940857, "training_acc": 53.0, "val_loss": 0.6924603962898255, "val_acc": 52.0}
{"epoch": 34, "training_loss": 0.6914014267921448, "training_acc": 53.0, "val_loss": 0.6924756336212158, "val_acc": 52.0}
{"epoch": 35, "training_loss": 0.6915010452270508, "training_acc": 53.0, "val_loss": 0.6924760365486144, "val_acc": 52.0}
{"epoch": 36, "training_loss": 0.6914486694335937, "training_acc": 53.0, "val_loss": 0.692483913898468, "val_acc": 52.0}
{"epoch": 37, "training_loss": 0.6912862133979797, "training_acc": 53.0, "val_loss": 0.6924846577644348, "val_acc": 52.0}
{"epoch": 38, "training_loss": 0.6913161063194275, "training_acc": 53.0, "val_loss": 0.6924770736694336, "val_acc": 52.0}
{"epoch": 39, "training_loss": 0.6913779783248901, "training_acc": 53.0, "val_loss": 0.6924618482589722, "val_acc": 52.0}
{"epoch": 40, "training_loss": 0.6914808559417724, "training_acc": 53.0, "val_loss": 0.6924514484405517, "val_acc": 52.0}
{"epoch": 41, "training_loss": 0.6913709473609925, "training_acc": 53.0, "val_loss": 0.6924613308906555, "val_acc": 52.0}
{"epoch": 42, "training_loss": 0.6913986492156983, "training_acc": 53.0, "val_loss": 0.6924560213088989, "val_acc": 52.0}
{"epoch": 43, "training_loss": 0.6913684988021851, "training_acc": 53.0, "val_loss": 0.6924560141563415, "val_acc": 52.0}
