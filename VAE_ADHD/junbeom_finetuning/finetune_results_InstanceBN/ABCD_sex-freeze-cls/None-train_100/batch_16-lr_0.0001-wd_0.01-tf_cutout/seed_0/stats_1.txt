"main_modify.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option BT_org --learning_rate 1e-4 --batch_size 16 --weight_decay 1e-2 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 0.7029565215110779, "training_acc": 47.0, "val_loss": 0.695496187210083, "val_acc": 48.0}
{"epoch": 1, "training_loss": 0.698504068851471, "training_acc": 41.0, "val_loss": 0.692527334690094, "val_acc": 52.0}
{"epoch": 2, "training_loss": 0.6919072651863098, "training_acc": 53.0, "val_loss": 0.6925759053230286, "val_acc": 52.0}
{"epoch": 3, "training_loss": 0.6918968105316162, "training_acc": 53.0, "val_loss": 0.6927374458312988, "val_acc": 52.0}
{"epoch": 4, "training_loss": 0.6915728187561035, "training_acc": 53.0, "val_loss": 0.6926933646202087, "val_acc": 52.0}
{"epoch": 5, "training_loss": 0.6918779873847961, "training_acc": 53.0, "val_loss": 0.692651960849762, "val_acc": 52.0}
{"epoch": 6, "training_loss": 0.6915646409988403, "training_acc": 53.0, "val_loss": 0.6928516554832459, "val_acc": 52.0}
{"epoch": 7, "training_loss": 0.6924305129051208, "training_acc": 53.0, "val_loss": 0.6926001715660095, "val_acc": 52.0}
{"epoch": 8, "training_loss": 0.691444878578186, "training_acc": 53.0, "val_loss": 0.6927166056632995, "val_acc": 52.0}
{"epoch": 9, "training_loss": 0.6933114624023438, "training_acc": 53.0, "val_loss": 0.692527117729187, "val_acc": 52.0}
{"epoch": 10, "training_loss": 0.6923777413368225, "training_acc": 53.0, "val_loss": 0.6926218700408936, "val_acc": 52.0}
{"epoch": 11, "training_loss": 0.6912400341033935, "training_acc": 53.0, "val_loss": 0.6925350880622864, "val_acc": 52.0}
{"epoch": 12, "training_loss": 0.6923164653778077, "training_acc": 53.0, "val_loss": 0.6925364255905151, "val_acc": 52.0}
{"epoch": 13, "training_loss": 0.6921475124359131, "training_acc": 53.0, "val_loss": 0.6925295209884643, "val_acc": 52.0}
{"epoch": 14, "training_loss": 0.691884388923645, "training_acc": 53.0, "val_loss": 0.6925872921943664, "val_acc": 52.0}
{"epoch": 15, "training_loss": 0.6913843631744385, "training_acc": 53.0, "val_loss": 0.6926948761940003, "val_acc": 52.0}
{"epoch": 16, "training_loss": 0.6912094974517822, "training_acc": 53.0, "val_loss": 0.6928438210487365, "val_acc": 52.0}
{"epoch": 17, "training_loss": 0.6912789034843445, "training_acc": 53.0, "val_loss": 0.6930673718452454, "val_acc": 52.0}
{"epoch": 18, "training_loss": 0.6915510845184326, "training_acc": 53.0, "val_loss": 0.6937598800659179, "val_acc": 52.0}
{"epoch": 19, "training_loss": 0.6921844911575318, "training_acc": 53.0, "val_loss": 0.6937780237197876, "val_acc": 52.0}
{"epoch": 20, "training_loss": 0.6920348310470581, "training_acc": 53.0, "val_loss": 0.6928084111213684, "val_acc": 52.0}
{"epoch": 21, "training_loss": 0.6913706612586975, "training_acc": 53.0, "val_loss": 0.6925832676887512, "val_acc": 52.0}
{"epoch": 22, "training_loss": 0.6918123245239258, "training_acc": 53.0, "val_loss": 0.6925249576568604, "val_acc": 52.0}
{"epoch": 23, "training_loss": 0.6914427471160889, "training_acc": 53.0, "val_loss": 0.6925911641120911, "val_acc": 52.0}
{"epoch": 24, "training_loss": 0.6915377950668335, "training_acc": 53.0, "val_loss": 0.6925614714622498, "val_acc": 52.0}
{"epoch": 25, "training_loss": 0.6917915987968445, "training_acc": 53.0, "val_loss": 0.6925349926948547, "val_acc": 52.0}
{"epoch": 26, "training_loss": 0.6914858675003052, "training_acc": 53.0, "val_loss": 0.6928806471824646, "val_acc": 52.0}
{"epoch": 27, "training_loss": 0.6928927683830262, "training_acc": 53.0, "val_loss": 0.6933297443389893, "val_acc": 52.0}
{"epoch": 28, "training_loss": 0.6925507855415344, "training_acc": 53.0, "val_loss": 0.6925765800476075, "val_acc": 52.0}
{"epoch": 29, "training_loss": 0.6916622757911682, "training_acc": 53.0, "val_loss": 0.6925361967086792, "val_acc": 52.0}
{"epoch": 30, "training_loss": 0.6922160005569458, "training_acc": 53.0, "val_loss": 0.6925806903839111, "val_acc": 52.0}
{"epoch": 31, "training_loss": 0.6920881366729736, "training_acc": 53.0, "val_loss": 0.6936725306510926, "val_acc": 52.0}
{"epoch": 32, "training_loss": 0.6917396545410156, "training_acc": 53.0, "val_loss": 0.6929710388183594, "val_acc": 52.0}
{"epoch": 33, "training_loss": 0.6916256952285766, "training_acc": 53.0, "val_loss": 0.6928914380073548, "val_acc": 52.0}
{"epoch": 34, "training_loss": 0.6915691733360291, "training_acc": 53.0, "val_loss": 0.6930171942710877, "val_acc": 52.0}
{"epoch": 35, "training_loss": 0.6918737602233886, "training_acc": 53.0, "val_loss": 0.6927732419967652, "val_acc": 52.0}
{"epoch": 36, "training_loss": 0.6923074150085449, "training_acc": 53.0, "val_loss": 0.6931216859817505, "val_acc": 52.0}
{"epoch": 37, "training_loss": 0.6938839101791382, "training_acc": 53.0, "val_loss": 0.6925402522087097, "val_acc": 52.0}
{"epoch": 38, "training_loss": 0.6916752362251282, "training_acc": 53.0, "val_loss": 0.6925441074371338, "val_acc": 52.0}
{"epoch": 39, "training_loss": 0.6917854833602906, "training_acc": 53.0, "val_loss": 0.6925979280471801, "val_acc": 52.0}
{"epoch": 40, "training_loss": 0.6915236759185791, "training_acc": 53.0, "val_loss": 0.6926013541221618, "val_acc": 52.0}
{"epoch": 41, "training_loss": 0.6922981095314026, "training_acc": 53.0, "val_loss": 0.6925362515449524, "val_acc": 52.0}
