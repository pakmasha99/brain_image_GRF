"main_modify.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option BT_org --learning_rate 1e-4 --batch_size 16 --weight_decay 1e-2 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 0.6928657722473145, "training_acc": 53.0, "val_loss": 0.692578809261322, "val_acc": 52.0}
{"epoch": 1, "training_loss": 0.6917621803283691, "training_acc": 53.0, "val_loss": 0.6925399374961853, "val_acc": 52.0}
{"epoch": 2, "training_loss": 0.6916800308227539, "training_acc": 53.0, "val_loss": 0.6925619983673096, "val_acc": 52.0}
{"epoch": 3, "training_loss": 0.6916646218299866, "training_acc": 53.0, "val_loss": 0.6924128270149231, "val_acc": 52.0}
{"epoch": 4, "training_loss": 0.6946712327003479, "training_acc": 53.0, "val_loss": 0.6928090953826904, "val_acc": 52.0}
{"epoch": 5, "training_loss": 0.6919607877731323, "training_acc": 53.0, "val_loss": 0.6924188661575318, "val_acc": 52.0}
{"epoch": 6, "training_loss": 0.691788580417633, "training_acc": 53.0, "val_loss": 0.692421600818634, "val_acc": 52.0}
{"epoch": 7, "training_loss": 0.6925152730941773, "training_acc": 53.0, "val_loss": 0.6928966116905212, "val_acc": 52.0}
{"epoch": 8, "training_loss": 0.6916038393974304, "training_acc": 53.0, "val_loss": 0.6930732083320618, "val_acc": 52.0}
{"epoch": 9, "training_loss": 0.6916617250442505, "training_acc": 53.0, "val_loss": 0.6928051710128784, "val_acc": 52.0}
{"epoch": 10, "training_loss": 0.6915450000762939, "training_acc": 53.0, "val_loss": 0.6929186701774597, "val_acc": 52.0}
{"epoch": 11, "training_loss": 0.6916888332366944, "training_acc": 53.0, "val_loss": 0.692868824005127, "val_acc": 52.0}
{"epoch": 12, "training_loss": 0.6916578078269958, "training_acc": 53.0, "val_loss": 0.692818729877472, "val_acc": 52.0}
{"epoch": 13, "training_loss": 0.6919825124740601, "training_acc": 53.0, "val_loss": 0.6937582135200501, "val_acc": 52.0}
{"epoch": 14, "training_loss": 0.694471697807312, "training_acc": 53.0, "val_loss": 0.694267361164093, "val_acc": 52.0}
{"epoch": 15, "training_loss": 0.692235038280487, "training_acc": 53.0, "val_loss": 0.6926641631126403, "val_acc": 52.0}
{"epoch": 16, "training_loss": 0.6914656734466553, "training_acc": 53.0, "val_loss": 0.6923974537849427, "val_acc": 52.0}
{"epoch": 17, "training_loss": 0.6923055553436279, "training_acc": 53.0, "val_loss": 0.6924838280677795, "val_acc": 52.0}
{"epoch": 18, "training_loss": 0.6922864770889282, "training_acc": 53.0, "val_loss": 0.6924773454666138, "val_acc": 52.0}
{"epoch": 19, "training_loss": 0.6915493249893189, "training_acc": 53.0, "val_loss": 0.6924389719963073, "val_acc": 52.0}
{"epoch": 20, "training_loss": 0.6907448720932007, "training_acc": 53.0, "val_loss": 0.6930518651008606, "val_acc": 52.0}
{"epoch": 21, "training_loss": 0.6931501102447509, "training_acc": 53.0, "val_loss": 0.6942925667762756, "val_acc": 52.0}
{"epoch": 22, "training_loss": 0.6924121570587158, "training_acc": 53.0, "val_loss": 0.693601815700531, "val_acc": 52.0}
{"epoch": 23, "training_loss": 0.6920625114440918, "training_acc": 53.0, "val_loss": 0.6934945797920227, "val_acc": 52.0}
{"epoch": 24, "training_loss": 0.6926052808761597, "training_acc": 53.0, "val_loss": 0.6924769687652588, "val_acc": 52.0}
{"epoch": 25, "training_loss": 0.6920956802368164, "training_acc": 53.0, "val_loss": 0.692390947341919, "val_acc": 52.0}
{"epoch": 26, "training_loss": 0.6921604347229003, "training_acc": 53.0, "val_loss": 0.6925785160064697, "val_acc": 52.0}
{"epoch": 27, "training_loss": 0.6946859812736511, "training_acc": 41.0, "val_loss": 0.6935351276397705, "val_acc": 48.0}
{"epoch": 28, "training_loss": 0.6932760810852051, "training_acc": 53.0, "val_loss": 0.692692551612854, "val_acc": 52.0}
{"epoch": 29, "training_loss": 0.6923291444778442, "training_acc": 53.0, "val_loss": 0.6924621486663818, "val_acc": 52.0}
{"epoch": 30, "training_loss": 0.6921389365196228, "training_acc": 53.0, "val_loss": 0.6924064564704895, "val_acc": 52.0}
{"epoch": 31, "training_loss": 0.6931852650642395, "training_acc": 53.0, "val_loss": 0.6924848246574402, "val_acc": 52.0}
{"epoch": 32, "training_loss": 0.6914808464050293, "training_acc": 53.0, "val_loss": 0.6923923993110657, "val_acc": 52.0}
{"epoch": 33, "training_loss": 0.6917061471939087, "training_acc": 53.0, "val_loss": 0.6923914456367493, "val_acc": 52.0}
{"epoch": 34, "training_loss": 0.6942317152023315, "training_acc": 53.0, "val_loss": 0.6927060317993164, "val_acc": 52.0}
{"epoch": 35, "training_loss": 0.691796293258667, "training_acc": 53.0, "val_loss": 0.6924241185188293, "val_acc": 52.0}
{"epoch": 36, "training_loss": 0.6921365404129028, "training_acc": 53.0, "val_loss": 0.6923917675018311, "val_acc": 52.0}
{"epoch": 37, "training_loss": 0.6920633244514466, "training_acc": 53.0, "val_loss": 0.6926360774040222, "val_acc": 52.0}
{"epoch": 38, "training_loss": 0.6914493489265442, "training_acc": 53.0, "val_loss": 0.6928210210800171, "val_acc": 52.0}
{"epoch": 39, "training_loss": 0.6936940526962281, "training_acc": 53.0, "val_loss": 0.6934162282943725, "val_acc": 52.0}
{"epoch": 40, "training_loss": 0.6909480237960816, "training_acc": 53.0, "val_loss": 0.6924566960334778, "val_acc": 52.0}
{"epoch": 41, "training_loss": 0.6912258863449097, "training_acc": 53.0, "val_loss": 0.6923903369903565, "val_acc": 52.0}
{"epoch": 42, "training_loss": 0.6917374038696289, "training_acc": 53.0, "val_loss": 0.6925882840156555, "val_acc": 52.0}
{"epoch": 43, "training_loss": 0.6925092315673829, "training_acc": 53.0, "val_loss": 0.6924145555496216, "val_acc": 52.0}
{"epoch": 44, "training_loss": 0.6919630002975464, "training_acc": 53.0, "val_loss": 0.6924169301986695, "val_acc": 52.0}
{"epoch": 45, "training_loss": 0.6916268825531006, "training_acc": 53.0, "val_loss": 0.6923952078819275, "val_acc": 52.0}
{"epoch": 46, "training_loss": 0.6917246961593628, "training_acc": 53.0, "val_loss": 0.6924868822097778, "val_acc": 52.0}
{"epoch": 47, "training_loss": 0.6921081209182739, "training_acc": 53.0, "val_loss": 0.6924085807800293, "val_acc": 52.0}
{"epoch": 48, "training_loss": 0.6920510625839233, "training_acc": 53.0, "val_loss": 0.6924051284790039, "val_acc": 52.0}
{"epoch": 49, "training_loss": 0.6921024131774902, "training_acc": 53.0, "val_loss": 0.6924362540245056, "val_acc": 52.0}
{"epoch": 50, "training_loss": 0.6925851631164551, "training_acc": 53.0, "val_loss": 0.6923939824104309, "val_acc": 52.0}
{"epoch": 51, "training_loss": 0.6936924171447754, "training_acc": 53.0, "val_loss": 0.6927314376831055, "val_acc": 52.0}
{"epoch": 52, "training_loss": 0.6924470663070679, "training_acc": 53.0, "val_loss": 0.6927701616287232, "val_acc": 52.0}
{"epoch": 53, "training_loss": 0.6930282020568848, "training_acc": 53.0, "val_loss": 0.6926056504249573, "val_acc": 52.0}
{"epoch": 54, "training_loss": 0.6921672010421753, "training_acc": 53.0, "val_loss": 0.6923953175544739, "val_acc": 52.0}
{"epoch": 55, "training_loss": 0.6923588585853576, "training_acc": 53.0, "val_loss": 0.692602858543396, "val_acc": 52.0}
{"epoch": 56, "training_loss": 0.6919916296005248, "training_acc": 53.0, "val_loss": 0.6924085354804993, "val_acc": 52.0}
{"epoch": 57, "training_loss": 0.6918652105331421, "training_acc": 53.0, "val_loss": 0.6924618124961853, "val_acc": 52.0}
{"epoch": 58, "training_loss": 0.6918030381202698, "training_acc": 53.0, "val_loss": 0.6928031754493713, "val_acc": 52.0}
{"epoch": 59, "training_loss": 0.692394666671753, "training_acc": 53.0, "val_loss": 0.6938243985176087, "val_acc": 52.0}
{"epoch": 60, "training_loss": 0.6916449666023254, "training_acc": 53.0, "val_loss": 0.6934254431724548, "val_acc": 52.0}
