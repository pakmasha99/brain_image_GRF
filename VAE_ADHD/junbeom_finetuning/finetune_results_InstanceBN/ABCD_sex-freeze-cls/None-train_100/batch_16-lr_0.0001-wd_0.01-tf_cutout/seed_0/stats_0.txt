"main_modify.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option BT_org --learning_rate 1e-4 --batch_size 16 --weight_decay 1e-2 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 0.6932760620117188, "training_acc": 52.0, "val_loss": 0.6897074460983277, "val_acc": 56.0}
{"epoch": 1, "training_loss": 0.6926347494125367, "training_acc": 52.0, "val_loss": 0.6890915274620056, "val_acc": 56.0}
{"epoch": 2, "training_loss": 0.6927469372749329, "training_acc": 52.0, "val_loss": 0.6892147064208984, "val_acc": 56.0}
{"epoch": 3, "training_loss": 0.6931182384490967, "training_acc": 52.0, "val_loss": 0.6877621507644653, "val_acc": 56.0}
{"epoch": 4, "training_loss": 0.6930714607238769, "training_acc": 52.0, "val_loss": 0.6887674593925476, "val_acc": 56.0}
{"epoch": 5, "training_loss": 0.6926507329940796, "training_acc": 52.0, "val_loss": 0.6882596898078919, "val_acc": 56.0}
{"epoch": 6, "training_loss": 0.6927135515213013, "training_acc": 52.0, "val_loss": 0.6882951378822326, "val_acc": 56.0}
{"epoch": 7, "training_loss": 0.6928093075752259, "training_acc": 52.0, "val_loss": 0.6892026233673095, "val_acc": 56.0}
{"epoch": 8, "training_loss": 0.6931154155731201, "training_acc": 52.0, "val_loss": 0.688446729183197, "val_acc": 56.0}
{"epoch": 9, "training_loss": 0.6927058768272399, "training_acc": 52.0, "val_loss": 0.6895084619522095, "val_acc": 56.0}
{"epoch": 10, "training_loss": 0.6925811386108398, "training_acc": 52.0, "val_loss": 0.691912579536438, "val_acc": 56.0}
{"epoch": 11, "training_loss": 0.692748110294342, "training_acc": 52.0, "val_loss": 0.6911274361610412, "val_acc": 56.0}
{"epoch": 12, "training_loss": 0.6945157098770142, "training_acc": 52.0, "val_loss": 0.6878500199317932, "val_acc": 56.0}
{"epoch": 13, "training_loss": 0.6924909591674805, "training_acc": 52.0, "val_loss": 0.6875838065147399, "val_acc": 56.0}
{"epoch": 14, "training_loss": 0.6929773283004761, "training_acc": 52.0, "val_loss": 0.6870101237297058, "val_acc": 56.0}
{"epoch": 15, "training_loss": 0.6929686427116394, "training_acc": 52.0, "val_loss": 0.6871867871284485, "val_acc": 56.0}
{"epoch": 16, "training_loss": 0.6940325760841369, "training_acc": 52.0, "val_loss": 0.6862909150123596, "val_acc": 56.0}
{"epoch": 17, "training_loss": 0.6933332991600036, "training_acc": 52.0, "val_loss": 0.6873524188995361, "val_acc": 56.0}
{"epoch": 18, "training_loss": 0.6923137283325196, "training_acc": 52.0, "val_loss": 0.6894229960441589, "val_acc": 56.0}
{"epoch": 19, "training_loss": 0.693362410068512, "training_acc": 52.0, "val_loss": 0.6921161651611328, "val_acc": 56.0}
{"epoch": 20, "training_loss": 0.6928842067718506, "training_acc": 52.0, "val_loss": 0.69157470703125, "val_acc": 56.0}
{"epoch": 21, "training_loss": 0.6927751588821411, "training_acc": 52.0, "val_loss": 0.6910141563415527, "val_acc": 56.0}
{"epoch": 22, "training_loss": 0.6935007572174072, "training_acc": 52.0, "val_loss": 0.6894247937202453, "val_acc": 56.0}
{"epoch": 23, "training_loss": 0.6923327016830444, "training_acc": 52.0, "val_loss": 0.6894703006744385, "val_acc": 56.0}
{"epoch": 24, "training_loss": 0.6935693979263305, "training_acc": 52.0, "val_loss": 0.6878810977935791, "val_acc": 56.0}
{"epoch": 25, "training_loss": 0.69249671459198, "training_acc": 52.0, "val_loss": 0.6886243605613709, "val_acc": 56.0}
{"epoch": 26, "training_loss": 0.6933241701126098, "training_acc": 52.0, "val_loss": 0.688766028881073, "val_acc": 56.0}
{"epoch": 27, "training_loss": 0.6926720190048218, "training_acc": 52.0, "val_loss": 0.6896952486038208, "val_acc": 56.0}
{"epoch": 28, "training_loss": 0.6927925491333008, "training_acc": 52.0, "val_loss": 0.6899355340003968, "val_acc": 56.0}
{"epoch": 29, "training_loss": 0.6924157452583313, "training_acc": 52.0, "val_loss": 0.6887397766113281, "val_acc": 56.0}
{"epoch": 30, "training_loss": 0.6941010570526123, "training_acc": 52.0, "val_loss": 0.6866541433334351, "val_acc": 56.0}
{"epoch": 31, "training_loss": 0.6931083488464356, "training_acc": 52.0, "val_loss": 0.686339111328125, "val_acc": 56.0}
{"epoch": 32, "training_loss": 0.6943134880065918, "training_acc": 52.0, "val_loss": 0.6858346056938172, "val_acc": 56.0}
{"epoch": 33, "training_loss": 0.6951603221893311, "training_acc": 52.0, "val_loss": 0.6858470797538757, "val_acc": 56.0}
{"epoch": 34, "training_loss": 0.6942753720283509, "training_acc": 52.0, "val_loss": 0.6865104103088379, "val_acc": 56.0}
{"epoch": 35, "training_loss": 0.6929884767532348, "training_acc": 52.0, "val_loss": 0.6886019229888916, "val_acc": 56.0}
{"epoch": 36, "training_loss": 0.6925823211669921, "training_acc": 52.0, "val_loss": 0.6892597961425782, "val_acc": 56.0}
{"epoch": 37, "training_loss": 0.692627637386322, "training_acc": 52.0, "val_loss": 0.6888615775108338, "val_acc": 56.0}
{"epoch": 38, "training_loss": 0.6929542708396912, "training_acc": 52.0, "val_loss": 0.6893344569206238, "val_acc": 56.0}
{"epoch": 39, "training_loss": 0.6925630831718445, "training_acc": 52.0, "val_loss": 0.6897366213798523, "val_acc": 56.0}
{"epoch": 40, "training_loss": 0.6930979800224304, "training_acc": 52.0, "val_loss": 0.6911778569221496, "val_acc": 56.0}
{"epoch": 41, "training_loss": 0.6927177238464356, "training_acc": 52.0, "val_loss": 0.6906566619873047, "val_acc": 56.0}
{"epoch": 42, "training_loss": 0.69294114112854, "training_acc": 52.0, "val_loss": 0.6901362228393555, "val_acc": 56.0}
{"epoch": 43, "training_loss": 0.6930038714408875, "training_acc": 52.0, "val_loss": 0.6898121619224549, "val_acc": 56.0}
{"epoch": 44, "training_loss": 0.6932377529144287, "training_acc": 52.0, "val_loss": 0.6917990469932556, "val_acc": 56.0}
{"epoch": 45, "training_loss": 0.6927368545532226, "training_acc": 52.0, "val_loss": 0.6915529584884643, "val_acc": 56.0}
{"epoch": 46, "training_loss": 0.6927739024162293, "training_acc": 52.0, "val_loss": 0.6907408881187439, "val_acc": 56.0}
{"epoch": 47, "training_loss": 0.6925437498092651, "training_acc": 52.0, "val_loss": 0.6893864226341248, "val_acc": 56.0}
{"epoch": 48, "training_loss": 0.6927257156372071, "training_acc": 52.0, "val_loss": 0.688445246219635, "val_acc": 56.0}
{"epoch": 49, "training_loss": 0.6922378444671631, "training_acc": 52.0, "val_loss": 0.6890604209899902, "val_acc": 56.0}
{"epoch": 50, "training_loss": 0.6925144767761231, "training_acc": 52.0, "val_loss": 0.6912495732307434, "val_acc": 56.0}
{"epoch": 51, "training_loss": 0.6925641655921936, "training_acc": 52.0, "val_loss": 0.6933949017524719, "val_acc": 44.0}
