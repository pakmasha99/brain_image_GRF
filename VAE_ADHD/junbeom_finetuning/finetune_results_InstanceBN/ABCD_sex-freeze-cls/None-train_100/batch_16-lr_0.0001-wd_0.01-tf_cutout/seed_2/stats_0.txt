"main_modify.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 2 --task ABCD_sex --input_option BT_org --learning_rate 1e-4 --batch_size 16 --weight_decay 1e-2 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 0.6939742207527161, "training_acc": 53.0, "val_loss": 0.6945695948600769, "val_acc": 52.0}
{"epoch": 1, "training_loss": 0.6932395768165588, "training_acc": 53.0, "val_loss": 0.6936135053634643, "val_acc": 52.0}
{"epoch": 2, "training_loss": 0.6926569509506225, "training_acc": 53.0, "val_loss": 0.6924875569343567, "val_acc": 52.0}
{"epoch": 3, "training_loss": 0.6919413518905639, "training_acc": 53.0, "val_loss": 0.6924389934539795, "val_acc": 52.0}
{"epoch": 4, "training_loss": 0.6913355922698975, "training_acc": 53.0, "val_loss": 0.6928511166572571, "val_acc": 52.0}
{"epoch": 5, "training_loss": 0.6918001413345337, "training_acc": 53.0, "val_loss": 0.693072862625122, "val_acc": 52.0}
{"epoch": 6, "training_loss": 0.6928209495544434, "training_acc": 53.0, "val_loss": 0.6923522973060607, "val_acc": 52.0}
{"epoch": 7, "training_loss": 0.6921785306930542, "training_acc": 53.0, "val_loss": 0.6926244688034058, "val_acc": 52.0}
{"epoch": 8, "training_loss": 0.6917678451538086, "training_acc": 53.0, "val_loss": 0.6923754119873047, "val_acc": 52.0}
{"epoch": 9, "training_loss": 0.6913418960571289, "training_acc": 53.0, "val_loss": 0.6922884488105774, "val_acc": 52.0}
{"epoch": 10, "training_loss": 0.6915118050575256, "training_acc": 53.0, "val_loss": 0.6923772382736206, "val_acc": 52.0}
{"epoch": 11, "training_loss": 0.6915298223495483, "training_acc": 53.0, "val_loss": 0.6923655033111572, "val_acc": 52.0}
{"epoch": 12, "training_loss": 0.6915530610084534, "training_acc": 53.0, "val_loss": 0.6925678086280823, "val_acc": 52.0}
{"epoch": 13, "training_loss": 0.6915509724617004, "training_acc": 53.0, "val_loss": 0.6927759575843812, "val_acc": 52.0}
{"epoch": 14, "training_loss": 0.6916088366508484, "training_acc": 53.0, "val_loss": 0.6928469872474671, "val_acc": 52.0}
{"epoch": 15, "training_loss": 0.6913856482505798, "training_acc": 53.0, "val_loss": 0.6931267642974853, "val_acc": 52.0}
{"epoch": 16, "training_loss": 0.6916634893417358, "training_acc": 53.0, "val_loss": 0.6929964470863342, "val_acc": 52.0}
{"epoch": 17, "training_loss": 0.6916657161712646, "training_acc": 53.0, "val_loss": 0.6926955795288086, "val_acc": 52.0}
{"epoch": 18, "training_loss": 0.6931415271759033, "training_acc": 53.0, "val_loss": 0.6935041093826294, "val_acc": 52.0}
{"epoch": 19, "training_loss": 0.6921449518203735, "training_acc": 53.0, "val_loss": 0.6933583498001099, "val_acc": 52.0}
{"epoch": 20, "training_loss": 0.6919758796691895, "training_acc": 53.0, "val_loss": 0.6929554033279419, "val_acc": 52.0}
{"epoch": 21, "training_loss": 0.6911111831665039, "training_acc": 53.0, "val_loss": 0.692431652545929, "val_acc": 52.0}
{"epoch": 22, "training_loss": 0.6933545541763305, "training_acc": 53.0, "val_loss": 0.6924621987342835, "val_acc": 52.0}
{"epoch": 23, "training_loss": 0.692342824935913, "training_acc": 53.0, "val_loss": 0.6923705983161926, "val_acc": 52.0}
{"epoch": 24, "training_loss": 0.6923406028747559, "training_acc": 53.0, "val_loss": 0.6922737860679626, "val_acc": 52.0}
{"epoch": 25, "training_loss": 0.6920922946929932, "training_acc": 53.0, "val_loss": 0.6922620415687561, "val_acc": 52.0}
{"epoch": 26, "training_loss": 0.6906588315963745, "training_acc": 53.0, "val_loss": 0.692737500667572, "val_acc": 52.0}
{"epoch": 27, "training_loss": 0.6911822080612182, "training_acc": 53.0, "val_loss": 0.6938119626045227, "val_acc": 52.0}
{"epoch": 28, "training_loss": 0.6947060489654541, "training_acc": 53.0, "val_loss": 0.6957306814193726, "val_acc": 52.0}
{"epoch": 29, "training_loss": 0.6927984976768493, "training_acc": 53.0, "val_loss": 0.69384605884552, "val_acc": 52.0}
{"epoch": 30, "training_loss": 0.6920028042793274, "training_acc": 53.0, "val_loss": 0.6932946467399597, "val_acc": 52.0}
{"epoch": 31, "training_loss": 0.6922234416007995, "training_acc": 53.0, "val_loss": 0.6925389099121094, "val_acc": 52.0}
{"epoch": 32, "training_loss": 0.691556568145752, "training_acc": 53.0, "val_loss": 0.6923855137825012, "val_acc": 52.0}
{"epoch": 33, "training_loss": 0.6916083216667175, "training_acc": 53.0, "val_loss": 0.6924858593940735, "val_acc": 52.0}
{"epoch": 34, "training_loss": 0.6907233810424804, "training_acc": 53.0, "val_loss": 0.6936680340766906, "val_acc": 52.0}
{"epoch": 35, "training_loss": 0.6931527900695801, "training_acc": 53.0, "val_loss": 0.6952947664260865, "val_acc": 52.0}
{"epoch": 36, "training_loss": 0.6932685685157776, "training_acc": 53.0, "val_loss": 0.6945788383483886, "val_acc": 52.0}
{"epoch": 37, "training_loss": 0.6917512202262879, "training_acc": 53.0, "val_loss": 0.6929157423973084, "val_acc": 52.0}
{"epoch": 38, "training_loss": 0.6902885150909424, "training_acc": 53.0, "val_loss": 0.6923033809661865, "val_acc": 52.0}
{"epoch": 39, "training_loss": 0.6931260204315186, "training_acc": 53.0, "val_loss": 0.6926351666450501, "val_acc": 52.0}
{"epoch": 40, "training_loss": 0.6930700635910034, "training_acc": 53.0, "val_loss": 0.692747311592102, "val_acc": 52.0}
{"epoch": 41, "training_loss": 0.6923803114891052, "training_acc": 53.0, "val_loss": 0.6922597885131836, "val_acc": 52.0}
{"epoch": 42, "training_loss": 0.6913979053497314, "training_acc": 53.0, "val_loss": 0.6923216724395752, "val_acc": 52.0}
{"epoch": 43, "training_loss": 0.6916745615005493, "training_acc": 53.0, "val_loss": 0.6924975180625915, "val_acc": 52.0}
{"epoch": 44, "training_loss": 0.6916909408569336, "training_acc": 53.0, "val_loss": 0.69241938829422, "val_acc": 52.0}
{"epoch": 45, "training_loss": 0.6916779804229737, "training_acc": 53.0, "val_loss": 0.6922688794136047, "val_acc": 52.0}
{"epoch": 46, "training_loss": 0.6918606352806091, "training_acc": 53.0, "val_loss": 0.6922615027427673, "val_acc": 52.0}
{"epoch": 47, "training_loss": 0.6916725897789001, "training_acc": 53.0, "val_loss": 0.6922945833206177, "val_acc": 52.0}
{"epoch": 48, "training_loss": 0.6915612363815308, "training_acc": 53.0, "val_loss": 0.6925857734680175, "val_acc": 52.0}
{"epoch": 49, "training_loss": 0.6913136053085327, "training_acc": 53.0, "val_loss": 0.692391517162323, "val_acc": 52.0}
{"epoch": 50, "training_loss": 0.6925836062431335, "training_acc": 53.0, "val_loss": 0.6922646784782409, "val_acc": 52.0}
{"epoch": 51, "training_loss": 0.6927461099624633, "training_acc": 53.0, "val_loss": 0.692683482170105, "val_acc": 52.0}
{"epoch": 52, "training_loss": 0.6915576124191284, "training_acc": 53.0, "val_loss": 0.69265949010849, "val_acc": 52.0}
{"epoch": 53, "training_loss": 0.6931231379508972, "training_acc": 53.0, "val_loss": 0.6922611355781555, "val_acc": 52.0}
{"epoch": 54, "training_loss": 0.6919160604476928, "training_acc": 53.0, "val_loss": 0.6922579503059387, "val_acc": 52.0}
{"epoch": 55, "training_loss": 0.6915389204025268, "training_acc": 53.0, "val_loss": 0.6922685933113099, "val_acc": 52.0}
{"epoch": 56, "training_loss": 0.6917271137237548, "training_acc": 53.0, "val_loss": 0.6922953009605408, "val_acc": 52.0}
{"epoch": 57, "training_loss": 0.6917820978164673, "training_acc": 53.0, "val_loss": 0.692425389289856, "val_acc": 52.0}
{"epoch": 58, "training_loss": 0.6916461420059205, "training_acc": 53.0, "val_loss": 0.6923580360412598, "val_acc": 52.0}
{"epoch": 59, "training_loss": 0.6928979539871216, "training_acc": 53.0, "val_loss": 0.6929921770095825, "val_acc": 52.0}
{"epoch": 60, "training_loss": 0.6932041716575622, "training_acc": 53.0, "val_loss": 0.6938973784446716, "val_acc": 52.0}
{"epoch": 61, "training_loss": 0.6923368525505066, "training_acc": 53.0, "val_loss": 0.6934758615493775, "val_acc": 52.0}
{"epoch": 62, "training_loss": 0.6923136520385742, "training_acc": 53.0, "val_loss": 0.692326946258545, "val_acc": 52.0}
{"epoch": 63, "training_loss": 0.6909973001480103, "training_acc": 53.0, "val_loss": 0.6925038242340088, "val_acc": 52.0}
{"epoch": 64, "training_loss": 0.6925736141204833, "training_acc": 53.0, "val_loss": 0.6924397206306457, "val_acc": 52.0}
{"epoch": 65, "training_loss": 0.6931777667999267, "training_acc": 44.0, "val_loss": 0.6931327176094055, "val_acc": 48.0}
{"epoch": 66, "training_loss": 0.693315908908844, "training_acc": 50.0, "val_loss": 0.6924627590179443, "val_acc": 52.0}
{"epoch": 67, "training_loss": 0.6936992311477661, "training_acc": 53.0, "val_loss": 0.6924179840087891, "val_acc": 52.0}
{"epoch": 68, "training_loss": 0.6913994932174683, "training_acc": 53.0, "val_loss": 0.692362174987793, "val_acc": 52.0}
{"epoch": 69, "training_loss": 0.6915687417984009, "training_acc": 53.0, "val_loss": 0.6923429799079895, "val_acc": 52.0}
{"epoch": 70, "training_loss": 0.6916960549354553, "training_acc": 53.0, "val_loss": 0.6922843503952026, "val_acc": 52.0}
{"epoch": 71, "training_loss": 0.6924758672714233, "training_acc": 53.0, "val_loss": 0.6924676060676574, "val_acc": 52.0}
{"epoch": 72, "training_loss": 0.6913650369644165, "training_acc": 53.0, "val_loss": 0.6923634266853332, "val_acc": 52.0}
{"epoch": 73, "training_loss": 0.6908994436264038, "training_acc": 53.0, "val_loss": 0.6923431372642517, "val_acc": 52.0}
