"main_modify.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 1 --task ABCD_sex --input_option BT_org --learning_rate 1e-4 --batch_size 16 --weight_decay 1e-2 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 0.6932563495635986, "training_acc": 53.0, "val_loss": 0.6923504734039306, "val_acc": 52.0}
{"epoch": 1, "training_loss": 0.6912288570404053, "training_acc": 53.0, "val_loss": 0.69272873878479, "val_acc": 52.0}
{"epoch": 2, "training_loss": 0.6914970135688782, "training_acc": 53.0, "val_loss": 0.6929535365104675, "val_acc": 52.0}
{"epoch": 3, "training_loss": 0.6920102787017822, "training_acc": 53.0, "val_loss": 0.6930437779426575, "val_acc": 52.0}
{"epoch": 4, "training_loss": 0.691508948802948, "training_acc": 53.0, "val_loss": 0.6930957388877869, "val_acc": 52.0}
{"epoch": 5, "training_loss": 0.6917413210868836, "training_acc": 53.0, "val_loss": 0.6928973007202148, "val_acc": 52.0}
{"epoch": 6, "training_loss": 0.6920350122451783, "training_acc": 53.0, "val_loss": 0.6924143624305725, "val_acc": 52.0}
{"epoch": 7, "training_loss": 0.6914985823631287, "training_acc": 53.0, "val_loss": 0.6924015855789185, "val_acc": 52.0}
{"epoch": 8, "training_loss": 0.6915520668029785, "training_acc": 53.0, "val_loss": 0.6926078844070435, "val_acc": 52.0}
{"epoch": 9, "training_loss": 0.6918579435348511, "training_acc": 53.0, "val_loss": 0.6936162972450256, "val_acc": 52.0}
{"epoch": 10, "training_loss": 0.6916465187072753, "training_acc": 53.0, "val_loss": 0.6932304883003235, "val_acc": 52.0}
{"epoch": 11, "training_loss": 0.6913976120948792, "training_acc": 53.0, "val_loss": 0.6927246832847596, "val_acc": 52.0}
{"epoch": 12, "training_loss": 0.6937052512168884, "training_acc": 53.0, "val_loss": 0.6923495936393738, "val_acc": 52.0}
{"epoch": 13, "training_loss": 0.6934584259986878, "training_acc": 53.0, "val_loss": 0.6928255033493042, "val_acc": 52.0}
{"epoch": 14, "training_loss": 0.6924073958396911, "training_acc": 53.0, "val_loss": 0.6930609846115112, "val_acc": 52.0}
{"epoch": 15, "training_loss": 0.6912839579582214, "training_acc": 53.0, "val_loss": 0.6926032876968384, "val_acc": 52.0}
{"epoch": 16, "training_loss": 0.691141493320465, "training_acc": 53.0, "val_loss": 0.6923480677604675, "val_acc": 52.0}
{"epoch": 17, "training_loss": 0.6924202299118042, "training_acc": 53.0, "val_loss": 0.6925919795036316, "val_acc": 52.0}
{"epoch": 18, "training_loss": 0.6923838710784912, "training_acc": 53.0, "val_loss": 0.6923843312263489, "val_acc": 52.0}
{"epoch": 19, "training_loss": 0.6921287322044373, "training_acc": 53.0, "val_loss": 0.6926733779907227, "val_acc": 52.0}
{"epoch": 20, "training_loss": 0.6921176838874817, "training_acc": 53.0, "val_loss": 0.6924969863891601, "val_acc": 52.0}
{"epoch": 21, "training_loss": 0.6922743892669678, "training_acc": 53.0, "val_loss": 0.6923480176925659, "val_acc": 52.0}
{"epoch": 22, "training_loss": 0.692039566040039, "training_acc": 53.0, "val_loss": 0.6923909854888916, "val_acc": 52.0}
{"epoch": 23, "training_loss": 0.691678261756897, "training_acc": 53.0, "val_loss": 0.6923647046089172, "val_acc": 52.0}
{"epoch": 24, "training_loss": 0.6922872734069824, "training_acc": 53.0, "val_loss": 0.6923686718940735, "val_acc": 52.0}
{"epoch": 25, "training_loss": 0.6919579839706421, "training_acc": 53.0, "val_loss": 0.6923693203926087, "val_acc": 52.0}
{"epoch": 26, "training_loss": 0.6915861058235169, "training_acc": 53.0, "val_loss": 0.692420415878296, "val_acc": 52.0}
{"epoch": 27, "training_loss": 0.6936316514015197, "training_acc": 53.0, "val_loss": 0.6928799033164978, "val_acc": 52.0}
{"epoch": 28, "training_loss": 0.6916295576095581, "training_acc": 53.0, "val_loss": 0.6926484680175782, "val_acc": 52.0}
{"epoch": 29, "training_loss": 0.6920190525054931, "training_acc": 53.0, "val_loss": 0.6926580476760864, "val_acc": 52.0}
{"epoch": 30, "training_loss": 0.6917281770706176, "training_acc": 53.0, "val_loss": 0.6926600360870361, "val_acc": 52.0}
{"epoch": 31, "training_loss": 0.6915859127044678, "training_acc": 53.0, "val_loss": 0.6926503300666809, "val_acc": 52.0}
{"epoch": 32, "training_loss": 0.6923830056190491, "training_acc": 53.0, "val_loss": 0.6931286668777465, "val_acc": 52.0}
{"epoch": 33, "training_loss": 0.6924756002426148, "training_acc": 53.0, "val_loss": 0.692497751712799, "val_acc": 52.0}
{"epoch": 34, "training_loss": 0.691326265335083, "training_acc": 53.0, "val_loss": 0.6925571775436401, "val_acc": 52.0}
{"epoch": 35, "training_loss": 0.6925617337226868, "training_acc": 53.0, "val_loss": 0.6923617506027222, "val_acc": 52.0}
{"epoch": 36, "training_loss": 0.6914873600006104, "training_acc": 53.0, "val_loss": 0.692484040260315, "val_acc": 52.0}
{"epoch": 37, "training_loss": 0.691471951007843, "training_acc": 53.0, "val_loss": 0.6930058383941651, "val_acc": 52.0}
{"epoch": 38, "training_loss": 0.6919437265396118, "training_acc": 53.0, "val_loss": 0.6928049015998841, "val_acc": 52.0}
{"epoch": 39, "training_loss": 0.6921989822387695, "training_acc": 53.0, "val_loss": 0.6926522850990295, "val_acc": 52.0}
{"epoch": 40, "training_loss": 0.6912659931182862, "training_acc": 53.0, "val_loss": 0.6924923276901245, "val_acc": 52.0}
{"epoch": 41, "training_loss": 0.6935202503204345, "training_acc": 53.0, "val_loss": 0.692347366809845, "val_acc": 52.0}
{"epoch": 42, "training_loss": 0.6917422485351562, "training_acc": 53.0, "val_loss": 0.6924262094497681, "val_acc": 52.0}
{"epoch": 43, "training_loss": 0.691885678768158, "training_acc": 53.0, "val_loss": 0.6928381299972535, "val_acc": 52.0}
{"epoch": 44, "training_loss": 0.6918136954307557, "training_acc": 53.0, "val_loss": 0.6929026103019714, "val_acc": 52.0}
{"epoch": 45, "training_loss": 0.6914769434928894, "training_acc": 53.0, "val_loss": 0.6924605298042298, "val_acc": 52.0}
{"epoch": 46, "training_loss": 0.6914909529685974, "training_acc": 53.0, "val_loss": 0.6923820638656616, "val_acc": 52.0}
{"epoch": 47, "training_loss": 0.6921047377586365, "training_acc": 53.0, "val_loss": 0.6923720693588257, "val_acc": 52.0}
{"epoch": 48, "training_loss": 0.6915944290161132, "training_acc": 53.0, "val_loss": 0.6928279304504394, "val_acc": 52.0}
{"epoch": 49, "training_loss": 0.6916631031036377, "training_acc": 53.0, "val_loss": 0.6932504224777222, "val_acc": 52.0}
{"epoch": 50, "training_loss": 0.6921842217445373, "training_acc": 53.0, "val_loss": 0.6942846465110779, "val_acc": 52.0}
{"epoch": 51, "training_loss": 0.6922810745239257, "training_acc": 53.0, "val_loss": 0.6938787245750427, "val_acc": 52.0}
{"epoch": 52, "training_loss": 0.692315764427185, "training_acc": 53.0, "val_loss": 0.6937573003768921, "val_acc": 52.0}
{"epoch": 53, "training_loss": 0.6927369546890259, "training_acc": 53.0, "val_loss": 0.6924742412567139, "val_acc": 52.0}
{"epoch": 54, "training_loss": 0.6918529605865479, "training_acc": 53.0, "val_loss": 0.6924132633209229, "val_acc": 52.0}
{"epoch": 55, "training_loss": 0.692100100517273, "training_acc": 53.0, "val_loss": 0.69240149974823, "val_acc": 52.0}
{"epoch": 56, "training_loss": 0.6920948934555053, "training_acc": 53.0, "val_loss": 0.6923607587814331, "val_acc": 52.0}
{"epoch": 57, "training_loss": 0.6920333194732666, "training_acc": 53.0, "val_loss": 0.6923788690567017, "val_acc": 52.0}
{"epoch": 58, "training_loss": 0.6923014688491821, "training_acc": 53.0, "val_loss": 0.6924176478385925, "val_acc": 52.0}
{"epoch": 59, "training_loss": 0.6912800550460816, "training_acc": 53.0, "val_loss": 0.6925606942176818, "val_acc": 52.0}
{"epoch": 60, "training_loss": 0.6912403011322021, "training_acc": 53.0, "val_loss": 0.6928921175003052, "val_acc": 52.0}
