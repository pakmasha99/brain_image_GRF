"main_modify.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option BT_org --learning_rate 5e-5 --batch_size 16 --weight_decay 5e-2 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 0.6928082418441772, "training_acc": 52.0, "val_loss": 0.6897324967384338, "val_acc": 56.0}
{"epoch": 1, "training_loss": 0.6923963165283203, "training_acc": 52.0, "val_loss": 0.6893529176712037, "val_acc": 56.0}
{"epoch": 2, "training_loss": 0.6924931621551513, "training_acc": 52.0, "val_loss": 0.6893542861938476, "val_acc": 56.0}
{"epoch": 3, "training_loss": 0.6926516652107239, "training_acc": 52.0, "val_loss": 0.6885017561912536, "val_acc": 56.0}
{"epoch": 4, "training_loss": 0.6927415800094604, "training_acc": 52.0, "val_loss": 0.6889439463615418, "val_acc": 56.0}
{"epoch": 5, "training_loss": 0.6925336337089538, "training_acc": 52.0, "val_loss": 0.6885870862007141, "val_acc": 56.0}
{"epoch": 6, "training_loss": 0.6925421595573426, "training_acc": 52.0, "val_loss": 0.6885215497016907, "val_acc": 56.0}
{"epoch": 7, "training_loss": 0.6924641466140747, "training_acc": 52.0, "val_loss": 0.688923351764679, "val_acc": 56.0}
{"epoch": 8, "training_loss": 0.6926825189590454, "training_acc": 52.0, "val_loss": 0.6885384964942932, "val_acc": 56.0}
{"epoch": 9, "training_loss": 0.692451183795929, "training_acc": 52.0, "val_loss": 0.6890547919273377, "val_acc": 56.0}
{"epoch": 10, "training_loss": 0.6923847627639771, "training_acc": 52.0, "val_loss": 0.6902169585227966, "val_acc": 56.0}
{"epoch": 11, "training_loss": 0.6923973894119263, "training_acc": 52.0, "val_loss": 0.6901175618171692, "val_acc": 56.0}
{"epoch": 12, "training_loss": 0.6933472776412963, "training_acc": 52.0, "val_loss": 0.6886294150352478, "val_acc": 56.0}
{"epoch": 13, "training_loss": 0.692321708202362, "training_acc": 52.0, "val_loss": 0.6884511208534241, "val_acc": 56.0}
{"epoch": 14, "training_loss": 0.6925818920135498, "training_acc": 52.0, "val_loss": 0.6879468488693238, "val_acc": 56.0}
{"epoch": 15, "training_loss": 0.69240403175354, "training_acc": 52.0, "val_loss": 0.6878612494468689, "val_acc": 56.0}
{"epoch": 16, "training_loss": 0.6931551599502563, "training_acc": 52.0, "val_loss": 0.6870578098297119, "val_acc": 56.0}
{"epoch": 17, "training_loss": 0.6927504611015319, "training_acc": 52.0, "val_loss": 0.6875232243537903, "val_acc": 56.0}
{"epoch": 18, "training_loss": 0.6924708986282349, "training_acc": 52.0, "val_loss": 0.688352358341217, "val_acc": 56.0}
{"epoch": 19, "training_loss": 0.6927799582481384, "training_acc": 52.0, "val_loss": 0.6895173263549804, "val_acc": 56.0}
{"epoch": 20, "training_loss": 0.6924646306037903, "training_acc": 52.0, "val_loss": 0.6896373867988587, "val_acc": 56.0}
{"epoch": 21, "training_loss": 0.6925713920593262, "training_acc": 52.0, "val_loss": 0.6898090100288391, "val_acc": 56.0}
{"epoch": 22, "training_loss": 0.6928338027000427, "training_acc": 52.0, "val_loss": 0.6893887352943421, "val_acc": 56.0}
{"epoch": 23, "training_loss": 0.6922277379035949, "training_acc": 52.0, "val_loss": 0.6895724987983703, "val_acc": 56.0}
{"epoch": 24, "training_loss": 0.6930293583869934, "training_acc": 52.0, "val_loss": 0.6887293100357056, "val_acc": 56.0}
{"epoch": 25, "training_loss": 0.6923609495162963, "training_acc": 52.0, "val_loss": 0.6890461778640747, "val_acc": 56.0}
{"epoch": 26, "training_loss": 0.6929513669013977, "training_acc": 52.0, "val_loss": 0.6889973902702331, "val_acc": 56.0}
{"epoch": 27, "training_loss": 0.6925561714172364, "training_acc": 52.0, "val_loss": 0.6893700075149536, "val_acc": 56.0}
{"epoch": 28, "training_loss": 0.6925174665451049, "training_acc": 52.0, "val_loss": 0.6894778871536255, "val_acc": 56.0}
{"epoch": 29, "training_loss": 0.6923751044273376, "training_acc": 52.0, "val_loss": 0.6889284253120422, "val_acc": 56.0}
{"epoch": 30, "training_loss": 0.6931179237365722, "training_acc": 52.0, "val_loss": 0.6876521277427673, "val_acc": 56.0}
{"epoch": 31, "training_loss": 0.6923282480239868, "training_acc": 52.0, "val_loss": 0.6872586750984192, "val_acc": 56.0}
{"epoch": 32, "training_loss": 0.6929598665237426, "training_acc": 52.0, "val_loss": 0.6865004825592042, "val_acc": 56.0}
{"epoch": 33, "training_loss": 0.6933425855636597, "training_acc": 52.0, "val_loss": 0.686331217288971, "val_acc": 56.0}
{"epoch": 34, "training_loss": 0.693473732471466, "training_acc": 52.0, "val_loss": 0.6866595268249511, "val_acc": 56.0}
{"epoch": 35, "training_loss": 0.6929350709915161, "training_acc": 52.0, "val_loss": 0.6874457669258117, "val_acc": 56.0}
{"epoch": 36, "training_loss": 0.69270099401474, "training_acc": 52.0, "val_loss": 0.6877429056167602, "val_acc": 56.0}
{"epoch": 37, "training_loss": 0.6927614212036133, "training_acc": 52.0, "val_loss": 0.6877715802192688, "val_acc": 56.0}
{"epoch": 38, "training_loss": 0.6929010534286499, "training_acc": 52.0, "val_loss": 0.6881982398033142, "val_acc": 56.0}
{"epoch": 39, "training_loss": 0.692498300075531, "training_acc": 52.0, "val_loss": 0.6886267948150635, "val_acc": 56.0}
{"epoch": 40, "training_loss": 0.6926616239547729, "training_acc": 52.0, "val_loss": 0.689533360004425, "val_acc": 56.0}
{"epoch": 41, "training_loss": 0.6925001573562622, "training_acc": 52.0, "val_loss": 0.6896528196334839, "val_acc": 56.0}
{"epoch": 42, "training_loss": 0.6925072240829467, "training_acc": 52.0, "val_loss": 0.6896940398216248, "val_acc": 56.0}
{"epoch": 43, "training_loss": 0.6925742530822754, "training_acc": 52.0, "val_loss": 0.6897203397750854, "val_acc": 56.0}
{"epoch": 44, "training_loss": 0.6928303718566895, "training_acc": 52.0, "val_loss": 0.6908030939102173, "val_acc": 56.0}
{"epoch": 45, "training_loss": 0.6924688243865966, "training_acc": 52.0, "val_loss": 0.6908741497993469, "val_acc": 56.0}
{"epoch": 46, "training_loss": 0.6926229524612427, "training_acc": 52.0, "val_loss": 0.6906487941741943, "val_acc": 56.0}
{"epoch": 47, "training_loss": 0.6925235033035279, "training_acc": 52.0, "val_loss": 0.6900198483467102, "val_acc": 56.0}
{"epoch": 48, "training_loss": 0.6924881386756897, "training_acc": 52.0, "val_loss": 0.6894237208366394, "val_acc": 56.0}
{"epoch": 49, "training_loss": 0.6922920846939087, "training_acc": 52.0, "val_loss": 0.6896034669876099, "val_acc": 56.0}
{"epoch": 50, "training_loss": 0.6924126052856445, "training_acc": 52.0, "val_loss": 0.6905587816238403, "val_acc": 56.0}
{"epoch": 51, "training_loss": 0.6923736357688903, "training_acc": 52.0, "val_loss": 0.6915553593635559, "val_acc": 56.0}
{"epoch": 52, "training_loss": 0.6931489086151124, "training_acc": 52.0, "val_loss": 0.6926600933074951, "val_acc": 56.0}
