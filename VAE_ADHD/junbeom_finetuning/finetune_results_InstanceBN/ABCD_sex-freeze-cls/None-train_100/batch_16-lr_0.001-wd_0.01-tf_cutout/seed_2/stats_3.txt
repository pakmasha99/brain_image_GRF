"main_modify.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 2 --task ABCD_sex --input_option BT_org --learning_rate 1e-3 --batch_size 16 --weight_decay 1e-2 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 0.7035071015357971, "training_acc": 49.0, "val_loss": 0.6942760872840882, "val_acc": 48.0}
{"epoch": 1, "training_loss": 0.7050982332229614, "training_acc": 47.0, "val_loss": 0.6924338269233704, "val_acc": 52.0}
{"epoch": 2, "training_loss": 0.7024180102348327, "training_acc": 53.0, "val_loss": 0.7166814947128296, "val_acc": 52.0}
{"epoch": 3, "training_loss": 0.7036352396011353, "training_acc": 53.0, "val_loss": 0.6924127173423767, "val_acc": 52.0}
{"epoch": 4, "training_loss": 0.6935502195358276, "training_acc": 53.0, "val_loss": 0.6924869227409363, "val_acc": 52.0}
{"epoch": 5, "training_loss": 0.6957921266555787, "training_acc": 53.0, "val_loss": 0.6973679661750793, "val_acc": 52.0}
{"epoch": 6, "training_loss": 0.7058302640914917, "training_acc": 53.0, "val_loss": 0.6994350147247315, "val_acc": 52.0}
{"epoch": 7, "training_loss": 0.6985200548171997, "training_acc": 53.0, "val_loss": 0.6925758290290832, "val_acc": 52.0}
{"epoch": 8, "training_loss": 0.6932110500335693, "training_acc": 53.0, "val_loss": 0.692566032409668, "val_acc": 52.0}
{"epoch": 9, "training_loss": 0.6948506784439087, "training_acc": 53.0, "val_loss": 0.6930311226844788, "val_acc": 52.0}
{"epoch": 10, "training_loss": 0.6920003247261047, "training_acc": 53.0, "val_loss": 0.6964016938209534, "val_acc": 52.0}
{"epoch": 11, "training_loss": 0.7002437782287597, "training_acc": 53.0, "val_loss": 0.6937135672569275, "val_acc": 52.0}
{"epoch": 12, "training_loss": 0.7010484457015991, "training_acc": 48.0, "val_loss": 0.6930888199806213, "val_acc": 52.0}
{"epoch": 13, "training_loss": 0.7069784832000733, "training_acc": 53.0, "val_loss": 0.7085792589187622, "val_acc": 52.0}
{"epoch": 14, "training_loss": 0.720571575164795, "training_acc": 45.0, "val_loss": 0.7016015863418579, "val_acc": 48.0}
{"epoch": 15, "training_loss": 0.6963470530509949, "training_acc": 49.0, "val_loss": 0.6985640335083008, "val_acc": 52.0}
{"epoch": 16, "training_loss": 0.6997806000709533, "training_acc": 53.0, "val_loss": 0.6955216813087464, "val_acc": 52.0}
{"epoch": 17, "training_loss": 0.7009749412536621, "training_acc": 45.0, "val_loss": 0.6936882901191711, "val_acc": 48.0}
{"epoch": 18, "training_loss": 0.6994146370887756, "training_acc": 45.0, "val_loss": 0.6958768200874329, "val_acc": 52.0}
{"epoch": 19, "training_loss": 0.6970282506942749, "training_acc": 53.0, "val_loss": 0.6958691716194153, "val_acc": 52.0}
{"epoch": 20, "training_loss": 0.7000137877464294, "training_acc": 53.0, "val_loss": 0.6926170682907105, "val_acc": 52.0}
{"epoch": 21, "training_loss": 0.717820086479187, "training_acc": 47.0, "val_loss": 0.7076820492744446, "val_acc": 48.0}
{"epoch": 22, "training_loss": 0.7024875092506409, "training_acc": 51.0, "val_loss": 0.7066925382614135, "val_acc": 52.0}
{"epoch": 23, "training_loss": 0.6965359687805176, "training_acc": 53.0, "val_loss": 0.6923964190483093, "val_acc": 52.0}
{"epoch": 24, "training_loss": 0.6958453464508056, "training_acc": 45.0, "val_loss": 0.6924153447151185, "val_acc": 52.0}
{"epoch": 25, "training_loss": 0.6956594920158387, "training_acc": 53.0, "val_loss": 0.6933373618125915, "val_acc": 52.0}
{"epoch": 26, "training_loss": 0.6905153608322143, "training_acc": 53.0, "val_loss": 0.6949048662185668, "val_acc": 48.0}
{"epoch": 27, "training_loss": 0.6943768358230591, "training_acc": 51.0, "val_loss": 0.6981375885009765, "val_acc": 52.0}
{"epoch": 28, "training_loss": 0.6967372179031373, "training_acc": 53.0, "val_loss": 0.6951259136199951, "val_acc": 52.0}
{"epoch": 29, "training_loss": 0.6966270923614502, "training_acc": 53.0, "val_loss": 0.6925872683525085, "val_acc": 52.0}
{"epoch": 30, "training_loss": 0.6951601648330689, "training_acc": 53.0, "val_loss": 0.6930342411994934, "val_acc": 52.0}
{"epoch": 31, "training_loss": 0.6939133548736572, "training_acc": 53.0, "val_loss": 0.6948950695991516, "val_acc": 52.0}
{"epoch": 32, "training_loss": 0.6935515308380127, "training_acc": 53.0, "val_loss": 0.6926113128662109, "val_acc": 52.0}
{"epoch": 33, "training_loss": 0.7031669855117798, "training_acc": 53.0, "val_loss": 0.6928327989578247, "val_acc": 52.0}
{"epoch": 34, "training_loss": 0.6929129219055176, "training_acc": 51.0, "val_loss": 0.6948335313796997, "val_acc": 48.0}
{"epoch": 35, "training_loss": 0.6981827187538147, "training_acc": 43.0, "val_loss": 0.6941920351982117, "val_acc": 52.0}
{"epoch": 36, "training_loss": 0.6943765950202941, "training_acc": 53.0, "val_loss": 0.6939389538764954, "val_acc": 52.0}
{"epoch": 37, "training_loss": 0.7050176286697387, "training_acc": 43.0, "val_loss": 0.6979190230369567, "val_acc": 48.0}
{"epoch": 38, "training_loss": 0.6928631114959717, "training_acc": 49.0, "val_loss": 0.6991182708740235, "val_acc": 52.0}
{"epoch": 39, "training_loss": 0.6971667551994324, "training_acc": 53.0, "val_loss": 0.6944596171379089, "val_acc": 52.0}
{"epoch": 40, "training_loss": 0.7000640821456909, "training_acc": 45.0, "val_loss": 0.6950908207893371, "val_acc": 48.0}
{"epoch": 41, "training_loss": 0.6952772665023804, "training_acc": 47.0, "val_loss": 0.6938039469718933, "val_acc": 52.0}
{"epoch": 42, "training_loss": 0.6940942406654358, "training_acc": 53.0, "val_loss": 0.6941068243980407, "val_acc": 52.0}
