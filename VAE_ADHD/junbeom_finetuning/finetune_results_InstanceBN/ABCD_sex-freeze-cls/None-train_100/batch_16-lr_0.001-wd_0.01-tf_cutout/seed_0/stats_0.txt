"main_modify.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option BT_org --learning_rate 1e-3 --batch_size 16 --weight_decay 1e-2 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 0.7093299818038941, "training_acc": 46.0, "val_loss": 0.6966051006317139, "val_acc": 44.0}
{"epoch": 1, "training_loss": 0.6996257185935975, "training_acc": 48.0, "val_loss": 0.6862161064147949, "val_acc": 56.0}
{"epoch": 2, "training_loss": 0.6987181377410888, "training_acc": 44.0, "val_loss": 0.6914568305015564, "val_acc": 56.0}
{"epoch": 3, "training_loss": 0.7027935886383057, "training_acc": 52.0, "val_loss": 0.6865313148498535, "val_acc": 56.0}
{"epoch": 4, "training_loss": 0.7018651413917542, "training_acc": 50.0, "val_loss": 0.7043031644821167, "val_acc": 44.0}
{"epoch": 5, "training_loss": 0.6977103185653687, "training_acc": 49.0, "val_loss": 0.6857944822311401, "val_acc": 56.0}
{"epoch": 6, "training_loss": 0.6965570163726806, "training_acc": 52.0, "val_loss": 0.6871012806892395, "val_acc": 56.0}
{"epoch": 7, "training_loss": 0.701516580581665, "training_acc": 44.0, "val_loss": 0.69670569896698, "val_acc": 44.0}
{"epoch": 8, "training_loss": 0.7071704936027526, "training_acc": 46.0, "val_loss": 0.6858180022239685, "val_acc": 56.0}
{"epoch": 9, "training_loss": 0.6991408491134643, "training_acc": 44.0, "val_loss": 0.7012527465820313, "val_acc": 44.0}
{"epoch": 10, "training_loss": 0.7067101836204529, "training_acc": 48.0, "val_loss": 0.7011304879188538, "val_acc": 44.0}
{"epoch": 11, "training_loss": 0.6925337147712708, "training_acc": 54.0, "val_loss": 0.6892866611480712, "val_acc": 56.0}
{"epoch": 12, "training_loss": 0.7371765971183777, "training_acc": 52.0, "val_loss": 0.6883242058753968, "val_acc": 56.0}
{"epoch": 13, "training_loss": 0.7149412751197814, "training_acc": 46.0, "val_loss": 0.7157523274421692, "val_acc": 44.0}
{"epoch": 14, "training_loss": 0.696395058631897, "training_acc": 52.0, "val_loss": 0.6859703993797303, "val_acc": 56.0}
{"epoch": 15, "training_loss": 0.6972161388397217, "training_acc": 52.0, "val_loss": 0.6858255648612976, "val_acc": 56.0}
{"epoch": 16, "training_loss": 0.7077727079391479, "training_acc": 52.0, "val_loss": 0.6862731909751892, "val_acc": 56.0}
{"epoch": 17, "training_loss": 0.7005771017074585, "training_acc": 48.0, "val_loss": 0.725627269744873, "val_acc": 44.0}
{"epoch": 18, "training_loss": 0.7113940525054931, "training_acc": 48.0, "val_loss": 0.6971799182891846, "val_acc": 44.0}
{"epoch": 19, "training_loss": 0.6951866006851196, "training_acc": 48.0, "val_loss": 0.6862130093574524, "val_acc": 56.0}
{"epoch": 20, "training_loss": 0.697518470287323, "training_acc": 52.0, "val_loss": 0.685776698589325, "val_acc": 56.0}
{"epoch": 21, "training_loss": 0.7004588317871093, "training_acc": 46.0, "val_loss": 0.6955108857154846, "val_acc": 44.0}
{"epoch": 22, "training_loss": 0.7000434017181396, "training_acc": 46.0, "val_loss": 0.6881419372558594, "val_acc": 56.0}
{"epoch": 23, "training_loss": 0.6918035650253296, "training_acc": 54.0, "val_loss": 0.6940360951423645, "val_acc": 44.0}
{"epoch": 24, "training_loss": 0.705634458065033, "training_acc": 48.0, "val_loss": 0.68584627866745, "val_acc": 56.0}
{"epoch": 25, "training_loss": 0.6930836749076843, "training_acc": 48.0, "val_loss": 0.7086918735504151, "val_acc": 44.0}
{"epoch": 26, "training_loss": 0.7093735837936401, "training_acc": 38.0, "val_loss": 0.690122766494751, "val_acc": 56.0}
{"epoch": 27, "training_loss": 0.6955314445495605, "training_acc": 52.0, "val_loss": 0.6906974005699158, "val_acc": 56.0}
{"epoch": 28, "training_loss": 0.6968425035476684, "training_acc": 51.0, "val_loss": 0.6881204319000244, "val_acc": 56.0}
{"epoch": 29, "training_loss": 0.6958549642562866, "training_acc": 52.0, "val_loss": 0.6858152985572815, "val_acc": 56.0}
{"epoch": 30, "training_loss": 0.7165231323242187, "training_acc": 52.0, "val_loss": 0.6870333170890808, "val_acc": 56.0}
{"epoch": 31, "training_loss": 0.708267912864685, "training_acc": 43.0, "val_loss": 0.6953176045417786, "val_acc": 44.0}
{"epoch": 32, "training_loss": 0.6990162181854248, "training_acc": 52.0, "val_loss": 0.6884662365913391, "val_acc": 56.0}
{"epoch": 33, "training_loss": 0.7029400300979615, "training_acc": 52.0, "val_loss": 0.6882873868942261, "val_acc": 56.0}
{"epoch": 34, "training_loss": 0.696662232875824, "training_acc": 46.0, "val_loss": 0.7116901063919068, "val_acc": 44.0}
{"epoch": 35, "training_loss": 0.7026305341720581, "training_acc": 48.0, "val_loss": 0.6926122760772705, "val_acc": 56.0}
{"epoch": 36, "training_loss": 0.6975647449493408, "training_acc": 52.0, "val_loss": 0.6880285263061523, "val_acc": 56.0}
{"epoch": 37, "training_loss": 0.7061296558380127, "training_acc": 52.0, "val_loss": 0.6873362851142883, "val_acc": 56.0}
{"epoch": 38, "training_loss": 0.7076070308685303, "training_acc": 44.0, "val_loss": 0.7043076610565185, "val_acc": 44.0}
{"epoch": 39, "training_loss": 0.6984764146804809, "training_acc": 44.0, "val_loss": 0.6890590643882751, "val_acc": 56.0}
