"main_modify.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 1 --task ABCD_sex --input_option BT_org --learning_rate 1e-3 --batch_size 16 --weight_decay 1e-2 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 0.7164620780944824, "training_acc": 47.0, "val_loss": 0.6925585293769836, "val_acc": 52.0}
{"epoch": 1, "training_loss": 0.7461462306976319, "training_acc": 53.0, "val_loss": 0.7305585885047913, "val_acc": 52.0}
{"epoch": 2, "training_loss": 0.687869291305542, "training_acc": 53.0, "val_loss": 0.7006770038604736, "val_acc": 48.0}
{"epoch": 3, "training_loss": 0.7150842833518982, "training_acc": 47.0, "val_loss": 0.7049700474739075, "val_acc": 48.0}
{"epoch": 4, "training_loss": 0.7037417078018189, "training_acc": 47.0, "val_loss": 0.6939797329902649, "val_acc": 52.0}
{"epoch": 5, "training_loss": 0.693553786277771, "training_acc": 53.0, "val_loss": 0.692913293838501, "val_acc": 52.0}
{"epoch": 6, "training_loss": 0.7042814254760742, "training_acc": 53.0, "val_loss": 0.7029819703102111, "val_acc": 52.0}
{"epoch": 7, "training_loss": 0.6926519250869752, "training_acc": 53.0, "val_loss": 0.6932210206985474, "val_acc": 52.0}
{"epoch": 8, "training_loss": 0.7123985075950623, "training_acc": 41.0, "val_loss": 0.696416015625, "val_acc": 48.0}
{"epoch": 9, "training_loss": 0.6954306483268737, "training_acc": 47.0, "val_loss": 0.6926678419113159, "val_acc": 52.0}
{"epoch": 10, "training_loss": 0.7077296829223633, "training_acc": 53.0, "val_loss": 0.6991446995735169, "val_acc": 52.0}
{"epoch": 11, "training_loss": 0.6963590455055236, "training_acc": 53.0, "val_loss": 0.6947940826416016, "val_acc": 48.0}
{"epoch": 12, "training_loss": 0.7076991844177246, "training_acc": 47.0, "val_loss": 0.6936315488815308, "val_acc": 48.0}
{"epoch": 13, "training_loss": 0.6924784708023072, "training_acc": 61.0, "val_loss": 0.7079227948188782, "val_acc": 52.0}
{"epoch": 14, "training_loss": 0.7066383600234986, "training_acc": 53.0, "val_loss": 0.692609989643097, "val_acc": 52.0}
{"epoch": 15, "training_loss": 0.7006826829910279, "training_acc": 53.0, "val_loss": 0.6925491833686829, "val_acc": 52.0}
{"epoch": 16, "training_loss": 0.6984881711006165, "training_acc": 45.0, "val_loss": 0.6931817650794982, "val_acc": 52.0}
{"epoch": 17, "training_loss": 0.694349946975708, "training_acc": 53.0, "val_loss": 0.6961716961860657, "val_acc": 52.0}
{"epoch": 18, "training_loss": 0.6945588064193725, "training_acc": 53.0, "val_loss": 0.6941820931434631, "val_acc": 52.0}
{"epoch": 19, "training_loss": 0.6943930816650391, "training_acc": 53.0, "val_loss": 0.6925486493110656, "val_acc": 52.0}
{"epoch": 20, "training_loss": 0.7033157873153687, "training_acc": 53.0, "val_loss": 0.6946225810050964, "val_acc": 52.0}
{"epoch": 21, "training_loss": 0.7087526321411133, "training_acc": 47.0, "val_loss": 0.6987720036506653, "val_acc": 48.0}
{"epoch": 22, "training_loss": 0.690609564781189, "training_acc": 56.0, "val_loss": 0.7001692700386047, "val_acc": 52.0}
{"epoch": 23, "training_loss": 0.7051939105987549, "training_acc": 43.0, "val_loss": 0.6929249119758606, "val_acc": 52.0}
{"epoch": 24, "training_loss": 0.6941481828689575, "training_acc": 53.0, "val_loss": 0.6950128173828125, "val_acc": 52.0}
{"epoch": 25, "training_loss": 0.6978611636161804, "training_acc": 53.0, "val_loss": 0.69678391456604, "val_acc": 52.0}
{"epoch": 26, "training_loss": 0.7003388261795044, "training_acc": 45.0, "val_loss": 0.694849545955658, "val_acc": 48.0}
{"epoch": 27, "training_loss": 0.6967720127105713, "training_acc": 49.0, "val_loss": 0.6943330955505371, "val_acc": 52.0}
{"epoch": 28, "training_loss": 0.6936714959144592, "training_acc": 53.0, "val_loss": 0.6935668921470642, "val_acc": 52.0}
{"epoch": 29, "training_loss": 0.7144335579872131, "training_acc": 37.0, "val_loss": 0.6943770289421082, "val_acc": 48.0}
{"epoch": 30, "training_loss": 0.7007246017456055, "training_acc": 45.0, "val_loss": 0.6995430397987366, "val_acc": 52.0}
{"epoch": 31, "training_loss": 0.7025484156608581, "training_acc": 53.0, "val_loss": 0.6946081590652465, "val_acc": 52.0}
{"epoch": 32, "training_loss": 0.6906417798995972, "training_acc": 51.0, "val_loss": 0.6975643277168274, "val_acc": 48.0}
{"epoch": 33, "training_loss": 0.7026287531852722, "training_acc": 47.0, "val_loss": 0.6949764251708984, "val_acc": 48.0}
{"epoch": 34, "training_loss": 0.6954838633537292, "training_acc": 51.0, "val_loss": 0.6976850652694702, "val_acc": 52.0}
{"epoch": 35, "training_loss": 0.6996095657348633, "training_acc": 53.0, "val_loss": 0.6945134091377259, "val_acc": 52.0}
{"epoch": 36, "training_loss": 0.6973520374298096, "training_acc": 53.0, "val_loss": 0.6996152901649475, "val_acc": 52.0}
{"epoch": 37, "training_loss": 0.6975387334823608, "training_acc": 53.0, "val_loss": 0.6925457739830017, "val_acc": 52.0}
{"epoch": 38, "training_loss": 0.6944912099838256, "training_acc": 53.0, "val_loss": 0.6958124566078187, "val_acc": 52.0}
{"epoch": 39, "training_loss": 0.6926686263084412, "training_acc": 53.0, "val_loss": 0.6928691458702088, "val_acc": 52.0}
{"epoch": 40, "training_loss": 0.6996937608718872, "training_acc": 53.0, "val_loss": 0.6936213827133179, "val_acc": 52.0}
{"epoch": 41, "training_loss": 0.7057694387435913, "training_acc": 43.0, "val_loss": 0.6988060021400452, "val_acc": 48.0}
{"epoch": 42, "training_loss": 0.6983261203765869, "training_acc": 47.0, "val_loss": 0.6925386309623718, "val_acc": 52.0}
{"epoch": 43, "training_loss": 0.6995592641830445, "training_acc": 53.0, "val_loss": 0.6993789625167847, "val_acc": 52.0}
{"epoch": 44, "training_loss": 0.6916515851020812, "training_acc": 53.0, "val_loss": 0.6928580451011658, "val_acc": 52.0}
{"epoch": 45, "training_loss": 0.7027531766891479, "training_acc": 45.0, "val_loss": 0.6951542639732361, "val_acc": 48.0}
{"epoch": 46, "training_loss": 0.6951757073402405, "training_acc": 51.0, "val_loss": 0.693867518901825, "val_acc": 52.0}
{"epoch": 47, "training_loss": 0.704740138053894, "training_acc": 53.0, "val_loss": 0.7163843846321106, "val_acc": 52.0}
{"epoch": 48, "training_loss": 0.706955988407135, "training_acc": 51.0, "val_loss": 0.6935109448432922, "val_acc": 48.0}
{"epoch": 49, "training_loss": 0.695977246761322, "training_acc": 53.0, "val_loss": 0.6928288006782531, "val_acc": 52.0}
{"epoch": 50, "training_loss": 0.6999559307098389, "training_acc": 47.0, "val_loss": 0.6978760147094727, "val_acc": 48.0}
{"epoch": 51, "training_loss": 0.6985492849349976, "training_acc": 49.0, "val_loss": 0.6951821732521057, "val_acc": 52.0}
{"epoch": 52, "training_loss": 0.695253562927246, "training_acc": 53.0, "val_loss": 0.6927697348594666, "val_acc": 52.0}
{"epoch": 53, "training_loss": 0.6940536618232727, "training_acc": 52.0, "val_loss": 0.6925603222846984, "val_acc": 52.0}
{"epoch": 54, "training_loss": 0.6998867177963257, "training_acc": 53.0, "val_loss": 0.6982747006416321, "val_acc": 52.0}
{"epoch": 55, "training_loss": 0.7076758050918579, "training_acc": 43.0, "val_loss": 0.6956281089782714, "val_acc": 48.0}
{"epoch": 56, "training_loss": 0.6921517062187195, "training_acc": 53.0, "val_loss": 0.6982178568840027, "val_acc": 52.0}
{"epoch": 57, "training_loss": 0.7073831152915955, "training_acc": 53.0, "val_loss": 0.6991959762573242, "val_acc": 52.0}
{"epoch": 58, "training_loss": 0.7057275080680847, "training_acc": 45.0, "val_loss": 0.6977287030220032, "val_acc": 48.0}
{"epoch": 59, "training_loss": 0.6938808631896972, "training_acc": 57.0, "val_loss": 0.6966960978507996, "val_acc": 52.0}
{"epoch": 60, "training_loss": 0.6962675404548645, "training_acc": 53.0, "val_loss": 0.6925816774368286, "val_acc": 52.0}
{"epoch": 61, "training_loss": 0.7181120681762695, "training_acc": 39.0, "val_loss": 0.6991859793663024, "val_acc": 48.0}
