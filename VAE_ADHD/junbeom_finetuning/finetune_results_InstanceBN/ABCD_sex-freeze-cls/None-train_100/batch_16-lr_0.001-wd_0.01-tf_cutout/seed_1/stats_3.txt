"main_modify.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 1 --task ABCD_sex --input_option BT_org --learning_rate 1e-3 --batch_size 16 --weight_decay 1e-2 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 0.7371283912658692, "training_acc": 51.0, "val_loss": 0.6924828004837036, "val_acc": 52.0}
{"epoch": 1, "training_loss": 0.7356404185295105, "training_acc": 41.0, "val_loss": 0.6982674169540405, "val_acc": 48.0}
{"epoch": 2, "training_loss": 0.692672667503357, "training_acc": 53.0, "val_loss": 0.7120213079452514, "val_acc": 52.0}
{"epoch": 3, "training_loss": 0.7040240812301636, "training_acc": 53.0, "val_loss": 0.6925581455230713, "val_acc": 52.0}
{"epoch": 4, "training_loss": 0.693278706073761, "training_acc": 53.0, "val_loss": 0.6924116230010986, "val_acc": 52.0}
{"epoch": 5, "training_loss": 0.6949371004104614, "training_acc": 43.0, "val_loss": 0.6928594660758972, "val_acc": 52.0}
{"epoch": 6, "training_loss": 0.6933186030387879, "training_acc": 53.0, "val_loss": 0.7035655903816224, "val_acc": 52.0}
{"epoch": 7, "training_loss": 0.6963405966758728, "training_acc": 53.0, "val_loss": 0.6933255314826965, "val_acc": 48.0}
{"epoch": 8, "training_loss": 0.6952362465858459, "training_acc": 43.0, "val_loss": 0.6925310134887696, "val_acc": 52.0}
{"epoch": 9, "training_loss": 0.6921954393386841, "training_acc": 53.0, "val_loss": 0.7014450240135193, "val_acc": 52.0}
{"epoch": 10, "training_loss": 0.7102125406265258, "training_acc": 53.0, "val_loss": 0.6989164209365845, "val_acc": 52.0}
{"epoch": 11, "training_loss": 0.6932015943527222, "training_acc": 51.0, "val_loss": 0.6942824769020081, "val_acc": 48.0}
{"epoch": 12, "training_loss": 0.6938125944137573, "training_acc": 49.0, "val_loss": 0.6939483332633972, "val_acc": 52.0}
{"epoch": 13, "training_loss": 0.7028005385398864, "training_acc": 53.0, "val_loss": 0.6956055188179016, "val_acc": 52.0}
{"epoch": 14, "training_loss": 0.7118334674835205, "training_acc": 45.0, "val_loss": 0.7023139572143555, "val_acc": 48.0}
{"epoch": 15, "training_loss": 0.6928775572776794, "training_acc": 53.0, "val_loss": 0.6986574983596802, "val_acc": 52.0}
{"epoch": 16, "training_loss": 0.693803117275238, "training_acc": 53.0, "val_loss": 0.6925893831253052, "val_acc": 52.0}
{"epoch": 17, "training_loss": 0.7022740840911865, "training_acc": 43.0, "val_loss": 0.6950199937820435, "val_acc": 48.0}
{"epoch": 18, "training_loss": 0.6908686923980712, "training_acc": 51.0, "val_loss": 0.7051397204399109, "val_acc": 52.0}
{"epoch": 19, "training_loss": 0.7091744422912598, "training_acc": 53.0, "val_loss": 0.6979383826255798, "val_acc": 52.0}
{"epoch": 20, "training_loss": 0.7009108233451843, "training_acc": 45.0, "val_loss": 0.7042082953453064, "val_acc": 48.0}
{"epoch": 21, "training_loss": 0.7035576343536377, "training_acc": 47.0, "val_loss": 0.692397243976593, "val_acc": 52.0}
{"epoch": 22, "training_loss": 0.6983543109893798, "training_acc": 53.0, "val_loss": 0.694497537612915, "val_acc": 52.0}
{"epoch": 23, "training_loss": 0.7431764650344849, "training_acc": 39.0, "val_loss": 0.7067856550216675, "val_acc": 48.0}
{"epoch": 24, "training_loss": 0.7271278858184814, "training_acc": 51.0, "val_loss": 0.7366336417198182, "val_acc": 52.0}
{"epoch": 25, "training_loss": 0.7061475133895874, "training_acc": 53.0, "val_loss": 0.6945401573181152, "val_acc": 48.0}
{"epoch": 26, "training_loss": 0.7005710530281067, "training_acc": 47.0, "val_loss": 0.6971491241455078, "val_acc": 48.0}
{"epoch": 27, "training_loss": 0.7090150260925293, "training_acc": 47.0, "val_loss": 0.6979782867431641, "val_acc": 48.0}
{"epoch": 28, "training_loss": 0.6917463946342468, "training_acc": 51.0, "val_loss": 0.7006263089179993, "val_acc": 52.0}
{"epoch": 29, "training_loss": 0.6962634611129761, "training_acc": 53.0, "val_loss": 0.6936860704421997, "val_acc": 52.0}
{"epoch": 30, "training_loss": 0.691025505065918, "training_acc": 56.0, "val_loss": 0.699144139289856, "val_acc": 48.0}
{"epoch": 31, "training_loss": 0.7081455612182617, "training_acc": 47.0, "val_loss": 0.695631651878357, "val_acc": 48.0}
{"epoch": 32, "training_loss": 0.7111241006851197, "training_acc": 53.0, "val_loss": 0.703802444934845, "val_acc": 52.0}
{"epoch": 33, "training_loss": 0.717275857925415, "training_acc": 47.0, "val_loss": 0.7039324045181274, "val_acc": 48.0}
{"epoch": 34, "training_loss": 0.6901623392105103, "training_acc": 57.0, "val_loss": 0.7087549710273743, "val_acc": 52.0}
{"epoch": 35, "training_loss": 0.7041483640670776, "training_acc": 53.0, "val_loss": 0.6976391506195069, "val_acc": 52.0}
{"epoch": 36, "training_loss": 0.6949452424049377, "training_acc": 53.0, "val_loss": 0.6924464416503906, "val_acc": 52.0}
{"epoch": 37, "training_loss": 0.710795476436615, "training_acc": 41.0, "val_loss": 0.6964848613739014, "val_acc": 48.0}
{"epoch": 38, "training_loss": 0.7115686130523682, "training_acc": 53.0, "val_loss": 0.7147316551208496, "val_acc": 52.0}
{"epoch": 39, "training_loss": 0.7028058099746705, "training_acc": 53.0, "val_loss": 0.6925060200691223, "val_acc": 52.0}
{"epoch": 40, "training_loss": 0.6960374617576599, "training_acc": 43.0, "val_loss": 0.6924046635627746, "val_acc": 52.0}
