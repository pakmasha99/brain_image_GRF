"main_modify.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 1 --task ABCD_sex --input_option BT_org --learning_rate 1e-5 --batch_size 16 --weight_decay 1e-2 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 0.7020611548423767, "training_acc": 47.0, "val_loss": 0.6994070720672607, "val_acc": 48.0}
{"epoch": 1, "training_loss": 0.7006272077560425, "training_acc": 47.0, "val_loss": 0.6986926960945129, "val_acc": 48.0}
{"epoch": 2, "training_loss": 0.6997330498695373, "training_acc": 47.0, "val_loss": 0.6982769060134888, "val_acc": 48.0}
{"epoch": 3, "training_loss": 0.6991616725921631, "training_acc": 47.0, "val_loss": 0.6975705981254577, "val_acc": 48.0}
{"epoch": 4, "training_loss": 0.6989950776100159, "training_acc": 47.0, "val_loss": 0.696763722896576, "val_acc": 48.0}
{"epoch": 5, "training_loss": 0.6978179454803467, "training_acc": 47.0, "val_loss": 0.6962842082977295, "val_acc": 48.0}
{"epoch": 6, "training_loss": 0.6970840311050415, "training_acc": 47.0, "val_loss": 0.6958559870719909, "val_acc": 48.0}
{"epoch": 7, "training_loss": 0.69655517578125, "training_acc": 47.0, "val_loss": 0.6955730032920837, "val_acc": 48.0}
{"epoch": 8, "training_loss": 0.6963547706604004, "training_acc": 47.0, "val_loss": 0.6952345728874206, "val_acc": 48.0}
{"epoch": 9, "training_loss": 0.695783531665802, "training_acc": 47.0, "val_loss": 0.6949156332015991, "val_acc": 48.0}
{"epoch": 10, "training_loss": 0.6952649736404419, "training_acc": 47.0, "val_loss": 0.6945217490196228, "val_acc": 48.0}
{"epoch": 11, "training_loss": 0.6948460626602173, "training_acc": 47.0, "val_loss": 0.6942226123809815, "val_acc": 48.0}
{"epoch": 12, "training_loss": 0.6945805311203003, "training_acc": 47.0, "val_loss": 0.6939204883575439, "val_acc": 48.0}
{"epoch": 13, "training_loss": 0.6940985631942749, "training_acc": 47.0, "val_loss": 0.6935784888267517, "val_acc": 48.0}
{"epoch": 14, "training_loss": 0.6937115550041199, "training_acc": 47.0, "val_loss": 0.6934354043006897, "val_acc": 48.0}
{"epoch": 15, "training_loss": 0.6935597491264344, "training_acc": 47.0, "val_loss": 0.693429799079895, "val_acc": 48.0}
{"epoch": 16, "training_loss": 0.6935941839218139, "training_acc": 47.0, "val_loss": 0.693329610824585, "val_acc": 48.0}
{"epoch": 17, "training_loss": 0.6934382128715515, "training_acc": 47.0, "val_loss": 0.6932414245605468, "val_acc": 48.0}
{"epoch": 18, "training_loss": 0.6934488344192505, "training_acc": 43.0, "val_loss": 0.6931833744049072, "val_acc": 48.0}
{"epoch": 19, "training_loss": 0.6931339740753174, "training_acc": 47.0, "val_loss": 0.6931570053100586, "val_acc": 52.0}
{"epoch": 20, "training_loss": 0.6930602788925171, "training_acc": 53.0, "val_loss": 0.6930383634567261, "val_acc": 52.0}
{"epoch": 21, "training_loss": 0.6927869176864624, "training_acc": 52.0, "val_loss": 0.6929609727859497, "val_acc": 52.0}
{"epoch": 22, "training_loss": 0.6929173231124878, "training_acc": 53.0, "val_loss": 0.6928083896636963, "val_acc": 52.0}
{"epoch": 23, "training_loss": 0.6924468636512756, "training_acc": 53.0, "val_loss": 0.692722327709198, "val_acc": 52.0}
{"epoch": 24, "training_loss": 0.6925193786621093, "training_acc": 53.0, "val_loss": 0.6926390385627746, "val_acc": 52.0}
{"epoch": 25, "training_loss": 0.6924294710159302, "training_acc": 53.0, "val_loss": 0.6926002168655395, "val_acc": 52.0}
{"epoch": 26, "training_loss": 0.6921948575973511, "training_acc": 53.0, "val_loss": 0.6925123691558838, "val_acc": 52.0}
{"epoch": 27, "training_loss": 0.6922954297065735, "training_acc": 53.0, "val_loss": 0.692530825138092, "val_acc": 52.0}
{"epoch": 28, "training_loss": 0.6922658038139343, "training_acc": 53.0, "val_loss": 0.692497444152832, "val_acc": 52.0}
{"epoch": 29, "training_loss": 0.6919710111618042, "training_acc": 53.0, "val_loss": 0.6924625706672668, "val_acc": 52.0}
{"epoch": 30, "training_loss": 0.6920791339874267, "training_acc": 53.0, "val_loss": 0.6924438452720643, "val_acc": 52.0}
{"epoch": 31, "training_loss": 0.6919943952560424, "training_acc": 53.0, "val_loss": 0.6924279379844666, "val_acc": 52.0}
{"epoch": 32, "training_loss": 0.6917969107627868, "training_acc": 53.0, "val_loss": 0.6924126291275025, "val_acc": 52.0}
{"epoch": 33, "training_loss": 0.6918297100067139, "training_acc": 53.0, "val_loss": 0.6923952293395996, "val_acc": 52.0}
{"epoch": 34, "training_loss": 0.6916912579536438, "training_acc": 53.0, "val_loss": 0.6923761439323425, "val_acc": 52.0}
{"epoch": 35, "training_loss": 0.6916419243812562, "training_acc": 53.0, "val_loss": 0.6923707103729249, "val_acc": 52.0}
{"epoch": 36, "training_loss": 0.6917657494544983, "training_acc": 53.0, "val_loss": 0.6923657250404358, "val_acc": 52.0}
{"epoch": 37, "training_loss": 0.6917474102973938, "training_acc": 53.0, "val_loss": 0.6923477149009705, "val_acc": 52.0}
{"epoch": 38, "training_loss": 0.6916839170455933, "training_acc": 53.0, "val_loss": 0.692341616153717, "val_acc": 52.0}
{"epoch": 39, "training_loss": 0.6917971658706665, "training_acc": 53.0, "val_loss": 0.6923325347900391, "val_acc": 52.0}
{"epoch": 40, "training_loss": 0.691624927520752, "training_acc": 53.0, "val_loss": 0.6923323845863343, "val_acc": 52.0}
{"epoch": 41, "training_loss": 0.6913648700714111, "training_acc": 53.0, "val_loss": 0.6923330450057983, "val_acc": 52.0}
{"epoch": 42, "training_loss": 0.691529016494751, "training_acc": 53.0, "val_loss": 0.6923297882080078, "val_acc": 52.0}
{"epoch": 43, "training_loss": 0.6914869260787964, "training_acc": 53.0, "val_loss": 0.6923352122306824, "val_acc": 52.0}
{"epoch": 44, "training_loss": 0.6917173457145691, "training_acc": 53.0, "val_loss": 0.6923513865470886, "val_acc": 52.0}
{"epoch": 45, "training_loss": 0.6915127635002136, "training_acc": 53.0, "val_loss": 0.6923493719100953, "val_acc": 52.0}
{"epoch": 46, "training_loss": 0.6914122486114502, "training_acc": 53.0, "val_loss": 0.6923717045783997, "val_acc": 52.0}
{"epoch": 47, "training_loss": 0.6914410448074341, "training_acc": 53.0, "val_loss": 0.6924151158332825, "val_acc": 52.0}
{"epoch": 48, "training_loss": 0.6911643028259278, "training_acc": 53.0, "val_loss": 0.6924768352508545, "val_acc": 52.0}
{"epoch": 49, "training_loss": 0.6914900970458985, "training_acc": 53.0, "val_loss": 0.6925037145614624, "val_acc": 52.0}
{"epoch": 50, "training_loss": 0.6912772274017334, "training_acc": 53.0, "val_loss": 0.6924846506118775, "val_acc": 52.0}
{"epoch": 51, "training_loss": 0.6914773964881897, "training_acc": 53.0, "val_loss": 0.692474434375763, "val_acc": 52.0}
{"epoch": 52, "training_loss": 0.6912419652938843, "training_acc": 53.0, "val_loss": 0.6924695134162903, "val_acc": 52.0}
{"epoch": 53, "training_loss": 0.691297423839569, "training_acc": 53.0, "val_loss": 0.6925204586982727, "val_acc": 52.0}
{"epoch": 54, "training_loss": 0.6911282062530517, "training_acc": 53.0, "val_loss": 0.6925539517402649, "val_acc": 52.0}
{"epoch": 55, "training_loss": 0.6914013814926148, "training_acc": 53.0, "val_loss": 0.6925245261192322, "val_acc": 52.0}
{"epoch": 56, "training_loss": 0.6915013146400452, "training_acc": 53.0, "val_loss": 0.6925268483161926, "val_acc": 52.0}
{"epoch": 57, "training_loss": 0.6913882875442505, "training_acc": 53.0, "val_loss": 0.6925229454040527, "val_acc": 52.0}
{"epoch": 58, "training_loss": 0.6914203405380249, "training_acc": 53.0, "val_loss": 0.6924934363365174, "val_acc": 52.0}
{"epoch": 59, "training_loss": 0.6912894225120545, "training_acc": 53.0, "val_loss": 0.6924972677230835, "val_acc": 52.0}
{"epoch": 60, "training_loss": 0.6916664505004883, "training_acc": 53.0, "val_loss": 0.6925317001342773, "val_acc": 52.0}
{"epoch": 61, "training_loss": 0.691461501121521, "training_acc": 53.0, "val_loss": 0.6924848985671997, "val_acc": 52.0}
