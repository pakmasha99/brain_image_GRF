"main_modify.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 1 --task ABCD_sex --input_option BT_org --learning_rate 1e-5 --batch_size 16 --weight_decay 1e-2 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 0.700167007446289, "training_acc": 47.0, "val_loss": 0.6977356791496276, "val_acc": 48.0}
{"epoch": 1, "training_loss": 0.6991250419616699, "training_acc": 47.0, "val_loss": 0.6971564674377442, "val_acc": 48.0}
{"epoch": 2, "training_loss": 0.6980550193786621, "training_acc": 47.0, "val_loss": 0.6966182708740234, "val_acc": 48.0}
{"epoch": 3, "training_loss": 0.6980084180831909, "training_acc": 47.0, "val_loss": 0.6959066033363343, "val_acc": 48.0}
{"epoch": 4, "training_loss": 0.6967663192749023, "training_acc": 47.0, "val_loss": 0.6956191968917846, "val_acc": 48.0}
{"epoch": 5, "training_loss": 0.6967415857315064, "training_acc": 47.0, "val_loss": 0.695192255973816, "val_acc": 48.0}
{"epoch": 6, "training_loss": 0.6961436128616333, "training_acc": 47.0, "val_loss": 0.6946509528160095, "val_acc": 48.0}
{"epoch": 7, "training_loss": 0.6951260232925415, "training_acc": 47.0, "val_loss": 0.6943175959587097, "val_acc": 48.0}
{"epoch": 8, "training_loss": 0.6946388459205628, "training_acc": 47.0, "val_loss": 0.6940969777107239, "val_acc": 48.0}
{"epoch": 9, "training_loss": 0.6945304107666016, "training_acc": 47.0, "val_loss": 0.6937148308753968, "val_acc": 48.0}
{"epoch": 10, "training_loss": 0.6942736101150513, "training_acc": 47.0, "val_loss": 0.6934297895431518, "val_acc": 48.0}
{"epoch": 11, "training_loss": 0.6936279463768006, "training_acc": 47.0, "val_loss": 0.6931804776191711, "val_acc": 48.0}
{"epoch": 12, "training_loss": 0.6937389683723449, "training_acc": 44.0, "val_loss": 0.6929510045051575, "val_acc": 52.0}
{"epoch": 13, "training_loss": 0.6930856084823609, "training_acc": 53.0, "val_loss": 0.6927816724777222, "val_acc": 52.0}
{"epoch": 14, "training_loss": 0.6927958679199219, "training_acc": 53.0, "val_loss": 0.6927122783660888, "val_acc": 52.0}
{"epoch": 15, "training_loss": 0.6928347969055175, "training_acc": 53.0, "val_loss": 0.6926758480072022, "val_acc": 52.0}
{"epoch": 16, "training_loss": 0.6928823471069336, "training_acc": 53.0, "val_loss": 0.6925160145759582, "val_acc": 52.0}
{"epoch": 17, "training_loss": 0.6922887349128723, "training_acc": 53.0, "val_loss": 0.6924399638175964, "val_acc": 52.0}
{"epoch": 18, "training_loss": 0.6921266388893127, "training_acc": 53.0, "val_loss": 0.6923970103263855, "val_acc": 52.0}
{"epoch": 19, "training_loss": 0.6923156094551086, "training_acc": 53.0, "val_loss": 0.6923678588867187, "val_acc": 52.0}
{"epoch": 20, "training_loss": 0.692160005569458, "training_acc": 53.0, "val_loss": 0.6922948455810547, "val_acc": 52.0}
{"epoch": 21, "training_loss": 0.6918326830863952, "training_acc": 53.0, "val_loss": 0.6922581672668457, "val_acc": 52.0}
{"epoch": 22, "training_loss": 0.6916525268554687, "training_acc": 53.0, "val_loss": 0.6922431182861328, "val_acc": 52.0}
{"epoch": 23, "training_loss": 0.6915771031379699, "training_acc": 53.0, "val_loss": 0.6922239995002747, "val_acc": 52.0}
{"epoch": 24, "training_loss": 0.6917622637748718, "training_acc": 53.0, "val_loss": 0.6922130990028381, "val_acc": 52.0}
{"epoch": 25, "training_loss": 0.6915102672576904, "training_acc": 53.0, "val_loss": 0.6922117924690246, "val_acc": 52.0}
{"epoch": 26, "training_loss": 0.6918669986724854, "training_acc": 53.0, "val_loss": 0.6922199106216431, "val_acc": 52.0}
{"epoch": 27, "training_loss": 0.6915367841720581, "training_acc": 53.0, "val_loss": 0.6922248959541321, "val_acc": 52.0}
{"epoch": 28, "training_loss": 0.6915295791625976, "training_acc": 53.0, "val_loss": 0.6922388434410095, "val_acc": 52.0}
{"epoch": 29, "training_loss": 0.6915411639213562, "training_acc": 53.0, "val_loss": 0.6922555184364318, "val_acc": 52.0}
{"epoch": 30, "training_loss": 0.6914180564880371, "training_acc": 53.0, "val_loss": 0.6922718071937561, "val_acc": 52.0}
{"epoch": 31, "training_loss": 0.6913956189155579, "training_acc": 53.0, "val_loss": 0.6922915601730346, "val_acc": 52.0}
{"epoch": 32, "training_loss": 0.6915400981903076, "training_acc": 53.0, "val_loss": 0.692341320514679, "val_acc": 52.0}
{"epoch": 33, "training_loss": 0.691621253490448, "training_acc": 53.0, "val_loss": 0.6923857235908508, "val_acc": 52.0}
{"epoch": 34, "training_loss": 0.6914209842681884, "training_acc": 53.0, "val_loss": 0.6924215435981751, "val_acc": 52.0}
{"epoch": 35, "training_loss": 0.6913672304153442, "training_acc": 53.0, "val_loss": 0.6924554419517517, "val_acc": 52.0}
{"epoch": 36, "training_loss": 0.6915262985229492, "training_acc": 53.0, "val_loss": 0.6924178767204284, "val_acc": 52.0}
{"epoch": 37, "training_loss": 0.6914686894416809, "training_acc": 53.0, "val_loss": 0.6924142384529114, "val_acc": 52.0}
{"epoch": 38, "training_loss": 0.6915902185440064, "training_acc": 53.0, "val_loss": 0.6923871612548829, "val_acc": 52.0}
{"epoch": 39, "training_loss": 0.6915122222900391, "training_acc": 53.0, "val_loss": 0.6923537564277649, "val_acc": 52.0}
{"epoch": 40, "training_loss": 0.6913948917388916, "training_acc": 53.0, "val_loss": 0.692358832359314, "val_acc": 52.0}
{"epoch": 41, "training_loss": 0.6915127038955688, "training_acc": 53.0, "val_loss": 0.6924016189575195, "val_acc": 52.0}
{"epoch": 42, "training_loss": 0.6914956665039063, "training_acc": 53.0, "val_loss": 0.6923946022987366, "val_acc": 52.0}
{"epoch": 43, "training_loss": 0.6914758968353272, "training_acc": 53.0, "val_loss": 0.6923808360099792, "val_acc": 52.0}
{"epoch": 44, "training_loss": 0.691339087486267, "training_acc": 53.0, "val_loss": 0.6923659634590149, "val_acc": 52.0}
