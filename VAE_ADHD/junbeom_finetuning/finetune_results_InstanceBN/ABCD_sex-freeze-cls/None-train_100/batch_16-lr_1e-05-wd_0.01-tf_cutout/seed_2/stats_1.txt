"main_modify.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 2 --task ABCD_sex --input_option BT_org --learning_rate 1e-5 --batch_size 16 --weight_decay 1e-2 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 0.7035080862045288, "training_acc": 47.0, "val_loss": 0.7006261706352234, "val_acc": 48.0}
{"epoch": 1, "training_loss": 0.7021202325820923, "training_acc": 47.0, "val_loss": 0.699920871257782, "val_acc": 48.0}
{"epoch": 2, "training_loss": 0.7007483553886413, "training_acc": 47.0, "val_loss": 0.6990323424339294, "val_acc": 48.0}
{"epoch": 3, "training_loss": 0.6999530172348023, "training_acc": 47.0, "val_loss": 0.6979693961143494, "val_acc": 48.0}
{"epoch": 4, "training_loss": 0.6988126707077026, "training_acc": 47.0, "val_loss": 0.6971994137763977, "val_acc": 48.0}
{"epoch": 5, "training_loss": 0.697608904838562, "training_acc": 47.0, "val_loss": 0.6965100622177124, "val_acc": 48.0}
{"epoch": 6, "training_loss": 0.6971402359008789, "training_acc": 47.0, "val_loss": 0.6959647607803344, "val_acc": 48.0}
{"epoch": 7, "training_loss": 0.6964023756980896, "training_acc": 47.0, "val_loss": 0.6954043531417846, "val_acc": 48.0}
{"epoch": 8, "training_loss": 0.6958030962944031, "training_acc": 47.0, "val_loss": 0.6948643827438354, "val_acc": 48.0}
{"epoch": 9, "training_loss": 0.6954490900039673, "training_acc": 47.0, "val_loss": 0.6944547963142395, "val_acc": 48.0}
{"epoch": 10, "training_loss": 0.6946466398239136, "training_acc": 47.0, "val_loss": 0.6941183137893677, "val_acc": 48.0}
{"epoch": 11, "training_loss": 0.6940035510063172, "training_acc": 47.0, "val_loss": 0.6937953495979309, "val_acc": 48.0}
{"epoch": 12, "training_loss": 0.6935628747940064, "training_acc": 47.0, "val_loss": 0.6934989666938782, "val_acc": 48.0}
{"epoch": 13, "training_loss": 0.6933106732368469, "training_acc": 50.0, "val_loss": 0.6932925844192505, "val_acc": 28.0}
{"epoch": 14, "training_loss": 0.6931721162796021, "training_acc": 48.0, "val_loss": 0.6931273174285889, "val_acc": 52.0}
{"epoch": 15, "training_loss": 0.692997772693634, "training_acc": 52.0, "val_loss": 0.6931030344963074, "val_acc": 52.0}
{"epoch": 16, "training_loss": 0.6928503274917602, "training_acc": 53.0, "val_loss": 0.6931259298324585, "val_acc": 52.0}
{"epoch": 17, "training_loss": 0.6931208181381225, "training_acc": 53.0, "val_loss": 0.6931648302078247, "val_acc": 52.0}
{"epoch": 18, "training_loss": 0.6930315947532654, "training_acc": 51.0, "val_loss": 0.6932195949554444, "val_acc": 52.0}
{"epoch": 19, "training_loss": 0.6929988098144532, "training_acc": 50.0, "val_loss": 0.6931185841560363, "val_acc": 52.0}
{"epoch": 20, "training_loss": 0.6929107236862183, "training_acc": 53.0, "val_loss": 0.692996256351471, "val_acc": 52.0}
{"epoch": 21, "training_loss": 0.6927746891975403, "training_acc": 53.0, "val_loss": 0.692849850654602, "val_acc": 52.0}
{"epoch": 22, "training_loss": 0.6924243569374084, "training_acc": 53.0, "val_loss": 0.6927456569671631, "val_acc": 52.0}
{"epoch": 23, "training_loss": 0.6921396279335021, "training_acc": 53.0, "val_loss": 0.6926781344413757, "val_acc": 52.0}
{"epoch": 24, "training_loss": 0.6920389628410339, "training_acc": 53.0, "val_loss": 0.6926103663444519, "val_acc": 52.0}
{"epoch": 25, "training_loss": 0.6918524312973022, "training_acc": 53.0, "val_loss": 0.6925480318069458, "val_acc": 52.0}
{"epoch": 26, "training_loss": 0.6919700384140015, "training_acc": 53.0, "val_loss": 0.6925193905830384, "val_acc": 52.0}
{"epoch": 27, "training_loss": 0.6916977691650391, "training_acc": 53.0, "val_loss": 0.6924996781349182, "val_acc": 52.0}
{"epoch": 28, "training_loss": 0.691659665107727, "training_acc": 53.0, "val_loss": 0.6924993467330932, "val_acc": 52.0}
{"epoch": 29, "training_loss": 0.6917022514343262, "training_acc": 53.0, "val_loss": 0.6924988174438477, "val_acc": 52.0}
{"epoch": 30, "training_loss": 0.6916269016265869, "training_acc": 53.0, "val_loss": 0.6924859547615051, "val_acc": 52.0}
{"epoch": 31, "training_loss": 0.6917409729957581, "training_acc": 53.0, "val_loss": 0.6924895238876343, "val_acc": 52.0}
{"epoch": 32, "training_loss": 0.6914009189605713, "training_acc": 53.0, "val_loss": 0.6924947524070739, "val_acc": 52.0}
{"epoch": 33, "training_loss": 0.6915255212783813, "training_acc": 53.0, "val_loss": 0.6925057697296143, "val_acc": 52.0}
{"epoch": 34, "training_loss": 0.6913567495346069, "training_acc": 53.0, "val_loss": 0.6925031208992004, "val_acc": 52.0}
{"epoch": 35, "training_loss": 0.6914676332473755, "training_acc": 53.0, "val_loss": 0.6924908351898194, "val_acc": 52.0}
{"epoch": 36, "training_loss": 0.6913752818107605, "training_acc": 53.0, "val_loss": 0.6924942827224732, "val_acc": 52.0}
{"epoch": 37, "training_loss": 0.6916011929512024, "training_acc": 53.0, "val_loss": 0.6924939036369324, "val_acc": 52.0}
{"epoch": 38, "training_loss": 0.6913725757598876, "training_acc": 53.0, "val_loss": 0.6925058579444885, "val_acc": 52.0}
{"epoch": 39, "training_loss": 0.6914159965515136, "training_acc": 53.0, "val_loss": 0.6925084233283997, "val_acc": 52.0}
{"epoch": 40, "training_loss": 0.6915153169631958, "training_acc": 53.0, "val_loss": 0.6925132346153259, "val_acc": 52.0}
{"epoch": 41, "training_loss": 0.6911456823348999, "training_acc": 53.0, "val_loss": 0.6925051808357239, "val_acc": 52.0}
{"epoch": 42, "training_loss": 0.6915378975868225, "training_acc": 53.0, "val_loss": 0.6925010919570923, "val_acc": 52.0}
{"epoch": 43, "training_loss": 0.6914294695854187, "training_acc": 53.0, "val_loss": 0.6924899291992187, "val_acc": 52.0}
{"epoch": 44, "training_loss": 0.691581220626831, "training_acc": 53.0, "val_loss": 0.6924827170372009, "val_acc": 52.0}
{"epoch": 45, "training_loss": 0.6912764978408813, "training_acc": 53.0, "val_loss": 0.6924869632720947, "val_acc": 52.0}
{"epoch": 46, "training_loss": 0.6913861131668091, "training_acc": 53.0, "val_loss": 0.692493245601654, "val_acc": 52.0}
{"epoch": 47, "training_loss": 0.6915913820266724, "training_acc": 53.0, "val_loss": 0.6925071263313294, "val_acc": 52.0}
{"epoch": 48, "training_loss": 0.6915016460418701, "training_acc": 53.0, "val_loss": 0.6925124859809876, "val_acc": 52.0}
{"epoch": 49, "training_loss": 0.6915388989448548, "training_acc": 53.0, "val_loss": 0.6925533032417297, "val_acc": 52.0}
{"epoch": 50, "training_loss": 0.6912042593955994, "training_acc": 53.0, "val_loss": 0.692584581375122, "val_acc": 52.0}
{"epoch": 51, "training_loss": 0.6914171195030212, "training_acc": 53.0, "val_loss": 0.6926252460479736, "val_acc": 52.0}
{"epoch": 52, "training_loss": 0.691526665687561, "training_acc": 53.0, "val_loss": 0.6926767921447754, "val_acc": 52.0}
{"epoch": 53, "training_loss": 0.691060585975647, "training_acc": 53.0, "val_loss": 0.6926692700386048, "val_acc": 52.0}
{"epoch": 54, "training_loss": 0.691295862197876, "training_acc": 53.0, "val_loss": 0.6926528573036194, "val_acc": 52.0}
{"epoch": 55, "training_loss": 0.6913429307937622, "training_acc": 53.0, "val_loss": 0.692631938457489, "val_acc": 52.0}
{"epoch": 56, "training_loss": 0.6914561319351197, "training_acc": 53.0, "val_loss": 0.6926569771766663, "val_acc": 52.0}
{"epoch": 57, "training_loss": 0.6911669373512268, "training_acc": 53.0, "val_loss": 0.6926722741127014, "val_acc": 52.0}
{"epoch": 58, "training_loss": 0.6912297439575196, "training_acc": 53.0, "val_loss": 0.6926551461219788, "val_acc": 52.0}
{"epoch": 59, "training_loss": 0.6915134406089782, "training_acc": 53.0, "val_loss": 0.6926619029045105, "val_acc": 52.0}
{"epoch": 60, "training_loss": 0.6912985706329345, "training_acc": 53.0, "val_loss": 0.6927012729644776, "val_acc": 52.0}
{"epoch": 61, "training_loss": 0.6916881275177001, "training_acc": 53.0, "val_loss": 0.6927188968658448, "val_acc": 52.0}
{"epoch": 62, "training_loss": 0.6914200210571289, "training_acc": 53.0, "val_loss": 0.6927172946929931, "val_acc": 52.0}
{"epoch": 63, "training_loss": 0.691199049949646, "training_acc": 53.0, "val_loss": 0.6927320575714111, "val_acc": 52.0}
