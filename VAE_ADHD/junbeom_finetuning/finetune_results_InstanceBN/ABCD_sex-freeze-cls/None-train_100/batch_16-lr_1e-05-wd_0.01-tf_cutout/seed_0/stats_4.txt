"main_modify.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option BT_org --learning_rate 1e-5 --batch_size 16 --weight_decay 1e-2 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 0.6914082670211792, "training_acc": 53.0, "val_loss": 0.692875258922577, "val_acc": 52.0}
{"epoch": 1, "training_loss": 0.691330018043518, "training_acc": 53.0, "val_loss": 0.6928675532341003, "val_acc": 52.0}
{"epoch": 2, "training_loss": 0.6917029857635498, "training_acc": 53.0, "val_loss": 0.6927445936203003, "val_acc": 52.0}
{"epoch": 3, "training_loss": 0.6915099096298217, "training_acc": 53.0, "val_loss": 0.6926915431022644, "val_acc": 52.0}
{"epoch": 4, "training_loss": 0.6914140939712524, "training_acc": 53.0, "val_loss": 0.692691195011139, "val_acc": 52.0}
{"epoch": 5, "training_loss": 0.6912699294090271, "training_acc": 53.0, "val_loss": 0.6926744723320007, "val_acc": 52.0}
{"epoch": 6, "training_loss": 0.6914342641830444, "training_acc": 53.0, "val_loss": 0.6926882600784302, "val_acc": 52.0}
{"epoch": 7, "training_loss": 0.6913749575614929, "training_acc": 53.0, "val_loss": 0.6927188158035278, "val_acc": 52.0}
{"epoch": 8, "training_loss": 0.6916667699813843, "training_acc": 53.0, "val_loss": 0.6928296279907227, "val_acc": 52.0}
{"epoch": 9, "training_loss": 0.6913319826126099, "training_acc": 53.0, "val_loss": 0.692834620475769, "val_acc": 52.0}
{"epoch": 10, "training_loss": 0.6910667276382446, "training_acc": 53.0, "val_loss": 0.6927805685997009, "val_acc": 52.0}
{"epoch": 11, "training_loss": 0.6915258312225342, "training_acc": 53.0, "val_loss": 0.6927402925491333, "val_acc": 52.0}
{"epoch": 12, "training_loss": 0.6910645174980163, "training_acc": 53.0, "val_loss": 0.6926625370979309, "val_acc": 52.0}
{"epoch": 13, "training_loss": 0.6917021799087525, "training_acc": 53.0, "val_loss": 0.6925789904594422, "val_acc": 52.0}
{"epoch": 14, "training_loss": 0.6913828563690185, "training_acc": 53.0, "val_loss": 0.6925751399993897, "val_acc": 52.0}
{"epoch": 15, "training_loss": 0.6912653160095215, "training_acc": 53.0, "val_loss": 0.6926162719726563, "val_acc": 52.0}
{"epoch": 16, "training_loss": 0.6912802886962891, "training_acc": 53.0, "val_loss": 0.6926507282257081, "val_acc": 52.0}
{"epoch": 17, "training_loss": 0.6915595817565918, "training_acc": 53.0, "val_loss": 0.6926344537734985, "val_acc": 52.0}
{"epoch": 18, "training_loss": 0.6913468480110169, "training_acc": 53.0, "val_loss": 0.6926150774955749, "val_acc": 52.0}
{"epoch": 19, "training_loss": 0.6913168168067932, "training_acc": 53.0, "val_loss": 0.6925898098945618, "val_acc": 52.0}
{"epoch": 20, "training_loss": 0.6912550520896912, "training_acc": 53.0, "val_loss": 0.6925435662269592, "val_acc": 52.0}
{"epoch": 21, "training_loss": 0.6914166188240052, "training_acc": 53.0, "val_loss": 0.6925183916091919, "val_acc": 52.0}
{"epoch": 22, "training_loss": 0.6916697549819947, "training_acc": 53.0, "val_loss": 0.6924840044975281, "val_acc": 52.0}
{"epoch": 23, "training_loss": 0.6914233779907226, "training_acc": 53.0, "val_loss": 0.6924899363517761, "val_acc": 52.0}
{"epoch": 24, "training_loss": 0.6915041971206665, "training_acc": 53.0, "val_loss": 0.6925060343742371, "val_acc": 52.0}
{"epoch": 25, "training_loss": 0.6912473773956299, "training_acc": 53.0, "val_loss": 0.6925005459785462, "val_acc": 52.0}
{"epoch": 26, "training_loss": 0.6914972329139709, "training_acc": 53.0, "val_loss": 0.6924921751022339, "val_acc": 52.0}
{"epoch": 27, "training_loss": 0.6913286209106445, "training_acc": 53.0, "val_loss": 0.6924791288375854, "val_acc": 52.0}
{"epoch": 28, "training_loss": 0.6910558247566223, "training_acc": 53.0, "val_loss": 0.6924708652496337, "val_acc": 52.0}
{"epoch": 29, "training_loss": 0.6913203954696655, "training_acc": 53.0, "val_loss": 0.6924612689018249, "val_acc": 52.0}
{"epoch": 30, "training_loss": 0.6915282869338989, "training_acc": 53.0, "val_loss": 0.6924660968780517, "val_acc": 52.0}
{"epoch": 31, "training_loss": 0.691256628036499, "training_acc": 53.0, "val_loss": 0.6924616146087647, "val_acc": 52.0}
{"epoch": 32, "training_loss": 0.6913460254669189, "training_acc": 53.0, "val_loss": 0.6924640965461731, "val_acc": 52.0}
{"epoch": 33, "training_loss": 0.6914206790924072, "training_acc": 53.0, "val_loss": 0.6924746322631836, "val_acc": 52.0}
{"epoch": 34, "training_loss": 0.6915141820907593, "training_acc": 53.0, "val_loss": 0.6924819087982178, "val_acc": 52.0}
{"epoch": 35, "training_loss": 0.6913203954696655, "training_acc": 53.0, "val_loss": 0.6924926710128784, "val_acc": 52.0}
{"epoch": 36, "training_loss": 0.6914559507369995, "training_acc": 53.0, "val_loss": 0.6924969601631165, "val_acc": 52.0}
{"epoch": 37, "training_loss": 0.6913502264022827, "training_acc": 53.0, "val_loss": 0.6925172924995422, "val_acc": 52.0}
{"epoch": 38, "training_loss": 0.6915613746643067, "training_acc": 53.0, "val_loss": 0.6925072789192199, "val_acc": 52.0}
{"epoch": 39, "training_loss": 0.6913412070274353, "training_acc": 53.0, "val_loss": 0.692522156238556, "val_acc": 52.0}
{"epoch": 40, "training_loss": 0.6914373826980591, "training_acc": 53.0, "val_loss": 0.6925097012519836, "val_acc": 52.0}
{"epoch": 41, "training_loss": 0.6912732172012329, "training_acc": 53.0, "val_loss": 0.6925131177902222, "val_acc": 52.0}
{"epoch": 42, "training_loss": 0.6913639211654663, "training_acc": 53.0, "val_loss": 0.6924921107292176, "val_acc": 52.0}
{"epoch": 43, "training_loss": 0.6914174103736878, "training_acc": 53.0, "val_loss": 0.6924767565727233, "val_acc": 52.0}
{"epoch": 44, "training_loss": 0.691338300704956, "training_acc": 53.0, "val_loss": 0.6924833559989929, "val_acc": 52.0}
{"epoch": 45, "training_loss": 0.6911921906471252, "training_acc": 53.0, "val_loss": 0.6925038385391236, "val_acc": 52.0}
{"epoch": 46, "training_loss": 0.6915699172019959, "training_acc": 53.0, "val_loss": 0.6925380229949951, "val_acc": 52.0}
{"epoch": 47, "training_loss": 0.6913466167449951, "training_acc": 53.0, "val_loss": 0.6925740385055542, "val_acc": 52.0}
{"epoch": 48, "training_loss": 0.6912826824188233, "training_acc": 53.0, "val_loss": 0.6926127648353577, "val_acc": 52.0}
