"main_modify.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option BT_org --learning_rate 1e-5 --batch_size 16 --weight_decay 1e-2 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 0.692478928565979, "training_acc": 52.0, "val_loss": 0.6899121522903442, "val_acc": 56.0}
{"epoch": 1, "training_loss": 0.6925142168998718, "training_acc": 52.0, "val_loss": 0.6898112797737121, "val_acc": 56.0}
{"epoch": 2, "training_loss": 0.6923523902893066, "training_acc": 52.0, "val_loss": 0.6897819852828979, "val_acc": 56.0}
{"epoch": 3, "training_loss": 0.692424304485321, "training_acc": 52.0, "val_loss": 0.6895651340484619, "val_acc": 56.0}
{"epoch": 4, "training_loss": 0.692387981414795, "training_acc": 52.0, "val_loss": 0.6896249008178711, "val_acc": 56.0}
{"epoch": 5, "training_loss": 0.6922283053398133, "training_acc": 52.0, "val_loss": 0.6894997096061707, "val_acc": 56.0}
{"epoch": 6, "training_loss": 0.692405788898468, "training_acc": 52.0, "val_loss": 0.6894365978240967, "val_acc": 56.0}
{"epoch": 7, "training_loss": 0.6923007225990295, "training_acc": 52.0, "val_loss": 0.689479341506958, "val_acc": 56.0}
{"epoch": 8, "training_loss": 0.6925322818756103, "training_acc": 52.0, "val_loss": 0.6893456649780273, "val_acc": 56.0}
{"epoch": 9, "training_loss": 0.6923871922492981, "training_acc": 52.0, "val_loss": 0.6894177603721618, "val_acc": 56.0}
{"epoch": 10, "training_loss": 0.6923179388046264, "training_acc": 52.0, "val_loss": 0.6896225142478943, "val_acc": 56.0}
{"epoch": 11, "training_loss": 0.6923701977729797, "training_acc": 52.0, "val_loss": 0.6896000742912293, "val_acc": 56.0}
{"epoch": 12, "training_loss": 0.6923631525039673, "training_acc": 52.0, "val_loss": 0.6893064999580383, "val_acc": 56.0}
{"epoch": 13, "training_loss": 0.6921126174926758, "training_acc": 52.0, "val_loss": 0.6892484784126282, "val_acc": 56.0}
{"epoch": 14, "training_loss": 0.6923680591583252, "training_acc": 52.0, "val_loss": 0.6890984892845153, "val_acc": 56.0}
{"epoch": 15, "training_loss": 0.6922315645217896, "training_acc": 52.0, "val_loss": 0.6890310907363891, "val_acc": 56.0}
{"epoch": 16, "training_loss": 0.692365071773529, "training_acc": 52.0, "val_loss": 0.6887449502944947, "val_acc": 56.0}
{"epoch": 17, "training_loss": 0.6923133707046509, "training_acc": 52.0, "val_loss": 0.688800356388092, "val_acc": 56.0}
{"epoch": 18, "training_loss": 0.6923757123947144, "training_acc": 52.0, "val_loss": 0.6889230060577393, "val_acc": 56.0}
{"epoch": 19, "training_loss": 0.6922533369064331, "training_acc": 52.0, "val_loss": 0.6891141557693481, "val_acc": 56.0}
{"epoch": 20, "training_loss": 0.6923383903503418, "training_acc": 52.0, "val_loss": 0.6891208243370056, "val_acc": 56.0}
{"epoch": 21, "training_loss": 0.6925307989120484, "training_acc": 52.0, "val_loss": 0.6891557455062867, "val_acc": 56.0}
{"epoch": 22, "training_loss": 0.692329089641571, "training_acc": 52.0, "val_loss": 0.6890918779373169, "val_acc": 56.0}
{"epoch": 23, "training_loss": 0.6924947929382325, "training_acc": 52.0, "val_loss": 0.6891446542739869, "val_acc": 56.0}
{"epoch": 24, "training_loss": 0.6924568033218383, "training_acc": 52.0, "val_loss": 0.6889974713325501, "val_acc": 56.0}
{"epoch": 25, "training_loss": 0.6924703788757324, "training_acc": 52.0, "val_loss": 0.6890546822547913, "val_acc": 56.0}
{"epoch": 26, "training_loss": 0.6924813175201416, "training_acc": 52.0, "val_loss": 0.6890415573120117, "val_acc": 56.0}
{"epoch": 27, "training_loss": 0.6922822284698487, "training_acc": 52.0, "val_loss": 0.6891149163246155, "val_acc": 56.0}
{"epoch": 28, "training_loss": 0.6922775793075562, "training_acc": 52.0, "val_loss": 0.689139986038208, "val_acc": 56.0}
{"epoch": 29, "training_loss": 0.6923005485534668, "training_acc": 52.0, "val_loss": 0.6890429186820984, "val_acc": 56.0}
{"epoch": 30, "training_loss": 0.6926091933250427, "training_acc": 52.0, "val_loss": 0.6887467384338379, "val_acc": 56.0}
{"epoch": 31, "training_loss": 0.6921860074996948, "training_acc": 52.0, "val_loss": 0.688610622882843, "val_acc": 56.0}
{"epoch": 32, "training_loss": 0.6923946380615235, "training_acc": 52.0, "val_loss": 0.6883127570152283, "val_acc": 56.0}
{"epoch": 33, "training_loss": 0.6924195742607117, "training_acc": 52.0, "val_loss": 0.6881567811965943, "val_acc": 56.0}
{"epoch": 34, "training_loss": 0.6924017238616943, "training_acc": 52.0, "val_loss": 0.6881791114807129, "val_acc": 56.0}
{"epoch": 35, "training_loss": 0.6925349926948547, "training_acc": 52.0, "val_loss": 0.6883054399490356, "val_acc": 56.0}
{"epoch": 36, "training_loss": 0.6924858832359314, "training_acc": 52.0, "val_loss": 0.6883043217658996, "val_acc": 56.0}
{"epoch": 37, "training_loss": 0.6924099731445312, "training_acc": 52.0, "val_loss": 0.6882598114013672, "val_acc": 56.0}
{"epoch": 38, "training_loss": 0.6925385904312134, "training_acc": 52.0, "val_loss": 0.6883136487007141, "val_acc": 56.0}
{"epoch": 39, "training_loss": 0.692313687801361, "training_acc": 52.0, "val_loss": 0.6883814072608948, "val_acc": 56.0}
{"epoch": 40, "training_loss": 0.6924351787567139, "training_acc": 52.0, "val_loss": 0.688546450138092, "val_acc": 56.0}
{"epoch": 41, "training_loss": 0.6924882864952088, "training_acc": 52.0, "val_loss": 0.6885941052436828, "val_acc": 56.0}
{"epoch": 42, "training_loss": 0.6922472643852234, "training_acc": 52.0, "val_loss": 0.6886319088935852, "val_acc": 56.0}
{"epoch": 43, "training_loss": 0.6923190426826477, "training_acc": 52.0, "val_loss": 0.6886784338951111, "val_acc": 56.0}
{"epoch": 44, "training_loss": 0.6922948598861695, "training_acc": 52.0, "val_loss": 0.6889093089103698, "val_acc": 56.0}
{"epoch": 45, "training_loss": 0.6922802686691284, "training_acc": 52.0, "val_loss": 0.6889890623092652, "val_acc": 56.0}
{"epoch": 46, "training_loss": 0.6925590085983276, "training_acc": 52.0, "val_loss": 0.6890312242507934, "val_acc": 56.0}
{"epoch": 47, "training_loss": 0.692453920841217, "training_acc": 52.0, "val_loss": 0.6889917159080505, "val_acc": 56.0}
{"epoch": 48, "training_loss": 0.6924084305763245, "training_acc": 52.0, "val_loss": 0.6889456105232239, "val_acc": 56.0}
{"epoch": 49, "training_loss": 0.6923164796829223, "training_acc": 52.0, "val_loss": 0.6890221881866455, "val_acc": 56.0}
{"epoch": 50, "training_loss": 0.6923884272575378, "training_acc": 52.0, "val_loss": 0.6892253375053405, "val_acc": 56.0}
{"epoch": 51, "training_loss": 0.6923003220558166, "training_acc": 52.0, "val_loss": 0.6894427680969238, "val_acc": 56.0}
{"epoch": 52, "training_loss": 0.6924824333190918, "training_acc": 52.0, "val_loss": 0.6897018480300904, "val_acc": 56.0}
