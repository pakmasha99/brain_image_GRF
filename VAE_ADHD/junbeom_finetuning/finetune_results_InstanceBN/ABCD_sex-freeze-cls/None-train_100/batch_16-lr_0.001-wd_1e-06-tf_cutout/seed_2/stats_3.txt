"main_modify.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 2 --task ABCD_sex --input_option BT_org --learning_rate 1e-3 --batch_size 16 --weight_decay 1e-6 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 0.7035086703300476, "training_acc": 49.0, "val_loss": 0.6942739987373352, "val_acc": 48.0}
{"epoch": 1, "training_loss": 0.7051044893264771, "training_acc": 47.0, "val_loss": 0.6924335789680481, "val_acc": 52.0}
{"epoch": 2, "training_loss": 0.7024155807495117, "training_acc": 53.0, "val_loss": 0.7166993832588195, "val_acc": 52.0}
{"epoch": 3, "training_loss": 0.7036513566970826, "training_acc": 53.0, "val_loss": 0.6924128055572509, "val_acc": 52.0}
{"epoch": 4, "training_loss": 0.6935470867156982, "training_acc": 53.0, "val_loss": 0.6924866437911987, "val_acc": 52.0}
{"epoch": 5, "training_loss": 0.6957881283760071, "training_acc": 53.0, "val_loss": 0.6973705124855042, "val_acc": 52.0}
{"epoch": 6, "training_loss": 0.705836980342865, "training_acc": 53.0, "val_loss": 0.6994450688362122, "val_acc": 52.0}
{"epoch": 7, "training_loss": 0.6985244345664978, "training_acc": 53.0, "val_loss": 0.6925767087936401, "val_acc": 52.0}
{"epoch": 8, "training_loss": 0.6932120895385743, "training_acc": 53.0, "val_loss": 0.6925663447380066, "val_acc": 52.0}
{"epoch": 9, "training_loss": 0.6948489093780518, "training_acc": 53.0, "val_loss": 0.693032374382019, "val_acc": 52.0}
{"epoch": 10, "training_loss": 0.6919996118545533, "training_acc": 53.0, "val_loss": 0.6964047431945801, "val_acc": 52.0}
{"epoch": 11, "training_loss": 0.7002464413642884, "training_acc": 53.0, "val_loss": 0.6937160682678223, "val_acc": 52.0}
{"epoch": 12, "training_loss": 0.7010473442077637, "training_acc": 48.0, "val_loss": 0.6930904626846314, "val_acc": 52.0}
{"epoch": 13, "training_loss": 0.7069798946380615, "training_acc": 53.0, "val_loss": 0.7085836458206177, "val_acc": 52.0}
{"epoch": 14, "training_loss": 0.7205682110786438, "training_acc": 45.0, "val_loss": 0.7015986371040345, "val_acc": 48.0}
{"epoch": 15, "training_loss": 0.6963472771644592, "training_acc": 49.0, "val_loss": 0.6985609102249145, "val_acc": 52.0}
{"epoch": 16, "training_loss": 0.6997796249389648, "training_acc": 53.0, "val_loss": 0.6955248188972473, "val_acc": 52.0}
{"epoch": 17, "training_loss": 0.7009667730331421, "training_acc": 45.0, "val_loss": 0.6936886525154113, "val_acc": 48.0}
{"epoch": 18, "training_loss": 0.699408483505249, "training_acc": 45.0, "val_loss": 0.6958763265609741, "val_acc": 52.0}
{"epoch": 19, "training_loss": 0.697030303478241, "training_acc": 53.0, "val_loss": 0.6958733963966369, "val_acc": 52.0}
{"epoch": 20, "training_loss": 0.7000185298919678, "training_acc": 53.0, "val_loss": 0.6926177334785462, "val_acc": 52.0}
{"epoch": 21, "training_loss": 0.7178213405609131, "training_acc": 47.0, "val_loss": 0.7076945090293885, "val_acc": 48.0}
{"epoch": 22, "training_loss": 0.7024922871589661, "training_acc": 51.0, "val_loss": 0.7066884851455688, "val_acc": 52.0}
{"epoch": 23, "training_loss": 0.6965382051467895, "training_acc": 53.0, "val_loss": 0.6923982977867127, "val_acc": 52.0}
{"epoch": 24, "training_loss": 0.6958366203308105, "training_acc": 45.0, "val_loss": 0.6924172782897949, "val_acc": 52.0}
{"epoch": 25, "training_loss": 0.695658450126648, "training_acc": 53.0, "val_loss": 0.6933375358581543, "val_acc": 52.0}
{"epoch": 26, "training_loss": 0.6905114126205444, "training_acc": 53.0, "val_loss": 0.6949061369895935, "val_acc": 48.0}
{"epoch": 27, "training_loss": 0.694379472732544, "training_acc": 51.0, "val_loss": 0.6981391763687134, "val_acc": 52.0}
{"epoch": 28, "training_loss": 0.6967410373687745, "training_acc": 53.0, "val_loss": 0.6951305079460144, "val_acc": 52.0}
{"epoch": 29, "training_loss": 0.69661865234375, "training_acc": 53.0, "val_loss": 0.6925893712043762, "val_acc": 52.0}
{"epoch": 30, "training_loss": 0.6951613116264344, "training_acc": 53.0, "val_loss": 0.6930355262756348, "val_acc": 52.0}
{"epoch": 31, "training_loss": 0.6939202737808228, "training_acc": 53.0, "val_loss": 0.6948975372314453, "val_acc": 52.0}
{"epoch": 32, "training_loss": 0.6935471081733704, "training_acc": 53.0, "val_loss": 0.6926134490966797, "val_acc": 52.0}
{"epoch": 33, "training_loss": 0.7031584095954895, "training_acc": 53.0, "val_loss": 0.692834985256195, "val_acc": 52.0}
{"epoch": 34, "training_loss": 0.6929026269912719, "training_acc": 51.0, "val_loss": 0.6948373150825501, "val_acc": 48.0}
{"epoch": 35, "training_loss": 0.698180820941925, "training_acc": 43.0, "val_loss": 0.6941939544677734, "val_acc": 52.0}
{"epoch": 36, "training_loss": 0.6943731737136841, "training_acc": 53.0, "val_loss": 0.6939425706863404, "val_acc": 52.0}
{"epoch": 37, "training_loss": 0.7050159406661988, "training_acc": 43.0, "val_loss": 0.6979230618476868, "val_acc": 48.0}
{"epoch": 38, "training_loss": 0.6928459668159485, "training_acc": 49.0, "val_loss": 0.6991194653511047, "val_acc": 52.0}
{"epoch": 39, "training_loss": 0.697164602279663, "training_acc": 53.0, "val_loss": 0.694464340209961, "val_acc": 52.0}
{"epoch": 40, "training_loss": 0.7000586605072021, "training_acc": 45.0, "val_loss": 0.6950961470603942, "val_acc": 48.0}
{"epoch": 41, "training_loss": 0.695285747051239, "training_acc": 47.0, "val_loss": 0.6938045835494995, "val_acc": 52.0}
{"epoch": 42, "training_loss": 0.6940983128547669, "training_acc": 53.0, "val_loss": 0.6941121172904968, "val_acc": 52.0}
