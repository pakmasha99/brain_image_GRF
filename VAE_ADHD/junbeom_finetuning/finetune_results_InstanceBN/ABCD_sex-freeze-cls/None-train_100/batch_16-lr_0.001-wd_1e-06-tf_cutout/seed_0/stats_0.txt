"main_modify.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option BT_org --learning_rate 1e-3 --batch_size 16 --weight_decay 1e-6 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 0.7093289017677307, "training_acc": 46.0, "val_loss": 0.6966032028198242, "val_acc": 44.0}
{"epoch": 1, "training_loss": 0.6996253275871277, "training_acc": 48.0, "val_loss": 0.6862155485153199, "val_acc": 56.0}
{"epoch": 2, "training_loss": 0.6987173676490783, "training_acc": 44.0, "val_loss": 0.6914552617073059, "val_acc": 56.0}
{"epoch": 3, "training_loss": 0.702793984413147, "training_acc": 52.0, "val_loss": 0.6865316390991211, "val_acc": 56.0}
{"epoch": 4, "training_loss": 0.701865394115448, "training_acc": 50.0, "val_loss": 0.7042995429039002, "val_acc": 44.0}
{"epoch": 5, "training_loss": 0.6977102851867676, "training_acc": 49.0, "val_loss": 0.6857939076423645, "val_acc": 56.0}
{"epoch": 6, "training_loss": 0.6965577363967895, "training_acc": 52.0, "val_loss": 0.6870988655090332, "val_acc": 56.0}
{"epoch": 7, "training_loss": 0.7015136480331421, "training_acc": 44.0, "val_loss": 0.6967040705680847, "val_acc": 44.0}
{"epoch": 8, "training_loss": 0.7071677231788636, "training_acc": 46.0, "val_loss": 0.6858170795440673, "val_acc": 56.0}
{"epoch": 9, "training_loss": 0.6991382932662964, "training_acc": 44.0, "val_loss": 0.7012473797798157, "val_acc": 44.0}
{"epoch": 10, "training_loss": 0.7067092680931091, "training_acc": 48.0, "val_loss": 0.701134877204895, "val_acc": 44.0}
{"epoch": 11, "training_loss": 0.6925315809249878, "training_acc": 54.0, "val_loss": 0.6892856931686402, "val_acc": 56.0}
{"epoch": 12, "training_loss": 0.7371936893463135, "training_acc": 52.0, "val_loss": 0.6883309197425842, "val_acc": 56.0}
{"epoch": 13, "training_loss": 0.7149384641647338, "training_acc": 46.0, "val_loss": 0.7157466506958008, "val_acc": 44.0}
{"epoch": 14, "training_loss": 0.6963976120948792, "training_acc": 52.0, "val_loss": 0.6859702181816101, "val_acc": 56.0}
{"epoch": 15, "training_loss": 0.6972078037261963, "training_acc": 52.0, "val_loss": 0.6858234143257141, "val_acc": 56.0}
{"epoch": 16, "training_loss": 0.7077856302261353, "training_acc": 52.0, "val_loss": 0.6862741804122925, "val_acc": 56.0}
{"epoch": 17, "training_loss": 0.7005765533447266, "training_acc": 48.0, "val_loss": 0.7256299781799317, "val_acc": 44.0}
{"epoch": 18, "training_loss": 0.7114034271240235, "training_acc": 48.0, "val_loss": 0.6971892762184143, "val_acc": 44.0}
{"epoch": 19, "training_loss": 0.6951899099349975, "training_acc": 48.0, "val_loss": 0.6862103772163392, "val_acc": 56.0}
{"epoch": 20, "training_loss": 0.6975230693817138, "training_acc": 52.0, "val_loss": 0.6857742261886597, "val_acc": 56.0}
{"epoch": 21, "training_loss": 0.7004623222351074, "training_acc": 46.0, "val_loss": 0.6955079412460328, "val_acc": 44.0}
{"epoch": 22, "training_loss": 0.700044927597046, "training_acc": 46.0, "val_loss": 0.68814049243927, "val_acc": 56.0}
{"epoch": 23, "training_loss": 0.691800343990326, "training_acc": 54.0, "val_loss": 0.6940311503410339, "val_acc": 44.0}
{"epoch": 24, "training_loss": 0.7056426072120666, "training_acc": 48.0, "val_loss": 0.6858439517021179, "val_acc": 56.0}
{"epoch": 25, "training_loss": 0.6930826616287231, "training_acc": 48.0, "val_loss": 0.708685405254364, "val_acc": 44.0}
{"epoch": 26, "training_loss": 0.7093748497962952, "training_acc": 38.0, "val_loss": 0.690122103691101, "val_acc": 56.0}
{"epoch": 27, "training_loss": 0.6955338621139526, "training_acc": 52.0, "val_loss": 0.6906922650337219, "val_acc": 56.0}
{"epoch": 28, "training_loss": 0.6968397712707519, "training_acc": 51.0, "val_loss": 0.6881150197982788, "val_acc": 56.0}
{"epoch": 29, "training_loss": 0.6958559775352477, "training_acc": 52.0, "val_loss": 0.6858121347427368, "val_acc": 56.0}
{"epoch": 30, "training_loss": 0.7165258359909058, "training_acc": 52.0, "val_loss": 0.6870319962501525, "val_acc": 56.0}
{"epoch": 31, "training_loss": 0.7082628750801087, "training_acc": 43.0, "val_loss": 0.6953101015090942, "val_acc": 44.0}
{"epoch": 32, "training_loss": 0.6990101909637452, "training_acc": 52.0, "val_loss": 0.6884626841545105, "val_acc": 56.0}
{"epoch": 33, "training_loss": 0.7029378461837769, "training_acc": 52.0, "val_loss": 0.6882798886299133, "val_acc": 56.0}
{"epoch": 34, "training_loss": 0.6966618776321412, "training_acc": 46.0, "val_loss": 0.7116838431358338, "val_acc": 44.0}
{"epoch": 35, "training_loss": 0.7026301217079163, "training_acc": 48.0, "val_loss": 0.6926135301589966, "val_acc": 56.0}
{"epoch": 36, "training_loss": 0.6975611615180969, "training_acc": 52.0, "val_loss": 0.6880268430709839, "val_acc": 56.0}
{"epoch": 37, "training_loss": 0.7061415481567382, "training_acc": 52.0, "val_loss": 0.6873273277282714, "val_acc": 56.0}
{"epoch": 38, "training_loss": 0.707610502243042, "training_acc": 44.0, "val_loss": 0.7043074774742126, "val_acc": 44.0}
{"epoch": 39, "training_loss": 0.6984832406044006, "training_acc": 44.0, "val_loss": 0.6890576338768005, "val_acc": 56.0}
