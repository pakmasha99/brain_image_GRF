"main_modify.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 2 --task ABCD_sex --input_option BT_org --learning_rate 1e-3 --batch_size 16 --weight_decay 1e-5 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 0.7035086774826049, "training_acc": 49.0, "val_loss": 0.6942739987373352, "val_acc": 48.0}
{"epoch": 1, "training_loss": 0.7051044988632202, "training_acc": 47.0, "val_loss": 0.6924335789680481, "val_acc": 52.0}
{"epoch": 2, "training_loss": 0.7024155735969544, "training_acc": 53.0, "val_loss": 0.7166994214057922, "val_acc": 52.0}
{"epoch": 3, "training_loss": 0.7036513376235962, "training_acc": 53.0, "val_loss": 0.6924128055572509, "val_acc": 52.0}
{"epoch": 4, "training_loss": 0.6935470843315125, "training_acc": 53.0, "val_loss": 0.6924866652488708, "val_acc": 52.0}
{"epoch": 5, "training_loss": 0.6957881212234497, "training_acc": 53.0, "val_loss": 0.6973705124855042, "val_acc": 52.0}
{"epoch": 6, "training_loss": 0.7058369612693787, "training_acc": 53.0, "val_loss": 0.6994451069831848, "val_acc": 52.0}
{"epoch": 7, "training_loss": 0.6985244369506836, "training_acc": 53.0, "val_loss": 0.6925767087936401, "val_acc": 52.0}
{"epoch": 8, "training_loss": 0.6932120990753173, "training_acc": 53.0, "val_loss": 0.6925663447380066, "val_acc": 52.0}
{"epoch": 9, "training_loss": 0.6948488926887513, "training_acc": 53.0, "val_loss": 0.693032374382019, "val_acc": 52.0}
{"epoch": 10, "training_loss": 0.6919995927810669, "training_acc": 53.0, "val_loss": 0.6964047265052795, "val_acc": 52.0}
{"epoch": 11, "training_loss": 0.7002464485168457, "training_acc": 53.0, "val_loss": 0.6937160682678223, "val_acc": 52.0}
{"epoch": 12, "training_loss": 0.70104736328125, "training_acc": 48.0, "val_loss": 0.6930904412269592, "val_acc": 52.0}
{"epoch": 13, "training_loss": 0.7069798851013184, "training_acc": 53.0, "val_loss": 0.708583607673645, "val_acc": 52.0}
{"epoch": 14, "training_loss": 0.7205682015419006, "training_acc": 45.0, "val_loss": 0.7015986371040345, "val_acc": 48.0}
{"epoch": 15, "training_loss": 0.6963472890853882, "training_acc": 49.0, "val_loss": 0.6985609102249145, "val_acc": 52.0}
{"epoch": 16, "training_loss": 0.6997796416282653, "training_acc": 53.0, "val_loss": 0.69552485704422, "val_acc": 52.0}
{"epoch": 17, "training_loss": 0.7009667992591858, "training_acc": 45.0, "val_loss": 0.6936885929107666, "val_acc": 48.0}
{"epoch": 18, "training_loss": 0.6994085121154785, "training_acc": 45.0, "val_loss": 0.695876305103302, "val_acc": 52.0}
{"epoch": 19, "training_loss": 0.697030303478241, "training_acc": 53.0, "val_loss": 0.6958733963966369, "val_acc": 52.0}
{"epoch": 20, "training_loss": 0.7000185298919678, "training_acc": 53.0, "val_loss": 0.6926177120208741, "val_acc": 52.0}
{"epoch": 21, "training_loss": 0.7178213286399842, "training_acc": 47.0, "val_loss": 0.7076944541931153, "val_acc": 48.0}
{"epoch": 22, "training_loss": 0.7024922800064087, "training_acc": 51.0, "val_loss": 0.7066884636878967, "val_acc": 52.0}
{"epoch": 23, "training_loss": 0.6965381979942322, "training_acc": 53.0, "val_loss": 0.6923982644081116, "val_acc": 52.0}
{"epoch": 24, "training_loss": 0.6958366298675537, "training_acc": 45.0, "val_loss": 0.6924172782897949, "val_acc": 52.0}
{"epoch": 25, "training_loss": 0.695658438205719, "training_acc": 53.0, "val_loss": 0.6933375525474549, "val_acc": 52.0}
{"epoch": 26, "training_loss": 0.6905113983154297, "training_acc": 53.0, "val_loss": 0.6949061369895935, "val_acc": 48.0}
{"epoch": 27, "training_loss": 0.6943794751167297, "training_acc": 51.0, "val_loss": 0.6981391763687134, "val_acc": 52.0}
{"epoch": 28, "training_loss": 0.6967410492897034, "training_acc": 53.0, "val_loss": 0.6951305079460144, "val_acc": 52.0}
{"epoch": 29, "training_loss": 0.69661865234375, "training_acc": 53.0, "val_loss": 0.6925893712043762, "val_acc": 52.0}
{"epoch": 30, "training_loss": 0.6951613116264344, "training_acc": 53.0, "val_loss": 0.6930355048179626, "val_acc": 52.0}
{"epoch": 31, "training_loss": 0.6939202642440796, "training_acc": 53.0, "val_loss": 0.6948975372314453, "val_acc": 52.0}
{"epoch": 32, "training_loss": 0.693547101020813, "training_acc": 53.0, "val_loss": 0.6926134490966797, "val_acc": 52.0}
{"epoch": 33, "training_loss": 0.7031584191322326, "training_acc": 53.0, "val_loss": 0.692834985256195, "val_acc": 52.0}
{"epoch": 34, "training_loss": 0.6929026103019714, "training_acc": 51.0, "val_loss": 0.6948372769355774, "val_acc": 48.0}
{"epoch": 35, "training_loss": 0.6981808233261109, "training_acc": 43.0, "val_loss": 0.6941939544677734, "val_acc": 52.0}
{"epoch": 36, "training_loss": 0.694373164176941, "training_acc": 53.0, "val_loss": 0.6939425706863404, "val_acc": 52.0}
{"epoch": 37, "training_loss": 0.7050159549713135, "training_acc": 43.0, "val_loss": 0.6979230618476868, "val_acc": 48.0}
{"epoch": 38, "training_loss": 0.6928460121154785, "training_acc": 49.0, "val_loss": 0.6991194653511047, "val_acc": 52.0}
{"epoch": 39, "training_loss": 0.6971645832061768, "training_acc": 53.0, "val_loss": 0.694464340209961, "val_acc": 52.0}
{"epoch": 40, "training_loss": 0.7000586605072021, "training_acc": 45.0, "val_loss": 0.6950961852073669, "val_acc": 48.0}
{"epoch": 41, "training_loss": 0.6952857375144958, "training_acc": 47.0, "val_loss": 0.6938045835494995, "val_acc": 52.0}
{"epoch": 42, "training_loss": 0.6940982627868653, "training_acc": 53.0, "val_loss": 0.6941120958328247, "val_acc": 52.0}
