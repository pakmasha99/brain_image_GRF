"main_modify.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 2 --task ABCD_sex --input_option BT_org --learning_rate 1e-3 --batch_size 16 --weight_decay 1e-4 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 0.7035086512565613, "training_acc": 49.0, "val_loss": 0.6942739987373352, "val_acc": 48.0}
{"epoch": 1, "training_loss": 0.7051044702529907, "training_acc": 47.0, "val_loss": 0.6924335789680481, "val_acc": 52.0}
{"epoch": 2, "training_loss": 0.702415623664856, "training_acc": 53.0, "val_loss": 0.71669926404953, "val_acc": 52.0}
{"epoch": 3, "training_loss": 0.7036512017250061, "training_acc": 53.0, "val_loss": 0.69241281747818, "val_acc": 52.0}
{"epoch": 4, "training_loss": 0.6935471057891845, "training_acc": 53.0, "val_loss": 0.6924866485595703, "val_acc": 52.0}
{"epoch": 5, "training_loss": 0.6957881546020508, "training_acc": 53.0, "val_loss": 0.6973705124855042, "val_acc": 52.0}
{"epoch": 6, "training_loss": 0.7058369064331055, "training_acc": 53.0, "val_loss": 0.6994450044631958, "val_acc": 52.0}
{"epoch": 7, "training_loss": 0.6985243892669678, "training_acc": 53.0, "val_loss": 0.6925767087936401, "val_acc": 52.0}
{"epoch": 8, "training_loss": 0.6932120728492737, "training_acc": 53.0, "val_loss": 0.6925663447380066, "val_acc": 52.0}
{"epoch": 9, "training_loss": 0.6948489260673523, "training_acc": 53.0, "val_loss": 0.6930323362350463, "val_acc": 52.0}
{"epoch": 10, "training_loss": 0.6919996023178101, "training_acc": 53.0, "val_loss": 0.6964046669006347, "val_acc": 52.0}
{"epoch": 11, "training_loss": 0.7002464199066162, "training_acc": 53.0, "val_loss": 0.6937160682678223, "val_acc": 52.0}
{"epoch": 12, "training_loss": 0.7010473370552063, "training_acc": 48.0, "val_loss": 0.6930904197692871, "val_acc": 52.0}
{"epoch": 13, "training_loss": 0.7069798564910889, "training_acc": 53.0, "val_loss": 0.708583607673645, "val_acc": 52.0}
{"epoch": 14, "training_loss": 0.7205682039260864, "training_acc": 45.0, "val_loss": 0.7015987014770508, "val_acc": 48.0}
{"epoch": 15, "training_loss": 0.6963472795486451, "training_acc": 49.0, "val_loss": 0.6985609483718872, "val_acc": 52.0}
{"epoch": 16, "training_loss": 0.6997796416282653, "training_acc": 53.0, "val_loss": 0.6955248022079468, "val_acc": 52.0}
{"epoch": 17, "training_loss": 0.7009668660163879, "training_acc": 45.0, "val_loss": 0.6936886310577393, "val_acc": 48.0}
{"epoch": 18, "training_loss": 0.6994085478782653, "training_acc": 45.0, "val_loss": 0.6958763813972473, "val_acc": 52.0}
{"epoch": 19, "training_loss": 0.6970302820205688, "training_acc": 53.0, "val_loss": 0.6958733534812928, "val_acc": 52.0}
{"epoch": 20, "training_loss": 0.7000184988975525, "training_acc": 53.0, "val_loss": 0.6926177120208741, "val_acc": 52.0}
{"epoch": 21, "training_loss": 0.7178213119506835, "training_acc": 47.0, "val_loss": 0.7076943826675415, "val_acc": 48.0}
{"epoch": 22, "training_loss": 0.7024922370910645, "training_acc": 51.0, "val_loss": 0.7066884970664978, "val_acc": 52.0}
{"epoch": 23, "training_loss": 0.6965381693840027, "training_acc": 53.0, "val_loss": 0.6923982691764832, "val_acc": 52.0}
{"epoch": 24, "training_loss": 0.695836718082428, "training_acc": 45.0, "val_loss": 0.6924172186851502, "val_acc": 52.0}
{"epoch": 25, "training_loss": 0.695658438205719, "training_acc": 53.0, "val_loss": 0.6933375096321106, "val_acc": 52.0}
{"epoch": 26, "training_loss": 0.6905114197731018, "training_acc": 53.0, "val_loss": 0.6949061322212219, "val_acc": 48.0}
{"epoch": 27, "training_loss": 0.6943794345855713, "training_acc": 51.0, "val_loss": 0.6981391549110413, "val_acc": 52.0}
{"epoch": 28, "training_loss": 0.6967410182952881, "training_acc": 53.0, "val_loss": 0.6951304745674133, "val_acc": 52.0}
{"epoch": 29, "training_loss": 0.6966187191009522, "training_acc": 53.0, "val_loss": 0.6925893330574036, "val_acc": 52.0}
{"epoch": 30, "training_loss": 0.6951613116264344, "training_acc": 53.0, "val_loss": 0.693035569190979, "val_acc": 52.0}
{"epoch": 31, "training_loss": 0.6939202260971069, "training_acc": 53.0, "val_loss": 0.6948975157737732, "val_acc": 52.0}
{"epoch": 32, "training_loss": 0.6935471677780152, "training_acc": 53.0, "val_loss": 0.6926134490966797, "val_acc": 52.0}
{"epoch": 33, "training_loss": 0.7031585049629211, "training_acc": 53.0, "val_loss": 0.6928349637985229, "val_acc": 52.0}
{"epoch": 34, "training_loss": 0.6929027175903321, "training_acc": 51.0, "val_loss": 0.6948372602462769, "val_acc": 48.0}
{"epoch": 35, "training_loss": 0.6981808471679688, "training_acc": 43.0, "val_loss": 0.6941939544677734, "val_acc": 52.0}
{"epoch": 36, "training_loss": 0.6943732070922851, "training_acc": 53.0, "val_loss": 0.6939425277709961, "val_acc": 52.0}
{"epoch": 37, "training_loss": 0.705015959739685, "training_acc": 43.0, "val_loss": 0.6979229855537414, "val_acc": 48.0}
{"epoch": 38, "training_loss": 0.692846131324768, "training_acc": 49.0, "val_loss": 0.6991194438934326, "val_acc": 52.0}
{"epoch": 39, "training_loss": 0.6971646165847778, "training_acc": 53.0, "val_loss": 0.6944643020629883, "val_acc": 52.0}
{"epoch": 40, "training_loss": 0.7000586891174316, "training_acc": 45.0, "val_loss": 0.6950961422920227, "val_acc": 48.0}
{"epoch": 41, "training_loss": 0.6952856659889222, "training_acc": 47.0, "val_loss": 0.6938045907020569, "val_acc": 52.0}
{"epoch": 42, "training_loss": 0.6940982437133789, "training_acc": 53.0, "val_loss": 0.6941120958328247, "val_acc": 52.0}
