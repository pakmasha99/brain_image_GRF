"main_modify.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option BT_org --learning_rate 1e-3 --batch_size 16 --weight_decay 1e-4 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 0.7093289017677307, "training_acc": 46.0, "val_loss": 0.6966032028198242, "val_acc": 44.0}
{"epoch": 1, "training_loss": 0.6996253395080566, "training_acc": 48.0, "val_loss": 0.6862155270576477, "val_acc": 56.0}
{"epoch": 2, "training_loss": 0.6987173819541931, "training_acc": 44.0, "val_loss": 0.6914552617073059, "val_acc": 56.0}
{"epoch": 3, "training_loss": 0.7027940130233765, "training_acc": 52.0, "val_loss": 0.6865316009521485, "val_acc": 56.0}
{"epoch": 4, "training_loss": 0.701865382194519, "training_acc": 50.0, "val_loss": 0.7042995810508728, "val_acc": 44.0}
{"epoch": 5, "training_loss": 0.6977102684974671, "training_acc": 49.0, "val_loss": 0.6857938694953919, "val_acc": 56.0}
{"epoch": 6, "training_loss": 0.6965577268600464, "training_acc": 52.0, "val_loss": 0.6870988869667053, "val_acc": 56.0}
{"epoch": 7, "training_loss": 0.7015136909484864, "training_acc": 44.0, "val_loss": 0.6967040920257568, "val_acc": 44.0}
{"epoch": 8, "training_loss": 0.7071677160263061, "training_acc": 46.0, "val_loss": 0.6858171010017395, "val_acc": 56.0}
{"epoch": 9, "training_loss": 0.699138298034668, "training_acc": 44.0, "val_loss": 0.7012474012374877, "val_acc": 44.0}
{"epoch": 10, "training_loss": 0.7067092967033386, "training_acc": 48.0, "val_loss": 0.7011348557472229, "val_acc": 44.0}
{"epoch": 11, "training_loss": 0.6925315952301025, "training_acc": 54.0, "val_loss": 0.6892857313156128, "val_acc": 56.0}
{"epoch": 12, "training_loss": 0.7371934986114502, "training_acc": 52.0, "val_loss": 0.6883308529853821, "val_acc": 56.0}
{"epoch": 13, "training_loss": 0.7149384832382202, "training_acc": 46.0, "val_loss": 0.7157467103004456, "val_acc": 44.0}
{"epoch": 14, "training_loss": 0.6963975858688355, "training_acc": 52.0, "val_loss": 0.6859701585769653, "val_acc": 56.0}
{"epoch": 15, "training_loss": 0.6972079110145569, "training_acc": 52.0, "val_loss": 0.6858234238624573, "val_acc": 56.0}
{"epoch": 16, "training_loss": 0.7077855110168457, "training_acc": 52.0, "val_loss": 0.6862741589546204, "val_acc": 56.0}
{"epoch": 17, "training_loss": 0.7005765676498413, "training_acc": 48.0, "val_loss": 0.7256299352645874, "val_acc": 44.0}
{"epoch": 18, "training_loss": 0.711403353214264, "training_acc": 48.0, "val_loss": 0.6971891450881958, "val_acc": 44.0}
{"epoch": 19, "training_loss": 0.6951898765563965, "training_acc": 48.0, "val_loss": 0.6862103772163392, "val_acc": 56.0}
{"epoch": 20, "training_loss": 0.6975230050086975, "training_acc": 52.0, "val_loss": 0.6857742738723754, "val_acc": 56.0}
{"epoch": 21, "training_loss": 0.7004622864723206, "training_acc": 46.0, "val_loss": 0.6955079579353333, "val_acc": 44.0}
{"epoch": 22, "training_loss": 0.7000448608398437, "training_acc": 46.0, "val_loss": 0.6881405639648438, "val_acc": 56.0}
{"epoch": 23, "training_loss": 0.6918003845214844, "training_acc": 54.0, "val_loss": 0.6940311884880066, "val_acc": 44.0}
{"epoch": 24, "training_loss": 0.7056425261497498, "training_acc": 48.0, "val_loss": 0.685843985080719, "val_acc": 56.0}
{"epoch": 25, "training_loss": 0.6930826807022095, "training_acc": 48.0, "val_loss": 0.7086855030059814, "val_acc": 44.0}
{"epoch": 26, "training_loss": 0.7093748331069947, "training_acc": 38.0, "val_loss": 0.6901221203804017, "val_acc": 56.0}
{"epoch": 27, "training_loss": 0.695533857345581, "training_acc": 52.0, "val_loss": 0.690692286491394, "val_acc": 56.0}
{"epoch": 28, "training_loss": 0.6968398070335389, "training_acc": 51.0, "val_loss": 0.688115074634552, "val_acc": 56.0}
{"epoch": 29, "training_loss": 0.6958559846878052, "training_acc": 52.0, "val_loss": 0.6858121562004089, "val_acc": 56.0}
{"epoch": 30, "training_loss": 0.7165258264541626, "training_acc": 52.0, "val_loss": 0.6870320057868957, "val_acc": 56.0}
{"epoch": 31, "training_loss": 0.7082629060745239, "training_acc": 43.0, "val_loss": 0.6953102207183838, "val_acc": 44.0}
{"epoch": 32, "training_loss": 0.6990102672576904, "training_acc": 52.0, "val_loss": 0.6884627270698548, "val_acc": 56.0}
{"epoch": 33, "training_loss": 0.7029378676414489, "training_acc": 52.0, "val_loss": 0.6882800030708313, "val_acc": 56.0}
{"epoch": 34, "training_loss": 0.6966618871688843, "training_acc": 46.0, "val_loss": 0.7116838645935059, "val_acc": 44.0}
{"epoch": 35, "training_loss": 0.7026301527023315, "training_acc": 48.0, "val_loss": 0.6926135087013244, "val_acc": 56.0}
{"epoch": 36, "training_loss": 0.6975611925125123, "training_acc": 52.0, "val_loss": 0.6880268430709839, "val_acc": 56.0}
{"epoch": 37, "training_loss": 0.7061414241790771, "training_acc": 52.0, "val_loss": 0.6873274087905884, "val_acc": 56.0}
{"epoch": 38, "training_loss": 0.7076104545593261, "training_acc": 44.0, "val_loss": 0.7043075323104858, "val_acc": 44.0}
{"epoch": 39, "training_loss": 0.6984831333160401, "training_acc": 44.0, "val_loss": 0.6890576124191284, "val_acc": 56.0}
