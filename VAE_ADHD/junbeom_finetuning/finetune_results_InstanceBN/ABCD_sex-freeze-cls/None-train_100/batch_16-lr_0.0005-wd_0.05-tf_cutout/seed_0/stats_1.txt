"main_modify.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option BT_org --learning_rate 5e-4 --batch_size 16 --weight_decay 5e-2 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 0.6895664405822753, "training_acc": 55.0, "val_loss": 0.7022917532920837, "val_acc": 52.0}
{"epoch": 1, "training_loss": 0.7222146248817444, "training_acc": 53.0, "val_loss": 0.7223267483711243, "val_acc": 52.0}
{"epoch": 2, "training_loss": 0.7155923962593078, "training_acc": 53.0, "val_loss": 0.6929150748252869, "val_acc": 52.0}
{"epoch": 3, "training_loss": 0.6942290258407593, "training_acc": 53.0, "val_loss": 0.6924706983566284, "val_acc": 52.0}
{"epoch": 4, "training_loss": 0.6944908761978149, "training_acc": 53.0, "val_loss": 0.6924971556663513, "val_acc": 52.0}
{"epoch": 5, "training_loss": 0.6939654135704041, "training_acc": 50.0, "val_loss": 0.6924293637275696, "val_acc": 52.0}
{"epoch": 6, "training_loss": 0.6955279207229614, "training_acc": 53.0, "val_loss": 0.6953672409057617, "val_acc": 52.0}
{"epoch": 7, "training_loss": 0.6947988653182984, "training_acc": 53.0, "val_loss": 0.6938680362701416, "val_acc": 52.0}
{"epoch": 8, "training_loss": 0.6964300203323365, "training_acc": 49.0, "val_loss": 0.6971613955497742, "val_acc": 48.0}
{"epoch": 9, "training_loss": 0.699842677116394, "training_acc": 41.0, "val_loss": 0.6924726390838623, "val_acc": 52.0}
{"epoch": 10, "training_loss": 0.6933345222473144, "training_acc": 53.0, "val_loss": 0.6929989337921143, "val_acc": 52.0}
{"epoch": 11, "training_loss": 0.6942221021652222, "training_acc": 53.0, "val_loss": 0.693559684753418, "val_acc": 52.0}
{"epoch": 12, "training_loss": 0.6951715421676635, "training_acc": 53.0, "val_loss": 0.6989504265785217, "val_acc": 52.0}
{"epoch": 13, "training_loss": 0.6943278741836548, "training_acc": 53.0, "val_loss": 0.6932916569709778, "val_acc": 52.0}
{"epoch": 14, "training_loss": 0.7005965089797974, "training_acc": 37.0, "val_loss": 0.6944972157478333, "val_acc": 48.0}
{"epoch": 15, "training_loss": 0.6972090148925781, "training_acc": 45.0, "val_loss": 0.69248131275177, "val_acc": 52.0}
{"epoch": 16, "training_loss": 0.6980424118041992, "training_acc": 53.0, "val_loss": 0.6946243286132813, "val_acc": 52.0}
{"epoch": 17, "training_loss": 0.6952189493179322, "training_acc": 53.0, "val_loss": 0.6942775416374206, "val_acc": 52.0}
{"epoch": 18, "training_loss": 0.694881649017334, "training_acc": 53.0, "val_loss": 0.6923837614059448, "val_acc": 52.0}
{"epoch": 19, "training_loss": 0.6929083085060119, "training_acc": 53.0, "val_loss": 0.6930066466331481, "val_acc": 52.0}
{"epoch": 20, "training_loss": 0.6922405982017517, "training_acc": 53.0, "val_loss": 0.6928061985969544, "val_acc": 52.0}
{"epoch": 21, "training_loss": 0.6962163710594177, "training_acc": 53.0, "val_loss": 0.6925309729576111, "val_acc": 52.0}
{"epoch": 22, "training_loss": 0.6907781839370728, "training_acc": 53.0, "val_loss": 0.6935122990608216, "val_acc": 52.0}
{"epoch": 23, "training_loss": 0.6959718799591065, "training_acc": 53.0, "val_loss": 0.6947950768470764, "val_acc": 52.0}
{"epoch": 24, "training_loss": 0.7015464210510254, "training_acc": 52.0, "val_loss": 0.693396897315979, "val_acc": 48.0}
{"epoch": 25, "training_loss": 0.6967822885513306, "training_acc": 45.0, "val_loss": 0.6923584103584289, "val_acc": 52.0}
{"epoch": 26, "training_loss": 0.6943850922584534, "training_acc": 53.0, "val_loss": 0.694577534198761, "val_acc": 52.0}
{"epoch": 27, "training_loss": 0.6974570441246033, "training_acc": 47.0, "val_loss": 0.6947507882118225, "val_acc": 48.0}
{"epoch": 28, "training_loss": 0.6972961521148682, "training_acc": 47.0, "val_loss": 0.6931002879142761, "val_acc": 52.0}
{"epoch": 29, "training_loss": 0.6976554965972901, "training_acc": 51.0, "val_loss": 0.6987295365333557, "val_acc": 52.0}
{"epoch": 30, "training_loss": 0.7068026351928711, "training_acc": 53.0, "val_loss": 0.7012784075737, "val_acc": 52.0}
{"epoch": 31, "training_loss": 0.6930762434005737, "training_acc": 52.0, "val_loss": 0.6934899306297302, "val_acc": 48.0}
{"epoch": 32, "training_loss": 0.7024753499031067, "training_acc": 47.0, "val_loss": 0.6936852216720581, "val_acc": 48.0}
{"epoch": 33, "training_loss": 0.6937583708763122, "training_acc": 49.0, "val_loss": 0.6923613238334656, "val_acc": 52.0}
{"epoch": 34, "training_loss": 0.6931626343727112, "training_acc": 53.0, "val_loss": 0.6932143759727478, "val_acc": 52.0}
{"epoch": 35, "training_loss": 0.6942825269699097, "training_acc": 53.0, "val_loss": 0.6956357979774475, "val_acc": 52.0}
{"epoch": 36, "training_loss": 0.6990081954002381, "training_acc": 53.0, "val_loss": 0.692541401386261, "val_acc": 52.0}
{"epoch": 37, "training_loss": 0.6919884371757508, "training_acc": 53.0, "val_loss": 0.6925594687461853, "val_acc": 52.0}
{"epoch": 38, "training_loss": 0.7008268642425537, "training_acc": 39.0, "val_loss": 0.6928309297561646, "val_acc": 52.0}
{"epoch": 39, "training_loss": 0.6971808099746704, "training_acc": 53.0, "val_loss": 0.6936799263954163, "val_acc": 52.0}
{"epoch": 40, "training_loss": 0.6904854273796082, "training_acc": 53.0, "val_loss": 0.6923695111274719, "val_acc": 52.0}
{"epoch": 41, "training_loss": 0.696463475227356, "training_acc": 41.0, "val_loss": 0.6934997892379761, "val_acc": 48.0}
{"epoch": 42, "training_loss": 0.6960419297218323, "training_acc": 49.0, "val_loss": 0.6928698134422302, "val_acc": 52.0}
{"epoch": 43, "training_loss": 0.6941504287719726, "training_acc": 53.0, "val_loss": 0.6935282444953919, "val_acc": 52.0}
{"epoch": 44, "training_loss": 0.6930880689620972, "training_acc": 53.0, "val_loss": 0.6928545880317688, "val_acc": 52.0}
