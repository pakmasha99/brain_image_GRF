"main_modify.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option BT_org --learning_rate 5e-4 --batch_size 16 --weight_decay 5e-2 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 0.7225802636146545, "training_acc": 45.0, "val_loss": 0.7001799321174622, "val_acc": 52.0}
{"epoch": 1, "training_loss": 0.6922789168357849, "training_acc": 53.0, "val_loss": 0.6930419564247131, "val_acc": 56.0}
{"epoch": 2, "training_loss": 0.702248797416687, "training_acc": 42.0, "val_loss": 0.6975425028800964, "val_acc": 48.0}
{"epoch": 3, "training_loss": 0.69122802734375, "training_acc": 51.0, "val_loss": 0.6937723755836487, "val_acc": 52.0}
{"epoch": 4, "training_loss": 0.6984785223007202, "training_acc": 53.0, "val_loss": 0.7119515943527222, "val_acc": 52.0}
{"epoch": 5, "training_loss": 0.7063798761367798, "training_acc": 53.0, "val_loss": 0.6999296307563782, "val_acc": 52.0}
{"epoch": 6, "training_loss": 0.6950572776794434, "training_acc": 53.0, "val_loss": 0.6928720474243164, "val_acc": 52.0}
{"epoch": 7, "training_loss": 0.6945094537734985, "training_acc": 45.0, "val_loss": 0.6934912467002868, "val_acc": 48.0}
{"epoch": 8, "training_loss": 0.6932593727111817, "training_acc": 47.0, "val_loss": 0.692329113483429, "val_acc": 52.0}
{"epoch": 9, "training_loss": 0.6920235180854797, "training_acc": 53.0, "val_loss": 0.6949114179611207, "val_acc": 52.0}
{"epoch": 10, "training_loss": 0.6927243638038635, "training_acc": 53.0, "val_loss": 0.6926043939590454, "val_acc": 52.0}
{"epoch": 11, "training_loss": 0.6932640552520752, "training_acc": 53.0, "val_loss": 0.6923077845573425, "val_acc": 52.0}
{"epoch": 12, "training_loss": 0.6954644560813904, "training_acc": 47.0, "val_loss": 0.695356366634369, "val_acc": 48.0}
{"epoch": 13, "training_loss": 0.6979351902008056, "training_acc": 49.0, "val_loss": 0.693274953365326, "val_acc": 52.0}
{"epoch": 14, "training_loss": 0.6937586164474487, "training_acc": 53.0, "val_loss": 0.6939088296890259, "val_acc": 52.0}
{"epoch": 15, "training_loss": 0.6888466310501099, "training_acc": 53.0, "val_loss": 0.6928936338424683, "val_acc": 52.0}
{"epoch": 16, "training_loss": 0.6954545450210571, "training_acc": 49.0, "val_loss": 0.6961672210693359, "val_acc": 48.0}
{"epoch": 17, "training_loss": 0.6928758931159973, "training_acc": 51.0, "val_loss": 0.6952862477302552, "val_acc": 52.0}
{"epoch": 18, "training_loss": 0.6962167930603027, "training_acc": 53.0, "val_loss": 0.6957989573478699, "val_acc": 52.0}
{"epoch": 19, "training_loss": 0.6970392942428589, "training_acc": 53.0, "val_loss": 0.6923595523834228, "val_acc": 52.0}
{"epoch": 20, "training_loss": 0.6922641706466675, "training_acc": 53.0, "val_loss": 0.6922883677482605, "val_acc": 52.0}
{"epoch": 21, "training_loss": 0.6938485097885132, "training_acc": 53.0, "val_loss": 0.6929534363746643, "val_acc": 52.0}
{"epoch": 22, "training_loss": 0.6931850743293763, "training_acc": 53.0, "val_loss": 0.6948025560379029, "val_acc": 52.0}
{"epoch": 23, "training_loss": 0.6930826544761658, "training_acc": 53.0, "val_loss": 0.6927608489990235, "val_acc": 52.0}
{"epoch": 24, "training_loss": 0.6924391961097718, "training_acc": 53.0, "val_loss": 0.6925499749183655, "val_acc": 52.0}
{"epoch": 25, "training_loss": 0.6933310317993164, "training_acc": 53.0, "val_loss": 0.6927630162239075, "val_acc": 52.0}
{"epoch": 26, "training_loss": 0.69073401927948, "training_acc": 53.0, "val_loss": 0.6930505323410034, "val_acc": 60.0}
{"epoch": 27, "training_loss": 0.7064807510375977, "training_acc": 40.0, "val_loss": 0.694013524055481, "val_acc": 48.0}
{"epoch": 28, "training_loss": 0.7068878722190857, "training_acc": 49.0, "val_loss": 0.7040503287315368, "val_acc": 52.0}
{"epoch": 29, "training_loss": 0.7034026169776917, "training_acc": 53.0, "val_loss": 0.6987900185585022, "val_acc": 52.0}
{"epoch": 30, "training_loss": 0.7048554182052612, "training_acc": 43.0, "val_loss": 0.6975771021842957, "val_acc": 48.0}
{"epoch": 31, "training_loss": 0.6961970996856689, "training_acc": 49.0, "val_loss": 0.69242919921875, "val_acc": 52.0}
{"epoch": 32, "training_loss": 0.6998177313804627, "training_acc": 53.0, "val_loss": 0.6992749881744384, "val_acc": 52.0}
{"epoch": 33, "training_loss": 0.6992065334320068, "training_acc": 53.0, "val_loss": 0.6966197919845581, "val_acc": 52.0}
{"epoch": 34, "training_loss": 0.6931897902488708, "training_acc": 53.0, "val_loss": 0.6924287629127502, "val_acc": 52.0}
{"epoch": 35, "training_loss": 0.6933518052101135, "training_acc": 53.0, "val_loss": 0.692277979850769, "val_acc": 52.0}
{"epoch": 36, "training_loss": 0.7034724950790405, "training_acc": 53.0, "val_loss": 0.6966920471191407, "val_acc": 52.0}
{"epoch": 37, "training_loss": 0.6926186776161194, "training_acc": 54.0, "val_loss": 0.694314317703247, "val_acc": 48.0}
{"epoch": 38, "training_loss": 0.6949469137191773, "training_acc": 45.0, "val_loss": 0.6922774481773376, "val_acc": 52.0}
{"epoch": 39, "training_loss": 0.6926632118225098, "training_acc": 53.0, "val_loss": 0.6963465309143066, "val_acc": 52.0}
{"epoch": 40, "training_loss": 0.6945798587799072, "training_acc": 53.0, "val_loss": 0.6922777986526489, "val_acc": 52.0}
{"epoch": 41, "training_loss": 0.6937770032882691, "training_acc": 48.0, "val_loss": 0.692357485294342, "val_acc": 52.0}
{"epoch": 42, "training_loss": 0.6911550879478454, "training_acc": 53.0, "val_loss": 0.6989452481269837, "val_acc": 52.0}
{"epoch": 43, "training_loss": 0.6995194673538208, "training_acc": 53.0, "val_loss": 0.7007056593894958, "val_acc": 52.0}
{"epoch": 44, "training_loss": 0.6969924211502075, "training_acc": 53.0, "val_loss": 0.6937075138092041, "val_acc": 52.0}
{"epoch": 45, "training_loss": 0.6926613998413086, "training_acc": 53.0, "val_loss": 0.6931171226501465, "val_acc": 52.0}
{"epoch": 46, "training_loss": 0.6915466737747192, "training_acc": 53.0, "val_loss": 0.6924311923980713, "val_acc": 52.0}
{"epoch": 47, "training_loss": 0.6929889035224914, "training_acc": 53.0, "val_loss": 0.6926494979858399, "val_acc": 52.0}
{"epoch": 48, "training_loss": 0.6979197001457215, "training_acc": 53.0, "val_loss": 0.694216411113739, "val_acc": 52.0}
{"epoch": 49, "training_loss": 0.6931933307647705, "training_acc": 53.0, "val_loss": 0.692279396057129, "val_acc": 52.0}
{"epoch": 50, "training_loss": 0.693292293548584, "training_acc": 51.0, "val_loss": 0.698334813117981, "val_acc": 48.0}
{"epoch": 51, "training_loss": 0.7033807039260864, "training_acc": 41.0, "val_loss": 0.6923828458786011, "val_acc": 52.0}
{"epoch": 52, "training_loss": 0.6935006976127625, "training_acc": 49.0, "val_loss": 0.6927479553222656, "val_acc": 52.0}
{"epoch": 53, "training_loss": 0.6928284549713135, "training_acc": 53.0, "val_loss": 0.6936388444900513, "val_acc": 52.0}
{"epoch": 54, "training_loss": 0.694500732421875, "training_acc": 53.0, "val_loss": 0.6924238300323486, "val_acc": 52.0}
{"epoch": 55, "training_loss": 0.6970325899124146, "training_acc": 47.0, "val_loss": 0.6996406507492066, "val_acc": 48.0}
{"epoch": 56, "training_loss": 0.6959520149230957, "training_acc": 49.0, "val_loss": 0.6931374096870422, "val_acc": 52.0}
{"epoch": 57, "training_loss": 0.6937485480308533, "training_acc": 53.0, "val_loss": 0.6946155524253845, "val_acc": 52.0}
