"main_modify.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 1 --task ABCD_sex --input_option BT_org --learning_rate 1e-4 --batch_size 16 --weight_decay 1e-3 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 0.6932563638687134, "training_acc": 53.0, "val_loss": 0.6923505210876465, "val_acc": 52.0}
{"epoch": 1, "training_loss": 0.6912288188934326, "training_acc": 53.0, "val_loss": 0.6927288889884948, "val_acc": 52.0}
{"epoch": 2, "training_loss": 0.6914970779418945, "training_acc": 53.0, "val_loss": 0.692953884601593, "val_acc": 52.0}
{"epoch": 3, "training_loss": 0.6920106363296509, "training_acc": 53.0, "val_loss": 0.6930443978309632, "val_acc": 52.0}
{"epoch": 4, "training_loss": 0.6915091371536255, "training_acc": 53.0, "val_loss": 0.6930964732170105, "val_acc": 52.0}
{"epoch": 5, "training_loss": 0.6917415118217468, "training_acc": 53.0, "val_loss": 0.6928978538513184, "val_acc": 52.0}
{"epoch": 6, "training_loss": 0.692035129070282, "training_acc": 53.0, "val_loss": 0.6924145531654358, "val_acc": 52.0}
{"epoch": 7, "training_loss": 0.6914982795715332, "training_acc": 53.0, "val_loss": 0.6924017071723938, "val_acc": 52.0}
{"epoch": 8, "training_loss": 0.6915519642829895, "training_acc": 53.0, "val_loss": 0.6926081395149231, "val_acc": 52.0}
{"epoch": 9, "training_loss": 0.6918580436706543, "training_acc": 53.0, "val_loss": 0.6936168909072876, "val_acc": 52.0}
{"epoch": 10, "training_loss": 0.691646831035614, "training_acc": 53.0, "val_loss": 0.6932310938835144, "val_acc": 52.0}
{"epoch": 11, "training_loss": 0.6913977813720703, "training_acc": 53.0, "val_loss": 0.6927251172065735, "val_acc": 52.0}
{"epoch": 12, "training_loss": 0.6937050604820252, "training_acc": 53.0, "val_loss": 0.6923496222496033, "val_acc": 52.0}
{"epoch": 13, "training_loss": 0.693457944393158, "training_acc": 53.0, "val_loss": 0.6928259134292603, "val_acc": 52.0}
{"epoch": 14, "training_loss": 0.6924076700210571, "training_acc": 53.0, "val_loss": 0.6930615234375, "val_acc": 52.0}
{"epoch": 15, "training_loss": 0.6912838411331177, "training_acc": 53.0, "val_loss": 0.6926036381721496, "val_acc": 52.0}
{"epoch": 16, "training_loss": 0.6911412119865418, "training_acc": 53.0, "val_loss": 0.6923480296134948, "val_acc": 52.0}
{"epoch": 17, "training_loss": 0.6924196171760559, "training_acc": 53.0, "val_loss": 0.6925917267799377, "val_acc": 52.0}
{"epoch": 18, "training_loss": 0.6923831796646118, "training_acc": 53.0, "val_loss": 0.6923843693733215, "val_acc": 52.0}
{"epoch": 19, "training_loss": 0.6921289920806885, "training_acc": 53.0, "val_loss": 0.6926735734939575, "val_acc": 52.0}
{"epoch": 20, "training_loss": 0.6921177482604981, "training_acc": 53.0, "val_loss": 0.6924971199035644, "val_acc": 52.0}
{"epoch": 21, "training_loss": 0.6922736930847168, "training_acc": 53.0, "val_loss": 0.6923479890823364, "val_acc": 52.0}
{"epoch": 22, "training_loss": 0.6920391750335694, "training_acc": 53.0, "val_loss": 0.6923910570144653, "val_acc": 52.0}
{"epoch": 23, "training_loss": 0.6916778230667114, "training_acc": 53.0, "val_loss": 0.6923648142814636, "val_acc": 52.0}
{"epoch": 24, "training_loss": 0.6922870969772339, "training_acc": 53.0, "val_loss": 0.6923685455322266, "val_acc": 52.0}
{"epoch": 25, "training_loss": 0.6919580554962158, "training_acc": 53.0, "val_loss": 0.6923693776130676, "val_acc": 52.0}
{"epoch": 26, "training_loss": 0.6915856385231018, "training_acc": 53.0, "val_loss": 0.6924204635620117, "val_acc": 52.0}
{"epoch": 27, "training_loss": 0.6936315107345581, "training_acc": 53.0, "val_loss": 0.6928801774978638, "val_acc": 52.0}
{"epoch": 28, "training_loss": 0.6916295146942139, "training_acc": 53.0, "val_loss": 0.6926487469673157, "val_acc": 52.0}
{"epoch": 29, "training_loss": 0.6920188403129578, "training_acc": 53.0, "val_loss": 0.6926583862304687, "val_acc": 52.0}
{"epoch": 30, "training_loss": 0.691728720664978, "training_acc": 53.0, "val_loss": 0.6926603102684021, "val_acc": 52.0}
{"epoch": 31, "training_loss": 0.6915861082077026, "training_acc": 53.0, "val_loss": 0.6926506376266479, "val_acc": 52.0}
{"epoch": 32, "training_loss": 0.6923828029632568, "training_acc": 53.0, "val_loss": 0.6931292462348938, "val_acc": 52.0}
{"epoch": 33, "training_loss": 0.6924750709533691, "training_acc": 53.0, "val_loss": 0.6924979710578918, "val_acc": 52.0}
{"epoch": 34, "training_loss": 0.6913260173797607, "training_acc": 53.0, "val_loss": 0.6925574135780335, "val_acc": 52.0}
{"epoch": 35, "training_loss": 0.6925619006156921, "training_acc": 53.0, "val_loss": 0.692361810207367, "val_acc": 52.0}
{"epoch": 36, "training_loss": 0.691486520767212, "training_acc": 53.0, "val_loss": 0.6924841856956482, "val_acc": 52.0}
{"epoch": 37, "training_loss": 0.6914720487594604, "training_acc": 53.0, "val_loss": 0.6930062508583069, "val_acc": 52.0}
{"epoch": 38, "training_loss": 0.691944465637207, "training_acc": 53.0, "val_loss": 0.6928052306175232, "val_acc": 52.0}
{"epoch": 39, "training_loss": 0.6921983146667481, "training_acc": 53.0, "val_loss": 0.6926525616645813, "val_acc": 52.0}
{"epoch": 40, "training_loss": 0.6912651634216309, "training_acc": 53.0, "val_loss": 0.6924925303459167, "val_acc": 52.0}
{"epoch": 41, "training_loss": 0.6935197973251342, "training_acc": 53.0, "val_loss": 0.6923473834991455, "val_acc": 52.0}
{"epoch": 42, "training_loss": 0.6917407464981079, "training_acc": 53.0, "val_loss": 0.6924263191223144, "val_acc": 52.0}
{"epoch": 43, "training_loss": 0.6918851184844971, "training_acc": 53.0, "val_loss": 0.6928384017944336, "val_acc": 52.0}
{"epoch": 44, "training_loss": 0.6918136358261109, "training_acc": 53.0, "val_loss": 0.6929029774665832, "val_acc": 52.0}
{"epoch": 45, "training_loss": 0.6914768123626709, "training_acc": 53.0, "val_loss": 0.6924607157707214, "val_acc": 52.0}
{"epoch": 46, "training_loss": 0.6914914608001709, "training_acc": 53.0, "val_loss": 0.692382128238678, "val_acc": 52.0}
{"epoch": 47, "training_loss": 0.692104070186615, "training_acc": 53.0, "val_loss": 0.6923721718788147, "val_acc": 52.0}
{"epoch": 48, "training_loss": 0.6915942740440368, "training_acc": 53.0, "val_loss": 0.6928282475471497, "val_acc": 52.0}
{"epoch": 49, "training_loss": 0.6916631007194519, "training_acc": 53.0, "val_loss": 0.6932508563995361, "val_acc": 52.0}
{"epoch": 50, "training_loss": 0.6921852350234985, "training_acc": 53.0, "val_loss": 0.6942854309082032, "val_acc": 52.0}
{"epoch": 51, "training_loss": 0.6922809958457947, "training_acc": 53.0, "val_loss": 0.6938796091079712, "val_acc": 52.0}
{"epoch": 52, "training_loss": 0.6923157262802124, "training_acc": 53.0, "val_loss": 0.6937581968307495, "val_acc": 52.0}
{"epoch": 53, "training_loss": 0.6927367258071899, "training_acc": 53.0, "val_loss": 0.6924745130538941, "val_acc": 52.0}
{"epoch": 54, "training_loss": 0.6918518447875976, "training_acc": 53.0, "val_loss": 0.6924129891395568, "val_acc": 52.0}
{"epoch": 55, "training_loss": 0.6921005415916442, "training_acc": 53.0, "val_loss": 0.6924013066291809, "val_acc": 52.0}
{"epoch": 56, "training_loss": 0.6920949339866638, "training_acc": 53.0, "val_loss": 0.692360656261444, "val_acc": 52.0}
{"epoch": 57, "training_loss": 0.692032413482666, "training_acc": 53.0, "val_loss": 0.692378761768341, "val_acc": 52.0}
{"epoch": 58, "training_loss": 0.6923003578186036, "training_acc": 53.0, "val_loss": 0.6924175763130188, "val_acc": 52.0}
{"epoch": 59, "training_loss": 0.6912790226936341, "training_acc": 53.0, "val_loss": 0.6925607800483704, "val_acc": 52.0}
{"epoch": 60, "training_loss": 0.691240873336792, "training_acc": 53.0, "val_loss": 0.6928922772407532, "val_acc": 52.0}
