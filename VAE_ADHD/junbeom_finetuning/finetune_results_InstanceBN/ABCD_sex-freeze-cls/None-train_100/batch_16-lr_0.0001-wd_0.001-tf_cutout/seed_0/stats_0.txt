"main_modify.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option BT_org --learning_rate 1e-4 --batch_size 16 --weight_decay 1e-3 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 0.6932760286331177, "training_acc": 52.0, "val_loss": 0.6897069525718689, "val_acc": 56.0}
{"epoch": 1, "training_loss": 0.692634687423706, "training_acc": 52.0, "val_loss": 0.6890907788276672, "val_acc": 56.0}
{"epoch": 2, "training_loss": 0.692746844291687, "training_acc": 52.0, "val_loss": 0.6892138624191284, "val_acc": 56.0}
{"epoch": 3, "training_loss": 0.6931182193756104, "training_acc": 52.0, "val_loss": 0.6877615022659301, "val_acc": 56.0}
{"epoch": 4, "training_loss": 0.6930716800689697, "training_acc": 52.0, "val_loss": 0.6887666249275207, "val_acc": 56.0}
{"epoch": 5, "training_loss": 0.6926508474349976, "training_acc": 52.0, "val_loss": 0.6882589054107666, "val_acc": 56.0}
{"epoch": 6, "training_loss": 0.6927137088775634, "training_acc": 52.0, "val_loss": 0.6882942819595337, "val_acc": 56.0}
{"epoch": 7, "training_loss": 0.6928091406822204, "training_acc": 52.0, "val_loss": 0.6892017006874085, "val_acc": 56.0}
{"epoch": 8, "training_loss": 0.693115336894989, "training_acc": 52.0, "val_loss": 0.6884458875656128, "val_acc": 56.0}
{"epoch": 9, "training_loss": 0.6927056980133056, "training_acc": 52.0, "val_loss": 0.6895075035095215, "val_acc": 56.0}
{"epoch": 10, "training_loss": 0.6925809669494629, "training_acc": 52.0, "val_loss": 0.6919114685058594, "val_acc": 56.0}
{"epoch": 11, "training_loss": 0.6927477216720581, "training_acc": 52.0, "val_loss": 0.6911266207695007, "val_acc": 56.0}
{"epoch": 12, "training_loss": 0.6945156812667846, "training_acc": 52.0, "val_loss": 0.6878495359420777, "val_acc": 56.0}
{"epoch": 13, "training_loss": 0.6924908590316773, "training_acc": 52.0, "val_loss": 0.6875833249092103, "val_acc": 56.0}
{"epoch": 14, "training_loss": 0.6929777383804321, "training_acc": 52.0, "val_loss": 0.687009494304657, "val_acc": 56.0}
{"epoch": 15, "training_loss": 0.6929685878753662, "training_acc": 52.0, "val_loss": 0.687186005115509, "val_acc": 56.0}
{"epoch": 16, "training_loss": 0.6940331745147705, "training_acc": 52.0, "val_loss": 0.6862903022766114, "val_acc": 56.0}
{"epoch": 17, "training_loss": 0.6933337497711182, "training_acc": 52.0, "val_loss": 0.6873513674736023, "val_acc": 56.0}
{"epoch": 18, "training_loss": 0.6923140859603882, "training_acc": 52.0, "val_loss": 0.6894213962554931, "val_acc": 56.0}
{"epoch": 19, "training_loss": 0.6933623075485229, "training_acc": 52.0, "val_loss": 0.6921144080162048, "val_acc": 56.0}
{"epoch": 20, "training_loss": 0.6928839612007142, "training_acc": 52.0, "val_loss": 0.6915734577178955, "val_acc": 56.0}
{"epoch": 21, "training_loss": 0.6927751350402832, "training_acc": 52.0, "val_loss": 0.6910133051872254, "val_acc": 56.0}
{"epoch": 22, "training_loss": 0.6935009407997131, "training_acc": 52.0, "val_loss": 0.6894242000579834, "val_acc": 56.0}
{"epoch": 23, "training_loss": 0.692332239151001, "training_acc": 52.0, "val_loss": 0.6894696378707885, "val_acc": 56.0}
{"epoch": 24, "training_loss": 0.693570146560669, "training_acc": 52.0, "val_loss": 0.6878804755210877, "val_acc": 56.0}
{"epoch": 25, "training_loss": 0.6924966955184937, "training_acc": 52.0, "val_loss": 0.6886235308647156, "val_acc": 56.0}
{"epoch": 26, "training_loss": 0.6933247351646423, "training_acc": 52.0, "val_loss": 0.6887650799751281, "val_acc": 56.0}
{"epoch": 27, "training_loss": 0.6926723217964172, "training_acc": 52.0, "val_loss": 0.6896941018104553, "val_acc": 56.0}
{"epoch": 28, "training_loss": 0.6927922105789185, "training_acc": 52.0, "val_loss": 0.6899343228340149, "val_acc": 56.0}
{"epoch": 29, "training_loss": 0.6924156737327576, "training_acc": 52.0, "val_loss": 0.6887388134002685, "val_acc": 56.0}
{"epoch": 30, "training_loss": 0.6941010808944702, "training_acc": 52.0, "val_loss": 0.686653482913971, "val_acc": 56.0}
{"epoch": 31, "training_loss": 0.6931080722808838, "training_acc": 52.0, "val_loss": 0.686338438987732, "val_acc": 56.0}
{"epoch": 32, "training_loss": 0.6943137454986572, "training_acc": 52.0, "val_loss": 0.6858341932296753, "val_acc": 56.0}
{"epoch": 33, "training_loss": 0.6951611304283142, "training_acc": 52.0, "val_loss": 0.6858466339111328, "val_acc": 56.0}
{"epoch": 34, "training_loss": 0.6942768311500549, "training_acc": 52.0, "val_loss": 0.6865092873573303, "val_acc": 56.0}
{"epoch": 35, "training_loss": 0.6929887437820434, "training_acc": 52.0, "val_loss": 0.6885999917984009, "val_acc": 56.0}
{"epoch": 36, "training_loss": 0.6925823259353637, "training_acc": 52.0, "val_loss": 0.6892578792572022, "val_acc": 56.0}
{"epoch": 37, "training_loss": 0.6926282000541687, "training_acc": 52.0, "val_loss": 0.6888600039482117, "val_acc": 56.0}
{"epoch": 38, "training_loss": 0.6929543542861939, "training_acc": 52.0, "val_loss": 0.6893330931663513, "val_acc": 56.0}
{"epoch": 39, "training_loss": 0.6925635600090027, "training_acc": 52.0, "val_loss": 0.689735426902771, "val_acc": 56.0}
{"epoch": 40, "training_loss": 0.6930975222587585, "training_acc": 52.0, "val_loss": 0.6911767292022705, "val_acc": 56.0}
{"epoch": 41, "training_loss": 0.6927175068855286, "training_acc": 52.0, "val_loss": 0.6906557178497315, "val_acc": 56.0}
{"epoch": 42, "training_loss": 0.6929411840438843, "training_acc": 52.0, "val_loss": 0.6901353287696839, "val_acc": 56.0}
{"epoch": 43, "training_loss": 0.6930036640167236, "training_acc": 52.0, "val_loss": 0.6898113536834717, "val_acc": 56.0}
{"epoch": 44, "training_loss": 0.6932378053665161, "training_acc": 52.0, "val_loss": 0.6917980122566223, "val_acc": 56.0}
{"epoch": 45, "training_loss": 0.6927361559867858, "training_acc": 52.0, "val_loss": 0.6915519809722901, "val_acc": 56.0}
{"epoch": 46, "training_loss": 0.6927740144729614, "training_acc": 52.0, "val_loss": 0.6907399892807007, "val_acc": 56.0}
{"epoch": 47, "training_loss": 0.6925436735153199, "training_acc": 52.0, "val_loss": 0.6893855619430542, "val_acc": 56.0}
{"epoch": 48, "training_loss": 0.6927249670028687, "training_acc": 52.0, "val_loss": 0.6884443950653076, "val_acc": 56.0}
{"epoch": 49, "training_loss": 0.6922372436523437, "training_acc": 52.0, "val_loss": 0.6890593028068542, "val_acc": 56.0}
{"epoch": 50, "training_loss": 0.692513816356659, "training_acc": 52.0, "val_loss": 0.6912481665611268, "val_acc": 56.0}
{"epoch": 51, "training_loss": 0.6925634479522705, "training_acc": 52.0, "val_loss": 0.6933934140205383, "val_acc": 44.0}
