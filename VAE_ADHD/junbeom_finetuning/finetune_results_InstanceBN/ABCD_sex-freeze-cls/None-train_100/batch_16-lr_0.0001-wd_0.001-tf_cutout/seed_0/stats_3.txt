"main_modify.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option BT_org --learning_rate 1e-4 --batch_size 16 --weight_decay 1e-3 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 0.692865834236145, "training_acc": 53.0, "val_loss": 0.6925788927078247, "val_acc": 52.0}
{"epoch": 1, "training_loss": 0.6917622232437134, "training_acc": 53.0, "val_loss": 0.6925401806831359, "val_acc": 52.0}
{"epoch": 2, "training_loss": 0.6916801643371582, "training_acc": 53.0, "val_loss": 0.6925622534751892, "val_acc": 52.0}
{"epoch": 3, "training_loss": 0.6916645240783691, "training_acc": 53.0, "val_loss": 0.69241295337677, "val_acc": 52.0}
{"epoch": 4, "training_loss": 0.6946706891059875, "training_acc": 53.0, "val_loss": 0.6928086829185486, "val_acc": 52.0}
{"epoch": 5, "training_loss": 0.6919604063034057, "training_acc": 53.0, "val_loss": 0.6924187922477723, "val_acc": 52.0}
{"epoch": 6, "training_loss": 0.6917882609367371, "training_acc": 53.0, "val_loss": 0.6924217343330383, "val_acc": 52.0}
{"epoch": 7, "training_loss": 0.6925150227546691, "training_acc": 53.0, "val_loss": 0.6928969955444336, "val_acc": 52.0}
{"epoch": 8, "training_loss": 0.6916038656234741, "training_acc": 53.0, "val_loss": 0.6930736517906189, "val_acc": 52.0}
{"epoch": 9, "training_loss": 0.691661651134491, "training_acc": 53.0, "val_loss": 0.6928056740760803, "val_acc": 52.0}
{"epoch": 10, "training_loss": 0.6915451860427857, "training_acc": 53.0, "val_loss": 0.6929192447662353, "val_acc": 52.0}
{"epoch": 11, "training_loss": 0.6916892266273499, "training_acc": 53.0, "val_loss": 0.6928694486618042, "val_acc": 52.0}
{"epoch": 12, "training_loss": 0.6916580390930176, "training_acc": 53.0, "val_loss": 0.6928192090988159, "val_acc": 52.0}
{"epoch": 13, "training_loss": 0.6919828581809998, "training_acc": 53.0, "val_loss": 0.6937591934204101, "val_acc": 52.0}
{"epoch": 14, "training_loss": 0.6944726443290711, "training_acc": 53.0, "val_loss": 0.6942685842514038, "val_acc": 52.0}
{"epoch": 15, "training_loss": 0.6922351837158203, "training_acc": 53.0, "val_loss": 0.6926647114753723, "val_acc": 52.0}
{"epoch": 16, "training_loss": 0.6914655470848083, "training_acc": 53.0, "val_loss": 0.6923974180221557, "val_acc": 52.0}
{"epoch": 17, "training_loss": 0.6923051738739013, "training_acc": 53.0, "val_loss": 0.6924837303161621, "val_acc": 52.0}
{"epoch": 18, "training_loss": 0.6922861528396607, "training_acc": 53.0, "val_loss": 0.6924772763252258, "val_acc": 52.0}
{"epoch": 19, "training_loss": 0.6915490627288818, "training_acc": 53.0, "val_loss": 0.6924391913414002, "val_acc": 52.0}
{"epoch": 20, "training_loss": 0.6907444429397583, "training_acc": 53.0, "val_loss": 0.693052372932434, "val_acc": 52.0}
{"epoch": 21, "training_loss": 0.6931506323814393, "training_acc": 53.0, "val_loss": 0.6942934513092041, "val_acc": 52.0}
{"epoch": 22, "training_loss": 0.6924130916595459, "training_acc": 53.0, "val_loss": 0.6936027073860168, "val_acc": 52.0}
{"epoch": 23, "training_loss": 0.6920628809928894, "training_acc": 53.0, "val_loss": 0.6934956002235413, "val_acc": 52.0}
{"epoch": 24, "training_loss": 0.6926049590110779, "training_acc": 53.0, "val_loss": 0.6924773502349854, "val_acc": 52.0}
{"epoch": 25, "training_loss": 0.6920959973335266, "training_acc": 53.0, "val_loss": 0.6923910856246949, "val_acc": 52.0}
{"epoch": 26, "training_loss": 0.6921600198745728, "training_acc": 53.0, "val_loss": 0.6925783491134644, "val_acc": 52.0}
{"epoch": 27, "training_loss": 0.6946850848197937, "training_acc": 41.0, "val_loss": 0.6935347032546997, "val_acc": 48.0}
{"epoch": 28, "training_loss": 0.693275580406189, "training_acc": 53.0, "val_loss": 0.6926925325393677, "val_acc": 52.0}
{"epoch": 29, "training_loss": 0.6923287987709046, "training_acc": 53.0, "val_loss": 0.6924622321128845, "val_acc": 52.0}
{"epoch": 30, "training_loss": 0.6921398878097534, "training_acc": 53.0, "val_loss": 0.6924065852165222, "val_acc": 52.0}
{"epoch": 31, "training_loss": 0.6931846952438354, "training_acc": 53.0, "val_loss": 0.6924850845336914, "val_acc": 52.0}
{"epoch": 32, "training_loss": 0.6914805102348328, "training_acc": 53.0, "val_loss": 0.6923926258087159, "val_acc": 52.0}
{"epoch": 33, "training_loss": 0.6917059707641602, "training_acc": 53.0, "val_loss": 0.6923915576934815, "val_acc": 52.0}
{"epoch": 34, "training_loss": 0.6942315697669983, "training_acc": 53.0, "val_loss": 0.6927065372467041, "val_acc": 52.0}
{"epoch": 35, "training_loss": 0.6917967581748963, "training_acc": 53.0, "val_loss": 0.692424418926239, "val_acc": 52.0}
{"epoch": 36, "training_loss": 0.692136869430542, "training_acc": 53.0, "val_loss": 0.692392041683197, "val_acc": 52.0}
{"epoch": 37, "training_loss": 0.6920623970031738, "training_acc": 53.0, "val_loss": 0.6926366066932679, "val_acc": 52.0}
{"epoch": 38, "training_loss": 0.6914493918418885, "training_acc": 53.0, "val_loss": 0.6928216433525085, "val_acc": 52.0}
{"epoch": 39, "training_loss": 0.6936943054199218, "training_acc": 53.0, "val_loss": 0.6934172153472901, "val_acc": 52.0}
{"epoch": 40, "training_loss": 0.6909468126296997, "training_acc": 53.0, "val_loss": 0.692457127571106, "val_acc": 52.0}
{"epoch": 41, "training_loss": 0.6912258338928222, "training_acc": 53.0, "val_loss": 0.6923905420303345, "val_acc": 52.0}
{"epoch": 42, "training_loss": 0.6917363595962525, "training_acc": 53.0, "val_loss": 0.6925881695747376, "val_acc": 52.0}
{"epoch": 43, "training_loss": 0.692508339881897, "training_acc": 53.0, "val_loss": 0.6924146413803101, "val_acc": 52.0}
{"epoch": 44, "training_loss": 0.6919634246826172, "training_acc": 53.0, "val_loss": 0.6924170899391174, "val_acc": 52.0}
{"epoch": 45, "training_loss": 0.6916267442703247, "training_acc": 53.0, "val_loss": 0.692395474910736, "val_acc": 52.0}
{"epoch": 46, "training_loss": 0.691724247932434, "training_acc": 53.0, "val_loss": 0.6924873208999633, "val_acc": 52.0}
{"epoch": 47, "training_loss": 0.6921082210540771, "training_acc": 53.0, "val_loss": 0.6924088191986084, "val_acc": 52.0}
{"epoch": 48, "training_loss": 0.692050096988678, "training_acc": 53.0, "val_loss": 0.6924052834510803, "val_acc": 52.0}
{"epoch": 49, "training_loss": 0.6921017575263977, "training_acc": 53.0, "val_loss": 0.6924364781379699, "val_acc": 52.0}
{"epoch": 50, "training_loss": 0.692584171295166, "training_acc": 53.0, "val_loss": 0.69239422082901, "val_acc": 52.0}
{"epoch": 51, "training_loss": 0.6936924505233765, "training_acc": 53.0, "val_loss": 0.6927313566207886, "val_acc": 52.0}
{"epoch": 52, "training_loss": 0.6924466896057129, "training_acc": 53.0, "val_loss": 0.6927701115608216, "val_acc": 52.0}
{"epoch": 53, "training_loss": 0.6930283164978027, "training_acc": 53.0, "val_loss": 0.6926056814193725, "val_acc": 52.0}
{"epoch": 54, "training_loss": 0.6921677470207215, "training_acc": 53.0, "val_loss": 0.6923956370353699, "val_acc": 52.0}
{"epoch": 55, "training_loss": 0.6923595213890076, "training_acc": 53.0, "val_loss": 0.6926032924652099, "val_acc": 52.0}
{"epoch": 56, "training_loss": 0.6919922232627869, "training_acc": 53.0, "val_loss": 0.6924089074134827, "val_acc": 52.0}
{"epoch": 57, "training_loss": 0.6918653106689453, "training_acc": 53.0, "val_loss": 0.6924622845649719, "val_acc": 52.0}
{"epoch": 58, "training_loss": 0.6918034839630127, "training_acc": 53.0, "val_loss": 0.6928039193153381, "val_acc": 52.0}
{"epoch": 59, "training_loss": 0.6923954820632935, "training_acc": 53.0, "val_loss": 0.69382563829422, "val_acc": 52.0}
{"epoch": 60, "training_loss": 0.6916440773010254, "training_acc": 53.0, "val_loss": 0.6934266614913941, "val_acc": 52.0}
