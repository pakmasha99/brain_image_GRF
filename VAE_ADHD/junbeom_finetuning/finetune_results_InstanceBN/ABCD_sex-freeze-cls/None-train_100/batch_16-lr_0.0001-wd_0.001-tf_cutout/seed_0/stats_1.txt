"main_modify.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option BT_org --learning_rate 1e-4 --batch_size 16 --weight_decay 1e-3 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 0.7029567980766296, "training_acc": 47.0, "val_loss": 0.6954965591430664, "val_acc": 48.0}
{"epoch": 1, "training_loss": 0.6985043144226074, "training_acc": 41.0, "val_loss": 0.6925273871421814, "val_acc": 52.0}
{"epoch": 2, "training_loss": 0.6919073677062988, "training_acc": 53.0, "val_loss": 0.6925759530067443, "val_acc": 52.0}
{"epoch": 3, "training_loss": 0.6918966841697692, "training_acc": 53.0, "val_loss": 0.6927375340461731, "val_acc": 52.0}
{"epoch": 4, "training_loss": 0.6915729022026063, "training_acc": 53.0, "val_loss": 0.6926935958862305, "val_acc": 52.0}
{"epoch": 5, "training_loss": 0.6918778610229492, "training_acc": 53.0, "val_loss": 0.6926522421836853, "val_acc": 52.0}
{"epoch": 6, "training_loss": 0.6915646123886109, "training_acc": 53.0, "val_loss": 0.6928521323204041, "val_acc": 52.0}
{"epoch": 7, "training_loss": 0.6924304151535035, "training_acc": 53.0, "val_loss": 0.6926004910469055, "val_acc": 52.0}
{"epoch": 8, "training_loss": 0.6914448380470276, "training_acc": 53.0, "val_loss": 0.6927170467376709, "val_acc": 52.0}
{"epoch": 9, "training_loss": 0.6933113193511963, "training_acc": 53.0, "val_loss": 0.6925273227691651, "val_acc": 52.0}
{"epoch": 10, "training_loss": 0.6923777747154236, "training_acc": 53.0, "val_loss": 0.6926222538948059, "val_acc": 52.0}
{"epoch": 11, "training_loss": 0.6912398982048035, "training_acc": 53.0, "val_loss": 0.6925353622436523, "val_acc": 52.0}
{"epoch": 12, "training_loss": 0.6923162865638733, "training_acc": 53.0, "val_loss": 0.6925365591049194, "val_acc": 52.0}
{"epoch": 13, "training_loss": 0.6921472334861756, "training_acc": 53.0, "val_loss": 0.6925297474861145, "val_acc": 52.0}
{"epoch": 14, "training_loss": 0.6918842005729675, "training_acc": 53.0, "val_loss": 0.6925876688957214, "val_acc": 52.0}
{"epoch": 15, "training_loss": 0.6913841009140015, "training_acc": 53.0, "val_loss": 0.6926953506469726, "val_acc": 52.0}
{"epoch": 16, "training_loss": 0.6912091159820557, "training_acc": 53.0, "val_loss": 0.6928444409370422, "val_acc": 52.0}
{"epoch": 17, "training_loss": 0.6912788677215577, "training_acc": 53.0, "val_loss": 0.6930680418014527, "val_acc": 52.0}
{"epoch": 18, "training_loss": 0.6915514326095581, "training_acc": 53.0, "val_loss": 0.6937609815597534, "val_acc": 52.0}
{"epoch": 19, "training_loss": 0.6921851444244385, "training_acc": 53.0, "val_loss": 0.6937792348861694, "val_acc": 52.0}
{"epoch": 20, "training_loss": 0.6920351362228394, "training_acc": 53.0, "val_loss": 0.6928092432022095, "val_acc": 52.0}
{"epoch": 21, "training_loss": 0.6913706803321839, "training_acc": 53.0, "val_loss": 0.6925838470458985, "val_acc": 52.0}
{"epoch": 22, "training_loss": 0.6918120503425598, "training_acc": 53.0, "val_loss": 0.6925254416465759, "val_acc": 52.0}
{"epoch": 23, "training_loss": 0.6914424276351929, "training_acc": 53.0, "val_loss": 0.6925918221473694, "val_acc": 52.0}
{"epoch": 24, "training_loss": 0.6915376019477845, "training_acc": 53.0, "val_loss": 0.6925620341300964, "val_acc": 52.0}
{"epoch": 25, "training_loss": 0.6917914485931397, "training_acc": 53.0, "val_loss": 0.6925355005264282, "val_acc": 52.0}
{"epoch": 26, "training_loss": 0.6914852857589722, "training_acc": 53.0, "val_loss": 0.6928814458847046, "val_acc": 52.0}
{"epoch": 27, "training_loss": 0.6928929567337037, "training_acc": 53.0, "val_loss": 0.6933307600021362, "val_acc": 52.0}
{"epoch": 28, "training_loss": 0.6925508165359497, "training_acc": 53.0, "val_loss": 0.6925772547721862, "val_acc": 52.0}
{"epoch": 29, "training_loss": 0.6916622591018676, "training_acc": 53.0, "val_loss": 0.6925368380546569, "val_acc": 52.0}
{"epoch": 30, "training_loss": 0.6922159028053284, "training_acc": 53.0, "val_loss": 0.6925814771652221, "val_acc": 52.0}
{"epoch": 31, "training_loss": 0.6920882081985473, "training_acc": 53.0, "val_loss": 0.6936737847328186, "val_acc": 52.0}
{"epoch": 32, "training_loss": 0.6917394495010376, "training_acc": 53.0, "val_loss": 0.692972116470337, "val_acc": 52.0}
{"epoch": 33, "training_loss": 0.6916256475448609, "training_acc": 53.0, "val_loss": 0.692892496585846, "val_acc": 52.0}
{"epoch": 34, "training_loss": 0.691568865776062, "training_acc": 53.0, "val_loss": 0.6930183815956116, "val_acc": 52.0}
{"epoch": 35, "training_loss": 0.6918743467330932, "training_acc": 53.0, "val_loss": 0.6927742648124695, "val_acc": 52.0}
{"epoch": 36, "training_loss": 0.6923075628280639, "training_acc": 53.0, "val_loss": 0.6931229567527771, "val_acc": 52.0}
{"epoch": 37, "training_loss": 0.6938837575912475, "training_acc": 53.0, "val_loss": 0.6925410437583923, "val_acc": 52.0}
{"epoch": 38, "training_loss": 0.6916750431060791, "training_acc": 53.0, "val_loss": 0.6925448966026306, "val_acc": 52.0}
{"epoch": 39, "training_loss": 0.6917851972579956, "training_acc": 53.0, "val_loss": 0.6925988030433655, "val_acc": 52.0}
{"epoch": 40, "training_loss": 0.6915238738059998, "training_acc": 53.0, "val_loss": 0.6926022648811341, "val_acc": 52.0}
{"epoch": 41, "training_loss": 0.6922985768318176, "training_acc": 53.0, "val_loss": 0.6925371623039246, "val_acc": 52.0}
