"main_modify.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option BT_org --learning_rate 1e-6 --batch_size 16 --weight_decay 1e-2 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 0.692751476764679, "training_acc": 53.0, "val_loss": 0.6929288983345032, "val_acc": 52.0}
{"epoch": 1, "training_loss": 0.6927276039123536, "training_acc": 53.0, "val_loss": 0.6929185485839844, "val_acc": 52.0}
{"epoch": 2, "training_loss": 0.692668251991272, "training_acc": 53.0, "val_loss": 0.6929095458984375, "val_acc": 52.0}
{"epoch": 3, "training_loss": 0.6925671434402466, "training_acc": 53.0, "val_loss": 0.6929018878936768, "val_acc": 52.0}
{"epoch": 4, "training_loss": 0.6926952886581421, "training_acc": 53.0, "val_loss": 0.6928950238227845, "val_acc": 52.0}
{"epoch": 5, "training_loss": 0.6926144695281983, "training_acc": 53.0, "val_loss": 0.6928769397735596, "val_acc": 52.0}
{"epoch": 6, "training_loss": 0.692671446800232, "training_acc": 53.0, "val_loss": 0.6928590846061706, "val_acc": 52.0}
{"epoch": 7, "training_loss": 0.6924728465080261, "training_acc": 53.0, "val_loss": 0.6928483963012695, "val_acc": 52.0}
{"epoch": 8, "training_loss": 0.6925481653213501, "training_acc": 53.0, "val_loss": 0.6928404664993286, "val_acc": 52.0}
{"epoch": 9, "training_loss": 0.6925636911392212, "training_acc": 53.0, "val_loss": 0.6928358387947082, "val_acc": 52.0}
{"epoch": 10, "training_loss": 0.692406108379364, "training_acc": 53.0, "val_loss": 0.6928242111206054, "val_acc": 52.0}
{"epoch": 11, "training_loss": 0.6925740909576416, "training_acc": 53.0, "val_loss": 0.6928160786628723, "val_acc": 52.0}
{"epoch": 12, "training_loss": 0.6924772644042969, "training_acc": 53.0, "val_loss": 0.6927990460395813, "val_acc": 52.0}
{"epoch": 13, "training_loss": 0.6924635791778564, "training_acc": 53.0, "val_loss": 0.6927731442451477, "val_acc": 52.0}
{"epoch": 14, "training_loss": 0.692403769493103, "training_acc": 53.0, "val_loss": 0.6927674031257629, "val_acc": 52.0}
{"epoch": 15, "training_loss": 0.6925270104408264, "training_acc": 53.0, "val_loss": 0.6927662420272828, "val_acc": 52.0}
{"epoch": 16, "training_loss": 0.6922591781616211, "training_acc": 53.0, "val_loss": 0.6927524709701538, "val_acc": 52.0}
{"epoch": 17, "training_loss": 0.6922357368469239, "training_acc": 53.0, "val_loss": 0.6927415800094604, "val_acc": 52.0}
{"epoch": 18, "training_loss": 0.6922092914581299, "training_acc": 53.0, "val_loss": 0.6927474594116211, "val_acc": 52.0}
{"epoch": 19, "training_loss": 0.6922708606719971, "training_acc": 53.0, "val_loss": 0.6927420330047608, "val_acc": 52.0}
{"epoch": 20, "training_loss": 0.6924613785743713, "training_acc": 53.0, "val_loss": 0.6927363514900208, "val_acc": 52.0}
{"epoch": 21, "training_loss": 0.6925397062301636, "training_acc": 53.0, "val_loss": 0.6927324652671814, "val_acc": 52.0}
{"epoch": 22, "training_loss": 0.6924438858032227, "training_acc": 53.0, "val_loss": 0.6927236914634705, "val_acc": 52.0}
{"epoch": 23, "training_loss": 0.6922681999206542, "training_acc": 53.0, "val_loss": 0.6927197575569153, "val_acc": 52.0}
{"epoch": 24, "training_loss": 0.692512366771698, "training_acc": 53.0, "val_loss": 0.6927086758613586, "val_acc": 52.0}
{"epoch": 25, "training_loss": 0.6923287105560303, "training_acc": 53.0, "val_loss": 0.6926894307136535, "val_acc": 52.0}
{"epoch": 26, "training_loss": 0.6923672986030579, "training_acc": 53.0, "val_loss": 0.6926818513870239, "val_acc": 52.0}
{"epoch": 27, "training_loss": 0.6924183964729309, "training_acc": 53.0, "val_loss": 0.6926796293258667, "val_acc": 52.0}
{"epoch": 28, "training_loss": 0.6920580506324768, "training_acc": 53.0, "val_loss": 0.6926757383346558, "val_acc": 52.0}
{"epoch": 29, "training_loss": 0.692361798286438, "training_acc": 53.0, "val_loss": 0.6926692152023315, "val_acc": 52.0}
{"epoch": 30, "training_loss": 0.6923103570938111, "training_acc": 53.0, "val_loss": 0.6926670885086059, "val_acc": 52.0}
{"epoch": 31, "training_loss": 0.692247269153595, "training_acc": 53.0, "val_loss": 0.6926593065261841, "val_acc": 52.0}
{"epoch": 32, "training_loss": 0.6922842359542847, "training_acc": 53.0, "val_loss": 0.6926499652862549, "val_acc": 52.0}
{"epoch": 33, "training_loss": 0.6921447515487671, "training_acc": 53.0, "val_loss": 0.6926356887817383, "val_acc": 52.0}
{"epoch": 34, "training_loss": 0.6921855735778809, "training_acc": 53.0, "val_loss": 0.6926314043998718, "val_acc": 52.0}
{"epoch": 35, "training_loss": 0.692278242111206, "training_acc": 53.0, "val_loss": 0.6926205635070801, "val_acc": 52.0}
{"epoch": 36, "training_loss": 0.6922180986404419, "training_acc": 53.0, "val_loss": 0.6926210141181945, "val_acc": 52.0}
{"epoch": 37, "training_loss": 0.6920311665534973, "training_acc": 53.0, "val_loss": 0.6926174974441528, "val_acc": 52.0}
{"epoch": 38, "training_loss": 0.6920787954330444, "training_acc": 53.0, "val_loss": 0.6926168537139893, "val_acc": 52.0}
{"epoch": 39, "training_loss": 0.6921179723739624, "training_acc": 53.0, "val_loss": 0.6926254653930664, "val_acc": 52.0}
{"epoch": 40, "training_loss": 0.6922062397003174, "training_acc": 53.0, "val_loss": 0.692617073059082, "val_acc": 52.0}
{"epoch": 41, "training_loss": 0.6920955157279969, "training_acc": 53.0, "val_loss": 0.6926175308227539, "val_acc": 52.0}
{"epoch": 42, "training_loss": 0.6921120595932007, "training_acc": 53.0, "val_loss": 0.6926136064529419, "val_acc": 52.0}
{"epoch": 43, "training_loss": 0.6920911192893981, "training_acc": 53.0, "val_loss": 0.6926101231575013, "val_acc": 52.0}
{"epoch": 44, "training_loss": 0.6920411300659179, "training_acc": 53.0, "val_loss": 0.69260662317276, "val_acc": 52.0}
{"epoch": 45, "training_loss": 0.6921367287635803, "training_acc": 53.0, "val_loss": 0.6926024270057678, "val_acc": 52.0}
{"epoch": 46, "training_loss": 0.692065110206604, "training_acc": 53.0, "val_loss": 0.6925946807861328, "val_acc": 52.0}
{"epoch": 47, "training_loss": 0.6919667243957519, "training_acc": 53.0, "val_loss": 0.6925927424430847, "val_acc": 52.0}
{"epoch": 48, "training_loss": 0.6920716214179993, "training_acc": 53.0, "val_loss": 0.6925918650627136, "val_acc": 52.0}
{"epoch": 49, "training_loss": 0.6919818639755249, "training_acc": 53.0, "val_loss": 0.6925853157043457, "val_acc": 52.0}
{"epoch": 50, "training_loss": 0.6919775819778442, "training_acc": 53.0, "val_loss": 0.6925770282745362, "val_acc": 52.0}
{"epoch": 51, "training_loss": 0.6920521426200866, "training_acc": 53.0, "val_loss": 0.6925659894943237, "val_acc": 52.0}
{"epoch": 52, "training_loss": 0.6920414900779724, "training_acc": 53.0, "val_loss": 0.6925639009475708, "val_acc": 52.0}
{"epoch": 53, "training_loss": 0.6921704483032226, "training_acc": 53.0, "val_loss": 0.6925563430786132, "val_acc": 52.0}
{"epoch": 54, "training_loss": 0.6921247386932373, "training_acc": 53.0, "val_loss": 0.6925571393966675, "val_acc": 52.0}
{"epoch": 55, "training_loss": 0.6919049096107482, "training_acc": 53.0, "val_loss": 0.6925464749336243, "val_acc": 52.0}
{"epoch": 56, "training_loss": 0.6920511603355408, "training_acc": 53.0, "val_loss": 0.6925391817092895, "val_acc": 52.0}
{"epoch": 57, "training_loss": 0.6917893671989441, "training_acc": 53.0, "val_loss": 0.6925336194038391, "val_acc": 52.0}
{"epoch": 58, "training_loss": 0.6918656849861144, "training_acc": 53.0, "val_loss": 0.6925272059440613, "val_acc": 52.0}
{"epoch": 59, "training_loss": 0.6921011018753052, "training_acc": 53.0, "val_loss": 0.6925241422653198, "val_acc": 52.0}
{"epoch": 60, "training_loss": 0.6920881938934326, "training_acc": 53.0, "val_loss": 0.6925194096565247, "val_acc": 52.0}
{"epoch": 61, "training_loss": 0.6919083571434022, "training_acc": 53.0, "val_loss": 0.6925208091735839, "val_acc": 52.0}
{"epoch": 62, "training_loss": 0.6921444821357727, "training_acc": 53.0, "val_loss": 0.6925212073326111, "val_acc": 52.0}
{"epoch": 63, "training_loss": 0.6917777252197266, "training_acc": 53.0, "val_loss": 0.6925186085700988, "val_acc": 52.0}
{"epoch": 64, "training_loss": 0.6917007207870484, "training_acc": 53.0, "val_loss": 0.6925083923339844, "val_acc": 52.0}
{"epoch": 65, "training_loss": 0.6919655466079712, "training_acc": 53.0, "val_loss": 0.6925035119056702, "val_acc": 52.0}
{"epoch": 66, "training_loss": 0.6918497848510742, "training_acc": 53.0, "val_loss": 0.6924960327148437, "val_acc": 52.0}
{"epoch": 67, "training_loss": 0.6918867659568787, "training_acc": 53.0, "val_loss": 0.6924956893920898, "val_acc": 52.0}
{"epoch": 68, "training_loss": 0.6918464040756226, "training_acc": 53.0, "val_loss": 0.6924925351142883, "val_acc": 52.0}
{"epoch": 69, "training_loss": 0.6919927215576172, "training_acc": 53.0, "val_loss": 0.6924885487556458, "val_acc": 52.0}
{"epoch": 70, "training_loss": 0.6918306708335876, "training_acc": 53.0, "val_loss": 0.6924893689155579, "val_acc": 52.0}
{"epoch": 71, "training_loss": 0.6919310474395752, "training_acc": 53.0, "val_loss": 0.692489140033722, "val_acc": 52.0}
{"epoch": 72, "training_loss": 0.6917944002151489, "training_acc": 53.0, "val_loss": 0.692489550113678, "val_acc": 52.0}
{"epoch": 73, "training_loss": 0.6917545270919799, "training_acc": 53.0, "val_loss": 0.6924867486953735, "val_acc": 52.0}
{"epoch": 74, "training_loss": 0.6918383169174195, "training_acc": 53.0, "val_loss": 0.6924838042259216, "val_acc": 52.0}
{"epoch": 75, "training_loss": 0.691826868057251, "training_acc": 53.0, "val_loss": 0.6924811172485351, "val_acc": 52.0}
{"epoch": 76, "training_loss": 0.6918778133392334, "training_acc": 53.0, "val_loss": 0.6924789476394654, "val_acc": 52.0}
{"epoch": 77, "training_loss": 0.6919783973693847, "training_acc": 53.0, "val_loss": 0.6924730062484741, "val_acc": 52.0}
{"epoch": 78, "training_loss": 0.6919550967216491, "training_acc": 53.0, "val_loss": 0.6924712085723876, "val_acc": 52.0}
{"epoch": 79, "training_loss": 0.6917574739456177, "training_acc": 53.0, "val_loss": 0.6924697971343994, "val_acc": 52.0}
{"epoch": 80, "training_loss": 0.6917741775512696, "training_acc": 53.0, "val_loss": 0.6924721002578735, "val_acc": 52.0}
{"epoch": 81, "training_loss": 0.6916900968551636, "training_acc": 53.0, "val_loss": 0.6924695944786072, "val_acc": 52.0}
{"epoch": 82, "training_loss": 0.6918008422851563, "training_acc": 53.0, "val_loss": 0.6924715495109558, "val_acc": 52.0}
{"epoch": 83, "training_loss": 0.6918595504760742, "training_acc": 53.0, "val_loss": 0.6924673962593079, "val_acc": 52.0}
{"epoch": 84, "training_loss": 0.6917910170555115, "training_acc": 53.0, "val_loss": 0.6924678897857666, "val_acc": 52.0}
{"epoch": 85, "training_loss": 0.6918514919281006, "training_acc": 53.0, "val_loss": 0.6924666023254394, "val_acc": 52.0}
{"epoch": 86, "training_loss": 0.6918033504486084, "training_acc": 53.0, "val_loss": 0.6924642658233643, "val_acc": 52.0}
{"epoch": 87, "training_loss": 0.6917319965362548, "training_acc": 53.0, "val_loss": 0.6924638032913208, "val_acc": 52.0}
{"epoch": 88, "training_loss": 0.691859827041626, "training_acc": 53.0, "val_loss": 0.6924602484703064, "val_acc": 52.0}
{"epoch": 89, "training_loss": 0.6917975234985352, "training_acc": 53.0, "val_loss": 0.6924573445320129, "val_acc": 52.0}
{"epoch": 90, "training_loss": 0.6917543268203735, "training_acc": 53.0, "val_loss": 0.692454080581665, "val_acc": 52.0}
{"epoch": 91, "training_loss": 0.6917705392837524, "training_acc": 53.0, "val_loss": 0.6924568629264831, "val_acc": 52.0}
{"epoch": 92, "training_loss": 0.6915672183036804, "training_acc": 53.0, "val_loss": 0.6924581885337829, "val_acc": 52.0}
{"epoch": 93, "training_loss": 0.6917751097679138, "training_acc": 53.0, "val_loss": 0.6924609398841858, "val_acc": 52.0}
{"epoch": 94, "training_loss": 0.6918615937232971, "training_acc": 53.0, "val_loss": 0.692460618019104, "val_acc": 52.0}
{"epoch": 95, "training_loss": 0.691854498386383, "training_acc": 53.0, "val_loss": 0.692461302280426, "val_acc": 52.0}
{"epoch": 96, "training_loss": 0.6918628573417663, "training_acc": 53.0, "val_loss": 0.692459614276886, "val_acc": 52.0}
{"epoch": 97, "training_loss": 0.6915669655799865, "training_acc": 53.0, "val_loss": 0.692462706565857, "val_acc": 52.0}
{"epoch": 98, "training_loss": 0.6918520879745483, "training_acc": 53.0, "val_loss": 0.692461428642273, "val_acc": 52.0}
{"epoch": 99, "training_loss": 0.6916413831710816, "training_acc": 53.0, "val_loss": 0.6924606919288635, "val_acc": 52.0}
