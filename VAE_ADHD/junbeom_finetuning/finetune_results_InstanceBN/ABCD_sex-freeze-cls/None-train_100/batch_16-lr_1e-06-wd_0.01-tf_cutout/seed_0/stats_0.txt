"main_modify.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option BT_org --learning_rate 1e-6 --batch_size 16 --weight_decay 1e-2 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 0.6924095392227173, "training_acc": 52.0, "val_loss": 0.6899776911735535, "val_acc": 56.0}
{"epoch": 1, "training_loss": 0.6924809980392456, "training_acc": 52.0, "val_loss": 0.6899730229377746, "val_acc": 56.0}
{"epoch": 2, "training_loss": 0.6923249673843384, "training_acc": 52.0, "val_loss": 0.6899669456481934, "val_acc": 56.0}
{"epoch": 3, "training_loss": 0.6923600459098815, "training_acc": 52.0, "val_loss": 0.6899410724639893, "val_acc": 56.0}
{"epoch": 4, "training_loss": 0.6923780775070191, "training_acc": 52.0, "val_loss": 0.6899438500404358, "val_acc": 56.0}
{"epoch": 5, "training_loss": 0.6922397541999817, "training_acc": 52.0, "val_loss": 0.6899326276779175, "val_acc": 56.0}
{"epoch": 6, "training_loss": 0.692416844367981, "training_acc": 52.0, "val_loss": 0.6899232578277588, "val_acc": 56.0}
{"epoch": 7, "training_loss": 0.6923033523559571, "training_acc": 52.0, "val_loss": 0.6899257373809814, "val_acc": 56.0}
{"epoch": 8, "training_loss": 0.6924777412414551, "training_acc": 52.0, "val_loss": 0.6899069714546203, "val_acc": 56.0}
{"epoch": 9, "training_loss": 0.6923904752731324, "training_acc": 52.0, "val_loss": 0.6899151706695557, "val_acc": 56.0}
{"epoch": 10, "training_loss": 0.6923510336875915, "training_acc": 52.0, "val_loss": 0.6899327850341797, "val_acc": 56.0}
{"epoch": 11, "training_loss": 0.6923862648010254, "training_acc": 52.0, "val_loss": 0.6899252152442932, "val_acc": 56.0}
{"epoch": 12, "training_loss": 0.6922385525703431, "training_acc": 52.0, "val_loss": 0.6898931050300598, "val_acc": 56.0}
{"epoch": 13, "training_loss": 0.6921489715576172, "training_acc": 52.0, "val_loss": 0.6898835492134094, "val_acc": 56.0}
{"epoch": 14, "training_loss": 0.6924055242538452, "training_acc": 52.0, "val_loss": 0.6898635458946228, "val_acc": 56.0}
{"epoch": 15, "training_loss": 0.692273313999176, "training_acc": 52.0, "val_loss": 0.6898548626899719, "val_acc": 56.0}
{"epoch": 16, "training_loss": 0.6922986507415771, "training_acc": 52.0, "val_loss": 0.689815571308136, "val_acc": 56.0}
{"epoch": 17, "training_loss": 0.6923404359817504, "training_acc": 52.0, "val_loss": 0.6898179173469543, "val_acc": 56.0}
{"epoch": 18, "training_loss": 0.6924176812171936, "training_acc": 52.0, "val_loss": 0.6898283958435059, "val_acc": 56.0}
{"epoch": 19, "training_loss": 0.6922322368621826, "training_acc": 52.0, "val_loss": 0.6898415875434876, "val_acc": 56.0}
{"epoch": 20, "training_loss": 0.6923714065551758, "training_acc": 52.0, "val_loss": 0.6898380708694458, "val_acc": 56.0}
{"epoch": 21, "training_loss": 0.6925449705123902, "training_acc": 52.0, "val_loss": 0.6898354983329773, "val_acc": 56.0}
{"epoch": 22, "training_loss": 0.6923123645782471, "training_acc": 52.0, "val_loss": 0.6898237824440002, "val_acc": 56.0}
{"epoch": 23, "training_loss": 0.6925425910949707, "training_acc": 52.0, "val_loss": 0.6898249745368957, "val_acc": 56.0}
{"epoch": 24, "training_loss": 0.6924215364456177, "training_acc": 52.0, "val_loss": 0.6898099851608276, "val_acc": 56.0}
{"epoch": 25, "training_loss": 0.6925068736076355, "training_acc": 52.0, "val_loss": 0.6898094224929809, "val_acc": 56.0}
{"epoch": 26, "training_loss": 0.6924462103843689, "training_acc": 52.0, "val_loss": 0.6898016810417176, "val_acc": 56.0}
{"epoch": 27, "training_loss": 0.6922994828224183, "training_acc": 52.0, "val_loss": 0.6898096036911011, "val_acc": 56.0}
{"epoch": 28, "training_loss": 0.6922710514068604, "training_acc": 52.0, "val_loss": 0.689806318283081, "val_acc": 56.0}
{"epoch": 29, "training_loss": 0.6923337554931641, "training_acc": 52.0, "val_loss": 0.6897919464111328, "val_acc": 56.0}
{"epoch": 30, "training_loss": 0.6925094103813172, "training_acc": 52.0, "val_loss": 0.6897500419616699, "val_acc": 56.0}
{"epoch": 31, "training_loss": 0.6922385549545288, "training_acc": 52.0, "val_loss": 0.6897332000732422, "val_acc": 56.0}
{"epoch": 32, "training_loss": 0.6923677539825439, "training_acc": 52.0, "val_loss": 0.6896961951255798, "val_acc": 56.0}
{"epoch": 33, "training_loss": 0.6923983669281006, "training_acc": 52.0, "val_loss": 0.6896692276000976, "val_acc": 56.0}
{"epoch": 34, "training_loss": 0.6923372888565064, "training_acc": 52.0, "val_loss": 0.6896658062934875, "val_acc": 56.0}
{"epoch": 35, "training_loss": 0.6924927639961242, "training_acc": 52.0, "val_loss": 0.6896719670295716, "val_acc": 56.0}
{"epoch": 36, "training_loss": 0.6924521160125733, "training_acc": 52.0, "val_loss": 0.6896627426147461, "val_acc": 56.0}
{"epoch": 37, "training_loss": 0.6923737573623657, "training_acc": 52.0, "val_loss": 0.6896511197090149, "val_acc": 56.0}
{"epoch": 38, "training_loss": 0.6924513792991638, "training_acc": 52.0, "val_loss": 0.6896496987342835, "val_acc": 56.0}
{"epoch": 39, "training_loss": 0.6922935628890992, "training_acc": 52.0, "val_loss": 0.6896547365188599, "val_acc": 56.0}
{"epoch": 40, "training_loss": 0.6923631477355957, "training_acc": 52.0, "val_loss": 0.6896643829345703, "val_acc": 56.0}
{"epoch": 41, "training_loss": 0.6924668216705322, "training_acc": 52.0, "val_loss": 0.6896674466133118, "val_acc": 56.0}
{"epoch": 42, "training_loss": 0.6922564530372619, "training_acc": 52.0, "val_loss": 0.6896633100509644, "val_acc": 56.0}
{"epoch": 43, "training_loss": 0.6923137092590332, "training_acc": 52.0, "val_loss": 0.6896616625785827, "val_acc": 56.0}
{"epoch": 44, "training_loss": 0.6922397303581238, "training_acc": 52.0, "val_loss": 0.6896864628791809, "val_acc": 56.0}
{"epoch": 45, "training_loss": 0.6923085165023803, "training_acc": 52.0, "val_loss": 0.68968736410141, "val_acc": 56.0}
{"epoch": 46, "training_loss": 0.6925815057754516, "training_acc": 52.0, "val_loss": 0.6896891093254089, "val_acc": 56.0}
{"epoch": 47, "training_loss": 0.692456636428833, "training_acc": 52.0, "val_loss": 0.689675064086914, "val_acc": 56.0}
{"epoch": 48, "training_loss": 0.692400541305542, "training_acc": 52.0, "val_loss": 0.6896738743782044, "val_acc": 56.0}
{"epoch": 49, "training_loss": 0.6923520851135254, "training_acc": 52.0, "val_loss": 0.6896773171424866, "val_acc": 56.0}
{"epoch": 50, "training_loss": 0.692402868270874, "training_acc": 52.0, "val_loss": 0.689690465927124, "val_acc": 56.0}
{"epoch": 51, "training_loss": 0.6923534011840821, "training_acc": 52.0, "val_loss": 0.6897130966186523, "val_acc": 56.0}
{"epoch": 52, "training_loss": 0.6924320960044861, "training_acc": 52.0, "val_loss": 0.6897373175621033, "val_acc": 56.0}
{"epoch": 53, "training_loss": 0.6923778247833252, "training_acc": 52.0, "val_loss": 0.6897442269325257, "val_acc": 56.0}
{"epoch": 54, "training_loss": 0.6922716903686523, "training_acc": 52.0, "val_loss": 0.6897487711906433, "val_acc": 56.0}
{"epoch": 55, "training_loss": 0.6922851777076722, "training_acc": 52.0, "val_loss": 0.689774124622345, "val_acc": 56.0}
{"epoch": 56, "training_loss": 0.6921900248527527, "training_acc": 52.0, "val_loss": 0.689805600643158, "val_acc": 56.0}
{"epoch": 57, "training_loss": 0.6923310279846191, "training_acc": 52.0, "val_loss": 0.689849214553833, "val_acc": 56.0}
