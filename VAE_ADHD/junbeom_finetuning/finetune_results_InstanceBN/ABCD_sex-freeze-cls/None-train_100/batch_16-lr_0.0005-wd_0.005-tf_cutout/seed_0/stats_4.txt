"main_modify.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option BT_org --learning_rate 5e-4 --batch_size 16 --weight_decay 5e-3 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 0.7225832080841065, "training_acc": 45.0, "val_loss": 0.7001886677742004, "val_acc": 52.0}
{"epoch": 1, "training_loss": 0.6922844314575195, "training_acc": 53.0, "val_loss": 0.6930359697341919, "val_acc": 52.0}
{"epoch": 2, "training_loss": 0.7022392797470093, "training_acc": 43.0, "val_loss": 0.697542417049408, "val_acc": 48.0}
{"epoch": 3, "training_loss": 0.6912335777282714, "training_acc": 51.0, "val_loss": 0.6937673687934875, "val_acc": 52.0}
{"epoch": 4, "training_loss": 0.69847647190094, "training_acc": 53.0, "val_loss": 0.7119689512252808, "val_acc": 52.0}
{"epoch": 5, "training_loss": 0.7064142322540283, "training_acc": 53.0, "val_loss": 0.6999655652046204, "val_acc": 52.0}
{"epoch": 6, "training_loss": 0.6950689792633057, "training_acc": 53.0, "val_loss": 0.6928637766838074, "val_acc": 52.0}
{"epoch": 7, "training_loss": 0.6944977045059204, "training_acc": 45.0, "val_loss": 0.693492271900177, "val_acc": 48.0}
{"epoch": 8, "training_loss": 0.6932630014419555, "training_acc": 47.0, "val_loss": 0.6923264193534852, "val_acc": 52.0}
{"epoch": 9, "training_loss": 0.6920224666595459, "training_acc": 53.0, "val_loss": 0.6949114871025085, "val_acc": 52.0}
{"epoch": 10, "training_loss": 0.6927329206466675, "training_acc": 53.0, "val_loss": 0.6926064825057984, "val_acc": 52.0}
{"epoch": 11, "training_loss": 0.6932696390151978, "training_acc": 53.0, "val_loss": 0.692306842803955, "val_acc": 52.0}
{"epoch": 12, "training_loss": 0.6954633712768554, "training_acc": 47.0, "val_loss": 0.6953568148612976, "val_acc": 48.0}
{"epoch": 13, "training_loss": 0.6979369831085205, "training_acc": 49.0, "val_loss": 0.6932696151733398, "val_acc": 52.0}
{"epoch": 14, "training_loss": 0.6937604522705079, "training_acc": 53.0, "val_loss": 0.6939103627204894, "val_acc": 52.0}
{"epoch": 15, "training_loss": 0.6888454008102417, "training_acc": 53.0, "val_loss": 0.6928865075111389, "val_acc": 52.0}
{"epoch": 16, "training_loss": 0.6954477953910828, "training_acc": 49.0, "val_loss": 0.6961652684211731, "val_acc": 48.0}
{"epoch": 17, "training_loss": 0.692881281375885, "training_acc": 51.0, "val_loss": 0.6952774381637573, "val_acc": 52.0}
{"epoch": 18, "training_loss": 0.6962248730659485, "training_acc": 53.0, "val_loss": 0.6958019375801087, "val_acc": 52.0}
{"epoch": 19, "training_loss": 0.6970409393310547, "training_acc": 53.0, "val_loss": 0.6923542809486389, "val_acc": 52.0}
{"epoch": 20, "training_loss": 0.6922708463668823, "training_acc": 53.0, "val_loss": 0.6922845911979675, "val_acc": 52.0}
{"epoch": 21, "training_loss": 0.6938489413261414, "training_acc": 53.0, "val_loss": 0.6929488849639892, "val_acc": 52.0}
{"epoch": 22, "training_loss": 0.6931962108612061, "training_acc": 53.0, "val_loss": 0.6948028230667114, "val_acc": 52.0}
{"epoch": 23, "training_loss": 0.693102056980133, "training_acc": 53.0, "val_loss": 0.69276034116745, "val_acc": 52.0}
{"epoch": 24, "training_loss": 0.6924366903305054, "training_acc": 53.0, "val_loss": 0.6925472474098205, "val_acc": 52.0}
{"epoch": 25, "training_loss": 0.6933364200592042, "training_acc": 53.0, "val_loss": 0.6927588653564453, "val_acc": 52.0}
{"epoch": 26, "training_loss": 0.6907325148582458, "training_acc": 53.0, "val_loss": 0.6930460453033447, "val_acc": 60.0}
{"epoch": 27, "training_loss": 0.7064890003204346, "training_acc": 40.0, "val_loss": 0.6940127730369567, "val_acc": 48.0}
{"epoch": 28, "training_loss": 0.7068977618217468, "training_acc": 49.0, "val_loss": 0.7040448784828186, "val_acc": 52.0}
{"epoch": 29, "training_loss": 0.7034250140190125, "training_acc": 53.0, "val_loss": 0.6988087487220764, "val_acc": 52.0}
{"epoch": 30, "training_loss": 0.7048500776290894, "training_acc": 43.0, "val_loss": 0.6975558090209961, "val_acc": 48.0}
{"epoch": 31, "training_loss": 0.6961872124671936, "training_acc": 49.0, "val_loss": 0.6924221754074097, "val_acc": 52.0}
{"epoch": 32, "training_loss": 0.6998126745223999, "training_acc": 53.0, "val_loss": 0.6992630457878113, "val_acc": 52.0}
{"epoch": 33, "training_loss": 0.6992228126525879, "training_acc": 53.0, "val_loss": 0.6966276168823242, "val_acc": 52.0}
{"epoch": 34, "training_loss": 0.6932120108604432, "training_acc": 53.0, "val_loss": 0.6924196672439575, "val_acc": 52.0}
{"epoch": 35, "training_loss": 0.6933549022674561, "training_acc": 53.0, "val_loss": 0.6922714734077453, "val_acc": 52.0}
{"epoch": 36, "training_loss": 0.7034712910652161, "training_acc": 53.0, "val_loss": 0.6966829490661621, "val_acc": 52.0}
{"epoch": 37, "training_loss": 0.6926035857200623, "training_acc": 54.0, "val_loss": 0.6943064212799073, "val_acc": 48.0}
{"epoch": 38, "training_loss": 0.6949566030502319, "training_acc": 45.0, "val_loss": 0.6922704195976257, "val_acc": 52.0}
{"epoch": 39, "training_loss": 0.6926843810081482, "training_acc": 53.0, "val_loss": 0.6963402962684632, "val_acc": 52.0}
{"epoch": 40, "training_loss": 0.6945958995819091, "training_acc": 53.0, "val_loss": 0.69227046251297, "val_acc": 52.0}
{"epoch": 41, "training_loss": 0.6937829732894898, "training_acc": 48.0, "val_loss": 0.6923495984077453, "val_acc": 52.0}
{"epoch": 42, "training_loss": 0.6911534976959228, "training_acc": 53.0, "val_loss": 0.6989418983459472, "val_acc": 52.0}
{"epoch": 43, "training_loss": 0.6995273017883301, "training_acc": 53.0, "val_loss": 0.7007144522666932, "val_acc": 52.0}
{"epoch": 44, "training_loss": 0.6970220375061035, "training_acc": 53.0, "val_loss": 0.693708074092865, "val_acc": 52.0}
{"epoch": 45, "training_loss": 0.6926733303070068, "training_acc": 53.0, "val_loss": 0.6931122612953186, "val_acc": 52.0}
{"epoch": 46, "training_loss": 0.6915472745895386, "training_acc": 53.0, "val_loss": 0.6924224352836609, "val_acc": 52.0}
{"epoch": 47, "training_loss": 0.693011474609375, "training_acc": 53.0, "val_loss": 0.6926404905319213, "val_acc": 52.0}
{"epoch": 48, "training_loss": 0.6979315662384034, "training_acc": 53.0, "val_loss": 0.694208984375, "val_acc": 52.0}
{"epoch": 49, "training_loss": 0.6931940221786499, "training_acc": 53.0, "val_loss": 0.6922705006599427, "val_acc": 52.0}
{"epoch": 50, "training_loss": 0.6932618474960327, "training_acc": 51.0, "val_loss": 0.6983284497261047, "val_acc": 48.0}
{"epoch": 51, "training_loss": 0.703384313583374, "training_acc": 41.0, "val_loss": 0.692375099658966, "val_acc": 52.0}
{"epoch": 52, "training_loss": 0.6935362386703491, "training_acc": 49.0, "val_loss": 0.6927411007881165, "val_acc": 52.0}
{"epoch": 53, "training_loss": 0.6928415656089782, "training_acc": 53.0, "val_loss": 0.6936312198638916, "val_acc": 52.0}
{"epoch": 54, "training_loss": 0.6945130920410156, "training_acc": 53.0, "val_loss": 0.6924152851104737, "val_acc": 52.0}
{"epoch": 55, "training_loss": 0.6970521306991577, "training_acc": 47.0, "val_loss": 0.6996380519866944, "val_acc": 48.0}
{"epoch": 56, "training_loss": 0.6959648990631103, "training_acc": 49.0, "val_loss": 0.6931216478347778, "val_acc": 52.0}
{"epoch": 57, "training_loss": 0.6937455463409424, "training_acc": 53.0, "val_loss": 0.6946059322357178, "val_acc": 52.0}
