"main_modify.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option BT_org --learning_rate 5e-4 --batch_size 16 --weight_decay 5e-3 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 0.6895563077926635, "training_acc": 55.0, "val_loss": 0.7023171234130859, "val_acc": 52.0}
{"epoch": 1, "training_loss": 0.7222578620910645, "training_acc": 53.0, "val_loss": 0.7223849606513977, "val_acc": 52.0}
{"epoch": 2, "training_loss": 0.7156242752075195, "training_acc": 53.0, "val_loss": 0.6929234194755555, "val_acc": 52.0}
{"epoch": 3, "training_loss": 0.6942303991317749, "training_acc": 53.0, "val_loss": 0.6924700212478637, "val_acc": 52.0}
{"epoch": 4, "training_loss": 0.6944962096214294, "training_acc": 53.0, "val_loss": 0.6924985456466675, "val_acc": 52.0}
{"epoch": 5, "training_loss": 0.6939709663391114, "training_acc": 50.0, "val_loss": 0.6924303078651428, "val_acc": 52.0}
{"epoch": 6, "training_loss": 0.6955279183387756, "training_acc": 53.0, "val_loss": 0.6953746438026428, "val_acc": 52.0}
{"epoch": 7, "training_loss": 0.6948122262954712, "training_acc": 53.0, "val_loss": 0.6938782835006714, "val_acc": 52.0}
{"epoch": 8, "training_loss": 0.6964272952079773, "training_acc": 49.0, "val_loss": 0.6971545171737671, "val_acc": 48.0}
{"epoch": 9, "training_loss": 0.6998380136489868, "training_acc": 41.0, "val_loss": 0.6924728369712829, "val_acc": 52.0}
{"epoch": 10, "training_loss": 0.6933314299583435, "training_acc": 53.0, "val_loss": 0.6929993486404419, "val_acc": 52.0}
{"epoch": 11, "training_loss": 0.6942218160629272, "training_acc": 53.0, "val_loss": 0.6935654020309449, "val_acc": 52.0}
{"epoch": 12, "training_loss": 0.695184097290039, "training_acc": 53.0, "val_loss": 0.6989713358879089, "val_acc": 52.0}
{"epoch": 13, "training_loss": 0.694343318939209, "training_acc": 53.0, "val_loss": 0.6933005976676941, "val_acc": 52.0}
{"epoch": 14, "training_loss": 0.7006032490730285, "training_acc": 37.0, "val_loss": 0.6944942188262939, "val_acc": 48.0}
{"epoch": 15, "training_loss": 0.6972047567367554, "training_acc": 45.0, "val_loss": 0.6924820709228515, "val_acc": 52.0}
{"epoch": 16, "training_loss": 0.6980495619773864, "training_acc": 53.0, "val_loss": 0.6946279501914978, "val_acc": 52.0}
{"epoch": 17, "training_loss": 0.6952345418930054, "training_acc": 53.0, "val_loss": 0.6942887806892395, "val_acc": 52.0}
{"epoch": 18, "training_loss": 0.6948802661895752, "training_acc": 53.0, "val_loss": 0.6923865532875061, "val_acc": 52.0}
{"epoch": 19, "training_loss": 0.6929146480560303, "training_acc": 53.0, "val_loss": 0.6930107164382935, "val_acc": 52.0}
{"epoch": 20, "training_loss": 0.6922461414337158, "training_acc": 53.0, "val_loss": 0.6928089952468872, "val_acc": 52.0}
{"epoch": 21, "training_loss": 0.6962158584594726, "training_acc": 53.0, "val_loss": 0.6925318646430969, "val_acc": 52.0}
{"epoch": 22, "training_loss": 0.690782196521759, "training_acc": 53.0, "val_loss": 0.6935164356231689, "val_acc": 52.0}
{"epoch": 23, "training_loss": 0.6959912753105164, "training_acc": 53.0, "val_loss": 0.6948050999641419, "val_acc": 52.0}
{"epoch": 24, "training_loss": 0.7015445041656494, "training_acc": 52.0, "val_loss": 0.6933940863609314, "val_acc": 48.0}
{"epoch": 25, "training_loss": 0.6967933368682862, "training_acc": 45.0, "val_loss": 0.6923603081703186, "val_acc": 52.0}
{"epoch": 26, "training_loss": 0.6943974447250366, "training_acc": 53.0, "val_loss": 0.694581196308136, "val_acc": 52.0}
{"epoch": 27, "training_loss": 0.6974606466293335, "training_acc": 47.0, "val_loss": 0.6947478079795837, "val_acc": 48.0}
{"epoch": 28, "training_loss": 0.6972823405265808, "training_acc": 47.0, "val_loss": 0.693101236820221, "val_acc": 52.0}
{"epoch": 29, "training_loss": 0.6976662492752075, "training_acc": 51.0, "val_loss": 0.6987362003326416, "val_acc": 52.0}
{"epoch": 30, "training_loss": 0.706839714050293, "training_acc": 53.0, "val_loss": 0.7013033986091614, "val_acc": 52.0}
{"epoch": 31, "training_loss": 0.6930888986587525, "training_acc": 53.0, "val_loss": 0.693482563495636, "val_acc": 48.0}
{"epoch": 32, "training_loss": 0.7024695038795471, "training_acc": 47.0, "val_loss": 0.6936862254142762, "val_acc": 48.0}
{"epoch": 33, "training_loss": 0.6937634468078613, "training_acc": 49.0, "val_loss": 0.69236412525177, "val_acc": 52.0}
{"epoch": 34, "training_loss": 0.6931624937057496, "training_acc": 53.0, "val_loss": 0.6932162094116211, "val_acc": 52.0}
{"epoch": 35, "training_loss": 0.6942887258529663, "training_acc": 53.0, "val_loss": 0.695649082660675, "val_acc": 52.0}
{"epoch": 36, "training_loss": 0.6990054035186768, "training_acc": 53.0, "val_loss": 0.6925405669212341, "val_acc": 52.0}
{"epoch": 37, "training_loss": 0.6919900465011597, "training_acc": 53.0, "val_loss": 0.6925631642341614, "val_acc": 52.0}
{"epoch": 38, "training_loss": 0.7008475875854492, "training_acc": 39.0, "val_loss": 0.692834062576294, "val_acc": 52.0}
{"epoch": 39, "training_loss": 0.6971777629852295, "training_acc": 53.0, "val_loss": 0.6936830925941467, "val_acc": 52.0}
{"epoch": 40, "training_loss": 0.6904844188690186, "training_acc": 53.0, "val_loss": 0.692371244430542, "val_acc": 52.0}
{"epoch": 41, "training_loss": 0.6964451026916504, "training_acc": 41.0, "val_loss": 0.6934988617897033, "val_acc": 48.0}
{"epoch": 42, "training_loss": 0.6960346078872681, "training_acc": 49.0, "val_loss": 0.6928732633590698, "val_acc": 52.0}
{"epoch": 43, "training_loss": 0.6941655778884888, "training_acc": 53.0, "val_loss": 0.6935343980789185, "val_acc": 52.0}
{"epoch": 44, "training_loss": 0.6930811476707458, "training_acc": 53.0, "val_loss": 0.6928616786003112, "val_acc": 52.0}
