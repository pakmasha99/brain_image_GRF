"main_modify.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option BT_org --learning_rate 1e-3 --batch_size 16 --weight_decay 1e-3 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 0.7093290090560913, "training_acc": 46.0, "val_loss": 0.6966033434867859, "val_acc": 44.0}
{"epoch": 1, "training_loss": 0.6996253967285156, "training_acc": 48.0, "val_loss": 0.6862156081199646, "val_acc": 56.0}
{"epoch": 2, "training_loss": 0.6987174677848816, "training_acc": 44.0, "val_loss": 0.6914553904533386, "val_acc": 56.0}
{"epoch": 3, "training_loss": 0.7027939558029175, "training_acc": 52.0, "val_loss": 0.6865316367149353, "val_acc": 56.0}
{"epoch": 4, "training_loss": 0.7018653774261474, "training_acc": 50.0, "val_loss": 0.7042999005317688, "val_acc": 44.0}
{"epoch": 5, "training_loss": 0.6977102899551392, "training_acc": 49.0, "val_loss": 0.6857938981056213, "val_acc": 56.0}
{"epoch": 6, "training_loss": 0.6965576481819152, "training_acc": 52.0, "val_loss": 0.687099130153656, "val_acc": 56.0}
{"epoch": 7, "training_loss": 0.7015139436721802, "training_acc": 44.0, "val_loss": 0.6967042708396911, "val_acc": 44.0}
{"epoch": 8, "training_loss": 0.7071680045127868, "training_acc": 46.0, "val_loss": 0.6858171820640564, "val_acc": 56.0}
{"epoch": 9, "training_loss": 0.6991385293006896, "training_acc": 44.0, "val_loss": 0.701247935295105, "val_acc": 44.0}
{"epoch": 10, "training_loss": 0.7067093801498413, "training_acc": 48.0, "val_loss": 0.7011344647407531, "val_acc": 44.0}
{"epoch": 11, "training_loss": 0.6925318002700805, "training_acc": 54.0, "val_loss": 0.6892858505249023, "val_acc": 56.0}
{"epoch": 12, "training_loss": 0.7371919775009155, "training_acc": 52.0, "val_loss": 0.6883301949501037, "val_acc": 56.0}
{"epoch": 13, "training_loss": 0.7149387502670288, "training_acc": 46.0, "val_loss": 0.7157472252845765, "val_acc": 44.0}
{"epoch": 14, "training_loss": 0.6963973712921142, "training_acc": 52.0, "val_loss": 0.6859702563285828, "val_acc": 56.0}
{"epoch": 15, "training_loss": 0.6972086477279663, "training_acc": 52.0, "val_loss": 0.685823585987091, "val_acc": 56.0}
{"epoch": 16, "training_loss": 0.7077843427658081, "training_acc": 52.0, "val_loss": 0.6862740993499756, "val_acc": 56.0}
{"epoch": 17, "training_loss": 0.7005766057968139, "training_acc": 48.0, "val_loss": 0.7256297469139099, "val_acc": 44.0}
{"epoch": 18, "training_loss": 0.7114025068283081, "training_acc": 48.0, "val_loss": 0.6971883296966552, "val_acc": 44.0}
{"epoch": 19, "training_loss": 0.6951895761489868, "training_acc": 48.0, "val_loss": 0.6862106275558472, "val_acc": 56.0}
{"epoch": 20, "training_loss": 0.6975225853919983, "training_acc": 52.0, "val_loss": 0.685774519443512, "val_acc": 56.0}
{"epoch": 21, "training_loss": 0.7004619789123535, "training_acc": 46.0, "val_loss": 0.6955082297325135, "val_acc": 44.0}
{"epoch": 22, "training_loss": 0.7000447797775269, "training_acc": 46.0, "val_loss": 0.6881406331062316, "val_acc": 56.0}
{"epoch": 23, "training_loss": 0.6918006801605224, "training_acc": 54.0, "val_loss": 0.6940316557884216, "val_acc": 44.0}
{"epoch": 24, "training_loss": 0.705641770362854, "training_acc": 48.0, "val_loss": 0.6858441996574401, "val_acc": 56.0}
{"epoch": 25, "training_loss": 0.6930827951431274, "training_acc": 48.0, "val_loss": 0.708686113357544, "val_acc": 44.0}
{"epoch": 26, "training_loss": 0.7093747329711914, "training_acc": 38.0, "val_loss": 0.6901221895217895, "val_acc": 56.0}
{"epoch": 27, "training_loss": 0.6955336284637451, "training_acc": 52.0, "val_loss": 0.6906927394866943, "val_acc": 56.0}
{"epoch": 28, "training_loss": 0.6968400382995605, "training_acc": 51.0, "val_loss": 0.6881155753135682, "val_acc": 56.0}
{"epoch": 29, "training_loss": 0.6958558988571167, "training_acc": 52.0, "val_loss": 0.6858124256134033, "val_acc": 56.0}
{"epoch": 30, "training_loss": 0.7165255856513977, "training_acc": 52.0, "val_loss": 0.6870321011543274, "val_acc": 56.0}
{"epoch": 31, "training_loss": 0.7082633781433105, "training_acc": 43.0, "val_loss": 0.6953108716011047, "val_acc": 44.0}
{"epoch": 32, "training_loss": 0.6990107870101929, "training_acc": 52.0, "val_loss": 0.6884630513191223, "val_acc": 56.0}
{"epoch": 33, "training_loss": 0.7029380679130555, "training_acc": 52.0, "val_loss": 0.6882806324958801, "val_acc": 56.0}
{"epoch": 34, "training_loss": 0.6966619062423706, "training_acc": 46.0, "val_loss": 0.7116844367980957, "val_acc": 44.0}
{"epoch": 35, "training_loss": 0.7026302003860474, "training_acc": 48.0, "val_loss": 0.6926134014129639, "val_acc": 56.0}
{"epoch": 36, "training_loss": 0.6975615358352661, "training_acc": 52.0, "val_loss": 0.6880269980430603, "val_acc": 56.0}
{"epoch": 37, "training_loss": 0.7061403369903565, "training_acc": 52.0, "val_loss": 0.6873281908035278, "val_acc": 56.0}
{"epoch": 38, "training_loss": 0.7076101589202881, "training_acc": 44.0, "val_loss": 0.7043074989318847, "val_acc": 44.0}
{"epoch": 39, "training_loss": 0.6984825229644775, "training_acc": 44.0, "val_loss": 0.6890577936172485, "val_acc": 56.0}
