"main_modify.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 2 --task ABCD_sex --input_option BT_org --learning_rate 1e-3 --batch_size 16 --weight_decay 1e-3 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 0.7035085391998291, "training_acc": 49.0, "val_loss": 0.6942741870880127, "val_acc": 48.0}
{"epoch": 1, "training_loss": 0.7051038885116577, "training_acc": 47.0, "val_loss": 0.6924336242675782, "val_acc": 52.0}
{"epoch": 2, "training_loss": 0.7024158763885499, "training_acc": 53.0, "val_loss": 0.7166976690292358, "val_acc": 52.0}
{"epoch": 3, "training_loss": 0.7036497163772583, "training_acc": 53.0, "val_loss": 0.6924128079414368, "val_acc": 52.0}
{"epoch": 4, "training_loss": 0.6935474061965943, "training_acc": 53.0, "val_loss": 0.6924866700172424, "val_acc": 52.0}
{"epoch": 5, "training_loss": 0.6957885360717774, "training_acc": 53.0, "val_loss": 0.6973703002929688, "val_acc": 52.0}
{"epoch": 6, "training_loss": 0.7058363032341003, "training_acc": 53.0, "val_loss": 0.6994440484046937, "val_acc": 52.0}
{"epoch": 7, "training_loss": 0.698523998260498, "training_acc": 53.0, "val_loss": 0.6925766801834107, "val_acc": 52.0}
{"epoch": 8, "training_loss": 0.6932119750976562, "training_acc": 53.0, "val_loss": 0.6925663137435913, "val_acc": 52.0}
{"epoch": 9, "training_loss": 0.6948490858078002, "training_acc": 53.0, "val_loss": 0.6930321907997131, "val_acc": 52.0}
{"epoch": 10, "training_loss": 0.691999659538269, "training_acc": 53.0, "val_loss": 0.6964044070243836, "val_acc": 52.0}
{"epoch": 11, "training_loss": 0.7002461957931518, "training_acc": 53.0, "val_loss": 0.6937158179283142, "val_acc": 52.0}
{"epoch": 12, "training_loss": 0.7010474443435669, "training_acc": 48.0, "val_loss": 0.6930902886390686, "val_acc": 52.0}
{"epoch": 13, "training_loss": 0.7069797468185425, "training_acc": 53.0, "val_loss": 0.7085832023620605, "val_acc": 52.0}
{"epoch": 14, "training_loss": 0.7205685520172119, "training_acc": 45.0, "val_loss": 0.7015989780426025, "val_acc": 48.0}
{"epoch": 15, "training_loss": 0.6963472723960876, "training_acc": 49.0, "val_loss": 0.6985612440109253, "val_acc": 52.0}
{"epoch": 16, "training_loss": 0.6997797417640687, "training_acc": 53.0, "val_loss": 0.6955245423316956, "val_acc": 52.0}
{"epoch": 17, "training_loss": 0.7009676051139831, "training_acc": 45.0, "val_loss": 0.6936885380744934, "val_acc": 48.0}
{"epoch": 18, "training_loss": 0.6994091010093689, "training_acc": 45.0, "val_loss": 0.6958763980865479, "val_acc": 52.0}
{"epoch": 19, "training_loss": 0.6970300793647766, "training_acc": 53.0, "val_loss": 0.6958729767799378, "val_acc": 52.0}
{"epoch": 20, "training_loss": 0.7000180578231812, "training_acc": 53.0, "val_loss": 0.6926176381111145, "val_acc": 52.0}
{"epoch": 21, "training_loss": 0.7178211784362794, "training_acc": 47.0, "val_loss": 0.7076932597160339, "val_acc": 48.0}
{"epoch": 22, "training_loss": 0.7024917936325074, "training_acc": 51.0, "val_loss": 0.7066888380050659, "val_acc": 52.0}
{"epoch": 23, "training_loss": 0.6965379786491394, "training_acc": 53.0, "val_loss": 0.6923981118202209, "val_acc": 52.0}
{"epoch": 24, "training_loss": 0.6958374977111816, "training_acc": 45.0, "val_loss": 0.6924170780181885, "val_acc": 52.0}
{"epoch": 25, "training_loss": 0.6956585693359375, "training_acc": 53.0, "val_loss": 0.6933375144004822, "val_acc": 52.0}
{"epoch": 26, "training_loss": 0.6905118036270141, "training_acc": 53.0, "val_loss": 0.6949060463905334, "val_acc": 48.0}
{"epoch": 27, "training_loss": 0.6943792223930358, "training_acc": 51.0, "val_loss": 0.6981390452384949, "val_acc": 52.0}
{"epoch": 28, "training_loss": 0.696740665435791, "training_acc": 53.0, "val_loss": 0.6951300692558289, "val_acc": 52.0}
{"epoch": 29, "training_loss": 0.69661949634552, "training_acc": 53.0, "val_loss": 0.6925891971588135, "val_acc": 52.0}
{"epoch": 30, "training_loss": 0.695161201953888, "training_acc": 53.0, "val_loss": 0.6930354356765747, "val_acc": 52.0}
{"epoch": 31, "training_loss": 0.6939195823669434, "training_acc": 53.0, "val_loss": 0.6948973035812378, "val_acc": 52.0}
{"epoch": 32, "training_loss": 0.6935475659370423, "training_acc": 53.0, "val_loss": 0.6926132225990296, "val_acc": 52.0}
{"epoch": 33, "training_loss": 0.703159282207489, "training_acc": 53.0, "val_loss": 0.6928347611427307, "val_acc": 52.0}
{"epoch": 34, "training_loss": 0.6929036521911621, "training_acc": 51.0, "val_loss": 0.6948369121551514, "val_acc": 48.0}
{"epoch": 35, "training_loss": 0.6981810092926025, "training_acc": 43.0, "val_loss": 0.6941937708854675, "val_acc": 52.0}
{"epoch": 36, "training_loss": 0.6943734979629517, "training_acc": 53.0, "val_loss": 0.6939421963691711, "val_acc": 52.0}
{"epoch": 37, "training_loss": 0.7050161170959472, "training_acc": 43.0, "val_loss": 0.6979226231575012, "val_acc": 48.0}
{"epoch": 38, "training_loss": 0.6928477215766907, "training_acc": 49.0, "val_loss": 0.6991193628311158, "val_acc": 52.0}
{"epoch": 39, "training_loss": 0.6971647953987121, "training_acc": 53.0, "val_loss": 0.6944638872146607, "val_acc": 52.0}
{"epoch": 40, "training_loss": 0.700059220790863, "training_acc": 45.0, "val_loss": 0.6950956273078919, "val_acc": 48.0}
{"epoch": 41, "training_loss": 0.6952848863601685, "training_acc": 47.0, "val_loss": 0.6938045454025269, "val_acc": 52.0}
{"epoch": 42, "training_loss": 0.6940978932380676, "training_acc": 53.0, "val_loss": 0.6941115808486938, "val_acc": 52.0}
