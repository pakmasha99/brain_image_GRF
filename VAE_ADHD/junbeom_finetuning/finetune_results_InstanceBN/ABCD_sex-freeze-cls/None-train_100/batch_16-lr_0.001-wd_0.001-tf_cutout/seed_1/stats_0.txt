"main_modify.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 1 --task ABCD_sex --input_option BT_org --learning_rate 1e-3 --batch_size 16 --weight_decay 1e-3 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 0.7080749297142028, "training_acc": 47.0, "val_loss": 0.716725902557373, "val_acc": 52.0}
{"epoch": 1, "training_loss": 0.7345347881317139, "training_acc": 53.0, "val_loss": 0.7051826858520508, "val_acc": 52.0}
{"epoch": 2, "training_loss": 0.6998785972595215, "training_acc": 53.0, "val_loss": 0.6923682808876037, "val_acc": 52.0}
{"epoch": 3, "training_loss": 0.7028909206390381, "training_acc": 41.0, "val_loss": 0.6925615286827087, "val_acc": 52.0}
{"epoch": 4, "training_loss": 0.6921515274047851, "training_acc": 53.0, "val_loss": 0.694695017337799, "val_acc": 52.0}
{"epoch": 5, "training_loss": 0.7100730681419373, "training_acc": 53.0, "val_loss": 0.7097811508178711, "val_acc": 52.0}
{"epoch": 6, "training_loss": 0.7018266153335572, "training_acc": 53.0, "val_loss": 0.692586178779602, "val_acc": 52.0}
{"epoch": 7, "training_loss": 0.7066834926605224, "training_acc": 49.0, "val_loss": 0.6988800740242005, "val_acc": 48.0}
{"epoch": 8, "training_loss": 0.6928908705711365, "training_acc": 49.0, "val_loss": 0.6968569302558899, "val_acc": 52.0}
{"epoch": 9, "training_loss": 0.7045865797996521, "training_acc": 53.0, "val_loss": 0.6962132596969605, "val_acc": 52.0}
{"epoch": 10, "training_loss": 0.7061099743843079, "training_acc": 42.0, "val_loss": 0.6974386882781982, "val_acc": 48.0}
{"epoch": 11, "training_loss": 0.6935153007507324, "training_acc": 49.0, "val_loss": 0.6948212003707885, "val_acc": 52.0}
{"epoch": 12, "training_loss": 0.7002201890945434, "training_acc": 53.0, "val_loss": 0.7036525702476502, "val_acc": 52.0}
{"epoch": 13, "training_loss": 0.6912426424026489, "training_acc": 53.0, "val_loss": 0.6937032294273376, "val_acc": 48.0}
{"epoch": 14, "training_loss": 0.7162107610702515, "training_acc": 47.0, "val_loss": 0.7031886339187622, "val_acc": 48.0}
{"epoch": 15, "training_loss": 0.728451759815216, "training_acc": 39.0, "val_loss": 0.7024674415588379, "val_acc": 52.0}
{"epoch": 16, "training_loss": 0.6941020584106445, "training_acc": 53.0, "val_loss": 0.6925065469741821, "val_acc": 52.0}
{"epoch": 17, "training_loss": 0.693365912437439, "training_acc": 53.0, "val_loss": 0.6923302984237671, "val_acc": 52.0}
{"epoch": 18, "training_loss": 0.6939845895767212, "training_acc": 49.0, "val_loss": 0.6927863597869873, "val_acc": 52.0}
{"epoch": 19, "training_loss": 0.6895132184028625, "training_acc": 53.0, "val_loss": 0.6977464318275451, "val_acc": 52.0}
{"epoch": 20, "training_loss": 0.7036938810348511, "training_acc": 53.0, "val_loss": 0.6937694668769836, "val_acc": 52.0}
{"epoch": 21, "training_loss": 0.6956801176071167, "training_acc": 53.0, "val_loss": 0.6940824031829834, "val_acc": 52.0}
{"epoch": 22, "training_loss": 0.7008275175094605, "training_acc": 53.0, "val_loss": 0.6977581477165222, "val_acc": 52.0}
{"epoch": 23, "training_loss": 0.6940098619461059, "training_acc": 53.0, "val_loss": 0.7025573015213012, "val_acc": 48.0}
{"epoch": 24, "training_loss": 0.7096671962738037, "training_acc": 47.0, "val_loss": 0.6923013186454773, "val_acc": 52.0}
{"epoch": 25, "training_loss": 0.6934825086593628, "training_acc": 53.0, "val_loss": 0.7263612818717956, "val_acc": 52.0}
{"epoch": 26, "training_loss": 0.7104086923599243, "training_acc": 53.0, "val_loss": 0.6923049235343933, "val_acc": 52.0}
{"epoch": 27, "training_loss": 0.6992363500595092, "training_acc": 53.0, "val_loss": 0.6923364305496216, "val_acc": 52.0}
{"epoch": 28, "training_loss": 0.7181633043289185, "training_acc": 43.0, "val_loss": 0.7017354536056518, "val_acc": 48.0}
{"epoch": 29, "training_loss": 0.717166051864624, "training_acc": 45.0, "val_loss": 0.7094599103927612, "val_acc": 52.0}
{"epoch": 30, "training_loss": 0.6966876149177551, "training_acc": 53.0, "val_loss": 0.6922834825515747, "val_acc": 52.0}
{"epoch": 31, "training_loss": 0.6942503881454468, "training_acc": 47.0, "val_loss": 0.6961934089660644, "val_acc": 48.0}
{"epoch": 32, "training_loss": 0.6982366108894348, "training_acc": 47.0, "val_loss": 0.6929740595817566, "val_acc": 52.0}
{"epoch": 33, "training_loss": 0.7035453271865845, "training_acc": 53.0, "val_loss": 0.7035775470733643, "val_acc": 52.0}
{"epoch": 34, "training_loss": 0.7053262090682983, "training_acc": 53.0, "val_loss": 0.6976158022880554, "val_acc": 52.0}
{"epoch": 35, "training_loss": 0.6998919105529785, "training_acc": 45.0, "val_loss": 0.7006814241409302, "val_acc": 48.0}
{"epoch": 36, "training_loss": 0.7059176206588745, "training_acc": 43.0, "val_loss": 0.693884015083313, "val_acc": 48.0}
{"epoch": 37, "training_loss": 0.696575984954834, "training_acc": 47.0, "val_loss": 0.6927194833755493, "val_acc": 52.0}
{"epoch": 38, "training_loss": 0.6935307002067566, "training_acc": 53.0, "val_loss": 0.6951891660690308, "val_acc": 52.0}
{"epoch": 39, "training_loss": 0.6928928136825562, "training_acc": 53.0, "val_loss": 0.6927978229522705, "val_acc": 52.0}
{"epoch": 40, "training_loss": 0.6939155054092407, "training_acc": 53.0, "val_loss": 0.6934571433067321, "val_acc": 48.0}
{"epoch": 41, "training_loss": 0.695301284790039, "training_acc": 47.0, "val_loss": 0.6924300217628478, "val_acc": 52.0}
{"epoch": 42, "training_loss": 0.692369794845581, "training_acc": 53.0, "val_loss": 0.6955332970619201, "val_acc": 52.0}
{"epoch": 43, "training_loss": 0.6995183038711548, "training_acc": 53.0, "val_loss": 0.6922917485237121, "val_acc": 52.0}
{"epoch": 44, "training_loss": 0.6921839094161988, "training_acc": 53.0, "val_loss": 0.6943166089057923, "val_acc": 52.0}
{"epoch": 45, "training_loss": 0.6978473377227783, "training_acc": 53.0, "val_loss": 0.6971826171875, "val_acc": 52.0}
{"epoch": 46, "training_loss": 0.7096852779388427, "training_acc": 49.0, "val_loss": 0.7060589933395386, "val_acc": 48.0}
{"epoch": 47, "training_loss": 0.6928980875015259, "training_acc": 53.0, "val_loss": 0.6997128796577453, "val_acc": 52.0}
{"epoch": 48, "training_loss": 0.7113763284683228, "training_acc": 53.0, "val_loss": 0.6988688588142395, "val_acc": 52.0}
{"epoch": 49, "training_loss": 0.6940857076644897, "training_acc": 47.0, "val_loss": 0.7001578283309936, "val_acc": 48.0}
