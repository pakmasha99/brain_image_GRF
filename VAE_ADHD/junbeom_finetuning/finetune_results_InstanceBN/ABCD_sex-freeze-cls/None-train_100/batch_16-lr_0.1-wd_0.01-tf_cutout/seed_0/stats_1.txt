"main_modify.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option BT_org --learning_rate 1e-1 --batch_size 16 --weight_decay 1e-2 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 8.2802001953125, "training_acc": 45.0, "val_loss": 5.8109228515625, "val_acc": 52.0}
{"epoch": 1, "training_loss": 4.320713939666748, "training_acc": 43.0, "val_loss": 3.7912591457366944, "val_acc": 52.0}
{"epoch": 2, "training_loss": 2.344564504623413, "training_acc": 53.0, "val_loss": 1.5856325340270996, "val_acc": 52.0}
{"epoch": 3, "training_loss": 1.9602885055541992, "training_acc": 49.0, "val_loss": 1.7800747537612915, "val_acc": 48.0}
{"epoch": 4, "training_loss": 3.4123920345306398, "training_acc": 51.0, "val_loss": 3.988715181350708, "val_acc": 52.0}
{"epoch": 5, "training_loss": 4.074506645202637, "training_acc": 45.0, "val_loss": 5.250239868164062, "val_acc": 52.0}
{"epoch": 6, "training_loss": 4.116751852035523, "training_acc": 53.0, "val_loss": 3.5274243354797363, "val_acc": 48.0}
{"epoch": 7, "training_loss": 2.462559461593628, "training_acc": 59.0, "val_loss": 2.0555803203582763, "val_acc": 48.0}
{"epoch": 8, "training_loss": 1.0434852457046508, "training_acc": 59.0, "val_loss": 1.0359414434432983, "val_acc": 48.0}
{"epoch": 9, "training_loss": 1.4992491817474365, "training_acc": 39.0, "val_loss": 1.4389372205734252, "val_acc": 48.0}
{"epoch": 10, "training_loss": 0.9518363952636719, "training_acc": 55.0, "val_loss": 1.1639368295669557, "val_acc": 48.0}
{"epoch": 11, "training_loss": 1.1555865240097045, "training_acc": 51.0, "val_loss": 3.3651751708984374, "val_acc": 52.0}
{"epoch": 12, "training_loss": 3.0922331047058105, "training_acc": 57.0, "val_loss": 0.7907262849807739, "val_acc": 48.0}
{"epoch": 13, "training_loss": 4.636206827163696, "training_acc": 47.0, "val_loss": 9.100998573303222, "val_acc": 48.0}
{"epoch": 14, "training_loss": 6.5986667919158934, "training_acc": 47.0, "val_loss": 4.360857639312744, "val_acc": 52.0}
{"epoch": 15, "training_loss": 4.840424060821533, "training_acc": 33.0, "val_loss": 2.5154883003234865, "val_acc": 52.0}
{"epoch": 16, "training_loss": 2.1228135776519776, "training_acc": 47.0, "val_loss": 1.3401362466812134, "val_acc": 52.0}
{"epoch": 17, "training_loss": 3.05894935131073, "training_acc": 49.0, "val_loss": 2.2101756381988524, "val_acc": 52.0}
{"epoch": 18, "training_loss": 2.4779370784759522, "training_acc": 51.0, "val_loss": 3.0170127964019775, "val_acc": 52.0}
{"epoch": 19, "training_loss": 3.268897924423218, "training_acc": 49.0, "val_loss": 6.356773052215576, "val_acc": 52.0}
{"epoch": 20, "training_loss": 4.319679827690124, "training_acc": 51.0, "val_loss": 2.235573720932007, "val_acc": 52.0}
{"epoch": 21, "training_loss": 2.0888654136657716, "training_acc": 47.0, "val_loss": 1.5149199151992798, "val_acc": 52.0}
{"epoch": 22, "training_loss": 1.1823524498939515, "training_acc": 53.0, "val_loss": 3.254165267944336, "val_acc": 48.0}
{"epoch": 23, "training_loss": 2.366115703582764, "training_acc": 49.0, "val_loss": 1.5226217937469482, "val_acc": 48.0}
{"epoch": 24, "training_loss": 1.861324234008789, "training_acc": 37.0, "val_loss": 0.7077459526062012, "val_acc": 48.0}
{"epoch": 25, "training_loss": 1.113858184814453, "training_acc": 49.0, "val_loss": 0.705319516658783, "val_acc": 48.0}
{"epoch": 26, "training_loss": 2.628162670135498, "training_acc": 41.0, "val_loss": 1.3722668409347534, "val_acc": 52.0}
{"epoch": 27, "training_loss": 2.4164880180358885, "training_acc": 47.0, "val_loss": 2.139197311401367, "val_acc": 52.0}
{"epoch": 28, "training_loss": 1.8168396615982056, "training_acc": 45.0, "val_loss": 1.1548228693008422, "val_acc": 52.0}
{"epoch": 29, "training_loss": 2.0851617288589477, "training_acc": 53.0, "val_loss": 1.4345095872879028, "val_acc": 52.0}
{"epoch": 30, "training_loss": 2.050031042098999, "training_acc": 49.0, "val_loss": 1.4960178995132447, "val_acc": 48.0}
{"epoch": 31, "training_loss": 1.1799388027191162, "training_acc": 43.0, "val_loss": 0.9054456162452698, "val_acc": 48.0}
{"epoch": 32, "training_loss": 1.011743516921997, "training_acc": 43.0, "val_loss": 1.335344099998474, "val_acc": 48.0}
{"epoch": 33, "training_loss": 1.3433073091506957, "training_acc": 49.0, "val_loss": 1.4991657209396363, "val_acc": 52.0}
{"epoch": 34, "training_loss": 1.3610102653503418, "training_acc": 51.0, "val_loss": 0.7844764637947083, "val_acc": 48.0}
{"epoch": 35, "training_loss": 0.9500499153137207, "training_acc": 45.0, "val_loss": 1.5113972949981689, "val_acc": 48.0}
{"epoch": 36, "training_loss": 1.762696328163147, "training_acc": 47.0, "val_loss": 0.8916011452674866, "val_acc": 48.0}
{"epoch": 37, "training_loss": 0.9694956517219544, "training_acc": 55.0, "val_loss": 1.249719319343567, "val_acc": 52.0}
{"epoch": 38, "training_loss": 1.3610421657562255, "training_acc": 45.0, "val_loss": 0.7402117729187012, "val_acc": 52.0}
{"epoch": 39, "training_loss": 0.8558979105949401, "training_acc": 51.0, "val_loss": 2.623078966140747, "val_acc": 48.0}
{"epoch": 40, "training_loss": 1.6867337465286254, "training_acc": 51.0, "val_loss": 1.0253184866905212, "val_acc": 52.0}
{"epoch": 41, "training_loss": 1.0941405391693115, "training_acc": 43.0, "val_loss": 0.7815354990959168, "val_acc": 52.0}
{"epoch": 42, "training_loss": 0.9768017108552158, "training_acc": 57.0, "val_loss": 3.4695773696899415, "val_acc": 52.0}
{"epoch": 43, "training_loss": 2.2543846416473388, "training_acc": 45.0, "val_loss": 1.1748014163970948, "val_acc": 48.0}
{"epoch": 44, "training_loss": 2.1163715362548827, "training_acc": 49.0, "val_loss": 1.089956841468811, "val_acc": 48.0}
