"main_modify.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option BT_org --learning_rate 1e-1 --batch_size 16 --weight_decay 1e-2 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 11.934216451644897, "training_acc": 46.0, "val_loss": 3.535663576126099, "val_acc": 56.0}
{"epoch": 1, "training_loss": 5.606215305328369, "training_acc": 50.0, "val_loss": 10.359841804504395, "val_acc": 44.0}
{"epoch": 2, "training_loss": 6.763088798522949, "training_acc": 50.0, "val_loss": 4.533137092590332, "val_acc": 56.0}
{"epoch": 3, "training_loss": 3.925401096343994, "training_acc": 42.0, "val_loss": 0.8985991835594177, "val_acc": 56.0}
{"epoch": 4, "training_loss": 2.7090711975097657, "training_acc": 44.0, "val_loss": 0.6998773837089538, "val_acc": 44.0}
{"epoch": 5, "training_loss": 1.6400016164779663, "training_acc": 50.0, "val_loss": 2.8073974418640137, "val_acc": 44.0}
{"epoch": 6, "training_loss": 1.4878859996795655, "training_acc": 60.0, "val_loss": 1.6634767293930053, "val_acc": 44.0}
{"epoch": 7, "training_loss": 1.188720588684082, "training_acc": 54.0, "val_loss": 1.2753604745864868, "val_acc": 56.0}
{"epoch": 8, "training_loss": 1.045656967163086, "training_acc": 52.0, "val_loss": 1.21642240524292, "val_acc": 44.0}
{"epoch": 9, "training_loss": 0.8459784412384033, "training_acc": 56.0, "val_loss": 2.597560558319092, "val_acc": 44.0}
{"epoch": 10, "training_loss": 1.7097873020172119, "training_acc": 52.0, "val_loss": 1.0551574563980102, "val_acc": 56.0}
{"epoch": 11, "training_loss": 1.2346681022644044, "training_acc": 42.0, "val_loss": 1.5386779069900514, "val_acc": 56.0}
{"epoch": 12, "training_loss": 2.0191373014450074, "training_acc": 54.0, "val_loss": 1.842823724746704, "val_acc": 56.0}
{"epoch": 13, "training_loss": 1.9720335388183594, "training_acc": 46.0, "val_loss": 1.1536592483520507, "val_acc": 44.0}
{"epoch": 14, "training_loss": 0.9023713874816894, "training_acc": 46.0, "val_loss": 0.7132498502731324, "val_acc": 56.0}
{"epoch": 15, "training_loss": 1.1223951959609986, "training_acc": 46.0, "val_loss": 3.147710671424866, "val_acc": 56.0}
{"epoch": 16, "training_loss": 3.346832971572876, "training_acc": 52.0, "val_loss": 1.6875241279602051, "val_acc": 44.0}
{"epoch": 17, "training_loss": 2.2482583260536195, "training_acc": 50.0, "val_loss": 1.1322867250442505, "val_acc": 56.0}
{"epoch": 18, "training_loss": 1.407428379058838, "training_acc": 52.0, "val_loss": 1.1069815564155578, "val_acc": 44.0}
{"epoch": 19, "training_loss": 2.4620272636413576, "training_acc": 46.0, "val_loss": 1.836927342414856, "val_acc": 44.0}
{"epoch": 20, "training_loss": 1.2701792430877685, "training_acc": 48.0, "val_loss": 0.6928941917419433, "val_acc": 48.0}
{"epoch": 21, "training_loss": 1.1737822031974792, "training_acc": 50.0, "val_loss": 0.8914714908599853, "val_acc": 56.0}
{"epoch": 22, "training_loss": 0.9015452289581298, "training_acc": 50.0, "val_loss": 0.761554901599884, "val_acc": 44.0}
{"epoch": 23, "training_loss": 0.8268609714508056, "training_acc": 40.0, "val_loss": 1.944894790649414, "val_acc": 56.0}
{"epoch": 24, "training_loss": 2.064075379371643, "training_acc": 52.0, "val_loss": 0.7993930435180664, "val_acc": 56.0}
{"epoch": 25, "training_loss": 0.7007288360595703, "training_acc": 56.0, "val_loss": 0.8612187576293945, "val_acc": 44.0}
{"epoch": 26, "training_loss": 0.9924137020111083, "training_acc": 58.0, "val_loss": 1.7312259006500244, "val_acc": 56.0}
{"epoch": 27, "training_loss": 2.2543131828308107, "training_acc": 48.0, "val_loss": 3.806151762008667, "val_acc": 56.0}
{"epoch": 28, "training_loss": 4.702703475952148, "training_acc": 44.0, "val_loss": 3.727795095443726, "val_acc": 56.0}
{"epoch": 29, "training_loss": 5.8863996887207035, "training_acc": 48.0, "val_loss": 5.122752475738525, "val_acc": 44.0}
{"epoch": 30, "training_loss": 4.304370269775391, "training_acc": 46.0, "val_loss": 6.363243789672851, "val_acc": 44.0}
{"epoch": 31, "training_loss": 3.5279096329212187, "training_acc": 54.0, "val_loss": 0.8978549313545227, "val_acc": 44.0}
{"epoch": 32, "training_loss": 1.0273609638214112, "training_acc": 50.0, "val_loss": 1.6066771411895753, "val_acc": 56.0}
{"epoch": 33, "training_loss": 1.8684277629852295, "training_acc": 46.0, "val_loss": 0.8834654664993287, "val_acc": 44.0}
{"epoch": 34, "training_loss": 1.644004111289978, "training_acc": 48.0, "val_loss": 1.0375758600234986, "val_acc": 44.0}
{"epoch": 35, "training_loss": 0.9145117664337158, "training_acc": 52.0, "val_loss": 0.719719545841217, "val_acc": 56.0}
{"epoch": 36, "training_loss": 0.7536811923980713, "training_acc": 50.0, "val_loss": 1.4914848518371582, "val_acc": 56.0}
{"epoch": 37, "training_loss": 1.0452055931091309, "training_acc": 58.0, "val_loss": 1.4710228443145752, "val_acc": 44.0}
{"epoch": 38, "training_loss": 1.0670240116119385, "training_acc": 44.0, "val_loss": 0.8366450905799866, "val_acc": 56.0}
{"epoch": 39, "training_loss": 1.4957377099990845, "training_acc": 52.0, "val_loss": 2.004235515594482, "val_acc": 44.0}
