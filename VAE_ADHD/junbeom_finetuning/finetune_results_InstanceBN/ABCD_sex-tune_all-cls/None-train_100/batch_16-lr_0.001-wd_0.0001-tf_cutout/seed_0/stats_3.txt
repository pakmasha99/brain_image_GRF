"main_modify.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option BT_org --learning_rate 1e-3 --batch_size 16 --weight_decay 1e-4 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 0.7119509601593017, "training_acc": 49.0, "val_loss": 0.69344083070755, "val_acc": 52.0}
{"epoch": 1, "training_loss": 0.696121199131012, "training_acc": 53.0, "val_loss": 0.6923543763160706, "val_acc": 52.0}
{"epoch": 2, "training_loss": 0.6967149567604065, "training_acc": 49.0, "val_loss": 0.6924208521842956, "val_acc": 52.0}
{"epoch": 3, "training_loss": 0.7079787278175353, "training_acc": 53.0, "val_loss": 0.692724678516388, "val_acc": 52.0}
{"epoch": 4, "training_loss": 0.6958107280731202, "training_acc": 43.0, "val_loss": 0.692958664894104, "val_acc": 52.0}
{"epoch": 5, "training_loss": 0.6959743547439575, "training_acc": 53.0, "val_loss": 0.6923603463172913, "val_acc": 52.0}
{"epoch": 6, "training_loss": 0.6951389217376709, "training_acc": 47.0, "val_loss": 0.6932180166244507, "val_acc": 48.0}
{"epoch": 7, "training_loss": 0.7238595342636108, "training_acc": 47.0, "val_loss": 0.6945167517662049, "val_acc": 48.0}
{"epoch": 8, "training_loss": 0.6908471298217773, "training_acc": 53.0, "val_loss": 0.7154388284683227, "val_acc": 52.0}
{"epoch": 9, "training_loss": 0.696819875240326, "training_acc": 53.0, "val_loss": 0.6923730611801148, "val_acc": 52.0}
{"epoch": 10, "training_loss": 0.7002338933944702, "training_acc": 53.0, "val_loss": 0.6924004411697388, "val_acc": 52.0}
{"epoch": 11, "training_loss": 0.6918265342712402, "training_acc": 53.0, "val_loss": 0.6927148652076721, "val_acc": 52.0}
{"epoch": 12, "training_loss": 0.6955436396598816, "training_acc": 45.0, "val_loss": 0.6923443365097046, "val_acc": 52.0}
{"epoch": 13, "training_loss": 0.6946714496612549, "training_acc": 53.0, "val_loss": 0.6972430968284606, "val_acc": 52.0}
{"epoch": 14, "training_loss": 0.6936361217498779, "training_acc": 53.0, "val_loss": 0.6923485612869262, "val_acc": 52.0}
{"epoch": 15, "training_loss": 0.6934017896652221, "training_acc": 49.0, "val_loss": 0.6925050354003907, "val_acc": 52.0}
{"epoch": 16, "training_loss": 0.7038518142700195, "training_acc": 53.0, "val_loss": 0.7049899411201477, "val_acc": 52.0}
{"epoch": 17, "training_loss": 0.6997936487197876, "training_acc": 53.0, "val_loss": 0.6939500141143798, "val_acc": 48.0}
{"epoch": 18, "training_loss": 0.7256390047073364, "training_acc": 47.0, "val_loss": 0.7073890352249146, "val_acc": 48.0}
{"epoch": 19, "training_loss": 0.7041595363616944, "training_acc": 43.0, "val_loss": 0.6947900462150574, "val_acc": 52.0}
{"epoch": 20, "training_loss": 0.6953789138793945, "training_acc": 53.0, "val_loss": 0.6952044796943665, "val_acc": 52.0}
{"epoch": 21, "training_loss": 0.6965803408622742, "training_acc": 49.0, "val_loss": 0.6923981523513794, "val_acc": 52.0}
{"epoch": 22, "training_loss": 0.6929630851745605, "training_acc": 53.0, "val_loss": 0.6968580174446106, "val_acc": 52.0}
{"epoch": 23, "training_loss": 0.6949240612983704, "training_acc": 53.0, "val_loss": 0.697157666683197, "val_acc": 52.0}
{"epoch": 24, "training_loss": 0.7000794696807862, "training_acc": 53.0, "val_loss": 0.6928363037109375, "val_acc": 52.0}
{"epoch": 25, "training_loss": 0.6919203543663025, "training_acc": 55.0, "val_loss": 0.6994397830963135, "val_acc": 48.0}
{"epoch": 26, "training_loss": 0.7064807653427124, "training_acc": 43.0, "val_loss": 0.6958052039146423, "val_acc": 52.0}
{"epoch": 27, "training_loss": 0.7013028717041015, "training_acc": 45.0, "val_loss": 0.6937797665596008, "val_acc": 48.0}
{"epoch": 28, "training_loss": 0.6974409890174865, "training_acc": 47.0, "val_loss": 0.6930730295181274, "val_acc": 52.0}
{"epoch": 29, "training_loss": 0.6949754238128663, "training_acc": 53.0, "val_loss": 0.6942036151885986, "val_acc": 48.0}
{"epoch": 30, "training_loss": 0.7155093955993652, "training_acc": 47.0, "val_loss": 0.6972367215156555, "val_acc": 48.0}
{"epoch": 31, "training_loss": 0.6960454154014587, "training_acc": 49.0, "val_loss": 0.7103423976898193, "val_acc": 52.0}
{"epoch": 32, "training_loss": 0.7081244468688965, "training_acc": 53.0, "val_loss": 0.6923371052742004, "val_acc": 52.0}
{"epoch": 33, "training_loss": 0.6988506484031677, "training_acc": 45.0, "val_loss": 0.694625370502472, "val_acc": 48.0}
{"epoch": 34, "training_loss": 0.7127813005447388, "training_acc": 45.0, "val_loss": 0.6976134419441223, "val_acc": 52.0}
{"epoch": 35, "training_loss": 0.6930399107933044, "training_acc": 49.0, "val_loss": 0.6999738311767578, "val_acc": 48.0}
{"epoch": 36, "training_loss": 0.6979675006866455, "training_acc": 47.0, "val_loss": 0.6923384094238281, "val_acc": 52.0}
{"epoch": 37, "training_loss": 0.723108913898468, "training_acc": 53.0, "val_loss": 0.7079137444496155, "val_acc": 52.0}
{"epoch": 38, "training_loss": 0.7006761407852173, "training_acc": 55.0, "val_loss": 0.7017164635658264, "val_acc": 48.0}
{"epoch": 39, "training_loss": 0.7022557473182678, "training_acc": 47.0, "val_loss": 0.6928239798545838, "val_acc": 52.0}
{"epoch": 40, "training_loss": 0.7126336145401001, "training_acc": 53.0, "val_loss": 0.6946017861366272, "val_acc": 52.0}
{"epoch": 41, "training_loss": 0.7024604463577271, "training_acc": 43.0, "val_loss": 0.6923445701599121, "val_acc": 52.0}
{"epoch": 42, "training_loss": 0.7187168407440185, "training_acc": 53.0, "val_loss": 0.6945469760894776, "val_acc": 52.0}
{"epoch": 43, "training_loss": 0.7021602725982666, "training_acc": 51.0, "val_loss": 0.7196977353096008, "val_acc": 48.0}
{"epoch": 44, "training_loss": 0.7191572856903076, "training_acc": 41.0, "val_loss": 0.6949358868598938, "val_acc": 52.0}
{"epoch": 45, "training_loss": 0.6933220291137695, "training_acc": 51.0, "val_loss": 0.6925979733467102, "val_acc": 52.0}
{"epoch": 46, "training_loss": 0.6982594132423401, "training_acc": 53.0, "val_loss": 0.6952382779121399, "val_acc": 52.0}
{"epoch": 47, "training_loss": 0.6921853041648864, "training_acc": 51.0, "val_loss": 0.6941366267204284, "val_acc": 48.0}
{"epoch": 48, "training_loss": 0.6923796987533569, "training_acc": 53.0, "val_loss": 0.6947019362449646, "val_acc": 52.0}
{"epoch": 49, "training_loss": 0.6976364636421204, "training_acc": 53.0, "val_loss": 0.6930101704597473, "val_acc": 52.0}
{"epoch": 50, "training_loss": 0.7076282453536987, "training_acc": 43.0, "val_loss": 0.7016424870491028, "val_acc": 48.0}
{"epoch": 51, "training_loss": 0.6906092643737793, "training_acc": 55.0, "val_loss": 0.6971026349067688, "val_acc": 52.0}
