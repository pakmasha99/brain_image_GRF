"main_modify.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option BT_org --learning_rate 1e-3 --batch_size 16 --weight_decay 1e-4 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 0.7197696661949158, "training_acc": 46.0, "val_loss": 0.6924845957756043, "val_acc": 52.0}
{"epoch": 1, "training_loss": 0.6975323128700256, "training_acc": 51.0, "val_loss": 0.6929144549369812, "val_acc": 52.0}
{"epoch": 2, "training_loss": 0.7011967968940734, "training_acc": 53.0, "val_loss": 0.6938534641265869, "val_acc": 52.0}
{"epoch": 3, "training_loss": 0.6992307043075562, "training_acc": 43.0, "val_loss": 0.6961048984527588, "val_acc": 52.0}
{"epoch": 4, "training_loss": 0.6951060009002685, "training_acc": 53.0, "val_loss": 0.6976050305366516, "val_acc": 52.0}
{"epoch": 5, "training_loss": 0.7077719831466674, "training_acc": 41.0, "val_loss": 0.6955873966217041, "val_acc": 48.0}
{"epoch": 6, "training_loss": 0.6976575708389282, "training_acc": 49.0, "val_loss": 0.6936312866210937, "val_acc": 52.0}
{"epoch": 7, "training_loss": 0.7169658946990967, "training_acc": 53.0, "val_loss": 0.6978622150421142, "val_acc": 52.0}
{"epoch": 8, "training_loss": 0.6933395719528198, "training_acc": 53.0, "val_loss": 0.6955109739303589, "val_acc": 48.0}
{"epoch": 9, "training_loss": 0.719412293434143, "training_acc": 47.0, "val_loss": 0.6979989552497864, "val_acc": 48.0}
{"epoch": 10, "training_loss": 0.7184958648681641, "training_acc": 51.0, "val_loss": 0.7121569657325745, "val_acc": 52.0}
{"epoch": 11, "training_loss": 0.7097032308578491, "training_acc": 53.0, "val_loss": 0.6930617213249206, "val_acc": 52.0}
{"epoch": 12, "training_loss": 0.6974030780792236, "training_acc": 47.0, "val_loss": 0.692608757019043, "val_acc": 52.0}
{"epoch": 13, "training_loss": 0.7033259415626526, "training_acc": 53.0, "val_loss": 0.7074073791503906, "val_acc": 52.0}
{"epoch": 14, "training_loss": 0.6931310939788818, "training_acc": 53.0, "val_loss": 0.6951161980628967, "val_acc": 48.0}
{"epoch": 15, "training_loss": 0.7127304649353028, "training_acc": 47.0, "val_loss": 0.6958526158332825, "val_acc": 48.0}
{"epoch": 16, "training_loss": 0.7118657302856445, "training_acc": 47.0, "val_loss": 0.7036293339729309, "val_acc": 52.0}
{"epoch": 17, "training_loss": 0.6954259037971496, "training_acc": 53.0, "val_loss": 0.6923813772201538, "val_acc": 52.0}
{"epoch": 18, "training_loss": 0.6940100646018982, "training_acc": 53.0, "val_loss": 0.6924945569038391, "val_acc": 52.0}
{"epoch": 19, "training_loss": 0.6941615891456604, "training_acc": 49.0, "val_loss": 0.6937549185752868, "val_acc": 52.0}
{"epoch": 20, "training_loss": 0.7002690052986145, "training_acc": 53.0, "val_loss": 0.6959862518310547, "val_acc": 52.0}
{"epoch": 21, "training_loss": 0.6971840357780457, "training_acc": 53.0, "val_loss": 0.6927101635932922, "val_acc": 52.0}
{"epoch": 22, "training_loss": 0.7048686599731445, "training_acc": 43.0, "val_loss": 0.6923371481895447, "val_acc": 52.0}
{"epoch": 23, "training_loss": 0.6917898797988892, "training_acc": 53.0, "val_loss": 0.7029577660560608, "val_acc": 52.0}
{"epoch": 24, "training_loss": 0.6958732652664185, "training_acc": 53.0, "val_loss": 0.6927177357673645, "val_acc": 52.0}
{"epoch": 25, "training_loss": 0.7324087595939637, "training_acc": 41.0, "val_loss": 0.6957405495643616, "val_acc": 48.0}
{"epoch": 26, "training_loss": 0.6907073998451233, "training_acc": 59.0, "val_loss": 0.7086266779899597, "val_acc": 52.0}
{"epoch": 27, "training_loss": 0.7044210314750672, "training_acc": 53.0, "val_loss": 0.692538149356842, "val_acc": 52.0}
{"epoch": 28, "training_loss": 0.7199962592124939, "training_acc": 45.0, "val_loss": 0.7134118747711181, "val_acc": 48.0}
{"epoch": 29, "training_loss": 0.71659019947052, "training_acc": 47.0, "val_loss": 0.6962290811538696, "val_acc": 52.0}
{"epoch": 30, "training_loss": 0.7173148560523986, "training_acc": 53.0, "val_loss": 0.7071701169013977, "val_acc": 52.0}
{"epoch": 31, "training_loss": 0.6963965010643005, "training_acc": 53.0, "val_loss": 0.6936085891723632, "val_acc": 48.0}
{"epoch": 32, "training_loss": 0.705484254360199, "training_acc": 47.0, "val_loss": 0.7015820813179016, "val_acc": 48.0}
{"epoch": 33, "training_loss": 0.6985332489013671, "training_acc": 49.0, "val_loss": 0.7033629298210144, "val_acc": 52.0}
{"epoch": 34, "training_loss": 0.6958363270759582, "training_acc": 53.0, "val_loss": 0.6923376417160034, "val_acc": 52.0}
{"epoch": 35, "training_loss": 0.7026704359054565, "training_acc": 43.0, "val_loss": 0.6924664425849915, "val_acc": 52.0}
{"epoch": 36, "training_loss": 0.6977794981002807, "training_acc": 53.0, "val_loss": 0.6958253908157349, "val_acc": 52.0}
{"epoch": 37, "training_loss": 0.7116441774368286, "training_acc": 39.0, "val_loss": 0.6932382845878601, "val_acc": 48.0}
{"epoch": 38, "training_loss": 0.6925920057296753, "training_acc": 57.0, "val_loss": 0.696160774230957, "val_acc": 52.0}
{"epoch": 39, "training_loss": 0.718417739868164, "training_acc": 35.0, "val_loss": 0.6926528644561768, "val_acc": 52.0}
{"epoch": 40, "training_loss": 0.7044814014434815, "training_acc": 53.0, "val_loss": 0.694751124382019, "val_acc": 52.0}
{"epoch": 41, "training_loss": 0.6882944035530091, "training_acc": 53.0, "val_loss": 0.6968184757232666, "val_acc": 48.0}
