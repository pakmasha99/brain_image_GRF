"main_modify.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option BT_org --learning_rate 1e-3 --batch_size 16 --weight_decay 1e-4 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 0.7198024272918702, "training_acc": 50.0, "val_loss": 0.6939826512336731, "val_acc": 48.0}
{"epoch": 1, "training_loss": 0.7057213997840881, "training_acc": 49.0, "val_loss": 0.7013587927818299, "val_acc": 52.0}
{"epoch": 2, "training_loss": 0.6986866950988769, "training_acc": 53.0, "val_loss": 0.6924675250053406, "val_acc": 52.0}
{"epoch": 3, "training_loss": 0.6978980827331543, "training_acc": 45.0, "val_loss": 0.6925316286087037, "val_acc": 52.0}
{"epoch": 4, "training_loss": 0.6941794967651367, "training_acc": 49.0, "val_loss": 0.701924033164978, "val_acc": 52.0}
{"epoch": 5, "training_loss": 0.7004035949707031, "training_acc": 53.0, "val_loss": 0.6928465461730957, "val_acc": 52.0}
{"epoch": 6, "training_loss": 0.6941016101837159, "training_acc": 46.0, "val_loss": 0.6929482650756836, "val_acc": 52.0}
{"epoch": 7, "training_loss": 0.6984361815452576, "training_acc": 53.0, "val_loss": 0.6931943225860596, "val_acc": 52.0}
{"epoch": 8, "training_loss": 0.6992363882064819, "training_acc": 53.0, "val_loss": 0.6924614500999451, "val_acc": 52.0}
{"epoch": 9, "training_loss": 0.696582932472229, "training_acc": 47.0, "val_loss": 0.6924434661865234, "val_acc": 52.0}
{"epoch": 10, "training_loss": 0.6937394189834595, "training_acc": 53.0, "val_loss": 0.6939339351654052, "val_acc": 52.0}
{"epoch": 11, "training_loss": 0.7055171370506287, "training_acc": 53.0, "val_loss": 0.6956578660011291, "val_acc": 52.0}
{"epoch": 12, "training_loss": 0.724504029750824, "training_acc": 43.0, "val_loss": 0.692435257434845, "val_acc": 52.0}
{"epoch": 13, "training_loss": 0.6885718154907227, "training_acc": 53.0, "val_loss": 0.7108887338638306, "val_acc": 52.0}
{"epoch": 14, "training_loss": 0.702241051197052, "training_acc": 53.0, "val_loss": 0.6925260233879089, "val_acc": 52.0}
{"epoch": 15, "training_loss": 0.6926561689376831, "training_acc": 53.0, "val_loss": 0.6932158994674683, "val_acc": 48.0}
{"epoch": 16, "training_loss": 0.7013129711151123, "training_acc": 47.0, "val_loss": 0.694574191570282, "val_acc": 48.0}
{"epoch": 17, "training_loss": 0.6940297555923461, "training_acc": 51.0, "val_loss": 0.6993264794349671, "val_acc": 52.0}
{"epoch": 18, "training_loss": 0.699041576385498, "training_acc": 53.0, "val_loss": 0.6935243606567383, "val_acc": 52.0}
{"epoch": 19, "training_loss": 0.6940673995018005, "training_acc": 53.0, "val_loss": 0.6925941061973572, "val_acc": 52.0}
{"epoch": 20, "training_loss": 0.6935280227661133, "training_acc": 53.0, "val_loss": 0.6923609137535095, "val_acc": 52.0}
{"epoch": 21, "training_loss": 0.7105630970001221, "training_acc": 49.0, "val_loss": 0.6974077939987182, "val_acc": 48.0}
{"epoch": 22, "training_loss": 0.7149080538749695, "training_acc": 49.0, "val_loss": 0.7083537030220032, "val_acc": 52.0}
{"epoch": 23, "training_loss": 0.6988060474395752, "training_acc": 53.0, "val_loss": 0.692446858882904, "val_acc": 52.0}
{"epoch": 24, "training_loss": 0.6959493732452393, "training_acc": 53.0, "val_loss": 0.6923737764358521, "val_acc": 52.0}
{"epoch": 25, "training_loss": 0.6935702300071717, "training_acc": 53.0, "val_loss": 0.6927014946937561, "val_acc": 52.0}
{"epoch": 26, "training_loss": 0.690651376247406, "training_acc": 53.0, "val_loss": 0.6972020411491394, "val_acc": 52.0}
{"epoch": 27, "training_loss": 0.6960725378990174, "training_acc": 53.0, "val_loss": 0.6923527097702027, "val_acc": 52.0}
{"epoch": 28, "training_loss": 0.7036143684387207, "training_acc": 47.0, "val_loss": 0.7026421785354614, "val_acc": 48.0}
{"epoch": 29, "training_loss": 0.6983866262435913, "training_acc": 49.0, "val_loss": 0.6938072633743286, "val_acc": 52.0}
{"epoch": 30, "training_loss": 0.7023470830917359, "training_acc": 53.0, "val_loss": 0.7029643630981446, "val_acc": 52.0}
{"epoch": 31, "training_loss": 0.6918280005455018, "training_acc": 53.0, "val_loss": 0.6962385940551757, "val_acc": 48.0}
{"epoch": 32, "training_loss": 0.6978416919708252, "training_acc": 47.0, "val_loss": 0.692458279132843, "val_acc": 52.0}
{"epoch": 33, "training_loss": 0.6973294830322265, "training_acc": 47.0, "val_loss": 0.6933876037597656, "val_acc": 52.0}
{"epoch": 34, "training_loss": 0.697104594707489, "training_acc": 53.0, "val_loss": 0.6957722067832947, "val_acc": 52.0}
{"epoch": 35, "training_loss": 0.6936121988296509, "training_acc": 53.0, "val_loss": 0.6924780416488647, "val_acc": 52.0}
{"epoch": 36, "training_loss": 0.6976154065132141, "training_acc": 41.0, "val_loss": 0.6943325543403626, "val_acc": 48.0}
{"epoch": 37, "training_loss": 0.6993998312950134, "training_acc": 55.0, "val_loss": 0.7045505023002625, "val_acc": 52.0}
{"epoch": 38, "training_loss": 0.7037754631042481, "training_acc": 53.0, "val_loss": 0.6932028150558471, "val_acc": 48.0}
{"epoch": 39, "training_loss": 0.6975412273406982, "training_acc": 47.0, "val_loss": 0.6937226796150208, "val_acc": 48.0}
{"epoch": 40, "training_loss": 0.6999596309661865, "training_acc": 47.0, "val_loss": 0.7001414132118225, "val_acc": 52.0}
{"epoch": 41, "training_loss": 0.7021490597724914, "training_acc": 53.0, "val_loss": 0.6934392285346985, "val_acc": 52.0}
{"epoch": 42, "training_loss": 0.7059878492355347, "training_acc": 43.0, "val_loss": 0.6932175064086914, "val_acc": 48.0}
{"epoch": 43, "training_loss": 0.7064717400074005, "training_acc": 51.0, "val_loss": 0.7200667595863343, "val_acc": 52.0}
{"epoch": 44, "training_loss": 0.7138012170791626, "training_acc": 53.0, "val_loss": 0.6926788425445557, "val_acc": 52.0}
{"epoch": 45, "training_loss": 0.6931695747375488, "training_acc": 51.0, "val_loss": 0.6929178595542907, "val_acc": 52.0}
{"epoch": 46, "training_loss": 0.6943441939353943, "training_acc": 53.0, "val_loss": 0.6958072400093078, "val_acc": 52.0}
