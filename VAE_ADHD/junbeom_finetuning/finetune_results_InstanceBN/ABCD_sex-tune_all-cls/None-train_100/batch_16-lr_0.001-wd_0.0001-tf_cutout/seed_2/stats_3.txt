"main_modify.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 2 --task ABCD_sex --input_option BT_org --learning_rate 1e-3 --batch_size 16 --weight_decay 1e-4 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 0.7156930208206177, "training_acc": 50.0, "val_loss": 0.6925565409660339, "val_acc": 52.0}
{"epoch": 1, "training_loss": 0.6997145104408264, "training_acc": 47.0, "val_loss": 0.6941536021232605, "val_acc": 48.0}
{"epoch": 2, "training_loss": 0.6965326881408691, "training_acc": 51.0, "val_loss": 0.6962239384651184, "val_acc": 48.0}
{"epoch": 3, "training_loss": 0.7080414009094238, "training_acc": 45.0, "val_loss": 0.6945038652420044, "val_acc": 48.0}
{"epoch": 4, "training_loss": 0.7001369857788086, "training_acc": 41.0, "val_loss": 0.6943688893318176, "val_acc": 48.0}
{"epoch": 5, "training_loss": 0.7032143878936767, "training_acc": 43.0, "val_loss": 0.6923511505126954, "val_acc": 52.0}
{"epoch": 6, "training_loss": 0.6932847881317139, "training_acc": 47.0, "val_loss": 0.6923417019844055, "val_acc": 52.0}
{"epoch": 7, "training_loss": 0.6907507371902466, "training_acc": 53.0, "val_loss": 0.6951945614814758, "val_acc": 52.0}
{"epoch": 8, "training_loss": 0.6949101781845093, "training_acc": 53.0, "val_loss": 0.6925342202186584, "val_acc": 52.0}
{"epoch": 9, "training_loss": 0.7032199668884277, "training_acc": 51.0, "val_loss": 0.6953627038002014, "val_acc": 48.0}
{"epoch": 10, "training_loss": 0.6997481155395507, "training_acc": 49.0, "val_loss": 0.6972094845771789, "val_acc": 52.0}
{"epoch": 11, "training_loss": 0.6918534851074218, "training_acc": 55.0, "val_loss": 0.6953173041343689, "val_acc": 48.0}
{"epoch": 12, "training_loss": 0.6981792736053467, "training_acc": 45.0, "val_loss": 0.6923862385749817, "val_acc": 52.0}
{"epoch": 13, "training_loss": 0.6943112373352051, "training_acc": 53.0, "val_loss": 0.6925819420814514, "val_acc": 52.0}
{"epoch": 14, "training_loss": 0.6929690122604371, "training_acc": 53.0, "val_loss": 0.6930117249488831, "val_acc": 52.0}
{"epoch": 15, "training_loss": 0.6982279181480407, "training_acc": 47.0, "val_loss": 0.6923416876792907, "val_acc": 52.0}
{"epoch": 16, "training_loss": 0.7042972946166992, "training_acc": 53.0, "val_loss": 0.705953631401062, "val_acc": 52.0}
{"epoch": 17, "training_loss": 0.7106626605987549, "training_acc": 43.0, "val_loss": 0.7097465348243713, "val_acc": 48.0}
{"epoch": 18, "training_loss": 0.708312931060791, "training_acc": 45.0, "val_loss": 0.6927087330818176, "val_acc": 52.0}
{"epoch": 19, "training_loss": 0.6963140654563904, "training_acc": 43.0, "val_loss": 0.6941607093811035, "val_acc": 52.0}
{"epoch": 20, "training_loss": 0.6949487471580506, "training_acc": 53.0, "val_loss": 0.6940857195854186, "val_acc": 52.0}
{"epoch": 21, "training_loss": 0.7013522624969483, "training_acc": 53.0, "val_loss": 0.695940055847168, "val_acc": 52.0}
{"epoch": 22, "training_loss": 0.6905805277824402, "training_acc": 55.0, "val_loss": 0.6970760655403138, "val_acc": 48.0}
{"epoch": 23, "training_loss": 0.6944705677032471, "training_acc": 53.0, "val_loss": 0.6924323177337647, "val_acc": 52.0}
{"epoch": 24, "training_loss": 0.6916128826141358, "training_acc": 53.0, "val_loss": 0.6928949475288391, "val_acc": 52.0}
{"epoch": 25, "training_loss": 0.6953175926208496, "training_acc": 53.0, "val_loss": 0.6923398971557617, "val_acc": 52.0}
{"epoch": 26, "training_loss": 0.6934224438667297, "training_acc": 53.0, "val_loss": 0.6924867749214172, "val_acc": 52.0}
{"epoch": 27, "training_loss": 0.694592695236206, "training_acc": 53.0, "val_loss": 0.6925252509117127, "val_acc": 52.0}
{"epoch": 28, "training_loss": 0.694145679473877, "training_acc": 47.0, "val_loss": 0.6928049182891846, "val_acc": 52.0}
{"epoch": 29, "training_loss": 0.6977323722839356, "training_acc": 53.0, "val_loss": 0.6938847088813782, "val_acc": 52.0}
{"epoch": 30, "training_loss": 0.6920470857620239, "training_acc": 53.0, "val_loss": 0.6937244486808777, "val_acc": 48.0}
{"epoch": 31, "training_loss": 0.6973589015007019, "training_acc": 47.0, "val_loss": 0.6924657678604126, "val_acc": 52.0}
{"epoch": 32, "training_loss": 0.6991559743881226, "training_acc": 53.0, "val_loss": 0.6970023012161255, "val_acc": 52.0}
{"epoch": 33, "training_loss": 0.6933681178092956, "training_acc": 53.0, "val_loss": 0.6924790692329407, "val_acc": 52.0}
{"epoch": 34, "training_loss": 0.6979768991470336, "training_acc": 47.0, "val_loss": 0.6983433842658997, "val_acc": 48.0}
{"epoch": 35, "training_loss": 0.7021007871627808, "training_acc": 45.0, "val_loss": 0.6925044560432434, "val_acc": 52.0}
{"epoch": 36, "training_loss": 0.7016154217720032, "training_acc": 41.0, "val_loss": 0.6943819904327393, "val_acc": 48.0}
{"epoch": 37, "training_loss": 0.6957888841629029, "training_acc": 47.0, "val_loss": 0.6923797607421875, "val_acc": 52.0}
{"epoch": 38, "training_loss": 0.6950967741012574, "training_acc": 53.0, "val_loss": 0.7028600025177002, "val_acc": 52.0}
{"epoch": 39, "training_loss": 0.6986305809020996, "training_acc": 53.0, "val_loss": 0.6930875635147095, "val_acc": 52.0}
{"epoch": 40, "training_loss": 0.7071825122833252, "training_acc": 45.0, "val_loss": 0.6971343421936035, "val_acc": 48.0}
{"epoch": 41, "training_loss": 0.7053172254562378, "training_acc": 43.0, "val_loss": 0.6923354935646057, "val_acc": 52.0}
{"epoch": 42, "training_loss": 0.6955479288101196, "training_acc": 47.0, "val_loss": 0.6927087116241455, "val_acc": 52.0}
{"epoch": 43, "training_loss": 0.7079395627975464, "training_acc": 53.0, "val_loss": 0.7000094032287598, "val_acc": 52.0}
{"epoch": 44, "training_loss": 0.7004553246498108, "training_acc": 53.0, "val_loss": 0.6922054266929627, "val_acc": 52.0}
{"epoch": 45, "training_loss": 0.6999809861183166, "training_acc": 53.0, "val_loss": 0.6925432229042053, "val_acc": 52.0}
{"epoch": 46, "training_loss": 0.6932020235061646, "training_acc": 53.0, "val_loss": 0.6935571765899659, "val_acc": 52.0}
{"epoch": 47, "training_loss": 0.6932693457603455, "training_acc": 53.0, "val_loss": 0.6935084843635559, "val_acc": 52.0}
{"epoch": 48, "training_loss": 0.6948161458969117, "training_acc": 53.0, "val_loss": 0.6970678639411926, "val_acc": 52.0}
{"epoch": 49, "training_loss": 0.6971707940101624, "training_acc": 53.0, "val_loss": 0.694344367980957, "val_acc": 52.0}
{"epoch": 50, "training_loss": 0.7108155488967896, "training_acc": 41.0, "val_loss": 0.6955231952667237, "val_acc": 48.0}
{"epoch": 51, "training_loss": 0.6921384811401368, "training_acc": 53.0, "val_loss": 0.6973602199554443, "val_acc": 52.0}
{"epoch": 52, "training_loss": 0.6942050933837891, "training_acc": 53.0, "val_loss": 0.6924491119384766, "val_acc": 52.0}
{"epoch": 53, "training_loss": 0.6961954545974731, "training_acc": 53.0, "val_loss": 0.6930800747871398, "val_acc": 52.0}
{"epoch": 54, "training_loss": 0.6944934844970703, "training_acc": 47.0, "val_loss": 0.6945964860916137, "val_acc": 48.0}
{"epoch": 55, "training_loss": 0.7025249910354614, "training_acc": 49.0, "val_loss": 0.6951204299926758, "val_acc": 52.0}
{"epoch": 56, "training_loss": 0.694667797088623, "training_acc": 53.0, "val_loss": 0.6924466633796692, "val_acc": 52.0}
{"epoch": 57, "training_loss": 0.6920212650299072, "training_acc": 53.0, "val_loss": 0.692370035648346, "val_acc": 52.0}
{"epoch": 58, "training_loss": 0.6940836000442505, "training_acc": 42.0, "val_loss": 0.6923712658882141, "val_acc": 52.0}
{"epoch": 59, "training_loss": 0.6962758588790894, "training_acc": 53.0, "val_loss": 0.7053705549240112, "val_acc": 52.0}
{"epoch": 60, "training_loss": 0.7046292543411254, "training_acc": 53.0, "val_loss": 0.6937114500999451, "val_acc": 52.0}
{"epoch": 61, "training_loss": 0.6931648302078247, "training_acc": 53.0, "val_loss": 0.6923163628578186, "val_acc": 52.0}
{"epoch": 62, "training_loss": 0.6940430688858032, "training_acc": 53.0, "val_loss": 0.6925055623054505, "val_acc": 52.0}
{"epoch": 63, "training_loss": 0.692251238822937, "training_acc": 53.0, "val_loss": 0.699581458568573, "val_acc": 52.0}
