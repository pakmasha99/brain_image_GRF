"main_modify.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 2 --task ABCD_sex --input_option BT_org --learning_rate 1e-3 --batch_size 16 --weight_decay 1e-4 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 0.7117105340957641, "training_acc": 50.0, "val_loss": 0.7084141254425049, "val_acc": 44.0}
{"epoch": 1, "training_loss": 0.706801540851593, "training_acc": 44.0, "val_loss": 0.6950626587867736, "val_acc": 44.0}
{"epoch": 2, "training_loss": 0.7075068736076355, "training_acc": 48.0, "val_loss": 0.6888793158531189, "val_acc": 56.0}
{"epoch": 3, "training_loss": 0.697924370765686, "training_acc": 46.0, "val_loss": 0.6918165183067322, "val_acc": 56.0}
{"epoch": 4, "training_loss": 0.7040159916877746, "training_acc": 40.0, "val_loss": 0.6860341119766236, "val_acc": 56.0}
{"epoch": 5, "training_loss": 0.7019614028930664, "training_acc": 52.0, "val_loss": 0.6860622906684876, "val_acc": 56.0}
{"epoch": 6, "training_loss": 0.6969934678077698, "training_acc": 52.0, "val_loss": 0.6860941672325134, "val_acc": 56.0}
{"epoch": 7, "training_loss": 0.6972830486297608, "training_acc": 48.0, "val_loss": 0.6993254971504211, "val_acc": 44.0}
{"epoch": 8, "training_loss": 0.7064150953292847, "training_acc": 40.0, "val_loss": 0.692536735534668, "val_acc": 56.0}
{"epoch": 9, "training_loss": 0.6944868612289429, "training_acc": 48.0, "val_loss": 0.6883677482604981, "val_acc": 56.0}
{"epoch": 10, "training_loss": 0.6995623350143433, "training_acc": 40.0, "val_loss": 0.6859407448768615, "val_acc": 56.0}
{"epoch": 11, "training_loss": 0.7075634050369263, "training_acc": 52.0, "val_loss": 0.6863284158706665, "val_acc": 56.0}
{"epoch": 12, "training_loss": 0.7060344648361206, "training_acc": 44.0, "val_loss": 0.7049330115318299, "val_acc": 44.0}
{"epoch": 13, "training_loss": 0.6992461824417114, "training_acc": 44.0, "val_loss": 0.6888898587226868, "val_acc": 56.0}
{"epoch": 14, "training_loss": 0.6979635429382324, "training_acc": 46.0, "val_loss": 0.696225380897522, "val_acc": 44.0}
{"epoch": 15, "training_loss": 0.6999229907989502, "training_acc": 48.0, "val_loss": 0.6861528253555298, "val_acc": 56.0}
{"epoch": 16, "training_loss": 0.693425121307373, "training_acc": 50.0, "val_loss": 0.6927768635749817, "val_acc": 56.0}
{"epoch": 17, "training_loss": 0.6980246758460998, "training_acc": 42.0, "val_loss": 0.6868266201019287, "val_acc": 56.0}
{"epoch": 18, "training_loss": 0.712958607673645, "training_acc": 52.0, "val_loss": 0.6904336977005004, "val_acc": 56.0}
{"epoch": 19, "training_loss": 0.7086801218986511, "training_acc": 52.0, "val_loss": 0.6875261116027832, "val_acc": 56.0}
{"epoch": 20, "training_loss": 0.6975460767745971, "training_acc": 52.0, "val_loss": 0.6915784025192261, "val_acc": 56.0}
{"epoch": 21, "training_loss": 0.708254919052124, "training_acc": 50.0, "val_loss": 0.7188911747932434, "val_acc": 44.0}
{"epoch": 22, "training_loss": 0.7145606565475464, "training_acc": 48.0, "val_loss": 0.6892250180244446, "val_acc": 56.0}
{"epoch": 23, "training_loss": 0.6938154101371765, "training_acc": 52.0, "val_loss": 0.6858879256248475, "val_acc": 56.0}
{"epoch": 24, "training_loss": 0.6962673997879029, "training_acc": 52.0, "val_loss": 0.6877509355545044, "val_acc": 56.0}
{"epoch": 25, "training_loss": 0.7141566848754883, "training_acc": 52.0, "val_loss": 0.6858906435966492, "val_acc": 56.0}
{"epoch": 26, "training_loss": 0.6957862424850464, "training_acc": 52.0, "val_loss": 0.6989470410346985, "val_acc": 44.0}
{"epoch": 27, "training_loss": 0.6926915121078491, "training_acc": 49.0, "val_loss": 0.6868105626106262, "val_acc": 56.0}
{"epoch": 28, "training_loss": 0.7155675292015076, "training_acc": 52.0, "val_loss": 0.6859650301933289, "val_acc": 56.0}
{"epoch": 29, "training_loss": 0.7005997133255005, "training_acc": 46.0, "val_loss": 0.7181881260871887, "val_acc": 44.0}
{"epoch": 30, "training_loss": 0.7079143762588501, "training_acc": 48.0, "val_loss": 0.689013819694519, "val_acc": 56.0}
{"epoch": 31, "training_loss": 0.7308047842979432, "training_acc": 52.0, "val_loss": 0.693694806098938, "val_acc": 56.0}
{"epoch": 32, "training_loss": 0.7024280548095703, "training_acc": 52.0, "val_loss": 0.6935548067092896, "val_acc": 44.0}
{"epoch": 33, "training_loss": 0.6941409468650818, "training_acc": 49.0, "val_loss": 0.7023616790771484, "val_acc": 44.0}
{"epoch": 34, "training_loss": 0.6951203727722168, "training_acc": 50.0, "val_loss": 0.6859976196289063, "val_acc": 56.0}
{"epoch": 35, "training_loss": 0.7234159064292908, "training_acc": 52.0, "val_loss": 0.6861479163169861, "val_acc": 56.0}
{"epoch": 36, "training_loss": 0.6947786283493042, "training_acc": 52.0, "val_loss": 0.7053822827339172, "val_acc": 44.0}
{"epoch": 37, "training_loss": 0.709423053264618, "training_acc": 48.0, "val_loss": 0.7094028973579407, "val_acc": 44.0}
{"epoch": 38, "training_loss": 0.7001612544059753, "training_acc": 46.0, "val_loss": 0.687505624294281, "val_acc": 56.0}
{"epoch": 39, "training_loss": 0.6942155289649964, "training_acc": 52.0, "val_loss": 0.6878990530967712, "val_acc": 56.0}
{"epoch": 40, "training_loss": 0.6954220414161683, "training_acc": 52.0, "val_loss": 0.6939684772491455, "val_acc": 44.0}
{"epoch": 41, "training_loss": 0.7182898235321045, "training_acc": 48.0, "val_loss": 0.7136056447029113, "val_acc": 44.0}
{"epoch": 42, "training_loss": 0.6934477734565735, "training_acc": 50.0, "val_loss": 0.6905022883415222, "val_acc": 56.0}
