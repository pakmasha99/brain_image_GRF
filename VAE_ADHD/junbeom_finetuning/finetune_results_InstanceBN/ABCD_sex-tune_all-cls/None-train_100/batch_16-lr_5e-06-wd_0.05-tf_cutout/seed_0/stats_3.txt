"main_modify.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option BT_org --learning_rate 5e-6 --batch_size 16 --weight_decay 5e-2 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 0.6915306258201599, "training_acc": 53.0, "val_loss": 0.6924974131584167, "val_acc": 52.0}
{"epoch": 1, "training_loss": 0.6917522239685059, "training_acc": 53.0, "val_loss": 0.6925456953048706, "val_acc": 52.0}
{"epoch": 2, "training_loss": 0.6911064291000366, "training_acc": 53.0, "val_loss": 0.6925997352600097, "val_acc": 52.0}
{"epoch": 3, "training_loss": 0.691082615852356, "training_acc": 53.0, "val_loss": 0.6926384782791137, "val_acc": 52.0}
{"epoch": 4, "training_loss": 0.6914375782012939, "training_acc": 53.0, "val_loss": 0.6928740262985229, "val_acc": 52.0}
{"epoch": 5, "training_loss": 0.6912726449966431, "training_acc": 53.0, "val_loss": 0.6928347015380859, "val_acc": 52.0}
{"epoch": 6, "training_loss": 0.690701367855072, "training_acc": 53.0, "val_loss": 0.6927543163299561, "val_acc": 52.0}
{"epoch": 7, "training_loss": 0.6909771609306335, "training_acc": 53.0, "val_loss": 0.6925511598587036, "val_acc": 52.0}
{"epoch": 8, "training_loss": 0.690497989654541, "training_acc": 53.0, "val_loss": 0.6923453068733215, "val_acc": 52.0}
{"epoch": 9, "training_loss": 0.690562059879303, "training_acc": 53.0, "val_loss": 0.6923566389083863, "val_acc": 52.0}
{"epoch": 10, "training_loss": 0.6899247884750366, "training_acc": 53.0, "val_loss": 0.6925228929519653, "val_acc": 52.0}
{"epoch": 11, "training_loss": 0.6898132991790772, "training_acc": 53.0, "val_loss": 0.6926830077171325, "val_acc": 52.0}
{"epoch": 12, "training_loss": 0.6898142004013061, "training_acc": 53.0, "val_loss": 0.692648594379425, "val_acc": 52.0}
{"epoch": 13, "training_loss": 0.6897344064712524, "training_acc": 53.0, "val_loss": 0.6926073837280273, "val_acc": 52.0}
{"epoch": 14, "training_loss": 0.690069489479065, "training_acc": 53.0, "val_loss": 0.6923194527626038, "val_acc": 52.0}
{"epoch": 15, "training_loss": 0.6899537563323974, "training_acc": 53.0, "val_loss": 0.6922138690948486, "val_acc": 52.0}
{"epoch": 16, "training_loss": 0.6898483085632324, "training_acc": 53.0, "val_loss": 0.692134621143341, "val_acc": 52.0}
{"epoch": 17, "training_loss": 0.6901397371292114, "training_acc": 53.0, "val_loss": 0.6921476578712463, "val_acc": 52.0}
{"epoch": 18, "training_loss": 0.6898959302902221, "training_acc": 53.0, "val_loss": 0.6922025871276856, "val_acc": 52.0}
{"epoch": 19, "training_loss": 0.6898195004463196, "training_acc": 53.0, "val_loss": 0.6921410441398621, "val_acc": 52.0}
{"epoch": 20, "training_loss": 0.6894384145736694, "training_acc": 53.0, "val_loss": 0.6920202612876892, "val_acc": 52.0}
{"epoch": 21, "training_loss": 0.6893252062797547, "training_acc": 53.0, "val_loss": 0.6920917439460754, "val_acc": 52.0}
{"epoch": 22, "training_loss": 0.6893251276016236, "training_acc": 53.0, "val_loss": 0.6920801162719726, "val_acc": 52.0}
{"epoch": 23, "training_loss": 0.6889304208755493, "training_acc": 53.0, "val_loss": 0.6920359778404236, "val_acc": 52.0}
{"epoch": 24, "training_loss": 0.6895364093780517, "training_acc": 53.0, "val_loss": 0.6921014046669006, "val_acc": 52.0}
{"epoch": 25, "training_loss": 0.6890659785270691, "training_acc": 53.0, "val_loss": 0.692131130695343, "val_acc": 52.0}
{"epoch": 26, "training_loss": 0.6894463229179383, "training_acc": 53.0, "val_loss": 0.6921301221847534, "val_acc": 52.0}
{"epoch": 27, "training_loss": 0.6892838096618652, "training_acc": 53.0, "val_loss": 0.6922615170478821, "val_acc": 52.0}
{"epoch": 28, "training_loss": 0.689387526512146, "training_acc": 53.0, "val_loss": 0.6923678660392761, "val_acc": 52.0}
{"epoch": 29, "training_loss": 0.6891613912582397, "training_acc": 53.0, "val_loss": 0.6921839928627014, "val_acc": 52.0}
{"epoch": 30, "training_loss": 0.688836841583252, "training_acc": 53.0, "val_loss": 0.6922640585899353, "val_acc": 52.0}
{"epoch": 31, "training_loss": 0.6880766201019287, "training_acc": 53.0, "val_loss": 0.6925017237663269, "val_acc": 52.0}
{"epoch": 32, "training_loss": 0.6886784744262695, "training_acc": 53.0, "val_loss": 0.6924851679801941, "val_acc": 52.0}
{"epoch": 33, "training_loss": 0.6887795448303222, "training_acc": 53.0, "val_loss": 0.6921602034568787, "val_acc": 52.0}
{"epoch": 34, "training_loss": 0.6881503820419311, "training_acc": 53.0, "val_loss": 0.6921352696418762, "val_acc": 52.0}
{"epoch": 35, "training_loss": 0.6879525065422059, "training_acc": 53.0, "val_loss": 0.6922221040725708, "val_acc": 52.0}
{"epoch": 36, "training_loss": 0.6880605363845825, "training_acc": 53.0, "val_loss": 0.6922831678390503, "val_acc": 52.0}
{"epoch": 37, "training_loss": 0.6890383458137512, "training_acc": 53.0, "val_loss": 0.6925196146965027, "val_acc": 52.0}
{"epoch": 38, "training_loss": 0.6887653613090515, "training_acc": 53.0, "val_loss": 0.6922046208381653, "val_acc": 52.0}
{"epoch": 39, "training_loss": 0.688858380317688, "training_acc": 53.0, "val_loss": 0.6921379780769348, "val_acc": 52.0}
