"main_modify.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option BT_org --learning_rate 5e-6 --batch_size 16 --weight_decay 5e-2 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 0.702982292175293, "training_acc": 47.0, "val_loss": 0.7009085011482239, "val_acc": 48.0}
{"epoch": 1, "training_loss": 0.702025649547577, "training_acc": 47.0, "val_loss": 0.7000685214996338, "val_acc": 48.0}
{"epoch": 2, "training_loss": 0.7007495450973511, "training_acc": 47.0, "val_loss": 0.6986010670661926, "val_acc": 48.0}
{"epoch": 3, "training_loss": 0.6996120882034301, "training_acc": 47.0, "val_loss": 0.6976434159278869, "val_acc": 48.0}
{"epoch": 4, "training_loss": 0.6979729127883911, "training_acc": 47.0, "val_loss": 0.6966943264007568, "val_acc": 48.0}
{"epoch": 5, "training_loss": 0.697082405090332, "training_acc": 47.0, "val_loss": 0.6962257742881774, "val_acc": 48.0}
{"epoch": 6, "training_loss": 0.696571249961853, "training_acc": 47.0, "val_loss": 0.6962886571884155, "val_acc": 48.0}
{"epoch": 7, "training_loss": 0.6947467660903931, "training_acc": 47.0, "val_loss": 0.6951438760757447, "val_acc": 48.0}
{"epoch": 8, "training_loss": 0.6961761689186097, "training_acc": 47.0, "val_loss": 0.6947789001464844, "val_acc": 48.0}
{"epoch": 9, "training_loss": 0.6948304891586303, "training_acc": 47.0, "val_loss": 0.6941662168502808, "val_acc": 48.0}
{"epoch": 10, "training_loss": 0.6941338443756103, "training_acc": 47.0, "val_loss": 0.6943108773231507, "val_acc": 48.0}
{"epoch": 11, "training_loss": 0.6937839365005494, "training_acc": 47.0, "val_loss": 0.6943419933319092, "val_acc": 48.0}
{"epoch": 12, "training_loss": 0.6941068077087402, "training_acc": 47.0, "val_loss": 0.6938418173789977, "val_acc": 48.0}
{"epoch": 13, "training_loss": 0.6933958005905151, "training_acc": 47.0, "val_loss": 0.6936876964569092, "val_acc": 48.0}
{"epoch": 14, "training_loss": 0.6930523180961609, "training_acc": 47.0, "val_loss": 0.6936026000976563, "val_acc": 48.0}
{"epoch": 15, "training_loss": 0.6925506687164307, "training_acc": 52.0, "val_loss": 0.6936277794837952, "val_acc": 56.0}
{"epoch": 16, "training_loss": 0.6914972925186157, "training_acc": 61.0, "val_loss": 0.6932987713813782, "val_acc": 44.0}
{"epoch": 17, "training_loss": 0.692569510936737, "training_acc": 50.0, "val_loss": 0.6935734534263611, "val_acc": 48.0}
{"epoch": 18, "training_loss": 0.6926104736328125, "training_acc": 51.0, "val_loss": 0.6935753178596497, "val_acc": 48.0}
{"epoch": 19, "training_loss": 0.6914215230941773, "training_acc": 54.0, "val_loss": 0.6936120963096619, "val_acc": 48.0}
{"epoch": 20, "training_loss": 0.6917359399795532, "training_acc": 55.0, "val_loss": 0.6928342771530152, "val_acc": 48.0}
{"epoch": 21, "training_loss": 0.6910654878616334, "training_acc": 57.0, "val_loss": 0.6927734756469727, "val_acc": 48.0}
{"epoch": 22, "training_loss": 0.6916780877113342, "training_acc": 46.0, "val_loss": 0.6933180284500122, "val_acc": 52.0}
{"epoch": 23, "training_loss": 0.6911425709724426, "training_acc": 55.0, "val_loss": 0.6940203285217286, "val_acc": 52.0}
{"epoch": 24, "training_loss": 0.6900007581710815, "training_acc": 56.0, "val_loss": 0.693582501411438, "val_acc": 52.0}
{"epoch": 25, "training_loss": 0.690652117729187, "training_acc": 53.0, "val_loss": 0.6935100579261779, "val_acc": 52.0}
{"epoch": 26, "training_loss": 0.6903332901000977, "training_acc": 52.0, "val_loss": 0.6939247584342957, "val_acc": 52.0}
{"epoch": 27, "training_loss": 0.690966432094574, "training_acc": 54.0, "val_loss": 0.6941721320152283, "val_acc": 52.0}
{"epoch": 28, "training_loss": 0.691172559261322, "training_acc": 53.0, "val_loss": 0.6938422441482544, "val_acc": 52.0}
{"epoch": 29, "training_loss": 0.6900769424438477, "training_acc": 52.0, "val_loss": 0.6939087390899659, "val_acc": 52.0}
{"epoch": 30, "training_loss": 0.6906344175338746, "training_acc": 53.0, "val_loss": 0.6920057106018066, "val_acc": 52.0}
{"epoch": 31, "training_loss": 0.6908677983283996, "training_acc": 53.0, "val_loss": 0.6918875813484192, "val_acc": 52.0}
{"epoch": 32, "training_loss": 0.6905470514297485, "training_acc": 53.0, "val_loss": 0.6927180457115173, "val_acc": 52.0}
{"epoch": 33, "training_loss": 0.6899899244308472, "training_acc": 53.0, "val_loss": 0.6934596228599549, "val_acc": 52.0}
{"epoch": 34, "training_loss": 0.6902696776390076, "training_acc": 53.0, "val_loss": 0.6944225931167602, "val_acc": 52.0}
{"epoch": 35, "training_loss": 0.6895446491241455, "training_acc": 53.0, "val_loss": 0.6933704423904419, "val_acc": 52.0}
{"epoch": 36, "training_loss": 0.6906804895401001, "training_acc": 53.0, "val_loss": 0.6927999973297119, "val_acc": 52.0}
{"epoch": 37, "training_loss": 0.689711468219757, "training_acc": 53.0, "val_loss": 0.6933904981613159, "val_acc": 52.0}
{"epoch": 38, "training_loss": 0.6904429125785828, "training_acc": 53.0, "val_loss": 0.6942758464813232, "val_acc": 52.0}
{"epoch": 39, "training_loss": 0.6886351346969605, "training_acc": 53.0, "val_loss": 0.6944934964179993, "val_acc": 52.0}
{"epoch": 40, "training_loss": 0.68905611038208, "training_acc": 53.0, "val_loss": 0.694272301197052, "val_acc": 52.0}
{"epoch": 41, "training_loss": 0.6893276977539062, "training_acc": 53.0, "val_loss": 0.6929197454452515, "val_acc": 52.0}
{"epoch": 42, "training_loss": 0.6900975704193115, "training_acc": 53.0, "val_loss": 0.6932707476615906, "val_acc": 52.0}
{"epoch": 43, "training_loss": 0.6903063416481018, "training_acc": 53.0, "val_loss": 0.6930202794075012, "val_acc": 52.0}
{"epoch": 44, "training_loss": 0.6894335746765137, "training_acc": 53.0, "val_loss": 0.6924429678916931, "val_acc": 52.0}
{"epoch": 45, "training_loss": 0.6900214052200317, "training_acc": 53.0, "val_loss": 0.6930190777778625, "val_acc": 52.0}
{"epoch": 46, "training_loss": 0.6901662397384644, "training_acc": 53.0, "val_loss": 0.6932916903495788, "val_acc": 52.0}
{"epoch": 47, "training_loss": 0.6899798059463501, "training_acc": 53.0, "val_loss": 0.6930265522003174, "val_acc": 52.0}
{"epoch": 48, "training_loss": 0.6892291688919068, "training_acc": 53.0, "val_loss": 0.692834644317627, "val_acc": 52.0}
{"epoch": 49, "training_loss": 0.6892351436614991, "training_acc": 53.0, "val_loss": 0.6929701161384583, "val_acc": 52.0}
{"epoch": 50, "training_loss": 0.6896944570541382, "training_acc": 53.0, "val_loss": 0.6928810739517212, "val_acc": 52.0}
