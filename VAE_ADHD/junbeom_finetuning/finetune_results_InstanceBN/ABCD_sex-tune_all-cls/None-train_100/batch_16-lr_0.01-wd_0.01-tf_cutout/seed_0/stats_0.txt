"main_modify.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option BT_org --learning_rate 1e-2 --batch_size 16 --weight_decay 1e-2 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 1.2281884527206421, "training_acc": 46.0, "val_loss": 0.6913133358955383, "val_acc": 52.0}
{"epoch": 1, "training_loss": 0.7758318400382995, "training_acc": 47.0, "val_loss": 0.7901780390739441, "val_acc": 44.0}
{"epoch": 2, "training_loss": 0.7554448866844177, "training_acc": 50.0, "val_loss": 0.6930879926681519, "val_acc": 56.0}
{"epoch": 3, "training_loss": 0.7410542845726014, "training_acc": 46.0, "val_loss": 0.8076515126228333, "val_acc": 44.0}
{"epoch": 4, "training_loss": 0.8568636083602905, "training_acc": 50.0, "val_loss": 0.7648493671417236, "val_acc": 56.0}
{"epoch": 5, "training_loss": 0.738250150680542, "training_acc": 46.0, "val_loss": 0.702418155670166, "val_acc": 44.0}
{"epoch": 6, "training_loss": 0.7243438386917114, "training_acc": 48.0, "val_loss": 0.703804748058319, "val_acc": 44.0}
{"epoch": 7, "training_loss": 0.7398461008071899, "training_acc": 52.0, "val_loss": 0.7105390214920044, "val_acc": 56.0}
{"epoch": 8, "training_loss": 0.6962598180770874, "training_acc": 54.0, "val_loss": 0.7487696719169616, "val_acc": 44.0}
{"epoch": 9, "training_loss": 0.7293918418884278, "training_acc": 52.0, "val_loss": 0.7668943929672242, "val_acc": 44.0}
{"epoch": 10, "training_loss": 0.8357322239875793, "training_acc": 50.0, "val_loss": 0.7086675763130188, "val_acc": 56.0}
{"epoch": 11, "training_loss": 0.738158860206604, "training_acc": 44.0, "val_loss": 0.7318425297737121, "val_acc": 56.0}
{"epoch": 12, "training_loss": 0.8487789559364319, "training_acc": 54.0, "val_loss": 0.9099879217147827, "val_acc": 44.0}
{"epoch": 13, "training_loss": 0.7268607378005981, "training_acc": 54.0, "val_loss": 0.7188784146308899, "val_acc": 56.0}
{"epoch": 14, "training_loss": 0.7269198417663574, "training_acc": 48.0, "val_loss": 0.6881743597984314, "val_acc": 56.0}
{"epoch": 15, "training_loss": 0.6883954358100891, "training_acc": 52.0, "val_loss": 0.8350667476654052, "val_acc": 56.0}
{"epoch": 16, "training_loss": 0.7505694675445557, "training_acc": 52.0, "val_loss": 0.851726598739624, "val_acc": 44.0}
{"epoch": 17, "training_loss": 0.7374068427085877, "training_acc": 52.0, "val_loss": 0.6899684929847717, "val_acc": 56.0}
{"epoch": 18, "training_loss": 0.7116339802742004, "training_acc": 42.0, "val_loss": 0.7082310819625854, "val_acc": 44.0}
{"epoch": 19, "training_loss": 0.7299719762802124, "training_acc": 44.0, "val_loss": 0.6876724219322204, "val_acc": 56.0}
{"epoch": 20, "training_loss": 0.7119949245452881, "training_acc": 52.0, "val_loss": 0.6901079607009888, "val_acc": 56.0}
{"epoch": 21, "training_loss": 0.7048763513565064, "training_acc": 44.0, "val_loss": 0.6888829398155213, "val_acc": 56.0}
{"epoch": 22, "training_loss": 0.7161846017837524, "training_acc": 54.0, "val_loss": 0.7740452098846435, "val_acc": 44.0}
{"epoch": 23, "training_loss": 0.7401216173171997, "training_acc": 42.0, "val_loss": 0.6982954692840576, "val_acc": 56.0}
{"epoch": 24, "training_loss": 0.76586998462677, "training_acc": 54.0, "val_loss": 0.7948122477531433, "val_acc": 44.0}
{"epoch": 25, "training_loss": 0.7498973035812377, "training_acc": 48.0, "val_loss": 0.6871129441261291, "val_acc": 56.0}
{"epoch": 26, "training_loss": 0.7398903393745422, "training_acc": 52.0, "val_loss": 0.7275932049751281, "val_acc": 44.0}
{"epoch": 27, "training_loss": 0.7172273159027099, "training_acc": 48.0, "val_loss": 0.6859331440925598, "val_acc": 56.0}
{"epoch": 28, "training_loss": 0.7291093778610229, "training_acc": 40.0, "val_loss": 0.6874008631706238, "val_acc": 56.0}
{"epoch": 29, "training_loss": 0.706708288192749, "training_acc": 48.0, "val_loss": 0.6863342237472534, "val_acc": 56.0}
{"epoch": 30, "training_loss": 0.7683238482475281, "training_acc": 50.0, "val_loss": 0.717172691822052, "val_acc": 44.0}
{"epoch": 31, "training_loss": 0.7036502552032471, "training_acc": 52.0, "val_loss": 0.742347559928894, "val_acc": 56.0}
{"epoch": 32, "training_loss": 0.7917818260192871, "training_acc": 50.0, "val_loss": 0.7014841890335083, "val_acc": 44.0}
{"epoch": 33, "training_loss": 0.7134103322029114, "training_acc": 50.0, "val_loss": 0.7098702168464661, "val_acc": 44.0}
{"epoch": 34, "training_loss": 0.7179212188720703, "training_acc": 44.0, "val_loss": 0.7018435978889466, "val_acc": 44.0}
{"epoch": 35, "training_loss": 0.7007796144485474, "training_acc": 50.0, "val_loss": 0.6921987891197204, "val_acc": 56.0}
{"epoch": 36, "training_loss": 0.7259767723083496, "training_acc": 46.0, "val_loss": 0.6883115148544312, "val_acc": 56.0}
{"epoch": 37, "training_loss": 0.7106882047653198, "training_acc": 42.0, "val_loss": 0.6871632313728333, "val_acc": 56.0}
{"epoch": 38, "training_loss": 0.7091375398635864, "training_acc": 42.0, "val_loss": 0.6863369297981262, "val_acc": 56.0}
{"epoch": 39, "training_loss": 0.698683786392212, "training_acc": 52.0, "val_loss": 0.7311421990394592, "val_acc": 44.0}
{"epoch": 40, "training_loss": 0.7364214491844178, "training_acc": 46.0, "val_loss": 0.7142182981967926, "val_acc": 56.0}
{"epoch": 41, "training_loss": 0.7302700185775757, "training_acc": 52.0, "val_loss": 0.7114351201057434, "val_acc": 44.0}
{"epoch": 42, "training_loss": 0.7065995121002198, "training_acc": 42.0, "val_loss": 0.7056277918815613, "val_acc": 44.0}
{"epoch": 43, "training_loss": 0.7254673099517822, "training_acc": 48.0, "val_loss": 0.7226603031158447, "val_acc": 44.0}
{"epoch": 44, "training_loss": 0.7534034228324891, "training_acc": 48.0, "val_loss": 0.6914639973640442, "val_acc": 56.0}
{"epoch": 45, "training_loss": 0.7156998133659362, "training_acc": 52.0, "val_loss": 0.699688904285431, "val_acc": 44.0}
{"epoch": 46, "training_loss": 0.7015650415420532, "training_acc": 46.0, "val_loss": 0.6860338473320007, "val_acc": 56.0}
