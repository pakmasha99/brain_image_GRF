"main_modify.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option BT_org --learning_rate 1e-1 --batch_size 16 --weight_decay 1e-2 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 9.294904317855835, "training_acc": 43.0, "val_loss": 3.2282954406738282, "val_acc": 52.0}
{"epoch": 1, "training_loss": 3.251384048461914, "training_acc": 57.0, "val_loss": 1.512884292602539, "val_acc": 48.0}
{"epoch": 2, "training_loss": 3.0904847145080567, "training_acc": 49.0, "val_loss": 2.9659902381896974, "val_acc": 52.0}
{"epoch": 3, "training_loss": 3.507042465209961, "training_acc": 51.0, "val_loss": 1.5585752964019775, "val_acc": 52.0}
{"epoch": 4, "training_loss": 1.8949672031402587, "training_acc": 53.0, "val_loss": 3.4321054458618163, "val_acc": 52.0}
{"epoch": 5, "training_loss": 2.6459662818908694, "training_acc": 49.0, "val_loss": 2.8116979598999023, "val_acc": 52.0}
{"epoch": 6, "training_loss": 2.416543788909912, "training_acc": 49.0, "val_loss": 2.8135257720947267, "val_acc": 52.0}
{"epoch": 7, "training_loss": 1.628351879119873, "training_acc": 49.0, "val_loss": 0.7904433059692383, "val_acc": 52.0}
{"epoch": 8, "training_loss": 1.3651498222351075, "training_acc": 43.0, "val_loss": 0.7196098518371582, "val_acc": 52.0}
{"epoch": 9, "training_loss": 0.9204113292694092, "training_acc": 45.0, "val_loss": 1.0634424424171447, "val_acc": 52.0}
{"epoch": 10, "training_loss": 1.1078704977035523, "training_acc": 53.0, "val_loss": 0.9303940486907959, "val_acc": 48.0}
{"epoch": 11, "training_loss": 0.981011095046997, "training_acc": 53.0, "val_loss": 0.8001420259475708, "val_acc": 48.0}
{"epoch": 12, "training_loss": 1.0114195013046265, "training_acc": 41.0, "val_loss": 1.054740128517151, "val_acc": 48.0}
{"epoch": 13, "training_loss": 0.9656126570701599, "training_acc": 55.0, "val_loss": 0.8504046201705933, "val_acc": 52.0}
{"epoch": 14, "training_loss": 1.0975629806518554, "training_acc": 53.0, "val_loss": 2.850604257583618, "val_acc": 52.0}
{"epoch": 15, "training_loss": 2.194295787811279, "training_acc": 51.0, "val_loss": 0.8161460518836975, "val_acc": 48.0}
{"epoch": 16, "training_loss": 0.939410126209259, "training_acc": 55.0, "val_loss": 0.8564702582359314, "val_acc": 52.0}
{"epoch": 17, "training_loss": 1.0610567951202392, "training_acc": 53.0, "val_loss": 5.584320087432861, "val_acc": 52.0}
{"epoch": 18, "training_loss": 1.8225443029403687, "training_acc": 51.0, "val_loss": 1.9593984842300416, "val_acc": 52.0}
{"epoch": 19, "training_loss": 2.095814895629883, "training_acc": 49.0, "val_loss": 1.0768105292320251, "val_acc": 48.0}
{"epoch": 20, "training_loss": 1.494675760269165, "training_acc": 47.0, "val_loss": 1.3437732172012329, "val_acc": 52.0}
{"epoch": 21, "training_loss": 1.8357929182052612, "training_acc": 49.0, "val_loss": 3.9517874050140382, "val_acc": 52.0}
{"epoch": 22, "training_loss": 2.7503594255447386, "training_acc": 57.0, "val_loss": 0.6923469924926757, "val_acc": 52.0}
{"epoch": 23, "training_loss": 0.7425526523590088, "training_acc": 53.0, "val_loss": 1.7739877414703369, "val_acc": 52.0}
{"epoch": 24, "training_loss": 1.6517507457733154, "training_acc": 47.0, "val_loss": 0.7840804648399353, "val_acc": 48.0}
{"epoch": 25, "training_loss": 0.7658332777023316, "training_acc": 53.0, "val_loss": 1.5132965087890624, "val_acc": 48.0}
{"epoch": 26, "training_loss": 1.7748406887054444, "training_acc": 37.0, "val_loss": 0.9807709455490112, "val_acc": 48.0}
{"epoch": 27, "training_loss": 1.5406737232208252, "training_acc": 51.0, "val_loss": 1.1391127061843873, "val_acc": 52.0}
{"epoch": 28, "training_loss": 1.2037526726722718, "training_acc": 55.0, "val_loss": 0.9064698076248169, "val_acc": 52.0}
{"epoch": 29, "training_loss": 1.2353118562698364, "training_acc": 51.0, "val_loss": 2.302440867424011, "val_acc": 52.0}
{"epoch": 30, "training_loss": 1.5130923175811768, "training_acc": 47.0, "val_loss": 1.0923611092567445, "val_acc": 52.0}
{"epoch": 31, "training_loss": 0.9584029340744018, "training_acc": 57.0, "val_loss": 1.2050816345214843, "val_acc": 48.0}
{"epoch": 32, "training_loss": 1.0057234001159667, "training_acc": 47.0, "val_loss": 0.8569341278076172, "val_acc": 52.0}
{"epoch": 33, "training_loss": 1.2669593238830565, "training_acc": 37.0, "val_loss": 1.3815892124176026, "val_acc": 52.0}
{"epoch": 34, "training_loss": 0.8753588414192199, "training_acc": 45.0, "val_loss": 0.6928246235847473, "val_acc": 52.0}
{"epoch": 35, "training_loss": 1.8185836935043336, "training_acc": 59.0, "val_loss": 0.6925184082984924, "val_acc": 52.0}
{"epoch": 36, "training_loss": 0.7742748594284058, "training_acc": 47.0, "val_loss": 0.7063821268081665, "val_acc": 52.0}
{"epoch": 37, "training_loss": 0.7721268534660339, "training_acc": 57.0, "val_loss": 1.492197413444519, "val_acc": 48.0}
{"epoch": 38, "training_loss": 1.6431964421272278, "training_acc": 45.0, "val_loss": 1.1853095364570618, "val_acc": 52.0}
{"epoch": 39, "training_loss": 1.3684653282165526, "training_acc": 49.0, "val_loss": 0.880751543045044, "val_acc": 48.0}
{"epoch": 40, "training_loss": 0.7916444277763367, "training_acc": 57.0, "val_loss": 2.3332654523849485, "val_acc": 48.0}
{"epoch": 41, "training_loss": 1.8648149681091308, "training_acc": 51.0, "val_loss": 1.7552208757400514, "val_acc": 52.0}
