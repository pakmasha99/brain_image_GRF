"main_modify.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option BT_org --learning_rate 1e-3 --batch_size 16 --weight_decay 1e-6 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 0.7199817490577698, "training_acc": 46.0, "val_loss": 0.692472267150879, "val_acc": 52.0}
{"epoch": 1, "training_loss": 0.6971679902076722, "training_acc": 51.0, "val_loss": 0.6930003809928894, "val_acc": 52.0}
{"epoch": 2, "training_loss": 0.7017021036148071, "training_acc": 53.0, "val_loss": 0.6941352581977844, "val_acc": 52.0}
{"epoch": 3, "training_loss": 0.7002391576766968, "training_acc": 43.0, "val_loss": 0.6956513500213624, "val_acc": 52.0}
{"epoch": 4, "training_loss": 0.6946351718902588, "training_acc": 53.0, "val_loss": 0.6981818795204162, "val_acc": 52.0}
{"epoch": 5, "training_loss": 0.7076881265640259, "training_acc": 41.0, "val_loss": 0.6953171539306641, "val_acc": 48.0}
{"epoch": 6, "training_loss": 0.6976249146461487, "training_acc": 49.0, "val_loss": 0.6935195541381836, "val_acc": 52.0}
{"epoch": 7, "training_loss": 0.7160715961456299, "training_acc": 53.0, "val_loss": 0.6973172497749328, "val_acc": 52.0}
{"epoch": 8, "training_loss": 0.6934902763366699, "training_acc": 53.0, "val_loss": 0.6952570104598998, "val_acc": 48.0}
{"epoch": 9, "training_loss": 0.7170446586608886, "training_acc": 47.0, "val_loss": 0.6961288547515869, "val_acc": 48.0}
{"epoch": 10, "training_loss": 0.7172998332977295, "training_acc": 51.0, "val_loss": 0.704784836769104, "val_acc": 52.0}
{"epoch": 11, "training_loss": 0.709165735244751, "training_acc": 37.0, "val_loss": 0.6927627682685852, "val_acc": 52.0}
{"epoch": 12, "training_loss": 0.6979550647735596, "training_acc": 53.0, "val_loss": 0.6932926249504089, "val_acc": 52.0}
{"epoch": 13, "training_loss": 0.7031191897392273, "training_acc": 53.0, "val_loss": 0.7047316336631775, "val_acc": 52.0}
{"epoch": 14, "training_loss": 0.6920126461982727, "training_acc": 53.0, "val_loss": 0.6944059991836548, "val_acc": 48.0}
{"epoch": 15, "training_loss": 0.7098210620880127, "training_acc": 47.0, "val_loss": 0.6958819675445557, "val_acc": 48.0}
{"epoch": 16, "training_loss": 0.7072635388374329, "training_acc": 47.0, "val_loss": 0.7009150290489197, "val_acc": 52.0}
{"epoch": 17, "training_loss": 0.6980266761779785, "training_acc": 53.0, "val_loss": 0.6933303904533387, "val_acc": 52.0}
{"epoch": 18, "training_loss": 0.6916282534599304, "training_acc": 53.0, "val_loss": 0.6924405288696289, "val_acc": 52.0}
{"epoch": 19, "training_loss": 0.6956161117553711, "training_acc": 43.0, "val_loss": 0.6923736166954041, "val_acc": 52.0}
{"epoch": 20, "training_loss": 0.6972119951248169, "training_acc": 53.0, "val_loss": 0.6969080805778504, "val_acc": 52.0}
{"epoch": 21, "training_loss": 0.6950754117965698, "training_acc": 53.0, "val_loss": 0.6925202870368957, "val_acc": 52.0}
{"epoch": 22, "training_loss": 0.702094931602478, "training_acc": 39.0, "val_loss": 0.6936096501350403, "val_acc": 48.0}
{"epoch": 23, "training_loss": 0.6896437168121338, "training_acc": 53.0, "val_loss": 0.6969068884849549, "val_acc": 52.0}
{"epoch": 24, "training_loss": 0.6995708727836609, "training_acc": 53.0, "val_loss": 0.6948911666870117, "val_acc": 52.0}
{"epoch": 25, "training_loss": 0.7119716238975525, "training_acc": 39.0, "val_loss": 0.6971217870712281, "val_acc": 48.0}
{"epoch": 26, "training_loss": 0.6959803414344787, "training_acc": 45.0, "val_loss": 0.6938140773773194, "val_acc": 52.0}
{"epoch": 27, "training_loss": 0.6979084587097169, "training_acc": 53.0, "val_loss": 0.6976428270339966, "val_acc": 52.0}
{"epoch": 28, "training_loss": 0.7038414478302002, "training_acc": 43.0, "val_loss": 0.7009333491325378, "val_acc": 48.0}
{"epoch": 29, "training_loss": 0.7046536254882813, "training_acc": 47.0, "val_loss": 0.6926587462425232, "val_acc": 52.0}
{"epoch": 30, "training_loss": 0.7030306100845337, "training_acc": 53.0, "val_loss": 0.7081318879127503, "val_acc": 52.0}
{"epoch": 31, "training_loss": 0.7109692001342773, "training_acc": 53.0, "val_loss": 0.698315417766571, "val_acc": 52.0}
{"epoch": 32, "training_loss": 0.6934872007369995, "training_acc": 53.0, "val_loss": 0.7020463228225708, "val_acc": 48.0}
{"epoch": 33, "training_loss": 0.7092025423049927, "training_acc": 45.0, "val_loss": 0.6925165486335755, "val_acc": 52.0}
{"epoch": 34, "training_loss": 0.6923139834403992, "training_acc": 53.0, "val_loss": 0.6940611243247986, "val_acc": 52.0}
{"epoch": 35, "training_loss": 0.6950161981582642, "training_acc": 53.0, "val_loss": 0.6935252046585083, "val_acc": 52.0}
{"epoch": 36, "training_loss": 0.6944129037857055, "training_acc": 53.0, "val_loss": 0.6938985586166382, "val_acc": 52.0}
{"epoch": 37, "training_loss": 0.7030692958831787, "training_acc": 41.0, "val_loss": 0.6939849948883057, "val_acc": 48.0}
{"epoch": 38, "training_loss": 0.6920961427688599, "training_acc": 51.0, "val_loss": 0.6939872860908508, "val_acc": 52.0}
