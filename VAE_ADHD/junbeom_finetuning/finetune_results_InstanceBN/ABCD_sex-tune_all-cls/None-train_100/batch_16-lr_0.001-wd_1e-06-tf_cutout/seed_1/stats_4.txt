"main_modify.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 1 --task ABCD_sex --input_option BT_org --learning_rate 1e-3 --batch_size 16 --weight_decay 1e-6 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 0.7055297660827636, "training_acc": 44.0, "val_loss": 0.6861876106262207, "val_acc": 56.0}
{"epoch": 1, "training_loss": 0.7150751090049744, "training_acc": 52.0, "val_loss": 0.6913644075393677, "val_acc": 56.0}
{"epoch": 2, "training_loss": 0.6971223974227905, "training_acc": 44.0, "val_loss": 0.6871303677558899, "val_acc": 56.0}
{"epoch": 3, "training_loss": 0.7035946989059448, "training_acc": 52.0, "val_loss": 0.6879402947425842, "val_acc": 56.0}
{"epoch": 4, "training_loss": 0.6975114917755127, "training_acc": 44.0, "val_loss": 0.6860223579406738, "val_acc": 56.0}
{"epoch": 5, "training_loss": 0.700387692451477, "training_acc": 52.0, "val_loss": 0.6859414219856262, "val_acc": 56.0}
{"epoch": 6, "training_loss": 0.695541684627533, "training_acc": 52.0, "val_loss": 0.6904055500030517, "val_acc": 56.0}
{"epoch": 7, "training_loss": 0.694534239768982, "training_acc": 52.0, "val_loss": 0.6942528104782104, "val_acc": 44.0}
{"epoch": 8, "training_loss": 0.70133629322052, "training_acc": 46.0, "val_loss": 0.6972991108894349, "val_acc": 44.0}
{"epoch": 9, "training_loss": 0.6994077205657959, "training_acc": 42.0, "val_loss": 0.6906495213508606, "val_acc": 56.0}
{"epoch": 10, "training_loss": 0.6963715553283691, "training_acc": 52.0, "val_loss": 0.6878934621810913, "val_acc": 56.0}
{"epoch": 11, "training_loss": 0.7073346877098083, "training_acc": 50.0, "val_loss": 0.718595895767212, "val_acc": 44.0}
{"epoch": 12, "training_loss": 0.7000376796722412, "training_acc": 48.0, "val_loss": 0.6872138237953186, "val_acc": 56.0}
{"epoch": 13, "training_loss": 0.7100629901885986, "training_acc": 52.0, "val_loss": 0.6869677639007569, "val_acc": 56.0}
{"epoch": 14, "training_loss": 0.7221771931648254, "training_acc": 46.0, "val_loss": 0.7231750845909118, "val_acc": 44.0}
{"epoch": 15, "training_loss": 0.7074383640289307, "training_acc": 46.0, "val_loss": 0.6864741468429565, "val_acc": 56.0}
{"epoch": 16, "training_loss": 0.695853328704834, "training_acc": 52.0, "val_loss": 0.68965726852417, "val_acc": 56.0}
{"epoch": 17, "training_loss": 0.6931107044219971, "training_acc": 52.0, "val_loss": 0.7099091243743897, "val_acc": 44.0}
{"epoch": 18, "training_loss": 0.7056795287132264, "training_acc": 42.0, "val_loss": 0.689655888080597, "val_acc": 56.0}
{"epoch": 19, "training_loss": 0.6974350452423096, "training_acc": 46.0, "val_loss": 0.7077523779869079, "val_acc": 44.0}
{"epoch": 20, "training_loss": 0.6998944568634033, "training_acc": 48.0, "val_loss": 0.6945508337020874, "val_acc": 44.0}
{"epoch": 21, "training_loss": 0.6896241354942322, "training_acc": 54.0, "val_loss": 0.6859296536445618, "val_acc": 56.0}
{"epoch": 22, "training_loss": 0.6970562028884888, "training_acc": 52.0, "val_loss": 0.6921541213989257, "val_acc": 56.0}
{"epoch": 23, "training_loss": 0.6939048790931701, "training_acc": 52.0, "val_loss": 0.6962171387672424, "val_acc": 44.0}
{"epoch": 24, "training_loss": 0.6955399918556213, "training_acc": 48.0, "val_loss": 0.6956079292297364, "val_acc": 44.0}
{"epoch": 25, "training_loss": 0.697275104522705, "training_acc": 50.0, "val_loss": 0.6886491394042968, "val_acc": 56.0}
{"epoch": 26, "training_loss": 0.7043493127822876, "training_acc": 48.0, "val_loss": 0.6993948078155517, "val_acc": 44.0}
{"epoch": 27, "training_loss": 0.6999158048629761, "training_acc": 46.0, "val_loss": 0.686704444885254, "val_acc": 56.0}
{"epoch": 28, "training_loss": 0.700181622505188, "training_acc": 52.0, "val_loss": 0.686924934387207, "val_acc": 56.0}
{"epoch": 29, "training_loss": 0.6992931365966797, "training_acc": 46.0, "val_loss": 0.699663577079773, "val_acc": 44.0}
{"epoch": 30, "training_loss": 0.698011519908905, "training_acc": 50.0, "val_loss": 0.6860554075241089, "val_acc": 56.0}
{"epoch": 31, "training_loss": 0.6877882504463195, "training_acc": 54.0, "val_loss": 0.7050043416023254, "val_acc": 44.0}
{"epoch": 32, "training_loss": 0.6992881321907043, "training_acc": 48.0, "val_loss": 0.6969782567024231, "val_acc": 44.0}
{"epoch": 33, "training_loss": 0.695198745727539, "training_acc": 46.0, "val_loss": 0.6894962763786316, "val_acc": 56.0}
{"epoch": 34, "training_loss": 0.6964440679550171, "training_acc": 52.0, "val_loss": 0.6859431958198547, "val_acc": 56.0}
{"epoch": 35, "training_loss": 0.6963869619369507, "training_acc": 52.0, "val_loss": 0.6861557793617249, "val_acc": 56.0}
{"epoch": 36, "training_loss": 0.6943247485160827, "training_acc": 52.0, "val_loss": 0.6898310208320617, "val_acc": 56.0}
{"epoch": 37, "training_loss": 0.6930950593948364, "training_acc": 52.0, "val_loss": 0.6883486890792847, "val_acc": 56.0}
{"epoch": 38, "training_loss": 0.6939913940429687, "training_acc": 52.0, "val_loss": 0.6893368220329285, "val_acc": 56.0}
{"epoch": 39, "training_loss": 0.6940807127952575, "training_acc": 52.0, "val_loss": 0.6863892269134522, "val_acc": 56.0}
{"epoch": 40, "training_loss": 0.7025663137435914, "training_acc": 52.0, "val_loss": 0.6864095044136047, "val_acc": 56.0}
