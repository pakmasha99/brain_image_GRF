"main_modify.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 1 --task ABCD_sex --input_option BT_org --learning_rate 1e-3 --batch_size 16 --weight_decay 1e-6 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 0.7271832299232482, "training_acc": 43.0, "val_loss": 0.7000967526435852, "val_acc": 52.0}
{"epoch": 1, "training_loss": 0.6915723252296447, "training_acc": 51.0, "val_loss": 0.6954612064361573, "val_acc": 48.0}
{"epoch": 2, "training_loss": 0.6915584707260132, "training_acc": 53.0, "val_loss": 0.7022681427001953, "val_acc": 52.0}
{"epoch": 3, "training_loss": 0.7001750469207764, "training_acc": 53.0, "val_loss": 0.6947980833053589, "val_acc": 52.0}
{"epoch": 4, "training_loss": 0.6942952799797059, "training_acc": 49.0, "val_loss": 0.6931847095489502, "val_acc": 48.0}
{"epoch": 5, "training_loss": 0.7007212114334106, "training_acc": 47.0, "val_loss": 0.6928300070762634, "val_acc": 52.0}
{"epoch": 6, "training_loss": 0.6940588331222535, "training_acc": 53.0, "val_loss": 0.6974594163894653, "val_acc": 52.0}
{"epoch": 7, "training_loss": 0.7088062977790832, "training_acc": 53.0, "val_loss": 0.6949394965171813, "val_acc": 52.0}
{"epoch": 8, "training_loss": 0.6938367795944214, "training_acc": 49.0, "val_loss": 0.6929443812370301, "val_acc": 52.0}
{"epoch": 9, "training_loss": 0.6923334717750549, "training_acc": 53.0, "val_loss": 0.6959825229644775, "val_acc": 52.0}
{"epoch": 10, "training_loss": 0.7004671955108642, "training_acc": 53.0, "val_loss": 0.6923879528045654, "val_acc": 52.0}
{"epoch": 11, "training_loss": 0.7165659189224243, "training_acc": 43.0, "val_loss": 0.6954186701774597, "val_acc": 48.0}
{"epoch": 12, "training_loss": 0.6947934246063232, "training_acc": 51.0, "val_loss": 0.6980044198036194, "val_acc": 52.0}
{"epoch": 13, "training_loss": 0.6937351942062377, "training_acc": 53.0, "val_loss": 0.694386715888977, "val_acc": 48.0}
{"epoch": 14, "training_loss": 0.703047068119049, "training_acc": 47.0, "val_loss": 0.6923995637893676, "val_acc": 52.0}
{"epoch": 15, "training_loss": 0.6937572145462036, "training_acc": 53.0, "val_loss": 0.7051502513885498, "val_acc": 52.0}
{"epoch": 16, "training_loss": 0.702633490562439, "training_acc": 53.0, "val_loss": 0.6929365849494934, "val_acc": 52.0}
{"epoch": 17, "training_loss": 0.702258939743042, "training_acc": 49.0, "val_loss": 0.6991575598716736, "val_acc": 48.0}
{"epoch": 18, "training_loss": 0.6980116510391235, "training_acc": 49.0, "val_loss": 0.693297655582428, "val_acc": 52.0}
{"epoch": 19, "training_loss": 0.695168628692627, "training_acc": 53.0, "val_loss": 0.692360270023346, "val_acc": 52.0}
{"epoch": 20, "training_loss": 0.7532512187957764, "training_acc": 43.0, "val_loss": 0.7010158967971801, "val_acc": 48.0}
{"epoch": 21, "training_loss": 0.738218367099762, "training_acc": 51.0, "val_loss": 0.7377680444717407, "val_acc": 52.0}
{"epoch": 22, "training_loss": 0.706063780784607, "training_acc": 53.0, "val_loss": 0.6983593964576721, "val_acc": 48.0}
{"epoch": 23, "training_loss": 0.70544842004776, "training_acc": 41.0, "val_loss": 0.6943787121772766, "val_acc": 48.0}
{"epoch": 24, "training_loss": 0.7072048425674439, "training_acc": 47.0, "val_loss": 0.6957213354110717, "val_acc": 48.0}
{"epoch": 25, "training_loss": 0.6915146017074585, "training_acc": 51.0, "val_loss": 0.7004144525527954, "val_acc": 52.0}
{"epoch": 26, "training_loss": 0.6948413324356079, "training_acc": 53.0, "val_loss": 0.6923468446731568, "val_acc": 52.0}
{"epoch": 27, "training_loss": 0.6947926807403565, "training_acc": 47.0, "val_loss": 0.6973766779899597, "val_acc": 48.0}
{"epoch": 28, "training_loss": 0.7036532115936279, "training_acc": 47.0, "val_loss": 0.6929419827461243, "val_acc": 52.0}
{"epoch": 29, "training_loss": 0.7111082029342651, "training_acc": 53.0, "val_loss": 0.7006942796707153, "val_acc": 52.0}
{"epoch": 30, "training_loss": 0.7256522798538207, "training_acc": 45.0, "val_loss": 0.708705837726593, "val_acc": 48.0}
{"epoch": 31, "training_loss": 0.6893974924087525, "training_acc": 57.0, "val_loss": 0.7112782406806946, "val_acc": 52.0}
{"epoch": 32, "training_loss": 0.7051120090484619, "training_acc": 53.0, "val_loss": 0.696749951839447, "val_acc": 52.0}
{"epoch": 33, "training_loss": 0.6946649527549744, "training_acc": 53.0, "val_loss": 0.692350537776947, "val_acc": 52.0}
{"epoch": 34, "training_loss": 0.7072363185882569, "training_acc": 41.0, "val_loss": 0.6952492237091065, "val_acc": 48.0}
{"epoch": 35, "training_loss": 0.7051522254943847, "training_acc": 53.0, "val_loss": 0.7050174331665039, "val_acc": 52.0}
{"epoch": 36, "training_loss": 0.698297872543335, "training_acc": 53.0, "val_loss": 0.6926337623596192, "val_acc": 52.0}
{"epoch": 37, "training_loss": 0.6938491916656494, "training_acc": 53.0, "val_loss": 0.6924552249908448, "val_acc": 52.0}
{"epoch": 38, "training_loss": 0.7041407918930054, "training_acc": 41.0, "val_loss": 0.6931433057785035, "val_acc": 52.0}
{"epoch": 39, "training_loss": 0.6953576231002807, "training_acc": 53.0, "val_loss": 0.699828519821167, "val_acc": 52.0}
{"epoch": 40, "training_loss": 0.7001039791107178, "training_acc": 53.0, "val_loss": 0.6972574806213379, "val_acc": 52.0}
{"epoch": 41, "training_loss": 0.6943687319755554, "training_acc": 51.0, "val_loss": 0.6928368401527405, "val_acc": 52.0}
{"epoch": 42, "training_loss": 0.6919500851631164, "training_acc": 53.0, "val_loss": 0.6940031385421753, "val_acc": 52.0}
{"epoch": 43, "training_loss": 0.6983101892471314, "training_acc": 53.0, "val_loss": 0.7049102401733398, "val_acc": 52.0}
{"epoch": 44, "training_loss": 0.6931064391136169, "training_acc": 53.0, "val_loss": 0.6923755645751953, "val_acc": 52.0}
{"epoch": 45, "training_loss": 0.6928598761558533, "training_acc": 53.0, "val_loss": 0.6924429821968079, "val_acc": 52.0}
