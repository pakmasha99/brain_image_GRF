"main_modify.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option BT_org --learning_rate 5e-5 --batch_size 16 --weight_decay 5e-2 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 0.692737340927124, "training_acc": 52.0, "val_loss": 0.6898539853096008, "val_acc": 56.0}
{"epoch": 1, "training_loss": 0.6922902870178222, "training_acc": 52.0, "val_loss": 0.6893325686454773, "val_acc": 56.0}
{"epoch": 2, "training_loss": 0.6928574085235596, "training_acc": 52.0, "val_loss": 0.6887873816490173, "val_acc": 56.0}
{"epoch": 3, "training_loss": 0.6929839468002319, "training_acc": 52.0, "val_loss": 0.6868632698059082, "val_acc": 56.0}
{"epoch": 4, "training_loss": 0.6928607106208802, "training_acc": 52.0, "val_loss": 0.6879467821121216, "val_acc": 56.0}
{"epoch": 5, "training_loss": 0.6922768640518189, "training_acc": 52.0, "val_loss": 0.6874220967292786, "val_acc": 56.0}
{"epoch": 6, "training_loss": 0.6920928287506104, "training_acc": 52.0, "val_loss": 0.688168330192566, "val_acc": 56.0}
{"epoch": 7, "training_loss": 0.692590959072113, "training_acc": 52.0, "val_loss": 0.6894787788391114, "val_acc": 56.0}
{"epoch": 8, "training_loss": 0.6926036310195923, "training_acc": 52.0, "val_loss": 0.6872167229652405, "val_acc": 56.0}
{"epoch": 9, "training_loss": 0.691994264125824, "training_acc": 52.0, "val_loss": 0.6886848258972168, "val_acc": 56.0}
{"epoch": 10, "training_loss": 0.6916533517837524, "training_acc": 52.0, "val_loss": 0.6897615575790406, "val_acc": 56.0}
{"epoch": 11, "training_loss": 0.6908352708816529, "training_acc": 52.0, "val_loss": 0.687105143070221, "val_acc": 56.0}
{"epoch": 12, "training_loss": 0.6957503938674927, "training_acc": 52.0, "val_loss": 0.6860048413276673, "val_acc": 56.0}
{"epoch": 13, "training_loss": 0.6935071992874146, "training_acc": 52.0, "val_loss": 0.687849268913269, "val_acc": 56.0}
{"epoch": 14, "training_loss": 0.6922281169891358, "training_acc": 52.0, "val_loss": 0.6871359419822692, "val_acc": 56.0}
{"epoch": 15, "training_loss": 0.6924604058265686, "training_acc": 52.0, "val_loss": 0.687646381855011, "val_acc": 56.0}
{"epoch": 16, "training_loss": 0.694274685382843, "training_acc": 52.0, "val_loss": 0.6861052322387695, "val_acc": 56.0}
{"epoch": 17, "training_loss": 0.692507746219635, "training_acc": 52.0, "val_loss": 0.689688322544098, "val_acc": 56.0}
{"epoch": 18, "training_loss": 0.6922801113128663, "training_acc": 52.0, "val_loss": 0.6923646926879883, "val_acc": 60.0}
{"epoch": 19, "training_loss": 0.6940617895126343, "training_acc": 44.0, "val_loss": 0.6920521187782288, "val_acc": 60.0}
{"epoch": 20, "training_loss": 0.6924748492240905, "training_acc": 52.0, "val_loss": 0.6875440406799317, "val_acc": 56.0}
{"epoch": 21, "training_loss": 0.6922056150436401, "training_acc": 52.0, "val_loss": 0.689134635925293, "val_acc": 56.0}
{"epoch": 22, "training_loss": 0.6934319257736206, "training_acc": 52.0, "val_loss": 0.6878523778915405, "val_acc": 56.0}
{"epoch": 23, "training_loss": 0.6914172291755676, "training_acc": 52.0, "val_loss": 0.6892585802078247, "val_acc": 56.0}
{"epoch": 24, "training_loss": 0.6935505199432374, "training_acc": 52.0, "val_loss": 0.6859155869483948, "val_acc": 56.0}
{"epoch": 25, "training_loss": 0.6913692355155945, "training_acc": 52.0, "val_loss": 0.6884849810600281, "val_acc": 56.0}
{"epoch": 26, "training_loss": 0.693609402179718, "training_acc": 52.0, "val_loss": 0.6875993871688842, "val_acc": 56.0}
{"epoch": 27, "training_loss": 0.6909442734718323, "training_acc": 52.0, "val_loss": 0.6896599221229553, "val_acc": 56.0}
{"epoch": 28, "training_loss": 0.6926906847953797, "training_acc": 52.0, "val_loss": 0.6890077137947083, "val_acc": 56.0}
{"epoch": 29, "training_loss": 0.6908711767196656, "training_acc": 52.0, "val_loss": 0.6855772852897644, "val_acc": 56.0}
{"epoch": 30, "training_loss": 0.6951577138900756, "training_acc": 52.0, "val_loss": 0.6838805341720581, "val_acc": 56.0}
{"epoch": 31, "training_loss": 0.6949205732345581, "training_acc": 52.0, "val_loss": 0.6838562750816345, "val_acc": 56.0}
{"epoch": 32, "training_loss": 0.6945902347564697, "training_acc": 52.0, "val_loss": 0.6849676394462585, "val_acc": 56.0}
{"epoch": 33, "training_loss": 0.6945695781707764, "training_acc": 52.0, "val_loss": 0.6858765006065368, "val_acc": 56.0}
{"epoch": 34, "training_loss": 0.6922408843040466, "training_acc": 52.0, "val_loss": 0.688950264453888, "val_acc": 56.0}
{"epoch": 35, "training_loss": 0.6922676229476928, "training_acc": 54.0, "val_loss": 0.6924091053009033, "val_acc": 48.0}
{"epoch": 36, "training_loss": 0.692178750038147, "training_acc": 48.0, "val_loss": 0.6879864454269409, "val_acc": 56.0}
{"epoch": 37, "training_loss": 0.6917031335830689, "training_acc": 52.0, "val_loss": 0.685688452720642, "val_acc": 56.0}
{"epoch": 38, "training_loss": 0.6932889699935914, "training_acc": 52.0, "val_loss": 0.6869042897224427, "val_acc": 56.0}
{"epoch": 39, "training_loss": 0.69142080783844, "training_acc": 52.0, "val_loss": 0.6882165956497193, "val_acc": 56.0}
{"epoch": 40, "training_loss": 0.6935984516143798, "training_acc": 58.0, "val_loss": 0.691131489276886, "val_acc": 56.0}
{"epoch": 41, "training_loss": 0.6913162064552307, "training_acc": 52.0, "val_loss": 0.6874956440925598, "val_acc": 56.0}
{"epoch": 42, "training_loss": 0.6929878306388855, "training_acc": 52.0, "val_loss": 0.6869224619865417, "val_acc": 56.0}
{"epoch": 43, "training_loss": 0.692547755241394, "training_acc": 52.0, "val_loss": 0.6869847059249878, "val_acc": 56.0}
{"epoch": 44, "training_loss": 0.6939046716690064, "training_acc": 47.0, "val_loss": 0.6922046995162964, "val_acc": 52.0}
{"epoch": 45, "training_loss": 0.6923499441146851, "training_acc": 49.0, "val_loss": 0.6897377872467041, "val_acc": 56.0}
{"epoch": 46, "training_loss": 0.6916535782814026, "training_acc": 52.0, "val_loss": 0.6875413370132446, "val_acc": 56.0}
{"epoch": 47, "training_loss": 0.6917720413208008, "training_acc": 52.0, "val_loss": 0.685936439037323, "val_acc": 56.0}
{"epoch": 48, "training_loss": 0.6923234033584594, "training_acc": 52.0, "val_loss": 0.6852934432029724, "val_acc": 56.0}
{"epoch": 49, "training_loss": 0.6900605797767639, "training_acc": 52.0, "val_loss": 0.6878106665611267, "val_acc": 56.0}
{"epoch": 50, "training_loss": 0.6927323842048645, "training_acc": 55.0, "val_loss": 0.6930743002891541, "val_acc": 44.0}
