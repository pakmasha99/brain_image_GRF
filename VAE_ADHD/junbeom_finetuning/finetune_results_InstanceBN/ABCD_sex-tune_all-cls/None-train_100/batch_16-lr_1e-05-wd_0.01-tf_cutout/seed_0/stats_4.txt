"main_modify.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option BT_org --learning_rate 1e-5 --batch_size 16 --weight_decay 1e-2 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 0.6917892980575562, "training_acc": 53.0, "val_loss": 0.6923988509178162, "val_acc": 52.0}
{"epoch": 1, "training_loss": 0.6937114810943603, "training_acc": 53.0, "val_loss": 0.692196958065033, "val_acc": 52.0}
{"epoch": 2, "training_loss": 0.6910817670822144, "training_acc": 53.0, "val_loss": 0.6919845962524414, "val_acc": 52.0}
{"epoch": 3, "training_loss": 0.6909684181213379, "training_acc": 53.0, "val_loss": 0.6921366620063781, "val_acc": 52.0}
{"epoch": 4, "training_loss": 0.6906014060974122, "training_acc": 53.0, "val_loss": 0.6925250601768493, "val_acc": 52.0}
{"epoch": 5, "training_loss": 0.6897574520111084, "training_acc": 53.0, "val_loss": 0.6926625394821166, "val_acc": 52.0}
{"epoch": 6, "training_loss": 0.6901716089248657, "training_acc": 53.0, "val_loss": 0.6927540898323059, "val_acc": 52.0}
{"epoch": 7, "training_loss": 0.6908805274963379, "training_acc": 53.0, "val_loss": 0.693054506778717, "val_acc": 52.0}
{"epoch": 8, "training_loss": 0.6901440286636352, "training_acc": 53.0, "val_loss": 0.6925918960571289, "val_acc": 52.0}
{"epoch": 9, "training_loss": 0.6889170002937317, "training_acc": 53.0, "val_loss": 0.6925281620025635, "val_acc": 52.0}
{"epoch": 10, "training_loss": 0.6889717483520508, "training_acc": 53.0, "val_loss": 0.6925002002716064, "val_acc": 52.0}
{"epoch": 11, "training_loss": 0.6881951260566711, "training_acc": 53.0, "val_loss": 0.6925177073478699, "val_acc": 52.0}
{"epoch": 12, "training_loss": 0.6878158044815064, "training_acc": 53.0, "val_loss": 0.6925285530090332, "val_acc": 52.0}
{"epoch": 13, "training_loss": 0.6874004888534546, "training_acc": 53.0, "val_loss": 0.6924110245704651, "val_acc": 52.0}
{"epoch": 14, "training_loss": 0.686902220249176, "training_acc": 53.0, "val_loss": 0.6923858428001404, "val_acc": 52.0}
{"epoch": 15, "training_loss": 0.6875823783874512, "training_acc": 53.0, "val_loss": 0.6924292612075805, "val_acc": 52.0}
{"epoch": 16, "training_loss": 0.687323522567749, "training_acc": 53.0, "val_loss": 0.69235267162323, "val_acc": 52.0}
{"epoch": 17, "training_loss": 0.6860153532028198, "training_acc": 53.0, "val_loss": 0.6922033500671386, "val_acc": 52.0}
{"epoch": 18, "training_loss": 0.6866556119918823, "training_acc": 53.0, "val_loss": 0.6919103240966797, "val_acc": 52.0}
{"epoch": 19, "training_loss": 0.6871901655197143, "training_acc": 53.0, "val_loss": 0.6926718640327454, "val_acc": 52.0}
{"epoch": 20, "training_loss": 0.6863127422332763, "training_acc": 53.0, "val_loss": 0.6928128361701965, "val_acc": 52.0}
{"epoch": 21, "training_loss": 0.6866799736022949, "training_acc": 53.0, "val_loss": 0.6934447121620179, "val_acc": 52.0}
{"epoch": 22, "training_loss": 0.6862343311309814, "training_acc": 53.0, "val_loss": 0.6927559995651245, "val_acc": 52.0}
{"epoch": 23, "training_loss": 0.6852213144302368, "training_acc": 53.0, "val_loss": 0.6921359181404114, "val_acc": 52.0}
{"epoch": 24, "training_loss": 0.6847982931137085, "training_acc": 53.0, "val_loss": 0.692278287410736, "val_acc": 52.0}
{"epoch": 25, "training_loss": 0.6872662782669068, "training_acc": 53.0, "val_loss": 0.693022403717041, "val_acc": 52.0}
{"epoch": 26, "training_loss": 0.6857655382156372, "training_acc": 53.0, "val_loss": 0.6930741310119629, "val_acc": 52.0}
{"epoch": 27, "training_loss": 0.6853100037574769, "training_acc": 53.0, "val_loss": 0.692668080329895, "val_acc": 52.0}
{"epoch": 28, "training_loss": 0.6847412586212158, "training_acc": 53.0, "val_loss": 0.6933666467666626, "val_acc": 52.0}
{"epoch": 29, "training_loss": 0.6836622166633606, "training_acc": 53.0, "val_loss": 0.6923582458496094, "val_acc": 52.0}
{"epoch": 30, "training_loss": 0.6847573137283325, "training_acc": 53.0, "val_loss": 0.6926769685745239, "val_acc": 52.0}
{"epoch": 31, "training_loss": 0.6832158374786377, "training_acc": 53.0, "val_loss": 0.6930975818634033, "val_acc": 52.0}
{"epoch": 32, "training_loss": 0.6845606660842896, "training_acc": 53.0, "val_loss": 0.6922187447547913, "val_acc": 52.0}
{"epoch": 33, "training_loss": 0.6835200643539429, "training_acc": 53.0, "val_loss": 0.6915198588371276, "val_acc": 52.0}
{"epoch": 34, "training_loss": 0.6826966094970703, "training_acc": 53.0, "val_loss": 0.6919341301918029, "val_acc": 52.0}
{"epoch": 35, "training_loss": 0.682379605770111, "training_acc": 53.0, "val_loss": 0.69185293674469, "val_acc": 52.0}
{"epoch": 36, "training_loss": 0.6826935243606568, "training_acc": 54.0, "val_loss": 0.6916247415542602, "val_acc": 52.0}
{"epoch": 37, "training_loss": 0.6829227423667907, "training_acc": 54.0, "val_loss": 0.6916292572021484, "val_acc": 52.0}
{"epoch": 38, "training_loss": 0.6815235948562622, "training_acc": 53.0, "val_loss": 0.6914175033569336, "val_acc": 52.0}
{"epoch": 39, "training_loss": 0.6811975955963134, "training_acc": 53.0, "val_loss": 0.692055504322052, "val_acc": 52.0}
{"epoch": 40, "training_loss": 0.6814140558242798, "training_acc": 53.0, "val_loss": 0.6920336580276489, "val_acc": 52.0}
{"epoch": 41, "training_loss": 0.6799499702453613, "training_acc": 53.0, "val_loss": 0.6919387078285217, "val_acc": 52.0}
{"epoch": 42, "training_loss": 0.6812956953048706, "training_acc": 53.0, "val_loss": 0.6918528580665588, "val_acc": 52.0}
{"epoch": 43, "training_loss": 0.6837545871734619, "training_acc": 53.0, "val_loss": 0.6937202453613281, "val_acc": 52.0}
{"epoch": 44, "training_loss": 0.6814158725738525, "training_acc": 53.0, "val_loss": 0.6923480296134948, "val_acc": 52.0}
{"epoch": 45, "training_loss": 0.6805845761299133, "training_acc": 53.0, "val_loss": 0.6914562678337097, "val_acc": 52.0}
{"epoch": 46, "training_loss": 0.6793895697593689, "training_acc": 53.0, "val_loss": 0.6915833592414856, "val_acc": 52.0}
{"epoch": 47, "training_loss": 0.6814654874801636, "training_acc": 53.0, "val_loss": 0.6916471910476685, "val_acc": 52.0}
{"epoch": 48, "training_loss": 0.6792281484603881, "training_acc": 54.0, "val_loss": 0.6921539664268493, "val_acc": 52.0}
{"epoch": 49, "training_loss": 0.6794210958480835, "training_acc": 53.0, "val_loss": 0.6918999409675598, "val_acc": 52.0}
{"epoch": 50, "training_loss": 0.6781497025489807, "training_acc": 54.0, "val_loss": 0.6917627191543579, "val_acc": 52.0}
{"epoch": 51, "training_loss": 0.6773696660995483, "training_acc": 53.0, "val_loss": 0.6920293402671814, "val_acc": 52.0}
{"epoch": 52, "training_loss": 0.6786444330215454, "training_acc": 54.0, "val_loss": 0.6913282203674317, "val_acc": 52.0}
{"epoch": 53, "training_loss": 0.6751661920547485, "training_acc": 53.0, "val_loss": 0.6923398542404174, "val_acc": 52.0}
{"epoch": 54, "training_loss": 0.6793979215621948, "training_acc": 53.0, "val_loss": 0.690956757068634, "val_acc": 52.0}
{"epoch": 55, "training_loss": 0.6775752449035645, "training_acc": 53.0, "val_loss": 0.6912915349006653, "val_acc": 52.0}
{"epoch": 56, "training_loss": 0.6759633278846741, "training_acc": 53.0, "val_loss": 0.691712760925293, "val_acc": 52.0}
{"epoch": 57, "training_loss": 0.676497859954834, "training_acc": 53.0, "val_loss": 0.6914491009712219, "val_acc": 52.0}
{"epoch": 58, "training_loss": 0.677646210193634, "training_acc": 53.0, "val_loss": 0.6920596671104431, "val_acc": 52.0}
{"epoch": 59, "training_loss": 0.6787651133537292, "training_acc": 60.0, "val_loss": 0.6903539681434632, "val_acc": 52.0}
{"epoch": 60, "training_loss": 0.6759049677848816, "training_acc": 64.0, "val_loss": 0.6912631273269654, "val_acc": 52.0}
{"epoch": 61, "training_loss": 0.6776662969589233, "training_acc": 54.0, "val_loss": 0.6918356442451477, "val_acc": 52.0}
{"epoch": 62, "training_loss": 0.6755560684204102, "training_acc": 55.0, "val_loss": 0.6915833687782288, "val_acc": 52.0}
{"epoch": 63, "training_loss": 0.6747229313850402, "training_acc": 54.0, "val_loss": 0.691764931678772, "val_acc": 52.0}
{"epoch": 64, "training_loss": 0.6735119533538818, "training_acc": 53.0, "val_loss": 0.6929084062576294, "val_acc": 52.0}
{"epoch": 65, "training_loss": 0.6791227269172668, "training_acc": 53.0, "val_loss": 0.694172921180725, "val_acc": 52.0}
{"epoch": 66, "training_loss": 0.6741407489776612, "training_acc": 53.0, "val_loss": 0.6911849188804626, "val_acc": 52.0}
{"epoch": 67, "training_loss": 0.6773570013046265, "training_acc": 58.0, "val_loss": 0.691793327331543, "val_acc": 48.0}
{"epoch": 68, "training_loss": 0.6776922941207886, "training_acc": 58.0, "val_loss": 0.6930069017410279, "val_acc": 52.0}
{"epoch": 69, "training_loss": 0.6743580794334412, "training_acc": 54.0, "val_loss": 0.6922843194007874, "val_acc": 56.0}
{"epoch": 70, "training_loss": 0.6743895149230957, "training_acc": 79.0, "val_loss": 0.6925765228271484, "val_acc": 48.0}
{"epoch": 71, "training_loss": 0.6731783080101014, "training_acc": 55.0, "val_loss": 0.6936594843864441, "val_acc": 52.0}
{"epoch": 72, "training_loss": 0.6760409235954284, "training_acc": 53.0, "val_loss": 0.6941676878929138, "val_acc": 52.0}
{"epoch": 73, "training_loss": 0.6733029389381409, "training_acc": 53.0, "val_loss": 0.6930304312705994, "val_acc": 52.0}
{"epoch": 74, "training_loss": 0.6718032574653625, "training_acc": 55.0, "val_loss": 0.6920718502998352, "val_acc": 48.0}
{"epoch": 75, "training_loss": 0.6723947548866271, "training_acc": 60.0, "val_loss": 0.6919869947433471, "val_acc": 52.0}
{"epoch": 76, "training_loss": 0.6706602191925048, "training_acc": 67.0, "val_loss": 0.6918219709396363, "val_acc": 56.0}
{"epoch": 77, "training_loss": 0.6728472375869751, "training_acc": 69.0, "val_loss": 0.6920953989028931, "val_acc": 52.0}
{"epoch": 78, "training_loss": 0.6710607767105102, "training_acc": 72.0, "val_loss": 0.6923809909820556, "val_acc": 56.0}
