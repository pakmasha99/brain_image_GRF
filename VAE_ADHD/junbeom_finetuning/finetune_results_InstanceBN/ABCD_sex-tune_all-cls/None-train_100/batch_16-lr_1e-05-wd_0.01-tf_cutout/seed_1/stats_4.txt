"main_modify.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 1 --task ABCD_sex --input_option BT_org --learning_rate 1e-5 --batch_size 16 --weight_decay 1e-2 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 0.6975606155395507, "training_acc": 48.0, "val_loss": 0.7014623737335205, "val_acc": 44.0}
{"epoch": 1, "training_loss": 0.6966991066932678, "training_acc": 48.0, "val_loss": 0.6979906582832336, "val_acc": 44.0}
{"epoch": 2, "training_loss": 0.6948650026321411, "training_acc": 48.0, "val_loss": 0.694826385974884, "val_acc": 44.0}
{"epoch": 3, "training_loss": 0.6930241918563843, "training_acc": 48.0, "val_loss": 0.6929873323440552, "val_acc": 56.0}
{"epoch": 4, "training_loss": 0.6926891255378723, "training_acc": 52.0, "val_loss": 0.692124137878418, "val_acc": 60.0}
{"epoch": 5, "training_loss": 0.691745080947876, "training_acc": 54.0, "val_loss": 0.6908501291275024, "val_acc": 48.0}
{"epoch": 6, "training_loss": 0.6898490524291992, "training_acc": 60.0, "val_loss": 0.6896889615058899, "val_acc": 56.0}
{"epoch": 7, "training_loss": 0.691832799911499, "training_acc": 52.0, "val_loss": 0.6878857088088989, "val_acc": 56.0}
{"epoch": 8, "training_loss": 0.6896222257614135, "training_acc": 52.0, "val_loss": 0.6889773178100586, "val_acc": 56.0}
{"epoch": 9, "training_loss": 0.6897601699829101, "training_acc": 52.0, "val_loss": 0.688812952041626, "val_acc": 56.0}
{"epoch": 10, "training_loss": 0.6892006397247314, "training_acc": 52.0, "val_loss": 0.688626606464386, "val_acc": 56.0}
{"epoch": 11, "training_loss": 0.6898184609413147, "training_acc": 53.0, "val_loss": 0.6890085625648499, "val_acc": 56.0}
{"epoch": 12, "training_loss": 0.688891966342926, "training_acc": 52.0, "val_loss": 0.68747478723526, "val_acc": 56.0}
{"epoch": 13, "training_loss": 0.68915296792984, "training_acc": 52.0, "val_loss": 0.6871477460861206, "val_acc": 56.0}
{"epoch": 14, "training_loss": 0.6894697523117066, "training_acc": 54.0, "val_loss": 0.6882812428474426, "val_acc": 56.0}
{"epoch": 15, "training_loss": 0.6870059204101563, "training_acc": 54.0, "val_loss": 0.6866434860229492, "val_acc": 56.0}
{"epoch": 16, "training_loss": 0.6883837461471558, "training_acc": 52.0, "val_loss": 0.6877596211433411, "val_acc": 56.0}
{"epoch": 17, "training_loss": 0.6870699596405029, "training_acc": 53.0, "val_loss": 0.6885612845420838, "val_acc": 56.0}
{"epoch": 18, "training_loss": 0.6888678550720215, "training_acc": 59.0, "val_loss": 0.6940072917938233, "val_acc": 52.0}
{"epoch": 19, "training_loss": 0.6886284589767456, "training_acc": 60.0, "val_loss": 0.690743145942688, "val_acc": 60.0}
{"epoch": 20, "training_loss": 0.6872751426696777, "training_acc": 65.0, "val_loss": 0.6906523728370666, "val_acc": 60.0}
{"epoch": 21, "training_loss": 0.6867004871368408, "training_acc": 63.0, "val_loss": 0.6901845383644104, "val_acc": 60.0}
{"epoch": 22, "training_loss": 0.6879063844680786, "training_acc": 58.0, "val_loss": 0.6962762308120728, "val_acc": 40.0}
{"epoch": 23, "training_loss": 0.6939025926589966, "training_acc": 44.0, "val_loss": 0.6888130140304566, "val_acc": 56.0}
{"epoch": 24, "training_loss": 0.6872299575805664, "training_acc": 60.0, "val_loss": 0.6916626405715942, "val_acc": 60.0}
{"epoch": 25, "training_loss": 0.6875860571861268, "training_acc": 56.0, "val_loss": 0.6892880845069885, "val_acc": 52.0}
{"epoch": 26, "training_loss": 0.6863600921630859, "training_acc": 59.0, "val_loss": 0.6942865681648255, "val_acc": 52.0}
{"epoch": 27, "training_loss": 0.6870372986793518, "training_acc": 60.0, "val_loss": 0.6923675584793091, "val_acc": 56.0}
{"epoch": 28, "training_loss": 0.6894566869735718, "training_acc": 55.0, "val_loss": 0.6874011039733887, "val_acc": 56.0}
{"epoch": 29, "training_loss": 0.6871224498748779, "training_acc": 54.0, "val_loss": 0.6877741646766663, "val_acc": 56.0}
{"epoch": 30, "training_loss": 0.6855318260192871, "training_acc": 54.0, "val_loss": 0.6865776801109313, "val_acc": 56.0}
{"epoch": 31, "training_loss": 0.685092830657959, "training_acc": 54.0, "val_loss": 0.6870771718025207, "val_acc": 56.0}
{"epoch": 32, "training_loss": 0.6839907026290893, "training_acc": 59.0, "val_loss": 0.6900983738899231, "val_acc": 52.0}
{"epoch": 33, "training_loss": 0.6861844778060913, "training_acc": 65.0, "val_loss": 0.692590172290802, "val_acc": 56.0}
{"epoch": 34, "training_loss": 0.6854505872726441, "training_acc": 66.0, "val_loss": 0.6880136895179748, "val_acc": 60.0}
{"epoch": 35, "training_loss": 0.6862159538269043, "training_acc": 53.0, "val_loss": 0.6845936250686645, "val_acc": 56.0}
{"epoch": 36, "training_loss": 0.6846762132644654, "training_acc": 52.0, "val_loss": 0.6870238995552063, "val_acc": 56.0}
{"epoch": 37, "training_loss": 0.6894562673568726, "training_acc": 55.0, "val_loss": 0.6950452876091003, "val_acc": 52.0}
{"epoch": 38, "training_loss": 0.6885551071166992, "training_acc": 57.0, "val_loss": 0.6901859545707703, "val_acc": 56.0}
{"epoch": 39, "training_loss": 0.6847678375244141, "training_acc": 62.0, "val_loss": 0.6919907879829407, "val_acc": 60.0}
{"epoch": 40, "training_loss": 0.6848341846466064, "training_acc": 65.0, "val_loss": 0.691346685886383, "val_acc": 64.0}
{"epoch": 41, "training_loss": 0.6847078323364257, "training_acc": 61.0, "val_loss": 0.6899274492263794, "val_acc": 60.0}
{"epoch": 42, "training_loss": 0.6848353052139282, "training_acc": 57.0, "val_loss": 0.694055528640747, "val_acc": 56.0}
{"epoch": 43, "training_loss": 0.6842602396011352, "training_acc": 60.0, "val_loss": 0.6957172465324402, "val_acc": 48.0}
{"epoch": 44, "training_loss": 0.6841965961456299, "training_acc": 63.0, "val_loss": 0.6871779370307922, "val_acc": 56.0}
{"epoch": 45, "training_loss": 0.6843217754364014, "training_acc": 53.0, "val_loss": 0.6851039481163025, "val_acc": 56.0}
{"epoch": 46, "training_loss": 0.6855456614494324, "training_acc": 52.0, "val_loss": 0.6856671977043152, "val_acc": 56.0}
{"epoch": 47, "training_loss": 0.6834522056579589, "training_acc": 60.0, "val_loss": 0.6917042064666749, "val_acc": 64.0}
{"epoch": 48, "training_loss": 0.6828429007530212, "training_acc": 66.0, "val_loss": 0.6886172151565552, "val_acc": 56.0}
{"epoch": 49, "training_loss": 0.6810256218910218, "training_acc": 56.0, "val_loss": 0.682955093383789, "val_acc": 56.0}
{"epoch": 50, "training_loss": 0.6875670909881592, "training_acc": 52.0, "val_loss": 0.6831214547157287, "val_acc": 56.0}
{"epoch": 51, "training_loss": 0.6847827959060669, "training_acc": 53.0, "val_loss": 0.6890136933326722, "val_acc": 56.0}
{"epoch": 52, "training_loss": 0.6826765608787536, "training_acc": 64.0, "val_loss": 0.6904506587982178, "val_acc": 60.0}
{"epoch": 53, "training_loss": 0.683175368309021, "training_acc": 56.0, "val_loss": 0.6865015196800232, "val_acc": 60.0}
{"epoch": 54, "training_loss": 0.687001838684082, "training_acc": 60.0, "val_loss": 0.6952368879318237, "val_acc": 56.0}
{"epoch": 55, "training_loss": 0.6837377142906189, "training_acc": 59.0, "val_loss": 0.6854487109184265, "val_acc": 56.0}
{"epoch": 56, "training_loss": 0.6817201566696167, "training_acc": 60.0, "val_loss": 0.6919281721115113, "val_acc": 56.0}
{"epoch": 57, "training_loss": 0.6830333042144775, "training_acc": 60.0, "val_loss": 0.6872747373580933, "val_acc": 52.0}
{"epoch": 58, "training_loss": 0.6799065160751343, "training_acc": 65.0, "val_loss": 0.6922092151641845, "val_acc": 56.0}
{"epoch": 59, "training_loss": 0.682943058013916, "training_acc": 62.0, "val_loss": 0.6883192396163941, "val_acc": 64.0}
{"epoch": 60, "training_loss": 0.6799542355537415, "training_acc": 60.0, "val_loss": 0.6986297559738159, "val_acc": 44.0}
{"epoch": 61, "training_loss": 0.6838853096961975, "training_acc": 56.0, "val_loss": 0.698693060874939, "val_acc": 40.0}
{"epoch": 62, "training_loss": 0.6813691520690918, "training_acc": 61.0, "val_loss": 0.6854453253746032, "val_acc": 60.0}
{"epoch": 63, "training_loss": 0.6825639843940735, "training_acc": 58.0, "val_loss": 0.6866552424430847, "val_acc": 60.0}
{"epoch": 64, "training_loss": 0.6798433923721313, "training_acc": 62.0, "val_loss": 0.6942488527297974, "val_acc": 56.0}
{"epoch": 65, "training_loss": 0.6799536085128784, "training_acc": 62.0, "val_loss": 0.685833466053009, "val_acc": 56.0}
{"epoch": 66, "training_loss": 0.6834417963027954, "training_acc": 57.0, "val_loss": 0.6837378239631653, "val_acc": 60.0}
{"epoch": 67, "training_loss": 0.6809592938423157, "training_acc": 57.0, "val_loss": 0.6860719561576843, "val_acc": 56.0}
{"epoch": 68, "training_loss": 0.6800482821464539, "training_acc": 61.0, "val_loss": 0.6877866554260254, "val_acc": 64.0}
