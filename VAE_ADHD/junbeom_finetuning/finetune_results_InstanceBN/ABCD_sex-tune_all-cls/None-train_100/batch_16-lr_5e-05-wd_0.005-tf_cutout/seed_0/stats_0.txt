"main_modify.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option BT_org --learning_rate 5e-5 --batch_size 16 --weight_decay 5e-3 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 0.6928702831268311, "training_acc": 52.0, "val_loss": 0.6892259097099305, "val_acc": 56.0}
{"epoch": 1, "training_loss": 0.693539457321167, "training_acc": 52.0, "val_loss": 0.6886602902412414, "val_acc": 56.0}
{"epoch": 2, "training_loss": 0.6938457536697388, "training_acc": 52.0, "val_loss": 0.687440721988678, "val_acc": 56.0}
{"epoch": 3, "training_loss": 0.6937928342819214, "training_acc": 52.0, "val_loss": 0.686623272895813, "val_acc": 56.0}
{"epoch": 4, "training_loss": 0.6948400926589966, "training_acc": 52.0, "val_loss": 0.6885541987419128, "val_acc": 56.0}
{"epoch": 5, "training_loss": 0.6931772708892823, "training_acc": 52.0, "val_loss": 0.6873031234741211, "val_acc": 56.0}
{"epoch": 6, "training_loss": 0.6932046556472778, "training_acc": 52.0, "val_loss": 0.6882681369781494, "val_acc": 56.0}
{"epoch": 7, "training_loss": 0.6938150095939636, "training_acc": 52.0, "val_loss": 0.6897118425369263, "val_acc": 56.0}
{"epoch": 8, "training_loss": 0.6949120759963989, "training_acc": 52.0, "val_loss": 0.6875809812545777, "val_acc": 56.0}
{"epoch": 9, "training_loss": 0.693879885673523, "training_acc": 52.0, "val_loss": 0.6905358552932739, "val_acc": 56.0}
{"epoch": 10, "training_loss": 0.6931727313995362, "training_acc": 48.0, "val_loss": 0.6923256850242615, "val_acc": 52.0}
{"epoch": 11, "training_loss": 0.6914308404922486, "training_acc": 53.0, "val_loss": 0.6868610072135926, "val_acc": 56.0}
{"epoch": 12, "training_loss": 0.6983285617828369, "training_acc": 52.0, "val_loss": 0.6862426209449768, "val_acc": 56.0}
{"epoch": 13, "training_loss": 0.6952397489547729, "training_acc": 52.0, "val_loss": 0.6879589509963989, "val_acc": 56.0}
{"epoch": 14, "training_loss": 0.6931546401977539, "training_acc": 52.0, "val_loss": 0.6869575452804565, "val_acc": 56.0}
{"epoch": 15, "training_loss": 0.6934286832809449, "training_acc": 52.0, "val_loss": 0.6877785873413086, "val_acc": 56.0}
{"epoch": 16, "training_loss": 0.6954009199142456, "training_acc": 52.0, "val_loss": 0.6858507442474365, "val_acc": 56.0}
{"epoch": 17, "training_loss": 0.6931981110572815, "training_acc": 52.0, "val_loss": 0.6895077466964722, "val_acc": 56.0}
{"epoch": 18, "training_loss": 0.6924410438537598, "training_acc": 52.0, "val_loss": 0.6930583620071411, "val_acc": 48.0}
{"epoch": 19, "training_loss": 0.6954278206825256, "training_acc": 47.0, "val_loss": 0.6945572757720947, "val_acc": 44.0}
{"epoch": 20, "training_loss": 0.6922759294509888, "training_acc": 52.0, "val_loss": 0.6884558081626893, "val_acc": 56.0}
{"epoch": 21, "training_loss": 0.6921977877616883, "training_acc": 52.0, "val_loss": 0.6876419138908386, "val_acc": 56.0}
{"epoch": 22, "training_loss": 0.6941728067398071, "training_acc": 52.0, "val_loss": 0.6867431235313416, "val_acc": 56.0}
{"epoch": 23, "training_loss": 0.691532826423645, "training_acc": 52.0, "val_loss": 0.6893294167518615, "val_acc": 56.0}
{"epoch": 24, "training_loss": 0.693815929889679, "training_acc": 52.0, "val_loss": 0.6865254712104797, "val_acc": 56.0}
{"epoch": 25, "training_loss": 0.6917594575881958, "training_acc": 52.0, "val_loss": 0.6896361136436462, "val_acc": 56.0}
{"epoch": 26, "training_loss": 0.6946501970291138, "training_acc": 52.0, "val_loss": 0.6888732647895813, "val_acc": 56.0}
{"epoch": 27, "training_loss": 0.6919473099708557, "training_acc": 52.0, "val_loss": 0.690299904346466, "val_acc": 56.0}
{"epoch": 28, "training_loss": 0.6934376001358032, "training_acc": 52.0, "val_loss": 0.6887357306480407, "val_acc": 56.0}
{"epoch": 29, "training_loss": 0.6915692853927612, "training_acc": 52.0, "val_loss": 0.6854459834098816, "val_acc": 56.0}
{"epoch": 30, "training_loss": 0.6971829080581665, "training_acc": 52.0, "val_loss": 0.6848297047615052, "val_acc": 56.0}
{"epoch": 31, "training_loss": 0.696809709072113, "training_acc": 52.0, "val_loss": 0.6847975540161133, "val_acc": 56.0}
{"epoch": 32, "training_loss": 0.6952829647064209, "training_acc": 52.0, "val_loss": 0.6845539498329163, "val_acc": 56.0}
{"epoch": 33, "training_loss": 0.6951069545745849, "training_acc": 52.0, "val_loss": 0.6851070857048035, "val_acc": 56.0}
{"epoch": 34, "training_loss": 0.6920866632461548, "training_acc": 52.0, "val_loss": 0.6898331451416015, "val_acc": 56.0}
{"epoch": 35, "training_loss": 0.6932099390029908, "training_acc": 45.0, "val_loss": 0.6934623575210571, "val_acc": 48.0}
{"epoch": 36, "training_loss": 0.6925091290473938, "training_acc": 51.0, "val_loss": 0.6872667741775512, "val_acc": 56.0}
{"epoch": 37, "training_loss": 0.6927394604682923, "training_acc": 52.0, "val_loss": 0.6854760766029357, "val_acc": 56.0}
{"epoch": 38, "training_loss": 0.694491581916809, "training_acc": 52.0, "val_loss": 0.6871980285644531, "val_acc": 56.0}
{"epoch": 39, "training_loss": 0.6917234349250794, "training_acc": 52.0, "val_loss": 0.689287142753601, "val_acc": 56.0}
{"epoch": 40, "training_loss": 0.694470648765564, "training_acc": 43.0, "val_loss": 0.6911845088005066, "val_acc": 68.0}
{"epoch": 41, "training_loss": 0.6915859937667846, "training_acc": 56.0, "val_loss": 0.6872173738479614, "val_acc": 56.0}
{"epoch": 42, "training_loss": 0.693038067817688, "training_acc": 52.0, "val_loss": 0.686917929649353, "val_acc": 56.0}
{"epoch": 43, "training_loss": 0.6927634501457214, "training_acc": 52.0, "val_loss": 0.687186312675476, "val_acc": 56.0}
{"epoch": 44, "training_loss": 0.6936326026916504, "training_acc": 46.0, "val_loss": 0.6909669137001038, "val_acc": 56.0}
{"epoch": 45, "training_loss": 0.6920924758911133, "training_acc": 52.0, "val_loss": 0.6886235022544861, "val_acc": 56.0}
{"epoch": 46, "training_loss": 0.6921538734436035, "training_acc": 52.0, "val_loss": 0.6874566745758056, "val_acc": 56.0}
{"epoch": 47, "training_loss": 0.69251877784729, "training_acc": 52.0, "val_loss": 0.686453902721405, "val_acc": 56.0}
{"epoch": 48, "training_loss": 0.6924471187591553, "training_acc": 52.0, "val_loss": 0.6863293552398682, "val_acc": 56.0}
{"epoch": 49, "training_loss": 0.6902225422859192, "training_acc": 52.0, "val_loss": 0.689697687625885, "val_acc": 56.0}
{"epoch": 50, "training_loss": 0.6934080362319947, "training_acc": 48.0, "val_loss": 0.6947180795669555, "val_acc": 44.0}
{"epoch": 51, "training_loss": 0.6941489291191101, "training_acc": 48.0, "val_loss": 0.6948981833457947, "val_acc": 44.0}
