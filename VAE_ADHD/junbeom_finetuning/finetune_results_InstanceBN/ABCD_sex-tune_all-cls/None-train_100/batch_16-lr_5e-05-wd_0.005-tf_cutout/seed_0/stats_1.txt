"main_modify.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option BT_org --learning_rate 5e-5 --batch_size 16 --weight_decay 5e-3 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 0.7016520309448242, "training_acc": 47.0, "val_loss": 0.6964933848381043, "val_acc": 48.0}
{"epoch": 1, "training_loss": 0.7003345966339112, "training_acc": 41.0, "val_loss": 0.6929865431785583, "val_acc": 48.0}
{"epoch": 2, "training_loss": 0.6947253847122192, "training_acc": 42.0, "val_loss": 0.691976227760315, "val_acc": 52.0}
{"epoch": 3, "training_loss": 0.6940323877334594, "training_acc": 51.0, "val_loss": 0.6915394258499146, "val_acc": 52.0}
{"epoch": 4, "training_loss": 0.6919160103797912, "training_acc": 53.0, "val_loss": 0.6918808341026306, "val_acc": 52.0}
{"epoch": 5, "training_loss": 0.6937934446334839, "training_acc": 53.0, "val_loss": 0.6918696713447571, "val_acc": 52.0}
{"epoch": 6, "training_loss": 0.6923111009597779, "training_acc": 53.0, "val_loss": 0.6928359723091125, "val_acc": 52.0}
{"epoch": 7, "training_loss": 0.6954929089546203, "training_acc": 53.0, "val_loss": 0.6916404461860657, "val_acc": 52.0}
{"epoch": 8, "training_loss": 0.6910763740539551, "training_acc": 53.0, "val_loss": 0.6919964694976807, "val_acc": 52.0}
{"epoch": 9, "training_loss": 0.6980398297309875, "training_acc": 53.0, "val_loss": 0.6916586542129517, "val_acc": 52.0}
{"epoch": 10, "training_loss": 0.6937580132484436, "training_acc": 53.0, "val_loss": 0.6916153240203857, "val_acc": 52.0}
{"epoch": 11, "training_loss": 0.690756402015686, "training_acc": 53.0, "val_loss": 0.6925151181221009, "val_acc": 52.0}
{"epoch": 12, "training_loss": 0.6945071053504944, "training_acc": 43.0, "val_loss": 0.6922892379760742, "val_acc": 52.0}
{"epoch": 13, "training_loss": 0.6937267684936523, "training_acc": 53.0, "val_loss": 0.6927821660041809, "val_acc": 52.0}
{"epoch": 14, "training_loss": 0.6924178314208984, "training_acc": 53.0, "val_loss": 0.6927098917961121, "val_acc": 52.0}
{"epoch": 15, "training_loss": 0.6920066785812378, "training_acc": 53.0, "val_loss": 0.6925735139846801, "val_acc": 52.0}
{"epoch": 16, "training_loss": 0.6911530303955078, "training_acc": 53.0, "val_loss": 0.6928845906257629, "val_acc": 52.0}
{"epoch": 17, "training_loss": 0.6915081191062927, "training_acc": 53.0, "val_loss": 0.692958209514618, "val_acc": 52.0}
{"epoch": 18, "training_loss": 0.6910210371017456, "training_acc": 53.0, "val_loss": 0.694648745059967, "val_acc": 52.0}
{"epoch": 19, "training_loss": 0.6917079973220825, "training_acc": 53.0, "val_loss": 0.6922420620918274, "val_acc": 52.0}
{"epoch": 20, "training_loss": 0.6926758098602295, "training_acc": 53.0, "val_loss": 0.6914249300956726, "val_acc": 52.0}
{"epoch": 21, "training_loss": 0.6914929580688477, "training_acc": 53.0, "val_loss": 0.692931866645813, "val_acc": 52.0}
{"epoch": 22, "training_loss": 0.6914656591415406, "training_acc": 53.0, "val_loss": 0.6919515609741211, "val_acc": 52.0}
{"epoch": 23, "training_loss": 0.6920274066925048, "training_acc": 53.0, "val_loss": 0.6920107102394104, "val_acc": 52.0}
{"epoch": 24, "training_loss": 0.6915056014060974, "training_acc": 53.0, "val_loss": 0.6919275617599487, "val_acc": 52.0}
{"epoch": 25, "training_loss": 0.6924026656150818, "training_acc": 53.0, "val_loss": 0.6917972993850708, "val_acc": 52.0}
{"epoch": 26, "training_loss": 0.6920309829711914, "training_acc": 53.0, "val_loss": 0.6929730796813964, "val_acc": 52.0}
{"epoch": 27, "training_loss": 0.6940972518920898, "training_acc": 53.0, "val_loss": 0.6928345060348511, "val_acc": 52.0}
{"epoch": 28, "training_loss": 0.6947037982940674, "training_acc": 53.0, "val_loss": 0.6919219398498535, "val_acc": 52.0}
{"epoch": 29, "training_loss": 0.691906418800354, "training_acc": 53.0, "val_loss": 0.6927447175979614, "val_acc": 52.0}
{"epoch": 30, "training_loss": 0.6953999710083008, "training_acc": 53.0, "val_loss": 0.6918477869033813, "val_acc": 52.0}
{"epoch": 31, "training_loss": 0.6929039549827576, "training_acc": 53.0, "val_loss": 0.6920549011230469, "val_acc": 52.0}
{"epoch": 32, "training_loss": 0.692842423915863, "training_acc": 53.0, "val_loss": 0.6921419382095337, "val_acc": 52.0}
{"epoch": 33, "training_loss": 0.6915081405639648, "training_acc": 53.0, "val_loss": 0.6923891544342041, "val_acc": 52.0}
{"epoch": 34, "training_loss": 0.6924260115623474, "training_acc": 53.0, "val_loss": 0.692395784854889, "val_acc": 52.0}
{"epoch": 35, "training_loss": 0.6924844574928284, "training_acc": 53.0, "val_loss": 0.6915313601493835, "val_acc": 52.0}
{"epoch": 36, "training_loss": 0.6935803747177124, "training_acc": 53.0, "val_loss": 0.692359275817871, "val_acc": 52.0}
{"epoch": 37, "training_loss": 0.6976529264450073, "training_acc": 53.0, "val_loss": 0.6916308617591858, "val_acc": 52.0}
{"epoch": 38, "training_loss": 0.6921984648704529, "training_acc": 53.0, "val_loss": 0.6918355298042297, "val_acc": 52.0}
{"epoch": 39, "training_loss": 0.6922786688804626, "training_acc": 53.0, "val_loss": 0.6920581388473511, "val_acc": 52.0}
