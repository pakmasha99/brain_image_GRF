"main_modify.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option BT_org --learning_rate 1e-4 --batch_size 16 --weight_decay 1e-2 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 0.6972595906257629, "training_acc": 47.0, "val_loss": 0.6923810887336731, "val_acc": 52.0}
{"epoch": 1, "training_loss": 0.6949835872650146, "training_acc": 53.0, "val_loss": 0.692269127368927, "val_acc": 52.0}
{"epoch": 2, "training_loss": 0.6925590443611145, "training_acc": 53.0, "val_loss": 0.6924492526054382, "val_acc": 52.0}
{"epoch": 3, "training_loss": 0.6923685336112976, "training_acc": 53.0, "val_loss": 0.6925453996658325, "val_acc": 52.0}
{"epoch": 4, "training_loss": 0.6925575160980224, "training_acc": 53.0, "val_loss": 0.6929078602790832, "val_acc": 52.0}
{"epoch": 5, "training_loss": 0.6931988453865051, "training_acc": 53.0, "val_loss": 0.6926918125152588, "val_acc": 52.0}
{"epoch": 6, "training_loss": 0.6912620115280151, "training_acc": 53.0, "val_loss": 0.6926156044006347, "val_acc": 52.0}
{"epoch": 7, "training_loss": 0.7002941274642944, "training_acc": 38.0, "val_loss": 0.6924663186073303, "val_acc": 52.0}
{"epoch": 8, "training_loss": 0.6984129905700683, "training_acc": 53.0, "val_loss": 0.6933364534378051, "val_acc": 52.0}
{"epoch": 9, "training_loss": 0.6940154004096984, "training_acc": 53.0, "val_loss": 0.6929985404014587, "val_acc": 52.0}
{"epoch": 10, "training_loss": 0.6969530487060547, "training_acc": 43.0, "val_loss": 0.6925061964988708, "val_acc": 52.0}
{"epoch": 11, "training_loss": 0.6934121108055115, "training_acc": 53.0, "val_loss": 0.6935153532028199, "val_acc": 52.0}
{"epoch": 12, "training_loss": 0.6968679785728454, "training_acc": 53.0, "val_loss": 0.6939449024200439, "val_acc": 52.0}
{"epoch": 13, "training_loss": 0.6946034455299377, "training_acc": 53.0, "val_loss": 0.6937884259223938, "val_acc": 52.0}
{"epoch": 14, "training_loss": 0.6920819067955017, "training_acc": 53.0, "val_loss": 0.6925187635421753, "val_acc": 52.0}
{"epoch": 15, "training_loss": 0.6925774335861206, "training_acc": 53.0, "val_loss": 0.6933202791213989, "val_acc": 52.0}
{"epoch": 16, "training_loss": 0.699204547405243, "training_acc": 53.0, "val_loss": 0.6943744373321533, "val_acc": 52.0}
{"epoch": 17, "training_loss": 0.6923744106292724, "training_acc": 53.0, "val_loss": 0.6924143147468567, "val_acc": 52.0}
{"epoch": 18, "training_loss": 0.6916957664489746, "training_acc": 53.0, "val_loss": 0.6929385495185852, "val_acc": 52.0}
{"epoch": 19, "training_loss": 0.6921820545196533, "training_acc": 53.0, "val_loss": 0.693532555103302, "val_acc": 52.0}
{"epoch": 20, "training_loss": 0.6941171050071716, "training_acc": 53.0, "val_loss": 0.6920166850090027, "val_acc": 52.0}
{"epoch": 21, "training_loss": 0.692021005153656, "training_acc": 53.0, "val_loss": 0.6929198980331421, "val_acc": 52.0}
{"epoch": 22, "training_loss": 0.692537875175476, "training_acc": 53.0, "val_loss": 0.6945275402069092, "val_acc": 52.0}
{"epoch": 23, "training_loss": 0.6947883844375611, "training_acc": 53.0, "val_loss": 0.6946990156173706, "val_acc": 52.0}
{"epoch": 24, "training_loss": 0.6925072288513183, "training_acc": 53.0, "val_loss": 0.6948954439163209, "val_acc": 52.0}
{"epoch": 25, "training_loss": 0.6942721462249756, "training_acc": 53.0, "val_loss": 0.6935826516151429, "val_acc": 52.0}
{"epoch": 26, "training_loss": 0.6921223449707031, "training_acc": 53.0, "val_loss": 0.6925938367843628, "val_acc": 52.0}
{"epoch": 27, "training_loss": 0.6936223196983338, "training_acc": 53.0, "val_loss": 0.6930085444450378, "val_acc": 52.0}
{"epoch": 28, "training_loss": 0.6964748764038086, "training_acc": 53.0, "val_loss": 0.6923931670188904, "val_acc": 52.0}
{"epoch": 29, "training_loss": 0.693423194885254, "training_acc": 53.0, "val_loss": 0.6925190758705139, "val_acc": 52.0}
{"epoch": 30, "training_loss": 0.6933355379104614, "training_acc": 45.0, "val_loss": 0.6930481576919556, "val_acc": 60.0}
{"epoch": 31, "training_loss": 0.6979635500907898, "training_acc": 50.0, "val_loss": 0.6921134161949157, "val_acc": 52.0}
{"epoch": 32, "training_loss": 0.6930824542045593, "training_acc": 47.0, "val_loss": 0.6929102039337158, "val_acc": 52.0}
{"epoch": 33, "training_loss": 0.6922483801841736, "training_acc": 53.0, "val_loss": 0.6927652359008789, "val_acc": 52.0}
{"epoch": 34, "training_loss": 0.6941034126281739, "training_acc": 53.0, "val_loss": 0.6923775744438171, "val_acc": 52.0}
{"epoch": 35, "training_loss": 0.6933272528648377, "training_acc": 47.0, "val_loss": 0.6934985041618347, "val_acc": 48.0}
{"epoch": 36, "training_loss": 0.6922801017761231, "training_acc": 51.0, "val_loss": 0.6927655744552612, "val_acc": 52.0}
{"epoch": 37, "training_loss": 0.6914197683334351, "training_acc": 53.0, "val_loss": 0.692749092578888, "val_acc": 52.0}
{"epoch": 38, "training_loss": 0.6935961627960205, "training_acc": 53.0, "val_loss": 0.6925450372695923, "val_acc": 52.0}
{"epoch": 39, "training_loss": 0.6920517659187317, "training_acc": 53.0, "val_loss": 0.6941838455200195, "val_acc": 52.0}
