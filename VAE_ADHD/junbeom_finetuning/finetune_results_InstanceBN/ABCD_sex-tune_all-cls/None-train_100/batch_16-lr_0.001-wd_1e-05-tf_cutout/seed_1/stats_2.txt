"main_modify.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 1 --task ABCD_sex --input_option BT_org --learning_rate 1e-3 --batch_size 16 --weight_decay 1e-5 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 0.713442063331604, "training_acc": 53.0, "val_loss": 0.6958914613723755, "val_acc": 52.0}
{"epoch": 1, "training_loss": 0.6935105895996094, "training_acc": 53.0, "val_loss": 0.6981155729293823, "val_acc": 48.0}
{"epoch": 2, "training_loss": 0.6952001571655273, "training_acc": 47.0, "val_loss": 0.6939447140693664, "val_acc": 52.0}
{"epoch": 3, "training_loss": 0.6990367984771728, "training_acc": 53.0, "val_loss": 0.692921690940857, "val_acc": 52.0}
{"epoch": 4, "training_loss": 0.7043795299530029, "training_acc": 51.0, "val_loss": 0.6924581837654114, "val_acc": 52.0}
{"epoch": 5, "training_loss": 0.7186577773094177, "training_acc": 53.0, "val_loss": 0.6946467995643616, "val_acc": 52.0}
{"epoch": 6, "training_loss": 0.7271357083320618, "training_acc": 45.0, "val_loss": 0.7005892610549926, "val_acc": 48.0}
{"epoch": 7, "training_loss": 0.688681092262268, "training_acc": 53.0, "val_loss": 0.7019841074943542, "val_acc": 52.0}
{"epoch": 8, "training_loss": 0.6992268991470337, "training_acc": 53.0, "val_loss": 0.6928341722488404, "val_acc": 52.0}
{"epoch": 9, "training_loss": 0.6959831190109252, "training_acc": 51.0, "val_loss": 0.6936635637283325, "val_acc": 48.0}
{"epoch": 10, "training_loss": 0.6936275124549866, "training_acc": 47.0, "val_loss": 0.6933075380325318, "val_acc": 52.0}
{"epoch": 11, "training_loss": 0.692484130859375, "training_acc": 53.0, "val_loss": 0.6923833084106445, "val_acc": 52.0}
{"epoch": 12, "training_loss": 0.693242871761322, "training_acc": 53.0, "val_loss": 0.6923690915107727, "val_acc": 52.0}
{"epoch": 13, "training_loss": 0.6927476787567138, "training_acc": 53.0, "val_loss": 0.6937323546409607, "val_acc": 52.0}
{"epoch": 14, "training_loss": 0.695260751247406, "training_acc": 47.0, "val_loss": 0.6939367723464965, "val_acc": 48.0}
{"epoch": 15, "training_loss": 0.6942473936080933, "training_acc": 49.0, "val_loss": 0.6931786847114563, "val_acc": 52.0}
{"epoch": 16, "training_loss": 0.6991283559799194, "training_acc": 53.0, "val_loss": 0.7077940392494202, "val_acc": 52.0}
{"epoch": 17, "training_loss": 0.7041595935821533, "training_acc": 47.0, "val_loss": 0.6942699551582336, "val_acc": 48.0}
{"epoch": 18, "training_loss": 0.6977903699874878, "training_acc": 43.0, "val_loss": 0.6923677396774292, "val_acc": 52.0}
{"epoch": 19, "training_loss": 0.6923184680938721, "training_acc": 53.0, "val_loss": 0.6923891425132751, "val_acc": 52.0}
{"epoch": 20, "training_loss": 0.6935662269592285, "training_acc": 53.0, "val_loss": 0.6923561525344849, "val_acc": 52.0}
{"epoch": 21, "training_loss": 0.6940669822692871, "training_acc": 53.0, "val_loss": 0.6931772089004516, "val_acc": 52.0}
{"epoch": 22, "training_loss": 0.69342698097229, "training_acc": 53.0, "val_loss": 0.6950728273391724, "val_acc": 52.0}
{"epoch": 23, "training_loss": 0.7044039297103882, "training_acc": 53.0, "val_loss": 0.6955882239341736, "val_acc": 52.0}
{"epoch": 24, "training_loss": 0.712188675403595, "training_acc": 41.0, "val_loss": 0.6961433458328247, "val_acc": 48.0}
{"epoch": 25, "training_loss": 0.6897186136245728, "training_acc": 51.0, "val_loss": 0.7025991106033325, "val_acc": 52.0}
{"epoch": 26, "training_loss": 0.7074012565612793, "training_acc": 53.0, "val_loss": 0.7089957976341248, "val_acc": 52.0}
{"epoch": 27, "training_loss": 0.7029382276535034, "training_acc": 53.0, "val_loss": 0.696317732334137, "val_acc": 52.0}
{"epoch": 28, "training_loss": 0.6904074263572693, "training_acc": 53.0, "val_loss": 0.6977813768386841, "val_acc": 48.0}
{"epoch": 29, "training_loss": 0.7059652256965637, "training_acc": 47.0, "val_loss": 0.6966348886489868, "val_acc": 48.0}
{"epoch": 30, "training_loss": 0.7085009002685547, "training_acc": 43.0, "val_loss": 0.6950594305992126, "val_acc": 52.0}
{"epoch": 31, "training_loss": 0.6943772983551025, "training_acc": 53.0, "val_loss": 0.694966173171997, "val_acc": 52.0}
{"epoch": 32, "training_loss": 0.6989446496963501, "training_acc": 53.0, "val_loss": 0.7018811869621276, "val_acc": 52.0}
{"epoch": 33, "training_loss": 0.6992818999290467, "training_acc": 53.0, "val_loss": 0.6925425267219544, "val_acc": 52.0}
{"epoch": 34, "training_loss": 0.6987791514396667, "training_acc": 49.0, "val_loss": 0.6995217442512512, "val_acc": 48.0}
{"epoch": 35, "training_loss": 0.6952511644363404, "training_acc": 47.0, "val_loss": 0.6945895075798034, "val_acc": 52.0}
{"epoch": 36, "training_loss": 0.6978471469879151, "training_acc": 53.0, "val_loss": 0.6953329205513, "val_acc": 52.0}
{"epoch": 37, "training_loss": 0.701400465965271, "training_acc": 43.0, "val_loss": 0.6927614951133728, "val_acc": 52.0}
{"epoch": 38, "training_loss": 0.6913441729545593, "training_acc": 53.0, "val_loss": 0.693457486629486, "val_acc": 52.0}
{"epoch": 39, "training_loss": 0.7071256804466247, "training_acc": 53.0, "val_loss": 0.6979152441024781, "val_acc": 52.0}
