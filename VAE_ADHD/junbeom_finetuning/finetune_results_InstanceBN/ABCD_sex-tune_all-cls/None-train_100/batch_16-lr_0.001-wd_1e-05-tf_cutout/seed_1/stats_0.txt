"main_modify.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 1 --task ABCD_sex --input_option BT_org --learning_rate 1e-3 --batch_size 16 --weight_decay 1e-5 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 0.7146498537063599, "training_acc": 47.0, "val_loss": 0.7014040613174438, "val_acc": 52.0}
{"epoch": 1, "training_loss": 0.7128488826751709, "training_acc": 53.0, "val_loss": 0.7096817326545716, "val_acc": 52.0}
{"epoch": 2, "training_loss": 0.7054572749137878, "training_acc": 53.0, "val_loss": 0.695957465171814, "val_acc": 52.0}
{"epoch": 3, "training_loss": 0.7064929246902466, "training_acc": 41.0, "val_loss": 0.6927645087242127, "val_acc": 52.0}
{"epoch": 4, "training_loss": 0.6986153745651245, "training_acc": 45.0, "val_loss": 0.695181941986084, "val_acc": 52.0}
{"epoch": 5, "training_loss": 0.7113489866256714, "training_acc": 53.0, "val_loss": 0.7019193577766418, "val_acc": 52.0}
{"epoch": 6, "training_loss": 0.6993249011039734, "training_acc": 53.0, "val_loss": 0.6951140952110291, "val_acc": 48.0}
{"epoch": 7, "training_loss": 0.7040854215621948, "training_acc": 47.0, "val_loss": 0.6923619556427002, "val_acc": 52.0}
{"epoch": 8, "training_loss": 0.6931881427764892, "training_acc": 53.0, "val_loss": 0.6956842494010925, "val_acc": 52.0}
{"epoch": 9, "training_loss": 0.6973338174819946, "training_acc": 53.0, "val_loss": 0.6924364399909974, "val_acc": 52.0}
{"epoch": 10, "training_loss": 0.7079491138458252, "training_acc": 43.0, "val_loss": 0.6926164603233338, "val_acc": 52.0}
{"epoch": 11, "training_loss": 0.6927736806869507, "training_acc": 53.0, "val_loss": 0.6983283305168152, "val_acc": 52.0}
{"epoch": 12, "training_loss": 0.6987486600875854, "training_acc": 53.0, "val_loss": 0.6949847102165222, "val_acc": 52.0}
{"epoch": 13, "training_loss": 0.6924643301963807, "training_acc": 53.0, "val_loss": 0.6945875668525696, "val_acc": 48.0}
{"epoch": 14, "training_loss": 0.7135784029960632, "training_acc": 47.0, "val_loss": 0.6955435991287231, "val_acc": 48.0}
{"epoch": 15, "training_loss": 0.7287362837791442, "training_acc": 45.0, "val_loss": 0.6992185473442077, "val_acc": 52.0}
{"epoch": 16, "training_loss": 0.692974967956543, "training_acc": 51.0, "val_loss": 0.6941433691978455, "val_acc": 48.0}
{"epoch": 17, "training_loss": 0.6938425350189209, "training_acc": 55.0, "val_loss": 0.6938111782073975, "val_acc": 52.0}
{"epoch": 18, "training_loss": 0.69521240234375, "training_acc": 49.0, "val_loss": 0.6932636094093323, "val_acc": 48.0}
{"epoch": 19, "training_loss": 0.6892937946319581, "training_acc": 55.0, "val_loss": 0.6983477091789245, "val_acc": 52.0}
{"epoch": 20, "training_loss": 0.7052062201499939, "training_acc": 53.0, "val_loss": 0.6929969000816345, "val_acc": 52.0}
{"epoch": 21, "training_loss": 0.694689929485321, "training_acc": 53.0, "val_loss": 0.6950526094436645, "val_acc": 52.0}
{"epoch": 22, "training_loss": 0.7027387046813964, "training_acc": 53.0, "val_loss": 0.6968063306808472, "val_acc": 52.0}
{"epoch": 23, "training_loss": 0.6942964458465576, "training_acc": 51.0, "val_loss": 0.7021575093269348, "val_acc": 48.0}
{"epoch": 24, "training_loss": 0.7075809788703918, "training_acc": 47.0, "val_loss": 0.6923468279838562, "val_acc": 52.0}
{"epoch": 25, "training_loss": 0.6927144026756287, "training_acc": 53.0, "val_loss": 0.7190682220458985, "val_acc": 52.0}
{"epoch": 26, "training_loss": 0.7067590188980103, "training_acc": 53.0, "val_loss": 0.6927850556373596, "val_acc": 52.0}
{"epoch": 27, "training_loss": 0.6976543021202087, "training_acc": 53.0, "val_loss": 0.6925632929801941, "val_acc": 52.0}
{"epoch": 28, "training_loss": 0.7126453185081482, "training_acc": 43.0, "val_loss": 0.7011830878257751, "val_acc": 48.0}
{"epoch": 29, "training_loss": 0.7091067218780518, "training_acc": 45.0, "val_loss": 0.6992081451416016, "val_acc": 52.0}
{"epoch": 30, "training_loss": 0.696512987613678, "training_acc": 53.0, "val_loss": 0.693350989818573, "val_acc": 52.0}
{"epoch": 31, "training_loss": 0.6916208076477051, "training_acc": 53.0, "val_loss": 0.6933806920051575, "val_acc": 48.0}
{"epoch": 32, "training_loss": 0.6966963911056518, "training_acc": 47.0, "val_loss": 0.6923902440071106, "val_acc": 52.0}
{"epoch": 33, "training_loss": 0.6975824642181396, "training_acc": 53.0, "val_loss": 0.700090184211731, "val_acc": 52.0}
{"epoch": 34, "training_loss": 0.7060344886779785, "training_acc": 53.0, "val_loss": 0.7033706617355346, "val_acc": 52.0}
{"epoch": 35, "training_loss": 0.6972251605987548, "training_acc": 53.0, "val_loss": 0.6950384759902954, "val_acc": 48.0}
{"epoch": 36, "training_loss": 0.7023526430130005, "training_acc": 47.0, "val_loss": 0.6989761400222778, "val_acc": 48.0}
{"epoch": 37, "training_loss": 0.7026266479492187, "training_acc": 47.0, "val_loss": 0.6946591210365295, "val_acc": 48.0}
{"epoch": 38, "training_loss": 0.6936933612823486, "training_acc": 49.0, "val_loss": 0.6952244305610656, "val_acc": 52.0}
{"epoch": 39, "training_loss": 0.6944012999534607, "training_acc": 53.0, "val_loss": 0.6948572444915772, "val_acc": 52.0}
{"epoch": 40, "training_loss": 0.6925012397766114, "training_acc": 53.0, "val_loss": 0.6928530502319336, "val_acc": 52.0}
{"epoch": 41, "training_loss": 0.6941802811622619, "training_acc": 51.0, "val_loss": 0.6934588742256165, "val_acc": 48.0}
{"epoch": 42, "training_loss": 0.693209080696106, "training_acc": 53.0, "val_loss": 0.6932961130142212, "val_acc": 52.0}
{"epoch": 43, "training_loss": 0.6947967338562012, "training_acc": 53.0, "val_loss": 0.6926965188980102, "val_acc": 52.0}
