"main_modify.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option BT_org --learning_rate 1e-3 --batch_size 16 --weight_decay 1e-5 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 0.7214587712287903, "training_acc": 54.0, "val_loss": 0.6929035449028015, "val_acc": 52.0}
{"epoch": 1, "training_loss": 0.6904001307487487, "training_acc": 55.0, "val_loss": 0.7005743765830994, "val_acc": 48.0}
{"epoch": 2, "training_loss": 0.6957002353668212, "training_acc": 51.0, "val_loss": 0.7103765130043029, "val_acc": 52.0}
{"epoch": 3, "training_loss": 0.7112388777732849, "training_acc": 53.0, "val_loss": 0.6950155758857727, "val_acc": 52.0}
{"epoch": 4, "training_loss": 0.6955489444732667, "training_acc": 53.0, "val_loss": 0.6925993633270263, "val_acc": 52.0}
{"epoch": 5, "training_loss": 0.6952237844467163, "training_acc": 51.0, "val_loss": 0.692372887134552, "val_acc": 52.0}
{"epoch": 6, "training_loss": 0.7119047451019287, "training_acc": 53.0, "val_loss": 0.6967309904098511, "val_acc": 52.0}
{"epoch": 7, "training_loss": 0.6946912741661072, "training_acc": 51.0, "val_loss": 0.6963600039482116, "val_acc": 48.0}
{"epoch": 8, "training_loss": 0.6971200799942017, "training_acc": 47.0, "val_loss": 0.6923862433433533, "val_acc": 52.0}
{"epoch": 9, "training_loss": 0.694212577342987, "training_acc": 53.0, "val_loss": 0.6926909327507019, "val_acc": 52.0}
{"epoch": 10, "training_loss": 0.7232987308502197, "training_acc": 43.0, "val_loss": 0.6935843729972839, "val_acc": 48.0}
{"epoch": 11, "training_loss": 0.6914345788955688, "training_acc": 53.0, "val_loss": 0.7120435047149658, "val_acc": 52.0}
{"epoch": 12, "training_loss": 0.6944639301300048, "training_acc": 53.0, "val_loss": 0.6927052688598633, "val_acc": 52.0}
{"epoch": 13, "training_loss": 0.7016620445251465, "training_acc": 53.0, "val_loss": 0.6927802348136902, "val_acc": 52.0}
{"epoch": 14, "training_loss": 0.6913431048393249, "training_acc": 53.0, "val_loss": 0.6926797413825989, "val_acc": 52.0}
{"epoch": 15, "training_loss": 0.6958040809631347, "training_acc": 45.0, "val_loss": 0.692393708229065, "val_acc": 52.0}
{"epoch": 16, "training_loss": 0.6940064311027527, "training_acc": 53.0, "val_loss": 0.696450080871582, "val_acc": 52.0}
{"epoch": 17, "training_loss": 0.6935550689697265, "training_acc": 53.0, "val_loss": 0.6924274349212647, "val_acc": 52.0}
{"epoch": 18, "training_loss": 0.6932896137237549, "training_acc": 49.0, "val_loss": 0.692446870803833, "val_acc": 52.0}
{"epoch": 19, "training_loss": 0.7021543502807617, "training_acc": 53.0, "val_loss": 0.7046971225738525, "val_acc": 52.0}
{"epoch": 20, "training_loss": 0.7001124501228333, "training_acc": 53.0, "val_loss": 0.6925716185569764, "val_acc": 52.0}
{"epoch": 21, "training_loss": 0.7183069181442261, "training_acc": 45.0, "val_loss": 0.7126972961425782, "val_acc": 48.0}
{"epoch": 22, "training_loss": 0.708928894996643, "training_acc": 43.0, "val_loss": 0.6927066922187806, "val_acc": 52.0}
{"epoch": 23, "training_loss": 0.6954321241378785, "training_acc": 53.0, "val_loss": 0.6982102537155152, "val_acc": 52.0}
{"epoch": 24, "training_loss": 0.6968033576011657, "training_acc": 53.0, "val_loss": 0.6923567175865173, "val_acc": 52.0}
{"epoch": 25, "training_loss": 0.6925771164894104, "training_acc": 53.0, "val_loss": 0.6944693374633789, "val_acc": 52.0}
{"epoch": 26, "training_loss": 0.6929068446159363, "training_acc": 53.0, "val_loss": 0.6976709461212158, "val_acc": 52.0}
{"epoch": 27, "training_loss": 0.7005502581596375, "training_acc": 53.0, "val_loss": 0.6939688062667847, "val_acc": 52.0}
{"epoch": 28, "training_loss": 0.6906233215332032, "training_acc": 53.0, "val_loss": 0.6983136916160584, "val_acc": 48.0}
{"epoch": 29, "training_loss": 0.7033481550216675, "training_acc": 47.0, "val_loss": 0.6935234236717224, "val_acc": 52.0}
{"epoch": 30, "training_loss": 0.6985158157348633, "training_acc": 45.0, "val_loss": 0.6931135201454163, "val_acc": 52.0}
{"epoch": 31, "training_loss": 0.6958380699157715, "training_acc": 41.0, "val_loss": 0.6928591322898865, "val_acc": 52.0}
{"epoch": 32, "training_loss": 0.6940766263008118, "training_acc": 53.0, "val_loss": 0.693564715385437, "val_acc": 48.0}
{"epoch": 33, "training_loss": 0.7111336994171142, "training_acc": 47.0, "val_loss": 0.6986206555366516, "val_acc": 48.0}
{"epoch": 34, "training_loss": 0.694611349105835, "training_acc": 49.0, "val_loss": 0.7024365639686585, "val_acc": 52.0}
{"epoch": 35, "training_loss": 0.7010554456710816, "training_acc": 53.0, "val_loss": 0.6937872695922852, "val_acc": 52.0}
{"epoch": 36, "training_loss": 0.6948709344863891, "training_acc": 51.0, "val_loss": 0.6943442630767822, "val_acc": 48.0}
{"epoch": 37, "training_loss": 0.7039726758003235, "training_acc": 45.0, "val_loss": 0.6929980158805847, "val_acc": 52.0}
{"epoch": 38, "training_loss": 0.6925382280349731, "training_acc": 51.0, "val_loss": 0.6942038440704346, "val_acc": 48.0}
{"epoch": 39, "training_loss": 0.6944329595565796, "training_acc": 47.0, "val_loss": 0.6924630641937256, "val_acc": 52.0}
{"epoch": 40, "training_loss": 0.7162155437469483, "training_acc": 53.0, "val_loss": 0.7025039982795716, "val_acc": 52.0}
{"epoch": 41, "training_loss": 0.6964147853851318, "training_acc": 49.0, "val_loss": 0.6958365178108216, "val_acc": 48.0}
{"epoch": 42, "training_loss": 0.6999267339706421, "training_acc": 47.0, "val_loss": 0.693753387928009, "val_acc": 48.0}
{"epoch": 43, "training_loss": 0.7016982221603394, "training_acc": 53.0, "val_loss": 0.7021537089347839, "val_acc": 52.0}
