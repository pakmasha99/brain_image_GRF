"main_modify.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 2 --task ABCD_sex --input_option BT_org --learning_rate 1e-3 --batch_size 16 --weight_decay 1e-5 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 0.7233973908424377, "training_acc": 45.0, "val_loss": 0.6964494395256042, "val_acc": 52.0}
{"epoch": 1, "training_loss": 0.7022349405288696, "training_acc": 53.0, "val_loss": 0.6937892532348633, "val_acc": 52.0}
{"epoch": 2, "training_loss": 0.7033250522613526, "training_acc": 41.0, "val_loss": 0.6962235713005066, "val_acc": 52.0}
{"epoch": 3, "training_loss": 0.7059885358810425, "training_acc": 53.0, "val_loss": 0.6925754284858704, "val_acc": 52.0}
{"epoch": 4, "training_loss": 0.6969919276237487, "training_acc": 47.0, "val_loss": 0.6957975697517395, "val_acc": 48.0}
{"epoch": 5, "training_loss": 0.6909013509750366, "training_acc": 55.0, "val_loss": 0.6951188969612122, "val_acc": 52.0}
{"epoch": 6, "training_loss": 0.6926849842071533, "training_acc": 53.0, "val_loss": 0.6927131223678589, "val_acc": 52.0}
{"epoch": 7, "training_loss": 0.6952243065834045, "training_acc": 45.0, "val_loss": 0.6930708742141723, "val_acc": 52.0}
{"epoch": 8, "training_loss": 0.6955643939971924, "training_acc": 53.0, "val_loss": 0.6925513410568237, "val_acc": 52.0}
{"epoch": 9, "training_loss": 0.6931835412979126, "training_acc": 53.0, "val_loss": 0.6924132061004639, "val_acc": 52.0}
{"epoch": 10, "training_loss": 0.6949279165267944, "training_acc": 43.0, "val_loss": 0.692392361164093, "val_acc": 52.0}
{"epoch": 11, "training_loss": 0.7011730432510376, "training_acc": 53.0, "val_loss": 0.6934596753120422, "val_acc": 52.0}
{"epoch": 12, "training_loss": 0.6928374457359314, "training_acc": 55.0, "val_loss": 0.6949378252029419, "val_acc": 48.0}
{"epoch": 13, "training_loss": 0.6979841041564941, "training_acc": 49.0, "val_loss": 0.6935310006141663, "val_acc": 52.0}
{"epoch": 14, "training_loss": 0.7011020350456237, "training_acc": 53.0, "val_loss": 0.6960009336471558, "val_acc": 52.0}
{"epoch": 15, "training_loss": 0.6928205251693725, "training_acc": 53.0, "val_loss": 0.6924628520011902, "val_acc": 52.0}
{"epoch": 16, "training_loss": 0.700015242099762, "training_acc": 49.0, "val_loss": 0.6958593487739563, "val_acc": 48.0}
{"epoch": 17, "training_loss": 0.6996739482879639, "training_acc": 47.0, "val_loss": 0.6923676538467407, "val_acc": 52.0}
{"epoch": 18, "training_loss": 0.7069184064865113, "training_acc": 41.0, "val_loss": 0.6962427830696106, "val_acc": 48.0}
{"epoch": 19, "training_loss": 0.6963998055458069, "training_acc": 47.0, "val_loss": 0.6926928639411927, "val_acc": 52.0}
{"epoch": 20, "training_loss": 0.7002680969238281, "training_acc": 53.0, "val_loss": 0.7035411477088929, "val_acc": 52.0}
{"epoch": 21, "training_loss": 0.6990868067741394, "training_acc": 53.0, "val_loss": 0.6924070787429809, "val_acc": 52.0}
{"epoch": 22, "training_loss": 0.7113603258132934, "training_acc": 39.0, "val_loss": 0.6951564383506775, "val_acc": 48.0}
{"epoch": 23, "training_loss": 0.7031344318389893, "training_acc": 49.0, "val_loss": 0.6933918309211731, "val_acc": 52.0}
{"epoch": 24, "training_loss": 0.6980137848854064, "training_acc": 51.0, "val_loss": 0.6939524412155151, "val_acc": 48.0}
{"epoch": 25, "training_loss": 0.7133919787406922, "training_acc": 43.0, "val_loss": 0.7026606130599976, "val_acc": 52.0}
{"epoch": 26, "training_loss": 0.7026515674591064, "training_acc": 53.0, "val_loss": 0.6927728748321533, "val_acc": 52.0}
{"epoch": 27, "training_loss": 0.6994478344917298, "training_acc": 53.0, "val_loss": 0.6926729774475098, "val_acc": 52.0}
{"epoch": 28, "training_loss": 0.6933480978012085, "training_acc": 53.0, "val_loss": 0.6948538637161255, "val_acc": 52.0}
{"epoch": 29, "training_loss": 0.694656765460968, "training_acc": 53.0, "val_loss": 0.6932242584228515, "val_acc": 52.0}
{"epoch": 30, "training_loss": 0.6954658794403076, "training_acc": 53.0, "val_loss": 0.6970379328727723, "val_acc": 52.0}
{"epoch": 31, "training_loss": 0.6974602746963501, "training_acc": 53.0, "val_loss": 0.6932638335227966, "val_acc": 52.0}
{"epoch": 32, "training_loss": 0.7191195011138916, "training_acc": 41.0, "val_loss": 0.6959531736373902, "val_acc": 48.0}
{"epoch": 33, "training_loss": 0.6928915929794311, "training_acc": 57.0, "val_loss": 0.7089183497428894, "val_acc": 52.0}
{"epoch": 34, "training_loss": 0.699259352684021, "training_acc": 51.0, "val_loss": 0.6937826418876648, "val_acc": 48.0}
{"epoch": 35, "training_loss": 0.6990702033042908, "training_acc": 47.0, "val_loss": 0.6926760601997376, "val_acc": 52.0}
{"epoch": 36, "training_loss": 0.6962475895881652, "training_acc": 51.0, "val_loss": 0.6947854566574097, "val_acc": 48.0}
