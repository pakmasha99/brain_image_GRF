"main_modify.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 2 --task ABCD_sex --input_option BT_org --learning_rate 1e-3 --batch_size 16 --weight_decay 1e-5 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 0.708870861530304, "training_acc": 46.0, "val_loss": 0.6870834445953369, "val_acc": 56.0}
{"epoch": 1, "training_loss": 0.7056628584861755, "training_acc": 52.0, "val_loss": 0.6866166758537292, "val_acc": 56.0}
{"epoch": 2, "training_loss": 0.7011562299728393, "training_acc": 52.0, "val_loss": 0.6956018042564392, "val_acc": 44.0}
{"epoch": 3, "training_loss": 0.6960634517669678, "training_acc": 48.0, "val_loss": 0.6875977444648743, "val_acc": 56.0}
{"epoch": 4, "training_loss": 0.7044517850875854, "training_acc": 43.0, "val_loss": 0.6863596725463867, "val_acc": 56.0}
{"epoch": 5, "training_loss": 0.7044729280471802, "training_acc": 52.0, "val_loss": 0.6859391021728516, "val_acc": 56.0}
{"epoch": 6, "training_loss": 0.6946545457839965, "training_acc": 52.0, "val_loss": 0.6942271304130554, "val_acc": 44.0}
{"epoch": 7, "training_loss": 0.7016186141967773, "training_acc": 44.0, "val_loss": 0.6920792388916016, "val_acc": 56.0}
{"epoch": 8, "training_loss": 0.7069537210464477, "training_acc": 52.0, "val_loss": 0.6860204291343689, "val_acc": 56.0}
{"epoch": 9, "training_loss": 0.6952265453338623, "training_acc": 50.0, "val_loss": 0.7002578306198121, "val_acc": 44.0}
{"epoch": 10, "training_loss": 0.6994255161285401, "training_acc": 44.0, "val_loss": 0.6910535764694213, "val_acc": 56.0}
{"epoch": 11, "training_loss": 0.7011259388923645, "training_acc": 52.0, "val_loss": 0.6876701092720032, "val_acc": 56.0}
{"epoch": 12, "training_loss": 0.696617374420166, "training_acc": 48.0, "val_loss": 0.6960030651092529, "val_acc": 44.0}
{"epoch": 13, "training_loss": 0.7015351223945617, "training_acc": 48.0, "val_loss": 0.6860208320617676, "val_acc": 56.0}
{"epoch": 14, "training_loss": 0.6989384722709656, "training_acc": 52.0, "val_loss": 0.6859513068199158, "val_acc": 56.0}
{"epoch": 15, "training_loss": 0.6973425245285034, "training_acc": 52.0, "val_loss": 0.6863895750045776, "val_acc": 56.0}
{"epoch": 16, "training_loss": 0.6966038084030152, "training_acc": 48.0, "val_loss": 0.6985145497322083, "val_acc": 44.0}
{"epoch": 17, "training_loss": 0.7053215551376343, "training_acc": 40.0, "val_loss": 0.6924791026115418, "val_acc": 56.0}
{"epoch": 18, "training_loss": 0.694368953704834, "training_acc": 48.0, "val_loss": 0.6887868189811707, "val_acc": 56.0}
{"epoch": 19, "training_loss": 0.6988818597793579, "training_acc": 40.0, "val_loss": 0.6859280061721802, "val_acc": 56.0}
{"epoch": 20, "training_loss": 0.7069583654403686, "training_acc": 52.0, "val_loss": 0.6864042973518372, "val_acc": 56.0}
{"epoch": 21, "training_loss": 0.7053425908088684, "training_acc": 44.0, "val_loss": 0.7044486546516419, "val_acc": 44.0}
{"epoch": 22, "training_loss": 0.6999339365959167, "training_acc": 44.0, "val_loss": 0.6893267130851746, "val_acc": 56.0}
{"epoch": 23, "training_loss": 0.6981076335906983, "training_acc": 46.0, "val_loss": 0.6962107849121094, "val_acc": 44.0}
{"epoch": 24, "training_loss": 0.699836072921753, "training_acc": 48.0, "val_loss": 0.6861938905715942, "val_acc": 56.0}
{"epoch": 25, "training_loss": 0.6934487223625183, "training_acc": 52.0, "val_loss": 0.6919291186332702, "val_acc": 56.0}
{"epoch": 26, "training_loss": 0.6979190015792847, "training_acc": 42.0, "val_loss": 0.6874897599220275, "val_acc": 56.0}
{"epoch": 27, "training_loss": 0.709326000213623, "training_acc": 52.0, "val_loss": 0.6910925817489624, "val_acc": 56.0}
{"epoch": 28, "training_loss": 0.7094136476516724, "training_acc": 52.0, "val_loss": 0.6864865064620972, "val_acc": 56.0}
{"epoch": 29, "training_loss": 0.6953081798553467, "training_acc": 52.0, "val_loss": 0.691675009727478, "val_acc": 56.0}
{"epoch": 30, "training_loss": 0.7061097407341004, "training_acc": 50.0, "val_loss": 0.7184063267707824, "val_acc": 44.0}
{"epoch": 31, "training_loss": 0.7144725370407105, "training_acc": 48.0, "val_loss": 0.6960170340538024, "val_acc": 44.0}
{"epoch": 32, "training_loss": 0.6908463048934936, "training_acc": 54.0, "val_loss": 0.6860041785240173, "val_acc": 56.0}
{"epoch": 33, "training_loss": 0.6975343775749206, "training_acc": 52.0, "val_loss": 0.6861689329147339, "val_acc": 56.0}
{"epoch": 34, "training_loss": 0.7066484785079956, "training_acc": 52.0, "val_loss": 0.6859316945075988, "val_acc": 56.0}
{"epoch": 35, "training_loss": 0.6946105742454529, "training_acc": 48.0, "val_loss": 0.6952179265022278, "val_acc": 44.0}
{"epoch": 36, "training_loss": 0.6921932983398438, "training_acc": 52.0, "val_loss": 0.6860316061973571, "val_acc": 56.0}
{"epoch": 37, "training_loss": 0.7075996255874634, "training_acc": 52.0, "val_loss": 0.6875214838981628, "val_acc": 56.0}
{"epoch": 38, "training_loss": 0.6952634906768799, "training_acc": 54.0, "val_loss": 0.7050449299812317, "val_acc": 44.0}
