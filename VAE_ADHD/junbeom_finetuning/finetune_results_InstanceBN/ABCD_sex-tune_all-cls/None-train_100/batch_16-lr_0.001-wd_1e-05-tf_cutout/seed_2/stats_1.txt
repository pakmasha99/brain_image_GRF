"main_modify.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 2 --task ABCD_sex --input_option BT_org --learning_rate 1e-3 --batch_size 16 --weight_decay 1e-5 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 0.7066634178161622, "training_acc": 47.0, "val_loss": 0.6924502515792846, "val_acc": 52.0}
{"epoch": 1, "training_loss": 0.7193524241447449, "training_acc": 43.0, "val_loss": 0.6930541920661927, "val_acc": 52.0}
{"epoch": 2, "training_loss": 0.6986805963516235, "training_acc": 53.0, "val_loss": 0.6963574576377869, "val_acc": 52.0}
{"epoch": 3, "training_loss": 0.695218539237976, "training_acc": 53.0, "val_loss": 0.6924997329711914, "val_acc": 52.0}
{"epoch": 4, "training_loss": 0.7055015468597412, "training_acc": 53.0, "val_loss": 0.6925253701210022, "val_acc": 52.0}
{"epoch": 5, "training_loss": 0.7020795893669128, "training_acc": 45.0, "val_loss": 0.692360577583313, "val_acc": 52.0}
{"epoch": 6, "training_loss": 0.6958264780044555, "training_acc": 53.0, "val_loss": 0.6932363152503968, "val_acc": 52.0}
{"epoch": 7, "training_loss": 0.6949527168273926, "training_acc": 43.0, "val_loss": 0.6927957224845886, "val_acc": 52.0}
{"epoch": 8, "training_loss": 0.7151930594444275, "training_acc": 53.0, "val_loss": 0.6971475386619568, "val_acc": 52.0}
{"epoch": 9, "training_loss": 0.6966572690010071, "training_acc": 45.0, "val_loss": 0.6951387357711792, "val_acc": 48.0}
{"epoch": 10, "training_loss": 0.6970338344573974, "training_acc": 45.0, "val_loss": 0.6924856734275818, "val_acc": 52.0}
{"epoch": 11, "training_loss": 0.6947139644622803, "training_acc": 47.0, "val_loss": 0.6927650165557862, "val_acc": 52.0}
{"epoch": 12, "training_loss": 0.7077692413330078, "training_acc": 53.0, "val_loss": 0.696349823474884, "val_acc": 52.0}
{"epoch": 13, "training_loss": 0.700434410572052, "training_acc": 47.0, "val_loss": 0.6998808026313782, "val_acc": 48.0}
{"epoch": 14, "training_loss": 0.7040986680984497, "training_acc": 47.0, "val_loss": 0.6932571458816529, "val_acc": 48.0}
{"epoch": 15, "training_loss": 0.6978404307365418, "training_acc": 49.0, "val_loss": 0.6936294221878052, "val_acc": 52.0}
{"epoch": 16, "training_loss": 0.6962078928947448, "training_acc": 53.0, "val_loss": 0.7044845151901246, "val_acc": 52.0}
{"epoch": 17, "training_loss": 0.6994812345504761, "training_acc": 53.0, "val_loss": 0.6943533253669739, "val_acc": 52.0}
{"epoch": 18, "training_loss": 0.6943358945846557, "training_acc": 53.0, "val_loss": 0.6927443718910218, "val_acc": 52.0}
{"epoch": 19, "training_loss": 0.7011461901664734, "training_acc": 49.0, "val_loss": 0.6936628079414368, "val_acc": 48.0}
{"epoch": 20, "training_loss": 0.6971178245544434, "training_acc": 53.0, "val_loss": 0.7128734159469604, "val_acc": 52.0}
{"epoch": 21, "training_loss": 0.7131916952133178, "training_acc": 53.0, "val_loss": 0.6923407387733459, "val_acc": 52.0}
{"epoch": 22, "training_loss": 0.6907062244415283, "training_acc": 53.0, "val_loss": 0.6964785313606262, "val_acc": 52.0}
{"epoch": 23, "training_loss": 0.697530415058136, "training_acc": 53.0, "val_loss": 0.6928527021408081, "val_acc": 52.0}
{"epoch": 24, "training_loss": 0.7117168045043946, "training_acc": 45.0, "val_loss": 0.7134081387519836, "val_acc": 48.0}
{"epoch": 25, "training_loss": 0.7148869037628174, "training_acc": 43.0, "val_loss": 0.6923645043373108, "val_acc": 52.0}
{"epoch": 26, "training_loss": 0.7065110540390015, "training_acc": 53.0, "val_loss": 0.6965518307685852, "val_acc": 52.0}
{"epoch": 27, "training_loss": 0.6909689927101135, "training_acc": 53.0, "val_loss": 0.6979130268096924, "val_acc": 48.0}
{"epoch": 28, "training_loss": 0.7025861024856568, "training_acc": 47.0, "val_loss": 0.693306610584259, "val_acc": 48.0}
{"epoch": 29, "training_loss": 0.7247215223312378, "training_acc": 47.0, "val_loss": 0.7031254434585571, "val_acc": 52.0}
{"epoch": 30, "training_loss": 0.6941825246810913, "training_acc": 53.0, "val_loss": 0.6923471903800964, "val_acc": 52.0}
{"epoch": 31, "training_loss": 0.6929087662696838, "training_acc": 53.0, "val_loss": 0.6925752758979797, "val_acc": 52.0}
{"epoch": 32, "training_loss": 0.69628981590271, "training_acc": 53.0, "val_loss": 0.6995841336250305, "val_acc": 52.0}
{"epoch": 33, "training_loss": 0.6975587010383606, "training_acc": 53.0, "val_loss": 0.6935011219978332, "val_acc": 52.0}
{"epoch": 34, "training_loss": 0.692980887889862, "training_acc": 53.0, "val_loss": 0.6923466157913208, "val_acc": 52.0}
{"epoch": 35, "training_loss": 0.695835313796997, "training_acc": 53.0, "val_loss": 0.692466847896576, "val_acc": 52.0}
{"epoch": 36, "training_loss": 0.7012505865097046, "training_acc": 41.0, "val_loss": 0.6935169243812561, "val_acc": 48.0}
{"epoch": 37, "training_loss": 0.6925607872009277, "training_acc": 55.0, "val_loss": 0.6943888401985169, "val_acc": 52.0}
{"epoch": 38, "training_loss": 0.6938669276237488, "training_acc": 53.0, "val_loss": 0.69361736536026, "val_acc": 52.0}
{"epoch": 39, "training_loss": 0.6945622277259826, "training_acc": 53.0, "val_loss": 0.6925954699516297, "val_acc": 52.0}
{"epoch": 40, "training_loss": 0.6918514895439148, "training_acc": 53.0, "val_loss": 0.693855094909668, "val_acc": 48.0}
