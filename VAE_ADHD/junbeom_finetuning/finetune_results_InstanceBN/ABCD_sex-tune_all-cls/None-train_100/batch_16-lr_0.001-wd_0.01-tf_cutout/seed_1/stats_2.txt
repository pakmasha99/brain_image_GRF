"main_modify.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 1 --task ABCD_sex --input_option BT_org --learning_rate 1e-3 --batch_size 16 --weight_decay 1e-2 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 0.7127490139007568, "training_acc": 46.0, "val_loss": 0.6939398455619812, "val_acc": 52.0}
{"epoch": 1, "training_loss": 0.6930499196052551, "training_acc": 53.0, "val_loss": 0.695350148677826, "val_acc": 52.0}
{"epoch": 2, "training_loss": 0.6970405578613281, "training_acc": 47.0, "val_loss": 0.692419888973236, "val_acc": 52.0}
{"epoch": 3, "training_loss": 0.7025888204574585, "training_acc": 43.0, "val_loss": 0.7045349860191346, "val_acc": 52.0}
{"epoch": 4, "training_loss": 0.7063674187660217, "training_acc": 53.0, "val_loss": 0.6928693127632141, "val_acc": 52.0}
{"epoch": 5, "training_loss": 0.6976844239234924, "training_acc": 44.0, "val_loss": 0.6929745984077453, "val_acc": 52.0}
{"epoch": 6, "training_loss": 0.708260645866394, "training_acc": 53.0, "val_loss": 0.6937517952919007, "val_acc": 52.0}
{"epoch": 7, "training_loss": 0.7025897264480591, "training_acc": 53.0, "val_loss": 0.6926183676719666, "val_acc": 52.0}
{"epoch": 8, "training_loss": 0.7021156334877015, "training_acc": 41.0, "val_loss": 0.7013888621330261, "val_acc": 48.0}
{"epoch": 9, "training_loss": 0.7121557569503785, "training_acc": 47.0, "val_loss": 0.6929972958564758, "val_acc": 52.0}
{"epoch": 10, "training_loss": 0.7051532506942749, "training_acc": 53.0, "val_loss": 0.6971761417388916, "val_acc": 52.0}
{"epoch": 11, "training_loss": 0.6959531140327454, "training_acc": 53.0, "val_loss": 0.6945938467979431, "val_acc": 48.0}
{"epoch": 12, "training_loss": 0.697466139793396, "training_acc": 41.0, "val_loss": 0.6965193939208985, "val_acc": 48.0}
{"epoch": 13, "training_loss": 0.7010622310638428, "training_acc": 47.0, "val_loss": 0.694698441028595, "val_acc": 52.0}
{"epoch": 14, "training_loss": 0.6987275075912476, "training_acc": 53.0, "val_loss": 0.6937507271766663, "val_acc": 52.0}
{"epoch": 15, "training_loss": 0.7043467354774475, "training_acc": 41.0, "val_loss": 0.6957456254959107, "val_acc": 52.0}
{"epoch": 16, "training_loss": 0.7018415546417236, "training_acc": 53.0, "val_loss": 0.6935220837593079, "val_acc": 52.0}
{"epoch": 17, "training_loss": 0.6936935257911682, "training_acc": 49.0, "val_loss": 0.6923830890655518, "val_acc": 52.0}
{"epoch": 18, "training_loss": 0.6989178586006165, "training_acc": 53.0, "val_loss": 0.6924161195755005, "val_acc": 52.0}
{"epoch": 19, "training_loss": 0.7003217458724975, "training_acc": 47.0, "val_loss": 0.6936124920845032, "val_acc": 52.0}
{"epoch": 20, "training_loss": 0.7041980791091919, "training_acc": 53.0, "val_loss": 0.6923623585700989, "val_acc": 52.0}
{"epoch": 21, "training_loss": 0.7166132450103759, "training_acc": 45.0, "val_loss": 0.6942343258857727, "val_acc": 48.0}
{"epoch": 22, "training_loss": 0.6906068754196167, "training_acc": 53.0, "val_loss": 0.6991375398635864, "val_acc": 52.0}
{"epoch": 23, "training_loss": 0.699361867904663, "training_acc": 53.0, "val_loss": 0.6927849078178405, "val_acc": 52.0}
{"epoch": 24, "training_loss": 0.6969288921356201, "training_acc": 43.0, "val_loss": 0.6929621529579163, "val_acc": 52.0}
{"epoch": 25, "training_loss": 0.696588215827942, "training_acc": 47.0, "val_loss": 0.6935944938659668, "val_acc": 52.0}
{"epoch": 26, "training_loss": 0.6921677017211914, "training_acc": 53.0, "val_loss": 0.69241455078125, "val_acc": 52.0}
{"epoch": 27, "training_loss": 0.6972249913215637, "training_acc": 53.0, "val_loss": 0.6931726098060608, "val_acc": 52.0}
{"epoch": 28, "training_loss": 0.6951940798759461, "training_acc": 53.0, "val_loss": 0.6923557257652283, "val_acc": 52.0}
{"epoch": 29, "training_loss": 0.6994208788871765, "training_acc": 49.0, "val_loss": 0.6925808811187744, "val_acc": 52.0}
{"epoch": 30, "training_loss": 0.6925473165512085, "training_acc": 45.0, "val_loss": 0.7023052549362183, "val_acc": 52.0}
{"epoch": 31, "training_loss": 0.7041398262977601, "training_acc": 53.0, "val_loss": 0.6956682205200195, "val_acc": 52.0}
{"epoch": 32, "training_loss": 0.7026211214065552, "training_acc": 39.0, "val_loss": 0.6925769019126892, "val_acc": 52.0}
{"epoch": 33, "training_loss": 0.7023518896102905, "training_acc": 53.0, "val_loss": 0.6924010038375854, "val_acc": 52.0}
{"epoch": 34, "training_loss": 0.6925059366226196, "training_acc": 53.0, "val_loss": 0.6927162957191467, "val_acc": 52.0}
{"epoch": 35, "training_loss": 0.6977297830581665, "training_acc": 45.0, "val_loss": 0.6923833107948303, "val_acc": 52.0}
{"epoch": 36, "training_loss": 0.6986221075057983, "training_acc": 53.0, "val_loss": 0.6931144762039184, "val_acc": 52.0}
{"epoch": 37, "training_loss": 0.6975620365142823, "training_acc": 53.0, "val_loss": 0.696344199180603, "val_acc": 52.0}
{"epoch": 38, "training_loss": 0.7076867151260376, "training_acc": 53.0, "val_loss": 0.6924080157279968, "val_acc": 52.0}
{"epoch": 39, "training_loss": 0.7129246950149536, "training_acc": 41.0, "val_loss": 0.6924822521209717, "val_acc": 52.0}
{"epoch": 40, "training_loss": 0.6945326566696167, "training_acc": 53.0, "val_loss": 0.7141772603988648, "val_acc": 52.0}
{"epoch": 41, "training_loss": 0.7169060397148133, "training_acc": 53.0, "val_loss": 0.7048052215576172, "val_acc": 52.0}
{"epoch": 42, "training_loss": 0.7005608654022217, "training_acc": 53.0, "val_loss": 0.6937983703613281, "val_acc": 52.0}
{"epoch": 43, "training_loss": 0.6929729223251343, "training_acc": 49.0, "val_loss": 0.6989910745620728, "val_acc": 48.0}
{"epoch": 44, "training_loss": 0.7055344438552856, "training_acc": 47.0, "val_loss": 0.6929641222953796, "val_acc": 52.0}
{"epoch": 45, "training_loss": 0.7124164152145386, "training_acc": 53.0, "val_loss": 0.6930491185188293, "val_acc": 52.0}
{"epoch": 46, "training_loss": 0.6964052104949952, "training_acc": 53.0, "val_loss": 0.695401451587677, "val_acc": 52.0}
{"epoch": 47, "training_loss": 0.7064135932922363, "training_acc": 53.0, "val_loss": 0.7029262971878052, "val_acc": 52.0}
