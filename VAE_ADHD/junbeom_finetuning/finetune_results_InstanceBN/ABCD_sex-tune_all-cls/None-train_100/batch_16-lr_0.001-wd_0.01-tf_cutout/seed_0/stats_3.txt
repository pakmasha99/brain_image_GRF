"main_modify.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option BT_org --learning_rate 1e-3 --batch_size 16 --weight_decay 1e-2 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 0.735593581199646, "training_acc": 45.0, "val_loss": 0.7010113835334778, "val_acc": 52.0}
{"epoch": 1, "training_loss": 0.6919019150733948, "training_acc": 53.0, "val_loss": 0.6969085693359375, "val_acc": 48.0}
{"epoch": 2, "training_loss": 0.697582197189331, "training_acc": 49.0, "val_loss": 0.7006334686279296, "val_acc": 48.0}
{"epoch": 3, "training_loss": 0.7065812635421753, "training_acc": 45.0, "val_loss": 0.6949050307273865, "val_acc": 48.0}
{"epoch": 4, "training_loss": 0.6983529424667358, "training_acc": 50.0, "val_loss": 0.692647774219513, "val_acc": 52.0}
{"epoch": 5, "training_loss": 0.6942839884757995, "training_acc": 53.0, "val_loss": 0.6935865306854248, "val_acc": 52.0}
{"epoch": 6, "training_loss": 0.7019938325881958, "training_acc": 53.0, "val_loss": 0.6923699569702149, "val_acc": 52.0}
{"epoch": 7, "training_loss": 0.6982538771629333, "training_acc": 47.0, "val_loss": 0.6963406682014466, "val_acc": 52.0}
{"epoch": 8, "training_loss": 0.7044559645652771, "training_acc": 53.0, "val_loss": 0.6923557615280151, "val_acc": 52.0}
{"epoch": 9, "training_loss": 0.7013236141204834, "training_acc": 45.0, "val_loss": 0.6924492716789246, "val_acc": 52.0}
{"epoch": 10, "training_loss": 0.7082150793075561, "training_acc": 53.0, "val_loss": 0.7082897114753723, "val_acc": 52.0}
{"epoch": 11, "training_loss": 0.712978971004486, "training_acc": 53.0, "val_loss": 0.6939279150962829, "val_acc": 52.0}
{"epoch": 12, "training_loss": 0.7039082741737366, "training_acc": 45.0, "val_loss": 0.7009048390388489, "val_acc": 52.0}
{"epoch": 13, "training_loss": 0.7047355103492737, "training_acc": 53.0, "val_loss": 0.7025243091583252, "val_acc": 52.0}
{"epoch": 14, "training_loss": 0.6969394755363464, "training_acc": 53.0, "val_loss": 0.6924937844276429, "val_acc": 52.0}
{"epoch": 15, "training_loss": 0.700449845790863, "training_acc": 47.0, "val_loss": 0.6938926410675049, "val_acc": 52.0}
{"epoch": 16, "training_loss": 0.6935547780990601, "training_acc": 53.0, "val_loss": 0.6925418472290039, "val_acc": 52.0}
{"epoch": 17, "training_loss": 0.6975654244422913, "training_acc": 43.0, "val_loss": 0.692540774345398, "val_acc": 52.0}
{"epoch": 18, "training_loss": 0.6927069187164306, "training_acc": 51.0, "val_loss": 0.6946097254753113, "val_acc": 52.0}
{"epoch": 19, "training_loss": 0.69821768283844, "training_acc": 53.0, "val_loss": 0.6923555827140808, "val_acc": 52.0}
{"epoch": 20, "training_loss": 0.6997406649589538, "training_acc": 47.0, "val_loss": 0.6933781599998474, "val_acc": 52.0}
{"epoch": 21, "training_loss": 0.712992877960205, "training_acc": 53.0, "val_loss": 0.6970559072494507, "val_acc": 52.0}
{"epoch": 22, "training_loss": 0.7048035049438477, "training_acc": 43.0, "val_loss": 0.6931745839118958, "val_acc": 48.0}
{"epoch": 23, "training_loss": 0.6995191025733948, "training_acc": 45.0, "val_loss": 0.6930128860473633, "val_acc": 52.0}
{"epoch": 24, "training_loss": 0.7011850452423096, "training_acc": 51.0, "val_loss": 0.6942754244804382, "val_acc": 48.0}
{"epoch": 25, "training_loss": 0.6951616024971008, "training_acc": 49.0, "val_loss": 0.6925373935699463, "val_acc": 52.0}
{"epoch": 26, "training_loss": 0.7030691242218018, "training_acc": 53.0, "val_loss": 0.6941430234909057, "val_acc": 48.0}
{"epoch": 27, "training_loss": 0.6988135671615601, "training_acc": 47.0, "val_loss": 0.6925773644447326, "val_acc": 52.0}
{"epoch": 28, "training_loss": 0.701204981803894, "training_acc": 53.0, "val_loss": 0.6939872550964356, "val_acc": 52.0}
{"epoch": 29, "training_loss": 0.6943581676483155, "training_acc": 53.0, "val_loss": 0.692644989490509, "val_acc": 52.0}
{"epoch": 30, "training_loss": 0.6980544972419739, "training_acc": 53.0, "val_loss": 0.692420265674591, "val_acc": 52.0}
{"epoch": 31, "training_loss": 0.6982343292236328, "training_acc": 45.0, "val_loss": 0.6984223484992981, "val_acc": 52.0}
{"epoch": 32, "training_loss": 0.7005816340446472, "training_acc": 53.0, "val_loss": 0.6979833507537841, "val_acc": 52.0}
{"epoch": 33, "training_loss": 0.6983512592315674, "training_acc": 53.0, "val_loss": 0.6923828554153443, "val_acc": 52.0}
{"epoch": 34, "training_loss": 0.6957727861404419, "training_acc": 45.0, "val_loss": 0.6923594760894776, "val_acc": 52.0}
{"epoch": 35, "training_loss": 0.7117125344276428, "training_acc": 53.0, "val_loss": 0.6943076014518738, "val_acc": 52.0}
{"epoch": 36, "training_loss": 0.6956657314300537, "training_acc": 51.0, "val_loss": 0.6948519992828369, "val_acc": 48.0}
{"epoch": 37, "training_loss": 0.6967729139328003, "training_acc": 47.0, "val_loss": 0.6923470306396484, "val_acc": 52.0}
{"epoch": 38, "training_loss": 0.6957253789901734, "training_acc": 53.0, "val_loss": 0.6935646915435791, "val_acc": 48.0}
{"epoch": 39, "training_loss": 0.7208087396621704, "training_acc": 47.0, "val_loss": 0.6923719024658204, "val_acc": 52.0}
{"epoch": 40, "training_loss": 0.6953496360778808, "training_acc": 53.0, "val_loss": 0.7091486430168152, "val_acc": 52.0}
{"epoch": 41, "training_loss": 0.6936112546920776, "training_acc": 51.0, "val_loss": 0.6929568219184875, "val_acc": 52.0}
{"epoch": 42, "training_loss": 0.7037737369537354, "training_acc": 53.0, "val_loss": 0.6925345706939697, "val_acc": 52.0}
{"epoch": 43, "training_loss": 0.6925051259994507, "training_acc": 53.0, "val_loss": 0.692921986579895, "val_acc": 52.0}
{"epoch": 44, "training_loss": 0.6987547516822815, "training_acc": 47.0, "val_loss": 0.6930087184906006, "val_acc": 52.0}
{"epoch": 45, "training_loss": 0.696966233253479, "training_acc": 53.0, "val_loss": 0.6943734812736512, "val_acc": 52.0}
{"epoch": 46, "training_loss": 0.6945242166519165, "training_acc": 53.0, "val_loss": 0.6923977565765381, "val_acc": 52.0}
{"epoch": 47, "training_loss": 0.695031669139862, "training_acc": 45.0, "val_loss": 0.6960258197784424, "val_acc": 52.0}
{"epoch": 48, "training_loss": 0.7042335653305054, "training_acc": 53.0, "val_loss": 0.6959509205818176, "val_acc": 52.0}
{"epoch": 49, "training_loss": 0.7042660474777221, "training_acc": 53.0, "val_loss": 0.6977562832832337, "val_acc": 48.0}
{"epoch": 50, "training_loss": 0.7215006351470947, "training_acc": 47.0, "val_loss": 0.7024414491653442, "val_acc": 48.0}
{"epoch": 51, "training_loss": 0.7021616125106811, "training_acc": 49.0, "val_loss": 0.6938533926010132, "val_acc": 52.0}
{"epoch": 52, "training_loss": 0.6971549940109253, "training_acc": 53.0, "val_loss": 0.6942074275016785, "val_acc": 52.0}
{"epoch": 53, "training_loss": 0.6967753648757935, "training_acc": 53.0, "val_loss": 0.6936445999145507, "val_acc": 52.0}
{"epoch": 54, "training_loss": 0.698825056552887, "training_acc": 53.0, "val_loss": 0.6977767896652222, "val_acc": 52.0}
{"epoch": 55, "training_loss": 0.6958574628829957, "training_acc": 53.0, "val_loss": 0.6973358750343323, "val_acc": 52.0}
{"epoch": 56, "training_loss": 0.7029581570625305, "training_acc": 53.0, "val_loss": 0.6932141470909119, "val_acc": 48.0}
