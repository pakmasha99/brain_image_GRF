"main_modify.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 2 --task ABCD_sex --input_option BT_org --learning_rate 1e-3 --batch_size 16 --weight_decay 1e-2 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 0.7255999326705933, "training_acc": 48.0, "val_loss": 0.6864833807945252, "val_acc": 56.0}
{"epoch": 1, "training_loss": 0.7075544142723084, "training_acc": 52.0, "val_loss": 0.6868816471099853, "val_acc": 56.0}
{"epoch": 2, "training_loss": 0.7048457193374634, "training_acc": 52.0, "val_loss": 0.700228304862976, "val_acc": 44.0}
{"epoch": 3, "training_loss": 0.7076520681381225, "training_acc": 38.0, "val_loss": 0.7049221014976501, "val_acc": 44.0}
{"epoch": 4, "training_loss": 0.7022452211380005, "training_acc": 46.0, "val_loss": 0.6872812032699585, "val_acc": 56.0}
{"epoch": 5, "training_loss": 0.7010130715370179, "training_acc": 48.0, "val_loss": 0.6872426080703735, "val_acc": 56.0}
{"epoch": 6, "training_loss": 0.7122221231460572, "training_acc": 52.0, "val_loss": 0.686311309337616, "val_acc": 56.0}
{"epoch": 7, "training_loss": 0.7046473407745362, "training_acc": 50.0, "val_loss": 0.6954196000099182, "val_acc": 44.0}
{"epoch": 8, "training_loss": 0.6977929997444153, "training_acc": 52.0, "val_loss": 0.6885300469398499, "val_acc": 56.0}
{"epoch": 9, "training_loss": 0.7014388465881347, "training_acc": 46.0, "val_loss": 0.6939210438728333, "val_acc": 44.0}
{"epoch": 10, "training_loss": 0.6978095054626465, "training_acc": 48.0, "val_loss": 0.6917872738838196, "val_acc": 56.0}
{"epoch": 11, "training_loss": 0.6968546485900879, "training_acc": 50.0, "val_loss": 0.6897577261924743, "val_acc": 56.0}
{"epoch": 12, "training_loss": 0.6954322290420533, "training_acc": 48.0, "val_loss": 0.6875012397766114, "val_acc": 56.0}
{"epoch": 13, "training_loss": 0.71426424741745, "training_acc": 52.0, "val_loss": 0.687171356678009, "val_acc": 56.0}
{"epoch": 14, "training_loss": 0.7077447414398194, "training_acc": 52.0, "val_loss": 0.6868995618820191, "val_acc": 56.0}
{"epoch": 15, "training_loss": 0.6986073851585388, "training_acc": 52.0, "val_loss": 0.6939824724197388, "val_acc": 44.0}
{"epoch": 16, "training_loss": 0.7087104868888855, "training_acc": 48.0, "val_loss": 0.7141620922088623, "val_acc": 44.0}
{"epoch": 17, "training_loss": 0.711144061088562, "training_acc": 48.0, "val_loss": 0.6904289364814759, "val_acc": 56.0}
{"epoch": 18, "training_loss": 0.6929976439476013, "training_acc": 52.0, "val_loss": 0.6861640882492065, "val_acc": 56.0}
{"epoch": 19, "training_loss": 0.6975123357772827, "training_acc": 52.0, "val_loss": 0.6859529948234558, "val_acc": 56.0}
{"epoch": 20, "training_loss": 0.71318510055542, "training_acc": 52.0, "val_loss": 0.6869141292572022, "val_acc": 56.0}
{"epoch": 21, "training_loss": 0.7010713005065918, "training_acc": 52.0, "val_loss": 0.6919499731063843, "val_acc": 56.0}
{"epoch": 22, "training_loss": 0.6940442609786988, "training_acc": 52.0, "val_loss": 0.6866894364356995, "val_acc": 56.0}
{"epoch": 23, "training_loss": 0.7089805388450623, "training_acc": 52.0, "val_loss": 0.6870089387893676, "val_acc": 56.0}
{"epoch": 24, "training_loss": 0.6994701504707337, "training_acc": 46.0, "val_loss": 0.7067801713943481, "val_acc": 44.0}
{"epoch": 25, "training_loss": 0.7027291774749755, "training_acc": 48.0, "val_loss": 0.6867740440368653, "val_acc": 56.0}
{"epoch": 26, "training_loss": 0.715451979637146, "training_acc": 52.0, "val_loss": 0.6889777088165283, "val_acc": 56.0}
{"epoch": 27, "training_loss": 0.705997359752655, "training_acc": 52.0, "val_loss": 0.6907829594612122, "val_acc": 56.0}
{"epoch": 28, "training_loss": 0.692399981021881, "training_acc": 52.0, "val_loss": 0.7028731036186219, "val_acc": 44.0}
{"epoch": 29, "training_loss": 0.6961013293266296, "training_acc": 48.0, "val_loss": 0.6859300565719605, "val_acc": 56.0}
{"epoch": 30, "training_loss": 0.7190983080863953, "training_acc": 52.0, "val_loss": 0.6862658262252808, "val_acc": 56.0}
{"epoch": 31, "training_loss": 0.696017107963562, "training_acc": 52.0, "val_loss": 0.704775173664093, "val_acc": 44.0}
{"epoch": 32, "training_loss": 0.7073262190818786, "training_acc": 48.0, "val_loss": 0.7130282378196716, "val_acc": 44.0}
{"epoch": 33, "training_loss": 0.7017363595962525, "training_acc": 46.0, "val_loss": 0.6893132758140564, "val_acc": 56.0}
{"epoch": 34, "training_loss": 0.6953580808639527, "training_acc": 52.0, "val_loss": 0.6879466557502747, "val_acc": 56.0}
{"epoch": 35, "training_loss": 0.695721583366394, "training_acc": 52.0, "val_loss": 0.7081365489959717, "val_acc": 44.0}
{"epoch": 36, "training_loss": 0.7136889386177063, "training_acc": 48.0, "val_loss": 0.6968252563476562, "val_acc": 44.0}
{"epoch": 37, "training_loss": 0.6944237136840821, "training_acc": 52.0, "val_loss": 0.6866919088363648, "val_acc": 56.0}
{"epoch": 38, "training_loss": 0.6993806505203247, "training_acc": 52.0, "val_loss": 0.6859898447990418, "val_acc": 56.0}
{"epoch": 39, "training_loss": 0.7033510732650757, "training_acc": 52.0, "val_loss": 0.6894097065925598, "val_acc": 56.0}
{"epoch": 40, "training_loss": 0.6976319789886475, "training_acc": 52.0, "val_loss": 0.697780454158783, "val_acc": 44.0}
{"epoch": 41, "training_loss": 0.703317461013794, "training_acc": 48.0, "val_loss": 0.6927713418006897, "val_acc": 56.0}
{"epoch": 42, "training_loss": 0.698147463798523, "training_acc": 52.0, "val_loss": 0.6931020283699035, "val_acc": 56.0}
{"epoch": 43, "training_loss": 0.6979791116714478, "training_acc": 44.0, "val_loss": 0.6961634421348571, "val_acc": 44.0}
{"epoch": 44, "training_loss": 0.6953902864456176, "training_acc": 44.0, "val_loss": 0.6886829161643981, "val_acc": 56.0}
{"epoch": 45, "training_loss": 0.7016654992103577, "training_acc": 44.0, "val_loss": 0.6880220150947571, "val_acc": 56.0}
{"epoch": 46, "training_loss": 0.6988934683799743, "training_acc": 40.0, "val_loss": 0.6864666891098022, "val_acc": 56.0}
{"epoch": 47, "training_loss": 0.7076668167114257, "training_acc": 52.0, "val_loss": 0.6861338257789612, "val_acc": 56.0}
{"epoch": 48, "training_loss": 0.7004672861099244, "training_acc": 52.0, "val_loss": 0.6880322742462158, "val_acc": 56.0}
