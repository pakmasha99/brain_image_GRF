"main_modify.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 2 --task ABCD_sex --input_option BT_org --learning_rate 1e-3 --batch_size 16 --weight_decay 1e-2 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 0.7276813602447509, "training_acc": 47.0, "val_loss": 0.6926685070991516, "val_acc": 52.0}
{"epoch": 1, "training_loss": 0.7030888032913208, "training_acc": 41.0, "val_loss": 0.6924534273147583, "val_acc": 52.0}
{"epoch": 2, "training_loss": 0.7100382375717164, "training_acc": 49.0, "val_loss": 0.6943621301651001, "val_acc": 52.0}
{"epoch": 3, "training_loss": 0.6930371069908142, "training_acc": 53.0, "val_loss": 0.6929137659072876, "val_acc": 52.0}
{"epoch": 4, "training_loss": 0.6976368999481202, "training_acc": 49.0, "val_loss": 0.6973274064064026, "val_acc": 48.0}
{"epoch": 5, "training_loss": 0.7025870227813721, "training_acc": 47.0, "val_loss": 0.6940559387207031, "val_acc": 48.0}
{"epoch": 6, "training_loss": 0.7137317943572998, "training_acc": 47.0, "val_loss": 0.6961851835250854, "val_acc": 48.0}
{"epoch": 7, "training_loss": 0.6958884382247925, "training_acc": 49.0, "val_loss": 0.6940123677253723, "val_acc": 52.0}
{"epoch": 8, "training_loss": 0.7021997928619385, "training_acc": 53.0, "val_loss": 0.7002338933944702, "val_acc": 52.0}
{"epoch": 9, "training_loss": 0.6982403182983399, "training_acc": 53.0, "val_loss": 0.6924837613105774, "val_acc": 52.0}
{"epoch": 10, "training_loss": 0.7067051649093627, "training_acc": 37.0, "val_loss": 0.6933064889907837, "val_acc": 48.0}
{"epoch": 11, "training_loss": 0.7065656471252442, "training_acc": 49.0, "val_loss": 0.6927964353561401, "val_acc": 52.0}
{"epoch": 12, "training_loss": 0.6987133598327637, "training_acc": 49.0, "val_loss": 0.6924078869819641, "val_acc": 52.0}
{"epoch": 13, "training_loss": 0.7161970233917236, "training_acc": 53.0, "val_loss": 0.6993452882766724, "val_acc": 52.0}
{"epoch": 14, "training_loss": 0.7002757143974304, "training_acc": 53.0, "val_loss": 0.6924261116981506, "val_acc": 52.0}
{"epoch": 15, "training_loss": 0.7020194911956787, "training_acc": 53.0, "val_loss": 0.6925972485542298, "val_acc": 52.0}
{"epoch": 16, "training_loss": 0.6945626950263977, "training_acc": 53.0, "val_loss": 0.6942923831939697, "val_acc": 52.0}
{"epoch": 17, "training_loss": 0.6961512303352356, "training_acc": 53.0, "val_loss": 0.6946504187583923, "val_acc": 52.0}
{"epoch": 18, "training_loss": 0.696571524143219, "training_acc": 53.0, "val_loss": 0.6951721668243408, "val_acc": 52.0}
{"epoch": 19, "training_loss": 0.6981087803840638, "training_acc": 53.0, "val_loss": 0.6923474621772766, "val_acc": 52.0}
{"epoch": 20, "training_loss": 0.7128158760070801, "training_acc": 41.0, "val_loss": 0.6932020902633667, "val_acc": 52.0}
{"epoch": 21, "training_loss": 0.6954076075553894, "training_acc": 53.0, "val_loss": 0.6974219179153442, "val_acc": 52.0}
{"epoch": 22, "training_loss": 0.6953475475311279, "training_acc": 47.0, "val_loss": 0.6925001502037048, "val_acc": 52.0}
{"epoch": 23, "training_loss": 0.7033602809906006, "training_acc": 53.0, "val_loss": 0.6923861622810363, "val_acc": 52.0}
{"epoch": 24, "training_loss": 0.6967521691322327, "training_acc": 49.0, "val_loss": 0.6926148056983947, "val_acc": 52.0}
{"epoch": 25, "training_loss": 0.7103756237030029, "training_acc": 53.0, "val_loss": 0.6933290100097657, "val_acc": 52.0}
{"epoch": 26, "training_loss": 0.6965886068344116, "training_acc": 51.0, "val_loss": 0.6932037043571472, "val_acc": 48.0}
{"epoch": 27, "training_loss": 0.6975045680999756, "training_acc": 49.0, "val_loss": 0.6923476910591125, "val_acc": 52.0}
{"epoch": 28, "training_loss": 0.696823182106018, "training_acc": 41.0, "val_loss": 0.6943906044960022, "val_acc": 52.0}
{"epoch": 29, "training_loss": 0.7039419960975647, "training_acc": 53.0, "val_loss": 0.7028942155838013, "val_acc": 52.0}
{"epoch": 30, "training_loss": 0.708779935836792, "training_acc": 53.0, "val_loss": 0.6924834895133972, "val_acc": 52.0}
{"epoch": 31, "training_loss": 0.695729308128357, "training_acc": 53.0, "val_loss": 0.6930173444747925, "val_acc": 52.0}
{"epoch": 32, "training_loss": 0.6985581398010254, "training_acc": 45.0, "val_loss": 0.6940000796318054, "val_acc": 52.0}
{"epoch": 33, "training_loss": 0.6961365509033203, "training_acc": 53.0, "val_loss": 0.6994352674484253, "val_acc": 52.0}
{"epoch": 34, "training_loss": 0.6992052984237671, "training_acc": 53.0, "val_loss": 0.6940258526802063, "val_acc": 52.0}
{"epoch": 35, "training_loss": 0.6948666739463806, "training_acc": 53.0, "val_loss": 0.6932545018196106, "val_acc": 52.0}
{"epoch": 36, "training_loss": 0.698306086063385, "training_acc": 53.0, "val_loss": 0.6968036770820618, "val_acc": 52.0}
{"epoch": 37, "training_loss": 0.7047023630142212, "training_acc": 53.0, "val_loss": 0.7013037228584289, "val_acc": 52.0}
{"epoch": 38, "training_loss": 0.7006451892852783, "training_acc": 53.0, "val_loss": 0.6931848549842834, "val_acc": 52.0}
