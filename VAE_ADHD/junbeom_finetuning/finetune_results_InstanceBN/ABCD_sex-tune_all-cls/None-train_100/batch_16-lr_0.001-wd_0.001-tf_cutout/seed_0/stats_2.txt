"main_modify.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option BT_org --learning_rate 1e-3 --batch_size 16 --weight_decay 1e-3 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 0.7067423105239868, "training_acc": 49.0, "val_loss": 0.6935225796699523, "val_acc": 48.0}
{"epoch": 1, "training_loss": 0.7049813079833984, "training_acc": 45.0, "val_loss": 0.7088504147529602, "val_acc": 52.0}
{"epoch": 2, "training_loss": 0.7222956562042236, "training_acc": 53.0, "val_loss": 0.6927656507492066, "val_acc": 52.0}
{"epoch": 3, "training_loss": 0.6993912100791931, "training_acc": 47.0, "val_loss": 0.692476999759674, "val_acc": 52.0}
{"epoch": 4, "training_loss": 0.6999966740608216, "training_acc": 53.0, "val_loss": 0.6934539985656738, "val_acc": 52.0}
{"epoch": 5, "training_loss": 0.6954660654067993, "training_acc": 53.0, "val_loss": 0.6938568997383118, "val_acc": 52.0}
{"epoch": 6, "training_loss": 0.6931181693077088, "training_acc": 53.0, "val_loss": 0.6977918362617492, "val_acc": 52.0}
{"epoch": 7, "training_loss": 0.6944339179992676, "training_acc": 53.0, "val_loss": 0.6960227227210999, "val_acc": 48.0}
{"epoch": 8, "training_loss": 0.7087700963020325, "training_acc": 47.0, "val_loss": 0.6958825707435607, "val_acc": 48.0}
{"epoch": 9, "training_loss": 0.6957736015319824, "training_acc": 49.0, "val_loss": 0.6957428002357483, "val_acc": 52.0}
{"epoch": 10, "training_loss": 0.7042095470428467, "training_acc": 53.0, "val_loss": 0.699986503124237, "val_acc": 52.0}
{"epoch": 11, "training_loss": 0.6918449831008912, "training_acc": 53.0, "val_loss": 0.6962959384918213, "val_acc": 48.0}
{"epoch": 12, "training_loss": 0.6978252553939819, "training_acc": 45.0, "val_loss": 0.692475574016571, "val_acc": 52.0}
{"epoch": 13, "training_loss": 0.6981390571594238, "training_acc": 47.0, "val_loss": 0.6937705254554749, "val_acc": 52.0}
{"epoch": 14, "training_loss": 0.6960446095466614, "training_acc": 53.0, "val_loss": 0.694307451248169, "val_acc": 52.0}
{"epoch": 15, "training_loss": 0.6943846035003662, "training_acc": 53.0, "val_loss": 0.6924061179161072, "val_acc": 52.0}
{"epoch": 16, "training_loss": 0.6996306085586548, "training_acc": 41.0, "val_loss": 0.6935759925842285, "val_acc": 48.0}
{"epoch": 17, "training_loss": 0.6999487733840942, "training_acc": 55.0, "val_loss": 0.7000472950935364, "val_acc": 52.0}
{"epoch": 18, "training_loss": 0.7021499347686767, "training_acc": 53.0, "val_loss": 0.6930403280258178, "val_acc": 52.0}
{"epoch": 19, "training_loss": 0.6949812579154968, "training_acc": 50.0, "val_loss": 0.6928179121017456, "val_acc": 52.0}
{"epoch": 20, "training_loss": 0.6990909028053284, "training_acc": 53.0, "val_loss": 0.6968014025688172, "val_acc": 52.0}
{"epoch": 21, "training_loss": 0.6992315483093262, "training_acc": 53.0, "val_loss": 0.6931228256225586, "val_acc": 52.0}
{"epoch": 22, "training_loss": 0.7046599626541138, "training_acc": 43.0, "val_loss": 0.6923953008651733, "val_acc": 52.0}
{"epoch": 23, "training_loss": 0.705048246383667, "training_acc": 53.0, "val_loss": 0.7124253129959106, "val_acc": 52.0}
{"epoch": 24, "training_loss": 0.708730354309082, "training_acc": 53.0, "val_loss": 0.6927166867256165, "val_acc": 52.0}
{"epoch": 25, "training_loss": 0.6954838681221008, "training_acc": 51.0, "val_loss": 0.6924826550483704, "val_acc": 52.0}
{"epoch": 26, "training_loss": 0.6958713388442993, "training_acc": 53.0, "val_loss": 0.695470929145813, "val_acc": 52.0}
{"epoch": 27, "training_loss": 0.6955722761154175, "training_acc": 53.0, "val_loss": 0.6933115410804749, "val_acc": 52.0}
{"epoch": 28, "training_loss": 0.6983141088485718, "training_acc": 45.0, "val_loss": 0.6924430441856384, "val_acc": 52.0}
{"epoch": 29, "training_loss": 0.7036638283729553, "training_acc": 53.0, "val_loss": 0.7005396962165833, "val_acc": 52.0}
{"epoch": 30, "training_loss": 0.7041175580024719, "training_acc": 53.0, "val_loss": 0.6931445980072022, "val_acc": 52.0}
{"epoch": 31, "training_loss": 0.7081385636329651, "training_acc": 47.0, "val_loss": 0.693694109916687, "val_acc": 48.0}
{"epoch": 32, "training_loss": 0.6927992463111877, "training_acc": 49.0, "val_loss": 0.702658965587616, "val_acc": 52.0}
{"epoch": 33, "training_loss": 0.713862669467926, "training_acc": 53.0, "val_loss": 0.6947076010704041, "val_acc": 52.0}
{"epoch": 34, "training_loss": 0.6879765295982361, "training_acc": 53.0, "val_loss": 0.7037200546264648, "val_acc": 48.0}
{"epoch": 35, "training_loss": 0.7049946594238281, "training_acc": 47.0, "val_loss": 0.6929088091850281, "val_acc": 52.0}
{"epoch": 36, "training_loss": 0.7021877264976502, "training_acc": 41.0, "val_loss": 0.6963527417182922, "val_acc": 52.0}
{"epoch": 37, "training_loss": 0.6997273492813111, "training_acc": 53.0, "val_loss": 0.7014276242256164, "val_acc": 52.0}
{"epoch": 38, "training_loss": 0.6996340799331665, "training_acc": 43.0, "val_loss": 0.6947687935829162, "val_acc": 48.0}
{"epoch": 39, "training_loss": 0.709528636932373, "training_acc": 47.0, "val_loss": 0.6923472452163696, "val_acc": 52.0}
{"epoch": 40, "training_loss": 0.6946376347541809, "training_acc": 53.0, "val_loss": 0.7006294703483582, "val_acc": 52.0}
{"epoch": 41, "training_loss": 0.6917242574691772, "training_acc": 53.0, "val_loss": 0.6980615663528442, "val_acc": 48.0}
{"epoch": 42, "training_loss": 0.6993414831161499, "training_acc": 45.0, "val_loss": 0.6923479795455932, "val_acc": 52.0}
{"epoch": 43, "training_loss": 0.6940443778038025, "training_acc": 53.0, "val_loss": 0.6924398756027221, "val_acc": 52.0}
{"epoch": 44, "training_loss": 0.6979944276809692, "training_acc": 43.0, "val_loss": 0.6929127240180969, "val_acc": 52.0}
{"epoch": 45, "training_loss": 0.6953891324996948, "training_acc": 49.0, "val_loss": 0.6925846409797668, "val_acc": 52.0}
{"epoch": 46, "training_loss": 0.696500654220581, "training_acc": 53.0, "val_loss": 0.7001788711547852, "val_acc": 52.0}
{"epoch": 47, "training_loss": 0.6946545839309692, "training_acc": 53.0, "val_loss": 0.6931463670730591, "val_acc": 52.0}
{"epoch": 48, "training_loss": 0.7005944418907165, "training_acc": 47.0, "val_loss": 0.6923470330238343, "val_acc": 52.0}
{"epoch": 49, "training_loss": 0.6984818339347839, "training_acc": 53.0, "val_loss": 0.6931164956092835, "val_acc": 52.0}
{"epoch": 50, "training_loss": 0.7017480039596558, "training_acc": 43.0, "val_loss": 0.6934009599685669, "val_acc": 48.0}
{"epoch": 51, "training_loss": 0.7029983854293823, "training_acc": 47.0, "val_loss": 0.6963701438903809, "val_acc": 48.0}
{"epoch": 52, "training_loss": 0.6956130170822143, "training_acc": 49.0, "val_loss": 0.6965761780738831, "val_acc": 52.0}
{"epoch": 53, "training_loss": 0.6966130256652832, "training_acc": 53.0, "val_loss": 0.6932715106010438, "val_acc": 48.0}
{"epoch": 54, "training_loss": 0.6982664203643799, "training_acc": 37.0, "val_loss": 0.6960728406906128, "val_acc": 48.0}
{"epoch": 55, "training_loss": 0.6992726182937622, "training_acc": 47.0, "val_loss": 0.6925385332107544, "val_acc": 52.0}
{"epoch": 56, "training_loss": 0.6938446950912476, "training_acc": 53.0, "val_loss": 0.6927949237823486, "val_acc": 52.0}
{"epoch": 57, "training_loss": 0.7053060746192932, "training_acc": 43.0, "val_loss": 0.6925902009010315, "val_acc": 52.0}
{"epoch": 58, "training_loss": 0.6989062714576721, "training_acc": 53.0, "val_loss": 0.6927648138999939, "val_acc": 52.0}
{"epoch": 59, "training_loss": 0.6976563572883606, "training_acc": 49.0, "val_loss": 0.6924360680580139, "val_acc": 52.0}
{"epoch": 60, "training_loss": 0.699802086353302, "training_acc": 53.0, "val_loss": 0.7094253277778626, "val_acc": 52.0}
{"epoch": 61, "training_loss": 0.7046172618865967, "training_acc": 53.0, "val_loss": 0.6924754452705383, "val_acc": 52.0}
{"epoch": 62, "training_loss": 0.7001280403137207, "training_acc": 43.0, "val_loss": 0.6923472189903259, "val_acc": 52.0}
{"epoch": 63, "training_loss": 0.7114038681983947, "training_acc": 53.0, "val_loss": 0.7053091382980347, "val_acc": 52.0}
{"epoch": 64, "training_loss": 0.6949750089645386, "training_acc": 53.0, "val_loss": 0.6942655563354492, "val_acc": 48.0}
{"epoch": 65, "training_loss": 0.7294823026657105, "training_acc": 47.0, "val_loss": 0.7096110582351685, "val_acc": 48.0}
{"epoch": 66, "training_loss": 0.7063711500167846, "training_acc": 51.0, "val_loss": 0.6933026814460754, "val_acc": 52.0}
{"epoch": 67, "training_loss": 0.6948397517204284, "training_acc": 53.0, "val_loss": 0.6923978734016418, "val_acc": 52.0}
