"main_modify.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option BT_org --learning_rate 1e-3 --batch_size 16 --weight_decay 1e-3 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 0.7063500356674194, "training_acc": 51.0, "val_loss": 0.6930672097206115, "val_acc": 52.0}
{"epoch": 1, "training_loss": 0.7345320296287536, "training_acc": 47.0, "val_loss": 0.7014258694648743, "val_acc": 48.0}
{"epoch": 2, "training_loss": 0.7111872577667236, "training_acc": 47.0, "val_loss": 0.6943640923500061, "val_acc": 52.0}
{"epoch": 3, "training_loss": 0.6999308657646179, "training_acc": 53.0, "val_loss": 0.6924864077568054, "val_acc": 52.0}
{"epoch": 4, "training_loss": 0.6957765769958496, "training_acc": 53.0, "val_loss": 0.6923733854293823, "val_acc": 52.0}
{"epoch": 5, "training_loss": 0.6963787317276001, "training_acc": 45.0, "val_loss": 0.6931336545944213, "val_acc": 52.0}
{"epoch": 6, "training_loss": 0.6992788028717041, "training_acc": 53.0, "val_loss": 0.6947056150436401, "val_acc": 52.0}
{"epoch": 7, "training_loss": 0.696825110912323, "training_acc": 53.0, "val_loss": 0.692398157119751, "val_acc": 52.0}
{"epoch": 8, "training_loss": 0.703629937171936, "training_acc": 45.0, "val_loss": 0.693256504535675, "val_acc": 52.0}
{"epoch": 9, "training_loss": 0.6937895607948303, "training_acc": 53.0, "val_loss": 0.6972392678260804, "val_acc": 52.0}
{"epoch": 10, "training_loss": 0.6952995204925537, "training_acc": 53.0, "val_loss": 0.6937721252441407, "val_acc": 48.0}
{"epoch": 11, "training_loss": 0.7265713715553284, "training_acc": 47.0, "val_loss": 0.692408754825592, "val_acc": 52.0}
{"epoch": 12, "training_loss": 0.6996593475341797, "training_acc": 53.0, "val_loss": 0.7042506170272828, "val_acc": 52.0}
{"epoch": 13, "training_loss": 0.7010404872894287, "training_acc": 53.0, "val_loss": 0.6924709343910217, "val_acc": 52.0}
{"epoch": 14, "training_loss": 0.7209768152236938, "training_acc": 45.0, "val_loss": 0.6972906351089477, "val_acc": 48.0}
{"epoch": 15, "training_loss": 0.7045872378349304, "training_acc": 41.0, "val_loss": 0.6963832402229309, "val_acc": 52.0}
{"epoch": 16, "training_loss": 0.7102790665626526, "training_acc": 53.0, "val_loss": 0.7022396183013916, "val_acc": 52.0}
{"epoch": 17, "training_loss": 0.6964917874336243, "training_acc": 53.0, "val_loss": 0.6932944917678833, "val_acc": 48.0}
{"epoch": 18, "training_loss": 0.7038805031776428, "training_acc": 47.0, "val_loss": 0.6964389038085937, "val_acc": 48.0}
{"epoch": 19, "training_loss": 0.7017581129074096, "training_acc": 49.0, "val_loss": 0.6983798956871032, "val_acc": 52.0}
{"epoch": 20, "training_loss": 0.6939361119270324, "training_acc": 53.0, "val_loss": 0.6923611855506897, "val_acc": 52.0}
{"epoch": 21, "training_loss": 0.7021595001220703, "training_acc": 37.0, "val_loss": 0.6938290405273437, "val_acc": 52.0}
{"epoch": 22, "training_loss": 0.6999650144577027, "training_acc": 53.0, "val_loss": 0.6937099814414978, "val_acc": 52.0}
{"epoch": 23, "training_loss": 0.7142131662368775, "training_acc": 39.0, "val_loss": 0.6926191782951355, "val_acc": 52.0}
{"epoch": 24, "training_loss": 0.6938110876083374, "training_acc": 53.0, "val_loss": 0.6952966237068177, "val_acc": 52.0}
{"epoch": 25, "training_loss": 0.7186552238464355, "training_acc": 35.0, "val_loss": 0.6923672652244568, "val_acc": 52.0}
{"epoch": 26, "training_loss": 0.703066942691803, "training_acc": 53.0, "val_loss": 0.692680447101593, "val_acc": 52.0}
{"epoch": 27, "training_loss": 0.6904344916343689, "training_acc": 53.0, "val_loss": 0.6964534568786621, "val_acc": 48.0}
{"epoch": 28, "training_loss": 0.7035267615318298, "training_acc": 47.0, "val_loss": 0.6923529148101807, "val_acc": 52.0}
{"epoch": 29, "training_loss": 0.7031339693069458, "training_acc": 53.0, "val_loss": 0.6952119183540344, "val_acc": 52.0}
{"epoch": 30, "training_loss": 0.6935867500305176, "training_acc": 51.0, "val_loss": 0.6927521514892578, "val_acc": 52.0}
{"epoch": 31, "training_loss": 0.6957415056228637, "training_acc": 43.0, "val_loss": 0.6929519653320313, "val_acc": 52.0}
{"epoch": 32, "training_loss": 0.6939798188209534, "training_acc": 53.0, "val_loss": 0.695377779006958, "val_acc": 52.0}
{"epoch": 33, "training_loss": 0.6959711360931397, "training_acc": 53.0, "val_loss": 0.6954614472389221, "val_acc": 52.0}
{"epoch": 34, "training_loss": 0.6957721710205078, "training_acc": 53.0, "val_loss": 0.6944366836547852, "val_acc": 52.0}
{"epoch": 35, "training_loss": 0.6915275573730468, "training_acc": 53.0, "val_loss": 0.6964725208282471, "val_acc": 48.0}
{"epoch": 36, "training_loss": 0.7051141619682312, "training_acc": 47.0, "val_loss": 0.6924510455131531, "val_acc": 52.0}
{"epoch": 37, "training_loss": 0.6943351173400879, "training_acc": 53.0, "val_loss": 0.6937944626808167, "val_acc": 52.0}
{"epoch": 38, "training_loss": 0.6953621244430542, "training_acc": 47.0, "val_loss": 0.6946816658973693, "val_acc": 52.0}
{"epoch": 39, "training_loss": 0.6976139950752258, "training_acc": 53.0, "val_loss": 0.6932671856880188, "val_acc": 52.0}
{"epoch": 40, "training_loss": 0.6962598848342896, "training_acc": 51.0, "val_loss": 0.6926651763916015, "val_acc": 52.0}
{"epoch": 41, "training_loss": 0.6931092977523804, "training_acc": 45.0, "val_loss": 0.6951712107658387, "val_acc": 52.0}
{"epoch": 42, "training_loss": 0.7031159257888794, "training_acc": 53.0, "val_loss": 0.6959164118766785, "val_acc": 52.0}
{"epoch": 43, "training_loss": 0.6968706655502319, "training_acc": 53.0, "val_loss": 0.6942554974555969, "val_acc": 48.0}
{"epoch": 44, "training_loss": 0.7204586720466614, "training_acc": 47.0, "val_loss": 0.6958262348175048, "val_acc": 48.0}
{"epoch": 45, "training_loss": 0.6956120324134827, "training_acc": 55.0, "val_loss": 0.7050513577461243, "val_acc": 52.0}
{"epoch": 46, "training_loss": 0.7179066467285157, "training_acc": 45.0, "val_loss": 0.6942639899253845, "val_acc": 52.0}
{"epoch": 47, "training_loss": 0.702740159034729, "training_acc": 53.0, "val_loss": 0.696663670539856, "val_acc": 52.0}
