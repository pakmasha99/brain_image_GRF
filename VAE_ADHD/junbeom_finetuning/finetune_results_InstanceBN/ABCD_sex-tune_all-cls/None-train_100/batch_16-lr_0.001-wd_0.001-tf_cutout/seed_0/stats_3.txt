"main_modify.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option BT_org --learning_rate 1e-3 --batch_size 16 --weight_decay 1e-3 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 0.7050396180152894, "training_acc": 51.0, "val_loss": 0.7058209300041198, "val_acc": 52.0}
{"epoch": 1, "training_loss": 0.7308670949935913, "training_acc": 53.0, "val_loss": 0.6926039218902588, "val_acc": 52.0}
{"epoch": 2, "training_loss": 0.7068278455734253, "training_acc": 51.0, "val_loss": 0.7077564764022827, "val_acc": 48.0}
{"epoch": 3, "training_loss": 0.7089797687530518, "training_acc": 45.0, "val_loss": 0.6941107106208801, "val_acc": 48.0}
{"epoch": 4, "training_loss": 0.6975879502296448, "training_acc": 47.0, "val_loss": 0.6924241757392884, "val_acc": 52.0}
{"epoch": 5, "training_loss": 0.7033173370361329, "training_acc": 53.0, "val_loss": 0.6966691303253174, "val_acc": 52.0}
{"epoch": 6, "training_loss": 0.6934859418869018, "training_acc": 51.0, "val_loss": 0.6946062016487121, "val_acc": 48.0}
{"epoch": 7, "training_loss": 0.6911230087280273, "training_acc": 53.0, "val_loss": 0.6978253388404846, "val_acc": 52.0}
{"epoch": 8, "training_loss": 0.6981656122207641, "training_acc": 53.0, "val_loss": 0.6931122708320617, "val_acc": 52.0}
{"epoch": 9, "training_loss": 0.7132961320877075, "training_acc": 42.0, "val_loss": 0.6924861264228821, "val_acc": 52.0}
{"epoch": 10, "training_loss": 0.6948933315277099, "training_acc": 46.0, "val_loss": 0.6972759246826172, "val_acc": 52.0}
{"epoch": 11, "training_loss": 0.7018209910392761, "training_acc": 45.0, "val_loss": 0.6924526381492615, "val_acc": 52.0}
{"epoch": 12, "training_loss": 0.7018303918838501, "training_acc": 53.0, "val_loss": 0.6932478785514832, "val_acc": 48.0}
{"epoch": 13, "training_loss": 0.7305900859832763, "training_acc": 47.0, "val_loss": 0.6985627031326294, "val_acc": 48.0}
{"epoch": 14, "training_loss": 0.7021308636665344, "training_acc": 45.0, "val_loss": 0.6933236694335938, "val_acc": 52.0}
{"epoch": 15, "training_loss": 0.7006477642059327, "training_acc": 53.0, "val_loss": 0.692446346282959, "val_acc": 52.0}
{"epoch": 16, "training_loss": 0.6937770175933838, "training_acc": 53.0, "val_loss": 0.694026141166687, "val_acc": 52.0}
{"epoch": 17, "training_loss": 0.6923377847671509, "training_acc": 53.0, "val_loss": 0.6934839367866517, "val_acc": 48.0}
{"epoch": 18, "training_loss": 0.7097888278961182, "training_acc": 47.0, "val_loss": 0.6942894649505615, "val_acc": 48.0}
{"epoch": 19, "training_loss": 0.7051174879074097, "training_acc": 49.0, "val_loss": 0.7002324032783508, "val_acc": 52.0}
{"epoch": 20, "training_loss": 0.6987889790534973, "training_acc": 53.0, "val_loss": 0.694701657295227, "val_acc": 52.0}
{"epoch": 21, "training_loss": 0.6989990615844727, "training_acc": 53.0, "val_loss": 0.6924047136306762, "val_acc": 52.0}
{"epoch": 22, "training_loss": 0.6925812911987305, "training_acc": 53.0, "val_loss": 0.6938303756713867, "val_acc": 48.0}
{"epoch": 23, "training_loss": 0.7034371590614319, "training_acc": 47.0, "val_loss": 0.6946255207061768, "val_acc": 52.0}
{"epoch": 24, "training_loss": 0.7011449766159058, "training_acc": 43.0, "val_loss": 0.6927788591384888, "val_acc": 52.0}
{"epoch": 25, "training_loss": 0.6926846051216126, "training_acc": 53.0, "val_loss": 0.6958331608772278, "val_acc": 52.0}
{"epoch": 26, "training_loss": 0.6986502933502198, "training_acc": 53.0, "val_loss": 0.6929194283485413, "val_acc": 52.0}
{"epoch": 27, "training_loss": 0.7041086602210999, "training_acc": 45.0, "val_loss": 0.6935763669013977, "val_acc": 48.0}
{"epoch": 28, "training_loss": 0.7051898336410523, "training_acc": 45.0, "val_loss": 0.6987024188041687, "val_acc": 52.0}
{"epoch": 29, "training_loss": 0.7103206300735474, "training_acc": 53.0, "val_loss": 0.6924018788337708, "val_acc": 52.0}
{"epoch": 30, "training_loss": 0.7014254546165466, "training_acc": 49.0, "val_loss": 0.7066625571250915, "val_acc": 48.0}
{"epoch": 31, "training_loss": 0.7130657768249512, "training_acc": 41.0, "val_loss": 0.692348473072052, "val_acc": 52.0}
{"epoch": 32, "training_loss": 0.7034382247924804, "training_acc": 39.0, "val_loss": 0.6924396967887878, "val_acc": 52.0}
{"epoch": 33, "training_loss": 0.7068706274032592, "training_acc": 53.0, "val_loss": 0.6952893257141113, "val_acc": 52.0}
{"epoch": 34, "training_loss": 0.6944491672515869, "training_acc": 53.0, "val_loss": 0.6927359819412231, "val_acc": 52.0}
{"epoch": 35, "training_loss": 0.6943893599510192, "training_acc": 49.0, "val_loss": 0.6942848157882691, "val_acc": 48.0}
{"epoch": 36, "training_loss": 0.695724630355835, "training_acc": 49.0, "val_loss": 0.6932362294197083, "val_acc": 52.0}
{"epoch": 37, "training_loss": 0.701109664440155, "training_acc": 45.0, "val_loss": 0.6926144766807556, "val_acc": 52.0}
{"epoch": 38, "training_loss": 0.7142527055740356, "training_acc": 53.0, "val_loss": 0.6999835348129273, "val_acc": 52.0}
{"epoch": 39, "training_loss": 0.6943850350379944, "training_acc": 53.0, "val_loss": 0.696124427318573, "val_acc": 48.0}
{"epoch": 40, "training_loss": 0.7069050288200378, "training_acc": 47.0, "val_loss": 0.6946990418434144, "val_acc": 48.0}
{"epoch": 41, "training_loss": 0.7028250885009766, "training_acc": 47.0, "val_loss": 0.6943049621582031, "val_acc": 52.0}
{"epoch": 42, "training_loss": 0.6957611036300659, "training_acc": 53.0, "val_loss": 0.6935376739501953, "val_acc": 52.0}
{"epoch": 43, "training_loss": 0.7076519584655762, "training_acc": 39.0, "val_loss": 0.6923739743232727, "val_acc": 52.0}
{"epoch": 44, "training_loss": 0.7071045875549317, "training_acc": 53.0, "val_loss": 0.7009142303466797, "val_acc": 52.0}
{"epoch": 45, "training_loss": 0.6954638767242431, "training_acc": 53.0, "val_loss": 0.6933651995658875, "val_acc": 48.0}
{"epoch": 46, "training_loss": 0.6966900277137756, "training_acc": 49.0, "val_loss": 0.6928164243698121, "val_acc": 52.0}
{"epoch": 47, "training_loss": 0.6918742656707764, "training_acc": 53.0, "val_loss": 0.7068779325485229, "val_acc": 52.0}
{"epoch": 48, "training_loss": 0.7084157991409302, "training_acc": 53.0, "val_loss": 0.6987019228935242, "val_acc": 52.0}
{"epoch": 49, "training_loss": 0.6872700262069702, "training_acc": 53.0, "val_loss": 0.6979882502555848, "val_acc": 48.0}
{"epoch": 50, "training_loss": 0.7037875747680664, "training_acc": 43.0, "val_loss": 0.6925310254096985, "val_acc": 52.0}
