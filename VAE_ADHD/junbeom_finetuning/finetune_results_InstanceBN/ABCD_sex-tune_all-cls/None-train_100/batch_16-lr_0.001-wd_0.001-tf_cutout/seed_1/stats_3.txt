"main_modify.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 1 --task ABCD_sex --input_option BT_org --learning_rate 1e-3 --batch_size 16 --weight_decay 1e-3 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 0.7149159455299378, "training_acc": 45.0, "val_loss": 0.6926982474327087, "val_acc": 52.0}
{"epoch": 1, "training_loss": 0.6968766784667969, "training_acc": 53.0, "val_loss": 0.7002696180343628, "val_acc": 48.0}
{"epoch": 2, "training_loss": 0.7038721776008606, "training_acc": 45.0, "val_loss": 0.6929908108711242, "val_acc": 52.0}
{"epoch": 3, "training_loss": 0.6992067337036133, "training_acc": 53.0, "val_loss": 0.6964535522460937, "val_acc": 52.0}
{"epoch": 4, "training_loss": 0.7008939790725708, "training_acc": 53.0, "val_loss": 0.6946835947036744, "val_acc": 52.0}
{"epoch": 5, "training_loss": 0.7035196661949158, "training_acc": 43.0, "val_loss": 0.6924263620376587, "val_acc": 52.0}
{"epoch": 6, "training_loss": 0.7060485124588013, "training_acc": 53.0, "val_loss": 0.6923984098434448, "val_acc": 52.0}
{"epoch": 7, "training_loss": 0.7052601671218872, "training_acc": 47.0, "val_loss": 0.6934604263305664, "val_acc": 48.0}
{"epoch": 8, "training_loss": 0.6982597923278808, "training_acc": 55.0, "val_loss": 0.6946006011962891, "val_acc": 52.0}
{"epoch": 9, "training_loss": 0.7153078651428223, "training_acc": 53.0, "val_loss": 0.6946447706222534, "val_acc": 48.0}
{"epoch": 10, "training_loss": 0.6963743829727173, "training_acc": 45.0, "val_loss": 0.6925308203697205, "val_acc": 52.0}
{"epoch": 11, "training_loss": 0.7027990388870239, "training_acc": 43.0, "val_loss": 0.6964367985725403, "val_acc": 52.0}
{"epoch": 12, "training_loss": 0.7102640533447265, "training_acc": 53.0, "val_loss": 0.6987193393707275, "val_acc": 52.0}
{"epoch": 13, "training_loss": 0.6961691689491272, "training_acc": 51.0, "val_loss": 0.6938368082046509, "val_acc": 48.0}
{"epoch": 14, "training_loss": 0.695941333770752, "training_acc": 49.0, "val_loss": 0.6926556420326233, "val_acc": 52.0}
{"epoch": 15, "training_loss": 0.7073753881454468, "training_acc": 53.0, "val_loss": 0.6923854351043701, "val_acc": 52.0}
{"epoch": 16, "training_loss": 0.6973228526115417, "training_acc": 53.0, "val_loss": 0.6924747586250305, "val_acc": 52.0}
{"epoch": 17, "training_loss": 0.7098057293891906, "training_acc": 39.0, "val_loss": 0.6935428166389466, "val_acc": 48.0}
{"epoch": 18, "training_loss": 0.6997606182098388, "training_acc": 51.0, "val_loss": 0.6972032976150513, "val_acc": 52.0}
{"epoch": 19, "training_loss": 0.7260446643829346, "training_acc": 53.0, "val_loss": 0.7009784841537475, "val_acc": 52.0}
{"epoch": 20, "training_loss": 0.6953374576568604, "training_acc": 53.0, "val_loss": 0.6947074151039123, "val_acc": 48.0}
{"epoch": 21, "training_loss": 0.7022203135490418, "training_acc": 47.0, "val_loss": 0.6923803353309631, "val_acc": 52.0}
{"epoch": 22, "training_loss": 0.6998010730743408, "training_acc": 43.0, "val_loss": 0.6975180959701538, "val_acc": 52.0}
{"epoch": 23, "training_loss": 0.7223162984848023, "training_acc": 53.0, "val_loss": 0.7042012715339661, "val_acc": 52.0}
{"epoch": 24, "training_loss": 0.7021652507781982, "training_acc": 49.0, "val_loss": 0.6941081237792969, "val_acc": 48.0}
{"epoch": 25, "training_loss": 0.6961071825027466, "training_acc": 49.0, "val_loss": 0.6952306103706359, "val_acc": 52.0}
{"epoch": 26, "training_loss": 0.6941988706588745, "training_acc": 53.0, "val_loss": 0.7048030543327332, "val_acc": 52.0}
{"epoch": 27, "training_loss": 0.7071891164779663, "training_acc": 53.0, "val_loss": 0.6923897981643676, "val_acc": 52.0}
{"epoch": 28, "training_loss": 0.6945034265518188, "training_acc": 45.0, "val_loss": 0.6927050471305847, "val_acc": 52.0}
{"epoch": 29, "training_loss": 0.7065456628799438, "training_acc": 53.0, "val_loss": 0.6941136479377746, "val_acc": 52.0}
{"epoch": 30, "training_loss": 0.7006088256835937, "training_acc": 45.0, "val_loss": 0.6926644492149353, "val_acc": 52.0}
{"epoch": 31, "training_loss": 0.692970757484436, "training_acc": 53.0, "val_loss": 0.6996909832954407, "val_acc": 52.0}
{"epoch": 32, "training_loss": 0.6949213004112244, "training_acc": 53.0, "val_loss": 0.6933114242553711, "val_acc": 48.0}
{"epoch": 33, "training_loss": 0.6976702260971069, "training_acc": 47.0, "val_loss": 0.6924899411201477, "val_acc": 52.0}
{"epoch": 34, "training_loss": 0.693460750579834, "training_acc": 53.0, "val_loss": 0.7001088047027588, "val_acc": 52.0}
{"epoch": 35, "training_loss": 0.7099757671356202, "training_acc": 53.0, "val_loss": 0.6946383404731751, "val_acc": 52.0}
{"epoch": 36, "training_loss": 0.6946250343322754, "training_acc": 49.0, "val_loss": 0.6926246237754822, "val_acc": 52.0}
{"epoch": 37, "training_loss": 0.6926687335968018, "training_acc": 53.0, "val_loss": 0.6962032723426819, "val_acc": 52.0}
{"epoch": 38, "training_loss": 0.6996775031089782, "training_acc": 53.0, "val_loss": 0.6925074052810669, "val_acc": 52.0}
{"epoch": 39, "training_loss": 0.7127604007720947, "training_acc": 43.0, "val_loss": 0.693030641078949, "val_acc": 52.0}
{"epoch": 40, "training_loss": 0.6963644123077393, "training_acc": 53.0, "val_loss": 0.694246838092804, "val_acc": 52.0}
