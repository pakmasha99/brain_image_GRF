"main_modify.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 1 --task ABCD_sex --input_option BT_org --learning_rate 1e-3 --batch_size 16 --weight_decay 1e-3 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 0.7204458713531494, "training_acc": 47.0, "val_loss": 0.6928380584716797, "val_acc": 52.0}
{"epoch": 1, "training_loss": 0.6932993125915528, "training_acc": 49.0, "val_loss": 0.7159106779098511, "val_acc": 52.0}
{"epoch": 2, "training_loss": 0.7095380520820618, "training_acc": 53.0, "val_loss": 0.6926054072380066, "val_acc": 52.0}
{"epoch": 3, "training_loss": 0.6946436071395874, "training_acc": 53.0, "val_loss": 0.6930706167221069, "val_acc": 52.0}
{"epoch": 4, "training_loss": 0.7184423375129699, "training_acc": 43.0, "val_loss": 0.6939323043823242, "val_acc": 52.0}
{"epoch": 5, "training_loss": 0.7146289253234863, "training_acc": 53.0, "val_loss": 0.6982380843162537, "val_acc": 52.0}
{"epoch": 6, "training_loss": 0.7123479866981506, "training_acc": 43.0, "val_loss": 0.69243488073349, "val_acc": 52.0}
{"epoch": 7, "training_loss": 0.7401805472373962, "training_acc": 53.0, "val_loss": 0.7079483604431153, "val_acc": 52.0}
{"epoch": 8, "training_loss": 0.7030311346054077, "training_acc": 45.0, "val_loss": 0.6936543226242066, "val_acc": 52.0}
{"epoch": 9, "training_loss": 0.6994008588790893, "training_acc": 53.0, "val_loss": 0.6930324292182922, "val_acc": 52.0}
{"epoch": 10, "training_loss": 0.6958497524261474, "training_acc": 49.0, "val_loss": 0.6924620699882508, "val_acc": 52.0}
{"epoch": 11, "training_loss": 0.7111754083633423, "training_acc": 53.0, "val_loss": 0.694886703491211, "val_acc": 52.0}
{"epoch": 12, "training_loss": 0.6933371210098267, "training_acc": 53.0, "val_loss": 0.6923991894721985, "val_acc": 52.0}
{"epoch": 13, "training_loss": 0.6919448041915893, "training_acc": 53.0, "val_loss": 0.6924135518074036, "val_acc": 52.0}
{"epoch": 14, "training_loss": 0.6968070411682129, "training_acc": 53.0, "val_loss": 0.6935110092163086, "val_acc": 52.0}
{"epoch": 15, "training_loss": 0.6949596500396729, "training_acc": 53.0, "val_loss": 0.6927634119987488, "val_acc": 52.0}
{"epoch": 16, "training_loss": 0.6964605236053467, "training_acc": 53.0, "val_loss": 0.6925642228126526, "val_acc": 52.0}
{"epoch": 17, "training_loss": 0.7003116345405579, "training_acc": 51.0, "val_loss": 0.6948222041130065, "val_acc": 48.0}
{"epoch": 18, "training_loss": 0.6909024429321289, "training_acc": 51.0, "val_loss": 0.6986750841140748, "val_acc": 52.0}
{"epoch": 19, "training_loss": 0.6978096294403077, "training_acc": 53.0, "val_loss": 0.694507532119751, "val_acc": 52.0}
{"epoch": 20, "training_loss": 0.6982089138031006, "training_acc": 53.0, "val_loss": 0.6931365084648132, "val_acc": 52.0}
{"epoch": 21, "training_loss": 0.6899761533737183, "training_acc": 53.0, "val_loss": 0.6961128735542297, "val_acc": 48.0}
{"epoch": 22, "training_loss": 0.6984757328033447, "training_acc": 45.0, "val_loss": 0.6923746514320374, "val_acc": 52.0}
{"epoch": 23, "training_loss": 0.7029324007034302, "training_acc": 41.0, "val_loss": 0.69407555103302, "val_acc": 52.0}
{"epoch": 24, "training_loss": 0.7284373807907104, "training_acc": 53.0, "val_loss": 0.7018412804603577, "val_acc": 52.0}
{"epoch": 25, "training_loss": 0.6852720260620118, "training_acc": 53.0, "val_loss": 0.7046630597114563, "val_acc": 48.0}
{"epoch": 26, "training_loss": 0.7059686398506164, "training_acc": 45.0, "val_loss": 0.6927049088478089, "val_acc": 52.0}
{"epoch": 27, "training_loss": 0.6961039304733276, "training_acc": 45.0, "val_loss": 0.692356436252594, "val_acc": 52.0}
{"epoch": 28, "training_loss": 0.6996863293647766, "training_acc": 47.0, "val_loss": 0.692604992389679, "val_acc": 52.0}
{"epoch": 29, "training_loss": 0.7176272535324096, "training_acc": 53.0, "val_loss": 0.7030940055847168, "val_acc": 52.0}
{"epoch": 30, "training_loss": 0.6911739325523376, "training_acc": 53.0, "val_loss": 0.6966751670837402, "val_acc": 48.0}
{"epoch": 31, "training_loss": 0.7153042769432068, "training_acc": 45.0, "val_loss": 0.6924244379997253, "val_acc": 52.0}
{"epoch": 32, "training_loss": 0.698216655254364, "training_acc": 45.0, "val_loss": 0.692869234085083, "val_acc": 52.0}
{"epoch": 33, "training_loss": 0.7054731607437134, "training_acc": 53.0, "val_loss": 0.6925535488128662, "val_acc": 52.0}
{"epoch": 34, "training_loss": 0.7007240867614746, "training_acc": 41.0, "val_loss": 0.6937482380867004, "val_acc": 48.0}
{"epoch": 35, "training_loss": 0.7041501688957215, "training_acc": 49.0, "val_loss": 0.6932984733581543, "val_acc": 52.0}
{"epoch": 36, "training_loss": 0.6960683012008667, "training_acc": 53.0, "val_loss": 0.7016154527664185, "val_acc": 52.0}
{"epoch": 37, "training_loss": 0.7052054166793823, "training_acc": 45.0, "val_loss": 0.693841028213501, "val_acc": 48.0}
{"epoch": 38, "training_loss": 0.7167887187004089, "training_acc": 45.0, "val_loss": 0.6926163721084595, "val_acc": 52.0}
{"epoch": 39, "training_loss": 0.7002575778961182, "training_acc": 47.0, "val_loss": 0.6923473906517029, "val_acc": 52.0}
{"epoch": 40, "training_loss": 0.7007378411293029, "training_acc": 53.0, "val_loss": 0.6951961469650269, "val_acc": 52.0}
{"epoch": 41, "training_loss": 0.6953177833557129, "training_acc": 53.0, "val_loss": 0.6937521529197693, "val_acc": 52.0}
{"epoch": 42, "training_loss": 0.6951935958862304, "training_acc": 53.0, "val_loss": 0.6925940442085267, "val_acc": 52.0}
{"epoch": 43, "training_loss": 0.7092120099067688, "training_acc": 53.0, "val_loss": 0.6927427124977111, "val_acc": 52.0}
{"epoch": 44, "training_loss": 0.7138639688491821, "training_acc": 43.0, "val_loss": 0.6948409652709961, "val_acc": 48.0}
{"epoch": 45, "training_loss": 0.6908432674407959, "training_acc": 55.0, "val_loss": 0.6999384260177612, "val_acc": 52.0}
{"epoch": 46, "training_loss": 0.7097783279418945, "training_acc": 41.0, "val_loss": 0.6925980806350708, "val_acc": 52.0}
{"epoch": 47, "training_loss": 0.6971083331108093, "training_acc": 53.0, "val_loss": 0.7000174379348755, "val_acc": 52.0}
{"epoch": 48, "training_loss": 0.7017996454238892, "training_acc": 53.0, "val_loss": 0.693167040348053, "val_acc": 52.0}
{"epoch": 49, "training_loss": 0.7058121109008789, "training_acc": 45.0, "val_loss": 0.6926728367805481, "val_acc": 52.0}
{"epoch": 50, "training_loss": 0.6940436935424805, "training_acc": 45.0, "val_loss": 0.6985730934143066, "val_acc": 52.0}
{"epoch": 51, "training_loss": 0.6943131494522095, "training_acc": 53.0, "val_loss": 0.6924619388580322, "val_acc": 52.0}
{"epoch": 52, "training_loss": 0.7175676512718201, "training_acc": 45.0, "val_loss": 0.6923487401008606, "val_acc": 52.0}
{"epoch": 53, "training_loss": 0.7088763952255249, "training_acc": 53.0, "val_loss": 0.7020941925048828, "val_acc": 52.0}
{"epoch": 54, "training_loss": 0.7018043041229248, "training_acc": 53.0, "val_loss": 0.6924362182617188, "val_acc": 52.0}
{"epoch": 55, "training_loss": 0.6937219643592835, "training_acc": 51.0, "val_loss": 0.6968668627738953, "val_acc": 48.0}
{"epoch": 56, "training_loss": 0.7013144683837891, "training_acc": 37.0, "val_loss": 0.6924303889274597, "val_acc": 52.0}
{"epoch": 57, "training_loss": 0.6952827215194702, "training_acc": 53.0, "val_loss": 0.6949358916282654, "val_acc": 52.0}
{"epoch": 58, "training_loss": 0.7018518137931824, "training_acc": 45.0, "val_loss": 0.6946597003936767, "val_acc": 52.0}
