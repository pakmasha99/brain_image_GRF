"main_modify.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 2 --task ABCD_sex --input_option BT_org --learning_rate 1e-3 --batch_size 16 --weight_decay 1e-3 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 0.7154339528083802, "training_acc": 50.0, "val_loss": 0.7052585411071778, "val_acc": 52.0}
{"epoch": 1, "training_loss": 0.6986139440536498, "training_acc": 53.0, "val_loss": 0.6937111091613769, "val_acc": 48.0}
{"epoch": 2, "training_loss": 0.7041095876693726, "training_acc": 49.0, "val_loss": 0.6927591753005982, "val_acc": 52.0}
{"epoch": 3, "training_loss": 0.6994084358215332, "training_acc": 47.0, "val_loss": 0.6927389860153198, "val_acc": 52.0}
{"epoch": 4, "training_loss": 0.7040100193023682, "training_acc": 53.0, "val_loss": 0.6929956841468811, "val_acc": 52.0}
{"epoch": 5, "training_loss": 0.7088257241249084, "training_acc": 41.0, "val_loss": 0.692390444278717, "val_acc": 52.0}
{"epoch": 6, "training_loss": 0.6974862146377564, "training_acc": 53.0, "val_loss": 0.6955553841590881, "val_acc": 52.0}
{"epoch": 7, "training_loss": 0.6931950616836547, "training_acc": 53.0, "val_loss": 0.6924676251411438, "val_acc": 52.0}
{"epoch": 8, "training_loss": 0.6938424158096314, "training_acc": 53.0, "val_loss": 0.6923719334602356, "val_acc": 52.0}
{"epoch": 9, "training_loss": 0.7148413848876953, "training_acc": 43.0, "val_loss": 0.6927329635620117, "val_acc": 52.0}
{"epoch": 10, "training_loss": 0.7005007219314575, "training_acc": 53.0, "val_loss": 0.6972979164123535, "val_acc": 52.0}
{"epoch": 11, "training_loss": 0.6960309672355652, "training_acc": 53.0, "val_loss": 0.6927171778678894, "val_acc": 52.0}
{"epoch": 12, "training_loss": 0.7037242078781127, "training_acc": 53.0, "val_loss": 0.6924973249435424, "val_acc": 52.0}
{"epoch": 13, "training_loss": 0.7017253875732422, "training_acc": 45.0, "val_loss": 0.692388277053833, "val_acc": 52.0}
{"epoch": 14, "training_loss": 0.695915253162384, "training_acc": 53.0, "val_loss": 0.6933915066719055, "val_acc": 52.0}
{"epoch": 15, "training_loss": 0.6948338079452515, "training_acc": 49.0, "val_loss": 0.6930572962760926, "val_acc": 52.0}
{"epoch": 16, "training_loss": 0.7176144218444824, "training_acc": 53.0, "val_loss": 0.6963548755645752, "val_acc": 52.0}
{"epoch": 17, "training_loss": 0.697561457157135, "training_acc": 45.0, "val_loss": 0.6954554271697998, "val_acc": 48.0}
{"epoch": 18, "training_loss": 0.6975808572769165, "training_acc": 45.0, "val_loss": 0.6925895738601685, "val_acc": 52.0}
{"epoch": 19, "training_loss": 0.6954669713973999, "training_acc": 47.0, "val_loss": 0.6935149955749512, "val_acc": 52.0}
{"epoch": 20, "training_loss": 0.7089869356155396, "training_acc": 53.0, "val_loss": 0.6927257108688355, "val_acc": 52.0}
{"epoch": 21, "training_loss": 0.7048746347427368, "training_acc": 45.0, "val_loss": 0.6998204779624939, "val_acc": 48.0}
{"epoch": 22, "training_loss": 0.7029539442062378, "training_acc": 45.0, "val_loss": 0.6924494409561157, "val_acc": 52.0}
{"epoch": 23, "training_loss": 0.7020009756088257, "training_acc": 47.0, "val_loss": 0.697127411365509, "val_acc": 52.0}
{"epoch": 24, "training_loss": 0.7008866882324218, "training_acc": 53.0, "val_loss": 0.702454948425293, "val_acc": 52.0}
{"epoch": 25, "training_loss": 0.6981354188919068, "training_acc": 53.0, "val_loss": 0.6930180406570434, "val_acc": 52.0}
{"epoch": 26, "training_loss": 0.6963761472702026, "training_acc": 53.0, "val_loss": 0.6928165817260742, "val_acc": 52.0}
{"epoch": 27, "training_loss": 0.7026983428001404, "training_acc": 49.0, "val_loss": 0.6923576784133911, "val_acc": 52.0}
{"epoch": 28, "training_loss": 0.7042871952056885, "training_acc": 53.0, "val_loss": 0.7051949763298034, "val_acc": 52.0}
{"epoch": 29, "training_loss": 0.7010923719406128, "training_acc": 47.0, "val_loss": 0.6951794934272766, "val_acc": 52.0}
{"epoch": 30, "training_loss": 0.6962159085273742, "training_acc": 53.0, "val_loss": 0.6986174726486206, "val_acc": 52.0}
{"epoch": 31, "training_loss": 0.6937033414840699, "training_acc": 53.0, "val_loss": 0.7015151977539062, "val_acc": 48.0}
{"epoch": 32, "training_loss": 0.7178793907165527, "training_acc": 47.0, "val_loss": 0.7002028155326844, "val_acc": 48.0}
{"epoch": 33, "training_loss": 0.7093628740310669, "training_acc": 43.0, "val_loss": 0.6930860567092896, "val_acc": 52.0}
{"epoch": 34, "training_loss": 0.699527907371521, "training_acc": 53.0, "val_loss": 0.6939369583129883, "val_acc": 48.0}
{"epoch": 35, "training_loss": 0.7029515123367309, "training_acc": 47.0, "val_loss": 0.6978152871131897, "val_acc": 48.0}
{"epoch": 36, "training_loss": 0.6924023056030273, "training_acc": 51.0, "val_loss": 0.69897864818573, "val_acc": 52.0}
{"epoch": 37, "training_loss": 0.7323434138298035, "training_acc": 53.0, "val_loss": 0.6928835463523865, "val_acc": 52.0}
{"epoch": 38, "training_loss": 0.6911263918876648, "training_acc": 59.0, "val_loss": 0.6992835450172424, "val_acc": 48.0}
{"epoch": 39, "training_loss": 0.6931579113006592, "training_acc": 51.0, "val_loss": 0.7036511921882629, "val_acc": 52.0}
{"epoch": 40, "training_loss": 0.7096804237365723, "training_acc": 53.0, "val_loss": 0.6988778424263, "val_acc": 52.0}
{"epoch": 41, "training_loss": 0.7033305931091308, "training_acc": 43.0, "val_loss": 0.6928106760978698, "val_acc": 52.0}
{"epoch": 42, "training_loss": 0.6976392531394958, "training_acc": 53.0, "val_loss": 0.6927728033065796, "val_acc": 52.0}
{"epoch": 43, "training_loss": 0.6999329471588135, "training_acc": 53.0, "val_loss": 0.6931121373176574, "val_acc": 52.0}
{"epoch": 44, "training_loss": 0.7146131181716919, "training_acc": 47.0, "val_loss": 0.6942111134529114, "val_acc": 48.0}
{"epoch": 45, "training_loss": 0.6932991313934326, "training_acc": 55.0, "val_loss": 0.7011468982696534, "val_acc": 52.0}
{"epoch": 46, "training_loss": 0.6963449716567993, "training_acc": 53.0, "val_loss": 0.6928969836235046, "val_acc": 52.0}
