"main_modify.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 1 --task ABCD_sex --input_option BT_org --learning_rate 1e-4 --batch_size 16 --weight_decay 1e-3 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 0.6958183240890503, "training_acc": 48.0, "val_loss": 0.6889594101905823, "val_acc": 56.0}
{"epoch": 1, "training_loss": 0.6944934272766113, "training_acc": 52.0, "val_loss": 0.6870804977416992, "val_acc": 56.0}
{"epoch": 2, "training_loss": 0.6946735143661499, "training_acc": 52.0, "val_loss": 0.6867346787452697, "val_acc": 56.0}
{"epoch": 3, "training_loss": 0.6971209406852722, "training_acc": 52.0, "val_loss": 0.6895215630531311, "val_acc": 56.0}
{"epoch": 4, "training_loss": 0.692461941242218, "training_acc": 52.0, "val_loss": 0.6908609890937805, "val_acc": 56.0}
{"epoch": 5, "training_loss": 0.695084056854248, "training_acc": 52.0, "val_loss": 0.6917613697052002, "val_acc": 56.0}
{"epoch": 6, "training_loss": 0.6943488049507142, "training_acc": 48.0, "val_loss": 0.6928765439987182, "val_acc": 60.0}
{"epoch": 7, "training_loss": 0.6944633054733277, "training_acc": 52.0, "val_loss": 0.6883206105232239, "val_acc": 56.0}
{"epoch": 8, "training_loss": 0.6969199299812316, "training_acc": 52.0, "val_loss": 0.6897515606880188, "val_acc": 56.0}
{"epoch": 9, "training_loss": 0.693216257095337, "training_acc": 52.0, "val_loss": 0.6960855484008789, "val_acc": 44.0}
{"epoch": 10, "training_loss": 0.6954187536239624, "training_acc": 43.0, "val_loss": 0.6902410960197449, "val_acc": 56.0}
{"epoch": 11, "training_loss": 0.6953709244728088, "training_acc": 39.0, "val_loss": 0.6907290959358215, "val_acc": 56.0}
{"epoch": 12, "training_loss": 0.6926942014694214, "training_acc": 52.0, "val_loss": 0.6880458092689514, "val_acc": 56.0}
{"epoch": 13, "training_loss": 0.6974649524688721, "training_acc": 52.0, "val_loss": 0.6868814659118653, "val_acc": 56.0}
{"epoch": 14, "training_loss": 0.6929870748519897, "training_acc": 52.0, "val_loss": 0.6911448335647583, "val_acc": 56.0}
{"epoch": 15, "training_loss": 0.6951455545425415, "training_acc": 50.0, "val_loss": 0.7003446555137635, "val_acc": 44.0}
{"epoch": 16, "training_loss": 0.6955990862846374, "training_acc": 46.0, "val_loss": 0.6907483696937561, "val_acc": 56.0}
{"epoch": 17, "training_loss": 0.6944962644577026, "training_acc": 52.0, "val_loss": 0.6884816122055054, "val_acc": 56.0}
{"epoch": 18, "training_loss": 0.692652451992035, "training_acc": 52.0, "val_loss": 0.6889709162712098, "val_acc": 56.0}
{"epoch": 19, "training_loss": 0.6945266056060792, "training_acc": 52.0, "val_loss": 0.6869089984893799, "val_acc": 56.0}
{"epoch": 20, "training_loss": 0.6940131592750549, "training_acc": 52.0, "val_loss": 0.6869346356391907, "val_acc": 56.0}
{"epoch": 21, "training_loss": 0.693777232170105, "training_acc": 52.0, "val_loss": 0.68609046459198, "val_acc": 56.0}
{"epoch": 22, "training_loss": 0.6947823786735534, "training_acc": 52.0, "val_loss": 0.6863316726684571, "val_acc": 56.0}
{"epoch": 23, "training_loss": 0.6926560425758361, "training_acc": 52.0, "val_loss": 0.6894173431396484, "val_acc": 56.0}
{"epoch": 24, "training_loss": 0.693138861656189, "training_acc": 48.0, "val_loss": 0.6957310938835144, "val_acc": 44.0}
{"epoch": 25, "training_loss": 0.6948126697540283, "training_acc": 48.0, "val_loss": 0.6958028745651245, "val_acc": 44.0}
{"epoch": 26, "training_loss": 0.6944022560119629, "training_acc": 49.0, "val_loss": 0.6895254993438721, "val_acc": 56.0}
{"epoch": 27, "training_loss": 0.6933314299583435, "training_acc": 46.0, "val_loss": 0.6954308390617371, "val_acc": 44.0}
{"epoch": 28, "training_loss": 0.6964142942428588, "training_acc": 48.0, "val_loss": 0.6970787048339844, "val_acc": 44.0}
{"epoch": 29, "training_loss": 0.6957135725021363, "training_acc": 51.0, "val_loss": 0.6883415961265564, "val_acc": 56.0}
{"epoch": 30, "training_loss": 0.6958744621276856, "training_acc": 44.0, "val_loss": 0.6934736967086792, "val_acc": 44.0}
{"epoch": 31, "training_loss": 0.6944375252723693, "training_acc": 50.0, "val_loss": 0.6895429539680481, "val_acc": 56.0}
{"epoch": 32, "training_loss": 0.6937972187995911, "training_acc": 52.0, "val_loss": 0.6908066129684448, "val_acc": 56.0}
{"epoch": 33, "training_loss": 0.6923007655143738, "training_acc": 51.0, "val_loss": 0.69645738363266, "val_acc": 44.0}
{"epoch": 34, "training_loss": 0.6961444664001465, "training_acc": 42.0, "val_loss": 0.6933784556388854, "val_acc": 44.0}
{"epoch": 35, "training_loss": 0.6951194906234741, "training_acc": 48.0, "val_loss": 0.7002686643600464, "val_acc": 44.0}
{"epoch": 36, "training_loss": 0.6965460443496704, "training_acc": 48.0, "val_loss": 0.6979006910324097, "val_acc": 44.0}
{"epoch": 37, "training_loss": 0.6919798994064331, "training_acc": 52.0, "val_loss": 0.6899383091926574, "val_acc": 56.0}
{"epoch": 38, "training_loss": 0.693493754863739, "training_acc": 52.0, "val_loss": 0.6902215170860291, "val_acc": 56.0}
{"epoch": 39, "training_loss": 0.6942579698562622, "training_acc": 52.0, "val_loss": 0.6902698159217835, "val_acc": 56.0}
{"epoch": 40, "training_loss": 0.6932394528388977, "training_acc": 52.0, "val_loss": 0.6922888231277465, "val_acc": 56.0}
