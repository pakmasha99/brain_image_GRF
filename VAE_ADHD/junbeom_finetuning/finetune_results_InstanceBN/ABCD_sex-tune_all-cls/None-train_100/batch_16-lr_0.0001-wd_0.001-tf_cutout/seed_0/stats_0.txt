"main_modify.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option BT_org --learning_rate 1e-4 --batch_size 16 --weight_decay 1e-3 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 0.6942357325553894, "training_acc": 52.0, "val_loss": 0.6900514769554138, "val_acc": 56.0}
{"epoch": 1, "training_loss": 0.6944023203849793, "training_acc": 52.0, "val_loss": 0.6884342193603515, "val_acc": 56.0}
{"epoch": 2, "training_loss": 0.6956770324707031, "training_acc": 53.0, "val_loss": 0.68755779504776, "val_acc": 56.0}
{"epoch": 3, "training_loss": 0.6972754430770874, "training_acc": 52.0, "val_loss": 0.6870187759399414, "val_acc": 56.0}
{"epoch": 4, "training_loss": 0.6963665294647217, "training_acc": 52.0, "val_loss": 0.6888227033615112, "val_acc": 56.0}
{"epoch": 5, "training_loss": 0.6938409376144409, "training_acc": 52.0, "val_loss": 0.6872035098075867, "val_acc": 56.0}
{"epoch": 6, "training_loss": 0.6944372367858886, "training_acc": 52.0, "val_loss": 0.6888276410102844, "val_acc": 56.0}
{"epoch": 7, "training_loss": 0.6949982929229737, "training_acc": 50.0, "val_loss": 0.6907221579551697, "val_acc": 56.0}
{"epoch": 8, "training_loss": 0.6969004678726196, "training_acc": 52.0, "val_loss": 0.6876255822181702, "val_acc": 56.0}
{"epoch": 9, "training_loss": 0.6949314975738525, "training_acc": 52.0, "val_loss": 0.6917555952072143, "val_acc": 56.0}
{"epoch": 10, "training_loss": 0.694827857017517, "training_acc": 46.0, "val_loss": 0.6959360551834106, "val_acc": 44.0}
{"epoch": 11, "training_loss": 0.6923546838760376, "training_acc": 53.0, "val_loss": 0.6874386596679688, "val_acc": 56.0}
{"epoch": 12, "training_loss": 0.7009102535247803, "training_acc": 52.0, "val_loss": 0.6858717846870422, "val_acc": 56.0}
{"epoch": 13, "training_loss": 0.6964085388183594, "training_acc": 52.0, "val_loss": 0.6878043293952942, "val_acc": 56.0}
{"epoch": 14, "training_loss": 0.693658766746521, "training_acc": 52.0, "val_loss": 0.6874408531188965, "val_acc": 56.0}
{"epoch": 15, "training_loss": 0.6939320087432861, "training_acc": 52.0, "val_loss": 0.6883233594894409, "val_acc": 56.0}
{"epoch": 16, "training_loss": 0.6971411657333374, "training_acc": 52.0, "val_loss": 0.6858929777145386, "val_acc": 56.0}
{"epoch": 17, "training_loss": 0.693854968547821, "training_acc": 52.0, "val_loss": 0.6917544651031494, "val_acc": 56.0}
{"epoch": 18, "training_loss": 0.6936556220054626, "training_acc": 52.0, "val_loss": 0.696114468574524, "val_acc": 44.0}
{"epoch": 19, "training_loss": 0.6968639826774597, "training_acc": 48.0, "val_loss": 0.695044937133789, "val_acc": 44.0}
{"epoch": 20, "training_loss": 0.6921925067901611, "training_acc": 49.0, "val_loss": 0.6877006077766419, "val_acc": 56.0}
{"epoch": 21, "training_loss": 0.6930870032310485, "training_acc": 52.0, "val_loss": 0.6876991939544678, "val_acc": 56.0}
{"epoch": 22, "training_loss": 0.6949972248077393, "training_acc": 52.0, "val_loss": 0.6872239398956299, "val_acc": 56.0}
{"epoch": 23, "training_loss": 0.6915752124786377, "training_acc": 52.0, "val_loss": 0.6908037996292115, "val_acc": 56.0}
{"epoch": 24, "training_loss": 0.6948029136657715, "training_acc": 52.0, "val_loss": 0.6873558568954468, "val_acc": 56.0}
{"epoch": 25, "training_loss": 0.6922502517700195, "training_acc": 52.0, "val_loss": 0.6909046673774719, "val_acc": 56.0}
{"epoch": 26, "training_loss": 0.6954286789894104, "training_acc": 52.0, "val_loss": 0.6897929501533508, "val_acc": 56.0}
{"epoch": 27, "training_loss": 0.6926954913139344, "training_acc": 52.0, "val_loss": 0.6911829471588135, "val_acc": 56.0}
{"epoch": 28, "training_loss": 0.6937744283676147, "training_acc": 52.0, "val_loss": 0.6894951295852662, "val_acc": 56.0}
{"epoch": 29, "training_loss": 0.6922873973846435, "training_acc": 52.0, "val_loss": 0.6861826062202454, "val_acc": 56.0}
{"epoch": 30, "training_loss": 0.6991023397445679, "training_acc": 52.0, "val_loss": 0.6856760025024414, "val_acc": 56.0}
{"epoch": 31, "training_loss": 0.698156476020813, "training_acc": 52.0, "val_loss": 0.685588071346283, "val_acc": 56.0}
{"epoch": 32, "training_loss": 0.6960436201095581, "training_acc": 52.0, "val_loss": 0.6854669523239135, "val_acc": 56.0}
{"epoch": 33, "training_loss": 0.6961560392379761, "training_acc": 52.0, "val_loss": 0.685676851272583, "val_acc": 56.0}
{"epoch": 34, "training_loss": 0.6924956607818603, "training_acc": 52.0, "val_loss": 0.6900191736221314, "val_acc": 56.0}
{"epoch": 35, "training_loss": 0.6937181186676026, "training_acc": 48.0, "val_loss": 0.6955069899559021, "val_acc": 44.0}
{"epoch": 36, "training_loss": 0.6931718397140503, "training_acc": 51.0, "val_loss": 0.6892250657081604, "val_acc": 56.0}
{"epoch": 37, "training_loss": 0.692360348701477, "training_acc": 52.0, "val_loss": 0.6863455629348755, "val_acc": 56.0}
{"epoch": 38, "training_loss": 0.6947101163864136, "training_acc": 52.0, "val_loss": 0.6879711890220642, "val_acc": 56.0}
{"epoch": 39, "training_loss": 0.6920257949829102, "training_acc": 52.0, "val_loss": 0.6902544140815735, "val_acc": 56.0}
{"epoch": 40, "training_loss": 0.6955957698822022, "training_acc": 45.0, "val_loss": 0.6923152136802674, "val_acc": 68.0}
{"epoch": 41, "training_loss": 0.6919650912284852, "training_acc": 54.0, "val_loss": 0.6873890924453735, "val_acc": 56.0}
{"epoch": 42, "training_loss": 0.6934573888778687, "training_acc": 52.0, "val_loss": 0.6882459616661072, "val_acc": 56.0}
{"epoch": 43, "training_loss": 0.693605055809021, "training_acc": 52.0, "val_loss": 0.6889231061935425, "val_acc": 56.0}
{"epoch": 44, "training_loss": 0.6951697015762329, "training_acc": 47.0, "val_loss": 0.6943670225143432, "val_acc": 44.0}
{"epoch": 45, "training_loss": 0.6933441972732544, "training_acc": 50.0, "val_loss": 0.6900618720054627, "val_acc": 56.0}
{"epoch": 46, "training_loss": 0.6925197720527649, "training_acc": 52.0, "val_loss": 0.6878750777244568, "val_acc": 56.0}
{"epoch": 47, "training_loss": 0.6931859636306763, "training_acc": 52.0, "val_loss": 0.6868499827384948, "val_acc": 56.0}
{"epoch": 48, "training_loss": 0.6932848572731019, "training_acc": 52.0, "val_loss": 0.6870209240913391, "val_acc": 56.0}
{"epoch": 49, "training_loss": 0.6908119487762451, "training_acc": 52.0, "val_loss": 0.6910467457771301, "val_acc": 56.0}
{"epoch": 50, "training_loss": 0.6945442867279052, "training_acc": 46.0, "val_loss": 0.6968728375434875, "val_acc": 44.0}
{"epoch": 51, "training_loss": 0.6953404569625854, "training_acc": 48.0, "val_loss": 0.6968119359016418, "val_acc": 44.0}
