"main_modify.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 2 --task ABCD_sex --input_option BT_org --learning_rate 1e-4 --batch_size 16 --weight_decay 1e-3 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 0.6952520847320557, "training_acc": 53.0, "val_loss": 0.6939553856849671, "val_acc": 52.0}
{"epoch": 1, "training_loss": 0.695980293750763, "training_acc": 53.0, "val_loss": 0.6931557011604309, "val_acc": 52.0}
{"epoch": 2, "training_loss": 0.6934742021560669, "training_acc": 53.0, "val_loss": 0.6930126214027404, "val_acc": 52.0}
{"epoch": 3, "training_loss": 0.693892958164215, "training_acc": 53.0, "val_loss": 0.6944579744338989, "val_acc": 52.0}
{"epoch": 4, "training_loss": 0.692899513244629, "training_acc": 53.0, "val_loss": 0.6941948437690735, "val_acc": 52.0}
{"epoch": 5, "training_loss": 0.6921443128585816, "training_acc": 53.0, "val_loss": 0.6922346043586731, "val_acc": 52.0}
{"epoch": 6, "training_loss": 0.6967690372467041, "training_acc": 44.0, "val_loss": 0.6920840787887573, "val_acc": 52.0}
{"epoch": 7, "training_loss": 0.695815691947937, "training_acc": 53.0, "val_loss": 0.6927591037750244, "val_acc": 52.0}
{"epoch": 8, "training_loss": 0.6938930821418762, "training_acc": 53.0, "val_loss": 0.6921944355964661, "val_acc": 52.0}
{"epoch": 9, "training_loss": 0.6923584508895874, "training_acc": 53.0, "val_loss": 0.6920897030830383, "val_acc": 52.0}
{"epoch": 10, "training_loss": 0.6914670586585998, "training_acc": 53.0, "val_loss": 0.6933360695838928, "val_acc": 52.0}
{"epoch": 11, "training_loss": 0.6929936027526855, "training_acc": 53.0, "val_loss": 0.6921067333221436, "val_acc": 52.0}
{"epoch": 12, "training_loss": 0.6927139616012573, "training_acc": 53.0, "val_loss": 0.6930178570747375, "val_acc": 52.0}
{"epoch": 13, "training_loss": 0.6917650365829467, "training_acc": 53.0, "val_loss": 0.6929268264770507, "val_acc": 52.0}
{"epoch": 14, "training_loss": 0.6915556645393371, "training_acc": 53.0, "val_loss": 0.6921286106109619, "val_acc": 52.0}
{"epoch": 15, "training_loss": 0.6906968450546265, "training_acc": 53.0, "val_loss": 0.6925027203559876, "val_acc": 52.0}
{"epoch": 16, "training_loss": 0.6913075137138367, "training_acc": 53.0, "val_loss": 0.6914030170440674, "val_acc": 52.0}
{"epoch": 17, "training_loss": 0.6923599815368653, "training_acc": 53.0, "val_loss": 0.691183578968048, "val_acc": 52.0}
{"epoch": 18, "training_loss": 0.6989056634902954, "training_acc": 53.0, "val_loss": 0.6948424053192138, "val_acc": 52.0}
{"epoch": 19, "training_loss": 0.6937140154838563, "training_acc": 53.0, "val_loss": 0.6923526430130005, "val_acc": 52.0}
{"epoch": 20, "training_loss": 0.6921165919303894, "training_acc": 53.0, "val_loss": 0.6909855771064758, "val_acc": 52.0}
{"epoch": 21, "training_loss": 0.6905349183082581, "training_acc": 53.0, "val_loss": 0.6905119252204895, "val_acc": 52.0}
{"epoch": 22, "training_loss": 0.697421932220459, "training_acc": 45.0, "val_loss": 0.6939125084877014, "val_acc": 48.0}
{"epoch": 23, "training_loss": 0.6951940393447876, "training_acc": 51.0, "val_loss": 0.6923244595527649, "val_acc": 52.0}
{"epoch": 24, "training_loss": 0.6924677848815918, "training_acc": 53.0, "val_loss": 0.692061493396759, "val_acc": 52.0}
{"epoch": 25, "training_loss": 0.6943880367279053, "training_acc": 53.0, "val_loss": 0.6918841505050659, "val_acc": 52.0}
{"epoch": 26, "training_loss": 0.689732985496521, "training_acc": 53.0, "val_loss": 0.6947575759887695, "val_acc": 52.0}
{"epoch": 27, "training_loss": 0.69358895778656, "training_acc": 53.0, "val_loss": 0.6958257412910461, "val_acc": 52.0}
{"epoch": 28, "training_loss": 0.6993646574020386, "training_acc": 53.0, "val_loss": 0.6968905258178711, "val_acc": 52.0}
{"epoch": 29, "training_loss": 0.6912495803833008, "training_acc": 53.0, "val_loss": 0.691863739490509, "val_acc": 52.0}
{"epoch": 30, "training_loss": 0.6920519971847534, "training_acc": 53.0, "val_loss": 0.6915935182571411, "val_acc": 52.0}
{"epoch": 31, "training_loss": 0.6919611024856568, "training_acc": 53.0, "val_loss": 0.6909922575950622, "val_acc": 52.0}
{"epoch": 32, "training_loss": 0.6903103876113892, "training_acc": 53.0, "val_loss": 0.6912247848510742, "val_acc": 52.0}
{"epoch": 33, "training_loss": 0.6911715316772461, "training_acc": 53.0, "val_loss": 0.6925911450386047, "val_acc": 52.0}
{"epoch": 34, "training_loss": 0.6921788191795349, "training_acc": 53.0, "val_loss": 0.6980557274818421, "val_acc": 52.0}
{"epoch": 35, "training_loss": 0.6967707276344299, "training_acc": 53.0, "val_loss": 0.696504533290863, "val_acc": 52.0}
{"epoch": 36, "training_loss": 0.6931608319282532, "training_acc": 53.0, "val_loss": 0.6923027801513671, "val_acc": 52.0}
{"epoch": 37, "training_loss": 0.6913229322433472, "training_acc": 53.0, "val_loss": 0.6921680736541748, "val_acc": 52.0}
{"epoch": 38, "training_loss": 0.6925592756271363, "training_acc": 51.0, "val_loss": 0.6938142776489258, "val_acc": 48.0}
{"epoch": 39, "training_loss": 0.6931695222854615, "training_acc": 44.0, "val_loss": 0.6913948345184326, "val_acc": 52.0}
{"epoch": 40, "training_loss": 0.6905846405029297, "training_acc": 53.0, "val_loss": 0.6910472822189331, "val_acc": 52.0}
