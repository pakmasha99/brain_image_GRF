"main_modify.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option BT_org --learning_rate 1e-6 --batch_size 16 --weight_decay 1e-2 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 0.6937785983085633, "training_acc": 46.0, "val_loss": 0.693336718082428, "val_acc": 48.0}
{"epoch": 1, "training_loss": 0.6934317445755005, "training_acc": 47.0, "val_loss": 0.6933171129226685, "val_acc": 48.0}
{"epoch": 2, "training_loss": 0.6935836386680603, "training_acc": 47.0, "val_loss": 0.6932559704780579, "val_acc": 52.0}
{"epoch": 3, "training_loss": 0.6931848502159119, "training_acc": 44.0, "val_loss": 0.69312166929245, "val_acc": 52.0}
{"epoch": 4, "training_loss": 0.6932623863220215, "training_acc": 47.0, "val_loss": 0.6929722332954407, "val_acc": 48.0}
{"epoch": 5, "training_loss": 0.6924551105499268, "training_acc": 57.0, "val_loss": 0.6929160642623902, "val_acc": 52.0}
{"epoch": 6, "training_loss": 0.6924387311935425, "training_acc": 55.0, "val_loss": 0.692913429737091, "val_acc": 48.0}
{"epoch": 7, "training_loss": 0.692216830253601, "training_acc": 53.0, "val_loss": 0.6928589177131653, "val_acc": 52.0}
{"epoch": 8, "training_loss": 0.6917023754119873, "training_acc": 53.0, "val_loss": 0.6928460335731507, "val_acc": 52.0}
{"epoch": 9, "training_loss": 0.6915084886550903, "training_acc": 54.0, "val_loss": 0.692839367389679, "val_acc": 52.0}
{"epoch": 10, "training_loss": 0.6918663763999939, "training_acc": 53.0, "val_loss": 0.6928014254570007, "val_acc": 52.0}
{"epoch": 11, "training_loss": 0.6908500266075134, "training_acc": 53.0, "val_loss": 0.6927925324440003, "val_acc": 52.0}
{"epoch": 12, "training_loss": 0.6911623334884643, "training_acc": 53.0, "val_loss": 0.6927821850776672, "val_acc": 52.0}
{"epoch": 13, "training_loss": 0.6909789657592773, "training_acc": 53.0, "val_loss": 0.6927741289138794, "val_acc": 52.0}
{"epoch": 14, "training_loss": 0.6907852673530579, "training_acc": 53.0, "val_loss": 0.6927575302124024, "val_acc": 52.0}
{"epoch": 15, "training_loss": 0.6908326864242553, "training_acc": 53.0, "val_loss": 0.6927539563179016, "val_acc": 52.0}
{"epoch": 16, "training_loss": 0.6900665044784546, "training_acc": 53.0, "val_loss": 0.6927313256263733, "val_acc": 52.0}
{"epoch": 17, "training_loss": 0.6910009384155273, "training_acc": 53.0, "val_loss": 0.6927116322517395, "val_acc": 52.0}
{"epoch": 18, "training_loss": 0.6905057430267334, "training_acc": 53.0, "val_loss": 0.6926621794700623, "val_acc": 52.0}
{"epoch": 19, "training_loss": 0.690508418083191, "training_acc": 53.0, "val_loss": 0.6926090550422669, "val_acc": 52.0}
{"epoch": 20, "training_loss": 0.6901308870315552, "training_acc": 53.0, "val_loss": 0.6925728273391724, "val_acc": 52.0}
{"epoch": 21, "training_loss": 0.6898285698890686, "training_acc": 53.0, "val_loss": 0.692542359828949, "val_acc": 52.0}
{"epoch": 22, "training_loss": 0.68962153673172, "training_acc": 53.0, "val_loss": 0.6925113320350647, "val_acc": 52.0}
{"epoch": 23, "training_loss": 0.690078649520874, "training_acc": 53.0, "val_loss": 0.6924925231933594, "val_acc": 52.0}
{"epoch": 24, "training_loss": 0.6895886731147766, "training_acc": 53.0, "val_loss": 0.6924851703643798, "val_acc": 52.0}
{"epoch": 25, "training_loss": 0.6897448348999023, "training_acc": 53.0, "val_loss": 0.6924517488479615, "val_acc": 52.0}
{"epoch": 26, "training_loss": 0.6900351285934448, "training_acc": 53.0, "val_loss": 0.6924389672279357, "val_acc": 52.0}
{"epoch": 27, "training_loss": 0.6896443367004395, "training_acc": 53.0, "val_loss": 0.6924319744110108, "val_acc": 52.0}
{"epoch": 28, "training_loss": 0.6892106032371521, "training_acc": 53.0, "val_loss": 0.6924338841438293, "val_acc": 52.0}
{"epoch": 29, "training_loss": 0.6899634528160096, "training_acc": 53.0, "val_loss": 0.6924230599403381, "val_acc": 52.0}
{"epoch": 30, "training_loss": 0.6888541007041931, "training_acc": 53.0, "val_loss": 0.6924180579185486, "val_acc": 52.0}
{"epoch": 31, "training_loss": 0.6894636750221252, "training_acc": 53.0, "val_loss": 0.6923884057998657, "val_acc": 52.0}
{"epoch": 32, "training_loss": 0.6884707927703857, "training_acc": 53.0, "val_loss": 0.6923412680625916, "val_acc": 52.0}
{"epoch": 33, "training_loss": 0.6892084312438965, "training_acc": 53.0, "val_loss": 0.6922200584411621, "val_acc": 52.0}
{"epoch": 34, "training_loss": 0.6889148378372192, "training_acc": 53.0, "val_loss": 0.6921608352661133, "val_acc": 52.0}
{"epoch": 35, "training_loss": 0.6884051179885864, "training_acc": 53.0, "val_loss": 0.6921215748786926, "val_acc": 52.0}
{"epoch": 36, "training_loss": 0.6889241623878479, "training_acc": 53.0, "val_loss": 0.6921034550666809, "val_acc": 52.0}
{"epoch": 37, "training_loss": 0.6885664272308349, "training_acc": 53.0, "val_loss": 0.6921265339851379, "val_acc": 52.0}
{"epoch": 38, "training_loss": 0.688287434577942, "training_acc": 53.0, "val_loss": 0.6921272253990174, "val_acc": 52.0}
{"epoch": 39, "training_loss": 0.6886739492416382, "training_acc": 53.0, "val_loss": 0.6921300101280212, "val_acc": 52.0}
{"epoch": 40, "training_loss": 0.6881477260589599, "training_acc": 53.0, "val_loss": 0.6921540713310241, "val_acc": 52.0}
{"epoch": 41, "training_loss": 0.6879352712631226, "training_acc": 53.0, "val_loss": 0.6921477675437927, "val_acc": 52.0}
{"epoch": 42, "training_loss": 0.6886848711967468, "training_acc": 53.0, "val_loss": 0.69215003490448, "val_acc": 52.0}
{"epoch": 43, "training_loss": 0.6883934211730957, "training_acc": 53.0, "val_loss": 0.6921930623054504, "val_acc": 52.0}
{"epoch": 44, "training_loss": 0.6884645223617554, "training_acc": 53.0, "val_loss": 0.6922679853439331, "val_acc": 52.0}
{"epoch": 45, "training_loss": 0.6877458620071412, "training_acc": 53.0, "val_loss": 0.6922720265388489, "val_acc": 52.0}
{"epoch": 46, "training_loss": 0.6869754910469055, "training_acc": 53.0, "val_loss": 0.692250485420227, "val_acc": 52.0}
{"epoch": 47, "training_loss": 0.6876651453971863, "training_acc": 53.0, "val_loss": 0.6922251963615418, "val_acc": 52.0}
{"epoch": 48, "training_loss": 0.6882225561141968, "training_acc": 53.0, "val_loss": 0.6922464466094971, "val_acc": 52.0}
{"epoch": 49, "training_loss": 0.6881663417816162, "training_acc": 53.0, "val_loss": 0.6922931790351867, "val_acc": 52.0}
{"epoch": 50, "training_loss": 0.6877969932556153, "training_acc": 53.0, "val_loss": 0.6923290228843689, "val_acc": 52.0}
{"epoch": 51, "training_loss": 0.6882563638687134, "training_acc": 53.0, "val_loss": 0.6923718690872193, "val_acc": 52.0}
{"epoch": 52, "training_loss": 0.6876965379714965, "training_acc": 53.0, "val_loss": 0.6924020409584045, "val_acc": 52.0}
{"epoch": 53, "training_loss": 0.6866510820388794, "training_acc": 53.0, "val_loss": 0.6923890995979309, "val_acc": 52.0}
{"epoch": 54, "training_loss": 0.6874629426002502, "training_acc": 53.0, "val_loss": 0.6923937678337098, "val_acc": 52.0}
{"epoch": 55, "training_loss": 0.6870593976974487, "training_acc": 53.0, "val_loss": 0.6923827171325684, "val_acc": 52.0}
