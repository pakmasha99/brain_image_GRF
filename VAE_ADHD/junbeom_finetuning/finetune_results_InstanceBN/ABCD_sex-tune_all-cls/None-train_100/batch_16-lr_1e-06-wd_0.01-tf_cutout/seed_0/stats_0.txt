"main_modify.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option BT_org --learning_rate 1e-6 --batch_size 16 --weight_decay 1e-2 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 0.6922074747085571, "training_acc": 52.0, "val_loss": 0.6899063205718994, "val_acc": 56.0}
{"epoch": 1, "training_loss": 0.6921865892410278, "training_acc": 52.0, "val_loss": 0.6898140287399293, "val_acc": 56.0}
{"epoch": 2, "training_loss": 0.6919573640823364, "training_acc": 52.0, "val_loss": 0.6896856760978699, "val_acc": 56.0}
{"epoch": 3, "training_loss": 0.6920592498779297, "training_acc": 52.0, "val_loss": 0.6895165586471558, "val_acc": 56.0}
{"epoch": 4, "training_loss": 0.6917949867248535, "training_acc": 52.0, "val_loss": 0.6895585465431213, "val_acc": 56.0}
{"epoch": 5, "training_loss": 0.6918257188796997, "training_acc": 52.0, "val_loss": 0.6894616770744324, "val_acc": 56.0}
{"epoch": 6, "training_loss": 0.6918430185317993, "training_acc": 52.0, "val_loss": 0.6893781661987305, "val_acc": 56.0}
{"epoch": 7, "training_loss": 0.6917680931091309, "training_acc": 52.0, "val_loss": 0.6893831706047058, "val_acc": 56.0}
{"epoch": 8, "training_loss": 0.691504955291748, "training_acc": 52.0, "val_loss": 0.6892153286933899, "val_acc": 56.0}
{"epoch": 9, "training_loss": 0.6916331362724304, "training_acc": 52.0, "val_loss": 0.6892004632949829, "val_acc": 56.0}
{"epoch": 10, "training_loss": 0.6918114566802979, "training_acc": 52.0, "val_loss": 0.6893026542663574, "val_acc": 56.0}
{"epoch": 11, "training_loss": 0.6912247180938721, "training_acc": 52.0, "val_loss": 0.6892454266548157, "val_acc": 56.0}
{"epoch": 12, "training_loss": 0.6912979578971863, "training_acc": 52.0, "val_loss": 0.689033191204071, "val_acc": 56.0}
{"epoch": 13, "training_loss": 0.6909937310218811, "training_acc": 52.0, "val_loss": 0.6889748883247375, "val_acc": 56.0}
{"epoch": 14, "training_loss": 0.6910061502456665, "training_acc": 52.0, "val_loss": 0.6889070892333984, "val_acc": 56.0}
{"epoch": 15, "training_loss": 0.6907083082199097, "training_acc": 52.0, "val_loss": 0.6889160346984863, "val_acc": 56.0}
{"epoch": 16, "training_loss": 0.6910599803924561, "training_acc": 52.0, "val_loss": 0.6886892700195313, "val_acc": 56.0}
{"epoch": 17, "training_loss": 0.6906626319885254, "training_acc": 52.0, "val_loss": 0.6886553549766541, "val_acc": 56.0}
{"epoch": 18, "training_loss": 0.6906012582778931, "training_acc": 52.0, "val_loss": 0.6887075757980347, "val_acc": 56.0}
{"epoch": 19, "training_loss": 0.6904115772247315, "training_acc": 52.0, "val_loss": 0.6888274884223938, "val_acc": 56.0}
{"epoch": 20, "training_loss": 0.6907498836517334, "training_acc": 52.0, "val_loss": 0.6887550926208497, "val_acc": 56.0}
{"epoch": 21, "training_loss": 0.6906518697738647, "training_acc": 52.0, "val_loss": 0.6887798738479615, "val_acc": 56.0}
{"epoch": 22, "training_loss": 0.6908468317985534, "training_acc": 52.0, "val_loss": 0.6887582612037658, "val_acc": 56.0}
{"epoch": 23, "training_loss": 0.6904872989654541, "training_acc": 52.0, "val_loss": 0.6888006544113159, "val_acc": 56.0}
{"epoch": 24, "training_loss": 0.6903875732421875, "training_acc": 52.0, "val_loss": 0.6887159705162048, "val_acc": 56.0}
{"epoch": 25, "training_loss": 0.6903903007507324, "training_acc": 52.0, "val_loss": 0.6887549543380738, "val_acc": 56.0}
{"epoch": 26, "training_loss": 0.689943609237671, "training_acc": 52.0, "val_loss": 0.6887328791618347, "val_acc": 56.0}
{"epoch": 27, "training_loss": 0.6898836326599121, "training_acc": 52.0, "val_loss": 0.6887594246864319, "val_acc": 56.0}
{"epoch": 28, "training_loss": 0.689950122833252, "training_acc": 52.0, "val_loss": 0.6887467312812805, "val_acc": 56.0}
{"epoch": 29, "training_loss": 0.6903431177139282, "training_acc": 52.0, "val_loss": 0.6885760450363159, "val_acc": 56.0}
{"epoch": 30, "training_loss": 0.6902091884613037, "training_acc": 52.0, "val_loss": 0.6881973695755005, "val_acc": 56.0}
{"epoch": 31, "training_loss": 0.6900823020935059, "training_acc": 52.0, "val_loss": 0.6879344344139099, "val_acc": 56.0}
{"epoch": 32, "training_loss": 0.6899879550933838, "training_acc": 52.0, "val_loss": 0.6875790977478027, "val_acc": 56.0}
{"epoch": 33, "training_loss": 0.6902167320251464, "training_acc": 52.0, "val_loss": 0.6874495315551757, "val_acc": 56.0}
{"epoch": 34, "training_loss": 0.6900899600982666, "training_acc": 52.0, "val_loss": 0.6875241732597351, "val_acc": 56.0}
{"epoch": 35, "training_loss": 0.689570598602295, "training_acc": 52.0, "val_loss": 0.6876152086257935, "val_acc": 56.0}
{"epoch": 36, "training_loss": 0.6900170421600342, "training_acc": 52.0, "val_loss": 0.6875553154945373, "val_acc": 56.0}
{"epoch": 37, "training_loss": 0.6895587921142579, "training_acc": 52.0, "val_loss": 0.687453203201294, "val_acc": 56.0}
{"epoch": 38, "training_loss": 0.6901276016235351, "training_acc": 52.0, "val_loss": 0.6874781155586243, "val_acc": 56.0}
{"epoch": 39, "training_loss": 0.6896277165412903, "training_acc": 52.0, "val_loss": 0.6875797629356384, "val_acc": 56.0}
{"epoch": 40, "training_loss": 0.6900891327857971, "training_acc": 52.0, "val_loss": 0.6877663373947144, "val_acc": 56.0}
{"epoch": 41, "training_loss": 0.6897165727615356, "training_acc": 52.0, "val_loss": 0.6876850366592407, "val_acc": 56.0}
{"epoch": 42, "training_loss": 0.68920738697052, "training_acc": 52.0, "val_loss": 0.6875406289100647, "val_acc": 56.0}
{"epoch": 43, "training_loss": 0.690079710483551, "training_acc": 52.0, "val_loss": 0.6874136781692505, "val_acc": 56.0}
{"epoch": 44, "training_loss": 0.6895413827896119, "training_acc": 52.0, "val_loss": 0.6875119400024414, "val_acc": 56.0}
{"epoch": 45, "training_loss": 0.689401535987854, "training_acc": 52.0, "val_loss": 0.6875533652305603, "val_acc": 56.0}
{"epoch": 46, "training_loss": 0.6888778829574584, "training_acc": 52.0, "val_loss": 0.687578136920929, "val_acc": 56.0}
{"epoch": 47, "training_loss": 0.6888116836547852, "training_acc": 52.0, "val_loss": 0.6874529385566711, "val_acc": 56.0}
{"epoch": 48, "training_loss": 0.6888326668739319, "training_acc": 52.0, "val_loss": 0.6873235654830933, "val_acc": 56.0}
{"epoch": 49, "training_loss": 0.6890199565887452, "training_acc": 52.0, "val_loss": 0.6872433567047119, "val_acc": 56.0}
{"epoch": 50, "training_loss": 0.6888782787322998, "training_acc": 52.0, "val_loss": 0.6873041367530823, "val_acc": 56.0}
{"epoch": 51, "training_loss": 0.6890860390663147, "training_acc": 52.0, "val_loss": 0.687348575592041, "val_acc": 56.0}
{"epoch": 52, "training_loss": 0.6887828350067139, "training_acc": 52.0, "val_loss": 0.6874765062332153, "val_acc": 56.0}
{"epoch": 53, "training_loss": 0.6891677689552307, "training_acc": 52.0, "val_loss": 0.6875534009933472, "val_acc": 56.0}
{"epoch": 54, "training_loss": 0.6886517763137817, "training_acc": 52.0, "val_loss": 0.687675564289093, "val_acc": 56.0}
{"epoch": 55, "training_loss": 0.6885499668121338, "training_acc": 52.0, "val_loss": 0.6878983664512635, "val_acc": 56.0}
{"epoch": 56, "training_loss": 0.6891011238098145, "training_acc": 52.0, "val_loss": 0.6880640459060668, "val_acc": 56.0}
{"epoch": 57, "training_loss": 0.6889918160438537, "training_acc": 52.0, "val_loss": 0.6881825089454651, "val_acc": 56.0}
{"epoch": 58, "training_loss": 0.6886140203475952, "training_acc": 52.0, "val_loss": 0.6879570960998536, "val_acc": 56.0}
{"epoch": 59, "training_loss": 0.6888913059234619, "training_acc": 52.0, "val_loss": 0.6875826740264892, "val_acc": 56.0}
{"epoch": 60, "training_loss": 0.6890028190612792, "training_acc": 52.0, "val_loss": 0.687117931842804, "val_acc": 56.0}
{"epoch": 61, "training_loss": 0.6883553647994995, "training_acc": 52.0, "val_loss": 0.6870933151245118, "val_acc": 56.0}
{"epoch": 62, "training_loss": 0.6889117789268494, "training_acc": 52.0, "val_loss": 0.687093575000763, "val_acc": 56.0}
{"epoch": 63, "training_loss": 0.6887886142730713, "training_acc": 52.0, "val_loss": 0.687199764251709, "val_acc": 56.0}
{"epoch": 64, "training_loss": 0.6884818077087402, "training_acc": 52.0, "val_loss": 0.6872240424156189, "val_acc": 56.0}
{"epoch": 65, "training_loss": 0.6880398297309875, "training_acc": 52.0, "val_loss": 0.6872980499267578, "val_acc": 56.0}
{"epoch": 66, "training_loss": 0.6877798914909363, "training_acc": 52.0, "val_loss": 0.6870697784423828, "val_acc": 56.0}
{"epoch": 67, "training_loss": 0.6883987951278686, "training_acc": 52.0, "val_loss": 0.6869413566589355, "val_acc": 56.0}
{"epoch": 68, "training_loss": 0.6879094266891479, "training_acc": 52.0, "val_loss": 0.6870223927497864, "val_acc": 56.0}
{"epoch": 69, "training_loss": 0.6883465075492858, "training_acc": 52.0, "val_loss": 0.6870505452156067, "val_acc": 56.0}
{"epoch": 70, "training_loss": 0.6879969310760498, "training_acc": 52.0, "val_loss": 0.6868768310546876, "val_acc": 56.0}
{"epoch": 71, "training_loss": 0.6883426666259765, "training_acc": 52.0, "val_loss": 0.6867602252960205, "val_acc": 56.0}
{"epoch": 72, "training_loss": 0.6884999299049377, "training_acc": 52.0, "val_loss": 0.6868630290031433, "val_acc": 56.0}
{"epoch": 73, "training_loss": 0.6878178596496582, "training_acc": 52.0, "val_loss": 0.6869604063034057, "val_acc": 56.0}
{"epoch": 74, "training_loss": 0.6884121131896973, "training_acc": 52.0, "val_loss": 0.6868250393867492, "val_acc": 56.0}
{"epoch": 75, "training_loss": 0.6879610180854797, "training_acc": 52.0, "val_loss": 0.6866785645484924, "val_acc": 56.0}
{"epoch": 76, "training_loss": 0.6880360555648803, "training_acc": 52.0, "val_loss": 0.686602213382721, "val_acc": 56.0}
{"epoch": 77, "training_loss": 0.6879118108749389, "training_acc": 52.0, "val_loss": 0.6863991117477417, "val_acc": 56.0}
{"epoch": 78, "training_loss": 0.6874233436584473, "training_acc": 52.0, "val_loss": 0.6861678695678711, "val_acc": 56.0}
{"epoch": 79, "training_loss": 0.6877153277397156, "training_acc": 52.0, "val_loss": 0.6859655690193176, "val_acc": 56.0}
{"epoch": 80, "training_loss": 0.6878858613967895, "training_acc": 52.0, "val_loss": 0.6857493495941163, "val_acc": 56.0}
{"epoch": 81, "training_loss": 0.6875427174568176, "training_acc": 52.0, "val_loss": 0.6855294895172119, "val_acc": 56.0}
{"epoch": 82, "training_loss": 0.6881249332427979, "training_acc": 52.0, "val_loss": 0.6853970432281494, "val_acc": 56.0}
{"epoch": 83, "training_loss": 0.6876316618919373, "training_acc": 52.0, "val_loss": 0.6853677892684936, "val_acc": 56.0}
{"epoch": 84, "training_loss": 0.6873464059829711, "training_acc": 52.0, "val_loss": 0.6854152488708496, "val_acc": 56.0}
{"epoch": 85, "training_loss": 0.6873617243766784, "training_acc": 52.0, "val_loss": 0.6855182385444641, "val_acc": 56.0}
{"epoch": 86, "training_loss": 0.687915506362915, "training_acc": 52.0, "val_loss": 0.6855989694595337, "val_acc": 56.0}
{"epoch": 87, "training_loss": 0.687353458404541, "training_acc": 52.0, "val_loss": 0.6856939506530761, "val_acc": 56.0}
{"epoch": 88, "training_loss": 0.6881046032905579, "training_acc": 52.0, "val_loss": 0.6856396508216858, "val_acc": 56.0}
{"epoch": 89, "training_loss": 0.6875993299484253, "training_acc": 52.0, "val_loss": 0.6855868101119995, "val_acc": 56.0}
{"epoch": 90, "training_loss": 0.6873453164100647, "training_acc": 52.0, "val_loss": 0.6855796551704407, "val_acc": 56.0}
{"epoch": 91, "training_loss": 0.6870231103897094, "training_acc": 52.0, "val_loss": 0.6854974627494812, "val_acc": 56.0}
{"epoch": 92, "training_loss": 0.6868369007110595, "training_acc": 52.0, "val_loss": 0.6853878712654113, "val_acc": 56.0}
{"epoch": 93, "training_loss": 0.6874041390419007, "training_acc": 52.0, "val_loss": 0.6853264665603638, "val_acc": 56.0}
{"epoch": 94, "training_loss": 0.6877096033096314, "training_acc": 52.0, "val_loss": 0.685312385559082, "val_acc": 56.0}
{"epoch": 95, "training_loss": 0.687388482093811, "training_acc": 52.0, "val_loss": 0.6853309726715088, "val_acc": 56.0}
{"epoch": 96, "training_loss": 0.687641773223877, "training_acc": 52.0, "val_loss": 0.6854475212097167, "val_acc": 56.0}
{"epoch": 97, "training_loss": 0.686601345539093, "training_acc": 52.0, "val_loss": 0.6854473495483399, "val_acc": 56.0}
{"epoch": 98, "training_loss": 0.6875400733947754, "training_acc": 52.0, "val_loss": 0.6851730751991272, "val_acc": 56.0}
{"epoch": 99, "training_loss": 0.6873013663291931, "training_acc": 52.0, "val_loss": 0.6851309132575989, "val_acc": 56.0}
