"main_modify.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 1 --task ABCD_sex --input_option BT_org --learning_rate 1e-6 --batch_size 16 --weight_decay 1e-2 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 0.6935797643661499, "training_acc": 47.0, "val_loss": 0.6932441878318787, "val_acc": 44.0}
{"epoch": 1, "training_loss": 0.6930995965003968, "training_acc": 50.0, "val_loss": 0.6931558656692505, "val_acc": 48.0}
{"epoch": 2, "training_loss": 0.6930635643005371, "training_acc": 50.0, "val_loss": 0.6929599976539612, "val_acc": 56.0}
{"epoch": 3, "training_loss": 0.6927015781402588, "training_acc": 54.0, "val_loss": 0.6930645298957825, "val_acc": 52.0}
{"epoch": 4, "training_loss": 0.6930838251113891, "training_acc": 52.0, "val_loss": 0.6928704881668091, "val_acc": 56.0}
{"epoch": 5, "training_loss": 0.693038682937622, "training_acc": 49.0, "val_loss": 0.6930567860603333, "val_acc": 52.0}
{"epoch": 6, "training_loss": 0.6924869966506958, "training_acc": 55.0, "val_loss": 0.6928295087814331, "val_acc": 48.0}
{"epoch": 7, "training_loss": 0.69237309217453, "training_acc": 53.0, "val_loss": 0.6927839589118957, "val_acc": 48.0}
{"epoch": 8, "training_loss": 0.6925131273269653, "training_acc": 54.0, "val_loss": 0.6927457809448242, "val_acc": 48.0}
{"epoch": 9, "training_loss": 0.6924010848999024, "training_acc": 53.0, "val_loss": 0.6926396107673645, "val_acc": 52.0}
{"epoch": 10, "training_loss": 0.6920682954788208, "training_acc": 54.0, "val_loss": 0.6924260640144348, "val_acc": 56.0}
{"epoch": 11, "training_loss": 0.6922034215927124, "training_acc": 51.0, "val_loss": 0.6924921131134033, "val_acc": 56.0}
{"epoch": 12, "training_loss": 0.6923299789428711, "training_acc": 54.0, "val_loss": 0.6923233795166016, "val_acc": 56.0}
{"epoch": 13, "training_loss": 0.692190318107605, "training_acc": 52.0, "val_loss": 0.692134063243866, "val_acc": 56.0}
{"epoch": 14, "training_loss": 0.6919577431678772, "training_acc": 52.0, "val_loss": 0.6919357824325562, "val_acc": 56.0}
{"epoch": 15, "training_loss": 0.69168123960495, "training_acc": 52.0, "val_loss": 0.6916426277160644, "val_acc": 56.0}
{"epoch": 16, "training_loss": 0.6917683124542237, "training_acc": 52.0, "val_loss": 0.6912853741645812, "val_acc": 56.0}
{"epoch": 17, "training_loss": 0.6916144752502441, "training_acc": 52.0, "val_loss": 0.6911455106735229, "val_acc": 56.0}
{"epoch": 18, "training_loss": 0.6913574481010437, "training_acc": 52.0, "val_loss": 0.6911420345306396, "val_acc": 56.0}
{"epoch": 19, "training_loss": 0.6912703418731689, "training_acc": 52.0, "val_loss": 0.6909154057502747, "val_acc": 56.0}
{"epoch": 20, "training_loss": 0.690968108177185, "training_acc": 52.0, "val_loss": 0.6907700037956238, "val_acc": 56.0}
{"epoch": 21, "training_loss": 0.6910937356948853, "training_acc": 52.0, "val_loss": 0.690652425289154, "val_acc": 56.0}
{"epoch": 22, "training_loss": 0.6912772607803345, "training_acc": 52.0, "val_loss": 0.6906019616127014, "val_acc": 56.0}
{"epoch": 23, "training_loss": 0.6912704229354858, "training_acc": 52.0, "val_loss": 0.690324923992157, "val_acc": 56.0}
{"epoch": 24, "training_loss": 0.690833899974823, "training_acc": 52.0, "val_loss": 0.6901759362220764, "val_acc": 56.0}
{"epoch": 25, "training_loss": 0.6911421632766723, "training_acc": 52.0, "val_loss": 0.6903119230270386, "val_acc": 56.0}
{"epoch": 26, "training_loss": 0.6902648997306824, "training_acc": 52.0, "val_loss": 0.6902466320991516, "val_acc": 56.0}
{"epoch": 27, "training_loss": 0.6900425481796265, "training_acc": 52.0, "val_loss": 0.6900700187683105, "val_acc": 56.0}
{"epoch": 28, "training_loss": 0.6911030435562133, "training_acc": 52.0, "val_loss": 0.6896208190917968, "val_acc": 56.0}
{"epoch": 29, "training_loss": 0.6904735231399536, "training_acc": 52.0, "val_loss": 0.6893642783164978, "val_acc": 56.0}
{"epoch": 30, "training_loss": 0.6900814485549926, "training_acc": 52.0, "val_loss": 0.6892280268669129, "val_acc": 56.0}
{"epoch": 31, "training_loss": 0.6905766153335571, "training_acc": 52.0, "val_loss": 0.6890332484245301, "val_acc": 56.0}
{"epoch": 32, "training_loss": 0.6908674931526184, "training_acc": 52.0, "val_loss": 0.6890630459785462, "val_acc": 56.0}
{"epoch": 33, "training_loss": 0.690301353931427, "training_acc": 52.0, "val_loss": 0.6887688827514649, "val_acc": 56.0}
{"epoch": 34, "training_loss": 0.6907895183563233, "training_acc": 52.0, "val_loss": 0.688578941822052, "val_acc": 56.0}
{"epoch": 35, "training_loss": 0.690357141494751, "training_acc": 52.0, "val_loss": 0.6887678527832031, "val_acc": 56.0}
{"epoch": 36, "training_loss": 0.6902610349655152, "training_acc": 52.0, "val_loss": 0.6886575484275818, "val_acc": 56.0}
{"epoch": 37, "training_loss": 0.6893890810012817, "training_acc": 52.0, "val_loss": 0.6883447766304016, "val_acc": 56.0}
{"epoch": 38, "training_loss": 0.6897840023040771, "training_acc": 52.0, "val_loss": 0.6882296800613403, "val_acc": 56.0}
{"epoch": 39, "training_loss": 0.6899081754684449, "training_acc": 52.0, "val_loss": 0.6881322431564331, "val_acc": 56.0}
{"epoch": 40, "training_loss": 0.6890475010871887, "training_acc": 52.0, "val_loss": 0.6879627323150634, "val_acc": 56.0}
{"epoch": 41, "training_loss": 0.6908871841430664, "training_acc": 52.0, "val_loss": 0.6881128883361817, "val_acc": 56.0}
{"epoch": 42, "training_loss": 0.6893141031265259, "training_acc": 52.0, "val_loss": 0.6879765701293945, "val_acc": 56.0}
{"epoch": 43, "training_loss": 0.6899916863441468, "training_acc": 52.0, "val_loss": 0.6877729845046997, "val_acc": 56.0}
{"epoch": 44, "training_loss": 0.6896030569076538, "training_acc": 52.0, "val_loss": 0.6882470321655273, "val_acc": 56.0}
{"epoch": 45, "training_loss": 0.6896458649635315, "training_acc": 52.0, "val_loss": 0.6883690595626831, "val_acc": 56.0}
{"epoch": 46, "training_loss": 0.6892060542106628, "training_acc": 52.0, "val_loss": 0.6881527781486512, "val_acc": 56.0}
{"epoch": 47, "training_loss": 0.6897608661651611, "training_acc": 52.0, "val_loss": 0.6881839466094971, "val_acc": 56.0}
{"epoch": 48, "training_loss": 0.6899340772628784, "training_acc": 52.0, "val_loss": 0.6882445240020751, "val_acc": 56.0}
{"epoch": 49, "training_loss": 0.6891237592697144, "training_acc": 52.0, "val_loss": 0.6885078024864196, "val_acc": 56.0}
{"epoch": 50, "training_loss": 0.6894896078109741, "training_acc": 52.0, "val_loss": 0.6881878900527955, "val_acc": 56.0}
{"epoch": 51, "training_loss": 0.6893922281265259, "training_acc": 52.0, "val_loss": 0.6879862642288208, "val_acc": 56.0}
{"epoch": 52, "training_loss": 0.6894657492637635, "training_acc": 52.0, "val_loss": 0.687968602180481, "val_acc": 56.0}
{"epoch": 53, "training_loss": 0.6891194081306458, "training_acc": 52.0, "val_loss": 0.6879892659187317, "val_acc": 56.0}
{"epoch": 54, "training_loss": 0.6883600234985352, "training_acc": 52.0, "val_loss": 0.6875883340835571, "val_acc": 56.0}
{"epoch": 55, "training_loss": 0.6890196657180786, "training_acc": 52.0, "val_loss": 0.6874589967727661, "val_acc": 56.0}
{"epoch": 56, "training_loss": 0.6891609477996826, "training_acc": 52.0, "val_loss": 0.6876382756233216, "val_acc": 56.0}
{"epoch": 57, "training_loss": 0.6887714481353759, "training_acc": 52.0, "val_loss": 0.6874445772171021, "val_acc": 56.0}
{"epoch": 58, "training_loss": 0.6888421511650086, "training_acc": 52.0, "val_loss": 0.6876045870780945, "val_acc": 56.0}
{"epoch": 59, "training_loss": 0.6899247121810913, "training_acc": 52.0, "val_loss": 0.687747163772583, "val_acc": 56.0}
{"epoch": 60, "training_loss": 0.6894623112678527, "training_acc": 52.0, "val_loss": 0.6877535390853882, "val_acc": 56.0}
{"epoch": 61, "training_loss": 0.6887161731719971, "training_acc": 52.0, "val_loss": 0.6877203440666199, "val_acc": 56.0}
{"epoch": 62, "training_loss": 0.6890873980522155, "training_acc": 52.0, "val_loss": 0.6880452394485473, "val_acc": 56.0}
{"epoch": 63, "training_loss": 0.6883228063583374, "training_acc": 52.0, "val_loss": 0.6884542036056519, "val_acc": 56.0}
{"epoch": 64, "training_loss": 0.6886978554725647, "training_acc": 52.0, "val_loss": 0.6891360259056092, "val_acc": 56.0}
{"epoch": 65, "training_loss": 0.6889116239547729, "training_acc": 52.0, "val_loss": 0.6891173481941223, "val_acc": 56.0}
{"epoch": 66, "training_loss": 0.6890826940536499, "training_acc": 52.0, "val_loss": 0.688995041847229, "val_acc": 56.0}
{"epoch": 67, "training_loss": 0.6882792568206787, "training_acc": 52.0, "val_loss": 0.6884904813766479, "val_acc": 56.0}
{"epoch": 68, "training_loss": 0.689272997379303, "training_acc": 52.0, "val_loss": 0.6878895211219788, "val_acc": 56.0}
{"epoch": 69, "training_loss": 0.6886264061927796, "training_acc": 52.0, "val_loss": 0.6877395939826966, "val_acc": 56.0}
{"epoch": 70, "training_loss": 0.6883557629585266, "training_acc": 52.0, "val_loss": 0.6877404904365539, "val_acc": 56.0}
{"epoch": 71, "training_loss": 0.6882000374794006, "training_acc": 52.0, "val_loss": 0.6878423738479614, "val_acc": 56.0}
{"epoch": 72, "training_loss": 0.6888526368141175, "training_acc": 52.0, "val_loss": 0.6881507444381714, "val_acc": 56.0}
{"epoch": 73, "training_loss": 0.6888393759727478, "training_acc": 52.0, "val_loss": 0.6880714893341064, "val_acc": 56.0}
{"epoch": 74, "training_loss": 0.6881700420379638, "training_acc": 52.0, "val_loss": 0.6881905841827393, "val_acc": 56.0}
{"epoch": 75, "training_loss": 0.6886964535713196, "training_acc": 52.0, "val_loss": 0.6887459588050843, "val_acc": 56.0}
{"epoch": 76, "training_loss": 0.68797785282135, "training_acc": 52.0, "val_loss": 0.6884621453285217, "val_acc": 56.0}
