"main_modify.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 1 --task ABCD_sex --input_option BT_org --learning_rate 1e-6 --batch_size 16 --weight_decay 1e-2 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 0.6933738613128662, "training_acc": 48.0, "val_loss": 0.6936312532424926, "val_acc": 48.0}
{"epoch": 1, "training_loss": 0.6937390232086181, "training_acc": 47.0, "val_loss": 0.6935871577262879, "val_acc": 48.0}
{"epoch": 2, "training_loss": 0.6934027624130249, "training_acc": 47.0, "val_loss": 0.6933061909675599, "val_acc": 48.0}
{"epoch": 3, "training_loss": 0.6935123825073242, "training_acc": 47.0, "val_loss": 0.6932406282424927, "val_acc": 48.0}
{"epoch": 4, "training_loss": 0.6931228733062744, "training_acc": 50.0, "val_loss": 0.6928690004348755, "val_acc": 56.0}
{"epoch": 5, "training_loss": 0.6927273607254029, "training_acc": 56.0, "val_loss": 0.6927154088020324, "val_acc": 60.0}
{"epoch": 6, "training_loss": 0.6924669504165649, "training_acc": 56.0, "val_loss": 0.6925108766555786, "val_acc": 52.0}
{"epoch": 7, "training_loss": 0.6924362707138062, "training_acc": 54.0, "val_loss": 0.6923762249946595, "val_acc": 52.0}
{"epoch": 8, "training_loss": 0.6920554971694947, "training_acc": 54.0, "val_loss": 0.6922203278541565, "val_acc": 52.0}
{"epoch": 9, "training_loss": 0.6924290227890014, "training_acc": 53.0, "val_loss": 0.6921815919876099, "val_acc": 52.0}
{"epoch": 10, "training_loss": 0.6914575266838073, "training_acc": 53.0, "val_loss": 0.6922509956359864, "val_acc": 52.0}
{"epoch": 11, "training_loss": 0.69125892162323, "training_acc": 52.0, "val_loss": 0.6922327184677124, "val_acc": 52.0}
{"epoch": 12, "training_loss": 0.6912394452095032, "training_acc": 53.0, "val_loss": 0.6921332621574402, "val_acc": 52.0}
{"epoch": 13, "training_loss": 0.6910413670539856, "training_acc": 53.0, "val_loss": 0.6919703435897827, "val_acc": 52.0}
{"epoch": 14, "training_loss": 0.6913189935684204, "training_acc": 53.0, "val_loss": 0.6918350338935852, "val_acc": 52.0}
{"epoch": 15, "training_loss": 0.6905425643920898, "training_acc": 53.0, "val_loss": 0.6917266798019409, "val_acc": 52.0}
{"epoch": 16, "training_loss": 0.6908027839660644, "training_acc": 53.0, "val_loss": 0.6917730951309204, "val_acc": 52.0}
{"epoch": 17, "training_loss": 0.6908723545074463, "training_acc": 53.0, "val_loss": 0.6916043519973755, "val_acc": 52.0}
{"epoch": 18, "training_loss": 0.6908675932884216, "training_acc": 53.0, "val_loss": 0.6916412878036499, "val_acc": 52.0}
{"epoch": 19, "training_loss": 0.6900123929977418, "training_acc": 53.0, "val_loss": 0.6915739130973816, "val_acc": 52.0}
{"epoch": 20, "training_loss": 0.6899268960952759, "training_acc": 53.0, "val_loss": 0.6915905833244324, "val_acc": 52.0}
{"epoch": 21, "training_loss": 0.6903038883209228, "training_acc": 53.0, "val_loss": 0.6913603329658509, "val_acc": 52.0}
{"epoch": 22, "training_loss": 0.6907795143127441, "training_acc": 53.0, "val_loss": 0.6913203883171082, "val_acc": 52.0}
{"epoch": 23, "training_loss": 0.6903206157684326, "training_acc": 53.0, "val_loss": 0.6913455247879028, "val_acc": 52.0}
{"epoch": 24, "training_loss": 0.6899567747116089, "training_acc": 53.0, "val_loss": 0.6914232206344605, "val_acc": 52.0}
{"epoch": 25, "training_loss": 0.6908048391342163, "training_acc": 53.0, "val_loss": 0.6916461563110352, "val_acc": 52.0}
{"epoch": 26, "training_loss": 0.6898603105545044, "training_acc": 53.0, "val_loss": 0.691536991596222, "val_acc": 52.0}
{"epoch": 27, "training_loss": 0.6895380020141602, "training_acc": 53.0, "val_loss": 0.6914440846443176, "val_acc": 52.0}
{"epoch": 28, "training_loss": 0.6887763857841491, "training_acc": 53.0, "val_loss": 0.6914474606513977, "val_acc": 52.0}
{"epoch": 29, "training_loss": 0.6897132635116577, "training_acc": 53.0, "val_loss": 0.6916057920455932, "val_acc": 52.0}
{"epoch": 30, "training_loss": 0.6885183334350586, "training_acc": 53.0, "val_loss": 0.6915613865852356, "val_acc": 52.0}
{"epoch": 31, "training_loss": 0.6892204070091248, "training_acc": 53.0, "val_loss": 0.6914799952507019, "val_acc": 52.0}
{"epoch": 32, "training_loss": 0.6889465761184692, "training_acc": 53.0, "val_loss": 0.6914396333694458, "val_acc": 52.0}
{"epoch": 33, "training_loss": 0.688393292427063, "training_acc": 53.0, "val_loss": 0.6912004423141479, "val_acc": 52.0}
{"epoch": 34, "training_loss": 0.689465787410736, "training_acc": 53.0, "val_loss": 0.6911543130874633, "val_acc": 52.0}
{"epoch": 35, "training_loss": 0.6892148661613464, "training_acc": 53.0, "val_loss": 0.6910944771766663, "val_acc": 52.0}
{"epoch": 36, "training_loss": 0.6882224941253662, "training_acc": 53.0, "val_loss": 0.6909517025947571, "val_acc": 52.0}
{"epoch": 37, "training_loss": 0.6897909998893738, "training_acc": 53.0, "val_loss": 0.6909547138214112, "val_acc": 52.0}
{"epoch": 38, "training_loss": 0.6885864448547363, "training_acc": 53.0, "val_loss": 0.6910458731651307, "val_acc": 52.0}
{"epoch": 39, "training_loss": 0.6881245708465576, "training_acc": 53.0, "val_loss": 0.6912529492378234, "val_acc": 52.0}
{"epoch": 40, "training_loss": 0.6888155102729797, "training_acc": 53.0, "val_loss": 0.6911803817749024, "val_acc": 52.0}
{"epoch": 41, "training_loss": 0.6886909198760987, "training_acc": 53.0, "val_loss": 0.6912064480781556, "val_acc": 52.0}
{"epoch": 42, "training_loss": 0.6885065627098084, "training_acc": 53.0, "val_loss": 0.6910888218879699, "val_acc": 52.0}
{"epoch": 43, "training_loss": 0.6885755157470703, "training_acc": 53.0, "val_loss": 0.6911578249931335, "val_acc": 52.0}
{"epoch": 44, "training_loss": 0.6887078666687012, "training_acc": 53.0, "val_loss": 0.6910413837432862, "val_acc": 52.0}
{"epoch": 45, "training_loss": 0.6891669869422913, "training_acc": 53.0, "val_loss": 0.6909936308860779, "val_acc": 52.0}
{"epoch": 46, "training_loss": 0.6892015647888183, "training_acc": 53.0, "val_loss": 0.6911420464515686, "val_acc": 52.0}
{"epoch": 47, "training_loss": 0.6889185738563538, "training_acc": 53.0, "val_loss": 0.6912337613105773, "val_acc": 52.0}
{"epoch": 48, "training_loss": 0.6880514025688171, "training_acc": 53.0, "val_loss": 0.6912827801704406, "val_acc": 52.0}
{"epoch": 49, "training_loss": 0.6876565170288086, "training_acc": 53.0, "val_loss": 0.6914523959159851, "val_acc": 52.0}
{"epoch": 50, "training_loss": 0.689035530090332, "training_acc": 53.0, "val_loss": 0.6914560770988465, "val_acc": 52.0}
{"epoch": 51, "training_loss": 0.6886404418945312, "training_acc": 53.0, "val_loss": 0.6914097929000854, "val_acc": 52.0}
{"epoch": 52, "training_loss": 0.6882493591308594, "training_acc": 53.0, "val_loss": 0.6913799405097961, "val_acc": 52.0}
{"epoch": 53, "training_loss": 0.6880710458755493, "training_acc": 53.0, "val_loss": 0.6913761568069458, "val_acc": 52.0}
{"epoch": 54, "training_loss": 0.6884702491760254, "training_acc": 53.0, "val_loss": 0.691164357662201, "val_acc": 52.0}
{"epoch": 55, "training_loss": 0.6878863120079041, "training_acc": 53.0, "val_loss": 0.6910618901252746, "val_acc": 52.0}
