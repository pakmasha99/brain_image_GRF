"main_modify.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option BT_org --learning_rate 5e-4 --batch_size 16 --weight_decay 5e-3 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 0.7000704884529114, "training_acc": 49.0, "val_loss": 0.6932739591598511, "val_acc": 52.0}
{"epoch": 1, "training_loss": 0.7121654844284058, "training_acc": 47.0, "val_loss": 0.69360995054245, "val_acc": 48.0}
{"epoch": 2, "training_loss": 0.6991373634338379, "training_acc": 47.0, "val_loss": 0.692393651008606, "val_acc": 52.0}
{"epoch": 3, "training_loss": 0.7006531047821045, "training_acc": 53.0, "val_loss": 0.6926282215118408, "val_acc": 52.0}
{"epoch": 4, "training_loss": 0.6965940308570862, "training_acc": 53.0, "val_loss": 0.6927299189567566, "val_acc": 52.0}
{"epoch": 5, "training_loss": 0.6957771229743958, "training_acc": 53.0, "val_loss": 0.6928205466270447, "val_acc": 52.0}
{"epoch": 6, "training_loss": 0.6963752508163452, "training_acc": 53.0, "val_loss": 0.6941509175300599, "val_acc": 52.0}
{"epoch": 7, "training_loss": 0.6949717044830322, "training_acc": 53.0, "val_loss": 0.6924287867546082, "val_acc": 52.0}
{"epoch": 8, "training_loss": 0.7015767955780029, "training_acc": 46.0, "val_loss": 0.6961866402626038, "val_acc": 52.0}
{"epoch": 9, "training_loss": 0.697969741821289, "training_acc": 53.0, "val_loss": 0.694021418094635, "val_acc": 52.0}
{"epoch": 10, "training_loss": 0.6950507235527038, "training_acc": 53.0, "val_loss": 0.693365318775177, "val_acc": 48.0}
{"epoch": 11, "training_loss": 0.7102010655403137, "training_acc": 45.0, "val_loss": 0.6926556491851806, "val_acc": 52.0}
{"epoch": 12, "training_loss": 0.7007734584808349, "training_acc": 53.0, "val_loss": 0.6952744078636169, "val_acc": 52.0}
{"epoch": 13, "training_loss": 0.6970741009712219, "training_acc": 53.0, "val_loss": 0.692345895767212, "val_acc": 52.0}
{"epoch": 14, "training_loss": 0.7028230953216553, "training_acc": 45.0, "val_loss": 0.694758768081665, "val_acc": 48.0}
{"epoch": 15, "training_loss": 0.699290976524353, "training_acc": 41.0, "val_loss": 0.6927109861373901, "val_acc": 52.0}
{"epoch": 16, "training_loss": 0.7002980899810791, "training_acc": 53.0, "val_loss": 0.6994243335723876, "val_acc": 52.0}
{"epoch": 17, "training_loss": 0.7016857481002807, "training_acc": 53.0, "val_loss": 0.6929004096984863, "val_acc": 52.0}
{"epoch": 18, "training_loss": 0.6940487098693847, "training_acc": 53.0, "val_loss": 0.69409423828125, "val_acc": 48.0}
{"epoch": 19, "training_loss": 0.7001745486259461, "training_acc": 49.0, "val_loss": 0.6923906064033508, "val_acc": 52.0}
{"epoch": 20, "training_loss": 0.693970308303833, "training_acc": 49.0, "val_loss": 0.6923194861412049, "val_acc": 52.0}
{"epoch": 21, "training_loss": 0.6990182876586915, "training_acc": 43.0, "val_loss": 0.6942499089241028, "val_acc": 52.0}
{"epoch": 22, "training_loss": 0.6971834683418274, "training_acc": 53.0, "val_loss": 0.6931468939781189, "val_acc": 52.0}
{"epoch": 23, "training_loss": 0.7035999250411987, "training_acc": 39.0, "val_loss": 0.6923710989952088, "val_acc": 52.0}
{"epoch": 24, "training_loss": 0.6921637368202209, "training_acc": 53.0, "val_loss": 0.6935177206993103, "val_acc": 52.0}
{"epoch": 25, "training_loss": 0.7073595190048217, "training_acc": 35.0, "val_loss": 0.6924118304252624, "val_acc": 52.0}
{"epoch": 26, "training_loss": 0.698496150970459, "training_acc": 53.0, "val_loss": 0.6928612661361694, "val_acc": 52.0}
{"epoch": 27, "training_loss": 0.690046968460083, "training_acc": 53.0, "val_loss": 0.6938267874717713, "val_acc": 48.0}
{"epoch": 28, "training_loss": 0.7004439020156861, "training_acc": 47.0, "val_loss": 0.6924476599693299, "val_acc": 52.0}
{"epoch": 29, "training_loss": 0.6988139915466308, "training_acc": 53.0, "val_loss": 0.6939326047897338, "val_acc": 52.0}
{"epoch": 30, "training_loss": 0.6941722846031189, "training_acc": 53.0, "val_loss": 0.6923827385902405, "val_acc": 52.0}
{"epoch": 31, "training_loss": 0.6947327089309693, "training_acc": 53.0, "val_loss": 0.692641727924347, "val_acc": 52.0}
{"epoch": 32, "training_loss": 0.6932619524002075, "training_acc": 53.0, "val_loss": 0.6940643310546875, "val_acc": 52.0}
{"epoch": 33, "training_loss": 0.6938481211662293, "training_acc": 53.0, "val_loss": 0.6953662419319153, "val_acc": 52.0}
{"epoch": 34, "training_loss": 0.6947722482681274, "training_acc": 53.0, "val_loss": 0.6947936630249023, "val_acc": 52.0}
{"epoch": 35, "training_loss": 0.6918148446083069, "training_acc": 53.0, "val_loss": 0.6936271977424622, "val_acc": 48.0}
{"epoch": 36, "training_loss": 0.7004531145095825, "training_acc": 47.0, "val_loss": 0.6928017950057983, "val_acc": 52.0}
{"epoch": 37, "training_loss": 0.6932050132751465, "training_acc": 53.0, "val_loss": 0.6927474331855774, "val_acc": 52.0}
{"epoch": 38, "training_loss": 0.6940588569641113, "training_acc": 47.0, "val_loss": 0.6945687222480774, "val_acc": 52.0}
{"epoch": 39, "training_loss": 0.697029025554657, "training_acc": 53.0, "val_loss": 0.6933233761787414, "val_acc": 52.0}
