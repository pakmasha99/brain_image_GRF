"main_modify.py --pretrained_path /scratch/connectome/dyhan316/VAE_ADHD/barlowtwins/pretrain_results/ABCDbt128a102.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 1 --task ABCD_sex --input_option BT_org --learning_rate 1e-3 --batch_size 16 --weight_decay 1e-4 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 0.711548810005188, "training_acc": 48.0, "val_loss": 0.7054717063903808, "val_acc": 52.0}
{"epoch": 1, "training_loss": 0.7142947840690613, "training_acc": 53.0, "val_loss": 0.7106904673576355, "val_acc": 52.0}
{"epoch": 2, "training_loss": 0.7047560119628906, "training_acc": 53.0, "val_loss": 0.6945272278785706, "val_acc": 52.0}
{"epoch": 3, "training_loss": 0.7043904852867127, "training_acc": 45.0, "val_loss": 0.6931942749023438, "val_acc": 52.0}
{"epoch": 4, "training_loss": 0.6990697288513184, "training_acc": 45.0, "val_loss": 0.6944928383827209, "val_acc": 52.0}
{"epoch": 5, "training_loss": 0.7118868494033813, "training_acc": 53.0, "val_loss": 0.7027415537834167, "val_acc": 52.0}
{"epoch": 6, "training_loss": 0.6982253122329712, "training_acc": 53.0, "val_loss": 0.6947468900680542, "val_acc": 48.0}
{"epoch": 7, "training_loss": 0.7045944285392761, "training_acc": 47.0, "val_loss": 0.6929959034919739, "val_acc": 52.0}
{"epoch": 8, "training_loss": 0.6920640802383423, "training_acc": 53.0, "val_loss": 0.6973795771598816, "val_acc": 52.0}
{"epoch": 9, "training_loss": 0.6981609725952148, "training_acc": 53.0, "val_loss": 0.6923602604866028, "val_acc": 52.0}
{"epoch": 10, "training_loss": 0.7089578223228454, "training_acc": 43.0, "val_loss": 0.6934653782844543, "val_acc": 48.0}
{"epoch": 11, "training_loss": 0.6920686173439026, "training_acc": 55.0, "val_loss": 0.6991282963752746, "val_acc": 52.0}
{"epoch": 12, "training_loss": 0.6996341872215271, "training_acc": 53.0, "val_loss": 0.6952170109748841, "val_acc": 52.0}
{"epoch": 13, "training_loss": 0.6920913505554199, "training_acc": 53.0, "val_loss": 0.6951263070106506, "val_acc": 48.0}
{"epoch": 14, "training_loss": 0.7143659496307373, "training_acc": 47.0, "val_loss": 0.6950391125679016, "val_acc": 48.0}
{"epoch": 15, "training_loss": 0.7308054971694946, "training_acc": 45.0, "val_loss": 0.6992722296714783, "val_acc": 52.0}
{"epoch": 16, "training_loss": 0.6931720685958862, "training_acc": 51.0, "val_loss": 0.6949125266075135, "val_acc": 48.0}
{"epoch": 17, "training_loss": 0.6940353083610534, "training_acc": 49.0, "val_loss": 0.6943380665779114, "val_acc": 52.0}
{"epoch": 18, "training_loss": 0.6951612758636475, "training_acc": 47.0, "val_loss": 0.6932292604446411, "val_acc": 48.0}
{"epoch": 19, "training_loss": 0.689468822479248, "training_acc": 55.0, "val_loss": 0.6976555371284485, "val_acc": 52.0}
{"epoch": 20, "training_loss": 0.7055823826789855, "training_acc": 53.0, "val_loss": 0.6932221460342407, "val_acc": 52.0}
{"epoch": 21, "training_loss": 0.6951155161857605, "training_acc": 53.0, "val_loss": 0.69572350025177, "val_acc": 52.0}
{"epoch": 22, "training_loss": 0.7036532998085022, "training_acc": 53.0, "val_loss": 0.6954284167289734, "val_acc": 52.0}
{"epoch": 23, "training_loss": 0.6959307026863099, "training_acc": 51.0, "val_loss": 0.7028588771820068, "val_acc": 48.0}
{"epoch": 24, "training_loss": 0.704098129272461, "training_acc": 49.0, "val_loss": 0.6954266881942749, "val_acc": 52.0}
{"epoch": 25, "training_loss": 0.7013968443870544, "training_acc": 53.0, "val_loss": 0.7204431557655334, "val_acc": 52.0}
{"epoch": 26, "training_loss": 0.7082250380516052, "training_acc": 53.0, "val_loss": 0.6924709463119507, "val_acc": 52.0}
{"epoch": 27, "training_loss": 0.7046710896492004, "training_acc": 53.0, "val_loss": 0.6929651665687561, "val_acc": 52.0}
{"epoch": 28, "training_loss": 0.7210871887207031, "training_acc": 43.0, "val_loss": 0.6988674163818359, "val_acc": 48.0}
