"main_modify.py --pretrained_path /scratch/connectome/dyhan316/VAE_ADHD/barlowtwins/pretrain_results/ABCDbt128a102.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 1 --task ABCD_sex --input_option BT_org --learning_rate 1e-3 --batch_size 16 --weight_decay 1e-4 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 0.722024393081665, "training_acc": 53.0, "val_loss": 0.6952718305587768, "val_acc": 52.0}
{"epoch": 1, "training_loss": 0.6932180976867676, "training_acc": 53.0, "val_loss": 0.7019400405883789, "val_acc": 48.0}
{"epoch": 2, "training_loss": 0.6962344837188721, "training_acc": 49.0, "val_loss": 0.6936834740638733, "val_acc": 52.0}
{"epoch": 3, "training_loss": 0.6998629283905029, "training_acc": 53.0, "val_loss": 0.6926742744445801, "val_acc": 52.0}
{"epoch": 4, "training_loss": 0.7030662727355957, "training_acc": 47.0, "val_loss": 0.6927550983428955, "val_acc": 52.0}
{"epoch": 5, "training_loss": 0.7123249673843384, "training_acc": 53.0, "val_loss": 0.6925588274002075, "val_acc": 52.0}
{"epoch": 6, "training_loss": 0.7239221000671386, "training_acc": 45.0, "val_loss": 0.6959393644332885, "val_acc": 48.0}
{"epoch": 7, "training_loss": 0.6894058847427368, "training_acc": 53.0, "val_loss": 0.6998805522918701, "val_acc": 52.0}
{"epoch": 8, "training_loss": 0.6980525779724122, "training_acc": 53.0, "val_loss": 0.6930526375770569, "val_acc": 52.0}
{"epoch": 9, "training_loss": 0.6948938989639282, "training_acc": 51.0, "val_loss": 0.6935437393188476, "val_acc": 48.0}
{"epoch": 10, "training_loss": 0.6946942138671875, "training_acc": 49.0, "val_loss": 0.6929743528366089, "val_acc": 52.0}
{"epoch": 11, "training_loss": 0.6924684071540832, "training_acc": 53.0, "val_loss": 0.692416079044342, "val_acc": 52.0}
{"epoch": 12, "training_loss": 0.6933309984207153, "training_acc": 53.0, "val_loss": 0.6923879671096802, "val_acc": 52.0}
{"epoch": 13, "training_loss": 0.6928224658966065, "training_acc": 53.0, "val_loss": 0.6936082005500793, "val_acc": 52.0}
{"epoch": 14, "training_loss": 0.695458927154541, "training_acc": 47.0, "val_loss": 0.6939948582649231, "val_acc": 48.0}
{"epoch": 15, "training_loss": 0.6939538764953613, "training_acc": 49.0, "val_loss": 0.6933762788772583, "val_acc": 52.0}
{"epoch": 16, "training_loss": 0.6992724370956421, "training_acc": 53.0, "val_loss": 0.7068459153175354, "val_acc": 52.0}
{"epoch": 17, "training_loss": 0.7037251472473145, "training_acc": 47.0, "val_loss": 0.6939719772338867, "val_acc": 48.0}
{"epoch": 18, "training_loss": 0.69772310256958, "training_acc": 43.0, "val_loss": 0.6923677182197571, "val_acc": 52.0}
{"epoch": 19, "training_loss": 0.6922060012817383, "training_acc": 53.0, "val_loss": 0.69234126329422, "val_acc": 52.0}
{"epoch": 20, "training_loss": 0.6937309551239014, "training_acc": 53.0, "val_loss": 0.6923489046096801, "val_acc": 52.0}
{"epoch": 21, "training_loss": 0.6943063044548035, "training_acc": 53.0, "val_loss": 0.6933131122589111, "val_acc": 52.0}
{"epoch": 22, "training_loss": 0.6936289024353027, "training_acc": 53.0, "val_loss": 0.6949406909942627, "val_acc": 52.0}
{"epoch": 23, "training_loss": 0.7043280458450317, "training_acc": 53.0, "val_loss": 0.6949311923980713, "val_acc": 52.0}
{"epoch": 24, "training_loss": 0.7074114894866943, "training_acc": 41.0, "val_loss": 0.6925406670570373, "val_acc": 52.0}
{"epoch": 25, "training_loss": 0.6962954115867614, "training_acc": 53.0, "val_loss": 0.7063902354240418, "val_acc": 52.0}
{"epoch": 26, "training_loss": 0.7132916402816772, "training_acc": 53.0, "val_loss": 0.6984891057014465, "val_acc": 52.0}
{"epoch": 27, "training_loss": 0.696502857208252, "training_acc": 53.0, "val_loss": 0.6958244419097901, "val_acc": 52.0}
{"epoch": 28, "training_loss": 0.6913983464241028, "training_acc": 55.0, "val_loss": 0.6993961548805236, "val_acc": 48.0}
{"epoch": 29, "training_loss": 0.7075365114212037, "training_acc": 45.0, "val_loss": 0.6928292012214661, "val_acc": 52.0}
{"epoch": 30, "training_loss": 0.7122788262367249, "training_acc": 53.0, "val_loss": 0.6963659787178039, "val_acc": 52.0}
{"epoch": 31, "training_loss": 0.6975009155273437, "training_acc": 49.0, "val_loss": 0.6924412560462951, "val_acc": 52.0}
{"epoch": 32, "training_loss": 0.7015165090560913, "training_acc": 53.0, "val_loss": 0.7071168684959411, "val_acc": 52.0}
{"epoch": 33, "training_loss": 0.7037155437469482, "training_acc": 53.0, "val_loss": 0.6925992369651794, "val_acc": 52.0}
{"epoch": 34, "training_loss": 0.7069604873657227, "training_acc": 47.0, "val_loss": 0.6986705422401428, "val_acc": 48.0}
{"epoch": 35, "training_loss": 0.6918327498435974, "training_acc": 55.0, "val_loss": 0.7074489283561707, "val_acc": 52.0}
{"epoch": 36, "training_loss": 0.7085597491264344, "training_acc": 53.0, "val_loss": 0.6923653388023376, "val_acc": 52.0}
{"epoch": 37, "training_loss": 0.7149720335006714, "training_acc": 43.0, "val_loss": 0.6941879796981811, "val_acc": 48.0}
{"epoch": 38, "training_loss": 0.6853905439376831, "training_acc": 57.0, "val_loss": 0.7035393524169922, "val_acc": 52.0}
