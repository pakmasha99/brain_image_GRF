"main_modify.py --pretrained_path /scratch/connectome/dyhan316/VAE_ADHD/barlowtwins/pretrain_results/ABCDbt128a102.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 1 --task ABCD_sex --input_option BT_org --learning_rate 1e-3 --batch_size 16 --weight_decay 1e-4 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 0.6972486257553101, "training_acc": 53.0, "val_loss": 0.7182792615890503, "val_acc": 52.0}
{"epoch": 1, "training_loss": 0.7099756622314453, "training_acc": 53.0, "val_loss": 0.6959073543548584, "val_acc": 48.0}
{"epoch": 2, "training_loss": 0.7263517308235169, "training_acc": 47.0, "val_loss": 0.6937878108024598, "val_acc": 52.0}
{"epoch": 3, "training_loss": 0.7175114178657531, "training_acc": 53.0, "val_loss": 0.7058700966835022, "val_acc": 52.0}
{"epoch": 4, "training_loss": 0.7170889186859131, "training_acc": 43.0, "val_loss": 0.6962425231933593, "val_acc": 48.0}
{"epoch": 5, "training_loss": 0.7342134380340576, "training_acc": 47.0, "val_loss": 0.7114928436279296, "val_acc": 52.0}
{"epoch": 6, "training_loss": 0.70320641040802, "training_acc": 53.0, "val_loss": 0.6923768734931945, "val_acc": 52.0}
{"epoch": 7, "training_loss": 0.6950370860099793, "training_acc": 53.0, "val_loss": 0.6929465818405152, "val_acc": 52.0}
{"epoch": 8, "training_loss": 0.694706563949585, "training_acc": 53.0, "val_loss": 0.6928810143470764, "val_acc": 52.0}
{"epoch": 9, "training_loss": 0.7095091724395752, "training_acc": 53.0, "val_loss": 0.6951885652542115, "val_acc": 52.0}
{"epoch": 10, "training_loss": 0.694019923210144, "training_acc": 53.0, "val_loss": 0.692447280883789, "val_acc": 52.0}
{"epoch": 11, "training_loss": 0.692005877494812, "training_acc": 53.0, "val_loss": 0.6924544858932495, "val_acc": 52.0}
{"epoch": 12, "training_loss": 0.6950404167175293, "training_acc": 53.0, "val_loss": 0.6935143828392029, "val_acc": 52.0}
{"epoch": 13, "training_loss": 0.6937098670005798, "training_acc": 53.0, "val_loss": 0.6927108335494995, "val_acc": 52.0}
{"epoch": 14, "training_loss": 0.6951631164550781, "training_acc": 53.0, "val_loss": 0.6924968028068542, "val_acc": 52.0}
{"epoch": 15, "training_loss": 0.698038239479065, "training_acc": 43.0, "val_loss": 0.6948253083229065, "val_acc": 48.0}
{"epoch": 16, "training_loss": 0.6902628755569458, "training_acc": 51.0, "val_loss": 0.6968021321296692, "val_acc": 52.0}
{"epoch": 17, "training_loss": 0.6978363084793091, "training_acc": 53.0, "val_loss": 0.6964775371551514, "val_acc": 52.0}
{"epoch": 18, "training_loss": 0.6975293707847595, "training_acc": 53.0, "val_loss": 0.6936481475830079, "val_acc": 52.0}
{"epoch": 19, "training_loss": 0.6895383977890015, "training_acc": 53.0, "val_loss": 0.6992082071304321, "val_acc": 48.0}
{"epoch": 20, "training_loss": 0.7008974146842957, "training_acc": 45.0, "val_loss": 0.6936527943611145, "val_acc": 52.0}
{"epoch": 21, "training_loss": 0.7042151546478271, "training_acc": 41.0, "val_loss": 0.6925624108314514, "val_acc": 52.0}
{"epoch": 22, "training_loss": 0.7285689496994019, "training_acc": 53.0, "val_loss": 0.7084270024299621, "val_acc": 52.0}
{"epoch": 23, "training_loss": 0.6832106113433838, "training_acc": 53.0, "val_loss": 0.7025055956840515, "val_acc": 48.0}
{"epoch": 24, "training_loss": 0.7064000272750854, "training_acc": 45.0, "val_loss": 0.6939151883125305, "val_acc": 48.0}
{"epoch": 25, "training_loss": 0.696915192604065, "training_acc": 45.0, "val_loss": 0.6925535392761231, "val_acc": 52.0}
{"epoch": 26, "training_loss": 0.697385823726654, "training_acc": 45.0, "val_loss": 0.6923516011238098, "val_acc": 52.0}
{"epoch": 27, "training_loss": 0.7119167137145996, "training_acc": 53.0, "val_loss": 0.7052284932136536, "val_acc": 52.0}
{"epoch": 28, "training_loss": 0.6923921203613281, "training_acc": 53.0, "val_loss": 0.6942322492599488, "val_acc": 48.0}
{"epoch": 29, "training_loss": 0.7143180656433106, "training_acc": 47.0, "val_loss": 0.6936638855934143, "val_acc": 48.0}
{"epoch": 30, "training_loss": 0.6949044728279113, "training_acc": 43.0, "val_loss": 0.6926131772994996, "val_acc": 52.0}
{"epoch": 31, "training_loss": 0.7056345653533935, "training_acc": 53.0, "val_loss": 0.6960563564300537, "val_acc": 52.0}
{"epoch": 32, "training_loss": 0.6964302492141724, "training_acc": 53.0, "val_loss": 0.6942822217941285, "val_acc": 48.0}
{"epoch": 33, "training_loss": 0.704938759803772, "training_acc": 47.0, "val_loss": 0.6928494572639465, "val_acc": 52.0}
{"epoch": 34, "training_loss": 0.6918671584129333, "training_acc": 53.0, "val_loss": 0.7032879567146302, "val_acc": 52.0}
{"epoch": 35, "training_loss": 0.7020065927505493, "training_acc": 53.0, "val_loss": 0.6925124669075012, "val_acc": 52.0}
{"epoch": 36, "training_loss": 0.7035139775276185, "training_acc": 53.0, "val_loss": 0.6928393650054931, "val_acc": 52.0}
{"epoch": 37, "training_loss": 0.7017595982551574, "training_acc": 45.0, "val_loss": 0.6929550862312317, "val_acc": 52.0}
{"epoch": 38, "training_loss": 0.6945468139648437, "training_acc": 53.0, "val_loss": 0.6968388295173645, "val_acc": 52.0}
{"epoch": 39, "training_loss": 0.6949693775177002, "training_acc": 53.0, "val_loss": 0.6932380390167237, "val_acc": 52.0}
{"epoch": 40, "training_loss": 0.6943625545501709, "training_acc": 53.0, "val_loss": 0.6923580741882325, "val_acc": 52.0}
{"epoch": 41, "training_loss": 0.703254668712616, "training_acc": 53.0, "val_loss": 0.6946399641036988, "val_acc": 52.0}
{"epoch": 42, "training_loss": 0.7057474994659424, "training_acc": 45.0, "val_loss": 0.6968595647811889, "val_acc": 48.0}
{"epoch": 43, "training_loss": 0.690935869216919, "training_acc": 51.0, "val_loss": 0.6959872770309449, "val_acc": 52.0}
{"epoch": 44, "training_loss": 0.7003133153915405, "training_acc": 53.0, "val_loss": 0.6923847246170044, "val_acc": 52.0}
{"epoch": 45, "training_loss": 0.6935395741462708, "training_acc": 53.0, "val_loss": 0.6945753407478332, "val_acc": 52.0}
