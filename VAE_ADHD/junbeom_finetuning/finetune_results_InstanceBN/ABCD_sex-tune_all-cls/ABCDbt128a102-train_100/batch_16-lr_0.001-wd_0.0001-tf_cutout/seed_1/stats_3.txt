"main_modify.py --pretrained_path /scratch/connectome/dyhan316/VAE_ADHD/barlowtwins/pretrain_results/ABCDbt128a102.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 1 --task ABCD_sex --input_option BT_org --learning_rate 1e-3 --batch_size 16 --weight_decay 1e-4 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 0.7135659098625183, "training_acc": 40.0, "val_loss": 0.6934521079063416, "val_acc": 48.0}
{"epoch": 1, "training_loss": 0.6979336833953858, "training_acc": 41.0, "val_loss": 0.692933955192566, "val_acc": 52.0}
{"epoch": 2, "training_loss": 0.6993311262130737, "training_acc": 47.0, "val_loss": 0.6943388795852661, "val_acc": 52.0}
{"epoch": 3, "training_loss": 0.7005063486099243, "training_acc": 53.0, "val_loss": 0.6971785116195679, "val_acc": 52.0}
{"epoch": 4, "training_loss": 0.7051400113105774, "training_acc": 47.0, "val_loss": 0.6928306126594543, "val_acc": 52.0}
{"epoch": 5, "training_loss": 0.7063443231582641, "training_acc": 53.0, "val_loss": 0.6937659931182861, "val_acc": 52.0}
{"epoch": 6, "training_loss": 0.704335560798645, "training_acc": 47.0, "val_loss": 0.6995904278755188, "val_acc": 48.0}
{"epoch": 7, "training_loss": 0.6992686653137207, "training_acc": 47.0, "val_loss": 0.6979172158241272, "val_acc": 52.0}
{"epoch": 8, "training_loss": 0.726485595703125, "training_acc": 53.0, "val_loss": 0.6941475653648377, "val_acc": 52.0}
{"epoch": 9, "training_loss": 0.6940389680862427, "training_acc": 49.0, "val_loss": 0.6987889385223389, "val_acc": 48.0}
{"epoch": 10, "training_loss": 0.7018568754196167, "training_acc": 49.0, "val_loss": 0.6945940899848938, "val_acc": 52.0}
{"epoch": 11, "training_loss": 0.7119477653503418, "training_acc": 53.0, "val_loss": 0.7096250486373902, "val_acc": 52.0}
{"epoch": 12, "training_loss": 0.6942132186889648, "training_acc": 51.0, "val_loss": 0.6947499799728394, "val_acc": 48.0}
{"epoch": 13, "training_loss": 0.6944522094726563, "training_acc": 47.0, "val_loss": 0.6924496936798096, "val_acc": 52.0}
{"epoch": 14, "training_loss": 0.7091485357284546, "training_acc": 53.0, "val_loss": 0.693672993183136, "val_acc": 52.0}
{"epoch": 15, "training_loss": 0.6936324667930603, "training_acc": 53.0, "val_loss": 0.6923604965209961, "val_acc": 52.0}
{"epoch": 16, "training_loss": 0.7075809979438782, "training_acc": 43.0, "val_loss": 0.6947654747962951, "val_acc": 48.0}
{"epoch": 17, "training_loss": 0.6988200688362122, "training_acc": 47.0, "val_loss": 0.693327362537384, "val_acc": 52.0}
{"epoch": 18, "training_loss": 0.7290460038185119, "training_acc": 53.0, "val_loss": 0.7197764730453491, "val_acc": 52.0}
{"epoch": 19, "training_loss": 0.6958749270439148, "training_acc": 53.0, "val_loss": 0.6947467422485352, "val_acc": 48.0}
{"epoch": 20, "training_loss": 0.7030018663406372, "training_acc": 47.0, "val_loss": 0.6957342386245727, "val_acc": 48.0}
{"epoch": 21, "training_loss": 0.6929036784172058, "training_acc": 51.0, "val_loss": 0.6942710971832275, "val_acc": 52.0}
{"epoch": 22, "training_loss": 0.7122380781173706, "training_acc": 53.0, "val_loss": 0.7126568222045898, "val_acc": 52.0}
{"epoch": 23, "training_loss": 0.7022598314285279, "training_acc": 53.0, "val_loss": 0.6926191020011901, "val_acc": 52.0}
{"epoch": 24, "training_loss": 0.6993546581268311, "training_acc": 43.0, "val_loss": 0.693053982257843, "val_acc": 52.0}
{"epoch": 25, "training_loss": 0.6890558862686157, "training_acc": 53.0, "val_loss": 0.7015846800804139, "val_acc": 52.0}
{"epoch": 26, "training_loss": 0.7036309123039246, "training_acc": 53.0, "val_loss": 0.6962689542770386, "val_acc": 52.0}
{"epoch": 27, "training_loss": 0.6959811782836914, "training_acc": 53.0, "val_loss": 0.6927594089508057, "val_acc": 52.0}
{"epoch": 28, "training_loss": 0.6975219130516053, "training_acc": 53.0, "val_loss": 0.6934573817253112, "val_acc": 52.0}
{"epoch": 29, "training_loss": 0.6940541219711304, "training_acc": 53.0, "val_loss": 0.6928932595252991, "val_acc": 52.0}
{"epoch": 30, "training_loss": 0.6917956256866455, "training_acc": 53.0, "val_loss": 0.6973883581161499, "val_acc": 52.0}
{"epoch": 31, "training_loss": 0.6941365647315979, "training_acc": 53.0, "val_loss": 0.6924194025993348, "val_acc": 52.0}
{"epoch": 32, "training_loss": 0.6931283259391785, "training_acc": 53.0, "val_loss": 0.6924593424797059, "val_acc": 52.0}
{"epoch": 33, "training_loss": 0.6913068294525146, "training_acc": 53.0, "val_loss": 0.6956358647346497, "val_acc": 52.0}
{"epoch": 34, "training_loss": 0.7023806238174438, "training_acc": 53.0, "val_loss": 0.7019954419136047, "val_acc": 52.0}
{"epoch": 35, "training_loss": 0.6957152891159057, "training_acc": 53.0, "val_loss": 0.6923482084274292, "val_acc": 52.0}
{"epoch": 36, "training_loss": 0.693564486503601, "training_acc": 53.0, "val_loss": 0.692349009513855, "val_acc": 52.0}
{"epoch": 37, "training_loss": 0.6987715244293213, "training_acc": 53.0, "val_loss": 0.6941433501243591, "val_acc": 52.0}
{"epoch": 38, "training_loss": 0.7004273796081543, "training_acc": 47.0, "val_loss": 0.6952359557151795, "val_acc": 48.0}
{"epoch": 39, "training_loss": 0.6924373626708984, "training_acc": 53.0, "val_loss": 0.693575668334961, "val_acc": 52.0}
{"epoch": 40, "training_loss": 0.692078902721405, "training_acc": 53.0, "val_loss": 0.6923600172996521, "val_acc": 52.0}
{"epoch": 41, "training_loss": 0.6976356339454651, "training_acc": 43.0, "val_loss": 0.6935570096969604, "val_acc": 48.0}
{"epoch": 42, "training_loss": 0.6907327246665954, "training_acc": 51.0, "val_loss": 0.6984191465377808, "val_acc": 52.0}
{"epoch": 43, "training_loss": 0.7037196302413941, "training_acc": 53.0, "val_loss": 0.6993360209465027, "val_acc": 52.0}
{"epoch": 44, "training_loss": 0.697055516242981, "training_acc": 49.0, "val_loss": 0.6961626529693603, "val_acc": 48.0}
{"epoch": 45, "training_loss": 0.6981300354003906, "training_acc": 47.0, "val_loss": 0.6937570333480835, "val_acc": 48.0}
{"epoch": 46, "training_loss": 0.6970845174789428, "training_acc": 51.0, "val_loss": 0.6930322742462158, "val_acc": 52.0}
{"epoch": 47, "training_loss": 0.7221902942657471, "training_acc": 39.0, "val_loss": 0.6983263063430786, "val_acc": 48.0}
{"epoch": 48, "training_loss": 0.7111759662628174, "training_acc": 51.0, "val_loss": 0.7110426449775695, "val_acc": 52.0}
{"epoch": 49, "training_loss": 0.6986060476303101, "training_acc": 53.0, "val_loss": 0.6923543095588685, "val_acc": 52.0}
{"epoch": 50, "training_loss": 0.6937816500663757, "training_acc": 53.0, "val_loss": 0.6939931035041809, "val_acc": 48.0}
{"epoch": 51, "training_loss": 0.707781982421875, "training_acc": 47.0, "val_loss": 0.7018791127204895, "val_acc": 48.0}
{"epoch": 52, "training_loss": 0.6950392150878906, "training_acc": 51.0, "val_loss": 0.6952287411689758, "val_acc": 52.0}
{"epoch": 53, "training_loss": 0.6944383573532105, "training_acc": 53.0, "val_loss": 0.6957678437232971, "val_acc": 52.0}
{"epoch": 54, "training_loss": 0.6897274780273438, "training_acc": 53.0, "val_loss": 0.6952264380455017, "val_acc": 48.0}
