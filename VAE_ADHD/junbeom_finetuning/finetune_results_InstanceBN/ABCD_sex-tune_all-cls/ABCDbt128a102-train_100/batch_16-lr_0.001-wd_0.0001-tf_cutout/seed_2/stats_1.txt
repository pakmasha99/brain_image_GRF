"main_modify.py --pretrained_path /scratch/connectome/dyhan316/VAE_ADHD/barlowtwins/pretrain_results/ABCDbt128a102.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 2 --task ABCD_sex --input_option BT_org --learning_rate 1e-3 --batch_size 16 --weight_decay 1e-4 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 0.7039295864105225, "training_acc": 47.0, "val_loss": 0.6944615197181702, "val_acc": 48.0}
{"epoch": 1, "training_loss": 0.6983338022232055, "training_acc": 45.0, "val_loss": 0.6928536081314087, "val_acc": 52.0}
{"epoch": 2, "training_loss": 0.6988893461227417, "training_acc": 53.0, "val_loss": 0.6934635186195374, "val_acc": 52.0}
{"epoch": 3, "training_loss": 0.6949653339385986, "training_acc": 53.0, "val_loss": 0.693431351184845, "val_acc": 48.0}
{"epoch": 4, "training_loss": 0.7226495218276977, "training_acc": 47.0, "val_loss": 0.6923543906211853, "val_acc": 52.0}
{"epoch": 5, "training_loss": 0.7024353194236755, "training_acc": 53.0, "val_loss": 0.7029075336456299, "val_acc": 52.0}
{"epoch": 6, "training_loss": 0.6961229038238526, "training_acc": 53.0, "val_loss": 0.6923564624786377, "val_acc": 52.0}
{"epoch": 7, "training_loss": 0.7041042804718017, "training_acc": 53.0, "val_loss": 0.6925721478462219, "val_acc": 52.0}
{"epoch": 8, "training_loss": 0.7016284465789795, "training_acc": 45.0, "val_loss": 0.6923524165153503, "val_acc": 52.0}
{"epoch": 9, "training_loss": 0.6961560273170471, "training_acc": 53.0, "val_loss": 0.693610577583313, "val_acc": 52.0}
{"epoch": 10, "training_loss": 0.6949292755126953, "training_acc": 44.0, "val_loss": 0.692563328742981, "val_acc": 52.0}
{"epoch": 11, "training_loss": 0.7166145706176758, "training_acc": 53.0, "val_loss": 0.698081967830658, "val_acc": 52.0}
{"epoch": 12, "training_loss": 0.6968563938140869, "training_acc": 48.0, "val_loss": 0.695808334350586, "val_acc": 48.0}
{"epoch": 13, "training_loss": 0.6976939010620117, "training_acc": 45.0, "val_loss": 0.6923558783531188, "val_acc": 52.0}
{"epoch": 14, "training_loss": 0.6947292399406433, "training_acc": 47.0, "val_loss": 0.6929087615013123, "val_acc": 52.0}
{"epoch": 15, "training_loss": 0.7083818531036377, "training_acc": 53.0, "val_loss": 0.6969430112838745, "val_acc": 52.0}
{"epoch": 16, "training_loss": 0.7009024620056152, "training_acc": 47.0, "val_loss": 0.7009268045425415, "val_acc": 48.0}
{"epoch": 17, "training_loss": 0.7047306823730469, "training_acc": 45.0, "val_loss": 0.6927844619750977, "val_acc": 52.0}
{"epoch": 18, "training_loss": 0.6990653252601624, "training_acc": 47.0, "val_loss": 0.6935358166694641, "val_acc": 52.0}
{"epoch": 19, "training_loss": 0.6962490177154541, "training_acc": 53.0, "val_loss": 0.704128532409668, "val_acc": 52.0}
{"epoch": 20, "training_loss": 0.6997511816024781, "training_acc": 53.0, "val_loss": 0.69416832447052, "val_acc": 52.0}
{"epoch": 21, "training_loss": 0.6948851823806763, "training_acc": 53.0, "val_loss": 0.6930391168594361, "val_acc": 52.0}
{"epoch": 22, "training_loss": 0.7024286079406739, "training_acc": 49.0, "val_loss": 0.6926984071731568, "val_acc": 52.0}
{"epoch": 23, "training_loss": 0.700558774471283, "training_acc": 53.0, "val_loss": 0.7151704287528992, "val_acc": 52.0}
{"epoch": 24, "training_loss": 0.7147321248054505, "training_acc": 43.0, "val_loss": 0.6923750042915344, "val_acc": 52.0}
{"epoch": 25, "training_loss": 0.6907453107833862, "training_acc": 53.0, "val_loss": 0.6963779640197754, "val_acc": 52.0}
{"epoch": 26, "training_loss": 0.6937963938713074, "training_acc": 53.0, "val_loss": 0.6944061613082886, "val_acc": 48.0}
{"epoch": 27, "training_loss": 0.7191627502441407, "training_acc": 47.0, "val_loss": 0.6980046796798706, "val_acc": 48.0}
