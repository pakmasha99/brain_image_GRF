"main_modify.py --pretrained_path /scratch/connectome/dyhan316/VAE_ADHD/barlowtwins/pretrain_results/ABCDbt128a102.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 2 --task ABCD_sex --input_option BT_org --learning_rate 1e-3 --batch_size 16 --weight_decay 1e-4 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 0.7088546371459961, "training_acc": 48.0, "val_loss": 0.6861485719680787, "val_acc": 56.0}
{"epoch": 1, "training_loss": 0.7128755664825439, "training_acc": 46.0, "val_loss": 0.6881288123130799, "val_acc": 56.0}
{"epoch": 2, "training_loss": 0.7302078008651733, "training_acc": 52.0, "val_loss": 0.686145794391632, "val_acc": 56.0}
{"epoch": 3, "training_loss": 0.7202056980133057, "training_acc": 46.0, "val_loss": 0.73526437997818, "val_acc": 44.0}
{"epoch": 4, "training_loss": 0.7197936844825744, "training_acc": 48.0, "val_loss": 0.6959586000442505, "val_acc": 44.0}
{"epoch": 5, "training_loss": 0.698438401222229, "training_acc": 52.0, "val_loss": 0.6859701180458069, "val_acc": 56.0}
{"epoch": 6, "training_loss": 0.6937466835975648, "training_acc": 50.0, "val_loss": 0.697366087436676, "val_acc": 44.0}
{"epoch": 7, "training_loss": 0.6998588371276856, "training_acc": 46.0, "val_loss": 0.6899872326850891, "val_acc": 56.0}
{"epoch": 8, "training_loss": 0.6943994235992431, "training_acc": 46.0, "val_loss": 0.6924866199493408, "val_acc": 56.0}
{"epoch": 9, "training_loss": 0.6966495609283447, "training_acc": 48.0, "val_loss": 0.6964384388923645, "val_acc": 44.0}
{"epoch": 10, "training_loss": 0.7015540361404419, "training_acc": 50.0, "val_loss": 0.6859447312355041, "val_acc": 56.0}
{"epoch": 11, "training_loss": 0.7022073626518249, "training_acc": 48.0, "val_loss": 0.7037543201446533, "val_acc": 44.0}
{"epoch": 12, "training_loss": 0.6952002096176148, "training_acc": 50.0, "val_loss": 0.6874876642227172, "val_acc": 56.0}
{"epoch": 13, "training_loss": 0.6934768271446228, "training_acc": 52.0, "val_loss": 0.6869594883918763, "val_acc": 56.0}
{"epoch": 14, "training_loss": 0.6966328620910645, "training_acc": 52.0, "val_loss": 0.6881075310707092, "val_acc": 56.0}
{"epoch": 15, "training_loss": 0.6932507419586181, "training_acc": 52.0, "val_loss": 0.6898151206970214, "val_acc": 56.0}
{"epoch": 16, "training_loss": 0.6947079610824585, "training_acc": 52.0, "val_loss": 0.6874415850639344, "val_acc": 56.0}
{"epoch": 17, "training_loss": 0.6946480917930603, "training_acc": 50.0, "val_loss": 0.6986686134338379, "val_acc": 44.0}
{"epoch": 18, "training_loss": 0.7059253883361817, "training_acc": 48.0, "val_loss": 0.6859846782684326, "val_acc": 56.0}
{"epoch": 19, "training_loss": 0.7156787133216858, "training_acc": 52.0, "val_loss": 0.6976998233795166, "val_acc": 56.0}
{"epoch": 20, "training_loss": 0.7029380559921264, "training_acc": 52.0, "val_loss": 0.6940369081497192, "val_acc": 44.0}
{"epoch": 21, "training_loss": 0.7033890151977539, "training_acc": 48.0, "val_loss": 0.6953615307807922, "val_acc": 44.0}
{"epoch": 22, "training_loss": 0.7025391578674316, "training_acc": 46.0, "val_loss": 0.6861534857749939, "val_acc": 56.0}
{"epoch": 23, "training_loss": 0.7128163242340088, "training_acc": 52.0, "val_loss": 0.6863329362869263, "val_acc": 56.0}
{"epoch": 24, "training_loss": 0.7094880485534668, "training_acc": 42.0, "val_loss": 0.6957334446907043, "val_acc": 44.0}
{"epoch": 25, "training_loss": 0.6965613985061645, "training_acc": 50.0, "val_loss": 0.6863028454780579, "val_acc": 56.0}
{"epoch": 26, "training_loss": 0.6963990020751953, "training_acc": 52.0, "val_loss": 0.6872649812698364, "val_acc": 56.0}
{"epoch": 27, "training_loss": 0.7056597089767456, "training_acc": 52.0, "val_loss": 0.6862036514282227, "val_acc": 56.0}
{"epoch": 28, "training_loss": 0.7034632205963135, "training_acc": 52.0, "val_loss": 0.6874828839302063, "val_acc": 56.0}
{"epoch": 29, "training_loss": 0.6993706178665161, "training_acc": 52.0, "val_loss": 0.6889323043823242, "val_acc": 56.0}
