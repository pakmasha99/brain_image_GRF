"main_modify.py --pretrained_path /scratch/connectome/dyhan316/VAE_ADHD/barlowtwins/pretrain_results/ABCDbt128a102.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option BT_org --learning_rate 1e-3 --batch_size 16 --weight_decay 1e-4 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 0.7081405401229859, "training_acc": 44.0, "val_loss": 0.6928927683830262, "val_acc": 52.0}
{"epoch": 1, "training_loss": 0.731724054813385, "training_acc": 53.0, "val_loss": 0.6930355262756348, "val_acc": 52.0}
{"epoch": 2, "training_loss": 0.6984986853599549, "training_acc": 47.0, "val_loss": 0.6926040649414062, "val_acc": 52.0}
{"epoch": 3, "training_loss": 0.7008273077011108, "training_acc": 53.0, "val_loss": 0.6937589120864868, "val_acc": 52.0}
{"epoch": 4, "training_loss": 0.6947779989242554, "training_acc": 53.0, "val_loss": 0.6924752807617187, "val_acc": 52.0}
{"epoch": 5, "training_loss": 0.6980546617507934, "training_acc": 53.0, "val_loss": 0.6926527142524719, "val_acc": 52.0}
{"epoch": 6, "training_loss": 0.6990484285354615, "training_acc": 43.0, "val_loss": 0.6956335043907166, "val_acc": 52.0}
{"epoch": 7, "training_loss": 0.699317934513092, "training_acc": 53.0, "val_loss": 0.6978094911575318, "val_acc": 52.0}
{"epoch": 8, "training_loss": 0.6968139982223511, "training_acc": 53.0, "val_loss": 0.6924563717842102, "val_acc": 52.0}
{"epoch": 9, "training_loss": 0.6950777435302734, "training_acc": 53.0, "val_loss": 0.6927265810966492, "val_acc": 52.0}
{"epoch": 10, "training_loss": 0.7115618658065795, "training_acc": 53.0, "val_loss": 0.6982198405265808, "val_acc": 52.0}
{"epoch": 11, "training_loss": 0.6942839097976684, "training_acc": 51.0, "val_loss": 0.6971275758743286, "val_acc": 48.0}
{"epoch": 12, "training_loss": 0.6976011848449707, "training_acc": 47.0, "val_loss": 0.6925088214874268, "val_acc": 52.0}
{"epoch": 13, "training_loss": 0.6936108851432801, "training_acc": 53.0, "val_loss": 0.6927077102661133, "val_acc": 52.0}
{"epoch": 14, "training_loss": 0.7274507665634156, "training_acc": 43.0, "val_loss": 0.696810085773468, "val_acc": 48.0}
{"epoch": 15, "training_loss": 0.6889614963531494, "training_acc": 53.0, "val_loss": 0.7170473551750183, "val_acc": 52.0}
{"epoch": 16, "training_loss": 0.6985319709777832, "training_acc": 53.0, "val_loss": 0.6923741579055787, "val_acc": 52.0}
{"epoch": 17, "training_loss": 0.6970869445800781, "training_acc": 53.0, "val_loss": 0.6923801159858703, "val_acc": 52.0}
{"epoch": 18, "training_loss": 0.6919717359542846, "training_acc": 53.0, "val_loss": 0.6925309085845948, "val_acc": 52.0}
{"epoch": 19, "training_loss": 0.695289044380188, "training_acc": 45.0, "val_loss": 0.6923611783981323, "val_acc": 52.0}
{"epoch": 20, "training_loss": 0.6940382671356201, "training_acc": 53.0, "val_loss": 0.6968646383285523, "val_acc": 52.0}
{"epoch": 21, "training_loss": 0.6934995174407959, "training_acc": 53.0, "val_loss": 0.6923999118804932, "val_acc": 52.0}
{"epoch": 22, "training_loss": 0.6931743621826172, "training_acc": 49.0, "val_loss": 0.6924031805992127, "val_acc": 52.0}
{"epoch": 23, "training_loss": 0.7019161081314087, "training_acc": 53.0, "val_loss": 0.7053398156166076, "val_acc": 52.0}
{"epoch": 24, "training_loss": 0.7008234453201294, "training_acc": 53.0, "val_loss": 0.6925038456916809, "val_acc": 52.0}
{"epoch": 25, "training_loss": 0.7185220861434937, "training_acc": 45.0, "val_loss": 0.7131388092041016, "val_acc": 48.0}
{"epoch": 26, "training_loss": 0.709158034324646, "training_acc": 43.0, "val_loss": 0.6931716632843018, "val_acc": 52.0}
{"epoch": 27, "training_loss": 0.6949122667312622, "training_acc": 53.0, "val_loss": 0.6970413160324097, "val_acc": 52.0}
{"epoch": 28, "training_loss": 0.6960173082351685, "training_acc": 53.0, "val_loss": 0.6923572158813477, "val_acc": 52.0}
{"epoch": 29, "training_loss": 0.6927137994766235, "training_acc": 53.0, "val_loss": 0.6948282861709595, "val_acc": 52.0}
{"epoch": 30, "training_loss": 0.6932406806945801, "training_acc": 53.0, "val_loss": 0.6972515988349914, "val_acc": 52.0}
{"epoch": 31, "training_loss": 0.700830078125, "training_acc": 53.0, "val_loss": 0.6937563252449036, "val_acc": 52.0}
{"epoch": 32, "training_loss": 0.6907606554031372, "training_acc": 53.0, "val_loss": 0.6984986925125122, "val_acc": 48.0}
{"epoch": 33, "training_loss": 0.705128607749939, "training_acc": 43.0, "val_loss": 0.6928693842887879, "val_acc": 52.0}
{"epoch": 34, "training_loss": 0.7084659004211425, "training_acc": 41.0, "val_loss": 0.6931041669845581, "val_acc": 52.0}
{"epoch": 35, "training_loss": 0.6978889060020447, "training_acc": 47.0, "val_loss": 0.6973691940307617, "val_acc": 52.0}
{"epoch": 36, "training_loss": 0.6999131679534912, "training_acc": 47.0, "val_loss": 0.7002453994750977, "val_acc": 48.0}
{"epoch": 37, "training_loss": 0.7251476907730102, "training_acc": 47.0, "val_loss": 0.6936067605018615, "val_acc": 48.0}
{"epoch": 38, "training_loss": 0.7062345266342163, "training_acc": 55.0, "val_loss": 0.7255654644966125, "val_acc": 52.0}
{"epoch": 39, "training_loss": 0.7211185884475708, "training_acc": 51.0, "val_loss": 0.6967789483070373, "val_acc": 48.0}
{"epoch": 40, "training_loss": 0.7039018964767456, "training_acc": 47.0, "val_loss": 0.6932353496551513, "val_acc": 48.0}
{"epoch": 41, "training_loss": 0.7154112648963928, "training_acc": 53.0, "val_loss": 0.7002290654182434, "val_acc": 52.0}
{"epoch": 42, "training_loss": 0.693348879814148, "training_acc": 49.0, "val_loss": 0.7022731041908264, "val_acc": 48.0}
{"epoch": 43, "training_loss": 0.6986695337295532, "training_acc": 49.0, "val_loss": 0.692446870803833, "val_acc": 52.0}
{"epoch": 44, "training_loss": 0.7240422201156617, "training_acc": 53.0, "val_loss": 0.6994535422325134, "val_acc": 52.0}
{"epoch": 45, "training_loss": 0.6990239524841309, "training_acc": 49.0, "val_loss": 0.6954342222213745, "val_acc": 48.0}
{"epoch": 46, "training_loss": 0.6985245680809021, "training_acc": 35.0, "val_loss": 0.6923633813858032, "val_acc": 52.0}
{"epoch": 47, "training_loss": 0.7036643648147582, "training_acc": 53.0, "val_loss": 0.6985345387458801, "val_acc": 52.0}
