"main_modify.py --pretrained_path /scratch/connectome/dyhan316/VAE_ADHD/barlowtwins/pretrain_results/ABCDbt128a102.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 2 --task ABCD_sex --input_option BT_org --learning_rate 1e-4 --batch_size 16 --weight_decay 1e-2 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 0.6917378330230712, "training_acc": 53.0, "val_loss": 0.6951638340950013, "val_acc": 52.0}
{"epoch": 1, "training_loss": 0.6930689144134522, "training_acc": 53.0, "val_loss": 0.692102472782135, "val_acc": 52.0}
{"epoch": 2, "training_loss": 0.6921418070793152, "training_acc": 53.0, "val_loss": 0.6924988293647766, "val_acc": 52.0}
{"epoch": 3, "training_loss": 0.6928229713439942, "training_acc": 53.0, "val_loss": 0.6927306675910949, "val_acc": 52.0}
{"epoch": 4, "training_loss": 0.6907934212684631, "training_acc": 53.0, "val_loss": 0.6945293378829956, "val_acc": 52.0}
{"epoch": 5, "training_loss": 0.694773063659668, "training_acc": 53.0, "val_loss": 0.6948797512054443, "val_acc": 52.0}
{"epoch": 6, "training_loss": 0.6915420484542847, "training_acc": 53.0, "val_loss": 0.6932131600379944, "val_acc": 52.0}
{"epoch": 7, "training_loss": 0.6925251960754395, "training_acc": 53.0, "val_loss": 0.6904014897346497, "val_acc": 52.0}
{"epoch": 8, "training_loss": 0.6925996685028076, "training_acc": 53.0, "val_loss": 0.6926041531562805, "val_acc": 52.0}
{"epoch": 9, "training_loss": 0.6926497602462769, "training_acc": 53.0, "val_loss": 0.6923900938034058, "val_acc": 52.0}
{"epoch": 10, "training_loss": 0.6931526350975037, "training_acc": 53.0, "val_loss": 0.6924124741554261, "val_acc": 52.0}
{"epoch": 11, "training_loss": 0.6918110179901124, "training_acc": 53.0, "val_loss": 0.6925107502937317, "val_acc": 52.0}
{"epoch": 12, "training_loss": 0.6919975519180298, "training_acc": 53.0, "val_loss": 0.6931716465950012, "val_acc": 52.0}
{"epoch": 13, "training_loss": 0.6922523975372314, "training_acc": 53.0, "val_loss": 0.6934017682075501, "val_acc": 52.0}
{"epoch": 14, "training_loss": 0.6948217725753785, "training_acc": 53.0, "val_loss": 0.6923297810554504, "val_acc": 52.0}
{"epoch": 15, "training_loss": 0.692234616279602, "training_acc": 53.0, "val_loss": 0.6924477744102479, "val_acc": 52.0}
{"epoch": 16, "training_loss": 0.6924458074569703, "training_acc": 53.0, "val_loss": 0.6936575174331665, "val_acc": 52.0}
{"epoch": 17, "training_loss": 0.6958016538619995, "training_acc": 53.0, "val_loss": 0.6945136976242066, "val_acc": 52.0}
{"epoch": 18, "training_loss": 0.6927944087982177, "training_acc": 53.0, "val_loss": 0.6924601912498474, "val_acc": 52.0}
{"epoch": 19, "training_loss": 0.6916441512107849, "training_acc": 53.0, "val_loss": 0.692270221710205, "val_acc": 52.0}
{"epoch": 20, "training_loss": 0.6921488332748413, "training_acc": 53.0, "val_loss": 0.6921911668777466, "val_acc": 52.0}
{"epoch": 21, "training_loss": 0.6934861183166504, "training_acc": 53.0, "val_loss": 0.6927520251274109, "val_acc": 52.0}
{"epoch": 22, "training_loss": 0.6928758192062378, "training_acc": 53.0, "val_loss": 0.693645625114441, "val_acc": 52.0}
{"epoch": 23, "training_loss": 0.6924182367324829, "training_acc": 53.0, "val_loss": 0.6923608732223511, "val_acc": 52.0}
{"epoch": 24, "training_loss": 0.6948203992843628, "training_acc": 47.0, "val_loss": 0.6928608822822571, "val_acc": 52.0}
{"epoch": 25, "training_loss": 0.6964998722076416, "training_acc": 53.0, "val_loss": 0.6928307747840882, "val_acc": 52.0}
{"epoch": 26, "training_loss": 0.6937114310264587, "training_acc": 53.0, "val_loss": 0.6926272749900818, "val_acc": 52.0}
