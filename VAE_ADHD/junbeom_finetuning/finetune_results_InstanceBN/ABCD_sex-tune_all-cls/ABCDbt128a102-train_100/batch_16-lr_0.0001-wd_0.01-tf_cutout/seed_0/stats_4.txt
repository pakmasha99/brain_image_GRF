"main_modify.py --pretrained_path /scratch/connectome/dyhan316/VAE_ADHD/barlowtwins/pretrain_results/ABCDbt128a102.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option BT_org --learning_rate 1e-4 --batch_size 16 --weight_decay 1e-2 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 0.6986494398117066, "training_acc": 48.0, "val_loss": 0.6944315385818481, "val_acc": 48.0}
{"epoch": 1, "training_loss": 0.6925913381576538, "training_acc": 52.0, "val_loss": 0.6923389267921448, "val_acc": 52.0}
{"epoch": 2, "training_loss": 0.6920814299583435, "training_acc": 53.0, "val_loss": 0.6929226350784302, "val_acc": 52.0}
{"epoch": 3, "training_loss": 0.6932707715034485, "training_acc": 53.0, "val_loss": 0.6930980324745178, "val_acc": 52.0}
{"epoch": 4, "training_loss": 0.6915253257751465, "training_acc": 53.0, "val_loss": 0.6924780964851379, "val_acc": 52.0}
{"epoch": 5, "training_loss": 0.6932711315155029, "training_acc": 53.0, "val_loss": 0.6925326657295227, "val_acc": 52.0}
{"epoch": 6, "training_loss": 0.6921905279159546, "training_acc": 53.0, "val_loss": 0.6923890662193298, "val_acc": 52.0}
{"epoch": 7, "training_loss": 0.6937911796569824, "training_acc": 53.0, "val_loss": 0.6924662804603576, "val_acc": 52.0}
{"epoch": 8, "training_loss": 0.6923778486251831, "training_acc": 53.0, "val_loss": 0.6924452638626098, "val_acc": 52.0}
{"epoch": 9, "training_loss": 0.6916317844390869, "training_acc": 53.0, "val_loss": 0.6923819661140442, "val_acc": 52.0}
{"epoch": 10, "training_loss": 0.6929247379302979, "training_acc": 51.0, "val_loss": 0.6926874208450318, "val_acc": 52.0}
{"epoch": 11, "training_loss": 0.6915647315979004, "training_acc": 53.0, "val_loss": 0.6932677912712097, "val_acc": 52.0}
{"epoch": 12, "training_loss": 0.6929697132110596, "training_acc": 53.0, "val_loss": 0.6930564618110657, "val_acc": 52.0}
{"epoch": 13, "training_loss": 0.6927785539627075, "training_acc": 53.0, "val_loss": 0.6930622220039367, "val_acc": 52.0}
{"epoch": 14, "training_loss": 0.6914273309707641, "training_acc": 53.0, "val_loss": 0.6919602465629577, "val_acc": 52.0}
{"epoch": 15, "training_loss": 0.6938058185577393, "training_acc": 53.0, "val_loss": 0.6932531666755676, "val_acc": 52.0}
{"epoch": 16, "training_loss": 0.694381582736969, "training_acc": 53.0, "val_loss": 0.6931955742835999, "val_acc": 52.0}
{"epoch": 17, "training_loss": 0.6930548310279846, "training_acc": 53.0, "val_loss": 0.6927621722221374, "val_acc": 52.0}
{"epoch": 18, "training_loss": 0.6929778337478638, "training_acc": 53.0, "val_loss": 0.6929605841636658, "val_acc": 52.0}
{"epoch": 19, "training_loss": 0.6937228560447692, "training_acc": 53.0, "val_loss": 0.6922825622558594, "val_acc": 52.0}
{"epoch": 20, "training_loss": 0.6907757711410523, "training_acc": 52.0, "val_loss": 0.6920394682884217, "val_acc": 60.0}
{"epoch": 21, "training_loss": 0.7003763365745544, "training_acc": 42.0, "val_loss": 0.6924246239662171, "val_acc": 52.0}
{"epoch": 22, "training_loss": 0.7001758909225464, "training_acc": 53.0, "val_loss": 0.693458309173584, "val_acc": 52.0}
{"epoch": 23, "training_loss": 0.693943269252777, "training_acc": 53.0, "val_loss": 0.6931458306312561, "val_acc": 52.0}
{"epoch": 24, "training_loss": 0.6969823884963989, "training_acc": 46.0, "val_loss": 0.6924411845207215, "val_acc": 52.0}
{"epoch": 25, "training_loss": 0.6934470796585083, "training_acc": 53.0, "val_loss": 0.6938063406944275, "val_acc": 52.0}
{"epoch": 26, "training_loss": 0.6970594263076783, "training_acc": 53.0, "val_loss": 0.6944466280937195, "val_acc": 52.0}
{"epoch": 27, "training_loss": 0.6943777227401733, "training_acc": 53.0, "val_loss": 0.6939408135414123, "val_acc": 52.0}
{"epoch": 28, "training_loss": 0.6920904684066772, "training_acc": 53.0, "val_loss": 0.6923533248901367, "val_acc": 52.0}
{"epoch": 29, "training_loss": 0.6923416996002197, "training_acc": 53.0, "val_loss": 0.6926807856559754, "val_acc": 52.0}
{"epoch": 30, "training_loss": 0.6987570476531982, "training_acc": 53.0, "val_loss": 0.6943791365623474, "val_acc": 52.0}
{"epoch": 31, "training_loss": 0.6920583200454712, "training_acc": 53.0, "val_loss": 0.692291100025177, "val_acc": 52.0}
{"epoch": 32, "training_loss": 0.6917674350738525, "training_acc": 53.0, "val_loss": 0.6927305722236633, "val_acc": 52.0}
{"epoch": 33, "training_loss": 0.6919153618812561, "training_acc": 53.0, "val_loss": 0.6937622952461243, "val_acc": 52.0}
