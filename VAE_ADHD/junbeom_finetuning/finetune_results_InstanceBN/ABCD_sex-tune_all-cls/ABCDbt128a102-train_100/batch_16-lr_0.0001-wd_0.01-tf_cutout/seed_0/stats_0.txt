"main_modify.py --pretrained_path /scratch/connectome/dyhan316/VAE_ADHD/barlowtwins/pretrain_results/ABCDbt128a102.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option BT_org --learning_rate 1e-4 --batch_size 16 --weight_decay 1e-2 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 0.6933587694168091, "training_acc": 52.0, "val_loss": 0.6895595645904541, "val_acc": 56.0}
{"epoch": 1, "training_loss": 0.6935715174674988, "training_acc": 52.0, "val_loss": 0.6877588772773743, "val_acc": 56.0}
{"epoch": 2, "training_loss": 0.6934526753425598, "training_acc": 52.0, "val_loss": 0.6889461350440979, "val_acc": 56.0}
{"epoch": 3, "training_loss": 0.6947121572494507, "training_acc": 52.0, "val_loss": 0.6870249485969544, "val_acc": 56.0}
{"epoch": 4, "training_loss": 0.6940568923950196, "training_acc": 52.0, "val_loss": 0.6886885952949524, "val_acc": 56.0}
{"epoch": 5, "training_loss": 0.6930321979522706, "training_acc": 52.0, "val_loss": 0.6880276989936829, "val_acc": 56.0}
{"epoch": 6, "training_loss": 0.6935235834121705, "training_acc": 52.0, "val_loss": 0.6886263561248779, "val_acc": 56.0}
{"epoch": 7, "training_loss": 0.693652400970459, "training_acc": 52.0, "val_loss": 0.6892241978645325, "val_acc": 56.0}
{"epoch": 8, "training_loss": 0.6953319644927979, "training_acc": 52.0, "val_loss": 0.6886329102516174, "val_acc": 56.0}
{"epoch": 9, "training_loss": 0.694750702381134, "training_acc": 52.0, "val_loss": 0.691408531665802, "val_acc": 56.0}
{"epoch": 10, "training_loss": 0.6944090270996094, "training_acc": 46.0, "val_loss": 0.6929768300056458, "val_acc": 56.0}
{"epoch": 11, "training_loss": 0.6926866698265076, "training_acc": 52.0, "val_loss": 0.6882776665687561, "val_acc": 56.0}
{"epoch": 12, "training_loss": 0.6981783533096313, "training_acc": 52.0, "val_loss": 0.6863656544685364, "val_acc": 56.0}
{"epoch": 13, "training_loss": 0.6951606559753418, "training_acc": 52.0, "val_loss": 0.6880059123039246, "val_acc": 56.0}
{"epoch": 14, "training_loss": 0.6934335517883301, "training_acc": 52.0, "val_loss": 0.6874844360351563, "val_acc": 56.0}
{"epoch": 15, "training_loss": 0.6936408734321594, "training_acc": 52.0, "val_loss": 0.6883564305305481, "val_acc": 56.0}
{"epoch": 16, "training_loss": 0.6958542442321778, "training_acc": 52.0, "val_loss": 0.686351432800293, "val_acc": 56.0}
{"epoch": 17, "training_loss": 0.693450391292572, "training_acc": 52.0, "val_loss": 0.6894240164756775, "val_acc": 56.0}
{"epoch": 18, "training_loss": 0.6935974740982056, "training_acc": 52.0, "val_loss": 0.6898591327667236, "val_acc": 56.0}
{"epoch": 19, "training_loss": 0.6954428052902222, "training_acc": 40.0, "val_loss": 0.6905057978630066, "val_acc": 56.0}
{"epoch": 20, "training_loss": 0.6936730146408081, "training_acc": 52.0, "val_loss": 0.6888203167915344, "val_acc": 56.0}
{"epoch": 21, "training_loss": 0.6948810625076294, "training_acc": 52.0, "val_loss": 0.6894049787521362, "val_acc": 56.0}
{"epoch": 22, "training_loss": 0.6964074730873108, "training_acc": 52.0, "val_loss": 0.6891455316543579, "val_acc": 56.0}
{"epoch": 23, "training_loss": 0.6921251010894776, "training_acc": 48.0, "val_loss": 0.6912191462516785, "val_acc": 56.0}
{"epoch": 24, "training_loss": 0.6955978083610534, "training_acc": 52.0, "val_loss": 0.6890701675415039, "val_acc": 56.0}
{"epoch": 25, "training_loss": 0.692665946483612, "training_acc": 51.0, "val_loss": 0.6933699202537537, "val_acc": 44.0}
{"epoch": 26, "training_loss": 0.7003950786590576, "training_acc": 48.0, "val_loss": 0.6899920082092286, "val_acc": 56.0}
{"epoch": 27, "training_loss": 0.6946908140182495, "training_acc": 48.0, "val_loss": 0.6921777486801147, "val_acc": 56.0}
{"epoch": 28, "training_loss": 0.6967754316329956, "training_acc": 49.0, "val_loss": 0.688534963130951, "val_acc": 56.0}
{"epoch": 29, "training_loss": 0.6941468381881714, "training_acc": 52.0, "val_loss": 0.686519582271576, "val_acc": 56.0}
{"epoch": 30, "training_loss": 0.7020699214935303, "training_acc": 52.0, "val_loss": 0.6857388138771057, "val_acc": 56.0}
{"epoch": 31, "training_loss": 0.6983738708496093, "training_acc": 52.0, "val_loss": 0.6870453882217408, "val_acc": 56.0}
{"epoch": 32, "training_loss": 0.6957219314575195, "training_acc": 52.0, "val_loss": 0.6860195541381836, "val_acc": 56.0}
{"epoch": 33, "training_loss": 0.6959022855758668, "training_acc": 52.0, "val_loss": 0.687056667804718, "val_acc": 56.0}
{"epoch": 34, "training_loss": 0.6928609275817871, "training_acc": 52.0, "val_loss": 0.6924219822883606, "val_acc": 56.0}
{"epoch": 35, "training_loss": 0.6946245002746582, "training_acc": 48.0, "val_loss": 0.6952334904670715, "val_acc": 44.0}
{"epoch": 36, "training_loss": 0.6928870368003845, "training_acc": 49.0, "val_loss": 0.6879203295707703, "val_acc": 56.0}
{"epoch": 37, "training_loss": 0.6934482908248901, "training_acc": 52.0, "val_loss": 0.6863451027870178, "val_acc": 56.0}
{"epoch": 38, "training_loss": 0.6964215898513794, "training_acc": 52.0, "val_loss": 0.6891835260391236, "val_acc": 56.0}
{"epoch": 39, "training_loss": 0.6926225423812866, "training_acc": 52.0, "val_loss": 0.6915872311592102, "val_acc": 56.0}
{"epoch": 40, "training_loss": 0.696247844696045, "training_acc": 46.0, "val_loss": 0.6939730167388916, "val_acc": 44.0}
{"epoch": 41, "training_loss": 0.6923378276824951, "training_acc": 54.0, "val_loss": 0.6885617876052856, "val_acc": 56.0}
{"epoch": 42, "training_loss": 0.6940088963508606, "training_acc": 52.0, "val_loss": 0.6884007310867309, "val_acc": 56.0}
{"epoch": 43, "training_loss": 0.6936726427078247, "training_acc": 52.0, "val_loss": 0.6895701909065246, "val_acc": 56.0}
{"epoch": 44, "training_loss": 0.6958346152305603, "training_acc": 45.0, "val_loss": 0.6959809446334839, "val_acc": 44.0}
{"epoch": 45, "training_loss": 0.69402259349823, "training_acc": 46.0, "val_loss": 0.6905283427238464, "val_acc": 56.0}
{"epoch": 46, "training_loss": 0.6929145288467408, "training_acc": 52.0, "val_loss": 0.68803546667099, "val_acc": 56.0}
{"epoch": 47, "training_loss": 0.6944064044952393, "training_acc": 52.0, "val_loss": 0.6872609353065491, "val_acc": 56.0}
{"epoch": 48, "training_loss": 0.6939344024658203, "training_acc": 52.0, "val_loss": 0.688143994808197, "val_acc": 56.0}
{"epoch": 49, "training_loss": 0.6914071369171143, "training_acc": 52.0, "val_loss": 0.6935373759269714, "val_acc": 44.0}
