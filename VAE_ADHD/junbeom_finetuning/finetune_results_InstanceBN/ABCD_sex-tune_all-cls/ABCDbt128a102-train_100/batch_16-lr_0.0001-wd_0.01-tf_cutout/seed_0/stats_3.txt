"main_modify.py --pretrained_path /scratch/connectome/dyhan316/VAE_ADHD/barlowtwins/pretrain_results/ABCDbt128a102.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option BT_org --learning_rate 1e-4 --batch_size 16 --weight_decay 1e-2 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 0.6938225030899048, "training_acc": 53.0, "val_loss": 0.694677586555481, "val_acc": 52.0}
{"epoch": 1, "training_loss": 0.6924850344657898, "training_acc": 53.0, "val_loss": 0.6924911165237426, "val_acc": 52.0}
{"epoch": 2, "training_loss": 0.6916121220588685, "training_acc": 53.0, "val_loss": 0.69300372838974, "val_acc": 52.0}
{"epoch": 3, "training_loss": 0.6922304344177246, "training_acc": 53.0, "val_loss": 0.6935757803916931, "val_acc": 52.0}
{"epoch": 4, "training_loss": 0.6926350712776184, "training_acc": 53.0, "val_loss": 0.693160526752472, "val_acc": 52.0}
{"epoch": 5, "training_loss": 0.6917666387557984, "training_acc": 53.0, "val_loss": 0.6921977758407593, "val_acc": 52.0}
{"epoch": 6, "training_loss": 0.6913908267021179, "training_acc": 50.0, "val_loss": 0.6926761817932129, "val_acc": 48.0}
{"epoch": 7, "training_loss": 0.6908528876304626, "training_acc": 52.0, "val_loss": 0.6920208168029786, "val_acc": 52.0}
{"epoch": 8, "training_loss": 0.6936576676368713, "training_acc": 53.0, "val_loss": 0.6923131680488587, "val_acc": 52.0}
{"epoch": 9, "training_loss": 0.6917222833633423, "training_acc": 52.0, "val_loss": 0.6930802631378173, "val_acc": 52.0}
{"epoch": 10, "training_loss": 0.6908888530731201, "training_acc": 53.0, "val_loss": 0.6918512654304504, "val_acc": 52.0}
{"epoch": 11, "training_loss": 0.6914140486717224, "training_acc": 53.0, "val_loss": 0.6918677258491516, "val_acc": 52.0}
{"epoch": 12, "training_loss": 0.6932097434997558, "training_acc": 53.0, "val_loss": 0.6932709527015686, "val_acc": 52.0}
{"epoch": 13, "training_loss": 0.6923987150192261, "training_acc": 53.0, "val_loss": 0.693263828754425, "val_acc": 52.0}
{"epoch": 14, "training_loss": 0.6908332729339599, "training_acc": 53.0, "val_loss": 0.6944575238227845, "val_acc": 52.0}
{"epoch": 15, "training_loss": 0.6902480506896973, "training_acc": 53.0, "val_loss": 0.6920264768600464, "val_acc": 52.0}
{"epoch": 16, "training_loss": 0.6900314378738404, "training_acc": 53.0, "val_loss": 0.6928517270088196, "val_acc": 52.0}
{"epoch": 17, "training_loss": 0.6976375222206116, "training_acc": 53.0, "val_loss": 0.6949788355827331, "val_acc": 52.0}
{"epoch": 18, "training_loss": 0.6900356364250183, "training_acc": 53.0, "val_loss": 0.6919925141334534, "val_acc": 52.0}
{"epoch": 19, "training_loss": 0.6914481592178344, "training_acc": 53.0, "val_loss": 0.6932691621780396, "val_acc": 52.0}
{"epoch": 20, "training_loss": 0.6908232212066651, "training_acc": 53.0, "val_loss": 0.6930379867553711, "val_acc": 48.0}
{"epoch": 21, "training_loss": 0.6975293636322022, "training_acc": 47.0, "val_loss": 0.6928571653366089, "val_acc": 52.0}
{"epoch": 22, "training_loss": 0.6909601402282715, "training_acc": 53.0, "val_loss": 0.6933927917480469, "val_acc": 52.0}
{"epoch": 23, "training_loss": 0.69100998878479, "training_acc": 53.0, "val_loss": 0.6926191806793213, "val_acc": 52.0}
{"epoch": 24, "training_loss": 0.6966849994659424, "training_acc": 53.0, "val_loss": 0.6931079602241517, "val_acc": 52.0}
{"epoch": 25, "training_loss": 0.6919242787361145, "training_acc": 53.0, "val_loss": 0.6923507308959961, "val_acc": 52.0}
{"epoch": 26, "training_loss": 0.6942068648338318, "training_acc": 53.0, "val_loss": 0.6927672171592713, "val_acc": 52.0}
{"epoch": 27, "training_loss": 0.6931753087043763, "training_acc": 53.0, "val_loss": 0.693247663974762, "val_acc": 52.0}
{"epoch": 28, "training_loss": 0.6923320412635803, "training_acc": 53.0, "val_loss": 0.6928121638298035, "val_acc": 52.0}
{"epoch": 29, "training_loss": 0.6924732065200806, "training_acc": 53.0, "val_loss": 0.6928645420074463, "val_acc": 52.0}
