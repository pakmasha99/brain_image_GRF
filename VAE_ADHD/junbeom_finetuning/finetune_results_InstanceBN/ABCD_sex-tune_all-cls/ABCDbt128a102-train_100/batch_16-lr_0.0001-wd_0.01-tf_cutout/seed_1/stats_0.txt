"main_modify.py --pretrained_path /scratch/connectome/dyhan316/VAE_ADHD/barlowtwins/pretrain_results/ABCDbt128a102.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 1 --task ABCD_sex --input_option BT_org --learning_rate 1e-4 --batch_size 16 --weight_decay 1e-2 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 0.6937505841255188, "training_acc": 52.0, "val_loss": 0.6925088763237, "val_acc": 52.0}
{"epoch": 1, "training_loss": 0.6927233123779297, "training_acc": 53.0, "val_loss": 0.6929273581504822, "val_acc": 52.0}
{"epoch": 2, "training_loss": 0.6913967990875244, "training_acc": 53.0, "val_loss": 0.6956177258491516, "val_acc": 52.0}
{"epoch": 3, "training_loss": 0.694348680973053, "training_acc": 53.0, "val_loss": 0.6944199800491333, "val_acc": 52.0}
{"epoch": 4, "training_loss": 0.6942886257171631, "training_acc": 53.0, "val_loss": 0.6930657243728637, "val_acc": 52.0}
{"epoch": 5, "training_loss": 0.6941125392913818, "training_acc": 53.0, "val_loss": 0.6948125433921813, "val_acc": 52.0}
{"epoch": 6, "training_loss": 0.6953949570655823, "training_acc": 53.0, "val_loss": 0.6946818113327027, "val_acc": 52.0}
{"epoch": 7, "training_loss": 0.6937399554252625, "training_acc": 53.0, "val_loss": 0.6925459408760071, "val_acc": 52.0}
{"epoch": 8, "training_loss": 0.6922568321228028, "training_acc": 53.0, "val_loss": 0.6923429536819458, "val_acc": 52.0}
{"epoch": 9, "training_loss": 0.6932897329330444, "training_acc": 53.0, "val_loss": 0.69263179063797, "val_acc": 52.0}
{"epoch": 10, "training_loss": 0.6933986949920654, "training_acc": 53.0, "val_loss": 0.6923142552375794, "val_acc": 52.0}
{"epoch": 11, "training_loss": 0.6922155666351318, "training_acc": 53.0, "val_loss": 0.6926763391494751, "val_acc": 52.0}
{"epoch": 12, "training_loss": 0.6923857164382935, "training_acc": 53.0, "val_loss": 0.6940176367759705, "val_acc": 52.0}
{"epoch": 13, "training_loss": 0.69405104637146, "training_acc": 53.0, "val_loss": 0.6930516386032104, "val_acc": 52.0}
{"epoch": 14, "training_loss": 0.6926272678375244, "training_acc": 53.0, "val_loss": 0.6922165679931641, "val_acc": 52.0}
{"epoch": 15, "training_loss": 0.6925009226799012, "training_acc": 53.0, "val_loss": 0.6927129006385804, "val_acc": 52.0}
{"epoch": 16, "training_loss": 0.6941547346115112, "training_acc": 53.0, "val_loss": 0.6924731826782227, "val_acc": 52.0}
{"epoch": 17, "training_loss": 0.6924663329124451, "training_acc": 53.0, "val_loss": 0.692425684928894, "val_acc": 52.0}
{"epoch": 18, "training_loss": 0.6931228637695312, "training_acc": 53.0, "val_loss": 0.69249915599823, "val_acc": 52.0}
{"epoch": 19, "training_loss": 0.6918073606491089, "training_acc": 53.0, "val_loss": 0.6934555387496948, "val_acc": 52.0}
{"epoch": 20, "training_loss": 0.6989171504974365, "training_acc": 53.0, "val_loss": 0.6940632581710815, "val_acc": 52.0}
{"epoch": 21, "training_loss": 0.6942673802375794, "training_acc": 53.0, "val_loss": 0.695357301235199, "val_acc": 52.0}
{"epoch": 22, "training_loss": 0.6943397784233093, "training_acc": 53.0, "val_loss": 0.6930349063873291, "val_acc": 52.0}
{"epoch": 23, "training_loss": 0.6923119783401489, "training_acc": 53.0, "val_loss": 0.692400541305542, "val_acc": 52.0}
{"epoch": 24, "training_loss": 0.6982684564590455, "training_acc": 39.0, "val_loss": 0.6923390221595764, "val_acc": 52.0}
{"epoch": 25, "training_loss": 0.6920262336730957, "training_acc": 53.0, "val_loss": 0.6939654660224914, "val_acc": 52.0}
{"epoch": 26, "training_loss": 0.6930968332290649, "training_acc": 53.0, "val_loss": 0.6938684153556823, "val_acc": 52.0}
{"epoch": 27, "training_loss": 0.6964639282226562, "training_acc": 53.0, "val_loss": 0.6950404047966003, "val_acc": 52.0}
{"epoch": 28, "training_loss": 0.6957078409194947, "training_acc": 53.0, "val_loss": 0.692403633594513, "val_acc": 52.0}
{"epoch": 29, "training_loss": 0.6939605498313903, "training_acc": 53.0, "val_loss": 0.6926987171173096, "val_acc": 52.0}
{"epoch": 30, "training_loss": 0.69231849193573, "training_acc": 53.0, "val_loss": 0.6926905202865601, "val_acc": 52.0}
{"epoch": 31, "training_loss": 0.6945613670349121, "training_acc": 53.0, "val_loss": 0.6927034378051757, "val_acc": 52.0}
{"epoch": 32, "training_loss": 0.6953889918327332, "training_acc": 44.0, "val_loss": 0.6926750874519348, "val_acc": 52.0}
{"epoch": 33, "training_loss": 0.6952576351165771, "training_acc": 53.0, "val_loss": 0.6939056491851807, "val_acc": 52.0}
