"main_modify.py --pretrained_path /scratch/connectome/dyhan316/VAE_ADHD/barlowtwins/pretrain_results/ABCDbt128a102.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 1 --task ABCD_sex --input_option BT_org --learning_rate 1e-4 --batch_size 16 --weight_decay 1e-2 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 0.6986357402801514, "training_acc": 47.0, "val_loss": 0.6934515023231507, "val_acc": 48.0}
{"epoch": 1, "training_loss": 0.6940925121307373, "training_acc": 50.0, "val_loss": 0.6930031609535218, "val_acc": 52.0}
{"epoch": 2, "training_loss": 0.6937913918495178, "training_acc": 45.0, "val_loss": 0.6923999094963074, "val_acc": 52.0}
{"epoch": 3, "training_loss": 0.6902595162391663, "training_acc": 53.0, "val_loss": 0.6936912083625794, "val_acc": 52.0}
{"epoch": 4, "training_loss": 0.6999761772155761, "training_acc": 53.0, "val_loss": 0.6948097729682923, "val_acc": 52.0}
{"epoch": 5, "training_loss": 0.6934015655517578, "training_acc": 53.0, "val_loss": 0.6933393430709839, "val_acc": 52.0}
{"epoch": 6, "training_loss": 0.6923593282699585, "training_acc": 53.0, "val_loss": 0.6924635314941406, "val_acc": 52.0}
{"epoch": 7, "training_loss": 0.6933534526824952, "training_acc": 53.0, "val_loss": 0.6923881220817566, "val_acc": 52.0}
{"epoch": 8, "training_loss": 0.6918617510795593, "training_acc": 53.0, "val_loss": 0.6922987699508667, "val_acc": 52.0}
{"epoch": 9, "training_loss": 0.6924163770675659, "training_acc": 53.0, "val_loss": 0.6924542212486267, "val_acc": 52.0}
{"epoch": 10, "training_loss": 0.6928601694107056, "training_acc": 53.0, "val_loss": 0.6930405378341675, "val_acc": 52.0}
{"epoch": 11, "training_loss": 0.6922934579849244, "training_acc": 53.0, "val_loss": 0.692565405368805, "val_acc": 52.0}
{"epoch": 12, "training_loss": 0.6940470242500305, "training_acc": 53.0, "val_loss": 0.6930121231079102, "val_acc": 52.0}
{"epoch": 13, "training_loss": 0.6945161151885987, "training_acc": 53.0, "val_loss": 0.6946589326858521, "val_acc": 52.0}
{"epoch": 14, "training_loss": 0.6921550464630127, "training_acc": 53.0, "val_loss": 0.6925171613693237, "val_acc": 52.0}
{"epoch": 15, "training_loss": 0.6944584012031555, "training_acc": 47.0, "val_loss": 0.6928344893455506, "val_acc": 52.0}
{"epoch": 16, "training_loss": 0.6914720630645752, "training_acc": 53.0, "val_loss": 0.6915620255470276, "val_acc": 52.0}
{"epoch": 17, "training_loss": 0.692992296218872, "training_acc": 53.0, "val_loss": 0.6923244857788086, "val_acc": 52.0}
{"epoch": 18, "training_loss": 0.6926852750778199, "training_acc": 53.0, "val_loss": 0.6927559185028076, "val_acc": 52.0}
{"epoch": 19, "training_loss": 0.6935842847824096, "training_acc": 49.0, "val_loss": 0.6923782277107239, "val_acc": 52.0}
{"epoch": 20, "training_loss": 0.6923680067062378, "training_acc": 53.0, "val_loss": 0.6926529812812805, "val_acc": 52.0}
{"epoch": 21, "training_loss": 0.6941836953163147, "training_acc": 53.0, "val_loss": 0.6925305509567261, "val_acc": 52.0}
{"epoch": 22, "training_loss": 0.6938522267341614, "training_acc": 53.0, "val_loss": 0.6938535404205323, "val_acc": 52.0}
{"epoch": 23, "training_loss": 0.6919161415100098, "training_acc": 53.0, "val_loss": 0.6925444555282593, "val_acc": 52.0}
{"epoch": 24, "training_loss": 0.6927199053764344, "training_acc": 53.0, "val_loss": 0.6925506544113159, "val_acc": 52.0}
{"epoch": 25, "training_loss": 0.6941442680358887, "training_acc": 53.0, "val_loss": 0.6923923563957214, "val_acc": 52.0}
{"epoch": 26, "training_loss": 0.6950107431411743, "training_acc": 53.0, "val_loss": 0.6926437711715698, "val_acc": 52.0}
{"epoch": 27, "training_loss": 0.6950298023223876, "training_acc": 53.0, "val_loss": 0.692372887134552, "val_acc": 52.0}
{"epoch": 28, "training_loss": 0.6925655364990234, "training_acc": 53.0, "val_loss": 0.6925672245025635, "val_acc": 52.0}
{"epoch": 29, "training_loss": 0.6945509624481201, "training_acc": 53.0, "val_loss": 0.6923099803924561, "val_acc": 52.0}
{"epoch": 30, "training_loss": 0.6950173664093018, "training_acc": 53.0, "val_loss": 0.6925855565071106, "val_acc": 52.0}
{"epoch": 31, "training_loss": 0.696141529083252, "training_acc": 47.0, "val_loss": 0.6923530387878418, "val_acc": 52.0}
{"epoch": 32, "training_loss": 0.6913336825370788, "training_acc": 53.0, "val_loss": 0.6923311519622802, "val_acc": 52.0}
{"epoch": 33, "training_loss": 0.6939599514007568, "training_acc": 53.0, "val_loss": 0.6926038289070129, "val_acc": 52.0}
{"epoch": 34, "training_loss": 0.6922184991836547, "training_acc": 53.0, "val_loss": 0.6931282472610474, "val_acc": 52.0}
{"epoch": 35, "training_loss": 0.692935299873352, "training_acc": 53.0, "val_loss": 0.6924475574493408, "val_acc": 52.0}
