"main_modify.py --pretrained_path /scratch/connectome/dyhan316/VAE_ADHD/barlowtwins/pretrain_results/ABCDbt128a102.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option BT_org --learning_rate 5e-4 --batch_size 16 --weight_decay 5e-3 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 0.6994502973556519, "training_acc": 50.0, "val_loss": 0.6950204110145569, "val_acc": 52.0}
{"epoch": 1, "training_loss": 0.6938188648223877, "training_acc": 53.0, "val_loss": 0.6931181073188781, "val_acc": 52.0}
{"epoch": 2, "training_loss": 0.6939005589485169, "training_acc": 53.0, "val_loss": 0.6927370834350586, "val_acc": 52.0}
{"epoch": 3, "training_loss": 0.696666510105133, "training_acc": 53.0, "val_loss": 0.6924909472465515, "val_acc": 52.0}
{"epoch": 4, "training_loss": 0.6960998392105102, "training_acc": 53.0, "val_loss": 0.6923716688156127, "val_acc": 52.0}
{"epoch": 5, "training_loss": 0.6978043389320373, "training_acc": 50.0, "val_loss": 0.6948907160758973, "val_acc": 52.0}
{"epoch": 6, "training_loss": 0.700756573677063, "training_acc": 53.0, "val_loss": 0.6945509743690491, "val_acc": 52.0}
{"epoch": 7, "training_loss": 0.692057204246521, "training_acc": 53.0, "val_loss": 0.6926850581169128, "val_acc": 52.0}
{"epoch": 8, "training_loss": 0.7004296183586121, "training_acc": 53.0, "val_loss": 0.6923578763008118, "val_acc": 52.0}
{"epoch": 9, "training_loss": 0.6984781503677369, "training_acc": 47.0, "val_loss": 0.6931201243400573, "val_acc": 52.0}
{"epoch": 10, "training_loss": 0.7016671800613403, "training_acc": 53.0, "val_loss": 0.6932486510276794, "val_acc": 52.0}
{"epoch": 11, "training_loss": 0.6950354528427124, "training_acc": 53.0, "val_loss": 0.6940010643005371, "val_acc": 48.0}
{"epoch": 12, "training_loss": 0.6946959018707275, "training_acc": 51.0, "val_loss": 0.7000121021270752, "val_acc": 48.0}
{"epoch": 13, "training_loss": 0.7027610731124878, "training_acc": 47.0, "val_loss": 0.6925153398513794, "val_acc": 52.0}
{"epoch": 14, "training_loss": 0.6932369375228882, "training_acc": 53.0, "val_loss": 0.699073965549469, "val_acc": 52.0}
{"epoch": 15, "training_loss": 0.6960256505012512, "training_acc": 53.0, "val_loss": 0.6923434901237487, "val_acc": 52.0}
{"epoch": 16, "training_loss": 0.6986865448951721, "training_acc": 43.0, "val_loss": 0.6924107456207276, "val_acc": 52.0}
{"epoch": 17, "training_loss": 0.6917124342918396, "training_acc": 53.0, "val_loss": 0.6940280079841614, "val_acc": 52.0}
{"epoch": 18, "training_loss": 0.6965441346168518, "training_acc": 53.0, "val_loss": 0.6925574445724487, "val_acc": 52.0}
{"epoch": 19, "training_loss": 0.6940537309646606, "training_acc": 53.0, "val_loss": 0.6933013081550599, "val_acc": 52.0}
{"epoch": 20, "training_loss": 0.6940250945091248, "training_acc": 53.0, "val_loss": 0.6930629849433899, "val_acc": 52.0}
{"epoch": 21, "training_loss": 0.6946534848213196, "training_acc": 53.0, "val_loss": 0.6933105206489563, "val_acc": 52.0}
{"epoch": 22, "training_loss": 0.6956102132797242, "training_acc": 53.0, "val_loss": 0.6923609328269958, "val_acc": 52.0}
{"epoch": 23, "training_loss": 0.6939812636375428, "training_acc": 47.0, "val_loss": 0.6935618734359741, "val_acc": 48.0}
{"epoch": 24, "training_loss": 0.7064973044395447, "training_acc": 49.0, "val_loss": 0.693794629573822, "val_acc": 52.0}
{"epoch": 25, "training_loss": 0.7152512454986573, "training_acc": 53.0, "val_loss": 0.7014867973327636, "val_acc": 52.0}
{"epoch": 26, "training_loss": 0.6963107061386108, "training_acc": 53.0, "val_loss": 0.692410671710968, "val_acc": 52.0}
{"epoch": 27, "training_loss": 0.7075762891769409, "training_acc": 49.0, "val_loss": 0.6950510835647583, "val_acc": 48.0}
{"epoch": 28, "training_loss": 0.6971957397460937, "training_acc": 49.0, "val_loss": 0.6993244194984436, "val_acc": 52.0}
{"epoch": 29, "training_loss": 0.7079544568061829, "training_acc": 53.0, "val_loss": 0.6957680916786194, "val_acc": 52.0}
{"epoch": 30, "training_loss": 0.6952231907844544, "training_acc": 53.0, "val_loss": 0.692481873035431, "val_acc": 52.0}
{"epoch": 31, "training_loss": 0.693800208568573, "training_acc": 53.0, "val_loss": 0.6923494362831115, "val_acc": 52.0}
{"epoch": 32, "training_loss": 0.6935796022415162, "training_acc": 53.0, "val_loss": 0.6952532196044922, "val_acc": 52.0}
{"epoch": 33, "training_loss": 0.7095083260536194, "training_acc": 53.0, "val_loss": 0.6935105109214783, "val_acc": 52.0}
{"epoch": 34, "training_loss": 0.6966989850997924, "training_acc": 47.0, "val_loss": 0.6954093551635743, "val_acc": 48.0}
