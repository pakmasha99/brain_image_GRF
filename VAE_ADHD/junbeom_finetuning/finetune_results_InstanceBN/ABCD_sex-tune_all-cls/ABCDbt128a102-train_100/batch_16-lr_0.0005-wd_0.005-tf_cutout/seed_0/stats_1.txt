"main_modify.py --pretrained_path /scratch/connectome/dyhan316/VAE_ADHD/barlowtwins/pretrain_results/ABCDbt128a102.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option BT_org --learning_rate 5e-4 --batch_size 16 --weight_decay 5e-3 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 0.7021080923080444, "training_acc": 47.0, "val_loss": 0.6928164410591126, "val_acc": 52.0}
{"epoch": 1, "training_loss": 0.7031994962692261, "training_acc": 53.0, "val_loss": 0.694675145149231, "val_acc": 52.0}
{"epoch": 2, "training_loss": 0.702995834350586, "training_acc": 47.0, "val_loss": 0.6929518675804138, "val_acc": 52.0}
{"epoch": 3, "training_loss": 0.6979911851882935, "training_acc": 53.0, "val_loss": 0.6930508136749267, "val_acc": 52.0}
{"epoch": 4, "training_loss": 0.6972620391845703, "training_acc": 53.0, "val_loss": 0.6976581621170044, "val_acc": 52.0}
{"epoch": 5, "training_loss": 0.6919757056236268, "training_acc": 53.0, "val_loss": 0.6924014258384704, "val_acc": 52.0}
{"epoch": 6, "training_loss": 0.7044269108772278, "training_acc": 47.0, "val_loss": 0.6928539323806763, "val_acc": 52.0}
{"epoch": 7, "training_loss": 0.6989960098266601, "training_acc": 53.0, "val_loss": 0.6930388569831848, "val_acc": 52.0}
{"epoch": 8, "training_loss": 0.7046105241775513, "training_acc": 53.0, "val_loss": 0.6929720401763916, "val_acc": 52.0}
{"epoch": 9, "training_loss": 0.6969487285614013, "training_acc": 53.0, "val_loss": 0.6924167990684509, "val_acc": 52.0}
{"epoch": 10, "training_loss": 0.6955600690841675, "training_acc": 49.0, "val_loss": 0.6933403706550598, "val_acc": 52.0}
{"epoch": 11, "training_loss": 0.696104736328125, "training_acc": 53.0, "val_loss": 0.6934605526924134, "val_acc": 52.0}
{"epoch": 12, "training_loss": 0.6945247459411621, "training_acc": 53.0, "val_loss": 0.6924446892738342, "val_acc": 52.0}
{"epoch": 13, "training_loss": 0.7006165194511413, "training_acc": 41.0, "val_loss": 0.6923756098747254, "val_acc": 52.0}
{"epoch": 14, "training_loss": 0.6912014389038086, "training_acc": 53.0, "val_loss": 0.6962316179275513, "val_acc": 52.0}
{"epoch": 15, "training_loss": 0.6952634000778198, "training_acc": 53.0, "val_loss": 0.6923675107955932, "val_acc": 52.0}
{"epoch": 16, "training_loss": 0.7102895021438599, "training_acc": 41.0, "val_loss": 0.6924548053741455, "val_acc": 52.0}
{"epoch": 17, "training_loss": 0.6997693371772766, "training_acc": 35.0, "val_loss": 0.6947404527664185, "val_acc": 52.0}
{"epoch": 18, "training_loss": 0.6971366024017334, "training_acc": 53.0, "val_loss": 0.6926151204109192, "val_acc": 52.0}
{"epoch": 19, "training_loss": 0.7025325965881347, "training_acc": 45.0, "val_loss": 0.6958425736427307, "val_acc": 48.0}
{"epoch": 20, "training_loss": 0.7005525875091553, "training_acc": 41.0, "val_loss": 0.6925042080879211, "val_acc": 52.0}
{"epoch": 21, "training_loss": 0.7015628790855408, "training_acc": 53.0, "val_loss": 0.6992284798622131, "val_acc": 52.0}
{"epoch": 22, "training_loss": 0.7031933403015137, "training_acc": 53.0, "val_loss": 0.6930975723266601, "val_acc": 52.0}
{"epoch": 23, "training_loss": 0.6942863082885742, "training_acc": 55.0, "val_loss": 0.6957441306114197, "val_acc": 48.0}
{"epoch": 24, "training_loss": 0.7001281452178955, "training_acc": 49.0, "val_loss": 0.6928023505210876, "val_acc": 52.0}
{"epoch": 25, "training_loss": 0.6923835515975952, "training_acc": 53.0, "val_loss": 0.6924691152572632, "val_acc": 52.0}
{"epoch": 26, "training_loss": 0.6975174069404602, "training_acc": 53.0, "val_loss": 0.6934943509101867, "val_acc": 52.0}
{"epoch": 27, "training_loss": 0.6963398790359497, "training_acc": 53.0, "val_loss": 0.6935946702957153, "val_acc": 52.0}
{"epoch": 28, "training_loss": 0.7036041355133057, "training_acc": 39.0, "val_loss": 0.6923930668830871, "val_acc": 52.0}
{"epoch": 29, "training_loss": 0.6922754287719727, "training_acc": 53.0, "val_loss": 0.6932029461860657, "val_acc": 52.0}
{"epoch": 30, "training_loss": 0.706930227279663, "training_acc": 35.0, "val_loss": 0.6923560261726379, "val_acc": 52.0}
{"epoch": 31, "training_loss": 0.698080096244812, "training_acc": 53.0, "val_loss": 0.6925937294960022, "val_acc": 52.0}
{"epoch": 32, "training_loss": 0.6905249786376954, "training_acc": 53.0, "val_loss": 0.6939009881019592, "val_acc": 48.0}
{"epoch": 33, "training_loss": 0.7004950141906738, "training_acc": 47.0, "val_loss": 0.6924116563796997, "val_acc": 52.0}
{"epoch": 34, "training_loss": 0.6986469221115112, "training_acc": 53.0, "val_loss": 0.6938549852371216, "val_acc": 52.0}
{"epoch": 35, "training_loss": 0.6939108324050903, "training_acc": 53.0, "val_loss": 0.6923737812042237, "val_acc": 52.0}
{"epoch": 36, "training_loss": 0.6947764825820922, "training_acc": 53.0, "val_loss": 0.6926440286636353, "val_acc": 52.0}
{"epoch": 37, "training_loss": 0.6932210278511047, "training_acc": 53.0, "val_loss": 0.6940842413902283, "val_acc": 52.0}
{"epoch": 38, "training_loss": 0.693968186378479, "training_acc": 53.0, "val_loss": 0.695416100025177, "val_acc": 52.0}
{"epoch": 39, "training_loss": 0.694763605594635, "training_acc": 53.0, "val_loss": 0.6945758748054505, "val_acc": 52.0}
{"epoch": 40, "training_loss": 0.6919318008422851, "training_acc": 53.0, "val_loss": 0.6935489654541016, "val_acc": 48.0}
{"epoch": 41, "training_loss": 0.6996712779998779, "training_acc": 47.0, "val_loss": 0.6928155064582825, "val_acc": 52.0}
{"epoch": 42, "training_loss": 0.6927802610397339, "training_acc": 53.0, "val_loss": 0.6927340197563171, "val_acc": 52.0}
{"epoch": 43, "training_loss": 0.6939064598083496, "training_acc": 53.0, "val_loss": 0.6938264489173889, "val_acc": 52.0}
{"epoch": 44, "training_loss": 0.6957045197486877, "training_acc": 53.0, "val_loss": 0.6937952351570129, "val_acc": 52.0}
{"epoch": 45, "training_loss": 0.6940404844284057, "training_acc": 53.0, "val_loss": 0.6924764251708985, "val_acc": 52.0}
{"epoch": 46, "training_loss": 0.694129753112793, "training_acc": 47.0, "val_loss": 0.6928395462036133, "val_acc": 52.0}
{"epoch": 47, "training_loss": 0.6963283061981201, "training_acc": 53.0, "val_loss": 0.6960696911811829, "val_acc": 52.0}
{"epoch": 48, "training_loss": 0.6976139712333679, "training_acc": 53.0, "val_loss": 0.6924370837211609, "val_acc": 52.0}
{"epoch": 49, "training_loss": 0.7049707174301147, "training_acc": 43.0, "val_loss": 0.6948957014083862, "val_acc": 48.0}
