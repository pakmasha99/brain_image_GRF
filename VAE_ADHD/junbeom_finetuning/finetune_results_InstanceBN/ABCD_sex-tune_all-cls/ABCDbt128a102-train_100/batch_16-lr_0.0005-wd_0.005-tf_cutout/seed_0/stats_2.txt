"main_modify.py --pretrained_path /scratch/connectome/dyhan316/VAE_ADHD/barlowtwins/pretrain_results/ABCDbt128a102.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option BT_org --learning_rate 5e-4 --batch_size 16 --weight_decay 5e-3 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 0.7004761791229248, "training_acc": 50.0, "val_loss": 0.6931259655952453, "val_acc": 52.0}
{"epoch": 1, "training_loss": 0.6934120368957519, "training_acc": 53.0, "val_loss": 0.6931120133399964, "val_acc": 52.0}
{"epoch": 2, "training_loss": 0.6939884996414185, "training_acc": 53.0, "val_loss": 0.6926962327957153, "val_acc": 52.0}
{"epoch": 3, "training_loss": 0.694298448562622, "training_acc": 53.0, "val_loss": 0.6923550748825074, "val_acc": 52.0}
{"epoch": 4, "training_loss": 0.7042678737640381, "training_acc": 49.0, "val_loss": 0.6931362509727478, "val_acc": 52.0}
{"epoch": 5, "training_loss": 0.7019695234298706, "training_acc": 53.0, "val_loss": 0.6944868421554565, "val_acc": 52.0}
{"epoch": 6, "training_loss": 0.6930969715118408, "training_acc": 53.0, "val_loss": 0.6926279664039612, "val_acc": 52.0}
{"epoch": 7, "training_loss": 0.6954025292396545, "training_acc": 53.0, "val_loss": 0.6938439917564392, "val_acc": 52.0}
{"epoch": 8, "training_loss": 0.697986388206482, "training_acc": 51.0, "val_loss": 0.6945280814170838, "val_acc": 52.0}
{"epoch": 9, "training_loss": 0.6942948341369629, "training_acc": 53.0, "val_loss": 0.6951643919944763, "val_acc": 52.0}
{"epoch": 10, "training_loss": 0.6943212342262268, "training_acc": 53.0, "val_loss": 0.6926629447937012, "val_acc": 52.0}
{"epoch": 11, "training_loss": 0.6981003141403198, "training_acc": 47.0, "val_loss": 0.6951936626434326, "val_acc": 48.0}
{"epoch": 12, "training_loss": 0.6951406288146973, "training_acc": 47.0, "val_loss": 0.692585620880127, "val_acc": 52.0}
{"epoch": 13, "training_loss": 0.6956478118896484, "training_acc": 53.0, "val_loss": 0.6984311747550964, "val_acc": 52.0}
{"epoch": 14, "training_loss": 0.6938288998603821, "training_acc": 53.0, "val_loss": 0.6923834276199341, "val_acc": 52.0}
{"epoch": 15, "training_loss": 0.6927946186065674, "training_acc": 53.0, "val_loss": 0.6924755716323853, "val_acc": 52.0}
{"epoch": 16, "training_loss": 0.6985313963890075, "training_acc": 43.0, "val_loss": 0.6926227307319641, "val_acc": 52.0}
{"epoch": 17, "training_loss": 0.6948037695884705, "training_acc": 53.0, "val_loss": 0.6950942993164062, "val_acc": 52.0}
{"epoch": 18, "training_loss": 0.6943333220481872, "training_acc": 53.0, "val_loss": 0.6923992252349853, "val_acc": 52.0}
{"epoch": 19, "training_loss": 0.6965371417999268, "training_acc": 49.0, "val_loss": 0.6930173516273499, "val_acc": 52.0}
{"epoch": 20, "training_loss": 0.69511554479599, "training_acc": 53.0, "val_loss": 0.6953249502182007, "val_acc": 52.0}
{"epoch": 21, "training_loss": 0.6971957898139953, "training_acc": 53.0, "val_loss": 0.6925899267196656, "val_acc": 52.0}
{"epoch": 22, "training_loss": 0.6920372128486634, "training_acc": 53.0, "val_loss": 0.6929216408729553, "val_acc": 52.0}
