"main_modify.py --pretrained_path /scratch/connectome/dyhan316/VAE_ADHD/barlowtwins/pretrain_results/ABCDbt128a102.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option BT_org --learning_rate 1e-5 --batch_size 16 --weight_decay 1e-3 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 0.6899608421325684, "training_acc": 53.0, "val_loss": 0.6941972804069519, "val_acc": 52.0}
{"epoch": 1, "training_loss": 0.6885760259628296, "training_acc": 53.0, "val_loss": 0.6945931243896485, "val_acc": 52.0}
{"epoch": 2, "training_loss": 0.6881606960296631, "training_acc": 53.0, "val_loss": 0.6935343861579895, "val_acc": 52.0}
{"epoch": 3, "training_loss": 0.6893632292747498, "training_acc": 53.0, "val_loss": 0.6948418498039246, "val_acc": 52.0}
{"epoch": 4, "training_loss": 0.6866540765762329, "training_acc": 53.0, "val_loss": 0.6958076930046082, "val_acc": 52.0}
{"epoch": 5, "training_loss": 0.6844974660873413, "training_acc": 53.0, "val_loss": 0.6992531037330627, "val_acc": 52.0}
{"epoch": 6, "training_loss": 0.6825405335426331, "training_acc": 53.0, "val_loss": 0.6972006607055664, "val_acc": 52.0}
{"epoch": 7, "training_loss": 0.6819448137283325, "training_acc": 53.0, "val_loss": 0.7002998948097229, "val_acc": 52.0}
{"epoch": 8, "training_loss": 0.6810744857788086, "training_acc": 53.0, "val_loss": 0.7002161431312561, "val_acc": 52.0}
{"epoch": 9, "training_loss": 0.678454966545105, "training_acc": 54.0, "val_loss": 0.6988924884796143, "val_acc": 52.0}
{"epoch": 10, "training_loss": 0.680614423751831, "training_acc": 52.0, "val_loss": 0.7003710865974426, "val_acc": 52.0}
{"epoch": 11, "training_loss": 0.6761965823173522, "training_acc": 59.0, "val_loss": 0.7037283825874329, "val_acc": 48.0}
{"epoch": 12, "training_loss": 0.6732886338233948, "training_acc": 62.0, "val_loss": 0.7026797366142273, "val_acc": 48.0}
{"epoch": 13, "training_loss": 0.6732769227027893, "training_acc": 61.0, "val_loss": 0.704455726146698, "val_acc": 44.0}
{"epoch": 14, "training_loss": 0.6721214628219605, "training_acc": 61.0, "val_loss": 0.7059184193611145, "val_acc": 48.0}
{"epoch": 15, "training_loss": 0.6712917137145996, "training_acc": 63.0, "val_loss": 0.7028480529785156, "val_acc": 48.0}
{"epoch": 16, "training_loss": 0.6724229168891906, "training_acc": 69.0, "val_loss": 0.7069952130317688, "val_acc": 44.0}
{"epoch": 17, "training_loss": 0.6719260454177857, "training_acc": 63.0, "val_loss": 0.7099125218391419, "val_acc": 48.0}
{"epoch": 18, "training_loss": 0.6666109204292298, "training_acc": 69.0, "val_loss": 0.7072515964508057, "val_acc": 40.0}
{"epoch": 19, "training_loss": 0.6632758641242981, "training_acc": 73.0, "val_loss": 0.7139270091056824, "val_acc": 36.0}
{"epoch": 20, "training_loss": 0.6621780776977539, "training_acc": 70.0, "val_loss": 0.7129338216781617, "val_acc": 48.0}
{"epoch": 21, "training_loss": 0.6626477122306824, "training_acc": 72.0, "val_loss": 0.715392758846283, "val_acc": 44.0}
