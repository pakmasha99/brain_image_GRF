"main_modify.py --pretrained_path /scratch/connectome/dyhan316/VAE_ADHD/barlowtwins/pretrain_results/ABCDbt128a102.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option BT_org --learning_rate 1e-5 --batch_size 16 --weight_decay 1e-3 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 0.7030432176589966, "training_acc": 47.0, "val_loss": 0.6993425011634826, "val_acc": 48.0}
{"epoch": 1, "training_loss": 0.7017929339408875, "training_acc": 47.0, "val_loss": 0.6974265170097351, "val_acc": 48.0}
{"epoch": 2, "training_loss": 0.6999670934677124, "training_acc": 47.0, "val_loss": 0.6977672219276428, "val_acc": 48.0}
{"epoch": 3, "training_loss": 0.6987532377243042, "training_acc": 47.0, "val_loss": 0.6956742358207703, "val_acc": 48.0}
{"epoch": 4, "training_loss": 0.6967906022071838, "training_acc": 47.0, "val_loss": 0.6925504660606384, "val_acc": 48.0}
{"epoch": 5, "training_loss": 0.6955008268356323, "training_acc": 47.0, "val_loss": 0.6944432854652405, "val_acc": 48.0}
{"epoch": 6, "training_loss": 0.6940582156181335, "training_acc": 47.0, "val_loss": 0.6943120527267456, "val_acc": 48.0}
{"epoch": 7, "training_loss": 0.6916680026054383, "training_acc": 47.0, "val_loss": 0.6925550293922424, "val_acc": 48.0}
{"epoch": 8, "training_loss": 0.6892294311523437, "training_acc": 47.0, "val_loss": 0.6920394253730774, "val_acc": 48.0}
{"epoch": 9, "training_loss": 0.6907981085777283, "training_acc": 47.0, "val_loss": 0.6890336394309997, "val_acc": 48.0}
{"epoch": 10, "training_loss": 0.6873056888580322, "training_acc": 52.0, "val_loss": 0.6870932769775391, "val_acc": 64.0}
{"epoch": 11, "training_loss": 0.6868934679031372, "training_acc": 58.0, "val_loss": 0.6874616932868958, "val_acc": 60.0}
{"epoch": 12, "training_loss": 0.6844139122962951, "training_acc": 60.0, "val_loss": 0.6880426144599915, "val_acc": 60.0}
{"epoch": 13, "training_loss": 0.6815530776977539, "training_acc": 64.0, "val_loss": 0.6867241287231445, "val_acc": 64.0}
{"epoch": 14, "training_loss": 0.6808876419067382, "training_acc": 69.0, "val_loss": 0.6826051378250122, "val_acc": 64.0}
{"epoch": 15, "training_loss": 0.6800642919540405, "training_acc": 69.0, "val_loss": 0.6845556282997132, "val_acc": 64.0}
{"epoch": 16, "training_loss": 0.6808401107788086, "training_acc": 66.0, "val_loss": 0.6858959317207336, "val_acc": 56.0}
{"epoch": 17, "training_loss": 0.6760156154632568, "training_acc": 72.0, "val_loss": 0.6839146423339844, "val_acc": 68.0}
{"epoch": 18, "training_loss": 0.6770113563537598, "training_acc": 69.0, "val_loss": 0.6850382089614868, "val_acc": 56.0}
{"epoch": 19, "training_loss": 0.674078483581543, "training_acc": 70.0, "val_loss": 0.6843977808952332, "val_acc": 64.0}
{"epoch": 20, "training_loss": 0.6753849124908448, "training_acc": 72.0, "val_loss": 0.684600658416748, "val_acc": 60.0}
{"epoch": 21, "training_loss": 0.6709197473526001, "training_acc": 75.0, "val_loss": 0.6822691082954406, "val_acc": 64.0}
{"epoch": 22, "training_loss": 0.6693430089950562, "training_acc": 78.0, "val_loss": 0.6794939470291138, "val_acc": 64.0}
{"epoch": 23, "training_loss": 0.667268385887146, "training_acc": 73.0, "val_loss": 0.6785919737815856, "val_acc": 64.0}
{"epoch": 24, "training_loss": 0.6676887774467468, "training_acc": 74.0, "val_loss": 0.6821136021614075, "val_acc": 60.0}
{"epoch": 25, "training_loss": 0.6677304935455323, "training_acc": 75.0, "val_loss": 0.6773891472816467, "val_acc": 64.0}
{"epoch": 26, "training_loss": 0.6693143939971924, "training_acc": 73.0, "val_loss": 0.681692533493042, "val_acc": 64.0}
{"epoch": 27, "training_loss": 0.6645872569084168, "training_acc": 77.0, "val_loss": 0.6803666758537292, "val_acc": 60.0}
{"epoch": 28, "training_loss": 0.6631809759140015, "training_acc": 71.0, "val_loss": 0.6811428475379944, "val_acc": 64.0}
{"epoch": 29, "training_loss": 0.6663207244873047, "training_acc": 75.0, "val_loss": 0.6795876574516296, "val_acc": 64.0}
{"epoch": 30, "training_loss": 0.664727942943573, "training_acc": 71.0, "val_loss": 0.685367865562439, "val_acc": 64.0}
{"epoch": 31, "training_loss": 0.6670311570167542, "training_acc": 73.0, "val_loss": 0.6790282034873962, "val_acc": 64.0}
{"epoch": 32, "training_loss": 0.6657279634475708, "training_acc": 69.0, "val_loss": 0.6761657667160034, "val_acc": 64.0}
{"epoch": 33, "training_loss": 0.6596096229553222, "training_acc": 72.0, "val_loss": 0.6847097134590149, "val_acc": 64.0}
{"epoch": 34, "training_loss": 0.662200059890747, "training_acc": 75.0, "val_loss": 0.6713285017013549, "val_acc": 64.0}
{"epoch": 35, "training_loss": 0.6603619909286499, "training_acc": 77.0, "val_loss": 0.6832265067100525, "val_acc": 48.0}
{"epoch": 36, "training_loss": 0.6568094968795777, "training_acc": 73.0, "val_loss": 0.6760663628578186, "val_acc": 64.0}
{"epoch": 37, "training_loss": 0.655927460193634, "training_acc": 72.0, "val_loss": 0.679972414970398, "val_acc": 64.0}
{"epoch": 38, "training_loss": 0.6527251482009888, "training_acc": 80.0, "val_loss": 0.6822538709640503, "val_acc": 52.0}
{"epoch": 39, "training_loss": 0.6520273423194886, "training_acc": 78.0, "val_loss": 0.6751627326011658, "val_acc": 64.0}
{"epoch": 40, "training_loss": 0.6572760105133056, "training_acc": 75.0, "val_loss": 0.691015543937683, "val_acc": 56.0}
{"epoch": 41, "training_loss": 0.6632966995239258, "training_acc": 72.0, "val_loss": 0.6752996158599853, "val_acc": 64.0}
{"epoch": 42, "training_loss": 0.6577818512916564, "training_acc": 76.0, "val_loss": 0.679114248752594, "val_acc": 56.0}
{"epoch": 43, "training_loss": 0.6499019908905029, "training_acc": 73.0, "val_loss": 0.6731851410865783, "val_acc": 64.0}
{"epoch": 44, "training_loss": 0.6478566217422486, "training_acc": 77.0, "val_loss": 0.6771408104896546, "val_acc": 60.0}
{"epoch": 45, "training_loss": 0.646879448890686, "training_acc": 80.0, "val_loss": 0.6822835397720337, "val_acc": 52.0}
{"epoch": 46, "training_loss": 0.6463829278945923, "training_acc": 80.0, "val_loss": 0.6776176047325134, "val_acc": 68.0}
{"epoch": 47, "training_loss": 0.6508546710014343, "training_acc": 73.0, "val_loss": 0.6778830790519714, "val_acc": 56.0}
{"epoch": 48, "training_loss": 0.6546878910064697, "training_acc": 75.0, "val_loss": 0.6809001183509826, "val_acc": 56.0}
{"epoch": 49, "training_loss": 0.6498022317886353, "training_acc": 75.0, "val_loss": 0.675039598941803, "val_acc": 68.0}
{"epoch": 50, "training_loss": 0.6470862817764282, "training_acc": 75.0, "val_loss": 0.679501633644104, "val_acc": 44.0}
{"epoch": 51, "training_loss": 0.6402900099754334, "training_acc": 79.0, "val_loss": 0.6787690305709839, "val_acc": 56.0}
{"epoch": 52, "training_loss": 0.6368418407440185, "training_acc": 79.0, "val_loss": 0.678273286819458, "val_acc": 52.0}
{"epoch": 53, "training_loss": 0.6378633117675782, "training_acc": 79.0, "val_loss": 0.6748604488372802, "val_acc": 60.0}
