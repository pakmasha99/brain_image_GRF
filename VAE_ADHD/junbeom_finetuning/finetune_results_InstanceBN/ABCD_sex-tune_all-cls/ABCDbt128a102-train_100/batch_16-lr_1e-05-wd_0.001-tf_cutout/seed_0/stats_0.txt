"main_modify.py --pretrained_path /scratch/connectome/dyhan316/VAE_ADHD/barlowtwins/pretrain_results/ABCDbt128a102.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option BT_org --learning_rate 1e-5 --batch_size 16 --weight_decay 1e-3 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 0.6921185064315796, "training_acc": 52.0, "val_loss": 0.6893625736236573, "val_acc": 56.0}
{"epoch": 1, "training_loss": 0.6912291383743286, "training_acc": 52.0, "val_loss": 0.6871804070472717, "val_acc": 56.0}
{"epoch": 2, "training_loss": 0.6918387651443482, "training_acc": 52.0, "val_loss": 0.6888021922111511, "val_acc": 56.0}
{"epoch": 3, "training_loss": 0.6916112279891968, "training_acc": 52.0, "val_loss": 0.6867908906936645, "val_acc": 56.0}
{"epoch": 4, "training_loss": 0.6926537346839905, "training_acc": 52.0, "val_loss": 0.6877306222915649, "val_acc": 56.0}
{"epoch": 5, "training_loss": 0.6904337072372436, "training_acc": 52.0, "val_loss": 0.6876930737495422, "val_acc": 56.0}
{"epoch": 6, "training_loss": 0.6891224932670593, "training_acc": 52.0, "val_loss": 0.685616717338562, "val_acc": 56.0}
{"epoch": 7, "training_loss": 0.687595648765564, "training_acc": 53.0, "val_loss": 0.6869874310493469, "val_acc": 56.0}
{"epoch": 8, "training_loss": 0.6901165866851806, "training_acc": 53.0, "val_loss": 0.6864444756507874, "val_acc": 56.0}
{"epoch": 9, "training_loss": 0.6890100908279418, "training_acc": 58.0, "val_loss": 0.6855134010314942, "val_acc": 56.0}
{"epoch": 10, "training_loss": 0.6859673929214477, "training_acc": 60.0, "val_loss": 0.6843468546867371, "val_acc": 56.0}
{"epoch": 11, "training_loss": 0.6840282702445983, "training_acc": 60.0, "val_loss": 0.6852299046516418, "val_acc": 56.0}
{"epoch": 12, "training_loss": 0.6826240682601928, "training_acc": 61.0, "val_loss": 0.6848048138618469, "val_acc": 56.0}
{"epoch": 13, "training_loss": 0.682182297706604, "training_acc": 62.0, "val_loss": 0.6825420355796814, "val_acc": 60.0}
{"epoch": 14, "training_loss": 0.6791200876235962, "training_acc": 62.0, "val_loss": 0.6829631495475769, "val_acc": 60.0}
{"epoch": 15, "training_loss": 0.6785636329650879, "training_acc": 62.0, "val_loss": 0.6835378456115723, "val_acc": 56.0}
{"epoch": 16, "training_loss": 0.6789599370956421, "training_acc": 60.0, "val_loss": 0.6832886219024659, "val_acc": 56.0}
{"epoch": 17, "training_loss": 0.6764132618904114, "training_acc": 61.0, "val_loss": 0.6817351603507995, "val_acc": 60.0}
{"epoch": 18, "training_loss": 0.6808351850509644, "training_acc": 57.0, "val_loss": 0.681820297241211, "val_acc": 56.0}
{"epoch": 19, "training_loss": 0.6848655533790589, "training_acc": 58.0, "val_loss": 0.6849560880661011, "val_acc": 60.0}
{"epoch": 20, "training_loss": 0.6878878355026246, "training_acc": 56.0, "val_loss": 0.6846013355255127, "val_acc": 60.0}
{"epoch": 21, "training_loss": 0.6849248456954956, "training_acc": 59.0, "val_loss": 0.6831456732749939, "val_acc": 56.0}
{"epoch": 22, "training_loss": 0.688083245754242, "training_acc": 60.0, "val_loss": 0.6845361804962158, "val_acc": 64.0}
{"epoch": 23, "training_loss": 0.6856979870796204, "training_acc": 58.0, "val_loss": 0.6807946014404297, "val_acc": 60.0}
{"epoch": 24, "training_loss": 0.6802732348442078, "training_acc": 59.0, "val_loss": 0.6810725378990173, "val_acc": 60.0}
{"epoch": 25, "training_loss": 0.6769086074829102, "training_acc": 57.0, "val_loss": 0.6804809498786927, "val_acc": 60.0}
{"epoch": 26, "training_loss": 0.6718833065032959, "training_acc": 64.0, "val_loss": 0.6796409034729004, "val_acc": 60.0}
{"epoch": 27, "training_loss": 0.6719236159324646, "training_acc": 69.0, "val_loss": 0.680197982788086, "val_acc": 56.0}
{"epoch": 28, "training_loss": 0.6716073346138001, "training_acc": 62.0, "val_loss": 0.6802553510665894, "val_acc": 60.0}
{"epoch": 29, "training_loss": 0.6703875494003296, "training_acc": 68.0, "val_loss": 0.6767369151115418, "val_acc": 56.0}
{"epoch": 30, "training_loss": 0.6730467557907105, "training_acc": 63.0, "val_loss": 0.6792532110214233, "val_acc": 64.0}
{"epoch": 31, "training_loss": 0.6671813869476318, "training_acc": 66.0, "val_loss": 0.6792657089233398, "val_acc": 56.0}
{"epoch": 32, "training_loss": 0.6640711832046509, "training_acc": 68.0, "val_loss": 0.6774282765388489, "val_acc": 64.0}
{"epoch": 33, "training_loss": 0.664082522392273, "training_acc": 65.0, "val_loss": 0.6787097525596618, "val_acc": 64.0}
{"epoch": 34, "training_loss": 0.6612040901184082, "training_acc": 66.0, "val_loss": 0.6790775895118714, "val_acc": 56.0}
{"epoch": 35, "training_loss": 0.6592068672180176, "training_acc": 66.0, "val_loss": 0.6796790671348572, "val_acc": 56.0}
{"epoch": 36, "training_loss": 0.658129301071167, "training_acc": 68.0, "val_loss": 0.6791705060005188, "val_acc": 60.0}
{"epoch": 37, "training_loss": 0.6587024974822998, "training_acc": 66.0, "val_loss": 0.6809746170043945, "val_acc": 64.0}
{"epoch": 38, "training_loss": 0.6611132001876832, "training_acc": 69.0, "val_loss": 0.6779218316078186, "val_acc": 56.0}
{"epoch": 39, "training_loss": 0.6631456851959229, "training_acc": 62.0, "val_loss": 0.6788112211227417, "val_acc": 60.0}
{"epoch": 40, "training_loss": 0.6589130353927612, "training_acc": 66.0, "val_loss": 0.6797601819038391, "val_acc": 56.0}
{"epoch": 41, "training_loss": 0.655308587551117, "training_acc": 69.0, "val_loss": 0.6808878445625305, "val_acc": 64.0}
{"epoch": 42, "training_loss": 0.6546321535110473, "training_acc": 72.0, "val_loss": 0.6810489869117737, "val_acc": 56.0}
{"epoch": 43, "training_loss": 0.6495535945892335, "training_acc": 71.0, "val_loss": 0.6819121646881103, "val_acc": 56.0}
{"epoch": 44, "training_loss": 0.6511255502700806, "training_acc": 69.0, "val_loss": 0.6825788497924805, "val_acc": 60.0}
{"epoch": 45, "training_loss": 0.6479533863067627, "training_acc": 70.0, "val_loss": 0.6747280931472779, "val_acc": 72.0}
{"epoch": 46, "training_loss": 0.6643006587028504, "training_acc": 66.0, "val_loss": 0.6824487590789795, "val_acc": 56.0}
{"epoch": 47, "training_loss": 0.6471552133560181, "training_acc": 71.0, "val_loss": 0.680807716846466, "val_acc": 56.0}
{"epoch": 48, "training_loss": 0.646148419380188, "training_acc": 72.0, "val_loss": 0.680164499282837, "val_acc": 64.0}
{"epoch": 49, "training_loss": 0.6459519839286805, "training_acc": 75.0, "val_loss": 0.6813144516944886, "val_acc": 60.0}
{"epoch": 50, "training_loss": 0.6435856461524964, "training_acc": 74.0, "val_loss": 0.6797441983222962, "val_acc": 64.0}
{"epoch": 51, "training_loss": 0.6485819458961487, "training_acc": 72.0, "val_loss": 0.6799947309494019, "val_acc": 56.0}
{"epoch": 52, "training_loss": 0.6435695028305054, "training_acc": 71.0, "val_loss": 0.677139801979065, "val_acc": 60.0}
{"epoch": 53, "training_loss": 0.6501399040222168, "training_acc": 70.0, "val_loss": 0.678555908203125, "val_acc": 60.0}
{"epoch": 54, "training_loss": 0.6443571496009827, "training_acc": 71.0, "val_loss": 0.6786593294143677, "val_acc": 56.0}
{"epoch": 55, "training_loss": 0.6492488050460815, "training_acc": 67.0, "val_loss": 0.6787358546257019, "val_acc": 72.0}
{"epoch": 56, "training_loss": 0.639603180885315, "training_acc": 78.0, "val_loss": 0.6787258601188659, "val_acc": 72.0}
{"epoch": 57, "training_loss": 0.6447248792648316, "training_acc": 76.0, "val_loss": 0.6790953230857849, "val_acc": 56.0}
{"epoch": 58, "training_loss": 0.6485421895980835, "training_acc": 71.0, "val_loss": 0.6766005277633667, "val_acc": 60.0}
{"epoch": 59, "training_loss": 0.6505210947990417, "training_acc": 73.0, "val_loss": 0.6720509815216065, "val_acc": 76.0}
{"epoch": 60, "training_loss": 0.6466985487937927, "training_acc": 69.0, "val_loss": 0.6751391124725342, "val_acc": 76.0}
{"epoch": 61, "training_loss": 0.6556212711334228, "training_acc": 71.0, "val_loss": 0.6816722965240478, "val_acc": 56.0}
{"epoch": 62, "training_loss": 0.6501246762275695, "training_acc": 65.0, "val_loss": 0.6822029423713684, "val_acc": 56.0}
{"epoch": 63, "training_loss": 0.6438704538345337, "training_acc": 72.0, "val_loss": 0.6722649645805359, "val_acc": 76.0}
{"epoch": 64, "training_loss": 0.6418952083587647, "training_acc": 69.0, "val_loss": 0.6768664979934692, "val_acc": 56.0}
{"epoch": 65, "training_loss": 0.6478358793258667, "training_acc": 66.0, "val_loss": 0.6703245997428894, "val_acc": 76.0}
{"epoch": 66, "training_loss": 0.6460028767585755, "training_acc": 78.0, "val_loss": 0.6788938188552857, "val_acc": 48.0}
{"epoch": 67, "training_loss": 0.6432209062576294, "training_acc": 71.0, "val_loss": 0.682967119216919, "val_acc": 48.0}
{"epoch": 68, "training_loss": 0.6429852437973023, "training_acc": 69.0, "val_loss": 0.6791235470771789, "val_acc": 60.0}
{"epoch": 69, "training_loss": 0.630602445602417, "training_acc": 75.0, "val_loss": 0.6791463994979858, "val_acc": 68.0}
{"epoch": 70, "training_loss": 0.638037555217743, "training_acc": 72.0, "val_loss": 0.6813981366157532, "val_acc": 56.0}
{"epoch": 71, "training_loss": 0.6256946992874145, "training_acc": 74.0, "val_loss": 0.675809133052826, "val_acc": 60.0}
{"epoch": 72, "training_loss": 0.6258885765075684, "training_acc": 79.0, "val_loss": 0.6780620121955871, "val_acc": 60.0}
{"epoch": 73, "training_loss": 0.6202097558975219, "training_acc": 81.0, "val_loss": 0.6828869271278382, "val_acc": 60.0}
{"epoch": 74, "training_loss": 0.6250942063331604, "training_acc": 75.0, "val_loss": 0.679081003665924, "val_acc": 52.0}
{"epoch": 75, "training_loss": 0.6213870859146118, "training_acc": 77.0, "val_loss": 0.6834148716926575, "val_acc": 60.0}
{"epoch": 76, "training_loss": 0.62465482711792, "training_acc": 78.0, "val_loss": 0.6782554388046265, "val_acc": 52.0}
{"epoch": 77, "training_loss": 0.6286354541778565, "training_acc": 76.0, "val_loss": 0.6808151316642761, "val_acc": 56.0}
{"epoch": 78, "training_loss": 0.6181746983528137, "training_acc": 76.0, "val_loss": 0.6820500779151917, "val_acc": 64.0}
{"epoch": 79, "training_loss": 0.6147118782997132, "training_acc": 75.0, "val_loss": 0.681041042804718, "val_acc": 60.0}
{"epoch": 80, "training_loss": 0.6150557684898377, "training_acc": 80.0, "val_loss": 0.6765642189979553, "val_acc": 60.0}
{"epoch": 81, "training_loss": 0.6198664236068726, "training_acc": 75.0, "val_loss": 0.6784654641151429, "val_acc": 68.0}
{"epoch": 82, "training_loss": 0.6234181785583496, "training_acc": 75.0, "val_loss": 0.6779108119010925, "val_acc": 56.0}
{"epoch": 83, "training_loss": 0.6181295442581177, "training_acc": 75.0, "val_loss": 0.6786912512779236, "val_acc": 68.0}
{"epoch": 84, "training_loss": 0.6203196978569031, "training_acc": 74.0, "val_loss": 0.6776876950263977, "val_acc": 60.0}
