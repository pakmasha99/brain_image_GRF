"main_modify.py --pretrained_path /scratch/connectome/dyhan316/VAE_ADHD/barlowtwins/pretrain_results/ABCDbt128a102.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option BT_org --learning_rate 1e-5 --batch_size 16 --weight_decay 1e-3 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 0.6912847089767457, "training_acc": 53.0, "val_loss": 0.691196255683899, "val_acc": 52.0}
{"epoch": 1, "training_loss": 0.6915114068984985, "training_acc": 53.0, "val_loss": 0.6906108570098877, "val_acc": 52.0}
{"epoch": 2, "training_loss": 0.6909471869468689, "training_acc": 53.0, "val_loss": 0.6913700103759766, "val_acc": 52.0}
{"epoch": 3, "training_loss": 0.6925998044013977, "training_acc": 53.0, "val_loss": 0.6935308909416199, "val_acc": 52.0}
{"epoch": 4, "training_loss": 0.6920940089225769, "training_acc": 53.0, "val_loss": 0.6927957606315612, "val_acc": 52.0}
{"epoch": 5, "training_loss": 0.6921270704269409, "training_acc": 53.0, "val_loss": 0.6925346875190734, "val_acc": 52.0}
{"epoch": 6, "training_loss": 0.6912947225570679, "training_acc": 53.0, "val_loss": 0.6917891430854798, "val_acc": 52.0}
{"epoch": 7, "training_loss": 0.6921221780776977, "training_acc": 53.0, "val_loss": 0.6921990990638733, "val_acc": 52.0}
{"epoch": 8, "training_loss": 0.6911754655838013, "training_acc": 53.0, "val_loss": 0.6921913576126099, "val_acc": 52.0}
{"epoch": 9, "training_loss": 0.6905839586257935, "training_acc": 53.0, "val_loss": 0.6919372391700744, "val_acc": 52.0}
{"epoch": 10, "training_loss": 0.6907138919830322, "training_acc": 53.0, "val_loss": 0.6926052355766297, "val_acc": 52.0}
{"epoch": 11, "training_loss": 0.6904912900924682, "training_acc": 53.0, "val_loss": 0.6920396518707276, "val_acc": 52.0}
{"epoch": 12, "training_loss": 0.6900794839859009, "training_acc": 53.0, "val_loss": 0.6922770190238953, "val_acc": 52.0}
{"epoch": 13, "training_loss": 0.6897304677963256, "training_acc": 53.0, "val_loss": 0.6915496158599853, "val_acc": 52.0}
{"epoch": 14, "training_loss": 0.6894118475914002, "training_acc": 53.0, "val_loss": 0.6904388213157654, "val_acc": 52.0}
{"epoch": 15, "training_loss": 0.6894404506683349, "training_acc": 53.0, "val_loss": 0.6899414944648743, "val_acc": 52.0}
{"epoch": 16, "training_loss": 0.6886259746551514, "training_acc": 53.0, "val_loss": 0.6900178861618042, "val_acc": 52.0}
{"epoch": 17, "training_loss": 0.6887859988212586, "training_acc": 53.0, "val_loss": 0.689624330997467, "val_acc": 52.0}
{"epoch": 18, "training_loss": 0.6893967247009277, "training_acc": 53.0, "val_loss": 0.6885740756988525, "val_acc": 52.0}
{"epoch": 19, "training_loss": 0.6885199308395386, "training_acc": 53.0, "val_loss": 0.6906477832794189, "val_acc": 52.0}
{"epoch": 20, "training_loss": 0.6886213302612305, "training_acc": 53.0, "val_loss": 0.6921590924263, "val_acc": 52.0}
{"epoch": 21, "training_loss": 0.6878038549423218, "training_acc": 53.0, "val_loss": 0.690447804927826, "val_acc": 52.0}
{"epoch": 22, "training_loss": 0.6869731330871582, "training_acc": 53.0, "val_loss": 0.688669605255127, "val_acc": 52.0}
{"epoch": 23, "training_loss": 0.6876783275604248, "training_acc": 53.0, "val_loss": 0.6905870747566223, "val_acc": 52.0}
{"epoch": 24, "training_loss": 0.687138786315918, "training_acc": 53.0, "val_loss": 0.68975830078125, "val_acc": 52.0}
{"epoch": 25, "training_loss": 0.6902399587631226, "training_acc": 53.0, "val_loss": 0.6944171261787414, "val_acc": 52.0}
{"epoch": 26, "training_loss": 0.6876492691040039, "training_acc": 53.0, "val_loss": 0.6879014325141907, "val_acc": 52.0}
{"epoch": 27, "training_loss": 0.6878956890106201, "training_acc": 53.0, "val_loss": 0.6868674874305725, "val_acc": 52.0}
{"epoch": 28, "training_loss": 0.688636109828949, "training_acc": 53.0, "val_loss": 0.6920970582962036, "val_acc": 52.0}
{"epoch": 29, "training_loss": 0.6881054210662841, "training_acc": 53.0, "val_loss": 0.6887780117988587, "val_acc": 52.0}
{"epoch": 30, "training_loss": 0.6856907367706299, "training_acc": 53.0, "val_loss": 0.6868283772468566, "val_acc": 52.0}
{"epoch": 31, "training_loss": 0.6865101671218872, "training_acc": 53.0, "val_loss": 0.6877543950080871, "val_acc": 52.0}
{"epoch": 32, "training_loss": 0.685105230808258, "training_acc": 53.0, "val_loss": 0.687148540019989, "val_acc": 52.0}
{"epoch": 33, "training_loss": 0.6857835292816162, "training_acc": 53.0, "val_loss": 0.6891505932807922, "val_acc": 52.0}
{"epoch": 34, "training_loss": 0.6863367342948914, "training_acc": 53.0, "val_loss": 0.6863095188140869, "val_acc": 52.0}
{"epoch": 35, "training_loss": 0.6838286924362182, "training_acc": 53.0, "val_loss": 0.691191828250885, "val_acc": 52.0}
{"epoch": 36, "training_loss": 0.6824537372589111, "training_acc": 53.0, "val_loss": 0.6849859881401063, "val_acc": 52.0}
{"epoch": 37, "training_loss": 0.6873443841934204, "training_acc": 53.0, "val_loss": 0.6850826740264893, "val_acc": 52.0}
{"epoch": 38, "training_loss": 0.6840072011947632, "training_acc": 53.0, "val_loss": 0.6856905484199524, "val_acc": 52.0}
{"epoch": 39, "training_loss": 0.6845688247680664, "training_acc": 53.0, "val_loss": 0.6852586030960083, "val_acc": 52.0}
{"epoch": 40, "training_loss": 0.6823150110244751, "training_acc": 53.0, "val_loss": 0.6868234872817993, "val_acc": 52.0}
{"epoch": 41, "training_loss": 0.6872237253189087, "training_acc": 53.0, "val_loss": 0.6838131809234619, "val_acc": 52.0}
{"epoch": 42, "training_loss": 0.6820079565048218, "training_acc": 54.0, "val_loss": 0.6924051308631897, "val_acc": 52.0}
{"epoch": 43, "training_loss": 0.691969723701477, "training_acc": 53.0, "val_loss": 0.6944310355186463, "val_acc": 52.0}
{"epoch": 44, "training_loss": 0.6914241886138917, "training_acc": 53.0, "val_loss": 0.6923874235153198, "val_acc": 52.0}
{"epoch": 45, "training_loss": 0.6902064657211304, "training_acc": 53.0, "val_loss": 0.6905838823318482, "val_acc": 52.0}
{"epoch": 46, "training_loss": 0.688994734287262, "training_acc": 53.0, "val_loss": 0.6897310566902161, "val_acc": 52.0}
{"epoch": 47, "training_loss": 0.6896601009368897, "training_acc": 53.0, "val_loss": 0.6911464858055115, "val_acc": 52.0}
{"epoch": 48, "training_loss": 0.6882821893692017, "training_acc": 53.0, "val_loss": 0.6887348175048829, "val_acc": 52.0}
{"epoch": 49, "training_loss": 0.6875334239006042, "training_acc": 53.0, "val_loss": 0.6866538572311401, "val_acc": 52.0}
{"epoch": 50, "training_loss": 0.6873715472221374, "training_acc": 53.0, "val_loss": 0.6864388990402222, "val_acc": 52.0}
{"epoch": 51, "training_loss": 0.6861937713623046, "training_acc": 53.0, "val_loss": 0.6858163261413575, "val_acc": 52.0}
{"epoch": 52, "training_loss": 0.6887826132774353, "training_acc": 55.0, "val_loss": 0.684899983406067, "val_acc": 52.0}
{"epoch": 53, "training_loss": 0.6854300427436829, "training_acc": 59.0, "val_loss": 0.6879835510253907, "val_acc": 48.0}
{"epoch": 54, "training_loss": 0.685927848815918, "training_acc": 53.0, "val_loss": 0.6881430292129517, "val_acc": 52.0}
{"epoch": 55, "training_loss": 0.683177011013031, "training_acc": 53.0, "val_loss": 0.6833545327186584, "val_acc": 56.0}
{"epoch": 56, "training_loss": 0.6834984874725342, "training_acc": 63.0, "val_loss": 0.6833897471427918, "val_acc": 64.0}
{"epoch": 57, "training_loss": 0.6816897845268249, "training_acc": 61.0, "val_loss": 0.6847322797775268, "val_acc": 60.0}
{"epoch": 58, "training_loss": 0.6785111999511719, "training_acc": 58.0, "val_loss": 0.6818775177001953, "val_acc": 60.0}
{"epoch": 59, "training_loss": 0.6820961785316467, "training_acc": 62.0, "val_loss": 0.6822723889350891, "val_acc": 60.0}
{"epoch": 60, "training_loss": 0.680931453704834, "training_acc": 59.0, "val_loss": 0.6823882818222046, "val_acc": 60.0}
{"epoch": 61, "training_loss": 0.688915548324585, "training_acc": 56.0, "val_loss": 0.6803409767150879, "val_acc": 56.0}
{"epoch": 62, "training_loss": 0.6805857157707215, "training_acc": 55.0, "val_loss": 0.6885558819770813, "val_acc": 52.0}
{"epoch": 63, "training_loss": 0.6844541931152344, "training_acc": 55.0, "val_loss": 0.6833449172973632, "val_acc": 60.0}
{"epoch": 64, "training_loss": 0.6836504364013671, "training_acc": 58.0, "val_loss": 0.6801112103462219, "val_acc": 56.0}
{"epoch": 65, "training_loss": 0.6780960130691528, "training_acc": 63.0, "val_loss": 0.6869134998321533, "val_acc": 56.0}
{"epoch": 66, "training_loss": 0.6852876019477844, "training_acc": 54.0, "val_loss": 0.6795770192146301, "val_acc": 56.0}
{"epoch": 67, "training_loss": 0.6801308751106262, "training_acc": 61.0, "val_loss": 0.6834226250648499, "val_acc": 60.0}
{"epoch": 68, "training_loss": 0.6759397530555725, "training_acc": 60.0, "val_loss": 0.6825147008895874, "val_acc": 60.0}
{"epoch": 69, "training_loss": 0.6723692655563355, "training_acc": 64.0, "val_loss": 0.6825962853431702, "val_acc": 56.0}
{"epoch": 70, "training_loss": 0.6764367008209229, "training_acc": 60.0, "val_loss": 0.6814981770515441, "val_acc": 64.0}
{"epoch": 71, "training_loss": 0.6759859561920166, "training_acc": 58.0, "val_loss": 0.6802686262130737, "val_acc": 64.0}
{"epoch": 72, "training_loss": 0.6712099313735962, "training_acc": 61.0, "val_loss": 0.6813901805877686, "val_acc": 60.0}
{"epoch": 73, "training_loss": 0.673929500579834, "training_acc": 61.0, "val_loss": 0.6806025028228759, "val_acc": 64.0}
{"epoch": 74, "training_loss": 0.6758172678947448, "training_acc": 64.0, "val_loss": 0.6811637210845948, "val_acc": 64.0}
{"epoch": 75, "training_loss": 0.6698808908462525, "training_acc": 62.0, "val_loss": 0.6802700400352478, "val_acc": 64.0}
{"epoch": 76, "training_loss": 0.6680996417999268, "training_acc": 62.0, "val_loss": 0.6812476325035095, "val_acc": 60.0}
{"epoch": 77, "training_loss": 0.6649496579170227, "training_acc": 63.0, "val_loss": 0.682231719493866, "val_acc": 60.0}
{"epoch": 78, "training_loss": 0.6728655004501343, "training_acc": 62.0, "val_loss": 0.6814614486694336, "val_acc": 60.0}
{"epoch": 79, "training_loss": 0.6644806671142578, "training_acc": 64.0, "val_loss": 0.6783141303062439, "val_acc": 64.0}
{"epoch": 80, "training_loss": 0.6684182214736939, "training_acc": 62.0, "val_loss": 0.678676233291626, "val_acc": 52.0}
{"epoch": 81, "training_loss": 0.6725602865219116, "training_acc": 63.0, "val_loss": 0.6777170372009277, "val_acc": 64.0}
{"epoch": 82, "training_loss": 0.6678411459922791, "training_acc": 62.0, "val_loss": 0.678804337978363, "val_acc": 56.0}
{"epoch": 83, "training_loss": 0.672283616065979, "training_acc": 60.0, "val_loss": 0.6816441798210144, "val_acc": 56.0}
{"epoch": 84, "training_loss": 0.6682265138626099, "training_acc": 60.0, "val_loss": 0.6769027280807495, "val_acc": 64.0}
{"epoch": 85, "training_loss": 0.6814754629135131, "training_acc": 56.0, "val_loss": 0.6841370868682861, "val_acc": 56.0}
{"epoch": 86, "training_loss": 0.6667056083679199, "training_acc": 63.0, "val_loss": 0.6750298404693603, "val_acc": 52.0}
{"epoch": 87, "training_loss": 0.6586428880691528, "training_acc": 65.0, "val_loss": 0.6781271743774414, "val_acc": 60.0}
{"epoch": 88, "training_loss": 0.664248776435852, "training_acc": 62.0, "val_loss": 0.6800269913673401, "val_acc": 52.0}
{"epoch": 89, "training_loss": 0.6650211954116821, "training_acc": 65.0, "val_loss": 0.6765044355392456, "val_acc": 60.0}
{"epoch": 90, "training_loss": 0.6617246103286744, "training_acc": 62.0, "val_loss": 0.678932831287384, "val_acc": 64.0}
{"epoch": 91, "training_loss": 0.6597994637489318, "training_acc": 61.0, "val_loss": 0.6768228936195374, "val_acc": 64.0}
{"epoch": 92, "training_loss": 0.6629976534843445, "training_acc": 62.0, "val_loss": 0.6775071883201599, "val_acc": 52.0}
{"epoch": 93, "training_loss": 0.6607411003112793, "training_acc": 66.0, "val_loss": 0.6746344709396362, "val_acc": 64.0}
{"epoch": 94, "training_loss": 0.6573569631576538, "training_acc": 60.0, "val_loss": 0.6760304951667786, "val_acc": 60.0}
{"epoch": 95, "training_loss": 0.6507445240020752, "training_acc": 65.0, "val_loss": 0.678866651058197, "val_acc": 60.0}
{"epoch": 96, "training_loss": 0.6478546476364135, "training_acc": 66.0, "val_loss": 0.678394889831543, "val_acc": 52.0}
{"epoch": 97, "training_loss": 0.685934739112854, "training_acc": 53.0, "val_loss": 0.6742608523368836, "val_acc": 64.0}
{"epoch": 98, "training_loss": 0.6730341291427613, "training_acc": 58.0, "val_loss": 0.685082905292511, "val_acc": 56.0}
{"epoch": 99, "training_loss": 0.6583958005905152, "training_acc": 60.0, "val_loss": 0.6748639130592347, "val_acc": 52.0}
