"main_modify.py --pretrained_path /scratch/connectome/dyhan316/VAE_ADHD/barlowtwins/pretrain_results/ABCDbt128a102.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option BT_org --learning_rate 1e-2 --batch_size 16 --weight_decay 1e-2 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 1.1404769396781922, "training_acc": 55.0, "val_loss": 0.6974423456192017, "val_acc": 52.0}
{"epoch": 1, "training_loss": 0.7657089805603028, "training_acc": 49.0, "val_loss": 0.6946451497077942, "val_acc": 48.0}
{"epoch": 2, "training_loss": 0.7255442380905152, "training_acc": 43.0, "val_loss": 0.875610945224762, "val_acc": 52.0}
{"epoch": 3, "training_loss": 0.8370242071151733, "training_acc": 47.0, "val_loss": 0.7017686152458191, "val_acc": 52.0}
{"epoch": 4, "training_loss": 0.7054953098297119, "training_acc": 53.0, "val_loss": 0.7102337455749512, "val_acc": 48.0}
{"epoch": 5, "training_loss": 0.7141637086868287, "training_acc": 41.0, "val_loss": 0.7887848901748657, "val_acc": 52.0}
{"epoch": 6, "training_loss": 0.75868319272995, "training_acc": 53.0, "val_loss": 0.7513264894485474, "val_acc": 48.0}
{"epoch": 7, "training_loss": 0.921894657611847, "training_acc": 53.0, "val_loss": 1.2527664709091186, "val_acc": 48.0}
{"epoch": 8, "training_loss": 1.0710328578948975, "training_acc": 51.0, "val_loss": 0.9858268070220947, "val_acc": 52.0}
{"epoch": 9, "training_loss": 0.8224396133422851, "training_acc": 51.0, "val_loss": 0.6992710041999817, "val_acc": 52.0}
{"epoch": 10, "training_loss": 0.7160496187210083, "training_acc": 53.0, "val_loss": 0.7150033307075501, "val_acc": 48.0}
{"epoch": 11, "training_loss": 0.7215502452850342, "training_acc": 51.0, "val_loss": 0.783070216178894, "val_acc": 52.0}
{"epoch": 12, "training_loss": 0.7379583501815796, "training_acc": 45.0, "val_loss": 0.7299057722091675, "val_acc": 52.0}
{"epoch": 13, "training_loss": 0.7241178321838379, "training_acc": 47.0, "val_loss": 0.7152188348770142, "val_acc": 52.0}
{"epoch": 14, "training_loss": 0.7345458936691284, "training_acc": 51.0, "val_loss": 0.8263806343078614, "val_acc": 48.0}
{"epoch": 15, "training_loss": 0.8095791625976563, "training_acc": 39.0, "val_loss": 0.6927090120315552, "val_acc": 52.0}
{"epoch": 16, "training_loss": 0.7197004175186157, "training_acc": 55.0, "val_loss": 0.9089383244514465, "val_acc": 48.0}
{"epoch": 17, "training_loss": 0.8237333512306213, "training_acc": 55.0, "val_loss": 0.8012715125083923, "val_acc": 52.0}
{"epoch": 18, "training_loss": 0.7922682857513428, "training_acc": 39.0, "val_loss": 0.6947330117225647, "val_acc": 48.0}
{"epoch": 19, "training_loss": 0.7371337795257569, "training_acc": 49.0, "val_loss": 0.6927020287513733, "val_acc": 52.0}
{"epoch": 20, "training_loss": 0.8016926765441894, "training_acc": 51.0, "val_loss": 0.9609656810760498, "val_acc": 52.0}
{"epoch": 21, "training_loss": 0.817445273399353, "training_acc": 53.0, "val_loss": 0.7061364698410034, "val_acc": 48.0}
{"epoch": 22, "training_loss": 0.7675817251205445, "training_acc": 53.0, "val_loss": 0.7057763361930847, "val_acc": 52.0}
{"epoch": 23, "training_loss": 0.727022910118103, "training_acc": 49.0, "val_loss": 0.7154278182983398, "val_acc": 52.0}
{"epoch": 24, "training_loss": 0.7034378743171692, "training_acc": 55.0, "val_loss": 0.9460319614410401, "val_acc": 48.0}
{"epoch": 25, "training_loss": 0.7929961371421814, "training_acc": 51.0, "val_loss": 0.7024872255325317, "val_acc": 52.0}
{"epoch": 26, "training_loss": 0.7000231885910034, "training_acc": 53.0, "val_loss": 0.7744332242012024, "val_acc": 52.0}
{"epoch": 27, "training_loss": 0.7084618592262268, "training_acc": 61.0, "val_loss": 1.1611537218093873, "val_acc": 48.0}
{"epoch": 28, "training_loss": 0.9463511085510254, "training_acc": 45.0, "val_loss": 0.7210263872146606, "val_acc": 52.0}
{"epoch": 29, "training_loss": 0.7557956886291504, "training_acc": 37.0, "val_loss": 0.7651101803779602, "val_acc": 52.0}
{"epoch": 30, "training_loss": 0.7887518119812011, "training_acc": 51.0, "val_loss": 0.7732666611671448, "val_acc": 48.0}
{"epoch": 31, "training_loss": 0.6955566692352295, "training_acc": 55.0, "val_loss": 0.7258309292793274, "val_acc": 52.0}
{"epoch": 32, "training_loss": 0.6913649892807007, "training_acc": 57.0, "val_loss": 0.8654679179191589, "val_acc": 48.0}
{"epoch": 33, "training_loss": 0.7943618297576904, "training_acc": 47.0, "val_loss": 0.7458681416511536, "val_acc": 52.0}
{"epoch": 34, "training_loss": 0.6934244656562805, "training_acc": 55.0, "val_loss": 0.8091894268989563, "val_acc": 48.0}
{"epoch": 35, "training_loss": 0.7414289331436157, "training_acc": 49.0, "val_loss": 0.7206631541252136, "val_acc": 52.0}
{"epoch": 36, "training_loss": 0.7052209043502807, "training_acc": 55.0, "val_loss": 0.7306276679039001, "val_acc": 48.0}
{"epoch": 37, "training_loss": 0.7332138419151306, "training_acc": 47.0, "val_loss": 0.7303579831123352, "val_acc": 52.0}
{"epoch": 38, "training_loss": 0.7140445566177368, "training_acc": 53.0, "val_loss": 0.6923509192466736, "val_acc": 52.0}
{"epoch": 39, "training_loss": 0.7011654138565063, "training_acc": 45.0, "val_loss": 0.7114789605140686, "val_acc": 48.0}
{"epoch": 40, "training_loss": 0.7279917454719543, "training_acc": 51.0, "val_loss": 0.744540319442749, "val_acc": 52.0}
{"epoch": 41, "training_loss": 0.7271642827987671, "training_acc": 53.0, "val_loss": 0.6932821607589722, "val_acc": 48.0}
{"epoch": 42, "training_loss": 0.7284577584266663, "training_acc": 45.0, "val_loss": 0.6963720703125, "val_acc": 52.0}
{"epoch": 43, "training_loss": 0.7136815714836121, "training_acc": 55.0, "val_loss": 0.7549712967872619, "val_acc": 48.0}
{"epoch": 44, "training_loss": 0.8418504619598388, "training_acc": 45.0, "val_loss": 0.7099898838996888, "val_acc": 52.0}
{"epoch": 45, "training_loss": 0.7164558887481689, "training_acc": 53.0, "val_loss": 0.6935354280471802, "val_acc": 48.0}
{"epoch": 46, "training_loss": 0.7397102952003479, "training_acc": 39.0, "val_loss": 0.6978526043891907, "val_acc": 52.0}
{"epoch": 47, "training_loss": 0.6982230758666992, "training_acc": 53.0, "val_loss": 0.6942688393592834, "val_acc": 48.0}
{"epoch": 48, "training_loss": 0.7007760405540466, "training_acc": 45.0, "val_loss": 0.7036883664131165, "val_acc": 48.0}
{"epoch": 49, "training_loss": 0.7272006464004517, "training_acc": 47.0, "val_loss": 0.7100711369514465, "val_acc": 52.0}
{"epoch": 50, "training_loss": 0.7219535398483277, "training_acc": 51.0, "val_loss": 0.697914810180664, "val_acc": 48.0}
{"epoch": 51, "training_loss": 0.7092767405509949, "training_acc": 45.0, "val_loss": 0.7107486033439636, "val_acc": 52.0}
{"epoch": 52, "training_loss": 0.7208470964431762, "training_acc": 55.0, "val_loss": 0.7464148354530334, "val_acc": 48.0}
{"epoch": 53, "training_loss": 0.7297484254837037, "training_acc": 47.0, "val_loss": 0.7237179183959961, "val_acc": 52.0}
{"epoch": 54, "training_loss": 0.7401706027984619, "training_acc": 53.0, "val_loss": 0.7318157196044922, "val_acc": 48.0}
{"epoch": 55, "training_loss": 0.7205942344665527, "training_acc": 47.0, "val_loss": 0.7082438445091248, "val_acc": 52.0}
{"epoch": 56, "training_loss": 0.7139663553237915, "training_acc": 53.0, "val_loss": 0.6964965867996216, "val_acc": 52.0}
{"epoch": 57, "training_loss": 0.6955645370483399, "training_acc": 53.0, "val_loss": 0.7121388101577759, "val_acc": 48.0}
