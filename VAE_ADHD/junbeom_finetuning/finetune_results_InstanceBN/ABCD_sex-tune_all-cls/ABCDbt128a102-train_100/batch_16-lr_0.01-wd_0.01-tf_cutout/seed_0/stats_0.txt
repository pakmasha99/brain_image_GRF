"main_modify.py --pretrained_path /scratch/connectome/dyhan316/VAE_ADHD/barlowtwins/pretrain_results/ABCDbt128a102.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option BT_org --learning_rate 1e-2 --batch_size 16 --weight_decay 1e-2 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 1.2541881251335143, "training_acc": 46.0, "val_loss": 0.6928047633171082, "val_acc": 56.0}
{"epoch": 1, "training_loss": 0.7974958777427673, "training_acc": 50.0, "val_loss": 0.8636043787002563, "val_acc": 44.0}
{"epoch": 2, "training_loss": 0.7714920568466187, "training_acc": 50.0, "val_loss": 0.6917716145515442, "val_acc": 56.0}
{"epoch": 3, "training_loss": 0.7451267600059509, "training_acc": 42.0, "val_loss": 0.796558051109314, "val_acc": 44.0}
{"epoch": 4, "training_loss": 0.83380291223526, "training_acc": 50.0, "val_loss": 0.7424484920501709, "val_acc": 56.0}
{"epoch": 5, "training_loss": 0.7247385168075562, "training_acc": 46.0, "val_loss": 0.7097207736968995, "val_acc": 44.0}
{"epoch": 6, "training_loss": 0.7278078556060791, "training_acc": 50.0, "val_loss": 0.7018087434768677, "val_acc": 44.0}
{"epoch": 7, "training_loss": 0.7471643018722535, "training_acc": 52.0, "val_loss": 0.7150210237503052, "val_acc": 56.0}
{"epoch": 8, "training_loss": 0.6939733052253723, "training_acc": 54.0, "val_loss": 0.7593096661567688, "val_acc": 44.0}
{"epoch": 9, "training_loss": 0.7274165916442871, "training_acc": 52.0, "val_loss": 0.7938759231567383, "val_acc": 44.0}
{"epoch": 10, "training_loss": 0.8929510164260864, "training_acc": 44.0, "val_loss": 0.8010915112495423, "val_acc": 56.0}
{"epoch": 11, "training_loss": 0.7643647241592407, "training_acc": 46.0, "val_loss": 0.7313345408439637, "val_acc": 56.0}
{"epoch": 12, "training_loss": 0.9084280776977539, "training_acc": 54.0, "val_loss": 1.0434829235076903, "val_acc": 44.0}
{"epoch": 13, "training_loss": 0.7743299865722656, "training_acc": 54.0, "val_loss": 0.7846166920661927, "val_acc": 56.0}
{"epoch": 14, "training_loss": 0.7844546461105346, "training_acc": 48.0, "val_loss": 0.6884869742393493, "val_acc": 56.0}
{"epoch": 15, "training_loss": 0.7233909368515015, "training_acc": 46.0, "val_loss": 0.7633222556114196, "val_acc": 56.0}
{"epoch": 16, "training_loss": 0.7547593784332275, "training_acc": 58.0, "val_loss": 0.985043179988861, "val_acc": 44.0}
{"epoch": 17, "training_loss": 0.7891235780715943, "training_acc": 52.0, "val_loss": 0.6948118925094604, "val_acc": 44.0}
{"epoch": 18, "training_loss": 0.7281655740737915, "training_acc": 46.0, "val_loss": 0.6923104524612427, "val_acc": 56.0}
{"epoch": 19, "training_loss": 0.755778923034668, "training_acc": 42.0, "val_loss": 0.7064406132698059, "val_acc": 56.0}
{"epoch": 20, "training_loss": 0.7389671993255615, "training_acc": 46.0, "val_loss": 0.6880086970329284, "val_acc": 56.0}
{"epoch": 21, "training_loss": 0.7128988456726074, "training_acc": 44.0, "val_loss": 0.695208797454834, "val_acc": 56.0}
{"epoch": 22, "training_loss": 0.7154588675498963, "training_acc": 50.0, "val_loss": 0.8215715861320496, "val_acc": 44.0}
{"epoch": 23, "training_loss": 0.7556313323974609, "training_acc": 44.0, "val_loss": 0.6887650632858277, "val_acc": 56.0}
{"epoch": 24, "training_loss": 0.7409164667129516, "training_acc": 52.0, "val_loss": 0.8598265552520752, "val_acc": 44.0}
{"epoch": 25, "training_loss": 0.7478884863853454, "training_acc": 48.0, "val_loss": 0.6859532403945923, "val_acc": 56.0}
{"epoch": 26, "training_loss": 0.7245784378051758, "training_acc": 48.0, "val_loss": 0.7642260456085205, "val_acc": 44.0}
{"epoch": 27, "training_loss": 0.7178154611587524, "training_acc": 48.0, "val_loss": 0.6868993091583252, "val_acc": 56.0}
{"epoch": 28, "training_loss": 0.7255563259124755, "training_acc": 40.0, "val_loss": 0.6871485590934754, "val_acc": 56.0}
{"epoch": 29, "training_loss": 0.7104551410675048, "training_acc": 48.0, "val_loss": 0.6861683177947998, "val_acc": 56.0}
{"epoch": 30, "training_loss": 0.7537905883789062, "training_acc": 50.0, "val_loss": 0.7008145093917847, "val_acc": 44.0}
{"epoch": 31, "training_loss": 0.7021457409858703, "training_acc": 52.0, "val_loss": 0.7532714462280273, "val_acc": 56.0}
{"epoch": 32, "training_loss": 0.7699556088447571, "training_acc": 52.0, "val_loss": 0.7164573979377746, "val_acc": 44.0}
{"epoch": 33, "training_loss": 0.7052948760986328, "training_acc": 44.0, "val_loss": 0.689586398601532, "val_acc": 56.0}
{"epoch": 34, "training_loss": 0.7159361457824707, "training_acc": 44.0, "val_loss": 0.7037130212783813, "val_acc": 44.0}
{"epoch": 35, "training_loss": 0.6983040380477905, "training_acc": 50.0, "val_loss": 0.6945605206489563, "val_acc": 56.0}
{"epoch": 36, "training_loss": 0.726011929512024, "training_acc": 46.0, "val_loss": 0.6940244174003601, "val_acc": 44.0}
{"epoch": 37, "training_loss": 0.7052553176879883, "training_acc": 52.0, "val_loss": 0.6863156914710998, "val_acc": 56.0}
{"epoch": 38, "training_loss": 0.7162142014503479, "training_acc": 42.0, "val_loss": 0.6864506864547729, "val_acc": 56.0}
{"epoch": 39, "training_loss": 0.7000810623168945, "training_acc": 52.0, "val_loss": 0.72667813539505, "val_acc": 44.0}
{"epoch": 40, "training_loss": 0.7428344202041626, "training_acc": 46.0, "val_loss": 0.7191064047813416, "val_acc": 56.0}
{"epoch": 41, "training_loss": 0.7314671468734741, "training_acc": 52.0, "val_loss": 0.7206425094604492, "val_acc": 44.0}
{"epoch": 42, "training_loss": 0.7118520259857177, "training_acc": 42.0, "val_loss": 0.6979556918144226, "val_acc": 44.0}
{"epoch": 43, "training_loss": 0.7184776067733765, "training_acc": 48.0, "val_loss": 0.7150798583030701, "val_acc": 44.0}
{"epoch": 44, "training_loss": 0.7520879888534546, "training_acc": 48.0, "val_loss": 0.6919574284553528, "val_acc": 56.0}
