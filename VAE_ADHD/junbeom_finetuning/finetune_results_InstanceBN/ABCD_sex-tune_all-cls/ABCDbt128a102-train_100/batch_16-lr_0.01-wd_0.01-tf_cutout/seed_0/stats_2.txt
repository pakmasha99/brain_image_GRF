"main_modify.py --pretrained_path /scratch/connectome/dyhan316/VAE_ADHD/barlowtwins/pretrain_results/ABCDbt128a102.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option BT_org --learning_rate 1e-2 --batch_size 16 --weight_decay 1e-2 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 1.1734834814071655, "training_acc": 53.0, "val_loss": 0.7193921256065369, "val_acc": 52.0}
{"epoch": 1, "training_loss": 0.9526635098457337, "training_acc": 51.0, "val_loss": 0.9910351610183716, "val_acc": 48.0}
{"epoch": 2, "training_loss": 0.8229201889038086, "training_acc": 51.0, "val_loss": 0.7076945114135742, "val_acc": 52.0}
{"epoch": 3, "training_loss": 0.7198346829414368, "training_acc": 51.0, "val_loss": 0.8684832882881165, "val_acc": 52.0}
{"epoch": 4, "training_loss": 0.806327087879181, "training_acc": 51.0, "val_loss": 0.734993622303009, "val_acc": 48.0}
{"epoch": 5, "training_loss": 0.6883292472362519, "training_acc": 59.0, "val_loss": 0.9494135427474976, "val_acc": 52.0}
{"epoch": 6, "training_loss": 0.9588781023025512, "training_acc": 39.0, "val_loss": 0.7881583738327026, "val_acc": 52.0}
{"epoch": 7, "training_loss": 0.7751781892776489, "training_acc": 51.0, "val_loss": 0.7182700109481811, "val_acc": 48.0}
{"epoch": 8, "training_loss": 0.7122284889221191, "training_acc": 51.0, "val_loss": 0.7585066246986389, "val_acc": 48.0}
{"epoch": 9, "training_loss": 0.7227936506271362, "training_acc": 51.0, "val_loss": 0.7627853345870972, "val_acc": 52.0}
{"epoch": 10, "training_loss": 0.716103286743164, "training_acc": 51.0, "val_loss": 0.7136320233345032, "val_acc": 52.0}
{"epoch": 11, "training_loss": 0.7227964115142822, "training_acc": 45.0, "val_loss": 0.7048689961433411, "val_acc": 52.0}
{"epoch": 12, "training_loss": 0.704112617969513, "training_acc": 49.0, "val_loss": 0.6989677429199219, "val_acc": 52.0}
{"epoch": 13, "training_loss": 0.7055292415618897, "training_acc": 53.0, "val_loss": 0.7824186372756958, "val_acc": 48.0}
{"epoch": 14, "training_loss": 0.7495259928703308, "training_acc": 53.0, "val_loss": 1.0408143615722656, "val_acc": 52.0}
{"epoch": 15, "training_loss": 0.7810948801040649, "training_acc": 55.0, "val_loss": 0.822402126789093, "val_acc": 48.0}
{"epoch": 16, "training_loss": 0.7528888797760009, "training_acc": 53.0, "val_loss": 0.6952069854736328, "val_acc": 52.0}
{"epoch": 17, "training_loss": 0.7180090951919555, "training_acc": 47.0, "val_loss": 0.6938459014892578, "val_acc": 52.0}
{"epoch": 18, "training_loss": 0.7067348623275757, "training_acc": 45.0, "val_loss": 0.7069612050056457, "val_acc": 52.0}
{"epoch": 19, "training_loss": 0.708856246471405, "training_acc": 47.0, "val_loss": 0.7103778624534607, "val_acc": 52.0}
{"epoch": 20, "training_loss": 0.6969310235977173, "training_acc": 53.0, "val_loss": 0.7422092270851135, "val_acc": 48.0}
{"epoch": 21, "training_loss": 0.7285363984107971, "training_acc": 49.0, "val_loss": 0.7116000366210937, "val_acc": 48.0}
{"epoch": 22, "training_loss": 0.7084697651863098, "training_acc": 51.0, "val_loss": 0.8254383969306945, "val_acc": 52.0}
{"epoch": 23, "training_loss": 0.7567775249481201, "training_acc": 53.0, "val_loss": 0.7231588387489318, "val_acc": 48.0}
{"epoch": 24, "training_loss": 0.7584358024597168, "training_acc": 45.0, "val_loss": 0.7841047406196594, "val_acc": 48.0}
{"epoch": 25, "training_loss": 0.7613178658485412, "training_acc": 49.0, "val_loss": 0.735962631702423, "val_acc": 48.0}
{"epoch": 26, "training_loss": 0.7249746394157409, "training_acc": 53.0, "val_loss": 0.7602812266349792, "val_acc": 52.0}
{"epoch": 27, "training_loss": 0.7151747393608093, "training_acc": 47.0, "val_loss": 0.7285243248939515, "val_acc": 52.0}
{"epoch": 28, "training_loss": 0.7370228505134583, "training_acc": 51.0, "val_loss": 0.7338021278381348, "val_acc": 48.0}
{"epoch": 29, "training_loss": 0.7739072895050049, "training_acc": 37.0, "val_loss": 0.693398187160492, "val_acc": 48.0}
{"epoch": 30, "training_loss": 0.7170584583282471, "training_acc": 55.0, "val_loss": 0.6924818015098572, "val_acc": 52.0}
{"epoch": 31, "training_loss": 0.7119128751754761, "training_acc": 43.0, "val_loss": 0.697914252281189, "val_acc": 52.0}
{"epoch": 32, "training_loss": 0.6936437559127807, "training_acc": 51.0, "val_loss": 0.6927770018577576, "val_acc": 52.0}
{"epoch": 33, "training_loss": 0.708321852684021, "training_acc": 49.0, "val_loss": 0.7001210498809814, "val_acc": 52.0}
{"epoch": 34, "training_loss": 0.7126651525497436, "training_acc": 53.0, "val_loss": 0.7134733891487122, "val_acc": 48.0}
{"epoch": 35, "training_loss": 0.7560673308372498, "training_acc": 47.0, "val_loss": 0.7908417272567749, "val_acc": 52.0}
{"epoch": 36, "training_loss": 0.7596578025817871, "training_acc": 49.0, "val_loss": 0.7097153782844543, "val_acc": 48.0}
{"epoch": 37, "training_loss": 0.7014755392074585, "training_acc": 51.0, "val_loss": 0.7010825300216674, "val_acc": 52.0}
{"epoch": 38, "training_loss": 0.7008926939964294, "training_acc": 51.0, "val_loss": 0.6989474868774415, "val_acc": 48.0}
{"epoch": 39, "training_loss": 0.7068835949897766, "training_acc": 51.0, "val_loss": 0.7061291766166687, "val_acc": 52.0}
{"epoch": 40, "training_loss": 0.7040847826004029, "training_acc": 53.0, "val_loss": 0.6929633522033691, "val_acc": 52.0}
{"epoch": 41, "training_loss": 0.6954417085647583, "training_acc": 51.0, "val_loss": 0.7103118634223938, "val_acc": 52.0}
{"epoch": 42, "training_loss": 0.7226698732376099, "training_acc": 51.0, "val_loss": 0.692738573551178, "val_acc": 52.0}
{"epoch": 43, "training_loss": 0.7039064931869506, "training_acc": 53.0, "val_loss": 0.7076388478279114, "val_acc": 48.0}
{"epoch": 44, "training_loss": 0.71049968957901, "training_acc": 47.0, "val_loss": 0.7184724831581115, "val_acc": 52.0}
{"epoch": 45, "training_loss": 0.7183720016479492, "training_acc": 49.0, "val_loss": 0.6945816159248352, "val_acc": 52.0}
{"epoch": 46, "training_loss": 0.7180522060394288, "training_acc": 53.0, "val_loss": 0.7064381408691406, "val_acc": 48.0}
{"epoch": 47, "training_loss": 0.7113910245895386, "training_acc": 43.0, "val_loss": 0.7016117596626281, "val_acc": 48.0}
{"epoch": 48, "training_loss": 0.7047129511833191, "training_acc": 45.0, "val_loss": 0.6935533475875855, "val_acc": 48.0}
{"epoch": 49, "training_loss": 0.71812344789505, "training_acc": 49.0, "val_loss": 0.7829214978218079, "val_acc": 52.0}
