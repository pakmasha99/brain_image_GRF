"main_modify.py --pretrained_path /scratch/connectome/dyhan316/VAE_ADHD/barlowtwins/pretrain_results/ABCDbt128a102.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 1 --task ABCD_sex --input_option BT_org --learning_rate 1e-2 --batch_size 16 --weight_decay 1e-2 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 1.237783051431179, "training_acc": 47.0, "val_loss": 1.0760954332351684, "val_acc": 52.0}
{"epoch": 1, "training_loss": 0.8986242938041688, "training_acc": 53.0, "val_loss": 0.8528340530395507, "val_acc": 52.0}
{"epoch": 2, "training_loss": 0.8977164554595948, "training_acc": 53.0, "val_loss": 0.7393778538703919, "val_acc": 48.0}
{"epoch": 3, "training_loss": 0.7665453863143921, "training_acc": 51.0, "val_loss": 0.7386111235618591, "val_acc": 52.0}
{"epoch": 4, "training_loss": 0.7675988006591797, "training_acc": 49.0, "val_loss": 0.8764677143096924, "val_acc": 52.0}
{"epoch": 5, "training_loss": 0.7475857734680176, "training_acc": 55.0, "val_loss": 0.7450421261787414, "val_acc": 48.0}
{"epoch": 6, "training_loss": 0.8157819271087646, "training_acc": 43.0, "val_loss": 0.7513040995597839, "val_acc": 48.0}
{"epoch": 7, "training_loss": 0.7089912271499634, "training_acc": 55.0, "val_loss": 0.7359573984146118, "val_acc": 52.0}
{"epoch": 8, "training_loss": 0.7292417812347413, "training_acc": 45.0, "val_loss": 0.6983765864372253, "val_acc": 52.0}
{"epoch": 9, "training_loss": 0.7100000762939453, "training_acc": 55.0, "val_loss": 0.7526738309860229, "val_acc": 48.0}
{"epoch": 10, "training_loss": 0.7109856867790222, "training_acc": 55.0, "val_loss": 0.7053623223304748, "val_acc": 52.0}
{"epoch": 11, "training_loss": 0.7189585494995118, "training_acc": 47.0, "val_loss": 0.7840160036087036, "val_acc": 52.0}
{"epoch": 12, "training_loss": 0.7413672780990601, "training_acc": 53.0, "val_loss": 0.7133782315254211, "val_acc": 48.0}
{"epoch": 13, "training_loss": 0.7432638573646545, "training_acc": 51.0, "val_loss": 0.9050793814659118, "val_acc": 48.0}
{"epoch": 14, "training_loss": 0.8374752879142762, "training_acc": 51.0, "val_loss": 0.7371471333503723, "val_acc": 52.0}
{"epoch": 15, "training_loss": 0.6726112604141236, "training_acc": 59.0, "val_loss": 0.7234957242012023, "val_acc": 48.0}
{"epoch": 16, "training_loss": 0.733876690864563, "training_acc": 51.0, "val_loss": 0.692825219631195, "val_acc": 52.0}
{"epoch": 17, "training_loss": 0.6995912599563598, "training_acc": 47.0, "val_loss": 0.7324923348426818, "val_acc": 48.0}
{"epoch": 18, "training_loss": 0.708848729133606, "training_acc": 51.0, "val_loss": 0.7928050088882447, "val_acc": 52.0}
{"epoch": 19, "training_loss": 0.7374576759338379, "training_acc": 49.0, "val_loss": 0.6998810458183289, "val_acc": 52.0}
{"epoch": 20, "training_loss": 0.7575800657272339, "training_acc": 45.0, "val_loss": 0.710598599910736, "val_acc": 52.0}
{"epoch": 21, "training_loss": 0.7907959938049316, "training_acc": 43.0, "val_loss": 0.7078896450996399, "val_acc": 52.0}
{"epoch": 22, "training_loss": 0.7240823388099671, "training_acc": 55.0, "val_loss": 0.8041733908653259, "val_acc": 48.0}
{"epoch": 23, "training_loss": 0.7583401298522949, "training_acc": 49.0, "val_loss": 0.6926446032524108, "val_acc": 52.0}
{"epoch": 24, "training_loss": 0.7446868276596069, "training_acc": 45.0, "val_loss": 0.9663303995132446, "val_acc": 52.0}
{"epoch": 25, "training_loss": 0.8151748847961425, "training_acc": 53.0, "val_loss": 0.7014497470855713, "val_acc": 48.0}
{"epoch": 26, "training_loss": 0.7237175130844116, "training_acc": 49.0, "val_loss": 0.755247392654419, "val_acc": 52.0}
{"epoch": 27, "training_loss": 0.7096774578094482, "training_acc": 57.0, "val_loss": 0.7989290642738343, "val_acc": 48.0}
{"epoch": 28, "training_loss": 0.871794981956482, "training_acc": 45.0, "val_loss": 0.8303072714805603, "val_acc": 52.0}
{"epoch": 29, "training_loss": 0.7526534366607666, "training_acc": 53.0, "val_loss": 0.7260443258285523, "val_acc": 48.0}
{"epoch": 30, "training_loss": 0.7349779438972474, "training_acc": 43.0, "val_loss": 0.6932055687904358, "val_acc": 48.0}
{"epoch": 31, "training_loss": 0.7230647826194763, "training_acc": 45.0, "val_loss": 0.7054321265220642, "val_acc": 48.0}
{"epoch": 32, "training_loss": 0.722510838508606, "training_acc": 49.0, "val_loss": 0.7197458219528198, "val_acc": 52.0}
{"epoch": 33, "training_loss": 0.7267739868164063, "training_acc": 49.0, "val_loss": 0.6931252741813659, "val_acc": 52.0}
{"epoch": 34, "training_loss": 0.7287758302688598, "training_acc": 53.0, "val_loss": 0.6949787092208862, "val_acc": 48.0}
{"epoch": 35, "training_loss": 0.7322691822052002, "training_acc": 45.0, "val_loss": 0.6923572993278504, "val_acc": 52.0}
{"epoch": 36, "training_loss": 0.6966899061203002, "training_acc": 53.0, "val_loss": 0.7027800679206848, "val_acc": 48.0}
{"epoch": 37, "training_loss": 0.7385758256912232, "training_acc": 47.0, "val_loss": 0.7052362465858459, "val_acc": 52.0}
{"epoch": 38, "training_loss": 0.70627863407135, "training_acc": 53.0, "val_loss": 0.6941318202018738, "val_acc": 48.0}
{"epoch": 39, "training_loss": 0.6967892026901246, "training_acc": 47.0, "val_loss": 0.6925209999084473, "val_acc": 52.0}
{"epoch": 40, "training_loss": 0.7059355449676513, "training_acc": 49.0, "val_loss": 0.6992084884643555, "val_acc": 48.0}
{"epoch": 41, "training_loss": 0.7104657459259033, "training_acc": 45.0, "val_loss": 0.7019583058357238, "val_acc": 52.0}
{"epoch": 42, "training_loss": 0.7097613573074341, "training_acc": 47.0, "val_loss": 0.6929518127441406, "val_acc": 52.0}
{"epoch": 43, "training_loss": 0.7064903450012207, "training_acc": 49.0, "val_loss": 0.7190597581863404, "val_acc": 52.0}
{"epoch": 44, "training_loss": 0.7087941241264343, "training_acc": 53.0, "val_loss": 0.6978436994552613, "val_acc": 52.0}
{"epoch": 45, "training_loss": 0.7081168603897094, "training_acc": 53.0, "val_loss": 0.7029199719429016, "val_acc": 48.0}
{"epoch": 46, "training_loss": 0.7672109746932984, "training_acc": 47.0, "val_loss": 0.708752510547638, "val_acc": 52.0}
{"epoch": 47, "training_loss": 0.7252095627784729, "training_acc": 53.0, "val_loss": 0.6964926624298096, "val_acc": 52.0}
{"epoch": 48, "training_loss": 0.6955633878707885, "training_acc": 51.0, "val_loss": 0.6944962644577026, "val_acc": 48.0}
{"epoch": 49, "training_loss": 0.7124458694458008, "training_acc": 41.0, "val_loss": 0.6929339838027954, "val_acc": 52.0}
{"epoch": 50, "training_loss": 0.6975024461746215, "training_acc": 51.0, "val_loss": 0.6967014002799988, "val_acc": 52.0}
{"epoch": 51, "training_loss": 0.7001745939254761, "training_acc": 43.0, "val_loss": 0.6981734514236451, "val_acc": 52.0}
{"epoch": 52, "training_loss": 0.7146051263809204, "training_acc": 51.0, "val_loss": 0.6926403880119324, "val_acc": 52.0}
{"epoch": 53, "training_loss": 0.7011556911468506, "training_acc": 53.0, "val_loss": 0.697952241897583, "val_acc": 48.0}
{"epoch": 54, "training_loss": 0.716011848449707, "training_acc": 47.0, "val_loss": 0.7261992335319519, "val_acc": 52.0}
