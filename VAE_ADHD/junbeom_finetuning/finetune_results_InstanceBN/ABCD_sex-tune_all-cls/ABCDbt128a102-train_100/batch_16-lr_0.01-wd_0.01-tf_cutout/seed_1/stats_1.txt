"main_modify.py --pretrained_path /scratch/connectome/dyhan316/VAE_ADHD/barlowtwins/pretrain_results/ABCDbt128a102.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 1 --task ABCD_sex --input_option BT_org --learning_rate 1e-2 --batch_size 16 --weight_decay 1e-2 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 0.9896018743515015, "training_acc": 53.0, "val_loss": 0.7934780979156494, "val_acc": 52.0}
{"epoch": 1, "training_loss": 0.7516996240615845, "training_acc": 55.0, "val_loss": 0.7112730097770691, "val_acc": 52.0}
{"epoch": 2, "training_loss": 0.7535226678848267, "training_acc": 53.0, "val_loss": 0.7003931474685668, "val_acc": 48.0}
{"epoch": 3, "training_loss": 0.7244576358795166, "training_acc": 53.0, "val_loss": 0.6943108820915223, "val_acc": 48.0}
{"epoch": 4, "training_loss": 0.7545202255249024, "training_acc": 55.0, "val_loss": 0.9726781272888183, "val_acc": 52.0}
{"epoch": 5, "training_loss": 0.811477336883545, "training_acc": 53.0, "val_loss": 0.7438430690765381, "val_acc": 48.0}
{"epoch": 6, "training_loss": 0.7303546476364136, "training_acc": 55.0, "val_loss": 0.8343613052368164, "val_acc": 48.0}
{"epoch": 7, "training_loss": 0.9018139147758484, "training_acc": 49.0, "val_loss": 0.9375501942634582, "val_acc": 52.0}
{"epoch": 8, "training_loss": 0.8165371751785279, "training_acc": 47.0, "val_loss": 0.7031336569786072, "val_acc": 52.0}
{"epoch": 9, "training_loss": 0.747154541015625, "training_acc": 45.0, "val_loss": 0.7210542726516723, "val_acc": 52.0}
{"epoch": 10, "training_loss": 0.7519544458389282, "training_acc": 55.0, "val_loss": 0.9520313262939453, "val_acc": 48.0}
{"epoch": 11, "training_loss": 0.8054458093643189, "training_acc": 53.0, "val_loss": 0.7523363947868347, "val_acc": 52.0}
{"epoch": 12, "training_loss": 0.8318450164794922, "training_acc": 45.0, "val_loss": 0.8769665503501892, "val_acc": 52.0}
{"epoch": 13, "training_loss": 0.7772316598892212, "training_acc": 45.0, "val_loss": 0.6925473093986512, "val_acc": 52.0}
{"epoch": 14, "training_loss": 0.7000510597229004, "training_acc": 45.0, "val_loss": 0.7691383814811706, "val_acc": 52.0}
{"epoch": 15, "training_loss": 0.7871512055397034, "training_acc": 51.0, "val_loss": 0.7976678013801575, "val_acc": 48.0}
{"epoch": 16, "training_loss": 0.7269878029823303, "training_acc": 55.0, "val_loss": 0.7741545939445496, "val_acc": 52.0}
{"epoch": 17, "training_loss": 0.7331715679168701, "training_acc": 47.0, "val_loss": 0.7053969240188599, "val_acc": 48.0}
{"epoch": 18, "training_loss": 0.7060457873344421, "training_acc": 49.0, "val_loss": 0.8954633331298828, "val_acc": 52.0}
{"epoch": 19, "training_loss": 0.9242784261703492, "training_acc": 43.0, "val_loss": 0.7155009865760803, "val_acc": 52.0}
{"epoch": 20, "training_loss": 0.8077494931221009, "training_acc": 51.0, "val_loss": 0.8131905817985534, "val_acc": 48.0}
{"epoch": 21, "training_loss": 0.8081203174591064, "training_acc": 49.0, "val_loss": 0.7849887037277221, "val_acc": 52.0}
{"epoch": 22, "training_loss": 0.8695304870605469, "training_acc": 41.0, "val_loss": 0.7895612597465516, "val_acc": 52.0}
{"epoch": 23, "training_loss": 0.7309001350402832, "training_acc": 51.0, "val_loss": 0.7021695065498352, "val_acc": 52.0}
{"epoch": 24, "training_loss": 0.7501491808891296, "training_acc": 47.0, "val_loss": 0.8654396629333496, "val_acc": 52.0}
{"epoch": 25, "training_loss": 0.8340705680847168, "training_acc": 49.0, "val_loss": 0.6955866718292236, "val_acc": 48.0}
{"epoch": 26, "training_loss": 0.7855744123458862, "training_acc": 53.0, "val_loss": 0.723528642654419, "val_acc": 48.0}
{"epoch": 27, "training_loss": 0.7190747737884522, "training_acc": 43.0, "val_loss": 0.6952338910102844, "val_acc": 48.0}
{"epoch": 28, "training_loss": 0.7172730541229249, "training_acc": 49.0, "val_loss": 0.6929109787940979, "val_acc": 52.0}
{"epoch": 29, "training_loss": 0.6987131881713867, "training_acc": 51.0, "val_loss": 0.6934513592720032, "val_acc": 52.0}
{"epoch": 30, "training_loss": 0.6991459584236145, "training_acc": 47.0, "val_loss": 0.7491333460807801, "val_acc": 52.0}
{"epoch": 31, "training_loss": 0.740441472530365, "training_acc": 53.0, "val_loss": 0.6964358162879943, "val_acc": 48.0}
{"epoch": 32, "training_loss": 0.7030043745040894, "training_acc": 51.0, "val_loss": 0.7241009140014648, "val_acc": 52.0}
