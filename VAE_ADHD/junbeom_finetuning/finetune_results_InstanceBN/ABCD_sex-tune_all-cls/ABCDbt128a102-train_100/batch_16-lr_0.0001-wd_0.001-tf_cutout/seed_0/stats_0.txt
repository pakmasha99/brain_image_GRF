"main_modify.py --pretrained_path /scratch/connectome/dyhan316/VAE_ADHD/barlowtwins/pretrain_results/ABCDbt128a102.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option BT_org --learning_rate 1e-4 --batch_size 16 --weight_decay 1e-3 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 0.6940505003929138, "training_acc": 53.0, "val_loss": 0.6887683534622192, "val_acc": 56.0}
{"epoch": 1, "training_loss": 0.6923396754264831, "training_acc": 52.0, "val_loss": 0.6884014201164246, "val_acc": 56.0}
{"epoch": 2, "training_loss": 0.6933869051933289, "training_acc": 50.0, "val_loss": 0.6885899782180787, "val_acc": 56.0}
{"epoch": 3, "training_loss": 0.6948829698562622, "training_acc": 52.0, "val_loss": 0.6873618388175964, "val_acc": 56.0}
{"epoch": 4, "training_loss": 0.6945095205307007, "training_acc": 52.0, "val_loss": 0.6887894892692565, "val_acc": 56.0}
{"epoch": 5, "training_loss": 0.6933535695075989, "training_acc": 52.0, "val_loss": 0.6875166320800781, "val_acc": 56.0}
{"epoch": 6, "training_loss": 0.6936008310317994, "training_acc": 52.0, "val_loss": 0.68848548412323, "val_acc": 56.0}
{"epoch": 7, "training_loss": 0.6943762183189393, "training_acc": 52.0, "val_loss": 0.6906461524963379, "val_acc": 56.0}
{"epoch": 8, "training_loss": 0.695491681098938, "training_acc": 52.0, "val_loss": 0.6881493711471558, "val_acc": 56.0}
{"epoch": 9, "training_loss": 0.6940604901313782, "training_acc": 52.0, "val_loss": 0.6911725354194641, "val_acc": 56.0}
{"epoch": 10, "training_loss": 0.6939541149139404, "training_acc": 47.0, "val_loss": 0.695317223072052, "val_acc": 44.0}
{"epoch": 11, "training_loss": 0.6932265329360962, "training_acc": 48.0, "val_loss": 0.6898636651039124, "val_acc": 56.0}
{"epoch": 12, "training_loss": 0.6976072359085083, "training_acc": 52.0, "val_loss": 0.6864499115943908, "val_acc": 56.0}
{"epoch": 13, "training_loss": 0.6945492839813232, "training_acc": 52.0, "val_loss": 0.6873029375076294, "val_acc": 56.0}
{"epoch": 14, "training_loss": 0.6936864614486694, "training_acc": 52.0, "val_loss": 0.6869758725166321, "val_acc": 56.0}
{"epoch": 15, "training_loss": 0.6938577842712402, "training_acc": 52.0, "val_loss": 0.6881138682365417, "val_acc": 56.0}
{"epoch": 16, "training_loss": 0.6955792474746704, "training_acc": 52.0, "val_loss": 0.6860960388183593, "val_acc": 56.0}
{"epoch": 17, "training_loss": 0.6937050151824952, "training_acc": 52.0, "val_loss": 0.6890418958663941, "val_acc": 56.0}
{"epoch": 18, "training_loss": 0.6924265766143799, "training_acc": 52.0, "val_loss": 0.6938333964347839, "val_acc": 44.0}
{"epoch": 19, "training_loss": 0.6955980277061462, "training_acc": 48.0, "val_loss": 0.6952481746673584, "val_acc": 44.0}
{"epoch": 20, "training_loss": 0.6927418184280395, "training_acc": 52.0, "val_loss": 0.6902033567428589, "val_acc": 56.0}
{"epoch": 21, "training_loss": 0.6927037572860718, "training_acc": 52.0, "val_loss": 0.689279899597168, "val_acc": 56.0}
{"epoch": 22, "training_loss": 0.6947993803024292, "training_acc": 52.0, "val_loss": 0.68758141040802, "val_acc": 56.0}
{"epoch": 23, "training_loss": 0.692021222114563, "training_acc": 52.0, "val_loss": 0.6898205375671387, "val_acc": 56.0}
{"epoch": 24, "training_loss": 0.694579758644104, "training_acc": 52.0, "val_loss": 0.6875510239601135, "val_acc": 56.0}
{"epoch": 25, "training_loss": 0.6922826290130615, "training_acc": 52.0, "val_loss": 0.69041006565094, "val_acc": 56.0}
{"epoch": 26, "training_loss": 0.6949991631507874, "training_acc": 52.0, "val_loss": 0.6897381186485291, "val_acc": 56.0}
{"epoch": 27, "training_loss": 0.69325288772583, "training_acc": 52.0, "val_loss": 0.6919905042648316, "val_acc": 56.0}
{"epoch": 28, "training_loss": 0.6941619348526001, "training_acc": 52.0, "val_loss": 0.6906458425521851, "val_acc": 56.0}
{"epoch": 29, "training_loss": 0.6926953434944153, "training_acc": 52.0, "val_loss": 0.6871570634841919, "val_acc": 56.0}
{"epoch": 30, "training_loss": 0.6987040638923645, "training_acc": 52.0, "val_loss": 0.686011655330658, "val_acc": 56.0}
{"epoch": 31, "training_loss": 0.6966697025299072, "training_acc": 52.0, "val_loss": 0.6863666343688964, "val_acc": 56.0}
{"epoch": 32, "training_loss": 0.6962675428390503, "training_acc": 52.0, "val_loss": 0.6857360959053039, "val_acc": 56.0}
{"epoch": 33, "training_loss": 0.6962303304672242, "training_acc": 52.0, "val_loss": 0.6862101364135742, "val_acc": 56.0}
{"epoch": 34, "training_loss": 0.6929898142814637, "training_acc": 52.0, "val_loss": 0.689453809261322, "val_acc": 56.0}
{"epoch": 35, "training_loss": 0.6935730624198914, "training_acc": 50.0, "val_loss": 0.6938161110877991, "val_acc": 44.0}
{"epoch": 36, "training_loss": 0.6929053688049316, "training_acc": 50.0, "val_loss": 0.6898498630523682, "val_acc": 56.0}
{"epoch": 37, "training_loss": 0.6924695253372193, "training_acc": 52.0, "val_loss": 0.6873326086997986, "val_acc": 56.0}
{"epoch": 38, "training_loss": 0.6942810392379761, "training_acc": 52.0, "val_loss": 0.6885318803787231, "val_acc": 56.0}
{"epoch": 39, "training_loss": 0.6924715924263001, "training_acc": 52.0, "val_loss": 0.6900573468208313, "val_acc": 56.0}
{"epoch": 40, "training_loss": 0.6944937753677368, "training_acc": 48.0, "val_loss": 0.693107144832611, "val_acc": 56.0}
{"epoch": 41, "training_loss": 0.6930981040000915, "training_acc": 52.0, "val_loss": 0.6907294106483459, "val_acc": 56.0}
{"epoch": 42, "training_loss": 0.6935546326637269, "training_acc": 52.0, "val_loss": 0.6894907903671265, "val_acc": 56.0}
{"epoch": 43, "training_loss": 0.693622441291809, "training_acc": 52.0, "val_loss": 0.6891833853721618, "val_acc": 56.0}
{"epoch": 44, "training_loss": 0.6941838431358337, "training_acc": 50.0, "val_loss": 0.693297049999237, "val_acc": 44.0}
{"epoch": 45, "training_loss": 0.6932875370979309, "training_acc": 48.0, "val_loss": 0.6915688157081604, "val_acc": 56.0}
{"epoch": 46, "training_loss": 0.692814872264862, "training_acc": 52.0, "val_loss": 0.6895985269546508, "val_acc": 56.0}
{"epoch": 47, "training_loss": 0.6929912900924683, "training_acc": 52.0, "val_loss": 0.6879624319076538, "val_acc": 56.0}
{"epoch": 48, "training_loss": 0.6935358500480652, "training_acc": 52.0, "val_loss": 0.6875902819633484, "val_acc": 56.0}
{"epoch": 49, "training_loss": 0.6917682194709778, "training_acc": 52.0, "val_loss": 0.6902964735031127, "val_acc": 56.0}
{"epoch": 50, "training_loss": 0.6937607717514038, "training_acc": 48.0, "val_loss": 0.6951322150230408, "val_acc": 44.0}
{"epoch": 51, "training_loss": 0.6943479204177856, "training_acc": 48.0, "val_loss": 0.6975356817245484, "val_acc": 44.0}
