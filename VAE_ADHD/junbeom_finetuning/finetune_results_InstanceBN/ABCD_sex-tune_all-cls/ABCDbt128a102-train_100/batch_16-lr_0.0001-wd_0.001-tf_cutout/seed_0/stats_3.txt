"main_modify.py --pretrained_path /scratch/connectome/dyhan316/VAE_ADHD/barlowtwins/pretrain_results/ABCDbt128a102.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option BT_org --learning_rate 1e-4 --batch_size 16 --weight_decay 1e-3 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 0.6921138072013855, "training_acc": 53.0, "val_loss": 0.6926785206794739, "val_acc": 52.0}
{"epoch": 1, "training_loss": 0.6919056367874146, "training_acc": 53.0, "val_loss": 0.6925100803375244, "val_acc": 52.0}
{"epoch": 2, "training_loss": 0.692394335269928, "training_acc": 53.0, "val_loss": 0.6924186205863953, "val_acc": 52.0}
{"epoch": 3, "training_loss": 0.6924031686782837, "training_acc": 53.0, "val_loss": 0.6925188875198365, "val_acc": 52.0}
{"epoch": 4, "training_loss": 0.6930853223800659, "training_acc": 53.0, "val_loss": 0.6941046452522278, "val_acc": 52.0}
{"epoch": 5, "training_loss": 0.6977262449264526, "training_acc": 53.0, "val_loss": 0.6937659978866577, "val_acc": 52.0}
{"epoch": 6, "training_loss": 0.6934557008743286, "training_acc": 53.0, "val_loss": 0.6924393248558044, "val_acc": 52.0}
{"epoch": 7, "training_loss": 0.6931440043449402, "training_acc": 53.0, "val_loss": 0.6927038025856018, "val_acc": 52.0}
{"epoch": 8, "training_loss": 0.6936276459693909, "training_acc": 53.0, "val_loss": 0.6924022364616395, "val_acc": 52.0}
{"epoch": 9, "training_loss": 0.6921585988998413, "training_acc": 53.0, "val_loss": 0.6923808431625367, "val_acc": 52.0}
{"epoch": 10, "training_loss": 0.6915994191169739, "training_acc": 53.0, "val_loss": 0.693679757118225, "val_acc": 52.0}
{"epoch": 11, "training_loss": 0.6919049263000489, "training_acc": 53.0, "val_loss": 0.6953341913223267, "val_acc": 52.0}
{"epoch": 12, "training_loss": 0.6956051063537597, "training_acc": 53.0, "val_loss": 0.6955539011955261, "val_acc": 52.0}
{"epoch": 13, "training_loss": 0.6915037393569946, "training_acc": 53.0, "val_loss": 0.6924303722381592, "val_acc": 52.0}
{"epoch": 14, "training_loss": 0.6927504301071167, "training_acc": 53.0, "val_loss": 0.6925245380401611, "val_acc": 52.0}
{"epoch": 15, "training_loss": 0.69458660364151, "training_acc": 53.0, "val_loss": 0.6926768302917481, "val_acc": 52.0}
{"epoch": 16, "training_loss": 0.6936535096168518, "training_acc": 53.0, "val_loss": 0.6924324584007263, "val_acc": 52.0}
{"epoch": 17, "training_loss": 0.6930219602584838, "training_acc": 53.0, "val_loss": 0.6929217100143432, "val_acc": 52.0}
{"epoch": 18, "training_loss": 0.6975108504295349, "training_acc": 45.0, "val_loss": 0.6942636752128601, "val_acc": 48.0}
{"epoch": 19, "training_loss": 0.6930219745635986, "training_acc": 49.0, "val_loss": 0.692417414188385, "val_acc": 52.0}
{"epoch": 20, "training_loss": 0.6931488347053528, "training_acc": 53.0, "val_loss": 0.6924931263923645, "val_acc": 52.0}
{"epoch": 21, "training_loss": 0.6919661545753479, "training_acc": 53.0, "val_loss": 0.6923711204528809, "val_acc": 52.0}
{"epoch": 22, "training_loss": 0.6961266899108887, "training_acc": 53.0, "val_loss": 0.6928411149978637, "val_acc": 52.0}
{"epoch": 23, "training_loss": 0.6915603971481323, "training_acc": 53.0, "val_loss": 0.6924979043006897, "val_acc": 52.0}
{"epoch": 24, "training_loss": 0.692448947429657, "training_acc": 53.0, "val_loss": 0.6924159717559815, "val_acc": 52.0}
{"epoch": 25, "training_loss": 0.6987942600250244, "training_acc": 53.0, "val_loss": 0.6931745457649231, "val_acc": 52.0}
{"epoch": 26, "training_loss": 0.6927513599395752, "training_acc": 53.0, "val_loss": 0.6923725152015686, "val_acc": 52.0}
{"epoch": 27, "training_loss": 0.6933885669708252, "training_acc": 53.0, "val_loss": 0.6923698902130127, "val_acc": 52.0}
{"epoch": 28, "training_loss": 0.694030179977417, "training_acc": 53.0, "val_loss": 0.6933083391189575, "val_acc": 52.0}
{"epoch": 29, "training_loss": 0.6928932666778564, "training_acc": 53.0, "val_loss": 0.6932217645645141, "val_acc": 52.0}
{"epoch": 30, "training_loss": 0.6961992430686951, "training_acc": 53.0, "val_loss": 0.6939621305465699, "val_acc": 52.0}
{"epoch": 31, "training_loss": 0.6910464572906494, "training_acc": 53.0, "val_loss": 0.6925488042831421, "val_acc": 52.0}
{"epoch": 32, "training_loss": 0.6926749229431153, "training_acc": 53.0, "val_loss": 0.692649576663971, "val_acc": 52.0}
{"epoch": 33, "training_loss": 0.6931842422485351, "training_acc": 49.0, "val_loss": 0.6933091235160828, "val_acc": 48.0}
{"epoch": 34, "training_loss": 0.6941883134841919, "training_acc": 53.0, "val_loss": 0.6923613333702088, "val_acc": 52.0}
{"epoch": 35, "training_loss": 0.6917107057571411, "training_acc": 53.0, "val_loss": 0.6923458814620972, "val_acc": 52.0}
{"epoch": 36, "training_loss": 0.6916198873519898, "training_acc": 53.0, "val_loss": 0.6925368690490723, "val_acc": 52.0}
{"epoch": 37, "training_loss": 0.692206687927246, "training_acc": 53.0, "val_loss": 0.6926599860191345, "val_acc": 52.0}
{"epoch": 38, "training_loss": 0.6931890201568603, "training_acc": 53.0, "val_loss": 0.6925226283073426, "val_acc": 52.0}
{"epoch": 39, "training_loss": 0.6927894997596741, "training_acc": 53.0, "val_loss": 0.6923738074302673, "val_acc": 52.0}
{"epoch": 40, "training_loss": 0.6929874753952027, "training_acc": 53.0, "val_loss": 0.6924054789543151, "val_acc": 52.0}
{"epoch": 41, "training_loss": 0.6943165493011475, "training_acc": 53.0, "val_loss": 0.6923511528968811, "val_acc": 52.0}
{"epoch": 42, "training_loss": 0.6968440532684326, "training_acc": 37.0, "val_loss": 0.6933148670196533, "val_acc": 48.0}
{"epoch": 43, "training_loss": 0.6935336756706237, "training_acc": 45.0, "val_loss": 0.692964699268341, "val_acc": 52.0}
{"epoch": 44, "training_loss": 0.6941995668411255, "training_acc": 52.0, "val_loss": 0.6923758721351624, "val_acc": 52.0}
{"epoch": 45, "training_loss": 0.6919056987762451, "training_acc": 53.0, "val_loss": 0.6929461073875427, "val_acc": 52.0}
{"epoch": 46, "training_loss": 0.6927795433998107, "training_acc": 53.0, "val_loss": 0.6931686496734619, "val_acc": 52.0}
{"epoch": 47, "training_loss": 0.693257007598877, "training_acc": 53.0, "val_loss": 0.6924827551841736, "val_acc": 52.0}
{"epoch": 48, "training_loss": 0.6929106879234314, "training_acc": 53.0, "val_loss": 0.69237389087677, "val_acc": 52.0}
{"epoch": 49, "training_loss": 0.692377462387085, "training_acc": 53.0, "val_loss": 0.6931846714019776, "val_acc": 52.0}
{"epoch": 50, "training_loss": 0.6935773777961731, "training_acc": 53.0, "val_loss": 0.6949563598632813, "val_acc": 52.0}
{"epoch": 51, "training_loss": 0.6918546533584595, "training_acc": 53.0, "val_loss": 0.6929185938835144, "val_acc": 52.0}
{"epoch": 52, "training_loss": 0.6923649263381958, "training_acc": 53.0, "val_loss": 0.6930641508102418, "val_acc": 52.0}
{"epoch": 53, "training_loss": 0.6929497051239014, "training_acc": 53.0, "val_loss": 0.6923645830154419, "val_acc": 52.0}
{"epoch": 54, "training_loss": 0.6917268013954163, "training_acc": 53.0, "val_loss": 0.6923885679244995, "val_acc": 52.0}
