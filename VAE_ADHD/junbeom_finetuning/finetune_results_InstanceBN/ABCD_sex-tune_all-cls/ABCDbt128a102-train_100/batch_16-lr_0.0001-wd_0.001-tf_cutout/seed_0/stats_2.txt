"main_modify.py --pretrained_path /scratch/connectome/dyhan316/VAE_ADHD/barlowtwins/pretrain_results/ABCDbt128a102.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option BT_org --learning_rate 1e-4 --batch_size 16 --weight_decay 1e-3 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 0.6998075318336486, "training_acc": 41.0, "val_loss": 0.6968879270553588, "val_acc": 48.0}
{"epoch": 1, "training_loss": 0.6903336024284363, "training_acc": 58.0, "val_loss": 0.6926601505279542, "val_acc": 52.0}
{"epoch": 2, "training_loss": 0.6925585842132569, "training_acc": 53.0, "val_loss": 0.6938834834098816, "val_acc": 52.0}
{"epoch": 3, "training_loss": 0.6929044055938721, "training_acc": 53.0, "val_loss": 0.6940952801704406, "val_acc": 52.0}
{"epoch": 4, "training_loss": 0.6925579357147217, "training_acc": 53.0, "val_loss": 0.692486093044281, "val_acc": 52.0}
{"epoch": 5, "training_loss": 0.6921790266036987, "training_acc": 53.0, "val_loss": 0.6928459572792053, "val_acc": 52.0}
{"epoch": 6, "training_loss": 0.6925546908378601, "training_acc": 53.0, "val_loss": 0.6928473043441773, "val_acc": 52.0}
{"epoch": 7, "training_loss": 0.6912831163406372, "training_acc": 53.0, "val_loss": 0.6923587846755982, "val_acc": 52.0}
{"epoch": 8, "training_loss": 0.6922724580764771, "training_acc": 53.0, "val_loss": 0.6925134110450745, "val_acc": 52.0}
{"epoch": 9, "training_loss": 0.6917743277549744, "training_acc": 53.0, "val_loss": 0.6938339352607727, "val_acc": 52.0}
{"epoch": 10, "training_loss": 0.6926665592193604, "training_acc": 53.0, "val_loss": 0.6929028940200805, "val_acc": 52.0}
{"epoch": 11, "training_loss": 0.6925837540626526, "training_acc": 53.0, "val_loss": 0.6950063085556031, "val_acc": 52.0}
{"epoch": 12, "training_loss": 0.6936998057365418, "training_acc": 53.0, "val_loss": 0.6964122867584228, "val_acc": 52.0}
{"epoch": 13, "training_loss": 0.6945718479156494, "training_acc": 53.0, "val_loss": 0.6952999687194824, "val_acc": 52.0}
{"epoch": 14, "training_loss": 0.6930681705474854, "training_acc": 53.0, "val_loss": 0.6939434814453125, "val_acc": 52.0}
{"epoch": 15, "training_loss": 0.6922237205505372, "training_acc": 53.0, "val_loss": 0.6933395695686341, "val_acc": 52.0}
{"epoch": 16, "training_loss": 0.6926257801055908, "training_acc": 53.0, "val_loss": 0.6925492906570434, "val_acc": 52.0}
{"epoch": 17, "training_loss": 0.6923259115219116, "training_acc": 53.0, "val_loss": 0.6936428141593933, "val_acc": 52.0}
{"epoch": 18, "training_loss": 0.6960573029518128, "training_acc": 53.0, "val_loss": 0.6950956869125366, "val_acc": 52.0}
{"epoch": 19, "training_loss": 0.6938057088851929, "training_acc": 53.0, "val_loss": 0.6927487874031066, "val_acc": 52.0}
{"epoch": 20, "training_loss": 0.6928331279754638, "training_acc": 53.0, "val_loss": 0.6924952721595764, "val_acc": 52.0}
{"epoch": 21, "training_loss": 0.6937902355194092, "training_acc": 53.0, "val_loss": 0.6936006569862365, "val_acc": 52.0}
{"epoch": 22, "training_loss": 0.6923767852783204, "training_acc": 53.0, "val_loss": 0.6926148343086242, "val_acc": 52.0}
{"epoch": 23, "training_loss": 0.6907178020477295, "training_acc": 53.0, "val_loss": 0.6924872374534607, "val_acc": 52.0}
{"epoch": 24, "training_loss": 0.6977465128898621, "training_acc": 39.0, "val_loss": 0.6928564047813416, "val_acc": 52.0}
{"epoch": 25, "training_loss": 0.6907013607025146, "training_acc": 53.0, "val_loss": 0.6923654246330261, "val_acc": 52.0}
{"epoch": 26, "training_loss": 0.6940383672714233, "training_acc": 53.0, "val_loss": 0.6925301074981689, "val_acc": 52.0}
