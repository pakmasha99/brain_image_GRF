"main_modify.py --pretrained_path /scratch/connectome/dyhan316/VAE_ADHD/barlowtwins/pretrain_results/ABCDbt128a102.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option BT_org --learning_rate 5e-5 --batch_size 16 --weight_decay 5e-2 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 0.6923322892189026, "training_acc": 52.0, "val_loss": 0.6909046578407287, "val_acc": 56.0}
{"epoch": 1, "training_loss": 0.6918485593795777, "training_acc": 52.0, "val_loss": 0.6884717106819153, "val_acc": 56.0}
{"epoch": 2, "training_loss": 0.6928231716156006, "training_acc": 52.0, "val_loss": 0.688601610660553, "val_acc": 56.0}
{"epoch": 3, "training_loss": 0.6930235004425049, "training_acc": 52.0, "val_loss": 0.6883017873764038, "val_acc": 56.0}
{"epoch": 4, "training_loss": 0.6929786419868469, "training_acc": 52.0, "val_loss": 0.6891662621498108, "val_acc": 56.0}
{"epoch": 5, "training_loss": 0.692688581943512, "training_acc": 52.0, "val_loss": 0.6883361458778381, "val_acc": 56.0}
{"epoch": 6, "training_loss": 0.6928415942192078, "training_acc": 52.0, "val_loss": 0.6875523114204407, "val_acc": 56.0}
{"epoch": 7, "training_loss": 0.6930066776275635, "training_acc": 52.0, "val_loss": 0.6894184017181396, "val_acc": 56.0}
{"epoch": 8, "training_loss": 0.6932934141159057, "training_acc": 52.0, "val_loss": 0.6883079886436463, "val_acc": 56.0}
{"epoch": 9, "training_loss": 0.6928608036041259, "training_acc": 52.0, "val_loss": 0.6873932433128357, "val_acc": 56.0}
{"epoch": 10, "training_loss": 0.6931099987030029, "training_acc": 52.0, "val_loss": 0.6893709254264831, "val_acc": 56.0}
{"epoch": 11, "training_loss": 0.6923167848587036, "training_acc": 52.0, "val_loss": 0.6883394145965576, "val_acc": 56.0}
{"epoch": 12, "training_loss": 0.6939280319213867, "training_acc": 52.0, "val_loss": 0.6887021279335022, "val_acc": 56.0}
{"epoch": 13, "training_loss": 0.6931955432891845, "training_acc": 52.0, "val_loss": 0.6885337209701539, "val_acc": 56.0}
{"epoch": 14, "training_loss": 0.6927216458320617, "training_acc": 52.0, "val_loss": 0.687873432636261, "val_acc": 56.0}
{"epoch": 15, "training_loss": 0.6930183553695679, "training_acc": 52.0, "val_loss": 0.6874465155601501, "val_acc": 56.0}
{"epoch": 16, "training_loss": 0.6941980791091918, "training_acc": 52.0, "val_loss": 0.6885541009902955, "val_acc": 56.0}
{"epoch": 17, "training_loss": 0.6928337335586547, "training_acc": 52.0, "val_loss": 0.6876336526870728, "val_acc": 56.0}
{"epoch": 18, "training_loss": 0.6921722984313965, "training_acc": 52.0, "val_loss": 0.688802182674408, "val_acc": 56.0}
{"epoch": 19, "training_loss": 0.6933705258369446, "training_acc": 50.0, "val_loss": 0.6935549712181092, "val_acc": 56.0}
{"epoch": 20, "training_loss": 0.692691068649292, "training_acc": 52.0, "val_loss": 0.6907509303092957, "val_acc": 56.0}
{"epoch": 21, "training_loss": 0.692562358379364, "training_acc": 52.0, "val_loss": 0.6897401762008667, "val_acc": 56.0}
{"epoch": 22, "training_loss": 0.6934577989578247, "training_acc": 52.0, "val_loss": 0.6882909798622131, "val_acc": 56.0}
{"epoch": 23, "training_loss": 0.6921808576583862, "training_acc": 52.0, "val_loss": 0.6888667511940002, "val_acc": 56.0}
{"epoch": 24, "training_loss": 0.693789873123169, "training_acc": 52.0, "val_loss": 0.6870008254051209, "val_acc": 56.0}
{"epoch": 25, "training_loss": 0.6924000740051269, "training_acc": 52.0, "val_loss": 0.6891412425041199, "val_acc": 56.0}
{"epoch": 26, "training_loss": 0.6937004661560059, "training_acc": 52.0, "val_loss": 0.6889682936668396, "val_acc": 56.0}
{"epoch": 27, "training_loss": 0.6920487976074219, "training_acc": 52.0, "val_loss": 0.6903487706184387, "val_acc": 56.0}
{"epoch": 28, "training_loss": 0.6935051155090332, "training_acc": 52.0, "val_loss": 0.6888341641426087, "val_acc": 56.0}
{"epoch": 29, "training_loss": 0.6921845388412475, "training_acc": 52.0, "val_loss": 0.6875567436218262, "val_acc": 56.0}
{"epoch": 30, "training_loss": 0.6952720737457275, "training_acc": 52.0, "val_loss": 0.6866581368446351, "val_acc": 56.0}
{"epoch": 31, "training_loss": 0.693954815864563, "training_acc": 52.0, "val_loss": 0.6866835117340088, "val_acc": 56.0}
{"epoch": 32, "training_loss": 0.694795560836792, "training_acc": 52.0, "val_loss": 0.6861386966705322, "val_acc": 56.0}
{"epoch": 33, "training_loss": 0.6949189615249634, "training_acc": 52.0, "val_loss": 0.68639089345932, "val_acc": 56.0}
{"epoch": 34, "training_loss": 0.6934588479995728, "training_acc": 52.0, "val_loss": 0.6879795527458191, "val_acc": 56.0}
{"epoch": 35, "training_loss": 0.6927329683303833, "training_acc": 52.0, "val_loss": 0.6907875061035156, "val_acc": 56.0}
{"epoch": 36, "training_loss": 0.6925627183914185, "training_acc": 52.0, "val_loss": 0.6892766618728637, "val_acc": 56.0}
{"epoch": 37, "training_loss": 0.6925844860076904, "training_acc": 52.0, "val_loss": 0.6879293847084046, "val_acc": 56.0}
{"epoch": 38, "training_loss": 0.6936124610900879, "training_acc": 52.0, "val_loss": 0.6885770654678345, "val_acc": 56.0}
{"epoch": 39, "training_loss": 0.6924064922332763, "training_acc": 52.0, "val_loss": 0.689992744922638, "val_acc": 56.0}
{"epoch": 40, "training_loss": 0.6942462968826294, "training_acc": 52.0, "val_loss": 0.6899422073364258, "val_acc": 56.0}
{"epoch": 41, "training_loss": 0.6922503876686096, "training_acc": 52.0, "val_loss": 0.6882704210281372, "val_acc": 56.0}
{"epoch": 42, "training_loss": 0.6930691051483154, "training_acc": 52.0, "val_loss": 0.6888489699363709, "val_acc": 56.0}
{"epoch": 43, "training_loss": 0.6939018130302429, "training_acc": 52.0, "val_loss": 0.689495108127594, "val_acc": 56.0}
{"epoch": 44, "training_loss": 0.6941774249076843, "training_acc": 45.0, "val_loss": 0.6911036682128906, "val_acc": 56.0}
{"epoch": 45, "training_loss": 0.6928516554832459, "training_acc": 52.0, "val_loss": 0.6898160600662231, "val_acc": 56.0}
{"epoch": 46, "training_loss": 0.6929148054122924, "training_acc": 52.0, "val_loss": 0.6893425822257996, "val_acc": 56.0}
{"epoch": 47, "training_loss": 0.6936734986305236, "training_acc": 52.0, "val_loss": 0.6879010367393493, "val_acc": 56.0}
{"epoch": 48, "training_loss": 0.6939865255355835, "training_acc": 52.0, "val_loss": 0.6880682945251465, "val_acc": 56.0}
{"epoch": 49, "training_loss": 0.6914508461952209, "training_acc": 52.0, "val_loss": 0.6918546342849732, "val_acc": 56.0}
{"epoch": 50, "training_loss": 0.6948570251464844, "training_acc": 46.0, "val_loss": 0.6964144849777222, "val_acc": 44.0}
{"epoch": 51, "training_loss": 0.6950642585754394, "training_acc": 48.0, "val_loss": 0.6968104600906372, "val_acc": 44.0}
