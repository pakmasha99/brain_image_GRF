"main_modify.py --pretrained_path /scratch/connectome/dyhan316/VAE_ADHD/barlowtwins/pretrain_results/ABCDbt128a102.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option BT_org --learning_rate 5e-4 --batch_size 16 --weight_decay 5e-2 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 0.7051162958145142, "training_acc": 41.0, "val_loss": 0.6939628624916077, "val_acc": 52.0}
{"epoch": 1, "training_loss": 0.6957137393951416, "training_acc": 53.0, "val_loss": 0.6924041485786439, "val_acc": 52.0}
{"epoch": 2, "training_loss": 0.6927222442626954, "training_acc": 53.0, "val_loss": 0.6943971204757691, "val_acc": 48.0}
{"epoch": 3, "training_loss": 0.6964754581451416, "training_acc": 51.0, "val_loss": 0.6932531476020813, "val_acc": 52.0}
{"epoch": 4, "training_loss": 0.6940038537979126, "training_acc": 53.0, "val_loss": 0.6956577181816102, "val_acc": 52.0}
{"epoch": 5, "training_loss": 0.6930516386032104, "training_acc": 53.0, "val_loss": 0.6974414825439453, "val_acc": 52.0}
{"epoch": 6, "training_loss": 0.7023350405693054, "training_acc": 53.0, "val_loss": 0.6923393416404724, "val_acc": 52.0}
{"epoch": 7, "training_loss": 0.6951769971847535, "training_acc": 47.0, "val_loss": 0.6937928485870362, "val_acc": 52.0}
{"epoch": 8, "training_loss": 0.7021944642066955, "training_acc": 53.0, "val_loss": 0.6938979411125183, "val_acc": 52.0}
{"epoch": 9, "training_loss": 0.6984973430633545, "training_acc": 53.0, "val_loss": 0.6929837870597839, "val_acc": 52.0}
{"epoch": 10, "training_loss": 0.6986408901214599, "training_acc": 45.0, "val_loss": 0.6927274775505066, "val_acc": 52.0}
{"epoch": 11, "training_loss": 0.6990440988540649, "training_acc": 53.0, "val_loss": 0.6926615285873413, "val_acc": 52.0}
{"epoch": 12, "training_loss": 0.7025421786308289, "training_acc": 37.0, "val_loss": 0.6923819351196289, "val_acc": 52.0}
{"epoch": 13, "training_loss": 0.6980640459060669, "training_acc": 53.0, "val_loss": 0.6944245147705078, "val_acc": 52.0}
{"epoch": 14, "training_loss": 0.6980891108512879, "training_acc": 53.0, "val_loss": 0.694756293296814, "val_acc": 52.0}
{"epoch": 15, "training_loss": 0.6918250131607055, "training_acc": 53.0, "val_loss": 0.6925805282592773, "val_acc": 52.0}
{"epoch": 16, "training_loss": 0.7065044069290161, "training_acc": 37.0, "val_loss": 0.6924504399299621, "val_acc": 52.0}
{"epoch": 17, "training_loss": 0.6994260597229004, "training_acc": 53.0, "val_loss": 0.6926612019538879, "val_acc": 52.0}
{"epoch": 18, "training_loss": 0.6994862127304077, "training_acc": 53.0, "val_loss": 0.692530791759491, "val_acc": 52.0}
{"epoch": 19, "training_loss": 0.6962341165542603, "training_acc": 53.0, "val_loss": 0.692492597103119, "val_acc": 52.0}
{"epoch": 20, "training_loss": 0.6948889589309692, "training_acc": 53.0, "val_loss": 0.6941404628753662, "val_acc": 52.0}
{"epoch": 21, "training_loss": 0.6953906559944153, "training_acc": 53.0, "val_loss": 0.6928191399574279, "val_acc": 52.0}
{"epoch": 22, "training_loss": 0.6942000436782837, "training_acc": 53.0, "val_loss": 0.6926556897163391, "val_acc": 52.0}
{"epoch": 23, "training_loss": 0.7021266651153565, "training_acc": 47.0, "val_loss": 0.6939904022216797, "val_acc": 52.0}
{"epoch": 24, "training_loss": 0.6940028142929077, "training_acc": 53.0, "val_loss": 0.6942509937286377, "val_acc": 52.0}
{"epoch": 25, "training_loss": 0.6946186423301697, "training_acc": 53.0, "val_loss": 0.6931230854988099, "val_acc": 52.0}
