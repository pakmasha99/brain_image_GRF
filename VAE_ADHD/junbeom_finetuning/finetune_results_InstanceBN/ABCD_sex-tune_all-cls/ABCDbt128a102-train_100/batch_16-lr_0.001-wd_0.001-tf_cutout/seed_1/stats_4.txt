"main_modify.py --pretrained_path /scratch/connectome/dyhan316/VAE_ADHD/barlowtwins/pretrain_results/ABCDbt128a102.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 1 --task ABCD_sex --input_option BT_org --learning_rate 1e-3 --batch_size 16 --weight_decay 1e-3 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 0.7173803973197938, "training_acc": 52.0, "val_loss": 0.7227280354499817, "val_acc": 44.0}
{"epoch": 1, "training_loss": 0.7117424416542053, "training_acc": 40.0, "val_loss": 0.6918426918983459, "val_acc": 56.0}
{"epoch": 2, "training_loss": 0.6963583588600158, "training_acc": 46.0, "val_loss": 0.6932141709327698, "val_acc": 44.0}
{"epoch": 3, "training_loss": 0.7122906732559204, "training_acc": 48.0, "val_loss": 0.6936908030509948, "val_acc": 44.0}
{"epoch": 4, "training_loss": 0.7019511079788208, "training_acc": 52.0, "val_loss": 0.6865480470657349, "val_acc": 56.0}
{"epoch": 5, "training_loss": 0.7022750425338745, "training_acc": 52.0, "val_loss": 0.6875379967689514, "val_acc": 56.0}
{"epoch": 6, "training_loss": 0.6970061349868775, "training_acc": 52.0, "val_loss": 0.692490348815918, "val_acc": 56.0}
{"epoch": 7, "training_loss": 0.6961961412429809, "training_acc": 50.0, "val_loss": 0.6973564028739929, "val_acc": 44.0}
{"epoch": 8, "training_loss": 0.7028507590293884, "training_acc": 44.0, "val_loss": 0.6907305479049682, "val_acc": 56.0}
{"epoch": 9, "training_loss": 0.7003884124755859, "training_acc": 54.0, "val_loss": 0.7046172070503235, "val_acc": 44.0}
{"epoch": 10, "training_loss": 0.6997052717208863, "training_acc": 54.0, "val_loss": 0.6866392946243286, "val_acc": 56.0}
{"epoch": 11, "training_loss": 0.701367883682251, "training_acc": 46.0, "val_loss": 0.6896888446807862, "val_acc": 56.0}
{"epoch": 12, "training_loss": 0.6959021472930909, "training_acc": 52.0, "val_loss": 0.6875732326507569, "val_acc": 56.0}
{"epoch": 13, "training_loss": 0.6998397922515869, "training_acc": 52.0, "val_loss": 0.7039123773574829, "val_acc": 44.0}
{"epoch": 14, "training_loss": 0.7063886022567749, "training_acc": 48.0, "val_loss": 0.7185460662841797, "val_acc": 44.0}
{"epoch": 15, "training_loss": 0.7059827756881714, "training_acc": 46.0, "val_loss": 0.6909657263755798, "val_acc": 56.0}
{"epoch": 16, "training_loss": 0.6953899216651916, "training_acc": 52.0, "val_loss": 0.6874109387397767, "val_acc": 56.0}
{"epoch": 17, "training_loss": 0.6940646719932556, "training_acc": 52.0, "val_loss": 0.6912333202362061, "val_acc": 56.0}
{"epoch": 18, "training_loss": 0.6975774669647217, "training_acc": 46.0, "val_loss": 0.6874178338050843, "val_acc": 56.0}
{"epoch": 19, "training_loss": 0.695284948348999, "training_acc": 52.0, "val_loss": 0.6859615635871887, "val_acc": 56.0}
{"epoch": 20, "training_loss": 0.6985773420333863, "training_acc": 52.0, "val_loss": 0.6873292970657349, "val_acc": 56.0}
{"epoch": 21, "training_loss": 0.7031109237670898, "training_acc": 40.0, "val_loss": 0.6922411727905273, "val_acc": 56.0}
{"epoch": 22, "training_loss": 0.6935190725326538, "training_acc": 52.0, "val_loss": 0.6898056411743164, "val_acc": 56.0}
{"epoch": 23, "training_loss": 0.6982510709762573, "training_acc": 44.0, "val_loss": 0.6931874489784241, "val_acc": 44.0}
{"epoch": 24, "training_loss": 0.6981548595428467, "training_acc": 48.0, "val_loss": 0.6918778347969056, "val_acc": 56.0}
{"epoch": 25, "training_loss": 0.6984664726257325, "training_acc": 52.0, "val_loss": 0.6869040608406067, "val_acc": 56.0}
{"epoch": 26, "training_loss": 0.6975007343292237, "training_acc": 52.0, "val_loss": 0.7070165014266968, "val_acc": 44.0}
{"epoch": 27, "training_loss": 0.7076590275764465, "training_acc": 48.0, "val_loss": 0.7000312638282776, "val_acc": 44.0}
{"epoch": 28, "training_loss": 0.7015955448150635, "training_acc": 48.0, "val_loss": 0.6868377828598022, "val_acc": 56.0}
{"epoch": 29, "training_loss": 0.7028524708747864, "training_acc": 42.0, "val_loss": 0.6905675148963928, "val_acc": 56.0}
{"epoch": 30, "training_loss": 0.6934136390686035, "training_acc": 52.0, "val_loss": 0.686363422870636, "val_acc": 56.0}
{"epoch": 31, "training_loss": 0.711244854927063, "training_acc": 52.0, "val_loss": 0.6882150244712829, "val_acc": 56.0}
{"epoch": 32, "training_loss": 0.696243188381195, "training_acc": 46.0, "val_loss": 0.7046708011627197, "val_acc": 44.0}
{"epoch": 33, "training_loss": 0.7072495245933532, "training_acc": 48.0, "val_loss": 0.7015734934806823, "val_acc": 44.0}
{"epoch": 34, "training_loss": 0.6990265035629273, "training_acc": 48.0, "val_loss": 0.6859308314323426, "val_acc": 56.0}
{"epoch": 35, "training_loss": 0.6954802083969116, "training_acc": 52.0, "val_loss": 0.6964676642417907, "val_acc": 44.0}
{"epoch": 36, "training_loss": 0.6964269065856934, "training_acc": 50.0, "val_loss": 0.6876821160316468, "val_acc": 56.0}
{"epoch": 37, "training_loss": 0.7049855804443359, "training_acc": 52.0, "val_loss": 0.6860852408409118, "val_acc": 56.0}
{"epoch": 38, "training_loss": 0.7002031087875367, "training_acc": 48.0, "val_loss": 0.6867129158973694, "val_acc": 56.0}
{"epoch": 39, "training_loss": 0.6968209385871887, "training_acc": 52.0, "val_loss": 0.6860221433639526, "val_acc": 56.0}
{"epoch": 40, "training_loss": 0.6964621877670288, "training_acc": 52.0, "val_loss": 0.690171844959259, "val_acc": 56.0}
{"epoch": 41, "training_loss": 0.6942784523963929, "training_acc": 52.0, "val_loss": 0.6949132084846497, "val_acc": 44.0}
{"epoch": 42, "training_loss": 0.7012381052970886, "training_acc": 42.0, "val_loss": 0.6968568158149719, "val_acc": 44.0}
{"epoch": 43, "training_loss": 0.6988729953765869, "training_acc": 36.0, "val_loss": 0.6911407876014709, "val_acc": 56.0}
{"epoch": 44, "training_loss": 0.6964839315414428, "training_acc": 52.0, "val_loss": 0.6889825940132142, "val_acc": 56.0}
{"epoch": 45, "training_loss": 0.7080156803131104, "training_acc": 50.0, "val_loss": 0.7159930539131164, "val_acc": 44.0}
{"epoch": 46, "training_loss": 0.6991354990005493, "training_acc": 48.0, "val_loss": 0.6861572384834289, "val_acc": 56.0}
{"epoch": 47, "training_loss": 0.7089259505271912, "training_acc": 52.0, "val_loss": 0.6859711456298828, "val_acc": 56.0}
{"epoch": 48, "training_loss": 0.727203106880188, "training_acc": 42.0, "val_loss": 0.7192225575447082, "val_acc": 44.0}
{"epoch": 49, "training_loss": 0.7087353014945984, "training_acc": 44.0, "val_loss": 0.6860535454750061, "val_acc": 56.0}
{"epoch": 50, "training_loss": 0.6985210943222045, "training_acc": 52.0, "val_loss": 0.6945215630531311, "val_acc": 44.0}
{"epoch": 51, "training_loss": 0.696791205406189, "training_acc": 48.0, "val_loss": 0.708757746219635, "val_acc": 44.0}
{"epoch": 52, "training_loss": 0.7087033462524414, "training_acc": 46.0, "val_loss": 0.6893524169921875, "val_acc": 56.0}
{"epoch": 53, "training_loss": 0.7065363931655884, "training_acc": 56.0, "val_loss": 0.7196740412712097, "val_acc": 44.0}
