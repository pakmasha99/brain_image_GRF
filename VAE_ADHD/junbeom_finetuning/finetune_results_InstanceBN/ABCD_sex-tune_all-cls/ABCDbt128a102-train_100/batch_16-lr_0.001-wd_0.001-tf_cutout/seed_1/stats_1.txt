"main_modify.py --pretrained_path /scratch/connectome/dyhan316/VAE_ADHD/barlowtwins/pretrain_results/ABCDbt128a102.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 1 --task ABCD_sex --input_option BT_org --learning_rate 1e-3 --batch_size 16 --weight_decay 1e-3 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 0.7095900368690491, "training_acc": 48.0, "val_loss": 0.6937547707557679, "val_acc": 52.0}
{"epoch": 1, "training_loss": 0.6957910680770873, "training_acc": 49.0, "val_loss": 0.6969385361671447, "val_acc": 48.0}
{"epoch": 2, "training_loss": 0.6981878471374512, "training_acc": 45.0, "val_loss": 0.6926811981201172, "val_acc": 52.0}
{"epoch": 3, "training_loss": 0.6987861824035645, "training_acc": 51.0, "val_loss": 0.6924318408966065, "val_acc": 52.0}
{"epoch": 4, "training_loss": 0.7178358197212219, "training_acc": 43.0, "val_loss": 0.6937283229827881, "val_acc": 52.0}
{"epoch": 5, "training_loss": 0.7431128120422363, "training_acc": 53.0, "val_loss": 0.7063185548782349, "val_acc": 52.0}
{"epoch": 6, "training_loss": 0.6852501487731933, "training_acc": 53.0, "val_loss": 0.7069279980659485, "val_acc": 48.0}
{"epoch": 7, "training_loss": 0.7074969482421875, "training_acc": 45.0, "val_loss": 0.6936640858650207, "val_acc": 48.0}
{"epoch": 8, "training_loss": 0.6972878241539001, "training_acc": 45.0, "val_loss": 0.6923606610298156, "val_acc": 52.0}
{"epoch": 9, "training_loss": 0.698391809463501, "training_acc": 47.0, "val_loss": 0.6926920437812805, "val_acc": 52.0}
{"epoch": 10, "training_loss": 0.7160645723342896, "training_acc": 53.0, "val_loss": 0.70221435546875, "val_acc": 52.0}
{"epoch": 11, "training_loss": 0.6913296031951904, "training_acc": 53.0, "val_loss": 0.6963238167762756, "val_acc": 48.0}
{"epoch": 12, "training_loss": 0.7168195128440857, "training_acc": 45.0, "val_loss": 0.6924488162994384, "val_acc": 52.0}
{"epoch": 13, "training_loss": 0.6977084898948669, "training_acc": 53.0, "val_loss": 0.692474319934845, "val_acc": 52.0}
{"epoch": 14, "training_loss": 0.705633454322815, "training_acc": 53.0, "val_loss": 0.6927005171775817, "val_acc": 52.0}
{"epoch": 15, "training_loss": 0.7010367274284363, "training_acc": 41.0, "val_loss": 0.6932462739944458, "val_acc": 48.0}
{"epoch": 16, "training_loss": 0.704418170452118, "training_acc": 49.0, "val_loss": 0.6933378148078918, "val_acc": 52.0}
{"epoch": 17, "training_loss": 0.6959100770950317, "training_acc": 53.0, "val_loss": 0.702375681400299, "val_acc": 52.0}
{"epoch": 18, "training_loss": 0.7059907054901123, "training_acc": 45.0, "val_loss": 0.6941662836074829, "val_acc": 48.0}
{"epoch": 19, "training_loss": 0.7156793236732483, "training_acc": 45.0, "val_loss": 0.6923516011238098, "val_acc": 52.0}
{"epoch": 20, "training_loss": 0.6991362333297729, "training_acc": 43.0, "val_loss": 0.6931248664855957, "val_acc": 52.0}
{"epoch": 21, "training_loss": 0.7054748916625977, "training_acc": 53.0, "val_loss": 0.6941765522956849, "val_acc": 52.0}
{"epoch": 22, "training_loss": 0.6955278587341308, "training_acc": 53.0, "val_loss": 0.6940234875679017, "val_acc": 52.0}
{"epoch": 23, "training_loss": 0.6954155945777893, "training_acc": 53.0, "val_loss": 0.6927741765975952, "val_acc": 52.0}
{"epoch": 24, "training_loss": 0.7090757536888123, "training_acc": 53.0, "val_loss": 0.6925565314292907, "val_acc": 52.0}
{"epoch": 25, "training_loss": 0.7128535413742065, "training_acc": 43.0, "val_loss": 0.6944670748710632, "val_acc": 48.0}
{"epoch": 26, "training_loss": 0.6906521391868591, "training_acc": 55.0, "val_loss": 0.6994546055793762, "val_acc": 52.0}
{"epoch": 27, "training_loss": 0.7102224826812744, "training_acc": 41.0, "val_loss": 0.6930046057701111, "val_acc": 52.0}
{"epoch": 28, "training_loss": 0.6973739123344421, "training_acc": 53.0, "val_loss": 0.6996811723709107, "val_acc": 52.0}
{"epoch": 29, "training_loss": 0.7019480752944947, "training_acc": 53.0, "val_loss": 0.6930295109748841, "val_acc": 52.0}
{"epoch": 30, "training_loss": 0.7054166340827942, "training_acc": 45.0, "val_loss": 0.6927070355415345, "val_acc": 52.0}
{"epoch": 31, "training_loss": 0.6935640573501587, "training_acc": 45.0, "val_loss": 0.6982667636871338, "val_acc": 52.0}
{"epoch": 32, "training_loss": 0.6940194988250732, "training_acc": 53.0, "val_loss": 0.6923930883407593, "val_acc": 52.0}
{"epoch": 33, "training_loss": 0.7163702082633973, "training_acc": 39.0, "val_loss": 0.6924537014961243, "val_acc": 52.0}
{"epoch": 34, "training_loss": 0.7077155447006226, "training_acc": 53.0, "val_loss": 0.70085622549057, "val_acc": 52.0}
{"epoch": 35, "training_loss": 0.7022591233253479, "training_acc": 53.0, "val_loss": 0.6923534536361694, "val_acc": 52.0}
{"epoch": 36, "training_loss": 0.6932597279548645, "training_acc": 51.0, "val_loss": 0.6971111917495727, "val_acc": 48.0}
{"epoch": 37, "training_loss": 0.7016567277908325, "training_acc": 47.0, "val_loss": 0.6926382541656494, "val_acc": 52.0}
{"epoch": 38, "training_loss": 0.6954317378997803, "training_acc": 53.0, "val_loss": 0.695241596698761, "val_acc": 52.0}
