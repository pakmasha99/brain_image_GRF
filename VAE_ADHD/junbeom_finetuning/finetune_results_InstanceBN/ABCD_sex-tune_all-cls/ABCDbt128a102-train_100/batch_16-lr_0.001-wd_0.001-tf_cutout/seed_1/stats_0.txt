"main_modify.py --pretrained_path /scratch/connectome/dyhan316/VAE_ADHD/barlowtwins/pretrain_results/ABCDbt128a102.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 1 --task ABCD_sex --input_option BT_org --learning_rate 1e-3 --batch_size 16 --weight_decay 1e-3 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 0.7137270545959473, "training_acc": 50.0, "val_loss": 0.7039021706581116, "val_acc": 52.0}
{"epoch": 1, "training_loss": 0.7164991974830628, "training_acc": 53.0, "val_loss": 0.7070869159698486, "val_acc": 52.0}
{"epoch": 2, "training_loss": 0.7025199222564698, "training_acc": 53.0, "val_loss": 0.6945156979560853, "val_acc": 52.0}
{"epoch": 3, "training_loss": 0.7050681257247925, "training_acc": 41.0, "val_loss": 0.6925620055198669, "val_acc": 52.0}
{"epoch": 4, "training_loss": 0.6970781326293946, "training_acc": 45.0, "val_loss": 0.6969912600517273, "val_acc": 52.0}
{"epoch": 5, "training_loss": 0.7130432367324829, "training_acc": 53.0, "val_loss": 0.7013267016410828, "val_acc": 52.0}
{"epoch": 6, "training_loss": 0.699615592956543, "training_acc": 49.0, "val_loss": 0.6950024342536927, "val_acc": 48.0}
{"epoch": 7, "training_loss": 0.7031945610046386, "training_acc": 47.0, "val_loss": 0.6923561525344849, "val_acc": 52.0}
{"epoch": 8, "training_loss": 0.6937113881111145, "training_acc": 53.0, "val_loss": 0.6946761441230774, "val_acc": 52.0}
{"epoch": 9, "training_loss": 0.6984661555290222, "training_acc": 53.0, "val_loss": 0.6925456261634827, "val_acc": 52.0}
{"epoch": 10, "training_loss": 0.7054383969306945, "training_acc": 43.0, "val_loss": 0.6923549818992615, "val_acc": 52.0}
{"epoch": 11, "training_loss": 0.6943022632598876, "training_acc": 53.0, "val_loss": 0.6973057746887207, "val_acc": 52.0}
{"epoch": 12, "training_loss": 0.6984686827659607, "training_acc": 53.0, "val_loss": 0.6935786700248718, "val_acc": 52.0}
{"epoch": 13, "training_loss": 0.6960818433761596, "training_acc": 53.0, "val_loss": 0.6951615905761719, "val_acc": 48.0}
{"epoch": 14, "training_loss": 0.711253309249878, "training_acc": 47.0, "val_loss": 0.6930393290519714, "val_acc": 52.0}
{"epoch": 15, "training_loss": 0.7218614435195922, "training_acc": 53.0, "val_loss": 0.6927820992469788, "val_acc": 52.0}
{"epoch": 16, "training_loss": 0.6957336616516113, "training_acc": 45.0, "val_loss": 0.6926024985313416, "val_acc": 52.0}
{"epoch": 17, "training_loss": 0.6932123994827271, "training_acc": 53.0, "val_loss": 0.6934214186668396, "val_acc": 52.0}
{"epoch": 18, "training_loss": 0.6969509649276734, "training_acc": 49.0, "val_loss": 0.693356204032898, "val_acc": 48.0}
{"epoch": 19, "training_loss": 0.6893409395217895, "training_acc": 55.0, "val_loss": 0.6998148274421692, "val_acc": 52.0}
{"epoch": 20, "training_loss": 0.705705885887146, "training_acc": 53.0, "val_loss": 0.6925532937049865, "val_acc": 52.0}
{"epoch": 21, "training_loss": 0.693485746383667, "training_acc": 53.0, "val_loss": 0.6982577872276307, "val_acc": 52.0}
{"epoch": 22, "training_loss": 0.7054465675354004, "training_acc": 53.0, "val_loss": 0.6937030053138733, "val_acc": 52.0}
{"epoch": 23, "training_loss": 0.6972276592254638, "training_acc": 53.0, "val_loss": 0.7004376363754272, "val_acc": 48.0}
{"epoch": 24, "training_loss": 0.7055331087112426, "training_acc": 49.0, "val_loss": 0.6960928440093994, "val_acc": 52.0}
{"epoch": 25, "training_loss": 0.7008875131607055, "training_acc": 53.0, "val_loss": 0.7132196617126465, "val_acc": 52.0}
{"epoch": 26, "training_loss": 0.706633198261261, "training_acc": 53.0, "val_loss": 0.6923475217819214, "val_acc": 52.0}
{"epoch": 27, "training_loss": 0.7055088376998901, "training_acc": 53.0, "val_loss": 0.6927739429473877, "val_acc": 52.0}
{"epoch": 28, "training_loss": 0.7232940125465394, "training_acc": 43.0, "val_loss": 0.6979888081550598, "val_acc": 48.0}
{"epoch": 29, "training_loss": 0.717021336555481, "training_acc": 47.0, "val_loss": 0.7025367856025696, "val_acc": 52.0}
{"epoch": 30, "training_loss": 0.6907380294799804, "training_acc": 53.0, "val_loss": 0.6939820957183838, "val_acc": 48.0}
{"epoch": 31, "training_loss": 0.7012331295013428, "training_acc": 41.0, "val_loss": 0.6928382444381714, "val_acc": 52.0}
{"epoch": 32, "training_loss": 0.6959622812271118, "training_acc": 43.0, "val_loss": 0.6939027523994445, "val_acc": 52.0}
{"epoch": 33, "training_loss": 0.7039262771606445, "training_acc": 53.0, "val_loss": 0.6975998663902283, "val_acc": 52.0}
{"epoch": 34, "training_loss": 0.7033088302612305, "training_acc": 53.0, "val_loss": 0.6955184888839722, "val_acc": 52.0}
{"epoch": 35, "training_loss": 0.7014150142669677, "training_acc": 45.0, "val_loss": 0.6975827407836914, "val_acc": 48.0}
{"epoch": 36, "training_loss": 0.7017187547683715, "training_acc": 45.0, "val_loss": 0.6926771545410156, "val_acc": 52.0}
{"epoch": 37, "training_loss": 0.6985142707824707, "training_acc": 45.0, "val_loss": 0.6934879374504089, "val_acc": 48.0}
{"epoch": 38, "training_loss": 0.6948090434074402, "training_acc": 53.0, "val_loss": 0.6964724373817444, "val_acc": 52.0}
{"epoch": 39, "training_loss": 0.6922938394546508, "training_acc": 53.0, "val_loss": 0.692366919517517, "val_acc": 52.0}
{"epoch": 40, "training_loss": 0.6970849823951721, "training_acc": 43.0, "val_loss": 0.6929609942436218, "val_acc": 52.0}
{"epoch": 41, "training_loss": 0.6951194024085998, "training_acc": 49.0, "val_loss": 0.6923739957809448, "val_acc": 52.0}
{"epoch": 42, "training_loss": 0.69419273853302, "training_acc": 53.0, "val_loss": 0.6939587020874023, "val_acc": 52.0}
{"epoch": 43, "training_loss": 0.702142105102539, "training_acc": 47.0, "val_loss": 0.6923486828804016, "val_acc": 52.0}
{"epoch": 44, "training_loss": 0.6910461854934692, "training_acc": 53.0, "val_loss": 0.6988783383369446, "val_acc": 52.0}
{"epoch": 45, "training_loss": 0.7001404857635498, "training_acc": 53.0, "val_loss": 0.6931578874588012, "val_acc": 52.0}
