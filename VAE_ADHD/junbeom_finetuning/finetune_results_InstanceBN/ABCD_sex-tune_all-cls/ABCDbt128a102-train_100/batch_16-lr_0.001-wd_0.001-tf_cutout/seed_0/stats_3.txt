"main_modify.py --pretrained_path /scratch/connectome/dyhan316/VAE_ADHD/barlowtwins/pretrain_results/ABCDbt128a102.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option BT_org --learning_rate 1e-3 --batch_size 16 --weight_decay 1e-3 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 0.7111752653121948, "training_acc": 43.0, "val_loss": 0.6927869296073914, "val_acc": 52.0}
{"epoch": 1, "training_loss": 0.7313452100753784, "training_acc": 53.0, "val_loss": 0.6931261467933655, "val_acc": 52.0}
{"epoch": 2, "training_loss": 0.6982800030708313, "training_acc": 47.0, "val_loss": 0.6925318622589112, "val_acc": 52.0}
{"epoch": 3, "training_loss": 0.7004853010177612, "training_acc": 53.0, "val_loss": 0.6937433338165283, "val_acc": 52.0}
{"epoch": 4, "training_loss": 0.6947395372390747, "training_acc": 53.0, "val_loss": 0.6925542688369751, "val_acc": 52.0}
{"epoch": 5, "training_loss": 0.6982929801940918, "training_acc": 53.0, "val_loss": 0.6924533534049988, "val_acc": 52.0}
{"epoch": 6, "training_loss": 0.6987058639526367, "training_acc": 43.0, "val_loss": 0.6962418866157531, "val_acc": 52.0}
{"epoch": 7, "training_loss": 0.7000607204437256, "training_acc": 53.0, "val_loss": 0.6975282740592956, "val_acc": 52.0}
{"epoch": 8, "training_loss": 0.6970844340324401, "training_acc": 53.0, "val_loss": 0.6925475859642028, "val_acc": 52.0}
{"epoch": 9, "training_loss": 0.6954851722717286, "training_acc": 51.0, "val_loss": 0.6923444032669067, "val_acc": 52.0}
{"epoch": 10, "training_loss": 0.7067012166976929, "training_acc": 53.0, "val_loss": 0.6929304051399231, "val_acc": 52.0}
{"epoch": 11, "training_loss": 0.6959228157997132, "training_acc": 53.0, "val_loss": 0.6929522633552552, "val_acc": 52.0}
{"epoch": 12, "training_loss": 0.6950658893585205, "training_acc": 53.0, "val_loss": 0.6932221126556396, "val_acc": 48.0}
{"epoch": 13, "training_loss": 0.6964526987075805, "training_acc": 45.0, "val_loss": 0.6926404881477356, "val_acc": 52.0}
{"epoch": 14, "training_loss": 0.7223861408233643, "training_acc": 43.0, "val_loss": 0.692569899559021, "val_acc": 52.0}
{"epoch": 15, "training_loss": 0.6942414236068726, "training_acc": 53.0, "val_loss": 0.7116306281089783, "val_acc": 52.0}
{"epoch": 16, "training_loss": 0.6940433597564697, "training_acc": 51.0, "val_loss": 0.6932227444648743, "val_acc": 48.0}
{"epoch": 17, "training_loss": 0.703706636428833, "training_acc": 49.0, "val_loss": 0.6925825762748719, "val_acc": 52.0}
{"epoch": 18, "training_loss": 0.6920897817611694, "training_acc": 53.0, "val_loss": 0.6926570844650268, "val_acc": 52.0}
{"epoch": 19, "training_loss": 0.6968553543090821, "training_acc": 45.0, "val_loss": 0.6923468089103699, "val_acc": 52.0}
{"epoch": 20, "training_loss": 0.6958529210090637, "training_acc": 53.0, "val_loss": 0.6964879608154297, "val_acc": 52.0}
{"epoch": 21, "training_loss": 0.693991928100586, "training_acc": 53.0, "val_loss": 0.6923638653755187, "val_acc": 52.0}
{"epoch": 22, "training_loss": 0.6938944721221924, "training_acc": 49.0, "val_loss": 0.6935441517829894, "val_acc": 52.0}
{"epoch": 23, "training_loss": 0.7071168184280395, "training_acc": 53.0, "val_loss": 0.7001783156394958, "val_acc": 52.0}
{"epoch": 24, "training_loss": 0.699213707447052, "training_acc": 53.0, "val_loss": 0.6978900837898254, "val_acc": 48.0}
{"epoch": 25, "training_loss": 0.7268581485748291, "training_acc": 47.0, "val_loss": 0.7010142517089843, "val_acc": 48.0}
{"epoch": 26, "training_loss": 0.7008945107460022, "training_acc": 49.0, "val_loss": 0.6961325383186341, "val_acc": 52.0}
{"epoch": 27, "training_loss": 0.6968565249443054, "training_acc": 53.0, "val_loss": 0.692988395690918, "val_acc": 52.0}
{"epoch": 28, "training_loss": 0.6967372989654541, "training_acc": 45.0, "val_loss": 0.6930433011054993, "val_acc": 52.0}
