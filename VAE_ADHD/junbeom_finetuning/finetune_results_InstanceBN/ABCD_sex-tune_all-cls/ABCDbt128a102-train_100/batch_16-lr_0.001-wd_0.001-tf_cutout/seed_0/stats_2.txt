"main_modify.py --pretrained_path /scratch/connectome/dyhan316/VAE_ADHD/barlowtwins/pretrain_results/ABCDbt128a102.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option BT_org --learning_rate 1e-3 --batch_size 16 --weight_decay 1e-3 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 0.736374158859253, "training_acc": 45.0, "val_loss": 0.6998270773887634, "val_acc": 52.0}
{"epoch": 1, "training_loss": 0.7199195575714111, "training_acc": 53.0, "val_loss": 0.6959441542625427, "val_acc": 52.0}
{"epoch": 2, "training_loss": 0.6958187222480774, "training_acc": 53.0, "val_loss": 0.6943339991569519, "val_acc": 48.0}
{"epoch": 3, "training_loss": 0.698163251876831, "training_acc": 47.0, "val_loss": 0.6927784776687622, "val_acc": 52.0}
{"epoch": 4, "training_loss": 0.6959464645385742, "training_acc": 53.0, "val_loss": 0.6933727312088013, "val_acc": 52.0}
{"epoch": 5, "training_loss": 0.7033337068557739, "training_acc": 53.0, "val_loss": 0.6945176386833191, "val_acc": 52.0}
{"epoch": 6, "training_loss": 0.715886435508728, "training_acc": 43.0, "val_loss": 0.6940489363670349, "val_acc": 52.0}
{"epoch": 7, "training_loss": 0.6972659683227539, "training_acc": 53.0, "val_loss": 0.7053581738471985, "val_acc": 52.0}
{"epoch": 8, "training_loss": 0.7000388813018799, "training_acc": 53.0, "val_loss": 0.6930172634124756, "val_acc": 52.0}
{"epoch": 9, "training_loss": 0.6920868158340454, "training_acc": 53.0, "val_loss": 0.6936705899238587, "val_acc": 48.0}
{"epoch": 10, "training_loss": 0.7033208513259888, "training_acc": 47.0, "val_loss": 0.6945312237739563, "val_acc": 48.0}
{"epoch": 11, "training_loss": 0.6950812363624572, "training_acc": 51.0, "val_loss": 0.7013319563865662, "val_acc": 52.0}
{"epoch": 12, "training_loss": 0.7015714406967163, "training_acc": 53.0, "val_loss": 0.6930360150337219, "val_acc": 52.0}
{"epoch": 13, "training_loss": 0.6950213956832886, "training_acc": 47.0, "val_loss": 0.6924759411811828, "val_acc": 52.0}
{"epoch": 14, "training_loss": 0.6942140769958496, "training_acc": 53.0, "val_loss": 0.6923727345466614, "val_acc": 52.0}
{"epoch": 15, "training_loss": 0.7160806894302368, "training_acc": 49.0, "val_loss": 0.6940113782882691, "val_acc": 48.0}
{"epoch": 16, "training_loss": 0.7193465566635132, "training_acc": 49.0, "val_loss": 0.704917242527008, "val_acc": 52.0}
{"epoch": 17, "training_loss": 0.6979064965248107, "training_acc": 49.0, "val_loss": 0.6927909898757935, "val_acc": 52.0}
{"epoch": 18, "training_loss": 0.6955076837539673, "training_acc": 53.0, "val_loss": 0.693257954120636, "val_acc": 52.0}
{"epoch": 19, "training_loss": 0.6941351509094238, "training_acc": 53.0, "val_loss": 0.6933923864364624, "val_acc": 52.0}
{"epoch": 20, "training_loss": 0.6925274443626404, "training_acc": 53.0, "val_loss": 0.696027615070343, "val_acc": 52.0}
{"epoch": 21, "training_loss": 0.6949241924285888, "training_acc": 53.0, "val_loss": 0.6959400010108948, "val_acc": 48.0}
{"epoch": 22, "training_loss": 0.7037905049324036, "training_acc": 47.0, "val_loss": 0.6959888482093811, "val_acc": 48.0}
{"epoch": 23, "training_loss": 0.6954687070846558, "training_acc": 49.0, "val_loss": 0.6955142569541931, "val_acc": 52.0}
{"epoch": 24, "training_loss": 0.7046527695655823, "training_acc": 53.0, "val_loss": 0.6992273449897766, "val_acc": 52.0}
{"epoch": 25, "training_loss": 0.6919789361953735, "training_acc": 53.0, "val_loss": 0.6957392907142639, "val_acc": 48.0}
{"epoch": 26, "training_loss": 0.6970683646202087, "training_acc": 45.0, "val_loss": 0.6924297022819519, "val_acc": 52.0}
{"epoch": 27, "training_loss": 0.6982983303070068, "training_acc": 43.0, "val_loss": 0.6934425473213196, "val_acc": 52.0}
{"epoch": 28, "training_loss": 0.6965762042999267, "training_acc": 53.0, "val_loss": 0.6950760769844055, "val_acc": 52.0}
{"epoch": 29, "training_loss": 0.6940042734146118, "training_acc": 53.0, "val_loss": 0.6924745535850525, "val_acc": 52.0}
{"epoch": 30, "training_loss": 0.6985498118400574, "training_acc": 41.0, "val_loss": 0.6937005162239075, "val_acc": 48.0}
{"epoch": 31, "training_loss": 0.6987969374656677, "training_acc": 55.0, "val_loss": 0.7006879281997681, "val_acc": 52.0}
{"epoch": 32, "training_loss": 0.7021854639053344, "training_acc": 53.0, "val_loss": 0.6926380491256714, "val_acc": 52.0}
{"epoch": 33, "training_loss": 0.6949835395812989, "training_acc": 49.0, "val_loss": 0.6928092885017395, "val_acc": 52.0}
