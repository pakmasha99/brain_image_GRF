"main_modify.py --pretrained_path /scratch/connectome/dyhan316/VAE_ADHD/barlowtwins/pretrain_results/ABCDbt128a102.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option BT_org --learning_rate 1e-3 --batch_size 16 --weight_decay 1e-3 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 0.7071920394897461, "training_acc": 45.0, "val_loss": 0.6998200917243957, "val_acc": 44.0}
{"epoch": 1, "training_loss": 0.7010155129432678, "training_acc": 48.0, "val_loss": 0.6890415978431702, "val_acc": 56.0}
{"epoch": 2, "training_loss": 0.7004696559906006, "training_acc": 42.0, "val_loss": 0.6865969967842102, "val_acc": 56.0}
{"epoch": 3, "training_loss": 0.7035699939727783, "training_acc": 52.0, "val_loss": 0.6876868748664856, "val_acc": 56.0}
{"epoch": 4, "training_loss": 0.7075888466835022, "training_acc": 42.0, "val_loss": 0.6909580206871033, "val_acc": 56.0}
{"epoch": 5, "training_loss": 0.6985867881774902, "training_acc": 52.0, "val_loss": 0.6861914706230163, "val_acc": 56.0}
{"epoch": 6, "training_loss": 0.6999948120117188, "training_acc": 40.0, "val_loss": 0.6916030478477478, "val_acc": 56.0}
{"epoch": 7, "training_loss": 0.6981865882873535, "training_acc": 42.0, "val_loss": 0.6876415348052979, "val_acc": 56.0}
{"epoch": 8, "training_loss": 0.7107880640029908, "training_acc": 52.0, "val_loss": 0.6881496143341065, "val_acc": 56.0}
{"epoch": 9, "training_loss": 0.7099403786659241, "training_acc": 44.0, "val_loss": 0.704404890537262, "val_acc": 44.0}
{"epoch": 10, "training_loss": 0.7076742935180664, "training_acc": 48.0, "val_loss": 0.6946921110153198, "val_acc": 44.0}
{"epoch": 11, "training_loss": 0.6945003414154053, "training_acc": 52.0, "val_loss": 0.6889781403541565, "val_acc": 56.0}
{"epoch": 12, "training_loss": 0.7296688723564148, "training_acc": 52.0, "val_loss": 0.6865453743934631, "val_acc": 56.0}
{"epoch": 13, "training_loss": 0.7110940551757813, "training_acc": 44.0, "val_loss": 0.6971059966087342, "val_acc": 44.0}
{"epoch": 14, "training_loss": 0.6965237045288086, "training_acc": 48.0, "val_loss": 0.6864218068122864, "val_acc": 56.0}
{"epoch": 15, "training_loss": 0.6970063734054566, "training_acc": 46.0, "val_loss": 0.6866852235794068, "val_acc": 56.0}
{"epoch": 16, "training_loss": 0.7112475895881653, "training_acc": 52.0, "val_loss": 0.6860642194747925, "val_acc": 56.0}
{"epoch": 17, "training_loss": 0.7002482151985169, "training_acc": 50.0, "val_loss": 0.7063177871704102, "val_acc": 44.0}
{"epoch": 18, "training_loss": 0.7006334781646728, "training_acc": 46.0, "val_loss": 0.6946902966499329, "val_acc": 44.0}
{"epoch": 19, "training_loss": 0.7024714279174805, "training_acc": 48.0, "val_loss": 0.688696711063385, "val_acc": 56.0}
{"epoch": 20, "training_loss": 0.6963514018058777, "training_acc": 52.0, "val_loss": 0.6859837889671325, "val_acc": 56.0}
{"epoch": 21, "training_loss": 0.7016707324981689, "training_acc": 44.0, "val_loss": 0.693227002620697, "val_acc": 44.0}
{"epoch": 22, "training_loss": 0.7036981773376465, "training_acc": 50.0, "val_loss": 0.688128674030304, "val_acc": 56.0}
{"epoch": 23, "training_loss": 0.6920619702339172, "training_acc": 52.0, "val_loss": 0.6972963833808898, "val_acc": 44.0}
{"epoch": 24, "training_loss": 0.706864275932312, "training_acc": 48.0, "val_loss": 0.6873471403121948, "val_acc": 56.0}
{"epoch": 25, "training_loss": 0.6968042039871216, "training_acc": 48.0, "val_loss": 0.7025849461555481, "val_acc": 44.0}
{"epoch": 26, "training_loss": 0.7165433382987976, "training_acc": 44.0, "val_loss": 0.6896305966377259, "val_acc": 56.0}
{"epoch": 27, "training_loss": 0.6972657728195191, "training_acc": 48.0, "val_loss": 0.6978314280509949, "val_acc": 44.0}
{"epoch": 28, "training_loss": 0.7000418043136597, "training_acc": 38.0, "val_loss": 0.6863181948661804, "val_acc": 56.0}
{"epoch": 29, "training_loss": 0.7009154510498047, "training_acc": 52.0, "val_loss": 0.685951361656189, "val_acc": 56.0}
{"epoch": 30, "training_loss": 0.7174328947067261, "training_acc": 52.0, "val_loss": 0.6859320759773254, "val_acc": 56.0}
{"epoch": 31, "training_loss": 0.7066252207756043, "training_acc": 46.0, "val_loss": 0.6907625722885132, "val_acc": 56.0}
{"epoch": 32, "training_loss": 0.7066157937049866, "training_acc": 52.0, "val_loss": 0.6896106576919556, "val_acc": 56.0}
{"epoch": 33, "training_loss": 0.702931034564972, "training_acc": 52.0, "val_loss": 0.6957220244407654, "val_acc": 44.0}
{"epoch": 34, "training_loss": 0.7022006583213806, "training_acc": 48.0, "val_loss": 0.7027368521690369, "val_acc": 44.0}
{"epoch": 35, "training_loss": 0.6965752005577087, "training_acc": 50.0, "val_loss": 0.687242157459259, "val_acc": 56.0}
{"epoch": 36, "training_loss": 0.7022180938720703, "training_acc": 52.0, "val_loss": 0.6860240650177002, "val_acc": 56.0}
{"epoch": 37, "training_loss": 0.7016933965682983, "training_acc": 52.0, "val_loss": 0.6905221128463745, "val_acc": 56.0}
{"epoch": 38, "training_loss": 0.7048984026908874, "training_acc": 44.0, "val_loss": 0.6940605545043945, "val_acc": 44.0}
{"epoch": 39, "training_loss": 0.6964544463157654, "training_acc": 50.0, "val_loss": 0.6894413828849792, "val_acc": 56.0}
{"epoch": 40, "training_loss": 0.7053959918022156, "training_acc": 46.0, "val_loss": 0.690337061882019, "val_acc": 56.0}
{"epoch": 41, "training_loss": 0.6927977132797242, "training_acc": 52.0, "val_loss": 0.685932343006134, "val_acc": 56.0}
{"epoch": 42, "training_loss": 0.6916248273849487, "training_acc": 52.0, "val_loss": 0.7007711553573608, "val_acc": 44.0}
{"epoch": 43, "training_loss": 0.7060073518753052, "training_acc": 40.0, "val_loss": 0.6920005464553833, "val_acc": 56.0}
{"epoch": 44, "training_loss": 0.704595468044281, "training_acc": 46.0, "val_loss": 0.6953377294540405, "val_acc": 44.0}
{"epoch": 45, "training_loss": 0.6966369199752808, "training_acc": 52.0, "val_loss": 0.6861425399780273, "val_acc": 56.0}
{"epoch": 46, "training_loss": 0.6943797588348388, "training_acc": 50.0, "val_loss": 0.6913130235671997, "val_acc": 56.0}
{"epoch": 47, "training_loss": 0.6980578804016113, "training_acc": 52.0, "val_loss": 0.6877508664131164, "val_acc": 56.0}
{"epoch": 48, "training_loss": 0.6970861697196961, "training_acc": 52.0, "val_loss": 0.6938709712028504, "val_acc": 44.0}
{"epoch": 49, "training_loss": 0.6958177995681762, "training_acc": 48.0, "val_loss": 0.7043515110015869, "val_acc": 44.0}
