"main_modify.py --pretrained_path /scratch/connectome/dyhan316/VAE_ADHD/barlowtwins/pretrain_results/ABCDbt128a102.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option BT_org --learning_rate 1e-3 --batch_size 16 --weight_decay 1e-3 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 0.7070153617858886, "training_acc": 56.0, "val_loss": 0.6928203630447388, "val_acc": 52.0}
{"epoch": 1, "training_loss": 0.7062566399574279, "training_acc": 49.0, "val_loss": 0.7049325513839722, "val_acc": 48.0}
{"epoch": 2, "training_loss": 0.7062073969841003, "training_acc": 49.0, "val_loss": 0.6924291706085205, "val_acc": 52.0}
{"epoch": 3, "training_loss": 0.6923251390457154, "training_acc": 53.0, "val_loss": 0.6973767971992493, "val_acc": 48.0}
{"epoch": 4, "training_loss": 0.7014350652694702, "training_acc": 47.0, "val_loss": 0.6923511624336243, "val_acc": 52.0}
{"epoch": 5, "training_loss": 0.6964893579483032, "training_acc": 53.0, "val_loss": 0.7001392459869384, "val_acc": 52.0}
{"epoch": 6, "training_loss": 0.6964259243011475, "training_acc": 49.0, "val_loss": 0.6930701756477355, "val_acc": 52.0}
{"epoch": 7, "training_loss": 0.6996141576766968, "training_acc": 45.0, "val_loss": 0.6929051017761231, "val_acc": 52.0}
{"epoch": 8, "training_loss": 0.693122341632843, "training_acc": 53.0, "val_loss": 0.6931932091712951, "val_acc": 52.0}
{"epoch": 9, "training_loss": 0.6974412870407104, "training_acc": 53.0, "val_loss": 0.6923429179191589, "val_acc": 52.0}
{"epoch": 10, "training_loss": 0.695590033531189, "training_acc": 53.0, "val_loss": 0.694423279762268, "val_acc": 52.0}
{"epoch": 11, "training_loss": 0.6949354553222656, "training_acc": 53.0, "val_loss": 0.6927147197723389, "val_acc": 52.0}
{"epoch": 12, "training_loss": 0.6943963813781738, "training_acc": 53.0, "val_loss": 0.6935977387428284, "val_acc": 52.0}
{"epoch": 13, "training_loss": 0.6962088632583618, "training_acc": 53.0, "val_loss": 0.6926954030990601, "val_acc": 52.0}
{"epoch": 14, "training_loss": 0.6960747981071472, "training_acc": 47.0, "val_loss": 0.6954555058479309, "val_acc": 48.0}
{"epoch": 15, "training_loss": 0.7034496784210205, "training_acc": 49.0, "val_loss": 0.7059851932525635, "val_acc": 52.0}
{"epoch": 16, "training_loss": 0.7376653409004211, "training_acc": 53.0, "val_loss": 0.6992710256576538, "val_acc": 52.0}
{"epoch": 17, "training_loss": 0.6913606762886048, "training_acc": 53.0, "val_loss": 0.6985328412055969, "val_acc": 48.0}
{"epoch": 18, "training_loss": 0.7203280830383301, "training_acc": 47.0, "val_loss": 0.6935657477378845, "val_acc": 48.0}
{"epoch": 19, "training_loss": 0.7126749730110169, "training_acc": 49.0, "val_loss": 0.7167929816246033, "val_acc": 52.0}
{"epoch": 20, "training_loss": 0.7126455044746399, "training_acc": 53.0, "val_loss": 0.6927267837524415, "val_acc": 52.0}
{"epoch": 21, "training_loss": 0.6953623342514038, "training_acc": 53.0, "val_loss": 0.6923578763008118, "val_acc": 52.0}
{"epoch": 22, "training_loss": 0.693581874370575, "training_acc": 53.0, "val_loss": 0.6931315350532532, "val_acc": 52.0}
{"epoch": 23, "training_loss": 0.69740816116333, "training_acc": 53.0, "val_loss": 0.6956330490112305, "val_acc": 52.0}
{"epoch": 24, "training_loss": 0.7155909514427186, "training_acc": 53.0, "val_loss": 0.6923603534698486, "val_acc": 52.0}
{"epoch": 25, "training_loss": 0.715593159198761, "training_acc": 47.0, "val_loss": 0.7019817328453064, "val_acc": 48.0}
{"epoch": 26, "training_loss": 0.6954355573654175, "training_acc": 53.0, "val_loss": 0.7107377147674561, "val_acc": 52.0}
{"epoch": 27, "training_loss": 0.7014520263671875, "training_acc": 53.0, "val_loss": 0.6923699879646301, "val_acc": 52.0}
{"epoch": 28, "training_loss": 0.7088982200622559, "training_acc": 49.0, "val_loss": 0.6947628140449524, "val_acc": 48.0}
