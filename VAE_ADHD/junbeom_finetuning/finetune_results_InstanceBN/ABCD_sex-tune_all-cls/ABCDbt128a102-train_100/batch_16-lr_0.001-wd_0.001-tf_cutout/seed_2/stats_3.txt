"main_modify.py --pretrained_path /scratch/connectome/dyhan316/VAE_ADHD/barlowtwins/pretrain_results/ABCDbt128a102.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 2 --task ABCD_sex --input_option BT_org --learning_rate 1e-3 --batch_size 16 --weight_decay 1e-3 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 0.708292121887207, "training_acc": 51.0, "val_loss": 0.6923986029624939, "val_acc": 52.0}
{"epoch": 1, "training_loss": 0.7131482577323913, "training_acc": 47.0, "val_loss": 0.706274082660675, "val_acc": 48.0}
{"epoch": 2, "training_loss": 0.7030211520195008, "training_acc": 49.0, "val_loss": 0.6924020671844482, "val_acc": 52.0}
{"epoch": 3, "training_loss": 0.7163643527030945, "training_acc": 53.0, "val_loss": 0.6930582475662231, "val_acc": 52.0}
{"epoch": 4, "training_loss": 0.6953243064880371, "training_acc": 53.0, "val_loss": 0.694261257648468, "val_acc": 48.0}
{"epoch": 5, "training_loss": 0.7011518692970276, "training_acc": 50.0, "val_loss": 0.6930486273765564, "val_acc": 52.0}
{"epoch": 6, "training_loss": 0.6931121230125428, "training_acc": 53.0, "val_loss": 0.6923693943023682, "val_acc": 52.0}
{"epoch": 7, "training_loss": 0.7022529125213623, "training_acc": 49.0, "val_loss": 0.6923332595825196, "val_acc": 52.0}
{"epoch": 8, "training_loss": 0.700295557975769, "training_acc": 53.0, "val_loss": 0.6976114797592163, "val_acc": 52.0}
{"epoch": 9, "training_loss": 0.6963203144073487, "training_acc": 53.0, "val_loss": 0.6924376964569092, "val_acc": 52.0}
{"epoch": 10, "training_loss": 0.6983860492706299, "training_acc": 45.0, "val_loss": 0.6924413537979126, "val_acc": 52.0}
{"epoch": 11, "training_loss": 0.6973361444473266, "training_acc": 53.0, "val_loss": 0.6938556981086731, "val_acc": 52.0}
{"epoch": 12, "training_loss": 0.6965972471237183, "training_acc": 53.0, "val_loss": 0.6932970881462097, "val_acc": 52.0}
{"epoch": 13, "training_loss": 0.6979976677894593, "training_acc": 53.0, "val_loss": 0.7014333653450012, "val_acc": 52.0}
{"epoch": 14, "training_loss": 0.7097789168357849, "training_acc": 53.0, "val_loss": 0.6988418936729431, "val_acc": 52.0}
{"epoch": 15, "training_loss": 0.6897783136367798, "training_acc": 53.0, "val_loss": 0.6970427751541137, "val_acc": 48.0}
{"epoch": 16, "training_loss": 0.7064853358268738, "training_acc": 47.0, "val_loss": 0.6936514091491699, "val_acc": 52.0}
{"epoch": 17, "training_loss": 0.7322063064575195, "training_acc": 53.0, "val_loss": 0.7075129389762879, "val_acc": 52.0}
{"epoch": 18, "training_loss": 0.7140982246398926, "training_acc": 41.0, "val_loss": 0.6943453693389893, "val_acc": 48.0}
{"epoch": 19, "training_loss": 0.7072829532623292, "training_acc": 49.0, "val_loss": 0.6944672083854675, "val_acc": 52.0}
{"epoch": 20, "training_loss": 0.702017240524292, "training_acc": 53.0, "val_loss": 0.7004718136787415, "val_acc": 52.0}
{"epoch": 21, "training_loss": 0.6957201838493348, "training_acc": 53.0, "val_loss": 0.6929930162429809, "val_acc": 52.0}
{"epoch": 22, "training_loss": 0.7050136804580689, "training_acc": 49.0, "val_loss": 0.6972951006889343, "val_acc": 48.0}
{"epoch": 23, "training_loss": 0.6970244169235229, "training_acc": 47.0, "val_loss": 0.6929176449775696, "val_acc": 52.0}
{"epoch": 24, "training_loss": 0.6930308437347412, "training_acc": 53.0, "val_loss": 0.6961365866661072, "val_acc": 52.0}
{"epoch": 25, "training_loss": 0.6971992683410645, "training_acc": 49.0, "val_loss": 0.6924648022651673, "val_acc": 52.0}
{"epoch": 26, "training_loss": 0.6962747859954834, "training_acc": 53.0, "val_loss": 0.6953829860687256, "val_acc": 52.0}
