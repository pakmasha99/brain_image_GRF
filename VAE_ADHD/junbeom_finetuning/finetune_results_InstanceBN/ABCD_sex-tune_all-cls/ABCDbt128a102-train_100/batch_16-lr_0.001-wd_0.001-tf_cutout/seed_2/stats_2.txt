"main_modify.py --pretrained_path /scratch/connectome/dyhan316/VAE_ADHD/barlowtwins/pretrain_results/ABCDbt128a102.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 2 --task ABCD_sex --input_option BT_org --learning_rate 1e-3 --batch_size 16 --weight_decay 1e-3 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 0.6968364381790161, "training_acc": 56.0, "val_loss": 0.7126145529747009, "val_acc": 48.0}
{"epoch": 1, "training_loss": 0.7105991983413696, "training_acc": 43.0, "val_loss": 0.6927724409103394, "val_acc": 52.0}
{"epoch": 2, "training_loss": 0.700477409362793, "training_acc": 53.0, "val_loss": 0.6973529100418091, "val_acc": 52.0}
{"epoch": 3, "training_loss": 0.6971484446525573, "training_acc": 53.0, "val_loss": 0.6981557559967041, "val_acc": 52.0}
{"epoch": 4, "training_loss": 0.7036763143539428, "training_acc": 53.0, "val_loss": 0.6931412148475647, "val_acc": 52.0}
{"epoch": 5, "training_loss": 0.7008039093017578, "training_acc": 45.0, "val_loss": 0.6925454449653625, "val_acc": 52.0}
{"epoch": 6, "training_loss": 0.6996873378753662, "training_acc": 47.0, "val_loss": 0.7065950465202332, "val_acc": 52.0}
{"epoch": 7, "training_loss": 0.7136422538757324, "training_acc": 53.0, "val_loss": 0.7079296207427979, "val_acc": 52.0}
{"epoch": 8, "training_loss": 0.7098827123641968, "training_acc": 53.0, "val_loss": 0.6924507999420166, "val_acc": 52.0}
{"epoch": 9, "training_loss": 0.6941805100440979, "training_acc": 53.0, "val_loss": 0.6958278846740723, "val_acc": 52.0}
{"epoch": 10, "training_loss": 0.6976935625076294, "training_acc": 53.0, "val_loss": 0.692742862701416, "val_acc": 52.0}
{"epoch": 11, "training_loss": 0.6939005613327026, "training_acc": 53.0, "val_loss": 0.7033216857910156, "val_acc": 48.0}
{"epoch": 12, "training_loss": 0.7030401420593262, "training_acc": 47.0, "val_loss": 0.6924287128448486, "val_acc": 52.0}
{"epoch": 13, "training_loss": 0.7091061115264893, "training_acc": 53.0, "val_loss": 0.6932216167449952, "val_acc": 52.0}
{"epoch": 14, "training_loss": 0.6947978067398072, "training_acc": 53.0, "val_loss": 0.6947057843208313, "val_acc": 48.0}
{"epoch": 15, "training_loss": 0.6946123099327087, "training_acc": 51.0, "val_loss": 0.6966569948196412, "val_acc": 52.0}
{"epoch": 16, "training_loss": 0.7065152788162231, "training_acc": 53.0, "val_loss": 0.6930121660232544, "val_acc": 52.0}
{"epoch": 17, "training_loss": 0.7204979801177979, "training_acc": 41.0, "val_loss": 0.6940779066085816, "val_acc": 48.0}
{"epoch": 18, "training_loss": 0.7105945515632629, "training_acc": 45.0, "val_loss": 0.701027648448944, "val_acc": 52.0}
{"epoch": 19, "training_loss": 0.7030322551727295, "training_acc": 53.0, "val_loss": 0.6937032747268677, "val_acc": 52.0}
{"epoch": 20, "training_loss": 0.6965430998802185, "training_acc": 47.0, "val_loss": 0.6993420004844666, "val_acc": 48.0}
{"epoch": 21, "training_loss": 0.7097910666465759, "training_acc": 41.0, "val_loss": 0.6930634832382202, "val_acc": 52.0}
{"epoch": 22, "training_loss": 0.7169069480895996, "training_acc": 45.0, "val_loss": 0.6989859580993653, "val_acc": 48.0}
{"epoch": 23, "training_loss": 0.7043451547622681, "training_acc": 45.0, "val_loss": 0.6928571033477783, "val_acc": 52.0}
{"epoch": 24, "training_loss": 0.7033916139602661, "training_acc": 53.0, "val_loss": 0.6923844575881958, "val_acc": 52.0}
{"epoch": 25, "training_loss": 0.7048249530792237, "training_acc": 39.0, "val_loss": 0.6935531640052796, "val_acc": 48.0}
{"epoch": 26, "training_loss": 0.7011424136161805, "training_acc": 43.0, "val_loss": 0.6941730904579163, "val_acc": 48.0}
{"epoch": 27, "training_loss": 0.6953717207908631, "training_acc": 45.0, "val_loss": 0.6925946164131165, "val_acc": 52.0}
{"epoch": 28, "training_loss": 0.6995609736442566, "training_acc": 53.0, "val_loss": 0.6924281740188598, "val_acc": 52.0}
{"epoch": 29, "training_loss": 0.7160593700408936, "training_acc": 41.0, "val_loss": 0.6933630228042602, "val_acc": 48.0}
{"epoch": 30, "training_loss": 0.697970187664032, "training_acc": 49.0, "val_loss": 0.6939874410629272, "val_acc": 52.0}
{"epoch": 31, "training_loss": 0.6925445961952209, "training_acc": 53.0, "val_loss": 0.6923755121231079, "val_acc": 52.0}
{"epoch": 32, "training_loss": 0.7170039558410645, "training_acc": 41.0, "val_loss": 0.693908314704895, "val_acc": 52.0}
{"epoch": 33, "training_loss": 0.7036681008338929, "training_acc": 53.0, "val_loss": 0.7010209703445435, "val_acc": 52.0}
{"epoch": 34, "training_loss": 0.6961913776397705, "training_acc": 49.0, "val_loss": 0.6930881476402283, "val_acc": 52.0}
{"epoch": 35, "training_loss": 0.6993442821502686, "training_acc": 53.0, "val_loss": 0.7007008695602417, "val_acc": 52.0}
{"epoch": 36, "training_loss": 0.6982792329788208, "training_acc": 53.0, "val_loss": 0.6943768787384034, "val_acc": 52.0}
{"epoch": 37, "training_loss": 0.6952867078781128, "training_acc": 53.0, "val_loss": 0.6924571752548218, "val_acc": 52.0}
{"epoch": 38, "training_loss": 0.6920672988891602, "training_acc": 53.0, "val_loss": 0.6932590866088867, "val_acc": 52.0}
{"epoch": 39, "training_loss": 0.6991545248031616, "training_acc": 53.0, "val_loss": 0.6927762246131897, "val_acc": 52.0}
{"epoch": 40, "training_loss": 0.7075546002388, "training_acc": 53.0, "val_loss": 0.6938869571685791, "val_acc": 48.0}
{"epoch": 41, "training_loss": 0.7388662576675415, "training_acc": 47.0, "val_loss": 0.698500394821167, "val_acc": 48.0}
{"epoch": 42, "training_loss": 0.6988084793090821, "training_acc": 51.0, "val_loss": 0.7080025506019593, "val_acc": 52.0}
{"epoch": 43, "training_loss": 0.7008320045471191, "training_acc": 53.0, "val_loss": 0.6930784273147583, "val_acc": 52.0}
{"epoch": 44, "training_loss": 0.7227030444145203, "training_acc": 41.0, "val_loss": 0.6937865090370178, "val_acc": 48.0}
{"epoch": 45, "training_loss": 0.6973159837722779, "training_acc": 55.0, "val_loss": 0.6955153942108154, "val_acc": 52.0}
{"epoch": 46, "training_loss": 0.6977200746536255, "training_acc": 47.0, "val_loss": 0.6954408669471741, "val_acc": 48.0}
{"epoch": 47, "training_loss": 0.7059536409378052, "training_acc": 51.0, "val_loss": 0.6937212085723877, "val_acc": 52.0}
{"epoch": 48, "training_loss": 0.695381042957306, "training_acc": 51.0, "val_loss": 0.7024346113204956, "val_acc": 48.0}
{"epoch": 49, "training_loss": 0.7056256937980652, "training_acc": 47.0, "val_loss": 0.6923993229866028, "val_acc": 52.0}
{"epoch": 50, "training_loss": 0.7094848847389221, "training_acc": 53.0, "val_loss": 0.7013164305686951, "val_acc": 52.0}
