"main_modify.py --pretrained_path /scratch/connectome/dyhan316/VAE_ADHD/barlowtwins/pretrain_results/ABCDbt128a102.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 2 --task ABCD_sex --input_option BT_org --learning_rate 1e-3 --batch_size 16 --weight_decay 1e-3 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 0.7038403415679931, "training_acc": 47.0, "val_loss": 0.6863438391685486, "val_acc": 56.0}
{"epoch": 1, "training_loss": 0.6951836562156677, "training_acc": 52.0, "val_loss": 0.6885212230682373, "val_acc": 56.0}
{"epoch": 2, "training_loss": 0.7029509472846985, "training_acc": 46.0, "val_loss": 0.6913210177421569, "val_acc": 56.0}
{"epoch": 3, "training_loss": 0.6940689563751221, "training_acc": 48.0, "val_loss": 0.6861458063125611, "val_acc": 56.0}
{"epoch": 4, "training_loss": 0.7179622602462769, "training_acc": 38.0, "val_loss": 0.6859877038002015, "val_acc": 56.0}
{"epoch": 5, "training_loss": 0.7046495532989502, "training_acc": 52.0, "val_loss": 0.686981029510498, "val_acc": 56.0}
{"epoch": 6, "training_loss": 0.7175255680084228, "training_acc": 44.0, "val_loss": 0.7047823762893677, "val_acc": 44.0}
{"epoch": 7, "training_loss": 0.7033311796188354, "training_acc": 46.0, "val_loss": 0.6894799089431762, "val_acc": 56.0}
{"epoch": 8, "training_loss": 0.7149936437606812, "training_acc": 42.0, "val_loss": 0.6939709758758545, "val_acc": 44.0}
{"epoch": 9, "training_loss": 0.694325385093689, "training_acc": 52.0, "val_loss": 0.6861763024330139, "val_acc": 56.0}
{"epoch": 10, "training_loss": 0.6979897117614746, "training_acc": 46.0, "val_loss": 0.695907690525055, "val_acc": 44.0}
{"epoch": 11, "training_loss": 0.7038660979270935, "training_acc": 48.0, "val_loss": 0.6904707956314087, "val_acc": 56.0}
{"epoch": 12, "training_loss": 0.6943232250213623, "training_acc": 44.0, "val_loss": 0.6859378623962402, "val_acc": 56.0}
{"epoch": 13, "training_loss": 0.6980848193168641, "training_acc": 52.0, "val_loss": 0.6860774326324462, "val_acc": 56.0}
{"epoch": 14, "training_loss": 0.7070216751098632, "training_acc": 52.0, "val_loss": 0.6865659666061401, "val_acc": 56.0}
{"epoch": 15, "training_loss": 0.7031433963775635, "training_acc": 46.0, "val_loss": 0.6987696146965027, "val_acc": 44.0}
{"epoch": 16, "training_loss": 0.7113865756988526, "training_acc": 46.0, "val_loss": 0.6860635042190552, "val_acc": 56.0}
{"epoch": 17, "training_loss": 0.6938338851928711, "training_acc": 50.0, "val_loss": 0.692678165435791, "val_acc": 56.0}
{"epoch": 18, "training_loss": 0.6934647655487061, "training_acc": 46.0, "val_loss": 0.6862026953697205, "val_acc": 56.0}
{"epoch": 19, "training_loss": 0.7070791959762573, "training_acc": 52.0, "val_loss": 0.6859293627738953, "val_acc": 56.0}
{"epoch": 20, "training_loss": 0.6963043451309204, "training_acc": 52.0, "val_loss": 0.6982098889350891, "val_acc": 44.0}
{"epoch": 21, "training_loss": 0.696987943649292, "training_acc": 48.0, "val_loss": 0.7140654110908509, "val_acc": 44.0}
{"epoch": 22, "training_loss": 0.6960350060462952, "training_acc": 50.0, "val_loss": 0.6861325907707214, "val_acc": 56.0}
{"epoch": 23, "training_loss": 0.700858850479126, "training_acc": 52.0, "val_loss": 0.6870803236961365, "val_acc": 56.0}
{"epoch": 24, "training_loss": 0.7024868154525756, "training_acc": 38.0, "val_loss": 0.7031878209114075, "val_acc": 44.0}
{"epoch": 25, "training_loss": 0.7109369921684265, "training_acc": 40.0, "val_loss": 0.7060668516159058, "val_acc": 44.0}
{"epoch": 26, "training_loss": 0.7025990009307861, "training_acc": 48.0, "val_loss": 0.7061708736419677, "val_acc": 44.0}
{"epoch": 27, "training_loss": 0.7037902426719665, "training_acc": 52.0, "val_loss": 0.6860100483894348, "val_acc": 56.0}
{"epoch": 28, "training_loss": 0.7154665303230285, "training_acc": 52.0, "val_loss": 0.6860440874099731, "val_acc": 56.0}
{"epoch": 29, "training_loss": 0.7091620063781738, "training_acc": 48.0, "val_loss": 0.7033506441116333, "val_acc": 44.0}
{"epoch": 30, "training_loss": 0.7029658365249634, "training_acc": 46.0, "val_loss": 0.6860765600204468, "val_acc": 56.0}
{"epoch": 31, "training_loss": 0.6954394817352295, "training_acc": 52.0, "val_loss": 0.6974967837333679, "val_acc": 44.0}
{"epoch": 32, "training_loss": 0.7136391544342041, "training_acc": 48.0, "val_loss": 0.6965686631202698, "val_acc": 44.0}
{"epoch": 33, "training_loss": 0.7036166715621949, "training_acc": 48.0, "val_loss": 0.685962688922882, "val_acc": 56.0}
{"epoch": 34, "training_loss": 0.7255348205566406, "training_acc": 52.0, "val_loss": 0.6905849194526672, "val_acc": 56.0}
{"epoch": 35, "training_loss": 0.6983645582199096, "training_acc": 48.0, "val_loss": 0.7019573831558228, "val_acc": 44.0}
{"epoch": 36, "training_loss": 0.7022691535949707, "training_acc": 46.0, "val_loss": 0.6868568968772888, "val_acc": 56.0}
{"epoch": 37, "training_loss": 0.6935700726509094, "training_acc": 52.0, "val_loss": 0.6886131119728088, "val_acc": 56.0}
{"epoch": 38, "training_loss": 0.6979946994781494, "training_acc": 52.0, "val_loss": 0.6866881370544433, "val_acc": 56.0}
