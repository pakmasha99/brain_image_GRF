"main_modify.py --pretrained_path /scratch/connectome/dyhan316/VAE_ADHD/barlowtwins/pretrain_results/ABCDbt128a102.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 2 --task ABCD_sex --input_option BT_org --learning_rate 1e-3 --batch_size 16 --weight_decay 1e-3 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 0.7187715721130371, "training_acc": 50.0, "val_loss": 0.7033497786521912, "val_acc": 52.0}
{"epoch": 1, "training_loss": 0.7085566759109497, "training_acc": 45.0, "val_loss": 0.695933108329773, "val_acc": 48.0}
{"epoch": 2, "training_loss": 0.6996014499664307, "training_acc": 49.0, "val_loss": 0.6959825396537781, "val_acc": 52.0}
{"epoch": 3, "training_loss": 0.6984458971023559, "training_acc": 53.0, "val_loss": 0.703984706401825, "val_acc": 52.0}
{"epoch": 4, "training_loss": 0.6983951854705811, "training_acc": 53.0, "val_loss": 0.6930989837646484, "val_acc": 52.0}
{"epoch": 5, "training_loss": 0.6942579913139343, "training_acc": 53.0, "val_loss": 0.6941344165802001, "val_acc": 48.0}
{"epoch": 6, "training_loss": 0.7114881539344787, "training_acc": 47.0, "val_loss": 0.6924779462814331, "val_acc": 52.0}
{"epoch": 7, "training_loss": 0.7185249638557434, "training_acc": 53.0, "val_loss": 0.7009209156036377, "val_acc": 52.0}
{"epoch": 8, "training_loss": 0.7052535438537597, "training_acc": 45.0, "val_loss": 0.6956693124771118, "val_acc": 48.0}
{"epoch": 9, "training_loss": 0.697540111541748, "training_acc": 47.0, "val_loss": 0.6941887021064759, "val_acc": 52.0}
{"epoch": 10, "training_loss": 0.6955235481262207, "training_acc": 53.0, "val_loss": 0.6925596284866333, "val_acc": 52.0}
{"epoch": 11, "training_loss": 0.6982239437103271, "training_acc": 49.0, "val_loss": 0.6957682037353515, "val_acc": 52.0}
{"epoch": 12, "training_loss": 0.7006755304336548, "training_acc": 53.0, "val_loss": 0.7013992238044738, "val_acc": 52.0}
{"epoch": 13, "training_loss": 0.6994580268859864, "training_acc": 53.0, "val_loss": 0.6928543639183045, "val_acc": 52.0}
{"epoch": 14, "training_loss": 0.6931178903579712, "training_acc": 49.0, "val_loss": 0.692539255619049, "val_acc": 52.0}
{"epoch": 15, "training_loss": 0.6930106019973755, "training_acc": 53.0, "val_loss": 0.695479199886322, "val_acc": 52.0}
{"epoch": 16, "training_loss": 0.6954975843429565, "training_acc": 53.0, "val_loss": 0.692444565296173, "val_acc": 52.0}
{"epoch": 17, "training_loss": 0.6950949454307556, "training_acc": 53.0, "val_loss": 0.6932848238945007, "val_acc": 52.0}
{"epoch": 18, "training_loss": 0.7263943433761597, "training_acc": 53.0, "val_loss": 0.6968850922584534, "val_acc": 52.0}
{"epoch": 19, "training_loss": 0.7017908859252929, "training_acc": 49.0, "val_loss": 0.6945806455612182, "val_acc": 48.0}
{"epoch": 20, "training_loss": 0.6974794292449951, "training_acc": 49.0, "val_loss": 0.6933596467971802, "val_acc": 52.0}
{"epoch": 21, "training_loss": 0.691932156085968, "training_acc": 53.0, "val_loss": 0.6952210736274719, "val_acc": 48.0}
{"epoch": 22, "training_loss": 0.7193702006340027, "training_acc": 47.0, "val_loss": 0.6928635740280151, "val_acc": 52.0}
{"epoch": 23, "training_loss": 0.7104898166656494, "training_acc": 53.0, "val_loss": 0.6990118145942688, "val_acc": 52.0}
{"epoch": 24, "training_loss": 0.6897631502151489, "training_acc": 53.0, "val_loss": 0.6970720314979553, "val_acc": 48.0}
{"epoch": 25, "training_loss": 0.7036078739166259, "training_acc": 47.0, "val_loss": 0.6931350708007813, "val_acc": 52.0}
{"epoch": 26, "training_loss": 0.7002843856811524, "training_acc": 53.0, "val_loss": 0.7135605692863465, "val_acc": 52.0}
{"epoch": 27, "training_loss": 0.7100012063980102, "training_acc": 53.0, "val_loss": 0.6930695509910584, "val_acc": 52.0}
{"epoch": 28, "training_loss": 0.7071850347518921, "training_acc": 53.0, "val_loss": 0.6924153470993042, "val_acc": 52.0}
{"epoch": 29, "training_loss": 0.6993972253799439, "training_acc": 51.0, "val_loss": 0.6986230564117432, "val_acc": 48.0}
{"epoch": 30, "training_loss": 0.7058438444137574, "training_acc": 49.0, "val_loss": 0.69885333776474, "val_acc": 52.0}
{"epoch": 31, "training_loss": 0.7002002310752868, "training_acc": 47.0, "val_loss": 0.6925011134147644, "val_acc": 52.0}
{"epoch": 32, "training_loss": 0.6926150035858154, "training_acc": 53.0, "val_loss": 0.6952508330345154, "val_acc": 52.0}
{"epoch": 33, "training_loss": 0.7003834342956543, "training_acc": 53.0, "val_loss": 0.6972665810585021, "val_acc": 52.0}
{"epoch": 34, "training_loss": 0.699134635925293, "training_acc": 53.0, "val_loss": 0.7053444695472717, "val_acc": 52.0}
{"epoch": 35, "training_loss": 0.6997143340110779, "training_acc": 53.0, "val_loss": 0.6923834085464478, "val_acc": 52.0}
{"epoch": 36, "training_loss": 0.7041657972335815, "training_acc": 39.0, "val_loss": 0.6929333615303039, "val_acc": 52.0}
{"epoch": 37, "training_loss": 0.7026360416412354, "training_acc": 45.0, "val_loss": 0.6928825306892396, "val_acc": 52.0}
{"epoch": 38, "training_loss": 0.6962255096435547, "training_acc": 51.0, "val_loss": 0.6952521419525146, "val_acc": 48.0}
{"epoch": 39, "training_loss": 0.6887012553215027, "training_acc": 55.0, "val_loss": 0.6967294049263001, "val_acc": 52.0}
{"epoch": 40, "training_loss": 0.6967470645904541, "training_acc": 53.0, "val_loss": 0.6924741387367248, "val_acc": 52.0}
{"epoch": 41, "training_loss": 0.6968916606903076, "training_acc": 53.0, "val_loss": 0.6952611899375916, "val_acc": 52.0}
{"epoch": 42, "training_loss": 0.6989348912239075, "training_acc": 49.0, "val_loss": 0.6926938390731812, "val_acc": 52.0}
{"epoch": 43, "training_loss": 0.7003239154815674, "training_acc": 47.0, "val_loss": 0.6969504976272582, "val_acc": 52.0}
{"epoch": 44, "training_loss": 0.6978433799743652, "training_acc": 53.0, "val_loss": 0.6930863881111144, "val_acc": 52.0}
{"epoch": 45, "training_loss": 0.7037077856063843, "training_acc": 47.0, "val_loss": 0.6948878335952758, "val_acc": 48.0}
{"epoch": 46, "training_loss": 0.7022078466415406, "training_acc": 47.0, "val_loss": 0.6975944614410401, "val_acc": 52.0}
{"epoch": 47, "training_loss": 0.6955768442153931, "training_acc": 51.0, "val_loss": 0.6923772931098938, "val_acc": 52.0}
{"epoch": 48, "training_loss": 0.6949225449562073, "training_acc": 53.0, "val_loss": 0.6938635993003845, "val_acc": 52.0}
{"epoch": 49, "training_loss": 0.6959596920013428, "training_acc": 49.0, "val_loss": 0.6937837266921997, "val_acc": 48.0}
{"epoch": 50, "training_loss": 0.6975127410888672, "training_acc": 49.0, "val_loss": 0.6967864799499511, "val_acc": 52.0}
{"epoch": 51, "training_loss": 0.7286293673515319, "training_acc": 53.0, "val_loss": 0.6961657309532165, "val_acc": 52.0}
{"epoch": 52, "training_loss": 0.6931948471069336, "training_acc": 51.0, "val_loss": 0.7049893164634704, "val_acc": 48.0}
{"epoch": 53, "training_loss": 0.7472549438476562, "training_acc": 47.0, "val_loss": 0.692367434501648, "val_acc": 52.0}
{"epoch": 54, "training_loss": 0.7032187581062317, "training_acc": 53.0, "val_loss": 0.7059340214729309, "val_acc": 52.0}
{"epoch": 55, "training_loss": 0.6993698740005493, "training_acc": 53.0, "val_loss": 0.6925803232192993, "val_acc": 52.0}
{"epoch": 56, "training_loss": 0.696668095588684, "training_acc": 47.0, "val_loss": 0.6926501035690308, "val_acc": 52.0}
{"epoch": 57, "training_loss": 0.6976824069023132, "training_acc": 53.0, "val_loss": 0.6939862179756164, "val_acc": 52.0}
{"epoch": 58, "training_loss": 0.6998199224472046, "training_acc": 45.0, "val_loss": 0.6923534011840821, "val_acc": 52.0}
{"epoch": 59, "training_loss": 0.7206821036338806, "training_acc": 53.0, "val_loss": 0.7002327275276184, "val_acc": 52.0}
{"epoch": 60, "training_loss": 0.6972257328033448, "training_acc": 53.0, "val_loss": 0.6928698754310608, "val_acc": 52.0}
{"epoch": 61, "training_loss": 0.7000140190124512, "training_acc": 43.0, "val_loss": 0.6952932810783387, "val_acc": 48.0}
{"epoch": 62, "training_loss": 0.7119702982902527, "training_acc": 43.0, "val_loss": 0.6940320682525635, "val_acc": 48.0}
{"epoch": 63, "training_loss": 0.6949719619750977, "training_acc": 43.0, "val_loss": 0.6923473691940307, "val_acc": 52.0}
{"epoch": 64, "training_loss": 0.7041952395439148, "training_acc": 53.0, "val_loss": 0.6943574213981628, "val_acc": 52.0}
{"epoch": 65, "training_loss": 0.7139580535888672, "training_acc": 49.0, "val_loss": 0.7067566561698914, "val_acc": 48.0}
{"epoch": 66, "training_loss": 0.6989964246749878, "training_acc": 55.0, "val_loss": 0.7152854180335999, "val_acc": 52.0}
{"epoch": 67, "training_loss": 0.7153424072265625, "training_acc": 53.0, "val_loss": 0.6930119705200195, "val_acc": 52.0}
{"epoch": 68, "training_loss": 0.7014073610305787, "training_acc": 49.0, "val_loss": 0.7025949788093567, "val_acc": 48.0}
{"epoch": 69, "training_loss": 0.7002217626571655, "training_acc": 47.0, "val_loss": 0.6937787818908692, "val_acc": 52.0}
{"epoch": 70, "training_loss": 0.6957784414291381, "training_acc": 53.0, "val_loss": 0.6923760509490967, "val_acc": 52.0}
{"epoch": 71, "training_loss": 0.7063741874694824, "training_acc": 53.0, "val_loss": 0.6932435154914856, "val_acc": 52.0}
{"epoch": 72, "training_loss": 0.6938500142097473, "training_acc": 45.0, "val_loss": 0.6980381822586059, "val_acc": 48.0}
{"epoch": 73, "training_loss": 0.7071202039718628, "training_acc": 47.0, "val_loss": 0.6955006814002991, "val_acc": 48.0}
{"epoch": 74, "training_loss": 0.6914391922950744, "training_acc": 51.0, "val_loss": 0.7001547718048096, "val_acc": 52.0}
{"epoch": 75, "training_loss": 0.7078023910522461, "training_acc": 53.0, "val_loss": 0.6965361046791076, "val_acc": 52.0}
{"epoch": 76, "training_loss": 0.6961739158630371, "training_acc": 53.0, "val_loss": 0.6923924040794373, "val_acc": 52.0}
{"epoch": 77, "training_loss": 0.6967068672180176, "training_acc": 53.0, "val_loss": 0.692415497303009, "val_acc": 52.0}
{"epoch": 78, "training_loss": 0.6956680250167847, "training_acc": 45.0, "val_loss": 0.6923619413375854, "val_acc": 52.0}
{"epoch": 79, "training_loss": 0.693470561504364, "training_acc": 53.0, "val_loss": 0.6946623921394348, "val_acc": 52.0}
{"epoch": 80, "training_loss": 0.7040497875213623, "training_acc": 43.0, "val_loss": 0.69832848072052, "val_acc": 52.0}
{"epoch": 81, "training_loss": 0.7175569200515747, "training_acc": 53.0, "val_loss": 0.6966049242019653, "val_acc": 52.0}
{"epoch": 82, "training_loss": 0.6941865110397338, "training_acc": 53.0, "val_loss": 0.6926073455810546, "val_acc": 52.0}
