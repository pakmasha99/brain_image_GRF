"main_modify.py --pretrained_path /scratch/connectome/dyhan316/VAE_ADHD/barlowtwins/pretrain_results/ABCDbt128a102.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option BT_org --learning_rate 1e-6 --batch_size 16 --weight_decay 1e-3 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 0.7055385327339172, "training_acc": 47.0, "val_loss": 0.7038790988922119, "val_acc": 48.0}
{"epoch": 1, "training_loss": 0.704402151107788, "training_acc": 47.0, "val_loss": 0.703553068637848, "val_acc": 48.0}
{"epoch": 2, "training_loss": 0.7039966106414794, "training_acc": 47.0, "val_loss": 0.7035299229621887, "val_acc": 48.0}
{"epoch": 3, "training_loss": 0.7038371062278748, "training_acc": 47.0, "val_loss": 0.7032329964637757, "val_acc": 48.0}
{"epoch": 4, "training_loss": 0.7032789897918701, "training_acc": 47.0, "val_loss": 0.7031169080734253, "val_acc": 48.0}
{"epoch": 5, "training_loss": 0.7028295087814331, "training_acc": 47.0, "val_loss": 0.7029313278198243, "val_acc": 48.0}
{"epoch": 6, "training_loss": 0.7025632286071777, "training_acc": 47.0, "val_loss": 0.7029268622398377, "val_acc": 48.0}
{"epoch": 7, "training_loss": 0.7017680168151855, "training_acc": 47.0, "val_loss": 0.7029352235794067, "val_acc": 48.0}
{"epoch": 8, "training_loss": 0.7018483829498291, "training_acc": 47.0, "val_loss": 0.7029395985603333, "val_acc": 48.0}
{"epoch": 9, "training_loss": 0.7015928840637207, "training_acc": 47.0, "val_loss": 0.7028076577186585, "val_acc": 48.0}
{"epoch": 10, "training_loss": 0.7008575487136841, "training_acc": 47.0, "val_loss": 0.702927622795105, "val_acc": 48.0}
{"epoch": 11, "training_loss": 0.6998949003219604, "training_acc": 47.0, "val_loss": 0.7026530814170837, "val_acc": 48.0}
{"epoch": 12, "training_loss": 0.699978551864624, "training_acc": 47.0, "val_loss": 0.7020820856094361, "val_acc": 48.0}
{"epoch": 13, "training_loss": 0.6997478699684143, "training_acc": 47.0, "val_loss": 0.7022489094734192, "val_acc": 48.0}
{"epoch": 14, "training_loss": 0.6994575333595275, "training_acc": 47.0, "val_loss": 0.7024077534675598, "val_acc": 48.0}
{"epoch": 15, "training_loss": 0.6989386248588562, "training_acc": 47.0, "val_loss": 0.702211537361145, "val_acc": 48.0}
{"epoch": 16, "training_loss": 0.6984852743148804, "training_acc": 47.0, "val_loss": 0.7021273446083068, "val_acc": 48.0}
{"epoch": 17, "training_loss": 0.698352575302124, "training_acc": 47.0, "val_loss": 0.7020121502876282, "val_acc": 48.0}
{"epoch": 18, "training_loss": 0.697744812965393, "training_acc": 47.0, "val_loss": 0.7016890025138856, "val_acc": 48.0}
{"epoch": 19, "training_loss": 0.69732093334198, "training_acc": 47.0, "val_loss": 0.7012598156929016, "val_acc": 48.0}
{"epoch": 20, "training_loss": 0.6969782400131226, "training_acc": 47.0, "val_loss": 0.7014563727378845, "val_acc": 48.0}
{"epoch": 21, "training_loss": 0.6961575436592102, "training_acc": 47.0, "val_loss": 0.7015032315254212, "val_acc": 48.0}
{"epoch": 22, "training_loss": 0.695980830192566, "training_acc": 47.0, "val_loss": 0.7012485432624816, "val_acc": 48.0}
{"epoch": 23, "training_loss": 0.6958386707305908, "training_acc": 47.0, "val_loss": 0.7008600616455078, "val_acc": 48.0}
{"epoch": 24, "training_loss": 0.6951770091056824, "training_acc": 47.0, "val_loss": 0.7005091166496277, "val_acc": 48.0}
{"epoch": 25, "training_loss": 0.6958429479598999, "training_acc": 47.0, "val_loss": 0.7004792618751526, "val_acc": 48.0}
{"epoch": 26, "training_loss": 0.6945632171630859, "training_acc": 47.0, "val_loss": 0.7005601835250854, "val_acc": 48.0}
{"epoch": 27, "training_loss": 0.6938215589523316, "training_acc": 47.0, "val_loss": 0.7002057909965516, "val_acc": 48.0}
{"epoch": 28, "training_loss": 0.6931899642944336, "training_acc": 47.0, "val_loss": 0.7001755261421203, "val_acc": 48.0}
{"epoch": 29, "training_loss": 0.6931385707855224, "training_acc": 47.0, "val_loss": 0.7000930833816529, "val_acc": 48.0}
{"epoch": 30, "training_loss": 0.6930571746826172, "training_acc": 47.0, "val_loss": 0.6997489881515503, "val_acc": 48.0}
{"epoch": 31, "training_loss": 0.6927671384811401, "training_acc": 47.0, "val_loss": 0.7000120139122009, "val_acc": 48.0}
{"epoch": 32, "training_loss": 0.6926934003829956, "training_acc": 47.0, "val_loss": 0.6995723080635071, "val_acc": 48.0}
{"epoch": 33, "training_loss": 0.6920191812515258, "training_acc": 47.0, "val_loss": 0.6995259428024292, "val_acc": 48.0}
{"epoch": 34, "training_loss": 0.6923149967193604, "training_acc": 47.0, "val_loss": 0.6993367791175842, "val_acc": 48.0}
{"epoch": 35, "training_loss": 0.6915678477287293, "training_acc": 47.0, "val_loss": 0.699002685546875, "val_acc": 48.0}
{"epoch": 36, "training_loss": 0.6912699699401855, "training_acc": 47.0, "val_loss": 0.6993316769599914, "val_acc": 48.0}
{"epoch": 37, "training_loss": 0.6908578777313232, "training_acc": 47.0, "val_loss": 0.6991999435424805, "val_acc": 48.0}
{"epoch": 38, "training_loss": 0.6904928064346314, "training_acc": 47.0, "val_loss": 0.6984145402908325, "val_acc": 48.0}
{"epoch": 39, "training_loss": 0.6900241804122925, "training_acc": 47.0, "val_loss": 0.698755042552948, "val_acc": 48.0}
{"epoch": 40, "training_loss": 0.6890600323677063, "training_acc": 47.0, "val_loss": 0.6985099816322327, "val_acc": 48.0}
{"epoch": 41, "training_loss": 0.6888681888580322, "training_acc": 47.0, "val_loss": 0.6986729669570922, "val_acc": 48.0}
{"epoch": 42, "training_loss": 0.688680911064148, "training_acc": 47.0, "val_loss": 0.6984509587287903, "val_acc": 48.0}
{"epoch": 43, "training_loss": 0.6886538553237915, "training_acc": 47.0, "val_loss": 0.6983280253410339, "val_acc": 48.0}
{"epoch": 44, "training_loss": 0.6886199235916137, "training_acc": 47.0, "val_loss": 0.6979911160469056, "val_acc": 48.0}
{"epoch": 45, "training_loss": 0.6881179571151733, "training_acc": 47.0, "val_loss": 0.6977876663208008, "val_acc": 48.0}
{"epoch": 46, "training_loss": 0.688690390586853, "training_acc": 47.0, "val_loss": 0.697822277545929, "val_acc": 48.0}
{"epoch": 47, "training_loss": 0.6878124594688415, "training_acc": 47.0, "val_loss": 0.6974400711059571, "val_acc": 48.0}
{"epoch": 48, "training_loss": 0.6876068115234375, "training_acc": 47.0, "val_loss": 0.69776948928833, "val_acc": 48.0}
{"epoch": 49, "training_loss": 0.6871643924713134, "training_acc": 47.0, "val_loss": 0.6974333238601684, "val_acc": 48.0}
{"epoch": 50, "training_loss": 0.6861918950080872, "training_acc": 47.0, "val_loss": 0.6976716184616089, "val_acc": 48.0}
{"epoch": 51, "training_loss": 0.6859022212028504, "training_acc": 47.0, "val_loss": 0.6973534822463989, "val_acc": 48.0}
{"epoch": 52, "training_loss": 0.6862848496437073, "training_acc": 47.0, "val_loss": 0.6972106838226318, "val_acc": 48.0}
{"epoch": 53, "training_loss": 0.6854578351974487, "training_acc": 47.0, "val_loss": 0.6966171479225158, "val_acc": 48.0}
{"epoch": 54, "training_loss": 0.6842625904083252, "training_acc": 47.0, "val_loss": 0.6968965935707092, "val_acc": 48.0}
{"epoch": 55, "training_loss": 0.6856819677352906, "training_acc": 47.0, "val_loss": 0.6965216422080993, "val_acc": 48.0}
{"epoch": 56, "training_loss": 0.6851383256912231, "training_acc": 47.0, "val_loss": 0.6968289637565612, "val_acc": 48.0}
{"epoch": 57, "training_loss": 0.6842723703384399, "training_acc": 47.0, "val_loss": 0.6962833642959595, "val_acc": 48.0}
{"epoch": 58, "training_loss": 0.6838711619377136, "training_acc": 47.0, "val_loss": 0.6963414788246155, "val_acc": 48.0}
{"epoch": 59, "training_loss": 0.6842890310287476, "training_acc": 47.0, "val_loss": 0.6959538769721985, "val_acc": 48.0}
{"epoch": 60, "training_loss": 0.6837584352493287, "training_acc": 47.0, "val_loss": 0.6963986420631408, "val_acc": 48.0}
{"epoch": 61, "training_loss": 0.6826449537277222, "training_acc": 47.0, "val_loss": 0.69553218126297, "val_acc": 48.0}
{"epoch": 62, "training_loss": 0.6828081512451172, "training_acc": 47.0, "val_loss": 0.6959365558624268, "val_acc": 48.0}
{"epoch": 63, "training_loss": 0.6826627159118652, "training_acc": 47.0, "val_loss": 0.6958932518959046, "val_acc": 48.0}
{"epoch": 64, "training_loss": 0.6826476764678955, "training_acc": 47.0, "val_loss": 0.6962324285507202, "val_acc": 48.0}
{"epoch": 65, "training_loss": 0.6818339896202087, "training_acc": 47.0, "val_loss": 0.6950006818771363, "val_acc": 48.0}
{"epoch": 66, "training_loss": 0.6813182091712952, "training_acc": 47.0, "val_loss": 0.6956105089187622, "val_acc": 48.0}
{"epoch": 67, "training_loss": 0.6812046217918396, "training_acc": 47.0, "val_loss": 0.6958242511749267, "val_acc": 48.0}
{"epoch": 68, "training_loss": 0.6818525338172913, "training_acc": 47.0, "val_loss": 0.6953876423835754, "val_acc": 48.0}
{"epoch": 69, "training_loss": 0.6811781263351441, "training_acc": 47.0, "val_loss": 0.6955391097068787, "val_acc": 48.0}
{"epoch": 70, "training_loss": 0.6794591689109802, "training_acc": 47.0, "val_loss": 0.6953037595748901, "val_acc": 48.0}
{"epoch": 71, "training_loss": 0.6796910953521729, "training_acc": 47.0, "val_loss": 0.6949225592613221, "val_acc": 48.0}
{"epoch": 72, "training_loss": 0.680168194770813, "training_acc": 47.0, "val_loss": 0.6947574210166931, "val_acc": 48.0}
{"epoch": 73, "training_loss": 0.6796710681915283, "training_acc": 47.0, "val_loss": 0.6950934147834777, "val_acc": 48.0}
{"epoch": 74, "training_loss": 0.678789689540863, "training_acc": 47.0, "val_loss": 0.6947054219245911, "val_acc": 48.0}
{"epoch": 75, "training_loss": 0.6802715277671814, "training_acc": 48.0, "val_loss": 0.6948227167129517, "val_acc": 48.0}
{"epoch": 76, "training_loss": 0.6785528516769409, "training_acc": 48.0, "val_loss": 0.6942396974563598, "val_acc": 48.0}
{"epoch": 77, "training_loss": 0.6786385774612427, "training_acc": 48.0, "val_loss": 0.6952087879180908, "val_acc": 48.0}
{"epoch": 78, "training_loss": 0.6782368469238281, "training_acc": 48.0, "val_loss": 0.6941836261749268, "val_acc": 48.0}
{"epoch": 79, "training_loss": 0.6782225060462952, "training_acc": 48.0, "val_loss": 0.6943846321105958, "val_acc": 48.0}
{"epoch": 80, "training_loss": 0.677996768951416, "training_acc": 49.0, "val_loss": 0.6941876339912415, "val_acc": 48.0}
{"epoch": 81, "training_loss": 0.6782503080368042, "training_acc": 48.0, "val_loss": 0.6946022725105285, "val_acc": 48.0}
{"epoch": 82, "training_loss": 0.6772871112823486, "training_acc": 49.0, "val_loss": 0.6936226391792297, "val_acc": 48.0}
{"epoch": 83, "training_loss": 0.6773784494400025, "training_acc": 49.0, "val_loss": 0.6940210628509521, "val_acc": 48.0}
{"epoch": 84, "training_loss": 0.6766116762161255, "training_acc": 49.0, "val_loss": 0.6942279553413391, "val_acc": 48.0}
{"epoch": 85, "training_loss": 0.6760928535461426, "training_acc": 50.0, "val_loss": 0.6939731431007385, "val_acc": 48.0}
{"epoch": 86, "training_loss": 0.6765938329696656, "training_acc": 48.0, "val_loss": 0.6934629511833191, "val_acc": 48.0}
{"epoch": 87, "training_loss": 0.6755824232101441, "training_acc": 50.0, "val_loss": 0.6933498668670655, "val_acc": 52.0}
{"epoch": 88, "training_loss": 0.6754422974586487, "training_acc": 53.0, "val_loss": 0.6937106823921204, "val_acc": 48.0}
{"epoch": 89, "training_loss": 0.674533441066742, "training_acc": 53.0, "val_loss": 0.6933616018295288, "val_acc": 52.0}
{"epoch": 90, "training_loss": 0.6747889852523804, "training_acc": 51.0, "val_loss": 0.6934400224685668, "val_acc": 52.0}
{"epoch": 91, "training_loss": 0.6749131155014038, "training_acc": 51.0, "val_loss": 0.6932709860801697, "val_acc": 52.0}
{"epoch": 92, "training_loss": 0.6760082244873047, "training_acc": 54.0, "val_loss": 0.6936010336875915, "val_acc": 52.0}
{"epoch": 93, "training_loss": 0.6756088209152221, "training_acc": 51.0, "val_loss": 0.6933325123786926, "val_acc": 52.0}
{"epoch": 94, "training_loss": 0.6735895419120789, "training_acc": 57.0, "val_loss": 0.6930546998977661, "val_acc": 52.0}
{"epoch": 95, "training_loss": 0.6734293222427368, "training_acc": 56.0, "val_loss": 0.6935926485061645, "val_acc": 52.0}
{"epoch": 96, "training_loss": 0.6736077594757081, "training_acc": 58.0, "val_loss": 0.6929088306427001, "val_acc": 52.0}
{"epoch": 97, "training_loss": 0.6726588535308838, "training_acc": 58.0, "val_loss": 0.6928323006629944, "val_acc": 52.0}
{"epoch": 98, "training_loss": 0.6728141045570374, "training_acc": 57.0, "val_loss": 0.6932190299034119, "val_acc": 52.0}
{"epoch": 99, "training_loss": 0.6724097919464112, "training_acc": 61.0, "val_loss": 0.6924315595626831, "val_acc": 52.0}
