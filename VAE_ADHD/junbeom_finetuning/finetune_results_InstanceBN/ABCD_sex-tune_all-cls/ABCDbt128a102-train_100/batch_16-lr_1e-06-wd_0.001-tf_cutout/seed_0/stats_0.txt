"main_modify.py --pretrained_path /scratch/connectome/dyhan316/VAE_ADHD/barlowtwins/pretrain_results/ABCDbt128a102.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option BT_org --learning_rate 1e-6 --batch_size 16 --weight_decay 1e-3 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 0.691912612915039, "training_acc": 52.0, "val_loss": 0.6898768734931946, "val_acc": 56.0}
{"epoch": 1, "training_loss": 0.6916820478439331, "training_acc": 52.0, "val_loss": 0.6894117069244384, "val_acc": 56.0}
{"epoch": 2, "training_loss": 0.6912409543991089, "training_acc": 52.0, "val_loss": 0.6897352600097656, "val_acc": 56.0}
{"epoch": 3, "training_loss": 0.6913681840896606, "training_acc": 52.0, "val_loss": 0.6898426413536072, "val_acc": 56.0}
{"epoch": 4, "training_loss": 0.6910190796852111, "training_acc": 52.0, "val_loss": 0.6899221277236939, "val_acc": 56.0}
{"epoch": 5, "training_loss": 0.6905413627624511, "training_acc": 52.0, "val_loss": 0.6896479797363281, "val_acc": 56.0}
{"epoch": 6, "training_loss": 0.6896896123886108, "training_acc": 52.0, "val_loss": 0.6893291735649109, "val_acc": 56.0}
{"epoch": 7, "training_loss": 0.6902316284179687, "training_acc": 52.0, "val_loss": 0.6893208765983582, "val_acc": 56.0}
{"epoch": 8, "training_loss": 0.6891679000854493, "training_acc": 52.0, "val_loss": 0.6888782429695129, "val_acc": 56.0}
{"epoch": 9, "training_loss": 0.6897578716278077, "training_acc": 52.0, "val_loss": 0.6889249849319458, "val_acc": 56.0}
{"epoch": 10, "training_loss": 0.6888672256469727, "training_acc": 52.0, "val_loss": 0.6892192125320434, "val_acc": 56.0}
{"epoch": 11, "training_loss": 0.6886863565444946, "training_acc": 52.0, "val_loss": 0.689097785949707, "val_acc": 56.0}
{"epoch": 12, "training_loss": 0.6881386828422547, "training_acc": 52.0, "val_loss": 0.6887858986854554, "val_acc": 56.0}
{"epoch": 13, "training_loss": 0.6883603811264039, "training_acc": 52.0, "val_loss": 0.688529236316681, "val_acc": 56.0}
{"epoch": 14, "training_loss": 0.6883576202392578, "training_acc": 52.0, "val_loss": 0.6890878176689148, "val_acc": 56.0}
{"epoch": 15, "training_loss": 0.687768144607544, "training_acc": 52.0, "val_loss": 0.6894045877456665, "val_acc": 56.0}
{"epoch": 16, "training_loss": 0.6879263353347779, "training_acc": 52.0, "val_loss": 0.6891074013710022, "val_acc": 56.0}
{"epoch": 17, "training_loss": 0.6872148609161377, "training_acc": 52.0, "val_loss": 0.689110951423645, "val_acc": 56.0}
{"epoch": 18, "training_loss": 0.6869459915161132, "training_acc": 52.0, "val_loss": 0.6889527153968811, "val_acc": 56.0}
{"epoch": 19, "training_loss": 0.6866718220710755, "training_acc": 52.0, "val_loss": 0.6888340044021607, "val_acc": 56.0}
{"epoch": 20, "training_loss": 0.686472589969635, "training_acc": 52.0, "val_loss": 0.6888871669769288, "val_acc": 56.0}
{"epoch": 21, "training_loss": 0.6861685752868653, "training_acc": 52.0, "val_loss": 0.6890794467926026, "val_acc": 56.0}
{"epoch": 22, "training_loss": 0.6859840798377991, "training_acc": 52.0, "val_loss": 0.6888331937789917, "val_acc": 56.0}
{"epoch": 23, "training_loss": 0.6850694179534912, "training_acc": 52.0, "val_loss": 0.6888952374458313, "val_acc": 56.0}
{"epoch": 24, "training_loss": 0.6858876132965088, "training_acc": 53.0, "val_loss": 0.6887371635437012, "val_acc": 56.0}
{"epoch": 25, "training_loss": 0.6854339337348938, "training_acc": 52.0, "val_loss": 0.6888615202903747, "val_acc": 56.0}
{"epoch": 26, "training_loss": 0.6839113473892212, "training_acc": 53.0, "val_loss": 0.6888601398468017, "val_acc": 56.0}
{"epoch": 27, "training_loss": 0.6843374967575073, "training_acc": 52.0, "val_loss": 0.6888971185684204, "val_acc": 56.0}
{"epoch": 28, "training_loss": 0.684584698677063, "training_acc": 53.0, "val_loss": 0.688736526966095, "val_acc": 56.0}
{"epoch": 29, "training_loss": 0.6835563564300537, "training_acc": 52.0, "val_loss": 0.6887045192718506, "val_acc": 56.0}
{"epoch": 30, "training_loss": 0.6838505864143372, "training_acc": 53.0, "val_loss": 0.6889560723304748, "val_acc": 56.0}
{"epoch": 31, "training_loss": 0.6838735342025757, "training_acc": 53.0, "val_loss": 0.688464629650116, "val_acc": 56.0}
{"epoch": 32, "training_loss": 0.6826630353927612, "training_acc": 53.0, "val_loss": 0.6886228990554809, "val_acc": 56.0}
{"epoch": 33, "training_loss": 0.6826550936698914, "training_acc": 52.0, "val_loss": 0.6885883378982544, "val_acc": 56.0}
{"epoch": 34, "training_loss": 0.6823383259773255, "training_acc": 53.0, "val_loss": 0.6887239384651184, "val_acc": 56.0}
{"epoch": 35, "training_loss": 0.6825233340263367, "training_acc": 53.0, "val_loss": 0.6887027001380921, "val_acc": 56.0}
{"epoch": 36, "training_loss": 0.6822369837760925, "training_acc": 53.0, "val_loss": 0.688777186870575, "val_acc": 56.0}
{"epoch": 37, "training_loss": 0.6812697505950928, "training_acc": 54.0, "val_loss": 0.6886179780960083, "val_acc": 56.0}
{"epoch": 38, "training_loss": 0.6811671400070191, "training_acc": 53.0, "val_loss": 0.6884379410743713, "val_acc": 56.0}
{"epoch": 39, "training_loss": 0.6815287446975709, "training_acc": 54.0, "val_loss": 0.6883187747001648, "val_acc": 56.0}
{"epoch": 40, "training_loss": 0.6811032342910767, "training_acc": 54.0, "val_loss": 0.6884230899810792, "val_acc": 56.0}
{"epoch": 41, "training_loss": 0.6808453273773193, "training_acc": 54.0, "val_loss": 0.6886465430259705, "val_acc": 56.0}
{"epoch": 42, "training_loss": 0.6808873653411865, "training_acc": 54.0, "val_loss": 0.6885423231124878, "val_acc": 56.0}
{"epoch": 43, "training_loss": 0.6795929098129272, "training_acc": 54.0, "val_loss": 0.688384563922882, "val_acc": 56.0}
{"epoch": 44, "training_loss": 0.6793774795532227, "training_acc": 55.0, "val_loss": 0.6886456990242005, "val_acc": 56.0}
{"epoch": 45, "training_loss": 0.6800264430046081, "training_acc": 56.0, "val_loss": 0.6887015104293823, "val_acc": 56.0}
{"epoch": 46, "training_loss": 0.6786091756820679, "training_acc": 55.0, "val_loss": 0.6885739636421203, "val_acc": 56.0}
{"epoch": 47, "training_loss": 0.6801287269592285, "training_acc": 55.0, "val_loss": 0.6885433053970337, "val_acc": 56.0}
{"epoch": 48, "training_loss": 0.6790588021278381, "training_acc": 57.0, "val_loss": 0.688716733455658, "val_acc": 56.0}
{"epoch": 49, "training_loss": 0.6788378882408143, "training_acc": 55.0, "val_loss": 0.6885641098022461, "val_acc": 56.0}
{"epoch": 50, "training_loss": 0.6790119051933289, "training_acc": 57.0, "val_loss": 0.6885370779037475, "val_acc": 56.0}
{"epoch": 51, "training_loss": 0.6791919612884522, "training_acc": 57.0, "val_loss": 0.6887705326080322, "val_acc": 56.0}
{"epoch": 52, "training_loss": 0.6779154562950134, "training_acc": 57.0, "val_loss": 0.6883419060707092, "val_acc": 56.0}
{"epoch": 53, "training_loss": 0.6771913886070251, "training_acc": 58.0, "val_loss": 0.6884706211090088, "val_acc": 56.0}
{"epoch": 54, "training_loss": 0.6770939636230469, "training_acc": 60.0, "val_loss": 0.6886263990402222, "val_acc": 56.0}
{"epoch": 55, "training_loss": 0.6767278623580932, "training_acc": 63.0, "val_loss": 0.6886101651191712, "val_acc": 56.0}
{"epoch": 56, "training_loss": 0.676508502960205, "training_acc": 61.0, "val_loss": 0.6883778405189515, "val_acc": 56.0}
{"epoch": 57, "training_loss": 0.6771657085418701, "training_acc": 63.0, "val_loss": 0.6886574077606201, "val_acc": 56.0}
{"epoch": 58, "training_loss": 0.6759620904922485, "training_acc": 64.0, "val_loss": 0.6884593439102172, "val_acc": 56.0}
