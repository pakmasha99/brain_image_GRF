"main_modify.py --pretrained_path /scratch/connectome/dyhan316/VAE_ADHD/barlowtwins/pretrain_results/ABCDbt128a102.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option BT_org --learning_rate 5e-5 --batch_size 16 --weight_decay 5e-3 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 0.6904481887817383, "training_acc": 53.0, "val_loss": 0.6953670763969422, "val_acc": 52.0}
{"epoch": 1, "training_loss": 0.6919554376602173, "training_acc": 53.0, "val_loss": 0.6934878635406494, "val_acc": 52.0}
{"epoch": 2, "training_loss": 0.6921419048309326, "training_acc": 53.0, "val_loss": 0.6954495692253113, "val_acc": 52.0}
{"epoch": 3, "training_loss": 0.6916954350471497, "training_acc": 53.0, "val_loss": 0.6964308667182922, "val_acc": 52.0}
{"epoch": 4, "training_loss": 0.6917504024505615, "training_acc": 53.0, "val_loss": 0.6989225435256958, "val_acc": 52.0}
{"epoch": 5, "training_loss": 0.696207594871521, "training_acc": 53.0, "val_loss": 0.6958916449546814, "val_acc": 52.0}
{"epoch": 6, "training_loss": 0.6919662189483643, "training_acc": 53.0, "val_loss": 0.6943260550498962, "val_acc": 52.0}
{"epoch": 7, "training_loss": 0.6928459310531616, "training_acc": 53.0, "val_loss": 0.6933145761489868, "val_acc": 52.0}
{"epoch": 8, "training_loss": 0.6922935891151428, "training_acc": 53.0, "val_loss": 0.6925367379188537, "val_acc": 52.0}
{"epoch": 9, "training_loss": 0.6925303030014038, "training_acc": 53.0, "val_loss": 0.6923447799682617, "val_acc": 52.0}
{"epoch": 10, "training_loss": 0.6917092084884644, "training_acc": 53.0, "val_loss": 0.6923705697059631, "val_acc": 52.0}
{"epoch": 11, "training_loss": 0.6924892830848693, "training_acc": 53.0, "val_loss": 0.6923822140693665, "val_acc": 52.0}
{"epoch": 12, "training_loss": 0.6917693710327149, "training_acc": 53.0, "val_loss": 0.6923931980133057, "val_acc": 52.0}
{"epoch": 13, "training_loss": 0.6935672569274902, "training_acc": 53.0, "val_loss": 0.6926752877235413, "val_acc": 52.0}
{"epoch": 14, "training_loss": 0.6931419563293457, "training_acc": 53.0, "val_loss": 0.692813663482666, "val_acc": 52.0}
{"epoch": 15, "training_loss": 0.6936368203163147, "training_acc": 53.0, "val_loss": 0.6926300168037415, "val_acc": 52.0}
{"epoch": 16, "training_loss": 0.6928621983528137, "training_acc": 53.0, "val_loss": 0.6926435494422912, "val_acc": 52.0}
{"epoch": 17, "training_loss": 0.6928062152862549, "training_acc": 53.0, "val_loss": 0.6926523995399475, "val_acc": 52.0}
{"epoch": 18, "training_loss": 0.6950730323791504, "training_acc": 53.0, "val_loss": 0.6925294995307922, "val_acc": 52.0}
{"epoch": 19, "training_loss": 0.6916666746139526, "training_acc": 53.0, "val_loss": 0.6926843738555908, "val_acc": 52.0}
{"epoch": 20, "training_loss": 0.6916967630386353, "training_acc": 53.0, "val_loss": 0.6929238796234131, "val_acc": 52.0}
{"epoch": 21, "training_loss": 0.6931399989128113, "training_acc": 53.0, "val_loss": 0.6932597780227661, "val_acc": 52.0}
{"epoch": 22, "training_loss": 0.6931816959381103, "training_acc": 53.0, "val_loss": 0.6924275660514831, "val_acc": 52.0}
{"epoch": 23, "training_loss": 0.6913062620162964, "training_acc": 53.0, "val_loss": 0.6926446151733399, "val_acc": 52.0}
{"epoch": 24, "training_loss": 0.6915192556381226, "training_acc": 53.0, "val_loss": 0.6925328040122986, "val_acc": 52.0}
{"epoch": 25, "training_loss": 0.6917818856239318, "training_acc": 53.0, "val_loss": 0.6927167582511902, "val_acc": 52.0}
{"epoch": 26, "training_loss": 0.690610773563385, "training_acc": 53.0, "val_loss": 0.6932547903060913, "val_acc": 52.0}
{"epoch": 27, "training_loss": 0.6910837125778199, "training_acc": 53.0, "val_loss": 0.6930891728401184, "val_acc": 52.0}
{"epoch": 28, "training_loss": 0.6914510846138, "training_acc": 53.0, "val_loss": 0.6933851742744446, "val_acc": 52.0}
