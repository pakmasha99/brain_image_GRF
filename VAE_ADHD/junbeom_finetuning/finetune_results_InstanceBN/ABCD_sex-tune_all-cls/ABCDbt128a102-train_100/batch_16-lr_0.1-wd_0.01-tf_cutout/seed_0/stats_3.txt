"main_modify.py --pretrained_path /scratch/connectome/dyhan316/VAE_ADHD/barlowtwins/pretrain_results/ABCDbt128a102.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option BT_org --learning_rate 1e-1 --batch_size 16 --weight_decay 1e-2 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 9.208870830535888, "training_acc": 49.0, "val_loss": 3.2639717292785644, "val_acc": 52.0}
{"epoch": 1, "training_loss": 5.2924837875366215, "training_acc": 49.0, "val_loss": 3.801484308242798, "val_acc": 52.0}
{"epoch": 2, "training_loss": 1.8993382453918457, "training_acc": 62.0, "val_loss": 1.3588616609573365, "val_acc": 52.0}
{"epoch": 3, "training_loss": 1.4896390485763549, "training_acc": 49.0, "val_loss": 1.44280264377594, "val_acc": 48.0}
{"epoch": 4, "training_loss": 1.4430883502960206, "training_acc": 53.0, "val_loss": 0.7281621098518372, "val_acc": 48.0}
{"epoch": 5, "training_loss": 1.0207486486434936, "training_acc": 53.0, "val_loss": 1.0368113946914672, "val_acc": 52.0}
{"epoch": 6, "training_loss": 1.1476674365997315, "training_acc": 45.0, "val_loss": 2.117699270248413, "val_acc": 52.0}
{"epoch": 7, "training_loss": 1.676517276763916, "training_acc": 55.0, "val_loss": 1.28055579662323, "val_acc": 52.0}
{"epoch": 8, "training_loss": 2.676089143753052, "training_acc": 51.0, "val_loss": 1.1074706268310548, "val_acc": 52.0}
{"epoch": 9, "training_loss": 1.5331303548812867, "training_acc": 45.0, "val_loss": 1.578015775680542, "val_acc": 48.0}
{"epoch": 10, "training_loss": 1.6670268845558167, "training_acc": 51.0, "val_loss": 3.7645894050598145, "val_acc": 52.0}
{"epoch": 11, "training_loss": 2.9754449677467347, "training_acc": 55.0, "val_loss": 1.5573325967788696, "val_acc": 52.0}
{"epoch": 12, "training_loss": 1.0983087849617004, "training_acc": 51.0, "val_loss": 0.8262701964378357, "val_acc": 48.0}
{"epoch": 13, "training_loss": 1.138612470626831, "training_acc": 51.0, "val_loss": 1.0915455722808838, "val_acc": 48.0}
{"epoch": 14, "training_loss": 0.8686270713806152, "training_acc": 47.0, "val_loss": 2.6715913581848145, "val_acc": 48.0}
{"epoch": 15, "training_loss": 2.074921112060547, "training_acc": 57.0, "val_loss": 0.7265296697616577, "val_acc": 48.0}
{"epoch": 16, "training_loss": 1.0185150003433228, "training_acc": 51.0, "val_loss": 1.801956901550293, "val_acc": 48.0}
{"epoch": 17, "training_loss": 0.9658849000930786, "training_acc": 65.0, "val_loss": 2.7231032848358154, "val_acc": 48.0}
{"epoch": 18, "training_loss": 1.7747997045516968, "training_acc": 51.0, "val_loss": 2.6588320398330687, "val_acc": 52.0}
{"epoch": 19, "training_loss": 2.144234094619751, "training_acc": 47.0, "val_loss": 3.43521692276001, "val_acc": 48.0}
{"epoch": 20, "training_loss": 1.9194577217102051, "training_acc": 45.0, "val_loss": 0.6967048001289368, "val_acc": 48.0}
{"epoch": 21, "training_loss": 0.8998394751548767, "training_acc": 47.0, "val_loss": 1.1062494564056395, "val_acc": 52.0}
{"epoch": 22, "training_loss": 0.7613041138648987, "training_acc": 55.0, "val_loss": 1.050156364440918, "val_acc": 48.0}
{"epoch": 23, "training_loss": 1.0490568780899048, "training_acc": 45.0, "val_loss": 1.1199363851547242, "val_acc": 52.0}
{"epoch": 24, "training_loss": 1.185932674407959, "training_acc": 39.0, "val_loss": 1.9111942005157472, "val_acc": 52.0}
{"epoch": 25, "training_loss": 1.487792694568634, "training_acc": 45.0, "val_loss": 2.5051185989379885, "val_acc": 52.0}
{"epoch": 26, "training_loss": 2.3616441535949706, "training_acc": 53.0, "val_loss": 5.486243553161621, "val_acc": 52.0}
{"epoch": 27, "training_loss": 1.7217230415344238, "training_acc": 49.0, "val_loss": 3.2500537204742432, "val_acc": 48.0}
{"epoch": 28, "training_loss": 2.112702350616455, "training_acc": 43.0, "val_loss": 0.9210128831863403, "val_acc": 52.0}
{"epoch": 29, "training_loss": 0.9426380848884582, "training_acc": 51.0, "val_loss": 0.7561693310737609, "val_acc": 48.0}
{"epoch": 30, "training_loss": 1.0303100538253784, "training_acc": 53.0, "val_loss": 0.6956912660598755, "val_acc": 52.0}
{"epoch": 31, "training_loss": 1.5250586843490601, "training_acc": 47.0, "val_loss": 2.211988048553467, "val_acc": 48.0}
{"epoch": 32, "training_loss": 1.8890205883979798, "training_acc": 51.0, "val_loss": 3.3183467292785647, "val_acc": 52.0}
{"epoch": 33, "training_loss": 2.1418118286132812, "training_acc": 45.0, "val_loss": 0.894866681098938, "val_acc": 52.0}
{"epoch": 34, "training_loss": 1.572720079421997, "training_acc": 45.0, "val_loss": 2.510099048614502, "val_acc": 48.0}
{"epoch": 35, "training_loss": 3.2514385104179384, "training_acc": 51.0, "val_loss": 2.437220420837402, "val_acc": 48.0}
{"epoch": 36, "training_loss": 2.9340581130981445, "training_acc": 55.0, "val_loss": 3.2286692810058595, "val_acc": 48.0}
{"epoch": 37, "training_loss": 3.6037596321105956, "training_acc": 53.0, "val_loss": 1.51309983253479, "val_acc": 52.0}
{"epoch": 38, "training_loss": 2.8932823944091797, "training_acc": 45.0, "val_loss": 4.91148567199707, "val_acc": 48.0}
{"epoch": 39, "training_loss": 6.367004356384277, "training_acc": 45.0, "val_loss": 11.450673923492431, "val_acc": 52.0}
{"epoch": 40, "training_loss": 5.937354049682617, "training_acc": 55.0, "val_loss": 9.554357414245606, "val_acc": 48.0}
{"epoch": 41, "training_loss": 7.364746913909912, "training_acc": 45.0, "val_loss": 2.1700945520401, "val_acc": 52.0}
{"epoch": 42, "training_loss": 3.618247880935669, "training_acc": 47.0, "val_loss": 3.834137535095215, "val_acc": 52.0}
{"epoch": 43, "training_loss": 1.8144705414772033, "training_acc": 49.0, "val_loss": 2.4005869007110596, "val_acc": 48.0}
{"epoch": 44, "training_loss": 2.3494735527038575, "training_acc": 47.0, "val_loss": 0.815043969154358, "val_acc": 48.0}
{"epoch": 45, "training_loss": 2.148931941986084, "training_acc": 55.0, "val_loss": 2.2256780672073364, "val_acc": 52.0}
{"epoch": 46, "training_loss": 1.6515598821640014, "training_acc": 49.0, "val_loss": 1.957561731338501, "val_acc": 52.0}
{"epoch": 47, "training_loss": 1.1782112646102905, "training_acc": 47.0, "val_loss": 1.4521164941787719, "val_acc": 48.0}
{"epoch": 48, "training_loss": 1.0090548229217529, "training_acc": 45.0, "val_loss": 1.2556855010986328, "val_acc": 52.0}
{"epoch": 49, "training_loss": 1.567242841720581, "training_acc": 51.0, "val_loss": 0.6958476686477661, "val_acc": 52.0}
