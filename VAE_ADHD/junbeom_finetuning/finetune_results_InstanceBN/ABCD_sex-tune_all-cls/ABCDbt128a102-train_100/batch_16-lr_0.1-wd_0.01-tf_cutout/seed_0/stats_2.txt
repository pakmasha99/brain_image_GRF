"main_modify.py --pretrained_path /scratch/connectome/dyhan316/VAE_ADHD/barlowtwins/pretrain_results/ABCDbt128a102.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option BT_org --learning_rate 1e-1 --batch_size 16 --weight_decay 1e-2 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 8.632279796600342, "training_acc": 45.0, "val_loss": 0.7847907447814941, "val_acc": 52.0}
{"epoch": 1, "training_loss": 3.622418451309204, "training_acc": 53.0, "val_loss": 5.825384683609009, "val_acc": 48.0}
{"epoch": 2, "training_loss": 5.174541807174682, "training_acc": 47.0, "val_loss": 0.6955801391601563, "val_acc": 48.0}
{"epoch": 3, "training_loss": 1.5290161561965943, "training_acc": 47.0, "val_loss": 0.6959431695938111, "val_acc": 52.0}
{"epoch": 4, "training_loss": 0.7718468618392944, "training_acc": 48.0, "val_loss": 0.8403254675865174, "val_acc": 48.0}
{"epoch": 5, "training_loss": 1.0153106379508972, "training_acc": 45.0, "val_loss": 2.0953895711898802, "val_acc": 52.0}
{"epoch": 6, "training_loss": 1.602100784778595, "training_acc": 53.0, "val_loss": 4.409070262908935, "val_acc": 48.0}
{"epoch": 7, "training_loss": 3.724944658279419, "training_acc": 43.0, "val_loss": 0.8242998051643372, "val_acc": 48.0}
{"epoch": 8, "training_loss": 1.0444110035896301, "training_acc": 51.0, "val_loss": 1.8092271900177002, "val_acc": 52.0}
{"epoch": 9, "training_loss": 1.16140811920166, "training_acc": 59.0, "val_loss": 2.7189323997497556, "val_acc": 48.0}
{"epoch": 10, "training_loss": 2.306856622695923, "training_acc": 49.0, "val_loss": 0.7824378418922424, "val_acc": 48.0}
{"epoch": 11, "training_loss": 3.079205732345581, "training_acc": 45.0, "val_loss": 4.185527620315551, "val_acc": 52.0}
{"epoch": 12, "training_loss": 4.341856219768524, "training_acc": 49.0, "val_loss": 0.9737019681930542, "val_acc": 52.0}
{"epoch": 13, "training_loss": 1.1259372997283936, "training_acc": 45.0, "val_loss": 0.6933137392997741, "val_acc": 48.0}
{"epoch": 14, "training_loss": 1.4923474168777466, "training_acc": 51.0, "val_loss": 2.6497303867340087, "val_acc": 52.0}
{"epoch": 15, "training_loss": 1.7941677713394164, "training_acc": 49.0, "val_loss": 1.3341495609283447, "val_acc": 48.0}
{"epoch": 16, "training_loss": 1.1109290981292725, "training_acc": 53.0, "val_loss": 2.2507146263122557, "val_acc": 52.0}
{"epoch": 17, "training_loss": 1.9130487489700316, "training_acc": 45.0, "val_loss": 0.7075700378417968, "val_acc": 52.0}
{"epoch": 18, "training_loss": 1.2484285473823546, "training_acc": 49.0, "val_loss": 1.7181776142120362, "val_acc": 48.0}
{"epoch": 19, "training_loss": 1.1575717210769654, "training_acc": 49.0, "val_loss": 0.7033573842048645, "val_acc": 52.0}
{"epoch": 20, "training_loss": 1.1935281825065613, "training_acc": 45.0, "val_loss": 1.5038704919815062, "val_acc": 52.0}
{"epoch": 21, "training_loss": 1.0992744874954223, "training_acc": 53.0, "val_loss": 0.7634659838676453, "val_acc": 48.0}
{"epoch": 22, "training_loss": 1.7068259525299072, "training_acc": 47.0, "val_loss": 4.470285339355469, "val_acc": 52.0}
{"epoch": 23, "training_loss": 2.9609976482391356, "training_acc": 47.0, "val_loss": 4.154231357574463, "val_acc": 52.0}
{"epoch": 24, "training_loss": 2.6431693267822265, "training_acc": 47.0, "val_loss": 1.1112790679931641, "val_acc": 48.0}
{"epoch": 25, "training_loss": 1.5467062568664551, "training_acc": 43.0, "val_loss": 0.6980045533180237, "val_acc": 48.0}
{"epoch": 26, "training_loss": 0.827753005027771, "training_acc": 51.0, "val_loss": 1.144219195842743, "val_acc": 48.0}
{"epoch": 27, "training_loss": 1.2325952816009522, "training_acc": 47.0, "val_loss": 2.287636957168579, "val_acc": 52.0}
{"epoch": 28, "training_loss": 2.1591910457611085, "training_acc": 51.0, "val_loss": 1.17245370388031, "val_acc": 48.0}
{"epoch": 29, "training_loss": 1.1070395874977113, "training_acc": 51.0, "val_loss": 0.971742753982544, "val_acc": 48.0}
{"epoch": 30, "training_loss": 0.755978615283966, "training_acc": 47.0, "val_loss": 1.1456021213531493, "val_acc": 52.0}
{"epoch": 31, "training_loss": 0.9953047466278077, "training_acc": 49.0, "val_loss": 0.7084052658081055, "val_acc": 48.0}
{"epoch": 32, "training_loss": 1.4418489193916322, "training_acc": 43.0, "val_loss": 1.4552587795257568, "val_acc": 48.0}
