"main_modify.py --pretrained_path /scratch/connectome/dyhan316/VAE_ADHD/barlowtwins/pretrain_results/ABCDbt128a102.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option BT_org --learning_rate 1e-1 --batch_size 16 --weight_decay 1e-2 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 9.643120861053466, "training_acc": 53.0, "val_loss": 7.742856979370117, "val_acc": 52.0}
{"epoch": 1, "training_loss": 5.6172745895385745, "training_acc": 47.0, "val_loss": 4.48114013671875, "val_acc": 52.0}
{"epoch": 2, "training_loss": 4.835443038940429, "training_acc": 41.0, "val_loss": 6.4015214729309085, "val_acc": 52.0}
{"epoch": 3, "training_loss": 4.8633880710601805, "training_acc": 45.0, "val_loss": 0.7809358668327332, "val_acc": 52.0}
{"epoch": 4, "training_loss": 2.1082037830352784, "training_acc": 53.0, "val_loss": 1.178074426651001, "val_acc": 52.0}
{"epoch": 5, "training_loss": 1.3747203731536866, "training_acc": 49.0, "val_loss": 1.5118790292739868, "val_acc": 48.0}
{"epoch": 6, "training_loss": 1.6061616802215577, "training_acc": 39.0, "val_loss": 1.4674638509750366, "val_acc": 52.0}
{"epoch": 7, "training_loss": 2.4691163635253908, "training_acc": 47.0, "val_loss": 3.11807373046875, "val_acc": 48.0}
{"epoch": 8, "training_loss": 4.248364715576172, "training_acc": 47.0, "val_loss": 6.43547887802124, "val_acc": 52.0}
{"epoch": 9, "training_loss": 2.8216615211963654, "training_acc": 63.0, "val_loss": 3.858640441894531, "val_acc": 52.0}
{"epoch": 10, "training_loss": 3.411184024810791, "training_acc": 53.0, "val_loss": 5.732429809570313, "val_acc": 48.0}
{"epoch": 11, "training_loss": 5.987872724533081, "training_acc": 47.0, "val_loss": 3.438420286178589, "val_acc": 48.0}
{"epoch": 12, "training_loss": 3.859753806591034, "training_acc": 47.0, "val_loss": 0.8323829317092896, "val_acc": 52.0}
{"epoch": 13, "training_loss": 3.4436418533325197, "training_acc": 43.0, "val_loss": 2.6165870571136476, "val_acc": 52.0}
{"epoch": 14, "training_loss": 3.38202449798584, "training_acc": 47.0, "val_loss": 4.467982158660889, "val_acc": 52.0}
{"epoch": 15, "training_loss": 4.070456318855285, "training_acc": 35.0, "val_loss": 3.3252803230285646, "val_acc": 52.0}
{"epoch": 16, "training_loss": 2.3712360000610353, "training_acc": 47.0, "val_loss": 1.1545324993133546, "val_acc": 52.0}
{"epoch": 17, "training_loss": 1.562291703224182, "training_acc": 53.0, "val_loss": 0.8998124694824219, "val_acc": 52.0}
{"epoch": 18, "training_loss": 1.4140402698516845, "training_acc": 39.0, "val_loss": 0.8753170824050903, "val_acc": 48.0}
{"epoch": 19, "training_loss": 1.4133659458160401, "training_acc": 61.0, "val_loss": 1.22702805519104, "val_acc": 48.0}
{"epoch": 20, "training_loss": 1.0431983661651612, "training_acc": 45.0, "val_loss": 1.2060756874084473, "val_acc": 48.0}
{"epoch": 21, "training_loss": 0.9643520951271057, "training_acc": 49.0, "val_loss": 0.7140419888496399, "val_acc": 48.0}
{"epoch": 22, "training_loss": 1.1644717502593993, "training_acc": 49.0, "val_loss": 1.8364745140075684, "val_acc": 48.0}
{"epoch": 23, "training_loss": 1.6377720546722412, "training_acc": 49.0, "val_loss": 1.1094307398796082, "val_acc": 48.0}
{"epoch": 24, "training_loss": 2.645617685317993, "training_acc": 41.0, "val_loss": 1.252756004333496, "val_acc": 52.0}
{"epoch": 25, "training_loss": 1.9021441555023193, "training_acc": 47.0, "val_loss": 1.9297181749343872, "val_acc": 52.0}
{"epoch": 26, "training_loss": 1.300807499885559, "training_acc": 47.0, "val_loss": 0.8729765343666077, "val_acc": 52.0}
{"epoch": 27, "training_loss": 0.9419429612159729, "training_acc": 49.0, "val_loss": 0.7011210799217225, "val_acc": 52.0}
{"epoch": 28, "training_loss": 0.7101053261756897, "training_acc": 47.0, "val_loss": 0.7003484749794007, "val_acc": 48.0}
{"epoch": 29, "training_loss": 0.8785660076141357, "training_acc": 45.0, "val_loss": 2.3274321031570433, "val_acc": 48.0}
{"epoch": 30, "training_loss": 1.2060838294029237, "training_acc": 49.0, "val_loss": 0.6942752003669739, "val_acc": 48.0}
{"epoch": 31, "training_loss": 0.7580489873886108, "training_acc": 49.0, "val_loss": 0.6940144777297974, "val_acc": 48.0}
{"epoch": 32, "training_loss": 0.7350036430358887, "training_acc": 53.0, "val_loss": 1.2881230473518372, "val_acc": 52.0}
{"epoch": 33, "training_loss": 1.067592363357544, "training_acc": 57.0, "val_loss": 2.633469820022583, "val_acc": 48.0}
{"epoch": 34, "training_loss": 2.5240592908859254, "training_acc": 49.0, "val_loss": 1.054111862182617, "val_acc": 48.0}
{"epoch": 35, "training_loss": 0.9039948511123658, "training_acc": 47.0, "val_loss": 1.2668036580085755, "val_acc": 52.0}
{"epoch": 36, "training_loss": 1.326659460067749, "training_acc": 45.0, "val_loss": 1.6054655170440675, "val_acc": 52.0}
{"epoch": 37, "training_loss": 1.139818139076233, "training_acc": 59.0, "val_loss": 0.834163019657135, "val_acc": 48.0}
{"epoch": 38, "training_loss": 0.8887826561927795, "training_acc": 51.0, "val_loss": 0.7294162797927857, "val_acc": 48.0}
{"epoch": 39, "training_loss": 1.0214528512954713, "training_acc": 47.0, "val_loss": 2.5061171531677244, "val_acc": 52.0}
{"epoch": 40, "training_loss": 3.3079453974962236, "training_acc": 47.0, "val_loss": 6.001017780303955, "val_acc": 52.0}
{"epoch": 41, "training_loss": 4.457263251245021, "training_acc": 51.0, "val_loss": 0.8223668003082275, "val_acc": 48.0}
{"epoch": 42, "training_loss": 0.8912718939781189, "training_acc": 51.0, "val_loss": 1.0468296813964844, "val_acc": 52.0}
{"epoch": 43, "training_loss": 1.1413302421569824, "training_acc": 43.0, "val_loss": 0.9658533143997192, "val_acc": 48.0}
{"epoch": 44, "training_loss": 0.9795618462562561, "training_acc": 53.0, "val_loss": 0.8877195072174072, "val_acc": 52.0}
{"epoch": 45, "training_loss": 0.9409994864463807, "training_acc": 51.0, "val_loss": 1.6351452493667602, "val_acc": 52.0}
{"epoch": 46, "training_loss": 1.2123533225059508, "training_acc": 49.0, "val_loss": 0.7091592907905578, "val_acc": 48.0}
{"epoch": 47, "training_loss": 0.9818893122673035, "training_acc": 51.0, "val_loss": 2.1050894165039065, "val_acc": 48.0}
{"epoch": 48, "training_loss": 1.9985846281051636, "training_acc": 39.0, "val_loss": 0.7497438931465149, "val_acc": 52.0}
{"epoch": 49, "training_loss": 1.1420894193649291, "training_acc": 53.0, "val_loss": 1.0783542680740357, "val_acc": 48.0}
{"epoch": 50, "training_loss": 1.4851652765274048, "training_acc": 45.0, "val_loss": 1.0736371779441833, "val_acc": 48.0}
