"main_modify.py --pretrained_path /scratch/connectome/dyhan316/VAE_ADHD/barlowtwins/pretrain_results/ABCDbt128a102.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 2 --task ABCD_sex --input_option BT_org --learning_rate 1e-1 --batch_size 16 --weight_decay 1e-2 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 12.15259391784668, "training_acc": 47.0, "val_loss": 12.153114509582519, "val_acc": 52.0}
{"epoch": 1, "training_loss": 7.675170888900757, "training_acc": 51.0, "val_loss": 0.9409348726272583, "val_acc": 48.0}
{"epoch": 2, "training_loss": 3.3316587829589843, "training_acc": 51.0, "val_loss": 4.059364833831787, "val_acc": 48.0}
{"epoch": 3, "training_loss": 2.255440320968628, "training_acc": 55.0, "val_loss": 0.9783628034591675, "val_acc": 48.0}
{"epoch": 4, "training_loss": 0.8829975700378419, "training_acc": 53.0, "val_loss": 0.7593559741973877, "val_acc": 52.0}
{"epoch": 5, "training_loss": 1.2867628264427184, "training_acc": 51.0, "val_loss": 3.242581777572632, "val_acc": 48.0}
{"epoch": 6, "training_loss": 1.4970437049865724, "training_acc": 55.0, "val_loss": 1.8541429042816162, "val_acc": 52.0}
{"epoch": 7, "training_loss": 1.094839210510254, "training_acc": 57.0, "val_loss": 1.0153961324691771, "val_acc": 48.0}
{"epoch": 8, "training_loss": 1.0836859607696534, "training_acc": 43.0, "val_loss": 1.795154709815979, "val_acc": 48.0}
{"epoch": 9, "training_loss": 1.342112820148468, "training_acc": 53.0, "val_loss": 1.9759718894958496, "val_acc": 52.0}
{"epoch": 10, "training_loss": 1.616143114566803, "training_acc": 53.0, "val_loss": 1.4367176151275636, "val_acc": 48.0}
{"epoch": 11, "training_loss": 1.1188282704353332, "training_acc": 51.0, "val_loss": 0.7326985597610474, "val_acc": 48.0}
{"epoch": 12, "training_loss": 1.2883638906478883, "training_acc": 57.0, "val_loss": 1.980548849105835, "val_acc": 48.0}
{"epoch": 13, "training_loss": 1.2478086948394775, "training_acc": 53.0, "val_loss": 0.862734956741333, "val_acc": 52.0}
{"epoch": 14, "training_loss": 0.9923742389678956, "training_acc": 51.0, "val_loss": 1.780566964149475, "val_acc": 52.0}
{"epoch": 15, "training_loss": 1.0624594497680664, "training_acc": 47.0, "val_loss": 1.0776304721832275, "val_acc": 48.0}
{"epoch": 16, "training_loss": 1.0442517518997192, "training_acc": 47.0, "val_loss": 1.083402795791626, "val_acc": 52.0}
{"epoch": 17, "training_loss": 1.3183223724365234, "training_acc": 53.0, "val_loss": 0.707722897529602, "val_acc": 52.0}
{"epoch": 18, "training_loss": 1.2638555455207825, "training_acc": 55.0, "val_loss": 0.9072806668281556, "val_acc": 48.0}
{"epoch": 19, "training_loss": 1.7376417422294617, "training_acc": 47.0, "val_loss": 1.478903512954712, "val_acc": 52.0}
{"epoch": 20, "training_loss": 2.0971638202667235, "training_acc": 47.0, "val_loss": 2.4941562366485597, "val_acc": 48.0}
{"epoch": 21, "training_loss": 3.0782769870758058, "training_acc": 43.0, "val_loss": 2.7613123989105226, "val_acc": 48.0}
{"epoch": 22, "training_loss": 2.150014390945435, "training_acc": 53.0, "val_loss": 2.3100905323028567, "val_acc": 48.0}
{"epoch": 23, "training_loss": 1.374311170578003, "training_acc": 53.0, "val_loss": 0.7138183569908142, "val_acc": 52.0}
{"epoch": 24, "training_loss": 1.0867092657089232, "training_acc": 45.0, "val_loss": 0.8104445004463195, "val_acc": 48.0}
{"epoch": 25, "training_loss": 1.385188223719597, "training_acc": 51.0, "val_loss": 2.608175935745239, "val_acc": 52.0}
{"epoch": 26, "training_loss": 1.2522409224510194, "training_acc": 49.0, "val_loss": 0.9699512600898743, "val_acc": 52.0}
{"epoch": 27, "training_loss": 0.9418455648422241, "training_acc": 57.0, "val_loss": 2.1049152851104735, "val_acc": 52.0}
{"epoch": 28, "training_loss": 1.0599024200439453, "training_acc": 55.0, "val_loss": 2.365174722671509, "val_acc": 48.0}
{"epoch": 29, "training_loss": 1.4385595226287842, "training_acc": 47.0, "val_loss": 1.4491180825233458, "val_acc": 52.0}
{"epoch": 30, "training_loss": 0.9451180648803711, "training_acc": 53.0, "val_loss": 0.744922513961792, "val_acc": 48.0}
{"epoch": 31, "training_loss": 0.924176435470581, "training_acc": 51.0, "val_loss": 0.947327914237976, "val_acc": 48.0}
{"epoch": 32, "training_loss": 1.7919062876701355, "training_acc": 45.0, "val_loss": 0.6996862745285034, "val_acc": 52.0}
{"epoch": 33, "training_loss": 1.1937984466552733, "training_acc": 51.0, "val_loss": 4.35213773727417, "val_acc": 52.0}
{"epoch": 34, "training_loss": 2.740644459724426, "training_acc": 51.0, "val_loss": 4.973433046340943, "val_acc": 52.0}
{"epoch": 35, "training_loss": 3.669714150428772, "training_acc": 53.0, "val_loss": 2.3957302570343018, "val_acc": 52.0}
{"epoch": 36, "training_loss": 2.073639442920685, "training_acc": 45.0, "val_loss": 4.479260559082031, "val_acc": 48.0}
{"epoch": 37, "training_loss": 4.0743638610839845, "training_acc": 45.0, "val_loss": 6.500717525482178, "val_acc": 48.0}
{"epoch": 38, "training_loss": 7.061615409851075, "training_acc": 45.0, "val_loss": 9.463603420257568, "val_acc": 52.0}
{"epoch": 39, "training_loss": 6.060501601696014, "training_acc": 45.0, "val_loss": 2.9764106178283694, "val_acc": 52.0}
{"epoch": 40, "training_loss": 2.1019893217086794, "training_acc": 51.0, "val_loss": 4.2057764434814455, "val_acc": 52.0}
{"epoch": 41, "training_loss": 3.099103817939758, "training_acc": 51.0, "val_loss": 2.2412931156158447, "val_acc": 52.0}
{"epoch": 42, "training_loss": 1.8720021438598633, "training_acc": 45.0, "val_loss": 1.4009148216247558, "val_acc": 48.0}
{"epoch": 43, "training_loss": 1.1133998441696167, "training_acc": 59.0, "val_loss": 0.7410675930976868, "val_acc": 52.0}
{"epoch": 44, "training_loss": 0.8168798696994781, "training_acc": 53.0, "val_loss": 3.390151329040527, "val_acc": 48.0}
{"epoch": 45, "training_loss": 3.1215376663208008, "training_acc": 41.0, "val_loss": 0.796639552116394, "val_acc": 48.0}
{"epoch": 46, "training_loss": 4.318652324676513, "training_acc": 45.0, "val_loss": 5.559458885192871, "val_acc": 48.0}
{"epoch": 47, "training_loss": 4.880678672790527, "training_acc": 47.0, "val_loss": 2.1906124353408813, "val_acc": 48.0}
{"epoch": 48, "training_loss": 2.0111556959152224, "training_acc": 53.0, "val_loss": 3.2705138397216795, "val_acc": 48.0}
{"epoch": 49, "training_loss": 2.677448043823242, "training_acc": 49.0, "val_loss": 1.6671348428726196, "val_acc": 48.0}
{"epoch": 50, "training_loss": 1.0297743391990661, "training_acc": 53.0, "val_loss": 0.968480339050293, "val_acc": 52.0}
{"epoch": 51, "training_loss": 1.1773441648483276, "training_acc": 45.0, "val_loss": 1.6311501026153565, "val_acc": 52.0}
