"main_modify.py --pretrained_path /scratch/connectome/dyhan316/VAE_ADHD/barlowtwins/pretrain_results/ABCDbt128a102.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 1 --task ABCD_sex --input_option BT_org --learning_rate 1e-1 --batch_size 16 --weight_decay 1e-2 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 13.727313480377198, "training_acc": 44.0, "val_loss": 12.027254066467286, "val_acc": 52.0}
{"epoch": 1, "training_loss": 10.80142936706543, "training_acc": 47.0, "val_loss": 6.949843215942383, "val_acc": 48.0}
{"epoch": 2, "training_loss": 5.7990604019165035, "training_acc": 43.0, "val_loss": 5.716525115966797, "val_acc": 52.0}
{"epoch": 3, "training_loss": 3.364874591827393, "training_acc": 45.0, "val_loss": 1.8560196542739869, "val_acc": 48.0}
{"epoch": 4, "training_loss": 1.866753225326538, "training_acc": 47.0, "val_loss": 1.0952948236465454, "val_acc": 52.0}
{"epoch": 5, "training_loss": 1.4918098449707031, "training_acc": 49.0, "val_loss": 2.7567036628723143, "val_acc": 48.0}
{"epoch": 6, "training_loss": 2.7258102798461916, "training_acc": 49.0, "val_loss": 0.8294067478179932, "val_acc": 48.0}
{"epoch": 7, "training_loss": 1.543852653503418, "training_acc": 55.0, "val_loss": 2.162594337463379, "val_acc": 48.0}
{"epoch": 8, "training_loss": 1.0381502723693847, "training_acc": 49.0, "val_loss": 0.9484153413772582, "val_acc": 48.0}
{"epoch": 9, "training_loss": 1.005324604511261, "training_acc": 53.0, "val_loss": 0.7011773610115051, "val_acc": 52.0}
{"epoch": 10, "training_loss": 0.8126019668579102, "training_acc": 49.0, "val_loss": 1.0272417998313903, "val_acc": 52.0}
{"epoch": 11, "training_loss": 2.1845744705200194, "training_acc": 47.0, "val_loss": 4.125387525558471, "val_acc": 48.0}
{"epoch": 12, "training_loss": 3.894152946472168, "training_acc": 35.0, "val_loss": 1.4287198066711426, "val_acc": 48.0}
{"epoch": 13, "training_loss": 3.199889087677002, "training_acc": 47.0, "val_loss": 0.7072543835639954, "val_acc": 52.0}
{"epoch": 14, "training_loss": 1.1660053133964539, "training_acc": 57.0, "val_loss": 2.926361074447632, "val_acc": 52.0}
{"epoch": 15, "training_loss": 1.6001814270019532, "training_acc": 51.0, "val_loss": 1.5288913011550904, "val_acc": 48.0}
{"epoch": 16, "training_loss": 1.1906331157684327, "training_acc": 49.0, "val_loss": 0.7765042209625244, "val_acc": 52.0}
{"epoch": 17, "training_loss": 1.4038540935516357, "training_acc": 51.0, "val_loss": 0.6934821701049805, "val_acc": 52.0}
{"epoch": 18, "training_loss": 1.3311483764648437, "training_acc": 49.0, "val_loss": 3.143105535507202, "val_acc": 52.0}
{"epoch": 19, "training_loss": 2.1759521555900574, "training_acc": 39.0, "val_loss": 1.178946976661682, "val_acc": 48.0}
{"epoch": 20, "training_loss": 1.022892119884491, "training_acc": 43.0, "val_loss": 0.7047735023498535, "val_acc": 48.0}
{"epoch": 21, "training_loss": 0.932680344581604, "training_acc": 51.0, "val_loss": 3.0124315547943117, "val_acc": 48.0}
{"epoch": 22, "training_loss": 2.0041066551208497, "training_acc": 53.0, "val_loss": 0.700011785030365, "val_acc": 48.0}
{"epoch": 23, "training_loss": 1.0074924564361571, "training_acc": 45.0, "val_loss": 1.5838982391357421, "val_acc": 52.0}
{"epoch": 24, "training_loss": 1.5055944967269896, "training_acc": 55.0, "val_loss": 0.9812629389762878, "val_acc": 52.0}
{"epoch": 25, "training_loss": 0.9984925866127015, "training_acc": 57.0, "val_loss": 1.0381998538970947, "val_acc": 52.0}
{"epoch": 26, "training_loss": 1.4602488470077515, "training_acc": 49.0, "val_loss": 3.1272753524780272, "val_acc": 48.0}
{"epoch": 27, "training_loss": 2.0480164098739624, "training_acc": 45.0, "val_loss": 1.9852984714508057, "val_acc": 52.0}
{"epoch": 28, "training_loss": 1.2589160108566284, "training_acc": 57.0, "val_loss": 1.70519446849823, "val_acc": 48.0}
{"epoch": 29, "training_loss": 1.3489401960372924, "training_acc": 57.0, "val_loss": 0.9117489981651307, "val_acc": 48.0}
{"epoch": 30, "training_loss": 0.8608468270301819, "training_acc": 47.0, "val_loss": 1.6096339464187621, "val_acc": 52.0}
{"epoch": 31, "training_loss": 1.1664772033691406, "training_acc": 39.0, "val_loss": 0.946863329410553, "val_acc": 48.0}
{"epoch": 32, "training_loss": 1.3334639835357667, "training_acc": 51.0, "val_loss": 1.6447128391265868, "val_acc": 52.0}
{"epoch": 33, "training_loss": 1.2317279720306396, "training_acc": 49.0, "val_loss": 0.7803052830696106, "val_acc": 48.0}
{"epoch": 34, "training_loss": 1.5563373804092406, "training_acc": 49.0, "val_loss": 1.0781381034851074, "val_acc": 52.0}
{"epoch": 35, "training_loss": 1.5173982238769532, "training_acc": 55.0, "val_loss": 1.4169230556488037, "val_acc": 52.0}
{"epoch": 36, "training_loss": 3.599147844314575, "training_acc": 43.0, "val_loss": 0.7063617300987244, "val_acc": 48.0}
