"main_modify.py --pretrained_path /scratch/connectome/dyhan316/VAE_ADHD/barlowtwins/pretrain_results/ABCDbt128a102.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 1 --task ABCD_sex --input_option BT_org --learning_rate 1e-1 --batch_size 16 --weight_decay 1e-2 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 11.154750347137451, "training_acc": 49.0, "val_loss": 3.2596046352386474, "val_acc": 48.0}
{"epoch": 1, "training_loss": 6.367000217437744, "training_acc": 53.0, "val_loss": 1.8397178649902344, "val_acc": 52.0}
{"epoch": 2, "training_loss": 2.7179570484161375, "training_acc": 49.0, "val_loss": 1.3224816513061524, "val_acc": 52.0}
{"epoch": 3, "training_loss": 1.1747587537765503, "training_acc": 44.0, "val_loss": 1.1281938171386718, "val_acc": 48.0}
{"epoch": 4, "training_loss": 0.8536126947402954, "training_acc": 51.0, "val_loss": 1.019340615272522, "val_acc": 52.0}
{"epoch": 5, "training_loss": 1.726070909500122, "training_acc": 43.0, "val_loss": 3.731620388031006, "val_acc": 52.0}
{"epoch": 6, "training_loss": 3.742814404964447, "training_acc": 51.0, "val_loss": 4.081677141189576, "val_acc": 52.0}
{"epoch": 7, "training_loss": 5.2519848442077635, "training_acc": 49.0, "val_loss": 2.3070053958892824, "val_acc": 48.0}
{"epoch": 8, "training_loss": 4.41635498046875, "training_acc": 45.0, "val_loss": 0.6937277412414551, "val_acc": 52.0}
{"epoch": 9, "training_loss": 2.2469625282287597, "training_acc": 47.0, "val_loss": 3.833548412322998, "val_acc": 52.0}
{"epoch": 10, "training_loss": 2.217534122467041, "training_acc": 53.0, "val_loss": 0.9859008884429932, "val_acc": 48.0}
{"epoch": 11, "training_loss": 1.5886231899261474, "training_acc": 53.0, "val_loss": 1.919914617538452, "val_acc": 48.0}
{"epoch": 12, "training_loss": 2.5685349178314207, "training_acc": 47.0, "val_loss": 1.9154697227478028, "val_acc": 52.0}
{"epoch": 13, "training_loss": 1.9283542895317078, "training_acc": 47.0, "val_loss": 1.4100369358062743, "val_acc": 48.0}
{"epoch": 14, "training_loss": 1.6185111474990845, "training_acc": 47.0, "val_loss": 1.881951141357422, "val_acc": 52.0}
{"epoch": 15, "training_loss": 2.304263515472412, "training_acc": 41.0, "val_loss": 1.4840073585510254, "val_acc": 48.0}
{"epoch": 16, "training_loss": 1.366335163116455, "training_acc": 45.0, "val_loss": 1.125361406803131, "val_acc": 48.0}
{"epoch": 17, "training_loss": 0.8987086296081543, "training_acc": 45.0, "val_loss": 0.8098214149475098, "val_acc": 48.0}
{"epoch": 18, "training_loss": 1.1362818241119386, "training_acc": 39.0, "val_loss": 0.7310546588897705, "val_acc": 52.0}
{"epoch": 19, "training_loss": 1.0165766072273255, "training_acc": 51.0, "val_loss": 1.2444542169570922, "val_acc": 48.0}
{"epoch": 20, "training_loss": 1.1668482446670532, "training_acc": 49.0, "val_loss": 0.8395258402824402, "val_acc": 52.0}
{"epoch": 21, "training_loss": 0.8406930494308472, "training_acc": 59.0, "val_loss": 1.719744782447815, "val_acc": 48.0}
{"epoch": 22, "training_loss": 1.3680613040924072, "training_acc": 49.0, "val_loss": 2.5046532917022706, "val_acc": 52.0}
{"epoch": 23, "training_loss": 1.628922414779663, "training_acc": 47.0, "val_loss": 0.7011819648742675, "val_acc": 48.0}
{"epoch": 24, "training_loss": 2.161310091018677, "training_acc": 53.0, "val_loss": 1.268287787437439, "val_acc": 48.0}
{"epoch": 25, "training_loss": 3.1486997032165527, "training_acc": 51.0, "val_loss": 3.489254550933838, "val_acc": 48.0}
{"epoch": 26, "training_loss": 1.9355774116516113, "training_acc": 59.0, "val_loss": 0.9895318365097046, "val_acc": 48.0}
{"epoch": 27, "training_loss": 1.4228560376167296, "training_acc": 53.0, "val_loss": 0.6943467330932617, "val_acc": 48.0}
