"main_modify.py --pretrained_path /scratch/connectome/dyhan316/VAE_ADHD/barlowtwins/pretrain_results/ABCDbt128a102.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 1 --task ABCD_sex --input_option BT_org --learning_rate 1e-1 --batch_size 16 --weight_decay 1e-2 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 7.912525186538696, "training_acc": 51.0, "val_loss": 16.837028579711912, "val_acc": 48.0}
{"epoch": 1, "training_loss": 11.10022933959961, "training_acc": 49.0, "val_loss": 13.222068367004395, "val_acc": 52.0}
{"epoch": 2, "training_loss": 6.035034456253052, "training_acc": 49.0, "val_loss": 5.963771858215332, "val_acc": 48.0}
{"epoch": 3, "training_loss": 5.935295114517212, "training_acc": 49.0, "val_loss": 4.873763980865479, "val_acc": 52.0}
{"epoch": 4, "training_loss": 4.15172532081604, "training_acc": 47.0, "val_loss": 5.9425161170959475, "val_acc": 52.0}
{"epoch": 5, "training_loss": 2.8618745517730715, "training_acc": 47.0, "val_loss": 0.7125282979011536, "val_acc": 52.0}
{"epoch": 6, "training_loss": 2.2629747104644777, "training_acc": 49.0, "val_loss": 1.7241311883926391, "val_acc": 52.0}
{"epoch": 7, "training_loss": 1.6379496192932128, "training_acc": 49.0, "val_loss": 0.7024886703491211, "val_acc": 52.0}
{"epoch": 8, "training_loss": 0.8440486764907837, "training_acc": 51.0, "val_loss": 0.7039622068405151, "val_acc": 48.0}
{"epoch": 9, "training_loss": 0.9125020694732666, "training_acc": 51.0, "val_loss": 0.6927350640296936, "val_acc": 52.0}
{"epoch": 10, "training_loss": 0.8876301550865173, "training_acc": 52.0, "val_loss": 0.9582327318191528, "val_acc": 52.0}
{"epoch": 11, "training_loss": 0.843260464668274, "training_acc": 47.0, "val_loss": 3.062658987045288, "val_acc": 48.0}
{"epoch": 12, "training_loss": 2.7845592975616453, "training_acc": 55.0, "val_loss": 2.433031759262085, "val_acc": 48.0}
{"epoch": 13, "training_loss": 1.2938079929351807, "training_acc": 45.0, "val_loss": 0.7034555053710938, "val_acc": 52.0}
{"epoch": 14, "training_loss": 0.8079573822021484, "training_acc": 55.0, "val_loss": 0.9927322316169739, "val_acc": 48.0}
{"epoch": 15, "training_loss": 0.8953647804260254, "training_acc": 49.0, "val_loss": 0.715733425617218, "val_acc": 48.0}
{"epoch": 16, "training_loss": 1.4121463775634766, "training_acc": 49.0, "val_loss": 0.6987635898590088, "val_acc": 48.0}
{"epoch": 17, "training_loss": 1.5946305561065675, "training_acc": 47.0, "val_loss": 0.6955067396163941, "val_acc": 48.0}
{"epoch": 18, "training_loss": 1.9534291124343872, "training_acc": 44.0, "val_loss": 1.2674555444717408, "val_acc": 52.0}
{"epoch": 19, "training_loss": 1.3010845685005188, "training_acc": 45.0, "val_loss": 0.7994940900802612, "val_acc": 48.0}
{"epoch": 20, "training_loss": 0.9611711311340332, "training_acc": 53.0, "val_loss": 0.7352748417854309, "val_acc": 48.0}
{"epoch": 21, "training_loss": 0.9584601020812988, "training_acc": 47.0, "val_loss": 1.4011449384689332, "val_acc": 52.0}
{"epoch": 22, "training_loss": 1.0294408893585205, "training_acc": 57.0, "val_loss": 0.7013447523117066, "val_acc": 48.0}
{"epoch": 23, "training_loss": 1.1884784078598023, "training_acc": 43.0, "val_loss": 1.0662210512161254, "val_acc": 52.0}
{"epoch": 24, "training_loss": 1.5628424167633057, "training_acc": 53.0, "val_loss": 1.6429609155654907, "val_acc": 48.0}
{"epoch": 25, "training_loss": 1.3209344053268433, "training_acc": 46.0, "val_loss": 0.8890467166900635, "val_acc": 48.0}
{"epoch": 26, "training_loss": 1.616948928833008, "training_acc": 42.0, "val_loss": 0.911414954662323, "val_acc": 48.0}
{"epoch": 27, "training_loss": 1.5214894580841065, "training_acc": 45.0, "val_loss": 2.014916603565216, "val_acc": 52.0}
{"epoch": 28, "training_loss": 2.1213408160209655, "training_acc": 47.0, "val_loss": 1.4957342386245727, "val_acc": 48.0}
