"main_modify.py --pretrained_path /scratch/connectome/dyhan316/VAE_ADHD/barlowtwins/pretrain_results/ABCDbt128a102.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 2 --task ABCD_sex --input_option BT_org --learning_rate 1e-6 --batch_size 16 --weight_decay 1e-2 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 0.692811906337738, "training_acc": 53.0, "val_loss": 0.6971696209907532, "val_acc": 52.0}
{"epoch": 1, "training_loss": 0.6918649792671203, "training_acc": 53.0, "val_loss": 0.6968965816497803, "val_acc": 52.0}
{"epoch": 2, "training_loss": 0.6918246912956237, "training_acc": 53.0, "val_loss": 0.6963463473320007, "val_acc": 52.0}
{"epoch": 3, "training_loss": 0.691662712097168, "training_acc": 53.0, "val_loss": 0.6960420989990235, "val_acc": 52.0}
{"epoch": 4, "training_loss": 0.6912901544570923, "training_acc": 53.0, "val_loss": 0.6955760955810547, "val_acc": 52.0}
{"epoch": 5, "training_loss": 0.690790228843689, "training_acc": 53.0, "val_loss": 0.6957833075523376, "val_acc": 52.0}
{"epoch": 6, "training_loss": 0.6904121017456055, "training_acc": 53.0, "val_loss": 0.6970040822029113, "val_acc": 52.0}
{"epoch": 7, "training_loss": 0.690457992553711, "training_acc": 53.0, "val_loss": 0.696957893371582, "val_acc": 52.0}
{"epoch": 8, "training_loss": 0.6898238253593445, "training_acc": 53.0, "val_loss": 0.6968447232246399, "val_acc": 52.0}
{"epoch": 9, "training_loss": 0.6901799869537354, "training_acc": 53.0, "val_loss": 0.6959888911247254, "val_acc": 52.0}
{"epoch": 10, "training_loss": 0.6906691360473632, "training_acc": 53.0, "val_loss": 0.6961217904090882, "val_acc": 52.0}
{"epoch": 11, "training_loss": 0.6896745872497558, "training_acc": 53.0, "val_loss": 0.6962080407142639, "val_acc": 52.0}
{"epoch": 12, "training_loss": 0.6894068241119384, "training_acc": 53.0, "val_loss": 0.6954300808906555, "val_acc": 52.0}
{"epoch": 13, "training_loss": 0.6894725942611695, "training_acc": 53.0, "val_loss": 0.6954239010810852, "val_acc": 52.0}
{"epoch": 14, "training_loss": 0.6902648019790649, "training_acc": 53.0, "val_loss": 0.6960841131210327, "val_acc": 52.0}
{"epoch": 15, "training_loss": 0.6888172554969788, "training_acc": 53.0, "val_loss": 0.6960102844238282, "val_acc": 52.0}
{"epoch": 16, "training_loss": 0.6889803576469421, "training_acc": 53.0, "val_loss": 0.6961345410346985, "val_acc": 52.0}
{"epoch": 17, "training_loss": 0.6888125228881836, "training_acc": 53.0, "val_loss": 0.695533595085144, "val_acc": 52.0}
{"epoch": 18, "training_loss": 0.6884923124313355, "training_acc": 53.0, "val_loss": 0.6952727174758911, "val_acc": 52.0}
{"epoch": 19, "training_loss": 0.6887154388427734, "training_acc": 53.0, "val_loss": 0.6955040454864502, "val_acc": 52.0}
{"epoch": 20, "training_loss": 0.6889741611480713, "training_acc": 53.0, "val_loss": 0.6957162213325501, "val_acc": 52.0}
{"epoch": 21, "training_loss": 0.6877125167846679, "training_acc": 53.0, "val_loss": 0.6961822915077209, "val_acc": 52.0}
{"epoch": 22, "training_loss": 0.6882957005500794, "training_acc": 53.0, "val_loss": 0.6951961374282837, "val_acc": 52.0}
{"epoch": 23, "training_loss": 0.6877113842964172, "training_acc": 53.0, "val_loss": 0.6948664116859437, "val_acc": 52.0}
{"epoch": 24, "training_loss": 0.6873773384094238, "training_acc": 53.0, "val_loss": 0.695149929523468, "val_acc": 52.0}
{"epoch": 25, "training_loss": 0.6874888229370117, "training_acc": 53.0, "val_loss": 0.6959452152252197, "val_acc": 52.0}
{"epoch": 26, "training_loss": 0.6873828244209289, "training_acc": 53.0, "val_loss": 0.6954116749763489, "val_acc": 52.0}
{"epoch": 27, "training_loss": 0.6868044781684876, "training_acc": 53.0, "val_loss": 0.6953821921348572, "val_acc": 52.0}
{"epoch": 28, "training_loss": 0.6865328502655029, "training_acc": 53.0, "val_loss": 0.6951941633224488, "val_acc": 52.0}
{"epoch": 29, "training_loss": 0.6868540811538696, "training_acc": 53.0, "val_loss": 0.6957531714439392, "val_acc": 52.0}
{"epoch": 30, "training_loss": 0.6864247941970825, "training_acc": 53.0, "val_loss": 0.6950361800193786, "val_acc": 52.0}
{"epoch": 31, "training_loss": 0.6865289664268494, "training_acc": 53.0, "val_loss": 0.6947211337089538, "val_acc": 52.0}
{"epoch": 32, "training_loss": 0.6858862209320068, "training_acc": 53.0, "val_loss": 0.6951407957077026, "val_acc": 52.0}
{"epoch": 33, "training_loss": 0.6860767030715942, "training_acc": 53.0, "val_loss": 0.6950993037223816, "val_acc": 52.0}
{"epoch": 34, "training_loss": 0.6856270289421081, "training_acc": 53.0, "val_loss": 0.6952159953117371, "val_acc": 52.0}
{"epoch": 35, "training_loss": 0.6865151143074035, "training_acc": 53.0, "val_loss": 0.6951441049575806, "val_acc": 52.0}
{"epoch": 36, "training_loss": 0.6860430312156677, "training_acc": 53.0, "val_loss": 0.6941648387908935, "val_acc": 52.0}
{"epoch": 37, "training_loss": 0.685961844921112, "training_acc": 53.0, "val_loss": 0.6951846408843995, "val_acc": 52.0}
{"epoch": 38, "training_loss": 0.6851897358894348, "training_acc": 53.0, "val_loss": 0.6953405499458313, "val_acc": 52.0}
{"epoch": 39, "training_loss": 0.6845666265487671, "training_acc": 53.0, "val_loss": 0.6945481562614441, "val_acc": 52.0}
{"epoch": 40, "training_loss": 0.6849006462097168, "training_acc": 53.0, "val_loss": 0.6948908710479736, "val_acc": 52.0}
{"epoch": 41, "training_loss": 0.6846158194541931, "training_acc": 53.0, "val_loss": 0.6950660681724549, "val_acc": 52.0}
{"epoch": 42, "training_loss": 0.6849690222740173, "training_acc": 53.0, "val_loss": 0.6949140024185181, "val_acc": 52.0}
{"epoch": 43, "training_loss": 0.6842429947853088, "training_acc": 53.0, "val_loss": 0.6948568081855774, "val_acc": 52.0}
{"epoch": 44, "training_loss": 0.6844817399978638, "training_acc": 53.0, "val_loss": 0.6952213788032532, "val_acc": 52.0}
{"epoch": 45, "training_loss": 0.683918833732605, "training_acc": 53.0, "val_loss": 0.6948716568946839, "val_acc": 52.0}
{"epoch": 46, "training_loss": 0.6837611961364746, "training_acc": 53.0, "val_loss": 0.6945934867858887, "val_acc": 52.0}
{"epoch": 47, "training_loss": 0.6833147168159485, "training_acc": 53.0, "val_loss": 0.6949752783775329, "val_acc": 52.0}
{"epoch": 48, "training_loss": 0.6840433549880981, "training_acc": 53.0, "val_loss": 0.6955599713325501, "val_acc": 52.0}
{"epoch": 49, "training_loss": 0.6834845066070556, "training_acc": 53.0, "val_loss": 0.6942401885986328, "val_acc": 52.0}
{"epoch": 50, "training_loss": 0.6833947658538818, "training_acc": 53.0, "val_loss": 0.6946988606452942, "val_acc": 52.0}
{"epoch": 51, "training_loss": 0.6836897921562195, "training_acc": 53.0, "val_loss": 0.6950992631912232, "val_acc": 52.0}
{"epoch": 52, "training_loss": 0.6837835550308228, "training_acc": 53.0, "val_loss": 0.6941838955879212, "val_acc": 52.0}
{"epoch": 53, "training_loss": 0.6834835147857666, "training_acc": 53.0, "val_loss": 0.6941024398803711, "val_acc": 52.0}
{"epoch": 54, "training_loss": 0.6828956174850463, "training_acc": 53.0, "val_loss": 0.6946027493476867, "val_acc": 52.0}
{"epoch": 55, "training_loss": 0.6831621599197387, "training_acc": 53.0, "val_loss": 0.6947094273567199, "val_acc": 52.0}
{"epoch": 56, "training_loss": 0.6822172713279724, "training_acc": 53.0, "val_loss": 0.6941329288482666, "val_acc": 52.0}
{"epoch": 57, "training_loss": 0.6823315048217773, "training_acc": 53.0, "val_loss": 0.6943381118774414, "val_acc": 52.0}
{"epoch": 58, "training_loss": 0.6824727821350097, "training_acc": 53.0, "val_loss": 0.6950694680213928, "val_acc": 52.0}
{"epoch": 59, "training_loss": 0.6827672624588013, "training_acc": 53.0, "val_loss": 0.6939524912834167, "val_acc": 52.0}
{"epoch": 60, "training_loss": 0.681197214126587, "training_acc": 53.0, "val_loss": 0.6943800354003906, "val_acc": 52.0}
{"epoch": 61, "training_loss": 0.6817768883705139, "training_acc": 53.0, "val_loss": 0.6946847486495972, "val_acc": 52.0}
{"epoch": 62, "training_loss": 0.6826501846313476, "training_acc": 53.0, "val_loss": 0.6944113945960999, "val_acc": 52.0}
{"epoch": 63, "training_loss": 0.6817335700988769, "training_acc": 53.0, "val_loss": 0.6942604541778564, "val_acc": 52.0}
{"epoch": 64, "training_loss": 0.6816117906570435, "training_acc": 53.0, "val_loss": 0.6949227166175842, "val_acc": 52.0}
{"epoch": 65, "training_loss": 0.6812045240402221, "training_acc": 53.0, "val_loss": 0.6939017581939697, "val_acc": 52.0}
{"epoch": 66, "training_loss": 0.681207902431488, "training_acc": 53.0, "val_loss": 0.6941594505310058, "val_acc": 52.0}
{"epoch": 67, "training_loss": 0.6802821373939514, "training_acc": 53.0, "val_loss": 0.6940642166137695, "val_acc": 52.0}
{"epoch": 68, "training_loss": 0.6810946941375733, "training_acc": 53.0, "val_loss": 0.6943085217475891, "val_acc": 52.0}
{"epoch": 69, "training_loss": 0.6809305047988892, "training_acc": 53.0, "val_loss": 0.6943341040611267, "val_acc": 52.0}
{"epoch": 70, "training_loss": 0.680525426864624, "training_acc": 53.0, "val_loss": 0.6942272186279297, "val_acc": 52.0}
{"epoch": 71, "training_loss": 0.6806772351264954, "training_acc": 53.0, "val_loss": 0.6949048686027527, "val_acc": 52.0}
{"epoch": 72, "training_loss": 0.6802408862113952, "training_acc": 53.0, "val_loss": 0.6939152932167053, "val_acc": 52.0}
{"epoch": 73, "training_loss": 0.6801054525375366, "training_acc": 53.0, "val_loss": 0.6939528393745422, "val_acc": 52.0}
{"epoch": 74, "training_loss": 0.6803050327301026, "training_acc": 53.0, "val_loss": 0.6943686747550964, "val_acc": 52.0}
{"epoch": 75, "training_loss": 0.6797020316123963, "training_acc": 53.0, "val_loss": 0.6937215733528137, "val_acc": 52.0}
{"epoch": 76, "training_loss": 0.6795845341682434, "training_acc": 53.0, "val_loss": 0.6941785860061646, "val_acc": 52.0}
{"epoch": 77, "training_loss": 0.6795014667510987, "training_acc": 53.0, "val_loss": 0.6943589234352112, "val_acc": 52.0}
{"epoch": 78, "training_loss": 0.6789319586753845, "training_acc": 53.0, "val_loss": 0.6939172625541687, "val_acc": 52.0}
{"epoch": 79, "training_loss": 0.6792833018302917, "training_acc": 53.0, "val_loss": 0.6942318701744079, "val_acc": 52.0}
{"epoch": 80, "training_loss": 0.6797763729095458, "training_acc": 53.0, "val_loss": 0.6944229578971863, "val_acc": 52.0}
{"epoch": 81, "training_loss": 0.6793837070465087, "training_acc": 53.0, "val_loss": 0.6934867119789123, "val_acc": 52.0}
{"epoch": 82, "training_loss": 0.6788573551177979, "training_acc": 53.0, "val_loss": 0.694149284362793, "val_acc": 52.0}
{"epoch": 83, "training_loss": 0.6785926008224488, "training_acc": 53.0, "val_loss": 0.6934948539733887, "val_acc": 52.0}
{"epoch": 84, "training_loss": 0.678685166835785, "training_acc": 53.0, "val_loss": 0.693801646232605, "val_acc": 52.0}
{"epoch": 85, "training_loss": 0.6787024235725403, "training_acc": 53.0, "val_loss": 0.6939771509170533, "val_acc": 52.0}
{"epoch": 86, "training_loss": 0.6778117036819458, "training_acc": 53.0, "val_loss": 0.6938218760490418, "val_acc": 52.0}
{"epoch": 87, "training_loss": 0.6778371238708496, "training_acc": 53.0, "val_loss": 0.694134418964386, "val_acc": 52.0}
{"epoch": 88, "training_loss": 0.6776116681098938, "training_acc": 53.0, "val_loss": 0.6936703777313232, "val_acc": 52.0}
{"epoch": 89, "training_loss": 0.6771816539764405, "training_acc": 53.0, "val_loss": 0.6940130090713501, "val_acc": 52.0}
{"epoch": 90, "training_loss": 0.6775974988937378, "training_acc": 53.0, "val_loss": 0.6934723448753357, "val_acc": 52.0}
{"epoch": 91, "training_loss": 0.6773236155509949, "training_acc": 53.0, "val_loss": 0.6936289167404175, "val_acc": 52.0}
{"epoch": 92, "training_loss": 0.6781393241882324, "training_acc": 53.0, "val_loss": 0.6941602015495301, "val_acc": 52.0}
{"epoch": 93, "training_loss": 0.6769690656661987, "training_acc": 53.0, "val_loss": 0.6934056091308594, "val_acc": 52.0}
{"epoch": 94, "training_loss": 0.6768704080581665, "training_acc": 53.0, "val_loss": 0.6936045527458191, "val_acc": 52.0}
{"epoch": 95, "training_loss": 0.6772146773338318, "training_acc": 53.0, "val_loss": 0.6933715772628785, "val_acc": 52.0}
{"epoch": 96, "training_loss": 0.6770296716690063, "training_acc": 53.0, "val_loss": 0.6938254594802856, "val_acc": 52.0}
{"epoch": 97, "training_loss": 0.6773933267593384, "training_acc": 53.0, "val_loss": 0.6939293599128723, "val_acc": 52.0}
{"epoch": 98, "training_loss": 0.6773063850402832, "training_acc": 53.0, "val_loss": 0.6933488416671753, "val_acc": 52.0}
{"epoch": 99, "training_loss": 0.67677978515625, "training_acc": 53.0, "val_loss": 0.6941148686408997, "val_acc": 52.0}
