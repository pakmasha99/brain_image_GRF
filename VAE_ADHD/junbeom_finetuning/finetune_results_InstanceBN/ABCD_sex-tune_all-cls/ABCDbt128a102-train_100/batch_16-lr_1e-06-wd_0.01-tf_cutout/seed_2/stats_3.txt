"main_modify.py --pretrained_path /scratch/connectome/dyhan316/VAE_ADHD/barlowtwins/pretrain_results/ABCDbt128a102.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 2 --task ABCD_sex --input_option BT_org --learning_rate 1e-6 --batch_size 16 --weight_decay 1e-2 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 0.6927252006530762, "training_acc": 54.0, "val_loss": 0.6896326661109924, "val_acc": 60.0}
{"epoch": 1, "training_loss": 0.6920319628715516, "training_acc": 51.0, "val_loss": 0.6897473478317261, "val_acc": 56.0}
{"epoch": 2, "training_loss": 0.6917752504348755, "training_acc": 52.0, "val_loss": 0.6897151899337769, "val_acc": 56.0}
{"epoch": 3, "training_loss": 0.691891770362854, "training_acc": 52.0, "val_loss": 0.6896255350112915, "val_acc": 56.0}
{"epoch": 4, "training_loss": 0.6913697671890259, "training_acc": 54.0, "val_loss": 0.6888887572288513, "val_acc": 60.0}
{"epoch": 5, "training_loss": 0.690804386138916, "training_acc": 54.0, "val_loss": 0.6884307050704956, "val_acc": 56.0}
{"epoch": 6, "training_loss": 0.6910647797584534, "training_acc": 53.0, "val_loss": 0.6880873990058899, "val_acc": 56.0}
{"epoch": 7, "training_loss": 0.6907055759429932, "training_acc": 55.0, "val_loss": 0.687915506362915, "val_acc": 56.0}
{"epoch": 8, "training_loss": 0.6907419896125794, "training_acc": 53.0, "val_loss": 0.6878315353393555, "val_acc": 56.0}
{"epoch": 9, "training_loss": 0.6901803016662598, "training_acc": 55.0, "val_loss": 0.6876167178153991, "val_acc": 56.0}
{"epoch": 10, "training_loss": 0.689698519706726, "training_acc": 54.0, "val_loss": 0.687665491104126, "val_acc": 56.0}
{"epoch": 11, "training_loss": 0.6897134780883789, "training_acc": 53.0, "val_loss": 0.687974009513855, "val_acc": 56.0}
{"epoch": 12, "training_loss": 0.6894324421882629, "training_acc": 53.0, "val_loss": 0.6871768283843994, "val_acc": 56.0}
{"epoch": 13, "training_loss": 0.6893971610069275, "training_acc": 56.0, "val_loss": 0.687029800415039, "val_acc": 56.0}
{"epoch": 14, "training_loss": 0.6899858593940735, "training_acc": 54.0, "val_loss": 0.6870573925971984, "val_acc": 56.0}
{"epoch": 15, "training_loss": 0.6886626052856445, "training_acc": 57.0, "val_loss": 0.6870292782783508, "val_acc": 56.0}
{"epoch": 16, "training_loss": 0.6889622950553894, "training_acc": 55.0, "val_loss": 0.6869808673858643, "val_acc": 56.0}
{"epoch": 17, "training_loss": 0.6885786867141723, "training_acc": 55.0, "val_loss": 0.6866173481941223, "val_acc": 56.0}
{"epoch": 18, "training_loss": 0.6887694859504699, "training_acc": 56.0, "val_loss": 0.6865158009529114, "val_acc": 56.0}
{"epoch": 19, "training_loss": 0.687908501625061, "training_acc": 55.0, "val_loss": 0.6866048407554627, "val_acc": 56.0}
{"epoch": 20, "training_loss": 0.68833899974823, "training_acc": 54.0, "val_loss": 0.6865765309333801, "val_acc": 56.0}
{"epoch": 21, "training_loss": 0.6876980686187744, "training_acc": 55.0, "val_loss": 0.6863446998596191, "val_acc": 56.0}
{"epoch": 22, "training_loss": 0.6877874994277954, "training_acc": 56.0, "val_loss": 0.6862154340744019, "val_acc": 56.0}
{"epoch": 23, "training_loss": 0.6871887564659118, "training_acc": 54.0, "val_loss": 0.6862725567817688, "val_acc": 56.0}
{"epoch": 24, "training_loss": 0.687126145362854, "training_acc": 55.0, "val_loss": 0.6863732075691223, "val_acc": 56.0}
{"epoch": 25, "training_loss": 0.6867108011245727, "training_acc": 57.0, "val_loss": 0.686051115989685, "val_acc": 56.0}
{"epoch": 26, "training_loss": 0.6868795394897461, "training_acc": 56.0, "val_loss": 0.685990104675293, "val_acc": 56.0}
{"epoch": 27, "training_loss": 0.6869066619873047, "training_acc": 57.0, "val_loss": 0.6859593963623047, "val_acc": 56.0}
{"epoch": 28, "training_loss": 0.6865281367301941, "training_acc": 56.0, "val_loss": 0.6859500408172607, "val_acc": 56.0}
{"epoch": 29, "training_loss": 0.686085867881775, "training_acc": 57.0, "val_loss": 0.6859990358352661, "val_acc": 56.0}
{"epoch": 30, "training_loss": 0.6863502025604248, "training_acc": 58.0, "val_loss": 0.685905122756958, "val_acc": 56.0}
{"epoch": 31, "training_loss": 0.686431941986084, "training_acc": 56.0, "val_loss": 0.6858798956871033, "val_acc": 56.0}
{"epoch": 32, "training_loss": 0.6861524176597595, "training_acc": 57.0, "val_loss": 0.6857197713851929, "val_acc": 56.0}
{"epoch": 33, "training_loss": 0.6857126927375794, "training_acc": 56.0, "val_loss": 0.6856847739219666, "val_acc": 56.0}
{"epoch": 34, "training_loss": 0.6851872873306274, "training_acc": 57.0, "val_loss": 0.6856607484817505, "val_acc": 56.0}
{"epoch": 35, "training_loss": 0.685489387512207, "training_acc": 57.0, "val_loss": 0.6855294084548951, "val_acc": 56.0}
{"epoch": 36, "training_loss": 0.6853368091583252, "training_acc": 58.0, "val_loss": 0.6854884672164917, "val_acc": 56.0}
{"epoch": 37, "training_loss": 0.6853269529342652, "training_acc": 56.0, "val_loss": 0.6854252743721009, "val_acc": 56.0}
{"epoch": 38, "training_loss": 0.6850056743621826, "training_acc": 59.0, "val_loss": 0.6854006266593933, "val_acc": 56.0}
{"epoch": 39, "training_loss": 0.6850988841056824, "training_acc": 56.0, "val_loss": 0.6853414273262024, "val_acc": 56.0}
{"epoch": 40, "training_loss": 0.6847585964202881, "training_acc": 57.0, "val_loss": 0.6852034568786621, "val_acc": 56.0}
{"epoch": 41, "training_loss": 0.6851794004440308, "training_acc": 57.0, "val_loss": 0.6852065587043762, "val_acc": 56.0}
{"epoch": 42, "training_loss": 0.684998984336853, "training_acc": 56.0, "val_loss": 0.6851557898521423, "val_acc": 56.0}
{"epoch": 43, "training_loss": 0.6843666577339172, "training_acc": 57.0, "val_loss": 0.6851461410522461, "val_acc": 56.0}
{"epoch": 44, "training_loss": 0.6842937898635865, "training_acc": 58.0, "val_loss": 0.6850064587593079, "val_acc": 56.0}
{"epoch": 45, "training_loss": 0.6843301606178284, "training_acc": 57.0, "val_loss": 0.6849556565284729, "val_acc": 56.0}
{"epoch": 46, "training_loss": 0.6837418389320373, "training_acc": 56.0, "val_loss": 0.6849354219436645, "val_acc": 56.0}
{"epoch": 47, "training_loss": 0.6835556435585022, "training_acc": 58.0, "val_loss": 0.685042188167572, "val_acc": 56.0}
{"epoch": 48, "training_loss": 0.6835550212860108, "training_acc": 57.0, "val_loss": 0.6848557019233703, "val_acc": 56.0}
{"epoch": 49, "training_loss": 0.6837332963943481, "training_acc": 56.0, "val_loss": 0.6848973870277405, "val_acc": 56.0}
{"epoch": 50, "training_loss": 0.6835653591156006, "training_acc": 55.0, "val_loss": 0.6848315477371216, "val_acc": 56.0}
{"epoch": 51, "training_loss": 0.6831906008720398, "training_acc": 59.0, "val_loss": 0.6846910119056702, "val_acc": 56.0}
{"epoch": 52, "training_loss": 0.6834337282180786, "training_acc": 56.0, "val_loss": 0.6845955967903137, "val_acc": 56.0}
{"epoch": 53, "training_loss": 0.683013858795166, "training_acc": 58.0, "val_loss": 0.6843719053268432, "val_acc": 56.0}
{"epoch": 54, "training_loss": 0.6826801657676697, "training_acc": 57.0, "val_loss": 0.6845256543159485, "val_acc": 56.0}
{"epoch": 55, "training_loss": 0.683344395160675, "training_acc": 56.0, "val_loss": 0.6843186211585999, "val_acc": 56.0}
{"epoch": 56, "training_loss": 0.6823216700553894, "training_acc": 55.0, "val_loss": 0.6842662191390991, "val_acc": 56.0}
{"epoch": 57, "training_loss": 0.6821769189834594, "training_acc": 55.0, "val_loss": 0.6842611241340637, "val_acc": 56.0}
{"epoch": 58, "training_loss": 0.6823191857337951, "training_acc": 58.0, "val_loss": 0.6842311429977417, "val_acc": 56.0}
{"epoch": 59, "training_loss": 0.6817433547973633, "training_acc": 55.0, "val_loss": 0.6841574454307556, "val_acc": 56.0}
{"epoch": 60, "training_loss": 0.6821518325805664, "training_acc": 57.0, "val_loss": 0.6839661884307862, "val_acc": 56.0}
{"epoch": 61, "training_loss": 0.6820970249176025, "training_acc": 56.0, "val_loss": 0.6840990042686462, "val_acc": 56.0}
{"epoch": 62, "training_loss": 0.681615104675293, "training_acc": 56.0, "val_loss": 0.6840546083450317, "val_acc": 56.0}
{"epoch": 63, "training_loss": 0.6811994409561157, "training_acc": 57.0, "val_loss": 0.6838608741760254, "val_acc": 56.0}
{"epoch": 64, "training_loss": 0.6812487721443177, "training_acc": 57.0, "val_loss": 0.6838611578941345, "val_acc": 56.0}
{"epoch": 65, "training_loss": 0.6808188486099244, "training_acc": 59.0, "val_loss": 0.6838487672805786, "val_acc": 56.0}
{"epoch": 66, "training_loss": 0.6809601855278015, "training_acc": 57.0, "val_loss": 0.6836582493782043, "val_acc": 56.0}
{"epoch": 67, "training_loss": 0.6806500935554505, "training_acc": 57.0, "val_loss": 0.6834682559967041, "val_acc": 56.0}
{"epoch": 68, "training_loss": 0.6806627917289734, "training_acc": 58.0, "val_loss": 0.6836792469024658, "val_acc": 56.0}
{"epoch": 69, "training_loss": 0.6809788942337036, "training_acc": 57.0, "val_loss": 0.6836332869529724, "val_acc": 56.0}
{"epoch": 70, "training_loss": 0.6806995463371277, "training_acc": 56.0, "val_loss": 0.6835145664215088, "val_acc": 56.0}
{"epoch": 71, "training_loss": 0.6804833602905274, "training_acc": 56.0, "val_loss": 0.6833812665939331, "val_acc": 56.0}
{"epoch": 72, "training_loss": 0.6809945797920227, "training_acc": 57.0, "val_loss": 0.6833741855621338, "val_acc": 56.0}
{"epoch": 73, "training_loss": 0.679970645904541, "training_acc": 57.0, "val_loss": 0.6833038425445557, "val_acc": 56.0}
{"epoch": 74, "training_loss": 0.6801939606666565, "training_acc": 56.0, "val_loss": 0.6832026410102844, "val_acc": 56.0}
{"epoch": 75, "training_loss": 0.6802960014343262, "training_acc": 57.0, "val_loss": 0.683111937046051, "val_acc": 56.0}
{"epoch": 76, "training_loss": 0.6808145141601563, "training_acc": 55.0, "val_loss": 0.6830398559570312, "val_acc": 56.0}
{"epoch": 77, "training_loss": 0.6795289182662964, "training_acc": 57.0, "val_loss": 0.6831128668785095, "val_acc": 56.0}
{"epoch": 78, "training_loss": 0.679235417842865, "training_acc": 59.0, "val_loss": 0.6830059623718262, "val_acc": 56.0}
{"epoch": 79, "training_loss": 0.6798296117782593, "training_acc": 56.0, "val_loss": 0.6829897665977478, "val_acc": 56.0}
{"epoch": 80, "training_loss": 0.6794474697113038, "training_acc": 58.0, "val_loss": 0.6830158233642578, "val_acc": 56.0}
{"epoch": 81, "training_loss": 0.6789328885078431, "training_acc": 57.0, "val_loss": 0.6829708433151245, "val_acc": 56.0}
{"epoch": 82, "training_loss": 0.6794709372520447, "training_acc": 55.0, "val_loss": 0.6827610611915589, "val_acc": 56.0}
{"epoch": 83, "training_loss": 0.6786517524719238, "training_acc": 58.0, "val_loss": 0.6825509762763977, "val_acc": 56.0}
{"epoch": 84, "training_loss": 0.6786157035827637, "training_acc": 58.0, "val_loss": 0.6827498626708984, "val_acc": 56.0}
{"epoch": 85, "training_loss": 0.6788858509063721, "training_acc": 58.0, "val_loss": 0.6825829029083252, "val_acc": 56.0}
{"epoch": 86, "training_loss": 0.67821848154068, "training_acc": 59.0, "val_loss": 0.6825864672660827, "val_acc": 56.0}
{"epoch": 87, "training_loss": 0.6781113767623901, "training_acc": 59.0, "val_loss": 0.6825500822067261, "val_acc": 56.0}
{"epoch": 88, "training_loss": 0.6790878629684448, "training_acc": 58.0, "val_loss": 0.6825959086418152, "val_acc": 56.0}
{"epoch": 89, "training_loss": 0.6787357187271118, "training_acc": 58.0, "val_loss": 0.6824108242988587, "val_acc": 56.0}
{"epoch": 90, "training_loss": 0.6784137177467346, "training_acc": 58.0, "val_loss": 0.6823936104774475, "val_acc": 56.0}
{"epoch": 91, "training_loss": 0.6781491565704346, "training_acc": 57.0, "val_loss": 0.6824145245552063, "val_acc": 56.0}
{"epoch": 92, "training_loss": 0.6767721939086914, "training_acc": 58.0, "val_loss": 0.6821724796295165, "val_acc": 56.0}
{"epoch": 93, "training_loss": 0.6777640604972839, "training_acc": 58.0, "val_loss": 0.6823445200920105, "val_acc": 56.0}
{"epoch": 94, "training_loss": 0.678208031654358, "training_acc": 58.0, "val_loss": 0.682187738418579, "val_acc": 56.0}
{"epoch": 95, "training_loss": 0.6784206628799438, "training_acc": 58.0, "val_loss": 0.6821534657478332, "val_acc": 56.0}
{"epoch": 96, "training_loss": 0.677599196434021, "training_acc": 59.0, "val_loss": 0.6822653913497925, "val_acc": 56.0}
{"epoch": 97, "training_loss": 0.6772750806808472, "training_acc": 57.0, "val_loss": 0.6821100234985351, "val_acc": 56.0}
{"epoch": 98, "training_loss": 0.677092261314392, "training_acc": 59.0, "val_loss": 0.6818302345275878, "val_acc": 56.0}
{"epoch": 99, "training_loss": 0.6767325901985168, "training_acc": 59.0, "val_loss": 0.6820848488807678, "val_acc": 56.0}
