"main_modify.py --pretrained_path /scratch/connectome/dyhan316/VAE_ADHD/barlowtwins/pretrain_results/ABCDbt128a102.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 2 --task ABCD_sex --input_option BT_org --learning_rate 1e-6 --batch_size 16 --weight_decay 1e-2 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 0.6917452430725097, "training_acc": 53.0, "val_loss": 0.6926328325271607, "val_acc": 52.0}
{"epoch": 1, "training_loss": 0.6917418813705445, "training_acc": 53.0, "val_loss": 0.6923165917396545, "val_acc": 52.0}
{"epoch": 2, "training_loss": 0.6918784809112549, "training_acc": 53.0, "val_loss": 0.6924300122261048, "val_acc": 52.0}
{"epoch": 3, "training_loss": 0.6912244248390198, "training_acc": 53.0, "val_loss": 0.6930131912231445, "val_acc": 52.0}
{"epoch": 4, "training_loss": 0.6908527159690857, "training_acc": 53.0, "val_loss": 0.6932923340797424, "val_acc": 52.0}
{"epoch": 5, "training_loss": 0.6905098104476929, "training_acc": 53.0, "val_loss": 0.6933130431175232, "val_acc": 52.0}
{"epoch": 6, "training_loss": 0.6899642562866211, "training_acc": 53.0, "val_loss": 0.6928915047645569, "val_acc": 52.0}
{"epoch": 7, "training_loss": 0.6901054811477662, "training_acc": 53.0, "val_loss": 0.6933081746101379, "val_acc": 52.0}
{"epoch": 8, "training_loss": 0.6900015830993652, "training_acc": 53.0, "val_loss": 0.6931236600875854, "val_acc": 52.0}
{"epoch": 9, "training_loss": 0.6898469543457031, "training_acc": 53.0, "val_loss": 0.6928468298912048, "val_acc": 52.0}
{"epoch": 10, "training_loss": 0.6900990319252014, "training_acc": 53.0, "val_loss": 0.692971122264862, "val_acc": 52.0}
{"epoch": 11, "training_loss": 0.6898932838439942, "training_acc": 53.0, "val_loss": 0.6934104490280152, "val_acc": 52.0}
{"epoch": 12, "training_loss": 0.6897781705856323, "training_acc": 53.0, "val_loss": 0.6932984185218811, "val_acc": 52.0}
{"epoch": 13, "training_loss": 0.6888019204139709, "training_acc": 53.0, "val_loss": 0.692700023651123, "val_acc": 52.0}
{"epoch": 14, "training_loss": 0.6887704086303711, "training_acc": 53.0, "val_loss": 0.6926990962028503, "val_acc": 52.0}
{"epoch": 15, "training_loss": 0.6883613872528076, "training_acc": 53.0, "val_loss": 0.6926145744323731, "val_acc": 52.0}
{"epoch": 16, "training_loss": 0.688253996372223, "training_acc": 53.0, "val_loss": 0.692588586807251, "val_acc": 52.0}
{"epoch": 17, "training_loss": 0.6882295417785644, "training_acc": 53.0, "val_loss": 0.6926466059684754, "val_acc": 52.0}
{"epoch": 18, "training_loss": 0.6884178686141967, "training_acc": 53.0, "val_loss": 0.6926995539665222, "val_acc": 52.0}
{"epoch": 19, "training_loss": 0.6878051447868347, "training_acc": 53.0, "val_loss": 0.69218013048172, "val_acc": 52.0}
{"epoch": 20, "training_loss": 0.6877205514907837, "training_acc": 53.0, "val_loss": 0.6925989842414856, "val_acc": 52.0}
{"epoch": 21, "training_loss": 0.6874323272705078, "training_acc": 53.0, "val_loss": 0.6926807856559754, "val_acc": 52.0}
{"epoch": 22, "training_loss": 0.6881099271774292, "training_acc": 53.0, "val_loss": 0.692289924621582, "val_acc": 52.0}
{"epoch": 23, "training_loss": 0.6870399904251099, "training_acc": 53.0, "val_loss": 0.6921448588371277, "val_acc": 52.0}
{"epoch": 24, "training_loss": 0.687588415145874, "training_acc": 53.0, "val_loss": 0.6924522423744202, "val_acc": 52.0}
{"epoch": 25, "training_loss": 0.687099039554596, "training_acc": 53.0, "val_loss": 0.6923787999153137, "val_acc": 52.0}
{"epoch": 26, "training_loss": 0.6870503497123718, "training_acc": 53.0, "val_loss": 0.6921943354606629, "val_acc": 52.0}
{"epoch": 27, "training_loss": 0.686632194519043, "training_acc": 53.0, "val_loss": 0.692471239566803, "val_acc": 52.0}
{"epoch": 28, "training_loss": 0.6862136626243591, "training_acc": 53.0, "val_loss": 0.692081651687622, "val_acc": 52.0}
{"epoch": 29, "training_loss": 0.6862472653388977, "training_acc": 53.0, "val_loss": 0.6920656633377075, "val_acc": 52.0}
{"epoch": 30, "training_loss": 0.6862004852294922, "training_acc": 53.0, "val_loss": 0.6924157047271728, "val_acc": 52.0}
{"epoch": 31, "training_loss": 0.6858210921287536, "training_acc": 53.0, "val_loss": 0.6919412589073182, "val_acc": 52.0}
{"epoch": 32, "training_loss": 0.6859177350997925, "training_acc": 53.0, "val_loss": 0.6922426295280456, "val_acc": 52.0}
{"epoch": 33, "training_loss": 0.686704273223877, "training_acc": 53.0, "val_loss": 0.692360680103302, "val_acc": 52.0}
{"epoch": 34, "training_loss": 0.6860150742530823, "training_acc": 53.0, "val_loss": 0.6924749660491943, "val_acc": 52.0}
{"epoch": 35, "training_loss": 0.6861875510215759, "training_acc": 53.0, "val_loss": 0.6923665308952331, "val_acc": 52.0}
{"epoch": 36, "training_loss": 0.6855502891540527, "training_acc": 53.0, "val_loss": 0.6916628766059876, "val_acc": 52.0}
{"epoch": 37, "training_loss": 0.6848134517669677, "training_acc": 53.0, "val_loss": 0.6916739630699158, "val_acc": 52.0}
{"epoch": 38, "training_loss": 0.6847646141052246, "training_acc": 53.0, "val_loss": 0.6914531064033508, "val_acc": 52.0}
{"epoch": 39, "training_loss": 0.684972767829895, "training_acc": 53.0, "val_loss": 0.6914765882492065, "val_acc": 52.0}
{"epoch": 40, "training_loss": 0.6844773197174072, "training_acc": 53.0, "val_loss": 0.691453640460968, "val_acc": 52.0}
{"epoch": 41, "training_loss": 0.6848402047157287, "training_acc": 53.0, "val_loss": 0.6916932725906372, "val_acc": 52.0}
{"epoch": 42, "training_loss": 0.6848926639556885, "training_acc": 53.0, "val_loss": 0.691551673412323, "val_acc": 52.0}
{"epoch": 43, "training_loss": 0.6844807863235474, "training_acc": 53.0, "val_loss": 0.6916451716423034, "val_acc": 52.0}
{"epoch": 44, "training_loss": 0.6845647788047791, "training_acc": 53.0, "val_loss": 0.6912767148017883, "val_acc": 52.0}
{"epoch": 45, "training_loss": 0.684088990688324, "training_acc": 53.0, "val_loss": 0.691308753490448, "val_acc": 52.0}
{"epoch": 46, "training_loss": 0.6839523386955261, "training_acc": 53.0, "val_loss": 0.6911855792999267, "val_acc": 52.0}
{"epoch": 47, "training_loss": 0.6841365218162536, "training_acc": 53.0, "val_loss": 0.691311867237091, "val_acc": 52.0}
{"epoch": 48, "training_loss": 0.683681001663208, "training_acc": 53.0, "val_loss": 0.6914085578918457, "val_acc": 52.0}
{"epoch": 49, "training_loss": 0.6833178663253784, "training_acc": 53.0, "val_loss": 0.6912992429733277, "val_acc": 52.0}
{"epoch": 50, "training_loss": 0.6837419438362121, "training_acc": 53.0, "val_loss": 0.6916581344604492, "val_acc": 52.0}
{"epoch": 51, "training_loss": 0.6838303303718567, "training_acc": 53.0, "val_loss": 0.6908999848365783, "val_acc": 52.0}
{"epoch": 52, "training_loss": 0.6837450075149536, "training_acc": 53.0, "val_loss": 0.6909917831420899, "val_acc": 52.0}
{"epoch": 53, "training_loss": 0.6836766624450683, "training_acc": 53.0, "val_loss": 0.6910806608200073, "val_acc": 52.0}
{"epoch": 54, "training_loss": 0.6830875873565674, "training_acc": 53.0, "val_loss": 0.6905592727661133, "val_acc": 52.0}
{"epoch": 55, "training_loss": 0.6827714157104492, "training_acc": 53.0, "val_loss": 0.6906652927398682, "val_acc": 52.0}
{"epoch": 56, "training_loss": 0.6822161483764648, "training_acc": 53.0, "val_loss": 0.690722267627716, "val_acc": 52.0}
{"epoch": 57, "training_loss": 0.6825841593742371, "training_acc": 53.0, "val_loss": 0.6907738208770752, "val_acc": 52.0}
{"epoch": 58, "training_loss": 0.6832529282569886, "training_acc": 53.0, "val_loss": 0.6909065985679627, "val_acc": 52.0}
{"epoch": 59, "training_loss": 0.6818580865859986, "training_acc": 53.0, "val_loss": 0.6908880376815796, "val_acc": 52.0}
{"epoch": 60, "training_loss": 0.6820867156982422, "training_acc": 53.0, "val_loss": 0.6907293272018432, "val_acc": 52.0}
{"epoch": 61, "training_loss": 0.6818645215034485, "training_acc": 53.0, "val_loss": 0.6906808853149414, "val_acc": 52.0}
{"epoch": 62, "training_loss": 0.6819907808303833, "training_acc": 53.0, "val_loss": 0.6906927347183227, "val_acc": 52.0}
{"epoch": 63, "training_loss": 0.6811311173439026, "training_acc": 53.0, "val_loss": 0.6906782174110413, "val_acc": 52.0}
{"epoch": 64, "training_loss": 0.6815522813796997, "training_acc": 53.0, "val_loss": 0.6905443143844604, "val_acc": 52.0}
{"epoch": 65, "training_loss": 0.6814409017562866, "training_acc": 53.0, "val_loss": 0.6906111931800842, "val_acc": 52.0}
{"epoch": 66, "training_loss": 0.6812337112426757, "training_acc": 53.0, "val_loss": 0.69060720205307, "val_acc": 52.0}
{"epoch": 67, "training_loss": 0.6812347435951233, "training_acc": 53.0, "val_loss": 0.6904682612419129, "val_acc": 52.0}
{"epoch": 68, "training_loss": 0.6814980936050415, "training_acc": 53.0, "val_loss": 0.690396523475647, "val_acc": 52.0}
{"epoch": 69, "training_loss": 0.6805989980697632, "training_acc": 53.0, "val_loss": 0.6906885266304016, "val_acc": 52.0}
{"epoch": 70, "training_loss": 0.6807416534423828, "training_acc": 53.0, "val_loss": 0.6905807209014893, "val_acc": 52.0}
{"epoch": 71, "training_loss": 0.6806101870536804, "training_acc": 53.0, "val_loss": 0.6905223774909973, "val_acc": 52.0}
{"epoch": 72, "training_loss": 0.6808818244934082, "training_acc": 53.0, "val_loss": 0.690205807685852, "val_acc": 52.0}
{"epoch": 73, "training_loss": 0.6802661371231079, "training_acc": 53.0, "val_loss": 0.6904223608970642, "val_acc": 52.0}
{"epoch": 74, "training_loss": 0.6800118494033813, "training_acc": 53.0, "val_loss": 0.6904536771774292, "val_acc": 52.0}
{"epoch": 75, "training_loss": 0.6800058126449585, "training_acc": 53.0, "val_loss": 0.6902506804466247, "val_acc": 52.0}
{"epoch": 76, "training_loss": 0.6796273374557495, "training_acc": 53.0, "val_loss": 0.6901803827285766, "val_acc": 52.0}
{"epoch": 77, "training_loss": 0.679869737625122, "training_acc": 53.0, "val_loss": 0.690318386554718, "val_acc": 52.0}
{"epoch": 78, "training_loss": 0.6801389741897583, "training_acc": 53.0, "val_loss": 0.690283317565918, "val_acc": 52.0}
{"epoch": 79, "training_loss": 0.6797311282157898, "training_acc": 53.0, "val_loss": 0.6904521107673645, "val_acc": 52.0}
{"epoch": 80, "training_loss": 0.6795850896835327, "training_acc": 53.0, "val_loss": 0.6901832890510559, "val_acc": 52.0}
{"epoch": 81, "training_loss": 0.6791321182250977, "training_acc": 53.0, "val_loss": 0.6902520871162414, "val_acc": 52.0}
{"epoch": 82, "training_loss": 0.6791941833496093, "training_acc": 53.0, "val_loss": 0.6902564191818237, "val_acc": 52.0}
{"epoch": 83, "training_loss": 0.6787696743011474, "training_acc": 53.0, "val_loss": 0.6901613521575928, "val_acc": 52.0}
{"epoch": 84, "training_loss": 0.6794995737075805, "training_acc": 53.0, "val_loss": 0.6900340247154236, "val_acc": 52.0}
{"epoch": 85, "training_loss": 0.6788238310813903, "training_acc": 53.0, "val_loss": 0.690241539478302, "val_acc": 52.0}
{"epoch": 86, "training_loss": 0.6783592796325684, "training_acc": 53.0, "val_loss": 0.6903363275527954, "val_acc": 52.0}
{"epoch": 87, "training_loss": 0.6781396484375, "training_acc": 53.0, "val_loss": 0.6902428436279296, "val_acc": 52.0}
{"epoch": 88, "training_loss": 0.6786878514289856, "training_acc": 53.0, "val_loss": 0.6902170658111573, "val_acc": 52.0}
{"epoch": 89, "training_loss": 0.6780504322052002, "training_acc": 53.0, "val_loss": 0.6900625419616699, "val_acc": 52.0}
{"epoch": 90, "training_loss": 0.6775015354156494, "training_acc": 53.0, "val_loss": 0.6900847101211548, "val_acc": 52.0}
{"epoch": 91, "training_loss": 0.6777058410644531, "training_acc": 53.0, "val_loss": 0.6900437021255493, "val_acc": 52.0}
{"epoch": 92, "training_loss": 0.6778034591674804, "training_acc": 53.0, "val_loss": 0.6900445151329041, "val_acc": 52.0}
{"epoch": 93, "training_loss": 0.67807058095932, "training_acc": 53.0, "val_loss": 0.6902822113037109, "val_acc": 52.0}
{"epoch": 94, "training_loss": 0.6776545333862305, "training_acc": 53.0, "val_loss": 0.689985659122467, "val_acc": 52.0}
{"epoch": 95, "training_loss": 0.6775156044960022, "training_acc": 53.0, "val_loss": 0.6900325727462768, "val_acc": 52.0}
{"epoch": 96, "training_loss": 0.6774976825714112, "training_acc": 53.0, "val_loss": 0.6900003933906556, "val_acc": 52.0}
{"epoch": 97, "training_loss": 0.677214879989624, "training_acc": 53.0, "val_loss": 0.6899794125556946, "val_acc": 52.0}
{"epoch": 98, "training_loss": 0.677281813621521, "training_acc": 53.0, "val_loss": 0.6900422239303589, "val_acc": 52.0}
{"epoch": 99, "training_loss": 0.6776994848251343, "training_acc": 53.0, "val_loss": 0.690100724697113, "val_acc": 52.0}
