"main_modify.py --pretrained_path /scratch/connectome/dyhan316/VAE_ADHD/barlowtwins/pretrain_results/ABCDbt128a102.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 1 --task ABCD_sex --input_option BT_org --learning_rate 1e-6 --batch_size 16 --weight_decay 1e-2 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 0.6916238927841186, "training_acc": 53.0, "val_loss": 0.6927195239067078, "val_acc": 52.0}
{"epoch": 1, "training_loss": 0.6916555047035218, "training_acc": 53.0, "val_loss": 0.6928379273414612, "val_acc": 52.0}
{"epoch": 2, "training_loss": 0.6914591860771179, "training_acc": 53.0, "val_loss": 0.6921311593055726, "val_acc": 52.0}
{"epoch": 3, "training_loss": 0.69102548122406, "training_acc": 53.0, "val_loss": 0.6915748620033264, "val_acc": 52.0}
{"epoch": 4, "training_loss": 0.6910624527931213, "training_acc": 53.0, "val_loss": 0.691786572933197, "val_acc": 52.0}
{"epoch": 5, "training_loss": 0.6906266403198242, "training_acc": 53.0, "val_loss": 0.6915588140487671, "val_acc": 52.0}
{"epoch": 6, "training_loss": 0.6905470752716064, "training_acc": 53.0, "val_loss": 0.6916212677955628, "val_acc": 52.0}
{"epoch": 7, "training_loss": 0.6901388335227966, "training_acc": 53.0, "val_loss": 0.6918013739585877, "val_acc": 52.0}
{"epoch": 8, "training_loss": 0.690222954750061, "training_acc": 53.0, "val_loss": 0.6923642301559448, "val_acc": 52.0}
{"epoch": 9, "training_loss": 0.6895390462875366, "training_acc": 53.0, "val_loss": 0.6917386984825135, "val_acc": 52.0}
{"epoch": 10, "training_loss": 0.6899749088287354, "training_acc": 53.0, "val_loss": 0.6912895441055298, "val_acc": 52.0}
{"epoch": 11, "training_loss": 0.6895591020584106, "training_acc": 53.0, "val_loss": 0.6914627766609192, "val_acc": 52.0}
{"epoch": 12, "training_loss": 0.6894581699371338, "training_acc": 53.0, "val_loss": 0.6913749885559082, "val_acc": 52.0}
{"epoch": 13, "training_loss": 0.6897532987594605, "training_acc": 53.0, "val_loss": 0.6915657353401184, "val_acc": 52.0}
{"epoch": 14, "training_loss": 0.689170069694519, "training_acc": 53.0, "val_loss": 0.6921815204620362, "val_acc": 52.0}
{"epoch": 15, "training_loss": 0.6889917039871216, "training_acc": 53.0, "val_loss": 0.6918610453605651, "val_acc": 52.0}
{"epoch": 16, "training_loss": 0.6887035059928894, "training_acc": 53.0, "val_loss": 0.6913152766227723, "val_acc": 52.0}
{"epoch": 17, "training_loss": 0.6884691452980042, "training_acc": 53.0, "val_loss": 0.6913741731643677, "val_acc": 52.0}
{"epoch": 18, "training_loss": 0.6893102884292602, "training_acc": 53.0, "val_loss": 0.691434223651886, "val_acc": 52.0}
{"epoch": 19, "training_loss": 0.6889194631576538, "training_acc": 53.0, "val_loss": 0.691902620792389, "val_acc": 52.0}
{"epoch": 20, "training_loss": 0.6885265994071961, "training_acc": 53.0, "val_loss": 0.6913556218147278, "val_acc": 52.0}
{"epoch": 21, "training_loss": 0.6881406307220459, "training_acc": 53.0, "val_loss": 0.6911000823974609, "val_acc": 52.0}
{"epoch": 22, "training_loss": 0.6877042913436889, "training_acc": 53.0, "val_loss": 0.6914600849151611, "val_acc": 52.0}
{"epoch": 23, "training_loss": 0.6878123569488526, "training_acc": 53.0, "val_loss": 0.6911930775642395, "val_acc": 52.0}
{"epoch": 24, "training_loss": 0.6874916696548462, "training_acc": 53.0, "val_loss": 0.691220178604126, "val_acc": 52.0}
{"epoch": 25, "training_loss": 0.6877599239349366, "training_acc": 53.0, "val_loss": 0.6914706420898438, "val_acc": 52.0}
{"epoch": 26, "training_loss": 0.6873316383361816, "training_acc": 53.0, "val_loss": 0.6916967344284057, "val_acc": 52.0}
{"epoch": 27, "training_loss": 0.6873735332489014, "training_acc": 53.0, "val_loss": 0.6916224002838135, "val_acc": 52.0}
{"epoch": 28, "training_loss": 0.6873323726654053, "training_acc": 53.0, "val_loss": 0.6911795973777771, "val_acc": 52.0}
{"epoch": 29, "training_loss": 0.6870478987693787, "training_acc": 53.0, "val_loss": 0.6912187147140503, "val_acc": 52.0}
{"epoch": 30, "training_loss": 0.6876295948028565, "training_acc": 53.0, "val_loss": 0.6912928104400635, "val_acc": 52.0}
{"epoch": 31, "training_loss": 0.6864518928527832, "training_acc": 53.0, "val_loss": 0.6914949798583985, "val_acc": 52.0}
{"epoch": 32, "training_loss": 0.6865790247917175, "training_acc": 53.0, "val_loss": 0.6913465452194214, "val_acc": 52.0}
{"epoch": 33, "training_loss": 0.6864214134216309, "training_acc": 53.0, "val_loss": 0.6912306141853333, "val_acc": 52.0}
{"epoch": 34, "training_loss": 0.6865703797340393, "training_acc": 53.0, "val_loss": 0.69106929063797, "val_acc": 52.0}
{"epoch": 35, "training_loss": 0.6864592456817626, "training_acc": 53.0, "val_loss": 0.6913099956512451, "val_acc": 52.0}
{"epoch": 36, "training_loss": 0.6864825940132141, "training_acc": 53.0, "val_loss": 0.6915688395500184, "val_acc": 52.0}
{"epoch": 37, "training_loss": 0.685503363609314, "training_acc": 53.0, "val_loss": 0.6913678669929504, "val_acc": 52.0}
{"epoch": 38, "training_loss": 0.6857296109199524, "training_acc": 53.0, "val_loss": 0.6916555714607239, "val_acc": 52.0}
{"epoch": 39, "training_loss": 0.68635009765625, "training_acc": 53.0, "val_loss": 0.6912605905532837, "val_acc": 52.0}
{"epoch": 40, "training_loss": 0.6852444314956665, "training_acc": 53.0, "val_loss": 0.6910308146476746, "val_acc": 52.0}
{"epoch": 41, "training_loss": 0.6851131105422974, "training_acc": 53.0, "val_loss": 0.6912628269195557, "val_acc": 52.0}
{"epoch": 42, "training_loss": 0.6854381370544433, "training_acc": 53.0, "val_loss": 0.6916301035881043, "val_acc": 52.0}
{"epoch": 43, "training_loss": 0.6848516464233398, "training_acc": 53.0, "val_loss": 0.6909107613563538, "val_acc": 52.0}
{"epoch": 44, "training_loss": 0.6850583052635193, "training_acc": 53.0, "val_loss": 0.690709388256073, "val_acc": 52.0}
{"epoch": 45, "training_loss": 0.6851531028747558, "training_acc": 53.0, "val_loss": 0.690926480293274, "val_acc": 52.0}
{"epoch": 46, "training_loss": 0.6848761177062989, "training_acc": 53.0, "val_loss": 0.6911384963989258, "val_acc": 52.0}
{"epoch": 47, "training_loss": 0.6846836471557617, "training_acc": 53.0, "val_loss": 0.6912590289115905, "val_acc": 52.0}
{"epoch": 48, "training_loss": 0.6845903086662293, "training_acc": 53.0, "val_loss": 0.690889093875885, "val_acc": 52.0}
{"epoch": 49, "training_loss": 0.6840282106399536, "training_acc": 53.0, "val_loss": 0.6909657311439514, "val_acc": 52.0}
{"epoch": 50, "training_loss": 0.6840052819252014, "training_acc": 53.0, "val_loss": 0.6916913914680481, "val_acc": 52.0}
{"epoch": 51, "training_loss": 0.683847188949585, "training_acc": 53.0, "val_loss": 0.6910910201072693, "val_acc": 52.0}
{"epoch": 52, "training_loss": 0.6841718959808349, "training_acc": 53.0, "val_loss": 0.6911751770973206, "val_acc": 52.0}
{"epoch": 53, "training_loss": 0.6838471317291259, "training_acc": 53.0, "val_loss": 0.6912509512901306, "val_acc": 52.0}
{"epoch": 54, "training_loss": 0.6835835814476013, "training_acc": 53.0, "val_loss": 0.6910735249519349, "val_acc": 52.0}
{"epoch": 55, "training_loss": 0.6836603903770446, "training_acc": 53.0, "val_loss": 0.6911416625976563, "val_acc": 52.0}
{"epoch": 56, "training_loss": 0.6829973268508911, "training_acc": 53.0, "val_loss": 0.6909972500801086, "val_acc": 52.0}
{"epoch": 57, "training_loss": 0.6833116340637208, "training_acc": 53.0, "val_loss": 0.6913063597679138, "val_acc": 52.0}
{"epoch": 58, "training_loss": 0.6830527329444885, "training_acc": 53.0, "val_loss": 0.6912013483047486, "val_acc": 52.0}
{"epoch": 59, "training_loss": 0.6828281092643738, "training_acc": 53.0, "val_loss": 0.6910074949264526, "val_acc": 52.0}
{"epoch": 60, "training_loss": 0.6831496047973633, "training_acc": 53.0, "val_loss": 0.6913257336616516, "val_acc": 52.0}
{"epoch": 61, "training_loss": 0.6826355934143067, "training_acc": 53.0, "val_loss": 0.6909827542304993, "val_acc": 52.0}
{"epoch": 62, "training_loss": 0.6828752541542054, "training_acc": 53.0, "val_loss": 0.691138949394226, "val_acc": 52.0}
{"epoch": 63, "training_loss": 0.6823398160934449, "training_acc": 53.0, "val_loss": 0.6912552762031555, "val_acc": 52.0}
