"main_modify.py --pretrained_path /scratch/connectome/dyhan316/VAE_ADHD/barlowtwins/pretrain_results/ABCDbt128a102.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option BT_org --learning_rate 1e-6 --batch_size 16 --weight_decay 1e-2 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 0.6960225963592529, "training_acc": 47.0, "val_loss": 0.6958259201049805, "val_acc": 48.0}
{"epoch": 1, "training_loss": 0.6963720679283142, "training_acc": 47.0, "val_loss": 0.6960536503791809, "val_acc": 48.0}
{"epoch": 2, "training_loss": 0.6959313344955445, "training_acc": 47.0, "val_loss": 0.6957157254219055, "val_acc": 48.0}
{"epoch": 3, "training_loss": 0.6957901287078857, "training_acc": 47.0, "val_loss": 0.6955000448226929, "val_acc": 48.0}
{"epoch": 4, "training_loss": 0.6957760047912598, "training_acc": 47.0, "val_loss": 0.6955320644378662, "val_acc": 48.0}
{"epoch": 5, "training_loss": 0.694952483177185, "training_acc": 47.0, "val_loss": 0.6953817009925842, "val_acc": 48.0}
{"epoch": 6, "training_loss": 0.6957767748832703, "training_acc": 47.0, "val_loss": 0.6945933818817138, "val_acc": 48.0}
{"epoch": 7, "training_loss": 0.6951085662841797, "training_acc": 47.0, "val_loss": 0.6943843817710876, "val_acc": 48.0}
{"epoch": 8, "training_loss": 0.6948811364173889, "training_acc": 47.0, "val_loss": 0.6944271683692932, "val_acc": 48.0}
{"epoch": 9, "training_loss": 0.6949067258834839, "training_acc": 47.0, "val_loss": 0.6942816758155823, "val_acc": 48.0}
{"epoch": 10, "training_loss": 0.694828987121582, "training_acc": 47.0, "val_loss": 0.6946550750732422, "val_acc": 48.0}
{"epoch": 11, "training_loss": 0.6942529320716858, "training_acc": 47.0, "val_loss": 0.6947589683532714, "val_acc": 48.0}
{"epoch": 12, "training_loss": 0.6942472887039185, "training_acc": 47.0, "val_loss": 0.6945411515235901, "val_acc": 48.0}
{"epoch": 13, "training_loss": 0.6941301059722901, "training_acc": 47.0, "val_loss": 0.6939409947395325, "val_acc": 48.0}
{"epoch": 14, "training_loss": 0.6941558599472046, "training_acc": 47.0, "val_loss": 0.6936832976341247, "val_acc": 48.0}
{"epoch": 15, "training_loss": 0.6938842511177064, "training_acc": 47.0, "val_loss": 0.6937405824661255, "val_acc": 48.0}
{"epoch": 16, "training_loss": 0.6936029529571534, "training_acc": 47.0, "val_loss": 0.6940427994728089, "val_acc": 48.0}
{"epoch": 17, "training_loss": 0.6931183958053588, "training_acc": 47.0, "val_loss": 0.6940162372589112, "val_acc": 48.0}
{"epoch": 18, "training_loss": 0.6932526469230652, "training_acc": 47.0, "val_loss": 0.6936553335189819, "val_acc": 48.0}
{"epoch": 19, "training_loss": 0.6934197473526001, "training_acc": 47.0, "val_loss": 0.6937890601158142, "val_acc": 48.0}
{"epoch": 20, "training_loss": 0.6928807830810547, "training_acc": 47.0, "val_loss": 0.6939844632148743, "val_acc": 48.0}
{"epoch": 21, "training_loss": 0.6933489656448364, "training_acc": 47.0, "val_loss": 0.6936544585227966, "val_acc": 48.0}
{"epoch": 22, "training_loss": 0.6929092955589294, "training_acc": 47.0, "val_loss": 0.6935627841949463, "val_acc": 48.0}
{"epoch": 23, "training_loss": 0.69222332239151, "training_acc": 47.0, "val_loss": 0.6935160040855408, "val_acc": 48.0}
{"epoch": 24, "training_loss": 0.6922711896896362, "training_acc": 47.0, "val_loss": 0.6930886054039002, "val_acc": 48.0}
{"epoch": 25, "training_loss": 0.692354564666748, "training_acc": 47.0, "val_loss": 0.6932065629959107, "val_acc": 48.0}
{"epoch": 26, "training_loss": 0.6920222949981689, "training_acc": 47.0, "val_loss": 0.6933454513549805, "val_acc": 48.0}
{"epoch": 27, "training_loss": 0.6916110229492187, "training_acc": 47.0, "val_loss": 0.6932609534263611, "val_acc": 48.0}
{"epoch": 28, "training_loss": 0.6921279764175415, "training_acc": 47.0, "val_loss": 0.6929817891120911, "val_acc": 48.0}
{"epoch": 29, "training_loss": 0.691651258468628, "training_acc": 47.0, "val_loss": 0.6930584812164307, "val_acc": 48.0}
{"epoch": 30, "training_loss": 0.6911450004577637, "training_acc": 47.0, "val_loss": 0.6930393433570862, "val_acc": 48.0}
{"epoch": 31, "training_loss": 0.691616621017456, "training_acc": 47.0, "val_loss": 0.6930915141105651, "val_acc": 48.0}
{"epoch": 32, "training_loss": 0.6909550952911377, "training_acc": 47.0, "val_loss": 0.6929004955291748, "val_acc": 48.0}
{"epoch": 33, "training_loss": 0.6908283519744873, "training_acc": 47.0, "val_loss": 0.6928568387031555, "val_acc": 48.0}
{"epoch": 34, "training_loss": 0.6906299281120301, "training_acc": 47.0, "val_loss": 0.6925647187232972, "val_acc": 48.0}
{"epoch": 35, "training_loss": 0.6904687404632568, "training_acc": 47.0, "val_loss": 0.6928871846199036, "val_acc": 48.0}
{"epoch": 36, "training_loss": 0.6907504796981812, "training_acc": 47.0, "val_loss": 0.6931180262565613, "val_acc": 48.0}
{"epoch": 37, "training_loss": 0.6900195598602294, "training_acc": 48.0, "val_loss": 0.6928287172317504, "val_acc": 48.0}
{"epoch": 38, "training_loss": 0.6900099563598633, "training_acc": 47.0, "val_loss": 0.6925354480743409, "val_acc": 48.0}
{"epoch": 39, "training_loss": 0.6900204277038574, "training_acc": 47.0, "val_loss": 0.6924821925163269, "val_acc": 48.0}
{"epoch": 40, "training_loss": 0.6899372053146362, "training_acc": 47.0, "val_loss": 0.6926852130889892, "val_acc": 48.0}
{"epoch": 41, "training_loss": 0.6900180387496948, "training_acc": 48.0, "val_loss": 0.6924254751205444, "val_acc": 48.0}
{"epoch": 42, "training_loss": 0.6895462417602539, "training_acc": 50.0, "val_loss": 0.6925467658042908, "val_acc": 48.0}
{"epoch": 43, "training_loss": 0.6891368818283081, "training_acc": 51.0, "val_loss": 0.6924031376838684, "val_acc": 48.0}
{"epoch": 44, "training_loss": 0.6895633840560913, "training_acc": 49.0, "val_loss": 0.6922457957267761, "val_acc": 48.0}
{"epoch": 45, "training_loss": 0.6893939709663391, "training_acc": 50.0, "val_loss": 0.6923907542228699, "val_acc": 48.0}
{"epoch": 46, "training_loss": 0.6888114833831787, "training_acc": 49.0, "val_loss": 0.6923931550979614, "val_acc": 48.0}
{"epoch": 47, "training_loss": 0.6891792845726014, "training_acc": 53.0, "val_loss": 0.6924139094352723, "val_acc": 48.0}
{"epoch": 48, "training_loss": 0.6886891603469849, "training_acc": 53.0, "val_loss": 0.6922137117385865, "val_acc": 44.0}
{"epoch": 49, "training_loss": 0.6888715696334838, "training_acc": 54.0, "val_loss": 0.6921948409080505, "val_acc": 44.0}
{"epoch": 50, "training_loss": 0.6888043427467346, "training_acc": 51.0, "val_loss": 0.6923417973518372, "val_acc": 44.0}
{"epoch": 51, "training_loss": 0.68783616065979, "training_acc": 54.0, "val_loss": 0.692137508392334, "val_acc": 52.0}
{"epoch": 52, "training_loss": 0.6884474992752075, "training_acc": 56.0, "val_loss": 0.6921876668930054, "val_acc": 52.0}
{"epoch": 53, "training_loss": 0.6881656169891357, "training_acc": 53.0, "val_loss": 0.6921932291984558, "val_acc": 52.0}
{"epoch": 54, "training_loss": 0.6878602647781372, "training_acc": 58.0, "val_loss": 0.6922365474700928, "val_acc": 52.0}
{"epoch": 55, "training_loss": 0.6875052881240845, "training_acc": 61.0, "val_loss": 0.6919214034080505, "val_acc": 52.0}
{"epoch": 56, "training_loss": 0.6878142619132995, "training_acc": 59.0, "val_loss": 0.6919889497756958, "val_acc": 52.0}
{"epoch": 57, "training_loss": 0.6872103548049927, "training_acc": 64.0, "val_loss": 0.6921592450141907, "val_acc": 52.0}
{"epoch": 58, "training_loss": 0.6874292993545532, "training_acc": 63.0, "val_loss": 0.6920172810554505, "val_acc": 52.0}
{"epoch": 59, "training_loss": 0.6872716426849366, "training_acc": 65.0, "val_loss": 0.6918715071678162, "val_acc": 52.0}
{"epoch": 60, "training_loss": 0.6873919177055359, "training_acc": 64.0, "val_loss": 0.6918734288215638, "val_acc": 52.0}
{"epoch": 61, "training_loss": 0.6869726133346558, "training_acc": 70.0, "val_loss": 0.6917550349235535, "val_acc": 52.0}
{"epoch": 62, "training_loss": 0.6869122982025146, "training_acc": 68.0, "val_loss": 0.6918620300292969, "val_acc": 52.0}
{"epoch": 63, "training_loss": 0.6869633626937867, "training_acc": 68.0, "val_loss": 0.691805853843689, "val_acc": 60.0}
{"epoch": 64, "training_loss": 0.6868847012519836, "training_acc": 71.0, "val_loss": 0.691667914390564, "val_acc": 60.0}
{"epoch": 65, "training_loss": 0.6869793581962585, "training_acc": 73.0, "val_loss": 0.6916608357429505, "val_acc": 56.0}
{"epoch": 66, "training_loss": 0.6861431217193603, "training_acc": 77.0, "val_loss": 0.6915378141403198, "val_acc": 60.0}
{"epoch": 67, "training_loss": 0.6862115478515625, "training_acc": 72.0, "val_loss": 0.6918564915657044, "val_acc": 56.0}
{"epoch": 68, "training_loss": 0.6864455270767212, "training_acc": 74.0, "val_loss": 0.6918189930915832, "val_acc": 60.0}
{"epoch": 69, "training_loss": 0.6861132144927978, "training_acc": 75.0, "val_loss": 0.691467068195343, "val_acc": 68.0}
{"epoch": 70, "training_loss": 0.6859072065353393, "training_acc": 74.0, "val_loss": 0.6915525698661804, "val_acc": 64.0}
{"epoch": 71, "training_loss": 0.6857323241233826, "training_acc": 77.0, "val_loss": 0.6913103795051575, "val_acc": 72.0}
{"epoch": 72, "training_loss": 0.6859665393829346, "training_acc": 76.0, "val_loss": 0.6913148212432861, "val_acc": 60.0}
{"epoch": 73, "training_loss": 0.685547161102295, "training_acc": 75.0, "val_loss": 0.6913027691841126, "val_acc": 64.0}
{"epoch": 74, "training_loss": 0.685065815448761, "training_acc": 77.0, "val_loss": 0.6911751794815063, "val_acc": 60.0}
{"epoch": 75, "training_loss": 0.6848365497589112, "training_acc": 82.0, "val_loss": 0.691188805103302, "val_acc": 64.0}
{"epoch": 76, "training_loss": 0.6854104208946228, "training_acc": 80.0, "val_loss": 0.6911326909065246, "val_acc": 60.0}
{"epoch": 77, "training_loss": 0.685233256816864, "training_acc": 79.0, "val_loss": 0.6909636068344116, "val_acc": 60.0}
{"epoch": 78, "training_loss": 0.6847035002708435, "training_acc": 82.0, "val_loss": 0.6910778307914733, "val_acc": 64.0}
{"epoch": 79, "training_loss": 0.6847615814208985, "training_acc": 81.0, "val_loss": 0.691175467967987, "val_acc": 64.0}
{"epoch": 80, "training_loss": 0.6844178462028503, "training_acc": 84.0, "val_loss": 0.691077573299408, "val_acc": 64.0}
{"epoch": 81, "training_loss": 0.6845419836044312, "training_acc": 87.0, "val_loss": 0.6909159350395203, "val_acc": 64.0}
{"epoch": 82, "training_loss": 0.6841279649734497, "training_acc": 85.0, "val_loss": 0.6908829474449157, "val_acc": 64.0}
{"epoch": 83, "training_loss": 0.6840674400329589, "training_acc": 83.0, "val_loss": 0.6908496284484863, "val_acc": 64.0}
{"epoch": 84, "training_loss": 0.6837628149986267, "training_acc": 86.0, "val_loss": 0.6909574580192566, "val_acc": 64.0}
{"epoch": 85, "training_loss": 0.6839857769012451, "training_acc": 84.0, "val_loss": 0.6908877801895141, "val_acc": 60.0}
{"epoch": 86, "training_loss": 0.6840076136589051, "training_acc": 84.0, "val_loss": 0.6910887432098388, "val_acc": 64.0}
{"epoch": 87, "training_loss": 0.6837681818008423, "training_acc": 84.0, "val_loss": 0.6906995797157287, "val_acc": 60.0}
{"epoch": 88, "training_loss": 0.6831994342803955, "training_acc": 90.0, "val_loss": 0.690915253162384, "val_acc": 60.0}
{"epoch": 89, "training_loss": 0.6831287240982056, "training_acc": 90.0, "val_loss": 0.690707402229309, "val_acc": 56.0}
{"epoch": 90, "training_loss": 0.6826876163482666, "training_acc": 89.0, "val_loss": 0.6909812021255494, "val_acc": 56.0}
{"epoch": 91, "training_loss": 0.6831457257270813, "training_acc": 85.0, "val_loss": 0.6905839490890503, "val_acc": 60.0}
{"epoch": 92, "training_loss": 0.6829414868354797, "training_acc": 89.0, "val_loss": 0.6907104969024658, "val_acc": 60.0}
{"epoch": 93, "training_loss": 0.6828225517272949, "training_acc": 87.0, "val_loss": 0.690662968158722, "val_acc": 52.0}
{"epoch": 94, "training_loss": 0.6834837341308594, "training_acc": 88.0, "val_loss": 0.6906407165527344, "val_acc": 56.0}
{"epoch": 95, "training_loss": 0.6824587082862854, "training_acc": 92.0, "val_loss": 0.6906413674354553, "val_acc": 56.0}
{"epoch": 96, "training_loss": 0.6824472141265869, "training_acc": 88.0, "val_loss": 0.6905479407310486, "val_acc": 52.0}
{"epoch": 97, "training_loss": 0.6821494150161743, "training_acc": 87.0, "val_loss": 0.69058513879776, "val_acc": 52.0}
{"epoch": 98, "training_loss": 0.6817550110816956, "training_acc": 91.0, "val_loss": 0.6905162930488586, "val_acc": 56.0}
{"epoch": 99, "training_loss": 0.6823984909057618, "training_acc": 86.0, "val_loss": 0.6905422449111939, "val_acc": 52.0}
