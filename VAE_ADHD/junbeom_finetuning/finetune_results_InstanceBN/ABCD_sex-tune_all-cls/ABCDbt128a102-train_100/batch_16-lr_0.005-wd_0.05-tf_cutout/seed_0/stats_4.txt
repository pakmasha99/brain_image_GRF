"main_modify.py --pretrained_path /scratch/connectome/dyhan316/VAE_ADHD/barlowtwins/pretrain_results/ABCDbt128a102.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option BT_org --learning_rate 5e-3 --batch_size 16 --weight_decay 5e-2 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 0.8336318063735962, "training_acc": 45.0, "val_loss": 0.7051903533935547, "val_acc": 52.0}
{"epoch": 1, "training_loss": 0.7187600111961365, "training_acc": 43.0, "val_loss": 0.7830391645431518, "val_acc": 52.0}
{"epoch": 2, "training_loss": 0.7307302021980285, "training_acc": 55.0, "val_loss": 0.7505313444137574, "val_acc": 48.0}
{"epoch": 3, "training_loss": 0.73801673412323, "training_acc": 55.0, "val_loss": 0.8928419613838195, "val_acc": 52.0}
{"epoch": 4, "training_loss": 0.8181620502471924, "training_acc": 43.0, "val_loss": 0.7160878229141235, "val_acc": 48.0}
{"epoch": 5, "training_loss": 0.7213865971565246, "training_acc": 51.0, "val_loss": 0.7044915103912354, "val_acc": 52.0}
{"epoch": 6, "training_loss": 0.7258880376815796, "training_acc": 43.0, "val_loss": 0.6978428196907044, "val_acc": 52.0}
{"epoch": 7, "training_loss": 0.7083881521224975, "training_acc": 51.0, "val_loss": 0.6925857543945313, "val_acc": 52.0}
{"epoch": 8, "training_loss": 0.7048754525184632, "training_acc": 53.0, "val_loss": 0.7067123508453369, "val_acc": 48.0}
{"epoch": 9, "training_loss": 0.7269059991836548, "training_acc": 47.0, "val_loss": 0.7591326546669006, "val_acc": 52.0}
{"epoch": 10, "training_loss": 0.7381696701049805, "training_acc": 47.0, "val_loss": 0.7009232306480407, "val_acc": 52.0}
{"epoch": 11, "training_loss": 0.7243614053726196, "training_acc": 53.0, "val_loss": 0.6954486584663391, "val_acc": 52.0}
{"epoch": 12, "training_loss": 0.6946613907814025, "training_acc": 49.0, "val_loss": 0.6926050162315369, "val_acc": 52.0}
{"epoch": 13, "training_loss": 0.708607268333435, "training_acc": 43.0, "val_loss": 0.6929738330841064, "val_acc": 52.0}
{"epoch": 14, "training_loss": 0.7086840748786927, "training_acc": 41.0, "val_loss": 0.6936951518058777, "val_acc": 48.0}
{"epoch": 15, "training_loss": 0.7039464473724365, "training_acc": 43.0, "val_loss": 0.7212024784088135, "val_acc": 52.0}
{"epoch": 16, "training_loss": 0.7388766503334045, "training_acc": 45.0, "val_loss": 0.6963712859153748, "val_acc": 52.0}
{"epoch": 17, "training_loss": 0.7048482704162597, "training_acc": 45.0, "val_loss": 0.6923481392860412, "val_acc": 52.0}
{"epoch": 18, "training_loss": 0.7040991115570069, "training_acc": 55.0, "val_loss": 0.7705538415908814, "val_acc": 48.0}
{"epoch": 19, "training_loss": 0.7303716158866882, "training_acc": 47.0, "val_loss": 0.7441409277915955, "val_acc": 52.0}
{"epoch": 20, "training_loss": 0.7529287242889404, "training_acc": 55.0, "val_loss": 0.7250159382820129, "val_acc": 48.0}
{"epoch": 21, "training_loss": 0.7246161174774169, "training_acc": 45.0, "val_loss": 0.7099017167091369, "val_acc": 48.0}
{"epoch": 22, "training_loss": 0.7263885831832886, "training_acc": 41.0, "val_loss": 0.7305683994293213, "val_acc": 48.0}
{"epoch": 23, "training_loss": 0.7304871535301208, "training_acc": 49.0, "val_loss": 0.7341456151008606, "val_acc": 52.0}
{"epoch": 24, "training_loss": 0.7292073011398316, "training_acc": 53.0, "val_loss": 0.7099097919464111, "val_acc": 48.0}
{"epoch": 25, "training_loss": 0.7088616442680359, "training_acc": 41.0, "val_loss": 0.6954398512840271, "val_acc": 52.0}
{"epoch": 26, "training_loss": 0.7094168663024902, "training_acc": 47.0, "val_loss": 0.6981093215942383, "val_acc": 52.0}
{"epoch": 27, "training_loss": 0.6954010891914367, "training_acc": 53.0, "val_loss": 0.6923474478721618, "val_acc": 52.0}
{"epoch": 28, "training_loss": 0.7144422245025634, "training_acc": 47.0, "val_loss": 0.6923851823806763, "val_acc": 52.0}
{"epoch": 29, "training_loss": 0.7043909668922425, "training_acc": 53.0, "val_loss": 0.6925560784339905, "val_acc": 52.0}
{"epoch": 30, "training_loss": 0.705722451210022, "training_acc": 47.0, "val_loss": 0.7002173733711242, "val_acc": 52.0}
{"epoch": 31, "training_loss": 0.7094548225402832, "training_acc": 47.0, "val_loss": 0.6932026386260987, "val_acc": 52.0}
{"epoch": 32, "training_loss": 0.6992420434951783, "training_acc": 53.0, "val_loss": 0.7032439851760864, "val_acc": 48.0}
{"epoch": 33, "training_loss": 0.7081821823120117, "training_acc": 43.0, "val_loss": 0.6923596572875976, "val_acc": 52.0}
{"epoch": 34, "training_loss": 0.7134307789802551, "training_acc": 39.0, "val_loss": 0.7412236571311951, "val_acc": 52.0}
{"epoch": 35, "training_loss": 0.7934110927581787, "training_acc": 53.0, "val_loss": 0.6953933715820313, "val_acc": 48.0}
{"epoch": 36, "training_loss": 0.7058147525787354, "training_acc": 45.0, "val_loss": 0.6967177128791809, "val_acc": 48.0}
{"epoch": 37, "training_loss": 0.7069728374481201, "training_acc": 49.0, "val_loss": 0.7093975806236267, "val_acc": 52.0}
{"epoch": 38, "training_loss": 0.7409431409835815, "training_acc": 53.0, "val_loss": 0.6930417704582215, "val_acc": 52.0}
{"epoch": 39, "training_loss": 0.7025935268402099, "training_acc": 51.0, "val_loss": 0.6952048563957214, "val_acc": 48.0}
{"epoch": 40, "training_loss": 0.7207172346115113, "training_acc": 45.0, "val_loss": 0.6925679516792297, "val_acc": 52.0}
{"epoch": 41, "training_loss": 0.7015091562271119, "training_acc": 47.0, "val_loss": 0.6926986241340637, "val_acc": 52.0}
{"epoch": 42, "training_loss": 0.7041343879699707, "training_acc": 53.0, "val_loss": 0.6999095273017883, "val_acc": 52.0}
{"epoch": 43, "training_loss": 0.7224966406822204, "training_acc": 53.0, "val_loss": 0.7142657589912415, "val_acc": 48.0}
{"epoch": 44, "training_loss": 0.78282390832901, "training_acc": 47.0, "val_loss": 0.6933396553993225, "val_acc": 52.0}
{"epoch": 45, "training_loss": 0.7275432157516479, "training_acc": 53.0, "val_loss": 0.7288560557365418, "val_acc": 52.0}
{"epoch": 46, "training_loss": 0.7054259014129639, "training_acc": 49.0, "val_loss": 0.7141895484924317, "val_acc": 48.0}
