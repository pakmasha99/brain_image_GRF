"main_modify.py --pretrained_path /scratch/connectome/dyhan316/VAE_ADHD/barlowtwins/pretrain_results/ABCDbt128a102.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option BT_org --learning_rate 5e-3 --batch_size 16 --weight_decay 5e-2 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 0.8317274403572082, "training_acc": 62.0, "val_loss": 1.2782748937606812, "val_acc": 52.0}
{"epoch": 1, "training_loss": 1.032749752998352, "training_acc": 41.0, "val_loss": 0.845733573436737, "val_acc": 48.0}
{"epoch": 2, "training_loss": 0.7352214097976685, "training_acc": 55.0, "val_loss": 0.8246986675262451, "val_acc": 52.0}
{"epoch": 3, "training_loss": 0.7923670411109924, "training_acc": 47.0, "val_loss": 0.7238813877105713, "val_acc": 48.0}
{"epoch": 4, "training_loss": 0.738526086807251, "training_acc": 43.0, "val_loss": 0.6937231087684631, "val_acc": 48.0}
{"epoch": 5, "training_loss": 0.7313804244995117, "training_acc": 49.0, "val_loss": 0.7151598858833313, "val_acc": 52.0}
{"epoch": 6, "training_loss": 0.7331242322921753, "training_acc": 53.0, "val_loss": 0.7015666151046753, "val_acc": 48.0}
{"epoch": 7, "training_loss": 0.766487979888916, "training_acc": 43.0, "val_loss": 0.7131546139717102, "val_acc": 52.0}
{"epoch": 8, "training_loss": 0.7435637426376343, "training_acc": 51.0, "val_loss": 0.6933103132247925, "val_acc": 52.0}
{"epoch": 9, "training_loss": 0.711991970539093, "training_acc": 53.0, "val_loss": 0.6935955262184144, "val_acc": 48.0}
{"epoch": 10, "training_loss": 0.6970775318145752, "training_acc": 45.0, "val_loss": 0.6926109433174134, "val_acc": 52.0}
{"epoch": 11, "training_loss": 0.7419075775146484, "training_acc": 47.0, "val_loss": 0.7040250015258789, "val_acc": 52.0}
{"epoch": 12, "training_loss": 0.7287860107421875, "training_acc": 53.0, "val_loss": 0.7182830905914307, "val_acc": 48.0}
{"epoch": 13, "training_loss": 0.7462860584259033, "training_acc": 39.0, "val_loss": 0.692695951461792, "val_acc": 52.0}
{"epoch": 14, "training_loss": 0.7098908424377441, "training_acc": 51.0, "val_loss": 0.6960683393478394, "val_acc": 48.0}
{"epoch": 15, "training_loss": 0.6973955535888672, "training_acc": 53.0, "val_loss": 0.7029453492164612, "val_acc": 52.0}
{"epoch": 16, "training_loss": 0.7046843934059143, "training_acc": 51.0, "val_loss": 0.6959003114700317, "val_acc": 48.0}
{"epoch": 17, "training_loss": 0.6929649829864502, "training_acc": 55.0, "val_loss": 0.6941957783699035, "val_acc": 48.0}
{"epoch": 18, "training_loss": 0.7218953013420105, "training_acc": 51.0, "val_loss": 0.7410843968391418, "val_acc": 52.0}
{"epoch": 19, "training_loss": 0.7309978199005127, "training_acc": 51.0, "val_loss": 0.6933493137359619, "val_acc": 48.0}
{"epoch": 20, "training_loss": 0.702214047908783, "training_acc": 47.0, "val_loss": 0.7197087907791138, "val_acc": 48.0}
{"epoch": 21, "training_loss": 0.7695690250396728, "training_acc": 45.0, "val_loss": 0.7925593113899231, "val_acc": 52.0}
{"epoch": 22, "training_loss": 0.7951523876190185, "training_acc": 39.0, "val_loss": 0.6929738187789917, "val_acc": 52.0}
{"epoch": 23, "training_loss": 0.7081347179412841, "training_acc": 53.0, "val_loss": 0.7149307370185852, "val_acc": 48.0}
{"epoch": 24, "training_loss": 0.780687837600708, "training_acc": 47.0, "val_loss": 0.7084394884109497, "val_acc": 52.0}
{"epoch": 25, "training_loss": 0.7231838870048523, "training_acc": 49.0, "val_loss": 0.6926390457153321, "val_acc": 52.0}
{"epoch": 26, "training_loss": 0.7202749156951904, "training_acc": 53.0, "val_loss": 0.6924178624153137, "val_acc": 52.0}
{"epoch": 27, "training_loss": 0.7166974020004272, "training_acc": 55.0, "val_loss": 0.7450876975059509, "val_acc": 48.0}
{"epoch": 28, "training_loss": 0.7446175861358643, "training_acc": 43.0, "val_loss": 0.7246261525154114, "val_acc": 52.0}
{"epoch": 29, "training_loss": 0.7334856271743775, "training_acc": 53.0, "val_loss": 0.692968327999115, "val_acc": 52.0}
{"epoch": 30, "training_loss": 0.714638090133667, "training_acc": 49.0, "val_loss": 0.6931612634658814, "val_acc": 52.0}
{"epoch": 31, "training_loss": 0.7102793693542481, "training_acc": 53.0, "val_loss": 0.708907790184021, "val_acc": 52.0}
{"epoch": 32, "training_loss": 0.7110877656936645, "training_acc": 53.0, "val_loss": 0.7010096883773804, "val_acc": 48.0}
{"epoch": 33, "training_loss": 0.7272287893295288, "training_acc": 49.0, "val_loss": 0.7145342874526978, "val_acc": 52.0}
{"epoch": 34, "training_loss": 0.7190532398223877, "training_acc": 53.0, "val_loss": 0.6955097913742065, "val_acc": 48.0}
{"epoch": 35, "training_loss": 0.7735376620292663, "training_acc": 47.0, "val_loss": 0.7115670919418335, "val_acc": 52.0}
{"epoch": 36, "training_loss": 0.7414782047271729, "training_acc": 53.0, "val_loss": 0.6970432305335998, "val_acc": 48.0}
{"epoch": 37, "training_loss": 0.7112582683563232, "training_acc": 47.0, "val_loss": 0.6937245917320252, "val_acc": 48.0}
{"epoch": 38, "training_loss": 0.7090357112884521, "training_acc": 45.0, "val_loss": 0.7009875297546386, "val_acc": 52.0}
{"epoch": 39, "training_loss": 0.6969613528251648, "training_acc": 53.0, "val_loss": 0.7069918894767762, "val_acc": 48.0}
{"epoch": 40, "training_loss": 0.7124379396438598, "training_acc": 37.0, "val_loss": 0.6939957571029663, "val_acc": 52.0}
{"epoch": 41, "training_loss": 0.7020504808425904, "training_acc": 53.0, "val_loss": 0.6939007115364074, "val_acc": 52.0}
{"epoch": 42, "training_loss": 0.6980730867385865, "training_acc": 45.0, "val_loss": 0.6965687966346741, "val_acc": 52.0}
{"epoch": 43, "training_loss": 0.6969153618812561, "training_acc": 53.0, "val_loss": 0.7000619459152222, "val_acc": 52.0}
{"epoch": 44, "training_loss": 0.6984834861755371, "training_acc": 53.0, "val_loss": 0.6925855922698975, "val_acc": 52.0}
{"epoch": 45, "training_loss": 0.6927540302276611, "training_acc": 49.0, "val_loss": 0.6999002194404602, "val_acc": 48.0}
