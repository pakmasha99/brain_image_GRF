"main_modify.py --pretrained_path /scratch/connectome/dyhan316/VAE_ADHD/barlowtwins/pretrain_results/ABCDbt128a102.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option BT_org --learning_rate 1e-3 --batch_size 16 --weight_decay 1e-6 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 0.7346824836730957, "training_acc": 45.0, "val_loss": 0.6997355651855469, "val_acc": 52.0}
{"epoch": 1, "training_loss": 0.7195058059692383, "training_acc": 53.0, "val_loss": 0.6951678395271301, "val_acc": 52.0}
{"epoch": 2, "training_loss": 0.6966394114494324, "training_acc": 53.0, "val_loss": 0.6945439219474793, "val_acc": 48.0}
{"epoch": 3, "training_loss": 0.6978678464889526, "training_acc": 47.0, "val_loss": 0.6929558134078979, "val_acc": 52.0}
{"epoch": 4, "training_loss": 0.6966058373451233, "training_acc": 47.0, "val_loss": 0.6936122441291809, "val_acc": 52.0}
{"epoch": 5, "training_loss": 0.7033125305175781, "training_acc": 53.0, "val_loss": 0.6940933537483215, "val_acc": 52.0}
{"epoch": 6, "training_loss": 0.7157531952857972, "training_acc": 39.0, "val_loss": 0.6926862692832947, "val_acc": 52.0}
{"epoch": 7, "training_loss": 0.6931816148757934, "training_acc": 53.0, "val_loss": 0.70822674036026, "val_acc": 52.0}
{"epoch": 8, "training_loss": 0.7000317931175232, "training_acc": 53.0, "val_loss": 0.6928278398513794, "val_acc": 52.0}
{"epoch": 9, "training_loss": 0.6919330191612244, "training_acc": 53.0, "val_loss": 0.6932771301269531, "val_acc": 48.0}
{"epoch": 10, "training_loss": 0.7015701389312744, "training_acc": 47.0, "val_loss": 0.6953161144256592, "val_acc": 48.0}
{"epoch": 11, "training_loss": 0.6943004631996155, "training_acc": 51.0, "val_loss": 0.7005064487457275, "val_acc": 52.0}
{"epoch": 12, "training_loss": 0.7000634241104126, "training_acc": 53.0, "val_loss": 0.6935457181930542, "val_acc": 52.0}
{"epoch": 13, "training_loss": 0.6943942523002624, "training_acc": 53.0, "val_loss": 0.6927511310577392, "val_acc": 52.0}
{"epoch": 14, "training_loss": 0.6937011480331421, "training_acc": 53.0, "val_loss": 0.6923620247840881, "val_acc": 52.0}
{"epoch": 15, "training_loss": 0.7111610364913941, "training_acc": 45.0, "val_loss": 0.6975429153442383, "val_acc": 48.0}
{"epoch": 16, "training_loss": 0.7148016166687011, "training_acc": 49.0, "val_loss": 0.7094488906860351, "val_acc": 52.0}
{"epoch": 17, "training_loss": 0.6993329167366028, "training_acc": 53.0, "val_loss": 0.6923838591575623, "val_acc": 52.0}
{"epoch": 18, "training_loss": 0.6931938695907592, "training_acc": 53.0, "val_loss": 0.6925480270385742, "val_acc": 52.0}
{"epoch": 19, "training_loss": 0.69275634765625, "training_acc": 53.0, "val_loss": 0.6928679347038269, "val_acc": 52.0}
{"epoch": 20, "training_loss": 0.6912739562988282, "training_acc": 53.0, "val_loss": 0.6957059144973755, "val_acc": 52.0}
{"epoch": 21, "training_loss": 0.6957440423965454, "training_acc": 53.0, "val_loss": 0.6925444316864013, "val_acc": 52.0}
{"epoch": 22, "training_loss": 0.6998221397399902, "training_acc": 47.0, "val_loss": 0.7018605422973633, "val_acc": 48.0}
{"epoch": 23, "training_loss": 0.6991039514541626, "training_acc": 47.0, "val_loss": 0.6925444912910461, "val_acc": 52.0}
{"epoch": 24, "training_loss": 0.701070852279663, "training_acc": 53.0, "val_loss": 0.7115373492240906, "val_acc": 52.0}
{"epoch": 25, "training_loss": 0.6969627451896667, "training_acc": 53.0, "val_loss": 0.6923871302604675, "val_acc": 52.0}
{"epoch": 26, "training_loss": 0.6929684281349182, "training_acc": 51.0, "val_loss": 0.69484778881073, "val_acc": 48.0}
{"epoch": 27, "training_loss": 0.6971521830558777, "training_acc": 47.0, "val_loss": 0.6923492527008057, "val_acc": 52.0}
{"epoch": 28, "training_loss": 0.6947007083892822, "training_acc": 53.0, "val_loss": 0.6988351464271545, "val_acc": 52.0}
{"epoch": 29, "training_loss": 0.6960207509994507, "training_acc": 53.0, "val_loss": 0.6934196257591247, "val_acc": 52.0}
{"epoch": 30, "training_loss": 0.6928461742401123, "training_acc": 49.0, "val_loss": 0.6958045649528504, "val_acc": 48.0}
{"epoch": 31, "training_loss": 0.6957922172546387, "training_acc": 45.0, "val_loss": 0.6948418927192688, "val_acc": 52.0}
{"epoch": 32, "training_loss": 0.6963147115707398, "training_acc": 53.0, "val_loss": 0.6951564502716064, "val_acc": 52.0}
{"epoch": 33, "training_loss": 0.6914083957672119, "training_acc": 53.0, "val_loss": 0.6939938259124756, "val_acc": 48.0}
{"epoch": 34, "training_loss": 0.6948577547073365, "training_acc": 47.0, "val_loss": 0.6926139903068542, "val_acc": 52.0}
{"epoch": 35, "training_loss": 0.6952616119384766, "training_acc": 53.0, "val_loss": 0.7002025961875915, "val_acc": 52.0}
{"epoch": 36, "training_loss": 0.6958588552474976, "training_acc": 53.0, "val_loss": 0.6923669743537902, "val_acc": 52.0}
{"epoch": 37, "training_loss": 0.6944390177726746, "training_acc": 53.0, "val_loss": 0.6994787621498108, "val_acc": 52.0}
{"epoch": 38, "training_loss": 0.7006634712219239, "training_acc": 53.0, "val_loss": 0.6989155197143555, "val_acc": 52.0}
{"epoch": 39, "training_loss": 0.6937749218940735, "training_acc": 53.0, "val_loss": 0.6923856353759765, "val_acc": 52.0}
{"epoch": 40, "training_loss": 0.6932629632949829, "training_acc": 53.0, "val_loss": 0.6923992538452148, "val_acc": 52.0}
{"epoch": 41, "training_loss": 0.6920672082901, "training_acc": 53.0, "val_loss": 0.694944839477539, "val_acc": 52.0}
{"epoch": 42, "training_loss": 0.6950643944740296, "training_acc": 53.0, "val_loss": 0.6925027513504028, "val_acc": 52.0}
{"epoch": 43, "training_loss": 0.6950306797027588, "training_acc": 53.0, "val_loss": 0.6967196679115295, "val_acc": 52.0}
{"epoch": 44, "training_loss": 0.7047673368453979, "training_acc": 53.0, "val_loss": 0.6960934090614319, "val_acc": 52.0}
{"epoch": 45, "training_loss": 0.7004109287261963, "training_acc": 43.0, "val_loss": 0.6981709504127502, "val_acc": 48.0}
{"epoch": 46, "training_loss": 0.6984692549705506, "training_acc": 47.0, "val_loss": 0.6923562216758729, "val_acc": 52.0}
