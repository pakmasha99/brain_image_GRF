"main_modify.py --pretrained_path /scratch/connectome/dyhan316/VAE_ADHD/barlowtwins/pretrain_results/ABCDbt128a102.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 1 --task ABCD_sex --input_option BT_org --learning_rate 1e-3 --batch_size 16 --weight_decay 1e-6 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 0.7128407287597657, "training_acc": 48.0, "val_loss": 0.7037260341644287, "val_acc": 52.0}
{"epoch": 1, "training_loss": 0.7164360880851746, "training_acc": 53.0, "val_loss": 0.7092716407775879, "val_acc": 52.0}
{"epoch": 2, "training_loss": 0.7039600276947021, "training_acc": 53.0, "val_loss": 0.6943619537353516, "val_acc": 52.0}
{"epoch": 3, "training_loss": 0.7058768367767334, "training_acc": 41.0, "val_loss": 0.6927652359008789, "val_acc": 52.0}
{"epoch": 4, "training_loss": 0.697438588142395, "training_acc": 45.0, "val_loss": 0.6961570477485657, "val_acc": 52.0}
{"epoch": 5, "training_loss": 0.7118410754203797, "training_acc": 53.0, "val_loss": 0.7008340001106262, "val_acc": 52.0}
{"epoch": 6, "training_loss": 0.6978109884262085, "training_acc": 53.0, "val_loss": 0.6950998425483703, "val_acc": 48.0}
{"epoch": 7, "training_loss": 0.7030037403106689, "training_acc": 47.0, "val_loss": 0.6924054598808289, "val_acc": 52.0}
{"epoch": 8, "training_loss": 0.6926745700836182, "training_acc": 53.0, "val_loss": 0.6958461809158325, "val_acc": 52.0}
{"epoch": 9, "training_loss": 0.6970535564422607, "training_acc": 53.0, "val_loss": 0.6923506474494934, "val_acc": 52.0}
{"epoch": 10, "training_loss": 0.7068650197982788, "training_acc": 43.0, "val_loss": 0.6932327032089234, "val_acc": 48.0}
{"epoch": 11, "training_loss": 0.6919043183326721, "training_acc": 55.0, "val_loss": 0.6979016613960266, "val_acc": 52.0}
{"epoch": 12, "training_loss": 0.6988388156890869, "training_acc": 53.0, "val_loss": 0.6962867403030395, "val_acc": 52.0}
{"epoch": 13, "training_loss": 0.6914942359924316, "training_acc": 53.0, "val_loss": 0.6939070844650268, "val_acc": 48.0}
{"epoch": 14, "training_loss": 0.711059501171112, "training_acc": 47.0, "val_loss": 0.6974391937255859, "val_acc": 48.0}
{"epoch": 15, "training_loss": 0.7226771545410157, "training_acc": 45.0, "val_loss": 0.6979487586021423, "val_acc": 52.0}
{"epoch": 16, "training_loss": 0.6927549958229064, "training_acc": 53.0, "val_loss": 0.692672004699707, "val_acc": 52.0}
{"epoch": 17, "training_loss": 0.6929480457305908, "training_acc": 53.0, "val_loss": 0.6928267621994019, "val_acc": 52.0}
{"epoch": 18, "training_loss": 0.6941860818862915, "training_acc": 47.0, "val_loss": 0.6930834579467774, "val_acc": 52.0}
{"epoch": 19, "training_loss": 0.6896022462844849, "training_acc": 53.0, "val_loss": 0.6963942456245422, "val_acc": 52.0}
{"epoch": 20, "training_loss": 0.7027681589126586, "training_acc": 53.0, "val_loss": 0.6945283246040345, "val_acc": 52.0}
{"epoch": 21, "training_loss": 0.695882523059845, "training_acc": 53.0, "val_loss": 0.6942436289787293, "val_acc": 52.0}
{"epoch": 22, "training_loss": 0.698851158618927, "training_acc": 53.0, "val_loss": 0.6971377992630005, "val_acc": 52.0}
{"epoch": 23, "training_loss": 0.6931378722190857, "training_acc": 47.0, "val_loss": 0.6974989438056945, "val_acc": 48.0}
{"epoch": 24, "training_loss": 0.7085294461250305, "training_acc": 47.0, "val_loss": 0.6927872467041015, "val_acc": 52.0}
{"epoch": 25, "training_loss": 0.6912286615371704, "training_acc": 53.0, "val_loss": 0.71646968126297, "val_acc": 52.0}
{"epoch": 26, "training_loss": 0.7055322027206421, "training_acc": 53.0, "val_loss": 0.6932303595542908, "val_acc": 52.0}
{"epoch": 27, "training_loss": 0.6972204375267029, "training_acc": 53.0, "val_loss": 0.6926446843147278, "val_acc": 52.0}
{"epoch": 28, "training_loss": 0.7121840596199036, "training_acc": 43.0, "val_loss": 0.7018536114692688, "val_acc": 48.0}
