"main_modify.py --pretrained_path /scratch/connectome/dyhan316/VAE_ADHD/barlowtwins/pretrain_results/ABCDbt128a102.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 1 --task ABCD_sex --input_option BT_org --learning_rate 1e-3 --batch_size 16 --weight_decay 1e-6 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 0.7222818875312805, "training_acc": 46.0, "val_loss": 0.6954994583129883, "val_acc": 52.0}
{"epoch": 1, "training_loss": 0.6956456565856933, "training_acc": 53.0, "val_loss": 0.6940243601799011, "val_acc": 48.0}
{"epoch": 2, "training_loss": 0.6981180214881897, "training_acc": 47.0, "val_loss": 0.6926787781715393, "val_acc": 52.0}
{"epoch": 3, "training_loss": 0.7004595375061036, "training_acc": 43.0, "val_loss": 0.6926740193367005, "val_acc": 52.0}
{"epoch": 4, "training_loss": 0.7048009014129639, "training_acc": 39.0, "val_loss": 0.6953215146064758, "val_acc": 52.0}
{"epoch": 5, "training_loss": 0.7201203536987305, "training_acc": 53.0, "val_loss": 0.6991443324089051, "val_acc": 52.0}
{"epoch": 6, "training_loss": 0.7018050241470337, "training_acc": 43.0, "val_loss": 0.6929386401176453, "val_acc": 52.0}
{"epoch": 7, "training_loss": 0.6933934879302979, "training_acc": 47.0, "val_loss": 0.6961825919151307, "val_acc": 52.0}
{"epoch": 8, "training_loss": 0.6947962403297424, "training_acc": 53.0, "val_loss": 0.7022371983528137, "val_acc": 52.0}
{"epoch": 9, "training_loss": 0.7053341484069824, "training_acc": 53.0, "val_loss": 0.6923768305778504, "val_acc": 52.0}
{"epoch": 10, "training_loss": 0.6944861507415772, "training_acc": 45.0, "val_loss": 0.6924367070198059, "val_acc": 52.0}
{"epoch": 11, "training_loss": 0.7068147659301758, "training_acc": 53.0, "val_loss": 0.6957367825508117, "val_acc": 52.0}
{"epoch": 12, "training_loss": 0.7014068102836609, "training_acc": 45.0, "val_loss": 0.6923678636550903, "val_acc": 52.0}
{"epoch": 13, "training_loss": 0.6912615203857422, "training_acc": 53.0, "val_loss": 0.7005089497566224, "val_acc": 52.0}
{"epoch": 14, "training_loss": 0.6955462551116943, "training_acc": 53.0, "val_loss": 0.692531235218048, "val_acc": 52.0}
{"epoch": 15, "training_loss": 0.6947229409217834, "training_acc": 51.0, "val_loss": 0.6924040365219116, "val_acc": 52.0}
{"epoch": 16, "training_loss": 0.6920299911499024, "training_acc": 53.0, "val_loss": 0.7001897287368775, "val_acc": 52.0}
{"epoch": 17, "training_loss": 0.7084297776222229, "training_acc": 53.0, "val_loss": 0.6977136826515198, "val_acc": 52.0}
{"epoch": 18, "training_loss": 0.6937251710891723, "training_acc": 51.0, "val_loss": 0.6931314420700073, "val_acc": 52.0}
{"epoch": 19, "training_loss": 0.6926546025276185, "training_acc": 53.0, "val_loss": 0.6945441627502441, "val_acc": 52.0}
{"epoch": 20, "training_loss": 0.701184766292572, "training_acc": 53.0, "val_loss": 0.6929868650436402, "val_acc": 52.0}
{"epoch": 21, "training_loss": 0.7159592294692994, "training_acc": 43.0, "val_loss": 0.6997761654853821, "val_acc": 48.0}
{"epoch": 22, "training_loss": 0.6930950021743775, "training_acc": 53.0, "val_loss": 0.6994324231147766, "val_acc": 52.0}
{"epoch": 23, "training_loss": 0.6937009072303773, "training_acc": 53.0, "val_loss": 0.6928477835655212, "val_acc": 52.0}
{"epoch": 24, "training_loss": 0.7015108013153076, "training_acc": 43.0, "val_loss": 0.6943375182151794, "val_acc": 48.0}
{"epoch": 25, "training_loss": 0.6907667016983032, "training_acc": 51.0, "val_loss": 0.7020889782905578, "val_acc": 52.0}
{"epoch": 26, "training_loss": 0.706194806098938, "training_acc": 53.0, "val_loss": 0.6986706280708312, "val_acc": 52.0}
{"epoch": 27, "training_loss": 0.6980286693572998, "training_acc": 51.0, "val_loss": 0.6989772820472717, "val_acc": 48.0}
{"epoch": 28, "training_loss": 0.7002900528907776, "training_acc": 47.0, "val_loss": 0.6931467223167419, "val_acc": 48.0}
{"epoch": 29, "training_loss": 0.6977131986618041, "training_acc": 51.0, "val_loss": 0.693680305480957, "val_acc": 52.0}
{"epoch": 30, "training_loss": 0.7268806910514831, "training_acc": 39.0, "val_loss": 0.7004290699958802, "val_acc": 48.0}
{"epoch": 31, "training_loss": 0.7123909568786622, "training_acc": 51.0, "val_loss": 0.7089952564239502, "val_acc": 52.0}
{"epoch": 32, "training_loss": 0.6980371308326722, "training_acc": 53.0, "val_loss": 0.6923487782478333, "val_acc": 52.0}
{"epoch": 33, "training_loss": 0.6939156532287598, "training_acc": 53.0, "val_loss": 0.6936103558540344, "val_acc": 48.0}
{"epoch": 34, "training_loss": 0.7079135179519653, "training_acc": 47.0, "val_loss": 0.7023764538764954, "val_acc": 48.0}
{"epoch": 35, "training_loss": 0.6953405380249024, "training_acc": 51.0, "val_loss": 0.6948844838142395, "val_acc": 52.0}
{"epoch": 36, "training_loss": 0.6942108249664307, "training_acc": 53.0, "val_loss": 0.695806155204773, "val_acc": 52.0}
{"epoch": 37, "training_loss": 0.6898658943176269, "training_acc": 53.0, "val_loss": 0.6947337675094605, "val_acc": 48.0}
{"epoch": 38, "training_loss": 0.7060087656974793, "training_acc": 47.0, "val_loss": 0.6984896969795227, "val_acc": 48.0}
{"epoch": 39, "training_loss": 0.7077101039886474, "training_acc": 49.0, "val_loss": 0.6966210508346558, "val_acc": 52.0}
{"epoch": 40, "training_loss": 0.7064375019073487, "training_acc": 47.0, "val_loss": 0.6956170797348022, "val_acc": 48.0}
{"epoch": 41, "training_loss": 0.6887373065948487, "training_acc": 59.0, "val_loss": 0.7025604557991028, "val_acc": 52.0}
{"epoch": 42, "training_loss": 0.6987667417526245, "training_acc": 53.0, "val_loss": 0.6958254981040954, "val_acc": 52.0}
{"epoch": 43, "training_loss": 0.6947635459899902, "training_acc": 53.0, "val_loss": 0.6926365280151368, "val_acc": 52.0}
{"epoch": 44, "training_loss": 0.7052707576751709, "training_acc": 45.0, "val_loss": 0.6955493974685669, "val_acc": 48.0}
{"epoch": 45, "training_loss": 0.7040347290039063, "training_acc": 51.0, "val_loss": 0.7021775150299072, "val_acc": 52.0}
{"epoch": 46, "training_loss": 0.6968614101409912, "training_acc": 53.0, "val_loss": 0.6927566075325012, "val_acc": 52.0}
{"epoch": 47, "training_loss": 0.6936976432800293, "training_acc": 53.0, "val_loss": 0.692684109210968, "val_acc": 52.0}
{"epoch": 48, "training_loss": 0.7045513153076172, "training_acc": 41.0, "val_loss": 0.6932924747467041, "val_acc": 48.0}
{"epoch": 49, "training_loss": 0.6953427886962891, "training_acc": 53.0, "val_loss": 0.6999830627441406, "val_acc": 52.0}
{"epoch": 50, "training_loss": 0.700460069179535, "training_acc": 53.0, "val_loss": 0.6980006837844849, "val_acc": 52.0}
{"epoch": 51, "training_loss": 0.6943572664260864, "training_acc": 53.0, "val_loss": 0.6927897381782532, "val_acc": 52.0}
