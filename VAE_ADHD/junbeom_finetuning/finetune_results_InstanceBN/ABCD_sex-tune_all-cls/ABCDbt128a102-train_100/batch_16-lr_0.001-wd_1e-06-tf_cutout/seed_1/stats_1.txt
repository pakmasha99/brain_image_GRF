"main_modify.py --pretrained_path /scratch/connectome/dyhan316/VAE_ADHD/barlowtwins/pretrain_results/ABCDbt128a102.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 1 --task ABCD_sex --input_option BT_org --learning_rate 1e-3 --batch_size 16 --weight_decay 1e-6 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 0.6961718916893005, "training_acc": 53.0, "val_loss": 0.7159171652793884, "val_acc": 52.0}
{"epoch": 1, "training_loss": 0.7108962273597718, "training_acc": 53.0, "val_loss": 0.6948599219322205, "val_acc": 48.0}
{"epoch": 2, "training_loss": 0.7279366731643677, "training_acc": 47.0, "val_loss": 0.6934012651443482, "val_acc": 52.0}
{"epoch": 3, "training_loss": 0.7174494552612305, "training_acc": 53.0, "val_loss": 0.7052259802818298, "val_acc": 52.0}
{"epoch": 4, "training_loss": 0.7161084985733033, "training_acc": 43.0, "val_loss": 0.6957102990150452, "val_acc": 48.0}
{"epoch": 5, "training_loss": 0.7328198337554932, "training_acc": 47.0, "val_loss": 0.7085725474357605, "val_acc": 52.0}
{"epoch": 6, "training_loss": 0.7016925048828125, "training_acc": 53.0, "val_loss": 0.6924302196502685, "val_acc": 52.0}
{"epoch": 7, "training_loss": 0.6958754014968872, "training_acc": 53.0, "val_loss": 0.6929910755157471, "val_acc": 52.0}
{"epoch": 8, "training_loss": 0.6950754499435425, "training_acc": 53.0, "val_loss": 0.6927616715431213, "val_acc": 52.0}
{"epoch": 9, "training_loss": 0.7104525899887085, "training_acc": 53.0, "val_loss": 0.6951371359825135, "val_acc": 52.0}
{"epoch": 10, "training_loss": 0.6940046024322509, "training_acc": 53.0, "val_loss": 0.6923987913131714, "val_acc": 52.0}
{"epoch": 11, "training_loss": 0.6920369529724121, "training_acc": 53.0, "val_loss": 0.6924580121040345, "val_acc": 52.0}
{"epoch": 12, "training_loss": 0.6952263832092285, "training_acc": 53.0, "val_loss": 0.6932206439971924, "val_acc": 52.0}
{"epoch": 13, "training_loss": 0.6935530877113343, "training_acc": 53.0, "val_loss": 0.6928363466262817, "val_acc": 52.0}
{"epoch": 14, "training_loss": 0.6951603651046753, "training_acc": 53.0, "val_loss": 0.6925125503540039, "val_acc": 52.0}
{"epoch": 15, "training_loss": 0.6979033017158508, "training_acc": 43.0, "val_loss": 0.6949166989326477, "val_acc": 48.0}
{"epoch": 16, "training_loss": 0.6904054021835327, "training_acc": 51.0, "val_loss": 0.6962533879280091, "val_acc": 52.0}
{"epoch": 17, "training_loss": 0.6977703833580017, "training_acc": 53.0, "val_loss": 0.6967647838592529, "val_acc": 52.0}
{"epoch": 18, "training_loss": 0.6976137924194336, "training_acc": 53.0, "val_loss": 0.6942336177825927, "val_acc": 52.0}
{"epoch": 19, "training_loss": 0.6889754676818848, "training_acc": 53.0, "val_loss": 0.6988258910179138, "val_acc": 48.0}
{"epoch": 20, "training_loss": 0.7005336570739746, "training_acc": 45.0, "val_loss": 0.6925807690620422, "val_acc": 52.0}
{"epoch": 21, "training_loss": 0.698787944316864, "training_acc": 43.0, "val_loss": 0.6927264523506165, "val_acc": 52.0}
{"epoch": 22, "training_loss": 0.7217704153060913, "training_acc": 53.0, "val_loss": 0.7100040555000305, "val_acc": 52.0}
{"epoch": 23, "training_loss": 0.6877048516273498, "training_acc": 53.0, "val_loss": 0.6956483435630798, "val_acc": 48.0}
{"epoch": 24, "training_loss": 0.7036713862419128, "training_acc": 47.0, "val_loss": 0.6985290622711182, "val_acc": 48.0}
{"epoch": 25, "training_loss": 0.7000499534606933, "training_acc": 47.0, "val_loss": 0.6924249744415283, "val_acc": 52.0}
{"epoch": 26, "training_loss": 0.6937455248832702, "training_acc": 49.0, "val_loss": 0.6924356937408447, "val_acc": 52.0}
{"epoch": 27, "training_loss": 0.7049388647079468, "training_acc": 53.0, "val_loss": 0.7046534824371338, "val_acc": 52.0}
{"epoch": 28, "training_loss": 0.6940412950515747, "training_acc": 53.0, "val_loss": 0.6924982047080994, "val_acc": 52.0}
{"epoch": 29, "training_loss": 0.709818069934845, "training_acc": 41.0, "val_loss": 0.6965422463417054, "val_acc": 48.0}
{"epoch": 30, "training_loss": 0.6968567991256713, "training_acc": 47.0, "val_loss": 0.6923980283737182, "val_acc": 52.0}
{"epoch": 31, "training_loss": 0.7044047403335572, "training_acc": 53.0, "val_loss": 0.6986505103111267, "val_acc": 52.0}
{"epoch": 32, "training_loss": 0.6946955823898315, "training_acc": 53.0, "val_loss": 0.6925966835021973, "val_acc": 52.0}
{"epoch": 33, "training_loss": 0.7030169749259949, "training_acc": 45.0, "val_loss": 0.694610321521759, "val_acc": 48.0}
{"epoch": 34, "training_loss": 0.6924551963806153, "training_acc": 53.0, "val_loss": 0.6986184740066528, "val_acc": 52.0}
{"epoch": 35, "training_loss": 0.699812605381012, "training_acc": 53.0, "val_loss": 0.6933464932441712, "val_acc": 52.0}
{"epoch": 36, "training_loss": 0.6987474465370178, "training_acc": 53.0, "val_loss": 0.6927307105064392, "val_acc": 52.0}
{"epoch": 37, "training_loss": 0.6969127893447876, "training_acc": 47.0, "val_loss": 0.6939834189414978, "val_acc": 48.0}
{"epoch": 38, "training_loss": 0.6938276672363282, "training_acc": 47.0, "val_loss": 0.6932552099227905, "val_acc": 52.0}
{"epoch": 39, "training_loss": 0.6918805742263794, "training_acc": 53.0, "val_loss": 0.6953176426887512, "val_acc": 52.0}
{"epoch": 40, "training_loss": 0.6944298601150513, "training_acc": 53.0, "val_loss": 0.6927067899703979, "val_acc": 52.0}
{"epoch": 41, "training_loss": 0.6982502937316895, "training_acc": 53.0, "val_loss": 0.693626937866211, "val_acc": 52.0}
{"epoch": 42, "training_loss": 0.7029711794853211, "training_acc": 45.0, "val_loss": 0.6962394618988037, "val_acc": 48.0}
{"epoch": 43, "training_loss": 0.6914622211456298, "training_acc": 51.0, "val_loss": 0.6944441962242126, "val_acc": 52.0}
{"epoch": 44, "training_loss": 0.6979105424880981, "training_acc": 53.0, "val_loss": 0.6923605847358704, "val_acc": 52.0}
{"epoch": 45, "training_loss": 0.693633348941803, "training_acc": 53.0, "val_loss": 0.6946021342277526, "val_acc": 52.0}
{"epoch": 46, "training_loss": 0.695563621520996, "training_acc": 53.0, "val_loss": 0.6962174725532532, "val_acc": 52.0}
{"epoch": 47, "training_loss": 0.696503131389618, "training_acc": 51.0, "val_loss": 0.6930798482894898, "val_acc": 52.0}
{"epoch": 48, "training_loss": 0.6981526279449463, "training_acc": 41.0, "val_loss": 0.6923813199996949, "val_acc": 52.0}
{"epoch": 49, "training_loss": 0.6920507431030274, "training_acc": 53.0, "val_loss": 0.6930806851387024, "val_acc": 52.0}
{"epoch": 50, "training_loss": 0.7041497373580933, "training_acc": 39.0, "val_loss": 0.6926991724967957, "val_acc": 52.0}
{"epoch": 51, "training_loss": 0.6967759537696838, "training_acc": 53.0, "val_loss": 0.6955460643768311, "val_acc": 52.0}
{"epoch": 52, "training_loss": 0.6985990381240845, "training_acc": 53.0, "val_loss": 0.6958978080749512, "val_acc": 52.0}
{"epoch": 53, "training_loss": 0.6917225241661071, "training_acc": 53.0, "val_loss": 0.6932349300384522, "val_acc": 48.0}
{"epoch": 54, "training_loss": 0.6976321315765381, "training_acc": 47.0, "val_loss": 0.6971708416938782, "val_acc": 48.0}
{"epoch": 55, "training_loss": 0.6958644151687622, "training_acc": 49.0, "val_loss": 0.6931820130348205, "val_acc": 52.0}
{"epoch": 56, "training_loss": 0.6916445302963257, "training_acc": 53.0, "val_loss": 0.6963538098335266, "val_acc": 52.0}
{"epoch": 57, "training_loss": 0.6979931163787841, "training_acc": 53.0, "val_loss": 0.701069552898407, "val_acc": 52.0}
{"epoch": 58, "training_loss": 0.6974718880653381, "training_acc": 53.0, "val_loss": 0.6925232791900635, "val_acc": 52.0}
{"epoch": 59, "training_loss": 0.6929864025115967, "training_acc": 53.0, "val_loss": 0.6939540815353393, "val_acc": 52.0}
{"epoch": 60, "training_loss": 0.6924577379226684, "training_acc": 53.0, "val_loss": 0.6923566842079163, "val_acc": 52.0}
{"epoch": 61, "training_loss": 0.6967795062065124, "training_acc": 53.0, "val_loss": 0.6931822943687439, "val_acc": 52.0}
{"epoch": 62, "training_loss": 0.7010187578201293, "training_acc": 43.0, "val_loss": 0.696595458984375, "val_acc": 48.0}
{"epoch": 63, "training_loss": 0.6985428380966187, "training_acc": 47.0, "val_loss": 0.693267867565155, "val_acc": 48.0}
{"epoch": 64, "training_loss": 0.697249858379364, "training_acc": 49.0, "val_loss": 0.6967518925666809, "val_acc": 52.0}
{"epoch": 65, "training_loss": 0.6932707786560058, "training_acc": 53.0, "val_loss": 0.6930022811889649, "val_acc": 52.0}
{"epoch": 66, "training_loss": 0.6981194615364075, "training_acc": 43.0, "val_loss": 0.6945966672897339, "val_acc": 48.0}
{"epoch": 67, "training_loss": 0.6992130541801452, "training_acc": 47.0, "val_loss": 0.6925606656074524, "val_acc": 52.0}
{"epoch": 68, "training_loss": 0.6953107810020447, "training_acc": 53.0, "val_loss": 0.7103682732582093, "val_acc": 52.0}
{"epoch": 69, "training_loss": 0.7029106855392456, "training_acc": 53.0, "val_loss": 0.693616828918457, "val_acc": 52.0}
{"epoch": 70, "training_loss": 0.6929299449920654, "training_acc": 53.0, "val_loss": 0.6923772358894348, "val_acc": 52.0}
{"epoch": 71, "training_loss": 0.7007514667510987, "training_acc": 47.0, "val_loss": 0.7002187657356262, "val_acc": 48.0}
{"epoch": 72, "training_loss": 0.700006103515625, "training_acc": 41.0, "val_loss": 0.692950050830841, "val_acc": 52.0}
{"epoch": 73, "training_loss": 0.6931737422943115, "training_acc": 53.0, "val_loss": 0.6937406635284424, "val_acc": 52.0}
{"epoch": 74, "training_loss": 0.6933337450027466, "training_acc": 53.0, "val_loss": 0.6925513458251953, "val_acc": 52.0}
{"epoch": 75, "training_loss": 0.6960761547088623, "training_acc": 53.0, "val_loss": 0.6955461049079895, "val_acc": 52.0}
{"epoch": 76, "training_loss": 0.7015074634552002, "training_acc": 43.0, "val_loss": 0.6936480402946472, "val_acc": 48.0}
{"epoch": 77, "training_loss": 0.6919163298606873, "training_acc": 51.0, "val_loss": 0.6945231914520263, "val_acc": 52.0}
{"epoch": 78, "training_loss": 0.7018165588378906, "training_acc": 53.0, "val_loss": 0.699968409538269, "val_acc": 52.0}
{"epoch": 79, "training_loss": 0.7008621048927307, "training_acc": 45.0, "val_loss": 0.6932526516914368, "val_acc": 48.0}
