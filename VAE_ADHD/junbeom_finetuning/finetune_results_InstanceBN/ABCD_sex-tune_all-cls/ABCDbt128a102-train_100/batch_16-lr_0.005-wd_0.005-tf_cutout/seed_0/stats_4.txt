"main_modify.py --pretrained_path /scratch/connectome/dyhan316/VAE_ADHD/barlowtwins/pretrain_results/ABCDbt128a102.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option BT_org --learning_rate 5e-3 --batch_size 16 --weight_decay 5e-3 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 0.7392546510696412, "training_acc": 57.0, "val_loss": 0.6925076699256897, "val_acc": 52.0}
{"epoch": 1, "training_loss": 0.8156880211830139, "training_acc": 55.0, "val_loss": 0.9478817772865296, "val_acc": 48.0}
{"epoch": 2, "training_loss": 0.9295844864845276, "training_acc": 49.0, "val_loss": 0.9411290502548217, "val_acc": 52.0}
{"epoch": 3, "training_loss": 0.8908300018310547, "training_acc": 53.0, "val_loss": 0.7820460176467896, "val_acc": 48.0}
{"epoch": 4, "training_loss": 0.8723288536071777, "training_acc": 49.0, "val_loss": 0.8077695751190186, "val_acc": 52.0}
{"epoch": 5, "training_loss": 0.8042433834075928, "training_acc": 53.0, "val_loss": 0.6998345255851746, "val_acc": 48.0}
{"epoch": 6, "training_loss": 0.7583635449409485, "training_acc": 47.0, "val_loss": 0.6989326000213623, "val_acc": 52.0}
{"epoch": 7, "training_loss": 0.700216932296753, "training_acc": 49.0, "val_loss": 0.6977213883399963, "val_acc": 52.0}
{"epoch": 8, "training_loss": 0.6981492853164672, "training_acc": 51.0, "val_loss": 0.6932028698921203, "val_acc": 52.0}
{"epoch": 9, "training_loss": 0.7056922769546509, "training_acc": 53.0, "val_loss": 0.7075983786582947, "val_acc": 48.0}
{"epoch": 10, "training_loss": 0.7299596381187439, "training_acc": 47.0, "val_loss": 0.7504099535942078, "val_acc": 52.0}
{"epoch": 11, "training_loss": 0.7359155368804932, "training_acc": 47.0, "val_loss": 0.7040639901161194, "val_acc": 52.0}
{"epoch": 12, "training_loss": 0.7243923759460449, "training_acc": 51.0, "val_loss": 0.6925429487228394, "val_acc": 52.0}
{"epoch": 13, "training_loss": 0.6935169982910157, "training_acc": 53.0, "val_loss": 0.6924871611595154, "val_acc": 52.0}
{"epoch": 14, "training_loss": 0.7069004344940185, "training_acc": 43.0, "val_loss": 0.6938572025299072, "val_acc": 52.0}
{"epoch": 15, "training_loss": 0.7061015701293946, "training_acc": 41.0, "val_loss": 0.6945995354652404, "val_acc": 48.0}
{"epoch": 16, "training_loss": 0.7057582998275757, "training_acc": 47.0, "val_loss": 0.7071855902671814, "val_acc": 52.0}
{"epoch": 17, "training_loss": 0.7308134412765503, "training_acc": 41.0, "val_loss": 0.6993863940238952, "val_acc": 52.0}
{"epoch": 18, "training_loss": 0.698242871761322, "training_acc": 51.0, "val_loss": 0.6923509454727172, "val_acc": 52.0}
{"epoch": 19, "training_loss": 0.7077479314804077, "training_acc": 55.0, "val_loss": 0.7777429342269897, "val_acc": 48.0}
{"epoch": 20, "training_loss": 0.7603075551986694, "training_acc": 47.0, "val_loss": 0.7846261596679688, "val_acc": 52.0}
{"epoch": 21, "training_loss": 0.7719692993164062, "training_acc": 55.0, "val_loss": 0.7625358128547668, "val_acc": 48.0}
{"epoch": 22, "training_loss": 0.7553027391433715, "training_acc": 49.0, "val_loss": 0.6926418757438659, "val_acc": 52.0}
{"epoch": 23, "training_loss": 0.6969055604934692, "training_acc": 51.0, "val_loss": 0.7288630533218384, "val_acc": 48.0}
{"epoch": 24, "training_loss": 0.7274661898612976, "training_acc": 45.0, "val_loss": 0.7245712876319885, "val_acc": 52.0}
{"epoch": 25, "training_loss": 0.7224534249305725, "training_acc": 53.0, "val_loss": 0.7073681688308716, "val_acc": 48.0}
{"epoch": 26, "training_loss": 0.7067662215232849, "training_acc": 41.0, "val_loss": 0.6973257660865784, "val_acc": 52.0}
{"epoch": 27, "training_loss": 0.7167066621780396, "training_acc": 43.0, "val_loss": 0.7038078141212464, "val_acc": 52.0}
{"epoch": 28, "training_loss": 0.6986017036437988, "training_acc": 53.0, "val_loss": 0.6926735305786133, "val_acc": 52.0}
{"epoch": 29, "training_loss": 0.7132619738578796, "training_acc": 47.0, "val_loss": 0.6925687766075135, "val_acc": 52.0}
{"epoch": 30, "training_loss": 0.7086272954940795, "training_acc": 53.0, "val_loss": 0.6955634927749634, "val_acc": 48.0}
{"epoch": 31, "training_loss": 0.7115079641342164, "training_acc": 49.0, "val_loss": 0.7152463436126709, "val_acc": 52.0}
{"epoch": 32, "training_loss": 0.7220951747894288, "training_acc": 47.0, "val_loss": 0.6930170559883118, "val_acc": 52.0}
{"epoch": 33, "training_loss": 0.7078798890113831, "training_acc": 53.0, "val_loss": 0.7396965289115905, "val_acc": 48.0}
{"epoch": 34, "training_loss": 0.7334499406814575, "training_acc": 49.0, "val_loss": 0.695806930065155, "val_acc": 48.0}
{"epoch": 35, "training_loss": 0.706732668876648, "training_acc": 55.0, "val_loss": 0.8820207524299621, "val_acc": 52.0}
{"epoch": 36, "training_loss": 0.8263227462768554, "training_acc": 49.0, "val_loss": 0.8366576051712036, "val_acc": 48.0}
{"epoch": 37, "training_loss": 0.7798072338104248, "training_acc": 47.0, "val_loss": 0.6944269943237305, "val_acc": 52.0}
