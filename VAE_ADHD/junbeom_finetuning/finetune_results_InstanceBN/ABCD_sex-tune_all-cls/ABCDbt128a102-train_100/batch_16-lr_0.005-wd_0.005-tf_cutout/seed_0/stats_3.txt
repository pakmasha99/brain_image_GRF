"main_modify.py --pretrained_path /scratch/connectome/dyhan316/VAE_ADHD/barlowtwins/pretrain_results/ABCDbt128a102.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option BT_org --learning_rate 5e-3 --batch_size 16 --weight_decay 5e-3 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 0.8508412122726441, "training_acc": 49.0, "val_loss": 0.8310733771324158, "val_acc": 52.0}
{"epoch": 1, "training_loss": 0.8501553225517273, "training_acc": 41.0, "val_loss": 0.7512433934211731, "val_acc": 52.0}
{"epoch": 2, "training_loss": 0.787067883014679, "training_acc": 43.0, "val_loss": 0.7338919758796691, "val_acc": 52.0}
{"epoch": 3, "training_loss": 0.7379155564308166, "training_acc": 53.0, "val_loss": 0.6944809055328369, "val_acc": 48.0}
{"epoch": 4, "training_loss": 0.7006823134422302, "training_acc": 49.0, "val_loss": 0.6931812405586243, "val_acc": 52.0}
{"epoch": 5, "training_loss": 0.7038725709915161, "training_acc": 49.0, "val_loss": 0.7045029950141907, "val_acc": 52.0}
{"epoch": 6, "training_loss": 0.7001100969314575, "training_acc": 51.0, "val_loss": 0.6943860578536988, "val_acc": 48.0}
{"epoch": 7, "training_loss": 0.7055920267105102, "training_acc": 41.0, "val_loss": 0.6951434898376465, "val_acc": 52.0}
{"epoch": 8, "training_loss": 0.6968778038024902, "training_acc": 47.0, "val_loss": 0.6973410749435425, "val_acc": 52.0}
{"epoch": 9, "training_loss": 0.7058740162849426, "training_acc": 53.0, "val_loss": 0.7059655594825744, "val_acc": 48.0}
{"epoch": 10, "training_loss": 0.7172640180587768, "training_acc": 51.0, "val_loss": 0.8332886266708374, "val_acc": 52.0}
{"epoch": 11, "training_loss": 0.8310489726066589, "training_acc": 53.0, "val_loss": 0.8051700806617736, "val_acc": 48.0}
{"epoch": 12, "training_loss": 0.7455822038650513, "training_acc": 47.0, "val_loss": 0.7496763348579407, "val_acc": 52.0}
{"epoch": 13, "training_loss": 0.6975070095062256, "training_acc": 55.0, "val_loss": 0.7529028964042663, "val_acc": 48.0}
{"epoch": 14, "training_loss": 0.7221662402153015, "training_acc": 47.0, "val_loss": 0.7122631192207336, "val_acc": 52.0}
{"epoch": 15, "training_loss": 0.7131040668487549, "training_acc": 51.0, "val_loss": 0.713198549747467, "val_acc": 48.0}
{"epoch": 16, "training_loss": 0.7621762180328369, "training_acc": 41.0, "val_loss": 0.7163090062141418, "val_acc": 48.0}
{"epoch": 17, "training_loss": 0.7277952671051026, "training_acc": 47.0, "val_loss": 0.7184235882759095, "val_acc": 52.0}
{"epoch": 18, "training_loss": 0.7018451690673828, "training_acc": 53.0, "val_loss": 0.7247316741943359, "val_acc": 48.0}
{"epoch": 19, "training_loss": 0.7298742723464966, "training_acc": 49.0, "val_loss": 0.6941831564903259, "val_acc": 52.0}
{"epoch": 20, "training_loss": 0.6946132469177246, "training_acc": 55.0, "val_loss": 0.6963036298751831, "val_acc": 48.0}
{"epoch": 21, "training_loss": 0.6991138601303101, "training_acc": 51.0, "val_loss": 0.7633536648750305, "val_acc": 52.0}
{"epoch": 22, "training_loss": 0.742686333656311, "training_acc": 49.0, "val_loss": 0.6944924473762513, "val_acc": 52.0}
{"epoch": 23, "training_loss": 0.7226364850997925, "training_acc": 53.0, "val_loss": 0.7154840040206909, "val_acc": 48.0}
