"main_modify.py --pretrained_path /scratch/connectome/dyhan316/VAE_ADHD/barlowtwins/pretrain_results/ABCDbt128a102.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option BT_org --learning_rate 1e-3 --batch_size 16 --weight_decay 1e-5 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 0.7240602159500122, "training_acc": 51.0, "val_loss": 0.6947136616706848, "val_acc": 52.0}
{"epoch": 1, "training_loss": 0.7101025867462158, "training_acc": 45.0, "val_loss": 0.6969624447822571, "val_acc": 48.0}
{"epoch": 2, "training_loss": 0.7039911890029907, "training_acc": 39.0, "val_loss": 0.6926415634155273, "val_acc": 52.0}
{"epoch": 3, "training_loss": 0.7102847051620483, "training_acc": 53.0, "val_loss": 0.6930258274078369, "val_acc": 52.0}
{"epoch": 4, "training_loss": 0.7020362377166748, "training_acc": 45.0, "val_loss": 0.6925131678581238, "val_acc": 52.0}
{"epoch": 5, "training_loss": 0.7121865820884704, "training_acc": 53.0, "val_loss": 0.6992431616783142, "val_acc": 52.0}
{"epoch": 6, "training_loss": 0.693935148715973, "training_acc": 53.0, "val_loss": 0.6941548991203308, "val_acc": 48.0}
{"epoch": 7, "training_loss": 0.7148726511001587, "training_acc": 47.0, "val_loss": 0.6943236470222474, "val_acc": 48.0}
{"epoch": 8, "training_loss": 0.6929600286483765, "training_acc": 51.0, "val_loss": 0.7059941411018371, "val_acc": 52.0}
{"epoch": 9, "training_loss": 0.7041462564468384, "training_acc": 53.0, "val_loss": 0.6925341248512268, "val_acc": 52.0}
{"epoch": 10, "training_loss": 0.729085648059845, "training_acc": 47.0, "val_loss": 0.7037112593650818, "val_acc": 48.0}
{"epoch": 11, "training_loss": 0.7015225410461425, "training_acc": 55.0, "val_loss": 0.702766842842102, "val_acc": 52.0}
{"epoch": 12, "training_loss": 0.7070651006698608, "training_acc": 45.0, "val_loss": 0.692528338432312, "val_acc": 52.0}
{"epoch": 13, "training_loss": 0.6905645155906677, "training_acc": 53.0, "val_loss": 0.6936341214179993, "val_acc": 52.0}
{"epoch": 14, "training_loss": 0.6942871856689453, "training_acc": 53.0, "val_loss": 0.6923451828956604, "val_acc": 52.0}
{"epoch": 15, "training_loss": 0.6992322874069213, "training_acc": 45.0, "val_loss": 0.6936884069442749, "val_acc": 48.0}
{"epoch": 16, "training_loss": 0.6941413450241088, "training_acc": 49.0, "val_loss": 0.6959004545211792, "val_acc": 52.0}
{"epoch": 17, "training_loss": 0.6976231336593628, "training_acc": 53.0, "val_loss": 0.6949039149284363, "val_acc": 52.0}
{"epoch": 18, "training_loss": 0.6995565629005432, "training_acc": 49.0, "val_loss": 0.6950495028495789, "val_acc": 48.0}
{"epoch": 19, "training_loss": 0.690266671180725, "training_acc": 53.0, "val_loss": 0.6956438159942627, "val_acc": 52.0}
{"epoch": 20, "training_loss": 0.7034575939178467, "training_acc": 53.0, "val_loss": 0.7136866688728333, "val_acc": 52.0}
{"epoch": 21, "training_loss": 0.7023644351959228, "training_acc": 53.0, "val_loss": 0.6932905316352844, "val_acc": 52.0}
{"epoch": 22, "training_loss": 0.6966671895980835, "training_acc": 53.0, "val_loss": 0.6950874328613281, "val_acc": 48.0}
{"epoch": 23, "training_loss": 0.6962092995643616, "training_acc": 47.0, "val_loss": 0.69248384475708, "val_acc": 52.0}
{"epoch": 24, "training_loss": 0.692674708366394, "training_acc": 53.0, "val_loss": 0.6936523079872131, "val_acc": 52.0}
{"epoch": 25, "training_loss": 0.696188039779663, "training_acc": 53.0, "val_loss": 0.6941794514656067, "val_acc": 52.0}
{"epoch": 26, "training_loss": 0.6917772173881531, "training_acc": 53.0, "val_loss": 0.6925008368492126, "val_acc": 52.0}
{"epoch": 27, "training_loss": 0.6970923590660095, "training_acc": 53.0, "val_loss": 0.6923885798454285, "val_acc": 52.0}
{"epoch": 28, "training_loss": 0.6966669845581055, "training_acc": 47.0, "val_loss": 0.6951334953308106, "val_acc": 48.0}
{"epoch": 29, "training_loss": 0.7005697441101074, "training_acc": 43.0, "val_loss": 0.6962274956703186, "val_acc": 52.0}
{"epoch": 30, "training_loss": 0.6936723470687867, "training_acc": 53.0, "val_loss": 0.6928396725654602, "val_acc": 52.0}
{"epoch": 31, "training_loss": 0.688393440246582, "training_acc": 55.0, "val_loss": 0.6965113377571106, "val_acc": 48.0}
{"epoch": 32, "training_loss": 0.7004697513580322, "training_acc": 47.0, "val_loss": 0.6948253417015076, "val_acc": 48.0}
{"epoch": 33, "training_loss": 0.6932508826255799, "training_acc": 53.0, "val_loss": 0.7051657819747925, "val_acc": 52.0}
