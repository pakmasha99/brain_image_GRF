"main_modify.py --pretrained_path /scratch/connectome/dyhan316/VAE_ADHD/barlowtwins/pretrain_results/ABCDbt128a102.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 1 --task ABCD_sex --input_option BT_org --learning_rate 1e-3 --batch_size 16 --weight_decay 1e-5 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 0.7346721839904785, "training_acc": 52.0, "val_loss": 0.6929855418205261, "val_acc": 52.0}
{"epoch": 1, "training_loss": 0.7207126998901368, "training_acc": 47.0, "val_loss": 0.6955055689811707, "val_acc": 48.0}
{"epoch": 2, "training_loss": 0.713956151008606, "training_acc": 49.0, "val_loss": 0.6933632326126099, "val_acc": 52.0}
{"epoch": 3, "training_loss": 0.7105152153968811, "training_acc": 45.0, "val_loss": 0.6926425123214721, "val_acc": 52.0}
{"epoch": 4, "training_loss": 0.692615852355957, "training_acc": 53.0, "val_loss": 0.6955854511260986, "val_acc": 52.0}
{"epoch": 5, "training_loss": 0.6976550817489624, "training_acc": 53.0, "val_loss": 0.6927620816230774, "val_acc": 52.0}
{"epoch": 6, "training_loss": 0.6964885330200196, "training_acc": 43.0, "val_loss": 0.6924993085861206, "val_acc": 52.0}
{"epoch": 7, "training_loss": 0.6949253153800964, "training_acc": 53.0, "val_loss": 0.6931127429008483, "val_acc": 52.0}
{"epoch": 8, "training_loss": 0.6920190715789795, "training_acc": 53.0, "val_loss": 0.6923732924461364, "val_acc": 52.0}
{"epoch": 9, "training_loss": 0.693822500705719, "training_acc": 53.0, "val_loss": 0.6924947071075439, "val_acc": 52.0}
{"epoch": 10, "training_loss": 0.6930027031898498, "training_acc": 53.0, "val_loss": 0.6938892555236816, "val_acc": 52.0}
{"epoch": 11, "training_loss": 0.69652672290802, "training_acc": 47.0, "val_loss": 0.6945664620399475, "val_acc": 48.0}
{"epoch": 12, "training_loss": 0.693302059173584, "training_acc": 51.0, "val_loss": 0.6946054434776306, "val_acc": 52.0}
{"epoch": 13, "training_loss": 0.7012209892272949, "training_acc": 53.0, "val_loss": 0.7064609599113464, "val_acc": 52.0}
{"epoch": 14, "training_loss": 0.7061643791198731, "training_acc": 47.0, "val_loss": 0.6957949328422547, "val_acc": 48.0}
{"epoch": 15, "training_loss": 0.701240873336792, "training_acc": 43.0, "val_loss": 0.6928823018074035, "val_acc": 52.0}
{"epoch": 16, "training_loss": 0.6920381712913514, "training_acc": 53.0, "val_loss": 0.6923955225944519, "val_acc": 52.0}
{"epoch": 17, "training_loss": 0.6946512508392334, "training_acc": 45.0, "val_loss": 0.6923776650428772, "val_acc": 52.0}
{"epoch": 18, "training_loss": 0.6955900621414185, "training_acc": 53.0, "val_loss": 0.694012258052826, "val_acc": 52.0}
{"epoch": 19, "training_loss": 0.6946313810348511, "training_acc": 53.0, "val_loss": 0.6946288251876831, "val_acc": 52.0}
{"epoch": 20, "training_loss": 0.7063199830055237, "training_acc": 53.0, "val_loss": 0.6942141652107239, "val_acc": 52.0}
{"epoch": 21, "training_loss": 0.7173965120315552, "training_acc": 43.0, "val_loss": 0.6956863451004028, "val_acc": 48.0}
{"epoch": 22, "training_loss": 0.6909229707717895, "training_acc": 51.0, "val_loss": 0.7091483759880066, "val_acc": 52.0}
{"epoch": 23, "training_loss": 0.7140745878219604, "training_acc": 53.0, "val_loss": 0.7034540939331054, "val_acc": 52.0}
{"epoch": 24, "training_loss": 0.6991956806182862, "training_acc": 53.0, "val_loss": 0.6949906277656556, "val_acc": 52.0}
{"epoch": 25, "training_loss": 0.6908060836791993, "training_acc": 53.0, "val_loss": 0.6972758603096009, "val_acc": 48.0}
{"epoch": 26, "training_loss": 0.7047072696685791, "training_acc": 47.0, "val_loss": 0.6948557257652282, "val_acc": 48.0}
{"epoch": 27, "training_loss": 0.7068922710418701, "training_acc": 43.0, "val_loss": 0.6948556113243103, "val_acc": 52.0}
