"main_modify.py --pretrained_path /scratch/connectome/dyhan316/VAE_ADHD/barlowtwins/pretrain_results/ABCDbt128a102.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 1 --task ABCD_sex --input_option BT_org --learning_rate 1e-3 --batch_size 16 --weight_decay 1e-5 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 0.7212174797058105, "training_acc": 41.0, "val_loss": 0.6949113488197327, "val_acc": 52.0}
{"epoch": 1, "training_loss": 0.6963063621520996, "training_acc": 53.0, "val_loss": 0.7096678495407105, "val_acc": 52.0}
{"epoch": 2, "training_loss": 0.7101079797744752, "training_acc": 53.0, "val_loss": 0.6929232120513916, "val_acc": 52.0}
{"epoch": 3, "training_loss": 0.71232027053833, "training_acc": 43.0, "val_loss": 0.7011047673225402, "val_acc": 48.0}
{"epoch": 4, "training_loss": 0.6984197616577148, "training_acc": 49.0, "val_loss": 0.6927759289741516, "val_acc": 52.0}
{"epoch": 5, "training_loss": 0.6970638942718506, "training_acc": 49.0, "val_loss": 0.6961825132369995, "val_acc": 52.0}
{"epoch": 6, "training_loss": 0.706967089176178, "training_acc": 53.0, "val_loss": 0.6946870064735413, "val_acc": 52.0}
{"epoch": 7, "training_loss": 0.6917773103713989, "training_acc": 53.0, "val_loss": 0.6954367136955262, "val_acc": 48.0}
{"epoch": 8, "training_loss": 0.700350980758667, "training_acc": 47.0, "val_loss": 0.6971060490608215, "val_acc": 48.0}
{"epoch": 9, "training_loss": 0.69954749584198, "training_acc": 47.0, "val_loss": 0.6930669355392456, "val_acc": 52.0}
{"epoch": 10, "training_loss": 0.6963927125930787, "training_acc": 53.0, "val_loss": 0.6960810828208923, "val_acc": 52.0}
{"epoch": 11, "training_loss": 0.7029101037979126, "training_acc": 53.0, "val_loss": 0.7011499786376953, "val_acc": 52.0}
{"epoch": 12, "training_loss": 0.7064423942565918, "training_acc": 43.0, "val_loss": 0.6955025291442871, "val_acc": 48.0}
{"epoch": 13, "training_loss": 0.7062045812606812, "training_acc": 47.0, "val_loss": 0.6938123726844787, "val_acc": 52.0}
{"epoch": 14, "training_loss": 0.6999197959899902, "training_acc": 47.0, "val_loss": 0.6972176241874695, "val_acc": 48.0}
{"epoch": 15, "training_loss": 0.6977012300491333, "training_acc": 47.0, "val_loss": 0.6950750708580017, "val_acc": 52.0}
{"epoch": 16, "training_loss": 0.7237683987617493, "training_acc": 53.0, "val_loss": 0.6977267813682556, "val_acc": 52.0}
{"epoch": 17, "training_loss": 0.6917955327033997, "training_acc": 51.0, "val_loss": 0.6984774112701416, "val_acc": 48.0}
{"epoch": 18, "training_loss": 0.7072550868988037, "training_acc": 47.0, "val_loss": 0.6923585367202759, "val_acc": 52.0}
{"epoch": 19, "training_loss": 0.7067591762542724, "training_acc": 53.0, "val_loss": 0.7136429905891418, "val_acc": 52.0}
{"epoch": 20, "training_loss": 0.6982366728782654, "training_acc": 53.0, "val_loss": 0.6925844144821167, "val_acc": 52.0}
{"epoch": 21, "training_loss": 0.6925027561187744, "training_acc": 53.0, "val_loss": 0.6925371241569519, "val_acc": 52.0}
{"epoch": 22, "training_loss": 0.7050921583175659, "training_acc": 53.0, "val_loss": 0.6938911533355713, "val_acc": 52.0}
{"epoch": 23, "training_loss": 0.6941545915603637, "training_acc": 53.0, "val_loss": 0.692858030796051, "val_acc": 52.0}
{"epoch": 24, "training_loss": 0.7046561479568482, "training_acc": 39.0, "val_loss": 0.6951706528663635, "val_acc": 48.0}
{"epoch": 25, "training_loss": 0.7019927334785462, "training_acc": 47.0, "val_loss": 0.6923530650138855, "val_acc": 52.0}
{"epoch": 26, "training_loss": 0.7210906147956848, "training_acc": 53.0, "val_loss": 0.7224905776977539, "val_acc": 52.0}
{"epoch": 27, "training_loss": 0.700123405456543, "training_acc": 53.0, "val_loss": 0.6924778819084167, "val_acc": 52.0}
{"epoch": 28, "training_loss": 0.7014866042137146, "training_acc": 49.0, "val_loss": 0.6973224639892578, "val_acc": 48.0}
{"epoch": 29, "training_loss": 0.6954318189620972, "training_acc": 47.0, "val_loss": 0.6927892756462097, "val_acc": 52.0}
{"epoch": 30, "training_loss": 0.7091420793533325, "training_acc": 53.0, "val_loss": 0.7155493807792663, "val_acc": 52.0}
{"epoch": 31, "training_loss": 0.7040934324264526, "training_acc": 53.0, "val_loss": 0.6923274731636048, "val_acc": 52.0}
{"epoch": 32, "training_loss": 0.6994090604782105, "training_acc": 43.0, "val_loss": 0.6939000678062439, "val_acc": 48.0}
{"epoch": 33, "training_loss": 0.6896911859512329, "training_acc": 57.0, "val_loss": 0.69882239818573, "val_acc": 52.0}
{"epoch": 34, "training_loss": 0.7014046669006347, "training_acc": 53.0, "val_loss": 0.6982805371284485, "val_acc": 52.0}
{"epoch": 35, "training_loss": 0.6962882685661316, "training_acc": 53.0, "val_loss": 0.6924672937393188, "val_acc": 52.0}
{"epoch": 36, "training_loss": 0.6956845259666443, "training_acc": 53.0, "val_loss": 0.6928624415397644, "val_acc": 52.0}
{"epoch": 37, "training_loss": 0.6935817623138427, "training_acc": 53.0, "val_loss": 0.6927418494224549, "val_acc": 52.0}
{"epoch": 38, "training_loss": 0.6915935373306275, "training_acc": 53.0, "val_loss": 0.6976571679115295, "val_acc": 52.0}
{"epoch": 39, "training_loss": 0.6944010400772095, "training_acc": 53.0, "val_loss": 0.6926067566871643, "val_acc": 52.0}
{"epoch": 40, "training_loss": 0.6927906322479248, "training_acc": 53.0, "val_loss": 0.6924724221229553, "val_acc": 52.0}
{"epoch": 41, "training_loss": 0.6913591504096985, "training_acc": 53.0, "val_loss": 0.6946226119995117, "val_acc": 52.0}
{"epoch": 42, "training_loss": 0.7001040863990784, "training_acc": 53.0, "val_loss": 0.7023096084594727, "val_acc": 52.0}
{"epoch": 43, "training_loss": 0.6966281032562256, "training_acc": 53.0, "val_loss": 0.6926143002510071, "val_acc": 52.0}
{"epoch": 44, "training_loss": 0.6933769822120667, "training_acc": 53.0, "val_loss": 0.6923525786399841, "val_acc": 52.0}
{"epoch": 45, "training_loss": 0.6976900291442871, "training_acc": 53.0, "val_loss": 0.693458023071289, "val_acc": 52.0}
{"epoch": 46, "training_loss": 0.6992542195320129, "training_acc": 47.0, "val_loss": 0.6948756742477417, "val_acc": 48.0}
{"epoch": 47, "training_loss": 0.6922571992874146, "training_acc": 53.0, "val_loss": 0.6932588243484497, "val_acc": 52.0}
{"epoch": 48, "training_loss": 0.6919203138351441, "training_acc": 53.0, "val_loss": 0.6923639798164367, "val_acc": 52.0}
{"epoch": 49, "training_loss": 0.6960705471038818, "training_acc": 49.0, "val_loss": 0.693566906452179, "val_acc": 48.0}
{"epoch": 50, "training_loss": 0.6908368825912475, "training_acc": 51.0, "val_loss": 0.6958726811408996, "val_acc": 52.0}
