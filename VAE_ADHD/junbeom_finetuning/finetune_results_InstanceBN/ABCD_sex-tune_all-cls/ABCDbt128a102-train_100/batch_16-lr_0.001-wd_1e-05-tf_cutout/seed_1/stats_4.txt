"main_modify.py --pretrained_path /scratch/connectome/dyhan316/VAE_ADHD/barlowtwins/pretrain_results/ABCDbt128a102.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 1 --task ABCD_sex --input_option BT_org --learning_rate 1e-3 --batch_size 16 --weight_decay 1e-5 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 0.7005845141410828, "training_acc": 47.0, "val_loss": 0.6871670579910278, "val_acc": 56.0}
{"epoch": 1, "training_loss": 0.70644606590271, "training_acc": 42.0, "val_loss": 0.6865685820579529, "val_acc": 56.0}
{"epoch": 2, "training_loss": 0.6981399154663086, "training_acc": 52.0, "val_loss": 0.6894158864021301, "val_acc": 56.0}
{"epoch": 3, "training_loss": 0.6946593570709229, "training_acc": 50.0, "val_loss": 0.7026197910308838, "val_acc": 44.0}
{"epoch": 4, "training_loss": 0.706076078414917, "training_acc": 44.0, "val_loss": 0.6894205379486084, "val_acc": 56.0}
{"epoch": 5, "training_loss": 0.6998292112350464, "training_acc": 54.0, "val_loss": 0.7070988416671753, "val_acc": 44.0}
{"epoch": 6, "training_loss": 0.6998893737792968, "training_acc": 50.0, "val_loss": 0.68723149061203, "val_acc": 56.0}
{"epoch": 7, "training_loss": 0.7027157211303711, "training_acc": 48.0, "val_loss": 0.6913747882843018, "val_acc": 56.0}
{"epoch": 8, "training_loss": 0.6949150013923645, "training_acc": 52.0, "val_loss": 0.6859611105918885, "val_acc": 56.0}
{"epoch": 9, "training_loss": 0.6957393860816956, "training_acc": 44.0, "val_loss": 0.7030337142944336, "val_acc": 44.0}
{"epoch": 10, "training_loss": 0.7056488490104675, "training_acc": 48.0, "val_loss": 0.7140734887123108, "val_acc": 44.0}
{"epoch": 11, "training_loss": 0.702402048110962, "training_acc": 46.0, "val_loss": 0.6917175364494323, "val_acc": 56.0}
{"epoch": 12, "training_loss": 0.6947980189323425, "training_acc": 52.0, "val_loss": 0.6877466440200806, "val_acc": 56.0}
{"epoch": 13, "training_loss": 0.6943501520156861, "training_acc": 52.0, "val_loss": 0.6905490469932556, "val_acc": 56.0}
{"epoch": 14, "training_loss": 0.6971367216110229, "training_acc": 46.0, "val_loss": 0.6880665683746338, "val_acc": 56.0}
{"epoch": 15, "training_loss": 0.6934165716171264, "training_acc": 52.0, "val_loss": 0.6859632468223572, "val_acc": 56.0}
{"epoch": 16, "training_loss": 0.6972353410720825, "training_acc": 52.0, "val_loss": 0.687814724445343, "val_acc": 56.0}
{"epoch": 17, "training_loss": 0.7011200952529907, "training_acc": 42.0, "val_loss": 0.6943070244789123, "val_acc": 44.0}
{"epoch": 18, "training_loss": 0.6935543990135193, "training_acc": 48.0, "val_loss": 0.6900119662284852, "val_acc": 56.0}
{"epoch": 19, "training_loss": 0.6956687784194946, "training_acc": 52.0, "val_loss": 0.6905985641479492, "val_acc": 56.0}
{"epoch": 20, "training_loss": 0.6975653696060181, "training_acc": 48.0, "val_loss": 0.6981177496910095, "val_acc": 44.0}
{"epoch": 21, "training_loss": 0.6973995566368103, "training_acc": 46.0, "val_loss": 0.6860077333450317, "val_acc": 56.0}
{"epoch": 22, "training_loss": 0.7007867550849914, "training_acc": 52.0, "val_loss": 0.6911922883987427, "val_acc": 56.0}
{"epoch": 23, "training_loss": 0.6988990831375123, "training_acc": 56.0, "val_loss": 0.7172003841400146, "val_acc": 44.0}
{"epoch": 24, "training_loss": 0.7047497415542603, "training_acc": 44.0, "val_loss": 0.6864215278625488, "val_acc": 56.0}
{"epoch": 25, "training_loss": 0.6964513063430786, "training_acc": 52.0, "val_loss": 0.6879470133781433, "val_acc": 56.0}
{"epoch": 26, "training_loss": 0.6935708022117615, "training_acc": 52.0, "val_loss": 0.6889402914047241, "val_acc": 56.0}
{"epoch": 27, "training_loss": 0.702732150554657, "training_acc": 52.0, "val_loss": 0.6861647129058838, "val_acc": 56.0}
