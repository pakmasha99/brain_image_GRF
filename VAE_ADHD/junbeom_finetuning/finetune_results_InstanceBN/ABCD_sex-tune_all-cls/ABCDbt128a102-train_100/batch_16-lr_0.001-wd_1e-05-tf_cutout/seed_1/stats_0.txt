"main_modify.py --pretrained_path /scratch/connectome/dyhan316/VAE_ADHD/barlowtwins/pretrain_results/ABCDbt128a102.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 1 --task ABCD_sex --input_option BT_org --learning_rate 1e-3 --batch_size 16 --weight_decay 1e-5 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 0.7108711242675781, "training_acc": 49.0, "val_loss": 0.7052152156829834, "val_acc": 52.0}
{"epoch": 1, "training_loss": 0.7148965167999267, "training_acc": 53.0, "val_loss": 0.7146041560173034, "val_acc": 52.0}
{"epoch": 2, "training_loss": 0.7066707491874695, "training_acc": 53.0, "val_loss": 0.6943012261390686, "val_acc": 52.0}
{"epoch": 3, "training_loss": 0.7070111632347107, "training_acc": 41.0, "val_loss": 0.6929810261726379, "val_acc": 52.0}
{"epoch": 4, "training_loss": 0.6977837324142456, "training_acc": 45.0, "val_loss": 0.6958686065673828, "val_acc": 52.0}
{"epoch": 5, "training_loss": 0.7106532478332519, "training_acc": 53.0, "val_loss": 0.7013018560409546, "val_acc": 52.0}
{"epoch": 6, "training_loss": 0.6986787819862366, "training_acc": 53.0, "val_loss": 0.69473801612854, "val_acc": 48.0}
{"epoch": 7, "training_loss": 0.7032954454421997, "training_acc": 47.0, "val_loss": 0.6925349068641663, "val_acc": 52.0}
{"epoch": 8, "training_loss": 0.6926640844345093, "training_acc": 53.0, "val_loss": 0.6958404493331909, "val_acc": 52.0}
{"epoch": 9, "training_loss": 0.6978434038162231, "training_acc": 53.0, "val_loss": 0.6924291300773621, "val_acc": 52.0}
{"epoch": 10, "training_loss": 0.7073363471031189, "training_acc": 43.0, "val_loss": 0.6923695945739746, "val_acc": 52.0}
{"epoch": 11, "training_loss": 0.693509418964386, "training_acc": 53.0, "val_loss": 0.696822612285614, "val_acc": 52.0}
{"epoch": 12, "training_loss": 0.6974649143218994, "training_acc": 53.0, "val_loss": 0.6945265626907349, "val_acc": 52.0}
{"epoch": 13, "training_loss": 0.6938441967964173, "training_acc": 53.0, "val_loss": 0.6940719032287598, "val_acc": 48.0}
{"epoch": 14, "training_loss": 0.7117926621437073, "training_acc": 47.0, "val_loss": 0.6947126936912537, "val_acc": 48.0}
{"epoch": 15, "training_loss": 0.7228629350662231, "training_acc": 45.0, "val_loss": 0.69603919506073, "val_acc": 52.0}
{"epoch": 16, "training_loss": 0.6930210685729981, "training_acc": 51.0, "val_loss": 0.6930260920524597, "val_acc": 52.0}
{"epoch": 17, "training_loss": 0.6929656362533569, "training_acc": 53.0, "val_loss": 0.693468279838562, "val_acc": 52.0}
{"epoch": 18, "training_loss": 0.6946001434326172, "training_acc": 49.0, "val_loss": 0.6932253456115722, "val_acc": 48.0}
{"epoch": 19, "training_loss": 0.6895584774017334, "training_acc": 55.0, "val_loss": 0.6965138959884644, "val_acc": 52.0}
{"epoch": 20, "training_loss": 0.7032411813735961, "training_acc": 53.0, "val_loss": 0.6941669845581054, "val_acc": 52.0}
{"epoch": 21, "training_loss": 0.6956625175476074, "training_acc": 53.0, "val_loss": 0.6947629117965698, "val_acc": 52.0}
{"epoch": 22, "training_loss": 0.6997684621810913, "training_acc": 53.0, "val_loss": 0.6957987213134765, "val_acc": 52.0}
{"epoch": 23, "training_loss": 0.6939775562286377, "training_acc": 53.0, "val_loss": 0.6987911343574524, "val_acc": 48.0}
{"epoch": 24, "training_loss": 0.7070551490783692, "training_acc": 47.0, "val_loss": 0.6933702039718628, "val_acc": 52.0}
{"epoch": 25, "training_loss": 0.6969259548187255, "training_acc": 53.0, "val_loss": 0.7160261702537537, "val_acc": 52.0}
{"epoch": 26, "training_loss": 0.7059453988075256, "training_acc": 53.0, "val_loss": 0.6923570299148559, "val_acc": 52.0}
{"epoch": 27, "training_loss": 0.7012440276145935, "training_acc": 53.0, "val_loss": 0.6933373928070068, "val_acc": 52.0}
{"epoch": 28, "training_loss": 0.7124346089363098, "training_acc": 43.0, "val_loss": 0.700512592792511, "val_acc": 48.0}
{"epoch": 29, "training_loss": 0.7090572547912598, "training_acc": 45.0, "val_loss": 0.6990046048164368, "val_acc": 52.0}
{"epoch": 30, "training_loss": 0.6953243374824524, "training_acc": 53.0, "val_loss": 0.6928713703155518, "val_acc": 52.0}
{"epoch": 31, "training_loss": 0.6920996499061585, "training_acc": 53.0, "val_loss": 0.6933278250694275, "val_acc": 48.0}
{"epoch": 32, "training_loss": 0.6964180374145508, "training_acc": 47.0, "val_loss": 0.6923547840118408, "val_acc": 52.0}
{"epoch": 33, "training_loss": 0.697796778678894, "training_acc": 53.0, "val_loss": 0.6998194885253907, "val_acc": 52.0}
{"epoch": 34, "training_loss": 0.7058648157119751, "training_acc": 53.0, "val_loss": 0.7022548985481262, "val_acc": 52.0}
{"epoch": 35, "training_loss": 0.6974610257148742, "training_acc": 55.0, "val_loss": 0.6957867741584778, "val_acc": 48.0}
{"epoch": 36, "training_loss": 0.7028468132019043, "training_acc": 47.0, "val_loss": 0.6973769116401672, "val_acc": 48.0}
{"epoch": 37, "training_loss": 0.7010027647018433, "training_acc": 47.0, "val_loss": 0.6939536833763122, "val_acc": 48.0}
{"epoch": 38, "training_loss": 0.6935636949539185, "training_acc": 53.0, "val_loss": 0.6954090428352356, "val_acc": 52.0}
{"epoch": 39, "training_loss": 0.6939026308059693, "training_acc": 53.0, "val_loss": 0.6939347004890442, "val_acc": 52.0}
{"epoch": 40, "training_loss": 0.6928476548194885, "training_acc": 53.0, "val_loss": 0.6931740283966065, "val_acc": 48.0}
{"epoch": 41, "training_loss": 0.6947759294509888, "training_acc": 47.0, "val_loss": 0.6931705570220947, "val_acc": 48.0}
{"epoch": 42, "training_loss": 0.6917098188400268, "training_acc": 53.0, "val_loss": 0.6944929099082947, "val_acc": 52.0}
{"epoch": 43, "training_loss": 0.6960192561149597, "training_acc": 53.0, "val_loss": 0.6925974035263062, "val_acc": 52.0}
{"epoch": 44, "training_loss": 0.69243497133255, "training_acc": 53.0, "val_loss": 0.6932345676422119, "val_acc": 52.0}
{"epoch": 45, "training_loss": 0.6953905487060547, "training_acc": 53.0, "val_loss": 0.6960818457603455, "val_acc": 52.0}
{"epoch": 46, "training_loss": 0.7013831663131714, "training_acc": 47.0, "val_loss": 0.6988147687911987, "val_acc": 48.0}
{"epoch": 47, "training_loss": 0.6948535323143006, "training_acc": 49.0, "val_loss": 0.6932483696937561, "val_acc": 52.0}
{"epoch": 48, "training_loss": 0.7013476324081421, "training_acc": 53.0, "val_loss": 0.6991809034347534, "val_acc": 52.0}
{"epoch": 49, "training_loss": 0.6950595045089721, "training_acc": 53.0, "val_loss": 0.6929536128044128, "val_acc": 52.0}
{"epoch": 50, "training_loss": 0.6981967234611511, "training_acc": 45.0, "val_loss": 0.6931709837913513, "val_acc": 48.0}
{"epoch": 51, "training_loss": 0.6921213912963867, "training_acc": 53.0, "val_loss": 0.6944611668586731, "val_acc": 52.0}
