"main_modify.py --pretrained_path /scratch/connectome/dyhan316/VAE_ADHD/barlowtwins/pretrain_results/ABCDbt128a102.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option BT_org --learning_rate 1e0 --batch_size 16 --weight_decay 1e-2 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 113.66811042785645, "training_acc": 46.0, "val_loss": 8.943357620239258, "val_acc": 56.0}
{"epoch": 1, "training_loss": 12.779020721912383, "training_acc": 56.0, "val_loss": 3.9922523498535156, "val_acc": 56.0}
{"epoch": 2, "training_loss": 19.638810691833495, "training_acc": 48.0, "val_loss": 50.02362030029297, "val_acc": 44.0}
{"epoch": 3, "training_loss": 32.72176847457886, "training_acc": 52.0, "val_loss": 40.4320654296875, "val_acc": 44.0}
{"epoch": 4, "training_loss": 36.88051571846008, "training_acc": 46.0, "val_loss": 33.16055709838867, "val_acc": 44.0}
{"epoch": 5, "training_loss": 24.940814437866212, "training_acc": 50.0, "val_loss": 30.748224639892577, "val_acc": 44.0}
{"epoch": 6, "training_loss": 18.93292053222656, "training_acc": 54.0, "val_loss": 68.3542578125, "val_acc": 44.0}
{"epoch": 7, "training_loss": 51.080774536132814, "training_acc": 52.0, "val_loss": 66.92445404052734, "val_acc": 56.0}
{"epoch": 8, "training_loss": 40.79675033569336, "training_acc": 58.0, "val_loss": 75.90506317138671, "val_acc": 44.0}
{"epoch": 9, "training_loss": 50.55904220581055, "training_acc": 52.0, "val_loss": 11.473749885559082, "val_acc": 56.0}
{"epoch": 10, "training_loss": 57.33304639816284, "training_acc": 48.0, "val_loss": 41.32036544799805, "val_acc": 56.0}
{"epoch": 11, "training_loss": 38.98952072143555, "training_acc": 52.0, "val_loss": 18.75374084472656, "val_acc": 44.0}
{"epoch": 12, "training_loss": 64.24739818572998, "training_acc": 44.0, "val_loss": 53.363516082763674, "val_acc": 44.0}
{"epoch": 13, "training_loss": 71.8253279876709, "training_acc": 50.0, "val_loss": 74.92136749267578, "val_acc": 56.0}
{"epoch": 14, "training_loss": NaN, "training_acc": 52.0, "val_loss": NaN, "val_acc": 56.0}
{"epoch": 15, "training_loss": NaN, "training_acc": 52.0, "val_loss": NaN, "val_acc": 56.0}
{"epoch": 16, "training_loss": NaN, "training_acc": 52.0, "val_loss": NaN, "val_acc": 56.0}
{"epoch": 17, "training_loss": NaN, "training_acc": 52.0, "val_loss": NaN, "val_acc": 56.0}
{"epoch": 18, "training_loss": NaN, "training_acc": 52.0, "val_loss": NaN, "val_acc": 56.0}
{"epoch": 19, "training_loss": NaN, "training_acc": 52.0, "val_loss": NaN, "val_acc": 56.0}
{"epoch": 20, "training_loss": NaN, "training_acc": 52.0, "val_loss": NaN, "val_acc": 56.0}
{"epoch": 21, "training_loss": NaN, "training_acc": 52.0, "val_loss": NaN, "val_acc": 56.0}
{"epoch": 22, "training_loss": NaN, "training_acc": 52.0, "val_loss": NaN, "val_acc": 56.0}
{"epoch": 23, "training_loss": NaN, "training_acc": 52.0, "val_loss": NaN, "val_acc": 56.0}
{"epoch": 24, "training_loss": NaN, "training_acc": 52.0, "val_loss": NaN, "val_acc": 56.0}
{"epoch": 25, "training_loss": NaN, "training_acc": 52.0, "val_loss": NaN, "val_acc": 56.0}
{"epoch": 26, "training_loss": NaN, "training_acc": 52.0, "val_loss": NaN, "val_acc": 56.0}
{"epoch": 27, "training_loss": NaN, "training_acc": 52.0, "val_loss": NaN, "val_acc": 56.0}
{"epoch": 28, "training_loss": NaN, "training_acc": 52.0, "val_loss": NaN, "val_acc": 56.0}
{"epoch": 29, "training_loss": NaN, "training_acc": 52.0, "val_loss": NaN, "val_acc": 56.0}
{"epoch": 30, "training_loss": NaN, "training_acc": 52.0, "val_loss": NaN, "val_acc": 56.0}
{"epoch": 31, "training_loss": NaN, "training_acc": 52.0, "val_loss": NaN, "val_acc": 56.0}
{"epoch": 32, "training_loss": NaN, "training_acc": 52.0, "val_loss": NaN, "val_acc": 56.0}
{"epoch": 33, "training_loss": NaN, "training_acc": 52.0, "val_loss": NaN, "val_acc": 56.0}
