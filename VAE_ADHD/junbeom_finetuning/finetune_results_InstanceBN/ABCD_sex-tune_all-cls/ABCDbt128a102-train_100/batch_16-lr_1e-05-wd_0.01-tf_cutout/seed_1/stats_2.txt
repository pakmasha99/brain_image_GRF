"main_modify.py --pretrained_path /scratch/connectome/dyhan316/VAE_ADHD/barlowtwins/pretrain_results/ABCDbt128a102.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 1 --task ABCD_sex --input_option BT_org --learning_rate 1e-5 --batch_size 16 --weight_decay 1e-2 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 0.7005844783782958, "training_acc": 47.0, "val_loss": 0.695936439037323, "val_acc": 48.0}
{"epoch": 1, "training_loss": 0.6967166996002198, "training_acc": 47.0, "val_loss": 0.6956202411651611, "val_acc": 48.0}
{"epoch": 2, "training_loss": 0.6960025691986084, "training_acc": 47.0, "val_loss": 0.6959039616584778, "val_acc": 48.0}
{"epoch": 3, "training_loss": 0.6956309247016906, "training_acc": 47.0, "val_loss": 0.6945486807823181, "val_acc": 48.0}
{"epoch": 4, "training_loss": 0.6937572574615478, "training_acc": 47.0, "val_loss": 0.6940249752998352, "val_acc": 48.0}
{"epoch": 5, "training_loss": 0.6930486130714416, "training_acc": 47.0, "val_loss": 0.692795250415802, "val_acc": 48.0}
{"epoch": 6, "training_loss": 0.6921047163009644, "training_acc": 48.0, "val_loss": 0.6909272956848145, "val_acc": 60.0}
{"epoch": 7, "training_loss": 0.6921913194656372, "training_acc": 53.0, "val_loss": 0.6925793552398681, "val_acc": 60.0}
{"epoch": 8, "training_loss": 0.690809268951416, "training_acc": 59.0, "val_loss": 0.6917638492584228, "val_acc": 56.0}
{"epoch": 9, "training_loss": 0.6892982172966003, "training_acc": 65.0, "val_loss": 0.6887740635871887, "val_acc": 68.0}
{"epoch": 10, "training_loss": 0.688207414150238, "training_acc": 67.0, "val_loss": 0.6900279974937439, "val_acc": 60.0}
{"epoch": 11, "training_loss": 0.6872641468048095, "training_acc": 67.0, "val_loss": 0.6901379537582397, "val_acc": 64.0}
{"epoch": 12, "training_loss": 0.6883690309524536, "training_acc": 58.0, "val_loss": 0.6882148432731628, "val_acc": 68.0}
{"epoch": 13, "training_loss": 0.6875799179077149, "training_acc": 60.0, "val_loss": 0.6877246356010437, "val_acc": 68.0}
{"epoch": 14, "training_loss": 0.6884223890304565, "training_acc": 58.0, "val_loss": 0.6885254645347595, "val_acc": 60.0}
{"epoch": 15, "training_loss": 0.6847016215324402, "training_acc": 64.0, "val_loss": 0.6894374799728393, "val_acc": 60.0}
{"epoch": 16, "training_loss": 0.6849144887924195, "training_acc": 65.0, "val_loss": 0.6878718781471252, "val_acc": 68.0}
{"epoch": 17, "training_loss": 0.684003827571869, "training_acc": 67.0, "val_loss": 0.6878345966339111, "val_acc": 68.0}
{"epoch": 18, "training_loss": 0.6818592739105225, "training_acc": 60.0, "val_loss": 0.685845103263855, "val_acc": 64.0}
{"epoch": 19, "training_loss": 0.6829077768325805, "training_acc": 64.0, "val_loss": 0.6858154463768006, "val_acc": 56.0}
{"epoch": 20, "training_loss": 0.6852135324478149, "training_acc": 59.0, "val_loss": 0.6852214646339416, "val_acc": 52.0}
{"epoch": 21, "training_loss": 0.6814598321914673, "training_acc": 60.0, "val_loss": 0.6866762495040893, "val_acc": 64.0}
{"epoch": 22, "training_loss": 0.6800299167633057, "training_acc": 59.0, "val_loss": 0.6864378523826599, "val_acc": 60.0}
{"epoch": 23, "training_loss": 0.6790883922576905, "training_acc": 58.0, "val_loss": 0.6860203957557678, "val_acc": 68.0}
{"epoch": 24, "training_loss": 0.6788519525527954, "training_acc": 59.0, "val_loss": 0.686875958442688, "val_acc": 56.0}
{"epoch": 25, "training_loss": 0.678057246208191, "training_acc": 59.0, "val_loss": 0.6847850346565246, "val_acc": 56.0}
{"epoch": 26, "training_loss": 0.6785898876190185, "training_acc": 59.0, "val_loss": 0.6857326102256774, "val_acc": 56.0}
{"epoch": 27, "training_loss": 0.6753182530403137, "training_acc": 56.0, "val_loss": 0.6837002682685852, "val_acc": 52.0}
{"epoch": 28, "training_loss": 0.6749564981460572, "training_acc": 59.0, "val_loss": 0.6831622266769409, "val_acc": 56.0}
{"epoch": 29, "training_loss": 0.675355339050293, "training_acc": 57.0, "val_loss": 0.685778865814209, "val_acc": 52.0}
{"epoch": 30, "training_loss": 0.6761799764633178, "training_acc": 58.0, "val_loss": 0.6847856640815735, "val_acc": 56.0}
{"epoch": 31, "training_loss": 0.6746568417549134, "training_acc": 58.0, "val_loss": 0.6846273732185364, "val_acc": 52.0}
{"epoch": 32, "training_loss": 0.6732698440551758, "training_acc": 58.0, "val_loss": 0.6843532800674439, "val_acc": 56.0}
{"epoch": 33, "training_loss": 0.6775597381591797, "training_acc": 58.0, "val_loss": 0.6837630009651184, "val_acc": 60.0}
{"epoch": 34, "training_loss": 0.6728862738609314, "training_acc": 59.0, "val_loss": 0.6825181889533997, "val_acc": 56.0}
{"epoch": 35, "training_loss": 0.6730766129493714, "training_acc": 60.0, "val_loss": 0.6828262305259705, "val_acc": 60.0}
{"epoch": 36, "training_loss": 0.6732970356941224, "training_acc": 59.0, "val_loss": 0.6828340864181519, "val_acc": 64.0}
{"epoch": 37, "training_loss": 0.6771940135955811, "training_acc": 59.0, "val_loss": 0.6809499025344848, "val_acc": 56.0}
{"epoch": 38, "training_loss": 0.6687073850631714, "training_acc": 61.0, "val_loss": 0.682193374633789, "val_acc": 56.0}
{"epoch": 39, "training_loss": 0.6785919833183288, "training_acc": 59.0, "val_loss": 0.6791772079467774, "val_acc": 60.0}
{"epoch": 40, "training_loss": 0.6686432433128356, "training_acc": 60.0, "val_loss": 0.6791644334793091, "val_acc": 64.0}
{"epoch": 41, "training_loss": 0.6684184789657592, "training_acc": 64.0, "val_loss": 0.6808695602416992, "val_acc": 64.0}
{"epoch": 42, "training_loss": 0.6658420133590698, "training_acc": 65.0, "val_loss": 0.6812028956413269, "val_acc": 64.0}
{"epoch": 43, "training_loss": 0.6677815318107605, "training_acc": 62.0, "val_loss": 0.6822522807121277, "val_acc": 64.0}
{"epoch": 44, "training_loss": 0.6716962742805481, "training_acc": 66.0, "val_loss": 0.6832292032241821, "val_acc": 68.0}
{"epoch": 45, "training_loss": 0.6680721759796142, "training_acc": 65.0, "val_loss": 0.6821604108810425, "val_acc": 60.0}
{"epoch": 46, "training_loss": 0.666547155380249, "training_acc": 64.0, "val_loss": 0.6844679999351502, "val_acc": 60.0}
{"epoch": 47, "training_loss": 0.6691400384902955, "training_acc": 63.0, "val_loss": 0.6827082419395447, "val_acc": 64.0}
{"epoch": 48, "training_loss": 0.6688142442703247, "training_acc": 61.0, "val_loss": 0.6822883820533753, "val_acc": 64.0}
{"epoch": 49, "training_loss": 0.6615004920959473, "training_acc": 70.0, "val_loss": 0.6822851943969727, "val_acc": 68.0}
{"epoch": 50, "training_loss": 0.662556710243225, "training_acc": 66.0, "val_loss": 0.6816645431518554, "val_acc": 64.0}
{"epoch": 51, "training_loss": 0.6667701911926269, "training_acc": 65.0, "val_loss": 0.6831899213790894, "val_acc": 72.0}
{"epoch": 52, "training_loss": 0.6632452154159546, "training_acc": 68.0, "val_loss": 0.680287823677063, "val_acc": 68.0}
{"epoch": 53, "training_loss": 0.6621596479415893, "training_acc": 65.0, "val_loss": 0.6797949266433716, "val_acc": 64.0}
{"epoch": 54, "training_loss": 0.6614408826828003, "training_acc": 69.0, "val_loss": 0.6818810820579528, "val_acc": 68.0}
{"epoch": 55, "training_loss": 0.6587436127662659, "training_acc": 62.0, "val_loss": 0.6803964710235596, "val_acc": 68.0}
{"epoch": 56, "training_loss": 0.666869044303894, "training_acc": 68.0, "val_loss": 0.6810563564300537, "val_acc": 68.0}
{"epoch": 57, "training_loss": 0.6637367463111877, "training_acc": 67.0, "val_loss": 0.6774723911285401, "val_acc": 64.0}
{"epoch": 58, "training_loss": 0.6570957231521607, "training_acc": 68.0, "val_loss": 0.6817535519599914, "val_acc": 64.0}
{"epoch": 59, "training_loss": 0.6552656936645508, "training_acc": 71.0, "val_loss": 0.6785622119903565, "val_acc": 68.0}
{"epoch": 60, "training_loss": 0.651439950466156, "training_acc": 73.0, "val_loss": 0.679925491809845, "val_acc": 68.0}
{"epoch": 61, "training_loss": 0.6574161052703857, "training_acc": 74.0, "val_loss": 0.6778957295417786, "val_acc": 68.0}
{"epoch": 62, "training_loss": 0.6553319478034973, "training_acc": 74.0, "val_loss": 0.6780693817138672, "val_acc": 68.0}
{"epoch": 63, "training_loss": 0.6506420874595642, "training_acc": 72.0, "val_loss": 0.6785391902923584, "val_acc": 64.0}
{"epoch": 64, "training_loss": 0.6587320995330811, "training_acc": 69.0, "val_loss": 0.6822135019302368, "val_acc": 68.0}
{"epoch": 65, "training_loss": 0.6647181510925293, "training_acc": 65.0, "val_loss": 0.6811443066596985, "val_acc": 68.0}
{"epoch": 66, "training_loss": 0.6698981833457947, "training_acc": 69.0, "val_loss": 0.6775760197639465, "val_acc": 68.0}
{"epoch": 67, "training_loss": 0.6591846346855164, "training_acc": 65.0, "val_loss": 0.683885281085968, "val_acc": 60.0}
{"epoch": 68, "training_loss": 0.648571515083313, "training_acc": 72.0, "val_loss": 0.6818589448928833, "val_acc": 68.0}
{"epoch": 69, "training_loss": 0.6459927558898926, "training_acc": 72.0, "val_loss": 0.6806911301612854, "val_acc": 64.0}
{"epoch": 70, "training_loss": 0.6506700420379639, "training_acc": 74.0, "val_loss": 0.680244243144989, "val_acc": 68.0}
{"epoch": 71, "training_loss": 0.6504848527908326, "training_acc": 72.0, "val_loss": 0.6777305769920349, "val_acc": 68.0}
{"epoch": 72, "training_loss": 0.6611178183555603, "training_acc": 66.0, "val_loss": 0.6808947467803955, "val_acc": 60.0}
{"epoch": 73, "training_loss": 0.6522507381439209, "training_acc": 74.0, "val_loss": 0.6773309254646301, "val_acc": 68.0}
{"epoch": 74, "training_loss": 0.6461611318588257, "training_acc": 74.0, "val_loss": 0.6818101263046265, "val_acc": 60.0}
{"epoch": 75, "training_loss": 0.6479374885559082, "training_acc": 74.0, "val_loss": 0.6798111414909362, "val_acc": 64.0}
{"epoch": 76, "training_loss": 0.6502209186553956, "training_acc": 72.0, "val_loss": 0.678889856338501, "val_acc": 64.0}
{"epoch": 77, "training_loss": 0.6433214092254639, "training_acc": 76.0, "val_loss": 0.6800257539749146, "val_acc": 68.0}
{"epoch": 78, "training_loss": 0.6435681486129761, "training_acc": 74.0, "val_loss": 0.6818259119987488, "val_acc": 68.0}
{"epoch": 79, "training_loss": 0.6420179152488709, "training_acc": 76.0, "val_loss": 0.6765659260749817, "val_acc": 68.0}
{"epoch": 80, "training_loss": 0.6464389657974243, "training_acc": 74.0, "val_loss": 0.6804229497909546, "val_acc": 60.0}
{"epoch": 81, "training_loss": 0.6637986016273498, "training_acc": 69.0, "val_loss": 0.6803202748298645, "val_acc": 68.0}
{"epoch": 82, "training_loss": 0.6557679748535157, "training_acc": 69.0, "val_loss": 0.676314423084259, "val_acc": 64.0}
{"epoch": 83, "training_loss": 0.6579253125190735, "training_acc": 65.0, "val_loss": 0.6831512522697448, "val_acc": 64.0}
{"epoch": 84, "training_loss": 0.6574690389633179, "training_acc": 65.0, "val_loss": 0.6814184880256653, "val_acc": 60.0}
{"epoch": 85, "training_loss": 0.6472717642784118, "training_acc": 79.0, "val_loss": 0.6810456395149231, "val_acc": 68.0}
{"epoch": 86, "training_loss": 0.6435451483726502, "training_acc": 77.0, "val_loss": 0.6826991987228394, "val_acc": 64.0}
{"epoch": 87, "training_loss": 0.6479680919647217, "training_acc": 69.0, "val_loss": 0.6767033076286316, "val_acc": 68.0}
{"epoch": 88, "training_loss": 0.6442391610145569, "training_acc": 73.0, "val_loss": 0.6756434488296509, "val_acc": 68.0}
{"epoch": 89, "training_loss": 0.634593620300293, "training_acc": 73.0, "val_loss": 0.679643280506134, "val_acc": 68.0}
{"epoch": 90, "training_loss": 0.6421805167198181, "training_acc": 76.0, "val_loss": 0.6831602931022644, "val_acc": 60.0}
{"epoch": 91, "training_loss": 0.6448887348175049, "training_acc": 70.0, "val_loss": 0.6757797741889954, "val_acc": 60.0}
{"epoch": 92, "training_loss": 0.6334449100494385, "training_acc": 76.0, "val_loss": 0.6796223664283753, "val_acc": 68.0}
{"epoch": 93, "training_loss": 0.639117591381073, "training_acc": 75.0, "val_loss": 0.6801183414459229, "val_acc": 64.0}
{"epoch": 94, "training_loss": 0.6543917560577392, "training_acc": 72.0, "val_loss": 0.675546612739563, "val_acc": 68.0}
{"epoch": 95, "training_loss": 0.6375715112686158, "training_acc": 75.0, "val_loss": 0.6799339914321899, "val_acc": 72.0}
{"epoch": 96, "training_loss": 0.6506155323982239, "training_acc": 68.0, "val_loss": 0.6769825315475464, "val_acc": 64.0}
{"epoch": 97, "training_loss": 0.6498842096328735, "training_acc": 74.0, "val_loss": 0.6753946018218994, "val_acc": 64.0}
{"epoch": 98, "training_loss": 0.6324791860580444, "training_acc": 79.0, "val_loss": 0.6779417037963867, "val_acc": 60.0}
{"epoch": 99, "training_loss": 0.6368612098693848, "training_acc": 76.0, "val_loss": 0.6777009129524231, "val_acc": 60.0}
