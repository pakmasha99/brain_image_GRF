"main_modify.py --pretrained_path /scratch/connectome/dyhan316/VAE_ADHD/barlowtwins/pretrain_results/ABCDbt128a102.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 1 --task ABCD_sex --input_option BT_org --learning_rate 1e-5 --batch_size 16 --weight_decay 1e-2 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 0.6928921627998352, "training_acc": 53.0, "val_loss": 0.6924794960021973, "val_acc": 52.0}
{"epoch": 1, "training_loss": 0.6923726987838745, "training_acc": 53.0, "val_loss": 0.6917067646980286, "val_acc": 52.0}
{"epoch": 2, "training_loss": 0.6908497333526611, "training_acc": 53.0, "val_loss": 0.6920283532142639, "val_acc": 52.0}
{"epoch": 3, "training_loss": 0.6907434296607972, "training_acc": 53.0, "val_loss": 0.6914808940887451, "val_acc": 52.0}
{"epoch": 4, "training_loss": 0.6894395446777344, "training_acc": 53.0, "val_loss": 0.689602632522583, "val_acc": 52.0}
{"epoch": 5, "training_loss": 0.6884412622451782, "training_acc": 53.0, "val_loss": 0.6912775802612304, "val_acc": 52.0}
{"epoch": 6, "training_loss": 0.6872830057144165, "training_acc": 53.0, "val_loss": 0.6898175525665283, "val_acc": 52.0}
{"epoch": 7, "training_loss": 0.6886781167984009, "training_acc": 53.0, "val_loss": 0.6912375688552856, "val_acc": 52.0}
{"epoch": 8, "training_loss": 0.6876520156860352, "training_acc": 53.0, "val_loss": 0.6909390139579773, "val_acc": 52.0}
{"epoch": 9, "training_loss": 0.6863762092590332, "training_acc": 53.0, "val_loss": 0.6913693261146545, "val_acc": 52.0}
{"epoch": 10, "training_loss": 0.6839813709259033, "training_acc": 53.0, "val_loss": 0.6893398451805115, "val_acc": 52.0}
{"epoch": 11, "training_loss": 0.6842879962921142, "training_acc": 53.0, "val_loss": 0.6897085881233216, "val_acc": 52.0}
{"epoch": 12, "training_loss": 0.6831919050216675, "training_acc": 53.0, "val_loss": 0.6902861452102661, "val_acc": 52.0}
{"epoch": 13, "training_loss": 0.6823211073875427, "training_acc": 53.0, "val_loss": 0.6914724564552307, "val_acc": 52.0}
{"epoch": 14, "training_loss": 0.6816365909576416, "training_acc": 53.0, "val_loss": 0.6922129654884338, "val_acc": 52.0}
{"epoch": 15, "training_loss": 0.6831883621215821, "training_acc": 53.0, "val_loss": 0.6921030139923096, "val_acc": 52.0}
{"epoch": 16, "training_loss": 0.6799722290039063, "training_acc": 53.0, "val_loss": 0.6895307207107544, "val_acc": 52.0}
{"epoch": 17, "training_loss": 0.6798788118362427, "training_acc": 53.0, "val_loss": 0.6907156038284302, "val_acc": 56.0}
{"epoch": 18, "training_loss": 0.6816541457176208, "training_acc": 54.0, "val_loss": 0.691170654296875, "val_acc": 52.0}
{"epoch": 19, "training_loss": 0.6780807662010193, "training_acc": 54.0, "val_loss": 0.6914333748817444, "val_acc": 52.0}
{"epoch": 20, "training_loss": 0.6772664737701416, "training_acc": 58.0, "val_loss": 0.6902728009223938, "val_acc": 52.0}
{"epoch": 21, "training_loss": 0.6778097891807556, "training_acc": 58.0, "val_loss": 0.6915947270393371, "val_acc": 52.0}
{"epoch": 22, "training_loss": 0.676055850982666, "training_acc": 58.0, "val_loss": 0.6907291483879089, "val_acc": 64.0}
{"epoch": 23, "training_loss": 0.6764782428741455, "training_acc": 57.0, "val_loss": 0.6922215962409973, "val_acc": 52.0}
{"epoch": 24, "training_loss": 0.6762504887580871, "training_acc": 58.0, "val_loss": 0.6930451679229737, "val_acc": 56.0}
{"epoch": 25, "training_loss": 0.6718077611923218, "training_acc": 58.0, "val_loss": 0.6921797919273377, "val_acc": 52.0}
{"epoch": 26, "training_loss": 0.6733398962020875, "training_acc": 56.0, "val_loss": 0.6944779205322266, "val_acc": 56.0}
{"epoch": 27, "training_loss": 0.6719373416900635, "training_acc": 60.0, "val_loss": 0.6925020480155945, "val_acc": 52.0}
{"epoch": 28, "training_loss": 0.6689019632339478, "training_acc": 63.0, "val_loss": 0.6923181295394898, "val_acc": 56.0}
{"epoch": 29, "training_loss": 0.6705239820480347, "training_acc": 59.0, "val_loss": 0.6927802109718323, "val_acc": 52.0}
