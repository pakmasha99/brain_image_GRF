"main_modify.py --pretrained_path /scratch/connectome/dyhan316/VAE_ADHD/barlowtwins/pretrain_results/ABCDbt128a102.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 1 --task ABCD_sex --input_option BT_org --learning_rate 1e-5 --batch_size 16 --weight_decay 1e-2 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 0.7078462934494019, "training_acc": 47.0, "val_loss": 0.7037215495109558, "val_acc": 48.0}
{"epoch": 1, "training_loss": 0.7056532597541809, "training_acc": 47.0, "val_loss": 0.7032282710075378, "val_acc": 48.0}
{"epoch": 2, "training_loss": 0.7030421161651611, "training_acc": 47.0, "val_loss": 0.7010899400711059, "val_acc": 48.0}
{"epoch": 3, "training_loss": 0.699783923625946, "training_acc": 47.0, "val_loss": 0.6984509420394898, "val_acc": 48.0}
{"epoch": 4, "training_loss": 0.6986233592033386, "training_acc": 47.0, "val_loss": 0.6958877491950989, "val_acc": 48.0}
{"epoch": 5, "training_loss": 0.697703595161438, "training_acc": 47.0, "val_loss": 0.6967374491691589, "val_acc": 48.0}
{"epoch": 6, "training_loss": 0.6973471832275391, "training_acc": 47.0, "val_loss": 0.6940013909339905, "val_acc": 48.0}
{"epoch": 7, "training_loss": 0.6951374197006226, "training_acc": 47.0, "val_loss": 0.6947473573684693, "val_acc": 48.0}
{"epoch": 8, "training_loss": 0.6955394148826599, "training_acc": 47.0, "val_loss": 0.6946149182319641, "val_acc": 48.0}
{"epoch": 9, "training_loss": 0.695098819732666, "training_acc": 47.0, "val_loss": 0.6941242122650146, "val_acc": 48.0}
{"epoch": 10, "training_loss": 0.6926956129074097, "training_acc": 47.0, "val_loss": 0.6904605412483216, "val_acc": 48.0}
{"epoch": 11, "training_loss": 0.6935285878181457, "training_acc": 47.0, "val_loss": 0.6913702034950256, "val_acc": 52.0}
{"epoch": 12, "training_loss": 0.6910003614425659, "training_acc": 49.0, "val_loss": 0.6896387028694153, "val_acc": 52.0}
{"epoch": 13, "training_loss": 0.6891540145874023, "training_acc": 65.0, "val_loss": 0.6889933037757874, "val_acc": 64.0}
{"epoch": 14, "training_loss": 0.6871658658981323, "training_acc": 62.0, "val_loss": 0.6870201230049133, "val_acc": 64.0}
{"epoch": 15, "training_loss": 0.6865663576126099, "training_acc": 66.0, "val_loss": 0.6855900406837463, "val_acc": 68.0}
{"epoch": 16, "training_loss": 0.6837076282501221, "training_acc": 73.0, "val_loss": 0.68466623544693, "val_acc": 72.0}
{"epoch": 17, "training_loss": 0.6833806538581848, "training_acc": 67.0, "val_loss": 0.684793860912323, "val_acc": 60.0}
{"epoch": 18, "training_loss": 0.6816899299621582, "training_acc": 69.0, "val_loss": 0.6848684787750244, "val_acc": 60.0}
{"epoch": 19, "training_loss": 0.6869595241546631, "training_acc": 59.0, "val_loss": 0.6879036355018616, "val_acc": 64.0}
{"epoch": 20, "training_loss": 0.6878196954727173, "training_acc": 60.0, "val_loss": 0.6848311233520508, "val_acc": 60.0}
{"epoch": 21, "training_loss": 0.684346809387207, "training_acc": 61.0, "val_loss": 0.6827589893341064, "val_acc": 60.0}
{"epoch": 22, "training_loss": 0.6811210870742798, "training_acc": 68.0, "val_loss": 0.6862804293632507, "val_acc": 64.0}
{"epoch": 23, "training_loss": 0.6845807933807373, "training_acc": 67.0, "val_loss": 0.6850453090667724, "val_acc": 64.0}
{"epoch": 24, "training_loss": 0.6820842599868775, "training_acc": 71.0, "val_loss": 0.682341058254242, "val_acc": 60.0}
{"epoch": 25, "training_loss": 0.6833817720413208, "training_acc": 62.0, "val_loss": 0.686396975517273, "val_acc": 56.0}
{"epoch": 26, "training_loss": 0.6806204843521119, "training_acc": 63.0, "val_loss": 0.6823460721969604, "val_acc": 60.0}
{"epoch": 27, "training_loss": 0.6809529805183411, "training_acc": 72.0, "val_loss": 0.6836286807060241, "val_acc": 56.0}
{"epoch": 28, "training_loss": 0.677042944431305, "training_acc": 69.0, "val_loss": 0.6803661131858826, "val_acc": 60.0}
{"epoch": 29, "training_loss": 0.6780094528198242, "training_acc": 68.0, "val_loss": 0.6800229001045227, "val_acc": 60.0}
{"epoch": 30, "training_loss": 0.6766501593589783, "training_acc": 67.0, "val_loss": 0.6834646415710449, "val_acc": 60.0}
{"epoch": 31, "training_loss": 0.6757097840309143, "training_acc": 72.0, "val_loss": 0.6819063282012939, "val_acc": 60.0}
{"epoch": 32, "training_loss": 0.6746330404281616, "training_acc": 70.0, "val_loss": 0.6786697936058045, "val_acc": 60.0}
{"epoch": 33, "training_loss": 0.6756627678871154, "training_acc": 71.0, "val_loss": 0.6790338945388794, "val_acc": 60.0}
{"epoch": 34, "training_loss": 0.6721685695648193, "training_acc": 71.0, "val_loss": 0.681194806098938, "val_acc": 60.0}
{"epoch": 35, "training_loss": 0.6738720560073852, "training_acc": 69.0, "val_loss": 0.6776443099975586, "val_acc": 60.0}
{"epoch": 36, "training_loss": 0.6807280850410461, "training_acc": 62.0, "val_loss": 0.6790765690803527, "val_acc": 60.0}
{"epoch": 37, "training_loss": 0.671818220615387, "training_acc": 66.0, "val_loss": 0.679305739402771, "val_acc": 56.0}
{"epoch": 38, "training_loss": 0.6753399109840393, "training_acc": 61.0, "val_loss": 0.6765412950515747, "val_acc": 60.0}
{"epoch": 39, "training_loss": 0.6721889901161194, "training_acc": 68.0, "val_loss": 0.679463107585907, "val_acc": 60.0}
{"epoch": 40, "training_loss": 0.6683829522132874, "training_acc": 67.0, "val_loss": 0.6760600399971008, "val_acc": 60.0}
{"epoch": 41, "training_loss": 0.6698887991905212, "training_acc": 71.0, "val_loss": 0.6795917582511902, "val_acc": 60.0}
{"epoch": 42, "training_loss": 0.6654121112823487, "training_acc": 71.0, "val_loss": 0.6767426633834839, "val_acc": 60.0}
{"epoch": 43, "training_loss": 0.6662020516395569, "training_acc": 75.0, "val_loss": 0.6811145329475403, "val_acc": 60.0}
{"epoch": 44, "training_loss": 0.6638694167137146, "training_acc": 74.0, "val_loss": 0.6750286936759948, "val_acc": 60.0}
{"epoch": 45, "training_loss": 0.6634447264671326, "training_acc": 75.0, "val_loss": 0.6808546352386474, "val_acc": 60.0}
{"epoch": 46, "training_loss": 0.6685434484481811, "training_acc": 72.0, "val_loss": 0.6753786778450013, "val_acc": 56.0}
{"epoch": 47, "training_loss": 0.6689496016502381, "training_acc": 71.0, "val_loss": 0.677290005683899, "val_acc": 60.0}
{"epoch": 48, "training_loss": 0.663166606426239, "training_acc": 71.0, "val_loss": 0.6757710218429566, "val_acc": 56.0}
{"epoch": 49, "training_loss": 0.6632980704307556, "training_acc": 69.0, "val_loss": 0.6763525128364563, "val_acc": 60.0}
{"epoch": 50, "training_loss": 0.6633042430877686, "training_acc": 73.0, "val_loss": 0.6741070175170898, "val_acc": 56.0}
{"epoch": 51, "training_loss": 0.6599691677093505, "training_acc": 72.0, "val_loss": 0.6757671308517456, "val_acc": 56.0}
{"epoch": 52, "training_loss": 0.659555983543396, "training_acc": 72.0, "val_loss": 0.6758026194572448, "val_acc": 60.0}
{"epoch": 53, "training_loss": 0.6577493977546692, "training_acc": 74.0, "val_loss": 0.6738543272018432, "val_acc": 60.0}
{"epoch": 54, "training_loss": 0.6546995067596435, "training_acc": 73.0, "val_loss": 0.6804810738563538, "val_acc": 56.0}
{"epoch": 55, "training_loss": 0.6623710656166076, "training_acc": 67.0, "val_loss": 0.674609944820404, "val_acc": 64.0}
{"epoch": 56, "training_loss": 0.67057781457901, "training_acc": 68.0, "val_loss": 0.6766472959518433, "val_acc": 60.0}
{"epoch": 57, "training_loss": 0.6623201322555542, "training_acc": 65.0, "val_loss": 0.6761175036430359, "val_acc": 60.0}
{"epoch": 58, "training_loss": 0.6569028997421265, "training_acc": 72.0, "val_loss": 0.6710178089141846, "val_acc": 60.0}
{"epoch": 59, "training_loss": 0.6567111730575561, "training_acc": 73.0, "val_loss": 0.6739021229743958, "val_acc": 56.0}
{"epoch": 60, "training_loss": 0.6603220343589783, "training_acc": 69.0, "val_loss": 0.6742939734458924, "val_acc": 56.0}
{"epoch": 61, "training_loss": 0.6548859167098999, "training_acc": 71.0, "val_loss": 0.6716492795944213, "val_acc": 56.0}
{"epoch": 62, "training_loss": 0.654678020477295, "training_acc": 69.0, "val_loss": 0.678765594959259, "val_acc": 56.0}
{"epoch": 63, "training_loss": 0.6533503055572509, "training_acc": 71.0, "val_loss": 0.6710759091377259, "val_acc": 56.0}
{"epoch": 64, "training_loss": 0.6467883157730102, "training_acc": 74.0, "val_loss": 0.6788663578033447, "val_acc": 60.0}
{"epoch": 65, "training_loss": 0.6509171271324158, "training_acc": 70.0, "val_loss": 0.668144223690033, "val_acc": 56.0}
{"epoch": 66, "training_loss": 0.6530288934707642, "training_acc": 70.0, "val_loss": 0.677699089050293, "val_acc": 60.0}
{"epoch": 67, "training_loss": 0.6502141833305359, "training_acc": 69.0, "val_loss": 0.6681487607955933, "val_acc": 64.0}
{"epoch": 68, "training_loss": 0.6529412984848022, "training_acc": 71.0, "val_loss": 0.6794511461257935, "val_acc": 56.0}
{"epoch": 69, "training_loss": 0.6531740427017212, "training_acc": 75.0, "val_loss": 0.6674647092819214, "val_acc": 60.0}
{"epoch": 70, "training_loss": 0.6611623907089234, "training_acc": 69.0, "val_loss": 0.6706290721893311, "val_acc": 60.0}
{"epoch": 71, "training_loss": 0.6502597856521607, "training_acc": 73.0, "val_loss": 0.6738928365707397, "val_acc": 56.0}
{"epoch": 72, "training_loss": 0.6501581501960755, "training_acc": 72.0, "val_loss": 0.6757785391807556, "val_acc": 60.0}
{"epoch": 73, "training_loss": 0.6585031390190125, "training_acc": 65.0, "val_loss": 0.6703651642799378, "val_acc": 56.0}
{"epoch": 74, "training_loss": 0.6512214946746826, "training_acc": 71.0, "val_loss": 0.6780081224441529, "val_acc": 56.0}
{"epoch": 75, "training_loss": 0.647524380683899, "training_acc": 69.0, "val_loss": 0.6708027291297912, "val_acc": 60.0}
{"epoch": 76, "training_loss": 0.671197054386139, "training_acc": 69.0, "val_loss": 0.6661646604537964, "val_acc": 60.0}
{"epoch": 77, "training_loss": 0.6495059561729432, "training_acc": 69.0, "val_loss": 0.6697714567184448, "val_acc": 60.0}
{"epoch": 78, "training_loss": 0.6442634272575378, "training_acc": 76.0, "val_loss": 0.672202332019806, "val_acc": 56.0}
{"epoch": 79, "training_loss": 0.6489330005645751, "training_acc": 68.0, "val_loss": 0.6679493308067321, "val_acc": 60.0}
{"epoch": 80, "training_loss": 0.6395319700241089, "training_acc": 75.0, "val_loss": 0.6738049769401551, "val_acc": 60.0}
{"epoch": 81, "training_loss": 0.6392747497558594, "training_acc": 72.0, "val_loss": 0.6698457288742066, "val_acc": 60.0}
{"epoch": 82, "training_loss": 0.6426650881767273, "training_acc": 72.0, "val_loss": 0.6732877826690674, "val_acc": 56.0}
{"epoch": 83, "training_loss": 0.6434439182281494, "training_acc": 72.0, "val_loss": 0.6692888188362122, "val_acc": 60.0}
{"epoch": 84, "training_loss": 0.6421434092521667, "training_acc": 70.0, "val_loss": 0.6664018988609314, "val_acc": 60.0}
{"epoch": 85, "training_loss": 0.6511880588531495, "training_acc": 73.0, "val_loss": 0.6666935229301453, "val_acc": 60.0}
{"epoch": 86, "training_loss": 0.6431065940856934, "training_acc": 73.0, "val_loss": 0.6667831826210022, "val_acc": 60.0}
{"epoch": 87, "training_loss": 0.6366935443878173, "training_acc": 74.0, "val_loss": 0.6713522124290466, "val_acc": 60.0}
{"epoch": 88, "training_loss": 0.6361652708053589, "training_acc": 73.0, "val_loss": 0.6648805499076843, "val_acc": 60.0}
{"epoch": 89, "training_loss": 0.636937370300293, "training_acc": 76.0, "val_loss": 0.6694799971580505, "val_acc": 60.0}
{"epoch": 90, "training_loss": 0.6347129917144776, "training_acc": 78.0, "val_loss": 0.6661670708656311, "val_acc": 60.0}
{"epoch": 91, "training_loss": 0.6332185935974121, "training_acc": 77.0, "val_loss": 0.6673956680297851, "val_acc": 60.0}
{"epoch": 92, "training_loss": 0.6316132307052612, "training_acc": 81.0, "val_loss": 0.6677351188659668, "val_acc": 64.0}
{"epoch": 93, "training_loss": 0.6314691734313965, "training_acc": 77.0, "val_loss": 0.6660130620002747, "val_acc": 60.0}
{"epoch": 94, "training_loss": 0.6330000615119934, "training_acc": 81.0, "val_loss": 0.6744328236579895, "val_acc": 56.0}
{"epoch": 95, "training_loss": 0.6345571756362915, "training_acc": 74.0, "val_loss": 0.6630921888351441, "val_acc": 60.0}
{"epoch": 96, "training_loss": 0.6319371700286865, "training_acc": 77.0, "val_loss": 0.66614413022995, "val_acc": 60.0}
{"epoch": 97, "training_loss": 0.6236584448814392, "training_acc": 80.0, "val_loss": 0.6629889678955078, "val_acc": 60.0}
{"epoch": 98, "training_loss": 0.6320183897018432, "training_acc": 75.0, "val_loss": 0.6645349621772766, "val_acc": 60.0}
{"epoch": 99, "training_loss": 0.6291695880889893, "training_acc": 77.0, "val_loss": 0.6687704467773438, "val_acc": 60.0}
