"main_modify.py --pretrained_path /scratch/connectome/dyhan316/VAE_ADHD/barlowtwins/pretrain_results/ABCDbt128a102.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 2 --task ABCD_sex --input_option BT_org --learning_rate 1e-5 --batch_size 16 --weight_decay 1e-2 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 0.6988100433349609, "training_acc": 47.0, "val_loss": 0.6976265454292297, "val_acc": 48.0}
{"epoch": 1, "training_loss": 0.6981912994384766, "training_acc": 47.0, "val_loss": 0.6972090864181518, "val_acc": 48.0}
{"epoch": 2, "training_loss": 0.6983366751670838, "training_acc": 47.0, "val_loss": 0.6954909515380859, "val_acc": 48.0}
{"epoch": 3, "training_loss": 0.6965693235397339, "training_acc": 47.0, "val_loss": 0.6938183450698853, "val_acc": 48.0}
{"epoch": 4, "training_loss": 0.6955013942718505, "training_acc": 47.0, "val_loss": 0.6928068852424621, "val_acc": 48.0}
{"epoch": 5, "training_loss": 0.6943239784240722, "training_acc": 47.0, "val_loss": 0.690834698677063, "val_acc": 48.0}
{"epoch": 6, "training_loss": 0.6925763297080993, "training_acc": 47.0, "val_loss": 0.6886986923217774, "val_acc": 48.0}
{"epoch": 7, "training_loss": 0.6906065249443054, "training_acc": 61.0, "val_loss": 0.6869101262092591, "val_acc": 80.0}
{"epoch": 8, "training_loss": 0.6901522779464722, "training_acc": 61.0, "val_loss": 0.6844380593299866, "val_acc": 68.0}
{"epoch": 9, "training_loss": 0.6877447628974914, "training_acc": 66.0, "val_loss": 0.6842871499061585, "val_acc": 80.0}
{"epoch": 10, "training_loss": 0.6878027105331421, "training_acc": 64.0, "val_loss": 0.6844603371620178, "val_acc": 60.0}
{"epoch": 11, "training_loss": 0.6877223467826843, "training_acc": 62.0, "val_loss": 0.683587772846222, "val_acc": 72.0}
{"epoch": 12, "training_loss": 0.687696521282196, "training_acc": 67.0, "val_loss": 0.6816705274581909, "val_acc": 56.0}
{"epoch": 13, "training_loss": 0.6854791665077209, "training_acc": 57.0, "val_loss": 0.6830349516868591, "val_acc": 68.0}
{"epoch": 14, "training_loss": 0.6879776644706727, "training_acc": 66.0, "val_loss": 0.6806279706954956, "val_acc": 56.0}
{"epoch": 15, "training_loss": 0.6891427993774414, "training_acc": 56.0, "val_loss": 0.6875228571891785, "val_acc": 52.0}
{"epoch": 16, "training_loss": 0.687006242275238, "training_acc": 56.0, "val_loss": 0.6818964076042175, "val_acc": 52.0}
{"epoch": 17, "training_loss": 0.6879773139953613, "training_acc": 64.0, "val_loss": 0.681008689403534, "val_acc": 64.0}
{"epoch": 18, "training_loss": 0.684582359790802, "training_acc": 58.0, "val_loss": 0.686775438785553, "val_acc": 52.0}
{"epoch": 19, "training_loss": 0.6872618889808655, "training_acc": 57.0, "val_loss": 0.6833365631103515, "val_acc": 52.0}
{"epoch": 20, "training_loss": 0.6846319532394409, "training_acc": 59.0, "val_loss": 0.6782073521614075, "val_acc": 60.0}
{"epoch": 21, "training_loss": 0.6851175737380981, "training_acc": 58.0, "val_loss": 0.6789486408233643, "val_acc": 44.0}
{"epoch": 22, "training_loss": 0.684141435623169, "training_acc": 57.0, "val_loss": 0.6798422050476074, "val_acc": 52.0}
{"epoch": 23, "training_loss": 0.6850825357437134, "training_acc": 64.0, "val_loss": 0.6809627914428711, "val_acc": 60.0}
{"epoch": 24, "training_loss": 0.685106074810028, "training_acc": 57.0, "val_loss": 0.6873994851112366, "val_acc": 52.0}
{"epoch": 25, "training_loss": 0.6895725131034851, "training_acc": 55.0, "val_loss": 0.6847090291976928, "val_acc": 52.0}
{"epoch": 26, "training_loss": 0.6839027285575867, "training_acc": 55.0, "val_loss": 0.6925768280029296, "val_acc": 52.0}
{"epoch": 27, "training_loss": 0.6924816513061524, "training_acc": 56.0, "val_loss": 0.6925360798835755, "val_acc": 52.0}
{"epoch": 28, "training_loss": 0.6923450946807861, "training_acc": 50.0, "val_loss": 0.6924722027778626, "val_acc": 52.0}
{"epoch": 29, "training_loss": 0.6914230489730835, "training_acc": 55.0, "val_loss": 0.6920031785964966, "val_acc": 56.0}
{"epoch": 30, "training_loss": 0.6909604358673096, "training_acc": 52.0, "val_loss": 0.6905046725273132, "val_acc": 56.0}
{"epoch": 31, "training_loss": 0.6881737089157105, "training_acc": 59.0, "val_loss": 0.6892001819610596, "val_acc": 56.0}
{"epoch": 32, "training_loss": 0.6864121103286743, "training_acc": 61.0, "val_loss": 0.6882941818237305, "val_acc": 56.0}
{"epoch": 33, "training_loss": 0.6848278760910034, "training_acc": 59.0, "val_loss": 0.6864712357521057, "val_acc": 56.0}
{"epoch": 34, "training_loss": 0.6836796402931213, "training_acc": 62.0, "val_loss": 0.685286591053009, "val_acc": 56.0}
{"epoch": 35, "training_loss": 0.6817592144012451, "training_acc": 62.0, "val_loss": 0.6846930265426636, "val_acc": 56.0}
{"epoch": 36, "training_loss": 0.6800611066818237, "training_acc": 62.0, "val_loss": 0.6830305218696594, "val_acc": 56.0}
{"epoch": 37, "training_loss": 0.6787329721450805, "training_acc": 63.0, "val_loss": 0.6824939632415772, "val_acc": 56.0}
{"epoch": 38, "training_loss": 0.6794330930709839, "training_acc": 59.0, "val_loss": 0.6823281216621399, "val_acc": 56.0}
{"epoch": 39, "training_loss": 0.6798618745803833, "training_acc": 59.0, "val_loss": 0.6832260942459106, "val_acc": 56.0}
