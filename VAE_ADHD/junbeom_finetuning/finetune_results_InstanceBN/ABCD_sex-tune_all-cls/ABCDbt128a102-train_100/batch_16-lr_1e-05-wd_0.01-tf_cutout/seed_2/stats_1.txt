"main_modify.py --pretrained_path /scratch/connectome/dyhan316/VAE_ADHD/barlowtwins/pretrain_results/ABCDbt128a102.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 2 --task ABCD_sex --input_option BT_org --learning_rate 1e-5 --batch_size 16 --weight_decay 1e-2 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 0.7003161549568176, "training_acc": 47.0, "val_loss": 0.6988734555244446, "val_acc": 48.0}
{"epoch": 1, "training_loss": 0.6996854686737061, "training_acc": 47.0, "val_loss": 0.6985507893562317, "val_acc": 48.0}
{"epoch": 2, "training_loss": 0.6970825576782227, "training_acc": 47.0, "val_loss": 0.695012629032135, "val_acc": 48.0}
{"epoch": 3, "training_loss": 0.6970258140563965, "training_acc": 47.0, "val_loss": 0.6929322361946106, "val_acc": 48.0}
{"epoch": 4, "training_loss": 0.6959774398803711, "training_acc": 47.0, "val_loss": 0.6909753513336182, "val_acc": 48.0}
{"epoch": 5, "training_loss": 0.69366934299469, "training_acc": 47.0, "val_loss": 0.6915494537353516, "val_acc": 48.0}
{"epoch": 6, "training_loss": 0.6929892301559448, "training_acc": 47.0, "val_loss": 0.6912287068367005, "val_acc": 48.0}
{"epoch": 7, "training_loss": 0.6929105186462402, "training_acc": 47.0, "val_loss": 0.6909187316894532, "val_acc": 48.0}
{"epoch": 8, "training_loss": 0.6936031889915466, "training_acc": 48.0, "val_loss": 0.6930578589439392, "val_acc": 48.0}
{"epoch": 9, "training_loss": 0.6925724649429321, "training_acc": 51.0, "val_loss": 0.6899022793769837, "val_acc": 56.0}
{"epoch": 10, "training_loss": 0.6906578087806702, "training_acc": 53.0, "val_loss": 0.6884715390205384, "val_acc": 64.0}
{"epoch": 11, "training_loss": 0.6902337408065796, "training_acc": 55.0, "val_loss": 0.6882102584838867, "val_acc": 72.0}
{"epoch": 12, "training_loss": 0.6886512947082519, "training_acc": 60.0, "val_loss": 0.6880969166755676, "val_acc": 72.0}
{"epoch": 13, "training_loss": 0.6852819299697877, "training_acc": 68.0, "val_loss": 0.6840818023681641, "val_acc": 76.0}
{"epoch": 14, "training_loss": 0.6847525596618652, "training_acc": 63.0, "val_loss": 0.6836597156524659, "val_acc": 72.0}
{"epoch": 15, "training_loss": 0.6838161468505859, "training_acc": 68.0, "val_loss": 0.683557276725769, "val_acc": 60.0}
{"epoch": 16, "training_loss": 0.6838256072998047, "training_acc": 67.0, "val_loss": 0.6826132273674012, "val_acc": 56.0}
{"epoch": 17, "training_loss": 0.6820332717895508, "training_acc": 64.0, "val_loss": 0.6807948017120361, "val_acc": 52.0}
{"epoch": 18, "training_loss": 0.6804718685150146, "training_acc": 65.0, "val_loss": 0.6839618468284607, "val_acc": 56.0}
{"epoch": 19, "training_loss": 0.6815831971168518, "training_acc": 67.0, "val_loss": 0.6797949504852295, "val_acc": 52.0}
{"epoch": 20, "training_loss": 0.6784924459457398, "training_acc": 62.0, "val_loss": 0.6793035554885865, "val_acc": 52.0}
{"epoch": 21, "training_loss": 0.6779427671432495, "training_acc": 67.0, "val_loss": 0.6799183535575867, "val_acc": 52.0}
{"epoch": 22, "training_loss": 0.6747672891616822, "training_acc": 65.0, "val_loss": 0.6772560119628906, "val_acc": 52.0}
{"epoch": 23, "training_loss": 0.6757126903533935, "training_acc": 66.0, "val_loss": 0.6766104865074157, "val_acc": 52.0}
{"epoch": 24, "training_loss": 0.6791030311584473, "training_acc": 59.0, "val_loss": 0.6764375424385071, "val_acc": 52.0}
{"epoch": 25, "training_loss": 0.6742267799377442, "training_acc": 68.0, "val_loss": 0.6759663963317871, "val_acc": 52.0}
{"epoch": 26, "training_loss": 0.6770557117462158, "training_acc": 60.0, "val_loss": 0.6753721356391906, "val_acc": 52.0}
{"epoch": 27, "training_loss": 0.6753681898117065, "training_acc": 67.0, "val_loss": 0.6752447319030762, "val_acc": 52.0}
{"epoch": 28, "training_loss": 0.6730622863769531, "training_acc": 64.0, "val_loss": 0.6738251781463623, "val_acc": 56.0}
{"epoch": 29, "training_loss": 0.6723788118362427, "training_acc": 71.0, "val_loss": 0.6746188306808472, "val_acc": 64.0}
{"epoch": 30, "training_loss": 0.6737654614448547, "training_acc": 68.0, "val_loss": 0.6728503108024597, "val_acc": 64.0}
{"epoch": 31, "training_loss": 0.6742043662071228, "training_acc": 66.0, "val_loss": 0.6740854215621949, "val_acc": 60.0}
{"epoch": 32, "training_loss": 0.670870087146759, "training_acc": 72.0, "val_loss": 0.6726387858390808, "val_acc": 60.0}
{"epoch": 33, "training_loss": 0.6689571809768676, "training_acc": 67.0, "val_loss": 0.6715935111045838, "val_acc": 64.0}
{"epoch": 34, "training_loss": 0.6670088529586792, "training_acc": 73.0, "val_loss": 0.6705084204673767, "val_acc": 60.0}
{"epoch": 35, "training_loss": 0.667299256324768, "training_acc": 68.0, "val_loss": 0.6726813197135926, "val_acc": 56.0}
{"epoch": 36, "training_loss": 0.6653018379211426, "training_acc": 69.0, "val_loss": 0.6707840394973755, "val_acc": 52.0}
{"epoch": 37, "training_loss": 0.6659716749191285, "training_acc": 69.0, "val_loss": 0.6708981227874756, "val_acc": 60.0}
{"epoch": 38, "training_loss": 0.6685411357879638, "training_acc": 67.0, "val_loss": 0.670266592502594, "val_acc": 56.0}
{"epoch": 39, "training_loss": 0.6624490022659302, "training_acc": 70.0, "val_loss": 0.6705119061470032, "val_acc": 52.0}
{"epoch": 40, "training_loss": 0.661705493927002, "training_acc": 70.0, "val_loss": 0.6707199096679688, "val_acc": 52.0}
{"epoch": 41, "training_loss": 0.664905047416687, "training_acc": 70.0, "val_loss": 0.6666216206550598, "val_acc": 60.0}
{"epoch": 42, "training_loss": 0.6639724397659301, "training_acc": 71.0, "val_loss": 0.6702484107017517, "val_acc": 60.0}
{"epoch": 43, "training_loss": 0.6610207629203796, "training_acc": 69.0, "val_loss": 0.6685585427284241, "val_acc": 52.0}
{"epoch": 44, "training_loss": 0.6615494585037232, "training_acc": 71.0, "val_loss": 0.6733001041412353, "val_acc": 52.0}
{"epoch": 45, "training_loss": 0.6622083759307862, "training_acc": 68.0, "val_loss": 0.6650939202308654, "val_acc": 52.0}
{"epoch": 46, "training_loss": 0.6617428016662598, "training_acc": 68.0, "val_loss": 0.6692949032783508, "val_acc": 52.0}
{"epoch": 47, "training_loss": 0.6617709946632385, "training_acc": 71.0, "val_loss": 0.6705482816696167, "val_acc": 56.0}
{"epoch": 48, "training_loss": 0.6594223999977111, "training_acc": 73.0, "val_loss": 0.6645491099357606, "val_acc": 60.0}
{"epoch": 49, "training_loss": 0.6603454351425171, "training_acc": 68.0, "val_loss": 0.6684140157699585, "val_acc": 56.0}
{"epoch": 50, "training_loss": 0.6674856233596802, "training_acc": 66.0, "val_loss": 0.6613286542892456, "val_acc": 64.0}
{"epoch": 51, "training_loss": 0.6647200489044189, "training_acc": 67.0, "val_loss": 0.668256230354309, "val_acc": 64.0}
{"epoch": 52, "training_loss": 0.6652129745483398, "training_acc": 66.0, "val_loss": 0.6626364994049072, "val_acc": 68.0}
{"epoch": 53, "training_loss": 0.6564751744270325, "training_acc": 71.0, "val_loss": 0.6634987735748291, "val_acc": 60.0}
{"epoch": 54, "training_loss": 0.6596556448936463, "training_acc": 77.0, "val_loss": 0.6648027372360229, "val_acc": 64.0}
{"epoch": 55, "training_loss": 0.6632972002029419, "training_acc": 74.0, "val_loss": 0.6574293446540832, "val_acc": 68.0}
{"epoch": 56, "training_loss": 0.6612906789779663, "training_acc": 68.0, "val_loss": 0.661440863609314, "val_acc": 72.0}
{"epoch": 57, "training_loss": 0.650318078994751, "training_acc": 74.0, "val_loss": 0.6646047902107238, "val_acc": 72.0}
{"epoch": 58, "training_loss": 0.6512946462631226, "training_acc": 73.0, "val_loss": 0.6561308598518372, "val_acc": 68.0}
{"epoch": 59, "training_loss": 0.6590251207351685, "training_acc": 67.0, "val_loss": 0.6633350896835327, "val_acc": 68.0}
{"epoch": 60, "training_loss": 0.6511169528961182, "training_acc": 76.0, "val_loss": 0.655303111076355, "val_acc": 68.0}
{"epoch": 61, "training_loss": 0.6547989320755004, "training_acc": 67.0, "val_loss": 0.6644660878181458, "val_acc": 64.0}
{"epoch": 62, "training_loss": 0.6519437456130981, "training_acc": 77.0, "val_loss": 0.6547755408287048, "val_acc": 68.0}
{"epoch": 63, "training_loss": 0.6563615727424622, "training_acc": 67.0, "val_loss": 0.6618098020553589, "val_acc": 64.0}
{"epoch": 64, "training_loss": 0.6554823398590088, "training_acc": 73.0, "val_loss": 0.6602035212516785, "val_acc": 68.0}
{"epoch": 65, "training_loss": 0.6475954008102417, "training_acc": 73.0, "val_loss": 0.6570475459098816, "val_acc": 60.0}
{"epoch": 66, "training_loss": 0.6495851373672485, "training_acc": 76.0, "val_loss": 0.6648544073104858, "val_acc": 64.0}
{"epoch": 67, "training_loss": 0.6545698976516724, "training_acc": 71.0, "val_loss": 0.6542567205429077, "val_acc": 64.0}
{"epoch": 68, "training_loss": 0.6542017436027527, "training_acc": 70.0, "val_loss": 0.6569303154945374, "val_acc": 68.0}
{"epoch": 69, "training_loss": 0.6521460819244385, "training_acc": 72.0, "val_loss": 0.6541304898262024, "val_acc": 64.0}
{"epoch": 70, "training_loss": 0.6475841689109803, "training_acc": 71.0, "val_loss": 0.6583464169502258, "val_acc": 68.0}
{"epoch": 71, "training_loss": 0.6458613300323486, "training_acc": 72.0, "val_loss": 0.655768654346466, "val_acc": 64.0}
{"epoch": 72, "training_loss": 0.6554568672180175, "training_acc": 72.0, "val_loss": 0.6539858961105347, "val_acc": 64.0}
{"epoch": 73, "training_loss": 0.6453158783912659, "training_acc": 74.0, "val_loss": 0.6550859427452087, "val_acc": 68.0}
{"epoch": 74, "training_loss": 0.6419404935836792, "training_acc": 75.0, "val_loss": 0.6558198642730713, "val_acc": 68.0}
{"epoch": 75, "training_loss": 0.6416652107238769, "training_acc": 74.0, "val_loss": 0.6521198844909668, "val_acc": 64.0}
{"epoch": 76, "training_loss": 0.6507704448699951, "training_acc": 70.0, "val_loss": 0.6573746752738953, "val_acc": 72.0}
{"epoch": 77, "training_loss": 0.6576489019393921, "training_acc": 73.0, "val_loss": 0.6498731660842896, "val_acc": 72.0}
{"epoch": 78, "training_loss": 0.6542891693115235, "training_acc": 67.0, "val_loss": 0.6506527590751648, "val_acc": 72.0}
{"epoch": 79, "training_loss": 0.6473244428634644, "training_acc": 76.0, "val_loss": 0.6496511793136597, "val_acc": 80.0}
{"epoch": 80, "training_loss": 0.6457403993606567, "training_acc": 71.0, "val_loss": 0.6515717434883118, "val_acc": 76.0}
{"epoch": 81, "training_loss": 0.6414481353759766, "training_acc": 75.0, "val_loss": 0.6468748474121093, "val_acc": 68.0}
{"epoch": 82, "training_loss": 0.6407451367378235, "training_acc": 75.0, "val_loss": 0.6513899159431458, "val_acc": 84.0}
{"epoch": 83, "training_loss": 0.638635778427124, "training_acc": 77.0, "val_loss": 0.6546670889854431, "val_acc": 76.0}
{"epoch": 84, "training_loss": 0.6359027242660522, "training_acc": 77.0, "val_loss": 0.6450904440879822, "val_acc": 76.0}
{"epoch": 85, "training_loss": 0.6395250630378723, "training_acc": 74.0, "val_loss": 0.6529565834999085, "val_acc": 80.0}
{"epoch": 86, "training_loss": 0.6332673192024231, "training_acc": 77.0, "val_loss": 0.6491823887825012, "val_acc": 84.0}
{"epoch": 87, "training_loss": 0.6363962697982788, "training_acc": 75.0, "val_loss": 0.6480372929573059, "val_acc": 84.0}
{"epoch": 88, "training_loss": 0.6341896390914917, "training_acc": 75.0, "val_loss": 0.6577343630790711, "val_acc": 80.0}
{"epoch": 89, "training_loss": 0.6470020961761475, "training_acc": 75.0, "val_loss": 0.6423047041893005, "val_acc": 72.0}
{"epoch": 90, "training_loss": 0.6424210834503173, "training_acc": 77.0, "val_loss": 0.6462573409080505, "val_acc": 72.0}
{"epoch": 91, "training_loss": 0.6400085544586182, "training_acc": 70.0, "val_loss": 0.6549154281616211, "val_acc": 68.0}
{"epoch": 92, "training_loss": 0.6374977016448975, "training_acc": 75.0, "val_loss": 0.6455667805671692, "val_acc": 84.0}
{"epoch": 93, "training_loss": 0.6400674891471863, "training_acc": 72.0, "val_loss": 0.6510323143005371, "val_acc": 68.0}
{"epoch": 94, "training_loss": 0.6524782037734985, "training_acc": 66.0, "val_loss": 0.6492753338813781, "val_acc": 76.0}
{"epoch": 95, "training_loss": 0.6401902294158935, "training_acc": 75.0, "val_loss": 0.642160267829895, "val_acc": 72.0}
{"epoch": 96, "training_loss": 0.6332963466644287, "training_acc": 76.0, "val_loss": 0.648969156742096, "val_acc": 84.0}
{"epoch": 97, "training_loss": 0.6285623168945312, "training_acc": 75.0, "val_loss": 0.6451492810249329, "val_acc": 68.0}
{"epoch": 98, "training_loss": 0.6398239660263062, "training_acc": 77.0, "val_loss": 0.6453262042999267, "val_acc": 76.0}
{"epoch": 99, "training_loss": 0.6474496078491211, "training_acc": 68.0, "val_loss": 0.6368720960617066, "val_acc": 72.0}
