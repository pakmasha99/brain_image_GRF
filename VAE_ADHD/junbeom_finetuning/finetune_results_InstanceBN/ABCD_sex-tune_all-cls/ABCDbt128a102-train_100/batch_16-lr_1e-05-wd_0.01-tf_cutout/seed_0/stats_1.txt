"main_modify.py --pretrained_path /scratch/connectome/dyhan316/VAE_ADHD/barlowtwins/pretrain_results/ABCDbt128a102.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option BT_org --learning_rate 1e-5 --batch_size 16 --weight_decay 1e-2 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 0.6924670577049256, "training_acc": 57.0, "val_loss": 0.6907584691047668, "val_acc": 64.0}
{"epoch": 1, "training_loss": 0.6926938080787659, "training_acc": 57.0, "val_loss": 0.6900667524337769, "val_acc": 64.0}
{"epoch": 2, "training_loss": 0.6924564027786255, "training_acc": 53.0, "val_loss": 0.6932940769195557, "val_acc": 52.0}
{"epoch": 3, "training_loss": 0.6932675671577454, "training_acc": 46.0, "val_loss": 0.6925138568878174, "val_acc": 52.0}
{"epoch": 4, "training_loss": 0.6932128810882568, "training_acc": 51.0, "val_loss": 0.6923003125190735, "val_acc": 52.0}
{"epoch": 5, "training_loss": 0.69215829372406, "training_acc": 52.0, "val_loss": 0.692766797542572, "val_acc": 52.0}
{"epoch": 6, "training_loss": 0.6921670722961426, "training_acc": 53.0, "val_loss": 0.6917822289466858, "val_acc": 52.0}
{"epoch": 7, "training_loss": 0.6911159324645996, "training_acc": 53.0, "val_loss": 0.6907075595855713, "val_acc": 52.0}
{"epoch": 8, "training_loss": 0.6910826826095581, "training_acc": 53.0, "val_loss": 0.6914667248725891, "val_acc": 52.0}
{"epoch": 9, "training_loss": 0.6907043123245239, "training_acc": 53.0, "val_loss": 0.6907915782928467, "val_acc": 52.0}
{"epoch": 10, "training_loss": 0.6887911033630371, "training_acc": 53.0, "val_loss": 0.6899707913398743, "val_acc": 52.0}
{"epoch": 11, "training_loss": 0.6891522264480591, "training_acc": 53.0, "val_loss": 0.6898575949668885, "val_acc": 52.0}
{"epoch": 12, "training_loss": 0.6880169367790222, "training_acc": 53.0, "val_loss": 0.689284176826477, "val_acc": 52.0}
{"epoch": 13, "training_loss": 0.6882831883430481, "training_acc": 54.0, "val_loss": 0.6880783891677856, "val_acc": 52.0}
{"epoch": 14, "training_loss": 0.6877225112915039, "training_acc": 53.0, "val_loss": 0.6895232439041138, "val_acc": 52.0}
{"epoch": 15, "training_loss": 0.6873892641067505, "training_acc": 53.0, "val_loss": 0.6892351341247559, "val_acc": 52.0}
{"epoch": 16, "training_loss": 0.6873078203201294, "training_acc": 53.0, "val_loss": 0.6891587281227112, "val_acc": 52.0}
{"epoch": 17, "training_loss": 0.6863408279418945, "training_acc": 53.0, "val_loss": 0.6879079246520996, "val_acc": 52.0}
{"epoch": 18, "training_loss": 0.687662262916565, "training_acc": 53.0, "val_loss": 0.6887381434440613, "val_acc": 52.0}
{"epoch": 19, "training_loss": 0.6860837626457215, "training_acc": 53.0, "val_loss": 0.6891366767883301, "val_acc": 52.0}
{"epoch": 20, "training_loss": 0.6853360676765442, "training_acc": 53.0, "val_loss": 0.6866208386421203, "val_acc": 52.0}
{"epoch": 21, "training_loss": 0.688657112121582, "training_acc": 53.0, "val_loss": 0.6835479378700257, "val_acc": 52.0}
{"epoch": 22, "training_loss": 0.6884895992279053, "training_acc": 53.0, "val_loss": 0.6878327536582947, "val_acc": 52.0}
{"epoch": 23, "training_loss": 0.6856800746917725, "training_acc": 53.0, "val_loss": 0.6892568755149842, "val_acc": 52.0}
{"epoch": 24, "training_loss": 0.685950198173523, "training_acc": 53.0, "val_loss": 0.6882483029365539, "val_acc": 52.0}
{"epoch": 25, "training_loss": 0.6858707475662231, "training_acc": 53.0, "val_loss": 0.6847659659385681, "val_acc": 52.0}
{"epoch": 26, "training_loss": 0.6839777398109436, "training_acc": 53.0, "val_loss": 0.6905246376991272, "val_acc": 52.0}
{"epoch": 27, "training_loss": 0.6844602179527283, "training_acc": 53.0, "val_loss": 0.6844944000244141, "val_acc": 52.0}
{"epoch": 28, "training_loss": 0.6849485874176026, "training_acc": 53.0, "val_loss": 0.6850892758369446, "val_acc": 52.0}
{"epoch": 29, "training_loss": 0.6863418626785278, "training_acc": 53.0, "val_loss": 0.6891781044006348, "val_acc": 52.0}
{"epoch": 30, "training_loss": 0.6881314706802368, "training_acc": 52.0, "val_loss": 0.6935094499588013, "val_acc": 52.0}
{"epoch": 31, "training_loss": 0.6850520610809326, "training_acc": 53.0, "val_loss": 0.6805594229698181, "val_acc": 52.0}
{"epoch": 32, "training_loss": 0.6848373222351074, "training_acc": 53.0, "val_loss": 0.6884713864326477, "val_acc": 52.0}
{"epoch": 33, "training_loss": 0.6831439757347106, "training_acc": 53.0, "val_loss": 0.6872120761871338, "val_acc": 52.0}
{"epoch": 34, "training_loss": 0.6845708465576172, "training_acc": 53.0, "val_loss": 0.6904934740066528, "val_acc": 52.0}
{"epoch": 35, "training_loss": 0.6847367238998413, "training_acc": 53.0, "val_loss": 0.6844112420082092, "val_acc": 52.0}
{"epoch": 36, "training_loss": 0.6818267107009888, "training_acc": 56.0, "val_loss": 0.6858399343490601, "val_acc": 44.0}
{"epoch": 37, "training_loss": 0.6813697147369385, "training_acc": 55.0, "val_loss": 0.6842758679389953, "val_acc": 52.0}
{"epoch": 38, "training_loss": 0.6818542003631591, "training_acc": 53.0, "val_loss": 0.6853144812583923, "val_acc": 52.0}
{"epoch": 39, "training_loss": 0.6814301872253418, "training_acc": 53.0, "val_loss": 0.6838932371139527, "val_acc": 52.0}
{"epoch": 40, "training_loss": 0.6804502415657043, "training_acc": 59.0, "val_loss": 0.6856005811691284, "val_acc": 56.0}
{"epoch": 41, "training_loss": 0.6802759218215942, "training_acc": 58.0, "val_loss": 0.6826508712768554, "val_acc": 44.0}
{"epoch": 42, "training_loss": 0.6810815000534057, "training_acc": 53.0, "val_loss": 0.6869321513175964, "val_acc": 48.0}
{"epoch": 43, "training_loss": 0.678994538784027, "training_acc": 63.0, "val_loss": 0.6844795632362366, "val_acc": 48.0}
{"epoch": 44, "training_loss": 0.6829945850372314, "training_acc": 58.0, "val_loss": 0.6848320722579956, "val_acc": 48.0}
{"epoch": 45, "training_loss": 0.6789058756828308, "training_acc": 62.0, "val_loss": 0.6836195015907287, "val_acc": 48.0}
{"epoch": 46, "training_loss": 0.680210976600647, "training_acc": 57.0, "val_loss": 0.6882799601554871, "val_acc": 48.0}
{"epoch": 47, "training_loss": 0.6886059832572937, "training_acc": 52.0, "val_loss": 0.6956237030029296, "val_acc": 40.0}
{"epoch": 48, "training_loss": 0.6905860376358032, "training_acc": 53.0, "val_loss": 0.6914162063598632, "val_acc": 52.0}
{"epoch": 49, "training_loss": 0.6886218190193176, "training_acc": 54.0, "val_loss": 0.6860217118263244, "val_acc": 52.0}
{"epoch": 50, "training_loss": 0.691067852973938, "training_acc": 53.0, "val_loss": 0.6846180462837219, "val_acc": 52.0}
