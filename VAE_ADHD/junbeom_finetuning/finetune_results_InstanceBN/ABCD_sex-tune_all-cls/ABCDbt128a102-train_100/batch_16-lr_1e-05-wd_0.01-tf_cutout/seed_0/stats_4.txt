"main_modify.py --pretrained_path /scratch/connectome/dyhan316/VAE_ADHD/barlowtwins/pretrain_results/ABCDbt128a102.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option BT_org --learning_rate 1e-5 --batch_size 16 --weight_decay 1e-2 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 0.6919327116012574, "training_acc": 53.0, "val_loss": 0.6922728419303894, "val_acc": 52.0}
{"epoch": 1, "training_loss": 0.6924700975418091, "training_acc": 53.0, "val_loss": 0.6914766764640808, "val_acc": 52.0}
{"epoch": 2, "training_loss": 0.6913632583618164, "training_acc": 53.0, "val_loss": 0.693505368232727, "val_acc": 52.0}
{"epoch": 3, "training_loss": 0.6915717434883117, "training_acc": 53.0, "val_loss": 0.6910636639595031, "val_acc": 52.0}
{"epoch": 4, "training_loss": 0.6918692755699157, "training_acc": 53.0, "val_loss": 0.6911233615875244, "val_acc": 52.0}
{"epoch": 5, "training_loss": 0.6906880640983581, "training_acc": 53.0, "val_loss": 0.6900027322769166, "val_acc": 52.0}
{"epoch": 6, "training_loss": 0.6912282013893127, "training_acc": 53.0, "val_loss": 0.6914839172363281, "val_acc": 52.0}
{"epoch": 7, "training_loss": 0.6904421615600586, "training_acc": 53.0, "val_loss": 0.6920416641235352, "val_acc": 52.0}
{"epoch": 8, "training_loss": 0.6895989990234375, "training_acc": 53.0, "val_loss": 0.690761148929596, "val_acc": 52.0}
{"epoch": 9, "training_loss": 0.6892875671386719, "training_acc": 53.0, "val_loss": 0.6912817120552063, "val_acc": 52.0}
{"epoch": 10, "training_loss": 0.6895654487609864, "training_acc": 53.0, "val_loss": 0.6905862212181091, "val_acc": 52.0}
{"epoch": 11, "training_loss": 0.688549165725708, "training_acc": 53.0, "val_loss": 0.6892794156074524, "val_acc": 52.0}
{"epoch": 12, "training_loss": 0.6867232179641723, "training_acc": 53.0, "val_loss": 0.6885631275177002, "val_acc": 52.0}
{"epoch": 13, "training_loss": 0.687082941532135, "training_acc": 53.0, "val_loss": 0.6893950700759888, "val_acc": 52.0}
{"epoch": 14, "training_loss": 0.6866411209106446, "training_acc": 53.0, "val_loss": 0.6908647704124451, "val_acc": 52.0}
{"epoch": 15, "training_loss": 0.6887748694419861, "training_acc": 53.0, "val_loss": 0.6908657765388488, "val_acc": 52.0}
{"epoch": 16, "training_loss": 0.6894880270957947, "training_acc": 53.0, "val_loss": 0.6922065305709839, "val_acc": 52.0}
{"epoch": 17, "training_loss": 0.6896308708190918, "training_acc": 53.0, "val_loss": 0.6906262373924256, "val_acc": 52.0}
{"epoch": 18, "training_loss": 0.6886327171325684, "training_acc": 53.0, "val_loss": 0.6902778673171998, "val_acc": 52.0}
{"epoch": 19, "training_loss": 0.6868824386596679, "training_acc": 53.0, "val_loss": 0.6908431363105774, "val_acc": 52.0}
{"epoch": 20, "training_loss": 0.6871376156806945, "training_acc": 53.0, "val_loss": 0.6897399020195008, "val_acc": 52.0}
{"epoch": 21, "training_loss": 0.6867395639419556, "training_acc": 53.0, "val_loss": 0.6895664811134339, "val_acc": 52.0}
{"epoch": 22, "training_loss": 0.6843643236160278, "training_acc": 53.0, "val_loss": 0.6892901706695557, "val_acc": 52.0}
{"epoch": 23, "training_loss": 0.6865727472305297, "training_acc": 53.0, "val_loss": 0.6880129766464234, "val_acc": 52.0}
{"epoch": 24, "training_loss": 0.6845973610877991, "training_acc": 53.0, "val_loss": 0.6893157148361206, "val_acc": 52.0}
{"epoch": 25, "training_loss": 0.6836424350738526, "training_acc": 53.0, "val_loss": 0.6878489279747009, "val_acc": 52.0}
{"epoch": 26, "training_loss": 0.6844555044174194, "training_acc": 53.0, "val_loss": 0.6879616999626159, "val_acc": 52.0}
{"epoch": 27, "training_loss": 0.6826445508003235, "training_acc": 53.0, "val_loss": 0.6884637379646301, "val_acc": 52.0}
{"epoch": 28, "training_loss": 0.6811671996116638, "training_acc": 53.0, "val_loss": 0.6868006896972656, "val_acc": 52.0}
{"epoch": 29, "training_loss": 0.6797213411331177, "training_acc": 53.0, "val_loss": 0.6862720179557801, "val_acc": 52.0}
{"epoch": 30, "training_loss": 0.678989233970642, "training_acc": 54.0, "val_loss": 0.6876941394805908, "val_acc": 52.0}
{"epoch": 31, "training_loss": 0.6772955846786499, "training_acc": 55.0, "val_loss": 0.6866977787017823, "val_acc": 52.0}
{"epoch": 32, "training_loss": 0.6758789992332459, "training_acc": 57.0, "val_loss": 0.6859719204902649, "val_acc": 52.0}
{"epoch": 33, "training_loss": 0.6760085654258728, "training_acc": 57.0, "val_loss": 0.6851893901824951, "val_acc": 52.0}
{"epoch": 34, "training_loss": 0.6740850210189819, "training_acc": 59.0, "val_loss": 0.6844627237319947, "val_acc": 56.0}
{"epoch": 35, "training_loss": 0.6719789600372315, "training_acc": 60.0, "val_loss": 0.6858875632286072, "val_acc": 52.0}
{"epoch": 36, "training_loss": 0.6744092226028442, "training_acc": 57.0, "val_loss": 0.6843482613563537, "val_acc": 56.0}
{"epoch": 37, "training_loss": 0.671011974811554, "training_acc": 62.0, "val_loss": 0.6841129398345948, "val_acc": 52.0}
{"epoch": 38, "training_loss": 0.6719122576713562, "training_acc": 62.0, "val_loss": 0.6837570524215698, "val_acc": 52.0}
{"epoch": 39, "training_loss": 0.6710048723220825, "training_acc": 63.0, "val_loss": 0.6843172931671142, "val_acc": 52.0}
{"epoch": 40, "training_loss": 0.6695743036270142, "training_acc": 62.0, "val_loss": 0.6834728670120239, "val_acc": 52.0}
{"epoch": 41, "training_loss": 0.6694462084770203, "training_acc": 62.0, "val_loss": 0.6842691731452942, "val_acc": 52.0}
{"epoch": 42, "training_loss": 0.6683492875099182, "training_acc": 62.0, "val_loss": 0.6805357670783997, "val_acc": 56.0}
{"epoch": 43, "training_loss": 0.6743305015563965, "training_acc": 61.0, "val_loss": 0.6856442379951477, "val_acc": 52.0}
{"epoch": 44, "training_loss": 0.6740394496917724, "training_acc": 58.0, "val_loss": 0.6816286849975586, "val_acc": 56.0}
{"epoch": 45, "training_loss": 0.6714900279045105, "training_acc": 61.0, "val_loss": 0.683537847995758, "val_acc": 52.0}
{"epoch": 46, "training_loss": 0.6693387603759766, "training_acc": 60.0, "val_loss": 0.682126431465149, "val_acc": 56.0}
{"epoch": 47, "training_loss": 0.6672632908821106, "training_acc": 62.0, "val_loss": 0.6842696762084961, "val_acc": 52.0}
{"epoch": 48, "training_loss": 0.6668384480476379, "training_acc": 60.0, "val_loss": 0.6824025654792786, "val_acc": 56.0}
{"epoch": 49, "training_loss": 0.6657033133506775, "training_acc": 59.0, "val_loss": 0.6820828366279602, "val_acc": 56.0}
{"epoch": 50, "training_loss": 0.6717844438552857, "training_acc": 59.0, "val_loss": 0.6829811692237854, "val_acc": 56.0}
{"epoch": 51, "training_loss": 0.679447340965271, "training_acc": 54.0, "val_loss": 0.6830271530151367, "val_acc": 56.0}
{"epoch": 52, "training_loss": 0.6681402206420899, "training_acc": 60.0, "val_loss": 0.6844880509376526, "val_acc": 52.0}
{"epoch": 53, "training_loss": 0.6675349354743958, "training_acc": 62.0, "val_loss": 0.6832372450828552, "val_acc": 52.0}
{"epoch": 54, "training_loss": 0.6633306217193603, "training_acc": 59.0, "val_loss": 0.6810813927650452, "val_acc": 56.0}
{"epoch": 55, "training_loss": 0.6658234405517578, "training_acc": 61.0, "val_loss": 0.6831172156333923, "val_acc": 52.0}
{"epoch": 56, "training_loss": 0.6636942291259765, "training_acc": 62.0, "val_loss": 0.6791416668891906, "val_acc": 56.0}
{"epoch": 57, "training_loss": 0.6618207716941833, "training_acc": 64.0, "val_loss": 0.6793016958236694, "val_acc": 56.0}
{"epoch": 58, "training_loss": 0.6604109573364257, "training_acc": 65.0, "val_loss": 0.6838547205924987, "val_acc": 60.0}
{"epoch": 59, "training_loss": 0.661477017402649, "training_acc": 64.0, "val_loss": 0.6812699961662293, "val_acc": 56.0}
{"epoch": 60, "training_loss": 0.6643854784965515, "training_acc": 65.0, "val_loss": 0.6794716095924378, "val_acc": 52.0}
{"epoch": 61, "training_loss": 0.6641580152511597, "training_acc": 63.0, "val_loss": 0.6798048424720764, "val_acc": 64.0}
{"epoch": 62, "training_loss": 0.6645714974403382, "training_acc": 68.0, "val_loss": 0.6781060719490051, "val_acc": 56.0}
{"epoch": 63, "training_loss": 0.659668595790863, "training_acc": 69.0, "val_loss": 0.679333221912384, "val_acc": 60.0}
{"epoch": 64, "training_loss": 0.6590278100967407, "training_acc": 71.0, "val_loss": 0.6784816408157348, "val_acc": 68.0}
{"epoch": 65, "training_loss": 0.660899875164032, "training_acc": 70.0, "val_loss": 0.681049816608429, "val_acc": 56.0}
{"epoch": 66, "training_loss": 0.6603549599647522, "training_acc": 66.0, "val_loss": 0.6745996379852295, "val_acc": 60.0}
{"epoch": 67, "training_loss": 0.6635267019271851, "training_acc": 66.0, "val_loss": 0.6819864273071289, "val_acc": 64.0}
{"epoch": 68, "training_loss": 0.6629625129699707, "training_acc": 63.0, "val_loss": 0.6798180937767029, "val_acc": 60.0}
{"epoch": 69, "training_loss": 0.6639229655265808, "training_acc": 64.0, "val_loss": 0.6751155519485473, "val_acc": 56.0}
{"epoch": 70, "training_loss": 0.6572326040267944, "training_acc": 68.0, "val_loss": 0.6801583099365235, "val_acc": 60.0}
{"epoch": 71, "training_loss": 0.6545975732803345, "training_acc": 72.0, "val_loss": 0.6752846407890319, "val_acc": 60.0}
{"epoch": 72, "training_loss": 0.6575275301933289, "training_acc": 65.0, "val_loss": 0.6781909370422363, "val_acc": 56.0}
{"epoch": 73, "training_loss": 0.6542409753799439, "training_acc": 71.0, "val_loss": 0.6727502751350403, "val_acc": 60.0}
{"epoch": 74, "training_loss": 0.6499149298667908, "training_acc": 73.0, "val_loss": 0.6760458707809448, "val_acc": 60.0}
{"epoch": 75, "training_loss": 0.6529133176803589, "training_acc": 72.0, "val_loss": 0.6733573102951049, "val_acc": 60.0}
{"epoch": 76, "training_loss": 0.6534215331077575, "training_acc": 67.0, "val_loss": 0.675621349811554, "val_acc": 56.0}
{"epoch": 77, "training_loss": 0.6513430047035217, "training_acc": 72.0, "val_loss": 0.6799894762039185, "val_acc": 64.0}
{"epoch": 78, "training_loss": 0.649811065196991, "training_acc": 71.0, "val_loss": 0.6737231397628785, "val_acc": 60.0}
{"epoch": 79, "training_loss": 0.6467786407470704, "training_acc": 73.0, "val_loss": 0.6749884605407714, "val_acc": 60.0}
{"epoch": 80, "training_loss": 0.6496073627471923, "training_acc": 70.0, "val_loss": 0.6761507916450501, "val_acc": 60.0}
{"epoch": 81, "training_loss": 0.652081298828125, "training_acc": 69.0, "val_loss": 0.672695918083191, "val_acc": 60.0}
{"epoch": 82, "training_loss": 0.646818401813507, "training_acc": 75.0, "val_loss": 0.673166229724884, "val_acc": 56.0}
{"epoch": 83, "training_loss": 0.6496532154083252, "training_acc": 70.0, "val_loss": 0.6774486708641052, "val_acc": 60.0}
{"epoch": 84, "training_loss": 0.647498893737793, "training_acc": 74.0, "val_loss": 0.6722319459915161, "val_acc": 60.0}
{"epoch": 85, "training_loss": 0.6511761355400085, "training_acc": 71.0, "val_loss": 0.6794344806671142, "val_acc": 48.0}
{"epoch": 86, "training_loss": 0.6491969394683837, "training_acc": 71.0, "val_loss": 0.6702687382698059, "val_acc": 64.0}
{"epoch": 87, "training_loss": 0.6496910953521728, "training_acc": 72.0, "val_loss": 0.6771292948722839, "val_acc": 60.0}
{"epoch": 88, "training_loss": 0.6491566133499146, "training_acc": 72.0, "val_loss": 0.6689928722381592, "val_acc": 64.0}
{"epoch": 89, "training_loss": 0.6483433866500854, "training_acc": 69.0, "val_loss": 0.6778962349891663, "val_acc": 52.0}
{"epoch": 90, "training_loss": 0.6488991737365722, "training_acc": 72.0, "val_loss": 0.6719359230995178, "val_acc": 56.0}
{"epoch": 91, "training_loss": 0.6465754652023316, "training_acc": 73.0, "val_loss": 0.6725167012214661, "val_acc": 60.0}
{"epoch": 92, "training_loss": 0.6485324001312256, "training_acc": 76.0, "val_loss": 0.6782820844650268, "val_acc": 60.0}
{"epoch": 93, "training_loss": 0.6498532915115356, "training_acc": 70.0, "val_loss": 0.6754586577415467, "val_acc": 52.0}
{"epoch": 94, "training_loss": 0.6463097953796386, "training_acc": 74.0, "val_loss": 0.6743461441993713, "val_acc": 60.0}
{"epoch": 95, "training_loss": 0.6528750562667847, "training_acc": 74.0, "val_loss": 0.6732645654678344, "val_acc": 64.0}
{"epoch": 96, "training_loss": 0.6508545041084289, "training_acc": 71.0, "val_loss": 0.6706379008293152, "val_acc": 60.0}
{"epoch": 97, "training_loss": 0.6508032727241516, "training_acc": 74.0, "val_loss": 0.669277286529541, "val_acc": 68.0}
{"epoch": 98, "training_loss": 0.645338351726532, "training_acc": 74.0, "val_loss": 0.6720617532730102, "val_acc": 56.0}
{"epoch": 99, "training_loss": 0.6403451013565064, "training_acc": 74.0, "val_loss": 0.6729626536369324, "val_acc": 60.0}
