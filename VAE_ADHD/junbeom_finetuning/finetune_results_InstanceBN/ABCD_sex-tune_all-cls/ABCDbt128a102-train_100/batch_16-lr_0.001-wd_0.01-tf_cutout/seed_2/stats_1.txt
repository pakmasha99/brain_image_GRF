"main_modify.py --pretrained_path /scratch/connectome/dyhan316/VAE_ADHD/barlowtwins/pretrain_results/ABCDbt128a102.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 2 --task ABCD_sex --input_option BT_org --learning_rate 1e-3 --batch_size 16 --weight_decay 1e-2 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 0.700327935218811, "training_acc": 53.0, "val_loss": 0.6952656292915345, "val_acc": 48.0}
{"epoch": 1, "training_loss": 0.701893835067749, "training_acc": 47.0, "val_loss": 0.6960721898078919, "val_acc": 52.0}
{"epoch": 2, "training_loss": 0.7211731672286987, "training_acc": 53.0, "val_loss": 0.6970655250549317, "val_acc": 52.0}
{"epoch": 3, "training_loss": 0.6969547080993652, "training_acc": 47.0, "val_loss": 0.6938195371627808, "val_acc": 48.0}
{"epoch": 4, "training_loss": 0.6953209686279297, "training_acc": 45.0, "val_loss": 0.6929629254341125, "val_acc": 56.0}
{"epoch": 5, "training_loss": 0.701518177986145, "training_acc": 49.0, "val_loss": 0.6967129230499267, "val_acc": 52.0}
{"epoch": 6, "training_loss": 0.7071581006050109, "training_acc": 53.0, "val_loss": 0.692621762752533, "val_acc": 52.0}
{"epoch": 7, "training_loss": 0.7066969799995423, "training_acc": 43.0, "val_loss": 0.6957848334312439, "val_acc": 48.0}
{"epoch": 8, "training_loss": 0.7009653425216675, "training_acc": 45.0, "val_loss": 0.6924550294876098, "val_acc": 52.0}
{"epoch": 9, "training_loss": 0.7038193535804749, "training_acc": 47.0, "val_loss": 0.696690468788147, "val_acc": 52.0}
{"epoch": 10, "training_loss": 0.7000404357910156, "training_acc": 53.0, "val_loss": 0.7027093100547791, "val_acc": 52.0}
{"epoch": 11, "training_loss": 0.6991716265678406, "training_acc": 53.0, "val_loss": 0.6937718200683594, "val_acc": 52.0}
{"epoch": 12, "training_loss": 0.6999275398254394, "training_acc": 53.0, "val_loss": 0.6930939412117004, "val_acc": 52.0}
{"epoch": 13, "training_loss": 0.702159423828125, "training_acc": 49.0, "val_loss": 0.6938339138031006, "val_acc": 52.0}
{"epoch": 14, "training_loss": 0.7001407718658448, "training_acc": 53.0, "val_loss": 0.7007464146614075, "val_acc": 52.0}
{"epoch": 15, "training_loss": 0.707470338344574, "training_acc": 43.0, "val_loss": 0.6935230278968811, "val_acc": 52.0}
{"epoch": 16, "training_loss": 0.695520396232605, "training_acc": 53.0, "val_loss": 0.7030995631217957, "val_acc": 52.0}
{"epoch": 17, "training_loss": 0.6914797878265381, "training_acc": 53.0, "val_loss": 0.6983624386787415, "val_acc": 48.0}
{"epoch": 18, "training_loss": 0.7246872758865357, "training_acc": 47.0, "val_loss": 0.7055035424232483, "val_acc": 48.0}
{"epoch": 19, "training_loss": 0.7126960611343384, "training_acc": 43.0, "val_loss": 0.6935516405105591, "val_acc": 52.0}
{"epoch": 20, "training_loss": 0.7009867429733276, "training_acc": 53.0, "val_loss": 0.6932863306999206, "val_acc": 48.0}
{"epoch": 21, "training_loss": 0.6990672636032105, "training_acc": 47.0, "val_loss": 0.6961856985092163, "val_acc": 48.0}
{"epoch": 22, "training_loss": 0.6956080198287964, "training_acc": 51.0, "val_loss": 0.6954678964614868, "val_acc": 52.0}
{"epoch": 23, "training_loss": 0.726192855834961, "training_acc": 53.0, "val_loss": 0.6923540115356446, "val_acc": 52.0}
{"epoch": 24, "training_loss": 0.693803699016571, "training_acc": 53.0, "val_loss": 0.6953650164604187, "val_acc": 48.0}
{"epoch": 25, "training_loss": 0.6936590671539307, "training_acc": 55.0, "val_loss": 0.7002591633796692, "val_acc": 52.0}
{"epoch": 26, "training_loss": 0.7071498012542725, "training_acc": 53.0, "val_loss": 0.6981473183631897, "val_acc": 52.0}
{"epoch": 27, "training_loss": 0.7019887018203735, "training_acc": 53.0, "val_loss": 0.6923893785476685, "val_acc": 52.0}
{"epoch": 28, "training_loss": 0.6989254474639892, "training_acc": 53.0, "val_loss": 0.6923516201972961, "val_acc": 52.0}
{"epoch": 29, "training_loss": 0.7029368209838868, "training_acc": 53.0, "val_loss": 0.692432987689972, "val_acc": 52.0}
{"epoch": 30, "training_loss": 0.7106410121917724, "training_acc": 47.0, "val_loss": 0.6924480056762695, "val_acc": 52.0}
{"epoch": 31, "training_loss": 0.6938984918594361, "training_acc": 53.0, "val_loss": 0.6967889285087585, "val_acc": 52.0}
{"epoch": 32, "training_loss": 0.6941382932662964, "training_acc": 53.0, "val_loss": 0.6925812172889709, "val_acc": 52.0}
{"epoch": 33, "training_loss": 0.7053031826019287, "training_acc": 53.0, "val_loss": 0.6925226664543152, "val_acc": 52.0}
{"epoch": 34, "training_loss": 0.6938587951660157, "training_acc": 53.0, "val_loss": 0.6978877878189087, "val_acc": 48.0}
{"epoch": 35, "training_loss": 0.7038060760498047, "training_acc": 47.0, "val_loss": 0.7005859255790711, "val_acc": 48.0}
{"epoch": 36, "training_loss": 0.7050321817398071, "training_acc": 49.0, "val_loss": 0.6950220704078675, "val_acc": 52.0}
{"epoch": 37, "training_loss": 0.7026720094680786, "training_acc": 53.0, "val_loss": 0.7027179884910584, "val_acc": 52.0}
{"epoch": 38, "training_loss": 0.7012243700027466, "training_acc": 53.0, "val_loss": 0.6944304275512695, "val_acc": 52.0}
{"epoch": 39, "training_loss": 0.7003087472915649, "training_acc": 53.0, "val_loss": 0.6927717161178589, "val_acc": 52.0}
{"epoch": 40, "training_loss": 0.7055377769470215, "training_acc": 43.0, "val_loss": 0.6971953320503235, "val_acc": 48.0}
{"epoch": 41, "training_loss": 0.6983558416366578, "training_acc": 47.0, "val_loss": 0.6925940203666687, "val_acc": 52.0}
{"epoch": 42, "training_loss": 0.7001017904281617, "training_acc": 43.0, "val_loss": 0.6935141062736512, "val_acc": 52.0}
{"epoch": 43, "training_loss": 0.7023350954055786, "training_acc": 53.0, "val_loss": 0.7025362777709961, "val_acc": 52.0}
{"epoch": 44, "training_loss": 0.71363938331604, "training_acc": 53.0, "val_loss": 0.6973291659355163, "val_acc": 52.0}
{"epoch": 45, "training_loss": 0.6961571979522705, "training_acc": 53.0, "val_loss": 0.6927862548828125, "val_acc": 52.0}
{"epoch": 46, "training_loss": 0.700817506313324, "training_acc": 53.0, "val_loss": 0.6927918434143067, "val_acc": 52.0}
{"epoch": 47, "training_loss": 0.6940746879577637, "training_acc": 49.0, "val_loss": 0.6961071634292603, "val_acc": 52.0}
