"main_modify.py --pretrained_path /scratch/connectome/dyhan316/VAE_ADHD/barlowtwins/pretrain_results/ABCDbt128a102.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option BT_org --learning_rate 1e-3 --batch_size 16 --weight_decay 1e-2 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 0.7225533366203308, "training_acc": 51.0, "val_loss": 0.6946110653877259, "val_acc": 52.0}
{"epoch": 1, "training_loss": 0.7091186332702637, "training_acc": 45.0, "val_loss": 0.6996363854408264, "val_acc": 48.0}
{"epoch": 2, "training_loss": 0.7074318790435791, "training_acc": 39.0, "val_loss": 0.692634665966034, "val_acc": 52.0}
{"epoch": 3, "training_loss": 0.7110026216506958, "training_acc": 53.0, "val_loss": 0.6924480962753295, "val_acc": 52.0}
{"epoch": 4, "training_loss": 0.694923620223999, "training_acc": 49.0, "val_loss": 0.6974432277679443, "val_acc": 52.0}
{"epoch": 5, "training_loss": 0.7076972818374634, "training_acc": 53.0, "val_loss": 0.6938264775276184, "val_acc": 52.0}
{"epoch": 6, "training_loss": 0.6938653802871704, "training_acc": 53.0, "val_loss": 0.6957784008979797, "val_acc": 48.0}
{"epoch": 7, "training_loss": 0.7092971134185792, "training_acc": 47.0, "val_loss": 0.6924947667121887, "val_acc": 52.0}
{"epoch": 8, "training_loss": 0.6946287488937378, "training_acc": 53.0, "val_loss": 0.7013823771476746, "val_acc": 52.0}
{"epoch": 9, "training_loss": 0.7055381488800049, "training_acc": 53.0, "val_loss": 0.6940901851654053, "val_acc": 48.0}
{"epoch": 10, "training_loss": 0.7279512906074523, "training_acc": 47.0, "val_loss": 0.6926002955436706, "val_acc": 52.0}
{"epoch": 11, "training_loss": 0.7022394657135009, "training_acc": 53.0, "val_loss": 0.6972271347045899, "val_acc": 52.0}
{"epoch": 12, "training_loss": 0.7116217803955078, "training_acc": 41.0, "val_loss": 0.6923711514472961, "val_acc": 52.0}
{"epoch": 13, "training_loss": 0.6915144872665405, "training_acc": 53.0, "val_loss": 0.6959739232063293, "val_acc": 52.0}
{"epoch": 14, "training_loss": 0.6988498711585999, "training_acc": 53.0, "val_loss": 0.6927128314971924, "val_acc": 52.0}
{"epoch": 15, "training_loss": 0.7010282802581788, "training_acc": 43.0, "val_loss": 0.6924626541137695, "val_acc": 52.0}
{"epoch": 16, "training_loss": 0.695732307434082, "training_acc": 53.0, "val_loss": 0.695143711566925, "val_acc": 52.0}
{"epoch": 17, "training_loss": 0.6987735462188721, "training_acc": 53.0, "val_loss": 0.692743272781372, "val_acc": 52.0}
{"epoch": 18, "training_loss": 0.7028595352172852, "training_acc": 43.0, "val_loss": 0.6925213003158569, "val_acc": 52.0}
{"epoch": 19, "training_loss": 0.6931633067131042, "training_acc": 53.0, "val_loss": 0.7027419996261597, "val_acc": 52.0}
{"epoch": 20, "training_loss": 0.7077692770957946, "training_acc": 53.0, "val_loss": 0.7017141032218933, "val_acc": 52.0}
{"epoch": 21, "training_loss": 0.6942708206176758, "training_acc": 53.0, "val_loss": 0.6931219935417176, "val_acc": 52.0}
{"epoch": 22, "training_loss": 0.6999749231338501, "training_acc": 43.0, "val_loss": 0.6930725407600403, "val_acc": 52.0}
{"epoch": 23, "training_loss": 0.6975457525253296, "training_acc": 53.0, "val_loss": 0.6923508477210999, "val_acc": 52.0}
{"epoch": 24, "training_loss": 0.6973896789550781, "training_acc": 47.0, "val_loss": 0.6939503455162048, "val_acc": 52.0}
{"epoch": 25, "training_loss": 0.7007931327819824, "training_acc": 53.0, "val_loss": 0.6949683380126953, "val_acc": 52.0}
{"epoch": 26, "training_loss": 0.692330515384674, "training_acc": 53.0, "val_loss": 0.6929306840896606, "val_acc": 52.0}
{"epoch": 27, "training_loss": 0.701268174648285, "training_acc": 53.0, "val_loss": 0.6938107419013977, "val_acc": 48.0}
{"epoch": 28, "training_loss": 0.7013170528411865, "training_acc": 47.0, "val_loss": 0.6924036359786987, "val_acc": 52.0}
{"epoch": 29, "training_loss": 0.7076506519317627, "training_acc": 53.0, "val_loss": 0.6950046515464783, "val_acc": 52.0}
{"epoch": 30, "training_loss": 0.6932389450073242, "training_acc": 53.0, "val_loss": 0.6937413477897644, "val_acc": 48.0}
{"epoch": 31, "training_loss": 0.6977363896369934, "training_acc": 41.0, "val_loss": 0.6985490107536316, "val_acc": 48.0}
{"epoch": 32, "training_loss": 0.7023782014846802, "training_acc": 47.0, "val_loss": 0.692686333656311, "val_acc": 52.0}
{"epoch": 33, "training_loss": 0.6978889107704163, "training_acc": 53.0, "val_loss": 0.7005749058723449, "val_acc": 52.0}
{"epoch": 34, "training_loss": 0.6972872352600098, "training_acc": 49.0, "val_loss": 0.6928368759155273, "val_acc": 52.0}
{"epoch": 35, "training_loss": 0.7002300882339477, "training_acc": 45.0, "val_loss": 0.6931036114692688, "val_acc": 52.0}
{"epoch": 36, "training_loss": 0.6929602503776551, "training_acc": 53.0, "val_loss": 0.6931316065788269, "val_acc": 52.0}
{"epoch": 37, "training_loss": 0.6989818334579467, "training_acc": 53.0, "val_loss": 0.6931151509284973, "val_acc": 52.0}
{"epoch": 38, "training_loss": 0.6955689430236817, "training_acc": 53.0, "val_loss": 0.692715528011322, "val_acc": 52.0}
{"epoch": 39, "training_loss": 0.6953165483474731, "training_acc": 53.0, "val_loss": 0.6936414122581482, "val_acc": 52.0}
{"epoch": 40, "training_loss": 0.69638090133667, "training_acc": 53.0, "val_loss": 0.6936108851432801, "val_acc": 52.0}
{"epoch": 41, "training_loss": 0.6963730049133301, "training_acc": 53.0, "val_loss": 0.6928900504112243, "val_acc": 52.0}
{"epoch": 42, "training_loss": 0.6966905403137207, "training_acc": 51.0, "val_loss": 0.6940272307395935, "val_acc": 48.0}
