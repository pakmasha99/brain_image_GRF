"main_modify.py --pretrained_path /scratch/connectome/dyhan316/VAE_ADHD/barlowtwins/pretrain_results/ABCDbt128a102.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option BT_org --learning_rate 1e-3 --batch_size 16 --weight_decay 1e-2 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 0.7181915378570557, "training_acc": 51.0, "val_loss": 0.6944026613235473, "val_acc": 48.0}
{"epoch": 1, "training_loss": 0.6987402820587159, "training_acc": 41.0, "val_loss": 0.6923519229888916, "val_acc": 52.0}
{"epoch": 2, "training_loss": 0.6973119950294495, "training_acc": 53.0, "val_loss": 0.6985492277145385, "val_acc": 52.0}
{"epoch": 3, "training_loss": 0.7166998171806336, "training_acc": 53.0, "val_loss": 0.7014226603507996, "val_acc": 52.0}
{"epoch": 4, "training_loss": 0.7057729530334472, "training_acc": 53.0, "val_loss": 0.6931919741630554, "val_acc": 48.0}
{"epoch": 5, "training_loss": 0.6939914345741272, "training_acc": 48.0, "val_loss": 0.714148817062378, "val_acc": 48.0}
{"epoch": 6, "training_loss": 0.7145947599411011, "training_acc": 43.0, "val_loss": 0.6928224277496338, "val_acc": 52.0}
{"epoch": 7, "training_loss": 0.6932757759094238, "training_acc": 53.0, "val_loss": 0.6971470403671265, "val_acc": 52.0}
{"epoch": 8, "training_loss": 0.728129324913025, "training_acc": 53.0, "val_loss": 0.6971654200553894, "val_acc": 52.0}
{"epoch": 9, "training_loss": 0.7134129238128663, "training_acc": 43.0, "val_loss": 0.6946077728271485, "val_acc": 48.0}
{"epoch": 10, "training_loss": 0.69808354139328, "training_acc": 43.0, "val_loss": 0.6925782084465026, "val_acc": 52.0}
{"epoch": 11, "training_loss": 0.700487322807312, "training_acc": 51.0, "val_loss": 0.6925051045417786, "val_acc": 52.0}
{"epoch": 12, "training_loss": 0.6979557991027832, "training_acc": 53.0, "val_loss": 0.6926395869255066, "val_acc": 52.0}
{"epoch": 13, "training_loss": 0.6918959856033325, "training_acc": 53.0, "val_loss": 0.6957122468948365, "val_acc": 48.0}
{"epoch": 14, "training_loss": 0.706433892250061, "training_acc": 45.0, "val_loss": 0.6944029188156128, "val_acc": 48.0}
{"epoch": 15, "training_loss": 0.6968738389015198, "training_acc": 49.0, "val_loss": 0.6924213528633117, "val_acc": 52.0}
{"epoch": 16, "training_loss": 0.6939002251625062, "training_acc": 53.0, "val_loss": 0.6936200714111328, "val_acc": 52.0}
{"epoch": 17, "training_loss": 0.7003535985946655, "training_acc": 53.0, "val_loss": 0.6923492813110351, "val_acc": 52.0}
{"epoch": 18, "training_loss": 0.6980677604675293, "training_acc": 45.0, "val_loss": 0.6924097800254821, "val_acc": 52.0}
{"epoch": 19, "training_loss": 0.6995715284347535, "training_acc": 53.0, "val_loss": 0.6937730550765991, "val_acc": 52.0}
{"epoch": 20, "training_loss": 0.7001350402832032, "training_acc": 51.0, "val_loss": 0.6923663258552551, "val_acc": 52.0}
{"epoch": 21, "training_loss": 0.7042781257629395, "training_acc": 53.0, "val_loss": 0.7064085483551026, "val_acc": 52.0}
{"epoch": 22, "training_loss": 0.7092975854873658, "training_acc": 53.0, "val_loss": 0.6956773114204406, "val_acc": 52.0}
{"epoch": 23, "training_loss": 0.7074767017364502, "training_acc": 45.0, "val_loss": 0.6998039364814759, "val_acc": 52.0}
{"epoch": 24, "training_loss": 0.7012933588027954, "training_acc": 53.0, "val_loss": 0.7052921867370605, "val_acc": 52.0}
{"epoch": 25, "training_loss": 0.6976933336257934, "training_acc": 53.0, "val_loss": 0.6933356046676635, "val_acc": 48.0}
{"epoch": 26, "training_loss": 0.699607949256897, "training_acc": 49.0, "val_loss": 0.6935702157020569, "val_acc": 52.0}
{"epoch": 27, "training_loss": 0.6929963064193726, "training_acc": 53.0, "val_loss": 0.6923586225509644, "val_acc": 52.0}
{"epoch": 28, "training_loss": 0.696578540802002, "training_acc": 41.0, "val_loss": 0.6925826382637024, "val_acc": 52.0}
{"epoch": 29, "training_loss": 0.6923768377304077, "training_acc": 53.0, "val_loss": 0.6944611978530884, "val_acc": 52.0}
{"epoch": 30, "training_loss": 0.6972194576263427, "training_acc": 53.0, "val_loss": 0.6923672151565552, "val_acc": 52.0}
{"epoch": 31, "training_loss": 0.699958257675171, "training_acc": 47.0, "val_loss": 0.6926995444297791, "val_acc": 52.0}
{"epoch": 32, "training_loss": 0.7121854877471924, "training_acc": 53.0, "val_loss": 0.6964454555511475, "val_acc": 52.0}
{"epoch": 33, "training_loss": 0.7040313386917114, "training_acc": 43.0, "val_loss": 0.6928812003135681, "val_acc": 52.0}
{"epoch": 34, "training_loss": 0.6991462087631226, "training_acc": 45.0, "val_loss": 0.6929342365264892, "val_acc": 52.0}
{"epoch": 35, "training_loss": 0.7003133821487427, "training_acc": 51.0, "val_loss": 0.6941140151023865, "val_acc": 48.0}
{"epoch": 36, "training_loss": 0.6948713326454162, "training_acc": 49.0, "val_loss": 0.692480320930481, "val_acc": 52.0}
