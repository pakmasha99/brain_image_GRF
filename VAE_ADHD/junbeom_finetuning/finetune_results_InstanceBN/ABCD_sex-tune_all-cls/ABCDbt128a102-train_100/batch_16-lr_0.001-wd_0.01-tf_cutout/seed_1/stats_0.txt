"main_modify.py --pretrained_path /scratch/connectome/dyhan316/VAE_ADHD/barlowtwins/pretrain_results/ABCDbt128a102.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 1 --task ABCD_sex --input_option BT_org --learning_rate 1e-3 --batch_size 16 --weight_decay 1e-2 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 0.7080596256256103, "training_acc": 48.0, "val_loss": 0.7066727399826049, "val_acc": 52.0}
{"epoch": 1, "training_loss": 0.7204488325119018, "training_acc": 53.0, "val_loss": 0.7116643166542054, "val_acc": 52.0}
{"epoch": 2, "training_loss": 0.7054051423072815, "training_acc": 53.0, "val_loss": 0.694211540222168, "val_acc": 52.0}
{"epoch": 3, "training_loss": 0.7059392833709717, "training_acc": 41.0, "val_loss": 0.6926707458496094, "val_acc": 52.0}
{"epoch": 4, "training_loss": 0.697916431427002, "training_acc": 45.0, "val_loss": 0.6974400281906128, "val_acc": 52.0}
{"epoch": 5, "training_loss": 0.7107411217689514, "training_acc": 53.0, "val_loss": 0.6984065747261048, "val_acc": 52.0}
{"epoch": 6, "training_loss": 0.6997121691703796, "training_acc": 53.0, "val_loss": 0.6945645833015441, "val_acc": 48.0}
{"epoch": 7, "training_loss": 0.7019615983963012, "training_acc": 47.0, "val_loss": 0.6924318289756775, "val_acc": 52.0}
{"epoch": 8, "training_loss": 0.6986197662353516, "training_acc": 53.0, "val_loss": 0.6939444351196289, "val_acc": 52.0}
{"epoch": 9, "training_loss": 0.7008163094520569, "training_acc": 53.0, "val_loss": 0.6924374389648438, "val_acc": 52.0}
{"epoch": 10, "training_loss": 0.7038223814964294, "training_acc": 43.0, "val_loss": 0.6924072813987732, "val_acc": 52.0}
{"epoch": 11, "training_loss": 0.694955153465271, "training_acc": 53.0, "val_loss": 0.6986728978157043, "val_acc": 52.0}
{"epoch": 12, "training_loss": 0.6992238616943359, "training_acc": 53.0, "val_loss": 0.6928750252723694, "val_acc": 52.0}
{"epoch": 13, "training_loss": 0.6984797620773315, "training_acc": 53.0, "val_loss": 0.6974433898925781, "val_acc": 48.0}
{"epoch": 14, "training_loss": 0.7075772666931153, "training_acc": 47.0, "val_loss": 0.6929398989677429, "val_acc": 52.0}
{"epoch": 15, "training_loss": 0.7149421072006226, "training_acc": 53.0, "val_loss": 0.6924145078659057, "val_acc": 52.0}
{"epoch": 16, "training_loss": 0.696811454296112, "training_acc": 43.0, "val_loss": 0.6923545026779174, "val_acc": 52.0}
{"epoch": 17, "training_loss": 0.6936916923522949, "training_acc": 53.0, "val_loss": 0.6929542183876037, "val_acc": 52.0}
{"epoch": 18, "training_loss": 0.6960643291473388, "training_acc": 49.0, "val_loss": 0.6923516011238098, "val_acc": 52.0}
{"epoch": 19, "training_loss": 0.6907572889328003, "training_acc": 53.0, "val_loss": 0.6967823433876038, "val_acc": 52.0}
{"epoch": 20, "training_loss": 0.706726701259613, "training_acc": 53.0, "val_loss": 0.6943776774406433, "val_acc": 52.0}
{"epoch": 21, "training_loss": 0.696160478591919, "training_acc": 53.0, "val_loss": 0.7011180448532105, "val_acc": 52.0}
{"epoch": 22, "training_loss": 0.7035139989852905, "training_acc": 53.0, "val_loss": 0.6924150466918946, "val_acc": 52.0}
{"epoch": 23, "training_loss": 0.6978905582427979, "training_acc": 49.0, "val_loss": 0.6970772552490234, "val_acc": 48.0}
{"epoch": 24, "training_loss": 0.7043693876266479, "training_acc": 49.0, "val_loss": 0.6978203558921814, "val_acc": 52.0}
{"epoch": 25, "training_loss": 0.7032576322555542, "training_acc": 53.0, "val_loss": 0.7066749286651611, "val_acc": 52.0}
{"epoch": 26, "training_loss": 0.7036525821685791, "training_acc": 53.0, "val_loss": 0.6935995197296143, "val_acc": 52.0}
{"epoch": 27, "training_loss": 0.7030594825744629, "training_acc": 53.0, "val_loss": 0.692508397102356, "val_acc": 52.0}
{"epoch": 28, "training_loss": 0.7222815346717835, "training_acc": 43.0, "val_loss": 0.6968361401557922, "val_acc": 48.0}
{"epoch": 29, "training_loss": 0.7123257303237915, "training_acc": 47.0, "val_loss": 0.6961173176765442, "val_acc": 52.0}
{"epoch": 30, "training_loss": 0.6924356651306153, "training_acc": 53.0, "val_loss": 0.6936566209793091, "val_acc": 48.0}
{"epoch": 31, "training_loss": 0.7004763126373291, "training_acc": 45.0, "val_loss": 0.6933553814888, "val_acc": 48.0}
{"epoch": 32, "training_loss": 0.6983941864967346, "training_acc": 45.0, "val_loss": 0.6943465447425843, "val_acc": 52.0}
{"epoch": 33, "training_loss": 0.7029527568817139, "training_acc": 53.0, "val_loss": 0.6969486546516418, "val_acc": 52.0}
{"epoch": 34, "training_loss": 0.7030881977081299, "training_acc": 53.0, "val_loss": 0.6939166331291199, "val_acc": 52.0}
{"epoch": 35, "training_loss": 0.6996614146232605, "training_acc": 43.0, "val_loss": 0.6949886989593506, "val_acc": 48.0}
{"epoch": 36, "training_loss": 0.6998514151573181, "training_acc": 45.0, "val_loss": 0.6939826941490174, "val_acc": 48.0}
{"epoch": 37, "training_loss": 0.7009824204444886, "training_acc": 47.0, "val_loss": 0.6931969022750855, "val_acc": 48.0}
