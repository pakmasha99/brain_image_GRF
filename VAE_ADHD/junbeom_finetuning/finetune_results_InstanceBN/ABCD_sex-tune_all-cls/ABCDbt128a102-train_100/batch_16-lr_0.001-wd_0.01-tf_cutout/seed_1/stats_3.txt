"main_modify.py --pretrained_path /scratch/connectome/dyhan316/VAE_ADHD/barlowtwins/pretrain_results/ABCDbt128a102.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 1 --task ABCD_sex --input_option BT_org --learning_rate 1e-3 --batch_size 16 --weight_decay 1e-2 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 0.697255539894104, "training_acc": 47.0, "val_loss": 0.6932374167442322, "val_acc": 52.0}
{"epoch": 1, "training_loss": 0.7051416969299317, "training_acc": 45.0, "val_loss": 0.6965732169151306, "val_acc": 52.0}
{"epoch": 2, "training_loss": 0.7012232732772827, "training_acc": 53.0, "val_loss": 0.7182031965255737, "val_acc": 52.0}
{"epoch": 3, "training_loss": 0.7113702058792114, "training_acc": 53.0, "val_loss": 0.6969603705406189, "val_acc": 48.0}
{"epoch": 4, "training_loss": 0.718522596359253, "training_acc": 47.0, "val_loss": 0.7005635190010071, "val_acc": 48.0}
{"epoch": 5, "training_loss": 0.6999468898773193, "training_acc": 43.0, "val_loss": 0.6930330467224121, "val_acc": 52.0}
{"epoch": 6, "training_loss": 0.7004691171646118, "training_acc": 47.0, "val_loss": 0.6984510850906372, "val_acc": 52.0}
{"epoch": 7, "training_loss": 0.7027521753311157, "training_acc": 53.0, "val_loss": 0.6924316024780274, "val_acc": 52.0}
{"epoch": 8, "training_loss": 0.7007860684394837, "training_acc": 53.0, "val_loss": 0.6943204879760743, "val_acc": 48.0}
{"epoch": 9, "training_loss": 0.6989747095108032, "training_acc": 47.0, "val_loss": 0.6976978993415832, "val_acc": 48.0}
{"epoch": 10, "training_loss": 0.7019332313537597, "training_acc": 45.0, "val_loss": 0.6928089570999145, "val_acc": 52.0}
{"epoch": 11, "training_loss": 0.6996168375015259, "training_acc": 53.0, "val_loss": 0.6981125378608704, "val_acc": 52.0}
{"epoch": 12, "training_loss": 0.6994885301589966, "training_acc": 53.0, "val_loss": 0.693526315689087, "val_acc": 52.0}
{"epoch": 13, "training_loss": 0.7021731877326965, "training_acc": 45.0, "val_loss": 0.6926886868476868, "val_acc": 52.0}
{"epoch": 14, "training_loss": 0.7035326099395752, "training_acc": 53.0, "val_loss": 0.6928037285804749, "val_acc": 52.0}
{"epoch": 15, "training_loss": 0.7062705755233765, "training_acc": 47.0, "val_loss": 0.6956317639350891, "val_acc": 48.0}
{"epoch": 16, "training_loss": 0.6990693616867065, "training_acc": 49.0, "val_loss": 0.6962672090530395, "val_acc": 52.0}
{"epoch": 17, "training_loss": 0.7214047384262084, "training_acc": 53.0, "val_loss": 0.6923535275459289, "val_acc": 52.0}
{"epoch": 18, "training_loss": 0.6947972679138184, "training_acc": 49.0, "val_loss": 0.6944724369049072, "val_acc": 48.0}
{"epoch": 19, "training_loss": 0.7006419420242309, "training_acc": 49.0, "val_loss": 0.6996748733520508, "val_acc": 52.0}
{"epoch": 20, "training_loss": 0.7096624588966369, "training_acc": 53.0, "val_loss": 0.6965694665908814, "val_acc": 52.0}
{"epoch": 21, "training_loss": 0.6958155822753906, "training_acc": 51.0, "val_loss": 0.6926420903205872, "val_acc": 52.0}
{"epoch": 22, "training_loss": 0.6946021723747253, "training_acc": 53.0, "val_loss": 0.6923706030845642, "val_acc": 52.0}
{"epoch": 23, "training_loss": 0.707608642578125, "training_acc": 53.0, "val_loss": 0.6923556923866272, "val_acc": 52.0}
{"epoch": 24, "training_loss": 0.6959681272506714, "training_acc": 53.0, "val_loss": 0.6924250340461731, "val_acc": 52.0}
{"epoch": 25, "training_loss": 0.7109317970275879, "training_acc": 41.0, "val_loss": 0.6930606484413147, "val_acc": 52.0}
{"epoch": 26, "training_loss": 0.7000590920448303, "training_acc": 47.0, "val_loss": 0.7001107907295228, "val_acc": 52.0}
{"epoch": 27, "training_loss": 0.72943439245224, "training_acc": 53.0, "val_loss": 0.7031543660163879, "val_acc": 52.0}
{"epoch": 28, "training_loss": 0.693349323272705, "training_acc": 53.0, "val_loss": 0.6957255935668946, "val_acc": 48.0}
{"epoch": 29, "training_loss": 0.701176266670227, "training_acc": 47.0, "val_loss": 0.6924589109420777, "val_acc": 52.0}
{"epoch": 30, "training_loss": 0.7016304111480713, "training_acc": 47.0, "val_loss": 0.7000220370292664, "val_acc": 52.0}
{"epoch": 31, "training_loss": 0.7170419216156005, "training_acc": 53.0, "val_loss": 0.7043212962150573, "val_acc": 52.0}
{"epoch": 32, "training_loss": 0.7027168655395508, "training_acc": 47.0, "val_loss": 0.6929057383537293, "val_acc": 52.0}
{"epoch": 33, "training_loss": 0.694973464012146, "training_acc": 45.0, "val_loss": 0.6959528827667236, "val_acc": 52.0}
{"epoch": 34, "training_loss": 0.6948585891723633, "training_acc": 53.0, "val_loss": 0.7029988384246826, "val_acc": 52.0}
{"epoch": 35, "training_loss": 0.7067406964302063, "training_acc": 53.0, "val_loss": 0.6924332475662232, "val_acc": 52.0}
{"epoch": 36, "training_loss": 0.6936801099777221, "training_acc": 53.0, "val_loss": 0.6932302117347717, "val_acc": 52.0}
