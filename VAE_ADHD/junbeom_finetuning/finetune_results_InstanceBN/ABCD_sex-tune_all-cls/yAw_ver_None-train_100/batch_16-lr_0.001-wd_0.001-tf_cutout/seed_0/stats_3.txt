"main_modify.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option BT_org --learning_rate 1e-3 --batch_size 16 --weight_decay 1e-3 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 0.7147775268554688, "training_acc": 43.0, "val_loss": 0.6924242734909057, "val_acc": 52.0}
{"epoch": 1, "training_loss": 0.7304283809661866, "training_acc": 53.0, "val_loss": 0.6923655915260315, "val_acc": 52.0}
{"epoch": 2, "training_loss": 0.6990684080123901, "training_acc": 47.0, "val_loss": 0.6925535893440247, "val_acc": 52.0}
{"epoch": 3, "training_loss": 0.7015468311309815, "training_acc": 53.0, "val_loss": 0.6943821954727173, "val_acc": 52.0}
{"epoch": 4, "training_loss": 0.693935866355896, "training_acc": 53.0, "val_loss": 0.6926925992965698, "val_acc": 52.0}
{"epoch": 5, "training_loss": 0.6983590650558472, "training_acc": 53.0, "val_loss": 0.6928376126289367, "val_acc": 52.0}
{"epoch": 6, "training_loss": 0.6989348220825196, "training_acc": 43.0, "val_loss": 0.6953779077529907, "val_acc": 52.0}
{"epoch": 7, "training_loss": 0.6990934801101685, "training_acc": 53.0, "val_loss": 0.697857449054718, "val_acc": 52.0}
{"epoch": 8, "training_loss": 0.6974066972732544, "training_acc": 53.0, "val_loss": 0.692757523059845, "val_acc": 52.0}
{"epoch": 9, "training_loss": 0.6958776473999023, "training_acc": 45.0, "val_loss": 0.6929156422615051, "val_acc": 52.0}
{"epoch": 10, "training_loss": 0.7073834276199341, "training_acc": 53.0, "val_loss": 0.6924002385139465, "val_acc": 52.0}
{"epoch": 11, "training_loss": 0.6955550336837768, "training_acc": 45.0, "val_loss": 0.6926066541671753, "val_acc": 52.0}
{"epoch": 12, "training_loss": 0.6955087852478027, "training_acc": 53.0, "val_loss": 0.6923852467536926, "val_acc": 52.0}
{"epoch": 13, "training_loss": 0.6953488254547119, "training_acc": 47.0, "val_loss": 0.6932502436637878, "val_acc": 48.0}
{"epoch": 14, "training_loss": 0.7228143978118896, "training_acc": 50.0, "val_loss": 0.692928535938263, "val_acc": 52.0}
{"epoch": 15, "training_loss": 0.6941109585762024, "training_acc": 53.0, "val_loss": 0.7170967507362366, "val_acc": 52.0}
{"epoch": 16, "training_loss": 0.6961565470695495, "training_acc": 52.0, "val_loss": 0.6935792589187622, "val_acc": 48.0}
{"epoch": 17, "training_loss": 0.7018338108062744, "training_acc": 49.0, "val_loss": 0.6925316166877746, "val_acc": 52.0}
{"epoch": 18, "training_loss": 0.6920061039924622, "training_acc": 53.0, "val_loss": 0.6924720358848572, "val_acc": 52.0}
{"epoch": 19, "training_loss": 0.6959172773361206, "training_acc": 45.0, "val_loss": 0.6923946523666382, "val_acc": 52.0}
{"epoch": 20, "training_loss": 0.6945279836654663, "training_acc": 53.0, "val_loss": 0.6966808247566223, "val_acc": 52.0}
{"epoch": 21, "training_loss": 0.6936614179611206, "training_acc": 53.0, "val_loss": 0.6923546910285949, "val_acc": 52.0}
{"epoch": 22, "training_loss": 0.6937213373184205, "training_acc": 49.0, "val_loss": 0.6929365944862366, "val_acc": 52.0}
{"epoch": 23, "training_loss": 0.7063755917549134, "training_acc": 53.0, "val_loss": 0.7029561305046081, "val_acc": 52.0}
{"epoch": 24, "training_loss": 0.6974319767951965, "training_acc": 53.0, "val_loss": 0.6960744619369507, "val_acc": 48.0}
{"epoch": 25, "training_loss": 0.7277892112731934, "training_acc": 47.0, "val_loss": 0.7040725040435791, "val_acc": 48.0}
{"epoch": 26, "training_loss": 0.7038523244857788, "training_acc": 49.0, "val_loss": 0.6973744583129883, "val_acc": 52.0}
{"epoch": 27, "training_loss": 0.6975502157211304, "training_acc": 53.0, "val_loss": 0.692677800655365, "val_acc": 52.0}
{"epoch": 28, "training_loss": 0.696365876197815, "training_acc": 45.0, "val_loss": 0.6926788449287414, "val_acc": 52.0}
{"epoch": 29, "training_loss": 0.697748703956604, "training_acc": 53.0, "val_loss": 0.6994390487670898, "val_acc": 52.0}
{"epoch": 30, "training_loss": 0.6965512943267822, "training_acc": 53.0, "val_loss": 0.6945253920555114, "val_acc": 52.0}
{"epoch": 31, "training_loss": 0.7015084838867187, "training_acc": 53.0, "val_loss": 0.6924147033691406, "val_acc": 52.0}
{"epoch": 32, "training_loss": 0.6937216019630432, "training_acc": 60.0, "val_loss": 0.6980749654769898, "val_acc": 48.0}
{"epoch": 33, "training_loss": 0.7091935443878173, "training_acc": 43.0, "val_loss": 0.6969130277633667, "val_acc": 52.0}
{"epoch": 34, "training_loss": 0.7078702354431152, "training_acc": 45.0, "val_loss": 0.695199544429779, "val_acc": 48.0}
{"epoch": 35, "training_loss": 0.6989892864227295, "training_acc": 47.0, "val_loss": 0.6945820212364197, "val_acc": 52.0}
{"epoch": 36, "training_loss": 0.6966046380996704, "training_acc": 47.0, "val_loss": 0.6955520248413086, "val_acc": 48.0}
{"epoch": 37, "training_loss": 0.7200032067298889, "training_acc": 47.0, "val_loss": 0.6948718571662903, "val_acc": 48.0}
{"epoch": 38, "training_loss": 0.6992169952392578, "training_acc": 55.0, "val_loss": 0.7150509357452393, "val_acc": 52.0}
{"epoch": 39, "training_loss": 0.7131127786636352, "training_acc": 53.0, "val_loss": 0.693065676689148, "val_acc": 52.0}
{"epoch": 40, "training_loss": 0.6990934252738953, "training_acc": 45.0, "val_loss": 0.6927853035926819, "val_acc": 60.0}
