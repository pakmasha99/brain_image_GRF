"main_modify.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option BT_org --learning_rate 1e-3 --batch_size 16 --weight_decay 1e-3 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 0.7132329344749451, "training_acc": 51.0, "val_loss": 0.6929780292510986, "val_acc": 52.0}
{"epoch": 1, "training_loss": 0.7087064266204834, "training_acc": 53.0, "val_loss": 0.6939946007728577, "val_acc": 48.0}
{"epoch": 2, "training_loss": 0.7128797316551209, "training_acc": 47.0, "val_loss": 0.6925000810623169, "val_acc": 52.0}
{"epoch": 3, "training_loss": 0.6935305404663086, "training_acc": 53.0, "val_loss": 0.6942577147483826, "val_acc": 52.0}
{"epoch": 4, "training_loss": 0.6949039602279663, "training_acc": 53.0, "val_loss": 0.6928637051582336, "val_acc": 52.0}
{"epoch": 5, "training_loss": 0.6958651447296142, "training_acc": 43.0, "val_loss": 0.6977195310592651, "val_acc": 52.0}
{"epoch": 6, "training_loss": 0.6966905736923218, "training_acc": 53.0, "val_loss": 0.693905053138733, "val_acc": 52.0}
{"epoch": 7, "training_loss": 0.6928021669387817, "training_acc": 53.0, "val_loss": 0.6931970596313477, "val_acc": 48.0}
{"epoch": 8, "training_loss": 0.6979219770431518, "training_acc": 47.0, "val_loss": 0.6929485940933228, "val_acc": 52.0}
{"epoch": 9, "training_loss": 0.6998121953010559, "training_acc": 53.0, "val_loss": 0.6924670362472534, "val_acc": 52.0}
{"epoch": 10, "training_loss": 0.6962265038490295, "training_acc": 47.0, "val_loss": 0.6926805448532104, "val_acc": 52.0}
{"epoch": 11, "training_loss": 0.698786735534668, "training_acc": 49.0, "val_loss": 0.6961183977127076, "val_acc": 52.0}
{"epoch": 12, "training_loss": 0.7042428398132324, "training_acc": 53.0, "val_loss": 0.6930891060829163, "val_acc": 52.0}
{"epoch": 13, "training_loss": 0.7076545333862305, "training_acc": 43.0, "val_loss": 0.6981107783317566, "val_acc": 52.0}
{"epoch": 14, "training_loss": 0.7032083320617676, "training_acc": 53.0, "val_loss": 0.7064925909042359, "val_acc": 52.0}
{"epoch": 15, "training_loss": 0.6987483286857605, "training_acc": 53.0, "val_loss": 0.6923818945884704, "val_acc": 52.0}
{"epoch": 16, "training_loss": 0.6932938814163208, "training_acc": 53.0, "val_loss": 0.6929973983764648, "val_acc": 52.0}
{"epoch": 17, "training_loss": 0.701762228012085, "training_acc": 53.0, "val_loss": 0.6946571707725525, "val_acc": 48.0}
{"epoch": 18, "training_loss": 0.6946626830101014, "training_acc": 51.0, "val_loss": 0.7009741640090943, "val_acc": 52.0}
{"epoch": 19, "training_loss": 0.7011266851425171, "training_acc": 53.0, "val_loss": 0.6930207443237305, "val_acc": 52.0}
{"epoch": 20, "training_loss": 0.6949617934226989, "training_acc": 47.0, "val_loss": 0.6924883675575256, "val_acc": 52.0}
{"epoch": 21, "training_loss": 0.6938854455947876, "training_acc": 53.0, "val_loss": 0.6923439049720764, "val_acc": 52.0}
{"epoch": 22, "training_loss": 0.7171790266036987, "training_acc": 49.0, "val_loss": 0.6936796879768372, "val_acc": 48.0}
{"epoch": 23, "training_loss": 0.7215654802322388, "training_acc": 49.0, "val_loss": 0.7049457478523254, "val_acc": 52.0}
{"epoch": 24, "training_loss": 0.6979104232788086, "training_acc": 49.0, "val_loss": 0.6928915476799011, "val_acc": 52.0}
{"epoch": 25, "training_loss": 0.6963339900970459, "training_acc": 53.0, "val_loss": 0.6930836868286133, "val_acc": 52.0}
{"epoch": 26, "training_loss": 0.6944259595870972, "training_acc": 53.0, "val_loss": 0.6933782601356506, "val_acc": 52.0}
{"epoch": 27, "training_loss": 0.6922818684577942, "training_acc": 53.0, "val_loss": 0.6971374344825745, "val_acc": 52.0}
{"epoch": 28, "training_loss": 0.6951748633384705, "training_acc": 53.0, "val_loss": 0.6939612460136414, "val_acc": 48.0}
{"epoch": 29, "training_loss": 0.7064018058776855, "training_acc": 47.0, "val_loss": 0.6987505674362182, "val_acc": 48.0}
{"epoch": 30, "training_loss": 0.6961183094978333, "training_acc": 49.0, "val_loss": 0.697829339504242, "val_acc": 52.0}
{"epoch": 31, "training_loss": 0.7080128145217895, "training_acc": 53.0, "val_loss": 0.6999468731880188, "val_acc": 52.0}
{"epoch": 32, "training_loss": 0.6915784764289856, "training_acc": 51.0, "val_loss": 0.6973064041137695, "val_acc": 48.0}
{"epoch": 33, "training_loss": 0.6979892444610596, "training_acc": 45.0, "val_loss": 0.69239271402359, "val_acc": 52.0}
{"epoch": 34, "training_loss": 0.6968397808074951, "training_acc": 47.0, "val_loss": 0.6941423344612122, "val_acc": 52.0}
{"epoch": 35, "training_loss": 0.696067705154419, "training_acc": 53.0, "val_loss": 0.6957276320457458, "val_acc": 52.0}
{"epoch": 36, "training_loss": 0.6944849443435669, "training_acc": 53.0, "val_loss": 0.6925183272361756, "val_acc": 52.0}
{"epoch": 37, "training_loss": 0.6986867141723633, "training_acc": 41.0, "val_loss": 0.6940123438835144, "val_acc": 48.0}
{"epoch": 38, "training_loss": 0.699224648475647, "training_acc": 55.0, "val_loss": 0.7015519595146179, "val_acc": 52.0}
{"epoch": 39, "training_loss": 0.7028680682182312, "training_acc": 53.0, "val_loss": 0.6927575993537903, "val_acc": 52.0}
{"epoch": 40, "training_loss": 0.6953785562515259, "training_acc": 49.0, "val_loss": 0.6929177188873291, "val_acc": 52.0}
