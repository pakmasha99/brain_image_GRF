"main_modify.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option BT_org --learning_rate 1e-3 --batch_size 16 --weight_decay 1e-3 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 0.7193841814994812, "training_acc": 46.0, "val_loss": 0.6923562955856323, "val_acc": 52.0}
{"epoch": 1, "training_loss": 0.6982625579833984, "training_acc": 51.0, "val_loss": 0.6929899215698242, "val_acc": 52.0}
{"epoch": 2, "training_loss": 0.7016091203689575, "training_acc": 53.0, "val_loss": 0.6935604071617126, "val_acc": 52.0}
{"epoch": 3, "training_loss": 0.6990695476531983, "training_acc": 43.0, "val_loss": 0.6973542976379394, "val_acc": 52.0}
{"epoch": 4, "training_loss": 0.6966440105438232, "training_acc": 53.0, "val_loss": 0.6971179461479187, "val_acc": 52.0}
{"epoch": 5, "training_loss": 0.7085961151123047, "training_acc": 41.0, "val_loss": 0.6953120732307434, "val_acc": 48.0}
{"epoch": 6, "training_loss": 0.6961568999290466, "training_acc": 49.0, "val_loss": 0.694918487071991, "val_acc": 52.0}
{"epoch": 7, "training_loss": 0.7168844723701477, "training_acc": 53.0, "val_loss": 0.6971600317955017, "val_acc": 52.0}
{"epoch": 8, "training_loss": 0.6953410005569458, "training_acc": 53.0, "val_loss": 0.6969504857063293, "val_acc": 48.0}
{"epoch": 9, "training_loss": 0.7093921256065369, "training_acc": 47.0, "val_loss": 0.6927728295326233, "val_acc": 52.0}
{"epoch": 10, "training_loss": 0.7042642450332641, "training_acc": 53.0, "val_loss": 0.6945365595817566, "val_acc": 48.0}
{"epoch": 11, "training_loss": 0.7105768394470214, "training_acc": 43.0, "val_loss": 0.6929675221443177, "val_acc": 52.0}
{"epoch": 12, "training_loss": 0.7016371417045594, "training_acc": 53.0, "val_loss": 0.6956867504119874, "val_acc": 52.0}
{"epoch": 13, "training_loss": 0.7034673166275024, "training_acc": 53.0, "val_loss": 0.6980243229866028, "val_acc": 52.0}
{"epoch": 14, "training_loss": 0.6904623985290528, "training_acc": 54.0, "val_loss": 0.6955293226242065, "val_acc": 48.0}
{"epoch": 15, "training_loss": 0.71020179271698, "training_acc": 47.0, "val_loss": 0.6926898765563965, "val_acc": 52.0}
{"epoch": 16, "training_loss": 0.7111276960372925, "training_acc": 53.0, "val_loss": 0.6993726396560669, "val_acc": 52.0}
{"epoch": 17, "training_loss": 0.6921923661231995, "training_acc": 53.0, "val_loss": 0.6929634785652161, "val_acc": 52.0}
{"epoch": 18, "training_loss": 0.6973934364318848, "training_acc": 53.0, "val_loss": 0.6923540496826172, "val_acc": 52.0}
{"epoch": 19, "training_loss": 0.695124270915985, "training_acc": 49.0, "val_loss": 0.6944720554351806, "val_acc": 52.0}
{"epoch": 20, "training_loss": 0.6996216630935669, "training_acc": 53.0, "val_loss": 0.6935816717147827, "val_acc": 52.0}
{"epoch": 21, "training_loss": 0.6968178510665893, "training_acc": 53.0, "val_loss": 0.6923319888114929, "val_acc": 52.0}
{"epoch": 22, "training_loss": 0.7047573971748352, "training_acc": 45.0, "val_loss": 0.6932282781600952, "val_acc": 52.0}
{"epoch": 23, "training_loss": 0.6941774106025695, "training_acc": 53.0, "val_loss": 0.6978076982498169, "val_acc": 52.0}
{"epoch": 24, "training_loss": 0.6935141372680664, "training_acc": 53.0, "val_loss": 0.6943926906585693, "val_acc": 48.0}
{"epoch": 25, "training_loss": 0.7287925910949707, "training_acc": 47.0, "val_loss": 0.6923733997344971, "val_acc": 52.0}
{"epoch": 26, "training_loss": 0.6952879858016968, "training_acc": 53.0, "val_loss": 0.7040248203277588, "val_acc": 52.0}
{"epoch": 27, "training_loss": 0.7016282510757447, "training_acc": 53.0, "val_loss": 0.6924343872070312, "val_acc": 52.0}
{"epoch": 28, "training_loss": 0.7205156779289246, "training_acc": 45.0, "val_loss": 0.7093278288841247, "val_acc": 48.0}
{"epoch": 29, "training_loss": 0.7130284237861634, "training_acc": 41.0, "val_loss": 0.6988354992866516, "val_acc": 52.0}
{"epoch": 30, "training_loss": 0.7156389570236206, "training_acc": 53.0, "val_loss": 0.7033979535102844, "val_acc": 52.0}
{"epoch": 31, "training_loss": 0.6969710731506348, "training_acc": 53.0, "val_loss": 0.6945845031738281, "val_acc": 48.0}
{"epoch": 32, "training_loss": 0.7067794871330261, "training_acc": 47.0, "val_loss": 0.6986598873138428, "val_acc": 48.0}
{"epoch": 33, "training_loss": 0.6966957378387452, "training_acc": 49.0, "val_loss": 0.7037581229209899, "val_acc": 52.0}
{"epoch": 34, "training_loss": 0.6954900789260864, "training_acc": 53.0, "val_loss": 0.6924032187461853, "val_acc": 52.0}
{"epoch": 35, "training_loss": 0.7037969565391541, "training_acc": 37.0, "val_loss": 0.6928995394706726, "val_acc": 52.0}
{"epoch": 36, "training_loss": 0.6992817091941833, "training_acc": 53.0, "val_loss": 0.6948910665512085, "val_acc": 52.0}
{"epoch": 37, "training_loss": 0.7131695032119751, "training_acc": 39.0, "val_loss": 0.6927624845504761, "val_acc": 52.0}
{"epoch": 38, "training_loss": 0.6931361389160157, "training_acc": 53.0, "val_loss": 0.695574848651886, "val_acc": 52.0}
{"epoch": 39, "training_loss": 0.7180167388916016, "training_acc": 35.0, "val_loss": 0.6924422955513001, "val_acc": 52.0}
{"epoch": 40, "training_loss": 0.702560293674469, "training_acc": 53.0, "val_loss": 0.6927717709541321, "val_acc": 52.0}
