"main_modify.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 3 --task ABCD_sex --input_option BT_org --learning_rate 1e-3 --batch_size 16 --weight_decay 1e-3 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 0.7088657855987549, "training_acc": 53.0, "val_loss": 0.697356309890747, "val_acc": 48.0}
{"epoch": 1, "training_loss": 0.7072705340385437, "training_acc": 43.0, "val_loss": 0.7037723994255066, "val_acc": 48.0}
{"epoch": 2, "training_loss": 0.715121464729309, "training_acc": 47.0, "val_loss": 0.6949159574508667, "val_acc": 52.0}
{"epoch": 3, "training_loss": 0.7555331945419311, "training_acc": 53.0, "val_loss": 0.7069123101234436, "val_acc": 52.0}
{"epoch": 4, "training_loss": 0.6994984745979309, "training_acc": 53.0, "val_loss": 0.6943122172355651, "val_acc": 48.0}
{"epoch": 5, "training_loss": 0.7026710033416748, "training_acc": 47.0, "val_loss": 0.6930503988265991, "val_acc": 52.0}
{"epoch": 6, "training_loss": 0.7011636590957642, "training_acc": 53.0, "val_loss": 0.6942334866523743, "val_acc": 52.0}
{"epoch": 7, "training_loss": 0.6970911955833435, "training_acc": 53.0, "val_loss": 0.6930659747123719, "val_acc": 52.0}
{"epoch": 8, "training_loss": 0.6948308229446412, "training_acc": 53.0, "val_loss": 0.6928565263748169, "val_acc": 52.0}
{"epoch": 9, "training_loss": 0.7051222586631775, "training_acc": 53.0, "val_loss": 0.7031385445594788, "val_acc": 52.0}
{"epoch": 10, "training_loss": 0.7056466746330261, "training_acc": 45.0, "val_loss": 0.6937719011306762, "val_acc": 52.0}
{"epoch": 11, "training_loss": 0.7016577601432801, "training_acc": 53.0, "val_loss": 0.6960409855842591, "val_acc": 52.0}
{"epoch": 12, "training_loss": 0.7001783204078674, "training_acc": 53.0, "val_loss": 0.6927570652961731, "val_acc": 52.0}
{"epoch": 13, "training_loss": 0.7051390624046325, "training_acc": 46.0, "val_loss": 0.6941213178634643, "val_acc": 48.0}
{"epoch": 14, "training_loss": 0.6961897945404053, "training_acc": 53.0, "val_loss": 0.6988507056236267, "val_acc": 52.0}
{"epoch": 15, "training_loss": 0.696419985294342, "training_acc": 53.0, "val_loss": 0.6934081554412842, "val_acc": 52.0}
{"epoch": 16, "training_loss": 0.6999842691421508, "training_acc": 43.0, "val_loss": 0.692725682258606, "val_acc": 52.0}
{"epoch": 17, "training_loss": 0.6956244707107544, "training_acc": 53.0, "val_loss": 0.693571949005127, "val_acc": 52.0}
{"epoch": 18, "training_loss": 0.7006920552253724, "training_acc": 44.0, "val_loss": 0.6924397397041321, "val_acc": 52.0}
{"epoch": 19, "training_loss": 0.6948982524871826, "training_acc": 49.0, "val_loss": 0.6946580076217651, "val_acc": 52.0}
{"epoch": 20, "training_loss": 0.6983427691459656, "training_acc": 53.0, "val_loss": 0.6924136018753052, "val_acc": 52.0}
{"epoch": 21, "training_loss": 0.6978632497787476, "training_acc": 43.0, "val_loss": 0.6926284432411194, "val_acc": 52.0}
{"epoch": 22, "training_loss": 0.6955867457389832, "training_acc": 53.0, "val_loss": 0.6948499774932861, "val_acc": 52.0}
{"epoch": 23, "training_loss": 0.7075584220886231, "training_acc": 53.0, "val_loss": 0.6924060010910034, "val_acc": 52.0}
{"epoch": 24, "training_loss": 0.6951121282577515, "training_acc": 49.0, "val_loss": 0.6936079835891724, "val_acc": 48.0}
{"epoch": 25, "training_loss": 0.6948639869689941, "training_acc": 51.0, "val_loss": 0.6992752051353455, "val_acc": 52.0}
{"epoch": 26, "training_loss": 0.7045238661766052, "training_acc": 53.0, "val_loss": 0.7057938766479492, "val_acc": 52.0}
{"epoch": 27, "training_loss": 0.7108883714675903, "training_acc": 53.0, "val_loss": 0.6926764035224915, "val_acc": 52.0}
{"epoch": 28, "training_loss": 0.7028439760208129, "training_acc": 43.0, "val_loss": 0.694527714252472, "val_acc": 48.0}
{"epoch": 29, "training_loss": 0.693412675857544, "training_acc": 51.0, "val_loss": 0.6978419613838196, "val_acc": 52.0}
{"epoch": 30, "training_loss": 0.7073057532310486, "training_acc": 53.0, "val_loss": 0.6949122595787048, "val_acc": 52.0}
{"epoch": 31, "training_loss": 0.7064701175689697, "training_acc": 51.0, "val_loss": 0.6977928853034974, "val_acc": 48.0}
{"epoch": 32, "training_loss": 0.6952929162979126, "training_acc": 55.0, "val_loss": 0.707200002670288, "val_acc": 52.0}
{"epoch": 33, "training_loss": 0.7129413652420044, "training_acc": 53.0, "val_loss": 0.6943695521354676, "val_acc": 52.0}
{"epoch": 34, "training_loss": 0.6958455467224121, "training_acc": 53.0, "val_loss": 0.6936624646186829, "val_acc": 52.0}
{"epoch": 35, "training_loss": 0.6919469499588012, "training_acc": 53.0, "val_loss": 0.6926020407676696, "val_acc": 52.0}
{"epoch": 36, "training_loss": 0.6936312150955201, "training_acc": 47.0, "val_loss": 0.6935103511810303, "val_acc": 52.0}
{"epoch": 37, "training_loss": 0.69832359790802, "training_acc": 53.0, "val_loss": 0.6966917729377746, "val_acc": 52.0}
{"epoch": 38, "training_loss": 0.6940830397605896, "training_acc": 49.0, "val_loss": 0.6947137379646301, "val_acc": 48.0}
{"epoch": 39, "training_loss": 0.694484429359436, "training_acc": 51.0, "val_loss": 0.6935558652877808, "val_acc": 52.0}
{"epoch": 40, "training_loss": 0.6974080681800843, "training_acc": 47.0, "val_loss": 0.6928939461708069, "val_acc": 52.0}
{"epoch": 41, "training_loss": 0.696752781867981, "training_acc": 53.0, "val_loss": 0.6925392460823059, "val_acc": 52.0}
{"epoch": 42, "training_loss": 0.6929538512229919, "training_acc": 53.0, "val_loss": 0.6936777853965759, "val_acc": 52.0}
