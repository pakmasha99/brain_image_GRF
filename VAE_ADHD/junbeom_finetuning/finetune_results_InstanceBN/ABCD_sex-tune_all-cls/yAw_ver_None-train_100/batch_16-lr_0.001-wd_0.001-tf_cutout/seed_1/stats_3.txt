"main_modify.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 1 --task ABCD_sex --input_option BT_org --learning_rate 1e-3 --batch_size 16 --weight_decay 1e-3 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 0.7027879762649536, "training_acc": 51.0, "val_loss": 0.6988212704658509, "val_acc": 52.0}
{"epoch": 1, "training_loss": 0.7019463348388671, "training_acc": 47.0, "val_loss": 0.6997014594078064, "val_acc": 52.0}
{"epoch": 2, "training_loss": 0.6994087171554565, "training_acc": 53.0, "val_loss": 0.6925189638137818, "val_acc": 52.0}
{"epoch": 3, "training_loss": 0.6991491031646728, "training_acc": 47.0, "val_loss": 0.6952805733680725, "val_acc": 52.0}
{"epoch": 4, "training_loss": 0.6979114460945129, "training_acc": 53.0, "val_loss": 0.7001891922950745, "val_acc": 52.0}
{"epoch": 5, "training_loss": 0.6998744821548462, "training_acc": 53.0, "val_loss": 0.6933098411560059, "val_acc": 48.0}
{"epoch": 6, "training_loss": 0.6994086074829101, "training_acc": 47.0, "val_loss": 0.6928551411628723, "val_acc": 52.0}
{"epoch": 7, "training_loss": 0.6969484949111938, "training_acc": 47.0, "val_loss": 0.6926169633865357, "val_acc": 52.0}
{"epoch": 8, "training_loss": 0.7013637852668763, "training_acc": 53.0, "val_loss": 0.6948797941207886, "val_acc": 52.0}
{"epoch": 9, "training_loss": 0.7021225476264954, "training_acc": 43.0, "val_loss": 0.6944752097129822, "val_acc": 52.0}
{"epoch": 10, "training_loss": 0.7201630520820618, "training_acc": 53.0, "val_loss": 0.6923989248275757, "val_acc": 52.0}
{"epoch": 11, "training_loss": 0.7165315818786621, "training_acc": 45.0, "val_loss": 0.6957696461677552, "val_acc": 52.0}
{"epoch": 12, "training_loss": 0.7053841733932495, "training_acc": 53.0, "val_loss": 0.6928326535224915, "val_acc": 52.0}
{"epoch": 13, "training_loss": 0.699168574810028, "training_acc": 47.0, "val_loss": 0.6932062125205993, "val_acc": 52.0}
{"epoch": 14, "training_loss": 0.6925307893753052, "training_acc": 53.0, "val_loss": 0.6968414449691772, "val_acc": 52.0}
{"epoch": 15, "training_loss": 0.7000498485565185, "training_acc": 53.0, "val_loss": 0.6935655379295349, "val_acc": 52.0}
{"epoch": 16, "training_loss": 0.7214783024787903, "training_acc": 53.0, "val_loss": 0.692375385761261, "val_acc": 52.0}
{"epoch": 17, "training_loss": 0.7243468809127808, "training_acc": 45.0, "val_loss": 0.6976838684082032, "val_acc": 48.0}
{"epoch": 18, "training_loss": 0.687721598148346, "training_acc": 55.0, "val_loss": 0.7049877500534057, "val_acc": 52.0}
{"epoch": 19, "training_loss": 0.7127749943733215, "training_acc": 53.0, "val_loss": 0.6960896611213684, "val_acc": 52.0}
{"epoch": 20, "training_loss": 0.6963374614715576, "training_acc": 49.0, "val_loss": 0.6932915902137756, "val_acc": 52.0}
{"epoch": 21, "training_loss": 0.6999887084960937, "training_acc": 51.0, "val_loss": 0.6968506956100464, "val_acc": 52.0}
{"epoch": 22, "training_loss": 0.6994279241561889, "training_acc": 53.0, "val_loss": 0.6922790861129761, "val_acc": 52.0}
{"epoch": 23, "training_loss": 0.6949130582809449, "training_acc": 53.0, "val_loss": 0.6924017000198365, "val_acc": 52.0}
{"epoch": 24, "training_loss": 0.7090548515319824, "training_acc": 53.0, "val_loss": 0.6932726001739502, "val_acc": 48.0}
{"epoch": 25, "training_loss": 0.7052590870857238, "training_acc": 47.0, "val_loss": 0.6972529220581055, "val_acc": 48.0}
{"epoch": 26, "training_loss": 0.7049105882644653, "training_acc": 49.0, "val_loss": 0.6940244913101197, "val_acc": 52.0}
{"epoch": 27, "training_loss": 0.702771155834198, "training_acc": 41.0, "val_loss": 0.6928718900680542, "val_acc": 52.0}
{"epoch": 28, "training_loss": 0.6973446655273438, "training_acc": 47.0, "val_loss": 0.6931663465499878, "val_acc": 52.0}
{"epoch": 29, "training_loss": 0.6961936283111573, "training_acc": 53.0, "val_loss": 0.6925040674209595, "val_acc": 52.0}
{"epoch": 30, "training_loss": 0.6977686977386475, "training_acc": 45.0, "val_loss": 0.6937197136878968, "val_acc": 48.0}
{"epoch": 31, "training_loss": 0.690332133769989, "training_acc": 53.0, "val_loss": 0.6980003309249878, "val_acc": 52.0}
{"epoch": 32, "training_loss": 0.7005952405929565, "training_acc": 53.0, "val_loss": 0.6967103910446167, "val_acc": 52.0}
{"epoch": 33, "training_loss": 0.6988788533210755, "training_acc": 53.0, "val_loss": 0.6925109982490539, "val_acc": 52.0}
{"epoch": 34, "training_loss": 0.697725100517273, "training_acc": 45.0, "val_loss": 0.6930217051506042, "val_acc": 52.0}
{"epoch": 35, "training_loss": 0.6945903539657593, "training_acc": 47.0, "val_loss": 0.6981850361824036, "val_acc": 52.0}
{"epoch": 36, "training_loss": 0.7079011273384094, "training_acc": 53.0, "val_loss": 0.7097993040084839, "val_acc": 52.0}
{"epoch": 37, "training_loss": 0.7058784532546997, "training_acc": 53.0, "val_loss": 0.6962456583976746, "val_acc": 48.0}
{"epoch": 38, "training_loss": 0.7332712984085084, "training_acc": 47.0, "val_loss": 0.7032367634773254, "val_acc": 48.0}
{"epoch": 39, "training_loss": 0.6996561765670777, "training_acc": 47.0, "val_loss": 0.6965999579429627, "val_acc": 52.0}
{"epoch": 40, "training_loss": 0.7004117250442505, "training_acc": 53.0, "val_loss": 0.6954880571365356, "val_acc": 52.0}
{"epoch": 41, "training_loss": 0.7067254638671875, "training_acc": 53.0, "val_loss": 0.693420467376709, "val_acc": 52.0}
