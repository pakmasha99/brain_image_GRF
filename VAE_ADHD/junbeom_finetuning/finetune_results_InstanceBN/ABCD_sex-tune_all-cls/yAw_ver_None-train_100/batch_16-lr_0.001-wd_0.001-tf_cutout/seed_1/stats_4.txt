"main_modify.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 1 --task ABCD_sex --input_option BT_org --learning_rate 1e-3 --batch_size 16 --weight_decay 1e-3 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 0.7162095260620117, "training_acc": 48.0, "val_loss": 0.6932331037521362, "val_acc": 44.0}
{"epoch": 1, "training_loss": 0.700758273601532, "training_acc": 49.0, "val_loss": 0.6879828739166259, "val_acc": 56.0}
{"epoch": 2, "training_loss": 0.707060866355896, "training_acc": 52.0, "val_loss": 0.6950826263427734, "val_acc": 44.0}
{"epoch": 3, "training_loss": 0.7012953662872314, "training_acc": 48.0, "val_loss": 0.6869673991203308, "val_acc": 56.0}
{"epoch": 4, "training_loss": 0.6989645624160766, "training_acc": 52.0, "val_loss": 0.6874620366096497, "val_acc": 56.0}
{"epoch": 5, "training_loss": 0.711249647140503, "training_acc": 42.0, "val_loss": 0.6863678240776062, "val_acc": 56.0}
{"epoch": 6, "training_loss": 0.7107178878784179, "training_acc": 52.0, "val_loss": 0.6860612487792969, "val_acc": 56.0}
{"epoch": 7, "training_loss": 0.6998090863227844, "training_acc": 46.0, "val_loss": 0.6908328366279602, "val_acc": 56.0}
{"epoch": 8, "training_loss": 0.7042661499977112, "training_acc": 52.0, "val_loss": 0.6859122824668884, "val_acc": 56.0}
{"epoch": 9, "training_loss": 0.7219796371459961, "training_acc": 52.0, "val_loss": 0.6860616993904114, "val_acc": 56.0}
{"epoch": 10, "training_loss": 0.6978675985336303, "training_acc": 52.0, "val_loss": 0.6863715147972107, "val_acc": 56.0}
{"epoch": 11, "training_loss": 0.699001693725586, "training_acc": 52.0, "val_loss": 0.6916571426391601, "val_acc": 56.0}
{"epoch": 12, "training_loss": 0.7100354838371277, "training_acc": 40.0, "val_loss": 0.6875274324417114, "val_acc": 56.0}
{"epoch": 13, "training_loss": 0.6977223587036133, "training_acc": 52.0, "val_loss": 0.6866418409347534, "val_acc": 56.0}
{"epoch": 14, "training_loss": 0.6997247433662415, "training_acc": 52.0, "val_loss": 0.6863537907600403, "val_acc": 56.0}
{"epoch": 15, "training_loss": 0.6951059341430664, "training_acc": 52.0, "val_loss": 0.6920510792732238, "val_acc": 56.0}
{"epoch": 16, "training_loss": 0.706516842842102, "training_acc": 46.0, "val_loss": 0.6885143971443176, "val_acc": 56.0}
{"epoch": 17, "training_loss": 0.6981245470046997, "training_acc": 42.0, "val_loss": 0.6860090947151184, "val_acc": 56.0}
{"epoch": 18, "training_loss": 0.7015143585205078, "training_acc": 52.0, "val_loss": 0.6860194969177246, "val_acc": 56.0}
{"epoch": 19, "training_loss": 0.693812255859375, "training_acc": 50.0, "val_loss": 0.6968629550933838, "val_acc": 44.0}
{"epoch": 20, "training_loss": 0.6982390189170837, "training_acc": 46.0, "val_loss": 0.6875717186927796, "val_acc": 56.0}
{"epoch": 21, "training_loss": 0.6976878833770752, "training_acc": 46.0, "val_loss": 0.6916728711128235, "val_acc": 56.0}
{"epoch": 22, "training_loss": 0.7001511025428772, "training_acc": 52.0, "val_loss": 0.6861942052841187, "val_acc": 56.0}
{"epoch": 23, "training_loss": 0.7019505143165589, "training_acc": 46.0, "val_loss": 0.7083099794387817, "val_acc": 44.0}
{"epoch": 24, "training_loss": 0.7023154139518738, "training_acc": 46.0, "val_loss": 0.6920590329170228, "val_acc": 56.0}
{"epoch": 25, "training_loss": 0.6939689207077027, "training_acc": 44.0, "val_loss": 0.6866300749778748, "val_acc": 56.0}
{"epoch": 26, "training_loss": 0.7073930478096009, "training_acc": 52.0, "val_loss": 0.6859318590164185, "val_acc": 56.0}
{"epoch": 27, "training_loss": 0.7071299576759338, "training_acc": 52.0, "val_loss": 0.686097731590271, "val_acc": 56.0}
