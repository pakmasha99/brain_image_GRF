"main_modify.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 1 --task ABCD_sex --input_option BT_org --learning_rate 1e-1 --batch_size 16 --weight_decay 1e-2 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 9.582853145599366, "training_acc": 57.0, "val_loss": 4.722315444946289, "val_acc": 52.0}
{"epoch": 1, "training_loss": 5.002511119842529, "training_acc": 49.0, "val_loss": 4.302549114227295, "val_acc": 52.0}
{"epoch": 2, "training_loss": 2.716063313484192, "training_acc": 53.0, "val_loss": 2.1493869018554688, "val_acc": 52.0}
{"epoch": 3, "training_loss": 1.1106957387924195, "training_acc": 55.0, "val_loss": 0.7475571060180664, "val_acc": 48.0}
{"epoch": 4, "training_loss": 0.8360898947715759, "training_acc": 55.0, "val_loss": 1.4762827491760253, "val_acc": 48.0}
{"epoch": 5, "training_loss": 1.2343188297748566, "training_acc": 51.0, "val_loss": 3.3193787479400636, "val_acc": 52.0}
{"epoch": 6, "training_loss": 1.4408941125869752, "training_acc": 51.0, "val_loss": 1.3554073572158813, "val_acc": 48.0}
{"epoch": 7, "training_loss": 1.2116783714294435, "training_acc": 49.0, "val_loss": 1.9546497631072999, "val_acc": 48.0}
{"epoch": 8, "training_loss": 2.195980958938599, "training_acc": 51.0, "val_loss": 2.195817289352417, "val_acc": 48.0}
{"epoch": 9, "training_loss": 0.9950751328468322, "training_acc": 51.0, "val_loss": 0.7420867538452148, "val_acc": 52.0}
{"epoch": 10, "training_loss": 0.9286540699005127, "training_acc": 49.0, "val_loss": 3.3473527336120608, "val_acc": 48.0}
{"epoch": 11, "training_loss": 2.2832011675834654, "training_acc": 49.0, "val_loss": 0.704244077205658, "val_acc": 48.0}
{"epoch": 12, "training_loss": 0.9651529693603516, "training_acc": 51.0, "val_loss": 1.8368969774246215, "val_acc": 52.0}
{"epoch": 13, "training_loss": 1.4026599550247192, "training_acc": 49.0, "val_loss": 0.7036989068984986, "val_acc": 52.0}
{"epoch": 14, "training_loss": 1.2125916767120362, "training_acc": 41.0, "val_loss": 0.8291782402992248, "val_acc": 52.0}
{"epoch": 15, "training_loss": 0.7354403638839722, "training_acc": 51.0, "val_loss": 0.756297082901001, "val_acc": 48.0}
{"epoch": 16, "training_loss": 0.8525155758857728, "training_acc": 47.0, "val_loss": 0.7169651532173157, "val_acc": 52.0}
{"epoch": 17, "training_loss": 0.9275246906280518, "training_acc": 49.0, "val_loss": 0.7139288449287414, "val_acc": 52.0}
{"epoch": 18, "training_loss": 1.068925380706787, "training_acc": 53.0, "val_loss": 1.1561701011657715, "val_acc": 52.0}
{"epoch": 19, "training_loss": 0.909834258556366, "training_acc": 49.0, "val_loss": 3.0128390693664553, "val_acc": 48.0}
{"epoch": 20, "training_loss": 2.782992422580719, "training_acc": 55.0, "val_loss": 2.676383399963379, "val_acc": 48.0}
{"epoch": 21, "training_loss": 1.3248874235153199, "training_acc": 47.0, "val_loss": 1.1601470041275024, "val_acc": 52.0}
{"epoch": 22, "training_loss": 1.382996621131897, "training_acc": 55.0, "val_loss": 4.901114597320556, "val_acc": 48.0}
{"epoch": 23, "training_loss": 3.170105438232422, "training_acc": 47.0, "val_loss": 2.017455468177795, "val_acc": 48.0}
{"epoch": 24, "training_loss": 1.5124930667877197, "training_acc": 49.0, "val_loss": 0.7165455555915833, "val_acc": 48.0}
{"epoch": 25, "training_loss": 1.449301462173462, "training_acc": 47.0, "val_loss": 1.1398206758499145, "val_acc": 52.0}
{"epoch": 26, "training_loss": 1.5910179996490479, "training_acc": 51.0, "val_loss": 1.2361506223678589, "val_acc": 52.0}
{"epoch": 27, "training_loss": 3.2638224029541014, "training_acc": 43.0, "val_loss": 0.6947562408447265, "val_acc": 48.0}
{"epoch": 28, "training_loss": 2.929510917663574, "training_acc": 53.0, "val_loss": 0.7968034338951111, "val_acc": 52.0}
{"epoch": 29, "training_loss": 3.3075379753112792, "training_acc": 49.0, "val_loss": 5.786464538574219, "val_acc": 52.0}
{"epoch": 30, "training_loss": 4.226856098175049, "training_acc": 39.0, "val_loss": 2.543755178451538, "val_acc": 52.0}
{"epoch": 31, "training_loss": 2.376199676990509, "training_acc": 49.0, "val_loss": 0.7609446549415588, "val_acc": 52.0}
{"epoch": 32, "training_loss": 1.3175756216049195, "training_acc": 53.0, "val_loss": 1.0603897070884705, "val_acc": 48.0}
{"epoch": 33, "training_loss": 1.6432949995994568, "training_acc": 45.0, "val_loss": 1.4476272749900818, "val_acc": 48.0}
{"epoch": 34, "training_loss": 1.2210279679298401, "training_acc": 49.0, "val_loss": 0.6959837770462036, "val_acc": 52.0}
{"epoch": 35, "training_loss": 1.0244493103027343, "training_acc": 51.0, "val_loss": 1.8067178273200988, "val_acc": 52.0}
{"epoch": 36, "training_loss": 2.060267136096954, "training_acc": 47.0, "val_loss": 1.7933001947402953, "val_acc": 48.0}
{"epoch": 37, "training_loss": 1.7089663529396057, "training_acc": 47.0, "val_loss": 0.8509449052810669, "val_acc": 52.0}
{"epoch": 38, "training_loss": 1.1889005160331727, "training_acc": 49.0, "val_loss": 1.5114370107650756, "val_acc": 52.0}
{"epoch": 39, "training_loss": 1.0757918787002563, "training_acc": 47.0, "val_loss": 3.2387453174591063, "val_acc": 52.0}
{"epoch": 40, "training_loss": 1.8765575796365739, "training_acc": 53.0, "val_loss": 1.9878491687774658, "val_acc": 52.0}
{"epoch": 41, "training_loss": 1.520372290611267, "training_acc": 45.0, "val_loss": 1.5961305475234986, "val_acc": 48.0}
{"epoch": 42, "training_loss": 1.334795503616333, "training_acc": 43.0, "val_loss": 1.13343932390213, "val_acc": 48.0}
{"epoch": 43, "training_loss": 3.5847982144355774, "training_acc": 53.0, "val_loss": 4.2197857856750485, "val_acc": 48.0}
{"epoch": 44, "training_loss": 4.259739255905151, "training_acc": 37.0, "val_loss": 2.2989340686798094, "val_acc": 52.0}
{"epoch": 45, "training_loss": 1.704087287336588, "training_acc": 51.0, "val_loss": 2.547005090713501, "val_acc": 52.0}
{"epoch": 46, "training_loss": 2.0617122554779055, "training_acc": 47.0, "val_loss": 1.862202262878418, "val_acc": 52.0}
