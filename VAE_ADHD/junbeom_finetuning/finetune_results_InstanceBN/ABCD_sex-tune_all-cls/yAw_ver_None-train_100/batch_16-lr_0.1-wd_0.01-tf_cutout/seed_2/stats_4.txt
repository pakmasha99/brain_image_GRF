"main_modify.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 2 --task ABCD_sex --input_option BT_org --learning_rate 1e-1 --batch_size 16 --weight_decay 1e-2 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 7.5363700437545775, "training_acc": 54.0, "val_loss": 3.603054790496826, "val_acc": 56.0}
{"epoch": 1, "training_loss": 2.9821929546818136, "training_acc": 48.0, "val_loss": 3.751553945541382, "val_acc": 56.0}
{"epoch": 2, "training_loss": 2.752977547645569, "training_acc": 52.0, "val_loss": 2.181927194595337, "val_acc": 56.0}
{"epoch": 3, "training_loss": 2.0323634433746336, "training_acc": 42.0, "val_loss": 1.270748920440674, "val_acc": 44.0}
{"epoch": 4, "training_loss": 1.6737226891517638, "training_acc": 58.0, "val_loss": 0.869543890953064, "val_acc": 56.0}
{"epoch": 5, "training_loss": 0.8291843807697297, "training_acc": 58.0, "val_loss": 3.5585202026367186, "val_acc": 44.0}
{"epoch": 6, "training_loss": 2.5300264978408813, "training_acc": 56.0, "val_loss": 3.5362542152404783, "val_acc": 44.0}
{"epoch": 7, "training_loss": 2.5236400890350343, "training_acc": 52.0, "val_loss": 2.284724235534668, "val_acc": 44.0}
{"epoch": 8, "training_loss": 1.008239179253578, "training_acc": 56.0, "val_loss": 2.6771317100524903, "val_acc": 56.0}
{"epoch": 9, "training_loss": 1.7721182537078857, "training_acc": 58.0, "val_loss": 2.2820246505737303, "val_acc": 56.0}
{"epoch": 10, "training_loss": 1.5707835818082094, "training_acc": 60.0, "val_loss": 1.8717048597335815, "val_acc": 56.0}
{"epoch": 11, "training_loss": 1.0685481595993043, "training_acc": 50.0, "val_loss": 2.9281986713409425, "val_acc": 56.0}
{"epoch": 12, "training_loss": 2.4511882400512697, "training_acc": 50.0, "val_loss": 1.3204957723617554, "val_acc": 56.0}
{"epoch": 13, "training_loss": 1.7323071670532226, "training_acc": 52.0, "val_loss": 3.4730019760131836, "val_acc": 44.0}
{"epoch": 14, "training_loss": 1.9584212398529053, "training_acc": 50.0, "val_loss": 2.641056499481201, "val_acc": 56.0}
{"epoch": 15, "training_loss": 3.9509221267700196, "training_acc": 50.0, "val_loss": 0.7050548338890076, "val_acc": 44.0}
{"epoch": 16, "training_loss": 3.1314125442504883, "training_acc": 54.0, "val_loss": 4.765940170288086, "val_acc": 44.0}
{"epoch": 17, "training_loss": 2.971801300048828, "training_acc": 46.0, "val_loss": 4.636744384765625, "val_acc": 44.0}
{"epoch": 18, "training_loss": 2.31425178527832, "training_acc": 52.0, "val_loss": 1.0694746923446656, "val_acc": 56.0}
{"epoch": 19, "training_loss": 1.6915814971923828, "training_acc": 58.0, "val_loss": 2.5546387577056886, "val_acc": 56.0}
{"epoch": 20, "training_loss": 2.278277816772461, "training_acc": 50.0, "val_loss": 0.7648544383049011, "val_acc": 44.0}
{"epoch": 21, "training_loss": 1.3223455142974854, "training_acc": 44.0, "val_loss": 0.6896102619171143, "val_acc": 56.0}
{"epoch": 22, "training_loss": 0.9120732355117798, "training_acc": 52.0, "val_loss": 0.6866094660758972, "val_acc": 56.0}
{"epoch": 23, "training_loss": 1.030823769569397, "training_acc": 46.0, "val_loss": 0.6861584115028382, "val_acc": 56.0}
{"epoch": 24, "training_loss": 0.8154512667655944, "training_acc": 50.0, "val_loss": 3.1270399951934813, "val_acc": 44.0}
{"epoch": 25, "training_loss": 3.0961401748657225, "training_acc": 48.0, "val_loss": 1.4732418775558471, "val_acc": 44.0}
{"epoch": 26, "training_loss": 1.3944375276565553, "training_acc": 46.0, "val_loss": 0.7664741230010986, "val_acc": 56.0}
{"epoch": 27, "training_loss": 2.2294656467437743, "training_acc": 46.0, "val_loss": 1.6099208354949952, "val_acc": 44.0}
{"epoch": 28, "training_loss": 1.0708700370788575, "training_acc": 46.0, "val_loss": 0.8414327049255371, "val_acc": 56.0}
{"epoch": 29, "training_loss": 0.8276082491874694, "training_acc": 48.0, "val_loss": 1.4922281122207641, "val_acc": 44.0}
{"epoch": 30, "training_loss": 0.986746096611023, "training_acc": 56.0, "val_loss": 0.7877223896980285, "val_acc": 56.0}
{"epoch": 31, "training_loss": 0.8848094463348388, "training_acc": 56.0, "val_loss": 0.796498293876648, "val_acc": 44.0}
{"epoch": 32, "training_loss": 0.8332372832298279, "training_acc": 52.0, "val_loss": 0.7909604263305664, "val_acc": 44.0}
{"epoch": 33, "training_loss": 1.0304077672958374, "training_acc": 48.0, "val_loss": 1.081712579727173, "val_acc": 44.0}
{"epoch": 34, "training_loss": 1.0802598333358764, "training_acc": 56.0, "val_loss": 1.5375588846206665, "val_acc": 56.0}
{"epoch": 35, "training_loss": 1.4071438550949096, "training_acc": 50.0, "val_loss": 0.7884571194648743, "val_acc": 44.0}
{"epoch": 36, "training_loss": 0.9729050517082214, "training_acc": 44.0, "val_loss": 1.7174090194702147, "val_acc": 56.0}
{"epoch": 37, "training_loss": 1.9040179681777953, "training_acc": 52.0, "val_loss": 1.966862106323242, "val_acc": 56.0}
{"epoch": 38, "training_loss": 3.605208854675293, "training_acc": 40.0, "val_loss": 1.1744497632980346, "val_acc": 56.0}
{"epoch": 39, "training_loss": 5.121494722366333, "training_acc": 46.0, "val_loss": 2.3046324634552002, "val_acc": 56.0}
{"epoch": 40, "training_loss": 1.9870427560806274, "training_acc": 50.0, "val_loss": 0.7235082268714905, "val_acc": 44.0}
{"epoch": 41, "training_loss": 1.15573956489563, "training_acc": 54.0, "val_loss": 0.7764755344390869, "val_acc": 44.0}
{"epoch": 42, "training_loss": 1.788239221572876, "training_acc": 58.0, "val_loss": 1.5014028358459472, "val_acc": 56.0}
