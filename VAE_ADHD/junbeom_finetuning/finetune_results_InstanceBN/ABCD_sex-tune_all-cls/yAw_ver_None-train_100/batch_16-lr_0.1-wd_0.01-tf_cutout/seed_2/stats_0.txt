"main_modify.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 2 --task ABCD_sex --input_option BT_org --learning_rate 1e-1 --batch_size 16 --weight_decay 1e-2 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 12.42175931930542, "training_acc": 47.0, "val_loss": 10.092698249816895, "val_acc": 52.0}
{"epoch": 1, "training_loss": 9.294491481781005, "training_acc": 51.0, "val_loss": 7.030825309753418, "val_acc": 48.0}
{"epoch": 2, "training_loss": 3.5898508644104004, "training_acc": 51.0, "val_loss": 1.37661545753479, "val_acc": 52.0}
{"epoch": 3, "training_loss": 2.30168363571167, "training_acc": 41.0, "val_loss": 1.1486019277572632, "val_acc": 48.0}
{"epoch": 4, "training_loss": 1.0508282423019408, "training_acc": 53.0, "val_loss": 0.7547598958015442, "val_acc": 48.0}
{"epoch": 5, "training_loss": 1.126541337966919, "training_acc": 45.0, "val_loss": 2.4641882228851317, "val_acc": 48.0}
{"epoch": 6, "training_loss": 1.3442099833488463, "training_acc": 51.0, "val_loss": 0.9688797664642333, "val_acc": 52.0}
{"epoch": 7, "training_loss": 0.7790771341323852, "training_acc": 51.0, "val_loss": 0.705925531387329, "val_acc": 48.0}
{"epoch": 8, "training_loss": 1.0248838043212891, "training_acc": 47.0, "val_loss": 1.0484143805503845, "val_acc": 48.0}
{"epoch": 9, "training_loss": 0.9441960430145264, "training_acc": 47.0, "val_loss": 1.3346341133117676, "val_acc": 52.0}
{"epoch": 10, "training_loss": 1.1203101301193237, "training_acc": 53.0, "val_loss": 0.8857825469970703, "val_acc": 48.0}
{"epoch": 11, "training_loss": 1.5044246244430541, "training_acc": 51.0, "val_loss": 2.331469888687134, "val_acc": 52.0}
{"epoch": 12, "training_loss": 2.685485391616821, "training_acc": 55.0, "val_loss": 1.6791690158843995, "val_acc": 52.0}
{"epoch": 13, "training_loss": 4.129515571594238, "training_acc": 45.0, "val_loss": 6.228962459564209, "val_acc": 52.0}
{"epoch": 14, "training_loss": 2.9093651962280274, "training_acc": 51.0, "val_loss": 5.140020389556884, "val_acc": 52.0}
{"epoch": 15, "training_loss": 3.956569712162018, "training_acc": 49.0, "val_loss": 2.384464826583862, "val_acc": 52.0}
{"epoch": 16, "training_loss": 1.9853824400901794, "training_acc": 45.0, "val_loss": 1.1806244015693665, "val_acc": 48.0}
{"epoch": 17, "training_loss": 0.9666086053848266, "training_acc": 49.0, "val_loss": 0.7910379719734192, "val_acc": 52.0}
{"epoch": 18, "training_loss": 0.8574084186553955, "training_acc": 47.0, "val_loss": 1.1350980377197266, "val_acc": 52.0}
{"epoch": 19, "training_loss": 0.9465803813934326, "training_acc": 49.0, "val_loss": 1.8387653779983522, "val_acc": 52.0}
{"epoch": 20, "training_loss": 1.2194497871398926, "training_acc": 49.0, "val_loss": 0.7793152451515197, "val_acc": 52.0}
{"epoch": 21, "training_loss": 1.5908322739601135, "training_acc": 49.0, "val_loss": 1.0849151635169982, "val_acc": 48.0}
{"epoch": 22, "training_loss": 1.0369111442565917, "training_acc": 53.0, "val_loss": 1.0088597774505614, "val_acc": 48.0}
{"epoch": 23, "training_loss": 1.0737287068367005, "training_acc": 51.0, "val_loss": 0.6926296973228454, "val_acc": 52.0}
{"epoch": 24, "training_loss": 1.0076386952400207, "training_acc": 45.0, "val_loss": 0.747848026752472, "val_acc": 48.0}
{"epoch": 25, "training_loss": 1.269304497204721, "training_acc": 51.0, "val_loss": 2.107691264152527, "val_acc": 52.0}
{"epoch": 26, "training_loss": 1.251029930114746, "training_acc": 45.0, "val_loss": 1.5318782281875611, "val_acc": 52.0}
{"epoch": 27, "training_loss": 1.4445574116706847, "training_acc": 53.0, "val_loss": 1.231814875602722, "val_acc": 48.0}
{"epoch": 28, "training_loss": 1.157345118522644, "training_acc": 47.0, "val_loss": 2.305637710094452, "val_acc": 48.0}
{"epoch": 29, "training_loss": 1.895796413421631, "training_acc": 45.0, "val_loss": 2.219847111701965, "val_acc": 52.0}
{"epoch": 30, "training_loss": 1.0741404819488525, "training_acc": 55.0, "val_loss": 0.7352593636512756, "val_acc": 48.0}
{"epoch": 31, "training_loss": 1.0140486884117126, "training_acc": 51.0, "val_loss": 1.1411047077178955, "val_acc": 48.0}
{"epoch": 32, "training_loss": 1.2027511596679688, "training_acc": 45.0, "val_loss": 0.7105196785926818, "val_acc": 48.0}
{"epoch": 33, "training_loss": 1.220019929409027, "training_acc": 49.0, "val_loss": 1.6701233386993408, "val_acc": 52.0}
{"epoch": 34, "training_loss": 1.4113900089263915, "training_acc": 41.0, "val_loss": 2.8993801784515383, "val_acc": 52.0}
{"epoch": 35, "training_loss": 2.3952213096618653, "training_acc": 53.0, "val_loss": 2.702965202331543, "val_acc": 52.0}
{"epoch": 36, "training_loss": 2.2262403202056884, "training_acc": 41.0, "val_loss": 4.9117230033874515, "val_acc": 48.0}
{"epoch": 37, "training_loss": 6.411838779449463, "training_acc": 45.0, "val_loss": 3.330127754211426, "val_acc": 52.0}
{"epoch": 38, "training_loss": 4.0433906030654905, "training_acc": 49.0, "val_loss": 3.039623622894287, "val_acc": 52.0}
{"epoch": 39, "training_loss": 1.6586837911605834, "training_acc": 49.0, "val_loss": 2.814808578491211, "val_acc": 48.0}
{"epoch": 40, "training_loss": 3.0862454557418824, "training_acc": 49.0, "val_loss": 1.263852469921112, "val_acc": 48.0}
{"epoch": 41, "training_loss": 1.575015859603882, "training_acc": 47.0, "val_loss": 0.8123861074447631, "val_acc": 48.0}
{"epoch": 42, "training_loss": 0.8904397487640381, "training_acc": 49.0, "val_loss": 0.6923820447921752, "val_acc": 52.0}
{"epoch": 43, "training_loss": 1.1850975418090821, "training_acc": 53.0, "val_loss": 1.6290215635299683, "val_acc": 48.0}
{"epoch": 44, "training_loss": 1.106007261276245, "training_acc": 49.0, "val_loss": 3.935506572723389, "val_acc": 48.0}
{"epoch": 45, "training_loss": 3.5993628311157226, "training_acc": 43.0, "val_loss": 0.7160539674758911, "val_acc": 48.0}
{"epoch": 46, "training_loss": 1.6192352867126465, "training_acc": 45.0, "val_loss": 0.6956813526153565, "val_acc": 52.0}
{"epoch": 47, "training_loss": 0.9552286458015442, "training_acc": 47.0, "val_loss": 1.496929063796997, "val_acc": 52.0}
{"epoch": 48, "training_loss": 1.3090110397338868, "training_acc": 47.0, "val_loss": 0.7699060440063477, "val_acc": 48.0}
{"epoch": 49, "training_loss": 0.7138093686103821, "training_acc": 53.0, "val_loss": 0.8052267503738403, "val_acc": 48.0}
{"epoch": 50, "training_loss": 1.0592756533622742, "training_acc": 49.0, "val_loss": 2.3067267322540284, "val_acc": 52.0}
{"epoch": 51, "training_loss": 1.0761403799057008, "training_acc": 57.0, "val_loss": 1.4445132088661194, "val_acc": 48.0}
{"epoch": 52, "training_loss": 0.9575590586662293, "training_acc": 47.0, "val_loss": 3.270566101074219, "val_acc": 48.0}
{"epoch": 53, "training_loss": 3.6884149265289308, "training_acc": 53.0, "val_loss": 1.7788301384449006, "val_acc": 48.0}
{"epoch": 54, "training_loss": 1.5243065881729125, "training_acc": 39.0, "val_loss": 0.7138847255706787, "val_acc": 48.0}
{"epoch": 55, "training_loss": 1.3752987480163574, "training_acc": 51.0, "val_loss": 1.5844063663482666, "val_acc": 52.0}
{"epoch": 56, "training_loss": 1.0582248449325562, "training_acc": 59.0, "val_loss": 1.3771954369544983, "val_acc": 52.0}
{"epoch": 57, "training_loss": 0.9680583381652832, "training_acc": 53.0, "val_loss": 0.7385808181762695, "val_acc": 48.0}
{"epoch": 58, "training_loss": 0.7225326871871949, "training_acc": 55.0, "val_loss": 0.8074735379219056, "val_acc": 52.0}
{"epoch": 59, "training_loss": 0.8276570177078247, "training_acc": 57.0, "val_loss": 1.4937625122070313, "val_acc": 52.0}
{"epoch": 60, "training_loss": 1.074777190685272, "training_acc": 59.0, "val_loss": 1.0335541486740112, "val_acc": 52.0}
{"epoch": 61, "training_loss": 0.7727633786201477, "training_acc": 55.0, "val_loss": 0.7812626338005066, "val_acc": 48.0}
