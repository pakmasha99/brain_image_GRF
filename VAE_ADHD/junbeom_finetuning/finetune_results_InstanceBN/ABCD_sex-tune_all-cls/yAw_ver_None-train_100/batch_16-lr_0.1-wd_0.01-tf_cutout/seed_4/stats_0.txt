"main_modify.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 4 --task ABCD_sex --input_option BT_org --learning_rate 1e-1 --batch_size 16 --weight_decay 1e-2 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 10.83487283706665, "training_acc": 48.0, "val_loss": 0.7930422973632812, "val_acc": 44.0}
{"epoch": 1, "training_loss": 7.489767837524414, "training_acc": 48.0, "val_loss": 9.622481346130371, "val_acc": 44.0}
{"epoch": 2, "training_loss": 5.285573196411133, "training_acc": 48.0, "val_loss": 1.099043037891388, "val_acc": 56.0}
{"epoch": 3, "training_loss": 3.695132999420166, "training_acc": 48.0, "val_loss": 1.4558431434631347, "val_acc": 56.0}
{"epoch": 4, "training_loss": 2.3759864139556885, "training_acc": 52.0, "val_loss": 1.8015694999694825, "val_acc": 44.0}
{"epoch": 5, "training_loss": 2.4299979877471922, "training_acc": 42.0, "val_loss": 1.4455145502090454, "val_acc": 44.0}
{"epoch": 6, "training_loss": 2.03985951423645, "training_acc": 50.0, "val_loss": 3.236117401123047, "val_acc": 56.0}
{"epoch": 7, "training_loss": 3.6775567150115966, "training_acc": 48.0, "val_loss": 1.1120902705192566, "val_acc": 56.0}
{"epoch": 8, "training_loss": 1.1165992403030396, "training_acc": 48.0, "val_loss": 0.6956829500198364, "val_acc": 44.0}
{"epoch": 9, "training_loss": 1.0095457553863525, "training_acc": 50.0, "val_loss": 0.8431366968154907, "val_acc": 44.0}
{"epoch": 10, "training_loss": 1.1140528297424317, "training_acc": 46.0, "val_loss": 1.1218609285354615, "val_acc": 44.0}
{"epoch": 11, "training_loss": 0.8689170551300048, "training_acc": 52.0, "val_loss": 0.7308295249938965, "val_acc": 44.0}
{"epoch": 12, "training_loss": 1.0381515407562256, "training_acc": 50.0, "val_loss": 1.8951985359191894, "val_acc": 44.0}
{"epoch": 13, "training_loss": 1.711448210477829, "training_acc": 48.0, "val_loss": 1.242134256362915, "val_acc": 44.0}
{"epoch": 14, "training_loss": 1.0832394337654114, "training_acc": 54.0, "val_loss": 0.9239321184158326, "val_acc": 56.0}
{"epoch": 15, "training_loss": 0.8954986524581909, "training_acc": 52.0, "val_loss": 1.6975528526306152, "val_acc": 56.0}
{"epoch": 16, "training_loss": 1.6854548454284668, "training_acc": 48.0, "val_loss": 3.9418156814575194, "val_acc": 44.0}
{"epoch": 17, "training_loss": 2.9315357065200804, "training_acc": 50.0, "val_loss": 2.23276909828186, "val_acc": 44.0}
{"epoch": 18, "training_loss": 1.1377335739135743, "training_acc": 54.0, "val_loss": 0.9365536832809448, "val_acc": 56.0}
{"epoch": 19, "training_loss": 0.8518823957443238, "training_acc": 54.0, "val_loss": 0.7019416451454162, "val_acc": 44.0}
{"epoch": 20, "training_loss": 0.762606008052826, "training_acc": 50.0, "val_loss": 0.8037249803543091, "val_acc": 44.0}
{"epoch": 21, "training_loss": 0.9759957504272461, "training_acc": 54.0, "val_loss": 0.6878533101081848, "val_acc": 56.0}
{"epoch": 22, "training_loss": 0.84510657787323, "training_acc": 52.0, "val_loss": 0.7415246272087097, "val_acc": 56.0}
{"epoch": 23, "training_loss": 1.2226317930221557, "training_acc": 52.0, "val_loss": 1.2229457187652588, "val_acc": 44.0}
{"epoch": 24, "training_loss": 0.864107358455658, "training_acc": 54.0, "val_loss": 0.9605999565124512, "val_acc": 56.0}
{"epoch": 25, "training_loss": 2.379387712478638, "training_acc": 54.0, "val_loss": 3.4171870470047, "val_acc": 56.0}
{"epoch": 26, "training_loss": 2.167789168357849, "training_acc": 58.0, "val_loss": 1.6561159515380859, "val_acc": 56.0}
{"epoch": 27, "training_loss": 1.0574963235855102, "training_acc": 50.0, "val_loss": 1.4593191051483154, "val_acc": 56.0}
{"epoch": 28, "training_loss": 1.4815264701843263, "training_acc": 44.0, "val_loss": 1.5643231391906738, "val_acc": 56.0}
{"epoch": 29, "training_loss": 1.9034646129608155, "training_acc": 50.0, "val_loss": 1.4476527738571168, "val_acc": 56.0}
{"epoch": 30, "training_loss": 1.683562593460083, "training_acc": 42.0, "val_loss": 1.52374840259552, "val_acc": 56.0}
{"epoch": 31, "training_loss": 1.207812418937683, "training_acc": 52.0, "val_loss": 3.1045295715332033, "val_acc": 44.0}
{"epoch": 32, "training_loss": 2.105423984527588, "training_acc": 56.0, "val_loss": 0.6892815852165222, "val_acc": 56.0}
{"epoch": 33, "training_loss": 1.5808497858047486, "training_acc": 46.0, "val_loss": 1.2735991621017455, "val_acc": 44.0}
{"epoch": 34, "training_loss": 1.1630940675735473, "training_acc": 50.0, "val_loss": 0.6937146782875061, "val_acc": 44.0}
{"epoch": 35, "training_loss": 1.0495459413528443, "training_acc": 48.0, "val_loss": 1.5056997013092042, "val_acc": 56.0}
{"epoch": 36, "training_loss": 1.9294237995147705, "training_acc": 46.0, "val_loss": 6.536050777435303, "val_acc": 44.0}
{"epoch": 37, "training_loss": 5.733647985458374, "training_acc": 46.0, "val_loss": 0.7003237128257751, "val_acc": 56.0}
{"epoch": 38, "training_loss": 1.8854570627212524, "training_acc": 44.0, "val_loss": 0.7968069100379944, "val_acc": 56.0}
{"epoch": 39, "training_loss": 1.3125754117965698, "training_acc": 62.0, "val_loss": 2.929344506263733, "val_acc": 56.0}
{"epoch": 40, "training_loss": 2.3687687969207762, "training_acc": 52.0, "val_loss": 1.286107578277588, "val_acc": 56.0}
