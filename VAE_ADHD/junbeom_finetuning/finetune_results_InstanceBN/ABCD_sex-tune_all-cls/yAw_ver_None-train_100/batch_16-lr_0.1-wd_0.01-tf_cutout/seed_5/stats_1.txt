"main_modify.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 5 --task ABCD_sex --input_option BT_org --learning_rate 1e-1 --batch_size 16 --weight_decay 1e-2 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 10.48933169798809, "training_acc": 47.0, "val_loss": 2.1438672494888307, "val_acc": 52.0}
{"epoch": 1, "training_loss": 3.5856351470947265, "training_acc": 47.0, "val_loss": 1.7128380680084228, "val_acc": 48.0}
{"epoch": 2, "training_loss": 3.6865909576416014, "training_acc": 51.0, "val_loss": 3.3750112199783326, "val_acc": 52.0}
{"epoch": 3, "training_loss": 2.281182360649109, "training_acc": 51.0, "val_loss": 1.809415626525879, "val_acc": 48.0}
{"epoch": 4, "training_loss": 1.5756078052520752, "training_acc": 51.0, "val_loss": 0.7208494114875793, "val_acc": 48.0}
{"epoch": 5, "training_loss": 3.066555609703064, "training_acc": 43.0, "val_loss": 1.4152443170547486, "val_acc": 52.0}
{"epoch": 6, "training_loss": 0.9625175380706787, "training_acc": 51.0, "val_loss": 0.807740216255188, "val_acc": 48.0}
{"epoch": 7, "training_loss": 0.7259810018539429, "training_acc": 55.0, "val_loss": 0.711962628364563, "val_acc": 52.0}
{"epoch": 8, "training_loss": 0.7917509818077088, "training_acc": 47.0, "val_loss": 1.6713787317276, "val_acc": 48.0}
{"epoch": 9, "training_loss": 1.07595228433609, "training_acc": 51.0, "val_loss": 1.182416410446167, "val_acc": 52.0}
{"epoch": 10, "training_loss": 3.8369169425964356, "training_acc": 43.0, "val_loss": 4.4184716606140135, "val_acc": 52.0}
{"epoch": 11, "training_loss": 2.462225708961487, "training_acc": 53.0, "val_loss": 2.4871332263946533, "val_acc": 52.0}
{"epoch": 12, "training_loss": 1.0979094791412354, "training_acc": 63.0, "val_loss": 1.5140701532363892, "val_acc": 48.0}
{"epoch": 13, "training_loss": 1.0617146492004395, "training_acc": 51.0, "val_loss": 1.477269597053528, "val_acc": 48.0}
{"epoch": 14, "training_loss": 1.3110270404815674, "training_acc": 55.0, "val_loss": 1.0217533993721009, "val_acc": 52.0}
{"epoch": 15, "training_loss": 1.0837360763549804, "training_acc": 53.0, "val_loss": 2.8146176528930664, "val_acc": 48.0}
{"epoch": 16, "training_loss": 2.982275953292847, "training_acc": 49.0, "val_loss": 4.0044400596618654, "val_acc": 48.0}
{"epoch": 17, "training_loss": 3.2375592041015624, "training_acc": 53.0, "val_loss": 4.029269075393676, "val_acc": 48.0}
{"epoch": 18, "training_loss": 3.906539936065674, "training_acc": 55.0, "val_loss": 5.15371337890625, "val_acc": 52.0}
{"epoch": 19, "training_loss": 5.398805618286133, "training_acc": 45.0, "val_loss": 6.603299942016601, "val_acc": 52.0}
{"epoch": 20, "training_loss": 5.7605061531066895, "training_acc": 45.0, "val_loss": 1.0879397583007813, "val_acc": 48.0}
{"epoch": 21, "training_loss": 3.951129322052002, "training_acc": 49.0, "val_loss": 3.0129504585266114, "val_acc": 48.0}
{"epoch": 22, "training_loss": 2.5736739158630373, "training_acc": 47.0, "val_loss": 5.614790630340576, "val_acc": 48.0}
{"epoch": 23, "training_loss": 2.824982843399048, "training_acc": 47.0, "val_loss": 1.2959758520126343, "val_acc": 48.0}
{"epoch": 24, "training_loss": 0.7698503494262695, "training_acc": 55.0, "val_loss": 1.1986144828796386, "val_acc": 52.0}
{"epoch": 25, "training_loss": 1.0497414135932923, "training_acc": 53.0, "val_loss": 1.0490994882583617, "val_acc": 48.0}
{"epoch": 26, "training_loss": 1.2791417241096497, "training_acc": 43.0, "val_loss": 0.692786099910736, "val_acc": 52.0}
{"epoch": 27, "training_loss": 0.9471231603622436, "training_acc": 45.0, "val_loss": 2.4355945014953613, "val_acc": 48.0}
{"epoch": 28, "training_loss": 1.1871792030334474, "training_acc": 59.0, "val_loss": 0.6988994145393371, "val_acc": 48.0}
{"epoch": 29, "training_loss": 0.8539510726928711, "training_acc": 49.0, "val_loss": 2.745660219192505, "val_acc": 52.0}
{"epoch": 30, "training_loss": 1.3950233840942383, "training_acc": 51.0, "val_loss": 1.4316969347000121, "val_acc": 48.0}
{"epoch": 31, "training_loss": 1.0748215055465697, "training_acc": 59.0, "val_loss": 1.4698552370071412, "val_acc": 52.0}
{"epoch": 32, "training_loss": 1.5954660010337829, "training_acc": 47.0, "val_loss": 1.4158786821365357, "val_acc": 48.0}
{"epoch": 33, "training_loss": 0.9378777575492859, "training_acc": 49.0, "val_loss": 1.291986117362976, "val_acc": 52.0}
{"epoch": 34, "training_loss": 1.1688257884979247, "training_acc": 53.0, "val_loss": 1.4724455928802491, "val_acc": 48.0}
{"epoch": 35, "training_loss": 1.5879197311401367, "training_acc": 43.0, "val_loss": 3.5561250114440917, "val_acc": 48.0}
{"epoch": 36, "training_loss": 2.213094334602356, "training_acc": 57.0, "val_loss": 2.3585666370391847, "val_acc": 48.0}
{"epoch": 37, "training_loss": 1.205753297805786, "training_acc": 57.0, "val_loss": 1.2148356747627258, "val_acc": 52.0}
{"epoch": 38, "training_loss": 1.0935394144058228, "training_acc": 45.0, "val_loss": 3.4557764530181885, "val_acc": 52.0}
{"epoch": 39, "training_loss": 1.9509100532531738, "training_acc": 53.0, "val_loss": 0.7260065770149231, "val_acc": 52.0}
{"epoch": 40, "training_loss": 1.2614759850502013, "training_acc": 41.0, "val_loss": 0.8065852355957032, "val_acc": 52.0}
{"epoch": 41, "training_loss": 0.9374878144264222, "training_acc": 41.0, "val_loss": 1.1211274647712708, "val_acc": 48.0}
{"epoch": 42, "training_loss": 1.4362242007255555, "training_acc": 37.0, "val_loss": 4.931210269927979, "val_acc": 48.0}
{"epoch": 43, "training_loss": 4.4752555847167965, "training_acc": 57.0, "val_loss": 5.661241235733033, "val_acc": 52.0}
{"epoch": 44, "training_loss": 3.4148431491851805, "training_acc": 61.0, "val_loss": 2.0480437707901, "val_acc": 52.0}
{"epoch": 45, "training_loss": 1.5862213778495788, "training_acc": 55.0, "val_loss": 2.0653681921958924, "val_acc": 52.0}
