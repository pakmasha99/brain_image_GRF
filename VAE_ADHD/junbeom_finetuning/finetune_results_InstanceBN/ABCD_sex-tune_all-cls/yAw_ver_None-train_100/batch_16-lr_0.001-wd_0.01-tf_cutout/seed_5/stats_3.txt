"main_modify.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 5 --task ABCD_sex --input_option BT_org --learning_rate 1e-3 --batch_size 16 --weight_decay 1e-2 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 0.723006341457367, "training_acc": 53.0, "val_loss": 0.7092304372787476, "val_acc": 52.0}
{"epoch": 1, "training_loss": 0.7557079029083252, "training_acc": 53.0, "val_loss": 0.6984789299964905, "val_acc": 52.0}
{"epoch": 2, "training_loss": 0.7000728130340577, "training_acc": 45.0, "val_loss": 0.6928934574127197, "val_acc": 52.0}
{"epoch": 3, "training_loss": 0.6957040643692016, "training_acc": 51.0, "val_loss": 0.6928536319732665, "val_acc": 52.0}
{"epoch": 4, "training_loss": 0.6946205806732177, "training_acc": 49.0, "val_loss": 0.7111069178581237, "val_acc": 52.0}
{"epoch": 5, "training_loss": 0.7012063765525818, "training_acc": 53.0, "val_loss": 0.6939632058143616, "val_acc": 52.0}
{"epoch": 6, "training_loss": 0.7032399487495422, "training_acc": 41.0, "val_loss": 0.6928785252571106, "val_acc": 52.0}
{"epoch": 7, "training_loss": 0.6960285973548889, "training_acc": 53.0, "val_loss": 0.693113739490509, "val_acc": 52.0}
{"epoch": 8, "training_loss": 0.7079646730422974, "training_acc": 39.0, "val_loss": 0.6944909024238587, "val_acc": 52.0}
{"epoch": 9, "training_loss": 0.7142646455764771, "training_acc": 53.0, "val_loss": 0.6946371960639953, "val_acc": 52.0}
{"epoch": 10, "training_loss": 0.7145785522460938, "training_acc": 41.0, "val_loss": 0.6923783349990845, "val_acc": 52.0}
{"epoch": 11, "training_loss": 0.6967561364173889, "training_acc": 53.0, "val_loss": 0.6974861645698547, "val_acc": 52.0}
{"epoch": 12, "training_loss": 0.6993088436126709, "training_acc": 53.0, "val_loss": 0.7029865789413452, "val_acc": 52.0}
{"epoch": 13, "training_loss": 0.6994082951545715, "training_acc": 53.0, "val_loss": 0.693900215625763, "val_acc": 52.0}
{"epoch": 14, "training_loss": 0.6945769119262696, "training_acc": 53.0, "val_loss": 0.6941701745986939, "val_acc": 48.0}
{"epoch": 15, "training_loss": 0.7035120201110839, "training_acc": 47.0, "val_loss": 0.6928713035583496, "val_acc": 52.0}
{"epoch": 16, "training_loss": 0.7114843535423279, "training_acc": 53.0, "val_loss": 0.6931865549087525, "val_acc": 52.0}
{"epoch": 17, "training_loss": 0.6971494293212891, "training_acc": 41.0, "val_loss": 0.6923751497268676, "val_acc": 52.0}
{"epoch": 18, "training_loss": 0.6962914180755615, "training_acc": 53.0, "val_loss": 0.6931387090682983, "val_acc": 52.0}
{"epoch": 19, "training_loss": 0.7030515098571777, "training_acc": 49.0, "val_loss": 0.6923765563964843, "val_acc": 52.0}
{"epoch": 20, "training_loss": 0.6941517210006714, "training_acc": 53.0, "val_loss": 0.6943880438804626, "val_acc": 52.0}
{"epoch": 21, "training_loss": 0.6904368352890015, "training_acc": 53.0, "val_loss": 0.6968341016769409, "val_acc": 48.0}
{"epoch": 22, "training_loss": 0.7062449121475219, "training_acc": 47.0, "val_loss": 0.6924083638191223, "val_acc": 52.0}
{"epoch": 23, "training_loss": 0.6926406741142273, "training_acc": 53.0, "val_loss": 0.7022610139846802, "val_acc": 52.0}
{"epoch": 24, "training_loss": 0.7057471060752869, "training_acc": 53.0, "val_loss": 0.6961610269546509, "val_acc": 52.0}
{"epoch": 25, "training_loss": 0.6958742761611938, "training_acc": 53.0, "val_loss": 0.6926022338867187, "val_acc": 52.0}
{"epoch": 26, "training_loss": 0.7060560512542725, "training_acc": 39.0, "val_loss": 0.6931103181838989, "val_acc": 52.0}
{"epoch": 27, "training_loss": 0.7001426410675049, "training_acc": 51.0, "val_loss": 0.6927713441848755, "val_acc": 52.0}
{"epoch": 28, "training_loss": 0.691022207736969, "training_acc": 53.0, "val_loss": 0.6955509233474731, "val_acc": 52.0}
{"epoch": 29, "training_loss": 0.6968781161308288, "training_acc": 45.0, "val_loss": 0.6924004197120667, "val_acc": 52.0}
{"epoch": 30, "training_loss": 0.6960555458068848, "training_acc": 51.0, "val_loss": 0.6925486850738526, "val_acc": 52.0}
{"epoch": 31, "training_loss": 0.6974642896652221, "training_acc": 43.0, "val_loss": 0.6923546409606933, "val_acc": 52.0}
{"epoch": 32, "training_loss": 0.6997317266464234, "training_acc": 53.0, "val_loss": 0.6925413107872009, "val_acc": 52.0}
{"epoch": 33, "training_loss": 0.7015214610099793, "training_acc": 43.0, "val_loss": 0.6940075349807739, "val_acc": 52.0}
{"epoch": 34, "training_loss": 0.695478253364563, "training_acc": 53.0, "val_loss": 0.7069179105758667, "val_acc": 52.0}
{"epoch": 35, "training_loss": 0.7082838201522828, "training_acc": 53.0, "val_loss": 0.6956246042251587, "val_acc": 52.0}
{"epoch": 36, "training_loss": 0.6987299513816834, "training_acc": 53.0, "val_loss": 0.6929745602607728, "val_acc": 52.0}
{"epoch": 37, "training_loss": 0.7000664925575256, "training_acc": 49.0, "val_loss": 0.6923553466796875, "val_acc": 52.0}
{"epoch": 38, "training_loss": 0.7090955829620361, "training_acc": 53.0, "val_loss": 0.7047362446784973, "val_acc": 52.0}
{"epoch": 39, "training_loss": 0.7078362131118774, "training_acc": 53.0, "val_loss": 0.6948732495307922, "val_acc": 48.0}
{"epoch": 40, "training_loss": 0.7219406914710998, "training_acc": 47.0, "val_loss": 0.6923977565765381, "val_acc": 52.0}
{"epoch": 41, "training_loss": 0.7022498083114624, "training_acc": 53.0, "val_loss": 0.6967085170745849, "val_acc": 52.0}
{"epoch": 42, "training_loss": 0.6917570447921753, "training_acc": 49.0, "val_loss": 0.6973343658447265, "val_acc": 48.0}
{"epoch": 43, "training_loss": 0.7085835933685303, "training_acc": 41.0, "val_loss": 0.6926768898963929, "val_acc": 52.0}
{"epoch": 44, "training_loss": 0.6923501586914063, "training_acc": 53.0, "val_loss": 0.6972416305541992, "val_acc": 52.0}
{"epoch": 45, "training_loss": 0.7036054539680481, "training_acc": 53.0, "val_loss": 0.695997838973999, "val_acc": 52.0}
{"epoch": 46, "training_loss": 0.698879005908966, "training_acc": 53.0, "val_loss": 0.699413914680481, "val_acc": 52.0}
{"epoch": 47, "training_loss": 0.7035395717620849, "training_acc": 53.0, "val_loss": 0.6980789113044739, "val_acc": 52.0}
{"epoch": 48, "training_loss": 0.698768572807312, "training_acc": 53.0, "val_loss": 0.6979111385345459, "val_acc": 48.0}
{"epoch": 49, "training_loss": 0.7220405101776123, "training_acc": 47.0, "val_loss": 0.698882942199707, "val_acc": 48.0}
{"epoch": 50, "training_loss": 0.7019383358955383, "training_acc": 47.0, "val_loss": 0.6931510663032532, "val_acc": 48.0}
