"main_modify.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 7 --task ABCD_sex --input_option BT_org --learning_rate 1e-3 --batch_size 16 --weight_decay 1e-2 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 0.7002662682533264, "training_acc": 49.0, "val_loss": 0.7209178471565246, "val_acc": 52.0}
{"epoch": 1, "training_loss": 0.7097384810447693, "training_acc": 53.0, "val_loss": 0.692902500629425, "val_acc": 52.0}
{"epoch": 2, "training_loss": 0.6970344638824463, "training_acc": 47.0, "val_loss": 0.697804925441742, "val_acc": 52.0}
{"epoch": 3, "training_loss": 0.7036265349388122, "training_acc": 52.0, "val_loss": 0.6930783295631409, "val_acc": 52.0}
{"epoch": 4, "training_loss": 0.7032246017456054, "training_acc": 53.0, "val_loss": 0.7048104214668274, "val_acc": 52.0}
{"epoch": 5, "training_loss": 0.7022212076187134, "training_acc": 53.0, "val_loss": 0.7060299849510193, "val_acc": 52.0}
{"epoch": 6, "training_loss": 0.7112017583847046, "training_acc": 53.0, "val_loss": 0.6949533796310425, "val_acc": 52.0}
{"epoch": 7, "training_loss": 0.7101343631744385, "training_acc": 44.0, "val_loss": 0.692414402961731, "val_acc": 52.0}
{"epoch": 8, "training_loss": 0.7255487370491028, "training_acc": 53.0, "val_loss": 0.7043664622306823, "val_acc": 52.0}
{"epoch": 9, "training_loss": 0.6970546340942383, "training_acc": 51.0, "val_loss": 0.6926301264762879, "val_acc": 52.0}
{"epoch": 10, "training_loss": 0.6940592217445374, "training_acc": 53.0, "val_loss": 0.6925164031982421, "val_acc": 52.0}
{"epoch": 11, "training_loss": 0.6946326780319214, "training_acc": 53.0, "val_loss": 0.6935983729362488, "val_acc": 48.0}
{"epoch": 12, "training_loss": 0.7022234535217285, "training_acc": 39.0, "val_loss": 0.6953958439826965, "val_acc": 48.0}
{"epoch": 13, "training_loss": 0.7045928335189819, "training_acc": 41.0, "val_loss": 0.6960882568359374, "val_acc": 48.0}
{"epoch": 14, "training_loss": 0.7047744512557983, "training_acc": 49.0, "val_loss": 0.6947599363327026, "val_acc": 52.0}
{"epoch": 15, "training_loss": 0.7033575606346131, "training_acc": 53.0, "val_loss": 0.7000343823432922, "val_acc": 52.0}
{"epoch": 16, "training_loss": 0.69805011510849, "training_acc": 53.0, "val_loss": 0.6935803151130676, "val_acc": 52.0}
{"epoch": 17, "training_loss": 0.6957542467117309, "training_acc": 53.0, "val_loss": 0.6928500342369079, "val_acc": 52.0}
{"epoch": 18, "training_loss": 0.6942378640174866, "training_acc": 53.0, "val_loss": 0.6939159035682678, "val_acc": 48.0}
{"epoch": 19, "training_loss": 0.6954970574378967, "training_acc": 47.0, "val_loss": 0.6923946499824524, "val_acc": 52.0}
{"epoch": 20, "training_loss": 0.6947949266433716, "training_acc": 53.0, "val_loss": 0.694319543838501, "val_acc": 48.0}
{"epoch": 21, "training_loss": 0.6987762355804443, "training_acc": 43.0, "val_loss": 0.7000249052047729, "val_acc": 48.0}
{"epoch": 22, "training_loss": 0.7128255462646484, "training_acc": 47.0, "val_loss": 0.6924071192741394, "val_acc": 52.0}
{"epoch": 23, "training_loss": 0.7017858028411865, "training_acc": 53.0, "val_loss": 0.698198390007019, "val_acc": 52.0}
{"epoch": 24, "training_loss": 0.7050357246398926, "training_acc": 53.0, "val_loss": 0.6932266330718995, "val_acc": 52.0}
{"epoch": 25, "training_loss": 0.7048134851455689, "training_acc": 45.0, "val_loss": 0.7024699759483337, "val_acc": 48.0}
{"epoch": 26, "training_loss": 0.704419002532959, "training_acc": 47.0, "val_loss": 0.6923590278625489, "val_acc": 52.0}
{"epoch": 27, "training_loss": 0.7039788579940796, "training_acc": 53.0, "val_loss": 0.6972254800796509, "val_acc": 52.0}
{"epoch": 28, "training_loss": 0.7010449290275573, "training_acc": 53.0, "val_loss": 0.6974470591545106, "val_acc": 52.0}
{"epoch": 29, "training_loss": 0.7008295679092407, "training_acc": 53.0, "val_loss": 0.6938960337638855, "val_acc": 52.0}
{"epoch": 30, "training_loss": 0.7082536149024964, "training_acc": 41.0, "val_loss": 0.6926885581016541, "val_acc": 52.0}
{"epoch": 31, "training_loss": 0.6995889973640442, "training_acc": 53.0, "val_loss": 0.6923995590209961, "val_acc": 52.0}
{"epoch": 32, "training_loss": 0.7053363132476806, "training_acc": 41.0, "val_loss": 0.6952477478981018, "val_acc": 52.0}
{"epoch": 33, "training_loss": 0.7053358888626099, "training_acc": 53.0, "val_loss": 0.6928907442092895, "val_acc": 52.0}
{"epoch": 34, "training_loss": 0.7206978559494018, "training_acc": 41.0, "val_loss": 0.6966604804992675, "val_acc": 48.0}
{"epoch": 35, "training_loss": 0.684410707950592, "training_acc": 57.0, "val_loss": 0.7112859296798706, "val_acc": 52.0}
{"epoch": 36, "training_loss": 0.7139817452430726, "training_acc": 53.0, "val_loss": 0.69431973695755, "val_acc": 52.0}
{"epoch": 37, "training_loss": 0.6918757176399231, "training_acc": 53.0, "val_loss": 0.6932618308067322, "val_acc": 48.0}
{"epoch": 38, "training_loss": 0.7075125980377197, "training_acc": 45.0, "val_loss": 0.6924519968032837, "val_acc": 52.0}
{"epoch": 39, "training_loss": 0.6937766480445862, "training_acc": 53.0, "val_loss": 0.6923490357398987, "val_acc": 52.0}
{"epoch": 40, "training_loss": 0.6937759351730347, "training_acc": 51.0, "val_loss": 0.6924443411827087, "val_acc": 52.0}
{"epoch": 41, "training_loss": 0.7034509420394898, "training_acc": 53.0, "val_loss": 0.6925405788421631, "val_acc": 52.0}
{"epoch": 42, "training_loss": 0.70185227394104, "training_acc": 47.0, "val_loss": 0.693173439502716, "val_acc": 48.0}
{"epoch": 43, "training_loss": 0.6943578743934631, "training_acc": 51.0, "val_loss": 0.6997342348098755, "val_acc": 52.0}
{"epoch": 44, "training_loss": 0.7075608444213867, "training_acc": 53.0, "val_loss": 0.703697280883789, "val_acc": 52.0}
{"epoch": 45, "training_loss": 0.7019637513160706, "training_acc": 53.0, "val_loss": 0.6923579049110412, "val_acc": 52.0}
{"epoch": 46, "training_loss": 0.7019572019577026, "training_acc": 49.0, "val_loss": 0.7002032780647278, "val_acc": 48.0}
{"epoch": 47, "training_loss": 0.7052700567245483, "training_acc": 41.0, "val_loss": 0.6931827449798584, "val_acc": 48.0}
{"epoch": 48, "training_loss": 0.7015425848960877, "training_acc": 49.0, "val_loss": 0.6931778931617737, "val_acc": 48.0}
{"epoch": 49, "training_loss": 0.7020152163505554, "training_acc": 43.0, "val_loss": 0.6973847651481628, "val_acc": 48.0}
{"epoch": 50, "training_loss": 0.7030552768707276, "training_acc": 43.0, "val_loss": 0.6945971608161926, "val_acc": 48.0}
{"epoch": 51, "training_loss": 0.6965637564659118, "training_acc": 47.0, "val_loss": 0.6924313855171204, "val_acc": 52.0}
{"epoch": 52, "training_loss": 0.7028274893760681, "training_acc": 53.0, "val_loss": 0.6978608751296997, "val_acc": 52.0}
{"epoch": 53, "training_loss": 0.7021847200393677, "training_acc": 53.0, "val_loss": 0.6929410886764527, "val_acc": 52.0}
{"epoch": 54, "training_loss": 0.694334683418274, "training_acc": 53.0, "val_loss": 0.694421923160553, "val_acc": 52.0}
{"epoch": 55, "training_loss": 0.70019611120224, "training_acc": 53.0, "val_loss": 0.6957549691200257, "val_acc": 52.0}
{"epoch": 56, "training_loss": 0.6996203422546386, "training_acc": 53.0, "val_loss": 0.6925321745872498, "val_acc": 52.0}
{"epoch": 57, "training_loss": 0.6964704799652099, "training_acc": 47.0, "val_loss": 0.6925680112838745, "val_acc": 52.0}
{"epoch": 58, "training_loss": 0.7026069402694702, "training_acc": 39.0, "val_loss": 0.69234708070755, "val_acc": 52.0}
{"epoch": 59, "training_loss": 0.6968566751480103, "training_acc": 49.0, "val_loss": 0.6970387554168701, "val_acc": 52.0}
{"epoch": 60, "training_loss": 0.7088564491271973, "training_acc": 53.0, "val_loss": 0.7053524494171143, "val_acc": 52.0}
{"epoch": 61, "training_loss": 0.703979766368866, "training_acc": 53.0, "val_loss": 0.6923587894439698, "val_acc": 52.0}
{"epoch": 62, "training_loss": 0.7061468052864075, "training_acc": 39.0, "val_loss": 0.6934000086784363, "val_acc": 48.0}
{"epoch": 63, "training_loss": 0.6987920475006103, "training_acc": 47.0, "val_loss": 0.6923470330238343, "val_acc": 52.0}
{"epoch": 64, "training_loss": 0.6912689447402954, "training_acc": 53.0, "val_loss": 0.6991177821159362, "val_acc": 52.0}
{"epoch": 65, "training_loss": 0.7023310375213623, "training_acc": 53.0, "val_loss": 0.6979265689849854, "val_acc": 52.0}
{"epoch": 66, "training_loss": 0.7060003089904785, "training_acc": 53.0, "val_loss": 0.692567036151886, "val_acc": 52.0}
{"epoch": 67, "training_loss": 0.705278959274292, "training_acc": 45.0, "val_loss": 0.7001128268241882, "val_acc": 48.0}
{"epoch": 68, "training_loss": 0.6994330644607544, "training_acc": 47.0, "val_loss": 0.6929186248779297, "val_acc": 52.0}
{"epoch": 69, "training_loss": 0.7006571674346924, "training_acc": 53.0, "val_loss": 0.6986383152008057, "val_acc": 52.0}
{"epoch": 70, "training_loss": 0.7026087808609008, "training_acc": 53.0, "val_loss": 0.692377507686615, "val_acc": 52.0}
{"epoch": 71, "training_loss": 0.6961604738235474, "training_acc": 51.0, "val_loss": 0.6923712134361267, "val_acc": 52.0}
{"epoch": 72, "training_loss": 0.7046197748184204, "training_acc": 41.0, "val_loss": 0.6981282353401184, "val_acc": 52.0}
{"epoch": 73, "training_loss": 0.6958265209197998, "training_acc": 53.0, "val_loss": 0.6923550391197204, "val_acc": 52.0}
{"epoch": 74, "training_loss": 0.7029153871536254, "training_acc": 49.0, "val_loss": 0.6939130306243897, "val_acc": 48.0}
{"epoch": 75, "training_loss": 0.6913290047645568, "training_acc": 47.0, "val_loss": 0.7085863852500915, "val_acc": 52.0}
{"epoch": 76, "training_loss": 0.7050007629394531, "training_acc": 53.0, "val_loss": 0.6930991291999817, "val_acc": 52.0}
{"epoch": 77, "training_loss": 0.7012290787696839, "training_acc": 47.0, "val_loss": 0.6929127073287964, "val_acc": 52.0}
{"epoch": 78, "training_loss": 0.6995576190948486, "training_acc": 53.0, "val_loss": 0.7006866550445556, "val_acc": 52.0}
{"epoch": 79, "training_loss": 0.7009037733078003, "training_acc": 53.0, "val_loss": 0.6927460527420044, "val_acc": 52.0}
{"epoch": 80, "training_loss": 0.7030084490776062, "training_acc": 45.0, "val_loss": 0.6928154349327087, "val_acc": 52.0}
{"epoch": 81, "training_loss": 0.6924654984474182, "training_acc": 53.0, "val_loss": 0.6931019139289856, "val_acc": 52.0}
{"epoch": 82, "training_loss": 0.7099697589874268, "training_acc": 53.0, "val_loss": 0.69296954870224, "val_acc": 52.0}
