"main_modify.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 3 --task ABCD_sex --input_option BT_org --learning_rate 1e-3 --batch_size 16 --weight_decay 1e-2 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 0.7399601197242737, "training_acc": 45.0, "val_loss": 0.6962852621078491, "val_acc": 48.0}
{"epoch": 1, "training_loss": 0.6913704085350036, "training_acc": 55.0, "val_loss": 0.6956950402259827, "val_acc": 52.0}
{"epoch": 2, "training_loss": 0.6960484719276429, "training_acc": 53.0, "val_loss": 0.6930475616455078, "val_acc": 52.0}
{"epoch": 3, "training_loss": 0.7033857917785644, "training_acc": 51.0, "val_loss": 0.6925776624679565, "val_acc": 52.0}
{"epoch": 4, "training_loss": 0.6997418689727783, "training_acc": 47.0, "val_loss": 0.698114562034607, "val_acc": 52.0}
{"epoch": 5, "training_loss": 0.7033390736579895, "training_acc": 53.0, "val_loss": 0.6965282320976257, "val_acc": 52.0}
{"epoch": 6, "training_loss": 0.6977319097518921, "training_acc": 49.0, "val_loss": 0.6937346601486206, "val_acc": 52.0}
{"epoch": 7, "training_loss": 0.7071128249168396, "training_acc": 53.0, "val_loss": 0.6987828302383423, "val_acc": 52.0}
{"epoch": 8, "training_loss": 0.6947417068481445, "training_acc": 53.0, "val_loss": 0.6937823247909546, "val_acc": 52.0}
{"epoch": 9, "training_loss": 0.6901319885253906, "training_acc": 53.0, "val_loss": 0.6967912244796753, "val_acc": 48.0}
{"epoch": 10, "training_loss": 0.699050223827362, "training_acc": 43.0, "val_loss": 0.6926996588706971, "val_acc": 52.0}
{"epoch": 11, "training_loss": 0.6997277975082398, "training_acc": 53.0, "val_loss": 0.703067774772644, "val_acc": 52.0}
{"epoch": 12, "training_loss": 0.712060067653656, "training_acc": 53.0, "val_loss": 0.6962573313713074, "val_acc": 52.0}
{"epoch": 13, "training_loss": 0.6986650562286377, "training_acc": 47.0, "val_loss": 0.6978004193305969, "val_acc": 48.0}
{"epoch": 14, "training_loss": 0.6969105195999146, "training_acc": 49.0, "val_loss": 0.692828221321106, "val_acc": 52.0}
{"epoch": 15, "training_loss": 0.7090217208862305, "training_acc": 53.0, "val_loss": 0.6938878345489502, "val_acc": 48.0}
{"epoch": 16, "training_loss": 0.7131436538696289, "training_acc": 47.0, "val_loss": 0.6924690651893616, "val_acc": 52.0}
{"epoch": 17, "training_loss": 0.723459177017212, "training_acc": 53.0, "val_loss": 0.6991835284233093, "val_acc": 52.0}
{"epoch": 18, "training_loss": 0.7343897652626038, "training_acc": 35.0, "val_loss": 0.6937638950347901, "val_acc": 48.0}
{"epoch": 19, "training_loss": 0.7008626580238342, "training_acc": 53.0, "val_loss": 0.6986397957801819, "val_acc": 52.0}
{"epoch": 20, "training_loss": 0.6923149204254151, "training_acc": 51.0, "val_loss": 0.6930115938186645, "val_acc": 52.0}
{"epoch": 21, "training_loss": 0.7068424296379089, "training_acc": 53.0, "val_loss": 0.6931391143798828, "val_acc": 52.0}
{"epoch": 22, "training_loss": 0.694568133354187, "training_acc": 53.0, "val_loss": 0.6923890137672424, "val_acc": 52.0}
{"epoch": 23, "training_loss": 0.7019840478897095, "training_acc": 43.0, "val_loss": 0.6923672080039978, "val_acc": 52.0}
{"epoch": 24, "training_loss": 0.70291832447052, "training_acc": 53.0, "val_loss": 0.6925333452224731, "val_acc": 52.0}
{"epoch": 25, "training_loss": 0.7034222173690796, "training_acc": 41.0, "val_loss": 0.6939754557609558, "val_acc": 48.0}
{"epoch": 26, "training_loss": 0.6978986501693726, "training_acc": 47.0, "val_loss": 0.6966667532920837, "val_acc": 48.0}
{"epoch": 27, "training_loss": 0.7024791240692139, "training_acc": 45.0, "val_loss": 0.6936325907707215, "val_acc": 52.0}
{"epoch": 28, "training_loss": 0.7043329429626465, "training_acc": 53.0, "val_loss": 0.6927844166755677, "val_acc": 52.0}
{"epoch": 29, "training_loss": 0.6944970917701722, "training_acc": 51.0, "val_loss": 0.6930946564674377, "val_acc": 52.0}
{"epoch": 30, "training_loss": 0.7108471393585205, "training_acc": 53.0, "val_loss": 0.6952145504951477, "val_acc": 52.0}
{"epoch": 31, "training_loss": 0.6950916242599487, "training_acc": 53.0, "val_loss": 0.6925382781028747, "val_acc": 52.0}
{"epoch": 32, "training_loss": 0.6955682754516601, "training_acc": 53.0, "val_loss": 0.6962363553047181, "val_acc": 52.0}
{"epoch": 33, "training_loss": 0.6955558466911316, "training_acc": 53.0, "val_loss": 0.6995521926879883, "val_acc": 52.0}
{"epoch": 34, "training_loss": 0.7083518600463867, "training_acc": 53.0, "val_loss": 0.6931383442878724, "val_acc": 52.0}
{"epoch": 35, "training_loss": 0.6947727060317993, "training_acc": 53.0, "val_loss": 0.6945211863517762, "val_acc": 48.0}
{"epoch": 36, "training_loss": 0.691206750869751, "training_acc": 55.0, "val_loss": 0.6976957654953003, "val_acc": 52.0}
{"epoch": 37, "training_loss": 0.6998902201652527, "training_acc": 53.0, "val_loss": 0.6946418023109436, "val_acc": 52.0}
{"epoch": 38, "training_loss": 0.6995642828941345, "training_acc": 53.0, "val_loss": 0.6925397968292236, "val_acc": 52.0}
{"epoch": 39, "training_loss": 0.706828556060791, "training_acc": 45.0, "val_loss": 0.6946794605255127, "val_acc": 48.0}
{"epoch": 40, "training_loss": 0.6951822566986084, "training_acc": 49.0, "val_loss": 0.6952521204948425, "val_acc": 52.0}
{"epoch": 41, "training_loss": 0.6953622579574585, "training_acc": 53.0, "val_loss": 0.6928628134727478, "val_acc": 52.0}
{"epoch": 42, "training_loss": 0.7045421552658081, "training_acc": 39.0, "val_loss": 0.6937946820259094, "val_acc": 48.0}
