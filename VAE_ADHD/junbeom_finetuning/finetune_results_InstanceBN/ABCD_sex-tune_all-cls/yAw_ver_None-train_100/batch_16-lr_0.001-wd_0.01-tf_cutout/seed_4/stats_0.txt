"main_modify.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 4 --task ABCD_sex --input_option BT_org --learning_rate 1e-3 --batch_size 16 --weight_decay 1e-2 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 0.6987060189247132, "training_acc": 53.0, "val_loss": 0.6860821342468262, "val_acc": 56.0}
{"epoch": 1, "training_loss": 0.7087031745910645, "training_acc": 52.0, "val_loss": 0.6885396122932435, "val_acc": 56.0}
{"epoch": 2, "training_loss": 0.6950053405761719, "training_acc": 52.0, "val_loss": 0.7002974605560303, "val_acc": 44.0}
{"epoch": 3, "training_loss": 0.7046199560165405, "training_acc": 42.0, "val_loss": 0.6963058948516846, "val_acc": 44.0}
{"epoch": 4, "training_loss": 0.7110686016082763, "training_acc": 50.0, "val_loss": 0.6864188575744629, "val_acc": 56.0}
{"epoch": 5, "training_loss": 0.6984529232978821, "training_acc": 50.0, "val_loss": 0.6865595030784607, "val_acc": 56.0}
{"epoch": 6, "training_loss": 0.7048833799362183, "training_acc": 48.0, "val_loss": 0.6860772395133972, "val_acc": 56.0}
{"epoch": 7, "training_loss": 0.6974869060516358, "training_acc": 52.0, "val_loss": 0.6873767781257629, "val_acc": 56.0}
{"epoch": 8, "training_loss": 0.7025582933425903, "training_acc": 40.0, "val_loss": 0.6879224133491516, "val_acc": 56.0}
{"epoch": 9, "training_loss": 0.7043848896026611, "training_acc": 42.0, "val_loss": 0.6881694746017456, "val_acc": 56.0}
{"epoch": 10, "training_loss": 0.69863853931427, "training_acc": 44.0, "val_loss": 0.6861270356178284, "val_acc": 56.0}
{"epoch": 11, "training_loss": 0.6966692376136779, "training_acc": 52.0, "val_loss": 0.6862884330749511, "val_acc": 56.0}
{"epoch": 12, "training_loss": 0.7072811031341553, "training_acc": 52.0, "val_loss": 0.7038466119766236, "val_acc": 44.0}
{"epoch": 13, "training_loss": 0.7048815202713012, "training_acc": 48.0, "val_loss": 0.7323153972625732, "val_acc": 44.0}
{"epoch": 14, "training_loss": 0.7140885210037231, "training_acc": 48.0, "val_loss": 0.6910290837287902, "val_acc": 56.0}
{"epoch": 15, "training_loss": 0.7222000932693482, "training_acc": 52.0, "val_loss": 0.6861197400093079, "val_acc": 56.0}
{"epoch": 16, "training_loss": 0.6997737550735473, "training_acc": 52.0, "val_loss": 0.6946003293991089, "val_acc": 44.0}
{"epoch": 17, "training_loss": 0.7021475458145141, "training_acc": 48.0, "val_loss": 0.7003604531288147, "val_acc": 44.0}
{"epoch": 18, "training_loss": 0.6959565639495849, "training_acc": 50.0, "val_loss": 0.686428291797638, "val_acc": 56.0}
{"epoch": 19, "training_loss": 0.7030702638626098, "training_acc": 52.0, "val_loss": 0.6860810780525207, "val_acc": 56.0}
{"epoch": 20, "training_loss": 0.6965851545333862, "training_acc": 52.0, "val_loss": 0.6890309929847718, "val_acc": 56.0}
{"epoch": 21, "training_loss": 0.6995991110801697, "training_acc": 52.0, "val_loss": 0.6996416568756103, "val_acc": 44.0}
{"epoch": 22, "training_loss": 0.7061094379425049, "training_acc": 48.0, "val_loss": 0.6972195506095886, "val_acc": 44.0}
{"epoch": 23, "training_loss": 0.7095005702972412, "training_acc": 48.0, "val_loss": 0.6859530520439148, "val_acc": 56.0}
{"epoch": 24, "training_loss": 0.6974559736251831, "training_acc": 52.0, "val_loss": 0.6867839121818542, "val_acc": 56.0}
{"epoch": 25, "training_loss": 0.6992585754394531, "training_acc": 52.0, "val_loss": 0.6859937977790832, "val_acc": 56.0}
{"epoch": 26, "training_loss": 0.7014711833000183, "training_acc": 52.0, "val_loss": 0.6914299058914185, "val_acc": 56.0}
{"epoch": 27, "training_loss": 0.7016878318786621, "training_acc": 42.0, "val_loss": 0.6917535662651062, "val_acc": 56.0}
{"epoch": 28, "training_loss": 0.6975162672996521, "training_acc": 52.0, "val_loss": 0.6859324955940247, "val_acc": 56.0}
{"epoch": 29, "training_loss": 0.7001757574081421, "training_acc": 52.0, "val_loss": 0.6961507725715638, "val_acc": 44.0}
{"epoch": 30, "training_loss": 0.7011127996444703, "training_acc": 48.0, "val_loss": 0.7015562510490417, "val_acc": 44.0}
{"epoch": 31, "training_loss": 0.7019492268562317, "training_acc": 44.0, "val_loss": 0.6920371770858764, "val_acc": 56.0}
{"epoch": 32, "training_loss": 0.7099479746818542, "training_acc": 44.0, "val_loss": 0.6906302762031555, "val_acc": 56.0}
{"epoch": 33, "training_loss": 0.7265868592262268, "training_acc": 52.0, "val_loss": 0.6861894178390503, "val_acc": 56.0}
{"epoch": 34, "training_loss": 0.7020131087303162, "training_acc": 50.0, "val_loss": 0.7117200589179993, "val_acc": 44.0}
{"epoch": 35, "training_loss": 0.70332190990448, "training_acc": 48.0, "val_loss": 0.6942471718788147, "val_acc": 44.0}
{"epoch": 36, "training_loss": 0.6996486043930054, "training_acc": 52.0, "val_loss": 0.6884166598320007, "val_acc": 56.0}
{"epoch": 37, "training_loss": 0.6946664428710938, "training_acc": 50.0, "val_loss": 0.7085155081748963, "val_acc": 44.0}
{"epoch": 38, "training_loss": 0.7044533944129944, "training_acc": 46.0, "val_loss": 0.6914471626281739, "val_acc": 56.0}
{"epoch": 39, "training_loss": 0.7199328327178955, "training_acc": 52.0, "val_loss": 0.6915463352203369, "val_acc": 56.0}
{"epoch": 40, "training_loss": 0.6939849662780762, "training_acc": 52.0, "val_loss": 0.6907949137687683, "val_acc": 56.0}
{"epoch": 41, "training_loss": 0.6939387273788452, "training_acc": 52.0, "val_loss": 0.699581253528595, "val_acc": 44.0}
{"epoch": 42, "training_loss": 0.7022979307174683, "training_acc": 46.0, "val_loss": 0.7007653069496155, "val_acc": 44.0}
{"epoch": 43, "training_loss": 0.6990978932380676, "training_acc": 48.0, "val_loss": 0.6905115032196045, "val_acc": 56.0}
{"epoch": 44, "training_loss": 0.699218819141388, "training_acc": 52.0, "val_loss": 0.6944809889793396, "val_acc": 44.0}
{"epoch": 45, "training_loss": 0.7357574653625488, "training_acc": 48.0, "val_loss": 0.6993981289863587, "val_acc": 44.0}
{"epoch": 46, "training_loss": 0.7177160000801086, "training_acc": 50.0, "val_loss": 0.6946542072296142, "val_acc": 56.0}
{"epoch": 47, "training_loss": 0.7167668986320496, "training_acc": 52.0, "val_loss": 0.6859303975105285, "val_acc": 56.0}
{"epoch": 48, "training_loss": 0.7049386262893677, "training_acc": 52.0, "val_loss": 0.6862877631187438, "val_acc": 56.0}
{"epoch": 49, "training_loss": 0.7312115287780762, "training_acc": 52.0, "val_loss": 0.6867077589035034, "val_acc": 56.0}
{"epoch": 50, "training_loss": 0.6993048357963562, "training_acc": 50.0, "val_loss": 0.7018334698677063, "val_acc": 44.0}
{"epoch": 51, "training_loss": 0.6956735849380493, "training_acc": 48.0, "val_loss": 0.6897348618507385, "val_acc": 56.0}
{"epoch": 52, "training_loss": 0.6998003816604614, "training_acc": 44.0, "val_loss": 0.6864517116546631, "val_acc": 56.0}
{"epoch": 53, "training_loss": 0.7048423337936401, "training_acc": 52.0, "val_loss": 0.6859349060058594, "val_acc": 56.0}
{"epoch": 54, "training_loss": 0.705466115474701, "training_acc": 46.0, "val_loss": 0.7032189154624939, "val_acc": 44.0}
{"epoch": 55, "training_loss": 0.7022432136535645, "training_acc": 48.0, "val_loss": 0.6885942006111145, "val_acc": 56.0}
{"epoch": 56, "training_loss": 0.6967637014389038, "training_acc": 52.0, "val_loss": 0.6899917745590209, "val_acc": 56.0}
{"epoch": 57, "training_loss": 0.6970817899703979, "training_acc": 44.0, "val_loss": 0.6988884568214416, "val_acc": 44.0}
{"epoch": 58, "training_loss": 0.7071556305885315, "training_acc": 42.0, "val_loss": 0.6929184460639953, "val_acc": 56.0}
{"epoch": 59, "training_loss": 0.6968625450134277, "training_acc": 48.0, "val_loss": 0.6934922432899475, "val_acc": 44.0}
{"epoch": 60, "training_loss": 0.6948172903060913, "training_acc": 50.0, "val_loss": 0.697019431591034, "val_acc": 44.0}
{"epoch": 61, "training_loss": 0.7004868555068969, "training_acc": 50.0, "val_loss": 0.6859681367874145, "val_acc": 56.0}
{"epoch": 62, "training_loss": 0.6993038296699524, "training_acc": 52.0, "val_loss": 0.6859915614128113, "val_acc": 56.0}
{"epoch": 63, "training_loss": 0.7013548278808593, "training_acc": 52.0, "val_loss": 0.6912538528442382, "val_acc": 56.0}
{"epoch": 64, "training_loss": 0.6973547387123108, "training_acc": 42.0, "val_loss": 0.7010569238662719, "val_acc": 44.0}
{"epoch": 65, "training_loss": 0.6978601169586182, "training_acc": 44.0, "val_loss": 0.6984811568260193, "val_acc": 44.0}
{"epoch": 66, "training_loss": 0.6998719096183776, "training_acc": 40.0, "val_loss": 0.6983621573448181, "val_acc": 44.0}
