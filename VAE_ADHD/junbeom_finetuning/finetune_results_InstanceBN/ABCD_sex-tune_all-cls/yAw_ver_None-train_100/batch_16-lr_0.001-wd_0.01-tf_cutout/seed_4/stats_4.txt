"main_modify.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 4 --task ABCD_sex --input_option BT_org --learning_rate 1e-3 --batch_size 16 --weight_decay 1e-2 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 0.711490478515625, "training_acc": 42.0, "val_loss": 0.6923974418640136, "val_acc": 52.0}
{"epoch": 1, "training_loss": 0.6982522439956665, "training_acc": 55.0, "val_loss": 0.6996677327156067, "val_acc": 48.0}
{"epoch": 2, "training_loss": 0.6970833301544189, "training_acc": 45.0, "val_loss": 0.6980625104904175, "val_acc": 52.0}
{"epoch": 3, "training_loss": 0.7026949167251587, "training_acc": 53.0, "val_loss": 0.7047347378730774, "val_acc": 52.0}
{"epoch": 4, "training_loss": 0.7091081261634826, "training_acc": 53.0, "val_loss": 0.6975779414176941, "val_acc": 52.0}
{"epoch": 5, "training_loss": 0.6994266176223755, "training_acc": 53.0, "val_loss": 0.6927074480056763, "val_acc": 52.0}
{"epoch": 6, "training_loss": 0.6991143941879272, "training_acc": 45.0, "val_loss": 0.6930459833145142, "val_acc": 52.0}
{"epoch": 7, "training_loss": 0.6947480010986328, "training_acc": 53.0, "val_loss": 0.7033052849769592, "val_acc": 52.0}
{"epoch": 8, "training_loss": 0.7121413493156433, "training_acc": 53.0, "val_loss": 0.6996227240562439, "val_acc": 52.0}
{"epoch": 9, "training_loss": 0.6949722146987916, "training_acc": 53.0, "val_loss": 0.6927040028572082, "val_acc": 52.0}
{"epoch": 10, "training_loss": 0.6952687358856201, "training_acc": 53.0, "val_loss": 0.6941280388832092, "val_acc": 52.0}
{"epoch": 11, "training_loss": 0.7073424577713012, "training_acc": 53.0, "val_loss": 0.6930288767814636, "val_acc": 52.0}
{"epoch": 12, "training_loss": 0.693525664806366, "training_acc": 47.0, "val_loss": 0.6940952038764954, "val_acc": 48.0}
{"epoch": 13, "training_loss": 0.7018067073822022, "training_acc": 45.0, "val_loss": 0.6945439529418945, "val_acc": 48.0}
{"epoch": 14, "training_loss": 0.7031033658981323, "training_acc": 47.0, "val_loss": 0.6928534269332886, "val_acc": 52.0}
{"epoch": 15, "training_loss": 0.6940071630477905, "training_acc": 53.0, "val_loss": 0.6943337631225586, "val_acc": 52.0}
{"epoch": 16, "training_loss": 0.6953739833831787, "training_acc": 53.0, "val_loss": 0.6937602233886718, "val_acc": 52.0}
{"epoch": 17, "training_loss": 0.7000513792037963, "training_acc": 53.0, "val_loss": 0.6935317683219909, "val_acc": 52.0}
{"epoch": 18, "training_loss": 0.6976881265640259, "training_acc": 53.0, "val_loss": 0.6923780870437622, "val_acc": 52.0}
{"epoch": 19, "training_loss": 0.700218939781189, "training_acc": 37.0, "val_loss": 0.6959013748168945, "val_acc": 52.0}
{"epoch": 20, "training_loss": 0.6967639517784119, "training_acc": 53.0, "val_loss": 0.7183090734481812, "val_acc": 52.0}
{"epoch": 21, "training_loss": 0.7197236108779907, "training_acc": 53.0, "val_loss": 0.6992026901245117, "val_acc": 52.0}
{"epoch": 22, "training_loss": 0.701199803352356, "training_acc": 49.0, "val_loss": 0.6927008652687072, "val_acc": 52.0}
{"epoch": 23, "training_loss": 0.699380407333374, "training_acc": 53.0, "val_loss": 0.698189287185669, "val_acc": 52.0}
{"epoch": 24, "training_loss": 0.7063745212554932, "training_acc": 43.0, "val_loss": 0.6923491930961609, "val_acc": 52.0}
{"epoch": 25, "training_loss": 0.6950066709518432, "training_acc": 47.0, "val_loss": 0.696274995803833, "val_acc": 52.0}
{"epoch": 26, "training_loss": 0.6951910519599914, "training_acc": 53.0, "val_loss": 0.6993343281745911, "val_acc": 52.0}
{"epoch": 27, "training_loss": 0.7115571451187134, "training_acc": 53.0, "val_loss": 0.6926976680755615, "val_acc": 52.0}
{"epoch": 28, "training_loss": 0.7319535684585571, "training_acc": 45.0, "val_loss": 0.703855905532837, "val_acc": 48.0}
{"epoch": 29, "training_loss": 0.6972840118408203, "training_acc": 53.0, "val_loss": 0.7013663983345032, "val_acc": 52.0}
{"epoch": 30, "training_loss": 0.7033590912818909, "training_acc": 53.0, "val_loss": 0.6923531746864319, "val_acc": 52.0}
{"epoch": 31, "training_loss": 0.6955926060676575, "training_acc": 49.0, "val_loss": 0.6931460070610046, "val_acc": 52.0}
{"epoch": 32, "training_loss": 0.6961814284324646, "training_acc": 53.0, "val_loss": 0.6951660990715027, "val_acc": 52.0}
{"epoch": 33, "training_loss": 0.7060433721542358, "training_acc": 53.0, "val_loss": 0.6924552512168884, "val_acc": 52.0}
{"epoch": 34, "training_loss": 0.697537579536438, "training_acc": 41.0, "val_loss": 0.6946737146377564, "val_acc": 52.0}
{"epoch": 35, "training_loss": 0.6979213809967041, "training_acc": 53.0, "val_loss": 0.6937033081054688, "val_acc": 52.0}
{"epoch": 36, "training_loss": 0.6983735656738281, "training_acc": 53.0, "val_loss": 0.6927482295036316, "val_acc": 52.0}
{"epoch": 37, "training_loss": 0.7011240005493165, "training_acc": 51.0, "val_loss": 0.6973391842842102, "val_acc": 48.0}
{"epoch": 38, "training_loss": 0.6998654842376709, "training_acc": 43.0, "val_loss": 0.6924072575569152, "val_acc": 52.0}
{"epoch": 39, "training_loss": 0.6985492181777954, "training_acc": 53.0, "val_loss": 0.692801570892334, "val_acc": 52.0}
{"epoch": 40, "training_loss": 0.6981989955902099, "training_acc": 53.0, "val_loss": 0.6944885182380677, "val_acc": 48.0}
{"epoch": 41, "training_loss": 0.710365719795227, "training_acc": 49.0, "val_loss": 0.6971592426300048, "val_acc": 52.0}
{"epoch": 42, "training_loss": 0.6972634959220886, "training_acc": 53.0, "val_loss": 0.6953050923347474, "val_acc": 52.0}
{"epoch": 43, "training_loss": 0.6971603441238403, "training_acc": 53.0, "val_loss": 0.6926852107048035, "val_acc": 52.0}
