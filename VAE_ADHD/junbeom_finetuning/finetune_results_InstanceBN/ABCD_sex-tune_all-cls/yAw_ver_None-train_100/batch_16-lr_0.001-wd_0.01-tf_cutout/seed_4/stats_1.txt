"main_modify.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 4 --task ABCD_sex --input_option BT_org --learning_rate 1e-3 --batch_size 16 --weight_decay 1e-2 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 0.7034899950027466, "training_acc": 51.0, "val_loss": 0.6935600686073303, "val_acc": 48.0}
{"epoch": 1, "training_loss": 0.6947015690803527, "training_acc": 53.0, "val_loss": 0.6997477984428406, "val_acc": 52.0}
{"epoch": 2, "training_loss": 0.7009462571144104, "training_acc": 49.0, "val_loss": 0.6995775580406189, "val_acc": 52.0}
{"epoch": 3, "training_loss": 0.7245225572586059, "training_acc": 53.0, "val_loss": 0.7013376593589783, "val_acc": 52.0}
{"epoch": 4, "training_loss": 0.7031369686126709, "training_acc": 53.0, "val_loss": 0.6927504014968872, "val_acc": 52.0}
{"epoch": 5, "training_loss": 0.7025173687934876, "training_acc": 47.0, "val_loss": 0.6944808220863342, "val_acc": 48.0}
{"epoch": 6, "training_loss": 0.7027680945396423, "training_acc": 49.0, "val_loss": 0.6925916314125061, "val_acc": 52.0}
{"epoch": 7, "training_loss": 0.7013757085800171, "training_acc": 43.0, "val_loss": 0.6941436767578125, "val_acc": 52.0}
{"epoch": 8, "training_loss": 0.6936142253875732, "training_acc": 52.0, "val_loss": 0.7075492334365845, "val_acc": 52.0}
{"epoch": 9, "training_loss": 0.7037895011901856, "training_acc": 53.0, "val_loss": 0.6972537040710449, "val_acc": 52.0}
{"epoch": 10, "training_loss": 0.697830057144165, "training_acc": 47.0, "val_loss": 0.6929485058784485, "val_acc": 52.0}
{"epoch": 11, "training_loss": 0.695355830192566, "training_acc": 53.0, "val_loss": 0.6924896693229675, "val_acc": 52.0}
{"epoch": 12, "training_loss": 0.7011599850654602, "training_acc": 43.0, "val_loss": 0.6939352059364319, "val_acc": 48.0}
{"epoch": 13, "training_loss": 0.694994306564331, "training_acc": 45.0, "val_loss": 0.6942253613471985, "val_acc": 48.0}
{"epoch": 14, "training_loss": 0.6948673439025879, "training_acc": 49.0, "val_loss": 0.7017871379852295, "val_acc": 52.0}
{"epoch": 15, "training_loss": 0.6993580794334412, "training_acc": 53.0, "val_loss": 0.7029387617111206, "val_acc": 52.0}
{"epoch": 16, "training_loss": 0.706975359916687, "training_acc": 53.0, "val_loss": 0.6926123929023743, "val_acc": 52.0}
{"epoch": 17, "training_loss": 0.6951944065093995, "training_acc": 45.0, "val_loss": 0.6996220684051514, "val_acc": 48.0}
{"epoch": 18, "training_loss": 0.7098806166648864, "training_acc": 43.0, "val_loss": 0.6926933073997498, "val_acc": 52.0}
{"epoch": 19, "training_loss": 0.6932467460632324, "training_acc": 49.0, "val_loss": 0.6957084250450134, "val_acc": 52.0}
{"epoch": 20, "training_loss": 0.694996485710144, "training_acc": 53.0, "val_loss": 0.6947498083114624, "val_acc": 52.0}
{"epoch": 21, "training_loss": 0.7018955564498901, "training_acc": 43.0, "val_loss": 0.6924557876586914, "val_acc": 52.0}
{"epoch": 22, "training_loss": 0.701218912601471, "training_acc": 41.0, "val_loss": 0.693833429813385, "val_acc": 52.0}
{"epoch": 23, "training_loss": 0.6952349519729615, "training_acc": 53.0, "val_loss": 0.692638635635376, "val_acc": 52.0}
{"epoch": 24, "training_loss": 0.7047661828994751, "training_acc": 51.0, "val_loss": 0.6960362267494201, "val_acc": 48.0}
{"epoch": 25, "training_loss": 0.6920852541923523, "training_acc": 53.0, "val_loss": 0.7047909283638001, "val_acc": 52.0}
{"epoch": 26, "training_loss": 0.7162515258789063, "training_acc": 53.0, "val_loss": 0.692347548007965, "val_acc": 52.0}
{"epoch": 27, "training_loss": 0.7359080362319946, "training_acc": 43.0, "val_loss": 0.6966377353668213, "val_acc": 48.0}
{"epoch": 28, "training_loss": 0.7036818313598633, "training_acc": 49.0, "val_loss": 0.6943263936042786, "val_acc": 52.0}
{"epoch": 29, "training_loss": 0.691996717453003, "training_acc": 51.0, "val_loss": 0.6948423743247986, "val_acc": 48.0}
{"epoch": 30, "training_loss": 0.7001617431640625, "training_acc": 45.0, "val_loss": 0.6925402879714966, "val_acc": 52.0}
{"epoch": 31, "training_loss": 0.6924790453910827, "training_acc": 53.0, "val_loss": 0.6963494920730591, "val_acc": 48.0}
{"epoch": 32, "training_loss": 0.7028804206848145, "training_acc": 47.0, "val_loss": 0.6933981418609619, "val_acc": 52.0}
{"epoch": 33, "training_loss": 0.7038154530525208, "training_acc": 53.0, "val_loss": 0.6974854254722596, "val_acc": 52.0}
{"epoch": 34, "training_loss": 0.6974005270004272, "training_acc": 53.0, "val_loss": 0.6953604245185852, "val_acc": 52.0}
{"epoch": 35, "training_loss": 0.694738039970398, "training_acc": 53.0, "val_loss": 0.6925413084030151, "val_acc": 52.0}
{"epoch": 36, "training_loss": 0.6951427507400513, "training_acc": 49.0, "val_loss": 0.6941252994537354, "val_acc": 52.0}
{"epoch": 37, "training_loss": 0.6992945981025696, "training_acc": 53.0, "val_loss": 0.698833270072937, "val_acc": 52.0}
{"epoch": 38, "training_loss": 0.6976165294647216, "training_acc": 53.0, "val_loss": 0.6923822808265686, "val_acc": 52.0}
{"epoch": 39, "training_loss": 0.6978692126274109, "training_acc": 47.0, "val_loss": 0.6925937962532044, "val_acc": 52.0}
{"epoch": 40, "training_loss": 0.6962740182876587, "training_acc": 47.0, "val_loss": 0.6926449942588806, "val_acc": 52.0}
{"epoch": 41, "training_loss": 0.7019548010826111, "training_acc": 53.0, "val_loss": 0.7006008839607238, "val_acc": 52.0}
{"epoch": 42, "training_loss": 0.7028509283065796, "training_acc": 53.0, "val_loss": 0.6949403071403504, "val_acc": 52.0}
{"epoch": 43, "training_loss": 0.7053408360481263, "training_acc": 39.0, "val_loss": 0.6931582880020142, "val_acc": 52.0}
{"epoch": 44, "training_loss": 0.6984143447875977, "training_acc": 53.0, "val_loss": 0.6926398420333862, "val_acc": 52.0}
{"epoch": 45, "training_loss": 0.6975411200523376, "training_acc": 53.0, "val_loss": 0.6932277345657348, "val_acc": 48.0}
