"main_modify.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 1 --task ABCD_sex --input_option BT_org --learning_rate 1e-3 --batch_size 16 --weight_decay 1e-2 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 0.7104326200485229, "training_acc": 47.0, "val_loss": 0.6977364444732665, "val_acc": 52.0}
{"epoch": 1, "training_loss": 0.7071746444702148, "training_acc": 53.0, "val_loss": 0.7015771985054016, "val_acc": 52.0}
{"epoch": 2, "training_loss": 0.7023102116584777, "training_acc": 51.0, "val_loss": 0.6927776074409485, "val_acc": 52.0}
{"epoch": 3, "training_loss": 0.692943344116211, "training_acc": 51.0, "val_loss": 0.6925027275085449, "val_acc": 52.0}
{"epoch": 4, "training_loss": 0.6926565551757813, "training_acc": 51.0, "val_loss": 0.693294038772583, "val_acc": 52.0}
{"epoch": 5, "training_loss": 0.6985217523574829, "training_acc": 51.0, "val_loss": 0.6933083748817443, "val_acc": 52.0}
{"epoch": 6, "training_loss": 0.6960168719291687, "training_acc": 53.0, "val_loss": 0.6934074711799622, "val_acc": 52.0}
{"epoch": 7, "training_loss": 0.6986155700683594, "training_acc": 53.0, "val_loss": 0.6923599529266358, "val_acc": 52.0}
{"epoch": 8, "training_loss": 0.7047927904129029, "training_acc": 51.0, "val_loss": 0.6936554694175721, "val_acc": 48.0}
{"epoch": 9, "training_loss": 0.6917012643814087, "training_acc": 51.0, "val_loss": 0.7007201433181762, "val_acc": 52.0}
{"epoch": 10, "training_loss": 0.6973895049095153, "training_acc": 49.0, "val_loss": 0.6948799514770507, "val_acc": 52.0}
{"epoch": 11, "training_loss": 0.6995561838150024, "training_acc": 53.0, "val_loss": 0.6923690819740296, "val_acc": 52.0}
{"epoch": 12, "training_loss": 0.6913899278640747, "training_acc": 51.0, "val_loss": 0.6954629135131836, "val_acc": 48.0}
{"epoch": 13, "training_loss": 0.6981993746757508, "training_acc": 45.0, "val_loss": 0.6923487210273742, "val_acc": 52.0}
{"epoch": 14, "training_loss": 0.7054505944252014, "training_acc": 45.0, "val_loss": 0.6984804153442383, "val_acc": 52.0}
{"epoch": 15, "training_loss": 0.7314854645729065, "training_acc": 53.0, "val_loss": 0.6984540343284606, "val_acc": 52.0}
{"epoch": 16, "training_loss": 0.6858071327209473, "training_acc": 53.0, "val_loss": 0.7032840371131897, "val_acc": 48.0}
{"epoch": 17, "training_loss": 0.7041043829917908, "training_acc": 45.0, "val_loss": 0.6927633690834045, "val_acc": 52.0}
{"epoch": 18, "training_loss": 0.6964446020126343, "training_acc": 45.0, "val_loss": 0.6930134630203247, "val_acc": 52.0}
{"epoch": 19, "training_loss": 0.6989941382408142, "training_acc": 47.0, "val_loss": 0.6942533040046692, "val_acc": 52.0}
{"epoch": 20, "training_loss": 0.7110459470748901, "training_acc": 53.0, "val_loss": 0.6983048605918885, "val_acc": 52.0}
{"epoch": 21, "training_loss": 0.6933317494392395, "training_acc": 53.0, "val_loss": 0.6951879048347473, "val_acc": 48.0}
{"epoch": 22, "training_loss": 0.7126585268974304, "training_acc": 49.0, "val_loss": 0.6925528383255005, "val_acc": 52.0}
{"epoch": 23, "training_loss": 0.6988485479354858, "training_acc": 41.0, "val_loss": 0.6931292939186097, "val_acc": 52.0}
{"epoch": 24, "training_loss": 0.7044756388664246, "training_acc": 53.0, "val_loss": 0.6923472690582275, "val_acc": 52.0}
{"epoch": 25, "training_loss": 0.7012162756919861, "training_acc": 43.0, "val_loss": 0.6936203455924987, "val_acc": 48.0}
{"epoch": 26, "training_loss": 0.7046419334411621, "training_acc": 47.0, "val_loss": 0.6939133667945862, "val_acc": 52.0}
{"epoch": 27, "training_loss": 0.6975001811981201, "training_acc": 53.0, "val_loss": 0.6988112711906433, "val_acc": 52.0}
{"epoch": 28, "training_loss": 0.703664927482605, "training_acc": 45.0, "val_loss": 0.692673704624176, "val_acc": 52.0}
{"epoch": 29, "training_loss": 0.7146601963043213, "training_acc": 53.0, "val_loss": 0.6923486828804016, "val_acc": 52.0}
{"epoch": 30, "training_loss": 0.7000241422653198, "training_acc": 45.0, "val_loss": 0.692522919178009, "val_acc": 52.0}
{"epoch": 31, "training_loss": 0.7033082866668701, "training_acc": 53.0, "val_loss": 0.694860200881958, "val_acc": 52.0}
{"epoch": 32, "training_loss": 0.6959260654449463, "training_acc": 53.0, "val_loss": 0.6942613768577576, "val_acc": 52.0}
{"epoch": 33, "training_loss": 0.6960108280181885, "training_acc": 49.0, "val_loss": 0.6937360787391662, "val_acc": 52.0}
{"epoch": 34, "training_loss": 0.7077673864364624, "training_acc": 53.0, "val_loss": 0.6923473119735718, "val_acc": 52.0}
{"epoch": 35, "training_loss": 0.7095408821105957, "training_acc": 43.0, "val_loss": 0.6923897171020508, "val_acc": 52.0}
{"epoch": 36, "training_loss": 0.6918517613410949, "training_acc": 53.0, "val_loss": 0.6973248314857483, "val_acc": 52.0}
{"epoch": 37, "training_loss": 0.7087238264083863, "training_acc": 47.0, "val_loss": 0.6926200032234192, "val_acc": 52.0}
{"epoch": 38, "training_loss": 0.6966914129257202, "training_acc": 53.0, "val_loss": 0.7016645669937134, "val_acc": 52.0}
{"epoch": 39, "training_loss": 0.7037355208396912, "training_acc": 53.0, "val_loss": 0.6926239943504333, "val_acc": 52.0}
{"epoch": 40, "training_loss": 0.7064107275009155, "training_acc": 47.0, "val_loss": 0.6924797749519348, "val_acc": 52.0}
{"epoch": 41, "training_loss": 0.6943445038795472, "training_acc": 49.0, "val_loss": 0.6973807311058045, "val_acc": 52.0}
{"epoch": 42, "training_loss": 0.6940731835365296, "training_acc": 53.0, "val_loss": 0.6924277400970459, "val_acc": 52.0}
{"epoch": 43, "training_loss": 0.7128240728378296, "training_acc": 45.0, "val_loss": 0.6928831791877746, "val_acc": 52.0}
