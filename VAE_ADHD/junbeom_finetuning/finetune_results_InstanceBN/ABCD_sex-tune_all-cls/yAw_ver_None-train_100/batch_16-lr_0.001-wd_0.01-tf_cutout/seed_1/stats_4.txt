"main_modify.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 1 --task ABCD_sex --input_option BT_org --learning_rate 1e-3 --batch_size 16 --weight_decay 1e-2 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 0.7205800199508667, "training_acc": 52.0, "val_loss": 0.6945281028747559, "val_acc": 44.0}
{"epoch": 1, "training_loss": 0.7107558059692383, "training_acc": 53.0, "val_loss": 0.7032469892501831, "val_acc": 44.0}
{"epoch": 2, "training_loss": 0.7093181085586547, "training_acc": 46.0, "val_loss": 0.6987322807312012, "val_acc": 44.0}
{"epoch": 3, "training_loss": 0.699947624206543, "training_acc": 42.0, "val_loss": 0.6879217028617859, "val_acc": 56.0}
{"epoch": 4, "training_loss": 0.7082856011390686, "training_acc": 50.0, "val_loss": 0.68598952293396, "val_acc": 56.0}
{"epoch": 5, "training_loss": 0.697007668018341, "training_acc": 49.0, "val_loss": 0.6877589392662048, "val_acc": 56.0}
{"epoch": 6, "training_loss": 0.7030125021934509, "training_acc": 52.0, "val_loss": 0.6955070161819458, "val_acc": 44.0}
{"epoch": 7, "training_loss": 0.6986726331710815, "training_acc": 46.0, "val_loss": 0.6977697420120239, "val_acc": 44.0}
{"epoch": 8, "training_loss": 0.7071408748626709, "training_acc": 48.0, "val_loss": 0.6893287634849549, "val_acc": 56.0}
{"epoch": 9, "training_loss": 0.7007085084915161, "training_acc": 52.0, "val_loss": 0.6859166097640991, "val_acc": 56.0}
{"epoch": 10, "training_loss": 0.7046649360656738, "training_acc": 52.0, "val_loss": 0.6864644980430603, "val_acc": 56.0}
{"epoch": 11, "training_loss": 0.6985063219070434, "training_acc": 52.0, "val_loss": 0.6919374084472656, "val_acc": 56.0}
{"epoch": 12, "training_loss": 0.6967630362510682, "training_acc": 50.0, "val_loss": 0.6990846562385559, "val_acc": 44.0}
{"epoch": 13, "training_loss": 0.7021301484107971, "training_acc": 48.0, "val_loss": 0.6991047930717468, "val_acc": 44.0}
{"epoch": 14, "training_loss": 0.7045345830917359, "training_acc": 48.0, "val_loss": 0.699039990901947, "val_acc": 44.0}
{"epoch": 15, "training_loss": 0.6995205879211426, "training_acc": 52.0, "val_loss": 0.6860447573661804, "val_acc": 56.0}
{"epoch": 16, "training_loss": 0.6998909783363342, "training_acc": 46.0, "val_loss": 0.6889379096031188, "val_acc": 56.0}
{"epoch": 17, "training_loss": 0.6970552921295166, "training_acc": 52.0, "val_loss": 0.6863130617141724, "val_acc": 56.0}
{"epoch": 18, "training_loss": 0.6981253814697266, "training_acc": 52.0, "val_loss": 0.7057978177070617, "val_acc": 44.0}
{"epoch": 19, "training_loss": 0.7067416191101075, "training_acc": 48.0, "val_loss": 0.7141026306152344, "val_acc": 44.0}
{"epoch": 20, "training_loss": 0.703893084526062, "training_acc": 46.0, "val_loss": 0.6907445693016052, "val_acc": 56.0}
{"epoch": 21, "training_loss": 0.6960370922088623, "training_acc": 52.0, "val_loss": 0.68835369348526, "val_acc": 56.0}
{"epoch": 22, "training_loss": 0.6952270078659057, "training_acc": 52.0, "val_loss": 0.6911143636703492, "val_acc": 56.0}
{"epoch": 23, "training_loss": 0.6977317428588867, "training_acc": 46.0, "val_loss": 0.685954487323761, "val_acc": 56.0}
{"epoch": 24, "training_loss": 0.700900650024414, "training_acc": 52.0, "val_loss": 0.6861095476150513, "val_acc": 56.0}
{"epoch": 25, "training_loss": 0.6983152675628662, "training_acc": 52.0, "val_loss": 0.686484558582306, "val_acc": 56.0}
{"epoch": 26, "training_loss": 0.703292498588562, "training_acc": 40.0, "val_loss": 0.691939651966095, "val_acc": 56.0}
{"epoch": 27, "training_loss": 0.6938155269622803, "training_acc": 48.0, "val_loss": 0.6897798657417298, "val_acc": 56.0}
{"epoch": 28, "training_loss": 0.7001180577278138, "training_acc": 44.0, "val_loss": 0.6943251490592957, "val_acc": 44.0}
