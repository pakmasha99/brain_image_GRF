"main_modify.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 8 --task ABCD_sex --input_option BT_org --learning_rate 1e-2 --batch_size 16 --weight_decay 1e-2 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 1.1282409477233886, "training_acc": 45.0, "val_loss": 0.7279744410514831, "val_acc": 52.0}
{"epoch": 1, "training_loss": 0.7415934419631958, "training_acc": 49.0, "val_loss": 0.7031971335411071, "val_acc": 52.0}
{"epoch": 2, "training_loss": 0.7223411798477173, "training_acc": 47.0, "val_loss": 0.6967614436149597, "val_acc": 52.0}
{"epoch": 3, "training_loss": 0.6997989654541016, "training_acc": 53.0, "val_loss": 0.7126349568367004, "val_acc": 48.0}
{"epoch": 4, "training_loss": 0.7814490103721619, "training_acc": 55.0, "val_loss": 1.123757176399231, "val_acc": 52.0}
{"epoch": 5, "training_loss": 0.9252945470809937, "training_acc": 49.0, "val_loss": 0.699532642364502, "val_acc": 52.0}
{"epoch": 6, "training_loss": 0.7292218232154846, "training_acc": 43.0, "val_loss": 0.7940692830085755, "val_acc": 52.0}
{"epoch": 7, "training_loss": 0.802387399673462, "training_acc": 49.0, "val_loss": 0.8235276913642884, "val_acc": 48.0}
{"epoch": 8, "training_loss": 0.7583920979499816, "training_acc": 47.0, "val_loss": 0.7474653244018554, "val_acc": 48.0}
{"epoch": 9, "training_loss": 0.7462859678268433, "training_acc": 45.0, "val_loss": 0.6935038948059082, "val_acc": 48.0}
{"epoch": 10, "training_loss": 0.7063771414756775, "training_acc": 51.0, "val_loss": 0.6942350149154664, "val_acc": 48.0}
{"epoch": 11, "training_loss": 0.7488951897621154, "training_acc": 41.0, "val_loss": 0.892344036102295, "val_acc": 48.0}
{"epoch": 12, "training_loss": 0.7691814565658569, "training_acc": 53.0, "val_loss": 0.9480662703514099, "val_acc": 52.0}
{"epoch": 13, "training_loss": 0.7886405515670777, "training_acc": 47.0, "val_loss": 0.7230173778533936, "val_acc": 48.0}
{"epoch": 14, "training_loss": 0.7476709246635437, "training_acc": 41.0, "val_loss": 0.714552161693573, "val_acc": 52.0}
{"epoch": 15, "training_loss": 0.7017467069625855, "training_acc": 53.0, "val_loss": 0.6924129486083984, "val_acc": 52.0}
{"epoch": 16, "training_loss": 0.7143274402618408, "training_acc": 43.0, "val_loss": 0.7239764833450317, "val_acc": 52.0}
{"epoch": 17, "training_loss": 0.7173452877998352, "training_acc": 53.0, "val_loss": 0.7744526433944702, "val_acc": 48.0}
{"epoch": 18, "training_loss": 0.7476944923400879, "training_acc": 47.0, "val_loss": 0.6994835710525513, "val_acc": 52.0}
{"epoch": 19, "training_loss": 0.7031715583801269, "training_acc": 51.0, "val_loss": 0.693468508720398, "val_acc": 48.0}
{"epoch": 20, "training_loss": 0.7208465003967285, "training_acc": 41.0, "val_loss": 0.714604206085205, "val_acc": 48.0}
{"epoch": 21, "training_loss": 0.7108540773391724, "training_acc": 45.0, "val_loss": 0.6923523044586182, "val_acc": 52.0}
{"epoch": 22, "training_loss": 0.7006908082962036, "training_acc": 53.0, "val_loss": 0.7504315972328186, "val_acc": 48.0}
{"epoch": 23, "training_loss": 0.7725261545181275, "training_acc": 47.0, "val_loss": 0.6933506846427917, "val_acc": 52.0}
{"epoch": 24, "training_loss": 0.7515441584587097, "training_acc": 43.0, "val_loss": 0.6987597918510438, "val_acc": 48.0}
{"epoch": 25, "training_loss": 0.7019401693344116, "training_acc": 43.0, "val_loss": 0.705773048400879, "val_acc": 52.0}
{"epoch": 26, "training_loss": 0.7150114727020264, "training_acc": 53.0, "val_loss": 0.6993625974655151, "val_acc": 48.0}
{"epoch": 27, "training_loss": 0.7276715755462646, "training_acc": 47.0, "val_loss": 0.6968665313720703, "val_acc": 52.0}
{"epoch": 28, "training_loss": 0.7195072460174561, "training_acc": 45.0, "val_loss": 0.7299243950843811, "val_acc": 52.0}
{"epoch": 29, "training_loss": 0.7260095930099487, "training_acc": 51.0, "val_loss": 0.69248055934906, "val_acc": 52.0}
{"epoch": 30, "training_loss": 0.7004244470596314, "training_acc": 53.0, "val_loss": 0.6930399918556214, "val_acc": 52.0}
{"epoch": 31, "training_loss": 0.7184158039093017, "training_acc": 43.0, "val_loss": 0.7318720006942749, "val_acc": 52.0}
{"epoch": 32, "training_loss": 0.7416826295852661, "training_acc": 55.0, "val_loss": 0.8006749367713928, "val_acc": 48.0}
{"epoch": 33, "training_loss": 0.7844212818145752, "training_acc": 51.0, "val_loss": 0.7102466416358948, "val_acc": 52.0}
{"epoch": 34, "training_loss": 0.7147272062301636, "training_acc": 53.0, "val_loss": 0.7069651460647584, "val_acc": 48.0}
{"epoch": 35, "training_loss": 0.698463933467865, "training_acc": 53.0, "val_loss": 0.7060636162757874, "val_acc": 52.0}
{"epoch": 36, "training_loss": 0.710549132823944, "training_acc": 51.0, "val_loss": 0.6928833770751953, "val_acc": 52.0}
{"epoch": 37, "training_loss": 0.693791766166687, "training_acc": 49.0, "val_loss": 0.7506643342971802, "val_acc": 52.0}
{"epoch": 38, "training_loss": 0.7381201267242432, "training_acc": 45.0, "val_loss": 0.7172091770172119, "val_acc": 52.0}
{"epoch": 39, "training_loss": 0.7072828531265258, "training_acc": 53.0, "val_loss": 0.7045401120185852, "val_acc": 48.0}
{"epoch": 40, "training_loss": 0.716687216758728, "training_acc": 47.0, "val_loss": 0.7150774455070495, "val_acc": 52.0}
{"epoch": 41, "training_loss": 0.7029897594451904, "training_acc": 51.0, "val_loss": 0.6923514890670777, "val_acc": 52.0}
{"epoch": 42, "training_loss": 0.7068318486213684, "training_acc": 53.0, "val_loss": 0.7047741174697876, "val_acc": 48.0}
{"epoch": 43, "training_loss": 0.7192699384689331, "training_acc": 47.0, "val_loss": 0.7033826184272766, "val_acc": 52.0}
{"epoch": 44, "training_loss": 0.7365594005584717, "training_acc": 53.0, "val_loss": 0.7178061985969544, "val_acc": 48.0}
{"epoch": 45, "training_loss": 0.7148505878448487, "training_acc": 51.0, "val_loss": 0.7427200603485108, "val_acc": 52.0}
{"epoch": 46, "training_loss": 0.7358423471450806, "training_acc": 53.0, "val_loss": 0.7200808000564575, "val_acc": 48.0}
{"epoch": 47, "training_loss": 0.710699987411499, "training_acc": 49.0, "val_loss": 0.7440247750282287, "val_acc": 52.0}
{"epoch": 48, "training_loss": 0.7334869146347046, "training_acc": 53.0, "val_loss": 0.7572267174720764, "val_acc": 48.0}
{"epoch": 49, "training_loss": 0.7522930550575256, "training_acc": 51.0, "val_loss": 0.7408793640136718, "val_acc": 52.0}
{"epoch": 50, "training_loss": 0.7052502775192261, "training_acc": 51.0, "val_loss": 0.6929993176460266, "val_acc": 52.0}
{"epoch": 51, "training_loss": 0.7216279077529907, "training_acc": 53.0, "val_loss": 0.7288309669494629, "val_acc": 48.0}
{"epoch": 52, "training_loss": 0.777055344581604, "training_acc": 45.0, "val_loss": 0.737581799030304, "val_acc": 52.0}
{"epoch": 53, "training_loss": 0.7269361257553101, "training_acc": 55.0, "val_loss": 0.8406744050979614, "val_acc": 48.0}
{"epoch": 54, "training_loss": 0.8082524800300598, "training_acc": 47.0, "val_loss": 0.7551121139526367, "val_acc": 52.0}
{"epoch": 55, "training_loss": 0.7159324884414673, "training_acc": 49.0, "val_loss": 0.6946315360069275, "val_acc": 48.0}
{"epoch": 56, "training_loss": 0.6843488621711731, "training_acc": 59.0, "val_loss": 0.7123327326774597, "val_acc": 52.0}
{"epoch": 57, "training_loss": 0.7119163799285889, "training_acc": 49.0, "val_loss": 0.692391095161438, "val_acc": 52.0}
{"epoch": 58, "training_loss": 0.7081187534332275, "training_acc": 53.0, "val_loss": 0.715394446849823, "val_acc": 48.0}
{"epoch": 59, "training_loss": 0.7543422532081604, "training_acc": 37.0, "val_loss": 0.7116096019744873, "val_acc": 48.0}
{"epoch": 60, "training_loss": 0.8163292646408081, "training_acc": 51.0, "val_loss": 0.8612533521652221, "val_acc": 52.0}
