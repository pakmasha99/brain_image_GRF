"main_modify.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 8 --task ABCD_sex --input_option BT_org --learning_rate 1e-2 --batch_size 16 --weight_decay 1e-2 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 1.2938403606414794, "training_acc": 51.0, "val_loss": 1.096295018196106, "val_acc": 52.0}
{"epoch": 1, "training_loss": 0.979838228225708, "training_acc": 49.0, "val_loss": 0.7222693061828613, "val_acc": 48.0}
{"epoch": 2, "training_loss": 0.7525090599060058, "training_acc": 43.0, "val_loss": 0.754474229812622, "val_acc": 48.0}
{"epoch": 3, "training_loss": 0.7201235103607178, "training_acc": 57.0, "val_loss": 1.0344543528556824, "val_acc": 52.0}
{"epoch": 4, "training_loss": 0.8199118185043335, "training_acc": 53.0, "val_loss": 0.7451458501815796, "val_acc": 48.0}
{"epoch": 5, "training_loss": 0.722718710899353, "training_acc": 59.0, "val_loss": 0.7751399230957031, "val_acc": 52.0}
{"epoch": 6, "training_loss": 0.7388909959793091, "training_acc": 45.0, "val_loss": 0.6933636975288391, "val_acc": 52.0}
{"epoch": 7, "training_loss": 0.7336937141418457, "training_acc": 47.0, "val_loss": 0.7293963050842285, "val_acc": 48.0}
{"epoch": 8, "training_loss": 0.7233855581283569, "training_acc": 49.0, "val_loss": 0.8467142629623413, "val_acc": 52.0}
{"epoch": 9, "training_loss": 0.8919358158111572, "training_acc": 49.0, "val_loss": 0.6965080761909485, "val_acc": 48.0}
{"epoch": 10, "training_loss": 0.8417546844482422, "training_acc": 45.0, "val_loss": 0.6989266252517701, "val_acc": 52.0}
{"epoch": 11, "training_loss": 0.731427812576294, "training_acc": 53.0, "val_loss": 0.6925251364707947, "val_acc": 52.0}
{"epoch": 12, "training_loss": 0.7143409681320191, "training_acc": 43.0, "val_loss": 0.7092915368080139, "val_acc": 52.0}
{"epoch": 13, "training_loss": 0.7247355937957763, "training_acc": 43.0, "val_loss": 0.7246247220039368, "val_acc": 52.0}
{"epoch": 14, "training_loss": 0.7092755651473999, "training_acc": 51.0, "val_loss": 0.7057787775993347, "val_acc": 52.0}
{"epoch": 15, "training_loss": 0.7639638638496399, "training_acc": 51.0, "val_loss": 0.6927847576141357, "val_acc": 52.0}
{"epoch": 16, "training_loss": 0.7104402256011962, "training_acc": 53.0, "val_loss": 0.6993748950958252, "val_acc": 48.0}
{"epoch": 17, "training_loss": 0.7060483694076538, "training_acc": 47.0, "val_loss": 0.7068841123580932, "val_acc": 48.0}
{"epoch": 18, "training_loss": 0.7106146359443665, "training_acc": 45.0, "val_loss": 0.6931282353401184, "val_acc": 52.0}
{"epoch": 19, "training_loss": 0.6956244897842407, "training_acc": 53.0, "val_loss": 0.7318211030960083, "val_acc": 48.0}
{"epoch": 20, "training_loss": 0.7118979501724243, "training_acc": 49.0, "val_loss": 0.6942426419258118, "val_acc": 52.0}
{"epoch": 21, "training_loss": 0.6966112589836121, "training_acc": 51.0, "val_loss": 0.7039901781082153, "val_acc": 48.0}
{"epoch": 22, "training_loss": 0.7038517999649048, "training_acc": 49.0, "val_loss": 0.7237817692756653, "val_acc": 52.0}
{"epoch": 23, "training_loss": 0.7257764768600464, "training_acc": 57.0, "val_loss": 0.8542498087882996, "val_acc": 48.0}
{"epoch": 24, "training_loss": 0.896392228603363, "training_acc": 43.0, "val_loss": 0.8075868248939514, "val_acc": 52.0}
{"epoch": 25, "training_loss": 0.8401964783668519, "training_acc": 41.0, "val_loss": 0.698420045375824, "val_acc": 48.0}
{"epoch": 26, "training_loss": 0.7066792893409729, "training_acc": 51.0, "val_loss": 0.6923485207557678, "val_acc": 52.0}
{"epoch": 27, "training_loss": 0.691759524345398, "training_acc": 55.0, "val_loss": 0.7179723167419434, "val_acc": 48.0}
{"epoch": 28, "training_loss": 0.7191034364700317, "training_acc": 41.0, "val_loss": 0.7014145994186402, "val_acc": 52.0}
{"epoch": 29, "training_loss": 0.7813430976867676, "training_acc": 55.0, "val_loss": 0.791678204536438, "val_acc": 48.0}
{"epoch": 30, "training_loss": 0.8029301309585571, "training_acc": 47.0, "val_loss": 0.7098829293251038, "val_acc": 52.0}
{"epoch": 31, "training_loss": 0.7273232889175415, "training_acc": 53.0, "val_loss": 0.6963681268692017, "val_acc": 52.0}
{"epoch": 32, "training_loss": 0.7081955718994141, "training_acc": 47.0, "val_loss": 0.6936975169181824, "val_acc": 48.0}
{"epoch": 33, "training_loss": 0.7083774828910827, "training_acc": 49.0, "val_loss": 0.693824474811554, "val_acc": 52.0}
{"epoch": 34, "training_loss": 0.6977609014511108, "training_acc": 53.0, "val_loss": 0.7043541836738586, "val_acc": 48.0}
{"epoch": 35, "training_loss": 0.7003230476379394, "training_acc": 49.0, "val_loss": 0.6926821565628052, "val_acc": 52.0}
{"epoch": 36, "training_loss": 0.7013424515724183, "training_acc": 49.0, "val_loss": 0.7021398520469666, "val_acc": 52.0}
{"epoch": 37, "training_loss": 0.7059304571151733, "training_acc": 53.0, "val_loss": 0.715142376422882, "val_acc": 48.0}
{"epoch": 38, "training_loss": 0.7158258724212646, "training_acc": 49.0, "val_loss": 0.7126562809944152, "val_acc": 52.0}
{"epoch": 39, "training_loss": 0.7467571830749512, "training_acc": 53.0, "val_loss": 0.7092409253120422, "val_acc": 48.0}
{"epoch": 40, "training_loss": 0.7426349377632141, "training_acc": 49.0, "val_loss": 0.7906004071235657, "val_acc": 52.0}
{"epoch": 41, "training_loss": 0.7518392181396485, "training_acc": 53.0, "val_loss": 0.7224755406379699, "val_acc": 48.0}
{"epoch": 42, "training_loss": 0.7144250917434692, "training_acc": 43.0, "val_loss": 0.7199101042747498, "val_acc": 48.0}
{"epoch": 43, "training_loss": 0.707557761669159, "training_acc": 49.0, "val_loss": 0.7289840197563171, "val_acc": 52.0}
{"epoch": 44, "training_loss": 0.718605124950409, "training_acc": 53.0, "val_loss": 0.759450376033783, "val_acc": 48.0}
{"epoch": 45, "training_loss": 0.7949359083175659, "training_acc": 41.0, "val_loss": 0.7118449521064758, "val_acc": 52.0}
