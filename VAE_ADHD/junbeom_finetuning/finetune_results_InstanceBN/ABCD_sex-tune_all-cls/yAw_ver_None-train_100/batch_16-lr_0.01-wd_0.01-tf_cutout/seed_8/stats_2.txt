"main_modify.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 8 --task ABCD_sex --input_option BT_org --learning_rate 1e-2 --batch_size 16 --weight_decay 1e-2 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 1.1456491088867187, "training_acc": 55.0, "val_loss": 0.6979848337173462, "val_acc": 48.0}
{"epoch": 1, "training_loss": 0.8925646138191223, "training_acc": 47.0, "val_loss": 1.0678140377998353, "val_acc": 52.0}
{"epoch": 2, "training_loss": 0.8956705808639527, "training_acc": 51.0, "val_loss": 0.7106803488731385, "val_acc": 48.0}
{"epoch": 3, "training_loss": 0.8326172208786011, "training_acc": 47.0, "val_loss": 0.7394082570075988, "val_acc": 48.0}
{"epoch": 4, "training_loss": 0.7065150260925293, "training_acc": 57.0, "val_loss": 0.8869027709960937, "val_acc": 52.0}
{"epoch": 5, "training_loss": 0.8602029466629029, "training_acc": 39.0, "val_loss": 0.712888343334198, "val_acc": 52.0}
{"epoch": 6, "training_loss": 0.7056843662261962, "training_acc": 53.0, "val_loss": 0.7158391499519348, "val_acc": 48.0}
{"epoch": 7, "training_loss": 0.715665135383606, "training_acc": 43.0, "val_loss": 0.7429277181625367, "val_acc": 52.0}
{"epoch": 8, "training_loss": 0.7893610000610352, "training_acc": 53.0, "val_loss": 0.9525927877426148, "val_acc": 48.0}
{"epoch": 9, "training_loss": 0.9068664240837098, "training_acc": 43.0, "val_loss": 0.7132841205596924, "val_acc": 48.0}
{"epoch": 10, "training_loss": 0.7418062782287598, "training_acc": 47.0, "val_loss": 0.7923108983039856, "val_acc": 52.0}
{"epoch": 11, "training_loss": 0.7080703687667846, "training_acc": 61.0, "val_loss": 0.8194548034667969, "val_acc": 48.0}
{"epoch": 12, "training_loss": 0.7554773426055909, "training_acc": 53.0, "val_loss": 0.7664653539657593, "val_acc": 52.0}
{"epoch": 13, "training_loss": 0.6898575997352601, "training_acc": 57.0, "val_loss": 0.8525936508178711, "val_acc": 48.0}
{"epoch": 14, "training_loss": 0.7613371706008911, "training_acc": 43.0, "val_loss": 0.8010898208618165, "val_acc": 52.0}
{"epoch": 15, "training_loss": 0.767708637714386, "training_acc": 49.0, "val_loss": 0.6967990756034851, "val_acc": 52.0}
{"epoch": 16, "training_loss": 0.7301700472831726, "training_acc": 47.0, "val_loss": 0.6943186545372009, "val_acc": 48.0}
{"epoch": 17, "training_loss": 0.703647677898407, "training_acc": 51.0, "val_loss": 0.7000624680519104, "val_acc": 52.0}
{"epoch": 18, "training_loss": 0.6973105335235595, "training_acc": 53.0, "val_loss": 0.6957972288131714, "val_acc": 48.0}
{"epoch": 19, "training_loss": 0.7224181818962098, "training_acc": 37.0, "val_loss": 0.7002889943122864, "val_acc": 52.0}
{"epoch": 20, "training_loss": 0.7083808207511901, "training_acc": 53.0, "val_loss": 0.7128855395317077, "val_acc": 48.0}
{"epoch": 21, "training_loss": 0.7209556436538697, "training_acc": 39.0, "val_loss": 0.695661404132843, "val_acc": 48.0}
{"epoch": 22, "training_loss": 0.7012036561965942, "training_acc": 47.0, "val_loss": 0.6976378560066223, "val_acc": 52.0}
{"epoch": 23, "training_loss": 0.6906112289428711, "training_acc": 53.0, "val_loss": 0.6999659419059754, "val_acc": 48.0}
{"epoch": 24, "training_loss": 0.7031223344802856, "training_acc": 47.0, "val_loss": 0.7144980311393738, "val_acc": 52.0}
{"epoch": 25, "training_loss": 0.7168194508552551, "training_acc": 53.0, "val_loss": 0.6949929451942444, "val_acc": 48.0}
{"epoch": 26, "training_loss": 0.7031084680557251, "training_acc": 49.0, "val_loss": 0.7247204542160034, "val_acc": 52.0}
{"epoch": 27, "training_loss": 0.7459488606452942, "training_acc": 53.0, "val_loss": 0.7151191425323487, "val_acc": 48.0}
{"epoch": 28, "training_loss": 0.7313347959518433, "training_acc": 45.0, "val_loss": 0.712904691696167, "val_acc": 52.0}
{"epoch": 29, "training_loss": 0.7328446435928345, "training_acc": 39.0, "val_loss": 0.7347532129287719, "val_acc": 52.0}
{"epoch": 30, "training_loss": 0.7243578386306763, "training_acc": 53.0, "val_loss": 0.6977048444747925, "val_acc": 48.0}
{"epoch": 31, "training_loss": 0.7000025200843811, "training_acc": 45.0, "val_loss": 0.6927377772331238, "val_acc": 52.0}
{"epoch": 32, "training_loss": 0.7031162214279175, "training_acc": 51.0, "val_loss": 0.6923901963233948, "val_acc": 52.0}
{"epoch": 33, "training_loss": 0.6970210289955139, "training_acc": 49.0, "val_loss": 0.7033232855796814, "val_acc": 48.0}
{"epoch": 34, "training_loss": 0.7227682065963745, "training_acc": 49.0, "val_loss": 0.6999488520622253, "val_acc": 52.0}
{"epoch": 35, "training_loss": 0.7112978386878968, "training_acc": 49.0, "val_loss": 0.7100647234916687, "val_acc": 48.0}
{"epoch": 36, "training_loss": 0.7017460441589356, "training_acc": 49.0, "val_loss": 0.7792194843292236, "val_acc": 52.0}
{"epoch": 37, "training_loss": 0.7758731842041016, "training_acc": 49.0, "val_loss": 0.7134421515464783, "val_acc": 48.0}
{"epoch": 38, "training_loss": 0.7062579488754273, "training_acc": 45.0, "val_loss": 0.7382290959358215, "val_acc": 52.0}
{"epoch": 39, "training_loss": 0.7241680765151978, "training_acc": 53.0, "val_loss": 0.7232770276069641, "val_acc": 48.0}
{"epoch": 40, "training_loss": 0.7156681561470032, "training_acc": 47.0, "val_loss": 0.6934402465820313, "val_acc": 48.0}
{"epoch": 41, "training_loss": 0.7109381580352783, "training_acc": 45.0, "val_loss": 0.6955976891517639, "val_acc": 52.0}
{"epoch": 42, "training_loss": 0.709257779121399, "training_acc": 41.0, "val_loss": 0.6966966319084168, "val_acc": 52.0}
{"epoch": 43, "training_loss": 0.7018133664131164, "training_acc": 53.0, "val_loss": 0.6977462220191956, "val_acc": 52.0}
{"epoch": 44, "training_loss": 0.7168721389770508, "training_acc": 41.0, "val_loss": 0.6974277782440186, "val_acc": 52.0}
{"epoch": 45, "training_loss": 0.7027570247650147, "training_acc": 45.0, "val_loss": 0.6959242343902587, "val_acc": 52.0}
{"epoch": 46, "training_loss": 0.7135280799865723, "training_acc": 53.0, "val_loss": 0.7032963562011719, "val_acc": 48.0}
{"epoch": 47, "training_loss": 0.8555378532409668, "training_acc": 45.0, "val_loss": 0.7178299713134766, "val_acc": 52.0}
{"epoch": 48, "training_loss": 0.7202353286743164, "training_acc": 47.0, "val_loss": 0.6937987232208251, "val_acc": 48.0}
{"epoch": 49, "training_loss": 0.7056812930107117, "training_acc": 49.0, "val_loss": 0.693517336845398, "val_acc": 52.0}
{"epoch": 50, "training_loss": 0.6957686614990234, "training_acc": 51.0, "val_loss": 0.6982460713386536, "val_acc": 52.0}
{"epoch": 51, "training_loss": 0.7073313331604004, "training_acc": 53.0, "val_loss": 0.7035697126388549, "val_acc": 48.0}
