"main_modify.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 1 --task ABCD_sex --input_option BT_org --learning_rate 1e-2 --batch_size 16 --weight_decay 1e-2 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 1.1139406967163086, "training_acc": 43.0, "val_loss": 0.7537920761108399, "val_acc": 48.0}
{"epoch": 1, "training_loss": 0.8141263914108277, "training_acc": 45.0, "val_loss": 0.7639457178115845, "val_acc": 48.0}
{"epoch": 2, "training_loss": 0.7180404019355774, "training_acc": 55.0, "val_loss": 0.8996714115142822, "val_acc": 52.0}
{"epoch": 3, "training_loss": 0.8008255100250244, "training_acc": 47.0, "val_loss": 0.8002710103988647, "val_acc": 52.0}
{"epoch": 4, "training_loss": 0.8893150281906128, "training_acc": 43.0, "val_loss": 0.6953091311454773, "val_acc": 52.0}
{"epoch": 5, "training_loss": 0.7066644072532654, "training_acc": 53.0, "val_loss": 0.7141435813903808, "val_acc": 48.0}
{"epoch": 6, "training_loss": 0.7356008195877075, "training_acc": 45.0, "val_loss": 0.6942017292976379, "val_acc": 48.0}
{"epoch": 7, "training_loss": 0.7191225385665894, "training_acc": 47.0, "val_loss": 0.7011329674720764, "val_acc": 48.0}
{"epoch": 8, "training_loss": 0.7506809520721436, "training_acc": 41.0, "val_loss": 0.7189168858528138, "val_acc": 48.0}
{"epoch": 9, "training_loss": 0.7308884930610656, "training_acc": 51.0, "val_loss": 0.769290165901184, "val_acc": 52.0}
{"epoch": 10, "training_loss": 0.7842106389999389, "training_acc": 49.0, "val_loss": 0.6948939657211304, "val_acc": 52.0}
{"epoch": 11, "training_loss": 0.7196618461608887, "training_acc": 53.0, "val_loss": 0.7216965937614441, "val_acc": 48.0}
{"epoch": 12, "training_loss": 0.7703494310379029, "training_acc": 47.0, "val_loss": 0.7684115481376648, "val_acc": 52.0}
{"epoch": 13, "training_loss": 0.7456361675262451, "training_acc": 43.0, "val_loss": 0.6926180386543274, "val_acc": 52.0}
{"epoch": 14, "training_loss": 0.8045568633079528, "training_acc": 41.0, "val_loss": 0.692685739994049, "val_acc": 52.0}
{"epoch": 15, "training_loss": 0.7669419479370118, "training_acc": 47.0, "val_loss": 0.8013466238975525, "val_acc": 52.0}
{"epoch": 16, "training_loss": 0.7621692276000976, "training_acc": 41.0, "val_loss": 0.6996788358688355, "val_acc": 52.0}
{"epoch": 17, "training_loss": 0.6989173817634583, "training_acc": 55.0, "val_loss": 0.7990291142463684, "val_acc": 48.0}
{"epoch": 18, "training_loss": 0.7345113325119018, "training_acc": 49.0, "val_loss": 0.7013192105293274, "val_acc": 52.0}
{"epoch": 19, "training_loss": 0.7310671234130859, "training_acc": 53.0, "val_loss": 0.6925239014625549, "val_acc": 52.0}
{"epoch": 20, "training_loss": 0.704308671951294, "training_acc": 47.0, "val_loss": 0.7046400904655457, "val_acc": 52.0}
{"epoch": 21, "training_loss": 0.7195523309707642, "training_acc": 53.0, "val_loss": 0.6998211765289306, "val_acc": 48.0}
{"epoch": 22, "training_loss": 0.7270748805999756, "training_acc": 45.0, "val_loss": 0.7168906807899476, "val_acc": 52.0}
{"epoch": 23, "training_loss": 0.756399998664856, "training_acc": 53.0, "val_loss": 0.7327223634719848, "val_acc": 48.0}
{"epoch": 24, "training_loss": 0.7752065563201904, "training_acc": 47.0, "val_loss": 0.6997309923171997, "val_acc": 52.0}
{"epoch": 25, "training_loss": 0.7358376455307006, "training_acc": 53.0, "val_loss": 0.6923509454727172, "val_acc": 52.0}
{"epoch": 26, "training_loss": 0.7194948387145996, "training_acc": 43.0, "val_loss": 0.7224094438552856, "val_acc": 48.0}
{"epoch": 27, "training_loss": 0.7245833063125611, "training_acc": 39.0, "val_loss": 0.6923614501953125, "val_acc": 52.0}
{"epoch": 28, "training_loss": 0.6935105419158936, "training_acc": 51.0, "val_loss": 0.6964374876022339, "val_acc": 52.0}
{"epoch": 29, "training_loss": 0.7083543300628662, "training_acc": 43.0, "val_loss": 0.7275337982177734, "val_acc": 52.0}
{"epoch": 30, "training_loss": 0.7261058139801025, "training_acc": 53.0, "val_loss": 0.715096402168274, "val_acc": 48.0}
{"epoch": 31, "training_loss": 0.7588189768791199, "training_acc": 43.0, "val_loss": 0.6957319760322571, "val_acc": 52.0}
{"epoch": 32, "training_loss": 0.6908536005020142, "training_acc": 57.0, "val_loss": 0.7928828954696655, "val_acc": 48.0}
{"epoch": 33, "training_loss": 0.8230668616294861, "training_acc": 51.0, "val_loss": 0.8161870169639588, "val_acc": 52.0}
{"epoch": 34, "training_loss": 0.7726187038421631, "training_acc": 53.0, "val_loss": 0.7035105109214783, "val_acc": 48.0}
{"epoch": 35, "training_loss": 0.7072156667709351, "training_acc": 43.0, "val_loss": 0.7002305269241333, "val_acc": 48.0}
{"epoch": 36, "training_loss": 0.7031389570236206, "training_acc": 45.0, "val_loss": 0.692361843585968, "val_acc": 52.0}
{"epoch": 37, "training_loss": 0.6990407991409302, "training_acc": 47.0, "val_loss": 0.7010270953178406, "val_acc": 52.0}
{"epoch": 38, "training_loss": 0.7191163778305054, "training_acc": 51.0, "val_loss": 0.6963301038742066, "val_acc": 48.0}
{"epoch": 39, "training_loss": 0.7191239166259765, "training_acc": 45.0, "val_loss": 0.6991016054153443, "val_acc": 52.0}
{"epoch": 40, "training_loss": 0.7080362510681152, "training_acc": 47.0, "val_loss": 0.6986970448493958, "val_acc": 48.0}
{"epoch": 41, "training_loss": 0.7079767084121704, "training_acc": 43.0, "val_loss": 0.6988818073272705, "val_acc": 52.0}
{"epoch": 42, "training_loss": 0.7223577260971069, "training_acc": 41.0, "val_loss": 0.7212618589401245, "val_acc": 52.0}
{"epoch": 43, "training_loss": 0.7588326239585876, "training_acc": 45.0, "val_loss": 0.6926574397087097, "val_acc": 52.0}
{"epoch": 44, "training_loss": 0.7206456565856934, "training_acc": 53.0, "val_loss": 0.7182937192916871, "val_acc": 48.0}
