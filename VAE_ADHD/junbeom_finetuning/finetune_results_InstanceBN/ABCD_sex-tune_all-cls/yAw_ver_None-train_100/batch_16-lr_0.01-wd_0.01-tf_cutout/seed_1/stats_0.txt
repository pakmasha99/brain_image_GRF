"main_modify.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 1 --task ABCD_sex --input_option BT_org --learning_rate 1e-2 --batch_size 16 --weight_decay 1e-2 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 1.2442522263526916, "training_acc": 47.0, "val_loss": 1.0888818454742433, "val_acc": 52.0}
{"epoch": 1, "training_loss": 0.8638660430908203, "training_acc": 47.0, "val_loss": 0.7671758675575256, "val_acc": 52.0}
{"epoch": 2, "training_loss": 0.8128680920600891, "training_acc": 53.0, "val_loss": 0.7258136701583863, "val_acc": 48.0}
{"epoch": 3, "training_loss": 0.7886296415328979, "training_acc": 51.0, "val_loss": 0.7764268207550049, "val_acc": 52.0}
{"epoch": 4, "training_loss": 0.7825675320625305, "training_acc": 43.0, "val_loss": 0.8528104114532471, "val_acc": 52.0}
{"epoch": 5, "training_loss": 0.757520523071289, "training_acc": 55.0, "val_loss": 0.7658912253379822, "val_acc": 48.0}
{"epoch": 6, "training_loss": 0.8121055626869201, "training_acc": 47.0, "val_loss": 0.7291330552101135, "val_acc": 48.0}
{"epoch": 7, "training_loss": 0.7103579902648925, "training_acc": 49.0, "val_loss": 0.7307874298095703, "val_acc": 52.0}
{"epoch": 8, "training_loss": 0.724579176902771, "training_acc": 41.0, "val_loss": 0.6949421811103821, "val_acc": 52.0}
{"epoch": 9, "training_loss": 0.7122834086418152, "training_acc": 55.0, "val_loss": 0.7489523005485534, "val_acc": 48.0}
{"epoch": 10, "training_loss": 0.7018415451049804, "training_acc": 55.0, "val_loss": 0.6944149470329285, "val_acc": 52.0}
{"epoch": 11, "training_loss": 0.7289016437530518, "training_acc": 41.0, "val_loss": 0.7360029983520507, "val_acc": 52.0}
{"epoch": 12, "training_loss": 0.7235264348983764, "training_acc": 53.0, "val_loss": 0.7161901044845581, "val_acc": 48.0}
{"epoch": 13, "training_loss": 0.7317971754074096, "training_acc": 51.0, "val_loss": 0.8514782691001892, "val_acc": 48.0}
{"epoch": 14, "training_loss": 0.7355129814147949, "training_acc": 51.0, "val_loss": 0.6935583758354187, "val_acc": 48.0}
{"epoch": 15, "training_loss": 0.7148309063911438, "training_acc": 51.0, "val_loss": 0.713549861907959, "val_acc": 48.0}
{"epoch": 16, "training_loss": 0.7232717752456665, "training_acc": 49.0, "val_loss": 0.700158269405365, "val_acc": 52.0}
{"epoch": 17, "training_loss": 0.7017771434783936, "training_acc": 53.0, "val_loss": 0.7361574935913086, "val_acc": 48.0}
{"epoch": 18, "training_loss": 0.7102755546569824, "training_acc": 47.0, "val_loss": 0.7918065357208252, "val_acc": 52.0}
{"epoch": 19, "training_loss": 0.7425559377670288, "training_acc": 45.0, "val_loss": 0.6936149549484253, "val_acc": 52.0}
{"epoch": 20, "training_loss": 0.7320644974708557, "training_acc": 45.0, "val_loss": 0.6960560059547425, "val_acc": 52.0}
{"epoch": 21, "training_loss": 0.706601800918579, "training_acc": 45.0, "val_loss": 0.7225589871406555, "val_acc": 52.0}
{"epoch": 22, "training_loss": 0.7124696087837219, "training_acc": 55.0, "val_loss": 0.7456412720680237, "val_acc": 48.0}
{"epoch": 23, "training_loss": 0.7318049669265747, "training_acc": 41.0, "val_loss": 0.7045511555671692, "val_acc": 52.0}
{"epoch": 24, "training_loss": 0.7391609048843384, "training_acc": 39.0, "val_loss": 0.7216254162788391, "val_acc": 52.0}
{"epoch": 25, "training_loss": 0.7297066974639893, "training_acc": 53.0, "val_loss": 0.6966867852210998, "val_acc": 52.0}
{"epoch": 26, "training_loss": 0.7471363496780395, "training_acc": 45.0, "val_loss": 0.7352960562705994, "val_acc": 52.0}
{"epoch": 27, "training_loss": 0.7269132685661316, "training_acc": 53.0, "val_loss": 0.7651784873008728, "val_acc": 48.0}
{"epoch": 28, "training_loss": 0.8762573003768921, "training_acc": 47.0, "val_loss": 0.7395901155471801, "val_acc": 52.0}
{"epoch": 29, "training_loss": 0.7905701684951782, "training_acc": 53.0, "val_loss": 0.7117315220832825, "val_acc": 48.0}
{"epoch": 30, "training_loss": 0.7151585030555725, "training_acc": 43.0, "val_loss": 0.7020070338249207, "val_acc": 48.0}
{"epoch": 31, "training_loss": 0.7247148513793945, "training_acc": 45.0, "val_loss": 0.6988772559165954, "val_acc": 48.0}
{"epoch": 32, "training_loss": 0.7150724315643311, "training_acc": 45.0, "val_loss": 0.7108355116844177, "val_acc": 52.0}
{"epoch": 33, "training_loss": 0.7232947325706482, "training_acc": 49.0, "val_loss": 0.6924547648429871, "val_acc": 52.0}
{"epoch": 34, "training_loss": 0.7296657037734985, "training_acc": 53.0, "val_loss": 0.7074284291267395, "val_acc": 48.0}
{"epoch": 35, "training_loss": 0.7348464822769165, "training_acc": 47.0, "val_loss": 0.6960457777976989, "val_acc": 52.0}
{"epoch": 36, "training_loss": 0.6987689781188965, "training_acc": 53.0, "val_loss": 0.713558132648468, "val_acc": 48.0}
{"epoch": 37, "training_loss": 0.7385531854629517, "training_acc": 49.0, "val_loss": 0.7128697800636291, "val_acc": 52.0}
{"epoch": 38, "training_loss": 0.7069233655929565, "training_acc": 53.0, "val_loss": 0.6936724495887756, "val_acc": 48.0}
{"epoch": 39, "training_loss": 0.695497932434082, "training_acc": 51.0, "val_loss": 0.6941540193557739, "val_acc": 48.0}
{"epoch": 40, "training_loss": 0.7081826448440551, "training_acc": 49.0, "val_loss": 0.702013475894928, "val_acc": 48.0}
{"epoch": 41, "training_loss": 0.7125114393234253, "training_acc": 45.0, "val_loss": 0.7038111352920532, "val_acc": 52.0}
{"epoch": 42, "training_loss": 0.7106570315361023, "training_acc": 47.0, "val_loss": 0.6923665428161621, "val_acc": 52.0}
{"epoch": 43, "training_loss": 0.7080947709083557, "training_acc": 39.0, "val_loss": 0.7156919646263122, "val_acc": 52.0}
{"epoch": 44, "training_loss": 0.7075030517578125, "training_acc": 53.0, "val_loss": 0.7030394339561462, "val_acc": 52.0}
{"epoch": 45, "training_loss": 0.711166033744812, "training_acc": 53.0, "val_loss": 0.7071891021728516, "val_acc": 48.0}
{"epoch": 46, "training_loss": 0.7654681444168091, "training_acc": 49.0, "val_loss": 0.7563901472091675, "val_acc": 52.0}
{"epoch": 47, "training_loss": 0.7620310831069946, "training_acc": 53.0, "val_loss": 0.6928436422348022, "val_acc": 52.0}
{"epoch": 48, "training_loss": 0.6977049160003662, "training_acc": 51.0, "val_loss": 0.6946640229225158, "val_acc": 48.0}
{"epoch": 49, "training_loss": 0.7157505202293396, "training_acc": 41.0, "val_loss": 0.6933459258079528, "val_acc": 48.0}
{"epoch": 50, "training_loss": 0.6980292224884033, "training_acc": 53.0, "val_loss": 0.6967011308670044, "val_acc": 52.0}
{"epoch": 51, "training_loss": 0.699686336517334, "training_acc": 43.0, "val_loss": 0.699936306476593, "val_acc": 52.0}
{"epoch": 52, "training_loss": 0.7189438343048096, "training_acc": 51.0, "val_loss": 0.6938285541534424, "val_acc": 48.0}
{"epoch": 53, "training_loss": 0.7028705263137818, "training_acc": 51.0, "val_loss": 0.6986196374893189, "val_acc": 48.0}
{"epoch": 54, "training_loss": 0.7159348773956299, "training_acc": 47.0, "val_loss": 0.722411036491394, "val_acc": 52.0}
{"epoch": 55, "training_loss": 0.7481581687927246, "training_acc": 37.0, "val_loss": 0.7593064522743225, "val_acc": 52.0}
{"epoch": 56, "training_loss": 0.7349331474304199, "training_acc": 53.0, "val_loss": 0.692421464920044, "val_acc": 52.0}
{"epoch": 57, "training_loss": 0.7187950015068054, "training_acc": 41.0, "val_loss": 0.6924984002113342, "val_acc": 52.0}
{"epoch": 58, "training_loss": 0.7032087779045105, "training_acc": 45.0, "val_loss": 0.6925490570068359, "val_acc": 52.0}
{"epoch": 59, "training_loss": 0.7119090366363525, "training_acc": 45.0, "val_loss": 0.695629997253418, "val_acc": 52.0}
{"epoch": 60, "training_loss": 0.7074647188186646, "training_acc": 43.0, "val_loss": 0.6936632132530213, "val_acc": 48.0}
{"epoch": 61, "training_loss": 0.7333773136138916, "training_acc": 45.0, "val_loss": 0.7277797746658325, "val_acc": 48.0}
