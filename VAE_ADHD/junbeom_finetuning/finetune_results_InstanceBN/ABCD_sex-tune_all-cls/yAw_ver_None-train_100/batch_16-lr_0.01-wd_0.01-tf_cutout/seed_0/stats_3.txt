"main_modify.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option BT_org --learning_rate 1e-2 --batch_size 16 --weight_decay 1e-2 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 1.2979832100868225, "training_acc": 45.0, "val_loss": 1.059536747932434, "val_acc": 52.0}
{"epoch": 1, "training_loss": 0.8795432996749878, "training_acc": 53.0, "val_loss": 0.7558001065254212, "val_acc": 52.0}
{"epoch": 2, "training_loss": 0.8135684108734131, "training_acc": 53.0, "val_loss": 0.7227212572097779, "val_acc": 48.0}
{"epoch": 3, "training_loss": 0.736399655342102, "training_acc": 49.0, "val_loss": 0.6923845458030701, "val_acc": 52.0}
{"epoch": 4, "training_loss": 0.7071100687980652, "training_acc": 51.0, "val_loss": 0.8116534757614136, "val_acc": 52.0}
{"epoch": 5, "training_loss": 0.7807034397125244, "training_acc": 53.0, "val_loss": 0.8054458379745484, "val_acc": 48.0}
{"epoch": 6, "training_loss": 0.9077328443527222, "training_acc": 39.0, "val_loss": 0.9625340771675109, "val_acc": 48.0}
{"epoch": 7, "training_loss": 0.8050808334350585, "training_acc": 51.0, "val_loss": 0.7187653303146362, "val_acc": 52.0}
{"epoch": 8, "training_loss": 0.734586923122406, "training_acc": 41.0, "val_loss": 0.6949206614494323, "val_acc": 52.0}
{"epoch": 9, "training_loss": 0.727933931350708, "training_acc": 47.0, "val_loss": 0.6962084817886353, "val_acc": 48.0}
{"epoch": 10, "training_loss": 0.7127163600921631, "training_acc": 51.0, "val_loss": 0.7686567425727844, "val_acc": 52.0}
{"epoch": 11, "training_loss": 0.7418575096130371, "training_acc": 45.0, "val_loss": 0.7199718976020812, "val_acc": 52.0}
{"epoch": 12, "training_loss": 0.7179523730278015, "training_acc": 47.0, "val_loss": 0.7286486458778382, "val_acc": 52.0}
{"epoch": 13, "training_loss": 0.7026796913146973, "training_acc": 51.0, "val_loss": 0.7644241309165954, "val_acc": 48.0}
{"epoch": 14, "training_loss": 0.7676422500610351, "training_acc": 39.0, "val_loss": 0.6969729232788086, "val_acc": 52.0}
{"epoch": 15, "training_loss": 0.7245336580276489, "training_acc": 55.0, "val_loss": 0.8872633695602417, "val_acc": 48.0}
{"epoch": 16, "training_loss": 0.7937155771255493, "training_acc": 55.0, "val_loss": 0.7101201367378235, "val_acc": 52.0}
{"epoch": 17, "training_loss": 0.7164451551437377, "training_acc": 45.0, "val_loss": 0.7355853605270386, "val_acc": 48.0}
{"epoch": 18, "training_loss": 0.7158477926254272, "training_acc": 49.0, "val_loss": 0.6929585981369019, "val_acc": 52.0}
{"epoch": 19, "training_loss": 0.7433412265777588, "training_acc": 47.0, "val_loss": 0.7671917772293091, "val_acc": 52.0}
{"epoch": 20, "training_loss": 0.7507879590988159, "training_acc": 53.0, "val_loss": 0.7079737877845764, "val_acc": 48.0}
{"epoch": 21, "training_loss": 0.7404559564590454, "training_acc": 53.0, "val_loss": 0.7098087668418884, "val_acc": 52.0}
{"epoch": 22, "training_loss": 0.7068220996856689, "training_acc": 45.0, "val_loss": 0.6923575162887573, "val_acc": 52.0}
{"epoch": 23, "training_loss": 0.724057297706604, "training_acc": 53.0, "val_loss": 0.7120824813842773, "val_acc": 48.0}
{"epoch": 24, "training_loss": 0.7311045217514038, "training_acc": 47.0, "val_loss": 0.6933361554145813, "val_acc": 52.0}
{"epoch": 25, "training_loss": 0.7029070949554443, "training_acc": 53.0, "val_loss": 0.739589307308197, "val_acc": 52.0}
{"epoch": 26, "training_loss": 0.6994891023635864, "training_acc": 55.0, "val_loss": 0.8367273068428039, "val_acc": 48.0}
{"epoch": 27, "training_loss": 0.825312671661377, "training_acc": 51.0, "val_loss": 0.7614509892463684, "val_acc": 52.0}
{"epoch": 28, "training_loss": 0.782954728603363, "training_acc": 45.0, "val_loss": 0.6972537922859192, "val_acc": 48.0}
{"epoch": 29, "training_loss": 0.7366088676452637, "training_acc": 43.0, "val_loss": 0.6930191946029663, "val_acc": 52.0}
{"epoch": 30, "training_loss": 0.7096438789367676, "training_acc": 41.0, "val_loss": 0.7047491741180419, "val_acc": 52.0}
{"epoch": 31, "training_loss": 0.7342127013206482, "training_acc": 57.0, "val_loss": 0.8193814945220947, "val_acc": 48.0}
{"epoch": 32, "training_loss": 0.8233459615707397, "training_acc": 47.0, "val_loss": 0.705047435760498, "val_acc": 52.0}
{"epoch": 33, "training_loss": 0.7362695050239563, "training_acc": 53.0, "val_loss": 0.7092916226387024, "val_acc": 48.0}
{"epoch": 34, "training_loss": 0.7094211935997009, "training_acc": 45.0, "val_loss": 0.697136070728302, "val_acc": 52.0}
{"epoch": 35, "training_loss": 0.7137726521492005, "training_acc": 53.0, "val_loss": 0.7083522510528565, "val_acc": 48.0}
{"epoch": 36, "training_loss": 0.7220450448989868, "training_acc": 47.0, "val_loss": 0.719635009765625, "val_acc": 52.0}
{"epoch": 37, "training_loss": 0.7086134433746338, "training_acc": 53.0, "val_loss": 0.6931210565567016, "val_acc": 52.0}
{"epoch": 38, "training_loss": 0.7024152588844299, "training_acc": 45.0, "val_loss": 0.7186033987998962, "val_acc": 48.0}
{"epoch": 39, "training_loss": 0.7374989509582519, "training_acc": 51.0, "val_loss": 0.7701409006118775, "val_acc": 52.0}
{"epoch": 40, "training_loss": 0.7420956301689148, "training_acc": 53.0, "val_loss": 0.6955779981613159, "val_acc": 48.0}
{"epoch": 41, "training_loss": 0.7195031356811523, "training_acc": 49.0, "val_loss": 0.7007593154907227, "val_acc": 52.0}
