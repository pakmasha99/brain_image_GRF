"main_modify.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option BT_org --learning_rate 1e-2 --batch_size 16 --weight_decay 1e-2 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 1.3403370189666748, "training_acc": 47.0, "val_loss": 0.7229033398628235, "val_acc": 52.0}
{"epoch": 1, "training_loss": 0.9050073218345642, "training_acc": 45.0, "val_loss": 1.021737666130066, "val_acc": 52.0}
{"epoch": 2, "training_loss": 0.8688210344314575, "training_acc": 49.0, "val_loss": 0.7745473980903625, "val_acc": 48.0}
{"epoch": 3, "training_loss": 0.7415253925323486, "training_acc": 51.0, "val_loss": 0.699355959892273, "val_acc": 52.0}
{"epoch": 4, "training_loss": 0.7295779728889465, "training_acc": 37.0, "val_loss": 0.7015441489219666, "val_acc": 52.0}
{"epoch": 5, "training_loss": 0.7140909385681152, "training_acc": 59.0, "val_loss": 0.8244555306434631, "val_acc": 48.0}
{"epoch": 6, "training_loss": 0.8327419042587281, "training_acc": 41.0, "val_loss": 0.9096012544631958, "val_acc": 48.0}
{"epoch": 7, "training_loss": 0.8161407661437988, "training_acc": 45.0, "val_loss": 0.698735613822937, "val_acc": 52.0}
{"epoch": 8, "training_loss": 0.6806695032119751, "training_acc": 57.0, "val_loss": 0.8375755643844605, "val_acc": 48.0}
{"epoch": 9, "training_loss": 0.7386525106430054, "training_acc": 51.0, "val_loss": 0.7672604727745056, "val_acc": 52.0}
{"epoch": 10, "training_loss": 0.7318015623092652, "training_acc": 47.0, "val_loss": 0.7549393343925476, "val_acc": 48.0}
{"epoch": 11, "training_loss": 0.7961499094963074, "training_acc": 47.0, "val_loss": 1.0058904814720153, "val_acc": 48.0}
{"epoch": 12, "training_loss": 0.9378806674480438, "training_acc": 49.0, "val_loss": 1.0184152626991272, "val_acc": 52.0}
{"epoch": 13, "training_loss": 0.9032262182235717, "training_acc": 47.0, "val_loss": 0.820869791507721, "val_acc": 48.0}
{"epoch": 14, "training_loss": 0.757330174446106, "training_acc": 45.0, "val_loss": 0.7013015842437744, "val_acc": 52.0}
{"epoch": 15, "training_loss": 0.700020809173584, "training_acc": 53.0, "val_loss": 0.8124710011482239, "val_acc": 52.0}
{"epoch": 16, "training_loss": 0.7518189382553101, "training_acc": 47.0, "val_loss": 0.8699411821365356, "val_acc": 52.0}
{"epoch": 17, "training_loss": 0.7514427971839904, "training_acc": 53.0, "val_loss": 0.7798911023139954, "val_acc": 48.0}
{"epoch": 18, "training_loss": 0.7245507097244263, "training_acc": 49.0, "val_loss": 0.6939204263687134, "val_acc": 48.0}
{"epoch": 19, "training_loss": 0.7335268592834473, "training_acc": 45.0, "val_loss": 0.6925681710243226, "val_acc": 52.0}
{"epoch": 20, "training_loss": 0.7286127138137818, "training_acc": 53.0, "val_loss": 0.7156021070480346, "val_acc": 48.0}
{"epoch": 21, "training_loss": 0.7543111371994019, "training_acc": 43.0, "val_loss": 0.6992203545570373, "val_acc": 48.0}
{"epoch": 22, "training_loss": 0.7170812106132507, "training_acc": 47.0, "val_loss": 0.6932610058784485, "val_acc": 48.0}
{"epoch": 23, "training_loss": 0.6957706665992737, "training_acc": 53.0, "val_loss": 0.8831533765792847, "val_acc": 52.0}
{"epoch": 24, "training_loss": 0.7802852487564087, "training_acc": 51.0, "val_loss": 0.7083453440666199, "val_acc": 48.0}
{"epoch": 25, "training_loss": 0.7097416472434998, "training_acc": 51.0, "val_loss": 0.7516164755821229, "val_acc": 52.0}
{"epoch": 26, "training_loss": 0.8008184814453125, "training_acc": 53.0, "val_loss": 0.7434473800659179, "val_acc": 48.0}
{"epoch": 27, "training_loss": 0.7433630037307739, "training_acc": 47.0, "val_loss": 0.7034545135498047, "val_acc": 52.0}
{"epoch": 28, "training_loss": 0.7179017543792725, "training_acc": 49.0, "val_loss": 0.6925305533409118, "val_acc": 52.0}
{"epoch": 29, "training_loss": 0.6939087224006653, "training_acc": 51.0, "val_loss": 0.6961468434333802, "val_acc": 52.0}
{"epoch": 30, "training_loss": 0.7749571514129638, "training_acc": 51.0, "val_loss": 0.7200622272491455, "val_acc": 48.0}
{"epoch": 31, "training_loss": 0.7287240219116211, "training_acc": 41.0, "val_loss": 0.7053322696685791, "val_acc": 52.0}
{"epoch": 32, "training_loss": 0.7024068069458008, "training_acc": 53.0, "val_loss": 0.7185608792304993, "val_acc": 52.0}
{"epoch": 33, "training_loss": 0.7196713328361511, "training_acc": 53.0, "val_loss": 0.6967703509330749, "val_acc": 48.0}
{"epoch": 34, "training_loss": 0.7065182542800903, "training_acc": 47.0, "val_loss": 0.6985307431221008, "val_acc": 52.0}
{"epoch": 35, "training_loss": 0.7407160568237304, "training_acc": 49.0, "val_loss": 0.6938301134109497, "val_acc": 52.0}
{"epoch": 36, "training_loss": 0.6993382883071899, "training_acc": 53.0, "val_loss": 0.695147922039032, "val_acc": 48.0}
{"epoch": 37, "training_loss": 0.7088252234458924, "training_acc": 45.0, "val_loss": 0.6923693943023682, "val_acc": 52.0}
{"epoch": 38, "training_loss": 0.6970536184310913, "training_acc": 47.0, "val_loss": 0.6923485207557678, "val_acc": 52.0}
{"epoch": 39, "training_loss": 0.7189799809455871, "training_acc": 41.0, "val_loss": 0.6935649156570435, "val_acc": 48.0}
{"epoch": 40, "training_loss": 0.706220600605011, "training_acc": 39.0, "val_loss": 0.7044090104103088, "val_acc": 48.0}
{"epoch": 41, "training_loss": 0.7543805289268494, "training_acc": 41.0, "val_loss": 0.7131246519088745, "val_acc": 52.0}
{"epoch": 42, "training_loss": 0.7193565988540649, "training_acc": 45.0, "val_loss": 0.6923486733436585, "val_acc": 52.0}
{"epoch": 43, "training_loss": 0.6935863995552063, "training_acc": 51.0, "val_loss": 0.7037698006629944, "val_acc": 52.0}
{"epoch": 44, "training_loss": 0.698463168144226, "training_acc": 53.0, "val_loss": 0.6944712328910828, "val_acc": 48.0}
{"epoch": 45, "training_loss": 0.6984099197387695, "training_acc": 47.0, "val_loss": 0.6950427365303039, "val_acc": 52.0}
{"epoch": 46, "training_loss": 0.7047619485855102, "training_acc": 53.0, "val_loss": 0.6927293705940246, "val_acc": 52.0}
{"epoch": 47, "training_loss": 0.6994962072372437, "training_acc": 47.0, "val_loss": 0.7289076519012451, "val_acc": 52.0}
{"epoch": 48, "training_loss": 0.7683735847473144, "training_acc": 53.0, "val_loss": 0.7022959542274475, "val_acc": 48.0}
{"epoch": 49, "training_loss": 0.7166154718399048, "training_acc": 47.0, "val_loss": 0.7100634789466858, "val_acc": 48.0}
{"epoch": 50, "training_loss": 0.7044404745101929, "training_acc": 49.0, "val_loss": 0.6960373997688294, "val_acc": 52.0}
{"epoch": 51, "training_loss": 0.7199969005584717, "training_acc": 45.0, "val_loss": 0.6992758655548096, "val_acc": 48.0}
{"epoch": 52, "training_loss": 0.7089086985588073, "training_acc": 45.0, "val_loss": 0.6959082126617432, "val_acc": 52.0}
{"epoch": 53, "training_loss": 0.6993256282806396, "training_acc": 53.0, "val_loss": 0.6945105719566346, "val_acc": 48.0}
{"epoch": 54, "training_loss": 0.7019846534729004, "training_acc": 43.0, "val_loss": 0.6924816489219665, "val_acc": 52.0}
{"epoch": 55, "training_loss": 0.6973476767539978, "training_acc": 47.0, "val_loss": 0.7150099897384643, "val_acc": 52.0}
{"epoch": 56, "training_loss": 0.7121653747558594, "training_acc": 53.0, "val_loss": 0.6932841157913208, "val_acc": 48.0}
{"epoch": 57, "training_loss": 0.7123701786994934, "training_acc": 51.0, "val_loss": 0.8051577377319336, "val_acc": 52.0}
