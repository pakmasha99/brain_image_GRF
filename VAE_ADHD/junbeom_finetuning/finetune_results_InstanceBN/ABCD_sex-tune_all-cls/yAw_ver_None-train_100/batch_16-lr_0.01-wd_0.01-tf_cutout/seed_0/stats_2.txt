"main_modify.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option BT_org --learning_rate 1e-2 --batch_size 16 --weight_decay 1e-2 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 1.3928376483917235, "training_acc": 45.0, "val_loss": 0.916515965461731, "val_acc": 48.0}
{"epoch": 1, "training_loss": 0.7514347386360168, "training_acc": 57.0, "val_loss": 0.7795984196662903, "val_acc": 52.0}
{"epoch": 2, "training_loss": 0.816663134098053, "training_acc": 41.0, "val_loss": 0.821596257686615, "val_acc": 52.0}
{"epoch": 3, "training_loss": 0.7754674577713012, "training_acc": 49.0, "val_loss": 0.7130279159545898, "val_acc": 48.0}
{"epoch": 4, "training_loss": 0.7028159332275391, "training_acc": 51.0, "val_loss": 0.735478069782257, "val_acc": 48.0}
{"epoch": 5, "training_loss": 0.7177281022071839, "training_acc": 51.0, "val_loss": 0.7426735711097717, "val_acc": 52.0}
{"epoch": 6, "training_loss": 0.7109851217269898, "training_acc": 51.0, "val_loss": 0.7090477085113526, "val_acc": 52.0}
{"epoch": 7, "training_loss": 0.7105587053298951, "training_acc": 51.0, "val_loss": 0.6988383197784424, "val_acc": 52.0}
{"epoch": 8, "training_loss": 0.6978687429428101, "training_acc": 49.0, "val_loss": 0.6932016468048096, "val_acc": 52.0}
{"epoch": 9, "training_loss": 0.7044906949996949, "training_acc": 53.0, "val_loss": 0.7964723300933838, "val_acc": 48.0}
{"epoch": 10, "training_loss": 0.7541476321220398, "training_acc": 53.0, "val_loss": 1.011417009830475, "val_acc": 52.0}
{"epoch": 11, "training_loss": 0.7681209325790406, "training_acc": 55.0, "val_loss": 0.8167407131195068, "val_acc": 48.0}
{"epoch": 12, "training_loss": 0.7376615643501282, "training_acc": 53.0, "val_loss": 0.7290625691413879, "val_acc": 52.0}
{"epoch": 13, "training_loss": 0.7329391765594483, "training_acc": 47.0, "val_loss": 0.6951836442947388, "val_acc": 52.0}
{"epoch": 14, "training_loss": 0.7068691396713257, "training_acc": 47.0, "val_loss": 0.7493173623085022, "val_acc": 52.0}
{"epoch": 15, "training_loss": 0.731579418182373, "training_acc": 45.0, "val_loss": 0.7112232089042664, "val_acc": 52.0}
{"epoch": 16, "training_loss": 0.6949424457550049, "training_acc": 51.0, "val_loss": 0.7727327704429626, "val_acc": 48.0}
{"epoch": 17, "training_loss": 0.7334378337860108, "training_acc": 49.0, "val_loss": 0.7175988340377808, "val_acc": 48.0}
{"epoch": 18, "training_loss": 0.7072252821922302, "training_acc": 49.0, "val_loss": 0.7362178587913513, "val_acc": 52.0}
{"epoch": 19, "training_loss": 0.7319150495529175, "training_acc": 53.0, "val_loss": 0.7058941984176635, "val_acc": 48.0}
{"epoch": 20, "training_loss": 0.7100479912757873, "training_acc": 43.0, "val_loss": 0.6927207398414612, "val_acc": 52.0}
{"epoch": 21, "training_loss": 0.7002660942077636, "training_acc": 53.0, "val_loss": 0.697882878780365, "val_acc": 48.0}
{"epoch": 22, "training_loss": 0.7040347242355347, "training_acc": 51.0, "val_loss": 0.7206795763969421, "val_acc": 52.0}
{"epoch": 23, "training_loss": 0.7074882793426513, "training_acc": 51.0, "val_loss": 0.693202600479126, "val_acc": 52.0}
{"epoch": 24, "training_loss": 0.6984374284744262, "training_acc": 53.0, "val_loss": 0.6987999987602234, "val_acc": 48.0}
{"epoch": 25, "training_loss": 0.7178819608688355, "training_acc": 39.0, "val_loss": 0.6957505893707275, "val_acc": 52.0}
{"epoch": 26, "training_loss": 0.7147677397727966, "training_acc": 51.0, "val_loss": 0.6925848340988159, "val_acc": 52.0}
{"epoch": 27, "training_loss": 0.7161652493476868, "training_acc": 41.0, "val_loss": 0.6923712992668152, "val_acc": 52.0}
{"epoch": 28, "training_loss": 0.6935081434249878, "training_acc": 53.0, "val_loss": 0.6924266147613526, "val_acc": 52.0}
{"epoch": 29, "training_loss": 0.7063096737861634, "training_acc": 49.0, "val_loss": 0.6977151536941528, "val_acc": 52.0}
{"epoch": 30, "training_loss": 0.7167087888717651, "training_acc": 53.0, "val_loss": 0.717527174949646, "val_acc": 48.0}
{"epoch": 31, "training_loss": 0.7604076313972473, "training_acc": 47.0, "val_loss": 0.7740863132476806, "val_acc": 52.0}
{"epoch": 32, "training_loss": 0.7551345157623292, "training_acc": 49.0, "val_loss": 0.7014275670051575, "val_acc": 48.0}
{"epoch": 33, "training_loss": 0.701031756401062, "training_acc": 51.0, "val_loss": 0.6976434254646301, "val_acc": 52.0}
{"epoch": 34, "training_loss": 0.7056547212600708, "training_acc": 51.0, "val_loss": 0.6964878129959107, "val_acc": 48.0}
{"epoch": 35, "training_loss": 0.7067223310470581, "training_acc": 51.0, "val_loss": 0.7051184058189393, "val_acc": 52.0}
{"epoch": 36, "training_loss": 0.7048072338104248, "training_acc": 47.0, "val_loss": 0.6923964238166809, "val_acc": 52.0}
{"epoch": 37, "training_loss": 0.6975072836875915, "training_acc": 47.0, "val_loss": 0.7137142133712768, "val_acc": 52.0}
{"epoch": 38, "training_loss": 0.7257745742797852, "training_acc": 51.0, "val_loss": 0.6930503106117248, "val_acc": 52.0}
{"epoch": 39, "training_loss": 0.70328209400177, "training_acc": 53.0, "val_loss": 0.7110659551620483, "val_acc": 48.0}
{"epoch": 40, "training_loss": 0.7072116160392761, "training_acc": 47.0, "val_loss": 0.7131971788406372, "val_acc": 52.0}
{"epoch": 41, "training_loss": 0.7147287082672119, "training_acc": 53.0, "val_loss": 0.6979495596885681, "val_acc": 52.0}
{"epoch": 42, "training_loss": 0.715368013381958, "training_acc": 53.0, "val_loss": 0.7116659593582153, "val_acc": 48.0}
{"epoch": 43, "training_loss": 0.7152816915512085, "training_acc": 45.0, "val_loss": 0.7003466486930847, "val_acc": 48.0}
{"epoch": 44, "training_loss": 0.70330331325531, "training_acc": 45.0, "val_loss": 0.6935719394683838, "val_acc": 48.0}
{"epoch": 45, "training_loss": 0.7165156745910645, "training_acc": 49.0, "val_loss": 0.7920842003822327, "val_acc": 52.0}
{"epoch": 46, "training_loss": 0.7700528192520142, "training_acc": 47.0, "val_loss": 0.6930553388595581, "val_acc": 52.0}
