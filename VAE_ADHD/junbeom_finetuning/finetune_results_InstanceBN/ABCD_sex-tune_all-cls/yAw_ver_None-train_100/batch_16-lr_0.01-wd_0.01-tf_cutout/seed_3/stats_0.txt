"main_modify.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 3 --task ABCD_sex --input_option BT_org --learning_rate 1e-2 --batch_size 16 --weight_decay 1e-2 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 1.23449556350708, "training_acc": 49.0, "val_loss": 0.7407110309600831, "val_acc": 48.0}
{"epoch": 1, "training_loss": 0.7988926267623901, "training_acc": 47.0, "val_loss": 0.8908335995674134, "val_acc": 48.0}
{"epoch": 2, "training_loss": 0.7617517614364624, "training_acc": 59.0, "val_loss": 0.9916328406333923, "val_acc": 52.0}
{"epoch": 3, "training_loss": 0.7856439352035522, "training_acc": 59.0, "val_loss": 0.9130513119697571, "val_acc": 48.0}
{"epoch": 4, "training_loss": 0.812416763305664, "training_acc": 55.0, "val_loss": 0.7086767196655274, "val_acc": 48.0}
{"epoch": 5, "training_loss": 0.8305229282379151, "training_acc": 47.0, "val_loss": 0.8034883570671082, "val_acc": 52.0}
{"epoch": 6, "training_loss": 0.7851532459259033, "training_acc": 51.0, "val_loss": 0.7295745921134948, "val_acc": 48.0}
{"epoch": 7, "training_loss": 0.7881299138069153, "training_acc": 43.0, "val_loss": 0.7660387873649597, "val_acc": 48.0}
{"epoch": 8, "training_loss": 0.7236132788658142, "training_acc": 49.0, "val_loss": 0.7436885190010071, "val_acc": 52.0}
{"epoch": 9, "training_loss": 0.7207015872001648, "training_acc": 55.0, "val_loss": 0.6994642043113708, "val_acc": 48.0}
{"epoch": 10, "training_loss": 0.6874883699417115, "training_acc": 51.0, "val_loss": 0.9145087575912476, "val_acc": 52.0}
{"epoch": 11, "training_loss": 0.7805166959762573, "training_acc": 55.0, "val_loss": 0.7266802859306335, "val_acc": 48.0}
{"epoch": 12, "training_loss": 0.7429960870742798, "training_acc": 47.0, "val_loss": 0.7629916739463806, "val_acc": 48.0}
{"epoch": 13, "training_loss": 0.7513105678558349, "training_acc": 45.0, "val_loss": 0.6939490222930909, "val_acc": 52.0}
{"epoch": 14, "training_loss": 0.7245158815383911, "training_acc": 45.0, "val_loss": 0.7129735898971558, "val_acc": 52.0}
{"epoch": 15, "training_loss": 0.7088894271850585, "training_acc": 47.0, "val_loss": 0.6991322255134582, "val_acc": 52.0}
{"epoch": 16, "training_loss": 0.7324271941184998, "training_acc": 49.0, "val_loss": 0.719648597240448, "val_acc": 52.0}
{"epoch": 17, "training_loss": 0.7273724389076233, "training_acc": 43.0, "val_loss": 0.7020891213417053, "val_acc": 48.0}
{"epoch": 18, "training_loss": 0.7080433177947998, "training_acc": 51.0, "val_loss": 0.6996838974952698, "val_acc": 52.0}
{"epoch": 19, "training_loss": 0.7098544692993164, "training_acc": 51.0, "val_loss": 0.7120241594314575, "val_acc": 52.0}
{"epoch": 20, "training_loss": 0.7110225963592529, "training_acc": 49.0, "val_loss": 0.6923474955558777, "val_acc": 52.0}
{"epoch": 21, "training_loss": 0.700015127658844, "training_acc": 49.0, "val_loss": 0.7082648086547851, "val_acc": 52.0}
{"epoch": 22, "training_loss": 0.7157889032363891, "training_acc": 45.0, "val_loss": 0.6979428553581237, "val_acc": 52.0}
{"epoch": 23, "training_loss": 0.7161855936050415, "training_acc": 53.0, "val_loss": 0.7348247838020324, "val_acc": 48.0}
{"epoch": 24, "training_loss": 0.7204209566116333, "training_acc": 47.0, "val_loss": 0.6959425830841064, "val_acc": 52.0}
{"epoch": 25, "training_loss": 0.707585768699646, "training_acc": 53.0, "val_loss": 0.7164772939682007, "val_acc": 52.0}
{"epoch": 26, "training_loss": 0.7393314313888549, "training_acc": 49.0, "val_loss": 0.696811535358429, "val_acc": 52.0}
{"epoch": 27, "training_loss": 0.7313476276397705, "training_acc": 53.0, "val_loss": 0.7065627884864807, "val_acc": 48.0}
{"epoch": 28, "training_loss": 0.736565101146698, "training_acc": 47.0, "val_loss": 0.6998615193367005, "val_acc": 52.0}
{"epoch": 29, "training_loss": 0.7011615180969238, "training_acc": 53.0, "val_loss": 0.7085548901557922, "val_acc": 52.0}
{"epoch": 30, "training_loss": 0.7012293815612793, "training_acc": 53.0, "val_loss": 0.7193761420249939, "val_acc": 48.0}
{"epoch": 31, "training_loss": 0.7218335437774658, "training_acc": 49.0, "val_loss": 0.7397446417808533, "val_acc": 52.0}
{"epoch": 32, "training_loss": 0.7283858704566956, "training_acc": 53.0, "val_loss": 0.6945295357704162, "val_acc": 48.0}
{"epoch": 33, "training_loss": 0.7667172241210938, "training_acc": 45.0, "val_loss": 0.807523250579834, "val_acc": 52.0}
{"epoch": 34, "training_loss": 0.7525415468215942, "training_acc": 53.0, "val_loss": 0.6968761110305786, "val_acc": 48.0}
{"epoch": 35, "training_loss": 0.7024333024024964, "training_acc": 45.0, "val_loss": 0.6923841285705566, "val_acc": 52.0}
{"epoch": 36, "training_loss": 0.7021022367477417, "training_acc": 47.0, "val_loss": 0.7187652516365052, "val_acc": 52.0}
{"epoch": 37, "training_loss": 0.7061777806282044, "training_acc": 53.0, "val_loss": 0.7005933499336243, "val_acc": 48.0}
{"epoch": 38, "training_loss": 0.6975975441932678, "training_acc": 49.0, "val_loss": 0.6936548590660095, "val_acc": 52.0}
{"epoch": 39, "training_loss": 0.7002556157112122, "training_acc": 53.0, "val_loss": 0.6923606586456299, "val_acc": 52.0}
