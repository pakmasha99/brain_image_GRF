"main_modify.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 3 --task ABCD_sex --input_option BT_org --learning_rate 1e-2 --batch_size 16 --weight_decay 1e-2 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 1.1615691876411438, "training_acc": 47.0, "val_loss": 0.7505202102661133, "val_acc": 52.0}
{"epoch": 1, "training_loss": 0.7786285126209259, "training_acc": 51.0, "val_loss": 1.093239998817444, "val_acc": 52.0}
{"epoch": 2, "training_loss": 0.9108840322494507, "training_acc": 55.0, "val_loss": 0.9285482144355774, "val_acc": 48.0}
{"epoch": 3, "training_loss": 0.8751871633529663, "training_acc": 43.0, "val_loss": 0.696698272228241, "val_acc": 52.0}
{"epoch": 4, "training_loss": 0.7755237078666687, "training_acc": 47.0, "val_loss": 0.697621397972107, "val_acc": 52.0}
{"epoch": 5, "training_loss": 0.7239234209060669, "training_acc": 43.0, "val_loss": 0.6924617075920105, "val_acc": 52.0}
{"epoch": 6, "training_loss": 0.7278137493133545, "training_acc": 53.0, "val_loss": 0.6924857497215271, "val_acc": 52.0}
{"epoch": 7, "training_loss": 0.736470832824707, "training_acc": 53.0, "val_loss": 0.7360812091827392, "val_acc": 48.0}
{"epoch": 8, "training_loss": 0.7053364586830139, "training_acc": 53.0, "val_loss": 0.711861572265625, "val_acc": 52.0}
{"epoch": 9, "training_loss": 0.7777404975891113, "training_acc": 43.0, "val_loss": 0.7321254873275757, "val_acc": 52.0}
{"epoch": 10, "training_loss": 0.7195766115188599, "training_acc": 47.0, "val_loss": 0.7037003016471863, "val_acc": 48.0}
{"epoch": 11, "training_loss": 0.7022687816619873, "training_acc": 51.0, "val_loss": 0.8336115741729736, "val_acc": 52.0}
{"epoch": 12, "training_loss": 0.7287446737289429, "training_acc": 51.0, "val_loss": 0.7668119072914124, "val_acc": 52.0}
{"epoch": 13, "training_loss": 0.7097928237915039, "training_acc": 53.0, "val_loss": 0.7228557896614075, "val_acc": 48.0}
{"epoch": 14, "training_loss": 0.7410485601425171, "training_acc": 43.0, "val_loss": 0.6923685884475708, "val_acc": 52.0}
{"epoch": 15, "training_loss": 0.7285836553573608, "training_acc": 55.0, "val_loss": 0.8179760289192199, "val_acc": 48.0}
{"epoch": 16, "training_loss": 0.7162087392807007, "training_acc": 61.0, "val_loss": 0.7690774750709534, "val_acc": 52.0}
{"epoch": 17, "training_loss": 0.7257541012763977, "training_acc": 47.0, "val_loss": 0.6929936385154725, "val_acc": 52.0}
{"epoch": 18, "training_loss": 0.7050492572784424, "training_acc": 45.0, "val_loss": 0.6936048841476441, "val_acc": 52.0}
{"epoch": 19, "training_loss": 0.7247763872146606, "training_acc": 55.0, "val_loss": 0.7293759751319885, "val_acc": 48.0}
{"epoch": 20, "training_loss": 0.7164004421234131, "training_acc": 51.0, "val_loss": 0.6998058247566223, "val_acc": 52.0}
{"epoch": 21, "training_loss": 0.7124269676208496, "training_acc": 37.0, "val_loss": 0.6932183957099914, "val_acc": 48.0}
{"epoch": 22, "training_loss": 0.6977848362922668, "training_acc": 45.0, "val_loss": 0.6969829678535462, "val_acc": 52.0}
{"epoch": 23, "training_loss": 0.7427635335922241, "training_acc": 39.0, "val_loss": 0.7171376156806946, "val_acc": 52.0}
{"epoch": 24, "training_loss": 0.7470143938064575, "training_acc": 49.0, "val_loss": 0.6923496222496033, "val_acc": 52.0}
{"epoch": 25, "training_loss": 0.7090405154228211, "training_acc": 53.0, "val_loss": 0.7007127165794372, "val_acc": 48.0}
{"epoch": 26, "training_loss": 0.7141219854354859, "training_acc": 37.0, "val_loss": 0.6923599600791931, "val_acc": 52.0}
{"epoch": 27, "training_loss": 0.71031329870224, "training_acc": 53.0, "val_loss": 0.7086461186408997, "val_acc": 52.0}
{"epoch": 28, "training_loss": 0.7358132743835449, "training_acc": 45.0, "val_loss": 0.6960050821304321, "val_acc": 48.0}
{"epoch": 29, "training_loss": 0.7126543712615967, "training_acc": 49.0, "val_loss": 0.6993446826934815, "val_acc": 52.0}
{"epoch": 30, "training_loss": 0.7071824741363525, "training_acc": 47.0, "val_loss": 0.7036612701416015, "val_acc": 48.0}
{"epoch": 31, "training_loss": 0.7052101421356202, "training_acc": 49.0, "val_loss": 0.726024751663208, "val_acc": 52.0}
{"epoch": 32, "training_loss": 0.728534324169159, "training_acc": 53.0, "val_loss": 0.7132361721992493, "val_acc": 52.0}
{"epoch": 33, "training_loss": 0.7102553200721741, "training_acc": 49.0, "val_loss": 0.6927141737937927, "val_acc": 52.0}
{"epoch": 34, "training_loss": 0.7010910367965698, "training_acc": 53.0, "val_loss": 0.6938052368164063, "val_acc": 48.0}
{"epoch": 35, "training_loss": 0.7088770389556884, "training_acc": 47.0, "val_loss": 0.7047524952888489, "val_acc": 52.0}
{"epoch": 36, "training_loss": 0.7213282036781311, "training_acc": 53.0, "val_loss": 0.7031753587722779, "val_acc": 48.0}
{"epoch": 37, "training_loss": 0.7406303215026856, "training_acc": 45.0, "val_loss": 0.6926266145706177, "val_acc": 52.0}
{"epoch": 38, "training_loss": 0.7111953687667847, "training_acc": 49.0, "val_loss": 0.7022474694252014, "val_acc": 52.0}
{"epoch": 39, "training_loss": 0.7163777589797974, "training_acc": 53.0, "val_loss": 0.6945073366165161, "val_acc": 52.0}
{"epoch": 40, "training_loss": 0.6923441171646119, "training_acc": 53.0, "val_loss": 0.6929507875442504, "val_acc": 52.0}
{"epoch": 41, "training_loss": 0.716881365776062, "training_acc": 53.0, "val_loss": 0.7250447034835815, "val_acc": 48.0}
{"epoch": 42, "training_loss": 0.7055282878875733, "training_acc": 49.0, "val_loss": 0.7431203389167785, "val_acc": 52.0}
{"epoch": 43, "training_loss": 0.7228767299652099, "training_acc": 53.0, "val_loss": 0.7027079391479493, "val_acc": 48.0}
