"main_modify.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 4 --task ABCD_sex --input_option BT_org --learning_rate 1e-2 --batch_size 16 --weight_decay 1e-2 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 1.1571893429756164, "training_acc": 50.0, "val_loss": 0.7495570874214172, "val_acc": 56.0}
{"epoch": 1, "training_loss": 0.863543586730957, "training_acc": 52.0, "val_loss": 0.7537190556526184, "val_acc": 44.0}
{"epoch": 2, "training_loss": 0.7183923482894897, "training_acc": 50.0, "val_loss": 0.8079737877845764, "val_acc": 44.0}
{"epoch": 3, "training_loss": 0.779855318069458, "training_acc": 50.0, "val_loss": 0.7208811044692993, "val_acc": 44.0}
{"epoch": 4, "training_loss": 0.7858600044250488, "training_acc": 56.0, "val_loss": 0.7782568717002869, "val_acc": 56.0}
{"epoch": 5, "training_loss": 0.739406189918518, "training_acc": 50.0, "val_loss": 0.7001810073852539, "val_acc": 56.0}
{"epoch": 6, "training_loss": 0.8014445877075196, "training_acc": 50.0, "val_loss": 0.7539954233169556, "val_acc": 44.0}
{"epoch": 7, "training_loss": 0.7490082550048828, "training_acc": 52.0, "val_loss": 0.7275469303131104, "val_acc": 44.0}
{"epoch": 8, "training_loss": 0.7663869023323059, "training_acc": 50.0, "val_loss": 0.6888201570510865, "val_acc": 56.0}
{"epoch": 9, "training_loss": 0.7421281576156616, "training_acc": 54.0, "val_loss": 0.760617401599884, "val_acc": 56.0}
{"epoch": 10, "training_loss": 0.7917350625991821, "training_acc": 40.0, "val_loss": 0.6941826558113098, "val_acc": 56.0}
{"epoch": 11, "training_loss": 0.7078895163536072, "training_acc": 50.0, "val_loss": 0.6863647413253784, "val_acc": 56.0}
{"epoch": 12, "training_loss": 0.7240819144248962, "training_acc": 50.0, "val_loss": 0.990180892944336, "val_acc": 44.0}
{"epoch": 13, "training_loss": 0.8514030838012695, "training_acc": 44.0, "val_loss": 0.7837066745758057, "val_acc": 44.0}
{"epoch": 14, "training_loss": 0.7657950305938721, "training_acc": 50.0, "val_loss": 0.8008535528182983, "val_acc": 56.0}
{"epoch": 15, "training_loss": 0.8001164722442627, "training_acc": 54.0, "val_loss": 0.7128957772254944, "val_acc": 44.0}
{"epoch": 16, "training_loss": 0.7602707290649414, "training_acc": 48.0, "val_loss": 0.886786892414093, "val_acc": 44.0}
{"epoch": 17, "training_loss": 0.7729767608642578, "training_acc": 48.0, "val_loss": 0.6871115493774415, "val_acc": 56.0}
{"epoch": 18, "training_loss": 0.7103064918518066, "training_acc": 54.0, "val_loss": 0.7127383399009705, "val_acc": 56.0}
{"epoch": 19, "training_loss": 0.7391921091079712, "training_acc": 48.0, "val_loss": 0.6862350964546203, "val_acc": 56.0}
{"epoch": 20, "training_loss": 0.7013186693191529, "training_acc": 50.0, "val_loss": 0.6865409255027771, "val_acc": 56.0}
{"epoch": 21, "training_loss": 0.7027096581459046, "training_acc": 54.0, "val_loss": 0.7874591445922852, "val_acc": 44.0}
{"epoch": 22, "training_loss": 0.7637850856781006, "training_acc": 44.0, "val_loss": 0.6862496376037598, "val_acc": 56.0}
{"epoch": 23, "training_loss": 0.715941104888916, "training_acc": 40.0, "val_loss": 0.6877928280830383, "val_acc": 56.0}
{"epoch": 24, "training_loss": 0.7100878143310547, "training_acc": 44.0, "val_loss": 0.6896118783950805, "val_acc": 56.0}
{"epoch": 25, "training_loss": 0.7032569575309754, "training_acc": 52.0, "val_loss": 0.6859537816047668, "val_acc": 56.0}
{"epoch": 26, "training_loss": 0.7052922010421753, "training_acc": 52.0, "val_loss": 0.7279939579963685, "val_acc": 44.0}
{"epoch": 27, "training_loss": 0.717146053314209, "training_acc": 50.0, "val_loss": 0.6939476370811463, "val_acc": 56.0}
{"epoch": 28, "training_loss": 0.7162643337249756, "training_acc": 50.0, "val_loss": 0.6914302372932434, "val_acc": 56.0}
{"epoch": 29, "training_loss": 0.7006496238708496, "training_acc": 52.0, "val_loss": 0.7232458972930909, "val_acc": 44.0}
{"epoch": 30, "training_loss": 0.7156599521636963, "training_acc": 40.0, "val_loss": 0.6877752423286438, "val_acc": 56.0}
{"epoch": 31, "training_loss": 0.7038830471038818, "training_acc": 54.0, "val_loss": 0.7473424124717712, "val_acc": 44.0}
{"epoch": 32, "training_loss": 0.7314462184906005, "training_acc": 50.0, "val_loss": 0.7033484816551209, "val_acc": 56.0}
{"epoch": 33, "training_loss": 0.760423846244812, "training_acc": 52.0, "val_loss": 0.7160659861564637, "val_acc": 44.0}
{"epoch": 34, "training_loss": 0.75074214220047, "training_acc": 46.0, "val_loss": 0.6936799573898316, "val_acc": 44.0}
{"epoch": 35, "training_loss": 0.709272563457489, "training_acc": 42.0, "val_loss": 0.6923348236083985, "val_acc": 56.0}
{"epoch": 36, "training_loss": 0.705605993270874, "training_acc": 48.0, "val_loss": 0.7130318760871888, "val_acc": 44.0}
{"epoch": 37, "training_loss": 0.7250047373771668, "training_acc": 48.0, "val_loss": 0.6862042474746705, "val_acc": 56.0}
{"epoch": 38, "training_loss": 0.707729058265686, "training_acc": 52.0, "val_loss": 0.7222680306434631, "val_acc": 44.0}
{"epoch": 39, "training_loss": 0.7692699909210206, "training_acc": 40.0, "val_loss": 0.7421123719215393, "val_acc": 44.0}
{"epoch": 40, "training_loss": 0.7172988128662109, "training_acc": 48.0, "val_loss": 0.687740547657013, "val_acc": 56.0}
{"epoch": 41, "training_loss": 0.6942946457862854, "training_acc": 52.0, "val_loss": 0.7323356199264527, "val_acc": 44.0}
{"epoch": 42, "training_loss": 0.7256998157501221, "training_acc": 46.0, "val_loss": 0.693143002986908, "val_acc": 56.0}
{"epoch": 43, "training_loss": 0.708328275680542, "training_acc": 50.0, "val_loss": 0.6859720611572265, "val_acc": 56.0}
{"epoch": 44, "training_loss": 0.702604148387909, "training_acc": 52.0, "val_loss": 0.774597475528717, "val_acc": 44.0}
