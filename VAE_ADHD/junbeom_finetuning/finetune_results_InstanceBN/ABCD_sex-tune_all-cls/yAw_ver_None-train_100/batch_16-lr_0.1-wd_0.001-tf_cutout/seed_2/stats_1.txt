"main_modify.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 2 --task ABCD_sex --input_option BT_org --learning_rate 1e-1 --batch_size 16 --weight_decay 1e-3 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 3.527016534805298, "training_acc": 59.0, "val_loss": 2.908958730697632, "val_acc": 48.0}
{"epoch": 1, "training_loss": 1.4575806379318237, "training_acc": 51.0, "val_loss": 2.8285253620147706, "val_acc": 52.0}
{"epoch": 2, "training_loss": 2.9227917289733885, "training_acc": 47.0, "val_loss": 3.4327612113952637, "val_acc": 52.0}
{"epoch": 3, "training_loss": 3.135082035064697, "training_acc": 47.0, "val_loss": 2.7211702346801756, "val_acc": 52.0}
{"epoch": 4, "training_loss": 2.3463868999481203, "training_acc": 45.0, "val_loss": 1.8642010974884033, "val_acc": 52.0}
{"epoch": 5, "training_loss": 1.3391010856628418, "training_acc": 45.0, "val_loss": 0.76749755859375, "val_acc": 48.0}
{"epoch": 6, "training_loss": 1.7663860750198364, "training_acc": 47.0, "val_loss": 1.0641320824623108, "val_acc": 52.0}
{"epoch": 7, "training_loss": 1.2380229425430298, "training_acc": 47.0, "val_loss": 0.9831504011154175, "val_acc": 48.0}
{"epoch": 8, "training_loss": 0.7750522923469544, "training_acc": 53.0, "val_loss": 0.7619578957557678, "val_acc": 52.0}
{"epoch": 9, "training_loss": 0.9252856254577637, "training_acc": 43.0, "val_loss": 1.5786625957489013, "val_acc": 52.0}
{"epoch": 10, "training_loss": 2.1353930711746214, "training_acc": 51.0, "val_loss": 2.4004690742492674, "val_acc": 52.0}
{"epoch": 11, "training_loss": 2.0745968627929687, "training_acc": 47.0, "val_loss": 1.7014205646514893, "val_acc": 52.0}
{"epoch": 12, "training_loss": 1.3724336910247803, "training_acc": 49.0, "val_loss": 1.4044429659843445, "val_acc": 48.0}
{"epoch": 13, "training_loss": 1.2658866024017335, "training_acc": 47.0, "val_loss": 1.9139956378936767, "val_acc": 52.0}
{"epoch": 14, "training_loss": 1.1472710633277894, "training_acc": 49.0, "val_loss": 1.0739244222640991, "val_acc": 48.0}
{"epoch": 15, "training_loss": 0.8232898330688476, "training_acc": 53.0, "val_loss": 0.9386699843406677, "val_acc": 48.0}
{"epoch": 16, "training_loss": 0.9169075155258178, "training_acc": 47.0, "val_loss": 1.73041428565979, "val_acc": 48.0}
{"epoch": 17, "training_loss": 1.0787331533432007, "training_acc": 59.0, "val_loss": 1.328501625061035, "val_acc": 52.0}
{"epoch": 18, "training_loss": 1.357576265335083, "training_acc": 51.0, "val_loss": 0.6968007206916809, "val_acc": 48.0}
{"epoch": 19, "training_loss": 1.42070725440979, "training_acc": 49.0, "val_loss": 1.1578285455703736, "val_acc": 52.0}
{"epoch": 20, "training_loss": 2.076917142868042, "training_acc": 45.0, "val_loss": 2.089413013458252, "val_acc": 52.0}
{"epoch": 21, "training_loss": 1.5612814202532173, "training_acc": 51.0, "val_loss": 3.37638147354126, "val_acc": 52.0}
{"epoch": 22, "training_loss": 2.13857102394104, "training_acc": 47.0, "val_loss": 1.1587739562988282, "val_acc": 52.0}
{"epoch": 23, "training_loss": 1.2290527391433717, "training_acc": 59.0, "val_loss": 1.0568084716796875, "val_acc": 52.0}
{"epoch": 24, "training_loss": 1.384625289440155, "training_acc": 41.0, "val_loss": 0.6955152606964111, "val_acc": 48.0}
{"epoch": 25, "training_loss": 1.087241644859314, "training_acc": 45.0, "val_loss": 2.670523500442505, "val_acc": 48.0}
{"epoch": 26, "training_loss": 2.0518732261657715, "training_acc": 57.0, "val_loss": 2.9400970840454104, "val_acc": 48.0}
{"epoch": 27, "training_loss": 3.0104018688201903, "training_acc": 43.0, "val_loss": 2.26912823677063, "val_acc": 48.0}
{"epoch": 28, "training_loss": 1.778391008377075, "training_acc": 53.0, "val_loss": 3.9431895065307616, "val_acc": 48.0}
{"epoch": 29, "training_loss": 2.1923582458496096, "training_acc": 49.0, "val_loss": 0.7161646580696106, "val_acc": 48.0}
{"epoch": 30, "training_loss": 1.1514761018753052, "training_acc": 47.0, "val_loss": 1.281651544570923, "val_acc": 48.0}
{"epoch": 31, "training_loss": 1.6401292037963868, "training_acc": 47.0, "val_loss": 4.893903522491455, "val_acc": 48.0}
{"epoch": 32, "training_loss": 4.574774041175842, "training_acc": 43.0, "val_loss": 1.4040631580352783, "val_acc": 48.0}
{"epoch": 33, "training_loss": 1.2745958662033081, "training_acc": 43.0, "val_loss": 0.9534865808486939, "val_acc": 52.0}
{"epoch": 34, "training_loss": 1.9386014366149902, "training_acc": 41.0, "val_loss": 1.1866555786132813, "val_acc": 52.0}
{"epoch": 35, "training_loss": 2.017546491622925, "training_acc": 45.0, "val_loss": 3.5728477954864504, "val_acc": 48.0}
{"epoch": 36, "training_loss": 1.9456140518188476, "training_acc": 45.0, "val_loss": 0.8311607694625854, "val_acc": 52.0}
{"epoch": 37, "training_loss": 0.7823074626922607, "training_acc": 57.0, "val_loss": 1.137263503074646, "val_acc": 48.0}
{"epoch": 38, "training_loss": 1.0536026573181152, "training_acc": 41.0, "val_loss": 1.3157041788101196, "val_acc": 52.0}
{"epoch": 39, "training_loss": 1.1395218801498412, "training_acc": 45.0, "val_loss": 0.8337383651733399, "val_acc": 48.0}
{"epoch": 40, "training_loss": 0.848496208190918, "training_acc": 45.0, "val_loss": 0.7151201725006103, "val_acc": 52.0}
{"epoch": 41, "training_loss": 0.7538540935516358, "training_acc": 55.0, "val_loss": 0.7182262754440307, "val_acc": 48.0}
{"epoch": 42, "training_loss": 0.8470793151855469, "training_acc": 49.0, "val_loss": 0.9292701363563538, "val_acc": 48.0}
{"epoch": 43, "training_loss": 0.8659933686256409, "training_acc": 49.0, "val_loss": 0.9791105222702027, "val_acc": 48.0}
