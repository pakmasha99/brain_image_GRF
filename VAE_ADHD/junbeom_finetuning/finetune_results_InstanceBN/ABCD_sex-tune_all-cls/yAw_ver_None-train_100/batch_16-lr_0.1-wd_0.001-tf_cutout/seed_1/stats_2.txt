"main_modify.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 1 --task ABCD_sex --input_option BT_org --learning_rate 1e-1 --batch_size 16 --weight_decay 1e-3 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 6.838528099060059, "training_acc": 41.0, "val_loss": 0.8903178334236145, "val_acc": 48.0}
{"epoch": 1, "training_loss": 1.466983313560486, "training_acc": 51.0, "val_loss": 0.8808649516105652, "val_acc": 48.0}
{"epoch": 2, "training_loss": 1.4158345794677734, "training_acc": 47.0, "val_loss": 0.7540371704101563, "val_acc": 52.0}
{"epoch": 3, "training_loss": 1.8538097000122071, "training_acc": 45.0, "val_loss": 2.917652940750122, "val_acc": 48.0}
{"epoch": 4, "training_loss": 2.1581192207336426, "training_acc": 41.0, "val_loss": 1.1397733545303346, "val_acc": 52.0}
{"epoch": 5, "training_loss": 1.4653502368927003, "training_acc": 49.0, "val_loss": 1.2558331966400147, "val_acc": 52.0}
{"epoch": 6, "training_loss": 1.0565860557556153, "training_acc": 55.0, "val_loss": 0.9696521091461182, "val_acc": 52.0}
{"epoch": 7, "training_loss": 0.7939640593528747, "training_acc": 51.0, "val_loss": 0.9400341129302978, "val_acc": 52.0}
{"epoch": 8, "training_loss": 0.9035001945495605, "training_acc": 41.0, "val_loss": 0.7803978800773621, "val_acc": 48.0}
{"epoch": 9, "training_loss": 0.858389493227005, "training_acc": 47.0, "val_loss": 1.8721677303314208, "val_acc": 52.0}
{"epoch": 10, "training_loss": 1.5039964628219604, "training_acc": 47.0, "val_loss": 1.4267784214019776, "val_acc": 52.0}
{"epoch": 11, "training_loss": 0.8584602642059326, "training_acc": 53.0, "val_loss": 0.6937260103225708, "val_acc": 48.0}
{"epoch": 12, "training_loss": 0.7059012889862061, "training_acc": 57.0, "val_loss": 0.7087611079216003, "val_acc": 48.0}
{"epoch": 13, "training_loss": 0.7376008772850037, "training_acc": 49.0, "val_loss": 1.5043979024887084, "val_acc": 48.0}
{"epoch": 14, "training_loss": 1.111817181110382, "training_acc": 51.0, "val_loss": 1.9702434825897217, "val_acc": 52.0}
{"epoch": 15, "training_loss": 1.2132751083374023, "training_acc": 43.0, "val_loss": 1.072423858642578, "val_acc": 52.0}
{"epoch": 16, "training_loss": 1.2551778888702392, "training_acc": 43.0, "val_loss": 0.6936096954345703, "val_acc": 52.0}
{"epoch": 17, "training_loss": 1.2953299522399901, "training_acc": 49.0, "val_loss": 1.375853910446167, "val_acc": 48.0}
{"epoch": 18, "training_loss": 1.290243535041809, "training_acc": 45.0, "val_loss": 0.7046054387092591, "val_acc": 48.0}
{"epoch": 19, "training_loss": 1.0966725480556487, "training_acc": 53.0, "val_loss": 2.5615700387954714, "val_acc": 52.0}
{"epoch": 20, "training_loss": 1.6038399314880372, "training_acc": 51.0, "val_loss": 3.2712656974792482, "val_acc": 48.0}
{"epoch": 21, "training_loss": 2.799360004112823, "training_acc": 57.0, "val_loss": 9.512234039306641, "val_acc": 48.0}
{"epoch": 22, "training_loss": 6.8624570846557615, "training_acc": 53.0, "val_loss": 7.186816463470459, "val_acc": 52.0}
{"epoch": 23, "training_loss": 5.05171953201294, "training_acc": 45.0, "val_loss": 3.2175119400024412, "val_acc": 52.0}
{"epoch": 24, "training_loss": 2.395393533706665, "training_acc": 47.0, "val_loss": 0.7110817837715149, "val_acc": 48.0}
{"epoch": 25, "training_loss": 1.6322862267494203, "training_acc": 45.0, "val_loss": 1.6161882209777831, "val_acc": 48.0}
{"epoch": 26, "training_loss": 0.9029735779762268, "training_acc": 49.0, "val_loss": 1.6157898569107056, "val_acc": 52.0}
{"epoch": 27, "training_loss": 1.513224310874939, "training_acc": 49.0, "val_loss": 1.0504530763626099, "val_acc": 48.0}
{"epoch": 28, "training_loss": 1.1551154375076294, "training_acc": 43.0, "val_loss": 0.867497866153717, "val_acc": 52.0}
{"epoch": 29, "training_loss": 0.7469681119918823, "training_acc": 53.0, "val_loss": 0.6978374600410462, "val_acc": 48.0}
{"epoch": 30, "training_loss": 0.7609921550750732, "training_acc": 45.0, "val_loss": 0.6983190870285034, "val_acc": 52.0}
{"epoch": 31, "training_loss": 0.8408318328857421, "training_acc": 43.0, "val_loss": 0.6931258869171143, "val_acc": 52.0}
{"epoch": 32, "training_loss": 0.9175137329101563, "training_acc": 53.0, "val_loss": 1.094460325241089, "val_acc": 52.0}
{"epoch": 33, "training_loss": 0.8648322105407715, "training_acc": 49.0, "val_loss": 2.820807361602783, "val_acc": 48.0}
{"epoch": 34, "training_loss": 2.4785728645324707, "training_acc": 53.0, "val_loss": 1.3286578512191773, "val_acc": 48.0}
{"epoch": 35, "training_loss": 1.8141083526611328, "training_acc": 49.0, "val_loss": 1.4831071424484252, "val_acc": 52.0}
{"epoch": 36, "training_loss": 3.311148414611816, "training_acc": 49.0, "val_loss": 0.7009048414230347, "val_acc": 48.0}
{"epoch": 37, "training_loss": 4.419779720306397, "training_acc": 45.0, "val_loss": 1.5117062473297118, "val_acc": 52.0}
{"epoch": 38, "training_loss": 4.322925567626953, "training_acc": 49.0, "val_loss": 7.702237510681153, "val_acc": 52.0}
{"epoch": 39, "training_loss": 5.842480239868164, "training_acc": 51.0, "val_loss": 0.8584799933433532, "val_acc": 52.0}
{"epoch": 40, "training_loss": 3.5951584911346437, "training_acc": 56.0, "val_loss": 0.9336490964889527, "val_acc": 48.0}
{"epoch": 41, "training_loss": 2.6721901416778566, "training_acc": 55.0, "val_loss": 3.427846736907959, "val_acc": 48.0}
{"epoch": 42, "training_loss": 2.156506986618042, "training_acc": 45.0, "val_loss": 1.3978299951553346, "val_acc": 52.0}
{"epoch": 43, "training_loss": 1.3906853151321412, "training_acc": 47.0, "val_loss": 1.8500168323516846, "val_acc": 52.0}
{"epoch": 44, "training_loss": 2.465009641647339, "training_acc": 45.0, "val_loss": 2.508457899093628, "val_acc": 48.0}
{"epoch": 45, "training_loss": 2.6869602537155153, "training_acc": 49.0, "val_loss": 1.2393264627456666, "val_acc": 48.0}
{"epoch": 46, "training_loss": 2.232217664718628, "training_acc": 45.0, "val_loss": 1.275829405784607, "val_acc": 52.0}
{"epoch": 47, "training_loss": 0.8959217834472656, "training_acc": 51.0, "val_loss": 0.719040310382843, "val_acc": 48.0}
{"epoch": 48, "training_loss": 1.9397125244140625, "training_acc": 41.0, "val_loss": 0.6951254630088806, "val_acc": 52.0}
{"epoch": 49, "training_loss": 1.197445023059845, "training_acc": 47.0, "val_loss": 1.2610279321670532, "val_acc": 52.0}
{"epoch": 50, "training_loss": 1.3569146728515624, "training_acc": 54.0, "val_loss": 0.9586831474304199, "val_acc": 48.0}
