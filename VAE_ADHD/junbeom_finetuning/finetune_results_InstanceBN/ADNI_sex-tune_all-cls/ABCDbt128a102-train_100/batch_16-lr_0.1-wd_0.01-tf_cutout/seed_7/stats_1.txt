"main_modify.py --pretrained_path /scratch/connectome/dyhan316/VAE_ADHD/barlowtwins/pretrain_results/ABCDbt128a102.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 7 --task ADNI_sex --input_option BT_org --learning_rate 1e-1 --batch_size 16 --weight_decay 1e-2 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 10.71090763092041, "training_acc": 45.0, "val_loss": 10.131965999603272, "val_acc": 52.0}
{"epoch": 1, "training_loss": 11.29270896911621, "training_acc": 45.0, "val_loss": 4.3665526008605955, "val_acc": 48.0}
{"epoch": 2, "training_loss": 5.694587249755859, "training_acc": 47.0, "val_loss": 9.324133377075196, "val_acc": 48.0}
{"epoch": 3, "training_loss": 6.874102509013101, "training_acc": 51.0, "val_loss": 9.866416282653809, "val_acc": 52.0}
{"epoch": 4, "training_loss": 7.865443172454834, "training_acc": 51.0, "val_loss": 6.55211877822876, "val_acc": 48.0}
{"epoch": 5, "training_loss": 3.5950551223754883, "training_acc": 49.0, "val_loss": 0.8017202043533325, "val_acc": 48.0}
{"epoch": 6, "training_loss": 0.8485043096542358, "training_acc": 51.0, "val_loss": 1.9011214303970336, "val_acc": 48.0}
{"epoch": 7, "training_loss": 1.1124619674682616, "training_acc": 53.0, "val_loss": 0.6959045028686524, "val_acc": 52.0}
{"epoch": 8, "training_loss": 0.7578419327735901, "training_acc": 51.0, "val_loss": 0.8455685377120972, "val_acc": 52.0}
{"epoch": 9, "training_loss": 0.9113696956634522, "training_acc": 55.0, "val_loss": 0.7165352988243103, "val_acc": 48.0}
{"epoch": 10, "training_loss": 0.9155714225769043, "training_acc": 55.0, "val_loss": 1.198983497619629, "val_acc": 52.0}
{"epoch": 11, "training_loss": 1.1194269394874572, "training_acc": 53.0, "val_loss": 0.779188916683197, "val_acc": 52.0}
{"epoch": 12, "training_loss": 0.7408732847869396, "training_acc": 53.0, "val_loss": 3.082878284454346, "val_acc": 52.0}
{"epoch": 13, "training_loss": 1.971477460861206, "training_acc": 49.0, "val_loss": 2.2284124660491944, "val_acc": 48.0}
{"epoch": 14, "training_loss": 2.052783203125, "training_acc": 49.0, "val_loss": 4.2473779392242434, "val_acc": 52.0}
{"epoch": 15, "training_loss": 2.0495385694503785, "training_acc": 65.0, "val_loss": 1.1747216176986695, "val_acc": 52.0}
{"epoch": 16, "training_loss": 1.8663658618927002, "training_acc": 47.0, "val_loss": 0.7596900892257691, "val_acc": 48.0}
{"epoch": 17, "training_loss": 1.1105331325531005, "training_acc": 45.0, "val_loss": 3.392628297805786, "val_acc": 48.0}
{"epoch": 18, "training_loss": 3.542545757293701, "training_acc": 47.0, "val_loss": 2.6684373569488526, "val_acc": 48.0}
{"epoch": 19, "training_loss": 2.011183986663818, "training_acc": 47.0, "val_loss": 4.43841586112976, "val_acc": 52.0}
{"epoch": 20, "training_loss": 4.1517187595367435, "training_acc": 59.0, "val_loss": 4.172960987091065, "val_acc": 48.0}
{"epoch": 21, "training_loss": 3.0372912311553955, "training_acc": 59.0, "val_loss": 3.7048855781555177, "val_acc": 48.0}
{"epoch": 22, "training_loss": 2.553087844848633, "training_acc": 55.0, "val_loss": 0.7964326500892639, "val_acc": 48.0}
{"epoch": 23, "training_loss": 0.9892643690109253, "training_acc": 53.0, "val_loss": 1.1727182364463806, "val_acc": 48.0}
{"epoch": 24, "training_loss": 1.104318208694458, "training_acc": 47.0, "val_loss": 0.6953745675086975, "val_acc": 52.0}
{"epoch": 25, "training_loss": 0.8933005428314209, "training_acc": 55.0, "val_loss": 1.2083597040176393, "val_acc": 52.0}
{"epoch": 26, "training_loss": 0.9219651436805725, "training_acc": 45.0, "val_loss": 1.6183091926574706, "val_acc": 48.0}
{"epoch": 27, "training_loss": 0.9842561960220337, "training_acc": 51.0, "val_loss": 0.8269061660766601, "val_acc": 52.0}
{"epoch": 28, "training_loss": 0.9133038330078125, "training_acc": 47.0, "val_loss": 3.51559663772583, "val_acc": 48.0}
{"epoch": 29, "training_loss": 2.587177906036377, "training_acc": 51.0, "val_loss": 2.557953214645386, "val_acc": 48.0}
{"epoch": 30, "training_loss": 1.774769902229309, "training_acc": 55.0, "val_loss": 0.7430768990516663, "val_acc": 52.0}
{"epoch": 31, "training_loss": 1.1392029762268066, "training_acc": 49.0, "val_loss": 2.7868545627593995, "val_acc": 48.0}
{"epoch": 32, "training_loss": 1.3126410388946532, "training_acc": 51.0, "val_loss": 3.001678018569946, "val_acc": 52.0}
{"epoch": 33, "training_loss": 2.309900178909302, "training_acc": 57.0, "val_loss": 0.9752388143539429, "val_acc": 52.0}
{"epoch": 34, "training_loss": 1.2129883670806885, "training_acc": 53.0, "val_loss": 2.0573319149017335, "val_acc": 48.0}
{"epoch": 35, "training_loss": 1.4974578332901, "training_acc": 53.0, "val_loss": 1.8588697814941406, "val_acc": 52.0}
{"epoch": 36, "training_loss": 1.6859903526306153, "training_acc": 41.0, "val_loss": 3.13708833694458, "val_acc": 48.0}
{"epoch": 37, "training_loss": 2.415699977874756, "training_acc": 51.0, "val_loss": 1.6780620002746582, "val_acc": 52.0}
{"epoch": 38, "training_loss": 2.209066104888916, "training_acc": 49.0, "val_loss": 3.196765260696411, "val_acc": 52.0}
{"epoch": 39, "training_loss": 2.086683833897114, "training_acc": 53.0, "val_loss": 2.1577180767059327, "val_acc": 52.0}
{"epoch": 40, "training_loss": 1.566880841255188, "training_acc": 47.0, "val_loss": 1.0539771604537964, "val_acc": 52.0}
{"epoch": 41, "training_loss": 0.8589142370223999, "training_acc": 51.0, "val_loss": 1.2197225904464721, "val_acc": 48.0}
{"epoch": 42, "training_loss": 1.0214135837554932, "training_acc": 51.0, "val_loss": 0.8061647248268128, "val_acc": 48.0}
{"epoch": 43, "training_loss": 0.9132601547241211, "training_acc": 43.0, "val_loss": 0.692351610660553, "val_acc": 52.0}
{"epoch": 44, "training_loss": 0.9844401931762695, "training_acc": 45.0, "val_loss": 1.9481280326843262, "val_acc": 48.0}
{"epoch": 45, "training_loss": 3.0531021118164063, "training_acc": 43.0, "val_loss": 7.781263923645019, "val_acc": 52.0}
{"epoch": 46, "training_loss": 7.253211917877198, "training_acc": 39.0, "val_loss": 1.2501019215583802, "val_acc": 48.0}
{"epoch": 47, "training_loss": 4.1146949100494385, "training_acc": 51.0, "val_loss": 3.6358820533752443, "val_acc": 48.0}
{"epoch": 48, "training_loss": 2.3972014665603636, "training_acc": 41.0, "val_loss": 3.1766880416870116, "val_acc": 48.0}
{"epoch": 49, "training_loss": 2.1970721435546876, "training_acc": 59.0, "val_loss": 11.793682765960693, "val_acc": 52.0}
{"epoch": 50, "training_loss": 6.959531660079956, "training_acc": 57.0, "val_loss": 2.9958737182617186, "val_acc": 48.0}
{"epoch": 51, "training_loss": 2.4441851997375488, "training_acc": 51.0, "val_loss": 1.4315353870391845, "val_acc": 48.0}
{"epoch": 52, "training_loss": 1.2694180011749268, "training_acc": 43.0, "val_loss": 1.3859641361236572, "val_acc": 52.0}
{"epoch": 53, "training_loss": 1.4264379930496216, "training_acc": 51.0, "val_loss": 1.8011283016204833, "val_acc": 52.0}
{"epoch": 54, "training_loss": 1.4520573925971985, "training_acc": 47.0, "val_loss": 0.7538192462921143, "val_acc": 48.0}
{"epoch": 55, "training_loss": 0.7282537007331848, "training_acc": 49.0, "val_loss": 1.6268670797348022, "val_acc": 48.0}
{"epoch": 56, "training_loss": 1.0032620811462403, "training_acc": 63.0, "val_loss": 0.8561874723434448, "val_acc": 48.0}
{"epoch": 57, "training_loss": 1.5217135572433471, "training_acc": 45.0, "val_loss": 1.7759757232666016, "val_acc": 48.0}
{"epoch": 58, "training_loss": 1.0505181980133056, "training_acc": 59.0, "val_loss": 1.7394126081466674, "val_acc": 48.0}
{"epoch": 59, "training_loss": 1.6090352964401244, "training_acc": 41.0, "val_loss": 1.9370868682861329, "val_acc": 48.0}
{"epoch": 60, "training_loss": 1.2210938024520874, "training_acc": 47.0, "val_loss": 1.423405523300171, "val_acc": 52.0}
{"epoch": 61, "training_loss": 1.491734309196472, "training_acc": 49.0, "val_loss": 1.9199711561203003, "val_acc": 52.0}
{"epoch": 62, "training_loss": 1.6076608848571778, "training_acc": 47.0, "val_loss": 1.0806427335739135, "val_acc": 52.0}
