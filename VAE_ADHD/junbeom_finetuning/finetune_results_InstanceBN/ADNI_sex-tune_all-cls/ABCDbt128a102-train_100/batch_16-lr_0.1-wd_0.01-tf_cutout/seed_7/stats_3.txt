"main_modify.py --pretrained_path /scratch/connectome/dyhan316/VAE_ADHD/barlowtwins/pretrain_results/ABCDbt128a102.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 7 --task ADNI_sex --input_option BT_org --learning_rate 1e-1 --batch_size 16 --weight_decay 1e-2 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 10.030274248123169, "training_acc": 46.0, "val_loss": 17.815534896850586, "val_acc": 52.0}
{"epoch": 1, "training_loss": 9.045959577560424, "training_acc": 52.0, "val_loss": 4.2313804435729985, "val_acc": 48.0}
{"epoch": 2, "training_loss": 2.530923271179199, "training_acc": 56.0, "val_loss": 2.469616184234619, "val_acc": 48.0}
{"epoch": 3, "training_loss": 3.504138135910034, "training_acc": 52.0, "val_loss": 5.9487683391571045, "val_acc": 48.0}
{"epoch": 4, "training_loss": 3.3226713228225706, "training_acc": 52.0, "val_loss": 4.1320541477203365, "val_acc": 48.0}
{"epoch": 5, "training_loss": 4.996719694137573, "training_acc": 44.0, "val_loss": 0.7995870471000671, "val_acc": 48.0}
{"epoch": 6, "training_loss": 0.9056551742553711, "training_acc": 48.0, "val_loss": 1.4430660152435302, "val_acc": 52.0}
{"epoch": 7, "training_loss": 1.7422827339172364, "training_acc": 46.0, "val_loss": 3.7844887161254883, "val_acc": 48.0}
{"epoch": 8, "training_loss": 3.393093090057373, "training_acc": 60.0, "val_loss": 4.006992123126984, "val_acc": 52.0}
{"epoch": 9, "training_loss": 2.6733365058898926, "training_acc": 52.0, "val_loss": 1.3297993803024293, "val_acc": 48.0}
{"epoch": 10, "training_loss": 1.1411771392822265, "training_acc": 52.0, "val_loss": 0.6930937886238098, "val_acc": 52.0}
{"epoch": 11, "training_loss": 0.924791865348816, "training_acc": 48.0, "val_loss": 2.569981565475464, "val_acc": 52.0}
{"epoch": 12, "training_loss": 1.9802119684219361, "training_acc": 54.0, "val_loss": 3.449461679458618, "val_acc": 52.0}
{"epoch": 13, "training_loss": 2.8380371809005736, "training_acc": 56.0, "val_loss": 3.7630087184906005, "val_acc": 52.0}
{"epoch": 14, "training_loss": 2.710420961380005, "training_acc": 50.0, "val_loss": 0.7000368404388427, "val_acc": 52.0}
{"epoch": 15, "training_loss": 0.9887072372436524, "training_acc": 42.0, "val_loss": 1.4940124607086183, "val_acc": 52.0}
{"epoch": 16, "training_loss": 0.951801266670227, "training_acc": 46.0, "val_loss": 1.3830518484115601, "val_acc": 52.0}
{"epoch": 17, "training_loss": 1.098818769454956, "training_acc": 46.0, "val_loss": 2.9086884880065917, "val_acc": 52.0}
{"epoch": 18, "training_loss": 2.195125403404236, "training_acc": 52.0, "val_loss": 0.7228080487251282, "val_acc": 52.0}
{"epoch": 19, "training_loss": 0.7839966154098511, "training_acc": 50.0, "val_loss": 2.159349513053894, "val_acc": 48.0}
{"epoch": 20, "training_loss": 0.9283112764358521, "training_acc": 58.0, "val_loss": 1.1188665771484374, "val_acc": 52.0}
{"epoch": 21, "training_loss": 0.8628093671798706, "training_acc": 54.0, "val_loss": 1.5191041040420532, "val_acc": 48.0}
{"epoch": 22, "training_loss": 1.2073557543754578, "training_acc": 48.0, "val_loss": 2.918019428253174, "val_acc": 48.0}
{"epoch": 23, "training_loss": 2.625859179496765, "training_acc": 44.0, "val_loss": 1.4770590257644653, "val_acc": 48.0}
{"epoch": 24, "training_loss": 1.1441236639022827, "training_acc": 52.0, "val_loss": 1.9976251220703125, "val_acc": 48.0}
{"epoch": 25, "training_loss": 1.0579904532432556, "training_acc": 60.0, "val_loss": 2.840139904022217, "val_acc": 52.0}
{"epoch": 26, "training_loss": 1.645083074569702, "training_acc": 54.0, "val_loss": 2.1686825942993164, "val_acc": 52.0}
{"epoch": 27, "training_loss": 1.0932701683044435, "training_acc": 56.0, "val_loss": 1.1597569632530211, "val_acc": 52.0}
{"epoch": 28, "training_loss": 1.0175781393051146, "training_acc": 48.0, "val_loss": 0.9973028421401977, "val_acc": 52.0}
{"epoch": 29, "training_loss": 1.0415729212760925, "training_acc": 52.0, "val_loss": 1.5095233488082886, "val_acc": 52.0}
