"main_modify.py --pretrained_path /scratch/connectome/dyhan316/VAE_ADHD/barlowtwins/pretrain_results/ABCDbt128a102.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 7 --task ADNI_sex --input_option BT_org --learning_rate 1e-1 --batch_size 16 --weight_decay 1e-2 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 4.465782580375671, "training_acc": 47.0, "val_loss": 4.895303974151611, "val_acc": 52.0}
{"epoch": 1, "training_loss": 3.0763818359375, "training_acc": 59.0, "val_loss": 1.6022771358489991, "val_acc": 52.0}
{"epoch": 2, "training_loss": 3.126966094970703, "training_acc": 47.0, "val_loss": 4.048079032897949, "val_acc": 48.0}
{"epoch": 3, "training_loss": 4.727283363342285, "training_acc": 45.0, "val_loss": 1.0435947394371032, "val_acc": 52.0}
{"epoch": 4, "training_loss": 3.5654459190368653, "training_acc": 45.0, "val_loss": 3.125603685379028, "val_acc": 52.0}
{"epoch": 5, "training_loss": 2.003957943916321, "training_acc": 57.0, "val_loss": 2.3158973121643065, "val_acc": 52.0}
{"epoch": 6, "training_loss": 2.164050006866455, "training_acc": 47.0, "val_loss": 1.5122446870803834, "val_acc": 52.0}
{"epoch": 7, "training_loss": 1.8360328090190887, "training_acc": 51.0, "val_loss": 3.7445680046081544, "val_acc": 48.0}
{"epoch": 8, "training_loss": 3.309516849517822, "training_acc": 51.0, "val_loss": 1.8052809810638428, "val_acc": 48.0}
{"epoch": 9, "training_loss": 1.2510032653808594, "training_acc": 55.0, "val_loss": 1.2995311880111695, "val_acc": 48.0}
{"epoch": 10, "training_loss": 1.0432336163520812, "training_acc": 53.0, "val_loss": 1.1410825967788696, "val_acc": 52.0}
{"epoch": 11, "training_loss": 1.4452783060073853, "training_acc": 45.0, "val_loss": 1.3181373500823974, "val_acc": 52.0}
{"epoch": 12, "training_loss": 0.9739669275283813, "training_acc": 53.0, "val_loss": 1.553294472694397, "val_acc": 48.0}
{"epoch": 13, "training_loss": 1.1931291604042054, "training_acc": 53.0, "val_loss": 0.7965726780891419, "val_acc": 52.0}
{"epoch": 14, "training_loss": 0.7413153171539306, "training_acc": 53.0, "val_loss": 1.7005800247192382, "val_acc": 48.0}
{"epoch": 15, "training_loss": 1.6967508029937743, "training_acc": 45.0, "val_loss": 1.1867070865631104, "val_acc": 48.0}
{"epoch": 16, "training_loss": 0.8341047763824463, "training_acc": 57.0, "val_loss": 1.5292604875564575, "val_acc": 52.0}
{"epoch": 17, "training_loss": 1.0483189392089844, "training_acc": 53.0, "val_loss": 0.8700658845901489, "val_acc": 48.0}
{"epoch": 18, "training_loss": 0.9366627073287964, "training_acc": 57.0, "val_loss": 1.0993555068969727, "val_acc": 52.0}
{"epoch": 19, "training_loss": 1.4362614250183106, "training_acc": 51.0, "val_loss": 5.59992883682251, "val_acc": 48.0}
{"epoch": 20, "training_loss": 3.797885675430298, "training_acc": 49.0, "val_loss": 2.823625030517578, "val_acc": 48.0}
{"epoch": 21, "training_loss": 3.449672193527222, "training_acc": 45.0, "val_loss": 6.468087100982666, "val_acc": 48.0}
{"epoch": 22, "training_loss": 7.618152313232422, "training_acc": 49.0, "val_loss": 8.341614627838135, "val_acc": 52.0}
{"epoch": 23, "training_loss": 5.095238475799561, "training_acc": 53.0, "val_loss": 1.5744557428359984, "val_acc": 48.0}
{"epoch": 24, "training_loss": 3.362585229536053, "training_acc": 53.0, "val_loss": 2.3174694967269898, "val_acc": 48.0}
{"epoch": 25, "training_loss": 3.689174995422363, "training_acc": 51.0, "val_loss": 6.07871259689331, "val_acc": 48.0}
{"epoch": 26, "training_loss": 3.442451171875, "training_acc": 41.0, "val_loss": 0.861897885799408, "val_acc": 52.0}
{"epoch": 27, "training_loss": 1.3021024894714355, "training_acc": 51.0, "val_loss": 0.8538676476478577, "val_acc": 52.0}
{"epoch": 28, "training_loss": 1.2790607333183288, "training_acc": 49.0, "val_loss": 0.7283456468582153, "val_acc": 48.0}
{"epoch": 29, "training_loss": 1.6861545753479004, "training_acc": 47.0, "val_loss": 1.3266049146652221, "val_acc": 48.0}
{"epoch": 30, "training_loss": 1.7430140972137451, "training_acc": 49.0, "val_loss": 0.6966446495056152, "val_acc": 48.0}
{"epoch": 31, "training_loss": 0.9954349398612976, "training_acc": 41.0, "val_loss": 0.8037274146080017, "val_acc": 52.0}
{"epoch": 32, "training_loss": 0.9033577299118042, "training_acc": 45.0, "val_loss": 2.9934936809539794, "val_acc": 48.0}
{"epoch": 33, "training_loss": 2.500438470840454, "training_acc": 43.0, "val_loss": 1.0257079052925109, "val_acc": 52.0}
{"epoch": 34, "training_loss": 1.1878292560577393, "training_acc": 41.0, "val_loss": 1.6266186809539795, "val_acc": 52.0}
{"epoch": 35, "training_loss": 1.694184045791626, "training_acc": 47.0, "val_loss": 0.6945915031433105, "val_acc": 52.0}
{"epoch": 36, "training_loss": 0.8864579725265503, "training_acc": 47.0, "val_loss": 0.766222734451294, "val_acc": 48.0}
{"epoch": 37, "training_loss": 0.7401724815368652, "training_acc": 49.0, "val_loss": 2.7538972425460817, "val_acc": 52.0}
{"epoch": 38, "training_loss": 1.804492974281311, "training_acc": 45.0, "val_loss": 1.1903461122512817, "val_acc": 52.0}
{"epoch": 39, "training_loss": 1.2978734493255615, "training_acc": 49.0, "val_loss": 0.8710735034942627, "val_acc": 48.0}
{"epoch": 40, "training_loss": 0.9039510607719421, "training_acc": 49.0, "val_loss": 1.653614754676819, "val_acc": 48.0}
{"epoch": 41, "training_loss": 1.259930307865143, "training_acc": 45.0, "val_loss": 1.6264463663101196, "val_acc": 48.0}
{"epoch": 42, "training_loss": 1.3932808685302733, "training_acc": 43.0, "val_loss": 1.058346652984619, "val_acc": 48.0}
{"epoch": 43, "training_loss": 0.821861810684204, "training_acc": 53.0, "val_loss": 0.6925574445724487, "val_acc": 52.0}
{"epoch": 44, "training_loss": 0.7620535326004029, "training_acc": 51.0, "val_loss": 0.7424517822265625, "val_acc": 52.0}
{"epoch": 45, "training_loss": 1.2526562595367432, "training_acc": 41.0, "val_loss": 3.0074425983428954, "val_acc": 52.0}
{"epoch": 46, "training_loss": 2.613706316947937, "training_acc": 53.0, "val_loss": 4.035335483551026, "val_acc": 52.0}
{"epoch": 47, "training_loss": 3.576388568878174, "training_acc": 49.0, "val_loss": 2.560684461593628, "val_acc": 52.0}
{"epoch": 48, "training_loss": 4.162370934486389, "training_acc": 43.0, "val_loss": 3.927008171081543, "val_acc": 52.0}
{"epoch": 49, "training_loss": 5.018681774139404, "training_acc": 49.0, "val_loss": 5.561152954101562, "val_acc": 48.0}
{"epoch": 50, "training_loss": 2.5760487842559816, "training_acc": 55.0, "val_loss": 3.8667901802062987, "val_acc": 48.0}
{"epoch": 51, "training_loss": 2.2410472011566163, "training_acc": 59.0, "val_loss": 4.027606925964355, "val_acc": 48.0}
{"epoch": 52, "training_loss": 3.164364719390869, "training_acc": 45.0, "val_loss": 1.7013146877288818, "val_acc": 48.0}
{"epoch": 53, "training_loss": 1.7245878672599793, "training_acc": 57.0, "val_loss": 0.6948633623123169, "val_acc": 48.0}
{"epoch": 54, "training_loss": 1.3824169826507569, "training_acc": 45.0, "val_loss": 1.7976002931594848, "val_acc": 48.0}
{"epoch": 55, "training_loss": 1.2938001918792725, "training_acc": 57.0, "val_loss": 0.8726915812492371, "val_acc": 48.0}
{"epoch": 56, "training_loss": 2.4503347492218017, "training_acc": 51.0, "val_loss": 0.7114943408966065, "val_acc": 52.0}
{"epoch": 57, "training_loss": 2.5074773979187013, "training_acc": 51.0, "val_loss": 1.698251428604126, "val_acc": 52.0}
{"epoch": 58, "training_loss": 1.8232709121704103, "training_acc": 51.0, "val_loss": 1.681262536048889, "val_acc": 52.0}
{"epoch": 59, "training_loss": 1.1284489011764527, "training_acc": 49.0, "val_loss": 0.7636254858970642, "val_acc": 48.0}
{"epoch": 60, "training_loss": 1.2469475841522217, "training_acc": 51.0, "val_loss": 2.026826181411743, "val_acc": 52.0}
{"epoch": 61, "training_loss": 1.4616655015945434, "training_acc": 49.0, "val_loss": 0.9144646811485291, "val_acc": 48.0}
{"epoch": 62, "training_loss": 0.8421312379837036, "training_acc": 49.0, "val_loss": 2.706793775558472, "val_acc": 48.0}
