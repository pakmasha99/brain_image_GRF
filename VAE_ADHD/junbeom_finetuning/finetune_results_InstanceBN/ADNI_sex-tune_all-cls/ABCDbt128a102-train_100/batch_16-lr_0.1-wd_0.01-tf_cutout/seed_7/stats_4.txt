"main_modify.py --pretrained_path /scratch/connectome/dyhan316/VAE_ADHD/barlowtwins/pretrain_results/ABCDbt128a102.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 7 --task ADNI_sex --input_option BT_org --learning_rate 1e-1 --batch_size 16 --weight_decay 1e-2 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 9.825050878524781, "training_acc": 54.0, "val_loss": 1.0723820900917054, "val_acc": 52.0}
{"epoch": 1, "training_loss": 4.725592174530029, "training_acc": 54.0, "val_loss": 4.931205863952637, "val_acc": 52.0}
{"epoch": 2, "training_loss": 3.0621153861284256, "training_acc": 40.0, "val_loss": 1.735191535949707, "val_acc": 52.0}
{"epoch": 3, "training_loss": 1.5589913511276245, "training_acc": 44.0, "val_loss": 1.3841211676597596, "val_acc": 48.0}
{"epoch": 4, "training_loss": 1.5157962036132813, "training_acc": 49.0, "val_loss": 1.179281997680664, "val_acc": 52.0}
{"epoch": 5, "training_loss": 0.9510448884963989, "training_acc": 42.0, "val_loss": 2.3101606035232543, "val_acc": 48.0}
{"epoch": 6, "training_loss": 1.0632388639450072, "training_acc": 50.0, "val_loss": 0.8631061553955078, "val_acc": 48.0}
{"epoch": 7, "training_loss": 0.7426675629615783, "training_acc": 56.0, "val_loss": 1.5090057611465455, "val_acc": 52.0}
{"epoch": 8, "training_loss": 1.4797836112976075, "training_acc": 42.0, "val_loss": 3.586385278701782, "val_acc": 48.0}
{"epoch": 9, "training_loss": 2.7185945558547973, "training_acc": 52.0, "val_loss": 1.2281286811828613, "val_acc": 48.0}
{"epoch": 10, "training_loss": 1.9057560825347901, "training_acc": 50.0, "val_loss": 3.6549622917175295, "val_acc": 52.0}
{"epoch": 11, "training_loss": 5.480190944671631, "training_acc": 46.0, "val_loss": 3.662056522369385, "val_acc": 48.0}
{"epoch": 12, "training_loss": 3.3669975280761717, "training_acc": 50.0, "val_loss": 4.493008890151978, "val_acc": 48.0}
{"epoch": 13, "training_loss": 2.922328567504883, "training_acc": 50.0, "val_loss": 0.9195170664787292, "val_acc": 48.0}
{"epoch": 14, "training_loss": 1.7926902675628662, "training_acc": 56.0, "val_loss": 0.9615978264808654, "val_acc": 52.0}
{"epoch": 15, "training_loss": 0.9867458057403564, "training_acc": 52.0, "val_loss": 1.96380295753479, "val_acc": 52.0}
{"epoch": 16, "training_loss": 1.3902499532699586, "training_acc": 50.0, "val_loss": 1.8865810203552247, "val_acc": 48.0}
{"epoch": 17, "training_loss": 1.3572907304763795, "training_acc": 46.0, "val_loss": 0.7529182004928588, "val_acc": 48.0}
{"epoch": 18, "training_loss": 1.1199173140525818, "training_acc": 42.0, "val_loss": 1.6637927770614624, "val_acc": 48.0}
{"epoch": 19, "training_loss": 1.2724871063232421, "training_acc": 50.0, "val_loss": 2.004521245956421, "val_acc": 48.0}
{"epoch": 20, "training_loss": 1.7948675656318664, "training_acc": 60.0, "val_loss": 3.423690128326416, "val_acc": 48.0}
{"epoch": 21, "training_loss": 2.3080854415893555, "training_acc": 50.0, "val_loss": 0.720474648475647, "val_acc": 48.0}
{"epoch": 22, "training_loss": 1.1100306797027588, "training_acc": 54.0, "val_loss": 0.7331586766242981, "val_acc": 48.0}
{"epoch": 23, "training_loss": 0.9587249040603638, "training_acc": 56.0, "val_loss": 0.6923490619659424, "val_acc": 52.0}
{"epoch": 24, "training_loss": 0.8067171621322632, "training_acc": 50.0, "val_loss": 1.9953452444076538, "val_acc": 52.0}
{"epoch": 25, "training_loss": 1.434836883544922, "training_acc": 46.0, "val_loss": 2.1262987995147706, "val_acc": 48.0}
{"epoch": 26, "training_loss": 1.3097447967529297, "training_acc": 48.0, "val_loss": 1.2510204076766969, "val_acc": 48.0}
{"epoch": 27, "training_loss": 1.1256802868843079, "training_acc": 52.0, "val_loss": 1.2771850252151489, "val_acc": 52.0}
{"epoch": 28, "training_loss": 1.9015308046340942, "training_acc": 44.0, "val_loss": 2.0318134212493897, "val_acc": 48.0}
{"epoch": 29, "training_loss": 1.117939908504486, "training_acc": 52.0, "val_loss": 1.3413308095932006, "val_acc": 48.0}
{"epoch": 30, "training_loss": 1.0869783353805542, "training_acc": 52.0, "val_loss": 0.8728433728218079, "val_acc": 52.0}
{"epoch": 31, "training_loss": 0.9353981590270997, "training_acc": 56.0, "val_loss": 2.1894576740264893, "val_acc": 48.0}
{"epoch": 32, "training_loss": 1.7000706934928893, "training_acc": 42.0, "val_loss": 2.04438871383667, "val_acc": 48.0}
{"epoch": 33, "training_loss": 2.6022053146362305, "training_acc": 46.0, "val_loss": 6.704602794647217, "val_acc": 48.0}
{"epoch": 34, "training_loss": 4.662124271392822, "training_acc": 48.0, "val_loss": 0.796883807182312, "val_acc": 52.0}
{"epoch": 35, "training_loss": 1.1214008331298828, "training_acc": 42.0, "val_loss": 0.7086767601966858, "val_acc": 52.0}
{"epoch": 36, "training_loss": 0.7640643239021301, "training_acc": 50.0, "val_loss": 1.657575707435608, "val_acc": 52.0}
{"epoch": 37, "training_loss": 1.1443069243431092, "training_acc": 46.0, "val_loss": 1.3028310012817383, "val_acc": 52.0}
{"epoch": 38, "training_loss": 0.8224340939521789, "training_acc": 54.0, "val_loss": 1.1679825735092164, "val_acc": 48.0}
{"epoch": 39, "training_loss": 1.3392688035964966, "training_acc": 50.0, "val_loss": 0.8542037224769592, "val_acc": 52.0}
{"epoch": 40, "training_loss": 1.0886328218877315, "training_acc": 58.0, "val_loss": 3.090921678543091, "val_acc": 48.0}
{"epoch": 41, "training_loss": 2.164494261741638, "training_acc": 46.0, "val_loss": 1.8215219402313232, "val_acc": 48.0}
{"epoch": 42, "training_loss": 1.2458729255199432, "training_acc": 44.0, "val_loss": 2.423602523803711, "val_acc": 52.0}
