"main_modify.py --pretrained_path /scratch/connectome/dyhan316/VAE_ADHD/barlowtwins/pretrain_results/ABCDbt128a102.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 4 --task ADNI_sex --input_option BT_org --learning_rate 1e-1 --batch_size 16 --weight_decay 1e-2 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 11.20376600265503, "training_acc": 50.0, "val_loss": 4.254242267608642, "val_acc": 48.0}
{"epoch": 1, "training_loss": 9.002848739624023, "training_acc": 54.0, "val_loss": 7.034331855773925, "val_acc": 48.0}
{"epoch": 2, "training_loss": 8.27738166809082, "training_acc": 46.0, "val_loss": 5.463807163238525, "val_acc": 52.0}
{"epoch": 3, "training_loss": 3.716320610046387, "training_acc": 44.0, "val_loss": 1.6475488185882567, "val_acc": 52.0}
{"epoch": 4, "training_loss": 1.168757815361023, "training_acc": 50.0, "val_loss": 1.3551976013183593, "val_acc": 48.0}
{"epoch": 5, "training_loss": 1.073528277873993, "training_acc": 44.0, "val_loss": 0.7529520535469055, "val_acc": 48.0}
{"epoch": 6, "training_loss": 0.9997238302230835, "training_acc": 44.0, "val_loss": 0.6964565062522888, "val_acc": 52.0}
{"epoch": 7, "training_loss": 1.6259809064865112, "training_acc": 54.0, "val_loss": 2.340264720916748, "val_acc": 52.0}
{"epoch": 8, "training_loss": 1.7218589943647384, "training_acc": 54.0, "val_loss": 3.5487325096130373, "val_acc": 52.0}
{"epoch": 9, "training_loss": 1.5773997449874877, "training_acc": 50.0, "val_loss": 2.2220843505859373, "val_acc": 52.0}
{"epoch": 10, "training_loss": 1.991055860519409, "training_acc": 52.0, "val_loss": 2.594538102149963, "val_acc": 52.0}
{"epoch": 11, "training_loss": 2.9432670783996584, "training_acc": 44.0, "val_loss": 2.681228618621826, "val_acc": 52.0}
{"epoch": 12, "training_loss": 1.5269588804244996, "training_acc": 48.0, "val_loss": 0.755386414527893, "val_acc": 48.0}
{"epoch": 13, "training_loss": 0.8349422574043274, "training_acc": 56.0, "val_loss": 0.9215205454826355, "val_acc": 48.0}
{"epoch": 14, "training_loss": 0.8748419332504273, "training_acc": 54.0, "val_loss": 0.6928146004676818, "val_acc": 52.0}
{"epoch": 15, "training_loss": 1.638181495666504, "training_acc": 40.0, "val_loss": 1.7777180790901184, "val_acc": 48.0}
{"epoch": 16, "training_loss": 1.5140909051895142, "training_acc": 48.0, "val_loss": 1.052991828918457, "val_acc": 48.0}
{"epoch": 17, "training_loss": 1.2255140399932862, "training_acc": 48.0, "val_loss": 0.7466108250617981, "val_acc": 48.0}
{"epoch": 18, "training_loss": 1.1205429458618164, "training_acc": 52.0, "val_loss": 0.7340575933456421, "val_acc": 48.0}
{"epoch": 19, "training_loss": 1.211202986240387, "training_acc": 48.0, "val_loss": 0.6931206631660461, "val_acc": 52.0}
{"epoch": 20, "training_loss": 0.8692914295196533, "training_acc": 48.0, "val_loss": 2.464441347122192, "val_acc": 52.0}
{"epoch": 21, "training_loss": 2.1870836067199706, "training_acc": 52.0, "val_loss": 2.374707956314087, "val_acc": 52.0}
{"epoch": 22, "training_loss": 2.1842432498931883, "training_acc": 52.0, "val_loss": 2.142341833114624, "val_acc": 52.0}
{"epoch": 23, "training_loss": 2.7862436151504517, "training_acc": 50.0, "val_loss": 1.039676218032837, "val_acc": 52.0}
{"epoch": 24, "training_loss": 2.468593730926514, "training_acc": 56.0, "val_loss": 0.7818572998046875, "val_acc": 52.0}
{"epoch": 25, "training_loss": 1.8488412189483643, "training_acc": 48.0, "val_loss": 1.9618369913101197, "val_acc": 52.0}
{"epoch": 26, "training_loss": 1.4422754955291748, "training_acc": 52.0, "val_loss": 0.7892326903343201, "val_acc": 52.0}
{"epoch": 27, "training_loss": 0.7162824034690857, "training_acc": 56.0, "val_loss": 1.2268427038192748, "val_acc": 48.0}
{"epoch": 28, "training_loss": 1.046371455192566, "training_acc": 46.0, "val_loss": 0.6982753324508667, "val_acc": 48.0}
{"epoch": 29, "training_loss": 0.8013754630088806, "training_acc": 46.0, "val_loss": 0.7739999198913574, "val_acc": 52.0}
{"epoch": 30, "training_loss": 1.1060758113861084, "training_acc": 52.0, "val_loss": 3.835098638534546, "val_acc": 48.0}
{"epoch": 31, "training_loss": 3.078224067687988, "training_acc": 52.0, "val_loss": 1.991180477142334, "val_acc": 52.0}
{"epoch": 32, "training_loss": 1.8034480094909668, "training_acc": 44.0, "val_loss": 0.721356213092804, "val_acc": 52.0}
{"epoch": 33, "training_loss": 1.5276902961730956, "training_acc": 50.0, "val_loss": 0.7742271113395691, "val_acc": 52.0}
