"main_modify.py --pretrained_path /scratch/connectome/dyhan316/VAE_ADHD/barlowtwins/pretrain_results/ABCDbt128a102.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 4 --task ADNI_sex --input_option BT_org --learning_rate 1e-1 --batch_size 16 --weight_decay 1e-2 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 9.054192924499512, "training_acc": 56.0, "val_loss": 3.6097383594512937, "val_acc": 48.0}
{"epoch": 1, "training_loss": 4.153223686218261, "training_acc": 56.0, "val_loss": 1.9693612241744995, "val_acc": 52.0}
{"epoch": 2, "training_loss": 5.841998481750489, "training_acc": 52.0, "val_loss": 5.203589782714844, "val_acc": 52.0}
{"epoch": 3, "training_loss": 3.0436724328994753, "training_acc": 56.0, "val_loss": 0.7771579051017761, "val_acc": 52.0}
{"epoch": 4, "training_loss": 0.9589801359176636, "training_acc": 50.0, "val_loss": 1.409154839515686, "val_acc": 48.0}
{"epoch": 5, "training_loss": 1.1583212089538575, "training_acc": 44.0, "val_loss": 0.7390820693969726, "val_acc": 52.0}
{"epoch": 6, "training_loss": 1.284649133682251, "training_acc": 58.0, "val_loss": 2.877091073989868, "val_acc": 48.0}
{"epoch": 7, "training_loss": 2.5912252044677735, "training_acc": 44.0, "val_loss": 2.213753719329834, "val_acc": 52.0}
{"epoch": 8, "training_loss": 1.602808804512024, "training_acc": 50.0, "val_loss": 1.3464789867401123, "val_acc": 48.0}
{"epoch": 9, "training_loss": 1.7618461179733276, "training_acc": 50.0, "val_loss": 1.580199646949768, "val_acc": 52.0}
{"epoch": 10, "training_loss": 1.755485258102417, "training_acc": 52.0, "val_loss": 2.364331102371216, "val_acc": 48.0}
{"epoch": 11, "training_loss": 1.9187646865844727, "training_acc": 42.0, "val_loss": 2.7806249713897704, "val_acc": 52.0}
{"epoch": 12, "training_loss": 2.8033094596862793, "training_acc": 52.0, "val_loss": 1.1570013380050659, "val_acc": 52.0}
{"epoch": 13, "training_loss": 1.5798422145843505, "training_acc": 50.0, "val_loss": 3.8795471954345704, "val_acc": 52.0}
{"epoch": 14, "training_loss": 2.593658857345581, "training_acc": 50.0, "val_loss": 6.752018508911132, "val_acc": 52.0}
{"epoch": 15, "training_loss": 4.280047068595886, "training_acc": 46.0, "val_loss": 1.2451953887939453, "val_acc": 52.0}
{"epoch": 16, "training_loss": 0.9952275037765503, "training_acc": 46.0, "val_loss": 0.9875312542915344, "val_acc": 48.0}
{"epoch": 17, "training_loss": 0.7549678325653076, "training_acc": 54.0, "val_loss": 0.8481778240203858, "val_acc": 48.0}
{"epoch": 18, "training_loss": 1.2326351261138917, "training_acc": 46.0, "val_loss": 0.7867209362983704, "val_acc": 52.0}
{"epoch": 19, "training_loss": 0.8837695741653442, "training_acc": 52.0, "val_loss": 2.3981657886505126, "val_acc": 48.0}
{"epoch": 20, "training_loss": 2.1818769931793214, "training_acc": 42.0, "val_loss": 3.303600869178772, "val_acc": 52.0}
{"epoch": 21, "training_loss": 3.756813793182373, "training_acc": 56.0, "val_loss": 2.8177616882324217, "val_acc": 48.0}
{"epoch": 22, "training_loss": 3.1866927671432497, "training_acc": 52.0, "val_loss": 4.326496648788452, "val_acc": 48.0}
{"epoch": 23, "training_loss": 2.195386318899691, "training_acc": 58.0, "val_loss": 7.5779718399047855, "val_acc": 48.0}
{"epoch": 24, "training_loss": 6.750276985168457, "training_acc": 46.0, "val_loss": 3.697010669708252, "val_acc": 52.0}
{"epoch": 25, "training_loss": 1.9597739124298095, "training_acc": 46.0, "val_loss": 0.730019416809082, "val_acc": 52.0}
{"epoch": 26, "training_loss": 0.8329415512084961, "training_acc": 52.0, "val_loss": 0.6981298565864563, "val_acc": 52.0}
{"epoch": 27, "training_loss": 0.7808981275558472, "training_acc": 42.0, "val_loss": 1.631470012664795, "val_acc": 48.0}
{"epoch": 28, "training_loss": 1.1379350185394288, "training_acc": 48.0, "val_loss": 1.9472498035430907, "val_acc": 48.0}
{"epoch": 29, "training_loss": 1.490413146018982, "training_acc": 36.0, "val_loss": 2.4316165447235107, "val_acc": 48.0}
{"epoch": 30, "training_loss": 2.585406062602997, "training_acc": 48.0, "val_loss": 4.084983196258545, "val_acc": 48.0}
{"epoch": 31, "training_loss": 2.6661581563949586, "training_acc": 52.0, "val_loss": 2.4866646003723143, "val_acc": 48.0}
{"epoch": 32, "training_loss": 2.3723096419870853, "training_acc": 46.0, "val_loss": 2.6802390003204346, "val_acc": 48.0}
{"epoch": 33, "training_loss": 1.7239509296417237, "training_acc": 48.0, "val_loss": 3.1144626045227053, "val_acc": 52.0}
{"epoch": 34, "training_loss": 2.3776176357269287, "training_acc": 52.0, "val_loss": 2.012347755432129, "val_acc": 52.0}
{"epoch": 35, "training_loss": 3.2900076007843015, "training_acc": 42.0, "val_loss": 0.7550394487380981, "val_acc": 48.0}
{"epoch": 36, "training_loss": 1.352005205154419, "training_acc": 50.0, "val_loss": 2.0816411542892457, "val_acc": 48.0}
{"epoch": 37, "training_loss": 1.295369758605957, "training_acc": 56.0, "val_loss": 0.6928015971183776, "val_acc": 52.0}
{"epoch": 38, "training_loss": 0.8475955390930175, "training_acc": 42.0, "val_loss": 1.2266037130355836, "val_acc": 52.0}
{"epoch": 39, "training_loss": 0.9726898670196533, "training_acc": 52.0, "val_loss": 0.6980543994903564, "val_acc": 52.0}
{"epoch": 40, "training_loss": 1.802560749053955, "training_acc": 52.0, "val_loss": 3.3150551605224607, "val_acc": 52.0}
{"epoch": 41, "training_loss": 1.650452880859375, "training_acc": 58.0, "val_loss": 2.7142478370666505, "val_acc": 52.0}
{"epoch": 42, "training_loss": 1.5154105997085572, "training_acc": 46.0, "val_loss": 2.4858887577056885, "val_acc": 52.0}
{"epoch": 43, "training_loss": 2.2199418258666994, "training_acc": 46.0, "val_loss": 0.7146767401695251, "val_acc": 48.0}
{"epoch": 44, "training_loss": 1.5745203137397765, "training_acc": 50.0, "val_loss": 2.0198810052871705, "val_acc": 48.0}
{"epoch": 45, "training_loss": 1.0233604979515076, "training_acc": 50.0, "val_loss": 1.0935586643218995, "val_acc": 52.0}
{"epoch": 46, "training_loss": 1.4873955488204955, "training_acc": 42.0, "val_loss": 1.0552505493164062, "val_acc": 52.0}
{"epoch": 47, "training_loss": 0.970003879070282, "training_acc": 48.0, "val_loss": 3.415735673904419, "val_acc": 52.0}
{"epoch": 48, "training_loss": 2.668611125946045, "training_acc": 50.0, "val_loss": 1.775427508354187, "val_acc": 52.0}
{"epoch": 49, "training_loss": 1.2440155363082885, "training_acc": 48.0, "val_loss": 0.6958475708961487, "val_acc": 52.0}
{"epoch": 50, "training_loss": 1.0923323678970336, "training_acc": 48.0, "val_loss": 1.983433427810669, "val_acc": 52.0}
{"epoch": 51, "training_loss": 1.7249233055114745, "training_acc": 50.0, "val_loss": 2.7886506509780884, "val_acc": 52.0}
{"epoch": 52, "training_loss": 1.8338895511627198, "training_acc": 46.0, "val_loss": 1.4608564043045045, "val_acc": 48.0}
{"epoch": 53, "training_loss": 1.1854875111579894, "training_acc": 50.0, "val_loss": 1.4012172889709473, "val_acc": 52.0}
{"epoch": 54, "training_loss": 1.2073539400100708, "training_acc": 48.0, "val_loss": 1.0434462308883667, "val_acc": 52.0}
{"epoch": 55, "training_loss": 1.3827301359176636, "training_acc": 56.0, "val_loss": 0.7000792407989502, "val_acc": 52.0}
{"epoch": 56, "training_loss": 0.8449722647666931, "training_acc": 46.0, "val_loss": 1.6492355012893676, "val_acc": 52.0}
