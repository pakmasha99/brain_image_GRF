"main_modify.py --pretrained_path /scratch/connectome/dyhan316/VAE_ADHD/barlowtwins/pretrain_results/ABCDbt128a102.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 5 --task ADNI_sex --input_option BT_org --learning_rate 1e-1 --batch_size 16 --weight_decay 1e-4 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 10.116648902893067, "training_acc": 50.0, "val_loss": 3.4669131660461425, "val_acc": 48.0}
{"epoch": 1, "training_loss": 4.09990894317627, "training_acc": 46.0, "val_loss": 1.446781129837036, "val_acc": 48.0}
{"epoch": 2, "training_loss": 2.081988615989685, "training_acc": 52.0, "val_loss": 1.2886193561553956, "val_acc": 52.0}
{"epoch": 3, "training_loss": 0.9892339777946472, "training_acc": 56.0, "val_loss": 1.8653451824188232, "val_acc": 48.0}
{"epoch": 4, "training_loss": 1.6814256238937377, "training_acc": 52.0, "val_loss": 1.2237156200408936, "val_acc": 48.0}
{"epoch": 5, "training_loss": 1.8638313961029054, "training_acc": 48.0, "val_loss": 0.8601216864585877, "val_acc": 48.0}
{"epoch": 6, "training_loss": 1.4017215824127198, "training_acc": 46.0, "val_loss": 0.7091146421432495, "val_acc": 52.0}
{"epoch": 7, "training_loss": 0.9729730606079101, "training_acc": 44.0, "val_loss": 1.2240775775909425, "val_acc": 48.0}
{"epoch": 8, "training_loss": 1.101747577190399, "training_acc": 46.0, "val_loss": 1.0752493286132812, "val_acc": 52.0}
{"epoch": 9, "training_loss": 1.0063634729385376, "training_acc": 46.0, "val_loss": 1.3686990928649903, "val_acc": 48.0}
{"epoch": 10, "training_loss": 1.6041283178329468, "training_acc": 44.0, "val_loss": 3.5300490283966064, "val_acc": 48.0}
{"epoch": 11, "training_loss": 2.1371167945861815, "training_acc": 52.0, "val_loss": 1.7965762042999267, "val_acc": 48.0}
{"epoch": 12, "training_loss": 1.86227530002594, "training_acc": 52.0, "val_loss": 2.7562773513793943, "val_acc": 48.0}
{"epoch": 13, "training_loss": 2.865844111442566, "training_acc": 50.0, "val_loss": 1.7580711770057678, "val_acc": 52.0}
{"epoch": 14, "training_loss": 1.7836384166777135, "training_acc": 48.0, "val_loss": 2.4293352365493774, "val_acc": 52.0}
{"epoch": 15, "training_loss": 2.5296502685546876, "training_acc": 36.0, "val_loss": 4.556511631011963, "val_acc": 52.0}
{"epoch": 16, "training_loss": 3.0885745906829833, "training_acc": 48.0, "val_loss": 0.8533804249763489, "val_acc": 52.0}
{"epoch": 17, "training_loss": 1.3069891667366027, "training_acc": 54.0, "val_loss": 1.1069022369384767, "val_acc": 52.0}
{"epoch": 18, "training_loss": 0.984106867313385, "training_acc": 42.0, "val_loss": 0.6998882269859314, "val_acc": 48.0}
{"epoch": 19, "training_loss": 0.7494941902160644, "training_acc": 48.0, "val_loss": 1.684991807937622, "val_acc": 48.0}
{"epoch": 20, "training_loss": 1.2684707641601562, "training_acc": 54.0, "val_loss": 1.0219072437286376, "val_acc": 48.0}
{"epoch": 21, "training_loss": 0.7044832968711853, "training_acc": 56.0, "val_loss": 2.511046485900879, "val_acc": 48.0}
{"epoch": 22, "training_loss": 1.5648522520065307, "training_acc": 48.0, "val_loss": 1.2245281648635864, "val_acc": 48.0}
{"epoch": 23, "training_loss": 1.1766745138168335, "training_acc": 46.0, "val_loss": 0.7034640860557556, "val_acc": 48.0}
{"epoch": 24, "training_loss": 0.7550921106338501, "training_acc": 48.0, "val_loss": 0.8730609154701233, "val_acc": 52.0}
{"epoch": 25, "training_loss": 0.7848038029670715, "training_acc": 50.0, "val_loss": 0.7226600670814514, "val_acc": 48.0}
{"epoch": 26, "training_loss": 1.611779180765152, "training_acc": 50.0, "val_loss": 0.9684574174880981, "val_acc": 48.0}
{"epoch": 27, "training_loss": 3.0405021287873386, "training_acc": 46.0, "val_loss": 6.0487097549438475, "val_acc": 52.0}
{"epoch": 28, "training_loss": 3.526114797592163, "training_acc": 40.0, "val_loss": 2.7199499225616455, "val_acc": 48.0}
{"epoch": 29, "training_loss": 2.149324345588684, "training_acc": 50.0, "val_loss": 1.2127256345748902, "val_acc": 52.0}
{"epoch": 30, "training_loss": 1.5193810176849365, "training_acc": 48.0, "val_loss": 3.434004535675049, "val_acc": 52.0}
{"epoch": 31, "training_loss": 3.1173982048034667, "training_acc": 52.0, "val_loss": 2.710656623840332, "val_acc": 52.0}
{"epoch": 32, "training_loss": 2.4166837882995607, "training_acc": 40.0, "val_loss": 2.047913837432861, "val_acc": 48.0}
{"epoch": 33, "training_loss": 2.855356311798096, "training_acc": 46.0, "val_loss": 0.9452149105072022, "val_acc": 52.0}
{"epoch": 34, "training_loss": 1.9497257375717163, "training_acc": 52.0, "val_loss": 1.1331216502189636, "val_acc": 52.0}
{"epoch": 35, "training_loss": 1.1652851009368896, "training_acc": 52.0, "val_loss": 1.0794478416442872, "val_acc": 48.0}
{"epoch": 36, "training_loss": 1.1440519428253173, "training_acc": 50.0, "val_loss": 0.8412969517707825, "val_acc": 48.0}
{"epoch": 37, "training_loss": 1.2571773052215576, "training_acc": 52.0, "val_loss": 1.992650032043457, "val_acc": 52.0}
