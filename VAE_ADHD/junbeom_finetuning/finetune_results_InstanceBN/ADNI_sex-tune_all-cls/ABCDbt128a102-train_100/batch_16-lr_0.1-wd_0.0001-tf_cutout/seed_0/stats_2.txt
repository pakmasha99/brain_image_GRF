"main_modify.py --pretrained_path /scratch/connectome/dyhan316/VAE_ADHD/barlowtwins/pretrain_results/ABCDbt128a102.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ADNI_sex --input_option BT_org --learning_rate 1e-1 --batch_size 16 --weight_decay 1e-4 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 9.209237298965455, "training_acc": 54.0, "val_loss": 0.6986134028434754, "val_acc": 48.0}
{"epoch": 1, "training_loss": 3.5046381092071535, "training_acc": 54.0, "val_loss": 4.9204676055908205, "val_acc": 52.0}
{"epoch": 2, "training_loss": 2.3622091150283815, "training_acc": 48.0, "val_loss": 1.07435124874115, "val_acc": 48.0}
{"epoch": 3, "training_loss": 1.0420086097717285, "training_acc": 44.0, "val_loss": 1.21478196144104, "val_acc": 48.0}
{"epoch": 4, "training_loss": 1.3583928298950196, "training_acc": 52.0, "val_loss": 0.9950391387939453, "val_acc": 52.0}
{"epoch": 5, "training_loss": 1.0854385852813722, "training_acc": 46.0, "val_loss": 1.059758985042572, "val_acc": 48.0}
{"epoch": 6, "training_loss": 0.8898125457763671, "training_acc": 50.0, "val_loss": 1.877739381790161, "val_acc": 52.0}
{"epoch": 7, "training_loss": 1.64534734249115, "training_acc": 58.0, "val_loss": 1.0277118802070617, "val_acc": 48.0}
{"epoch": 8, "training_loss": 1.0076421356201173, "training_acc": 52.0, "val_loss": 1.1147126626968384, "val_acc": 52.0}
{"epoch": 9, "training_loss": 1.0020798897743226, "training_acc": 52.0, "val_loss": 1.9682853412628174, "val_acc": 48.0}
{"epoch": 10, "training_loss": 1.7383518171310426, "training_acc": 54.0, "val_loss": 2.1063342094421387, "val_acc": 48.0}
{"epoch": 11, "training_loss": 1.2919883489608766, "training_acc": 52.0, "val_loss": 0.9957508969306946, "val_acc": 48.0}
{"epoch": 12, "training_loss": 1.3286574363708497, "training_acc": 50.0, "val_loss": 1.851358208656311, "val_acc": 52.0}
{"epoch": 13, "training_loss": 1.8737022829055787, "training_acc": 46.0, "val_loss": 2.8233610916137697, "val_acc": 52.0}
{"epoch": 14, "training_loss": 1.9649108362197876, "training_acc": 52.0, "val_loss": 2.2143748950958253, "val_acc": 52.0}
{"epoch": 15, "training_loss": 1.764263572692871, "training_acc": 46.0, "val_loss": 0.6936637449264527, "val_acc": 52.0}
{"epoch": 16, "training_loss": 0.9335192847251892, "training_acc": 54.0, "val_loss": 1.0545729303359985, "val_acc": 48.0}
{"epoch": 17, "training_loss": 0.7454208850860595, "training_acc": 56.0, "val_loss": 0.7831531333923339, "val_acc": 52.0}
{"epoch": 18, "training_loss": 0.7784037685394287, "training_acc": 50.0, "val_loss": 0.8881869912147522, "val_acc": 48.0}
{"epoch": 19, "training_loss": 0.9105946159362793, "training_acc": 50.0, "val_loss": 1.0489742946624756, "val_acc": 52.0}
{"epoch": 20, "training_loss": 0.8819539356231689, "training_acc": 54.0, "val_loss": 1.917807364463806, "val_acc": 48.0}
{"epoch": 21, "training_loss": 1.8762708854675294, "training_acc": 46.0, "val_loss": 1.4888477611541748, "val_acc": 48.0}
{"epoch": 22, "training_loss": 0.7850987815856934, "training_acc": 62.0, "val_loss": 0.7002365827560425, "val_acc": 52.0}
{"epoch": 23, "training_loss": 1.0349941635131836, "training_acc": 50.0, "val_loss": 1.5915898990631103, "val_acc": 48.0}
{"epoch": 24, "training_loss": 1.9144046306610107, "training_acc": 44.0, "val_loss": 1.5540903854370116, "val_acc": 48.0}
{"epoch": 25, "training_loss": 1.1969114112854005, "training_acc": 48.0, "val_loss": 1.6267938232421875, "val_acc": 52.0}
{"epoch": 26, "training_loss": 1.2313298606872558, "training_acc": 52.0, "val_loss": 0.9978672409057617, "val_acc": 48.0}
{"epoch": 27, "training_loss": 1.3592698001861572, "training_acc": 44.0, "val_loss": 1.549927339553833, "val_acc": 48.0}
{"epoch": 28, "training_loss": 1.5978274726867676, "training_acc": 38.0, "val_loss": 0.6946897840499878, "val_acc": 52.0}
{"epoch": 29, "training_loss": 0.9095326662063599, "training_acc": 42.0, "val_loss": 1.4787436628341675, "val_acc": 48.0}
{"epoch": 30, "training_loss": 1.2482592010498046, "training_acc": 56.0, "val_loss": 1.8407153940200807, "val_acc": 48.0}
{"epoch": 31, "training_loss": 1.0414887976646423, "training_acc": 58.0, "val_loss": 0.8344594645500183, "val_acc": 48.0}
{"epoch": 32, "training_loss": 0.9513187456130981, "training_acc": 46.0, "val_loss": 0.7023626041412353, "val_acc": 52.0}
{"epoch": 33, "training_loss": 0.9498672795295715, "training_acc": 46.0, "val_loss": 0.7956329441070557, "val_acc": 52.0}
{"epoch": 34, "training_loss": 0.8156025242805481, "training_acc": 56.0, "val_loss": 0.9501790857315063, "val_acc": 48.0}
