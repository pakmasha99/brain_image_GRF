"main_modify.py --pretrained_path /scratch/connectome/dyhan316/VAE_ADHD/barlowtwins/pretrain_results/ABCDbt128a102.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ADNI_sex --input_option BT_org --learning_rate 1e-1 --batch_size 16 --weight_decay 1e-4 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 10.958156909942627, "training_acc": 52.0, "val_loss": 3.2073294353485107, "val_acc": 52.0}
{"epoch": 1, "training_loss": 7.728980646133423, "training_acc": 44.0, "val_loss": 3.868259782791138, "val_acc": 52.0}
{"epoch": 2, "training_loss": 6.475332159996032, "training_acc": 50.0, "val_loss": 3.6679486274719237, "val_acc": 48.0}
{"epoch": 3, "training_loss": 4.350182161331177, "training_acc": 50.0, "val_loss": 4.324818553924561, "val_acc": 52.0}
{"epoch": 4, "training_loss": 2.9389201545715333, "training_acc": 52.0, "val_loss": 0.8540968680381775, "val_acc": 48.0}
{"epoch": 5, "training_loss": 3.0444748981297014, "training_acc": 48.0, "val_loss": 6.260580997467041, "val_acc": 48.0}
{"epoch": 6, "training_loss": 4.930285687446594, "training_acc": 48.0, "val_loss": 3.7154886436462404, "val_acc": 52.0}
{"epoch": 7, "training_loss": 2.6813001537323, "training_acc": 46.0, "val_loss": 1.2495863246917724, "val_acc": 52.0}
{"epoch": 8, "training_loss": 1.4468070793151855, "training_acc": 46.0, "val_loss": 1.6252269744873047, "val_acc": 52.0}
{"epoch": 9, "training_loss": 1.1768926882743835, "training_acc": 48.0, "val_loss": 1.0429440259933471, "val_acc": 48.0}
{"epoch": 10, "training_loss": 0.930902853012085, "training_acc": 56.0, "val_loss": 0.8563394117355346, "val_acc": 48.0}
{"epoch": 11, "training_loss": 1.274874782562256, "training_acc": 56.0, "val_loss": 1.1986265134811402, "val_acc": 48.0}
{"epoch": 12, "training_loss": 2.64657066822052, "training_acc": 46.0, "val_loss": 1.6307447052001953, "val_acc": 52.0}
{"epoch": 13, "training_loss": 1.9507657814025878, "training_acc": 48.0, "val_loss": 1.7667289352416993, "val_acc": 52.0}
{"epoch": 14, "training_loss": 1.4326833629608153, "training_acc": 54.0, "val_loss": 3.2431314325332643, "val_acc": 48.0}
{"epoch": 15, "training_loss": 2.6022299766540526, "training_acc": 60.0, "val_loss": 3.279728717803955, "val_acc": 52.0}
{"epoch": 16, "training_loss": 2.052917900085449, "training_acc": 58.0, "val_loss": 3.3724670791625977, "val_acc": 52.0}
{"epoch": 17, "training_loss": 1.8638918161392213, "training_acc": 50.0, "val_loss": 1.5657403039932252, "val_acc": 52.0}
{"epoch": 18, "training_loss": 0.9212022638320922, "training_acc": 50.0, "val_loss": 0.6991088223457337, "val_acc": 52.0}
{"epoch": 19, "training_loss": 0.7356521224975586, "training_acc": 54.0, "val_loss": 1.4256543016433716, "val_acc": 48.0}
{"epoch": 20, "training_loss": 0.9294164919853211, "training_acc": 56.0, "val_loss": 0.9223852849006653, "val_acc": 52.0}
{"epoch": 21, "training_loss": 0.8761055779457092, "training_acc": 48.0, "val_loss": 0.8936016392707825, "val_acc": 52.0}
{"epoch": 22, "training_loss": 0.926013536453247, "training_acc": 52.0, "val_loss": 0.9601895427703857, "val_acc": 52.0}
{"epoch": 23, "training_loss": 1.5303314161300658, "training_acc": 44.0, "val_loss": 3.2082567024230957, "val_acc": 48.0}
{"epoch": 24, "training_loss": 2.7833487398177383, "training_acc": 56.0, "val_loss": 2.3389212608337404, "val_acc": 52.0}
{"epoch": 25, "training_loss": 1.6855086183547974, "training_acc": 54.0, "val_loss": 1.1156117153167724, "val_acc": 48.0}
{"epoch": 26, "training_loss": 0.8764374613761902, "training_acc": 50.0, "val_loss": 1.9086785078048707, "val_acc": 52.0}
{"epoch": 27, "training_loss": 1.6552097155898808, "training_acc": 50.0, "val_loss": 1.644952826499939, "val_acc": 52.0}
{"epoch": 28, "training_loss": 0.9636313986778259, "training_acc": 44.0, "val_loss": 0.9658515739440918, "val_acc": 48.0}
{"epoch": 29, "training_loss": 0.8118892335891723, "training_acc": 50.0, "val_loss": 0.7643622446060181, "val_acc": 52.0}
{"epoch": 30, "training_loss": 0.9749731731414795, "training_acc": 48.0, "val_loss": 1.3322842836380004, "val_acc": 52.0}
{"epoch": 31, "training_loss": 1.03708251953125, "training_acc": 50.0, "val_loss": 1.6733526182174683, "val_acc": 48.0}
{"epoch": 32, "training_loss": 1.0075186824798583, "training_acc": 44.0, "val_loss": 3.3697924995422364, "val_acc": 52.0}
{"epoch": 33, "training_loss": 2.1754539728164675, "training_acc": 46.0, "val_loss": 1.4173400592803955, "val_acc": 48.0}
{"epoch": 34, "training_loss": 0.9461228275299072, "training_acc": 50.0, "val_loss": 1.6267920637130737, "val_acc": 48.0}
{"epoch": 35, "training_loss": 0.9480870389938354, "training_acc": 54.0, "val_loss": 1.2175169038772582, "val_acc": 52.0}
{"epoch": 36, "training_loss": 0.987538800239563, "training_acc": 44.0, "val_loss": 0.7016504406929016, "val_acc": 48.0}
{"epoch": 37, "training_loss": 0.9408684015274048, "training_acc": 42.0, "val_loss": 1.965421323776245, "val_acc": 48.0}
