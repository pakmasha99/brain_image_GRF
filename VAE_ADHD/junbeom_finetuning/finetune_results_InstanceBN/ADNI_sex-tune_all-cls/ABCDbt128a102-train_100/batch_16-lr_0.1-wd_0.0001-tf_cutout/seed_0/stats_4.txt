"main_modify.py --pretrained_path /scratch/connectome/dyhan316/VAE_ADHD/barlowtwins/pretrain_results/ABCDbt128a102.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ADNI_sex --input_option BT_org --learning_rate 1e-1 --batch_size 16 --weight_decay 1e-4 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 11.39529712677002, "training_acc": 46.0, "val_loss": 5.687988986968994, "val_acc": 48.0}
{"epoch": 1, "training_loss": 4.560173811912537, "training_acc": 56.0, "val_loss": 4.098419933319092, "val_acc": 48.0}
{"epoch": 2, "training_loss": 3.7782089424133303, "training_acc": 52.0, "val_loss": 1.814296875, "val_acc": 52.0}
{"epoch": 3, "training_loss": 2.585189037322998, "training_acc": 46.0, "val_loss": 2.0176916098594666, "val_acc": 52.0}
{"epoch": 4, "training_loss": 1.2170128870010375, "training_acc": 52.0, "val_loss": 2.3590468072891237, "val_acc": 48.0}
{"epoch": 5, "training_loss": 1.7909502935409547, "training_acc": 54.0, "val_loss": 3.3535900497436524, "val_acc": 48.0}
{"epoch": 6, "training_loss": 2.2174014234542847, "training_acc": 62.0, "val_loss": 0.8559380030632019, "val_acc": 48.0}
{"epoch": 7, "training_loss": 1.0774332237243653, "training_acc": 52.0, "val_loss": 1.9473756170272827, "val_acc": 48.0}
{"epoch": 8, "training_loss": 1.4384485721588134, "training_acc": 48.0, "val_loss": 0.7419772338867188, "val_acc": 48.0}
{"epoch": 9, "training_loss": 0.7345520639419556, "training_acc": 54.0, "val_loss": 0.9814128255844117, "val_acc": 52.0}
{"epoch": 10, "training_loss": 2.058476085662842, "training_acc": 38.0, "val_loss": 1.269423267841339, "val_acc": 48.0}
{"epoch": 11, "training_loss": 2.530078996231314, "training_acc": 48.0, "val_loss": 4.217368793487549, "val_acc": 48.0}
{"epoch": 12, "training_loss": 1.9836201572418213, "training_acc": 52.0, "val_loss": 0.7040508651733398, "val_acc": 48.0}
{"epoch": 13, "training_loss": 1.1211666202545165, "training_acc": 54.0, "val_loss": 0.7565862321853638, "val_acc": 48.0}
{"epoch": 14, "training_loss": 0.7700074434280395, "training_acc": 46.0, "val_loss": 0.7076808977127075, "val_acc": 48.0}
{"epoch": 15, "training_loss": 0.9697364330291748, "training_acc": 48.0, "val_loss": 1.1957781744003295, "val_acc": 52.0}
{"epoch": 16, "training_loss": 1.1536565136909485, "training_acc": 48.0, "val_loss": 1.7178479146957397, "val_acc": 48.0}
{"epoch": 17, "training_loss": 1.151095485687256, "training_acc": 54.0, "val_loss": 0.6952492260932922, "val_acc": 52.0}
{"epoch": 18, "training_loss": 1.0058400297164918, "training_acc": 46.0, "val_loss": 0.751234905719757, "val_acc": 52.0}
{"epoch": 19, "training_loss": 1.2043031978607177, "training_acc": 48.0, "val_loss": 0.695829656124115, "val_acc": 52.0}
{"epoch": 20, "training_loss": 0.8969385671615601, "training_acc": 48.0, "val_loss": 1.2607460308074951, "val_acc": 48.0}
{"epoch": 21, "training_loss": 1.195768756866455, "training_acc": 58.0, "val_loss": 0.7104173445701599, "val_acc": 48.0}
{"epoch": 22, "training_loss": 0.7476465511322021, "training_acc": 54.0, "val_loss": 0.9822466611862183, "val_acc": 48.0}
{"epoch": 23, "training_loss": 0.8948576283454895, "training_acc": 52.0, "val_loss": 1.7248043489456177, "val_acc": 52.0}
{"epoch": 24, "training_loss": 1.8613423587381839, "training_acc": 52.0, "val_loss": 5.32217191696167, "val_acc": 52.0}
{"epoch": 25, "training_loss": 3.046921981275082, "training_acc": 50.0, "val_loss": 1.9898275136947632, "val_acc": 48.0}
{"epoch": 26, "training_loss": 1.4182691287994384, "training_acc": 44.0, "val_loss": 1.503678822517395, "val_acc": 52.0}
{"epoch": 27, "training_loss": 1.5410931730270385, "training_acc": 52.0, "val_loss": 2.573134536743164, "val_acc": 48.0}
{"epoch": 28, "training_loss": 1.458368592262268, "training_acc": 52.0, "val_loss": 0.8812231349945069, "val_acc": 48.0}
{"epoch": 29, "training_loss": 1.5523013162612915, "training_acc": 44.0, "val_loss": 6.7441433143615725, "val_acc": 48.0}
{"epoch": 30, "training_loss": 2.8749031138420107, "training_acc": 46.0, "val_loss": 3.187132701873779, "val_acc": 52.0}
{"epoch": 31, "training_loss": 2.6392309284210205, "training_acc": 50.0, "val_loss": 2.900790672302246, "val_acc": 52.0}
{"epoch": 32, "training_loss": 3.5623466873168947, "training_acc": 48.0, "val_loss": 2.9675848960876463, "val_acc": 48.0}
{"epoch": 33, "training_loss": 2.9736131620407105, "training_acc": 50.0, "val_loss": 1.4835331344604492, "val_acc": 52.0}
{"epoch": 34, "training_loss": 1.2760697174072266, "training_acc": 50.0, "val_loss": 1.0478520154953004, "val_acc": 52.0}
{"epoch": 35, "training_loss": 1.2797494220733643, "training_acc": 51.0, "val_loss": 0.8639905786514283, "val_acc": 52.0}
{"epoch": 36, "training_loss": 0.8733593368530274, "training_acc": 51.0, "val_loss": 2.922478427886963, "val_acc": 48.0}
