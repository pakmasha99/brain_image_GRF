"main_modify.py --pretrained_path /scratch/connectome/dyhan316/VAE_ADHD/barlowtwins/pretrain_results/ABCDbt128a102.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 8 --task ADNI_sex --input_option BT_org --learning_rate 1e-2 --batch_size 16 --weight_decay 1e-2 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 1.1033261561393737, "training_acc": 50.0, "val_loss": 0.7621057486534119, "val_acc": 48.0}
{"epoch": 1, "training_loss": 0.7824207019805908, "training_acc": 44.0, "val_loss": 0.8379183220863342, "val_acc": 48.0}
{"epoch": 2, "training_loss": 0.7914684724807739, "training_acc": 42.0, "val_loss": 0.6927410912513733, "val_acc": 52.0}
{"epoch": 3, "training_loss": 0.7185246324539185, "training_acc": 50.0, "val_loss": 0.7369212079048156, "val_acc": 52.0}
{"epoch": 4, "training_loss": 0.7252733540534974, "training_acc": 50.0, "val_loss": 0.7839636588096619, "val_acc": 48.0}
{"epoch": 5, "training_loss": 0.726092472076416, "training_acc": 56.0, "val_loss": 0.8136872339248657, "val_acc": 52.0}
{"epoch": 6, "training_loss": 0.8006038475036621, "training_acc": 44.0, "val_loss": 0.7298164343833924, "val_acc": 52.0}
{"epoch": 7, "training_loss": 0.7241571378707886, "training_acc": 52.0, "val_loss": 0.6947962999343872, "val_acc": 48.0}
{"epoch": 8, "training_loss": 0.7018228888511657, "training_acc": 58.0, "val_loss": 0.7816012907028198, "val_acc": 52.0}
{"epoch": 9, "training_loss": 0.7376913094520569, "training_acc": 50.0, "val_loss": 0.7605946516990661, "val_acc": 48.0}
{"epoch": 10, "training_loss": 0.7087911105155945, "training_acc": 52.0, "val_loss": 0.8072550582885742, "val_acc": 52.0}
{"epoch": 11, "training_loss": 0.7728452181816101, "training_acc": 40.0, "val_loss": 0.8382464575767518, "val_acc": 48.0}
{"epoch": 12, "training_loss": 0.7876609873771667, "training_acc": 50.0, "val_loss": 0.7069564056396485, "val_acc": 48.0}
{"epoch": 13, "training_loss": 0.7491025710105896, "training_acc": 46.0, "val_loss": 0.7543986034393311, "val_acc": 52.0}
{"epoch": 14, "training_loss": 0.7154270362854004, "training_acc": 52.0, "val_loss": 0.7678239560127258, "val_acc": 48.0}
{"epoch": 15, "training_loss": 0.7006685090065002, "training_acc": 56.0, "val_loss": 0.7641584467887879, "val_acc": 52.0}
{"epoch": 16, "training_loss": 0.7581192445755005, "training_acc": 38.0, "val_loss": 0.7239902806282044, "val_acc": 48.0}
{"epoch": 17, "training_loss": 0.713893404006958, "training_acc": 52.0, "val_loss": 0.8118817496299744, "val_acc": 52.0}
{"epoch": 18, "training_loss": 0.7945488429069519, "training_acc": 40.0, "val_loss": 0.7099935364723206, "val_acc": 52.0}
{"epoch": 19, "training_loss": 0.7418682098388671, "training_acc": 50.0, "val_loss": 0.7482563757896423, "val_acc": 52.0}
{"epoch": 20, "training_loss": 0.7574287033081055, "training_acc": 42.0, "val_loss": 0.7046680164337158, "val_acc": 52.0}
{"epoch": 21, "training_loss": 0.7155603218078613, "training_acc": 44.0, "val_loss": 0.7477831363677978, "val_acc": 48.0}
{"epoch": 22, "training_loss": 0.7309955787658692, "training_acc": 48.0, "val_loss": 0.6925156307220459, "val_acc": 52.0}
{"epoch": 23, "training_loss": 0.7071944904327393, "training_acc": 52.0, "val_loss": 0.7064712715148925, "val_acc": 48.0}
{"epoch": 24, "training_loss": 0.7508667755126953, "training_acc": 48.0, "val_loss": 0.6928088808059693, "val_acc": 52.0}
{"epoch": 25, "training_loss": 0.7024239683151245, "training_acc": 50.0, "val_loss": 0.7109734797477723, "val_acc": 48.0}
{"epoch": 26, "training_loss": 0.7255140995979309, "training_acc": 44.0, "val_loss": 0.7924348187446594, "val_acc": 48.0}
{"epoch": 27, "training_loss": 0.7450318241119385, "training_acc": 48.0, "val_loss": 0.6929482316970825, "val_acc": 52.0}
{"epoch": 28, "training_loss": 0.7203433990478516, "training_acc": 48.0, "val_loss": 0.694984712600708, "val_acc": 52.0}
{"epoch": 29, "training_loss": 0.7153487825393676, "training_acc": 50.0, "val_loss": 0.6923471164703369, "val_acc": 52.0}
{"epoch": 30, "training_loss": 0.6992903637886048, "training_acc": 50.0, "val_loss": 0.6955614066123963, "val_acc": 52.0}
{"epoch": 31, "training_loss": 0.7330908751487732, "training_acc": 42.0, "val_loss": 0.6924592280387878, "val_acc": 52.0}
{"epoch": 32, "training_loss": 0.7089009690284729, "training_acc": 44.0, "val_loss": 0.694206600189209, "val_acc": 48.0}
{"epoch": 33, "training_loss": 0.7049219131469726, "training_acc": 46.0, "val_loss": 0.7109943890571594, "val_acc": 48.0}
{"epoch": 34, "training_loss": 0.7243859338760376, "training_acc": 50.0, "val_loss": 0.6929549837112426, "val_acc": 52.0}
{"epoch": 35, "training_loss": 0.696270821094513, "training_acc": 48.0, "val_loss": 0.7419852495193482, "val_acc": 48.0}
{"epoch": 36, "training_loss": 0.7130104899406433, "training_acc": 54.0, "val_loss": 0.7708387684822082, "val_acc": 52.0}
{"epoch": 37, "training_loss": 0.7720296001434326, "training_acc": 50.0, "val_loss": 0.733980860710144, "val_acc": 48.0}
{"epoch": 38, "training_loss": 0.7285948586463928, "training_acc": 50.0, "val_loss": 0.6951554322242737, "val_acc": 52.0}
{"epoch": 39, "training_loss": 0.7275104570388794, "training_acc": 44.0, "val_loss": 0.7219619560241699, "val_acc": 48.0}
{"epoch": 40, "training_loss": 0.7154574489593506, "training_acc": 48.0, "val_loss": 0.6927622938156128, "val_acc": 52.0}
{"epoch": 41, "training_loss": 0.7118528890609741, "training_acc": 42.0, "val_loss": 0.7125448560714722, "val_acc": 48.0}
{"epoch": 42, "training_loss": 0.7114576816558837, "training_acc": 46.0, "val_loss": 0.6935717010498047, "val_acc": 48.0}
{"epoch": 43, "training_loss": 0.7053787183761596, "training_acc": 48.0, "val_loss": 0.706668050289154, "val_acc": 52.0}
{"epoch": 44, "training_loss": 0.8583425951004028, "training_acc": 50.0, "val_loss": 0.7238775181770325, "val_acc": 48.0}
{"epoch": 45, "training_loss": 0.7282403373718261, "training_acc": 44.0, "val_loss": 0.6923614931106568, "val_acc": 52.0}
{"epoch": 46, "training_loss": 0.7080943965911866, "training_acc": 48.0, "val_loss": 0.6970510816574097, "val_acc": 48.0}
{"epoch": 47, "training_loss": 0.7063529825210572, "training_acc": 52.0, "val_loss": 0.692377290725708, "val_acc": 52.0}
{"epoch": 48, "training_loss": 0.7267156147956848, "training_acc": 50.0, "val_loss": 0.7043090057373047, "val_acc": 52.0}
