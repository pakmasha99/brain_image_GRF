"main_modify.py --pretrained_path /scratch/connectome/dyhan316/VAE_ADHD/barlowtwins/pretrain_results/ABCDbt128a102.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 8 --task ADNI_sex --input_option BT_org --learning_rate 1e-2 --batch_size 16 --weight_decay 1e-2 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 1.190122365951538, "training_acc": 54.0, "val_loss": 0.7631771802902222, "val_acc": 48.0}
{"epoch": 1, "training_loss": 0.9072941493988037, "training_acc": 50.0, "val_loss": 0.9631613540649414, "val_acc": 48.0}
{"epoch": 2, "training_loss": 0.766927011013031, "training_acc": 48.0, "val_loss": 0.6975073981285095, "val_acc": 52.0}
{"epoch": 3, "training_loss": 0.7085135149955749, "training_acc": 50.0, "val_loss": 0.7015113162994385, "val_acc": 52.0}
{"epoch": 4, "training_loss": 0.7756755518913269, "training_acc": 54.0, "val_loss": 0.98834228515625, "val_acc": 48.0}
{"epoch": 5, "training_loss": 0.8404781484603882, "training_acc": 48.0, "val_loss": 0.7037676906585694, "val_acc": 48.0}
{"epoch": 6, "training_loss": 0.7046309542655945, "training_acc": 50.0, "val_loss": 0.8512152171134949, "val_acc": 48.0}
{"epoch": 7, "training_loss": 0.7717359209060669, "training_acc": 52.0, "val_loss": 0.6987912011146545, "val_acc": 52.0}
{"epoch": 8, "training_loss": 0.7247659111022949, "training_acc": 46.0, "val_loss": 0.7553244352340698, "val_acc": 52.0}
{"epoch": 9, "training_loss": 0.7449786710739136, "training_acc": 46.0, "val_loss": 0.7019692611694336, "val_acc": 52.0}
{"epoch": 10, "training_loss": 0.720800302028656, "training_acc": 54.0, "val_loss": 0.703763735294342, "val_acc": 48.0}
{"epoch": 11, "training_loss": 0.7173421025276184, "training_acc": 44.0, "val_loss": 0.8292060852050781, "val_acc": 52.0}
{"epoch": 12, "training_loss": 0.7423787760734558, "training_acc": 52.0, "val_loss": 0.8128669476509094, "val_acc": 48.0}
{"epoch": 13, "training_loss": 0.752545952796936, "training_acc": 42.0, "val_loss": 0.6949380040168762, "val_acc": 48.0}
{"epoch": 14, "training_loss": 0.7437250041961669, "training_acc": 48.0, "val_loss": 0.6939594388008118, "val_acc": 48.0}
{"epoch": 15, "training_loss": 0.7281174206733704, "training_acc": 52.0, "val_loss": 0.7501098322868347, "val_acc": 52.0}
{"epoch": 16, "training_loss": 0.7492203617095947, "training_acc": 44.0, "val_loss": 0.7473769450187683, "val_acc": 48.0}
{"epoch": 17, "training_loss": 0.7366680812835693, "training_acc": 46.0, "val_loss": 0.7229075384140015, "val_acc": 52.0}
{"epoch": 18, "training_loss": 0.7625985312461853, "training_acc": 50.0, "val_loss": 0.7139699220657348, "val_acc": 48.0}
{"epoch": 19, "training_loss": 0.7043116784095764, "training_acc": 50.0, "val_loss": 0.6938148236274719, "val_acc": 48.0}
{"epoch": 20, "training_loss": 0.7435426807403565, "training_acc": 50.0, "val_loss": 0.714051296710968, "val_acc": 52.0}
{"epoch": 21, "training_loss": 0.7153119897842407, "training_acc": 46.0, "val_loss": 0.6954048085212707, "val_acc": 52.0}
{"epoch": 22, "training_loss": 0.7123057699203491, "training_acc": 52.0, "val_loss": 0.8192015385627747, "val_acc": 52.0}
{"epoch": 23, "training_loss": 0.82506667137146, "training_acc": 44.0, "val_loss": 0.6948745656013489, "val_acc": 48.0}
{"epoch": 24, "training_loss": 0.7512261176109314, "training_acc": 50.0, "val_loss": 0.7120872569084168, "val_acc": 48.0}
{"epoch": 25, "training_loss": 0.7252187585830688, "training_acc": 48.0, "val_loss": 0.7346433448791504, "val_acc": 48.0}
{"epoch": 26, "training_loss": 0.7125540947914124, "training_acc": 52.0, "val_loss": 0.7251513409614563, "val_acc": 52.0}
{"epoch": 27, "training_loss": 0.7233175563812256, "training_acc": 54.0, "val_loss": 0.6923503684997558, "val_acc": 52.0}
{"epoch": 28, "training_loss": 0.7341650700569153, "training_acc": 54.0, "val_loss": 0.92742351770401, "val_acc": 48.0}
{"epoch": 29, "training_loss": 0.7895847511291504, "training_acc": 50.0, "val_loss": 0.7155810928344727, "val_acc": 48.0}
{"epoch": 30, "training_loss": 0.7242271709442138, "training_acc": 50.0, "val_loss": 0.7374165630340577, "val_acc": 52.0}
{"epoch": 31, "training_loss": 0.7570333552360534, "training_acc": 48.0, "val_loss": 0.7858047533035278, "val_acc": 48.0}
{"epoch": 32, "training_loss": 0.7010740518569947, "training_acc": 56.0, "val_loss": 0.8532751369476318, "val_acc": 52.0}
{"epoch": 33, "training_loss": 0.7595770955085754, "training_acc": 50.0, "val_loss": 0.7136955308914185, "val_acc": 48.0}
{"epoch": 34, "training_loss": 0.7136923837661743, "training_acc": 54.0, "val_loss": 0.6974019742012024, "val_acc": 52.0}
{"epoch": 35, "training_loss": 0.6883833503723145, "training_acc": 54.0, "val_loss": 0.7149646806716919, "val_acc": 48.0}
{"epoch": 36, "training_loss": 0.7104611706733703, "training_acc": 50.0, "val_loss": 0.6953148961067199, "val_acc": 52.0}
{"epoch": 37, "training_loss": 0.6901049423217773, "training_acc": 50.0, "val_loss": 0.7848458814620972, "val_acc": 48.0}
{"epoch": 38, "training_loss": 0.7476404047012329, "training_acc": 40.0, "val_loss": 0.6981030988693238, "val_acc": 52.0}
{"epoch": 39, "training_loss": 0.7058391857147217, "training_acc": 46.0, "val_loss": 0.6923761868476868, "val_acc": 52.0}
{"epoch": 40, "training_loss": 0.7216106152534485, "training_acc": 50.0, "val_loss": 0.7098196911811828, "val_acc": 48.0}
{"epoch": 41, "training_loss": 0.707205376625061, "training_acc": 48.0, "val_loss": 0.6961300539970398, "val_acc": 48.0}
{"epoch": 42, "training_loss": 0.704295916557312, "training_acc": 46.0, "val_loss": 0.6992032194137573, "val_acc": 52.0}
{"epoch": 43, "training_loss": 0.7141856050491333, "training_acc": 50.0, "val_loss": 0.7191064119338989, "val_acc": 48.0}
{"epoch": 44, "training_loss": 0.7426024794578552, "training_acc": 50.0, "val_loss": 0.7233379721641541, "val_acc": 52.0}
{"epoch": 45, "training_loss": 0.7194381356239319, "training_acc": 52.0, "val_loss": 0.7357467079162597, "val_acc": 48.0}
{"epoch": 46, "training_loss": 0.7418663311004638, "training_acc": 52.0, "val_loss": 0.7948868918418884, "val_acc": 52.0}
