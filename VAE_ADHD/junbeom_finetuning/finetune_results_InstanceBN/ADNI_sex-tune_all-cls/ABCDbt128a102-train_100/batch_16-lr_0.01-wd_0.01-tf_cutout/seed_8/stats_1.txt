"main_modify.py --pretrained_path /scratch/connectome/dyhan316/VAE_ADHD/barlowtwins/pretrain_results/ABCDbt128a102.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 8 --task ADNI_sex --input_option BT_org --learning_rate 1e-2 --batch_size 16 --weight_decay 1e-2 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 1.0204337000846864, "training_acc": 53.0, "val_loss": 0.7109015464782715, "val_acc": 52.0}
{"epoch": 1, "training_loss": 0.7615850639343261, "training_acc": 59.0, "val_loss": 0.9710617685317993, "val_acc": 52.0}
{"epoch": 2, "training_loss": 0.7934518814086914, "training_acc": 49.0, "val_loss": 0.6927033972740173, "val_acc": 52.0}
{"epoch": 3, "training_loss": 0.6919527339935303, "training_acc": 53.0, "val_loss": 0.8957984256744385, "val_acc": 48.0}
{"epoch": 4, "training_loss": 0.8329110717773438, "training_acc": 43.0, "val_loss": 0.6929806065559387, "val_acc": 52.0}
{"epoch": 5, "training_loss": 0.7220557808876038, "training_acc": 45.0, "val_loss": 0.7206900596618653, "val_acc": 48.0}
{"epoch": 6, "training_loss": 0.7238108849525452, "training_acc": 47.0, "val_loss": 0.7016345310211182, "val_acc": 48.0}
{"epoch": 7, "training_loss": 0.7267137193679809, "training_acc": 49.0, "val_loss": 0.8105065679550171, "val_acc": 52.0}
{"epoch": 8, "training_loss": 0.7463106894493103, "training_acc": 51.0, "val_loss": 0.7042570948600769, "val_acc": 48.0}
{"epoch": 9, "training_loss": 0.6945997047424316, "training_acc": 53.0, "val_loss": 0.692347240447998, "val_acc": 52.0}
{"epoch": 10, "training_loss": 0.7084915828704834, "training_acc": 51.0, "val_loss": 0.7584992265701294, "val_acc": 52.0}
{"epoch": 11, "training_loss": 0.7900222206115722, "training_acc": 37.0, "val_loss": 0.6943943476676941, "val_acc": 52.0}
{"epoch": 12, "training_loss": 0.7256512546539307, "training_acc": 43.0, "val_loss": 0.6932654929161072, "val_acc": 48.0}
{"epoch": 13, "training_loss": 0.7283464312553406, "training_acc": 53.0, "val_loss": 0.7484346985816955, "val_acc": 52.0}
{"epoch": 14, "training_loss": 0.7444256687164307, "training_acc": 51.0, "val_loss": 0.7248046803474426, "val_acc": 52.0}
{"epoch": 15, "training_loss": 0.7409817123413086, "training_acc": 47.0, "val_loss": 0.9028028869628906, "val_acc": 48.0}
{"epoch": 16, "training_loss": 0.9005410289764404, "training_acc": 39.0, "val_loss": 0.8657229971885682, "val_acc": 48.0}
{"epoch": 17, "training_loss": 0.7642151832580566, "training_acc": 55.0, "val_loss": 0.9017001128196717, "val_acc": 52.0}
{"epoch": 18, "training_loss": 0.7977904272079468, "training_acc": 49.0, "val_loss": 0.6963588762283325, "val_acc": 48.0}
{"epoch": 19, "training_loss": 0.7454467153549195, "training_acc": 41.0, "val_loss": 0.7571164751052857, "val_acc": 52.0}
{"epoch": 20, "training_loss": 0.735682623386383, "training_acc": 51.0, "val_loss": 0.8028341317176819, "val_acc": 48.0}
{"epoch": 21, "training_loss": 0.7433362555503845, "training_acc": 49.0, "val_loss": 0.6923543787002564, "val_acc": 52.0}
{"epoch": 22, "training_loss": 0.7270983481407165, "training_acc": 45.0, "val_loss": 0.7146001887321473, "val_acc": 52.0}
{"epoch": 23, "training_loss": 0.7483016777038575, "training_acc": 51.0, "val_loss": 0.7076805448532104, "val_acc": 48.0}
{"epoch": 24, "training_loss": 0.70915766954422, "training_acc": 53.0, "val_loss": 0.7175244975090027, "val_acc": 48.0}
{"epoch": 25, "training_loss": 0.7157510852813721, "training_acc": 43.0, "val_loss": 0.6923739719390869, "val_acc": 52.0}
{"epoch": 26, "training_loss": 0.7088006806373596, "training_acc": 51.0, "val_loss": 0.7824800515174866, "val_acc": 48.0}
{"epoch": 27, "training_loss": 0.767376971244812, "training_acc": 53.0, "val_loss": 0.7833927536010742, "val_acc": 52.0}
{"epoch": 28, "training_loss": 0.7290850639343261, "training_acc": 53.0, "val_loss": 1.0010455965995788, "val_acc": 48.0}
