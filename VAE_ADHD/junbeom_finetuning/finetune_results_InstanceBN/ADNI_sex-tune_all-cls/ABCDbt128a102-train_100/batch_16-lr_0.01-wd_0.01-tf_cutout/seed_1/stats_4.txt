"main_modify.py --pretrained_path /scratch/connectome/dyhan316/VAE_ADHD/barlowtwins/pretrain_results/ABCDbt128a102.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 1 --task ADNI_sex --input_option BT_org --learning_rate 1e-2 --batch_size 16 --weight_decay 1e-2 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 1.131973114013672, "training_acc": 51.0, "val_loss": 0.6940802693367004, "val_acc": 48.0}
{"epoch": 1, "training_loss": 0.7568027186393738, "training_acc": 51.0, "val_loss": 0.6937640309333801, "val_acc": 52.0}
{"epoch": 2, "training_loss": 0.7239921998977661, "training_acc": 45.0, "val_loss": 0.8380113101005554, "val_acc": 48.0}
{"epoch": 3, "training_loss": 0.7700001668930053, "training_acc": 47.0, "val_loss": 0.9174824476242065, "val_acc": 48.0}
{"epoch": 4, "training_loss": 0.8170591998100281, "training_acc": 51.0, "val_loss": 0.7002783799171448, "val_acc": 52.0}
{"epoch": 5, "training_loss": 0.675872837305069, "training_acc": 57.0, "val_loss": 1.056615433692932, "val_acc": 48.0}
{"epoch": 6, "training_loss": 0.8612034249305726, "training_acc": 49.0, "val_loss": 0.6987854337692261, "val_acc": 48.0}
{"epoch": 7, "training_loss": 0.7338333082199097, "training_acc": 53.0, "val_loss": 0.8555111241340637, "val_acc": 52.0}
{"epoch": 8, "training_loss": 0.8491926050186157, "training_acc": 39.0, "val_loss": 0.6979607129096985, "val_acc": 48.0}
{"epoch": 9, "training_loss": 0.7291654992103577, "training_acc": 41.0, "val_loss": 0.7080965924263001, "val_acc": 48.0}
{"epoch": 10, "training_loss": 0.7145048713684082, "training_acc": 47.0, "val_loss": 0.7490562510490417, "val_acc": 48.0}
{"epoch": 11, "training_loss": 0.7617664742469787, "training_acc": 39.0, "val_loss": 0.7065338897705078, "val_acc": 48.0}
{"epoch": 12, "training_loss": 0.7183837532997132, "training_acc": 49.0, "val_loss": 0.8203688001632691, "val_acc": 48.0}
{"epoch": 13, "training_loss": 0.7324280786514282, "training_acc": 55.0, "val_loss": 0.7831481266021728, "val_acc": 52.0}
{"epoch": 14, "training_loss": 0.7633783769607544, "training_acc": 43.0, "val_loss": 0.6927318668365479, "val_acc": 52.0}
{"epoch": 15, "training_loss": 0.700605285167694, "training_acc": 49.0, "val_loss": 0.7558358073234558, "val_acc": 48.0}
{"epoch": 16, "training_loss": 0.7359227991104126, "training_acc": 43.0, "val_loss": 0.7211703824996948, "val_acc": 52.0}
{"epoch": 17, "training_loss": 0.7291628408432007, "training_acc": 43.0, "val_loss": 0.8037696886062622, "val_acc": 48.0}
{"epoch": 18, "training_loss": 0.7781598877906799, "training_acc": 43.0, "val_loss": 0.6972258758544921, "val_acc": 48.0}
{"epoch": 19, "training_loss": 0.7079847383499146, "training_acc": 43.0, "val_loss": 0.741791775226593, "val_acc": 48.0}
{"epoch": 20, "training_loss": 0.7408609628677368, "training_acc": 43.0, "val_loss": 0.6926548099517822, "val_acc": 52.0}
{"epoch": 21, "training_loss": 0.736247673034668, "training_acc": 49.0, "val_loss": 0.8064486289024353, "val_acc": 48.0}
{"epoch": 22, "training_loss": 0.788122205734253, "training_acc": 49.0, "val_loss": 0.6924399256706237, "val_acc": 52.0}
{"epoch": 23, "training_loss": 0.725944619178772, "training_acc": 45.0, "val_loss": 0.697710964679718, "val_acc": 52.0}
{"epoch": 24, "training_loss": 0.7135329675674439, "training_acc": 49.0, "val_loss": 0.69247483253479, "val_acc": 52.0}
{"epoch": 25, "training_loss": 0.7021392583847046, "training_acc": 47.0, "val_loss": 0.7028743743896484, "val_acc": 52.0}
{"epoch": 26, "training_loss": 0.7405922746658326, "training_acc": 45.0, "val_loss": 0.7079136681556701, "val_acc": 48.0}
{"epoch": 27, "training_loss": 0.7231848382949829, "training_acc": 37.0, "val_loss": 0.7109023594856262, "val_acc": 48.0}
{"epoch": 28, "training_loss": 0.7099165534973144, "training_acc": 51.0, "val_loss": 0.7012548494338989, "val_acc": 48.0}
{"epoch": 29, "training_loss": 0.7160519623756408, "training_acc": 51.0, "val_loss": 0.742908444404602, "val_acc": 52.0}
{"epoch": 30, "training_loss": 0.7962776279449463, "training_acc": 49.0, "val_loss": 0.740095362663269, "val_acc": 48.0}
{"epoch": 31, "training_loss": 0.7146793127059936, "training_acc": 51.0, "val_loss": 0.6931791234016419, "val_acc": 52.0}
{"epoch": 32, "training_loss": 0.7084436941146851, "training_acc": 47.0, "val_loss": 0.709923894405365, "val_acc": 48.0}
{"epoch": 33, "training_loss": 0.7019392585754395, "training_acc": 51.0, "val_loss": 0.7032408952713013, "val_acc": 52.0}
{"epoch": 34, "training_loss": 0.7225714826583862, "training_acc": 51.0, "val_loss": 0.7920508122444153, "val_acc": 48.0}
{"epoch": 35, "training_loss": 0.762118284702301, "training_acc": 43.0, "val_loss": 0.6924456810951233, "val_acc": 52.0}
{"epoch": 36, "training_loss": 0.7050322580337525, "training_acc": 51.0, "val_loss": 0.6923481869697571, "val_acc": 52.0}
{"epoch": 37, "training_loss": 0.7069440507888793, "training_acc": 43.0, "val_loss": 0.6923860907554626, "val_acc": 52.0}
{"epoch": 38, "training_loss": 0.6991658234596252, "training_acc": 49.0, "val_loss": 0.6931205034255982, "val_acc": 52.0}
{"epoch": 39, "training_loss": 0.7246651935577393, "training_acc": 49.0, "val_loss": 0.7435873293876648, "val_acc": 48.0}
{"epoch": 40, "training_loss": 0.7271516990661621, "training_acc": 45.0, "val_loss": 0.6940011906623841, "val_acc": 48.0}
{"epoch": 41, "training_loss": 0.7056297492980957, "training_acc": 51.0, "val_loss": 0.692607262134552, "val_acc": 52.0}
{"epoch": 42, "training_loss": 0.7063319396972656, "training_acc": 47.0, "val_loss": 0.6949128723144531, "val_acc": 52.0}
{"epoch": 43, "training_loss": 0.7201121211051941, "training_acc": 49.0, "val_loss": 0.7260324597358704, "val_acc": 48.0}
{"epoch": 44, "training_loss": 0.7092524147033692, "training_acc": 49.0, "val_loss": 0.6933547902107239, "val_acc": 48.0}
{"epoch": 45, "training_loss": 0.7006173539161682, "training_acc": 51.0, "val_loss": 0.7015645599365234, "val_acc": 52.0}
{"epoch": 46, "training_loss": 0.7175545144081116, "training_acc": 41.0, "val_loss": 0.7634964680671692, "val_acc": 48.0}
{"epoch": 47, "training_loss": 0.7553518342971802, "training_acc": 45.0, "val_loss": 0.6928950500488281, "val_acc": 52.0}
{"epoch": 48, "training_loss": 0.6975442147254944, "training_acc": 53.0, "val_loss": 0.7338633894920349, "val_acc": 48.0}
{"epoch": 49, "training_loss": 0.6986473989486695, "training_acc": 53.0, "val_loss": 0.7320158100128173, "val_acc": 52.0}
{"epoch": 50, "training_loss": 0.7080653095245362, "training_acc": 55.0, "val_loss": 0.8381754803657532, "val_acc": 48.0}
{"epoch": 51, "training_loss": 0.8321439933776855, "training_acc": 47.0, "val_loss": 0.7116333866119384, "val_acc": 52.0}
{"epoch": 52, "training_loss": 0.7336230826377869, "training_acc": 47.0, "val_loss": 0.7675492882728576, "val_acc": 48.0}
{"epoch": 53, "training_loss": 0.7773532915115356, "training_acc": 45.0, "val_loss": 0.6954214954376221, "val_acc": 48.0}
{"epoch": 54, "training_loss": 0.7882383966445923, "training_acc": 49.0, "val_loss": 0.6965864467620849, "val_acc": 52.0}
{"epoch": 55, "training_loss": 0.7105718398094177, "training_acc": 45.0, "val_loss": 0.6964439344406128, "val_acc": 48.0}
