"main_modify.py --pretrained_path /scratch/connectome/dyhan316/VAE_ADHD/barlowtwins/pretrain_results/ABCDbt128a102.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 1 --task ADNI_sex --input_option BT_org --learning_rate 1e-2 --batch_size 16 --weight_decay 1e-2 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 1.142662807703018, "training_acc": 46.0, "val_loss": 1.0979041385650634, "val_acc": 48.0}
{"epoch": 1, "training_loss": 0.893315315246582, "training_acc": 46.0, "val_loss": 0.8323415565490723, "val_acc": 48.0}
{"epoch": 2, "training_loss": 0.8405716323852539, "training_acc": 50.0, "val_loss": 0.7276586294174194, "val_acc": 52.0}
{"epoch": 3, "training_loss": 0.7414685249328613, "training_acc": 50.0, "val_loss": 0.7141361713409424, "val_acc": 48.0}
{"epoch": 4, "training_loss": 0.7512472796440125, "training_acc": 46.0, "val_loss": 0.7254100775718689, "val_acc": 48.0}
{"epoch": 5, "training_loss": 0.7174217033386231, "training_acc": 46.0, "val_loss": 0.7093768358230591, "val_acc": 52.0}
{"epoch": 6, "training_loss": 0.7429396414756775, "training_acc": 44.0, "val_loss": 0.6998545479774475, "val_acc": 52.0}
{"epoch": 7, "training_loss": 0.7288170719146728, "training_acc": 50.0, "val_loss": 0.7464359021186828, "val_acc": 48.0}
{"epoch": 8, "training_loss": 0.748447277545929, "training_acc": 48.0, "val_loss": 0.7201474881172181, "val_acc": 48.0}
{"epoch": 9, "training_loss": 0.700577654838562, "training_acc": 52.0, "val_loss": 0.6964740371704101, "val_acc": 52.0}
{"epoch": 10, "training_loss": 0.7096899724006653, "training_acc": 56.0, "val_loss": 0.6934297466278077, "val_acc": 48.0}
{"epoch": 11, "training_loss": 0.7193825769424439, "training_acc": 42.0, "val_loss": 0.6958005738258362, "val_acc": 48.0}
{"epoch": 12, "training_loss": 0.7148950409889221, "training_acc": 46.0, "val_loss": 0.6954562759399414, "val_acc": 52.0}
{"epoch": 13, "training_loss": 0.7085648441314697, "training_acc": 52.0, "val_loss": 0.8719079351425171, "val_acc": 52.0}
{"epoch": 14, "training_loss": 0.7881265854835511, "training_acc": 50.0, "val_loss": 0.6955605363845825, "val_acc": 48.0}
{"epoch": 15, "training_loss": 0.6938348889350892, "training_acc": 60.0, "val_loss": 0.7786141562461854, "val_acc": 52.0}
{"epoch": 16, "training_loss": 0.7667077875137329, "training_acc": 50.0, "val_loss": 0.6949018883705139, "val_acc": 48.0}
{"epoch": 17, "training_loss": 0.7213689184188843, "training_acc": 44.0, "val_loss": 0.7123436379432678, "val_acc": 52.0}
{"epoch": 18, "training_loss": 0.7050176954269409, "training_acc": 52.0, "val_loss": 0.8696772527694702, "val_acc": 48.0}
{"epoch": 19, "training_loss": 0.7597597455978393, "training_acc": 44.0, "val_loss": 0.7081036353111267, "val_acc": 48.0}
{"epoch": 20, "training_loss": 0.7355214738845826, "training_acc": 54.0, "val_loss": 0.6969045352935791, "val_acc": 48.0}
{"epoch": 21, "training_loss": 0.7224348163604737, "training_acc": 44.0, "val_loss": 0.7343411636352539, "val_acc": 48.0}
{"epoch": 22, "training_loss": 0.7373196411132813, "training_acc": 44.0, "val_loss": 0.7096395707130432, "val_acc": 52.0}
{"epoch": 23, "training_loss": 0.7261815404891968, "training_acc": 40.0, "val_loss": 0.6925626492500305, "val_acc": 52.0}
{"epoch": 24, "training_loss": 0.7250854778289795, "training_acc": 52.0, "val_loss": 0.8545817613601685, "val_acc": 48.0}
{"epoch": 25, "training_loss": 0.7871888399124145, "training_acc": 50.0, "val_loss": 0.695831573009491, "val_acc": 52.0}
{"epoch": 26, "training_loss": 0.7267489671707154, "training_acc": 50.0, "val_loss": 0.8003617954254151, "val_acc": 48.0}
{"epoch": 27, "training_loss": 0.7265055084228516, "training_acc": 54.0, "val_loss": 0.7994293713569641, "val_acc": 52.0}
{"epoch": 28, "training_loss": 0.8683713293075561, "training_acc": 46.0, "val_loss": 0.8898427963256836, "val_acc": 48.0}
{"epoch": 29, "training_loss": 0.8259993076324463, "training_acc": 52.0, "val_loss": 0.9052539873123169, "val_acc": 52.0}
{"epoch": 30, "training_loss": 0.865581967830658, "training_acc": 46.0, "val_loss": 0.733143241405487, "val_acc": 48.0}
{"epoch": 31, "training_loss": 0.705896430015564, "training_acc": 52.0, "val_loss": 0.7031688809394836, "val_acc": 52.0}
{"epoch": 32, "training_loss": 0.7034735441207886, "training_acc": 50.0, "val_loss": 0.7293616557121276, "val_acc": 48.0}
{"epoch": 33, "training_loss": 0.7355697441101074, "training_acc": 46.0, "val_loss": 0.6928461980819702, "val_acc": 52.0}
{"epoch": 34, "training_loss": 0.7312635803222656, "training_acc": 52.0, "val_loss": 0.6964861750602722, "val_acc": 52.0}
{"epoch": 35, "training_loss": 0.7173369455337525, "training_acc": 48.0, "val_loss": 0.6924608039855957, "val_acc": 52.0}
{"epoch": 36, "training_loss": 0.7037419128417969, "training_acc": 44.0, "val_loss": 0.7073508167266845, "val_acc": 52.0}
{"epoch": 37, "training_loss": 0.735881233215332, "training_acc": 50.0, "val_loss": 0.715576844215393, "val_acc": 48.0}
{"epoch": 38, "training_loss": 0.7114699125289917, "training_acc": 50.0, "val_loss": 0.6948859000205994, "val_acc": 52.0}
{"epoch": 39, "training_loss": 0.6981033277511597, "training_acc": 48.0, "val_loss": 0.6923623728752136, "val_acc": 52.0}
{"epoch": 40, "training_loss": 0.7093257999420166, "training_acc": 48.0, "val_loss": 0.6984910464286804, "val_acc": 52.0}
{"epoch": 41, "training_loss": 0.7107508611679078, "training_acc": 50.0, "val_loss": 0.7281893491744995, "val_acc": 48.0}
{"epoch": 42, "training_loss": 0.7270562815666198, "training_acc": 44.0, "val_loss": 0.6923746585845947, "val_acc": 52.0}
{"epoch": 43, "training_loss": 0.710085210800171, "training_acc": 42.0, "val_loss": 0.7014581179618835, "val_acc": 48.0}
{"epoch": 44, "training_loss": 0.7082216453552246, "training_acc": 46.0, "val_loss": 0.7107062840461731, "val_acc": 48.0}
{"epoch": 45, "training_loss": 0.720107593536377, "training_acc": 50.0, "val_loss": 0.7255639004707336, "val_acc": 52.0}
{"epoch": 46, "training_loss": 0.7933313870429992, "training_acc": 52.0, "val_loss": 0.7660698938369751, "val_acc": 48.0}
{"epoch": 47, "training_loss": 0.7579415988922119, "training_acc": 50.0, "val_loss": 0.6960148334503173, "val_acc": 52.0}
{"epoch": 48, "training_loss": 0.707287609577179, "training_acc": 50.0, "val_loss": 0.6924489784240723, "val_acc": 52.0}
{"epoch": 49, "training_loss": 0.7347858667373657, "training_acc": 40.0, "val_loss": 0.6931520748138428, "val_acc": 52.0}
{"epoch": 50, "training_loss": 0.7061598753929138, "training_acc": 52.0, "val_loss": 0.6999460339546204, "val_acc": 48.0}
{"epoch": 51, "training_loss": 0.7012625932693481, "training_acc": 46.0, "val_loss": 0.6938068747520447, "val_acc": 48.0}
{"epoch": 52, "training_loss": 0.7123591375350952, "training_acc": 48.0, "val_loss": 0.6940449690818786, "val_acc": 48.0}
{"epoch": 53, "training_loss": 0.7044490432739258, "training_acc": 44.0, "val_loss": 0.6977789974212647, "val_acc": 52.0}
{"epoch": 54, "training_loss": 0.7200343608856201, "training_acc": 48.0, "val_loss": 0.764016695022583, "val_acc": 48.0}
{"epoch": 55, "training_loss": 0.7822892951965332, "training_acc": 36.0, "val_loss": 0.741919424533844, "val_acc": 48.0}
{"epoch": 56, "training_loss": 0.7239956879615783, "training_acc": 50.0, "val_loss": 0.6924378204345704, "val_acc": 52.0}
{"epoch": 57, "training_loss": 0.7098995685577393, "training_acc": 46.0, "val_loss": 0.6928100943565368, "val_acc": 52.0}
{"epoch": 58, "training_loss": 0.7149579119682312, "training_acc": 40.0, "val_loss": 0.6961440229415894, "val_acc": 52.0}
