"main_modify.py --pretrained_path /scratch/connectome/dyhan316/VAE_ADHD/barlowtwins/pretrain_results/ABCDbt128a102.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 1 --task ADNI_sex --input_option BT_org --learning_rate 1e-2 --batch_size 16 --weight_decay 1e-2 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 1.2448631620407105, "training_acc": 45.0, "val_loss": 1.0095390272140503, "val_acc": 48.0}
{"epoch": 1, "training_loss": 0.8309333181381225, "training_acc": 49.0, "val_loss": 0.8095312714576721, "val_acc": 48.0}
{"epoch": 2, "training_loss": 0.7621409130096436, "training_acc": 49.0, "val_loss": 0.7489600706100464, "val_acc": 48.0}
{"epoch": 3, "training_loss": 0.7096969294548034, "training_acc": 51.0, "val_loss": 0.7028387475013733, "val_acc": 52.0}
{"epoch": 4, "training_loss": 0.6915748584270477, "training_acc": 53.0, "val_loss": 1.097159776687622, "val_acc": 48.0}
{"epoch": 5, "training_loss": 0.8316595613956451, "training_acc": 53.0, "val_loss": 1.0537979793548584, "val_acc": 52.0}
{"epoch": 6, "training_loss": 0.9154744720458985, "training_acc": 43.0, "val_loss": 0.6993293356895447, "val_acc": 48.0}
{"epoch": 7, "training_loss": 0.7153484582901001, "training_acc": 45.0, "val_loss": 0.746855971813202, "val_acc": 52.0}
{"epoch": 8, "training_loss": 0.7679957103729248, "training_acc": 45.0, "val_loss": 0.712909505367279, "val_acc": 48.0}
{"epoch": 9, "training_loss": 0.7244231367111206, "training_acc": 51.0, "val_loss": 0.7446640396118164, "val_acc": 52.0}
{"epoch": 10, "training_loss": 0.7196453499794007, "training_acc": 43.0, "val_loss": 0.7677709412574768, "val_acc": 48.0}
{"epoch": 11, "training_loss": 0.723878664970398, "training_acc": 45.0, "val_loss": 0.6942903995513916, "val_acc": 48.0}
{"epoch": 12, "training_loss": 0.739321494102478, "training_acc": 47.0, "val_loss": 0.7949312996864318, "val_acc": 48.0}
{"epoch": 13, "training_loss": 0.8596869707107544, "training_acc": 53.0, "val_loss": 0.8963399696350097, "val_acc": 52.0}
{"epoch": 14, "training_loss": 0.7746425843238831, "training_acc": 51.0, "val_loss": 0.6923509526252747, "val_acc": 52.0}
{"epoch": 15, "training_loss": 0.7084019088745117, "training_acc": 49.0, "val_loss": 0.8005536580085755, "val_acc": 48.0}
{"epoch": 16, "training_loss": 0.7456688976287842, "training_acc": 47.0, "val_loss": 0.6966977763175964, "val_acc": 48.0}
{"epoch": 17, "training_loss": 0.7004434800148011, "training_acc": 53.0, "val_loss": 0.8689777612686157, "val_acc": 52.0}
{"epoch": 18, "training_loss": 0.8417702960968018, "training_acc": 45.0, "val_loss": 0.7346204853057862, "val_acc": 48.0}
{"epoch": 19, "training_loss": 0.7435597324371338, "training_acc": 39.0, "val_loss": 0.6954197192192078, "val_acc": 52.0}
{"epoch": 20, "training_loss": 0.7485577249526978, "training_acc": 47.0, "val_loss": 0.7028873443603516, "val_acc": 52.0}
{"epoch": 21, "training_loss": 0.74756751537323, "training_acc": 47.0, "val_loss": 0.7662373328208923, "val_acc": 48.0}
{"epoch": 22, "training_loss": 0.734232931137085, "training_acc": 51.0, "val_loss": 0.7280304431915283, "val_acc": 52.0}
{"epoch": 23, "training_loss": 0.7201795315742493, "training_acc": 57.0, "val_loss": 0.7578692626953125, "val_acc": 48.0}
{"epoch": 24, "training_loss": 0.7033366584777831, "training_acc": 51.0, "val_loss": 0.6948221945762634, "val_acc": 48.0}
{"epoch": 25, "training_loss": 0.7001229429244995, "training_acc": 47.0, "val_loss": 0.6985008907318115, "val_acc": 48.0}
{"epoch": 26, "training_loss": 0.7084009838104248, "training_acc": 49.0, "val_loss": 0.6981269383430481, "val_acc": 48.0}
{"epoch": 27, "training_loss": 0.7199677133560181, "training_acc": 43.0, "val_loss": 0.7053626036643982, "val_acc": 48.0}
{"epoch": 28, "training_loss": 0.7012027740478516, "training_acc": 51.0, "val_loss": 0.6935882663726807, "val_acc": 48.0}
{"epoch": 29, "training_loss": 0.7139845418930054, "training_acc": 41.0, "val_loss": 0.6963271236419678, "val_acc": 52.0}
{"epoch": 30, "training_loss": 0.7206907463073731, "training_acc": 49.0, "val_loss": 0.7138508248329163, "val_acc": 48.0}
{"epoch": 31, "training_loss": 0.7345061063766479, "training_acc": 41.0, "val_loss": 0.6939718651771546, "val_acc": 52.0}
{"epoch": 32, "training_loss": 0.7031749105453491, "training_acc": 43.0, "val_loss": 0.720502164363861, "val_acc": 48.0}
{"epoch": 33, "training_loss": 0.7257322788238525, "training_acc": 49.0, "val_loss": 0.6937672376632691, "val_acc": 48.0}
