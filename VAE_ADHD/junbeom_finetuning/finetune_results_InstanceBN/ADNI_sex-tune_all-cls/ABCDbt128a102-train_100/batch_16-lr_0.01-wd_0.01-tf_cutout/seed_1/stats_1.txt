"main_modify.py --pretrained_path /scratch/connectome/dyhan316/VAE_ADHD/barlowtwins/pretrain_results/ABCDbt128a102.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 1 --task ADNI_sex --input_option BT_org --learning_rate 1e-2 --batch_size 16 --weight_decay 1e-2 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 1.30751136302948, "training_acc": 48.0, "val_loss": 0.7315933156013489, "val_acc": 48.0}
{"epoch": 1, "training_loss": 0.7006238293647766, "training_acc": 54.0, "val_loss": 0.7024298644065857, "val_acc": 48.0}
{"epoch": 2, "training_loss": 0.7032427668571473, "training_acc": 48.0, "val_loss": 0.7338196659088134, "val_acc": 52.0}
{"epoch": 3, "training_loss": 0.7527767539024353, "training_acc": 48.0, "val_loss": 0.6953678154945373, "val_acc": 48.0}
{"epoch": 4, "training_loss": 0.7699876499176025, "training_acc": 42.0, "val_loss": 0.6960625052452087, "val_acc": 52.0}
{"epoch": 5, "training_loss": 0.74333815574646, "training_acc": 50.0, "val_loss": 0.9146225929260254, "val_acc": 48.0}
{"epoch": 6, "training_loss": 0.7444296550750732, "training_acc": 58.0, "val_loss": 0.7461927986145019, "val_acc": 52.0}
{"epoch": 7, "training_loss": 0.7138325834274292, "training_acc": 54.0, "val_loss": 0.7068240356445312, "val_acc": 48.0}
{"epoch": 8, "training_loss": 0.8066492128372192, "training_acc": 46.0, "val_loss": 0.8722743582725525, "val_acc": 48.0}
{"epoch": 9, "training_loss": 0.7677499389648438, "training_acc": 44.0, "val_loss": 0.7137725806236267, "val_acc": 52.0}
{"epoch": 10, "training_loss": 0.7113838076591492, "training_acc": 52.0, "val_loss": 0.7951091074943543, "val_acc": 48.0}
{"epoch": 11, "training_loss": 0.7548359441757202, "training_acc": 52.0, "val_loss": 0.8138838648796082, "val_acc": 52.0}
{"epoch": 12, "training_loss": 0.7225757694244385, "training_acc": 56.0, "val_loss": 0.8706666254997253, "val_acc": 48.0}
{"epoch": 13, "training_loss": 0.7790962123870849, "training_acc": 44.0, "val_loss": 0.7476699090003968, "val_acc": 48.0}
{"epoch": 14, "training_loss": 0.7845008683204651, "training_acc": 46.0, "val_loss": 0.7707810711860656, "val_acc": 48.0}
{"epoch": 15, "training_loss": 0.8686409378051758, "training_acc": 46.0, "val_loss": 0.693717315196991, "val_acc": 48.0}
{"epoch": 16, "training_loss": 0.734103319644928, "training_acc": 46.0, "val_loss": 0.7134826874732971, "val_acc": 52.0}
{"epoch": 17, "training_loss": 0.7703540134429931, "training_acc": 50.0, "val_loss": 0.7449358010292053, "val_acc": 48.0}
{"epoch": 18, "training_loss": 0.7921831583976746, "training_acc": 44.0, "val_loss": 0.836391636133194, "val_acc": 48.0}
{"epoch": 19, "training_loss": 0.7482323503494263, "training_acc": 48.0, "val_loss": 0.6937046432495118, "val_acc": 48.0}
{"epoch": 20, "training_loss": 0.7064228010177612, "training_acc": 48.0, "val_loss": 0.7384291887283325, "val_acc": 48.0}
{"epoch": 21, "training_loss": 0.7203731393814087, "training_acc": 54.0, "val_loss": 0.7906043648719787, "val_acc": 48.0}
{"epoch": 22, "training_loss": 0.749933409690857, "training_acc": 52.0, "val_loss": 0.7103736138343811, "val_acc": 52.0}
{"epoch": 23, "training_loss": 0.7237195587158203, "training_acc": 44.0, "val_loss": 0.7165430688858032, "val_acc": 52.0}
{"epoch": 24, "training_loss": 0.7250087976455688, "training_acc": 46.0, "val_loss": 0.7003920769691467, "val_acc": 48.0}
{"epoch": 25, "training_loss": 0.7043655395507813, "training_acc": 48.0, "val_loss": 0.7009210300445556, "val_acc": 48.0}
{"epoch": 26, "training_loss": 0.7031073188781738, "training_acc": 50.0, "val_loss": 0.7225233173370361, "val_acc": 48.0}
{"epoch": 27, "training_loss": 0.7222329068183899, "training_acc": 50.0, "val_loss": 0.6926525902748107, "val_acc": 52.0}
{"epoch": 28, "training_loss": 0.7009732007980347, "training_acc": 44.0, "val_loss": 0.7007760429382324, "val_acc": 48.0}
{"epoch": 29, "training_loss": 0.7072621393203735, "training_acc": 50.0, "val_loss": 0.6981979322433471, "val_acc": 52.0}
{"epoch": 30, "training_loss": 0.7352865076065064, "training_acc": 42.0, "val_loss": 0.7107486343383789, "val_acc": 48.0}
{"epoch": 31, "training_loss": 0.7075794577598572, "training_acc": 50.0, "val_loss": 0.7011949276924133, "val_acc": 52.0}
{"epoch": 32, "training_loss": 0.7492277097702026, "training_acc": 48.0, "val_loss": 0.6991812872886658, "val_acc": 48.0}
{"epoch": 33, "training_loss": 0.702209186553955, "training_acc": 50.0, "val_loss": 0.6940371751785278, "val_acc": 48.0}
{"epoch": 34, "training_loss": 0.7087226319313049, "training_acc": 50.0, "val_loss": 0.6944393658638001, "val_acc": 52.0}
{"epoch": 35, "training_loss": 0.7004132604598999, "training_acc": 48.0, "val_loss": 0.6925434327125549, "val_acc": 52.0}
{"epoch": 36, "training_loss": 0.7131231927871704, "training_acc": 46.0, "val_loss": 0.6941687083244323, "val_acc": 48.0}
{"epoch": 37, "training_loss": 0.713847451210022, "training_acc": 44.0, "val_loss": 0.7667550802230835, "val_acc": 48.0}
{"epoch": 38, "training_loss": 0.7475182723999023, "training_acc": 50.0, "val_loss": 0.7136089849472046, "val_acc": 52.0}
{"epoch": 39, "training_loss": 0.7127659106254578, "training_acc": 52.0, "val_loss": 0.790818874835968, "val_acc": 48.0}
{"epoch": 40, "training_loss": 0.7308169984817505, "training_acc": 50.0, "val_loss": 0.7014552998542786, "val_acc": 52.0}
{"epoch": 41, "training_loss": 0.7578179311752319, "training_acc": 50.0, "val_loss": 0.7011070585250855, "val_acc": 48.0}
{"epoch": 42, "training_loss": 0.724731936454773, "training_acc": 50.0, "val_loss": 0.6946033215522767, "val_acc": 52.0}
{"epoch": 43, "training_loss": 0.7254426765441895, "training_acc": 50.0, "val_loss": 0.7014797568321228, "val_acc": 48.0}
{"epoch": 44, "training_loss": 0.7113957238197327, "training_acc": 46.0, "val_loss": 0.7030731654167175, "val_acc": 48.0}
{"epoch": 45, "training_loss": 0.7009730911254883, "training_acc": 52.0, "val_loss": 0.7105997824668884, "val_acc": 52.0}
{"epoch": 46, "training_loss": 0.7409226393699646, "training_acc": 46.0, "val_loss": 0.797406005859375, "val_acc": 48.0}
{"epoch": 47, "training_loss": 0.7460109567642212, "training_acc": 48.0, "val_loss": 0.6938816547393799, "val_acc": 52.0}
{"epoch": 48, "training_loss": 0.7110033464431763, "training_acc": 52.0, "val_loss": 0.6928394055366516, "val_acc": 52.0}
{"epoch": 49, "training_loss": 0.7072200274467468, "training_acc": 52.0, "val_loss": 0.7503337454795838, "val_acc": 48.0}
{"epoch": 50, "training_loss": 0.736821448802948, "training_acc": 50.0, "val_loss": 0.7638237571716309, "val_acc": 52.0}
{"epoch": 51, "training_loss": 0.85085125207901, "training_acc": 42.0, "val_loss": 0.7142808914184571, "val_acc": 48.0}
{"epoch": 52, "training_loss": 0.7698334693908692, "training_acc": 42.0, "val_loss": 0.7994481444358825, "val_acc": 48.0}
{"epoch": 53, "training_loss": 0.7605314016342163, "training_acc": 52.0, "val_loss": 0.7884652733802795, "val_acc": 52.0}
{"epoch": 54, "training_loss": 0.7935541701316834, "training_acc": 42.0, "val_loss": 0.692363657951355, "val_acc": 52.0}
{"epoch": 55, "training_loss": 0.6990501594543457, "training_acc": 44.0, "val_loss": 0.6971833086013794, "val_acc": 48.0}
{"epoch": 56, "training_loss": 0.7053716540336609, "training_acc": 44.0, "val_loss": 0.7345027613639832, "val_acc": 48.0}
{"epoch": 57, "training_loss": 0.7500752639770508, "training_acc": 42.0, "val_loss": 0.7195963358879089, "val_acc": 52.0}
{"epoch": 58, "training_loss": 0.7487551712989807, "training_acc": 46.0, "val_loss": 0.6965076231956482, "val_acc": 48.0}
{"epoch": 59, "training_loss": 0.7225594139099121, "training_acc": 46.0, "val_loss": 0.7055162882804871, "val_acc": 48.0}
{"epoch": 60, "training_loss": 0.7254744815826416, "training_acc": 46.0, "val_loss": 0.6925202870368957, "val_acc": 52.0}
{"epoch": 61, "training_loss": 0.737381272315979, "training_acc": 50.0, "val_loss": 0.7010925602912903, "val_acc": 52.0}
{"epoch": 62, "training_loss": 0.7262534523010253, "training_acc": 50.0, "val_loss": 0.6977798104286194, "val_acc": 48.0}
{"epoch": 63, "training_loss": 0.7240064835548401, "training_acc": 50.0, "val_loss": 0.7002924776077271, "val_acc": 52.0}
{"epoch": 64, "training_loss": 0.7125400495529175, "training_acc": 52.0, "val_loss": 0.8344866013526917, "val_acc": 48.0}
{"epoch": 65, "training_loss": 0.7708274412155152, "training_acc": 50.0, "val_loss": 0.6928024435043335, "val_acc": 52.0}
{"epoch": 66, "training_loss": 0.7022384262084961, "training_acc": 50.0, "val_loss": 0.7305460476875305, "val_acc": 48.0}
{"epoch": 67, "training_loss": 0.7709752035140991, "training_acc": 40.0, "val_loss": 0.6926171541213989, "val_acc": 52.0}
{"epoch": 68, "training_loss": 0.7088752269744873, "training_acc": 46.0, "val_loss": 0.6945151329040528, "val_acc": 52.0}
{"epoch": 69, "training_loss": 0.7292217874526977, "training_acc": 38.0, "val_loss": 0.6988559627532959, "val_acc": 52.0}
{"epoch": 70, "training_loss": 0.7636068320274353, "training_acc": 44.0, "val_loss": 0.7105627369880676, "val_acc": 48.0}
{"epoch": 71, "training_loss": 0.7175742769241333, "training_acc": 46.0, "val_loss": 0.6970912957191467, "val_acc": 48.0}
{"epoch": 72, "training_loss": 0.7053839111328125, "training_acc": 46.0, "val_loss": 0.7044361233711243, "val_acc": 48.0}
{"epoch": 73, "training_loss": 0.7216406869888305, "training_acc": 36.0, "val_loss": 0.6942041873931885, "val_acc": 52.0}
