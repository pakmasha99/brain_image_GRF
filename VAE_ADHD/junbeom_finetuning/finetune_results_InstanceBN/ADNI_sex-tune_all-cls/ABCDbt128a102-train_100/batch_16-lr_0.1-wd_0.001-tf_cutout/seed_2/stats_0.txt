"main_modify.py --pretrained_path /scratch/connectome/dyhan316/VAE_ADHD/barlowtwins/pretrain_results/ABCDbt128a102.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 2 --task ADNI_sex --input_option BT_org --learning_rate 1e-1 --batch_size 16 --weight_decay 1e-3 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 12.028420696258545, "training_acc": 46.0, "val_loss": 7.471423397064209, "val_acc": 48.0}
{"epoch": 1, "training_loss": 3.630931844711304, "training_acc": 60.0, "val_loss": 2.107165379524231, "val_acc": 48.0}
{"epoch": 2, "training_loss": 2.67877742767334, "training_acc": 58.0, "val_loss": 1.1396906423568725, "val_acc": 48.0}
{"epoch": 3, "training_loss": 2.585999653339386, "training_acc": 52.0, "val_loss": 0.8638081216812133, "val_acc": 52.0}
{"epoch": 4, "training_loss": 0.8568686890602112, "training_acc": 56.0, "val_loss": 0.6932523369789123, "val_acc": 44.0}
{"epoch": 5, "training_loss": 1.0018955230712892, "training_acc": 53.0, "val_loss": 3.634170722961426, "val_acc": 52.0}
{"epoch": 6, "training_loss": 1.48667537689209, "training_acc": 48.0, "val_loss": 2.1851244306564332, "val_acc": 52.0}
{"epoch": 7, "training_loss": 2.0820010185241697, "training_acc": 44.0, "val_loss": 1.225131402015686, "val_acc": 48.0}
{"epoch": 8, "training_loss": 1.2506813287734986, "training_acc": 48.0, "val_loss": 0.7414255499839782, "val_acc": 48.0}
{"epoch": 9, "training_loss": 0.8023399114608765, "training_acc": 48.0, "val_loss": 0.761110315322876, "val_acc": 48.0}
{"epoch": 10, "training_loss": 0.9567948484420776, "training_acc": 49.0, "val_loss": 1.6460745000839234, "val_acc": 52.0}
{"epoch": 11, "training_loss": 1.5395127177238463, "training_acc": 46.0, "val_loss": 1.1738093662261964, "val_acc": 48.0}
{"epoch": 12, "training_loss": 1.4081276082992553, "training_acc": 52.0, "val_loss": 4.282978057861328, "val_acc": 52.0}
{"epoch": 13, "training_loss": 3.6127486991882325, "training_acc": 52.0, "val_loss": 1.1067425966262818, "val_acc": 52.0}
{"epoch": 14, "training_loss": 1.83871395111084, "training_acc": 56.0, "val_loss": 0.6904687094688415, "val_acc": 52.0}
{"epoch": 15, "training_loss": 0.8596754455566407, "training_acc": 54.0, "val_loss": 0.6891239476203919, "val_acc": 48.0}
{"epoch": 16, "training_loss": 0.8182566666603088, "training_acc": 46.0, "val_loss": 0.6798737072944641, "val_acc": 56.0}
{"epoch": 17, "training_loss": 0.7946862316131592, "training_acc": 57.0, "val_loss": 0.7626134872436523, "val_acc": 48.0}
{"epoch": 18, "training_loss": 0.8235463619232177, "training_acc": 54.0, "val_loss": 0.9632560682296752, "val_acc": 48.0}
{"epoch": 19, "training_loss": 0.9267736673355103, "training_acc": 48.0, "val_loss": 1.0908207678794861, "val_acc": 48.0}
{"epoch": 20, "training_loss": 1.85577712059021, "training_acc": 52.0, "val_loss": 4.038795795440674, "val_acc": 52.0}
{"epoch": 21, "training_loss": 4.588862247467041, "training_acc": 46.0, "val_loss": 0.7420861101150513, "val_acc": 52.0}
{"epoch": 22, "training_loss": 2.1216735458374023, "training_acc": 58.0, "val_loss": 1.0071089196205139, "val_acc": 48.0}
{"epoch": 23, "training_loss": 1.9106507205963135, "training_acc": 46.0, "val_loss": 1.3448010444641114, "val_acc": 52.0}
{"epoch": 24, "training_loss": 1.831812219619751, "training_acc": 48.0, "val_loss": 1.5170020437240601, "val_acc": 48.0}
{"epoch": 25, "training_loss": 2.4171363377571105, "training_acc": 48.0, "val_loss": 3.026597490310669, "val_acc": 48.0}
{"epoch": 26, "training_loss": 1.7897203612327575, "training_acc": 54.0, "val_loss": 2.516091814041138, "val_acc": 48.0}
{"epoch": 27, "training_loss": 2.2086350250244142, "training_acc": 48.0, "val_loss": 1.3337309885025024, "val_acc": 48.0}
{"epoch": 28, "training_loss": 0.8587976503372192, "training_acc": 52.0, "val_loss": 0.7917247438430786, "val_acc": 44.0}
{"epoch": 29, "training_loss": 0.7451519298553467, "training_acc": 47.0, "val_loss": 1.4940646767616272, "val_acc": 48.0}
{"epoch": 30, "training_loss": 0.9141935539245606, "training_acc": 50.0, "val_loss": 0.7731442975997925, "val_acc": 52.0}
{"epoch": 31, "training_loss": 0.7794588613510132, "training_acc": 50.0, "val_loss": 0.7051194643974305, "val_acc": 48.0}
{"epoch": 32, "training_loss": 0.8825477123260498, "training_acc": 47.0, "val_loss": 1.0828841495513917, "val_acc": 48.0}
{"epoch": 33, "training_loss": 1.1988283443450927, "training_acc": 46.0, "val_loss": 2.039461908340454, "val_acc": 48.0}
{"epoch": 34, "training_loss": 1.5046567153930663, "training_acc": 46.0, "val_loss": 0.807666118144989, "val_acc": 48.0}
{"epoch": 35, "training_loss": 0.9093356394767761, "training_acc": 44.0, "val_loss": 0.8907651233673096, "val_acc": 52.0}
