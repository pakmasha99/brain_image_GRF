"main_modify.py --pretrained_path /scratch/connectome/dyhan316/VAE_ADHD/barlowtwins/pretrain_results/ABCDbt128a102.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 2 --task ADNI_sex --input_option BT_org --learning_rate 1e-1 --batch_size 16 --weight_decay 1e-3 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 6.917583560943603, "training_acc": 54.0, "val_loss": 9.340801448822022, "val_acc": 52.0}
{"epoch": 1, "training_loss": 6.4899843883514405, "training_acc": 45.0, "val_loss": 2.0844799995422365, "val_acc": 52.0}
{"epoch": 2, "training_loss": 2.3065014934539794, "training_acc": 46.0, "val_loss": 0.9596671104431153, "val_acc": 48.0}
{"epoch": 3, "training_loss": 1.0848280262947083, "training_acc": 46.0, "val_loss": 0.7806861090660095, "val_acc": 52.0}
{"epoch": 4, "training_loss": 1.188933334350586, "training_acc": 42.0, "val_loss": 0.9866752624511719, "val_acc": 52.0}
{"epoch": 5, "training_loss": 0.8980448818206788, "training_acc": 40.0, "val_loss": 2.0717837762832643, "val_acc": 48.0}
{"epoch": 6, "training_loss": 2.656508650779724, "training_acc": 54.0, "val_loss": 3.34194130897522, "val_acc": 48.0}
{"epoch": 7, "training_loss": 2.9128832912445066, "training_acc": 42.0, "val_loss": 3.6680947303771974, "val_acc": 48.0}
{"epoch": 8, "training_loss": 2.231417326927185, "training_acc": 50.0, "val_loss": 1.414505181312561, "val_acc": 52.0}
{"epoch": 9, "training_loss": 1.1174044346809386, "training_acc": 46.0, "val_loss": 1.8618853855133057, "val_acc": 48.0}
{"epoch": 10, "training_loss": 1.432875289916992, "training_acc": 44.0, "val_loss": 0.9610928344726563, "val_acc": 52.0}
{"epoch": 11, "training_loss": 1.064676742553711, "training_acc": 50.0, "val_loss": 2.1690049600601196, "val_acc": 52.0}
{"epoch": 12, "training_loss": 1.153131275177002, "training_acc": 52.0, "val_loss": 1.3697182607650757, "val_acc": 52.0}
{"epoch": 13, "training_loss": 1.0801405596733094, "training_acc": 48.0, "val_loss": 1.12194575548172, "val_acc": 52.0}
{"epoch": 14, "training_loss": 0.9305270338058471, "training_acc": 50.0, "val_loss": 0.8343167734146119, "val_acc": 48.0}
{"epoch": 15, "training_loss": 1.4909121704101562, "training_acc": 44.0, "val_loss": 2.672772512435913, "val_acc": 48.0}
{"epoch": 16, "training_loss": 3.034566116333008, "training_acc": 42.0, "val_loss": 3.2953106117248536, "val_acc": 48.0}
{"epoch": 17, "training_loss": 2.518725233078003, "training_acc": 50.0, "val_loss": 3.432875509262085, "val_acc": 48.0}
{"epoch": 18, "training_loss": 2.186280107498169, "training_acc": 52.0, "val_loss": 0.7228777098655701, "val_acc": 52.0}
{"epoch": 19, "training_loss": 0.8428832244873047, "training_acc": 56.0, "val_loss": 3.0000031757354737, "val_acc": 48.0}
{"epoch": 20, "training_loss": 1.5552259993553161, "training_acc": 50.0, "val_loss": 0.6998736333847045, "val_acc": 52.0}
{"epoch": 21, "training_loss": 1.5128494834899902, "training_acc": 44.0, "val_loss": 2.5437779378890992, "val_acc": 52.0}
{"epoch": 22, "training_loss": 2.1147092962265015, "training_acc": 54.0, "val_loss": 3.8308404445648194, "val_acc": 52.0}
{"epoch": 23, "training_loss": 2.6898846673965453, "training_acc": 50.0, "val_loss": 2.9219377994537354, "val_acc": 52.0}
{"epoch": 24, "training_loss": 1.4799120950698852, "training_acc": 56.0, "val_loss": 0.7525351357460022, "val_acc": 52.0}
{"epoch": 25, "training_loss": 1.3630217123031616, "training_acc": 46.0, "val_loss": 1.0896435976028442, "val_acc": 52.0}
{"epoch": 26, "training_loss": 0.8602778983116149, "training_acc": 54.0, "val_loss": 1.1341298866271972, "val_acc": 48.0}
{"epoch": 27, "training_loss": 0.8776794981956482, "training_acc": 49.0, "val_loss": 1.6012781381607055, "val_acc": 48.0}
{"epoch": 28, "training_loss": 1.0234883689880372, "training_acc": 54.0, "val_loss": 1.5008568143844605, "val_acc": 48.0}
{"epoch": 29, "training_loss": 0.8523611402511597, "training_acc": 56.0, "val_loss": 1.1525153636932373, "val_acc": 48.0}
{"epoch": 30, "training_loss": 2.226044244766235, "training_acc": 40.0, "val_loss": 2.6443130493164064, "val_acc": 52.0}
{"epoch": 31, "training_loss": 1.3319569683074952, "training_acc": 50.0, "val_loss": 1.6725415515899658, "val_acc": 48.0}
{"epoch": 32, "training_loss": 0.9923380899429322, "training_acc": 54.0, "val_loss": 0.6925775861740112, "val_acc": 48.0}
{"epoch": 33, "training_loss": 0.8876996707916259, "training_acc": 48.0, "val_loss": 1.5837572145462036, "val_acc": 52.0}
{"epoch": 34, "training_loss": 1.4705247116088866, "training_acc": 54.0, "val_loss": 2.5515965175628663, "val_acc": 48.0}
{"epoch": 35, "training_loss": 1.6853269910812378, "training_acc": 44.0, "val_loss": 0.8093952679634094, "val_acc": 48.0}
{"epoch": 36, "training_loss": 0.76271728515625, "training_acc": 50.0, "val_loss": 0.6870930123329163, "val_acc": 52.0}
{"epoch": 37, "training_loss": 1.0257095885276795, "training_acc": 42.0, "val_loss": 0.6862189531326294, "val_acc": 52.0}
{"epoch": 38, "training_loss": 0.8280707788467407, "training_acc": 57.0, "val_loss": 3.680251989364624, "val_acc": 52.0}
{"epoch": 39, "training_loss": 3.2934008598327638, "training_acc": 50.0, "val_loss": 3.874692859649658, "val_acc": 52.0}
{"epoch": 40, "training_loss": 2.839327595233917, "training_acc": 58.0, "val_loss": 2.330798740386963, "val_acc": 52.0}
{"epoch": 41, "training_loss": 2.5052954006195067, "training_acc": 52.0, "val_loss": 1.35598069190979, "val_acc": 52.0}
{"epoch": 42, "training_loss": 1.0455026531219482, "training_acc": 45.0, "val_loss": 1.7284918117523194, "val_acc": 48.0}
{"epoch": 43, "training_loss": 1.9735494136810303, "training_acc": 46.0, "val_loss": 3.737989110946655, "val_acc": 52.0}
{"epoch": 44, "training_loss": 4.1901728057861325, "training_acc": 52.0, "val_loss": 1.5176868057250976, "val_acc": 48.0}
{"epoch": 45, "training_loss": 4.167236242294312, "training_acc": 50.0, "val_loss": 2.7284427070617676, "val_acc": 48.0}
{"epoch": 46, "training_loss": 2.2995749282836915, "training_acc": 51.0, "val_loss": 0.9802387619018554, "val_acc": 48.0}
{"epoch": 47, "training_loss": 2.9461475801467896, "training_acc": 44.0, "val_loss": 0.7082296776771545, "val_acc": 52.0}
{"epoch": 48, "training_loss": 1.0353529977798461, "training_acc": 48.0, "val_loss": 1.201138870716095, "val_acc": 48.0}
{"epoch": 49, "training_loss": 1.2005105781555176, "training_acc": 47.0, "val_loss": 1.9740866088867188, "val_acc": 52.0}
{"epoch": 50, "training_loss": 1.6879627466201783, "training_acc": 46.0, "val_loss": 0.7855595350265503, "val_acc": 48.0}
{"epoch": 51, "training_loss": 0.7061030396446586, "training_acc": 52.0, "val_loss": 3.9073223304748534, "val_acc": 48.0}
{"epoch": 52, "training_loss": 3.788872494697571, "training_acc": 54.0, "val_loss": 6.923882789611817, "val_acc": 48.0}
{"epoch": 53, "training_loss": 4.870068162487005, "training_acc": 56.0, "val_loss": 6.01397476196289, "val_acc": 52.0}
{"epoch": 54, "training_loss": 3.0368237590789793, "training_acc": 46.0, "val_loss": 1.141660406589508, "val_acc": 48.0}
{"epoch": 55, "training_loss": 1.6754478931427002, "training_acc": 39.0, "val_loss": 0.7558611989021301, "val_acc": 52.0}
{"epoch": 56, "training_loss": 1.1577680969238282, "training_acc": 46.0, "val_loss": 0.7285468578338623, "val_acc": 52.0}
