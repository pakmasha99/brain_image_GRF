"main_modify.py --pretrained_path /scratch/connectome/dyhan316/VAE_ADHD/barlowtwins/pretrain_results/ABCDbt128a102.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 2 --task ADNI_sex --input_option BT_org --learning_rate 1e-1 --batch_size 16 --weight_decay 1e-3 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 10.168844366073609, "training_acc": 46.0, "val_loss": 1.8476832437515258, "val_acc": 48.0}
{"epoch": 1, "training_loss": 9.298474159240723, "training_acc": 46.0, "val_loss": 4.782506790161133, "val_acc": 48.0}
{"epoch": 2, "training_loss": 7.519295749664306, "training_acc": 50.0, "val_loss": 1.1759090614318848, "val_acc": 52.0}
{"epoch": 3, "training_loss": 5.398257961273194, "training_acc": 50.0, "val_loss": 1.82755934715271, "val_acc": 48.0}
{"epoch": 4, "training_loss": 3.1201274490356443, "training_acc": 42.0, "val_loss": 1.0240201377868652, "val_acc": 52.0}
{"epoch": 5, "training_loss": 2.015090374946594, "training_acc": 46.0, "val_loss": 0.9043212461471558, "val_acc": 48.0}
{"epoch": 6, "training_loss": 1.0093771147727966, "training_acc": 60.0, "val_loss": 1.3572344207763671, "val_acc": 48.0}
{"epoch": 7, "training_loss": 0.8760900950431824, "training_acc": 56.0, "val_loss": 0.696214234828949, "val_acc": 52.0}
{"epoch": 8, "training_loss": 1.0884621000289918, "training_acc": 55.0, "val_loss": 1.2280207681655884, "val_acc": 52.0}
{"epoch": 9, "training_loss": 1.1567592763900756, "training_acc": 46.0, "val_loss": 1.417928261756897, "val_acc": 52.0}
{"epoch": 10, "training_loss": 1.1870742297172547, "training_acc": 50.0, "val_loss": 1.10151282787323, "val_acc": 48.0}
{"epoch": 11, "training_loss": 0.9383676815032959, "training_acc": 52.0, "val_loss": 1.071184811592102, "val_acc": 48.0}
{"epoch": 12, "training_loss": 1.252322473526001, "training_acc": 42.0, "val_loss": 1.2579883670806884, "val_acc": 52.0}
{"epoch": 13, "training_loss": 1.2692684412002564, "training_acc": 40.0, "val_loss": 0.7099917340278625, "val_acc": 52.0}
{"epoch": 14, "training_loss": 0.9608520364761353, "training_acc": 50.0, "val_loss": 0.8053811264038085, "val_acc": 52.0}
{"epoch": 15, "training_loss": 0.896074333190918, "training_acc": 50.0, "val_loss": 3.229620199203491, "val_acc": 48.0}
{"epoch": 16, "training_loss": 1.985060110092163, "training_acc": 44.0, "val_loss": 0.8762931871414185, "val_acc": 48.0}
{"epoch": 17, "training_loss": 1.16094566822052, "training_acc": 58.0, "val_loss": 0.7094341969490051, "val_acc": 52.0}
{"epoch": 18, "training_loss": 0.8418506813049317, "training_acc": 50.0, "val_loss": 1.8756184887886047, "val_acc": 48.0}
{"epoch": 19, "training_loss": 1.4583965921401978, "training_acc": 51.0, "val_loss": 1.3401990413665772, "val_acc": 48.0}
{"epoch": 20, "training_loss": 1.2893983602523804, "training_acc": 48.0, "val_loss": 0.9384434771537781, "val_acc": 52.0}
{"epoch": 21, "training_loss": 0.946422061920166, "training_acc": 52.0, "val_loss": 0.6984673738479614, "val_acc": 48.0}
{"epoch": 22, "training_loss": 0.9856819152832031, "training_acc": 56.0, "val_loss": 1.2295131540298463, "val_acc": 52.0}
{"epoch": 23, "training_loss": 0.9599058556556702, "training_acc": 56.0, "val_loss": 0.7518904662132263, "val_acc": 48.0}
{"epoch": 24, "training_loss": 2.007886724472046, "training_acc": 48.0, "val_loss": 2.2865132808685305, "val_acc": 52.0}
{"epoch": 25, "training_loss": 1.7057766532897949, "training_acc": 56.0, "val_loss": 1.2012293148040771, "val_acc": 48.0}
{"epoch": 26, "training_loss": 1.5384862184524537, "training_acc": 56.0, "val_loss": 2.424039659500122, "val_acc": 48.0}
