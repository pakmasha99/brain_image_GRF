"main_modify.py --pretrained_path /scratch/connectome/dyhan316/VAE_ADHD/barlowtwins/pretrain_results/ABCDbt128a102.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 2 --task ADNI_sex --input_option BT_org --learning_rate 1e-1 --batch_size 16 --weight_decay 1e-3 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 10.0543884885311, "training_acc": 53.0, "val_loss": 4.397642326354981, "val_acc": 48.0}
{"epoch": 1, "training_loss": 3.486120376586914, "training_acc": 41.0, "val_loss": 0.8858712840080262, "val_acc": 52.0}
{"epoch": 2, "training_loss": 1.0138722157478333, "training_acc": 49.0, "val_loss": 1.377333459854126, "val_acc": 48.0}
{"epoch": 3, "training_loss": 1.0334250736236572, "training_acc": 51.0, "val_loss": 0.8789034676551819, "val_acc": 48.0}
{"epoch": 4, "training_loss": 1.8242210674285888, "training_acc": 49.0, "val_loss": 1.7279751229286193, "val_acc": 52.0}
{"epoch": 5, "training_loss": 1.4152269077301025, "training_acc": 51.0, "val_loss": 1.4647771644592285, "val_acc": 52.0}
{"epoch": 6, "training_loss": 1.3266741275787353, "training_acc": 47.0, "val_loss": 0.88984619140625, "val_acc": 52.0}
{"epoch": 7, "training_loss": 1.6076420402526856, "training_acc": 47.0, "val_loss": 2.4593725490570066, "val_acc": 48.0}
{"epoch": 8, "training_loss": 2.9304300117492676, "training_acc": 47.0, "val_loss": 6.426101665496827, "val_acc": 48.0}
{"epoch": 9, "training_loss": 3.4784724807739256, "training_acc": 49.0, "val_loss": 2.671265230178833, "val_acc": 48.0}
{"epoch": 10, "training_loss": 1.3000238037109375, "training_acc": 51.0, "val_loss": 0.6926308560371399, "val_acc": 52.0}
{"epoch": 11, "training_loss": 1.7733254146575927, "training_acc": 39.0, "val_loss": 5.333012790679931, "val_acc": 48.0}
{"epoch": 12, "training_loss": 3.3122299242019655, "training_acc": 55.0, "val_loss": 3.5321266746520994, "val_acc": 48.0}
{"epoch": 13, "training_loss": 3.253646106719971, "training_acc": 53.0, "val_loss": 0.7329814815521241, "val_acc": 52.0}
{"epoch": 14, "training_loss": 3.6713873958587646, "training_acc": 49.0, "val_loss": 5.378669738769531, "val_acc": 52.0}
{"epoch": 15, "training_loss": 3.4684008955955505, "training_acc": 55.0, "val_loss": 1.798850564956665, "val_acc": 52.0}
{"epoch": 16, "training_loss": 1.4652732753753661, "training_acc": 57.0, "val_loss": 1.6117993116378784, "val_acc": 52.0}
{"epoch": 17, "training_loss": 1.6273754930496216, "training_acc": 55.0, "val_loss": 1.2762317514419557, "val_acc": 52.0}
{"epoch": 18, "training_loss": 1.4606529140472413, "training_acc": 45.0, "val_loss": 0.9602847480773926, "val_acc": 52.0}
{"epoch": 19, "training_loss": 1.2237854862213136, "training_acc": 45.0, "val_loss": 0.7480589389801026, "val_acc": 52.0}
{"epoch": 20, "training_loss": 0.7045043468475342, "training_acc": 57.0, "val_loss": 1.1733080983161925, "val_acc": 48.0}
{"epoch": 21, "training_loss": 0.8157084465026856, "training_acc": 49.0, "val_loss": 3.7359644317626954, "val_acc": 48.0}
{"epoch": 22, "training_loss": 2.4402818489074707, "training_acc": 55.0, "val_loss": 2.4090091037750243, "val_acc": 48.0}
{"epoch": 23, "training_loss": 1.5215866327285767, "training_acc": 51.0, "val_loss": 0.9621329045295716, "val_acc": 52.0}
{"epoch": 24, "training_loss": 0.9084219121932984, "training_acc": 49.0, "val_loss": 3.063013801574707, "val_acc": 52.0}
{"epoch": 25, "training_loss": 2.150141363143921, "training_acc": 59.0, "val_loss": 2.1085795831680296, "val_acc": 52.0}
{"epoch": 26, "training_loss": 3.006637649536133, "training_acc": 53.0, "val_loss": 4.227810001373291, "val_acc": 52.0}
{"epoch": 27, "training_loss": 6.063243198394775, "training_acc": 49.0, "val_loss": 6.503677463531494, "val_acc": 48.0}
{"epoch": 28, "training_loss": 2.9951812839508056, "training_acc": 53.0, "val_loss": 3.363965549468994, "val_acc": 48.0}
{"epoch": 29, "training_loss": 1.8727517080307008, "training_acc": 55.0, "val_loss": 1.669091501235962, "val_acc": 48.0}
