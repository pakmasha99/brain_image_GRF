"main_modify.py --pretrained_path /scratch/connectome/dyhan316/VAE_ADHD/barlowtwins/pretrain_results/ABCDbt128a102.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 5 --task ADNI_sex --input_option BT_org --learning_rate 1e-1 --batch_size 16 --weight_decay 1e-3 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 7.395218980312348, "training_acc": 54.0, "val_loss": 5.187736873626709, "val_acc": 52.0}
{"epoch": 1, "training_loss": 4.499798316955566, "training_acc": 50.0, "val_loss": 1.1740912008285522, "val_acc": 48.0}
{"epoch": 2, "training_loss": 4.371458349227905, "training_acc": 46.0, "val_loss": 3.2138580513000488, "val_acc": 48.0}
{"epoch": 3, "training_loss": 2.397545728683472, "training_acc": 50.0, "val_loss": 1.9882369184494018, "val_acc": 48.0}
{"epoch": 4, "training_loss": 1.5452098986506462, "training_acc": 50.0, "val_loss": 4.1649057579040525, "val_acc": 48.0}
{"epoch": 5, "training_loss": 2.951227626800537, "training_acc": 54.0, "val_loss": 0.8092474865913392, "val_acc": 52.0}
{"epoch": 6, "training_loss": 2.431289863586426, "training_acc": 52.0, "val_loss": 2.7485733318328855, "val_acc": 52.0}
{"epoch": 7, "training_loss": 2.011213574409485, "training_acc": 50.0, "val_loss": 2.6668835830688478, "val_acc": 52.0}
{"epoch": 8, "training_loss": 1.7959761142730712, "training_acc": 42.0, "val_loss": 0.8335125041007996, "val_acc": 52.0}
{"epoch": 9, "training_loss": 0.9860937905311584, "training_acc": 48.0, "val_loss": 1.831485891342163, "val_acc": 48.0}
{"epoch": 10, "training_loss": 0.980037100315094, "training_acc": 52.0, "val_loss": 1.3859436893463135, "val_acc": 52.0}
{"epoch": 11, "training_loss": 1.072076573371887, "training_acc": 48.0, "val_loss": 0.9189487814903259, "val_acc": 48.0}
{"epoch": 12, "training_loss": 1.1764169764518737, "training_acc": 44.0, "val_loss": 0.8479700565338135, "val_acc": 52.0}
{"epoch": 13, "training_loss": 0.7930799722671509, "training_acc": 52.0, "val_loss": 1.832598361968994, "val_acc": 48.0}
{"epoch": 14, "training_loss": 1.4962880420684814, "training_acc": 52.0, "val_loss": 1.0258334374427795, "val_acc": 52.0}
{"epoch": 15, "training_loss": 1.0030431175231933, "training_acc": 54.0, "val_loss": 0.9470765972137452, "val_acc": 52.0}
{"epoch": 16, "training_loss": 1.656786618232727, "training_acc": 46.0, "val_loss": 2.723614296913147, "val_acc": 52.0}
{"epoch": 17, "training_loss": 1.4178825950622558, "training_acc": 52.0, "val_loss": 1.1544482612609863, "val_acc": 48.0}
{"epoch": 18, "training_loss": 0.8688193464279175, "training_acc": 56.0, "val_loss": 0.9712602758407592, "val_acc": 52.0}
{"epoch": 19, "training_loss": 1.1417839670181273, "training_acc": 54.0, "val_loss": 0.7686736226081848, "val_acc": 48.0}
{"epoch": 20, "training_loss": 0.9708150272816419, "training_acc": 58.0, "val_loss": 4.643975276947021, "val_acc": 52.0}
{"epoch": 21, "training_loss": 2.8697740960121156, "training_acc": 46.0, "val_loss": 0.8666055750846863, "val_acc": 48.0}
{"epoch": 22, "training_loss": 0.9129790830612182, "training_acc": 52.0, "val_loss": 0.7201714944839478, "val_acc": 48.0}
{"epoch": 23, "training_loss": 1.6281386852264403, "training_acc": 48.0, "val_loss": 1.4215936470031738, "val_acc": 52.0}
{"epoch": 24, "training_loss": 1.248149929046631, "training_acc": 48.0, "val_loss": 2.1086701011657714, "val_acc": 48.0}
{"epoch": 25, "training_loss": 1.340692322254181, "training_acc": 48.0, "val_loss": 1.0141173315048218, "val_acc": 48.0}
{"epoch": 26, "training_loss": 1.3088621616363525, "training_acc": 48.0, "val_loss": 0.7905137300491333, "val_acc": 48.0}
{"epoch": 27, "training_loss": 0.9313172197341919, "training_acc": 44.0, "val_loss": 0.8135483980178833, "val_acc": 52.0}
{"epoch": 28, "training_loss": 1.0778772282600402, "training_acc": 48.0, "val_loss": 0.8290937447547913, "val_acc": 48.0}
{"epoch": 29, "training_loss": 0.7235818552970886, "training_acc": 52.0, "val_loss": 3.248589639663696, "val_acc": 52.0}
{"epoch": 30, "training_loss": 2.8658962297439574, "training_acc": 50.0, "val_loss": 5.405386838912964, "val_acc": 52.0}
{"epoch": 31, "training_loss": 2.970161144733429, "training_acc": 56.0, "val_loss": 1.5690357637405397, "val_acc": 52.0}
{"epoch": 32, "training_loss": 1.1240653657913209, "training_acc": 48.0, "val_loss": 0.9072078585624694, "val_acc": 52.0}
{"epoch": 33, "training_loss": 1.3205714988708497, "training_acc": 46.0, "val_loss": 1.118304738998413, "val_acc": 52.0}
{"epoch": 34, "training_loss": 0.9643659830093384, "training_acc": 56.0, "val_loss": 1.2959866094589234, "val_acc": 48.0}
{"epoch": 35, "training_loss": 2.128959041982889, "training_acc": 54.0, "val_loss": 1.0341931223869323, "val_acc": 48.0}
{"epoch": 36, "training_loss": 1.6548815393447875, "training_acc": 46.0, "val_loss": 0.71271235704422, "val_acc": 48.0}
{"epoch": 37, "training_loss": 1.4880713653564452, "training_acc": 38.0, "val_loss": 2.1998832702636717, "val_acc": 48.0}
{"epoch": 38, "training_loss": 1.092198920249939, "training_acc": 54.0, "val_loss": 0.6971269726753235, "val_acc": 52.0}
{"epoch": 39, "training_loss": 0.8738760757446289, "training_acc": 54.0, "val_loss": 1.2146519660949706, "val_acc": 48.0}
{"epoch": 40, "training_loss": 1.031298360824585, "training_acc": 50.0, "val_loss": 0.961852741241455, "val_acc": 48.0}
{"epoch": 41, "training_loss": 1.1517930841445922, "training_acc": 48.0, "val_loss": 0.9843621253967285, "val_acc": 52.0}
{"epoch": 42, "training_loss": 2.100933246612549, "training_acc": 42.0, "val_loss": 1.0423769640922547, "val_acc": 52.0}
{"epoch": 43, "training_loss": 1.4014572238922118, "training_acc": 58.0, "val_loss": 2.6637806940078734, "val_acc": 52.0}
{"epoch": 44, "training_loss": 2.0486150217056274, "training_acc": 50.0, "val_loss": 1.230402421951294, "val_acc": 48.0}
{"epoch": 45, "training_loss": 1.0463549065589905, "training_acc": 48.0, "val_loss": 0.7281103372573853, "val_acc": 48.0}
{"epoch": 46, "training_loss": 0.9988231444358826, "training_acc": 50.0, "val_loss": 0.849439172744751, "val_acc": 48.0}
{"epoch": 47, "training_loss": 0.9051335382461548, "training_acc": 48.0, "val_loss": 0.7615846562385559, "val_acc": 48.0}
{"epoch": 48, "training_loss": 0.7958994126319885, "training_acc": 46.0, "val_loss": 1.717626748085022, "val_acc": 52.0}
{"epoch": 49, "training_loss": 1.1343855249881745, "training_acc": 56.0, "val_loss": 3.582259464263916, "val_acc": 48.0}
{"epoch": 50, "training_loss": 2.942391805648804, "training_acc": 42.0, "val_loss": 0.8162518572807312, "val_acc": 48.0}
{"epoch": 51, "training_loss": 2.0183144855499267, "training_acc": 48.0, "val_loss": 1.2739382839202882, "val_acc": 52.0}
{"epoch": 52, "training_loss": 0.9018598175048829, "training_acc": 56.0, "val_loss": 1.6205166578292847, "val_acc": 52.0}
{"epoch": 53, "training_loss": 1.2782185554504395, "training_acc": 38.0, "val_loss": 1.6424235582351685, "val_acc": 48.0}
{"epoch": 54, "training_loss": 1.3453175687789918, "training_acc": 54.0, "val_loss": 0.7016735029220581, "val_acc": 52.0}
{"epoch": 55, "training_loss": 1.1993095684051513, "training_acc": 52.0, "val_loss": 0.9377402234077453, "val_acc": 48.0}
{"epoch": 56, "training_loss": 1.0382320261001587, "training_acc": 50.0, "val_loss": 0.7009603524208069, "val_acc": 52.0}
{"epoch": 57, "training_loss": 0.9358628845214844, "training_acc": 52.0, "val_loss": 2.1371591091156006, "val_acc": 52.0}
