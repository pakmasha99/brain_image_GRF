"main_modify.py --pretrained_path /scratch/connectome/dyhan316/VAE_ADHD/barlowtwins/pretrain_results/ABCDbt128a102.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 5 --task ADNI_sex --input_option BT_org --learning_rate 1e-1 --batch_size 16 --weight_decay 1e-3 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 8.074677381515503, "training_acc": 55.0, "val_loss": 1.0571362066268921, "val_acc": 48.0}
{"epoch": 1, "training_loss": 1.567409839630127, "training_acc": 53.0, "val_loss": 1.3949738311767579, "val_acc": 52.0}
{"epoch": 2, "training_loss": 1.2142914032936096, "training_acc": 47.0, "val_loss": 2.4270771884918214, "val_acc": 48.0}
{"epoch": 3, "training_loss": 1.416148326396942, "training_acc": 53.0, "val_loss": 0.9744666528701782, "val_acc": 52.0}
{"epoch": 4, "training_loss": 1.3498031282424927, "training_acc": 53.0, "val_loss": 0.918031804561615, "val_acc": 48.0}
{"epoch": 5, "training_loss": 1.8122443174966612, "training_acc": 45.0, "val_loss": 8.382047710418702, "val_acc": 52.0}
{"epoch": 6, "training_loss": 5.939461841583252, "training_acc": 55.0, "val_loss": 5.487991237640381, "val_acc": 48.0}
{"epoch": 7, "training_loss": 3.197188024520874, "training_acc": 53.0, "val_loss": 7.189657249450684, "val_acc": 48.0}
{"epoch": 8, "training_loss": 4.687715816497803, "training_acc": 53.0, "val_loss": 3.6144255447387694, "val_acc": 52.0}
{"epoch": 9, "training_loss": 4.349438648223877, "training_acc": 39.0, "val_loss": 3.703289337158203, "val_acc": 52.0}
{"epoch": 10, "training_loss": 3.0410017013549804, "training_acc": 51.0, "val_loss": 3.11321213722229, "val_acc": 52.0}
{"epoch": 11, "training_loss": 2.583342638015747, "training_acc": 39.0, "val_loss": 3.5692687702178953, "val_acc": 48.0}
{"epoch": 12, "training_loss": 4.223369617462158, "training_acc": 49.0, "val_loss": 0.7096811413764954, "val_acc": 48.0}
{"epoch": 13, "training_loss": 3.0634762144088743, "training_acc": 45.0, "val_loss": 2.3987255096435547, "val_acc": 48.0}
{"epoch": 14, "training_loss": 2.8546202301979067, "training_acc": 47.0, "val_loss": 4.030509738922119, "val_acc": 48.0}
{"epoch": 15, "training_loss": 2.75886568069458, "training_acc": 43.0, "val_loss": 0.8240482068061828, "val_acc": 52.0}
{"epoch": 16, "training_loss": 0.9119563293457031, "training_acc": 51.0, "val_loss": 2.3415510749816892, "val_acc": 48.0}
{"epoch": 17, "training_loss": 0.9917349576950073, "training_acc": 57.0, "val_loss": 2.2319205951690675, "val_acc": 48.0}
{"epoch": 18, "training_loss": 1.1992185974121095, "training_acc": 57.0, "val_loss": 1.462944576740265, "val_acc": 52.0}
{"epoch": 19, "training_loss": 1.794411678314209, "training_acc": 39.0, "val_loss": 2.7498271083831787, "val_acc": 48.0}
{"epoch": 20, "training_loss": 2.1879777669906617, "training_acc": 53.0, "val_loss": 3.927970790863037, "val_acc": 48.0}
{"epoch": 21, "training_loss": 3.8358526992797852, "training_acc": 53.0, "val_loss": 6.271202354431153, "val_acc": 52.0}
{"epoch": 22, "training_loss": 4.284970273971558, "training_acc": 55.0, "val_loss": 0.7215743637084961, "val_acc": 52.0}
{"epoch": 23, "training_loss": 3.6571186637878417, "training_acc": 51.0, "val_loss": 7.169255332946777, "val_acc": 48.0}
{"epoch": 24, "training_loss": 4.564016695022583, "training_acc": 49.0, "val_loss": 0.9160664796829223, "val_acc": 48.0}
{"epoch": 25, "training_loss": 1.7553660011291503, "training_acc": 49.0, "val_loss": 3.3713187694549562, "val_acc": 48.0}
{"epoch": 26, "training_loss": 3.125154724121094, "training_acc": 49.0, "val_loss": 1.2157316732406616, "val_acc": 48.0}
{"epoch": 27, "training_loss": 1.6965113258361817, "training_acc": 45.0, "val_loss": 1.2987801027297974, "val_acc": 48.0}
{"epoch": 28, "training_loss": 1.696319522857666, "training_acc": 47.0, "val_loss": 0.7331209826469421, "val_acc": 52.0}
{"epoch": 29, "training_loss": 1.1682395076751708, "training_acc": 49.0, "val_loss": 0.693438868522644, "val_acc": 48.0}
{"epoch": 30, "training_loss": 1.1988743495941163, "training_acc": 47.0, "val_loss": 1.2865372157096864, "val_acc": 48.0}
{"epoch": 31, "training_loss": 1.4824229621887206, "training_acc": 49.0, "val_loss": 3.046566047668457, "val_acc": 48.0}
{"epoch": 32, "training_loss": 1.9874599647521973, "training_acc": 49.0, "val_loss": 1.8642906045913696, "val_acc": 48.0}
{"epoch": 33, "training_loss": 1.6091907119750977, "training_acc": 53.0, "val_loss": 0.7282087469100952, "val_acc": 48.0}
{"epoch": 34, "training_loss": 1.196076135635376, "training_acc": 57.0, "val_loss": 0.7656738257408142, "val_acc": 52.0}
{"epoch": 35, "training_loss": 0.9001512157917023, "training_acc": 51.0, "val_loss": 1.6330312776565552, "val_acc": 48.0}
{"epoch": 36, "training_loss": 1.845353434085846, "training_acc": 37.0, "val_loss": 1.057770938873291, "val_acc": 48.0}
{"epoch": 37, "training_loss": 0.9703377962112427, "training_acc": 49.0, "val_loss": 2.0453826236724852, "val_acc": 52.0}
{"epoch": 38, "training_loss": 2.403306074142456, "training_acc": 45.0, "val_loss": 1.1069064331054688, "val_acc": 52.0}
{"epoch": 39, "training_loss": 2.7824409770965577, "training_acc": 53.0, "val_loss": 3.323300380706787, "val_acc": 52.0}
{"epoch": 40, "training_loss": 2.2178762984275817, "training_acc": 47.0, "val_loss": 1.0363601064682006, "val_acc": 52.0}
{"epoch": 41, "training_loss": 0.8145856738090516, "training_acc": 49.0, "val_loss": 0.6996059536933898, "val_acc": 48.0}
{"epoch": 42, "training_loss": 0.7501903820037842, "training_acc": 55.0, "val_loss": 1.7537464094161987, "val_acc": 52.0}
{"epoch": 43, "training_loss": 1.1395751070976257, "training_acc": 45.0, "val_loss": 0.7078544926643372, "val_acc": 52.0}
{"epoch": 44, "training_loss": 1.3547839069366454, "training_acc": 41.0, "val_loss": 0.9422167038917542, "val_acc": 52.0}
{"epoch": 45, "training_loss": 1.3382509922981263, "training_acc": 55.0, "val_loss": 2.9706779098510743, "val_acc": 52.0}
{"epoch": 46, "training_loss": 3.0983466291427613, "training_acc": 39.0, "val_loss": 2.839344024658203, "val_acc": 52.0}
{"epoch": 47, "training_loss": 2.2379068088531495, "training_acc": 51.0, "val_loss": 1.771128396987915, "val_acc": 52.0}
{"epoch": 48, "training_loss": 1.1516456508636475, "training_acc": 47.0, "val_loss": 0.7669479727745057, "val_acc": 52.0}
