"main_modify.py --pretrained_path /scratch/connectome/dyhan316/VAE_ADHD/barlowtwins/pretrain_results/ABCDbt128a102.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 5 --task ADNI_sex --input_option BT_org --learning_rate 1e-1 --batch_size 16 --weight_decay 1e-3 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 9.023934831619263, "training_acc": 55.0, "val_loss": 3.174005069732666, "val_acc": 48.0}
{"epoch": 1, "training_loss": 3.548384876251221, "training_acc": 45.0, "val_loss": 1.411056170463562, "val_acc": 48.0}
{"epoch": 2, "training_loss": 3.4842189168930053, "training_acc": 47.0, "val_loss": 5.542750129699707, "val_acc": 48.0}
{"epoch": 3, "training_loss": 3.765960388183594, "training_acc": 45.0, "val_loss": 1.8042136526107788, "val_acc": 48.0}
{"epoch": 4, "training_loss": 2.510443592071533, "training_acc": 45.0, "val_loss": 1.9618076229095458, "val_acc": 48.0}
{"epoch": 5, "training_loss": 2.057538838386536, "training_acc": 47.0, "val_loss": 1.6266350412368775, "val_acc": 48.0}
{"epoch": 6, "training_loss": 1.2255694580078125, "training_acc": 45.0, "val_loss": 1.470671238899231, "val_acc": 52.0}
{"epoch": 7, "training_loss": 1.163805103302002, "training_acc": 49.0, "val_loss": 1.0834243607521057, "val_acc": 48.0}
{"epoch": 8, "training_loss": 0.8616652727127075, "training_acc": 48.0, "val_loss": 1.8062598991394043, "val_acc": 52.0}
{"epoch": 9, "training_loss": 1.2414017772674562, "training_acc": 57.0, "val_loss": 1.3010274124145509, "val_acc": 52.0}
{"epoch": 10, "training_loss": 1.2607517290115355, "training_acc": 45.0, "val_loss": 0.9996295094490051, "val_acc": 48.0}
{"epoch": 11, "training_loss": 0.7298995208740234, "training_acc": 55.0, "val_loss": 1.4439075088500977, "val_acc": 52.0}
{"epoch": 12, "training_loss": 1.0927375507354737, "training_acc": 39.0, "val_loss": 2.1897274112701415, "val_acc": 48.0}
{"epoch": 13, "training_loss": 2.10977365732193, "training_acc": 51.0, "val_loss": 1.9062753200531006, "val_acc": 48.0}
{"epoch": 14, "training_loss": 1.9733571910858154, "training_acc": 47.0, "val_loss": 1.271312222480774, "val_acc": 52.0}
{"epoch": 15, "training_loss": 1.9316977739334107, "training_acc": 43.0, "val_loss": 1.0313869190216065, "val_acc": 52.0}
{"epoch": 16, "training_loss": 0.9261812829971313, "training_acc": 55.0, "val_loss": 0.7403727030754089, "val_acc": 48.0}
{"epoch": 17, "training_loss": 1.181537274122238, "training_acc": 49.0, "val_loss": 1.8088056421279908, "val_acc": 48.0}
{"epoch": 18, "training_loss": 1.1982648944854737, "training_acc": 53.0, "val_loss": 2.4242272758483887, "val_acc": 52.0}
{"epoch": 19, "training_loss": 2.221535358428955, "training_acc": 43.0, "val_loss": 0.6981094193458557, "val_acc": 52.0}
{"epoch": 20, "training_loss": 1.7249341487884522, "training_acc": 63.0, "val_loss": 1.556125087738037, "val_acc": 52.0}
{"epoch": 21, "training_loss": 1.0531081748008728, "training_acc": 50.0, "val_loss": 0.6835122609138489, "val_acc": 48.0}
{"epoch": 22, "training_loss": 1.1758052206039429, "training_acc": 50.0, "val_loss": 3.0228082180023192, "val_acc": 48.0}
{"epoch": 23, "training_loss": 3.133551530838013, "training_acc": 53.0, "val_loss": 4.319264087677002, "val_acc": 48.0}
{"epoch": 24, "training_loss": 2.409726185798645, "training_acc": 49.0, "val_loss": 2.4127129173278807, "val_acc": 52.0}
{"epoch": 25, "training_loss": 3.7181837272644045, "training_acc": 37.0, "val_loss": 5.5834557151794435, "val_acc": 52.0}
{"epoch": 26, "training_loss": 4.964249744415283, "training_acc": 45.0, "val_loss": 5.878128433227539, "val_acc": 52.0}
{"epoch": 27, "training_loss": 5.780141558647156, "training_acc": 41.0, "val_loss": 3.816131286621094, "val_acc": 52.0}
{"epoch": 28, "training_loss": 5.029426879882813, "training_acc": 47.0, "val_loss": 1.785185317993164, "val_acc": 48.0}
{"epoch": 29, "training_loss": 4.2968120288848874, "training_acc": 47.0, "val_loss": 5.399222450256348, "val_acc": 48.0}
{"epoch": 30, "training_loss": 2.8214136505126954, "training_acc": 45.0, "val_loss": 0.769033694267273, "val_acc": 52.0}
{"epoch": 31, "training_loss": 1.1599140024185182, "training_acc": 41.0, "val_loss": 1.002450726032257, "val_acc": 52.0}
{"epoch": 32, "training_loss": 1.0911873197555542, "training_acc": 44.0, "val_loss": 0.8168784713745117, "val_acc": 48.0}
{"epoch": 33, "training_loss": 1.0138943004608154, "training_acc": 52.0, "val_loss": 0.716641993522644, "val_acc": 48.0}
{"epoch": 34, "training_loss": 1.4310481882095336, "training_acc": 52.0, "val_loss": 0.9851971578598022, "val_acc": 48.0}
{"epoch": 35, "training_loss": 1.2519659328460693, "training_acc": 51.0, "val_loss": 0.7058517765998841, "val_acc": 44.0}
{"epoch": 36, "training_loss": 0.7309003162384033, "training_acc": 54.0, "val_loss": 0.7534333062171936, "val_acc": 48.0}
{"epoch": 37, "training_loss": 0.8014972591400147, "training_acc": 46.0, "val_loss": 3.4058395767211915, "val_acc": 48.0}
{"epoch": 38, "training_loss": 2.8545387172698975, "training_acc": 49.0, "val_loss": 3.919393997192383, "val_acc": 48.0}
{"epoch": 39, "training_loss": 1.435912320613861, "training_acc": 53.0, "val_loss": 1.4045970106124879, "val_acc": 48.0}
{"epoch": 40, "training_loss": 0.8937645554542542, "training_acc": 52.0, "val_loss": 1.4385466718673705, "val_acc": 52.0}
