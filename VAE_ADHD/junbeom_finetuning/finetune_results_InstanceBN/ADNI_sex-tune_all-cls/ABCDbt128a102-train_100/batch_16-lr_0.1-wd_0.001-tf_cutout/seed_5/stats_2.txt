"main_modify.py --pretrained_path /scratch/connectome/dyhan316/VAE_ADHD/barlowtwins/pretrain_results/ABCDbt128a102.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 5 --task ADNI_sex --input_option BT_org --learning_rate 1e-1 --batch_size 16 --weight_decay 1e-3 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 7.721577305793762, "training_acc": 54.0, "val_loss": 6.872841873168945, "val_acc": 48.0}
{"epoch": 1, "training_loss": 5.41336067199707, "training_acc": 48.0, "val_loss": 1.445600724220276, "val_acc": 52.0}
{"epoch": 2, "training_loss": 3.2701601791381836, "training_acc": 50.0, "val_loss": 4.922167129516602, "val_acc": 52.0}
{"epoch": 3, "training_loss": 3.6764870262145997, "training_acc": 48.0, "val_loss": 1.1569706964492799, "val_acc": 48.0}
{"epoch": 4, "training_loss": 1.3031121063232423, "training_acc": 52.0, "val_loss": 0.8777716708183289, "val_acc": 52.0}
{"epoch": 5, "training_loss": 0.9588084316253662, "training_acc": 49.0, "val_loss": 1.05646701335907, "val_acc": 52.0}
{"epoch": 6, "training_loss": 1.3989662981033326, "training_acc": 48.0, "val_loss": 1.897484426498413, "val_acc": 48.0}
{"epoch": 7, "training_loss": 1.1656786727905273, "training_acc": 56.0, "val_loss": 1.9452134323120118, "val_acc": 52.0}
{"epoch": 8, "training_loss": 1.8296411752700805, "training_acc": 50.0, "val_loss": 4.031516036987305, "val_acc": 48.0}
{"epoch": 9, "training_loss": 3.8500383853912354, "training_acc": 46.0, "val_loss": 1.124664695262909, "val_acc": 48.0}
{"epoch": 10, "training_loss": 0.9274656915664673, "training_acc": 52.0, "val_loss": 1.244370355606079, "val_acc": 48.0}
{"epoch": 11, "training_loss": 0.8399756193161011, "training_acc": 54.0, "val_loss": 1.263627552986145, "val_acc": 48.0}
{"epoch": 12, "training_loss": 0.9428297901153564, "training_acc": 56.0, "val_loss": 1.0115811729431152, "val_acc": 48.0}
{"epoch": 13, "training_loss": 1.1717394065856934, "training_acc": 48.0, "val_loss": 1.861647253036499, "val_acc": 48.0}
{"epoch": 14, "training_loss": 1.5904761737585067, "training_acc": 58.0, "val_loss": 2.7035000801086424, "val_acc": 48.0}
{"epoch": 15, "training_loss": 1.7333911275863647, "training_acc": 50.0, "val_loss": 1.468089485168457, "val_acc": 52.0}
{"epoch": 16, "training_loss": 0.9823739576339722, "training_acc": 52.0, "val_loss": 1.7330514621734618, "val_acc": 52.0}
{"epoch": 17, "training_loss": 1.692815637588501, "training_acc": 48.0, "val_loss": 1.0331300592422485, "val_acc": 48.0}
{"epoch": 18, "training_loss": 1.0301227140426636, "training_acc": 52.0, "val_loss": 0.7443073344230652, "val_acc": 52.0}
{"epoch": 19, "training_loss": 1.1680163145065308, "training_acc": 46.0, "val_loss": 2.3053208637237548, "val_acc": 52.0}
{"epoch": 20, "training_loss": 1.3852857112884522, "training_acc": 54.0, "val_loss": 3.0408667278289796, "val_acc": 48.0}
{"epoch": 21, "training_loss": 1.4647405457496643, "training_acc": 56.0, "val_loss": 1.950601625442505, "val_acc": 52.0}
{"epoch": 22, "training_loss": 1.5601510214805603, "training_acc": 40.0, "val_loss": 0.77736825466156, "val_acc": 52.0}
{"epoch": 23, "training_loss": 0.8427622604370117, "training_acc": 54.0, "val_loss": 1.1701859331130982, "val_acc": 52.0}
{"epoch": 24, "training_loss": 1.2839888954162597, "training_acc": 50.0, "val_loss": 0.7005951023101806, "val_acc": 52.0}
{"epoch": 25, "training_loss": 0.8153608798980713, "training_acc": 48.0, "val_loss": 2.276122226715088, "val_acc": 52.0}
{"epoch": 26, "training_loss": 1.4485530269145965, "training_acc": 56.0, "val_loss": 1.4344680213928223, "val_acc": 52.0}
{"epoch": 27, "training_loss": 1.1702842950820922, "training_acc": 50.0, "val_loss": 1.2548666286468506, "val_acc": 48.0}
{"epoch": 28, "training_loss": 1.1400706672668457, "training_acc": 54.0, "val_loss": 0.7309074878692627, "val_acc": 48.0}
{"epoch": 29, "training_loss": 0.8142812442779541, "training_acc": 46.0, "val_loss": 4.174746398925781, "val_acc": 48.0}
{"epoch": 30, "training_loss": 1.8757315015792846, "training_acc": 60.0, "val_loss": 1.9808327150344849, "val_acc": 48.0}
{"epoch": 31, "training_loss": 1.1661851406097412, "training_acc": 56.0, "val_loss": 0.8309151506423951, "val_acc": 48.0}
{"epoch": 32, "training_loss": 0.814402928352356, "training_acc": 52.0, "val_loss": 2.88954363822937, "val_acc": 48.0}
{"epoch": 33, "training_loss": 1.547022249698639, "training_acc": 54.0, "val_loss": 1.7115944623947144, "val_acc": 52.0}
{"epoch": 34, "training_loss": 1.563722472190857, "training_acc": 56.0, "val_loss": 1.0544714689254762, "val_acc": 52.0}
{"epoch": 35, "training_loss": 1.3573294258117676, "training_acc": 58.0, "val_loss": 2.554198989868164, "val_acc": 48.0}
{"epoch": 36, "training_loss": 3.151129541397095, "training_acc": 42.0, "val_loss": 5.99377477645874, "val_acc": 48.0}
{"epoch": 37, "training_loss": 2.5968266248703005, "training_acc": 52.0, "val_loss": 0.9987341690063477, "val_acc": 52.0}
{"epoch": 38, "training_loss": 1.0892728328704835, "training_acc": 52.0, "val_loss": 2.158196659088135, "val_acc": 48.0}
{"epoch": 39, "training_loss": 1.3052790904045104, "training_acc": 46.0, "val_loss": 0.707784206867218, "val_acc": 48.0}
{"epoch": 40, "training_loss": 0.9709099102020263, "training_acc": 48.0, "val_loss": 0.7057848787307739, "val_acc": 48.0}
{"epoch": 41, "training_loss": 0.7950853681564332, "training_acc": 56.0, "val_loss": 0.6988098430633545, "val_acc": 52.0}
{"epoch": 42, "training_loss": 1.3417456912994385, "training_acc": 42.0, "val_loss": 3.277512397766113, "val_acc": 52.0}
{"epoch": 43, "training_loss": 2.845367879867554, "training_acc": 50.0, "val_loss": 1.9895863580703734, "val_acc": 52.0}
{"epoch": 44, "training_loss": 1.0799470353126526, "training_acc": 44.0, "val_loss": 1.4018968868255615, "val_acc": 48.0}
{"epoch": 45, "training_loss": 0.9070302438735962, "training_acc": 52.0, "val_loss": 3.1887256050109865, "val_acc": 52.0}
{"epoch": 46, "training_loss": 3.360701313018799, "training_acc": 52.0, "val_loss": 0.7710485064983368, "val_acc": 52.0}
{"epoch": 47, "training_loss": 3.013066644668579, "training_acc": 50.0, "val_loss": 0.9625944995880127, "val_acc": 52.0}
{"epoch": 48, "training_loss": 1.4961379528045655, "training_acc": 54.0, "val_loss": 1.4000633263587952, "val_acc": 48.0}
{"epoch": 49, "training_loss": 0.9654913377761841, "training_acc": 48.0, "val_loss": 0.7200307846069336, "val_acc": 52.0}
{"epoch": 50, "training_loss": 0.8228048801422119, "training_acc": 56.0, "val_loss": 1.0031672644615173, "val_acc": 52.0}
{"epoch": 51, "training_loss": 0.7965848541259766, "training_acc": 52.0, "val_loss": 0.7792040538787842, "val_acc": 48.0}
{"epoch": 52, "training_loss": 1.259195041656494, "training_acc": 46.0, "val_loss": 3.6945100688934325, "val_acc": 48.0}
{"epoch": 53, "training_loss": 4.437907905578613, "training_acc": 48.0, "val_loss": 2.931654176712036, "val_acc": 52.0}
{"epoch": 54, "training_loss": 1.9897880887985229, "training_acc": 50.0, "val_loss": 0.7835745692253113, "val_acc": 52.0}
{"epoch": 55, "training_loss": 0.7077423095703125, "training_acc": 62.0, "val_loss": 1.6161331987380982, "val_acc": 48.0}
{"epoch": 56, "training_loss": 1.1627362871170044, "training_acc": 54.0, "val_loss": 0.7851108932495117, "val_acc": 48.0}
{"epoch": 57, "training_loss": 1.2780036902427674, "training_acc": 46.0, "val_loss": 1.1064422750473022, "val_acc": 48.0}
{"epoch": 58, "training_loss": 1.1302721309661865, "training_acc": 50.0, "val_loss": 3.6044687175750734, "val_acc": 52.0}
{"epoch": 59, "training_loss": 1.9865142166614533, "training_acc": 52.0, "val_loss": 3.1410905075073243, "val_acc": 48.0}
{"epoch": 60, "training_loss": 2.7921585273742675, "training_acc": 46.0, "val_loss": 3.541760025024414, "val_acc": 52.0}
