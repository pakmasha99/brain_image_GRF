"main_modify.py --pretrained_path /scratch/connectome/dyhan316/VAE_ADHD/barlowtwins/pretrain_results/ABCDbt128a102.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ADNI_sex --input_option BT_org --learning_rate 1e-2 --batch_size 16 --weight_decay 1e-4 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 1.3901363801956177, "training_acc": 46.0, "val_loss": 0.7212315392494202, "val_acc": 48.0}
{"epoch": 1, "training_loss": 0.936490216255188, "training_acc": 50.0, "val_loss": 0.8855032086372375, "val_acc": 52.0}
{"epoch": 2, "training_loss": 0.8350322341918945, "training_acc": 46.0, "val_loss": 0.7607474827766418, "val_acc": 48.0}
{"epoch": 3, "training_loss": 0.7204682207107544, "training_acc": 50.0, "val_loss": 0.7276698684692383, "val_acc": 52.0}
{"epoch": 4, "training_loss": 0.7166094064712525, "training_acc": 52.0, "val_loss": 0.6926855039596558, "val_acc": 52.0}
{"epoch": 5, "training_loss": 0.7278079462051391, "training_acc": 52.0, "val_loss": 0.8119413828849793, "val_acc": 48.0}
{"epoch": 6, "training_loss": 0.8257940649986267, "training_acc": 52.0, "val_loss": 0.8019955921173095, "val_acc": 52.0}
{"epoch": 7, "training_loss": 0.7355048942565918, "training_acc": 54.0, "val_loss": 1.1010766172409057, "val_acc": 48.0}
{"epoch": 8, "training_loss": 1.0554144763946534, "training_acc": 36.0, "val_loss": 0.6928882241249085, "val_acc": 52.0}
{"epoch": 9, "training_loss": 0.7106196188926697, "training_acc": 52.0, "val_loss": 0.693467288017273, "val_acc": 52.0}
{"epoch": 10, "training_loss": 0.7048269176483154, "training_acc": 46.0, "val_loss": 0.7564480209350586, "val_acc": 52.0}
{"epoch": 11, "training_loss": 0.720351116657257, "training_acc": 52.0, "val_loss": 0.7720100927352905, "val_acc": 48.0}
{"epoch": 12, "training_loss": 0.7256733465194702, "training_acc": 46.0, "val_loss": 0.7096278047561646, "val_acc": 48.0}
{"epoch": 13, "training_loss": 0.7343942427635193, "training_acc": 42.0, "val_loss": 0.7019211530685425, "val_acc": 48.0}
{"epoch": 14, "training_loss": 0.7168223524093628, "training_acc": 48.0, "val_loss": 0.6925647807121277, "val_acc": 52.0}
{"epoch": 15, "training_loss": 0.7032853841781617, "training_acc": 49.0, "val_loss": 0.734915840625763, "val_acc": 52.0}
{"epoch": 16, "training_loss": 0.7413314056396484, "training_acc": 52.0, "val_loss": 0.9529662275314331, "val_acc": 48.0}
{"epoch": 17, "training_loss": 0.8447425246238709, "training_acc": 56.0, "val_loss": 0.9239325904846192, "val_acc": 52.0}
{"epoch": 18, "training_loss": 0.8130137729644775, "training_acc": 50.0, "val_loss": 0.8571498990058899, "val_acc": 48.0}
{"epoch": 19, "training_loss": 0.7947572803497315, "training_acc": 46.0, "val_loss": 0.7826622104644776, "val_acc": 52.0}
{"epoch": 20, "training_loss": 0.7522677183151245, "training_acc": 50.0, "val_loss": 0.7215278792381287, "val_acc": 48.0}
{"epoch": 21, "training_loss": 0.7698022365570069, "training_acc": 44.0, "val_loss": 0.7082494378089905, "val_acc": 48.0}
{"epoch": 22, "training_loss": 0.7079717826843261, "training_acc": 52.0, "val_loss": 0.7903591251373291, "val_acc": 52.0}
{"epoch": 23, "training_loss": 0.7809354639053345, "training_acc": 54.0, "val_loss": 0.7918895268440247, "val_acc": 48.0}
{"epoch": 24, "training_loss": 0.746046667098999, "training_acc": 48.0, "val_loss": 0.6977297782897949, "val_acc": 52.0}
{"epoch": 25, "training_loss": 0.775920934677124, "training_acc": 52.0, "val_loss": 0.7003330159187316, "val_acc": 52.0}
{"epoch": 26, "training_loss": 0.7360071086883545, "training_acc": 44.0, "val_loss": 0.7001049542427062, "val_acc": 52.0}
{"epoch": 27, "training_loss": 0.7091774749755859, "training_acc": 50.0, "val_loss": 0.7016849040985107, "val_acc": 48.0}
{"epoch": 28, "training_loss": 0.7175835752487183, "training_acc": 44.0, "val_loss": 0.7308512735366821, "val_acc": 48.0}
{"epoch": 29, "training_loss": 0.7186079359054566, "training_acc": 48.0, "val_loss": 0.6986217975616456, "val_acc": 52.0}
{"epoch": 30, "training_loss": 0.7092927479743958, "training_acc": 46.0, "val_loss": 0.693242781162262, "val_acc": 52.0}
{"epoch": 31, "training_loss": 0.7107353687286377, "training_acc": 50.0, "val_loss": 0.6924262547492981, "val_acc": 52.0}
{"epoch": 32, "training_loss": 0.7088264465332031, "training_acc": 48.0, "val_loss": 0.6930982542037963, "val_acc": 52.0}
{"epoch": 33, "training_loss": 0.7021344232559205, "training_acc": 50.0, "val_loss": 0.6941627955436707, "val_acc": 52.0}
{"epoch": 34, "training_loss": 0.7010289049148559, "training_acc": 50.0, "val_loss": 0.6931998133659363, "val_acc": 48.0}
{"epoch": 35, "training_loss": 0.6994921875, "training_acc": 52.0, "val_loss": 0.6984819293022155, "val_acc": 48.0}
{"epoch": 36, "training_loss": 0.7213148093223571, "training_acc": 50.0, "val_loss": 0.7024326610565186, "val_acc": 52.0}
{"epoch": 37, "training_loss": 0.749851622581482, "training_acc": 46.0, "val_loss": 0.7911584496498107, "val_acc": 48.0}
{"epoch": 38, "training_loss": 0.7592318534851075, "training_acc": 54.0, "val_loss": 0.6929201173782349, "val_acc": 52.0}
{"epoch": 39, "training_loss": 0.7127486085891723, "training_acc": 48.0, "val_loss": 0.7597693967819213, "val_acc": 48.0}
{"epoch": 40, "training_loss": 0.7216944932937622, "training_acc": 54.0, "val_loss": 0.7145617985725403, "val_acc": 48.0}
{"epoch": 41, "training_loss": 0.7933431816101074, "training_acc": 52.0, "val_loss": 0.7040618658065796, "val_acc": 48.0}
{"epoch": 42, "training_loss": 0.7696266794204711, "training_acc": 46.0, "val_loss": 0.7039084935188293, "val_acc": 48.0}
{"epoch": 43, "training_loss": 0.7126516342163086, "training_acc": 48.0, "val_loss": 1.0262746000289917, "val_acc": 48.0}
{"epoch": 44, "training_loss": 0.7972998523712158, "training_acc": 50.0, "val_loss": 0.8103962063789367, "val_acc": 48.0}
{"epoch": 45, "training_loss": 0.8494571685791016, "training_acc": 58.0, "val_loss": 1.0611253666877747, "val_acc": 52.0}
{"epoch": 46, "training_loss": 0.9144170570373535, "training_acc": 46.0, "val_loss": 0.7561781144142151, "val_acc": 52.0}
{"epoch": 47, "training_loss": 0.8094171738624573, "training_acc": 48.0, "val_loss": 0.7916921305656434, "val_acc": 48.0}
{"epoch": 48, "training_loss": 0.706921570301056, "training_acc": 56.0, "val_loss": 0.7125765347480774, "val_acc": 52.0}
{"epoch": 49, "training_loss": 0.7687878465652466, "training_acc": 48.0, "val_loss": 0.8531271886825561, "val_acc": 52.0}
{"epoch": 50, "training_loss": 0.7807411336898804, "training_acc": 48.0, "val_loss": 0.6947914266586304, "val_acc": 52.0}
