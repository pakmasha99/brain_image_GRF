"main_modify.py --pretrained_path /scratch/connectome/dyhan316/VAE_ADHD/barlowtwins/pretrain_results/ABCDbt128a102.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 2 --task ADNI_sex --input_option BT_org --learning_rate 1e-2 --batch_size 16 --weight_decay 1e-4 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 1.1093184733390808, "training_acc": 49.0, "val_loss": 1.0576212215423584, "val_acc": 48.0}
{"epoch": 1, "training_loss": 0.9072057032585144, "training_acc": 49.0, "val_loss": 0.8768479919433594, "val_acc": 48.0}
{"epoch": 2, "training_loss": 0.8168058443069458, "training_acc": 49.0, "val_loss": 0.7330080151557923, "val_acc": 52.0}
{"epoch": 3, "training_loss": 0.7259341335296631, "training_acc": 51.0, "val_loss": 0.7010208487510681, "val_acc": 52.0}
{"epoch": 4, "training_loss": 0.77939288854599, "training_acc": 47.0, "val_loss": 0.7396267771720886, "val_acc": 48.0}
{"epoch": 5, "training_loss": 0.7419902086257935, "training_acc": 43.0, "val_loss": 0.7034657406806946, "val_acc": 48.0}
{"epoch": 6, "training_loss": 0.7153578615188598, "training_acc": 42.0, "val_loss": 0.6924699401855469, "val_acc": 52.0}
{"epoch": 7, "training_loss": 0.7223091411590576, "training_acc": 49.0, "val_loss": 0.7035043787956238, "val_acc": 48.0}
{"epoch": 8, "training_loss": 0.7447991704940796, "training_acc": 49.0, "val_loss": 0.8026704549789428, "val_acc": 48.0}
{"epoch": 9, "training_loss": 0.7542867803573609, "training_acc": 51.0, "val_loss": 0.886252760887146, "val_acc": 48.0}
{"epoch": 10, "training_loss": 0.8662901020050049, "training_acc": 43.0, "val_loss": 0.7626658082008362, "val_acc": 48.0}
{"epoch": 11, "training_loss": 0.862236270904541, "training_acc": 44.0, "val_loss": 0.6952787184715271, "val_acc": 52.0}
{"epoch": 12, "training_loss": 0.7486158466339111, "training_acc": 43.0, "val_loss": 0.6986581039428711, "val_acc": 52.0}
{"epoch": 13, "training_loss": 0.6918097019195557, "training_acc": 53.0, "val_loss": 0.7135028266906738, "val_acc": 48.0}
{"epoch": 14, "training_loss": 0.7052211236953735, "training_acc": 49.0, "val_loss": 0.7110214328765869, "val_acc": 48.0}
{"epoch": 15, "training_loss": 0.7133377695083618, "training_acc": 43.0, "val_loss": 0.7161830997467041, "val_acc": 48.0}
{"epoch": 16, "training_loss": 0.7048752403259277, "training_acc": 51.0, "val_loss": 0.705883436203003, "val_acc": 52.0}
{"epoch": 17, "training_loss": 0.7033684873580932, "training_acc": 51.0, "val_loss": 0.7783773851394653, "val_acc": 48.0}
{"epoch": 18, "training_loss": 0.7526898860931397, "training_acc": 53.0, "val_loss": 0.7127255606651306, "val_acc": 52.0}
{"epoch": 19, "training_loss": 0.7548566555976868, "training_acc": 45.0, "val_loss": 0.6924523544311524, "val_acc": 52.0}
{"epoch": 20, "training_loss": 0.7406695246696472, "training_acc": 51.0, "val_loss": 0.7358131313323975, "val_acc": 52.0}
{"epoch": 21, "training_loss": 0.7125816059112549, "training_acc": 51.0, "val_loss": 0.7283251690864563, "val_acc": 48.0}
{"epoch": 22, "training_loss": 0.6864621901512146, "training_acc": 57.0, "val_loss": 0.8297514343261718, "val_acc": 52.0}
{"epoch": 23, "training_loss": 0.7661350274085998, "training_acc": 53.0, "val_loss": 0.9096241331100464, "val_acc": 48.0}
{"epoch": 24, "training_loss": 0.8799927806854249, "training_acc": 47.0, "val_loss": 0.75859605550766, "val_acc": 52.0}
{"epoch": 25, "training_loss": 0.8022588300704956, "training_acc": 55.0, "val_loss": 0.6962290215492248, "val_acc": 48.0}
{"epoch": 26, "training_loss": 0.7065425372123718, "training_acc": 53.0, "val_loss": 0.6980393290519714, "val_acc": 48.0}
{"epoch": 27, "training_loss": 0.7342102289199829, "training_acc": 45.0, "val_loss": 0.7014569449424743, "val_acc": 52.0}
{"epoch": 28, "training_loss": 0.6973081159591675, "training_acc": 53.0, "val_loss": 0.7379838180541992, "val_acc": 48.0}
{"epoch": 29, "training_loss": 0.7541581296920776, "training_acc": 47.0, "val_loss": 0.7082682275772094, "val_acc": 52.0}
{"epoch": 30, "training_loss": 0.7152954530715943, "training_acc": 49.0, "val_loss": 0.7203534603118896, "val_acc": 48.0}
{"epoch": 31, "training_loss": 0.7007547855377197, "training_acc": 53.0, "val_loss": 0.6947676920890808, "val_acc": 52.0}
{"epoch": 32, "training_loss": 0.7214785289764404, "training_acc": 45.0, "val_loss": 0.6930148649215698, "val_acc": 52.0}
{"epoch": 33, "training_loss": 0.7179766845703125, "training_acc": 45.0, "val_loss": 0.708075487613678, "val_acc": 48.0}
{"epoch": 34, "training_loss": 0.7059610939025879, "training_acc": 51.0, "val_loss": 0.8231866502761841, "val_acc": 48.0}
{"epoch": 35, "training_loss": 0.7640918159484863, "training_acc": 49.0, "val_loss": 0.7049166107177735, "val_acc": 52.0}
{"epoch": 36, "training_loss": 0.7568859910964966, "training_acc": 47.0, "val_loss": 0.6926604127883911, "val_acc": 52.0}
{"epoch": 37, "training_loss": 0.7165848016738892, "training_acc": 55.0, "val_loss": 0.7860726284980774, "val_acc": 48.0}
{"epoch": 38, "training_loss": 0.7983847427368164, "training_acc": 45.0, "val_loss": 0.7165836405754089, "val_acc": 48.0}
