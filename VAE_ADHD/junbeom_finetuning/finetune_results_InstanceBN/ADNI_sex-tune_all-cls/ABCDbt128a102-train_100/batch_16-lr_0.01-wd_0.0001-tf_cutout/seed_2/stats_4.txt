"main_modify.py --pretrained_path /scratch/connectome/dyhan316/VAE_ADHD/barlowtwins/pretrain_results/ABCDbt128a102.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 2 --task ADNI_sex --input_option BT_org --learning_rate 1e-2 --batch_size 16 --weight_decay 1e-4 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 1.1563859295845031, "training_acc": 47.0, "val_loss": 0.7024979019165039, "val_acc": 52.0}
{"epoch": 1, "training_loss": 0.7137474155426026, "training_acc": 49.0, "val_loss": 0.6932693934440612, "val_acc": 52.0}
{"epoch": 2, "training_loss": 0.7029391503334046, "training_acc": 55.0, "val_loss": 0.7345657181739808, "val_acc": 48.0}
{"epoch": 3, "training_loss": 0.7166368913650513, "training_acc": 51.0, "val_loss": 0.8722312998771667, "val_acc": 48.0}
{"epoch": 4, "training_loss": 0.7809525871276856, "training_acc": 47.0, "val_loss": 0.7186501049995422, "val_acc": 52.0}
{"epoch": 5, "training_loss": 0.7044439935684204, "training_acc": 55.0, "val_loss": 0.814416434764862, "val_acc": 48.0}
{"epoch": 6, "training_loss": 0.72237646818161, "training_acc": 57.0, "val_loss": 0.7238011145591736, "val_acc": 52.0}
{"epoch": 7, "training_loss": 0.7087395811080932, "training_acc": 53.0, "val_loss": 0.6951082634925843, "val_acc": 52.0}
{"epoch": 8, "training_loss": 0.7113253450393677, "training_acc": 45.0, "val_loss": 0.6982156085968018, "val_acc": 48.0}
{"epoch": 9, "training_loss": 0.7412589168548585, "training_acc": 50.0, "val_loss": 0.8805933094024658, "val_acc": 48.0}
{"epoch": 10, "training_loss": 0.8519395542144775, "training_acc": 49.0, "val_loss": 0.7124672245979309, "val_acc": 52.0}
{"epoch": 11, "training_loss": 0.7481957197189331, "training_acc": 43.0, "val_loss": 0.6927452778816223, "val_acc": 52.0}
{"epoch": 12, "training_loss": 0.7033525133132934, "training_acc": 45.0, "val_loss": 0.6930462288856506, "val_acc": 52.0}
{"epoch": 13, "training_loss": 0.7171944212913514, "training_acc": 53.0, "val_loss": 0.9142289400100708, "val_acc": 52.0}
{"epoch": 14, "training_loss": 0.9418625497817993, "training_acc": 43.0, "val_loss": 0.7687671899795532, "val_acc": 48.0}
{"epoch": 15, "training_loss": 0.795051417350769, "training_acc": 47.0, "val_loss": 0.7448125839233398, "val_acc": 48.0}
{"epoch": 16, "training_loss": 0.7721864604949951, "training_acc": 47.0, "val_loss": 0.7375227189064026, "val_acc": 52.0}
{"epoch": 17, "training_loss": 0.7770516920089722, "training_acc": 35.0, "val_loss": 0.7174152731895447, "val_acc": 52.0}
{"epoch": 18, "training_loss": 0.737069993019104, "training_acc": 55.0, "val_loss": 0.7909286546707154, "val_acc": 48.0}
{"epoch": 19, "training_loss": 0.7030175876617432, "training_acc": 51.0, "val_loss": 0.7764511632919312, "val_acc": 52.0}
{"epoch": 20, "training_loss": 0.8140599536895752, "training_acc": 41.0, "val_loss": 0.6976823878288269, "val_acc": 48.0}
{"epoch": 21, "training_loss": 0.7042407131195069, "training_acc": 50.0, "val_loss": 0.6964314222335816, "val_acc": 52.0}
{"epoch": 22, "training_loss": 0.7295479869842529, "training_acc": 43.0, "val_loss": 0.7221937417984009, "val_acc": 52.0}
{"epoch": 23, "training_loss": 0.8330249524116516, "training_acc": 47.0, "val_loss": 0.7982641172409057, "val_acc": 48.0}
{"epoch": 24, "training_loss": 0.7584457492828369, "training_acc": 45.0, "val_loss": 0.7800691962242127, "val_acc": 52.0}
{"epoch": 25, "training_loss": 0.7619686460494995, "training_acc": 49.0, "val_loss": 0.7704600238800049, "val_acc": 48.0}
{"epoch": 26, "training_loss": 0.7236705994606019, "training_acc": 51.0, "val_loss": 0.7102209067344666, "val_acc": 52.0}
{"epoch": 27, "training_loss": 0.77385005235672, "training_acc": 50.0, "val_loss": 0.827008330821991, "val_acc": 52.0}
{"epoch": 28, "training_loss": 0.7887853813171387, "training_acc": 53.0, "val_loss": 0.6933476996421813, "val_acc": 52.0}
