"main_modify.py --pretrained_path /scratch/connectome/dyhan316/VAE_ADHD/barlowtwins/pretrain_results/ABCDbt128a102.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 1 --task ADNI_sex --input_option BT_org --learning_rate 1e-3 --batch_size 16 --weight_decay 1e-2 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 0.7078540325164795, "training_acc": 46.0, "val_loss": 0.7084424543380737, "val_acc": 48.0}
{"epoch": 1, "training_loss": 0.7264918255805969, "training_acc": 50.0, "val_loss": 0.73019362449646, "val_acc": 48.0}
{"epoch": 2, "training_loss": 0.7097714042663574, "training_acc": 50.0, "val_loss": 0.6927173089981079, "val_acc": 52.0}
{"epoch": 3, "training_loss": 0.7080428838729859, "training_acc": 45.0, "val_loss": 0.6965849447250366, "val_acc": 48.0}
{"epoch": 4, "training_loss": 0.7023792362213135, "training_acc": 46.0, "val_loss": 0.6955709457397461, "val_acc": 48.0}
{"epoch": 5, "training_loss": 0.7095974683761597, "training_acc": 42.0, "val_loss": 0.6926878881454468, "val_acc": 52.0}
{"epoch": 6, "training_loss": 0.7079844045639038, "training_acc": 44.0, "val_loss": 0.6934898805618286, "val_acc": 52.0}
{"epoch": 7, "training_loss": 0.7036448860168457, "training_acc": 50.0, "val_loss": 0.6982629704475403, "val_acc": 48.0}
{"epoch": 8, "training_loss": 0.6987392711639404, "training_acc": 50.0, "val_loss": 0.6944834637641907, "val_acc": 48.0}
{"epoch": 9, "training_loss": 0.6968814420700074, "training_acc": 50.0, "val_loss": 0.6926207733154297, "val_acc": 52.0}
{"epoch": 10, "training_loss": 0.7068838381767273, "training_acc": 50.0, "val_loss": 0.7005943036079407, "val_acc": 48.0}
{"epoch": 11, "training_loss": 0.6991580986976623, "training_acc": 46.0, "val_loss": 0.6933337736129761, "val_acc": 48.0}
{"epoch": 12, "training_loss": 0.7002459239959716, "training_acc": 44.0, "val_loss": 0.6949748158454895, "val_acc": 48.0}
{"epoch": 13, "training_loss": 0.698977279663086, "training_acc": 52.0, "val_loss": 0.6993064451217651, "val_acc": 52.0}
{"epoch": 14, "training_loss": 0.7125690841674804, "training_acc": 46.0, "val_loss": 0.692433545589447, "val_acc": 52.0}
{"epoch": 15, "training_loss": 0.7206136989593506, "training_acc": 42.0, "val_loss": 0.6967678499221802, "val_acc": 52.0}
{"epoch": 16, "training_loss": 0.7045073747634888, "training_acc": 50.0, "val_loss": 0.6966297268867493, "val_acc": 48.0}
{"epoch": 17, "training_loss": 0.6997394561767578, "training_acc": 50.0, "val_loss": 0.6927402496337891, "val_acc": 52.0}
{"epoch": 18, "training_loss": 0.7049438953399658, "training_acc": 50.0, "val_loss": 0.6925216293334961, "val_acc": 52.0}
{"epoch": 19, "training_loss": 0.6926132225990296, "training_acc": 52.0, "val_loss": 0.7046498227119445, "val_acc": 48.0}
{"epoch": 20, "training_loss": 0.7103879070281982, "training_acc": 46.0, "val_loss": 0.6952540636062622, "val_acc": 48.0}
{"epoch": 21, "training_loss": 0.6972872018814087, "training_acc": 50.0, "val_loss": 0.7043370532989502, "val_acc": 48.0}
{"epoch": 22, "training_loss": 0.7041700220108033, "training_acc": 50.0, "val_loss": 0.6923675465583802, "val_acc": 52.0}
{"epoch": 23, "training_loss": 0.6993569707870484, "training_acc": 50.0, "val_loss": 0.6935456085205078, "val_acc": 52.0}
{"epoch": 24, "training_loss": 0.7134753465652466, "training_acc": 50.0, "val_loss": 0.7084020924568176, "val_acc": 48.0}
{"epoch": 25, "training_loss": 0.710813581943512, "training_acc": 50.0, "val_loss": 0.7121862316131592, "val_acc": 48.0}
{"epoch": 26, "training_loss": 0.7093079257011413, "training_acc": 42.0, "val_loss": 0.7001155495643616, "val_acc": 48.0}
{"epoch": 27, "training_loss": 0.7055208969116211, "training_acc": 50.0, "val_loss": 0.692347674369812, "val_acc": 52.0}
{"epoch": 28, "training_loss": 0.7276177000999451, "training_acc": 50.0, "val_loss": 0.6926640391349792, "val_acc": 52.0}
{"epoch": 29, "training_loss": 0.7139907002449035, "training_acc": 44.0, "val_loss": 0.6934330248832703, "val_acc": 48.0}
{"epoch": 30, "training_loss": 0.692931034564972, "training_acc": 52.0, "val_loss": 0.6950122141838073, "val_acc": 52.0}
{"epoch": 31, "training_loss": 0.7023371458053589, "training_acc": 44.0, "val_loss": 0.6933974575996399, "val_acc": 48.0}
{"epoch": 32, "training_loss": 0.6954758238792419, "training_acc": 48.0, "val_loss": 0.697008113861084, "val_acc": 48.0}
{"epoch": 33, "training_loss": 0.7075297927856445, "training_acc": 46.0, "val_loss": 0.7038791608810425, "val_acc": 48.0}
{"epoch": 34, "training_loss": 0.7035707998275756, "training_acc": 50.0, "val_loss": 0.6925106287002564, "val_acc": 52.0}
{"epoch": 35, "training_loss": 0.6978707695007325, "training_acc": 48.0, "val_loss": 0.6923488569259644, "val_acc": 52.0}
{"epoch": 36, "training_loss": 0.6992290472984314, "training_acc": 46.0, "val_loss": 0.6931701612472534, "val_acc": 52.0}
{"epoch": 37, "training_loss": 0.7063008308410644, "training_acc": 50.0, "val_loss": 0.6923573660850525, "val_acc": 52.0}
{"epoch": 38, "training_loss": 0.6997081756591796, "training_acc": 46.0, "val_loss": 0.6953263592720031, "val_acc": 48.0}
{"epoch": 39, "training_loss": 0.6932348155975342, "training_acc": 50.0, "val_loss": 0.6929023098945618, "val_acc": 52.0}
{"epoch": 40, "training_loss": 0.7023717093467713, "training_acc": 44.0, "val_loss": 0.6926902842521667, "val_acc": 52.0}
{"epoch": 41, "training_loss": 0.6984752702713013, "training_acc": 50.0, "val_loss": 0.6969428944587708, "val_acc": 48.0}
{"epoch": 42, "training_loss": 0.7039558601379394, "training_acc": 44.0, "val_loss": 0.6941880774497986, "val_acc": 48.0}
{"epoch": 43, "training_loss": 0.7020827889442444, "training_acc": 42.0, "val_loss": 0.6928144025802613, "val_acc": 52.0}
{"epoch": 44, "training_loss": 0.6973889684677124, "training_acc": 50.0, "val_loss": 0.6992696619033814, "val_acc": 48.0}
{"epoch": 45, "training_loss": 0.706406273841858, "training_acc": 50.0, "val_loss": 0.6925187015533447, "val_acc": 52.0}
{"epoch": 46, "training_loss": 0.7165053033828735, "training_acc": 50.0, "val_loss": 0.6930066776275635, "val_acc": 52.0}
