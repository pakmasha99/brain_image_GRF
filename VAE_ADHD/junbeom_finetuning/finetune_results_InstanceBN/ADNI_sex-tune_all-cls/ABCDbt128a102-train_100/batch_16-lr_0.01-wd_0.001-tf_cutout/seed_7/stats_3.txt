"main_modify.py --pretrained_path /scratch/connectome/dyhan316/VAE_ADHD/barlowtwins/pretrain_results/ABCDbt128a102.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 7 --task ADNI_sex --input_option BT_org --learning_rate 1e-2 --batch_size 16 --weight_decay 1e-3 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 1.2055327224731445, "training_acc": 48.0, "val_loss": 0.6963496327400207, "val_acc": 52.0}
{"epoch": 1, "training_loss": 0.8536695528030396, "training_acc": 50.0, "val_loss": 0.7459236145019531, "val_acc": 52.0}
{"epoch": 2, "training_loss": 0.7263143539428711, "training_acc": 44.0, "val_loss": 0.8124967694282532, "val_acc": 48.0}
{"epoch": 3, "training_loss": 0.7472635078430175, "training_acc": 48.0, "val_loss": 0.7248117065429688, "val_acc": 52.0}
{"epoch": 4, "training_loss": 0.7907753205299377, "training_acc": 48.0, "val_loss": 0.7141335988044739, "val_acc": 48.0}
{"epoch": 5, "training_loss": 0.7237751960754395, "training_acc": 54.0, "val_loss": 0.6956093907356262, "val_acc": 48.0}
{"epoch": 6, "training_loss": 0.7465136456489563, "training_acc": 40.0, "val_loss": 0.734921019077301, "val_acc": 48.0}
{"epoch": 7, "training_loss": 0.7145571517944336, "training_acc": 48.0, "val_loss": 0.707397997379303, "val_acc": 52.0}
{"epoch": 8, "training_loss": 0.7245332574844361, "training_acc": 52.0, "val_loss": 0.7926741075515747, "val_acc": 48.0}
{"epoch": 9, "training_loss": 0.7670052123069763, "training_acc": 46.0, "val_loss": 0.9399001359939575, "val_acc": 48.0}
{"epoch": 10, "training_loss": 0.9027949571609497, "training_acc": 46.0, "val_loss": 0.699613254070282, "val_acc": 48.0}
{"epoch": 11, "training_loss": 0.7498844385147094, "training_acc": 54.0, "val_loss": 0.8506655049324036, "val_acc": 52.0}
{"epoch": 12, "training_loss": 0.7176638221740723, "training_acc": 58.0, "val_loss": 0.7648129487037658, "val_acc": 48.0}
{"epoch": 13, "training_loss": 0.7674043846130371, "training_acc": 42.0, "val_loss": 0.6979311299324036, "val_acc": 52.0}
{"epoch": 14, "training_loss": 0.7254982089996338, "training_acc": 44.0, "val_loss": 0.7113455271720887, "val_acc": 48.0}
{"epoch": 15, "training_loss": 0.6950938439369202, "training_acc": 54.0, "val_loss": 0.9449823093414307, "val_acc": 52.0}
{"epoch": 16, "training_loss": 0.8532011699676514, "training_acc": 54.0, "val_loss": 0.8799488115310669, "val_acc": 48.0}
{"epoch": 17, "training_loss": 0.8055919194221497, "training_acc": 48.0, "val_loss": 0.9073597669601441, "val_acc": 48.0}
{"epoch": 18, "training_loss": 0.9160031843185424, "training_acc": 50.0, "val_loss": 0.8019942951202392, "val_acc": 52.0}
{"epoch": 19, "training_loss": 0.7602658033370971, "training_acc": 48.0, "val_loss": 0.7889588904380799, "val_acc": 52.0}
{"epoch": 20, "training_loss": 0.8028357362747193, "training_acc": 50.0, "val_loss": 0.7570797872543334, "val_acc": 48.0}
{"epoch": 21, "training_loss": 0.6958700704574585, "training_acc": 54.0, "val_loss": 0.694365246295929, "val_acc": 52.0}
{"epoch": 22, "training_loss": 0.7813277554512024, "training_acc": 42.0, "val_loss": 0.8604768323898315, "val_acc": 52.0}
{"epoch": 23, "training_loss": 0.7606339359283447, "training_acc": 54.0, "val_loss": 0.6962913155555726, "val_acc": 52.0}
{"epoch": 24, "training_loss": 0.7600051832199096, "training_acc": 46.0, "val_loss": 0.6934519338607789, "val_acc": 52.0}
{"epoch": 25, "training_loss": 0.7086616706848144, "training_acc": 50.0, "val_loss": 0.730940670967102, "val_acc": 48.0}
{"epoch": 26, "training_loss": 0.7678675079345703, "training_acc": 50.0, "val_loss": 0.7501556730270386, "val_acc": 48.0}
{"epoch": 27, "training_loss": 0.8594800305366516, "training_acc": 44.0, "val_loss": 0.7973748874664307, "val_acc": 52.0}
{"epoch": 28, "training_loss": 0.7407233333587646, "training_acc": 56.0, "val_loss": 0.7150090122222901, "val_acc": 48.0}
{"epoch": 29, "training_loss": 0.7416128230094909, "training_acc": 50.0, "val_loss": 0.794350574016571, "val_acc": 48.0}
{"epoch": 30, "training_loss": 0.8009293556213379, "training_acc": 44.0, "val_loss": 0.693550841808319, "val_acc": 52.0}
{"epoch": 31, "training_loss": 0.705297532081604, "training_acc": 46.0, "val_loss": 0.6937685513496399, "val_acc": 52.0}
{"epoch": 32, "training_loss": 0.7540030479431152, "training_acc": 44.0, "val_loss": 0.6924192881584168, "val_acc": 52.0}
{"epoch": 33, "training_loss": 0.7049824953079223, "training_acc": 54.0, "val_loss": 0.8980947804450988, "val_acc": 48.0}
{"epoch": 34, "training_loss": 0.9158032393455505, "training_acc": 42.0, "val_loss": 0.7160489654541016, "val_acc": 52.0}
{"epoch": 35, "training_loss": 0.7032942485809326, "training_acc": 52.0, "val_loss": 0.6923477840423584, "val_acc": 52.0}
{"epoch": 36, "training_loss": 0.7732767248153687, "training_acc": 46.0, "val_loss": 0.7001447558403016, "val_acc": 48.0}
{"epoch": 37, "training_loss": 0.7279970216751098, "training_acc": 50.0, "val_loss": 0.731036262512207, "val_acc": 48.0}
{"epoch": 38, "training_loss": 0.714101345539093, "training_acc": 46.0, "val_loss": 0.71704425573349, "val_acc": 48.0}
{"epoch": 39, "training_loss": 0.7295609426498413, "training_acc": 46.0, "val_loss": 0.7022954392433166, "val_acc": 48.0}
{"epoch": 40, "training_loss": 0.7635485720634461, "training_acc": 50.0, "val_loss": 0.7351682376861572, "val_acc": 52.0}
{"epoch": 41, "training_loss": 0.8096265697479248, "training_acc": 48.0, "val_loss": 0.7292542958259582, "val_acc": 48.0}
{"epoch": 42, "training_loss": 0.7247765350341797, "training_acc": 44.0, "val_loss": 0.7125119757652283, "val_acc": 48.0}
{"epoch": 43, "training_loss": 0.7264686059951783, "training_acc": 50.0, "val_loss": 0.69239173412323, "val_acc": 52.0}
{"epoch": 44, "training_loss": 0.6999407052993775, "training_acc": 50.0, "val_loss": 0.7006986594200134, "val_acc": 48.0}
{"epoch": 45, "training_loss": 0.7157264471054077, "training_acc": 52.0, "val_loss": 0.6944301915168762, "val_acc": 52.0}
{"epoch": 46, "training_loss": 0.7368507409095764, "training_acc": 50.0, "val_loss": 0.7608772110939026, "val_acc": 48.0}
{"epoch": 47, "training_loss": 0.7260995531082153, "training_acc": 48.0, "val_loss": 0.7062604904174805, "val_acc": 52.0}
{"epoch": 48, "training_loss": 0.7135702800750733, "training_acc": 50.0, "val_loss": 0.6990984344482422, "val_acc": 48.0}
{"epoch": 49, "training_loss": 0.7027307796478272, "training_acc": 46.0, "val_loss": 0.7220477366447449, "val_acc": 48.0}
{"epoch": 50, "training_loss": 0.7486717081069947, "training_acc": 50.0, "val_loss": 0.731646888256073, "val_acc": 52.0}
{"epoch": 51, "training_loss": 0.7291108798980713, "training_acc": 52.0, "val_loss": 0.8430654501914978, "val_acc": 48.0}
{"epoch": 52, "training_loss": 0.7927537298202515, "training_acc": 48.0, "val_loss": 0.7366878819465638, "val_acc": 52.0}
{"epoch": 53, "training_loss": 0.7226006269454956, "training_acc": 50.0, "val_loss": 0.7167803406715393, "val_acc": 48.0}
{"epoch": 54, "training_loss": 0.7103501892089844, "training_acc": 46.0, "val_loss": 0.6925908970832825, "val_acc": 52.0}
