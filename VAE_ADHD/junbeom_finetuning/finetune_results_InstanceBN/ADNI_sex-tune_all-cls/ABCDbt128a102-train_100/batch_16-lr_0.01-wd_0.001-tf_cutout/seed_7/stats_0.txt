"main_modify.py --pretrained_path /scratch/connectome/dyhan316/VAE_ADHD/barlowtwins/pretrain_results/ABCDbt128a102.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 7 --task ADNI_sex --input_option BT_org --learning_rate 1e-2 --batch_size 16 --weight_decay 1e-3 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 0.9460294580459595, "training_acc": 50.0, "val_loss": 0.6965412259101867, "val_acc": 48.0}
{"epoch": 1, "training_loss": 0.8384164357185364, "training_acc": 45.0, "val_loss": 0.7035001730918884, "val_acc": 48.0}
{"epoch": 2, "training_loss": 0.7124821710586547, "training_acc": 51.0, "val_loss": 0.9286399579048157, "val_acc": 48.0}
{"epoch": 3, "training_loss": 0.848531494140625, "training_acc": 45.0, "val_loss": 0.7226653385162354, "val_acc": 48.0}
{"epoch": 4, "training_loss": 0.7551968383789063, "training_acc": 47.0, "val_loss": 0.6931875562667846, "val_acc": 48.0}
{"epoch": 5, "training_loss": 0.7257621598243713, "training_acc": 47.0, "val_loss": 0.7422150039672851, "val_acc": 52.0}
{"epoch": 6, "training_loss": 0.7857109832763672, "training_acc": 45.0, "val_loss": 0.6930983281135559, "val_acc": 52.0}
{"epoch": 7, "training_loss": 0.696061315536499, "training_acc": 55.0, "val_loss": 0.9208908224105835, "val_acc": 48.0}
{"epoch": 8, "training_loss": 0.8892678070068359, "training_acc": 49.0, "val_loss": 0.7288620591163635, "val_acc": 52.0}
{"epoch": 9, "training_loss": 0.7428000593185424, "training_acc": 49.0, "val_loss": 0.6928238606452942, "val_acc": 52.0}
{"epoch": 10, "training_loss": 0.7103314256668091, "training_acc": 43.0, "val_loss": 0.7346045637130737, "val_acc": 52.0}
{"epoch": 11, "training_loss": 0.7332845497131347, "training_acc": 43.0, "val_loss": 0.7091045331954956, "val_acc": 52.0}
{"epoch": 12, "training_loss": 0.7391868305206298, "training_acc": 47.0, "val_loss": 0.7043358492851257, "val_acc": 48.0}
{"epoch": 13, "training_loss": 0.7080861735343933, "training_acc": 55.0, "val_loss": 0.8021052622795105, "val_acc": 52.0}
{"epoch": 14, "training_loss": 0.7109727692604065, "training_acc": 53.0, "val_loss": 0.7770695805549621, "val_acc": 48.0}
{"epoch": 15, "training_loss": 0.7394398927688599, "training_acc": 45.0, "val_loss": 0.7942566299438476, "val_acc": 48.0}
{"epoch": 16, "training_loss": 0.7616707897186279, "training_acc": 49.0, "val_loss": 0.723140676021576, "val_acc": 52.0}
{"epoch": 17, "training_loss": 0.7308896040916443, "training_acc": 45.0, "val_loss": 0.7614354634284973, "val_acc": 48.0}
{"epoch": 18, "training_loss": 0.7916042852401733, "training_acc": 41.0, "val_loss": 0.6928921866416932, "val_acc": 52.0}
{"epoch": 19, "training_loss": 0.7276625561714173, "training_acc": 43.0, "val_loss": 0.7737033700942993, "val_acc": 48.0}
{"epoch": 20, "training_loss": 0.7459070777893066, "training_acc": 49.0, "val_loss": 0.7061668801307678, "val_acc": 52.0}
{"epoch": 21, "training_loss": 0.7546282148361206, "training_acc": 43.0, "val_loss": 0.7965263485908508, "val_acc": 48.0}
{"epoch": 22, "training_loss": 0.7755228137969971, "training_acc": 49.0, "val_loss": 0.6924797320365905, "val_acc": 52.0}
{"epoch": 23, "training_loss": 0.7784170532226562, "training_acc": 45.0, "val_loss": 0.7348213815689086, "val_acc": 52.0}
{"epoch": 24, "training_loss": 0.6815158915519715, "training_acc": 57.0, "val_loss": 1.0469764733314515, "val_acc": 48.0}
{"epoch": 25, "training_loss": 0.9018262982368469, "training_acc": 47.0, "val_loss": 0.7401691365242005, "val_acc": 48.0}
{"epoch": 26, "training_loss": 0.7212509965896606, "training_acc": 53.0, "val_loss": 0.8158498072624206, "val_acc": 52.0}
{"epoch": 27, "training_loss": 0.8679922699928284, "training_acc": 43.0, "val_loss": 0.7216110825538635, "val_acc": 52.0}
{"epoch": 28, "training_loss": 0.7734873032569886, "training_acc": 47.0, "val_loss": 0.6938067603111268, "val_acc": 48.0}
{"epoch": 29, "training_loss": 0.701564884185791, "training_acc": 45.0, "val_loss": 0.8427444005012512, "val_acc": 48.0}
{"epoch": 30, "training_loss": 0.8383437991142273, "training_acc": 55.0, "val_loss": 0.8947550964355468, "val_acc": 52.0}
{"epoch": 31, "training_loss": 0.7982788705825805, "training_acc": 49.0, "val_loss": 0.6942399573326111, "val_acc": 52.0}
{"epoch": 32, "training_loss": 0.7638848340511322, "training_acc": 51.0, "val_loss": 1.0680982923507691, "val_acc": 48.0}
{"epoch": 33, "training_loss": 0.9080365324020385, "training_acc": 43.0, "val_loss": 0.6986231446266175, "val_acc": 52.0}
{"epoch": 34, "training_loss": 0.7147615242004395, "training_acc": 47.0, "val_loss": 0.7273026013374329, "val_acc": 52.0}
{"epoch": 35, "training_loss": 0.7573800277709961, "training_acc": 41.0, "val_loss": 0.7475793385505676, "val_acc": 52.0}
{"epoch": 36, "training_loss": 0.7466589164733887, "training_acc": 49.0, "val_loss": 0.6926946187019348, "val_acc": 52.0}
{"epoch": 37, "training_loss": 0.7339449882507324, "training_acc": 49.0, "val_loss": 0.7203389143943787, "val_acc": 52.0}
{"epoch": 38, "training_loss": 0.7638291025161743, "training_acc": 43.0, "val_loss": 0.6947313022613525, "val_acc": 52.0}
{"epoch": 39, "training_loss": 0.7738706421852112, "training_acc": 47.0, "val_loss": 0.696236879825592, "val_acc": 52.0}
{"epoch": 40, "training_loss": 0.7379061985015869, "training_acc": 49.0, "val_loss": 0.7737373852729797, "val_acc": 48.0}
{"epoch": 41, "training_loss": 0.7191201257705688, "training_acc": 49.0, "val_loss": 0.693093569278717, "val_acc": 52.0}
