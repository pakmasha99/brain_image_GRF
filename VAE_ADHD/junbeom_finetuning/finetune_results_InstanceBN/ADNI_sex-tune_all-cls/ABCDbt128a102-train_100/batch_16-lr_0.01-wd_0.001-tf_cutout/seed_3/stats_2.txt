"main_modify.py --pretrained_path /scratch/connectome/dyhan316/VAE_ADHD/barlowtwins/pretrain_results/ABCDbt128a102.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 3 --task ADNI_sex --input_option BT_org --learning_rate 1e-2 --batch_size 16 --weight_decay 1e-3 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 1.3561910700798034, "training_acc": 46.0, "val_loss": 0.6975720691680908, "val_acc": 48.0}
{"epoch": 1, "training_loss": 0.7367349433898925, "training_acc": 50.0, "val_loss": 0.736595847606659, "val_acc": 48.0}
{"epoch": 2, "training_loss": 0.742279314994812, "training_acc": 54.0, "val_loss": 0.719128680229187, "val_acc": 48.0}
{"epoch": 3, "training_loss": 0.7142300605773926, "training_acc": 50.0, "val_loss": 0.7817769765853881, "val_acc": 48.0}
{"epoch": 4, "training_loss": 0.7322487354278564, "training_acc": 52.0, "val_loss": 0.8065574383735656, "val_acc": 52.0}
{"epoch": 5, "training_loss": 0.760284333229065, "training_acc": 52.0, "val_loss": 0.6929039072990417, "val_acc": 52.0}
{"epoch": 6, "training_loss": 0.7044592094421387, "training_acc": 54.0, "val_loss": 0.9650232243537903, "val_acc": 48.0}
{"epoch": 7, "training_loss": 0.9317361783981323, "training_acc": 46.0, "val_loss": 0.709561915397644, "val_acc": 52.0}
{"epoch": 8, "training_loss": 0.7817355346679687, "training_acc": 48.0, "val_loss": 0.9758266520500183, "val_acc": 52.0}
{"epoch": 9, "training_loss": 0.9948294925689697, "training_acc": 50.0, "val_loss": 0.8295818018913269, "val_acc": 48.0}
{"epoch": 10, "training_loss": 0.7655139064788818, "training_acc": 52.0, "val_loss": 0.7871982645988465, "val_acc": 48.0}
{"epoch": 11, "training_loss": 0.7285036540031433, "training_acc": 56.0, "val_loss": 0.8753155493736267, "val_acc": 52.0}
{"epoch": 12, "training_loss": 0.7889387130737304, "training_acc": 50.0, "val_loss": 0.7024894428253173, "val_acc": 52.0}
{"epoch": 13, "training_loss": 0.7622851800918579, "training_acc": 40.0, "val_loss": 0.693164074420929, "val_acc": 48.0}
{"epoch": 14, "training_loss": 0.704211950302124, "training_acc": 54.0, "val_loss": 0.7339447474479676, "val_acc": 52.0}
{"epoch": 15, "training_loss": 0.7940395927429199, "training_acc": 44.0, "val_loss": 0.8820034003257752, "val_acc": 52.0}
{"epoch": 16, "training_loss": 0.9953392124176026, "training_acc": 46.0, "val_loss": 0.8311972808837891, "val_acc": 48.0}
{"epoch": 17, "training_loss": 0.8251731467247009, "training_acc": 36.0, "val_loss": 0.6943506336212159, "val_acc": 52.0}
{"epoch": 18, "training_loss": 0.7579189205169677, "training_acc": 48.0, "val_loss": 0.7591554641723632, "val_acc": 48.0}
{"epoch": 19, "training_loss": 0.7046647000312806, "training_acc": 54.0, "val_loss": 0.7561062622070313, "val_acc": 52.0}
{"epoch": 20, "training_loss": 0.7820496606826782, "training_acc": 42.0, "val_loss": 0.6982612347602845, "val_acc": 52.0}
{"epoch": 21, "training_loss": 0.7108019351959228, "training_acc": 46.0, "val_loss": 0.7756912732124328, "val_acc": 52.0}
{"epoch": 22, "training_loss": 0.7501774048805236, "training_acc": 48.0, "val_loss": 0.7039547920227051, "val_acc": 48.0}
{"epoch": 23, "training_loss": 0.7486429262161255, "training_acc": 48.0, "val_loss": 0.7289401006698608, "val_acc": 48.0}
{"epoch": 24, "training_loss": 0.7395280933380127, "training_acc": 46.0, "val_loss": 0.7384164309501648, "val_acc": 48.0}
{"epoch": 25, "training_loss": 0.7103667759895325, "training_acc": 46.0, "val_loss": 0.6923530268669128, "val_acc": 52.0}
{"epoch": 26, "training_loss": 0.786725046634674, "training_acc": 40.0, "val_loss": 0.9702519249916076, "val_acc": 52.0}
{"epoch": 27, "training_loss": 0.92994699716568, "training_acc": 40.0, "val_loss": 0.6993334817886353, "val_acc": 52.0}
{"epoch": 28, "training_loss": 0.7293703651428223, "training_acc": 50.0, "val_loss": 0.6926613807678222, "val_acc": 52.0}
{"epoch": 29, "training_loss": 0.7285607194900513, "training_acc": 48.0, "val_loss": 0.7151740908622741, "val_acc": 48.0}
{"epoch": 30, "training_loss": 0.7542167520523071, "training_acc": 50.0, "val_loss": 0.7073045086860656, "val_acc": 48.0}
{"epoch": 31, "training_loss": 0.723033537864685, "training_acc": 52.0, "val_loss": 0.7079315495491028, "val_acc": 52.0}
{"epoch": 32, "training_loss": 0.7332332372665405, "training_acc": 48.0, "val_loss": 0.8332193875312806, "val_acc": 52.0}
{"epoch": 33, "training_loss": 0.7901833248138428, "training_acc": 50.0, "val_loss": 0.6934674048423767, "val_acc": 48.0}
{"epoch": 34, "training_loss": 0.7190918135643005, "training_acc": 50.0, "val_loss": 0.8994636297225952, "val_acc": 48.0}
{"epoch": 35, "training_loss": 0.8809739494323731, "training_acc": 50.0, "val_loss": 0.6984105753898621, "val_acc": 52.0}
{"epoch": 36, "training_loss": 0.8610235786437989, "training_acc": 42.0, "val_loss": 0.6985738158226014, "val_acc": 52.0}
{"epoch": 37, "training_loss": 0.8157097005844116, "training_acc": 52.0, "val_loss": 0.9863797092437744, "val_acc": 52.0}
{"epoch": 38, "training_loss": 0.8964313840866089, "training_acc": 56.0, "val_loss": 1.1643495416641236, "val_acc": 48.0}
{"epoch": 39, "training_loss": 0.8533679080009461, "training_acc": 52.0, "val_loss": 0.7845429992675781, "val_acc": 52.0}
{"epoch": 40, "training_loss": 0.7764002990722656, "training_acc": 50.0, "val_loss": 0.6937253713607788, "val_acc": 52.0}
{"epoch": 41, "training_loss": 0.7116902160644532, "training_acc": 52.0, "val_loss": 0.7289450120925903, "val_acc": 48.0}
{"epoch": 42, "training_loss": 0.7179281067848206, "training_acc": 42.0, "val_loss": 0.6923482966423035, "val_acc": 52.0}
{"epoch": 43, "training_loss": 0.6987913870811462, "training_acc": 46.0, "val_loss": 0.704182059764862, "val_acc": 48.0}
{"epoch": 44, "training_loss": 0.7066037368774414, "training_acc": 50.0, "val_loss": 0.7312462353706359, "val_acc": 52.0}
{"epoch": 45, "training_loss": 0.7754975748062134, "training_acc": 50.0, "val_loss": 0.7758726835250854, "val_acc": 48.0}
{"epoch": 46, "training_loss": 0.751623182296753, "training_acc": 46.0, "val_loss": 0.6932924580574036, "val_acc": 48.0}
{"epoch": 47, "training_loss": 0.7785806035995484, "training_acc": 48.0, "val_loss": 0.7706938862800599, "val_acc": 52.0}
{"epoch": 48, "training_loss": 0.7328833436965942, "training_acc": 48.0, "val_loss": 0.7204751920700073, "val_acc": 48.0}
{"epoch": 49, "training_loss": 0.7261219120025635, "training_acc": 50.0, "val_loss": 0.6942826581001281, "val_acc": 48.0}
{"epoch": 50, "training_loss": 0.7210140419006348, "training_acc": 50.0, "val_loss": 0.7247531485557556, "val_acc": 52.0}
{"epoch": 51, "training_loss": 0.7708908891677857, "training_acc": 50.0, "val_loss": 0.7916776585578919, "val_acc": 48.0}
{"epoch": 52, "training_loss": 0.7721938276290894, "training_acc": 46.0, "val_loss": 0.7130707836151123, "val_acc": 52.0}
{"epoch": 53, "training_loss": 0.6881183385848999, "training_acc": 58.0, "val_loss": 0.7790544986724853, "val_acc": 48.0}
{"epoch": 54, "training_loss": 0.7687103939056397, "training_acc": 52.0, "val_loss": 0.848976891040802, "val_acc": 52.0}
{"epoch": 55, "training_loss": 0.8807781124114991, "training_acc": 44.0, "val_loss": 0.7369521355628967, "val_acc": 48.0}
{"epoch": 56, "training_loss": 0.7075470662117005, "training_acc": 48.0, "val_loss": 0.6992718982696533, "val_acc": 52.0}
{"epoch": 57, "training_loss": 0.7269206237792969, "training_acc": 46.0, "val_loss": 0.6935236859321594, "val_acc": 52.0}
{"epoch": 58, "training_loss": 0.7295770072937011, "training_acc": 46.0, "val_loss": 0.6924600505828857, "val_acc": 52.0}
{"epoch": 59, "training_loss": 0.7012271165847779, "training_acc": 50.0, "val_loss": 0.6923691534996033, "val_acc": 52.0}
{"epoch": 60, "training_loss": 0.7116331005096436, "training_acc": 42.0, "val_loss": 0.7009108209609985, "val_acc": 48.0}
{"epoch": 61, "training_loss": 0.7205066108703613, "training_acc": 44.0, "val_loss": 0.6936385798454284, "val_acc": 48.0}
