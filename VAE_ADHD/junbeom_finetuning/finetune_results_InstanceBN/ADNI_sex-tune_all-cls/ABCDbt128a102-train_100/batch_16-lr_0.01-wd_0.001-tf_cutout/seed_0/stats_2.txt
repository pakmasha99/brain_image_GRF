"main_modify.py --pretrained_path /scratch/connectome/dyhan316/VAE_ADHD/barlowtwins/pretrain_results/ABCDbt128a102.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ADNI_sex --input_option BT_org --learning_rate 1e-2 --batch_size 16 --weight_decay 1e-3 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 1.3337636280059815, "training_acc": 42.0, "val_loss": 0.6995217180252076, "val_acc": 48.0}
{"epoch": 1, "training_loss": 0.8801813554763794, "training_acc": 46.0, "val_loss": 0.8113898491859436, "val_acc": 48.0}
{"epoch": 2, "training_loss": 0.8192030477523804, "training_acc": 42.0, "val_loss": 0.7107066822052002, "val_acc": 48.0}
{"epoch": 3, "training_loss": 0.7715526485443115, "training_acc": 48.0, "val_loss": 0.7060531830787659, "val_acc": 52.0}
{"epoch": 4, "training_loss": 0.7879319715499878, "training_acc": 44.0, "val_loss": 0.9037557888031006, "val_acc": 52.0}
{"epoch": 5, "training_loss": 0.9948457562923432, "training_acc": 52.0, "val_loss": 1.4095642280578613, "val_acc": 48.0}
{"epoch": 6, "training_loss": 1.1220186853408813, "training_acc": 50.0, "val_loss": 0.964714093208313, "val_acc": 52.0}
{"epoch": 7, "training_loss": 0.8232378435134887, "training_acc": 50.0, "val_loss": 0.7110340785980225, "val_acc": 48.0}
{"epoch": 8, "training_loss": 0.72331716299057, "training_acc": 40.0, "val_loss": 0.8106941223144531, "val_acc": 52.0}
{"epoch": 9, "training_loss": 0.8720353078842163, "training_acc": 48.0, "val_loss": 0.8876336216926575, "val_acc": 48.0}
{"epoch": 10, "training_loss": 0.7859359788894653, "training_acc": 48.0, "val_loss": 0.6928665232658386, "val_acc": 52.0}
{"epoch": 11, "training_loss": 0.7048982691764831, "training_acc": 50.0, "val_loss": 0.7276207089424134, "val_acc": 52.0}
{"epoch": 12, "training_loss": 0.7605548810958862, "training_acc": 54.0, "val_loss": 0.7633976435661316, "val_acc": 48.0}
{"epoch": 13, "training_loss": 0.7339995241165161, "training_acc": 44.0, "val_loss": 0.6936156368255615, "val_acc": 48.0}
{"epoch": 14, "training_loss": 0.7262914943695068, "training_acc": 46.0, "val_loss": 0.6951845741271973, "val_acc": 52.0}
{"epoch": 15, "training_loss": 0.7325981831550599, "training_acc": 42.0, "val_loss": 0.6952096891403198, "val_acc": 48.0}
{"epoch": 16, "training_loss": 0.7361591243743897, "training_acc": 50.0, "val_loss": 0.7067413067817688, "val_acc": 52.0}
{"epoch": 17, "training_loss": 0.6983483982086182, "training_acc": 52.0, "val_loss": 0.7364475393295288, "val_acc": 52.0}
{"epoch": 18, "training_loss": 0.7062308049201965, "training_acc": 56.0, "val_loss": 0.8921794128417969, "val_acc": 48.0}
{"epoch": 19, "training_loss": 0.8039413642883301, "training_acc": 50.0, "val_loss": 0.6954353833198548, "val_acc": 52.0}
{"epoch": 20, "training_loss": 0.6846258556842804, "training_acc": 56.0, "val_loss": 0.9481731081008911, "val_acc": 48.0}
{"epoch": 21, "training_loss": 0.9624394464492798, "training_acc": 40.0, "val_loss": 0.8104885578155517, "val_acc": 48.0}
{"epoch": 22, "training_loss": 0.7986223363876342, "training_acc": 48.0, "val_loss": 0.7238655185699463, "val_acc": 52.0}
{"epoch": 23, "training_loss": 0.7437176966667175, "training_acc": 50.0, "val_loss": 0.8720513844490051, "val_acc": 52.0}
{"epoch": 24, "training_loss": 0.7678130435943603, "training_acc": 52.0, "val_loss": 0.815554232597351, "val_acc": 48.0}
{"epoch": 25, "training_loss": 0.7452380847930908, "training_acc": 46.0, "val_loss": 0.7826955771446228, "val_acc": 48.0}
{"epoch": 26, "training_loss": 0.8017734289169312, "training_acc": 42.0, "val_loss": 0.7714717936515808, "val_acc": 48.0}
{"epoch": 27, "training_loss": 0.7482077836990356, "training_acc": 50.0, "val_loss": 0.6956423497200013, "val_acc": 48.0}
{"epoch": 28, "training_loss": 0.7133950686454773, "training_acc": 50.0, "val_loss": 0.7706090259552002, "val_acc": 52.0}
{"epoch": 29, "training_loss": 0.7374114537239075, "training_acc": 56.0, "val_loss": 0.9153315663337708, "val_acc": 48.0}
