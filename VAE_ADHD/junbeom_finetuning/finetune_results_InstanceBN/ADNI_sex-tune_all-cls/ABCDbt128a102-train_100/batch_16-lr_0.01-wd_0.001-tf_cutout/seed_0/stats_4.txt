"main_modify.py --pretrained_path /scratch/connectome/dyhan316/VAE_ADHD/barlowtwins/pretrain_results/ABCDbt128a102.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ADNI_sex --input_option BT_org --learning_rate 1e-2 --batch_size 16 --weight_decay 1e-3 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 0.9909399127960206, "training_acc": 54.0, "val_loss": 0.7682454872131348, "val_acc": 48.0}
{"epoch": 1, "training_loss": 0.8179125881195068, "training_acc": 58.0, "val_loss": 0.813556261062622, "val_acc": 52.0}
{"epoch": 2, "training_loss": 0.809999942779541, "training_acc": 50.0, "val_loss": 0.8916980099678039, "val_acc": 52.0}
{"epoch": 3, "training_loss": 0.7557295799255371, "training_acc": 56.0, "val_loss": 0.9206481981277466, "val_acc": 48.0}
{"epoch": 4, "training_loss": 0.799288649559021, "training_acc": 46.0, "val_loss": 0.7437031626701355, "val_acc": 48.0}
{"epoch": 5, "training_loss": 0.6934866380691528, "training_acc": 60.0, "val_loss": 1.20080153465271, "val_acc": 52.0}
{"epoch": 6, "training_loss": 0.909210147857666, "training_acc": 58.0, "val_loss": 1.0959507465362548, "val_acc": 48.0}
{"epoch": 7, "training_loss": 0.8630840349197387, "training_acc": 46.0, "val_loss": 0.6929276204109192, "val_acc": 52.0}
{"epoch": 8, "training_loss": 0.7107618904113769, "training_acc": 52.0, "val_loss": 0.7162858891487122, "val_acc": 48.0}
{"epoch": 9, "training_loss": 0.7396435737609863, "training_acc": 52.0, "val_loss": 0.7661205410957337, "val_acc": 48.0}
{"epoch": 10, "training_loss": 0.7468184947967529, "training_acc": 42.0, "val_loss": 0.6946903157234192, "val_acc": 48.0}
{"epoch": 11, "training_loss": 0.7242631721496582, "training_acc": 50.0, "val_loss": 0.8498952436447144, "val_acc": 48.0}
{"epoch": 12, "training_loss": 0.7578650808334351, "training_acc": 48.0, "val_loss": 0.7421097087860108, "val_acc": 48.0}
{"epoch": 13, "training_loss": 0.7513541173934937, "training_acc": 50.0, "val_loss": 0.7226217317581177, "val_acc": 52.0}
{"epoch": 14, "training_loss": 0.7483333396911621, "training_acc": 50.0, "val_loss": 0.7301232552528382, "val_acc": 48.0}
{"epoch": 15, "training_loss": 0.7107745766639709, "training_acc": 52.0, "val_loss": 0.9238331556320191, "val_acc": 48.0}
{"epoch": 16, "training_loss": 0.8624262523651123, "training_acc": 48.0, "val_loss": 0.6925309777259827, "val_acc": 52.0}
{"epoch": 17, "training_loss": 0.7575431108474732, "training_acc": 50.0, "val_loss": 0.7428705382347107, "val_acc": 52.0}
{"epoch": 18, "training_loss": 0.751183385848999, "training_acc": 48.0, "val_loss": 0.6970370435714721, "val_acc": 52.0}
{"epoch": 19, "training_loss": 0.7371858620643615, "training_acc": 46.0, "val_loss": 0.6931478881835937, "val_acc": 48.0}
{"epoch": 20, "training_loss": 0.7146631789207458, "training_acc": 42.0, "val_loss": 0.6976471638679504, "val_acc": 48.0}
{"epoch": 21, "training_loss": 0.7171973824501038, "training_acc": 44.0, "val_loss": 0.6969754981994629, "val_acc": 48.0}
{"epoch": 22, "training_loss": 0.7364940547943115, "training_acc": 50.0, "val_loss": 0.8037033581733704, "val_acc": 48.0}
{"epoch": 23, "training_loss": 0.6979785537719727, "training_acc": 56.0, "val_loss": 0.8539522480964661, "val_acc": 52.0}
{"epoch": 24, "training_loss": 0.8094602441787719, "training_acc": 50.0, "val_loss": 0.6923474240303039, "val_acc": 52.0}
{"epoch": 25, "training_loss": 0.721556077003479, "training_acc": 44.0, "val_loss": 0.6931719326972962, "val_acc": 48.0}
{"epoch": 26, "training_loss": 0.7110906982421875, "training_acc": 46.0, "val_loss": 0.7038100528717041, "val_acc": 52.0}
{"epoch": 27, "training_loss": 0.7524747514724731, "training_acc": 42.0, "val_loss": 0.7299559879302978, "val_acc": 52.0}
{"epoch": 28, "training_loss": 0.740590705871582, "training_acc": 46.0, "val_loss": 0.7499899744987488, "val_acc": 48.0}
{"epoch": 29, "training_loss": 0.8118983721733093, "training_acc": 48.0, "val_loss": 0.7182140731811524, "val_acc": 52.0}
{"epoch": 30, "training_loss": 0.7224363946914673, "training_acc": 50.0, "val_loss": 0.6923875141143799, "val_acc": 52.0}
{"epoch": 31, "training_loss": 0.7240569114685058, "training_acc": 46.0, "val_loss": 0.7775420689582825, "val_acc": 48.0}
{"epoch": 32, "training_loss": 0.7240237951278686, "training_acc": 52.0, "val_loss": 0.7101888585090638, "val_acc": 52.0}
{"epoch": 33, "training_loss": 0.7464883184432983, "training_acc": 42.0, "val_loss": 0.692746319770813, "val_acc": 52.0}
{"epoch": 34, "training_loss": 0.7352923440933228, "training_acc": 52.0, "val_loss": 0.8034685921669006, "val_acc": 52.0}
{"epoch": 35, "training_loss": 0.7751264190673828, "training_acc": 50.0, "val_loss": 0.7647059941291809, "val_acc": 48.0}
{"epoch": 36, "training_loss": 0.7508968591690064, "training_acc": 46.0, "val_loss": 0.7322941184043884, "val_acc": 48.0}
{"epoch": 37, "training_loss": 0.7145881724357604, "training_acc": 52.0, "val_loss": 0.8507281827926636, "val_acc": 52.0}
{"epoch": 38, "training_loss": 0.7953713989257812, "training_acc": 44.0, "val_loss": 0.7396234631538391, "val_acc": 52.0}
{"epoch": 39, "training_loss": 0.8391057634353638, "training_acc": 54.0, "val_loss": 1.0501526236534118, "val_acc": 48.0}
{"epoch": 40, "training_loss": 0.7753214144706726, "training_acc": 56.0, "val_loss": 0.826426568031311, "val_acc": 52.0}
{"epoch": 41, "training_loss": 0.7820137286186218, "training_acc": 46.0, "val_loss": 0.6923893308639526, "val_acc": 52.0}
{"epoch": 42, "training_loss": 0.7352173328399658, "training_acc": 52.0, "val_loss": 0.803554835319519, "val_acc": 48.0}
{"epoch": 43, "training_loss": 0.8000104451179504, "training_acc": 54.0, "val_loss": 0.716759192943573, "val_acc": 52.0}
