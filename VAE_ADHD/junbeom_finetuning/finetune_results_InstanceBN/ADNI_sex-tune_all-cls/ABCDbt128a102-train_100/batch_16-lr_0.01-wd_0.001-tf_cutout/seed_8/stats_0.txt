"main_modify.py --pretrained_path /scratch/connectome/dyhan316/VAE_ADHD/barlowtwins/pretrain_results/ABCDbt128a102.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 8 --task ADNI_sex --input_option BT_org --learning_rate 1e-2 --batch_size 16 --weight_decay 1e-3 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 0.9675004410743714, "training_acc": 53.0, "val_loss": 0.71794673204422, "val_acc": 48.0}
{"epoch": 1, "training_loss": 0.7716641902923584, "training_acc": 45.0, "val_loss": 0.6929455876350403, "val_acc": 52.0}
{"epoch": 2, "training_loss": 0.722474319934845, "training_acc": 49.0, "val_loss": 0.7792075395584106, "val_acc": 52.0}
{"epoch": 3, "training_loss": 0.8644906949996948, "training_acc": 48.0, "val_loss": 0.8404157257080078, "val_acc": 52.0}
{"epoch": 4, "training_loss": 0.7467391550540924, "training_acc": 55.0, "val_loss": 1.0151301908493042, "val_acc": 48.0}
{"epoch": 5, "training_loss": 0.8492471694946289, "training_acc": 49.0, "val_loss": 0.6969888138771058, "val_acc": 48.0}
{"epoch": 6, "training_loss": 0.8416959643363953, "training_acc": 45.0, "val_loss": 0.6979361367225647, "val_acc": 52.0}
{"epoch": 7, "training_loss": 0.7303744459152222, "training_acc": 41.0, "val_loss": 0.7722276020050048, "val_acc": 48.0}
{"epoch": 8, "training_loss": 0.8020555591583252, "training_acc": 49.0, "val_loss": 0.7424745512008667, "val_acc": 52.0}
{"epoch": 9, "training_loss": 0.7172829914093017, "training_acc": 49.0, "val_loss": 0.7098775100708008, "val_acc": 48.0}
{"epoch": 10, "training_loss": 0.7239783000946045, "training_acc": 49.0, "val_loss": 0.7252578902244567, "val_acc": 48.0}
{"epoch": 11, "training_loss": 0.7224678182601929, "training_acc": 43.0, "val_loss": 0.6926187086105347, "val_acc": 52.0}
{"epoch": 12, "training_loss": 0.7599442958831787, "training_acc": 43.0, "val_loss": 0.6929882955551148, "val_acc": 52.0}
{"epoch": 13, "training_loss": 0.7102894067764283, "training_acc": 43.0, "val_loss": 0.6982756018638611, "val_acc": 52.0}
{"epoch": 14, "training_loss": 0.7523768091201782, "training_acc": 35.0, "val_loss": 0.6947194457054138, "val_acc": 48.0}
{"epoch": 15, "training_loss": 0.7003699159622192, "training_acc": 51.0, "val_loss": 0.7121741080284119, "val_acc": 48.0}
{"epoch": 16, "training_loss": 0.7347569131851196, "training_acc": 45.0, "val_loss": 0.7165842151641846, "val_acc": 48.0}
{"epoch": 17, "training_loss": 0.7176254057884216, "training_acc": 49.0, "val_loss": 0.791198661327362, "val_acc": 48.0}
{"epoch": 18, "training_loss": 0.7906579494476318, "training_acc": 37.0, "val_loss": 0.6923472952842712, "val_acc": 52.0}
{"epoch": 19, "training_loss": 0.6991296195983887, "training_acc": 49.0, "val_loss": 0.7038655972480774, "val_acc": 48.0}
{"epoch": 20, "training_loss": 0.7105533599853515, "training_acc": 53.0, "val_loss": 0.6970868039131165, "val_acc": 52.0}
{"epoch": 21, "training_loss": 0.7157161569595337, "training_acc": 51.0, "val_loss": 0.7316775631904602, "val_acc": 52.0}
{"epoch": 22, "training_loss": 0.698321715593338, "training_acc": 57.0, "val_loss": 1.1885150957107544, "val_acc": 48.0}
{"epoch": 23, "training_loss": 0.9132915163040161, "training_acc": 43.0, "val_loss": 0.6923564457893372, "val_acc": 52.0}
{"epoch": 24, "training_loss": 0.7219357919692994, "training_acc": 47.0, "val_loss": 0.6970347857475281, "val_acc": 52.0}
{"epoch": 25, "training_loss": 0.7141341018676758, "training_acc": 43.0, "val_loss": 0.6956032490730286, "val_acc": 52.0}
{"epoch": 26, "training_loss": 0.7078054547309875, "training_acc": 49.0, "val_loss": 0.7101606130599976, "val_acc": 48.0}
{"epoch": 27, "training_loss": 0.703356864452362, "training_acc": 49.0, "val_loss": 0.6924229788780213, "val_acc": 52.0}
{"epoch": 28, "training_loss": 0.7043362903594971, "training_acc": 41.0, "val_loss": 0.7160440325737, "val_acc": 48.0}
{"epoch": 29, "training_loss": 0.7054552125930786, "training_acc": 49.0, "val_loss": 0.7048448610305786, "val_acc": 48.0}
{"epoch": 30, "training_loss": 0.746507682800293, "training_acc": 37.0, "val_loss": 0.6947073912620545, "val_acc": 48.0}
{"epoch": 31, "training_loss": 0.7254736185073852, "training_acc": 47.0, "val_loss": 0.7218423891067505, "val_acc": 48.0}
{"epoch": 32, "training_loss": 0.7151372218132019, "training_acc": 45.0, "val_loss": 0.7220914483070373, "val_acc": 48.0}
{"epoch": 33, "training_loss": 0.7804886054992676, "training_acc": 51.0, "val_loss": 0.7641880488395691, "val_acc": 52.0}
{"epoch": 34, "training_loss": 0.7339149904251099, "training_acc": 51.0, "val_loss": 0.7474731945991516, "val_acc": 48.0}
{"epoch": 35, "training_loss": 0.7191164684295654, "training_acc": 49.0, "val_loss": 0.6933424830436706, "val_acc": 52.0}
{"epoch": 36, "training_loss": 0.7612599945068359, "training_acc": 49.0, "val_loss": 0.6983584713935852, "val_acc": 52.0}
{"epoch": 37, "training_loss": 0.7979407858848572, "training_acc": 47.0, "val_loss": 0.8729341053962707, "val_acc": 48.0}
