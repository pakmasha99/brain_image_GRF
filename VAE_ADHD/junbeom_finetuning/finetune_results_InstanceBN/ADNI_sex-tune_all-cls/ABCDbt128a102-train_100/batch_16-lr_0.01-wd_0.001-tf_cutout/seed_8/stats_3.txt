"main_modify.py --pretrained_path /scratch/connectome/dyhan316/VAE_ADHD/barlowtwins/pretrain_results/ABCDbt128a102.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 8 --task ADNI_sex --input_option BT_org --learning_rate 1e-2 --batch_size 16 --weight_decay 1e-3 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 0.9426191902160644, "training_acc": 54.0, "val_loss": 0.793948392868042, "val_acc": 52.0}
{"epoch": 1, "training_loss": 0.8108924555778504, "training_acc": 44.0, "val_loss": 0.9243722343444825, "val_acc": 52.0}
{"epoch": 2, "training_loss": 0.8337475633621216, "training_acc": 46.0, "val_loss": 0.703317973613739, "val_acc": 52.0}
{"epoch": 3, "training_loss": 0.7685381746292115, "training_acc": 44.0, "val_loss": 0.7955080509185791, "val_acc": 52.0}
{"epoch": 4, "training_loss": 0.7120494318008422, "training_acc": 56.0, "val_loss": 1.0669329142570496, "val_acc": 48.0}
{"epoch": 5, "training_loss": 0.8245006942749024, "training_acc": 46.0, "val_loss": 0.6991232419013977, "val_acc": 48.0}
{"epoch": 6, "training_loss": 0.6990802407264709, "training_acc": 48.0, "val_loss": 0.7195622682571411, "val_acc": 48.0}
{"epoch": 7, "training_loss": 0.7611862897872925, "training_acc": 50.0, "val_loss": 0.8599935841560363, "val_acc": 48.0}
{"epoch": 8, "training_loss": 0.7578866958618165, "training_acc": 48.0, "val_loss": 0.6985351347923279, "val_acc": 48.0}
{"epoch": 9, "training_loss": 0.6963622045516967, "training_acc": 50.0, "val_loss": 0.7266936588287354, "val_acc": 52.0}
{"epoch": 10, "training_loss": 0.755432415008545, "training_acc": 54.0, "val_loss": 0.9279926657676697, "val_acc": 48.0}
{"epoch": 11, "training_loss": 0.8154111099243164, "training_acc": 48.0, "val_loss": 0.7951886415481567, "val_acc": 48.0}
{"epoch": 12, "training_loss": 0.8126604318618774, "training_acc": 44.0, "val_loss": 0.9817548894882202, "val_acc": 48.0}
{"epoch": 13, "training_loss": 0.9492858695983887, "training_acc": 52.0, "val_loss": 0.8929177188873291, "val_acc": 52.0}
{"epoch": 14, "training_loss": 0.7928575944900512, "training_acc": 52.0, "val_loss": 0.7894600987434387, "val_acc": 52.0}
{"epoch": 15, "training_loss": 0.7736735010147094, "training_acc": 48.0, "val_loss": 0.6953134942054748, "val_acc": 52.0}
{"epoch": 16, "training_loss": 0.7214365911483764, "training_acc": 54.0, "val_loss": 0.7349947452545166, "val_acc": 48.0}
{"epoch": 17, "training_loss": 0.7036560440063476, "training_acc": 48.0, "val_loss": 0.8304904294013977, "val_acc": 52.0}
{"epoch": 18, "training_loss": 0.7447461056709289, "training_acc": 52.0, "val_loss": 0.7895980381965637, "val_acc": 48.0}
{"epoch": 19, "training_loss": 0.7543460702896119, "training_acc": 46.0, "val_loss": 0.7114802169799804, "val_acc": 48.0}
{"epoch": 20, "training_loss": 0.7360943412780762, "training_acc": 48.0, "val_loss": 0.6935861587524415, "val_acc": 48.0}
{"epoch": 21, "training_loss": 0.7652478671073913, "training_acc": 52.0, "val_loss": 0.8840375256538391, "val_acc": 52.0}
{"epoch": 22, "training_loss": 0.8291817355155945, "training_acc": 48.0, "val_loss": 0.7438339686393738, "val_acc": 48.0}
{"epoch": 23, "training_loss": 0.7315412211418152, "training_acc": 46.0, "val_loss": 0.6979064869880677, "val_acc": 52.0}
{"epoch": 24, "training_loss": 0.7538315153121948, "training_acc": 50.0, "val_loss": 0.736423225402832, "val_acc": 48.0}
{"epoch": 25, "training_loss": 0.7094064617156982, "training_acc": 50.0, "val_loss": 0.6952704191207886, "val_acc": 48.0}
{"epoch": 26, "training_loss": 0.7364138031005859, "training_acc": 50.0, "val_loss": 0.712055389881134, "val_acc": 52.0}
{"epoch": 27, "training_loss": 0.7159226560592651, "training_acc": 46.0, "val_loss": 0.6977200222015381, "val_acc": 52.0}
{"epoch": 28, "training_loss": 0.7121098661422729, "training_acc": 52.0, "val_loss": 0.8970660901069641, "val_acc": 52.0}
{"epoch": 29, "training_loss": 0.946232795715332, "training_acc": 44.0, "val_loss": 0.7126570248603821, "val_acc": 48.0}
{"epoch": 30, "training_loss": 0.7278376531600952, "training_acc": 52.0, "val_loss": 0.7254527807235718, "val_acc": 48.0}
{"epoch": 31, "training_loss": 0.7690907502174378, "training_acc": 48.0, "val_loss": 0.6947699999809265, "val_acc": 48.0}
{"epoch": 32, "training_loss": 0.7252847957611084, "training_acc": 52.0, "val_loss": 0.7577275085449219, "val_acc": 52.0}
{"epoch": 33, "training_loss": 0.7608885288238525, "training_acc": 52.0, "val_loss": 0.7083873081207276, "val_acc": 48.0}
{"epoch": 34, "training_loss": 0.7825577831268311, "training_acc": 46.0, "val_loss": 1.0266866636276246, "val_acc": 48.0}
{"epoch": 35, "training_loss": 0.8453607940673828, "training_acc": 50.0, "val_loss": 0.6923555445671081, "val_acc": 52.0}
{"epoch": 36, "training_loss": 0.7256339955329895, "training_acc": 52.0, "val_loss": 0.7632325410842895, "val_acc": 52.0}
{"epoch": 37, "training_loss": 0.764502010345459, "training_acc": 48.0, "val_loss": 0.7945085000991822, "val_acc": 48.0}
{"epoch": 38, "training_loss": 0.7008077073097229, "training_acc": 56.0, "val_loss": 0.8708009147644042, "val_acc": 52.0}
{"epoch": 39, "training_loss": 0.7635448551177979, "training_acc": 50.0, "val_loss": 0.6987967991828918, "val_acc": 48.0}
{"epoch": 40, "training_loss": 0.6975220537185669, "training_acc": 54.0, "val_loss": 0.6929604935646058, "val_acc": 52.0}
{"epoch": 41, "training_loss": 0.6937959480285645, "training_acc": 54.0, "val_loss": 0.726119089126587, "val_acc": 48.0}
{"epoch": 42, "training_loss": 0.7083199548721314, "training_acc": 50.0, "val_loss": 0.6990287733078003, "val_acc": 52.0}
{"epoch": 43, "training_loss": 0.6884047079086304, "training_acc": 54.0, "val_loss": 0.800546464920044, "val_acc": 48.0}
{"epoch": 44, "training_loss": 0.7590697765350342, "training_acc": 40.0, "val_loss": 0.6945932507514954, "val_acc": 52.0}
{"epoch": 45, "training_loss": 0.7071380352973938, "training_acc": 46.0, "val_loss": 0.6923879218101502, "val_acc": 52.0}
{"epoch": 46, "training_loss": 0.7208949255943299, "training_acc": 50.0, "val_loss": 0.7187194418907166, "val_acc": 48.0}
{"epoch": 47, "training_loss": 0.711077823638916, "training_acc": 48.0, "val_loss": 0.6927959632873535, "val_acc": 52.0}
{"epoch": 48, "training_loss": 0.7037390756607056, "training_acc": 50.0, "val_loss": 0.7424930572509766, "val_acc": 52.0}
{"epoch": 49, "training_loss": 0.7421349239349365, "training_acc": 50.0, "val_loss": 0.7755368494987488, "val_acc": 48.0}
{"epoch": 50, "training_loss": 0.718791732788086, "training_acc": 52.0, "val_loss": 0.7457588219642639, "val_acc": 52.0}
{"epoch": 51, "training_loss": 0.73104332447052, "training_acc": 48.0, "val_loss": 0.7003450894355774, "val_acc": 48.0}
{"epoch": 52, "training_loss": 0.7266123557090759, "training_acc": 52.0, "val_loss": 0.7898087763786316, "val_acc": 52.0}
{"epoch": 53, "training_loss": 0.7285377025604248, "training_acc": 52.0, "val_loss": 0.8179373264312744, "val_acc": 48.0}
{"epoch": 54, "training_loss": 0.7424905443191528, "training_acc": 56.0, "val_loss": 0.8190918755531311, "val_acc": 52.0}
