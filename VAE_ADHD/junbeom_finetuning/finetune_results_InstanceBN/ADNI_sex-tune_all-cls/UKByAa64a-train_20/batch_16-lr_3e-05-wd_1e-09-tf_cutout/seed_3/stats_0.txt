"main_modify.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 20 --layer_control tune_all --stratify strat --random_seed 3 --task ADNI_sex --input_option yAware --learning_rate 3e-5 --batch_size 16 --weight_decay 1e-9 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 0.6915336132049561, "training_acc": 50.0, "val_loss": 0.7002992630004883, "val_acc": 40.0}
{"epoch": 1, "training_loss": 0.6958863258361816, "training_acc": 50.0, "val_loss": 0.6948375105857849, "val_acc": 40.0}
{"epoch": 2, "training_loss": 0.6888970375061035, "training_acc": 50.0, "val_loss": 0.6955613493919373, "val_acc": 40.0}
{"epoch": 3, "training_loss": 0.6870752334594726, "training_acc": 50.0, "val_loss": 0.687297523021698, "val_acc": 60.0}
{"epoch": 4, "training_loss": 0.6829986333847046, "training_acc": 45.0, "val_loss": 0.6875166296958923, "val_acc": 60.0}
{"epoch": 5, "training_loss": 0.6872395396232605, "training_acc": 50.0, "val_loss": 0.6864824295043945, "val_acc": 80.0}
{"epoch": 6, "training_loss": 0.6870926260948181, "training_acc": 55.0, "val_loss": 0.6783686280250549, "val_acc": 80.0}
{"epoch": 7, "training_loss": 0.6808353662490845, "training_acc": 70.0, "val_loss": 0.6772581338882446, "val_acc": 80.0}
{"epoch": 8, "training_loss": 0.6737340927124024, "training_acc": 80.0, "val_loss": 0.6689678430557251, "val_acc": 80.0}
{"epoch": 9, "training_loss": 0.6704923391342164, "training_acc": 70.0, "val_loss": 0.6646193861961365, "val_acc": 80.0}
{"epoch": 10, "training_loss": 0.6678993582725525, "training_acc": 70.0, "val_loss": 0.6574985980987549, "val_acc": 60.0}
{"epoch": 11, "training_loss": 0.6611266374588013, "training_acc": 70.0, "val_loss": 0.6530122756958008, "val_acc": 60.0}
{"epoch": 12, "training_loss": 0.6647286653518677, "training_acc": 70.0, "val_loss": 0.6486523747444153, "val_acc": 80.0}
{"epoch": 13, "training_loss": 0.6511591672897339, "training_acc": 70.0, "val_loss": 0.6619821786880493, "val_acc": 80.0}
{"epoch": 14, "training_loss": 0.6688565254211426, "training_acc": 75.0, "val_loss": 0.6635949611663818, "val_acc": 60.0}
{"epoch": 15, "training_loss": 0.6608395099639892, "training_acc": 80.0, "val_loss": 0.6499606966972351, "val_acc": 80.0}
{"epoch": 16, "training_loss": 0.6505209922790527, "training_acc": 70.0, "val_loss": 0.6488953232765198, "val_acc": 60.0}
{"epoch": 17, "training_loss": 0.6565937519073486, "training_acc": 65.0, "val_loss": 0.6371008157730103, "val_acc": 80.0}
{"epoch": 18, "training_loss": 0.6418927669525146, "training_acc": 65.0, "val_loss": 0.6403988599777222, "val_acc": 80.0}
{"epoch": 19, "training_loss": 0.6410234689712524, "training_acc": 75.0, "val_loss": 0.6368772983551025, "val_acc": 80.0}
{"epoch": 20, "training_loss": 0.6402299165725708, "training_acc": 75.0, "val_loss": 0.6324819922447205, "val_acc": 80.0}
{"epoch": 21, "training_loss": 0.6368824124336243, "training_acc": 70.0, "val_loss": 0.6306338310241699, "val_acc": 80.0}
{"epoch": 22, "training_loss": 0.6250229597091674, "training_acc": 70.0, "val_loss": 0.6325498819351196, "val_acc": 80.0}
{"epoch": 23, "training_loss": 0.6177056550979614, "training_acc": 85.0, "val_loss": 0.627567708492279, "val_acc": 80.0}
{"epoch": 24, "training_loss": 0.6130742311477662, "training_acc": 75.0, "val_loss": 0.6274963617324829, "val_acc": 80.0}
{"epoch": 25, "training_loss": 0.6165616273880005, "training_acc": 65.0, "val_loss": 0.6224770545959473, "val_acc": 80.0}
{"epoch": 26, "training_loss": 0.6122126102447509, "training_acc": 80.0, "val_loss": 0.6252113580703735, "val_acc": 60.0}
{"epoch": 27, "training_loss": 0.6056864261627197, "training_acc": 75.0, "val_loss": 0.6095308661460876, "val_acc": 80.0}
{"epoch": 28, "training_loss": 0.5937493920326233, "training_acc": 80.0, "val_loss": 0.6084352731704712, "val_acc": 80.0}
{"epoch": 29, "training_loss": 0.5693265795707703, "training_acc": 85.0, "val_loss": 0.6148174405097961, "val_acc": 80.0}
{"epoch": 30, "training_loss": 0.5780450344085694, "training_acc": 80.0, "val_loss": 0.6432528495788574, "val_acc": 60.0}
{"epoch": 31, "training_loss": 0.606014084815979, "training_acc": 80.0, "val_loss": 0.6605582237243652, "val_acc": 60.0}
{"epoch": 32, "training_loss": 0.6173875331878662, "training_acc": 75.0, "val_loss": 0.6086002588272095, "val_acc": 80.0}
{"epoch": 33, "training_loss": 0.5744257211685181, "training_acc": 80.0, "val_loss": 0.6025005578994751, "val_acc": 80.0}
{"epoch": 34, "training_loss": 0.5571226358413697, "training_acc": 80.0, "val_loss": 0.6557642221450806, "val_acc": 60.0}
{"epoch": 35, "training_loss": 0.6326279163360595, "training_acc": 60.0, "val_loss": 0.6851585507392883, "val_acc": 60.0}
{"epoch": 36, "training_loss": 0.617917275428772, "training_acc": 65.0, "val_loss": 0.6137228012084961, "val_acc": 60.0}
{"epoch": 37, "training_loss": 0.5361798107624054, "training_acc": 85.0, "val_loss": 0.6367079615592957, "val_acc": 60.0}
{"epoch": 38, "training_loss": 0.6020740270614624, "training_acc": 75.0, "val_loss": 0.6037077307701111, "val_acc": 80.0}
{"epoch": 39, "training_loss": 0.5619927406311035, "training_acc": 90.0, "val_loss": 0.6245530843734741, "val_acc": 60.0}
{"epoch": 40, "training_loss": 0.6046066522598267, "training_acc": 80.0, "val_loss": 0.6416574716567993, "val_acc": 60.0}
{"epoch": 41, "training_loss": 0.5954270839691163, "training_acc": 75.0, "val_loss": 0.6045705676078796, "val_acc": 60.0}
{"epoch": 42, "training_loss": 0.5449481964111328, "training_acc": 85.0, "val_loss": 0.5973303914070129, "val_acc": 80.0}
{"epoch": 43, "training_loss": 0.5689271926879883, "training_acc": 80.0, "val_loss": 0.5916290879249573, "val_acc": 80.0}
{"epoch": 44, "training_loss": 0.5353341102600098, "training_acc": 85.0, "val_loss": 0.6029927134513855, "val_acc": 60.0}
{"epoch": 45, "training_loss": 0.5465674877166748, "training_acc": 85.0, "val_loss": 0.5960742831230164, "val_acc": 60.0}
{"epoch": 46, "training_loss": 0.5265264749526978, "training_acc": 80.0, "val_loss": 0.5800001621246338, "val_acc": 80.0}
{"epoch": 47, "training_loss": 0.503724992275238, "training_acc": 90.0, "val_loss": 0.5750313997268677, "val_acc": 80.0}
{"epoch": 48, "training_loss": 0.48604347705841067, "training_acc": 95.0, "val_loss": 0.626846432685852, "val_acc": 60.0}
{"epoch": 49, "training_loss": 0.5521389842033386, "training_acc": 80.0, "val_loss": 0.6090699434280396, "val_acc": 80.0}
{"epoch": 50, "training_loss": 0.4720738291740417, "training_acc": 95.0, "val_loss": 0.599763035774231, "val_acc": 80.0}
{"epoch": 51, "training_loss": 0.524122953414917, "training_acc": 85.0, "val_loss": 0.5832160115242004, "val_acc": 60.0}
{"epoch": 52, "training_loss": 0.5039941668510437, "training_acc": 85.0, "val_loss": 0.6201763153076172, "val_acc": 80.0}
{"epoch": 53, "training_loss": 0.4474942207336426, "training_acc": 95.0, "val_loss": 0.6089619398117065, "val_acc": 60.0}
{"epoch": 54, "training_loss": 0.44169052839279177, "training_acc": 100.0, "val_loss": 0.5938342213630676, "val_acc": 80.0}
{"epoch": 55, "training_loss": 0.43793563842773436, "training_acc": 95.0, "val_loss": 0.6072249412536621, "val_acc": 60.0}
{"epoch": 56, "training_loss": 0.41969226598739623, "training_acc": 100.0, "val_loss": 0.6085940599441528, "val_acc": 60.0}
{"epoch": 57, "training_loss": 0.4045384109020233, "training_acc": 100.0, "val_loss": 0.6190350651741028, "val_acc": 60.0}
{"epoch": 58, "training_loss": 0.41691327691078184, "training_acc": 95.0, "val_loss": 0.6938943266868591, "val_acc": 60.0}
{"epoch": 59, "training_loss": 0.40537068247795105, "training_acc": 100.0, "val_loss": 0.5942897796630859, "val_acc": 60.0}
{"epoch": 60, "training_loss": 0.3962390661239624, "training_acc": 100.0, "val_loss": 0.5983344316482544, "val_acc": 80.0}
{"epoch": 61, "training_loss": 0.3899240255355835, "training_acc": 95.0, "val_loss": 0.6578960418701172, "val_acc": 60.0}
{"epoch": 62, "training_loss": 0.39568777084350587, "training_acc": 95.0, "val_loss": 0.570719301700592, "val_acc": 60.0}
{"epoch": 63, "training_loss": 0.3488765299320221, "training_acc": 100.0, "val_loss": 0.5930410623550415, "val_acc": 80.0}
{"epoch": 64, "training_loss": 0.395047664642334, "training_acc": 95.0, "val_loss": 0.5648989081382751, "val_acc": 60.0}
{"epoch": 65, "training_loss": 0.37221546173095704, "training_acc": 100.0, "val_loss": 0.567384660243988, "val_acc": 60.0}
{"epoch": 66, "training_loss": 0.3294997036457062, "training_acc": 100.0, "val_loss": 0.614839494228363, "val_acc": 60.0}
{"epoch": 67, "training_loss": 0.32550851106643675, "training_acc": 100.0, "val_loss": 0.6342684030532837, "val_acc": 60.0}
{"epoch": 68, "training_loss": 0.3446657657623291, "training_acc": 100.0, "val_loss": 0.5828040242195129, "val_acc": 80.0}
{"epoch": 69, "training_loss": 0.34121930599212646, "training_acc": 100.0, "val_loss": 0.6101552248001099, "val_acc": 60.0}
{"epoch": 70, "training_loss": 0.3399143576622009, "training_acc": 100.0, "val_loss": 0.6364253163337708, "val_acc": 60.0}
{"epoch": 71, "training_loss": 0.3317150890827179, "training_acc": 100.0, "val_loss": 0.6425315737724304, "val_acc": 60.0}
{"epoch": 72, "training_loss": 0.33297230005264283, "training_acc": 100.0, "val_loss": 0.6181139349937439, "val_acc": 60.0}
{"epoch": 73, "training_loss": 0.3207729697227478, "training_acc": 100.0, "val_loss": 0.588878870010376, "val_acc": 80.0}
{"epoch": 74, "training_loss": 0.31545929312705995, "training_acc": 95.0, "val_loss": 0.6926552653312683, "val_acc": 60.0}
{"epoch": 75, "training_loss": 0.3084891736507416, "training_acc": 100.0, "val_loss": 0.5868543982505798, "val_acc": 60.0}
{"epoch": 76, "training_loss": 0.28628952503204347, "training_acc": 100.0, "val_loss": 0.6166180968284607, "val_acc": 60.0}
{"epoch": 77, "training_loss": 0.3251274824142456, "training_acc": 95.0, "val_loss": 0.6356562972068787, "val_acc": 60.0}
{"epoch": 78, "training_loss": 0.31934654712677, "training_acc": 100.0, "val_loss": 0.5804764628410339, "val_acc": 60.0}
{"epoch": 79, "training_loss": 0.2885537505149841, "training_acc": 100.0, "val_loss": 0.6183662414550781, "val_acc": 60.0}
{"epoch": 80, "training_loss": 0.28554320335388184, "training_acc": 100.0, "val_loss": 0.6118467450141907, "val_acc": 60.0}
{"epoch": 81, "training_loss": 0.28053480982780454, "training_acc": 100.0, "val_loss": 0.6242616772651672, "val_acc": 60.0}
{"epoch": 82, "training_loss": 0.2950644016265869, "training_acc": 100.0, "val_loss": 0.643977165222168, "val_acc": 60.0}
{"epoch": 83, "training_loss": 0.31460625529289243, "training_acc": 100.0, "val_loss": 0.6918937563896179, "val_acc": 60.0}
