"main_modify.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 5 --task ADNI_sex --input_option yAware --learning_rate 1e-3 --batch_size 16 --weight_decay 1e-6 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 0.7137375164031983, "training_acc": 51.0, "val_loss": 0.7126916646957397, "val_acc": 48.0}
{"epoch": 1, "training_loss": 0.7130781507492066, "training_acc": 50.0, "val_loss": 0.693411967754364, "val_acc": 48.0}
{"epoch": 2, "training_loss": 0.7054991006851197, "training_acc": 46.0, "val_loss": 0.6933823418617249, "val_acc": 52.0}
{"epoch": 3, "training_loss": 0.6961522912979126, "training_acc": 50.0, "val_loss": 0.6930009889602661, "val_acc": 52.0}
{"epoch": 4, "training_loss": 0.6978072643280029, "training_acc": 50.0, "val_loss": 0.700677011013031, "val_acc": 48.0}
{"epoch": 5, "training_loss": 0.7206410050392151, "training_acc": 50.0, "val_loss": 0.7045302557945251, "val_acc": 48.0}
{"epoch": 6, "training_loss": 0.6968222665786743, "training_acc": 50.0, "val_loss": 0.6923643898963928, "val_acc": 52.0}
{"epoch": 7, "training_loss": 0.6981954336166382, "training_acc": 50.0, "val_loss": 0.692431526184082, "val_acc": 52.0}
{"epoch": 8, "training_loss": 0.6973476099967957, "training_acc": 50.0, "val_loss": 0.6926334095001221, "val_acc": 52.0}
{"epoch": 9, "training_loss": 0.7102439308166504, "training_acc": 50.0, "val_loss": 0.6928390574455261, "val_acc": 52.0}
{"epoch": 10, "training_loss": 0.7377315020561218, "training_acc": 46.0, "val_loss": 0.7110214471817017, "val_acc": 48.0}
{"epoch": 11, "training_loss": 0.7384027481079102, "training_acc": 46.0, "val_loss": 0.70700767993927, "val_acc": 52.0}
{"epoch": 12, "training_loss": 0.7082611083984375, "training_acc": 48.0, "val_loss": 0.6971279573440552, "val_acc": 48.0}
{"epoch": 13, "training_loss": 0.6952091312408447, "training_acc": 50.0, "val_loss": 0.6924894666671753, "val_acc": 52.0}
{"epoch": 14, "training_loss": 0.6941266727447509, "training_acc": 50.0, "val_loss": 0.7009938740730286, "val_acc": 48.0}
{"epoch": 15, "training_loss": 0.7101421546936035, "training_acc": 40.0, "val_loss": 0.6936456370353699, "val_acc": 48.0}
{"epoch": 16, "training_loss": 0.700864999294281, "training_acc": 50.0, "val_loss": 0.6952891278266907, "val_acc": 48.0}
{"epoch": 17, "training_loss": 0.6953806161880494, "training_acc": 54.0, "val_loss": 0.6964590382575989, "val_acc": 52.0}
{"epoch": 18, "training_loss": 0.7016973495483398, "training_acc": 46.0, "val_loss": 0.6953724479675293, "val_acc": 48.0}
{"epoch": 19, "training_loss": 0.6954173469543456, "training_acc": 48.0, "val_loss": 0.6927699208259582, "val_acc": 52.0}
{"epoch": 20, "training_loss": 0.6982986044883728, "training_acc": 50.0, "val_loss": 0.6964827561378479, "val_acc": 48.0}
{"epoch": 21, "training_loss": 0.6990092158317566, "training_acc": 52.0, "val_loss": 0.7042808151245117, "val_acc": 52.0}
{"epoch": 22, "training_loss": 0.705737874507904, "training_acc": 50.0, "val_loss": 0.6930173683166504, "val_acc": 52.0}
{"epoch": 23, "training_loss": 0.6988200974464417, "training_acc": 46.0, "val_loss": 0.6993324971199035, "val_acc": 48.0}
{"epoch": 24, "training_loss": 0.6998785305023193, "training_acc": 50.0, "val_loss": 0.6926283288002014, "val_acc": 52.0}
{"epoch": 25, "training_loss": 0.6964977860450745, "training_acc": 50.0, "val_loss": 0.6923490452766419, "val_acc": 52.0}
{"epoch": 26, "training_loss": 0.6987156009674073, "training_acc": 52.0, "val_loss": 0.6989405751228333, "val_acc": 48.0}
{"epoch": 27, "training_loss": 0.7136723375320435, "training_acc": 50.0, "val_loss": 0.713409116268158, "val_acc": 48.0}
{"epoch": 28, "training_loss": 0.7026706504821777, "training_acc": 48.0, "val_loss": 0.6972224092483521, "val_acc": 52.0}
{"epoch": 29, "training_loss": 0.7009833526611328, "training_acc": 46.0, "val_loss": 0.6924339985847473, "val_acc": 52.0}
{"epoch": 30, "training_loss": 0.6971386337280273, "training_acc": 50.0, "val_loss": 0.6939188575744629, "val_acc": 52.0}
{"epoch": 31, "training_loss": 0.7061274337768555, "training_acc": 50.0, "val_loss": 0.692350196838379, "val_acc": 52.0}
{"epoch": 32, "training_loss": 0.6916208124160766, "training_acc": 52.0, "val_loss": 0.7037352466583252, "val_acc": 48.0}
{"epoch": 33, "training_loss": 0.7047679567337036, "training_acc": 46.0, "val_loss": 0.6924494504928589, "val_acc": 52.0}
{"epoch": 34, "training_loss": 0.6968847417831421, "training_acc": 50.0, "val_loss": 0.6929391241073608, "val_acc": 52.0}
{"epoch": 35, "training_loss": 0.6919868946075439, "training_acc": 56.0, "val_loss": 0.7045446705818176, "val_acc": 48.0}
{"epoch": 36, "training_loss": 0.7220044946670532, "training_acc": 50.0, "val_loss": 0.7127307152748108, "val_acc": 48.0}
{"epoch": 37, "training_loss": 0.7075989294052124, "training_acc": 52.0, "val_loss": 0.7061859536170959, "val_acc": 52.0}
{"epoch": 38, "training_loss": 0.7104018878936768, "training_acc": 50.0, "val_loss": 0.6929065823554993, "val_acc": 52.0}
{"epoch": 39, "training_loss": 0.6926893901824951, "training_acc": 48.0, "val_loss": 0.7033352589607239, "val_acc": 48.0}
{"epoch": 40, "training_loss": 0.7066683530807495, "training_acc": 50.0, "val_loss": 0.6965762424468994, "val_acc": 48.0}
{"epoch": 41, "training_loss": 0.7008805298805236, "training_acc": 48.0, "val_loss": 0.6924737954139709, "val_acc": 52.0}
{"epoch": 42, "training_loss": 0.6992327380180359, "training_acc": 44.0, "val_loss": 0.6930095624923706, "val_acc": 52.0}
{"epoch": 43, "training_loss": 0.7146091413497925, "training_acc": 50.0, "val_loss": 0.6984878873825073, "val_acc": 52.0}
{"epoch": 44, "training_loss": 0.7084173345565796, "training_acc": 44.0, "val_loss": 0.6991847896575928, "val_acc": 48.0}
