"main_modify.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 5 --task ADNI_sex --input_option yAware --learning_rate 1e-3 --batch_size 16 --weight_decay 1e-6 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 0.782963662147522, "training_acc": 37.0, "val_loss": 0.6980017757415772, "val_acc": 48.0}
{"epoch": 1, "training_loss": 0.7219792366027832, "training_acc": 43.0, "val_loss": 0.6943275022506714, "val_acc": 48.0}
{"epoch": 2, "training_loss": 0.7051430058479309, "training_acc": 51.0, "val_loss": 0.692520751953125, "val_acc": 52.0}
{"epoch": 3, "training_loss": 0.7301980018615722, "training_acc": 49.0, "val_loss": 0.6983941435813904, "val_acc": 52.0}
{"epoch": 4, "training_loss": 0.7051220178604126, "training_acc": 49.0, "val_loss": 0.693707845211029, "val_acc": 48.0}
{"epoch": 5, "training_loss": 0.6972900700569152, "training_acc": 51.0, "val_loss": 0.6936322379112244, "val_acc": 48.0}
{"epoch": 6, "training_loss": 0.6998471188545227, "training_acc": 49.0, "val_loss": 0.6923854279518128, "val_acc": 52.0}
{"epoch": 7, "training_loss": 0.6934501338005066, "training_acc": 51.0, "val_loss": 0.6950898885726928, "val_acc": 48.0}
{"epoch": 8, "training_loss": 0.6955979776382446, "training_acc": 51.0, "val_loss": 0.6982145738601685, "val_acc": 48.0}
{"epoch": 9, "training_loss": 0.6967893600463867, "training_acc": 51.0, "val_loss": 0.6964496779441833, "val_acc": 48.0}
{"epoch": 10, "training_loss": 0.6985769319534302, "training_acc": 51.0, "val_loss": 0.6993346786499024, "val_acc": 48.0}
{"epoch": 11, "training_loss": 0.7027145171165466, "training_acc": 43.0, "val_loss": 0.6943770575523377, "val_acc": 48.0}
{"epoch": 12, "training_loss": 0.7245925736427307, "training_acc": 51.0, "val_loss": 0.7138173246383667, "val_acc": 48.0}
{"epoch": 13, "training_loss": 0.7224551677703858, "training_acc": 43.0, "val_loss": 0.6991790866851807, "val_acc": 52.0}
{"epoch": 14, "training_loss": 0.6999425077438355, "training_acc": 47.0, "val_loss": 0.6994112968444824, "val_acc": 48.0}
{"epoch": 15, "training_loss": 0.7040094995498657, "training_acc": 51.0, "val_loss": 0.6940186691284179, "val_acc": 48.0}
{"epoch": 16, "training_loss": 0.6987548971176147, "training_acc": 47.0, "val_loss": 0.6967940402030944, "val_acc": 52.0}
{"epoch": 17, "training_loss": 0.7024118232727051, "training_acc": 49.0, "val_loss": 0.6927874064445496, "val_acc": 52.0}
{"epoch": 18, "training_loss": 0.6925870180130005, "training_acc": 51.0, "val_loss": 0.7008030819892883, "val_acc": 48.0}
{"epoch": 19, "training_loss": 0.6973480296134948, "training_acc": 51.0, "val_loss": 0.6928998684883118, "val_acc": 52.0}
{"epoch": 20, "training_loss": 0.6988917207717895, "training_acc": 49.0, "val_loss": 0.6926251745223999, "val_acc": 52.0}
{"epoch": 21, "training_loss": 0.7061475968360901, "training_acc": 45.0, "val_loss": 0.6968968152999878, "val_acc": 48.0}
{"epoch": 22, "training_loss": 0.6960223054885865, "training_acc": 49.0, "val_loss": 0.6923845624923706, "val_acc": 52.0}
{"epoch": 23, "training_loss": 0.6960391688346863, "training_acc": 57.0, "val_loss": 0.7120967936515809, "val_acc": 48.0}
{"epoch": 24, "training_loss": 0.7121028923988342, "training_acc": 51.0, "val_loss": 0.697901701927185, "val_acc": 48.0}
{"epoch": 25, "training_loss": 0.6978895688056945, "training_acc": 43.0, "val_loss": 0.6932130670547485, "val_acc": 48.0}
{"epoch": 26, "training_loss": 0.6937413239479064, "training_acc": 51.0, "val_loss": 0.7036751198768616, "val_acc": 48.0}
{"epoch": 27, "training_loss": 0.7089716672897339, "training_acc": 51.0, "val_loss": 0.703677167892456, "val_acc": 48.0}
{"epoch": 28, "training_loss": 0.7062631988525391, "training_acc": 51.0, "val_loss": 0.7019723534584046, "val_acc": 48.0}
{"epoch": 29, "training_loss": 0.6966214776039124, "training_acc": 47.0, "val_loss": 0.6925397825241089, "val_acc": 52.0}
{"epoch": 30, "training_loss": 0.6992060732841492, "training_acc": 45.0, "val_loss": 0.694521849155426, "val_acc": 48.0}
{"epoch": 31, "training_loss": 0.6917595767974853, "training_acc": 53.0, "val_loss": 0.6934305930137634, "val_acc": 52.0}
{"epoch": 32, "training_loss": 0.7019764614105225, "training_acc": 49.0, "val_loss": 0.6925580906867981, "val_acc": 52.0}
{"epoch": 33, "training_loss": 0.6893206024169922, "training_acc": 55.0, "val_loss": 0.71941157579422, "val_acc": 48.0}
{"epoch": 34, "training_loss": 0.7249089407920838, "training_acc": 51.0, "val_loss": 0.7023448252677917, "val_acc": 48.0}
{"epoch": 35, "training_loss": 0.693566517829895, "training_acc": 51.0, "val_loss": 0.6944139194488526, "val_acc": 52.0}
{"epoch": 36, "training_loss": 0.7033605480194092, "training_acc": 49.0, "val_loss": 0.6925532150268555, "val_acc": 52.0}
{"epoch": 37, "training_loss": 0.6944225311279297, "training_acc": 49.0, "val_loss": 0.6962369537353515, "val_acc": 48.0}
{"epoch": 38, "training_loss": 0.7009703874588012, "training_acc": 51.0, "val_loss": 0.7136048746109008, "val_acc": 48.0}
{"epoch": 39, "training_loss": 0.6984638905525208, "training_acc": 51.0, "val_loss": 0.6924128818511963, "val_acc": 52.0}
{"epoch": 40, "training_loss": 0.6960635709762574, "training_acc": 49.0, "val_loss": 0.695676612854004, "val_acc": 52.0}
{"epoch": 41, "training_loss": 0.7024282312393189, "training_acc": 49.0, "val_loss": 0.6974862599372864, "val_acc": 48.0}
