"main_modify.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 8 --task ADNI_sex --input_option yAware --learning_rate 1e-3 --batch_size 16 --weight_decay 1e-6 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 0.7349733924865722, "training_acc": 43.0, "val_loss": 0.6942936825752258, "val_acc": 48.0}
{"epoch": 1, "training_loss": 0.698399658203125, "training_acc": 50.0, "val_loss": 0.701873025894165, "val_acc": 48.0}
{"epoch": 2, "training_loss": 0.7256881427764893, "training_acc": 50.0, "val_loss": 0.7010736393928528, "val_acc": 48.0}
{"epoch": 3, "training_loss": 0.69442720413208, "training_acc": 52.0, "val_loss": 0.6929090476036072, "val_acc": 52.0}
{"epoch": 4, "training_loss": 0.7047169733047486, "training_acc": 50.0, "val_loss": 0.6968509602546692, "val_acc": 48.0}
{"epoch": 5, "training_loss": 0.6966916584968567, "training_acc": 46.0, "val_loss": 0.6995874929428101, "val_acc": 48.0}
{"epoch": 6, "training_loss": 0.7112311863899231, "training_acc": 50.0, "val_loss": 0.7010061478614807, "val_acc": 48.0}
{"epoch": 7, "training_loss": 0.6947316431999206, "training_acc": 52.0, "val_loss": 0.692694251537323, "val_acc": 52.0}
{"epoch": 8, "training_loss": 0.6973406672477722, "training_acc": 50.0, "val_loss": 0.6939562106132507, "val_acc": 48.0}
{"epoch": 9, "training_loss": 0.7060004043579101, "training_acc": 50.0, "val_loss": 0.6937425327301026, "val_acc": 48.0}
{"epoch": 10, "training_loss": 0.7006201839447022, "training_acc": 54.0, "val_loss": 0.706978759765625, "val_acc": 52.0}
{"epoch": 11, "training_loss": 0.7000930285453797, "training_acc": 50.0, "val_loss": 0.704916489124298, "val_acc": 48.0}
{"epoch": 12, "training_loss": 0.7126483011245728, "training_acc": 50.0, "val_loss": 0.7098899841308594, "val_acc": 48.0}
{"epoch": 13, "training_loss": 0.7035397028923035, "training_acc": 48.0, "val_loss": 0.6967989015579223, "val_acc": 52.0}
{"epoch": 14, "training_loss": 0.7018355751037597, "training_acc": 50.0, "val_loss": 0.6923859858512879, "val_acc": 52.0}
{"epoch": 15, "training_loss": 0.6944552803039551, "training_acc": 50.0, "val_loss": 0.6941713285446167, "val_acc": 48.0}
{"epoch": 16, "training_loss": 0.6950252366065979, "training_acc": 44.0, "val_loss": 0.6952248430252075, "val_acc": 48.0}
{"epoch": 17, "training_loss": 0.6976313781738281, "training_acc": 40.0, "val_loss": 0.6948588490486145, "val_acc": 48.0}
{"epoch": 18, "training_loss": 0.701153712272644, "training_acc": 50.0, "val_loss": 0.7008174538612366, "val_acc": 48.0}
{"epoch": 19, "training_loss": 0.6987582445144653, "training_acc": 50.0, "val_loss": 0.6933024668693543, "val_acc": 52.0}
{"epoch": 20, "training_loss": 0.7023088788986206, "training_acc": 46.0, "val_loss": 0.7032333874702453, "val_acc": 48.0}
{"epoch": 21, "training_loss": 0.7031865882873535, "training_acc": 50.0, "val_loss": 0.6959160661697388, "val_acc": 48.0}
{"epoch": 22, "training_loss": 0.6913357305526734, "training_acc": 52.0, "val_loss": 0.6931082272529602, "val_acc": 52.0}
{"epoch": 23, "training_loss": 0.7030830907821656, "training_acc": 50.0, "val_loss": 0.6923849225044251, "val_acc": 52.0}
{"epoch": 24, "training_loss": 0.7065291976928711, "training_acc": 50.0, "val_loss": 0.7012971997261047, "val_acc": 48.0}
{"epoch": 25, "training_loss": 0.6962783908843995, "training_acc": 48.0, "val_loss": 0.6937708306312561, "val_acc": 52.0}
{"epoch": 26, "training_loss": 0.7166980624198913, "training_acc": 50.0, "val_loss": 0.6934132838249206, "val_acc": 52.0}
{"epoch": 27, "training_loss": 0.7010556149482727, "training_acc": 46.0, "val_loss": 0.7017811894416809, "val_acc": 48.0}
{"epoch": 28, "training_loss": 0.6989888572692871, "training_acc": 50.0, "val_loss": 0.6932423686981202, "val_acc": 48.0}
{"epoch": 29, "training_loss": 0.70125816822052, "training_acc": 48.0, "val_loss": 0.698777859210968, "val_acc": 52.0}
{"epoch": 30, "training_loss": 0.7040133571624756, "training_acc": 50.0, "val_loss": 0.6926703381538392, "val_acc": 52.0}
{"epoch": 31, "training_loss": 0.6982746028900146, "training_acc": 50.0, "val_loss": 0.6931217503547669, "val_acc": 52.0}
{"epoch": 32, "training_loss": 0.6946567940711975, "training_acc": 50.0, "val_loss": 0.6982246041297913, "val_acc": 48.0}
{"epoch": 33, "training_loss": 0.7058837175369262, "training_acc": 50.0, "val_loss": 0.698865511417389, "val_acc": 48.0}
{"epoch": 34, "training_loss": 0.6854748678207397, "training_acc": 60.0, "val_loss": 0.6955584645271301, "val_acc": 52.0}
{"epoch": 35, "training_loss": 0.715393397808075, "training_acc": 50.0, "val_loss": 0.6928790092468262, "val_acc": 52.0}
{"epoch": 36, "training_loss": 0.6905528545379639, "training_acc": 50.0, "val_loss": 0.7176494216918945, "val_acc": 48.0}
{"epoch": 37, "training_loss": 0.7152891683578492, "training_acc": 50.0, "val_loss": 0.6990044355392456, "val_acc": 48.0}
{"epoch": 38, "training_loss": 0.6949190354347229, "training_acc": 50.0, "val_loss": 0.6928359603881836, "val_acc": 52.0}
{"epoch": 39, "training_loss": 0.696470787525177, "training_acc": 50.0, "val_loss": 0.6925204181671143, "val_acc": 52.0}
{"epoch": 40, "training_loss": 0.6950705289840698, "training_acc": 50.0, "val_loss": 0.693794846534729, "val_acc": 48.0}
{"epoch": 41, "training_loss": 0.6948142528533936, "training_acc": 50.0, "val_loss": 0.6975728154182435, "val_acc": 48.0}
{"epoch": 42, "training_loss": 0.6952854013442993, "training_acc": 50.0, "val_loss": 0.6930803513526916, "val_acc": 52.0}
{"epoch": 43, "training_loss": 0.70182781457901, "training_acc": 50.0, "val_loss": 0.6923499989509583, "val_acc": 52.0}
{"epoch": 44, "training_loss": 0.6970330548286437, "training_acc": 38.0, "val_loss": 0.6945514678955078, "val_acc": 48.0}
{"epoch": 45, "training_loss": 0.7220957970619202, "training_acc": 50.0, "val_loss": 0.696934678554535, "val_acc": 48.0}
{"epoch": 46, "training_loss": 0.7077135467529296, "training_acc": 48.0, "val_loss": 0.7125872635841369, "val_acc": 52.0}
{"epoch": 47, "training_loss": 0.7173919582366943, "training_acc": 50.0, "val_loss": 0.6923885464668273, "val_acc": 52.0}
{"epoch": 48, "training_loss": 0.7023757219314575, "training_acc": 50.0, "val_loss": 0.6924944806098938, "val_acc": 52.0}
{"epoch": 49, "training_loss": 0.699832935333252, "training_acc": 52.0, "val_loss": 0.7129988408088684, "val_acc": 48.0}
{"epoch": 50, "training_loss": 0.7149276661872864, "training_acc": 40.0, "val_loss": 0.6928004646301269, "val_acc": 52.0}
{"epoch": 51, "training_loss": 0.6989271473884583, "training_acc": 48.0, "val_loss": 0.6944227600097657, "val_acc": 48.0}
{"epoch": 52, "training_loss": 0.6968037748336792, "training_acc": 50.0, "val_loss": 0.6927457451820374, "val_acc": 52.0}
{"epoch": 53, "training_loss": 0.7065067291259766, "training_acc": 50.0, "val_loss": 0.692574360370636, "val_acc": 52.0}
{"epoch": 54, "training_loss": 0.715500316619873, "training_acc": 42.0, "val_loss": 0.7197710418701172, "val_acc": 48.0}
{"epoch": 55, "training_loss": 0.7168163537979126, "training_acc": 50.0, "val_loss": 0.6945007705688476, "val_acc": 48.0}
{"epoch": 56, "training_loss": 0.6980383157730102, "training_acc": 50.0, "val_loss": 0.6996111369132996, "val_acc": 48.0}
{"epoch": 57, "training_loss": 0.697566590309143, "training_acc": 50.0, "val_loss": 0.6950952935218812, "val_acc": 48.0}
{"epoch": 58, "training_loss": 0.694955542087555, "training_acc": 48.0, "val_loss": 0.6929951930046081, "val_acc": 52.0}
{"epoch": 59, "training_loss": 0.6934207201004028, "training_acc": 48.0, "val_loss": 0.6945234751701355, "val_acc": 48.0}
{"epoch": 60, "training_loss": 0.7086052799224853, "training_acc": 50.0, "val_loss": 0.6994127750396728, "val_acc": 48.0}
{"epoch": 61, "training_loss": 0.6984443902969361, "training_acc": 50.0, "val_loss": 0.6942511081695557, "val_acc": 48.0}
{"epoch": 62, "training_loss": 0.6933364200592042, "training_acc": 50.0, "val_loss": 0.6925214648246765, "val_acc": 52.0}
