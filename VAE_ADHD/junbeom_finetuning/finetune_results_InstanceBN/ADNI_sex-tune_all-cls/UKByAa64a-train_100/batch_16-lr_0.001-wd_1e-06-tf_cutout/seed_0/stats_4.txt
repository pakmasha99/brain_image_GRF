"main_modify.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ADNI_sex --input_option yAware --learning_rate 1e-3 --batch_size 16 --weight_decay 1e-6 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 0.7027489924430848, "training_acc": 56.0, "val_loss": 0.7380865645408631, "val_acc": 48.0}
{"epoch": 1, "training_loss": 0.7067427062988281, "training_acc": 50.0, "val_loss": 0.693256504535675, "val_acc": 52.0}
{"epoch": 2, "training_loss": 0.7081510639190673, "training_acc": 48.0, "val_loss": 0.6975014543533326, "val_acc": 48.0}
{"epoch": 3, "training_loss": 0.6992541527748108, "training_acc": 42.0, "val_loss": 0.6926546096801758, "val_acc": 52.0}
{"epoch": 4, "training_loss": 0.6990707206726074, "training_acc": 44.0, "val_loss": 0.6973971176147461, "val_acc": 48.0}
{"epoch": 5, "training_loss": 0.7001455402374268, "training_acc": 48.0, "val_loss": 0.6966489720344543, "val_acc": 48.0}
{"epoch": 6, "training_loss": 0.6993797445297241, "training_acc": 48.0, "val_loss": 0.6925076770782471, "val_acc": 52.0}
{"epoch": 7, "training_loss": 0.7157437086105347, "training_acc": 44.0, "val_loss": 0.6944736266136169, "val_acc": 48.0}
{"epoch": 8, "training_loss": 0.7083268690109253, "training_acc": 48.0, "val_loss": 0.6950600504875183, "val_acc": 52.0}
{"epoch": 9, "training_loss": 0.7155311679840088, "training_acc": 48.0, "val_loss": 0.6963395810127259, "val_acc": 48.0}
{"epoch": 10, "training_loss": 0.6964284992218017, "training_acc": 50.0, "val_loss": 0.6928436303138733, "val_acc": 52.0}
{"epoch": 11, "training_loss": 0.7030356979370117, "training_acc": 42.0, "val_loss": 0.692477035522461, "val_acc": 52.0}
{"epoch": 12, "training_loss": 0.6992144632339478, "training_acc": 50.0, "val_loss": 0.6924386382102966, "val_acc": 52.0}
{"epoch": 13, "training_loss": 0.6915883922576904, "training_acc": 53.0, "val_loss": 0.7099960827827454, "val_acc": 48.0}
{"epoch": 14, "training_loss": 0.7025477123260498, "training_acc": 50.0, "val_loss": 0.6924010038375854, "val_acc": 52.0}
{"epoch": 15, "training_loss": 0.7026651120185852, "training_acc": 50.0, "val_loss": 0.6926894211769103, "val_acc": 52.0}
{"epoch": 16, "training_loss": 0.6972860670089722, "training_acc": 50.0, "val_loss": 0.6973068165779114, "val_acc": 48.0}
{"epoch": 17, "training_loss": 0.694139723777771, "training_acc": 54.0, "val_loss": 0.6930186080932618, "val_acc": 52.0}
{"epoch": 18, "training_loss": 0.7010530209541321, "training_acc": 44.0, "val_loss": 0.6986791205406189, "val_acc": 48.0}
{"epoch": 19, "training_loss": 0.6964521074295044, "training_acc": 44.0, "val_loss": 0.6934721755981446, "val_acc": 48.0}
{"epoch": 20, "training_loss": 0.6946902704238892, "training_acc": 46.0, "val_loss": 0.6943665719032288, "val_acc": 48.0}
{"epoch": 21, "training_loss": 0.698934063911438, "training_acc": 50.0, "val_loss": 0.6941362738609314, "val_acc": 48.0}
{"epoch": 22, "training_loss": 0.6915774798393249, "training_acc": 54.0, "val_loss": 0.6971718192100524, "val_acc": 52.0}
{"epoch": 23, "training_loss": 0.7301258754730224, "training_acc": 50.0, "val_loss": 0.6931621623039246, "val_acc": 52.0}
{"epoch": 24, "training_loss": 0.7288588142395019, "training_acc": 46.0, "val_loss": 0.7175653052330017, "val_acc": 48.0}
{"epoch": 25, "training_loss": 0.6942223644256592, "training_acc": 52.0, "val_loss": 0.696296043395996, "val_acc": 52.0}
{"epoch": 26, "training_loss": 0.7247823405265809, "training_acc": 50.0, "val_loss": 0.6968341159820557, "val_acc": 52.0}
{"epoch": 27, "training_loss": 0.7175951266288757, "training_acc": 46.0, "val_loss": 0.7285702466964722, "val_acc": 48.0}
{"epoch": 28, "training_loss": 0.72103515625, "training_acc": 50.0, "val_loss": 0.6925831365585328, "val_acc": 52.0}
{"epoch": 29, "training_loss": 0.6964302301406861, "training_acc": 44.0, "val_loss": 0.6923573994636536, "val_acc": 52.0}
{"epoch": 30, "training_loss": 0.6971730279922486, "training_acc": 50.0, "val_loss": 0.6960375928878784, "val_acc": 48.0}
{"epoch": 31, "training_loss": 0.7039685440063477, "training_acc": 50.0, "val_loss": 0.6993074822425842, "val_acc": 48.0}
{"epoch": 32, "training_loss": 0.7212802791595458, "training_acc": 50.0, "val_loss": 0.6940478944778442, "val_acc": 48.0}
{"epoch": 33, "training_loss": 0.7126296806335449, "training_acc": 50.0, "val_loss": 0.7019864368438721, "val_acc": 52.0}
{"epoch": 34, "training_loss": 0.6975709390640259, "training_acc": 52.0, "val_loss": 0.7145679450035095, "val_acc": 48.0}
{"epoch": 35, "training_loss": 0.7102361059188843, "training_acc": 50.0, "val_loss": 0.6983419275283813, "val_acc": 48.0}
{"epoch": 36, "training_loss": 0.7130817890167236, "training_acc": 50.0, "val_loss": 0.6987365245819092, "val_acc": 52.0}
{"epoch": 37, "training_loss": 0.6933781576156616, "training_acc": 54.0, "val_loss": 0.7077092432975769, "val_acc": 48.0}
{"epoch": 38, "training_loss": 0.7247193312644958, "training_acc": 50.0, "val_loss": 0.7059969639778138, "val_acc": 48.0}
{"epoch": 39, "training_loss": 0.7046921253204346, "training_acc": 44.0, "val_loss": 0.6936338305473327, "val_acc": 52.0}
{"epoch": 40, "training_loss": 0.6912066173553467, "training_acc": 52.0, "val_loss": 0.7029280710220337, "val_acc": 48.0}
{"epoch": 41, "training_loss": 0.7017728638648987, "training_acc": 50.0, "val_loss": 0.6937613415718079, "val_acc": 48.0}
{"epoch": 42, "training_loss": 0.6940892291069031, "training_acc": 52.0, "val_loss": 0.6923439073562622, "val_acc": 52.0}
{"epoch": 43, "training_loss": 0.6976692485809326, "training_acc": 50.0, "val_loss": 0.6955569100379944, "val_acc": 48.0}
{"epoch": 44, "training_loss": 0.7058211612701416, "training_acc": 50.0, "val_loss": 0.6939376902580261, "val_acc": 48.0}
{"epoch": 45, "training_loss": 0.6873227882385254, "training_acc": 58.0, "val_loss": 0.7018235945701599, "val_acc": 52.0}
{"epoch": 46, "training_loss": 0.7099161052703857, "training_acc": 50.0, "val_loss": 0.6933592534065247, "val_acc": 52.0}
{"epoch": 47, "training_loss": 0.7219841933250427, "training_acc": 38.0, "val_loss": 0.7020650601387024, "val_acc": 48.0}
{"epoch": 48, "training_loss": 0.6934673237800598, "training_acc": 50.0, "val_loss": 0.6964450812339783, "val_acc": 52.0}
{"epoch": 49, "training_loss": 0.6974788069725036, "training_acc": 48.0, "val_loss": 0.6938851833343506, "val_acc": 48.0}
{"epoch": 50, "training_loss": 0.7032029438018799, "training_acc": 50.0, "val_loss": 0.6937231540679931, "val_acc": 48.0}
{"epoch": 51, "training_loss": 0.6999026131629944, "training_acc": 52.0, "val_loss": 0.6995862746238708, "val_acc": 52.0}
{"epoch": 52, "training_loss": 0.698941502571106, "training_acc": 48.0, "val_loss": 0.7073344421386719, "val_acc": 48.0}
{"epoch": 53, "training_loss": 0.6972690153121949, "training_acc": 50.0, "val_loss": 0.6933642196655273, "val_acc": 48.0}
{"epoch": 54, "training_loss": 0.7041683769226075, "training_acc": 48.0, "val_loss": 0.6923502779006958, "val_acc": 52.0}
{"epoch": 55, "training_loss": 0.6975883579254151, "training_acc": 50.0, "val_loss": 0.7064743041992188, "val_acc": 48.0}
{"epoch": 56, "training_loss": 0.7032512068748474, "training_acc": 50.0, "val_loss": 0.6975590848922729, "val_acc": 48.0}
{"epoch": 57, "training_loss": 0.6891795182228089, "training_acc": 54.0, "val_loss": 0.6957386708259583, "val_acc": 52.0}
{"epoch": 58, "training_loss": 0.7015204477310181, "training_acc": 50.0, "val_loss": 0.6926241040229797, "val_acc": 52.0}
{"epoch": 59, "training_loss": 0.712252984046936, "training_acc": 40.0, "val_loss": 0.7027776193618774, "val_acc": 48.0}
{"epoch": 60, "training_loss": 0.6952525472640991, "training_acc": 50.0, "val_loss": 0.6923676562309266, "val_acc": 52.0}
{"epoch": 61, "training_loss": 0.7013558912277221, "training_acc": 50.0, "val_loss": 0.6942275309562683, "val_acc": 52.0}
