"main_modify.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ADNI_sex --input_option yAware --learning_rate 1e-3 --batch_size 16 --weight_decay 1e-6 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 0.6871145129203796, "training_acc": 51.0, "val_loss": 0.7013030028343201, "val_acc": 48.0}
{"epoch": 1, "training_loss": 0.6935987854003907, "training_acc": 56.0, "val_loss": 0.6975621438026428, "val_acc": 52.0}
{"epoch": 2, "training_loss": 0.6988478994369507, "training_acc": 54.0, "val_loss": 0.7066991472244263, "val_acc": 48.0}
{"epoch": 3, "training_loss": 0.7069303655624389, "training_acc": 48.0, "val_loss": 0.7008546471595765, "val_acc": 52.0}
{"epoch": 4, "training_loss": 0.710227882862091, "training_acc": 50.0, "val_loss": 0.6929109692573547, "val_acc": 52.0}
{"epoch": 5, "training_loss": 0.7018092203140259, "training_acc": 48.0, "val_loss": 0.6975202202796936, "val_acc": 48.0}
{"epoch": 6, "training_loss": 0.6918579435348511, "training_acc": 54.0, "val_loss": 0.6942135310173034, "val_acc": 52.0}
{"epoch": 7, "training_loss": 0.7160111951828003, "training_acc": 50.0, "val_loss": 0.6924374127388, "val_acc": 52.0}
{"epoch": 8, "training_loss": 0.6950899076461792, "training_acc": 48.0, "val_loss": 0.6940885996818542, "val_acc": 48.0}
{"epoch": 9, "training_loss": 0.6949034738540649, "training_acc": 48.0, "val_loss": 0.6927102994918823, "val_acc": 52.0}
{"epoch": 10, "training_loss": 0.6998639392852783, "training_acc": 42.0, "val_loss": 0.6927066707611084, "val_acc": 52.0}
{"epoch": 11, "training_loss": 0.7025946521759033, "training_acc": 40.0, "val_loss": 0.6924156975746155, "val_acc": 52.0}
{"epoch": 12, "training_loss": 0.702159514427185, "training_acc": 46.0, "val_loss": 0.6998726320266724, "val_acc": 48.0}
{"epoch": 13, "training_loss": 0.6957133984565735, "training_acc": 52.0, "val_loss": 0.6956033754348755, "val_acc": 52.0}
{"epoch": 14, "training_loss": 0.7017827367782593, "training_acc": 46.0, "val_loss": 0.6996002960205078, "val_acc": 48.0}
{"epoch": 15, "training_loss": 0.6974677324295044, "training_acc": 50.0, "val_loss": 0.702040753364563, "val_acc": 48.0}
{"epoch": 16, "training_loss": 0.7108681917190551, "training_acc": 40.0, "val_loss": 0.6958580756187439, "val_acc": 48.0}
{"epoch": 17, "training_loss": 0.7024760484695435, "training_acc": 50.0, "val_loss": 0.7109829449653625, "val_acc": 48.0}
{"epoch": 18, "training_loss": 0.7012344598770142, "training_acc": 46.0, "val_loss": 0.6934684419631958, "val_acc": 52.0}
{"epoch": 19, "training_loss": 0.7018245315551758, "training_acc": 50.0, "val_loss": 0.693575325012207, "val_acc": 48.0}
{"epoch": 20, "training_loss": 0.6967357206344604, "training_acc": 50.0, "val_loss": 0.6942740631103516, "val_acc": 48.0}
{"epoch": 21, "training_loss": 0.6994143486022949, "training_acc": 48.0, "val_loss": 0.6948296284675598, "val_acc": 52.0}
{"epoch": 22, "training_loss": 0.6943296384811402, "training_acc": 52.0, "val_loss": 0.697217378616333, "val_acc": 48.0}
{"epoch": 23, "training_loss": 0.697342553138733, "training_acc": 50.0, "val_loss": 0.6941156506538391, "val_acc": 48.0}
{"epoch": 24, "training_loss": 0.6984395551681518, "training_acc": 48.0, "val_loss": 0.6923457312583924, "val_acc": 52.0}
{"epoch": 25, "training_loss": 0.70252454996109, "training_acc": 50.0, "val_loss": 0.701670880317688, "val_acc": 48.0}
{"epoch": 26, "training_loss": 0.7082421970367432, "training_acc": 44.0, "val_loss": 0.6938564038276672, "val_acc": 52.0}
{"epoch": 27, "training_loss": 0.7039145231246948, "training_acc": 48.0, "val_loss": 0.6929043316841126, "val_acc": 52.0}
{"epoch": 28, "training_loss": 0.6957339859008789, "training_acc": 50.0, "val_loss": 0.6925175905227661, "val_acc": 52.0}
{"epoch": 29, "training_loss": 0.6956067514419556, "training_acc": 48.0, "val_loss": 0.693336181640625, "val_acc": 48.0}
{"epoch": 30, "training_loss": 0.7048026156425476, "training_acc": 40.0, "val_loss": 0.6923445677757263, "val_acc": 52.0}
{"epoch": 31, "training_loss": 0.7097797632217407, "training_acc": 50.0, "val_loss": 0.6987269186973571, "val_acc": 52.0}
{"epoch": 32, "training_loss": 0.7089792966842652, "training_acc": 46.0, "val_loss": 0.7186539530754089, "val_acc": 48.0}
{"epoch": 33, "training_loss": 0.702759256362915, "training_acc": 50.0, "val_loss": 0.6925652313232422, "val_acc": 52.0}
{"epoch": 34, "training_loss": 0.6967724657058716, "training_acc": 50.0, "val_loss": 0.6924259305000305, "val_acc": 52.0}
{"epoch": 35, "training_loss": 0.6935158491134643, "training_acc": 50.0, "val_loss": 0.703159954547882, "val_acc": 48.0}
{"epoch": 36, "training_loss": 0.7012182068824768, "training_acc": 50.0, "val_loss": 0.6972419452667237, "val_acc": 48.0}
{"epoch": 37, "training_loss": 0.6948625516891479, "training_acc": 50.0, "val_loss": 0.6945047807693482, "val_acc": 52.0}
{"epoch": 38, "training_loss": 0.7076830172538757, "training_acc": 50.0, "val_loss": 0.6935595011711121, "val_acc": 52.0}
{"epoch": 39, "training_loss": 0.7139213037490845, "training_acc": 44.0, "val_loss": 0.7131854724884034, "val_acc": 48.0}
{"epoch": 40, "training_loss": 0.6991324663162232, "training_acc": 50.0, "val_loss": 0.6949573540687561, "val_acc": 52.0}
{"epoch": 41, "training_loss": 0.6984054803848266, "training_acc": 46.0, "val_loss": 0.6944950151443482, "val_acc": 48.0}
{"epoch": 42, "training_loss": 0.6981312036514282, "training_acc": 44.0, "val_loss": 0.6927476048469543, "val_acc": 52.0}
{"epoch": 43, "training_loss": 0.7253541493415833, "training_acc": 50.0, "val_loss": 0.6928057026863098, "val_acc": 52.0}
{"epoch": 44, "training_loss": 0.6926601028442383, "training_acc": 52.0, "val_loss": 0.731062695980072, "val_acc": 48.0}
{"epoch": 45, "training_loss": 0.7026774549484253, "training_acc": 50.0, "val_loss": 0.6929895877838135, "val_acc": 52.0}
{"epoch": 46, "training_loss": 0.6997991037368775, "training_acc": 40.0, "val_loss": 0.6932387280464173, "val_acc": 48.0}
{"epoch": 47, "training_loss": 0.6962705278396606, "training_acc": 50.0, "val_loss": 0.6939474081993103, "val_acc": 48.0}
{"epoch": 48, "training_loss": 0.6957094693183898, "training_acc": 48.0, "val_loss": 0.6923537015914917, "val_acc": 52.0}
{"epoch": 49, "training_loss": 0.6988235855102539, "training_acc": 46.0, "val_loss": 0.6967272472381592, "val_acc": 48.0}
