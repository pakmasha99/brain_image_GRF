"main_modify.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 7 --task ADNI_sex --input_option yAware --learning_rate 1e-3 --batch_size 16 --weight_decay 1e-6 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 0.6861768293380738, "training_acc": 58.0, "val_loss": 0.6996554160118102, "val_acc": 52.0}
{"epoch": 1, "training_loss": 0.7070490980148315, "training_acc": 46.0, "val_loss": 0.692564251422882, "val_acc": 52.0}
{"epoch": 2, "training_loss": 0.702293004989624, "training_acc": 50.0, "val_loss": 0.6940843200683594, "val_acc": 52.0}
{"epoch": 3, "training_loss": 0.7197201704978943, "training_acc": 50.0, "val_loss": 0.6932467699050904, "val_acc": 52.0}
{"epoch": 4, "training_loss": 0.7089280748367309, "training_acc": 46.0, "val_loss": 0.7019005227088928, "val_acc": 48.0}
{"epoch": 5, "training_loss": 0.7044254112243652, "training_acc": 42.0, "val_loss": 0.6926840519905091, "val_acc": 52.0}
{"epoch": 6, "training_loss": 0.7000344181060791, "training_acc": 50.0, "val_loss": 0.692442979812622, "val_acc": 52.0}
{"epoch": 7, "training_loss": 0.695196738243103, "training_acc": 48.0, "val_loss": 0.6977632927894593, "val_acc": 48.0}
{"epoch": 8, "training_loss": 0.6987681126594544, "training_acc": 50.0, "val_loss": 0.6945834517478943, "val_acc": 48.0}
{"epoch": 9, "training_loss": 0.695372531414032, "training_acc": 42.0, "val_loss": 0.6934370446205139, "val_acc": 48.0}
{"epoch": 10, "training_loss": 0.6972213315963746, "training_acc": 50.0, "val_loss": 0.6958134031295776, "val_acc": 48.0}
{"epoch": 11, "training_loss": 0.6998769545555115, "training_acc": 50.0, "val_loss": 0.6933352017402649, "val_acc": 48.0}
{"epoch": 12, "training_loss": 0.6985021305084228, "training_acc": 50.0, "val_loss": 0.6923807406425476, "val_acc": 52.0}
{"epoch": 13, "training_loss": 0.6969362282752991, "training_acc": 50.0, "val_loss": 0.6973631381988525, "val_acc": 48.0}
{"epoch": 14, "training_loss": 0.6962849497795105, "training_acc": 50.0, "val_loss": 0.6923703050613403, "val_acc": 52.0}
{"epoch": 15, "training_loss": 0.7029456543922424, "training_acc": 50.0, "val_loss": 0.6941854429244995, "val_acc": 52.0}
{"epoch": 16, "training_loss": 0.7103038167953492, "training_acc": 50.0, "val_loss": 0.7193882870674133, "val_acc": 48.0}
{"epoch": 17, "training_loss": 0.6932740259170532, "training_acc": 50.0, "val_loss": 0.6949588704109192, "val_acc": 52.0}
{"epoch": 18, "training_loss": 0.7207561564445496, "training_acc": 50.0, "val_loss": 0.711830940246582, "val_acc": 52.0}
{"epoch": 19, "training_loss": 0.7062916374206543, "training_acc": 50.0, "val_loss": 0.6990376591682435, "val_acc": 48.0}
{"epoch": 20, "training_loss": 0.6956503295898437, "training_acc": 50.0, "val_loss": 0.6923526740074157, "val_acc": 52.0}
{"epoch": 21, "training_loss": 0.7066716194152832, "training_acc": 50.0, "val_loss": 0.6936977005004883, "val_acc": 52.0}
{"epoch": 22, "training_loss": 0.6931284260749817, "training_acc": 52.0, "val_loss": 0.7067386054992676, "val_acc": 48.0}
{"epoch": 23, "training_loss": 0.7006532764434814, "training_acc": 50.0, "val_loss": 0.6924207210540771, "val_acc": 52.0}
{"epoch": 24, "training_loss": 0.7118472671508789, "training_acc": 50.0, "val_loss": 0.6958965587615967, "val_acc": 52.0}
{"epoch": 25, "training_loss": 0.6884231805801392, "training_acc": 56.0, "val_loss": 0.7245245385169983, "val_acc": 48.0}
{"epoch": 26, "training_loss": 0.7127075529098511, "training_acc": 50.0, "val_loss": 0.6932429194450378, "val_acc": 48.0}
{"epoch": 27, "training_loss": 0.6953806018829346, "training_acc": 48.0, "val_loss": 0.6926351857185363, "val_acc": 52.0}
{"epoch": 28, "training_loss": 0.6946086287498474, "training_acc": 50.0, "val_loss": 0.6947457313537597, "val_acc": 48.0}
{"epoch": 29, "training_loss": 0.700814733505249, "training_acc": 50.0, "val_loss": 0.6980341410636902, "val_acc": 48.0}
{"epoch": 30, "training_loss": 0.7004066181182861, "training_acc": 40.0, "val_loss": 0.6927235150337219, "val_acc": 52.0}
{"epoch": 31, "training_loss": 0.7151180076599121, "training_acc": 50.0, "val_loss": 0.6935849714279175, "val_acc": 52.0}
{"epoch": 32, "training_loss": 0.6952184557914733, "training_acc": 48.0, "val_loss": 0.7024454617500305, "val_acc": 48.0}
{"epoch": 33, "training_loss": 0.7101946592330932, "training_acc": 50.0, "val_loss": 0.703247537612915, "val_acc": 48.0}
{"epoch": 34, "training_loss": 0.6976848149299621, "training_acc": 50.0, "val_loss": 0.6940940427780151, "val_acc": 52.0}
{"epoch": 35, "training_loss": 0.6976697015762329, "training_acc": 48.0, "val_loss": 0.6927377438545227, "val_acc": 52.0}
{"epoch": 36, "training_loss": 0.6962793588638305, "training_acc": 50.0, "val_loss": 0.6923831987380982, "val_acc": 52.0}
{"epoch": 37, "training_loss": 0.7035402679443359, "training_acc": 50.0, "val_loss": 0.693277325630188, "val_acc": 48.0}
{"epoch": 38, "training_loss": 0.7075831151008606, "training_acc": 50.0, "val_loss": 0.6973377728462219, "val_acc": 48.0}
{"epoch": 39, "training_loss": 0.6952111625671387, "training_acc": 50.0, "val_loss": 0.6923652577400208, "val_acc": 52.0}
