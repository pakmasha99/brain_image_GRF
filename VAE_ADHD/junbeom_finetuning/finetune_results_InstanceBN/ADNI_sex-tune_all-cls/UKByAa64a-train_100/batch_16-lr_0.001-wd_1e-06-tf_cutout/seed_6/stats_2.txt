"main_modify.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 6 --task ADNI_sex --input_option yAware --learning_rate 1e-3 --batch_size 16 --weight_decay 1e-6 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 0.701079683303833, "training_acc": 46.0, "val_loss": 0.7010810089111328, "val_acc": 48.0}
{"epoch": 1, "training_loss": 0.6897331357002259, "training_acc": 56.0, "val_loss": 0.7156082320213318, "val_acc": 52.0}
{"epoch": 2, "training_loss": 0.7220124769210815, "training_acc": 44.0, "val_loss": 0.6923596382141113, "val_acc": 52.0}
{"epoch": 3, "training_loss": 0.7027598190307617, "training_acc": 46.0, "val_loss": 0.6962328958511352, "val_acc": 48.0}
{"epoch": 4, "training_loss": 0.703120231628418, "training_acc": 40.0, "val_loss": 0.6965465116500854, "val_acc": 48.0}
{"epoch": 5, "training_loss": 0.7037497615814209, "training_acc": 46.0, "val_loss": 0.6962294816970825, "val_acc": 48.0}
{"epoch": 6, "training_loss": 0.7030399060249328, "training_acc": 50.0, "val_loss": 0.70299560546875, "val_acc": 48.0}
{"epoch": 7, "training_loss": 0.706955018043518, "training_acc": 44.0, "val_loss": 0.692506685256958, "val_acc": 52.0}
{"epoch": 8, "training_loss": 0.7051191067695618, "training_acc": 46.0, "val_loss": 0.6973266243934632, "val_acc": 48.0}
{"epoch": 9, "training_loss": 0.7090068984031678, "training_acc": 50.0, "val_loss": 0.6923584103584289, "val_acc": 52.0}
{"epoch": 10, "training_loss": 0.6972599387168884, "training_acc": 50.0, "val_loss": 0.6932524490356445, "val_acc": 52.0}
{"epoch": 11, "training_loss": 0.701324372291565, "training_acc": 50.0, "val_loss": 0.6932773590087891, "val_acc": 48.0}
{"epoch": 12, "training_loss": 0.6986120581626892, "training_acc": 40.0, "val_loss": 0.698744580745697, "val_acc": 48.0}
{"epoch": 13, "training_loss": 0.703702073097229, "training_acc": 50.0, "val_loss": 0.7033724904060363, "val_acc": 48.0}
{"epoch": 14, "training_loss": 0.7403246879577636, "training_acc": 50.0, "val_loss": 0.700706603527069, "val_acc": 48.0}
{"epoch": 15, "training_loss": 0.7454431128501892, "training_acc": 44.0, "val_loss": 0.7157613635063171, "val_acc": 52.0}
{"epoch": 16, "training_loss": 0.707849714756012, "training_acc": 48.0, "val_loss": 0.7009840250015259, "val_acc": 48.0}
{"epoch": 17, "training_loss": 0.6988005208969116, "training_acc": 50.0, "val_loss": 0.692827844619751, "val_acc": 52.0}
{"epoch": 18, "training_loss": 0.7037111330032348, "training_acc": 50.0, "val_loss": 0.6949099445343018, "val_acc": 52.0}
{"epoch": 19, "training_loss": 0.7024235582351684, "training_acc": 50.0, "val_loss": 0.6949827289581298, "val_acc": 48.0}
{"epoch": 20, "training_loss": 0.700162250995636, "training_acc": 50.0, "val_loss": 0.709274218082428, "val_acc": 48.0}
{"epoch": 21, "training_loss": 0.7106314897537231, "training_acc": 42.0, "val_loss": 0.6924379467964172, "val_acc": 52.0}
{"epoch": 22, "training_loss": 0.7030921792984008, "training_acc": 40.0, "val_loss": 0.6954961681365966, "val_acc": 48.0}
{"epoch": 23, "training_loss": 0.6970647764205933, "training_acc": 40.0, "val_loss": 0.6930839467048645, "val_acc": 52.0}
{"epoch": 24, "training_loss": 0.70071359872818, "training_acc": 50.0, "val_loss": 0.6923518800735473, "val_acc": 52.0}
{"epoch": 25, "training_loss": 0.6957639503479004, "training_acc": 46.0, "val_loss": 0.6943700885772706, "val_acc": 48.0}
{"epoch": 26, "training_loss": 0.6954139566421509, "training_acc": 50.0, "val_loss": 0.69463219165802, "val_acc": 48.0}
{"epoch": 27, "training_loss": 0.6943584966659546, "training_acc": 48.0, "val_loss": 0.6928385734558106, "val_acc": 52.0}
{"epoch": 28, "training_loss": 0.6953938341140747, "training_acc": 44.0, "val_loss": 0.6963795804977417, "val_acc": 48.0}
{"epoch": 29, "training_loss": 0.7043949270248413, "training_acc": 50.0, "val_loss": 0.6999711346626282, "val_acc": 48.0}
{"epoch": 30, "training_loss": 0.695320405960083, "training_acc": 50.0, "val_loss": 0.6933677673339844, "val_acc": 52.0}
{"epoch": 31, "training_loss": 0.6976299381256104, "training_acc": 50.0, "val_loss": 0.6957498955726623, "val_acc": 48.0}
{"epoch": 32, "training_loss": 0.7009024477005005, "training_acc": 50.0, "val_loss": 0.6945325946807861, "val_acc": 48.0}
{"epoch": 33, "training_loss": 0.6965060687065124, "training_acc": 50.0, "val_loss": 0.69347008228302, "val_acc": 52.0}
{"epoch": 34, "training_loss": 0.7006262803077697, "training_acc": 50.0, "val_loss": 0.6927186346054077, "val_acc": 52.0}
{"epoch": 35, "training_loss": 0.6946299147605896, "training_acc": 50.0, "val_loss": 0.6931924915313721, "val_acc": 48.0}
{"epoch": 36, "training_loss": 0.6964313316345215, "training_acc": 50.0, "val_loss": 0.6982509994506836, "val_acc": 48.0}
{"epoch": 37, "training_loss": 0.6989935493469238, "training_acc": 50.0, "val_loss": 0.6927098059654235, "val_acc": 52.0}
{"epoch": 38, "training_loss": 0.6946401357650757, "training_acc": 50.0, "val_loss": 0.6938653349876404, "val_acc": 52.0}
{"epoch": 39, "training_loss": 0.7044316792488098, "training_acc": 44.0, "val_loss": 0.6938615012168884, "val_acc": 48.0}
{"epoch": 40, "training_loss": 0.694863076210022, "training_acc": 52.0, "val_loss": 0.6954866933822632, "val_acc": 52.0}
{"epoch": 41, "training_loss": 0.7142281198501587, "training_acc": 50.0, "val_loss": 0.6980908799171448, "val_acc": 52.0}
{"epoch": 42, "training_loss": 0.6958762526512146, "training_acc": 50.0, "val_loss": 0.6957016587257385, "val_acc": 48.0}
{"epoch": 43, "training_loss": 0.6945081996917725, "training_acc": 50.0, "val_loss": 0.7000952219963074, "val_acc": 48.0}
