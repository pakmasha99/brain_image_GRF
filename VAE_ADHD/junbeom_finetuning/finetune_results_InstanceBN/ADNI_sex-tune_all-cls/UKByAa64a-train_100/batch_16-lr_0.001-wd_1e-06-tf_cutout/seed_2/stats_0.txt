"main_modify.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 2 --task ADNI_sex --input_option yAware --learning_rate 1e-3 --batch_size 16 --weight_decay 1e-6 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 0.7070711064338684, "training_acc": 49.0, "val_loss": 0.6988980054855347, "val_acc": 48.0}
{"epoch": 1, "training_loss": 0.7161785292625428, "training_acc": 52.0, "val_loss": 0.6990479707717896, "val_acc": 52.0}
{"epoch": 2, "training_loss": 0.7004283285140991, "training_acc": 52.0, "val_loss": 0.7128501653671264, "val_acc": 48.0}
{"epoch": 3, "training_loss": 0.7093878555297851, "training_acc": 50.0, "val_loss": 0.7014054322242737, "val_acc": 48.0}
{"epoch": 4, "training_loss": 0.6998911190032959, "training_acc": 50.0, "val_loss": 0.6948124647140503, "val_acc": 48.0}
{"epoch": 5, "training_loss": 0.6954612374305725, "training_acc": 52.0, "val_loss": 0.6934937286376953, "val_acc": 52.0}
{"epoch": 6, "training_loss": 0.7167824625968933, "training_acc": 50.0, "val_loss": 0.6923655891418456, "val_acc": 52.0}
{"epoch": 7, "training_loss": 0.7025983953475952, "training_acc": 46.0, "val_loss": 0.6946915912628174, "val_acc": 48.0}
{"epoch": 8, "training_loss": 0.6975748276710511, "training_acc": 48.0, "val_loss": 0.6928657031059265, "val_acc": 52.0}
{"epoch": 9, "training_loss": 0.6984847354888916, "training_acc": 46.0, "val_loss": 0.69281085729599, "val_acc": 52.0}
{"epoch": 10, "training_loss": 0.6951752758026123, "training_acc": 48.0, "val_loss": 0.692504665851593, "val_acc": 52.0}
{"epoch": 11, "training_loss": 0.6957127022743225, "training_acc": 50.0, "val_loss": 0.6951890611648559, "val_acc": 48.0}
{"epoch": 12, "training_loss": 0.7003950166702271, "training_acc": 50.0, "val_loss": 0.7022753238677979, "val_acc": 48.0}
{"epoch": 13, "training_loss": 0.715168948173523, "training_acc": 42.0, "val_loss": 0.695699679851532, "val_acc": 52.0}
{"epoch": 14, "training_loss": 0.6914054942131043, "training_acc": 52.0, "val_loss": 0.7026546263694763, "val_acc": 48.0}
{"epoch": 15, "training_loss": 0.7063640403747559, "training_acc": 50.0, "val_loss": 0.7005654072761536, "val_acc": 48.0}
{"epoch": 16, "training_loss": 0.6965168714523315, "training_acc": 50.0, "val_loss": 0.6936912512779236, "val_acc": 52.0}
{"epoch": 17, "training_loss": 0.6996991991996765, "training_acc": 50.0, "val_loss": 0.6952216005325318, "val_acc": 48.0}
{"epoch": 18, "training_loss": 0.7472261500358581, "training_acc": 50.0, "val_loss": 0.7112993311882019, "val_acc": 48.0}
{"epoch": 19, "training_loss": 0.703174958229065, "training_acc": 52.0, "val_loss": 0.6964511251449585, "val_acc": 52.0}
{"epoch": 20, "training_loss": 0.7043224811553955, "training_acc": 48.0, "val_loss": 0.6945790362358093, "val_acc": 48.0}
{"epoch": 21, "training_loss": 0.6964758110046386, "training_acc": 50.0, "val_loss": 0.6923633170127869, "val_acc": 52.0}
{"epoch": 22, "training_loss": 0.7164073944091797, "training_acc": 50.0, "val_loss": 0.6964667248725891, "val_acc": 52.0}
{"epoch": 23, "training_loss": 0.7208832120895385, "training_acc": 40.0, "val_loss": 0.7127814054489136, "val_acc": 48.0}
{"epoch": 24, "training_loss": 0.6951263761520385, "training_acc": 50.0, "val_loss": 0.6930327200889588, "val_acc": 52.0}
{"epoch": 25, "training_loss": 0.7028479766845703, "training_acc": 50.0, "val_loss": 0.6935992383956909, "val_acc": 52.0}
{"epoch": 26, "training_loss": 0.6920049905776977, "training_acc": 50.0, "val_loss": 0.7087292218208313, "val_acc": 48.0}
{"epoch": 27, "training_loss": 0.7053540706634521, "training_acc": 50.0, "val_loss": 0.6978524899482728, "val_acc": 48.0}
{"epoch": 28, "training_loss": 0.6932467317581177, "training_acc": 50.0, "val_loss": 0.6923901224136353, "val_acc": 52.0}
{"epoch": 29, "training_loss": 0.6978794264793396, "training_acc": 50.0, "val_loss": 0.6928426098823547, "val_acc": 52.0}
{"epoch": 30, "training_loss": 0.6946506071090698, "training_acc": 50.0, "val_loss": 0.7033332943916321, "val_acc": 48.0}
{"epoch": 31, "training_loss": 0.6989515781402588, "training_acc": 50.0, "val_loss": 0.6926015496253968, "val_acc": 52.0}
{"epoch": 32, "training_loss": 0.6991980218887329, "training_acc": 50.0, "val_loss": 0.6927161240577697, "val_acc": 52.0}
{"epoch": 33, "training_loss": 0.6948256921768189, "training_acc": 48.0, "val_loss": 0.7073933458328248, "val_acc": 48.0}
{"epoch": 34, "training_loss": 0.7045152497291565, "training_acc": 50.0, "val_loss": 0.7057318496704101, "val_acc": 48.0}
{"epoch": 35, "training_loss": 0.7011747002601624, "training_acc": 50.0, "val_loss": 0.6943455862998963, "val_acc": 48.0}
{"epoch": 36, "training_loss": 0.7083427596092224, "training_acc": 42.0, "val_loss": 0.6930923962593079, "val_acc": 52.0}
{"epoch": 37, "training_loss": 0.7014038991928101, "training_acc": 42.0, "val_loss": 0.6925151300430298, "val_acc": 52.0}
{"epoch": 38, "training_loss": 0.6926075625419617, "training_acc": 50.0, "val_loss": 0.6940940833091735, "val_acc": 52.0}
{"epoch": 39, "training_loss": 0.6936125445365906, "training_acc": 48.0, "val_loss": 0.6958294224739074, "val_acc": 48.0}
{"epoch": 40, "training_loss": 0.6944350719451904, "training_acc": 50.0, "val_loss": 0.6934778308868408, "val_acc": 48.0}
