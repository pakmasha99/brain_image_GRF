"main_modify.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 4 --task ADNI_sex --input_option yAware --learning_rate 1e-3 --batch_size 16 --weight_decay 1e-6 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 0.6972684192657471, "training_acc": 50.0, "val_loss": 0.6933181738853454, "val_acc": 48.0}
{"epoch": 1, "training_loss": 0.7189590287208557, "training_acc": 44.0, "val_loss": 0.6959712123870849, "val_acc": 52.0}
{"epoch": 2, "training_loss": 0.723045892715454, "training_acc": 50.0, "val_loss": 0.6942647027969361, "val_acc": 52.0}
{"epoch": 3, "training_loss": 0.7081456518173218, "training_acc": 50.0, "val_loss": 0.6967386817932129, "val_acc": 48.0}
{"epoch": 4, "training_loss": 0.7331305408477783, "training_acc": 50.0, "val_loss": 0.7106982731819153, "val_acc": 48.0}
{"epoch": 5, "training_loss": 0.696100754737854, "training_acc": 50.0, "val_loss": 0.6954039120674134, "val_acc": 52.0}
{"epoch": 6, "training_loss": 0.698992121219635, "training_acc": 48.0, "val_loss": 0.6984645199775695, "val_acc": 48.0}
{"epoch": 7, "training_loss": 0.6984568238258362, "training_acc": 50.0, "val_loss": 0.6951261281967163, "val_acc": 48.0}
{"epoch": 8, "training_loss": 0.6958903074264526, "training_acc": 42.0, "val_loss": 0.6940570545196533, "val_acc": 48.0}
{"epoch": 9, "training_loss": 0.6951109981536865, "training_acc": 50.0, "val_loss": 0.6975535321235656, "val_acc": 48.0}
{"epoch": 10, "training_loss": 0.7026538038253785, "training_acc": 50.0, "val_loss": 0.6923851203918457, "val_acc": 52.0}
{"epoch": 11, "training_loss": 0.7217302322387695, "training_acc": 50.0, "val_loss": 0.7048855972290039, "val_acc": 52.0}
{"epoch": 12, "training_loss": 0.6979270982742309, "training_acc": 52.0, "val_loss": 0.7008676648139953, "val_acc": 48.0}
{"epoch": 13, "training_loss": 0.6980372500419617, "training_acc": 50.0, "val_loss": 0.7092471027374267, "val_acc": 48.0}
{"epoch": 14, "training_loss": 0.7077297544479371, "training_acc": 44.0, "val_loss": 0.6931038331985474, "val_acc": 52.0}
{"epoch": 15, "training_loss": 0.6981030893325806, "training_acc": 50.0, "val_loss": 0.6958472084999084, "val_acc": 48.0}
{"epoch": 16, "training_loss": 0.7002715134620666, "training_acc": 50.0, "val_loss": 0.7083539581298828, "val_acc": 48.0}
{"epoch": 17, "training_loss": 0.7143625259399414, "training_acc": 46.0, "val_loss": 0.6965388083457946, "val_acc": 52.0}
{"epoch": 18, "training_loss": 0.7462880682945251, "training_acc": 38.0, "val_loss": 0.7074106478691101, "val_acc": 48.0}
{"epoch": 19, "training_loss": 0.6964024639129639, "training_acc": 52.0, "val_loss": 0.705760726928711, "val_acc": 52.0}
{"epoch": 20, "training_loss": 0.7019394826889038, "training_acc": 52.0, "val_loss": 0.7027088952064514, "val_acc": 48.0}
{"epoch": 21, "training_loss": 0.7265956687927246, "training_acc": 50.0, "val_loss": 0.7228459763526917, "val_acc": 48.0}
{"epoch": 22, "training_loss": 0.6944350409507751, "training_acc": 56.0, "val_loss": 0.69709308385849, "val_acc": 52.0}
{"epoch": 23, "training_loss": 0.7078167653083801, "training_acc": 50.0, "val_loss": 0.6924975633621215, "val_acc": 52.0}
{"epoch": 24, "training_loss": 0.7077241659164428, "training_acc": 46.0, "val_loss": 0.708321259021759, "val_acc": 48.0}
{"epoch": 25, "training_loss": 0.6998672485351562, "training_acc": 48.0, "val_loss": 0.6943243622779847, "val_acc": 52.0}
{"epoch": 26, "training_loss": 0.6987218523025512, "training_acc": 50.0, "val_loss": 0.6923728919029236, "val_acc": 52.0}
{"epoch": 27, "training_loss": 0.6961945343017578, "training_acc": 44.0, "val_loss": 0.6932208561897277, "val_acc": 48.0}
{"epoch": 28, "training_loss": 0.696678318977356, "training_acc": 50.0, "val_loss": 0.692417118549347, "val_acc": 52.0}
{"epoch": 29, "training_loss": 0.7251807975769043, "training_acc": 50.0, "val_loss": 0.6958059668540955, "val_acc": 52.0}
{"epoch": 30, "training_loss": 0.7166245460510254, "training_acc": 46.0, "val_loss": 0.7172396898269653, "val_acc": 48.0}
{"epoch": 31, "training_loss": 0.6988486933708191, "training_acc": 50.0, "val_loss": 0.6937232518196106, "val_acc": 52.0}
{"epoch": 32, "training_loss": 0.7015333247184753, "training_acc": 50.0, "val_loss": 0.6927972745895385, "val_acc": 52.0}
{"epoch": 33, "training_loss": 0.6996648693084717, "training_acc": 50.0, "val_loss": 0.6972554707527161, "val_acc": 48.0}
{"epoch": 34, "training_loss": 0.7150288248062133, "training_acc": 50.0, "val_loss": 0.7039848709106445, "val_acc": 48.0}
{"epoch": 35, "training_loss": 0.6889626264572144, "training_acc": 54.0, "val_loss": 0.6945645070075989, "val_acc": 52.0}
{"epoch": 36, "training_loss": 0.7063499927520752, "training_acc": 50.0, "val_loss": 0.6979671287536621, "val_acc": 52.0}
{"epoch": 37, "training_loss": 0.7014625692367553, "training_acc": 50.0, "val_loss": 0.6939568424224853, "val_acc": 48.0}
{"epoch": 38, "training_loss": 0.7077993011474609, "training_acc": 50.0, "val_loss": 0.7256966686248779, "val_acc": 48.0}
{"epoch": 39, "training_loss": 0.706529278755188, "training_acc": 54.0, "val_loss": 0.6933236503601075, "val_acc": 52.0}
{"epoch": 40, "training_loss": 0.7103564786911011, "training_acc": 50.0, "val_loss": 0.7125284886360168, "val_acc": 52.0}
{"epoch": 41, "training_loss": 0.7174472427368164, "training_acc": 50.0, "val_loss": 0.6923576760292053, "val_acc": 52.0}
{"epoch": 42, "training_loss": 0.7215492439270019, "training_acc": 48.0, "val_loss": 0.7234290599822998, "val_acc": 48.0}
{"epoch": 43, "training_loss": 0.7229948377609253, "training_acc": 50.0, "val_loss": 0.6958088517189026, "val_acc": 48.0}
{"epoch": 44, "training_loss": 0.753412914276123, "training_acc": 50.0, "val_loss": 0.7250985646247864, "val_acc": 52.0}
{"epoch": 45, "training_loss": 0.7177665257453918, "training_acc": 46.0, "val_loss": 0.7259255337715149, "val_acc": 48.0}
{"epoch": 46, "training_loss": 0.7046331238746643, "training_acc": 50.0, "val_loss": 0.6924620509147644, "val_acc": 52.0}
{"epoch": 47, "training_loss": 0.7060693550109863, "training_acc": 50.0, "val_loss": 0.6991048979759217, "val_acc": 52.0}
{"epoch": 48, "training_loss": 0.6935566520690918, "training_acc": 50.0, "val_loss": 0.6969305157661438, "val_acc": 48.0}
{"epoch": 49, "training_loss": 0.7016945791244507, "training_acc": 50.0, "val_loss": 0.6966186451911927, "val_acc": 48.0}
{"epoch": 50, "training_loss": 0.694979772567749, "training_acc": 50.0, "val_loss": 0.6928352475166321, "val_acc": 52.0}
{"epoch": 51, "training_loss": 0.6984581804275513, "training_acc": 50.0, "val_loss": 0.6996363544464111, "val_acc": 52.0}
{"epoch": 52, "training_loss": 0.7076160383224487, "training_acc": 50.0, "val_loss": 0.6928853535652161, "val_acc": 52.0}
{"epoch": 53, "training_loss": 0.6977798843383789, "training_acc": 46.0, "val_loss": 0.6968148517608642, "val_acc": 48.0}
{"epoch": 54, "training_loss": 0.7003852605819703, "training_acc": 50.0, "val_loss": 0.6996852874755859, "val_acc": 48.0}
{"epoch": 55, "training_loss": 0.7027495718002319, "training_acc": 46.0, "val_loss": 0.6931610131263732, "val_acc": 52.0}
{"epoch": 56, "training_loss": 0.7001216268539429, "training_acc": 44.0, "val_loss": 0.694966733455658, "val_acc": 48.0}
{"epoch": 57, "training_loss": 0.7209782338142395, "training_acc": 50.0, "val_loss": 0.7139482641220093, "val_acc": 48.0}
{"epoch": 58, "training_loss": 0.7057712507247925, "training_acc": 50.0, "val_loss": 0.6932518410682679, "val_acc": 52.0}
{"epoch": 59, "training_loss": 0.6980346441268921, "training_acc": 50.0, "val_loss": 0.6926059532165527, "val_acc": 52.0}
{"epoch": 60, "training_loss": 0.6966291761398316, "training_acc": 50.0, "val_loss": 0.6962486290931702, "val_acc": 48.0}
