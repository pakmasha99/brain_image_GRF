"main_modify.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 3 --task ADNI_sex --input_option yAware --learning_rate 1e-3 --batch_size 16 --weight_decay 1e-6 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 0.717212529182434, "training_acc": 48.0, "val_loss": 0.6940312886238098, "val_acc": 52.0}
{"epoch": 1, "training_loss": 0.7097021055221557, "training_acc": 42.0, "val_loss": 0.6986191964149475, "val_acc": 52.0}
{"epoch": 2, "training_loss": 0.7090967416763305, "training_acc": 50.0, "val_loss": 0.7034506344795227, "val_acc": 48.0}
{"epoch": 3, "training_loss": 0.7450529575347901, "training_acc": 50.0, "val_loss": 0.6976682591438294, "val_acc": 48.0}
{"epoch": 4, "training_loss": 0.6993464374542236, "training_acc": 48.0, "val_loss": 0.6928774571418762, "val_acc": 52.0}
{"epoch": 5, "training_loss": 0.7014592552185058, "training_acc": 50.0, "val_loss": 0.693557059764862, "val_acc": 48.0}
{"epoch": 6, "training_loss": 0.7066902136802673, "training_acc": 50.0, "val_loss": 0.6963181042671204, "val_acc": 48.0}
{"epoch": 7, "training_loss": 0.6973821210861206, "training_acc": 50.0, "val_loss": 0.6930729198455811, "val_acc": 52.0}
{"epoch": 8, "training_loss": 0.6966444897651672, "training_acc": 50.0, "val_loss": 0.6924759244918823, "val_acc": 52.0}
{"epoch": 9, "training_loss": 0.7003469085693359, "training_acc": 42.0, "val_loss": 0.6996574306488037, "val_acc": 48.0}
{"epoch": 10, "training_loss": 0.7014147591590881, "training_acc": 44.0, "val_loss": 0.6956579732894898, "val_acc": 48.0}
{"epoch": 11, "training_loss": 0.7121734428405762, "training_acc": 50.0, "val_loss": 0.7125470328330994, "val_acc": 48.0}
{"epoch": 12, "training_loss": 0.6987742614746094, "training_acc": 50.0, "val_loss": 0.6926420712471009, "val_acc": 52.0}
{"epoch": 13, "training_loss": 0.7120122671127319, "training_acc": 50.0, "val_loss": 0.6950912070274353, "val_acc": 52.0}
{"epoch": 14, "training_loss": 0.6897079634666443, "training_acc": 52.0, "val_loss": 0.7013530349731445, "val_acc": 48.0}
{"epoch": 15, "training_loss": 0.7124871826171875, "training_acc": 50.0, "val_loss": 0.7065234208106994, "val_acc": 48.0}
{"epoch": 16, "training_loss": 0.7129913210868836, "training_acc": 40.0, "val_loss": 0.6958923172950745, "val_acc": 52.0}
{"epoch": 17, "training_loss": 0.7041827249526977, "training_acc": 50.0, "val_loss": 0.6933854675292969, "val_acc": 48.0}
{"epoch": 18, "training_loss": 0.6938013052940368, "training_acc": 50.0, "val_loss": 0.6952138233184815, "val_acc": 48.0}
{"epoch": 19, "training_loss": 0.6986196613311768, "training_acc": 46.0, "val_loss": 0.6923683667182923, "val_acc": 52.0}
{"epoch": 20, "training_loss": 0.6960187435150147, "training_acc": 44.0, "val_loss": 0.6934454011917114, "val_acc": 48.0}
{"epoch": 21, "training_loss": 0.6957909059524536, "training_acc": 46.0, "val_loss": 0.69342857837677, "val_acc": 48.0}
{"epoch": 22, "training_loss": 0.6958452582359314, "training_acc": 42.0, "val_loss": 0.6936807250976562, "val_acc": 48.0}
{"epoch": 23, "training_loss": 0.697278037071228, "training_acc": 50.0, "val_loss": 0.6928054356575012, "val_acc": 52.0}
{"epoch": 24, "training_loss": 0.6944608116149902, "training_acc": 50.0, "val_loss": 0.6927117252349854, "val_acc": 52.0}
{"epoch": 25, "training_loss": 0.694883017539978, "training_acc": 50.0, "val_loss": 0.6957248425483704, "val_acc": 48.0}
{"epoch": 26, "training_loss": 0.7019283056259156, "training_acc": 50.0, "val_loss": 0.7120653176307679, "val_acc": 48.0}
{"epoch": 27, "training_loss": 0.70108473777771, "training_acc": 50.0, "val_loss": 0.6924293041229248, "val_acc": 52.0}
{"epoch": 28, "training_loss": 0.7054690217971802, "training_acc": 50.0, "val_loss": 0.6937121057510376, "val_acc": 52.0}
{"epoch": 29, "training_loss": 0.6991664242744445, "training_acc": 52.0, "val_loss": 0.7088372468948364, "val_acc": 48.0}
{"epoch": 30, "training_loss": 0.6973195409774781, "training_acc": 50.0, "val_loss": 0.6923596239089966, "val_acc": 52.0}
{"epoch": 31, "training_loss": 0.7073138570785522, "training_acc": 50.0, "val_loss": 0.6958369994163514, "val_acc": 52.0}
{"epoch": 32, "training_loss": 0.692199444770813, "training_acc": 52.0, "val_loss": 0.7128962349891662, "val_acc": 48.0}
{"epoch": 33, "training_loss": 0.7081821632385253, "training_acc": 50.0, "val_loss": 0.6967701268196106, "val_acc": 48.0}
{"epoch": 34, "training_loss": 0.6993718934059143, "training_acc": 50.0, "val_loss": 0.6935471820831299, "val_acc": 48.0}
{"epoch": 35, "training_loss": 0.694095435142517, "training_acc": 48.0, "val_loss": 0.6925187969207763, "val_acc": 52.0}
{"epoch": 36, "training_loss": 0.6961763954162598, "training_acc": 50.0, "val_loss": 0.6933075475692749, "val_acc": 48.0}
{"epoch": 37, "training_loss": 0.6937907528877258, "training_acc": 50.0, "val_loss": 0.7046152400970459, "val_acc": 48.0}
{"epoch": 38, "training_loss": 0.7025859141349793, "training_acc": 44.0, "val_loss": 0.6923953819274903, "val_acc": 52.0}
{"epoch": 39, "training_loss": 0.6970577907562255, "training_acc": 50.0, "val_loss": 0.6927115321159363, "val_acc": 52.0}
{"epoch": 40, "training_loss": 0.6938183355331421, "training_acc": 52.0, "val_loss": 0.6969048810005188, "val_acc": 48.0}
{"epoch": 41, "training_loss": 0.697285704612732, "training_acc": 50.0, "val_loss": 0.6935288262367248, "val_acc": 48.0}
{"epoch": 42, "training_loss": 0.6962219429016113, "training_acc": 46.0, "val_loss": 0.6935231328010559, "val_acc": 48.0}
{"epoch": 43, "training_loss": 0.7006942892074585, "training_acc": 50.0, "val_loss": 0.7096592354774475, "val_acc": 48.0}
{"epoch": 44, "training_loss": 0.712232654094696, "training_acc": 50.0, "val_loss": 0.7041082358360291, "val_acc": 48.0}
{"epoch": 45, "training_loss": 0.6954326295852661, "training_acc": 48.0, "val_loss": 0.6923681402206421, "val_acc": 52.0}
{"epoch": 46, "training_loss": 0.6988026022911071, "training_acc": 44.0, "val_loss": 0.6943647861480713, "val_acc": 48.0}
{"epoch": 47, "training_loss": 0.6968118071556091, "training_acc": 44.0, "val_loss": 0.6936906051635742, "val_acc": 48.0}
{"epoch": 48, "training_loss": 0.6992700743675232, "training_acc": 42.0, "val_loss": 0.6948650312423706, "val_acc": 48.0}
{"epoch": 49, "training_loss": 0.6987603521347046, "training_acc": 50.0, "val_loss": 0.7006545281410217, "val_acc": 48.0}
