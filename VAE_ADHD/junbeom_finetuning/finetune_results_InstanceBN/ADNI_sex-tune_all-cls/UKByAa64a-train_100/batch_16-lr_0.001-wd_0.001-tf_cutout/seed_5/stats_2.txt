"main_modify.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 5 --task ADNI_sex --input_option yAware --learning_rate 1e-3 --batch_size 16 --weight_decay 1e-3 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 0.7073531889915466, "training_acc": 54.0, "val_loss": 0.693199622631073, "val_acc": 52.0}
{"epoch": 1, "training_loss": 0.7112275505065918, "training_acc": 44.0, "val_loss": 0.7114314770698548, "val_acc": 52.0}
{"epoch": 2, "training_loss": 0.7221938848495484, "training_acc": 46.0, "val_loss": 0.6924635291099548, "val_acc": 52.0}
{"epoch": 3, "training_loss": 0.7060098457336426, "training_acc": 36.0, "val_loss": 0.6928812408447266, "val_acc": 52.0}
{"epoch": 4, "training_loss": 0.6963368010520935, "training_acc": 50.0, "val_loss": 0.6923533844947815, "val_acc": 52.0}
{"epoch": 5, "training_loss": 0.6945751166343689, "training_acc": 46.0, "val_loss": 0.6943783664703369, "val_acc": 48.0}
{"epoch": 6, "training_loss": 0.7006318902969361, "training_acc": 44.0, "val_loss": 0.693405499458313, "val_acc": 48.0}
{"epoch": 7, "training_loss": 0.6942146110534668, "training_acc": 46.0, "val_loss": 0.6990093541145325, "val_acc": 48.0}
{"epoch": 8, "training_loss": 0.7157633209228516, "training_acc": 50.0, "val_loss": 0.6970542454719544, "val_acc": 48.0}
{"epoch": 9, "training_loss": 0.6968772983551026, "training_acc": 52.0, "val_loss": 0.6931105160713196, "val_acc": 52.0}
{"epoch": 10, "training_loss": 0.6963739156723022, "training_acc": 54.0, "val_loss": 0.7122343754768372, "val_acc": 48.0}
{"epoch": 11, "training_loss": 0.7116756510734558, "training_acc": 50.0, "val_loss": 0.6997253799438476, "val_acc": 48.0}
{"epoch": 12, "training_loss": 0.6996057367324829, "training_acc": 50.0, "val_loss": 0.6923522305488586, "val_acc": 52.0}
{"epoch": 13, "training_loss": 0.6951628923416138, "training_acc": 50.0, "val_loss": 0.6924007868766785, "val_acc": 52.0}
{"epoch": 14, "training_loss": 0.709367790222168, "training_acc": 50.0, "val_loss": 0.699754822254181, "val_acc": 48.0}
{"epoch": 15, "training_loss": 0.7143844747543335, "training_acc": 50.0, "val_loss": 0.7175838828086853, "val_acc": 48.0}
{"epoch": 16, "training_loss": 0.6896249389648438, "training_acc": 54.0, "val_loss": 0.7026750469207763, "val_acc": 52.0}
{"epoch": 17, "training_loss": 0.6924629259109497, "training_acc": 52.0, "val_loss": 0.7103901767730713, "val_acc": 48.0}
{"epoch": 18, "training_loss": 0.7056830143928527, "training_acc": 50.0, "val_loss": 0.6928472995758057, "val_acc": 52.0}
{"epoch": 19, "training_loss": 0.7119542622566223, "training_acc": 50.0, "val_loss": 0.6924461364746094, "val_acc": 52.0}
{"epoch": 20, "training_loss": 0.703457863330841, "training_acc": 42.0, "val_loss": 0.6983274149894715, "val_acc": 48.0}
{"epoch": 21, "training_loss": 0.7007714796066284, "training_acc": 50.0, "val_loss": 0.6971313548088074, "val_acc": 48.0}
{"epoch": 22, "training_loss": 0.7056365585327149, "training_acc": 44.0, "val_loss": 0.6923755502700806, "val_acc": 52.0}
{"epoch": 23, "training_loss": 0.6988447523117065, "training_acc": 54.0, "val_loss": 0.7086022353172302, "val_acc": 48.0}
{"epoch": 24, "training_loss": 0.7000031542778015, "training_acc": 48.0, "val_loss": 0.6923468899726868, "val_acc": 52.0}
{"epoch": 25, "training_loss": 0.6947836351394653, "training_acc": 50.0, "val_loss": 0.697271580696106, "val_acc": 48.0}
{"epoch": 26, "training_loss": 0.6973994421958923, "training_acc": 50.0, "val_loss": 0.6924351286888123, "val_acc": 52.0}
{"epoch": 27, "training_loss": 0.7021184992790223, "training_acc": 50.0, "val_loss": 0.6963725399971008, "val_acc": 52.0}
{"epoch": 28, "training_loss": 0.7020706677436829, "training_acc": 44.0, "val_loss": 0.6945688843727111, "val_acc": 48.0}
{"epoch": 29, "training_loss": 0.694544768333435, "training_acc": 50.0, "val_loss": 0.6929070234298706, "val_acc": 52.0}
{"epoch": 30, "training_loss": 0.6967061734199524, "training_acc": 42.0, "val_loss": 0.6931437993049622, "val_acc": 52.0}
{"epoch": 31, "training_loss": 0.6941200828552246, "training_acc": 50.0, "val_loss": 0.6929428195953369, "val_acc": 52.0}
{"epoch": 32, "training_loss": 0.6932216715812684, "training_acc": 50.0, "val_loss": 0.6997677659988404, "val_acc": 48.0}
{"epoch": 33, "training_loss": 0.696169056892395, "training_acc": 50.0, "val_loss": 0.6923476099967957, "val_acc": 52.0}
{"epoch": 34, "training_loss": 0.7033686923980713, "training_acc": 50.0, "val_loss": 0.6928541445732117, "val_acc": 52.0}
{"epoch": 35, "training_loss": 0.694502387046814, "training_acc": 48.0, "val_loss": 0.6953342151641846, "val_acc": 48.0}
{"epoch": 36, "training_loss": 0.7046931409835815, "training_acc": 44.0, "val_loss": 0.6936295056343078, "val_acc": 48.0}
{"epoch": 37, "training_loss": 0.7070635604858398, "training_acc": 50.0, "val_loss": 0.7001090025901795, "val_acc": 48.0}
{"epoch": 38, "training_loss": 0.6978049039840698, "training_acc": 50.0, "val_loss": 0.6927616786956787, "val_acc": 52.0}
{"epoch": 39, "training_loss": 0.7026041603088379, "training_acc": 48.0, "val_loss": 0.6923840379714966, "val_acc": 52.0}
{"epoch": 40, "training_loss": 0.7119733333587647, "training_acc": 44.0, "val_loss": 0.6941692686080932, "val_acc": 48.0}
{"epoch": 41, "training_loss": 0.6954370665550232, "training_acc": 46.0, "val_loss": 0.6959735226631164, "val_acc": 48.0}
{"epoch": 42, "training_loss": 0.7087747716903686, "training_acc": 46.0, "val_loss": 0.697028431892395, "val_acc": 48.0}
{"epoch": 43, "training_loss": 0.7038322615623475, "training_acc": 50.0, "val_loss": 0.7003330302238464, "val_acc": 48.0}
