"main_modify.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 5 --task ADNI_sex --input_option yAware --learning_rate 1e-3 --batch_size 16 --weight_decay 1e-3 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 0.7390779662132263, "training_acc": 36.0, "val_loss": 0.7019865179061889, "val_acc": 48.0}
{"epoch": 1, "training_loss": 0.7126228380203247, "training_acc": 42.0, "val_loss": 0.7009183859825134, "val_acc": 48.0}
{"epoch": 2, "training_loss": 0.7116595411300659, "training_acc": 50.0, "val_loss": 0.6924912190437317, "val_acc": 52.0}
{"epoch": 3, "training_loss": 0.7039824414253235, "training_acc": 50.0, "val_loss": 0.6945012664794922, "val_acc": 52.0}
{"epoch": 4, "training_loss": 0.6973799180984497, "training_acc": 50.0, "val_loss": 0.6947987675666809, "val_acc": 48.0}
{"epoch": 5, "training_loss": 0.6964819478988648, "training_acc": 50.0, "val_loss": 0.695419807434082, "val_acc": 48.0}
{"epoch": 6, "training_loss": 0.6950235080718994, "training_acc": 50.0, "val_loss": 0.6923781299591064, "val_acc": 52.0}
{"epoch": 7, "training_loss": 0.7147573471069336, "training_acc": 50.0, "val_loss": 0.6923919010162354, "val_acc": 52.0}
{"epoch": 8, "training_loss": 0.6918363785743713, "training_acc": 58.0, "val_loss": 0.7204183387756348, "val_acc": 48.0}
{"epoch": 9, "training_loss": 0.7051311111450196, "training_acc": 48.0, "val_loss": 0.6927423810958863, "val_acc": 52.0}
{"epoch": 10, "training_loss": 0.6969600129127502, "training_acc": 42.0, "val_loss": 0.6941778302192688, "val_acc": 48.0}
{"epoch": 11, "training_loss": 0.7074485301971436, "training_acc": 50.0, "val_loss": 0.6923888754844666, "val_acc": 52.0}
{"epoch": 12, "training_loss": 0.7090409660339355, "training_acc": 50.0, "val_loss": 0.6931198954582214, "val_acc": 52.0}
{"epoch": 13, "training_loss": 0.6999370193481446, "training_acc": 46.0, "val_loss": 0.6924905347824096, "val_acc": 52.0}
{"epoch": 14, "training_loss": 0.7029021263122559, "training_acc": 50.0, "val_loss": 0.6927800345420837, "val_acc": 52.0}
{"epoch": 15, "training_loss": 0.7004916191101074, "training_acc": 50.0, "val_loss": 0.692356870174408, "val_acc": 52.0}
{"epoch": 16, "training_loss": 0.6981233835220337, "training_acc": 50.0, "val_loss": 0.6930309367179871, "val_acc": 52.0}
{"epoch": 17, "training_loss": 0.6946961593627929, "training_acc": 50.0, "val_loss": 0.7001797485351563, "val_acc": 48.0}
{"epoch": 18, "training_loss": 0.7020373821258545, "training_acc": 50.0, "val_loss": 0.6991461300849915, "val_acc": 48.0}
{"epoch": 19, "training_loss": 0.6949901533126831, "training_acc": 52.0, "val_loss": 0.6923748230934144, "val_acc": 52.0}
{"epoch": 20, "training_loss": 0.7077929878234863, "training_acc": 42.0, "val_loss": 0.6962620520591736, "val_acc": 48.0}
{"epoch": 21, "training_loss": 0.6942472171783447, "training_acc": 50.0, "val_loss": 0.6925805711746216, "val_acc": 52.0}
{"epoch": 22, "training_loss": 0.7039276742935181, "training_acc": 50.0, "val_loss": 0.7023899388313294, "val_acc": 48.0}
{"epoch": 23, "training_loss": 0.7090750122070313, "training_acc": 50.0, "val_loss": 0.6990439653396606, "val_acc": 48.0}
{"epoch": 24, "training_loss": 0.6976630306243896, "training_acc": 50.0, "val_loss": 0.693267867565155, "val_acc": 52.0}
{"epoch": 25, "training_loss": 0.7131283688545227, "training_acc": 50.0, "val_loss": 0.6923474502563477, "val_acc": 52.0}
{"epoch": 26, "training_loss": 0.6974565267562867, "training_acc": 46.0, "val_loss": 0.6987860441207886, "val_acc": 48.0}
{"epoch": 27, "training_loss": 0.6998150086402893, "training_acc": 46.0, "val_loss": 0.6946838045120239, "val_acc": 48.0}
{"epoch": 28, "training_loss": 0.7101186084747314, "training_acc": 50.0, "val_loss": 0.696857464313507, "val_acc": 48.0}
{"epoch": 29, "training_loss": 0.7057649278640747, "training_acc": 48.0, "val_loss": 0.6960086750984192, "val_acc": 52.0}
{"epoch": 30, "training_loss": 0.6996340274810791, "training_acc": 48.0, "val_loss": 0.6983318305015564, "val_acc": 48.0}
{"epoch": 31, "training_loss": 0.6942326831817627, "training_acc": 50.0, "val_loss": 0.6926048278808594, "val_acc": 52.0}
{"epoch": 32, "training_loss": 0.7177396869659424, "training_acc": 50.0, "val_loss": 0.6933340787887573, "val_acc": 52.0}
{"epoch": 33, "training_loss": 0.7254777312278747, "training_acc": 42.0, "val_loss": 0.694826922416687, "val_acc": 48.0}
{"epoch": 34, "training_loss": 0.711676344871521, "training_acc": 48.0, "val_loss": 0.6923645901679992, "val_acc": 52.0}
{"epoch": 35, "training_loss": 0.6935876822471618, "training_acc": 50.0, "val_loss": 0.6997323131561279, "val_acc": 48.0}
{"epoch": 36, "training_loss": 0.6997570037841797, "training_acc": 46.0, "val_loss": 0.6966625595092774, "val_acc": 48.0}
{"epoch": 37, "training_loss": 0.7206233811378479, "training_acc": 50.0, "val_loss": 0.7071617817878724, "val_acc": 48.0}
{"epoch": 38, "training_loss": 0.7249119257926941, "training_acc": 46.0, "val_loss": 0.6950109601020813, "val_acc": 52.0}
{"epoch": 39, "training_loss": 0.6977498531341553, "training_acc": 48.0, "val_loss": 0.6970933628082275, "val_acc": 48.0}
{"epoch": 40, "training_loss": 0.6976075458526612, "training_acc": 46.0, "val_loss": 0.6959999966621399, "val_acc": 52.0}
{"epoch": 41, "training_loss": 0.7324684357643128, "training_acc": 50.0, "val_loss": 0.6926440930366516, "val_acc": 52.0}
{"epoch": 42, "training_loss": 0.7505705928802491, "training_acc": 44.0, "val_loss": 0.7014461755752563, "val_acc": 48.0}
{"epoch": 43, "training_loss": 0.6951889371871949, "training_acc": 54.0, "val_loss": 0.694502146244049, "val_acc": 52.0}
{"epoch": 44, "training_loss": 0.6990264129638671, "training_acc": 50.0, "val_loss": 0.7044804739952087, "val_acc": 48.0}
