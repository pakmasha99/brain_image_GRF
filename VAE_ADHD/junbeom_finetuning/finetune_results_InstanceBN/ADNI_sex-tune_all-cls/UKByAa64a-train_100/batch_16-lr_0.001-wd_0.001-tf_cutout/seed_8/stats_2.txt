"main_modify.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 8 --task ADNI_sex --input_option yAware --learning_rate 1e-3 --batch_size 16 --weight_decay 1e-3 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 0.715056791305542, "training_acc": 46.0, "val_loss": 0.6946903228759765, "val_acc": 48.0}
{"epoch": 1, "training_loss": 0.7054109525680542, "training_acc": 46.0, "val_loss": 0.7099362683296203, "val_acc": 48.0}
{"epoch": 2, "training_loss": 0.7124293303489685, "training_acc": 46.0, "val_loss": 0.6930727291107178, "val_acc": 52.0}
{"epoch": 3, "training_loss": 0.7015985703468323, "training_acc": 44.0, "val_loss": 0.6934992337226867, "val_acc": 48.0}
{"epoch": 4, "training_loss": 0.6967578029632568, "training_acc": 50.0, "val_loss": 0.6925657653808593, "val_acc": 52.0}
{"epoch": 5, "training_loss": 0.7009744119644165, "training_acc": 46.0, "val_loss": 0.6961805558204651, "val_acc": 48.0}
{"epoch": 6, "training_loss": 0.7089092206954956, "training_acc": 44.0, "val_loss": 0.6930250477790832, "val_acc": 52.0}
{"epoch": 7, "training_loss": 0.7094437265396119, "training_acc": 50.0, "val_loss": 0.698330729007721, "val_acc": 48.0}
{"epoch": 8, "training_loss": 0.6957204842567444, "training_acc": 50.0, "val_loss": 0.6949658989906311, "val_acc": 52.0}
{"epoch": 9, "training_loss": 0.7105351972579956, "training_acc": 50.0, "val_loss": 0.6942020750045776, "val_acc": 48.0}
{"epoch": 10, "training_loss": 0.7138904905319214, "training_acc": 50.0, "val_loss": 0.7062464475631713, "val_acc": 48.0}
{"epoch": 11, "training_loss": 0.6989985537528992, "training_acc": 50.0, "val_loss": 0.6937365508079529, "val_acc": 52.0}
{"epoch": 12, "training_loss": 0.7118744277954101, "training_acc": 50.0, "val_loss": 0.7069602131843566, "val_acc": 48.0}
{"epoch": 13, "training_loss": 0.7161817336082459, "training_acc": 42.0, "val_loss": 0.7299451780319214, "val_acc": 48.0}
{"epoch": 14, "training_loss": 0.7157757568359375, "training_acc": 50.0, "val_loss": 0.6945377135276795, "val_acc": 48.0}
{"epoch": 15, "training_loss": 0.6980172300338745, "training_acc": 50.0, "val_loss": 0.6923811411857606, "val_acc": 52.0}
{"epoch": 16, "training_loss": 0.6936635398864746, "training_acc": 50.0, "val_loss": 0.7063279676437378, "val_acc": 48.0}
{"epoch": 17, "training_loss": 0.7046412229537964, "training_acc": 50.0, "val_loss": 0.693865864276886, "val_acc": 48.0}
{"epoch": 18, "training_loss": 0.7035091805458069, "training_acc": 46.0, "val_loss": 0.6937529087066651, "val_acc": 52.0}
{"epoch": 19, "training_loss": 0.6971092414855957, "training_acc": 50.0, "val_loss": 0.6936715841293335, "val_acc": 48.0}
{"epoch": 20, "training_loss": 0.721580400466919, "training_acc": 50.0, "val_loss": 0.6994698309898376, "val_acc": 48.0}
{"epoch": 21, "training_loss": 0.6909375810623168, "training_acc": 54.0, "val_loss": 0.6971794295310975, "val_acc": 52.0}
{"epoch": 22, "training_loss": 0.7007533359527588, "training_acc": 50.0, "val_loss": 0.6958604621887207, "val_acc": 48.0}
{"epoch": 23, "training_loss": 0.7182156133651734, "training_acc": 50.0, "val_loss": 0.6929472470283509, "val_acc": 52.0}
{"epoch": 24, "training_loss": 0.7037871217727661, "training_acc": 50.0, "val_loss": 0.6938190817832947, "val_acc": 48.0}
{"epoch": 25, "training_loss": 0.7055878686904907, "training_acc": 50.0, "val_loss": 0.6925861930847168, "val_acc": 52.0}
{"epoch": 26, "training_loss": 0.701880509853363, "training_acc": 50.0, "val_loss": 0.6923667168617249, "val_acc": 52.0}
{"epoch": 27, "training_loss": 0.7042189741134643, "training_acc": 50.0, "val_loss": 0.7081873035430908, "val_acc": 48.0}
{"epoch": 28, "training_loss": 0.7006153202056885, "training_acc": 52.0, "val_loss": 0.69266117811203, "val_acc": 52.0}
{"epoch": 29, "training_loss": 0.7082941436767578, "training_acc": 50.0, "val_loss": 0.6924492192268371, "val_acc": 52.0}
{"epoch": 30, "training_loss": 0.7034807634353638, "training_acc": 50.0, "val_loss": 0.692877311706543, "val_acc": 52.0}
{"epoch": 31, "training_loss": 0.7033000946044922, "training_acc": 50.0, "val_loss": 0.6923470568656921, "val_acc": 52.0}
{"epoch": 32, "training_loss": 0.70224534034729, "training_acc": 52.0, "val_loss": 0.6968971753120422, "val_acc": 48.0}
{"epoch": 33, "training_loss": 0.6896840333938599, "training_acc": 56.0, "val_loss": 0.6973586535453796, "val_acc": 52.0}
{"epoch": 34, "training_loss": 0.7087937235832215, "training_acc": 48.0, "val_loss": 0.6931957507133484, "val_acc": 48.0}
{"epoch": 35, "training_loss": 0.6971940279006958, "training_acc": 50.0, "val_loss": 0.6925750160217286, "val_acc": 52.0}
{"epoch": 36, "training_loss": 0.6972151589393616, "training_acc": 50.0, "val_loss": 0.6924653196334839, "val_acc": 52.0}
{"epoch": 37, "training_loss": 0.69426344871521, "training_acc": 50.0, "val_loss": 0.7056454396247864, "val_acc": 48.0}
{"epoch": 38, "training_loss": 0.7001190662384034, "training_acc": 48.0, "val_loss": 0.6925285387039185, "val_acc": 52.0}
{"epoch": 39, "training_loss": 0.6989225482940674, "training_acc": 42.0, "val_loss": 0.6923553895950317, "val_acc": 52.0}
{"epoch": 40, "training_loss": 0.7022952127456665, "training_acc": 50.0, "val_loss": 0.6924329781532288, "val_acc": 52.0}
{"epoch": 41, "training_loss": 0.6931469869613648, "training_acc": 54.0, "val_loss": 0.7048951029777527, "val_acc": 48.0}
{"epoch": 42, "training_loss": 0.704178740978241, "training_acc": 50.0, "val_loss": 0.709613926410675, "val_acc": 48.0}
{"epoch": 43, "training_loss": 0.7005764746665955, "training_acc": 48.0, "val_loss": 0.6937453436851502, "val_acc": 52.0}
{"epoch": 44, "training_loss": 0.7022798299789429, "training_acc": 44.0, "val_loss": 0.6930411767959594, "val_acc": 52.0}
{"epoch": 45, "training_loss": 0.695223798751831, "training_acc": 46.0, "val_loss": 0.6928819012641907, "val_acc": 52.0}
{"epoch": 46, "training_loss": 0.7052247238159179, "training_acc": 50.0, "val_loss": 0.6932403922080994, "val_acc": 48.0}
{"epoch": 47, "training_loss": 0.7017426753044128, "training_acc": 50.0, "val_loss": 0.6965379285812378, "val_acc": 48.0}
{"epoch": 48, "training_loss": 0.6978645586967468, "training_acc": 44.0, "val_loss": 0.6948323488235474, "val_acc": 48.0}
{"epoch": 49, "training_loss": 0.7100243425369263, "training_acc": 50.0, "val_loss": 0.7049223828315735, "val_acc": 48.0}
{"epoch": 50, "training_loss": 0.704975368976593, "training_acc": 42.0, "val_loss": 0.694981243610382, "val_acc": 48.0}
