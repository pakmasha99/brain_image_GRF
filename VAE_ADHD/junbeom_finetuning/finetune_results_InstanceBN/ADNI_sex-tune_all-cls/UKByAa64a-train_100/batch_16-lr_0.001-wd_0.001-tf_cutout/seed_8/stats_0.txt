"main_modify.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 8 --task ADNI_sex --input_option yAware --learning_rate 1e-3 --batch_size 16 --weight_decay 1e-3 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 0.7171906304359436, "training_acc": 52.0, "val_loss": 0.69267174243927, "val_acc": 52.0}
{"epoch": 1, "training_loss": 0.7128590679168701, "training_acc": 49.0, "val_loss": 0.6959248018264771, "val_acc": 52.0}
{"epoch": 2, "training_loss": 0.7133945941925048, "training_acc": 43.0, "val_loss": 0.6945792865753174, "val_acc": 48.0}
{"epoch": 3, "training_loss": 0.7094434118270874, "training_acc": 51.0, "val_loss": 0.692820839881897, "val_acc": 52.0}
{"epoch": 4, "training_loss": 0.7092729020118713, "training_acc": 49.0, "val_loss": 0.6924266767501831, "val_acc": 52.0}
{"epoch": 5, "training_loss": 0.7050248074531555, "training_acc": 51.0, "val_loss": 0.7255332112312317, "val_acc": 48.0}
{"epoch": 6, "training_loss": 0.7146920824050903, "training_acc": 45.0, "val_loss": 0.6923702931404114, "val_acc": 52.0}
{"epoch": 7, "training_loss": 0.6992006421089172, "training_acc": 49.0, "val_loss": 0.6946107029914856, "val_acc": 48.0}
{"epoch": 8, "training_loss": 0.7188493156433106, "training_acc": 51.0, "val_loss": 0.7026253128051758, "val_acc": 48.0}
{"epoch": 9, "training_loss": 0.7060775566101074, "training_acc": 47.0, "val_loss": 0.694298243522644, "val_acc": 52.0}
{"epoch": 10, "training_loss": 0.6967269086837768, "training_acc": 50.0, "val_loss": 0.6992990183830261, "val_acc": 48.0}
{"epoch": 11, "training_loss": 0.6980489063262939, "training_acc": 51.0, "val_loss": 0.696696093082428, "val_acc": 48.0}
{"epoch": 12, "training_loss": 0.6981609201431275, "training_acc": 51.0, "val_loss": 0.6949563670158386, "val_acc": 48.0}
{"epoch": 13, "training_loss": 0.6956275153160095, "training_acc": 51.0, "val_loss": 0.6933080983161927, "val_acc": 48.0}
{"epoch": 14, "training_loss": 0.7035849905014038, "training_acc": 47.0, "val_loss": 0.6934110188484192, "val_acc": 52.0}
{"epoch": 15, "training_loss": 0.6962558364868164, "training_acc": 49.0, "val_loss": 0.6947407865524292, "val_acc": 48.0}
{"epoch": 16, "training_loss": 0.6967493987083435, "training_acc": 45.0, "val_loss": 0.698552405834198, "val_acc": 48.0}
{"epoch": 17, "training_loss": 0.7007468461990356, "training_acc": 43.0, "val_loss": 0.6943451809883118, "val_acc": 48.0}
{"epoch": 18, "training_loss": 0.698783450126648, "training_acc": 39.0, "val_loss": 0.6982480335235596, "val_acc": 48.0}
{"epoch": 19, "training_loss": 0.6934846138954163, "training_acc": 51.0, "val_loss": 0.6923594689369201, "val_acc": 52.0}
{"epoch": 20, "training_loss": 0.6984728765487671, "training_acc": 43.0, "val_loss": 0.6932027506828308, "val_acc": 48.0}
{"epoch": 21, "training_loss": 0.6967863583564758, "training_acc": 47.0, "val_loss": 0.6925646328926086, "val_acc": 52.0}
{"epoch": 22, "training_loss": 0.7053409862518311, "training_acc": 49.0, "val_loss": 0.6983753442764282, "val_acc": 48.0}
{"epoch": 23, "training_loss": 0.7019176959991456, "training_acc": 47.0, "val_loss": 0.7033210325241089, "val_acc": 48.0}
{"epoch": 24, "training_loss": 0.7001819109916687, "training_acc": 51.0, "val_loss": 0.6934634971618653, "val_acc": 52.0}
{"epoch": 25, "training_loss": 0.7026124620437622, "training_acc": 45.0, "val_loss": 0.692350800037384, "val_acc": 52.0}
{"epoch": 26, "training_loss": 0.7026416254043579, "training_acc": 49.0, "val_loss": 0.6931107378005982, "val_acc": 52.0}
{"epoch": 27, "training_loss": 0.6983138871192932, "training_acc": 49.0, "val_loss": 0.6985493206977844, "val_acc": 48.0}
{"epoch": 28, "training_loss": 0.7045342826843262, "training_acc": 41.0, "val_loss": 0.6923511052131652, "val_acc": 52.0}
{"epoch": 29, "training_loss": 0.6952371454238891, "training_acc": 49.0, "val_loss": 0.7025399541854859, "val_acc": 48.0}
{"epoch": 30, "training_loss": 0.7031085920333863, "training_acc": 51.0, "val_loss": 0.6979616737365723, "val_acc": 48.0}
{"epoch": 31, "training_loss": 0.6933307528495789, "training_acc": 49.0, "val_loss": 0.6923791193962097, "val_acc": 52.0}
{"epoch": 32, "training_loss": 0.6917116403579712, "training_acc": 53.0, "val_loss": 0.7056312823295593, "val_acc": 48.0}
{"epoch": 33, "training_loss": 0.7389817142486572, "training_acc": 51.0, "val_loss": 0.7076673579216003, "val_acc": 48.0}
{"epoch": 34, "training_loss": 0.7057121658325195, "training_acc": 47.0, "val_loss": 0.6926376628875732, "val_acc": 52.0}
{"epoch": 35, "training_loss": 0.6993002128601075, "training_acc": 43.0, "val_loss": 0.6923662185668945, "val_acc": 52.0}
{"epoch": 36, "training_loss": 0.708141074180603, "training_acc": 43.0, "val_loss": 0.6932673287391663, "val_acc": 48.0}
{"epoch": 37, "training_loss": 0.7010643458366395, "training_acc": 51.0, "val_loss": 0.6933618807792663, "val_acc": 48.0}
{"epoch": 38, "training_loss": 0.6987115764617919, "training_acc": 43.0, "val_loss": 0.6941624760627747, "val_acc": 48.0}
{"epoch": 39, "training_loss": 0.7036057090759278, "training_acc": 41.0, "val_loss": 0.6959990048408509, "val_acc": 48.0}
{"epoch": 40, "training_loss": 0.700954487323761, "training_acc": 51.0, "val_loss": 0.7099300527572632, "val_acc": 48.0}
{"epoch": 41, "training_loss": 0.6951597785949707, "training_acc": 49.0, "val_loss": 0.6923986506462098, "val_acc": 52.0}
{"epoch": 42, "training_loss": 0.6941127562522889, "training_acc": 51.0, "val_loss": 0.7104028630256652, "val_acc": 48.0}
{"epoch": 43, "training_loss": 0.715948441028595, "training_acc": 51.0, "val_loss": 0.6928158593177796, "val_acc": 52.0}
{"epoch": 44, "training_loss": 0.7095923948287964, "training_acc": 47.0, "val_loss": 0.6924285817146302, "val_acc": 52.0}
