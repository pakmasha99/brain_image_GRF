"main_modify.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 2 --task ADNI_sex --input_option yAware --learning_rate 1e-3 --batch_size 16 --weight_decay 1e-3 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 0.7361427450180054, "training_acc": 42.0, "val_loss": 0.6978475999832153, "val_acc": 52.0}
{"epoch": 1, "training_loss": 0.7103037786483765, "training_acc": 48.0, "val_loss": 0.6996694159507751, "val_acc": 52.0}
{"epoch": 2, "training_loss": 0.7069893527030945, "training_acc": 44.0, "val_loss": 0.6926975178718567, "val_acc": 52.0}
{"epoch": 3, "training_loss": 0.719496021270752, "training_acc": 50.0, "val_loss": 0.6924743747711182, "val_acc": 52.0}
{"epoch": 4, "training_loss": 0.6967899751663208, "training_acc": 50.0, "val_loss": 0.7068037462234497, "val_acc": 48.0}
{"epoch": 5, "training_loss": 0.7268309903144836, "training_acc": 50.0, "val_loss": 0.705657262802124, "val_acc": 48.0}
{"epoch": 6, "training_loss": 0.7039162635803222, "training_acc": 46.0, "val_loss": 0.6935973024368286, "val_acc": 52.0}
{"epoch": 7, "training_loss": 0.7131341552734375, "training_acc": 42.0, "val_loss": 0.7018118405342102, "val_acc": 48.0}
{"epoch": 8, "training_loss": 0.706479299068451, "training_acc": 44.0, "val_loss": 0.6937739944458008, "val_acc": 48.0}
{"epoch": 9, "training_loss": 0.6967241716384888, "training_acc": 46.0, "val_loss": 0.6959121298789978, "val_acc": 48.0}
{"epoch": 10, "training_loss": 0.7054484534263611, "training_acc": 50.0, "val_loss": 0.7072710800170898, "val_acc": 48.0}
{"epoch": 11, "training_loss": 0.6919961833953857, "training_acc": 54.0, "val_loss": 0.6986825037002563, "val_acc": 52.0}
{"epoch": 12, "training_loss": 0.7202575397491455, "training_acc": 50.0, "val_loss": 0.7288786721229553, "val_acc": 52.0}
{"epoch": 13, "training_loss": 0.7176348328590393, "training_acc": 50.0, "val_loss": 0.7021591591835022, "val_acc": 48.0}
{"epoch": 14, "training_loss": 0.7070837330818176, "training_acc": 50.0, "val_loss": 0.6964529490470887, "val_acc": 48.0}
{"epoch": 15, "training_loss": 0.7021972465515137, "training_acc": 50.0, "val_loss": 0.6925094199180603, "val_acc": 52.0}
{"epoch": 16, "training_loss": 0.7102829623222351, "training_acc": 50.0, "val_loss": 0.6930881071090699, "val_acc": 52.0}
{"epoch": 17, "training_loss": 0.6986135959625244, "training_acc": 52.0, "val_loss": 0.7036100196838379, "val_acc": 48.0}
{"epoch": 18, "training_loss": 0.6914335823059082, "training_acc": 54.0, "val_loss": 0.6991536593437195, "val_acc": 52.0}
{"epoch": 19, "training_loss": 0.706705060005188, "training_acc": 50.0, "val_loss": 0.6924354672431946, "val_acc": 52.0}
{"epoch": 20, "training_loss": 0.7068894624710083, "training_acc": 50.0, "val_loss": 0.7147282528877258, "val_acc": 48.0}
{"epoch": 21, "training_loss": 0.7253997707366944, "training_acc": 38.0, "val_loss": 0.6924262833595276, "val_acc": 52.0}
{"epoch": 22, "training_loss": 0.7002514886856079, "training_acc": 44.0, "val_loss": 0.6950375699996948, "val_acc": 48.0}
{"epoch": 23, "training_loss": 0.7159887218475341, "training_acc": 48.0, "val_loss": 0.701371922492981, "val_acc": 52.0}
{"epoch": 24, "training_loss": 0.6898645687103272, "training_acc": 52.0, "val_loss": 0.7033865356445312, "val_acc": 48.0}
{"epoch": 25, "training_loss": 0.7271926879882813, "training_acc": 50.0, "val_loss": 0.7066362166404724, "val_acc": 48.0}
{"epoch": 26, "training_loss": 0.6935587525367737, "training_acc": 50.0, "val_loss": 0.6944274806976318, "val_acc": 52.0}
{"epoch": 27, "training_loss": 0.7042040753364563, "training_acc": 50.0, "val_loss": 0.6934129667282104, "val_acc": 52.0}
{"epoch": 28, "training_loss": 0.6989094734191894, "training_acc": 50.0, "val_loss": 0.6970882439613342, "val_acc": 48.0}
{"epoch": 29, "training_loss": 0.7029834461212158, "training_acc": 50.0, "val_loss": 0.6947320532798767, "val_acc": 48.0}
{"epoch": 30, "training_loss": 0.6906935048103332, "training_acc": 54.0, "val_loss": 0.6966972327232361, "val_acc": 52.0}
{"epoch": 31, "training_loss": 0.6985946917533874, "training_acc": 50.0, "val_loss": 0.694719250202179, "val_acc": 48.0}
{"epoch": 32, "training_loss": 0.7008606338500977, "training_acc": 50.0, "val_loss": 0.6967269444465637, "val_acc": 48.0}
{"epoch": 33, "training_loss": 0.6919749975204468, "training_acc": 56.0, "val_loss": 0.6991127419471741, "val_acc": 52.0}
{"epoch": 34, "training_loss": 0.7034522104263305, "training_acc": 48.0, "val_loss": 0.6939680099487304, "val_acc": 48.0}
{"epoch": 35, "training_loss": 0.7062516379356384, "training_acc": 48.0, "val_loss": 0.6927268552780151, "val_acc": 52.0}
{"epoch": 36, "training_loss": 0.6944522976875305, "training_acc": 52.0, "val_loss": 0.7056339311599732, "val_acc": 48.0}
{"epoch": 37, "training_loss": 0.7107575345039367, "training_acc": 46.0, "val_loss": 0.6927007818222046, "val_acc": 52.0}
{"epoch": 38, "training_loss": 0.699648163318634, "training_acc": 50.0, "val_loss": 0.7016061401367187, "val_acc": 48.0}
{"epoch": 39, "training_loss": 0.7014641523361206, "training_acc": 50.0, "val_loss": 0.6991379737854004, "val_acc": 48.0}
{"epoch": 40, "training_loss": 0.7046596431732177, "training_acc": 50.0, "val_loss": 0.6971381092071534, "val_acc": 48.0}
