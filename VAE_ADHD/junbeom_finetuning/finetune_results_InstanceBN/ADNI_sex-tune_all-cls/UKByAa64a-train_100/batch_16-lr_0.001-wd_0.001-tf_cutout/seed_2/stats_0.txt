"main_modify.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 2 --task ADNI_sex --input_option yAware --learning_rate 1e-3 --batch_size 16 --weight_decay 1e-3 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 0.7095456600189209, "training_acc": 48.0, "val_loss": 0.6950014233589172, "val_acc": 48.0}
{"epoch": 1, "training_loss": 0.7163159441947937, "training_acc": 52.0, "val_loss": 0.6974634194374084, "val_acc": 52.0}
{"epoch": 2, "training_loss": 0.6999273347854614, "training_acc": 52.0, "val_loss": 0.7108986496925354, "val_acc": 48.0}
{"epoch": 3, "training_loss": 0.7083457827568054, "training_acc": 50.0, "val_loss": 0.7035132336616516, "val_acc": 48.0}
{"epoch": 4, "training_loss": 0.7003475522994995, "training_acc": 50.0, "val_loss": 0.6932643818855285, "val_acc": 48.0}
{"epoch": 5, "training_loss": 0.6974431109428406, "training_acc": 52.0, "val_loss": 0.6927780747413635, "val_acc": 52.0}
{"epoch": 6, "training_loss": 0.7154026842117309, "training_acc": 50.0, "val_loss": 0.6926438689231873, "val_acc": 52.0}
{"epoch": 7, "training_loss": 0.70110107421875, "training_acc": 46.0, "val_loss": 0.6925503134727478, "val_acc": 52.0}
{"epoch": 8, "training_loss": 0.6988317680358886, "training_acc": 50.0, "val_loss": 0.6924037861824036, "val_acc": 52.0}
{"epoch": 9, "training_loss": 0.6978518629074096, "training_acc": 44.0, "val_loss": 0.6925918531417846, "val_acc": 52.0}
{"epoch": 10, "training_loss": 0.6960664892196655, "training_acc": 50.0, "val_loss": 0.6924169206619263, "val_acc": 52.0}
{"epoch": 11, "training_loss": 0.6949026584625244, "training_acc": 50.0, "val_loss": 0.6981290245056152, "val_acc": 48.0}
{"epoch": 12, "training_loss": 0.7028348517417907, "training_acc": 50.0, "val_loss": 0.6981780028343201, "val_acc": 48.0}
{"epoch": 13, "training_loss": 0.716410403251648, "training_acc": 46.0, "val_loss": 0.6924495005607605, "val_acc": 52.0}
{"epoch": 14, "training_loss": 0.6964614343643188, "training_acc": 48.0, "val_loss": 0.7099919605255127, "val_acc": 48.0}
{"epoch": 15, "training_loss": 0.7090556192398071, "training_acc": 50.0, "val_loss": 0.6941681814193725, "val_acc": 48.0}
{"epoch": 16, "training_loss": 0.6951541829109192, "training_acc": 48.0, "val_loss": 0.6929065251350403, "val_acc": 52.0}
{"epoch": 17, "training_loss": 0.7081477260589599, "training_acc": 44.0, "val_loss": 0.6962582802772522, "val_acc": 48.0}
{"epoch": 18, "training_loss": 0.7416425013542175, "training_acc": 50.0, "val_loss": 0.696193344593048, "val_acc": 48.0}
{"epoch": 19, "training_loss": 0.7003882455825806, "training_acc": 46.0, "val_loss": 0.6924647188186646, "val_acc": 52.0}
{"epoch": 20, "training_loss": 0.7025506591796875, "training_acc": 46.0, "val_loss": 0.6942640209197998, "val_acc": 48.0}
{"epoch": 21, "training_loss": 0.6944981026649475, "training_acc": 46.0, "val_loss": 0.6946112942695618, "val_acc": 52.0}
{"epoch": 22, "training_loss": 0.7166381025314331, "training_acc": 50.0, "val_loss": 0.6923467803001404, "val_acc": 52.0}
{"epoch": 23, "training_loss": 0.7263382005691529, "training_acc": 50.0, "val_loss": 0.7084187412261963, "val_acc": 48.0}
{"epoch": 24, "training_loss": 0.68907235622406, "training_acc": 52.0, "val_loss": 0.6988841962814331, "val_acc": 52.0}
{"epoch": 25, "training_loss": 0.7067044758796692, "training_acc": 50.0, "val_loss": 0.6926666927337647, "val_acc": 52.0}
{"epoch": 26, "training_loss": 0.697925157546997, "training_acc": 52.0, "val_loss": 0.7056231236457825, "val_acc": 48.0}
{"epoch": 27, "training_loss": 0.7017137694358826, "training_acc": 50.0, "val_loss": 0.6929808497428894, "val_acc": 52.0}
{"epoch": 28, "training_loss": 0.7032245922088624, "training_acc": 44.0, "val_loss": 0.6923983502388, "val_acc": 52.0}
{"epoch": 29, "training_loss": 0.6979957103729248, "training_acc": 50.0, "val_loss": 0.692396171092987, "val_acc": 52.0}
{"epoch": 30, "training_loss": 0.6986999750137329, "training_acc": 50.0, "val_loss": 0.7019023895263672, "val_acc": 48.0}
{"epoch": 31, "training_loss": 0.6997687077522278, "training_acc": 46.0, "val_loss": 0.6923665952682495, "val_acc": 52.0}
{"epoch": 32, "training_loss": 0.6970004320144654, "training_acc": 52.0, "val_loss": 0.7008528113365173, "val_acc": 48.0}
{"epoch": 33, "training_loss": 0.7092444062232971, "training_acc": 50.0, "val_loss": 0.7024269413948059, "val_acc": 48.0}
{"epoch": 34, "training_loss": 0.7002132368087769, "training_acc": 50.0, "val_loss": 0.7030036973953248, "val_acc": 48.0}
{"epoch": 35, "training_loss": 0.7035808682441711, "training_acc": 50.0, "val_loss": 0.6944918608665467, "val_acc": 48.0}
{"epoch": 36, "training_loss": 0.7130199337005615, "training_acc": 42.0, "val_loss": 0.6925479435920715, "val_acc": 52.0}
{"epoch": 37, "training_loss": 0.7020317506790161, "training_acc": 42.0, "val_loss": 0.6924146866798401, "val_acc": 52.0}
{"epoch": 38, "training_loss": 0.6933971333503723, "training_acc": 50.0, "val_loss": 0.6942641425132752, "val_acc": 52.0}
{"epoch": 39, "training_loss": 0.6905263376235962, "training_acc": 54.0, "val_loss": 0.7005628538131714, "val_acc": 48.0}
{"epoch": 40, "training_loss": 0.6973610019683838, "training_acc": 48.0, "val_loss": 0.6924745869636536, "val_acc": 52.0}
{"epoch": 41, "training_loss": 0.6948949003219604, "training_acc": 46.0, "val_loss": 0.6928373456001282, "val_acc": 52.0}
