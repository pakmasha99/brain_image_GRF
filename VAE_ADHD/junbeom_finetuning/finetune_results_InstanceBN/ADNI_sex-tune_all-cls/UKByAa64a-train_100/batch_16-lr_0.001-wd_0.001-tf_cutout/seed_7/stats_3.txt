"main_modify.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 7 --task ADNI_sex --input_option yAware --learning_rate 1e-3 --batch_size 16 --weight_decay 1e-3 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 0.7170764780044556, "training_acc": 46.0, "val_loss": 0.692392508983612, "val_acc": 52.0}
{"epoch": 1, "training_loss": 0.7034992623329163, "training_acc": 48.0, "val_loss": 0.6923983407020569, "val_acc": 52.0}
{"epoch": 2, "training_loss": 0.7069837999343872, "training_acc": 50.0, "val_loss": 0.6925065159797669, "val_acc": 52.0}
{"epoch": 3, "training_loss": 0.7172954106330871, "training_acc": 50.0, "val_loss": 0.6924794626235962, "val_acc": 52.0}
{"epoch": 4, "training_loss": 0.6963481092453003, "training_acc": 50.0, "val_loss": 0.7091422033309936, "val_acc": 48.0}
{"epoch": 5, "training_loss": 0.7130459308624267, "training_acc": 50.0, "val_loss": 0.6932829761505127, "val_acc": 48.0}
{"epoch": 6, "training_loss": 0.69689612865448, "training_acc": 48.0, "val_loss": 0.6929172873497009, "val_acc": 52.0}
{"epoch": 7, "training_loss": 0.7000770378112793, "training_acc": 50.0, "val_loss": 0.6933271098136902, "val_acc": 48.0}
{"epoch": 8, "training_loss": 0.7045335698127747, "training_acc": 50.0, "val_loss": 0.6937396621704102, "val_acc": 48.0}
{"epoch": 9, "training_loss": 0.6980348157882691, "training_acc": 42.0, "val_loss": 0.6959441494941712, "val_acc": 52.0}
{"epoch": 10, "training_loss": 0.7135212850570679, "training_acc": 50.0, "val_loss": 0.6940277409553528, "val_acc": 52.0}
{"epoch": 11, "training_loss": 0.6985024881362915, "training_acc": 50.0, "val_loss": 0.6988687109947205, "val_acc": 52.0}
{"epoch": 12, "training_loss": 0.7000928354263306, "training_acc": 48.0, "val_loss": 0.6993687200546265, "val_acc": 48.0}
{"epoch": 13, "training_loss": 0.7088863039016724, "training_acc": 44.0, "val_loss": 0.7005972266197205, "val_acc": 48.0}
{"epoch": 14, "training_loss": 0.7167562913894653, "training_acc": 50.0, "val_loss": 0.6983104252815246, "val_acc": 48.0}
{"epoch": 15, "training_loss": 0.7005306196212768, "training_acc": 50.0, "val_loss": 0.6932756161689758, "val_acc": 48.0}
{"epoch": 16, "training_loss": 0.7068342852592469, "training_acc": 50.0, "val_loss": 0.6976651120185852, "val_acc": 48.0}
{"epoch": 17, "training_loss": 0.6974010133743286, "training_acc": 50.0, "val_loss": 0.693906421661377, "val_acc": 48.0}
{"epoch": 18, "training_loss": 0.6958406400680542, "training_acc": 46.0, "val_loss": 0.6923834323883057, "val_acc": 52.0}
{"epoch": 19, "training_loss": 0.7000779390335083, "training_acc": 50.0, "val_loss": 0.6929321026802063, "val_acc": 52.0}
{"epoch": 20, "training_loss": 0.6977482748031616, "training_acc": 44.0, "val_loss": 0.6946340942382813, "val_acc": 48.0}
{"epoch": 21, "training_loss": 0.7116819500923157, "training_acc": 50.0, "val_loss": 0.7074196314811707, "val_acc": 48.0}
{"epoch": 22, "training_loss": 0.7018448233604431, "training_acc": 50.0, "val_loss": 0.6924092745780945, "val_acc": 52.0}
{"epoch": 23, "training_loss": 0.7071683192253113, "training_acc": 50.0, "val_loss": 0.6929176282882691, "val_acc": 52.0}
{"epoch": 24, "training_loss": 0.6998884677886963, "training_acc": 50.0, "val_loss": 0.6924855947494507, "val_acc": 52.0}
{"epoch": 25, "training_loss": 0.6921512174606324, "training_acc": 52.0, "val_loss": 0.7034801125526429, "val_acc": 48.0}
{"epoch": 26, "training_loss": 0.7075357818603516, "training_acc": 50.0, "val_loss": 0.6975584030151367, "val_acc": 48.0}
{"epoch": 27, "training_loss": 0.7148725652694702, "training_acc": 50.0, "val_loss": 0.6939342522621155, "val_acc": 48.0}
{"epoch": 28, "training_loss": 0.717138123512268, "training_acc": 48.0, "val_loss": 0.6979458093643188, "val_acc": 52.0}
{"epoch": 29, "training_loss": 0.7004443264007568, "training_acc": 50.0, "val_loss": 0.6977684187889099, "val_acc": 48.0}
{"epoch": 30, "training_loss": 0.7087005424499512, "training_acc": 50.0, "val_loss": 0.6975478863716126, "val_acc": 48.0}
{"epoch": 31, "training_loss": 0.6973242473602295, "training_acc": 48.0, "val_loss": 0.692348313331604, "val_acc": 52.0}
{"epoch": 32, "training_loss": 0.70598388671875, "training_acc": 46.0, "val_loss": 0.6946275663375855, "val_acc": 48.0}
{"epoch": 33, "training_loss": 0.7073803615570068, "training_acc": 40.0, "val_loss": 0.6965765762329101, "val_acc": 48.0}
{"epoch": 34, "training_loss": 0.6983632445335388, "training_acc": 50.0, "val_loss": 0.6934370827674866, "val_acc": 48.0}
{"epoch": 35, "training_loss": 0.6979655861854553, "training_acc": 52.0, "val_loss": 0.6962696957588196, "val_acc": 52.0}
{"epoch": 36, "training_loss": 0.6936368203163147, "training_acc": 50.0, "val_loss": 0.698616714477539, "val_acc": 48.0}
{"epoch": 37, "training_loss": 0.7210305595397949, "training_acc": 50.0, "val_loss": 0.6968785500526429, "val_acc": 48.0}
{"epoch": 38, "training_loss": 0.7128602957725525, "training_acc": 46.0, "val_loss": 0.6939406275749207, "val_acc": 48.0}
{"epoch": 39, "training_loss": 0.7011203598976136, "training_acc": 48.0, "val_loss": 0.6955046319961548, "val_acc": 48.0}
{"epoch": 40, "training_loss": 0.7103253412246704, "training_acc": 44.0, "val_loss": 0.6928855156898499, "val_acc": 52.0}
{"epoch": 41, "training_loss": 0.6987273550033569, "training_acc": 48.0, "val_loss": 0.6933185982704163, "val_acc": 48.0}
{"epoch": 42, "training_loss": 0.6970579242706298, "training_acc": 50.0, "val_loss": 0.6923763394355774, "val_acc": 52.0}
{"epoch": 43, "training_loss": 0.7159363079071045, "training_acc": 44.0, "val_loss": 0.6949367618560791, "val_acc": 48.0}
{"epoch": 44, "training_loss": 0.7135644841194153, "training_acc": 48.0, "val_loss": 0.6928214049339294, "val_acc": 52.0}
{"epoch": 45, "training_loss": 0.6952380180358887, "training_acc": 50.0, "val_loss": 0.7141413140296936, "val_acc": 48.0}
{"epoch": 46, "training_loss": 0.7143994784355163, "training_acc": 50.0, "val_loss": 0.6923689985275269, "val_acc": 52.0}
{"epoch": 47, "training_loss": 0.7284355545043946, "training_acc": 50.0, "val_loss": 0.7148217749595642, "val_acc": 52.0}
{"epoch": 48, "training_loss": 0.7132270669937134, "training_acc": 48.0, "val_loss": 0.699481258392334, "val_acc": 48.0}
{"epoch": 49, "training_loss": 0.7030723977088928, "training_acc": 42.0, "val_loss": 0.6952615094184875, "val_acc": 48.0}
{"epoch": 50, "training_loss": 0.7064485764503479, "training_acc": 50.0, "val_loss": 0.6954062962532044, "val_acc": 48.0}
