"main_modify.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ADNI_sex --input_option yAware --learning_rate 1e-3 --batch_size 16 --weight_decay 1e-3 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 0.7441692638397217, "training_acc": 32.0, "val_loss": 0.6928597617149354, "val_acc": 52.0}
{"epoch": 1, "training_loss": 0.7027075076103211, "training_acc": 46.0, "val_loss": 0.693906147480011, "val_acc": 52.0}
{"epoch": 2, "training_loss": 0.7024868559837342, "training_acc": 44.0, "val_loss": 0.6925199913978577, "val_acc": 52.0}
{"epoch": 3, "training_loss": 0.7044369411468506, "training_acc": 50.0, "val_loss": 0.6925269269943237, "val_acc": 52.0}
{"epoch": 4, "training_loss": 0.7055434560775757, "training_acc": 50.0, "val_loss": 0.6931229710578919, "val_acc": 52.0}
{"epoch": 5, "training_loss": 0.7022363948822021, "training_acc": 46.0, "val_loss": 0.695982220172882, "val_acc": 48.0}
{"epoch": 6, "training_loss": 0.6971907520294189, "training_acc": 50.0, "val_loss": 0.692398636341095, "val_acc": 52.0}
{"epoch": 7, "training_loss": 0.6963956332206727, "training_acc": 44.0, "val_loss": 0.6924585199356079, "val_acc": 52.0}
{"epoch": 8, "training_loss": 0.7153305435180664, "training_acc": 50.0, "val_loss": 0.6930387926101684, "val_acc": 52.0}
{"epoch": 9, "training_loss": 0.6947173595428466, "training_acc": 50.0, "val_loss": 0.697211525440216, "val_acc": 48.0}
{"epoch": 10, "training_loss": 0.7056870698928833, "training_acc": 42.0, "val_loss": 0.6937664198875427, "val_acc": 48.0}
{"epoch": 11, "training_loss": 0.7011652326583863, "training_acc": 50.0, "val_loss": 0.69248948097229, "val_acc": 52.0}
{"epoch": 12, "training_loss": 0.7124676561355591, "training_acc": 38.0, "val_loss": 0.6928234839439392, "val_acc": 52.0}
{"epoch": 13, "training_loss": 0.7212942600250244, "training_acc": 50.0, "val_loss": 0.6931550908088684, "val_acc": 48.0}
{"epoch": 14, "training_loss": 0.7048519825935364, "training_acc": 50.0, "val_loss": 0.6985465598106384, "val_acc": 48.0}
{"epoch": 15, "training_loss": 0.7002331066131592, "training_acc": 44.0, "val_loss": 0.695848777294159, "val_acc": 48.0}
{"epoch": 16, "training_loss": 0.7018969583511353, "training_acc": 50.0, "val_loss": 0.6928210973739624, "val_acc": 52.0}
{"epoch": 17, "training_loss": 0.7258000540733337, "training_acc": 50.0, "val_loss": 0.6937738752365112, "val_acc": 52.0}
{"epoch": 18, "training_loss": 0.6931527447700501, "training_acc": 52.0, "val_loss": 0.7027390241622925, "val_acc": 48.0}
{"epoch": 19, "training_loss": 0.6941792726516723, "training_acc": 52.0, "val_loss": 0.6943903040885925, "val_acc": 52.0}
{"epoch": 20, "training_loss": 0.7128049421310425, "training_acc": 50.0, "val_loss": 0.6930627346038818, "val_acc": 52.0}
{"epoch": 21, "training_loss": 0.6952416443824768, "training_acc": 54.0, "val_loss": 0.7058592700958252, "val_acc": 48.0}
{"epoch": 22, "training_loss": 0.6952953243255615, "training_acc": 50.0, "val_loss": 0.6932057976722718, "val_acc": 52.0}
{"epoch": 23, "training_loss": 0.6993606567382813, "training_acc": 50.0, "val_loss": 0.6938884449005127, "val_acc": 48.0}
{"epoch": 24, "training_loss": 0.7051124572753906, "training_acc": 50.0, "val_loss": 0.696028208732605, "val_acc": 48.0}
{"epoch": 25, "training_loss": 0.6965456128120422, "training_acc": 48.0, "val_loss": 0.6930360603332519, "val_acc": 52.0}
{"epoch": 26, "training_loss": 0.7008716058731079, "training_acc": 50.0, "val_loss": 0.6923806571960449, "val_acc": 52.0}
{"epoch": 27, "training_loss": 0.708279504776001, "training_acc": 46.0, "val_loss": 0.7060883736610413, "val_acc": 48.0}
{"epoch": 28, "training_loss": 0.7201352143287658, "training_acc": 44.0, "val_loss": 0.6993792700767517, "val_acc": 48.0}
{"epoch": 29, "training_loss": 0.7052459359169007, "training_acc": 36.0, "val_loss": 0.7148414373397827, "val_acc": 48.0}
{"epoch": 30, "training_loss": 0.7041581916809082, "training_acc": 50.0, "val_loss": 0.6933494353294373, "val_acc": 48.0}
{"epoch": 31, "training_loss": 0.6953521728515625, "training_acc": 46.0, "val_loss": 0.6923866367340088, "val_acc": 52.0}
{"epoch": 32, "training_loss": 0.7066893196105957, "training_acc": 50.0, "val_loss": 0.6940624737739562, "val_acc": 52.0}
{"epoch": 33, "training_loss": 0.6927696752548218, "training_acc": 50.0, "val_loss": 0.707126591205597, "val_acc": 48.0}
{"epoch": 34, "training_loss": 0.7066647744178772, "training_acc": 50.0, "val_loss": 0.6950328469276428, "val_acc": 48.0}
{"epoch": 35, "training_loss": 0.6955736494064331, "training_acc": 46.0, "val_loss": 0.6923885273933411, "val_acc": 52.0}
{"epoch": 36, "training_loss": 0.6953473234176636, "training_acc": 46.0, "val_loss": 0.6923468518257141, "val_acc": 52.0}
{"epoch": 37, "training_loss": 0.7172395277023316, "training_acc": 50.0, "val_loss": 0.6923643517494201, "val_acc": 52.0}
{"epoch": 38, "training_loss": 0.7126862525939941, "training_acc": 46.0, "val_loss": 0.6940345454216004, "val_acc": 48.0}
{"epoch": 39, "training_loss": 0.6968289923667907, "training_acc": 46.0, "val_loss": 0.694191746711731, "val_acc": 48.0}
{"epoch": 40, "training_loss": 0.7189367127418518, "training_acc": 50.0, "val_loss": 0.6929071521759034, "val_acc": 52.0}
{"epoch": 41, "training_loss": 0.6977494955062866, "training_acc": 50.0, "val_loss": 0.6928080725669861, "val_acc": 52.0}
{"epoch": 42, "training_loss": 0.6987963819503784, "training_acc": 48.0, "val_loss": 0.6944492983818055, "val_acc": 48.0}
{"epoch": 43, "training_loss": 0.6966548490524292, "training_acc": 50.0, "val_loss": 0.6932318520545959, "val_acc": 52.0}
{"epoch": 44, "training_loss": 0.7179112243652344, "training_acc": 50.0, "val_loss": 0.6959302258491517, "val_acc": 52.0}
{"epoch": 45, "training_loss": 0.6971356701850892, "training_acc": 50.0, "val_loss": 0.704743640422821, "val_acc": 48.0}
{"epoch": 46, "training_loss": 0.7174933671951294, "training_acc": 50.0, "val_loss": 0.70004878282547, "val_acc": 48.0}
{"epoch": 47, "training_loss": 0.690458402633667, "training_acc": 56.0, "val_loss": 0.6998001217842102, "val_acc": 52.0}
{"epoch": 48, "training_loss": 0.7077724885940552, "training_acc": 50.0, "val_loss": 0.6923562097549438, "val_acc": 52.0}
{"epoch": 49, "training_loss": 0.6928070068359375, "training_acc": 52.0, "val_loss": 0.6997674250602722, "val_acc": 48.0}
{"epoch": 50, "training_loss": 0.6999288177490235, "training_acc": 50.0, "val_loss": 0.6948242592811584, "val_acc": 48.0}
{"epoch": 51, "training_loss": 0.695374231338501, "training_acc": 50.0, "val_loss": 0.6925094246864318, "val_acc": 52.0}
{"epoch": 52, "training_loss": 0.6970233821868896, "training_acc": 50.0, "val_loss": 0.6940763425827027, "val_acc": 52.0}
{"epoch": 53, "training_loss": 0.6978841400146485, "training_acc": 50.0, "val_loss": 0.6975249171257019, "val_acc": 48.0}
{"epoch": 54, "training_loss": 0.7021465492248535, "training_acc": 50.0, "val_loss": 0.6942497301101684, "val_acc": 48.0}
{"epoch": 55, "training_loss": 0.6962710952758789, "training_acc": 52.0, "val_loss": 0.6958210778236389, "val_acc": 52.0}
