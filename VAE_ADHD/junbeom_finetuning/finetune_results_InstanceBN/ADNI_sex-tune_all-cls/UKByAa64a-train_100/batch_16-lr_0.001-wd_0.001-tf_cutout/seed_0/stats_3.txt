"main_modify.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ADNI_sex --input_option yAware --learning_rate 1e-3 --batch_size 16 --weight_decay 1e-3 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 0.7121378898620605, "training_acc": 41.0, "val_loss": 0.7032354712486267, "val_acc": 48.0}
{"epoch": 1, "training_loss": 0.7349902200698852, "training_acc": 50.0, "val_loss": 0.6984687113761902, "val_acc": 52.0}
{"epoch": 2, "training_loss": 0.7067173767089844, "training_acc": 50.0, "val_loss": 0.6941514158248902, "val_acc": 48.0}
{"epoch": 3, "training_loss": 0.7045585966110229, "training_acc": 50.0, "val_loss": 0.6931082487106324, "val_acc": 56.0}
{"epoch": 4, "training_loss": 0.703477783203125, "training_acc": 48.0, "val_loss": 0.692803373336792, "val_acc": 52.0}
{"epoch": 5, "training_loss": 0.6993207287788391, "training_acc": 50.0, "val_loss": 0.6984905672073364, "val_acc": 48.0}
{"epoch": 6, "training_loss": 0.7006699824333191, "training_acc": 44.0, "val_loss": 0.6969958615303039, "val_acc": 48.0}
{"epoch": 7, "training_loss": 0.6973577952384948, "training_acc": 50.0, "val_loss": 0.6960097670555114, "val_acc": 48.0}
{"epoch": 8, "training_loss": 0.6952466678619384, "training_acc": 50.0, "val_loss": 0.6943719077110291, "val_acc": 52.0}
{"epoch": 9, "training_loss": 0.7075879597663879, "training_acc": 50.0, "val_loss": 0.6924514412879944, "val_acc": 52.0}
{"epoch": 10, "training_loss": 0.7204084181785584, "training_acc": 44.0, "val_loss": 0.7083434557914734, "val_acc": 48.0}
{"epoch": 11, "training_loss": 0.7000723385810852, "training_acc": 52.0, "val_loss": 0.6954186701774597, "val_acc": 52.0}
{"epoch": 12, "training_loss": 0.6995899200439453, "training_acc": 48.0, "val_loss": 0.69450270652771, "val_acc": 48.0}
{"epoch": 13, "training_loss": 0.7016990637779236, "training_acc": 41.0, "val_loss": 0.6942519354820251, "val_acc": 52.0}
{"epoch": 14, "training_loss": 0.7133312320709229, "training_acc": 50.0, "val_loss": 0.6988182401657105, "val_acc": 48.0}
{"epoch": 15, "training_loss": 0.7003054237365722, "training_acc": 50.0, "val_loss": 0.7154428029060363, "val_acc": 48.0}
{"epoch": 16, "training_loss": 0.6954700517654419, "training_acc": 50.0, "val_loss": 0.692997362613678, "val_acc": 52.0}
{"epoch": 17, "training_loss": 0.7045539999008179, "training_acc": 48.0, "val_loss": 0.6975125885009765, "val_acc": 48.0}
{"epoch": 18, "training_loss": 0.6940908694267273, "training_acc": 50.0, "val_loss": 0.6923629713058471, "val_acc": 52.0}
{"epoch": 19, "training_loss": 0.6970938920974732, "training_acc": 50.0, "val_loss": 0.692583703994751, "val_acc": 52.0}
{"epoch": 20, "training_loss": 0.703659348487854, "training_acc": 46.0, "val_loss": 0.6985017871856689, "val_acc": 48.0}
{"epoch": 21, "training_loss": 0.6968751430511475, "training_acc": 48.0, "val_loss": 0.6924545359611511, "val_acc": 52.0}
{"epoch": 22, "training_loss": 0.6937666368484497, "training_acc": 50.0, "val_loss": 0.694699387550354, "val_acc": 48.0}
{"epoch": 23, "training_loss": 0.702388949394226, "training_acc": 50.0, "val_loss": 0.7023984909057617, "val_acc": 48.0}
{"epoch": 24, "training_loss": 0.7135614967346191, "training_acc": 50.0, "val_loss": 0.692348234653473, "val_acc": 52.0}
{"epoch": 25, "training_loss": 0.7271279382705689, "training_acc": 50.0, "val_loss": 0.7009566116333008, "val_acc": 52.0}
{"epoch": 26, "training_loss": 0.6991625308990479, "training_acc": 48.0, "val_loss": 0.6998100590705871, "val_acc": 48.0}
{"epoch": 27, "training_loss": 0.7013543653488159, "training_acc": 50.0, "val_loss": 0.6962208104133606, "val_acc": 48.0}
{"epoch": 28, "training_loss": 0.6980483436584473, "training_acc": 46.0, "val_loss": 0.693393862247467, "val_acc": 48.0}
{"epoch": 29, "training_loss": 0.7020005679130554, "training_acc": 50.0, "val_loss": 0.6965765738487244, "val_acc": 48.0}
{"epoch": 30, "training_loss": 0.6969709157943725, "training_acc": 48.0, "val_loss": 0.6924335098266602, "val_acc": 52.0}
{"epoch": 31, "training_loss": 0.6968342804908753, "training_acc": 46.0, "val_loss": 0.6926512622833252, "val_acc": 52.0}
{"epoch": 32, "training_loss": 0.6969380378723145, "training_acc": 50.0, "val_loss": 0.6931548857688904, "val_acc": 52.0}
{"epoch": 33, "training_loss": 0.7201758766174317, "training_acc": 40.0, "val_loss": 0.6950855374336242, "val_acc": 48.0}
{"epoch": 34, "training_loss": 0.729904453754425, "training_acc": 44.0, "val_loss": 0.6941268181800843, "val_acc": 52.0}
{"epoch": 35, "training_loss": 0.7037362623214721, "training_acc": 48.0, "val_loss": 0.6948032569885254, "val_acc": 48.0}
{"epoch": 36, "training_loss": 0.6980635285377502, "training_acc": 50.0, "val_loss": 0.6941280031204223, "val_acc": 52.0}
{"epoch": 37, "training_loss": 0.7172455406188964, "training_acc": 50.0, "val_loss": 0.6923856711387635, "val_acc": 52.0}
{"epoch": 38, "training_loss": 0.7149988985061646, "training_acc": 50.0, "val_loss": 0.7133049368858337, "val_acc": 48.0}
{"epoch": 39, "training_loss": 0.7124359655380249, "training_acc": 40.0, "val_loss": 0.6952969861030579, "val_acc": 52.0}
{"epoch": 40, "training_loss": 0.7004517984390258, "training_acc": 50.0, "val_loss": 0.6928282713890076, "val_acc": 52.0}
{"epoch": 41, "training_loss": 0.7148922395706176, "training_acc": 50.0, "val_loss": 0.6959022665023804, "val_acc": 48.0}
{"epoch": 42, "training_loss": 0.6982693862915039, "training_acc": 54.0, "val_loss": 0.7059556746482849, "val_acc": 52.0}
{"epoch": 43, "training_loss": 0.6981146788597107, "training_acc": 52.0, "val_loss": 0.7008945250511169, "val_acc": 48.0}
