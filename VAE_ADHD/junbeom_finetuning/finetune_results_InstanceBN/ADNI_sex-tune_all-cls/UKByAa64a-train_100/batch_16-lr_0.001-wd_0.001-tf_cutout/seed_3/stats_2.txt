"main_modify.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 3 --task ADNI_sex --input_option yAware --learning_rate 1e-3 --batch_size 16 --weight_decay 1e-3 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 0.709609055519104, "training_acc": 54.0, "val_loss": 0.7112151718139649, "val_acc": 48.0}
{"epoch": 1, "training_loss": 0.7153092527389526, "training_acc": 44.0, "val_loss": 0.6944155144691467, "val_acc": 48.0}
{"epoch": 2, "training_loss": 0.7055178308486938, "training_acc": 54.0, "val_loss": 0.6924205875396728, "val_acc": 52.0}
{"epoch": 3, "training_loss": 0.6974068307876586, "training_acc": 50.0, "val_loss": 0.6944405722618103, "val_acc": 48.0}
{"epoch": 4, "training_loss": 0.7018333435058594, "training_acc": 48.0, "val_loss": 0.6965964698791504, "val_acc": 52.0}
{"epoch": 5, "training_loss": 0.6966629838943481, "training_acc": 50.0, "val_loss": 0.6971992707252502, "val_acc": 48.0}
{"epoch": 6, "training_loss": 0.7072836971282959, "training_acc": 50.0, "val_loss": 0.6935072040557861, "val_acc": 48.0}
{"epoch": 7, "training_loss": 0.6964677858352661, "training_acc": 48.0, "val_loss": 0.6946398258209229, "val_acc": 48.0}
{"epoch": 8, "training_loss": 0.7008988642692566, "training_acc": 50.0, "val_loss": 0.6971039128303528, "val_acc": 48.0}
{"epoch": 9, "training_loss": 0.6983197927474976, "training_acc": 46.0, "val_loss": 0.692713885307312, "val_acc": 52.0}
{"epoch": 10, "training_loss": 0.6998682975769043, "training_acc": 50.0, "val_loss": 0.6924081015586853, "val_acc": 52.0}
{"epoch": 11, "training_loss": 0.7148628306388854, "training_acc": 44.0, "val_loss": 0.6931636023521424, "val_acc": 48.0}
{"epoch": 12, "training_loss": 0.7154897689819336, "training_acc": 52.0, "val_loss": 0.6992654442787171, "val_acc": 52.0}
{"epoch": 13, "training_loss": 0.7036075448989868, "training_acc": 50.0, "val_loss": 0.695788962841034, "val_acc": 48.0}
{"epoch": 14, "training_loss": 0.7267063188552857, "training_acc": 50.0, "val_loss": 0.7086102795600892, "val_acc": 48.0}
{"epoch": 15, "training_loss": 0.7042507553100585, "training_acc": 46.0, "val_loss": 0.6974509119987488, "val_acc": 48.0}
{"epoch": 16, "training_loss": 0.7029158329963684, "training_acc": 50.0, "val_loss": 0.6974461126327515, "val_acc": 48.0}
{"epoch": 17, "training_loss": 0.6963869190216064, "training_acc": 42.0, "val_loss": 0.6937192678451538, "val_acc": 52.0}
{"epoch": 18, "training_loss": 0.7110968065261841, "training_acc": 50.0, "val_loss": 0.6934811758995056, "val_acc": 52.0}
{"epoch": 19, "training_loss": 0.708611626625061, "training_acc": 50.0, "val_loss": 0.6934278631210327, "val_acc": 52.0}
{"epoch": 20, "training_loss": 0.7137316155433655, "training_acc": 52.0, "val_loss": 0.7336751770973206, "val_acc": 48.0}
{"epoch": 21, "training_loss": 0.7209552168846131, "training_acc": 50.0, "val_loss": 0.6923634719848633, "val_acc": 52.0}
{"epoch": 22, "training_loss": 0.7065385675430298, "training_acc": 50.0, "val_loss": 0.6925041389465332, "val_acc": 52.0}
{"epoch": 23, "training_loss": 0.6953649663925171, "training_acc": 50.0, "val_loss": 0.6923541355133057, "val_acc": 52.0}
{"epoch": 24, "training_loss": 0.6980577754974365, "training_acc": 50.0, "val_loss": 0.693783836364746, "val_acc": 48.0}
{"epoch": 25, "training_loss": 0.6951254081726074, "training_acc": 50.0, "val_loss": 0.6939993381500245, "val_acc": 48.0}
{"epoch": 26, "training_loss": 0.6983501863479614, "training_acc": 44.0, "val_loss": 0.6926111197471618, "val_acc": 52.0}
{"epoch": 27, "training_loss": 0.6943636131286621, "training_acc": 50.0, "val_loss": 0.6944811630249024, "val_acc": 48.0}
{"epoch": 28, "training_loss": 0.7083231973648071, "training_acc": 50.0, "val_loss": 0.6985960221290588, "val_acc": 48.0}
{"epoch": 29, "training_loss": 0.7040982437133789, "training_acc": 46.0, "val_loss": 0.6963640356063843, "val_acc": 52.0}
{"epoch": 30, "training_loss": 0.7009575867652893, "training_acc": 50.0, "val_loss": 0.6963637161254883, "val_acc": 48.0}
{"epoch": 31, "training_loss": 0.7135368394851684, "training_acc": 50.0, "val_loss": 0.697350664138794, "val_acc": 48.0}
{"epoch": 32, "training_loss": 0.69420907497406, "training_acc": 50.0, "val_loss": 0.6932427167892456, "val_acc": 52.0}
{"epoch": 33, "training_loss": 0.7184444093704223, "training_acc": 50.0, "val_loss": 0.6924095129966736, "val_acc": 52.0}
{"epoch": 34, "training_loss": 0.6957137632369995, "training_acc": 50.0, "val_loss": 0.6982809185981751, "val_acc": 48.0}
{"epoch": 35, "training_loss": 0.7121689462661743, "training_acc": 50.0, "val_loss": 0.6941475248336793, "val_acc": 48.0}
{"epoch": 36, "training_loss": 0.693555724620819, "training_acc": 56.0, "val_loss": 0.6981144738197327, "val_acc": 52.0}
{"epoch": 37, "training_loss": 0.7098353576660156, "training_acc": 40.0, "val_loss": 0.6951408123970032, "val_acc": 48.0}
{"epoch": 38, "training_loss": 0.7048271536827088, "training_acc": 50.0, "val_loss": 0.6954504370689392, "val_acc": 48.0}
{"epoch": 39, "training_loss": 0.7006447887420655, "training_acc": 44.0, "val_loss": 0.6940121936798096, "val_acc": 52.0}
{"epoch": 40, "training_loss": 0.7182174062728882, "training_acc": 50.0, "val_loss": 0.6993007302284241, "val_acc": 52.0}
{"epoch": 41, "training_loss": 0.70947744846344, "training_acc": 46.0, "val_loss": 0.6950961136817932, "val_acc": 48.0}
{"epoch": 42, "training_loss": 0.6979122829437255, "training_acc": 44.0, "val_loss": 0.6931993436813354, "val_acc": 48.0}
