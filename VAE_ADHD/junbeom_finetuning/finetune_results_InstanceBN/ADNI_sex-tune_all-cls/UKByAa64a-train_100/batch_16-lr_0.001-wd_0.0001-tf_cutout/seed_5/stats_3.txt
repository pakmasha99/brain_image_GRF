"main_modify.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 5 --task ADNI_sex --input_option yAware --learning_rate 1e-3 --batch_size 16 --weight_decay 1e-4 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 0.7054195570945739, "training_acc": 48.0, "val_loss": 0.6947879910469055, "val_acc": 52.0}
{"epoch": 1, "training_loss": 0.7240884208679199, "training_acc": 43.0, "val_loss": 0.6986888647079468, "val_acc": 52.0}
{"epoch": 2, "training_loss": 0.7198541569709778, "training_acc": 49.0, "val_loss": 0.6994018936157227, "val_acc": 48.0}
{"epoch": 3, "training_loss": 0.7461727857589722, "training_acc": 51.0, "val_loss": 0.704111840724945, "val_acc": 48.0}
{"epoch": 4, "training_loss": 0.7006815099716186, "training_acc": 47.0, "val_loss": 0.6934811019897461, "val_acc": 52.0}
{"epoch": 5, "training_loss": 0.7091732811927796, "training_acc": 37.0, "val_loss": 0.6923677563667298, "val_acc": 52.0}
{"epoch": 6, "training_loss": 0.6968057179450988, "training_acc": 49.0, "val_loss": 0.6929247641563415, "val_acc": 52.0}
{"epoch": 7, "training_loss": 0.6982283401489258, "training_acc": 47.0, "val_loss": 0.7001282429695129, "val_acc": 48.0}
{"epoch": 8, "training_loss": 0.7012787961959839, "training_acc": 51.0, "val_loss": 0.7036950325965882, "val_acc": 48.0}
{"epoch": 9, "training_loss": 0.7031376934051514, "training_acc": 43.0, "val_loss": 0.6923854160308838, "val_acc": 52.0}
{"epoch": 10, "training_loss": 0.6948514938354492, "training_acc": 47.0, "val_loss": 0.6947040295600891, "val_acc": 48.0}
{"epoch": 11, "training_loss": 0.6977958369255066, "training_acc": 43.0, "val_loss": 0.6949631595611572, "val_acc": 48.0}
{"epoch": 12, "training_loss": 0.703850736618042, "training_acc": 51.0, "val_loss": 0.7039407277107239, "val_acc": 48.0}
{"epoch": 13, "training_loss": 0.6960228729248047, "training_acc": 51.0, "val_loss": 0.6938122510910034, "val_acc": 52.0}
{"epoch": 14, "training_loss": 0.69128342628479, "training_acc": 51.0, "val_loss": 0.7026627373695373, "val_acc": 48.0}
{"epoch": 15, "training_loss": 0.7097089910507202, "training_acc": 51.0, "val_loss": 0.709392831325531, "val_acc": 48.0}
{"epoch": 16, "training_loss": 0.691600866317749, "training_acc": 55.0, "val_loss": 0.6951500630378723, "val_acc": 52.0}
{"epoch": 17, "training_loss": 0.7100516748428345, "training_acc": 49.0, "val_loss": 0.6935439610481262, "val_acc": 52.0}
{"epoch": 18, "training_loss": 0.6954518413543701, "training_acc": 47.0, "val_loss": 0.6947446513175964, "val_acc": 48.0}
{"epoch": 19, "training_loss": 0.702678587436676, "training_acc": 51.0, "val_loss": 0.699238440990448, "val_acc": 48.0}
{"epoch": 20, "training_loss": 0.7030269527435302, "training_acc": 51.0, "val_loss": 0.7036050462722778, "val_acc": 48.0}
{"epoch": 21, "training_loss": 0.6927767300605774, "training_acc": 51.0, "val_loss": 0.6923284888267517, "val_acc": 52.0}
{"epoch": 22, "training_loss": 0.6945836615562438, "training_acc": 47.0, "val_loss": 0.6952900099754333, "val_acc": 48.0}
{"epoch": 23, "training_loss": 0.7000306010246277, "training_acc": 51.0, "val_loss": 0.6973329710960389, "val_acc": 48.0}
{"epoch": 24, "training_loss": 0.6955239868164063, "training_acc": 51.0, "val_loss": 0.6930490970611572, "val_acc": 52.0}
{"epoch": 25, "training_loss": 0.6974241995811462, "training_acc": 49.0, "val_loss": 0.6938349986076355, "val_acc": 48.0}
{"epoch": 26, "training_loss": 0.7040148997306823, "training_acc": 51.0, "val_loss": 0.7030014514923095, "val_acc": 48.0}
{"epoch": 27, "training_loss": 0.6915274953842163, "training_acc": 53.0, "val_loss": 0.6935330319404602, "val_acc": 52.0}
{"epoch": 28, "training_loss": 0.7168526434898377, "training_acc": 49.0, "val_loss": 0.6971695280075073, "val_acc": 52.0}
{"epoch": 29, "training_loss": 0.7015241694450378, "training_acc": 45.0, "val_loss": 0.7032855296134949, "val_acc": 48.0}
{"epoch": 30, "training_loss": 0.7008641886711121, "training_acc": 51.0, "val_loss": 0.7023765611648559, "val_acc": 48.0}
{"epoch": 31, "training_loss": 0.7025646257400513, "training_acc": 45.0, "val_loss": 0.6924835181236267, "val_acc": 52.0}
{"epoch": 32, "training_loss": 0.7059687376022339, "training_acc": 49.0, "val_loss": 0.695958137512207, "val_acc": 48.0}
{"epoch": 33, "training_loss": 0.7220908880233765, "training_acc": 51.0, "val_loss": 0.703823356628418, "val_acc": 48.0}
{"epoch": 34, "training_loss": 0.7115680813789368, "training_acc": 49.0, "val_loss": 0.6955808401107788, "val_acc": 52.0}
{"epoch": 35, "training_loss": 0.6921431350708008, "training_acc": 55.0, "val_loss": 0.7323738813400269, "val_acc": 48.0}
{"epoch": 36, "training_loss": 0.7280075168609619, "training_acc": 51.0, "val_loss": 0.696915123462677, "val_acc": 48.0}
{"epoch": 37, "training_loss": 0.695588412284851, "training_acc": 51.0, "val_loss": 0.693512966632843, "val_acc": 48.0}
{"epoch": 38, "training_loss": 0.6948415660858154, "training_acc": 53.0, "val_loss": 0.6926722407341004, "val_acc": 52.0}
{"epoch": 39, "training_loss": 0.7003467845916748, "training_acc": 47.0, "val_loss": 0.6923623776435852, "val_acc": 52.0}
{"epoch": 40, "training_loss": 0.703354938030243, "training_acc": 49.0, "val_loss": 0.693991539478302, "val_acc": 52.0}
