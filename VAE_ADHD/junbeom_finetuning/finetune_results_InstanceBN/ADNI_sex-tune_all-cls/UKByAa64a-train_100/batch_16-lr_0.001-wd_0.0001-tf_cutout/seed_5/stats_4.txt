"main_modify.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 5 --task ADNI_sex --input_option yAware --learning_rate 1e-3 --batch_size 16 --weight_decay 1e-4 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 0.7047599196434021, "training_acc": 48.0, "val_loss": 0.6963338112831116, "val_acc": 48.0}
{"epoch": 1, "training_loss": 0.720494441986084, "training_acc": 45.0, "val_loss": 0.6952576541900635, "val_acc": 48.0}
{"epoch": 2, "training_loss": 0.6969306182861328, "training_acc": 51.0, "val_loss": 0.697255163192749, "val_acc": 48.0}
{"epoch": 3, "training_loss": 0.7003536486625671, "training_acc": 47.0, "val_loss": 0.6940422558784485, "val_acc": 48.0}
{"epoch": 4, "training_loss": 0.6947010445594788, "training_acc": 51.0, "val_loss": 0.7037994885444641, "val_acc": 48.0}
{"epoch": 5, "training_loss": 0.7016391468048095, "training_acc": 43.0, "val_loss": 0.6928794860839844, "val_acc": 52.0}
{"epoch": 6, "training_loss": 0.6996884441375733, "training_acc": 49.0, "val_loss": 0.6937540531158447, "val_acc": 48.0}
{"epoch": 7, "training_loss": 0.6972820568084717, "training_acc": 49.0, "val_loss": 0.6927935743331909, "val_acc": 52.0}
{"epoch": 8, "training_loss": 0.704478633403778, "training_acc": 49.0, "val_loss": 0.7094511485099793, "val_acc": 48.0}
{"epoch": 9, "training_loss": 0.7034206867218018, "training_acc": 51.0, "val_loss": 0.6926816129684448, "val_acc": 52.0}
{"epoch": 10, "training_loss": 0.6954591703414917, "training_acc": 49.0, "val_loss": 0.6932687425613403, "val_acc": 48.0}
{"epoch": 11, "training_loss": 0.7022186183929443, "training_acc": 37.0, "val_loss": 0.7003520631790161, "val_acc": 48.0}
{"epoch": 12, "training_loss": 0.7226260375976562, "training_acc": 51.0, "val_loss": 0.7046430540084839, "val_acc": 48.0}
{"epoch": 13, "training_loss": 0.693294997215271, "training_acc": 53.0, "val_loss": 0.6937466406822205, "val_acc": 52.0}
{"epoch": 14, "training_loss": 0.7024581265449524, "training_acc": 47.0, "val_loss": 0.7034081315994263, "val_acc": 48.0}
{"epoch": 15, "training_loss": 0.7138035082817078, "training_acc": 45.0, "val_loss": 0.6936361813545227, "val_acc": 52.0}
{"epoch": 16, "training_loss": 0.6902243828773499, "training_acc": 57.0, "val_loss": 0.7088161039352417, "val_acc": 48.0}
{"epoch": 17, "training_loss": 0.7056643509864807, "training_acc": 51.0, "val_loss": 0.6958835911750794, "val_acc": 48.0}
{"epoch": 18, "training_loss": 0.7100265455245972, "training_acc": 45.0, "val_loss": 0.699694881439209, "val_acc": 52.0}
{"epoch": 19, "training_loss": 0.7105331993103028, "training_acc": 49.0, "val_loss": 0.6945601272583007, "val_acc": 48.0}
{"epoch": 20, "training_loss": 0.7131444764137268, "training_acc": 51.0, "val_loss": 0.7025683283805847, "val_acc": 48.0}
{"epoch": 21, "training_loss": 0.7216240787506103, "training_acc": 45.0, "val_loss": 0.7102196431159973, "val_acc": 52.0}
{"epoch": 22, "training_loss": 0.7200192880630493, "training_acc": 49.0, "val_loss": 0.6926218175888061, "val_acc": 52.0}
{"epoch": 23, "training_loss": 0.6982225894927978, "training_acc": 49.0, "val_loss": 0.6989597678184509, "val_acc": 48.0}
{"epoch": 24, "training_loss": 0.6975196528434754, "training_acc": 45.0, "val_loss": 0.6923693943023682, "val_acc": 52.0}
{"epoch": 25, "training_loss": 0.694578320980072, "training_acc": 49.0, "val_loss": 0.6934325909614563, "val_acc": 48.0}
{"epoch": 26, "training_loss": 0.6954280281066895, "training_acc": 51.0, "val_loss": 0.7011386609077453, "val_acc": 48.0}
{"epoch": 27, "training_loss": 0.6982574558258057, "training_acc": 51.0, "val_loss": 0.6975583553314209, "val_acc": 48.0}
{"epoch": 28, "training_loss": 0.6968595194816589, "training_acc": 51.0, "val_loss": 0.6976053547859192, "val_acc": 48.0}
{"epoch": 29, "training_loss": 0.7005919313430786, "training_acc": 41.0, "val_loss": 0.6946746897697449, "val_acc": 48.0}
{"epoch": 30, "training_loss": 0.7234309577941894, "training_acc": 51.0, "val_loss": 0.7173724293708801, "val_acc": 48.0}
{"epoch": 31, "training_loss": 0.7217713713645935, "training_acc": 43.0, "val_loss": 0.7012312245368958, "val_acc": 52.0}
{"epoch": 32, "training_loss": 0.7026167678833007, "training_acc": 47.0, "val_loss": 0.6988397240638733, "val_acc": 48.0}
{"epoch": 33, "training_loss": 0.7047452545166015, "training_acc": 51.0, "val_loss": 0.6949722027778625, "val_acc": 48.0}
{"epoch": 34, "training_loss": 0.6981370782852173, "training_acc": 47.0, "val_loss": 0.6971273422241211, "val_acc": 52.0}
{"epoch": 35, "training_loss": 0.7029422354698182, "training_acc": 49.0, "val_loss": 0.6928058552742005, "val_acc": 52.0}
{"epoch": 36, "training_loss": 0.6925372195243835, "training_acc": 51.0, "val_loss": 0.7013211798667908, "val_acc": 48.0}
{"epoch": 37, "training_loss": 0.697656192779541, "training_acc": 51.0, "val_loss": 0.6927591776847839, "val_acc": 52.0}
{"epoch": 38, "training_loss": 0.6991713547706604, "training_acc": 49.0, "val_loss": 0.6927032017707825, "val_acc": 52.0}
{"epoch": 39, "training_loss": 0.7053274583816528, "training_acc": 45.0, "val_loss": 0.6968828916549683, "val_acc": 48.0}
{"epoch": 40, "training_loss": 0.6957123041152954, "training_acc": 49.0, "val_loss": 0.6924459624290467, "val_acc": 52.0}
{"epoch": 41, "training_loss": 0.6952094030380249, "training_acc": 57.0, "val_loss": 0.710464084148407, "val_acc": 48.0}
{"epoch": 42, "training_loss": 0.710382788181305, "training_acc": 51.0, "val_loss": 0.700531702041626, "val_acc": 48.0}
{"epoch": 43, "training_loss": 0.6981840705871583, "training_acc": 47.0, "val_loss": 0.6931661939620972, "val_acc": 48.0}
