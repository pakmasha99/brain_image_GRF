"main_modify.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ADNI_sex --input_option yAware --learning_rate 1e-3 --batch_size 16 --weight_decay 1e-4 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 0.7018113613128663, "training_acc": 51.0, "val_loss": 0.7040372443199158, "val_acc": 48.0}
{"epoch": 1, "training_loss": 0.6968210482597351, "training_acc": 50.0, "val_loss": 0.6995078730583191, "val_acc": 48.0}
{"epoch": 2, "training_loss": 0.711824209690094, "training_acc": 42.0, "val_loss": 0.6970025634765625, "val_acc": 48.0}
{"epoch": 3, "training_loss": 0.7028995609283447, "training_acc": 48.0, "val_loss": 0.6940753579139709, "val_acc": 48.0}
{"epoch": 4, "training_loss": 0.7126241207122803, "training_acc": 50.0, "val_loss": 0.6948730254173279, "val_acc": 48.0}
{"epoch": 5, "training_loss": 0.7175061058998108, "training_acc": 50.0, "val_loss": 0.6933630681037903, "val_acc": 52.0}
{"epoch": 6, "training_loss": 0.7033877420425415, "training_acc": 46.0, "val_loss": 0.6968214654922485, "val_acc": 48.0}
{"epoch": 7, "training_loss": 0.6984875321388244, "training_acc": 52.0, "val_loss": 0.6956382966041565, "val_acc": 52.0}
{"epoch": 8, "training_loss": 0.6986154317855835, "training_acc": 48.0, "val_loss": 0.6952170276641846, "val_acc": 48.0}
{"epoch": 9, "training_loss": 0.7051887083053588, "training_acc": 50.0, "val_loss": 0.6926624345779419, "val_acc": 52.0}
{"epoch": 10, "training_loss": 0.717928855419159, "training_acc": 50.0, "val_loss": 0.6984108781814575, "val_acc": 52.0}
{"epoch": 11, "training_loss": 0.7158094501495361, "training_acc": 52.0, "val_loss": 0.7263641500473023, "val_acc": 48.0}
{"epoch": 12, "training_loss": 0.7041904497146606, "training_acc": 52.0, "val_loss": 0.6928939390182495, "val_acc": 52.0}
{"epoch": 13, "training_loss": 0.6993694353103638, "training_acc": 50.0, "val_loss": 0.6946222591400146, "val_acc": 48.0}
{"epoch": 14, "training_loss": 0.6956875896453858, "training_acc": 50.0, "val_loss": 0.7031653332710266, "val_acc": 48.0}
{"epoch": 15, "training_loss": 0.6997395944595337, "training_acc": 50.0, "val_loss": 0.6950265502929688, "val_acc": 48.0}
{"epoch": 16, "training_loss": 0.69463463306427, "training_acc": 49.0, "val_loss": 0.6936393094062805, "val_acc": 52.0}
{"epoch": 17, "training_loss": 0.7058963394165039, "training_acc": 50.0, "val_loss": 0.6938905072212219, "val_acc": 52.0}
{"epoch": 18, "training_loss": 0.7128679990768433, "training_acc": 44.0, "val_loss": 0.7173667979240418, "val_acc": 48.0}
{"epoch": 19, "training_loss": 0.6999930310249328, "training_acc": 48.0, "val_loss": 0.6957639718055725, "val_acc": 52.0}
{"epoch": 20, "training_loss": 0.6992132425308227, "training_acc": 50.0, "val_loss": 0.6936354398727417, "val_acc": 48.0}
{"epoch": 21, "training_loss": 0.6968844366073609, "training_acc": 41.0, "val_loss": 0.6922948908805847, "val_acc": 52.0}
{"epoch": 22, "training_loss": 0.7254400396347046, "training_acc": 50.0, "val_loss": 0.6934696936607361, "val_acc": 52.0}
{"epoch": 23, "training_loss": 0.6905572247505188, "training_acc": 52.0, "val_loss": 0.7301114177703858, "val_acc": 48.0}
{"epoch": 24, "training_loss": 0.7031637811660767, "training_acc": 48.0, "val_loss": 0.6924740624427795, "val_acc": 52.0}
{"epoch": 25, "training_loss": 0.6988641738891601, "training_acc": 42.0, "val_loss": 0.6931354093551636, "val_acc": 60.0}
{"epoch": 26, "training_loss": 0.6957645463943481, "training_acc": 46.0, "val_loss": 0.6931512761116028, "val_acc": 48.0}
{"epoch": 27, "training_loss": 0.695913758277893, "training_acc": 47.0, "val_loss": 0.6923809933662415, "val_acc": 52.0}
{"epoch": 28, "training_loss": 0.700557689666748, "training_acc": 46.0, "val_loss": 0.6971613240242004, "val_acc": 48.0}
{"epoch": 29, "training_loss": 0.6959176158905029, "training_acc": 48.0, "val_loss": 0.6926755833625794, "val_acc": 52.0}
{"epoch": 30, "training_loss": 0.6936208367347717, "training_acc": 50.0, "val_loss": 0.6940897083282471, "val_acc": 48.0}
{"epoch": 31, "training_loss": 0.7007838344573974, "training_acc": 50.0, "val_loss": 0.7027672410011292, "val_acc": 48.0}
{"epoch": 32, "training_loss": 0.7128631806373597, "training_acc": 50.0, "val_loss": 0.6932994508743286, "val_acc": 48.0}
{"epoch": 33, "training_loss": 0.7188963866233826, "training_acc": 48.0, "val_loss": 0.7095933270454406, "val_acc": 52.0}
{"epoch": 34, "training_loss": 0.7063898038864136, "training_acc": 50.0, "val_loss": 0.6961168646812439, "val_acc": 48.0}
{"epoch": 35, "training_loss": 0.699363443851471, "training_acc": 50.0, "val_loss": 0.7029480743408203, "val_acc": 48.0}
{"epoch": 36, "training_loss": 0.6996041870117188, "training_acc": 50.0, "val_loss": 0.6923766326904297, "val_acc": 52.0}
{"epoch": 37, "training_loss": 0.6960334277153015, "training_acc": 46.0, "val_loss": 0.6968539142608643, "val_acc": 48.0}
{"epoch": 38, "training_loss": 0.6947769451141358, "training_acc": 50.0, "val_loss": 0.6931029629707336, "val_acc": 52.0}
{"epoch": 39, "training_loss": 0.6942490792274475, "training_acc": 48.0, "val_loss": 0.6923882722854614, "val_acc": 52.0}
{"epoch": 40, "training_loss": 0.6963700842857361, "training_acc": 50.0, "val_loss": 0.6928490495681763, "val_acc": 52.0}
