"main_modify.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ADNI_sex --input_option yAware --learning_rate 1e-3 --batch_size 16 --weight_decay 1e-4 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 0.6999707794189454, "training_acc": 53.0, "val_loss": 0.694449577331543, "val_acc": 52.0}
{"epoch": 1, "training_loss": 0.711123275756836, "training_acc": 43.0, "val_loss": 0.692426106929779, "val_acc": 52.0}
{"epoch": 2, "training_loss": 0.7029361057281495, "training_acc": 45.0, "val_loss": 0.6924647450447082, "val_acc": 52.0}
{"epoch": 3, "training_loss": 0.6997374725341797, "training_acc": 49.0, "val_loss": 0.6935548090934753, "val_acc": 48.0}
{"epoch": 4, "training_loss": 0.7237614870071412, "training_acc": 51.0, "val_loss": 0.6961897778511047, "val_acc": 48.0}
{"epoch": 5, "training_loss": 0.7075972366333008, "training_acc": 51.0, "val_loss": 0.6959220409393311, "val_acc": 52.0}
{"epoch": 6, "training_loss": 0.7062819933891297, "training_acc": 45.0, "val_loss": 0.6994539713859558, "val_acc": 48.0}
{"epoch": 7, "training_loss": 0.6978048944473266, "training_acc": 51.0, "val_loss": 0.6936666893959046, "val_acc": 48.0}
{"epoch": 8, "training_loss": 0.7089337253570557, "training_acc": 45.0, "val_loss": 0.693221025466919, "val_acc": 52.0}
{"epoch": 9, "training_loss": 0.6953065276145936, "training_acc": 53.0, "val_loss": 0.701655216217041, "val_acc": 48.0}
{"epoch": 10, "training_loss": 0.7111101007461548, "training_acc": 51.0, "val_loss": 0.7063376045227051, "val_acc": 48.0}
{"epoch": 11, "training_loss": 0.6966238832473755, "training_acc": 51.0, "val_loss": 0.6961700558662415, "val_acc": 52.0}
{"epoch": 12, "training_loss": 0.7065395498275757, "training_acc": 49.0, "val_loss": 0.697458279132843, "val_acc": 48.0}
{"epoch": 13, "training_loss": 0.7203367948532104, "training_acc": 51.0, "val_loss": 0.7108270072937012, "val_acc": 48.0}
{"epoch": 14, "training_loss": 0.6865065717697143, "training_acc": 55.0, "val_loss": 0.6983936643600464, "val_acc": 52.0}
{"epoch": 15, "training_loss": 0.7098769950866699, "training_acc": 45.0, "val_loss": 0.6931237030029297, "val_acc": 52.0}
{"epoch": 16, "training_loss": 0.7001025223731995, "training_acc": 49.0, "val_loss": 0.6928407502174377, "val_acc": 52.0}
{"epoch": 17, "training_loss": 0.6948910546302796, "training_acc": 53.0, "val_loss": 0.7180860066413879, "val_acc": 48.0}
{"epoch": 18, "training_loss": 0.7100542116165162, "training_acc": 51.0, "val_loss": 0.6991740393638611, "val_acc": 48.0}
{"epoch": 19, "training_loss": 0.696300368309021, "training_acc": 53.0, "val_loss": 0.6922712445259094, "val_acc": 52.0}
{"epoch": 20, "training_loss": 0.698428966999054, "training_acc": 49.0, "val_loss": 0.6921564602851867, "val_acc": 52.0}
{"epoch": 21, "training_loss": 0.7071732139587402, "training_acc": 47.0, "val_loss": 0.7102189564704895, "val_acc": 48.0}
{"epoch": 22, "training_loss": 0.7065733981132507, "training_acc": 43.0, "val_loss": 0.6924745154380798, "val_acc": 52.0}
{"epoch": 23, "training_loss": 0.6899870371818543, "training_acc": 53.0, "val_loss": 0.7031079149246215, "val_acc": 48.0}
{"epoch": 24, "training_loss": 0.6961605501174927, "training_acc": 49.0, "val_loss": 0.6931334900856018, "val_acc": 52.0}
{"epoch": 25, "training_loss": 0.6945799112319946, "training_acc": 44.0, "val_loss": 0.7005992102622985, "val_acc": 48.0}
{"epoch": 26, "training_loss": 0.7030219078063965, "training_acc": 51.0, "val_loss": 0.7004852342605591, "val_acc": 48.0}
{"epoch": 27, "training_loss": 0.6962009143829345, "training_acc": 51.0, "val_loss": 0.6967962217330933, "val_acc": 48.0}
{"epoch": 28, "training_loss": 0.6996088600158692, "training_acc": 43.0, "val_loss": 0.6923677325248718, "val_acc": 52.0}
{"epoch": 29, "training_loss": 0.6977530026435852, "training_acc": 47.0, "val_loss": 0.6944686317443848, "val_acc": 48.0}
{"epoch": 30, "training_loss": 0.7069232797622681, "training_acc": 47.0, "val_loss": 0.6974260258674622, "val_acc": 52.0}
{"epoch": 31, "training_loss": 0.7128229403495788, "training_acc": 39.0, "val_loss": 0.6936805272102355, "val_acc": 48.0}
{"epoch": 32, "training_loss": 0.7022524762153626, "training_acc": 51.0, "val_loss": 0.6960485339164734, "val_acc": 52.0}
{"epoch": 33, "training_loss": 0.7009845495223999, "training_acc": 49.0, "val_loss": 0.695911374092102, "val_acc": 48.0}
{"epoch": 34, "training_loss": 0.6999472713470459, "training_acc": 51.0, "val_loss": 0.7102842664718628, "val_acc": 48.0}
{"epoch": 35, "training_loss": 0.702078309059143, "training_acc": 51.0, "val_loss": 0.6957911610603332, "val_acc": 48.0}
{"epoch": 36, "training_loss": 0.6940839982032776, "training_acc": 51.0, "val_loss": 0.694693832397461, "val_acc": 48.0}
{"epoch": 37, "training_loss": 0.6970103502273559, "training_acc": 51.0, "val_loss": 0.6964231991767883, "val_acc": 48.0}
{"epoch": 38, "training_loss": 0.7045468711853027, "training_acc": 51.0, "val_loss": 0.698518967628479, "val_acc": 48.0}
{"epoch": 39, "training_loss": 0.6963848876953125, "training_acc": 47.0, "val_loss": 0.6938585495948791, "val_acc": 48.0}
