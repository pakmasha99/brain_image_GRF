"main_modify.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 4 --task ADNI_sex --input_option yAware --learning_rate 1e-3 --batch_size 16 --weight_decay 1e-4 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 0.7047615790367127, "training_acc": 49.0, "val_loss": 0.7032996869087219, "val_acc": 52.0}
{"epoch": 1, "training_loss": 0.7175482559204102, "training_acc": 47.0, "val_loss": 0.6963129925727845, "val_acc": 48.0}
{"epoch": 2, "training_loss": 0.6978945970535279, "training_acc": 45.0, "val_loss": 0.7015161085128784, "val_acc": 48.0}
{"epoch": 3, "training_loss": 0.6997397041320801, "training_acc": 51.0, "val_loss": 0.6990677452087403, "val_acc": 48.0}
{"epoch": 4, "training_loss": 0.7224879956245422, "training_acc": 49.0, "val_loss": 0.6923984098434448, "val_acc": 52.0}
{"epoch": 5, "training_loss": 0.6996151304244995, "training_acc": 47.0, "val_loss": 0.6924585270881652, "val_acc": 52.0}
{"epoch": 6, "training_loss": 0.7070574331283569, "training_acc": 47.0, "val_loss": 0.693938159942627, "val_acc": 48.0}
{"epoch": 7, "training_loss": 0.6971966338157654, "training_acc": 51.0, "val_loss": 0.6946606040000916, "val_acc": 48.0}
{"epoch": 8, "training_loss": 0.7012669944763184, "training_acc": 47.0, "val_loss": 0.6926129627227783, "val_acc": 52.0}
{"epoch": 9, "training_loss": 0.7108948469161988, "training_acc": 43.0, "val_loss": 0.7056280064582825, "val_acc": 48.0}
{"epoch": 10, "training_loss": 0.7030883836746216, "training_acc": 51.0, "val_loss": 0.6937159371376037, "val_acc": 48.0}
{"epoch": 11, "training_loss": 0.6929041981697083, "training_acc": 53.0, "val_loss": 0.6929202437400818, "val_acc": 52.0}
{"epoch": 12, "training_loss": 0.6960514736175537, "training_acc": 49.0, "val_loss": 0.7076688480377197, "val_acc": 48.0}
{"epoch": 13, "training_loss": 0.7240551662445068, "training_acc": 51.0, "val_loss": 0.7245646023750305, "val_acc": 48.0}
{"epoch": 14, "training_loss": 0.7084935903549194, "training_acc": 51.0, "val_loss": 0.6942760848999023, "val_acc": 48.0}
{"epoch": 15, "training_loss": 0.7166398525238037, "training_acc": 41.0, "val_loss": 0.6933143258094787, "val_acc": 48.0}
{"epoch": 16, "training_loss": 0.6950180625915527, "training_acc": 51.0, "val_loss": 0.7047804975509644, "val_acc": 48.0}
{"epoch": 17, "training_loss": 0.703484697341919, "training_acc": 51.0, "val_loss": 0.6960624027252197, "val_acc": 48.0}
{"epoch": 18, "training_loss": 0.6952370858192444, "training_acc": 51.0, "val_loss": 0.6929594445228576, "val_acc": 52.0}
{"epoch": 19, "training_loss": 0.7029856491088867, "training_acc": 49.0, "val_loss": 0.6928137612342834, "val_acc": 52.0}
{"epoch": 20, "training_loss": 0.6947491645812989, "training_acc": 49.0, "val_loss": 0.7013874793052673, "val_acc": 48.0}
{"epoch": 21, "training_loss": 0.7010668587684631, "training_acc": 51.0, "val_loss": 0.7028765106201171, "val_acc": 48.0}
{"epoch": 22, "training_loss": 0.6994842910766601, "training_acc": 51.0, "val_loss": 0.6959815287590027, "val_acc": 48.0}
{"epoch": 23, "training_loss": 0.6991294074058533, "training_acc": 51.0, "val_loss": 0.692374336719513, "val_acc": 52.0}
{"epoch": 24, "training_loss": 0.6975110244750976, "training_acc": 49.0, "val_loss": 0.6928719258308411, "val_acc": 52.0}
{"epoch": 25, "training_loss": 0.6979504489898681, "training_acc": 49.0, "val_loss": 0.6921145963668823, "val_acc": 52.0}
{"epoch": 26, "training_loss": 0.6998573994636536, "training_acc": 49.0, "val_loss": 0.6934369564056396, "val_acc": 48.0}
{"epoch": 27, "training_loss": 0.7025380778312683, "training_acc": 51.0, "val_loss": 0.6997685194015503, "val_acc": 48.0}
{"epoch": 28, "training_loss": 0.7078619313240051, "training_acc": 47.0, "val_loss": 0.69729731798172, "val_acc": 52.0}
{"epoch": 29, "training_loss": 0.7019260692596435, "training_acc": 49.0, "val_loss": 0.7004370403289795, "val_acc": 48.0}
{"epoch": 30, "training_loss": 0.7121420955657959, "training_acc": 51.0, "val_loss": 0.7120160245895386, "val_acc": 48.0}
{"epoch": 31, "training_loss": 0.7094520616531372, "training_acc": 47.0, "val_loss": 0.6926546168327331, "val_acc": 52.0}
{"epoch": 32, "training_loss": 0.7206808114051819, "training_acc": 45.0, "val_loss": 0.6968440723419189, "val_acc": 48.0}
{"epoch": 33, "training_loss": 0.7341454315185547, "training_acc": 45.0, "val_loss": 0.6934679365158081, "val_acc": 52.0}
{"epoch": 34, "training_loss": 0.7150141191482544, "training_acc": 43.0, "val_loss": 0.7212895441055298, "val_acc": 48.0}
{"epoch": 35, "training_loss": 0.7049289751052856, "training_acc": 51.0, "val_loss": 0.6955994081497192, "val_acc": 48.0}
{"epoch": 36, "training_loss": 0.6990312767028809, "training_acc": 49.0, "val_loss": 0.6925762629508972, "val_acc": 52.0}
{"epoch": 37, "training_loss": 0.6949037885665894, "training_acc": 53.0, "val_loss": 0.7210656523704528, "val_acc": 48.0}
{"epoch": 38, "training_loss": 0.7077147674560547, "training_acc": 51.0, "val_loss": 0.6924237108230591, "val_acc": 52.0}
{"epoch": 39, "training_loss": 0.7132304716110229, "training_acc": 49.0, "val_loss": 0.6928651762008667, "val_acc": 52.0}
{"epoch": 40, "training_loss": 0.6937150096893311, "training_acc": 51.0, "val_loss": 0.6971311950683594, "val_acc": 48.0}
{"epoch": 41, "training_loss": 0.6989335250854493, "training_acc": 51.0, "val_loss": 0.7090687108039856, "val_acc": 48.0}
{"epoch": 42, "training_loss": 0.7028612518310546, "training_acc": 51.0, "val_loss": 0.6951781368255615, "val_acc": 48.0}
{"epoch": 43, "training_loss": 0.6936878871917724, "training_acc": 51.0, "val_loss": 0.6954967951774598, "val_acc": 48.0}
{"epoch": 44, "training_loss": 0.6979008865356445, "training_acc": 43.0, "val_loss": 0.6932903027534485, "val_acc": 48.0}
