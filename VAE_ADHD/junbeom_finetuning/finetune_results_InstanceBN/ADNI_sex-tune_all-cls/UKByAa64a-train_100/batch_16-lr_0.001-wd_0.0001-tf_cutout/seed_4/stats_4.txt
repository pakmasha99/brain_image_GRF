"main_modify.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 4 --task ADNI_sex --input_option yAware --learning_rate 1e-3 --batch_size 16 --weight_decay 1e-4 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 0.6988555479049683, "training_acc": 54.0, "val_loss": 0.693607575893402, "val_acc": 48.0}
{"epoch": 1, "training_loss": 0.7111192274093628, "training_acc": 50.0, "val_loss": 0.6982984924316407, "val_acc": 48.0}
{"epoch": 2, "training_loss": 0.7032109880447388, "training_acc": 48.0, "val_loss": 0.6934400129318238, "val_acc": 48.0}
{"epoch": 3, "training_loss": 0.7064535307884217, "training_acc": 50.0, "val_loss": 0.7006966805458069, "val_acc": 48.0}
{"epoch": 4, "training_loss": 0.7058144855499268, "training_acc": 50.0, "val_loss": 0.6929053544998169, "val_acc": 52.0}
{"epoch": 5, "training_loss": 0.7007683420181274, "training_acc": 50.0, "val_loss": 0.6956368184089661, "val_acc": 52.0}
{"epoch": 6, "training_loss": 0.6994547414779663, "training_acc": 46.0, "val_loss": 0.6948878788948059, "val_acc": 48.0}
{"epoch": 7, "training_loss": 0.703340675830841, "training_acc": 50.0, "val_loss": 0.6947662210464478, "val_acc": 52.0}
{"epoch": 8, "training_loss": 0.6988270854949952, "training_acc": 48.0, "val_loss": 0.6984174776077271, "val_acc": 48.0}
{"epoch": 9, "training_loss": 0.7003334712982178, "training_acc": 50.0, "val_loss": 0.6923718786239624, "val_acc": 52.0}
{"epoch": 10, "training_loss": 0.711925163269043, "training_acc": 50.0, "val_loss": 0.693403594493866, "val_acc": 52.0}
{"epoch": 11, "training_loss": 0.6902520513534546, "training_acc": 56.0, "val_loss": 0.7102744269371033, "val_acc": 48.0}
{"epoch": 12, "training_loss": 0.7045101070404053, "training_acc": 50.0, "val_loss": 0.6987071561813355, "val_acc": 48.0}
{"epoch": 13, "training_loss": 0.6994839572906494, "training_acc": 48.0, "val_loss": 0.6952180051803589, "val_acc": 52.0}
{"epoch": 14, "training_loss": 0.7071260499954224, "training_acc": 50.0, "val_loss": 0.6926619791984558, "val_acc": 52.0}
{"epoch": 15, "training_loss": 0.6960935640335083, "training_acc": 50.0, "val_loss": 0.6983663034439087, "val_acc": 48.0}
{"epoch": 16, "training_loss": 0.6913586330413818, "training_acc": 52.0, "val_loss": 0.6930109024047851, "val_acc": 52.0}
{"epoch": 17, "training_loss": 0.7017436981201172, "training_acc": 42.0, "val_loss": 0.6923870301246643, "val_acc": 52.0}
{"epoch": 18, "training_loss": 0.6976870894432068, "training_acc": 50.0, "val_loss": 0.6935042548179626, "val_acc": 52.0}
{"epoch": 19, "training_loss": 0.7004045987129212, "training_acc": 48.0, "val_loss": 0.6925600051879883, "val_acc": 52.0}
{"epoch": 20, "training_loss": 0.6992630124092102, "training_acc": 50.0, "val_loss": 0.6924109816551208, "val_acc": 52.0}
{"epoch": 21, "training_loss": 0.7052468347549439, "training_acc": 44.0, "val_loss": 0.695571985244751, "val_acc": 48.0}
{"epoch": 22, "training_loss": 0.6994183540344239, "training_acc": 48.0, "val_loss": 0.6923518013954163, "val_acc": 52.0}
{"epoch": 23, "training_loss": 0.6909773015975952, "training_acc": 52.0, "val_loss": 0.7072010564804078, "val_acc": 48.0}
{"epoch": 24, "training_loss": 0.7289785385131836, "training_acc": 50.0, "val_loss": 0.708507957458496, "val_acc": 48.0}
{"epoch": 25, "training_loss": 0.6921897721290589, "training_acc": 48.0, "val_loss": 0.6989978766441345, "val_acc": 52.0}
{"epoch": 26, "training_loss": 0.7104665088653564, "training_acc": 50.0, "val_loss": 0.6943837308883667, "val_acc": 48.0}
{"epoch": 27, "training_loss": 0.6950356674194336, "training_acc": 50.0, "val_loss": 0.7010221052169799, "val_acc": 48.0}
{"epoch": 28, "training_loss": 0.7117880749702453, "training_acc": 50.0, "val_loss": 0.7075595426559448, "val_acc": 48.0}
{"epoch": 29, "training_loss": 0.6972766280174255, "training_acc": 50.0, "val_loss": 0.6923887181282044, "val_acc": 52.0}
{"epoch": 30, "training_loss": 0.6946247482299804, "training_acc": 50.0, "val_loss": 0.6950078129768371, "val_acc": 48.0}
{"epoch": 31, "training_loss": 0.7118480968475341, "training_acc": 50.0, "val_loss": 0.70344886302948, "val_acc": 48.0}
{"epoch": 32, "training_loss": 0.6916913247108459, "training_acc": 54.0, "val_loss": 0.6944195985794067, "val_acc": 52.0}
{"epoch": 33, "training_loss": 0.7009523439407349, "training_acc": 50.0, "val_loss": 0.6925497007369995, "val_acc": 52.0}
{"epoch": 34, "training_loss": 0.6966545367240906, "training_acc": 50.0, "val_loss": 0.6935075616836548, "val_acc": 48.0}
{"epoch": 35, "training_loss": 0.6940342950820922, "training_acc": 50.0, "val_loss": 0.696644868850708, "val_acc": 48.0}
{"epoch": 36, "training_loss": 0.6968147921562194, "training_acc": 48.0, "val_loss": 0.693374125957489, "val_acc": 48.0}
{"epoch": 37, "training_loss": 0.6963745212554932, "training_acc": 40.0, "val_loss": 0.6942706632614136, "val_acc": 48.0}
{"epoch": 38, "training_loss": 0.6978330564498901, "training_acc": 50.0, "val_loss": 0.693164963722229, "val_acc": 48.0}
{"epoch": 39, "training_loss": 0.7049115633964539, "training_acc": 48.0, "val_loss": 0.6940133881568908, "val_acc": 52.0}
{"epoch": 40, "training_loss": 0.6873642516136169, "training_acc": 54.0, "val_loss": 0.7122593402862549, "val_acc": 48.0}
{"epoch": 41, "training_loss": 0.7175517845153808, "training_acc": 50.0, "val_loss": 0.7122479963302613, "val_acc": 48.0}
