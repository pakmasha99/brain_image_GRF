"main_modify.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 4 --task ADNI_sex --input_option yAware --learning_rate 1e-3 --batch_size 16 --weight_decay 1e-4 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 0.7535476994514465, "training_acc": 35.0, "val_loss": 0.6982016491889954, "val_acc": 48.0}
{"epoch": 1, "training_loss": 0.7088407373428345, "training_acc": 49.0, "val_loss": 0.6979045963287354, "val_acc": 48.0}
{"epoch": 2, "training_loss": 0.703152232170105, "training_acc": 51.0, "val_loss": 0.6923781228065491, "val_acc": 52.0}
{"epoch": 3, "training_loss": 0.710195209980011, "training_acc": 49.0, "val_loss": 0.6971713209152222, "val_acc": 48.0}
{"epoch": 4, "training_loss": 0.6946105742454529, "training_acc": 51.0, "val_loss": 0.7135709857940674, "val_acc": 48.0}
{"epoch": 5, "training_loss": 0.711877989768982, "training_acc": 51.0, "val_loss": 0.6997725391387939, "val_acc": 48.0}
{"epoch": 6, "training_loss": 0.6948969268798828, "training_acc": 51.0, "val_loss": 0.6928120446205139, "val_acc": 52.0}
{"epoch": 7, "training_loss": 0.693937611579895, "training_acc": 49.0, "val_loss": 0.6933440113067627, "val_acc": 52.0}
{"epoch": 8, "training_loss": 0.7040743207931519, "training_acc": 49.0, "val_loss": 0.6923605442047119, "val_acc": 52.0}
{"epoch": 9, "training_loss": 0.6948059225082397, "training_acc": 49.0, "val_loss": 0.6926129841804505, "val_acc": 52.0}
{"epoch": 10, "training_loss": 0.696817741394043, "training_acc": 43.0, "val_loss": 0.6978213119506836, "val_acc": 48.0}
{"epoch": 11, "training_loss": 0.7028692483901977, "training_acc": 51.0, "val_loss": 0.6942234587669373, "val_acc": 48.0}
{"epoch": 12, "training_loss": 0.7029174041748046, "training_acc": 51.0, "val_loss": 0.7025185179710388, "val_acc": 52.0}
{"epoch": 13, "training_loss": 0.7022864198684693, "training_acc": 49.0, "val_loss": 0.7006347727775574, "val_acc": 48.0}
{"epoch": 14, "training_loss": 0.7093557524681091, "training_acc": 51.0, "val_loss": 0.6975903272628784, "val_acc": 48.0}
{"epoch": 15, "training_loss": 0.7063469552993774, "training_acc": 37.0, "val_loss": 0.6951508259773255, "val_acc": 48.0}
{"epoch": 16, "training_loss": 0.7014496564865113, "training_acc": 51.0, "val_loss": 0.7028071546554565, "val_acc": 48.0}
{"epoch": 17, "training_loss": 0.6950179219245911, "training_acc": 51.0, "val_loss": 0.6931211400032044, "val_acc": 52.0}
{"epoch": 18, "training_loss": 0.693106677532196, "training_acc": 49.0, "val_loss": 0.6949340629577637, "val_acc": 52.0}
{"epoch": 19, "training_loss": 0.6979472041130066, "training_acc": 49.0, "val_loss": 0.6940085577964783, "val_acc": 48.0}
{"epoch": 20, "training_loss": 0.6998057746887207, "training_acc": 51.0, "val_loss": 0.6943615555763245, "val_acc": 48.0}
{"epoch": 21, "training_loss": 0.6939712285995483, "training_acc": 51.0, "val_loss": 0.6926256513595581, "val_acc": 52.0}
{"epoch": 22, "training_loss": 0.6969375610351562, "training_acc": 51.0, "val_loss": 0.7044838285446167, "val_acc": 48.0}
{"epoch": 23, "training_loss": 0.694911093711853, "training_acc": 51.0, "val_loss": 0.6924293708801269, "val_acc": 52.0}
{"epoch": 24, "training_loss": 0.7019574618339539, "training_acc": 45.0, "val_loss": 0.6923556947708129, "val_acc": 52.0}
{"epoch": 25, "training_loss": 0.7488471984863281, "training_acc": 49.0, "val_loss": 0.6986944174766541, "val_acc": 52.0}
{"epoch": 26, "training_loss": 0.7046385431289672, "training_acc": 49.0, "val_loss": 0.699505693912506, "val_acc": 48.0}
{"epoch": 27, "training_loss": 0.7002879619598389, "training_acc": 51.0, "val_loss": 0.6983984065055847, "val_acc": 48.0}
{"epoch": 28, "training_loss": 0.6973216962814331, "training_acc": 49.0, "val_loss": 0.6938008952140808, "val_acc": 48.0}
{"epoch": 29, "training_loss": 0.7007896566390991, "training_acc": 51.0, "val_loss": 0.6941895413398743, "val_acc": 48.0}
{"epoch": 30, "training_loss": 0.6938965153694153, "training_acc": 51.0, "val_loss": 0.6942813158035278, "val_acc": 52.0}
{"epoch": 31, "training_loss": 0.7098642492294311, "training_acc": 49.0, "val_loss": 0.6948255634307862, "val_acc": 52.0}
{"epoch": 32, "training_loss": 0.6945169687271118, "training_acc": 51.0, "val_loss": 0.7075674748420715, "val_acc": 48.0}
{"epoch": 33, "training_loss": 0.6999982452392578, "training_acc": 51.0, "val_loss": 0.6965898156166077, "val_acc": 48.0}
{"epoch": 34, "training_loss": 0.7055509424209595, "training_acc": 41.0, "val_loss": 0.6967752170562744, "val_acc": 48.0}
{"epoch": 35, "training_loss": 0.699981803894043, "training_acc": 51.0, "val_loss": 0.7129097414016724, "val_acc": 48.0}
{"epoch": 36, "training_loss": 0.6941175508499146, "training_acc": 53.0, "val_loss": 0.6932596898078919, "val_acc": 52.0}
{"epoch": 37, "training_loss": 0.7066382026672363, "training_acc": 49.0, "val_loss": 0.6935769438743591, "val_acc": 52.0}
{"epoch": 38, "training_loss": 0.714590561389923, "training_acc": 49.0, "val_loss": 0.6927037024497986, "val_acc": 52.0}
{"epoch": 39, "training_loss": 0.6875273370742798, "training_acc": 57.0, "val_loss": 0.7251411151885986, "val_acc": 48.0}
{"epoch": 40, "training_loss": 0.7107626438140869, "training_acc": 51.0, "val_loss": 0.6969633102416992, "val_acc": 48.0}
{"epoch": 41, "training_loss": 0.6981820106506348, "training_acc": 51.0, "val_loss": 0.6928339552879333, "val_acc": 52.0}
{"epoch": 42, "training_loss": 0.6951001262664795, "training_acc": 49.0, "val_loss": 0.6930360531806946, "val_acc": 52.0}
{"epoch": 43, "training_loss": 0.7079462981224061, "training_acc": 43.0, "val_loss": 0.7026795530319214, "val_acc": 48.0}
