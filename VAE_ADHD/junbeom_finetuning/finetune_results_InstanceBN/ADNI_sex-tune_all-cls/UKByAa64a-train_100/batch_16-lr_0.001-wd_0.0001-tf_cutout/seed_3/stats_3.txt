"main_modify.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 3 --task ADNI_sex --input_option yAware --learning_rate 1e-3 --batch_size 16 --weight_decay 1e-4 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 0.7491125893592835, "training_acc": 43.0, "val_loss": 0.6934385299682617, "val_acc": 48.0}
{"epoch": 1, "training_loss": 0.7097242450714112, "training_acc": 47.0, "val_loss": 0.6923733139038086, "val_acc": 52.0}
{"epoch": 2, "training_loss": 0.7018603610992432, "training_acc": 49.0, "val_loss": 0.7005637764930726, "val_acc": 48.0}
{"epoch": 3, "training_loss": 0.7169356036186219, "training_acc": 47.0, "val_loss": 0.6955503821372986, "val_acc": 48.0}
{"epoch": 4, "training_loss": 0.6955132126808167, "training_acc": 51.0, "val_loss": 0.7030546879768371, "val_acc": 48.0}
{"epoch": 5, "training_loss": 0.7049965977668762, "training_acc": 51.0, "val_loss": 0.6940264630317688, "val_acc": 48.0}
{"epoch": 6, "training_loss": 0.7045891427993775, "training_acc": 49.0, "val_loss": 0.6926400661468506, "val_acc": 52.0}
{"epoch": 7, "training_loss": 0.6905927062034607, "training_acc": 55.0, "val_loss": 0.7077291560173035, "val_acc": 48.0}
{"epoch": 8, "training_loss": 0.7138402891159058, "training_acc": 41.0, "val_loss": 0.6923522996902466, "val_acc": 52.0}
{"epoch": 9, "training_loss": 0.6956335306167603, "training_acc": 49.0, "val_loss": 0.6968267035484313, "val_acc": 48.0}
{"epoch": 10, "training_loss": 0.6916332817077637, "training_acc": 51.0, "val_loss": 0.6925317311286926, "val_acc": 52.0}
{"epoch": 11, "training_loss": 0.7020195364952088, "training_acc": 41.0, "val_loss": 0.6923626089096069, "val_acc": 52.0}
{"epoch": 12, "training_loss": 0.7181817746162414, "training_acc": 49.0, "val_loss": 0.6924574398994445, "val_acc": 52.0}
{"epoch": 13, "training_loss": 0.6893174982070923, "training_acc": 55.0, "val_loss": 0.7146334767341613, "val_acc": 48.0}
{"epoch": 14, "training_loss": 0.7016966676712036, "training_acc": 47.0, "val_loss": 0.6937644028663635, "val_acc": 52.0}
{"epoch": 15, "training_loss": 0.7041725111007691, "training_acc": 49.0, "val_loss": 0.6931332516670227, "val_acc": 56.0}
{"epoch": 16, "training_loss": 0.69578537940979, "training_acc": 49.0, "val_loss": 0.697498733997345, "val_acc": 48.0}
{"epoch": 17, "training_loss": 0.7268113946914673, "training_acc": 51.0, "val_loss": 0.7283709716796875, "val_acc": 48.0}
{"epoch": 18, "training_loss": 0.7042799091339111, "training_acc": 49.0, "val_loss": 0.6977156138420105, "val_acc": 52.0}
{"epoch": 19, "training_loss": 0.7065994310379028, "training_acc": 49.0, "val_loss": 0.6928173995018005, "val_acc": 52.0}
{"epoch": 20, "training_loss": 0.7101141953468323, "training_acc": 43.0, "val_loss": 0.705909080505371, "val_acc": 48.0}
{"epoch": 21, "training_loss": 0.6973487949371338, "training_acc": 51.0, "val_loss": 0.6923465800285339, "val_acc": 52.0}
{"epoch": 22, "training_loss": 0.7063942790031433, "training_acc": 49.0, "val_loss": 0.6936480379104615, "val_acc": 52.0}
{"epoch": 23, "training_loss": 0.6913627290725708, "training_acc": 53.0, "val_loss": 0.7019169235229492, "val_acc": 48.0}
{"epoch": 24, "training_loss": 0.7090620088577271, "training_acc": 51.0, "val_loss": 0.6981226849555969, "val_acc": 48.0}
{"epoch": 25, "training_loss": 0.7275336098670959, "training_acc": 49.0, "val_loss": 0.6975242519378662, "val_acc": 52.0}
{"epoch": 26, "training_loss": 0.6996537017822265, "training_acc": 49.0, "val_loss": 0.7347195172309875, "val_acc": 48.0}
{"epoch": 27, "training_loss": 0.7226593613624572, "training_acc": 51.0, "val_loss": 0.6978461527824402, "val_acc": 48.0}
{"epoch": 28, "training_loss": 0.6993843579292297, "training_acc": 51.0, "val_loss": 0.7003534388542175, "val_acc": 48.0}
{"epoch": 29, "training_loss": 0.705797278881073, "training_acc": 45.0, "val_loss": 0.6923817729949951, "val_acc": 52.0}
{"epoch": 30, "training_loss": 0.693875961303711, "training_acc": 51.0, "val_loss": 0.6986420011520386, "val_acc": 48.0}
{"epoch": 31, "training_loss": 0.6958770656585693, "training_acc": 51.0, "val_loss": 0.6955479836463928, "val_acc": 48.0}
{"epoch": 32, "training_loss": 0.6938277554512023, "training_acc": 49.0, "val_loss": 0.6924347615242005, "val_acc": 52.0}
{"epoch": 33, "training_loss": 0.6972245168685913, "training_acc": 45.0, "val_loss": 0.692356333732605, "val_acc": 52.0}
{"epoch": 34, "training_loss": 0.7120206284523011, "training_acc": 49.0, "val_loss": 0.6949387669563294, "val_acc": 52.0}
{"epoch": 35, "training_loss": 0.7081370496749878, "training_acc": 43.0, "val_loss": 0.7002107763290405, "val_acc": 48.0}
{"epoch": 36, "training_loss": 0.6937203598022461, "training_acc": 51.0, "val_loss": 0.6924083256721496, "val_acc": 52.0}
{"epoch": 37, "training_loss": 0.6945176982879638, "training_acc": 49.0, "val_loss": 0.6930201292037964, "val_acc": 52.0}
{"epoch": 38, "training_loss": 0.7099143671989441, "training_acc": 49.0, "val_loss": 0.6926447916030883, "val_acc": 52.0}
{"epoch": 39, "training_loss": 0.7011924338340759, "training_acc": 51.0, "val_loss": 0.7114733123779297, "val_acc": 48.0}
{"epoch": 40, "training_loss": 0.6916315507888794, "training_acc": 51.0, "val_loss": 0.6929625415802002, "val_acc": 52.0}
