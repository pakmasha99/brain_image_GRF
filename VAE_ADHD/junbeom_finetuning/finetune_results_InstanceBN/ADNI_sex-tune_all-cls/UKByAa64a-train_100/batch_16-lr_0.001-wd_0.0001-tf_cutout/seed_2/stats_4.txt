"main_modify.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 2 --task ADNI_sex --input_option yAware --learning_rate 1e-3 --batch_size 16 --weight_decay 1e-4 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 0.718948450088501, "training_acc": 44.0, "val_loss": 0.6995764875411987, "val_acc": 48.0}
{"epoch": 1, "training_loss": 0.7018425631523132, "training_acc": 51.0, "val_loss": 0.7180761432647705, "val_acc": 48.0}
{"epoch": 2, "training_loss": 0.702662148475647, "training_acc": 47.0, "val_loss": 0.6930088829994202, "val_acc": 52.0}
{"epoch": 3, "training_loss": 0.7163565063476562, "training_acc": 45.0, "val_loss": 0.6938033294677735, "val_acc": 52.0}
{"epoch": 4, "training_loss": 0.7187732315063476, "training_acc": 49.0, "val_loss": 0.6923702335357667, "val_acc": 52.0}
{"epoch": 5, "training_loss": 0.7125449419021607, "training_acc": 49.0, "val_loss": 0.6980415272712708, "val_acc": 48.0}
{"epoch": 6, "training_loss": 0.6929328107833862, "training_acc": 51.0, "val_loss": 0.6924028491973877, "val_acc": 52.0}
{"epoch": 7, "training_loss": 0.6990153813362121, "training_acc": 45.0, "val_loss": 0.6924587249755859, "val_acc": 52.0}
{"epoch": 8, "training_loss": 0.6991460180282593, "training_acc": 41.0, "val_loss": 0.6927367734909058, "val_acc": 52.0}
{"epoch": 9, "training_loss": 0.7187862086296082, "training_acc": 49.0, "val_loss": 0.6972705054283143, "val_acc": 52.0}
{"epoch": 10, "training_loss": 0.7015323877334595, "training_acc": 47.0, "val_loss": 0.6966407442092896, "val_acc": 48.0}
{"epoch": 11, "training_loss": 0.6949697399139404, "training_acc": 49.0, "val_loss": 0.6927944922447205, "val_acc": 52.0}
{"epoch": 12, "training_loss": 0.6939638614654541, "training_acc": 49.0, "val_loss": 0.6929096293449402, "val_acc": 52.0}
{"epoch": 13, "training_loss": 0.7021195006370544, "training_acc": 39.0, "val_loss": 0.6924465894699097, "val_acc": 52.0}
{"epoch": 14, "training_loss": 0.705000696182251, "training_acc": 49.0, "val_loss": 0.6934928917884826, "val_acc": 52.0}
{"epoch": 15, "training_loss": 0.6972128582000733, "training_acc": 47.0, "val_loss": 0.6968835759162902, "val_acc": 48.0}
{"epoch": 16, "training_loss": 0.7007082772254943, "training_acc": 51.0, "val_loss": 0.6983924150466919, "val_acc": 48.0}
{"epoch": 17, "training_loss": 0.7070728969573975, "training_acc": 45.0, "val_loss": 0.6954838538169861, "val_acc": 52.0}
{"epoch": 18, "training_loss": 0.6953675842285156, "training_acc": 49.0, "val_loss": 0.7038287568092346, "val_acc": 48.0}
{"epoch": 19, "training_loss": 0.6997578072547913, "training_acc": 51.0, "val_loss": 0.699318699836731, "val_acc": 48.0}
{"epoch": 20, "training_loss": 0.7076726388931275, "training_acc": 43.0, "val_loss": 0.692359733581543, "val_acc": 52.0}
{"epoch": 21, "training_loss": 0.6999433588981628, "training_acc": 49.0, "val_loss": 0.711594443321228, "val_acc": 48.0}
{"epoch": 22, "training_loss": 0.6982869338989258, "training_acc": 51.0, "val_loss": 0.6923476099967957, "val_acc": 52.0}
{"epoch": 23, "training_loss": 0.7008880472183228, "training_acc": 49.0, "val_loss": 0.6936002469062805, "val_acc": 52.0}
{"epoch": 24, "training_loss": 0.6983836269378663, "training_acc": 49.0, "val_loss": 0.6928690648078919, "val_acc": 52.0}
{"epoch": 25, "training_loss": 0.6970143413543701, "training_acc": 47.0, "val_loss": 0.6988274955749512, "val_acc": 48.0}
{"epoch": 26, "training_loss": 0.7015008020401001, "training_acc": 51.0, "val_loss": 0.6968899559974671, "val_acc": 48.0}
{"epoch": 27, "training_loss": 0.6941696310043335, "training_acc": 51.0, "val_loss": 0.6943182063102722, "val_acc": 48.0}
{"epoch": 28, "training_loss": 0.6993560791015625, "training_acc": 51.0, "val_loss": 0.6923829460144043, "val_acc": 52.0}
{"epoch": 29, "training_loss": 0.7045501232147217, "training_acc": 49.0, "val_loss": 0.6949025654792785, "val_acc": 52.0}
{"epoch": 30, "training_loss": 0.7029437756538391, "training_acc": 45.0, "val_loss": 0.7035636520385742, "val_acc": 48.0}
{"epoch": 31, "training_loss": 0.7002587532997131, "training_acc": 51.0, "val_loss": 0.6978938961029053, "val_acc": 48.0}
{"epoch": 32, "training_loss": 0.6970981073379516, "training_acc": 51.0, "val_loss": 0.6982511401176452, "val_acc": 48.0}
{"epoch": 33, "training_loss": 0.7024371290206909, "training_acc": 47.0, "val_loss": 0.6923483943939209, "val_acc": 52.0}
{"epoch": 34, "training_loss": 0.6904908418655396, "training_acc": 57.0, "val_loss": 0.7032950687408447, "val_acc": 48.0}
{"epoch": 35, "training_loss": 0.6973470878601075, "training_acc": 51.0, "val_loss": 0.6923511338233947, "val_acc": 52.0}
{"epoch": 36, "training_loss": 0.7246781158447265, "training_acc": 49.0, "val_loss": 0.7045340728759766, "val_acc": 52.0}
{"epoch": 37, "training_loss": 0.7070507168769836, "training_acc": 47.0, "val_loss": 0.6961713504791259, "val_acc": 48.0}
{"epoch": 38, "training_loss": 0.6968322539329529, "training_acc": 51.0, "val_loss": 0.7026431560516357, "val_acc": 48.0}
{"epoch": 39, "training_loss": 0.707082679271698, "training_acc": 51.0, "val_loss": 0.7088360261917114, "val_acc": 48.0}
{"epoch": 40, "training_loss": 0.705619330406189, "training_acc": 51.0, "val_loss": 0.6947750163078308, "val_acc": 48.0}
{"epoch": 41, "training_loss": 0.6939183855056763, "training_acc": 51.0, "val_loss": 0.6927368235588074, "val_acc": 52.0}
