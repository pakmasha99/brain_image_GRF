"main_modify.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 2 --task ADNI_sex --input_option yAware --learning_rate 1e-3 --batch_size 16 --weight_decay 1e-4 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 0.7253139448165894, "training_acc": 38.0, "val_loss": 0.6932821774482727, "val_acc": 48.0}
{"epoch": 1, "training_loss": 0.7055378723144531, "training_acc": 39.0, "val_loss": 0.7161905360221863, "val_acc": 48.0}
{"epoch": 2, "training_loss": 0.7064553236961365, "training_acc": 47.0, "val_loss": 0.6939174318313599, "val_acc": 48.0}
{"epoch": 3, "training_loss": 0.6943355035781861, "training_acc": 51.0, "val_loss": 0.7011111950874329, "val_acc": 48.0}
{"epoch": 4, "training_loss": 0.6955484032630921, "training_acc": 51.0, "val_loss": 0.6934265851974487, "val_acc": 48.0}
{"epoch": 5, "training_loss": 0.6989313173294067, "training_acc": 49.0, "val_loss": 0.697669358253479, "val_acc": 48.0}
{"epoch": 6, "training_loss": 0.7007775974273681, "training_acc": 51.0, "val_loss": 0.7022268795967102, "val_acc": 48.0}
{"epoch": 7, "training_loss": 0.7013536548614502, "training_acc": 47.0, "val_loss": 0.6923394870758056, "val_acc": 52.0}
{"epoch": 8, "training_loss": 0.699904761314392, "training_acc": 47.0, "val_loss": 0.7021288394927978, "val_acc": 48.0}
{"epoch": 9, "training_loss": 0.6956485652923584, "training_acc": 47.0, "val_loss": 0.6935315203666687, "val_acc": 48.0}
{"epoch": 10, "training_loss": 0.7043355011940002, "training_acc": 51.0, "val_loss": 0.7026694869995117, "val_acc": 48.0}
{"epoch": 11, "training_loss": 0.6971695137023926, "training_acc": 49.0, "val_loss": 0.6925286173820495, "val_acc": 52.0}
{"epoch": 12, "training_loss": 0.7082598686218262, "training_acc": 41.0, "val_loss": 0.6944103169441224, "val_acc": 48.0}
{"epoch": 13, "training_loss": 0.7028357338905334, "training_acc": 55.0, "val_loss": 0.6984000062942505, "val_acc": 52.0}
{"epoch": 14, "training_loss": 0.7024403882026672, "training_acc": 47.0, "val_loss": 0.7250917673110961, "val_acc": 48.0}
{"epoch": 15, "training_loss": 0.7123056530952454, "training_acc": 51.0, "val_loss": 0.7015641069412232, "val_acc": 48.0}
{"epoch": 16, "training_loss": 0.6959798884391785, "training_acc": 49.0, "val_loss": 0.6925860667228698, "val_acc": 52.0}
{"epoch": 17, "training_loss": 0.6975985193252563, "training_acc": 49.0, "val_loss": 0.6927246141433716, "val_acc": 52.0}
{"epoch": 18, "training_loss": 0.6934940099716187, "training_acc": 49.0, "val_loss": 0.6997354435920715, "val_acc": 48.0}
{"epoch": 19, "training_loss": 0.7017401933670044, "training_acc": 51.0, "val_loss": 0.695942554473877, "val_acc": 48.0}
{"epoch": 20, "training_loss": 0.6937062978744507, "training_acc": 51.0, "val_loss": 0.6923399901390076, "val_acc": 52.0}
{"epoch": 21, "training_loss": 0.6953149628639221, "training_acc": 51.0, "val_loss": 0.7009090900421142, "val_acc": 48.0}
{"epoch": 22, "training_loss": 0.6985110092163086, "training_acc": 51.0, "val_loss": 0.6937736749649048, "val_acc": 48.0}
{"epoch": 23, "training_loss": 0.6986133503913879, "training_acc": 47.0, "val_loss": 0.6923393201828003, "val_acc": 52.0}
{"epoch": 24, "training_loss": 0.6936133575439453, "training_acc": 51.0, "val_loss": 0.6968177103996277, "val_acc": 48.0}
{"epoch": 25, "training_loss": 0.6974472761154175, "training_acc": 51.0, "val_loss": 0.704169647693634, "val_acc": 48.0}
{"epoch": 26, "training_loss": 0.6945267510414124, "training_acc": 53.0, "val_loss": 0.6923997664451599, "val_acc": 52.0}
{"epoch": 27, "training_loss": 0.6971629118919372, "training_acc": 49.0, "val_loss": 0.6957381725311279, "val_acc": 48.0}
{"epoch": 28, "training_loss": 0.7021640300750732, "training_acc": 51.0, "val_loss": 0.6977724123001099, "val_acc": 48.0}
{"epoch": 29, "training_loss": 0.7012548208236694, "training_acc": 43.0, "val_loss": 0.6923726010322571, "val_acc": 52.0}
{"epoch": 30, "training_loss": 0.6944115328788757, "training_acc": 51.0, "val_loss": 0.6976126313209534, "val_acc": 48.0}
{"epoch": 31, "training_loss": 0.7019127702713013, "training_acc": 51.0, "val_loss": 0.7047486662864685, "val_acc": 48.0}
{"epoch": 32, "training_loss": 0.6997466230392456, "training_acc": 47.0, "val_loss": 0.6946343541145324, "val_acc": 48.0}
{"epoch": 33, "training_loss": 0.7064277744293213, "training_acc": 51.0, "val_loss": 0.7083582735061645, "val_acc": 48.0}
{"epoch": 34, "training_loss": 0.7041144800186158, "training_acc": 51.0, "val_loss": 0.7024478483200073, "val_acc": 48.0}
{"epoch": 35, "training_loss": 0.6954588031768799, "training_acc": 53.0, "val_loss": 0.6962475919723511, "val_acc": 52.0}
{"epoch": 36, "training_loss": 0.7051823902130127, "training_acc": 49.0, "val_loss": 0.6925000572204589, "val_acc": 52.0}
{"epoch": 37, "training_loss": 0.710467324256897, "training_acc": 43.0, "val_loss": 0.7120675015449524, "val_acc": 48.0}
{"epoch": 38, "training_loss": 0.7082866835594177, "training_acc": 47.0, "val_loss": 0.6948504281044007, "val_acc": 48.0}
{"epoch": 39, "training_loss": 0.7004641962051391, "training_acc": 51.0, "val_loss": 0.694971296787262, "val_acc": 48.0}
{"epoch": 40, "training_loss": 0.7326480054855347, "training_acc": 39.0, "val_loss": 0.6925827264785767, "val_acc": 52.0}
{"epoch": 41, "training_loss": 0.704133324623108, "training_acc": 47.0, "val_loss": 0.6928522610664367, "val_acc": 52.0}
{"epoch": 42, "training_loss": 0.7100017166137695, "training_acc": 45.0, "val_loss": 0.6958183312416076, "val_acc": 48.0}
