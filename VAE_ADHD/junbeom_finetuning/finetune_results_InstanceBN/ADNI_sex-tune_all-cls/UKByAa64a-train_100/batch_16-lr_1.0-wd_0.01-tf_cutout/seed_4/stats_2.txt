"main_modify.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 4 --task ADNI_sex --input_option yAware --learning_rate 1e0 --batch_size 16 --weight_decay 1e-2 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 136.16834918022155, "training_acc": 46.0, "val_loss": 55.828619384765624, "val_acc": 52.0}
{"epoch": 1, "training_loss": 73.76983688354493, "training_acc": 48.0, "val_loss": 36.666845703125, "val_acc": 52.0}
{"epoch": 2, "training_loss": 21.56476287841797, "training_acc": 52.0, "val_loss": 27.80267333984375, "val_acc": 52.0}
{"epoch": 3, "training_loss": 51.80125305175781, "training_acc": 42.0, "val_loss": 34.79195533752441, "val_acc": 52.0}
{"epoch": 4, "training_loss": 43.54615234375, "training_acc": 52.0, "val_loss": 108.33001495361329, "val_acc": 48.0}
{"epoch": 5, "training_loss": 58.202589950561524, "training_acc": 52.0, "val_loss": 43.2503507232666, "val_acc": 52.0}
{"epoch": 6, "training_loss": 27.281364135742187, "training_acc": 54.0, "val_loss": 47.32081512451172, "val_acc": 52.0}
{"epoch": 7, "training_loss": 38.52695808410645, "training_acc": 46.0, "val_loss": 46.35245254516602, "val_acc": 52.0}
{"epoch": 8, "training_loss": 54.27213928222656, "training_acc": 46.0, "val_loss": 84.56807434082032, "val_acc": 48.0}
{"epoch": 9, "training_loss": 39.44997634887695, "training_acc": 54.0, "val_loss": 13.953687744140625, "val_acc": 48.0}
{"epoch": 10, "training_loss": 25.163560409545898, "training_acc": 38.0, "val_loss": 38.03855148315429, "val_acc": 48.0}
{"epoch": 11, "training_loss": 33.15050790786743, "training_acc": 50.0, "val_loss": 26.270899810791015, "val_acc": 48.0}
{"epoch": 12, "training_loss": 42.576688842773436, "training_acc": 44.0, "val_loss": 47.85835006713867, "val_acc": 52.0}
{"epoch": 13, "training_loss": 24.637424336671824, "training_acc": 58.0, "val_loss": 9.804977474212647, "val_acc": 52.0}
{"epoch": 14, "training_loss": 8.83437599182129, "training_acc": 54.0, "val_loss": 14.689352912902832, "val_acc": 48.0}
{"epoch": 15, "training_loss": 22.378464431762694, "training_acc": 42.0, "val_loss": 19.856340103149414, "val_acc": 52.0}
{"epoch": 16, "training_loss": 18.247650356292723, "training_acc": 46.0, "val_loss": 23.775169372558594, "val_acc": 52.0}
{"epoch": 17, "training_loss": 21.695724143981934, "training_acc": 54.0, "val_loss": 47.6557113647461, "val_acc": 52.0}
{"epoch": 18, "training_loss": 38.1483120727539, "training_acc": 40.0, "val_loss": 18.719714050292968, "val_acc": 52.0}
{"epoch": 19, "training_loss": 22.79116865158081, "training_acc": 54.0, "val_loss": 62.75106750488281, "val_acc": 52.0}
{"epoch": 20, "training_loss": 40.703055458068846, "training_acc": 46.0, "val_loss": 5.6360048484802245, "val_acc": 52.0}
{"epoch": 21, "training_loss": 12.922184066772461, "training_acc": 48.0, "val_loss": 12.499346466064454, "val_acc": 52.0}
{"epoch": 22, "training_loss": 14.231286792755126, "training_acc": 40.0, "val_loss": 22.65297351837158, "val_acc": 48.0}
{"epoch": 23, "training_loss": 14.612677803039551, "training_acc": 42.0, "val_loss": 11.798815193176269, "val_acc": 52.0}
{"epoch": 24, "training_loss": 11.098901195526123, "training_acc": 60.0, "val_loss": 2.6994388628005983, "val_acc": 52.0}
{"epoch": 25, "training_loss": 14.652922286987305, "training_acc": 54.0, "val_loss": 15.50316032409668, "val_acc": 52.0}
{"epoch": 26, "training_loss": 11.77976963043213, "training_acc": 50.0, "val_loss": 41.79512672424316, "val_acc": 48.0}
{"epoch": 27, "training_loss": 34.98412956237793, "training_acc": 56.0, "val_loss": 96.0636669921875, "val_acc": 52.0}
{"epoch": 28, "training_loss": 53.37306911468506, "training_acc": 50.0, "val_loss": 10.075653324127197, "val_acc": 52.0}
{"epoch": 29, "training_loss": 12.123856706619263, "training_acc": 48.0, "val_loss": 1.3981902980804444, "val_acc": 52.0}
{"epoch": 30, "training_loss": 10.046796855926514, "training_acc": 46.0, "val_loss": 21.25392318725586, "val_acc": 48.0}
{"epoch": 31, "training_loss": 14.813466186523437, "training_acc": 42.0, "val_loss": 1.9170794343948365, "val_acc": 52.0}
{"epoch": 32, "training_loss": 12.46294044494629, "training_acc": 48.0, "val_loss": 4.626488399505615, "val_acc": 48.0}
{"epoch": 33, "training_loss": 26.44193904876709, "training_acc": 40.0, "val_loss": 13.924806175231934, "val_acc": 52.0}
{"epoch": 34, "training_loss": 15.380976028442383, "training_acc": 50.0, "val_loss": 19.429253730773926, "val_acc": 52.0}
{"epoch": 35, "training_loss": 13.558312320709229, "training_acc": 44.0, "val_loss": 4.174719944000244, "val_acc": 52.0}
{"epoch": 36, "training_loss": 12.870243530273438, "training_acc": 56.0, "val_loss": 14.48328109741211, "val_acc": 52.0}
{"epoch": 37, "training_loss": 23.69104766845703, "training_acc": 46.0, "val_loss": 14.52263011932373, "val_acc": 48.0}
{"epoch": 38, "training_loss": 18.221491775512696, "training_acc": 46.0, "val_loss": 45.8801057434082, "val_acc": 48.0}
{"epoch": 39, "training_loss": 29.140456161499024, "training_acc": 48.0, "val_loss": 10.860604629516601, "val_acc": 48.0}
{"epoch": 40, "training_loss": 18.15790714263916, "training_acc": 48.0, "val_loss": 5.74887336730957, "val_acc": 48.0}
{"epoch": 41, "training_loss": 9.686389245986938, "training_acc": 48.0, "val_loss": 40.66926155090332, "val_acc": 52.0}
{"epoch": 42, "training_loss": 28.006813354492188, "training_acc": 46.0, "val_loss": 7.292234115600586, "val_acc": 52.0}
{"epoch": 43, "training_loss": 20.741134376525878, "training_acc": 48.0, "val_loss": 0.8232768297195434, "val_acc": 52.0}
{"epoch": 44, "training_loss": 44.71280988693238, "training_acc": 50.0, "val_loss": 43.223368377685546, "val_acc": 52.0}
{"epoch": 45, "training_loss": 48.60184463500977, "training_acc": 44.0, "val_loss": 52.78693130493164, "val_acc": 48.0}
{"epoch": 46, "training_loss": 57.76938873291016, "training_acc": 46.0, "val_loss": 23.058671798706055, "val_acc": 48.0}
{"epoch": 47, "training_loss": 47.81417495727539, "training_acc": 48.0, "val_loss": 47.52452545166015, "val_acc": 52.0}
{"epoch": 48, "training_loss": 39.26043838500976, "training_acc": 50.0, "val_loss": 6.057229957580566, "val_acc": 52.0}
{"epoch": 49, "training_loss": 13.869652404785157, "training_acc": 50.0, "val_loss": 38.17289581298828, "val_acc": 52.0}
{"epoch": 50, "training_loss": 37.096891708374024, "training_acc": 50.0, "val_loss": 15.097478408813476, "val_acc": 52.0}
{"epoch": 51, "training_loss": 14.102701959609986, "training_acc": 48.0, "val_loss": 8.01845142364502, "val_acc": 48.0}
{"epoch": 52, "training_loss": 10.552542152404785, "training_acc": 50.0, "val_loss": 2.414355592727661, "val_acc": 48.0}
{"epoch": 53, "training_loss": 7.616923799514771, "training_acc": 51.0, "val_loss": 19.36869285583496, "val_acc": 52.0}
{"epoch": 54, "training_loss": 17.039298248291015, "training_acc": 52.0, "val_loss": 27.777810440063476, "val_acc": 52.0}
{"epoch": 55, "training_loss": 11.903585357666016, "training_acc": 48.0, "val_loss": 5.984673776626587, "val_acc": 48.0}
{"epoch": 56, "training_loss": 40.17147285461426, "training_acc": 48.0, "val_loss": 15.803373794555664, "val_acc": 48.0}
{"epoch": 57, "training_loss": 34.21328765869141, "training_acc": 56.0, "val_loss": 39.77040252685547, "val_acc": 52.0}
{"epoch": 58, "training_loss": 53.30237422943115, "training_acc": 45.0, "val_loss": 53.31988265991211, "val_acc": 52.0}
{"epoch": 59, "training_loss": NaN, "training_acc": 46.0, "val_loss": NaN, "val_acc": 48.0}
{"epoch": 60, "training_loss": NaN, "training_acc": 50.0, "val_loss": NaN, "val_acc": 48.0}
{"epoch": 61, "training_loss": NaN, "training_acc": 50.0, "val_loss": NaN, "val_acc": 48.0}
{"epoch": 62, "training_loss": NaN, "training_acc": 50.0, "val_loss": NaN, "val_acc": 48.0}
{"epoch": 63, "training_loss": NaN, "training_acc": 50.0, "val_loss": NaN, "val_acc": 48.0}
{"epoch": 64, "training_loss": NaN, "training_acc": 50.0, "val_loss": NaN, "val_acc": 48.0}
{"epoch": 65, "training_loss": NaN, "training_acc": 50.0, "val_loss": NaN, "val_acc": 48.0}
{"epoch": 66, "training_loss": NaN, "training_acc": 50.0, "val_loss": NaN, "val_acc": 48.0}
{"epoch": 67, "training_loss": NaN, "training_acc": 50.0, "val_loss": NaN, "val_acc": 48.0}
{"epoch": 68, "training_loss": NaN, "training_acc": 50.0, "val_loss": NaN, "val_acc": 48.0}
{"epoch": 69, "training_loss": NaN, "training_acc": 50.0, "val_loss": NaN, "val_acc": 48.0}
{"epoch": 70, "training_loss": NaN, "training_acc": 50.0, "val_loss": NaN, "val_acc": 48.0}
{"epoch": 71, "training_loss": NaN, "training_acc": 50.0, "val_loss": NaN, "val_acc": 48.0}
{"epoch": 72, "training_loss": NaN, "training_acc": 50.0, "val_loss": NaN, "val_acc": 48.0}
{"epoch": 73, "training_loss": NaN, "training_acc": 50.0, "val_loss": NaN, "val_acc": 48.0}
{"epoch": 74, "training_loss": NaN, "training_acc": 50.0, "val_loss": NaN, "val_acc": 48.0}
{"epoch": 75, "training_loss": NaN, "training_acc": 50.0, "val_loss": NaN, "val_acc": 48.0}
{"epoch": 76, "training_loss": NaN, "training_acc": 50.0, "val_loss": NaN, "val_acc": 48.0}
{"epoch": 77, "training_loss": NaN, "training_acc": 50.0, "val_loss": NaN, "val_acc": 48.0}
{"epoch": 78, "training_loss": NaN, "training_acc": 50.0, "val_loss": NaN, "val_acc": 48.0}
{"epoch": 79, "training_loss": NaN, "training_acc": 50.0, "val_loss": NaN, "val_acc": 48.0}
{"epoch": 80, "training_loss": NaN, "training_acc": 50.0, "val_loss": NaN, "val_acc": 48.0}
{"epoch": 81, "training_loss": NaN, "training_acc": 50.0, "val_loss": NaN, "val_acc": 48.0}
{"epoch": 82, "training_loss": NaN, "training_acc": 50.0, "val_loss": NaN, "val_acc": 48.0}
{"epoch": 83, "training_loss": NaN, "training_acc": 50.0, "val_loss": NaN, "val_acc": 48.0}
{"epoch": 84, "training_loss": NaN, "training_acc": 50.0, "val_loss": NaN, "val_acc": 48.0}
{"epoch": 85, "training_loss": NaN, "training_acc": 50.0, "val_loss": NaN, "val_acc": 48.0}
{"epoch": 86, "training_loss": NaN, "training_acc": 50.0, "val_loss": NaN, "val_acc": 48.0}
{"epoch": 87, "training_loss": NaN, "training_acc": 50.0, "val_loss": NaN, "val_acc": 48.0}
{"epoch": 88, "training_loss": NaN, "training_acc": 50.0, "val_loss": NaN, "val_acc": 48.0}
{"epoch": 89, "training_loss": NaN, "training_acc": 50.0, "val_loss": NaN, "val_acc": 48.0}
{"epoch": 90, "training_loss": NaN, "training_acc": 50.0, "val_loss": NaN, "val_acc": 48.0}
{"epoch": 91, "training_loss": NaN, "training_acc": 50.0, "val_loss": NaN, "val_acc": 48.0}
{"epoch": 92, "training_loss": NaN, "training_acc": 50.0, "val_loss": NaN, "val_acc": 48.0}
{"epoch": 93, "training_loss": NaN, "training_acc": 50.0, "val_loss": NaN, "val_acc": 48.0}
{"epoch": 94, "training_loss": NaN, "training_acc": 50.0, "val_loss": NaN, "val_acc": 48.0}
{"epoch": 95, "training_loss": NaN, "training_acc": 50.0, "val_loss": NaN, "val_acc": 48.0}
{"epoch": 96, "training_loss": NaN, "training_acc": 50.0, "val_loss": NaN, "val_acc": 48.0}
{"epoch": 97, "training_loss": NaN, "training_acc": 50.0, "val_loss": NaN, "val_acc": 48.0}
{"epoch": 98, "training_loss": NaN, "training_acc": 50.0, "val_loss": NaN, "val_acc": 48.0}
{"epoch": 99, "training_loss": NaN, "training_acc": 50.0, "val_loss": NaN, "val_acc": 48.0}
