"main_modify.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 2 --task ADNI_sex --input_option yAware --learning_rate 1e0 --batch_size 16 --weight_decay 1e-2 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 95.59104128837585, "training_acc": 48.0, "val_loss": 79.13572814941406, "val_acc": 52.0}
{"epoch": 1, "training_loss": 69.62582183837891, "training_acc": 56.0, "val_loss": 123.82677703857422, "val_acc": 48.0}
{"epoch": 2, "training_loss": 72.6595704650879, "training_acc": 52.0, "val_loss": 81.91688751220703, "val_acc": 52.0}
{"epoch": 3, "training_loss": 71.77719360351563, "training_acc": 48.0, "val_loss": 59.52785354614258, "val_acc": 48.0}
{"epoch": 4, "training_loss": 107.37154067993164, "training_acc": 42.0, "val_loss": 50.453379516601565, "val_acc": 52.0}
{"epoch": 5, "training_loss": 39.99606912612915, "training_acc": 54.0, "val_loss": 35.0426350402832, "val_acc": 52.0}
{"epoch": 6, "training_loss": 28.980483779907228, "training_acc": 48.0, "val_loss": 25.019169921875, "val_acc": 52.0}
{"epoch": 7, "training_loss": 11.141989192962647, "training_acc": 54.0, "val_loss": 24.5236222076416, "val_acc": 48.0}
{"epoch": 8, "training_loss": 22.11958812713623, "training_acc": 50.0, "val_loss": 33.28352279663086, "val_acc": 48.0}
{"epoch": 9, "training_loss": 58.77307025909424, "training_acc": 42.0, "val_loss": 62.56292938232422, "val_acc": 48.0}
{"epoch": 10, "training_loss": 69.823648686409, "training_acc": 54.0, "val_loss": 49.560064697265624, "val_acc": 52.0}
{"epoch": 11, "training_loss": 48.146032314300534, "training_acc": 56.0, "val_loss": 37.00994636535645, "val_acc": 48.0}
{"epoch": 12, "training_loss": 28.060710411071778, "training_acc": 48.0, "val_loss": 63.337337036132816, "val_acc": 48.0}
{"epoch": 13, "training_loss": 46.02980499267578, "training_acc": 48.0, "val_loss": 16.199015731811524, "val_acc": 52.0}
{"epoch": 14, "training_loss": 24.308768463134765, "training_acc": 56.0, "val_loss": 44.77928192138672, "val_acc": 52.0}
{"epoch": 15, "training_loss": 28.534799728393555, "training_acc": 48.0, "val_loss": 5.306291255950928, "val_acc": 52.0}
{"epoch": 16, "training_loss": 14.39537974357605, "training_acc": 50.0, "val_loss": 22.772777252197265, "val_acc": 48.0}
{"epoch": 17, "training_loss": 18.375185317993164, "training_acc": 52.0, "val_loss": 17.324776916503907, "val_acc": 52.0}
{"epoch": 18, "training_loss": 12.676778450012208, "training_acc": 50.0, "val_loss": 9.07757884979248, "val_acc": 48.0}
{"epoch": 19, "training_loss": 14.911856727600098, "training_acc": 48.0, "val_loss": 3.3464163303375245, "val_acc": 48.0}
{"epoch": 20, "training_loss": 14.874883079528809, "training_acc": 42.0, "val_loss": 47.6387905883789, "val_acc": 52.0}
{"epoch": 21, "training_loss": 49.94934188842773, "training_acc": 46.0, "val_loss": 62.23798110961914, "val_acc": 48.0}
{"epoch": 22, "training_loss": 47.44008617401123, "training_acc": 52.0, "val_loss": 21.5048201751709, "val_acc": 52.0}
{"epoch": 23, "training_loss": 39.11097549438477, "training_acc": 42.0, "val_loss": 43.7961392211914, "val_acc": 52.0}
{"epoch": 24, "training_loss": 41.094215087890625, "training_acc": 56.0, "val_loss": 24.82076461791992, "val_acc": 52.0}
{"epoch": 25, "training_loss": 31.79063766479492, "training_acc": 54.0, "val_loss": 57.40619384765625, "val_acc": 48.0}
{"epoch": 26, "training_loss": 50.48923782348633, "training_acc": 46.0, "val_loss": 3.2008373403549193, "val_acc": 48.0}
{"epoch": 27, "training_loss": 12.359507541656495, "training_acc": 46.0, "val_loss": 5.340358066558838, "val_acc": 48.0}
{"epoch": 28, "training_loss": 29.806020736694336, "training_acc": 42.0, "val_loss": 7.3110295677185055, "val_acc": 52.0}
{"epoch": 29, "training_loss": 12.184657711982727, "training_acc": 50.0, "val_loss": 2.303428955078125, "val_acc": 52.0}
{"epoch": 30, "training_loss": 15.085493659973144, "training_acc": 44.0, "val_loss": 11.002707023620605, "val_acc": 52.0}
{"epoch": 31, "training_loss": 17.88194435119629, "training_acc": 50.0, "val_loss": 19.42347366333008, "val_acc": 52.0}
{"epoch": 32, "training_loss": 22.18679428100586, "training_acc": 48.0, "val_loss": 0.6924693655967712, "val_acc": 52.0}
{"epoch": 33, "training_loss": 13.203210906982422, "training_acc": 56.0, "val_loss": 31.441798095703124, "val_acc": 48.0}
{"epoch": 34, "training_loss": 31.515175170898438, "training_acc": 50.0, "val_loss": 13.47709255218506, "val_acc": 52.0}
{"epoch": 35, "training_loss": 36.75068267822266, "training_acc": 46.0, "val_loss": 43.866398620605466, "val_acc": 52.0}
{"epoch": 36, "training_loss": 22.967677230834962, "training_acc": 48.0, "val_loss": 18.997370529174805, "val_acc": 48.0}
{"epoch": 37, "training_loss": 22.886343207359314, "training_acc": 50.0, "val_loss": 20.779729385375976, "val_acc": 48.0}
{"epoch": 38, "training_loss": 26.343208847045897, "training_acc": 50.0, "val_loss": 33.884208831787106, "val_acc": 48.0}
{"epoch": 39, "training_loss": NaN, "training_acc": 48.0, "val_loss": NaN, "val_acc": 48.0}
{"epoch": 40, "training_loss": NaN, "training_acc": 50.0, "val_loss": NaN, "val_acc": 48.0}
{"epoch": 41, "training_loss": NaN, "training_acc": 50.0, "val_loss": NaN, "val_acc": 48.0}
{"epoch": 42, "training_loss": NaN, "training_acc": 50.0, "val_loss": NaN, "val_acc": 48.0}
{"epoch": 43, "training_loss": NaN, "training_acc": 50.0, "val_loss": NaN, "val_acc": 48.0}
{"epoch": 44, "training_loss": NaN, "training_acc": 50.0, "val_loss": NaN, "val_acc": 48.0}
{"epoch": 45, "training_loss": NaN, "training_acc": 50.0, "val_loss": NaN, "val_acc": 48.0}
{"epoch": 46, "training_loss": NaN, "training_acc": 50.0, "val_loss": NaN, "val_acc": 48.0}
{"epoch": 47, "training_loss": NaN, "training_acc": 50.0, "val_loss": NaN, "val_acc": 48.0}
{"epoch": 48, "training_loss": NaN, "training_acc": 50.0, "val_loss": NaN, "val_acc": 48.0}
{"epoch": 49, "training_loss": NaN, "training_acc": 50.0, "val_loss": NaN, "val_acc": 48.0}
{"epoch": 50, "training_loss": NaN, "training_acc": 50.0, "val_loss": NaN, "val_acc": 48.0}
{"epoch": 51, "training_loss": NaN, "training_acc": 50.0, "val_loss": NaN, "val_acc": 48.0}
{"epoch": 52, "training_loss": NaN, "training_acc": 50.0, "val_loss": NaN, "val_acc": 48.0}
{"epoch": 53, "training_loss": NaN, "training_acc": 50.0, "val_loss": NaN, "val_acc": 48.0}
{"epoch": 54, "training_loss": NaN, "training_acc": 50.0, "val_loss": NaN, "val_acc": 48.0}
{"epoch": 55, "training_loss": NaN, "training_acc": 50.0, "val_loss": NaN, "val_acc": 48.0}
{"epoch": 56, "training_loss": NaN, "training_acc": 50.0, "val_loss": NaN, "val_acc": 48.0}
{"epoch": 57, "training_loss": NaN, "training_acc": 50.0, "val_loss": NaN, "val_acc": 48.0}
{"epoch": 58, "training_loss": NaN, "training_acc": 50.0, "val_loss": NaN, "val_acc": 48.0}
{"epoch": 59, "training_loss": NaN, "training_acc": 50.0, "val_loss": NaN, "val_acc": 48.0}
{"epoch": 60, "training_loss": NaN, "training_acc": 50.0, "val_loss": NaN, "val_acc": 48.0}
{"epoch": 61, "training_loss": NaN, "training_acc": 50.0, "val_loss": NaN, "val_acc": 48.0}
{"epoch": 62, "training_loss": NaN, "training_acc": 50.0, "val_loss": NaN, "val_acc": 48.0}
{"epoch": 63, "training_loss": NaN, "training_acc": 50.0, "val_loss": NaN, "val_acc": 48.0}
{"epoch": 64, "training_loss": NaN, "training_acc": 50.0, "val_loss": NaN, "val_acc": 48.0}
{"epoch": 65, "training_loss": NaN, "training_acc": 50.0, "val_loss": NaN, "val_acc": 48.0}
{"epoch": 66, "training_loss": NaN, "training_acc": 50.0, "val_loss": NaN, "val_acc": 48.0}
{"epoch": 67, "training_loss": NaN, "training_acc": 50.0, "val_loss": NaN, "val_acc": 48.0}
{"epoch": 68, "training_loss": NaN, "training_acc": 50.0, "val_loss": NaN, "val_acc": 48.0}
{"epoch": 69, "training_loss": NaN, "training_acc": 50.0, "val_loss": NaN, "val_acc": 48.0}
{"epoch": 70, "training_loss": NaN, "training_acc": 50.0, "val_loss": NaN, "val_acc": 48.0}
{"epoch": 71, "training_loss": NaN, "training_acc": 50.0, "val_loss": NaN, "val_acc": 48.0}
{"epoch": 72, "training_loss": NaN, "training_acc": 50.0, "val_loss": NaN, "val_acc": 48.0}
{"epoch": 73, "training_loss": NaN, "training_acc": 50.0, "val_loss": NaN, "val_acc": 48.0}
{"epoch": 74, "training_loss": NaN, "training_acc": 50.0, "val_loss": NaN, "val_acc": 48.0}
{"epoch": 75, "training_loss": NaN, "training_acc": 50.0, "val_loss": NaN, "val_acc": 48.0}
{"epoch": 76, "training_loss": NaN, "training_acc": 50.0, "val_loss": NaN, "val_acc": 48.0}
{"epoch": 77, "training_loss": NaN, "training_acc": 50.0, "val_loss": NaN, "val_acc": 48.0}
{"epoch": 78, "training_loss": NaN, "training_acc": 50.0, "val_loss": NaN, "val_acc": 48.0}
{"epoch": 79, "training_loss": NaN, "training_acc": 50.0, "val_loss": NaN, "val_acc": 48.0}
{"epoch": 80, "training_loss": NaN, "training_acc": 50.0, "val_loss": NaN, "val_acc": 48.0}
{"epoch": 81, "training_loss": NaN, "training_acc": 50.0, "val_loss": NaN, "val_acc": 48.0}
{"epoch": 82, "training_loss": NaN, "training_acc": 50.0, "val_loss": NaN, "val_acc": 48.0}
{"epoch": 83, "training_loss": NaN, "training_acc": 50.0, "val_loss": NaN, "val_acc": 48.0}
{"epoch": 84, "training_loss": NaN, "training_acc": 50.0, "val_loss": NaN, "val_acc": 48.0}
{"epoch": 85, "training_loss": NaN, "training_acc": 50.0, "val_loss": NaN, "val_acc": 48.0}
{"epoch": 86, "training_loss": NaN, "training_acc": 50.0, "val_loss": NaN, "val_acc": 48.0}
{"epoch": 87, "training_loss": NaN, "training_acc": 50.0, "val_loss": NaN, "val_acc": 48.0}
{"epoch": 88, "training_loss": NaN, "training_acc": 50.0, "val_loss": NaN, "val_acc": 48.0}
{"epoch": 89, "training_loss": NaN, "training_acc": 50.0, "val_loss": NaN, "val_acc": 48.0}
{"epoch": 90, "training_loss": NaN, "training_acc": 50.0, "val_loss": NaN, "val_acc": 48.0}
{"epoch": 91, "training_loss": NaN, "training_acc": 50.0, "val_loss": NaN, "val_acc": 48.0}
{"epoch": 92, "training_loss": NaN, "training_acc": 50.0, "val_loss": NaN, "val_acc": 48.0}
{"epoch": 93, "training_loss": NaN, "training_acc": 50.0, "val_loss": NaN, "val_acc": 48.0}
{"epoch": 94, "training_loss": NaN, "training_acc": 50.0, "val_loss": NaN, "val_acc": 48.0}
{"epoch": 95, "training_loss": NaN, "training_acc": 50.0, "val_loss": NaN, "val_acc": 48.0}
{"epoch": 96, "training_loss": NaN, "training_acc": 50.0, "val_loss": NaN, "val_acc": 48.0}
{"epoch": 97, "training_loss": NaN, "training_acc": 50.0, "val_loss": NaN, "val_acc": 48.0}
{"epoch": 98, "training_loss": NaN, "training_acc": 50.0, "val_loss": NaN, "val_acc": 48.0}
{"epoch": 99, "training_loss": NaN, "training_acc": 50.0, "val_loss": NaN, "val_acc": 48.0}
