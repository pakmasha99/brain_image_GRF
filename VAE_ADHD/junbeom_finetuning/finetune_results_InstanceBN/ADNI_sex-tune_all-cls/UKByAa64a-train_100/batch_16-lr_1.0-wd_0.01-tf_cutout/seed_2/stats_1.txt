"main_modify.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 2 --task ADNI_sex --input_option yAware --learning_rate 1e0 --batch_size 16 --weight_decay 1e-2 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 99.96155646324158, "training_acc": 54.0, "val_loss": 17.378967323303222, "val_acc": 52.0}
{"epoch": 1, "training_loss": 29.203897857666014, "training_acc": 44.0, "val_loss": 56.70741760253906, "val_acc": 52.0}
{"epoch": 2, "training_loss": 44.38861106872559, "training_acc": 36.0, "val_loss": 64.21104217529297, "val_acc": 52.0}
{"epoch": 3, "training_loss": 56.76538818359375, "training_acc": 46.0, "val_loss": 47.45576522827148, "val_acc": 48.0}
{"epoch": 4, "training_loss": 33.14834665775299, "training_acc": 56.0, "val_loss": 21.112906341552733, "val_acc": 48.0}
{"epoch": 5, "training_loss": 15.787411708831787, "training_acc": 43.0, "val_loss": 32.69880485534668, "val_acc": 48.0}
{"epoch": 6, "training_loss": 34.73886428833008, "training_acc": 52.0, "val_loss": 16.417635192871092, "val_acc": 52.0}
{"epoch": 7, "training_loss": 20.529904289245607, "training_acc": 46.0, "val_loss": 23.201562881469727, "val_acc": 48.0}
{"epoch": 8, "training_loss": 14.242667350769043, "training_acc": 56.0, "val_loss": 16.02841133117676, "val_acc": 48.0}
{"epoch": 9, "training_loss": 9.547168216705323, "training_acc": 52.0, "val_loss": 20.52260787963867, "val_acc": 48.0}
{"epoch": 10, "training_loss": 23.99290672302246, "training_acc": 56.0, "val_loss": 38.851507873535155, "val_acc": 52.0}
{"epoch": 11, "training_loss": 33.94368492126465, "training_acc": 52.0, "val_loss": 53.60112548828125, "val_acc": 52.0}
{"epoch": 12, "training_loss": 66.17666969299316, "training_acc": 48.0, "val_loss": 30.111104125976563, "val_acc": 48.0}
{"epoch": 13, "training_loss": 13.39785987854004, "training_acc": 44.0, "val_loss": 27.953585662841796, "val_acc": 48.0}
{"epoch": 14, "training_loss": 34.717121276855465, "training_acc": 48.0, "val_loss": 59.7432827758789, "val_acc": 48.0}
{"epoch": 15, "training_loss": 27.510014266967772, "training_acc": 52.0, "val_loss": 50.00651031494141, "val_acc": 48.0}
{"epoch": 16, "training_loss": 45.13219331741333, "training_acc": 44.0, "val_loss": 33.11533218383789, "val_acc": 48.0}
{"epoch": 17, "training_loss": 23.810223388671876, "training_acc": 50.0, "val_loss": 52.8815771484375, "val_acc": 48.0}
{"epoch": 18, "training_loss": 29.831913661956786, "training_acc": 54.0, "val_loss": 39.73165588378906, "val_acc": 48.0}
{"epoch": 19, "training_loss": 54.351640968322755, "training_acc": 42.0, "val_loss": 25.60568016052246, "val_acc": 52.0}
{"epoch": 20, "training_loss": 42.63163452148437, "training_acc": 54.0, "val_loss": 43.23638160705566, "val_acc": 52.0}
{"epoch": 21, "training_loss": 37.964672546386716, "training_acc": 46.0, "val_loss": 36.45685173034668, "val_acc": 52.0}
{"epoch": 22, "training_loss": 49.90443786621094, "training_acc": 50.0, "val_loss": 40.76295211791992, "val_acc": 48.0}
{"epoch": 23, "training_loss": 21.266980628967286, "training_acc": 50.0, "val_loss": 3.529368257522583, "val_acc": 52.0}
{"epoch": 24, "training_loss": 7.305633163452148, "training_acc": 52.0, "val_loss": 26.91005844116211, "val_acc": 52.0}
{"epoch": 25, "training_loss": 23.5674209022522, "training_acc": 48.0, "val_loss": 19.32707405090332, "val_acc": 52.0}
{"epoch": 26, "training_loss": 8.928912763595582, "training_acc": 48.0, "val_loss": 8.408084716796875, "val_acc": 52.0}
{"epoch": 27, "training_loss": 9.99303352355957, "training_acc": 48.0, "val_loss": 11.524946937561035, "val_acc": 52.0}
{"epoch": 28, "training_loss": 36.3548486328125, "training_acc": 44.0, "val_loss": 61.816839904785155, "val_acc": 52.0}
{"epoch": 29, "training_loss": 29.8264782333374, "training_acc": 42.0, "val_loss": 3.420591688156128, "val_acc": 52.0}
{"epoch": 30, "training_loss": 31.442369117736817, "training_acc": 52.0, "val_loss": 68.48710968017578, "val_acc": 52.0}
{"epoch": 31, "training_loss": 46.72028167724609, "training_acc": 52.0, "val_loss": 62.95402954101562, "val_acc": 48.0}
{"epoch": 32, "training_loss": 27.914145317077637, "training_acc": 54.0, "val_loss": 37.00947509765625, "val_acc": 48.0}
{"epoch": 33, "training_loss": 21.333929142951966, "training_acc": 58.0, "val_loss": 28.85578887939453, "val_acc": 48.0}
{"epoch": 34, "training_loss": 34.39322982788086, "training_acc": 46.0, "val_loss": 46.085620727539066, "val_acc": 48.0}
{"epoch": 35, "training_loss": 36.67769564628601, "training_acc": 52.0, "val_loss": 23.655853424072266, "val_acc": 52.0}
{"epoch": 36, "training_loss": 22.982623977661135, "training_acc": 48.0, "val_loss": 9.028614597320557, "val_acc": 48.0}
{"epoch": 37, "training_loss": 9.035710983276367, "training_acc": 54.0, "val_loss": 22.434140739440917, "val_acc": 52.0}
{"epoch": 38, "training_loss": 23.03406145095814, "training_acc": 48.0, "val_loss": 9.204201622009277, "val_acc": 52.0}
{"epoch": 39, "training_loss": 12.29877197265625, "training_acc": 48.0, "val_loss": 22.438554763793945, "val_acc": 52.0}
{"epoch": 40, "training_loss": 32.261673278808594, "training_acc": 54.0, "val_loss": 51.91887161254883, "val_acc": 48.0}
{"epoch": 41, "training_loss": 51.52988450527191, "training_acc": 46.0, "val_loss": 30.30935134887695, "val_acc": 48.0}
{"epoch": 42, "training_loss": 37.13477973937988, "training_acc": 42.0, "val_loss": 49.447195053100586, "val_acc": 48.0}
{"epoch": 43, "training_loss": 47.19304061889648, "training_acc": 56.0, "val_loss": 48.9755744934082, "val_acc": 52.0}
{"epoch": 44, "training_loss": 41.45260299682617, "training_acc": 50.0, "val_loss": 9.17410514831543, "val_acc": 52.0}
{"epoch": 45, "training_loss": 27.21054412841797, "training_acc": 48.0, "val_loss": 15.296134948730469, "val_acc": 48.0}
{"epoch": 46, "training_loss": 32.69234352111816, "training_acc": 52.0, "val_loss": 33.26599380493164, "val_acc": 48.0}
{"epoch": 47, "training_loss": 28.800279388427736, "training_acc": 48.0, "val_loss": 67.44041900634765, "val_acc": 48.0}
{"epoch": 48, "training_loss": 45.06123954772949, "training_acc": 52.0, "val_loss": 11.990603256225587, "val_acc": 52.0}
