"main_modify.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 2 --task ADNI_sex --input_option yAware --learning_rate 1e0 --batch_size 16 --weight_decay 1e-2 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 133.69370774269103, "training_acc": 46.0, "val_loss": 20.605520172119142, "val_acc": 48.0}
{"epoch": 1, "training_loss": 104.151591796875, "training_acc": 54.0, "val_loss": 17.81359729766846, "val_acc": 48.0}
{"epoch": 2, "training_loss": 40.25363571166992, "training_acc": 42.0, "val_loss": 15.129008636474609, "val_acc": 48.0}
{"epoch": 3, "training_loss": 25.577936000823975, "training_acc": 46.0, "val_loss": 37.933810806274415, "val_acc": 48.0}
{"epoch": 4, "training_loss": 24.873355026245118, "training_acc": 50.0, "val_loss": 12.177147102355956, "val_acc": 48.0}
{"epoch": 5, "training_loss": 13.336709003448487, "training_acc": 44.0, "val_loss": 5.1456781768798825, "val_acc": 52.0}
{"epoch": 6, "training_loss": 10.13695219039917, "training_acc": 60.0, "val_loss": 22.592155227661134, "val_acc": 52.0}
{"epoch": 7, "training_loss": 22.561326599121095, "training_acc": 46.0, "val_loss": 30.80554672241211, "val_acc": 52.0}
{"epoch": 8, "training_loss": 36.52100233078003, "training_acc": 54.0, "val_loss": 26.176865844726564, "val_acc": 52.0}
{"epoch": 9, "training_loss": 29.96553961277008, "training_acc": 44.0, "val_loss": 8.150842876434327, "val_acc": 52.0}
{"epoch": 10, "training_loss": 15.406593122482299, "training_acc": 44.0, "val_loss": 28.53220718383789, "val_acc": 48.0}
{"epoch": 11, "training_loss": 21.526012573242188, "training_acc": 50.0, "val_loss": 42.91018844604492, "val_acc": 48.0}
{"epoch": 12, "training_loss": 18.887068519592287, "training_acc": 46.0, "val_loss": 31.11042434692383, "val_acc": 52.0}
{"epoch": 13, "training_loss": 10.495095977783203, "training_acc": 56.0, "val_loss": 6.999493350982666, "val_acc": 48.0}
{"epoch": 14, "training_loss": 7.732165451049805, "training_acc": 56.0, "val_loss": 28.992137603759765, "val_acc": 48.0}
{"epoch": 15, "training_loss": 37.758124294281004, "training_acc": 48.0, "val_loss": 24.584536361694337, "val_acc": 48.0}
{"epoch": 16, "training_loss": 11.775006122589112, "training_acc": 48.0, "val_loss": 2.438198890686035, "val_acc": 48.0}
{"epoch": 17, "training_loss": 8.825217781066895, "training_acc": 54.0, "val_loss": 30.332675170898437, "val_acc": 48.0}
{"epoch": 18, "training_loss": 14.40497314453125, "training_acc": 56.0, "val_loss": 10.762055740356445, "val_acc": 52.0}
{"epoch": 19, "training_loss": 22.54598648071289, "training_acc": 44.0, "val_loss": 29.485757598876955, "val_acc": 52.0}
{"epoch": 20, "training_loss": 19.507444000244142, "training_acc": 38.0, "val_loss": 17.047662200927736, "val_acc": 48.0}
{"epoch": 21, "training_loss": 21.4255025100708, "training_acc": 46.0, "val_loss": 37.65833480834961, "val_acc": 52.0}
{"epoch": 22, "training_loss": 39.44531280517578, "training_acc": 54.0, "val_loss": 97.24508453369141, "val_acc": 48.0}
{"epoch": 23, "training_loss": 51.500069274902344, "training_acc": 58.0, "val_loss": 83.53880859375, "val_acc": 52.0}
{"epoch": 24, "training_loss": 81.65944129943847, "training_acc": 42.0, "val_loss": 54.86805297851563, "val_acc": 48.0}
{"epoch": 25, "training_loss": 72.21158966064453, "training_acc": 56.0, "val_loss": 48.1530647277832, "val_acc": 52.0}
{"epoch": 26, "training_loss": 46.451055755615236, "training_acc": 50.0, "val_loss": 36.19291091918945, "val_acc": 52.0}
{"epoch": 27, "training_loss": 35.41689609527588, "training_acc": 56.0, "val_loss": 2.9907847595214845, "val_acc": 48.0}
{"epoch": 28, "training_loss": 36.28194242477417, "training_acc": 48.0, "val_loss": 13.886604309082031, "val_acc": 48.0}
{"epoch": 29, "training_loss": 17.019816913604735, "training_acc": 54.0, "val_loss": 12.104193496704102, "val_acc": 52.0}
{"epoch": 30, "training_loss": 15.897105293273926, "training_acc": 46.0, "val_loss": 34.160054473876954, "val_acc": 48.0}
{"epoch": 31, "training_loss": 43.31607927322388, "training_acc": 46.0, "val_loss": 35.738045349121094, "val_acc": 52.0}
{"epoch": 32, "training_loss": 18.034207859039306, "training_acc": 46.0, "val_loss": 46.620615234375, "val_acc": 48.0}
{"epoch": 33, "training_loss": 46.951936645507814, "training_acc": 46.0, "val_loss": 9.12941951751709, "val_acc": 48.0}
{"epoch": 34, "training_loss": 16.27372428894043, "training_acc": 46.0, "val_loss": 46.61865394592285, "val_acc": 48.0}
{"epoch": 35, "training_loss": 43.11805828094482, "training_acc": 48.0, "val_loss": 54.511943359375, "val_acc": 52.0}
