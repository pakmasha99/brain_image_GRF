"main_modify.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ADNI_sex --input_option yAware --learning_rate 1e0 --batch_size 16 --weight_decay 1e-2 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 93.51861221313476, "training_acc": 55.0, "val_loss": 52.711958770751956, "val_acc": 48.0}
{"epoch": 1, "training_loss": 44.345136108398435, "training_acc": 45.0, "val_loss": 49.319932556152345, "val_acc": 48.0}
{"epoch": 2, "training_loss": 33.60964988708496, "training_acc": 55.0, "val_loss": 28.920132446289063, "val_acc": 48.0}
{"epoch": 3, "training_loss": 17.93839250564575, "training_acc": 52.0, "val_loss": 6.484406776428223, "val_acc": 48.0}
{"epoch": 4, "training_loss": 17.330642776489256, "training_acc": 43.0, "val_loss": 53.99146240234375, "val_acc": 52.0}
{"epoch": 5, "training_loss": 52.00092124938965, "training_acc": 49.0, "val_loss": 17.250527725219726, "val_acc": 48.0}
{"epoch": 6, "training_loss": 57.087578125, "training_acc": 47.0, "val_loss": 62.951279296875, "val_acc": 48.0}
{"epoch": 7, "training_loss": 57.64428497314453, "training_acc": 43.0, "val_loss": 32.57501216888428, "val_acc": 52.0}
{"epoch": 8, "training_loss": 37.121988983154296, "training_acc": 47.0, "val_loss": 51.88374664306641, "val_acc": 52.0}
{"epoch": 9, "training_loss": 37.74637847900391, "training_acc": 55.0, "val_loss": 53.34533660888672, "val_acc": 48.0}
{"epoch": 10, "training_loss": 22.95020721435547, "training_acc": 51.0, "val_loss": 43.43944793701172, "val_acc": 48.0}
{"epoch": 11, "training_loss": 17.431145086288453, "training_acc": 45.0, "val_loss": 4.865145950317383, "val_acc": 52.0}
{"epoch": 12, "training_loss": 21.990817070007324, "training_acc": 51.0, "val_loss": 1.8300572061538696, "val_acc": 48.0}
{"epoch": 13, "training_loss": 15.786715030670166, "training_acc": 43.0, "val_loss": 9.450885162353515, "val_acc": 52.0}
{"epoch": 14, "training_loss": 6.3377009201049805, "training_acc": 63.0, "val_loss": 4.141450119018555, "val_acc": 52.0}
{"epoch": 15, "training_loss": 5.9456735038757325, "training_acc": 49.0, "val_loss": 13.992877883911133, "val_acc": 52.0}
{"epoch": 16, "training_loss": 8.567324161529541, "training_acc": 51.0, "val_loss": 14.139786911010741, "val_acc": 52.0}
{"epoch": 17, "training_loss": 9.814365119934083, "training_acc": 49.0, "val_loss": 1.0779575538635253, "val_acc": 52.0}
{"epoch": 18, "training_loss": 20.925903968811035, "training_acc": 47.0, "val_loss": 4.5268737411499025, "val_acc": 48.0}
{"epoch": 19, "training_loss": 6.044550743103027, "training_acc": 47.0, "val_loss": 10.503878059387207, "val_acc": 52.0}
{"epoch": 20, "training_loss": 16.60208786010742, "training_acc": 43.0, "val_loss": 33.78856430053711, "val_acc": 48.0}
{"epoch": 21, "training_loss": 34.43590288162231, "training_acc": 53.0, "val_loss": 5.026525001525879, "val_acc": 48.0}
{"epoch": 22, "training_loss": 10.134158897399903, "training_acc": 51.0, "val_loss": 1.6795033454895019, "val_acc": 52.0}
{"epoch": 23, "training_loss": 4.173449153900147, "training_acc": 58.0, "val_loss": 14.559555206298828, "val_acc": 48.0}
{"epoch": 24, "training_loss": 18.66842918395996, "training_acc": 59.0, "val_loss": 32.76335693359375, "val_acc": 48.0}
{"epoch": 25, "training_loss": 30.11273208618164, "training_acc": 57.0, "val_loss": 26.096159057617186, "val_acc": 52.0}
{"epoch": 26, "training_loss": 21.231896686553956, "training_acc": 47.0, "val_loss": 35.60067840576172, "val_acc": 48.0}
{"epoch": 27, "training_loss": 40.504696426391604, "training_acc": 49.0, "val_loss": 76.06156509399415, "val_acc": 52.0}
{"epoch": 28, "training_loss": 42.626689758300785, "training_acc": 59.0, "val_loss": 11.46351806640625, "val_acc": 48.0}
{"epoch": 29, "training_loss": 65.70539818286896, "training_acc": 45.0, "val_loss": 59.599001770019534, "val_acc": 48.0}
{"epoch": 30, "training_loss": 61.173586196899414, "training_acc": 45.0, "val_loss": 45.20000305175781, "val_acc": 52.0}
{"epoch": 31, "training_loss": 31.85579204559326, "training_acc": 51.0, "val_loss": 14.315630264282227, "val_acc": 52.0}
{"epoch": 32, "training_loss": 30.15618755340576, "training_acc": 35.0, "val_loss": 18.957020263671875, "val_acc": 52.0}
{"epoch": 33, "training_loss": 30.468258666992188, "training_acc": 47.0, "val_loss": 26.528271408081054, "val_acc": 52.0}
{"epoch": 34, "training_loss": 38.8412593460083, "training_acc": 47.0, "val_loss": 27.45171241760254, "val_acc": 52.0}
{"epoch": 35, "training_loss": 27.566139223575593, "training_acc": 51.0, "val_loss": 27.359172821044922, "val_acc": 52.0}
{"epoch": 36, "training_loss": 39.33784561157226, "training_acc": 41.0, "val_loss": 33.73555206298828, "val_acc": 52.0}
