"main_modify.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ADNI_sex --input_option yAware --learning_rate 1e0 --batch_size 16 --weight_decay 1e-2 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 69.08895352363587, "training_acc": 51.0, "val_loss": 23.627766418457032, "val_acc": 52.0}
{"epoch": 1, "training_loss": 18.416196806430772, "training_acc": 52.0, "val_loss": 7.065650215148926, "val_acc": 48.0}
{"epoch": 2, "training_loss": 12.813268032073974, "training_acc": 52.0, "val_loss": 20.293119812011717, "val_acc": 48.0}
{"epoch": 3, "training_loss": 17.957760620117188, "training_acc": 44.0, "val_loss": 5.50496618270874, "val_acc": 52.0}
{"epoch": 4, "training_loss": 18.517273406982422, "training_acc": 54.0, "val_loss": 11.58433937072754, "val_acc": 52.0}
{"epoch": 5, "training_loss": 8.589478302001954, "training_acc": 52.0, "val_loss": 29.006331100463868, "val_acc": 48.0}
{"epoch": 6, "training_loss": 22.745841598510744, "training_acc": 46.0, "val_loss": 35.76464424133301, "val_acc": 48.0}
{"epoch": 7, "training_loss": 20.71484344482422, "training_acc": 52.0, "val_loss": 1.2942617416381836, "val_acc": 52.0}
{"epoch": 8, "training_loss": 7.49627682685852, "training_acc": 56.0, "val_loss": 26.7377001953125, "val_acc": 48.0}
{"epoch": 9, "training_loss": 27.38284267425537, "training_acc": 46.0, "val_loss": 4.624234561920166, "val_acc": 48.0}
{"epoch": 10, "training_loss": 9.19725977897644, "training_acc": 54.0, "val_loss": 18.5221435546875, "val_acc": 48.0}
{"epoch": 11, "training_loss": 11.231383724212646, "training_acc": 48.0, "val_loss": 16.354839706420897, "val_acc": 48.0}
{"epoch": 12, "training_loss": 10.681071243286134, "training_acc": 56.0, "val_loss": 17.93526885986328, "val_acc": 52.0}
{"epoch": 13, "training_loss": 12.186490001678466, "training_acc": 50.0, "val_loss": 12.009518737792968, "val_acc": 48.0}
{"epoch": 14, "training_loss": 16.705609283447266, "training_acc": 56.0, "val_loss": 2.346023802757263, "val_acc": 52.0}
{"epoch": 15, "training_loss": 11.31345775604248, "training_acc": 48.0, "val_loss": 3.0548830699920653, "val_acc": 52.0}
{"epoch": 16, "training_loss": 7.254150619506836, "training_acc": 58.0, "val_loss": 10.901926879882813, "val_acc": 48.0}
{"epoch": 17, "training_loss": 17.57177616119385, "training_acc": 54.0, "val_loss": 79.51638336181641, "val_acc": 48.0}
{"epoch": 18, "training_loss": 52.42683013916016, "training_acc": 50.0, "val_loss": 7.071804504394532, "val_acc": 52.0}
{"epoch": 19, "training_loss": 57.17880392074585, "training_acc": 48.0, "val_loss": 69.81526733398438, "val_acc": 52.0}
{"epoch": 20, "training_loss": 103.4463021850586, "training_acc": 50.0, "val_loss": 48.420491790771486, "val_acc": 48.0}
{"epoch": 21, "training_loss": 79.53108253479004, "training_acc": 48.0, "val_loss": 25.89034553527832, "val_acc": 52.0}
{"epoch": 22, "training_loss": 17.65527174949646, "training_acc": 58.0, "val_loss": 1.0322801184654236, "val_acc": 52.0}
{"epoch": 23, "training_loss": 17.00620189666748, "training_acc": 48.0, "val_loss": 29.841219635009764, "val_acc": 48.0}
{"epoch": 24, "training_loss": 11.49254249572754, "training_acc": 56.0, "val_loss": 39.76649826049805, "val_acc": 52.0}
{"epoch": 25, "training_loss": 22.310458984375, "training_acc": 56.0, "val_loss": 0.6970690774917603, "val_acc": 48.0}
{"epoch": 26, "training_loss": 12.012587671279908, "training_acc": 58.0, "val_loss": 26.743871841430664, "val_acc": 48.0}
{"epoch": 27, "training_loss": 19.244296016693117, "training_acc": 52.0, "val_loss": 7.127505474090576, "val_acc": 48.0}
{"epoch": 28, "training_loss": 13.806700916290284, "training_acc": 46.0, "val_loss": 15.069534301757812, "val_acc": 48.0}
{"epoch": 29, "training_loss": 7.156263093948365, "training_acc": 54.0, "val_loss": 23.466311111450196, "val_acc": 52.0}
{"epoch": 30, "training_loss": 18.975297260284425, "training_acc": 56.0, "val_loss": 21.83061592102051, "val_acc": 52.0}
{"epoch": 31, "training_loss": 30.40205062866211, "training_acc": 44.0, "val_loss": 78.14987213134765, "val_acc": 52.0}
{"epoch": 32, "training_loss": 62.24503753662109, "training_acc": 54.0, "val_loss": 101.29520812988281, "val_acc": 48.0}
{"epoch": 33, "training_loss": 71.95122501373291, "training_acc": 48.0, "val_loss": 96.86670349121094, "val_acc": 52.0}
{"epoch": 34, "training_loss": 80.80777618408203, "training_acc": 48.0, "val_loss": 79.08950225830078, "val_acc": 48.0}
{"epoch": 35, "training_loss": 39.23840563774109, "training_acc": 56.0, "val_loss": 27.554022216796874, "val_acc": 48.0}
{"epoch": 36, "training_loss": 31.79799133300781, "training_acc": 52.0, "val_loss": 18.673542938232423, "val_acc": 52.0}
{"epoch": 37, "training_loss": 15.517750778198241, "training_acc": 50.0, "val_loss": 14.084651069641113, "val_acc": 48.0}
{"epoch": 38, "training_loss": 11.345719356536865, "training_acc": 48.0, "val_loss": 25.36483787536621, "val_acc": 48.0}
{"epoch": 39, "training_loss": 24.441063385009766, "training_acc": 46.0, "val_loss": 11.977489395141601, "val_acc": 48.0}
{"epoch": 40, "training_loss": 7.145215454101563, "training_acc": 50.0, "val_loss": 10.765062942504883, "val_acc": 48.0}
{"epoch": 41, "training_loss": 12.570866737365723, "training_acc": 50.0, "val_loss": 33.2824698638916, "val_acc": 48.0}
{"epoch": 42, "training_loss": 37.3318327331543, "training_acc": 50.0, "val_loss": 18.6024658203125, "val_acc": 52.0}
{"epoch": 43, "training_loss": 19.14242202758789, "training_acc": 48.0, "val_loss": 6.425399856567383, "val_acc": 52.0}
{"epoch": 44, "training_loss": 7.151478483527899, "training_acc": 50.0, "val_loss": 5.496792526245117, "val_acc": 48.0}
