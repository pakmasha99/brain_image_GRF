"main_modify.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 6 --task ADNI_sex --input_option yAware --learning_rate 1e0 --batch_size 16 --weight_decay 1e-2 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 67.14459005355835, "training_acc": 55.0, "val_loss": 49.446423034667966, "val_acc": 52.0}
{"epoch": 1, "training_loss": 42.192862091064455, "training_acc": 45.0, "val_loss": 10.586212882995605, "val_acc": 52.0}
{"epoch": 2, "training_loss": 41.045523986816406, "training_acc": 45.0, "val_loss": 46.17370086669922, "val_acc": 52.0}
{"epoch": 3, "training_loss": 51.597508926391605, "training_acc": 51.0, "val_loss": 21.948775329589843, "val_acc": 52.0}
{"epoch": 4, "training_loss": 35.28368417739868, "training_acc": 49.0, "val_loss": 15.880096817016602, "val_acc": 48.0}
{"epoch": 5, "training_loss": 12.042883796691894, "training_acc": 49.0, "val_loss": 14.734910049438476, "val_acc": 48.0}
{"epoch": 6, "training_loss": 19.20010429382324, "training_acc": 45.0, "val_loss": 36.59756057739258, "val_acc": 48.0}
{"epoch": 7, "training_loss": 22.341843948364257, "training_acc": 45.0, "val_loss": 34.292757530212405, "val_acc": 48.0}
{"epoch": 8, "training_loss": 22.727123947143554, "training_acc": 49.0, "val_loss": 71.40546127319335, "val_acc": 48.0}
{"epoch": 9, "training_loss": 57.29527862548828, "training_acc": 49.0, "val_loss": 67.16844604492188, "val_acc": 52.0}
{"epoch": 10, "training_loss": 31.866165771484376, "training_acc": 47.0, "val_loss": 28.02619926452637, "val_acc": 52.0}
{"epoch": 11, "training_loss": 24.26404556274414, "training_acc": 49.0, "val_loss": 63.679126586914066, "val_acc": 52.0}
{"epoch": 12, "training_loss": 46.27766986846924, "training_acc": 53.0, "val_loss": 60.5893994140625, "val_acc": 48.0}
{"epoch": 13, "training_loss": 29.62833950996399, "training_acc": 62.0, "val_loss": 34.28749526977539, "val_acc": 48.0}
{"epoch": 14, "training_loss": 29.175691146850586, "training_acc": 55.0, "val_loss": 2.042830991744995, "val_acc": 48.0}
{"epoch": 15, "training_loss": 22.246729888916015, "training_acc": 33.0, "val_loss": 42.71463409423828, "val_acc": 48.0}
{"epoch": 16, "training_loss": 36.242477359771726, "training_acc": 49.0, "val_loss": 6.619048576354981, "val_acc": 48.0}
{"epoch": 17, "training_loss": 7.963172168731689, "training_acc": 53.0, "val_loss": 10.0982373046875, "val_acc": 52.0}
{"epoch": 18, "training_loss": 13.182781448364258, "training_acc": 49.0, "val_loss": 17.490946426391602, "val_acc": 52.0}
{"epoch": 19, "training_loss": 13.354869747161866, "training_acc": 49.0, "val_loss": 14.891199913024902, "val_acc": 48.0}
{"epoch": 20, "training_loss": 15.148631973266601, "training_acc": 53.0, "val_loss": 12.823264389038085, "val_acc": 48.0}
{"epoch": 21, "training_loss": 33.12567123413086, "training_acc": 35.0, "val_loss": 31.82820182800293, "val_acc": 52.0}
{"epoch": 22, "training_loss": 34.29177867889404, "training_acc": 50.0, "val_loss": 1.0621684455871583, "val_acc": 56.0}
{"epoch": 23, "training_loss": 26.351672973632812, "training_acc": 51.0, "val_loss": 62.9848176574707, "val_acc": 48.0}
{"epoch": 24, "training_loss": 47.41039993286133, "training_acc": 51.0, "val_loss": 55.38163238525391, "val_acc": 52.0}
{"epoch": 25, "training_loss": 32.88070896148682, "training_acc": 53.0, "val_loss": 9.932133064270019, "val_acc": 52.0}
{"epoch": 26, "training_loss": 7.44844084739685, "training_acc": 48.0, "val_loss": 35.637339935302734, "val_acc": 52.0}
{"epoch": 27, "training_loss": 51.590770416259765, "training_acc": 43.0, "val_loss": 12.716566543579102, "val_acc": 48.0}
{"epoch": 28, "training_loss": 104.57542572021484, "training_acc": 43.0, "val_loss": 5.510913619995117, "val_acc": 48.0}
{"epoch": 29, "training_loss": 23.6465474319458, "training_acc": 53.0, "val_loss": 39.18163116455078, "val_acc": 52.0}
{"epoch": 30, "training_loss": 33.7825394821167, "training_acc": 47.0, "val_loss": 35.614895782470704, "val_acc": 52.0}
{"epoch": 31, "training_loss": 26.490228881835936, "training_acc": 45.0, "val_loss": 29.754937744140626, "val_acc": 52.0}
{"epoch": 32, "training_loss": 17.038487548828126, "training_acc": 41.0, "val_loss": 35.030753173828124, "val_acc": 48.0}
{"epoch": 33, "training_loss": 26.960272827148437, "training_acc": 47.0, "val_loss": 22.83512710571289, "val_acc": 48.0}
{"epoch": 34, "training_loss": 8.899795532226562, "training_acc": 55.0, "val_loss": 8.61560131072998, "val_acc": 48.0}
{"epoch": 35, "training_loss": 9.382482719421386, "training_acc": 51.0, "val_loss": 32.924375762939455, "val_acc": 48.0}
{"epoch": 36, "training_loss": 14.91835560798645, "training_acc": 55.0, "val_loss": 16.0156383895874, "val_acc": 52.0}
{"epoch": 37, "training_loss": 17.468168487548827, "training_acc": 53.0, "val_loss": 10.432227020263673, "val_acc": 52.0}
{"epoch": 38, "training_loss": 13.557644538879394, "training_acc": 46.0, "val_loss": 2.5767363834381105, "val_acc": 56.0}
{"epoch": 39, "training_loss": 27.45599905490875, "training_acc": 41.0, "val_loss": 22.4044815826416, "val_acc": 52.0}
{"epoch": 40, "training_loss": 28.4146063041687, "training_acc": 50.0, "val_loss": 22.51193878173828, "val_acc": 52.0}
{"epoch": 41, "training_loss": 21.9324409866333, "training_acc": 53.0, "val_loss": 45.47602188110351, "val_acc": 52.0}
