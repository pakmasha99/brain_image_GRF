"main_modify.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 6 --task ADNI_sex --input_option yAware --learning_rate 1e0 --batch_size 16 --weight_decay 1e-2 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 102.77979078292847, "training_acc": 53.0, "val_loss": 16.502242431640624, "val_acc": 48.0}
{"epoch": 1, "training_loss": 50.11671493530273, "training_acc": 45.0, "val_loss": 17.385101356506347, "val_acc": 48.0}
{"epoch": 2, "training_loss": 22.288603477478027, "training_acc": 43.0, "val_loss": 75.9140640258789, "val_acc": 48.0}
{"epoch": 3, "training_loss": 54.86962646484375, "training_acc": 51.0, "val_loss": 29.494639053344727, "val_acc": 52.0}
{"epoch": 4, "training_loss": 20.029809951782227, "training_acc": 45.0, "val_loss": 6.417752723693848, "val_acc": 48.0}
{"epoch": 5, "training_loss": 11.697762317657471, "training_acc": 57.0, "val_loss": 5.242065830230713, "val_acc": 52.0}
{"epoch": 6, "training_loss": 8.57671248435974, "training_acc": 53.0, "val_loss": 2.6683394432067873, "val_acc": 52.0}
{"epoch": 7, "training_loss": 9.478055791854858, "training_acc": 55.0, "val_loss": 13.07011978149414, "val_acc": 52.0}
{"epoch": 8, "training_loss": 19.498285522460936, "training_acc": 49.0, "val_loss": 29.37932289123535, "val_acc": 52.0}
{"epoch": 9, "training_loss": 31.413246841430663, "training_acc": 55.0, "val_loss": 4.109775619506836, "val_acc": 52.0}
{"epoch": 10, "training_loss": 21.485903282165527, "training_acc": 45.0, "val_loss": 47.87007507324219, "val_acc": 48.0}
{"epoch": 11, "training_loss": 25.596065635681153, "training_acc": 51.0, "val_loss": 26.062471008300783, "val_acc": 48.0}
{"epoch": 12, "training_loss": 18.39244697570801, "training_acc": 41.0, "val_loss": 47.30491928100586, "val_acc": 52.0}
{"epoch": 13, "training_loss": 29.230162048339842, "training_acc": 45.0, "val_loss": 13.17096549987793, "val_acc": 52.0}
{"epoch": 14, "training_loss": 28.331077880859375, "training_acc": 49.0, "val_loss": 40.222453918457035, "val_acc": 52.0}
{"epoch": 15, "training_loss": 26.255883255004882, "training_acc": 51.0, "val_loss": 35.084883270263674, "val_acc": 52.0}
{"epoch": 16, "training_loss": 26.75593521118164, "training_acc": 55.0, "val_loss": 19.31624282836914, "val_acc": 52.0}
{"epoch": 17, "training_loss": 35.98795894622803, "training_acc": 49.0, "val_loss": 25.89213920593262, "val_acc": 48.0}
{"epoch": 18, "training_loss": 39.836984424591066, "training_acc": 45.0, "val_loss": 22.4512890625, "val_acc": 48.0}
{"epoch": 19, "training_loss": 24.554838275909425, "training_acc": 45.0, "val_loss": 1.226901545524597, "val_acc": 48.0}
{"epoch": 20, "training_loss": 46.05793613433838, "training_acc": 43.0, "val_loss": 98.81793243408202, "val_acc": 48.0}
{"epoch": 21, "training_loss": 63.88721618652344, "training_acc": 51.0, "val_loss": 58.01975708007812, "val_acc": 52.0}
{"epoch": 22, "training_loss": 41.07867225646973, "training_acc": 45.0, "val_loss": 35.502134246826174, "val_acc": 52.0}
{"epoch": 23, "training_loss": 30.26297367095947, "training_acc": 55.0, "val_loss": 1.2407175636291503, "val_acc": 48.0}
{"epoch": 24, "training_loss": 19.779449653625488, "training_acc": 53.0, "val_loss": 1.5291706275939942, "val_acc": 48.0}
{"epoch": 25, "training_loss": 33.859271392822265, "training_acc": 57.0, "val_loss": 33.171513366699216, "val_acc": 48.0}
{"epoch": 26, "training_loss": 15.051318264007568, "training_acc": 45.0, "val_loss": 11.948316154479981, "val_acc": 48.0}
{"epoch": 27, "training_loss": 10.0335701751709, "training_acc": 53.0, "val_loss": 6.252044925689697, "val_acc": 48.0}
{"epoch": 28, "training_loss": 13.995570755004882, "training_acc": 47.0, "val_loss": 26.05562644958496, "val_acc": 48.0}
{"epoch": 29, "training_loss": 34.89494377136231, "training_acc": 39.0, "val_loss": 35.893404693603514, "val_acc": 48.0}
{"epoch": 30, "training_loss": 13.977135467529298, "training_acc": 69.0, "val_loss": 15.180280227661132, "val_acc": 48.0}
{"epoch": 31, "training_loss": 15.610137939453125, "training_acc": 57.0, "val_loss": 16.180942764282225, "val_acc": 48.0}
{"epoch": 32, "training_loss": 26.077738342285155, "training_acc": 45.0, "val_loss": 13.69512134552002, "val_acc": 52.0}
{"epoch": 33, "training_loss": 21.566800079345704, "training_acc": 47.0, "val_loss": 13.81400562286377, "val_acc": 52.0}
{"epoch": 34, "training_loss": 13.255278778076171, "training_acc": 45.0, "val_loss": 1.8367458629608153, "val_acc": 52.0}
{"epoch": 35, "training_loss": 10.000935726165771, "training_acc": 47.0, "val_loss": 12.031092376708985, "val_acc": 52.0}
{"epoch": 36, "training_loss": 12.700726585388184, "training_acc": 53.0, "val_loss": 49.15235549926758, "val_acc": 48.0}
{"epoch": 37, "training_loss": 30.305134468078613, "training_acc": 49.0, "val_loss": 13.208328590393066, "val_acc": 48.0}
{"epoch": 38, "training_loss": 11.635663919448852, "training_acc": 51.0, "val_loss": 32.78569923400879, "val_acc": 52.0}
