"main_modify.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 5 --task ADNI_sex --input_option yAware --learning_rate 1e0 --batch_size 16 --weight_decay 1e-2 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 79.14428833961487, "training_acc": 53.0, "val_loss": 50.48875534057617, "val_acc": 52.0}
{"epoch": 1, "training_loss": 31.569658203125, "training_acc": 58.0, "val_loss": 67.19487716674804, "val_acc": 52.0}
{"epoch": 2, "training_loss": 51.672048797607424, "training_acc": 46.0, "val_loss": 38.36777572631836, "val_acc": 52.0}
{"epoch": 3, "training_loss": 35.54830238342285, "training_acc": 52.0, "val_loss": 2.5238809108734133, "val_acc": 48.0}
{"epoch": 4, "training_loss": 33.62305087089538, "training_acc": 46.0, "val_loss": 93.75368225097657, "val_acc": 48.0}
{"epoch": 5, "training_loss": 59.409438858032225, "training_acc": 54.0, "val_loss": 26.74857940673828, "val_acc": 52.0}
{"epoch": 6, "training_loss": 25.854042358398438, "training_acc": 52.0, "val_loss": 43.0303857421875, "val_acc": 52.0}
{"epoch": 7, "training_loss": 27.39775276184082, "training_acc": 50.0, "val_loss": 68.76764556884766, "val_acc": 52.0}
{"epoch": 8, "training_loss": 51.99299228668213, "training_acc": 50.0, "val_loss": 49.04117172241211, "val_acc": 48.0}
{"epoch": 9, "training_loss": 86.05270797729492, "training_acc": 46.0, "val_loss": 24.037590637207032, "val_acc": 52.0}
{"epoch": 10, "training_loss": 116.344873046875, "training_acc": 46.0, "val_loss": 19.904600944519043, "val_acc": 48.0}
{"epoch": 11, "training_loss": 128.24230895996095, "training_acc": 48.0, "val_loss": 57.363283233642576, "val_acc": 52.0}
{"epoch": 12, "training_loss": 68.6211782836914, "training_acc": 48.0, "val_loss": 50.57609832763672, "val_acc": 52.0}
{"epoch": 13, "training_loss": 72.0871915435791, "training_acc": 52.0, "val_loss": 80.94176544189453, "val_acc": 48.0}
{"epoch": 14, "training_loss": 62.21978500366211, "training_acc": 52.0, "val_loss": 79.68739440917969, "val_acc": 52.0}
{"epoch": 15, "training_loss": 50.26965087890625, "training_acc": 54.0, "val_loss": 104.2033267211914, "val_acc": 48.0}
{"epoch": 16, "training_loss": 48.2296210861206, "training_acc": 54.0, "val_loss": 0.7207482933998108, "val_acc": 48.0}
{"epoch": 17, "training_loss": 13.045908203125, "training_acc": 46.0, "val_loss": 12.914930572509766, "val_acc": 48.0}
{"epoch": 18, "training_loss": 7.610776023864746, "training_acc": 54.0, "val_loss": 32.21536865234375, "val_acc": 52.0}
{"epoch": 19, "training_loss": 23.851405639648437, "training_acc": 44.0, "val_loss": 18.951844787597658, "val_acc": 52.0}
{"epoch": 20, "training_loss": 15.654721908569336, "training_acc": 46.0, "val_loss": 4.137549705505371, "val_acc": 52.0}
{"epoch": 21, "training_loss": 6.384884262084961, "training_acc": 44.0, "val_loss": 9.292208633422852, "val_acc": 52.0}
{"epoch": 22, "training_loss": 11.947496461868287, "training_acc": 48.0, "val_loss": 31.79383529663086, "val_acc": 48.0}
{"epoch": 23, "training_loss": 23.98928575515747, "training_acc": 44.0, "val_loss": 27.63598274230957, "val_acc": 48.0}
{"epoch": 24, "training_loss": 16.39847589492798, "training_acc": 56.0, "val_loss": 17.411447601318358, "val_acc": 48.0}
{"epoch": 25, "training_loss": 10.58738380432129, "training_acc": 48.0, "val_loss": 9.355352325439453, "val_acc": 48.0}
{"epoch": 26, "training_loss": 13.337670631408692, "training_acc": 44.0, "val_loss": 47.71898468017578, "val_acc": 48.0}
{"epoch": 27, "training_loss": 24.16750274658203, "training_acc": 44.0, "val_loss": 0.8090251970291138, "val_acc": 48.0}
{"epoch": 28, "training_loss": 20.049325380325318, "training_acc": 50.0, "val_loss": 1.634513487815857, "val_acc": 48.0}
{"epoch": 29, "training_loss": 30.266065559387208, "training_acc": 50.0, "val_loss": 25.821350708007813, "val_acc": 48.0}
{"epoch": 30, "training_loss": 14.784510879516601, "training_acc": 50.0, "val_loss": 18.988926429748535, "val_acc": 52.0}
{"epoch": 31, "training_loss": 10.601716346740723, "training_acc": 52.0, "val_loss": 38.262771911621094, "val_acc": 48.0}
{"epoch": 32, "training_loss": 24.723232440948486, "training_acc": 50.0, "val_loss": 3.560131702423096, "val_acc": 48.0}
{"epoch": 33, "training_loss": 13.808494701385499, "training_acc": 56.0, "val_loss": 22.56243755340576, "val_acc": 52.0}
{"epoch": 34, "training_loss": 19.437560272216796, "training_acc": 50.0, "val_loss": 16.67539447784424, "val_acc": 52.0}
{"epoch": 35, "training_loss": 5.43815239906311, "training_acc": 57.0, "val_loss": 24.385193367004394, "val_acc": 48.0}
