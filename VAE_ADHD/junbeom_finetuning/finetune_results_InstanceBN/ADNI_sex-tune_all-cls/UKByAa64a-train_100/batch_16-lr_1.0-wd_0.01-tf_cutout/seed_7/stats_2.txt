"main_modify.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 7 --task ADNI_sex --input_option yAware --learning_rate 1e0 --batch_size 16 --weight_decay 1e-2 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 124.93128429412842, "training_acc": 50.0, "val_loss": 13.384681282043458, "val_acc": 48.0}
{"epoch": 1, "training_loss": 131.3836993408203, "training_acc": 46.0, "val_loss": 0.746612446308136, "val_acc": 48.0}
{"epoch": 2, "training_loss": 82.08582862854004, "training_acc": 50.0, "val_loss": 25.895148162841796, "val_acc": 52.0}
{"epoch": 3, "training_loss": 68.26120025634765, "training_acc": 48.0, "val_loss": 53.01460464477539, "val_acc": 48.0}
{"epoch": 4, "training_loss": 46.159307403564455, "training_acc": 40.0, "val_loss": 43.77946502685547, "val_acc": 48.0}
{"epoch": 5, "training_loss": 50.69654846191406, "training_acc": 48.0, "val_loss": 43.79197723388672, "val_acc": 52.0}
{"epoch": 6, "training_loss": 25.49192367553711, "training_acc": 60.0, "val_loss": 1.1858841943740845, "val_acc": 48.0}
{"epoch": 7, "training_loss": 22.275135135650636, "training_acc": 56.0, "val_loss": 12.332432746887207, "val_acc": 48.0}
{"epoch": 8, "training_loss": 5.865857009887695, "training_acc": 58.0, "val_loss": 18.64533073425293, "val_acc": 48.0}
{"epoch": 9, "training_loss": 20.034274973869323, "training_acc": 52.0, "val_loss": 8.333733863830567, "val_acc": 48.0}
{"epoch": 10, "training_loss": 7.291744174957276, "training_acc": 50.0, "val_loss": 29.067444686889647, "val_acc": 48.0}
{"epoch": 11, "training_loss": 29.5214892578125, "training_acc": 48.0, "val_loss": 59.78599319458008, "val_acc": 48.0}
{"epoch": 12, "training_loss": 37.021156311035156, "training_acc": 44.0, "val_loss": 2.439435291290283, "val_acc": 48.0}
{"epoch": 13, "training_loss": 13.488544616699219, "training_acc": 58.0, "val_loss": 4.080987720489502, "val_acc": 48.0}
{"epoch": 14, "training_loss": 12.652156372070312, "training_acc": 52.0, "val_loss": 0.7090459179878235, "val_acc": 48.0}
{"epoch": 15, "training_loss": 9.867371687889099, "training_acc": 50.0, "val_loss": 17.797571105957033, "val_acc": 52.0}
{"epoch": 16, "training_loss": 9.464823379516602, "training_acc": 56.0, "val_loss": 22.04826057434082, "val_acc": 48.0}
{"epoch": 17, "training_loss": 24.41212640762329, "training_acc": 46.0, "val_loss": 9.997517204284668, "val_acc": 48.0}
{"epoch": 18, "training_loss": 26.687401580810548, "training_acc": 46.0, "val_loss": 16.763337554931642, "val_acc": 48.0}
{"epoch": 19, "training_loss": 40.87393600463867, "training_acc": 46.0, "val_loss": 82.90595245361328, "val_acc": 48.0}
{"epoch": 20, "training_loss": 77.93537574768067, "training_acc": 38.0, "val_loss": 39.80390243530273, "val_acc": 52.0}
{"epoch": 21, "training_loss": 49.15248275756836, "training_acc": 50.0, "val_loss": 32.06853530883789, "val_acc": 52.0}
{"epoch": 22, "training_loss": 56.325035400390625, "training_acc": 48.0, "val_loss": 79.5258364868164, "val_acc": 48.0}
{"epoch": 23, "training_loss": 54.84765937805176, "training_acc": 50.0, "val_loss": 28.54626190185547, "val_acc": 52.0}
{"epoch": 24, "training_loss": 28.77578227996826, "training_acc": 56.0, "val_loss": 36.65910598754883, "val_acc": 52.0}
{"epoch": 25, "training_loss": 34.856721801757814, "training_acc": 46.0, "val_loss": 36.48513427734375, "val_acc": 52.0}
{"epoch": 26, "training_loss": 47.09253639221191, "training_acc": 50.0, "val_loss": 78.05770690917969, "val_acc": 48.0}
{"epoch": 27, "training_loss": 47.91202056884766, "training_acc": 52.0, "val_loss": 3.2288206672668456, "val_acc": 52.0}
{"epoch": 28, "training_loss": 46.26716682434082, "training_acc": 54.0, "val_loss": 55.271713409423825, "val_acc": 52.0}
{"epoch": 29, "training_loss": 53.72243209838867, "training_acc": 40.0, "val_loss": 5.305197105407715, "val_acc": 52.0}
{"epoch": 30, "training_loss": 17.01962959289551, "training_acc": 50.0, "val_loss": 21.853074417114257, "val_acc": 52.0}
{"epoch": 31, "training_loss": 19.429389991760253, "training_acc": 44.0, "val_loss": 48.71870132446289, "val_acc": 52.0}
{"epoch": 32, "training_loss": 29.31804735183716, "training_acc": 54.0, "val_loss": 7.113735046386719, "val_acc": 52.0}
{"epoch": 33, "training_loss": 13.468224143981933, "training_acc": 50.0, "val_loss": 47.87076431274414, "val_acc": 48.0}
