"main_modify.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 3 --task ADNI_sex --input_option yAware --learning_rate 1e0 --batch_size 16 --weight_decay 1e-2 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 146.8237050819397, "training_acc": 44.0, "val_loss": 35.15305023193359, "val_acc": 48.0}
{"epoch": 1, "training_loss": 126.79466003417969, "training_acc": 46.0, "val_loss": 5.486607780456543, "val_acc": 52.0}
{"epoch": 2, "training_loss": 106.9875245666504, "training_acc": 54.0, "val_loss": 64.36271362304687, "val_acc": 48.0}
{"epoch": 3, "training_loss": 35.46012657165527, "training_acc": 48.0, "val_loss": 37.077321166992185, "val_acc": 48.0}
{"epoch": 4, "training_loss": 20.67678840637207, "training_acc": 54.0, "val_loss": 3.9035595703125, "val_acc": 48.0}
{"epoch": 5, "training_loss": 13.624430284500122, "training_acc": 46.0, "val_loss": 7.195356216430664, "val_acc": 48.0}
{"epoch": 6, "training_loss": 7.219197940826416, "training_acc": 50.0, "val_loss": 39.12035873413086, "val_acc": 52.0}
{"epoch": 7, "training_loss": 32.47390975952148, "training_acc": 52.0, "val_loss": 13.808178863525391, "val_acc": 48.0}
{"epoch": 8, "training_loss": 21.06934913635254, "training_acc": 48.0, "val_loss": 19.696960525512694, "val_acc": 52.0}
{"epoch": 9, "training_loss": 20.261138863563538, "training_acc": 44.0, "val_loss": 9.324713706970215, "val_acc": 52.0}
{"epoch": 10, "training_loss": 7.762150344848632, "training_acc": 46.0, "val_loss": 6.098707962036133, "val_acc": 48.0}
{"epoch": 11, "training_loss": 14.011544723510742, "training_acc": 54.0, "val_loss": 1.7209136056900025, "val_acc": 48.0}
{"epoch": 12, "training_loss": 11.034699172973633, "training_acc": 48.0, "val_loss": 21.71051040649414, "val_acc": 48.0}
{"epoch": 13, "training_loss": 10.714817657470704, "training_acc": 52.0, "val_loss": 4.565591278076172, "val_acc": 48.0}
{"epoch": 14, "training_loss": 7.78061243057251, "training_acc": 50.0, "val_loss": 3.0694726943969726, "val_acc": 48.0}
{"epoch": 15, "training_loss": 17.462179222106933, "training_acc": 52.0, "val_loss": 29.3608740234375, "val_acc": 52.0}
{"epoch": 16, "training_loss": 30.829844665527343, "training_acc": 42.0, "val_loss": 42.83641555786133, "val_acc": 52.0}
{"epoch": 17, "training_loss": 21.29006054878235, "training_acc": 60.0, "val_loss": 24.889829483032226, "val_acc": 52.0}
{"epoch": 18, "training_loss": 12.43078899383545, "training_acc": 50.0, "val_loss": 39.89066307067871, "val_acc": 48.0}
{"epoch": 19, "training_loss": 23.51998046875, "training_acc": 52.0, "val_loss": 39.900742797851564, "val_acc": 48.0}
{"epoch": 20, "training_loss": 38.17888046264648, "training_acc": 46.0, "val_loss": 20.790450820922853, "val_acc": 48.0}
{"epoch": 21, "training_loss": 22.65151023864746, "training_acc": 40.0, "val_loss": 12.535835151672364, "val_acc": 52.0}
{"epoch": 22, "training_loss": 32.66060657501221, "training_acc": 46.0, "val_loss": 33.5126774597168, "val_acc": 52.0}
{"epoch": 23, "training_loss": 60.688967590332034, "training_acc": 40.0, "val_loss": 50.257973175048825, "val_acc": 48.0}
{"epoch": 24, "training_loss": 48.394000396728515, "training_acc": 50.0, "val_loss": 38.9845751953125, "val_acc": 48.0}
{"epoch": 25, "training_loss": 67.14300537109375, "training_acc": 48.0, "val_loss": 50.479486083984376, "val_acc": 52.0}
{"epoch": 26, "training_loss": 35.78627838134766, "training_acc": 56.0, "val_loss": 45.282627716064454, "val_acc": 48.0}
{"epoch": 27, "training_loss": 44.236486287117, "training_acc": 48.0, "val_loss": 37.20763717651367, "val_acc": 48.0}
{"epoch": 28, "training_loss": 38.08731483459473, "training_acc": 52.0, "val_loss": 75.13663482666016, "val_acc": 52.0}
{"epoch": 29, "training_loss": 39.44991683959961, "training_acc": 56.0, "val_loss": 15.22193862915039, "val_acc": 52.0}
{"epoch": 30, "training_loss": 15.768798923492431, "training_acc": 48.0, "val_loss": 27.82774230957031, "val_acc": 52.0}
{"epoch": 31, "training_loss": 30.41994152069092, "training_acc": 40.0, "val_loss": 0.9479224872589112, "val_acc": 48.0}
{"epoch": 32, "training_loss": 10.243387603759766, "training_acc": 44.0, "val_loss": 8.233520183563233, "val_acc": 48.0}
{"epoch": 33, "training_loss": 9.327624988555907, "training_acc": 54.0, "val_loss": 9.338466796875, "val_acc": 52.0}
{"epoch": 34, "training_loss": 15.223159770965577, "training_acc": 54.0, "val_loss": 13.463094177246093, "val_acc": 52.0}
{"epoch": 35, "training_loss": 8.403716850280762, "training_acc": 46.0, "val_loss": 51.95183090209961, "val_acc": 48.0}
{"epoch": 36, "training_loss": 28.104983406066893, "training_acc": 54.0, "val_loss": 14.035723152160644, "val_acc": 48.0}
{"epoch": 37, "training_loss": 18.08038299560547, "training_acc": 48.0, "val_loss": 3.2019745445251466, "val_acc": 52.0}
{"epoch": 38, "training_loss": 7.431018848419189, "training_acc": 58.0, "val_loss": 3.73461651802063, "val_acc": 48.0}
{"epoch": 39, "training_loss": 9.9374409198761, "training_acc": 50.0, "val_loss": 26.10542953491211, "val_acc": 48.0}
{"epoch": 40, "training_loss": 22.199447288513184, "training_acc": 60.0, "val_loss": 26.713574523925782, "val_acc": 52.0}
{"epoch": 41, "training_loss": 20.066268539428712, "training_acc": 44.0, "val_loss": 1.1585778093338013, "val_acc": 48.0}
{"epoch": 42, "training_loss": 21.07325125694275, "training_acc": 42.0, "val_loss": 0.7830822730064392, "val_acc": 48.0}
{"epoch": 43, "training_loss": 8.576200742721557, "training_acc": 54.0, "val_loss": 4.778889217376709, "val_acc": 52.0}
{"epoch": 44, "training_loss": 7.486761550903321, "training_acc": 54.0, "val_loss": 23.359826583862304, "val_acc": 52.0}
{"epoch": 45, "training_loss": 15.895695343017579, "training_acc": 58.0, "val_loss": 3.3540899085998537, "val_acc": 52.0}
{"epoch": 46, "training_loss": 5.867251181602478, "training_acc": 56.0, "val_loss": 19.68000862121582, "val_acc": 52.0}
{"epoch": 47, "training_loss": 26.92377758026123, "training_acc": 52.0, "val_loss": 25.42320442199707, "val_acc": 52.0}
{"epoch": 48, "training_loss": 38.35383697509766, "training_acc": 48.0, "val_loss": 13.51909278869629, "val_acc": 48.0}
{"epoch": 49, "training_loss": 44.90117118835449, "training_acc": 48.0, "val_loss": 30.74979949951172, "val_acc": 48.0}
{"epoch": 50, "training_loss": 20.50862497329712, "training_acc": 56.0, "val_loss": 17.23051509857178, "val_acc": 48.0}
{"epoch": 51, "training_loss": 26.188654899597168, "training_acc": 48.0, "val_loss": 40.86074768066406, "val_acc": 48.0}
{"epoch": 52, "training_loss": 34.45183280944824, "training_acc": 52.0, "val_loss": 9.463190383911133, "val_acc": 48.0}
{"epoch": 53, "training_loss": 12.636946430206299, "training_acc": 48.0, "val_loss": 1.96221905708313, "val_acc": 48.0}
{"epoch": 54, "training_loss": 12.704275207519531, "training_acc": 50.0, "val_loss": 37.02799301147461, "val_acc": 52.0}
{"epoch": 55, "training_loss": 30.15104721069336, "training_acc": 40.0, "val_loss": 68.61980056762695, "val_acc": 52.0}
{"epoch": 56, "training_loss": 42.74771820068359, "training_acc": 40.0, "val_loss": 21.572983169555663, "val_acc": 52.0}
{"epoch": 57, "training_loss": 15.038416900634765, "training_acc": 56.0, "val_loss": 1.2316309547424316, "val_acc": 52.0}
{"epoch": 58, "training_loss": 6.625358219146729, "training_acc": 54.0, "val_loss": 8.286247177124023, "val_acc": 48.0}
{"epoch": 59, "training_loss": 3.855344543457031, "training_acc": 60.0, "val_loss": 5.840998477935791, "val_acc": 48.0}
{"epoch": 60, "training_loss": 31.12030212402344, "training_acc": 44.0, "val_loss": 33.33656532287598, "val_acc": 48.0}
{"epoch": 61, "training_loss": 9.914346361160279, "training_acc": 52.0, "val_loss": 7.36805269241333, "val_acc": 52.0}
