"main_modify.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 3 --task ADNI_sex --input_option yAware --learning_rate 1e0 --batch_size 16 --weight_decay 1e-2 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 85.24670434951783, "training_acc": 45.0, "val_loss": 19.463623809814454, "val_acc": 48.0}
{"epoch": 1, "training_loss": 19.222639045715333, "training_acc": 47.0, "val_loss": 6.336936874389648, "val_acc": 48.0}
{"epoch": 2, "training_loss": 19.623353900909425, "training_acc": 39.0, "val_loss": 34.538215255737306, "val_acc": 52.0}
{"epoch": 3, "training_loss": 41.34256622314453, "training_acc": 49.0, "val_loss": 18.05471778869629, "val_acc": 48.0}
{"epoch": 4, "training_loss": 23.04512607574463, "training_acc": 51.0, "val_loss": 45.7319571685791, "val_acc": 48.0}
{"epoch": 5, "training_loss": 40.35621685028076, "training_acc": 55.0, "val_loss": 21.06159610748291, "val_acc": 52.0}
{"epoch": 6, "training_loss": 51.92162419080734, "training_acc": 49.0, "val_loss": 40.27244705200195, "val_acc": 52.0}
{"epoch": 7, "training_loss": 42.10663808822632, "training_acc": 51.0, "val_loss": 73.01282440185547, "val_acc": 48.0}
{"epoch": 8, "training_loss": 63.0651399230957, "training_acc": 43.0, "val_loss": 23.40360633850098, "val_acc": 52.0}
{"epoch": 9, "training_loss": 44.539121532440184, "training_acc": 49.0, "val_loss": 32.94543045043945, "val_acc": 52.0}
{"epoch": 10, "training_loss": 26.69102294921875, "training_acc": 59.0, "val_loss": 46.29696319580078, "val_acc": 48.0}
{"epoch": 11, "training_loss": 24.70889060974121, "training_acc": 53.0, "val_loss": 64.33422302246093, "val_acc": 48.0}
{"epoch": 12, "training_loss": 53.81574035644531, "training_acc": 43.0, "val_loss": 21.674573135375976, "val_acc": 52.0}
{"epoch": 13, "training_loss": 38.48448089599609, "training_acc": 51.0, "val_loss": 44.83904266357422, "val_acc": 52.0}
{"epoch": 14, "training_loss": 46.062604064941404, "training_acc": 51.0, "val_loss": 68.7220083618164, "val_acc": 48.0}
{"epoch": 15, "training_loss": 38.795095901489255, "training_acc": 49.0, "val_loss": 36.70028961181641, "val_acc": 48.0}
{"epoch": 16, "training_loss": 28.163110065460206, "training_acc": 53.0, "val_loss": 38.203868255615234, "val_acc": 48.0}
{"epoch": 17, "training_loss": 47.309223327636715, "training_acc": 49.0, "val_loss": 80.3025244140625, "val_acc": 52.0}
{"epoch": 18, "training_loss": 51.30113098144531, "training_acc": 47.0, "val_loss": 8.561906623840333, "val_acc": 52.0}
{"epoch": 19, "training_loss": 17.75064311981201, "training_acc": 57.0, "val_loss": 5.3776204299926755, "val_acc": 48.0}
{"epoch": 20, "training_loss": 7.802743701934815, "training_acc": 53.0, "val_loss": 26.439083404541016, "val_acc": 52.0}
{"epoch": 21, "training_loss": 23.63687400817871, "training_acc": 51.0, "val_loss": 63.26505416870117, "val_acc": 52.0}
{"epoch": 22, "training_loss": 59.245674781799316, "training_acc": 45.0, "val_loss": 55.106721801757814, "val_acc": 48.0}
{"epoch": 23, "training_loss": 73.80140533447266, "training_acc": 47.0, "val_loss": 2.6829377174377442, "val_acc": 52.0}
{"epoch": 24, "training_loss": 86.93127319335937, "training_acc": 51.0, "val_loss": 19.7495499420166, "val_acc": 48.0}
{"epoch": 25, "training_loss": 67.76485412597657, "training_acc": 57.0, "val_loss": 2.505091438293457, "val_acc": 52.0}
{"epoch": 26, "training_loss": 105.47857833862305, "training_acc": 43.0, "val_loss": 10.069485549926759, "val_acc": 48.0}
{"epoch": 27, "training_loss": 82.25030746459962, "training_acc": 53.0, "val_loss": 12.164954032897949, "val_acc": 52.0}
{"epoch": 28, "training_loss": 84.84905647277832, "training_acc": 49.0, "val_loss": 9.601540508270263, "val_acc": 48.0}
{"epoch": 29, "training_loss": 66.5796395111084, "training_acc": 45.0, "val_loss": 19.235063552856445, "val_acc": 48.0}
{"epoch": 30, "training_loss": 11.18522216796875, "training_acc": 51.0, "val_loss": 47.04912796020508, "val_acc": 48.0}
{"epoch": 31, "training_loss": 44.415587158203124, "training_acc": 51.0, "val_loss": 51.68711410522461, "val_acc": 52.0}
{"epoch": 32, "training_loss": 21.939524307250977, "training_acc": 55.0, "val_loss": 46.655094909667966, "val_acc": 52.0}
{"epoch": 33, "training_loss": 41.84308120727539, "training_acc": 47.0, "val_loss": 25.58223861694336, "val_acc": 52.0}
{"epoch": 34, "training_loss": 35.59317314147949, "training_acc": 55.0, "val_loss": 76.15111297607422, "val_acc": 48.0}
{"epoch": 35, "training_loss": 67.41819038391114, "training_acc": 43.0, "val_loss": 71.86434051513672, "val_acc": 52.0}
{"epoch": 36, "training_loss": NaN, "training_acc": 45.0, "val_loss": NaN, "val_acc": 52.0}
{"epoch": 37, "training_loss": NaN, "training_acc": 49.0, "val_loss": NaN, "val_acc": 52.0}
{"epoch": 38, "training_loss": NaN, "training_acc": 49.0, "val_loss": NaN, "val_acc": 52.0}
{"epoch": 39, "training_loss": NaN, "training_acc": 49.0, "val_loss": NaN, "val_acc": 52.0}
{"epoch": 40, "training_loss": NaN, "training_acc": 49.0, "val_loss": NaN, "val_acc": 52.0}
{"epoch": 41, "training_loss": NaN, "training_acc": 49.0, "val_loss": NaN, "val_acc": 52.0}
{"epoch": 42, "training_loss": NaN, "training_acc": 49.0, "val_loss": NaN, "val_acc": 52.0}
{"epoch": 43, "training_loss": NaN, "training_acc": 49.0, "val_loss": NaN, "val_acc": 52.0}
{"epoch": 44, "training_loss": NaN, "training_acc": 49.0, "val_loss": NaN, "val_acc": 52.0}
{"epoch": 45, "training_loss": NaN, "training_acc": 49.0, "val_loss": NaN, "val_acc": 52.0}
{"epoch": 46, "training_loss": NaN, "training_acc": 49.0, "val_loss": NaN, "val_acc": 52.0}
{"epoch": 47, "training_loss": NaN, "training_acc": 49.0, "val_loss": NaN, "val_acc": 52.0}
{"epoch": 48, "training_loss": NaN, "training_acc": 49.0, "val_loss": NaN, "val_acc": 52.0}
{"epoch": 49, "training_loss": NaN, "training_acc": 49.0, "val_loss": NaN, "val_acc": 52.0}
{"epoch": 50, "training_loss": NaN, "training_acc": 49.0, "val_loss": NaN, "val_acc": 52.0}
{"epoch": 51, "training_loss": NaN, "training_acc": 49.0, "val_loss": NaN, "val_acc": 52.0}
{"epoch": 52, "training_loss": NaN, "training_acc": 49.0, "val_loss": NaN, "val_acc": 52.0}
{"epoch": 53, "training_loss": NaN, "training_acc": 49.0, "val_loss": NaN, "val_acc": 52.0}
{"epoch": 54, "training_loss": NaN, "training_acc": 49.0, "val_loss": NaN, "val_acc": 52.0}
{"epoch": 55, "training_loss": NaN, "training_acc": 49.0, "val_loss": NaN, "val_acc": 52.0}
{"epoch": 56, "training_loss": NaN, "training_acc": 49.0, "val_loss": NaN, "val_acc": 52.0}
{"epoch": 57, "training_loss": NaN, "training_acc": 49.0, "val_loss": NaN, "val_acc": 52.0}
{"epoch": 58, "training_loss": NaN, "training_acc": 49.0, "val_loss": NaN, "val_acc": 52.0}
{"epoch": 59, "training_loss": NaN, "training_acc": 49.0, "val_loss": NaN, "val_acc": 52.0}
{"epoch": 60, "training_loss": NaN, "training_acc": 49.0, "val_loss": NaN, "val_acc": 52.0}
{"epoch": 61, "training_loss": NaN, "training_acc": 49.0, "val_loss": NaN, "val_acc": 52.0}
{"epoch": 62, "training_loss": NaN, "training_acc": 49.0, "val_loss": NaN, "val_acc": 52.0}
{"epoch": 63, "training_loss": NaN, "training_acc": 49.0, "val_loss": NaN, "val_acc": 52.0}
{"epoch": 64, "training_loss": NaN, "training_acc": 49.0, "val_loss": NaN, "val_acc": 52.0}
{"epoch": 65, "training_loss": NaN, "training_acc": 49.0, "val_loss": NaN, "val_acc": 52.0}
{"epoch": 66, "training_loss": NaN, "training_acc": 49.0, "val_loss": NaN, "val_acc": 52.0}
{"epoch": 67, "training_loss": NaN, "training_acc": 49.0, "val_loss": NaN, "val_acc": 52.0}
{"epoch": 68, "training_loss": NaN, "training_acc": 49.0, "val_loss": NaN, "val_acc": 52.0}
{"epoch": 69, "training_loss": NaN, "training_acc": 49.0, "val_loss": NaN, "val_acc": 52.0}
{"epoch": 70, "training_loss": NaN, "training_acc": 49.0, "val_loss": NaN, "val_acc": 52.0}
{"epoch": 71, "training_loss": NaN, "training_acc": 49.0, "val_loss": NaN, "val_acc": 52.0}
{"epoch": 72, "training_loss": NaN, "training_acc": 49.0, "val_loss": NaN, "val_acc": 52.0}
{"epoch": 73, "training_loss": NaN, "training_acc": 49.0, "val_loss": NaN, "val_acc": 52.0}
{"epoch": 74, "training_loss": NaN, "training_acc": 49.0, "val_loss": NaN, "val_acc": 52.0}
{"epoch": 75, "training_loss": NaN, "training_acc": 49.0, "val_loss": NaN, "val_acc": 52.0}
{"epoch": 76, "training_loss": NaN, "training_acc": 49.0, "val_loss": NaN, "val_acc": 52.0}
{"epoch": 77, "training_loss": NaN, "training_acc": 49.0, "val_loss": NaN, "val_acc": 52.0}
{"epoch": 78, "training_loss": NaN, "training_acc": 49.0, "val_loss": NaN, "val_acc": 52.0}
{"epoch": 79, "training_loss": NaN, "training_acc": 49.0, "val_loss": NaN, "val_acc": 52.0}
{"epoch": 80, "training_loss": NaN, "training_acc": 49.0, "val_loss": NaN, "val_acc": 52.0}
{"epoch": 81, "training_loss": NaN, "training_acc": 49.0, "val_loss": NaN, "val_acc": 52.0}
{"epoch": 82, "training_loss": NaN, "training_acc": 49.0, "val_loss": NaN, "val_acc": 52.0}
{"epoch": 83, "training_loss": NaN, "training_acc": 49.0, "val_loss": NaN, "val_acc": 52.0}
{"epoch": 84, "training_loss": NaN, "training_acc": 49.0, "val_loss": NaN, "val_acc": 52.0}
{"epoch": 85, "training_loss": NaN, "training_acc": 49.0, "val_loss": NaN, "val_acc": 52.0}
{"epoch": 86, "training_loss": NaN, "training_acc": 49.0, "val_loss": NaN, "val_acc": 52.0}
{"epoch": 87, "training_loss": NaN, "training_acc": 49.0, "val_loss": NaN, "val_acc": 52.0}
{"epoch": 88, "training_loss": NaN, "training_acc": 49.0, "val_loss": NaN, "val_acc": 52.0}
{"epoch": 89, "training_loss": NaN, "training_acc": 49.0, "val_loss": NaN, "val_acc": 52.0}
{"epoch": 90, "training_loss": NaN, "training_acc": 49.0, "val_loss": NaN, "val_acc": 52.0}
{"epoch": 91, "training_loss": NaN, "training_acc": 49.0, "val_loss": NaN, "val_acc": 52.0}
{"epoch": 92, "training_loss": NaN, "training_acc": 49.0, "val_loss": NaN, "val_acc": 52.0}
{"epoch": 93, "training_loss": NaN, "training_acc": 49.0, "val_loss": NaN, "val_acc": 52.0}
{"epoch": 94, "training_loss": NaN, "training_acc": 49.0, "val_loss": NaN, "val_acc": 52.0}
{"epoch": 95, "training_loss": NaN, "training_acc": 49.0, "val_loss": NaN, "val_acc": 52.0}
{"epoch": 96, "training_loss": NaN, "training_acc": 49.0, "val_loss": NaN, "val_acc": 52.0}
{"epoch": 97, "training_loss": NaN, "training_acc": 49.0, "val_loss": NaN, "val_acc": 52.0}
{"epoch": 98, "training_loss": NaN, "training_acc": 49.0, "val_loss": NaN, "val_acc": 52.0}
{"epoch": 99, "training_loss": NaN, "training_acc": 49.0, "val_loss": NaN, "val_acc": 52.0}
