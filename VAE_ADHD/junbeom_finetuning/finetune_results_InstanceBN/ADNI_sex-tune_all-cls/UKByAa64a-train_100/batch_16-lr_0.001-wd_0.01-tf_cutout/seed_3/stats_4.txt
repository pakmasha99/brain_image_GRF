"main_modify.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 3 --task ADNI_sex --input_option yAware --learning_rate 1e-3 --batch_size 16 --weight_decay 1e-2 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 0.7090224480628967, "training_acc": 52.0, "val_loss": 0.705997576713562, "val_acc": 52.0}
{"epoch": 1, "training_loss": 0.7212969923019409, "training_acc": 41.0, "val_loss": 0.6981342053413391, "val_acc": 48.0}
{"epoch": 2, "training_loss": 0.7020999026298523, "training_acc": 51.0, "val_loss": 0.6936930799484253, "val_acc": 48.0}
{"epoch": 3, "training_loss": 0.6964117527008057, "training_acc": 47.0, "val_loss": 0.7241831302642823, "val_acc": 48.0}
{"epoch": 4, "training_loss": 0.7157721924781799, "training_acc": 51.0, "val_loss": 0.6939121437072754, "val_acc": 48.0}
{"epoch": 5, "training_loss": 0.6961338758468628, "training_acc": 45.0, "val_loss": 0.6932713532447815, "val_acc": 52.0}
{"epoch": 6, "training_loss": 0.7129982614517212, "training_acc": 37.0, "val_loss": 0.7050726795196534, "val_acc": 52.0}
{"epoch": 7, "training_loss": 0.7237675666809082, "training_acc": 51.0, "val_loss": 0.7160117077827454, "val_acc": 48.0}
{"epoch": 8, "training_loss": 0.7140167546272278, "training_acc": 47.0, "val_loss": 0.6983100795745849, "val_acc": 48.0}
{"epoch": 9, "training_loss": 0.6963007354736328, "training_acc": 51.0, "val_loss": 0.7019421863555908, "val_acc": 48.0}
{"epoch": 10, "training_loss": 0.703863172531128, "training_acc": 51.0, "val_loss": 0.7108652997016907, "val_acc": 48.0}
{"epoch": 11, "training_loss": 0.7222715902328491, "training_acc": 51.0, "val_loss": 0.6936314153671265, "val_acc": 48.0}
{"epoch": 12, "training_loss": 0.6988467597961425, "training_acc": 45.0, "val_loss": 0.6923505091667175, "val_acc": 52.0}
{"epoch": 13, "training_loss": 0.6976875495910645, "training_acc": 45.0, "val_loss": 0.7047838950157166, "val_acc": 52.0}
{"epoch": 14, "training_loss": 0.7111107921600341, "training_acc": 49.0, "val_loss": 0.7005830049514771, "val_acc": 48.0}
{"epoch": 15, "training_loss": 0.7112157225608826, "training_acc": 51.0, "val_loss": 0.6926141858100892, "val_acc": 52.0}
{"epoch": 16, "training_loss": 0.7022169637680054, "training_acc": 47.0, "val_loss": 0.6928023886680603, "val_acc": 52.0}
{"epoch": 17, "training_loss": 0.726251380443573, "training_acc": 49.0, "val_loss": 0.7061622285842896, "val_acc": 48.0}
{"epoch": 18, "training_loss": 0.7112660241127015, "training_acc": 51.0, "val_loss": 0.6935214281082154, "val_acc": 48.0}
{"epoch": 19, "training_loss": 0.7031288766860961, "training_acc": 37.0, "val_loss": 0.702483971118927, "val_acc": 48.0}
{"epoch": 20, "training_loss": 0.7070242810249329, "training_acc": 51.0, "val_loss": 0.6924874258041381, "val_acc": 52.0}
{"epoch": 21, "training_loss": 0.7021729373931884, "training_acc": 47.0, "val_loss": 0.6934426379203796, "val_acc": 48.0}
{"epoch": 22, "training_loss": 0.6962488794326782, "training_acc": 47.0, "val_loss": 0.6927716755867004, "val_acc": 52.0}
{"epoch": 23, "training_loss": 0.6983246231079101, "training_acc": 37.0, "val_loss": 0.6924482822418213, "val_acc": 52.0}
{"epoch": 24, "training_loss": 0.7026934909820557, "training_acc": 45.0, "val_loss": 0.6923540186882019, "val_acc": 52.0}
{"epoch": 25, "training_loss": 0.7038453197479249, "training_acc": 47.0, "val_loss": 0.7066493320465088, "val_acc": 48.0}
{"epoch": 26, "training_loss": 0.712163953781128, "training_acc": 39.0, "val_loss": 0.7019914221763611, "val_acc": 48.0}
{"epoch": 27, "training_loss": 0.6985264039039611, "training_acc": 51.0, "val_loss": 0.6923471426963806, "val_acc": 52.0}
{"epoch": 28, "training_loss": 0.7022948479652404, "training_acc": 49.0, "val_loss": 0.6927926278114319, "val_acc": 52.0}
{"epoch": 29, "training_loss": 0.6946908760070801, "training_acc": 57.0, "val_loss": 0.7131552600860596, "val_acc": 48.0}
{"epoch": 30, "training_loss": 0.7202232980728149, "training_acc": 43.0, "val_loss": 0.702800760269165, "val_acc": 48.0}
{"epoch": 31, "training_loss": 0.7033860969543457, "training_acc": 51.0, "val_loss": 0.6984207653999328, "val_acc": 48.0}
{"epoch": 32, "training_loss": 0.7017199850082397, "training_acc": 43.0, "val_loss": 0.6964374136924744, "val_acc": 48.0}
{"epoch": 33, "training_loss": 0.7092654943466187, "training_acc": 51.0, "val_loss": 0.6941043496131897, "val_acc": 48.0}
{"epoch": 34, "training_loss": 0.6978707647323609, "training_acc": 47.0, "val_loss": 0.692603793144226, "val_acc": 52.0}
{"epoch": 35, "training_loss": 0.6975109910964966, "training_acc": 49.0, "val_loss": 0.6941072201728821, "val_acc": 48.0}
{"epoch": 36, "training_loss": 0.701200876235962, "training_acc": 51.0, "val_loss": 0.6923670887947082, "val_acc": 52.0}
{"epoch": 37, "training_loss": 0.7058197975158691, "training_acc": 49.0, "val_loss": 0.6976843643188476, "val_acc": 48.0}
{"epoch": 38, "training_loss": 0.7210646772384643, "training_acc": 51.0, "val_loss": 0.6925885653495789, "val_acc": 52.0}
{"epoch": 39, "training_loss": 0.7115148258209228, "training_acc": 39.0, "val_loss": 0.6923595118522644, "val_acc": 52.0}
{"epoch": 40, "training_loss": 0.7004150176048278, "training_acc": 49.0, "val_loss": 0.6924113059043884, "val_acc": 52.0}
{"epoch": 41, "training_loss": 0.6979721355438232, "training_acc": 47.0, "val_loss": 0.6979299211502075, "val_acc": 48.0}
{"epoch": 42, "training_loss": 0.6957300472259521, "training_acc": 51.0, "val_loss": 0.7013663053512573, "val_acc": 48.0}
{"epoch": 43, "training_loss": 0.698399920463562, "training_acc": 51.0, "val_loss": 0.6923678183555603, "val_acc": 52.0}
{"epoch": 44, "training_loss": 0.6992998385429382, "training_acc": 49.0, "val_loss": 0.6966248488426209, "val_acc": 48.0}
{"epoch": 45, "training_loss": 0.7011041641235352, "training_acc": 51.0, "val_loss": 0.701907045841217, "val_acc": 48.0}
{"epoch": 46, "training_loss": 0.7012141823768616, "training_acc": 47.0, "val_loss": 0.7047356724739074, "val_acc": 48.0}
