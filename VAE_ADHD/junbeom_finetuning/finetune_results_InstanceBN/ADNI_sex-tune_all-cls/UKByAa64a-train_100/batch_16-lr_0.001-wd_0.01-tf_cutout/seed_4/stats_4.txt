"main_modify.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 4 --task ADNI_sex --input_option yAware --learning_rate 1e-3 --batch_size 16 --weight_decay 1e-2 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 0.7022958946228027, "training_acc": 50.0, "val_loss": 0.6963638854026795, "val_acc": 52.0}
{"epoch": 1, "training_loss": 0.6988383674621582, "training_acc": 50.0, "val_loss": 0.7351944661140442, "val_acc": 52.0}
{"epoch": 2, "training_loss": 0.7321022224426269, "training_acc": 44.0, "val_loss": 0.7004341959953309, "val_acc": 52.0}
{"epoch": 3, "training_loss": 0.7111890029907226, "training_acc": 50.0, "val_loss": 0.6974400401115417, "val_acc": 48.0}
{"epoch": 4, "training_loss": 0.6987229371070862, "training_acc": 52.0, "val_loss": 0.7272732472419738, "val_acc": 48.0}
{"epoch": 5, "training_loss": 0.7032612991333008, "training_acc": 50.0, "val_loss": 0.6965134477615357, "val_acc": 52.0}
{"epoch": 6, "training_loss": 0.7015110945701599, "training_acc": 50.0, "val_loss": 0.708381495475769, "val_acc": 48.0}
{"epoch": 7, "training_loss": 0.7122702097892761, "training_acc": 46.0, "val_loss": 0.7084450459480286, "val_acc": 48.0}
{"epoch": 8, "training_loss": 0.7060970067977905, "training_acc": 50.0, "val_loss": 0.6972814249992371, "val_acc": 48.0}
{"epoch": 9, "training_loss": 0.7156145858764649, "training_acc": 42.0, "val_loss": 0.6924876141548156, "val_acc": 52.0}
{"epoch": 10, "training_loss": 0.6960409951210021, "training_acc": 50.0, "val_loss": 0.7021939206123352, "val_acc": 48.0}
{"epoch": 11, "training_loss": 0.7154507970809937, "training_acc": 42.0, "val_loss": 0.7098101997375488, "val_acc": 48.0}
{"epoch": 12, "training_loss": 0.7110464501380921, "training_acc": 50.0, "val_loss": 0.7081741380691529, "val_acc": 48.0}
{"epoch": 13, "training_loss": 0.709774374961853, "training_acc": 38.0, "val_loss": 0.6943339514732361, "val_acc": 48.0}
{"epoch": 14, "training_loss": 0.7044601011276245, "training_acc": 46.0, "val_loss": 0.6925957155227661, "val_acc": 52.0}
{"epoch": 15, "training_loss": 0.7029393768310547, "training_acc": 42.0, "val_loss": 0.6958512139320373, "val_acc": 48.0}
{"epoch": 16, "training_loss": 0.6964775156974793, "training_acc": 46.0, "val_loss": 0.7019691228866577, "val_acc": 48.0}
{"epoch": 17, "training_loss": 0.7148279356956482, "training_acc": 50.0, "val_loss": 0.7021357536315918, "val_acc": 48.0}
{"epoch": 18, "training_loss": 0.7006360101699829, "training_acc": 48.0, "val_loss": 0.6928448629379272, "val_acc": 52.0}
{"epoch": 19, "training_loss": 0.6981015658378601, "training_acc": 50.0, "val_loss": 0.6944639945030212, "val_acc": 48.0}
{"epoch": 20, "training_loss": 0.6970506525039672, "training_acc": 48.0, "val_loss": 0.6947597551345825, "val_acc": 48.0}
{"epoch": 21, "training_loss": 0.7010662531852723, "training_acc": 50.0, "val_loss": 0.6924462461471558, "val_acc": 52.0}
{"epoch": 22, "training_loss": 0.7059041929244995, "training_acc": 44.0, "val_loss": 0.6959683585166931, "val_acc": 48.0}
{"epoch": 23, "training_loss": 0.7154781341552734, "training_acc": 48.0, "val_loss": 0.6928790760040283, "val_acc": 52.0}
{"epoch": 24, "training_loss": 0.6978534889221192, "training_acc": 44.0, "val_loss": 0.6957072329521179, "val_acc": 48.0}
{"epoch": 25, "training_loss": 0.7112672424316406, "training_acc": 50.0, "val_loss": 0.696166684627533, "val_acc": 52.0}
{"epoch": 26, "training_loss": 0.7043855094909668, "training_acc": 50.0, "val_loss": 0.698378701210022, "val_acc": 52.0}
{"epoch": 27, "training_loss": 0.7005044984817504, "training_acc": 50.0, "val_loss": 0.6994992828369141, "val_acc": 48.0}
{"epoch": 28, "training_loss": 0.7083867168426514, "training_acc": 40.0, "val_loss": 0.6962785243988037, "val_acc": 48.0}
{"epoch": 29, "training_loss": 0.7064423990249634, "training_acc": 46.0, "val_loss": 0.6970026540756226, "val_acc": 48.0}
{"epoch": 30, "training_loss": 0.7062854909896851, "training_acc": 42.0, "val_loss": 0.6924581599235534, "val_acc": 52.0}
{"epoch": 31, "training_loss": 0.6995497727394104, "training_acc": 50.0, "val_loss": 0.6969108486175537, "val_acc": 48.0}
{"epoch": 32, "training_loss": 0.7055470895767212, "training_acc": 50.0, "val_loss": 0.7064566421508789, "val_acc": 48.0}
{"epoch": 33, "training_loss": 0.7077344393730164, "training_acc": 50.0, "val_loss": 0.6934974312782287, "val_acc": 52.0}
{"epoch": 34, "training_loss": 0.7003262329101563, "training_acc": 50.0, "val_loss": 0.6933898878097534, "val_acc": 52.0}
{"epoch": 35, "training_loss": 0.701672043800354, "training_acc": 46.0, "val_loss": 0.6924816870689392, "val_acc": 52.0}
{"epoch": 36, "training_loss": 0.7075229692459106, "training_acc": 50.0, "val_loss": 0.6923469877243043, "val_acc": 52.0}
{"epoch": 37, "training_loss": 0.6976481866836548, "training_acc": 48.0, "val_loss": 0.6936442136764527, "val_acc": 48.0}
{"epoch": 38, "training_loss": 0.6992751121520996, "training_acc": 52.0, "val_loss": 0.6943150973320007, "val_acc": 52.0}
{"epoch": 39, "training_loss": 0.7101064062118531, "training_acc": 50.0, "val_loss": 0.6934147977828979, "val_acc": 48.0}
{"epoch": 40, "training_loss": 0.6991857862472535, "training_acc": 40.0, "val_loss": 0.7068698811531067, "val_acc": 48.0}
{"epoch": 41, "training_loss": 0.7028707027435303, "training_acc": 50.0, "val_loss": 0.6959661293029785, "val_acc": 48.0}
{"epoch": 42, "training_loss": 0.701176438331604, "training_acc": 48.0, "val_loss": 0.6929858732223511, "val_acc": 52.0}
{"epoch": 43, "training_loss": 0.7056557178497315, "training_acc": 50.0, "val_loss": 0.6935243201255799, "val_acc": 48.0}
{"epoch": 44, "training_loss": 0.6989979767799377, "training_acc": 46.0, "val_loss": 0.6952489399909973, "val_acc": 48.0}
{"epoch": 45, "training_loss": 0.6919183516502381, "training_acc": 54.0, "val_loss": 0.6931556725502014, "val_acc": 52.0}
{"epoch": 46, "training_loss": 0.7062083864212036, "training_acc": 44.0, "val_loss": 0.6929152274131775, "val_acc": 52.0}
{"epoch": 47, "training_loss": 0.7004394865036011, "training_acc": 50.0, "val_loss": 0.6933596920967102, "val_acc": 52.0}
{"epoch": 48, "training_loss": 0.7023766827583313, "training_acc": 48.0, "val_loss": 0.6923476028442382, "val_acc": 52.0}
{"epoch": 49, "training_loss": 0.7025522756576538, "training_acc": 50.0, "val_loss": 0.6937641501426697, "val_acc": 48.0}
{"epoch": 50, "training_loss": 0.7071210527420044, "training_acc": 48.0, "val_loss": 0.6939250874519348, "val_acc": 48.0}
{"epoch": 51, "training_loss": 0.6977416849136353, "training_acc": 48.0, "val_loss": 0.7079187059402465, "val_acc": 48.0}
{"epoch": 52, "training_loss": 0.7083053231239319, "training_acc": 50.0, "val_loss": 0.7060689878463745, "val_acc": 48.0}
{"epoch": 53, "training_loss": 0.7122959399223328, "training_acc": 50.0, "val_loss": 0.6941762042045593, "val_acc": 48.0}
{"epoch": 54, "training_loss": 0.6979913187026977, "training_acc": 48.0, "val_loss": 0.6936700916290284, "val_acc": 52.0}
{"epoch": 55, "training_loss": 0.7066207599639892, "training_acc": 46.0, "val_loss": 0.6947190165519714, "val_acc": 48.0}
