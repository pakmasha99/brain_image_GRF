"main_modify.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 4 --task ADNI_sex --input_option yAware --learning_rate 1e-3 --batch_size 16 --weight_decay 1e-2 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 0.7035062217712402, "training_acc": 52.0, "val_loss": 0.7084737515449524, "val_acc": 52.0}
{"epoch": 1, "training_loss": 0.7200659942626954, "training_acc": 47.0, "val_loss": 0.6946662926673889, "val_acc": 48.0}
{"epoch": 2, "training_loss": 0.6994179272651673, "training_acc": 45.0, "val_loss": 0.7037416768074035, "val_acc": 48.0}
{"epoch": 3, "training_loss": 0.6991757440567017, "training_acc": 50.0, "val_loss": 0.6940790939331055, "val_acc": 48.0}
{"epoch": 4, "training_loss": 0.70737135887146, "training_acc": 57.0, "val_loss": 0.6924968957901001, "val_acc": 52.0}
{"epoch": 5, "training_loss": 0.6999929738044739, "training_acc": 49.0, "val_loss": 0.6925536108016968, "val_acc": 52.0}
{"epoch": 6, "training_loss": 0.7205318784713746, "training_acc": 47.0, "val_loss": 0.6947594404220581, "val_acc": 48.0}
{"epoch": 7, "training_loss": 0.6970823192596436, "training_acc": 51.0, "val_loss": 0.6930777978897095, "val_acc": 52.0}
{"epoch": 8, "training_loss": 0.7035200500488281, "training_acc": 49.0, "val_loss": 0.6927902102470398, "val_acc": 52.0}
{"epoch": 9, "training_loss": 0.7147888374328614, "training_acc": 53.0, "val_loss": 0.6973082828521728, "val_acc": 48.0}
{"epoch": 10, "training_loss": 0.7045923328399658, "training_acc": 51.0, "val_loss": 0.6931720089912414, "val_acc": 52.0}
{"epoch": 11, "training_loss": 0.7014233446121216, "training_acc": 47.0, "val_loss": 0.6925827527046203, "val_acc": 52.0}
{"epoch": 12, "training_loss": 0.703147976398468, "training_acc": 41.0, "val_loss": 0.7122929120063781, "val_acc": 48.0}
{"epoch": 13, "training_loss": 0.728100368976593, "training_acc": 51.0, "val_loss": 0.7154811406135559, "val_acc": 48.0}
{"epoch": 14, "training_loss": 0.7066047143936157, "training_acc": 51.0, "val_loss": 0.6965945386886596, "val_acc": 48.0}
{"epoch": 15, "training_loss": 0.7200832319259644, "training_acc": 41.0, "val_loss": 0.6977682471275329, "val_acc": 48.0}
{"epoch": 16, "training_loss": 0.7008723115921021, "training_acc": 45.0, "val_loss": 0.7000942921638489, "val_acc": 48.0}
{"epoch": 17, "training_loss": 0.7061592388153076, "training_acc": 51.0, "val_loss": 0.6961667704582214, "val_acc": 48.0}
{"epoch": 18, "training_loss": 0.6968322372436524, "training_acc": 53.0, "val_loss": 0.6946909594535827, "val_acc": 52.0}
{"epoch": 19, "training_loss": 0.7088694071769714, "training_acc": 49.0, "val_loss": 0.6925551247596741, "val_acc": 52.0}
{"epoch": 20, "training_loss": 0.6957115721702576, "training_acc": 49.0, "val_loss": 0.7059200882911683, "val_acc": 48.0}
{"epoch": 21, "training_loss": 0.7074055600166321, "training_acc": 51.0, "val_loss": 0.7073268556594848, "val_acc": 48.0}
{"epoch": 22, "training_loss": 0.7028746271133423, "training_acc": 51.0, "val_loss": 0.6940294003486633, "val_acc": 48.0}
{"epoch": 23, "training_loss": 0.7049226045608521, "training_acc": 51.0, "val_loss": 0.6946294808387756, "val_acc": 52.0}
{"epoch": 24, "training_loss": 0.7009829044342041, "training_acc": 47.0, "val_loss": 0.6924127578735352, "val_acc": 52.0}
{"epoch": 25, "training_loss": 0.6993160343170166, "training_acc": 49.0, "val_loss": 0.6923481965065003, "val_acc": 52.0}
{"epoch": 26, "training_loss": 0.704368371963501, "training_acc": 49.0, "val_loss": 0.6962270402908325, "val_acc": 48.0}
{"epoch": 27, "training_loss": 0.703637821674347, "training_acc": 51.0, "val_loss": 0.6931228184700012, "val_acc": 52.0}
{"epoch": 28, "training_loss": 0.7047439813613892, "training_acc": 47.0, "val_loss": 0.6938914966583252, "val_acc": 52.0}
{"epoch": 29, "training_loss": 0.6977870917320251, "training_acc": 51.0, "val_loss": 0.7336903309822083, "val_acc": 48.0}
{"epoch": 30, "training_loss": 0.7144548940658569, "training_acc": 51.0, "val_loss": 0.6936985373497009, "val_acc": 48.0}
{"epoch": 31, "training_loss": 0.6985203242301941, "training_acc": 47.0, "val_loss": 0.6990109610557557, "val_acc": 48.0}
{"epoch": 32, "training_loss": 0.7096252536773682, "training_acc": 51.0, "val_loss": 0.6923623704910278, "val_acc": 52.0}
{"epoch": 33, "training_loss": 0.71732093334198, "training_acc": 49.0, "val_loss": 0.6940165019035339, "val_acc": 48.0}
{"epoch": 34, "training_loss": 0.7078218889236451, "training_acc": 51.0, "val_loss": 0.7043722176551819, "val_acc": 48.0}
{"epoch": 35, "training_loss": 0.7022488069534302, "training_acc": 51.0, "val_loss": 0.7003830361366272, "val_acc": 48.0}
{"epoch": 36, "training_loss": 0.6991550087928772, "training_acc": 49.0, "val_loss": 0.6968680548667908, "val_acc": 48.0}
{"epoch": 37, "training_loss": 0.6978875255584717, "training_acc": 51.0, "val_loss": 0.7068030142784119, "val_acc": 48.0}
{"epoch": 38, "training_loss": 0.7043745279312134, "training_acc": 45.0, "val_loss": 0.6954185891151429, "val_acc": 48.0}
{"epoch": 39, "training_loss": 0.7142855072021485, "training_acc": 41.0, "val_loss": 0.6990380215644837, "val_acc": 48.0}
{"epoch": 40, "training_loss": 0.7025972032546997, "training_acc": 45.0, "val_loss": 0.7016046023368836, "val_acc": 48.0}
{"epoch": 41, "training_loss": 0.7016760349273682, "training_acc": 51.0, "val_loss": 0.7063072967529297, "val_acc": 48.0}
{"epoch": 42, "training_loss": 0.7048555850982666, "training_acc": 49.0, "val_loss": 0.6953107810020447, "val_acc": 48.0}
{"epoch": 43, "training_loss": 0.6949582624435425, "training_acc": 51.0, "val_loss": 0.6953860592842102, "val_acc": 48.0}
{"epoch": 44, "training_loss": 0.7005489754676819, "training_acc": 45.0, "val_loss": 0.6968317341804504, "val_acc": 48.0}
