"main_modify.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 8 --task ADNI_sex --input_option yAware --learning_rate 1e-3 --batch_size 16 --weight_decay 1e-2 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 0.7351853561401367, "training_acc": 49.0, "val_loss": 0.6928106570243835, "val_acc": 52.0}
{"epoch": 1, "training_loss": 0.7063149547576905, "training_acc": 46.0, "val_loss": 0.6927255821228028, "val_acc": 52.0}
{"epoch": 2, "training_loss": 0.7044775009155273, "training_acc": 51.0, "val_loss": 0.7112630581855774, "val_acc": 48.0}
{"epoch": 3, "training_loss": 0.7134262704849244, "training_acc": 53.0, "val_loss": 0.7032906985282898, "val_acc": 52.0}
{"epoch": 4, "training_loss": 0.7175762867927551, "training_acc": 47.0, "val_loss": 0.6925082898139954, "val_acc": 52.0}
{"epoch": 5, "training_loss": 0.6998965477943421, "training_acc": 49.0, "val_loss": 0.6994516801834106, "val_acc": 48.0}
{"epoch": 6, "training_loss": 0.7025559425354004, "training_acc": 49.0, "val_loss": 0.6936157965660095, "val_acc": 52.0}
{"epoch": 7, "training_loss": 0.7022924852371216, "training_acc": 51.0, "val_loss": 0.6993792080879211, "val_acc": 48.0}
{"epoch": 8, "training_loss": 0.6955061721801757, "training_acc": 49.0, "val_loss": 0.7164048027992248, "val_acc": 48.0}
{"epoch": 9, "training_loss": 0.7107000255584717, "training_acc": 51.0, "val_loss": 0.692410089969635, "val_acc": 52.0}
{"epoch": 10, "training_loss": 0.7101326417922974, "training_acc": 41.0, "val_loss": 0.6925414276123046, "val_acc": 52.0}
{"epoch": 11, "training_loss": 0.7261168956756592, "training_acc": 49.0, "val_loss": 0.693093683719635, "val_acc": 52.0}
{"epoch": 12, "training_loss": 0.7041579675674439, "training_acc": 53.0, "val_loss": 0.7043895745277404, "val_acc": 48.0}
{"epoch": 13, "training_loss": 0.7087167119979858, "training_acc": 45.0, "val_loss": 0.6933466649055481, "val_acc": 48.0}
{"epoch": 14, "training_loss": 0.6985316896438598, "training_acc": 39.0, "val_loss": 0.6976430916786194, "val_acc": 48.0}
{"epoch": 15, "training_loss": 0.7148113822937012, "training_acc": 51.0, "val_loss": 0.6959367036819458, "val_acc": 48.0}
{"epoch": 16, "training_loss": 0.7097244215011597, "training_acc": 43.0, "val_loss": 0.6923479199409485, "val_acc": 52.0}
{"epoch": 17, "training_loss": 0.7124462294578552, "training_acc": 47.0, "val_loss": 0.6981089186668396, "val_acc": 52.0}
{"epoch": 18, "training_loss": 0.7150699472427369, "training_acc": 47.0, "val_loss": 0.6926710128784179, "val_acc": 52.0}
{"epoch": 19, "training_loss": 0.6987647986412049, "training_acc": 49.0, "val_loss": 0.6941289615631103, "val_acc": 48.0}
{"epoch": 20, "training_loss": 0.6952181768417358, "training_acc": 45.0, "val_loss": 0.7086651968955994, "val_acc": 48.0}
{"epoch": 21, "training_loss": 0.7095245265960693, "training_acc": 51.0, "val_loss": 0.7005008244514466, "val_acc": 48.0}
{"epoch": 22, "training_loss": 0.6950275707244873, "training_acc": 51.0, "val_loss": 0.6939503407478332, "val_acc": 48.0}
{"epoch": 23, "training_loss": 0.6983238887786866, "training_acc": 51.0, "val_loss": 0.6949633836746216, "val_acc": 48.0}
{"epoch": 24, "training_loss": 0.7023525476455689, "training_acc": 39.0, "val_loss": 0.6927273201942444, "val_acc": 52.0}
{"epoch": 25, "training_loss": 0.6982678842544555, "training_acc": 49.0, "val_loss": 0.6923471689224243, "val_acc": 52.0}
{"epoch": 26, "training_loss": 0.7001321315765381, "training_acc": 47.0, "val_loss": 0.6924544906616211, "val_acc": 52.0}
{"epoch": 27, "training_loss": 0.6988708400726318, "training_acc": 49.0, "val_loss": 0.6929220581054687, "val_acc": 52.0}
{"epoch": 28, "training_loss": 0.7054934525489807, "training_acc": 49.0, "val_loss": 0.6929647827148437, "val_acc": 52.0}
{"epoch": 29, "training_loss": 0.6987111902236939, "training_acc": 47.0, "val_loss": 0.6939176630973816, "val_acc": 48.0}
{"epoch": 30, "training_loss": 0.7047013711929321, "training_acc": 51.0, "val_loss": 0.6927925062179565, "val_acc": 52.0}
{"epoch": 31, "training_loss": 0.7051185059547425, "training_acc": 45.0, "val_loss": 0.6925051832199096, "val_acc": 52.0}
{"epoch": 32, "training_loss": 0.6988889145851135, "training_acc": 49.0, "val_loss": 0.6986646175384521, "val_acc": 48.0}
{"epoch": 33, "training_loss": 0.7031974840164185, "training_acc": 51.0, "val_loss": 0.7154469728469849, "val_acc": 48.0}
{"epoch": 34, "training_loss": 0.7109463024139404, "training_acc": 51.0, "val_loss": 0.693302309513092, "val_acc": 48.0}
{"epoch": 35, "training_loss": 0.7070116090774536, "training_acc": 49.0, "val_loss": 0.6931354546546936, "val_acc": 52.0}
{"epoch": 36, "training_loss": 0.7104577684402466, "training_acc": 51.0, "val_loss": 0.6931542205810547, "val_acc": 48.0}
{"epoch": 37, "training_loss": 0.6969797110557556, "training_acc": 53.0, "val_loss": 0.6953564810752869, "val_acc": 48.0}
{"epoch": 38, "training_loss": 0.70162522315979, "training_acc": 51.0, "val_loss": 0.6953753590583801, "val_acc": 48.0}
{"epoch": 39, "training_loss": 0.699330735206604, "training_acc": 39.0, "val_loss": 0.6925624442100525, "val_acc": 52.0}
{"epoch": 40, "training_loss": 0.7021772646903992, "training_acc": 49.0, "val_loss": 0.6953870296478272, "val_acc": 48.0}
{"epoch": 41, "training_loss": 0.6993819785118103, "training_acc": 43.0, "val_loss": 0.6976585578918457, "val_acc": 48.0}
{"epoch": 42, "training_loss": 0.6988684415817261, "training_acc": 51.0, "val_loss": 0.6941985988616943, "val_acc": 48.0}
{"epoch": 43, "training_loss": 0.7115180015563964, "training_acc": 47.0, "val_loss": 0.7007543301582336, "val_acc": 48.0}
{"epoch": 44, "training_loss": 0.7200413322448731, "training_acc": 51.0, "val_loss": 0.6961957216262817, "val_acc": 48.0}
