"main_modify.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 7 --task ADNI_sex --input_option yAware --learning_rate 1e-3 --batch_size 16 --weight_decay 1e-2 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 0.7087916898727417, "training_acc": 51.0, "val_loss": 0.6978544569015503, "val_acc": 52.0}
{"epoch": 1, "training_loss": 0.7287995243072509, "training_acc": 41.0, "val_loss": 0.6934152293205261, "val_acc": 40.0}
{"epoch": 2, "training_loss": 0.7016771459579467, "training_acc": 39.0, "val_loss": 0.7085488033294678, "val_acc": 48.0}
{"epoch": 3, "training_loss": 0.7075142168998718, "training_acc": 51.0, "val_loss": 0.715080304145813, "val_acc": 48.0}
{"epoch": 4, "training_loss": 0.7063876390457153, "training_acc": 49.0, "val_loss": 0.6969689536094665, "val_acc": 48.0}
{"epoch": 5, "training_loss": 0.7096682929992676, "training_acc": 47.0, "val_loss": 0.6924172306060791, "val_acc": 52.0}
{"epoch": 6, "training_loss": 0.7035401296615601, "training_acc": 41.0, "val_loss": 0.693127977848053, "val_acc": 52.0}
{"epoch": 7, "training_loss": 0.6933386921882629, "training_acc": 53.0, "val_loss": 0.7189960908889771, "val_acc": 48.0}
{"epoch": 8, "training_loss": 0.7112361216545104, "training_acc": 51.0, "val_loss": 0.7002032732963562, "val_acc": 48.0}
{"epoch": 9, "training_loss": 0.7007099556922912, "training_acc": 41.0, "val_loss": 0.6963822221755982, "val_acc": 48.0}
{"epoch": 10, "training_loss": 0.6983461570739746, "training_acc": 51.0, "val_loss": 0.6928696537017822, "val_acc": 52.0}
{"epoch": 11, "training_loss": 0.695979642868042, "training_acc": 49.0, "val_loss": 0.694805645942688, "val_acc": 52.0}
{"epoch": 12, "training_loss": 0.7038519859313965, "training_acc": 45.0, "val_loss": 0.7000464797019958, "val_acc": 48.0}
{"epoch": 13, "training_loss": 0.7139228558540345, "training_acc": 51.0, "val_loss": 0.692986855506897, "val_acc": 52.0}
{"epoch": 14, "training_loss": 0.6979887962341309, "training_acc": 53.0, "val_loss": 0.7155663418769836, "val_acc": 48.0}
{"epoch": 15, "training_loss": 0.7047066187858582, "training_acc": 49.0, "val_loss": 0.6975453972816468, "val_acc": 48.0}
{"epoch": 16, "training_loss": 0.7000803136825562, "training_acc": 51.0, "val_loss": 0.6928237891197204, "val_acc": 52.0}
{"epoch": 17, "training_loss": 0.7026910305023193, "training_acc": 49.0, "val_loss": 0.6923849296569824, "val_acc": 52.0}
{"epoch": 18, "training_loss": 0.6994988250732422, "training_acc": 49.0, "val_loss": 0.7000122499465943, "val_acc": 48.0}
{"epoch": 19, "training_loss": 0.7013697099685668, "training_acc": 51.0, "val_loss": 0.6945331478118897, "val_acc": 48.0}
{"epoch": 20, "training_loss": 0.6972894477844238, "training_acc": 51.0, "val_loss": 0.6963328981399536, "val_acc": 48.0}
{"epoch": 21, "training_loss": 0.7052935838699341, "training_acc": 45.0, "val_loss": 0.6978636980056763, "val_acc": 48.0}
{"epoch": 22, "training_loss": 0.7064630174636841, "training_acc": 51.0, "val_loss": 0.7093891215324402, "val_acc": 48.0}
{"epoch": 23, "training_loss": 0.7016595506668091, "training_acc": 45.0, "val_loss": 0.6924786067008972, "val_acc": 52.0}
{"epoch": 24, "training_loss": 0.7083267307281494, "training_acc": 49.0, "val_loss": 0.7028549766540527, "val_acc": 48.0}
{"epoch": 25, "training_loss": 0.7015571284294129, "training_acc": 51.0, "val_loss": 0.7178913927078248, "val_acc": 48.0}
{"epoch": 26, "training_loss": 0.7052357387542725, "training_acc": 51.0, "val_loss": 0.6923761606216431, "val_acc": 52.0}
{"epoch": 27, "training_loss": 0.7023939943313598, "training_acc": 41.0, "val_loss": 0.6928204274177552, "val_acc": 52.0}
{"epoch": 28, "training_loss": 0.6998243832588196, "training_acc": 47.0, "val_loss": 0.6939583897590638, "val_acc": 48.0}
{"epoch": 29, "training_loss": 0.6950576472282409, "training_acc": 47.0, "val_loss": 0.7030111312866211, "val_acc": 48.0}
{"epoch": 30, "training_loss": 0.7135820055007934, "training_acc": 51.0, "val_loss": 0.6947396802902222, "val_acc": 48.0}
{"epoch": 31, "training_loss": 0.7014277911186219, "training_acc": 43.0, "val_loss": 0.6937630939483642, "val_acc": 48.0}
{"epoch": 32, "training_loss": 0.6998504614830017, "training_acc": 47.0, "val_loss": 0.7134762501716614, "val_acc": 48.0}
{"epoch": 33, "training_loss": 0.7149528002738953, "training_acc": 51.0, "val_loss": 0.6966887712478638, "val_acc": 48.0}
{"epoch": 34, "training_loss": 0.6987350463867188, "training_acc": 51.0, "val_loss": 0.6936917161941528, "val_acc": 52.0}
{"epoch": 35, "training_loss": 0.7036661553382874, "training_acc": 41.0, "val_loss": 0.6929634976387024, "val_acc": 52.0}
{"epoch": 36, "training_loss": 0.702435953617096, "training_acc": 49.0, "val_loss": 0.6940681767463684, "val_acc": 48.0}
{"epoch": 37, "training_loss": 0.6959921932220459, "training_acc": 51.0, "val_loss": 0.6932170605659485, "val_acc": 48.0}
{"epoch": 38, "training_loss": 0.6936239910125732, "training_acc": 55.0, "val_loss": 0.6970831274986267, "val_acc": 52.0}
{"epoch": 39, "training_loss": 0.7164481449127197, "training_acc": 41.0, "val_loss": 0.6945367550849915, "val_acc": 48.0}
{"epoch": 40, "training_loss": 0.6957663726806641, "training_acc": 47.0, "val_loss": 0.7008702111244202, "val_acc": 48.0}
{"epoch": 41, "training_loss": 0.6968386697769166, "training_acc": 51.0, "val_loss": 0.696028561592102, "val_acc": 48.0}
{"epoch": 42, "training_loss": 0.7003968811035156, "training_acc": 45.0, "val_loss": 0.6979627895355225, "val_acc": 48.0}
{"epoch": 43, "training_loss": 0.7018636536598205, "training_acc": 51.0, "val_loss": 0.6923555493354797, "val_acc": 52.0}
{"epoch": 44, "training_loss": 0.6973131132125855, "training_acc": 51.0, "val_loss": 0.693228600025177, "val_acc": 48.0}
{"epoch": 45, "training_loss": 0.7000781631469727, "training_acc": 51.0, "val_loss": 0.6926596546173096, "val_acc": 52.0}
{"epoch": 46, "training_loss": 0.7090882921218872, "training_acc": 47.0, "val_loss": 0.6926013898849487, "val_acc": 52.0}
{"epoch": 47, "training_loss": 0.6967053604125977, "training_acc": 49.0, "val_loss": 0.6955965423583984, "val_acc": 48.0}
{"epoch": 48, "training_loss": 0.7080159211158752, "training_acc": 51.0, "val_loss": 0.6923550343513489, "val_acc": 52.0}
{"epoch": 49, "training_loss": 0.6973175835609436, "training_acc": 49.0, "val_loss": 0.6983253479003906, "val_acc": 48.0}
{"epoch": 50, "training_loss": 0.7081143927574157, "training_acc": 51.0, "val_loss": 0.6924085903167725, "val_acc": 52.0}
{"epoch": 51, "training_loss": 0.7072152853012085, "training_acc": 49.0, "val_loss": 0.6967078375816346, "val_acc": 48.0}
{"epoch": 52, "training_loss": 0.695630338191986, "training_acc": 51.0, "val_loss": 0.6944577479362488, "val_acc": 48.0}
{"epoch": 53, "training_loss": 0.7048953533172607, "training_acc": 49.0, "val_loss": 0.6987861657142639, "val_acc": 48.0}
{"epoch": 54, "training_loss": 0.6956842756271362, "training_acc": 51.0, "val_loss": 0.7137215256690979, "val_acc": 48.0}
{"epoch": 55, "training_loss": 0.7076882028579712, "training_acc": 51.0, "val_loss": 0.7007744908332825, "val_acc": 48.0}
{"epoch": 56, "training_loss": 0.7038519763946534, "training_acc": 39.0, "val_loss": 0.6958118057250977, "val_acc": 48.0}
{"epoch": 57, "training_loss": 0.7007122969627381, "training_acc": 43.0, "val_loss": 0.6956124234199524, "val_acc": 48.0}
{"epoch": 58, "training_loss": 0.6977403450012207, "training_acc": 49.0, "val_loss": 0.6924810075759887, "val_acc": 52.0}
{"epoch": 59, "training_loss": 0.7058379888534546, "training_acc": 49.0, "val_loss": 0.6926707482337952, "val_acc": 52.0}
{"epoch": 60, "training_loss": 0.7160280799865723, "training_acc": 51.0, "val_loss": 0.6931950497627258, "val_acc": 48.0}
{"epoch": 61, "training_loss": 0.7077551031112671, "training_acc": 49.0, "val_loss": 0.6925636434555054, "val_acc": 52.0}
{"epoch": 62, "training_loss": 0.7029780626296998, "training_acc": 43.0, "val_loss": 0.7050514578819275, "val_acc": 48.0}
{"epoch": 63, "training_loss": 0.7046635818481445, "training_acc": 51.0, "val_loss": 0.7155147862434387, "val_acc": 48.0}
{"epoch": 64, "training_loss": 0.7270859622955322, "training_acc": 51.0, "val_loss": 0.6925568795204162, "val_acc": 52.0}
{"epoch": 65, "training_loss": 0.7081135702133179, "training_acc": 49.0, "val_loss": 0.69554034948349, "val_acc": 48.0}
{"epoch": 66, "training_loss": 0.6940681958198547, "training_acc": 51.0, "val_loss": 0.7086884808540345, "val_acc": 48.0}
{"epoch": 67, "training_loss": 0.7048979210853576, "training_acc": 51.0, "val_loss": 0.697897617816925, "val_acc": 48.0}
