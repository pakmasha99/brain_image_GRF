"main_modify.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 1 --task ADNI_sex --input_option yAware --learning_rate 1e-1 --batch_size 16 --weight_decay 1e-3 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 10.394907245635986, "training_acc": 49.0, "val_loss": 16.277024536132814, "val_acc": 52.0}
{"epoch": 1, "training_loss": 10.517112102508545, "training_acc": 49.0, "val_loss": 9.971934814453125, "val_acc": 48.0}
{"epoch": 2, "training_loss": 3.756151020526886, "training_acc": 51.0, "val_loss": 2.4856826877593994, "val_acc": 48.0}
{"epoch": 3, "training_loss": 2.686648416519165, "training_acc": 47.0, "val_loss": 1.3461757898330688, "val_acc": 48.0}
{"epoch": 4, "training_loss": 0.9336945724487304, "training_acc": 59.0, "val_loss": 2.3217339372634886, "val_acc": 52.0}
{"epoch": 5, "training_loss": 2.4012016105651854, "training_acc": 45.0, "val_loss": 0.7960928440093994, "val_acc": 52.0}
{"epoch": 6, "training_loss": 1.3589451646804809, "training_acc": 57.0, "val_loss": 0.8834631276130677, "val_acc": 48.0}
{"epoch": 7, "training_loss": 0.710753071308136, "training_acc": 59.0, "val_loss": 3.4195346641540527, "val_acc": 48.0}
{"epoch": 8, "training_loss": 1.8501891803741455, "training_acc": 49.0, "val_loss": 2.095975408554077, "val_acc": 52.0}
{"epoch": 9, "training_loss": 1.8879704570770264, "training_acc": 47.0, "val_loss": 1.9946516704559327, "val_acc": 48.0}
{"epoch": 10, "training_loss": 1.8764565753936768, "training_acc": 45.0, "val_loss": 5.451029386520386, "val_acc": 52.0}
{"epoch": 11, "training_loss": 4.995027623176575, "training_acc": 49.0, "val_loss": 2.0763566970825194, "val_acc": 48.0}
{"epoch": 12, "training_loss": 1.6676979351043701, "training_acc": 47.0, "val_loss": 2.046914267539978, "val_acc": 48.0}
{"epoch": 13, "training_loss": 1.4033415508270264, "training_acc": 45.0, "val_loss": 1.0807226610183716, "val_acc": 48.0}
{"epoch": 14, "training_loss": 1.192966480255127, "training_acc": 43.0, "val_loss": 0.694751706123352, "val_acc": 48.0}
{"epoch": 15, "training_loss": 1.9065599012374879, "training_acc": 41.0, "val_loss": 0.7580578541755676, "val_acc": 52.0}
{"epoch": 16, "training_loss": 0.8050265169143677, "training_acc": 55.0, "val_loss": 0.7646118211746216, "val_acc": 48.0}
{"epoch": 17, "training_loss": 0.9925740671157837, "training_acc": 45.0, "val_loss": 0.9342148041725159, "val_acc": 52.0}
{"epoch": 18, "training_loss": 1.3551701021194458, "training_acc": 41.0, "val_loss": 1.0436258792877198, "val_acc": 52.0}
{"epoch": 19, "training_loss": 1.1552940273284913, "training_acc": 55.0, "val_loss": 1.3837674951553345, "val_acc": 48.0}
{"epoch": 20, "training_loss": 1.0430241584777833, "training_acc": 51.0, "val_loss": 0.9341316223144531, "val_acc": 52.0}
{"epoch": 21, "training_loss": 1.321328845024109, "training_acc": 53.0, "val_loss": 1.0843472862243653, "val_acc": 48.0}
{"epoch": 22, "training_loss": 1.6440312385559082, "training_acc": 41.0, "val_loss": 0.8585915875434875, "val_acc": 48.0}
{"epoch": 23, "training_loss": 0.9893383669853211, "training_acc": 47.0, "val_loss": 0.6943161344528198, "val_acc": 48.0}
{"epoch": 24, "training_loss": 0.9331184959411621, "training_acc": 47.0, "val_loss": 0.6937090754508972, "val_acc": 48.0}
{"epoch": 25, "training_loss": 0.7507718276977539, "training_acc": 55.0, "val_loss": 1.4784404754638671, "val_acc": 48.0}
{"epoch": 26, "training_loss": 1.2065636920928955, "training_acc": 41.0, "val_loss": 0.8124239277839661, "val_acc": 48.0}
{"epoch": 27, "training_loss": 0.9590119886398315, "training_acc": 51.0, "val_loss": 1.1090265560150145, "val_acc": 48.0}
{"epoch": 28, "training_loss": 1.144839849472046, "training_acc": 43.0, "val_loss": 1.0989443445205689, "val_acc": 52.0}
{"epoch": 29, "training_loss": 0.8308116054534912, "training_acc": 47.0, "val_loss": 0.6950662302970886, "val_acc": 48.0}
{"epoch": 30, "training_loss": 1.0558417510986329, "training_acc": 45.0, "val_loss": 0.7862623476982117, "val_acc": 48.0}
{"epoch": 31, "training_loss": 0.9775361108779907, "training_acc": 47.0, "val_loss": 2.5865953731536866, "val_acc": 48.0}
{"epoch": 32, "training_loss": 1.4397729873657226, "training_acc": 47.0, "val_loss": 1.8323136615753173, "val_acc": 52.0}
{"epoch": 33, "training_loss": 1.6148574328422547, "training_acc": 55.0, "val_loss": 2.2513026452064513, "val_acc": 48.0}
{"epoch": 34, "training_loss": 1.9619479274749756, "training_acc": 45.0, "val_loss": 1.5758564472198486, "val_acc": 48.0}
{"epoch": 35, "training_loss": 2.5303377056121827, "training_acc": 45.0, "val_loss": 2.8314753723144532, "val_acc": 52.0}
{"epoch": 36, "training_loss": 4.332503604888916, "training_acc": 49.0, "val_loss": 2.3068397521972654, "val_acc": 48.0}
{"epoch": 37, "training_loss": 3.3376071739196775, "training_acc": 49.0, "val_loss": 1.8826942825317383, "val_acc": 48.0}
{"epoch": 38, "training_loss": 2.1122671365737915, "training_acc": 51.0, "val_loss": 3.40948157787323, "val_acc": 52.0}
{"epoch": 39, "training_loss": 2.928314752578735, "training_acc": 47.0, "val_loss": 2.1772745037078858, "val_acc": 52.0}
{"epoch": 40, "training_loss": 1.6977327537536622, "training_acc": 49.0, "val_loss": 2.0571952199935915, "val_acc": 48.0}
{"epoch": 41, "training_loss": 1.6578615760803224, "training_acc": 53.0, "val_loss": 3.5680161476135255, "val_acc": 48.0}
{"epoch": 42, "training_loss": 2.732017936706543, "training_acc": 43.0, "val_loss": 3.3078001594543456, "val_acc": 48.0}
{"epoch": 43, "training_loss": 2.425536252222955, "training_acc": 51.0, "val_loss": 3.9763389873504638, "val_acc": 48.0}
