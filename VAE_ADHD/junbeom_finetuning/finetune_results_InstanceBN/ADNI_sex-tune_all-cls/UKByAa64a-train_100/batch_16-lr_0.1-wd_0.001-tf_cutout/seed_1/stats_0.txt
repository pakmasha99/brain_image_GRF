"main_modify.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 1 --task ADNI_sex --input_option yAware --learning_rate 1e-1 --batch_size 16 --weight_decay 1e-3 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 8.394054532051086, "training_acc": 46.0, "val_loss": 2.194688310623169, "val_acc": 52.0}
{"epoch": 1, "training_loss": 2.2838459515571596, "training_acc": 44.0, "val_loss": 5.389517412185669, "val_acc": 48.0}
{"epoch": 2, "training_loss": 4.559922285079956, "training_acc": 50.0, "val_loss": 1.6451305437088013, "val_acc": 52.0}
{"epoch": 3, "training_loss": 1.326366856098175, "training_acc": 58.0, "val_loss": 0.8951161003112793, "val_acc": 48.0}
{"epoch": 4, "training_loss": 1.1353203248977661, "training_acc": 54.0, "val_loss": 0.7711281514167786, "val_acc": 52.0}
{"epoch": 5, "training_loss": 0.9331663513183593, "training_acc": 60.0, "val_loss": 0.9677132081985473, "val_acc": 48.0}
{"epoch": 6, "training_loss": 0.7870437049865723, "training_acc": 54.0, "val_loss": 0.7985030984878541, "val_acc": 48.0}
{"epoch": 7, "training_loss": 0.9413250350952148, "training_acc": 58.0, "val_loss": 0.801842987537384, "val_acc": 52.0}
{"epoch": 8, "training_loss": 1.0140392208099365, "training_acc": 46.0, "val_loss": 1.1726822137832642, "val_acc": 48.0}
{"epoch": 9, "training_loss": 1.4277282094955444, "training_acc": 48.0, "val_loss": 0.8526081252098083, "val_acc": 48.0}
{"epoch": 10, "training_loss": 0.9393249106407165, "training_acc": 46.0, "val_loss": 0.7858494520187378, "val_acc": 48.0}
{"epoch": 11, "training_loss": 0.9632351779937744, "training_acc": 44.0, "val_loss": 0.7503330612182617, "val_acc": 52.0}
{"epoch": 12, "training_loss": 0.793741545677185, "training_acc": 54.0, "val_loss": 1.226377568244934, "val_acc": 48.0}
{"epoch": 13, "training_loss": 0.9734021902084351, "training_acc": 50.0, "val_loss": 1.1413519287109375, "val_acc": 52.0}
{"epoch": 14, "training_loss": 1.0550794219970703, "training_acc": 42.0, "val_loss": 1.0110488891601563, "val_acc": 52.0}
{"epoch": 15, "training_loss": 2.1379265785217285, "training_acc": 52.0, "val_loss": 1.9580101203918456, "val_acc": 52.0}
{"epoch": 16, "training_loss": 3.3671625900268554, "training_acc": 48.0, "val_loss": 4.494585838317871, "val_acc": 52.0}
{"epoch": 17, "training_loss": 3.2920006322860718, "training_acc": 58.0, "val_loss": 5.159764499664306, "val_acc": 52.0}
{"epoch": 18, "training_loss": 2.966688566207886, "training_acc": 50.0, "val_loss": 0.6954895949363709, "val_acc": 48.0}
{"epoch": 19, "training_loss": 0.9150501728057862, "training_acc": 50.0, "val_loss": 0.7111235070228576, "val_acc": 48.0}
{"epoch": 20, "training_loss": 0.6967548704147339, "training_acc": 62.0, "val_loss": 3.369687578678131, "val_acc": 48.0}
{"epoch": 21, "training_loss": 2.3783033084869385, "training_acc": 50.0, "val_loss": 2.104860682487488, "val_acc": 48.0}
{"epoch": 22, "training_loss": 1.9551034355163575, "training_acc": 52.0, "val_loss": 2.9858021259307863, "val_acc": 52.0}
{"epoch": 23, "training_loss": 2.721482696533203, "training_acc": 42.0, "val_loss": 0.7817891836166382, "val_acc": 48.0}
{"epoch": 24, "training_loss": 0.9030008292198182, "training_acc": 56.0, "val_loss": 0.6953989696502686, "val_acc": 52.0}
{"epoch": 25, "training_loss": 1.7031412982940675, "training_acc": 60.0, "val_loss": 1.8989427757263184, "val_acc": 52.0}
{"epoch": 26, "training_loss": 1.1341603469848633, "training_acc": 56.0, "val_loss": 2.09387788772583, "val_acc": 48.0}
{"epoch": 27, "training_loss": 1.0696386781334877, "training_acc": 54.0, "val_loss": 2.9703800010681154, "val_acc": 52.0}
{"epoch": 28, "training_loss": 2.130000352859497, "training_acc": 50.0, "val_loss": 2.2148812580108643, "val_acc": 48.0}
{"epoch": 29, "training_loss": 1.2038356280326843, "training_acc": 53.0, "val_loss": 1.2299445962905884, "val_acc": 52.0}
{"epoch": 30, "training_loss": 1.1779907751083374, "training_acc": 50.0, "val_loss": 0.6982732009887695, "val_acc": 48.0}
{"epoch": 31, "training_loss": 0.9063818311691284, "training_acc": 48.0, "val_loss": 0.9205639696121216, "val_acc": 48.0}
{"epoch": 32, "training_loss": 0.9809163498878479, "training_acc": 49.0, "val_loss": 1.4548186206817626, "val_acc": 48.0}
{"epoch": 33, "training_loss": 1.0571624994277955, "training_acc": 50.0, "val_loss": 3.210654602050781, "val_acc": 48.0}
{"epoch": 34, "training_loss": 2.2276997184753418, "training_acc": 52.0, "val_loss": 2.232421293258667, "val_acc": 48.0}
{"epoch": 35, "training_loss": 1.793146619796753, "training_acc": 50.0, "val_loss": 1.5495617961883545, "val_acc": 52.0}
{"epoch": 36, "training_loss": 1.363071141242981, "training_acc": 52.0, "val_loss": 2.3334089851379396, "val_acc": 52.0}
{"epoch": 37, "training_loss": 1.8001558303833007, "training_acc": 46.0, "val_loss": 2.008747673034668, "val_acc": 48.0}
{"epoch": 38, "training_loss": 1.795456886291504, "training_acc": 46.0, "val_loss": 1.1178415536880493, "val_acc": 52.0}
{"epoch": 39, "training_loss": 0.9791597843170166, "training_acc": 50.0, "val_loss": 0.7212729334831238, "val_acc": 48.0}
{"epoch": 40, "training_loss": 0.958818883895874, "training_acc": 50.0, "val_loss": 0.7248646593093873, "val_acc": 48.0}
{"epoch": 41, "training_loss": 0.8800869488716125, "training_acc": 46.0, "val_loss": 2.5224554443359377, "val_acc": 48.0}
{"epoch": 42, "training_loss": 1.345573868751526, "training_acc": 56.0, "val_loss": 0.8594366097450257, "val_acc": 52.0}
{"epoch": 43, "training_loss": 1.8443215990066528, "training_acc": 47.0, "val_loss": 1.2286388349533082, "val_acc": 52.0}
