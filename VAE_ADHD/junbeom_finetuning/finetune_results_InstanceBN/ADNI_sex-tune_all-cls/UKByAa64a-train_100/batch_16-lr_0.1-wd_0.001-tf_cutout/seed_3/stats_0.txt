"main_modify.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 3 --task ADNI_sex --input_option yAware --learning_rate 1e-1 --batch_size 16 --weight_decay 1e-3 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 11.055550184249878, "training_acc": 48.0, "val_loss": 1.1122536325454713, "val_acc": 52.0}
{"epoch": 1, "training_loss": 5.8469420909881595, "training_acc": 48.0, "val_loss": 8.906085891723633, "val_acc": 52.0}
{"epoch": 2, "training_loss": 6.514259977340698, "training_acc": 52.0, "val_loss": 7.979733257293701, "val_acc": 48.0}
{"epoch": 3, "training_loss": 4.73668140411377, "training_acc": 56.0, "val_loss": 6.001644878387451, "val_acc": 52.0}
{"epoch": 4, "training_loss": 3.469784870147705, "training_acc": 52.0, "val_loss": 3.7269993591308594, "val_acc": 52.0}
{"epoch": 5, "training_loss": 4.2743886280059815, "training_acc": 48.0, "val_loss": 2.4863737869262694, "val_acc": 48.0}
{"epoch": 6, "training_loss": 1.802366065979004, "training_acc": 56.0, "val_loss": 0.9653874206542968, "val_acc": 48.0}
{"epoch": 7, "training_loss": 0.754251298904419, "training_acc": 56.0, "val_loss": 0.7166797876358032, "val_acc": 52.0}
{"epoch": 8, "training_loss": 1.411565899848938, "training_acc": 50.0, "val_loss": 0.8074246382713318, "val_acc": 48.0}
{"epoch": 9, "training_loss": 1.250261869430542, "training_acc": 54.0, "val_loss": 0.7432202053070068, "val_acc": 52.0}
{"epoch": 10, "training_loss": 1.4489883214235306, "training_acc": 51.0, "val_loss": 4.264149837493896, "val_acc": 48.0}
{"epoch": 11, "training_loss": 3.1049470591545103, "training_acc": 52.0, "val_loss": 3.735772132873535, "val_acc": 48.0}
{"epoch": 12, "training_loss": 2.054989151954651, "training_acc": 46.0, "val_loss": 0.7049018502235412, "val_acc": 48.0}
{"epoch": 13, "training_loss": 0.9563300943374634, "training_acc": 52.0, "val_loss": 1.0566293334960937, "val_acc": 52.0}
{"epoch": 14, "training_loss": 0.9251634073257446, "training_acc": 49.0, "val_loss": 1.784742784500122, "val_acc": 48.0}
{"epoch": 15, "training_loss": 1.1004344749450683, "training_acc": 44.0, "val_loss": 0.7956737208366395, "val_acc": 48.0}
{"epoch": 16, "training_loss": 1.1684025526046753, "training_acc": 58.0, "val_loss": 2.218122806549072, "val_acc": 52.0}
{"epoch": 17, "training_loss": 2.1506642723083496, "training_acc": 48.0, "val_loss": 2.0017029237747193, "val_acc": 52.0}
{"epoch": 18, "training_loss": 1.8514408659934998, "training_acc": 50.0, "val_loss": 2.445952281951904, "val_acc": 48.0}
{"epoch": 19, "training_loss": 1.7906734561920166, "training_acc": 52.0, "val_loss": 1.2634870862960816, "val_acc": 48.0}
{"epoch": 20, "training_loss": 1.0185230541229249, "training_acc": 48.0, "val_loss": 0.6940435457229615, "val_acc": 52.0}
{"epoch": 21, "training_loss": 0.8937482118606568, "training_acc": 48.0, "val_loss": 0.693017749786377, "val_acc": 52.0}
{"epoch": 22, "training_loss": 0.8383200526237488, "training_acc": 50.0, "val_loss": 2.3781229877471923, "val_acc": 52.0}
{"epoch": 23, "training_loss": 2.0696205425262453, "training_acc": 46.0, "val_loss": 1.569325406551361, "val_acc": 52.0}
{"epoch": 24, "training_loss": 2.1972987031936646, "training_acc": 52.0, "val_loss": 1.9267689895629883, "val_acc": 48.0}
{"epoch": 25, "training_loss": 1.3191697883605957, "training_acc": 44.0, "val_loss": 2.6818443012237547, "val_acc": 48.0}
{"epoch": 26, "training_loss": 1.9103652381896972, "training_acc": 52.0, "val_loss": 2.0889792442321777, "val_acc": 48.0}
{"epoch": 27, "training_loss": 2.253721890449524, "training_acc": 44.0, "val_loss": 1.8158153796195984, "val_acc": 52.0}
{"epoch": 28, "training_loss": 1.5676570320129395, "training_acc": 48.0, "val_loss": 2.4488105392456054, "val_acc": 48.0}
{"epoch": 29, "training_loss": 2.21057776927948, "training_acc": 48.0, "val_loss": 1.5584318161010742, "val_acc": 48.0}
{"epoch": 30, "training_loss": 1.1263828897476196, "training_acc": 48.0, "val_loss": 1.0016430616378784, "val_acc": 52.0}
{"epoch": 31, "training_loss": 0.988175573348999, "training_acc": 50.0, "val_loss": 2.448179349899292, "val_acc": 48.0}
{"epoch": 32, "training_loss": 2.055827159881592, "training_acc": 48.0, "val_loss": 1.9019537258148194, "val_acc": 52.0}
{"epoch": 33, "training_loss": 2.07400776386261, "training_acc": 60.0, "val_loss": 1.3192487478256225, "val_acc": 52.0}
{"epoch": 34, "training_loss": 1.8032359528541564, "training_acc": 42.0, "val_loss": 1.6248502874374389, "val_acc": 48.0}
{"epoch": 35, "training_loss": 1.375046935081482, "training_acc": 50.0, "val_loss": 0.7411630916595459, "val_acc": 52.0}
{"epoch": 36, "training_loss": 0.9111209344863892, "training_acc": 50.0, "val_loss": 1.3343186950683594, "val_acc": 48.0}
{"epoch": 37, "training_loss": 0.9458519506454468, "training_acc": 43.0, "val_loss": 0.6806585836410523, "val_acc": 68.0}
{"epoch": 38, "training_loss": 0.7117267513275146, "training_acc": 53.0, "val_loss": 0.8114602780342102, "val_acc": 52.0}
{"epoch": 39, "training_loss": 0.9620219230651855, "training_acc": 46.0, "val_loss": 0.9846281623840332, "val_acc": 48.0}
{"epoch": 40, "training_loss": 0.9415484809875488, "training_acc": 53.0, "val_loss": 0.767539324760437, "val_acc": 52.0}
{"epoch": 41, "training_loss": 1.362514944076538, "training_acc": 46.0, "val_loss": 0.6959843420982361, "val_acc": 52.0}
{"epoch": 42, "training_loss": 1.415010871887207, "training_acc": 54.0, "val_loss": 0.9087801504135132, "val_acc": 48.0}
{"epoch": 43, "training_loss": 1.1060096359252929, "training_acc": 48.0, "val_loss": 2.54260160446167, "val_acc": 48.0}
{"epoch": 44, "training_loss": 1.8737785959243773, "training_acc": 48.0, "val_loss": 1.3910700225830077, "val_acc": 48.0}
{"epoch": 45, "training_loss": 1.1560794067382814, "training_acc": 48.0, "val_loss": 2.2443239450454713, "val_acc": 48.0}
{"epoch": 46, "training_loss": 1.5411970329284668, "training_acc": 58.0, "val_loss": 1.7928368759155273, "val_acc": 48.0}
{"epoch": 47, "training_loss": 1.622565622329712, "training_acc": 51.0, "val_loss": 0.7196889615058899, "val_acc": 48.0}
{"epoch": 48, "training_loss": 1.4112194085121155, "training_acc": 50.0, "val_loss": 1.1163005971908568, "val_acc": 48.0}
{"epoch": 49, "training_loss": 0.9426768732070923, "training_acc": 52.0, "val_loss": 1.782474889755249, "val_acc": 52.0}
{"epoch": 50, "training_loss": 1.467815363407135, "training_acc": 52.0, "val_loss": 1.6924081897735597, "val_acc": 52.0}
{"epoch": 51, "training_loss": 1.4503650665283203, "training_acc": 56.0, "val_loss": 1.9241134548187255, "val_acc": 52.0}
{"epoch": 52, "training_loss": 1.7241451048851013, "training_acc": 44.0, "val_loss": 1.7033595895767213, "val_acc": 52.0}
{"epoch": 53, "training_loss": 1.0400484013557434, "training_acc": 48.0, "val_loss": 1.0440289497375488, "val_acc": 48.0}
{"epoch": 54, "training_loss": 0.8562110543251038, "training_acc": 40.0, "val_loss": 1.7359445667266846, "val_acc": 52.0}
{"epoch": 55, "training_loss": 1.2119549369812013, "training_acc": 50.0, "val_loss": 1.0460224914550782, "val_acc": 52.0}
{"epoch": 56, "training_loss": 0.9037992000579834, "training_acc": 44.0, "val_loss": 1.0072430229187013, "val_acc": 52.0}
