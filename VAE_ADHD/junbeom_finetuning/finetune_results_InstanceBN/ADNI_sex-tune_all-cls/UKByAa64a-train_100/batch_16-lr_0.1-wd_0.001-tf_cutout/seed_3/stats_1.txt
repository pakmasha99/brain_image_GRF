"main_modify.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 3 --task ADNI_sex --input_option yAware --learning_rate 1e-1 --batch_size 16 --weight_decay 1e-3 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 8.358098182678223, "training_acc": 50.0, "val_loss": 4.304304943084717, "val_acc": 52.0}
{"epoch": 1, "training_loss": 4.765924453735352, "training_acc": 46.0, "val_loss": 0.7019733500480652, "val_acc": 52.0}
{"epoch": 2, "training_loss": 1.0741922760009766, "training_acc": 44.0, "val_loss": 0.7970680856704712, "val_acc": 52.0}
{"epoch": 3, "training_loss": 1.061371054649353, "training_acc": 44.0, "val_loss": 0.8242286539077759, "val_acc": 52.0}
{"epoch": 4, "training_loss": 1.0685893630981445, "training_acc": 42.0, "val_loss": 0.6942005443572998, "val_acc": 52.0}
{"epoch": 5, "training_loss": 0.779558470249176, "training_acc": 44.0, "val_loss": 1.3184941482543946, "val_acc": 48.0}
{"epoch": 6, "training_loss": 3.4107976579666137, "training_acc": 48.0, "val_loss": 2.791434645652771, "val_acc": 48.0}
{"epoch": 7, "training_loss": 5.741515097618103, "training_acc": 46.0, "val_loss": 4.810962429046631, "val_acc": 48.0}
{"epoch": 8, "training_loss": 4.579403438568115, "training_acc": 46.0, "val_loss": 2.5510991477966307, "val_acc": 52.0}
{"epoch": 9, "training_loss": 1.5684654498100281, "training_acc": 38.0, "val_loss": 1.1073683547973632, "val_acc": 48.0}
{"epoch": 10, "training_loss": 1.6655551528930663, "training_acc": 42.0, "val_loss": 3.0878363275527954, "val_acc": 48.0}
{"epoch": 11, "training_loss": 3.6877067375183104, "training_acc": 46.0, "val_loss": 3.4394940662384035, "val_acc": 48.0}
{"epoch": 12, "training_loss": 3.0758732604980468, "training_acc": 56.0, "val_loss": 0.6955110049247741, "val_acc": 52.0}
{"epoch": 13, "training_loss": 1.839450228214264, "training_acc": 60.0, "val_loss": 1.0514870119094848, "val_acc": 48.0}
{"epoch": 14, "training_loss": 0.9272916793823243, "training_acc": 54.0, "val_loss": 0.7698311328887939, "val_acc": 52.0}
{"epoch": 15, "training_loss": 0.7277772998809815, "training_acc": 56.0, "val_loss": 0.8895849776268006, "val_acc": 52.0}
{"epoch": 16, "training_loss": 1.1444069051742554, "training_acc": 48.0, "val_loss": 0.717228741645813, "val_acc": 48.0}
{"epoch": 17, "training_loss": 1.113620297908783, "training_acc": 52.0, "val_loss": 0.6930122303962708, "val_acc": 52.0}
{"epoch": 18, "training_loss": 0.8197970056533813, "training_acc": 50.0, "val_loss": 1.740866117477417, "val_acc": 48.0}
{"epoch": 19, "training_loss": 1.0775603294372558, "training_acc": 52.0, "val_loss": 0.7191828155517578, "val_acc": 48.0}
{"epoch": 20, "training_loss": 0.9121510076522827, "training_acc": 48.0, "val_loss": 2.0699870014190673, "val_acc": 52.0}
{"epoch": 21, "training_loss": 1.7784372663497925, "training_acc": 44.0, "val_loss": 1.1413247299194336, "val_acc": 48.0}
{"epoch": 22, "training_loss": 1.0496222591400146, "training_acc": 50.0, "val_loss": 1.904841103553772, "val_acc": 48.0}
{"epoch": 23, "training_loss": 1.0383694410324096, "training_acc": 54.0, "val_loss": 1.6208158349990844, "val_acc": 52.0}
{"epoch": 24, "training_loss": 1.7890887975692749, "training_acc": 48.0, "val_loss": 1.5438339185714722, "val_acc": 48.0}
{"epoch": 25, "training_loss": 1.541191782951355, "training_acc": 52.0, "val_loss": 1.4968123602867127, "val_acc": 48.0}
{"epoch": 26, "training_loss": 2.21193808555603, "training_acc": 50.0, "val_loss": 2.2554680633544923, "val_acc": 52.0}
{"epoch": 27, "training_loss": 3.9573755645751953, "training_acc": 50.0, "val_loss": 3.766181163787842, "val_acc": 48.0}
{"epoch": 28, "training_loss": 3.018674736022949, "training_acc": 50.0, "val_loss": 1.8328652906417846, "val_acc": 48.0}
{"epoch": 29, "training_loss": 2.6629103088378905, "training_acc": 42.0, "val_loss": 2.5427603340148925, "val_acc": 52.0}
{"epoch": 30, "training_loss": 2.67201274394989, "training_acc": 44.0, "val_loss": 3.9940225219726564, "val_acc": 52.0}
{"epoch": 31, "training_loss": 3.5185279655456543, "training_acc": 44.0, "val_loss": 1.8779255867004394, "val_acc": 52.0}
{"epoch": 32, "training_loss": 1.6111826229095458, "training_acc": 50.0, "val_loss": 1.8740067529678344, "val_acc": 48.0}
{"epoch": 33, "training_loss": 1.7342608737945557, "training_acc": 46.0, "val_loss": 0.8847647523880005, "val_acc": 48.0}
{"epoch": 34, "training_loss": 2.5304337310791016, "training_acc": 52.0, "val_loss": 5.837420063018799, "val_acc": 48.0}
{"epoch": 35, "training_loss": 3.1121192836761473, "training_acc": 44.0, "val_loss": 1.9181494045257568, "val_acc": 48.0}
{"epoch": 36, "training_loss": 1.4403994178771973, "training_acc": 46.0, "val_loss": 0.8116933679580689, "val_acc": 48.0}
