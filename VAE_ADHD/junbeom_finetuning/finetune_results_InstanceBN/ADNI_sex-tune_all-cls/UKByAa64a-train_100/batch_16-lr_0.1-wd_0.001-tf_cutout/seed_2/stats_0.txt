"main_modify.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 2 --task ADNI_sex --input_option yAware --learning_rate 1e-1 --batch_size 16 --weight_decay 1e-3 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 12.992131357192994, "training_acc": 46.0, "val_loss": 5.759724979400635, "val_acc": 48.0}
{"epoch": 1, "training_loss": 4.942105121612549, "training_acc": 52.0, "val_loss": 5.129447956085205, "val_acc": 48.0}
{"epoch": 2, "training_loss": 4.415165042877197, "training_acc": 44.0, "val_loss": 3.7567888832092287, "val_acc": 48.0}
{"epoch": 3, "training_loss": 3.8396326446533204, "training_acc": 46.0, "val_loss": 0.7003451919555664, "val_acc": 48.0}
{"epoch": 4, "training_loss": 1.2754450130462647, "training_acc": 57.0, "val_loss": 0.9439735507965088, "val_acc": 48.0}
{"epoch": 5, "training_loss": 0.9048411273956298, "training_acc": 52.0, "val_loss": 1.9943419075012208, "val_acc": 52.0}
{"epoch": 6, "training_loss": 1.3059659862518311, "training_acc": 52.0, "val_loss": 1.391685140132904, "val_acc": 52.0}
{"epoch": 7, "training_loss": 1.6436634969711303, "training_acc": 44.0, "val_loss": 1.7555161714553833, "val_acc": 48.0}
{"epoch": 8, "training_loss": 1.4424222445487975, "training_acc": 46.0, "val_loss": 1.7023327112197877, "val_acc": 52.0}
{"epoch": 9, "training_loss": 1.6245522594451904, "training_acc": 50.0, "val_loss": 0.954504861831665, "val_acc": 52.0}
{"epoch": 10, "training_loss": 2.7195423889160155, "training_acc": 44.0, "val_loss": 1.2458765506744385, "val_acc": 48.0}
{"epoch": 11, "training_loss": 1.3631140470504761, "training_acc": 50.0, "val_loss": 3.563170175552368, "val_acc": 48.0}
{"epoch": 12, "training_loss": 3.163828887939453, "training_acc": 36.0, "val_loss": 1.8138723659515381, "val_acc": 48.0}
{"epoch": 13, "training_loss": 3.0175297164916994, "training_acc": 48.0, "val_loss": 4.122893409729004, "val_acc": 48.0}
{"epoch": 14, "training_loss": 2.9198322772979735, "training_acc": 48.0, "val_loss": 4.801081829071045, "val_acc": 48.0}
{"epoch": 15, "training_loss": 3.4978964853286745, "training_acc": 46.0, "val_loss": 1.749240255355835, "val_acc": 48.0}
{"epoch": 16, "training_loss": 1.7266583919525147, "training_acc": 50.0, "val_loss": 1.901859874725342, "val_acc": 48.0}
{"epoch": 17, "training_loss": 1.802464361190796, "training_acc": 50.0, "val_loss": 3.291448936462402, "val_acc": 48.0}
{"epoch": 18, "training_loss": 1.9482816648483277, "training_acc": 58.0, "val_loss": 3.2974861907958983, "val_acc": 48.0}
{"epoch": 19, "training_loss": 3.1138865184783935, "training_acc": 52.0, "val_loss": 1.2831040048599243, "val_acc": 52.0}
{"epoch": 20, "training_loss": 1.9409631657600404, "training_acc": 48.0, "val_loss": 0.6950592160224914, "val_acc": 52.0}
{"epoch": 21, "training_loss": 0.7918599724769593, "training_acc": 52.0, "val_loss": 1.4363351941108704, "val_acc": 52.0}
{"epoch": 22, "training_loss": 1.2129661226272583, "training_acc": 46.0, "val_loss": 1.32543137550354, "val_acc": 48.0}
{"epoch": 23, "training_loss": 1.3094596767425537, "training_acc": 46.0, "val_loss": 1.3261789441108705, "val_acc": 52.0}
{"epoch": 24, "training_loss": 1.892927780151367, "training_acc": 48.0, "val_loss": 0.9496766805648804, "val_acc": 48.0}
{"epoch": 25, "training_loss": 2.0929367446899416, "training_acc": 48.0, "val_loss": 2.9287855434417724, "val_acc": 48.0}
{"epoch": 26, "training_loss": 1.975995841026306, "training_acc": 50.0, "val_loss": 4.035434999465942, "val_acc": 48.0}
{"epoch": 27, "training_loss": 3.2992277574539184, "training_acc": 44.0, "val_loss": 2.6535191249847414, "val_acc": 48.0}
{"epoch": 28, "training_loss": 2.1208509159088136, "training_acc": 58.0, "val_loss": 0.7277940356731415, "val_acc": 52.0}
{"epoch": 29, "training_loss": 2.29506498336792, "training_acc": 46.0, "val_loss": 2.062763032913208, "val_acc": 48.0}
{"epoch": 30, "training_loss": 2.409822256565094, "training_acc": 50.0, "val_loss": 2.4584885311126707, "val_acc": 48.0}
{"epoch": 31, "training_loss": 2.248238925933838, "training_acc": 46.0, "val_loss": 1.304085030555725, "val_acc": 48.0}
{"epoch": 32, "training_loss": 1.2582187128067017, "training_acc": 46.0, "val_loss": 0.6833272767066956, "val_acc": 48.0}
{"epoch": 33, "training_loss": 1.1536639404296876, "training_acc": 45.0, "val_loss": 1.9987498950958251, "val_acc": 48.0}
{"epoch": 34, "training_loss": 1.6306872701644897, "training_acc": 46.0, "val_loss": 0.7549445128440857, "val_acc": 48.0}
{"epoch": 35, "training_loss": 0.885755295753479, "training_acc": 44.0, "val_loss": 0.9550255393981933, "val_acc": 52.0}
{"epoch": 36, "training_loss": 0.824503014087677, "training_acc": 60.0, "val_loss": 0.8728693032264709, "val_acc": 52.0}
{"epoch": 37, "training_loss": 0.7994122231006622, "training_acc": 50.0, "val_loss": 2.7719363498687746, "val_acc": 52.0}
{"epoch": 38, "training_loss": 2.1393425178527834, "training_acc": 46.0, "val_loss": 0.8173075079917907, "val_acc": 48.0}
{"epoch": 39, "training_loss": 1.2584912109375, "training_acc": 46.0, "val_loss": 1.0274543833732606, "val_acc": 52.0}
{"epoch": 40, "training_loss": 1.8662267112731934, "training_acc": 50.0, "val_loss": 2.313151969909668, "val_acc": 52.0}
{"epoch": 41, "training_loss": 1.395348858833313, "training_acc": 46.0, "val_loss": 1.0833830738067627, "val_acc": 48.0}
{"epoch": 42, "training_loss": 1.612373685836792, "training_acc": 45.0, "val_loss": 1.032531042098999, "val_acc": 52.0}
{"epoch": 43, "training_loss": 0.7802687644958496, "training_acc": 50.0, "val_loss": 1.5468144845962524, "val_acc": 52.0}
{"epoch": 44, "training_loss": 1.3482552373409271, "training_acc": 54.0, "val_loss": 1.198435673713684, "val_acc": 52.0}
{"epoch": 45, "training_loss": 1.2605559492111207, "training_acc": 54.0, "val_loss": 1.94070641040802, "val_acc": 48.0}
{"epoch": 46, "training_loss": 1.3562907814979552, "training_acc": 56.0, "val_loss": 0.7213186883926391, "val_acc": 48.0}
{"epoch": 47, "training_loss": 0.714047884941101, "training_acc": 54.0, "val_loss": 0.9323668241500854, "val_acc": 48.0}
{"epoch": 48, "training_loss": 1.4141077494621277, "training_acc": 46.0, "val_loss": 2.0786055660247804, "val_acc": 52.0}
{"epoch": 49, "training_loss": 1.6778024005889893, "training_acc": 50.0, "val_loss": 0.8779028248786926, "val_acc": 52.0}
{"epoch": 50, "training_loss": 1.0074534606933594, "training_acc": 42.0, "val_loss": 2.4260156536102295, "val_acc": 48.0}
{"epoch": 51, "training_loss": 1.1985970664024352, "training_acc": 56.0, "val_loss": 0.7859133100509643, "val_acc": 48.0}
