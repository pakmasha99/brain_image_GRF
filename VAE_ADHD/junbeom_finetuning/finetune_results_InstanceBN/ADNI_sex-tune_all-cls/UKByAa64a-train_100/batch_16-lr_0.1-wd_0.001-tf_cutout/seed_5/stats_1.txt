"main_modify.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 5 --task ADNI_sex --input_option yAware --learning_rate 1e-1 --batch_size 16 --weight_decay 1e-3 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 9.889563570022583, "training_acc": 48.0, "val_loss": 2.958499622344971, "val_acc": 48.0}
{"epoch": 1, "training_loss": 3.3918835043907167, "training_acc": 50.0, "val_loss": 0.6999233913421631, "val_acc": 44.0}
{"epoch": 2, "training_loss": 0.894374270439148, "training_acc": 54.0, "val_loss": 3.375440502166748, "val_acc": 52.0}
{"epoch": 3, "training_loss": 2.9436452770233155, "training_acc": 56.0, "val_loss": 1.7862595081329347, "val_acc": 52.0}
{"epoch": 4, "training_loss": 1.718374490737915, "training_acc": 46.0, "val_loss": 0.7311671805381775, "val_acc": 48.0}
{"epoch": 5, "training_loss": 1.5621790409088134, "training_acc": 44.0, "val_loss": 0.8930444884300232, "val_acc": 52.0}
{"epoch": 6, "training_loss": 2.694503302574158, "training_acc": 44.0, "val_loss": 1.6656851959228516, "val_acc": 48.0}
{"epoch": 7, "training_loss": 1.023985424041748, "training_acc": 52.0, "val_loss": 0.6965862369537353, "val_acc": 52.0}
{"epoch": 8, "training_loss": 1.005089225769043, "training_acc": 46.0, "val_loss": 1.3897940564155578, "val_acc": 48.0}
{"epoch": 9, "training_loss": 0.8518796253204346, "training_acc": 52.0, "val_loss": 1.1080996942520143, "val_acc": 52.0}
{"epoch": 10, "training_loss": 0.756878695487976, "training_acc": 54.0, "val_loss": 1.104734983444214, "val_acc": 48.0}
{"epoch": 11, "training_loss": 2.9835397720336916, "training_acc": 46.0, "val_loss": 1.9910768127441407, "val_acc": 48.0}
{"epoch": 12, "training_loss": 4.096185607910156, "training_acc": 52.0, "val_loss": 7.6887431335449214, "val_acc": 48.0}
{"epoch": 13, "training_loss": 6.875138397216797, "training_acc": 42.0, "val_loss": 6.3448443031311035, "val_acc": 52.0}
{"epoch": 14, "training_loss": 7.562879848480224, "training_acc": 44.0, "val_loss": 2.2678443813323974, "val_acc": 52.0}
{"epoch": 15, "training_loss": 5.179787082672119, "training_acc": 48.0, "val_loss": 4.294441404342652, "val_acc": 48.0}
{"epoch": 16, "training_loss": 2.3093467330932618, "training_acc": 50.0, "val_loss": 0.9001073575019837, "val_acc": 52.0}
{"epoch": 17, "training_loss": 1.1871204161643982, "training_acc": 50.0, "val_loss": 0.9849319648742676, "val_acc": 52.0}
{"epoch": 18, "training_loss": 1.1930243968963623, "training_acc": 46.0, "val_loss": 2.002255563735962, "val_acc": 52.0}
{"epoch": 19, "training_loss": 1.1414592504501342, "training_acc": 50.0, "val_loss": 0.7233753252029419, "val_acc": 48.0}
{"epoch": 20, "training_loss": 0.7853029870986938, "training_acc": 52.0, "val_loss": 1.7612246942520142, "val_acc": 48.0}
{"epoch": 21, "training_loss": 2.1894561004638673, "training_acc": 40.0, "val_loss": 1.2748846340179443, "val_acc": 48.0}
{"epoch": 22, "training_loss": 1.622523603439331, "training_acc": 52.0, "val_loss": 0.7162755966186524, "val_acc": 52.0}
{"epoch": 23, "training_loss": 0.7715953111648559, "training_acc": 52.0, "val_loss": 0.69516517162323, "val_acc": 48.0}
{"epoch": 24, "training_loss": 0.8484422874450683, "training_acc": 50.0, "val_loss": 0.7062711024284363, "val_acc": 48.0}
{"epoch": 25, "training_loss": 0.9404647660255432, "training_acc": 48.0, "val_loss": 1.741541361808777, "val_acc": 48.0}
{"epoch": 26, "training_loss": 1.2869221901893615, "training_acc": 52.0, "val_loss": 1.3476488971710205, "val_acc": 52.0}
{"epoch": 27, "training_loss": 0.9176248931884765, "training_acc": 54.0, "val_loss": 0.9697921133041382, "val_acc": 48.0}
{"epoch": 28, "training_loss": 0.8752402544021607, "training_acc": 44.0, "val_loss": 1.5154492855072021, "val_acc": 52.0}
{"epoch": 29, "training_loss": 0.9630914855003357, "training_acc": 50.0, "val_loss": 0.7037503099441529, "val_acc": 48.0}
{"epoch": 30, "training_loss": 0.8348925590515137, "training_acc": 48.0, "val_loss": 3.6920427322387694, "val_acc": 48.0}
{"epoch": 31, "training_loss": 3.1165335750579835, "training_acc": 54.0, "val_loss": 0.7304419684410095, "val_acc": 52.0}
{"epoch": 32, "training_loss": 1.3022524309158325, "training_acc": 56.0, "val_loss": 0.9256146311759949, "val_acc": 48.0}
{"epoch": 33, "training_loss": 0.9334599590301513, "training_acc": 56.0, "val_loss": 0.839927875995636, "val_acc": 48.0}
{"epoch": 34, "training_loss": 0.8785152244567871, "training_acc": 46.0, "val_loss": 1.4589750862121582, "val_acc": 52.0}
{"epoch": 35, "training_loss": 0.8421682119369507, "training_acc": 60.0, "val_loss": 1.0341588711738587, "val_acc": 52.0}
{"epoch": 36, "training_loss": 0.895779390335083, "training_acc": 64.0, "val_loss": 1.1677567481994628, "val_acc": 48.0}
{"epoch": 37, "training_loss": 1.4664838075637818, "training_acc": 50.0, "val_loss": 2.53632568359375, "val_acc": 52.0}
{"epoch": 38, "training_loss": 2.102347187995911, "training_acc": 56.0, "val_loss": 1.8178826427459718, "val_acc": 52.0}
{"epoch": 39, "training_loss": 1.1808607175946235, "training_acc": 56.0, "val_loss": 3.7178924560546873, "val_acc": 48.0}
{"epoch": 40, "training_loss": 2.040467371940613, "training_acc": 50.0, "val_loss": 1.019139699935913, "val_acc": 52.0}
{"epoch": 41, "training_loss": 1.1336759281158448, "training_acc": 54.0, "val_loss": 0.8395680570602417, "val_acc": 52.0}
{"epoch": 42, "training_loss": 1.2985827255249023, "training_acc": 50.0, "val_loss": 0.7456014752388, "val_acc": 52.0}
