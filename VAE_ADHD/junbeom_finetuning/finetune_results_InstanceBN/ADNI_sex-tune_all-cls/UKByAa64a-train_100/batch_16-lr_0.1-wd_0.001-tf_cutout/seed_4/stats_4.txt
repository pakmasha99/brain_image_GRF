"main_modify.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 4 --task ADNI_sex --input_option yAware --learning_rate 1e-1 --batch_size 16 --weight_decay 1e-3 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 7.481527414321899, "training_acc": 48.0, "val_loss": 5.211733570098877, "val_acc": 52.0}
{"epoch": 1, "training_loss": 3.995584259033203, "training_acc": 46.0, "val_loss": 4.319431629180908, "val_acc": 52.0}
{"epoch": 2, "training_loss": 3.0803258323669436, "training_acc": 42.0, "val_loss": 2.2173779582977295, "val_acc": 52.0}
{"epoch": 3, "training_loss": 1.5057914233207703, "training_acc": 48.0, "val_loss": 0.8152054023742675, "val_acc": 52.0}
{"epoch": 4, "training_loss": 0.8498169422149658, "training_acc": 50.0, "val_loss": 1.0741632318496703, "val_acc": 52.0}
{"epoch": 5, "training_loss": 1.0615322160720826, "training_acc": 54.0, "val_loss": 1.4673910570144653, "val_acc": 48.0}
{"epoch": 6, "training_loss": 0.8803220319747925, "training_acc": 48.0, "val_loss": 0.9117639470100403, "val_acc": 52.0}
{"epoch": 7, "training_loss": 1.0899648427963258, "training_acc": 48.0, "val_loss": 2.2909907293319702, "val_acc": 48.0}
{"epoch": 8, "training_loss": 1.4013229012489319, "training_acc": 50.0, "val_loss": 1.2073195600509643, "val_acc": 48.0}
{"epoch": 9, "training_loss": 0.9697382974624634, "training_acc": 50.0, "val_loss": 1.3909566593170166, "val_acc": 48.0}
{"epoch": 10, "training_loss": 1.7583531951904297, "training_acc": 52.0, "val_loss": 0.8495679330825806, "val_acc": 52.0}
{"epoch": 11, "training_loss": 1.0455381774902344, "training_acc": 56.0, "val_loss": 0.9791023159027099, "val_acc": 48.0}
{"epoch": 12, "training_loss": 1.059165554046631, "training_acc": 48.0, "val_loss": 2.24996036529541, "val_acc": 48.0}
{"epoch": 13, "training_loss": 1.5032481002807616, "training_acc": 56.0, "val_loss": 1.5141242122650147, "val_acc": 48.0}
{"epoch": 14, "training_loss": 0.854264280796051, "training_acc": 52.0, "val_loss": 1.9685906124114991, "val_acc": 48.0}
{"epoch": 15, "training_loss": 1.5451504468917847, "training_acc": 52.0, "val_loss": 0.8364401221275329, "val_acc": 48.0}
{"epoch": 16, "training_loss": 0.9991145944595337, "training_acc": 56.0, "val_loss": 0.9419261860847473, "val_acc": 48.0}
{"epoch": 17, "training_loss": 0.9389374208450317, "training_acc": 46.0, "val_loss": 0.7452148294448853, "val_acc": 48.0}
{"epoch": 18, "training_loss": 1.7236031770706177, "training_acc": 42.0, "val_loss": 0.8732746076583863, "val_acc": 48.0}
{"epoch": 19, "training_loss": 1.7777608847618103, "training_acc": 42.0, "val_loss": 1.8305107474327087, "val_acc": 48.0}
{"epoch": 20, "training_loss": 1.2068641042709352, "training_acc": 44.0, "val_loss": 0.883038945198059, "val_acc": 52.0}
{"epoch": 21, "training_loss": 0.8458392238616943, "training_acc": 54.0, "val_loss": 1.3220297479629517, "val_acc": 48.0}
{"epoch": 22, "training_loss": 2.0337206602096556, "training_acc": 42.0, "val_loss": 1.0648986530303954, "val_acc": 48.0}
{"epoch": 23, "training_loss": 1.2476904296875, "training_acc": 52.0, "val_loss": 3.2093887615203855, "val_acc": 52.0}
{"epoch": 24, "training_loss": 3.292181568145752, "training_acc": 46.0, "val_loss": 1.6362578392028808, "val_acc": 52.0}
{"epoch": 25, "training_loss": 2.79151695728302, "training_acc": 48.0, "val_loss": 5.583316488265991, "val_acc": 48.0}
{"epoch": 26, "training_loss": 5.244804134368897, "training_acc": 48.0, "val_loss": 0.6963864374160766, "val_acc": 48.0}
{"epoch": 27, "training_loss": 2.930345640182495, "training_acc": 46.0, "val_loss": 4.2775986289978025, "val_acc": 48.0}
{"epoch": 28, "training_loss": 4.389129838943481, "training_acc": 50.0, "val_loss": 0.8640611958503723, "val_acc": 52.0}
{"epoch": 29, "training_loss": 1.8587451171875, "training_acc": 46.0, "val_loss": 0.706679527759552, "val_acc": 52.0}
{"epoch": 30, "training_loss": 0.8474776744842529, "training_acc": 56.0, "val_loss": 1.3132393407821654, "val_acc": 48.0}
{"epoch": 31, "training_loss": 0.8820309114456176, "training_acc": 50.0, "val_loss": 1.338618884086609, "val_acc": 48.0}
{"epoch": 32, "training_loss": 0.8002048206329345, "training_acc": 52.0, "val_loss": 2.2969845390319823, "val_acc": 52.0}
{"epoch": 33, "training_loss": 1.4058365726470947, "training_acc": 48.0, "val_loss": 1.3849363899230958, "val_acc": 48.0}
{"epoch": 34, "training_loss": 1.318128080368042, "training_acc": 54.0, "val_loss": 0.7078863596916198, "val_acc": 52.0}
{"epoch": 35, "training_loss": 0.7732657337188721, "training_acc": 56.0, "val_loss": 2.8904826068878173, "val_acc": 52.0}
{"epoch": 36, "training_loss": 2.8845102119445802, "training_acc": 48.0, "val_loss": 2.3134145879745485, "val_acc": 52.0}
{"epoch": 37, "training_loss": 1.6991714239120483, "training_acc": 48.0, "val_loss": 1.8000314378738402, "val_acc": 48.0}
{"epoch": 38, "training_loss": 0.8887896966934205, "training_acc": 62.0, "val_loss": 0.7036762189865112, "val_acc": 48.0}
{"epoch": 39, "training_loss": 1.3142737197875975, "training_acc": 50.0, "val_loss": 0.8151112794876099, "val_acc": 52.0}
{"epoch": 40, "training_loss": 1.1099875640869141, "training_acc": 56.0, "val_loss": 2.4821225357055665, "val_acc": 48.0}
{"epoch": 41, "training_loss": 1.8367251300811767, "training_acc": 46.0, "val_loss": 2.5625736618041994, "val_acc": 52.0}
{"epoch": 42, "training_loss": 1.5506606221199035, "training_acc": 42.0, "val_loss": 1.4385034608840943, "val_acc": 52.0}
{"epoch": 43, "training_loss": 0.9270559120178222, "training_acc": 52.0, "val_loss": 0.7359756541252136, "val_acc": 48.0}
{"epoch": 44, "training_loss": 1.0171379327774048, "training_acc": 50.0, "val_loss": 0.7167399096488952, "val_acc": 52.0}
{"epoch": 45, "training_loss": 0.7419778823852539, "training_acc": 42.0, "val_loss": 1.0395144200325013, "val_acc": 52.0}
