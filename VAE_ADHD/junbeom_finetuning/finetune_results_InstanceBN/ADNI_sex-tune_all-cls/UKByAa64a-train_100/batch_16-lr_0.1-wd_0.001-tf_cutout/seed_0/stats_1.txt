"main_modify.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ADNI_sex --input_option yAware --learning_rate 1e-1 --batch_size 16 --weight_decay 1e-3 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 3.366859705448151, "training_acc": 58.0, "val_loss": 0.8623826146125794, "val_acc": 52.0}
{"epoch": 1, "training_loss": 1.4350517106056213, "training_acc": 49.0, "val_loss": 3.558988218307495, "val_acc": 52.0}
{"epoch": 2, "training_loss": 2.635307056903839, "training_acc": 51.0, "val_loss": 4.773230495452881, "val_acc": 48.0}
{"epoch": 3, "training_loss": 2.4203217458724975, "training_acc": 47.0, "val_loss": 1.9905342721939088, "val_acc": 52.0}
{"epoch": 4, "training_loss": 1.3468120908737182, "training_acc": 49.0, "val_loss": 0.7087189412117004, "val_acc": 52.0}
{"epoch": 5, "training_loss": 0.9962119197845459, "training_acc": 43.0, "val_loss": 3.037932939529419, "val_acc": 52.0}
{"epoch": 6, "training_loss": 2.5681568145751954, "training_acc": 47.0, "val_loss": 0.988151662349701, "val_acc": 52.0}
{"epoch": 7, "training_loss": 1.7128139591217042, "training_acc": 61.0, "val_loss": 2.9536625480651857, "val_acc": 52.0}
{"epoch": 8, "training_loss": 2.0066661834716797, "training_acc": 49.0, "val_loss": 1.0165611600875855, "val_acc": 48.0}
{"epoch": 9, "training_loss": 1.3663909149169922, "training_acc": 41.0, "val_loss": 1.2828962230682373, "val_acc": 52.0}
{"epoch": 10, "training_loss": 1.6785244727134705, "training_acc": 41.0, "val_loss": 4.432551326751709, "val_acc": 48.0}
{"epoch": 11, "training_loss": 4.155730152130127, "training_acc": 51.0, "val_loss": 3.9906298971176146, "val_acc": 52.0}
{"epoch": 12, "training_loss": 2.4273881626129152, "training_acc": 51.0, "val_loss": 1.9453311252593994, "val_acc": 52.0}
{"epoch": 13, "training_loss": 1.584548330307007, "training_acc": 51.0, "val_loss": 1.3988995361328125, "val_acc": 48.0}
{"epoch": 14, "training_loss": 1.0267943000793458, "training_acc": 39.0, "val_loss": 1.6924115896224976, "val_acc": 52.0}
{"epoch": 15, "training_loss": 1.244947805404663, "training_acc": 49.0, "val_loss": 1.0839169645309448, "val_acc": 48.0}
{"epoch": 16, "training_loss": 1.143897247314453, "training_acc": 45.0, "val_loss": 0.7007026267051697, "val_acc": 48.0}
{"epoch": 17, "training_loss": 1.1261703300476074, "training_acc": 49.0, "val_loss": 1.0284494018554688, "val_acc": 52.0}
{"epoch": 18, "training_loss": 1.5641216564178466, "training_acc": 49.0, "val_loss": 2.079709539413452, "val_acc": 48.0}
{"epoch": 19, "training_loss": 1.449867343902588, "training_acc": 59.0, "val_loss": 2.6529215240478514, "val_acc": 48.0}
{"epoch": 20, "training_loss": 1.8559023475646972, "training_acc": 49.0, "val_loss": 0.9950487375259399, "val_acc": 52.0}
{"epoch": 21, "training_loss": 1.2397639727592469, "training_acc": 43.0, "val_loss": 1.4148087310791015, "val_acc": 48.0}
{"epoch": 22, "training_loss": 0.9438824272155761, "training_acc": 47.0, "val_loss": 1.0321871423721314, "val_acc": 52.0}
{"epoch": 23, "training_loss": 0.9412698745727539, "training_acc": 43.0, "val_loss": 1.3048755598068238, "val_acc": 48.0}
{"epoch": 24, "training_loss": 1.3774041271209716, "training_acc": 45.0, "val_loss": 0.9071913957595825, "val_acc": 48.0}
{"epoch": 25, "training_loss": 0.7422786808013916, "training_acc": 47.0, "val_loss": 0.6937274670600891, "val_acc": 48.0}
{"epoch": 26, "training_loss": 0.8052032041549683, "training_acc": 45.0, "val_loss": 1.0129182815551758, "val_acc": 48.0}
{"epoch": 27, "training_loss": 1.2981168508529664, "training_acc": 59.0, "val_loss": 0.9770230388641358, "val_acc": 48.0}
{"epoch": 28, "training_loss": 0.9967590141296386, "training_acc": 57.0, "val_loss": 1.1806128549575805, "val_acc": 48.0}
{"epoch": 29, "training_loss": 1.2785854029655457, "training_acc": 53.0, "val_loss": 2.181218090057373, "val_acc": 48.0}
{"epoch": 30, "training_loss": 1.3230835056304933, "training_acc": 57.0, "val_loss": 1.9131382751464843, "val_acc": 48.0}
{"epoch": 31, "training_loss": 1.5994167995452881, "training_acc": 45.0, "val_loss": 0.8441761827468872, "val_acc": 48.0}
{"epoch": 32, "training_loss": 1.2116903495788574, "training_acc": 53.0, "val_loss": 0.7456801748275756, "val_acc": 52.0}
{"epoch": 33, "training_loss": 1.349124665260315, "training_acc": 63.0, "val_loss": 2.059820704460144, "val_acc": 48.0}
{"epoch": 34, "training_loss": 1.5785443258285523, "training_acc": 45.0, "val_loss": 0.9389757633209228, "val_acc": 48.0}
{"epoch": 35, "training_loss": 0.7174147772789001, "training_acc": 59.0, "val_loss": 2.1194114685058594, "val_acc": 48.0}
{"epoch": 36, "training_loss": 1.195722005367279, "training_acc": 57.0, "val_loss": 1.0872938489913941, "val_acc": 48.0}
{"epoch": 37, "training_loss": 0.8407680892944336, "training_acc": 55.0, "val_loss": 0.6948271489143372, "val_acc": 48.0}
{"epoch": 38, "training_loss": 0.9275093078613281, "training_acc": 43.0, "val_loss": 1.1010311985015868, "val_acc": 48.0}
{"epoch": 39, "training_loss": 0.8345921230316162, "training_acc": 57.0, "val_loss": 0.6949339699745178, "val_acc": 52.0}
{"epoch": 40, "training_loss": 0.8199543380737304, "training_acc": 41.0, "val_loss": 1.1479020261764525, "val_acc": 48.0}
{"epoch": 41, "training_loss": 1.3547246313095094, "training_acc": 61.0, "val_loss": 0.9375048756599427, "val_acc": 48.0}
{"epoch": 42, "training_loss": 0.9082099843025208, "training_acc": 49.0, "val_loss": 1.2181149435043335, "val_acc": 48.0}
{"epoch": 43, "training_loss": 0.9570248603820801, "training_acc": 49.0, "val_loss": 0.8212287187576294, "val_acc": 52.0}
{"epoch": 44, "training_loss": 1.1271335458755494, "training_acc": 45.0, "val_loss": 0.6984714770317078, "val_acc": 48.0}
