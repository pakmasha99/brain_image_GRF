"main_modify.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 5 --task ADNI_sex --input_option yAware --learning_rate 1e-3 --batch_size 16 --weight_decay 1e-5 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 0.7136998891830444, "training_acc": 51.0, "val_loss": 0.7195582270622254, "val_acc": 48.0}
{"epoch": 1, "training_loss": 0.7140680122375488, "training_acc": 50.0, "val_loss": 0.6932726383209229, "val_acc": 48.0}
{"epoch": 2, "training_loss": 0.7056172513961791, "training_acc": 46.0, "val_loss": 0.6934637928009033, "val_acc": 52.0}
{"epoch": 3, "training_loss": 0.6959030723571777, "training_acc": 50.0, "val_loss": 0.69309406042099, "val_acc": 52.0}
{"epoch": 4, "training_loss": 0.6974387717247009, "training_acc": 50.0, "val_loss": 0.6993303990364075, "val_acc": 48.0}
{"epoch": 5, "training_loss": 0.7191314697265625, "training_acc": 50.0, "val_loss": 0.7053306221961975, "val_acc": 48.0}
{"epoch": 6, "training_loss": 0.6967382264137268, "training_acc": 50.0, "val_loss": 0.6923580980300903, "val_acc": 52.0}
{"epoch": 7, "training_loss": 0.6978324961662292, "training_acc": 50.0, "val_loss": 0.6924108242988587, "val_acc": 52.0}
{"epoch": 8, "training_loss": 0.6971425104141236, "training_acc": 50.0, "val_loss": 0.6927615308761597, "val_acc": 52.0}
{"epoch": 9, "training_loss": 0.7100654554367065, "training_acc": 50.0, "val_loss": 0.6927748680114746, "val_acc": 52.0}
{"epoch": 10, "training_loss": 0.735533971786499, "training_acc": 46.0, "val_loss": 0.7111792945861817, "val_acc": 48.0}
{"epoch": 11, "training_loss": 0.73856538772583, "training_acc": 46.0, "val_loss": 0.7038029050827026, "val_acc": 52.0}
{"epoch": 12, "training_loss": 0.7060901427268982, "training_acc": 46.0, "val_loss": 0.6983479881286621, "val_acc": 48.0}
{"epoch": 13, "training_loss": 0.6953358125686645, "training_acc": 52.0, "val_loss": 0.6924724984169006, "val_acc": 52.0}
{"epoch": 14, "training_loss": 0.6942446899414062, "training_acc": 50.0, "val_loss": 0.6992814087867737, "val_acc": 48.0}
{"epoch": 15, "training_loss": 0.7093808722496032, "training_acc": 40.0, "val_loss": 0.6938634371757507, "val_acc": 48.0}
{"epoch": 16, "training_loss": 0.7019449186325073, "training_acc": 50.0, "val_loss": 0.6955841565132141, "val_acc": 48.0}
{"epoch": 17, "training_loss": 0.6958167695999146, "training_acc": 54.0, "val_loss": 0.6973463010787964, "val_acc": 52.0}
{"epoch": 18, "training_loss": 0.7014754128456115, "training_acc": 48.0, "val_loss": 0.6953570532798767, "val_acc": 48.0}
{"epoch": 19, "training_loss": 0.6955649423599243, "training_acc": 46.0, "val_loss": 0.6929188990592956, "val_acc": 52.0}
{"epoch": 20, "training_loss": 0.6977618527412415, "training_acc": 50.0, "val_loss": 0.6955253744125366, "val_acc": 48.0}
{"epoch": 21, "training_loss": 0.6994942331314087, "training_acc": 52.0, "val_loss": 0.7038688659667969, "val_acc": 52.0}
{"epoch": 22, "training_loss": 0.7046606922149659, "training_acc": 50.0, "val_loss": 0.6935072731971741, "val_acc": 48.0}
{"epoch": 23, "training_loss": 0.7000502896308899, "training_acc": 50.0, "val_loss": 0.698880853652954, "val_acc": 48.0}
{"epoch": 24, "training_loss": 0.6989360761642456, "training_acc": 50.0, "val_loss": 0.6925513339042664, "val_acc": 52.0}
{"epoch": 25, "training_loss": 0.696202085018158, "training_acc": 50.0, "val_loss": 0.6923538517951965, "val_acc": 52.0}
{"epoch": 26, "training_loss": 0.6986459350585937, "training_acc": 52.0, "val_loss": 0.6984225106239319, "val_acc": 48.0}
{"epoch": 27, "training_loss": 0.7122895431518554, "training_acc": 50.0, "val_loss": 0.7121209645271301, "val_acc": 48.0}
{"epoch": 28, "training_loss": 0.7013086342811584, "training_acc": 48.0, "val_loss": 0.6956728339195252, "val_acc": 52.0}
{"epoch": 29, "training_loss": 0.6997313165664673, "training_acc": 46.0, "val_loss": 0.6923648548126221, "val_acc": 52.0}
{"epoch": 30, "training_loss": 0.6987743234634399, "training_acc": 50.0, "val_loss": 0.6939466071128845, "val_acc": 52.0}
{"epoch": 31, "training_loss": 0.7048793005943298, "training_acc": 50.0, "val_loss": 0.6924406576156616, "val_acc": 52.0}
{"epoch": 32, "training_loss": 0.6920665836334229, "training_acc": 52.0, "val_loss": 0.7029496669769287, "val_acc": 48.0}
{"epoch": 33, "training_loss": 0.704786262512207, "training_acc": 46.0, "val_loss": 0.6923790860176087, "val_acc": 52.0}
{"epoch": 34, "training_loss": 0.6968556690216064, "training_acc": 50.0, "val_loss": 0.6932671809196472, "val_acc": 48.0}
{"epoch": 35, "training_loss": 0.6925546979904175, "training_acc": 50.0, "val_loss": 0.7061088013648987, "val_acc": 48.0}
{"epoch": 36, "training_loss": 0.7236182165145874, "training_acc": 50.0, "val_loss": 0.7079041409492492, "val_acc": 48.0}
{"epoch": 37, "training_loss": 0.711680793762207, "training_acc": 50.0, "val_loss": 0.7113808703422546, "val_acc": 52.0}
{"epoch": 38, "training_loss": 0.7101870584487915, "training_acc": 50.0, "val_loss": 0.6928823590278625, "val_acc": 52.0}
{"epoch": 39, "training_loss": 0.6937402606010437, "training_acc": 54.0, "val_loss": 0.70302894115448, "val_acc": 48.0}
{"epoch": 40, "training_loss": 0.7014206600189209, "training_acc": 50.0, "val_loss": 0.6930485796928406, "val_acc": 52.0}
{"epoch": 41, "training_loss": 0.7006880664825439, "training_acc": 50.0, "val_loss": 0.692371723651886, "val_acc": 52.0}
{"epoch": 42, "training_loss": 0.7018747186660766, "training_acc": 44.0, "val_loss": 0.6934826231002807, "val_acc": 48.0}
{"epoch": 43, "training_loss": 0.7236027979850769, "training_acc": 48.0, "val_loss": 0.7005927920341491, "val_acc": 52.0}
{"epoch": 44, "training_loss": 0.7140412950515747, "training_acc": 44.0, "val_loss": 0.7035667705535888, "val_acc": 48.0}
