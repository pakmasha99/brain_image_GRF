"main_modify.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 3 --task ADNI_sex --input_option yAware --learning_rate 1e-3 --batch_size 16 --weight_decay 1e-5 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 0.7183660674095154, "training_acc": 46.0, "val_loss": 0.6940256047248841, "val_acc": 52.0}
{"epoch": 1, "training_loss": 0.7109728193283081, "training_acc": 42.0, "val_loss": 0.6974889874458313, "val_acc": 52.0}
{"epoch": 2, "training_loss": 0.7083953261375427, "training_acc": 50.0, "val_loss": 0.7013565897941589, "val_acc": 48.0}
{"epoch": 3, "training_loss": 0.7415671443939209, "training_acc": 50.0, "val_loss": 0.6974000144004822, "val_acc": 48.0}
{"epoch": 4, "training_loss": 0.6991985058784485, "training_acc": 48.0, "val_loss": 0.6926353120803833, "val_acc": 52.0}
{"epoch": 5, "training_loss": 0.7013047027587891, "training_acc": 50.0, "val_loss": 0.6935981297492981, "val_acc": 48.0}
{"epoch": 6, "training_loss": 0.7068427681922913, "training_acc": 50.0, "val_loss": 0.6958764719963074, "val_acc": 48.0}
{"epoch": 7, "training_loss": 0.6971756410598755, "training_acc": 50.0, "val_loss": 0.6929396557807922, "val_acc": 52.0}
{"epoch": 8, "training_loss": 0.6963481569290161, "training_acc": 50.0, "val_loss": 0.6924785017967224, "val_acc": 52.0}
{"epoch": 9, "training_loss": 0.7004407930374146, "training_acc": 42.0, "val_loss": 0.6998002195358276, "val_acc": 48.0}
{"epoch": 10, "training_loss": 0.7014797329902649, "training_acc": 44.0, "val_loss": 0.6958234786987305, "val_acc": 48.0}
{"epoch": 11, "training_loss": 0.7124170637130738, "training_acc": 50.0, "val_loss": 0.7114199519157409, "val_acc": 48.0}
{"epoch": 12, "training_loss": 0.6987654209136963, "training_acc": 50.0, "val_loss": 0.6926317787170411, "val_acc": 52.0}
{"epoch": 13, "training_loss": 0.7109688973426819, "training_acc": 50.0, "val_loss": 0.6948850893974304, "val_acc": 52.0}
{"epoch": 14, "training_loss": 0.6901816129684448, "training_acc": 52.0, "val_loss": 0.7006807661056519, "val_acc": 48.0}
{"epoch": 15, "training_loss": 0.7114601349830627, "training_acc": 50.0, "val_loss": 0.7063101887702942, "val_acc": 48.0}
{"epoch": 16, "training_loss": 0.7116638875007629, "training_acc": 40.0, "val_loss": 0.6953856563568115, "val_acc": 52.0}
{"epoch": 17, "training_loss": 0.7038230872154236, "training_acc": 50.0, "val_loss": 0.6932384181022644, "val_acc": 48.0}
{"epoch": 18, "training_loss": 0.6937671971321105, "training_acc": 50.0, "val_loss": 0.695334746837616, "val_acc": 48.0}
{"epoch": 19, "training_loss": 0.699388861656189, "training_acc": 46.0, "val_loss": 0.692348656654358, "val_acc": 52.0}
{"epoch": 20, "training_loss": 0.6965838432312011, "training_acc": 44.0, "val_loss": 0.6936690545082093, "val_acc": 48.0}
{"epoch": 21, "training_loss": 0.6964138197898865, "training_acc": 46.0, "val_loss": 0.6934067583084107, "val_acc": 48.0}
{"epoch": 22, "training_loss": 0.6960301256179809, "training_acc": 42.0, "val_loss": 0.693841860294342, "val_acc": 48.0}
{"epoch": 23, "training_loss": 0.6976321172714234, "training_acc": 50.0, "val_loss": 0.6926907467842102, "val_acc": 52.0}
{"epoch": 24, "training_loss": 0.6947996139526367, "training_acc": 50.0, "val_loss": 0.692812647819519, "val_acc": 52.0}
{"epoch": 25, "training_loss": 0.6946304392814636, "training_acc": 50.0, "val_loss": 0.6968703174591064, "val_acc": 48.0}
{"epoch": 26, "training_loss": 0.7042664957046508, "training_acc": 50.0, "val_loss": 0.7105519676208496, "val_acc": 48.0}
{"epoch": 27, "training_loss": 0.6998567247390747, "training_acc": 50.0, "val_loss": 0.6924191880226135, "val_acc": 52.0}
{"epoch": 28, "training_loss": 0.7047492456436157, "training_acc": 50.0, "val_loss": 0.6937810325622559, "val_acc": 52.0}
{"epoch": 29, "training_loss": 0.699359860420227, "training_acc": 52.0, "val_loss": 0.70911137342453, "val_acc": 48.0}
{"epoch": 30, "training_loss": 0.6968599224090576, "training_acc": 50.0, "val_loss": 0.6923378038406373, "val_acc": 52.0}
{"epoch": 31, "training_loss": 0.7069702196121216, "training_acc": 50.0, "val_loss": 0.6957836985588074, "val_acc": 52.0}
{"epoch": 32, "training_loss": 0.692537407875061, "training_acc": 52.0, "val_loss": 0.7128265714645385, "val_acc": 48.0}
{"epoch": 33, "training_loss": 0.7083585882186889, "training_acc": 50.0, "val_loss": 0.6965160870552063, "val_acc": 48.0}
{"epoch": 34, "training_loss": 0.6992581987380981, "training_acc": 50.0, "val_loss": 0.6938891649246216, "val_acc": 48.0}
{"epoch": 35, "training_loss": 0.6940071058273315, "training_acc": 48.0, "val_loss": 0.6924984097480774, "val_acc": 52.0}
{"epoch": 36, "training_loss": 0.6963688135147095, "training_acc": 50.0, "val_loss": 0.693176109790802, "val_acc": 48.0}
{"epoch": 37, "training_loss": 0.69365957736969, "training_acc": 50.0, "val_loss": 0.7049005341529846, "val_acc": 48.0}
{"epoch": 38, "training_loss": 0.7027158546447754, "training_acc": 46.0, "val_loss": 0.6923963546752929, "val_acc": 52.0}
{"epoch": 39, "training_loss": 0.6971267652511597, "training_acc": 50.0, "val_loss": 0.692720844745636, "val_acc": 52.0}
{"epoch": 40, "training_loss": 0.69373703956604, "training_acc": 52.0, "val_loss": 0.6969073915481567, "val_acc": 48.0}
{"epoch": 41, "training_loss": 0.6972828006744385, "training_acc": 50.0, "val_loss": 0.6934212136268616, "val_acc": 48.0}
{"epoch": 42, "training_loss": 0.6961382007598877, "training_acc": 46.0, "val_loss": 0.6936287879943848, "val_acc": 48.0}
{"epoch": 43, "training_loss": 0.7010170459747315, "training_acc": 50.0, "val_loss": 0.70978440284729, "val_acc": 48.0}
{"epoch": 44, "training_loss": 0.7120629596710205, "training_acc": 50.0, "val_loss": 0.7036919784545899, "val_acc": 48.0}
{"epoch": 45, "training_loss": 0.6953334283828735, "training_acc": 48.0, "val_loss": 0.6923692297935485, "val_acc": 52.0}
{"epoch": 46, "training_loss": 0.6987580680847167, "training_acc": 44.0, "val_loss": 0.6943702721595764, "val_acc": 48.0}
{"epoch": 47, "training_loss": 0.6967982482910157, "training_acc": 44.0, "val_loss": 0.6936628317832947, "val_acc": 48.0}
{"epoch": 48, "training_loss": 0.6991969418525695, "training_acc": 42.0, "val_loss": 0.6948128652572632, "val_acc": 48.0}
{"epoch": 49, "training_loss": 0.6986204981803894, "training_acc": 50.0, "val_loss": 0.7006574249267579, "val_acc": 48.0}
