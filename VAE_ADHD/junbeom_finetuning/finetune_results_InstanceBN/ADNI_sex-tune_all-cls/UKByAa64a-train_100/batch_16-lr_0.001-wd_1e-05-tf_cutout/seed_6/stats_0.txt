"main_modify.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 6 --task ADNI_sex --input_option yAware --learning_rate 1e-3 --batch_size 16 --weight_decay 1e-5 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 0.7309918403625488, "training_acc": 50.0, "val_loss": 0.6951964354515076, "val_acc": 48.0}
{"epoch": 1, "training_loss": 0.7110303521156311, "training_acc": 45.0, "val_loss": 0.6970289969444274, "val_acc": 48.0}
{"epoch": 2, "training_loss": 0.7159693574905396, "training_acc": 41.0, "val_loss": 0.7070877242088318, "val_acc": 48.0}
{"epoch": 3, "training_loss": 0.7173826384544373, "training_acc": 51.0, "val_loss": 0.6924811959266662, "val_acc": 52.0}
{"epoch": 4, "training_loss": 0.7176106500625611, "training_acc": 49.0, "val_loss": 0.698744158744812, "val_acc": 52.0}
{"epoch": 5, "training_loss": 0.7030711221694946, "training_acc": 47.0, "val_loss": 0.6987265372276306, "val_acc": 48.0}
{"epoch": 6, "training_loss": 0.6961611604690552, "training_acc": 51.0, "val_loss": 0.6936946964263916, "val_acc": 48.0}
{"epoch": 7, "training_loss": 0.6966169571876526, "training_acc": 45.0, "val_loss": 0.6928494572639465, "val_acc": 52.0}
{"epoch": 8, "training_loss": 0.6940479278564453, "training_acc": 49.0, "val_loss": 0.6985260105133057, "val_acc": 48.0}
{"epoch": 9, "training_loss": 0.6964677381515503, "training_acc": 51.0, "val_loss": 0.7013316202163696, "val_acc": 48.0}
{"epoch": 10, "training_loss": 0.7063333058357238, "training_acc": 51.0, "val_loss": 0.6992812752723694, "val_acc": 48.0}
{"epoch": 11, "training_loss": 0.7002546668052674, "training_acc": 51.0, "val_loss": 0.6958452939987183, "val_acc": 48.0}
{"epoch": 12, "training_loss": 0.6993293261528015, "training_acc": 49.0, "val_loss": 0.6974284672737121, "val_acc": 52.0}
{"epoch": 13, "training_loss": 0.7217077493667603, "training_acc": 37.0, "val_loss": 0.7105691766738892, "val_acc": 48.0}
{"epoch": 14, "training_loss": 0.7009664344787597, "training_acc": 51.0, "val_loss": 0.6943255710601807, "val_acc": 48.0}
{"epoch": 15, "training_loss": 0.7002707719802856, "training_acc": 49.0, "val_loss": 0.6923593258857728, "val_acc": 52.0}
{"epoch": 16, "training_loss": 0.6947298121452331, "training_acc": 51.0, "val_loss": 0.6983370327949524, "val_acc": 48.0}
{"epoch": 17, "training_loss": 0.6959621906280518, "training_acc": 51.0, "val_loss": 0.6938639807701111, "val_acc": 48.0}
{"epoch": 18, "training_loss": 0.7019416046142578, "training_acc": 43.0, "val_loss": 0.6923809552192688, "val_acc": 52.0}
{"epoch": 19, "training_loss": 0.6985801267623901, "training_acc": 49.0, "val_loss": 0.6951899814605713, "val_acc": 48.0}
{"epoch": 20, "training_loss": 0.6946555852890015, "training_acc": 51.0, "val_loss": 0.6972567677497864, "val_acc": 48.0}
{"epoch": 21, "training_loss": 0.6973262333869934, "training_acc": 51.0, "val_loss": 0.6948265552520752, "val_acc": 48.0}
{"epoch": 22, "training_loss": 0.6920833444595337, "training_acc": 51.0, "val_loss": 0.6944732213020325, "val_acc": 52.0}
{"epoch": 23, "training_loss": 0.7047759103775024, "training_acc": 49.0, "val_loss": 0.6923449254035949, "val_acc": 52.0}
{"epoch": 24, "training_loss": 0.6971193265914917, "training_acc": 49.0, "val_loss": 0.7153384828567505, "val_acc": 48.0}
{"epoch": 25, "training_loss": 0.7095090532302857, "training_acc": 47.0, "val_loss": 0.6925552988052368, "val_acc": 52.0}
{"epoch": 26, "training_loss": 0.7002635478973389, "training_acc": 49.0, "val_loss": 0.6923314094543457, "val_acc": 52.0}
{"epoch": 27, "training_loss": 0.6920720720291138, "training_acc": 51.0, "val_loss": 0.7086776280403138, "val_acc": 48.0}
{"epoch": 28, "training_loss": 0.7095058822631836, "training_acc": 51.0, "val_loss": 0.7004601383209228, "val_acc": 48.0}
{"epoch": 29, "training_loss": 0.730059986114502, "training_acc": 39.0, "val_loss": 0.6935298657417297, "val_acc": 52.0}
{"epoch": 30, "training_loss": 0.726947615146637, "training_acc": 45.0, "val_loss": 0.7115844464302064, "val_acc": 48.0}
{"epoch": 31, "training_loss": 0.7020922255516052, "training_acc": 51.0, "val_loss": 0.6924088287353516, "val_acc": 52.0}
{"epoch": 32, "training_loss": 0.7099745082855224, "training_acc": 49.0, "val_loss": 0.692894070148468, "val_acc": 52.0}
{"epoch": 33, "training_loss": 0.6966273093223572, "training_acc": 49.0, "val_loss": 0.6962720870971679, "val_acc": 48.0}
{"epoch": 34, "training_loss": 0.7059679794311523, "training_acc": 51.0, "val_loss": 0.7047080707550049, "val_acc": 48.0}
{"epoch": 35, "training_loss": 0.6927932691574097, "training_acc": 51.0, "val_loss": 0.6940496373176575, "val_acc": 52.0}
{"epoch": 36, "training_loss": 0.7032507014274597, "training_acc": 49.0, "val_loss": 0.6923618674278259, "val_acc": 52.0}
{"epoch": 37, "training_loss": 0.7042071437835693, "training_acc": 45.0, "val_loss": 0.7075897455215454, "val_acc": 48.0}
{"epoch": 38, "training_loss": 0.6988516569137573, "training_acc": 47.0, "val_loss": 0.6924401807785034, "val_acc": 52.0}
{"epoch": 39, "training_loss": 0.6967941498756409, "training_acc": 49.0, "val_loss": 0.6933822965621949, "val_acc": 48.0}
{"epoch": 40, "training_loss": 0.6931910276412964, "training_acc": 51.0, "val_loss": 0.7002182364463806, "val_acc": 48.0}
{"epoch": 41, "training_loss": 0.69712890625, "training_acc": 45.0, "val_loss": 0.6934999179840088, "val_acc": 48.0}
{"epoch": 42, "training_loss": 0.6997069239616394, "training_acc": 51.0, "val_loss": 0.7032136511802674, "val_acc": 48.0}
{"epoch": 43, "training_loss": 0.6944511151313781, "training_acc": 49.0, "val_loss": 0.6931306505203247, "val_acc": 52.0}
{"epoch": 44, "training_loss": 0.6967015266418457, "training_acc": 49.0, "val_loss": 0.6960420727729797, "val_acc": 48.0}
{"epoch": 45, "training_loss": 0.7199454212188721, "training_acc": 39.0, "val_loss": 0.6924433636665345, "val_acc": 52.0}
