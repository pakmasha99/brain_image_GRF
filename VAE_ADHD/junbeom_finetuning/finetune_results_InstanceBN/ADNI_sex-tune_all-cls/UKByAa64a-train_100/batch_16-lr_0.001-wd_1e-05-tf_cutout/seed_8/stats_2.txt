"main_modify.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 8 --task ADNI_sex --input_option yAware --learning_rate 1e-3 --batch_size 16 --weight_decay 1e-5 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 0.6915470886230469, "training_acc": 50.0, "val_loss": 0.7052385663986206, "val_acc": 48.0}
{"epoch": 1, "training_loss": 0.7083278894424438, "training_acc": 50.0, "val_loss": 0.6925151085853577, "val_acc": 52.0}
{"epoch": 2, "training_loss": 0.6992201495170594, "training_acc": 50.0, "val_loss": 0.6926138091087342, "val_acc": 52.0}
{"epoch": 3, "training_loss": 0.7046761226654052, "training_acc": 48.0, "val_loss": 0.6987854623794556, "val_acc": 48.0}
{"epoch": 4, "training_loss": 0.6964748764038086, "training_acc": 48.0, "val_loss": 0.6930198979377746, "val_acc": 52.0}
{"epoch": 5, "training_loss": 0.6951976823806763, "training_acc": 50.0, "val_loss": 0.6949844694137574, "val_acc": 48.0}
{"epoch": 6, "training_loss": 0.7119993114471436, "training_acc": 42.0, "val_loss": 0.6940805172920227, "val_acc": 48.0}
{"epoch": 7, "training_loss": 0.7139972925186158, "training_acc": 50.0, "val_loss": 0.6932126712799073, "val_acc": 48.0}
{"epoch": 8, "training_loss": 0.6954506158828735, "training_acc": 52.0, "val_loss": 0.6923683619499207, "val_acc": 52.0}
{"epoch": 9, "training_loss": 0.7161612606048584, "training_acc": 48.0, "val_loss": 0.7095882344245911, "val_acc": 48.0}
{"epoch": 10, "training_loss": 0.6950639533996582, "training_acc": 50.0, "val_loss": 0.7021010351181031, "val_acc": 52.0}
{"epoch": 11, "training_loss": 0.7040948700904847, "training_acc": 50.0, "val_loss": 0.6941426777839661, "val_acc": 48.0}
{"epoch": 12, "training_loss": 0.6921948194503784, "training_acc": 50.0, "val_loss": 0.7123202514648438, "val_acc": 48.0}
{"epoch": 13, "training_loss": 0.7275245237350464, "training_acc": 50.0, "val_loss": 0.6984758687019348, "val_acc": 48.0}
{"epoch": 14, "training_loss": 0.7155521893501282, "training_acc": 44.0, "val_loss": 0.7050589108467102, "val_acc": 52.0}
{"epoch": 15, "training_loss": 0.7107717442512512, "training_acc": 50.0, "val_loss": 0.6981403470039368, "val_acc": 48.0}
{"epoch": 16, "training_loss": 0.7337341451644898, "training_acc": 50.0, "val_loss": 0.695889630317688, "val_acc": 48.0}
{"epoch": 17, "training_loss": 0.6997950935363769, "training_acc": 52.0, "val_loss": 0.7074690318107605, "val_acc": 52.0}
{"epoch": 18, "training_loss": 0.7142279362678527, "training_acc": 50.0, "val_loss": 0.6939116716384888, "val_acc": 48.0}
{"epoch": 19, "training_loss": 0.7030720639228821, "training_acc": 50.0, "val_loss": 0.7033082365989685, "val_acc": 48.0}
{"epoch": 20, "training_loss": 0.6964982843399048, "training_acc": 50.0, "val_loss": 0.6924706816673278, "val_acc": 52.0}
{"epoch": 21, "training_loss": 0.7055771970748901, "training_acc": 50.0, "val_loss": 0.6930788064002991, "val_acc": 52.0}
{"epoch": 22, "training_loss": 0.723250207901001, "training_acc": 52.0, "val_loss": 0.726724100112915, "val_acc": 48.0}
{"epoch": 23, "training_loss": 0.7106039714813233, "training_acc": 48.0, "val_loss": 0.6925241422653198, "val_acc": 52.0}
{"epoch": 24, "training_loss": 0.6948964595794678, "training_acc": 44.0, "val_loss": 0.6924186325073243, "val_acc": 52.0}
{"epoch": 25, "training_loss": 0.697788815498352, "training_acc": 50.0, "val_loss": 0.6923595714569092, "val_acc": 52.0}
{"epoch": 26, "training_loss": 0.6966486644744873, "training_acc": 48.0, "val_loss": 0.693957531452179, "val_acc": 48.0}
{"epoch": 27, "training_loss": 0.7036334800720215, "training_acc": 50.0, "val_loss": 0.6926630854606628, "val_acc": 52.0}
{"epoch": 28, "training_loss": 0.771384596824646, "training_acc": 50.0, "val_loss": 0.706267592906952, "val_acc": 52.0}
{"epoch": 29, "training_loss": 0.6989411807060242, "training_acc": 48.0, "val_loss": 0.7104317212104797, "val_acc": 48.0}
{"epoch": 30, "training_loss": 0.7063751029968262, "training_acc": 50.0, "val_loss": 0.6981081986427307, "val_acc": 48.0}
{"epoch": 31, "training_loss": 0.7046713399887085, "training_acc": 46.0, "val_loss": 0.696784565448761, "val_acc": 52.0}
{"epoch": 32, "training_loss": 0.7046357202529907, "training_acc": 50.0, "val_loss": 0.6926441073417664, "val_acc": 52.0}
{"epoch": 33, "training_loss": 0.6953578925132752, "training_acc": 44.0, "val_loss": 0.6933322596549988, "val_acc": 48.0}
{"epoch": 34, "training_loss": 0.6956574344635009, "training_acc": 46.0, "val_loss": 0.6934835457801819, "val_acc": 48.0}
{"epoch": 35, "training_loss": 0.7028867793083191, "training_acc": 44.0, "val_loss": 0.6923999881744385, "val_acc": 52.0}
{"epoch": 36, "training_loss": 0.7040961408615112, "training_acc": 46.0, "val_loss": 0.70053612947464, "val_acc": 48.0}
{"epoch": 37, "training_loss": 0.6936643099784852, "training_acc": 52.0, "val_loss": 0.6926463055610657, "val_acc": 52.0}
{"epoch": 38, "training_loss": 0.7024229574203491, "training_acc": 50.0, "val_loss": 0.6926922917366027, "val_acc": 52.0}
{"epoch": 39, "training_loss": 0.7048170518875122, "training_acc": 46.0, "val_loss": 0.7175304841995239, "val_acc": 48.0}
{"epoch": 40, "training_loss": 0.7126981806755066, "training_acc": 50.0, "val_loss": 0.6971140599250794, "val_acc": 48.0}
{"epoch": 41, "training_loss": 0.7137842512130738, "training_acc": 44.0, "val_loss": 0.697890944480896, "val_acc": 52.0}
{"epoch": 42, "training_loss": 0.6917108941078186, "training_acc": 50.0, "val_loss": 0.7074247455596924, "val_acc": 48.0}
{"epoch": 43, "training_loss": 0.717514476776123, "training_acc": 50.0, "val_loss": 0.7212750172615051, "val_acc": 48.0}
{"epoch": 44, "training_loss": 0.7000372624397277, "training_acc": 50.0, "val_loss": 0.6929804658889771, "val_acc": 52.0}
