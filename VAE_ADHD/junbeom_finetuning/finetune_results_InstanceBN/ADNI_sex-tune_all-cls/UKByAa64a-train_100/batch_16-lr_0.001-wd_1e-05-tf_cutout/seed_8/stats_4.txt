"main_modify.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 8 --task ADNI_sex --input_option yAware --learning_rate 1e-3 --batch_size 16 --weight_decay 1e-5 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 0.7091043281555176, "training_acc": 52.0, "val_loss": 0.7187399005889893, "val_acc": 48.0}
{"epoch": 1, "training_loss": 0.7303088426589965, "training_acc": 46.0, "val_loss": 0.7296911382675171, "val_acc": 48.0}
{"epoch": 2, "training_loss": 0.7270752429962158, "training_acc": 44.0, "val_loss": 0.6933375525474549, "val_acc": 48.0}
{"epoch": 3, "training_loss": 0.6912097215652466, "training_acc": 50.0, "val_loss": 0.7133508610725403, "val_acc": 48.0}
{"epoch": 4, "training_loss": 0.7047125124931335, "training_acc": 50.0, "val_loss": 0.6957146573066711, "val_acc": 48.0}
{"epoch": 5, "training_loss": 0.6949887490272522, "training_acc": 52.0, "val_loss": 0.693604941368103, "val_acc": 52.0}
{"epoch": 6, "training_loss": 0.7045196771621705, "training_acc": 50.0, "val_loss": 0.6974574995040893, "val_acc": 52.0}
{"epoch": 7, "training_loss": 0.7041040945053101, "training_acc": 50.0, "val_loss": 0.6926736569404602, "val_acc": 52.0}
{"epoch": 8, "training_loss": 0.6931477737426758, "training_acc": 52.0, "val_loss": 0.6998299860954285, "val_acc": 48.0}
{"epoch": 9, "training_loss": 0.7196479940414429, "training_acc": 50.0, "val_loss": 0.7014072704315185, "val_acc": 48.0}
{"epoch": 10, "training_loss": 0.7530608797073364, "training_acc": 50.0, "val_loss": 0.7170256543159484, "val_acc": 52.0}
{"epoch": 11, "training_loss": 0.7148189377784729, "training_acc": 48.0, "val_loss": 0.7088323831558228, "val_acc": 48.0}
{"epoch": 12, "training_loss": 0.6984449911117554, "training_acc": 50.0, "val_loss": 0.6932249093055725, "val_acc": 48.0}
{"epoch": 13, "training_loss": 0.7022955417633057, "training_acc": 46.0, "val_loss": 0.693648099899292, "val_acc": 52.0}
{"epoch": 14, "training_loss": 0.6992920088768005, "training_acc": 44.0, "val_loss": 0.6960331654548645, "val_acc": 48.0}
{"epoch": 15, "training_loss": 0.7041611552238465, "training_acc": 50.0, "val_loss": 0.7140359234809875, "val_acc": 48.0}
{"epoch": 16, "training_loss": 0.7109596943855285, "training_acc": 50.0, "val_loss": 0.6942363810539246, "val_acc": 48.0}
{"epoch": 17, "training_loss": 0.6921836757659912, "training_acc": 52.0, "val_loss": 0.6971084237098694, "val_acc": 52.0}
{"epoch": 18, "training_loss": 0.7042098355293274, "training_acc": 50.0, "val_loss": 0.6929220652580261, "val_acc": 52.0}
{"epoch": 19, "training_loss": 0.7034566593170166, "training_acc": 48.0, "val_loss": 0.7101477456092834, "val_acc": 48.0}
{"epoch": 20, "training_loss": 0.7034198188781738, "training_acc": 50.0, "val_loss": 0.6932171630859375, "val_acc": 48.0}
{"epoch": 21, "training_loss": 0.6978268718719483, "training_acc": 54.0, "val_loss": 0.6966531658172608, "val_acc": 52.0}
{"epoch": 22, "training_loss": 0.7039017176628113, "training_acc": 50.0, "val_loss": 0.6925045800209045, "val_acc": 52.0}
{"epoch": 23, "training_loss": 0.6948184156417847, "training_acc": 50.0, "val_loss": 0.6935378694534302, "val_acc": 48.0}
{"epoch": 24, "training_loss": 0.7013351058959961, "training_acc": 50.0, "val_loss": 0.7013354802131653, "val_acc": 48.0}
{"epoch": 25, "training_loss": 0.6921179437637329, "training_acc": 50.0, "val_loss": 0.6958673286437989, "val_acc": 52.0}
{"epoch": 26, "training_loss": 0.7096088051795959, "training_acc": 50.0, "val_loss": 0.7000534152984619, "val_acc": 52.0}
{"epoch": 27, "training_loss": 0.6963806962966919, "training_acc": 50.0, "val_loss": 0.6976317882537841, "val_acc": 48.0}
{"epoch": 28, "training_loss": 0.7037402272224427, "training_acc": 50.0, "val_loss": 0.6994918394088745, "val_acc": 48.0}
{"epoch": 29, "training_loss": 0.7011691832542419, "training_acc": 50.0, "val_loss": 0.6955190682411194, "val_acc": 52.0}
{"epoch": 30, "training_loss": 0.6893367099761963, "training_acc": 54.0, "val_loss": 0.709426395893097, "val_acc": 48.0}
{"epoch": 31, "training_loss": 0.7094550228118897, "training_acc": 50.0, "val_loss": 0.7108924555778503, "val_acc": 48.0}
{"epoch": 32, "training_loss": 0.7026201581954956, "training_acc": 46.0, "val_loss": 0.6929734873771668, "val_acc": 52.0}
{"epoch": 33, "training_loss": 0.7043876957893371, "training_acc": 54.0, "val_loss": 0.7046857094764709, "val_acc": 48.0}
{"epoch": 34, "training_loss": 0.6987785863876342, "training_acc": 50.0, "val_loss": 0.6942227673530579, "val_acc": 48.0}
{"epoch": 35, "training_loss": 0.7008662152290345, "training_acc": 46.0, "val_loss": 0.6930240345001221, "val_acc": 52.0}
{"epoch": 36, "training_loss": 0.6936256456375122, "training_acc": 50.0, "val_loss": 0.6957864761352539, "val_acc": 48.0}
{"epoch": 37, "training_loss": 0.706272497177124, "training_acc": 50.0, "val_loss": 0.7165961050987244, "val_acc": 48.0}
{"epoch": 38, "training_loss": 0.6992923521995544, "training_acc": 50.0, "val_loss": 0.692358226776123, "val_acc": 52.0}
{"epoch": 39, "training_loss": 0.6963216257095337, "training_acc": 50.0, "val_loss": 0.6926542234420776, "val_acc": 52.0}
{"epoch": 40, "training_loss": 0.7018774580955506, "training_acc": 44.0, "val_loss": 0.6974083614349366, "val_acc": 48.0}
{"epoch": 41, "training_loss": 0.6938572931289673, "training_acc": 52.0, "val_loss": 0.6980591940879822, "val_acc": 52.0}
{"epoch": 42, "training_loss": 0.7032994818687439, "training_acc": 50.0, "val_loss": 0.6931415796279907, "val_acc": 52.0}
{"epoch": 43, "training_loss": 0.7035226058959961, "training_acc": 50.0, "val_loss": 0.7158543825149536, "val_acc": 48.0}
{"epoch": 44, "training_loss": 0.7020437049865723, "training_acc": 52.0, "val_loss": 0.6925329637527465, "val_acc": 52.0}
{"epoch": 45, "training_loss": 0.6950214719772339, "training_acc": 50.0, "val_loss": 0.6949377155303955, "val_acc": 52.0}
{"epoch": 46, "training_loss": 0.6968589401245118, "training_acc": 50.0, "val_loss": 0.6930950808525086, "val_acc": 52.0}
{"epoch": 47, "training_loss": 0.6924993824958802, "training_acc": 54.0, "val_loss": 0.6973336982727051, "val_acc": 48.0}
{"epoch": 48, "training_loss": 0.697814257144928, "training_acc": 42.0, "val_loss": 0.694345953464508, "val_acc": 48.0}
{"epoch": 49, "training_loss": 0.6984920620918273, "training_acc": 50.0, "val_loss": 0.698201220035553, "val_acc": 48.0}
{"epoch": 50, "training_loss": 0.6964739656448364, "training_acc": 48.0, "val_loss": 0.6925006461143494, "val_acc": 52.0}
{"epoch": 51, "training_loss": 0.6990926790237427, "training_acc": 46.0, "val_loss": 0.6995747137069702, "val_acc": 48.0}
{"epoch": 52, "training_loss": 0.70164626121521, "training_acc": 50.0, "val_loss": 0.6979413318634033, "val_acc": 48.0}
{"epoch": 53, "training_loss": 0.6914499855041504, "training_acc": 56.0, "val_loss": 0.6925763058662414, "val_acc": 52.0}
{"epoch": 54, "training_loss": 0.7040976238250732, "training_acc": 50.0, "val_loss": 0.6924730539321899, "val_acc": 52.0}
{"epoch": 55, "training_loss": 0.7053933143615723, "training_acc": 46.0, "val_loss": 0.700742962360382, "val_acc": 48.0}
{"epoch": 56, "training_loss": 0.6957110977172851, "training_acc": 48.0, "val_loss": 0.6928449749946595, "val_acc": 52.0}
{"epoch": 57, "training_loss": 0.7161889052391053, "training_acc": 50.0, "val_loss": 0.6939742207527161, "val_acc": 52.0}
