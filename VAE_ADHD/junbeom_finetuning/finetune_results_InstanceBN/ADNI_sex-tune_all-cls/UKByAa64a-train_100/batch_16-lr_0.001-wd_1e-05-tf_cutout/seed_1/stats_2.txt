"main_modify.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 1 --task ADNI_sex --input_option yAware --learning_rate 1e-3 --batch_size 16 --weight_decay 1e-5 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 0.7203830528259277, "training_acc": 54.0, "val_loss": 0.7044523167610168, "val_acc": 48.0}
{"epoch": 1, "training_loss": 0.7032682800292969, "training_acc": 46.0, "val_loss": 0.7293238639831543, "val_acc": 48.0}
{"epoch": 2, "training_loss": 0.7279974889755249, "training_acc": 50.0, "val_loss": 0.6940874218940735, "val_acc": 48.0}
{"epoch": 3, "training_loss": 0.6927839827537536, "training_acc": 52.0, "val_loss": 0.6947079205513, "val_acc": 52.0}
{"epoch": 4, "training_loss": 0.7064668822288513, "training_acc": 50.0, "val_loss": 0.6937122654914856, "val_acc": 48.0}
{"epoch": 5, "training_loss": 0.7034784460067749, "training_acc": 42.0, "val_loss": 0.6953236031532287, "val_acc": 48.0}
{"epoch": 6, "training_loss": 0.714472393989563, "training_acc": 50.0, "val_loss": 0.6969154930114746, "val_acc": 48.0}
{"epoch": 7, "training_loss": 0.7341392660140991, "training_acc": 48.0, "val_loss": 0.7046931505203247, "val_acc": 52.0}
{"epoch": 8, "training_loss": 0.6990986704826355, "training_acc": 52.0, "val_loss": 0.7084208345413208, "val_acc": 48.0}
{"epoch": 9, "training_loss": 0.6939144277572632, "training_acc": 52.0, "val_loss": 0.6931915068626404, "val_acc": 52.0}
{"epoch": 10, "training_loss": 0.7104188323020935, "training_acc": 50.0, "val_loss": 0.692701804637909, "val_acc": 52.0}
{"epoch": 11, "training_loss": 0.7150637412071228, "training_acc": 50.0, "val_loss": 0.6947354245185852, "val_acc": 52.0}
{"epoch": 12, "training_loss": 0.702611346244812, "training_acc": 46.0, "val_loss": 0.6976852464675903, "val_acc": 48.0}
{"epoch": 13, "training_loss": 0.6933549332618714, "training_acc": 50.0, "val_loss": 0.6926825451850891, "val_acc": 52.0}
{"epoch": 14, "training_loss": 0.6954983472824097, "training_acc": 46.0, "val_loss": 0.6952621936798096, "val_acc": 48.0}
{"epoch": 15, "training_loss": 0.6949564981460571, "training_acc": 48.0, "val_loss": 0.6926186299324035, "val_acc": 52.0}
{"epoch": 16, "training_loss": 0.7071799850463867, "training_acc": 50.0, "val_loss": 0.6925443959236145, "val_acc": 52.0}
{"epoch": 17, "training_loss": 0.705679202079773, "training_acc": 52.0, "val_loss": 0.7112524676322937, "val_acc": 48.0}
{"epoch": 18, "training_loss": 0.703442645072937, "training_acc": 46.0, "val_loss": 0.69556640625, "val_acc": 52.0}
{"epoch": 19, "training_loss": 0.7058147644996643, "training_acc": 46.0, "val_loss": 0.6930992865562439, "val_acc": 52.0}
{"epoch": 20, "training_loss": 0.6939933466911316, "training_acc": 46.0, "val_loss": 0.6923470711708068, "val_acc": 52.0}
{"epoch": 21, "training_loss": 0.6978706645965577, "training_acc": 50.0, "val_loss": 0.6926646852493286, "val_acc": 52.0}
{"epoch": 22, "training_loss": 0.6973322534561157, "training_acc": 46.0, "val_loss": 0.6977728462219238, "val_acc": 48.0}
{"epoch": 23, "training_loss": 0.7000178241729736, "training_acc": 50.0, "val_loss": 0.6982753944396972, "val_acc": 48.0}
{"epoch": 24, "training_loss": 0.6998583102226257, "training_acc": 50.0, "val_loss": 0.6945608258247375, "val_acc": 48.0}
{"epoch": 25, "training_loss": 0.7201577210426331, "training_acc": 42.0, "val_loss": 0.6930357360839844, "val_acc": 52.0}
{"epoch": 26, "training_loss": 0.6994754052162171, "training_acc": 48.0, "val_loss": 0.7190845608711243, "val_acc": 48.0}
{"epoch": 27, "training_loss": 0.7208534955978394, "training_acc": 50.0, "val_loss": 0.7052256798744202, "val_acc": 48.0}
{"epoch": 28, "training_loss": 0.699888105392456, "training_acc": 50.0, "val_loss": 0.6949829220771789, "val_acc": 48.0}
{"epoch": 29, "training_loss": 0.6954185509681702, "training_acc": 50.0, "val_loss": 0.6946437764167785, "val_acc": 52.0}
{"epoch": 30, "training_loss": 0.702190351486206, "training_acc": 50.0, "val_loss": 0.69267094373703, "val_acc": 52.0}
{"epoch": 31, "training_loss": 0.7036052083969117, "training_acc": 40.0, "val_loss": 0.694857702255249, "val_acc": 48.0}
{"epoch": 32, "training_loss": 0.6978617644309998, "training_acc": 44.0, "val_loss": 0.6924640655517578, "val_acc": 52.0}
{"epoch": 33, "training_loss": 0.6966564655303955, "training_acc": 46.0, "val_loss": 0.701655969619751, "val_acc": 48.0}
{"epoch": 34, "training_loss": 0.7013087153434754, "training_acc": 50.0, "val_loss": 0.6954236316680908, "val_acc": 48.0}
{"epoch": 35, "training_loss": 0.6959229111671448, "training_acc": 50.0, "val_loss": 0.6966014194488526, "val_acc": 52.0}
{"epoch": 36, "training_loss": 0.69748131275177, "training_acc": 48.0, "val_loss": 0.6986731338500977, "val_acc": 48.0}
{"epoch": 37, "training_loss": 0.7016794490814209, "training_acc": 50.0, "val_loss": 0.6973938846588135, "val_acc": 48.0}
{"epoch": 38, "training_loss": 0.7063813042640686, "training_acc": 44.0, "val_loss": 0.6938203144073486, "val_acc": 52.0}
{"epoch": 39, "training_loss": 0.6919398403167725, "training_acc": 50.0, "val_loss": 0.7007872128486633, "val_acc": 48.0}
