"main_modify.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 1 --task ADNI_sex --input_option yAware --learning_rate 1e-3 --batch_size 16 --weight_decay 1e-5 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 0.7173307871818543, "training_acc": 57.0, "val_loss": 0.6924153089523315, "val_acc": 52.0}
{"epoch": 1, "training_loss": 0.6997344899177551, "training_acc": 47.0, "val_loss": 0.6928796315193176, "val_acc": 52.0}
{"epoch": 2, "training_loss": 0.7000680708885193, "training_acc": 53.0, "val_loss": 0.6927261686325074, "val_acc": 52.0}
{"epoch": 3, "training_loss": 0.7064601850509643, "training_acc": 49.0, "val_loss": 0.6923519992828369, "val_acc": 52.0}
{"epoch": 4, "training_loss": 0.7157822608947754, "training_acc": 47.0, "val_loss": 0.7061512064933777, "val_acc": 48.0}
{"epoch": 5, "training_loss": 0.7096257019042969, "training_acc": 47.0, "val_loss": 0.6926148867607117, "val_acc": 52.0}
{"epoch": 6, "training_loss": 0.7070722961425782, "training_acc": 49.0, "val_loss": 0.7115909028053283, "val_acc": 48.0}
{"epoch": 7, "training_loss": 0.6984759569168091, "training_acc": 47.0, "val_loss": 0.6928977870941162, "val_acc": 52.0}
{"epoch": 8, "training_loss": 0.7153088998794556, "training_acc": 49.0, "val_loss": 0.6937789463996887, "val_acc": 48.0}
{"epoch": 9, "training_loss": 0.6982603406906128, "training_acc": 51.0, "val_loss": 0.7116647243499756, "val_acc": 48.0}
{"epoch": 10, "training_loss": 0.6971106481552124, "training_acc": 51.0, "val_loss": 0.6923895573616028, "val_acc": 52.0}
{"epoch": 11, "training_loss": 0.7174101972579956, "training_acc": 49.0, "val_loss": 0.7010098338127136, "val_acc": 52.0}
{"epoch": 12, "training_loss": 0.6993879652023316, "training_acc": 47.0, "val_loss": 0.708211989402771, "val_acc": 48.0}
{"epoch": 13, "training_loss": 0.7018698191642762, "training_acc": 49.0, "val_loss": 0.6927067518234253, "val_acc": 52.0}
{"epoch": 14, "training_loss": 0.7095688486099243, "training_acc": 49.0, "val_loss": 0.6929618573188782, "val_acc": 52.0}
{"epoch": 15, "training_loss": 0.6976506567001343, "training_acc": 41.0, "val_loss": 0.6958951616287231, "val_acc": 48.0}
{"epoch": 16, "training_loss": 0.7309157252311707, "training_acc": 51.0, "val_loss": 0.7171078658103943, "val_acc": 48.0}
{"epoch": 17, "training_loss": 0.696094434261322, "training_acc": 51.0, "val_loss": 0.6924186706542969, "val_acc": 52.0}
{"epoch": 18, "training_loss": 0.7297317099571228, "training_acc": 49.0, "val_loss": 0.7026044583320618, "val_acc": 52.0}
{"epoch": 19, "training_loss": 0.6995580792427063, "training_acc": 49.0, "val_loss": 0.7103432083129883, "val_acc": 48.0}
{"epoch": 20, "training_loss": 0.70103271484375, "training_acc": 51.0, "val_loss": 0.6989996361732483, "val_acc": 48.0}
{"epoch": 21, "training_loss": 0.6956338548660278, "training_acc": 51.0, "val_loss": 0.6923495674133301, "val_acc": 52.0}
{"epoch": 22, "training_loss": 0.7197399377822876, "training_acc": 49.0, "val_loss": 0.7015954661369324, "val_acc": 52.0}
{"epoch": 23, "training_loss": 0.7001396751403809, "training_acc": 53.0, "val_loss": 0.7014382290840149, "val_acc": 48.0}
{"epoch": 24, "training_loss": 0.7090141415596009, "training_acc": 51.0, "val_loss": 0.7001927256584167, "val_acc": 48.0}
{"epoch": 25, "training_loss": 0.6883809566497803, "training_acc": 53.0, "val_loss": 0.7011617040634155, "val_acc": 52.0}
{"epoch": 26, "training_loss": 0.7165609121322631, "training_acc": 49.0, "val_loss": 0.6924309086799622, "val_acc": 52.0}
{"epoch": 27, "training_loss": 0.7001633358001709, "training_acc": 49.0, "val_loss": 0.7049200630187988, "val_acc": 48.0}
{"epoch": 28, "training_loss": 0.7070674967765808, "training_acc": 43.0, "val_loss": 0.692582995891571, "val_acc": 52.0}
{"epoch": 29, "training_loss": 0.6989956951141357, "training_acc": 45.0, "val_loss": 0.6929738736152649, "val_acc": 52.0}
{"epoch": 30, "training_loss": 0.6937120842933655, "training_acc": 49.0, "val_loss": 0.6923818612098693, "val_acc": 52.0}
{"epoch": 31, "training_loss": 0.694943232536316, "training_acc": 49.0, "val_loss": 0.6943301033973693, "val_acc": 48.0}
{"epoch": 32, "training_loss": 0.695179328918457, "training_acc": 51.0, "val_loss": 0.706588225364685, "val_acc": 48.0}
{"epoch": 33, "training_loss": 0.6961385297775269, "training_acc": 49.0, "val_loss": 0.6925770664215087, "val_acc": 52.0}
{"epoch": 34, "training_loss": 0.6993114519119262, "training_acc": 41.0, "val_loss": 0.6940056037902832, "val_acc": 48.0}
{"epoch": 35, "training_loss": 0.6939723873138428, "training_acc": 51.0, "val_loss": 0.6943338322639465, "val_acc": 48.0}
{"epoch": 36, "training_loss": 0.6939277458190918, "training_acc": 51.0, "val_loss": 0.6923589277267456, "val_acc": 52.0}
{"epoch": 37, "training_loss": 0.69866464138031, "training_acc": 49.0, "val_loss": 0.6927443408966064, "val_acc": 52.0}
{"epoch": 38, "training_loss": 0.7083089113235473, "training_acc": 45.0, "val_loss": 0.7102994012832642, "val_acc": 48.0}
{"epoch": 39, "training_loss": 0.6919673585891724, "training_acc": 53.0, "val_loss": 0.6931537389755249, "val_acc": 52.0}
{"epoch": 40, "training_loss": 0.6977275371551513, "training_acc": 49.0, "val_loss": 0.696974093914032, "val_acc": 48.0}
