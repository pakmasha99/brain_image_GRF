"main_modify.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 1 --task ADNI_sex --input_option yAware --learning_rate 1e-3 --batch_size 16 --weight_decay 1e-5 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 0.7185810661315918, "training_acc": 39.0, "val_loss": 0.6977207469940185, "val_acc": 48.0}
{"epoch": 1, "training_loss": 0.7188744282722473, "training_acc": 44.0, "val_loss": 0.7137705039978027, "val_acc": 48.0}
{"epoch": 2, "training_loss": 0.7091135168075562, "training_acc": 50.0, "val_loss": 0.6953555870056153, "val_acc": 48.0}
{"epoch": 3, "training_loss": 0.7087428998947144, "training_acc": 42.0, "val_loss": 0.6951118922233581, "val_acc": 48.0}
{"epoch": 4, "training_loss": 0.6997791767120362, "training_acc": 42.0, "val_loss": 0.6960445618629456, "val_acc": 48.0}
{"epoch": 5, "training_loss": 0.7045639562606811, "training_acc": 50.0, "val_loss": 0.6953312301635742, "val_acc": 48.0}
{"epoch": 6, "training_loss": 0.6941431188583373, "training_acc": 52.0, "val_loss": 0.6943157005310059, "val_acc": 52.0}
{"epoch": 7, "training_loss": 0.7039498281478882, "training_acc": 50.0, "val_loss": 0.6931943345069885, "val_acc": 48.0}
{"epoch": 8, "training_loss": 0.6948272871971131, "training_acc": 50.0, "val_loss": 0.6999446964263916, "val_acc": 48.0}
{"epoch": 9, "training_loss": 0.6961710643768311, "training_acc": 50.0, "val_loss": 0.6923679828643798, "val_acc": 52.0}
{"epoch": 10, "training_loss": 0.7105991315841674, "training_acc": 50.0, "val_loss": 0.6923836374282837, "val_acc": 52.0}
{"epoch": 11, "training_loss": 0.6960739326477051, "training_acc": 52.0, "val_loss": 0.7015549063682556, "val_acc": 48.0}
{"epoch": 12, "training_loss": 0.6962405037879944, "training_acc": 50.0, "val_loss": 0.6924969601631165, "val_acc": 52.0}
{"epoch": 13, "training_loss": 0.6990608739852905, "training_acc": 40.0, "val_loss": 0.6923686623573303, "val_acc": 52.0}
{"epoch": 14, "training_loss": 0.7087678122520447, "training_acc": 50.0, "val_loss": 0.6939326906204224, "val_acc": 52.0}
{"epoch": 15, "training_loss": 0.7373923826217651, "training_acc": 36.0, "val_loss": 0.702063148021698, "val_acc": 48.0}
{"epoch": 16, "training_loss": 0.6964992237091064, "training_acc": 48.0, "val_loss": 0.6940471243858337, "val_acc": 52.0}
{"epoch": 17, "training_loss": 0.696461386680603, "training_acc": 50.0, "val_loss": 0.6972917890548707, "val_acc": 48.0}
{"epoch": 18, "training_loss": 0.6994535517692566, "training_acc": 48.0, "val_loss": 0.6925161385536194, "val_acc": 52.0}
{"epoch": 19, "training_loss": 0.6905919337272644, "training_acc": 54.0, "val_loss": 0.6994984912872314, "val_acc": 48.0}
{"epoch": 20, "training_loss": 0.7098679065704345, "training_acc": 50.0, "val_loss": 0.6981539869308472, "val_acc": 48.0}
{"epoch": 21, "training_loss": 0.697599151134491, "training_acc": 50.0, "val_loss": 0.6951629996299744, "val_acc": 48.0}
{"epoch": 22, "training_loss": 0.6966515350341796, "training_acc": 50.0, "val_loss": 0.6961874008178711, "val_acc": 48.0}
{"epoch": 23, "training_loss": 0.6933301639556885, "training_acc": 54.0, "val_loss": 0.694492495059967, "val_acc": 52.0}
{"epoch": 24, "training_loss": 0.7157934474945068, "training_acc": 50.0, "val_loss": 0.692365472316742, "val_acc": 52.0}
{"epoch": 25, "training_loss": 0.6897750353813171, "training_acc": 58.0, "val_loss": 0.7313849115371704, "val_acc": 48.0}
{"epoch": 26, "training_loss": 0.7154057741165161, "training_acc": 50.0, "val_loss": 0.6939448499679566, "val_acc": 48.0}
{"epoch": 27, "training_loss": 0.6985366582870484, "training_acc": 42.0, "val_loss": 0.6930232667922973, "val_acc": 52.0}
{"epoch": 28, "training_loss": 0.7163645577430725, "training_acc": 50.0, "val_loss": 0.6969858551025391, "val_acc": 52.0}
{"epoch": 29, "training_loss": 0.7213378071784973, "training_acc": 44.0, "val_loss": 0.7061368632316589, "val_acc": 48.0}
{"epoch": 30, "training_loss": 0.688402247428894, "training_acc": 54.0, "val_loss": 0.695733323097229, "val_acc": 52.0}
{"epoch": 31, "training_loss": 0.7030221176147461, "training_acc": 50.0, "val_loss": 0.6926775455474854, "val_acc": 52.0}
{"epoch": 32, "training_loss": 0.6937036752700806, "training_acc": 48.0, "val_loss": 0.6965953755378723, "val_acc": 48.0}
{"epoch": 33, "training_loss": 0.7056429195404053, "training_acc": 50.0, "val_loss": 0.6994012045860291, "val_acc": 48.0}
{"epoch": 34, "training_loss": 0.7022044134140014, "training_acc": 50.0, "val_loss": 0.6995796608924866, "val_acc": 48.0}
{"epoch": 35, "training_loss": 0.6969003534317016, "training_acc": 48.0, "val_loss": 0.695059769153595, "val_acc": 52.0}
{"epoch": 36, "training_loss": 0.7034016323089599, "training_acc": 50.0, "val_loss": 0.693699655532837, "val_acc": 52.0}
{"epoch": 37, "training_loss": 0.7004861307144165, "training_acc": 50.0, "val_loss": 0.6924044799804687, "val_acc": 52.0}
{"epoch": 38, "training_loss": 0.6969498252868652, "training_acc": 46.0, "val_loss": 0.699501428604126, "val_acc": 48.0}
{"epoch": 39, "training_loss": 0.6959986686706543, "training_acc": 50.0, "val_loss": 0.6932410645484924, "val_acc": 48.0}
{"epoch": 40, "training_loss": 0.6967657995223999, "training_acc": 48.0, "val_loss": 0.6930256366729737, "val_acc": 52.0}
{"epoch": 41, "training_loss": 0.6980281639099121, "training_acc": 50.0, "val_loss": 0.6924372816085815, "val_acc": 52.0}
{"epoch": 42, "training_loss": 0.6937596082687378, "training_acc": 52.0, "val_loss": 0.7003450846672058, "val_acc": 48.0}
{"epoch": 43, "training_loss": 0.7018729591369629, "training_acc": 42.0, "val_loss": 0.692436339855194, "val_acc": 52.0}
