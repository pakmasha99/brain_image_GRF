"main_modify.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 2 --task ADNI_sex --input_option yAware --learning_rate 1e-3 --batch_size 16 --weight_decay 1e-5 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 0.7195170736312866, "training_acc": 42.0, "val_loss": 0.7010884070396424, "val_acc": 48.0}
{"epoch": 1, "training_loss": 0.7031321668624878, "training_acc": 51.0, "val_loss": 0.7149391627311706, "val_acc": 48.0}
{"epoch": 2, "training_loss": 0.7022582340240479, "training_acc": 47.0, "val_loss": 0.6933012628555297, "val_acc": 48.0}
{"epoch": 3, "training_loss": 0.7171648645401001, "training_acc": 53.0, "val_loss": 0.6940748476982117, "val_acc": 52.0}
{"epoch": 4, "training_loss": 0.7178234076499939, "training_acc": 49.0, "val_loss": 0.6924537014961243, "val_acc": 52.0}
{"epoch": 5, "training_loss": 0.7127625107765198, "training_acc": 49.0, "val_loss": 0.6967287135124206, "val_acc": 48.0}
{"epoch": 6, "training_loss": 0.6935446453094483, "training_acc": 51.0, "val_loss": 0.6924255824089051, "val_acc": 52.0}
{"epoch": 7, "training_loss": 0.6994928455352784, "training_acc": 43.0, "val_loss": 0.6924915719032287, "val_acc": 52.0}
{"epoch": 8, "training_loss": 0.6989031744003296, "training_acc": 41.0, "val_loss": 0.6928375291824341, "val_acc": 52.0}
{"epoch": 9, "training_loss": 0.7194785904884339, "training_acc": 49.0, "val_loss": 0.6974736404418945, "val_acc": 52.0}
{"epoch": 10, "training_loss": 0.701653757095337, "training_acc": 47.0, "val_loss": 0.696886351108551, "val_acc": 48.0}
{"epoch": 11, "training_loss": 0.6947480750083923, "training_acc": 51.0, "val_loss": 0.6928242254257202, "val_acc": 52.0}
{"epoch": 12, "training_loss": 0.6939073801040649, "training_acc": 49.0, "val_loss": 0.6928269362449646, "val_acc": 52.0}
{"epoch": 13, "training_loss": 0.7019485759735108, "training_acc": 39.0, "val_loss": 0.6924914407730103, "val_acc": 52.0}
{"epoch": 14, "training_loss": 0.7043001556396484, "training_acc": 49.0, "val_loss": 0.6935784602165223, "val_acc": 52.0}
{"epoch": 15, "training_loss": 0.697577576637268, "training_acc": 47.0, "val_loss": 0.69624351978302, "val_acc": 48.0}
{"epoch": 16, "training_loss": 0.7006522440910339, "training_acc": 51.0, "val_loss": 0.6992478466033936, "val_acc": 48.0}
{"epoch": 17, "training_loss": 0.7062435674667359, "training_acc": 49.0, "val_loss": 0.6957095742225647, "val_acc": 52.0}
{"epoch": 18, "training_loss": 0.6960413861274719, "training_acc": 49.0, "val_loss": 0.7010584592819213, "val_acc": 48.0}
{"epoch": 19, "training_loss": 0.6987846541404724, "training_acc": 51.0, "val_loss": 0.701506745815277, "val_acc": 48.0}
{"epoch": 20, "training_loss": 0.7072529363632202, "training_acc": 43.0, "val_loss": 0.6923845005035401, "val_acc": 52.0}
{"epoch": 21, "training_loss": 0.6977519822120667, "training_acc": 49.0, "val_loss": 0.708764591217041, "val_acc": 48.0}
{"epoch": 22, "training_loss": 0.7009198331832885, "training_acc": 51.0, "val_loss": 0.693198926448822, "val_acc": 48.0}
{"epoch": 23, "training_loss": 0.696868896484375, "training_acc": 49.0, "val_loss": 0.6944750785827637, "val_acc": 52.0}
{"epoch": 24, "training_loss": 0.6997286295890808, "training_acc": 49.0, "val_loss": 0.6923996067047119, "val_acc": 52.0}
{"epoch": 25, "training_loss": 0.6964946746826172, "training_acc": 47.0, "val_loss": 0.7006429290771484, "val_acc": 48.0}
{"epoch": 26, "training_loss": 0.7015490412712098, "training_acc": 51.0, "val_loss": 0.697611620426178, "val_acc": 48.0}
{"epoch": 27, "training_loss": 0.6944410991668701, "training_acc": 51.0, "val_loss": 0.6939986729621888, "val_acc": 48.0}
{"epoch": 28, "training_loss": 0.6991104412078858, "training_acc": 51.0, "val_loss": 0.6924347567558289, "val_acc": 52.0}
{"epoch": 29, "training_loss": 0.703799409866333, "training_acc": 49.0, "val_loss": 0.6946352744102477, "val_acc": 52.0}
{"epoch": 30, "training_loss": 0.7020947813987732, "training_acc": 45.0, "val_loss": 0.702153205871582, "val_acc": 48.0}
{"epoch": 31, "training_loss": 0.7005377435684204, "training_acc": 51.0, "val_loss": 0.6984369611740112, "val_acc": 48.0}
{"epoch": 32, "training_loss": 0.6971347188949585, "training_acc": 51.0, "val_loss": 0.698474268913269, "val_acc": 48.0}
{"epoch": 33, "training_loss": 0.701783492565155, "training_acc": 47.0, "val_loss": 0.6923552823066711, "val_acc": 52.0}
{"epoch": 34, "training_loss": 0.6907341027259827, "training_acc": 57.0, "val_loss": 0.7015253496170044, "val_acc": 48.0}
{"epoch": 35, "training_loss": 0.6982124328613282, "training_acc": 51.0, "val_loss": 0.6926120305061341, "val_acc": 52.0}
{"epoch": 36, "training_loss": 0.7195909690856933, "training_acc": 49.0, "val_loss": 0.7069715523719787, "val_acc": 52.0}
{"epoch": 37, "training_loss": 0.7119762921333312, "training_acc": 49.0, "val_loss": 0.6935693049430847, "val_acc": 48.0}
{"epoch": 38, "training_loss": 0.6933127975463867, "training_acc": 51.0, "val_loss": 0.7055417275428773, "val_acc": 48.0}
{"epoch": 39, "training_loss": 0.7083125448226929, "training_acc": 51.0, "val_loss": 0.7101907277107239, "val_acc": 48.0}
{"epoch": 40, "training_loss": 0.7041811919212342, "training_acc": 51.0, "val_loss": 0.6954947209358215, "val_acc": 48.0}
{"epoch": 41, "training_loss": 0.693334047794342, "training_acc": 51.0, "val_loss": 0.6929441142082214, "val_acc": 52.0}
{"epoch": 42, "training_loss": 0.6972751498222352, "training_acc": 45.0, "val_loss": 0.6928283047676086, "val_acc": 52.0}
{"epoch": 43, "training_loss": 0.7134073853492737, "training_acc": 49.0, "val_loss": 0.6928931069374085, "val_acc": 52.0}
{"epoch": 44, "training_loss": 0.6967171478271484, "training_acc": 49.0, "val_loss": 0.7021871685981751, "val_acc": 48.0}
{"epoch": 45, "training_loss": 0.6940365028381348, "training_acc": 53.0, "val_loss": 0.6926990962028503, "val_acc": 52.0}
{"epoch": 46, "training_loss": 0.7019591808319092, "training_acc": 49.0, "val_loss": 0.6923532485961914, "val_acc": 52.0}
{"epoch": 47, "training_loss": 0.6938012480735779, "training_acc": 51.0, "val_loss": 0.7112640118598939, "val_acc": 48.0}
{"epoch": 48, "training_loss": 0.7049827933311462, "training_acc": 51.0, "val_loss": 0.6991851878166199, "val_acc": 48.0}
{"epoch": 49, "training_loss": 0.7043410325050354, "training_acc": 45.0, "val_loss": 0.6981858468055725, "val_acc": 52.0}
{"epoch": 50, "training_loss": 0.7084833431243897, "training_acc": 49.0, "val_loss": 0.6926927208900452, "val_acc": 52.0}
{"epoch": 51, "training_loss": 0.6895483922958374, "training_acc": 55.0, "val_loss": 0.7055328702926635, "val_acc": 48.0}
{"epoch": 52, "training_loss": 0.6985034537315369, "training_acc": 51.0, "val_loss": 0.6935775876045227, "val_acc": 48.0}
{"epoch": 53, "training_loss": 0.7451086449623108, "training_acc": 45.0, "val_loss": 0.7041262364387513, "val_acc": 52.0}
{"epoch": 54, "training_loss": 0.6959404945373535, "training_acc": 51.0, "val_loss": 0.7096566891670227, "val_acc": 48.0}
{"epoch": 55, "training_loss": 0.7209033584594726, "training_acc": 51.0, "val_loss": 0.7267103457450866, "val_acc": 48.0}
{"epoch": 56, "training_loss": 0.7071153378486633, "training_acc": 49.0, "val_loss": 0.692424590587616, "val_acc": 52.0}
{"epoch": 57, "training_loss": 0.6968204021453858, "training_acc": 49.0, "val_loss": 0.6932356929779053, "val_acc": 48.0}
{"epoch": 58, "training_loss": 0.6938792824745178, "training_acc": 49.0, "val_loss": 0.6995068669319153, "val_acc": 48.0}
{"epoch": 59, "training_loss": 0.7124104642868042, "training_acc": 51.0, "val_loss": 0.7160608100891114, "val_acc": 48.0}
{"epoch": 60, "training_loss": 0.698695855140686, "training_acc": 47.0, "val_loss": 0.6941854953765869, "val_acc": 52.0}
{"epoch": 61, "training_loss": 0.7007512998580933, "training_acc": 49.0, "val_loss": 0.6931562113761902, "val_acc": 52.0}
{"epoch": 62, "training_loss": 0.7009555339813233, "training_acc": 47.0, "val_loss": 0.7015103912353515, "val_acc": 48.0}
{"epoch": 63, "training_loss": 0.6975056838989258, "training_acc": 51.0, "val_loss": 0.6945672297477722, "val_acc": 48.0}
{"epoch": 64, "training_loss": 0.6950931072235107, "training_acc": 51.0, "val_loss": 0.7007710719108582, "val_acc": 48.0}
{"epoch": 65, "training_loss": 0.699909336566925, "training_acc": 45.0, "val_loss": 0.69265300989151, "val_acc": 52.0}
