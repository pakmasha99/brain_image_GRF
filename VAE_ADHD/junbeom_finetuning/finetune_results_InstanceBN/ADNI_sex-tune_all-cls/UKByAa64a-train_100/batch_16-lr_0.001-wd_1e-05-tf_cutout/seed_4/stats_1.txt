"main_modify.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 4 --task ADNI_sex --input_option yAware --learning_rate 1e-3 --batch_size 16 --weight_decay 1e-5 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 0.7072126960754395, "training_acc": 53.0, "val_loss": 0.7132260227203369, "val_acc": 48.0}
{"epoch": 1, "training_loss": 0.710394892692566, "training_acc": 39.0, "val_loss": 0.6957189512252807, "val_acc": 48.0}
{"epoch": 2, "training_loss": 0.7034664368629455, "training_acc": 43.0, "val_loss": 0.6923763394355774, "val_acc": 52.0}
{"epoch": 3, "training_loss": 0.710332727432251, "training_acc": 49.0, "val_loss": 0.6923783230781555, "val_acc": 52.0}
{"epoch": 4, "training_loss": 0.7050932884216309, "training_acc": 51.0, "val_loss": 0.7023395347595215, "val_acc": 48.0}
{"epoch": 5, "training_loss": 0.6985744524002075, "training_acc": 45.0, "val_loss": 0.693376305103302, "val_acc": 48.0}
{"epoch": 6, "training_loss": 0.6948519563674926, "training_acc": 51.0, "val_loss": 0.6936280465126038, "val_acc": 48.0}
{"epoch": 7, "training_loss": 0.695854172706604, "training_acc": 47.0, "val_loss": 0.6936838865280152, "val_acc": 48.0}
{"epoch": 8, "training_loss": 0.699291000366211, "training_acc": 43.0, "val_loss": 0.6955836129188537, "val_acc": 48.0}
{"epoch": 9, "training_loss": 0.7026977682113648, "training_acc": 51.0, "val_loss": 0.7012098050117492, "val_acc": 48.0}
{"epoch": 10, "training_loss": 0.7041050577163697, "training_acc": 41.0, "val_loss": 0.6945310235023499, "val_acc": 48.0}
{"epoch": 11, "training_loss": 0.7007928776741028, "training_acc": 39.0, "val_loss": 0.693104453086853, "val_acc": 52.0}
{"epoch": 12, "training_loss": 0.6968125510215759, "training_acc": 49.0, "val_loss": 0.6923739337921142, "val_acc": 52.0}
{"epoch": 13, "training_loss": 0.6968587517738343, "training_acc": 47.0, "val_loss": 0.6931650686264038, "val_acc": 48.0}
{"epoch": 14, "training_loss": 0.6944511461257935, "training_acc": 43.0, "val_loss": 0.6925940322875976, "val_acc": 52.0}
{"epoch": 15, "training_loss": 0.7015892887115478, "training_acc": 49.0, "val_loss": 0.6928650426864624, "val_acc": 52.0}
{"epoch": 16, "training_loss": 0.6970227479934692, "training_acc": 49.0, "val_loss": 0.694914481639862, "val_acc": 48.0}
{"epoch": 17, "training_loss": 0.69983389377594, "training_acc": 39.0, "val_loss": 0.6990868711471557, "val_acc": 48.0}
{"epoch": 18, "training_loss": 0.7015473484992981, "training_acc": 51.0, "val_loss": 0.7019109272956848, "val_acc": 48.0}
{"epoch": 19, "training_loss": 0.7023686003684998, "training_acc": 41.0, "val_loss": 0.6925451993942261, "val_acc": 52.0}
{"epoch": 20, "training_loss": 0.6980944442749023, "training_acc": 49.0, "val_loss": 0.6926538395881653, "val_acc": 52.0}
{"epoch": 21, "training_loss": 0.6956306743621826, "training_acc": 45.0, "val_loss": 0.6933132314682007, "val_acc": 48.0}
{"epoch": 22, "training_loss": 0.6959820723533631, "training_acc": 51.0, "val_loss": 0.6966503119468689, "val_acc": 48.0}
{"epoch": 23, "training_loss": 0.7002984595298767, "training_acc": 51.0, "val_loss": 0.6971012949943542, "val_acc": 48.0}
{"epoch": 24, "training_loss": 0.70653644323349, "training_acc": 47.0, "val_loss": 0.6928691077232361, "val_acc": 52.0}
{"epoch": 25, "training_loss": 0.688216483592987, "training_acc": 57.0, "val_loss": 0.7091974449157715, "val_acc": 48.0}
{"epoch": 26, "training_loss": 0.7177251887321472, "training_acc": 51.0, "val_loss": 0.713269739151001, "val_acc": 48.0}
{"epoch": 27, "training_loss": 0.696468985080719, "training_acc": 51.0, "val_loss": 0.6923582196235657, "val_acc": 52.0}
{"epoch": 28, "training_loss": 0.6964934492111206, "training_acc": 49.0, "val_loss": 0.6944824290275574, "val_acc": 52.0}
{"epoch": 29, "training_loss": 0.7049488878250122, "training_acc": 47.0, "val_loss": 0.6926554417610169, "val_acc": 52.0}
{"epoch": 30, "training_loss": 0.6941256761550904, "training_acc": 49.0, "val_loss": 0.6925444531440735, "val_acc": 52.0}
{"epoch": 31, "training_loss": 0.696704204082489, "training_acc": 45.0, "val_loss": 0.6967672061920166, "val_acc": 48.0}
{"epoch": 32, "training_loss": 0.7033850431442261, "training_acc": 51.0, "val_loss": 0.6949207782745361, "val_acc": 48.0}
{"epoch": 33, "training_loss": 0.7011484050750733, "training_acc": 51.0, "val_loss": 0.7015916657447815, "val_acc": 52.0}
{"epoch": 34, "training_loss": 0.7017553234100342, "training_acc": 53.0, "val_loss": 0.7018505883216858, "val_acc": 48.0}
{"epoch": 35, "training_loss": 0.7105194282531738, "training_acc": 51.0, "val_loss": 0.6949673795700073, "val_acc": 48.0}
{"epoch": 36, "training_loss": 0.7053543710708619, "training_acc": 39.0, "val_loss": 0.6967533898353576, "val_acc": 48.0}
{"epoch": 37, "training_loss": 0.7029727077484131, "training_acc": 51.0, "val_loss": 0.7023594760894776, "val_acc": 48.0}
{"epoch": 38, "training_loss": 0.6938118863105774, "training_acc": 51.0, "val_loss": 0.6923727035522461, "val_acc": 52.0}
{"epoch": 39, "training_loss": 0.696545729637146, "training_acc": 49.0, "val_loss": 0.6939186573028564, "val_acc": 52.0}
{"epoch": 40, "training_loss": 0.6965640759468079, "training_acc": 49.0, "val_loss": 0.6950529479980468, "val_acc": 48.0}
{"epoch": 41, "training_loss": 0.6990578365325928, "training_acc": 51.0, "val_loss": 0.6942105197906494, "val_acc": 48.0}
{"epoch": 42, "training_loss": 0.6939674305915833, "training_acc": 51.0, "val_loss": 0.6933322143554688, "val_acc": 52.0}
{"epoch": 43, "training_loss": 0.6971833443641663, "training_acc": 51.0, "val_loss": 0.7051087498664856, "val_acc": 48.0}
{"epoch": 44, "training_loss": 0.6978630590438842, "training_acc": 51.0, "val_loss": 0.6944235920906067, "val_acc": 48.0}
{"epoch": 45, "training_loss": 0.6954270744323731, "training_acc": 51.0, "val_loss": 0.6925164914131164, "val_acc": 52.0}
{"epoch": 46, "training_loss": 0.7481676316261292, "training_acc": 49.0, "val_loss": 0.7007332253456116, "val_acc": 52.0}
