"main_modify.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 4 --task ADNI_sex --input_option yAware --learning_rate 1e-3 --batch_size 16 --weight_decay 1e-5 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 0.6998583078384399, "training_acc": 50.0, "val_loss": 0.6982205295562744, "val_acc": 48.0}
{"epoch": 1, "training_loss": 0.7166549539566041, "training_acc": 44.0, "val_loss": 0.6984091687202454, "val_acc": 52.0}
{"epoch": 2, "training_loss": 0.7263281607627868, "training_acc": 50.0, "val_loss": 0.693784601688385, "val_acc": 52.0}
{"epoch": 3, "training_loss": 0.7072954654693604, "training_acc": 50.0, "val_loss": 0.6983434009552002, "val_acc": 48.0}
{"epoch": 4, "training_loss": 0.7354757022857666, "training_acc": 50.0, "val_loss": 0.7032966184616088, "val_acc": 48.0}
{"epoch": 5, "training_loss": 0.6972570443153381, "training_acc": 52.0, "val_loss": 0.6940498065948486, "val_acc": 52.0}
{"epoch": 6, "training_loss": 0.6987158918380737, "training_acc": 50.0, "val_loss": 0.6968750047683716, "val_acc": 48.0}
{"epoch": 7, "training_loss": 0.6989690327644348, "training_acc": 50.0, "val_loss": 0.6947459411621094, "val_acc": 48.0}
{"epoch": 8, "training_loss": 0.696148943901062, "training_acc": 42.0, "val_loss": 0.6952886986732483, "val_acc": 48.0}
{"epoch": 9, "training_loss": 0.6960856246948243, "training_acc": 50.0, "val_loss": 0.696824848651886, "val_acc": 48.0}
{"epoch": 10, "training_loss": 0.7031462812423706, "training_acc": 50.0, "val_loss": 0.6929557371139526, "val_acc": 52.0}
{"epoch": 11, "training_loss": 0.7200270175933838, "training_acc": 50.0, "val_loss": 0.6995293521881103, "val_acc": 52.0}
{"epoch": 12, "training_loss": 0.6969922780990601, "training_acc": 52.0, "val_loss": 0.699887466430664, "val_acc": 48.0}
{"epoch": 13, "training_loss": 0.6969729709625244, "training_acc": 50.0, "val_loss": 0.7063316750526428, "val_acc": 48.0}
{"epoch": 14, "training_loss": 0.7056713390350342, "training_acc": 44.0, "val_loss": 0.6925463795661926, "val_acc": 52.0}
{"epoch": 15, "training_loss": 0.6972084856033325, "training_acc": 50.0, "val_loss": 0.6958931279182434, "val_acc": 48.0}
{"epoch": 16, "training_loss": 0.699517912864685, "training_acc": 50.0, "val_loss": 0.7059587597846985, "val_acc": 48.0}
{"epoch": 17, "training_loss": 0.7132922339439393, "training_acc": 46.0, "val_loss": 0.6955678844451905, "val_acc": 52.0}
{"epoch": 18, "training_loss": 0.7499382066726684, "training_acc": 38.0, "val_loss": 0.7072546696662902, "val_acc": 48.0}
{"epoch": 19, "training_loss": 0.6983325242996216, "training_acc": 52.0, "val_loss": 0.7089345121383667, "val_acc": 52.0}
{"epoch": 20, "training_loss": 0.7034046459197998, "training_acc": 54.0, "val_loss": 0.7031391716003418, "val_acc": 48.0}
{"epoch": 21, "training_loss": 0.729343364238739, "training_acc": 50.0, "val_loss": 0.723762972354889, "val_acc": 48.0}
{"epoch": 22, "training_loss": 0.6946432876586914, "training_acc": 56.0, "val_loss": 0.6973188042640686, "val_acc": 52.0}
{"epoch": 23, "training_loss": 0.707609839439392, "training_acc": 50.0, "val_loss": 0.6923424220085144, "val_acc": 52.0}
{"epoch": 24, "training_loss": 0.7112789988517761, "training_acc": 46.0, "val_loss": 0.7065361166000366, "val_acc": 48.0}
{"epoch": 25, "training_loss": 0.7011216950416564, "training_acc": 50.0, "val_loss": 0.6972116732597351, "val_acc": 52.0}
{"epoch": 26, "training_loss": 0.7000114965438843, "training_acc": 48.0, "val_loss": 0.6936232423782349, "val_acc": 48.0}
{"epoch": 27, "training_loss": 0.6956447744369507, "training_acc": 50.0, "val_loss": 0.6929410600662231, "val_acc": 52.0}
{"epoch": 28, "training_loss": 0.6952930641174316, "training_acc": 44.0, "val_loss": 0.6925578927993774, "val_acc": 52.0}
{"epoch": 29, "training_loss": 0.7295193862915039, "training_acc": 50.0, "val_loss": 0.6941244173049926, "val_acc": 52.0}
{"epoch": 30, "training_loss": 0.724388279914856, "training_acc": 44.0, "val_loss": 0.7253061985969543, "val_acc": 48.0}
{"epoch": 31, "training_loss": 0.7007914876937866, "training_acc": 50.0, "val_loss": 0.6972493720054627, "val_acc": 52.0}
{"epoch": 32, "training_loss": 0.703848934173584, "training_acc": 50.0, "val_loss": 0.6923985719680786, "val_acc": 52.0}
{"epoch": 33, "training_loss": 0.6989315605163574, "training_acc": 50.0, "val_loss": 0.6997276997566223, "val_acc": 48.0}
{"epoch": 34, "training_loss": 0.7127403211593628, "training_acc": 50.0, "val_loss": 0.7005625605583191, "val_acc": 48.0}
{"epoch": 35, "training_loss": 0.6885766935348511, "training_acc": 52.0, "val_loss": 0.6964574313163757, "val_acc": 52.0}
{"epoch": 36, "training_loss": 0.7059387588500976, "training_acc": 50.0, "val_loss": 0.6956514859199524, "val_acc": 52.0}
{"epoch": 37, "training_loss": 0.6998469758033753, "training_acc": 50.0, "val_loss": 0.6941556143760681, "val_acc": 48.0}
{"epoch": 38, "training_loss": 0.7070967054367066, "training_acc": 50.0, "val_loss": 0.7211656141281128, "val_acc": 48.0}
{"epoch": 39, "training_loss": 0.7039256048202515, "training_acc": 48.0, "val_loss": 0.6946987843513489, "val_acc": 52.0}
{"epoch": 40, "training_loss": 0.7129864025115967, "training_acc": 50.0, "val_loss": 0.7078075957298279, "val_acc": 52.0}
{"epoch": 41, "training_loss": 0.7114597082138061, "training_acc": 50.0, "val_loss": 0.6926071619987488, "val_acc": 52.0}
{"epoch": 42, "training_loss": 0.718609824180603, "training_acc": 48.0, "val_loss": 0.7176424074172973, "val_acc": 48.0}
