"main_modify.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ADNI_sex --input_option yAware --learning_rate 1e-3 --batch_size 16 --weight_decay 1e-5 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 0.6993387317657471, "training_acc": 53.0, "val_loss": 0.6934950256347656, "val_acc": 52.0}
{"epoch": 1, "training_loss": 0.7113453769683837, "training_acc": 43.0, "val_loss": 0.6923576664924621, "val_acc": 52.0}
{"epoch": 2, "training_loss": 0.7033208084106445, "training_acc": 45.0, "val_loss": 0.6924879837036133, "val_acc": 52.0}
{"epoch": 3, "training_loss": 0.6995179224014282, "training_acc": 49.0, "val_loss": 0.69305584192276, "val_acc": 52.0}
{"epoch": 4, "training_loss": 0.7237408447265625, "training_acc": 41.0, "val_loss": 0.6978169369697571, "val_acc": 48.0}
{"epoch": 5, "training_loss": 0.7072179889678956, "training_acc": 51.0, "val_loss": 0.6967046546936035, "val_acc": 52.0}
{"epoch": 6, "training_loss": 0.7059242916107178, "training_acc": 45.0, "val_loss": 0.6993275666236878, "val_acc": 48.0}
{"epoch": 7, "training_loss": 0.6980537605285645, "training_acc": 51.0, "val_loss": 0.6937858200073242, "val_acc": 48.0}
{"epoch": 8, "training_loss": 0.7082884359359741, "training_acc": 45.0, "val_loss": 0.6930757451057434, "val_acc": 52.0}
{"epoch": 9, "training_loss": 0.6954530191421509, "training_acc": 49.0, "val_loss": 0.7012198376655578, "val_acc": 48.0}
{"epoch": 10, "training_loss": 0.7106855177879333, "training_acc": 51.0, "val_loss": 0.706310043334961, "val_acc": 48.0}
{"epoch": 11, "training_loss": 0.6968027830123902, "training_acc": 51.0, "val_loss": 0.6965143084526062, "val_acc": 52.0}
{"epoch": 12, "training_loss": 0.7075158643722534, "training_acc": 49.0, "val_loss": 0.6981174206733703, "val_acc": 48.0}
{"epoch": 13, "training_loss": 0.7281435179710388, "training_acc": 51.0, "val_loss": 0.7144416809082031, "val_acc": 48.0}
{"epoch": 14, "training_loss": 0.6860935258865356, "training_acc": 55.0, "val_loss": 0.6992005634307862, "val_acc": 52.0}
{"epoch": 15, "training_loss": 0.7110580778121949, "training_acc": 45.0, "val_loss": 0.6925510716438293, "val_acc": 52.0}
{"epoch": 16, "training_loss": 0.7001130509376526, "training_acc": 49.0, "val_loss": 0.6924387502670288, "val_acc": 52.0}
{"epoch": 17, "training_loss": 0.6957035398483277, "training_acc": 51.0, "val_loss": 0.7193131351470947, "val_acc": 48.0}
{"epoch": 18, "training_loss": 0.7091776180267334, "training_acc": 51.0, "val_loss": 0.6970719480514527, "val_acc": 48.0}
{"epoch": 19, "training_loss": 0.6965482330322266, "training_acc": 51.0, "val_loss": 0.6923509001731872, "val_acc": 52.0}
{"epoch": 20, "training_loss": 0.6979161596298218, "training_acc": 49.0, "val_loss": 0.6923466873168945, "val_acc": 52.0}
{"epoch": 21, "training_loss": 0.7077838349342346, "training_acc": 47.0, "val_loss": 0.7097693586349487, "val_acc": 48.0}
{"epoch": 22, "training_loss": 0.7064830470085144, "training_acc": 43.0, "val_loss": 0.6924005746841431, "val_acc": 52.0}
{"epoch": 23, "training_loss": 0.6897429180145264, "training_acc": 53.0, "val_loss": 0.7033638048171997, "val_acc": 48.0}
{"epoch": 24, "training_loss": 0.6961860179901123, "training_acc": 49.0, "val_loss": 0.6934641981124878, "val_acc": 48.0}
{"epoch": 25, "training_loss": 0.6947671627998352, "training_acc": 41.0, "val_loss": 0.6994505906105042, "val_acc": 48.0}
{"epoch": 26, "training_loss": 0.7020612812042236, "training_acc": 51.0, "val_loss": 0.7003183364868164, "val_acc": 48.0}
{"epoch": 27, "training_loss": 0.696243028640747, "training_acc": 51.0, "val_loss": 0.6972123074531555, "val_acc": 48.0}
{"epoch": 28, "training_loss": 0.6994026851654053, "training_acc": 43.0, "val_loss": 0.6923786902427673, "val_acc": 52.0}
{"epoch": 29, "training_loss": 0.6975624942779541, "training_acc": 47.0, "val_loss": 0.6942598819732666, "val_acc": 48.0}
{"epoch": 30, "training_loss": 0.7064656305313111, "training_acc": 47.0, "val_loss": 0.697152693271637, "val_acc": 52.0}
{"epoch": 31, "training_loss": 0.7121352863311767, "training_acc": 39.0, "val_loss": 0.6935391235351562, "val_acc": 48.0}
{"epoch": 32, "training_loss": 0.7020717477798462, "training_acc": 51.0, "val_loss": 0.6961846566200256, "val_acc": 52.0}
{"epoch": 33, "training_loss": 0.7013474416732788, "training_acc": 49.0, "val_loss": 0.694693341255188, "val_acc": 48.0}
{"epoch": 34, "training_loss": 0.6987277793884278, "training_acc": 51.0, "val_loss": 0.7124910736083985, "val_acc": 48.0}
{"epoch": 35, "training_loss": 0.7038857221603394, "training_acc": 51.0, "val_loss": 0.6972992730140686, "val_acc": 48.0}
{"epoch": 36, "training_loss": 0.6942337322235107, "training_acc": 51.0, "val_loss": 0.6939026498794556, "val_acc": 48.0}
{"epoch": 37, "training_loss": 0.6961438179016113, "training_acc": 51.0, "val_loss": 0.6957097578048707, "val_acc": 48.0}
{"epoch": 38, "training_loss": 0.7043405842781066, "training_acc": 51.0, "val_loss": 0.701611602306366, "val_acc": 48.0}
{"epoch": 39, "training_loss": 0.6960073566436767, "training_acc": 51.0, "val_loss": 0.6938956546783447, "val_acc": 48.0}
