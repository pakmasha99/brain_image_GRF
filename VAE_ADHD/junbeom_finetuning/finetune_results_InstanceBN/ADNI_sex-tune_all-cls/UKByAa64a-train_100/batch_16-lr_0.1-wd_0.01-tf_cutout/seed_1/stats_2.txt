"main_modify.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 1 --task ADNI_sex --input_option yAware --learning_rate 1e-1 --batch_size 16 --weight_decay 1e-2 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 12.135399586769054, "training_acc": 46.0, "val_loss": 0.8391056513786316, "val_acc": 48.0}
{"epoch": 1, "training_loss": 2.2497780323028564, "training_acc": 46.0, "val_loss": 1.0523377561569214, "val_acc": 52.0}
{"epoch": 2, "training_loss": 1.4997377586364746, "training_acc": 44.0, "val_loss": 0.7402978110313415, "val_acc": 48.0}
{"epoch": 3, "training_loss": 1.227313928604126, "training_acc": 50.0, "val_loss": 2.492943162918091, "val_acc": 48.0}
{"epoch": 4, "training_loss": 2.126630344390869, "training_acc": 52.0, "val_loss": 3.385985870361328, "val_acc": 48.0}
{"epoch": 5, "training_loss": 2.5869131669122725, "training_acc": 52.0, "val_loss": 5.9359517097473145, "val_acc": 48.0}
{"epoch": 6, "training_loss": 4.163461055755615, "training_acc": 52.0, "val_loss": 1.3143592691421508, "val_acc": 52.0}
{"epoch": 7, "training_loss": 3.544976453781128, "training_acc": 50.0, "val_loss": 3.632313175201416, "val_acc": 52.0}
{"epoch": 8, "training_loss": 2.26035605430603, "training_acc": 48.0, "val_loss": 0.6938307666778565, "val_acc": 48.0}
{"epoch": 9, "training_loss": 1.2138931727409363, "training_acc": 52.0, "val_loss": 1.8792123126983642, "val_acc": 48.0}
{"epoch": 10, "training_loss": 0.9911944055557251, "training_acc": 46.0, "val_loss": 2.4619757080078126, "val_acc": 52.0}
{"epoch": 11, "training_loss": 1.2379726362228394, "training_acc": 52.0, "val_loss": 1.3518817043304443, "val_acc": 48.0}
{"epoch": 12, "training_loss": 0.8234952688217163, "training_acc": 54.0, "val_loss": 1.8577412605285644, "val_acc": 52.0}
{"epoch": 13, "training_loss": 1.4403668689727782, "training_acc": 50.0, "val_loss": 0.989873046875, "val_acc": 52.0}
{"epoch": 14, "training_loss": 0.8253343534469605, "training_acc": 50.0, "val_loss": 2.3031556510925295, "val_acc": 52.0}
{"epoch": 15, "training_loss": 1.621211004257202, "training_acc": 46.0, "val_loss": 1.7534420967102051, "val_acc": 48.0}
{"epoch": 16, "training_loss": 1.2554835820198058, "training_acc": 50.0, "val_loss": 0.7102527689933776, "val_acc": 52.0}
{"epoch": 17, "training_loss": 1.420890417098999, "training_acc": 44.0, "val_loss": 0.7162254333496094, "val_acc": 48.0}
{"epoch": 18, "training_loss": 1.424573199748993, "training_acc": 46.0, "val_loss": 1.7498384428024292, "val_acc": 52.0}
{"epoch": 19, "training_loss": 1.2824921607971191, "training_acc": 42.0, "val_loss": 2.483795375823975, "val_acc": 52.0}
{"epoch": 20, "training_loss": 2.062063903808594, "training_acc": 52.0, "val_loss": 0.8307200312614441, "val_acc": 52.0}
{"epoch": 21, "training_loss": 0.903317391872406, "training_acc": 50.0, "val_loss": 2.2004052734375, "val_acc": 52.0}
{"epoch": 22, "training_loss": 2.2753166580200195, "training_acc": 48.0, "val_loss": 0.8143574380874634, "val_acc": 52.0}
{"epoch": 23, "training_loss": 2.1398786163330077, "training_acc": 46.0, "val_loss": 0.692395281791687, "val_acc": 52.0}
{"epoch": 24, "training_loss": 1.2018963527679443, "training_acc": 50.0, "val_loss": 1.998468852043152, "val_acc": 52.0}
{"epoch": 25, "training_loss": 1.5932135963439942, "training_acc": 40.0, "val_loss": 1.6756016540527343, "val_acc": 52.0}
{"epoch": 26, "training_loss": 1.1849895238876342, "training_acc": 54.0, "val_loss": 1.8512056636810303, "val_acc": 48.0}
{"epoch": 27, "training_loss": 2.382954092025757, "training_acc": 46.0, "val_loss": 1.6455556011199952, "val_acc": 52.0}
{"epoch": 28, "training_loss": 1.411532609462738, "training_acc": 48.0, "val_loss": 0.718936767578125, "val_acc": 48.0}
{"epoch": 29, "training_loss": 1.2160649085044861, "training_acc": 50.0, "val_loss": 1.3929800939559938, "val_acc": 48.0}
{"epoch": 30, "training_loss": 0.9474954700469971, "training_acc": 52.0, "val_loss": 3.302152099609375, "val_acc": 48.0}
{"epoch": 31, "training_loss": 1.8049502205848693, "training_acc": 52.0, "val_loss": 2.3069999599456787, "val_acc": 48.0}
{"epoch": 32, "training_loss": 1.9359104919433594, "training_acc": 46.0, "val_loss": 3.8835814094543455, "val_acc": 52.0}
{"epoch": 33, "training_loss": 4.047385988235473, "training_acc": 46.0, "val_loss": 1.3562941026687623, "val_acc": 52.0}
{"epoch": 34, "training_loss": 2.286113369464874, "training_acc": 52.0, "val_loss": 2.7225915813446044, "val_acc": 52.0}
{"epoch": 35, "training_loss": 2.112185544967651, "training_acc": 52.0, "val_loss": 2.0796186208724974, "val_acc": 52.0}
{"epoch": 36, "training_loss": 1.0907800936698913, "training_acc": 50.0, "val_loss": 1.7604914283752442, "val_acc": 48.0}
{"epoch": 37, "training_loss": 1.9815555095672608, "training_acc": 48.0, "val_loss": 1.3686042261123657, "val_acc": 52.0}
{"epoch": 38, "training_loss": 2.2212745571136474, "training_acc": 42.0, "val_loss": 4.1820475864410405, "val_acc": 52.0}
{"epoch": 39, "training_loss": 4.226738395690918, "training_acc": 50.0, "val_loss": 1.043056344985962, "val_acc": 48.0}
{"epoch": 40, "training_loss": 2.9667663621902465, "training_acc": 42.0, "val_loss": 2.546307544708252, "val_acc": 52.0}
{"epoch": 41, "training_loss": 1.2684974145889283, "training_acc": 50.0, "val_loss": 1.3675395941734314, "val_acc": 52.0}
{"epoch": 42, "training_loss": 1.5330174827575684, "training_acc": 50.0, "val_loss": 1.4245642042160034, "val_acc": 48.0}
