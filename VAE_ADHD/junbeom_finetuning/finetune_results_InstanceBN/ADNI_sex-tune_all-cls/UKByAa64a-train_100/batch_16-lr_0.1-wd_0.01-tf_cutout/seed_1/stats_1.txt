"main_modify.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 1 --task ADNI_sex --input_option yAware --learning_rate 1e-1 --batch_size 16 --weight_decay 1e-2 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 9.275083208084107, "training_acc": 45.0, "val_loss": 5.222602825164795, "val_acc": 52.0}
{"epoch": 1, "training_loss": 5.614174575805664, "training_acc": 48.0, "val_loss": 0.7238039779663086, "val_acc": 52.0}
{"epoch": 2, "training_loss": 4.7399723127298055, "training_acc": 52.0, "val_loss": 6.443026714324951, "val_acc": 48.0}
{"epoch": 3, "training_loss": 4.186528906822205, "training_acc": 44.0, "val_loss": 0.9402537512779235, "val_acc": 48.0}
{"epoch": 4, "training_loss": 0.7944557684659957, "training_acc": 54.0, "val_loss": 2.3433876514434813, "val_acc": 48.0}
{"epoch": 5, "training_loss": 1.327910394668579, "training_acc": 48.0, "val_loss": 2.10444561958313, "val_acc": 48.0}
{"epoch": 6, "training_loss": 2.066393487453461, "training_acc": 54.0, "val_loss": 3.7689417457580565, "val_acc": 48.0}
{"epoch": 7, "training_loss": 2.659418876171112, "training_acc": 54.0, "val_loss": 2.066653504371643, "val_acc": 48.0}
{"epoch": 8, "training_loss": 1.8560246801376343, "training_acc": 46.0, "val_loss": 0.7323843789100647, "val_acc": 52.0}
{"epoch": 9, "training_loss": 0.7441057133674621, "training_acc": 56.0, "val_loss": 1.4939769220352173, "val_acc": 48.0}
{"epoch": 10, "training_loss": 0.9549845743179322, "training_acc": 52.0, "val_loss": 1.4151994395256042, "val_acc": 48.0}
{"epoch": 11, "training_loss": 1.0340860605239868, "training_acc": 50.0, "val_loss": 0.8889973449707032, "val_acc": 52.0}
{"epoch": 12, "training_loss": 1.795427622795105, "training_acc": 46.0, "val_loss": 2.557561550140381, "val_acc": 48.0}
{"epoch": 13, "training_loss": 1.7409230017662047, "training_acc": 46.0, "val_loss": 0.7878006863594055, "val_acc": 52.0}
{"epoch": 14, "training_loss": 0.9719863271713257, "training_acc": 56.0, "val_loss": 0.759132080078125, "val_acc": 52.0}
{"epoch": 15, "training_loss": 0.8330738997459411, "training_acc": 46.0, "val_loss": 0.8503856039047242, "val_acc": 52.0}
{"epoch": 16, "training_loss": 0.84331374168396, "training_acc": 50.0, "val_loss": 1.7817936611175538, "val_acc": 48.0}
{"epoch": 17, "training_loss": 0.9623195552825927, "training_acc": 50.0, "val_loss": 2.097631950378418, "val_acc": 48.0}
{"epoch": 18, "training_loss": 1.1099319553375244, "training_acc": 54.0, "val_loss": 1.525546636581421, "val_acc": 52.0}
{"epoch": 19, "training_loss": 1.564502353668213, "training_acc": 46.0, "val_loss": 1.3783549499511718, "val_acc": 52.0}
{"epoch": 20, "training_loss": 1.3515343236923218, "training_acc": 54.0, "val_loss": 1.6946006584167481, "val_acc": 48.0}
{"epoch": 21, "training_loss": 1.7091321659088134, "training_acc": 50.0, "val_loss": 0.6971646094322205, "val_acc": 48.0}
{"epoch": 22, "training_loss": 1.5600468063354491, "training_acc": 38.0, "val_loss": 3.7001681327819824, "val_acc": 52.0}
{"epoch": 23, "training_loss": 2.8558719873428347, "training_acc": 42.0, "val_loss": 2.5473874950408937, "val_acc": 48.0}
{"epoch": 24, "training_loss": 2.297809638977051, "training_acc": 52.0, "val_loss": 1.6361014795303346, "val_acc": 48.0}
{"epoch": 25, "training_loss": 1.250499014854431, "training_acc": 50.0, "val_loss": 1.1568770456314086, "val_acc": 52.0}
{"epoch": 26, "training_loss": 0.8342484366893769, "training_acc": 56.0, "val_loss": 2.419261922836304, "val_acc": 48.0}
{"epoch": 27, "training_loss": 1.4212908697128297, "training_acc": 54.0, "val_loss": 1.4957232522964476, "val_acc": 52.0}
{"epoch": 28, "training_loss": 1.0719177627563476, "training_acc": 42.0, "val_loss": 1.300606780052185, "val_acc": 48.0}
{"epoch": 29, "training_loss": 1.4484433937072754, "training_acc": 44.0, "val_loss": 0.8316015577316285, "val_acc": 48.0}
{"epoch": 30, "training_loss": 0.8597192478179931, "training_acc": 58.0, "val_loss": 0.7343831324577331, "val_acc": 52.0}
{"epoch": 31, "training_loss": 0.8053457736968994, "training_acc": 50.0, "val_loss": 0.8902786636352539, "val_acc": 48.0}
{"epoch": 32, "training_loss": 0.9527682161331177, "training_acc": 48.0, "val_loss": 1.654987244606018, "val_acc": 52.0}
{"epoch": 33, "training_loss": 1.0396191263198853, "training_acc": 58.0, "val_loss": 0.7084135150909424, "val_acc": 52.0}
{"epoch": 34, "training_loss": 1.1867231130599976, "training_acc": 50.0, "val_loss": 1.3027078366279603, "val_acc": 52.0}
{"epoch": 35, "training_loss": 1.5688522624969483, "training_acc": 46.0, "val_loss": 0.8060455775260925, "val_acc": 48.0}
{"epoch": 36, "training_loss": 0.7904079294204712, "training_acc": 56.0, "val_loss": 0.7081647205352783, "val_acc": 48.0}
{"epoch": 37, "training_loss": 1.0937880039215089, "training_acc": 52.0, "val_loss": 4.210624504089355, "val_acc": 48.0}
{"epoch": 38, "training_loss": 5.017898197174072, "training_acc": 42.0, "val_loss": 4.42584903717041, "val_acc": 52.0}
{"epoch": 39, "training_loss": 2.643615779876709, "training_acc": 52.0, "val_loss": 2.0072083139419554, "val_acc": 52.0}
{"epoch": 40, "training_loss": 2.110380835533142, "training_acc": 56.0, "val_loss": 2.7929151964187624, "val_acc": 48.0}
