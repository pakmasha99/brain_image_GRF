"main_modify.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 5 --task ADNI_sex --input_option yAware --learning_rate 1e-1 --batch_size 16 --weight_decay 1e-2 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 9.439605202674866, "training_acc": 42.0, "val_loss": 0.7456194424629211, "val_acc": 48.0}
{"epoch": 1, "training_loss": 0.8503620052337646, "training_acc": 52.0, "val_loss": 3.8477627754211428, "val_acc": 52.0}
{"epoch": 2, "training_loss": 5.045434532165527, "training_acc": 52.0, "val_loss": 7.248541259765625, "val_acc": 48.0}
{"epoch": 3, "training_loss": 6.720996103286743, "training_acc": 40.0, "val_loss": 4.365236601829529, "val_acc": 48.0}
{"epoch": 4, "training_loss": 5.504448795318604, "training_acc": 50.0, "val_loss": 7.131423397064209, "val_acc": 52.0}
{"epoch": 5, "training_loss": 4.732726993560791, "training_acc": 54.0, "val_loss": 4.490929832458496, "val_acc": 48.0}
{"epoch": 6, "training_loss": 2.554988422393799, "training_acc": 48.0, "val_loss": 1.5320100641250611, "val_acc": 48.0}
{"epoch": 7, "training_loss": 1.9188833808898926, "training_acc": 48.0, "val_loss": 1.2612028789520264, "val_acc": 52.0}
{"epoch": 8, "training_loss": 1.051461763381958, "training_acc": 50.0, "val_loss": 1.06325829744339, "val_acc": 52.0}
{"epoch": 9, "training_loss": 0.7414071273803711, "training_acc": 52.0, "val_loss": 1.0174279594421387, "val_acc": 48.0}
{"epoch": 10, "training_loss": 1.9039983940124512, "training_acc": 54.0, "val_loss": 3.0079822158813476, "val_acc": 52.0}
{"epoch": 11, "training_loss": 3.440861644744873, "training_acc": 54.0, "val_loss": 0.7204793906211853, "val_acc": 48.0}
{"epoch": 12, "training_loss": 1.3211454105377198, "training_acc": 46.0, "val_loss": 0.9429662942886352, "val_acc": 52.0}
{"epoch": 13, "training_loss": 0.9028306579589844, "training_acc": 50.0, "val_loss": 1.3564819669723511, "val_acc": 52.0}
{"epoch": 14, "training_loss": 1.4183381366729737, "training_acc": 56.0, "val_loss": 0.9093670845031738, "val_acc": 52.0}
{"epoch": 15, "training_loss": 2.3742940473556517, "training_acc": 48.0, "val_loss": 0.6938186073303223, "val_acc": 52.0}
{"epoch": 16, "training_loss": 0.9240463328361511, "training_acc": 48.0, "val_loss": 0.9682370519638062, "val_acc": 52.0}
{"epoch": 17, "training_loss": 0.8765729141235351, "training_acc": 46.0, "val_loss": 1.4344398164749146, "val_acc": 52.0}
{"epoch": 18, "training_loss": 1.2108424878120423, "training_acc": 46.0, "val_loss": 0.7025211381912232, "val_acc": 52.0}
{"epoch": 19, "training_loss": 0.7439243459701538, "training_acc": 56.0, "val_loss": 1.9702324962615967, "val_acc": 48.0}
{"epoch": 20, "training_loss": 2.5125810432434084, "training_acc": 40.0, "val_loss": 1.9849801063537598, "val_acc": 48.0}
{"epoch": 21, "training_loss": 1.7573810958862304, "training_acc": 52.0, "val_loss": 0.69238694190979, "val_acc": 52.0}
{"epoch": 22, "training_loss": 0.7599608182907105, "training_acc": 52.0, "val_loss": 0.7085206437110901, "val_acc": 48.0}
{"epoch": 23, "training_loss": 0.8464179873466492, "training_acc": 50.0, "val_loss": 0.7614562463760376, "val_acc": 48.0}
{"epoch": 24, "training_loss": 1.0800806379318237, "training_acc": 48.0, "val_loss": 1.8169052124023437, "val_acc": 48.0}
{"epoch": 25, "training_loss": 1.2959287023544313, "training_acc": 52.0, "val_loss": 0.835207667350769, "val_acc": 52.0}
{"epoch": 26, "training_loss": 1.0449744606018065, "training_acc": 48.0, "val_loss": 0.7490906929969787, "val_acc": 48.0}
{"epoch": 27, "training_loss": 0.8696457195281982, "training_acc": 52.0, "val_loss": 1.6251756954193115, "val_acc": 52.0}
{"epoch": 28, "training_loss": 1.0233440446853637, "training_acc": 50.0, "val_loss": 0.6949801731109619, "val_acc": 48.0}
{"epoch": 29, "training_loss": 0.9047811126708984, "training_acc": 48.0, "val_loss": 3.9616956329345703, "val_acc": 48.0}
{"epoch": 30, "training_loss": 4.073742828369141, "training_acc": 54.0, "val_loss": 2.7079815578460695, "val_acc": 52.0}
{"epoch": 31, "training_loss": 1.339669065475464, "training_acc": 56.0, "val_loss": 0.8856628394126892, "val_acc": 48.0}
{"epoch": 32, "training_loss": 2.8218706226348877, "training_acc": 50.0, "val_loss": 2.763964853286743, "val_acc": 52.0}
{"epoch": 33, "training_loss": 2.636506962776184, "training_acc": 48.0, "val_loss": 4.445765552520752, "val_acc": 52.0}
{"epoch": 34, "training_loss": 3.107906937599182, "training_acc": 56.0, "val_loss": 5.607101764678955, "val_acc": 52.0}
{"epoch": 35, "training_loss": 6.65029806137085, "training_acc": 36.0, "val_loss": 0.6936754059791564, "val_acc": 52.0}
{"epoch": 36, "training_loss": 2.7675814914703367, "training_acc": 52.0, "val_loss": 2.669785346984863, "val_acc": 52.0}
{"epoch": 37, "training_loss": 1.8178314447402955, "training_acc": 56.0, "val_loss": 0.8222388839721679, "val_acc": 48.0}
{"epoch": 38, "training_loss": 0.9830680370330811, "training_acc": 46.0, "val_loss": 4.215986957550049, "val_acc": 48.0}
{"epoch": 39, "training_loss": 2.463016571998596, "training_acc": 52.0, "val_loss": 0.7284619379043579, "val_acc": 52.0}
{"epoch": 40, "training_loss": 1.2170970153808593, "training_acc": 48.0, "val_loss": 0.7115621209144593, "val_acc": 48.0}
