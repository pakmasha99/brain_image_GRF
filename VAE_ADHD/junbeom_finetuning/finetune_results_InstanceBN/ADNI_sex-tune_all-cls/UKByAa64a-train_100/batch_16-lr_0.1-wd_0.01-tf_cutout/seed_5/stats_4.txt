"main_modify.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 5 --task ADNI_sex --input_option yAware --learning_rate 1e-1 --batch_size 16 --weight_decay 1e-2 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 8.778175947666169, "training_acc": 49.0, "val_loss": 3.801771297454834, "val_acc": 48.0}
{"epoch": 1, "training_loss": 2.694412841796875, "training_acc": 49.0, "val_loss": 2.194228267669678, "val_acc": 48.0}
{"epoch": 2, "training_loss": 2.873447856903076, "training_acc": 49.0, "val_loss": 1.9588064765930175, "val_acc": 52.0}
{"epoch": 3, "training_loss": 1.8902748203277588, "training_acc": 43.0, "val_loss": 1.1967388772964478, "val_acc": 52.0}
{"epoch": 4, "training_loss": 1.524118003845215, "training_acc": 47.0, "val_loss": 2.2136448287963866, "val_acc": 48.0}
{"epoch": 5, "training_loss": 1.4571602439880371, "training_acc": 47.0, "val_loss": 0.9109039783477784, "val_acc": 52.0}
{"epoch": 6, "training_loss": 0.8656406545639038, "training_acc": 59.0, "val_loss": 0.8215254211425781, "val_acc": 48.0}
{"epoch": 7, "training_loss": 1.2434316086769104, "training_acc": 43.0, "val_loss": 1.5768262195587157, "val_acc": 48.0}
{"epoch": 8, "training_loss": 1.5396261882781983, "training_acc": 47.0, "val_loss": 1.569844732284546, "val_acc": 52.0}
{"epoch": 9, "training_loss": 2.154394702911377, "training_acc": 49.0, "val_loss": 0.927780408859253, "val_acc": 48.0}
{"epoch": 10, "training_loss": 2.315015115737915, "training_acc": 53.0, "val_loss": 2.2444921493530274, "val_acc": 48.0}
{"epoch": 11, "training_loss": 3.522847442626953, "training_acc": 53.0, "val_loss": 2.8572947549819947, "val_acc": 52.0}
{"epoch": 12, "training_loss": 2.3615044498443605, "training_acc": 41.0, "val_loss": 2.7121392822265626, "val_acc": 48.0}
{"epoch": 13, "training_loss": 2.3939755725860596, "training_acc": 45.0, "val_loss": 2.0660675716400148, "val_acc": 48.0}
{"epoch": 14, "training_loss": 1.0313209795951843, "training_acc": 59.0, "val_loss": 0.8869646430015564, "val_acc": 52.0}
{"epoch": 15, "training_loss": 0.7517289400100708, "training_acc": 57.0, "val_loss": 1.1736915636062621, "val_acc": 52.0}
{"epoch": 16, "training_loss": 1.7715476417541505, "training_acc": 49.0, "val_loss": 4.591079025268555, "val_acc": 48.0}
{"epoch": 17, "training_loss": 3.9257405090331847, "training_acc": 55.0, "val_loss": 8.84255023956299, "val_acc": 52.0}
{"epoch": 18, "training_loss": 6.384881706237793, "training_acc": 53.0, "val_loss": 7.608136882781983, "val_acc": 48.0}
{"epoch": 19, "training_loss": 5.123911008834839, "training_acc": 51.0, "val_loss": 3.887582359313965, "val_acc": 48.0}
{"epoch": 20, "training_loss": 4.227607493400574, "training_acc": 45.0, "val_loss": 0.6924695992469787, "val_acc": 52.0}
{"epoch": 21, "training_loss": 1.1727205991744996, "training_acc": 43.0, "val_loss": 0.8511046242713928, "val_acc": 48.0}
{"epoch": 22, "training_loss": 0.9051234245300293, "training_acc": 47.0, "val_loss": 0.6990556383132934, "val_acc": 48.0}
{"epoch": 23, "training_loss": 0.9248347544670105, "training_acc": 51.0, "val_loss": 1.582934980392456, "val_acc": 48.0}
{"epoch": 24, "training_loss": 1.1140692615509034, "training_acc": 53.0, "val_loss": 1.0911762094497681, "val_acc": 48.0}
{"epoch": 25, "training_loss": 1.404168701171875, "training_acc": 45.0, "val_loss": 0.8691581058502197, "val_acc": 52.0}
{"epoch": 26, "training_loss": 0.9959884533286094, "training_acc": 57.0, "val_loss": 3.0415655422210692, "val_acc": 48.0}
{"epoch": 27, "training_loss": 1.5179788637161256, "training_acc": 53.0, "val_loss": 1.923150463104248, "val_acc": 52.0}
{"epoch": 28, "training_loss": 1.1135380935668946, "training_acc": 51.0, "val_loss": 0.939779770374298, "val_acc": 52.0}
{"epoch": 29, "training_loss": 0.9023699188232421, "training_acc": 47.0, "val_loss": 0.8266914391517639, "val_acc": 52.0}
{"epoch": 30, "training_loss": 1.3591056060791016, "training_acc": 47.0, "val_loss": 2.3555574512481687, "val_acc": 52.0}
{"epoch": 31, "training_loss": 3.0378937339782714, "training_acc": 45.0, "val_loss": 4.271815776824951, "val_acc": 52.0}
{"epoch": 32, "training_loss": 3.7855290818214415, "training_acc": 47.0, "val_loss": 3.37636700630188, "val_acc": 52.0}
{"epoch": 33, "training_loss": 2.512789835929871, "training_acc": 53.0, "val_loss": 1.241452965736389, "val_acc": 52.0}
{"epoch": 34, "training_loss": 1.030668408870697, "training_acc": 47.0, "val_loss": 1.6296362781524658, "val_acc": 52.0}
{"epoch": 35, "training_loss": 1.0989712762832642, "training_acc": 55.0, "val_loss": 0.8333397293090821, "val_acc": 48.0}
{"epoch": 36, "training_loss": 0.9116959619522095, "training_acc": 51.0, "val_loss": 0.8337992405891419, "val_acc": 48.0}
{"epoch": 37, "training_loss": 1.5309376721829175, "training_acc": 57.0, "val_loss": 5.66716423034668, "val_acc": 48.0}
{"epoch": 38, "training_loss": 3.8050723004341127, "training_acc": 49.0, "val_loss": 3.5506864547729493, "val_acc": 48.0}
{"epoch": 39, "training_loss": 2.9518513441085816, "training_acc": 53.0, "val_loss": 5.4768480205535885, "val_acc": 48.0}
