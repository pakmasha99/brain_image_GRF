"main_modify.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 8 --task ADNI_sex --input_option yAware --learning_rate 1e-1 --batch_size 16 --weight_decay 1e-2 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 10.042563009262086, "training_acc": 50.0, "val_loss": 4.143264789581298, "val_acc": 48.0}
{"epoch": 1, "training_loss": 3.786566667556763, "training_acc": 56.0, "val_loss": 1.5863813161849976, "val_acc": 48.0}
{"epoch": 2, "training_loss": 2.148933277130127, "training_acc": 46.0, "val_loss": 2.8856980752944947, "val_acc": 48.0}
{"epoch": 3, "training_loss": 2.271773593425751, "training_acc": 46.0, "val_loss": 1.5275918388366698, "val_acc": 52.0}
{"epoch": 4, "training_loss": 1.3346751356124877, "training_acc": 58.0, "val_loss": 2.959470062255859, "val_acc": 52.0}
{"epoch": 5, "training_loss": 2.6068678760528563, "training_acc": 54.0, "val_loss": 5.027573738098145, "val_acc": 52.0}
{"epoch": 6, "training_loss": 4.203420522212983, "training_acc": 46.0, "val_loss": 3.41044771194458, "val_acc": 52.0}
{"epoch": 7, "training_loss": 3.662705774307251, "training_acc": 58.0, "val_loss": 7.371522254943848, "val_acc": 48.0}
{"epoch": 8, "training_loss": 6.188186798095703, "training_acc": 46.0, "val_loss": 0.772231957912445, "val_acc": 52.0}
{"epoch": 9, "training_loss": 5.420782546997071, "training_acc": 50.0, "val_loss": 5.177657642364502, "val_acc": 52.0}
{"epoch": 10, "training_loss": 4.3564738225936885, "training_acc": 40.0, "val_loss": 2.5488542461395265, "val_acc": 52.0}
{"epoch": 11, "training_loss": 2.0638433504104614, "training_acc": 54.0, "val_loss": 0.6977737140655518, "val_acc": 48.0}
{"epoch": 12, "training_loss": 0.7351542162895203, "training_acc": 50.0, "val_loss": 1.3734135007858277, "val_acc": 48.0}
{"epoch": 13, "training_loss": 0.9625176668167115, "training_acc": 52.0, "val_loss": 0.8544364905357361, "val_acc": 48.0}
{"epoch": 14, "training_loss": 0.7412266993522644, "training_acc": 52.0, "val_loss": 0.7027394247055053, "val_acc": 52.0}
{"epoch": 15, "training_loss": 1.0711204767227174, "training_acc": 48.0, "val_loss": 0.7583466386795044, "val_acc": 48.0}
{"epoch": 16, "training_loss": 1.0616040706634522, "training_acc": 46.0, "val_loss": 1.6388830757141113, "val_acc": 48.0}
{"epoch": 17, "training_loss": 1.6109378480911254, "training_acc": 46.0, "val_loss": 0.7770936942100525, "val_acc": 52.0}
{"epoch": 18, "training_loss": 0.866773362159729, "training_acc": 50.0, "val_loss": 0.8199283862113953, "val_acc": 48.0}
{"epoch": 19, "training_loss": 1.2338632774353027, "training_acc": 54.0, "val_loss": 0.8828001356124878, "val_acc": 48.0}
{"epoch": 20, "training_loss": 1.159670991897583, "training_acc": 52.0, "val_loss": 3.7616085243225097, "val_acc": 48.0}
{"epoch": 21, "training_loss": 3.4005427723564208, "training_acc": 58.0, "val_loss": 0.781802453994751, "val_acc": 52.0}
{"epoch": 22, "training_loss": 1.9241717290878295, "training_acc": 54.0, "val_loss": 0.7374053955078125, "val_acc": 48.0}
{"epoch": 23, "training_loss": 0.9558154129981995, "training_acc": 50.0, "val_loss": 1.2140980648994446, "val_acc": 52.0}
{"epoch": 24, "training_loss": 1.5324688673019409, "training_acc": 48.0, "val_loss": 2.5843568229675293, "val_acc": 48.0}
{"epoch": 25, "training_loss": 1.537774815559387, "training_acc": 50.0, "val_loss": 0.7820344543457032, "val_acc": 48.0}
{"epoch": 26, "training_loss": 1.6831737518310548, "training_acc": 52.0, "val_loss": 0.6925155377388, "val_acc": 52.0}
{"epoch": 27, "training_loss": 2.2548878383636475, "training_acc": 48.0, "val_loss": 3.402506504058838, "val_acc": 52.0}
{"epoch": 28, "training_loss": 3.4265836477279663, "training_acc": 44.0, "val_loss": 1.438753137588501, "val_acc": 52.0}
{"epoch": 29, "training_loss": 1.0404074451327323, "training_acc": 56.0, "val_loss": 3.8959406280517577, "val_acc": 48.0}
{"epoch": 30, "training_loss": 3.7250012493133546, "training_acc": 50.0, "val_loss": 3.7992913818359373, "val_acc": 48.0}
{"epoch": 31, "training_loss": 5.983269844055176, "training_acc": 44.0, "val_loss": 6.499867935180664, "val_acc": 52.0}
{"epoch": 32, "training_loss": 5.633500723838806, "training_acc": 52.0, "val_loss": 3.096820821762085, "val_acc": 52.0}
{"epoch": 33, "training_loss": 3.996897358894348, "training_acc": 46.0, "val_loss": 1.4279738521575929, "val_acc": 48.0}
{"epoch": 34, "training_loss": 2.192383146286011, "training_acc": 50.0, "val_loss": 1.0853723859786988, "val_acc": 52.0}
{"epoch": 35, "training_loss": 0.8387708711624146, "training_acc": 54.0, "val_loss": 1.1337787914276123, "val_acc": 48.0}
{"epoch": 36, "training_loss": 0.9623444700241088, "training_acc": 58.0, "val_loss": 0.9835291695594788, "val_acc": 48.0}
{"epoch": 37, "training_loss": 1.500312089920044, "training_acc": 44.0, "val_loss": 2.770055170059204, "val_acc": 52.0}
{"epoch": 38, "training_loss": 1.1979590344429016, "training_acc": 50.0, "val_loss": 0.7012735390663147, "val_acc": 48.0}
{"epoch": 39, "training_loss": 0.7419011878967285, "training_acc": 60.0, "val_loss": 1.2450108814239502, "val_acc": 52.0}
{"epoch": 40, "training_loss": 1.7805069637298585, "training_acc": 46.0, "val_loss": 3.072152462005615, "val_acc": 52.0}
{"epoch": 41, "training_loss": 3.0359563636779785, "training_acc": 48.0, "val_loss": 2.3831234550476075, "val_acc": 52.0}
{"epoch": 42, "training_loss": 1.354139289855957, "training_acc": 46.0, "val_loss": 2.207771854400635, "val_acc": 52.0}
{"epoch": 43, "training_loss": 1.2256833481788636, "training_acc": 52.0, "val_loss": 1.8012406253814697, "val_acc": 48.0}
{"epoch": 44, "training_loss": 1.1186900394782424, "training_acc": 56.0, "val_loss": 4.896065521240234, "val_acc": 52.0}
{"epoch": 45, "training_loss": 3.912999119758606, "training_acc": 48.0, "val_loss": 1.8463875579833984, "val_acc": 52.0}
