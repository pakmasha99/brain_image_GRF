"main_modify.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ADNI_sex --input_option yAware --learning_rate 1e-1 --batch_size 16 --weight_decay 1e-2 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 10.212237730026246, "training_acc": 55.0, "val_loss": 2.620286407470703, "val_acc": 48.0}
{"epoch": 1, "training_loss": 4.9546002006530765, "training_acc": 51.0, "val_loss": 0.7287561535835266, "val_acc": 48.0}
{"epoch": 2, "training_loss": 1.8031094551086426, "training_acc": 47.0, "val_loss": 2.5054757690429685, "val_acc": 52.0}
{"epoch": 3, "training_loss": 1.5358114099502564, "training_acc": 47.0, "val_loss": 2.1778800678253174, "val_acc": 48.0}
{"epoch": 4, "training_loss": 1.555645980834961, "training_acc": 53.0, "val_loss": 2.238757448196411, "val_acc": 52.0}
{"epoch": 5, "training_loss": 1.8829157781600951, "training_acc": 43.0, "val_loss": 1.3390414714813232, "val_acc": 48.0}
{"epoch": 6, "training_loss": 1.0851609086990357, "training_acc": 45.0, "val_loss": 0.8329236888885498, "val_acc": 48.0}
{"epoch": 7, "training_loss": 0.8216734266281128, "training_acc": 47.0, "val_loss": 0.792762484550476, "val_acc": 52.0}
{"epoch": 8, "training_loss": 0.9355456638336181, "training_acc": 53.0, "val_loss": 1.1966228532791137, "val_acc": 52.0}
{"epoch": 9, "training_loss": 1.3214629733562469, "training_acc": 47.0, "val_loss": 3.5420313453674317, "val_acc": 48.0}
{"epoch": 10, "training_loss": 2.084349627494812, "training_acc": 55.0, "val_loss": 1.5254788970947266, "val_acc": 48.0}
{"epoch": 11, "training_loss": 1.2233991098403931, "training_acc": 51.0, "val_loss": 0.7077377772331238, "val_acc": 48.0}
{"epoch": 12, "training_loss": 1.3293091869354248, "training_acc": 43.0, "val_loss": 3.134410705566406, "val_acc": 48.0}
{"epoch": 13, "training_loss": 2.825105333328247, "training_acc": 49.0, "val_loss": 1.6707335758209227, "val_acc": 48.0}
{"epoch": 14, "training_loss": 0.9005884337425232, "training_acc": 49.0, "val_loss": 0.895098648071289, "val_acc": 48.0}
{"epoch": 15, "training_loss": 0.8477290350198746, "training_acc": 47.0, "val_loss": 2.5515356969833376, "val_acc": 52.0}
{"epoch": 16, "training_loss": 1.898086633682251, "training_acc": 49.0, "val_loss": 3.4755414295196534, "val_acc": 48.0}
{"epoch": 17, "training_loss": 2.495746579170227, "training_acc": 51.0, "val_loss": 2.449517240524292, "val_acc": 48.0}
{"epoch": 18, "training_loss": 1.6510798692703248, "training_acc": 45.0, "val_loss": 1.32363826751709, "val_acc": 48.0}
{"epoch": 19, "training_loss": 1.960102777481079, "training_acc": 47.0, "val_loss": 0.9057621049880982, "val_acc": 52.0}
{"epoch": 20, "training_loss": 1.97406231880188, "training_acc": 45.0, "val_loss": 1.8793963813781738, "val_acc": 52.0}
{"epoch": 21, "training_loss": 1.892975640296936, "training_acc": 51.0, "val_loss": 0.9509589505195618, "val_acc": 48.0}
{"epoch": 22, "training_loss": 1.5052263075113297, "training_acc": 55.0, "val_loss": 0.6930221104621888, "val_acc": 52.0}
{"epoch": 23, "training_loss": 1.401441695690155, "training_acc": 47.0, "val_loss": 0.7592904210090637, "val_acc": 52.0}
{"epoch": 24, "training_loss": 0.7338670444488525, "training_acc": 49.0, "val_loss": 1.3938156914711, "val_acc": 48.0}
{"epoch": 25, "training_loss": 1.643626766204834, "training_acc": 45.0, "val_loss": 0.7394372868537903, "val_acc": 52.0}
{"epoch": 26, "training_loss": 1.9250893115997314, "training_acc": 43.0, "val_loss": 3.0419539260864257, "val_acc": 48.0}
{"epoch": 27, "training_loss": 2.4196941375732424, "training_acc": 47.0, "val_loss": 2.7957351398468018, "val_acc": 52.0}
{"epoch": 28, "training_loss": 3.119910550117493, "training_acc": 47.0, "val_loss": 1.8323194217681884, "val_acc": 52.0}
{"epoch": 29, "training_loss": 1.0592990803718567, "training_acc": 49.0, "val_loss": 2.812653617858887, "val_acc": 52.0}
{"epoch": 30, "training_loss": 1.7172354555130005, "training_acc": 39.0, "val_loss": 1.465226593017578, "val_acc": 52.0}
{"epoch": 31, "training_loss": 0.9839886444807052, "training_acc": 49.0, "val_loss": 2.5683945846557616, "val_acc": 52.0}
{"epoch": 32, "training_loss": 1.507144947052002, "training_acc": 47.0, "val_loss": 0.7034275078773499, "val_acc": 52.0}
{"epoch": 33, "training_loss": 0.8746322536468506, "training_acc": 51.0, "val_loss": 0.7191828346252441, "val_acc": 48.0}
{"epoch": 34, "training_loss": 1.7672625637054444, "training_acc": 41.0, "val_loss": 0.7710823273658752, "val_acc": 48.0}
{"epoch": 35, "training_loss": 1.7920072889328003, "training_acc": 49.0, "val_loss": 0.7102007627487182, "val_acc": 48.0}
{"epoch": 36, "training_loss": 1.1538453006744385, "training_acc": 55.0, "val_loss": 1.0192168378829956, "val_acc": 52.0}
{"epoch": 37, "training_loss": 1.031642713546753, "training_acc": 55.0, "val_loss": 2.4028584575653076, "val_acc": 48.0}
{"epoch": 38, "training_loss": 1.6175120568275452, "training_acc": 49.0, "val_loss": 1.7544150257110596, "val_acc": 48.0}
{"epoch": 39, "training_loss": 1.5638976716995239, "training_acc": 49.0, "val_loss": 0.7092299318313598, "val_acc": 52.0}
{"epoch": 40, "training_loss": 0.9229984569549561, "training_acc": 55.0, "val_loss": 1.852159469127655, "val_acc": 52.0}
{"epoch": 41, "training_loss": 2.3788449001312255, "training_acc": 45.0, "val_loss": 1.0170685052871704, "val_acc": 48.0}
