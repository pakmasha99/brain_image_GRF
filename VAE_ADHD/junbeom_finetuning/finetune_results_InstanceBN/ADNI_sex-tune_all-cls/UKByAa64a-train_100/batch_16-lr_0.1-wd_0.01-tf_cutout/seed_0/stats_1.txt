"main_modify.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ADNI_sex --input_option yAware --learning_rate 1e-1 --batch_size 16 --weight_decay 1e-2 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 9.356667556762694, "training_acc": 53.0, "val_loss": 2.9929893732070925, "val_acc": 48.0}
{"epoch": 1, "training_loss": 6.803910160064698, "training_acc": 49.0, "val_loss": 8.138070049285888, "val_acc": 52.0}
{"epoch": 2, "training_loss": 5.720576944351197, "training_acc": 53.0, "val_loss": 1.5555069971084594, "val_acc": 52.0}
{"epoch": 3, "training_loss": 2.1299421882629392, "training_acc": 47.0, "val_loss": 0.840294804573059, "val_acc": 52.0}
{"epoch": 4, "training_loss": 0.9460598063468934, "training_acc": 49.0, "val_loss": 2.6638878631591796, "val_acc": 48.0}
{"epoch": 5, "training_loss": 2.2322439122200013, "training_acc": 57.0, "val_loss": 0.8689246940612793, "val_acc": 48.0}
{"epoch": 6, "training_loss": 1.2369822216033937, "training_acc": 57.0, "val_loss": 2.833989381790161, "val_acc": 48.0}
{"epoch": 7, "training_loss": 2.0516521644592287, "training_acc": 45.0, "val_loss": 2.9884339714050294, "val_acc": 48.0}
{"epoch": 8, "training_loss": 1.8019644689559937, "training_acc": 57.0, "val_loss": 3.288308334350586, "val_acc": 48.0}
{"epoch": 9, "training_loss": 2.828133544921875, "training_acc": 51.0, "val_loss": 1.1085748147964478, "val_acc": 48.0}
{"epoch": 10, "training_loss": 3.600807991027832, "training_acc": 45.0, "val_loss": 4.303617515563965, "val_acc": 48.0}
{"epoch": 11, "training_loss": 3.091596050262451, "training_acc": 47.0, "val_loss": 6.882963943481445, "val_acc": 48.0}
{"epoch": 12, "training_loss": 4.870453281402588, "training_acc": 49.0, "val_loss": 2.371340446472168, "val_acc": 52.0}
{"epoch": 13, "training_loss": 3.9622829246520994, "training_acc": 39.0, "val_loss": 3.244648103713989, "val_acc": 52.0}
{"epoch": 14, "training_loss": 2.746119728088379, "training_acc": 47.0, "val_loss": 2.887751245498657, "val_acc": 52.0}
{"epoch": 15, "training_loss": 2.8018432807922364, "training_acc": 47.0, "val_loss": 1.2389039182662964, "val_acc": 52.0}
{"epoch": 16, "training_loss": 1.3270939803123474, "training_acc": 55.0, "val_loss": 2.3943418788909914, "val_acc": 48.0}
{"epoch": 17, "training_loss": 0.9743058633804321, "training_acc": 57.0, "val_loss": 1.0474742078781127, "val_acc": 52.0}
{"epoch": 18, "training_loss": 0.8496060848236084, "training_acc": 53.0, "val_loss": 2.682346773147583, "val_acc": 48.0}
{"epoch": 19, "training_loss": 3.2329640007019043, "training_acc": 53.0, "val_loss": 3.1702609062194824, "val_acc": 52.0}
{"epoch": 20, "training_loss": 1.677527003288269, "training_acc": 49.0, "val_loss": 1.6687526559829713, "val_acc": 48.0}
{"epoch": 21, "training_loss": 0.9789726758003234, "training_acc": 51.0, "val_loss": 0.7065580034255982, "val_acc": 48.0}
{"epoch": 22, "training_loss": 1.1912343335151672, "training_acc": 49.0, "val_loss": 1.5433154439926147, "val_acc": 48.0}
{"epoch": 23, "training_loss": 1.1076602554321289, "training_acc": 51.0, "val_loss": 0.8996957325935364, "val_acc": 48.0}
{"epoch": 24, "training_loss": 1.2605101919174195, "training_acc": 37.0, "val_loss": 0.7719928741455078, "val_acc": 52.0}
{"epoch": 25, "training_loss": 0.8748966240882874, "training_acc": 55.0, "val_loss": 0.7574213838577271, "val_acc": 48.0}
{"epoch": 26, "training_loss": 1.0059849333763122, "training_acc": 39.0, "val_loss": 1.3229948329925536, "val_acc": 52.0}
{"epoch": 27, "training_loss": 0.9857619285583497, "training_acc": 51.0, "val_loss": 1.560831708908081, "val_acc": 52.0}
{"epoch": 28, "training_loss": 1.0994422769546508, "training_acc": 45.0, "val_loss": 0.9617024183273315, "val_acc": 52.0}
{"epoch": 29, "training_loss": 0.849581332206726, "training_acc": 53.0, "val_loss": 0.7604226708412171, "val_acc": 48.0}
{"epoch": 30, "training_loss": 1.4546414375305177, "training_acc": 39.0, "val_loss": 1.3594114780426025, "val_acc": 52.0}
{"epoch": 31, "training_loss": 1.0153792691230774, "training_acc": 49.0, "val_loss": 0.9435201382637024, "val_acc": 52.0}
{"epoch": 32, "training_loss": 1.0259858560562134, "training_acc": 53.0, "val_loss": 1.0957862401008607, "val_acc": 52.0}
{"epoch": 33, "training_loss": 0.8774419689178466, "training_acc": 57.0, "val_loss": 3.280903835296631, "val_acc": 48.0}
{"epoch": 34, "training_loss": 1.857808141708374, "training_acc": 47.0, "val_loss": 1.213352961540222, "val_acc": 52.0}
{"epoch": 35, "training_loss": 1.3617760372161865, "training_acc": 49.0, "val_loss": 1.2082850050926208, "val_acc": 52.0}
{"epoch": 36, "training_loss": 1.2607536125183105, "training_acc": 45.0, "val_loss": 1.5621779108047484, "val_acc": 52.0}
{"epoch": 37, "training_loss": 1.4426576852798463, "training_acc": 45.0, "val_loss": 4.735338535308838, "val_acc": 48.0}
{"epoch": 38, "training_loss": 3.3016414403915406, "training_acc": 57.0, "val_loss": 3.660113925933838, "val_acc": 48.0}
{"epoch": 39, "training_loss": 2.524216594696045, "training_acc": 47.0, "val_loss": 0.7488379287719726, "val_acc": 48.0}
{"epoch": 40, "training_loss": 1.4871416435390712, "training_acc": 47.0, "val_loss": 5.51587589263916, "val_acc": 52.0}
