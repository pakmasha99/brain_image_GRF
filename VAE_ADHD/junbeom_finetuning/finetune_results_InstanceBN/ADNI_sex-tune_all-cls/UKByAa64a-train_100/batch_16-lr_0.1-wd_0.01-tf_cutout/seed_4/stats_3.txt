"main_modify.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 4 --task ADNI_sex --input_option yAware --learning_rate 1e-1 --batch_size 16 --weight_decay 1e-2 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 8.973536710739136, "training_acc": 48.0, "val_loss": 7.659905872344971, "val_acc": 52.0}
{"epoch": 1, "training_loss": 7.162806282043457, "training_acc": 42.0, "val_loss": 2.0217788887023924, "val_acc": 52.0}
{"epoch": 2, "training_loss": 4.103590202331543, "training_acc": 50.0, "val_loss": 1.288253779411316, "val_acc": 48.0}
{"epoch": 3, "training_loss": 2.237625018209219, "training_acc": 56.0, "val_loss": 5.665507831573486, "val_acc": 48.0}
{"epoch": 4, "training_loss": 3.9391744804382323, "training_acc": 48.0, "val_loss": 2.782010040283203, "val_acc": 48.0}
{"epoch": 5, "training_loss": 2.4800563621520997, "training_acc": 58.0, "val_loss": 1.598815279006958, "val_acc": 52.0}
{"epoch": 6, "training_loss": 1.7755569267272948, "training_acc": 50.0, "val_loss": 0.7217797780036926, "val_acc": 52.0}
{"epoch": 7, "training_loss": 0.8543174839019776, "training_acc": 54.0, "val_loss": 0.7058423614501953, "val_acc": 48.0}
{"epoch": 8, "training_loss": 1.0044056129455567, "training_acc": 46.0, "val_loss": 0.7600935721397399, "val_acc": 48.0}
{"epoch": 9, "training_loss": 0.9460098266601562, "training_acc": 52.0, "val_loss": 2.947342567443848, "val_acc": 48.0}
{"epoch": 10, "training_loss": 1.60037446975708, "training_acc": 52.0, "val_loss": 1.0601464009284973, "val_acc": 52.0}
{"epoch": 11, "training_loss": 0.8963474750518798, "training_acc": 46.0, "val_loss": 1.6405935239791871, "val_acc": 52.0}
{"epoch": 12, "training_loss": 0.9952972888946533, "training_acc": 52.0, "val_loss": 2.053636140823364, "val_acc": 52.0}
{"epoch": 13, "training_loss": 1.5626696681976318, "training_acc": 56.0, "val_loss": 0.8150959134101867, "val_acc": 52.0}
{"epoch": 14, "training_loss": 1.794076805114746, "training_acc": 46.0, "val_loss": 1.0054068279266357, "val_acc": 52.0}
{"epoch": 15, "training_loss": 1.5181634140014648, "training_acc": 54.0, "val_loss": 2.937012052536011, "val_acc": 52.0}
{"epoch": 16, "training_loss": 4.124140272140503, "training_acc": 46.0, "val_loss": 8.735767936706543, "val_acc": 52.0}
{"epoch": 17, "training_loss": 7.219671268463134, "training_acc": 44.0, "val_loss": 1.447812328338623, "val_acc": 48.0}
{"epoch": 18, "training_loss": 2.739337637424469, "training_acc": 44.0, "val_loss": 1.7027603244781495, "val_acc": 52.0}
{"epoch": 19, "training_loss": 1.2490188550949097, "training_acc": 42.0, "val_loss": 1.3125863671302795, "val_acc": 52.0}
{"epoch": 20, "training_loss": 1.030624451637268, "training_acc": 46.0, "val_loss": 0.7295055866241456, "val_acc": 52.0}
{"epoch": 21, "training_loss": 1.0478278303146362, "training_acc": 46.0, "val_loss": 3.586987314224243, "val_acc": 48.0}
{"epoch": 22, "training_loss": 1.5262388324737548, "training_acc": 54.0, "val_loss": 0.8469077181816101, "val_acc": 52.0}
{"epoch": 23, "training_loss": 0.8233859729766846, "training_acc": 50.0, "val_loss": 0.6958141875267029, "val_acc": 52.0}
{"epoch": 24, "training_loss": 0.9298543548583984, "training_acc": 46.0, "val_loss": 1.1387766122817993, "val_acc": 52.0}
{"epoch": 25, "training_loss": 0.9143976521492004, "training_acc": 52.0, "val_loss": 1.5278580045700074, "val_acc": 52.0}
{"epoch": 26, "training_loss": 1.5803677368164062, "training_acc": 40.0, "val_loss": 2.2183435440063475, "val_acc": 52.0}
{"epoch": 27, "training_loss": 2.1266739797592162, "training_acc": 44.0, "val_loss": 0.7121661019325256, "val_acc": 52.0}
{"epoch": 28, "training_loss": 1.1873126482963563, "training_acc": 46.0, "val_loss": 1.5466692924499512, "val_acc": 52.0}
{"epoch": 29, "training_loss": 1.4897770404815673, "training_acc": 44.0, "val_loss": 0.9551680731773377, "val_acc": 52.0}
{"epoch": 30, "training_loss": 1.2869193363189697, "training_acc": 54.0, "val_loss": 2.530464057922363, "val_acc": 48.0}
{"epoch": 31, "training_loss": 1.497239155769348, "training_acc": 52.0, "val_loss": 0.7085443902015686, "val_acc": 48.0}
{"epoch": 32, "training_loss": 0.8568443059921265, "training_acc": 52.0, "val_loss": 1.018102867603302, "val_acc": 52.0}
{"epoch": 33, "training_loss": 1.0439010047912598, "training_acc": 50.0, "val_loss": 2.688543634414673, "val_acc": 48.0}
{"epoch": 34, "training_loss": 3.4494374275207518, "training_acc": 48.0, "val_loss": 5.912792415618896, "val_acc": 48.0}
{"epoch": 35, "training_loss": 4.40190848827362, "training_acc": 50.0, "val_loss": 4.57837947845459, "val_acc": 48.0}
{"epoch": 36, "training_loss": 3.5089910888671874, "training_acc": 48.0, "val_loss": 4.864750080108642, "val_acc": 48.0}
{"epoch": 37, "training_loss": 4.347365379333496, "training_acc": 50.0, "val_loss": 1.1434458112716674, "val_acc": 52.0}
{"epoch": 38, "training_loss": 4.229879903793335, "training_acc": 52.0, "val_loss": 7.796172199249267, "val_acc": 52.0}
{"epoch": 39, "training_loss": 5.019274215698243, "training_acc": 40.0, "val_loss": 0.8311904382705688, "val_acc": 52.0}
{"epoch": 40, "training_loss": 1.5105621576309205, "training_acc": 44.0, "val_loss": 0.7951106190681457, "val_acc": 48.0}
{"epoch": 41, "training_loss": 1.0342261648178102, "training_acc": 44.0, "val_loss": 1.002569146156311, "val_acc": 52.0}
{"epoch": 42, "training_loss": 1.2994214582443238, "training_acc": 48.0, "val_loss": 0.6993768692016602, "val_acc": 52.0}
