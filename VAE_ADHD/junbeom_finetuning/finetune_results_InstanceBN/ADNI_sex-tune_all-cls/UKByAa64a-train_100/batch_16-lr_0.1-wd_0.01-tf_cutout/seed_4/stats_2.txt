"main_modify.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 4 --task ADNI_sex --input_option yAware --learning_rate 1e-1 --batch_size 16 --weight_decay 1e-2 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 9.542979354858398, "training_acc": 54.0, "val_loss": 2.2288689041137695, "val_acc": 48.0}
{"epoch": 1, "training_loss": 2.702210578918457, "training_acc": 48.0, "val_loss": 0.7137938261032104, "val_acc": 48.0}
{"epoch": 2, "training_loss": 1.0752865600585937, "training_acc": 50.0, "val_loss": 1.1687871026992798, "val_acc": 48.0}
{"epoch": 3, "training_loss": 1.6467175006866455, "training_acc": 48.0, "val_loss": 1.407976360321045, "val_acc": 48.0}
{"epoch": 4, "training_loss": 1.6423230743408204, "training_acc": 44.0, "val_loss": 1.8639204025268554, "val_acc": 52.0}
{"epoch": 5, "training_loss": 1.3681781911849975, "training_acc": 42.0, "val_loss": 1.4223771905899047, "val_acc": 52.0}
{"epoch": 6, "training_loss": 1.9083800888061524, "training_acc": 46.0, "val_loss": 3.237147455215454, "val_acc": 48.0}
{"epoch": 7, "training_loss": 3.3376164340972903, "training_acc": 38.0, "val_loss": 4.746369667053223, "val_acc": 48.0}
{"epoch": 8, "training_loss": 3.1515730571746827, "training_acc": 50.0, "val_loss": 4.663537540435791, "val_acc": 48.0}
{"epoch": 9, "training_loss": 5.354990711212158, "training_acc": 44.0, "val_loss": 4.583339338302612, "val_acc": 52.0}
{"epoch": 10, "training_loss": 2.8262448692321778, "training_acc": 54.0, "val_loss": 2.140416717529297, "val_acc": 48.0}
{"epoch": 11, "training_loss": 1.8306395053863525, "training_acc": 42.0, "val_loss": 3.690094623565674, "val_acc": 52.0}
{"epoch": 12, "training_loss": 4.611923332214356, "training_acc": 44.0, "val_loss": 1.5259449362754822, "val_acc": 48.0}
{"epoch": 13, "training_loss": 2.1379587554931643, "training_acc": 58.0, "val_loss": 1.8729501581192016, "val_acc": 48.0}
{"epoch": 14, "training_loss": 1.6071202659606934, "training_acc": 48.0, "val_loss": 2.1034202718734742, "val_acc": 52.0}
{"epoch": 15, "training_loss": 1.275272274017334, "training_acc": 54.0, "val_loss": 1.7917480897903442, "val_acc": 48.0}
{"epoch": 16, "training_loss": 1.2543811321258544, "training_acc": 42.0, "val_loss": 0.6990806198120117, "val_acc": 48.0}
{"epoch": 17, "training_loss": 0.8457345342636109, "training_acc": 52.0, "val_loss": 0.9259827780723572, "val_acc": 48.0}
{"epoch": 18, "training_loss": 1.2875147581100463, "training_acc": 44.0, "val_loss": 1.0224644541740417, "val_acc": 48.0}
{"epoch": 19, "training_loss": 1.2198164033889771, "training_acc": 56.0, "val_loss": 1.959596095085144, "val_acc": 48.0}
{"epoch": 20, "training_loss": 1.9504621315002442, "training_acc": 38.0, "val_loss": 1.7051760816574097, "val_acc": 48.0}
{"epoch": 21, "training_loss": 1.2142068529129029, "training_acc": 52.0, "val_loss": 2.5066357851028442, "val_acc": 52.0}
{"epoch": 22, "training_loss": 2.891643738746643, "training_acc": 48.0, "val_loss": 3.449358510971069, "val_acc": 52.0}
{"epoch": 23, "training_loss": 2.937621726989746, "training_acc": 58.0, "val_loss": 3.355650339126587, "val_acc": 48.0}
{"epoch": 24, "training_loss": 2.6995929718017577, "training_acc": 44.0, "val_loss": 0.9212956714630127, "val_acc": 52.0}
{"epoch": 25, "training_loss": 1.189412899017334, "training_acc": 50.0, "val_loss": 1.2528781032562255, "val_acc": 48.0}
{"epoch": 26, "training_loss": 1.4160714340209961, "training_acc": 48.0, "val_loss": 0.6960823392868042, "val_acc": 48.0}
{"epoch": 27, "training_loss": 0.948538761138916, "training_acc": 52.0, "val_loss": 0.8710888576507568, "val_acc": 48.0}
{"epoch": 28, "training_loss": 0.975940752029419, "training_acc": 40.0, "val_loss": 1.984645004272461, "val_acc": 48.0}
{"epoch": 29, "training_loss": 1.656589093208313, "training_acc": 46.0, "val_loss": 2.895241069793701, "val_acc": 52.0}
{"epoch": 30, "training_loss": 4.831973552703857, "training_acc": 36.0, "val_loss": 4.79456639289856, "val_acc": 52.0}
{"epoch": 31, "training_loss": 6.799703216552734, "training_acc": 48.0, "val_loss": 8.543891067504882, "val_acc": 48.0}
{"epoch": 32, "training_loss": 6.01136848449707, "training_acc": 48.0, "val_loss": 4.099817867279053, "val_acc": 52.0}
{"epoch": 33, "training_loss": 2.552616662979126, "training_acc": 58.0, "val_loss": 2.594157090187073, "val_acc": 52.0}
{"epoch": 34, "training_loss": 1.8959925842285157, "training_acc": 44.0, "val_loss": 1.0919558000564575, "val_acc": 48.0}
{"epoch": 35, "training_loss": 1.4493296337127686, "training_acc": 50.0, "val_loss": 0.7731466746330261, "val_acc": 48.0}
{"epoch": 36, "training_loss": 1.1930990839004516, "training_acc": 46.0, "val_loss": 0.7151909923553467, "val_acc": 52.0}
{"epoch": 37, "training_loss": 0.804032301902771, "training_acc": 52.0, "val_loss": 2.6803952980041506, "val_acc": 48.0}
{"epoch": 38, "training_loss": 1.1997715245233849, "training_acc": 54.0, "val_loss": 6.82068754196167, "val_acc": 52.0}
{"epoch": 39, "training_loss": 4.317934789657593, "training_acc": 46.0, "val_loss": 1.106341643333435, "val_acc": 52.0}
{"epoch": 40, "training_loss": 1.0132583698630333, "training_acc": 50.0, "val_loss": 3.665826778411865, "val_acc": 48.0}
{"epoch": 41, "training_loss": 1.6690517711639403, "training_acc": 46.0, "val_loss": 0.9680664014816284, "val_acc": 52.0}
{"epoch": 42, "training_loss": 1.0363735771179199, "training_acc": 48.0, "val_loss": 0.7258981466293335, "val_acc": 48.0}
{"epoch": 43, "training_loss": 1.2415149974822999, "training_acc": 46.0, "val_loss": 0.7055096507072449, "val_acc": 48.0}
{"epoch": 44, "training_loss": 1.1648778629302978, "training_acc": 52.0, "val_loss": 1.0115536618232728, "val_acc": 52.0}
{"epoch": 45, "training_loss": 1.141678776741028, "training_acc": 48.0, "val_loss": 0.9065707397460937, "val_acc": 48.0}
{"epoch": 46, "training_loss": 1.133899610042572, "training_acc": 48.0, "val_loss": 0.6944431114196777, "val_acc": 48.0}
{"epoch": 47, "training_loss": 1.5600457096099853, "training_acc": 44.0, "val_loss": 0.9016851329803467, "val_acc": 52.0}
{"epoch": 48, "training_loss": 0.9888334226608276, "training_acc": 44.0, "val_loss": 1.822919626235962, "val_acc": 52.0}
{"epoch": 49, "training_loss": 1.533561954498291, "training_acc": 58.0, "val_loss": 0.7110561084747314, "val_acc": 52.0}
{"epoch": 50, "training_loss": 1.5150393676757812, "training_acc": 40.0, "val_loss": 1.9250158309936523, "val_acc": 52.0}
{"epoch": 51, "training_loss": 1.5338118886947631, "training_acc": 52.0, "val_loss": 0.7687435150146484, "val_acc": 48.0}
{"epoch": 52, "training_loss": 1.05399906873703, "training_acc": 48.0, "val_loss": 1.355058765411377, "val_acc": 52.0}
{"epoch": 53, "training_loss": 1.137242658138275, "training_acc": 64.0, "val_loss": 1.6272238826751708, "val_acc": 52.0}
{"epoch": 54, "training_loss": 1.8769941520690918, "training_acc": 46.0, "val_loss": 1.4637152338027954, "val_acc": 48.0}
{"epoch": 55, "training_loss": 1.6988715839385986, "training_acc": 56.0, "val_loss": 1.23786301612854, "val_acc": 48.0}
{"epoch": 56, "training_loss": 1.1507984542846679, "training_acc": 52.0, "val_loss": 1.0138924646377563, "val_acc": 52.0}
{"epoch": 57, "training_loss": 0.742396068572998, "training_acc": 52.0, "val_loss": 2.599894208908081, "val_acc": 48.0}
{"epoch": 58, "training_loss": 2.8655635690689087, "training_acc": 46.0, "val_loss": 2.5472296619415284, "val_acc": 48.0}
{"epoch": 59, "training_loss": 1.6065480899810791, "training_acc": 56.0, "val_loss": 0.9200593566894532, "val_acc": 52.0}
{"epoch": 60, "training_loss": 1.1273495197296142, "training_acc": 46.0, "val_loss": 2.1220286464691163, "val_acc": 52.0}
{"epoch": 61, "training_loss": 1.410759654045105, "training_acc": 48.0, "val_loss": 1.5632154750823974, "val_acc": 48.0}
{"epoch": 62, "training_loss": 0.9588339948654174, "training_acc": 60.0, "val_loss": 0.786823399066925, "val_acc": 48.0}
{"epoch": 63, "training_loss": 0.8914398193359375, "training_acc": 56.0, "val_loss": 1.6986260652542113, "val_acc": 52.0}
{"epoch": 64, "training_loss": 1.026816924214363, "training_acc": 50.0, "val_loss": 1.9362071704864503, "val_acc": 48.0}
{"epoch": 65, "training_loss": 1.104341411590576, "training_acc": 48.0, "val_loss": 0.8171688365936279, "val_acc": 52.0}
