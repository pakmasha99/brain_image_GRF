"main_modify.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 3 --task ADNI_sex --input_option yAware --learning_rate 1e-1 --batch_size 16 --weight_decay 1e-2 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 8.558644037246705, "training_acc": 48.0, "val_loss": 4.789338111877441, "val_acc": 52.0}
{"epoch": 1, "training_loss": 4.122582989344373, "training_acc": 58.0, "val_loss": 1.9525292348861694, "val_acc": 48.0}
{"epoch": 2, "training_loss": 3.9173261642456056, "training_acc": 48.0, "val_loss": 1.535489821434021, "val_acc": 52.0}
{"epoch": 3, "training_loss": 1.929555082321167, "training_acc": 44.0, "val_loss": 3.222838478088379, "val_acc": 52.0}
{"epoch": 4, "training_loss": 1.7769727039337158, "training_acc": 62.0, "val_loss": 1.6097420692443847, "val_acc": 52.0}
{"epoch": 5, "training_loss": 2.000166025161743, "training_acc": 44.0, "val_loss": 1.8092126321792603, "val_acc": 48.0}
{"epoch": 6, "training_loss": 2.0400640630722044, "training_acc": 50.0, "val_loss": 4.3822619819641115, "val_acc": 48.0}
{"epoch": 7, "training_loss": 2.877608036994934, "training_acc": 50.0, "val_loss": 0.7383446502685547, "val_acc": 48.0}
{"epoch": 8, "training_loss": 0.7396117162704468, "training_acc": 54.0, "val_loss": 1.2771257829666138, "val_acc": 52.0}
{"epoch": 9, "training_loss": 1.291644732952118, "training_acc": 46.0, "val_loss": 0.9449592733383179, "val_acc": 52.0}
{"epoch": 10, "training_loss": 0.8550626468658448, "training_acc": 52.0, "val_loss": 2.9525929832458497, "val_acc": 52.0}
{"epoch": 11, "training_loss": 1.8462378931045533, "training_acc": 56.0, "val_loss": 0.7028962659835816, "val_acc": 48.0}
{"epoch": 12, "training_loss": 0.7134601259231568, "training_acc": 52.0, "val_loss": 1.6483941173553467, "val_acc": 48.0}
{"epoch": 13, "training_loss": 1.355728759765625, "training_acc": 46.0, "val_loss": 2.362531929016113, "val_acc": 52.0}
{"epoch": 14, "training_loss": 2.702799015045166, "training_acc": 46.0, "val_loss": 0.982291488647461, "val_acc": 52.0}
{"epoch": 15, "training_loss": 2.7071333646774294, "training_acc": 46.0, "val_loss": 0.7376799368858338, "val_acc": 52.0}
{"epoch": 16, "training_loss": 1.2309977531433105, "training_acc": 56.0, "val_loss": 0.9839020085334778, "val_acc": 48.0}
{"epoch": 17, "training_loss": 2.1732146835327146, "training_acc": 52.0, "val_loss": 1.261907525062561, "val_acc": 52.0}
{"epoch": 18, "training_loss": 1.3532928943634033, "training_acc": 48.0, "val_loss": 1.2066845083236695, "val_acc": 48.0}
{"epoch": 19, "training_loss": 1.862861852645874, "training_acc": 56.0, "val_loss": 1.8138645124435424, "val_acc": 48.0}
{"epoch": 20, "training_loss": 1.3138357853889466, "training_acc": 54.0, "val_loss": 1.6077518892288207, "val_acc": 52.0}
{"epoch": 21, "training_loss": 1.2259311199188232, "training_acc": 50.0, "val_loss": 0.6974417519569397, "val_acc": 48.0}
{"epoch": 22, "training_loss": 0.8833399057388306, "training_acc": 52.0, "val_loss": 0.9869607353210449, "val_acc": 48.0}
{"epoch": 23, "training_loss": 3.5633567667007444, "training_acc": 48.0, "val_loss": 3.379642324447632, "val_acc": 48.0}
{"epoch": 24, "training_loss": 6.102065238952637, "training_acc": 46.0, "val_loss": 5.779532470703125, "val_acc": 48.0}
{"epoch": 25, "training_loss": 5.530144348144531, "training_acc": 46.0, "val_loss": 5.993753776550293, "val_acc": 52.0}
{"epoch": 26, "training_loss": 5.900566778182983, "training_acc": 40.0, "val_loss": 2.1533763122558596, "val_acc": 52.0}
{"epoch": 27, "training_loss": 1.9893068122863768, "training_acc": 46.0, "val_loss": 0.7748628163337707, "val_acc": 48.0}
{"epoch": 28, "training_loss": 1.866286153793335, "training_acc": 46.0, "val_loss": 4.489719552993774, "val_acc": 48.0}
{"epoch": 29, "training_loss": 2.362407670021057, "training_acc": 58.0, "val_loss": 2.756322031021118, "val_acc": 48.0}
{"epoch": 30, "training_loss": 1.5448669075965882, "training_acc": 44.0, "val_loss": 1.31118980884552, "val_acc": 52.0}
{"epoch": 31, "training_loss": 0.9542446041107178, "training_acc": 50.0, "val_loss": 0.8940530776977539, "val_acc": 52.0}
{"epoch": 32, "training_loss": 0.7632523012161255, "training_acc": 56.0, "val_loss": 0.7246555042266846, "val_acc": 52.0}
{"epoch": 33, "training_loss": 1.02478285074234, "training_acc": 40.0, "val_loss": 1.4530443954467773, "val_acc": 48.0}
{"epoch": 34, "training_loss": 1.2023323822021483, "training_acc": 48.0, "val_loss": 0.6965709066390992, "val_acc": 48.0}
{"epoch": 35, "training_loss": 0.7922459363937377, "training_acc": 46.0, "val_loss": 1.2789400219917297, "val_acc": 48.0}
{"epoch": 36, "training_loss": 1.0122416067123412, "training_acc": 52.0, "val_loss": 0.7020769429206848, "val_acc": 52.0}
{"epoch": 37, "training_loss": 0.7970063519477845, "training_acc": 50.0, "val_loss": 1.9941444206237793, "val_acc": 52.0}
{"epoch": 38, "training_loss": 1.7276492309570313, "training_acc": 44.0, "val_loss": 1.0626253914833068, "val_acc": 48.0}
{"epoch": 39, "training_loss": 1.031175217628479, "training_acc": 50.0, "val_loss": 1.5502979898452758, "val_acc": 48.0}
{"epoch": 40, "training_loss": 0.9196742343902587, "training_acc": 54.0, "val_loss": 1.1903506326675415, "val_acc": 52.0}
{"epoch": 41, "training_loss": 1.5741057586669922, "training_acc": 48.0, "val_loss": 0.6924253463745117, "val_acc": 52.0}
{"epoch": 42, "training_loss": 1.1333146381378174, "training_acc": 42.0, "val_loss": 0.7841498279571533, "val_acc": 52.0}
{"epoch": 43, "training_loss": 0.8066384792327881, "training_acc": 52.0, "val_loss": 1.7529418277740478, "val_acc": 52.0}
{"epoch": 44, "training_loss": 1.5513875555992127, "training_acc": 60.0, "val_loss": 3.5330045318603513, "val_acc": 52.0}
{"epoch": 45, "training_loss": 2.7333641815185548, "training_acc": 50.0, "val_loss": 4.933685264587402, "val_acc": 52.0}
{"epoch": 46, "training_loss": 3.8546244049072267, "training_acc": 52.0, "val_loss": 3.733111734390259, "val_acc": 52.0}
{"epoch": 47, "training_loss": 4.736211833953857, "training_acc": 44.0, "val_loss": 2.2659846782684325, "val_acc": 52.0}
{"epoch": 48, "training_loss": 2.6181295204162596, "training_acc": 44.0, "val_loss": 2.3124880981445313, "val_acc": 52.0}
{"epoch": 49, "training_loss": 1.5955679178237916, "training_acc": 50.0, "val_loss": 1.6772740364074707, "val_acc": 48.0}
{"epoch": 50, "training_loss": 1.1766353416442872, "training_acc": 54.0, "val_loss": 1.94234224319458, "val_acc": 52.0}
{"epoch": 51, "training_loss": 0.8991192674636841, "training_acc": 54.0, "val_loss": 0.7249456882476807, "val_acc": 52.0}
{"epoch": 52, "training_loss": 1.0315285205841065, "training_acc": 46.0, "val_loss": 2.8151797676086425, "val_acc": 52.0}
{"epoch": 53, "training_loss": 2.0449486446380614, "training_acc": 50.0, "val_loss": 1.5349675083160401, "val_acc": 48.0}
{"epoch": 54, "training_loss": 1.6186017990112305, "training_acc": 58.0, "val_loss": 2.1797188758850097, "val_acc": 48.0}
{"epoch": 55, "training_loss": 1.1774476385116577, "training_acc": 54.0, "val_loss": 2.022190475463867, "val_acc": 52.0}
{"epoch": 56, "training_loss": 1.113316662311554, "training_acc": 50.0, "val_loss": 1.1564605188369752, "val_acc": 48.0}
{"epoch": 57, "training_loss": 1.0190100502967834, "training_acc": 46.0, "val_loss": 1.906436905860901, "val_acc": 48.0}
{"epoch": 58, "training_loss": 1.1198945236206055, "training_acc": 44.0, "val_loss": 2.011477074623108, "val_acc": 52.0}
{"epoch": 59, "training_loss": 1.3428701734542847, "training_acc": 46.0, "val_loss": 3.1815624904632567, "val_acc": 48.0}
{"epoch": 60, "training_loss": 2.240324535369873, "training_acc": 50.0, "val_loss": 3.368315887451172, "val_acc": 52.0}
