"main_modify.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 3 --task ADNI_sex --input_option yAware --learning_rate 1e-1 --batch_size 16 --weight_decay 1e-2 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 11.43796036720276, "training_acc": 48.0, "val_loss": 1.5363814449310302, "val_acc": 48.0}
{"epoch": 1, "training_loss": 3.030988667011261, "training_acc": 52.0, "val_loss": 2.4404565143585204, "val_acc": 48.0}
{"epoch": 2, "training_loss": 2.070067629814148, "training_acc": 48.0, "val_loss": 1.9285248231887817, "val_acc": 48.0}
{"epoch": 3, "training_loss": 1.5261485767364502, "training_acc": 48.0, "val_loss": 3.397057056427002, "val_acc": 48.0}
{"epoch": 4, "training_loss": 2.7414822006225585, "training_acc": 48.0, "val_loss": 0.8581233978271484, "val_acc": 52.0}
{"epoch": 5, "training_loss": 1.0554384803771972, "training_acc": 56.0, "val_loss": 2.3019735527038576, "val_acc": 48.0}
{"epoch": 6, "training_loss": 1.5542597198486328, "training_acc": 56.0, "val_loss": 0.7490983486175538, "val_acc": 52.0}
{"epoch": 7, "training_loss": 0.9505679941177368, "training_acc": 46.0, "val_loss": 0.7284046888351441, "val_acc": 52.0}
{"epoch": 8, "training_loss": 1.401935019493103, "training_acc": 48.0, "val_loss": 0.7199388909339904, "val_acc": 48.0}
{"epoch": 9, "training_loss": 1.0241025161743165, "training_acc": 54.0, "val_loss": 1.433495626449585, "val_acc": 48.0}
{"epoch": 10, "training_loss": 0.8507178235054016, "training_acc": 54.0, "val_loss": 2.8644211006164553, "val_acc": 48.0}
{"epoch": 11, "training_loss": 1.7369798088073731, "training_acc": 44.0, "val_loss": 0.9020601797103882, "val_acc": 48.0}
{"epoch": 12, "training_loss": 0.8409319400787354, "training_acc": 48.0, "val_loss": 0.9616811084747314, "val_acc": 52.0}
{"epoch": 13, "training_loss": 1.924669075012207, "training_acc": 42.0, "val_loss": 1.2314707612991334, "val_acc": 48.0}
{"epoch": 14, "training_loss": 3.2712376308441162, "training_acc": 52.0, "val_loss": 7.657980308532715, "val_acc": 48.0}
{"epoch": 15, "training_loss": 5.266097812652588, "training_acc": 52.0, "val_loss": 0.9002561116218567, "val_acc": 48.0}
{"epoch": 16, "training_loss": 1.9230500221252442, "training_acc": 42.0, "val_loss": 1.7574457597732545, "val_acc": 52.0}
{"epoch": 17, "training_loss": 2.1520202922821046, "training_acc": 46.0, "val_loss": 1.9416391944885254, "val_acc": 52.0}
{"epoch": 18, "training_loss": 1.4417494916915894, "training_acc": 50.0, "val_loss": 1.0650007605552674, "val_acc": 48.0}
{"epoch": 19, "training_loss": 0.8503208303451538, "training_acc": 50.0, "val_loss": 0.81355708360672, "val_acc": 52.0}
{"epoch": 20, "training_loss": 0.8582405090332031, "training_acc": 48.0, "val_loss": 0.6940340828895569, "val_acc": 52.0}
{"epoch": 21, "training_loss": 0.9519607496261596, "training_acc": 54.0, "val_loss": 0.7380471682548523, "val_acc": 48.0}
{"epoch": 22, "training_loss": 0.8516753983497619, "training_acc": 50.0, "val_loss": 1.4439575815200805, "val_acc": 52.0}
{"epoch": 23, "training_loss": 1.2363204050064087, "training_acc": 54.0, "val_loss": 0.7010744500160218, "val_acc": 52.0}
{"epoch": 24, "training_loss": 1.0378741240501403, "training_acc": 42.0, "val_loss": 0.8188443017005921, "val_acc": 48.0}
{"epoch": 25, "training_loss": 0.9356084418296814, "training_acc": 56.0, "val_loss": 4.291406993865967, "val_acc": 48.0}
{"epoch": 26, "training_loss": 4.254360768795014, "training_acc": 44.0, "val_loss": 4.05227502822876, "val_acc": 48.0}
{"epoch": 27, "training_loss": 3.38960373878479, "training_acc": 62.0, "val_loss": 2.2231638336181643, "val_acc": 52.0}
{"epoch": 28, "training_loss": 2.122411823272705, "training_acc": 56.0, "val_loss": 2.628111801147461, "val_acc": 48.0}
{"epoch": 29, "training_loss": 1.8827502202987672, "training_acc": 44.0, "val_loss": 1.373005609512329, "val_acc": 52.0}
{"epoch": 30, "training_loss": 1.090590844154358, "training_acc": 52.0, "val_loss": 1.7110263442993163, "val_acc": 52.0}
{"epoch": 31, "training_loss": 1.799635021686554, "training_acc": 48.0, "val_loss": 2.6778554248809816, "val_acc": 48.0}
{"epoch": 32, "training_loss": 2.3005849170684813, "training_acc": 48.0, "val_loss": 1.2500504922866822, "val_acc": 52.0}
{"epoch": 33, "training_loss": 1.8636518287658692, "training_acc": 58.0, "val_loss": 0.928697657585144, "val_acc": 52.0}
{"epoch": 34, "training_loss": 1.097230806350708, "training_acc": 56.0, "val_loss": 0.9493928503990173, "val_acc": 52.0}
{"epoch": 35, "training_loss": 1.0285798263549806, "training_acc": 42.0, "val_loss": 0.7239176082611084, "val_acc": 48.0}
{"epoch": 36, "training_loss": 1.041657886505127, "training_acc": 44.0, "val_loss": 1.353571252822876, "val_acc": 48.0}
{"epoch": 37, "training_loss": 1.0335605573654174, "training_acc": 46.0, "val_loss": 0.6942752647399902, "val_acc": 52.0}
{"epoch": 38, "training_loss": 0.8813450193405151, "training_acc": 52.0, "val_loss": 0.697584125995636, "val_acc": 48.0}
{"epoch": 39, "training_loss": 0.9464941453933716, "training_acc": 46.0, "val_loss": 0.7456171393394471, "val_acc": 48.0}
