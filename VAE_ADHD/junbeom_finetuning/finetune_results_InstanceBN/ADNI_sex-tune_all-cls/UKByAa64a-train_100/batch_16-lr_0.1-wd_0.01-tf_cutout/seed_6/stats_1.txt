"main_modify.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 6 --task ADNI_sex --input_option yAware --learning_rate 1e-1 --batch_size 16 --weight_decay 1e-2 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 10.244737948179244, "training_acc": 39.0, "val_loss": 2.0048672485351564, "val_acc": 52.0}
{"epoch": 1, "training_loss": 3.523245582580566, "training_acc": 41.0, "val_loss": 3.9528902053833006, "val_acc": 52.0}
{"epoch": 2, "training_loss": 2.985608205795288, "training_acc": 47.0, "val_loss": 1.3246331453323363, "val_acc": 52.0}
{"epoch": 3, "training_loss": 0.9597564435005188, "training_acc": 57.0, "val_loss": 1.6699538612365723, "val_acc": 48.0}
{"epoch": 4, "training_loss": 0.9742728900909424, "training_acc": 49.0, "val_loss": 1.5194493675231933, "val_acc": 48.0}
{"epoch": 5, "training_loss": 1.307674036026001, "training_acc": 49.0, "val_loss": 0.8541483402252197, "val_acc": 52.0}
{"epoch": 6, "training_loss": 0.7106168985366821, "training_acc": 53.0, "val_loss": 1.893487992286682, "val_acc": 48.0}
{"epoch": 7, "training_loss": 1.2228812456130982, "training_acc": 55.0, "val_loss": 0.7912559700012207, "val_acc": 52.0}
{"epoch": 8, "training_loss": 0.9411680388450623, "training_acc": 47.0, "val_loss": 0.72759920835495, "val_acc": 48.0}
{"epoch": 9, "training_loss": 1.0688622879981995, "training_acc": 45.0, "val_loss": 1.792035322189331, "val_acc": 48.0}
{"epoch": 10, "training_loss": 0.9662820291519165, "training_acc": 51.0, "val_loss": 1.142877721786499, "val_acc": 52.0}
{"epoch": 11, "training_loss": 1.1153666591644287, "training_acc": 53.0, "val_loss": 0.7009132122993469, "val_acc": 52.0}
{"epoch": 12, "training_loss": 1.05049578666687, "training_acc": 45.0, "val_loss": 1.2969422006607056, "val_acc": 52.0}
{"epoch": 13, "training_loss": 1.4883772444725036, "training_acc": 47.0, "val_loss": 2.1213481044769287, "val_acc": 48.0}
{"epoch": 14, "training_loss": 1.658810214996338, "training_acc": 57.0, "val_loss": 4.659665508270264, "val_acc": 48.0}
{"epoch": 15, "training_loss": 3.778830680847168, "training_acc": 43.0, "val_loss": 2.8030434036254883, "val_acc": 48.0}
{"epoch": 16, "training_loss": 2.451753911972046, "training_acc": 53.0, "val_loss": 3.212941665649414, "val_acc": 48.0}
{"epoch": 17, "training_loss": 2.08807385802269, "training_acc": 51.0, "val_loss": 4.674567222595215, "val_acc": 52.0}
{"epoch": 18, "training_loss": 4.298403301239014, "training_acc": 41.0, "val_loss": 2.7639851188659668, "val_acc": 52.0}
{"epoch": 19, "training_loss": 1.8520230150222778, "training_acc": 47.0, "val_loss": 1.0610460138320923, "val_acc": 48.0}
{"epoch": 20, "training_loss": 2.1610100246965884, "training_acc": 47.0, "val_loss": 5.674447898864746, "val_acc": 52.0}
{"epoch": 21, "training_loss": 4.277906107902527, "training_acc": 45.0, "val_loss": 1.937503366470337, "val_acc": 52.0}
{"epoch": 22, "training_loss": 1.1563058972358704, "training_acc": 53.0, "val_loss": 2.6015710544586184, "val_acc": 48.0}
{"epoch": 23, "training_loss": 1.503408818244934, "training_acc": 51.0, "val_loss": 0.8832017326354981, "val_acc": 52.0}
{"epoch": 24, "training_loss": 0.8237899780273438, "training_acc": 49.0, "val_loss": 0.7876970839500427, "val_acc": 52.0}
{"epoch": 25, "training_loss": 1.05424241065979, "training_acc": 47.0, "val_loss": 1.7360706806182862, "val_acc": 52.0}
{"epoch": 26, "training_loss": 1.7922602716088294, "training_acc": 55.0, "val_loss": 4.067738952636719, "val_acc": 52.0}
{"epoch": 27, "training_loss": 3.29876763343811, "training_acc": 57.0, "val_loss": 0.8289181661605834, "val_acc": 52.0}
{"epoch": 28, "training_loss": 2.877680320739746, "training_acc": 53.0, "val_loss": 1.4101500034332275, "val_acc": 48.0}
{"epoch": 29, "training_loss": 1.9582459592819215, "training_acc": 49.0, "val_loss": 2.6859848308563232, "val_acc": 52.0}
{"epoch": 30, "training_loss": 2.5059030151367185, "training_acc": 47.0, "val_loss": 1.1975837445259094, "val_acc": 52.0}
{"epoch": 31, "training_loss": 1.7380433368682862, "training_acc": 45.0, "val_loss": 0.6928592205047608, "val_acc": 52.0}
{"epoch": 32, "training_loss": 0.9178071904182434, "training_acc": 61.0, "val_loss": 0.6924756717681885, "val_acc": 52.0}
{"epoch": 33, "training_loss": 0.8407351064682007, "training_acc": 47.0, "val_loss": 1.758112859725952, "val_acc": 52.0}
{"epoch": 34, "training_loss": 1.3371084260940551, "training_acc": 49.0, "val_loss": 0.7845448756217956, "val_acc": 52.0}
{"epoch": 35, "training_loss": 0.9291646313667298, "training_acc": 53.0, "val_loss": 0.8583970546722413, "val_acc": 52.0}
{"epoch": 36, "training_loss": 0.8262229061126709, "training_acc": 49.0, "val_loss": 0.8612001466751099, "val_acc": 48.0}
{"epoch": 37, "training_loss": 0.8057286334037781, "training_acc": 49.0, "val_loss": 1.625565962791443, "val_acc": 52.0}
{"epoch": 38, "training_loss": 1.2025711250305176, "training_acc": 55.0, "val_loss": 0.7092957520484924, "val_acc": 52.0}
{"epoch": 39, "training_loss": 1.1190250492095948, "training_acc": 49.0, "val_loss": 0.709282534122467, "val_acc": 48.0}
{"epoch": 40, "training_loss": 1.330387692451477, "training_acc": 55.0, "val_loss": 2.217163486480713, "val_acc": 52.0}
{"epoch": 41, "training_loss": 2.297488474845886, "training_acc": 43.0, "val_loss": 3.6557153129577635, "val_acc": 48.0}
{"epoch": 42, "training_loss": 1.625887839794159, "training_acc": 49.0, "val_loss": 0.9190532541275025, "val_acc": 48.0}
{"epoch": 43, "training_loss": 1.2159417057037354, "training_acc": 49.0, "val_loss": 0.715098249912262, "val_acc": 48.0}
{"epoch": 44, "training_loss": 1.0075681972503663, "training_acc": 51.0, "val_loss": 0.7101955771446228, "val_acc": 52.0}
{"epoch": 45, "training_loss": 0.9116406202316284, "training_acc": 39.0, "val_loss": 1.959124674797058, "val_acc": 48.0}
{"epoch": 46, "training_loss": 2.247364025115967, "training_acc": 49.0, "val_loss": 3.2492314529418946, "val_acc": 48.0}
{"epoch": 47, "training_loss": 1.8091911029815675, "training_acc": 53.0, "val_loss": 0.7606065392494201, "val_acc": 52.0}
{"epoch": 48, "training_loss": 1.8379643726348878, "training_acc": 45.0, "val_loss": 3.994527931213379, "val_acc": 52.0}
{"epoch": 49, "training_loss": 2.4493862438201903, "training_acc": 53.0, "val_loss": 1.1173576378822327, "val_acc": 52.0}
{"epoch": 50, "training_loss": 1.2145229721069335, "training_acc": 51.0, "val_loss": 0.7625226306915284, "val_acc": 52.0}
{"epoch": 51, "training_loss": 1.1958697080612182, "training_acc": 47.0, "val_loss": 2.2900273323059084, "val_acc": 48.0}
