"main_modify.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 6 --task ADNI_sex --input_option yAware --learning_rate 1e-1 --batch_size 16 --weight_decay 1e-2 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 7.87390703201294, "training_acc": 50.0, "val_loss": 4.991098918914795, "val_acc": 48.0}
{"epoch": 1, "training_loss": 3.0730301570892333, "training_acc": 56.0, "val_loss": 5.2137847328186036, "val_acc": 48.0}
{"epoch": 2, "training_loss": 2.6178149366378785, "training_acc": 52.0, "val_loss": 1.4773264122009278, "val_acc": 48.0}
{"epoch": 3, "training_loss": 2.0492515659332273, "training_acc": 42.0, "val_loss": 2.0361677551269532, "val_acc": 48.0}
{"epoch": 4, "training_loss": 1.765654525756836, "training_acc": 52.0, "val_loss": 0.8537816858291626, "val_acc": 52.0}
{"epoch": 5, "training_loss": 1.2742092156410216, "training_acc": 66.0, "val_loss": 0.7597094440460205, "val_acc": 52.0}
{"epoch": 6, "training_loss": 1.623135166168213, "training_acc": 42.0, "val_loss": 1.2500064206123351, "val_acc": 48.0}
{"epoch": 7, "training_loss": 0.969760286808014, "training_acc": 48.0, "val_loss": 1.6398880577087402, "val_acc": 48.0}
{"epoch": 8, "training_loss": 0.9295946389436722, "training_acc": 56.0, "val_loss": 2.3617107343673704, "val_acc": 52.0}
{"epoch": 9, "training_loss": 1.3296297335624694, "training_acc": 60.0, "val_loss": 0.7327397489547729, "val_acc": 48.0}
{"epoch": 10, "training_loss": 1.6880739974975585, "training_acc": 48.0, "val_loss": 1.563831901550293, "val_acc": 48.0}
{"epoch": 11, "training_loss": 1.372401418685913, "training_acc": 54.0, "val_loss": 2.2426282119750978, "val_acc": 52.0}
{"epoch": 12, "training_loss": 1.5071197867393493, "training_acc": 48.0, "val_loss": 1.6613022136688231, "val_acc": 48.0}
{"epoch": 13, "training_loss": 1.0398684310913087, "training_acc": 48.0, "val_loss": 2.8742490577697755, "val_acc": 48.0}
{"epoch": 14, "training_loss": 2.3546677923202513, "training_acc": 56.0, "val_loss": 3.0632467746734617, "val_acc": 48.0}
{"epoch": 15, "training_loss": 1.5478799533843994, "training_acc": 48.0, "val_loss": 1.4662264251708985, "val_acc": 48.0}
{"epoch": 16, "training_loss": 1.3103233146667481, "training_acc": 54.0, "val_loss": 1.7920245504379273, "val_acc": 52.0}
{"epoch": 17, "training_loss": 1.1506012535095216, "training_acc": 54.0, "val_loss": 0.8648927307128906, "val_acc": 48.0}
{"epoch": 18, "training_loss": 1.5807209014892578, "training_acc": 42.0, "val_loss": 0.8645598268508912, "val_acc": 52.0}
{"epoch": 19, "training_loss": 1.020380802154541, "training_acc": 58.0, "val_loss": 0.7157350468635559, "val_acc": 48.0}
{"epoch": 20, "training_loss": 1.5714237213134765, "training_acc": 44.0, "val_loss": 0.7947419667243958, "val_acc": 48.0}
{"epoch": 21, "training_loss": 0.780040512084961, "training_acc": 56.0, "val_loss": 0.801598138809204, "val_acc": 52.0}
{"epoch": 22, "training_loss": 1.2104189348220826, "training_acc": 46.0, "val_loss": 1.2729366207122803, "val_acc": 48.0}
{"epoch": 23, "training_loss": 0.7539877653121948, "training_acc": 50.0, "val_loss": 3.328805284500122, "val_acc": 48.0}
{"epoch": 24, "training_loss": 2.8323125648498535, "training_acc": 44.0, "val_loss": 5.6678391456604, "val_acc": 48.0}
{"epoch": 25, "training_loss": 3.0704187393188476, "training_acc": 54.0, "val_loss": 2.3632471227645873, "val_acc": 48.0}
{"epoch": 26, "training_loss": 1.5438374805450439, "training_acc": 46.0, "val_loss": 0.6923516845703125, "val_acc": 52.0}
{"epoch": 27, "training_loss": 0.7740386152267456, "training_acc": 56.0, "val_loss": 0.7015627717971802, "val_acc": 48.0}
{"epoch": 28, "training_loss": 1.1511784839630126, "training_acc": 46.0, "val_loss": 1.3484384536743164, "val_acc": 48.0}
{"epoch": 29, "training_loss": 1.1754611873626708, "training_acc": 50.0, "val_loss": 3.1558802700042725, "val_acc": 52.0}
{"epoch": 30, "training_loss": 2.045491199493408, "training_acc": 50.0, "val_loss": 1.9206222581863404, "val_acc": 52.0}
{"epoch": 31, "training_loss": 1.56059757232666, "training_acc": 52.0, "val_loss": 0.6923502779006958, "val_acc": 52.0}
{"epoch": 32, "training_loss": 1.0065717792510986, "training_acc": 54.0, "val_loss": 0.7864941072463989, "val_acc": 48.0}
{"epoch": 33, "training_loss": 0.79453049428761, "training_acc": 50.0, "val_loss": 3.1663043022155763, "val_acc": 48.0}
{"epoch": 34, "training_loss": 2.390982608795166, "training_acc": 54.0, "val_loss": 2.900897378921509, "val_acc": 48.0}
{"epoch": 35, "training_loss": 2.8728641986846926, "training_acc": 46.0, "val_loss": 3.374423999786377, "val_acc": 48.0}
{"epoch": 36, "training_loss": 2.0909893856942654, "training_acc": 58.0, "val_loss": 3.039292311668396, "val_acc": 48.0}
{"epoch": 37, "training_loss": 1.9833951568603516, "training_acc": 44.0, "val_loss": 2.4172929096221925, "val_acc": 48.0}
{"epoch": 38, "training_loss": 1.5966236352920533, "training_acc": 50.0, "val_loss": 1.29501296043396, "val_acc": 52.0}
{"epoch": 39, "training_loss": 1.42532413482666, "training_acc": 48.0, "val_loss": 0.8437181115150452, "val_acc": 52.0}
{"epoch": 40, "training_loss": 0.9515263032913208, "training_acc": 52.0, "val_loss": 1.1206179189682006, "val_acc": 52.0}
{"epoch": 41, "training_loss": 1.070254213809967, "training_acc": 46.0, "val_loss": 0.701651566028595, "val_acc": 48.0}
{"epoch": 42, "training_loss": 0.8735878658294678, "training_acc": 50.0, "val_loss": 0.8943671655654907, "val_acc": 52.0}
{"epoch": 43, "training_loss": 1.1047433376312257, "training_acc": 44.0, "val_loss": 1.8650759410858155, "val_acc": 52.0}
{"epoch": 44, "training_loss": 1.2452760934829712, "training_acc": 54.0, "val_loss": 1.6114781284332276, "val_acc": 52.0}
{"epoch": 45, "training_loss": 1.5883720350265502, "training_acc": 52.0, "val_loss": 1.227042145729065, "val_acc": 48.0}
{"epoch": 46, "training_loss": 1.0691740226745605, "training_acc": 52.0, "val_loss": 1.8365604639053346, "val_acc": 52.0}
{"epoch": 47, "training_loss": 1.3239212203025819, "training_acc": 54.0, "val_loss": 0.9911679148674011, "val_acc": 52.0}
{"epoch": 48, "training_loss": 0.9369813251495361, "training_acc": 46.0, "val_loss": 0.7495567631721497, "val_acc": 52.0}
{"epoch": 49, "training_loss": 0.9311067342758179, "training_acc": 54.0, "val_loss": 0.6924791693687439, "val_acc": 52.0}
{"epoch": 50, "training_loss": 1.2586739778518676, "training_acc": 50.0, "val_loss": 0.6923607182502747, "val_acc": 52.0}
