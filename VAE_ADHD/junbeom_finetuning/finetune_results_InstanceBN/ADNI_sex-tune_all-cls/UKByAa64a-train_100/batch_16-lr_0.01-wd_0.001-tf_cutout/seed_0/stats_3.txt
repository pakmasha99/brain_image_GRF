"main_modify.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ADNI_sex --input_option yAware --learning_rate 1e-2 --batch_size 16 --weight_decay 1e-3 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 1.2609329342842102, "training_acc": 46.0, "val_loss": 0.734136049747467, "val_acc": 48.0}
{"epoch": 1, "training_loss": 0.8923837566375732, "training_acc": 46.0, "val_loss": 1.0672374057769776, "val_acc": 48.0}
{"epoch": 2, "training_loss": 0.968126859664917, "training_acc": 40.0, "val_loss": 0.7850547671318054, "val_acc": 48.0}
{"epoch": 3, "training_loss": 0.8512371397018432, "training_acc": 50.0, "val_loss": 0.7179437279701233, "val_acc": 52.0}
{"epoch": 4, "training_loss": 0.7173365640640259, "training_acc": 46.0, "val_loss": 0.7082563161849975, "val_acc": 48.0}
{"epoch": 5, "training_loss": 0.7410844182968139, "training_acc": 46.0, "val_loss": 0.7086635303497314, "val_acc": 48.0}
{"epoch": 6, "training_loss": 0.6999359560012818, "training_acc": 48.0, "val_loss": 0.7246642231941223, "val_acc": 52.0}
{"epoch": 7, "training_loss": 0.7304899024963379, "training_acc": 48.0, "val_loss": 0.6977368235588074, "val_acc": 48.0}
{"epoch": 8, "training_loss": 0.6949664545059204, "training_acc": 50.0, "val_loss": 0.7070075225830078, "val_acc": 48.0}
{"epoch": 9, "training_loss": 0.7405710983276367, "training_acc": 44.0, "val_loss": 0.6977884292602539, "val_acc": 52.0}
{"epoch": 10, "training_loss": 0.7706152415275573, "training_acc": 50.0, "val_loss": 0.8357320237159729, "val_acc": 48.0}
{"epoch": 11, "training_loss": 0.77851158618927, "training_acc": 52.0, "val_loss": 0.7034572696685791, "val_acc": 48.0}
{"epoch": 12, "training_loss": 0.7767184090614319, "training_acc": 42.0, "val_loss": 0.715353057384491, "val_acc": 48.0}
{"epoch": 13, "training_loss": 0.7423451399803161, "training_acc": 40.0, "val_loss": 0.7274215006828308, "val_acc": 52.0}
{"epoch": 14, "training_loss": 0.7242064428329468, "training_acc": 50.0, "val_loss": 0.7351253461837769, "val_acc": 48.0}
{"epoch": 15, "training_loss": 0.7206555843353272, "training_acc": 50.0, "val_loss": 0.7102003526687622, "val_acc": 52.0}
{"epoch": 16, "training_loss": 0.8053820276260376, "training_acc": 46.0, "val_loss": 1.1778472137451172, "val_acc": 52.0}
{"epoch": 17, "training_loss": 0.913297462463379, "training_acc": 52.0, "val_loss": 0.9619221639633179, "val_acc": 48.0}
{"epoch": 18, "training_loss": 0.756025583744049, "training_acc": 54.0, "val_loss": 0.7142289566993714, "val_acc": 52.0}
{"epoch": 19, "training_loss": 0.7137669372558594, "training_acc": 52.0, "val_loss": 0.7119761538505555, "val_acc": 52.0}
{"epoch": 20, "training_loss": 0.7653257751464844, "training_acc": 44.0, "val_loss": 0.6925559163093566, "val_acc": 52.0}
{"epoch": 21, "training_loss": 0.731103184223175, "training_acc": 50.0, "val_loss": 0.7800740838050843, "val_acc": 48.0}
{"epoch": 22, "training_loss": 0.7343314099311828, "training_acc": 46.0, "val_loss": 0.7181102371215821, "val_acc": 48.0}
{"epoch": 23, "training_loss": 0.7178359293937683, "training_acc": 46.0, "val_loss": 0.7328183650970459, "val_acc": 52.0}
{"epoch": 24, "training_loss": 0.7294649267196656, "training_acc": 48.0, "val_loss": 0.8460955286026001, "val_acc": 48.0}
{"epoch": 25, "training_loss": 0.8332573890686035, "training_acc": 50.0, "val_loss": 0.7825875616073609, "val_acc": 52.0}
{"epoch": 26, "training_loss": 0.7351441383361816, "training_acc": 50.0, "val_loss": 0.7005908012390136, "val_acc": 48.0}
{"epoch": 27, "training_loss": 0.6938422966003418, "training_acc": 52.0, "val_loss": 0.692845389842987, "val_acc": 52.0}
{"epoch": 28, "training_loss": 0.7082528638839721, "training_acc": 40.0, "val_loss": 0.6927736616134643, "val_acc": 52.0}
{"epoch": 29, "training_loss": 0.739671106338501, "training_acc": 50.0, "val_loss": 0.7442197442054749, "val_acc": 48.0}
{"epoch": 30, "training_loss": 0.7670121479034424, "training_acc": 50.0, "val_loss": 0.694131634235382, "val_acc": 48.0}
{"epoch": 31, "training_loss": 0.6990848875045776, "training_acc": 52.0, "val_loss": 0.7003369951248168, "val_acc": 48.0}
{"epoch": 32, "training_loss": 0.7261808204650879, "training_acc": 48.0, "val_loss": 0.7230325031280518, "val_acc": 52.0}
{"epoch": 33, "training_loss": 0.7336244106292724, "training_acc": 48.0, "val_loss": 0.6955965757369995, "val_acc": 52.0}
{"epoch": 34, "training_loss": 0.7047267818450927, "training_acc": 52.0, "val_loss": 0.7329972767829895, "val_acc": 48.0}
{"epoch": 35, "training_loss": 0.7685327744483947, "training_acc": 44.0, "val_loss": 0.6973773550987243, "val_acc": 52.0}
{"epoch": 36, "training_loss": 0.7083385753631591, "training_acc": 50.0, "val_loss": 0.6936619520187378, "val_acc": 48.0}
{"epoch": 37, "training_loss": 0.697086911201477, "training_acc": 48.0, "val_loss": 0.7205350780487061, "val_acc": 48.0}
{"epoch": 38, "training_loss": 0.7105384254455567, "training_acc": 50.0, "val_loss": 0.6933302307128906, "val_acc": 52.0}
{"epoch": 39, "training_loss": 0.767637894153595, "training_acc": 52.0, "val_loss": 0.7547558569908142, "val_acc": 52.0}
