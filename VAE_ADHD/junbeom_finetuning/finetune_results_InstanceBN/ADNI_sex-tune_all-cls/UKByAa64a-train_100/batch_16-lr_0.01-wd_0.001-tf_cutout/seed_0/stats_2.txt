"main_modify.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ADNI_sex --input_option yAware --learning_rate 1e-2 --batch_size 16 --weight_decay 1e-3 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 1.3345020294189454, "training_acc": 44.0, "val_loss": 0.7301833629608154, "val_acc": 52.0}
{"epoch": 1, "training_loss": 0.8572877788543701, "training_acc": 52.0, "val_loss": 0.7161575651168823, "val_acc": 48.0}
{"epoch": 2, "training_loss": 0.7347819685935975, "training_acc": 42.0, "val_loss": 0.7194002151489258, "val_acc": 52.0}
{"epoch": 3, "training_loss": 0.7574475884437561, "training_acc": 48.0, "val_loss": 0.7083670735359192, "val_acc": 48.0}
{"epoch": 4, "training_loss": 0.7206853818893433, "training_acc": 46.0, "val_loss": 0.7153264975547791, "val_acc": 52.0}
{"epoch": 5, "training_loss": 0.7568331003189087, "training_acc": 42.0, "val_loss": 0.7051467680931092, "val_acc": 52.0}
{"epoch": 6, "training_loss": 0.7211003422737121, "training_acc": 50.0, "val_loss": 0.797746388912201, "val_acc": 52.0}
{"epoch": 7, "training_loss": 0.8081493711471558, "training_acc": 52.0, "val_loss": 0.7655458045005799, "val_acc": 48.0}
{"epoch": 8, "training_loss": 0.7835298156738282, "training_acc": 46.0, "val_loss": 0.8020427703857422, "val_acc": 48.0}
{"epoch": 9, "training_loss": 0.826534252166748, "training_acc": 46.0, "val_loss": 0.9087136507034301, "val_acc": 48.0}
{"epoch": 10, "training_loss": 0.9105787658691407, "training_acc": 48.0, "val_loss": 0.7791554737091064, "val_acc": 52.0}
{"epoch": 11, "training_loss": 0.8406112575531006, "training_acc": 54.0, "val_loss": 0.8391050076484681, "val_acc": 52.0}
{"epoch": 12, "training_loss": 1.1542100858688356, "training_acc": 54.0, "val_loss": 1.4718106079101563, "val_acc": 48.0}
{"epoch": 13, "training_loss": 1.3088509058952331, "training_acc": 50.0, "val_loss": 0.9411512279510498, "val_acc": 52.0}
{"epoch": 14, "training_loss": 0.884094021320343, "training_acc": 50.0, "val_loss": 0.7257994103431702, "val_acc": 48.0}
{"epoch": 15, "training_loss": 0.7175701546669007, "training_acc": 54.0, "val_loss": 0.9161338043212891, "val_acc": 52.0}
{"epoch": 16, "training_loss": 0.9146200466156006, "training_acc": 48.0, "val_loss": 0.8806447649002075, "val_acc": 48.0}
{"epoch": 17, "training_loss": 0.7878672480583191, "training_acc": 48.0, "val_loss": 0.6935482501983643, "val_acc": 52.0}
{"epoch": 18, "training_loss": 0.70358229637146, "training_acc": 50.0, "val_loss": 0.7251915621757508, "val_acc": 52.0}
{"epoch": 19, "training_loss": 0.7668049860000611, "training_acc": 54.0, "val_loss": 0.8524728322029114, "val_acc": 48.0}
{"epoch": 20, "training_loss": 0.774181752204895, "training_acc": 46.0, "val_loss": 0.6932595825195312, "val_acc": 48.0}
{"epoch": 21, "training_loss": 0.7073035478591919, "training_acc": 46.0, "val_loss": 0.6972481632232665, "val_acc": 52.0}
{"epoch": 22, "training_loss": 0.7278880476951599, "training_acc": 42.0, "val_loss": 0.6942070937156677, "val_acc": 48.0}
{"epoch": 23, "training_loss": 0.729778242111206, "training_acc": 50.0, "val_loss": 0.7232823133468628, "val_acc": 52.0}
{"epoch": 24, "training_loss": 0.7111911082267761, "training_acc": 50.0, "val_loss": 0.7017712044715881, "val_acc": 52.0}
{"epoch": 25, "training_loss": 0.7114051866531372, "training_acc": 52.0, "val_loss": 0.8733080577850342, "val_acc": 48.0}
{"epoch": 26, "training_loss": 0.814468309879303, "training_acc": 50.0, "val_loss": 0.7515851259231567, "val_acc": 52.0}
{"epoch": 27, "training_loss": 0.6908680248260498, "training_acc": 60.0, "val_loss": 1.0112183427810668, "val_acc": 48.0}
{"epoch": 28, "training_loss": 0.9810276484489441, "training_acc": 40.0, "val_loss": 0.8042566871643066, "val_acc": 48.0}
{"epoch": 29, "training_loss": 0.7850320196151733, "training_acc": 48.0, "val_loss": 0.7212902164459228, "val_acc": 52.0}
{"epoch": 30, "training_loss": 0.7398512935638428, "training_acc": 50.0, "val_loss": 0.8118528747558593, "val_acc": 52.0}
{"epoch": 31, "training_loss": 0.7534868955612183, "training_acc": 52.0, "val_loss": 0.8437793040275574, "val_acc": 48.0}
{"epoch": 32, "training_loss": 0.7516310620307922, "training_acc": 46.0, "val_loss": 0.7287950587272644, "val_acc": 48.0}
{"epoch": 33, "training_loss": 0.743458342552185, "training_acc": 42.0, "val_loss": 0.7194784021377564, "val_acc": 48.0}
{"epoch": 34, "training_loss": 0.7190701723098755, "training_acc": 50.0, "val_loss": 0.6935790729522705, "val_acc": 48.0}
{"epoch": 35, "training_loss": 0.7055882835388183, "training_acc": 46.0, "val_loss": 0.7372903847694396, "val_acc": 52.0}
{"epoch": 36, "training_loss": 0.7392089366912842, "training_acc": 52.0, "val_loss": 0.8490774869918823, "val_acc": 48.0}
{"epoch": 37, "training_loss": 0.7632540965080261, "training_acc": 54.0, "val_loss": 0.7422271656990052, "val_acc": 52.0}
{"epoch": 38, "training_loss": 0.7243066716194153, "training_acc": 48.0, "val_loss": 0.6970625615119934, "val_acc": 48.0}
{"epoch": 39, "training_loss": 0.7652459383010864, "training_acc": 46.0, "val_loss": 0.7048386383056641, "val_acc": 52.0}
