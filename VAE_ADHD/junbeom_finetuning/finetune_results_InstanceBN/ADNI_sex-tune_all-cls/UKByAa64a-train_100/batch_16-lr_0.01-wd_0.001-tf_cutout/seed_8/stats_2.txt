"main_modify.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 8 --task ADNI_sex --input_option yAware --learning_rate 1e-2 --batch_size 16 --weight_decay 1e-3 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 1.3628227424621582, "training_acc": 48.0, "val_loss": 0.8828198957443237, "val_acc": 48.0}
{"epoch": 1, "training_loss": 1.3549062776565552, "training_acc": 50.0, "val_loss": 0.8592950510978699, "val_acc": 52.0}
{"epoch": 2, "training_loss": 1.0108034992218018, "training_acc": 52.0, "val_loss": 0.9638009262084961, "val_acc": 48.0}
{"epoch": 3, "training_loss": 0.9104614067077637, "training_acc": 50.0, "val_loss": 0.6977262353897095, "val_acc": 52.0}
{"epoch": 4, "training_loss": 0.7091747665405274, "training_acc": 48.0, "val_loss": 0.6938634490966797, "val_acc": 48.0}
{"epoch": 5, "training_loss": 0.728816339969635, "training_acc": 53.0, "val_loss": 0.6998111891746521, "val_acc": 48.0}
{"epoch": 6, "training_loss": 0.7036814093589783, "training_acc": 48.0, "val_loss": 0.7000418066978454, "val_acc": 48.0}
{"epoch": 7, "training_loss": 0.7252245712280273, "training_acc": 42.0, "val_loss": 0.6927706837654114, "val_acc": 52.0}
{"epoch": 8, "training_loss": 0.7363202714920044, "training_acc": 48.0, "val_loss": 0.7095527410507202, "val_acc": 52.0}
{"epoch": 9, "training_loss": 0.7108303046226502, "training_acc": 50.0, "val_loss": 0.747046730518341, "val_acc": 48.0}
{"epoch": 10, "training_loss": 0.7246965408325196, "training_acc": 56.0, "val_loss": 0.8403747034072876, "val_acc": 52.0}
{"epoch": 11, "training_loss": 0.8286742377281189, "training_acc": 46.0, "val_loss": 0.7333613133430481, "val_acc": 52.0}
{"epoch": 12, "training_loss": 0.7293144416809082, "training_acc": 52.0, "val_loss": 0.7177522611618042, "val_acc": 48.0}
{"epoch": 13, "training_loss": 0.6984307384490966, "training_acc": 58.0, "val_loss": 0.7981698632240295, "val_acc": 52.0}
{"epoch": 14, "training_loss": 0.7466840362548828, "training_acc": 50.0, "val_loss": 0.7272101044654846, "val_acc": 48.0}
{"epoch": 15, "training_loss": 0.707990403175354, "training_acc": 48.0, "val_loss": 0.7943806099891663, "val_acc": 52.0}
{"epoch": 16, "training_loss": 0.7764152336120606, "training_acc": 40.0, "val_loss": 0.7667424416542054, "val_acc": 48.0}
{"epoch": 17, "training_loss": 0.7681461429595947, "training_acc": 50.0, "val_loss": 0.6942191767692566, "val_acc": 52.0}
{"epoch": 18, "training_loss": 0.7414555168151855, "training_acc": 48.0, "val_loss": 0.7689342713356018, "val_acc": 52.0}
{"epoch": 19, "training_loss": 0.7178835868835449, "training_acc": 52.0, "val_loss": 0.8086756730079651, "val_acc": 48.0}
{"epoch": 20, "training_loss": 0.701045389175415, "training_acc": 56.0, "val_loss": 0.7517345356941223, "val_acc": 52.0}
{"epoch": 21, "training_loss": 0.7462439870834351, "training_acc": 44.0, "val_loss": 0.6994979476928711, "val_acc": 48.0}
{"epoch": 22, "training_loss": 0.7066394424438477, "training_acc": 52.0, "val_loss": 0.7633957386016845, "val_acc": 52.0}
{"epoch": 23, "training_loss": 0.7714189743995666, "training_acc": 44.0, "val_loss": 0.6981599617004395, "val_acc": 52.0}
{"epoch": 24, "training_loss": 0.7406905817985535, "training_acc": 48.0, "val_loss": 0.6935111618041992, "val_acc": 52.0}
{"epoch": 25, "training_loss": 0.7188334274291992, "training_acc": 46.0, "val_loss": 0.6925346398353577, "val_acc": 52.0}
{"epoch": 26, "training_loss": 0.7081579637527465, "training_acc": 44.0, "val_loss": 0.71029620885849, "val_acc": 48.0}
{"epoch": 27, "training_loss": 0.7160055780410767, "training_acc": 50.0, "val_loss": 0.6941455221176147, "val_acc": 52.0}
{"epoch": 28, "training_loss": 0.7189751553535462, "training_acc": 50.0, "val_loss": 0.7160615658760071, "val_acc": 48.0}
{"epoch": 29, "training_loss": 0.7361480093002319, "training_acc": 48.0, "val_loss": 0.7013389706611634, "val_acc": 52.0}
{"epoch": 30, "training_loss": 0.7066915655136108, "training_acc": 50.0, "val_loss": 0.7240687346458435, "val_acc": 48.0}
{"epoch": 31, "training_loss": 0.7279286456108093, "training_acc": 40.0, "val_loss": 0.7385263371467591, "val_acc": 48.0}
{"epoch": 32, "training_loss": 0.7294483041763306, "training_acc": 50.0, "val_loss": 0.6941410040855408, "val_acc": 52.0}
{"epoch": 33, "training_loss": 0.7159953117370605, "training_acc": 44.0, "val_loss": 0.6923473477363586, "val_acc": 52.0}
{"epoch": 34, "training_loss": 0.7105449509620666, "training_acc": 50.0, "val_loss": 0.6926582431793213, "val_acc": 52.0}
{"epoch": 35, "training_loss": 0.6990650463104248, "training_acc": 50.0, "val_loss": 0.6957081031799316, "val_acc": 52.0}
{"epoch": 36, "training_loss": 0.7330867195129395, "training_acc": 44.0, "val_loss": 0.6932086110115051, "val_acc": 48.0}
{"epoch": 37, "training_loss": 0.7081581926345826, "training_acc": 46.0, "val_loss": 0.6928611636161804, "val_acc": 52.0}
{"epoch": 38, "training_loss": 0.7021662807464599, "training_acc": 56.0, "val_loss": 0.7079357504844666, "val_acc": 48.0}
{"epoch": 39, "training_loss": 0.7242732739448547, "training_acc": 46.0, "val_loss": 0.6938309025764465, "val_acc": 52.0}
{"epoch": 40, "training_loss": 0.6932086992263794, "training_acc": 52.0, "val_loss": 0.7359286427497864, "val_acc": 48.0}
{"epoch": 41, "training_loss": 0.7118017983436584, "training_acc": 54.0, "val_loss": 0.7569851732254028, "val_acc": 52.0}
{"epoch": 42, "training_loss": 0.7691359329223633, "training_acc": 50.0, "val_loss": 0.7222969889640808, "val_acc": 48.0}
{"epoch": 43, "training_loss": 0.7267308855056762, "training_acc": 50.0, "val_loss": 0.6930922770500183, "val_acc": 52.0}
{"epoch": 44, "training_loss": 0.7200805568695068, "training_acc": 44.0, "val_loss": 0.7022015881538392, "val_acc": 48.0}
{"epoch": 45, "training_loss": 0.7059126853942871, "training_acc": 48.0, "val_loss": 0.6938441967964173, "val_acc": 48.0}
{"epoch": 46, "training_loss": 0.7172599267959595, "training_acc": 40.0, "val_loss": 0.7092155337333679, "val_acc": 48.0}
{"epoch": 47, "training_loss": 0.707479829788208, "training_acc": 46.0, "val_loss": 0.6959569382667542, "val_acc": 48.0}
{"epoch": 48, "training_loss": 0.7042023706436157, "training_acc": 50.0, "val_loss": 0.7005184221267701, "val_acc": 52.0}
{"epoch": 49, "training_loss": 0.8388072991371155, "training_acc": 48.0, "val_loss": 0.7254144763946533, "val_acc": 48.0}
{"epoch": 50, "training_loss": 0.7212468099594116, "training_acc": 48.0, "val_loss": 0.6957715344429016, "val_acc": 52.0}
{"epoch": 51, "training_loss": 0.700799036026001, "training_acc": 52.0, "val_loss": 0.6989926958084106, "val_acc": 48.0}
{"epoch": 52, "training_loss": 0.7016170549392701, "training_acc": 52.0, "val_loss": 0.6923923993110657, "val_acc": 52.0}
