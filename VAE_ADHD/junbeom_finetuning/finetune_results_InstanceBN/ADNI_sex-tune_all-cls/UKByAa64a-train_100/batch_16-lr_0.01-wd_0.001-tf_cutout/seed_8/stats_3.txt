"main_modify.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 8 --task ADNI_sex --input_option yAware --learning_rate 1e-2 --batch_size 16 --weight_decay 1e-3 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 1.49664333820343, "training_acc": 46.0, "val_loss": 0.7265504455566406, "val_acc": 48.0}
{"epoch": 1, "training_loss": 0.8169092226028443, "training_acc": 50.0, "val_loss": 0.8509044194221497, "val_acc": 48.0}
{"epoch": 2, "training_loss": 0.8147671175003052, "training_acc": 38.0, "val_loss": 0.7254013037681579, "val_acc": 48.0}
{"epoch": 3, "training_loss": 0.7219269180297851, "training_acc": 46.0, "val_loss": 0.699808475971222, "val_acc": 52.0}
{"epoch": 4, "training_loss": 0.7060887336730957, "training_acc": 48.0, "val_loss": 0.7315796041488647, "val_acc": 52.0}
{"epoch": 5, "training_loss": 0.7505336308479309, "training_acc": 54.0, "val_loss": 0.919134795665741, "val_acc": 48.0}
{"epoch": 6, "training_loss": 0.7900917339324951, "training_acc": 48.0, "val_loss": 0.7274061131477356, "val_acc": 48.0}
{"epoch": 7, "training_loss": 0.7279279088973999, "training_acc": 46.0, "val_loss": 0.9683373260498047, "val_acc": 48.0}
{"epoch": 8, "training_loss": 0.8400244450569153, "training_acc": 52.0, "val_loss": 0.7066365146636963, "val_acc": 52.0}
{"epoch": 9, "training_loss": 0.7413686847686768, "training_acc": 48.0, "val_loss": 0.7837596821784973, "val_acc": 52.0}
{"epoch": 10, "training_loss": 0.7549488735198975, "training_acc": 44.0, "val_loss": 0.7259617638587952, "val_acc": 52.0}
{"epoch": 11, "training_loss": 0.7177211236953736, "training_acc": 54.0, "val_loss": 0.7097136807441712, "val_acc": 48.0}
{"epoch": 12, "training_loss": 0.7235927248001098, "training_acc": 44.0, "val_loss": 0.8251280617713929, "val_acc": 52.0}
{"epoch": 13, "training_loss": 0.7454315161705017, "training_acc": 52.0, "val_loss": 0.8086977934837342, "val_acc": 48.0}
{"epoch": 14, "training_loss": 0.7558379650115967, "training_acc": 46.0, "val_loss": 0.7055365490913391, "val_acc": 48.0}
{"epoch": 15, "training_loss": 0.7546684050559997, "training_acc": 48.0, "val_loss": 0.6955312657356262, "val_acc": 48.0}
{"epoch": 16, "training_loss": 0.7735372352600097, "training_acc": 52.0, "val_loss": 0.883908805847168, "val_acc": 52.0}
{"epoch": 17, "training_loss": 0.8027301406860352, "training_acc": 48.0, "val_loss": 0.7662887978553772, "val_acc": 48.0}
{"epoch": 18, "training_loss": 0.7264839100837708, "training_acc": 48.0, "val_loss": 0.7206953740119935, "val_acc": 52.0}
{"epoch": 19, "training_loss": 0.7407174468040466, "training_acc": 50.0, "val_loss": 0.7220143604278565, "val_acc": 48.0}
{"epoch": 20, "training_loss": 0.6998949480056763, "training_acc": 48.0, "val_loss": 0.6932761597633362, "val_acc": 48.0}
{"epoch": 21, "training_loss": 0.7205766916275025, "training_acc": 50.0, "val_loss": 0.7204324078559875, "val_acc": 52.0}
{"epoch": 22, "training_loss": 0.7113696050643921, "training_acc": 48.0, "val_loss": 0.7005437755584717, "val_acc": 48.0}
{"epoch": 23, "training_loss": 0.6976882338523864, "training_acc": 54.0, "val_loss": 0.7419151139259338, "val_acc": 52.0}
{"epoch": 24, "training_loss": 0.7822003650665283, "training_acc": 50.0, "val_loss": 0.7055770802497864, "val_acc": 48.0}
{"epoch": 25, "training_loss": 0.7300631475448608, "training_acc": 42.0, "val_loss": 0.692415668964386, "val_acc": 52.0}
{"epoch": 26, "training_loss": 0.7136846375465393, "training_acc": 46.0, "val_loss": 0.6958041095733642, "val_acc": 48.0}
{"epoch": 27, "training_loss": 0.7380051326751709, "training_acc": 50.0, "val_loss": 0.7377273392677307, "val_acc": 52.0}
{"epoch": 28, "training_loss": 0.7644568967819214, "training_acc": 52.0, "val_loss": 0.7133120846748352, "val_acc": 48.0}
{"epoch": 29, "training_loss": 0.7330715227127075, "training_acc": 46.0, "val_loss": 0.9036653542518616, "val_acc": 48.0}
{"epoch": 30, "training_loss": 0.779813392162323, "training_acc": 52.0, "val_loss": 0.7651922202110291, "val_acc": 48.0}
{"epoch": 31, "training_loss": 0.7374623870849609, "training_acc": 52.0, "val_loss": 0.7217345523834229, "val_acc": 52.0}
{"epoch": 32, "training_loss": 0.74516770362854, "training_acc": 42.0, "val_loss": 0.7483662056922913, "val_acc": 48.0}
{"epoch": 33, "training_loss": 0.712322027683258, "training_acc": 56.0, "val_loss": 0.9373235511779785, "val_acc": 52.0}
{"epoch": 34, "training_loss": 0.7916557455062866, "training_acc": 50.0, "val_loss": 0.7260316133499145, "val_acc": 48.0}
{"epoch": 35, "training_loss": 0.7056292247772217, "training_acc": 54.0, "val_loss": 0.6926067852973938, "val_acc": 52.0}
{"epoch": 36, "training_loss": 0.6895448637008667, "training_acc": 54.0, "val_loss": 0.7167582440376282, "val_acc": 48.0}
{"epoch": 37, "training_loss": 0.7140854620933532, "training_acc": 50.0, "val_loss": 0.7045913243293762, "val_acc": 52.0}
{"epoch": 38, "training_loss": 0.6868946838378907, "training_acc": 56.0, "val_loss": 0.786573030948639, "val_acc": 48.0}
{"epoch": 39, "training_loss": 0.756017427444458, "training_acc": 40.0, "val_loss": 0.6930931949615479, "val_acc": 52.0}
{"epoch": 40, "training_loss": 0.7061601114273072, "training_acc": 46.0, "val_loss": 0.6923703002929688, "val_acc": 52.0}
{"epoch": 41, "training_loss": 0.7236701488494873, "training_acc": 50.0, "val_loss": 0.725078125, "val_acc": 48.0}
{"epoch": 42, "training_loss": 0.7157755851745605, "training_acc": 48.0, "val_loss": 0.6937246608734131, "val_acc": 52.0}
{"epoch": 43, "training_loss": 0.707401270866394, "training_acc": 52.0, "val_loss": 0.6928268361091614, "val_acc": 52.0}
{"epoch": 44, "training_loss": 0.7198021101951599, "training_acc": 50.0, "val_loss": 0.7122145438194275, "val_acc": 48.0}
{"epoch": 45, "training_loss": 0.7595487880706787, "training_acc": 50.0, "val_loss": 0.7085673594474793, "val_acc": 52.0}
{"epoch": 46, "training_loss": 0.7152614903450012, "training_acc": 52.0, "val_loss": 0.7273502397537231, "val_acc": 48.0}
{"epoch": 47, "training_loss": 0.7409356594085693, "training_acc": 52.0, "val_loss": 0.7917310333251953, "val_acc": 52.0}
{"epoch": 48, "training_loss": 0.7426535320281983, "training_acc": 52.0, "val_loss": 0.8327503705024719, "val_acc": 48.0}
{"epoch": 49, "training_loss": 0.767182183265686, "training_acc": 56.0, "val_loss": 0.8066177821159363, "val_acc": 52.0}
{"epoch": 50, "training_loss": 0.7630440330505371, "training_acc": 50.0, "val_loss": 0.760702908039093, "val_acc": 48.0}
{"epoch": 51, "training_loss": 0.7166374492645263, "training_acc": 50.0, "val_loss": 0.6983175325393677, "val_acc": 52.0}
{"epoch": 52, "training_loss": 0.7270413970947266, "training_acc": 50.0, "val_loss": 0.7068324398994446, "val_acc": 52.0}
{"epoch": 53, "training_loss": 0.7611267471313476, "training_acc": 50.0, "val_loss": 0.7566518640518188, "val_acc": 48.0}
{"epoch": 54, "training_loss": 0.7101719808578492, "training_acc": 54.0, "val_loss": 0.7672680020332336, "val_acc": 52.0}
{"epoch": 55, "training_loss": 0.7705910444259644, "training_acc": 48.0, "val_loss": 0.7030581831932068, "val_acc": 48.0}
{"epoch": 56, "training_loss": 0.6979378652572632, "training_acc": 52.0, "val_loss": 0.6927126407623291, "val_acc": 52.0}
{"epoch": 57, "training_loss": 0.695465841293335, "training_acc": 56.0, "val_loss": 0.7103649854660035, "val_acc": 48.0}
{"epoch": 58, "training_loss": 0.7147445774078369, "training_acc": 46.0, "val_loss": 0.7011382389068603, "val_acc": 48.0}
{"epoch": 59, "training_loss": 0.704631838798523, "training_acc": 52.0, "val_loss": 0.7437617874145508, "val_acc": 52.0}
