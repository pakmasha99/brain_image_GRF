"main_modify.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 7 --task ADNI_sex --input_option yAware --learning_rate 1e-2 --batch_size 16 --weight_decay 1e-3 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 1.5061483097076416, "training_acc": 46.0, "val_loss": 0.6944224953651428, "val_acc": 48.0}
{"epoch": 1, "training_loss": 1.046506187915802, "training_acc": 48.0, "val_loss": 0.9001023030281067, "val_acc": 48.0}
{"epoch": 2, "training_loss": 0.8142968702316284, "training_acc": 46.0, "val_loss": 0.7167223978042603, "val_acc": 52.0}
{"epoch": 3, "training_loss": 0.7049754095077515, "training_acc": 54.0, "val_loss": 0.6926119256019593, "val_acc": 52.0}
{"epoch": 4, "training_loss": 0.7526176118850708, "training_acc": 50.0, "val_loss": 0.7611185932159423, "val_acc": 48.0}
{"epoch": 5, "training_loss": 0.7060679244995117, "training_acc": 52.0, "val_loss": 0.7528578948974609, "val_acc": 52.0}
{"epoch": 6, "training_loss": 0.8124897050857544, "training_acc": 50.0, "val_loss": 0.761271550655365, "val_acc": 48.0}
{"epoch": 7, "training_loss": 0.7303743100166321, "training_acc": 52.0, "val_loss": 0.7236508512496949, "val_acc": 52.0}
{"epoch": 8, "training_loss": 0.7986890459060669, "training_acc": 48.0, "val_loss": 0.6957885384559631, "val_acc": 52.0}
{"epoch": 9, "training_loss": 0.8644225215911865, "training_acc": 52.0, "val_loss": 1.24776517868042, "val_acc": 48.0}
{"epoch": 10, "training_loss": 1.036231677532196, "training_acc": 46.0, "val_loss": 0.693871967792511, "val_acc": 52.0}
{"epoch": 11, "training_loss": 0.6954555296897889, "training_acc": 54.0, "val_loss": 0.7082059931755066, "val_acc": 48.0}
{"epoch": 12, "training_loss": 0.6993946886062622, "training_acc": 54.0, "val_loss": 0.6938008618354797, "val_acc": 48.0}
{"epoch": 13, "training_loss": 0.7747213006019592, "training_acc": 50.0, "val_loss": 0.6940488147735596, "val_acc": 48.0}
{"epoch": 14, "training_loss": 0.7505452156066894, "training_acc": 52.0, "val_loss": 0.7132423877716064, "val_acc": 52.0}
{"epoch": 15, "training_loss": 0.7191699838638306, "training_acc": 44.0, "val_loss": 0.7184447431564331, "val_acc": 48.0}
{"epoch": 16, "training_loss": 0.7579760670661926, "training_acc": 48.0, "val_loss": 0.7897986555099488, "val_acc": 48.0}
{"epoch": 17, "training_loss": 0.7551640748977662, "training_acc": 44.0, "val_loss": 0.6925296807289123, "val_acc": 52.0}
{"epoch": 18, "training_loss": 0.7469732511043549, "training_acc": 58.0, "val_loss": 1.265561854839325, "val_acc": 48.0}
{"epoch": 19, "training_loss": 0.9718903994560242, "training_acc": 50.0, "val_loss": 0.7957037782669067, "val_acc": 52.0}
{"epoch": 20, "training_loss": 0.7423801851272583, "training_acc": 48.0, "val_loss": 0.693349506855011, "val_acc": 52.0}
{"epoch": 21, "training_loss": 0.7276094579696655, "training_acc": 46.0, "val_loss": 0.7098971939086914, "val_acc": 48.0}
{"epoch": 22, "training_loss": 0.7054575252532959, "training_acc": 44.0, "val_loss": 0.7295640254020691, "val_acc": 48.0}
{"epoch": 23, "training_loss": 0.7091915082931518, "training_acc": 46.0, "val_loss": 0.6923729038238525, "val_acc": 52.0}
{"epoch": 24, "training_loss": 0.7109368395805359, "training_acc": 54.0, "val_loss": 0.7828923106193543, "val_acc": 48.0}
{"epoch": 25, "training_loss": 0.8536486291885376, "training_acc": 38.0, "val_loss": 0.9073539662361145, "val_acc": 48.0}
{"epoch": 26, "training_loss": 0.7778320860862732, "training_acc": 42.0, "val_loss": 0.7042580127716065, "val_acc": 52.0}
{"epoch": 27, "training_loss": 0.7176324987411499, "training_acc": 54.0, "val_loss": 0.7741799616813659, "val_acc": 48.0}
{"epoch": 28, "training_loss": 0.7589376306533814, "training_acc": 52.0, "val_loss": 0.6949408173561096, "val_acc": 48.0}
{"epoch": 29, "training_loss": 0.7084307670593262, "training_acc": 46.0, "val_loss": 0.7020715308189392, "val_acc": 52.0}
{"epoch": 30, "training_loss": 0.7903495049476623, "training_acc": 48.0, "val_loss": 0.7007614207267762, "val_acc": 52.0}
{"epoch": 31, "training_loss": 0.7651499652862549, "training_acc": 48.0, "val_loss": 0.7115619659423829, "val_acc": 48.0}
{"epoch": 32, "training_loss": 0.7094698476791382, "training_acc": 44.0, "val_loss": 0.6926419162750244, "val_acc": 52.0}
{"epoch": 33, "training_loss": 0.7086567068099976, "training_acc": 44.0, "val_loss": 0.7945869946479798, "val_acc": 52.0}
{"epoch": 34, "training_loss": 0.9254339122772217, "training_acc": 40.0, "val_loss": 0.7191192698478699, "val_acc": 48.0}
{"epoch": 35, "training_loss": 0.7133087873458862, "training_acc": 42.0, "val_loss": 0.718858380317688, "val_acc": 52.0}
{"epoch": 36, "training_loss": 0.7857449007034302, "training_acc": 48.0, "val_loss": 0.7008380913734436, "val_acc": 52.0}
{"epoch": 37, "training_loss": 0.7462560367584229, "training_acc": 50.0, "val_loss": 0.7119893264770508, "val_acc": 48.0}
{"epoch": 38, "training_loss": 0.716116464138031, "training_acc": 50.0, "val_loss": 0.6925750350952149, "val_acc": 52.0}
{"epoch": 39, "training_loss": 0.7002845621109008, "training_acc": 44.0, "val_loss": 0.6981043720245361, "val_acc": 48.0}
{"epoch": 40, "training_loss": 0.7037245607376099, "training_acc": 42.0, "val_loss": 0.6941058278083801, "val_acc": 48.0}
{"epoch": 41, "training_loss": 0.7091550016403199, "training_acc": 44.0, "val_loss": 0.6934071373939514, "val_acc": 48.0}
{"epoch": 42, "training_loss": 0.7121420621871948, "training_acc": 48.0, "val_loss": 0.6962557435035706, "val_acc": 52.0}
