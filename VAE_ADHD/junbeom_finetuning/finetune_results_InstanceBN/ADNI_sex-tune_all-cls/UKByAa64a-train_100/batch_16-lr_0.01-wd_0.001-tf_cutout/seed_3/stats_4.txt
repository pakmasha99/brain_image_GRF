"main_modify.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 3 --task ADNI_sex --input_option yAware --learning_rate 1e-2 --batch_size 16 --weight_decay 1e-3 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 1.108632686138153, "training_acc": 53.0, "val_loss": 0.6996108365058898, "val_acc": 48.0}
{"epoch": 1, "training_loss": 0.7011855340003967, "training_acc": 49.0, "val_loss": 0.7566399359703064, "val_acc": 52.0}
{"epoch": 2, "training_loss": 0.7743169832229614, "training_acc": 47.0, "val_loss": 0.6941531229019166, "val_acc": 48.0}
{"epoch": 3, "training_loss": 0.7457072401046753, "training_acc": 53.0, "val_loss": 0.8368226361274719, "val_acc": 52.0}
{"epoch": 4, "training_loss": 0.8068897151947021, "training_acc": 47.0, "val_loss": 0.7010707116127014, "val_acc": 52.0}
{"epoch": 5, "training_loss": 0.8118979096412658, "training_acc": 51.0, "val_loss": 0.9334803390502929, "val_acc": 48.0}
{"epoch": 6, "training_loss": 0.7334538841247559, "training_acc": 53.0, "val_loss": 0.6950847554206848, "val_acc": 52.0}
{"epoch": 7, "training_loss": 0.7177515506744385, "training_acc": 49.0, "val_loss": 0.7681186604499817, "val_acc": 48.0}
{"epoch": 8, "training_loss": 0.7557455539703369, "training_acc": 55.0, "val_loss": 0.7120514130592346, "val_acc": 52.0}
{"epoch": 9, "training_loss": 0.7168729734420777, "training_acc": 51.0, "val_loss": 0.7145941948890686, "val_acc": 52.0}
{"epoch": 10, "training_loss": 0.711839861869812, "training_acc": 49.0, "val_loss": 0.7146962094306946, "val_acc": 52.0}
{"epoch": 11, "training_loss": 0.7364891719818115, "training_acc": 43.0, "val_loss": 0.7639957737922668, "val_acc": 52.0}
{"epoch": 12, "training_loss": 0.7612630271911621, "training_acc": 47.0, "val_loss": 0.9298421025276185, "val_acc": 52.0}
{"epoch": 13, "training_loss": 0.8773821234703064, "training_acc": 53.0, "val_loss": 0.898241503238678, "val_acc": 48.0}
{"epoch": 14, "training_loss": 0.8513512492179871, "training_acc": 39.0, "val_loss": 0.8713549017906189, "val_acc": 48.0}
{"epoch": 15, "training_loss": 0.7672421145439148, "training_acc": 41.0, "val_loss": 0.7109819436073304, "val_acc": 52.0}
{"epoch": 16, "training_loss": 0.7421678495407105, "training_acc": 47.0, "val_loss": 0.7218794250488281, "val_acc": 48.0}
{"epoch": 17, "training_loss": 0.7234082293510437, "training_acc": 43.0, "val_loss": 0.7275166702270508, "val_acc": 48.0}
{"epoch": 18, "training_loss": 0.7414735150337219, "training_acc": 41.0, "val_loss": 0.9092015385627746, "val_acc": 48.0}
{"epoch": 19, "training_loss": 0.7458186197280884, "training_acc": 53.0, "val_loss": 0.6937803292274475, "val_acc": 52.0}
{"epoch": 20, "training_loss": 0.7544269990921021, "training_acc": 41.0, "val_loss": 0.7045821428298951, "val_acc": 48.0}
{"epoch": 21, "training_loss": 0.7606704926490784, "training_acc": 51.0, "val_loss": 0.7228008842468262, "val_acc": 52.0}
{"epoch": 22, "training_loss": 0.7784092116355896, "training_acc": 43.0, "val_loss": 0.7056410312652588, "val_acc": 52.0}
{"epoch": 23, "training_loss": 0.7191735696792603, "training_acc": 47.0, "val_loss": 0.7065044784545899, "val_acc": 52.0}
{"epoch": 24, "training_loss": 0.7385594797134399, "training_acc": 45.0, "val_loss": 0.7167111492156982, "val_acc": 52.0}
{"epoch": 25, "training_loss": 0.7008949947357178, "training_acc": 55.0, "val_loss": 0.7547586917877197, "val_acc": 48.0}
{"epoch": 26, "training_loss": 0.7540163326263428, "training_acc": 55.0, "val_loss": 0.763885395526886, "val_acc": 52.0}
{"epoch": 27, "training_loss": 0.846758623123169, "training_acc": 47.0, "val_loss": 0.902565689086914, "val_acc": 52.0}
{"epoch": 28, "training_loss": 0.8251536250114441, "training_acc": 47.0, "val_loss": 0.7123041200637817, "val_acc": 52.0}
{"epoch": 29, "training_loss": 0.743576922416687, "training_acc": 45.0, "val_loss": 0.6943188047409058, "val_acc": 48.0}
{"epoch": 30, "training_loss": 0.6986203289031983, "training_acc": 49.0, "val_loss": 0.7314237475395202, "val_acc": 48.0}
{"epoch": 31, "training_loss": 0.7329334902763367, "training_acc": 51.0, "val_loss": 0.7087776565551758, "val_acc": 52.0}
{"epoch": 32, "training_loss": 0.7037651371955872, "training_acc": 49.0, "val_loss": 0.8227487945556641, "val_acc": 48.0}
{"epoch": 33, "training_loss": 0.7466286110877991, "training_acc": 53.0, "val_loss": 0.70680734872818, "val_acc": 52.0}
{"epoch": 34, "training_loss": 0.7086221122741699, "training_acc": 47.0, "val_loss": 0.788927948474884, "val_acc": 48.0}
{"epoch": 35, "training_loss": 0.7135004544258118, "training_acc": 57.0, "val_loss": 0.84450856924057, "val_acc": 52.0}
{"epoch": 36, "training_loss": 0.8025184726715088, "training_acc": 45.0, "val_loss": 0.6983261132240295, "val_acc": 48.0}
{"epoch": 37, "training_loss": 0.7230132794380189, "training_acc": 47.0, "val_loss": 0.8407324147224426, "val_acc": 48.0}
{"epoch": 38, "training_loss": 0.7921159172058105, "training_acc": 47.0, "val_loss": 0.74105313539505, "val_acc": 48.0}
{"epoch": 39, "training_loss": 0.7339280223846436, "training_acc": 51.0, "val_loss": 0.6924142551422119, "val_acc": 52.0}
{"epoch": 40, "training_loss": 0.7146829986572265, "training_acc": 45.0, "val_loss": 0.7686650133132935, "val_acc": 52.0}
{"epoch": 41, "training_loss": 0.7904510998725891, "training_acc": 49.0, "val_loss": 0.8207446384429932, "val_acc": 48.0}
{"epoch": 42, "training_loss": 0.860090217590332, "training_acc": 41.0, "val_loss": 1.0001784563064575, "val_acc": 48.0}
{"epoch": 43, "training_loss": 0.8130475974082947, "training_acc": 49.0, "val_loss": 0.7356253886222839, "val_acc": 52.0}
{"epoch": 44, "training_loss": 0.727339825630188, "training_acc": 51.0, "val_loss": 0.7199167895317078, "val_acc": 48.0}
{"epoch": 45, "training_loss": 0.6947489261627198, "training_acc": 53.0, "val_loss": 0.7111113357543946, "val_acc": 52.0}
{"epoch": 46, "training_loss": 0.7376620101928711, "training_acc": 43.0, "val_loss": 0.7464250302314759, "val_acc": 52.0}
{"epoch": 47, "training_loss": 0.7254626083374024, "training_acc": 51.0, "val_loss": 0.7707756900787354, "val_acc": 48.0}
{"epoch": 48, "training_loss": 0.7202723836898803, "training_acc": 51.0, "val_loss": 0.6926124525070191, "val_acc": 52.0}
{"epoch": 49, "training_loss": 0.7102416300773621, "training_acc": 57.0, "val_loss": 0.761209967136383, "val_acc": 52.0}
{"epoch": 50, "training_loss": 0.7605242466926575, "training_acc": 47.0, "val_loss": 0.8480316662788391, "val_acc": 48.0}
{"epoch": 51, "training_loss": 0.9127937889099121, "training_acc": 49.0, "val_loss": 0.6924182963371277, "val_acc": 52.0}
{"epoch": 52, "training_loss": 0.8097364568710327, "training_acc": 53.0, "val_loss": 0.7903306674957276, "val_acc": 52.0}
{"epoch": 53, "training_loss": 0.7338226890563965, "training_acc": 53.0, "val_loss": 0.7773278522491455, "val_acc": 48.0}
{"epoch": 54, "training_loss": 0.7211380171775817, "training_acc": 49.0, "val_loss": 0.7273539018630981, "val_acc": 48.0}
{"epoch": 55, "training_loss": 0.7111088538169861, "training_acc": 49.0, "val_loss": 0.7131942772865295, "val_acc": 48.0}
{"epoch": 56, "training_loss": 0.6906102824211121, "training_acc": 55.0, "val_loss": 0.9298599195480347, "val_acc": 52.0}
{"epoch": 57, "training_loss": 0.9362094283103943, "training_acc": 45.0, "val_loss": 0.748457157611847, "val_acc": 48.0}
{"epoch": 58, "training_loss": 0.7873999834060669, "training_acc": 47.0, "val_loss": 0.8760422587394714, "val_acc": 48.0}
