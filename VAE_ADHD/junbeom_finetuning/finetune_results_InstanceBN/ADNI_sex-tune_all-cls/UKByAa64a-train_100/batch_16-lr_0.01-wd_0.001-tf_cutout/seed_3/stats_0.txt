"main_modify.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 3 --task ADNI_sex --input_option yAware --learning_rate 1e-2 --batch_size 16 --weight_decay 1e-3 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 1.333907015323639, "training_acc": 48.0, "val_loss": 0.6985630226135254, "val_acc": 52.0}
{"epoch": 1, "training_loss": 0.7763354110717774, "training_acc": 50.0, "val_loss": 0.823259129524231, "val_acc": 52.0}
{"epoch": 2, "training_loss": 0.7417187857627868, "training_acc": 58.0, "val_loss": 0.8405028057098388, "val_acc": 48.0}
{"epoch": 3, "training_loss": 0.7181002187728882, "training_acc": 56.0, "val_loss": 0.6940636324882508, "val_acc": 52.0}
{"epoch": 4, "training_loss": 0.7283853316307067, "training_acc": 50.0, "val_loss": 0.7591311526298523, "val_acc": 52.0}
{"epoch": 5, "training_loss": 0.7952769517898559, "training_acc": 44.0, "val_loss": 0.7122209858894348, "val_acc": 48.0}
{"epoch": 6, "training_loss": 0.7684928894042968, "training_acc": 50.0, "val_loss": 0.6994136476516724, "val_acc": 48.0}
{"epoch": 7, "training_loss": 0.8354923200607299, "training_acc": 55.0, "val_loss": 0.8545832538604736, "val_acc": 52.0}
{"epoch": 8, "training_loss": 0.7754202270507813, "training_acc": 46.0, "val_loss": 0.6945714926719666, "val_acc": 52.0}
{"epoch": 9, "training_loss": 0.7536156558990479, "training_acc": 48.0, "val_loss": 0.697007327079773, "val_acc": 52.0}
{"epoch": 10, "training_loss": 0.6873533582687378, "training_acc": 54.0, "val_loss": 0.9972020483016968, "val_acc": 48.0}
{"epoch": 11, "training_loss": 0.8722693347930908, "training_acc": 54.0, "val_loss": 0.7292524361610413, "val_acc": 52.0}
{"epoch": 12, "training_loss": 0.7805241322517396, "training_acc": 50.0, "val_loss": 0.8874464726448059, "val_acc": 52.0}
{"epoch": 13, "training_loss": 0.7930682015419006, "training_acc": 56.0, "val_loss": 0.8486462736129761, "val_acc": 48.0}
{"epoch": 14, "training_loss": 0.8337946939468384, "training_acc": 46.0, "val_loss": 1.029379072189331, "val_acc": 48.0}
{"epoch": 15, "training_loss": 0.9440543508529663, "training_acc": 48.0, "val_loss": 0.819304165840149, "val_acc": 52.0}
{"epoch": 16, "training_loss": 0.7099513149261475, "training_acc": 54.0, "val_loss": 0.6951658725738525, "val_acc": 48.0}
{"epoch": 17, "training_loss": 0.779264497756958, "training_acc": 40.0, "val_loss": 0.6984586071968079, "val_acc": 48.0}
{"epoch": 18, "training_loss": 0.7036098527908325, "training_acc": 48.0, "val_loss": 0.699068055152893, "val_acc": 48.0}
{"epoch": 19, "training_loss": 0.7153779363632202, "training_acc": 48.0, "val_loss": 0.7573177218437195, "val_acc": 48.0}
{"epoch": 20, "training_loss": 0.7759118700027465, "training_acc": 50.0, "val_loss": 0.6935506367683411, "val_acc": 48.0}
{"epoch": 21, "training_loss": 0.7136323976516724, "training_acc": 46.0, "val_loss": 0.7018490695953369, "val_acc": 48.0}
{"epoch": 22, "training_loss": 0.7257538509368896, "training_acc": 46.0, "val_loss": 0.7170615482330323, "val_acc": 48.0}
{"epoch": 23, "training_loss": 0.6848469400405883, "training_acc": 56.0, "val_loss": 0.7134139013290405, "val_acc": 52.0}
{"epoch": 24, "training_loss": 0.7230042219161987, "training_acc": 50.0, "val_loss": 0.7022818493843078, "val_acc": 52.0}
{"epoch": 25, "training_loss": 0.7098214173316956, "training_acc": 50.0, "val_loss": 0.8356426429748535, "val_acc": 48.0}
{"epoch": 26, "training_loss": 0.8525098729133606, "training_acc": 44.0, "val_loss": 0.6923721575737, "val_acc": 52.0}
{"epoch": 27, "training_loss": 0.7705352449417114, "training_acc": 44.0, "val_loss": 0.8073744678497314, "val_acc": 52.0}
{"epoch": 28, "training_loss": 0.7895150518417359, "training_acc": 50.0, "val_loss": 0.7573780918121338, "val_acc": 48.0}
{"epoch": 29, "training_loss": 0.7305715489387512, "training_acc": 48.0, "val_loss": 0.6958668923377991, "val_acc": 48.0}
{"epoch": 30, "training_loss": 0.6958619976043701, "training_acc": 52.0, "val_loss": 0.753384485244751, "val_acc": 52.0}
{"epoch": 31, "training_loss": 0.743775281906128, "training_acc": 48.0, "val_loss": 0.7462734460830689, "val_acc": 48.0}
{"epoch": 32, "training_loss": 0.7739938616752624, "training_acc": 42.0, "val_loss": 0.7394221043586731, "val_acc": 48.0}
{"epoch": 33, "training_loss": 0.7848548889160156, "training_acc": 40.0, "val_loss": 0.8462331032752991, "val_acc": 48.0}
{"epoch": 34, "training_loss": 0.7756058645248413, "training_acc": 44.0, "val_loss": 0.6937161946296692, "val_acc": 48.0}
{"epoch": 35, "training_loss": 0.7289437174797058, "training_acc": 48.0, "val_loss": 0.695590443611145, "val_acc": 48.0}
{"epoch": 36, "training_loss": 0.6998909878730774, "training_acc": 50.0, "val_loss": 0.7753298807144166, "val_acc": 48.0}
{"epoch": 37, "training_loss": 0.7257826519012451, "training_acc": 48.0, "val_loss": 0.6953440046310425, "val_acc": 48.0}
{"epoch": 38, "training_loss": 0.7202568125724792, "training_acc": 46.0, "val_loss": 0.7570088696479798, "val_acc": 48.0}
{"epoch": 39, "training_loss": 0.7289766669273376, "training_acc": 46.0, "val_loss": 0.7133425521850586, "val_acc": 48.0}
{"epoch": 40, "training_loss": 0.732629747390747, "training_acc": 42.0, "val_loss": 0.7486581873893737, "val_acc": 48.0}
{"epoch": 41, "training_loss": 0.7492227983474732, "training_acc": 44.0, "val_loss": 0.715737669467926, "val_acc": 48.0}
{"epoch": 42, "training_loss": 0.7106542921066284, "training_acc": 46.0, "val_loss": 0.7420824813842773, "val_acc": 48.0}
{"epoch": 43, "training_loss": 0.7368503522872925, "training_acc": 52.0, "val_loss": 0.6923534798622132, "val_acc": 52.0}
{"epoch": 44, "training_loss": 0.763573784828186, "training_acc": 48.0, "val_loss": 0.6987285780906677, "val_acc": 52.0}
{"epoch": 45, "training_loss": 0.7262882685661316, "training_acc": 42.0, "val_loss": 0.6925197196006775, "val_acc": 52.0}
{"epoch": 46, "training_loss": 0.7311371040344238, "training_acc": 46.0, "val_loss": 0.6973830509185791, "val_acc": 52.0}
{"epoch": 47, "training_loss": 0.7085257697105408, "training_acc": 52.0, "val_loss": 0.7436559557914734, "val_acc": 48.0}
{"epoch": 48, "training_loss": 0.7404729390144348, "training_acc": 40.0, "val_loss": 0.722007577419281, "val_acc": 48.0}
{"epoch": 49, "training_loss": 0.7256488227844238, "training_acc": 54.0, "val_loss": 0.7300458073616027, "val_acc": 52.0}
{"epoch": 50, "training_loss": 0.7795500230789184, "training_acc": 46.0, "val_loss": 0.7252930879592896, "val_acc": 48.0}
{"epoch": 51, "training_loss": 0.7465138912200928, "training_acc": 36.0, "val_loss": 0.6940062427520752, "val_acc": 48.0}
{"epoch": 52, "training_loss": 0.6995006895065308, "training_acc": 52.0, "val_loss": 0.7284315490722656, "val_acc": 52.0}
{"epoch": 53, "training_loss": 0.7263640689849854, "training_acc": 52.0, "val_loss": 0.7783348822593689, "val_acc": 48.0}
{"epoch": 54, "training_loss": 0.74035888671875, "training_acc": 54.0, "val_loss": 0.7297160363197327, "val_acc": 52.0}
{"epoch": 55, "training_loss": 0.7558133172988891, "training_acc": 48.0, "val_loss": 0.7040563130378723, "val_acc": 48.0}
{"epoch": 56, "training_loss": 0.7048677921295166, "training_acc": 44.0, "val_loss": 0.6929606223106384, "val_acc": 52.0}
{"epoch": 57, "training_loss": 0.722879147529602, "training_acc": 44.0, "val_loss": 0.7215892863273621, "val_acc": 52.0}
{"epoch": 58, "training_loss": 0.7988479328155518, "training_acc": 52.0, "val_loss": 0.8755511903762817, "val_acc": 48.0}
{"epoch": 59, "training_loss": 0.8686033368110657, "training_acc": 48.0, "val_loss": 0.7001567149162292, "val_acc": 52.0}
{"epoch": 60, "training_loss": 0.7095053052902222, "training_acc": 50.0, "val_loss": 0.6962480425834656, "val_acc": 48.0}
{"epoch": 61, "training_loss": 0.7124445152282715, "training_acc": 48.0, "val_loss": 0.6973458099365234, "val_acc": 52.0}
{"epoch": 62, "training_loss": 0.7160789132118225, "training_acc": 48.0, "val_loss": 0.7025505352020264, "val_acc": 48.0}
