"main_modify.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 1 --task ADNI_sex --input_option yAware --learning_rate 1e-2 --batch_size 16 --weight_decay 1e-3 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 1.0922248673439026, "training_acc": 51.0, "val_loss": 0.7019541740417481, "val_acc": 48.0}
{"epoch": 1, "training_loss": 0.7796124005317688, "training_acc": 41.0, "val_loss": 0.7031599140167236, "val_acc": 48.0}
{"epoch": 2, "training_loss": 0.7078687214851379, "training_acc": 45.0, "val_loss": 0.7081234097480774, "val_acc": 48.0}
{"epoch": 3, "training_loss": 0.7134208989143371, "training_acc": 45.0, "val_loss": 0.6941410899162292, "val_acc": 52.0}
{"epoch": 4, "training_loss": 0.7006052422523499, "training_acc": 53.0, "val_loss": 1.0652469301223755, "val_acc": 48.0}
{"epoch": 5, "training_loss": 0.85469233751297, "training_acc": 47.0, "val_loss": 0.7376463389396668, "val_acc": 52.0}
{"epoch": 6, "training_loss": 0.7191590261459351, "training_acc": 45.0, "val_loss": 0.8374806141853333, "val_acc": 48.0}
{"epoch": 7, "training_loss": 0.7513043022155762, "training_acc": 43.0, "val_loss": 0.7936912107467652, "val_acc": 52.0}
{"epoch": 8, "training_loss": 0.8129066705703736, "training_acc": 49.0, "val_loss": 0.7650915932655334, "val_acc": 48.0}
{"epoch": 9, "training_loss": 0.7375060844421387, "training_acc": 51.0, "val_loss": 0.9725284743309021, "val_acc": 48.0}
{"epoch": 10, "training_loss": 0.9063115835189819, "training_acc": 49.0, "val_loss": 0.7135197281837463, "val_acc": 52.0}
{"epoch": 11, "training_loss": 0.7883048963546753, "training_acc": 45.0, "val_loss": 0.7367588615417481, "val_acc": 52.0}
{"epoch": 12, "training_loss": 0.735208375453949, "training_acc": 47.0, "val_loss": 0.6926855039596558, "val_acc": 52.0}
{"epoch": 13, "training_loss": 0.7201280212402343, "training_acc": 51.0, "val_loss": 0.716506896018982, "val_acc": 48.0}
{"epoch": 14, "training_loss": 0.6980585050582886, "training_acc": 47.0, "val_loss": 0.7275273585319519, "val_acc": 52.0}
{"epoch": 15, "training_loss": 0.7397111511230469, "training_acc": 45.0, "val_loss": 0.7372273302078247, "val_acc": 52.0}
{"epoch": 16, "training_loss": 0.7888340091705323, "training_acc": 41.0, "val_loss": 0.7461846160888672, "val_acc": 52.0}
{"epoch": 17, "training_loss": 0.7598915123939514, "training_acc": 43.0, "val_loss": 0.7039796876907348, "val_acc": 52.0}
{"epoch": 18, "training_loss": 0.7147156095504761, "training_acc": 47.0, "val_loss": 0.7156264948844909, "val_acc": 52.0}
{"epoch": 19, "training_loss": 0.791043541431427, "training_acc": 47.0, "val_loss": 0.6924752807617187, "val_acc": 52.0}
{"epoch": 20, "training_loss": 0.7047125959396362, "training_acc": 47.0, "val_loss": 0.6924175119400025, "val_acc": 52.0}
{"epoch": 21, "training_loss": 0.7030701971054077, "training_acc": 45.0, "val_loss": 0.7211447262763977, "val_acc": 48.0}
{"epoch": 22, "training_loss": 0.7406999778747558, "training_acc": 45.0, "val_loss": 0.9291508197784424, "val_acc": 48.0}
{"epoch": 23, "training_loss": 0.7808472800254822, "training_acc": 49.0, "val_loss": 0.6984880614280701, "val_acc": 52.0}
{"epoch": 24, "training_loss": 0.7256011629104614, "training_acc": 47.0, "val_loss": 0.6968200397491455, "val_acc": 48.0}
{"epoch": 25, "training_loss": 0.7380257844924927, "training_acc": 45.0, "val_loss": 0.6925581097602844, "val_acc": 52.0}
{"epoch": 26, "training_loss": 0.7001812219619751, "training_acc": 49.0, "val_loss": 0.693930811882019, "val_acc": 52.0}
{"epoch": 27, "training_loss": 0.7255544590950013, "training_acc": 49.0, "val_loss": 0.7587091851234437, "val_acc": 48.0}
{"epoch": 28, "training_loss": 0.725133843421936, "training_acc": 49.0, "val_loss": 0.7900794625282288, "val_acc": 48.0}
{"epoch": 29, "training_loss": 0.7593800592422485, "training_acc": 51.0, "val_loss": 0.7459026837348938, "val_acc": 52.0}
{"epoch": 30, "training_loss": 0.7434105491638183, "training_acc": 47.0, "val_loss": 0.7119911289215088, "val_acc": 48.0}
{"epoch": 31, "training_loss": 0.7185490202903747, "training_acc": 47.0, "val_loss": 0.7548809885978699, "val_acc": 48.0}
{"epoch": 32, "training_loss": 0.71196533203125, "training_acc": 51.0, "val_loss": 0.6989889907836914, "val_acc": 52.0}
{"epoch": 33, "training_loss": 0.7394330716133117, "training_acc": 51.0, "val_loss": 0.7008530116081237, "val_acc": 48.0}
{"epoch": 34, "training_loss": 0.7001566505432129, "training_acc": 51.0, "val_loss": 0.7012941455841064, "val_acc": 52.0}
{"epoch": 35, "training_loss": 0.7080764627456665, "training_acc": 49.0, "val_loss": 0.6945809268951416, "val_acc": 48.0}
{"epoch": 36, "training_loss": 0.6956959366798401, "training_acc": 51.0, "val_loss": 0.6931108808517457, "val_acc": 52.0}
{"epoch": 37, "training_loss": 0.6999519062042237, "training_acc": 49.0, "val_loss": 0.730508759021759, "val_acc": 48.0}
{"epoch": 38, "training_loss": 0.7275394368171691, "training_acc": 45.0, "val_loss": 0.6923499870300293, "val_acc": 52.0}
{"epoch": 39, "training_loss": 0.6981860470771789, "training_acc": 55.0, "val_loss": 0.7159821772575379, "val_acc": 48.0}
{"epoch": 40, "training_loss": 0.7082165813446045, "training_acc": 49.0, "val_loss": 0.7110874485969544, "val_acc": 48.0}
{"epoch": 41, "training_loss": 0.7657853174209595, "training_acc": 49.0, "val_loss": 0.6971433925628662, "val_acc": 52.0}
{"epoch": 42, "training_loss": 0.7127917456626892, "training_acc": 47.0, "val_loss": 0.7378449773788452, "val_acc": 52.0}
{"epoch": 43, "training_loss": 0.7313394641876221, "training_acc": 53.0, "val_loss": 0.8460462093353271, "val_acc": 48.0}
{"epoch": 44, "training_loss": 0.8948470973968505, "training_acc": 51.0, "val_loss": 0.8231783628463745, "val_acc": 52.0}
{"epoch": 45, "training_loss": 0.7825598907470703, "training_acc": 55.0, "val_loss": 0.9230017971992492, "val_acc": 48.0}
{"epoch": 46, "training_loss": 0.8817994689941406, "training_acc": 45.0, "val_loss": 0.7142408037185669, "val_acc": 52.0}
{"epoch": 47, "training_loss": 0.7033318090438843, "training_acc": 53.0, "val_loss": 0.7161435294151306, "val_acc": 48.0}
{"epoch": 48, "training_loss": 0.7406972289085388, "training_acc": 51.0, "val_loss": 0.8558585214614868, "val_acc": 48.0}
{"epoch": 49, "training_loss": 0.8567964768409729, "training_acc": 49.0, "val_loss": 0.7188605499267579, "val_acc": 52.0}
{"epoch": 50, "training_loss": 0.7202201557159423, "training_acc": 51.0, "val_loss": 0.6938366770744324, "val_acc": 48.0}
{"epoch": 51, "training_loss": 0.707411892414093, "training_acc": 49.0, "val_loss": 0.6923903107643128, "val_acc": 52.0}
{"epoch": 52, "training_loss": 0.7274345946311951, "training_acc": 47.0, "val_loss": 0.6923786640167237, "val_acc": 52.0}
{"epoch": 53, "training_loss": 0.7127692365646362, "training_acc": 53.0, "val_loss": 0.775880959033966, "val_acc": 48.0}
{"epoch": 54, "training_loss": 0.727775342464447, "training_acc": 47.0, "val_loss": 0.6923726010322571, "val_acc": 52.0}
{"epoch": 55, "training_loss": 0.7021184921264648, "training_acc": 43.0, "val_loss": 0.7211688685417176, "val_acc": 48.0}
{"epoch": 56, "training_loss": 0.7332608461380005, "training_acc": 51.0, "val_loss": 0.7252426886558533, "val_acc": 52.0}
{"epoch": 57, "training_loss": 0.7392257213592529, "training_acc": 47.0, "val_loss": 0.7189186096191407, "val_acc": 48.0}
