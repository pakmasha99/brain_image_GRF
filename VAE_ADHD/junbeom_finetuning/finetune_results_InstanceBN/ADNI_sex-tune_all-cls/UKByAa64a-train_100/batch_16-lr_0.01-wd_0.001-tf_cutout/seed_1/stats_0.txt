"main_modify.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 1 --task ADNI_sex --input_option yAware --learning_rate 1e-2 --batch_size 16 --weight_decay 1e-3 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 1.2154617524147033, "training_acc": 46.0, "val_loss": 0.8616012597084045, "val_acc": 48.0}
{"epoch": 1, "training_loss": 0.7681314373016357, "training_acc": 54.0, "val_loss": 0.9012660956382752, "val_acc": 48.0}
{"epoch": 2, "training_loss": 0.8593388080596924, "training_acc": 50.0, "val_loss": 0.7488563251495362, "val_acc": 52.0}
{"epoch": 3, "training_loss": 0.7442594909667969, "training_acc": 54.0, "val_loss": 0.7116681408882141, "val_acc": 48.0}
{"epoch": 4, "training_loss": 0.7762501072883606, "training_acc": 48.0, "val_loss": 0.7761794447898864, "val_acc": 48.0}
{"epoch": 5, "training_loss": 0.7237648057937622, "training_acc": 54.0, "val_loss": 0.7502234864234925, "val_acc": 52.0}
{"epoch": 6, "training_loss": 0.8026715207099915, "training_acc": 40.0, "val_loss": 0.7410299777984619, "val_acc": 52.0}
{"epoch": 7, "training_loss": 0.708603401184082, "training_acc": 56.0, "val_loss": 0.7383891725540161, "val_acc": 48.0}
{"epoch": 8, "training_loss": 0.7400874447822571, "training_acc": 47.0, "val_loss": 0.7043378043174744, "val_acc": 48.0}
{"epoch": 9, "training_loss": 0.7054695916175843, "training_acc": 52.0, "val_loss": 0.6937541937828064, "val_acc": 52.0}
{"epoch": 10, "training_loss": 0.7109030914306641, "training_acc": 56.0, "val_loss": 0.6948118472099304, "val_acc": 48.0}
{"epoch": 11, "training_loss": 0.7170406579971313, "training_acc": 42.0, "val_loss": 0.7036598706245423, "val_acc": 48.0}
{"epoch": 12, "training_loss": 0.7308561277389526, "training_acc": 44.0, "val_loss": 0.69319251537323, "val_acc": 52.0}
{"epoch": 13, "training_loss": 0.7115029978752136, "training_acc": 42.0, "val_loss": 0.8646821188926697, "val_acc": 52.0}
{"epoch": 14, "training_loss": 0.8304077243804932, "training_acc": 50.0, "val_loss": 0.7119300246238709, "val_acc": 48.0}
{"epoch": 15, "training_loss": 0.6767218351364136, "training_acc": 60.0, "val_loss": 0.7510143351554871, "val_acc": 52.0}
{"epoch": 16, "training_loss": 0.7747208404541016, "training_acc": 50.0, "val_loss": 0.7044765210151672, "val_acc": 52.0}
{"epoch": 17, "training_loss": 0.711434326171875, "training_acc": 50.0, "val_loss": 0.7157972383499146, "val_acc": 52.0}
{"epoch": 18, "training_loss": 0.7125930070877076, "training_acc": 56.0, "val_loss": 0.9226906871795655, "val_acc": 48.0}
{"epoch": 19, "training_loss": 0.8373059582710266, "training_acc": 44.0, "val_loss": 0.7283759903907776, "val_acc": 48.0}
{"epoch": 20, "training_loss": 0.8171112537384033, "training_acc": 46.0, "val_loss": 0.7020455193519592, "val_acc": 52.0}
{"epoch": 21, "training_loss": 0.762754135131836, "training_acc": 46.0, "val_loss": 0.6924448037147521, "val_acc": 52.0}
{"epoch": 22, "training_loss": 0.7204912686347962, "training_acc": 48.0, "val_loss": 0.7190007519721985, "val_acc": 52.0}
{"epoch": 23, "training_loss": 0.7517620134353638, "training_acc": 42.0, "val_loss": 0.7008897471427917, "val_acc": 52.0}
{"epoch": 24, "training_loss": 0.7081232333183288, "training_acc": 58.0, "val_loss": 1.1736596155166625, "val_acc": 48.0}
{"epoch": 25, "training_loss": 0.9725301146507264, "training_acc": 40.0, "val_loss": 0.7092836475372315, "val_acc": 48.0}
{"epoch": 26, "training_loss": 0.7190608882904053, "training_acc": 44.0, "val_loss": 0.7770816683769226, "val_acc": 48.0}
{"epoch": 27, "training_loss": 0.7057339477539063, "training_acc": 54.0, "val_loss": 0.8312911272048951, "val_acc": 52.0}
{"epoch": 28, "training_loss": 0.8277947330474853, "training_acc": 52.0, "val_loss": 0.856517825126648, "val_acc": 48.0}
{"epoch": 29, "training_loss": 0.741952257156372, "training_acc": 56.0, "val_loss": 0.813136670589447, "val_acc": 52.0}
{"epoch": 30, "training_loss": 0.793471965789795, "training_acc": 46.0, "val_loss": 0.6960745477676391, "val_acc": 48.0}
{"epoch": 31, "training_loss": 0.7003925132751465, "training_acc": 50.0, "val_loss": 0.7009647536277771, "val_acc": 52.0}
{"epoch": 32, "training_loss": 0.7055482292175292, "training_acc": 48.0, "val_loss": 0.7324813890457154, "val_acc": 48.0}
{"epoch": 33, "training_loss": 0.7608739709854127, "training_acc": 50.0, "val_loss": 0.6928193879127502, "val_acc": 52.0}
{"epoch": 34, "training_loss": 0.7662027049064636, "training_acc": 52.0, "val_loss": 0.7048873376846313, "val_acc": 52.0}
{"epoch": 35, "training_loss": 0.736032600402832, "training_acc": 50.0, "val_loss": 0.6953820848464966, "val_acc": 48.0}
{"epoch": 36, "training_loss": 0.7360500907897949, "training_acc": 46.0, "val_loss": 0.6940140271186829, "val_acc": 48.0}
{"epoch": 37, "training_loss": 0.7117693758010865, "training_acc": 46.0, "val_loss": 0.6999229454994201, "val_acc": 48.0}
{"epoch": 38, "training_loss": 0.7044470143318177, "training_acc": 50.0, "val_loss": 0.6926257228851318, "val_acc": 52.0}
{"epoch": 39, "training_loss": 0.6977564001083374, "training_acc": 46.0, "val_loss": 0.6934956383705139, "val_acc": 52.0}
{"epoch": 40, "training_loss": 0.7109851360321044, "training_acc": 44.0, "val_loss": 0.6928115558624267, "val_acc": 52.0}
