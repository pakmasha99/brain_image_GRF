"main_modify.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 4 --task ADNI_sex --input_option yAware --learning_rate 1e-2 --batch_size 16 --weight_decay 1e-3 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 1.1181531143188477, "training_acc": 52.0, "val_loss": 0.9410475778579712, "val_acc": 52.0}
{"epoch": 1, "training_loss": 0.826204309463501, "training_acc": 50.0, "val_loss": 0.692691695690155, "val_acc": 52.0}
{"epoch": 2, "training_loss": 0.6979344296455383, "training_acc": 44.0, "val_loss": 0.8016243147850036, "val_acc": 52.0}
{"epoch": 3, "training_loss": 0.810218493938446, "training_acc": 50.0, "val_loss": 0.7153082847595215, "val_acc": 48.0}
{"epoch": 4, "training_loss": 0.718484902381897, "training_acc": 54.0, "val_loss": 1.178394546508789, "val_acc": 48.0}
{"epoch": 5, "training_loss": 0.9969894933700562, "training_acc": 48.0, "val_loss": 0.7235471844673157, "val_acc": 52.0}
{"epoch": 6, "training_loss": 0.782793755531311, "training_acc": 46.0, "val_loss": 0.8727779221534729, "val_acc": 52.0}
{"epoch": 7, "training_loss": 0.7773494005203248, "training_acc": 52.0, "val_loss": 0.6966982746124267, "val_acc": 48.0}
{"epoch": 8, "training_loss": 0.7628564405441284, "training_acc": 44.0, "val_loss": 0.7523024773597717, "val_acc": 48.0}
{"epoch": 9, "training_loss": 0.7165515303611756, "training_acc": 50.0, "val_loss": 0.7187358570098877, "val_acc": 48.0}
{"epoch": 10, "training_loss": 0.7557664203643799, "training_acc": 48.0, "val_loss": 0.8647303032875061, "val_acc": 48.0}
{"epoch": 11, "training_loss": 0.7830703043937683, "training_acc": 52.0, "val_loss": 0.770287172794342, "val_acc": 52.0}
{"epoch": 12, "training_loss": 0.7195633840560913, "training_acc": 54.0, "val_loss": 0.7095160031318665, "val_acc": 52.0}
{"epoch": 13, "training_loss": 0.74945885181427, "training_acc": 52.0, "val_loss": 0.7597680234909058, "val_acc": 48.0}
{"epoch": 14, "training_loss": 0.8059344816207886, "training_acc": 38.0, "val_loss": 0.6938556075096131, "val_acc": 52.0}
{"epoch": 15, "training_loss": 0.7175487327575684, "training_acc": 50.0, "val_loss": 0.783242154121399, "val_acc": 48.0}
{"epoch": 16, "training_loss": 0.8253903865814209, "training_acc": 40.0, "val_loss": 0.7551044464111328, "val_acc": 48.0}
{"epoch": 17, "training_loss": 0.7136280727386475, "training_acc": 54.0, "val_loss": 0.9746354818344116, "val_acc": 52.0}
{"epoch": 18, "training_loss": 0.9832649087905884, "training_acc": 38.0, "val_loss": 0.7588117599487305, "val_acc": 52.0}
{"epoch": 19, "training_loss": 0.7836067914962769, "training_acc": 46.0, "val_loss": 0.692415497303009, "val_acc": 52.0}
{"epoch": 20, "training_loss": 0.7001794910430909, "training_acc": 46.0, "val_loss": 0.7223535251617431, "val_acc": 52.0}
{"epoch": 21, "training_loss": 0.720624008178711, "training_acc": 50.0, "val_loss": 0.6925118350982666, "val_acc": 52.0}
{"epoch": 22, "training_loss": 0.7027774381637574, "training_acc": 60.0, "val_loss": 1.0108584451675415, "val_acc": 48.0}
{"epoch": 23, "training_loss": 0.8636491346359253, "training_acc": 52.0, "val_loss": 0.7979550218582153, "val_acc": 52.0}
{"epoch": 24, "training_loss": 0.7512189674377442, "training_acc": 52.0, "val_loss": 0.6966002774238587, "val_acc": 52.0}
{"epoch": 25, "training_loss": 0.7213254570960999, "training_acc": 46.0, "val_loss": 0.6981512022018432, "val_acc": 48.0}
{"epoch": 26, "training_loss": 0.6904292464256286, "training_acc": 54.0, "val_loss": 0.8090076971054078, "val_acc": 52.0}
{"epoch": 27, "training_loss": 0.7556767988204957, "training_acc": 50.0, "val_loss": 0.6923805522918701, "val_acc": 52.0}
{"epoch": 28, "training_loss": 0.7150457859039306, "training_acc": 40.0, "val_loss": 0.8411542177200317, "val_acc": 52.0}
{"epoch": 29, "training_loss": 0.7719452333450317, "training_acc": 50.0, "val_loss": 0.7444357252120972, "val_acc": 48.0}
{"epoch": 30, "training_loss": 0.705689651966095, "training_acc": 52.0, "val_loss": 0.7613304018974304, "val_acc": 52.0}
{"epoch": 31, "training_loss": 0.7687682151794434, "training_acc": 40.0, "val_loss": 0.752101788520813, "val_acc": 48.0}
{"epoch": 32, "training_loss": 0.7419814109802246, "training_acc": 50.0, "val_loss": 0.7560243320465088, "val_acc": 52.0}
{"epoch": 33, "training_loss": 0.723262541294098, "training_acc": 50.0, "val_loss": 0.7696864581108094, "val_acc": 48.0}
{"epoch": 34, "training_loss": 0.7103016114234925, "training_acc": 50.0, "val_loss": 0.6925539779663086, "val_acc": 52.0}
{"epoch": 35, "training_loss": 0.7150536918640137, "training_acc": 42.0, "val_loss": 0.7184282255172729, "val_acc": 52.0}
{"epoch": 36, "training_loss": 0.7345761823654174, "training_acc": 50.0, "val_loss": 0.9478687500953674, "val_acc": 48.0}
{"epoch": 37, "training_loss": 0.8084394526481629, "training_acc": 48.0, "val_loss": 0.7171666431427002, "val_acc": 48.0}
{"epoch": 38, "training_loss": 0.7649802923202514, "training_acc": 50.0, "val_loss": 0.7150424933433532, "val_acc": 52.0}
{"epoch": 39, "training_loss": 0.7375729060173035, "training_acc": 52.0, "val_loss": 0.8605454301834107, "val_acc": 52.0}
{"epoch": 40, "training_loss": 0.8394073963165283, "training_acc": 40.0, "val_loss": 0.7196528744697571, "val_acc": 48.0}
{"epoch": 41, "training_loss": 0.7226122808456421, "training_acc": 50.0, "val_loss": 0.7041152167320252, "val_acc": 48.0}
{"epoch": 42, "training_loss": 0.7051365613937378, "training_acc": 46.0, "val_loss": 0.7035466122627259, "val_acc": 52.0}
{"epoch": 43, "training_loss": 0.7752993178367614, "training_acc": 52.0, "val_loss": 0.7159405875205994, "val_acc": 48.0}
{"epoch": 44, "training_loss": 0.7156453657150269, "training_acc": 52.0, "val_loss": 0.6941119313240052, "val_acc": 48.0}
{"epoch": 45, "training_loss": 0.7046892213821411, "training_acc": 50.0, "val_loss": 0.7146941041946411, "val_acc": 48.0}
{"epoch": 46, "training_loss": 0.7423396873474121, "training_acc": 56.0, "val_loss": 0.7499298119544983, "val_acc": 52.0}
