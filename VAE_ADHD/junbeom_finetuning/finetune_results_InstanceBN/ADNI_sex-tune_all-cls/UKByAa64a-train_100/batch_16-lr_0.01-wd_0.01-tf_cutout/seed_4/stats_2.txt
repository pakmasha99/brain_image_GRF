"main_modify.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 4 --task ADNI_sex --input_option yAware --learning_rate 1e-2 --batch_size 16 --weight_decay 1e-2 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 1.0567978286743165, "training_acc": 52.0, "val_loss": 0.8414207005500793, "val_acc": 48.0}
{"epoch": 1, "training_loss": 0.822971076965332, "training_acc": 44.0, "val_loss": 0.8854832434654236, "val_acc": 48.0}
{"epoch": 2, "training_loss": 0.7744341802597046, "training_acc": 46.0, "val_loss": 0.7866947293281555, "val_acc": 48.0}
{"epoch": 3, "training_loss": 0.8132484769821167, "training_acc": 44.0, "val_loss": 0.6944752717018128, "val_acc": 52.0}
{"epoch": 4, "training_loss": 0.7203461217880249, "training_acc": 56.0, "val_loss": 1.081251678466797, "val_acc": 48.0}
{"epoch": 5, "training_loss": 0.8596725559234619, "training_acc": 46.0, "val_loss": 0.8375939273834229, "val_acc": 52.0}
{"epoch": 6, "training_loss": 0.8326384496688842, "training_acc": 44.0, "val_loss": 0.6935866212844849, "val_acc": 52.0}
{"epoch": 7, "training_loss": 0.7141616511344909, "training_acc": 50.0, "val_loss": 0.7064152264595032, "val_acc": 48.0}
{"epoch": 8, "training_loss": 0.6988655161857605, "training_acc": 52.0, "val_loss": 0.7393632173538208, "val_acc": 52.0}
{"epoch": 9, "training_loss": 0.7433702182769776, "training_acc": 42.0, "val_loss": 0.6923863339424133, "val_acc": 52.0}
{"epoch": 10, "training_loss": 0.7084911727905273, "training_acc": 54.0, "val_loss": 0.6929651188850403, "val_acc": 52.0}
{"epoch": 11, "training_loss": 0.72754967212677, "training_acc": 46.0, "val_loss": 0.7101021337509156, "val_acc": 52.0}
{"epoch": 12, "training_loss": 0.7200895118713379, "training_acc": 54.0, "val_loss": 0.7747379422187806, "val_acc": 48.0}
{"epoch": 13, "training_loss": 0.8068465971946717, "training_acc": 48.0, "val_loss": 0.8175255799293518, "val_acc": 48.0}
{"epoch": 14, "training_loss": 0.7976685953140259, "training_acc": 46.0, "val_loss": 0.7206659078598022, "val_acc": 52.0}
{"epoch": 15, "training_loss": 0.7369113445281983, "training_acc": 54.0, "val_loss": 0.8393645405769348, "val_acc": 52.0}
{"epoch": 16, "training_loss": 0.8523201870918274, "training_acc": 46.0, "val_loss": 0.694666645526886, "val_acc": 48.0}
{"epoch": 17, "training_loss": 0.7054939365386963, "training_acc": 54.0, "val_loss": 0.8370360279083252, "val_acc": 48.0}
{"epoch": 18, "training_loss": 0.7282327151298523, "training_acc": 56.0, "val_loss": 0.7558526921272278, "val_acc": 52.0}
{"epoch": 19, "training_loss": 0.7526132392883301, "training_acc": 50.0, "val_loss": 0.7083625221252441, "val_acc": 48.0}
{"epoch": 20, "training_loss": 0.6975357007980346, "training_acc": 50.0, "val_loss": 0.6927759671211242, "val_acc": 52.0}
{"epoch": 21, "training_loss": 0.7061877393722534, "training_acc": 46.0, "val_loss": 0.696295018196106, "val_acc": 48.0}
{"epoch": 22, "training_loss": 0.7036357808113098, "training_acc": 42.0, "val_loss": 0.7050892615318298, "val_acc": 48.0}
{"epoch": 23, "training_loss": 0.7050853800773621, "training_acc": 46.0, "val_loss": 0.6923472642898559, "val_acc": 52.0}
{"epoch": 24, "training_loss": 0.7250621581077575, "training_acc": 38.0, "val_loss": 0.7469372224807739, "val_acc": 52.0}
{"epoch": 25, "training_loss": 0.7667773962020874, "training_acc": 48.0, "val_loss": 0.707326819896698, "val_acc": 48.0}
{"epoch": 26, "training_loss": 0.7056948804855346, "training_acc": 44.0, "val_loss": 0.7159595036506653, "val_acc": 48.0}
{"epoch": 27, "training_loss": 0.7145046353340149, "training_acc": 44.0, "val_loss": 0.6991662621498108, "val_acc": 48.0}
{"epoch": 28, "training_loss": 0.7073945760726928, "training_acc": 44.0, "val_loss": 0.6993175125122071, "val_acc": 48.0}
{"epoch": 29, "training_loss": 0.702383303642273, "training_acc": 44.0, "val_loss": 0.7382363843917846, "val_acc": 48.0}
{"epoch": 30, "training_loss": 0.7196747422218323, "training_acc": 50.0, "val_loss": 0.6987490391731263, "val_acc": 52.0}
{"epoch": 31, "training_loss": 0.7223740100860596, "training_acc": 52.0, "val_loss": 0.7790981078147888, "val_acc": 48.0}
{"epoch": 32, "training_loss": 0.7920659065246582, "training_acc": 54.0, "val_loss": 0.8050795698165893, "val_acc": 52.0}
{"epoch": 33, "training_loss": 0.8928658866882324, "training_acc": 50.0, "val_loss": 0.7021476411819458, "val_acc": 48.0}
{"epoch": 34, "training_loss": 0.7908967351913452, "training_acc": 46.0, "val_loss": 0.7060255742073059, "val_acc": 48.0}
{"epoch": 35, "training_loss": 0.7020957612991333, "training_acc": 50.0, "val_loss": 0.6987034344673156, "val_acc": 52.0}
{"epoch": 36, "training_loss": 0.7060236024856568, "training_acc": 48.0, "val_loss": 0.6923693656921387, "val_acc": 52.0}
{"epoch": 37, "training_loss": 0.7091953372955322, "training_acc": 46.0, "val_loss": 0.7502561235427856, "val_acc": 48.0}
{"epoch": 38, "training_loss": 0.7406306838989258, "training_acc": 48.0, "val_loss": 0.7381842923164368, "val_acc": 52.0}
{"epoch": 39, "training_loss": 0.7183030939102173, "training_acc": 50.0, "val_loss": 0.7146435523033142, "val_acc": 48.0}
{"epoch": 40, "training_loss": 0.7051872515678406, "training_acc": 48.0, "val_loss": 0.7110893750190734, "val_acc": 52.0}
{"epoch": 41, "training_loss": 0.7261926698684692, "training_acc": 44.0, "val_loss": 0.6923969578742981, "val_acc": 52.0}
{"epoch": 42, "training_loss": 0.7085988759994507, "training_acc": 46.0, "val_loss": 0.7320161032676696, "val_acc": 52.0}
