"main_modify.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 4 --task ADNI_sex --input_option yAware --learning_rate 1e-2 --batch_size 16 --weight_decay 1e-2 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 1.3382515907287598, "training_acc": 52.0, "val_loss": 0.7231006097793579, "val_acc": 52.0}
{"epoch": 1, "training_loss": 0.7360510158538819, "training_acc": 42.0, "val_loss": 0.8242443943023682, "val_acc": 48.0}
{"epoch": 2, "training_loss": 0.7837918615341186, "training_acc": 40.0, "val_loss": 0.6967216801643371, "val_acc": 52.0}
{"epoch": 3, "training_loss": 0.7228047299385071, "training_acc": 46.0, "val_loss": 0.7059059000015259, "val_acc": 52.0}
{"epoch": 4, "training_loss": 0.7637223482131958, "training_acc": 46.0, "val_loss": 0.7002088475227356, "val_acc": 48.0}
{"epoch": 5, "training_loss": 0.741711745262146, "training_acc": 46.0, "val_loss": 0.727655963897705, "val_acc": 52.0}
{"epoch": 6, "training_loss": 0.7315333318710328, "training_acc": 46.0, "val_loss": 0.692490508556366, "val_acc": 52.0}
{"epoch": 7, "training_loss": 0.7269614934921265, "training_acc": 48.0, "val_loss": 0.8292669796943665, "val_acc": 52.0}
{"epoch": 8, "training_loss": 0.7693861246109008, "training_acc": 48.0, "val_loss": 0.7289459562301636, "val_acc": 52.0}
{"epoch": 9, "training_loss": 0.7618480610847473, "training_acc": 46.0, "val_loss": 0.7141322350502014, "val_acc": 52.0}
{"epoch": 10, "training_loss": 0.7811991167068482, "training_acc": 50.0, "val_loss": 0.709235873222351, "val_acc": 48.0}
{"epoch": 11, "training_loss": 0.7419313907623291, "training_acc": 56.0, "val_loss": 0.694338607788086, "val_acc": 48.0}
{"epoch": 12, "training_loss": 0.7034605550765991, "training_acc": 44.0, "val_loss": 0.7959058499336242, "val_acc": 48.0}
{"epoch": 13, "training_loss": 0.7471528363227844, "training_acc": 48.0, "val_loss": 0.9366013813018799, "val_acc": 48.0}
{"epoch": 14, "training_loss": 0.7853822541236878, "training_acc": 50.0, "val_loss": 0.6928861927986145, "val_acc": 52.0}
{"epoch": 15, "training_loss": 0.7401464653015136, "training_acc": 46.0, "val_loss": 0.7003710484504699, "val_acc": 48.0}
{"epoch": 16, "training_loss": 0.7140840196609497, "training_acc": 46.0, "val_loss": 0.6927833104133606, "val_acc": 52.0}
{"epoch": 17, "training_loss": 0.7275021958351136, "training_acc": 44.0, "val_loss": 0.8110413980484009, "val_acc": 48.0}
{"epoch": 18, "training_loss": 0.7627112197875977, "training_acc": 50.0, "val_loss": 0.7226200389862061, "val_acc": 52.0}
{"epoch": 19, "training_loss": 0.7190523099899292, "training_acc": 48.0, "val_loss": 0.704337146282196, "val_acc": 48.0}
{"epoch": 20, "training_loss": 0.7134125113487244, "training_acc": 48.0, "val_loss": 0.7138058948516846, "val_acc": 48.0}
{"epoch": 21, "training_loss": 0.7398129892349243, "training_acc": 50.0, "val_loss": 0.7023438954353333, "val_acc": 52.0}
{"epoch": 22, "training_loss": 0.7077973318099976, "training_acc": 50.0, "val_loss": 0.6924941205978393, "val_acc": 52.0}
{"epoch": 23, "training_loss": 0.7150809717178345, "training_acc": 44.0, "val_loss": 0.6923496174812317, "val_acc": 52.0}
{"epoch": 24, "training_loss": 0.7044307541847229, "training_acc": 50.0, "val_loss": 0.701775667667389, "val_acc": 48.0}
{"epoch": 25, "training_loss": 0.7091324710845948, "training_acc": 40.0, "val_loss": 0.6983361363410949, "val_acc": 48.0}
{"epoch": 26, "training_loss": 0.7002363967895507, "training_acc": 48.0, "val_loss": 0.6970195579528808, "val_acc": 48.0}
{"epoch": 27, "training_loss": 0.7082232213020325, "training_acc": 44.0, "val_loss": 0.6927961659431457, "val_acc": 52.0}
{"epoch": 28, "training_loss": 0.7097941541671753, "training_acc": 38.0, "val_loss": 0.6975392460823059, "val_acc": 52.0}
{"epoch": 29, "training_loss": 0.7190842151641845, "training_acc": 52.0, "val_loss": 0.7559806632995606, "val_acc": 48.0}
{"epoch": 30, "training_loss": 0.7409719705581665, "training_acc": 44.0, "val_loss": 0.6991671323776245, "val_acc": 48.0}
{"epoch": 31, "training_loss": 0.7073285579681396, "training_acc": 48.0, "val_loss": 0.7128523230552674, "val_acc": 48.0}
{"epoch": 32, "training_loss": 0.7087400388717652, "training_acc": 44.0, "val_loss": 0.7152031540870667, "val_acc": 48.0}
{"epoch": 33, "training_loss": 0.718874990940094, "training_acc": 50.0, "val_loss": 0.6954520630836487, "val_acc": 52.0}
{"epoch": 34, "training_loss": 0.7192831921577454, "training_acc": 50.0, "val_loss": 0.7575712728500367, "val_acc": 48.0}
{"epoch": 35, "training_loss": 0.7513647270202637, "training_acc": 42.0, "val_loss": 0.6991887831687927, "val_acc": 48.0}
{"epoch": 36, "training_loss": 0.6986995100975036, "training_acc": 46.0, "val_loss": 0.7577334141731262, "val_acc": 48.0}
{"epoch": 37, "training_loss": 0.7036741161346436, "training_acc": 56.0, "val_loss": 0.8483119654655457, "val_acc": 52.0}
{"epoch": 38, "training_loss": 0.8045146942138672, "training_acc": 52.0, "val_loss": 0.9696468925476074, "val_acc": 48.0}
{"epoch": 39, "training_loss": 0.900421199798584, "training_acc": 44.0, "val_loss": 0.756526174545288, "val_acc": 52.0}
{"epoch": 40, "training_loss": 0.718315668106079, "training_acc": 54.0, "val_loss": 0.7187960028648377, "val_acc": 48.0}
{"epoch": 41, "training_loss": 0.7032406806945801, "training_acc": 50.0, "val_loss": 0.6963582611083985, "val_acc": 48.0}
{"epoch": 42, "training_loss": 0.6962203121185303, "training_acc": 48.0, "val_loss": 0.7085790944099426, "val_acc": 48.0}
