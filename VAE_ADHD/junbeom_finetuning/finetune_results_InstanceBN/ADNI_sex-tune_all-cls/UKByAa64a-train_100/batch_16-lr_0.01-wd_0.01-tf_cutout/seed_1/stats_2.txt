"main_modify.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 1 --task ADNI_sex --input_option yAware --learning_rate 1e-2 --batch_size 16 --weight_decay 1e-2 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 1.0113880920410157, "training_acc": 52.0, "val_loss": 0.7046307587623596, "val_acc": 48.0}
{"epoch": 1, "training_loss": 0.7491269540786744, "training_acc": 52.0, "val_loss": 0.966362156867981, "val_acc": 52.0}
{"epoch": 2, "training_loss": 0.8827630162239075, "training_acc": 42.0, "val_loss": 0.8812800693511963, "val_acc": 52.0}
{"epoch": 3, "training_loss": 0.8334569454193115, "training_acc": 54.0, "val_loss": 0.8062535524368286, "val_acc": 48.0}
{"epoch": 4, "training_loss": 0.7007744669914245, "training_acc": 54.0, "val_loss": 0.7621089506149292, "val_acc": 52.0}
{"epoch": 5, "training_loss": 0.7351130962371826, "training_acc": 48.0, "val_loss": 0.7292311024665833, "val_acc": 48.0}
{"epoch": 6, "training_loss": 0.7277938890457153, "training_acc": 38.0, "val_loss": 0.7247675657272339, "val_acc": 52.0}
{"epoch": 7, "training_loss": 0.7263683223724365, "training_acc": 52.0, "val_loss": 0.7020786905288696, "val_acc": 52.0}
{"epoch": 8, "training_loss": 0.7309163975715637, "training_acc": 52.0, "val_loss": 0.8623128080368042, "val_acc": 48.0}
{"epoch": 9, "training_loss": 0.756546721458435, "training_acc": 44.0, "val_loss": 0.81017742395401, "val_acc": 52.0}
{"epoch": 10, "training_loss": 0.7691808390617371, "training_acc": 46.0, "val_loss": 0.7162624287605286, "val_acc": 48.0}
{"epoch": 11, "training_loss": 0.7515102887153625, "training_acc": 50.0, "val_loss": 0.7033825421333313, "val_acc": 52.0}
{"epoch": 12, "training_loss": 0.7143170809745789, "training_acc": 46.0, "val_loss": 0.7280060005187988, "val_acc": 52.0}
{"epoch": 13, "training_loss": 0.7374236273765564, "training_acc": 46.0, "val_loss": 0.7076644158363342, "val_acc": 48.0}
{"epoch": 14, "training_loss": 0.7025610613822937, "training_acc": 50.0, "val_loss": 0.6949936699867248, "val_acc": 48.0}
{"epoch": 15, "training_loss": 0.7229304122924805, "training_acc": 38.0, "val_loss": 0.7109986114501953, "val_acc": 48.0}
{"epoch": 16, "training_loss": 0.7022805213928223, "training_acc": 50.0, "val_loss": 0.696183660030365, "val_acc": 52.0}
{"epoch": 17, "training_loss": 0.7101648068428039, "training_acc": 56.0, "val_loss": 0.8422594499588013, "val_acc": 48.0}
{"epoch": 18, "training_loss": 0.782804069519043, "training_acc": 46.0, "val_loss": 0.6947131013870239, "val_acc": 48.0}
{"epoch": 19, "training_loss": 0.7049442052841186, "training_acc": 50.0, "val_loss": 0.7401572895050049, "val_acc": 48.0}
{"epoch": 20, "training_loss": 0.7343590450286865, "training_acc": 50.0, "val_loss": 0.7170273685455322, "val_acc": 52.0}
{"epoch": 21, "training_loss": 0.7331838798522949, "training_acc": 48.0, "val_loss": 0.6933096814155578, "val_acc": 48.0}
{"epoch": 22, "training_loss": 0.6998313617706299, "training_acc": 44.0, "val_loss": 0.7051257920265198, "val_acc": 52.0}
{"epoch": 23, "training_loss": 0.7371243524551392, "training_acc": 44.0, "val_loss": 0.6955497121810913, "val_acc": 52.0}
{"epoch": 24, "training_loss": 0.715071997642517, "training_acc": 52.0, "val_loss": 0.759721326828003, "val_acc": 48.0}
{"epoch": 25, "training_loss": 0.7614720368385315, "training_acc": 46.0, "val_loss": 0.6923681759834289, "val_acc": 52.0}
{"epoch": 26, "training_loss": 0.7227666807174683, "training_acc": 42.0, "val_loss": 0.6924996638298034, "val_acc": 52.0}
{"epoch": 27, "training_loss": 0.7197316884994507, "training_acc": 50.0, "val_loss": 0.7174790692329407, "val_acc": 48.0}
{"epoch": 28, "training_loss": 0.7153345203399658, "training_acc": 50.0, "val_loss": 0.6925232076644897, "val_acc": 52.0}
{"epoch": 29, "training_loss": 0.7275872611999512, "training_acc": 38.0, "val_loss": 0.6923973441123963, "val_acc": 52.0}
{"epoch": 30, "training_loss": 0.7127511119842529, "training_acc": 48.0, "val_loss": 0.7593930840492249, "val_acc": 48.0}
{"epoch": 31, "training_loss": 0.724952220916748, "training_acc": 50.0, "val_loss": 0.6924691724777222, "val_acc": 52.0}
{"epoch": 32, "training_loss": 0.714806900024414, "training_acc": 44.0, "val_loss": 0.7612329077720642, "val_acc": 52.0}
{"epoch": 33, "training_loss": 0.7680285477638245, "training_acc": 50.0, "val_loss": 0.767194972038269, "val_acc": 48.0}
{"epoch": 34, "training_loss": 0.7307990217208862, "training_acc": 50.0, "val_loss": 0.7045172023773193, "val_acc": 52.0}
{"epoch": 35, "training_loss": 0.7095758104324341, "training_acc": 50.0, "val_loss": 0.7381243944168091, "val_acc": 48.0}
{"epoch": 36, "training_loss": 0.7252132439613342, "training_acc": 50.0, "val_loss": 0.7013771867752076, "val_acc": 52.0}
{"epoch": 37, "training_loss": 0.7087827777862549, "training_acc": 52.0, "val_loss": 0.8054516291618348, "val_acc": 48.0}
{"epoch": 38, "training_loss": 0.7353537487983703, "training_acc": 52.0, "val_loss": 0.7959063005447388, "val_acc": 52.0}
{"epoch": 39, "training_loss": 0.7586824178695679, "training_acc": 54.0, "val_loss": 0.7161626434326172, "val_acc": 48.0}
{"epoch": 40, "training_loss": 0.7082849025726319, "training_acc": 50.0, "val_loss": 0.7029175543785096, "val_acc": 52.0}
{"epoch": 41, "training_loss": 0.7092265939712524, "training_acc": 48.0, "val_loss": 0.6930393052101135, "val_acc": 52.0}
{"epoch": 42, "training_loss": 0.7260405588150024, "training_acc": 44.0, "val_loss": 0.695356023311615, "val_acc": 52.0}
{"epoch": 43, "training_loss": 0.69439697265625, "training_acc": 52.0, "val_loss": 0.6969661259651184, "val_acc": 48.0}
{"epoch": 44, "training_loss": 0.7118293261528015, "training_acc": 46.0, "val_loss": 0.7424043154716492, "val_acc": 48.0}
