"main_modify.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 1 --task ADNI_sex --input_option yAware --learning_rate 1e-2 --batch_size 16 --weight_decay 1e-2 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 1.209488298892975, "training_acc": 46.0, "val_loss": 0.8347722172737122, "val_acc": 48.0}
{"epoch": 1, "training_loss": 0.757792854309082, "training_acc": 54.0, "val_loss": 0.8797171711921692, "val_acc": 48.0}
{"epoch": 2, "training_loss": 0.8026197957992554, "training_acc": 50.0, "val_loss": 0.6963275146484375, "val_acc": 52.0}
{"epoch": 3, "training_loss": 0.7672358679771424, "training_acc": 50.0, "val_loss": 0.6994901752471924, "val_acc": 48.0}
{"epoch": 4, "training_loss": 0.7354178428649902, "training_acc": 46.0, "val_loss": 0.7057897663116455, "val_acc": 48.0}
{"epoch": 5, "training_loss": 0.7260586929321289, "training_acc": 46.0, "val_loss": 0.7148130917549134, "val_acc": 52.0}
{"epoch": 6, "training_loss": 0.7477531480789185, "training_acc": 48.0, "val_loss": 0.6930815052986145, "val_acc": 52.0}
{"epoch": 7, "training_loss": 0.7174884819984436, "training_acc": 46.0, "val_loss": 0.7195315480232238, "val_acc": 48.0}
{"epoch": 8, "training_loss": 0.7318029880523682, "training_acc": 44.0, "val_loss": 0.7020433521270752, "val_acc": 48.0}
{"epoch": 9, "training_loss": 0.6981336498260498, "training_acc": 52.0, "val_loss": 0.6931576824188233, "val_acc": 52.0}
{"epoch": 10, "training_loss": 0.7124006271362304, "training_acc": 56.0, "val_loss": 0.6926129603385925, "val_acc": 52.0}
{"epoch": 11, "training_loss": 0.7243269634246826, "training_acc": 46.0, "val_loss": 0.6937303900718689, "val_acc": 48.0}
{"epoch": 12, "training_loss": 0.7160548996925354, "training_acc": 46.0, "val_loss": 0.6933856201171875, "val_acc": 52.0}
{"epoch": 13, "training_loss": 0.706239550113678, "training_acc": 52.0, "val_loss": 0.8366677570343017, "val_acc": 52.0}
{"epoch": 14, "training_loss": 0.7604094171524047, "training_acc": 50.0, "val_loss": 0.6947430896759034, "val_acc": 48.0}
{"epoch": 15, "training_loss": 0.7059402751922608, "training_acc": 56.0, "val_loss": 0.7695974326133728, "val_acc": 52.0}
{"epoch": 16, "training_loss": 0.737804024219513, "training_acc": 48.0, "val_loss": 0.7576698231697082, "val_acc": 48.0}
{"epoch": 17, "training_loss": 0.7239413976669311, "training_acc": 52.0, "val_loss": 0.71546480178833, "val_acc": 52.0}
{"epoch": 18, "training_loss": 0.7074219369888306, "training_acc": 52.0, "val_loss": 0.7612868762016296, "val_acc": 48.0}
{"epoch": 19, "training_loss": 0.7410714697837829, "training_acc": 46.0, "val_loss": 0.6923604726791381, "val_acc": 52.0}
{"epoch": 20, "training_loss": 0.7167339158058167, "training_acc": 44.0, "val_loss": 0.6980706763267517, "val_acc": 48.0}
{"epoch": 21, "training_loss": 0.7140688395500183, "training_acc": 48.0, "val_loss": 0.7048827695846558, "val_acc": 48.0}
{"epoch": 22, "training_loss": 0.7080473136901856, "training_acc": 44.0, "val_loss": 0.701816532611847, "val_acc": 52.0}
{"epoch": 23, "training_loss": 0.7163928937911987, "training_acc": 42.0, "val_loss": 0.6925847172737122, "val_acc": 52.0}
{"epoch": 24, "training_loss": 0.723732123374939, "training_acc": 52.0, "val_loss": 0.8208365654945373, "val_acc": 48.0}
{"epoch": 25, "training_loss": 0.768719687461853, "training_acc": 50.0, "val_loss": 0.6923579716682434, "val_acc": 52.0}
{"epoch": 26, "training_loss": 0.715796194076538, "training_acc": 50.0, "val_loss": 0.7351382565498352, "val_acc": 48.0}
{"epoch": 27, "training_loss": 0.7177847671508789, "training_acc": 50.0, "val_loss": 0.7369944524765014, "val_acc": 52.0}
{"epoch": 28, "training_loss": 0.8110089826583863, "training_acc": 50.0, "val_loss": 0.7677371454238892, "val_acc": 48.0}
{"epoch": 29, "training_loss": 0.790679144859314, "training_acc": 52.0, "val_loss": 0.8527349019050598, "val_acc": 52.0}
{"epoch": 30, "training_loss": 0.8149306607246399, "training_acc": 46.0, "val_loss": 0.7003308963775635, "val_acc": 48.0}
{"epoch": 31, "training_loss": 0.7013725447654724, "training_acc": 52.0, "val_loss": 0.6978369879722596, "val_acc": 52.0}
{"epoch": 32, "training_loss": 0.7064186692237854, "training_acc": 46.0, "val_loss": 0.7412405109405518, "val_acc": 48.0}
{"epoch": 33, "training_loss": 0.7299230861663818, "training_acc": 50.0, "val_loss": 0.700584123134613, "val_acc": 48.0}
{"epoch": 34, "training_loss": 0.7300630474090576, "training_acc": 50.0, "val_loss": 0.704409749507904, "val_acc": 52.0}
{"epoch": 35, "training_loss": 0.7110392165184021, "training_acc": 50.0, "val_loss": 0.6939198613166809, "val_acc": 52.0}
{"epoch": 36, "training_loss": 0.7097723817825318, "training_acc": 44.0, "val_loss": 0.7104196166992187, "val_acc": 52.0}
{"epoch": 37, "training_loss": 0.7332725095748901, "training_acc": 50.0, "val_loss": 0.7080578351020813, "val_acc": 48.0}
{"epoch": 38, "training_loss": 0.7153074264526367, "training_acc": 50.0, "val_loss": 0.6959136176109314, "val_acc": 52.0}
{"epoch": 39, "training_loss": 0.6984943556785583, "training_acc": 48.0, "val_loss": 0.6924646258354187, "val_acc": 52.0}
{"epoch": 40, "training_loss": 0.7100588703155517, "training_acc": 48.0, "val_loss": 0.7023211407661438, "val_acc": 52.0}
{"epoch": 41, "training_loss": 0.7139310383796692, "training_acc": 48.0, "val_loss": 0.7333392143249512, "val_acc": 48.0}
{"epoch": 42, "training_loss": 0.7288816022872925, "training_acc": 44.0, "val_loss": 0.693282732963562, "val_acc": 48.0}
{"epoch": 43, "training_loss": 0.7160898494720459, "training_acc": 36.0, "val_loss": 0.6963314867019653, "val_acc": 48.0}
{"epoch": 44, "training_loss": 0.7052627134323121, "training_acc": 44.0, "val_loss": 0.7117133355140686, "val_acc": 48.0}
