"main_modify.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 5 --task ADNI_sex --input_option yAware --learning_rate 1e-2 --batch_size 16 --weight_decay 1e-2 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 1.403854215145111, "training_acc": 41.0, "val_loss": 0.7694832563400269, "val_acc": 48.0}
{"epoch": 1, "training_loss": 0.8406547474861145, "training_acc": 43.0, "val_loss": 0.6967318058013916, "val_acc": 48.0}
{"epoch": 2, "training_loss": 0.7380627584457398, "training_acc": 45.0, "val_loss": 0.709202766418457, "val_acc": 48.0}
{"epoch": 3, "training_loss": 0.7123761868476868, "training_acc": 51.0, "val_loss": 0.7970754361152649, "val_acc": 52.0}
{"epoch": 4, "training_loss": 0.7525552177429199, "training_acc": 49.0, "val_loss": 0.90279691696167, "val_acc": 48.0}
{"epoch": 5, "training_loss": 0.7686784744262696, "training_acc": 51.0, "val_loss": 0.6971235537528991, "val_acc": 48.0}
{"epoch": 6, "training_loss": 0.7131983804702758, "training_acc": 41.0, "val_loss": 0.7956651258468628, "val_acc": 48.0}
{"epoch": 7, "training_loss": 0.7139868354797363, "training_acc": 53.0, "val_loss": 0.7459610199928284, "val_acc": 52.0}
{"epoch": 8, "training_loss": 0.7807891941070557, "training_acc": 43.0, "val_loss": 0.729670672416687, "val_acc": 52.0}
{"epoch": 9, "training_loss": 0.7477532720565796, "training_acc": 43.0, "val_loss": 0.75799964427948, "val_acc": 52.0}
{"epoch": 10, "training_loss": 0.7796871590614319, "training_acc": 47.0, "val_loss": 0.7115669751167297, "val_acc": 48.0}
{"epoch": 11, "training_loss": 0.7442097854614258, "training_acc": 45.0, "val_loss": 0.8352800750732422, "val_acc": 48.0}
{"epoch": 12, "training_loss": 0.8003002119064331, "training_acc": 47.0, "val_loss": 0.7322952198982239, "val_acc": 48.0}
{"epoch": 13, "training_loss": 0.7318343639373779, "training_acc": 51.0, "val_loss": 0.7256853580474854, "val_acc": 48.0}
{"epoch": 14, "training_loss": 0.7579597496986389, "training_acc": 53.0, "val_loss": 0.9577429699897766, "val_acc": 52.0}
{"epoch": 15, "training_loss": 0.7819997310638428, "training_acc": 55.0, "val_loss": 0.9422081351280213, "val_acc": 48.0}
{"epoch": 16, "training_loss": 0.7868425107002258, "training_acc": 49.0, "val_loss": 0.721072165966034, "val_acc": 52.0}
{"epoch": 17, "training_loss": 0.7365592217445374, "training_acc": 45.0, "val_loss": 0.7094596147537231, "val_acc": 52.0}
{"epoch": 18, "training_loss": 0.7158111476898193, "training_acc": 47.0, "val_loss": 0.7465388584136963, "val_acc": 48.0}
{"epoch": 19, "training_loss": 0.7263623881340027, "training_acc": 49.0, "val_loss": 0.699445173740387, "val_acc": 52.0}
{"epoch": 20, "training_loss": 0.7008793544769287, "training_acc": 49.0, "val_loss": 0.6959238362312317, "val_acc": 48.0}
{"epoch": 21, "training_loss": 0.7032001090049743, "training_acc": 47.0, "val_loss": 0.6926296544075012, "val_acc": 52.0}
{"epoch": 22, "training_loss": 0.7051335954666138, "training_acc": 41.0, "val_loss": 0.6942645359039307, "val_acc": 52.0}
{"epoch": 23, "training_loss": 0.7314818835258484, "training_acc": 45.0, "val_loss": 0.7125548529624939, "val_acc": 52.0}
{"epoch": 24, "training_loss": 0.7226321649551392, "training_acc": 49.0, "val_loss": 0.7230031299591064, "val_acc": 48.0}
{"epoch": 25, "training_loss": 0.7252004671096802, "training_acc": 51.0, "val_loss": 0.6933916854858398, "val_acc": 52.0}
{"epoch": 26, "training_loss": 0.7094118356704712, "training_acc": 45.0, "val_loss": 0.697582905292511, "val_acc": 52.0}
{"epoch": 27, "training_loss": 0.7508524250984192, "training_acc": 39.0, "val_loss": 0.7070286679267883, "val_acc": 52.0}
{"epoch": 28, "training_loss": 0.7447619676589966, "training_acc": 43.0, "val_loss": 0.7148346018791198, "val_acc": 48.0}
{"epoch": 29, "training_loss": 0.7046248245239258, "training_acc": 47.0, "val_loss": 0.6923521518707275, "val_acc": 52.0}
{"epoch": 30, "training_loss": 0.6972961854934693, "training_acc": 47.0, "val_loss": 0.7007699680328369, "val_acc": 48.0}
{"epoch": 31, "training_loss": 0.7144485855102539, "training_acc": 51.0, "val_loss": 0.7011467003822327, "val_acc": 52.0}
{"epoch": 32, "training_loss": 0.7064987468719482, "training_acc": 47.0, "val_loss": 0.6925717639923096, "val_acc": 52.0}
{"epoch": 33, "training_loss": 0.7023166608810425, "training_acc": 43.0, "val_loss": 0.6946538281440735, "val_acc": 52.0}
{"epoch": 34, "training_loss": 0.7228816890716553, "training_acc": 47.0, "val_loss": 0.7290873050689697, "val_acc": 52.0}
{"epoch": 35, "training_loss": 0.7957202935218811, "training_acc": 51.0, "val_loss": 0.8385100293159485, "val_acc": 48.0}
{"epoch": 36, "training_loss": 0.7684034824371337, "training_acc": 47.0, "val_loss": 0.6925890755653381, "val_acc": 52.0}
{"epoch": 37, "training_loss": 0.7153044986724854, "training_acc": 39.0, "val_loss": 0.6923812079429627, "val_acc": 52.0}
{"epoch": 38, "training_loss": 0.7765159463882446, "training_acc": 47.0, "val_loss": 0.7152629590034485, "val_acc": 48.0}
{"epoch": 39, "training_loss": 0.7079526948928833, "training_acc": 47.0, "val_loss": 0.6993310856819153, "val_acc": 48.0}
{"epoch": 40, "training_loss": 0.7081259155273437, "training_acc": 53.0, "val_loss": 0.7310009789466858, "val_acc": 52.0}
{"epoch": 41, "training_loss": 0.7259369802474975, "training_acc": 51.0, "val_loss": 0.7325391435623169, "val_acc": 48.0}
{"epoch": 42, "training_loss": 0.7277212977409363, "training_acc": 51.0, "val_loss": 0.7627491879463196, "val_acc": 52.0}
{"epoch": 43, "training_loss": 0.8785756587982178, "training_acc": 51.0, "val_loss": 0.842975583076477, "val_acc": 48.0}
{"epoch": 44, "training_loss": 0.8549047327041626, "training_acc": 49.0, "val_loss": 0.69811936378479, "val_acc": 52.0}
{"epoch": 45, "training_loss": 0.7205654811859131, "training_acc": 39.0, "val_loss": 0.7050903964042664, "val_acc": 48.0}
{"epoch": 46, "training_loss": 0.7291483974456787, "training_acc": 49.0, "val_loss": 0.6923624157905579, "val_acc": 52.0}
{"epoch": 47, "training_loss": 0.6918170261383056, "training_acc": 53.0, "val_loss": 0.7352439570426941, "val_acc": 48.0}
{"epoch": 48, "training_loss": 0.739326536655426, "training_acc": 43.0, "val_loss": 0.7088484787940978, "val_acc": 48.0}
