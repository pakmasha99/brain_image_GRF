"main_modify.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 5 --task ADNI_sex --input_option yAware --learning_rate 1e-2 --batch_size 16 --weight_decay 1e-2 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 1.2774196100234985, "training_acc": 41.0, "val_loss": 0.7600025081634522, "val_acc": 52.0}
{"epoch": 1, "training_loss": 0.8828513717651367, "training_acc": 49.0, "val_loss": 0.8389059114456177, "val_acc": 52.0}
{"epoch": 2, "training_loss": 0.784917254447937, "training_acc": 49.0, "val_loss": 0.8307240986824036, "val_acc": 48.0}
{"epoch": 3, "training_loss": 0.7673197078704834, "training_acc": 49.0, "val_loss": 0.6933577418327331, "val_acc": 52.0}
{"epoch": 4, "training_loss": 0.72432950258255, "training_acc": 45.0, "val_loss": 0.7219564175605774, "val_acc": 48.0}
{"epoch": 5, "training_loss": 0.7215146255493164, "training_acc": 43.0, "val_loss": 0.7575551652908326, "val_acc": 48.0}
{"epoch": 6, "training_loss": 0.7549591064453125, "training_acc": 41.0, "val_loss": 0.8202629160881042, "val_acc": 48.0}
{"epoch": 7, "training_loss": 0.7797100448608398, "training_acc": 47.0, "val_loss": 0.8173188400268555, "val_acc": 48.0}
{"epoch": 8, "training_loss": 0.8257598948478698, "training_acc": 49.0, "val_loss": 0.7244685029983521, "val_acc": 52.0}
{"epoch": 9, "training_loss": 0.7574423432350159, "training_acc": 43.0, "val_loss": 0.7434297227859497, "val_acc": 48.0}
{"epoch": 10, "training_loss": 0.700650019645691, "training_acc": 55.0, "val_loss": 0.8481801915168762, "val_acc": 52.0}
{"epoch": 11, "training_loss": 0.8092187738418579, "training_acc": 43.0, "val_loss": 0.6939255619049072, "val_acc": 52.0}
{"epoch": 12, "training_loss": 0.7013181447982788, "training_acc": 45.0, "val_loss": 0.9116854858398438, "val_acc": 48.0}
{"epoch": 13, "training_loss": 0.7652093029022217, "training_acc": 45.0, "val_loss": 0.7508145213127136, "val_acc": 48.0}
{"epoch": 14, "training_loss": 0.7823681139945984, "training_acc": 49.0, "val_loss": 0.6937542057037354, "val_acc": 52.0}
{"epoch": 15, "training_loss": 0.7040959930419922, "training_acc": 51.0, "val_loss": 0.6943787598609924, "val_acc": 52.0}
{"epoch": 16, "training_loss": 0.7337437868118286, "training_acc": 41.0, "val_loss": 0.6962872552871704, "val_acc": 48.0}
{"epoch": 17, "training_loss": 0.7010961055755616, "training_acc": 47.0, "val_loss": 0.7330873608589172, "val_acc": 48.0}
{"epoch": 18, "training_loss": 0.7176214838027954, "training_acc": 51.0, "val_loss": 0.6928665137290955, "val_acc": 52.0}
{"epoch": 19, "training_loss": 0.7159982252120972, "training_acc": 43.0, "val_loss": 0.7109315896034241, "val_acc": 52.0}
{"epoch": 20, "training_loss": 0.7358060121536255, "training_acc": 41.0, "val_loss": 0.6937535452842712, "val_acc": 52.0}
{"epoch": 21, "training_loss": 0.706382999420166, "training_acc": 43.0, "val_loss": 0.705526967048645, "val_acc": 48.0}
{"epoch": 22, "training_loss": 0.7209799766540528, "training_acc": 51.0, "val_loss": 0.7024902009963989, "val_acc": 52.0}
{"epoch": 23, "training_loss": 0.7330916285514831, "training_acc": 47.0, "val_loss": 0.6961359024047852, "val_acc": 48.0}
{"epoch": 24, "training_loss": 0.707178750038147, "training_acc": 47.0, "val_loss": 0.7163232684135437, "val_acc": 48.0}
{"epoch": 25, "training_loss": 0.7070777082443237, "training_acc": 55.0, "val_loss": 0.7493126392364502, "val_acc": 52.0}
{"epoch": 26, "training_loss": 0.7952331113815307, "training_acc": 49.0, "val_loss": 0.7634850382804871, "val_acc": 48.0}
{"epoch": 27, "training_loss": 0.784561653137207, "training_acc": 51.0, "val_loss": 0.7009593319892883, "val_acc": 52.0}
{"epoch": 28, "training_loss": 0.744647033214569, "training_acc": 47.0, "val_loss": 0.6964487981796265, "val_acc": 48.0}
{"epoch": 29, "training_loss": 0.6974745607376098, "training_acc": 47.0, "val_loss": 0.6923931074142456, "val_acc": 52.0}
{"epoch": 30, "training_loss": 0.7034950757026672, "training_acc": 47.0, "val_loss": 0.6952717924118041, "val_acc": 52.0}
{"epoch": 31, "training_loss": 0.6995590877532959, "training_acc": 47.0, "val_loss": 0.7059003281593322, "val_acc": 48.0}
{"epoch": 32, "training_loss": 0.7085719418525696, "training_acc": 51.0, "val_loss": 0.7023295617103577, "val_acc": 52.0}
{"epoch": 33, "training_loss": 0.7260789561271668, "training_acc": 49.0, "val_loss": 0.7073268175125123, "val_acc": 48.0}
{"epoch": 34, "training_loss": 0.70755455493927, "training_acc": 51.0, "val_loss": 0.6927881789207458, "val_acc": 52.0}
{"epoch": 35, "training_loss": 0.7498537349700928, "training_acc": 51.0, "val_loss": 0.7774283742904663, "val_acc": 48.0}
{"epoch": 36, "training_loss": 0.7519468021392822, "training_acc": 43.0, "val_loss": 0.7101552987098694, "val_acc": 52.0}
{"epoch": 37, "training_loss": 0.738997130393982, "training_acc": 43.0, "val_loss": 0.6942692708969116, "val_acc": 52.0}
{"epoch": 38, "training_loss": 0.7283012771606445, "training_acc": 45.0, "val_loss": 0.7074042558670044, "val_acc": 52.0}
{"epoch": 39, "training_loss": 0.7501288843154907, "training_acc": 51.0, "val_loss": 0.831367781162262, "val_acc": 48.0}
{"epoch": 40, "training_loss": 0.7733200097084045, "training_acc": 45.0, "val_loss": 0.7159170079231262, "val_acc": 48.0}
{"epoch": 41, "training_loss": 0.7188315105438232, "training_acc": 51.0, "val_loss": 0.7189295864105225, "val_acc": 48.0}
{"epoch": 42, "training_loss": 0.7120619916915893, "training_acc": 47.0, "val_loss": 0.6923700714111328, "val_acc": 52.0}
{"epoch": 43, "training_loss": 0.7041021108627319, "training_acc": 51.0, "val_loss": 0.6924707055091858, "val_acc": 52.0}
{"epoch": 44, "training_loss": 0.716889853477478, "training_acc": 49.0, "val_loss": 0.7367161846160889, "val_acc": 48.0}
{"epoch": 45, "training_loss": 0.7295361638069153, "training_acc": 51.0, "val_loss": 0.7166701817512512, "val_acc": 52.0}
{"epoch": 46, "training_loss": 0.7581405377388001, "training_acc": 47.0, "val_loss": 0.7000576472282409, "val_acc": 48.0}
{"epoch": 47, "training_loss": 0.7454815196990967, "training_acc": 49.0, "val_loss": 0.7053248977661133, "val_acc": 52.0}
{"epoch": 48, "training_loss": 0.7199927687644958, "training_acc": 43.0, "val_loss": 0.6974050736427307, "val_acc": 52.0}
{"epoch": 49, "training_loss": 0.7209813404083252, "training_acc": 43.0, "val_loss": 0.7573180842399597, "val_acc": 48.0}
{"epoch": 50, "training_loss": 0.7814688515663147, "training_acc": 49.0, "val_loss": 0.7035686874389648, "val_acc": 52.0}
{"epoch": 51, "training_loss": 0.7114137983322144, "training_acc": 53.0, "val_loss": 0.7076816248893738, "val_acc": 48.0}
{"epoch": 52, "training_loss": 0.6976632308959961, "training_acc": 55.0, "val_loss": 0.735814254283905, "val_acc": 52.0}
{"epoch": 53, "training_loss": 0.7453647494316101, "training_acc": 49.0, "val_loss": 0.7575460004806519, "val_acc": 48.0}
{"epoch": 54, "training_loss": 0.7372283124923706, "training_acc": 45.0, "val_loss": 0.7035120844841003, "val_acc": 48.0}
{"epoch": 55, "training_loss": 0.7416372680664063, "training_acc": 51.0, "val_loss": 0.7100223183631897, "val_acc": 52.0}
{"epoch": 56, "training_loss": 0.725395450592041, "training_acc": 49.0, "val_loss": 0.7115841245651245, "val_acc": 48.0}
{"epoch": 57, "training_loss": 0.7156457662582397, "training_acc": 43.0, "val_loss": 0.7658607172966003, "val_acc": 48.0}
{"epoch": 58, "training_loss": 0.7166715455055237, "training_acc": 51.0, "val_loss": 0.6925041317939759, "val_acc": 52.0}
{"epoch": 59, "training_loss": 0.7295502853393555, "training_acc": 33.0, "val_loss": 0.692375214099884, "val_acc": 52.0}
{"epoch": 60, "training_loss": 0.7138638544082642, "training_acc": 39.0, "val_loss": 0.7108594059944153, "val_acc": 48.0}
{"epoch": 61, "training_loss": 0.7094335055351257, "training_acc": 51.0, "val_loss": 0.7230902767181396, "val_acc": 52.0}
