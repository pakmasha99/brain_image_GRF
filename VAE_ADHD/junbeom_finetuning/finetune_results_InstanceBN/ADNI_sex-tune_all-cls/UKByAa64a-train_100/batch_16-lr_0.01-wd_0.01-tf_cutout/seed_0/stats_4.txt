"main_modify.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ADNI_sex --input_option yAware --learning_rate 1e-2 --batch_size 16 --weight_decay 1e-2 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 1.3844244289398193, "training_acc": 50.0, "val_loss": 0.7316662216186524, "val_acc": 48.0}
{"epoch": 1, "training_loss": 0.9466767597198487, "training_acc": 50.0, "val_loss": 0.7709184670448304, "val_acc": 52.0}
{"epoch": 2, "training_loss": 0.760780553817749, "training_acc": 44.0, "val_loss": 0.787163987159729, "val_acc": 52.0}
{"epoch": 3, "training_loss": 0.7472764658927917, "training_acc": 42.0, "val_loss": 0.75175372838974, "val_acc": 48.0}
{"epoch": 4, "training_loss": 0.7388631677627564, "training_acc": 44.0, "val_loss": 0.7189004492759704, "val_acc": 52.0}
{"epoch": 5, "training_loss": 0.783183913230896, "training_acc": 46.0, "val_loss": 0.9246728897094727, "val_acc": 52.0}
{"epoch": 6, "training_loss": 0.8681289219856262, "training_acc": 48.0, "val_loss": 0.9310356259346009, "val_acc": 48.0}
{"epoch": 7, "training_loss": 0.8012609672546387, "training_acc": 48.0, "val_loss": 0.7348418545722961, "val_acc": 52.0}
{"epoch": 8, "training_loss": 0.7269284725189209, "training_acc": 46.0, "val_loss": 0.7074597573280335, "val_acc": 48.0}
{"epoch": 9, "training_loss": 0.7127219963073731, "training_acc": 44.0, "val_loss": 0.9031539678573608, "val_acc": 48.0}
{"epoch": 10, "training_loss": 0.8075528430938721, "training_acc": 50.0, "val_loss": 0.7351091313362121, "val_acc": 48.0}
{"epoch": 11, "training_loss": 0.737069616317749, "training_acc": 50.0, "val_loss": 0.7911517143249511, "val_acc": 52.0}
{"epoch": 12, "training_loss": 0.7519819688796997, "training_acc": 48.0, "val_loss": 0.693167200088501, "val_acc": 52.0}
{"epoch": 13, "training_loss": 0.7326321315765381, "training_acc": 48.0, "val_loss": 0.6955329036712646, "val_acc": 48.0}
{"epoch": 14, "training_loss": 0.7498104119300842, "training_acc": 56.0, "val_loss": 0.7785151433944703, "val_acc": 52.0}
{"epoch": 15, "training_loss": 0.8101530456542969, "training_acc": 48.0, "val_loss": 0.7986868000030518, "val_acc": 52.0}
{"epoch": 16, "training_loss": 0.7868458771705628, "training_acc": 50.0, "val_loss": 0.6956957340240478, "val_acc": 48.0}
{"epoch": 17, "training_loss": 0.717757682800293, "training_acc": 48.0, "val_loss": 0.894865186214447, "val_acc": 48.0}
{"epoch": 18, "training_loss": 0.7712083864212036, "training_acc": 54.0, "val_loss": 0.6976637744903564, "val_acc": 52.0}
{"epoch": 19, "training_loss": 0.7071852016448975, "training_acc": 44.0, "val_loss": 0.7448675608634949, "val_acc": 48.0}
{"epoch": 20, "training_loss": 0.751500940322876, "training_acc": 52.0, "val_loss": 0.7660940194129944, "val_acc": 52.0}
{"epoch": 21, "training_loss": 0.7684945392608643, "training_acc": 50.0, "val_loss": 0.7306869840621948, "val_acc": 48.0}
{"epoch": 22, "training_loss": 0.7328291130065918, "training_acc": 46.0, "val_loss": 0.6923586964607239, "val_acc": 52.0}
{"epoch": 23, "training_loss": 0.6970593571662903, "training_acc": 48.0, "val_loss": 0.7047860622406006, "val_acc": 48.0}
{"epoch": 24, "training_loss": 0.7649871301651001, "training_acc": 48.0, "val_loss": 0.7019556403160095, "val_acc": 52.0}
{"epoch": 25, "training_loss": 0.7158510494232178, "training_acc": 50.0, "val_loss": 0.7107210540771485, "val_acc": 48.0}
{"epoch": 26, "training_loss": 0.7076713418960572, "training_acc": 46.0, "val_loss": 0.7317367267608642, "val_acc": 48.0}
{"epoch": 27, "training_loss": 0.7193801259994507, "training_acc": 50.0, "val_loss": 0.7003026127815246, "val_acc": 52.0}
{"epoch": 28, "training_loss": 0.7157462310791015, "training_acc": 50.0, "val_loss": 0.7122474002838135, "val_acc": 48.0}
{"epoch": 29, "training_loss": 0.7399472332000733, "training_acc": 46.0, "val_loss": 0.6924040603637696, "val_acc": 52.0}
{"epoch": 30, "training_loss": 0.7044376516342163, "training_acc": 50.0, "val_loss": 0.695228099822998, "val_acc": 52.0}
{"epoch": 31, "training_loss": 0.7182778930664062, "training_acc": 48.0, "val_loss": 0.6923477101325989, "val_acc": 52.0}
{"epoch": 32, "training_loss": 0.7008121681213378, "training_acc": 50.0, "val_loss": 0.6927356839179992, "val_acc": 52.0}
{"epoch": 33, "training_loss": 0.7176582956314087, "training_acc": 42.0, "val_loss": 0.6925135016441345, "val_acc": 52.0}
{"epoch": 34, "training_loss": 0.7187468099594116, "training_acc": 36.0, "val_loss": 0.7049469447135925, "val_acc": 52.0}
{"epoch": 35, "training_loss": 0.7601279830932617, "training_acc": 42.0, "val_loss": 0.7183622288703918, "val_acc": 48.0}
{"epoch": 36, "training_loss": 0.7269155073165894, "training_acc": 44.0, "val_loss": 0.6955000686645508, "val_acc": 52.0}
{"epoch": 37, "training_loss": 0.6997445487976074, "training_acc": 48.0, "val_loss": 0.6957966303825378, "val_acc": 48.0}
{"epoch": 38, "training_loss": 0.6978660106658936, "training_acc": 48.0, "val_loss": 0.6924734473228454, "val_acc": 52.0}
{"epoch": 39, "training_loss": 0.6980625724792481, "training_acc": 48.0, "val_loss": 0.6931523895263672, "val_acc": 48.0}
{"epoch": 40, "training_loss": 0.7000430512428284, "training_acc": 44.0, "val_loss": 0.6942347812652588, "val_acc": 48.0}
{"epoch": 41, "training_loss": 0.6989371871948242, "training_acc": 42.0, "val_loss": 0.7049850535392761, "val_acc": 48.0}
{"epoch": 42, "training_loss": 0.7187928104400635, "training_acc": 50.0, "val_loss": 0.6997679710388184, "val_acc": 52.0}
{"epoch": 43, "training_loss": 0.7227442979812622, "training_acc": 44.0, "val_loss": 0.6927243781089782, "val_acc": 52.0}
{"epoch": 44, "training_loss": 0.7030154228210449, "training_acc": 46.0, "val_loss": 0.6951313400268555, "val_acc": 48.0}
{"epoch": 45, "training_loss": 0.7211805438995361, "training_acc": 50.0, "val_loss": 0.6996499633789063, "val_acc": 52.0}
{"epoch": 46, "training_loss": 0.7173564767837525, "training_acc": 46.0, "val_loss": 0.6928523302078247, "val_acc": 52.0}
{"epoch": 47, "training_loss": 0.7027856731414794, "training_acc": 48.0, "val_loss": 0.6923896074295044, "val_acc": 52.0}
{"epoch": 48, "training_loss": 0.7047115898132325, "training_acc": 46.0, "val_loss": 0.6931079411506653, "val_acc": 52.0}
{"epoch": 49, "training_loss": 0.7015380859375, "training_acc": 44.0, "val_loss": 0.7105397772789002, "val_acc": 48.0}
{"epoch": 50, "training_loss": 0.706369342803955, "training_acc": 50.0, "val_loss": 0.6934945321083069, "val_acc": 52.0}
