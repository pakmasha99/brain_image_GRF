"main_modify.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ADNI_sex --input_option yAware --learning_rate 1e-2 --batch_size 16 --weight_decay 1e-2 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 1.4139763879776002, "training_acc": 48.0, "val_loss": 0.6998939609527588, "val_acc": 52.0}
{"epoch": 1, "training_loss": 0.7353397417068481, "training_acc": 60.0, "val_loss": 0.856196186542511, "val_acc": 48.0}
{"epoch": 2, "training_loss": 0.826236629486084, "training_acc": 42.0, "val_loss": 0.7360264086723327, "val_acc": 48.0}
{"epoch": 3, "training_loss": 0.7153099370002747, "training_acc": 48.0, "val_loss": 0.6947511434555054, "val_acc": 48.0}
{"epoch": 4, "training_loss": 0.6960898494720459, "training_acc": 50.0, "val_loss": 0.793669137954712, "val_acc": 52.0}
{"epoch": 5, "training_loss": 0.726791410446167, "training_acc": 52.0, "val_loss": 0.7198461723327637, "val_acc": 48.0}
{"epoch": 6, "training_loss": 0.7148665571212769, "training_acc": 46.0, "val_loss": 0.7568936085700989, "val_acc": 48.0}
{"epoch": 7, "training_loss": 0.7527336359024048, "training_acc": 46.0, "val_loss": 0.7210393023490905, "val_acc": 48.0}
{"epoch": 8, "training_loss": 0.7089347958564758, "training_acc": 50.0, "val_loss": 0.7054881381988526, "val_acc": 48.0}
{"epoch": 9, "training_loss": 0.7224918794631958, "training_acc": 42.0, "val_loss": 0.765589497089386, "val_acc": 52.0}
{"epoch": 10, "training_loss": 0.7209130144119262, "training_acc": 56.0, "val_loss": 1.0405793476104737, "val_acc": 48.0}
{"epoch": 11, "training_loss": 0.7759959006309509, "training_acc": 54.0, "val_loss": 0.7618024468421936, "val_acc": 52.0}
{"epoch": 12, "training_loss": 0.7277838921546936, "training_acc": 48.0, "val_loss": 0.8265036654472351, "val_acc": 48.0}
{"epoch": 13, "training_loss": 0.7759529900550842, "training_acc": 46.0, "val_loss": 0.692627820968628, "val_acc": 52.0}
{"epoch": 14, "training_loss": 0.7095883512496948, "training_acc": 48.0, "val_loss": 0.6925119090080262, "val_acc": 52.0}
{"epoch": 15, "training_loss": 0.7101181960105896, "training_acc": 54.0, "val_loss": 0.6944497776031494, "val_acc": 48.0}
{"epoch": 16, "training_loss": 0.6889121103286743, "training_acc": 56.0, "val_loss": 0.7547258400917053, "val_acc": 52.0}
{"epoch": 17, "training_loss": 0.7201720261573792, "training_acc": 52.0, "val_loss": 0.7048396635055542, "val_acc": 48.0}
{"epoch": 18, "training_loss": 0.6980173087120056, "training_acc": 52.0, "val_loss": 0.6970663475990295, "val_acc": 48.0}
{"epoch": 19, "training_loss": 0.7233946084976196, "training_acc": 50.0, "val_loss": 0.6930664801597595, "val_acc": 52.0}
{"epoch": 20, "training_loss": 0.6996141147613525, "training_acc": 50.0, "val_loss": 0.7258325695991517, "val_acc": 52.0}
{"epoch": 21, "training_loss": 0.7199758243560791, "training_acc": 46.0, "val_loss": 0.696286473274231, "val_acc": 48.0}
{"epoch": 22, "training_loss": 0.7049943208694458, "training_acc": 48.0, "val_loss": 0.7068753290176392, "val_acc": 48.0}
{"epoch": 23, "training_loss": 0.7078251552581787, "training_acc": 48.0, "val_loss": 0.6983192253112793, "val_acc": 48.0}
{"epoch": 24, "training_loss": 0.7108919429779053, "training_acc": 50.0, "val_loss": 0.7083604788780212, "val_acc": 52.0}
{"epoch": 25, "training_loss": 0.7286692714691162, "training_acc": 40.0, "val_loss": 0.6924107694625854, "val_acc": 52.0}
{"epoch": 26, "training_loss": 0.7032917284965515, "training_acc": 48.0, "val_loss": 0.7011782765388489, "val_acc": 48.0}
{"epoch": 27, "training_loss": 0.7118481206893921, "training_acc": 50.0, "val_loss": 0.7011055493354797, "val_acc": 52.0}
{"epoch": 28, "training_loss": 0.7040933895111084, "training_acc": 48.0, "val_loss": 0.692724905014038, "val_acc": 52.0}
{"epoch": 29, "training_loss": 0.7078847575187683, "training_acc": 48.0, "val_loss": 0.7133989667892456, "val_acc": 48.0}
{"epoch": 30, "training_loss": 0.7282391619682312, "training_acc": 46.0, "val_loss": 0.7077103829383851, "val_acc": 52.0}
{"epoch": 31, "training_loss": 0.7431345891952514, "training_acc": 46.0, "val_loss": 0.7908985924720764, "val_acc": 48.0}
{"epoch": 32, "training_loss": 0.7549424505233765, "training_acc": 54.0, "val_loss": 0.7106322932243347, "val_acc": 52.0}
{"epoch": 33, "training_loss": 0.7102599239349365, "training_acc": 50.0, "val_loss": 0.7006670713424683, "val_acc": 48.0}
{"epoch": 34, "training_loss": 0.7038597655296326, "training_acc": 48.0, "val_loss": 0.693615460395813, "val_acc": 52.0}
{"epoch": 35, "training_loss": 0.704459080696106, "training_acc": 50.0, "val_loss": 0.7098843502998352, "val_acc": 48.0}
{"epoch": 36, "training_loss": 0.7026017045974732, "training_acc": 46.0, "val_loss": 0.6928321504592896, "val_acc": 52.0}
{"epoch": 37, "training_loss": 0.6950576114654541, "training_acc": 52.0, "val_loss": 0.7452058601379394, "val_acc": 48.0}
{"epoch": 38, "training_loss": 0.7361481595039367, "training_acc": 50.0, "val_loss": 0.6960356831550598, "val_acc": 52.0}
{"epoch": 39, "training_loss": 0.7253075766563416, "training_acc": 44.0, "val_loss": 0.6936095929145814, "val_acc": 52.0}
{"epoch": 40, "training_loss": 0.7062545657157898, "training_acc": 50.0, "val_loss": 0.7022956848144531, "val_acc": 48.0}
{"epoch": 41, "training_loss": 0.711039867401123, "training_acc": 50.0, "val_loss": 0.7095743536949157, "val_acc": 48.0}
{"epoch": 42, "training_loss": 0.7159356403350831, "training_acc": 50.0, "val_loss": 0.725882043838501, "val_acc": 52.0}
{"epoch": 43, "training_loss": 0.7302855253219604, "training_acc": 50.0, "val_loss": 0.6926645493507385, "val_acc": 52.0}
{"epoch": 44, "training_loss": 0.6999513053894043, "training_acc": 50.0, "val_loss": 0.6928522491455078, "val_acc": 52.0}
