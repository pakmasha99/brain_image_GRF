"main_modify.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 8 --task ADNI_sex --input_option yAware --learning_rate 1e-2 --batch_size 16 --weight_decay 1e-2 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 1.170946296453476, "training_acc": 53.0, "val_loss": 0.716300904750824, "val_acc": 52.0}
{"epoch": 1, "training_loss": 0.8165935134887695, "training_acc": 49.0, "val_loss": 0.9806011533737182, "val_acc": 52.0}
{"epoch": 2, "training_loss": 0.8162729358673095, "training_acc": 51.0, "val_loss": 0.7029829096794128, "val_acc": 48.0}
{"epoch": 3, "training_loss": 0.7359297227859497, "training_acc": 53.0, "val_loss": 0.8024205803871155, "val_acc": 48.0}
{"epoch": 4, "training_loss": 0.7569308376312256, "training_acc": 51.0, "val_loss": 0.7999842977523803, "val_acc": 52.0}
{"epoch": 5, "training_loss": 0.7216592788696289, "training_acc": 53.0, "val_loss": 0.7295520401000977, "val_acc": 48.0}
{"epoch": 6, "training_loss": 0.7082915139198304, "training_acc": 49.0, "val_loss": 0.7578351068496704, "val_acc": 48.0}
{"epoch": 7, "training_loss": 0.7310947275161743, "training_acc": 45.0, "val_loss": 0.704797511100769, "val_acc": 52.0}
{"epoch": 8, "training_loss": 0.7439991092681885, "training_acc": 45.0, "val_loss": 0.8121404957771301, "val_acc": 52.0}
{"epoch": 9, "training_loss": 0.7941656804084778, "training_acc": 59.0, "val_loss": 1.2629489183425904, "val_acc": 48.0}
{"epoch": 10, "training_loss": 0.8742773652076721, "training_acc": 47.0, "val_loss": 0.6947749257087708, "val_acc": 52.0}
{"epoch": 11, "training_loss": 0.7085795187950135, "training_acc": 47.0, "val_loss": 0.773711335659027, "val_acc": 48.0}
{"epoch": 12, "training_loss": 0.7431487798690796, "training_acc": 47.0, "val_loss": 0.8136013507843017, "val_acc": 48.0}
{"epoch": 13, "training_loss": 0.7101119899749756, "training_acc": 57.0, "val_loss": 0.6933820652961731, "val_acc": 52.0}
{"epoch": 14, "training_loss": 0.736800651550293, "training_acc": 49.0, "val_loss": 0.6932017588615418, "val_acc": 48.0}
{"epoch": 15, "training_loss": 0.7056051445007324, "training_acc": 49.0, "val_loss": 0.8466541361808777, "val_acc": 52.0}
{"epoch": 16, "training_loss": 0.8064741230010987, "training_acc": 49.0, "val_loss": 0.7240942764282227, "val_acc": 52.0}
{"epoch": 17, "training_loss": 0.7338956737518311, "training_acc": 51.0, "val_loss": 0.7048877763748169, "val_acc": 48.0}
{"epoch": 18, "training_loss": 0.6950069165229797, "training_acc": 53.0, "val_loss": 0.8519779062271118, "val_acc": 48.0}
{"epoch": 19, "training_loss": 0.8079860019683838, "training_acc": 35.0, "val_loss": 0.6923639965057373, "val_acc": 52.0}
{"epoch": 20, "training_loss": 0.7108493161201477, "training_acc": 49.0, "val_loss": 0.7374920344352722, "val_acc": 48.0}
{"epoch": 21, "training_loss": 0.7213641500473023, "training_acc": 47.0, "val_loss": 0.6924378561973572, "val_acc": 52.0}
{"epoch": 22, "training_loss": 0.7204795789718628, "training_acc": 43.0, "val_loss": 0.6988413619995117, "val_acc": 52.0}
{"epoch": 23, "training_loss": 0.7095550131797791, "training_acc": 49.0, "val_loss": 0.6970597195625305, "val_acc": 48.0}
{"epoch": 24, "training_loss": 0.7002829027175903, "training_acc": 51.0, "val_loss": 0.6936065626144409, "val_acc": 48.0}
{"epoch": 25, "training_loss": 0.697430944442749, "training_acc": 49.0, "val_loss": 0.7081894755363465, "val_acc": 52.0}
{"epoch": 26, "training_loss": 0.7298380279541016, "training_acc": 47.0, "val_loss": 0.6940006589889527, "val_acc": 48.0}
{"epoch": 27, "training_loss": 0.7006675910949707, "training_acc": 45.0, "val_loss": 0.6923555374145508, "val_acc": 52.0}
{"epoch": 28, "training_loss": 0.7203068614006043, "training_acc": 47.0, "val_loss": 0.6952344059944153, "val_acc": 52.0}
{"epoch": 29, "training_loss": 0.7235490989685058, "training_acc": 45.0, "val_loss": 0.6983333349227905, "val_acc": 48.0}
{"epoch": 30, "training_loss": 0.7033756256103516, "training_acc": 49.0, "val_loss": 0.7052450752258301, "val_acc": 48.0}
{"epoch": 31, "training_loss": 0.7243820905685425, "training_acc": 51.0, "val_loss": 0.7349034404754639, "val_acc": 48.0}
{"epoch": 32, "training_loss": 0.7079524374008179, "training_acc": 53.0, "val_loss": 0.7254449772834778, "val_acc": 52.0}
{"epoch": 33, "training_loss": 0.7491530108451844, "training_acc": 45.0, "val_loss": 0.7213066577911377, "val_acc": 48.0}
{"epoch": 34, "training_loss": 0.7058114075660705, "training_acc": 53.0, "val_loss": 0.7164372563362121, "val_acc": 52.0}
{"epoch": 35, "training_loss": 0.7162413311004638, "training_acc": 51.0, "val_loss": 0.7361338448524475, "val_acc": 48.0}
{"epoch": 36, "training_loss": 0.7356015062332153, "training_acc": 51.0, "val_loss": 0.6991044330596924, "val_acc": 52.0}
{"epoch": 37, "training_loss": 0.7235571193695068, "training_acc": 41.0, "val_loss": 0.6960131216049195, "val_acc": 48.0}
{"epoch": 38, "training_loss": 0.7088045501708984, "training_acc": 43.0, "val_loss": 0.7010094404220581, "val_acc": 48.0}
{"epoch": 39, "training_loss": 0.7057897758483886, "training_acc": 43.0, "val_loss": 0.6961781787872314, "val_acc": 48.0}
{"epoch": 40, "training_loss": 0.710912070274353, "training_acc": 39.0, "val_loss": 0.6926755023002624, "val_acc": 52.0}
{"epoch": 41, "training_loss": 0.7187046384811402, "training_acc": 51.0, "val_loss": 0.7975460839271545, "val_acc": 48.0}
{"epoch": 42, "training_loss": 0.7836683702468872, "training_acc": 53.0, "val_loss": 0.8029982948303223, "val_acc": 52.0}
{"epoch": 43, "training_loss": 0.7494778251647949, "training_acc": 53.0, "val_loss": 0.8873824715614319, "val_acc": 48.0}
{"epoch": 44, "training_loss": 0.8209413528442383, "training_acc": 51.0, "val_loss": 0.7120084261894226, "val_acc": 52.0}
{"epoch": 45, "training_loss": 0.746720130443573, "training_acc": 45.0, "val_loss": 0.694343490600586, "val_acc": 48.0}
{"epoch": 46, "training_loss": 0.7103774642944336, "training_acc": 43.0, "val_loss": 0.6923577332496643, "val_acc": 52.0}
