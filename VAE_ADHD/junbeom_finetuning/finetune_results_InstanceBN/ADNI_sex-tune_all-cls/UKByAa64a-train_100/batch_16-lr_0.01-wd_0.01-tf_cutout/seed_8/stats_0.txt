"main_modify.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 8 --task ADNI_sex --input_option yAware --learning_rate 1e-2 --batch_size 16 --weight_decay 1e-2 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 1.0219266843795776, "training_acc": 53.0, "val_loss": 0.719767780303955, "val_acc": 48.0}
{"epoch": 1, "training_loss": 0.7806144833564759, "training_acc": 45.0, "val_loss": 0.6926491141319275, "val_acc": 52.0}
{"epoch": 2, "training_loss": 0.7202877998352051, "training_acc": 49.0, "val_loss": 0.7518910908699036, "val_acc": 52.0}
{"epoch": 3, "training_loss": 0.836486439704895, "training_acc": 47.0, "val_loss": 0.8438481068611146, "val_acc": 52.0}
{"epoch": 4, "training_loss": 0.738579193353653, "training_acc": 55.0, "val_loss": 1.090332441329956, "val_acc": 48.0}
{"epoch": 5, "training_loss": 0.8739727640151977, "training_acc": 53.0, "val_loss": 0.6929551720619201, "val_acc": 52.0}
{"epoch": 6, "training_loss": 0.8001042747497559, "training_acc": 41.0, "val_loss": 0.6925904417037964, "val_acc": 52.0}
{"epoch": 7, "training_loss": 0.7259471583366394, "training_acc": 43.0, "val_loss": 0.7912908101081848, "val_acc": 48.0}
{"epoch": 8, "training_loss": 0.7571664762496948, "training_acc": 49.0, "val_loss": 0.7283747792243958, "val_acc": 52.0}
{"epoch": 9, "training_loss": 0.7060939884185791, "training_acc": 53.0, "val_loss": 0.7285546255111695, "val_acc": 48.0}
{"epoch": 10, "training_loss": 0.7140667486190796, "training_acc": 49.0, "val_loss": 0.6954432988166809, "val_acc": 48.0}
{"epoch": 11, "training_loss": 0.7357552528381348, "training_acc": 49.0, "val_loss": 0.6925648117065429, "val_acc": 52.0}
{"epoch": 12, "training_loss": 0.7444685888290405, "training_acc": 43.0, "val_loss": 0.7149188184738159, "val_acc": 48.0}
{"epoch": 13, "training_loss": 0.7205657410621643, "training_acc": 45.0, "val_loss": 0.6999687957763672, "val_acc": 52.0}
{"epoch": 14, "training_loss": 0.7399429178237915, "training_acc": 45.0, "val_loss": 0.6956670546531677, "val_acc": 48.0}
{"epoch": 15, "training_loss": 0.6994513916969299, "training_acc": 51.0, "val_loss": 0.6929288148880005, "val_acc": 52.0}
{"epoch": 16, "training_loss": 0.7103740692138671, "training_acc": 51.0, "val_loss": 0.7016868329048157, "val_acc": 48.0}
{"epoch": 17, "training_loss": 0.7119003891944885, "training_acc": 49.0, "val_loss": 0.6957573699951172, "val_acc": 48.0}
{"epoch": 18, "training_loss": 0.7039183473587036, "training_acc": 43.0, "val_loss": 0.7047570013999939, "val_acc": 48.0}
{"epoch": 19, "training_loss": 0.6985789871215821, "training_acc": 51.0, "val_loss": 0.6924059271812439, "val_acc": 52.0}
{"epoch": 20, "training_loss": 0.7034496998786927, "training_acc": 47.0, "val_loss": 0.6923669075965881, "val_acc": 52.0}
{"epoch": 21, "training_loss": 0.7078468322753906, "training_acc": 41.0, "val_loss": 0.6923474740982055, "val_acc": 52.0}
{"epoch": 22, "training_loss": 0.7085440087318421, "training_acc": 49.0, "val_loss": 0.748183946609497, "val_acc": 48.0}
{"epoch": 23, "training_loss": 0.7262562990188599, "training_acc": 51.0, "val_loss": 0.6936122512817383, "val_acc": 48.0}
{"epoch": 24, "training_loss": 0.7099940347671508, "training_acc": 45.0, "val_loss": 0.6950402522087097, "val_acc": 52.0}
{"epoch": 25, "training_loss": 0.715076675415039, "training_acc": 41.0, "val_loss": 0.7070133161544799, "val_acc": 52.0}
{"epoch": 26, "training_loss": 0.7213046455383301, "training_acc": 51.0, "val_loss": 0.7232262825965882, "val_acc": 48.0}
{"epoch": 27, "training_loss": 0.7114597511291504, "training_acc": 47.0, "val_loss": 0.6934613537788391, "val_acc": 52.0}
{"epoch": 28, "training_loss": 0.7064963054656982, "training_acc": 49.0, "val_loss": 0.7288748717308045, "val_acc": 48.0}
{"epoch": 29, "training_loss": 0.7086177492141723, "training_acc": 49.0, "val_loss": 0.6934143614768982, "val_acc": 48.0}
{"epoch": 30, "training_loss": 0.7259683609008789, "training_acc": 37.0, "val_loss": 0.7036220860481263, "val_acc": 48.0}
{"epoch": 31, "training_loss": 0.7084394121170043, "training_acc": 51.0, "val_loss": 0.7005626773834228, "val_acc": 48.0}
{"epoch": 32, "training_loss": 0.7013613224029541, "training_acc": 51.0, "val_loss": 0.7477880096435547, "val_acc": 48.0}
{"epoch": 33, "training_loss": 0.7476723074913025, "training_acc": 55.0, "val_loss": 0.7648450326919556, "val_acc": 52.0}
{"epoch": 34, "training_loss": 0.728409698009491, "training_acc": 51.0, "val_loss": 0.7446421980857849, "val_acc": 48.0}
{"epoch": 35, "training_loss": 0.7138212299346924, "training_acc": 49.0, "val_loss": 0.7272401022911071, "val_acc": 52.0}
{"epoch": 36, "training_loss": 0.7563036680221558, "training_acc": 49.0, "val_loss": 0.7172612833976746, "val_acc": 48.0}
{"epoch": 37, "training_loss": 0.7451968717575074, "training_acc": 51.0, "val_loss": 0.7038795185089112, "val_acc": 48.0}
{"epoch": 38, "training_loss": 0.7161734962463379, "training_acc": 39.0, "val_loss": 0.6929578042030334, "val_acc": 52.0}
{"epoch": 39, "training_loss": 0.7182829141616821, "training_acc": 51.0, "val_loss": 0.8357429218292236, "val_acc": 48.0}
{"epoch": 40, "training_loss": 0.7596349811553955, "training_acc": 51.0, "val_loss": 0.7013672327995301, "val_acc": 52.0}
