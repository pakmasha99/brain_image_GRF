"main_modify.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 2 --task ADNI_sex --input_option yAware --learning_rate 1e-2 --batch_size 16 --weight_decay 1e-2 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 1.5004825067520142, "training_acc": 43.0, "val_loss": 0.7110703778266907, "val_acc": 52.0}
{"epoch": 1, "training_loss": 0.88564936876297, "training_acc": 45.0, "val_loss": 0.8554746627807617, "val_acc": 48.0}
{"epoch": 2, "training_loss": 0.7577130031585694, "training_acc": 51.0, "val_loss": 0.6952404141426086, "val_acc": 52.0}
{"epoch": 3, "training_loss": 0.737068133354187, "training_acc": 39.0, "val_loss": 0.7001445698738098, "val_acc": 52.0}
{"epoch": 4, "training_loss": 0.7257320141792297, "training_acc": 43.0, "val_loss": 0.6929567384719849, "val_acc": 52.0}
{"epoch": 5, "training_loss": 0.7040422439575196, "training_acc": 49.0, "val_loss": 0.829542248249054, "val_acc": 48.0}
{"epoch": 6, "training_loss": 0.7498830127716064, "training_acc": 45.0, "val_loss": 0.7487455368041992, "val_acc": 52.0}
{"epoch": 7, "training_loss": 0.7768660140037537, "training_acc": 45.0, "val_loss": 0.692787480354309, "val_acc": 52.0}
{"epoch": 8, "training_loss": 0.7258050465583801, "training_acc": 47.0, "val_loss": 0.7611612796783447, "val_acc": 48.0}
{"epoch": 9, "training_loss": 0.7673606443405151, "training_acc": 45.0, "val_loss": 0.7388042306900025, "val_acc": 48.0}
{"epoch": 10, "training_loss": 0.7630021333694458, "training_acc": 45.0, "val_loss": 0.7074562549591065, "val_acc": 48.0}
{"epoch": 11, "training_loss": 0.709929621219635, "training_acc": 49.0, "val_loss": 0.7427366614341736, "val_acc": 48.0}
{"epoch": 12, "training_loss": 0.7162236547470093, "training_acc": 47.0, "val_loss": 0.708122980594635, "val_acc": 48.0}
{"epoch": 13, "training_loss": 0.7177886891365052, "training_acc": 43.0, "val_loss": 0.8444986701011657, "val_acc": 48.0}
{"epoch": 14, "training_loss": 0.8403705620765686, "training_acc": 47.0, "val_loss": 0.7203797030448914, "val_acc": 48.0}
{"epoch": 15, "training_loss": 0.7243611645698548, "training_acc": 51.0, "val_loss": 0.7478631973266602, "val_acc": 52.0}
{"epoch": 16, "training_loss": 0.8063649702072143, "training_acc": 49.0, "val_loss": 0.6934690475463867, "val_acc": 52.0}
{"epoch": 17, "training_loss": 0.7191481351852417, "training_acc": 43.0, "val_loss": 0.7098124527931213, "val_acc": 48.0}
{"epoch": 18, "training_loss": 0.7234712934494019, "training_acc": 49.0, "val_loss": 0.6930448698997498, "val_acc": 52.0}
{"epoch": 19, "training_loss": 0.7126952767372131, "training_acc": 39.0, "val_loss": 0.7417299699783325, "val_acc": 48.0}
{"epoch": 20, "training_loss": 0.7347693777084351, "training_acc": 51.0, "val_loss": 0.7331222414970398, "val_acc": 52.0}
{"epoch": 21, "training_loss": 0.8861575841903686, "training_acc": 49.0, "val_loss": 0.7136138653755189, "val_acc": 48.0}
{"epoch": 22, "training_loss": 0.7107933473587036, "training_acc": 51.0, "val_loss": 0.6934520411491394, "val_acc": 48.0}
{"epoch": 23, "training_loss": 0.7267918515205384, "training_acc": 43.0, "val_loss": 0.6943158745765686, "val_acc": 48.0}
{"epoch": 24, "training_loss": 0.7049815082550048, "training_acc": 53.0, "val_loss": 0.6926284885406494, "val_acc": 52.0}
{"epoch": 25, "training_loss": 0.7172981524467468, "training_acc": 43.0, "val_loss": 0.6965415501594543, "val_acc": 52.0}
{"epoch": 26, "training_loss": 0.7094775247573852, "training_acc": 51.0, "val_loss": 0.7104405283927917, "val_acc": 48.0}
{"epoch": 27, "training_loss": 0.7093152236938477, "training_acc": 45.0, "val_loss": 0.7025583958625794, "val_acc": 48.0}
{"epoch": 28, "training_loss": 0.7201446008682251, "training_acc": 53.0, "val_loss": 0.756544759273529, "val_acc": 52.0}
{"epoch": 29, "training_loss": 0.7383859491348267, "training_acc": 51.0, "val_loss": 0.7440665149688721, "val_acc": 48.0}
{"epoch": 30, "training_loss": 0.7216561603546142, "training_acc": 51.0, "val_loss": 0.6934065628051758, "val_acc": 52.0}
{"epoch": 31, "training_loss": 0.7064341688156128, "training_acc": 51.0, "val_loss": 0.7707866740226745, "val_acc": 48.0}
{"epoch": 32, "training_loss": 0.7210936450958252, "training_acc": 51.0, "val_loss": 0.7028077244758606, "val_acc": 52.0}
{"epoch": 33, "training_loss": 0.7482376146316528, "training_acc": 47.0, "val_loss": 0.7407483696937561, "val_acc": 48.0}
{"epoch": 34, "training_loss": 0.7186404418945312, "training_acc": 51.0, "val_loss": 0.6937802243232727, "val_acc": 52.0}
{"epoch": 35, "training_loss": 0.7202935767173767, "training_acc": 53.0, "val_loss": 0.7385666728019714, "val_acc": 48.0}
{"epoch": 36, "training_loss": 0.7319538116455078, "training_acc": 49.0, "val_loss": 0.7853303718566894, "val_acc": 52.0}
{"epoch": 37, "training_loss": 0.7811769151687622, "training_acc": 47.0, "val_loss": 0.7461274623870849, "val_acc": 48.0}
{"epoch": 38, "training_loss": 0.7277754354476929, "training_acc": 53.0, "val_loss": 0.7074158430099488, "val_acc": 52.0}
{"epoch": 39, "training_loss": 0.7241380500793457, "training_acc": 49.0, "val_loss": 0.7200225019454956, "val_acc": 48.0}
{"epoch": 40, "training_loss": 0.6936321926116943, "training_acc": 51.0, "val_loss": 0.7104298901557923, "val_acc": 52.0}
{"epoch": 41, "training_loss": 0.7184554910659791, "training_acc": 47.0, "val_loss": 0.6983546829223632, "val_acc": 48.0}
{"epoch": 42, "training_loss": 0.7044550323486328, "training_acc": 49.0, "val_loss": 0.7156939649581909, "val_acc": 52.0}
{"epoch": 43, "training_loss": 0.7175080728530884, "training_acc": 51.0, "val_loss": 0.7022876596450806, "val_acc": 48.0}
