"main_modify.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 2 --task ADNI_sex --input_option yAware --learning_rate 1e-2 --batch_size 16 --weight_decay 1e-2 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 1.374265766143799, "training_acc": 46.0, "val_loss": 0.7307996416091919, "val_acc": 52.0}
{"epoch": 1, "training_loss": 0.7918397903442382, "training_acc": 48.0, "val_loss": 0.7146918916702271, "val_acc": 48.0}
{"epoch": 2, "training_loss": 0.7326714968681336, "training_acc": 44.0, "val_loss": 0.8302549171447754, "val_acc": 48.0}
{"epoch": 3, "training_loss": 0.7488673830032349, "training_acc": 44.0, "val_loss": 0.8131464457511902, "val_acc": 48.0}
{"epoch": 4, "training_loss": 0.7218475031852722, "training_acc": 52.0, "val_loss": 0.6927775573730469, "val_acc": 52.0}
{"epoch": 5, "training_loss": 0.731839838027954, "training_acc": 42.0, "val_loss": 0.7124551200866699, "val_acc": 52.0}
{"epoch": 6, "training_loss": 0.7123172426223755, "training_acc": 56.0, "val_loss": 0.7053383135795593, "val_acc": 48.0}
{"epoch": 7, "training_loss": 0.7028090953826904, "training_acc": 54.0, "val_loss": 0.70090083360672, "val_acc": 48.0}
{"epoch": 8, "training_loss": 0.7312881898880005, "training_acc": 40.0, "val_loss": 0.6980563378334046, "val_acc": 52.0}
{"epoch": 9, "training_loss": 0.7117694115638733, "training_acc": 50.0, "val_loss": 0.7165953421592712, "val_acc": 52.0}
{"epoch": 10, "training_loss": 0.7358139610290527, "training_acc": 42.0, "val_loss": 0.6977932643890381, "val_acc": 48.0}
{"epoch": 11, "training_loss": 0.7094883060455323, "training_acc": 48.0, "val_loss": 0.8332239222526551, "val_acc": 48.0}
{"epoch": 12, "training_loss": 0.7836772751808166, "training_acc": 36.0, "val_loss": 0.7093718814849853, "val_acc": 52.0}
{"epoch": 13, "training_loss": 0.7715845012664795, "training_acc": 54.0, "val_loss": 0.8073769450187683, "val_acc": 48.0}
{"epoch": 14, "training_loss": 0.7683840584754944, "training_acc": 48.0, "val_loss": 0.8410201573371887, "val_acc": 48.0}
{"epoch": 15, "training_loss": 0.7848838138580322, "training_acc": 46.0, "val_loss": 0.692360577583313, "val_acc": 52.0}
{"epoch": 16, "training_loss": 0.7103056859970093, "training_acc": 46.0, "val_loss": 0.6974135327339173, "val_acc": 48.0}
{"epoch": 17, "training_loss": 0.7280561709403992, "training_acc": 48.0, "val_loss": 0.9702328491210938, "val_acc": 48.0}
{"epoch": 18, "training_loss": 0.808481650352478, "training_acc": 54.0, "val_loss": 0.7890906620025635, "val_acc": 52.0}
{"epoch": 19, "training_loss": 0.7703562903404236, "training_acc": 44.0, "val_loss": 0.6946932530403137, "val_acc": 52.0}
{"epoch": 20, "training_loss": 0.730043785572052, "training_acc": 46.0, "val_loss": 0.6951117730140686, "val_acc": 48.0}
{"epoch": 21, "training_loss": 0.6975208806991577, "training_acc": 48.0, "val_loss": 0.7188970232009888, "val_acc": 52.0}
{"epoch": 22, "training_loss": 0.7124788808822632, "training_acc": 50.0, "val_loss": 0.74387047290802, "val_acc": 48.0}
{"epoch": 23, "training_loss": 0.7173063492774964, "training_acc": 50.0, "val_loss": 0.7355933451652527, "val_acc": 52.0}
{"epoch": 24, "training_loss": 0.7374798965454101, "training_acc": 40.0, "val_loss": 0.6932471656799316, "val_acc": 48.0}
{"epoch": 25, "training_loss": 0.737261266708374, "training_acc": 46.0, "val_loss": 0.6941099548339844, "val_acc": 48.0}
{"epoch": 26, "training_loss": 0.7079326343536377, "training_acc": 48.0, "val_loss": 0.7114160585403443, "val_acc": 48.0}
{"epoch": 27, "training_loss": 0.7093361377716064, "training_acc": 44.0, "val_loss": 0.6930253696441651, "val_acc": 52.0}
{"epoch": 28, "training_loss": 0.705435619354248, "training_acc": 44.0, "val_loss": 0.7152790069580078, "val_acc": 52.0}
{"epoch": 29, "training_loss": 0.7083892679214477, "training_acc": 50.0, "val_loss": 0.735294964313507, "val_acc": 48.0}
{"epoch": 30, "training_loss": 0.7231826972961426, "training_acc": 46.0, "val_loss": 0.6923544669151306, "val_acc": 52.0}
{"epoch": 31, "training_loss": 0.7018273878097534, "training_acc": 46.0, "val_loss": 0.7017210340499878, "val_acc": 48.0}
{"epoch": 32, "training_loss": 0.7052263545989991, "training_acc": 42.0, "val_loss": 0.7216769361495972, "val_acc": 48.0}
{"epoch": 33, "training_loss": 0.7235355544090271, "training_acc": 44.0, "val_loss": 0.7090842938423156, "val_acc": 48.0}
{"epoch": 34, "training_loss": 0.7067276024818421, "training_acc": 50.0, "val_loss": 0.7431016755104065, "val_acc": 48.0}
{"epoch": 35, "training_loss": 0.7137380385398865, "training_acc": 48.0, "val_loss": 0.6948942875862122, "val_acc": 52.0}
{"epoch": 36, "training_loss": 0.7374941110610962, "training_acc": 48.0, "val_loss": 0.7023285865783692, "val_acc": 48.0}
{"epoch": 37, "training_loss": 0.7132833623886108, "training_acc": 46.0, "val_loss": 0.7336479592323303, "val_acc": 52.0}
{"epoch": 38, "training_loss": 0.7285187554359436, "training_acc": 44.0, "val_loss": 0.7065366315841675, "val_acc": 48.0}
{"epoch": 39, "training_loss": 0.7044482207298279, "training_acc": 50.0, "val_loss": 0.6923971962928772, "val_acc": 52.0}
{"epoch": 40, "training_loss": 0.7106047916412354, "training_acc": 50.0, "val_loss": 0.7032224130630493, "val_acc": 48.0}
{"epoch": 41, "training_loss": 0.7074893569946289, "training_acc": 50.0, "val_loss": 0.6942590761184693, "val_acc": 52.0}
{"epoch": 42, "training_loss": 0.7214541435241699, "training_acc": 46.0, "val_loss": 0.70706871509552, "val_acc": 48.0}
{"epoch": 43, "training_loss": 0.7345072269439697, "training_acc": 40.0, "val_loss": 0.6923657941818238, "val_acc": 52.0}
{"epoch": 44, "training_loss": 0.7298777437210083, "training_acc": 48.0, "val_loss": 0.6932616639137268, "val_acc": 52.0}
{"epoch": 45, "training_loss": 0.7226170825958252, "training_acc": 50.0, "val_loss": 0.6966415739059448, "val_acc": 48.0}
{"epoch": 46, "training_loss": 0.7218697595596314, "training_acc": 48.0, "val_loss": 0.6975478482246399, "val_acc": 52.0}
{"epoch": 47, "training_loss": 0.7006314373016358, "training_acc": 52.0, "val_loss": 0.7304606175422669, "val_acc": 48.0}
{"epoch": 48, "training_loss": 0.7073213577270507, "training_acc": 50.0, "val_loss": 0.697967426776886, "val_acc": 52.0}
{"epoch": 49, "training_loss": 0.7160522294044495, "training_acc": 48.0, "val_loss": 0.6925419163703919, "val_acc": 52.0}
