"main_modify.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 6 --task ADNI_sex --input_option yAware --learning_rate 1e-2 --batch_size 16 --weight_decay 1e-2 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 1.3014495038986207, "training_acc": 50.0, "val_loss": 0.7016827321052551, "val_acc": 48.0}
{"epoch": 1, "training_loss": 0.7848935770988464, "training_acc": 50.0, "val_loss": 0.7073413109779358, "val_acc": 52.0}
{"epoch": 2, "training_loss": 0.7291854286193847, "training_acc": 50.0, "val_loss": 0.7436085247993469, "val_acc": 52.0}
{"epoch": 3, "training_loss": 0.7330465602874756, "training_acc": 54.0, "val_loss": 0.9932867646217346, "val_acc": 48.0}
{"epoch": 4, "training_loss": 0.7990163898468018, "training_acc": 50.0, "val_loss": 0.7385679173469544, "val_acc": 52.0}
{"epoch": 5, "training_loss": 0.7100639700889587, "training_acc": 58.0, "val_loss": 0.8590969467163085, "val_acc": 48.0}
{"epoch": 6, "training_loss": 0.7646596765518189, "training_acc": 46.0, "val_loss": 0.7107781958580017, "val_acc": 48.0}
{"epoch": 7, "training_loss": 0.7296926593780517, "training_acc": 46.0, "val_loss": 0.9342579555511474, "val_acc": 48.0}
{"epoch": 8, "training_loss": 0.8316440868377686, "training_acc": 46.0, "val_loss": 0.7164674353599548, "val_acc": 52.0}
{"epoch": 9, "training_loss": 0.6945078110694886, "training_acc": 54.0, "val_loss": 0.7008652567863465, "val_acc": 48.0}
{"epoch": 10, "training_loss": 0.7276145029067993, "training_acc": 44.0, "val_loss": 0.7542907452583313, "val_acc": 48.0}
{"epoch": 11, "training_loss": 0.6931712245941162, "training_acc": 60.0, "val_loss": 0.9869154381752014, "val_acc": 52.0}
{"epoch": 12, "training_loss": 0.8534862041473389, "training_acc": 44.0, "val_loss": 0.7784473037719727, "val_acc": 52.0}
{"epoch": 13, "training_loss": 0.7933554816246032, "training_acc": 48.0, "val_loss": 0.6990125632286072, "val_acc": 52.0}
{"epoch": 14, "training_loss": 0.744216423034668, "training_acc": 48.0, "val_loss": 0.7051812362670898, "val_acc": 48.0}
{"epoch": 15, "training_loss": 0.7280901455879212, "training_acc": 40.0, "val_loss": 0.7100214886665345, "val_acc": 48.0}
{"epoch": 16, "training_loss": 0.7096575164794922, "training_acc": 46.0, "val_loss": 0.700459623336792, "val_acc": 52.0}
{"epoch": 17, "training_loss": 0.7309428071975708, "training_acc": 40.0, "val_loss": 0.7143550157546997, "val_acc": 52.0}
{"epoch": 18, "training_loss": 0.7305698204040527, "training_acc": 52.0, "val_loss": 0.7657847023010254, "val_acc": 48.0}
{"epoch": 19, "training_loss": 0.7507109689712524, "training_acc": 46.0, "val_loss": 0.6947429394721985, "val_acc": 48.0}
{"epoch": 20, "training_loss": 0.6983205151557922, "training_acc": 50.0, "val_loss": 0.6949829077720642, "val_acc": 48.0}
{"epoch": 21, "training_loss": 0.7066204071044921, "training_acc": 52.0, "val_loss": 0.7222723698616028, "val_acc": 52.0}
{"epoch": 22, "training_loss": 0.7114856266975402, "training_acc": 50.0, "val_loss": 0.7163967490196228, "val_acc": 48.0}
{"epoch": 23, "training_loss": 0.7353186917304992, "training_acc": 48.0, "val_loss": 0.6928149366378784, "val_acc": 52.0}
{"epoch": 24, "training_loss": 0.7020871138572693, "training_acc": 52.0, "val_loss": 0.7271213865280152, "val_acc": 48.0}
{"epoch": 25, "training_loss": 0.7093219041824341, "training_acc": 48.0, "val_loss": 0.6972682499885559, "val_acc": 48.0}
{"epoch": 26, "training_loss": 0.7001073741912842, "training_acc": 44.0, "val_loss": 0.7077459692955017, "val_acc": 48.0}
{"epoch": 27, "training_loss": 0.7388381361961365, "training_acc": 42.0, "val_loss": 0.6935533332824707, "val_acc": 52.0}
{"epoch": 28, "training_loss": 0.7063694286346436, "training_acc": 46.0, "val_loss": 0.7213016366958618, "val_acc": 48.0}
{"epoch": 29, "training_loss": 0.7182351016998291, "training_acc": 50.0, "val_loss": 0.7236981987953186, "val_acc": 52.0}
{"epoch": 30, "training_loss": 0.7116753196716309, "training_acc": 50.0, "val_loss": 0.779856493473053, "val_acc": 48.0}
{"epoch": 31, "training_loss": 0.7533930850028991, "training_acc": 44.0, "val_loss": 0.7319324541091919, "val_acc": 52.0}
{"epoch": 32, "training_loss": 0.7142956137657166, "training_acc": 54.0, "val_loss": 0.8050908374786377, "val_acc": 48.0}
{"epoch": 33, "training_loss": 0.7320355987548828, "training_acc": 50.0, "val_loss": 0.7286562156677246, "val_acc": 52.0}
{"epoch": 34, "training_loss": 0.7232625842094421, "training_acc": 52.0, "val_loss": 0.8128262424468994, "val_acc": 48.0}
{"epoch": 35, "training_loss": 0.7582469463348389, "training_acc": 48.0, "val_loss": 0.6949587321281433, "val_acc": 52.0}
{"epoch": 36, "training_loss": 0.7285730624198914, "training_acc": 42.0, "val_loss": 0.6924245238304139, "val_acc": 52.0}
{"epoch": 37, "training_loss": 0.7041189289093017, "training_acc": 42.0, "val_loss": 0.7027648663520814, "val_acc": 52.0}
{"epoch": 38, "training_loss": 0.7034810924530029, "training_acc": 52.0, "val_loss": 0.7746388745307923, "val_acc": 48.0}
{"epoch": 39, "training_loss": 0.7654311752319336, "training_acc": 50.0, "val_loss": 0.7273605847358704, "val_acc": 52.0}
{"epoch": 40, "training_loss": 0.7819809532165527, "training_acc": 48.0, "val_loss": 0.6995896983146668, "val_acc": 48.0}
{"epoch": 41, "training_loss": 0.7103024864196777, "training_acc": 46.0, "val_loss": 0.6925632905960083, "val_acc": 52.0}
{"epoch": 42, "training_loss": 0.7125554871559143, "training_acc": 48.0, "val_loss": 0.7066501212120057, "val_acc": 48.0}
{"epoch": 43, "training_loss": 0.7047309923171997, "training_acc": 50.0, "val_loss": 0.692378237247467, "val_acc": 52.0}
{"epoch": 44, "training_loss": 0.7210943651199341, "training_acc": 46.0, "val_loss": 0.6981385374069213, "val_acc": 52.0}
{"epoch": 45, "training_loss": 0.7045337629318237, "training_acc": 52.0, "val_loss": 0.7673824810981751, "val_acc": 48.0}
{"epoch": 46, "training_loss": 0.7300224328041076, "training_acc": 46.0, "val_loss": 0.692392840385437, "val_acc": 52.0}
{"epoch": 47, "training_loss": 0.7140252256393432, "training_acc": 44.0, "val_loss": 0.7355902552604675, "val_acc": 52.0}
{"epoch": 48, "training_loss": 0.7477208662033081, "training_acc": 48.0, "val_loss": 0.7024637699127197, "val_acc": 48.0}
{"epoch": 49, "training_loss": 0.7242076778411866, "training_acc": 48.0, "val_loss": 0.7611605763435364, "val_acc": 48.0}
{"epoch": 50, "training_loss": 0.7277794218063355, "training_acc": 48.0, "val_loss": 0.7135556650161743, "val_acc": 48.0}
{"epoch": 51, "training_loss": 0.7054116296768188, "training_acc": 52.0, "val_loss": 0.8230118536949158, "val_acc": 52.0}
{"epoch": 52, "training_loss": 0.7818445348739624, "training_acc": 54.0, "val_loss": 0.7762165188789367, "val_acc": 48.0}
{"epoch": 53, "training_loss": 0.7838286590576172, "training_acc": 48.0, "val_loss": 0.7092890977859497, "val_acc": 48.0}
{"epoch": 54, "training_loss": 0.7178386688232422, "training_acc": 44.0, "val_loss": 0.7191581583023071, "val_acc": 48.0}
{"epoch": 55, "training_loss": 0.7458915853500366, "training_acc": 44.0, "val_loss": 0.6939083766937256, "val_acc": 48.0}
{"epoch": 56, "training_loss": 0.7064222621917725, "training_acc": 44.0, "val_loss": 0.700563280582428, "val_acc": 48.0}
{"epoch": 57, "training_loss": 0.7128659248352051, "training_acc": 48.0, "val_loss": 0.823968665599823, "val_acc": 48.0}
{"epoch": 58, "training_loss": 0.8243587732315063, "training_acc": 54.0, "val_loss": 0.9884613513946533, "val_acc": 52.0}
{"epoch": 59, "training_loss": 0.9995813465118408, "training_acc": 48.0, "val_loss": 0.7447676038742066, "val_acc": 48.0}
{"epoch": 60, "training_loss": 0.7475779104232788, "training_acc": 50.0, "val_loss": 0.6936933612823486, "val_acc": 52.0}
{"epoch": 61, "training_loss": 0.7263011479377747, "training_acc": 50.0, "val_loss": 0.6992078423500061, "val_acc": 48.0}
{"epoch": 62, "training_loss": 0.7155762529373169, "training_acc": 46.0, "val_loss": 0.6949873352050782, "val_acc": 52.0}
