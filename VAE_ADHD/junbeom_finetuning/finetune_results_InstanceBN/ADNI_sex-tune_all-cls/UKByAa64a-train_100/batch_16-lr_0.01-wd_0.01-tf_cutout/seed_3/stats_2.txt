"main_modify.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 3 --task ADNI_sex --input_option yAware --learning_rate 1e-2 --batch_size 16 --weight_decay 1e-2 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 1.5824232053756715, "training_acc": 44.0, "val_loss": 0.6962653732299805, "val_acc": 48.0}
{"epoch": 1, "training_loss": 0.9070863771438599, "training_acc": 48.0, "val_loss": 0.7115412068367004, "val_acc": 48.0}
{"epoch": 2, "training_loss": 0.7251814270019531, "training_acc": 46.0, "val_loss": 0.697684931755066, "val_acc": 52.0}
{"epoch": 3, "training_loss": 0.7408816623687744, "training_acc": 52.0, "val_loss": 0.8849106645584106, "val_acc": 48.0}
{"epoch": 4, "training_loss": 0.7597593498229981, "training_acc": 48.0, "val_loss": 0.775803337097168, "val_acc": 52.0}
{"epoch": 5, "training_loss": 0.7938173961639404, "training_acc": 34.0, "val_loss": 0.6999070072174072, "val_acc": 48.0}
{"epoch": 6, "training_loss": 0.7013579320907593, "training_acc": 48.0, "val_loss": 0.6935406994819641, "val_acc": 48.0}
{"epoch": 7, "training_loss": 0.7293668603897094, "training_acc": 54.0, "val_loss": 0.6923758792877197, "val_acc": 52.0}
{"epoch": 8, "training_loss": 0.7009411525726318, "training_acc": 52.0, "val_loss": 0.7431846213340759, "val_acc": 48.0}
{"epoch": 9, "training_loss": 0.7184468078613281, "training_acc": 50.0, "val_loss": 0.6935652828216553, "val_acc": 48.0}
{"epoch": 10, "training_loss": 0.7184007382392883, "training_acc": 46.0, "val_loss": 0.7323865246772766, "val_acc": 52.0}
{"epoch": 11, "training_loss": 0.7166825532913208, "training_acc": 52.0, "val_loss": 0.7011716318130493, "val_acc": 52.0}
{"epoch": 12, "training_loss": 0.7291950225830078, "training_acc": 50.0, "val_loss": 0.9151619815826416, "val_acc": 52.0}
{"epoch": 13, "training_loss": 0.7948707389831543, "training_acc": 50.0, "val_loss": 0.7047490572929382, "val_acc": 48.0}
{"epoch": 14, "training_loss": 0.7042439651489257, "training_acc": 50.0, "val_loss": 0.7777865672111511, "val_acc": 48.0}
{"epoch": 15, "training_loss": 0.7445869016647338, "training_acc": 52.0, "val_loss": 0.704118835926056, "val_acc": 48.0}
{"epoch": 16, "training_loss": 0.7360291814804077, "training_acc": 46.0, "val_loss": 0.8378759813308716, "val_acc": 48.0}
{"epoch": 17, "training_loss": 0.8188673281669616, "training_acc": 42.0, "val_loss": 0.7044500613212585, "val_acc": 52.0}
{"epoch": 18, "training_loss": 0.7473034381866455, "training_acc": 48.0, "val_loss": 0.8020782542228698, "val_acc": 52.0}
{"epoch": 19, "training_loss": 0.8444034504890442, "training_acc": 40.0, "val_loss": 0.7274381589889526, "val_acc": 52.0}
{"epoch": 20, "training_loss": 0.715582103729248, "training_acc": 54.0, "val_loss": 0.9009675216674805, "val_acc": 48.0}
{"epoch": 21, "training_loss": 0.7865036678314209, "training_acc": 48.0, "val_loss": 0.6936807036399841, "val_acc": 52.0}
{"epoch": 22, "training_loss": 0.7286426591873169, "training_acc": 42.0, "val_loss": 0.6999447751045227, "val_acc": 48.0}
{"epoch": 23, "training_loss": 0.7427688407897949, "training_acc": 42.0, "val_loss": 0.7215556693077088, "val_acc": 52.0}
{"epoch": 24, "training_loss": 0.7211157345771789, "training_acc": 48.0, "val_loss": 0.6949753785133361, "val_acc": 48.0}
{"epoch": 25, "training_loss": 0.7201914453506469, "training_acc": 44.0, "val_loss": 0.6990534520149231, "val_acc": 48.0}
{"epoch": 26, "training_loss": 0.7002392387390137, "training_acc": 46.0, "val_loss": 0.6923480343818664, "val_acc": 52.0}
{"epoch": 27, "training_loss": 0.7125724124908447, "training_acc": 44.0, "val_loss": 0.6923530220985412, "val_acc": 52.0}
{"epoch": 28, "training_loss": 0.6955987310409546, "training_acc": 46.0, "val_loss": 0.7210390090942382, "val_acc": 48.0}
{"epoch": 29, "training_loss": 0.7184674596786499, "training_acc": 52.0, "val_loss": 0.7249996495246888, "val_acc": 52.0}
{"epoch": 30, "training_loss": 0.741722846031189, "training_acc": 48.0, "val_loss": 0.6970068144798279, "val_acc": 48.0}
{"epoch": 31, "training_loss": 0.7064646792411804, "training_acc": 46.0, "val_loss": 0.7077975869178772, "val_acc": 48.0}
{"epoch": 32, "training_loss": 0.737893054485321, "training_acc": 50.0, "val_loss": 0.6928388261795044, "val_acc": 52.0}
{"epoch": 33, "training_loss": 0.6951838111877442, "training_acc": 50.0, "val_loss": 0.7180245280265808, "val_acc": 52.0}
{"epoch": 34, "training_loss": 0.7497400999069214, "training_acc": 50.0, "val_loss": 0.7190346932411193, "val_acc": 48.0}
{"epoch": 35, "training_loss": 0.7044841718673706, "training_acc": 50.0, "val_loss": 0.6931946730613708, "val_acc": 48.0}
{"epoch": 36, "training_loss": 0.7302464318275451, "training_acc": 50.0, "val_loss": 0.6997793889045716, "val_acc": 52.0}
{"epoch": 37, "training_loss": 0.7153091382980347, "training_acc": 48.0, "val_loss": 0.6936294984817505, "val_acc": 52.0}
{"epoch": 38, "training_loss": 0.7109357357025147, "training_acc": 44.0, "val_loss": 0.6925349473953247, "val_acc": 52.0}
{"epoch": 39, "training_loss": 0.699971055984497, "training_acc": 46.0, "val_loss": 0.6923753380775451, "val_acc": 52.0}
{"epoch": 40, "training_loss": 0.7194795775413513, "training_acc": 44.0, "val_loss": 0.7048819756507874, "val_acc": 52.0}
{"epoch": 41, "training_loss": 0.7651039099693299, "training_acc": 48.0, "val_loss": 0.6936333203315734, "val_acc": 48.0}
{"epoch": 42, "training_loss": 0.720765073299408, "training_acc": 42.0, "val_loss": 0.7012854504585266, "val_acc": 52.0}
{"epoch": 43, "training_loss": 0.7393566846847535, "training_acc": 50.0, "val_loss": 0.7142401432991028, "val_acc": 48.0}
{"epoch": 44, "training_loss": 0.7084447169303894, "training_acc": 50.0, "val_loss": 0.7549692749977112, "val_acc": 52.0}
{"epoch": 45, "training_loss": 0.7714610266685485, "training_acc": 48.0, "val_loss": 0.6951308298110962, "val_acc": 48.0}
