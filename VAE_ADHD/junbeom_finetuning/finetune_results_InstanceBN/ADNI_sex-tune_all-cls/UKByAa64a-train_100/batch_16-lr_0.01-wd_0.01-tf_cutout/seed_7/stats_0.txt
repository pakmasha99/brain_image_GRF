"main_modify.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 7 --task ADNI_sex --input_option yAware --learning_rate 1e-2 --batch_size 16 --weight_decay 1e-2 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 0.9658399200439454, "training_acc": 45.0, "val_loss": 0.6935146450996399, "val_acc": 52.0}
{"epoch": 1, "training_loss": 0.7796726202964783, "training_acc": 39.0, "val_loss": 0.7018079710006714, "val_acc": 48.0}
{"epoch": 2, "training_loss": 0.7289345431327819, "training_acc": 47.0, "val_loss": 0.9598961544036865, "val_acc": 48.0}
{"epoch": 3, "training_loss": 0.8705764102935791, "training_acc": 45.0, "val_loss": 0.7242456674575806, "val_acc": 48.0}
{"epoch": 4, "training_loss": 0.7527599692344665, "training_acc": 47.0, "val_loss": 0.6964848184585571, "val_acc": 48.0}
{"epoch": 5, "training_loss": 0.7312281656265259, "training_acc": 47.0, "val_loss": 0.7712261724472046, "val_acc": 52.0}
{"epoch": 6, "training_loss": 0.7924069118499756, "training_acc": 43.0, "val_loss": 0.693331573009491, "val_acc": 52.0}
{"epoch": 7, "training_loss": 0.6963682103157044, "training_acc": 53.0, "val_loss": 0.8718404150009156, "val_acc": 48.0}
{"epoch": 8, "training_loss": 0.85287921667099, "training_acc": 49.0, "val_loss": 0.7035294961929321, "val_acc": 52.0}
{"epoch": 9, "training_loss": 0.7385858535766602, "training_acc": 49.0, "val_loss": 0.6945108222961426, "val_acc": 48.0}
{"epoch": 10, "training_loss": 0.7214823675155639, "training_acc": 43.0, "val_loss": 0.7177717423439026, "val_acc": 52.0}
{"epoch": 11, "training_loss": 0.7263035631179809, "training_acc": 47.0, "val_loss": 0.7037496137619018, "val_acc": 52.0}
{"epoch": 12, "training_loss": 0.7159597945213317, "training_acc": 47.0, "val_loss": 0.7031251215934753, "val_acc": 48.0}
{"epoch": 13, "training_loss": 0.7297604942321777, "training_acc": 55.0, "val_loss": 0.7993288826942444, "val_acc": 52.0}
{"epoch": 14, "training_loss": 0.7052366828918457, "training_acc": 55.0, "val_loss": 0.8449513673782348, "val_acc": 48.0}
{"epoch": 15, "training_loss": 0.7487384033203125, "training_acc": 49.0, "val_loss": 0.6959145069122314, "val_acc": 48.0}
{"epoch": 16, "training_loss": 0.7118276882171631, "training_acc": 47.0, "val_loss": 0.7015466165542602, "val_acc": 52.0}
{"epoch": 17, "training_loss": 0.7108426284790039, "training_acc": 49.0, "val_loss": 0.7122337436676025, "val_acc": 48.0}
{"epoch": 18, "training_loss": 0.735288987159729, "training_acc": 43.0, "val_loss": 0.6948181915283204, "val_acc": 48.0}
{"epoch": 19, "training_loss": 0.7108666706085205, "training_acc": 51.0, "val_loss": 0.7000190544128418, "val_acc": 48.0}
{"epoch": 20, "training_loss": 0.7107124137878418, "training_acc": 51.0, "val_loss": 0.6924550342559814, "val_acc": 52.0}
{"epoch": 21, "training_loss": 0.7303091239929199, "training_acc": 43.0, "val_loss": 0.7314004158973694, "val_acc": 48.0}
{"epoch": 22, "training_loss": 0.7168336439132691, "training_acc": 49.0, "val_loss": 0.6925590443611145, "val_acc": 52.0}
{"epoch": 23, "training_loss": 0.7031315326690674, "training_acc": 43.0, "val_loss": 0.6925471925735474, "val_acc": 52.0}
{"epoch": 24, "training_loss": 0.7034933519363403, "training_acc": 53.0, "val_loss": 0.8327981305122375, "val_acc": 48.0}
{"epoch": 25, "training_loss": 0.7974306821823121, "training_acc": 43.0, "val_loss": 0.694876184463501, "val_acc": 52.0}
{"epoch": 26, "training_loss": 0.710970606803894, "training_acc": 45.0, "val_loss": 0.6932794690132141, "val_acc": 52.0}
{"epoch": 27, "training_loss": 0.7151678824424743, "training_acc": 43.0, "val_loss": 0.6975506663322448, "val_acc": 52.0}
{"epoch": 28, "training_loss": 0.7108391284942627, "training_acc": 47.0, "val_loss": 0.6927603220939637, "val_acc": 52.0}
{"epoch": 29, "training_loss": 0.6981913185119629, "training_acc": 49.0, "val_loss": 0.7334287977218628, "val_acc": 48.0}
{"epoch": 30, "training_loss": 0.7605251884460449, "training_acc": 51.0, "val_loss": 0.7500601983070374, "val_acc": 52.0}
{"epoch": 31, "training_loss": 0.750041663646698, "training_acc": 47.0, "val_loss": 0.7368025588989258, "val_acc": 48.0}
{"epoch": 32, "training_loss": 0.7177915692329406, "training_acc": 45.0, "val_loss": 0.7137174534797669, "val_acc": 48.0}
{"epoch": 33, "training_loss": 0.7206232404708862, "training_acc": 51.0, "val_loss": 0.6946622085571289, "val_acc": 52.0}
{"epoch": 34, "training_loss": 0.7243441343307495, "training_acc": 47.0, "val_loss": 0.6940990352630615, "val_acc": 48.0}
{"epoch": 35, "training_loss": 0.7040103578567505, "training_acc": 51.0, "val_loss": 0.7299015951156617, "val_acc": 52.0}
{"epoch": 36, "training_loss": 0.7297902297973633, "training_acc": 49.0, "val_loss": 0.7206948876380921, "val_acc": 48.0}
{"epoch": 37, "training_loss": 0.7015533256530762, "training_acc": 51.0, "val_loss": 0.7211644291877747, "val_acc": 52.0}
{"epoch": 38, "training_loss": 0.7358716583251953, "training_acc": 43.0, "val_loss": 0.6925909757614136, "val_acc": 52.0}
{"epoch": 39, "training_loss": 0.731565489768982, "training_acc": 41.0, "val_loss": 0.6974583339691162, "val_acc": 48.0}
