"main_modify.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 1 --task ADNI_sex --input_option yAware --learning_rate 1e-2 --batch_size 16 --weight_decay 1e-4 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 1.1173087739944458, "training_acc": 50.0, "val_loss": 0.8317813110351563, "val_acc": 52.0}
{"epoch": 1, "training_loss": 0.7957330226898194, "training_acc": 52.0, "val_loss": 0.8847992062568665, "val_acc": 52.0}
{"epoch": 2, "training_loss": 0.8277651405334473, "training_acc": 54.0, "val_loss": 0.7473412656784058, "val_acc": 48.0}
{"epoch": 3, "training_loss": 0.7269353294372558, "training_acc": 54.0, "val_loss": 0.6945629739761352, "val_acc": 48.0}
{"epoch": 4, "training_loss": 0.7022083330154419, "training_acc": 44.0, "val_loss": 0.7185218405723571, "val_acc": 48.0}
{"epoch": 5, "training_loss": 0.7427308559417725, "training_acc": 48.0, "val_loss": 0.6940070104598999, "val_acc": 52.0}
{"epoch": 6, "training_loss": 0.7064384555816651, "training_acc": 46.0, "val_loss": 0.8383127546310425, "val_acc": 48.0}
{"epoch": 7, "training_loss": 0.8344743442535401, "training_acc": 48.0, "val_loss": 0.832594347000122, "val_acc": 52.0}
{"epoch": 8, "training_loss": 0.7849783539772034, "training_acc": 48.0, "val_loss": 0.7296724915504456, "val_acc": 52.0}
{"epoch": 9, "training_loss": 0.8224549865722657, "training_acc": 48.0, "val_loss": 0.7868131685256958, "val_acc": 48.0}
{"epoch": 10, "training_loss": 0.8113374137878417, "training_acc": 46.0, "val_loss": 0.836121780872345, "val_acc": 48.0}
{"epoch": 11, "training_loss": 0.8460365295410156, "training_acc": 56.0, "val_loss": 1.1684368085861205, "val_acc": 52.0}
{"epoch": 12, "training_loss": 1.1017867708206177, "training_acc": 50.0, "val_loss": 1.36267897605896, "val_acc": 48.0}
{"epoch": 13, "training_loss": 1.0869177556037903, "training_acc": 46.0, "val_loss": 1.046134786605835, "val_acc": 52.0}
{"epoch": 14, "training_loss": 0.9327932214736938, "training_acc": 48.0, "val_loss": 0.7903093910217285, "val_acc": 48.0}
{"epoch": 15, "training_loss": 0.7554864406585693, "training_acc": 50.0, "val_loss": 0.7010822343826294, "val_acc": 52.0}
{"epoch": 16, "training_loss": 0.71829838514328, "training_acc": 54.0, "val_loss": 0.7763645339012146, "val_acc": 48.0}
{"epoch": 17, "training_loss": 0.7023069000244141, "training_acc": 54.0, "val_loss": 0.7660390543937683, "val_acc": 52.0}
{"epoch": 18, "training_loss": 0.7363708209991455, "training_acc": 50.0, "val_loss": 0.736158607006073, "val_acc": 48.0}
{"epoch": 19, "training_loss": 0.7200571703910827, "training_acc": 48.0, "val_loss": 0.7028108143806457, "val_acc": 52.0}
{"epoch": 20, "training_loss": 0.7161719536781311, "training_acc": 46.0, "val_loss": 0.6930245184898376, "val_acc": 52.0}
{"epoch": 21, "training_loss": 0.7668513202667236, "training_acc": 52.0, "val_loss": 1.0339968013763428, "val_acc": 48.0}
{"epoch": 22, "training_loss": 0.8162397360801696, "training_acc": 50.0, "val_loss": 0.7459184408187867, "val_acc": 52.0}
{"epoch": 23, "training_loss": 0.7437911248207092, "training_acc": 46.0, "val_loss": 0.6982735085487366, "val_acc": 48.0}
{"epoch": 24, "training_loss": 0.7203345084190369, "training_acc": 50.0, "val_loss": 0.7059417843818665, "val_acc": 52.0}
{"epoch": 25, "training_loss": 0.7116811990737915, "training_acc": 50.0, "val_loss": 0.7275598955154419, "val_acc": 52.0}
{"epoch": 26, "training_loss": 0.7328631973266602, "training_acc": 46.0, "val_loss": 0.7318970060348511, "val_acc": 48.0}
{"epoch": 27, "training_loss": 0.7011642837524414, "training_acc": 54.0, "val_loss": 0.6978321194648742, "val_acc": 48.0}
{"epoch": 28, "training_loss": 0.7348015165328979, "training_acc": 48.0, "val_loss": 0.695762529373169, "val_acc": 48.0}
{"epoch": 29, "training_loss": 0.7184061980247498, "training_acc": 50.0, "val_loss": 0.7342761874198913, "val_acc": 52.0}
{"epoch": 30, "training_loss": 0.6797405982017517, "training_acc": 58.0, "val_loss": 0.9559056329727172, "val_acc": 48.0}
{"epoch": 31, "training_loss": 0.873223271369934, "training_acc": 48.0, "val_loss": 0.6933463716506958, "val_acc": 48.0}
{"epoch": 32, "training_loss": 0.9070388031005859, "training_acc": 42.0, "val_loss": 0.692809190750122, "val_acc": 52.0}
{"epoch": 33, "training_loss": 0.701689043045044, "training_acc": 54.0, "val_loss": 0.7200334167480469, "val_acc": 52.0}
{"epoch": 34, "training_loss": 0.7578476333618164, "training_acc": 46.0, "val_loss": 0.7044257712364197, "val_acc": 52.0}
{"epoch": 35, "training_loss": 0.8178161334991455, "training_acc": 46.0, "val_loss": 0.6982608461380004, "val_acc": 48.0}
{"epoch": 36, "training_loss": 0.7827458715438843, "training_acc": 40.0, "val_loss": 0.6944805979728699, "val_acc": 52.0}
{"epoch": 37, "training_loss": 0.7433718180656433, "training_acc": 50.0, "val_loss": 0.8497991275787353, "val_acc": 48.0}
{"epoch": 38, "training_loss": 0.8430267667770386, "training_acc": 44.0, "val_loss": 0.712284061908722, "val_acc": 48.0}
{"epoch": 39, "training_loss": 0.7396186971664429, "training_acc": 50.0, "val_loss": 0.7727410888671875, "val_acc": 52.0}
{"epoch": 40, "training_loss": 0.8193908739089966, "training_acc": 48.0, "val_loss": 0.874989697933197, "val_acc": 48.0}
{"epoch": 41, "training_loss": 0.7890220046043396, "training_acc": 44.0, "val_loss": 0.6975635910034179, "val_acc": 48.0}
{"epoch": 42, "training_loss": 0.7377307939529419, "training_acc": 38.0, "val_loss": 0.6933745980262757, "val_acc": 52.0}
{"epoch": 43, "training_loss": 0.7427248883247376, "training_acc": 48.0, "val_loss": 0.8570352864265441, "val_acc": 48.0}
{"epoch": 44, "training_loss": 0.7759418749809265, "training_acc": 46.0, "val_loss": 0.6934388041496277, "val_acc": 48.0}
{"epoch": 45, "training_loss": 0.7067689347267151, "training_acc": 56.0, "val_loss": 0.9313405680656434, "val_acc": 52.0}
{"epoch": 46, "training_loss": 0.8039560794830323, "training_acc": 56.0, "val_loss": 0.9142399907112122, "val_acc": 48.0}
{"epoch": 47, "training_loss": 0.7285363745689392, "training_acc": 54.0, "val_loss": 0.6927839541435241, "val_acc": 52.0}
{"epoch": 48, "training_loss": 0.7377002954483032, "training_acc": 44.0, "val_loss": 0.6938968586921692, "val_acc": 48.0}
{"epoch": 49, "training_loss": 0.7466119694709777, "training_acc": 52.0, "val_loss": 0.808413245677948, "val_acc": 52.0}
{"epoch": 50, "training_loss": 0.7165872478485107, "training_acc": 56.0, "val_loss": 0.8669184112548828, "val_acc": 48.0}
{"epoch": 51, "training_loss": 0.7337470006942749, "training_acc": 56.0, "val_loss": 0.8705936861038208, "val_acc": 52.0}
{"epoch": 52, "training_loss": 0.764931526184082, "training_acc": 56.0, "val_loss": 0.6932486343383789, "val_acc": 48.0}
{"epoch": 53, "training_loss": 0.7751172423362732, "training_acc": 44.0, "val_loss": 0.7125820970535278, "val_acc": 48.0}
{"epoch": 54, "training_loss": 0.7343863701820373, "training_acc": 48.0, "val_loss": 0.726322374343872, "val_acc": 48.0}
{"epoch": 55, "training_loss": 0.7678536367416382, "training_acc": 50.0, "val_loss": 0.7517135882377625, "val_acc": 52.0}
{"epoch": 56, "training_loss": 0.7172160148620605, "training_acc": 52.0, "val_loss": 0.6931349992752075, "val_acc": 52.0}
{"epoch": 57, "training_loss": 0.7213582038879395, "training_acc": 52.0, "val_loss": 0.8428256225585937, "val_acc": 48.0}
{"epoch": 58, "training_loss": 0.7406006383895875, "training_acc": 60.0, "val_loss": 0.7923643565177918, "val_acc": 52.0}
{"epoch": 59, "training_loss": 0.8079720544815063, "training_acc": 46.0, "val_loss": 0.703930847644806, "val_acc": 48.0}
{"epoch": 60, "training_loss": 0.6954069638252258, "training_acc": 58.0, "val_loss": 0.7845286560058594, "val_acc": 52.0}
{"epoch": 61, "training_loss": 0.8789859366416931, "training_acc": 48.0, "val_loss": 0.9177486848831177, "val_acc": 48.0}
{"epoch": 62, "training_loss": 0.8623913240432739, "training_acc": 44.0, "val_loss": 0.7002996754646301, "val_acc": 48.0}
{"epoch": 63, "training_loss": 0.7524972295761109, "training_acc": 54.0, "val_loss": 0.8255524802207946, "val_acc": 52.0}
{"epoch": 64, "training_loss": 0.7336546587944031, "training_acc": 56.0, "val_loss": 0.7332066059112549, "val_acc": 48.0}
{"epoch": 65, "training_loss": 0.7101176881790161, "training_acc": 54.0, "val_loss": 0.6954407835006714, "val_acc": 48.0}
{"epoch": 66, "training_loss": 0.7436535024642944, "training_acc": 48.0, "val_loss": 0.7244122457504273, "val_acc": 52.0}
