"main_modify.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 7 --task ADNI_sex --input_option yAware --learning_rate 1e-2 --batch_size 16 --weight_decay 1e-4 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 1.2457412266731263, "training_acc": 52.0, "val_loss": 0.7968514752388001, "val_acc": 48.0}
{"epoch": 1, "training_loss": 0.7551197218894958, "training_acc": 56.0, "val_loss": 1.12267662525177, "val_acc": 52.0}
{"epoch": 2, "training_loss": 1.015504574775696, "training_acc": 40.0, "val_loss": 0.695003559589386, "val_acc": 52.0}
{"epoch": 3, "training_loss": 0.799710693359375, "training_acc": 46.0, "val_loss": 0.7715897035598754, "val_acc": 48.0}
{"epoch": 4, "training_loss": 0.7472118496894836, "training_acc": 48.0, "val_loss": 0.6934706425666809, "val_acc": 52.0}
{"epoch": 5, "training_loss": 0.7003276085853577, "training_acc": 54.0, "val_loss": 0.7030391240119934, "val_acc": 48.0}
{"epoch": 6, "training_loss": 0.7311087632179261, "training_acc": 52.0, "val_loss": 0.7563677310943604, "val_acc": 48.0}
{"epoch": 7, "training_loss": 0.7121040964126587, "training_acc": 54.0, "val_loss": 0.7936495518684388, "val_acc": 52.0}
{"epoch": 8, "training_loss": 0.8205790138244629, "training_acc": 50.0, "val_loss": 0.7779348826408387, "val_acc": 48.0}
{"epoch": 9, "training_loss": 0.7300443959236145, "training_acc": 52.0, "val_loss": 0.7158118796348572, "val_acc": 52.0}
{"epoch": 10, "training_loss": 0.7849380826950073, "training_acc": 48.0, "val_loss": 0.7048373746871949, "val_acc": 48.0}
{"epoch": 11, "training_loss": 0.900424313545227, "training_acc": 48.0, "val_loss": 1.0690779042243959, "val_acc": 48.0}
{"epoch": 12, "training_loss": 0.9893352031707764, "training_acc": 48.0, "val_loss": 0.7821293663978577, "val_acc": 52.0}
{"epoch": 13, "training_loss": 0.7127225494384766, "training_acc": 54.0, "val_loss": 0.7547740125656128, "val_acc": 48.0}
{"epoch": 14, "training_loss": 0.7120967340469361, "training_acc": 54.0, "val_loss": 0.6926781630516052, "val_acc": 52.0}
{"epoch": 15, "training_loss": 0.7881423258781433, "training_acc": 42.0, "val_loss": 0.7028610277175903, "val_acc": 52.0}
{"epoch": 16, "training_loss": 0.7523069190979004, "training_acc": 48.0, "val_loss": 0.7397733426094055, "val_acc": 52.0}
{"epoch": 17, "training_loss": 0.7225899648666382, "training_acc": 52.0, "val_loss": 0.766242322921753, "val_acc": 48.0}
{"epoch": 18, "training_loss": 0.7969114971160889, "training_acc": 46.0, "val_loss": 0.6952899885177612, "val_acc": 48.0}
{"epoch": 19, "training_loss": 0.7012147688865662, "training_acc": 50.0, "val_loss": 0.6932422518730164, "val_acc": 52.0}
{"epoch": 20, "training_loss": 0.7836716532707214, "training_acc": 54.0, "val_loss": 1.1408934354782105, "val_acc": 48.0}
{"epoch": 21, "training_loss": 1.1073166561126708, "training_acc": 50.0, "val_loss": 1.0013733005523682, "val_acc": 52.0}
{"epoch": 22, "training_loss": 0.9528549242019654, "training_acc": 48.0, "val_loss": 0.9035883402824402, "val_acc": 48.0}
{"epoch": 23, "training_loss": 0.7804082155227661, "training_acc": 50.0, "val_loss": 0.7120811820030213, "val_acc": 52.0}
{"epoch": 24, "training_loss": 0.7131223678588867, "training_acc": 54.0, "val_loss": 0.7099676632881164, "val_acc": 48.0}
{"epoch": 25, "training_loss": 0.7075277280807495, "training_acc": 46.0, "val_loss": 0.697466413974762, "val_acc": 48.0}
{"epoch": 26, "training_loss": 0.7115904116630554, "training_acc": 42.0, "val_loss": 0.7298109459877015, "val_acc": 48.0}
{"epoch": 27, "training_loss": 0.7947045707702637, "training_acc": 34.0, "val_loss": 0.716781895160675, "val_acc": 48.0}
{"epoch": 28, "training_loss": 0.7047533321380616, "training_acc": 52.0, "val_loss": 0.7162221884727478, "val_acc": 52.0}
{"epoch": 29, "training_loss": 0.7502600359916687, "training_acc": 48.0, "val_loss": 0.7768593597412109, "val_acc": 48.0}
{"epoch": 30, "training_loss": 0.7626822781562805, "training_acc": 50.0, "val_loss": 0.78843829870224, "val_acc": 52.0}
{"epoch": 31, "training_loss": 0.7669216918945313, "training_acc": 50.0, "val_loss": 0.7356639766693115, "val_acc": 48.0}
{"epoch": 32, "training_loss": 0.7366889047622681, "training_acc": 46.0, "val_loss": 0.6931034064292908, "val_acc": 52.0}
{"epoch": 33, "training_loss": 0.7079769802093506, "training_acc": 44.0, "val_loss": 0.6935090351104737, "val_acc": 52.0}
{"epoch": 34, "training_loss": 0.7091440534591675, "training_acc": 48.0, "val_loss": 0.6924764609336853, "val_acc": 52.0}
{"epoch": 35, "training_loss": 0.716980152130127, "training_acc": 44.0, "val_loss": 0.7081487703323365, "val_acc": 52.0}
{"epoch": 36, "training_loss": 0.814283390045166, "training_acc": 40.0, "val_loss": 0.7287635660171509, "val_acc": 48.0}
{"epoch": 37, "training_loss": 0.7057665109634399, "training_acc": 54.0, "val_loss": 0.7355600833892822, "val_acc": 52.0}
{"epoch": 38, "training_loss": 0.7879205942153931, "training_acc": 44.0, "val_loss": 0.7072235417366027, "val_acc": 48.0}
{"epoch": 39, "training_loss": 0.7475802540779114, "training_acc": 56.0, "val_loss": 0.7170710492134095, "val_acc": 48.0}
{"epoch": 40, "training_loss": 0.7355139064788818, "training_acc": 50.0, "val_loss": 0.705935697555542, "val_acc": 52.0}
{"epoch": 41, "training_loss": 0.7047771286964416, "training_acc": 48.0, "val_loss": 0.6944552278518676, "val_acc": 48.0}
{"epoch": 42, "training_loss": 0.7070472884178162, "training_acc": 48.0, "val_loss": 0.7025023579597474, "val_acc": 48.0}
{"epoch": 43, "training_loss": 0.712991406917572, "training_acc": 46.0, "val_loss": 0.6924150657653808, "val_acc": 52.0}
{"epoch": 44, "training_loss": 0.7293234586715698, "training_acc": 48.0, "val_loss": 0.7143161582946778, "val_acc": 52.0}
{"epoch": 45, "training_loss": 0.7559909200668335, "training_acc": 48.0, "val_loss": 0.7819143629074097, "val_acc": 48.0}
{"epoch": 46, "training_loss": 0.7828646326065063, "training_acc": 42.0, "val_loss": 0.6987156677246094, "val_acc": 52.0}
{"epoch": 47, "training_loss": 0.7118184661865234, "training_acc": 50.0, "val_loss": 0.719858238697052, "val_acc": 52.0}
{"epoch": 48, "training_loss": 0.7502581453323365, "training_acc": 54.0, "val_loss": 0.8787076544761657, "val_acc": 48.0}
{"epoch": 49, "training_loss": 0.794304347038269, "training_acc": 52.0, "val_loss": 0.9210459971427918, "val_acc": 52.0}
{"epoch": 50, "training_loss": 1.009270224571228, "training_acc": 42.0, "val_loss": 0.7331379270553589, "val_acc": 48.0}
{"epoch": 51, "training_loss": 0.794327802658081, "training_acc": 56.0, "val_loss": 0.7112946891784668, "val_acc": 48.0}
{"epoch": 52, "training_loss": 0.808054358959198, "training_acc": 48.0, "val_loss": 0.8496714544296264, "val_acc": 52.0}
{"epoch": 53, "training_loss": 0.8276295256614685, "training_acc": 46.0, "val_loss": 0.7095399808883667, "val_acc": 48.0}
{"epoch": 54, "training_loss": 0.752110800743103, "training_acc": 50.0, "val_loss": 0.7813120651245117, "val_acc": 48.0}
{"epoch": 55, "training_loss": 0.8130290794372559, "training_acc": 48.0, "val_loss": 0.7561233878135681, "val_acc": 52.0}
{"epoch": 56, "training_loss": 0.7597235989570618, "training_acc": 46.0, "val_loss": 0.6945604109764099, "val_acc": 52.0}
{"epoch": 57, "training_loss": 0.739540183544159, "training_acc": 50.0, "val_loss": 0.8509589457511901, "val_acc": 48.0}
{"epoch": 58, "training_loss": 0.8540853476524353, "training_acc": 50.0, "val_loss": 0.7655106472969055, "val_acc": 52.0}
{"epoch": 59, "training_loss": 0.7672280764579773, "training_acc": 50.0, "val_loss": 0.9161439967155457, "val_acc": 48.0}
{"epoch": 60, "training_loss": 0.7635797119140625, "training_acc": 52.0, "val_loss": 0.7289252829551697, "val_acc": 52.0}
{"epoch": 61, "training_loss": 0.7213164043426513, "training_acc": 50.0, "val_loss": 0.7280691885948181, "val_acc": 48.0}
{"epoch": 62, "training_loss": 0.7040809917449952, "training_acc": 50.0, "val_loss": 0.702595763206482, "val_acc": 52.0}
