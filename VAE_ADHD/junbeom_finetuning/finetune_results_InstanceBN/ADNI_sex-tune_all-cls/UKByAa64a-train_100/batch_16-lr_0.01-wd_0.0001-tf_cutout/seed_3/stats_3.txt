"main_modify.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 3 --task ADNI_sex --input_option yAware --learning_rate 1e-2 --batch_size 16 --weight_decay 1e-4 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 1.142440800666809, "training_acc": 47.0, "val_loss": 0.6950950813293457, "val_acc": 48.0}
{"epoch": 1, "training_loss": 0.7102034521102906, "training_acc": 49.0, "val_loss": 0.7395044779777527, "val_acc": 52.0}
{"epoch": 2, "training_loss": 0.7416769027709961, "training_acc": 47.0, "val_loss": 0.7894464945793152, "val_acc": 52.0}
{"epoch": 3, "training_loss": 0.7480553674697876, "training_acc": 55.0, "val_loss": 0.950930986404419, "val_acc": 48.0}
{"epoch": 4, "training_loss": 0.787684862613678, "training_acc": 51.0, "val_loss": 0.6937346577644348, "val_acc": 52.0}
{"epoch": 5, "training_loss": 0.7196779203414917, "training_acc": 45.0, "val_loss": 0.7313649439811707, "val_acc": 52.0}
{"epoch": 6, "training_loss": 0.7771505999565125, "training_acc": 41.0, "val_loss": 0.8630316925048828, "val_acc": 52.0}
{"epoch": 7, "training_loss": 0.9516412615776062, "training_acc": 41.0, "val_loss": 0.7039089488983155, "val_acc": 48.0}
{"epoch": 8, "training_loss": 0.6977365112304688, "training_acc": 53.0, "val_loss": 0.7723579359054565, "val_acc": 48.0}
{"epoch": 9, "training_loss": 0.7074405384063721, "training_acc": 55.0, "val_loss": 0.819550244808197, "val_acc": 52.0}
{"epoch": 10, "training_loss": 0.8534327626228333, "training_acc": 37.0, "val_loss": 0.7069681215286255, "val_acc": 48.0}
{"epoch": 11, "training_loss": 0.7075251340866089, "training_acc": 49.0, "val_loss": 0.70475341796875, "val_acc": 48.0}
{"epoch": 12, "training_loss": 0.7007538032531738, "training_acc": 47.0, "val_loss": 0.6928713703155518, "val_acc": 52.0}
{"epoch": 13, "training_loss": 0.7180851697921753, "training_acc": 47.0, "val_loss": 0.7079185724258423, "val_acc": 52.0}
{"epoch": 14, "training_loss": 0.7240852212905884, "training_acc": 55.0, "val_loss": 0.9641530895233155, "val_acc": 48.0}
{"epoch": 15, "training_loss": 0.9182797002792359, "training_acc": 47.0, "val_loss": 0.7054539752006531, "val_acc": 48.0}
{"epoch": 16, "training_loss": 0.9944962191581727, "training_acc": 53.0, "val_loss": 1.023956027030945, "val_acc": 52.0}
{"epoch": 17, "training_loss": 0.9784319639205933, "training_acc": 57.0, "val_loss": 1.0480822443962097, "val_acc": 48.0}
{"epoch": 18, "training_loss": 0.781930058002472, "training_acc": 57.0, "val_loss": 0.9797899627685547, "val_acc": 52.0}
{"epoch": 19, "training_loss": 0.8537937879562378, "training_acc": 49.0, "val_loss": 0.7408723282814026, "val_acc": 48.0}
{"epoch": 20, "training_loss": 0.7242435336112976, "training_acc": 55.0, "val_loss": 0.6976837611198425, "val_acc": 52.0}
{"epoch": 21, "training_loss": 0.7378486490249634, "training_acc": 49.0, "val_loss": 0.7269126105308533, "val_acc": 52.0}
{"epoch": 22, "training_loss": 0.8007701683044434, "training_acc": 41.0, "val_loss": 0.692391083240509, "val_acc": 52.0}
{"epoch": 23, "training_loss": 0.7075590205192566, "training_acc": 40.0, "val_loss": 0.7358443164825439, "val_acc": 52.0}
{"epoch": 24, "training_loss": 0.7644582414627075, "training_acc": 43.0, "val_loss": 0.6941410374641418, "val_acc": 52.0}
{"epoch": 25, "training_loss": 0.7432987403869629, "training_acc": 56.0, "val_loss": 0.9069080328941346, "val_acc": 48.0}
{"epoch": 26, "training_loss": 0.7463139271736146, "training_acc": 51.0, "val_loss": 0.880737464427948, "val_acc": 48.0}
{"epoch": 27, "training_loss": 0.781143102645874, "training_acc": 47.0, "val_loss": 0.6958331727981567, "val_acc": 52.0}
{"epoch": 28, "training_loss": 0.6979698038101196, "training_acc": 51.0, "val_loss": 0.8527852606773376, "val_acc": 52.0}
{"epoch": 29, "training_loss": 0.7511461901664734, "training_acc": 53.0, "val_loss": 0.6977186131477356, "val_acc": 52.0}
{"epoch": 30, "training_loss": 0.8971988320350647, "training_acc": 47.0, "val_loss": 0.6994095492362976, "val_acc": 48.0}
{"epoch": 31, "training_loss": 0.808312885761261, "training_acc": 49.0, "val_loss": 0.9716349983215332, "val_acc": 48.0}
{"epoch": 32, "training_loss": 0.8306212115287781, "training_acc": 49.0, "val_loss": 0.7279301738739014, "val_acc": 48.0}
{"epoch": 33, "training_loss": 0.8282201290130615, "training_acc": 51.0, "val_loss": 0.8763720083236695, "val_acc": 52.0}
{"epoch": 34, "training_loss": 0.9026483535766602, "training_acc": 49.0, "val_loss": 0.749799439907074, "val_acc": 52.0}
{"epoch": 35, "training_loss": 0.7770904541015625, "training_acc": 47.0, "val_loss": 0.7726760053634644, "val_acc": 48.0}
{"epoch": 36, "training_loss": 0.7192762613296508, "training_acc": 55.0, "val_loss": 0.8057381272315979, "val_acc": 52.0}
{"epoch": 37, "training_loss": 0.8492072010040284, "training_acc": 43.0, "val_loss": 0.8640326619148254, "val_acc": 52.0}
{"epoch": 38, "training_loss": 0.8859998297691345, "training_acc": 55.0, "val_loss": 1.1227829933166504, "val_acc": 48.0}
{"epoch": 39, "training_loss": 0.8531726264953613, "training_acc": 51.0, "val_loss": 0.7316851544380188, "val_acc": 52.0}
{"epoch": 40, "training_loss": 0.7940092849731445, "training_acc": 49.0, "val_loss": 0.7342359471321106, "val_acc": 52.0}
{"epoch": 41, "training_loss": 0.7695963621139527, "training_acc": 50.0, "val_loss": 0.9336189389228821, "val_acc": 48.0}
