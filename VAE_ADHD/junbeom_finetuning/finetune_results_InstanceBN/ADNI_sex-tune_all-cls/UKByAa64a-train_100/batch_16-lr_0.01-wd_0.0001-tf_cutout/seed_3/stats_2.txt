"main_modify.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 3 --task ADNI_sex --input_option yAware --learning_rate 1e-2 --batch_size 16 --weight_decay 1e-4 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 1.4949920129776002, "training_acc": 38.0, "val_loss": 0.7096607899665832, "val_acc": 48.0}
{"epoch": 1, "training_loss": 0.8510750579833984, "training_acc": 52.0, "val_loss": 1.0950848484039306, "val_acc": 52.0}
{"epoch": 2, "training_loss": 0.9498629379272461, "training_acc": 50.0, "val_loss": 0.8144060468673706, "val_acc": 48.0}
{"epoch": 3, "training_loss": 0.773944263458252, "training_acc": 50.0, "val_loss": 0.7013564467430115, "val_acc": 48.0}
{"epoch": 4, "training_loss": 0.9052733612060547, "training_acc": 48.0, "val_loss": 0.7263503813743591, "val_acc": 52.0}
{"epoch": 5, "training_loss": 0.7400794506072998, "training_acc": 54.0, "val_loss": 0.8907712197303772, "val_acc": 48.0}
{"epoch": 6, "training_loss": 0.8533682107925415, "training_acc": 54.0, "val_loss": 0.7950477457046509, "val_acc": 52.0}
{"epoch": 7, "training_loss": 0.8500440502166748, "training_acc": 42.0, "val_loss": 0.6970692276954651, "val_acc": 48.0}
{"epoch": 8, "training_loss": 0.7958320188522339, "training_acc": 42.0, "val_loss": 0.69674809217453, "val_acc": 52.0}
{"epoch": 9, "training_loss": 0.7350690984725952, "training_acc": 54.0, "val_loss": 0.9124173831939697, "val_acc": 48.0}
{"epoch": 10, "training_loss": 0.892373218536377, "training_acc": 48.0, "val_loss": 0.8228173184394837, "val_acc": 52.0}
{"epoch": 11, "training_loss": 0.7424379205703735, "training_acc": 50.0, "val_loss": 0.8078738403320312, "val_acc": 48.0}
{"epoch": 12, "training_loss": 0.7276277542114258, "training_acc": 48.0, "val_loss": 0.7145519948005676, "val_acc": 52.0}
{"epoch": 13, "training_loss": 0.7137309813499451, "training_acc": 48.0, "val_loss": 0.6981501960754395, "val_acc": 48.0}
{"epoch": 14, "training_loss": 0.7325351333618164, "training_acc": 52.0, "val_loss": 0.7274674606323243, "val_acc": 48.0}
{"epoch": 15, "training_loss": 0.7205403518676757, "training_acc": 48.0, "val_loss": 0.7012322926521302, "val_acc": 52.0}
{"epoch": 16, "training_loss": 0.7556642580032349, "training_acc": 40.0, "val_loss": 0.7075899887084961, "val_acc": 52.0}
{"epoch": 17, "training_loss": 0.7043452787399292, "training_acc": 52.0, "val_loss": 0.708250572681427, "val_acc": 48.0}
{"epoch": 18, "training_loss": 0.7118243980407715, "training_acc": 52.0, "val_loss": 0.783229250907898, "val_acc": 52.0}
{"epoch": 19, "training_loss": 0.7759025478363037, "training_acc": 52.0, "val_loss": 0.7519144892692566, "val_acc": 48.0}
{"epoch": 20, "training_loss": 0.7236144781112671, "training_acc": 50.0, "val_loss": 0.8743377089500427, "val_acc": 48.0}
{"epoch": 21, "training_loss": 0.9543690800666809, "training_acc": 46.0, "val_loss": 0.8280721998214722, "val_acc": 52.0}
{"epoch": 22, "training_loss": 0.8370377373695373, "training_acc": 46.0, "val_loss": 0.7774533104896545, "val_acc": 52.0}
{"epoch": 23, "training_loss": 0.9695475602149963, "training_acc": 44.0, "val_loss": 0.9667550992965698, "val_acc": 48.0}
{"epoch": 24, "training_loss": 0.7912616872787476, "training_acc": 50.0, "val_loss": 0.741955292224884, "val_acc": 52.0}
{"epoch": 25, "training_loss": 0.8376167821884155, "training_acc": 48.0, "val_loss": 0.6971527171134949, "val_acc": 52.0}
{"epoch": 26, "training_loss": 0.7526642513275147, "training_acc": 48.0, "val_loss": 0.7063090562820434, "val_acc": 48.0}
{"epoch": 27, "training_loss": 0.7090628337860108, "training_acc": 52.0, "val_loss": 0.7132263588905334, "val_acc": 52.0}
{"epoch": 28, "training_loss": 0.7307310581207276, "training_acc": 46.0, "val_loss": 0.6945215106010437, "val_acc": 52.0}
{"epoch": 29, "training_loss": 0.7683805274963379, "training_acc": 40.0, "val_loss": 0.6942311930656433, "val_acc": 52.0}
{"epoch": 30, "training_loss": 0.8057469892501831, "training_acc": 48.0, "val_loss": 0.7336845636367798, "val_acc": 48.0}
{"epoch": 31, "training_loss": 0.712574372291565, "training_acc": 52.0, "val_loss": 0.711475224494934, "val_acc": 52.0}
{"epoch": 32, "training_loss": 0.7548217988014221, "training_acc": 52.0, "val_loss": 0.7753958868980407, "val_acc": 48.0}
{"epoch": 33, "training_loss": 0.7112562012672424, "training_acc": 52.0, "val_loss": 0.8070822620391845, "val_acc": 52.0}
{"epoch": 34, "training_loss": 0.7996463012695313, "training_acc": 52.0, "val_loss": 0.7220755004882813, "val_acc": 48.0}
{"epoch": 35, "training_loss": 0.6801862955093384, "training_acc": 58.0, "val_loss": 0.7596915555000305, "val_acc": 52.0}
{"epoch": 36, "training_loss": 0.7372259521484374, "training_acc": 48.0, "val_loss": 0.7266826343536377, "val_acc": 48.0}
{"epoch": 37, "training_loss": 0.7264713454246521, "training_acc": 44.0, "val_loss": 0.6963068008422851, "val_acc": 48.0}
{"epoch": 38, "training_loss": 0.7008218002319336, "training_acc": 44.0, "val_loss": 0.7037655377388, "val_acc": 48.0}
{"epoch": 39, "training_loss": 0.6974289035797119, "training_acc": 48.0, "val_loss": 0.6919671916961669, "val_acc": 52.0}
{"epoch": 40, "training_loss": 0.778535966873169, "training_acc": 40.0, "val_loss": 0.7088668060302734, "val_acc": 52.0}
{"epoch": 41, "training_loss": 0.7217922520637512, "training_acc": 50.0, "val_loss": 0.7210704588890076, "val_acc": 48.0}
{"epoch": 42, "training_loss": 0.7180603170394897, "training_acc": 50.0, "val_loss": 0.7009620451927185, "val_acc": 52.0}
{"epoch": 43, "training_loss": 0.7185108757019043, "training_acc": 49.0, "val_loss": 0.6927370071411133, "val_acc": 48.0}
{"epoch": 44, "training_loss": 0.7354563856124878, "training_acc": 50.0, "val_loss": 0.7216557431221008, "val_acc": 48.0}
{"epoch": 45, "training_loss": 0.7180280256271362, "training_acc": 52.0, "val_loss": 0.6988532757759094, "val_acc": 52.0}
{"epoch": 46, "training_loss": 0.7380923557281495, "training_acc": 52.0, "val_loss": 0.8981559729576111, "val_acc": 52.0}
{"epoch": 47, "training_loss": 0.8327113151550293, "training_acc": 46.0, "val_loss": 0.6892706537246704, "val_acc": 56.0}
{"epoch": 48, "training_loss": 0.7367938399314881, "training_acc": 50.0, "val_loss": 0.96140549659729, "val_acc": 48.0}
{"epoch": 49, "training_loss": 0.9224561023712158, "training_acc": 50.0, "val_loss": 0.7247293496131897, "val_acc": 52.0}
{"epoch": 50, "training_loss": 0.8670409107208252, "training_acc": 42.0, "val_loss": 0.7159692025184632, "val_acc": 52.0}
{"epoch": 51, "training_loss": 0.8627468800544739, "training_acc": 38.0, "val_loss": 0.8547482395172119, "val_acc": 52.0}
{"epoch": 52, "training_loss": 0.9347564220428467, "training_acc": 56.0, "val_loss": 1.1944855642318726, "val_acc": 48.0}
{"epoch": 53, "training_loss": 0.9121524524688721, "training_acc": 52.0, "val_loss": 0.9780848026275635, "val_acc": 52.0}
{"epoch": 54, "training_loss": 0.9282118511199952, "training_acc": 44.0, "val_loss": 0.6959515690803528, "val_acc": 48.0}
{"epoch": 55, "training_loss": 0.8101265335083008, "training_acc": 50.0, "val_loss": 0.8708623504638672, "val_acc": 48.0}
{"epoch": 56, "training_loss": 0.7518008160591125, "training_acc": 52.0, "val_loss": 0.7191989541053772, "val_acc": 52.0}
{"epoch": 57, "training_loss": 0.7219827628135681, "training_acc": 48.0, "val_loss": 0.6966336560249329, "val_acc": 48.0}
{"epoch": 58, "training_loss": 0.7108779001235962, "training_acc": 40.0, "val_loss": 0.7363432240486145, "val_acc": 52.0}
{"epoch": 59, "training_loss": 0.776257553100586, "training_acc": 50.0, "val_loss": 0.9963670921325684, "val_acc": 48.0}
{"epoch": 60, "training_loss": 0.8526425647735596, "training_acc": 52.0, "val_loss": 0.7627384161949158, "val_acc": 52.0}
{"epoch": 61, "training_loss": 0.8670607995986939, "training_acc": 41.0, "val_loss": 0.7602365946769715, "val_acc": 52.0}
{"epoch": 62, "training_loss": 0.7288445377349854, "training_acc": 52.0, "val_loss": 0.7795053195953369, "val_acc": 48.0}
{"epoch": 63, "training_loss": 0.7634064674377441, "training_acc": 50.0, "val_loss": 0.6967045450210572, "val_acc": 52.0}
{"epoch": 64, "training_loss": 0.737766661643982, "training_acc": 52.0, "val_loss": 0.7576185631752014, "val_acc": 52.0}
{"epoch": 65, "training_loss": 0.8226477909088135, "training_acc": 50.0, "val_loss": 0.9094351935386658, "val_acc": 48.0}
{"epoch": 66, "training_loss": 0.8257292556762695, "training_acc": 50.0, "val_loss": 0.7737847375869751, "val_acc": 52.0}
