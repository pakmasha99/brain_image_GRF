"main_modify.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 5 --task ADNI_sex --input_option yAware --learning_rate 1e-2 --batch_size 16 --weight_decay 1e-4 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 1.252650136947632, "training_acc": 52.0, "val_loss": 0.6982185292243958, "val_acc": 52.0}
{"epoch": 1, "training_loss": 1.0723703289031983, "training_acc": 42.0, "val_loss": 0.6987014150619507, "val_acc": 48.0}
{"epoch": 2, "training_loss": 0.7174283003807068, "training_acc": 46.0, "val_loss": 0.6952362489700318, "val_acc": 52.0}
{"epoch": 3, "training_loss": 0.7697558641433716, "training_acc": 40.0, "val_loss": 0.70224534034729, "val_acc": 52.0}
{"epoch": 4, "training_loss": 0.7237029337882995, "training_acc": 52.0, "val_loss": 0.7061639404296876, "val_acc": 48.0}
{"epoch": 5, "training_loss": 0.7125257635116578, "training_acc": 48.0, "val_loss": 0.6956690931320191, "val_acc": 52.0}
{"epoch": 6, "training_loss": 0.7183434128761291, "training_acc": 46.0, "val_loss": 0.7901911568641663, "val_acc": 52.0}
{"epoch": 7, "training_loss": 0.8806902503967285, "training_acc": 50.0, "val_loss": 1.048385705947876, "val_acc": 48.0}
{"epoch": 8, "training_loss": 0.8881170558929443, "training_acc": 54.0, "val_loss": 0.7944094014167785, "val_acc": 52.0}
{"epoch": 9, "training_loss": 0.7241428756713867, "training_acc": 52.0, "val_loss": 0.7351142239570617, "val_acc": 48.0}
{"epoch": 10, "training_loss": 0.729384229183197, "training_acc": 44.0, "val_loss": 0.7657284092903137, "val_acc": 48.0}
{"epoch": 11, "training_loss": 0.7261712574958801, "training_acc": 52.0, "val_loss": 0.7098554563522339, "val_acc": 48.0}
{"epoch": 12, "training_loss": 0.8577355313301086, "training_acc": 48.0, "val_loss": 0.839966106414795, "val_acc": 52.0}
{"epoch": 13, "training_loss": 0.7830154180526734, "training_acc": 50.0, "val_loss": 0.7004836249351502, "val_acc": 52.0}
{"epoch": 14, "training_loss": 0.719412989616394, "training_acc": 46.0, "val_loss": 0.7075399732589722, "val_acc": 48.0}
{"epoch": 15, "training_loss": 0.7558890461921692, "training_acc": 42.0, "val_loss": 0.7814800763130187, "val_acc": 48.0}
{"epoch": 16, "training_loss": 0.7738470387458801, "training_acc": 54.0, "val_loss": 0.8165166425704956, "val_acc": 52.0}
{"epoch": 17, "training_loss": 0.7944225287437439, "training_acc": 38.0, "val_loss": 0.6948766660690308, "val_acc": 48.0}
{"epoch": 18, "training_loss": 0.7270134353637695, "training_acc": 54.0, "val_loss": 0.7768296122550964, "val_acc": 52.0}
{"epoch": 19, "training_loss": 0.791163330078125, "training_acc": 52.0, "val_loss": 0.6997811985015869, "val_acc": 48.0}
{"epoch": 20, "training_loss": 0.6894871687889099, "training_acc": 58.0, "val_loss": 0.7174654936790467, "val_acc": 52.0}
{"epoch": 21, "training_loss": 0.7170551753044129, "training_acc": 48.0, "val_loss": 0.6926604032516479, "val_acc": 52.0}
{"epoch": 22, "training_loss": 0.7028460454940796, "training_acc": 50.0, "val_loss": 0.7085028123855591, "val_acc": 48.0}
{"epoch": 23, "training_loss": 0.7335936713218689, "training_acc": 44.0, "val_loss": 0.7038399505615235, "val_acc": 48.0}
{"epoch": 24, "training_loss": 0.7120819759368896, "training_acc": 46.0, "val_loss": 0.7173224258422851, "val_acc": 48.0}
{"epoch": 25, "training_loss": 0.7709885716438294, "training_acc": 50.0, "val_loss": 0.7898386430740356, "val_acc": 52.0}
{"epoch": 26, "training_loss": 0.7759515905380249, "training_acc": 48.0, "val_loss": 0.7461509799957275, "val_acc": 48.0}
{"epoch": 27, "training_loss": 0.7352750062942505, "training_acc": 48.0, "val_loss": 0.6923422956466675, "val_acc": 52.0}
{"epoch": 28, "training_loss": 0.7124924135208129, "training_acc": 48.0, "val_loss": 0.6957643270492554, "val_acc": 48.0}
{"epoch": 29, "training_loss": 0.7174278926849366, "training_acc": 48.0, "val_loss": 0.7060255551338196, "val_acc": 52.0}
{"epoch": 30, "training_loss": 0.7170220184326171, "training_acc": 46.0, "val_loss": 0.6932886481285095, "val_acc": 52.0}
{"epoch": 31, "training_loss": 0.7266538345813751, "training_acc": 54.0, "val_loss": 1.0334306025505067, "val_acc": 48.0}
{"epoch": 32, "training_loss": 0.8299459648132325, "training_acc": 52.0, "val_loss": 0.9385324621200561, "val_acc": 52.0}
{"epoch": 33, "training_loss": 0.8419946002960205, "training_acc": 48.0, "val_loss": 0.7743242120742798, "val_acc": 48.0}
{"epoch": 34, "training_loss": 0.7703409433364868, "training_acc": 43.0, "val_loss": 0.7872672605514527, "val_acc": 48.0}
{"epoch": 35, "training_loss": 0.735446150302887, "training_acc": 56.0, "val_loss": 0.8276513385772705, "val_acc": 52.0}
{"epoch": 36, "training_loss": 0.8414709258079529, "training_acc": 54.0, "val_loss": 0.9285913920402527, "val_acc": 48.0}
{"epoch": 37, "training_loss": 0.8724132347106933, "training_acc": 44.0, "val_loss": 0.6939179253578186, "val_acc": 52.0}
{"epoch": 38, "training_loss": 0.753908474445343, "training_acc": 52.0, "val_loss": 0.7048743724822998, "val_acc": 52.0}
{"epoch": 39, "training_loss": 0.7288106727600098, "training_acc": 52.0, "val_loss": 0.8728552198410034, "val_acc": 48.0}
{"epoch": 40, "training_loss": 0.7777635836601258, "training_acc": 50.0, "val_loss": 0.7705783987045288, "val_acc": 52.0}
{"epoch": 41, "training_loss": 0.7290221524238586, "training_acc": 52.0, "val_loss": 0.7804011178016662, "val_acc": 48.0}
{"epoch": 42, "training_loss": 0.7339484667778016, "training_acc": 46.0, "val_loss": 0.6947144532203674, "val_acc": 52.0}
{"epoch": 43, "training_loss": 0.7131490898132324, "training_acc": 48.0, "val_loss": 0.7158935856819153, "val_acc": 52.0}
{"epoch": 44, "training_loss": 0.7383963298797608, "training_acc": 50.0, "val_loss": 0.7212336301803589, "val_acc": 48.0}
{"epoch": 45, "training_loss": 0.7044811058044433, "training_acc": 50.0, "val_loss": 0.6927470993995667, "val_acc": 52.0}
{"epoch": 46, "training_loss": 0.6993330788612365, "training_acc": 46.0, "val_loss": 0.6923897194862366, "val_acc": 52.0}
