"main_modify.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 5 --task ADNI_sex --input_option yAware --learning_rate 1e-2 --batch_size 16 --weight_decay 1e-4 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 1.178961567878723, "training_acc": 47.0, "val_loss": 0.7890120816230773, "val_acc": 52.0}
{"epoch": 1, "training_loss": 0.7940769004821777, "training_acc": 51.0, "val_loss": 0.7216719007492065, "val_acc": 52.0}
{"epoch": 2, "training_loss": 0.726478910446167, "training_acc": 41.0, "val_loss": 0.8521988606452942, "val_acc": 48.0}
{"epoch": 3, "training_loss": 0.7685892963409424, "training_acc": 51.0, "val_loss": 0.7065846228599548, "val_acc": 52.0}
{"epoch": 4, "training_loss": 0.7783075475692749, "training_acc": 49.0, "val_loss": 0.7203258562088013, "val_acc": 52.0}
{"epoch": 5, "training_loss": 0.818873929977417, "training_acc": 41.0, "val_loss": 0.7055619788169861, "val_acc": 48.0}
{"epoch": 6, "training_loss": 0.7191381573677063, "training_acc": 41.0, "val_loss": 0.7389240884780883, "val_acc": 52.0}
{"epoch": 7, "training_loss": 0.7961501455307007, "training_acc": 45.0, "val_loss": 0.7877123975753784, "val_acc": 48.0}
{"epoch": 8, "training_loss": 0.7807050514221191, "training_acc": 39.0, "val_loss": 0.7336903047561646, "val_acc": 48.0}
{"epoch": 9, "training_loss": 0.7076435303688049, "training_acc": 53.0, "val_loss": 0.7032399773597717, "val_acc": 52.0}
{"epoch": 10, "training_loss": 0.7241995334625244, "training_acc": 51.0, "val_loss": 0.7847912859916687, "val_acc": 52.0}
{"epoch": 11, "training_loss": 0.8228101301193237, "training_acc": 55.0, "val_loss": 0.8453086066246033, "val_acc": 48.0}
{"epoch": 12, "training_loss": 0.7572322297096252, "training_acc": 49.0, "val_loss": 0.7913297176361084, "val_acc": 48.0}
{"epoch": 13, "training_loss": 0.7914006567001343, "training_acc": 49.0, "val_loss": 0.7146996164321899, "val_acc": 52.0}
{"epoch": 14, "training_loss": 0.7121742153167725, "training_acc": 51.0, "val_loss": 0.7564573383331299, "val_acc": 48.0}
{"epoch": 15, "training_loss": 0.7464274168014526, "training_acc": 45.0, "val_loss": 0.7487765574455261, "val_acc": 48.0}
{"epoch": 16, "training_loss": 0.7478021621704102, "training_acc": 43.0, "val_loss": 0.7081933975219726, "val_acc": 48.0}
{"epoch": 17, "training_loss": 0.7165103244781494, "training_acc": 55.0, "val_loss": 0.82585120677948, "val_acc": 52.0}
{"epoch": 18, "training_loss": 0.7877597093582154, "training_acc": 47.0, "val_loss": 0.7557583665847778, "val_acc": 48.0}
{"epoch": 19, "training_loss": 0.6968834233283997, "training_acc": 55.0, "val_loss": 0.7116296482086182, "val_acc": 52.0}
{"epoch": 20, "training_loss": 0.7733256053924561, "training_acc": 53.0, "val_loss": 0.7104044198989868, "val_acc": 48.0}
{"epoch": 21, "training_loss": 0.7345394372940064, "training_acc": 49.0, "val_loss": 0.733550112247467, "val_acc": 48.0}
{"epoch": 22, "training_loss": 0.7523969268798828, "training_acc": 39.0, "val_loss": 0.7429348754882813, "val_acc": 48.0}
{"epoch": 23, "training_loss": 0.7131244850158691, "training_acc": 55.0, "val_loss": 0.8168345332145691, "val_acc": 52.0}
{"epoch": 24, "training_loss": 0.7906530499458313, "training_acc": 47.0, "val_loss": 0.738433530330658, "val_acc": 48.0}
{"epoch": 25, "training_loss": 0.7163318157196045, "training_acc": 53.0, "val_loss": 0.7554225897789002, "val_acc": 52.0}
{"epoch": 26, "training_loss": 0.7057258677482605, "training_acc": 51.0, "val_loss": 0.8838210844993591, "val_acc": 48.0}
{"epoch": 27, "training_loss": 0.8097149205207824, "training_acc": 47.0, "val_loss": 0.7011559176445007, "val_acc": 52.0}
{"epoch": 28, "training_loss": 0.7339448523521424, "training_acc": 45.0, "val_loss": 0.7450668382644653, "val_acc": 52.0}
{"epoch": 29, "training_loss": 0.8233254528045655, "training_acc": 47.0, "val_loss": 0.8123906350135803, "val_acc": 48.0}
{"epoch": 30, "training_loss": 0.7629671573638916, "training_acc": 51.0, "val_loss": 0.7150188183784485, "val_acc": 52.0}
{"epoch": 31, "training_loss": 0.8604135894775391, "training_acc": 49.0, "val_loss": 0.8082386016845703, "val_acc": 52.0}
{"epoch": 32, "training_loss": 1.1320711183547973, "training_acc": 45.0, "val_loss": 0.8583053278923035, "val_acc": 48.0}
{"epoch": 33, "training_loss": 0.7492374658584595, "training_acc": 55.0, "val_loss": 0.7678220081329346, "val_acc": 52.0}
{"epoch": 34, "training_loss": 0.7361247682571411, "training_acc": 49.0, "val_loss": 0.7003705215454101, "val_acc": 48.0}
{"epoch": 35, "training_loss": 0.7427056646347046, "training_acc": 49.0, "val_loss": 0.7196261692047119, "val_acc": 48.0}
{"epoch": 36, "training_loss": 0.7083477067947388, "training_acc": 49.0, "val_loss": 0.6920829057693482, "val_acc": 52.0}
{"epoch": 37, "training_loss": 0.7076456832885742, "training_acc": 47.0, "val_loss": 0.6933742237091064, "val_acc": 48.0}
{"epoch": 38, "training_loss": 0.700575635433197, "training_acc": 47.0, "val_loss": 0.7030627799034118, "val_acc": 48.0}
{"epoch": 39, "training_loss": 0.7268981099128723, "training_acc": 49.0, "val_loss": 0.6970423817634582, "val_acc": 52.0}
{"epoch": 40, "training_loss": 0.7011770462989807, "training_acc": 50.0, "val_loss": 0.8269930601119995, "val_acc": 48.0}
{"epoch": 41, "training_loss": 0.8332389831542969, "training_acc": 55.0, "val_loss": 1.0642546367645265, "val_acc": 52.0}
{"epoch": 42, "training_loss": 0.9180971622467041, "training_acc": 51.0, "val_loss": 1.1703443145751953, "val_acc": 48.0}
{"epoch": 43, "training_loss": 0.8797181367874145, "training_acc": 49.0, "val_loss": 0.7953281021118164, "val_acc": 52.0}
{"epoch": 44, "training_loss": 0.8258389282226563, "training_acc": 41.0, "val_loss": 0.7296309566497803, "val_acc": 52.0}
{"epoch": 45, "training_loss": 0.8233299612998962, "training_acc": 49.0, "val_loss": 0.7420418787002564, "val_acc": 48.0}
{"epoch": 46, "training_loss": 0.7178012418746949, "training_acc": 49.0, "val_loss": 0.6944788432121277, "val_acc": 48.0}
{"epoch": 47, "training_loss": 0.7043965625762939, "training_acc": 51.0, "val_loss": 0.693556079864502, "val_acc": 48.0}
{"epoch": 48, "training_loss": 0.7061465740203857, "training_acc": 43.0, "val_loss": 0.7001545715332032, "val_acc": 48.0}
{"epoch": 49, "training_loss": 0.717684531211853, "training_acc": 45.0, "val_loss": 0.6923197674751281, "val_acc": 52.0}
{"epoch": 50, "training_loss": 0.738879337310791, "training_acc": 43.0, "val_loss": 0.7130670881271363, "val_acc": 52.0}
{"epoch": 51, "training_loss": 0.7271774959564209, "training_acc": 49.0, "val_loss": 0.7255692028999329, "val_acc": 48.0}
{"epoch": 52, "training_loss": 0.7256999444961548, "training_acc": 49.0, "val_loss": 0.7074297380447387, "val_acc": 52.0}
{"epoch": 53, "training_loss": 0.7287743020057679, "training_acc": 43.0, "val_loss": 0.7126535749435425, "val_acc": 48.0}
{"epoch": 54, "training_loss": 0.7234250712394714, "training_acc": 47.0, "val_loss": 0.7120213270187378, "val_acc": 48.0}
{"epoch": 55, "training_loss": 0.7217403149604797, "training_acc": 43.0, "val_loss": 0.7363518857955933, "val_acc": 48.0}
