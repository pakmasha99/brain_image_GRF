"main_modify.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ADNI_sex --input_option yAware --learning_rate 1e-2 --batch_size 16 --weight_decay 1e-4 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 1.16384605884552, "training_acc": 46.0, "val_loss": 0.6937157106399536, "val_acc": 48.0}
{"epoch": 1, "training_loss": 0.7354791569709778, "training_acc": 54.0, "val_loss": 1.0981272745132447, "val_acc": 48.0}
{"epoch": 2, "training_loss": 0.8979698944091797, "training_acc": 52.0, "val_loss": 0.7823091912269592, "val_acc": 52.0}
{"epoch": 3, "training_loss": 0.9235215377807617, "training_acc": 40.0, "val_loss": 0.7238672256469727, "val_acc": 52.0}
{"epoch": 4, "training_loss": 0.7328086853027344, "training_acc": 46.0, "val_loss": 0.6951689481735229, "val_acc": 48.0}
{"epoch": 5, "training_loss": 0.7169339179992675, "training_acc": 46.0, "val_loss": 0.7966513156890869, "val_acc": 48.0}
{"epoch": 6, "training_loss": 0.841510181427002, "training_acc": 40.0, "val_loss": 0.720265622138977, "val_acc": 48.0}
{"epoch": 7, "training_loss": 0.9077315759658814, "training_acc": 54.0, "val_loss": 1.0803601932525635, "val_acc": 52.0}
{"epoch": 8, "training_loss": 1.1015440607070923, "training_acc": 46.0, "val_loss": 1.0618500566482545, "val_acc": 48.0}
{"epoch": 9, "training_loss": 0.870721206665039, "training_acc": 48.0, "val_loss": 0.7659248805046082, "val_acc": 52.0}
{"epoch": 10, "training_loss": 0.7493374562263488, "training_acc": 50.0, "val_loss": 0.7011155080795288, "val_acc": 52.0}
{"epoch": 11, "training_loss": 0.8080126142501831, "training_acc": 46.0, "val_loss": 0.8327009296417236, "val_acc": 48.0}
{"epoch": 12, "training_loss": 0.7748346376419067, "training_acc": 46.0, "val_loss": 0.8530314707756043, "val_acc": 48.0}
{"epoch": 13, "training_loss": 0.8593427610397338, "training_acc": 50.0, "val_loss": 0.898636269569397, "val_acc": 52.0}
{"epoch": 14, "training_loss": 0.7822653818130493, "training_acc": 48.0, "val_loss": 0.8452221608161926, "val_acc": 48.0}
{"epoch": 15, "training_loss": 0.789051022529602, "training_acc": 44.0, "val_loss": 0.7156759262084961, "val_acc": 48.0}
{"epoch": 16, "training_loss": 0.7384887266159058, "training_acc": 48.0, "val_loss": 0.7266356229782105, "val_acc": 52.0}
{"epoch": 17, "training_loss": 0.7307790088653564, "training_acc": 48.0, "val_loss": 0.69491206407547, "val_acc": 48.0}
{"epoch": 18, "training_loss": 0.7254483866691589, "training_acc": 42.0, "val_loss": 0.6918499684333801, "val_acc": 52.0}
{"epoch": 19, "training_loss": 0.7447292685508728, "training_acc": 53.0, "val_loss": 0.8885099363327026, "val_acc": 52.0}
{"epoch": 20, "training_loss": 0.8572591924667359, "training_acc": 48.0, "val_loss": 0.699219331741333, "val_acc": 48.0}
{"epoch": 21, "training_loss": 0.7093566751480103, "training_acc": 53.0, "val_loss": 0.7005790138244629, "val_acc": 48.0}
{"epoch": 22, "training_loss": 0.7344040799140931, "training_acc": 56.0, "val_loss": 0.925292100906372, "val_acc": 52.0}
{"epoch": 23, "training_loss": 0.8164805507659912, "training_acc": 50.0, "val_loss": 0.8438170289993286, "val_acc": 48.0}
{"epoch": 24, "training_loss": 0.7705323696136475, "training_acc": 46.0, "val_loss": 0.7325886940956116, "val_acc": 52.0}
{"epoch": 25, "training_loss": 0.822361192703247, "training_acc": 42.0, "val_loss": 0.716109631061554, "val_acc": 52.0}
{"epoch": 26, "training_loss": 0.8637968492507935, "training_acc": 54.0, "val_loss": 0.8641795778274536, "val_acc": 48.0}
{"epoch": 27, "training_loss": 0.9208770298957825, "training_acc": 52.0, "val_loss": 0.8938545536994934, "val_acc": 52.0}
{"epoch": 28, "training_loss": 0.8662701988220215, "training_acc": 46.0, "val_loss": 0.8805459332466126, "val_acc": 48.0}
{"epoch": 29, "training_loss": 0.8640670394897461, "training_acc": 44.0, "val_loss": 0.693461937904358, "val_acc": 40.0}
{"epoch": 30, "training_loss": 0.8073321127891541, "training_acc": 43.0, "val_loss": 0.6986290431022644, "val_acc": 52.0}
{"epoch": 31, "training_loss": 0.7066307306289673, "training_acc": 48.0, "val_loss": 0.6915112996101379, "val_acc": 52.0}
{"epoch": 32, "training_loss": 0.7129369473457337, "training_acc": 46.0, "val_loss": 0.6917944526672364, "val_acc": 56.0}
{"epoch": 33, "training_loss": 0.7115049123764038, "training_acc": 43.0, "val_loss": 0.7026568150520325, "val_acc": 52.0}
{"epoch": 34, "training_loss": 0.7661507773399353, "training_acc": 40.0, "val_loss": 0.7399955439567566, "val_acc": 52.0}
{"epoch": 35, "training_loss": 0.8350732254981995, "training_acc": 36.0, "val_loss": 0.6955859327316284, "val_acc": 48.0}
{"epoch": 36, "training_loss": 0.7369614696502685, "training_acc": 46.0, "val_loss": 0.7170659756660461, "val_acc": 48.0}
{"epoch": 37, "training_loss": 0.7308067035675049, "training_acc": 43.0, "val_loss": 0.7862281894683838, "val_acc": 48.0}
{"epoch": 38, "training_loss": 0.7765093088150025, "training_acc": 48.0, "val_loss": 0.7327506971359253, "val_acc": 52.0}
{"epoch": 39, "training_loss": 0.7158503532409668, "training_acc": 59.0, "val_loss": 0.8152820658683777, "val_acc": 48.0}
{"epoch": 40, "training_loss": 0.7905768656730652, "training_acc": 56.0, "val_loss": 0.9658888936042785, "val_acc": 52.0}
{"epoch": 41, "training_loss": 0.8245935964584351, "training_acc": 56.0, "val_loss": 0.8835868883132935, "val_acc": 48.0}
{"epoch": 42, "training_loss": 0.8153401947021485, "training_acc": 48.0, "val_loss": 0.729533166885376, "val_acc": 52.0}
{"epoch": 43, "training_loss": 0.7649504590034485, "training_acc": 44.0, "val_loss": 0.6929729533195496, "val_acc": 52.0}
{"epoch": 44, "training_loss": 0.7770130252838134, "training_acc": 38.0, "val_loss": 0.7501429104804993, "val_acc": 52.0}
{"epoch": 45, "training_loss": 0.7639858031272888, "training_acc": 42.0, "val_loss": 0.7104800152778625, "val_acc": 48.0}
{"epoch": 46, "training_loss": 0.7201489210128784, "training_acc": 48.0, "val_loss": 0.7726520705223083, "val_acc": 48.0}
{"epoch": 47, "training_loss": 0.750132966041565, "training_acc": 51.0, "val_loss": 0.7807741641998291, "val_acc": 52.0}
{"epoch": 48, "training_loss": 0.7687383460998535, "training_acc": 48.0, "val_loss": 0.7495041084289551, "val_acc": 48.0}
{"epoch": 49, "training_loss": 0.7234589576721191, "training_acc": 52.0, "val_loss": 0.7170034241676331, "val_acc": 52.0}
{"epoch": 50, "training_loss": 0.7488159990310669, "training_acc": 50.0, "val_loss": 0.7122955656051636, "val_acc": 52.0}
