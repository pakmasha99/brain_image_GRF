"main_modify.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 8 --task ADNI_sex --input_option yAware --learning_rate 1e-2 --batch_size 16 --weight_decay 1e-4 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 1.0180232334136963, "training_acc": 53.0, "val_loss": 0.707690315246582, "val_acc": 48.0}
{"epoch": 1, "training_loss": 0.7658547496795655, "training_acc": 47.0, "val_loss": 0.69281001329422, "val_acc": 52.0}
{"epoch": 2, "training_loss": 0.721721863746643, "training_acc": 51.0, "val_loss": 0.7929986119270325, "val_acc": 52.0}
{"epoch": 3, "training_loss": 0.8961615443229676, "training_acc": 41.0, "val_loss": 0.742361695766449, "val_acc": 52.0}
{"epoch": 4, "training_loss": 0.7666491937637329, "training_acc": 57.0, "val_loss": 1.158260464668274, "val_acc": 48.0}
{"epoch": 5, "training_loss": 0.99903564453125, "training_acc": 47.0, "val_loss": 0.8720074319839477, "val_acc": 52.0}
{"epoch": 6, "training_loss": 0.7659185647964477, "training_acc": 49.0, "val_loss": 0.7088745427131653, "val_acc": 48.0}
{"epoch": 7, "training_loss": 0.7158676886558533, "training_acc": 49.0, "val_loss": 0.9273862171173096, "val_acc": 48.0}
{"epoch": 8, "training_loss": 0.8501030778884888, "training_acc": 49.0, "val_loss": 0.8201669359207153, "val_acc": 52.0}
{"epoch": 9, "training_loss": 0.7242117619514465, "training_acc": 55.0, "val_loss": 0.7198246383666992, "val_acc": 48.0}
{"epoch": 10, "training_loss": 0.7205681800842285, "training_acc": 51.0, "val_loss": 0.7408368682861328, "val_acc": 48.0}
{"epoch": 11, "training_loss": 0.7197649526596069, "training_acc": 43.0, "val_loss": 0.6923564100265502, "val_acc": 52.0}
{"epoch": 12, "training_loss": 0.7411248826980591, "training_acc": 43.0, "val_loss": 0.6937554597854614, "val_acc": 48.0}
{"epoch": 13, "training_loss": 0.7061905860900879, "training_acc": 45.0, "val_loss": 0.6936464524269104, "val_acc": 52.0}
{"epoch": 14, "training_loss": 0.7294254207611084, "training_acc": 35.0, "val_loss": 0.695286729335785, "val_acc": 48.0}
{"epoch": 15, "training_loss": 0.6975909662246704, "training_acc": 51.0, "val_loss": 0.6981590747833252, "val_acc": 48.0}
{"epoch": 16, "training_loss": 0.7304076361656189, "training_acc": 41.0, "val_loss": 0.6961730241775512, "val_acc": 48.0}
{"epoch": 17, "training_loss": 0.7103787755966187, "training_acc": 51.0, "val_loss": 0.8269241261482239, "val_acc": 48.0}
{"epoch": 18, "training_loss": 0.8273399424552917, "training_acc": 37.0, "val_loss": 0.7076912069320679, "val_acc": 48.0}
{"epoch": 19, "training_loss": 0.7029130482673644, "training_acc": 51.0, "val_loss": 0.7077586340904236, "val_acc": 48.0}
{"epoch": 20, "training_loss": 0.7285116481781005, "training_acc": 53.0, "val_loss": 0.7125204133987427, "val_acc": 52.0}
{"epoch": 21, "training_loss": 0.7208419632911682, "training_acc": 51.0, "val_loss": 0.7470182776451111, "val_acc": 52.0}
{"epoch": 22, "training_loss": 0.7122062873840332, "training_acc": 57.0, "val_loss": 1.2402990913391114, "val_acc": 48.0}
{"epoch": 23, "training_loss": 0.9581356000900269, "training_acc": 45.0, "val_loss": 0.6968851494789123, "val_acc": 48.0}
{"epoch": 24, "training_loss": 0.7124093866348267, "training_acc": 51.0, "val_loss": 0.7834623670578003, "val_acc": 52.0}
{"epoch": 25, "training_loss": 0.7951959085464477, "training_acc": 43.0, "val_loss": 0.7567316508293152, "val_acc": 52.0}
{"epoch": 26, "training_loss": 0.8126061940193177, "training_acc": 49.0, "val_loss": 0.8187898182868958, "val_acc": 48.0}
{"epoch": 27, "training_loss": 0.7468553638458252, "training_acc": 51.0, "val_loss": 0.7159545516967774, "val_acc": 48.0}
{"epoch": 28, "training_loss": 0.7551459050178528, "training_acc": 47.0, "val_loss": 0.7025850343704224, "val_acc": 48.0}
{"epoch": 29, "training_loss": 0.7258414793014526, "training_acc": 49.0, "val_loss": 0.692353012561798, "val_acc": 52.0}
{"epoch": 30, "training_loss": 0.7268368554115295, "training_acc": 59.0, "val_loss": 0.6953438878059387, "val_acc": 52.0}
{"epoch": 31, "training_loss": 0.7785823059082031, "training_acc": 47.0, "val_loss": 0.8067422127723693, "val_acc": 48.0}
{"epoch": 32, "training_loss": 0.7491714763641357, "training_acc": 47.0, "val_loss": 0.8394023633003235, "val_acc": 48.0}
{"epoch": 33, "training_loss": 0.9176685523986816, "training_acc": 55.0, "val_loss": 1.077684645652771, "val_acc": 52.0}
{"epoch": 34, "training_loss": 0.8241085934638978, "training_acc": 53.0, "val_loss": 0.71808762550354, "val_acc": 48.0}
{"epoch": 35, "training_loss": 0.7243518614768982, "training_acc": 51.0, "val_loss": 0.714360282421112, "val_acc": 48.0}
{"epoch": 36, "training_loss": 0.7781556606292724, "training_acc": 45.0, "val_loss": 0.6961098146438599, "val_acc": 48.0}
{"epoch": 37, "training_loss": 0.7902807402610779, "training_acc": 49.0, "val_loss": 0.9074105072021484, "val_acc": 48.0}
{"epoch": 38, "training_loss": 0.8487623643875122, "training_acc": 41.0, "val_loss": 0.7336951899528503, "val_acc": 48.0}
{"epoch": 39, "training_loss": 0.752189371585846, "training_acc": 43.0, "val_loss": 0.9650665402412415, "val_acc": 48.0}
{"epoch": 40, "training_loss": 0.8497807192802429, "training_acc": 45.0, "val_loss": 0.6930848407745361, "val_acc": 52.0}
{"epoch": 41, "training_loss": 0.7833601474761963, "training_acc": 45.0, "val_loss": 0.7595443654060364, "val_acc": 52.0}
{"epoch": 42, "training_loss": 0.7039642906188965, "training_acc": 57.0, "val_loss": 0.7686180591583252, "val_acc": 48.0}
{"epoch": 43, "training_loss": 0.7231594538688659, "training_acc": 53.0, "val_loss": 0.735116856098175, "val_acc": 52.0}
{"epoch": 44, "training_loss": 0.7002778196334839, "training_acc": 53.0, "val_loss": 0.7013696980476379, "val_acc": 48.0}
{"epoch": 45, "training_loss": 0.7081834745407104, "training_acc": 51.0, "val_loss": 0.7515232515335083, "val_acc": 48.0}
{"epoch": 46, "training_loss": 0.7346173572540283, "training_acc": 51.0, "val_loss": 0.6975907635688782, "val_acc": 52.0}
{"epoch": 47, "training_loss": 0.7485591173171997, "training_acc": 47.0, "val_loss": 0.7023619055747986, "val_acc": 52.0}
{"epoch": 48, "training_loss": 0.7252866005897523, "training_acc": 45.0, "val_loss": 0.692351610660553, "val_acc": 52.0}
{"epoch": 49, "training_loss": 0.730869448184967, "training_acc": 47.0, "val_loss": 0.7553259325027466, "val_acc": 52.0}
{"epoch": 50, "training_loss": 0.7613409614562988, "training_acc": 45.0, "val_loss": 0.7081571173667908, "val_acc": 48.0}
{"epoch": 51, "training_loss": 0.7307793736457825, "training_acc": 47.0, "val_loss": 0.8300107979774475, "val_acc": 48.0}
{"epoch": 52, "training_loss": 0.8156401968002319, "training_acc": 51.0, "val_loss": 0.9710517930984497, "val_acc": 52.0}
{"epoch": 53, "training_loss": 0.8940131282806396, "training_acc": 53.0, "val_loss": 0.83597904920578, "val_acc": 48.0}
{"epoch": 54, "training_loss": 0.7496537494659424, "training_acc": 55.0, "val_loss": 0.7308972668647766, "val_acc": 48.0}
{"epoch": 55, "training_loss": 0.7670496726036071, "training_acc": 53.0, "val_loss": 0.8907733511924744, "val_acc": 52.0}
{"epoch": 56, "training_loss": 0.8210731554031372, "training_acc": 47.0, "val_loss": 0.7793027853965759, "val_acc": 48.0}
{"epoch": 57, "training_loss": 0.7205207252502441, "training_acc": 53.0, "val_loss": 0.7151167511940002, "val_acc": 48.0}
{"epoch": 58, "training_loss": 0.7542635774612427, "training_acc": 49.0, "val_loss": 0.7334390878677368, "val_acc": 52.0}
{"epoch": 59, "training_loss": 0.7281119298934936, "training_acc": 51.0, "val_loss": 0.9714453554153443, "val_acc": 48.0}
{"epoch": 60, "training_loss": 0.8101927089691162, "training_acc": 51.0, "val_loss": 0.7275028347969055, "val_acc": 52.0}
{"epoch": 61, "training_loss": 0.7471398830413818, "training_acc": 53.0, "val_loss": 0.7006605315208435, "val_acc": 52.0}
{"epoch": 62, "training_loss": 0.7271728730201721, "training_acc": 45.0, "val_loss": 0.6962449169158935, "val_acc": 52.0}
{"epoch": 63, "training_loss": 0.7113704586029053, "training_acc": 47.0, "val_loss": 0.6948602414131164, "val_acc": 52.0}
{"epoch": 64, "training_loss": 0.7293158626556396, "training_acc": 49.0, "val_loss": 0.7114487767219544, "val_acc": 48.0}
{"epoch": 65, "training_loss": 0.7043387269973755, "training_acc": 47.0, "val_loss": 0.6975417923927307, "val_acc": 48.0}
{"epoch": 66, "training_loss": 0.7680398535728454, "training_acc": 47.0, "val_loss": 0.7243457531929016, "val_acc": 52.0}
{"epoch": 67, "training_loss": 0.7618760013580322, "training_acc": 45.0, "val_loss": 0.7179665446281434, "val_acc": 52.0}
