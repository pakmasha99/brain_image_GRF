"main_modify.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 2 --task ADNI_sex --input_option yAware --learning_rate 1e-2 --batch_size 16 --weight_decay 1e-4 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 0.9331874036788941, "training_acc": 50.0, "val_loss": 0.7594900059700013, "val_acc": 48.0}
{"epoch": 1, "training_loss": 0.7669178104400635, "training_acc": 50.0, "val_loss": 0.7557170605659485, "val_acc": 48.0}
{"epoch": 2, "training_loss": 0.7530422353744507, "training_acc": 50.0, "val_loss": 0.9937248849868774, "val_acc": 48.0}
{"epoch": 3, "training_loss": 0.8309537506103516, "training_acc": 52.0, "val_loss": 0.8151648640632629, "val_acc": 52.0}
{"epoch": 4, "training_loss": 0.7109634113311768, "training_acc": 52.0, "val_loss": 0.8463260340690613, "val_acc": 48.0}
{"epoch": 5, "training_loss": 0.7700346779823303, "training_acc": 48.0, "val_loss": 0.7214225506782532, "val_acc": 52.0}
{"epoch": 6, "training_loss": 0.7514834332466126, "training_acc": 48.0, "val_loss": 0.8891879415512085, "val_acc": 52.0}
{"epoch": 7, "training_loss": 0.8733884906768798, "training_acc": 50.0, "val_loss": 0.8199129176139831, "val_acc": 48.0}
{"epoch": 8, "training_loss": 0.6971919369697571, "training_acc": 54.0, "val_loss": 0.7274438118934632, "val_acc": 52.0}
{"epoch": 9, "training_loss": 0.779319303035736, "training_acc": 48.0, "val_loss": 0.830526614189148, "val_acc": 52.0}
{"epoch": 10, "training_loss": 0.8129722642898559, "training_acc": 52.0, "val_loss": 0.856031620502472, "val_acc": 48.0}
{"epoch": 11, "training_loss": 0.7749325275421143, "training_acc": 46.0, "val_loss": 0.7072123551368713, "val_acc": 48.0}
{"epoch": 12, "training_loss": 0.7186600208282471, "training_acc": 54.0, "val_loss": 0.8541022539138794, "val_acc": 52.0}
{"epoch": 13, "training_loss": 0.8626108694076539, "training_acc": 44.0, "val_loss": 0.708278615474701, "val_acc": 52.0}
{"epoch": 14, "training_loss": 0.726476743221283, "training_acc": 44.0, "val_loss": 0.828348970413208, "val_acc": 48.0}
{"epoch": 15, "training_loss": 0.7504375648498535, "training_acc": 50.0, "val_loss": 0.7004111576080322, "val_acc": 52.0}
{"epoch": 16, "training_loss": 0.6976089811325074, "training_acc": 52.0, "val_loss": 0.6941240096092224, "val_acc": 48.0}
{"epoch": 17, "training_loss": 0.7160421562194824, "training_acc": 46.0, "val_loss": 0.7150777745246887, "val_acc": 48.0}
{"epoch": 18, "training_loss": 0.7008476376533508, "training_acc": 60.0, "val_loss": 0.9098256230354309, "val_acc": 52.0}
{"epoch": 19, "training_loss": 0.7533119583129883, "training_acc": 54.0, "val_loss": 0.7878953552246094, "val_acc": 48.0}
{"epoch": 20, "training_loss": 0.7522164559364319, "training_acc": 46.0, "val_loss": 0.714413719177246, "val_acc": 48.0}
{"epoch": 21, "training_loss": 0.718933596611023, "training_acc": 50.0, "val_loss": 0.6999753189086914, "val_acc": 48.0}
{"epoch": 22, "training_loss": 0.7259403848648072, "training_acc": 54.0, "val_loss": 1.0348454427719116, "val_acc": 52.0}
{"epoch": 23, "training_loss": 0.9356214141845703, "training_acc": 46.0, "val_loss": 0.6927525353431702, "val_acc": 52.0}
{"epoch": 24, "training_loss": 0.8614235258102417, "training_acc": 46.0, "val_loss": 0.7504966711997986, "val_acc": 48.0}
{"epoch": 25, "training_loss": 0.7919811153411865, "training_acc": 42.0, "val_loss": 0.8955975270271301, "val_acc": 48.0}
{"epoch": 26, "training_loss": 0.8130923414230347, "training_acc": 46.0, "val_loss": 0.6925326943397522, "val_acc": 52.0}
{"epoch": 27, "training_loss": 0.7138331985473633, "training_acc": 46.0, "val_loss": 0.7167088627815247, "val_acc": 48.0}
{"epoch": 28, "training_loss": 0.7261600089073181, "training_acc": 38.0, "val_loss": 0.6960818409919739, "val_acc": 52.0}
{"epoch": 29, "training_loss": 0.7279076910018921, "training_acc": 52.0, "val_loss": 0.7259629154205323, "val_acc": 48.0}
{"epoch": 30, "training_loss": 0.7227160334587097, "training_acc": 48.0, "val_loss": 0.7060072302818299, "val_acc": 48.0}
{"epoch": 31, "training_loss": 0.720040225982666, "training_acc": 44.0, "val_loss": 0.7153271842002868, "val_acc": 48.0}
{"epoch": 32, "training_loss": 0.7311241030693054, "training_acc": 42.0, "val_loss": 0.69606121301651, "val_acc": 48.0}
{"epoch": 33, "training_loss": 0.7583107209205627, "training_acc": 52.0, "val_loss": 0.7469514894485474, "val_acc": 52.0}
{"epoch": 34, "training_loss": 0.7724313998222351, "training_acc": 50.0, "val_loss": 0.7104486393928527, "val_acc": 52.0}
{"epoch": 35, "training_loss": 0.7273248624801636, "training_acc": 44.0, "val_loss": 0.6929126048088073, "val_acc": 52.0}
{"epoch": 36, "training_loss": 0.701596896648407, "training_acc": 46.0, "val_loss": 0.7648046088218688, "val_acc": 48.0}
{"epoch": 37, "training_loss": 0.9306200122833252, "training_acc": 40.0, "val_loss": 0.7099027037620544, "val_acc": 48.0}
{"epoch": 38, "training_loss": 0.8440098285675048, "training_acc": 54.0, "val_loss": 1.1071753215789795, "val_acc": 52.0}
{"epoch": 39, "training_loss": 0.9823264718055725, "training_acc": 54.0, "val_loss": 1.242616674900055, "val_acc": 48.0}
{"epoch": 40, "training_loss": 0.9818629455566407, "training_acc": 52.0, "val_loss": 0.747915403842926, "val_acc": 52.0}
{"epoch": 41, "training_loss": 0.7185933065414428, "training_acc": 54.0, "val_loss": 0.6927321481704712, "val_acc": 52.0}
{"epoch": 42, "training_loss": 0.7044897890090942, "training_acc": 52.0, "val_loss": 0.759414644241333, "val_acc": 48.0}
{"epoch": 43, "training_loss": 0.7450966167449952, "training_acc": 46.0, "val_loss": 0.6926275634765625, "val_acc": 52.0}
{"epoch": 44, "training_loss": 0.7118127560615539, "training_acc": 52.0, "val_loss": 0.7161082005500794, "val_acc": 52.0}
{"epoch": 45, "training_loss": 0.7118164157867432, "training_acc": 50.0, "val_loss": 0.7347160029411316, "val_acc": 48.0}
