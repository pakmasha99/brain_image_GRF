"main_modify.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 2 --task ADNI_sex --input_option yAware --learning_rate 1e-2 --batch_size 16 --weight_decay 1e-4 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 1.3829237365722655, "training_acc": 46.0, "val_loss": 0.7035403943061829, "val_acc": 52.0}
{"epoch": 1, "training_loss": 0.7902732419967652, "training_acc": 48.0, "val_loss": 0.7413036108016968, "val_acc": 48.0}
{"epoch": 2, "training_loss": 0.7561063385009765, "training_acc": 46.0, "val_loss": 0.8032656240463257, "val_acc": 48.0}
{"epoch": 3, "training_loss": 0.7953904891014099, "training_acc": 46.0, "val_loss": 0.6959745144844055, "val_acc": 48.0}
{"epoch": 4, "training_loss": 0.7100602579116821, "training_acc": 50.0, "val_loss": 0.7392468190193177, "val_acc": 52.0}
{"epoch": 5, "training_loss": 0.7441501951217652, "training_acc": 46.0, "val_loss": 0.6994056105613708, "val_acc": 52.0}
{"epoch": 6, "training_loss": 0.8338229274749756, "training_acc": 52.0, "val_loss": 0.9201124763488769, "val_acc": 48.0}
{"epoch": 7, "training_loss": 0.7791963672637939, "training_acc": 50.0, "val_loss": 0.7773583698272705, "val_acc": 52.0}
{"epoch": 8, "training_loss": 0.7438834238052369, "training_acc": 52.0, "val_loss": 0.7034335780143738, "val_acc": 52.0}
{"epoch": 9, "training_loss": 0.7441513466835022, "training_acc": 46.0, "val_loss": 0.6933214044570923, "val_acc": 48.0}
{"epoch": 10, "training_loss": 0.7037353658676148, "training_acc": 51.0, "val_loss": 0.7083030033111573, "val_acc": 48.0}
{"epoch": 11, "training_loss": 0.7128409576416016, "training_acc": 48.0, "val_loss": 0.7715039992332459, "val_acc": 48.0}
{"epoch": 12, "training_loss": 0.7585531330108642, "training_acc": 42.0, "val_loss": 0.7074150371551514, "val_acc": 52.0}
{"epoch": 13, "training_loss": 0.7503182268142701, "training_acc": 54.0, "val_loss": 0.8332498168945313, "val_acc": 48.0}
{"epoch": 14, "training_loss": 0.8021610522270203, "training_acc": 46.0, "val_loss": 0.7816226506233215, "val_acc": 48.0}
{"epoch": 15, "training_loss": 0.828513822555542, "training_acc": 50.0, "val_loss": 0.7444257473945618, "val_acc": 52.0}
{"epoch": 16, "training_loss": 0.719248685836792, "training_acc": 50.0, "val_loss": 0.6923022532463073, "val_acc": 52.0}
{"epoch": 17, "training_loss": 0.7214505600929261, "training_acc": 52.0, "val_loss": 0.9239920997619628, "val_acc": 48.0}
{"epoch": 18, "training_loss": 0.8995974731445312, "training_acc": 54.0, "val_loss": 1.0167469716072082, "val_acc": 52.0}
{"epoch": 19, "training_loss": 0.8908097219467163, "training_acc": 48.0, "val_loss": 0.7246534204483033, "val_acc": 48.0}
{"epoch": 20, "training_loss": 0.8341871333122254, "training_acc": 50.0, "val_loss": 0.7504672169685364, "val_acc": 48.0}
{"epoch": 21, "training_loss": 0.6973383283615112, "training_acc": 54.0, "val_loss": 0.7986475515365601, "val_acc": 52.0}
{"epoch": 22, "training_loss": 0.7315924859046936, "training_acc": 58.0, "val_loss": 0.8679118657112121, "val_acc": 48.0}
{"epoch": 23, "training_loss": 0.7064923548698425, "training_acc": 58.0, "val_loss": 0.7684928894042968, "val_acc": 52.0}
{"epoch": 24, "training_loss": 0.7880292987823486, "training_acc": 44.0, "val_loss": 0.7046448802947998, "val_acc": 52.0}
{"epoch": 25, "training_loss": 0.7188489627838135, "training_acc": 50.0, "val_loss": 0.7408527493476867, "val_acc": 48.0}
{"epoch": 26, "training_loss": 0.7712188649177552, "training_acc": 46.0, "val_loss": 0.702907989025116, "val_acc": 52.0}
{"epoch": 27, "training_loss": 0.7053768181800842, "training_acc": 50.0, "val_loss": 0.6927212381362915, "val_acc": 48.0}
{"epoch": 28, "training_loss": 0.6981691908836365, "training_acc": 50.0, "val_loss": 0.7378337287902832, "val_acc": 52.0}
{"epoch": 29, "training_loss": 0.7161336159706115, "training_acc": 52.0, "val_loss": 0.7337610602378846, "val_acc": 48.0}
{"epoch": 30, "training_loss": 0.7333656167984008, "training_acc": 46.0, "val_loss": 0.6940161800384521, "val_acc": 52.0}
{"epoch": 31, "training_loss": 0.7035212755203247, "training_acc": 50.0, "val_loss": 0.6912211203575134, "val_acc": 56.0}
{"epoch": 32, "training_loss": 0.7108982372283935, "training_acc": 50.0, "val_loss": 0.7992663931846619, "val_acc": 48.0}
{"epoch": 33, "training_loss": 0.8082614707946777, "training_acc": 44.0, "val_loss": 0.698657157421112, "val_acc": 48.0}
{"epoch": 34, "training_loss": 0.7408395218849182, "training_acc": 48.0, "val_loss": 0.6921069025993347, "val_acc": 52.0}
{"epoch": 35, "training_loss": 0.7052215957641601, "training_acc": 48.0, "val_loss": 0.6981946516036988, "val_acc": 52.0}
{"epoch": 36, "training_loss": 0.7676150846481323, "training_acc": 48.0, "val_loss": 0.7200925827026368, "val_acc": 48.0}
{"epoch": 37, "training_loss": 0.7175083088874817, "training_acc": 50.0, "val_loss": 0.8043303799629211, "val_acc": 52.0}
{"epoch": 38, "training_loss": 0.7530828332901001, "training_acc": 48.0, "val_loss": 0.7055749464035034, "val_acc": 48.0}
{"epoch": 39, "training_loss": 0.705751714706421, "training_acc": 50.0, "val_loss": 0.6931490254402161, "val_acc": 48.0}
{"epoch": 40, "training_loss": 0.7150791549682617, "training_acc": 46.0, "val_loss": 0.7066936874389649, "val_acc": 48.0}
{"epoch": 41, "training_loss": 0.7096107220649719, "training_acc": 52.0, "val_loss": 0.7052719926834107, "val_acc": 48.0}
{"epoch": 42, "training_loss": 0.7225129675865173, "training_acc": 44.0, "val_loss": 0.6923980617523193, "val_acc": 52.0}
{"epoch": 43, "training_loss": 0.7608601069450378, "training_acc": 46.0, "val_loss": 0.6938810706138611, "val_acc": 52.0}
{"epoch": 44, "training_loss": 0.7579955720901489, "training_acc": 52.0, "val_loss": 0.8339565467834472, "val_acc": 52.0}
{"epoch": 45, "training_loss": 0.9089168810844421, "training_acc": 48.0, "val_loss": 0.7042415976524353, "val_acc": 48.0}
{"epoch": 46, "training_loss": 0.7002476716041565, "training_acc": 54.0, "val_loss": 0.7375645184516907, "val_acc": 48.0}
{"epoch": 47, "training_loss": 0.7725423264503479, "training_acc": 48.0, "val_loss": 0.8172040700912475, "val_acc": 48.0}
{"epoch": 48, "training_loss": 0.7750190567970275, "training_acc": 50.0, "val_loss": 0.7349568510055542, "val_acc": 52.0}
{"epoch": 49, "training_loss": 0.7519374489784241, "training_acc": 50.0, "val_loss": 0.8294937133789062, "val_acc": 52.0}
{"epoch": 50, "training_loss": 0.7737078380584717, "training_acc": 56.0, "val_loss": 1.0007596492767334, "val_acc": 48.0}
