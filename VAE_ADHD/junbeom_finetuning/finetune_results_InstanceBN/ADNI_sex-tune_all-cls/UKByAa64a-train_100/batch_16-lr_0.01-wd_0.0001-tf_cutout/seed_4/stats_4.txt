"main_modify.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 4 --task ADNI_sex --input_option yAware --learning_rate 1e-2 --batch_size 16 --weight_decay 1e-4 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 1.1702349662780762, "training_acc": 56.0, "val_loss": 0.699648094177246, "val_acc": 48.0}
{"epoch": 1, "training_loss": 0.8959188461303711, "training_acc": 48.0, "val_loss": 0.7159078359603882, "val_acc": 52.0}
{"epoch": 2, "training_loss": 0.759412682056427, "training_acc": 48.0, "val_loss": 0.9392100667953491, "val_acc": 52.0}
{"epoch": 3, "training_loss": 0.9364185094833374, "training_acc": 46.0, "val_loss": 0.6924015736579895, "val_acc": 52.0}
{"epoch": 4, "training_loss": 0.7742560839653015, "training_acc": 50.0, "val_loss": 0.7671175193786621, "val_acc": 48.0}
{"epoch": 5, "training_loss": 0.8416182136535645, "training_acc": 50.0, "val_loss": 0.8478092265129089, "val_acc": 52.0}
{"epoch": 6, "training_loss": 0.8685546875, "training_acc": 44.0, "val_loss": 0.6925205969810486, "val_acc": 52.0}
{"epoch": 7, "training_loss": 0.7413195610046387, "training_acc": 50.0, "val_loss": 0.7157912755012512, "val_acc": 48.0}
{"epoch": 8, "training_loss": 0.7550454139709473, "training_acc": 44.0, "val_loss": 0.7516694235801696, "val_acc": 48.0}
{"epoch": 9, "training_loss": 0.8322425222396851, "training_acc": 48.0, "val_loss": 0.9234703874588013, "val_acc": 52.0}
{"epoch": 10, "training_loss": 0.9255688381195069, "training_acc": 44.0, "val_loss": 0.7196060681343078, "val_acc": 48.0}
{"epoch": 11, "training_loss": 0.7613069653511048, "training_acc": 48.0, "val_loss": 0.7134236645698547, "val_acc": 48.0}
{"epoch": 12, "training_loss": 0.7219934797286988, "training_acc": 46.0, "val_loss": 0.6923684430122375, "val_acc": 52.0}
{"epoch": 13, "training_loss": 0.7052796578407288, "training_acc": 44.0, "val_loss": 0.6978686976432801, "val_acc": 48.0}
{"epoch": 14, "training_loss": 0.7066949415206909, "training_acc": 48.0, "val_loss": 0.7118996548652649, "val_acc": 48.0}
{"epoch": 15, "training_loss": 0.7409917211532593, "training_acc": 46.0, "val_loss": 0.6935122919082641, "val_acc": 48.0}
{"epoch": 16, "training_loss": 0.7696847414970398, "training_acc": 44.0, "val_loss": 0.7082070970535278, "val_acc": 52.0}
{"epoch": 17, "training_loss": 0.6892821359634399, "training_acc": 56.0, "val_loss": 0.7536134696006775, "val_acc": 48.0}
{"epoch": 18, "training_loss": 0.7470510792732239, "training_acc": 50.0, "val_loss": 0.8510560011863708, "val_acc": 48.0}
{"epoch": 19, "training_loss": 0.7906067609786988, "training_acc": 48.0, "val_loss": 0.6930511569976807, "val_acc": 52.0}
{"epoch": 20, "training_loss": 0.7357878541946411, "training_acc": 42.0, "val_loss": 0.7009512448310852, "val_acc": 52.0}
{"epoch": 21, "training_loss": 0.7127243828773498, "training_acc": 54.0, "val_loss": 0.8028949809074402, "val_acc": 48.0}
{"epoch": 22, "training_loss": 0.8735886430740356, "training_acc": 38.0, "val_loss": 0.7269196772575378, "val_acc": 48.0}
{"epoch": 23, "training_loss": 0.7755394077301025, "training_acc": 48.0, "val_loss": 0.7006672596931458, "val_acc": 52.0}
{"epoch": 24, "training_loss": 0.6981561183929443, "training_acc": 52.0, "val_loss": 0.7423950910568238, "val_acc": 48.0}
{"epoch": 25, "training_loss": 0.7195060420036316, "training_acc": 50.0, "val_loss": 0.6923531007766723, "val_acc": 52.0}
{"epoch": 26, "training_loss": 0.689961085319519, "training_acc": 54.0, "val_loss": 0.7279232120513917, "val_acc": 48.0}
{"epoch": 27, "training_loss": 0.7004793071746827, "training_acc": 52.0, "val_loss": 0.7644929194450378, "val_acc": 52.0}
{"epoch": 28, "training_loss": 0.7435750102996826, "training_acc": 54.0, "val_loss": 0.8297105884552002, "val_acc": 48.0}
{"epoch": 29, "training_loss": 0.7803102731704712, "training_acc": 52.0, "val_loss": 0.6945185351371765, "val_acc": 52.0}
{"epoch": 30, "training_loss": 0.832951192855835, "training_acc": 46.0, "val_loss": 0.7269088768959046, "val_acc": 52.0}
{"epoch": 31, "training_loss": 0.7551161885261536, "training_acc": 50.0, "val_loss": 0.7660751366615295, "val_acc": 48.0}
{"epoch": 32, "training_loss": 0.775978946685791, "training_acc": 50.0, "val_loss": 0.6923470330238343, "val_acc": 52.0}
{"epoch": 33, "training_loss": 0.845111255645752, "training_acc": 48.0, "val_loss": 0.8700939226150513, "val_acc": 52.0}
{"epoch": 34, "training_loss": 1.1067595529556273, "training_acc": 50.0, "val_loss": 0.8927425122261048, "val_acc": 48.0}
{"epoch": 35, "training_loss": 0.9499562096595764, "training_acc": 50.0, "val_loss": 0.8809956312179565, "val_acc": 52.0}
{"epoch": 36, "training_loss": 0.8852458143234253, "training_acc": 48.0, "val_loss": 0.8293091201782227, "val_acc": 48.0}
{"epoch": 37, "training_loss": 0.7889974975585937, "training_acc": 38.0, "val_loss": 0.6972457289695739, "val_acc": 52.0}
{"epoch": 38, "training_loss": 0.7040441703796386, "training_acc": 50.0, "val_loss": 0.698988356590271, "val_acc": 48.0}
{"epoch": 39, "training_loss": 0.7123805141448974, "training_acc": 50.0, "val_loss": 0.7195019173622131, "val_acc": 52.0}
{"epoch": 40, "training_loss": 0.7250364398956299, "training_acc": 48.0, "val_loss": 0.7133258032798767, "val_acc": 48.0}
{"epoch": 41, "training_loss": 0.7175914096832275, "training_acc": 52.0, "val_loss": 0.6980572438240051, "val_acc": 48.0}
{"epoch": 42, "training_loss": 0.7044013476371765, "training_acc": 50.0, "val_loss": 0.7136704158782959, "val_acc": 52.0}
{"epoch": 43, "training_loss": 0.7620486688613891, "training_acc": 44.0, "val_loss": 0.7179302883148193, "val_acc": 48.0}
{"epoch": 44, "training_loss": 0.6962669086456299, "training_acc": 50.0, "val_loss": 0.70792072057724, "val_acc": 52.0}
{"epoch": 45, "training_loss": 0.7327884387969971, "training_acc": 44.0, "val_loss": 0.6934142756462097, "val_acc": 48.0}
{"epoch": 46, "training_loss": 0.7226619005203248, "training_acc": 42.0, "val_loss": 0.697004747390747, "val_acc": 48.0}
{"epoch": 47, "training_loss": 0.7092030334472657, "training_acc": 48.0, "val_loss": 0.6923890805244446, "val_acc": 52.0}
{"epoch": 48, "training_loss": 0.7377364826202393, "training_acc": 44.0, "val_loss": 0.699864501953125, "val_acc": 48.0}
{"epoch": 49, "training_loss": 0.717657539844513, "training_acc": 48.0, "val_loss": 0.7237082743644714, "val_acc": 52.0}
{"epoch": 50, "training_loss": 0.7231966137886048, "training_acc": 48.0, "val_loss": 0.6939506363868714, "val_acc": 48.0}
{"epoch": 51, "training_loss": 0.7418329048156739, "training_acc": 44.0, "val_loss": 0.7520224833488465, "val_acc": 48.0}
