"main_modify.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 4 --task ADNI_sex --input_option yAware --learning_rate 1e-2 --batch_size 16 --weight_decay 1e-4 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 1.1929792165756226, "training_acc": 45.0, "val_loss": 0.8343325352668762, "val_acc": 52.0}
{"epoch": 1, "training_loss": 0.8276666688919068, "training_acc": 43.0, "val_loss": 0.699100489616394, "val_acc": 48.0}
{"epoch": 2, "training_loss": 0.7189875507354736, "training_acc": 49.0, "val_loss": 0.7283214044570923, "val_acc": 52.0}
{"epoch": 3, "training_loss": 0.7463117170333863, "training_acc": 49.0, "val_loss": 0.8267300581932068, "val_acc": 48.0}
{"epoch": 4, "training_loss": 0.8386784982681275, "training_acc": 41.0, "val_loss": 0.867314944267273, "val_acc": 48.0}
{"epoch": 5, "training_loss": 0.8994761180877685, "training_acc": 47.0, "val_loss": 0.7918919086456299, "val_acc": 52.0}
{"epoch": 6, "training_loss": 0.7875271677970886, "training_acc": 49.0, "val_loss": 0.692450315952301, "val_acc": 52.0}
{"epoch": 7, "training_loss": 0.7622243094444275, "training_acc": 45.0, "val_loss": 0.7038294744491577, "val_acc": 48.0}
{"epoch": 8, "training_loss": 0.7097880363464355, "training_acc": 43.0, "val_loss": 0.6975012254714966, "val_acc": 52.0}
{"epoch": 9, "training_loss": 0.7040911054611206, "training_acc": 51.0, "val_loss": 0.7244002103805542, "val_acc": 48.0}
{"epoch": 10, "training_loss": 0.7328257751464844, "training_acc": 39.0, "val_loss": 0.6991746497154235, "val_acc": 48.0}
{"epoch": 11, "training_loss": 0.7091303443908692, "training_acc": 55.0, "val_loss": 0.9315836167335511, "val_acc": 52.0}
{"epoch": 12, "training_loss": 0.9423272776603698, "training_acc": 49.0, "val_loss": 0.7944272685050965, "val_acc": 48.0}
{"epoch": 13, "training_loss": 0.7517797374725341, "training_acc": 47.0, "val_loss": 0.7184182286262513, "val_acc": 48.0}
{"epoch": 14, "training_loss": 0.7979798984527587, "training_acc": 47.0, "val_loss": 0.6957246208190918, "val_acc": 52.0}
{"epoch": 15, "training_loss": 0.7167413377761841, "training_acc": 53.0, "val_loss": 0.7177228736877441, "val_acc": 48.0}
{"epoch": 16, "training_loss": 0.6971379446983338, "training_acc": 45.0, "val_loss": 0.6948654484748841, "val_acc": 48.0}
{"epoch": 17, "training_loss": 0.7053443431854248, "training_acc": 54.0, "val_loss": 0.7980998229980468, "val_acc": 52.0}
{"epoch": 18, "training_loss": 0.8153896498680114, "training_acc": 41.0, "val_loss": 0.6926312971115113, "val_acc": 64.0}
{"epoch": 19, "training_loss": 0.6974288368225098, "training_acc": 53.0, "val_loss": 0.7178078651428222, "val_acc": 48.0}
{"epoch": 20, "training_loss": 0.7311577105522156, "training_acc": 51.0, "val_loss": 0.7426660084724426, "val_acc": 52.0}
{"epoch": 21, "training_loss": 0.770635895729065, "training_acc": 43.0, "val_loss": 0.6942275285720825, "val_acc": 52.0}
{"epoch": 22, "training_loss": 0.7179794979095458, "training_acc": 51.0, "val_loss": 0.6937459492683411, "val_acc": 52.0}
{"epoch": 23, "training_loss": 0.7047841095924378, "training_acc": 47.0, "val_loss": 0.6914621353149414, "val_acc": 56.0}
{"epoch": 24, "training_loss": 0.7023119401931762, "training_acc": 55.0, "val_loss": 0.91672842502594, "val_acc": 52.0}
{"epoch": 25, "training_loss": 1.080833683013916, "training_acc": 47.0, "val_loss": 1.2766361141204834, "val_acc": 48.0}
{"epoch": 26, "training_loss": 1.0101433753967286, "training_acc": 51.0, "val_loss": 0.7713083410263062, "val_acc": 52.0}
{"epoch": 27, "training_loss": 0.8606309127807618, "training_acc": 47.0, "val_loss": 0.6970472311973572, "val_acc": 52.0}
{"epoch": 28, "training_loss": 0.7335647916793824, "training_acc": 47.0, "val_loss": 0.7619418263435364, "val_acc": 48.0}
{"epoch": 29, "training_loss": 0.7933548140525818, "training_acc": 47.0, "val_loss": 0.7015791654586792, "val_acc": 52.0}
{"epoch": 30, "training_loss": 0.717144992351532, "training_acc": 49.0, "val_loss": 0.8551545023918152, "val_acc": 52.0}
{"epoch": 31, "training_loss": 0.8644651889801025, "training_acc": 51.0, "val_loss": 0.8729115414619446, "val_acc": 48.0}
{"epoch": 32, "training_loss": 0.7643395566940308, "training_acc": 47.0, "val_loss": 0.7043148875236511, "val_acc": 48.0}
{"epoch": 33, "training_loss": 0.7019881725311279, "training_acc": 51.0, "val_loss": 0.7297909188270569, "val_acc": 48.0}
{"epoch": 34, "training_loss": 0.834532241821289, "training_acc": 43.0, "val_loss": 0.8047239255905151, "val_acc": 48.0}
{"epoch": 35, "training_loss": 0.9225276231765747, "training_acc": 49.0, "val_loss": 0.8402206110954284, "val_acc": 52.0}
{"epoch": 36, "training_loss": 0.8137934064865112, "training_acc": 49.0, "val_loss": 0.6912194561958312, "val_acc": 52.0}
{"epoch": 37, "training_loss": 0.7712966465950012, "training_acc": 42.0, "val_loss": 0.691049337387085, "val_acc": 52.0}
{"epoch": 38, "training_loss": 0.7553133916854858, "training_acc": 51.0, "val_loss": 1.0025084805488587, "val_acc": 48.0}
{"epoch": 39, "training_loss": 0.8910567498207093, "training_acc": 43.0, "val_loss": 0.702259612083435, "val_acc": 52.0}
{"epoch": 40, "training_loss": 0.6996615076065064, "training_acc": 57.0, "val_loss": 0.786125648021698, "val_acc": 48.0}
{"epoch": 41, "training_loss": 0.7130584478378296, "training_acc": 53.0, "val_loss": 0.7208497548103332, "val_acc": 52.0}
{"epoch": 42, "training_loss": 0.7348063564300538, "training_acc": 43.0, "val_loss": 0.6884375905990601, "val_acc": 52.0}
{"epoch": 43, "training_loss": 0.711432089805603, "training_acc": 53.0, "val_loss": 0.7201710605621338, "val_acc": 52.0}
{"epoch": 44, "training_loss": 0.7879111433029174, "training_acc": 39.0, "val_loss": 0.7185746145248413, "val_acc": 52.0}
{"epoch": 45, "training_loss": 0.719437530040741, "training_acc": 49.0, "val_loss": 0.752192656993866, "val_acc": 48.0}
{"epoch": 46, "training_loss": 0.7064455151557922, "training_acc": 56.0, "val_loss": 0.7607264733314514, "val_acc": 52.0}
{"epoch": 47, "training_loss": 0.7629347562789917, "training_acc": 45.0, "val_loss": 0.6926455545425415, "val_acc": 52.0}
{"epoch": 48, "training_loss": 0.7213487815856934, "training_acc": 49.0, "val_loss": 0.8960241603851319, "val_acc": 48.0}
{"epoch": 49, "training_loss": 0.7387968754768371, "training_acc": 57.0, "val_loss": 0.9870369553565979, "val_acc": 52.0}
{"epoch": 50, "training_loss": 0.7565559816360473, "training_acc": 61.0, "val_loss": 0.868104202747345, "val_acc": 48.0}
{"epoch": 51, "training_loss": 0.7528708934783935, "training_acc": 51.0, "val_loss": 0.7997810888290405, "val_acc": 48.0}
{"epoch": 52, "training_loss": 0.8832887744903565, "training_acc": 51.0, "val_loss": 0.8111937832832337, "val_acc": 52.0}
{"epoch": 53, "training_loss": 0.7334763383865357, "training_acc": 57.0, "val_loss": 0.7081879472732544, "val_acc": 48.0}
{"epoch": 54, "training_loss": 0.7051836776733399, "training_acc": 47.0, "val_loss": 0.6911828708648682, "val_acc": 52.0}
{"epoch": 55, "training_loss": 0.7281249165534973, "training_acc": 46.0, "val_loss": 0.6966514134407044, "val_acc": 52.0}
{"epoch": 56, "training_loss": 0.747755651473999, "training_acc": 47.0, "val_loss": 0.7105016446113587, "val_acc": 48.0}
{"epoch": 57, "training_loss": 0.69743572473526, "training_acc": 51.0, "val_loss": 0.7186274147033691, "val_acc": 48.0}
{"epoch": 58, "training_loss": 0.7280254197120667, "training_acc": 49.0, "val_loss": 0.7012263226509095, "val_acc": 52.0}
{"epoch": 59, "training_loss": 0.7521097493171692, "training_acc": 47.0, "val_loss": 0.7668001794815064, "val_acc": 52.0}
{"epoch": 60, "training_loss": 0.7467881345748901, "training_acc": 48.0, "val_loss": 0.6822915530204773, "val_acc": 52.0}
{"epoch": 61, "training_loss": 0.6862533712387084, "training_acc": 56.0, "val_loss": 0.7014708805084229, "val_acc": 48.0}
{"epoch": 62, "training_loss": 0.7052550196647644, "training_acc": 51.0, "val_loss": 0.7236513948440552, "val_acc": 52.0}
{"epoch": 63, "training_loss": 0.7257191729545593, "training_acc": 47.0, "val_loss": 0.6867365360260009, "val_acc": 52.0}
{"epoch": 64, "training_loss": 0.7218028044700623, "training_acc": 47.0, "val_loss": 0.7051530456542969, "val_acc": 48.0}
{"epoch": 65, "training_loss": 0.6876001214981079, "training_acc": 52.0, "val_loss": 0.7540513563156128, "val_acc": 52.0}
{"epoch": 66, "training_loss": 0.7366673731803894, "training_acc": 54.0, "val_loss": 0.7006886243820191, "val_acc": 52.0}
{"epoch": 67, "training_loss": 0.703347053527832, "training_acc": 49.0, "val_loss": 0.7238708829879761, "val_acc": 48.0}
{"epoch": 68, "training_loss": 0.6893375158309937, "training_acc": 53.0, "val_loss": 0.6922430062294006, "val_acc": 52.0}
{"epoch": 69, "training_loss": 0.667240834236145, "training_acc": 61.0, "val_loss": 0.7319586491584777, "val_acc": 48.0}
{"epoch": 70, "training_loss": 0.72570472240448, "training_acc": 42.0, "val_loss": 0.6808885669708252, "val_acc": 56.0}
{"epoch": 71, "training_loss": 0.6807573890686035, "training_acc": 52.0, "val_loss": 0.8091147637367249, "val_acc": 52.0}
{"epoch": 72, "training_loss": 0.7554966521263122, "training_acc": 52.0, "val_loss": 0.6846025180816651, "val_acc": 64.0}
{"epoch": 73, "training_loss": 0.8046527361869812, "training_acc": 52.0, "val_loss": 0.730775752067566, "val_acc": 48.0}
{"epoch": 74, "training_loss": 0.7592606449127197, "training_acc": 50.0, "val_loss": 1.0945140361785888, "val_acc": 48.0}
{"epoch": 75, "training_loss": 0.8474334859848023, "training_acc": 52.0, "val_loss": 0.7491327619552612, "val_acc": 52.0}
{"epoch": 76, "training_loss": 0.7058937454223633, "training_acc": 50.0, "val_loss": 0.7139313459396363, "val_acc": 52.0}
{"epoch": 77, "training_loss": 0.7951328086853028, "training_acc": 55.0, "val_loss": 0.9579699420928955, "val_acc": 48.0}
{"epoch": 78, "training_loss": 0.734472713470459, "training_acc": 52.0, "val_loss": 0.775623779296875, "val_acc": 48.0}
{"epoch": 79, "training_loss": 0.7702793788909912, "training_acc": 53.0, "val_loss": 0.841029314994812, "val_acc": 52.0}
{"epoch": 80, "training_loss": 0.8413084316253662, "training_acc": 45.0, "val_loss": 0.6921347689628601, "val_acc": 52.0}
{"epoch": 81, "training_loss": 0.7172833204269409, "training_acc": 52.0, "val_loss": 0.6967233276367187, "val_acc": 52.0}
{"epoch": 82, "training_loss": 0.6901692152023315, "training_acc": 49.0, "val_loss": 0.6946586036682129, "val_acc": 48.0}
{"epoch": 83, "training_loss": 0.6832904577255249, "training_acc": 51.0, "val_loss": 0.7649573612213135, "val_acc": 52.0}
{"epoch": 84, "training_loss": 0.8295698022842407, "training_acc": 52.0, "val_loss": 0.9098243594169617, "val_acc": 48.0}
{"epoch": 85, "training_loss": 0.7962307953834533, "training_acc": 53.0, "val_loss": 0.7541198849678039, "val_acc": 48.0}
{"epoch": 86, "training_loss": 0.7513011026382447, "training_acc": 49.0, "val_loss": 0.7713682079315185, "val_acc": 52.0}
{"epoch": 87, "training_loss": 0.7802621698379517, "training_acc": 45.0, "val_loss": 0.7466427278518677, "val_acc": 52.0}
{"epoch": 88, "training_loss": 0.7825179958343506, "training_acc": 51.0, "val_loss": 0.6725098514556884, "val_acc": 56.0}
{"epoch": 89, "training_loss": 0.6657680892944335, "training_acc": 55.0, "val_loss": 0.858006763458252, "val_acc": 48.0}
{"epoch": 90, "training_loss": 0.8698254442214965, "training_acc": 42.0, "val_loss": 0.7698704099655151, "val_acc": 48.0}
{"epoch": 91, "training_loss": 0.6938579368591309, "training_acc": 58.0, "val_loss": 0.7314281868934631, "val_acc": 52.0}
{"epoch": 92, "training_loss": 0.748007664680481, "training_acc": 50.0, "val_loss": 0.7269224143028259, "val_acc": 52.0}
{"epoch": 93, "training_loss": 0.7509728240966796, "training_acc": 49.0, "val_loss": 0.7254373502731323, "val_acc": 44.0}
{"epoch": 94, "training_loss": 0.6982712364196777, "training_acc": 50.0, "val_loss": 0.7038936471939087, "val_acc": 52.0}
{"epoch": 95, "training_loss": 0.7230761313438415, "training_acc": 51.0, "val_loss": 0.8120537209510803, "val_acc": 48.0}
{"epoch": 96, "training_loss": 0.7244190597534179, "training_acc": 50.0, "val_loss": 0.8601394581794739, "val_acc": 48.0}
{"epoch": 97, "training_loss": 0.7669723415374756, "training_acc": 51.0, "val_loss": 0.7383880972862243, "val_acc": 52.0}
{"epoch": 98, "training_loss": 0.7399560308456421, "training_acc": 54.0, "val_loss": 0.6711075329780578, "val_acc": 68.0}
{"epoch": 99, "training_loss": 0.6585836291313172, "training_acc": 55.0, "val_loss": 1.0366347360610961, "val_acc": 48.0}
