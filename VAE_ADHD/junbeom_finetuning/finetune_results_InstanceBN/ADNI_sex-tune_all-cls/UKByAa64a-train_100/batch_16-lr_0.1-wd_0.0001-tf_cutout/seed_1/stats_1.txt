"main_modify.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 1 --task ADNI_sex --input_option yAware --learning_rate 1e-1 --batch_size 16 --weight_decay 1e-4 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 10.995431718826294, "training_acc": 50.0, "val_loss": 0.7167830181121826, "val_acc": 52.0}
{"epoch": 1, "training_loss": 4.982095766067505, "training_acc": 52.0, "val_loss": 8.979217491149903, "val_acc": 48.0}
{"epoch": 2, "training_loss": 6.740773868560791, "training_acc": 50.0, "val_loss": 4.535856647491455, "val_acc": 52.0}
{"epoch": 3, "training_loss": 2.8388451528549195, "training_acc": 50.0, "val_loss": 2.715137357711792, "val_acc": 52.0}
{"epoch": 4, "training_loss": 1.8324937987327576, "training_acc": 52.0, "val_loss": 1.7906825876235961, "val_acc": 48.0}
{"epoch": 5, "training_loss": 1.1120081233978272, "training_acc": 46.0, "val_loss": 1.0716658449172973, "val_acc": 48.0}
{"epoch": 6, "training_loss": 0.9442919659614563, "training_acc": 50.0, "val_loss": 1.2238988065719605, "val_acc": 48.0}
{"epoch": 7, "training_loss": 1.7891147994995118, "training_acc": 38.0, "val_loss": 2.9172737789154053, "val_acc": 52.0}
{"epoch": 8, "training_loss": 2.5783103561401366, "training_acc": 42.0, "val_loss": 2.1631321620941164, "val_acc": 52.0}
{"epoch": 9, "training_loss": 1.6987419486045838, "training_acc": 48.0, "val_loss": 0.7004375171661377, "val_acc": 52.0}
{"epoch": 10, "training_loss": 1.009036464691162, "training_acc": 50.0, "val_loss": 1.6223218584060668, "val_acc": 52.0}
{"epoch": 11, "training_loss": 1.674903621673584, "training_acc": 52.0, "val_loss": 0.9618138742446899, "val_acc": 48.0}
{"epoch": 12, "training_loss": 1.3045879411697388, "training_acc": 56.0, "val_loss": 2.0360430765151976, "val_acc": 48.0}
{"epoch": 13, "training_loss": 1.681364574432373, "training_acc": 46.0, "val_loss": 0.7963117146492005, "val_acc": 52.0}
{"epoch": 14, "training_loss": 1.4536068892478944, "training_acc": 54.0, "val_loss": 2.035905427932739, "val_acc": 52.0}
{"epoch": 15, "training_loss": 1.1608368825912476, "training_acc": 44.0, "val_loss": 0.8609558296203613, "val_acc": 48.0}
{"epoch": 16, "training_loss": 0.7659419965744019, "training_acc": 54.0, "val_loss": 0.856321108341217, "val_acc": 52.0}
{"epoch": 17, "training_loss": 0.809994773864746, "training_acc": 54.0, "val_loss": 0.7574170327186585, "val_acc": 52.0}
{"epoch": 18, "training_loss": 0.8170531558990478, "training_acc": 52.0, "val_loss": 0.7205056691169739, "val_acc": 48.0}
{"epoch": 19, "training_loss": 0.852863473892212, "training_acc": 38.0, "val_loss": 1.2448848676681519, "val_acc": 52.0}
{"epoch": 20, "training_loss": 0.9505944538116455, "training_acc": 48.0, "val_loss": 0.7273228335380554, "val_acc": 48.0}
{"epoch": 21, "training_loss": 0.8735492467880249, "training_acc": 48.0, "val_loss": 1.0664123606681823, "val_acc": 48.0}
{"epoch": 22, "training_loss": 1.1147216844558716, "training_acc": 44.0, "val_loss": 0.7082044315338135, "val_acc": 52.0}
{"epoch": 23, "training_loss": 1.5100500679016113, "training_acc": 44.0, "val_loss": 1.772785882949829, "val_acc": 48.0}
{"epoch": 24, "training_loss": 2.0653393936157225, "training_acc": 42.0, "val_loss": 1.854412965774536, "val_acc": 52.0}
{"epoch": 25, "training_loss": 1.7494330596923828, "training_acc": 48.0, "val_loss": 0.692497456073761, "val_acc": 52.0}
{"epoch": 26, "training_loss": 1.1103507423400878, "training_acc": 46.0, "val_loss": 0.711535451412201, "val_acc": 48.0}
{"epoch": 27, "training_loss": 1.315879430770874, "training_acc": 48.0, "val_loss": 0.6938187432289123, "val_acc": 48.0}
{"epoch": 28, "training_loss": 0.9913759231567383, "training_acc": 40.0, "val_loss": 1.2166016435623168, "val_acc": 48.0}
{"epoch": 29, "training_loss": 0.8814966726303101, "training_acc": 46.0, "val_loss": 1.695486969947815, "val_acc": 48.0}
{"epoch": 30, "training_loss": 0.9132857847213746, "training_acc": 60.0, "val_loss": 0.9025074696540832, "val_acc": 48.0}
{"epoch": 31, "training_loss": 0.9624735450744629, "training_acc": 54.0, "val_loss": 1.4516628694534301, "val_acc": 52.0}
{"epoch": 32, "training_loss": 1.120935034751892, "training_acc": 42.0, "val_loss": 0.8721410632133484, "val_acc": 48.0}
{"epoch": 33, "training_loss": 1.0432068753242492, "training_acc": 50.0, "val_loss": 1.001734766960144, "val_acc": 52.0}
{"epoch": 34, "training_loss": 0.9422609090805054, "training_acc": 50.0, "val_loss": 0.8189686250686645, "val_acc": 48.0}
{"epoch": 35, "training_loss": 1.1838561344146727, "training_acc": 58.0, "val_loss": 0.8711703205108643, "val_acc": 52.0}
{"epoch": 36, "training_loss": 1.1004018115997314, "training_acc": 50.0, "val_loss": 1.6974794244766236, "val_acc": 48.0}
{"epoch": 37, "training_loss": 1.0447314500808715, "training_acc": 52.0, "val_loss": 1.0520364189147948, "val_acc": 52.0}
{"epoch": 38, "training_loss": 0.9918597984313965, "training_acc": 44.0, "val_loss": 1.163173050880432, "val_acc": 52.0}
{"epoch": 39, "training_loss": 1.0724971628189086, "training_acc": 48.0, "val_loss": 1.5970932245254517, "val_acc": 48.0}
{"epoch": 40, "training_loss": 1.0239015054702758, "training_acc": 52.0, "val_loss": 1.5670586013793946, "val_acc": 48.0}
{"epoch": 41, "training_loss": 1.0750099110603333, "training_acc": 42.0, "val_loss": 1.8504252433776855, "val_acc": 48.0}
{"epoch": 42, "training_loss": 1.3695536327362061, "training_acc": 46.0, "val_loss": 1.7445662021636963, "val_acc": 52.0}
{"epoch": 43, "training_loss": 1.2623129820823669, "training_acc": 42.0, "val_loss": 0.7897329902648926, "val_acc": 48.0}
{"epoch": 44, "training_loss": 0.7465006756782532, "training_acc": 48.0, "val_loss": 2.0144110202789305, "val_acc": 52.0}
