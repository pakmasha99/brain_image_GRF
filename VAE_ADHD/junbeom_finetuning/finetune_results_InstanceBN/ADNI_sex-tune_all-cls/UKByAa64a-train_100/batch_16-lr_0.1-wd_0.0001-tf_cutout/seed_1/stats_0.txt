"main_modify.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 1 --task ADNI_sex --input_option yAware --learning_rate 1e-1 --batch_size 16 --weight_decay 1e-4 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 8.454860324263572, "training_acc": 46.0, "val_loss": 2.154766836166382, "val_acc": 52.0}
{"epoch": 1, "training_loss": 2.23736270904541, "training_acc": 48.0, "val_loss": 5.453633222579956, "val_acc": 48.0}
{"epoch": 2, "training_loss": 4.0215855884552, "training_acc": 50.0, "val_loss": 0.7031103086471557, "val_acc": 48.0}
{"epoch": 3, "training_loss": 0.900056586265564, "training_acc": 46.0, "val_loss": 0.7270486378669738, "val_acc": 52.0}
{"epoch": 4, "training_loss": 0.8729645442962647, "training_acc": 56.0, "val_loss": 1.1933500266075134, "val_acc": 48.0}
{"epoch": 5, "training_loss": 1.0343237352371215, "training_acc": 48.0, "val_loss": 1.1190963220596313, "val_acc": 48.0}
{"epoch": 6, "training_loss": 0.7290634846687317, "training_acc": 58.0, "val_loss": 0.6936191129684448, "val_acc": 52.0}
{"epoch": 7, "training_loss": 0.732149338722229, "training_acc": 58.0, "val_loss": 0.778749806880951, "val_acc": 52.0}
{"epoch": 8, "training_loss": 1.0382935285568238, "training_acc": 42.0, "val_loss": 1.3798671054840088, "val_acc": 48.0}
{"epoch": 9, "training_loss": 0.8779958057403564, "training_acc": 50.0, "val_loss": 0.8046354794502258, "val_acc": 48.0}
{"epoch": 10, "training_loss": 1.0717519760131835, "training_acc": 48.0, "val_loss": 0.901485641002655, "val_acc": 48.0}
{"epoch": 11, "training_loss": 0.8820640182495117, "training_acc": 44.0, "val_loss": 0.8344746994972229, "val_acc": 52.0}
{"epoch": 12, "training_loss": 0.7551380586624146, "training_acc": 58.0, "val_loss": 0.9426822209358215, "val_acc": 48.0}
{"epoch": 13, "training_loss": 0.832290620803833, "training_acc": 50.0, "val_loss": 1.079597692489624, "val_acc": 52.0}
{"epoch": 14, "training_loss": 1.1334777879714966, "training_acc": 46.0, "val_loss": 0.8097174263000488, "val_acc": 52.0}
{"epoch": 15, "training_loss": 2.679924144744873, "training_acc": 52.0, "val_loss": 3.187267198562622, "val_acc": 52.0}
{"epoch": 16, "training_loss": 3.138880977630615, "training_acc": 48.0, "val_loss": 3.6467361736297605, "val_acc": 52.0}
{"epoch": 17, "training_loss": 2.053972625732422, "training_acc": 58.0, "val_loss": 1.7658806848526, "val_acc": 52.0}
{"epoch": 18, "training_loss": 1.188526430130005, "training_acc": 52.0, "val_loss": 1.7492198944091797, "val_acc": 48.0}
{"epoch": 19, "training_loss": 1.3774941515922547, "training_acc": 52.0, "val_loss": 1.436780228614807, "val_acc": 52.0}
{"epoch": 20, "training_loss": 1.7947694873809814, "training_acc": 48.0, "val_loss": 2.694871211051941, "val_acc": 48.0}
{"epoch": 21, "training_loss": 3.450477523803711, "training_acc": 48.0, "val_loss": 1.0018806958198547, "val_acc": 48.0}
{"epoch": 22, "training_loss": 2.2588254904747007, "training_acc": 50.0, "val_loss": 1.225969491004944, "val_acc": 48.0}
{"epoch": 23, "training_loss": 0.8574488925933837, "training_acc": 56.0, "val_loss": 0.698145043849945, "val_acc": 48.0}
{"epoch": 24, "training_loss": 0.7425202703475953, "training_acc": 62.0, "val_loss": 0.6923784923553467, "val_acc": 52.0}
{"epoch": 25, "training_loss": 1.3380853414535523, "training_acc": 60.0, "val_loss": 1.9300961351394654, "val_acc": 52.0}
{"epoch": 26, "training_loss": 1.0932246112823487, "training_acc": 56.0, "val_loss": 2.032347960472107, "val_acc": 48.0}
{"epoch": 27, "training_loss": 1.571775074005127, "training_acc": 46.0, "val_loss": 2.720123739242554, "val_acc": 52.0}
{"epoch": 28, "training_loss": 3.692665390968323, "training_acc": 52.0, "val_loss": 2.3532226276397705, "val_acc": 48.0}
{"epoch": 29, "training_loss": 1.309299063682556, "training_acc": 54.0, "val_loss": 2.3208842658996582, "val_acc": 52.0}
{"epoch": 30, "training_loss": 2.5097941303253175, "training_acc": 46.0, "val_loss": 2.6678207397460936, "val_acc": 52.0}
{"epoch": 31, "training_loss": 2.3274183082580566, "training_acc": 52.0, "val_loss": 3.6161076831817627, "val_acc": 52.0}
{"epoch": 32, "training_loss": 3.1324322509765623, "training_acc": 50.0, "val_loss": 4.06579285621643, "val_acc": 52.0}
{"epoch": 33, "training_loss": 2.9356082916259765, "training_acc": 42.0, "val_loss": 0.6991253209114074, "val_acc": 52.0}
{"epoch": 34, "training_loss": 2.111714553833008, "training_acc": 54.0, "val_loss": 2.5983763980865477, "val_acc": 52.0}
{"epoch": 35, "training_loss": 1.7527751016616822, "training_acc": 44.0, "val_loss": 0.7385673713684082, "val_acc": 48.0}
{"epoch": 36, "training_loss": 0.7639663982391357, "training_acc": 44.0, "val_loss": 2.621024932861328, "val_acc": 52.0}
{"epoch": 37, "training_loss": 2.657488203048706, "training_acc": 48.0, "val_loss": 1.8726337671279907, "val_acc": 52.0}
{"epoch": 38, "training_loss": 1.3424132204055785, "training_acc": 58.0, "val_loss": 0.7093421149253846, "val_acc": 52.0}
{"epoch": 39, "training_loss": 1.471847221851349, "training_acc": 52.0, "val_loss": 1.911922206878662, "val_acc": 48.0}
{"epoch": 40, "training_loss": 1.276564702987671, "training_acc": 52.0, "val_loss": 1.3120681476593017, "val_acc": 52.0}
{"epoch": 41, "training_loss": 1.2776455211639404, "training_acc": 52.0, "val_loss": 0.781482241153717, "val_acc": 48.0}
{"epoch": 42, "training_loss": 1.3054296207427978, "training_acc": 48.0, "val_loss": 3.2243255138397218, "val_acc": 48.0}
{"epoch": 43, "training_loss": 2.25923677444458, "training_acc": 50.0, "val_loss": 1.9954820203781127, "val_acc": 48.0}
