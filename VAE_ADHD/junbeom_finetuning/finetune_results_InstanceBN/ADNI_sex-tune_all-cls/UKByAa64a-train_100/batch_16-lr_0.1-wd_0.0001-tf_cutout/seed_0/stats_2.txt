"main_modify.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ADNI_sex --input_option yAware --learning_rate 1e-1 --batch_size 16 --weight_decay 1e-4 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 4.906141443252563, "training_acc": 43.0, "val_loss": 0.8010433268547058, "val_acc": 52.0}
{"epoch": 1, "training_loss": 3.6608711433410646, "training_acc": 46.0, "val_loss": 1.5859350395202636, "val_acc": 48.0}
{"epoch": 2, "training_loss": 2.4189675521850584, "training_acc": 52.0, "val_loss": 0.778080337047577, "val_acc": 48.0}
{"epoch": 3, "training_loss": 0.932812557220459, "training_acc": 56.0, "val_loss": 0.7315053391456604, "val_acc": 52.0}
{"epoch": 4, "training_loss": 0.9479841804504394, "training_acc": 46.0, "val_loss": 1.2434703159332274, "val_acc": 48.0}
{"epoch": 5, "training_loss": 1.2626376843452454, "training_acc": 48.0, "val_loss": 1.4726954650878907, "val_acc": 52.0}
{"epoch": 6, "training_loss": 1.4892194652557373, "training_acc": 50.0, "val_loss": 1.3870494484901428, "val_acc": 48.0}
{"epoch": 7, "training_loss": 1.9617531490325928, "training_acc": 46.0, "val_loss": 2.213806610107422, "val_acc": 48.0}
{"epoch": 8, "training_loss": 0.8819897222518921, "training_acc": 64.0, "val_loss": 0.7720639276504516, "val_acc": 52.0}
{"epoch": 9, "training_loss": 0.8927288699150085, "training_acc": 54.0, "val_loss": 2.1193516778945924, "val_acc": 48.0}
{"epoch": 10, "training_loss": 1.4639412784576415, "training_acc": 56.0, "val_loss": 1.0227504777908325, "val_acc": 52.0}
{"epoch": 11, "training_loss": 1.2476565146446228, "training_acc": 50.0, "val_loss": 0.8717997121810913, "val_acc": 52.0}
{"epoch": 12, "training_loss": 1.446716685295105, "training_acc": 50.0, "val_loss": 2.4022944831848143, "val_acc": 48.0}
{"epoch": 13, "training_loss": 1.7382086181640626, "training_acc": 52.0, "val_loss": 1.1242600631713868, "val_acc": 48.0}
{"epoch": 14, "training_loss": 2.802411891222, "training_acc": 42.0, "val_loss": 0.8296610999107361, "val_acc": 48.0}
{"epoch": 15, "training_loss": 0.9255067825317382, "training_acc": 54.0, "val_loss": 1.643639121055603, "val_acc": 48.0}
{"epoch": 16, "training_loss": 2.314379320144653, "training_acc": 46.0, "val_loss": 2.6131573152542114, "val_acc": 48.0}
{"epoch": 17, "training_loss": 1.7413021659851073, "training_acc": 56.0, "val_loss": 2.7559421920776366, "val_acc": 48.0}
{"epoch": 18, "training_loss": 2.23712317943573, "training_acc": 48.0, "val_loss": 2.6439834690093993, "val_acc": 48.0}
{"epoch": 19, "training_loss": 2.2373567390441895, "training_acc": 46.0, "val_loss": 2.0637943267822267, "val_acc": 48.0}
{"epoch": 20, "training_loss": 1.7778258228302002, "training_acc": 48.0, "val_loss": 2.7791510391235352, "val_acc": 48.0}
{"epoch": 21, "training_loss": 1.4616823744773866, "training_acc": 52.0, "val_loss": 0.6938888669013977, "val_acc": 48.0}
{"epoch": 22, "training_loss": 0.7329556941986084, "training_acc": 58.0, "val_loss": 0.6956688666343689, "val_acc": 48.0}
{"epoch": 23, "training_loss": 0.8341995906829834, "training_acc": 52.0, "val_loss": 0.7167214131355286, "val_acc": 48.0}
{"epoch": 24, "training_loss": 1.4494287538528443, "training_acc": 40.0, "val_loss": 0.7117614412307739, "val_acc": 48.0}
{"epoch": 25, "training_loss": 1.0160252666473388, "training_acc": 56.0, "val_loss": 0.7349721932411194, "val_acc": 48.0}
{"epoch": 26, "training_loss": 0.8029799318313598, "training_acc": 54.0, "val_loss": 0.9948154163360595, "val_acc": 52.0}
{"epoch": 27, "training_loss": 1.0184791278839112, "training_acc": 44.0, "val_loss": 1.0150197792053222, "val_acc": 48.0}
{"epoch": 28, "training_loss": 0.9263828897476196, "training_acc": 60.0, "val_loss": 0.7091978812217712, "val_acc": 48.0}
{"epoch": 29, "training_loss": 1.3844924426078797, "training_acc": 50.0, "val_loss": 1.614120020866394, "val_acc": 52.0}
{"epoch": 30, "training_loss": 1.2401720046997071, "training_acc": 54.0, "val_loss": 1.4678078651428224, "val_acc": 52.0}
{"epoch": 31, "training_loss": 0.9465188002586364, "training_acc": 46.0, "val_loss": 2.6823125076293945, "val_acc": 48.0}
{"epoch": 32, "training_loss": 2.06283052444458, "training_acc": 50.0, "val_loss": 2.0658596658706667, "val_acc": 48.0}
{"epoch": 33, "training_loss": 2.3809543514251708, "training_acc": 42.0, "val_loss": 1.9537373828887938, "val_acc": 52.0}
{"epoch": 34, "training_loss": 1.361309404373169, "training_acc": 55.0, "val_loss": 1.4372707414627075, "val_acc": 52.0}
{"epoch": 35, "training_loss": 1.792373740673065, "training_acc": 46.0, "val_loss": 1.3803796100616454, "val_acc": 48.0}
{"epoch": 36, "training_loss": 1.2237657833099365, "training_acc": 48.0, "val_loss": 1.0550285410881042, "val_acc": 52.0}
{"epoch": 37, "training_loss": 0.9744802927970886, "training_acc": 48.0, "val_loss": 2.6901259851455688, "val_acc": 48.0}
{"epoch": 38, "training_loss": 1.9434725666046142, "training_acc": 50.0, "val_loss": 2.0414097547531127, "val_acc": 48.0}
{"epoch": 39, "training_loss": 1.4539568614959717, "training_acc": 48.0, "val_loss": 0.7294301676750183, "val_acc": 48.0}
{"epoch": 40, "training_loss": 1.2703859949111937, "training_acc": 42.0, "val_loss": 0.6911685299873352, "val_acc": 52.0}
{"epoch": 41, "training_loss": 0.9337743163108826, "training_acc": 50.0, "val_loss": 0.6936545634269714, "val_acc": 52.0}
{"epoch": 42, "training_loss": 0.8594440547376871, "training_acc": 58.0, "val_loss": 4.116192874908447, "val_acc": 52.0}
{"epoch": 43, "training_loss": 3.1534417724609374, "training_acc": 38.0, "val_loss": 1.2281542921066284, "val_acc": 52.0}
{"epoch": 44, "training_loss": 2.367851486206055, "training_acc": 50.0, "val_loss": 0.7288412237167359, "val_acc": 48.0}
{"epoch": 45, "training_loss": 1.9659994792938233, "training_acc": 48.0, "val_loss": 1.9678530025482177, "val_acc": 48.0}
{"epoch": 46, "training_loss": 1.4340556979179382, "training_acc": 46.0, "val_loss": 2.2062833452224733, "val_acc": 52.0}
{"epoch": 47, "training_loss": 2.3322033309936523, "training_acc": 46.0, "val_loss": 1.3019035458564758, "val_acc": 52.0}
{"epoch": 48, "training_loss": 1.984339370727539, "training_acc": 50.0, "val_loss": 1.3516257476806641, "val_acc": 48.0}
{"epoch": 49, "training_loss": 1.4016919803619385, "training_acc": 52.0, "val_loss": 1.5372565078735352, "val_acc": 48.0}
{"epoch": 50, "training_loss": 1.489040403366089, "training_acc": 50.0, "val_loss": 2.6441553115844725, "val_acc": 52.0}
{"epoch": 51, "training_loss": 2.345127305984497, "training_acc": 44.0, "val_loss": 0.7117334365844726, "val_acc": 52.0}
{"epoch": 52, "training_loss": 1.7999289894104005, "training_acc": 46.0, "val_loss": 2.9796644973754884, "val_acc": 48.0}
{"epoch": 53, "training_loss": 2.578348934650421, "training_acc": 46.0, "val_loss": 1.4044309997558593, "val_acc": 48.0}
{"epoch": 54, "training_loss": 1.0474487590789794, "training_acc": 46.0, "val_loss": 0.7497292947769165, "val_acc": 48.0}
{"epoch": 55, "training_loss": 0.8499894499778747, "training_acc": 60.0, "val_loss": 1.8858192157745362, "val_acc": 48.0}
{"epoch": 56, "training_loss": 1.1337802457809447, "training_acc": 52.0, "val_loss": 2.854521646499634, "val_acc": 52.0}
{"epoch": 57, "training_loss": 1.5408018136024475, "training_acc": 60.0, "val_loss": 2.053927526473999, "val_acc": 52.0}
{"epoch": 58, "training_loss": 1.3821328401565551, "training_acc": 40.0, "val_loss": 0.6961363577842712, "val_acc": 52.0}
{"epoch": 59, "training_loss": 0.8097289752960205, "training_acc": 54.0, "val_loss": 1.1148329973220825, "val_acc": 52.0}
