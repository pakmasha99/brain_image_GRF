"main_modify.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ADNI_sex --input_option yAware --learning_rate 1e-1 --batch_size 16 --weight_decay 1e-4 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 9.684731092453003, "training_acc": 55.0, "val_loss": 1.2589295482635499, "val_acc": 52.0}
{"epoch": 1, "training_loss": 9.353664665222167, "training_acc": 47.0, "val_loss": 4.069676761627197, "val_acc": 52.0}
{"epoch": 2, "training_loss": 7.450858564376831, "training_acc": 47.0, "val_loss": 4.7568376350402835, "val_acc": 48.0}
{"epoch": 3, "training_loss": 3.7352004051208496, "training_acc": 47.0, "val_loss": 0.7104289984703064, "val_acc": 48.0}
{"epoch": 4, "training_loss": 3.575259599685669, "training_acc": 53.0, "val_loss": 5.269173927307129, "val_acc": 52.0}
{"epoch": 5, "training_loss": 3.5641472053527834, "training_acc": 51.0, "val_loss": 2.065534152984619, "val_acc": 52.0}
{"epoch": 6, "training_loss": 1.9698270106315612, "training_acc": 41.0, "val_loss": 0.9253532719612122, "val_acc": 48.0}
{"epoch": 7, "training_loss": 0.9254012298583985, "training_acc": 51.0, "val_loss": 1.9767566585540772, "val_acc": 52.0}
{"epoch": 8, "training_loss": 1.5227153491973877, "training_acc": 49.0, "val_loss": 0.7710247015953064, "val_acc": 48.0}
{"epoch": 9, "training_loss": 0.8340260887145996, "training_acc": 45.0, "val_loss": 1.8269086647033692, "val_acc": 48.0}
{"epoch": 10, "training_loss": 1.4204294204711914, "training_acc": 55.0, "val_loss": 0.8298419070243835, "val_acc": 48.0}
{"epoch": 11, "training_loss": 1.2734690713882446, "training_acc": 55.0, "val_loss": 1.173296332359314, "val_acc": 52.0}
{"epoch": 12, "training_loss": 1.126667685508728, "training_acc": 51.0, "val_loss": 0.9225806355476379, "val_acc": 48.0}
{"epoch": 13, "training_loss": 1.4569147777557374, "training_acc": 49.0, "val_loss": 2.086468458175659, "val_acc": 48.0}
{"epoch": 14, "training_loss": 1.1539722061157227, "training_acc": 51.0, "val_loss": 1.2092120885848998, "val_acc": 52.0}
{"epoch": 15, "training_loss": 1.062966923713684, "training_acc": 51.0, "val_loss": 1.3811777448654174, "val_acc": 52.0}
{"epoch": 16, "training_loss": 1.2767422008514404, "training_acc": 45.0, "val_loss": 1.8280371713638306, "val_acc": 48.0}
{"epoch": 17, "training_loss": 1.6270945835113526, "training_acc": 51.0, "val_loss": 1.9482962036132812, "val_acc": 48.0}
{"epoch": 18, "training_loss": 1.3465036487579345, "training_acc": 45.0, "val_loss": 0.9948368763923645, "val_acc": 48.0}
{"epoch": 19, "training_loss": 1.7177802848815917, "training_acc": 47.0, "val_loss": 0.6970992994308471, "val_acc": 52.0}
{"epoch": 20, "training_loss": 1.369535083770752, "training_acc": 45.0, "val_loss": 0.7084237289428711, "val_acc": 52.0}
{"epoch": 21, "training_loss": 1.2886048698425292, "training_acc": 51.0, "val_loss": 1.584090600013733, "val_acc": 48.0}
{"epoch": 22, "training_loss": 1.508139899596572, "training_acc": 49.0, "val_loss": 2.628497905731201, "val_acc": 48.0}
{"epoch": 23, "training_loss": 1.7252747631072998, "training_acc": 53.0, "val_loss": 1.5721414041519166, "val_acc": 48.0}
{"epoch": 24, "training_loss": 1.7268662929534913, "training_acc": 51.0, "val_loss": 0.6942682194709778, "val_acc": 52.0}
{"epoch": 25, "training_loss": 1.6212753868103027, "training_acc": 51.0, "val_loss": 1.1112331438064575, "val_acc": 52.0}
{"epoch": 26, "training_loss": 1.1450765800476075, "training_acc": 39.0, "val_loss": 0.7185174989700317, "val_acc": 48.0}
{"epoch": 27, "training_loss": 1.6769985580444335, "training_acc": 43.0, "val_loss": 1.607360634803772, "val_acc": 52.0}
{"epoch": 28, "training_loss": 2.026976728439331, "training_acc": 47.0, "val_loss": 1.915248966217041, "val_acc": 52.0}
{"epoch": 29, "training_loss": 1.2866124990582466, "training_acc": 55.0, "val_loss": 1.8227210521697998, "val_acc": 52.0}
{"epoch": 30, "training_loss": 1.4961997199058532, "training_acc": 41.0, "val_loss": 0.8076488256454468, "val_acc": 52.0}
{"epoch": 31, "training_loss": 0.813380087018013, "training_acc": 45.0, "val_loss": 2.4030522537231445, "val_acc": 52.0}
{"epoch": 32, "training_loss": 1.4719719552993775, "training_acc": 49.0, "val_loss": 0.8364062786102295, "val_acc": 52.0}
{"epoch": 33, "training_loss": 0.8698669838905334, "training_acc": 57.0, "val_loss": 1.5135125494003296, "val_acc": 48.0}
{"epoch": 34, "training_loss": 1.6766774535179139, "training_acc": 45.0, "val_loss": 0.806778461933136, "val_acc": 52.0}
{"epoch": 35, "training_loss": 0.7800082874298095, "training_acc": 50.0, "val_loss": 0.6960854244232177, "val_acc": 52.0}
{"epoch": 36, "training_loss": 1.3552603387832642, "training_acc": 47.0, "val_loss": 1.2277946662902832, "val_acc": 52.0}
{"epoch": 37, "training_loss": 1.2971810960769654, "training_acc": 39.0, "val_loss": 2.046727991104126, "val_acc": 48.0}
{"epoch": 38, "training_loss": 1.6188013124465943, "training_acc": 59.0, "val_loss": 1.2276981973648071, "val_acc": 48.0}
{"epoch": 39, "training_loss": 1.0342012310028077, "training_acc": 55.0, "val_loss": 1.9915585041046142, "val_acc": 48.0}
{"epoch": 40, "training_loss": 1.8921218872070313, "training_acc": 55.0, "val_loss": 1.9951687049865723, "val_acc": 48.0}
{"epoch": 41, "training_loss": 1.0809517097473145, "training_acc": 47.0, "val_loss": 1.5771579837799072, "val_acc": 48.0}
{"epoch": 42, "training_loss": 0.9923801469802856, "training_acc": 53.0, "val_loss": 0.7224848246574402, "val_acc": 48.0}
{"epoch": 43, "training_loss": 0.7974257745593786, "training_acc": 51.0, "val_loss": 2.450342502593994, "val_acc": 48.0}
