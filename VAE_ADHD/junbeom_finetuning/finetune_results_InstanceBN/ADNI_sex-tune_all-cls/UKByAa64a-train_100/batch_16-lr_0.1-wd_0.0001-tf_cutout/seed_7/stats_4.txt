"main_modify.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 7 --task ADNI_sex --input_option yAware --learning_rate 1e-1 --batch_size 16 --weight_decay 1e-4 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 9.28175477027893, "training_acc": 52.0, "val_loss": 1.3861310577392578, "val_acc": 52.0}
{"epoch": 1, "training_loss": 3.084787435531616, "training_acc": 58.0, "val_loss": 2.8481780433654786, "val_acc": 48.0}
{"epoch": 2, "training_loss": 1.8687001514434813, "training_acc": 48.0, "val_loss": 0.7741010093688965, "val_acc": 48.0}
{"epoch": 3, "training_loss": 0.8478605270385742, "training_acc": 52.0, "val_loss": 1.3681738662719727, "val_acc": 48.0}
{"epoch": 4, "training_loss": 1.150800564289093, "training_acc": 46.0, "val_loss": 2.540208168029785, "val_acc": 48.0}
{"epoch": 5, "training_loss": 2.2266378688812254, "training_acc": 50.0, "val_loss": 1.6950119829177857, "val_acc": 48.0}
{"epoch": 6, "training_loss": 1.6117864990234374, "training_acc": 42.0, "val_loss": 1.4998044300079345, "val_acc": 52.0}
{"epoch": 7, "training_loss": 1.435923318862915, "training_acc": 46.0, "val_loss": 1.0936656141281127, "val_acc": 48.0}
{"epoch": 8, "training_loss": 1.8282121181488038, "training_acc": 48.0, "val_loss": 2.6358768939971924, "val_acc": 48.0}
{"epoch": 9, "training_loss": 1.6140812301635743, "training_acc": 54.0, "val_loss": 1.1161726093292237, "val_acc": 48.0}
{"epoch": 10, "training_loss": 0.9926439905166626, "training_acc": 56.0, "val_loss": 1.3592217874526977, "val_acc": 52.0}
{"epoch": 11, "training_loss": 1.0774373173713685, "training_acc": 50.0, "val_loss": 1.1587203931808472, "val_acc": 48.0}
{"epoch": 12, "training_loss": 1.3535573291778564, "training_acc": 46.0, "val_loss": 1.051207082271576, "val_acc": 52.0}
{"epoch": 13, "training_loss": 1.5128267669677735, "training_acc": 44.0, "val_loss": 0.8405439043045044, "val_acc": 48.0}
{"epoch": 14, "training_loss": 0.9709427309036255, "training_acc": 50.0, "val_loss": 0.7418168091773987, "val_acc": 52.0}
{"epoch": 15, "training_loss": 1.059314215183258, "training_acc": 58.0, "val_loss": 2.315340728759766, "val_acc": 52.0}
{"epoch": 16, "training_loss": 1.8310755443573, "training_acc": 50.0, "val_loss": 2.088792085647583, "val_acc": 52.0}
{"epoch": 17, "training_loss": 1.5048464488983155, "training_acc": 44.0, "val_loss": 1.0061837697029115, "val_acc": 48.0}
{"epoch": 18, "training_loss": 0.7130871343612671, "training_acc": 56.0, "val_loss": 1.362528419494629, "val_acc": 52.0}
{"epoch": 19, "training_loss": 0.9949354434013367, "training_acc": 52.0, "val_loss": 1.8888324213027954, "val_acc": 48.0}
{"epoch": 20, "training_loss": 1.2447339820861816, "training_acc": 54.0, "val_loss": 1.8931087827682496, "val_acc": 52.0}
{"epoch": 21, "training_loss": 2.3642990303039553, "training_acc": 48.0, "val_loss": 2.4445300102233887, "val_acc": 52.0}
{"epoch": 22, "training_loss": 1.471411280632019, "training_acc": 50.0, "val_loss": 1.851382703781128, "val_acc": 48.0}
{"epoch": 23, "training_loss": 1.392769136428833, "training_acc": 54.0, "val_loss": 0.692193603515625, "val_acc": 52.0}
{"epoch": 24, "training_loss": 1.007199649810791, "training_acc": 50.0, "val_loss": 2.6671472930908204, "val_acc": 48.0}
{"epoch": 25, "training_loss": 3.052903230190277, "training_acc": 46.0, "val_loss": 4.742466678619385, "val_acc": 48.0}
{"epoch": 26, "training_loss": 4.0118790626525875, "training_acc": 50.0, "val_loss": 4.177602891921997, "val_acc": 52.0}
{"epoch": 27, "training_loss": 2.9937993240356446, "training_acc": 44.0, "val_loss": 2.068367953300476, "val_acc": 52.0}
{"epoch": 28, "training_loss": 1.486743812561035, "training_acc": 48.0, "val_loss": 0.6926128888130187, "val_acc": 52.0}
{"epoch": 29, "training_loss": 0.8941863560676575, "training_acc": 56.0, "val_loss": 1.0170567297935487, "val_acc": 52.0}
{"epoch": 30, "training_loss": 0.9341142749786377, "training_acc": 54.0, "val_loss": 0.7432649993896484, "val_acc": 52.0}
{"epoch": 31, "training_loss": 0.8338852024078369, "training_acc": 54.0, "val_loss": 0.7864268612861633, "val_acc": 48.0}
{"epoch": 32, "training_loss": 0.8598883104324341, "training_acc": 46.0, "val_loss": 0.9492716693878174, "val_acc": 48.0}
{"epoch": 33, "training_loss": 0.976435444355011, "training_acc": 46.0, "val_loss": 0.7599294567108155, "val_acc": 48.0}
{"epoch": 34, "training_loss": 0.7748374700546264, "training_acc": 56.0, "val_loss": 1.1745059204101562, "val_acc": 48.0}
{"epoch": 35, "training_loss": 0.7933250617980957, "training_acc": 58.0, "val_loss": 0.8985416507720947, "val_acc": 48.0}
{"epoch": 36, "training_loss": 1.3654364776611327, "training_acc": 50.0, "val_loss": 1.2163734412193299, "val_acc": 48.0}
{"epoch": 37, "training_loss": 1.3942479801177978, "training_acc": 44.0, "val_loss": 1.5327659845352173, "val_acc": 48.0}
{"epoch": 38, "training_loss": 1.2777788877487182, "training_acc": 44.0, "val_loss": 0.7398759746551513, "val_acc": 48.0}
{"epoch": 39, "training_loss": 0.8483410191535949, "training_acc": 48.0, "val_loss": 1.191098961830139, "val_acc": 52.0}
{"epoch": 40, "training_loss": 0.9799167156219483, "training_acc": 42.0, "val_loss": 2.9934465217590334, "val_acc": 52.0}
{"epoch": 41, "training_loss": 3.091478900909424, "training_acc": 52.0, "val_loss": 0.9281689023971558, "val_acc": 48.0}
{"epoch": 42, "training_loss": 3.964174299240112, "training_acc": 46.0, "val_loss": 1.7246803379058837, "val_acc": 48.0}
