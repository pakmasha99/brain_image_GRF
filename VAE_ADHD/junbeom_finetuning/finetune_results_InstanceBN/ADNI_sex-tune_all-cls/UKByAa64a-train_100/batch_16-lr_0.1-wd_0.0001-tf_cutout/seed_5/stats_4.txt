"main_modify.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 5 --task ADNI_sex --input_option yAware --learning_rate 1e-1 --batch_size 16 --weight_decay 1e-4 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 9.59785460472107, "training_acc": 49.0, "val_loss": 4.569271602630615, "val_acc": 48.0}
{"epoch": 1, "training_loss": 4.34636852696538, "training_acc": 55.0, "val_loss": 5.889199371337891, "val_acc": 52.0}
{"epoch": 2, "training_loss": 4.931305451393127, "training_acc": 43.0, "val_loss": 2.328489274978638, "val_acc": 52.0}
{"epoch": 3, "training_loss": 2.4789324140548707, "training_acc": 55.0, "val_loss": 1.0795011043548584, "val_acc": 48.0}
{"epoch": 4, "training_loss": 2.125457017421722, "training_acc": 49.0, "val_loss": 0.8089639139175415, "val_acc": 52.0}
{"epoch": 5, "training_loss": 0.8958568286895752, "training_acc": 47.0, "val_loss": 1.0532387256622315, "val_acc": 52.0}
{"epoch": 6, "training_loss": 0.880414228439331, "training_acc": 57.0, "val_loss": 0.725243809223175, "val_acc": 52.0}
{"epoch": 7, "training_loss": 1.105983772277832, "training_acc": 49.0, "val_loss": 2.8685238361358643, "val_acc": 52.0}
{"epoch": 8, "training_loss": 1.6739764785766602, "training_acc": 53.0, "val_loss": 1.6952274227142334, "val_acc": 48.0}
{"epoch": 9, "training_loss": 1.2223706722259522, "training_acc": 45.0, "val_loss": 0.9047950100898743, "val_acc": 52.0}
{"epoch": 10, "training_loss": 1.2758617305755615, "training_acc": 49.0, "val_loss": 1.034747943878174, "val_acc": 48.0}
{"epoch": 11, "training_loss": 0.7300197410583497, "training_acc": 55.0, "val_loss": 0.9060644626617431, "val_acc": 48.0}
{"epoch": 12, "training_loss": 1.0273903656005858, "training_acc": 45.0, "val_loss": 1.3065143179893495, "val_acc": 48.0}
{"epoch": 13, "training_loss": 1.4587656688690185, "training_acc": 51.0, "val_loss": 0.7167512631416321, "val_acc": 48.0}
{"epoch": 14, "training_loss": 1.4504941749572753, "training_acc": 43.0, "val_loss": 1.7945193529129029, "val_acc": 52.0}
{"epoch": 15, "training_loss": 1.5662874245643617, "training_acc": 45.0, "val_loss": 2.745941801071167, "val_acc": 48.0}
{"epoch": 16, "training_loss": 1.59690265417099, "training_acc": 59.0, "val_loss": 0.7273144769668579, "val_acc": 52.0}
{"epoch": 17, "training_loss": 1.0392036771774291, "training_acc": 47.0, "val_loss": 1.9497530031204224, "val_acc": 48.0}
{"epoch": 18, "training_loss": 1.4595525026321412, "training_acc": 39.0, "val_loss": 0.694884581565857, "val_acc": 52.0}
{"epoch": 19, "training_loss": 1.5623384189605714, "training_acc": 39.0, "val_loss": 0.9280162858963013, "val_acc": 48.0}
{"epoch": 20, "training_loss": 2.5419138526916503, "training_acc": 45.0, "val_loss": 1.1525551080703735, "val_acc": 48.0}
{"epoch": 21, "training_loss": 1.819715337753296, "training_acc": 53.0, "val_loss": 0.6944970059394836, "val_acc": 52.0}
{"epoch": 22, "training_loss": 1.7628440189361572, "training_acc": 51.0, "val_loss": 0.863499047756195, "val_acc": 52.0}
{"epoch": 23, "training_loss": 1.4029199147224427, "training_acc": 53.0, "val_loss": 2.548830862045288, "val_acc": 52.0}
{"epoch": 24, "training_loss": 2.06534574508667, "training_acc": 47.0, "val_loss": 0.7656288814544677, "val_acc": 52.0}
{"epoch": 25, "training_loss": 1.0879118061065673, "training_acc": 53.0, "val_loss": 0.7083341526985169, "val_acc": 48.0}
{"epoch": 26, "training_loss": 1.0144304418563843, "training_acc": 55.0, "val_loss": 0.885165284872055, "val_acc": 52.0}
{"epoch": 27, "training_loss": 0.9464956665039063, "training_acc": 45.0, "val_loss": 0.897665593624115, "val_acc": 48.0}
{"epoch": 28, "training_loss": 1.3435586324334146, "training_acc": 47.0, "val_loss": 3.034493236541748, "val_acc": 52.0}
{"epoch": 29, "training_loss": 2.624432547688484, "training_acc": 45.0, "val_loss": 3.603105058670044, "val_acc": 52.0}
{"epoch": 30, "training_loss": 3.010545883178711, "training_acc": 55.0, "val_loss": 2.4473074197769167, "val_acc": 48.0}
{"epoch": 31, "training_loss": 2.3543557852506636, "training_acc": 47.0, "val_loss": 1.7695565271377562, "val_acc": 48.0}
{"epoch": 32, "training_loss": 2.2525300359725953, "training_acc": 55.0, "val_loss": 0.7119825601577758, "val_acc": 52.0}
{"epoch": 33, "training_loss": 1.0439636850357055, "training_acc": 51.0, "val_loss": 0.7307773089408874, "val_acc": 48.0}
{"epoch": 34, "training_loss": 0.9962776303291321, "training_acc": 47.0, "val_loss": 1.760097737312317, "val_acc": 52.0}
{"epoch": 35, "training_loss": 1.3192649245262147, "training_acc": 49.0, "val_loss": 0.788619225025177, "val_acc": 48.0}
{"epoch": 36, "training_loss": 1.5027086269855499, "training_acc": 47.0, "val_loss": 1.3369059801101684, "val_acc": 52.0}
{"epoch": 37, "training_loss": 1.3950550937652588, "training_acc": 47.0, "val_loss": 0.7370878529548645, "val_acc": 48.0}
{"epoch": 38, "training_loss": 1.1485004425048828, "training_acc": 53.0, "val_loss": 1.8103054666519165, "val_acc": 48.0}
{"epoch": 39, "training_loss": 1.6604615211486817, "training_acc": 49.0, "val_loss": 2.0444734382629393, "val_acc": 52.0}
{"epoch": 40, "training_loss": 1.6260888290405273, "training_acc": 49.0, "val_loss": 0.7857755398750306, "val_acc": 52.0}
