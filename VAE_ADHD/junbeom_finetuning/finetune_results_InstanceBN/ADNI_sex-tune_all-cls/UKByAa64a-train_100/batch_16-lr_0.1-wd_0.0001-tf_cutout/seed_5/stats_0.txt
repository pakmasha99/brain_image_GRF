"main_modify.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 5 --task ADNI_sex --input_option yAware --learning_rate 1e-1 --batch_size 16 --weight_decay 1e-4 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 7.456649851799011, "training_acc": 53.0, "val_loss": 3.0105380725860598, "val_acc": 52.0}
{"epoch": 1, "training_loss": 2.429083705842495, "training_acc": 58.0, "val_loss": 4.945329723358154, "val_acc": 52.0}
{"epoch": 2, "training_loss": 4.1531319379806515, "training_acc": 46.0, "val_loss": 2.371688108444214, "val_acc": 52.0}
{"epoch": 3, "training_loss": 2.1708320593833923, "training_acc": 46.0, "val_loss": 1.4918882131576539, "val_acc": 48.0}
{"epoch": 4, "training_loss": 1.18861834526062, "training_acc": 46.0, "val_loss": 3.2390305900573733, "val_acc": 48.0}
{"epoch": 5, "training_loss": 2.1827010560035705, "training_acc": 54.0, "val_loss": 3.1785190677642823, "val_acc": 48.0}
{"epoch": 6, "training_loss": 1.8983468198776245, "training_acc": 56.0, "val_loss": 1.8528673315048219, "val_acc": 48.0}
{"epoch": 7, "training_loss": 1.1611145639419556, "training_acc": 54.0, "val_loss": 1.3235132217407226, "val_acc": 52.0}
{"epoch": 8, "training_loss": 1.2952526712417602, "training_acc": 44.0, "val_loss": 0.7239044761657715, "val_acc": 48.0}
{"epoch": 9, "training_loss": 0.8151753377914429, "training_acc": 56.0, "val_loss": 0.743365626335144, "val_acc": 48.0}
{"epoch": 10, "training_loss": 0.8152360057830811, "training_acc": 52.0, "val_loss": 1.4329581356048584, "val_acc": 52.0}
{"epoch": 11, "training_loss": 1.3041294288635255, "training_acc": 48.0, "val_loss": 0.7683539652824402, "val_acc": 48.0}
{"epoch": 12, "training_loss": 1.6225566101074218, "training_acc": 46.0, "val_loss": 0.7182356190681457, "val_acc": 52.0}
{"epoch": 13, "training_loss": 1.0565870547294616, "training_acc": 56.0, "val_loss": 0.829669029712677, "val_acc": 48.0}
{"epoch": 14, "training_loss": 1.4849149417877197, "training_acc": 50.0, "val_loss": 3.2742444229125978, "val_acc": 52.0}
{"epoch": 15, "training_loss": 2.0983834314346312, "training_acc": 60.0, "val_loss": 2.728340721130371, "val_acc": 52.0}
{"epoch": 16, "training_loss": 2.4234673595428466, "training_acc": 48.0, "val_loss": 4.4845063018798825, "val_acc": 52.0}
{"epoch": 17, "training_loss": 3.421526198387146, "training_acc": 50.0, "val_loss": 3.282085113525391, "val_acc": 52.0}
{"epoch": 18, "training_loss": 3.954105796813965, "training_acc": 50.0, "val_loss": 1.9326748180389404, "val_acc": 48.0}
{"epoch": 19, "training_loss": 2.787909870147705, "training_acc": 54.0, "val_loss": 3.8358844470977784, "val_acc": 48.0}
{"epoch": 20, "training_loss": 3.204576587677002, "training_acc": 40.0, "val_loss": 0.6934380769729614, "val_acc": 48.0}
{"epoch": 21, "training_loss": 1.6516619110107422, "training_acc": 56.0, "val_loss": 2.613668041229248, "val_acc": 52.0}
{"epoch": 22, "training_loss": 2.0129922008514405, "training_acc": 52.0, "val_loss": 1.6885291981697081, "val_acc": 52.0}
{"epoch": 23, "training_loss": 1.0299391841888428, "training_acc": 44.0, "val_loss": 0.7008058023452759, "val_acc": 52.0}
{"epoch": 24, "training_loss": 0.7595873403549195, "training_acc": 46.0, "val_loss": 0.8260902500152588, "val_acc": 48.0}
{"epoch": 25, "training_loss": 1.1374544525146484, "training_acc": 48.0, "val_loss": 0.9310263800621033, "val_acc": 48.0}
{"epoch": 26, "training_loss": 0.9232898998260498, "training_acc": 48.0, "val_loss": 0.9597648096084594, "val_acc": 48.0}
{"epoch": 27, "training_loss": 0.8191437244415283, "training_acc": 52.0, "val_loss": 0.6968992877006531, "val_acc": 52.0}
{"epoch": 28, "training_loss": 0.915620493888855, "training_acc": 46.0, "val_loss": 0.7415883564949035, "val_acc": 52.0}
{"epoch": 29, "training_loss": 1.1163776779174805, "training_acc": 46.0, "val_loss": 2.131759510040283, "val_acc": 52.0}
{"epoch": 30, "training_loss": 2.1344711136817933, "training_acc": 50.0, "val_loss": 2.9229982471466065, "val_acc": 52.0}
{"epoch": 31, "training_loss": 1.503406891822815, "training_acc": 54.0, "val_loss": 1.3080626678466798, "val_acc": 48.0}
{"epoch": 32, "training_loss": 1.1517327404022217, "training_acc": 52.0, "val_loss": 1.3925249099731445, "val_acc": 52.0}
{"epoch": 33, "training_loss": 0.86914071559906, "training_acc": 52.0, "val_loss": 0.7390765023231506, "val_acc": 48.0}
{"epoch": 34, "training_loss": 0.7494511127471923, "training_acc": 48.0, "val_loss": 1.8784568691253662, "val_acc": 48.0}
{"epoch": 35, "training_loss": 1.5118986129760743, "training_acc": 50.0, "val_loss": 1.642503035068512, "val_acc": 48.0}
{"epoch": 36, "training_loss": 1.0296331357955932, "training_acc": 54.0, "val_loss": 1.5239696216583252, "val_acc": 52.0}
{"epoch": 37, "training_loss": 1.749203634262085, "training_acc": 42.0, "val_loss": 0.7116149640083314, "val_acc": 52.0}
{"epoch": 38, "training_loss": 0.8478834056854248, "training_acc": 42.0, "val_loss": 0.6924967098236084, "val_acc": 52.0}
{"epoch": 39, "training_loss": 1.3529670810699463, "training_acc": 54.0, "val_loss": 1.90302903175354, "val_acc": 52.0}
{"epoch": 40, "training_loss": 2.209149522781372, "training_acc": 46.0, "val_loss": 1.4931432294845581, "val_acc": 48.0}
{"epoch": 41, "training_loss": 2.078858528137207, "training_acc": 42.0, "val_loss": 2.358650093078613, "val_acc": 48.0}
{"epoch": 42, "training_loss": 1.777140121459961, "training_acc": 54.0, "val_loss": 0.8063455319404602, "val_acc": 52.0}
{"epoch": 43, "training_loss": 2.5126086235046388, "training_acc": 52.0, "val_loss": 1.5881966686248778, "val_acc": 48.0}
{"epoch": 44, "training_loss": 1.9237716817855834, "training_acc": 50.0, "val_loss": 2.6646154928207397, "val_acc": 52.0}
{"epoch": 45, "training_loss": 3.107432231903076, "training_acc": 54.0, "val_loss": 1.8775197601318359, "val_acc": 48.0}
{"epoch": 46, "training_loss": 3.5433331966400146, "training_acc": 52.0, "val_loss": 4.426630878448487, "val_acc": 48.0}
{"epoch": 47, "training_loss": 2.1030708575248718, "training_acc": 48.0, "val_loss": 1.1102284479141236, "val_acc": 52.0}
{"epoch": 48, "training_loss": 0.914636607170105, "training_acc": 60.0, "val_loss": 0.8437639164924622, "val_acc": 52.0}
{"epoch": 49, "training_loss": 0.6974731874465943, "training_acc": 56.0, "val_loss": 2.467663860321045, "val_acc": 48.0}
{"epoch": 50, "training_loss": 2.4470323944091796, "training_acc": 42.0, "val_loss": 0.7345102024078369, "val_acc": 48.0}
{"epoch": 51, "training_loss": 2.4158196687698363, "training_acc": 50.0, "val_loss": 1.0029066944122313, "val_acc": 52.0}
{"epoch": 52, "training_loss": 1.3464454340934753, "training_acc": 52.0, "val_loss": 0.7114732098579407, "val_acc": 52.0}
{"epoch": 53, "training_loss": 1.4516974067687989, "training_acc": 44.0, "val_loss": 0.9119595766067505, "val_acc": 48.0}
{"epoch": 54, "training_loss": 0.8928266549110413, "training_acc": 52.0, "val_loss": 1.677138991355896, "val_acc": 48.0}
{"epoch": 55, "training_loss": 1.103645782470703, "training_acc": 40.0, "val_loss": 1.1770825338363649, "val_acc": 48.0}
{"epoch": 56, "training_loss": 0.7443363809585571, "training_acc": 58.0, "val_loss": 0.7127862167358399, "val_acc": 48.0}
{"epoch": 57, "training_loss": 0.8499064636230469, "training_acc": 42.0, "val_loss": 1.0693701934814452, "val_acc": 52.0}
