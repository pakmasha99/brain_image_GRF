"main_modify.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 5 --task ADNI_sex --input_option yAware --learning_rate 1e-1 --batch_size 16 --weight_decay 1e-4 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 9.39380859375, "training_acc": 50.0, "val_loss": 2.1686568593978883, "val_acc": 48.0}
{"epoch": 1, "training_loss": 1.7952255010604858, "training_acc": 50.0, "val_loss": 0.7857776665687561, "val_acc": 52.0}
{"epoch": 2, "training_loss": 0.9474865341186524, "training_acc": 49.0, "val_loss": 0.6966444873809814, "val_acc": 48.0}
{"epoch": 3, "training_loss": 0.9273552513122558, "training_acc": 50.0, "val_loss": 1.7371235466003419, "val_acc": 52.0}
{"epoch": 4, "training_loss": 1.0183361101150512, "training_acc": 48.0, "val_loss": 1.0217171025276184, "val_acc": 52.0}
{"epoch": 5, "training_loss": 0.9412474918365479, "training_acc": 58.0, "val_loss": 0.9557401967048645, "val_acc": 48.0}
{"epoch": 6, "training_loss": 1.6659256553649902, "training_acc": 50.0, "val_loss": 2.8979765605926513, "val_acc": 52.0}
{"epoch": 7, "training_loss": 3.6196074295043945, "training_acc": 52.0, "val_loss": 2.6946721649169922, "val_acc": 48.0}
{"epoch": 8, "training_loss": 3.3915966160409154, "training_acc": 52.0, "val_loss": 4.979768333435058, "val_acc": 48.0}
{"epoch": 9, "training_loss": 2.8583232879638674, "training_acc": 52.0, "val_loss": 2.564604558944702, "val_acc": 48.0}
{"epoch": 10, "training_loss": 1.7869283485412597, "training_acc": 50.0, "val_loss": 0.6985502934455872, "val_acc": 48.0}
{"epoch": 11, "training_loss": 1.6416633057594299, "training_acc": 42.0, "val_loss": 1.392739815711975, "val_acc": 52.0}
{"epoch": 12, "training_loss": 2.0450353956222536, "training_acc": 42.0, "val_loss": 1.2759478759765626, "val_acc": 48.0}
{"epoch": 13, "training_loss": 1.2774268746376038, "training_acc": 54.0, "val_loss": 0.6962119245529175, "val_acc": 52.0}
{"epoch": 14, "training_loss": 1.0731245183944702, "training_acc": 40.0, "val_loss": 0.6947708821296692, "val_acc": 52.0}
{"epoch": 15, "training_loss": 0.8972919821739197, "training_acc": 48.0, "val_loss": 1.7567815971374512, "val_acc": 48.0}
{"epoch": 16, "training_loss": 1.7974854469299317, "training_acc": 48.0, "val_loss": 3.7778400993347168, "val_acc": 48.0}
{"epoch": 17, "training_loss": 1.5357903957366943, "training_acc": 46.0, "val_loss": 1.7971759128570557, "val_acc": 48.0}
{"epoch": 18, "training_loss": 1.1100918912887574, "training_acc": 52.0, "val_loss": 0.8672688746452332, "val_acc": 52.0}
{"epoch": 19, "training_loss": 0.7746404504776001, "training_acc": 50.0, "val_loss": 0.9240886068344116, "val_acc": 52.0}
{"epoch": 20, "training_loss": 0.8486122417449952, "training_acc": 48.0, "val_loss": 0.6923569631576538, "val_acc": 52.0}
{"epoch": 21, "training_loss": 0.9375074005126953, "training_acc": 54.0, "val_loss": 1.4597813129425048, "val_acc": 52.0}
{"epoch": 22, "training_loss": 1.2048918294906616, "training_acc": 50.0, "val_loss": 3.7671648502349853, "val_acc": 48.0}
{"epoch": 23, "training_loss": 2.7186012363433836, "training_acc": 50.0, "val_loss": 1.2745163679122924, "val_acc": 48.0}
{"epoch": 24, "training_loss": 0.8703295040130615, "training_acc": 46.0, "val_loss": 0.9745800924301148, "val_acc": 52.0}
{"epoch": 25, "training_loss": 1.1093948554992676, "training_acc": 48.0, "val_loss": 0.7260388159751892, "val_acc": 52.0}
{"epoch": 26, "training_loss": 1.1125092530250549, "training_acc": 40.0, "val_loss": 1.4749842166900635, "val_acc": 52.0}
{"epoch": 27, "training_loss": 1.7677166843414307, "training_acc": 40.0, "val_loss": 0.8219626569747924, "val_acc": 52.0}
{"epoch": 28, "training_loss": 1.1072489833831787, "training_acc": 58.0, "val_loss": 1.9446574354171753, "val_acc": 52.0}
{"epoch": 29, "training_loss": 1.340733242034912, "training_acc": 48.0, "val_loss": 1.5342432260513306, "val_acc": 48.0}
{"epoch": 30, "training_loss": 1.2851473426818847, "training_acc": 54.0, "val_loss": 2.443678407669067, "val_acc": 48.0}
{"epoch": 31, "training_loss": 2.4432988739013672, "training_acc": 42.0, "val_loss": 0.9501243495941162, "val_acc": 48.0}
{"epoch": 32, "training_loss": 1.9718402481079103, "training_acc": 56.0, "val_loss": 3.761903696060181, "val_acc": 48.0}
{"epoch": 33, "training_loss": 3.2915869522094727, "training_acc": 48.0, "val_loss": 1.5671346378326416, "val_acc": 48.0}
{"epoch": 34, "training_loss": 2.2365537071228028, "training_acc": 54.0, "val_loss": 1.972700777053833, "val_acc": 48.0}
{"epoch": 35, "training_loss": 2.1903152775764467, "training_acc": 46.0, "val_loss": 0.8928120017051697, "val_acc": 52.0}
{"epoch": 36, "training_loss": 0.8078228139877319, "training_acc": 42.0, "val_loss": 0.769502944946289, "val_acc": 48.0}
{"epoch": 37, "training_loss": 0.7672111797332763, "training_acc": 50.0, "val_loss": 0.922040867805481, "val_acc": 52.0}
{"epoch": 38, "training_loss": 0.8286860752105712, "training_acc": 52.0, "val_loss": 0.7872400236129761, "val_acc": 48.0}
{"epoch": 39, "training_loss": 0.8018313074111938, "training_acc": 54.0, "val_loss": 0.72859135389328, "val_acc": 52.0}
