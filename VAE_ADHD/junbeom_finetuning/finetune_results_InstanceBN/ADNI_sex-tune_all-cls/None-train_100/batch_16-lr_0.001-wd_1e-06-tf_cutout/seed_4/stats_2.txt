"main_modify.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 4 --task ADNI_sex --input_option yAware --learning_rate 1e-3 --batch_size 16 --weight_decay 1e-6 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 0.7105021715164185, "training_acc": 54.0, "val_loss": 0.694478805065155, "val_acc": 48.0}
{"epoch": 1, "training_loss": 0.7096441364288331, "training_acc": 44.0, "val_loss": 0.6925204586982727, "val_acc": 52.0}
{"epoch": 2, "training_loss": 0.7059839487075805, "training_acc": 46.0, "val_loss": 0.6941002678871154, "val_acc": 48.0}
{"epoch": 3, "training_loss": 0.6967650127410888, "training_acc": 52.0, "val_loss": 0.6937182879447937, "val_acc": 52.0}
{"epoch": 4, "training_loss": 0.6940617895126343, "training_acc": 50.0, "val_loss": 0.6987311267852783, "val_acc": 48.0}
{"epoch": 5, "training_loss": 0.7291197490692138, "training_acc": 50.0, "val_loss": 0.6924730610847473, "val_acc": 52.0}
{"epoch": 6, "training_loss": 0.7466572046279907, "training_acc": 50.0, "val_loss": 0.7021380352973938, "val_acc": 52.0}
{"epoch": 7, "training_loss": 0.7094168853759766, "training_acc": 46.0, "val_loss": 0.7034620308876037, "val_acc": 48.0}
{"epoch": 8, "training_loss": 0.6982619738578797, "training_acc": 50.0, "val_loss": 0.6924000191688537, "val_acc": 52.0}
{"epoch": 9, "training_loss": 0.6998747301101684, "training_acc": 48.0, "val_loss": 0.6934665060043335, "val_acc": 48.0}
{"epoch": 10, "training_loss": 0.698024172782898, "training_acc": 52.0, "val_loss": 0.6925104022026062, "val_acc": 52.0}
{"epoch": 11, "training_loss": 0.697634813785553, "training_acc": 46.0, "val_loss": 0.6954572868347167, "val_acc": 48.0}
{"epoch": 12, "training_loss": 0.7091377019882202, "training_acc": 38.0, "val_loss": 0.6948978281021119, "val_acc": 48.0}
{"epoch": 13, "training_loss": 0.6973154735565186, "training_acc": 50.0, "val_loss": 0.7042649269104004, "val_acc": 48.0}
{"epoch": 14, "training_loss": 0.7065766716003418, "training_acc": 50.0, "val_loss": 0.6961733174324035, "val_acc": 48.0}
{"epoch": 15, "training_loss": 0.7223738503456115, "training_acc": 42.0, "val_loss": 0.692931797504425, "val_acc": 52.0}
{"epoch": 16, "training_loss": 0.7009380722045898, "training_acc": 50.0, "val_loss": 0.7225911402702332, "val_acc": 48.0}
{"epoch": 17, "training_loss": 0.6973109102249145, "training_acc": 56.0, "val_loss": 0.6985904645919799, "val_acc": 52.0}
{"epoch": 18, "training_loss": 0.7070990490913391, "training_acc": 50.0, "val_loss": 0.6968109583854676, "val_acc": 52.0}
{"epoch": 19, "training_loss": 0.6977095890045166, "training_acc": 48.0, "val_loss": 0.6992121887207031, "val_acc": 48.0}
{"epoch": 20, "training_loss": 0.6970757246017456, "training_acc": 50.0, "val_loss": 0.6937470698356628, "val_acc": 48.0}
{"epoch": 21, "training_loss": 0.6957458114624023, "training_acc": 46.0, "val_loss": 0.6925298690795898, "val_acc": 52.0}
{"epoch": 22, "training_loss": 0.6978524875640869, "training_acc": 46.0, "val_loss": 0.6956605720520019, "val_acc": 48.0}
{"epoch": 23, "training_loss": 0.7037738490104676, "training_acc": 40.0, "val_loss": 0.692358558177948, "val_acc": 52.0}
{"epoch": 24, "training_loss": 0.6991105604171753, "training_acc": 44.0, "val_loss": 0.6961603689193726, "val_acc": 48.0}
{"epoch": 25, "training_loss": 0.7030321264266968, "training_acc": 50.0, "val_loss": 0.702155032157898, "val_acc": 48.0}
{"epoch": 26, "training_loss": 0.697931592464447, "training_acc": 50.0, "val_loss": 0.692939465045929, "val_acc": 52.0}
{"epoch": 27, "training_loss": 0.7050155973434449, "training_acc": 50.0, "val_loss": 0.7052138495445252, "val_acc": 52.0}
{"epoch": 28, "training_loss": 0.7130036354064941, "training_acc": 50.0, "val_loss": 0.6923687744140625, "val_acc": 52.0}
{"epoch": 29, "training_loss": 0.7300345087051392, "training_acc": 48.0, "val_loss": 0.7364935898780822, "val_acc": 48.0}
{"epoch": 30, "training_loss": 0.7040392994880676, "training_acc": 48.0, "val_loss": 0.6924151968955994, "val_acc": 52.0}
{"epoch": 31, "training_loss": 0.6958572936058044, "training_acc": 50.0, "val_loss": 0.6923849868774414, "val_acc": 52.0}
{"epoch": 32, "training_loss": 0.6992058801651001, "training_acc": 42.0, "val_loss": 0.6983551454544067, "val_acc": 48.0}
{"epoch": 33, "training_loss": 0.6971662497520447, "training_acc": 50.0, "val_loss": 0.6964563679695129, "val_acc": 48.0}
{"epoch": 34, "training_loss": 0.6969151735305786, "training_acc": 50.0, "val_loss": 0.6942080736160279, "val_acc": 48.0}
{"epoch": 35, "training_loss": 0.702793607711792, "training_acc": 50.0, "val_loss": 0.6924564838409424, "val_acc": 52.0}
{"epoch": 36, "training_loss": 0.7111907887458802, "training_acc": 50.0, "val_loss": 0.7020966362953186, "val_acc": 52.0}
{"epoch": 37, "training_loss": 0.70113116979599, "training_acc": 50.0, "val_loss": 0.6939062881469726, "val_acc": 48.0}
{"epoch": 38, "training_loss": 0.6907532930374145, "training_acc": 50.0, "val_loss": 0.7119732975959778, "val_acc": 48.0}
{"epoch": 39, "training_loss": 0.7072016811370849, "training_acc": 50.0, "val_loss": 0.6925992178916931, "val_acc": 52.0}
{"epoch": 40, "training_loss": 0.7009190726280212, "training_acc": 50.0, "val_loss": 0.6923865413665772, "val_acc": 52.0}
{"epoch": 41, "training_loss": 0.6946766614913941, "training_acc": 58.0, "val_loss": 0.7049202299118043, "val_acc": 48.0}
{"epoch": 42, "training_loss": 0.7056028747558594, "training_acc": 46.0, "val_loss": 0.6926080703735351, "val_acc": 52.0}
