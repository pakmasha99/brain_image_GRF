"main_modify.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 5 --task ADNI_sex --input_option yAware --learning_rate 1e-3 --batch_size 16 --weight_decay 1e-6 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 0.7017114400863648, "training_acc": 49.0, "val_loss": 0.6949566769599914, "val_acc": 48.0}
{"epoch": 1, "training_loss": 0.7025001239776612, "training_acc": 47.0, "val_loss": 0.7086998343467712, "val_acc": 48.0}
{"epoch": 2, "training_loss": 0.6954770040512085, "training_acc": 51.0, "val_loss": 0.6927035975456238, "val_acc": 52.0}
{"epoch": 3, "training_loss": 0.7101851081848145, "training_acc": 49.0, "val_loss": 0.6971098804473876, "val_acc": 48.0}
{"epoch": 4, "training_loss": 0.7124630188941956, "training_acc": 51.0, "val_loss": 0.6993304562568664, "val_acc": 52.0}
{"epoch": 5, "training_loss": 0.7022676968574524, "training_acc": 47.0, "val_loss": 0.7179367017745971, "val_acc": 48.0}
{"epoch": 6, "training_loss": 0.7127928400039673, "training_acc": 51.0, "val_loss": 0.6963808083534241, "val_acc": 48.0}
{"epoch": 7, "training_loss": 0.7085787320137024, "training_acc": 47.0, "val_loss": 0.692418966293335, "val_acc": 52.0}
{"epoch": 8, "training_loss": 0.6927344465255737, "training_acc": 53.0, "val_loss": 0.7093835306167603, "val_acc": 48.0}
{"epoch": 9, "training_loss": 0.7030780434608459, "training_acc": 47.0, "val_loss": 0.6927129364013672, "val_acc": 52.0}
{"epoch": 10, "training_loss": 0.6984626364707947, "training_acc": 45.0, "val_loss": 0.6934283947944642, "val_acc": 48.0}
{"epoch": 11, "training_loss": 0.6970904231071472, "training_acc": 49.0, "val_loss": 0.6926568007469177, "val_acc": 52.0}
{"epoch": 12, "training_loss": 0.7046792268753052, "training_acc": 49.0, "val_loss": 0.7103508520126343, "val_acc": 48.0}
{"epoch": 13, "training_loss": 0.7038619947433472, "training_acc": 51.0, "val_loss": 0.6924917507171631, "val_acc": 52.0}
{"epoch": 14, "training_loss": 0.6958369779586792, "training_acc": 49.0, "val_loss": 0.6935924673080445, "val_acc": 48.0}
{"epoch": 15, "training_loss": 0.7031518292427062, "training_acc": 37.0, "val_loss": 0.7017217087745666, "val_acc": 48.0}
{"epoch": 16, "training_loss": 0.7248648643493653, "training_acc": 51.0, "val_loss": 0.7047553658485413, "val_acc": 48.0}
{"epoch": 17, "training_loss": 0.6932902789115906, "training_acc": 53.0, "val_loss": 0.6945641207695007, "val_acc": 52.0}
{"epoch": 18, "training_loss": 0.7031142950057984, "training_acc": 47.0, "val_loss": 0.7047338891029358, "val_acc": 48.0}
{"epoch": 19, "training_loss": 0.7146571516990662, "training_acc": 45.0, "val_loss": 0.6937007856369019, "val_acc": 52.0}
{"epoch": 20, "training_loss": 0.6903063535690308, "training_acc": 53.0, "val_loss": 0.7083193325996399, "val_acc": 48.0}
{"epoch": 21, "training_loss": 0.7065511751174927, "training_acc": 51.0, "val_loss": 0.6975968217849732, "val_acc": 48.0}
{"epoch": 22, "training_loss": 0.7074923944473267, "training_acc": 45.0, "val_loss": 0.700732307434082, "val_acc": 52.0}
{"epoch": 23, "training_loss": 0.7103695797920228, "training_acc": 49.0, "val_loss": 0.6931734967231751, "val_acc": 48.0}
{"epoch": 24, "training_loss": 0.7146540355682373, "training_acc": 51.0, "val_loss": 0.7072661709785462, "val_acc": 48.0}
{"epoch": 25, "training_loss": 0.7163858366012573, "training_acc": 45.0, "val_loss": 0.7085539722442626, "val_acc": 52.0}
{"epoch": 26, "training_loss": 0.7213210964202881, "training_acc": 49.0, "val_loss": 0.6923882699012757, "val_acc": 52.0}
{"epoch": 27, "training_loss": 0.6981479048728942, "training_acc": 49.0, "val_loss": 0.6989913201332092, "val_acc": 48.0}
{"epoch": 28, "training_loss": 0.6978037786483765, "training_acc": 45.0, "val_loss": 0.692420244216919, "val_acc": 52.0}
{"epoch": 29, "training_loss": 0.6942816495895385, "training_acc": 49.0, "val_loss": 0.6933186984062195, "val_acc": 48.0}
{"epoch": 30, "training_loss": 0.6953796482086182, "training_acc": 51.0, "val_loss": 0.7001302218437195, "val_acc": 48.0}
{"epoch": 31, "training_loss": 0.6979667115211486, "training_acc": 51.0, "val_loss": 0.6973621010780334, "val_acc": 48.0}
{"epoch": 32, "training_loss": 0.697201464176178, "training_acc": 51.0, "val_loss": 0.6979546284675598, "val_acc": 48.0}
{"epoch": 33, "training_loss": 0.7008666563034057, "training_acc": 41.0, "val_loss": 0.6946623897552491, "val_acc": 48.0}
{"epoch": 34, "training_loss": 0.7229347467422486, "training_acc": 51.0, "val_loss": 0.7169860339164734, "val_acc": 48.0}
{"epoch": 35, "training_loss": 0.7203597021102905, "training_acc": 43.0, "val_loss": 0.7007632994651795, "val_acc": 52.0}
{"epoch": 36, "training_loss": 0.7032836866378784, "training_acc": 49.0, "val_loss": 0.6957172226905822, "val_acc": 48.0}
{"epoch": 37, "training_loss": 0.7052030873298645, "training_acc": 51.0, "val_loss": 0.7011121201515198, "val_acc": 48.0}
{"epoch": 38, "training_loss": 0.693652617931366, "training_acc": 53.0, "val_loss": 0.6961840391159058, "val_acc": 52.0}
{"epoch": 39, "training_loss": 0.7058147144317627, "training_acc": 49.0, "val_loss": 0.6927778339385986, "val_acc": 52.0}
{"epoch": 40, "training_loss": 0.6917155885696411, "training_acc": 51.0, "val_loss": 0.7016441679000854, "val_acc": 48.0}
{"epoch": 41, "training_loss": 0.6976367998123169, "training_acc": 51.0, "val_loss": 0.6955412817001343, "val_acc": 48.0}
{"epoch": 42, "training_loss": 0.6952757072448731, "training_acc": 49.0, "val_loss": 0.6923466944694519, "val_acc": 52.0}
{"epoch": 43, "training_loss": 0.703484308719635, "training_acc": 43.0, "val_loss": 0.6952266216278076, "val_acc": 48.0}
{"epoch": 44, "training_loss": 0.6967260885238648, "training_acc": 47.0, "val_loss": 0.6933354115486146, "val_acc": 48.0}
{"epoch": 45, "training_loss": 0.6954998207092286, "training_acc": 51.0, "val_loss": 0.7086103892326355, "val_acc": 48.0}
{"epoch": 46, "training_loss": 0.7081397867202759, "training_acc": 51.0, "val_loss": 0.6996465444564819, "val_acc": 48.0}
{"epoch": 47, "training_loss": 0.6975006747245789, "training_acc": 47.0, "val_loss": 0.6932062220573425, "val_acc": 48.0}
{"epoch": 48, "training_loss": 0.694133186340332, "training_acc": 43.0, "val_loss": 0.6998892283439636, "val_acc": 48.0}
{"epoch": 49, "training_loss": 0.7042728996276856, "training_acc": 51.0, "val_loss": 0.7061828184127807, "val_acc": 48.0}
{"epoch": 50, "training_loss": 0.7089142584800721, "training_acc": 51.0, "val_loss": 0.7059236860275269, "val_acc": 48.0}
{"epoch": 51, "training_loss": 0.6960290861129761, "training_acc": 47.0, "val_loss": 0.6927015686035156, "val_acc": 52.0}
{"epoch": 52, "training_loss": 0.7000939393043518, "training_acc": 45.0, "val_loss": 0.6932067489624023, "val_acc": 48.0}
{"epoch": 53, "training_loss": 0.6933563899993896, "training_acc": 55.0, "val_loss": 0.692817485332489, "val_acc": 52.0}
{"epoch": 54, "training_loss": 0.7004424166679383, "training_acc": 49.0, "val_loss": 0.6927017259597779, "val_acc": 52.0}
{"epoch": 55, "training_loss": 0.6895852088928223, "training_acc": 55.0, "val_loss": 0.7177358031272888, "val_acc": 48.0}
{"epoch": 56, "training_loss": 0.7241916465759277, "training_acc": 51.0, "val_loss": 0.7019304966926575, "val_acc": 48.0}
{"epoch": 57, "training_loss": 0.6936935758590699, "training_acc": 51.0, "val_loss": 0.6944682335853577, "val_acc": 52.0}
{"epoch": 58, "training_loss": 0.7031089878082275, "training_acc": 49.0, "val_loss": 0.692531840801239, "val_acc": 52.0}
{"epoch": 59, "training_loss": 0.6942428946495056, "training_acc": 49.0, "val_loss": 0.6960024356842041, "val_acc": 48.0}
{"epoch": 60, "training_loss": 0.7003821396827697, "training_acc": 51.0, "val_loss": 0.714580192565918, "val_acc": 48.0}
{"epoch": 61, "training_loss": 0.6994149923324585, "training_acc": 51.0, "val_loss": 0.6924272203445434, "val_acc": 52.0}
