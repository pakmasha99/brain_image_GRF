"main_modify.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 2 --task ADNI_sex --input_option yAware --learning_rate 1e-3 --batch_size 16 --weight_decay 1e-6 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 0.705713312625885, "training_acc": 50.0, "val_loss": 0.7066803002357482, "val_acc": 48.0}
{"epoch": 1, "training_loss": 0.7166205143928528, "training_acc": 52.0, "val_loss": 0.7000868320465088, "val_acc": 52.0}
{"epoch": 2, "training_loss": 0.7021480822563171, "training_acc": 52.0, "val_loss": 0.7149812746047973, "val_acc": 48.0}
{"epoch": 3, "training_loss": 0.7110370349884033, "training_acc": 50.0, "val_loss": 0.7012168431282043, "val_acc": 48.0}
{"epoch": 4, "training_loss": 0.699378046989441, "training_acc": 50.0, "val_loss": 0.6941799521446228, "val_acc": 48.0}
{"epoch": 5, "training_loss": 0.6960157346725464, "training_acc": 52.0, "val_loss": 0.6930499196052551, "val_acc": 52.0}
{"epoch": 6, "training_loss": 0.7180406999588013, "training_acc": 50.0, "val_loss": 0.6924318814277649, "val_acc": 52.0}
{"epoch": 7, "training_loss": 0.7036917972564697, "training_acc": 46.0, "val_loss": 0.6953470611572266, "val_acc": 48.0}
{"epoch": 8, "training_loss": 0.6983912992477417, "training_acc": 48.0, "val_loss": 0.6939440870285034, "val_acc": 52.0}
{"epoch": 9, "training_loss": 0.7006850242614746, "training_acc": 46.0, "val_loss": 0.6935873174667359, "val_acc": 48.0}
{"epoch": 10, "training_loss": 0.6951464748382569, "training_acc": 46.0, "val_loss": 0.692467188835144, "val_acc": 52.0}
{"epoch": 11, "training_loss": 0.6961097002029419, "training_acc": 50.0, "val_loss": 0.694644501209259, "val_acc": 48.0}
{"epoch": 12, "training_loss": 0.7002185988426208, "training_acc": 50.0, "val_loss": 0.7039464664459228, "val_acc": 48.0}
{"epoch": 13, "training_loss": 0.7148047518730164, "training_acc": 42.0, "val_loss": 0.6965196585655212, "val_acc": 52.0}
{"epoch": 14, "training_loss": 0.6919521760940551, "training_acc": 52.0, "val_loss": 0.7011741352081299, "val_acc": 48.0}
{"epoch": 15, "training_loss": 0.7057346868515014, "training_acc": 50.0, "val_loss": 0.7031254553794861, "val_acc": 48.0}
{"epoch": 16, "training_loss": 0.6967032480239869, "training_acc": 50.0, "val_loss": 0.6940026497840881, "val_acc": 52.0}
{"epoch": 17, "training_loss": 0.7011274385452271, "training_acc": 50.0, "val_loss": 0.693703429698944, "val_acc": 48.0}
{"epoch": 18, "training_loss": 0.7448116445541382, "training_acc": 50.0, "val_loss": 0.7152193784713745, "val_acc": 48.0}
{"epoch": 19, "training_loss": 0.7031893038749695, "training_acc": 52.0, "val_loss": 0.69515141248703, "val_acc": 52.0}
{"epoch": 20, "training_loss": 0.7046988296508789, "training_acc": 50.0, "val_loss": 0.6929598832130432, "val_acc": 52.0}
{"epoch": 21, "training_loss": 0.6974451470375062, "training_acc": 44.0, "val_loss": 0.6928037238121033, "val_acc": 52.0}
{"epoch": 22, "training_loss": 0.7115919876098633, "training_acc": 50.0, "val_loss": 0.6966737818717956, "val_acc": 52.0}
{"epoch": 23, "training_loss": 0.7171995449066162, "training_acc": 40.0, "val_loss": 0.7096183967590332, "val_acc": 48.0}
{"epoch": 24, "training_loss": 0.6964407539367676, "training_acc": 50.0, "val_loss": 0.6924278306961059, "val_acc": 52.0}
{"epoch": 25, "training_loss": 0.7015013599395752, "training_acc": 50.0, "val_loss": 0.6943530440330505, "val_acc": 52.0}
{"epoch": 26, "training_loss": 0.6915987634658813, "training_acc": 52.0, "val_loss": 0.7078939938545227, "val_acc": 48.0}
{"epoch": 27, "training_loss": 0.7057005167007446, "training_acc": 50.0, "val_loss": 0.6984833765029907, "val_acc": 48.0}
{"epoch": 28, "training_loss": 0.692979998588562, "training_acc": 50.0, "val_loss": 0.6924414753913879, "val_acc": 52.0}
{"epoch": 29, "training_loss": 0.6983500576019287, "training_acc": 50.0, "val_loss": 0.6928787183761597, "val_acc": 52.0}
{"epoch": 30, "training_loss": 0.6944782733917236, "training_acc": 50.0, "val_loss": 0.7035535407066346, "val_acc": 48.0}
{"epoch": 31, "training_loss": 0.6992183828353882, "training_acc": 50.0, "val_loss": 0.6925639033317565, "val_acc": 52.0}
{"epoch": 32, "training_loss": 0.6997153639793396, "training_acc": 50.0, "val_loss": 0.6929522299766541, "val_acc": 52.0}
{"epoch": 33, "training_loss": 0.6960504198074341, "training_acc": 48.0, "val_loss": 0.7093775987625122, "val_acc": 48.0}
{"epoch": 34, "training_loss": 0.7054991340637207, "training_acc": 50.0, "val_loss": 0.7041479969024658, "val_acc": 48.0}
{"epoch": 35, "training_loss": 0.700312328338623, "training_acc": 50.0, "val_loss": 0.694383614063263, "val_acc": 48.0}
{"epoch": 36, "training_loss": 0.7074223661422729, "training_acc": 42.0, "val_loss": 0.6929993176460266, "val_acc": 52.0}
{"epoch": 37, "training_loss": 0.7012627220153809, "training_acc": 42.0, "val_loss": 0.6924708938598633, "val_acc": 52.0}
{"epoch": 38, "training_loss": 0.692777042388916, "training_acc": 50.0, "val_loss": 0.6940877842903137, "val_acc": 52.0}
{"epoch": 39, "training_loss": 0.6934502291679382, "training_acc": 48.0, "val_loss": 0.695998661518097, "val_acc": 48.0}
{"epoch": 40, "training_loss": 0.6945029544830322, "training_acc": 50.0, "val_loss": 0.6934491801261902, "val_acc": 48.0}
{"epoch": 41, "training_loss": 0.6938723874092102, "training_acc": 50.0, "val_loss": 0.6927567982673645, "val_acc": 52.0}
{"epoch": 42, "training_loss": 0.6975049829483032, "training_acc": 50.0, "val_loss": 0.6929956603050232, "val_acc": 52.0}
{"epoch": 43, "training_loss": 0.6996813726425171, "training_acc": 46.0, "val_loss": 0.6952433085441589, "val_acc": 48.0}
