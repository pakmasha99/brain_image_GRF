"main_modify.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 6 --task ADNI_sex --input_option yAware --learning_rate 1e-3 --batch_size 16 --weight_decay 1e-4 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 0.7168650603294373, "training_acc": 44.0, "val_loss": 0.6949578189849853, "val_acc": 48.0}
{"epoch": 1, "training_loss": 0.7164364814758301, "training_acc": 44.0, "val_loss": 0.6989147853851319, "val_acc": 48.0}
{"epoch": 2, "training_loss": 0.7088120770454407, "training_acc": 44.0, "val_loss": 0.7002378487586975, "val_acc": 48.0}
{"epoch": 3, "training_loss": 0.7048608493804932, "training_acc": 42.0, "val_loss": 0.7043911337852478, "val_acc": 48.0}
{"epoch": 4, "training_loss": 0.7176907181739807, "training_acc": 50.0, "val_loss": 0.7078844952583313, "val_acc": 48.0}
{"epoch": 5, "training_loss": 0.7156166362762452, "training_acc": 40.0, "val_loss": 0.6933230304718018, "val_acc": 52.0}
{"epoch": 6, "training_loss": 0.6989188122749329, "training_acc": 46.0, "val_loss": 0.6932789349555969, "val_acc": 48.0}
{"epoch": 7, "training_loss": 0.6965217161178588, "training_acc": 48.0, "val_loss": 0.6923770070075989, "val_acc": 52.0}
{"epoch": 8, "training_loss": 0.6918212676048279, "training_acc": 52.0, "val_loss": 0.7037086963653565, "val_acc": 48.0}
{"epoch": 9, "training_loss": 0.7035994291305542, "training_acc": 50.0, "val_loss": 0.6973639988899231, "val_acc": 48.0}
{"epoch": 10, "training_loss": 0.7039145112037659, "training_acc": 52.0, "val_loss": 0.695363609790802, "val_acc": 52.0}
{"epoch": 11, "training_loss": 0.6949323606491089, "training_acc": 50.0, "val_loss": 0.6997843623161316, "val_acc": 48.0}
{"epoch": 12, "training_loss": 0.716322979927063, "training_acc": 50.0, "val_loss": 0.6964854907989502, "val_acc": 48.0}
{"epoch": 13, "training_loss": 0.7127467727661133, "training_acc": 46.0, "val_loss": 0.7071982979774475, "val_acc": 52.0}
{"epoch": 14, "training_loss": 0.6875137066841126, "training_acc": 54.0, "val_loss": 0.7155809903144836, "val_acc": 48.0}
{"epoch": 15, "training_loss": 0.7253830242156982, "training_acc": 50.0, "val_loss": 0.6985410046577454, "val_acc": 48.0}
{"epoch": 16, "training_loss": 0.7018857717514038, "training_acc": 44.0, "val_loss": 0.6927608132362366, "val_acc": 52.0}
{"epoch": 17, "training_loss": 0.6991179704666137, "training_acc": 48.0, "val_loss": 0.6963861894607544, "val_acc": 48.0}
{"epoch": 18, "training_loss": 0.6979583573341369, "training_acc": 50.0, "val_loss": 0.6924654912948608, "val_acc": 52.0}
{"epoch": 19, "training_loss": 0.7056349849700928, "training_acc": 40.0, "val_loss": 0.6948757123947144, "val_acc": 48.0}
{"epoch": 20, "training_loss": 0.6937541675567627, "training_acc": 48.0, "val_loss": 0.6936530685424804, "val_acc": 52.0}
{"epoch": 21, "training_loss": 0.7129136967658997, "training_acc": 50.0, "val_loss": 0.6952305603027343, "val_acc": 52.0}
{"epoch": 22, "training_loss": 0.7059986448287964, "training_acc": 46.0, "val_loss": 0.7110682392120361, "val_acc": 48.0}
{"epoch": 23, "training_loss": 0.705293402671814, "training_acc": 44.0, "val_loss": 0.6923520398139954, "val_acc": 52.0}
{"epoch": 24, "training_loss": 0.7024196147918701, "training_acc": 50.0, "val_loss": 0.6924031305313111, "val_acc": 52.0}
{"epoch": 25, "training_loss": 0.7008143854141236, "training_acc": 46.0, "val_loss": 0.7008816885948181, "val_acc": 48.0}
{"epoch": 26, "training_loss": 0.7042947483062744, "training_acc": 44.0, "val_loss": 0.6927224802970886, "val_acc": 52.0}
{"epoch": 27, "training_loss": 0.6996840000152588, "training_acc": 50.0, "val_loss": 0.6932882404327393, "val_acc": 48.0}
{"epoch": 28, "training_loss": 0.6985474824905396, "training_acc": 50.0, "val_loss": 0.7168032956123352, "val_acc": 48.0}
{"epoch": 29, "training_loss": 0.7060240483283997, "training_acc": 50.0, "val_loss": 0.6935992455482483, "val_acc": 48.0}
{"epoch": 30, "training_loss": 0.6980002236366272, "training_acc": 52.0, "val_loss": 0.6958284568786621, "val_acc": 52.0}
{"epoch": 31, "training_loss": 0.6892399120330811, "training_acc": 52.0, "val_loss": 0.7029779839515686, "val_acc": 48.0}
{"epoch": 32, "training_loss": 0.7055837225914001, "training_acc": 50.0, "val_loss": 0.7072098922729492, "val_acc": 48.0}
{"epoch": 33, "training_loss": 0.7018232917785645, "training_acc": 48.0, "val_loss": 0.692369532585144, "val_acc": 52.0}
{"epoch": 34, "training_loss": 0.6989890193939209, "training_acc": 46.0, "val_loss": 0.6983094334602356, "val_acc": 48.0}
{"epoch": 35, "training_loss": 0.7016780471801758, "training_acc": 44.0, "val_loss": 0.6923703694343567, "val_acc": 52.0}
{"epoch": 36, "training_loss": 0.6983087348937989, "training_acc": 50.0, "val_loss": 0.6932844853401184, "val_acc": 52.0}
{"epoch": 37, "training_loss": 0.6967524766921998, "training_acc": 48.0, "val_loss": 0.694940333366394, "val_acc": 48.0}
{"epoch": 38, "training_loss": 0.6984172821044922, "training_acc": 40.0, "val_loss": 0.6935083746910096, "val_acc": 48.0}
{"epoch": 39, "training_loss": 0.6963541412353516, "training_acc": 46.0, "val_loss": 0.6972340250015259, "val_acc": 48.0}
{"epoch": 40, "training_loss": 0.7066787910461426, "training_acc": 50.0, "val_loss": 0.6924087524414062, "val_acc": 52.0}
{"epoch": 41, "training_loss": 0.6982705664634704, "training_acc": 50.0, "val_loss": 0.7118112230300904, "val_acc": 52.0}
{"epoch": 42, "training_loss": 0.7249893712997436, "training_acc": 50.0, "val_loss": 0.6924248290061951, "val_acc": 52.0}
