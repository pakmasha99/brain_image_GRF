"main_modify.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 3 --task ADNI_sex --input_option yAware --learning_rate 1e-1 --batch_size 16 --weight_decay 1e-2 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 8.266955369114875, "training_acc": 55.0, "val_loss": 5.153373756408691, "val_acc": 48.0}
{"epoch": 1, "training_loss": 2.9639086723327637, "training_acc": 55.0, "val_loss": 1.084715151786804, "val_acc": 52.0}
{"epoch": 2, "training_loss": 2.931260750498623, "training_acc": 47.0, "val_loss": 4.919286422729492, "val_acc": 48.0}
{"epoch": 3, "training_loss": 2.359342179298401, "training_acc": 55.0, "val_loss": 0.7586864662170411, "val_acc": 48.0}
{"epoch": 4, "training_loss": 0.9745424973964691, "training_acc": 53.0, "val_loss": 3.220016222000122, "val_acc": 48.0}
{"epoch": 5, "training_loss": 2.1531592178344727, "training_acc": 47.0, "val_loss": 1.14537540435791, "val_acc": 52.0}
{"epoch": 6, "training_loss": 1.078012342453003, "training_acc": 55.0, "val_loss": 0.8057031941413879, "val_acc": 52.0}
{"epoch": 7, "training_loss": 0.8860966563224792, "training_acc": 49.0, "val_loss": 1.1543035173416138, "val_acc": 48.0}
{"epoch": 8, "training_loss": 1.3877561950683595, "training_acc": 53.0, "val_loss": 1.2183379101753236, "val_acc": 48.0}
{"epoch": 9, "training_loss": 0.8552955150604248, "training_acc": 55.0, "val_loss": 0.911443247795105, "val_acc": 52.0}
{"epoch": 10, "training_loss": 1.5817412662506103, "training_acc": 49.0, "val_loss": 1.199857053756714, "val_acc": 52.0}
{"epoch": 11, "training_loss": 0.9553267359733582, "training_acc": 51.0, "val_loss": 2.4325217628479003, "val_acc": 52.0}
{"epoch": 12, "training_loss": 1.9910175275802613, "training_acc": 47.0, "val_loss": 1.132869701385498, "val_acc": 48.0}
{"epoch": 13, "training_loss": 0.997663369178772, "training_acc": 47.0, "val_loss": 2.0777732849121096, "val_acc": 52.0}
{"epoch": 14, "training_loss": 1.2032387590408324, "training_acc": 47.0, "val_loss": 1.291597466468811, "val_acc": 52.0}
{"epoch": 15, "training_loss": 1.136455430984497, "training_acc": 53.0, "val_loss": 0.7067825603485107, "val_acc": 48.0}
{"epoch": 16, "training_loss": 1.3252548885345459, "training_acc": 51.0, "val_loss": 3.5364750099182127, "val_acc": 52.0}
{"epoch": 17, "training_loss": 3.223202705383301, "training_acc": 47.0, "val_loss": 3.822888946533203, "val_acc": 52.0}
{"epoch": 18, "training_loss": 3.056181173324585, "training_acc": 49.0, "val_loss": 3.104230489730835, "val_acc": 52.0}
{"epoch": 19, "training_loss": 2.4931604862213135, "training_acc": 55.0, "val_loss": 4.312714233398437, "val_acc": 52.0}
{"epoch": 20, "training_loss": 3.6362544536590575, "training_acc": 45.0, "val_loss": 0.7762858247756959, "val_acc": 52.0}
{"epoch": 21, "training_loss": 1.4701177644729615, "training_acc": 57.0, "val_loss": 1.2058945655822755, "val_acc": 52.0}
{"epoch": 22, "training_loss": 0.9549334707856179, "training_acc": 59.0, "val_loss": 3.603837671279907, "val_acc": 48.0}
{"epoch": 23, "training_loss": 2.2435291528701784, "training_acc": 43.0, "val_loss": 0.9854358768463135, "val_acc": 48.0}
{"epoch": 24, "training_loss": 0.758018159866333, "training_acc": 51.0, "val_loss": 1.444169626235962, "val_acc": 52.0}
{"epoch": 25, "training_loss": 0.9505578184127808, "training_acc": 53.0, "val_loss": 1.8820939540863038, "val_acc": 52.0}
{"epoch": 26, "training_loss": 1.2945328426361085, "training_acc": 51.0, "val_loss": 3.0094940853118897, "val_acc": 48.0}
{"epoch": 27, "training_loss": 2.0456027714163065, "training_acc": 53.0, "val_loss": 3.8951479721069338, "val_acc": 48.0}
{"epoch": 28, "training_loss": 2.50249463558197, "training_acc": 57.0, "val_loss": 1.8562933444976806, "val_acc": 52.0}
{"epoch": 29, "training_loss": 0.9632405376434326, "training_acc": 53.0, "val_loss": 1.1847992706298829, "val_acc": 52.0}
{"epoch": 30, "training_loss": 1.3429344010353088, "training_acc": 43.0, "val_loss": 1.9629818773269654, "val_acc": 52.0}
{"epoch": 31, "training_loss": 1.1359381914138793, "training_acc": 47.0, "val_loss": 0.6974860334396362, "val_acc": 48.0}
{"epoch": 32, "training_loss": 1.314868950843811, "training_acc": 55.0, "val_loss": 1.2905919313430787, "val_acc": 52.0}
{"epoch": 33, "training_loss": 1.1302232837677002, "training_acc": 47.0, "val_loss": 1.8481285524368287, "val_acc": 52.0}
{"epoch": 34, "training_loss": 1.2311946249008179, "training_acc": 59.0, "val_loss": 0.8555573987960815, "val_acc": 48.0}
{"epoch": 35, "training_loss": 1.1444676780700684, "training_acc": 51.0, "val_loss": 0.7336412954330445, "val_acc": 52.0}
{"epoch": 36, "training_loss": 1.2556464767456055, "training_acc": 47.0, "val_loss": 0.9644730424880982, "val_acc": 52.0}
{"epoch": 37, "training_loss": 0.8499860095977784, "training_acc": 55.0, "val_loss": 1.3689284563064574, "val_acc": 48.0}
{"epoch": 38, "training_loss": 1.015530776977539, "training_acc": 49.0, "val_loss": 3.8070014762878417, "val_acc": 48.0}
{"epoch": 39, "training_loss": 2.7302096319198608, "training_acc": 37.0, "val_loss": 0.7101991391181945, "val_acc": 48.0}
{"epoch": 40, "training_loss": 1.0012086391448975, "training_acc": 55.0, "val_loss": 0.7343671178817749, "val_acc": 52.0}
{"epoch": 41, "training_loss": 1.0804421091079712, "training_acc": 51.0, "val_loss": 1.626146478652954, "val_acc": 52.0}
{"epoch": 42, "training_loss": 1.4753120183944701, "training_acc": 53.0, "val_loss": 1.7066936540603637, "val_acc": 48.0}
{"epoch": 43, "training_loss": 1.875829873085022, "training_acc": 47.0, "val_loss": 2.0956919956207276, "val_acc": 52.0}
{"epoch": 44, "training_loss": 1.9051270198822021, "training_acc": 45.0, "val_loss": 1.8378596448898314, "val_acc": 48.0}
{"epoch": 45, "training_loss": 1.15918110370636, "training_acc": 49.0, "val_loss": 2.1225024890899657, "val_acc": 48.0}
{"epoch": 46, "training_loss": 1.279665789604187, "training_acc": 51.0, "val_loss": 0.8318668341636658, "val_acc": 48.0}
{"epoch": 47, "training_loss": 0.7816108131408691, "training_acc": 55.0, "val_loss": 1.2758104228973388, "val_acc": 48.0}
{"epoch": 48, "training_loss": 1.0932928657531737, "training_acc": 49.0, "val_loss": 1.1173073720932007, "val_acc": 48.0}
{"epoch": 49, "training_loss": 1.2232659435272217, "training_acc": 53.0, "val_loss": 2.1059977769851685, "val_acc": 52.0}
{"epoch": 50, "training_loss": 1.6674557209014893, "training_acc": 49.0, "val_loss": 1.6573713874816896, "val_acc": 48.0}
