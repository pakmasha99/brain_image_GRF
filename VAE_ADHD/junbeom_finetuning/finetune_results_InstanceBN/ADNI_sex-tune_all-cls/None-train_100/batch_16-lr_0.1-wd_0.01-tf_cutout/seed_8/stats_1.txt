"main_modify.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 8 --task ADNI_sex --input_option yAware --learning_rate 1e-1 --batch_size 16 --weight_decay 1e-2 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 7.687600212097168, "training_acc": 41.0, "val_loss": 1.765597095489502, "val_acc": 48.0}
{"epoch": 1, "training_loss": 3.98012336730957, "training_acc": 41.0, "val_loss": 1.9239726972579956, "val_acc": 48.0}
{"epoch": 2, "training_loss": 3.190580520629883, "training_acc": 51.0, "val_loss": 1.5554824542999268, "val_acc": 48.0}
{"epoch": 3, "training_loss": 1.989840784072876, "training_acc": 41.0, "val_loss": 3.213156614303589, "val_acc": 52.0}
{"epoch": 4, "training_loss": 2.041682686805725, "training_acc": 51.0, "val_loss": 0.8841436100006104, "val_acc": 52.0}
{"epoch": 5, "training_loss": 0.966934461593628, "training_acc": 53.0, "val_loss": 0.9739842653274536, "val_acc": 52.0}
{"epoch": 6, "training_loss": 0.8109313225746155, "training_acc": 53.0, "val_loss": 2.296628017425537, "val_acc": 48.0}
{"epoch": 7, "training_loss": 2.3924927520751953, "training_acc": 45.0, "val_loss": 2.4315356159210206, "val_acc": 48.0}
{"epoch": 8, "training_loss": 2.289520945549011, "training_acc": 47.0, "val_loss": 0.9748091220855712, "val_acc": 48.0}
{"epoch": 9, "training_loss": 1.117622537612915, "training_acc": 39.0, "val_loss": 1.6450880575180054, "val_acc": 48.0}
{"epoch": 10, "training_loss": 1.6694687414169311, "training_acc": 53.0, "val_loss": 1.2204921007156373, "val_acc": 48.0}
{"epoch": 11, "training_loss": 1.1748802709579467, "training_acc": 55.0, "val_loss": 1.1006649541854858, "val_acc": 52.0}
{"epoch": 12, "training_loss": 0.9413976454734803, "training_acc": 49.0, "val_loss": 0.7016927456855774, "val_acc": 48.0}
{"epoch": 13, "training_loss": 0.7914570927619934, "training_acc": 49.0, "val_loss": 1.3733670902252197, "val_acc": 52.0}
{"epoch": 14, "training_loss": 1.8463358616828918, "training_acc": 51.0, "val_loss": 1.7148950719833373, "val_acc": 48.0}
{"epoch": 15, "training_loss": 0.9190685558319092, "training_acc": 55.0, "val_loss": 0.705551540851593, "val_acc": 52.0}
{"epoch": 16, "training_loss": 1.2724672031402589, "training_acc": 41.0, "val_loss": 0.9358519458770752, "val_acc": 48.0}
{"epoch": 17, "training_loss": 1.2380012059211731, "training_acc": 47.0, "val_loss": 2.412216958999634, "val_acc": 52.0}
{"epoch": 18, "training_loss": 2.2078679847717284, "training_acc": 45.0, "val_loss": 0.9382181692123414, "val_acc": 48.0}
{"epoch": 19, "training_loss": 2.5012771606445314, "training_acc": 41.0, "val_loss": 7.759346237182617, "val_acc": 48.0}
{"epoch": 20, "training_loss": 4.665131406784058, "training_acc": 57.0, "val_loss": 3.7820842361450193, "val_acc": 52.0}
{"epoch": 21, "training_loss": 2.758179111480713, "training_acc": 51.0, "val_loss": 4.637090511322022, "val_acc": 52.0}
{"epoch": 22, "training_loss": 2.594806489944458, "training_acc": 53.0, "val_loss": 4.442622299194336, "val_acc": 52.0}
{"epoch": 23, "training_loss": 2.8010323429107666, "training_acc": 41.0, "val_loss": 2.041535177230835, "val_acc": 48.0}
{"epoch": 24, "training_loss": 2.0960801887512206, "training_acc": 49.0, "val_loss": 1.3189890193939209, "val_acc": 48.0}
{"epoch": 25, "training_loss": 1.608022391796112, "training_acc": 45.0, "val_loss": 0.7053319931030273, "val_acc": 48.0}
{"epoch": 26, "training_loss": 0.7727105760574341, "training_acc": 49.0, "val_loss": 0.6923649191856385, "val_acc": 52.0}
{"epoch": 27, "training_loss": 0.8480082654953003, "training_acc": 51.0, "val_loss": 0.6924362540245056, "val_acc": 52.0}
{"epoch": 28, "training_loss": 1.1664490413665771, "training_acc": 41.0, "val_loss": 0.7376576137542724, "val_acc": 52.0}
{"epoch": 29, "training_loss": 1.144906828403473, "training_acc": 43.0, "val_loss": 0.6973653841018677, "val_acc": 52.0}
{"epoch": 30, "training_loss": 1.0005186700820923, "training_acc": 41.0, "val_loss": 0.7473490738868713, "val_acc": 48.0}
{"epoch": 31, "training_loss": 1.1050111693143845, "training_acc": 51.0, "val_loss": 1.179835684299469, "val_acc": 48.0}
{"epoch": 32, "training_loss": 1.440953631401062, "training_acc": 49.0, "val_loss": 0.9485644006729126, "val_acc": 52.0}
{"epoch": 33, "training_loss": 0.809524393081665, "training_acc": 55.0, "val_loss": 1.4054629969596864, "val_acc": 52.0}
{"epoch": 34, "training_loss": 1.2218172121047974, "training_acc": 45.0, "val_loss": 1.9755049800872804, "val_acc": 52.0}
{"epoch": 35, "training_loss": 1.5125755834579468, "training_acc": 47.0, "val_loss": 0.995527491569519, "val_acc": 48.0}
{"epoch": 36, "training_loss": 1.2844440031051636, "training_acc": 57.0, "val_loss": 1.835180368423462, "val_acc": 52.0}
{"epoch": 37, "training_loss": 2.4633904504776, "training_acc": 57.0, "val_loss": 1.9566627407073975, "val_acc": 52.0}
{"epoch": 38, "training_loss": 1.9635219383239746, "training_acc": 43.0, "val_loss": 2.6877083206176757, "val_acc": 48.0}
{"epoch": 39, "training_loss": 2.4990865802764892, "training_acc": 45.0, "val_loss": 1.989454412460327, "val_acc": 48.0}
{"epoch": 40, "training_loss": 0.9667577171325683, "training_acc": 51.0, "val_loss": 0.7748106122016907, "val_acc": 48.0}
{"epoch": 41, "training_loss": 1.1736647844314576, "training_acc": 43.0, "val_loss": 0.9755379128456115, "val_acc": 52.0}
{"epoch": 42, "training_loss": 0.7811539816856384, "training_acc": 49.0, "val_loss": 1.627540292739868, "val_acc": 48.0}
{"epoch": 43, "training_loss": 1.264593515396118, "training_acc": 43.0, "val_loss": 1.349034732580185, "val_acc": 52.0}
{"epoch": 44, "training_loss": 1.216987977027893, "training_acc": 43.0, "val_loss": 0.7619493436813355, "val_acc": 48.0}
{"epoch": 45, "training_loss": 1.0608101844787599, "training_acc": 53.0, "val_loss": 2.6838014936447143, "val_acc": 52.0}
