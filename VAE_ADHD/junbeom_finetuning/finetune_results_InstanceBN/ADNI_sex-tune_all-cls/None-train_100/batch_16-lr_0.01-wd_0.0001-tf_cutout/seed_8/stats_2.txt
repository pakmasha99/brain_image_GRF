"main_modify.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 8 --task ADNI_sex --input_option yAware --learning_rate 1e-2 --batch_size 16 --weight_decay 1e-4 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 1.1389665031433105, "training_acc": 54.0, "val_loss": 0.7055617570877075, "val_acc": 48.0}
{"epoch": 1, "training_loss": 0.9870121097564697, "training_acc": 50.0, "val_loss": 0.8029357814788818, "val_acc": 52.0}
{"epoch": 2, "training_loss": 0.8484587335586548, "training_acc": 44.0, "val_loss": 0.7428775000572204, "val_acc": 52.0}
{"epoch": 3, "training_loss": 0.7700271415710449, "training_acc": 52.0, "val_loss": 0.7210910820960998, "val_acc": 48.0}
{"epoch": 4, "training_loss": 0.7143587136268615, "training_acc": 46.0, "val_loss": 0.6963719940185547, "val_acc": 48.0}
{"epoch": 5, "training_loss": 0.7318105363845825, "training_acc": 50.0, "val_loss": 0.8274239349365234, "val_acc": 52.0}
{"epoch": 6, "training_loss": 0.7924371671676635, "training_acc": 54.0, "val_loss": 0.8942878794670105, "val_acc": 48.0}
{"epoch": 7, "training_loss": 0.726304337978363, "training_acc": 54.0, "val_loss": 0.7937740421295166, "val_acc": 52.0}
{"epoch": 8, "training_loss": 0.7763367700576782, "training_acc": 40.0, "val_loss": 0.7315805387496949, "val_acc": 48.0}
{"epoch": 9, "training_loss": 0.7457208776473999, "training_acc": 50.0, "val_loss": 0.6930798387527466, "val_acc": 52.0}
{"epoch": 10, "training_loss": 0.7467903709411621, "training_acc": 48.0, "val_loss": 0.7879895305633545, "val_acc": 52.0}
{"epoch": 11, "training_loss": 0.7258928728103637, "training_acc": 52.0, "val_loss": 0.8394759488105774, "val_acc": 48.0}
{"epoch": 12, "training_loss": 0.708601450920105, "training_acc": 56.0, "val_loss": 0.7684505772590637, "val_acc": 52.0}
{"epoch": 13, "training_loss": 0.7533983302116394, "training_acc": 44.0, "val_loss": 0.6953688097000122, "val_acc": 48.0}
{"epoch": 14, "training_loss": 0.7099416851997375, "training_acc": 48.0, "val_loss": 0.7508065438270569, "val_acc": 52.0}
{"epoch": 15, "training_loss": 0.7670913267135621, "training_acc": 44.0, "val_loss": 0.7001376295089722, "val_acc": 52.0}
{"epoch": 16, "training_loss": 0.7452105355262756, "training_acc": 48.0, "val_loss": 0.6924313092231751, "val_acc": 52.0}
{"epoch": 17, "training_loss": 0.7206081080436707, "training_acc": 46.0, "val_loss": 0.6918573665618897, "val_acc": 52.0}
{"epoch": 18, "training_loss": 0.7055399060249329, "training_acc": 49.0, "val_loss": 0.7552328538894654, "val_acc": 48.0}
{"epoch": 19, "training_loss": 0.7487056422233581, "training_acc": 48.0, "val_loss": 0.6963594222068786, "val_acc": 52.0}
{"epoch": 20, "training_loss": 0.7029289603233337, "training_acc": 52.0, "val_loss": 0.6965198111534119, "val_acc": 48.0}
{"epoch": 21, "training_loss": 0.7457638025283814, "training_acc": 48.0, "val_loss": 0.7144590711593628, "val_acc": 48.0}
{"epoch": 22, "training_loss": 0.7290036273002625, "training_acc": 44.0, "val_loss": 0.7527311301231384, "val_acc": 48.0}
{"epoch": 23, "training_loss": 0.7548624110221863, "training_acc": 44.0, "val_loss": 0.8814988136291504, "val_acc": 48.0}
{"epoch": 24, "training_loss": 0.8080978918075562, "training_acc": 48.0, "val_loss": 0.7330220818519593, "val_acc": 52.0}
{"epoch": 25, "training_loss": 0.7630362701416016, "training_acc": 44.0, "val_loss": 0.7013910794258118, "val_acc": 52.0}
{"epoch": 26, "training_loss": 0.7377637481689453, "training_acc": 48.0, "val_loss": 0.6921347451210021, "val_acc": 52.0}
{"epoch": 27, "training_loss": 0.7004381561279297, "training_acc": 48.0, "val_loss": 0.6918805646896362, "val_acc": 52.0}
{"epoch": 28, "training_loss": 0.7309721183776855, "training_acc": 42.0, "val_loss": 0.696469337940216, "val_acc": 52.0}
{"epoch": 29, "training_loss": 0.7243335962295532, "training_acc": 40.0, "val_loss": 0.7369622087478638, "val_acc": 48.0}
{"epoch": 30, "training_loss": 0.7290528726577759, "training_acc": 42.0, "val_loss": 0.7880474138259888, "val_acc": 48.0}
{"epoch": 31, "training_loss": 0.7917573738098145, "training_acc": 56.0, "val_loss": 0.7225614953041076, "val_acc": 52.0}
{"epoch": 32, "training_loss": 0.7545152807235718, "training_acc": 52.0, "val_loss": 0.6915049219131469, "val_acc": 60.0}
{"epoch": 33, "training_loss": 0.7006392097473144, "training_acc": 53.0, "val_loss": 0.8250661063194275, "val_acc": 52.0}
{"epoch": 34, "training_loss": 0.8179274129867554, "training_acc": 50.0, "val_loss": 0.7384957456588745, "val_acc": 48.0}
{"epoch": 35, "training_loss": 0.7506939792633056, "training_acc": 52.0, "val_loss": 0.7515772294998169, "val_acc": 48.0}
{"epoch": 36, "training_loss": 0.7348076701164246, "training_acc": 48.0, "val_loss": 0.7076432991027832, "val_acc": 52.0}
{"epoch": 37, "training_loss": 0.7414658331871032, "training_acc": 52.0, "val_loss": 0.6940464377403259, "val_acc": 52.0}
{"epoch": 38, "training_loss": 0.7138881587982178, "training_acc": 54.0, "val_loss": 0.7918057751655578, "val_acc": 48.0}
{"epoch": 39, "training_loss": 0.7714744997024536, "training_acc": 46.0, "val_loss": 0.7753452038764954, "val_acc": 48.0}
{"epoch": 40, "training_loss": 0.7144417190551757, "training_acc": 56.0, "val_loss": 0.8142911505699157, "val_acc": 52.0}
{"epoch": 41, "training_loss": 0.9690880393981933, "training_acc": 50.0, "val_loss": 0.8705529117584229, "val_acc": 48.0}
{"epoch": 42, "training_loss": 0.7944904899597168, "training_acc": 50.0, "val_loss": 0.7205759859085084, "val_acc": 48.0}
{"epoch": 43, "training_loss": 0.7821118640899658, "training_acc": 44.0, "val_loss": 0.7187929630279541, "val_acc": 52.0}
{"epoch": 44, "training_loss": 0.7351810407638549, "training_acc": 42.0, "val_loss": 0.692815306186676, "val_acc": 52.0}
{"epoch": 45, "training_loss": 0.7270847749710083, "training_acc": 50.0, "val_loss": 0.7471815896034241, "val_acc": 52.0}
{"epoch": 46, "training_loss": 0.8272364282608032, "training_acc": 54.0, "val_loss": 0.9846884274482727, "val_acc": 48.0}
{"epoch": 47, "training_loss": 0.7918026256561279, "training_acc": 52.0, "val_loss": 0.8645122241973877, "val_acc": 52.0}
{"epoch": 48, "training_loss": 0.830991439819336, "training_acc": 48.0, "val_loss": 0.6996605420112609, "val_acc": 48.0}
{"epoch": 49, "training_loss": 0.6963186764717102, "training_acc": 52.0, "val_loss": 0.6993410181999207, "val_acc": 52.0}
{"epoch": 50, "training_loss": 0.7345018672943116, "training_acc": 48.0, "val_loss": 0.8893294930458069, "val_acc": 52.0}
{"epoch": 51, "training_loss": 0.9536767387390137, "training_acc": 48.0, "val_loss": 0.7610054278373718, "val_acc": 48.0}
