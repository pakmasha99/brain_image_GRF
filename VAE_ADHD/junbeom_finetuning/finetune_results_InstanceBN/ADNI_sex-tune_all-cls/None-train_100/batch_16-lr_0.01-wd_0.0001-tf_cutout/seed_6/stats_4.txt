"main_modify.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 6 --task ADNI_sex --input_option yAware --learning_rate 1e-2 --batch_size 16 --weight_decay 1e-4 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 1.1973567748069762, "training_acc": 48.0, "val_loss": 0.7842742943763733, "val_acc": 48.0}
{"epoch": 1, "training_loss": 0.7400449800491333, "training_acc": 44.0, "val_loss": 0.6944586133956909, "val_acc": 48.0}
{"epoch": 2, "training_loss": 0.6979487562179565, "training_acc": 48.0, "val_loss": 0.6931107521057129, "val_acc": 52.0}
{"epoch": 3, "training_loss": 0.7613217878341675, "training_acc": 48.0, "val_loss": 0.6923409199714661, "val_acc": 52.0}
{"epoch": 4, "training_loss": 0.7375895857810975, "training_acc": 54.0, "val_loss": 0.7479735612869263, "val_acc": 48.0}
{"epoch": 5, "training_loss": 0.7393063926696777, "training_acc": 50.0, "val_loss": 0.7778432393074035, "val_acc": 48.0}
{"epoch": 6, "training_loss": 0.7139238166809082, "training_acc": 54.0, "val_loss": 0.6923897814750671, "val_acc": 52.0}
{"epoch": 7, "training_loss": 0.7281726408004761, "training_acc": 54.0, "val_loss": 0.9097452712059021, "val_acc": 52.0}
{"epoch": 8, "training_loss": 0.8013574075698853, "training_acc": 48.0, "val_loss": 0.6998983693122863, "val_acc": 48.0}
{"epoch": 9, "training_loss": 0.712597484588623, "training_acc": 46.0, "val_loss": 0.6919475269317626, "val_acc": 52.0}
{"epoch": 10, "training_loss": 0.754927487373352, "training_acc": 46.0, "val_loss": 0.8226963901519775, "val_acc": 52.0}
{"epoch": 11, "training_loss": 0.8739235091209412, "training_acc": 48.0, "val_loss": 0.7483109211921692, "val_acc": 48.0}
{"epoch": 12, "training_loss": 0.7286532831192016, "training_acc": 52.0, "val_loss": 0.9072175931930542, "val_acc": 48.0}
{"epoch": 13, "training_loss": 0.8870093059539795, "training_acc": 50.0, "val_loss": 0.6934969210624695, "val_acc": 48.0}
{"epoch": 14, "training_loss": 0.9697720909118652, "training_acc": 50.0, "val_loss": 0.9580591607093811, "val_acc": 52.0}
{"epoch": 15, "training_loss": 0.8279581022262573, "training_acc": 46.0, "val_loss": 0.7362128877639771, "val_acc": 48.0}
{"epoch": 16, "training_loss": 0.7455627369880676, "training_acc": 46.0, "val_loss": 0.7855602574348449, "val_acc": 48.0}
{"epoch": 17, "training_loss": 0.7756258535385132, "training_acc": 54.0, "val_loss": 1.0972956323623657, "val_acc": 52.0}
{"epoch": 18, "training_loss": 0.809821081161499, "training_acc": 58.0, "val_loss": 1.1022435641288757, "val_acc": 48.0}
{"epoch": 19, "training_loss": 0.7572756361961365, "training_acc": 58.0, "val_loss": 1.1759180307388306, "val_acc": 52.0}
{"epoch": 20, "training_loss": 1.0143412590026855, "training_acc": 46.0, "val_loss": 0.7626401782035828, "val_acc": 48.0}
{"epoch": 21, "training_loss": 0.7468197607994079, "training_acc": 50.0, "val_loss": 0.6987498521804809, "val_acc": 48.0}
{"epoch": 22, "training_loss": 0.8264078283309937, "training_acc": 44.0, "val_loss": 0.7523026967048645, "val_acc": 52.0}
{"epoch": 23, "training_loss": 0.7210126662254334, "training_acc": 52.0, "val_loss": 0.6923082375526428, "val_acc": 52.0}
{"epoch": 24, "training_loss": 0.7106442523002624, "training_acc": 46.0, "val_loss": 0.6992334008216858, "val_acc": 48.0}
{"epoch": 25, "training_loss": 0.7064303827285766, "training_acc": 47.0, "val_loss": 0.7562960815429688, "val_acc": 48.0}
{"epoch": 26, "training_loss": 0.7675197291374206, "training_acc": 46.0, "val_loss": 0.6935710787773133, "val_acc": 52.0}
{"epoch": 27, "training_loss": 0.7234879422187805, "training_acc": 44.0, "val_loss": 0.6917510342597961, "val_acc": 52.0}
{"epoch": 28, "training_loss": 0.6927633142471313, "training_acc": 53.0, "val_loss": 0.7188768362998963, "val_acc": 48.0}
{"epoch": 29, "training_loss": 0.7147078800201416, "training_acc": 52.0, "val_loss": 0.728752658367157, "val_acc": 52.0}
{"epoch": 30, "training_loss": 0.7188095569610595, "training_acc": 48.0, "val_loss": 0.6985628533363343, "val_acc": 48.0}
{"epoch": 31, "training_loss": 0.7080469655990601, "training_acc": 44.0, "val_loss": 0.6912553596496582, "val_acc": 56.0}
{"epoch": 32, "training_loss": 0.7165477323532105, "training_acc": 53.0, "val_loss": 0.6931415271759033, "val_acc": 52.0}
{"epoch": 33, "training_loss": 0.7033913373947144, "training_acc": 46.0, "val_loss": 0.6941657447814942, "val_acc": 52.0}
{"epoch": 34, "training_loss": 0.7017375564575196, "training_acc": 44.0, "val_loss": 0.6929342246055603, "val_acc": 52.0}
{"epoch": 35, "training_loss": 0.7158757853507995, "training_acc": 44.0, "val_loss": 0.6925184965133667, "val_acc": 52.0}
{"epoch": 36, "training_loss": 0.7300525951385498, "training_acc": 50.0, "val_loss": 0.7136719417572022, "val_acc": 48.0}
{"epoch": 37, "training_loss": 0.7486156487464904, "training_acc": 48.0, "val_loss": 0.7035878300666809, "val_acc": 52.0}
{"epoch": 38, "training_loss": 0.7053705430030823, "training_acc": 52.0, "val_loss": 0.6938700270652771, "val_acc": 48.0}
{"epoch": 39, "training_loss": 0.7190391683578491, "training_acc": 48.0, "val_loss": 0.7025501418113709, "val_acc": 52.0}
{"epoch": 40, "training_loss": 0.7264665079116821, "training_acc": 52.0, "val_loss": 0.8153988218307495, "val_acc": 48.0}
{"epoch": 41, "training_loss": 0.7608102297782898, "training_acc": 50.0, "val_loss": 0.7354877877235413, "val_acc": 52.0}
{"epoch": 42, "training_loss": 0.7607926821708679, "training_acc": 58.0, "val_loss": 0.8277206492424011, "val_acc": 48.0}
{"epoch": 43, "training_loss": 0.7564034533500671, "training_acc": 46.0, "val_loss": 0.6939438557624817, "val_acc": 48.0}
{"epoch": 44, "training_loss": 0.7272758150100708, "training_acc": 41.0, "val_loss": 0.9189478349685669, "val_acc": 48.0}
{"epoch": 45, "training_loss": 0.8699321937561035, "training_acc": 46.0, "val_loss": 0.7599206614494324, "val_acc": 52.0}
{"epoch": 46, "training_loss": 0.7085086846351624, "training_acc": 54.0, "val_loss": 0.7081191730499268, "val_acc": 48.0}
{"epoch": 47, "training_loss": 0.7290110158920288, "training_acc": 52.0, "val_loss": 0.7322032189369202, "val_acc": 48.0}
{"epoch": 48, "training_loss": 0.687550311088562, "training_acc": 60.0, "val_loss": 0.9405811023712158, "val_acc": 52.0}
{"epoch": 49, "training_loss": 0.8942423391342164, "training_acc": 48.0, "val_loss": 0.6923522901535034, "val_acc": 52.0}
{"epoch": 50, "training_loss": 0.7923180770874023, "training_acc": 48.0, "val_loss": 0.7175665020942688, "val_acc": 48.0}
