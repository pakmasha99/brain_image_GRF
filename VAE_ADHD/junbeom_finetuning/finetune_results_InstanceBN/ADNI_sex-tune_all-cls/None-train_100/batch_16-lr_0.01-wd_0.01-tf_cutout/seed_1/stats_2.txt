"main_modify.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 1 --task ADNI_sex --input_option yAware --learning_rate 1e-2 --batch_size 16 --weight_decay 1e-2 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 1.0159918880462646, "training_acc": 54.0, "val_loss": 0.7006700563430787, "val_acc": 52.0}
{"epoch": 1, "training_loss": 0.7198664140701294, "training_acc": 44.0, "val_loss": 0.7748220610618591, "val_acc": 48.0}
{"epoch": 2, "training_loss": 0.7543345355987549, "training_acc": 46.0, "val_loss": 0.7149050736427307, "val_acc": 48.0}
{"epoch": 3, "training_loss": 0.7282371282577514, "training_acc": 54.0, "val_loss": 1.0557995796203614, "val_acc": 48.0}
{"epoch": 4, "training_loss": 0.8681011939048767, "training_acc": 52.0, "val_loss": 0.7026349997520447, "val_acc": 52.0}
{"epoch": 5, "training_loss": 0.7193840003013611, "training_acc": 50.0, "val_loss": 0.8192595028877259, "val_acc": 52.0}
{"epoch": 6, "training_loss": 0.7920725584030152, "training_acc": 50.0, "val_loss": 0.6928430581092835, "val_acc": 52.0}
{"epoch": 7, "training_loss": 0.7070524883270264, "training_acc": 52.0, "val_loss": 1.010161099433899, "val_acc": 48.0}
{"epoch": 8, "training_loss": 0.7594956707954407, "training_acc": 54.0, "val_loss": 1.0161195278167725, "val_acc": 52.0}
{"epoch": 9, "training_loss": 0.8384020113945008, "training_acc": 54.0, "val_loss": 0.867475597858429, "val_acc": 48.0}
{"epoch": 10, "training_loss": 0.7848148441314697, "training_acc": 50.0, "val_loss": 0.6955239462852478, "val_acc": 48.0}
{"epoch": 11, "training_loss": 0.7026353168487549, "training_acc": 48.0, "val_loss": 0.7915488696098327, "val_acc": 52.0}
{"epoch": 12, "training_loss": 0.8234451198577881, "training_acc": 44.0, "val_loss": 0.7858338379859924, "val_acc": 52.0}
{"epoch": 13, "training_loss": 0.7843992805480957, "training_acc": 54.0, "val_loss": 0.7231156396865844, "val_acc": 48.0}
{"epoch": 14, "training_loss": 0.6932232284545898, "training_acc": 54.0, "val_loss": 0.7869397592544556, "val_acc": 52.0}
{"epoch": 15, "training_loss": 0.741512279510498, "training_acc": 44.0, "val_loss": 0.7290432071685791, "val_acc": 48.0}
{"epoch": 16, "training_loss": 0.723087739944458, "training_acc": 40.0, "val_loss": 0.7079996395111084, "val_acc": 52.0}
{"epoch": 17, "training_loss": 0.7145084857940673, "training_acc": 46.0, "val_loss": 0.6924665951728821, "val_acc": 52.0}
{"epoch": 18, "training_loss": 0.7049151182174682, "training_acc": 52.0, "val_loss": 0.8172548222541809, "val_acc": 48.0}
{"epoch": 19, "training_loss": 0.7402233791351318, "training_acc": 44.0, "val_loss": 0.733144690990448, "val_acc": 52.0}
{"epoch": 20, "training_loss": 0.7329146242141724, "training_acc": 50.0, "val_loss": 0.720132839679718, "val_acc": 48.0}
{"epoch": 21, "training_loss": 0.7310966062545776, "training_acc": 54.0, "val_loss": 0.7372973728179931, "val_acc": 52.0}
{"epoch": 22, "training_loss": 0.7218819046020508, "training_acc": 48.0, "val_loss": 0.699048683643341, "val_acc": 48.0}
{"epoch": 23, "training_loss": 0.7193724489212037, "training_acc": 50.0, "val_loss": 0.6923973441123963, "val_acc": 52.0}
{"epoch": 24, "training_loss": 0.7046980452537537, "training_acc": 48.0, "val_loss": 0.697234148979187, "val_acc": 48.0}
{"epoch": 25, "training_loss": 0.7192500734329224, "training_acc": 42.0, "val_loss": 0.7179166984558105, "val_acc": 48.0}
{"epoch": 26, "training_loss": 0.7098120498657227, "training_acc": 50.0, "val_loss": 0.7000082445144653, "val_acc": 52.0}
{"epoch": 27, "training_loss": 0.7231701350212097, "training_acc": 52.0, "val_loss": 0.7611964654922485, "val_acc": 48.0}
{"epoch": 28, "training_loss": 0.7517810249328614, "training_acc": 46.0, "val_loss": 0.7298714923858642, "val_acc": 48.0}
{"epoch": 29, "training_loss": 0.7472857046127319, "training_acc": 44.0, "val_loss": 0.7002565050125122, "val_acc": 48.0}
{"epoch": 30, "training_loss": 0.7131472444534301, "training_acc": 50.0, "val_loss": 0.6987106037139893, "val_acc": 52.0}
{"epoch": 31, "training_loss": 0.7366900444030762, "training_acc": 48.0, "val_loss": 0.6940989232063294, "val_acc": 48.0}
{"epoch": 32, "training_loss": 0.6993488144874572, "training_acc": 42.0, "val_loss": 0.7043838119506836, "val_acc": 52.0}
{"epoch": 33, "training_loss": 0.7438330507278442, "training_acc": 44.0, "val_loss": 0.6932433414459228, "val_acc": 52.0}
{"epoch": 34, "training_loss": 0.7180727577209473, "training_acc": 52.0, "val_loss": 0.7715680694580078, "val_acc": 48.0}
{"epoch": 35, "training_loss": 0.7703783369064331, "training_acc": 46.0, "val_loss": 0.6935897946357727, "val_acc": 52.0}
{"epoch": 36, "training_loss": 0.7208620405197144, "training_acc": 50.0, "val_loss": 0.6949270009994507, "val_acc": 48.0}
{"epoch": 37, "training_loss": 0.7229509115219116, "training_acc": 50.0, "val_loss": 0.7065635395050048, "val_acc": 48.0}
{"epoch": 38, "training_loss": 0.7142887783050537, "training_acc": 50.0, "val_loss": 0.6932268953323364, "val_acc": 48.0}
{"epoch": 39, "training_loss": 0.7333342361450196, "training_acc": 46.0, "val_loss": 0.6925415396690369, "val_acc": 52.0}
{"epoch": 40, "training_loss": 0.7121950578689575, "training_acc": 48.0, "val_loss": 0.7526756429672241, "val_acc": 48.0}
{"epoch": 41, "training_loss": 0.7246243333816529, "training_acc": 48.0, "val_loss": 0.6930096173286437, "val_acc": 52.0}
{"epoch": 42, "training_loss": 0.7136993002891541, "training_acc": 44.0, "val_loss": 0.7574092817306518, "val_acc": 52.0}
