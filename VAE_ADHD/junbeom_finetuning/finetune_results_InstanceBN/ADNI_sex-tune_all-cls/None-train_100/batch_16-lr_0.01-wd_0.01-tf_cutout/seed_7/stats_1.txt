"main_modify.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 7 --task ADNI_sex --input_option yAware --learning_rate 1e-2 --batch_size 16 --weight_decay 1e-2 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 1.3740238857269287, "training_acc": 43.0, "val_loss": 0.7265640687942505, "val_acc": 48.0}
{"epoch": 1, "training_loss": 0.9966904425621033, "training_acc": 51.0, "val_loss": 0.7579561257362366, "val_acc": 52.0}
{"epoch": 2, "training_loss": 0.7471983671188355, "training_acc": 47.0, "val_loss": 0.6947011375427246, "val_acc": 52.0}
{"epoch": 3, "training_loss": 0.6985032987594605, "training_acc": 50.0, "val_loss": 0.797161865234375, "val_acc": 48.0}
{"epoch": 4, "training_loss": 0.7304551100730896, "training_acc": 47.0, "val_loss": 0.6928674006462097, "val_acc": 52.0}
{"epoch": 5, "training_loss": 0.7341484069824219, "training_acc": 57.0, "val_loss": 0.7164122462272644, "val_acc": 48.0}
{"epoch": 6, "training_loss": 0.7361913371086121, "training_acc": 45.0, "val_loss": 0.9049812388420105, "val_acc": 48.0}
{"epoch": 7, "training_loss": 0.7428046226501465, "training_acc": 57.0, "val_loss": 0.6930741262435913, "val_acc": 52.0}
{"epoch": 8, "training_loss": 0.7096233582496643, "training_acc": 51.0, "val_loss": 0.6937484073638917, "val_acc": 52.0}
{"epoch": 9, "training_loss": 0.7086456727981567, "training_acc": 51.0, "val_loss": 0.7508024907112122, "val_acc": 48.0}
{"epoch": 10, "training_loss": 0.7544121313095092, "training_acc": 53.0, "val_loss": 0.8660382008552552, "val_acc": 52.0}
{"epoch": 11, "training_loss": 0.8211383986473083, "training_acc": 43.0, "val_loss": 0.8270427083969116, "val_acc": 48.0}
{"epoch": 12, "training_loss": 0.7794497537612916, "training_acc": 49.0, "val_loss": 0.7022558093070984, "val_acc": 48.0}
{"epoch": 13, "training_loss": 0.7382578301429749, "training_acc": 43.0, "val_loss": 0.702766375541687, "val_acc": 48.0}
{"epoch": 14, "training_loss": 0.7121557426452637, "training_acc": 45.0, "val_loss": 0.6951487326622009, "val_acc": 48.0}
{"epoch": 15, "training_loss": 0.741423556804657, "training_acc": 47.0, "val_loss": 0.6957392978668213, "val_acc": 52.0}
{"epoch": 16, "training_loss": 0.7104196453094482, "training_acc": 51.0, "val_loss": 0.6947936129570007, "val_acc": 52.0}
{"epoch": 17, "training_loss": 0.709169135093689, "training_acc": 53.0, "val_loss": 0.8197203040122986, "val_acc": 48.0}
{"epoch": 18, "training_loss": 0.7406719112396241, "training_acc": 53.0, "val_loss": 0.7615911817550659, "val_acc": 52.0}
{"epoch": 19, "training_loss": 0.7425559687614441, "training_acc": 43.0, "val_loss": 0.748410906791687, "val_acc": 48.0}
{"epoch": 20, "training_loss": 0.7306856560707092, "training_acc": 51.0, "val_loss": 0.7084697270393372, "val_acc": 48.0}
{"epoch": 21, "training_loss": 0.7076436114311219, "training_acc": 55.0, "val_loss": 0.7674333238601685, "val_acc": 52.0}
{"epoch": 22, "training_loss": 0.7670144367218018, "training_acc": 49.0, "val_loss": 0.7084079003334045, "val_acc": 48.0}
{"epoch": 23, "training_loss": 0.7061334371566772, "training_acc": 51.0, "val_loss": 0.6923511552810669, "val_acc": 52.0}
{"epoch": 24, "training_loss": 0.7095074558258057, "training_acc": 49.0, "val_loss": 0.6987635159492492, "val_acc": 48.0}
{"epoch": 25, "training_loss": 0.7192926931381226, "training_acc": 51.0, "val_loss": 0.6926521110534668, "val_acc": 52.0}
{"epoch": 26, "training_loss": 0.7003839683532714, "training_acc": 49.0, "val_loss": 0.7054598879814148, "val_acc": 52.0}
{"epoch": 27, "training_loss": 0.734360842704773, "training_acc": 41.0, "val_loss": 0.708611056804657, "val_acc": 52.0}
{"epoch": 28, "training_loss": 0.7219644689559936, "training_acc": 55.0, "val_loss": 0.7349454569816589, "val_acc": 48.0}
{"epoch": 29, "training_loss": 0.7259834861755371, "training_acc": 41.0, "val_loss": 0.699497046470642, "val_acc": 48.0}
{"epoch": 30, "training_loss": 0.6961652374267578, "training_acc": 51.0, "val_loss": 0.7266815614700317, "val_acc": 52.0}
{"epoch": 31, "training_loss": 0.7940565776824952, "training_acc": 51.0, "val_loss": 0.8489753842353821, "val_acc": 48.0}
{"epoch": 32, "training_loss": 0.7750196290016175, "training_acc": 53.0, "val_loss": 0.7588321709632874, "val_acc": 52.0}
{"epoch": 33, "training_loss": 0.7815880990028381, "training_acc": 49.0, "val_loss": 0.7578910732269287, "val_acc": 48.0}
{"epoch": 34, "training_loss": 0.7293760752677918, "training_acc": 53.0, "val_loss": 0.70959547996521, "val_acc": 52.0}
{"epoch": 35, "training_loss": 0.731656014919281, "training_acc": 43.0, "val_loss": 0.7146837496757508, "val_acc": 48.0}
{"epoch": 36, "training_loss": 0.7132906341552734, "training_acc": 49.0, "val_loss": 0.6926218748092652, "val_acc": 52.0}
{"epoch": 37, "training_loss": 0.7135545897483826, "training_acc": 45.0, "val_loss": 0.7114410376548768, "val_acc": 52.0}
{"epoch": 38, "training_loss": 0.807487359046936, "training_acc": 47.0, "val_loss": 0.8131552052497864, "val_acc": 48.0}
{"epoch": 39, "training_loss": 0.7729900622367859, "training_acc": 55.0, "val_loss": 0.7536848855018615, "val_acc": 52.0}
{"epoch": 40, "training_loss": 0.74771484375, "training_acc": 45.0, "val_loss": 0.7043010640144348, "val_acc": 52.0}
{"epoch": 41, "training_loss": 0.7131301736831666, "training_acc": 49.0, "val_loss": 0.6942912983894348, "val_acc": 48.0}
{"epoch": 42, "training_loss": 0.7017760586738586, "training_acc": 51.0, "val_loss": 0.7265927910804748, "val_acc": 52.0}
