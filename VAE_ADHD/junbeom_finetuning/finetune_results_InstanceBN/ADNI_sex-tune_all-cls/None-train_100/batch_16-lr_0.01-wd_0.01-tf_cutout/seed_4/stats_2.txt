"main_modify.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 4 --task ADNI_sex --input_option yAware --learning_rate 1e-2 --batch_size 16 --weight_decay 1e-2 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 1.0566447687149048, "training_acc": 52.0, "val_loss": 0.6944806671142578, "val_acc": 48.0}
{"epoch": 1, "training_loss": 0.733293104171753, "training_acc": 59.0, "val_loss": 0.7243219614028931, "val_acc": 48.0}
{"epoch": 2, "training_loss": 0.7703436923027038, "training_acc": 48.0, "val_loss": 1.1595254230499268, "val_acc": 48.0}
{"epoch": 3, "training_loss": 0.9019817590713501, "training_acc": 46.0, "val_loss": 0.8011734342575073, "val_acc": 52.0}
{"epoch": 4, "training_loss": 0.8064032888412476, "training_acc": 48.0, "val_loss": 0.6981596064567566, "val_acc": 52.0}
{"epoch": 5, "training_loss": 0.7147466611862182, "training_acc": 50.0, "val_loss": 0.7138111877441407, "val_acc": 48.0}
{"epoch": 6, "training_loss": 0.6987063407897949, "training_acc": 52.0, "val_loss": 0.7400246262550354, "val_acc": 52.0}
{"epoch": 7, "training_loss": 0.7554448986053467, "training_acc": 40.0, "val_loss": 0.6924663496017456, "val_acc": 52.0}
{"epoch": 8, "training_loss": 0.708319787979126, "training_acc": 46.0, "val_loss": 0.6924388241767884, "val_acc": 52.0}
{"epoch": 9, "training_loss": 0.7257627773284913, "training_acc": 46.0, "val_loss": 0.6984625506401062, "val_acc": 52.0}
{"epoch": 10, "training_loss": 0.7276141929626465, "training_acc": 54.0, "val_loss": 0.7942889022827149, "val_acc": 48.0}
{"epoch": 11, "training_loss": 0.8251249933242798, "training_acc": 48.0, "val_loss": 0.7450086688995361, "val_acc": 48.0}
{"epoch": 12, "training_loss": 0.7740040111541748, "training_acc": 46.0, "val_loss": 0.6926052570343018, "val_acc": 52.0}
{"epoch": 13, "training_loss": 0.7230780410766602, "training_acc": 52.0, "val_loss": 0.8564444732666016, "val_acc": 52.0}
{"epoch": 14, "training_loss": 0.8465269756317139, "training_acc": 46.0, "val_loss": 0.7024255347251892, "val_acc": 52.0}
{"epoch": 15, "training_loss": 0.750198769569397, "training_acc": 54.0, "val_loss": 0.8945187377929688, "val_acc": 48.0}
{"epoch": 16, "training_loss": 0.7525915265083313, "training_acc": 56.0, "val_loss": 0.7648867344856263, "val_acc": 52.0}
{"epoch": 17, "training_loss": 0.7692258191108704, "training_acc": 48.0, "val_loss": 0.6986530208587647, "val_acc": 48.0}
{"epoch": 18, "training_loss": 0.702311475276947, "training_acc": 50.0, "val_loss": 0.6924340128898621, "val_acc": 52.0}
{"epoch": 19, "training_loss": 0.7082124996185303, "training_acc": 54.0, "val_loss": 0.6984073209762574, "val_acc": 48.0}
{"epoch": 20, "training_loss": 0.7204048252105713, "training_acc": 46.0, "val_loss": 0.7117604923248291, "val_acc": 48.0}
{"epoch": 21, "training_loss": 0.7081069707870483, "training_acc": 46.0, "val_loss": 0.6927616262435913, "val_acc": 52.0}
{"epoch": 22, "training_loss": 0.7097256326675415, "training_acc": 38.0, "val_loss": 0.7227389168739319, "val_acc": 52.0}
{"epoch": 23, "training_loss": 0.7418244075775147, "training_acc": 50.0, "val_loss": 0.6924112677574158, "val_acc": 52.0}
{"epoch": 24, "training_loss": 0.6995413494110108, "training_acc": 46.0, "val_loss": 0.7286734414100647, "val_acc": 48.0}
{"epoch": 25, "training_loss": 0.7186701154708862, "training_acc": 46.0, "val_loss": 0.6978112149238587, "val_acc": 48.0}
{"epoch": 26, "training_loss": 0.7079050064086914, "training_acc": 44.0, "val_loss": 0.7004138875007629, "val_acc": 48.0}
{"epoch": 27, "training_loss": 0.7021584129333496, "training_acc": 44.0, "val_loss": 0.7294119787216187, "val_acc": 48.0}
{"epoch": 28, "training_loss": 0.715886287689209, "training_acc": 50.0, "val_loss": 0.6972280049324036, "val_acc": 52.0}
{"epoch": 29, "training_loss": 0.7241579246520996, "training_acc": 52.0, "val_loss": 0.7477745294570923, "val_acc": 48.0}
{"epoch": 30, "training_loss": 0.7816711473464966, "training_acc": 50.0, "val_loss": 0.7060458111763, "val_acc": 52.0}
{"epoch": 31, "training_loss": 0.7300116395950318, "training_acc": 50.0, "val_loss": 0.6927968907356262, "val_acc": 52.0}
{"epoch": 32, "training_loss": 0.7043807029724121, "training_acc": 48.0, "val_loss": 0.728871340751648, "val_acc": 48.0}
{"epoch": 33, "training_loss": 0.7247132921218872, "training_acc": 50.0, "val_loss": 0.703458948135376, "val_acc": 52.0}
{"epoch": 34, "training_loss": 0.7141129517555237, "training_acc": 48.0, "val_loss": 0.6927355551719665, "val_acc": 52.0}
{"epoch": 35, "training_loss": 0.7096235823631286, "training_acc": 46.0, "val_loss": 0.7512569046020507, "val_acc": 48.0}
{"epoch": 36, "training_loss": 0.737446882724762, "training_acc": 48.0, "val_loss": 0.7254902791976928, "val_acc": 52.0}
{"epoch": 37, "training_loss": 0.7137946057319641, "training_acc": 50.0, "val_loss": 0.7126943373680115, "val_acc": 48.0}
{"epoch": 38, "training_loss": 0.7050197124481201, "training_acc": 44.0, "val_loss": 0.7135820174217224, "val_acc": 52.0}
{"epoch": 39, "training_loss": 0.7293565845489502, "training_acc": 38.0, "val_loss": 0.693459599018097, "val_acc": 52.0}
{"epoch": 40, "training_loss": 0.7144840717315674, "training_acc": 46.0, "val_loss": 0.7357270383834839, "val_acc": 52.0}
{"epoch": 41, "training_loss": 0.7167848634719849, "training_acc": 54.0, "val_loss": 0.9004493284225464, "val_acc": 48.0}
{"epoch": 42, "training_loss": 0.7668573093414307, "training_acc": 56.0, "val_loss": 0.8381848096847534, "val_acc": 52.0}
