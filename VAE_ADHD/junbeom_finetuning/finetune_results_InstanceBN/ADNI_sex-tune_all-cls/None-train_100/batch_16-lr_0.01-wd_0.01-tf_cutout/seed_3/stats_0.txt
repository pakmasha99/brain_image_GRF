"main_modify.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 3 --task ADNI_sex --input_option yAware --learning_rate 1e-2 --batch_size 16 --weight_decay 1e-2 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 1.3384793782234192, "training_acc": 48.0, "val_loss": 0.6976038432121277, "val_acc": 52.0}
{"epoch": 1, "training_loss": 0.7493714046478271, "training_acc": 48.0, "val_loss": 0.8398406910896301, "val_acc": 52.0}
{"epoch": 2, "training_loss": 0.7391349911689759, "training_acc": 48.0, "val_loss": 0.8521851396560669, "val_acc": 48.0}
{"epoch": 3, "training_loss": 0.7268112754821777, "training_acc": 56.0, "val_loss": 0.6948791241645813, "val_acc": 52.0}
{"epoch": 4, "training_loss": 0.7281561040878296, "training_acc": 50.0, "val_loss": 0.7552867436408996, "val_acc": 52.0}
{"epoch": 5, "training_loss": 0.791486554145813, "training_acc": 44.0, "val_loss": 0.8031806874275208, "val_acc": 48.0}
{"epoch": 6, "training_loss": 0.7670845127105713, "training_acc": 50.0, "val_loss": 0.6959640574455261, "val_acc": 48.0}
{"epoch": 7, "training_loss": 0.7908658981323242, "training_acc": 54.0, "val_loss": 0.7671382904052735, "val_acc": 52.0}
{"epoch": 8, "training_loss": 0.7473217129707337, "training_acc": 46.0, "val_loss": 0.6947701740264892, "val_acc": 52.0}
{"epoch": 9, "training_loss": 0.7358043384552002, "training_acc": 40.0, "val_loss": 0.6925602674484252, "val_acc": 52.0}
{"epoch": 10, "training_loss": 0.6979886078834534, "training_acc": 50.0, "val_loss": 0.9918827772140503, "val_acc": 48.0}
{"epoch": 11, "training_loss": 0.8650549554824829, "training_acc": 54.0, "val_loss": 0.7364958572387695, "val_acc": 52.0}
{"epoch": 12, "training_loss": 0.735074429512024, "training_acc": 48.0, "val_loss": 0.7256779503822327, "val_acc": 52.0}
{"epoch": 13, "training_loss": 0.7292547011375428, "training_acc": 48.0, "val_loss": 0.7169090723991394, "val_acc": 48.0}
{"epoch": 14, "training_loss": 0.7295664644241333, "training_acc": 46.0, "val_loss": 0.9209231996536255, "val_acc": 48.0}
{"epoch": 15, "training_loss": 0.7497004365921021, "training_acc": 48.0, "val_loss": 0.6995086979866028, "val_acc": 48.0}
{"epoch": 16, "training_loss": 0.7244080114364624, "training_acc": 50.0, "val_loss": 0.6925615334510803, "val_acc": 52.0}
{"epoch": 17, "training_loss": 0.7403535127639771, "training_acc": 46.0, "val_loss": 0.6924044346809387, "val_acc": 52.0}
{"epoch": 18, "training_loss": 0.7009763288497924, "training_acc": 46.0, "val_loss": 0.6932360005378723, "val_acc": 48.0}
{"epoch": 19, "training_loss": 0.7021967911720276, "training_acc": 54.0, "val_loss": 0.7158625555038453, "val_acc": 48.0}
{"epoch": 20, "training_loss": 0.7287279796600342, "training_acc": 46.0, "val_loss": 0.6925790429115295, "val_acc": 52.0}
{"epoch": 21, "training_loss": 0.6986266374588013, "training_acc": 52.0, "val_loss": 0.7150323176383973, "val_acc": 48.0}
{"epoch": 22, "training_loss": 0.7175696897506714, "training_acc": 42.0, "val_loss": 0.6923889589309692, "val_acc": 52.0}
{"epoch": 23, "training_loss": 0.7023431134223937, "training_acc": 50.0, "val_loss": 0.7003932356834411, "val_acc": 52.0}
{"epoch": 24, "training_loss": 0.7095984983444213, "training_acc": 44.0, "val_loss": 0.6952750158309936, "val_acc": 48.0}
{"epoch": 25, "training_loss": 0.7060564875602722, "training_acc": 44.0, "val_loss": 0.7369238018989563, "val_acc": 48.0}
{"epoch": 26, "training_loss": 0.7549405336380005, "training_acc": 46.0, "val_loss": 0.6939121627807617, "val_acc": 52.0}
{"epoch": 27, "training_loss": 0.7320559072494507, "training_acc": 42.0, "val_loss": 0.6961120533943176, "val_acc": 52.0}
{"epoch": 28, "training_loss": 0.7152703666687011, "training_acc": 52.0, "val_loss": 0.7270321345329285, "val_acc": 48.0}
{"epoch": 29, "training_loss": 0.714851725101471, "training_acc": 50.0, "val_loss": 0.6975953269004822, "val_acc": 52.0}
{"epoch": 30, "training_loss": 0.7034424495697021, "training_acc": 48.0, "val_loss": 0.6932256627082825, "val_acc": 52.0}
{"epoch": 31, "training_loss": 0.7033436822891236, "training_acc": 50.0, "val_loss": 0.7201754808425903, "val_acc": 48.0}
{"epoch": 32, "training_loss": 0.7206192994117737, "training_acc": 50.0, "val_loss": 0.6955121278762817, "val_acc": 48.0}
{"epoch": 33, "training_loss": 0.743717234134674, "training_acc": 40.0, "val_loss": 0.7976622581481934, "val_acc": 48.0}
{"epoch": 34, "training_loss": 0.766445140838623, "training_acc": 46.0, "val_loss": 0.7032176327705383, "val_acc": 52.0}
{"epoch": 35, "training_loss": 0.7098696613311768, "training_acc": 48.0, "val_loss": 0.6967684936523437, "val_acc": 48.0}
{"epoch": 36, "training_loss": 0.699953269958496, "training_acc": 50.0, "val_loss": 0.7279991865158081, "val_acc": 48.0}
{"epoch": 37, "training_loss": 0.7100973463058472, "training_acc": 48.0, "val_loss": 0.6927451729774475, "val_acc": 52.0}
{"epoch": 38, "training_loss": 0.7024163675308227, "training_acc": 46.0, "val_loss": 0.7056273698806763, "val_acc": 48.0}
{"epoch": 39, "training_loss": 0.7039147067070007, "training_acc": 42.0, "val_loss": 0.6970913314819336, "val_acc": 48.0}
{"epoch": 40, "training_loss": 0.707678279876709, "training_acc": 48.0, "val_loss": 0.7012782979011536, "val_acc": 48.0}
{"epoch": 41, "training_loss": 0.7102521252632141, "training_acc": 44.0, "val_loss": 0.6991634678840637, "val_acc": 48.0}
