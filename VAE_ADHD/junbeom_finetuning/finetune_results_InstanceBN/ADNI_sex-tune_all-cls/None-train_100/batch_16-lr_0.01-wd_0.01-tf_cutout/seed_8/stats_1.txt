"main_modify.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 8 --task ADNI_sex --input_option yAware --learning_rate 1e-2 --batch_size 16 --weight_decay 1e-2 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 1.1957503747940064, "training_acc": 49.0, "val_loss": 0.6983600306510925, "val_acc": 48.0}
{"epoch": 1, "training_loss": 0.7728546380996704, "training_acc": 42.0, "val_loss": 0.7349046087265014, "val_acc": 52.0}
{"epoch": 2, "training_loss": 0.7307222962379456, "training_acc": 49.0, "val_loss": 0.7522616505622863, "val_acc": 52.0}
{"epoch": 3, "training_loss": 0.7434211444854736, "training_acc": 51.0, "val_loss": 0.7067198896408081, "val_acc": 48.0}
{"epoch": 4, "training_loss": 0.7115140914916992, "training_acc": 53.0, "val_loss": 0.7292688202857971, "val_acc": 48.0}
{"epoch": 5, "training_loss": 0.7505813264846801, "training_acc": 47.0, "val_loss": 0.7656348776817322, "val_acc": 48.0}
{"epoch": 6, "training_loss": 0.7666334056854248, "training_acc": 49.0, "val_loss": 0.7017725586891175, "val_acc": 52.0}
{"epoch": 7, "training_loss": 0.7062726378440857, "training_acc": 45.0, "val_loss": 0.7265326189994812, "val_acc": 48.0}
{"epoch": 8, "training_loss": 0.7140850257873536, "training_acc": 49.0, "val_loss": 0.728501455783844, "val_acc": 52.0}
{"epoch": 9, "training_loss": 0.7389156770706177, "training_acc": 51.0, "val_loss": 0.6962452292442322, "val_acc": 52.0}
{"epoch": 10, "training_loss": 0.73391774892807, "training_acc": 53.0, "val_loss": 0.7075466299057007, "val_acc": 48.0}
{"epoch": 11, "training_loss": 0.736789517402649, "training_acc": 61.0, "val_loss": 0.9475540971755981, "val_acc": 52.0}
{"epoch": 12, "training_loss": 0.7933865642547607, "training_acc": 49.0, "val_loss": 0.7034776377677917, "val_acc": 52.0}
{"epoch": 13, "training_loss": 0.7400310921669007, "training_acc": 45.0, "val_loss": 0.8175128269195556, "val_acc": 48.0}
{"epoch": 14, "training_loss": 0.7722593760490417, "training_acc": 51.0, "val_loss": 0.7116254043579101, "val_acc": 52.0}
{"epoch": 15, "training_loss": 0.7015777063369751, "training_acc": 53.0, "val_loss": 0.6986465430259705, "val_acc": 48.0}
{"epoch": 16, "training_loss": 0.6986571168899536, "training_acc": 49.0, "val_loss": 0.7496462631225586, "val_acc": 48.0}
{"epoch": 17, "training_loss": 0.722472813129425, "training_acc": 45.0, "val_loss": 0.7153213024139404, "val_acc": 52.0}
{"epoch": 18, "training_loss": 0.741698579788208, "training_acc": 45.0, "val_loss": 0.6941893815994262, "val_acc": 52.0}
{"epoch": 19, "training_loss": 0.742790424823761, "training_acc": 51.0, "val_loss": 0.9144964170455933, "val_acc": 48.0}
{"epoch": 20, "training_loss": 0.7605686330795288, "training_acc": 47.0, "val_loss": 0.7194519925117493, "val_acc": 48.0}
{"epoch": 21, "training_loss": 0.7610440492630005, "training_acc": 47.0, "val_loss": 0.708265106678009, "val_acc": 48.0}
{"epoch": 22, "training_loss": 0.72905517578125, "training_acc": 47.0, "val_loss": 0.9975654554367065, "val_acc": 48.0}
{"epoch": 23, "training_loss": 0.7354816174507142, "training_acc": 57.0, "val_loss": 0.7494577121734619, "val_acc": 52.0}
{"epoch": 24, "training_loss": 0.7491622018814087, "training_acc": 53.0, "val_loss": 0.7069403123855591, "val_acc": 52.0}
{"epoch": 25, "training_loss": 0.8006312799453735, "training_acc": 47.0, "val_loss": 0.8542510628700256, "val_acc": 52.0}
{"epoch": 26, "training_loss": 0.8407718276977539, "training_acc": 47.0, "val_loss": 0.7052293133735656, "val_acc": 48.0}
{"epoch": 27, "training_loss": 0.6992655062675476, "training_acc": 49.0, "val_loss": 0.6940570306777955, "val_acc": 48.0}
{"epoch": 28, "training_loss": 0.6893852496147156, "training_acc": 53.0, "val_loss": 0.7922116780281067, "val_acc": 48.0}
{"epoch": 29, "training_loss": 0.7718464469909668, "training_acc": 39.0, "val_loss": 0.6958414196968079, "val_acc": 52.0}
{"epoch": 30, "training_loss": 0.7104357433319092, "training_acc": 49.0, "val_loss": 0.7259045505523681, "val_acc": 48.0}
{"epoch": 31, "training_loss": 0.7157219529151917, "training_acc": 47.0, "val_loss": 0.6923573803901673, "val_acc": 52.0}
{"epoch": 32, "training_loss": 0.7199952745437622, "training_acc": 43.0, "val_loss": 0.6974742126464843, "val_acc": 52.0}
{"epoch": 33, "training_loss": 0.7065607500076294, "training_acc": 49.0, "val_loss": 0.700629563331604, "val_acc": 48.0}
{"epoch": 34, "training_loss": 0.6992031288146973, "training_acc": 51.0, "val_loss": 0.6934583973884583, "val_acc": 52.0}
{"epoch": 35, "training_loss": 0.7019548320770264, "training_acc": 49.0, "val_loss": 0.7017323303222657, "val_acc": 52.0}
{"epoch": 36, "training_loss": 0.7279113078117371, "training_acc": 37.0, "val_loss": 0.6924245834350586, "val_acc": 52.0}
{"epoch": 37, "training_loss": 0.7035710692405701, "training_acc": 45.0, "val_loss": 0.692560076713562, "val_acc": 52.0}
{"epoch": 38, "training_loss": 0.7211427545547485, "training_acc": 47.0, "val_loss": 0.6981547665596008, "val_acc": 52.0}
{"epoch": 39, "training_loss": 0.7262106442451477, "training_acc": 45.0, "val_loss": 0.6981793284416199, "val_acc": 48.0}
{"epoch": 40, "training_loss": 0.7042701935768128, "training_acc": 49.0, "val_loss": 0.7039365696907044, "val_acc": 48.0}
{"epoch": 41, "training_loss": 0.7215851068496704, "training_acc": 45.0, "val_loss": 0.7492222905158996, "val_acc": 48.0}
{"epoch": 42, "training_loss": 0.7067114782333374, "training_acc": 53.0, "val_loss": 0.7330659198760986, "val_acc": 52.0}
{"epoch": 43, "training_loss": 0.742218132019043, "training_acc": 45.0, "val_loss": 0.7187328362464904, "val_acc": 48.0}
{"epoch": 44, "training_loss": 0.7085731077194214, "training_acc": 51.0, "val_loss": 0.7129633259773255, "val_acc": 52.0}
{"epoch": 45, "training_loss": 0.7148737263679504, "training_acc": 51.0, "val_loss": 0.738599169254303, "val_acc": 48.0}
{"epoch": 46, "training_loss": 0.7290625047683715, "training_acc": 51.0, "val_loss": 0.6997530484199523, "val_acc": 52.0}
{"epoch": 47, "training_loss": 0.7143646192550659, "training_acc": 41.0, "val_loss": 0.6924948883056641, "val_acc": 52.0}
{"epoch": 48, "training_loss": 0.7104182982444763, "training_acc": 51.0, "val_loss": 0.7095594668388366, "val_acc": 48.0}
{"epoch": 49, "training_loss": 0.70771164894104, "training_acc": 45.0, "val_loss": 0.6936325788497925, "val_acc": 48.0}
{"epoch": 50, "training_loss": 0.7095840978622436, "training_acc": 47.0, "val_loss": 0.6926190686225892, "val_acc": 52.0}
