"main_modify.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 5 --task ADNI_sex --input_option yAware --learning_rate 1e-1 --batch_size 16 --weight_decay 1e-3 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 7.645965943336487, "training_acc": 54.0, "val_loss": 3.515212211608887, "val_acc": 52.0}
{"epoch": 1, "training_loss": 2.8031678549945354, "training_acc": 58.0, "val_loss": 5.61005633354187, "val_acc": 52.0}
{"epoch": 2, "training_loss": 4.386099700927734, "training_acc": 46.0, "val_loss": 2.196662178039551, "val_acc": 52.0}
{"epoch": 3, "training_loss": 1.6606390380859375, "training_acc": 46.0, "val_loss": 1.007987151145935, "val_acc": 48.0}
{"epoch": 4, "training_loss": 1.6018877124786377, "training_acc": 42.0, "val_loss": 4.4646640968322755, "val_acc": 48.0}
{"epoch": 5, "training_loss": 4.079141674041748, "training_acc": 54.0, "val_loss": 1.3043828058242797, "val_acc": 52.0}
{"epoch": 6, "training_loss": 3.280026226043701, "training_acc": 52.0, "val_loss": 3.5734110069274903, "val_acc": 52.0}
{"epoch": 7, "training_loss": 2.2769099855422974, "training_acc": 46.0, "val_loss": 1.1908918380737306, "val_acc": 52.0}
{"epoch": 8, "training_loss": 1.1882068634033203, "training_acc": 48.0, "val_loss": 0.7800660490989685, "val_acc": 48.0}
{"epoch": 9, "training_loss": 1.2165449833869935, "training_acc": 56.0, "val_loss": 0.7352391362190247, "val_acc": 52.0}
{"epoch": 10, "training_loss": 0.759074239730835, "training_acc": 48.0, "val_loss": 1.2145218753814697, "val_acc": 52.0}
{"epoch": 11, "training_loss": 0.9737137889862061, "training_acc": 52.0, "val_loss": 0.7073992252349853, "val_acc": 48.0}
{"epoch": 12, "training_loss": 1.044492530822754, "training_acc": 44.0, "val_loss": 0.7316506743431092, "val_acc": 52.0}
{"epoch": 13, "training_loss": 0.7009463596343994, "training_acc": 56.0, "val_loss": 1.508186821937561, "val_acc": 48.0}
{"epoch": 14, "training_loss": 1.2327294540405274, "training_acc": 52.0, "val_loss": 0.8159862852096558, "val_acc": 52.0}
{"epoch": 15, "training_loss": 0.7457019090652466, "training_acc": 53.0, "val_loss": 0.6935882472991943, "val_acc": 48.0}
{"epoch": 16, "training_loss": 0.82690931558609, "training_acc": 50.0, "val_loss": 1.7316588592529296, "val_acc": 52.0}
{"epoch": 17, "training_loss": 1.130398292541504, "training_acc": 44.0, "val_loss": 0.7856495022773743, "val_acc": 52.0}
{"epoch": 18, "training_loss": 1.0027840423583985, "training_acc": 50.0, "val_loss": 2.2133989906311036, "val_acc": 52.0}
{"epoch": 19, "training_loss": 2.172043008804321, "training_acc": 46.0, "val_loss": 2.2963836097717287, "val_acc": 48.0}
{"epoch": 20, "training_loss": 1.9826978600025178, "training_acc": 44.0, "val_loss": 2.230151290893555, "val_acc": 52.0}
{"epoch": 21, "training_loss": 1.583845205307007, "training_acc": 51.0, "val_loss": 2.1248976230621337, "val_acc": 52.0}
{"epoch": 22, "training_loss": 1.1841079425811767, "training_acc": 49.0, "val_loss": 1.1030591535568237, "val_acc": 52.0}
{"epoch": 23, "training_loss": 1.2169567441940308, "training_acc": 44.0, "val_loss": 0.7583816409111023, "val_acc": 52.0}
{"epoch": 24, "training_loss": 1.0010733556747438, "training_acc": 52.0, "val_loss": 0.9047354936599732, "val_acc": 52.0}
{"epoch": 25, "training_loss": 0.8551345157623291, "training_acc": 52.0, "val_loss": 0.688136785030365, "val_acc": 52.0}
{"epoch": 26, "training_loss": 1.3923532962799072, "training_acc": 56.0, "val_loss": 1.126918318271637, "val_acc": 52.0}
{"epoch": 27, "training_loss": 1.3010420632362365, "training_acc": 56.0, "val_loss": 0.9972311115264892, "val_acc": 48.0}
{"epoch": 28, "training_loss": 1.0224290657043458, "training_acc": 52.0, "val_loss": 1.2261409068107605, "val_acc": 48.0}
{"epoch": 29, "training_loss": 0.8786215394735336, "training_acc": 56.0, "val_loss": 2.6864659118652345, "val_acc": 52.0}
{"epoch": 30, "training_loss": 2.00706529378891, "training_acc": 46.0, "val_loss": 0.6985611581802368, "val_acc": 48.0}
{"epoch": 31, "training_loss": 1.0973616743087768, "training_acc": 48.0, "val_loss": 0.8427195310592651, "val_acc": 52.0}
{"epoch": 32, "training_loss": 0.8372178483009338, "training_acc": 50.0, "val_loss": 0.6855617570877075, "val_acc": 44.0}
{"epoch": 33, "training_loss": 1.32524564743042, "training_acc": 50.0, "val_loss": 1.776570816040039, "val_acc": 52.0}
{"epoch": 34, "training_loss": 2.010011637210846, "training_acc": 46.0, "val_loss": 3.867913303375244, "val_acc": 48.0}
{"epoch": 35, "training_loss": 2.1922903290763496, "training_acc": 48.0, "val_loss": 2.9818338632583616, "val_acc": 48.0}
{"epoch": 36, "training_loss": 1.8035566425323486, "training_acc": 54.0, "val_loss": 1.5759083890914918, "val_acc": 52.0}
{"epoch": 37, "training_loss": 2.132537806034088, "training_acc": 48.0, "val_loss": 1.6842639255523681, "val_acc": 52.0}
{"epoch": 38, "training_loss": 1.1646868801116943, "training_acc": 49.0, "val_loss": 0.7328051161766053, "val_acc": 48.0}
{"epoch": 39, "training_loss": 1.2195420455932617, "training_acc": 50.0, "val_loss": 0.6907675170898437, "val_acc": 44.0}
{"epoch": 40, "training_loss": 1.2183243250846862, "training_acc": 54.0, "val_loss": 1.5111186265945435, "val_acc": 48.0}
{"epoch": 41, "training_loss": 1.2173811435699462, "training_acc": 48.0, "val_loss": 1.0624660205841066, "val_acc": 52.0}
{"epoch": 42, "training_loss": 1.5955686855316162, "training_acc": 44.0, "val_loss": 2.246254506111145, "val_acc": 52.0}
{"epoch": 43, "training_loss": 1.7900858116149903, "training_acc": 58.0, "val_loss": 1.3651524376869202, "val_acc": 52.0}
{"epoch": 44, "training_loss": 1.1163639307022095, "training_acc": 50.0, "val_loss": 1.6039286184310912, "val_acc": 52.0}
{"epoch": 45, "training_loss": 0.9500338506698608, "training_acc": 58.0, "val_loss": 0.7034080576896667, "val_acc": 56.0}
{"epoch": 46, "training_loss": 0.8565360832214356, "training_acc": 50.0, "val_loss": 0.6998297500610352, "val_acc": 52.0}
{"epoch": 47, "training_loss": 0.9186806535720825, "training_acc": 49.0, "val_loss": 0.91394611120224, "val_acc": 48.0}
{"epoch": 48, "training_loss": 0.8633167195320129, "training_acc": 46.0, "val_loss": 1.5830040311813354, "val_acc": 52.0}
{"epoch": 49, "training_loss": 1.0041908949613572, "training_acc": 56.0, "val_loss": 3.167805004119873, "val_acc": 48.0}
{"epoch": 50, "training_loss": 2.9759732913970947, "training_acc": 42.0, "val_loss": 1.6635704135894775, "val_acc": 48.0}
{"epoch": 51, "training_loss": 3.1410108470916747, "training_acc": 48.0, "val_loss": 4.274912405014038, "val_acc": 48.0}
