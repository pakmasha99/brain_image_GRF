"main_modify.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 2 --task ADNI_sex --input_option yAware --learning_rate 1e-3 --batch_size 16 --weight_decay 1e-5 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 0.6956276297569275, "training_acc": 51.0, "val_loss": 0.6927119183540345, "val_acc": 52.0}
{"epoch": 1, "training_loss": 0.7101121425628663, "training_acc": 47.0, "val_loss": 0.6967719054222107, "val_acc": 48.0}
{"epoch": 2, "training_loss": 0.7088202357292175, "training_acc": 51.0, "val_loss": 0.6969929242134094, "val_acc": 52.0}
{"epoch": 3, "training_loss": 0.7213507890701294, "training_acc": 49.0, "val_loss": 0.6945473098754883, "val_acc": 52.0}
{"epoch": 4, "training_loss": 0.7012295770645142, "training_acc": 49.0, "val_loss": 0.6957187557220459, "val_acc": 48.0}
{"epoch": 5, "training_loss": 0.6978419184684753, "training_acc": 51.0, "val_loss": 0.6961975860595703, "val_acc": 48.0}
{"epoch": 6, "training_loss": 0.7069257426261902, "training_acc": 47.0, "val_loss": 0.6942713975906372, "val_acc": 52.0}
{"epoch": 7, "training_loss": 0.7213465309143067, "training_acc": 49.0, "val_loss": 0.6928099060058593, "val_acc": 52.0}
{"epoch": 8, "training_loss": 0.7146135282516479, "training_acc": 45.0, "val_loss": 0.7025658369064331, "val_acc": 48.0}
{"epoch": 9, "training_loss": 0.6928201198577881, "training_acc": 51.0, "val_loss": 0.6923516535758972, "val_acc": 52.0}
{"epoch": 10, "training_loss": 0.6973919153213501, "training_acc": 49.0, "val_loss": 0.6923933720588684, "val_acc": 52.0}
{"epoch": 11, "training_loss": 0.7012383604049682, "training_acc": 41.0, "val_loss": 0.6924467611312867, "val_acc": 52.0}
{"epoch": 12, "training_loss": 0.7145058727264404, "training_acc": 49.0, "val_loss": 0.6972765707969666, "val_acc": 52.0}
{"epoch": 13, "training_loss": 0.7013246822357178, "training_acc": 47.0, "val_loss": 0.6952509236335754, "val_acc": 48.0}
{"epoch": 14, "training_loss": 0.6944022226333618, "training_acc": 51.0, "val_loss": 0.6933727025985718, "val_acc": 48.0}
{"epoch": 15, "training_loss": 0.6937508940696716, "training_acc": 51.0, "val_loss": 0.6928123450279235, "val_acc": 52.0}
{"epoch": 16, "training_loss": 0.7016055297851562, "training_acc": 39.0, "val_loss": 0.692381854057312, "val_acc": 52.0}
{"epoch": 17, "training_loss": 0.7041391515731812, "training_acc": 49.0, "val_loss": 0.6932777333259582, "val_acc": 52.0}
{"epoch": 18, "training_loss": 0.6972254824638366, "training_acc": 47.0, "val_loss": 0.6960159778594971, "val_acc": 48.0}
{"epoch": 19, "training_loss": 0.7003198099136353, "training_acc": 51.0, "val_loss": 0.6988626527786255, "val_acc": 48.0}
{"epoch": 20, "training_loss": 0.7049861001968384, "training_acc": 49.0, "val_loss": 0.6950799202919007, "val_acc": 52.0}
{"epoch": 21, "training_loss": 0.6961677980422973, "training_acc": 49.0, "val_loss": 0.6989177823066711, "val_acc": 48.0}
{"epoch": 22, "training_loss": 0.6978781008720398, "training_acc": 51.0, "val_loss": 0.7024472665786743, "val_acc": 48.0}
{"epoch": 23, "training_loss": 0.7059686970710755, "training_acc": 43.0, "val_loss": 0.6923343753814697, "val_acc": 52.0}
{"epoch": 24, "training_loss": 0.696393404006958, "training_acc": 49.0, "val_loss": 0.7055522894859314, "val_acc": 48.0}
{"epoch": 25, "training_loss": 0.701427698135376, "training_acc": 51.0, "val_loss": 0.6940772151947021, "val_acc": 48.0}
{"epoch": 26, "training_loss": 0.6952085256576538, "training_acc": 49.0, "val_loss": 0.6942432975769043, "val_acc": 52.0}
{"epoch": 27, "training_loss": 0.6996577334403992, "training_acc": 49.0, "val_loss": 0.6923460817337036, "val_acc": 52.0}
{"epoch": 28, "training_loss": 0.6963836097717285, "training_acc": 47.0, "val_loss": 0.7007725214958191, "val_acc": 48.0}
{"epoch": 29, "training_loss": 0.7012452745437622, "training_acc": 51.0, "val_loss": 0.69819664478302, "val_acc": 48.0}
{"epoch": 30, "training_loss": 0.6946417713165283, "training_acc": 51.0, "val_loss": 0.6935698366165162, "val_acc": 48.0}
{"epoch": 31, "training_loss": 0.6991574859619141, "training_acc": 51.0, "val_loss": 0.6924558806419373, "val_acc": 52.0}
{"epoch": 32, "training_loss": 0.7028773617744446, "training_acc": 49.0, "val_loss": 0.6942958569526673, "val_acc": 52.0}
{"epoch": 33, "training_loss": 0.7014446973800659, "training_acc": 45.0, "val_loss": 0.701229739189148, "val_acc": 48.0}
{"epoch": 34, "training_loss": 0.7001419973373413, "training_acc": 51.0, "val_loss": 0.6989159512519837, "val_acc": 48.0}
{"epoch": 35, "training_loss": 0.6973984813690186, "training_acc": 51.0, "val_loss": 0.6989154386520385, "val_acc": 48.0}
{"epoch": 36, "training_loss": 0.7018329620361328, "training_acc": 45.0, "val_loss": 0.6923505878448486, "val_acc": 52.0}
{"epoch": 37, "training_loss": 0.6908546566963196, "training_acc": 55.0, "val_loss": 0.7011286592483521, "val_acc": 48.0}
{"epoch": 38, "training_loss": 0.6984334707260131, "training_acc": 51.0, "val_loss": 0.6927383351325989, "val_acc": 52.0}
{"epoch": 39, "training_loss": 0.7187524604797363, "training_acc": 49.0, "val_loss": 0.7071949028968811, "val_acc": 52.0}
{"epoch": 40, "training_loss": 0.7133846735954285, "training_acc": 49.0, "val_loss": 0.6928921127319336, "val_acc": 52.0}
{"epoch": 41, "training_loss": 0.691692099571228, "training_acc": 51.0, "val_loss": 0.7068973040580749, "val_acc": 48.0}
{"epoch": 42, "training_loss": 0.7093711400032043, "training_acc": 51.0, "val_loss": 0.711515817642212, "val_acc": 48.0}
