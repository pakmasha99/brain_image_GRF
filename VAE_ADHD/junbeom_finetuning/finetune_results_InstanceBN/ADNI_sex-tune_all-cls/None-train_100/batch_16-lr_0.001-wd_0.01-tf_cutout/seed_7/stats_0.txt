"main_modify.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 7 --task ADNI_sex --input_option yAware --learning_rate 1e-3 --batch_size 16 --weight_decay 1e-2 --BN inst --save_path finetune_results_InstanceBN --run_where lab"
{"epoch": 0, "training_loss": 0.7062255001068115, "training_acc": 51.0, "val_loss": 0.7004733943939209, "val_acc": 52.0}
{"epoch": 1, "training_loss": 0.7275676298141479, "training_acc": 41.0, "val_loss": 0.6940913581848145, "val_acc": 48.0}
{"epoch": 2, "training_loss": 0.7038331890106201, "training_acc": 41.0, "val_loss": 0.7091629719734192, "val_acc": 48.0}
{"epoch": 3, "training_loss": 0.7075402331352234, "training_acc": 51.0, "val_loss": 0.7113248062133789, "val_acc": 48.0}
{"epoch": 4, "training_loss": 0.708332645893097, "training_acc": 51.0, "val_loss": 0.6952728629112244, "val_acc": 48.0}
{"epoch": 5, "training_loss": 0.7083030796051025, "training_acc": 49.0, "val_loss": 0.7023095035552979, "val_acc": 52.0}
{"epoch": 6, "training_loss": 0.7120745873451233, "training_acc": 41.0, "val_loss": 0.6928710007667541, "val_acc": 52.0}
{"epoch": 7, "training_loss": 0.6931277823448181, "training_acc": 53.0, "val_loss": 0.7148811292648315, "val_acc": 48.0}
{"epoch": 8, "training_loss": 0.7270979046821594, "training_acc": 51.0, "val_loss": 0.6951294589042664, "val_acc": 48.0}
{"epoch": 9, "training_loss": 0.6993383359909058, "training_acc": 44.0, "val_loss": 0.697007303237915, "val_acc": 48.0}
{"epoch": 10, "training_loss": 0.6991084909439087, "training_acc": 51.0, "val_loss": 0.6924438834190368, "val_acc": 52.0}
{"epoch": 11, "training_loss": 0.6978119683265686, "training_acc": 49.0, "val_loss": 0.6945752024650573, "val_acc": 52.0}
{"epoch": 12, "training_loss": 0.7040115451812744, "training_acc": 45.0, "val_loss": 0.6999213743209839, "val_acc": 48.0}
{"epoch": 13, "training_loss": 0.7055674314498901, "training_acc": 51.0, "val_loss": 0.6941096806526184, "val_acc": 52.0}
{"epoch": 14, "training_loss": 0.6950602149963379, "training_acc": 51.0, "val_loss": 0.7158020496368408, "val_acc": 48.0}
{"epoch": 15, "training_loss": 0.7084284067153931, "training_acc": 49.0, "val_loss": 0.6978432965278626, "val_acc": 48.0}
{"epoch": 16, "training_loss": 0.6991657614707947, "training_acc": 51.0, "val_loss": 0.6923685503005982, "val_acc": 52.0}
{"epoch": 17, "training_loss": 0.7022809076309204, "training_acc": 49.0, "val_loss": 0.6935934782028198, "val_acc": 48.0}
{"epoch": 18, "training_loss": 0.6991277551651001, "training_acc": 51.0, "val_loss": 0.6972742557525635, "val_acc": 48.0}
{"epoch": 19, "training_loss": 0.7030000376701355, "training_acc": 51.0, "val_loss": 0.6931258106231689, "val_acc": 52.0}
{"epoch": 20, "training_loss": 0.6961887693405151, "training_acc": 53.0, "val_loss": 0.6980328464508057, "val_acc": 48.0}
{"epoch": 21, "training_loss": 0.7047072172164917, "training_acc": 45.0, "val_loss": 0.6992513537406921, "val_acc": 48.0}
{"epoch": 22, "training_loss": 0.7079482340812683, "training_acc": 51.0, "val_loss": 0.7082186102867126, "val_acc": 48.0}
{"epoch": 23, "training_loss": 0.7009022474288941, "training_acc": 47.0, "val_loss": 0.6926639294624328, "val_acc": 52.0}
{"epoch": 24, "training_loss": 0.7101110196113587, "training_acc": 49.0, "val_loss": 0.7056037259101867, "val_acc": 48.0}
{"epoch": 25, "training_loss": 0.706195433139801, "training_acc": 51.0, "val_loss": 0.7132019448280335, "val_acc": 48.0}
{"epoch": 26, "training_loss": 0.7016242718696595, "training_acc": 51.0, "val_loss": 0.6923622465133668, "val_acc": 52.0}
{"epoch": 27, "training_loss": 0.7020876836776734, "training_acc": 43.0, "val_loss": 0.6924103617668151, "val_acc": 52.0}
{"epoch": 28, "training_loss": 0.6968506622314453, "training_acc": 45.0, "val_loss": 0.6925801634788513, "val_acc": 52.0}
{"epoch": 29, "training_loss": 0.6949421191215515, "training_acc": 49.0, "val_loss": 0.7091147017478943, "val_acc": 48.0}
{"epoch": 30, "training_loss": 0.7102777528762817, "training_acc": 51.0, "val_loss": 0.6950320053100586, "val_acc": 48.0}
{"epoch": 31, "training_loss": 0.698267068862915, "training_acc": 45.0, "val_loss": 0.6958418679237366, "val_acc": 48.0}
{"epoch": 32, "training_loss": 0.699125452041626, "training_acc": 49.0, "val_loss": 0.7149315595626831, "val_acc": 48.0}
{"epoch": 33, "training_loss": 0.7159131479263305, "training_acc": 51.0, "val_loss": 0.6957347702980041, "val_acc": 48.0}
{"epoch": 34, "training_loss": 0.6994521760940552, "training_acc": 51.0, "val_loss": 0.6935619473457336, "val_acc": 52.0}
{"epoch": 35, "training_loss": 0.7044482135772705, "training_acc": 41.0, "val_loss": 0.692964780330658, "val_acc": 52.0}
{"epoch": 36, "training_loss": 0.7027656865119934, "training_acc": 49.0, "val_loss": 0.6947103214263916, "val_acc": 48.0}
{"epoch": 37, "training_loss": 0.6968981719017029, "training_acc": 51.0, "val_loss": 0.6924286770820618, "val_acc": 52.0}
{"epoch": 38, "training_loss": 0.6982369089126587, "training_acc": 49.0, "val_loss": 0.6978894591331481, "val_acc": 52.0}
{"epoch": 39, "training_loss": 0.7148475980758667, "training_acc": 41.0, "val_loss": 0.6932054233551025, "val_acc": 52.0}
{"epoch": 40, "training_loss": 0.6986879253387451, "training_acc": 49.0, "val_loss": 0.7126362228393555, "val_acc": 48.0}
{"epoch": 41, "training_loss": 0.7001990294456482, "training_acc": 51.0, "val_loss": 0.6946507525444031, "val_acc": 48.0}
{"epoch": 42, "training_loss": 0.7025801086425781, "training_acc": 47.0, "val_loss": 0.7013483500480652, "val_acc": 48.0}
{"epoch": 43, "training_loss": 0.6991854429244995, "training_acc": 51.0, "val_loss": 0.6923475742340088, "val_acc": 52.0}
{"epoch": 44, "training_loss": 0.6960747480392456, "training_acc": 51.0, "val_loss": 0.698092269897461, "val_acc": 48.0}
{"epoch": 45, "training_loss": 0.6988170790672302, "training_acc": 51.0, "val_loss": 0.6929130911827087, "val_acc": 52.0}
{"epoch": 46, "training_loss": 0.7097572612762452, "training_acc": 43.0, "val_loss": 0.6924393844604492, "val_acc": 52.0}
{"epoch": 47, "training_loss": 0.6960723638534546, "training_acc": 49.0, "val_loss": 0.6938045048713684, "val_acc": 48.0}
{"epoch": 48, "training_loss": 0.7059799861907959, "training_acc": 43.0, "val_loss": 0.6925956344604492, "val_acc": 52.0}
{"epoch": 49, "training_loss": 0.7078656911849975, "training_acc": 49.0, "val_loss": 0.7082531857490539, "val_acc": 48.0}
{"epoch": 50, "training_loss": 0.7049943923950195, "training_acc": 51.0, "val_loss": 0.6928758668899536, "val_acc": 52.0}
{"epoch": 51, "training_loss": 0.7040661668777466, "training_acc": 49.0, "val_loss": 0.7069991397857666, "val_acc": 48.0}
{"epoch": 52, "training_loss": 0.6979537606239319, "training_acc": 51.0, "val_loss": 0.6923581314086914, "val_acc": 52.0}
{"epoch": 53, "training_loss": 0.7069789123535156, "training_acc": 49.0, "val_loss": 0.6954778790473938, "val_acc": 48.0}
{"epoch": 54, "training_loss": 0.6952355623245239, "training_acc": 51.0, "val_loss": 0.7109318971633911, "val_acc": 48.0}
{"epoch": 55, "training_loss": 0.7116264486312867, "training_acc": 43.0, "val_loss": 0.6974042534828186, "val_acc": 48.0}
{"epoch": 56, "training_loss": 0.6991569137573242, "training_acc": 39.0, "val_loss": 0.699775710105896, "val_acc": 48.0}
{"epoch": 57, "training_loss": 0.7030897331237793, "training_acc": 43.0, "val_loss": 0.6938597583770751, "val_acc": 48.0}
{"epoch": 58, "training_loss": 0.6990165567398071, "training_acc": 47.0, "val_loss": 0.6923496294021606, "val_acc": 52.0}
{"epoch": 59, "training_loss": 0.7062103271484375, "training_acc": 49.0, "val_loss": 0.6928202056884766, "val_acc": 52.0}
{"epoch": 60, "training_loss": 0.7157324552536011, "training_acc": 51.0, "val_loss": 0.6927242016792298, "val_acc": 52.0}
{"epoch": 61, "training_loss": 0.7042186093330384, "training_acc": 41.0, "val_loss": 0.6929897952079773, "val_acc": 52.0}
{"epoch": 62, "training_loss": 0.7012905144691467, "training_acc": 47.0, "val_loss": 0.7048813700675964, "val_acc": 48.0}
