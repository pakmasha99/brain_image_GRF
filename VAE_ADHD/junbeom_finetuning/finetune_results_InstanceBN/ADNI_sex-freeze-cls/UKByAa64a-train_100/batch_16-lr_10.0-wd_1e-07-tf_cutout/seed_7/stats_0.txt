"main_modify.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 7 --task ADNI_sex --input_option yAware --learning_rate 1e1 --batch_size 16 --weight_decay 1e-7 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 705.1069372940063, "training_acc": 47.0, "val_loss": 985.2005224609375, "val_acc": 48.0}
{"epoch": 1, "training_loss": 582.2302084350586, "training_acc": 47.0, "val_loss": 466.899169921875, "val_acc": 48.0}
{"epoch": 2, "training_loss": 427.0753491210937, "training_acc": 49.0, "val_loss": 376.68799682617185, "val_acc": 48.0}
{"epoch": 3, "training_loss": 523.53931640625, "training_acc": 45.0, "val_loss": 193.54773162841798, "val_acc": 52.0}
{"epoch": 4, "training_loss": 219.81865234375, "training_acc": 43.0, "val_loss": 206.3818701171875, "val_acc": 48.0}
{"epoch": 5, "training_loss": 183.01752685546876, "training_acc": 41.0, "val_loss": 183.98627014160155, "val_acc": 52.0}
{"epoch": 6, "training_loss": 255.06363220214843, "training_acc": 45.0, "val_loss": 159.33666931152345, "val_acc": 52.0}
{"epoch": 7, "training_loss": 172.55570373535156, "training_acc": 51.0, "val_loss": 57.268919982910155, "val_acc": 52.0}
{"epoch": 8, "training_loss": 491.996953125, "training_acc": 45.0, "val_loss": 514.9465637207031, "val_acc": 52.0}
{"epoch": 9, "training_loss": 482.42156372070315, "training_acc": 49.0, "val_loss": 622.0618237304687, "val_acc": 48.0}
{"epoch": 10, "training_loss": 255.13924926757812, "training_acc": 50.0, "val_loss": 111.61651763916015, "val_acc": 52.0}
{"epoch": 11, "training_loss": 124.00986877441406, "training_acc": 41.0, "val_loss": 59.388474197387694, "val_acc": 48.0}
{"epoch": 12, "training_loss": 221.96158813476563, "training_acc": 49.0, "val_loss": 89.33163208007812, "val_acc": 48.0}
{"epoch": 13, "training_loss": 213.166376953125, "training_acc": 47.0, "val_loss": 195.76007690429688, "val_acc": 52.0}
{"epoch": 14, "training_loss": 244.03430358886717, "training_acc": 57.0, "val_loss": 341.3222180175781, "val_acc": 48.0}
{"epoch": 15, "training_loss": 404.2397119140625, "training_acc": 45.0, "val_loss": 578.6619604492188, "val_acc": 48.0}
{"epoch": 16, "training_loss": 748.5066448974609, "training_acc": 53.0, "val_loss": 471.18690673828127, "val_acc": 52.0}
{"epoch": 17, "training_loss": 345.0316271972656, "training_acc": 53.0, "val_loss": 62.7973876953125, "val_acc": 48.0}
{"epoch": 18, "training_loss": 187.84690704345704, "training_acc": 53.0, "val_loss": 167.16386840820311, "val_acc": 52.0}
{"epoch": 19, "training_loss": 196.48777893066406, "training_acc": 47.0, "val_loss": 200.6065704345703, "val_acc": 52.0}
{"epoch": 20, "training_loss": 159.09557586669922, "training_acc": 55.0, "val_loss": 213.23078247070313, "val_acc": 52.0}
{"epoch": 21, "training_loss": 217.64538940429688, "training_acc": 46.0, "val_loss": 375.0605725097656, "val_acc": 48.0}
{"epoch": 22, "training_loss": 424.75773681640624, "training_acc": 53.0, "val_loss": 340.1434014892578, "val_acc": 52.0}
{"epoch": 23, "training_loss": 326.4468434143066, "training_acc": 51.0, "val_loss": 285.58257934570315, "val_acc": 52.0}
{"epoch": 24, "training_loss": 172.43022613525392, "training_acc": 55.0, "val_loss": 15.895326538085937, "val_acc": 64.0}
{"epoch": 25, "training_loss": 183.43465530395508, "training_acc": 52.0, "val_loss": 262.1236633300781, "val_acc": 48.0}
{"epoch": 26, "training_loss": 204.6304976388812, "training_acc": 59.0, "val_loss": 97.27790618896485, "val_acc": 48.0}
{"epoch": 27, "training_loss": 122.54495391845703, "training_acc": 47.0, "val_loss": 124.61974578857422, "val_acc": 52.0}
{"epoch": 28, "training_loss": 110.48912643432617, "training_acc": 56.0, "val_loss": 298.9191854858398, "val_acc": 48.0}
{"epoch": 29, "training_loss": 162.5044317626953, "training_acc": 56.0, "val_loss": 394.3024645996094, "val_acc": 48.0}
{"epoch": 30, "training_loss": 217.62015804290772, "training_acc": 57.0, "val_loss": 70.57588684082032, "val_acc": 52.0}
{"epoch": 31, "training_loss": 46.439370498657226, "training_acc": 51.0, "val_loss": 47.7670426940918, "val_acc": 56.0}
{"epoch": 32, "training_loss": 41.47972747802734, "training_acc": 62.0, "val_loss": 374.80511352539065, "val_acc": 48.0}
{"epoch": 33, "training_loss": 347.26770568847655, "training_acc": 51.0, "val_loss": 30.839929161071776, "val_acc": 60.0}
{"epoch": 34, "training_loss": 180.96534118652343, "training_acc": 53.0, "val_loss": 173.9876153564453, "val_acc": 48.0}
{"epoch": 35, "training_loss": 150.10748931884766, "training_acc": 57.0, "val_loss": 56.95111770629883, "val_acc": 60.0}
{"epoch": 36, "training_loss": 102.14388275146484, "training_acc": 53.0, "val_loss": 372.2809729003906, "val_acc": 52.0}
{"epoch": 37, "training_loss": 389.37947021484376, "training_acc": 51.0, "val_loss": 20.957509651184083, "val_acc": 60.0}
{"epoch": 38, "training_loss": 201.7845324707031, "training_acc": 50.0, "val_loss": 274.8518194580078, "val_acc": 52.0}
{"epoch": 39, "training_loss": 434.454287109375, "training_acc": 47.0, "val_loss": 339.14916625976565, "val_acc": 48.0}
{"epoch": 40, "training_loss": 209.83913604736327, "training_acc": 51.0, "val_loss": 90.60322540283204, "val_acc": 48.0}
{"epoch": 41, "training_loss": 219.76177978515625, "training_acc": 45.0, "val_loss": 56.24520263671875, "val_acc": 56.0}
{"epoch": 42, "training_loss": 99.14898803710938, "training_acc": 54.0, "val_loss": 31.503426284790038, "val_acc": 60.0}
{"epoch": 43, "training_loss": 262.47274291992187, "training_acc": 50.0, "val_loss": 498.6204150390625, "val_acc": 52.0}
