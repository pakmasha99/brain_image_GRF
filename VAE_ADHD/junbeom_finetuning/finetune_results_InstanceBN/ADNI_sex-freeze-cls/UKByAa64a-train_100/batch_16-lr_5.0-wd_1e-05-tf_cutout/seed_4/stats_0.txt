"main_modify.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 4 --task ADNI_sex --input_option yAware --learning_rate 5e0 --batch_size 16 --weight_decay 1e-5 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 519.5716142654419, "training_acc": 51.0, "val_loss": 240.38042846679687, "val_acc": 48.0}
{"epoch": 1, "training_loss": 154.4025814819336, "training_acc": 47.0, "val_loss": 76.23550567626953, "val_acc": 52.0}
{"epoch": 2, "training_loss": 65.8501626586914, "training_acc": 53.0, "val_loss": 85.51420837402344, "val_acc": 48.0}
{"epoch": 3, "training_loss": 74.10464691162109, "training_acc": 49.0, "val_loss": 165.85175048828125, "val_acc": 52.0}
{"epoch": 4, "training_loss": 237.93483276367186, "training_acc": 35.0, "val_loss": 226.14924194335939, "val_acc": 52.0}
{"epoch": 5, "training_loss": 166.37847900390625, "training_acc": 53.0, "val_loss": 111.98686370849609, "val_acc": 52.0}
{"epoch": 6, "training_loss": 212.87808471679688, "training_acc": 49.0, "val_loss": 461.61867431640627, "val_acc": 48.0}
{"epoch": 7, "training_loss": 198.3777410888672, "training_acc": 53.0, "val_loss": 100.19131256103516, "val_acc": 48.0}
{"epoch": 8, "training_loss": 103.91330505371094, "training_acc": 47.0, "val_loss": 227.58212219238283, "val_acc": 48.0}
{"epoch": 9, "training_loss": 126.19107421875, "training_acc": 55.0, "val_loss": 174.56145812988282, "val_acc": 48.0}
{"epoch": 10, "training_loss": 193.927314453125, "training_acc": 55.0, "val_loss": 302.3078869628906, "val_acc": 52.0}
{"epoch": 11, "training_loss": 301.83610168457034, "training_acc": 46.0, "val_loss": 132.471884765625, "val_acc": 48.0}
{"epoch": 12, "training_loss": 179.16322906494142, "training_acc": 53.0, "val_loss": 505.2941748046875, "val_acc": 48.0}
{"epoch": 13, "training_loss": 457.54905212402343, "training_acc": 47.0, "val_loss": 422.91087524414064, "val_acc": 52.0}
{"epoch": 14, "training_loss": 277.31708862304686, "training_acc": 51.0, "val_loss": 186.88438537597656, "val_acc": 48.0}
{"epoch": 15, "training_loss": 104.43398620605468, "training_acc": 49.0, "val_loss": 50.68781799316406, "val_acc": 52.0}
{"epoch": 16, "training_loss": 95.73544807434082, "training_acc": 50.0, "val_loss": 104.072431640625, "val_acc": 52.0}
{"epoch": 17, "training_loss": 161.0182501220703, "training_acc": 45.0, "val_loss": 181.08030181884766, "val_acc": 52.0}
{"epoch": 18, "training_loss": 119.12273559570312, "training_acc": 43.0, "val_loss": 181.09694641113282, "val_acc": 52.0}
{"epoch": 19, "training_loss": 181.8230453491211, "training_acc": 45.0, "val_loss": 181.2364874267578, "val_acc": 52.0}
{"epoch": 20, "training_loss": 151.5571324157715, "training_acc": 51.0, "val_loss": 113.66040100097656, "val_acc": 52.0}
{"epoch": 21, "training_loss": 139.29946533203125, "training_acc": 55.0, "val_loss": 254.0172283935547, "val_acc": 48.0}
{"epoch": 22, "training_loss": 170.16907348632813, "training_acc": 49.0, "val_loss": 183.69165954589843, "val_acc": 48.0}
{"epoch": 23, "training_loss": 115.949193649292, "training_acc": 61.0, "val_loss": 19.306250114440918, "val_acc": 52.0}
{"epoch": 24, "training_loss": 40.11747566223144, "training_acc": 59.0, "val_loss": 104.73254364013673, "val_acc": 52.0}
{"epoch": 25, "training_loss": 102.92158218383788, "training_acc": 53.0, "val_loss": 100.92869415283204, "val_acc": 52.0}
{"epoch": 26, "training_loss": 54.06021728515625, "training_acc": 49.0, "val_loss": 175.07111206054688, "val_acc": 48.0}
{"epoch": 27, "training_loss": 73.28435943603516, "training_acc": 54.0, "val_loss": 120.48761779785156, "val_acc": 52.0}
{"epoch": 28, "training_loss": 66.97921264648437, "training_acc": 54.0, "val_loss": 20.640586013793946, "val_acc": 52.0}
{"epoch": 29, "training_loss": 20.561414680480958, "training_acc": 59.0, "val_loss": 57.91608428955078, "val_acc": 48.0}
{"epoch": 30, "training_loss": 33.57424659729004, "training_acc": 58.0, "val_loss": 24.223180351257323, "val_acc": 52.0}
{"epoch": 31, "training_loss": 64.2687232208252, "training_acc": 54.0, "val_loss": 126.0035205078125, "val_acc": 48.0}
{"epoch": 32, "training_loss": 110.06173950195313, "training_acc": 59.0, "val_loss": 102.20513763427735, "val_acc": 48.0}
{"epoch": 33, "training_loss": 141.23775749206544, "training_acc": 49.0, "val_loss": 267.2322332763672, "val_acc": 48.0}
{"epoch": 34, "training_loss": 341.77912841796876, "training_acc": 47.0, "val_loss": 184.83971984863283, "val_acc": 52.0}
{"epoch": 35, "training_loss": 138.1341403198242, "training_acc": 53.0, "val_loss": 114.52822784423829, "val_acc": 52.0}
{"epoch": 36, "training_loss": 62.912635498046875, "training_acc": 49.0, "val_loss": 137.27639892578125, "val_acc": 48.0}
{"epoch": 37, "training_loss": 81.80363525390625, "training_acc": 52.0, "val_loss": 64.91202682495117, "val_acc": 48.0}
{"epoch": 38, "training_loss": 119.88582275390625, "training_acc": 53.0, "val_loss": 321.253056640625, "val_acc": 48.0}
{"epoch": 39, "training_loss": 232.9201232910156, "training_acc": 37.0, "val_loss": 305.64591918945314, "val_acc": 48.0}
{"epoch": 40, "training_loss": 237.44275146484375, "training_acc": 45.0, "val_loss": 116.80441589355469, "val_acc": 48.0}
{"epoch": 41, "training_loss": 189.47920608520508, "training_acc": 52.0, "val_loss": 205.0160974121094, "val_acc": 52.0}
{"epoch": 42, "training_loss": 166.2155451965332, "training_acc": 51.0, "val_loss": 181.14621704101563, "val_acc": 52.0}
