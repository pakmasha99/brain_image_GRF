"main_modify.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 4 --task ADNI_sex --input_option yAware --learning_rate 5e0 --batch_size 16 --weight_decay 1e-5 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 515.7810925388336, "training_acc": 54.0, "val_loss": 172.75250030517577, "val_acc": 52.0}
{"epoch": 1, "training_loss": 171.92422897338867, "training_acc": 48.0, "val_loss": 365.2037023925781, "val_acc": 52.0}
{"epoch": 2, "training_loss": 252.0312109375, "training_acc": 58.0, "val_loss": 540.8319519042968, "val_acc": 48.0}
{"epoch": 3, "training_loss": 262.93817443847655, "training_acc": 58.0, "val_loss": 61.09873550415039, "val_acc": 52.0}
{"epoch": 4, "training_loss": 241.3186474609375, "training_acc": 48.0, "val_loss": 377.80541015625, "val_acc": 52.0}
{"epoch": 5, "training_loss": 323.554365234375, "training_acc": 48.0, "val_loss": 404.19531494140625, "val_acc": 48.0}
{"epoch": 6, "training_loss": 184.7327911376953, "training_acc": 52.0, "val_loss": 224.9411474609375, "val_acc": 48.0}
{"epoch": 7, "training_loss": 193.50429473876954, "training_acc": 50.0, "val_loss": 138.2060919189453, "val_acc": 48.0}
{"epoch": 8, "training_loss": 158.5026693725586, "training_acc": 48.0, "val_loss": 37.299229278564454, "val_acc": 48.0}
{"epoch": 9, "training_loss": 54.857670593261716, "training_acc": 50.0, "val_loss": 195.50537109375, "val_acc": 52.0}
{"epoch": 10, "training_loss": 102.84336822509766, "training_acc": 50.0, "val_loss": 83.72763992309571, "val_acc": 52.0}
{"epoch": 11, "training_loss": 74.9024609375, "training_acc": 44.0, "val_loss": 53.063052291870115, "val_acc": 48.0}
{"epoch": 12, "training_loss": 131.83868328094482, "training_acc": 50.0, "val_loss": 156.698388671875, "val_acc": 48.0}
{"epoch": 13, "training_loss": 74.37229644775391, "training_acc": 54.0, "val_loss": 63.72887664794922, "val_acc": 52.0}
{"epoch": 14, "training_loss": 73.72774047851563, "training_acc": 54.0, "val_loss": 112.69088775634765, "val_acc": 52.0}
{"epoch": 15, "training_loss": 118.74425537109374, "training_acc": 60.0, "val_loss": 234.21999938964845, "val_acc": 52.0}
{"epoch": 16, "training_loss": 206.9808349609375, "training_acc": 54.0, "val_loss": 323.320791015625, "val_acc": 48.0}
{"epoch": 17, "training_loss": 163.0436962890625, "training_acc": 62.0, "val_loss": 157.35348663330078, "val_acc": 52.0}
{"epoch": 18, "training_loss": 79.0900528717041, "training_acc": 49.0, "val_loss": 209.676865234375, "val_acc": 48.0}
{"epoch": 19, "training_loss": 201.63934143066408, "training_acc": 48.0, "val_loss": 36.09536392211914, "val_acc": 48.0}
{"epoch": 20, "training_loss": 48.45878711700439, "training_acc": 54.0, "val_loss": 14.753339424133301, "val_acc": 52.0}
{"epoch": 21, "training_loss": 78.02013870239257, "training_acc": 59.0, "val_loss": 9.199787483215331, "val_acc": 48.0}
{"epoch": 22, "training_loss": 55.43624626159668, "training_acc": 46.0, "val_loss": 42.19406845092774, "val_acc": 48.0}
{"epoch": 23, "training_loss": 64.66976379394531, "training_acc": 58.0, "val_loss": 93.8684002685547, "val_acc": 48.0}
{"epoch": 24, "training_loss": 94.99928878784179, "training_acc": 54.0, "val_loss": 33.67997932434082, "val_acc": 52.0}
{"epoch": 25, "training_loss": 38.73710906982422, "training_acc": 52.0, "val_loss": 41.06517715454102, "val_acc": 48.0}
{"epoch": 26, "training_loss": 35.07073738098145, "training_acc": 58.0, "val_loss": 107.81150146484374, "val_acc": 52.0}
{"epoch": 27, "training_loss": 57.0766215346707, "training_acc": 52.0, "val_loss": 8.41067071914673, "val_acc": 68.0}
{"epoch": 28, "training_loss": 14.22474153250456, "training_acc": 65.0, "val_loss": 4.482406702041626, "val_acc": 76.0}
{"epoch": 29, "training_loss": 49.779843978881836, "training_acc": 55.0, "val_loss": 60.081341857910154, "val_acc": 52.0}
{"epoch": 30, "training_loss": 54.95272975921631, "training_acc": 54.0, "val_loss": 66.37824981689454, "val_acc": 48.0}
{"epoch": 31, "training_loss": 95.07776000976563, "training_acc": 48.0, "val_loss": 148.4671011352539, "val_acc": 48.0}
{"epoch": 32, "training_loss": 127.85553735733032, "training_acc": 55.0, "val_loss": 213.81718872070311, "val_acc": 48.0}
{"epoch": 33, "training_loss": 89.60816162109376, "training_acc": 63.0, "val_loss": 176.50101623535156, "val_acc": 48.0}
{"epoch": 34, "training_loss": 113.05118598937989, "training_acc": 58.0, "val_loss": 17.038249855041503, "val_acc": 48.0}
{"epoch": 35, "training_loss": 23.119863815307617, "training_acc": 56.0, "val_loss": 114.18169738769531, "val_acc": 52.0}
{"epoch": 36, "training_loss": 115.17564956665039, "training_acc": 50.0, "val_loss": 46.32539993286133, "val_acc": 48.0}
{"epoch": 37, "training_loss": 93.47603607177734, "training_acc": 50.0, "val_loss": 83.17562957763671, "val_acc": 48.0}
{"epoch": 38, "training_loss": 38.10380172729492, "training_acc": 51.0, "val_loss": 184.3192755126953, "val_acc": 52.0}
{"epoch": 39, "training_loss": 208.12286254882812, "training_acc": 48.0, "val_loss": 61.3640771484375, "val_acc": 48.0}
{"epoch": 40, "training_loss": 260.2870225524902, "training_acc": 52.0, "val_loss": 246.26904907226563, "val_acc": 48.0}
{"epoch": 41, "training_loss": 206.71427490234376, "training_acc": 52.0, "val_loss": 99.8687368774414, "val_acc": 52.0}
{"epoch": 42, "training_loss": 292.18798568725583, "training_acc": 44.0, "val_loss": 349.66788818359373, "val_acc": 52.0}
{"epoch": 43, "training_loss": 277.44938201904296, "training_acc": 54.0, "val_loss": 683.333857421875, "val_acc": 48.0}
{"epoch": 44, "training_loss": 728.2835803222656, "training_acc": 50.0, "val_loss": 217.4044903564453, "val_acc": 52.0}
{"epoch": 45, "training_loss": 542.2361029052735, "training_acc": 50.0, "val_loss": 116.95512573242188, "val_acc": 48.0}
{"epoch": 46, "training_loss": 225.58199951171875, "training_acc": 46.0, "val_loss": 317.5541979980469, "val_acc": 52.0}
{"epoch": 47, "training_loss": 211.57925537109375, "training_acc": 54.0, "val_loss": 75.72599700927735, "val_acc": 48.0}
