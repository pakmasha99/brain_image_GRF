"main_modify.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 7 --task ADNI_sex --input_option yAware --learning_rate 5e0 --batch_size 16 --weight_decay 1e-5 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 352.6020325088501, "training_acc": 47.0, "val_loss": 492.72551513671874, "val_acc": 48.0}
{"epoch": 1, "training_loss": 291.08984008789065, "training_acc": 47.0, "val_loss": 233.54166137695313, "val_acc": 48.0}
{"epoch": 2, "training_loss": 213.52623779296874, "training_acc": 49.0, "val_loss": 188.46328063964845, "val_acc": 48.0}
{"epoch": 3, "training_loss": 261.84795654296875, "training_acc": 45.0, "val_loss": 96.72288436889649, "val_acc": 52.0}
{"epoch": 4, "training_loss": 109.91243560791015, "training_acc": 43.0, "val_loss": 103.22596557617187, "val_acc": 48.0}
{"epoch": 5, "training_loss": 91.53288299560546, "training_acc": 41.0, "val_loss": 92.02120697021485, "val_acc": 52.0}
{"epoch": 6, "training_loss": 127.55695037841797, "training_acc": 45.0, "val_loss": 79.71865234375, "val_acc": 52.0}
{"epoch": 7, "training_loss": 86.28607208251952, "training_acc": 51.0, "val_loss": 28.7039151763916, "val_acc": 52.0}
{"epoch": 8, "training_loss": 245.98218017578125, "training_acc": 45.0, "val_loss": 257.6124139404297, "val_acc": 52.0}
{"epoch": 9, "training_loss": 241.28097229003907, "training_acc": 49.0, "val_loss": 310.9168542480469, "val_acc": 48.0}
{"epoch": 10, "training_loss": 127.50384674072265, "training_acc": 50.0, "val_loss": 59.57859497070312, "val_acc": 52.0}
{"epoch": 11, "training_loss": 63.73716064453125, "training_acc": 41.0, "val_loss": 17.784164276123047, "val_acc": 60.0}
{"epoch": 12, "training_loss": 115.84373550415039, "training_acc": 48.0, "val_loss": 85.1506103515625, "val_acc": 48.0}
{"epoch": 13, "training_loss": 66.85548107147217, "training_acc": 53.0, "val_loss": 95.65976531982422, "val_acc": 52.0}
{"epoch": 14, "training_loss": 64.11001800537109, "training_acc": 51.0, "val_loss": 140.67319458007813, "val_acc": 48.0}
{"epoch": 15, "training_loss": 99.79721099853515, "training_acc": 53.0, "val_loss": 176.13607543945312, "val_acc": 48.0}
{"epoch": 16, "training_loss": 144.27750534057617, "training_acc": 51.0, "val_loss": 128.96509216308593, "val_acc": 48.0}
{"epoch": 17, "training_loss": 196.75727416992189, "training_acc": 47.0, "val_loss": 168.22734619140624, "val_acc": 52.0}
{"epoch": 18, "training_loss": 113.83340362548829, "training_acc": 47.0, "val_loss": 155.95026000976563, "val_acc": 52.0}
{"epoch": 19, "training_loss": 171.23794067382812, "training_acc": 45.0, "val_loss": 176.89516723632812, "val_acc": 52.0}
{"epoch": 20, "training_loss": 106.74708251953125, "training_acc": 55.0, "val_loss": 124.020380859375, "val_acc": 52.0}
{"epoch": 21, "training_loss": 114.30448928833007, "training_acc": 40.0, "val_loss": 29.054780426025392, "val_acc": 56.0}
{"epoch": 22, "training_loss": 47.57956390380859, "training_acc": 51.0, "val_loss": 10.03030616760254, "val_acc": 60.0}
{"epoch": 23, "training_loss": 16.625834655761718, "training_acc": 60.0, "val_loss": 11.855733871459961, "val_acc": 60.0}
{"epoch": 24, "training_loss": 26.523799591064453, "training_acc": 58.0, "val_loss": 123.20887756347656, "val_acc": 48.0}
{"epoch": 25, "training_loss": 103.30539733886718, "training_acc": 50.0, "val_loss": 117.28849426269531, "val_acc": 48.0}
{"epoch": 26, "training_loss": 40.95022262573242, "training_acc": 57.0, "val_loss": 180.53930786132813, "val_acc": 52.0}
{"epoch": 27, "training_loss": 181.02580276489257, "training_acc": 47.0, "val_loss": 195.3480987548828, "val_acc": 52.0}
{"epoch": 28, "training_loss": 260.77328125, "training_acc": 45.0, "val_loss": 422.2755242919922, "val_acc": 48.0}
{"epoch": 29, "training_loss": 244.02942016601563, "training_acc": 49.0, "val_loss": 65.11154846191407, "val_acc": 48.0}
{"epoch": 30, "training_loss": 171.30416076660157, "training_acc": 55.0, "val_loss": 250.92013916015625, "val_acc": 52.0}
{"epoch": 31, "training_loss": 214.36242973327637, "training_acc": 55.0, "val_loss": 74.4300161743164, "val_acc": 48.0}
{"epoch": 32, "training_loss": 248.9801123046875, "training_acc": 51.0, "val_loss": 336.91463256835937, "val_acc": 48.0}
{"epoch": 33, "training_loss": 267.6211962890625, "training_acc": 51.0, "val_loss": 372.34485229492185, "val_acc": 52.0}
{"epoch": 34, "training_loss": 209.43244384765626, "training_acc": 53.0, "val_loss": 117.37232391357422, "val_acc": 52.0}
{"epoch": 35, "training_loss": 151.51661239624025, "training_acc": 45.0, "val_loss": 71.84113967895507, "val_acc": 52.0}
{"epoch": 36, "training_loss": 124.0784226989746, "training_acc": 50.0, "val_loss": 12.943941345214844, "val_acc": 68.0}
{"epoch": 37, "training_loss": 69.09610717430391, "training_acc": 56.0, "val_loss": 123.38499786376953, "val_acc": 52.0}
{"epoch": 38, "training_loss": 79.75616470336914, "training_acc": 55.0, "val_loss": 101.42202209472656, "val_acc": 52.0}
{"epoch": 39, "training_loss": 106.92835754394531, "training_acc": 53.0, "val_loss": 286.234375, "val_acc": 52.0}
{"epoch": 40, "training_loss": 248.59360382080078, "training_acc": 50.0, "val_loss": 362.7130029296875, "val_acc": 48.0}
{"epoch": 41, "training_loss": 146.09835876464842, "training_acc": 53.0, "val_loss": 166.7115625, "val_acc": 48.0}
