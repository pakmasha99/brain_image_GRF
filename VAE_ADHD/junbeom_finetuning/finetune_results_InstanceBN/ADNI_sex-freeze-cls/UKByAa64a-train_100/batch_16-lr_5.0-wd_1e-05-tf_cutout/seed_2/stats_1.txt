"main_modify.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 2 --task ADNI_sex --input_option yAware --learning_rate 5e0 --batch_size 16 --weight_decay 1e-5 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 209.66676780700683, "training_acc": 51.0, "val_loss": 275.5703594970703, "val_acc": 48.0}
{"epoch": 1, "training_loss": 279.64427734375, "training_acc": 56.0, "val_loss": 202.6028759765625, "val_acc": 52.0}
{"epoch": 2, "training_loss": 189.47425415039064, "training_acc": 52.0, "val_loss": 466.87660400390627, "val_acc": 52.0}
{"epoch": 3, "training_loss": 412.71112548828125, "training_acc": 42.0, "val_loss": 328.02388427734377, "val_acc": 48.0}
{"epoch": 4, "training_loss": 279.4236376953125, "training_acc": 50.0, "val_loss": 190.43871459960937, "val_acc": 48.0}
{"epoch": 5, "training_loss": 411.50104370117185, "training_acc": 50.0, "val_loss": 282.9842785644531, "val_acc": 52.0}
{"epoch": 6, "training_loss": 223.81764938354493, "training_acc": 53.0, "val_loss": 302.9665783691406, "val_acc": 48.0}
{"epoch": 7, "training_loss": 112.71799499511718, "training_acc": 50.0, "val_loss": 58.50017822265625, "val_acc": 52.0}
{"epoch": 8, "training_loss": 32.83850326538086, "training_acc": 58.0, "val_loss": 68.38393646240235, "val_acc": 48.0}
{"epoch": 9, "training_loss": 78.11273704528809, "training_acc": 48.0, "val_loss": 219.15266967773437, "val_acc": 52.0}
{"epoch": 10, "training_loss": 290.30633666992185, "training_acc": 46.0, "val_loss": 402.66083251953125, "val_acc": 48.0}
{"epoch": 11, "training_loss": 303.92560424804685, "training_acc": 46.0, "val_loss": 176.6247003173828, "val_acc": 52.0}
{"epoch": 12, "training_loss": 95.34944980621339, "training_acc": 44.0, "val_loss": 89.07841705322265, "val_acc": 48.0}
{"epoch": 13, "training_loss": 86.72344665527343, "training_acc": 48.0, "val_loss": 226.49547302246094, "val_acc": 48.0}
{"epoch": 14, "training_loss": 119.4917264175415, "training_acc": 55.0, "val_loss": 259.05592529296877, "val_acc": 48.0}
{"epoch": 15, "training_loss": 188.69843551635742, "training_acc": 42.0, "val_loss": 11.998389663696289, "val_acc": 60.0}
{"epoch": 16, "training_loss": 58.417715606689455, "training_acc": 53.0, "val_loss": 126.75541381835937, "val_acc": 52.0}
{"epoch": 17, "training_loss": 107.59439338684082, "training_acc": 52.0, "val_loss": 138.24657806396485, "val_acc": 52.0}
{"epoch": 18, "training_loss": 120.13574676513672, "training_acc": 45.0, "val_loss": 14.127619031826034, "val_acc": 64.0}
{"epoch": 19, "training_loss": 43.51117614746094, "training_acc": 55.0, "val_loss": 77.53105026245117, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.1855419921875, "training_acc": 49.0, "val_loss": 59.19016204833984, "val_acc": 52.0}
{"epoch": 21, "training_loss": 55.87400253295898, "training_acc": 46.0, "val_loss": 108.04558624267578, "val_acc": 52.0}
{"epoch": 22, "training_loss": 143.00213675498964, "training_acc": 43.0, "val_loss": 139.19013122558593, "val_acc": 52.0}
{"epoch": 23, "training_loss": 187.4214953613281, "training_acc": 44.0, "val_loss": 183.42121337890626, "val_acc": 52.0}
{"epoch": 24, "training_loss": 216.72064880371093, "training_acc": 52.0, "val_loss": 168.37162536621094, "val_acc": 48.0}
{"epoch": 25, "training_loss": 157.96447692871095, "training_acc": 47.0, "val_loss": 264.4932958984375, "val_acc": 48.0}
{"epoch": 26, "training_loss": 165.7195263671875, "training_acc": 62.0, "val_loss": 312.05413330078125, "val_acc": 52.0}
{"epoch": 27, "training_loss": 240.2028402709961, "training_acc": 42.0, "val_loss": 117.96098510742188, "val_acc": 52.0}
{"epoch": 28, "training_loss": 72.99754600524902, "training_acc": 45.0, "val_loss": 136.89858337402345, "val_acc": 48.0}
{"epoch": 29, "training_loss": 78.26454284667969, "training_acc": 43.0, "val_loss": 12.837024765014649, "val_acc": 64.0}
{"epoch": 30, "training_loss": 49.51988773345947, "training_acc": 50.0, "val_loss": 25.919835243225098, "val_acc": 64.0}
{"epoch": 31, "training_loss": 24.16316390991211, "training_acc": 56.0, "val_loss": 14.492972984313965, "val_acc": 64.0}
{"epoch": 32, "training_loss": 14.75229766845703, "training_acc": 60.0, "val_loss": 42.51823196411133, "val_acc": 48.0}
{"epoch": 33, "training_loss": 20.466623001098633, "training_acc": 63.0, "val_loss": 24.688909912109374, "val_acc": 60.0}
{"epoch": 34, "training_loss": 23.60696517944336, "training_acc": 53.0, "val_loss": 14.013837890625, "val_acc": 60.0}
