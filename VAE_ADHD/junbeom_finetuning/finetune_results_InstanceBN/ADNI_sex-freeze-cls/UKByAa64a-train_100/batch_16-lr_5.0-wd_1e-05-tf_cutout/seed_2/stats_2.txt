"main_modify.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 2 --task ADNI_sex --input_option yAware --learning_rate 5e0 --batch_size 16 --weight_decay 1e-5 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 380.31728353500364, "training_acc": 54.0, "val_loss": 286.8065478515625, "val_acc": 52.0}
{"epoch": 1, "training_loss": 248.87819549560547, "training_acc": 48.0, "val_loss": 465.77679321289065, "val_acc": 52.0}
{"epoch": 2, "training_loss": 347.42583984375, "training_acc": 46.0, "val_loss": 92.08798431396484, "val_acc": 48.0}
{"epoch": 3, "training_loss": 155.7791424560547, "training_acc": 52.0, "val_loss": 208.878427734375, "val_acc": 48.0}
{"epoch": 4, "training_loss": 88.39273468017578, "training_acc": 52.0, "val_loss": 146.80502563476563, "val_acc": 52.0}
{"epoch": 5, "training_loss": 95.92779579162598, "training_acc": 46.0, "val_loss": 219.80307861328126, "val_acc": 48.0}
{"epoch": 6, "training_loss": 212.50453857421874, "training_acc": 54.0, "val_loss": 375.8627661132812, "val_acc": 52.0}
{"epoch": 7, "training_loss": 219.4214190673828, "training_acc": 54.0, "val_loss": 9.169869384765626, "val_acc": 48.0}
{"epoch": 8, "training_loss": 174.36117668151854, "training_acc": 46.0, "val_loss": 126.80653381347656, "val_acc": 48.0}
{"epoch": 9, "training_loss": 189.39799072265626, "training_acc": 44.0, "val_loss": 213.7518408203125, "val_acc": 48.0}
{"epoch": 10, "training_loss": 167.1000897216797, "training_acc": 46.0, "val_loss": 279.67307250976563, "val_acc": 48.0}
{"epoch": 11, "training_loss": 337.1790881347656, "training_acc": 50.0, "val_loss": 359.66435668945314, "val_acc": 52.0}
{"epoch": 12, "training_loss": 335.35984619140623, "training_acc": 40.0, "val_loss": 72.67462036132812, "val_acc": 48.0}
{"epoch": 13, "training_loss": 222.99568908691407, "training_acc": 50.0, "val_loss": 261.624169921875, "val_acc": 48.0}
{"epoch": 14, "training_loss": 225.12654907226562, "training_acc": 48.0, "val_loss": 49.48628860473633, "val_acc": 48.0}
{"epoch": 15, "training_loss": 89.57090339660644, "training_acc": 52.0, "val_loss": 27.739090881347657, "val_acc": 48.0}
{"epoch": 16, "training_loss": 60.615836448669434, "training_acc": 49.0, "val_loss": 153.18115661621093, "val_acc": 52.0}
{"epoch": 17, "training_loss": 106.77351440429688, "training_acc": 64.0, "val_loss": 27.83090606689453, "val_acc": 48.0}
{"epoch": 18, "training_loss": 169.3603515625, "training_acc": 44.0, "val_loss": 301.37690368652346, "val_acc": 48.0}
{"epoch": 19, "training_loss": 104.15648330688477, "training_acc": 55.0, "val_loss": 48.44188003540039, "val_acc": 52.0}
{"epoch": 20, "training_loss": 42.46303867340088, "training_acc": 54.0, "val_loss": 47.979487609863284, "val_acc": 48.0}
{"epoch": 21, "training_loss": 21.718933181762694, "training_acc": 67.0, "val_loss": 101.7974462890625, "val_acc": 48.0}
{"epoch": 22, "training_loss": 85.8120037841797, "training_acc": 50.0, "val_loss": 244.25764526367186, "val_acc": 48.0}
{"epoch": 23, "training_loss": 116.97004089355468, "training_acc": 48.0, "val_loss": 33.765522689819335, "val_acc": 52.0}
{"epoch": 24, "training_loss": 49.62685494765639, "training_acc": 52.0, "val_loss": 44.787631072998046, "val_acc": 48.0}
{"epoch": 25, "training_loss": 52.012738647460935, "training_acc": 44.0, "val_loss": 110.81492767333984, "val_acc": 48.0}
{"epoch": 26, "training_loss": 165.73128540039062, "training_acc": 48.0, "val_loss": 172.422490234375, "val_acc": 52.0}
