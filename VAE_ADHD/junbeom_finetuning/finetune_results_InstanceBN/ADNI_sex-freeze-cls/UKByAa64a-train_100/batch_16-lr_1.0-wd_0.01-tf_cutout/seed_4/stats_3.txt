"main_modify.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 4 --task ADNI_sex --input_option yAware --learning_rate 1e0 --batch_size 16 --weight_decay 1e-2 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 110.99556400299072, "training_acc": 48.0, "val_loss": 26.831347579956056, "val_acc": 52.0}
{"epoch": 1, "training_loss": 55.7236279296875, "training_acc": 48.0, "val_loss": 63.36173721313477, "val_acc": 48.0}
{"epoch": 2, "training_loss": 28.299734039306642, "training_acc": 54.0, "val_loss": 42.01778793334961, "val_acc": 48.0}
{"epoch": 3, "training_loss": 30.992237758636474, "training_acc": 45.0, "val_loss": 45.977006072998044, "val_acc": 48.0}
{"epoch": 4, "training_loss": 21.98891677856445, "training_acc": 48.0, "val_loss": 11.628268852233887, "val_acc": 48.0}
{"epoch": 5, "training_loss": 32.80279628753662, "training_acc": 48.0, "val_loss": 34.53610633850098, "val_acc": 48.0}
{"epoch": 6, "training_loss": 11.296423683166504, "training_acc": 56.0, "val_loss": 5.858723793029785, "val_acc": 52.0}
{"epoch": 7, "training_loss": 6.465953845977783, "training_acc": 47.0, "val_loss": 13.307797393798829, "val_acc": 48.0}
{"epoch": 8, "training_loss": 13.298266916275024, "training_acc": 42.0, "val_loss": 20.312558555603026, "val_acc": 48.0}
{"epoch": 9, "training_loss": 13.837314262390137, "training_acc": 54.0, "val_loss": 39.05324310302734, "val_acc": 48.0}
{"epoch": 10, "training_loss": 16.41316839877516, "training_acc": 46.0, "val_loss": 13.06414249420166, "val_acc": 48.0}
{"epoch": 11, "training_loss": 16.00408239364624, "training_acc": 52.0, "val_loss": 26.452593536376952, "val_acc": 48.0}
{"epoch": 12, "training_loss": 25.2114807510376, "training_acc": 56.0, "val_loss": 49.664429626464845, "val_acc": 48.0}
{"epoch": 13, "training_loss": 36.55193252563477, "training_acc": 58.0, "val_loss": 54.6920947265625, "val_acc": 52.0}
{"epoch": 14, "training_loss": 55.1410116481781, "training_acc": 42.0, "val_loss": 10.919723587036133, "val_acc": 52.0}
{"epoch": 15, "training_loss": 14.749859085083008, "training_acc": 40.0, "val_loss": 27.601234283447265, "val_acc": 52.0}
{"epoch": 16, "training_loss": 37.103495864868165, "training_acc": 54.0, "val_loss": 106.18006103515626, "val_acc": 48.0}
{"epoch": 17, "training_loss": 69.1649690246582, "training_acc": 50.0, "val_loss": 100.674658203125, "val_acc": 52.0}
{"epoch": 18, "training_loss": 64.06914123535157, "training_acc": 52.0, "val_loss": 56.708994140625, "val_acc": 48.0}
{"epoch": 19, "training_loss": 68.59581352233887, "training_acc": 54.0, "val_loss": 36.46765686035156, "val_acc": 52.0}
{"epoch": 20, "training_loss": 45.55385261535645, "training_acc": 46.0, "val_loss": 64.4743049621582, "val_acc": 52.0}
{"epoch": 21, "training_loss": 56.05965148925781, "training_acc": 44.0, "val_loss": 8.690087013244629, "val_acc": 48.0}
{"epoch": 22, "training_loss": 28.17469940185547, "training_acc": 50.0, "val_loss": 54.0333740234375, "val_acc": 48.0}
{"epoch": 23, "training_loss": 21.83678771018982, "training_acc": 47.0, "val_loss": 0.630462486743927, "val_acc": 60.0}
{"epoch": 24, "training_loss": 11.301037464141846, "training_acc": 56.0, "val_loss": 37.34897338867187, "val_acc": 52.0}
{"epoch": 25, "training_loss": 22.62456554412842, "training_acc": 48.0, "val_loss": 5.464405851364136, "val_acc": 52.0}
{"epoch": 26, "training_loss": 30.608621368408205, "training_acc": 50.0, "val_loss": 70.13228607177734, "val_acc": 52.0}
{"epoch": 27, "training_loss": 57.99239471435547, "training_acc": 50.0, "val_loss": 89.86544464111329, "val_acc": 48.0}
{"epoch": 28, "training_loss": 84.8844580078125, "training_acc": 46.0, "val_loss": 69.370751953125, "val_acc": 52.0}
{"epoch": 29, "training_loss": 89.09173141479492, "training_acc": 52.0, "val_loss": 81.19992706298828, "val_acc": 48.0}
{"epoch": 30, "training_loss": 48.99165023803711, "training_acc": 58.0, "val_loss": 7.436196575164795, "val_acc": 52.0}
{"epoch": 31, "training_loss": 50.32639091491699, "training_acc": 52.0, "val_loss": 46.44570655822754, "val_acc": 52.0}
{"epoch": 32, "training_loss": 44.84232452392578, "training_acc": 52.0, "val_loss": 60.923470458984376, "val_acc": 48.0}
{"epoch": 33, "training_loss": 39.82336416244507, "training_acc": 50.0, "val_loss": 19.697006225585938, "val_acc": 48.0}
{"epoch": 34, "training_loss": 10.294610452651977, "training_acc": 51.0, "val_loss": 18.137346305847167, "val_acc": 48.0}
{"epoch": 35, "training_loss": 21.85583246231079, "training_acc": 50.0, "val_loss": 13.07062526702881, "val_acc": 48.0}
{"epoch": 36, "training_loss": 11.051001625061035, "training_acc": 54.0, "val_loss": 43.46460189819336, "val_acc": 52.0}
{"epoch": 37, "training_loss": 25.665290603637697, "training_acc": 54.0, "val_loss": 45.22335983276367, "val_acc": 52.0}
{"epoch": 38, "training_loss": 53.71520990371704, "training_acc": 43.0, "val_loss": 13.70263069152832, "val_acc": 48.0}
{"epoch": 39, "training_loss": 28.280868377685547, "training_acc": 50.0, "val_loss": 54.550259552001954, "val_acc": 48.0}
{"epoch": 40, "training_loss": 35.945172214508055, "training_acc": 40.0, "val_loss": 16.23189613342285, "val_acc": 48.0}
{"epoch": 41, "training_loss": 16.070426921844483, "training_acc": 40.0, "val_loss": 11.609573554992675, "val_acc": 52.0}
{"epoch": 42, "training_loss": 21.131743774414062, "training_acc": 52.0, "val_loss": 8.04836139678955, "val_acc": 52.0}
