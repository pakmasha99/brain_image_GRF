"main_modify.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 2 --task ADNI_sex --input_option yAware --learning_rate 1e0 --batch_size 16 --weight_decay 1e-2 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 135.2251451587677, "training_acc": 46.0, "val_loss": 10.388038825988769, "val_acc": 48.0}
{"epoch": 1, "training_loss": 116.554047164917, "training_acc": 54.0, "val_loss": 10.187322540283203, "val_acc": 48.0}
{"epoch": 2, "training_loss": 37.38401901245117, "training_acc": 42.0, "val_loss": 22.085550994873046, "val_acc": 48.0}
{"epoch": 3, "training_loss": 21.327048034667968, "training_acc": 46.0, "val_loss": 58.776180572509766, "val_acc": 48.0}
{"epoch": 4, "training_loss": 29.386585845947266, "training_acc": 50.0, "val_loss": 21.16740997314453, "val_acc": 48.0}
{"epoch": 5, "training_loss": 22.75401985168457, "training_acc": 48.0, "val_loss": 10.963492584228515, "val_acc": 52.0}
{"epoch": 6, "training_loss": 14.466686182022094, "training_acc": 58.0, "val_loss": 44.87904319763184, "val_acc": 52.0}
{"epoch": 7, "training_loss": 37.97671684265137, "training_acc": 50.0, "val_loss": 12.823546028137207, "val_acc": 52.0}
{"epoch": 8, "training_loss": 20.874310193061827, "training_acc": 52.0, "val_loss": 35.58928741455078, "val_acc": 52.0}
{"epoch": 9, "training_loss": 24.662835960388183, "training_acc": 44.0, "val_loss": 28.66833076477051, "val_acc": 52.0}
{"epoch": 10, "training_loss": 23.17444999694824, "training_acc": 50.0, "val_loss": 3.751078014373779, "val_acc": 48.0}
{"epoch": 11, "training_loss": 8.069656467437744, "training_acc": 48.0, "val_loss": 22.099600524902343, "val_acc": 48.0}
{"epoch": 12, "training_loss": 25.68669921875, "training_acc": 50.0, "val_loss": 9.158213577270509, "val_acc": 48.0}
{"epoch": 13, "training_loss": 62.16553913116455, "training_acc": 46.0, "val_loss": 43.85916244506836, "val_acc": 48.0}
{"epoch": 14, "training_loss": 31.814092588424682, "training_acc": 48.0, "val_loss": 24.397324295043944, "val_acc": 48.0}
{"epoch": 15, "training_loss": 19.074173164367675, "training_acc": 48.0, "val_loss": 42.08820281982422, "val_acc": 48.0}
{"epoch": 16, "training_loss": 37.055878524780276, "training_acc": 48.0, "val_loss": 26.073940887451172, "val_acc": 48.0}
{"epoch": 17, "training_loss": 18.127571182250975, "training_acc": 50.0, "val_loss": 36.7606916809082, "val_acc": 48.0}
{"epoch": 18, "training_loss": 12.989586639404298, "training_acc": 56.0, "val_loss": 9.06871732711792, "val_acc": 52.0}
{"epoch": 19, "training_loss": 21.016144409179688, "training_acc": 44.0, "val_loss": 37.86752914428711, "val_acc": 52.0}
{"epoch": 20, "training_loss": 29.193317098617555, "training_acc": 58.0, "val_loss": 27.208779220581054, "val_acc": 52.0}
{"epoch": 21, "training_loss": 18.655346212387084, "training_acc": 45.0, "val_loss": 3.588154983520508, "val_acc": 52.0}
{"epoch": 22, "training_loss": 15.375556430816651, "training_acc": 50.0, "val_loss": 23.136726684570313, "val_acc": 48.0}
{"epoch": 23, "training_loss": 13.362356033325195, "training_acc": 50.0, "val_loss": 13.667261428833008, "val_acc": 52.0}
{"epoch": 24, "training_loss": 22.206071891784667, "training_acc": 48.0, "val_loss": 20.87514423370361, "val_acc": 52.0}
{"epoch": 25, "training_loss": 29.77884443283081, "training_acc": 40.0, "val_loss": 7.927820854187011, "val_acc": 48.0}
{"epoch": 26, "training_loss": 13.023163986206054, "training_acc": 50.0, "val_loss": 57.222633361816406, "val_acc": 48.0}
{"epoch": 27, "training_loss": 37.740151529312136, "training_acc": 44.0, "val_loss": 7.179744300842285, "val_acc": 48.0}
{"epoch": 28, "training_loss": 10.378779640197754, "training_acc": 56.0, "val_loss": 5.9239530181884765, "val_acc": 48.0}
{"epoch": 29, "training_loss": 6.025802307128906, "training_acc": 49.0, "val_loss": 14.603555793762206, "val_acc": 48.0}
{"epoch": 30, "training_loss": 8.707993125915527, "training_acc": 54.0, "val_loss": 11.102310810089111, "val_acc": 52.0}
{"epoch": 31, "training_loss": 13.380296936035156, "training_acc": 46.0, "val_loss": 2.7954600715637206, "val_acc": 52.0}
{"epoch": 32, "training_loss": 5.4330433654785155, "training_acc": 56.0, "val_loss": 29.42557731628418, "val_acc": 48.0}
{"epoch": 33, "training_loss": 28.011771854162216, "training_acc": 48.0, "val_loss": 35.94283279418946, "val_acc": 48.0}
{"epoch": 34, "training_loss": 38.53155750274658, "training_acc": 44.0, "val_loss": 43.385547943115235, "val_acc": 48.0}
{"epoch": 35, "training_loss": 53.061686248779296, "training_acc": 54.0, "val_loss": 34.333927154541016, "val_acc": 52.0}
{"epoch": 36, "training_loss": 12.878949089050293, "training_acc": 60.0, "val_loss": 5.343445529937744, "val_acc": 52.0}
{"epoch": 37, "training_loss": 15.196043369174003, "training_acc": 54.0, "val_loss": 4.487412395477295, "val_acc": 48.0}
{"epoch": 38, "training_loss": 5.543569602966309, "training_acc": 52.0, "val_loss": 28.445490798950196, "val_acc": 48.0}
{"epoch": 39, "training_loss": 30.126729888916017, "training_acc": 42.0, "val_loss": 14.586524353027343, "val_acc": 48.0}
{"epoch": 40, "training_loss": 12.780910081863404, "training_acc": 46.0, "val_loss": 7.0816588211059575, "val_acc": 48.0}
{"epoch": 41, "training_loss": 16.673582229614258, "training_acc": 50.0, "val_loss": 27.93672721862793, "val_acc": 48.0}
{"epoch": 42, "training_loss": 27.13559913635254, "training_acc": 42.0, "val_loss": 1.2640792798995972, "val_acc": 52.0}
{"epoch": 43, "training_loss": 14.597088737487793, "training_acc": 56.0, "val_loss": 27.73717826843262, "val_acc": 52.0}
{"epoch": 44, "training_loss": 32.70898933410645, "training_acc": 52.0, "val_loss": 24.008442840576173, "val_acc": 52.0}
{"epoch": 45, "training_loss": 39.658297805786134, "training_acc": 56.0, "val_loss": 61.81090621948242, "val_acc": 48.0}
{"epoch": 46, "training_loss": 49.32587219238281, "training_acc": 52.0, "val_loss": 27.393551864624023, "val_acc": 52.0}
{"epoch": 47, "training_loss": 37.37904800415039, "training_acc": 46.0, "val_loss": 5.024805030822754, "val_acc": 52.0}
{"epoch": 48, "training_loss": 15.614663543701171, "training_acc": 52.0, "val_loss": 3.8242431259155274, "val_acc": 52.0}
{"epoch": 49, "training_loss": 8.646010370254517, "training_acc": 52.0, "val_loss": 17.39625701904297, "val_acc": 52.0}
{"epoch": 50, "training_loss": 7.8349370193481445, "training_acc": 46.0, "val_loss": 19.83869857788086, "val_acc": 48.0}
{"epoch": 51, "training_loss": 15.074061584472656, "training_acc": 54.0, "val_loss": 12.208894729614258, "val_acc": 48.0}
{"epoch": 52, "training_loss": 18.408767700195312, "training_acc": 52.0, "val_loss": 38.169358825683595, "val_acc": 52.0}
{"epoch": 53, "training_loss": 65.2313557434082, "training_acc": 44.0, "val_loss": 87.79160705566406, "val_acc": 48.0}
{"epoch": 54, "training_loss": 66.52890106201171, "training_acc": 46.0, "val_loss": 88.15533355712891, "val_acc": 52.0}
{"epoch": 55, "training_loss": 62.18634063720703, "training_acc": 52.0, "val_loss": 55.7249284362793, "val_acc": 48.0}
{"epoch": 56, "training_loss": 80.72640357971191, "training_acc": 50.0, "val_loss": 29.544659118652344, "val_acc": 52.0}
{"epoch": 57, "training_loss": 79.2243049621582, "training_acc": 48.0, "val_loss": 34.19401641845703, "val_acc": 52.0}
{"epoch": 58, "training_loss": 51.97324478149414, "training_acc": 52.0, "val_loss": 99.79356231689454, "val_acc": 48.0}
{"epoch": 59, "training_loss": 88.02172622680663, "training_acc": 46.0, "val_loss": 43.68103057861328, "val_acc": 52.0}
{"epoch": 60, "training_loss": 37.48844184875488, "training_acc": 42.0, "val_loss": 52.09136489868164, "val_acc": 52.0}
{"epoch": 61, "training_loss": 42.8453214263916, "training_acc": 42.0, "val_loss": 43.12627258300781, "val_acc": 52.0}
