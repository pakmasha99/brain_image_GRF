"main_modify.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 6 --task ADNI_sex --input_option yAware --learning_rate 1e0 --batch_size 16 --weight_decay 1e-2 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 87.5847074508667, "training_acc": 57.0, "val_loss": 63.43231201171875, "val_acc": 48.0}
{"epoch": 1, "training_loss": 91.8448681640625, "training_acc": 48.0, "val_loss": 83.31549194335938, "val_acc": 52.0}
{"epoch": 2, "training_loss": 39.96980651855469, "training_acc": 48.0, "val_loss": 33.90635955810547, "val_acc": 52.0}
{"epoch": 3, "training_loss": 32.46728183746338, "training_acc": 56.0, "val_loss": 8.355895442962646, "val_acc": 48.0}
{"epoch": 4, "training_loss": 32.11287120819092, "training_acc": 52.0, "val_loss": 7.770378456115723, "val_acc": 48.0}
{"epoch": 5, "training_loss": 8.56177248954773, "training_acc": 50.0, "val_loss": 17.46951332092285, "val_acc": 52.0}
{"epoch": 6, "training_loss": 14.719191665649413, "training_acc": 42.0, "val_loss": 12.705529251098632, "val_acc": 48.0}
{"epoch": 7, "training_loss": 23.12259712219238, "training_acc": 48.0, "val_loss": 4.015675630569458, "val_acc": 52.0}
{"epoch": 8, "training_loss": 7.148682327270508, "training_acc": 58.0, "val_loss": 3.2719040393829344, "val_acc": 48.0}
{"epoch": 9, "training_loss": 20.372875213623047, "training_acc": 52.0, "val_loss": 101.25320892333984, "val_acc": 48.0}
{"epoch": 10, "training_loss": 55.41601669311523, "training_acc": 58.0, "val_loss": 143.43029235839845, "val_acc": 52.0}
{"epoch": 11, "training_loss": 114.19528625488282, "training_acc": 50.0, "val_loss": 132.9222882080078, "val_acc": 48.0}
{"epoch": 12, "training_loss": 110.12153861999512, "training_acc": 52.0, "val_loss": 74.14135818481445, "val_acc": 52.0}
{"epoch": 13, "training_loss": 68.89268432617187, "training_acc": 48.0, "val_loss": 63.716834259033206, "val_acc": 48.0}
{"epoch": 14, "training_loss": 29.790577545166016, "training_acc": 44.0, "val_loss": 7.59359619140625, "val_acc": 52.0}
{"epoch": 15, "training_loss": 15.522509632110596, "training_acc": 62.0, "val_loss": 34.94673309326172, "val_acc": 52.0}
{"epoch": 16, "training_loss": 34.476165771484375, "training_acc": 52.0, "val_loss": 28.82396141052246, "val_acc": 48.0}
{"epoch": 17, "training_loss": 12.251434555053711, "training_acc": 56.0, "val_loss": 6.9422598075866695, "val_acc": 48.0}
{"epoch": 18, "training_loss": 14.565708465576172, "training_acc": 49.0, "val_loss": 50.98026565551758, "val_acc": 52.0}
{"epoch": 19, "training_loss": 33.4497034072876, "training_acc": 52.0, "val_loss": 33.933144912719726, "val_acc": 52.0}
{"epoch": 20, "training_loss": 37.487912292480466, "training_acc": 50.0, "val_loss": 106.72604309082031, "val_acc": 48.0}
{"epoch": 21, "training_loss": 79.18521331787109, "training_acc": 46.0, "val_loss": 108.80714691162109, "val_acc": 52.0}
{"epoch": 22, "training_loss": 75.20324768066406, "training_acc": 50.0, "val_loss": 50.838197784423826, "val_acc": 48.0}
{"epoch": 23, "training_loss": 53.761554374694825, "training_acc": 56.0, "val_loss": 0.8960460782051086, "val_acc": 52.0}
{"epoch": 24, "training_loss": 43.024818878173825, "training_acc": 53.0, "val_loss": 55.105784759521484, "val_acc": 52.0}
{"epoch": 25, "training_loss": 46.431167907714844, "training_acc": 44.0, "val_loss": 32.90757179260254, "val_acc": 52.0}
{"epoch": 26, "training_loss": 32.38415885925293, "training_acc": 50.0, "val_loss": 2.3288423728942873, "val_acc": 48.0}
{"epoch": 27, "training_loss": 29.035608596801758, "training_acc": 48.0, "val_loss": 62.94856719970703, "val_acc": 48.0}
{"epoch": 28, "training_loss": 44.431916046142575, "training_acc": 58.0, "val_loss": 35.24815872192383, "val_acc": 52.0}
{"epoch": 29, "training_loss": 27.485081443786623, "training_acc": 52.0, "val_loss": 30.202177734375, "val_acc": 52.0}
{"epoch": 30, "training_loss": 22.441798858642578, "training_acc": 54.0, "val_loss": 63.59381591796875, "val_acc": 52.0}
{"epoch": 31, "training_loss": 49.275086669921876, "training_acc": 52.0, "val_loss": 50.31475540161133, "val_acc": 48.0}
{"epoch": 32, "training_loss": 41.902760162353516, "training_acc": 54.0, "val_loss": 51.21512252807617, "val_acc": 48.0}
{"epoch": 33, "training_loss": 65.61315002441407, "training_acc": 46.0, "val_loss": 40.55174087524414, "val_acc": 52.0}
{"epoch": 34, "training_loss": 30.0426806640625, "training_acc": 42.0, "val_loss": 17.334070472717286, "val_acc": 52.0}
{"epoch": 35, "training_loss": 14.448118629455566, "training_acc": 58.0, "val_loss": 15.036971473693848, "val_acc": 48.0}
{"epoch": 36, "training_loss": 9.389365348815918, "training_acc": 56.0, "val_loss": 31.193241119384766, "val_acc": 52.0}
{"epoch": 37, "training_loss": 31.230509643554687, "training_acc": 52.0, "val_loss": 23.499912719726563, "val_acc": 52.0}
{"epoch": 38, "training_loss": 39.739190673828126, "training_acc": 52.0, "val_loss": 89.82409332275391, "val_acc": 48.0}
{"epoch": 39, "training_loss": 65.98381134033202, "training_acc": 42.0, "val_loss": 4.527812442779541, "val_acc": 52.0}
{"epoch": 40, "training_loss": 68.57435836791993, "training_acc": 42.0, "val_loss": 42.02877838134766, "val_acc": 52.0}
{"epoch": 41, "training_loss": 48.85230377197266, "training_acc": 46.0, "val_loss": 7.973462028503418, "val_acc": 52.0}
{"epoch": 42, "training_loss": 31.89701591491699, "training_acc": 58.0, "val_loss": 71.3264224243164, "val_acc": 48.0}
