"main_modify.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 6 --task ADNI_sex --input_option yAware --learning_rate 1e0 --batch_size 16 --weight_decay 1e-2 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 102.47493558883667, "training_acc": 53.0, "val_loss": 27.409251556396484, "val_acc": 48.0}
{"epoch": 1, "training_loss": 67.47612747192383, "training_acc": 49.0, "val_loss": 98.67958892822266, "val_acc": 52.0}
{"epoch": 2, "training_loss": 57.994863967895505, "training_acc": 57.0, "val_loss": 159.5569854736328, "val_acc": 48.0}
{"epoch": 3, "training_loss": 96.72227478027344, "training_acc": 47.0, "val_loss": 125.82015716552735, "val_acc": 52.0}
{"epoch": 4, "training_loss": 78.26350494384765, "training_acc": 51.0, "val_loss": 86.09364761352539, "val_acc": 48.0}
{"epoch": 5, "training_loss": 67.99386489868164, "training_acc": 53.0, "val_loss": 71.84826080322266, "val_acc": 52.0}
{"epoch": 6, "training_loss": 70.38298538208008, "training_acc": 47.0, "val_loss": 9.041227378845214, "val_acc": 48.0}
{"epoch": 7, "training_loss": 70.09023113250733, "training_acc": 45.0, "val_loss": 60.70331146240235, "val_acc": 48.0}
{"epoch": 8, "training_loss": 80.94516647338867, "training_acc": 49.0, "val_loss": 55.03314651489258, "val_acc": 52.0}
{"epoch": 9, "training_loss": 41.70145156860352, "training_acc": 57.0, "val_loss": 59.40366027832031, "val_acc": 48.0}
{"epoch": 10, "training_loss": 36.560712356567386, "training_acc": 49.0, "val_loss": 54.81692260742187, "val_acc": 48.0}
{"epoch": 11, "training_loss": 42.60807708740234, "training_acc": 49.0, "val_loss": 45.81332305908203, "val_acc": 52.0}
{"epoch": 12, "training_loss": 40.81664192199707, "training_acc": 47.0, "val_loss": 21.17029670715332, "val_acc": 52.0}
{"epoch": 13, "training_loss": 36.342660369873045, "training_acc": 41.0, "val_loss": 53.756486587524414, "val_acc": 52.0}
{"epoch": 14, "training_loss": 30.33583953857422, "training_acc": 53.0, "val_loss": 32.496945724487304, "val_acc": 52.0}
{"epoch": 15, "training_loss": 29.767349548339844, "training_acc": 57.0, "val_loss": 19.082059020996095, "val_acc": 48.0}
{"epoch": 16, "training_loss": 36.73676788330078, "training_acc": 45.0, "val_loss": 51.527565460205075, "val_acc": 48.0}
{"epoch": 17, "training_loss": 21.399198570251464, "training_acc": 53.0, "val_loss": 12.609207077026367, "val_acc": 52.0}
{"epoch": 18, "training_loss": 10.674657554626465, "training_acc": 49.0, "val_loss": 23.415732040405274, "val_acc": 48.0}
{"epoch": 19, "training_loss": 11.48101601600647, "training_acc": 49.0, "val_loss": 20.66743453979492, "val_acc": 48.0}
{"epoch": 20, "training_loss": 13.020565223693847, "training_acc": 49.0, "val_loss": 4.84321590423584, "val_acc": 52.0}
{"epoch": 21, "training_loss": 17.723853492736815, "training_acc": 55.0, "val_loss": 0.994430661201477, "val_acc": 48.0}
{"epoch": 22, "training_loss": 11.59026089668274, "training_acc": 53.0, "val_loss": 25.525921249389647, "val_acc": 48.0}
{"epoch": 23, "training_loss": 24.748314132690428, "training_acc": 55.0, "val_loss": 62.09012771606445, "val_acc": 48.0}
{"epoch": 24, "training_loss": 51.80483917236328, "training_acc": 49.0, "val_loss": 37.660222930908205, "val_acc": 52.0}
{"epoch": 25, "training_loss": 15.706003379821777, "training_acc": 35.0, "val_loss": 7.411005096435547, "val_acc": 52.0}
{"epoch": 26, "training_loss": 18.8067520904541, "training_acc": 47.0, "val_loss": 20.284005126953126, "val_acc": 52.0}
{"epoch": 27, "training_loss": 20.216498527526856, "training_acc": 47.0, "val_loss": 40.31379066467285, "val_acc": 48.0}
{"epoch": 28, "training_loss": 44.85904251098633, "training_acc": 47.0, "val_loss": 82.13555633544922, "val_acc": 52.0}
{"epoch": 29, "training_loss": 48.04412124633789, "training_acc": 61.0, "val_loss": 112.039296875, "val_acc": 48.0}
{"epoch": 30, "training_loss": 55.65208129882812, "training_acc": 57.0, "val_loss": 98.20298950195313, "val_acc": 52.0}
{"epoch": 31, "training_loss": 72.51588592529296, "training_acc": 51.0, "val_loss": 55.83453582763672, "val_acc": 48.0}
{"epoch": 32, "training_loss": 34.484286346435546, "training_acc": 41.0, "val_loss": 28.0564054107666, "val_acc": 48.0}
{"epoch": 33, "training_loss": 21.104595642089844, "training_acc": 47.0, "val_loss": 3.422538928985596, "val_acc": 52.0}
{"epoch": 34, "training_loss": 12.191226272583007, "training_acc": 53.0, "val_loss": 40.26646423339844, "val_acc": 52.0}
{"epoch": 35, "training_loss": 33.147958526611326, "training_acc": 53.0, "val_loss": 34.66894119262695, "val_acc": 52.0}
{"epoch": 36, "training_loss": 31.04643572807312, "training_acc": 50.0, "val_loss": 17.070130004882813, "val_acc": 52.0}
{"epoch": 37, "training_loss": 22.751259155273438, "training_acc": 43.0, "val_loss": 36.47380935668945, "val_acc": 52.0}
{"epoch": 38, "training_loss": 34.30692813873291, "training_acc": 53.0, "val_loss": 14.710154495239259, "val_acc": 52.0}
{"epoch": 39, "training_loss": 15.070183486938477, "training_acc": 53.0, "val_loss": 21.066561965942384, "val_acc": 52.0}
{"epoch": 40, "training_loss": 16.71898567199707, "training_acc": 51.0, "val_loss": 26.28119640350342, "val_acc": 48.0}
