"main_modify.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 1 --task ADNI_sex --input_option yAware --learning_rate 1e0 --batch_size 16 --weight_decay 1e-2 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 118.5231235408783, "training_acc": 50.0, "val_loss": 15.320449447631836, "val_acc": 48.0}
{"epoch": 1, "training_loss": 36.3225715637207, "training_acc": 54.0, "val_loss": 59.82540924072266, "val_acc": 52.0}
{"epoch": 2, "training_loss": 30.140550003051757, "training_acc": 54.0, "val_loss": 57.389199829101564, "val_acc": 52.0}
{"epoch": 3, "training_loss": 38.03163828849792, "training_acc": 53.0, "val_loss": 45.332129669189456, "val_acc": 52.0}
{"epoch": 4, "training_loss": 60.88131942749023, "training_acc": 44.0, "val_loss": 81.64093841552734, "val_acc": 48.0}
{"epoch": 5, "training_loss": 45.76599914550781, "training_acc": 56.0, "val_loss": 26.612130432128907, "val_acc": 52.0}
{"epoch": 6, "training_loss": 25.304106616973876, "training_acc": 44.0, "val_loss": 18.591630783081055, "val_acc": 48.0}
{"epoch": 7, "training_loss": 14.257591056823731, "training_acc": 52.0, "val_loss": 1.2046914720535278, "val_acc": 52.0}
{"epoch": 8, "training_loss": 10.466714305877685, "training_acc": 46.0, "val_loss": 5.707775650024414, "val_acc": 48.0}
{"epoch": 9, "training_loss": 16.851360702514647, "training_acc": 50.0, "val_loss": 29.089625778198243, "val_acc": 52.0}
{"epoch": 10, "training_loss": 15.44110403060913, "training_acc": 46.0, "val_loss": 15.682808837890626, "val_acc": 48.0}
{"epoch": 11, "training_loss": 19.468152198791504, "training_acc": 52.0, "val_loss": 3.116594123840332, "val_acc": 48.0}
{"epoch": 12, "training_loss": 42.611368331909176, "training_acc": 40.0, "val_loss": 61.0752456665039, "val_acc": 48.0}
{"epoch": 13, "training_loss": 36.658973655700684, "training_acc": 48.0, "val_loss": 28.605266342163088, "val_acc": 48.0}
{"epoch": 14, "training_loss": 29.02604591369629, "training_acc": 50.0, "val_loss": 24.95102035522461, "val_acc": 48.0}
{"epoch": 15, "training_loss": 34.11628608703613, "training_acc": 52.0, "val_loss": 34.01743160247803, "val_acc": 52.0}
{"epoch": 16, "training_loss": 24.95592315673828, "training_acc": 40.0, "val_loss": 12.899997291564942, "val_acc": 48.0}
{"epoch": 17, "training_loss": 13.178752899169922, "training_acc": 56.0, "val_loss": 40.66531127929687, "val_acc": 48.0}
{"epoch": 18, "training_loss": 43.70088130950928, "training_acc": 42.0, "val_loss": 22.03562660217285, "val_acc": 48.0}
{"epoch": 19, "training_loss": 39.13129638671875, "training_acc": 50.0, "val_loss": 75.35686614990234, "val_acc": 52.0}
{"epoch": 20, "training_loss": 45.21572509765625, "training_acc": 58.0, "val_loss": 116.12823303222656, "val_acc": 48.0}
{"epoch": 21, "training_loss": 84.09764190673827, "training_acc": 46.0, "val_loss": 102.89876373291015, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.26920135498047, "training_acc": 52.0, "val_loss": 100.48146057128906, "val_acc": 48.0}
{"epoch": 23, "training_loss": 73.96804107666016, "training_acc": 44.0, "val_loss": 45.11557357788086, "val_acc": 52.0}
{"epoch": 24, "training_loss": 62.10999839782715, "training_acc": 50.0, "val_loss": 0.6390741324424744, "val_acc": 52.0}
{"epoch": 25, "training_loss": 66.76156573534011, "training_acc": 50.0, "val_loss": 55.546975708007814, "val_acc": 48.0}
{"epoch": 26, "training_loss": 60.816886291503906, "training_acc": 50.0, "val_loss": 90.73565368652343, "val_acc": 52.0}
{"epoch": 27, "training_loss": 76.51970993041992, "training_acc": 54.0, "val_loss": 57.90733581542969, "val_acc": 48.0}
{"epoch": 28, "training_loss": 41.44606712341309, "training_acc": 44.0, "val_loss": 43.791569519042966, "val_acc": 48.0}
{"epoch": 29, "training_loss": 35.77212432861328, "training_acc": 46.0, "val_loss": 21.930632553100587, "val_acc": 52.0}
{"epoch": 30, "training_loss": 27.187173345088958, "training_acc": 47.0, "val_loss": 17.68006820678711, "val_acc": 52.0}
{"epoch": 31, "training_loss": 27.866304893493652, "training_acc": 56.0, "val_loss": 13.503173789978028, "val_acc": 52.0}
{"epoch": 32, "training_loss": 27.803107604980468, "training_acc": 52.0, "val_loss": 24.938775024414063, "val_acc": 48.0}
{"epoch": 33, "training_loss": 44.842958221435545, "training_acc": 48.0, "val_loss": 86.15644927978515, "val_acc": 48.0}
{"epoch": 34, "training_loss": 54.403190765380856, "training_acc": 48.0, "val_loss": 0.9225800228118897, "val_acc": 48.0}
{"epoch": 35, "training_loss": 7.87046968460083, "training_acc": 58.0, "val_loss": 7.547717056274414, "val_acc": 52.0}
{"epoch": 36, "training_loss": 5.658509044647217, "training_acc": 57.0, "val_loss": 13.03329475402832, "val_acc": 52.0}
{"epoch": 37, "training_loss": 17.761127166748047, "training_acc": 52.0, "val_loss": 9.477478828430176, "val_acc": 52.0}
{"epoch": 38, "training_loss": 37.80407211303711, "training_acc": 44.0, "val_loss": 32.08176376342774, "val_acc": 52.0}
{"epoch": 39, "training_loss": 15.692727737426758, "training_acc": 52.0, "val_loss": 27.70848663330078, "val_acc": 48.0}
{"epoch": 40, "training_loss": 29.65689913749695, "training_acc": 46.0, "val_loss": 26.61976303100586, "val_acc": 48.0}
{"epoch": 41, "training_loss": 23.634671649932862, "training_acc": 56.0, "val_loss": 22.778005752563477, "val_acc": 48.0}
{"epoch": 42, "training_loss": 26.681863098144532, "training_acc": 42.0, "val_loss": 18.47275945663452, "val_acc": 48.0}
{"epoch": 43, "training_loss": 23.57365020751953, "training_acc": 44.0, "val_loss": 0.6452361416816711, "val_acc": 52.0}
