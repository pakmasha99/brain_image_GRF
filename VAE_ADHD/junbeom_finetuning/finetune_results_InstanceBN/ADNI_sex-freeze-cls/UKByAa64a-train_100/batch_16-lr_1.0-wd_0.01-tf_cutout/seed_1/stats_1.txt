"main_modify.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 1 --task ADNI_sex --input_option yAware --learning_rate 1e0 --batch_size 16 --weight_decay 1e-2 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 103.17063214302063, "training_acc": 49.0, "val_loss": 42.990403442382814, "val_acc": 52.0}
{"epoch": 1, "training_loss": 62.2916943359375, "training_acc": 44.0, "val_loss": 27.76950622558594, "val_acc": 48.0}
{"epoch": 2, "training_loss": 36.62234344482422, "training_acc": 48.0, "val_loss": 46.01249526977539, "val_acc": 48.0}
{"epoch": 3, "training_loss": 26.53906234741211, "training_acc": 48.0, "val_loss": 69.99081085205079, "val_acc": 48.0}
{"epoch": 4, "training_loss": 42.48656765937805, "training_acc": 46.0, "val_loss": 26.533678359985352, "val_acc": 48.0}
{"epoch": 5, "training_loss": 31.8633243560791, "training_acc": 42.0, "val_loss": 60.76849578857422, "val_acc": 48.0}
{"epoch": 6, "training_loss": 102.88105266571046, "training_acc": 50.0, "val_loss": 54.137583618164065, "val_acc": 52.0}
{"epoch": 7, "training_loss": 76.56285016059876, "training_acc": 52.0, "val_loss": 48.10177474975586, "val_acc": 48.0}
{"epoch": 8, "training_loss": 37.565939331054686, "training_acc": 50.0, "val_loss": 5.616715564727783, "val_acc": 52.0}
{"epoch": 9, "training_loss": 16.66408531188965, "training_acc": 52.0, "val_loss": 10.884268035888672, "val_acc": 48.0}
{"epoch": 10, "training_loss": 11.500405807495117, "training_acc": 50.0, "val_loss": 24.065390853881837, "val_acc": 48.0}
{"epoch": 11, "training_loss": 29.926482276916502, "training_acc": 52.0, "val_loss": 21.46075843811035, "val_acc": 52.0}
{"epoch": 12, "training_loss": 15.97711399078369, "training_acc": 50.0, "val_loss": 13.941496505737305, "val_acc": 48.0}
{"epoch": 13, "training_loss": 7.551076049804688, "training_acc": 56.0, "val_loss": 7.530090379714966, "val_acc": 52.0}
{"epoch": 14, "training_loss": 10.759756541252136, "training_acc": 54.0, "val_loss": 34.865455322265625, "val_acc": 48.0}
{"epoch": 15, "training_loss": 19.053537673950196, "training_acc": 48.0, "val_loss": 31.448735427856445, "val_acc": 52.0}
{"epoch": 16, "training_loss": 22.67915909767151, "training_acc": 42.0, "val_loss": 24.543521728515625, "val_acc": 48.0}
{"epoch": 17, "training_loss": 35.99545541763305, "training_acc": 44.0, "val_loss": 38.20389587402344, "val_acc": 48.0}
{"epoch": 18, "training_loss": 49.6152490234375, "training_acc": 50.0, "val_loss": 35.25301422119141, "val_acc": 52.0}
{"epoch": 19, "training_loss": 31.391204872131347, "training_acc": 52.0, "val_loss": 46.59822601318359, "val_acc": 52.0}
{"epoch": 20, "training_loss": 36.29263887405396, "training_acc": 47.0, "val_loss": 30.800755157470704, "val_acc": 52.0}
{"epoch": 21, "training_loss": 24.322727432250975, "training_acc": 46.0, "val_loss": 35.2760424041748, "val_acc": 52.0}
{"epoch": 22, "training_loss": 12.179223670959473, "training_acc": 50.0, "val_loss": 33.622316665649414, "val_acc": 48.0}
{"epoch": 23, "training_loss": 24.30029415130615, "training_acc": 58.0, "val_loss": 26.56322166442871, "val_acc": 48.0}
{"epoch": 24, "training_loss": 36.42123641967773, "training_acc": 52.0, "val_loss": 26.516856918334963, "val_acc": 52.0}
{"epoch": 25, "training_loss": 18.75473731994629, "training_acc": 46.0, "val_loss": 2.587017526626587, "val_acc": 52.0}
{"epoch": 26, "training_loss": 10.187199440002441, "training_acc": 52.0, "val_loss": 31.483316955566405, "val_acc": 52.0}
{"epoch": 27, "training_loss": 39.695608673095705, "training_acc": 54.0, "val_loss": 109.036171875, "val_acc": 48.0}
{"epoch": 28, "training_loss": 75.12135528564453, "training_acc": 52.0, "val_loss": 112.53419921875, "val_acc": 52.0}
{"epoch": 29, "training_loss": 80.79417236328125, "training_acc": 46.0, "val_loss": 66.54938766479492, "val_acc": 48.0}
{"epoch": 30, "training_loss": 56.74196355819702, "training_acc": 42.0, "val_loss": 44.42334449768067, "val_acc": 48.0}
{"epoch": 31, "training_loss": 51.69448013305664, "training_acc": 42.0, "val_loss": 0.8070263957977295, "val_acc": 60.0}
{"epoch": 32, "training_loss": 33.05696173667908, "training_acc": 49.0, "val_loss": 53.86741744995117, "val_acc": 52.0}
{"epoch": 33, "training_loss": 51.96581115722656, "training_acc": 50.0, "val_loss": 34.15234733581543, "val_acc": 48.0}
{"epoch": 34, "training_loss": 51.23118667602539, "training_acc": 48.0, "val_loss": 53.495130920410155, "val_acc": 48.0}
{"epoch": 35, "training_loss": 31.106377868652345, "training_acc": 48.0, "val_loss": 14.001943359375, "val_acc": 48.0}
{"epoch": 36, "training_loss": 5.456450538635254, "training_acc": 60.0, "val_loss": 15.945572700500488, "val_acc": 52.0}
{"epoch": 37, "training_loss": 21.807096862792967, "training_acc": 44.0, "val_loss": 41.742233734130856, "val_acc": 52.0}
{"epoch": 38, "training_loss": 20.79541877746582, "training_acc": 52.0, "val_loss": 47.7461946105957, "val_acc": 52.0}
{"epoch": 39, "training_loss": 29.591435508728026, "training_acc": 60.0, "val_loss": 8.789886970520019, "val_acc": 52.0}
{"epoch": 40, "training_loss": 12.75186517715454, "training_acc": 52.0, "val_loss": 22.49882556915283, "val_acc": 52.0}
{"epoch": 41, "training_loss": 24.672651405334474, "training_acc": 48.0, "val_loss": 6.3826602172851565, "val_acc": 52.0}
{"epoch": 42, "training_loss": 23.90042449951172, "training_acc": 48.0, "val_loss": 16.89156879425049, "val_acc": 52.0}
{"epoch": 43, "training_loss": 22.95019561767578, "training_acc": 50.0, "val_loss": 22.308740386962892, "val_acc": 48.0}
{"epoch": 44, "training_loss": 34.84949264526367, "training_acc": 46.0, "val_loss": 21.751588020324707, "val_acc": 52.0}
{"epoch": 45, "training_loss": 39.14366241455078, "training_acc": 40.0, "val_loss": 30.363407287597656, "val_acc": 52.0}
{"epoch": 46, "training_loss": 24.25499481201172, "training_acc": 46.0, "val_loss": 15.92127311706543, "val_acc": 48.0}
{"epoch": 47, "training_loss": 16.059817924499512, "training_acc": 50.0, "val_loss": 20.482572860717774, "val_acc": 52.0}
{"epoch": 48, "training_loss": 18.14744888305664, "training_acc": 54.0, "val_loss": 12.476904830932618, "val_acc": 52.0}
{"epoch": 49, "training_loss": 11.465374183654784, "training_acc": 60.0, "val_loss": 5.346835606098175, "val_acc": 48.0}
{"epoch": 50, "training_loss": 7.506179666519165, "training_acc": 49.0, "val_loss": 4.235208024978638, "val_acc": 52.0}
