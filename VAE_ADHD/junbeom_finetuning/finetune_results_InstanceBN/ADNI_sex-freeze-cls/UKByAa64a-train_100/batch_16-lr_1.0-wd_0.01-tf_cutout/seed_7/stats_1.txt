"main_modify.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 7 --task ADNI_sex --input_option yAware --learning_rate 1e0 --batch_size 16 --weight_decay 1e-2 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 121.82106601715088, "training_acc": 47.0, "val_loss": 16.21623649597168, "val_acc": 48.0}
{"epoch": 1, "training_loss": 73.24858383178712, "training_acc": 49.0, "val_loss": 64.38807815551758, "val_acc": 48.0}
{"epoch": 2, "training_loss": 31.42167266845703, "training_acc": 49.0, "val_loss": 17.125684967041014, "val_acc": 48.0}
{"epoch": 3, "training_loss": 24.160243530273437, "training_acc": 53.0, "val_loss": 64.90190383911133, "val_acc": 48.0}
{"epoch": 4, "training_loss": 50.37582077026367, "training_acc": 49.0, "val_loss": 15.014692993164063, "val_acc": 52.0}
{"epoch": 5, "training_loss": 41.26167667388916, "training_acc": 55.0, "val_loss": 51.82597625732422, "val_acc": 52.0}
{"epoch": 6, "training_loss": 41.15708717346192, "training_acc": 53.0, "val_loss": 42.1288412475586, "val_acc": 48.0}
{"epoch": 7, "training_loss": 42.57119915008545, "training_acc": 49.0, "val_loss": 23.572575607299804, "val_acc": 48.0}
{"epoch": 8, "training_loss": 27.61234909057617, "training_acc": 41.0, "val_loss": 35.83393508911133, "val_acc": 48.0}
{"epoch": 9, "training_loss": 19.275099487304686, "training_acc": 49.0, "val_loss": 0.8069289207458497, "val_acc": 48.0}
{"epoch": 10, "training_loss": 13.8920184135437, "training_acc": 48.0, "val_loss": 4.4199773216247555, "val_acc": 48.0}
{"epoch": 11, "training_loss": 11.76631404876709, "training_acc": 49.0, "val_loss": 26.714189224243164, "val_acc": 52.0}
{"epoch": 12, "training_loss": 26.5098974609375, "training_acc": 41.0, "val_loss": 22.12814125061035, "val_acc": 52.0}
{"epoch": 13, "training_loss": 27.66497383117676, "training_acc": 59.0, "val_loss": 53.35605606079102, "val_acc": 52.0}
{"epoch": 14, "training_loss": 56.08690776824951, "training_acc": 53.0, "val_loss": 108.452216796875, "val_acc": 48.0}
{"epoch": 15, "training_loss": 99.63511688232421, "training_acc": 47.0, "val_loss": 63.38311065673828, "val_acc": 52.0}
{"epoch": 16, "training_loss": 46.7515412902832, "training_acc": 53.0, "val_loss": 47.19085647583008, "val_acc": 48.0}
{"epoch": 17, "training_loss": 32.82943817138672, "training_acc": 53.0, "val_loss": 29.824750061035157, "val_acc": 48.0}
{"epoch": 18, "training_loss": 30.254441680908204, "training_acc": 55.0, "val_loss": 7.681485366821289, "val_acc": 48.0}
{"epoch": 19, "training_loss": 14.358426685333251, "training_acc": 44.0, "val_loss": 1.1536467456817627, "val_acc": 48.0}
{"epoch": 20, "training_loss": 27.50636112213135, "training_acc": 53.0, "val_loss": 66.09234771728515, "val_acc": 48.0}
{"epoch": 21, "training_loss": 31.822720108032225, "training_acc": 53.0, "val_loss": 2.4451786947250365, "val_acc": 52.0}
{"epoch": 22, "training_loss": 8.210913105010986, "training_acc": 58.0, "val_loss": 23.162936325073243, "val_acc": 48.0}
{"epoch": 23, "training_loss": 27.8120636177063, "training_acc": 43.0, "val_loss": 15.81869384765625, "val_acc": 48.0}
{"epoch": 24, "training_loss": 18.42361373901367, "training_acc": 53.0, "val_loss": 0.7447804880142211, "val_acc": 56.0}
{"epoch": 25, "training_loss": 9.84829833984375, "training_acc": 47.0, "val_loss": 16.43471607208252, "val_acc": 48.0}
{"epoch": 26, "training_loss": 13.606399307250976, "training_acc": 49.0, "val_loss": 36.73877975463867, "val_acc": 52.0}
{"epoch": 27, "training_loss": 37.403107719421385, "training_acc": 49.0, "val_loss": 8.428117446899414, "val_acc": 48.0}
{"epoch": 28, "training_loss": 17.672673416137695, "training_acc": 53.0, "val_loss": 19.56460060119629, "val_acc": 52.0}
{"epoch": 29, "training_loss": 19.68413366317749, "training_acc": 53.0, "val_loss": 24.68356269836426, "val_acc": 52.0}
{"epoch": 30, "training_loss": 31.32067886352539, "training_acc": 41.0, "val_loss": 75.80131500244141, "val_acc": 52.0}
{"epoch": 31, "training_loss": 55.44105010986328, "training_acc": 55.0, "val_loss": 120.8762060546875, "val_acc": 48.0}
{"epoch": 32, "training_loss": 84.45291900634766, "training_acc": 45.0, "val_loss": 79.30828338623047, "val_acc": 52.0}
{"epoch": 33, "training_loss": 48.204225845336914, "training_acc": 45.0, "val_loss": 58.08717071533203, "val_acc": 52.0}
{"epoch": 34, "training_loss": 105.11745204925538, "training_acc": 49.0, "val_loss": 84.34982284545899, "val_acc": 48.0}
{"epoch": 35, "training_loss": 154.075791015625, "training_acc": 51.0, "val_loss": 32.188661651611326, "val_acc": 48.0}
{"epoch": 36, "training_loss": 150.7329895019531, "training_acc": 47.0, "val_loss": 84.11589309692383, "val_acc": 52.0}
{"epoch": 37, "training_loss": 93.98327514648437, "training_acc": 51.0, "val_loss": 105.78071075439453, "val_acc": 48.0}
{"epoch": 38, "training_loss": 52.0803288269043, "training_acc": 57.0, "val_loss": 5.833765888214112, "val_acc": 48.0}
{"epoch": 39, "training_loss": 26.837967529296876, "training_acc": 49.0, "val_loss": 6.521347732543945, "val_acc": 48.0}
{"epoch": 40, "training_loss": 8.313709030151367, "training_acc": 39.0, "val_loss": 42.22573364257813, "val_acc": 52.0}
{"epoch": 41, "training_loss": 52.289067077636716, "training_acc": 55.0, "val_loss": 62.02635406494141, "val_acc": 48.0}
{"epoch": 42, "training_loss": 34.01753173828125, "training_acc": 57.0, "val_loss": 11.356690826416015, "val_acc": 48.0}
{"epoch": 43, "training_loss": 24.00144989013672, "training_acc": 57.0, "val_loss": 31.046153793334963, "val_acc": 52.0}
