"main_modify.py --pretrained_path None --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_sex --input_option yAware --learning_rate 5e0 --batch_size 8 --weight_decay 5e-9 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 520.6917481422424, "training_acc": 55.0, "val_loss": 291.349365234375, "val_acc": 60.0}
{"epoch": 1, "training_loss": 609.2076293945313, "training_acc": 45.0, "val_loss": 97.97909545898438, "val_acc": 60.0}
{"epoch": 2, "training_loss": 521.3534790039063, "training_acc": 35.0, "val_loss": 1089.6541748046875, "val_acc": 40.0}
{"epoch": 3, "training_loss": 741.67978515625, "training_acc": 55.0, "val_loss": 447.32275390625, "val_acc": 40.0}
{"epoch": 4, "training_loss": 157.07863159179686, "training_acc": 55.0, "val_loss": 474.4747619628906, "val_acc": 60.0}
{"epoch": 5, "training_loss": 666.3381103515625, "training_acc": 45.0, "val_loss": 355.8410339355469, "val_acc": 60.0}
{"epoch": 6, "training_loss": 289.57472076416013, "training_acc": 55.0, "val_loss": 465.8740234375, "val_acc": 40.0}
{"epoch": 7, "training_loss": 399.4642272949219, "training_acc": 55.0, "val_loss": 489.6974792480469, "val_acc": 40.0}
{"epoch": 8, "training_loss": 237.09920959472657, "training_acc": 55.0, "val_loss": 215.99661254882812, "val_acc": 60.0}
{"epoch": 9, "training_loss": 423.7839721679687, "training_acc": 45.0, "val_loss": 321.83697509765625, "val_acc": 60.0}
{"epoch": 10, "training_loss": 263.9068950653076, "training_acc": 45.0, "val_loss": 429.293212890625, "val_acc": 40.0}
{"epoch": 11, "training_loss": 563.3680419921875, "training_acc": 55.0, "val_loss": 921.3519897460938, "val_acc": 40.0}
{"epoch": 12, "training_loss": 592.5715515136719, "training_acc": 55.0, "val_loss": 226.75015258789062, "val_acc": 40.0}
{"epoch": 13, "training_loss": 156.98719482421876, "training_acc": 65.0, "val_loss": 291.8140563964844, "val_acc": 60.0}
{"epoch": 14, "training_loss": 296.7295379638672, "training_acc": 45.0, "val_loss": 222.70742797851562, "val_acc": 40.0}
{"epoch": 15, "training_loss": 331.6423400878906, "training_acc": 55.0, "val_loss": 514.4576416015625, "val_acc": 40.0}
{"epoch": 16, "training_loss": 319.9625732421875, "training_acc": 55.0, "val_loss": 167.66163635253906, "val_acc": 60.0}
{"epoch": 17, "training_loss": 294.16260986328126, "training_acc": 45.0, "val_loss": 110.75292205810547, "val_acc": 60.0}
{"epoch": 18, "training_loss": 144.143212890625, "training_acc": 45.0, "val_loss": 289.7972717285156, "val_acc": 40.0}
{"epoch": 19, "training_loss": 185.92188568115233, "training_acc": 55.0, "val_loss": 106.7498779296875, "val_acc": 60.0}
{"epoch": 20, "training_loss": 185.10699768066405, "training_acc": 45.0, "val_loss": 90.2313461303711, "val_acc": 60.0}
{"epoch": 21, "training_loss": 169.19437255859376, "training_acc": 35.0, "val_loss": 163.31251525878906, "val_acc": 40.0}
{"epoch": 22, "training_loss": 81.82983474731445, "training_acc": 45.0, "val_loss": 57.11677169799805, "val_acc": 40.0}
{"epoch": 23, "training_loss": 38.007921600341795, "training_acc": 55.0, "val_loss": 9.416571617126465, "val_acc": 40.0}
{"epoch": 24, "training_loss": 61.645117950439456, "training_acc": 35.0, "val_loss": 162.5985870361328, "val_acc": 40.0}
{"epoch": 25, "training_loss": 151.30706787109375, "training_acc": 55.0, "val_loss": 89.6262435913086, "val_acc": 40.0}
{"epoch": 26, "training_loss": 126.19526977539063, "training_acc": 55.0, "val_loss": 87.6871109008789, "val_acc": 60.0}
{"epoch": 27, "training_loss": 102.02151184082031, "training_acc": 55.0, "val_loss": 195.5004119873047, "val_acc": 40.0}
{"epoch": 28, "training_loss": 98.78651733398438, "training_acc": 55.0, "val_loss": 126.10009765625, "val_acc": 60.0}
{"epoch": 29, "training_loss": 151.6131103515625, "training_acc": 35.0, "val_loss": 143.97007751464844, "val_acc": 40.0}
{"epoch": 30, "training_loss": 78.13179321289063, "training_acc": 55.0, "val_loss": 96.37785339355469, "val_acc": 60.0}
{"epoch": 31, "training_loss": 75.6047576904297, "training_acc": 65.0, "val_loss": 195.1653594970703, "val_acc": 40.0}
{"epoch": 32, "training_loss": 156.94554443359374, "training_acc": 55.0, "val_loss": 18.200054168701172, "val_acc": 60.0}
{"epoch": 33, "training_loss": 117.87132263183594, "training_acc": 45.0, "val_loss": 110.55440521240234, "val_acc": 40.0}
{"epoch": 34, "training_loss": 96.67306365966797, "training_acc": 55.0, "val_loss": 29.70815086364746, "val_acc": 40.0}
{"epoch": 35, "training_loss": 128.4294105529785, "training_acc": 45.0, "val_loss": 80.39485931396484, "val_acc": 60.0}
{"epoch": 36, "training_loss": 91.29173583984375, "training_acc": 55.0, "val_loss": 208.78250122070312, "val_acc": 40.0}
{"epoch": 37, "training_loss": 130.1318328857422, "training_acc": 45.0, "val_loss": 80.58272552490234, "val_acc": 60.0}
{"epoch": 38, "training_loss": 84.24393348693847, "training_acc": 35.0, "val_loss": 43.65754318237305, "val_acc": 60.0}
{"epoch": 39, "training_loss": 58.48487091064453, "training_acc": 45.0, "val_loss": 212.83958435058594, "val_acc": 40.0}
{"epoch": 40, "training_loss": 133.21299896240234, "training_acc": 45.0, "val_loss": 39.00533676147461, "val_acc": 60.0}
{"epoch": 41, "training_loss": 73.23080215454101, "training_acc": 45.0, "val_loss": 34.37435531616211, "val_acc": 40.0}
{"epoch": 42, "training_loss": 73.96727447509765, "training_acc": 55.0, "val_loss": 7.084713935852051, "val_acc": 60.0}
{"epoch": 43, "training_loss": 197.3347946166992, "training_acc": 45.0, "val_loss": 382.9493408203125, "val_acc": 40.0}
{"epoch": 44, "training_loss": 212.5352554321289, "training_acc": 45.0, "val_loss": 97.90477752685547, "val_acc": 60.0}
{"epoch": 45, "training_loss": 106.88012142181397, "training_acc": 25.0, "val_loss": 30.429840087890625, "val_acc": 40.0}
{"epoch": 46, "training_loss": 41.066725730895996, "training_acc": 55.0, "val_loss": 115.42327880859375, "val_acc": 60.0}
{"epoch": 47, "training_loss": 124.59962310791016, "training_acc": 45.0, "val_loss": 255.2141571044922, "val_acc": 40.0}
{"epoch": 48, "training_loss": 148.47735748291015, "training_acc": 55.0, "val_loss": 104.3924789428711, "val_acc": 60.0}
{"epoch": 49, "training_loss": 167.30772094726564, "training_acc": 45.0, "val_loss": 3.765286684036255, "val_acc": 40.0}
{"epoch": 50, "training_loss": 16.994316577911377, "training_acc": 55.0, "val_loss": 91.1055679321289, "val_acc": 60.0}
{"epoch": 51, "training_loss": 113.82899169921875, "training_acc": 45.0, "val_loss": 202.1051483154297, "val_acc": 40.0}
{"epoch": 52, "training_loss": 265.89862670898435, "training_acc": 55.0, "val_loss": 289.8500061035156, "val_acc": 40.0}
{"epoch": 53, "training_loss": 201.1458755493164, "training_acc": 45.0, "val_loss": 285.3520812988281, "val_acc": 60.0}
{"epoch": 54, "training_loss": 357.0450927734375, "training_acc": 45.0, "val_loss": 5.230746746063232, "val_acc": 60.0}
{"epoch": 55, "training_loss": 240.14062576293946, "training_acc": 45.0, "val_loss": 746.2914428710938, "val_acc": 40.0}
{"epoch": 56, "training_loss": 567.6847900390625, "training_acc": 55.0, "val_loss": 453.8204040527344, "val_acc": 40.0}
{"epoch": 57, "training_loss": 244.95914611816406, "training_acc": 55.0, "val_loss": 260.7607116699219, "val_acc": 60.0}
{"epoch": 58, "training_loss": 380.4876739501953, "training_acc": 45.0, "val_loss": 96.83112335205078, "val_acc": 60.0}
{"epoch": 59, "training_loss": 183.56002807617188, "training_acc": 45.0, "val_loss": 328.5404357910156, "val_acc": 40.0}
{"epoch": 60, "training_loss": 168.92603492736816, "training_acc": 55.0, "val_loss": 56.7098503112793, "val_acc": 60.0}
{"epoch": 61, "training_loss": 58.215994644165036, "training_acc": 35.0, "val_loss": 104.82252502441406, "val_acc": 60.0}
{"epoch": 62, "training_loss": 137.85989685058593, "training_acc": 45.0, "val_loss": 127.7649917602539, "val_acc": 40.0}
{"epoch": 63, "training_loss": 109.58230285644531, "training_acc": 55.0, "val_loss": 5.513834476470947, "val_acc": 40.0}
{"epoch": 64, "training_loss": 164.2932325363159, "training_acc": 50.0, "val_loss": 167.8391571044922, "val_acc": 60.0}
{"epoch": 65, "training_loss": 145.22699584960938, "training_acc": 45.0, "val_loss": 403.76568603515625, "val_acc": 40.0}
{"epoch": 66, "training_loss": 297.5411773681641, "training_acc": 55.0, "val_loss": 205.5839080810547, "val_acc": 40.0}
{"epoch": 67, "training_loss": 161.64396209716796, "training_acc": 35.0, "val_loss": 31.622732162475586, "val_acc": 60.0}
{"epoch": 68, "training_loss": 95.92283477783204, "training_acc": 55.0, "val_loss": 293.019287109375, "val_acc": 40.0}
