"main_modify.py --pretrained_path None --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 4 --task ADNI_sex --input_option yAware --learning_rate 5e0 --batch_size 8 --weight_decay 5e-9 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 586.2402544498443, "training_acc": 40.0, "val_loss": 332.6790466308594, "val_acc": 40.0}
{"epoch": 1, "training_loss": 366.11705322265624, "training_acc": 50.0, "val_loss": 225.6202850341797, "val_acc": 40.0}
{"epoch": 2, "training_loss": 211.82090759277344, "training_acc": 50.0, "val_loss": 248.23291015625, "val_acc": 60.0}
{"epoch": 3, "training_loss": 178.94588394165038, "training_acc": 60.0, "val_loss": 234.7512664794922, "val_acc": 40.0}
{"epoch": 4, "training_loss": 195.66722869873047, "training_acc": 50.0, "val_loss": 158.1360626220703, "val_acc": 60.0}
{"epoch": 5, "training_loss": 227.09527282714845, "training_acc": 50.0, "val_loss": 11.07196044921875, "val_acc": 60.0}
{"epoch": 6, "training_loss": 245.41427612304688, "training_acc": 40.0, "val_loss": 512.639892578125, "val_acc": 40.0}
{"epoch": 7, "training_loss": 301.57493286132814, "training_acc": 50.0, "val_loss": 168.41282653808594, "val_acc": 60.0}
{"epoch": 8, "training_loss": 330.83469543457034, "training_acc": 50.0, "val_loss": 332.1814880371094, "val_acc": 60.0}
{"epoch": 9, "training_loss": 274.6088623046875, "training_acc": 50.0, "val_loss": 313.1506042480469, "val_acc": 40.0}
{"epoch": 10, "training_loss": 432.5092407226563, "training_acc": 50.0, "val_loss": 609.0448608398438, "val_acc": 40.0}
{"epoch": 11, "training_loss": 356.1478637695312, "training_acc": 50.0, "val_loss": 146.44276428222656, "val_acc": 60.0}
{"epoch": 12, "training_loss": 279.55125427246094, "training_acc": 50.0, "val_loss": 340.2662658691406, "val_acc": 60.0}
{"epoch": 13, "training_loss": 341.4882652282715, "training_acc": 50.0, "val_loss": 236.0494842529297, "val_acc": 40.0}
{"epoch": 14, "training_loss": 269.3052673339844, "training_acc": 50.0, "val_loss": 261.7868957519531, "val_acc": 40.0}
{"epoch": 15, "training_loss": 117.34430923461915, "training_acc": 60.0, "val_loss": 331.2026062011719, "val_acc": 60.0}
{"epoch": 16, "training_loss": 419.89853515625, "training_acc": 50.0, "val_loss": 187.6192169189453, "val_acc": 60.0}
{"epoch": 17, "training_loss": 205.37963256835937, "training_acc": 40.0, "val_loss": 244.8949737548828, "val_acc": 40.0}
{"epoch": 18, "training_loss": 140.6346893310547, "training_acc": 50.0, "val_loss": 160.1010284423828, "val_acc": 60.0}
{"epoch": 19, "training_loss": 142.19810180664064, "training_acc": 50.0, "val_loss": 238.95132446289062, "val_acc": 40.0}
{"epoch": 20, "training_loss": 270.36589965820315, "training_acc": 50.0, "val_loss": 262.7032775878906, "val_acc": 40.0}
{"epoch": 21, "training_loss": 232.8595362186432, "training_acc": 30.0, "val_loss": 303.9139099121094, "val_acc": 60.0}
{"epoch": 22, "training_loss": 342.3477844238281, "training_acc": 50.0, "val_loss": 4.607064247131348, "val_acc": 40.0}
{"epoch": 23, "training_loss": 64.92135801315308, "training_acc": 50.0, "val_loss": 56.449806213378906, "val_acc": 60.0}
{"epoch": 24, "training_loss": 57.362779235839845, "training_acc": 50.0, "val_loss": 12.293498039245605, "val_acc": 60.0}
{"epoch": 25, "training_loss": 38.86867065429688, "training_acc": 50.0, "val_loss": 85.8574447631836, "val_acc": 60.0}
{"epoch": 26, "training_loss": 123.24320182800292, "training_acc": 50.0, "val_loss": 81.58448791503906, "val_acc": 40.0}
{"epoch": 27, "training_loss": 59.148292541503906, "training_acc": 50.0, "val_loss": 146.2093048095703, "val_acc": 60.0}
{"epoch": 28, "training_loss": 207.14873962402345, "training_acc": 50.0, "val_loss": 79.20108795166016, "val_acc": 60.0}
{"epoch": 29, "training_loss": 62.62357711791992, "training_acc": 70.0, "val_loss": 163.904052734375, "val_acc": 40.0}
{"epoch": 30, "training_loss": 77.00878143310547, "training_acc": 60.0, "val_loss": 221.515380859375, "val_acc": 60.0}
{"epoch": 31, "training_loss": 255.42249145507813, "training_acc": 50.0, "val_loss": 24.993793487548828, "val_acc": 40.0}
{"epoch": 32, "training_loss": 29.369382858276367, "training_acc": 40.0, "val_loss": 104.3718032836914, "val_acc": 40.0}
{"epoch": 33, "training_loss": 71.00682487487794, "training_acc": 50.0, "val_loss": 173.7589569091797, "val_acc": 60.0}
{"epoch": 34, "training_loss": 279.8335266113281, "training_acc": 50.0, "val_loss": 169.51339721679688, "val_acc": 60.0}
{"epoch": 35, "training_loss": 131.23397369384764, "training_acc": 50.0, "val_loss": 474.43902587890625, "val_acc": 40.0}
{"epoch": 36, "training_loss": 403.147900390625, "training_acc": 50.0, "val_loss": 232.5197296142578, "val_acc": 40.0}
{"epoch": 37, "training_loss": 268.5473999023437, "training_acc": 30.0, "val_loss": 232.7941436767578, "val_acc": 60.0}
{"epoch": 38, "training_loss": 183.5283432006836, "training_acc": 50.0, "val_loss": 314.5365295410156, "val_acc": 40.0}
{"epoch": 39, "training_loss": 347.9859130859375, "training_acc": 50.0, "val_loss": 504.4322204589844, "val_acc": 40.0}
{"epoch": 40, "training_loss": 291.0168788909912, "training_acc": 50.0, "val_loss": 223.91015625, "val_acc": 60.0}
{"epoch": 41, "training_loss": 442.48549194335936, "training_acc": 50.0, "val_loss": 382.81396484375, "val_acc": 60.0}
