"main_modify.py --pretrained_path None --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 2 --task ADNI_sex --input_option yAware --learning_rate 5e0 --batch_size 8 --weight_decay 5e-9 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 345.71604495048524, "training_acc": 55.0, "val_loss": 289.952392578125, "val_acc": 60.0}
{"epoch": 1, "training_loss": 445.89808349609376, "training_acc": 45.0, "val_loss": 19.952011108398438, "val_acc": 40.0}
{"epoch": 2, "training_loss": 86.62502403259278, "training_acc": 55.0, "val_loss": 128.70654296875, "val_acc": 60.0}
{"epoch": 3, "training_loss": 183.73792304992676, "training_acc": 45.0, "val_loss": 191.29006958007812, "val_acc": 40.0}
{"epoch": 4, "training_loss": 153.57656555175782, "training_acc": 55.0, "val_loss": 44.85432052612305, "val_acc": 60.0}
{"epoch": 5, "training_loss": 86.82777557373046, "training_acc": 35.0, "val_loss": 146.3289794921875, "val_acc": 40.0}
{"epoch": 6, "training_loss": 108.92650146484375, "training_acc": 35.0, "val_loss": 126.82796478271484, "val_acc": 40.0}
{"epoch": 7, "training_loss": 102.90011291503906, "training_acc": 55.0, "val_loss": 8.846915245056152, "val_acc": 60.0}
{"epoch": 8, "training_loss": 12.523641967773438, "training_acc": 55.0, "val_loss": 47.36700439453125, "val_acc": 60.0}
{"epoch": 9, "training_loss": 46.28064193725586, "training_acc": 55.0, "val_loss": 31.45257568359375, "val_acc": 60.0}
{"epoch": 10, "training_loss": 32.74131565093994, "training_acc": 45.0, "val_loss": 5.992193698883057, "val_acc": 60.0}
{"epoch": 11, "training_loss": 49.99538784027099, "training_acc": 65.0, "val_loss": 143.91357421875, "val_acc": 40.0}
{"epoch": 12, "training_loss": 85.73689270019531, "training_acc": 35.0, "val_loss": 130.58624267578125, "val_acc": 40.0}
{"epoch": 13, "training_loss": 92.0412094116211, "training_acc": 55.0, "val_loss": 58.99105453491211, "val_acc": 60.0}
{"epoch": 14, "training_loss": 70.54718933105468, "training_acc": 45.0, "val_loss": 96.75328826904297, "val_acc": 40.0}
{"epoch": 15, "training_loss": 63.38053817749024, "training_acc": 35.0, "val_loss": 43.25505447387695, "val_acc": 60.0}
{"epoch": 16, "training_loss": 36.81117553710938, "training_acc": 45.0, "val_loss": 58.0737419128418, "val_acc": 40.0}
{"epoch": 17, "training_loss": 42.99380798339844, "training_acc": 55.0, "val_loss": 65.14791107177734, "val_acc": 60.0}
{"epoch": 18, "training_loss": 26.754289627075195, "training_acc": 65.0, "val_loss": 374.6710510253906, "val_acc": 40.0}
{"epoch": 19, "training_loss": 297.50535888671874, "training_acc": 55.0, "val_loss": 199.8144989013672, "val_acc": 40.0}
{"epoch": 20, "training_loss": 129.46941223144532, "training_acc": 35.0, "val_loss": 6.786287784576416, "val_acc": 40.0}
{"epoch": 21, "training_loss": 23.153185272216795, "training_acc": 45.0, "val_loss": 116.71406555175781, "val_acc": 40.0}
{"epoch": 22, "training_loss": 68.44253234863281, "training_acc": 55.0, "val_loss": 109.06201171875, "val_acc": 60.0}
{"epoch": 23, "training_loss": 112.0625114440918, "training_acc": 45.0, "val_loss": 285.8549499511719, "val_acc": 40.0}
{"epoch": 24, "training_loss": 183.20073852539062, "training_acc": 55.0, "val_loss": 65.27137756347656, "val_acc": 60.0}
{"epoch": 25, "training_loss": 133.28673400878907, "training_acc": 45.0, "val_loss": 4.353957653045654, "val_acc": 40.0}
{"epoch": 26, "training_loss": 101.66147093772888, "training_acc": 55.0, "val_loss": 30.440750122070312, "val_acc": 60.0}
{"epoch": 27, "training_loss": 55.57512435913086, "training_acc": 35.0, "val_loss": 26.728857040405273, "val_acc": 40.0}
{"epoch": 28, "training_loss": 68.09342956542969, "training_acc": 55.0, "val_loss": 20.113765716552734, "val_acc": 60.0}
{"epoch": 29, "training_loss": 86.1052963256836, "training_acc": 55.0, "val_loss": 271.9419860839844, "val_acc": 40.0}
{"epoch": 30, "training_loss": 139.20156316757203, "training_acc": 55.0, "val_loss": 22.595273971557617, "val_acc": 60.0}
{"epoch": 31, "training_loss": 32.66087017059326, "training_acc": 55.0, "val_loss": 44.47715377807617, "val_acc": 60.0}
{"epoch": 32, "training_loss": 108.30905151367188, "training_acc": 25.0, "val_loss": 196.01284790039062, "val_acc": 40.0}
{"epoch": 33, "training_loss": 104.61387481689454, "training_acc": 55.0, "val_loss": 151.75376892089844, "val_acc": 60.0}
{"epoch": 34, "training_loss": 200.32513427734375, "training_acc": 25.0, "val_loss": 99.25582122802734, "val_acc": 40.0}
{"epoch": 35, "training_loss": 43.52020449638367, "training_acc": 45.0, "val_loss": 54.43709945678711, "val_acc": 60.0}
{"epoch": 36, "training_loss": 48.744390869140624, "training_acc": 35.0, "val_loss": 142.44151306152344, "val_acc": 60.0}
{"epoch": 37, "training_loss": 236.79342041015624, "training_acc": 45.0, "val_loss": 49.34549331665039, "val_acc": 60.0}
{"epoch": 38, "training_loss": 225.79840698242188, "training_acc": 35.0, "val_loss": 418.8653259277344, "val_acc": 40.0}
{"epoch": 39, "training_loss": 229.47344665527345, "training_acc": 55.0, "val_loss": 120.519287109375, "val_acc": 60.0}
{"epoch": 40, "training_loss": 200.27741241455078, "training_acc": 45.0, "val_loss": 108.43341064453125, "val_acc": 60.0}
{"epoch": 41, "training_loss": 98.43511581420898, "training_acc": 45.0, "val_loss": 103.38277435302734, "val_acc": 40.0}
{"epoch": 42, "training_loss": 109.81048126220703, "training_acc": 35.0, "val_loss": 167.0604705810547, "val_acc": 60.0}
{"epoch": 43, "training_loss": 159.9892364501953, "training_acc": 45.0, "val_loss": 241.31265258789062, "val_acc": 40.0}
{"epoch": 44, "training_loss": 164.610107421875, "training_acc": 55.0, "val_loss": 48.230892181396484, "val_acc": 60.0}
