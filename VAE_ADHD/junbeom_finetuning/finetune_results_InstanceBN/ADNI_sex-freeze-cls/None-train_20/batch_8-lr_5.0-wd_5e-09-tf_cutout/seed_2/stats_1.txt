"main_modify.py --pretrained_path None --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 2 --task ADNI_sex --input_option yAware --learning_rate 5e0 --batch_size 8 --weight_decay 5e-9 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 317.33321006298064, "training_acc": 50.0, "val_loss": 39.16178512573242, "val_acc": 40.0}
{"epoch": 1, "training_loss": 258.601123046875, "training_acc": 40.0, "val_loss": 36.762821197509766, "val_acc": 60.0}
{"epoch": 2, "training_loss": 192.84310607910157, "training_acc": 60.0, "val_loss": 558.2030029296875, "val_acc": 40.0}
{"epoch": 3, "training_loss": 315.8557388305664, "training_acc": 50.0, "val_loss": 309.7672424316406, "val_acc": 60.0}
{"epoch": 4, "training_loss": 473.650927734375, "training_acc": 50.0, "val_loss": 401.7762145996094, "val_acc": 60.0}
{"epoch": 5, "training_loss": 310.8612739562988, "training_acc": 50.0, "val_loss": 485.276611328125, "val_acc": 40.0}
{"epoch": 6, "training_loss": 617.1113037109375, "training_acc": 50.0, "val_loss": 880.2427978515625, "val_acc": 40.0}
{"epoch": 7, "training_loss": 616.7992248535156, "training_acc": 50.0, "val_loss": 12.13792610168457, "val_acc": 40.0}
{"epoch": 8, "training_loss": 266.0552547454834, "training_acc": 60.0, "val_loss": 566.44140625, "val_acc": 60.0}
{"epoch": 9, "training_loss": 647.5991333007812, "training_acc": 50.0, "val_loss": 200.46824645996094, "val_acc": 60.0}
{"epoch": 10, "training_loss": 299.8106994628906, "training_acc": 40.0, "val_loss": 421.7520446777344, "val_acc": 40.0}
{"epoch": 11, "training_loss": 252.95000610351562, "training_acc": 50.0, "val_loss": 159.7438201904297, "val_acc": 60.0}
{"epoch": 12, "training_loss": 254.58327026367186, "training_acc": 50.0, "val_loss": 276.8533630371094, "val_acc": 60.0}
{"epoch": 13, "training_loss": 214.96790161132813, "training_acc": 50.0, "val_loss": 304.8536071777344, "val_acc": 40.0}
{"epoch": 14, "training_loss": 396.14462890625, "training_acc": 50.0, "val_loss": 631.943603515625, "val_acc": 40.0}
{"epoch": 15, "training_loss": 417.74244384765626, "training_acc": 50.0, "val_loss": 106.2940673828125, "val_acc": 60.0}
{"epoch": 16, "training_loss": 199.5128601074219, "training_acc": 50.0, "val_loss": 195.58006286621094, "val_acc": 60.0}
{"epoch": 17, "training_loss": 203.91531372070312, "training_acc": 40.0, "val_loss": 266.1659240722656, "val_acc": 40.0}
{"epoch": 18, "training_loss": 176.4113983154297, "training_acc": 50.0, "val_loss": 125.89591217041016, "val_acc": 60.0}
{"epoch": 19, "training_loss": 188.055859375, "training_acc": 50.0, "val_loss": 140.1991729736328, "val_acc": 60.0}
{"epoch": 20, "training_loss": 116.94076232910156, "training_acc": 50.0, "val_loss": 277.7518005371094, "val_acc": 40.0}
{"epoch": 21, "training_loss": 188.02630310058595, "training_acc": 50.0, "val_loss": 96.9671859741211, "val_acc": 60.0}
{"epoch": 22, "training_loss": 133.70035552978516, "training_acc": 50.0, "val_loss": 6.237178325653076, "val_acc": 60.0}
{"epoch": 23, "training_loss": 124.70872116088867, "training_acc": 60.0, "val_loss": 373.260498046875, "val_acc": 40.0}
{"epoch": 24, "training_loss": 212.20897216796874, "training_acc": 50.0, "val_loss": 168.21176147460938, "val_acc": 60.0}
{"epoch": 25, "training_loss": 343.1720764160156, "training_acc": 50.0, "val_loss": 362.03643798828125, "val_acc": 60.0}
{"epoch": 26, "training_loss": 323.9058532714844, "training_acc": 50.0, "val_loss": 192.24215698242188, "val_acc": 40.0}
{"epoch": 27, "training_loss": 246.19183654785155, "training_acc": 50.0, "val_loss": 440.1015319824219, "val_acc": 40.0}
{"epoch": 28, "training_loss": 310.1033447265625, "training_acc": 50.0, "val_loss": 142.48275756835938, "val_acc": 60.0}
{"epoch": 29, "training_loss": 243.0165588378906, "training_acc": 50.0, "val_loss": 126.194580078125, "val_acc": 60.0}
{"epoch": 30, "training_loss": 74.51271209716796, "training_acc": 60.0, "val_loss": 162.6810760498047, "val_acc": 40.0}
{"epoch": 31, "training_loss": 78.51954193115235, "training_acc": 60.0, "val_loss": 127.48345184326172, "val_acc": 60.0}
{"epoch": 32, "training_loss": 121.8265884399414, "training_acc": 50.0, "val_loss": 232.81382751464844, "val_acc": 40.0}
{"epoch": 33, "training_loss": 242.18323974609376, "training_acc": 50.0, "val_loss": 167.92080688476562, "val_acc": 40.0}
{"epoch": 34, "training_loss": 114.18028564453125, "training_acc": 50.0, "val_loss": 107.5408706665039, "val_acc": 60.0}
{"epoch": 35, "training_loss": 122.67526245117188, "training_acc": 40.0, "val_loss": 312.8318786621094, "val_acc": 40.0}
{"epoch": 36, "training_loss": 197.2104347229004, "training_acc": 50.0, "val_loss": 137.474609375, "val_acc": 60.0}
{"epoch": 37, "training_loss": 261.52861328125, "training_acc": 50.0, "val_loss": 146.12571716308594, "val_acc": 60.0}
{"epoch": 38, "training_loss": 93.08047332763672, "training_acc": 60.0, "val_loss": 358.52838134765625, "val_acc": 40.0}
{"epoch": 39, "training_loss": 298.583642578125, "training_acc": 50.0, "val_loss": 91.38964080810547, "val_acc": 40.0}
{"epoch": 40, "training_loss": 205.169287109375, "training_acc": 50.0, "val_loss": 307.6407165527344, "val_acc": 60.0}
{"epoch": 41, "training_loss": 298.1908813476563, "training_acc": 50.0, "val_loss": 174.04356384277344, "val_acc": 40.0}
