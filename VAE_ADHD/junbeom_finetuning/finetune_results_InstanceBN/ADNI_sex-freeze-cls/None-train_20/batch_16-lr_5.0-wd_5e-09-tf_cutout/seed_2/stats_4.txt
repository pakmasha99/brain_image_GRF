"main_modify.py --pretrained_path None --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 2 --task ADNI_sex --input_option yAware --learning_rate 5e0 --batch_size 16 --weight_decay 5e-9 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 215.6065800189972, "training_acc": 45.0, "val_loss": 478.31158447265625, "val_acc": 40.0}
{"epoch": 1, "training_loss": 455.69232177734375, "training_acc": 45.0, "val_loss": 387.4290466308594, "val_acc": 60.0}
{"epoch": 2, "training_loss": 462.25803833007814, "training_acc": 45.0, "val_loss": 270.76031494140625, "val_acc": 40.0}
{"epoch": 3, "training_loss": 223.530078125, "training_acc": 55.0, "val_loss": 619.2105712890625, "val_acc": 40.0}
{"epoch": 4, "training_loss": 464.743701171875, "training_acc": 55.0, "val_loss": 358.408935546875, "val_acc": 40.0}
{"epoch": 5, "training_loss": 244.51040840148926, "training_acc": 55.0, "val_loss": 191.92384338378906, "val_acc": 60.0}
{"epoch": 6, "training_loss": 280.77149658203126, "training_acc": 45.0, "val_loss": 207.9670867919922, "val_acc": 60.0}
{"epoch": 7, "training_loss": 226.84364318847656, "training_acc": 45.0, "val_loss": 352.1922912597656, "val_acc": 40.0}
{"epoch": 8, "training_loss": 305.34886474609374, "training_acc": 55.0, "val_loss": 668.6815795898438, "val_acc": 40.0}
{"epoch": 9, "training_loss": 494.2990447998047, "training_acc": 55.0, "val_loss": 431.73614501953125, "val_acc": 40.0}
{"epoch": 10, "training_loss": 279.8832977294922, "training_acc": 55.0, "val_loss": 140.2139129638672, "val_acc": 60.0}
{"epoch": 11, "training_loss": 221.38804931640624, "training_acc": 45.0, "val_loss": 267.082275390625, "val_acc": 60.0}
{"epoch": 12, "training_loss": 342.5972045898437, "training_acc": 45.0, "val_loss": 7.65675687789917, "val_acc": 40.0}
{"epoch": 13, "training_loss": 24.836115264892577, "training_acc": 55.0, "val_loss": 94.0380630493164, "val_acc": 40.0}
{"epoch": 14, "training_loss": 79.53516845703125, "training_acc": 45.0, "val_loss": 10.602660179138184, "val_acc": 60.0}
{"epoch": 15, "training_loss": 23.71328659057617, "training_acc": 55.0, "val_loss": 263.2340393066406, "val_acc": 40.0}
{"epoch": 16, "training_loss": 193.84448852539063, "training_acc": 55.0, "val_loss": 45.69108200073242, "val_acc": 40.0}
{"epoch": 17, "training_loss": 128.43505249023437, "training_acc": 35.0, "val_loss": 214.61753845214844, "val_acc": 60.0}
{"epoch": 18, "training_loss": 271.232275390625, "training_acc": 45.0, "val_loss": 35.88654708862305, "val_acc": 40.0}
{"epoch": 19, "training_loss": 26.237579345703125, "training_acc": 55.0, "val_loss": 227.44725036621094, "val_acc": 40.0}
{"epoch": 20, "training_loss": 166.42425079345702, "training_acc": 55.0, "val_loss": 86.66476440429688, "val_acc": 40.0}
{"epoch": 21, "training_loss": 88.89000244140625, "training_acc": 45.0, "val_loss": 89.96633911132812, "val_acc": 60.0}
{"epoch": 22, "training_loss": 131.5525390625, "training_acc": 25.0, "val_loss": 45.415706634521484, "val_acc": 60.0}
{"epoch": 23, "training_loss": 56.040910959243774, "training_acc": 45.0, "val_loss": 111.0338363647461, "val_acc": 40.0}
{"epoch": 24, "training_loss": 82.31160888671874, "training_acc": 55.0, "val_loss": 6.475799083709717, "val_acc": 60.0}
{"epoch": 25, "training_loss": 14.962532043457031, "training_acc": 35.0, "val_loss": 71.76195526123047, "val_acc": 60.0}
{"epoch": 26, "training_loss": 99.13355102539063, "training_acc": 45.0, "val_loss": 54.67257308959961, "val_acc": 40.0}
{"epoch": 27, "training_loss": 48.0391342163086, "training_acc": 55.0, "val_loss": 31.093753814697266, "val_acc": 40.0}
{"epoch": 28, "training_loss": 40.47237854003906, "training_acc": 55.0, "val_loss": 116.05168914794922, "val_acc": 60.0}
{"epoch": 29, "training_loss": 140.8930992126465, "training_acc": 45.0, "val_loss": 139.4847869873047, "val_acc": 40.0}
{"epoch": 30, "training_loss": 117.68138427734375, "training_acc": 55.0, "val_loss": 183.91464233398438, "val_acc": 40.0}
{"epoch": 31, "training_loss": 104.97781066894531, "training_acc": 55.0, "val_loss": 156.6345977783203, "val_acc": 60.0}
{"epoch": 32, "training_loss": 235.19296264648438, "training_acc": 45.0, "val_loss": 240.4517364501953, "val_acc": 60.0}
{"epoch": 33, "training_loss": 306.21637268066405, "training_acc": 45.0, "val_loss": 17.01610565185547, "val_acc": 40.0}
{"epoch": 34, "training_loss": 11.1108642578125, "training_acc": 55.0, "val_loss": 175.16160583496094, "val_acc": 40.0}
{"epoch": 35, "training_loss": 124.33558349609375, "training_acc": 55.0, "val_loss": 30.783716201782227, "val_acc": 60.0}
{"epoch": 36, "training_loss": 65.13141174316407, "training_acc": 45.0, "val_loss": 50.6661491394043, "val_acc": 40.0}
{"epoch": 37, "training_loss": 44.060018920898436, "training_acc": 55.0, "val_loss": 26.92339515686035, "val_acc": 40.0}
{"epoch": 38, "training_loss": 75.52802886962891, "training_acc": 35.0, "val_loss": 78.3255386352539, "val_acc": 60.0}
{"epoch": 39, "training_loss": 97.271240234375, "training_acc": 45.0, "val_loss": 112.35626220703125, "val_acc": 40.0}
{"epoch": 40, "training_loss": 71.36971130371094, "training_acc": 55.0, "val_loss": 99.12247467041016, "val_acc": 60.0}
{"epoch": 41, "training_loss": 153.42962036132812, "training_acc": 45.0, "val_loss": 80.9439697265625, "val_acc": 60.0}
{"epoch": 42, "training_loss": 106.26505432128906, "training_acc": 45.0, "val_loss": 190.07273864746094, "val_acc": 40.0}
{"epoch": 43, "training_loss": 140.5999755859375, "training_acc": 55.0, "val_loss": 89.95291137695312, "val_acc": 40.0}
