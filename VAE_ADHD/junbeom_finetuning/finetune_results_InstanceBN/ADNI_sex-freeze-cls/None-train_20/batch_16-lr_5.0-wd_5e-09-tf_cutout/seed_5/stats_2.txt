"main_modify.py --pretrained_path None --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 5 --task ADNI_sex --input_option yAware --learning_rate 5e0 --batch_size 16 --weight_decay 5e-9 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 84.73307943344116, "training_acc": 50.0, "val_loss": 407.8662109375, "val_acc": 60.0}
{"epoch": 1, "training_loss": 569.807666015625, "training_acc": 50.0, "val_loss": 324.166259765625, "val_acc": 60.0}
{"epoch": 2, "training_loss": 289.12228908538816, "training_acc": 60.0, "val_loss": 344.20440673828125, "val_acc": 40.0}
{"epoch": 3, "training_loss": 295.302001953125, "training_acc": 50.0, "val_loss": 102.8373031616211, "val_acc": 40.0}
{"epoch": 4, "training_loss": 84.55887756347656, "training_acc": 60.0, "val_loss": 382.7179260253906, "val_acc": 60.0}
{"epoch": 5, "training_loss": 490.270947265625, "training_acc": 50.0, "val_loss": 320.4521484375, "val_acc": 60.0}
{"epoch": 6, "training_loss": 336.41392822265624, "training_acc": 50.0, "val_loss": 249.7309112548828, "val_acc": 40.0}
{"epoch": 7, "training_loss": 247.02463989257814, "training_acc": 50.0, "val_loss": 572.8753662109375, "val_acc": 40.0}
{"epoch": 8, "training_loss": 474.8453125, "training_acc": 50.0, "val_loss": 341.40093994140625, "val_acc": 40.0}
{"epoch": 9, "training_loss": 225.7210479736328, "training_acc": 50.0, "val_loss": 188.4063262939453, "val_acc": 60.0}
{"epoch": 10, "training_loss": 255.94302978515626, "training_acc": 50.0, "val_loss": 399.898681640625, "val_acc": 60.0}
{"epoch": 11, "training_loss": 498.681591796875, "training_acc": 50.0, "val_loss": 265.8642578125, "val_acc": 60.0}
{"epoch": 12, "training_loss": 289.02178955078125, "training_acc": 50.0, "val_loss": 265.4309997558594, "val_acc": 40.0}
{"epoch": 13, "training_loss": 254.23585205078126, "training_acc": 50.0, "val_loss": 537.72412109375, "val_acc": 40.0}
{"epoch": 14, "training_loss": 430.1325927734375, "training_acc": 50.0, "val_loss": 226.9203643798828, "val_acc": 40.0}
{"epoch": 15, "training_loss": 170.62671813964843, "training_acc": 50.0, "val_loss": 203.35472106933594, "val_acc": 60.0}
{"epoch": 16, "training_loss": 265.3588012695312, "training_acc": 50.0, "val_loss": 168.94493103027344, "val_acc": 60.0}
{"epoch": 17, "training_loss": 166.8297866821289, "training_acc": 50.0, "val_loss": 294.5091247558594, "val_acc": 40.0}
{"epoch": 18, "training_loss": 258.2402862548828, "training_acc": 50.0, "val_loss": 578.6787719726562, "val_acc": 40.0}
{"epoch": 19, "training_loss": 474.29503173828124, "training_acc": 50.0, "val_loss": 357.9049072265625, "val_acc": 40.0}
{"epoch": 20, "training_loss": 245.89069061279298, "training_acc": 50.0, "val_loss": 227.90966796875, "val_acc": 60.0}
{"epoch": 21, "training_loss": 308.2856384277344, "training_acc": 50.0, "val_loss": 465.3273620605469, "val_acc": 60.0}
{"epoch": 22, "training_loss": 584.6587524414062, "training_acc": 50.0, "val_loss": 401.6129150390625, "val_acc": 60.0}
{"epoch": 23, "training_loss": 474.51746826171876, "training_acc": 50.0, "val_loss": 70.04107666015625, "val_acc": 60.0}
{"epoch": 24, "training_loss": 88.00304870605468, "training_acc": 60.0, "val_loss": 553.330078125, "val_acc": 40.0}
{"epoch": 25, "training_loss": 469.26080322265625, "training_acc": 50.0, "val_loss": 703.3678588867188, "val_acc": 40.0}
{"epoch": 26, "training_loss": 563.5473876953125, "training_acc": 50.0, "val_loss": 339.99835205078125, "val_acc": 40.0}
{"epoch": 27, "training_loss": 309.2467315673828, "training_acc": 30.0, "val_loss": 140.2115936279297, "val_acc": 60.0}
{"epoch": 28, "training_loss": 179.2754913330078, "training_acc": 50.0, "val_loss": 78.3386001586914, "val_acc": 60.0}
{"epoch": 29, "training_loss": 91.60821228027343, "training_acc": 50.0, "val_loss": 114.66387939453125, "val_acc": 40.0}
{"epoch": 30, "training_loss": 86.06084871292114, "training_acc": 50.0, "val_loss": 76.51897430419922, "val_acc": 60.0}
{"epoch": 31, "training_loss": 102.56796875, "training_acc": 50.0, "val_loss": 5.043235778808594, "val_acc": 60.0}
{"epoch": 32, "training_loss": 43.488155364990234, "training_acc": 50.0, "val_loss": 292.1122741699219, "val_acc": 40.0}
{"epoch": 33, "training_loss": 232.93704223632812, "training_acc": 50.0, "val_loss": 75.38848114013672, "val_acc": 40.0}
{"epoch": 34, "training_loss": 81.4517608642578, "training_acc": 50.0, "val_loss": 209.1573028564453, "val_acc": 60.0}
{"epoch": 35, "training_loss": 265.842431640625, "training_acc": 50.0, "val_loss": 91.66265869140625, "val_acc": 60.0}
{"epoch": 36, "training_loss": 93.94252319335938, "training_acc": 60.0, "val_loss": 306.6809997558594, "val_acc": 40.0}
{"epoch": 37, "training_loss": 256.5612060546875, "training_acc": 50.0, "val_loss": 293.7030944824219, "val_acc": 40.0}
{"epoch": 38, "training_loss": 227.2684181213379, "training_acc": 50.0, "val_loss": 60.83492660522461, "val_acc": 60.0}
{"epoch": 39, "training_loss": 103.64125366210938, "training_acc": 50.0, "val_loss": 49.52223587036133, "val_acc": 60.0}
{"epoch": 40, "training_loss": 75.5487564086914, "training_acc": 50.0, "val_loss": 210.2161407470703, "val_acc": 40.0}
{"epoch": 41, "training_loss": 167.25491333007812, "training_acc": 50.0, "val_loss": 9.725778579711914, "val_acc": 40.0}
{"epoch": 42, "training_loss": 65.78473510742188, "training_acc": 40.0, "val_loss": 185.3474884033203, "val_acc": 60.0}
{"epoch": 43, "training_loss": 222.56370849609374, "training_acc": 50.0, "val_loss": 0.5054677128791809, "val_acc": 80.0}
{"epoch": 44, "training_loss": 39.827731418609616, "training_acc": 60.0, "val_loss": 331.820068359375, "val_acc": 40.0}
{"epoch": 45, "training_loss": 268.1598327636719, "training_acc": 50.0, "val_loss": 99.7543716430664, "val_acc": 40.0}
{"epoch": 46, "training_loss": 100.25244750976563, "training_acc": 50.0, "val_loss": 238.33580017089844, "val_acc": 60.0}
{"epoch": 47, "training_loss": 302.1083984375, "training_acc": 50.0, "val_loss": 220.5045928955078, "val_acc": 60.0}
{"epoch": 48, "training_loss": 268.87503814697266, "training_acc": 50.0, "val_loss": 9.549664497375488, "val_acc": 40.0}
{"epoch": 49, "training_loss": 22.258825492858886, "training_acc": 50.0, "val_loss": 22.341108322143555, "val_acc": 60.0}
{"epoch": 50, "training_loss": 33.60465850830078, "training_acc": 50.0, "val_loss": 139.91065979003906, "val_acc": 40.0}
{"epoch": 51, "training_loss": 120.3826416015625, "training_acc": 50.0, "val_loss": 96.22933959960938, "val_acc": 40.0}
{"epoch": 52, "training_loss": 78.48053588867188, "training_acc": 50.0, "val_loss": 101.72672271728516, "val_acc": 60.0}
{"epoch": 53, "training_loss": 120.37605590820313, "training_acc": 50.0, "val_loss": 99.2523193359375, "val_acc": 40.0}
{"epoch": 54, "training_loss": 88.34166717529297, "training_acc": 50.0, "val_loss": 63.181617736816406, "val_acc": 40.0}
{"epoch": 55, "training_loss": 44.77866897583008, "training_acc": 60.0, "val_loss": 141.83164978027344, "val_acc": 60.0}
{"epoch": 56, "training_loss": 177.76700134277343, "training_acc": 50.0, "val_loss": 18.734067916870117, "val_acc": 60.0}
{"epoch": 57, "training_loss": 85.96312866210937, "training_acc": 40.0, "val_loss": 303.1361389160156, "val_acc": 40.0}
{"epoch": 58, "training_loss": 251.043505859375, "training_acc": 50.0, "val_loss": 117.64373016357422, "val_acc": 40.0}
{"epoch": 59, "training_loss": 73.65413055419921, "training_acc": 60.0, "val_loss": 112.44563293457031, "val_acc": 60.0}
{"epoch": 60, "training_loss": 142.5930290222168, "training_acc": 50.0, "val_loss": 16.13899803161621, "val_acc": 60.0}
{"epoch": 61, "training_loss": 71.70748748779297, "training_acc": 40.0, "val_loss": 219.2296142578125, "val_acc": 40.0}
{"epoch": 62, "training_loss": 181.2506591796875, "training_acc": 50.0, "val_loss": 19.79065704345703, "val_acc": 60.0}
