"main_modify.py --pretrained_path None --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 5 --task ADNI_sex --input_option yAware --learning_rate 5e0 --batch_size 16 --weight_decay 5e-9 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 107.9514904975891, "training_acc": 60.0, "val_loss": 365.8306579589844, "val_acc": 60.0}
{"epoch": 1, "training_loss": 274.129345703125, "training_acc": 70.0, "val_loss": 1276.802734375, "val_acc": 40.0}
{"epoch": 2, "training_loss": 1066.7918701171875, "training_acc": 50.0, "val_loss": 779.0615234375, "val_acc": 40.0}
{"epoch": 3, "training_loss": 533.5846801757813, "training_acc": 50.0, "val_loss": 490.2409362792969, "val_acc": 60.0}
{"epoch": 4, "training_loss": 729.850927734375, "training_acc": 50.0, "val_loss": 835.4071655273438, "val_acc": 60.0}
{"epoch": 5, "training_loss": 1016.939208984375, "training_acc": 50.0, "val_loss": 513.5773315429688, "val_acc": 60.0}
{"epoch": 6, "training_loss": 500.24736328125, "training_acc": 50.0, "val_loss": 300.3505554199219, "val_acc": 40.0}
{"epoch": 7, "training_loss": 282.6896118164062, "training_acc": 50.0, "val_loss": 963.8697509765625, "val_acc": 40.0}
{"epoch": 8, "training_loss": 808.8889770507812, "training_acc": 50.0, "val_loss": 1024.4815673828125, "val_acc": 40.0}
{"epoch": 9, "training_loss": 818.700244140625, "training_acc": 50.0, "val_loss": 552.9795532226562, "val_acc": 40.0}
{"epoch": 10, "training_loss": 387.96861267089844, "training_acc": 50.0, "val_loss": 272.4381103515625, "val_acc": 60.0}
{"epoch": 11, "training_loss": 395.464990234375, "training_acc": 50.0, "val_loss": 600.7531127929688, "val_acc": 60.0}
{"epoch": 12, "training_loss": 751.582763671875, "training_acc": 50.0, "val_loss": 521.879150390625, "val_acc": 60.0}
{"epoch": 13, "training_loss": 629.9990356445312, "training_acc": 50.0, "val_loss": 144.14248657226562, "val_acc": 60.0}
{"epoch": 14, "training_loss": 175.38968505859376, "training_acc": 50.0, "val_loss": 420.54345703125, "val_acc": 40.0}
{"epoch": 15, "training_loss": 362.5170837402344, "training_acc": 50.0, "val_loss": 431.3714904785156, "val_acc": 40.0}
{"epoch": 16, "training_loss": 341.9841705322266, "training_acc": 50.0, "val_loss": 16.2391300201416, "val_acc": 60.0}
{"epoch": 17, "training_loss": 47.87294921875, "training_acc": 50.0, "val_loss": 26.57996940612793, "val_acc": 60.0}
{"epoch": 18, "training_loss": 76.9692169189453, "training_acc": 40.0, "val_loss": 204.16461181640625, "val_acc": 40.0}
{"epoch": 19, "training_loss": 150.66966247558594, "training_acc": 50.0, "val_loss": 91.80264282226562, "val_acc": 60.0}
{"epoch": 20, "training_loss": 119.54190216064453, "training_acc": 50.0, "val_loss": 130.25062561035156, "val_acc": 60.0}
{"epoch": 21, "training_loss": 140.43662109375, "training_acc": 50.0, "val_loss": 181.24810791015625, "val_acc": 40.0}
{"epoch": 22, "training_loss": 165.9127624511719, "training_acc": 50.0, "val_loss": 233.15049743652344, "val_acc": 40.0}
{"epoch": 23, "training_loss": 156.5019729614258, "training_acc": 50.0, "val_loss": 156.95278930664062, "val_acc": 60.0}
{"epoch": 24, "training_loss": 222.73380126953126, "training_acc": 50.0, "val_loss": 279.9342041015625, "val_acc": 60.0}
{"epoch": 25, "training_loss": 331.7320251464844, "training_acc": 50.0, "val_loss": 62.368865966796875, "val_acc": 60.0}
{"epoch": 26, "training_loss": 130.31342163085938, "training_acc": 40.0, "val_loss": 360.4498596191406, "val_acc": 40.0}
{"epoch": 27, "training_loss": 296.7024200439453, "training_acc": 50.0, "val_loss": 232.0030059814453, "val_acc": 40.0}
{"epoch": 28, "training_loss": 174.04896860122682, "training_acc": 50.0, "val_loss": 170.93235778808594, "val_acc": 60.0}
{"epoch": 29, "training_loss": 245.34852294921876, "training_acc": 50.0, "val_loss": 210.559814453125, "val_acc": 60.0}
{"epoch": 30, "training_loss": 231.4451705932617, "training_acc": 50.0, "val_loss": 163.5454864501953, "val_acc": 40.0}
{"epoch": 31, "training_loss": 145.99878692626953, "training_acc": 50.0, "val_loss": 336.6275939941406, "val_acc": 40.0}
{"epoch": 32, "training_loss": 266.07322998046874, "training_acc": 50.0, "val_loss": 59.515419006347656, "val_acc": 40.0}
{"epoch": 33, "training_loss": 79.11610107421875, "training_acc": 50.0, "val_loss": 259.61407470703125, "val_acc": 60.0}
{"epoch": 34, "training_loss": 322.99627685546875, "training_acc": 50.0, "val_loss": 207.83352661132812, "val_acc": 60.0}
{"epoch": 35, "training_loss": 242.25972366333008, "training_acc": 50.0, "val_loss": 138.312255859375, "val_acc": 40.0}
