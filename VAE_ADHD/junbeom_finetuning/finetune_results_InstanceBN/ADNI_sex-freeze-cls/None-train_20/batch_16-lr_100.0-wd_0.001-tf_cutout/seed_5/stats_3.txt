"main_modify.py --pretrained_path None --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 5 --task ADNI_sex --input_option yAware --learning_rate 1e2 --batch_size 16 --weight_decay 1e-3 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 2664.080996990204, "training_acc": 50.0, "val_loss": 8376.9521484375, "val_acc": 40.0}
{"epoch": 1, "training_loss": 7433.05078125, "training_acc": 50.0, "val_loss": 6147.89404296875, "val_acc": 40.0}
{"epoch": 2, "training_loss": 5551.90244140625, "training_acc": 40.0, "val_loss": 3077.71923828125, "val_acc": 60.0}
{"epoch": 3, "training_loss": 3270.671337890625, "training_acc": 50.0, "val_loss": 5418.44384765625, "val_acc": 40.0}
{"epoch": 4, "training_loss": 4815.80595703125, "training_acc": 50.0, "val_loss": 5051.21630859375, "val_acc": 40.0}
{"epoch": 5, "training_loss": 3919.840441894531, "training_acc": 40.0, "val_loss": 603.773193359375, "val_acc": 60.0}
{"epoch": 6, "training_loss": 659.7026611328125, "training_acc": 60.0, "val_loss": 1712.806884765625, "val_acc": 40.0}
{"epoch": 7, "training_loss": 1537.012109375, "training_acc": 40.0, "val_loss": 572.30078125, "val_acc": 40.0}
{"epoch": 8, "training_loss": 479.09169921875, "training_acc": 50.0, "val_loss": 900.2346801757812, "val_acc": 40.0}
{"epoch": 9, "training_loss": 523.6962734222412, "training_acc": 50.0, "val_loss": 2947.8701171875, "val_acc": 60.0}
{"epoch": 10, "training_loss": 3904.52177734375, "training_acc": 50.0, "val_loss": 2862.991943359375, "val_acc": 60.0}
{"epoch": 11, "training_loss": 3219.168515777588, "training_acc": 50.0, "val_loss": 4825.89208984375, "val_acc": 40.0}
{"epoch": 12, "training_loss": 4331.7150390625, "training_acc": 50.0, "val_loss": 5700.02197265625, "val_acc": 40.0}
{"epoch": 13, "training_loss": 3952.27080078125, "training_acc": 50.0, "val_loss": 2580.672607421875, "val_acc": 60.0}
{"epoch": 14, "training_loss": 3757.06640625, "training_acc": 50.0, "val_loss": 4973.4033203125, "val_acc": 60.0}
{"epoch": 15, "training_loss": 5990.529467773437, "training_acc": 50.0, "val_loss": 793.9605712890625, "val_acc": 60.0}
{"epoch": 16, "training_loss": 1535.190478515625, "training_acc": 50.0, "val_loss": 7082.9072265625, "val_acc": 40.0}
{"epoch": 17, "training_loss": 5859.75908203125, "training_acc": 50.0, "val_loss": 4059.345703125, "val_acc": 40.0}
{"epoch": 18, "training_loss": 3334.9262451171876, "training_acc": 40.0, "val_loss": 1596.40673828125, "val_acc": 60.0}
{"epoch": 19, "training_loss": 1790.6243286132812, "training_acc": 50.0, "val_loss": 2251.664794921875, "val_acc": 40.0}
{"epoch": 20, "training_loss": 1911.624365234375, "training_acc": 50.0, "val_loss": 1854.5623779296875, "val_acc": 40.0}
{"epoch": 21, "training_loss": 1771.938134765625, "training_acc": 40.0, "val_loss": 741.1503295898438, "val_acc": 60.0}
{"epoch": 22, "training_loss": 1003.1485595703125, "training_acc": 50.0, "val_loss": 1629.06884765625, "val_acc": 40.0}
{"epoch": 23, "training_loss": 1441.77861328125, "training_acc": 40.0, "val_loss": 244.19773864746094, "val_acc": 40.0}
{"epoch": 24, "training_loss": 200.60681762695313, "training_acc": 60.0, "val_loss": 267.4214782714844, "val_acc": 60.0}
{"epoch": 25, "training_loss": 388.25164794921875, "training_acc": 60.0, "val_loss": 2693.29931640625, "val_acc": 40.0}
{"epoch": 26, "training_loss": 1970.6003295898438, "training_acc": 50.0, "val_loss": 1828.313720703125, "val_acc": 60.0}
{"epoch": 27, "training_loss": 2451.94501953125, "training_acc": 50.0, "val_loss": 1497.636474609375, "val_acc": 60.0}
{"epoch": 28, "training_loss": 1408.1314819335937, "training_acc": 60.0, "val_loss": 3162.6259765625, "val_acc": 40.0}
{"epoch": 29, "training_loss": 2533.162109375, "training_acc": 50.0, "val_loss": 776.7636108398438, "val_acc": 60.0}
{"epoch": 30, "training_loss": 1042.621142578125, "training_acc": 50.0, "val_loss": 1094.158203125, "val_acc": 60.0}
{"epoch": 31, "training_loss": 1278.301123046875, "training_acc": 50.0, "val_loss": 1247.235595703125, "val_acc": 40.0}
{"epoch": 32, "training_loss": 1254.85390625, "training_acc": 40.0, "val_loss": 39.71133041381836, "val_acc": 60.0}
{"epoch": 33, "training_loss": 1349.8870727539063, "training_acc": 30.0, "val_loss": 2750.075927734375, "val_acc": 40.0}
{"epoch": 34, "training_loss": 2293.08125, "training_acc": 40.0, "val_loss": 552.8916015625, "val_acc": 60.0}
{"epoch": 35, "training_loss": 587.4526611328125, "training_acc": 60.0, "val_loss": 1959.770751953125, "val_acc": 40.0}
{"epoch": 36, "training_loss": 1474.0864974975586, "training_acc": 40.0, "val_loss": 1569.3817138671875, "val_acc": 40.0}
{"epoch": 37, "training_loss": 1157.98095703125, "training_acc": 50.0, "val_loss": 1968.6715087890625, "val_acc": 60.0}
{"epoch": 38, "training_loss": 2655.56103515625, "training_acc": 50.0, "val_loss": 1856.0238037109375, "val_acc": 60.0}
{"epoch": 39, "training_loss": 1986.1632568359375, "training_acc": 50.0, "val_loss": 1725.0985107421875, "val_acc": 40.0}
{"epoch": 40, "training_loss": 1190.967950439453, "training_acc": 50.0, "val_loss": 2220.558349609375, "val_acc": 60.0}
{"epoch": 41, "training_loss": 2913.64697265625, "training_acc": 50.0, "val_loss": 1665.7122802734375, "val_acc": 60.0}
{"epoch": 42, "training_loss": 2282.51806640625, "training_acc": 40.0, "val_loss": 1920.3319091796875, "val_acc": 40.0}
{"epoch": 43, "training_loss": 1150.8428588867187, "training_acc": 50.0, "val_loss": 3227.79150390625, "val_acc": 60.0}
{"epoch": 44, "training_loss": 4178.178564453125, "training_acc": 50.0, "val_loss": 4521.8388671875, "val_acc": 60.0}
{"epoch": 45, "training_loss": 5256.00546875, "training_acc": 50.0, "val_loss": 128.65379333496094, "val_acc": 40.0}
{"epoch": 46, "training_loss": 414.85069580078124, "training_acc": 50.0, "val_loss": 1309.5552978515625, "val_acc": 40.0}
{"epoch": 47, "training_loss": 1137.56328125, "training_acc": 50.0, "val_loss": 1266.7801513671875, "val_acc": 60.0}
{"epoch": 48, "training_loss": 1134.68271484375, "training_acc": 50.0, "val_loss": 4869.00927734375, "val_acc": 40.0}
{"epoch": 49, "training_loss": 4055.459765625, "training_acc": 50.0, "val_loss": 7390.01904296875, "val_acc": 40.0}
{"epoch": 50, "training_loss": 5885.9185546875, "training_acc": 50.0, "val_loss": 1814.139892578125, "val_acc": 40.0}
{"epoch": 51, "training_loss": 2449.20859375, "training_acc": 40.0, "val_loss": 4229.66650390625, "val_acc": 60.0}
