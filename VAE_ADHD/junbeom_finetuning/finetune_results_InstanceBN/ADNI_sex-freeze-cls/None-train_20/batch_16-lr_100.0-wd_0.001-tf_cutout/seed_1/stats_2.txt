"main_modify.py --pretrained_path None --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 1 --task ADNI_sex --input_option yAware --learning_rate 1e2 --batch_size 16 --weight_decay 1e-3 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 6446.596356582641, "training_acc": 40.0, "val_loss": 9055.36328125, "val_acc": 40.0}
{"epoch": 1, "training_loss": 9474.555859375, "training_acc": 40.0, "val_loss": 10153.5859375, "val_acc": 60.0}
{"epoch": 2, "training_loss": 12458.9255859375, "training_acc": 50.0, "val_loss": 4871.640625, "val_acc": 60.0}
{"epoch": 3, "training_loss": 5076.968017578125, "training_acc": 50.0, "val_loss": 4892.8037109375, "val_acc": 40.0}
{"epoch": 4, "training_loss": 3993.21171875, "training_acc": 50.0, "val_loss": 554.090576171875, "val_acc": 40.0}
{"epoch": 5, "training_loss": 1343.3486572265624, "training_acc": 50.0, "val_loss": 5446.9033203125, "val_acc": 60.0}
{"epoch": 6, "training_loss": 6620.197265625, "training_acc": 50.0, "val_loss": 1091.5933837890625, "val_acc": 60.0}
{"epoch": 7, "training_loss": 1452.92783203125, "training_acc": 60.0, "val_loss": 11298.4794921875, "val_acc": 40.0}
{"epoch": 8, "training_loss": 9689.1935546875, "training_acc": 50.0, "val_loss": 11367.671875, "val_acc": 40.0}
{"epoch": 9, "training_loss": 8755.2310546875, "training_acc": 50.0, "val_loss": 511.8460388183594, "val_acc": 40.0}
{"epoch": 10, "training_loss": 920.905517578125, "training_acc": 60.0, "val_loss": 8769.3134765625, "val_acc": 60.0}
{"epoch": 11, "training_loss": 11108.43486328125, "training_acc": 50.0, "val_loss": 9851.5419921875, "val_acc": 60.0}
{"epoch": 12, "training_loss": 11595.962109375, "training_acc": 50.0, "val_loss": 3674.111083984375, "val_acc": 60.0}
{"epoch": 13, "training_loss": 2754.08828125, "training_acc": 70.0, "val_loss": 9154.8271484375, "val_acc": 40.0}
{"epoch": 14, "training_loss": 8217.476953125, "training_acc": 50.0, "val_loss": 13031.2705078125, "val_acc": 40.0}
{"epoch": 15, "training_loss": 10624.27880859375, "training_acc": 50.0, "val_loss": 6175.74853515625, "val_acc": 40.0}
{"epoch": 16, "training_loss": 3665.8024353027345, "training_acc": 50.0, "val_loss": 5595.19775390625, "val_acc": 60.0}
{"epoch": 17, "training_loss": 7852.6095703125, "training_acc": 50.0, "val_loss": 10276.09375, "val_acc": 60.0}
{"epoch": 18, "training_loss": 12715.82744140625, "training_acc": 50.0, "val_loss": 7282.37353515625, "val_acc": 60.0}
{"epoch": 19, "training_loss": 8630.458251953125, "training_acc": 50.0, "val_loss": 1165.8460693359375, "val_acc": 40.0}
{"epoch": 20, "training_loss": 1241.684423828125, "training_acc": 50.0, "val_loss": 6038.00146484375, "val_acc": 40.0}
{"epoch": 21, "training_loss": 4843.612109375, "training_acc": 50.0, "val_loss": 1061.815185546875, "val_acc": 40.0}
{"epoch": 22, "training_loss": 1545.785009765625, "training_acc": 50.0, "val_loss": 5377.57373046875, "val_acc": 60.0}
{"epoch": 23, "training_loss": 6834.0880859375, "training_acc": 50.0, "val_loss": 3507.456787109375, "val_acc": 60.0}
{"epoch": 24, "training_loss": 3108.7163024902343, "training_acc": 50.0, "val_loss": 7686.47021484375, "val_acc": 40.0}
{"epoch": 25, "training_loss": 7614.71640625, "training_acc": 50.0, "val_loss": 13064.5986328125, "val_acc": 40.0}
{"epoch": 26, "training_loss": 10398.3677734375, "training_acc": 50.0, "val_loss": 5701.4736328125, "val_acc": 40.0}
{"epoch": 27, "training_loss": 4060.98642578125, "training_acc": 50.0, "val_loss": 3924.685546875, "val_acc": 60.0}
{"epoch": 28, "training_loss": 5004.29228515625, "training_acc": 50.0, "val_loss": 4559.80322265625, "val_acc": 60.0}
{"epoch": 29, "training_loss": 5449.416943359375, "training_acc": 50.0, "val_loss": 52.77016067504883, "val_acc": 40.0}
{"epoch": 30, "training_loss": 43.86643676757812, "training_acc": 50.0, "val_loss": 1551.7440185546875, "val_acc": 40.0}
{"epoch": 31, "training_loss": 1503.7051513671875, "training_acc": 30.0, "val_loss": 1784.1558837890625, "val_acc": 40.0}
{"epoch": 32, "training_loss": 1476.894970703125, "training_acc": 50.0, "val_loss": 379.9165954589844, "val_acc": 60.0}
{"epoch": 33, "training_loss": 453.1451477050781, "training_acc": 50.0, "val_loss": 1875.2781982421875, "val_acc": 40.0}
{"epoch": 34, "training_loss": 1587.55849609375, "training_acc": 50.0, "val_loss": 850.6644897460938, "val_acc": 60.0}
{"epoch": 35, "training_loss": 1179.793359375, "training_acc": 50.0, "val_loss": 231.38427734375, "val_acc": 60.0}
{"epoch": 36, "training_loss": 456.9536499023437, "training_acc": 60.0, "val_loss": 4907.35302734375, "val_acc": 40.0}
{"epoch": 37, "training_loss": 3967.79638671875, "training_acc": 50.0, "val_loss": 1132.4603271484375, "val_acc": 40.0}
{"epoch": 38, "training_loss": 1398.476025390625, "training_acc": 50.0, "val_loss": 3996.189208984375, "val_acc": 60.0}
{"epoch": 39, "training_loss": 4902.9103515625, "training_acc": 50.0, "val_loss": 1686.412109375, "val_acc": 60.0}
{"epoch": 40, "training_loss": 1653.7141235351562, "training_acc": 60.0, "val_loss": 5186.75634765625, "val_acc": 40.0}
{"epoch": 41, "training_loss": 4323.044091796875, "training_acc": 50.0, "val_loss": 3863.861328125, "val_acc": 40.0}
{"epoch": 42, "training_loss": 2900.195202064514, "training_acc": 40.0, "val_loss": 91.4699935913086, "val_acc": 60.0}
{"epoch": 43, "training_loss": 222.20543212890624, "training_acc": 60.0, "val_loss": 2182.47265625, "val_acc": 40.0}
{"epoch": 44, "training_loss": 1411.4106689453124, "training_acc": 50.0, "val_loss": 2861.751220703125, "val_acc": 60.0}
{"epoch": 45, "training_loss": 3899.1181640625, "training_acc": 50.0, "val_loss": 3653.870361328125, "val_acc": 60.0}
{"epoch": 46, "training_loss": 4039.5973876953126, "training_acc": 50.0, "val_loss": 2851.639404296875, "val_acc": 40.0}
{"epoch": 47, "training_loss": 2760.3775390625, "training_acc": 50.0, "val_loss": 4759.9931640625, "val_acc": 40.0}
{"epoch": 48, "training_loss": 3336.723779296875, "training_acc": 50.0, "val_loss": 2319.661376953125, "val_acc": 60.0}
