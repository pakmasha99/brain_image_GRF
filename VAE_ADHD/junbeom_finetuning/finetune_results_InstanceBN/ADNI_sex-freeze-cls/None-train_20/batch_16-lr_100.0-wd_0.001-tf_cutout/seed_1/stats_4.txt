"main_modify.py --pretrained_path None --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 1 --task ADNI_sex --input_option yAware --learning_rate 1e2 --batch_size 16 --weight_decay 1e-3 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 6431.765392112732, "training_acc": 40.0, "val_loss": 5735.60302734375, "val_acc": 60.0}
{"epoch": 1, "training_loss": 5911.793359375, "training_acc": 60.0, "val_loss": 21372.259765625, "val_acc": 40.0}
{"epoch": 2, "training_loss": 18115.50859375, "training_acc": 50.0, "val_loss": 15621.619140625, "val_acc": 40.0}
{"epoch": 3, "training_loss": 11276.749609375, "training_acc": 50.0, "val_loss": 4923.47607421875, "val_acc": 60.0}
{"epoch": 4, "training_loss": 8014.006640625, "training_acc": 50.0, "val_loss": 10399.31640625, "val_acc": 60.0}
{"epoch": 5, "training_loss": 12504.7248046875, "training_acc": 50.0, "val_loss": 4490.2744140625, "val_acc": 60.0}
{"epoch": 6, "training_loss": 4723.355810546875, "training_acc": 50.0, "val_loss": 5923.44677734375, "val_acc": 40.0}
{"epoch": 7, "training_loss": 5312.875, "training_acc": 50.0, "val_loss": 4757.06103515625, "val_acc": 40.0}
{"epoch": 8, "training_loss": 4219.187744140625, "training_acc": 30.0, "val_loss": 636.9552612304688, "val_acc": 60.0}
{"epoch": 9, "training_loss": 827.1519775390625, "training_acc": 50.0, "val_loss": 758.0543212890625, "val_acc": 40.0}
{"epoch": 10, "training_loss": 1089.95068359375, "training_acc": 40.0, "val_loss": 856.2587890625, "val_acc": 60.0}
{"epoch": 11, "training_loss": 1436.484716796875, "training_acc": 40.0, "val_loss": 1474.2640380859375, "val_acc": 40.0}
{"epoch": 12, "training_loss": 1159.718994140625, "training_acc": 50.0, "val_loss": 802.5554809570312, "val_acc": 60.0}
{"epoch": 13, "training_loss": 748.1009826660156, "training_acc": 60.0, "val_loss": 1079.0863037109375, "val_acc": 40.0}
{"epoch": 14, "training_loss": 1281.7624267578126, "training_acc": 30.0, "val_loss": 1060.5350341796875, "val_acc": 40.0}
{"epoch": 15, "training_loss": 853.4156677246094, "training_acc": 50.0, "val_loss": 466.20269775390625, "val_acc": 60.0}
{"epoch": 16, "training_loss": 489.9798553466797, "training_acc": 50.0, "val_loss": 784.4158325195312, "val_acc": 60.0}
{"epoch": 17, "training_loss": 886.9592132568359, "training_acc": 40.0, "val_loss": 1340.8638916015625, "val_acc": 60.0}
{"epoch": 18, "training_loss": 1622.9882568359376, "training_acc": 50.0, "val_loss": 732.5919799804688, "val_acc": 40.0}
{"epoch": 19, "training_loss": 624.0948486328125, "training_acc": 50.0, "val_loss": 821.6422119140625, "val_acc": 60.0}
{"epoch": 20, "training_loss": 979.9350341796875, "training_acc": 50.0, "val_loss": 908.8632202148438, "val_acc": 40.0}
{"epoch": 21, "training_loss": 637.5911071777343, "training_acc": 50.0, "val_loss": 1723.9215087890625, "val_acc": 60.0}
{"epoch": 22, "training_loss": 2290.85400390625, "training_acc": 50.0, "val_loss": 216.45462036132812, "val_acc": 60.0}
{"epoch": 23, "training_loss": 938.5860107421875, "training_acc": 50.0, "val_loss": 6249.5888671875, "val_acc": 40.0}
{"epoch": 24, "training_loss": 5098.482421875, "training_acc": 50.0, "val_loss": 2668.487548828125, "val_acc": 40.0}
{"epoch": 25, "training_loss": 2146.583642578125, "training_acc": 50.0, "val_loss": 2926.6953125, "val_acc": 60.0}
{"epoch": 26, "training_loss": 3600.417431640625, "training_acc": 50.0, "val_loss": 948.6549072265625, "val_acc": 60.0}
{"epoch": 27, "training_loss": 1917.08857421875, "training_acc": 40.0, "val_loss": 4388.01708984375, "val_acc": 40.0}
{"epoch": 28, "training_loss": 3367.978564453125, "training_acc": 50.0, "val_loss": 737.496337890625, "val_acc": 60.0}
{"epoch": 29, "training_loss": 1425.039697265625, "training_acc": 50.0, "val_loss": 1082.0828857421875, "val_acc": 60.0}
{"epoch": 30, "training_loss": 1760.17900390625, "training_acc": 40.0, "val_loss": 2324.984130859375, "val_acc": 40.0}
{"epoch": 31, "training_loss": 1592.6723327636719, "training_acc": 50.0, "val_loss": 2489.996826171875, "val_acc": 60.0}
{"epoch": 32, "training_loss": 3334.271484375, "training_acc": 50.0, "val_loss": 2627.50537109375, "val_acc": 60.0}
{"epoch": 33, "training_loss": 2360.297119140625, "training_acc": 50.0, "val_loss": 5547.35302734375, "val_acc": 40.0}
{"epoch": 34, "training_loss": 4909.68759765625, "training_acc": 50.0, "val_loss": 10726.4052734375, "val_acc": 40.0}
{"epoch": 35, "training_loss": 8753.7865234375, "training_acc": 50.0, "val_loss": 5803.72216796875, "val_acc": 40.0}
{"epoch": 36, "training_loss": 3388.821495819092, "training_acc": 60.0, "val_loss": 2861.921875, "val_acc": 60.0}
{"epoch": 37, "training_loss": 4025.57626953125, "training_acc": 50.0, "val_loss": 2853.164794921875, "val_acc": 60.0}
{"epoch": 38, "training_loss": 2434.5831298828125, "training_acc": 50.0, "val_loss": 6365.046875, "val_acc": 40.0}
{"epoch": 39, "training_loss": 5999.3349609375, "training_acc": 50.0, "val_loss": 11802.70703125, "val_acc": 40.0}
{"epoch": 40, "training_loss": 9540.610546875, "training_acc": 50.0, "val_loss": 6029.56591796875, "val_acc": 40.0}
{"epoch": 41, "training_loss": 3531.7262298583983, "training_acc": 60.0, "val_loss": 3165.216552734375, "val_acc": 60.0}
