"main_modify.py --pretrained_path None --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 1 --task ADNI_sex --input_option yAware --learning_rate 1e2 --batch_size 16 --weight_decay 1e-3 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 2149.089481830597, "training_acc": 55.0, "val_loss": 7249.16162109375, "val_acc": 40.0}
{"epoch": 1, "training_loss": 4825.49970703125, "training_acc": 65.0, "val_loss": 14808.9111328125, "val_acc": 60.0}
{"epoch": 2, "training_loss": 19470.721875, "training_acc": 45.0, "val_loss": 3974.356201171875, "val_acc": 60.0}
{"epoch": 3, "training_loss": 5858.709765625, "training_acc": 45.0, "val_loss": 15140.15625, "val_acc": 40.0}
{"epoch": 4, "training_loss": 11770.55546875, "training_acc": 55.0, "val_loss": 11986.5703125, "val_acc": 40.0}
{"epoch": 5, "training_loss": 8316.036376953125, "training_acc": 55.0, "val_loss": 3327.782958984375, "val_acc": 60.0}
{"epoch": 6, "training_loss": 5244.025, "training_acc": 45.0, "val_loss": 6064.06005859375, "val_acc": 60.0}
{"epoch": 7, "training_loss": 7368.474609375, "training_acc": 45.0, "val_loss": 1657.904296875, "val_acc": 40.0}
{"epoch": 8, "training_loss": 1603.39892578125, "training_acc": 55.0, "val_loss": 8338.1787109375, "val_acc": 40.0}
{"epoch": 9, "training_loss": 6289.725390625, "training_acc": 55.0, "val_loss": 3436.951904296875, "val_acc": 40.0}
{"epoch": 10, "training_loss": 1969.2853271484375, "training_acc": 65.0, "val_loss": 5012.49951171875, "val_acc": 60.0}
{"epoch": 11, "training_loss": 7063.0078125, "training_acc": 45.0, "val_loss": 4501.49072265625, "val_acc": 60.0}
{"epoch": 12, "training_loss": 5135.81455078125, "training_acc": 45.0, "val_loss": 4699.43310546875, "val_acc": 40.0}
{"epoch": 13, "training_loss": 4241.35, "training_acc": 55.0, "val_loss": 10257.5458984375, "val_acc": 40.0}
{"epoch": 14, "training_loss": 7432.65, "training_acc": 55.0, "val_loss": 4629.46875, "val_acc": 40.0}
{"epoch": 15, "training_loss": 3564.61533203125, "training_acc": 45.0, "val_loss": 2916.90869140625, "val_acc": 60.0}
{"epoch": 16, "training_loss": 3939.78720703125, "training_acc": 45.0, "val_loss": 816.8703002929688, "val_acc": 60.0}
{"epoch": 17, "training_loss": 1104.46533203125, "training_acc": 55.0, "val_loss": 6480.78271484375, "val_acc": 40.0}
{"epoch": 18, "training_loss": 4943.552734375, "training_acc": 55.0, "val_loss": 4989.99609375, "val_acc": 40.0}
{"epoch": 19, "training_loss": 2818.69111328125, "training_acc": 55.0, "val_loss": 3552.028076171875, "val_acc": 60.0}
{"epoch": 20, "training_loss": 5428.24912109375, "training_acc": 45.0, "val_loss": 6004.83935546875, "val_acc": 60.0}
{"epoch": 21, "training_loss": 8029.3068359375, "training_acc": 45.0, "val_loss": 1649.888916015625, "val_acc": 60.0}
{"epoch": 22, "training_loss": 3006.27919921875, "training_acc": 35.0, "val_loss": 5957.990234375, "val_acc": 40.0}
{"epoch": 23, "training_loss": 4436.60234375, "training_acc": 55.0, "val_loss": 3226.762939453125, "val_acc": 40.0}
{"epoch": 24, "training_loss": 1683.4422119140625, "training_acc": 65.0, "val_loss": 2282.587646484375, "val_acc": 60.0}
{"epoch": 25, "training_loss": 3090.9367431640626, "training_acc": 45.0, "val_loss": 734.9779663085938, "val_acc": 60.0}
{"epoch": 26, "training_loss": 1734.520556640625, "training_acc": 35.0, "val_loss": 3753.390380859375, "val_acc": 40.0}
{"epoch": 27, "training_loss": 2654.9240600585936, "training_acc": 55.0, "val_loss": 702.5758666992188, "val_acc": 60.0}
{"epoch": 28, "training_loss": 1057.601611328125, "training_acc": 45.0, "val_loss": 1607.3856201171875, "val_acc": 40.0}
{"epoch": 29, "training_loss": 1242.837890625, "training_acc": 55.0, "val_loss": 1297.456298828125, "val_acc": 40.0}
{"epoch": 30, "training_loss": 741.7634033203125, "training_acc": 65.0, "val_loss": 1432.8563232421875, "val_acc": 60.0}
{"epoch": 31, "training_loss": 1688.9845336914063, "training_acc": 45.0, "val_loss": 3317.23046875, "val_acc": 40.0}
{"epoch": 32, "training_loss": 2571.0652587890627, "training_acc": 55.0, "val_loss": 3960.263671875, "val_acc": 40.0}
{"epoch": 33, "training_loss": 2737.5440063476562, "training_acc": 55.0, "val_loss": 1666.077392578125, "val_acc": 60.0}
{"epoch": 34, "training_loss": 2526.6900390625, "training_acc": 45.0, "val_loss": 498.5773620605469, "val_acc": 60.0}
{"epoch": 35, "training_loss": 1753.97119140625, "training_acc": 35.0, "val_loss": 5689.33837890625, "val_acc": 40.0}
{"epoch": 36, "training_loss": 4071.680078125, "training_acc": 55.0, "val_loss": 1064.1702880859375, "val_acc": 40.0}
{"epoch": 37, "training_loss": 1798.3447265625, "training_acc": 45.0, "val_loss": 3782.29345703125, "val_acc": 60.0}
{"epoch": 38, "training_loss": 4939.902490234375, "training_acc": 45.0, "val_loss": 188.9082489013672, "val_acc": 60.0}
{"epoch": 39, "training_loss": 640.3449951171875, "training_acc": 55.0, "val_loss": 9216.4892578125, "val_acc": 40.0}
{"epoch": 40, "training_loss": 6973.59443359375, "training_acc": 55.0, "val_loss": 9166.4326171875, "val_acc": 40.0}
{"epoch": 41, "training_loss": 6161.25390625, "training_acc": 55.0, "val_loss": 156.98953247070312, "val_acc": 40.0}
{"epoch": 42, "training_loss": 2019.602001953125, "training_acc": 45.0, "val_loss": 7320.4814453125, "val_acc": 60.0}
{"epoch": 43, "training_loss": 10138.3884765625, "training_acc": 45.0, "val_loss": 5154.26513671875, "val_acc": 60.0}
{"epoch": 44, "training_loss": 5654.86123046875, "training_acc": 45.0, "val_loss": 6528.0712890625, "val_acc": 40.0}
{"epoch": 45, "training_loss": 5805.65390625, "training_acc": 55.0, "val_loss": 14241.0390625, "val_acc": 40.0}
{"epoch": 46, "training_loss": 10615.20390625, "training_acc": 55.0, "val_loss": 9912.5888671875, "val_acc": 40.0}
{"epoch": 47, "training_loss": 6905.3338623046875, "training_acc": 55.0, "val_loss": 2203.274658203125, "val_acc": 60.0}
{"epoch": 48, "training_loss": 3631.9728515625, "training_acc": 45.0, "val_loss": 5121.09521484375, "val_acc": 60.0}
{"epoch": 49, "training_loss": 6841.72490234375, "training_acc": 45.0, "val_loss": 1206.1072998046875, "val_acc": 60.0}
{"epoch": 50, "training_loss": 2546.9779296875, "training_acc": 35.0, "val_loss": 6044.81396484375, "val_acc": 40.0}
{"epoch": 51, "training_loss": 4450.3283203125, "training_acc": 55.0, "val_loss": 2697.21875, "val_acc": 40.0}
{"epoch": 52, "training_loss": 2846.0658203125, "training_acc": 35.0, "val_loss": 1741.362548828125, "val_acc": 60.0}
{"epoch": 53, "training_loss": 1851.5934936523438, "training_acc": 45.0, "val_loss": 4794.09619140625, "val_acc": 40.0}
{"epoch": 54, "training_loss": 4028.385546875, "training_acc": 55.0, "val_loss": 7281.19775390625, "val_acc": 40.0}
{"epoch": 55, "training_loss": 5458.14375, "training_acc": 55.0, "val_loss": 1645.1109619140625, "val_acc": 40.0}
{"epoch": 56, "training_loss": 1036.5351318359376, "training_acc": 65.0, "val_loss": 3446.515625, "val_acc": 60.0}
{"epoch": 57, "training_loss": 4679.5326171875, "training_acc": 45.0, "val_loss": 1392.6993408203125, "val_acc": 60.0}
{"epoch": 58, "training_loss": 1614.517431640625, "training_acc": 55.0, "val_loss": 5736.17333984375, "val_acc": 40.0}
{"epoch": 59, "training_loss": 4398.1662109375, "training_acc": 55.0, "val_loss": 4380.9013671875, "val_acc": 40.0}
{"epoch": 60, "training_loss": 2636.94775390625, "training_acc": 55.0, "val_loss": 3493.914794921875, "val_acc": 60.0}
