"main_modify.py --pretrained_path None --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 4 --task ADNI_sex --input_option yAware --learning_rate 1e2 --batch_size 16 --weight_decay 1e-3 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 2150.4661547660826, "training_acc": 55.0, "val_loss": 8702.0107421875, "val_acc": 40.0}
{"epoch": 1, "training_loss": 7132.2515625, "training_acc": 55.0, "val_loss": 10420.1748046875, "val_acc": 60.0}
{"epoch": 2, "training_loss": 13281.9708984375, "training_acc": 45.0, "val_loss": 1423.084228515625, "val_acc": 40.0}
{"epoch": 3, "training_loss": 1850.78193359375, "training_acc": 55.0, "val_loss": 5215.97607421875, "val_acc": 40.0}
{"epoch": 4, "training_loss": 3485.001330566406, "training_acc": 55.0, "val_loss": 4214.76025390625, "val_acc": 60.0}
{"epoch": 5, "training_loss": 6411.490234375, "training_acc": 45.0, "val_loss": 1932.071533203125, "val_acc": 60.0}
{"epoch": 6, "training_loss": 3035.4537109375, "training_acc": 45.0, "val_loss": 9071.7890625, "val_acc": 40.0}
{"epoch": 7, "training_loss": 7004.755078125, "training_acc": 55.0, "val_loss": 6084.55615234375, "val_acc": 40.0}
{"epoch": 8, "training_loss": 3137.4522705078125, "training_acc": 55.0, "val_loss": 5596.7578125, "val_acc": 60.0}
{"epoch": 9, "training_loss": 7691.815625, "training_acc": 45.0, "val_loss": 10128.0078125, "val_acc": 60.0}
{"epoch": 10, "training_loss": 13918.65625, "training_acc": 45.0, "val_loss": 7898.42431640625, "val_acc": 60.0}
{"epoch": 11, "training_loss": 10425.118212890626, "training_acc": 45.0, "val_loss": 337.9149475097656, "val_acc": 60.0}
{"epoch": 12, "training_loss": 2408.5177734375, "training_acc": 35.0, "val_loss": 11584.3662109375, "val_acc": 40.0}
{"epoch": 13, "training_loss": 8946.4490234375, "training_acc": 55.0, "val_loss": 9671.9619140625, "val_acc": 40.0}
{"epoch": 14, "training_loss": 6061.32890625, "training_acc": 55.0, "val_loss": 1866.0814208984375, "val_acc": 60.0}
{"epoch": 15, "training_loss": 3286.6361328125, "training_acc": 45.0, "val_loss": 5697.94482421875, "val_acc": 60.0}
{"epoch": 16, "training_loss": 7516.92265625, "training_acc": 45.0, "val_loss": 1751.9644775390625, "val_acc": 60.0}
{"epoch": 17, "training_loss": 2069.801708984375, "training_acc": 55.0, "val_loss": 8444.6943359375, "val_acc": 40.0}
{"epoch": 18, "training_loss": 6465.67265625, "training_acc": 55.0, "val_loss": 10061.5888671875, "val_acc": 40.0}
{"epoch": 19, "training_loss": 7323.347119140625, "training_acc": 55.0, "val_loss": 3675.35791015625, "val_acc": 40.0}
{"epoch": 20, "training_loss": 2968.921875, "training_acc": 45.0, "val_loss": 2563.421142578125, "val_acc": 60.0}
{"epoch": 21, "training_loss": 3352.40009765625, "training_acc": 45.0, "val_loss": 406.26617431640625, "val_acc": 40.0}
{"epoch": 22, "training_loss": 617.8682739257813, "training_acc": 55.0, "val_loss": 368.3752746582031, "val_acc": 60.0}
{"epoch": 23, "training_loss": 453.42100219726564, "training_acc": 45.0, "val_loss": 3115.177734375, "val_acc": 40.0}
{"epoch": 24, "training_loss": 2515.5064453125, "training_acc": 55.0, "val_loss": 2843.7529296875, "val_acc": 40.0}
{"epoch": 25, "training_loss": 1432.3190567016602, "training_acc": 65.0, "val_loss": 1165.9793701171875, "val_acc": 60.0}
{"epoch": 26, "training_loss": 1416.86162109375, "training_acc": 45.0, "val_loss": 2612.004638671875, "val_acc": 40.0}
{"epoch": 27, "training_loss": 2007.679541015625, "training_acc": 55.0, "val_loss": 2511.642578125, "val_acc": 40.0}
{"epoch": 28, "training_loss": 1787.8993896484376, "training_acc": 45.0, "val_loss": 233.8158416748047, "val_acc": 40.0}
{"epoch": 29, "training_loss": 499.03013916015624, "training_acc": 45.0, "val_loss": 557.3775634765625, "val_acc": 40.0}
{"epoch": 30, "training_loss": 487.72869873046875, "training_acc": 35.0, "val_loss": 3468.072998046875, "val_acc": 40.0}
{"epoch": 31, "training_loss": 2682.4843017578123, "training_acc": 55.0, "val_loss": 4093.085205078125, "val_acc": 40.0}
{"epoch": 32, "training_loss": 2663.234228515625, "training_acc": 55.0, "val_loss": 1858.8408203125, "val_acc": 60.0}
{"epoch": 33, "training_loss": 2977.586328125, "training_acc": 45.0, "val_loss": 1689.1871337890625, "val_acc": 60.0}
{"epoch": 34, "training_loss": 2196.41181640625, "training_acc": 45.0, "val_loss": 3422.494140625, "val_acc": 40.0}
{"epoch": 35, "training_loss": 2493.246533203125, "training_acc": 55.0, "val_loss": 562.8987426757812, "val_acc": 40.0}
{"epoch": 36, "training_loss": 860.089111328125, "training_acc": 55.0, "val_loss": 2824.760498046875, "val_acc": 60.0}
{"epoch": 37, "training_loss": 3517.35634765625, "training_acc": 45.0, "val_loss": 1953.3026123046875, "val_acc": 40.0}
{"epoch": 38, "training_loss": 1463.48291015625, "training_acc": 55.0, "val_loss": 5031.40966796875, "val_acc": 40.0}
{"epoch": 39, "training_loss": 3613.4369140625, "training_acc": 55.0, "val_loss": 329.5714416503906, "val_acc": 40.0}
{"epoch": 40, "training_loss": 1075.0341186523438, "training_acc": 55.0, "val_loss": 5288.42724609375, "val_acc": 60.0}
{"epoch": 41, "training_loss": 7189.67607421875, "training_acc": 45.0, "val_loss": 3016.24755859375, "val_acc": 60.0}
{"epoch": 42, "training_loss": 3526.30380859375, "training_acc": 45.0, "val_loss": 3359.993896484375, "val_acc": 40.0}
{"epoch": 43, "training_loss": 2553.95478515625, "training_acc": 55.0, "val_loss": 1376.2860107421875, "val_acc": 40.0}
{"epoch": 44, "training_loss": 1639.05703125, "training_acc": 45.0, "val_loss": 2172.83056640625, "val_acc": 60.0}
{"epoch": 45, "training_loss": 2601.494775390625, "training_acc": 45.0, "val_loss": 3386.821044921875, "val_acc": 40.0}
{"epoch": 46, "training_loss": 2667.13896484375, "training_acc": 55.0, "val_loss": 5002.14697265625, "val_acc": 40.0}
{"epoch": 47, "training_loss": 3293.4759765625, "training_acc": 55.0, "val_loss": 1293.4346923828125, "val_acc": 60.0}
