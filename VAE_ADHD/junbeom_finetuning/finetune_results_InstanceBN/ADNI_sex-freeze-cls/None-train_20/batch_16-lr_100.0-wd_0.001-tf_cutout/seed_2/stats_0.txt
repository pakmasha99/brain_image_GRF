"main_modify.py --pretrained_path None --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 2 --task ADNI_sex --input_option yAware --learning_rate 1e2 --batch_size 16 --weight_decay 1e-3 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 4296.022985267639, "training_acc": 50.0, "val_loss": 5339.357421875, "val_acc": 60.0}
{"epoch": 1, "training_loss": 9288.358203125, "training_acc": 40.0, "val_loss": 16063.6318359375, "val_acc": 40.0}
{"epoch": 2, "training_loss": 12718.41484375, "training_acc": 50.0, "val_loss": 3652.853271484375, "val_acc": 40.0}
{"epoch": 3, "training_loss": 3679.4, "training_acc": 50.0, "val_loss": 8410.798828125, "val_acc": 60.0}
{"epoch": 4, "training_loss": 10661.1921875, "training_acc": 50.0, "val_loss": 5566.34912109375, "val_acc": 60.0}
{"epoch": 5, "training_loss": 5144.41064453125, "training_acc": 50.0, "val_loss": 9258.6748046875, "val_acc": 40.0}
{"epoch": 6, "training_loss": 8176.1744140625, "training_acc": 50.0, "val_loss": 17624.669921875, "val_acc": 40.0}
{"epoch": 7, "training_loss": 14592.15478515625, "training_acc": 50.0, "val_loss": 13303.5068359375, "val_acc": 40.0}
{"epoch": 8, "training_loss": 10582.1888671875, "training_acc": 50.0, "val_loss": 178.0337677001953, "val_acc": 40.0}
{"epoch": 9, "training_loss": 3170.4231811523437, "training_acc": 30.0, "val_loss": 7968.90185546875, "val_acc": 60.0}
{"epoch": 10, "training_loss": 9997.4556640625, "training_acc": 50.0, "val_loss": 5624.08251953125, "val_acc": 60.0}
{"epoch": 11, "training_loss": 6531.95517578125, "training_acc": 50.0, "val_loss": 4209.20166015625, "val_acc": 40.0}
{"epoch": 12, "training_loss": 4113.212109375, "training_acc": 50.0, "val_loss": 8609.1533203125, "val_acc": 40.0}
{"epoch": 13, "training_loss": 6793.2876953125, "training_acc": 50.0, "val_loss": 2259.283935546875, "val_acc": 40.0}
{"epoch": 14, "training_loss": 3474.52158203125, "training_acc": 30.0, "val_loss": 4424.52490234375, "val_acc": 60.0}
{"epoch": 15, "training_loss": 5431.6705078125, "training_acc": 50.0, "val_loss": 2135.369873046875, "val_acc": 60.0}
{"epoch": 16, "training_loss": 2386.762841796875, "training_acc": 50.0, "val_loss": 3646.673583984375, "val_acc": 40.0}
{"epoch": 17, "training_loss": 3122.987109375, "training_acc": 50.0, "val_loss": 37.60741424560547, "val_acc": 60.0}
{"epoch": 18, "training_loss": 304.4273681640625, "training_acc": 50.0, "val_loss": 611.5099487304688, "val_acc": 60.0}
{"epoch": 19, "training_loss": 661.552001953125, "training_acc": 60.0, "val_loss": 2646.957763671875, "val_acc": 40.0}
{"epoch": 20, "training_loss": 2015.288525390625, "training_acc": 50.0, "val_loss": 1101.15234375, "val_acc": 60.0}
{"epoch": 21, "training_loss": 1619.02744140625, "training_acc": 50.0, "val_loss": 204.02525329589844, "val_acc": 60.0}
{"epoch": 22, "training_loss": 478.6830810546875, "training_acc": 60.0, "val_loss": 5988.5322265625, "val_acc": 40.0}
{"epoch": 23, "training_loss": 5011.102734375, "training_acc": 50.0, "val_loss": 2788.307861328125, "val_acc": 40.0}
{"epoch": 24, "training_loss": 2253.381640625, "training_acc": 50.0, "val_loss": 3216.38623046875, "val_acc": 60.0}
{"epoch": 25, "training_loss": 4010.961279296875, "training_acc": 50.0, "val_loss": 1629.0360107421875, "val_acc": 60.0}
{"epoch": 26, "training_loss": 2358.59072265625, "training_acc": 40.0, "val_loss": 2967.10986328125, "val_acc": 40.0}
{"epoch": 27, "training_loss": 2236.035009765625, "training_acc": 50.0, "val_loss": 1263.90625, "val_acc": 60.0}
{"epoch": 28, "training_loss": 1736.00419921875, "training_acc": 50.0, "val_loss": 967.7605590820312, "val_acc": 60.0}
{"epoch": 29, "training_loss": 989.02451171875, "training_acc": 60.0, "val_loss": 3412.81494140625, "val_acc": 40.0}
{"epoch": 30, "training_loss": 2784.02255859375, "training_acc": 50.0, "val_loss": 840.4535522460938, "val_acc": 60.0}
{"epoch": 31, "training_loss": 1368.4828125, "training_acc": 50.0, "val_loss": 1754.0640869140625, "val_acc": 60.0}
{"epoch": 32, "training_loss": 1764.1934799194337, "training_acc": 50.0, "val_loss": 364.70806884765625, "val_acc": 40.0}
{"epoch": 33, "training_loss": 713.89111328125, "training_acc": 40.0, "val_loss": 285.12249755859375, "val_acc": 60.0}
{"epoch": 34, "training_loss": 1113.7574462890625, "training_acc": 40.0, "val_loss": 3109.072021484375, "val_acc": 40.0}
{"epoch": 35, "training_loss": 2085.117724609375, "training_acc": 50.0, "val_loss": 2616.531494140625, "val_acc": 60.0}
{"epoch": 36, "training_loss": 3902.04033203125, "training_acc": 50.0, "val_loss": 3542.21484375, "val_acc": 60.0}
