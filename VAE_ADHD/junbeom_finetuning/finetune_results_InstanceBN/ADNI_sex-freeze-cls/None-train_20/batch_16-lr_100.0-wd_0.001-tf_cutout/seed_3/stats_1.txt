"main_modify.py --pretrained_path None --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 3 --task ADNI_sex --input_option yAware --learning_rate 1e2 --batch_size 16 --weight_decay 1e-3 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 4292.949235200882, "training_acc": 50.0, "val_loss": 5952.51611328125, "val_acc": 60.0}
{"epoch": 1, "training_loss": 7857.809375, "training_acc": 50.0, "val_loss": 17438.0703125, "val_acc": 40.0}
{"epoch": 2, "training_loss": 14062.28984375, "training_acc": 50.0, "val_loss": 6579.6875, "val_acc": 40.0}
{"epoch": 3, "training_loss": 6195.11484375, "training_acc": 40.0, "val_loss": 5629.3642578125, "val_acc": 60.0}
{"epoch": 4, "training_loss": 6853.7755859375, "training_acc": 50.0, "val_loss": 1890.584228515625, "val_acc": 60.0}
{"epoch": 5, "training_loss": 2612.76982421875, "training_acc": 50.0, "val_loss": 7374.86279296875, "val_acc": 40.0}
{"epoch": 6, "training_loss": 6071.1865234375, "training_acc": 50.0, "val_loss": 2400.093505859375, "val_acc": 40.0}
{"epoch": 7, "training_loss": 2351.8412109375, "training_acc": 50.0, "val_loss": 5194.07958984375, "val_acc": 60.0}
{"epoch": 8, "training_loss": 6553.672265625, "training_acc": 50.0, "val_loss": 2822.763427734375, "val_acc": 60.0}
{"epoch": 9, "training_loss": 3120.4099609375, "training_acc": 50.0, "val_loss": 4701.58056640625, "val_acc": 40.0}
{"epoch": 10, "training_loss": 3988.0255859375, "training_acc": 50.0, "val_loss": 1480.5399169921875, "val_acc": 40.0}
{"epoch": 11, "training_loss": 2186.84150390625, "training_acc": 40.0, "val_loss": 3879.669677734375, "val_acc": 60.0}
{"epoch": 12, "training_loss": 4654.90634765625, "training_acc": 50.0, "val_loss": 809.8831176757812, "val_acc": 60.0}
{"epoch": 13, "training_loss": 1036.22763671875, "training_acc": 60.0, "val_loss": 7294.55322265625, "val_acc": 40.0}
{"epoch": 14, "training_loss": 6261.8025390625, "training_acc": 50.0, "val_loss": 5010.59912109375, "val_acc": 40.0}
{"epoch": 15, "training_loss": 2955.2835205078127, "training_acc": 50.0, "val_loss": 5001.92724609375, "val_acc": 60.0}
{"epoch": 16, "training_loss": 7895.301953125, "training_acc": 50.0, "val_loss": 7988.53466796875, "val_acc": 60.0}
{"epoch": 17, "training_loss": 9293.0765625, "training_acc": 50.0, "val_loss": 2204.98046875, "val_acc": 60.0}
{"epoch": 18, "training_loss": 2916.649267578125, "training_acc": 50.0, "val_loss": 8832.7919921875, "val_acc": 40.0}
{"epoch": 19, "training_loss": 7839.97265625, "training_acc": 50.0, "val_loss": 8931.9873046875, "val_acc": 40.0}
{"epoch": 20, "training_loss": 7080.856103515625, "training_acc": 50.0, "val_loss": 355.34991455078125, "val_acc": 60.0}
{"epoch": 21, "training_loss": 861.148193359375, "training_acc": 50.0, "val_loss": 2074.266357421875, "val_acc": 60.0}
{"epoch": 22, "training_loss": 2226.6076904296874, "training_acc": 50.0, "val_loss": 3182.57861328125, "val_acc": 40.0}
{"epoch": 23, "training_loss": 2896.182421875, "training_acc": 50.0, "val_loss": 3666.406005859375, "val_acc": 40.0}
{"epoch": 24, "training_loss": 2769.401751708984, "training_acc": 50.0, "val_loss": 2616.846435546875, "val_acc": 60.0}
{"epoch": 25, "training_loss": 3367.314453125, "training_acc": 50.0, "val_loss": 3286.01025390625, "val_acc": 60.0}
{"epoch": 26, "training_loss": 3683.100927734375, "training_acc": 50.0, "val_loss": 2128.115234375, "val_acc": 40.0}
{"epoch": 27, "training_loss": 2080.318310546875, "training_acc": 50.0, "val_loss": 3295.499267578125, "val_acc": 40.0}
{"epoch": 28, "training_loss": 2482.924984741211, "training_acc": 50.0, "val_loss": 2566.229736328125, "val_acc": 60.0}
{"epoch": 29, "training_loss": 3412.2525390625, "training_acc": 50.0, "val_loss": 2544.127197265625, "val_acc": 60.0}
{"epoch": 30, "training_loss": 2372.6826416015624, "training_acc": 50.0, "val_loss": 5585.80322265625, "val_acc": 40.0}
{"epoch": 31, "training_loss": 5513.99921875, "training_acc": 50.0, "val_loss": 8473.216796875, "val_acc": 40.0}
{"epoch": 32, "training_loss": 6375.2572265625, "training_acc": 50.0, "val_loss": 121.89375305175781, "val_acc": 60.0}
{"epoch": 33, "training_loss": 393.085498046875, "training_acc": 50.0, "val_loss": 2988.793701171875, "val_acc": 60.0}
{"epoch": 34, "training_loss": 3529.33193359375, "training_acc": 50.0, "val_loss": 456.0687561035156, "val_acc": 40.0}
{"epoch": 35, "training_loss": 484.659326171875, "training_acc": 50.0, "val_loss": 1692.8739013671875, "val_acc": 40.0}
{"epoch": 36, "training_loss": 1224.4267578125, "training_acc": 50.0, "val_loss": 275.9981384277344, "val_acc": 60.0}
{"epoch": 37, "training_loss": 1170.7716064453125, "training_acc": 30.0, "val_loss": 643.3099975585938, "val_acc": 40.0}
{"epoch": 38, "training_loss": 960.631640625, "training_acc": 50.0, "val_loss": 2917.906982421875, "val_acc": 60.0}
{"epoch": 39, "training_loss": 3431.19638671875, "training_acc": 50.0, "val_loss": 348.395751953125, "val_acc": 40.0}
{"epoch": 40, "training_loss": 443.3438720703125, "training_acc": 50.0, "val_loss": 87.69744873046875, "val_acc": 60.0}
{"epoch": 41, "training_loss": 118.84930419921875, "training_acc": 60.0, "val_loss": 6.9599528312683105, "val_acc": 60.0}
{"epoch": 42, "training_loss": 494.8258361816406, "training_acc": 40.0, "val_loss": 351.7610778808594, "val_acc": 40.0}
{"epoch": 43, "training_loss": 1154.345166015625, "training_acc": 40.0, "val_loss": 2439.612060546875, "val_acc": 60.0}
{"epoch": 44, "training_loss": 2481.892822265625, "training_acc": 50.0, "val_loss": 3933.969482421875, "val_acc": 40.0}
{"epoch": 45, "training_loss": 3777.38515625, "training_acc": 50.0, "val_loss": 7188.22216796875, "val_acc": 40.0}
{"epoch": 46, "training_loss": 5617.38505859375, "training_acc": 50.0, "val_loss": 602.7781982421875, "val_acc": 40.0}
{"epoch": 47, "training_loss": 789.4156982421875, "training_acc": 60.0, "val_loss": 6166.708984375, "val_acc": 60.0}
{"epoch": 48, "training_loss": 7877.06796875, "training_acc": 50.0, "val_loss": 5759.13818359375, "val_acc": 60.0}
{"epoch": 49, "training_loss": 6525.375634765625, "training_acc": 50.0, "val_loss": 1364.1278076171875, "val_acc": 40.0}
{"epoch": 50, "training_loss": 1994.8001953125, "training_acc": 50.0, "val_loss": 4411.7490234375, "val_acc": 40.0}
{"epoch": 51, "training_loss": 2954.50986328125, "training_acc": 50.0, "val_loss": 2727.26611328125, "val_acc": 60.0}
{"epoch": 52, "training_loss": 3665.358544921875, "training_acc": 50.0, "val_loss": 5760.3408203125, "val_acc": 60.0}
{"epoch": 53, "training_loss": 6989.6671875, "training_acc": 50.0, "val_loss": 2572.630126953125, "val_acc": 60.0}
{"epoch": 54, "training_loss": 2849.77294921875, "training_acc": 50.0, "val_loss": 4420.14306640625, "val_acc": 40.0}
{"epoch": 55, "training_loss": 3669.12392578125, "training_acc": 50.0, "val_loss": 2860.835693359375, "val_acc": 40.0}
{"epoch": 56, "training_loss": 2388.948486328125, "training_acc": 40.0, "val_loss": 740.931884765625, "val_acc": 60.0}
{"epoch": 57, "training_loss": 903.7353515625, "training_acc": 50.0, "val_loss": 650.3401489257812, "val_acc": 40.0}
{"epoch": 58, "training_loss": 1018.9712890625, "training_acc": 40.0, "val_loss": 855.0028686523438, "val_acc": 60.0}
{"epoch": 59, "training_loss": 1137.84423828125, "training_acc": 50.0, "val_loss": 2153.103271484375, "val_acc": 40.0}
{"epoch": 60, "training_loss": 1615.5545066833497, "training_acc": 50.0, "val_loss": 2006.6160888671875, "val_acc": 60.0}
