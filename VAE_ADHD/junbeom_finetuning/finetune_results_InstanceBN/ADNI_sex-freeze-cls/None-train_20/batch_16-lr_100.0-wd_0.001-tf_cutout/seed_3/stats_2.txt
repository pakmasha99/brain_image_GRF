"main_modify.py --pretrained_path None --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 3 --task ADNI_sex --input_option yAware --learning_rate 1e2 --batch_size 16 --weight_decay 1e-3 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 4263.785135507584, "training_acc": 50.0, "val_loss": 8067.34765625, "val_acc": 40.0}
{"epoch": 1, "training_loss": 9257.5251953125, "training_acc": 40.0, "val_loss": 10483.5078125, "val_acc": 60.0}
{"epoch": 2, "training_loss": 12747.90703125, "training_acc": 50.0, "val_loss": 2943.046630859375, "val_acc": 60.0}
{"epoch": 3, "training_loss": 3869.2083984375, "training_acc": 50.0, "val_loss": 9760.6474609375, "val_acc": 40.0}
{"epoch": 4, "training_loss": 8117.796875, "training_acc": 50.0, "val_loss": 4315.90966796875, "val_acc": 40.0}
{"epoch": 5, "training_loss": 2786.95029296875, "training_acc": 60.0, "val_loss": 5509.70654296875, "val_acc": 60.0}
{"epoch": 6, "training_loss": 7250.22890625, "training_acc": 50.0, "val_loss": 4203.91357421875, "val_acc": 60.0}
{"epoch": 7, "training_loss": 4743.982131958008, "training_acc": 50.0, "val_loss": 6828.52197265625, "val_acc": 40.0}
{"epoch": 8, "training_loss": 6580.875, "training_acc": 50.0, "val_loss": 9201.775390625, "val_acc": 40.0}
{"epoch": 9, "training_loss": 6773.98984375, "training_acc": 50.0, "val_loss": 888.697265625, "val_acc": 60.0}
{"epoch": 10, "training_loss": 2137.65146484375, "training_acc": 50.0, "val_loss": 3565.20947265625, "val_acc": 60.0}
{"epoch": 11, "training_loss": 4224.13134765625, "training_acc": 50.0, "val_loss": 1339.0133056640625, "val_acc": 40.0}
{"epoch": 12, "training_loss": 1300.6253173828125, "training_acc": 50.0, "val_loss": 1065.19091796875, "val_acc": 40.0}
{"epoch": 13, "training_loss": 1125.25478515625, "training_acc": 50.0, "val_loss": 2210.324951171875, "val_acc": 60.0}
{"epoch": 14, "training_loss": 2605.3098754882812, "training_acc": 50.0, "val_loss": 1565.194580078125, "val_acc": 40.0}
{"epoch": 15, "training_loss": 1454.232421875, "training_acc": 50.0, "val_loss": 506.052734375, "val_acc": 60.0}
{"epoch": 16, "training_loss": 794.796044921875, "training_acc": 50.0, "val_loss": 1411.0780029296875, "val_acc": 40.0}
{"epoch": 17, "training_loss": 1217.034130859375, "training_acc": 50.0, "val_loss": 262.0859069824219, "val_acc": 60.0}
{"epoch": 18, "training_loss": 304.14671630859374, "training_acc": 50.0, "val_loss": 3123.33935546875, "val_acc": 40.0}
{"epoch": 19, "training_loss": 3035.353125, "training_acc": 50.0, "val_loss": 1058.3004150390625, "val_acc": 40.0}
{"epoch": 20, "training_loss": 942.6013671875, "training_acc": 60.0, "val_loss": 4779.22021484375, "val_acc": 60.0}
{"epoch": 21, "training_loss": 6166.0404296875, "training_acc": 50.0, "val_loss": 3329.966552734375, "val_acc": 60.0}
{"epoch": 22, "training_loss": 3337.4073974609373, "training_acc": 50.0, "val_loss": 6648.08544921875, "val_acc": 40.0}
{"epoch": 23, "training_loss": 6503.045703125, "training_acc": 50.0, "val_loss": 10256.251953125, "val_acc": 40.0}
{"epoch": 24, "training_loss": 8093.0923828125, "training_acc": 50.0, "val_loss": 2548.223876953125, "val_acc": 40.0}
{"epoch": 25, "training_loss": 1812.596240234375, "training_acc": 60.0, "val_loss": 5665.36083984375, "val_acc": 60.0}
{"epoch": 26, "training_loss": 7360.253125, "training_acc": 50.0, "val_loss": 6002.60400390625, "val_acc": 60.0}
{"epoch": 27, "training_loss": 6920.603125, "training_acc": 50.0, "val_loss": 116.9424819946289, "val_acc": 40.0}
{"epoch": 28, "training_loss": 312.2175048828125, "training_acc": 50.0, "val_loss": 3833.75439453125, "val_acc": 40.0}
{"epoch": 29, "training_loss": 2934.404150390625, "training_acc": 50.0, "val_loss": 1026.0699462890625, "val_acc": 60.0}
{"epoch": 30, "training_loss": 1399.8873046875, "training_acc": 50.0, "val_loss": 1965.720703125, "val_acc": 60.0}
{"epoch": 31, "training_loss": 2079.9583251953127, "training_acc": 50.0, "val_loss": 3616.75390625, "val_acc": 40.0}
{"epoch": 32, "training_loss": 3267.9701171875, "training_acc": 50.0, "val_loss": 4065.93212890625, "val_acc": 40.0}
{"epoch": 33, "training_loss": 3090.3813873291015, "training_acc": 50.0, "val_loss": 2607.775390625, "val_acc": 60.0}
{"epoch": 34, "training_loss": 3726.57734375, "training_acc": 50.0, "val_loss": 2583.014404296875, "val_acc": 60.0}
{"epoch": 35, "training_loss": 2618.6108276367186, "training_acc": 50.0, "val_loss": 1636.7010498046875, "val_acc": 40.0}
{"epoch": 36, "training_loss": 1199.8635986328125, "training_acc": 50.0, "val_loss": 1641.9984130859375, "val_acc": 60.0}
{"epoch": 37, "training_loss": 2249.44365234375, "training_acc": 50.0, "val_loss": 319.6911315917969, "val_acc": 60.0}
{"epoch": 38, "training_loss": 1027.1080078125, "training_acc": 50.0, "val_loss": 6092.32958984375, "val_acc": 40.0}
{"epoch": 39, "training_loss": 4948.1748046875, "training_acc": 50.0, "val_loss": 2133.435546875, "val_acc": 40.0}
{"epoch": 40, "training_loss": 2424.42958984375, "training_acc": 40.0, "val_loss": 3133.663818359375, "val_acc": 60.0}
{"epoch": 41, "training_loss": 3805.80625, "training_acc": 50.0, "val_loss": 525.3582153320312, "val_acc": 60.0}
{"epoch": 42, "training_loss": 1592.9869140625, "training_acc": 40.0, "val_loss": 4807.5, "val_acc": 40.0}
{"epoch": 43, "training_loss": 4010.65234375, "training_acc": 50.0, "val_loss": 472.6297912597656, "val_acc": 40.0}
{"epoch": 44, "training_loss": 925.606689453125, "training_acc": 50.0, "val_loss": 3351.662109375, "val_acc": 60.0}
{"epoch": 45, "training_loss": 3964.9732421875, "training_acc": 50.0, "val_loss": 198.89035034179688, "val_acc": 40.0}
{"epoch": 46, "training_loss": 649.5852905273438, "training_acc": 50.0, "val_loss": 481.83599853515625, "val_acc": 40.0}
