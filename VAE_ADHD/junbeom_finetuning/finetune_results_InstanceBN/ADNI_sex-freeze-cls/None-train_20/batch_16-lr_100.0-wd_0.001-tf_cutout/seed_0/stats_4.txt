"main_modify.py --pretrained_path None --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_sex --input_option yAware --learning_rate 1e2 --batch_size 16 --weight_decay 1e-3 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 2058.006587314606, "training_acc": 55.0, "val_loss": 6045.14599609375, "val_acc": 40.0}
{"epoch": 1, "training_loss": 4312.25556640625, "training_acc": 65.0, "val_loss": 15227.447265625, "val_acc": 60.0}
{"epoch": 2, "training_loss": 20411.68671875, "training_acc": 45.0, "val_loss": 4731.19287109375, "val_acc": 60.0}
{"epoch": 3, "training_loss": 5232.731787109375, "training_acc": 55.0, "val_loss": 14378.8154296875, "val_acc": 40.0}
{"epoch": 4, "training_loss": 11426.401953125, "training_acc": 55.0, "val_loss": 12257.578125, "val_acc": 40.0}
{"epoch": 5, "training_loss": 8519.633227539063, "training_acc": 55.0, "val_loss": 3347.094482421875, "val_acc": 60.0}
{"epoch": 6, "training_loss": 4598.9546875, "training_acc": 45.0, "val_loss": 6922.21240234375, "val_acc": 60.0}
{"epoch": 7, "training_loss": 9109.4712890625, "training_acc": 45.0, "val_loss": 1804.4573974609375, "val_acc": 60.0}
{"epoch": 8, "training_loss": 3004.159765625, "training_acc": 45.0, "val_loss": 10386.837890625, "val_acc": 40.0}
{"epoch": 9, "training_loss": 8176.8140625, "training_acc": 55.0, "val_loss": 8850.8359375, "val_acc": 40.0}
{"epoch": 10, "training_loss": 6169.4449462890625, "training_acc": 55.0, "val_loss": 2205.4287109375, "val_acc": 60.0}
{"epoch": 11, "training_loss": 3825.5234375, "training_acc": 45.0, "val_loss": 3533.517333984375, "val_acc": 60.0}
{"epoch": 12, "training_loss": 4193.082421875, "training_acc": 45.0, "val_loss": 4689.8876953125, "val_acc": 40.0}
{"epoch": 13, "training_loss": 4035.6080078125, "training_acc": 55.0, "val_loss": 7869.92529296875, "val_acc": 40.0}
{"epoch": 14, "training_loss": 5387.684375, "training_acc": 55.0, "val_loss": 250.4239501953125, "val_acc": 40.0}
{"epoch": 15, "training_loss": 670.1629272460938, "training_acc": 65.0, "val_loss": 7490.93115234375, "val_acc": 60.0}
{"epoch": 16, "training_loss": 10361.34765625, "training_acc": 45.0, "val_loss": 7353.7890625, "val_acc": 60.0}
{"epoch": 17, "training_loss": 9446.6171875, "training_acc": 45.0, "val_loss": 599.7669677734375, "val_acc": 60.0}
{"epoch": 18, "training_loss": 1886.6654296875, "training_acc": 45.0, "val_loss": 11993.134765625, "val_acc": 40.0}
{"epoch": 19, "training_loss": 9118.91640625, "training_acc": 55.0, "val_loss": 12994.9990234375, "val_acc": 40.0}
{"epoch": 20, "training_loss": 9484.396923828124, "training_acc": 55.0, "val_loss": 5253.97412109375, "val_acc": 40.0}
{"epoch": 21, "training_loss": 2693.302166748047, "training_acc": 65.0, "val_loss": 3372.103515625, "val_acc": 60.0}
{"epoch": 22, "training_loss": 4693.684228515625, "training_acc": 45.0, "val_loss": 3312.055419921875, "val_acc": 60.0}
{"epoch": 23, "training_loss": 4233.320989990234, "training_acc": 45.0, "val_loss": 3555.836669921875, "val_acc": 40.0}
{"epoch": 24, "training_loss": 2667.8703125, "training_acc": 55.0, "val_loss": 6067.97509765625, "val_acc": 40.0}
{"epoch": 25, "training_loss": 4286.47939453125, "training_acc": 55.0, "val_loss": 322.2288818359375, "val_acc": 40.0}
{"epoch": 26, "training_loss": 634.9223510742188, "training_acc": 65.0, "val_loss": 6466.46728515625, "val_acc": 60.0}
{"epoch": 27, "training_loss": 8972.7140625, "training_acc": 45.0, "val_loss": 5247.76123046875, "val_acc": 60.0}
{"epoch": 28, "training_loss": 6768.05927734375, "training_acc": 45.0, "val_loss": 3635.895751953125, "val_acc": 40.0}
{"epoch": 29, "training_loss": 3280.977734375, "training_acc": 55.0, "val_loss": 7269.53662109375, "val_acc": 40.0}
{"epoch": 30, "training_loss": 5454.1078125, "training_acc": 55.0, "val_loss": 1961.65625, "val_acc": 40.0}
{"epoch": 31, "training_loss": 2523.75693359375, "training_acc": 35.0, "val_loss": 1928.6239013671875, "val_acc": 60.0}
{"epoch": 32, "training_loss": 2181.516103363037, "training_acc": 45.0, "val_loss": 427.8960876464844, "val_acc": 40.0}
{"epoch": 33, "training_loss": 298.4674072265625, "training_acc": 65.0, "val_loss": 747.0407104492188, "val_acc": 60.0}
{"epoch": 34, "training_loss": 1709.7615234375, "training_acc": 25.0, "val_loss": 181.88507080078125, "val_acc": 40.0}
{"epoch": 35, "training_loss": 692.9852416992187, "training_acc": 55.0, "val_loss": 2939.83984375, "val_acc": 60.0}
{"epoch": 36, "training_loss": 3617.88037109375, "training_acc": 45.0, "val_loss": 2343.367919921875, "val_acc": 40.0}
{"epoch": 37, "training_loss": 2445.49619140625, "training_acc": 55.0, "val_loss": 3916.440673828125, "val_acc": 40.0}
{"epoch": 38, "training_loss": 2401.1656005859377, "training_acc": 55.0, "val_loss": 3019.509521484375, "val_acc": 60.0}
{"epoch": 39, "training_loss": 4288.12822265625, "training_acc": 45.0, "val_loss": 4170.9150390625, "val_acc": 60.0}
{"epoch": 40, "training_loss": 5110.5580078125, "training_acc": 45.0, "val_loss": 2021.9515380859375, "val_acc": 40.0}
{"epoch": 41, "training_loss": 2039.78232421875, "training_acc": 55.0, "val_loss": 5494.45068359375, "val_acc": 40.0}
{"epoch": 42, "training_loss": 3709.03701171875, "training_acc": 55.0, "val_loss": 805.0184936523438, "val_acc": 60.0}
{"epoch": 43, "training_loss": 1663.06171875, "training_acc": 45.0, "val_loss": 1254.8348388671875, "val_acc": 60.0}
{"epoch": 44, "training_loss": 1768.3578125, "training_acc": 45.0, "val_loss": 3401.606689453125, "val_acc": 40.0}
{"epoch": 45, "training_loss": 2446.030480957031, "training_acc": 55.0, "val_loss": 163.78005981445312, "val_acc": 60.0}
{"epoch": 46, "training_loss": 321.7515380859375, "training_acc": 35.0, "val_loss": 1536.7103271484375, "val_acc": 60.0}
{"epoch": 47, "training_loss": 2146.90771484375, "training_acc": 45.0, "val_loss": 929.2593994140625, "val_acc": 40.0}
{"epoch": 48, "training_loss": 696.36796875, "training_acc": 55.0, "val_loss": 1737.3797607421875, "val_acc": 40.0}
{"epoch": 49, "training_loss": 938.003076171875, "training_acc": 55.0, "val_loss": 2961.949951171875, "val_acc": 60.0}
{"epoch": 50, "training_loss": 4324.63623046875, "training_acc": 45.0, "val_loss": 3197.910888671875, "val_acc": 60.0}
{"epoch": 51, "training_loss": 3765.385778808594, "training_acc": 45.0, "val_loss": 4710.33984375, "val_acc": 40.0}
{"epoch": 52, "training_loss": 4030.265234375, "training_acc": 55.0, "val_loss": 7759.92333984375, "val_acc": 40.0}
{"epoch": 53, "training_loss": 5333.3501953125, "training_acc": 55.0, "val_loss": 409.212890625, "val_acc": 40.0}
{"epoch": 54, "training_loss": 2642.9350341796876, "training_acc": 35.0, "val_loss": 5895.25634765625, "val_acc": 60.0}
{"epoch": 55, "training_loss": 7896.44560546875, "training_acc": 45.0, "val_loss": 2637.75830078125, "val_acc": 60.0}
{"epoch": 56, "training_loss": 3864.79990234375, "training_acc": 35.0, "val_loss": 4444.8251953125, "val_acc": 40.0}
{"epoch": 57, "training_loss": 3305.490380859375, "training_acc": 55.0, "val_loss": 1702.156494140625, "val_acc": 40.0}
{"epoch": 58, "training_loss": 1431.45458984375, "training_acc": 55.0, "val_loss": 2799.695068359375, "val_acc": 60.0}
{"epoch": 59, "training_loss": 3718.2910888671877, "training_acc": 45.0, "val_loss": 8.725032806396484, "val_acc": 60.0}
{"epoch": 60, "training_loss": 391.9551834106445, "training_acc": 55.0, "val_loss": 7438.50390625, "val_acc": 40.0}
{"epoch": 61, "training_loss": 5721.8578125, "training_acc": 55.0, "val_loss": 4822.9990234375, "val_acc": 40.0}
{"epoch": 62, "training_loss": 2848.7485687255858, "training_acc": 55.0, "val_loss": 1658.9439697265625, "val_acc": 60.0}
{"epoch": 63, "training_loss": 2184.466064453125, "training_acc": 45.0, "val_loss": 932.6677856445312, "val_acc": 40.0}
{"epoch": 64, "training_loss": 698.734130859375, "training_acc": 55.0, "val_loss": 884.9784545898438, "val_acc": 40.0}
{"epoch": 65, "training_loss": 516.226416015625, "training_acc": 65.0, "val_loss": 872.7618408203125, "val_acc": 60.0}
{"epoch": 66, "training_loss": 1134.2218017578125, "training_acc": 45.0, "val_loss": 608.4564819335938, "val_acc": 40.0}
{"epoch": 67, "training_loss": 634.68916015625, "training_acc": 55.0, "val_loss": 928.0338134765625, "val_acc": 60.0}
{"epoch": 68, "training_loss": 1290.8545166015624, "training_acc": 45.0, "val_loss": 1731.5882568359375, "val_acc": 40.0}
{"epoch": 69, "training_loss": 1252.6366577148438, "training_acc": 45.0, "val_loss": 1121.9886474609375, "val_acc": 40.0}
{"epoch": 70, "training_loss": 761.9400466918945, "training_acc": 55.0, "val_loss": 1228.791748046875, "val_acc": 60.0}
{"epoch": 71, "training_loss": 1550.5260009765625, "training_acc": 45.0, "val_loss": 2057.14697265625, "val_acc": 40.0}
{"epoch": 72, "training_loss": 1784.9982421875, "training_acc": 55.0, "val_loss": 351.75299072265625, "val_acc": 40.0}
{"epoch": 73, "training_loss": 1321.83251953125, "training_acc": 45.0, "val_loss": 3318.1171875, "val_acc": 60.0}
{"epoch": 74, "training_loss": 4353.966723632812, "training_acc": 45.0, "val_loss": 981.7529296875, "val_acc": 40.0}
{"epoch": 75, "training_loss": 919.15751953125, "training_acc": 55.0, "val_loss": 710.8800659179688, "val_acc": 40.0}
{"epoch": 76, "training_loss": 1181.901708984375, "training_acc": 45.0, "val_loss": 1658.533203125, "val_acc": 60.0}
{"epoch": 77, "training_loss": 1675.2950119018556, "training_acc": 55.0, "val_loss": 1481.8489990234375, "val_acc": 40.0}
{"epoch": 78, "training_loss": 960.6967529296875, "training_acc": 55.0, "val_loss": 1699.16796875, "val_acc": 60.0}
