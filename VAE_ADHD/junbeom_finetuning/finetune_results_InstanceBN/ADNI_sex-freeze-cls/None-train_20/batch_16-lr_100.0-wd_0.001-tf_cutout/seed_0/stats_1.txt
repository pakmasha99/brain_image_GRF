"main_modify.py --pretrained_path None --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_sex --input_option yAware --learning_rate 1e2 --batch_size 16 --weight_decay 1e-3 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 417.0598331451416, "training_acc": 55.0, "val_loss": 10943.3623046875, "val_acc": 60.0}
{"epoch": 1, "training_loss": 13713.75, "training_acc": 50.0, "val_loss": 4652.9033203125, "val_acc": 60.0}
{"epoch": 2, "training_loss": 6191.35126953125, "training_acc": 40.0, "val_loss": 4293.74853515625, "val_acc": 40.0}
{"epoch": 3, "training_loss": 3827.9815673828125, "training_acc": 30.0, "val_loss": 2501.320556640625, "val_acc": 40.0}
{"epoch": 4, "training_loss": 1992.8822265625, "training_acc": 50.0, "val_loss": 1260.8031005859375, "val_acc": 60.0}
{"epoch": 5, "training_loss": 1570.4200439453125, "training_acc": 50.0, "val_loss": 938.0678100585938, "val_acc": 40.0}
{"epoch": 6, "training_loss": 739.948095703125, "training_acc": 50.0, "val_loss": 1594.7978515625, "val_acc": 60.0}
{"epoch": 7, "training_loss": 2018.014697265625, "training_acc": 50.0, "val_loss": 1274.0152587890625, "val_acc": 40.0}
{"epoch": 8, "training_loss": 1106.1959716796875, "training_acc": 50.0, "val_loss": 838.3322143554688, "val_acc": 40.0}
{"epoch": 9, "training_loss": 673.3570190429688, "training_acc": 60.0, "val_loss": 2403.396240234375, "val_acc": 60.0}
{"epoch": 10, "training_loss": 2767.8659423828126, "training_acc": 50.0, "val_loss": 1662.2440185546875, "val_acc": 40.0}
{"epoch": 11, "training_loss": 1531.1064453125, "training_acc": 50.0, "val_loss": 782.1565551757812, "val_acc": 40.0}
{"epoch": 12, "training_loss": 1476.421728515625, "training_acc": 40.0, "val_loss": 2440.096923828125, "val_acc": 60.0}
{"epoch": 13, "training_loss": 2660.6867919921874, "training_acc": 50.0, "val_loss": 3289.928466796875, "val_acc": 40.0}
{"epoch": 14, "training_loss": 3217.38759765625, "training_acc": 50.0, "val_loss": 3192.881591796875, "val_acc": 40.0}
{"epoch": 15, "training_loss": 1922.977471923828, "training_acc": 60.0, "val_loss": 2104.806396484375, "val_acc": 60.0}
{"epoch": 16, "training_loss": 2583.0537109375, "training_acc": 50.0, "val_loss": 95.87248992919922, "val_acc": 60.0}
{"epoch": 17, "training_loss": 868.6392578125, "training_acc": 50.0, "val_loss": 6398.58154296875, "val_acc": 40.0}
{"epoch": 18, "training_loss": 5192.817578125, "training_acc": 50.0, "val_loss": 871.9555053710938, "val_acc": 40.0}
{"epoch": 19, "training_loss": 1583.093212890625, "training_acc": 50.0, "val_loss": 6479.6103515625, "val_acc": 60.0}
{"epoch": 20, "training_loss": 8203.46796875, "training_acc": 50.0, "val_loss": 5535.14990234375, "val_acc": 60.0}
{"epoch": 21, "training_loss": 6169.4630859375, "training_acc": 50.0, "val_loss": 2564.935546875, "val_acc": 40.0}
{"epoch": 22, "training_loss": 3067.42158203125, "training_acc": 50.0, "val_loss": 5994.92333984375, "val_acc": 40.0}
{"epoch": 23, "training_loss": 4545.21669921875, "training_acc": 50.0, "val_loss": 1020.3404541015625, "val_acc": 60.0}
{"epoch": 24, "training_loss": 1423.224560546875, "training_acc": 50.0, "val_loss": 2428.392333984375, "val_acc": 60.0}
{"epoch": 25, "training_loss": 2585.7943359375, "training_acc": 50.0, "val_loss": 3168.770263671875, "val_acc": 40.0}
{"epoch": 26, "training_loss": 2799.135986328125, "training_acc": 50.0, "val_loss": 5416.29443359375, "val_acc": 40.0}
{"epoch": 27, "training_loss": 3988.26484375, "training_acc": 50.0, "val_loss": 1400.5400390625, "val_acc": 60.0}
{"epoch": 28, "training_loss": 2590.04560546875, "training_acc": 50.0, "val_loss": 3295.42578125, "val_acc": 60.0}
{"epoch": 29, "training_loss": 3858.999365234375, "training_acc": 50.0, "val_loss": 2177.86474609375, "val_acc": 40.0}
{"epoch": 30, "training_loss": 2032.6244140625, "training_acc": 50.0, "val_loss": 2326.143310546875, "val_acc": 40.0}
{"epoch": 31, "training_loss": 1419.3826416015625, "training_acc": 60.0, "val_loss": 1603.8756103515625, "val_acc": 60.0}
{"epoch": 32, "training_loss": 1863.3859375, "training_acc": 50.0, "val_loss": 1500.7459716796875, "val_acc": 40.0}
{"epoch": 33, "training_loss": 1435.395263671875, "training_acc": 50.0, "val_loss": 350.7826232910156, "val_acc": 60.0}
{"epoch": 34, "training_loss": 568.42783203125, "training_acc": 50.0, "val_loss": 1857.0513916015625, "val_acc": 40.0}
{"epoch": 35, "training_loss": 1697.6701171875, "training_acc": 50.0, "val_loss": 290.29376220703125, "val_acc": 60.0}
