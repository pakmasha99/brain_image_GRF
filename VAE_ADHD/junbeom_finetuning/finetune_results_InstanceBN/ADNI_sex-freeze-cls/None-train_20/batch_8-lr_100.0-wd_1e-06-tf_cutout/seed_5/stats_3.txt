"main_modify.py --pretrained_path None --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 5 --task ADNI_sex --input_option yAware --learning_rate 1e2 --batch_size 8 --weight_decay 1e-6 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 12871.494307470322, "training_acc": 50.0, "val_loss": 3687.641357421875, "val_acc": 60.0}
{"epoch": 1, "training_loss": 4110.148986816406, "training_acc": 50.0, "val_loss": 10042.939453125, "val_acc": 40.0}
{"epoch": 2, "training_loss": 9624.844921875, "training_acc": 50.0, "val_loss": 5041.10986328125, "val_acc": 40.0}
{"epoch": 3, "training_loss": 6175.83984375, "training_acc": 40.0, "val_loss": 5639.2734375, "val_acc": 60.0}
{"epoch": 4, "training_loss": 4498.24677734375, "training_acc": 50.0, "val_loss": 5402.7158203125, "val_acc": 40.0}
{"epoch": 5, "training_loss": 4434.584643554687, "training_acc": 50.0, "val_loss": 2130.83447265625, "val_acc": 60.0}
{"epoch": 6, "training_loss": 4508.444873046875, "training_acc": 50.0, "val_loss": 403.29693603515625, "val_acc": 60.0}
{"epoch": 7, "training_loss": 2458.45830078125, "training_acc": 70.0, "val_loss": 9663.0126953125, "val_acc": 40.0}
{"epoch": 8, "training_loss": 6756.751196289062, "training_acc": 50.0, "val_loss": 2141.12939453125, "val_acc": 60.0}
{"epoch": 9, "training_loss": 3085.407373046875, "training_acc": 50.0, "val_loss": 1382.8629150390625, "val_acc": 60.0}
{"epoch": 10, "training_loss": 2594.0913330078124, "training_acc": 40.0, "val_loss": 2653.969482421875, "val_acc": 40.0}
{"epoch": 11, "training_loss": 1584.3661865234376, "training_acc": 50.0, "val_loss": 4977.44384765625, "val_acc": 60.0}
{"epoch": 12, "training_loss": 5579.632666015625, "training_acc": 50.0, "val_loss": 707.9442749023438, "val_acc": 40.0}
{"epoch": 13, "training_loss": 1483.6896240234375, "training_acc": 50.0, "val_loss": 734.3858032226562, "val_acc": 60.0}
{"epoch": 14, "training_loss": 825.4392944335938, "training_acc": 40.0, "val_loss": 1067.6162109375, "val_acc": 60.0}
{"epoch": 15, "training_loss": 860.030908203125, "training_acc": 50.0, "val_loss": 1921.0640869140625, "val_acc": 60.0}
{"epoch": 16, "training_loss": 2881.7511962890626, "training_acc": 50.0, "val_loss": 1705.4373779296875, "val_acc": 40.0}
{"epoch": 17, "training_loss": 1287.479312133789, "training_acc": 45.0, "val_loss": 695.1343994140625, "val_acc": 40.0}
{"epoch": 18, "training_loss": 1387.2625366210937, "training_acc": 20.0, "val_loss": 1529.2457275390625, "val_acc": 60.0}
{"epoch": 19, "training_loss": 1916.141357421875, "training_acc": 50.0, "val_loss": 3637.325439453125, "val_acc": 40.0}
{"epoch": 20, "training_loss": 4027.3774169921876, "training_acc": 50.0, "val_loss": 2733.979248046875, "val_acc": 40.0}
{"epoch": 21, "training_loss": 2164.66982421875, "training_acc": 50.0, "val_loss": 1235.7181396484375, "val_acc": 60.0}
{"epoch": 22, "training_loss": 2700.646875, "training_acc": 40.0, "val_loss": 2289.321044921875, "val_acc": 40.0}
{"epoch": 23, "training_loss": 3335.58310546875, "training_acc": 30.0, "val_loss": 2066.007080078125, "val_acc": 60.0}
{"epoch": 24, "training_loss": 1273.78408203125, "training_acc": 50.0, "val_loss": 448.7366638183594, "val_acc": 60.0}
{"epoch": 25, "training_loss": 505.9452331542969, "training_acc": 50.0, "val_loss": 367.7145690917969, "val_acc": 60.0}
{"epoch": 26, "training_loss": 1533.7628173828125, "training_acc": 50.0, "val_loss": 1186.05810546875, "val_acc": 40.0}
{"epoch": 27, "training_loss": 1861.81015625, "training_acc": 50.0, "val_loss": 2042.384033203125, "val_acc": 60.0}
{"epoch": 28, "training_loss": 2280.80615234375, "training_acc": 30.0, "val_loss": 887.6884765625, "val_acc": 60.0}
{"epoch": 29, "training_loss": 1255.3318115234374, "training_acc": 40.0, "val_loss": 390.3595275878906, "val_acc": 40.0}
{"epoch": 30, "training_loss": 1691.5260864257812, "training_acc": 50.0, "val_loss": 1325.6868896484375, "val_acc": 60.0}
{"epoch": 31, "training_loss": 1768.54345703125, "training_acc": 50.0, "val_loss": 1667.535400390625, "val_acc": 40.0}
{"epoch": 32, "training_loss": 2183.74921875, "training_acc": 40.0, "val_loss": 1030.868408203125, "val_acc": 60.0}
{"epoch": 33, "training_loss": 642.5472778320312, "training_acc": 70.0, "val_loss": 1109.0155029296875, "val_acc": 40.0}
{"epoch": 34, "training_loss": 1705.50205078125, "training_acc": 50.0, "val_loss": 157.31285095214844, "val_acc": 40.0}
{"epoch": 35, "training_loss": 669.1242919921875, "training_acc": 50.0, "val_loss": 469.65728759765625, "val_acc": 40.0}
{"epoch": 36, "training_loss": 1098.6156494140625, "training_acc": 40.0, "val_loss": 2338.9443359375, "val_acc": 40.0}
{"epoch": 37, "training_loss": 2657.744287109375, "training_acc": 50.0, "val_loss": 682.2245483398438, "val_acc": 60.0}
{"epoch": 38, "training_loss": 1432.0221435546875, "training_acc": 50.0, "val_loss": 2774.14892578125, "val_acc": 40.0}
{"epoch": 39, "training_loss": 3136.080908203125, "training_acc": 50.0, "val_loss": 534.3681030273438, "val_acc": 60.0}
{"epoch": 40, "training_loss": 2801.395068359375, "training_acc": 50.0, "val_loss": 430.39044189453125, "val_acc": 60.0}
{"epoch": 41, "training_loss": 3371.4532104492187, "training_acc": 50.0, "val_loss": 7281.7001953125, "val_acc": 40.0}
{"epoch": 42, "training_loss": 4418.1728515625, "training_acc": 50.0, "val_loss": 2400.539306640625, "val_acc": 60.0}
{"epoch": 43, "training_loss": 3388.59267578125, "training_acc": 50.0, "val_loss": 3051.86962890625, "val_acc": 40.0}
{"epoch": 44, "training_loss": 3115.343359375, "training_acc": 50.0, "val_loss": 1678.054931640625, "val_acc": 40.0}
{"epoch": 45, "training_loss": 3303.890380859375, "training_acc": 40.0, "val_loss": 3109.757568359375, "val_acc": 60.0}
{"epoch": 46, "training_loss": 2835.4185791015625, "training_acc": 50.0, "val_loss": 7340.00732421875, "val_acc": 40.0}
{"epoch": 47, "training_loss": 6438.2853515625, "training_acc": 50.0, "val_loss": 1485.1092529296875, "val_acc": 40.0}
{"epoch": 48, "training_loss": 3475.006396484375, "training_acc": 50.0, "val_loss": 6090.74365234375, "val_acc": 60.0}
{"epoch": 49, "training_loss": 6593.39130859375, "training_acc": 50.0, "val_loss": 1051.9322509765625, "val_acc": 40.0}
{"epoch": 50, "training_loss": 1812.88798828125, "training_acc": 50.0, "val_loss": 1811.4722900390625, "val_acc": 40.0}
{"epoch": 51, "training_loss": 3119.794921875, "training_acc": 30.0, "val_loss": 1297.1177978515625, "val_acc": 60.0}
{"epoch": 52, "training_loss": 2498.52236328125, "training_acc": 40.0, "val_loss": 3728.993896484375, "val_acc": 40.0}
{"epoch": 53, "training_loss": 1769.5172973632812, "training_acc": 60.0, "val_loss": 2229.72216796875, "val_acc": 60.0}
