"main_modify.py --pretrained_path None --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 2 --task ADNI_sex --input_option yAware --learning_rate 1e2 --batch_size 8 --weight_decay 1e-6 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 6364.314703989029, "training_acc": 60.0, "val_loss": 4986.7470703125, "val_acc": 40.0}
{"epoch": 1, "training_loss": 7157.0400390625, "training_acc": 50.0, "val_loss": 4672.8837890625, "val_acc": 40.0}
{"epoch": 2, "training_loss": 5110.4916015625, "training_acc": 40.0, "val_loss": 5002.66357421875, "val_acc": 60.0}
{"epoch": 3, "training_loss": 5786.890234375, "training_acc": 30.0, "val_loss": 2802.961181640625, "val_acc": 40.0}
{"epoch": 4, "training_loss": 1160.993701171875, "training_acc": 40.0, "val_loss": 1651.1541748046875, "val_acc": 60.0}
{"epoch": 5, "training_loss": 2153.134375, "training_acc": 50.0, "val_loss": 3542.94384765625, "val_acc": 40.0}
{"epoch": 6, "training_loss": 4516.84775390625, "training_acc": 50.0, "val_loss": 3007.662841796875, "val_acc": 40.0}
{"epoch": 7, "training_loss": 3022.792724609375, "training_acc": 40.0, "val_loss": 2584.922607421875, "val_acc": 60.0}
{"epoch": 8, "training_loss": 1734.7349609375, "training_acc": 60.0, "val_loss": 5065.19921875, "val_acc": 40.0}
{"epoch": 9, "training_loss": 3838.491357421875, "training_acc": 50.0, "val_loss": 1048.5245361328125, "val_acc": 60.0}
{"epoch": 10, "training_loss": 1896.64228515625, "training_acc": 50.0, "val_loss": 2330.553955078125, "val_acc": 40.0}
{"epoch": 11, "training_loss": 2240.354052734375, "training_acc": 50.0, "val_loss": 1059.2373046875, "val_acc": 60.0}
{"epoch": 12, "training_loss": 1188.512060546875, "training_acc": 50.0, "val_loss": 3278.300048828125, "val_acc": 40.0}
{"epoch": 13, "training_loss": 2500.9197631835937, "training_acc": 50.0, "val_loss": 1191.5882568359375, "val_acc": 60.0}
{"epoch": 14, "training_loss": 1275.442014503479, "training_acc": 50.0, "val_loss": 295.9548034667969, "val_acc": 60.0}
{"epoch": 15, "training_loss": 789.4261474609375, "training_acc": 50.0, "val_loss": 1360.8172607421875, "val_acc": 60.0}
{"epoch": 16, "training_loss": 1952.1981437683105, "training_acc": 50.0, "val_loss": 3564.573486328125, "val_acc": 40.0}
{"epoch": 17, "training_loss": 2947.3129028320313, "training_acc": 50.0, "val_loss": 784.9514770507812, "val_acc": 60.0}
{"epoch": 18, "training_loss": 1201.3337646484374, "training_acc": 40.0, "val_loss": 434.970458984375, "val_acc": 40.0}
{"epoch": 19, "training_loss": 1137.7030151367187, "training_acc": 60.0, "val_loss": 1134.6390380859375, "val_acc": 60.0}
{"epoch": 20, "training_loss": 2036.0234375, "training_acc": 40.0, "val_loss": 740.7969970703125, "val_acc": 40.0}
{"epoch": 21, "training_loss": 1343.2738525390625, "training_acc": 60.0, "val_loss": 2112.753173828125, "val_acc": 60.0}
{"epoch": 22, "training_loss": 1198.9234130859375, "training_acc": 70.0, "val_loss": 5250.05615234375, "val_acc": 40.0}
{"epoch": 23, "training_loss": 4098.02626953125, "training_acc": 50.0, "val_loss": 840.8350830078125, "val_acc": 60.0}
{"epoch": 24, "training_loss": 1709.9566650390625, "training_acc": 50.0, "val_loss": 1586.912109375, "val_acc": 40.0}
{"epoch": 25, "training_loss": 1747.5914978027345, "training_acc": 50.0, "val_loss": 1479.5364990234375, "val_acc": 60.0}
{"epoch": 26, "training_loss": 1742.878515625, "training_acc": 40.0, "val_loss": 204.4435272216797, "val_acc": 60.0}
{"epoch": 27, "training_loss": 706.6884582519531, "training_acc": 40.0, "val_loss": 1269.457763671875, "val_acc": 40.0}
{"epoch": 28, "training_loss": 1018.9671630859375, "training_acc": 50.0, "val_loss": 1700.9508056640625, "val_acc": 60.0}
{"epoch": 29, "training_loss": 1170.8486572265624, "training_acc": 60.0, "val_loss": 5137.52490234375, "val_acc": 40.0}
{"epoch": 30, "training_loss": 3299.5552612304687, "training_acc": 50.0, "val_loss": 2631.171630859375, "val_acc": 60.0}
{"epoch": 31, "training_loss": 5219.801416015625, "training_acc": 50.0, "val_loss": 2109.22265625, "val_acc": 60.0}
{"epoch": 32, "training_loss": 2623.28056640625, "training_acc": 40.0, "val_loss": 3017.444091796875, "val_acc": 40.0}
{"epoch": 33, "training_loss": 1798.894091796875, "training_acc": 50.0, "val_loss": 3830.650146484375, "val_acc": 60.0}
{"epoch": 34, "training_loss": 4072.873779296875, "training_acc": 50.0, "val_loss": 2712.323974609375, "val_acc": 40.0}
{"epoch": 35, "training_loss": 4453.524609375, "training_acc": 50.0, "val_loss": 3901.816162109375, "val_acc": 40.0}
{"epoch": 36, "training_loss": 2998.489404296875, "training_acc": 40.0, "val_loss": 2271.40185546875, "val_acc": 60.0}
{"epoch": 37, "training_loss": 1454.0203430175782, "training_acc": 40.0, "val_loss": 1431.8123779296875, "val_acc": 60.0}
{"epoch": 38, "training_loss": 1800.372998046875, "training_acc": 40.0, "val_loss": 857.2365112304688, "val_acc": 40.0}
{"epoch": 39, "training_loss": 875.1907958984375, "training_acc": 60.0, "val_loss": 256.33331298828125, "val_acc": 40.0}
{"epoch": 40, "training_loss": 1276.6324584960937, "training_acc": 20.0, "val_loss": 4347.66552734375, "val_acc": 40.0}
{"epoch": 41, "training_loss": 3813.810205078125, "training_acc": 50.0, "val_loss": 2118.894287109375, "val_acc": 40.0}
{"epoch": 42, "training_loss": 1403.3270263671875, "training_acc": 60.0, "val_loss": 1383.5343017578125, "val_acc": 60.0}
{"epoch": 43, "training_loss": 1989.147607421875, "training_acc": 40.0, "val_loss": 440.03350830078125, "val_acc": 40.0}
{"epoch": 44, "training_loss": 1590.7453002929688, "training_acc": 60.0, "val_loss": 2207.323486328125, "val_acc": 60.0}
{"epoch": 45, "training_loss": 1830.6443115234374, "training_acc": 50.0, "val_loss": 7648.56005859375, "val_acc": 40.0}
