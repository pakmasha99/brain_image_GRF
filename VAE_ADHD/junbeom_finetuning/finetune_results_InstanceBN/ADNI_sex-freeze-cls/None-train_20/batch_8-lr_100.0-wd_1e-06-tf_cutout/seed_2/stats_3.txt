"main_modify.py --pretrained_path None --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 2 --task ADNI_sex --input_option yAware --learning_rate 1e2 --batch_size 8 --weight_decay 1e-6 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 10698.98009519577, "training_acc": 45.0, "val_loss": 12764.0498046875, "val_acc": 40.0}
{"epoch": 1, "training_loss": 17694.20546875, "training_acc": 55.0, "val_loss": 22526.83203125, "val_acc": 40.0}
{"epoch": 2, "training_loss": 11643.540563964843, "training_acc": 55.0, "val_loss": 7210.59716796875, "val_acc": 60.0}
{"epoch": 3, "training_loss": 14434.798828125, "training_acc": 45.0, "val_loss": 10938.6591796875, "val_acc": 60.0}
{"epoch": 4, "training_loss": 9874.530969238282, "training_acc": 45.0, "val_loss": 10220.4140625, "val_acc": 40.0}
{"epoch": 5, "training_loss": 11163.47734375, "training_acc": 55.0, "val_loss": 21482.1953125, "val_acc": 40.0}
{"epoch": 6, "training_loss": 14392.14140625, "training_acc": 55.0, "val_loss": 8127.94775390625, "val_acc": 40.0}
{"epoch": 7, "training_loss": 5368.62119140625, "training_acc": 35.0, "val_loss": 4170.78662109375, "val_acc": 60.0}
{"epoch": 8, "training_loss": 4206.053125, "training_acc": 45.0, "val_loss": 4542.79345703125, "val_acc": 40.0}
{"epoch": 9, "training_loss": 2565.3780029296877, "training_acc": 55.0, "val_loss": 2619.104248046875, "val_acc": 60.0}
{"epoch": 10, "training_loss": 3885.475732421875, "training_acc": 45.0, "val_loss": 371.7072448730469, "val_acc": 40.0}
{"epoch": 11, "training_loss": 595.6878173828125, "training_acc": 55.0, "val_loss": 2021.8231201171875, "val_acc": 60.0}
{"epoch": 12, "training_loss": 3231.099853515625, "training_acc": 45.0, "val_loss": 2039.2293701171875, "val_acc": 40.0}
{"epoch": 13, "training_loss": 1671.4888427734375, "training_acc": 55.0, "val_loss": 1180.5556640625, "val_acc": 60.0}
{"epoch": 14, "training_loss": 1714.423486328125, "training_acc": 35.0, "val_loss": 712.4176025390625, "val_acc": 40.0}
{"epoch": 15, "training_loss": 1335.0957641601562, "training_acc": 55.0, "val_loss": 405.3206481933594, "val_acc": 40.0}
{"epoch": 16, "training_loss": 386.7098388671875, "training_acc": 45.0, "val_loss": 3727.393798828125, "val_acc": 40.0}
{"epoch": 17, "training_loss": 3153.7728759765623, "training_acc": 55.0, "val_loss": 1517.966796875, "val_acc": 60.0}
{"epoch": 18, "training_loss": 3213.866552734375, "training_acc": 45.0, "val_loss": 1199.072265625, "val_acc": 60.0}
{"epoch": 19, "training_loss": 2871.5353515625, "training_acc": 45.0, "val_loss": 5611.17333984375, "val_acc": 40.0}
{"epoch": 20, "training_loss": 3480.58984375, "training_acc": 45.0, "val_loss": 1800.1463623046875, "val_acc": 60.0}
{"epoch": 21, "training_loss": 1449.3163330078125, "training_acc": 55.0, "val_loss": 5505.73193359375, "val_acc": 40.0}
{"epoch": 22, "training_loss": 3840.6533447265624, "training_acc": 55.0, "val_loss": 462.3883972167969, "val_acc": 60.0}
{"epoch": 23, "training_loss": 425.2234741210938, "training_acc": 65.0, "val_loss": 1144.3660888671875, "val_acc": 40.0}
{"epoch": 24, "training_loss": 538.9553497314453, "training_acc": 65.0, "val_loss": 2456.96875, "val_acc": 60.0}
{"epoch": 25, "training_loss": 2110.5571044921876, "training_acc": 55.0, "val_loss": 3401.591552734375, "val_acc": 40.0}
{"epoch": 26, "training_loss": 2163.517431640625, "training_acc": 55.0, "val_loss": 2427.9208984375, "val_acc": 60.0}
{"epoch": 27, "training_loss": 4639.32744140625, "training_acc": 45.0, "val_loss": 348.4219665527344, "val_acc": 60.0}
{"epoch": 28, "training_loss": 1983.9470825195312, "training_acc": 65.0, "val_loss": 9257.3310546875, "val_acc": 40.0}
{"epoch": 29, "training_loss": 6156.658056640625, "training_acc": 55.0, "val_loss": 86.38819885253906, "val_acc": 40.0}
{"epoch": 30, "training_loss": 5147.094854736328, "training_acc": 35.0, "val_loss": 6376.16796875, "val_acc": 60.0}
{"epoch": 31, "training_loss": 6288.17880859375, "training_acc": 45.0, "val_loss": 6188.89306640625, "val_acc": 40.0}
{"epoch": 32, "training_loss": 6632.6212890625, "training_acc": 55.0, "val_loss": 11225.6240234375, "val_acc": 40.0}
{"epoch": 33, "training_loss": 6044.86552734375, "training_acc": 55.0, "val_loss": 2097.737060546875, "val_acc": 60.0}
{"epoch": 34, "training_loss": 4841.7232421875, "training_acc": 45.0, "val_loss": 3920.171630859375, "val_acc": 60.0}
{"epoch": 35, "training_loss": 4778.982080078125, "training_acc": 35.0, "val_loss": 9304.3037109375, "val_acc": 40.0}
{"epoch": 36, "training_loss": 6783.3650390625, "training_acc": 55.0, "val_loss": 3079.612548828125, "val_acc": 40.0}
{"epoch": 37, "training_loss": 732.1804290771485, "training_acc": 65.0, "val_loss": 6293.14208984375, "val_acc": 60.0}
{"epoch": 38, "training_loss": 8476.007421875, "training_acc": 45.0, "val_loss": 2186.912353515625, "val_acc": 60.0}
{"epoch": 39, "training_loss": 3046.4939453125, "training_acc": 55.0, "val_loss": 8151.2626953125, "val_acc": 40.0}
{"epoch": 40, "training_loss": 4933.652197265625, "training_acc": 55.0, "val_loss": 1320.51513671875, "val_acc": 60.0}
{"epoch": 41, "training_loss": 2603.4908203125, "training_acc": 45.0, "val_loss": 528.9534301757812, "val_acc": 40.0}
{"epoch": 42, "training_loss": 1840.6443237304688, "training_acc": 55.0, "val_loss": 1039.499267578125, "val_acc": 60.0}
{"epoch": 43, "training_loss": 1758.50625, "training_acc": 45.0, "val_loss": 2442.901611328125, "val_acc": 40.0}
{"epoch": 44, "training_loss": 1799.6729919433594, "training_acc": 55.0, "val_loss": 997.4771728515625, "val_acc": 60.0}
{"epoch": 45, "training_loss": 949.3367797851563, "training_acc": 55.0, "val_loss": 2639.66455078125, "val_acc": 40.0}
{"epoch": 46, "training_loss": 2052.82685546875, "training_acc": 45.0, "val_loss": 2080.295654296875, "val_acc": 60.0}
{"epoch": 47, "training_loss": 1467.9299743652343, "training_acc": 45.0, "val_loss": 860.8534545898438, "val_acc": 60.0}
{"epoch": 48, "training_loss": 1347.1507080078125, "training_acc": 45.0, "val_loss": 3380.988037109375, "val_acc": 40.0}
