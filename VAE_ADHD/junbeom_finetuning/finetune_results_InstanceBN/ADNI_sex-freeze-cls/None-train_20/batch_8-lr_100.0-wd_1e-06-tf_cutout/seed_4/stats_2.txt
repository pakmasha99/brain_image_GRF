"main_modify.py --pretrained_path None --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 4 --task ADNI_sex --input_option yAware --learning_rate 1e2 --batch_size 8 --weight_decay 1e-6 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 8661.732045841218, "training_acc": 50.0, "val_loss": 11501.1787109375, "val_acc": 40.0}
{"epoch": 1, "training_loss": 14724.2623046875, "training_acc": 50.0, "val_loss": 12649.3349609375, "val_acc": 40.0}
{"epoch": 2, "training_loss": 5626.31953125, "training_acc": 60.0, "val_loss": 12188.8125, "val_acc": 60.0}
{"epoch": 3, "training_loss": 16449.2943359375, "training_acc": 50.0, "val_loss": 9706.8798828125, "val_acc": 60.0}
{"epoch": 4, "training_loss": 8676.89443359375, "training_acc": 40.0, "val_loss": 6891.45458984375, "val_acc": 40.0}
{"epoch": 5, "training_loss": 5906.5189453125, "training_acc": 50.0, "val_loss": 234.271240234375, "val_acc": 60.0}
{"epoch": 6, "training_loss": 2383.7511596679688, "training_acc": 50.0, "val_loss": 1436.9703369140625, "val_acc": 40.0}
{"epoch": 7, "training_loss": 1216.788623046875, "training_acc": 50.0, "val_loss": 2990.774658203125, "val_acc": 60.0}
{"epoch": 8, "training_loss": 4613.4283203125, "training_acc": 50.0, "val_loss": 1534.363525390625, "val_acc": 60.0}
{"epoch": 9, "training_loss": 1245.31513671875, "training_acc": 70.0, "val_loss": 4505.9404296875, "val_acc": 40.0}
{"epoch": 10, "training_loss": 2190.9845703125, "training_acc": 60.0, "val_loss": 2429.038330078125, "val_acc": 60.0}
{"epoch": 11, "training_loss": 2254.686013793945, "training_acc": 50.0, "val_loss": 225.8691864013672, "val_acc": 40.0}
{"epoch": 12, "training_loss": 1718.508203125, "training_acc": 40.0, "val_loss": 555.3681030273438, "val_acc": 40.0}
{"epoch": 13, "training_loss": 446.8145324707031, "training_acc": 60.0, "val_loss": 1045.5260009765625, "val_acc": 60.0}
{"epoch": 14, "training_loss": 791.1937744140625, "training_acc": 60.0, "val_loss": 6055.8642578125, "val_acc": 40.0}
{"epoch": 15, "training_loss": 4286.11015625, "training_acc": 50.0, "val_loss": 2183.74072265625, "val_acc": 60.0}
{"epoch": 16, "training_loss": 3760.2607421875, "training_acc": 50.0, "val_loss": 138.5403289794922, "val_acc": 60.0}
{"epoch": 17, "training_loss": 2738.376824951172, "training_acc": 60.0, "val_loss": 8227.0732421875, "val_acc": 40.0}
{"epoch": 18, "training_loss": 5234.895178222656, "training_acc": 40.0, "val_loss": 1161.6922607421875, "val_acc": 60.0}
{"epoch": 19, "training_loss": 1267.4688812255858, "training_acc": 50.0, "val_loss": 5020.96484375, "val_acc": 40.0}
{"epoch": 20, "training_loss": 4227.8373046875, "training_acc": 30.0, "val_loss": 1743.596923828125, "val_acc": 60.0}
{"epoch": 21, "training_loss": 1125.6330078125, "training_acc": 60.0, "val_loss": 6643.94482421875, "val_acc": 40.0}
{"epoch": 22, "training_loss": 5509.721875, "training_acc": 50.0, "val_loss": 92.32598114013672, "val_acc": 40.0}
{"epoch": 23, "training_loss": 5818.637017822266, "training_acc": 40.0, "val_loss": 8713.9755859375, "val_acc": 60.0}
{"epoch": 24, "training_loss": 8839.2775390625, "training_acc": 50.0, "val_loss": 264.2550354003906, "val_acc": 40.0}
{"epoch": 25, "training_loss": 1729.0094116210937, "training_acc": 50.0, "val_loss": 2926.28173828125, "val_acc": 40.0}
{"epoch": 26, "training_loss": 2265.63984375, "training_acc": 40.0, "val_loss": 571.286376953125, "val_acc": 60.0}
{"epoch": 27, "training_loss": 2510.452490234375, "training_acc": 40.0, "val_loss": 3134.2880859375, "val_acc": 40.0}
{"epoch": 28, "training_loss": 1682.1471405029297, "training_acc": 40.0, "val_loss": 888.7916870117188, "val_acc": 40.0}
{"epoch": 29, "training_loss": 1175.3495239257813, "training_acc": 30.0, "val_loss": 3795.444091796875, "val_acc": 40.0}
{"epoch": 30, "training_loss": 2969.589794921875, "training_acc": 50.0, "val_loss": 250.87547302246094, "val_acc": 60.0}
{"epoch": 31, "training_loss": 483.5650207519531, "training_acc": 50.0, "val_loss": 1078.4346923828125, "val_acc": 40.0}
{"epoch": 32, "training_loss": 1911.567578125, "training_acc": 40.0, "val_loss": 321.359375, "val_acc": 60.0}
{"epoch": 33, "training_loss": 1560.2667236328125, "training_acc": 60.0, "val_loss": 3969.9921875, "val_acc": 40.0}
{"epoch": 34, "training_loss": 2313.5029296875, "training_acc": 50.0, "val_loss": 2971.058349609375, "val_acc": 60.0}
{"epoch": 35, "training_loss": 2730.151159667969, "training_acc": 50.0, "val_loss": 4554.80615234375, "val_acc": 40.0}
{"epoch": 36, "training_loss": 4025.9013671875, "training_acc": 50.0, "val_loss": 2224.29541015625, "val_acc": 40.0}
{"epoch": 37, "training_loss": 3132.61298828125, "training_acc": 40.0, "val_loss": 3036.693115234375, "val_acc": 60.0}
{"epoch": 38, "training_loss": 2611.26279296875, "training_acc": 50.0, "val_loss": 5680.8115234375, "val_acc": 40.0}
{"epoch": 39, "training_loss": 4234.783435058594, "training_acc": 50.0, "val_loss": 1614.2646484375, "val_acc": 60.0}
{"epoch": 40, "training_loss": 2525.00263671875, "training_acc": 50.0, "val_loss": 635.9205322265625, "val_acc": 40.0}
{"epoch": 41, "training_loss": 971.5394302368164, "training_acc": 50.0, "val_loss": 2697.514404296875, "val_acc": 60.0}
