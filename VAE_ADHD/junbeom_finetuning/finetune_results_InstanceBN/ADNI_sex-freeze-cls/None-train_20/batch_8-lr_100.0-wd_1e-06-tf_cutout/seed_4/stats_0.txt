"main_modify.py --pretrained_path None --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 4 --task ADNI_sex --input_option yAware --learning_rate 1e2 --batch_size 8 --weight_decay 1e-6 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 14955.653195357323, "training_acc": 50.0, "val_loss": 5098.15771484375, "val_acc": 40.0}
{"epoch": 1, "training_loss": 8480.699951171875, "training_acc": 50.0, "val_loss": 4267.59765625, "val_acc": 40.0}
{"epoch": 2, "training_loss": 2874.151904296875, "training_acc": 60.0, "val_loss": 3922.926513671875, "val_acc": 60.0}
{"epoch": 3, "training_loss": 3112.478396606445, "training_acc": 30.0, "val_loss": 2605.003173828125, "val_acc": 60.0}
{"epoch": 4, "training_loss": 3313.93310546875, "training_acc": 50.0, "val_loss": 2677.0390625, "val_acc": 40.0}
{"epoch": 5, "training_loss": 3268.646044921875, "training_acc": 50.0, "val_loss": 1930.5791015625, "val_acc": 40.0}
{"epoch": 6, "training_loss": 1332.2875244140625, "training_acc": 70.0, "val_loss": 3374.948486328125, "val_acc": 60.0}
{"epoch": 7, "training_loss": 3436.725634765625, "training_acc": 40.0, "val_loss": 2513.953857421875, "val_acc": 40.0}
{"epoch": 8, "training_loss": 1259.896630859375, "training_acc": 60.0, "val_loss": 2766.112548828125, "val_acc": 60.0}
{"epoch": 9, "training_loss": 3038.8012756347657, "training_acc": 50.0, "val_loss": 4573.3349609375, "val_acc": 40.0}
{"epoch": 10, "training_loss": 4533.29013671875, "training_acc": 50.0, "val_loss": 2118.644287109375, "val_acc": 40.0}
{"epoch": 11, "training_loss": 3122.599609375, "training_acc": 50.0, "val_loss": 3619.586669921875, "val_acc": 60.0}
{"epoch": 12, "training_loss": 2931.26240234375, "training_acc": 50.0, "val_loss": 5307.419921875, "val_acc": 40.0}
{"epoch": 13, "training_loss": 4136.026171875, "training_acc": 50.0, "val_loss": 1241.5111083984375, "val_acc": 60.0}
{"epoch": 14, "training_loss": 2759.13388671875, "training_acc": 50.0, "val_loss": 1093.6451416015625, "val_acc": 60.0}
{"epoch": 15, "training_loss": 1773.499365234375, "training_acc": 60.0, "val_loss": 3735.544189453125, "val_acc": 40.0}
{"epoch": 16, "training_loss": 2120.841064453125, "training_acc": 50.0, "val_loss": 3925.28369140625, "val_acc": 60.0}
{"epoch": 17, "training_loss": 4939.7263671875, "training_acc": 50.0, "val_loss": 1092.8392333984375, "val_acc": 40.0}
{"epoch": 18, "training_loss": 2502.5341796875, "training_acc": 50.0, "val_loss": 2896.854248046875, "val_acc": 40.0}
{"epoch": 19, "training_loss": 1124.9484649658202, "training_acc": 60.0, "val_loss": 689.5411376953125, "val_acc": 40.0}
{"epoch": 20, "training_loss": 462.96748046875, "training_acc": 50.0, "val_loss": 1479.9246826171875, "val_acc": 40.0}
{"epoch": 21, "training_loss": 792.214453125, "training_acc": 50.0, "val_loss": 2417.443115234375, "val_acc": 40.0}
{"epoch": 22, "training_loss": 1997.8644287109375, "training_acc": 50.0, "val_loss": 2634.790771484375, "val_acc": 60.0}
{"epoch": 23, "training_loss": 3960.6685546875, "training_acc": 50.0, "val_loss": 1026.616943359375, "val_acc": 60.0}
{"epoch": 24, "training_loss": 1878.2516357421875, "training_acc": 60.0, "val_loss": 5518.26416015625, "val_acc": 40.0}
{"epoch": 25, "training_loss": 2518.3135498046877, "training_acc": 70.0, "val_loss": 1999.2076416015625, "val_acc": 60.0}
{"epoch": 26, "training_loss": 2613.04296875, "training_acc": 30.0, "val_loss": 233.2235870361328, "val_acc": 60.0}
{"epoch": 27, "training_loss": 448.3639892578125, "training_acc": 50.0, "val_loss": 90.65294647216797, "val_acc": 40.0}
{"epoch": 28, "training_loss": 529.7767883300781, "training_acc": 50.0, "val_loss": 3063.713623046875, "val_acc": 40.0}
{"epoch": 29, "training_loss": 2336.459930419922, "training_acc": 50.0, "val_loss": 1852.8837890625, "val_acc": 60.0}
{"epoch": 30, "training_loss": 2636.4525390625, "training_acc": 50.0, "val_loss": 2205.805419921875, "val_acc": 40.0}
{"epoch": 31, "training_loss": 2263.665808105469, "training_acc": 50.0, "val_loss": 68.97522735595703, "val_acc": 60.0}
{"epoch": 32, "training_loss": 519.116618347168, "training_acc": 45.0, "val_loss": 1713.6636962890625, "val_acc": 60.0}
{"epoch": 33, "training_loss": 1126.3550048828124, "training_acc": 60.0, "val_loss": 5794.86474609375, "val_acc": 40.0}
{"epoch": 34, "training_loss": 4230.3673828125, "training_acc": 50.0, "val_loss": 1382.974609375, "val_acc": 60.0}
{"epoch": 35, "training_loss": 2108.5427734375, "training_acc": 50.0, "val_loss": 353.5694885253906, "val_acc": 40.0}
{"epoch": 36, "training_loss": 573.9348388671875, "training_acc": 50.0, "val_loss": 737.5213623046875, "val_acc": 60.0}
{"epoch": 37, "training_loss": 1237.657080078125, "training_acc": 50.0, "val_loss": 183.08021545410156, "val_acc": 60.0}
{"epoch": 38, "training_loss": 1012.8170166015625, "training_acc": 30.0, "val_loss": 1914.9788818359375, "val_acc": 40.0}
{"epoch": 39, "training_loss": 1683.754052734375, "training_acc": 40.0, "val_loss": 142.1592559814453, "val_acc": 40.0}
{"epoch": 40, "training_loss": 466.98475341796876, "training_acc": 50.0, "val_loss": 898.3468017578125, "val_acc": 60.0}
{"epoch": 41, "training_loss": 536.0565414428711, "training_acc": 70.0, "val_loss": 2697.75390625, "val_acc": 40.0}
{"epoch": 42, "training_loss": 2204.666162109375, "training_acc": 40.0, "val_loss": 1403.1580810546875, "val_acc": 60.0}
{"epoch": 43, "training_loss": 1263.11689453125, "training_acc": 40.0, "val_loss": 1517.77294921875, "val_acc": 60.0}
{"epoch": 44, "training_loss": 1488.5834602355958, "training_acc": 50.0, "val_loss": 174.31698608398438, "val_acc": 60.0}
{"epoch": 45, "training_loss": 199.02355041503907, "training_acc": 70.0, "val_loss": 1610.3865966796875, "val_acc": 60.0}
{"epoch": 46, "training_loss": 1482.5558471679688, "training_acc": 50.0, "val_loss": 165.94302368164062, "val_acc": 40.0}
{"epoch": 47, "training_loss": 2006.8839294433594, "training_acc": 40.0, "val_loss": 430.60772705078125, "val_acc": 60.0}
{"epoch": 48, "training_loss": 1939.4852416992187, "training_acc": 60.0, "val_loss": 6100.61767578125, "val_acc": 40.0}
{"epoch": 49, "training_loss": 3719.845654296875, "training_acc": 50.0, "val_loss": 1875.0416259765625, "val_acc": 60.0}
{"epoch": 50, "training_loss": 1371.49619140625, "training_acc": 60.0, "val_loss": 2744.780517578125, "val_acc": 40.0}
