"main_modify.py --pretrained_path None --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 1 --task ADNI_sex --input_option yAware --learning_rate 1e2 --batch_size 8 --weight_decay 1e-6 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 11576.152504897118, "training_acc": 50.0, "val_loss": 7599.40576171875, "val_acc": 40.0}
{"epoch": 1, "training_loss": 8554.4763671875, "training_acc": 50.0, "val_loss": 1681.2113037109375, "val_acc": 60.0}
{"epoch": 2, "training_loss": 3464.47265625, "training_acc": 50.0, "val_loss": 3520.180419921875, "val_acc": 40.0}
{"epoch": 3, "training_loss": 2344.112060546875, "training_acc": 50.0, "val_loss": 1634.1337890625, "val_acc": 60.0}
{"epoch": 4, "training_loss": 1291.568411254883, "training_acc": 40.0, "val_loss": 3586.515625, "val_acc": 40.0}
{"epoch": 5, "training_loss": 2297.0515228271483, "training_acc": 50.0, "val_loss": 3375.703125, "val_acc": 60.0}
{"epoch": 6, "training_loss": 6297.9166015625, "training_acc": 50.0, "val_loss": 2083.233154296875, "val_acc": 60.0}
{"epoch": 7, "training_loss": 4835.5638671875, "training_acc": 40.0, "val_loss": 7960.81884765625, "val_acc": 40.0}
{"epoch": 8, "training_loss": 4534.92841796875, "training_acc": 50.0, "val_loss": 1793.623046875, "val_acc": 60.0}
{"epoch": 9, "training_loss": 1745.1107421875, "training_acc": 50.0, "val_loss": 2013.8922119140625, "val_acc": 40.0}
{"epoch": 10, "training_loss": 924.3690673828125, "training_acc": 60.0, "val_loss": 4001.243408203125, "val_acc": 60.0}
{"epoch": 11, "training_loss": 3908.751220703125, "training_acc": 50.0, "val_loss": 3389.993896484375, "val_acc": 40.0}
{"epoch": 12, "training_loss": 4041.80791015625, "training_acc": 50.0, "val_loss": 3227.509521484375, "val_acc": 40.0}
{"epoch": 13, "training_loss": 1671.00703125, "training_acc": 50.0, "val_loss": 6292.9794921875, "val_acc": 60.0}
{"epoch": 14, "training_loss": 8650.4951171875, "training_acc": 50.0, "val_loss": 3087.41357421875, "val_acc": 60.0}
{"epoch": 15, "training_loss": 3829.636328125, "training_acc": 40.0, "val_loss": 6026.96435546875, "val_acc": 40.0}
{"epoch": 16, "training_loss": 3428.1275390625, "training_acc": 50.0, "val_loss": 3672.61181640625, "val_acc": 60.0}
{"epoch": 17, "training_loss": 6793.08125, "training_acc": 50.0, "val_loss": 7114.4970703125, "val_acc": 60.0}
{"epoch": 18, "training_loss": 7770.185546875, "training_acc": 50.0, "val_loss": 2208.430908203125, "val_acc": 40.0}
{"epoch": 19, "training_loss": 3938.94619140625, "training_acc": 50.0, "val_loss": 1578.6829833984375, "val_acc": 40.0}
{"epoch": 20, "training_loss": 2764.8779296875, "training_acc": 50.0, "val_loss": 4699.73828125, "val_acc": 60.0}
{"epoch": 21, "training_loss": 4612.784564208984, "training_acc": 40.0, "val_loss": 614.7193603515625, "val_acc": 40.0}
{"epoch": 22, "training_loss": 633.541455078125, "training_acc": 50.0, "val_loss": 1238.6861572265625, "val_acc": 60.0}
{"epoch": 23, "training_loss": 1513.807568359375, "training_acc": 50.0, "val_loss": 3409.287841796875, "val_acc": 40.0}
{"epoch": 24, "training_loss": 3248.369921875, "training_acc": 50.0, "val_loss": 1052.463134765625, "val_acc": 40.0}
{"epoch": 25, "training_loss": 3397.82099609375, "training_acc": 40.0, "val_loss": 4068.502685546875, "val_acc": 60.0}
{"epoch": 26, "training_loss": 3385.7400634765627, "training_acc": 50.0, "val_loss": 3520.73681640625, "val_acc": 40.0}
{"epoch": 27, "training_loss": 2482.8799560546877, "training_acc": 50.0, "val_loss": 2848.26171875, "val_acc": 60.0}
{"epoch": 28, "training_loss": 4510.42763671875, "training_acc": 50.0, "val_loss": 2141.096923828125, "val_acc": 60.0}
{"epoch": 29, "training_loss": 548.9621856689453, "training_acc": 70.0, "val_loss": 9762.3076171875, "val_acc": 40.0}
{"epoch": 30, "training_loss": 8540.18642578125, "training_acc": 50.0, "val_loss": 7349.109375, "val_acc": 40.0}
{"epoch": 31, "training_loss": 4988.849169921875, "training_acc": 40.0, "val_loss": 4962.2255859375, "val_acc": 60.0}
{"epoch": 32, "training_loss": 5797.04091796875, "training_acc": 50.0, "val_loss": 409.2118835449219, "val_acc": 60.0}
{"epoch": 33, "training_loss": 4539.676245117187, "training_acc": 40.0, "val_loss": 10376.0263671875, "val_acc": 40.0}
{"epoch": 34, "training_loss": 7067.485400390625, "training_acc": 50.0, "val_loss": 986.5027465820312, "val_acc": 60.0}
{"epoch": 35, "training_loss": 2279.692431640625, "training_acc": 50.0, "val_loss": 1506.8125, "val_acc": 60.0}
{"epoch": 36, "training_loss": 2894.41806640625, "training_acc": 40.0, "val_loss": 2665.71923828125, "val_acc": 40.0}
{"epoch": 37, "training_loss": 1185.5682373046875, "training_acc": 60.0, "val_loss": 565.0154418945312, "val_acc": 60.0}
{"epoch": 38, "training_loss": 1708.0951904296876, "training_acc": 50.0, "val_loss": 1647.269775390625, "val_acc": 40.0}
{"epoch": 39, "training_loss": 1567.3212890625, "training_acc": 60.0, "val_loss": 1041.8314208984375, "val_acc": 60.0}
{"epoch": 40, "training_loss": 2722.303515625, "training_acc": 40.0, "val_loss": 3233.585205078125, "val_acc": 40.0}
{"epoch": 41, "training_loss": 1778.55087890625, "training_acc": 50.0, "val_loss": 4964.13037109375, "val_acc": 60.0}
{"epoch": 42, "training_loss": 5697.923999023437, "training_acc": 50.0, "val_loss": 124.02900695800781, "val_acc": 60.0}
{"epoch": 43, "training_loss": 4203.409191894531, "training_acc": 50.0, "val_loss": 8542.029296875, "val_acc": 40.0}
{"epoch": 44, "training_loss": 4030.86142578125, "training_acc": 50.0, "val_loss": 4830.1982421875, "val_acc": 60.0}
{"epoch": 45, "training_loss": 8779.5421875, "training_acc": 50.0, "val_loss": 9618.6923828125, "val_acc": 60.0}
{"epoch": 46, "training_loss": 10115.798291015624, "training_acc": 50.0, "val_loss": 1544.610595703125, "val_acc": 40.0}
{"epoch": 47, "training_loss": 2989.2263671875, "training_acc": 50.0, "val_loss": 3387.7265625, "val_acc": 40.0}
{"epoch": 48, "training_loss": 1027.8256423950195, "training_acc": 70.0, "val_loss": 1761.670166015625, "val_acc": 60.0}
{"epoch": 49, "training_loss": 1961.319873046875, "training_acc": 50.0, "val_loss": 3108.09765625, "val_acc": 40.0}
{"epoch": 50, "training_loss": 1554.522509765625, "training_acc": 50.0, "val_loss": 4255.76171875, "val_acc": 60.0}
{"epoch": 51, "training_loss": 9753.585986328126, "training_acc": 50.0, "val_loss": 7298.35791015625, "val_acc": 60.0}
{"epoch": 52, "training_loss": 5397.91806640625, "training_acc": 50.0, "val_loss": 8074.04833984375, "val_acc": 40.0}
{"epoch": 53, "training_loss": 9921.26015625, "training_acc": 50.0, "val_loss": 16168.9140625, "val_acc": 40.0}
{"epoch": 54, "training_loss": 11283.241796875, "training_acc": 50.0, "val_loss": 3151.736083984375, "val_acc": 40.0}
{"epoch": 55, "training_loss": 5808.20029296875, "training_acc": 50.0, "val_loss": 10209.654296875, "val_acc": 60.0}
{"epoch": 56, "training_loss": 12214.06640625, "training_acc": 50.0, "val_loss": 5342.49755859375, "val_acc": 60.0}
{"epoch": 57, "training_loss": 5987.527490234375, "training_acc": 30.0, "val_loss": 11612.0703125, "val_acc": 40.0}
{"epoch": 58, "training_loss": 9999.0791015625, "training_acc": 50.0, "val_loss": 7581.2001953125, "val_acc": 40.0}
{"epoch": 59, "training_loss": 4303.851403808594, "training_acc": 60.0, "val_loss": 6134.8896484375, "val_acc": 60.0}
{"epoch": 60, "training_loss": 7935.0720703125, "training_acc": 50.0, "val_loss": 4218.64990234375, "val_acc": 60.0}
{"epoch": 61, "training_loss": 4118.6517578125, "training_acc": 40.0, "val_loss": 8115.66357421875, "val_acc": 40.0}
