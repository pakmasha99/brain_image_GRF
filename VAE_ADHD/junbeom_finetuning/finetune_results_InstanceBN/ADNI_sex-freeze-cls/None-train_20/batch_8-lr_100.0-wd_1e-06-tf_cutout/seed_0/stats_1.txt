"main_modify.py --pretrained_path None --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_sex --input_option yAware --learning_rate 1e2 --batch_size 8 --weight_decay 1e-6 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 11591.1187261343, "training_acc": 40.0, "val_loss": 5158.21142578125, "val_acc": 60.0}
{"epoch": 1, "training_loss": 11631.9138671875, "training_acc": 50.0, "val_loss": 6612.078125, "val_acc": 60.0}
{"epoch": 2, "training_loss": 5050.034124755859, "training_acc": 60.0, "val_loss": 16917.22265625, "val_acc": 40.0}
{"epoch": 3, "training_loss": 14641.05390625, "training_acc": 50.0, "val_loss": 10819.2314453125, "val_acc": 40.0}
{"epoch": 4, "training_loss": 6847.426123046875, "training_acc": 40.0, "val_loss": 10238.69140625, "val_acc": 60.0}
{"epoch": 5, "training_loss": 13523.37431640625, "training_acc": 50.0, "val_loss": 7800.83447265625, "val_acc": 60.0}
{"epoch": 6, "training_loss": 6638.580078125, "training_acc": 50.0, "val_loss": 6788.58984375, "val_acc": 40.0}
{"epoch": 7, "training_loss": 5296.278955078125, "training_acc": 50.0, "val_loss": 684.833984375, "val_acc": 40.0}
{"epoch": 8, "training_loss": 4800.798828125, "training_acc": 40.0, "val_loss": 7159.6064453125, "val_acc": 60.0}
{"epoch": 9, "training_loss": 7026.833203125, "training_acc": 50.0, "val_loss": 1980.807861328125, "val_acc": 40.0}
{"epoch": 10, "training_loss": 3001.123095703125, "training_acc": 50.0, "val_loss": 4683.86328125, "val_acc": 40.0}
{"epoch": 11, "training_loss": 3791.106964111328, "training_acc": 40.0, "val_loss": 4735.0712890625, "val_acc": 60.0}
{"epoch": 12, "training_loss": 4720.37705078125, "training_acc": 50.0, "val_loss": 3035.896728515625, "val_acc": 40.0}
{"epoch": 13, "training_loss": 4347.547509765625, "training_acc": 50.0, "val_loss": 2998.158203125, "val_acc": 40.0}
{"epoch": 14, "training_loss": 899.47431640625, "training_acc": 70.0, "val_loss": 2581.369384765625, "val_acc": 60.0}
{"epoch": 15, "training_loss": 2807.21279296875, "training_acc": 40.0, "val_loss": 2205.288818359375, "val_acc": 40.0}
{"epoch": 16, "training_loss": 1600.5997680664063, "training_acc": 40.0, "val_loss": 2394.580078125, "val_acc": 40.0}
{"epoch": 17, "training_loss": 2816.538134765625, "training_acc": 50.0, "val_loss": 424.03302001953125, "val_acc": 60.0}
{"epoch": 18, "training_loss": 593.546435546875, "training_acc": 50.0, "val_loss": 201.97109985351562, "val_acc": 60.0}
{"epoch": 19, "training_loss": 960.3954833984375, "training_acc": 40.0, "val_loss": 1743.260986328125, "val_acc": 60.0}
{"epoch": 20, "training_loss": 2594.71484375, "training_acc": 50.0, "val_loss": 2017.5552978515625, "val_acc": 40.0}
{"epoch": 21, "training_loss": 2478.138134765625, "training_acc": 50.0, "val_loss": 226.65432739257812, "val_acc": 40.0}
{"epoch": 22, "training_loss": 1670.5190307617188, "training_acc": 60.0, "val_loss": 3066.382568359375, "val_acc": 60.0}
{"epoch": 23, "training_loss": 2808.8599609375, "training_acc": 50.0, "val_loss": 4842.51513671875, "val_acc": 40.0}
{"epoch": 24, "training_loss": 2932.0202087402345, "training_acc": 50.0, "val_loss": 3141.798828125, "val_acc": 60.0}
{"epoch": 25, "training_loss": 5641.7681640625, "training_acc": 50.0, "val_loss": 2851.180908203125, "val_acc": 60.0}
{"epoch": 26, "training_loss": 1750.8725708007812, "training_acc": 60.0, "val_loss": 3169.072998046875, "val_acc": 40.0}
{"epoch": 27, "training_loss": 1649.718408203125, "training_acc": 60.0, "val_loss": 2801.658935546875, "val_acc": 60.0}
{"epoch": 28, "training_loss": 3209.35048828125, "training_acc": 50.0, "val_loss": 2984.647216796875, "val_acc": 40.0}
{"epoch": 29, "training_loss": 2496.5377685546873, "training_acc": 50.0, "val_loss": 852.6768798828125, "val_acc": 60.0}
{"epoch": 30, "training_loss": 1197.7771911621094, "training_acc": 50.0, "val_loss": 3558.966552734375, "val_acc": 40.0}
{"epoch": 31, "training_loss": 2895.1376953125, "training_acc": 50.0, "val_loss": 943.49755859375, "val_acc": 60.0}
{"epoch": 32, "training_loss": 1663.913427734375, "training_acc": 50.0, "val_loss": 644.468505859375, "val_acc": 40.0}
{"epoch": 33, "training_loss": 878.7796630859375, "training_acc": 50.0, "val_loss": 278.79278564453125, "val_acc": 60.0}
{"epoch": 34, "training_loss": 1289.406689453125, "training_acc": 50.0, "val_loss": 3.6046454906463623, "val_acc": 80.0}
{"epoch": 35, "training_loss": 243.67550354003907, "training_acc": 55.0, "val_loss": 1740.9501953125, "val_acc": 60.0}
{"epoch": 36, "training_loss": 1682.4984375, "training_acc": 50.0, "val_loss": 4301.52880859375, "val_acc": 40.0}
{"epoch": 37, "training_loss": 2229.5057006835937, "training_acc": 60.0, "val_loss": 1396.449462890625, "val_acc": 60.0}
{"epoch": 38, "training_loss": 1606.78257522583, "training_acc": 60.0, "val_loss": 1643.268798828125, "val_acc": 40.0}
{"epoch": 39, "training_loss": 1620.25087890625, "training_acc": 40.0, "val_loss": 2291.267578125, "val_acc": 60.0}
{"epoch": 40, "training_loss": 3388.7019287109374, "training_acc": 30.0, "val_loss": 5708.6376953125, "val_acc": 40.0}
{"epoch": 41, "training_loss": 3694.5401123046877, "training_acc": 40.0, "val_loss": 1327.3677978515625, "val_acc": 60.0}
{"epoch": 42, "training_loss": 1416.864923095703, "training_acc": 30.0, "val_loss": 2285.612548828125, "val_acc": 60.0}
{"epoch": 43, "training_loss": 2900.460791015625, "training_acc": 50.0, "val_loss": 759.10986328125, "val_acc": 40.0}
{"epoch": 44, "training_loss": 746.2913330078125, "training_acc": 50.0, "val_loss": 2638.366943359375, "val_acc": 60.0}
{"epoch": 45, "training_loss": 4020.314013671875, "training_acc": 50.0, "val_loss": 1104.2113037109375, "val_acc": 60.0}
{"epoch": 46, "training_loss": 3040.21767578125, "training_acc": 50.0, "val_loss": 5458.91259765625, "val_acc": 40.0}
{"epoch": 47, "training_loss": 3625.126953125, "training_acc": 40.0, "val_loss": 3525.16845703125, "val_acc": 60.0}
{"epoch": 48, "training_loss": 3539.7970947265626, "training_acc": 50.0, "val_loss": 4143.12353515625, "val_acc": 40.0}
{"epoch": 49, "training_loss": 4578.5052734375, "training_acc": 50.0, "val_loss": 2212.550048828125, "val_acc": 40.0}
{"epoch": 50, "training_loss": 3751.29189453125, "training_acc": 40.0, "val_loss": 3698.790771484375, "val_acc": 60.0}
{"epoch": 51, "training_loss": 2502.6128051757814, "training_acc": 60.0, "val_loss": 4810.70654296875, "val_acc": 40.0}
{"epoch": 52, "training_loss": 3822.1810546875, "training_acc": 50.0, "val_loss": 670.1651611328125, "val_acc": 60.0}
{"epoch": 53, "training_loss": 1052.72890625, "training_acc": 50.0, "val_loss": 1398.0103759765625, "val_acc": 40.0}
