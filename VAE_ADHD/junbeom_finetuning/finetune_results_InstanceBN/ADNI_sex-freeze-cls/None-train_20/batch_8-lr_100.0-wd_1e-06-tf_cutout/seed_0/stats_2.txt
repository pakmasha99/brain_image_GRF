"main_modify.py --pretrained_path None --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_sex --input_option yAware --learning_rate 1e2 --batch_size 8 --weight_decay 1e-6 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 17111.261913442613, "training_acc": 20.0, "val_loss": 597.2968139648438, "val_acc": 60.0}
{"epoch": 1, "training_loss": 7670.957861328125, "training_acc": 60.0, "val_loss": 28390.384765625, "val_acc": 40.0}
{"epoch": 2, "training_loss": 21827.62890625, "training_acc": 50.0, "val_loss": 12569.2177734375, "val_acc": 40.0}
{"epoch": 3, "training_loss": 4206.6212890625, "training_acc": 60.0, "val_loss": 12095.087890625, "val_acc": 60.0}
{"epoch": 4, "training_loss": 18353.895703125, "training_acc": 50.0, "val_loss": 14172.3779296875, "val_acc": 60.0}
{"epoch": 5, "training_loss": 14138.982080078125, "training_acc": 50.0, "val_loss": 1544.8990478515625, "val_acc": 40.0}
{"epoch": 6, "training_loss": 3237.224560546875, "training_acc": 50.0, "val_loss": 6636.58447265625, "val_acc": 40.0}
{"epoch": 7, "training_loss": 3198.3285522460938, "training_acc": 60.0, "val_loss": 3232.601318359375, "val_acc": 60.0}
{"epoch": 8, "training_loss": 3868.5609375, "training_acc": 50.0, "val_loss": 2746.450927734375, "val_acc": 40.0}
{"epoch": 9, "training_loss": 3552.22900390625, "training_acc": 50.0, "val_loss": 2210.3203125, "val_acc": 40.0}
{"epoch": 10, "training_loss": 1046.6236450195313, "training_acc": 70.0, "val_loss": 1125.51953125, "val_acc": 60.0}
{"epoch": 11, "training_loss": 1749.486328125, "training_acc": 50.0, "val_loss": 765.1199340820312, "val_acc": 40.0}
{"epoch": 12, "training_loss": 2211.0332763671877, "training_acc": 50.0, "val_loss": 2563.716064453125, "val_acc": 60.0}
{"epoch": 13, "training_loss": 1762.9919311523438, "training_acc": 60.0, "val_loss": 7657.28857421875, "val_acc": 40.0}
{"epoch": 14, "training_loss": 6026.5888671875, "training_acc": 50.0, "val_loss": 209.12771606445312, "val_acc": 40.0}
{"epoch": 15, "training_loss": 4669.354522705078, "training_acc": 50.0, "val_loss": 7630.1064453125, "val_acc": 60.0}
{"epoch": 16, "training_loss": 7026.9755859375, "training_acc": 50.0, "val_loss": 4043.64501953125, "val_acc": 40.0}
{"epoch": 17, "training_loss": 5619.720361328125, "training_acc": 50.0, "val_loss": 8403.2294921875, "val_acc": 40.0}
{"epoch": 18, "training_loss": 4268.403674316406, "training_acc": 60.0, "val_loss": 2261.392333984375, "val_acc": 60.0}
{"epoch": 19, "training_loss": 2749.211865234375, "training_acc": 50.0, "val_loss": 3452.136474609375, "val_acc": 40.0}
{"epoch": 20, "training_loss": 3581.907421875, "training_acc": 50.0, "val_loss": 2039.3997802734375, "val_acc": 40.0}
{"epoch": 21, "training_loss": 2363.1404052734374, "training_acc": 50.0, "val_loss": 3071.855224609375, "val_acc": 60.0}
{"epoch": 22, "training_loss": 2819.19736328125, "training_acc": 50.0, "val_loss": 5369.3857421875, "val_acc": 40.0}
{"epoch": 23, "training_loss": 3271.23818359375, "training_acc": 50.0, "val_loss": 3272.225341796875, "val_acc": 60.0}
{"epoch": 24, "training_loss": 4644.497412109375, "training_acc": 50.0, "val_loss": 3366.7265625, "val_acc": 60.0}
{"epoch": 25, "training_loss": 2677.75703125, "training_acc": 50.0, "val_loss": 7456.85546875, "val_acc": 40.0}
{"epoch": 26, "training_loss": 5743.681860351562, "training_acc": 50.0, "val_loss": 139.52935791015625, "val_acc": 60.0}
{"epoch": 27, "training_loss": 358.0174621582031, "training_acc": 50.0, "val_loss": 162.774169921875, "val_acc": 60.0}
{"epoch": 28, "training_loss": 283.27806396484374, "training_acc": 60.0, "val_loss": 1044.5897216796875, "val_acc": 40.0}
{"epoch": 29, "training_loss": 895.9430511474609, "training_acc": 40.0, "val_loss": 86.951904296875, "val_acc": 40.0}
{"epoch": 30, "training_loss": 2882.418811035156, "training_acc": 40.0, "val_loss": 3125.187255859375, "val_acc": 60.0}
{"epoch": 31, "training_loss": 2579.170751953125, "training_acc": 50.0, "val_loss": 5856.47119140625, "val_acc": 40.0}
{"epoch": 32, "training_loss": 4460.44453125, "training_acc": 50.0, "val_loss": 1417.2476806640625, "val_acc": 60.0}
{"epoch": 33, "training_loss": 2134.5513916015625, "training_acc": 50.0, "val_loss": 838.9986572265625, "val_acc": 60.0}
{"epoch": 34, "training_loss": 2047.72236328125, "training_acc": 50.0, "val_loss": 2615.148681640625, "val_acc": 40.0}
{"epoch": 35, "training_loss": 1620.606103515625, "training_acc": 50.0, "val_loss": 338.4251403808594, "val_acc": 60.0}
{"epoch": 36, "training_loss": 3044.1303100585938, "training_acc": 40.0, "val_loss": 3605.971435546875, "val_acc": 40.0}
{"epoch": 37, "training_loss": 2213.50224609375, "training_acc": 50.0, "val_loss": 955.8410034179688, "val_acc": 60.0}
{"epoch": 38, "training_loss": 2526.9661865234375, "training_acc": 40.0, "val_loss": 3002.183349609375, "val_acc": 40.0}
{"epoch": 39, "training_loss": 1265.6919311523438, "training_acc": 60.0, "val_loss": 5084.79296875, "val_acc": 60.0}
{"epoch": 40, "training_loss": 5761.6474609375, "training_acc": 50.0, "val_loss": 401.7521057128906, "val_acc": 60.0}
{"epoch": 41, "training_loss": 4589.85986328125, "training_acc": 40.0, "val_loss": 10370.5478515625, "val_acc": 40.0}
{"epoch": 42, "training_loss": 6871.9763671875, "training_acc": 50.0, "val_loss": 1740.370361328125, "val_acc": 60.0}
{"epoch": 43, "training_loss": 3720.8056640625, "training_acc": 50.0, "val_loss": 2904.811767578125, "val_acc": 60.0}
{"epoch": 44, "training_loss": 1926.45498046875, "training_acc": 60.0, "val_loss": 8268.595703125, "val_acc": 40.0}
{"epoch": 45, "training_loss": 6508.70576171875, "training_acc": 50.0, "val_loss": 1706.699462890625, "val_acc": 40.0}
{"epoch": 46, "training_loss": 2921.68740234375, "training_acc": 50.0, "val_loss": 4210.96728515625, "val_acc": 60.0}
{"epoch": 47, "training_loss": 5075.066796875, "training_acc": 30.0, "val_loss": 4217.140625, "val_acc": 40.0}
{"epoch": 48, "training_loss": 2607.63779296875, "training_acc": 50.0, "val_loss": 2811.174072265625, "val_acc": 60.0}
