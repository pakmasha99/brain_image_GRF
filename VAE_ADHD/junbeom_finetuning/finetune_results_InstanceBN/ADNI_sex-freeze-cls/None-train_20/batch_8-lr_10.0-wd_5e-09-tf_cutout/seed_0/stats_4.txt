"main_modify.py --pretrained_path None --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_sex --input_option yAware --learning_rate 1e1 --batch_size 8 --weight_decay 5e-9 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 1059.673496055603, "training_acc": 45.0, "val_loss": 438.46710205078125, "val_acc": 60.0}
{"epoch": 1, "training_loss": 1245.6244140625, "training_acc": 45.0, "val_loss": 178.0552520751953, "val_acc": 60.0}
{"epoch": 2, "training_loss": 548.6247802734375, "training_acc": 65.0, "val_loss": 2232.321044921875, "val_acc": 40.0}
{"epoch": 3, "training_loss": 1738.190234375, "training_acc": 55.0, "val_loss": 1405.0784912109375, "val_acc": 40.0}
{"epoch": 4, "training_loss": 434.7161437988281, "training_acc": 75.0, "val_loss": 900.22900390625, "val_acc": 60.0}
{"epoch": 5, "training_loss": 1500.2623046875, "training_acc": 45.0, "val_loss": 1002.5758056640625, "val_acc": 60.0}
{"epoch": 6, "training_loss": 852.7335235595704, "training_acc": 45.0, "val_loss": 949.7369995117188, "val_acc": 40.0}
{"epoch": 7, "training_loss": 1129.1416015625, "training_acc": 55.0, "val_loss": 2179.844482421875, "val_acc": 40.0}
{"epoch": 8, "training_loss": 1498.658837890625, "training_acc": 55.0, "val_loss": 989.90283203125, "val_acc": 40.0}
{"epoch": 9, "training_loss": 356.6726593017578, "training_acc": 65.0, "val_loss": 929.4405517578125, "val_acc": 60.0}
{"epoch": 10, "training_loss": 1432.203125, "training_acc": 45.0, "val_loss": 925.8910522460938, "val_acc": 60.0}
{"epoch": 11, "training_loss": 799.1115478515625, "training_acc": 45.0, "val_loss": 941.6158447265625, "val_acc": 40.0}
{"epoch": 12, "training_loss": 1172.764013671875, "training_acc": 55.0, "val_loss": 2120.031982421875, "val_acc": 40.0}
{"epoch": 13, "training_loss": 1462.1709716796875, "training_acc": 55.0, "val_loss": 777.8038330078125, "val_acc": 40.0}
{"epoch": 14, "training_loss": 387.3263198852539, "training_acc": 35.0, "val_loss": 262.6188049316406, "val_acc": 60.0}
{"epoch": 15, "training_loss": 214.99828338623047, "training_acc": 55.0, "val_loss": 503.58154296875, "val_acc": 40.0}
{"epoch": 16, "training_loss": 337.99034423828124, "training_acc": 55.0, "val_loss": 89.6954574584961, "val_acc": 60.0}
{"epoch": 17, "training_loss": 276.82158813476565, "training_acc": 45.0, "val_loss": 122.59942626953125, "val_acc": 40.0}
{"epoch": 18, "training_loss": 153.0697479248047, "training_acc": 55.0, "val_loss": 36.01368713378906, "val_acc": 60.0}
{"epoch": 19, "training_loss": 31.319056701660156, "training_acc": 55.0, "val_loss": 246.917724609375, "val_acc": 60.0}
{"epoch": 20, "training_loss": 329.8967987060547, "training_acc": 45.0, "val_loss": 212.73594665527344, "val_acc": 40.0}
{"epoch": 21, "training_loss": 175.92646179199218, "training_acc": 55.0, "val_loss": 34.0670280456543, "val_acc": 60.0}
{"epoch": 22, "training_loss": 82.93978271484374, "training_acc": 45.0, "val_loss": 236.10220336914062, "val_acc": 40.0}
{"epoch": 23, "training_loss": 156.13944091796876, "training_acc": 25.0, "val_loss": 67.38709259033203, "val_acc": 60.0}
{"epoch": 24, "training_loss": 63.25281524658203, "training_acc": 65.0, "val_loss": 322.7529296875, "val_acc": 40.0}
{"epoch": 25, "training_loss": 178.27442665100097, "training_acc": 55.0, "val_loss": 276.8822937011719, "val_acc": 60.0}
{"epoch": 26, "training_loss": 415.2481170654297, "training_acc": 45.0, "val_loss": 2.7405319213867188, "val_acc": 60.0}
{"epoch": 27, "training_loss": 148.28080837875603, "training_acc": 65.0, "val_loss": 57.95048904418945, "val_acc": 60.0}
{"epoch": 28, "training_loss": 89.949658203125, "training_acc": 45.0, "val_loss": 224.1960906982422, "val_acc": 40.0}
{"epoch": 29, "training_loss": 90.26306762695313, "training_acc": 65.0, "val_loss": 326.9048767089844, "val_acc": 60.0}
{"epoch": 30, "training_loss": 328.38756256103517, "training_acc": 45.0, "val_loss": 548.3191528320312, "val_acc": 40.0}
{"epoch": 31, "training_loss": 596.2621948242188, "training_acc": 55.0, "val_loss": 868.41064453125, "val_acc": 40.0}
{"epoch": 32, "training_loss": 379.1274101257324, "training_acc": 55.0, "val_loss": 199.1732940673828, "val_acc": 60.0}
{"epoch": 33, "training_loss": 214.44584197998046, "training_acc": 45.0, "val_loss": 70.72661590576172, "val_acc": 40.0}
{"epoch": 34, "training_loss": 175.2991455078125, "training_acc": 35.0, "val_loss": 241.67236328125, "val_acc": 40.0}
{"epoch": 35, "training_loss": 364.223583984375, "training_acc": 55.0, "val_loss": 243.51528930664062, "val_acc": 40.0}
{"epoch": 36, "training_loss": 283.3807434082031, "training_acc": 45.0, "val_loss": 271.77099609375, "val_acc": 60.0}
{"epoch": 37, "training_loss": 298.3300064086914, "training_acc": 25.0, "val_loss": 9.210741996765137, "val_acc": 60.0}
{"epoch": 38, "training_loss": 95.23081665039062, "training_acc": 35.0, "val_loss": 174.035888671875, "val_acc": 60.0}
{"epoch": 39, "training_loss": 202.36780700683593, "training_acc": 45.0, "val_loss": 405.9612731933594, "val_acc": 40.0}
{"epoch": 40, "training_loss": 390.02113342285156, "training_acc": 55.0, "val_loss": 434.94342041015625, "val_acc": 40.0}
{"epoch": 41, "training_loss": 201.18845825195314, "training_acc": 55.0, "val_loss": 391.3075866699219, "val_acc": 60.0}
{"epoch": 42, "training_loss": 494.1103790283203, "training_acc": 45.0, "val_loss": 271.1160583496094, "val_acc": 40.0}
{"epoch": 43, "training_loss": 265.75681457519534, "training_acc": 55.0, "val_loss": 174.5625, "val_acc": 40.0}
{"epoch": 44, "training_loss": 77.19192352294922, "training_acc": 65.0, "val_loss": 25.92510414123535, "val_acc": 60.0}
{"epoch": 45, "training_loss": 151.2280303955078, "training_acc": 55.0, "val_loss": 265.278564453125, "val_acc": 40.0}
