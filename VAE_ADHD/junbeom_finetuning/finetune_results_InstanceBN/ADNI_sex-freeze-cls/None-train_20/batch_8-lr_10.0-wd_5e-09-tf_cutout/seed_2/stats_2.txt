"main_modify.py --pretrained_path None --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 2 --task ADNI_sex --input_option yAware --learning_rate 1e1 --batch_size 8 --weight_decay 5e-9 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 636.920758676529, "training_acc": 60.0, "val_loss": 497.5440979003906, "val_acc": 40.0}
{"epoch": 1, "training_loss": 714.612060546875, "training_acc": 50.0, "val_loss": 465.65118408203125, "val_acc": 40.0}
{"epoch": 2, "training_loss": 511.387890625, "training_acc": 40.0, "val_loss": 501.4987487792969, "val_acc": 60.0}
{"epoch": 3, "training_loss": 579.6084838867188, "training_acc": 30.0, "val_loss": 278.28802490234375, "val_acc": 40.0}
{"epoch": 4, "training_loss": 115.76823768615722, "training_acc": 40.0, "val_loss": 166.56260681152344, "val_acc": 60.0}
{"epoch": 5, "training_loss": 217.15984191894532, "training_acc": 50.0, "val_loss": 352.02105712890625, "val_acc": 40.0}
{"epoch": 6, "training_loss": 449.78412475585935, "training_acc": 50.0, "val_loss": 298.4848937988281, "val_acc": 40.0}
{"epoch": 7, "training_loss": 302.657666015625, "training_acc": 40.0, "val_loss": 260.0065612792969, "val_acc": 60.0}
{"epoch": 8, "training_loss": 174.60982818603514, "training_acc": 60.0, "val_loss": 504.2596740722656, "val_acc": 40.0}
{"epoch": 9, "training_loss": 381.96979064941405, "training_acc": 50.0, "val_loss": 106.33977508544922, "val_acc": 60.0}
{"epoch": 10, "training_loss": 191.50641479492188, "training_acc": 50.0, "val_loss": 230.890869140625, "val_acc": 40.0}
{"epoch": 11, "training_loss": 222.2441650390625, "training_acc": 50.0, "val_loss": 107.33916473388672, "val_acc": 60.0}
{"epoch": 12, "training_loss": 120.6017562866211, "training_acc": 50.0, "val_loss": 325.7830505371094, "val_acc": 40.0}
{"epoch": 13, "training_loss": 248.39407348632812, "training_acc": 50.0, "val_loss": 120.48799133300781, "val_acc": 60.0}
{"epoch": 14, "training_loss": 128.6404228568077, "training_acc": 60.0, "val_loss": 113.5211181640625, "val_acc": 40.0}
{"epoch": 15, "training_loss": 60.32657470703125, "training_acc": 50.0, "val_loss": 29.45572280883789, "val_acc": 60.0}
{"epoch": 16, "training_loss": 17.22859745025635, "training_acc": 70.0, "val_loss": 5.332511901855469, "val_acc": 40.0}
{"epoch": 17, "training_loss": 139.18692588806152, "training_acc": 40.0, "val_loss": 149.7028350830078, "val_acc": 40.0}
{"epoch": 18, "training_loss": 192.41350402832032, "training_acc": 50.0, "val_loss": 157.78823852539062, "val_acc": 60.0}
{"epoch": 19, "training_loss": 225.25061492919923, "training_acc": 50.0, "val_loss": 60.55488204956055, "val_acc": 40.0}
{"epoch": 20, "training_loss": 84.51565704345703, "training_acc": 50.0, "val_loss": 95.67594146728516, "val_acc": 60.0}
{"epoch": 21, "training_loss": 186.48638916015625, "training_acc": 40.0, "val_loss": 84.4025650024414, "val_acc": 60.0}
{"epoch": 22, "training_loss": 152.83326110839843, "training_acc": 50.0, "val_loss": 262.85723876953125, "val_acc": 40.0}
{"epoch": 23, "training_loss": 309.8239501953125, "training_acc": 50.0, "val_loss": 128.12721252441406, "val_acc": 40.0}
{"epoch": 24, "training_loss": 288.2009307861328, "training_acc": 50.0, "val_loss": 342.9921875, "val_acc": 60.0}
{"epoch": 25, "training_loss": 238.85374145507814, "training_acc": 60.0, "val_loss": 623.3057861328125, "val_acc": 40.0}
{"epoch": 26, "training_loss": 546.4386352539062, "training_acc": 50.0, "val_loss": 111.7089614868164, "val_acc": 40.0}
{"epoch": 27, "training_loss": 421.23594970703124, "training_acc": 50.0, "val_loss": 675.5213012695312, "val_acc": 60.0}
{"epoch": 28, "training_loss": 663.4292175292969, "training_acc": 50.0, "val_loss": 249.0290985107422, "val_acc": 40.0}
{"epoch": 29, "training_loss": 315.8815032958984, "training_acc": 50.0, "val_loss": 393.5126037597656, "val_acc": 40.0}
{"epoch": 30, "training_loss": 249.1876220703125, "training_acc": 30.0, "val_loss": 54.581539154052734, "val_acc": 40.0}
{"epoch": 31, "training_loss": 128.5154296875, "training_acc": 20.0, "val_loss": 22.62407875061035, "val_acc": 60.0}
{"epoch": 32, "training_loss": 93.25425262451172, "training_acc": 30.0, "val_loss": 112.45184326171875, "val_acc": 40.0}
{"epoch": 33, "training_loss": 100.47791748046875, "training_acc": 50.0, "val_loss": 172.2078399658203, "val_acc": 60.0}
{"epoch": 34, "training_loss": 121.51914520263672, "training_acc": 60.0, "val_loss": 427.8758850097656, "val_acc": 40.0}
{"epoch": 35, "training_loss": 302.9379455566406, "training_acc": 50.0, "val_loss": 229.5375518798828, "val_acc": 60.0}
