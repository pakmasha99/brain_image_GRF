"main_modify.py --pretrained_path None --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 4 --task ADNI_sex --input_option yAware --learning_rate 1e1 --batch_size 8 --weight_decay 5e-9 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 1317.4310666561128, "training_acc": 35.0, "val_loss": 233.25515747070312, "val_acc": 40.0}
{"epoch": 1, "training_loss": 1072.1226806640625, "training_acc": 45.0, "val_loss": 1533.8817138671875, "val_acc": 60.0}
{"epoch": 2, "training_loss": 1710.7906982421875, "training_acc": 45.0, "val_loss": 129.34768676757812, "val_acc": 60.0}
{"epoch": 3, "training_loss": 896.37685546875, "training_acc": 45.0, "val_loss": 2454.860107421875, "val_acc": 40.0}
{"epoch": 4, "training_loss": 1851.030908203125, "training_acc": 55.0, "val_loss": 1879.1141357421875, "val_acc": 40.0}
{"epoch": 5, "training_loss": 987.7979125976562, "training_acc": 55.0, "val_loss": 408.8046875, "val_acc": 60.0}
{"epoch": 6, "training_loss": 958.3328125, "training_acc": 45.0, "val_loss": 922.9470825195312, "val_acc": 60.0}
{"epoch": 7, "training_loss": 940.737353515625, "training_acc": 45.0, "val_loss": 241.53306579589844, "val_acc": 40.0}
{"epoch": 8, "training_loss": 702.3715805053711, "training_acc": 55.0, "val_loss": 1332.6492919921875, "val_acc": 40.0}
{"epoch": 9, "training_loss": 887.43203125, "training_acc": 55.0, "val_loss": 391.8923034667969, "val_acc": 40.0}
{"epoch": 10, "training_loss": 411.048291015625, "training_acc": 45.0, "val_loss": 583.90673828125, "val_acc": 60.0}
{"epoch": 11, "training_loss": 685.93955078125, "training_acc": 45.0, "val_loss": 210.6051025390625, "val_acc": 40.0}
{"epoch": 12, "training_loss": 287.0934814453125, "training_acc": 55.0, "val_loss": 501.780029296875, "val_acc": 40.0}
{"epoch": 13, "training_loss": 291.17323913574216, "training_acc": 45.0, "val_loss": 134.03131103515625, "val_acc": 60.0}
{"epoch": 14, "training_loss": 146.6694763183594, "training_acc": 45.0, "val_loss": 594.3549194335938, "val_acc": 40.0}
{"epoch": 15, "training_loss": 366.4217895507812, "training_acc": 55.0, "val_loss": 119.3025894165039, "val_acc": 60.0}
{"epoch": 16, "training_loss": 237.73755798339843, "training_acc": 45.0, "val_loss": 16.959806442260742, "val_acc": 40.0}
{"epoch": 17, "training_loss": 70.5318992614746, "training_acc": 35.0, "val_loss": 232.97935485839844, "val_acc": 40.0}
{"epoch": 18, "training_loss": 183.47091751098634, "training_acc": 45.0, "val_loss": 290.518798828125, "val_acc": 60.0}
{"epoch": 19, "training_loss": 303.0470947265625, "training_acc": 45.0, "val_loss": 498.208984375, "val_acc": 40.0}
{"epoch": 20, "training_loss": 326.7806060791016, "training_acc": 55.0, "val_loss": 130.7455291748047, "val_acc": 60.0}
{"epoch": 21, "training_loss": 259.62578735351565, "training_acc": 45.0, "val_loss": 117.1811294555664, "val_acc": 40.0}
{"epoch": 22, "training_loss": 148.84716186523437, "training_acc": 55.0, "val_loss": 39.50008773803711, "val_acc": 60.0}
{"epoch": 23, "training_loss": 64.50367641448975, "training_acc": 55.0, "val_loss": 70.94811248779297, "val_acc": 40.0}
{"epoch": 24, "training_loss": 130.46346893310547, "training_acc": 35.0, "val_loss": 262.2713623046875, "val_acc": 40.0}
{"epoch": 25, "training_loss": 244.88231658935547, "training_acc": 55.0, "val_loss": 34.62002182006836, "val_acc": 60.0}
{"epoch": 26, "training_loss": 65.86520805358887, "training_acc": 45.0, "val_loss": 270.9130859375, "val_acc": 40.0}
{"epoch": 27, "training_loss": 126.3872142791748, "training_acc": 35.0, "val_loss": 51.3626823425293, "val_acc": 60.0}
{"epoch": 28, "training_loss": 93.91031112670899, "training_acc": 35.0, "val_loss": 195.91246032714844, "val_acc": 60.0}
{"epoch": 29, "training_loss": 274.6843963623047, "training_acc": 25.0, "val_loss": 39.405921936035156, "val_acc": 60.0}
{"epoch": 30, "training_loss": 53.11935119628906, "training_acc": 45.0, "val_loss": 125.94194793701172, "val_acc": 40.0}
{"epoch": 31, "training_loss": 84.90664901733399, "training_acc": 55.0, "val_loss": 160.16050720214844, "val_acc": 60.0}
{"epoch": 32, "training_loss": 119.1884521484375, "training_acc": 55.0, "val_loss": 626.6661987304688, "val_acc": 40.0}
{"epoch": 33, "training_loss": 488.6134979248047, "training_acc": 55.0, "val_loss": 177.83534240722656, "val_acc": 40.0}
{"epoch": 34, "training_loss": 305.838232421875, "training_acc": 45.0, "val_loss": 278.9864807128906, "val_acc": 60.0}
{"epoch": 35, "training_loss": 253.18235473632814, "training_acc": 45.0, "val_loss": 851.8773803710938, "val_acc": 40.0}
