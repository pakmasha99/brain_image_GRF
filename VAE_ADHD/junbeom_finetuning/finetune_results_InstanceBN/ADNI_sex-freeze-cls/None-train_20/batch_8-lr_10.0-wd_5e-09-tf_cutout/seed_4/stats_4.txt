"main_modify.py --pretrained_path None --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 4 --task ADNI_sex --input_option yAware --learning_rate 1e1 --batch_size 8 --weight_decay 5e-9 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 1399.6160591602325, "training_acc": 45.0, "val_loss": 1413.6881103515625, "val_acc": 40.0}
{"epoch": 1, "training_loss": 1250.6378662109375, "training_acc": 55.0, "val_loss": 1703.924072265625, "val_acc": 40.0}
{"epoch": 2, "training_loss": 868.1647323608398, "training_acc": 55.0, "val_loss": 284.05609130859375, "val_acc": 60.0}
{"epoch": 3, "training_loss": 314.7760070800781, "training_acc": 45.0, "val_loss": 353.2500915527344, "val_acc": 40.0}
{"epoch": 4, "training_loss": 262.8359893798828, "training_acc": 45.0, "val_loss": 279.4395751953125, "val_acc": 60.0}
{"epoch": 5, "training_loss": 272.30662841796874, "training_acc": 45.0, "val_loss": 807.7848510742188, "val_acc": 40.0}
{"epoch": 6, "training_loss": 579.9284118652344, "training_acc": 55.0, "val_loss": 81.45515441894531, "val_acc": 40.0}
{"epoch": 7, "training_loss": 249.6988082885742, "training_acc": 65.0, "val_loss": 573.5719604492188, "val_acc": 60.0}
{"epoch": 8, "training_loss": 568.8048217773437, "training_acc": 45.0, "val_loss": 679.6447143554688, "val_acc": 40.0}
{"epoch": 9, "training_loss": 616.7816345214844, "training_acc": 55.0, "val_loss": 987.3705444335938, "val_acc": 40.0}
{"epoch": 10, "training_loss": 514.71357421875, "training_acc": 55.0, "val_loss": 292.2928161621094, "val_acc": 60.0}
{"epoch": 11, "training_loss": 530.7485534667969, "training_acc": 45.0, "val_loss": 433.0065612792969, "val_acc": 60.0}
{"epoch": 12, "training_loss": 395.55140380859376, "training_acc": 45.0, "val_loss": 671.7597045898438, "val_acc": 40.0}
{"epoch": 13, "training_loss": 493.753466796875, "training_acc": 55.0, "val_loss": 103.12651824951172, "val_acc": 40.0}
{"epoch": 14, "training_loss": 145.79620971679688, "training_acc": 65.0, "val_loss": 165.61866760253906, "val_acc": 60.0}
{"epoch": 15, "training_loss": 254.7680633544922, "training_acc": 45.0, "val_loss": 212.0492706298828, "val_acc": 40.0}
{"epoch": 16, "training_loss": 131.32625579833984, "training_acc": 55.0, "val_loss": 32.756614685058594, "val_acc": 60.0}
{"epoch": 17, "training_loss": 254.54016723632813, "training_acc": 45.0, "val_loss": 354.2032775878906, "val_acc": 40.0}
{"epoch": 18, "training_loss": 102.15707969665527, "training_acc": 55.0, "val_loss": 55.13471603393555, "val_acc": 40.0}
{"epoch": 19, "training_loss": 72.64928741455078, "training_acc": 45.0, "val_loss": 16.980762481689453, "val_acc": 60.0}
{"epoch": 20, "training_loss": 189.5229293823242, "training_acc": 35.0, "val_loss": 60.3324089050293, "val_acc": 60.0}
{"epoch": 21, "training_loss": 184.2937744140625, "training_acc": 45.0, "val_loss": 312.1407165527344, "val_acc": 40.0}
{"epoch": 22, "training_loss": 274.8071594238281, "training_acc": 55.0, "val_loss": 178.03871154785156, "val_acc": 40.0}
{"epoch": 23, "training_loss": 233.32939758300782, "training_acc": 45.0, "val_loss": 184.6837158203125, "val_acc": 60.0}
{"epoch": 24, "training_loss": 162.163484954834, "training_acc": 45.0, "val_loss": 16.904016494750977, "val_acc": 40.0}
{"epoch": 25, "training_loss": 129.37659759521483, "training_acc": 55.0, "val_loss": 4.122793674468994, "val_acc": 60.0}
{"epoch": 26, "training_loss": 374.2682247161865, "training_acc": 35.0, "val_loss": 749.5208129882812, "val_acc": 40.0}
{"epoch": 27, "training_loss": 376.5129165649414, "training_acc": 55.0, "val_loss": 373.9795837402344, "val_acc": 60.0}
{"epoch": 28, "training_loss": 709.7836669921875, "training_acc": 45.0, "val_loss": 432.1239318847656, "val_acc": 60.0}
{"epoch": 29, "training_loss": 297.90537719726564, "training_acc": 55.0, "val_loss": 906.7673950195312, "val_acc": 40.0}
{"epoch": 30, "training_loss": 723.5184326171875, "training_acc": 55.0, "val_loss": 788.088134765625, "val_acc": 40.0}
{"epoch": 31, "training_loss": 364.38726272583006, "training_acc": 55.0, "val_loss": 149.60391235351562, "val_acc": 60.0}
{"epoch": 32, "training_loss": 175.913232421875, "training_acc": 45.0, "val_loss": 250.5680694580078, "val_acc": 40.0}
{"epoch": 33, "training_loss": 142.63515014648436, "training_acc": 55.0, "val_loss": 194.70968627929688, "val_acc": 60.0}
{"epoch": 34, "training_loss": 162.29608154296875, "training_acc": 55.0, "val_loss": 596.0465698242188, "val_acc": 40.0}
{"epoch": 35, "training_loss": 417.3737548828125, "training_acc": 55.0, "val_loss": 80.87117767333984, "val_acc": 60.0}
{"epoch": 36, "training_loss": 117.1985092163086, "training_acc": 55.0, "val_loss": 118.429931640625, "val_acc": 40.0}
{"epoch": 37, "training_loss": 88.46270446777343, "training_acc": 55.0, "val_loss": 262.39556884765625, "val_acc": 60.0}
{"epoch": 38, "training_loss": 321.06544189453126, "training_acc": 35.0, "val_loss": 516.205078125, "val_acc": 40.0}
{"epoch": 39, "training_loss": 292.3689758300781, "training_acc": 55.0, "val_loss": 285.2790222167969, "val_acc": 60.0}
{"epoch": 40, "training_loss": 432.9355834960937, "training_acc": 45.0, "val_loss": 84.20516204833984, "val_acc": 60.0}
{"epoch": 41, "training_loss": 237.86635131835936, "training_acc": 55.0, "val_loss": 907.6296997070312, "val_acc": 40.0}
{"epoch": 42, "training_loss": 616.706640625, "training_acc": 55.0, "val_loss": 140.2913055419922, "val_acc": 40.0}
{"epoch": 43, "training_loss": 582.9121643066406, "training_acc": 35.0, "val_loss": 574.9076538085938, "val_acc": 60.0}
{"epoch": 44, "training_loss": 707.0536376953125, "training_acc": 25.0, "val_loss": 527.6680297851562, "val_acc": 40.0}
