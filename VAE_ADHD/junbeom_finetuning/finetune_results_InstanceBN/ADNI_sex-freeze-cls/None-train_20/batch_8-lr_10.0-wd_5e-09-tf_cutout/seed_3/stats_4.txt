"main_modify.py --pretrained_path None --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 3 --task ADNI_sex --input_option yAware --learning_rate 1e1 --batch_size 8 --weight_decay 5e-9 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 989.0480595111846, "training_acc": 55.0, "val_loss": 917.0143432617188, "val_acc": 60.0}
{"epoch": 1, "training_loss": 1266.0872375488282, "training_acc": 45.0, "val_loss": 158.6015625, "val_acc": 60.0}
{"epoch": 2, "training_loss": 730.7676025390625, "training_acc": 45.0, "val_loss": 1494.6199951171875, "val_acc": 40.0}
{"epoch": 3, "training_loss": 820.6260375976562, "training_acc": 55.0, "val_loss": 339.2007141113281, "val_acc": 60.0}
{"epoch": 4, "training_loss": 740.0768737792969, "training_acc": 45.0, "val_loss": 461.3561706542969, "val_acc": 60.0}
{"epoch": 5, "training_loss": 583.9281616210938, "training_acc": 25.0, "val_loss": 967.0988159179688, "val_acc": 40.0}
{"epoch": 6, "training_loss": 731.971826171875, "training_acc": 55.0, "val_loss": 327.8907165527344, "val_acc": 40.0}
{"epoch": 7, "training_loss": 347.0178466796875, "training_acc": 55.0, "val_loss": 609.4805908203125, "val_acc": 60.0}
{"epoch": 8, "training_loss": 667.9899658203125, "training_acc": 45.0, "val_loss": 322.3510437011719, "val_acc": 40.0}
{"epoch": 9, "training_loss": 469.8869140625, "training_acc": 55.0, "val_loss": 641.6441650390625, "val_acc": 40.0}
{"epoch": 10, "training_loss": 387.4585327148437, "training_acc": 45.0, "val_loss": 414.3326110839844, "val_acc": 60.0}
{"epoch": 11, "training_loss": 465.7258666992187, "training_acc": 45.0, "val_loss": 299.5330505371094, "val_acc": 40.0}
{"epoch": 12, "training_loss": 380.40721435546874, "training_acc": 55.0, "val_loss": 719.947021484375, "val_acc": 40.0}
{"epoch": 13, "training_loss": 450.1358245849609, "training_acc": 35.0, "val_loss": 40.98756790161133, "val_acc": 60.0}
{"epoch": 14, "training_loss": 46.07065200805664, "training_acc": 65.0, "val_loss": 36.61560821533203, "val_acc": 60.0}
{"epoch": 15, "training_loss": 107.85775756835938, "training_acc": 35.0, "val_loss": 148.4402313232422, "val_acc": 60.0}
{"epoch": 16, "training_loss": 215.33099212646485, "training_acc": 35.0, "val_loss": 28.245487213134766, "val_acc": 60.0}
{"epoch": 17, "training_loss": 56.03624420166015, "training_acc": 55.0, "val_loss": 97.31957244873047, "val_acc": 60.0}
{"epoch": 18, "training_loss": 123.86777954101562, "training_acc": 45.0, "val_loss": 324.0556640625, "val_acc": 40.0}
{"epoch": 19, "training_loss": 171.5441131591797, "training_acc": 55.0, "val_loss": 101.83412170410156, "val_acc": 60.0}
{"epoch": 20, "training_loss": 109.77816619873047, "training_acc": 45.0, "val_loss": 127.2693862915039, "val_acc": 60.0}
{"epoch": 21, "training_loss": 180.8174072265625, "training_acc": 35.0, "val_loss": 26.56854248046875, "val_acc": 40.0}
{"epoch": 22, "training_loss": 105.3498550415039, "training_acc": 55.0, "val_loss": 27.24824333190918, "val_acc": 40.0}
{"epoch": 23, "training_loss": 61.84018821716309, "training_acc": 55.0, "val_loss": 111.24016571044922, "val_acc": 60.0}
{"epoch": 24, "training_loss": 88.79708251953124, "training_acc": 55.0, "val_loss": 57.873931884765625, "val_acc": 60.0}
{"epoch": 25, "training_loss": 61.28838882446289, "training_acc": 45.0, "val_loss": 8.711335182189941, "val_acc": 40.0}
{"epoch": 26, "training_loss": 67.63737277984619, "training_acc": 45.0, "val_loss": 21.5788516998291, "val_acc": 40.0}
{"epoch": 27, "training_loss": 56.3794225692749, "training_acc": 75.0, "val_loss": 28.19849967956543, "val_acc": 60.0}
{"epoch": 28, "training_loss": 226.0832305908203, "training_acc": 35.0, "val_loss": 259.3548583984375, "val_acc": 40.0}
{"epoch": 29, "training_loss": 123.48228454589844, "training_acc": 45.0, "val_loss": 156.13548278808594, "val_acc": 40.0}
{"epoch": 30, "training_loss": 129.82763214111327, "training_acc": 55.0, "val_loss": 258.3819580078125, "val_acc": 60.0}
{"epoch": 31, "training_loss": 454.6138427734375, "training_acc": 45.0, "val_loss": 104.44502258300781, "val_acc": 60.0}
{"epoch": 32, "training_loss": 204.04461059570312, "training_acc": 55.0, "val_loss": 719.1967163085938, "val_acc": 40.0}
{"epoch": 33, "training_loss": 449.9249328613281, "training_acc": 55.0, "val_loss": 77.12996673583984, "val_acc": 60.0}
{"epoch": 34, "training_loss": 140.93002624511718, "training_acc": 45.0, "val_loss": 246.2917938232422, "val_acc": 40.0}
{"epoch": 35, "training_loss": 204.55478515625, "training_acc": 55.0, "val_loss": 61.02326202392578, "val_acc": 60.0}
{"epoch": 36, "training_loss": 99.42524719238281, "training_acc": 45.0, "val_loss": 225.300048828125, "val_acc": 40.0}
{"epoch": 37, "training_loss": 122.5843276977539, "training_acc": 35.0, "val_loss": 41.305809020996094, "val_acc": 60.0}
{"epoch": 38, "training_loss": 36.29304161071777, "training_acc": 55.0, "val_loss": 142.84202575683594, "val_acc": 40.0}
{"epoch": 39, "training_loss": 88.34125318527222, "training_acc": 50.0, "val_loss": 76.05110931396484, "val_acc": 60.0}
{"epoch": 40, "training_loss": 238.667529296875, "training_acc": 35.0, "val_loss": 208.9600067138672, "val_acc": 40.0}
{"epoch": 41, "training_loss": 134.34829406738282, "training_acc": 55.0, "val_loss": 16.56956672668457, "val_acc": 40.0}
{"epoch": 42, "training_loss": 28.751258659362794, "training_acc": 55.0, "val_loss": 34.1159782409668, "val_acc": 60.0}
{"epoch": 43, "training_loss": 184.14289245605468, "training_acc": 45.0, "val_loss": 295.41082763671875, "val_acc": 40.0}
{"epoch": 44, "training_loss": 149.9964813232422, "training_acc": 55.0, "val_loss": 354.7736511230469, "val_acc": 60.0}
