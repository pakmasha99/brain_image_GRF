"main_modify.py --pretrained_path None --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 3 --task ADNI_sex --input_option yAware --learning_rate 1e1 --batch_size 8 --weight_decay 5e-9 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 1212.1440045118331, "training_acc": 50.0, "val_loss": 1261.4930419921875, "val_acc": 40.0}
{"epoch": 1, "training_loss": 1812.3405517578126, "training_acc": 50.0, "val_loss": 1564.2557373046875, "val_acc": 40.0}
{"epoch": 2, "training_loss": 789.2688110351562, "training_acc": 60.0, "val_loss": 1072.5604248046875, "val_acc": 60.0}
{"epoch": 3, "training_loss": 1467.9302856445313, "training_acc": 50.0, "val_loss": 844.2732543945312, "val_acc": 60.0}
{"epoch": 4, "training_loss": 638.1539733886718, "training_acc": 50.0, "val_loss": 820.0234375, "val_acc": 40.0}
{"epoch": 5, "training_loss": 704.1043701171875, "training_acc": 50.0, "val_loss": 215.3736572265625, "val_acc": 40.0}
{"epoch": 6, "training_loss": 285.40159606933594, "training_acc": 70.0, "val_loss": 550.0348510742188, "val_acc": 60.0}
{"epoch": 7, "training_loss": 404.63485565185545, "training_acc": 50.0, "val_loss": 840.83349609375, "val_acc": 40.0}
{"epoch": 8, "training_loss": 1013.5080078125, "training_acc": 50.0, "val_loss": 1392.3778076171875, "val_acc": 40.0}
{"epoch": 9, "training_loss": 837.3835083007813, "training_acc": 50.0, "val_loss": 421.3052673339844, "val_acc": 60.0}
{"epoch": 10, "training_loss": 893.0355590820312, "training_acc": 50.0, "val_loss": 854.6990356445312, "val_acc": 60.0}
{"epoch": 11, "training_loss": 801.2370788574219, "training_acc": 50.0, "val_loss": 481.4452819824219, "val_acc": 40.0}
{"epoch": 12, "training_loss": 622.4262268066407, "training_acc": 50.0, "val_loss": 914.0880126953125, "val_acc": 40.0}
{"epoch": 13, "training_loss": 553.2725826263428, "training_acc": 40.0, "val_loss": 118.2872543334961, "val_acc": 60.0}
{"epoch": 14, "training_loss": 221.81146736145018, "training_acc": 30.0, "val_loss": 334.4071350097656, "val_acc": 40.0}
{"epoch": 15, "training_loss": 187.09422454833984, "training_acc": 50.0, "val_loss": 493.4176940917969, "val_acc": 60.0}
{"epoch": 16, "training_loss": 594.7302734375, "training_acc": 50.0, "val_loss": 23.470230102539062, "val_acc": 60.0}
{"epoch": 17, "training_loss": 429.57849578857423, "training_acc": 50.0, "val_loss": 1248.197509765625, "val_acc": 40.0}
{"epoch": 18, "training_loss": 975.2335693359375, "training_acc": 50.0, "val_loss": 313.8631286621094, "val_acc": 40.0}
{"epoch": 19, "training_loss": 312.216845703125, "training_acc": 60.0, "val_loss": 658.2789916992188, "val_acc": 60.0}
{"epoch": 20, "training_loss": 731.3434326171875, "training_acc": 50.0, "val_loss": 31.786767959594727, "val_acc": 60.0}
{"epoch": 21, "training_loss": 331.5379974365234, "training_acc": 60.0, "val_loss": 1372.7679443359375, "val_acc": 40.0}
{"epoch": 22, "training_loss": 1069.3288452148438, "training_acc": 50.0, "val_loss": 533.7936401367188, "val_acc": 40.0}
{"epoch": 23, "training_loss": 163.69809112548828, "training_acc": 60.0, "val_loss": 827.9271850585938, "val_acc": 60.0}
{"epoch": 24, "training_loss": 1108.1549682617188, "training_acc": 50.0, "val_loss": 762.0546875, "val_acc": 60.0}
{"epoch": 25, "training_loss": 648.0347915649414, "training_acc": 50.0, "val_loss": 786.011474609375, "val_acc": 40.0}
{"epoch": 26, "training_loss": 857.9172119140625, "training_acc": 50.0, "val_loss": 1323.6715087890625, "val_acc": 40.0}
{"epoch": 27, "training_loss": 858.4748291015625, "training_acc": 50.0, "val_loss": 138.12088012695312, "val_acc": 60.0}
{"epoch": 28, "training_loss": 238.9129180908203, "training_acc": 50.0, "val_loss": 304.9956970214844, "val_acc": 60.0}
{"epoch": 29, "training_loss": 217.12103729248048, "training_acc": 60.0, "val_loss": 575.7954711914062, "val_acc": 40.0}
{"epoch": 30, "training_loss": 466.1705688476562, "training_acc": 50.0, "val_loss": 57.23895263671875, "val_acc": 60.0}
{"epoch": 31, "training_loss": 324.01951293945314, "training_acc": 50.0, "val_loss": 73.4850082397461, "val_acc": 60.0}
{"epoch": 32, "training_loss": 209.22915344238282, "training_acc": 60.0, "val_loss": 671.4515991210938, "val_acc": 40.0}
{"epoch": 33, "training_loss": 365.6708557128906, "training_acc": 50.0, "val_loss": 385.1289978027344, "val_acc": 60.0}
{"epoch": 34, "training_loss": 757.8708129882813, "training_acc": 50.0, "val_loss": 621.5493774414062, "val_acc": 60.0}
{"epoch": 35, "training_loss": 568.0207702636719, "training_acc": 40.0, "val_loss": 377.0375671386719, "val_acc": 40.0}
