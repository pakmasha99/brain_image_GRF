"main_modify.py --pretrained_path None --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_sex --input_option yAware --learning_rate 1e2 --batch_size 8 --weight_decay 1e-2 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 12517.461201810836, "training_acc": 45.0, "val_loss": 12691.6484375, "val_acc": 40.0}
{"epoch": 1, "training_loss": 12469.584375, "training_acc": 55.0, "val_loss": 11483.3662109375, "val_acc": 40.0}
{"epoch": 2, "training_loss": 5765.594775390625, "training_acc": 45.0, "val_loss": 9770.255859375, "val_acc": 60.0}
{"epoch": 3, "training_loss": 13336.95703125, "training_acc": 45.0, "val_loss": 3395.067138671875, "val_acc": 60.0}
{"epoch": 4, "training_loss": 3421.438720703125, "training_acc": 45.0, "val_loss": 9010.72265625, "val_acc": 40.0}
{"epoch": 5, "training_loss": 6300.96328125, "training_acc": 55.0, "val_loss": 2017.392578125, "val_acc": 40.0}
{"epoch": 6, "training_loss": 2782.960107421875, "training_acc": 45.0, "val_loss": 4604.39208984375, "val_acc": 60.0}
{"epoch": 7, "training_loss": 4818.695703125, "training_acc": 45.0, "val_loss": 2101.06689453125, "val_acc": 40.0}
{"epoch": 8, "training_loss": 2281.573486328125, "training_acc": 55.0, "val_loss": 4955.0751953125, "val_acc": 40.0}
{"epoch": 9, "training_loss": 2279.16181640625, "training_acc": 55.0, "val_loss": 1792.6484375, "val_acc": 60.0}
{"epoch": 10, "training_loss": 2416.12919921875, "training_acc": 45.0, "val_loss": 1118.7362060546875, "val_acc": 40.0}
{"epoch": 11, "training_loss": 1362.8963623046875, "training_acc": 55.0, "val_loss": 529.9567260742188, "val_acc": 40.0}
{"epoch": 12, "training_loss": 906.4598022460938, "training_acc": 65.0, "val_loss": 1449.5916748046875, "val_acc": 60.0}
{"epoch": 13, "training_loss": 1598.220703125, "training_acc": 35.0, "val_loss": 3710.13720703125, "val_acc": 40.0}
{"epoch": 14, "training_loss": 1986.549853515625, "training_acc": 55.0, "val_loss": 1875.2059326171875, "val_acc": 60.0}
{"epoch": 15, "training_loss": 2901.88291015625, "training_acc": 45.0, "val_loss": 135.1241912841797, "val_acc": 60.0}
{"epoch": 16, "training_loss": 1183.0863067626954, "training_acc": 65.0, "val_loss": 4282.48193359375, "val_acc": 40.0}
{"epoch": 17, "training_loss": 2499.767822265625, "training_acc": 45.0, "val_loss": 1824.1129150390625, "val_acc": 60.0}
{"epoch": 18, "training_loss": 2141.847607421875, "training_acc": 35.0, "val_loss": 1466.4603271484375, "val_acc": 40.0}
{"epoch": 19, "training_loss": 626.0602172851562, "training_acc": 65.0, "val_loss": 1268.173828125, "val_acc": 60.0}
{"epoch": 20, "training_loss": 1592.550537109375, "training_acc": 35.0, "val_loss": 2040.6317138671875, "val_acc": 40.0}
{"epoch": 21, "training_loss": 1814.2481323242187, "training_acc": 35.0, "val_loss": 1484.058837890625, "val_acc": 60.0}
{"epoch": 22, "training_loss": 1311.572088623047, "training_acc": 45.0, "val_loss": 323.1486511230469, "val_acc": 40.0}
{"epoch": 23, "training_loss": 1595.2063232421874, "training_acc": 35.0, "val_loss": 343.27105712890625, "val_acc": 60.0}
{"epoch": 24, "training_loss": 1545.473095703125, "training_acc": 45.0, "val_loss": 1967.632080078125, "val_acc": 40.0}
{"epoch": 25, "training_loss": 1199.0371826171875, "training_acc": 45.0, "val_loss": 544.9456176757812, "val_acc": 60.0}
{"epoch": 26, "training_loss": 575.7757934570312, "training_acc": 65.0, "val_loss": 387.0971374511719, "val_acc": 40.0}
{"epoch": 27, "training_loss": 1482.21103515625, "training_acc": 45.0, "val_loss": 4.748789310455322, "val_acc": 60.0}
{"epoch": 28, "training_loss": 750.0386322021484, "training_acc": 75.0, "val_loss": 3945.897216796875, "val_acc": 40.0}
{"epoch": 29, "training_loss": 2205.562646484375, "training_acc": 55.0, "val_loss": 2177.928466796875, "val_acc": 60.0}
{"epoch": 30, "training_loss": 2683.292529296875, "training_acc": 35.0, "val_loss": 2220.788818359375, "val_acc": 40.0}
{"epoch": 31, "training_loss": 725.0566162109375, "training_acc": 75.0, "val_loss": 1710.0321044921875, "val_acc": 60.0}
{"epoch": 32, "training_loss": 1802.0294311523437, "training_acc": 45.0, "val_loss": 1577.7169189453125, "val_acc": 40.0}
{"epoch": 33, "training_loss": 1169.98369140625, "training_acc": 45.0, "val_loss": 914.3912963867188, "val_acc": 60.0}
{"epoch": 34, "training_loss": 969.489599609375, "training_acc": 55.0, "val_loss": 38.569068908691406, "val_acc": 40.0}
{"epoch": 35, "training_loss": 935.5086345672607, "training_acc": 65.0, "val_loss": 502.3851013183594, "val_acc": 60.0}
{"epoch": 36, "training_loss": 2001.8082275390625, "training_acc": 45.0, "val_loss": 2175.286865234375, "val_acc": 40.0}
{"epoch": 37, "training_loss": 1517.8107421875, "training_acc": 55.0, "val_loss": 965.8666381835938, "val_acc": 60.0}
{"epoch": 38, "training_loss": 978.8466186523438, "training_acc": 65.0, "val_loss": 1694.4697265625, "val_acc": 40.0}
{"epoch": 39, "training_loss": 713.5339660644531, "training_acc": 55.0, "val_loss": 92.43335723876953, "val_acc": 40.0}
{"epoch": 40, "training_loss": 772.2824462890625, "training_acc": 25.0, "val_loss": 3055.223388671875, "val_acc": 40.0}
{"epoch": 41, "training_loss": 2187.377490234375, "training_acc": 55.0, "val_loss": 711.7907104492188, "val_acc": 60.0}
{"epoch": 42, "training_loss": 1388.4970947265624, "training_acc": 45.0, "val_loss": 2164.0673828125, "val_acc": 40.0}
{"epoch": 43, "training_loss": 1888.6978515625, "training_acc": 55.0, "val_loss": 580.6654052734375, "val_acc": 60.0}
{"epoch": 44, "training_loss": 1749.008544921875, "training_acc": 45.0, "val_loss": 1723.6390380859375, "val_acc": 40.0}
{"epoch": 45, "training_loss": 1795.436328125, "training_acc": 55.0, "val_loss": 213.5835723876953, "val_acc": 60.0}
{"epoch": 46, "training_loss": 756.5449462890625, "training_acc": 35.0, "val_loss": 1227.0921630859375, "val_acc": 40.0}
