"main_modify.py --pretrained_path None --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_sex --input_option yAware --learning_rate 1e2 --batch_size 8 --weight_decay 1e-2 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 12810.117268157006, "training_acc": 30.0, "val_loss": 7312.20849609375, "val_acc": 60.0}
{"epoch": 1, "training_loss": 12178.529296875, "training_acc": 50.0, "val_loss": 7145.05810546875, "val_acc": 60.0}
{"epoch": 2, "training_loss": 6172.77451171875, "training_acc": 50.0, "val_loss": 14089.2646484375, "val_acc": 40.0}
{"epoch": 3, "training_loss": 11328.6515625, "training_acc": 50.0, "val_loss": 4649.0205078125, "val_acc": 40.0}
{"epoch": 4, "training_loss": 2635.758740234375, "training_acc": 60.0, "val_loss": 6686.5, "val_acc": 60.0}
{"epoch": 5, "training_loss": 7531.2572265625, "training_acc": 50.0, "val_loss": 843.5185546875, "val_acc": 60.0}
{"epoch": 6, "training_loss": 2989.9146484375, "training_acc": 60.0, "val_loss": 8292.2353515625, "val_acc": 40.0}
{"epoch": 7, "training_loss": 5887.983239746094, "training_acc": 50.0, "val_loss": 1882.4222412109375, "val_acc": 60.0}
{"epoch": 8, "training_loss": 3729.85205078125, "training_acc": 50.0, "val_loss": 2544.039794921875, "val_acc": 60.0}
{"epoch": 9, "training_loss": 3144.782849121094, "training_acc": 30.0, "val_loss": 5939.44873046875, "val_acc": 40.0}
{"epoch": 10, "training_loss": 4293.86328125, "training_acc": 50.0, "val_loss": 896.7706909179688, "val_acc": 60.0}
{"epoch": 11, "training_loss": 1612.8257080078124, "training_acc": 50.0, "val_loss": 1229.1519775390625, "val_acc": 60.0}
{"epoch": 12, "training_loss": 1321.1388671875, "training_acc": 40.0, "val_loss": 1030.5218505859375, "val_acc": 40.0}
{"epoch": 13, "training_loss": 710.5071716308594, "training_acc": 50.0, "val_loss": 165.68789672851562, "val_acc": 60.0}
{"epoch": 14, "training_loss": 810.2145812988281, "training_acc": 50.0, "val_loss": 263.4725036621094, "val_acc": 40.0}
{"epoch": 15, "training_loss": 1138.4934936523437, "training_acc": 50.0, "val_loss": 1045.4190673828125, "val_acc": 60.0}
{"epoch": 16, "training_loss": 848.7114074707031, "training_acc": 50.0, "val_loss": 590.8665771484375, "val_acc": 40.0}
{"epoch": 17, "training_loss": 459.1826904296875, "training_acc": 60.0, "val_loss": 136.23814392089844, "val_acc": 40.0}
{"epoch": 18, "training_loss": 160.45294952392578, "training_acc": 60.0, "val_loss": 19.5263614654541, "val_acc": 40.0}
{"epoch": 19, "training_loss": 1292.4405044555665, "training_acc": 40.0, "val_loss": 150.4066619873047, "val_acc": 60.0}
{"epoch": 20, "training_loss": 1227.0855773925782, "training_acc": 60.0, "val_loss": 2743.09423828125, "val_acc": 40.0}
{"epoch": 21, "training_loss": 1227.7333740234376, "training_acc": 60.0, "val_loss": 3061.133544921875, "val_acc": 60.0}
{"epoch": 22, "training_loss": 2891.1585021972655, "training_acc": 50.0, "val_loss": 3342.280517578125, "val_acc": 40.0}
{"epoch": 23, "training_loss": 3114.59423828125, "training_acc": 50.0, "val_loss": 495.8480529785156, "val_acc": 40.0}
{"epoch": 24, "training_loss": 2465.07392578125, "training_acc": 40.0, "val_loss": 2276.624267578125, "val_acc": 60.0}
{"epoch": 25, "training_loss": 1308.3695190429687, "training_acc": 60.0, "val_loss": 5770.29296875, "val_acc": 40.0}
{"epoch": 26, "training_loss": 4160.78544921875, "training_acc": 50.0, "val_loss": 1719.3558349609375, "val_acc": 60.0}
{"epoch": 27, "training_loss": 2949.030859375, "training_acc": 50.0, "val_loss": 574.1630249023438, "val_acc": 60.0}
{"epoch": 28, "training_loss": 1423.3271484375, "training_acc": 60.0, "val_loss": 3922.477294921875, "val_acc": 40.0}
{"epoch": 29, "training_loss": 2211.768896484375, "training_acc": 50.0, "val_loss": 2488.166748046875, "val_acc": 60.0}
{"epoch": 30, "training_loss": 2509.9120849609376, "training_acc": 40.0, "val_loss": 997.7719116210938, "val_acc": 40.0}
{"epoch": 31, "training_loss": 423.874462890625, "training_acc": 70.0, "val_loss": 1532.599853515625, "val_acc": 60.0}
{"epoch": 32, "training_loss": 1717.63154296875, "training_acc": 40.0, "val_loss": 1368.6263427734375, "val_acc": 40.0}
{"epoch": 33, "training_loss": 1057.4694580078126, "training_acc": 40.0, "val_loss": 994.2396850585938, "val_acc": 40.0}
{"epoch": 34, "training_loss": 779.7385131835938, "training_acc": 50.0, "val_loss": 136.1886749267578, "val_acc": 60.0}
{"epoch": 35, "training_loss": 673.9551452636719, "training_acc": 50.0, "val_loss": 567.8622436523438, "val_acc": 60.0}
{"epoch": 36, "training_loss": 1211.7423828125, "training_acc": 30.0, "val_loss": 868.0974731445312, "val_acc": 40.0}
{"epoch": 37, "training_loss": 1218.80361328125, "training_acc": 50.0, "val_loss": 421.4173889160156, "val_acc": 60.0}
