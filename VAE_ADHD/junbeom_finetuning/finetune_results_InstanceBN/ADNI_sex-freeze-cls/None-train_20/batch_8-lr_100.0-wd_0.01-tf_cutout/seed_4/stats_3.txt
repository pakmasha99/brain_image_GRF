"main_modify.py --pretrained_path None --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 4 --task ADNI_sex --input_option yAware --learning_rate 1e2 --batch_size 8 --weight_decay 1e-2 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 9883.024063968658, "training_acc": 45.0, "val_loss": 7597.1376953125, "val_acc": 60.0}
{"epoch": 1, "training_loss": 13315.83359375, "training_acc": 45.0, "val_loss": 5395.99462890625, "val_acc": 60.0}
{"epoch": 2, "training_loss": 6415.025927734375, "training_acc": 45.0, "val_loss": 12185.26953125, "val_acc": 40.0}
{"epoch": 3, "training_loss": 7996.9908203125, "training_acc": 55.0, "val_loss": 198.8302764892578, "val_acc": 60.0}
{"epoch": 4, "training_loss": 2481.647497558594, "training_acc": 45.0, "val_loss": 3289.291015625, "val_acc": 60.0}
{"epoch": 5, "training_loss": 2380.854040527344, "training_acc": 55.0, "val_loss": 4461.63623046875, "val_acc": 40.0}
{"epoch": 6, "training_loss": 3547.011572265625, "training_acc": 55.0, "val_loss": 900.0289306640625, "val_acc": 40.0}
{"epoch": 7, "training_loss": 1955.1182373046875, "training_acc": 55.0, "val_loss": 2796.33203125, "val_acc": 60.0}
{"epoch": 8, "training_loss": 2505.9548828125, "training_acc": 45.0, "val_loss": 3940.73291015625, "val_acc": 40.0}
{"epoch": 9, "training_loss": 2739.8144775390624, "training_acc": 55.0, "val_loss": 616.0247192382812, "val_acc": 60.0}
{"epoch": 10, "training_loss": 1672.9378662109375, "training_acc": 45.0, "val_loss": 754.9404907226562, "val_acc": 40.0}
{"epoch": 11, "training_loss": 787.7357299804687, "training_acc": 55.0, "val_loss": 579.39453125, "val_acc": 60.0}
{"epoch": 12, "training_loss": 736.8680419921875, "training_acc": 45.0, "val_loss": 417.11016845703125, "val_acc": 40.0}
{"epoch": 13, "training_loss": 355.8553161621094, "training_acc": 55.0, "val_loss": 1406.1827392578125, "val_acc": 40.0}
{"epoch": 14, "training_loss": 1362.81708984375, "training_acc": 55.0, "val_loss": 1450.9725341796875, "val_acc": 60.0}
{"epoch": 15, "training_loss": 2171.735546875, "training_acc": 45.0, "val_loss": 1713.2220458984375, "val_acc": 40.0}
{"epoch": 16, "training_loss": 2065.808203125, "training_acc": 55.0, "val_loss": 1037.8857421875, "val_acc": 40.0}
{"epoch": 17, "training_loss": 1751.59921875, "training_acc": 55.0, "val_loss": 1925.0101318359375, "val_acc": 60.0}
{"epoch": 18, "training_loss": 1820.1039428710938, "training_acc": 45.0, "val_loss": 1361.8275146484375, "val_acc": 40.0}
{"epoch": 19, "training_loss": 449.2937316894531, "training_acc": 65.0, "val_loss": 276.11224365234375, "val_acc": 40.0}
{"epoch": 20, "training_loss": 441.61180419921874, "training_acc": 55.0, "val_loss": 572.3197631835938, "val_acc": 60.0}
{"epoch": 21, "training_loss": 402.1522583007812, "training_acc": 65.0, "val_loss": 72.61505126953125, "val_acc": 60.0}
{"epoch": 22, "training_loss": 457.224112701416, "training_acc": 35.0, "val_loss": 1139.6163330078125, "val_acc": 40.0}
{"epoch": 23, "training_loss": 713.0497436523438, "training_acc": 55.0, "val_loss": 711.3016967773438, "val_acc": 60.0}
{"epoch": 24, "training_loss": 1151.4935546875, "training_acc": 45.0, "val_loss": 198.79055786132812, "val_acc": 60.0}
{"epoch": 25, "training_loss": 266.35869140625, "training_acc": 55.0, "val_loss": 1003.5369262695312, "val_acc": 40.0}
{"epoch": 26, "training_loss": 661.6452392578125, "training_acc": 35.0, "val_loss": 844.9454956054688, "val_acc": 60.0}
{"epoch": 27, "training_loss": 1231.176708984375, "training_acc": 35.0, "val_loss": 871.2449340820312, "val_acc": 40.0}
{"epoch": 28, "training_loss": 1144.4703125, "training_acc": 45.0, "val_loss": 848.4119262695312, "val_acc": 40.0}
{"epoch": 29, "training_loss": 739.371117401123, "training_acc": 45.0, "val_loss": 939.4910278320312, "val_acc": 40.0}
{"epoch": 30, "training_loss": 447.9042007446289, "training_acc": 65.0, "val_loss": 1131.7791748046875, "val_acc": 60.0}
{"epoch": 31, "training_loss": 925.2991363525391, "training_acc": 25.0, "val_loss": 2545.978515625, "val_acc": 40.0}
{"epoch": 32, "training_loss": 1788.3698486328126, "training_acc": 55.0, "val_loss": 1646.1859130859375, "val_acc": 60.0}
{"epoch": 33, "training_loss": 2546.3166748046874, "training_acc": 45.0, "val_loss": 1395.255859375, "val_acc": 40.0}
{"epoch": 34, "training_loss": 1417.117578125, "training_acc": 55.0, "val_loss": 590.7213745117188, "val_acc": 60.0}
{"epoch": 35, "training_loss": 974.1059295654297, "training_acc": 45.0, "val_loss": 127.4491195678711, "val_acc": 40.0}
{"epoch": 36, "training_loss": 1171.3990844726563, "training_acc": 35.0, "val_loss": 2183.25, "val_acc": 40.0}
{"epoch": 37, "training_loss": 3061.982043457031, "training_acc": 55.0, "val_loss": 278.73211669921875, "val_acc": 60.0}
{"epoch": 38, "training_loss": 760.0853271484375, "training_acc": 35.0, "val_loss": 486.224609375, "val_acc": 60.0}
{"epoch": 39, "training_loss": 323.00548095703124, "training_acc": 55.0, "val_loss": 928.3959350585938, "val_acc": 40.0}
{"epoch": 40, "training_loss": 664.6138854980469, "training_acc": 35.0, "val_loss": 597.9762573242188, "val_acc": 40.0}
