"main_modify.py --pretrained_path None --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 2 --task ADNI_sex --input_option yAware --learning_rate 1e2 --batch_size 8 --weight_decay 1e-2 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 11289.90691139698, "training_acc": 50.0, "val_loss": 10741.3916015625, "val_acc": 40.0}
{"epoch": 1, "training_loss": 11253.01796875, "training_acc": 50.0, "val_loss": 8026.44140625, "val_acc": 40.0}
{"epoch": 2, "training_loss": 6505.964306640625, "training_acc": 40.0, "val_loss": 7750.8955078125, "val_acc": 60.0}
{"epoch": 3, "training_loss": 8354.990966796875, "training_acc": 50.0, "val_loss": 1013.39892578125, "val_acc": 40.0}
{"epoch": 4, "training_loss": 2162.328173828125, "training_acc": 50.0, "val_loss": 5680.640625, "val_acc": 40.0}
{"epoch": 5, "training_loss": 3639.0412109375, "training_acc": 40.0, "val_loss": 2085.771240234375, "val_acc": 60.0}
{"epoch": 6, "training_loss": 2504.73837890625, "training_acc": 50.0, "val_loss": 1204.6541748046875, "val_acc": 40.0}
{"epoch": 7, "training_loss": 1460.179296875, "training_acc": 50.0, "val_loss": 239.74990844726562, "val_acc": 40.0}
{"epoch": 8, "training_loss": 1635.7783081054688, "training_acc": 50.0, "val_loss": 1948.1375732421875, "val_acc": 60.0}
{"epoch": 9, "training_loss": 2260.3232421875, "training_acc": 30.0, "val_loss": 4160.52294921875, "val_acc": 40.0}
{"epoch": 10, "training_loss": 2107.142041015625, "training_acc": 50.0, "val_loss": 2461.25390625, "val_acc": 60.0}
{"epoch": 11, "training_loss": 4124.783251953125, "training_acc": 50.0, "val_loss": 2037.6199951171875, "val_acc": 60.0}
{"epoch": 12, "training_loss": 1105.9833862304688, "training_acc": 60.0, "val_loss": 3064.4443359375, "val_acc": 40.0}
{"epoch": 13, "training_loss": 1760.548876953125, "training_acc": 50.0, "val_loss": 1154.6422119140625, "val_acc": 60.0}
{"epoch": 14, "training_loss": 1149.9448364257812, "training_acc": 50.0, "val_loss": 937.2474975585938, "val_acc": 40.0}
{"epoch": 15, "training_loss": 802.0405395507812, "training_acc": 30.0, "val_loss": 1756.0926513671875, "val_acc": 40.0}
{"epoch": 16, "training_loss": 1327.2105964660645, "training_acc": 50.0, "val_loss": 1314.9703369140625, "val_acc": 60.0}
{"epoch": 17, "training_loss": 1680.30732421875, "training_acc": 50.0, "val_loss": 2070.216064453125, "val_acc": 40.0}
{"epoch": 18, "training_loss": 1995.46181640625, "training_acc": 50.0, "val_loss": 572.33984375, "val_acc": 60.0}
{"epoch": 19, "training_loss": 876.3110961914062, "training_acc": 50.0, "val_loss": 1304.287109375, "val_acc": 40.0}
{"epoch": 20, "training_loss": 1026.8904174804688, "training_acc": 40.0, "val_loss": 197.259521484375, "val_acc": 40.0}
{"epoch": 21, "training_loss": 282.82163391113284, "training_acc": 50.0, "val_loss": 250.25657653808594, "val_acc": 60.0}
{"epoch": 22, "training_loss": 315.2737762451172, "training_acc": 50.0, "val_loss": 498.91778564453125, "val_acc": 40.0}
{"epoch": 23, "training_loss": 653.55146484375, "training_acc": 30.0, "val_loss": 366.017822265625, "val_acc": 60.0}
{"epoch": 24, "training_loss": 369.4961242675781, "training_acc": 60.0, "val_loss": 1662.412109375, "val_acc": 40.0}
{"epoch": 25, "training_loss": 776.2817749023437, "training_acc": 60.0, "val_loss": 1962.6744384765625, "val_acc": 60.0}
{"epoch": 26, "training_loss": 2131.5490234375, "training_acc": 40.0, "val_loss": 2035.7789306640625, "val_acc": 40.0}
{"epoch": 27, "training_loss": 1209.6291015625, "training_acc": 50.0, "val_loss": 2142.108154296875, "val_acc": 60.0}
{"epoch": 28, "training_loss": 2720.7693359375, "training_acc": 30.0, "val_loss": 2460.04833984375, "val_acc": 40.0}
{"epoch": 29, "training_loss": 2245.1984375, "training_acc": 30.0, "val_loss": 2410.045166015625, "val_acc": 60.0}
{"epoch": 30, "training_loss": 2052.5447509765627, "training_acc": 50.0, "val_loss": 4150.859375, "val_acc": 40.0}
{"epoch": 31, "training_loss": 2778.2509521484376, "training_acc": 40.0, "val_loss": 1132.376220703125, "val_acc": 60.0}
{"epoch": 32, "training_loss": 863.8375366210937, "training_acc": 60.0, "val_loss": 2274.601318359375, "val_acc": 40.0}
{"epoch": 33, "training_loss": 1126.8533203125, "training_acc": 60.0, "val_loss": 1711.995361328125, "val_acc": 60.0}
{"epoch": 34, "training_loss": 1323.4038879394532, "training_acc": 60.0, "val_loss": 1976.8363037109375, "val_acc": 40.0}
{"epoch": 35, "training_loss": 1265.7635009765625, "training_acc": 50.0, "val_loss": 1286.1544189453125, "val_acc": 60.0}
{"epoch": 36, "training_loss": 888.87021484375, "training_acc": 60.0, "val_loss": 3261.111083984375, "val_acc": 40.0}
{"epoch": 37, "training_loss": 2115.7167724609376, "training_acc": 50.0, "val_loss": 1575.3154296875, "val_acc": 60.0}
{"epoch": 38, "training_loss": 1853.389453125, "training_acc": 40.0, "val_loss": 2701.972900390625, "val_acc": 40.0}
{"epoch": 39, "training_loss": 1964.44697265625, "training_acc": 40.0, "val_loss": 2023.3182373046875, "val_acc": 60.0}
