"main_modify.py --pretrained_path None --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 1 --task ADNI_sex --input_option yAware --learning_rate 1e2 --batch_size 8 --weight_decay 1e-2 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 9136.049364471435, "training_acc": 55.0, "val_loss": 8095.92529296875, "val_acc": 60.0}
{"epoch": 1, "training_loss": 13002.34208984375, "training_acc": 45.0, "val_loss": 4312.94091796875, "val_acc": 60.0}
{"epoch": 2, "training_loss": 6331.8001953125, "training_acc": 35.0, "val_loss": 11230.8720703125, "val_acc": 40.0}
{"epoch": 3, "training_loss": 6723.36484375, "training_acc": 55.0, "val_loss": 1663.2274169921875, "val_acc": 60.0}
{"epoch": 4, "training_loss": 4117.54697265625, "training_acc": 45.0, "val_loss": 3383.86328125, "val_acc": 60.0}
{"epoch": 5, "training_loss": 2711.208154296875, "training_acc": 55.0, "val_loss": 6015.30810546875, "val_acc": 40.0}
{"epoch": 6, "training_loss": 4181.217822265625, "training_acc": 55.0, "val_loss": 528.1434936523438, "val_acc": 40.0}
{"epoch": 7, "training_loss": 3277.5765380859375, "training_acc": 45.0, "val_loss": 3318.604736328125, "val_acc": 60.0}
{"epoch": 8, "training_loss": 2260.2745361328125, "training_acc": 55.0, "val_loss": 5642.41015625, "val_acc": 40.0}
{"epoch": 9, "training_loss": 4187.419140625, "training_acc": 55.0, "val_loss": 810.6959838867188, "val_acc": 40.0}
{"epoch": 10, "training_loss": 3624.1950927734374, "training_acc": 35.0, "val_loss": 4391.6689453125, "val_acc": 60.0}
{"epoch": 11, "training_loss": 4308.684631347656, "training_acc": 45.0, "val_loss": 3490.88671875, "val_acc": 40.0}
{"epoch": 12, "training_loss": 2721.4421142578126, "training_acc": 55.0, "val_loss": 111.05547332763672, "val_acc": 40.0}
{"epoch": 13, "training_loss": 2107.2361572265627, "training_acc": 45.0, "val_loss": 1999.0584716796875, "val_acc": 60.0}
{"epoch": 14, "training_loss": 2123.232043457031, "training_acc": 35.0, "val_loss": 5585.6572265625, "val_acc": 40.0}
{"epoch": 15, "training_loss": 3414.9557861328126, "training_acc": 55.0, "val_loss": 1726.3843994140625, "val_acc": 60.0}
{"epoch": 16, "training_loss": 3175.5357421875, "training_acc": 45.0, "val_loss": 360.0011901855469, "val_acc": 60.0}
{"epoch": 17, "training_loss": 2129.22529296875, "training_acc": 45.0, "val_loss": 4558.37841796875, "val_acc": 40.0}
{"epoch": 18, "training_loss": 2147.4095703125, "training_acc": 55.0, "val_loss": 2298.404052734375, "val_acc": 60.0}
{"epoch": 19, "training_loss": 2618.021021270752, "training_acc": 45.0, "val_loss": 3049.640625, "val_acc": 40.0}
{"epoch": 20, "training_loss": 2956.687158203125, "training_acc": 55.0, "val_loss": 167.674560546875, "val_acc": 40.0}
{"epoch": 21, "training_loss": 1516.906005859375, "training_acc": 65.0, "val_loss": 2545.757568359375, "val_acc": 60.0}
{"epoch": 22, "training_loss": 3054.047412109375, "training_acc": 35.0, "val_loss": 5144.17529296875, "val_acc": 40.0}
{"epoch": 23, "training_loss": 2849.5648986816404, "training_acc": 55.0, "val_loss": 2544.282958984375, "val_acc": 60.0}
{"epoch": 24, "training_loss": 3877.0487548828123, "training_acc": 45.0, "val_loss": 46.64346694946289, "val_acc": 60.0}
{"epoch": 25, "training_loss": 2180.821290588379, "training_acc": 55.0, "val_loss": 4453.52197265625, "val_acc": 40.0}
{"epoch": 26, "training_loss": 1448.1600341796875, "training_acc": 65.0, "val_loss": 3796.052490234375, "val_acc": 60.0}
{"epoch": 27, "training_loss": 4674.135400390625, "training_acc": 45.0, "val_loss": 2573.994384765625, "val_acc": 40.0}
{"epoch": 28, "training_loss": 3586.784765625, "training_acc": 55.0, "val_loss": 3704.39453125, "val_acc": 40.0}
{"epoch": 29, "training_loss": 2586.191845703125, "training_acc": 35.0, "val_loss": 1483.033203125, "val_acc": 60.0}
{"epoch": 30, "training_loss": 1581.942431640625, "training_acc": 45.0, "val_loss": 829.6492309570312, "val_acc": 40.0}
{"epoch": 31, "training_loss": 990.7925048828125, "training_acc": 55.0, "val_loss": 243.84548950195312, "val_acc": 60.0}
{"epoch": 32, "training_loss": 824.4328002929688, "training_acc": 65.0, "val_loss": 1934.90625, "val_acc": 40.0}
{"epoch": 33, "training_loss": 1582.0851318359375, "training_acc": 35.0, "val_loss": 275.0373840332031, "val_acc": 40.0}
{"epoch": 34, "training_loss": 560.2158325195312, "training_acc": 45.0, "val_loss": 384.00982666015625, "val_acc": 40.0}
{"epoch": 35, "training_loss": 221.88366241455077, "training_acc": 65.0, "val_loss": 938.8297119140625, "val_acc": 60.0}
{"epoch": 36, "training_loss": 596.0238220214844, "training_acc": 55.0, "val_loss": 479.3403015136719, "val_acc": 60.0}
{"epoch": 37, "training_loss": 690.0366577148437, "training_acc": 55.0, "val_loss": 2138.944580078125, "val_acc": 40.0}
{"epoch": 38, "training_loss": 1187.40166015625, "training_acc": 55.0, "val_loss": 1127.5673828125, "val_acc": 60.0}
{"epoch": 39, "training_loss": 806.3007400512695, "training_acc": 45.0, "val_loss": 492.6728515625, "val_acc": 60.0}
{"epoch": 40, "training_loss": 430.2046783447266, "training_acc": 45.0, "val_loss": 1120.5455322265625, "val_acc": 40.0}
{"epoch": 41, "training_loss": 774.8828491210937, "training_acc": 55.0, "val_loss": 2214.4287109375, "val_acc": 60.0}
{"epoch": 42, "training_loss": 3684.30966796875, "training_acc": 45.0, "val_loss": 2009.0765380859375, "val_acc": 40.0}
{"epoch": 43, "training_loss": 2433.1869140625, "training_acc": 55.0, "val_loss": 1603.0335693359375, "val_acc": 40.0}
