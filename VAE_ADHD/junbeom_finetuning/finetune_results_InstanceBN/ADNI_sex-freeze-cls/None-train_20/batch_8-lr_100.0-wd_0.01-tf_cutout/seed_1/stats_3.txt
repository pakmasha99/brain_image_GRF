"main_modify.py --pretrained_path None --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 1 --task ADNI_sex --input_option yAware --learning_rate 1e2 --batch_size 8 --weight_decay 1e-2 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 10384.99835524559, "training_acc": 50.0, "val_loss": 12964.5576171875, "val_acc": 40.0}
{"epoch": 1, "training_loss": 13335.19921875, "training_acc": 50.0, "val_loss": 10029.2490234375, "val_acc": 40.0}
{"epoch": 2, "training_loss": 4675.054870605469, "training_acc": 50.0, "val_loss": 7557.57421875, "val_acc": 60.0}
{"epoch": 3, "training_loss": 9103.5333984375, "training_acc": 50.0, "val_loss": 782.0782470703125, "val_acc": 60.0}
{"epoch": 4, "training_loss": 2047.4236206054688, "training_acc": 70.0, "val_loss": 7563.3642578125, "val_acc": 40.0}
{"epoch": 5, "training_loss": 4480.968408203125, "training_acc": 50.0, "val_loss": 2397.024658203125, "val_acc": 60.0}
{"epoch": 6, "training_loss": 4404.5376953125, "training_acc": 50.0, "val_loss": 3120.259765625, "val_acc": 60.0}
{"epoch": 7, "training_loss": 1587.4650390625, "training_acc": 70.0, "val_loss": 5254.966796875, "val_acc": 40.0}
{"epoch": 8, "training_loss": 4629.746484375, "training_acc": 50.0, "val_loss": 932.9426879882812, "val_acc": 40.0}
{"epoch": 9, "training_loss": 3204.5839599609376, "training_acc": 40.0, "val_loss": 3685.796142578125, "val_acc": 60.0}
{"epoch": 10, "training_loss": 2461.348291015625, "training_acc": 60.0, "val_loss": 3860.996826171875, "val_acc": 40.0}
{"epoch": 11, "training_loss": 3333.072705078125, "training_acc": 50.0, "val_loss": 116.15802001953125, "val_acc": 40.0}
{"epoch": 12, "training_loss": 3117.6641845703125, "training_acc": 40.0, "val_loss": 3014.838623046875, "val_acc": 60.0}
{"epoch": 13, "training_loss": 2874.103515625, "training_acc": 40.0, "val_loss": 5670.67919921875, "val_acc": 40.0}
{"epoch": 14, "training_loss": 3670.10634765625, "training_acc": 50.0, "val_loss": 1337.8270263671875, "val_acc": 60.0}
{"epoch": 15, "training_loss": 3243.125048828125, "training_acc": 50.0, "val_loss": 2151.678466796875, "val_acc": 60.0}
{"epoch": 16, "training_loss": 1767.768408203125, "training_acc": 50.0, "val_loss": 3098.737060546875, "val_acc": 40.0}
{"epoch": 17, "training_loss": 2178.2350341796873, "training_acc": 40.0, "val_loss": 1753.9976806640625, "val_acc": 60.0}
{"epoch": 18, "training_loss": 1833.35947265625, "training_acc": 40.0, "val_loss": 1767.440673828125, "val_acc": 40.0}
{"epoch": 19, "training_loss": 878.515283203125, "training_acc": 60.0, "val_loss": 1452.5020751953125, "val_acc": 60.0}
{"epoch": 20, "training_loss": 1149.8068908691407, "training_acc": 60.0, "val_loss": 1798.7108154296875, "val_acc": 40.0}
{"epoch": 21, "training_loss": 935.8225341796875, "training_acc": 60.0, "val_loss": 1176.4542236328125, "val_acc": 60.0}
{"epoch": 22, "training_loss": 1422.24296875, "training_acc": 40.0, "val_loss": 1398.3619384765625, "val_acc": 40.0}
{"epoch": 23, "training_loss": 609.3462829589844, "training_acc": 60.0, "val_loss": 2095.085693359375, "val_acc": 60.0}
{"epoch": 24, "training_loss": 1646.7566345214843, "training_acc": 60.0, "val_loss": 2004.1103515625, "val_acc": 40.0}
{"epoch": 25, "training_loss": 1837.39658203125, "training_acc": 30.0, "val_loss": 730.5274658203125, "val_acc": 60.0}
{"epoch": 26, "training_loss": 2188.323876953125, "training_acc": 20.0, "val_loss": 51.01287841796875, "val_acc": 40.0}
{"epoch": 27, "training_loss": 2610.3616058349608, "training_acc": 40.0, "val_loss": 1673.060546875, "val_acc": 60.0}
{"epoch": 28, "training_loss": 2557.88447265625, "training_acc": 40.0, "val_loss": 3472.028076171875, "val_acc": 40.0}
{"epoch": 29, "training_loss": 1947.78486328125, "training_acc": 50.0, "val_loss": 3008.32861328125, "val_acc": 60.0}
{"epoch": 30, "training_loss": 2555.9574951171876, "training_acc": 50.0, "val_loss": 4090.726318359375, "val_acc": 40.0}
{"epoch": 31, "training_loss": 4666.945361328125, "training_acc": 50.0, "val_loss": 1800.4442138671875, "val_acc": 40.0}
{"epoch": 32, "training_loss": 2955.374658203125, "training_acc": 40.0, "val_loss": 2971.380615234375, "val_acc": 60.0}
{"epoch": 33, "training_loss": 2189.42060546875, "training_acc": 50.0, "val_loss": 4985.45556640625, "val_acc": 40.0}
{"epoch": 34, "training_loss": 3740.77900390625, "training_acc": 50.0, "val_loss": 1800.8646240234375, "val_acc": 60.0}
{"epoch": 35, "training_loss": 2797.891796875, "training_acc": 50.0, "val_loss": 362.8040466308594, "val_acc": 60.0}
{"epoch": 36, "training_loss": 1701.8536987304688, "training_acc": 50.0, "val_loss": 2199.123046875, "val_acc": 40.0}
{"epoch": 37, "training_loss": 1244.71416015625, "training_acc": 50.0, "val_loss": 1173.3006591796875, "val_acc": 60.0}
{"epoch": 38, "training_loss": 994.4049621582031, "training_acc": 40.0, "val_loss": 805.7982788085938, "val_acc": 60.0}
{"epoch": 39, "training_loss": 1313.7870971679688, "training_acc": 30.0, "val_loss": 346.3771667480469, "val_acc": 40.0}
{"epoch": 40, "training_loss": 1308.1263427734375, "training_acc": 50.0, "val_loss": 619.2451171875, "val_acc": 60.0}
{"epoch": 41, "training_loss": 1478.01953125, "training_acc": 50.0, "val_loss": 1861.344970703125, "val_acc": 40.0}
{"epoch": 42, "training_loss": 726.9770141601563, "training_acc": 60.0, "val_loss": 439.1732482910156, "val_acc": 60.0}
{"epoch": 43, "training_loss": 600.9827270507812, "training_acc": 60.0, "val_loss": 286.4541015625, "val_acc": 60.0}
{"epoch": 44, "training_loss": 464.22584228515626, "training_acc": 50.0, "val_loss": 984.2189331054688, "val_acc": 40.0}
{"epoch": 45, "training_loss": 501.4544311523438, "training_acc": 60.0, "val_loss": 483.099365234375, "val_acc": 40.0}
