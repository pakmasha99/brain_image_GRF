"main_modify.py --pretrained_path None --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 1 --task ADNI_sex --input_option yAware --learning_rate 1e2 --batch_size 8 --weight_decay 1e-2 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 9819.958513617516, "training_acc": 45.0, "val_loss": 7882.37841796875, "val_acc": 60.0}
{"epoch": 1, "training_loss": 13901.41748046875, "training_acc": 45.0, "val_loss": 5405.9755859375, "val_acc": 60.0}
{"epoch": 2, "training_loss": 4812.9677734375, "training_acc": 45.0, "val_loss": 11374.9912109375, "val_acc": 40.0}
{"epoch": 3, "training_loss": 8061.734765625, "training_acc": 55.0, "val_loss": 301.47589111328125, "val_acc": 40.0}
{"epoch": 4, "training_loss": 4063.505163574219, "training_acc": 45.0, "val_loss": 5115.00537109375, "val_acc": 60.0}
{"epoch": 5, "training_loss": 3872.99345703125, "training_acc": 55.0, "val_loss": 4232.36474609375, "val_acc": 40.0}
{"epoch": 6, "training_loss": 4316.1095703125, "training_acc": 55.0, "val_loss": 2808.91455078125, "val_acc": 40.0}
{"epoch": 7, "training_loss": 1577.7446533203124, "training_acc": 55.0, "val_loss": 2861.493408203125, "val_acc": 60.0}
{"epoch": 8, "training_loss": 2466.3273376464845, "training_acc": 45.0, "val_loss": 4105.15234375, "val_acc": 40.0}
{"epoch": 9, "training_loss": 3818.96416015625, "training_acc": 55.0, "val_loss": 3138.9375, "val_acc": 40.0}
{"epoch": 10, "training_loss": 3194.742578125, "training_acc": 25.0, "val_loss": 2130.527099609375, "val_acc": 60.0}
{"epoch": 11, "training_loss": 2283.132958984375, "training_acc": 35.0, "val_loss": 3991.427001953125, "val_acc": 40.0}
{"epoch": 12, "training_loss": 2483.7709838867186, "training_acc": 55.0, "val_loss": 1574.504638671875, "val_acc": 60.0}
{"epoch": 13, "training_loss": 2320.95029296875, "training_acc": 45.0, "val_loss": 292.6779479980469, "val_acc": 40.0}
{"epoch": 14, "training_loss": 297.3304840087891, "training_acc": 45.0, "val_loss": 1084.6185302734375, "val_acc": 40.0}
{"epoch": 15, "training_loss": 845.1772216796875, "training_acc": 45.0, "val_loss": 347.9024353027344, "val_acc": 60.0}
{"epoch": 16, "training_loss": 1462.3986328125, "training_acc": 35.0, "val_loss": 464.04345703125, "val_acc": 40.0}
{"epoch": 17, "training_loss": 1759.03193359375, "training_acc": 45.0, "val_loss": 1203.8089599609375, "val_acc": 60.0}
{"epoch": 18, "training_loss": 1303.227392578125, "training_acc": 55.0, "val_loss": 2020.1861572265625, "val_acc": 40.0}
{"epoch": 19, "training_loss": 659.698388671875, "training_acc": 65.0, "val_loss": 2429.7802734375, "val_acc": 60.0}
{"epoch": 20, "training_loss": 2498.042138671875, "training_acc": 45.0, "val_loss": 4075.44140625, "val_acc": 40.0}
{"epoch": 21, "training_loss": 3873.0404296875, "training_acc": 55.0, "val_loss": 2455.19775390625, "val_acc": 40.0}
{"epoch": 22, "training_loss": 1708.780322265625, "training_acc": 55.0, "val_loss": 1531.9488525390625, "val_acc": 60.0}
{"epoch": 23, "training_loss": 1345.6680297851562, "training_acc": 55.0, "val_loss": 1100.07373046875, "val_acc": 40.0}
{"epoch": 24, "training_loss": 2284.89931640625, "training_acc": 25.0, "val_loss": 1.913223147392273, "val_acc": 60.0}
{"epoch": 25, "training_loss": 1235.1519548416138, "training_acc": 65.0, "val_loss": 3936.22314453125, "val_acc": 40.0}
{"epoch": 26, "training_loss": 1877.094384765625, "training_acc": 55.0, "val_loss": 2859.701171875, "val_acc": 60.0}
{"epoch": 27, "training_loss": 2929.6958129882814, "training_acc": 45.0, "val_loss": 4379.14208984375, "val_acc": 40.0}
{"epoch": 28, "training_loss": 4085.0162109375, "training_acc": 55.0, "val_loss": 1511.2520751953125, "val_acc": 40.0}
{"epoch": 29, "training_loss": 1825.220458984375, "training_acc": 65.0, "val_loss": 2972.515380859375, "val_acc": 60.0}
{"epoch": 30, "training_loss": 3290.7806640625, "training_acc": 35.0, "val_loss": 5468.1025390625, "val_acc": 40.0}
{"epoch": 31, "training_loss": 3214.697866821289, "training_acc": 55.0, "val_loss": 2443.145263671875, "val_acc": 60.0}
{"epoch": 32, "training_loss": 3717.04443359375, "training_acc": 45.0, "val_loss": 389.005859375, "val_acc": 40.0}
{"epoch": 33, "training_loss": 1257.0851928710938, "training_acc": 55.0, "val_loss": 434.94708251953125, "val_acc": 60.0}
{"epoch": 34, "training_loss": 683.7634094238281, "training_acc": 45.0, "val_loss": 1893.1488037109375, "val_acc": 40.0}
{"epoch": 35, "training_loss": 1848.4813232421875, "training_acc": 55.0, "val_loss": 1466.9774169921875, "val_acc": 60.0}
{"epoch": 36, "training_loss": 2220.4137329101563, "training_acc": 45.0, "val_loss": 891.7116088867188, "val_acc": 40.0}
{"epoch": 37, "training_loss": 1491.2942810058594, "training_acc": 55.0, "val_loss": 1240.5872802734375, "val_acc": 60.0}
{"epoch": 38, "training_loss": 2126.713134765625, "training_acc": 45.0, "val_loss": 1662.2513427734375, "val_acc": 40.0}
{"epoch": 39, "training_loss": 1220.4681884765625, "training_acc": 55.0, "val_loss": 644.7518310546875, "val_acc": 60.0}
{"epoch": 40, "training_loss": 848.2330932617188, "training_acc": 45.0, "val_loss": 512.7202758789062, "val_acc": 40.0}
{"epoch": 41, "training_loss": 468.17419586181643, "training_acc": 45.0, "val_loss": 930.765625, "val_acc": 60.0}
{"epoch": 42, "training_loss": 1062.4437255859375, "training_acc": 45.0, "val_loss": 2077.824951171875, "val_acc": 40.0}
{"epoch": 43, "training_loss": 835.7826782226563, "training_acc": 65.0, "val_loss": 2029.5653076171875, "val_acc": 60.0}
