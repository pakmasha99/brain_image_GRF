"main_modify.py --pretrained_path None --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 3 --task ADNI_sex --input_option yAware --learning_rate 1e2 --batch_size 8 --weight_decay 1e-2 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 9716.43329744339, "training_acc": 50.0, "val_loss": 12581.5322265625, "val_acc": 40.0}
{"epoch": 1, "training_loss": 16490.761328125, "training_acc": 50.0, "val_loss": 9706.9130859375, "val_acc": 40.0}
{"epoch": 2, "training_loss": 5001.764501953125, "training_acc": 60.0, "val_loss": 8722.673828125, "val_acc": 60.0}
{"epoch": 3, "training_loss": 10014.1236328125, "training_acc": 50.0, "val_loss": 1438.103759765625, "val_acc": 60.0}
{"epoch": 4, "training_loss": 3270.242626953125, "training_acc": 60.0, "val_loss": 10578.0693359375, "val_acc": 40.0}
{"epoch": 5, "training_loss": 7329.1314453125, "training_acc": 50.0, "val_loss": 516.5430908203125, "val_acc": 60.0}
{"epoch": 6, "training_loss": 2597.930712890625, "training_acc": 50.0, "val_loss": 3606.868896484375, "val_acc": 60.0}
{"epoch": 7, "training_loss": 3473.5010009765624, "training_acc": 40.0, "val_loss": 3459.458740234375, "val_acc": 40.0}
{"epoch": 8, "training_loss": 2705.0456787109374, "training_acc": 50.0, "val_loss": 415.1737365722656, "val_acc": 60.0}
{"epoch": 9, "training_loss": 1431.1857177734375, "training_acc": 50.0, "val_loss": 315.76043701171875, "val_acc": 60.0}
{"epoch": 10, "training_loss": 930.0565063476563, "training_acc": 60.0, "val_loss": 2138.123291015625, "val_acc": 40.0}
{"epoch": 11, "training_loss": 1228.9312255859375, "training_acc": 50.0, "val_loss": 2239.872802734375, "val_acc": 60.0}
{"epoch": 12, "training_loss": 1903.3075439453125, "training_acc": 50.0, "val_loss": 3127.38232421875, "val_acc": 40.0}
{"epoch": 13, "training_loss": 3346.85947265625, "training_acc": 50.0, "val_loss": 1631.4830322265625, "val_acc": 40.0}
{"epoch": 14, "training_loss": 2351.20087890625, "training_acc": 40.0, "val_loss": 2894.103271484375, "val_acc": 60.0}
{"epoch": 15, "training_loss": 2876.880322265625, "training_acc": 40.0, "val_loss": 2708.458984375, "val_acc": 40.0}
{"epoch": 16, "training_loss": 1907.5583251953126, "training_acc": 40.0, "val_loss": 529.5735473632812, "val_acc": 60.0}
{"epoch": 17, "training_loss": 443.0903945922852, "training_acc": 40.0, "val_loss": 1254.2498779296875, "val_acc": 40.0}
{"epoch": 18, "training_loss": 834.6677490234375, "training_acc": 50.0, "val_loss": 520.3024291992188, "val_acc": 60.0}
{"epoch": 19, "training_loss": 961.161083984375, "training_acc": 40.0, "val_loss": 696.267333984375, "val_acc": 60.0}
{"epoch": 20, "training_loss": 1031.6005615234376, "training_acc": 50.0, "val_loss": 1567.8441162109375, "val_acc": 40.0}
{"epoch": 21, "training_loss": 1337.6494873046875, "training_acc": 50.0, "val_loss": 1170.9586181640625, "val_acc": 60.0}
{"epoch": 22, "training_loss": 1815.34931640625, "training_acc": 50.0, "val_loss": 1327.037109375, "val_acc": 40.0}
{"epoch": 23, "training_loss": 1267.38212890625, "training_acc": 50.0, "val_loss": 712.8461303710938, "val_acc": 60.0}
{"epoch": 24, "training_loss": 1114.8221130371094, "training_acc": 40.0, "val_loss": 16.934213638305664, "val_acc": 60.0}
{"epoch": 25, "training_loss": 417.38643608093264, "training_acc": 50.0, "val_loss": 980.4558715820312, "val_acc": 60.0}
{"epoch": 26, "training_loss": 1223.0517700195312, "training_acc": 50.0, "val_loss": 3525.909423828125, "val_acc": 40.0}
{"epoch": 27, "training_loss": 3838.4458984375, "training_acc": 50.0, "val_loss": 742.101318359375, "val_acc": 40.0}
{"epoch": 28, "training_loss": 1547.2441528320312, "training_acc": 70.0, "val_loss": 3074.31640625, "val_acc": 60.0}
{"epoch": 29, "training_loss": 3195.691943359375, "training_acc": 40.0, "val_loss": 4901.15087890625, "val_acc": 40.0}
{"epoch": 30, "training_loss": 2946.9310546875, "training_acc": 50.0, "val_loss": 2749.9052734375, "val_acc": 60.0}
{"epoch": 31, "training_loss": 3863.51376953125, "training_acc": 50.0, "val_loss": 735.0645751953125, "val_acc": 60.0}
{"epoch": 32, "training_loss": 3290.075048828125, "training_acc": 40.0, "val_loss": 4594.904296875, "val_acc": 40.0}
{"epoch": 33, "training_loss": 1421.5538818359375, "training_acc": 70.0, "val_loss": 4349.03466796875, "val_acc": 60.0}
{"epoch": 34, "training_loss": 4980.731030273438, "training_acc": 50.0, "val_loss": 1466.5133056640625, "val_acc": 40.0}
{"epoch": 35, "training_loss": 3030.305615234375, "training_acc": 50.0, "val_loss": 1009.5155639648438, "val_acc": 40.0}
{"epoch": 36, "training_loss": 2143.8425537109374, "training_acc": 50.0, "val_loss": 2374.53369140625, "val_acc": 60.0}
{"epoch": 37, "training_loss": 1591.0964057922363, "training_acc": 40.0, "val_loss": 1303.281494140625, "val_acc": 40.0}
{"epoch": 38, "training_loss": 973.53798828125, "training_acc": 40.0, "val_loss": 1190.6282958984375, "val_acc": 40.0}
{"epoch": 39, "training_loss": 820.7743103027344, "training_acc": 50.0, "val_loss": 140.6259765625, "val_acc": 60.0}
{"epoch": 40, "training_loss": 236.03838806152345, "training_acc": 70.0, "val_loss": 550.7634887695312, "val_acc": 60.0}
{"epoch": 41, "training_loss": 526.8727966308594, "training_acc": 40.0, "val_loss": 28.041839599609375, "val_acc": 60.0}
{"epoch": 42, "training_loss": 1385.8582336425782, "training_acc": 40.0, "val_loss": 231.40147399902344, "val_acc": 40.0}
{"epoch": 43, "training_loss": 1542.9577026367188, "training_acc": 50.0, "val_loss": 1008.3814697265625, "val_acc": 60.0}
