"main_modify.py --pretrained_path None --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 3 --task ADNI_sex --input_option yAware --learning_rate 1e2 --batch_size 8 --weight_decay 1e-2 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 13389.991582465173, "training_acc": 55.0, "val_loss": 7015.5, "val_acc": 60.0}
{"epoch": 1, "training_loss": 13567.715234375, "training_acc": 45.0, "val_loss": 5533.06787109375, "val_acc": 60.0}
{"epoch": 2, "training_loss": 3618.26328125, "training_acc": 65.0, "val_loss": 11349.2548828125, "val_acc": 40.0}
{"epoch": 3, "training_loss": 7544.8890625, "training_acc": 55.0, "val_loss": 594.8383178710938, "val_acc": 40.0}
{"epoch": 4, "training_loss": 4023.687121582031, "training_acc": 55.0, "val_loss": 6256.00634765625, "val_acc": 60.0}
{"epoch": 5, "training_loss": 5945.376013183593, "training_acc": 45.0, "val_loss": 4853.74462890625, "val_acc": 40.0}
{"epoch": 6, "training_loss": 5502.754833984375, "training_acc": 55.0, "val_loss": 7019.58349609375, "val_acc": 40.0}
{"epoch": 7, "training_loss": 2897.531884765625, "training_acc": 55.0, "val_loss": 3250.260498046875, "val_acc": 60.0}
{"epoch": 8, "training_loss": 5275.79755859375, "training_acc": 45.0, "val_loss": 881.0514526367188, "val_acc": 60.0}
{"epoch": 9, "training_loss": 1570.96689453125, "training_acc": 65.0, "val_loss": 6427.74755859375, "val_acc": 40.0}
{"epoch": 10, "training_loss": 4147.4490234375, "training_acc": 55.0, "val_loss": 1639.0426025390625, "val_acc": 60.0}
{"epoch": 11, "training_loss": 2903.7269775390623, "training_acc": 45.0, "val_loss": 803.9074096679688, "val_acc": 60.0}
{"epoch": 12, "training_loss": 819.864892578125, "training_acc": 65.0, "val_loss": 3114.653076171875, "val_acc": 40.0}
{"epoch": 13, "training_loss": 1364.5142181396484, "training_acc": 65.0, "val_loss": 1114.0018310546875, "val_acc": 60.0}
{"epoch": 14, "training_loss": 1030.6405883789062, "training_acc": 55.0, "val_loss": 1380.913818359375, "val_acc": 40.0}
{"epoch": 15, "training_loss": 1018.2245483398438, "training_acc": 45.0, "val_loss": 869.2628173828125, "val_acc": 60.0}
{"epoch": 16, "training_loss": 611.0752258300781, "training_acc": 55.0, "val_loss": 113.71727752685547, "val_acc": 40.0}
{"epoch": 17, "training_loss": 951.7064575195312, "training_acc": 45.0, "val_loss": 661.2698974609375, "val_acc": 40.0}
{"epoch": 18, "training_loss": 834.902099609375, "training_acc": 55.0, "val_loss": 852.7501220703125, "val_acc": 60.0}
{"epoch": 19, "training_loss": 1008.0938537597656, "training_acc": 45.0, "val_loss": 243.6112518310547, "val_acc": 40.0}
{"epoch": 20, "training_loss": 557.032568359375, "training_acc": 45.0, "val_loss": 1659.7001953125, "val_acc": 40.0}
{"epoch": 21, "training_loss": 1428.406103515625, "training_acc": 55.0, "val_loss": 1328.4388427734375, "val_acc": 60.0}
{"epoch": 22, "training_loss": 2309.3027587890624, "training_acc": 45.0, "val_loss": 1734.0404052734375, "val_acc": 40.0}
{"epoch": 23, "training_loss": 1694.083203125, "training_acc": 55.0, "val_loss": 99.14684295654297, "val_acc": 60.0}
{"epoch": 24, "training_loss": 182.94618530273436, "training_acc": 45.0, "val_loss": 816.7288818359375, "val_acc": 60.0}
{"epoch": 25, "training_loss": 1210.9388916015625, "training_acc": 35.0, "val_loss": 316.66241455078125, "val_acc": 60.0}
{"epoch": 26, "training_loss": 730.6643463134766, "training_acc": 35.0, "val_loss": 1343.2423095703125, "val_acc": 40.0}
{"epoch": 27, "training_loss": 649.5560638427735, "training_acc": 55.0, "val_loss": 356.5881652832031, "val_acc": 40.0}
{"epoch": 28, "training_loss": 459.2182250976563, "training_acc": 55.0, "val_loss": 849.2483520507812, "val_acc": 60.0}
{"epoch": 29, "training_loss": 1050.6810546875, "training_acc": 45.0, "val_loss": 111.68428802490234, "val_acc": 60.0}
{"epoch": 30, "training_loss": 502.2364929199219, "training_acc": 45.0, "val_loss": 1657.695556640625, "val_acc": 40.0}
{"epoch": 31, "training_loss": 934.525341796875, "training_acc": 55.0, "val_loss": 2012.651611328125, "val_acc": 60.0}
{"epoch": 32, "training_loss": 1970.449365234375, "training_acc": 45.0, "val_loss": 3359.35009765625, "val_acc": 40.0}
{"epoch": 33, "training_loss": 1758.1540283203126, "training_acc": 55.0, "val_loss": 1025.2703857421875, "val_acc": 60.0}
{"epoch": 34, "training_loss": 1114.1212890625, "training_acc": 45.0, "val_loss": 2949.999267578125, "val_acc": 40.0}
{"epoch": 35, "training_loss": 1518.2345703125, "training_acc": 55.0, "val_loss": 1743.3939208984375, "val_acc": 60.0}
{"epoch": 36, "training_loss": 1465.0906005859374, "training_acc": 55.0, "val_loss": 3226.009033203125, "val_acc": 40.0}
{"epoch": 37, "training_loss": 1666.1232177734375, "training_acc": 55.0, "val_loss": 2707.26220703125, "val_acc": 60.0}
{"epoch": 38, "training_loss": 4266.662890625, "training_acc": 45.0, "val_loss": 34.94355392456055, "val_acc": 60.0}
{"epoch": 39, "training_loss": 2482.201109313965, "training_acc": 55.0, "val_loss": 5600.98388671875, "val_acc": 40.0}
{"epoch": 40, "training_loss": 2088.47783203125, "training_acc": 65.0, "val_loss": 4394.66845703125, "val_acc": 60.0}
{"epoch": 41, "training_loss": 5163.771826171875, "training_acc": 45.0, "val_loss": 3716.571044921875, "val_acc": 40.0}
{"epoch": 42, "training_loss": 3454.8078125, "training_acc": 55.0, "val_loss": 1158.1732177734375, "val_acc": 40.0}
{"epoch": 43, "training_loss": 3156.3966552734373, "training_acc": 45.0, "val_loss": 2566.179443359375, "val_acc": 60.0}
{"epoch": 44, "training_loss": 1947.1902587890625, "training_acc": 55.0, "val_loss": 3276.01220703125, "val_acc": 40.0}
{"epoch": 45, "training_loss": 1640.333837890625, "training_acc": 55.0, "val_loss": 2279.846923828125, "val_acc": 60.0}
{"epoch": 46, "training_loss": 2757.832666015625, "training_acc": 35.0, "val_loss": 2957.855224609375, "val_acc": 40.0}
{"epoch": 47, "training_loss": 1222.1555908203125, "training_acc": 65.0, "val_loss": 1905.029541015625, "val_acc": 60.0}
{"epoch": 48, "training_loss": 2363.1195068359375, "training_acc": 35.0, "val_loss": 2385.038330078125, "val_acc": 40.0}
{"epoch": 49, "training_loss": 1476.8355030059815, "training_acc": 55.0, "val_loss": 2123.421875, "val_acc": 60.0}
{"epoch": 50, "training_loss": 1330.754150390625, "training_acc": 65.0, "val_loss": 4614.94775390625, "val_acc": 40.0}
{"epoch": 51, "training_loss": 2815.02734375, "training_acc": 55.0, "val_loss": 2153.640380859375, "val_acc": 60.0}
{"epoch": 52, "training_loss": 3604.709765625, "training_acc": 45.0, "val_loss": 933.17822265625, "val_acc": 40.0}
{"epoch": 53, "training_loss": 2420.371240234375, "training_acc": 55.0, "val_loss": 894.4861450195312, "val_acc": 40.0}
{"epoch": 54, "training_loss": 3185.6008056640626, "training_acc": 35.0, "val_loss": 1641.675048828125, "val_acc": 60.0}
{"epoch": 55, "training_loss": 2858.73994140625, "training_acc": 45.0, "val_loss": 3631.430908203125, "val_acc": 40.0}
{"epoch": 56, "training_loss": 1722.3454711914062, "training_acc": 55.0, "val_loss": 3803.856201171875, "val_acc": 60.0}
{"epoch": 57, "training_loss": 3705.922326660156, "training_acc": 45.0, "val_loss": 3191.4345703125, "val_acc": 40.0}
