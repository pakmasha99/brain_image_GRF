"main_modify.py --pretrained_path None --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 3 --task ADNI_sex --input_option yAware --learning_rate 1e1 --batch_size 16 --weight_decay 1e-9 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 429.7109664440155, "training_acc": 50.0, "val_loss": 484.6116638183594, "val_acc": 60.0}
{"epoch": 1, "training_loss": 543.3715698242188, "training_acc": 60.0, "val_loss": 2560.767578125, "val_acc": 40.0}
{"epoch": 2, "training_loss": 2126.9375, "training_acc": 50.0, "val_loss": 1834.1990966796875, "val_acc": 40.0}
{"epoch": 3, "training_loss": 1339.3218872070313, "training_acc": 50.0, "val_loss": 479.9331970214844, "val_acc": 60.0}
{"epoch": 4, "training_loss": 652.0543334960937, "training_acc": 50.0, "val_loss": 1111.1041259765625, "val_acc": 60.0}
{"epoch": 5, "training_loss": 1371.7259033203125, "training_acc": 50.0, "val_loss": 715.0051879882812, "val_acc": 60.0}
{"epoch": 6, "training_loss": 722.6603210449218, "training_acc": 50.0, "val_loss": 707.0134887695312, "val_acc": 40.0}
{"epoch": 7, "training_loss": 752.75546875, "training_acc": 50.0, "val_loss": 1422.0244140625, "val_acc": 40.0}
{"epoch": 8, "training_loss": 1139.6843627929688, "training_acc": 50.0, "val_loss": 611.2156982421875, "val_acc": 40.0}
{"epoch": 9, "training_loss": 368.00853576660154, "training_acc": 60.0, "val_loss": 443.875732421875, "val_acc": 60.0}
{"epoch": 10, "training_loss": 554.5404296875, "training_acc": 50.0, "val_loss": 552.5347900390625, "val_acc": 60.0}
{"epoch": 11, "training_loss": 690.27783203125, "training_acc": 50.0, "val_loss": 171.0882568359375, "val_acc": 60.0}
{"epoch": 12, "training_loss": 169.44242401123046, "training_acc": 60.0, "val_loss": 550.9849243164062, "val_acc": 40.0}
{"epoch": 13, "training_loss": 454.0351135253906, "training_acc": 50.0, "val_loss": 292.2693786621094, "val_acc": 40.0}
{"epoch": 14, "training_loss": 182.63813858032228, "training_acc": 60.0, "val_loss": 260.04302978515625, "val_acc": 60.0}
{"epoch": 15, "training_loss": 315.8710678100586, "training_acc": 50.0, "val_loss": 24.010053634643555, "val_acc": 60.0}
{"epoch": 16, "training_loss": 102.04647979736328, "training_acc": 50.0, "val_loss": 640.8840942382812, "val_acc": 40.0}
{"epoch": 17, "training_loss": 508.34716796875, "training_acc": 50.0, "val_loss": 22.37126922607422, "val_acc": 40.0}
{"epoch": 18, "training_loss": 70.15811767578126, "training_acc": 60.0, "val_loss": 790.2365112304688, "val_acc": 60.0}
{"epoch": 19, "training_loss": 1014.966064453125, "training_acc": 50.0, "val_loss": 812.1256713867188, "val_acc": 60.0}
{"epoch": 20, "training_loss": 947.843408203125, "training_acc": 50.0, "val_loss": 118.72377014160156, "val_acc": 60.0}
{"epoch": 21, "training_loss": 229.804248046875, "training_acc": 50.0, "val_loss": 1159.4078369140625, "val_acc": 40.0}
{"epoch": 22, "training_loss": 975.5150634765625, "training_acc": 50.0, "val_loss": 1256.3914794921875, "val_acc": 40.0}
{"epoch": 23, "training_loss": 978.9386962890625, "training_acc": 50.0, "val_loss": 338.59332275390625, "val_acc": 40.0}
{"epoch": 24, "training_loss": 311.340283203125, "training_acc": 50.0, "val_loss": 673.1845703125, "val_acc": 60.0}
{"epoch": 25, "training_loss": 869.147998046875, "training_acc": 50.0, "val_loss": 710.7947387695312, "val_acc": 60.0}
{"epoch": 26, "training_loss": 824.799658203125, "training_acc": 50.0, "val_loss": 53.07984161376953, "val_acc": 60.0}
{"epoch": 27, "training_loss": 103.66671142578124, "training_acc": 60.0, "val_loss": 1280.475341796875, "val_acc": 40.0}
{"epoch": 28, "training_loss": 1136.932275390625, "training_acc": 50.0, "val_loss": 1402.7484130859375, "val_acc": 40.0}
{"epoch": 29, "training_loss": 1074.26005859375, "training_acc": 50.0, "val_loss": 286.6497497558594, "val_acc": 40.0}
{"epoch": 30, "training_loss": 299.064990234375, "training_acc": 50.0, "val_loss": 803.8391723632812, "val_acc": 60.0}
{"epoch": 31, "training_loss": 1003.2787109375, "training_acc": 50.0, "val_loss": 1029.6317138671875, "val_acc": 60.0}
{"epoch": 32, "training_loss": 1263.6102783203125, "training_acc": 50.0, "val_loss": 653.1434936523438, "val_acc": 60.0}
{"epoch": 33, "training_loss": 650.2269104003906, "training_acc": 50.0, "val_loss": 657.2435913085938, "val_acc": 40.0}
{"epoch": 34, "training_loss": 547.587109375, "training_acc": 50.0, "val_loss": 1712.8037109375, "val_acc": 40.0}
{"epoch": 35, "training_loss": 1512.53974609375, "training_acc": 50.0, "val_loss": 1675.374267578125, "val_acc": 40.0}
{"epoch": 36, "training_loss": 1273.0243408203125, "training_acc": 50.0, "val_loss": 363.7489929199219, "val_acc": 40.0}
