"main_modify.py --pretrained_path None --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_sex --input_option yAware --learning_rate 1e1 --batch_size 16 --weight_decay 1e-9 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 429.96777334213255, "training_acc": 45.0, "val_loss": 938.7117309570312, "val_acc": 40.0}
{"epoch": 1, "training_loss": 557.9280212402343, "training_acc": 65.0, "val_loss": 1351.2791748046875, "val_acc": 60.0}
{"epoch": 2, "training_loss": 1811.596142578125, "training_acc": 45.0, "val_loss": 593.0048828125, "val_acc": 60.0}
{"epoch": 3, "training_loss": 734.389599609375, "training_acc": 45.0, "val_loss": 948.3536376953125, "val_acc": 40.0}
{"epoch": 4, "training_loss": 709.9509765625, "training_acc": 55.0, "val_loss": 688.4091186523438, "val_acc": 40.0}
{"epoch": 5, "training_loss": 464.0285640716553, "training_acc": 55.0, "val_loss": 470.6737976074219, "val_acc": 60.0}
{"epoch": 6, "training_loss": 659.3709289550782, "training_acc": 45.0, "val_loss": 537.8148193359375, "val_acc": 60.0}
{"epoch": 7, "training_loss": 697.6006072998047, "training_acc": 45.0, "val_loss": 309.9791564941406, "val_acc": 40.0}
{"epoch": 8, "training_loss": 304.06451416015625, "training_acc": 55.0, "val_loss": 344.9580078125, "val_acc": 40.0}
{"epoch": 9, "training_loss": 336.2333190917969, "training_acc": 35.0, "val_loss": 85.4332046508789, "val_acc": 60.0}
{"epoch": 10, "training_loss": 185.06846923828124, "training_acc": 35.0, "val_loss": 295.2271423339844, "val_acc": 40.0}
{"epoch": 11, "training_loss": 165.45736389160157, "training_acc": 55.0, "val_loss": 343.596435546875, "val_acc": 60.0}
{"epoch": 12, "training_loss": 510.5788330078125, "training_acc": 45.0, "val_loss": 463.68994140625, "val_acc": 60.0}
{"epoch": 13, "training_loss": 606.6798858642578, "training_acc": 45.0, "val_loss": 127.60491180419922, "val_acc": 40.0}
{"epoch": 14, "training_loss": 126.398681640625, "training_acc": 55.0, "val_loss": 228.06387329101562, "val_acc": 40.0}
{"epoch": 15, "training_loss": 215.60436096191407, "training_acc": 35.0, "val_loss": 36.75218200683594, "val_acc": 40.0}
{"epoch": 16, "training_loss": 54.113214111328126, "training_acc": 35.0, "val_loss": 284.1554870605469, "val_acc": 40.0}
{"epoch": 17, "training_loss": 233.012646484375, "training_acc": 55.0, "val_loss": 286.63385009765625, "val_acc": 40.0}
{"epoch": 18, "training_loss": 142.53072900176048, "training_acc": 70.0, "val_loss": 192.25408935546875, "val_acc": 60.0}
{"epoch": 19, "training_loss": 263.547119140625, "training_acc": 45.0, "val_loss": 105.2766342163086, "val_acc": 60.0}
{"epoch": 20, "training_loss": 145.45315551757812, "training_acc": 45.0, "val_loss": 219.15855407714844, "val_acc": 40.0}
{"epoch": 21, "training_loss": 147.87105655670166, "training_acc": 55.0, "val_loss": 176.59031677246094, "val_acc": 60.0}
{"epoch": 22, "training_loss": 239.24906311035156, "training_acc": 45.0, "val_loss": 49.433834075927734, "val_acc": 60.0}
{"epoch": 23, "training_loss": 110.79400634765625, "training_acc": 45.0, "val_loss": 462.2218933105469, "val_acc": 40.0}
{"epoch": 24, "training_loss": 329.5131469726563, "training_acc": 55.0, "val_loss": 15.188183784484863, "val_acc": 60.0}
{"epoch": 25, "training_loss": 55.33836975097656, "training_acc": 45.0, "val_loss": 73.30684661865234, "val_acc": 40.0}
{"epoch": 26, "training_loss": 54.48390884399414, "training_acc": 55.0, "val_loss": 106.7405776977539, "val_acc": 60.0}
{"epoch": 27, "training_loss": 138.9638813018799, "training_acc": 45.0, "val_loss": 122.28303527832031, "val_acc": 40.0}
{"epoch": 28, "training_loss": 85.40028839111328, "training_acc": 55.0, "val_loss": 77.52483367919922, "val_acc": 60.0}
{"epoch": 29, "training_loss": 87.52226958274841, "training_acc": 45.0, "val_loss": 336.64215087890625, "val_acc": 40.0}
{"epoch": 30, "training_loss": 256.0358520507813, "training_acc": 55.0, "val_loss": 340.5880432128906, "val_acc": 40.0}
{"epoch": 31, "training_loss": 194.21178588867187, "training_acc": 55.0, "val_loss": 316.316650390625, "val_acc": 60.0}
{"epoch": 32, "training_loss": 503.6529052734375, "training_acc": 45.0, "val_loss": 425.4615173339844, "val_acc": 60.0}
{"epoch": 33, "training_loss": 480.14561767578124, "training_acc": 45.0, "val_loss": 424.4286193847656, "val_acc": 40.0}
{"epoch": 34, "training_loss": 440.933984375, "training_acc": 55.0, "val_loss": 1016.3436889648438, "val_acc": 40.0}
{"epoch": 35, "training_loss": 740.6358154296875, "training_acc": 55.0, "val_loss": 545.4742431640625, "val_acc": 40.0}
{"epoch": 36, "training_loss": 321.2236358642578, "training_acc": 55.0, "val_loss": 455.07696533203125, "val_acc": 60.0}
{"epoch": 37, "training_loss": 686.473583984375, "training_acc": 45.0, "val_loss": 764.7888793945312, "val_acc": 60.0}
{"epoch": 38, "training_loss": 1033.7325317382813, "training_acc": 45.0, "val_loss": 416.9069519042969, "val_acc": 60.0}
{"epoch": 39, "training_loss": 410.26731567382814, "training_acc": 45.0, "val_loss": 765.8072509765625, "val_acc": 40.0}
{"epoch": 40, "training_loss": 674.87470703125, "training_acc": 55.0, "val_loss": 1686.810546875, "val_acc": 40.0}
{"epoch": 41, "training_loss": 1289.37509765625, "training_acc": 55.0, "val_loss": 1531.966064453125, "val_acc": 40.0}
{"epoch": 42, "training_loss": 1074.89189453125, "training_acc": 55.0, "val_loss": 458.564697265625, "val_acc": 40.0}
{"epoch": 43, "training_loss": 319.53636474609374, "training_acc": 55.0, "val_loss": 521.5397338867188, "val_acc": 60.0}
