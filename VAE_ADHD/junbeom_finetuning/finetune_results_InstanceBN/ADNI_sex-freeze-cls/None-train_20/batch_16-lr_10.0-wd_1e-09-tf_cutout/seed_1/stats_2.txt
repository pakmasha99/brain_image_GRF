"main_modify.py --pretrained_path None --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 1 --task ADNI_sex --input_option yAware --learning_rate 1e1 --batch_size 16 --weight_decay 1e-9 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 428.71386709213255, "training_acc": 50.0, "val_loss": 821.4688720703125, "val_acc": 40.0}
{"epoch": 1, "training_loss": 763.0000732421875, "training_acc": 50.0, "val_loss": 1231.0615234375, "val_acc": 60.0}
{"epoch": 2, "training_loss": 1490.8099609375, "training_acc": 50.0, "val_loss": 484.3163146972656, "val_acc": 60.0}
{"epoch": 3, "training_loss": 670.8135375976562, "training_acc": 40.0, "val_loss": 777.0216064453125, "val_acc": 40.0}
{"epoch": 4, "training_loss": 617.8556640625, "training_acc": 50.0, "val_loss": 65.45503997802734, "val_acc": 40.0}
{"epoch": 5, "training_loss": 169.89910278320312, "training_acc": 50.0, "val_loss": 743.9864501953125, "val_acc": 60.0}
{"epoch": 6, "training_loss": 950.5906494140625, "training_acc": 50.0, "val_loss": 413.75, "val_acc": 60.0}
{"epoch": 7, "training_loss": 440.8640075683594, "training_acc": 50.0, "val_loss": 563.0839233398438, "val_acc": 40.0}
{"epoch": 8, "training_loss": 496.26767578125, "training_acc": 50.0, "val_loss": 354.6083679199219, "val_acc": 40.0}
{"epoch": 9, "training_loss": 268.9722534179688, "training_acc": 50.0, "val_loss": 279.1642761230469, "val_acc": 60.0}
{"epoch": 10, "training_loss": 340.96448974609376, "training_acc": 50.0, "val_loss": 23.786392211914062, "val_acc": 40.0}
{"epoch": 11, "training_loss": 56.40334014892578, "training_acc": 50.0, "val_loss": 49.9443473815918, "val_acc": 60.0}
{"epoch": 12, "training_loss": 57.12907304763794, "training_acc": 50.0, "val_loss": 160.8980712890625, "val_acc": 40.0}
{"epoch": 13, "training_loss": 119.3161735534668, "training_acc": 50.0, "val_loss": 168.9973602294922, "val_acc": 60.0}
{"epoch": 14, "training_loss": 210.642578125, "training_acc": 50.0, "val_loss": 150.2968292236328, "val_acc": 60.0}
{"epoch": 15, "training_loss": 130.98683309555054, "training_acc": 60.0, "val_loss": 88.00890350341797, "val_acc": 40.0}
{"epoch": 16, "training_loss": 44.18095703125, "training_acc": 70.0, "val_loss": 82.52203369140625, "val_acc": 60.0}
{"epoch": 17, "training_loss": 87.70924606323243, "training_acc": 50.0, "val_loss": 45.620155334472656, "val_acc": 60.0}
{"epoch": 18, "training_loss": 59.200538635253906, "training_acc": 50.0, "val_loss": 16.087299346923828, "val_acc": 60.0}
{"epoch": 19, "training_loss": 36.50455322265625, "training_acc": 50.0, "val_loss": 10.396097183227539, "val_acc": 40.0}
{"epoch": 20, "training_loss": 101.04226989746094, "training_acc": 40.0, "val_loss": 231.5388641357422, "val_acc": 60.0}
{"epoch": 21, "training_loss": 243.21030502319337, "training_acc": 50.0, "val_loss": 417.9208679199219, "val_acc": 40.0}
{"epoch": 22, "training_loss": 361.9160888671875, "training_acc": 50.0, "val_loss": 607.9683227539062, "val_acc": 40.0}
{"epoch": 23, "training_loss": 468.8101806640625, "training_acc": 50.0, "val_loss": 46.789791107177734, "val_acc": 60.0}
{"epoch": 24, "training_loss": 104.84794006347656, "training_acc": 50.0, "val_loss": 39.686405181884766, "val_acc": 60.0}
{"epoch": 25, "training_loss": 143.3487335205078, "training_acc": 40.0, "val_loss": 438.4114685058594, "val_acc": 40.0}
{"epoch": 26, "training_loss": 331.052197265625, "training_acc": 50.0, "val_loss": 130.50343322753906, "val_acc": 60.0}
{"epoch": 27, "training_loss": 185.7337158203125, "training_acc": 50.0, "val_loss": 148.6164093017578, "val_acc": 60.0}
{"epoch": 28, "training_loss": 168.3184020996094, "training_acc": 50.0, "val_loss": 193.03407287597656, "val_acc": 40.0}
{"epoch": 29, "training_loss": 177.45030212402344, "training_acc": 30.0, "val_loss": 213.8387908935547, "val_acc": 40.0}
{"epoch": 30, "training_loss": 175.88367767333983, "training_acc": 50.0, "val_loss": 34.64071273803711, "val_acc": 40.0}
{"epoch": 31, "training_loss": 78.4805404663086, "training_acc": 50.0, "val_loss": 288.7420349121094, "val_acc": 60.0}
{"epoch": 32, "training_loss": 333.53412170410155, "training_acc": 50.0, "val_loss": 97.3605728149414, "val_acc": 40.0}
{"epoch": 33, "training_loss": 114.38194580078125, "training_acc": 50.0, "val_loss": 8.379347801208496, "val_acc": 60.0}
{"epoch": 34, "training_loss": 17.53770751953125, "training_acc": 40.0, "val_loss": 180.78244018554688, "val_acc": 60.0}
{"epoch": 35, "training_loss": 242.31605224609376, "training_acc": 50.0, "val_loss": 34.69039535522461, "val_acc": 60.0}
{"epoch": 36, "training_loss": 24.716952514648437, "training_acc": 70.0, "val_loss": 786.83544921875, "val_acc": 40.0}
{"epoch": 37, "training_loss": 675.7415893554687, "training_acc": 50.0, "val_loss": 777.0891723632812, "val_acc": 40.0}
{"epoch": 38, "training_loss": 615.2741149902344, "training_acc": 50.0, "val_loss": 51.71356964111328, "val_acc": 60.0}
{"epoch": 39, "training_loss": 74.46984558105468, "training_acc": 50.0, "val_loss": 164.36685180664062, "val_acc": 60.0}
{"epoch": 40, "training_loss": 165.68924255371093, "training_acc": 50.0, "val_loss": 423.41552734375, "val_acc": 40.0}
{"epoch": 41, "training_loss": 400.447900390625, "training_acc": 50.0, "val_loss": 421.98883056640625, "val_acc": 40.0}
{"epoch": 42, "training_loss": 256.0503875732422, "training_acc": 50.0, "val_loss": 441.478515625, "val_acc": 60.0}
{"epoch": 43, "training_loss": 655.723779296875, "training_acc": 50.0, "val_loss": 737.4680786132812, "val_acc": 60.0}
{"epoch": 44, "training_loss": 899.2623168945313, "training_acc": 50.0, "val_loss": 340.56060791015625, "val_acc": 60.0}
{"epoch": 45, "training_loss": 344.9175712585449, "training_acc": 50.0, "val_loss": 294.68927001953125, "val_acc": 40.0}
{"epoch": 46, "training_loss": 242.0348098754883, "training_acc": 50.0, "val_loss": 98.78205871582031, "val_acc": 40.0}
{"epoch": 47, "training_loss": 150.5739990234375, "training_acc": 40.0, "val_loss": 213.6061553955078, "val_acc": 60.0}
{"epoch": 48, "training_loss": 242.8313129425049, "training_acc": 50.0, "val_loss": 293.9906921386719, "val_acc": 40.0}
{"epoch": 49, "training_loss": 273.5192016601562, "training_acc": 50.0, "val_loss": 142.8972625732422, "val_acc": 40.0}
{"epoch": 50, "training_loss": 150.63839721679688, "training_acc": 50.0, "val_loss": 344.69384765625, "val_acc": 60.0}
{"epoch": 51, "training_loss": 419.47393493652345, "training_acc": 50.0, "val_loss": 136.2091827392578, "val_acc": 60.0}
{"epoch": 52, "training_loss": 215.4993469238281, "training_acc": 40.0, "val_loss": 308.2037048339844, "val_acc": 40.0}
