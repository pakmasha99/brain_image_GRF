"main_modify.py --pretrained_path None --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 1 --task ADNI_sex --input_option yAware --learning_rate 1e1 --batch_size 16 --weight_decay 1e-9 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 215.4054486274719, "training_acc": 55.0, "val_loss": 789.3790893554688, "val_acc": 40.0}
{"epoch": 1, "training_loss": 506.93662109375, "training_acc": 65.0, "val_loss": 1434.254150390625, "val_acc": 60.0}
{"epoch": 2, "training_loss": 1875.7532958984375, "training_acc": 45.0, "val_loss": 280.0196228027344, "val_acc": 60.0}
{"epoch": 3, "training_loss": 502.1368408203125, "training_acc": 45.0, "val_loss": 1814.833984375, "val_acc": 40.0}
{"epoch": 4, "training_loss": 1411.52841796875, "training_acc": 55.0, "val_loss": 1528.1412353515625, "val_acc": 40.0}
{"epoch": 5, "training_loss": 1076.9390014648438, "training_acc": 55.0, "val_loss": 148.1578369140625, "val_acc": 60.0}
{"epoch": 6, "training_loss": 264.3556762695313, "training_acc": 45.0, "val_loss": 358.918701171875, "val_acc": 60.0}
{"epoch": 7, "training_loss": 376.8752868652344, "training_acc": 45.0, "val_loss": 706.53271484375, "val_acc": 40.0}
{"epoch": 8, "training_loss": 569.7771362304687, "training_acc": 55.0, "val_loss": 1478.9833984375, "val_acc": 40.0}
{"epoch": 9, "training_loss": 1131.168798828125, "training_acc": 55.0, "val_loss": 1048.4803466796875, "val_acc": 40.0}
{"epoch": 10, "training_loss": 622.0575317382812, "training_acc": 55.0, "val_loss": 384.024658203125, "val_acc": 60.0}
{"epoch": 11, "training_loss": 622.233740234375, "training_acc": 45.0, "val_loss": 922.1840209960938, "val_acc": 60.0}
{"epoch": 12, "training_loss": 1257.4487548828124, "training_acc": 45.0, "val_loss": 614.7815551757812, "val_acc": 60.0}
{"epoch": 13, "training_loss": 736.2442169189453, "training_acc": 45.0, "val_loss": 571.6026611328125, "val_acc": 40.0}
{"epoch": 14, "training_loss": 569.95517578125, "training_acc": 55.0, "val_loss": 1273.1939697265625, "val_acc": 40.0}
{"epoch": 15, "training_loss": 943.1036804199218, "training_acc": 55.0, "val_loss": 907.0635986328125, "val_acc": 40.0}
{"epoch": 16, "training_loss": 607.0863891601563, "training_acc": 55.0, "val_loss": 108.0033187866211, "val_acc": 60.0}
{"epoch": 17, "training_loss": 230.14871826171876, "training_acc": 45.0, "val_loss": 272.6385192871094, "val_acc": 60.0}
{"epoch": 18, "training_loss": 318.08798751831057, "training_acc": 45.0, "val_loss": 485.1875915527344, "val_acc": 40.0}
{"epoch": 19, "training_loss": 441.7462890625, "training_acc": 55.0, "val_loss": 720.81103515625, "val_acc": 40.0}
{"epoch": 20, "training_loss": 491.89149169921876, "training_acc": 55.0, "val_loss": 39.41843795776367, "val_acc": 60.0}
{"epoch": 21, "training_loss": 67.2772720336914, "training_acc": 45.0, "val_loss": 142.59974670410156, "val_acc": 60.0}
{"epoch": 22, "training_loss": 197.70401000976562, "training_acc": 35.0, "val_loss": 12.59030818939209, "val_acc": 60.0}
{"epoch": 23, "training_loss": 41.786093139648436, "training_acc": 45.0, "val_loss": 83.47859954833984, "val_acc": 40.0}
{"epoch": 24, "training_loss": 54.364190673828126, "training_acc": 65.0, "val_loss": 178.51171875, "val_acc": 60.0}
{"epoch": 25, "training_loss": 229.63374862670898, "training_acc": 45.0, "val_loss": 245.8601531982422, "val_acc": 40.0}
{"epoch": 26, "training_loss": 207.33428344726562, "training_acc": 55.0, "val_loss": 67.37360382080078, "val_acc": 40.0}
{"epoch": 27, "training_loss": 148.9852783203125, "training_acc": 45.0, "val_loss": 331.242431640625, "val_acc": 60.0}
{"epoch": 28, "training_loss": 414.1788818359375, "training_acc": 45.0, "val_loss": 177.7330322265625, "val_acc": 40.0}
{"epoch": 29, "training_loss": 150.07050170898438, "training_acc": 55.0, "val_loss": 476.5390625, "val_acc": 40.0}
{"epoch": 30, "training_loss": 328.51673583984376, "training_acc": 55.0, "val_loss": 55.681396484375, "val_acc": 60.0}
{"epoch": 31, "training_loss": 100.59216918945313, "training_acc": 45.0, "val_loss": 74.8080062866211, "val_acc": 60.0}
{"epoch": 32, "training_loss": 93.52171478271484, "training_acc": 55.0, "val_loss": 412.1453552246094, "val_acc": 40.0}
{"epoch": 33, "training_loss": 301.8369201660156, "training_acc": 55.0, "val_loss": 155.74708557128906, "val_acc": 40.0}
{"epoch": 34, "training_loss": 165.2461730957031, "training_acc": 45.0, "val_loss": 170.00851440429688, "val_acc": 60.0}
{"epoch": 35, "training_loss": 222.61864776611327, "training_acc": 35.0, "val_loss": 35.371578216552734, "val_acc": 60.0}
{"epoch": 36, "training_loss": 60.96419830322266, "training_acc": 45.0, "val_loss": 55.904457092285156, "val_acc": 40.0}
{"epoch": 37, "training_loss": 97.356689453125, "training_acc": 45.0, "val_loss": 107.08919525146484, "val_acc": 60.0}
{"epoch": 38, "training_loss": 151.08011169433593, "training_acc": 45.0, "val_loss": 249.4918670654297, "val_acc": 40.0}
{"epoch": 39, "training_loss": 170.5922538757324, "training_acc": 55.0, "val_loss": 130.7510223388672, "val_acc": 60.0}
{"epoch": 40, "training_loss": 183.71241455078126, "training_acc": 45.0, "val_loss": 138.19320678710938, "val_acc": 40.0}
{"epoch": 41, "training_loss": 134.94781494140625, "training_acc": 55.0, "val_loss": 39.32244873046875, "val_acc": 40.0}
