"main_modify.py --pretrained_path None --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 5 --task ADNI_sex --input_option yAware --learning_rate 1e2 --batch_size 16 --weight_decay 1e-2 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 8562.526534986497, "training_acc": 30.0, "val_loss": 5145.51708984375, "val_acc": 60.0}
{"epoch": 1, "training_loss": 8547.015234375, "training_acc": 40.0, "val_loss": 18308.53515625, "val_acc": 40.0}
{"epoch": 2, "training_loss": 15028.2306640625, "training_acc": 50.0, "val_loss": 10390.9580078125, "val_acc": 40.0}
{"epoch": 3, "training_loss": 5691.07744140625, "training_acc": 50.0, "val_loss": 5923.05078125, "val_acc": 60.0}
{"epoch": 4, "training_loss": 7875.591796875, "training_acc": 50.0, "val_loss": 10720.3134765625, "val_acc": 60.0}
{"epoch": 5, "training_loss": 13386.934375, "training_acc": 50.0, "val_loss": 5255.77685546875, "val_acc": 60.0}
{"epoch": 6, "training_loss": 5409.48271484375, "training_acc": 50.0, "val_loss": 6421.15380859375, "val_acc": 40.0}
{"epoch": 7, "training_loss": 5708.42900390625, "training_acc": 50.0, "val_loss": 12224.8642578125, "val_acc": 40.0}
{"epoch": 8, "training_loss": 9890.0958984375, "training_acc": 50.0, "val_loss": 6200.6845703125, "val_acc": 40.0}
{"epoch": 9, "training_loss": 3739.461962890625, "training_acc": 50.0, "val_loss": 4082.28125, "val_acc": 60.0}
{"epoch": 10, "training_loss": 5419.941796875, "training_acc": 50.0, "val_loss": 7529.05029296875, "val_acc": 60.0}
{"epoch": 11, "training_loss": 9017.1095703125, "training_acc": 50.0, "val_loss": 3599.65087890625, "val_acc": 60.0}
{"epoch": 12, "training_loss": 3651.8996704101564, "training_acc": 50.0, "val_loss": 4577.9140625, "val_acc": 40.0}
{"epoch": 13, "training_loss": 4169.8060546875, "training_acc": 50.0, "val_loss": 6586.71728515625, "val_acc": 40.0}
{"epoch": 14, "training_loss": 4973.81904296875, "training_acc": 50.0, "val_loss": 526.2098999023438, "val_acc": 40.0}
{"epoch": 15, "training_loss": 1039.57119140625, "training_acc": 50.0, "val_loss": 4473.12890625, "val_acc": 60.0}
{"epoch": 16, "training_loss": 5594.6283203125, "training_acc": 50.0, "val_loss": 3484.27197265625, "val_acc": 60.0}
{"epoch": 17, "training_loss": 4067.1239624023438, "training_acc": 50.0, "val_loss": 2081.500732421875, "val_acc": 40.0}
{"epoch": 18, "training_loss": 2101.272265625, "training_acc": 50.0, "val_loss": 4535.86962890625, "val_acc": 40.0}
{"epoch": 19, "training_loss": 3517.229296875, "training_acc": 50.0, "val_loss": 25.961347579956055, "val_acc": 40.0}
{"epoch": 20, "training_loss": 960.5066925048828, "training_acc": 40.0, "val_loss": 3336.271240234375, "val_acc": 60.0}
{"epoch": 21, "training_loss": 4087.9528076171873, "training_acc": 50.0, "val_loss": 1320.1365966796875, "val_acc": 60.0}
{"epoch": 22, "training_loss": 1840.6036376953125, "training_acc": 40.0, "val_loss": 2717.432373046875, "val_acc": 40.0}
{"epoch": 23, "training_loss": 2201.7845458984375, "training_acc": 50.0, "val_loss": 537.3078002929688, "val_acc": 40.0}
{"epoch": 24, "training_loss": 731.514453125, "training_acc": 50.0, "val_loss": 2192.609130859375, "val_acc": 60.0}
{"epoch": 25, "training_loss": 2584.645703125, "training_acc": 50.0, "val_loss": 15.281432151794434, "val_acc": 60.0}
{"epoch": 26, "training_loss": 289.3329879760742, "training_acc": 60.0, "val_loss": 5151.04052734375, "val_acc": 40.0}
{"epoch": 27, "training_loss": 4214.15732421875, "training_acc": 50.0, "val_loss": 1998.650390625, "val_acc": 40.0}
{"epoch": 28, "training_loss": 2044.623291015625, "training_acc": 40.0, "val_loss": 2603.719970703125, "val_acc": 60.0}
{"epoch": 29, "training_loss": 3213.8239990234374, "training_acc": 50.0, "val_loss": 1194.66162109375, "val_acc": 60.0}
{"epoch": 30, "training_loss": 1130.31689453125, "training_acc": 60.0, "val_loss": 2831.326171875, "val_acc": 40.0}
{"epoch": 31, "training_loss": 2346.92021484375, "training_acc": 50.0, "val_loss": 1004.8796997070312, "val_acc": 40.0}
{"epoch": 32, "training_loss": 988.73642578125, "training_acc": 50.0, "val_loss": 2020.78515625, "val_acc": 60.0}
{"epoch": 33, "training_loss": 2396.49052734375, "training_acc": 50.0, "val_loss": 38.44485092163086, "val_acc": 40.0}
{"epoch": 34, "training_loss": 187.8975402832031, "training_acc": 50.0, "val_loss": 460.2496643066406, "val_acc": 40.0}
{"epoch": 35, "training_loss": 695.856298828125, "training_acc": 40.0, "val_loss": 696.2284545898438, "val_acc": 60.0}
{"epoch": 36, "training_loss": 652.4253448486328, "training_acc": 60.0, "val_loss": 1249.8880615234375, "val_acc": 40.0}
{"epoch": 37, "training_loss": 962.0658309936523, "training_acc": 50.0, "val_loss": 809.74560546875, "val_acc": 60.0}
{"epoch": 38, "training_loss": 991.0566772460937, "training_acc": 50.0, "val_loss": 51.54836654663086, "val_acc": 40.0}
{"epoch": 39, "training_loss": 73.25711669921876, "training_acc": 50.0, "val_loss": 771.5853271484375, "val_acc": 40.0}
{"epoch": 40, "training_loss": 560.4934814453125, "training_acc": 50.0, "val_loss": 1190.1424560546875, "val_acc": 60.0}
{"epoch": 41, "training_loss": 1504.4671508789063, "training_acc": 50.0, "val_loss": 764.93017578125, "val_acc": 60.0}
{"epoch": 42, "training_loss": 952.7581787109375, "training_acc": 50.0, "val_loss": 1691.987548828125, "val_acc": 40.0}
{"epoch": 43, "training_loss": 1302.0125671386718, "training_acc": 50.0, "val_loss": 985.9606323242188, "val_acc": 60.0}
{"epoch": 44, "training_loss": 1248.6742919921876, "training_acc": 50.0, "val_loss": 30.18023109436035, "val_acc": 60.0}
