"main_modify.py --pretrained_path None --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 5 --task ADNI_sex --input_option yAware --learning_rate 1e2 --batch_size 16 --weight_decay 1e-2 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 4272.669423294067, "training_acc": 50.0, "val_loss": 7210.12255859375, "val_acc": 40.0}
{"epoch": 1, "training_loss": 6825.3791015625, "training_acc": 50.0, "val_loss": 12858.9248046875, "val_acc": 60.0}
{"epoch": 2, "training_loss": 15619.821484375, "training_acc": 50.0, "val_loss": 5861.79833984375, "val_acc": 60.0}
{"epoch": 3, "training_loss": 5227.644958496094, "training_acc": 60.0, "val_loss": 9103.5732421875, "val_acc": 40.0}
{"epoch": 4, "training_loss": 8141.3833984375, "training_acc": 50.0, "val_loss": 11422.4990234375, "val_acc": 40.0}
{"epoch": 5, "training_loss": 8780.99462890625, "training_acc": 50.0, "val_loss": 612.1837158203125, "val_acc": 40.0}
{"epoch": 6, "training_loss": 1464.315966796875, "training_acc": 50.0, "val_loss": 6787.42822265625, "val_acc": 60.0}
{"epoch": 7, "training_loss": 8532.934375, "training_acc": 50.0, "val_loss": 5171.80615234375, "val_acc": 60.0}
{"epoch": 8, "training_loss": 5260.01728515625, "training_acc": 50.0, "val_loss": 3423.59375, "val_acc": 40.0}
{"epoch": 9, "training_loss": 3180.0443359375, "training_acc": 50.0, "val_loss": 9050.3876953125, "val_acc": 40.0}
{"epoch": 10, "training_loss": 7537.246875, "training_acc": 50.0, "val_loss": 4880.8115234375, "val_acc": 40.0}
{"epoch": 11, "training_loss": 3001.786584472656, "training_acc": 50.0, "val_loss": 3228.393798828125, "val_acc": 60.0}
{"epoch": 12, "training_loss": 4534.90703125, "training_acc": 50.0, "val_loss": 5385.30419921875, "val_acc": 60.0}
{"epoch": 13, "training_loss": 6176.57294921875, "training_acc": 50.0, "val_loss": 889.77197265625, "val_acc": 60.0}
{"epoch": 14, "training_loss": 1563.7919921875, "training_acc": 50.0, "val_loss": 7150.38134765625, "val_acc": 40.0}
{"epoch": 15, "training_loss": 6025.043359375, "training_acc": 50.0, "val_loss": 5515.67529296875, "val_acc": 40.0}
{"epoch": 16, "training_loss": 4257.978894042969, "training_acc": 50.0, "val_loss": 1985.7396240234375, "val_acc": 60.0}
{"epoch": 17, "training_loss": 3379.7470703125, "training_acc": 50.0, "val_loss": 3308.42578125, "val_acc": 60.0}
{"epoch": 18, "training_loss": 3694.3982666015627, "training_acc": 50.0, "val_loss": 1522.5369873046875, "val_acc": 40.0}
{"epoch": 19, "training_loss": 1436.7932373046874, "training_acc": 50.0, "val_loss": 4185.57275390625, "val_acc": 40.0}
{"epoch": 20, "training_loss": 3267.463671875, "training_acc": 50.0, "val_loss": 56.6861572265625, "val_acc": 40.0}
{"epoch": 21, "training_loss": 971.5122253417969, "training_acc": 40.0, "val_loss": 3176.3720703125, "val_acc": 60.0}
{"epoch": 22, "training_loss": 3730.6349609375, "training_acc": 50.0, "val_loss": 392.1246032714844, "val_acc": 60.0}
{"epoch": 23, "training_loss": 626.9725341796875, "training_acc": 60.0, "val_loss": 5796.58935546875, "val_acc": 40.0}
{"epoch": 24, "training_loss": 4806.35947265625, "training_acc": 50.0, "val_loss": 3295.77392578125, "val_acc": 40.0}
{"epoch": 25, "training_loss": 2299.9105834960938, "training_acc": 50.0, "val_loss": 1962.0960693359375, "val_acc": 60.0}
{"epoch": 26, "training_loss": 2576.5625, "training_acc": 50.0, "val_loss": 1003.9846801757812, "val_acc": 60.0}
{"epoch": 27, "training_loss": 1285.000732421875, "training_acc": 50.0, "val_loss": 3101.4306640625, "val_acc": 40.0}
{"epoch": 28, "training_loss": 2495.877587890625, "training_acc": 50.0, "val_loss": 418.66876220703125, "val_acc": 40.0}
{"epoch": 29, "training_loss": 1043.2708251953125, "training_acc": 40.0, "val_loss": 2387.027099609375, "val_acc": 60.0}
{"epoch": 30, "training_loss": 2634.609765625, "training_acc": 50.0, "val_loss": 1247.0228271484375, "val_acc": 40.0}
{"epoch": 31, "training_loss": 1573.74765625, "training_acc": 50.0, "val_loss": 2844.518798828125, "val_acc": 40.0}
{"epoch": 32, "training_loss": 1835.9529541015625, "training_acc": 50.0, "val_loss": 2083.105224609375, "val_acc": 60.0}
{"epoch": 33, "training_loss": 2869.30791015625, "training_acc": 50.0, "val_loss": 2644.01953125, "val_acc": 60.0}
{"epoch": 34, "training_loss": 2844.38232421875, "training_acc": 50.0, "val_loss": 2711.2451171875, "val_acc": 40.0}
{"epoch": 35, "training_loss": 2391.837353515625, "training_acc": 50.0, "val_loss": 4221.9443359375, "val_acc": 40.0}
{"epoch": 36, "training_loss": 3316.8828125, "training_acc": 50.0, "val_loss": 885.2963256835938, "val_acc": 60.0}
{"epoch": 37, "training_loss": 1206.20361328125, "training_acc": 50.0, "val_loss": 1626.0823974609375, "val_acc": 60.0}
{"epoch": 38, "training_loss": 1863.5409729003907, "training_acc": 50.0, "val_loss": 2104.985107421875, "val_acc": 40.0}
{"epoch": 39, "training_loss": 1787.9330810546876, "training_acc": 50.0, "val_loss": 1707.6429443359375, "val_acc": 40.0}
