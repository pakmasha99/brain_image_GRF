"main_modify.py --pretrained_path None --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 5 --task ADNI_sex --input_option yAware --learning_rate 1e2 --batch_size 16 --weight_decay 1e-2 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 8551.086825609207, "training_acc": 45.0, "val_loss": 4571.1796875, "val_acc": 60.0}
{"epoch": 1, "training_loss": 5580.5869140625, "training_acc": 55.0, "val_loss": 21287.703125, "val_acc": 40.0}
{"epoch": 2, "training_loss": 15806.47734375, "training_acc": 55.0, "val_loss": 13357.9443359375, "val_acc": 40.0}
{"epoch": 3, "training_loss": 8376.746142578126, "training_acc": 55.0, "val_loss": 4669.15771484375, "val_acc": 60.0}
{"epoch": 4, "training_loss": 7478.89453125, "training_acc": 45.0, "val_loss": 10062.9169921875, "val_acc": 60.0}
{"epoch": 5, "training_loss": 13419.0029296875, "training_acc": 45.0, "val_loss": 4794.82861328125, "val_acc": 60.0}
{"epoch": 6, "training_loss": 6001.622928619385, "training_acc": 35.0, "val_loss": 5104.49609375, "val_acc": 40.0}
{"epoch": 7, "training_loss": 4297.106640625, "training_acc": 55.0, "val_loss": 8108.6640625, "val_acc": 40.0}
{"epoch": 8, "training_loss": 5477.22265625, "training_acc": 55.0, "val_loss": 1790.5325927734375, "val_acc": 40.0}
{"epoch": 9, "training_loss": 2550.41787109375, "training_acc": 35.0, "val_loss": 4014.180419921875, "val_acc": 60.0}
{"epoch": 10, "training_loss": 5516.379443359375, "training_acc": 45.0, "val_loss": 3027.562255859375, "val_acc": 60.0}
{"epoch": 11, "training_loss": 3404.7112548828127, "training_acc": 45.0, "val_loss": 2866.648193359375, "val_acc": 40.0}
{"epoch": 12, "training_loss": 2592.543359375, "training_acc": 55.0, "val_loss": 6054.70654296875, "val_acc": 40.0}
{"epoch": 13, "training_loss": 4308.675, "training_acc": 55.0, "val_loss": 1649.4742431640625, "val_acc": 40.0}
{"epoch": 14, "training_loss": 1678.989599609375, "training_acc": 45.0, "val_loss": 2714.796875, "val_acc": 60.0}
{"epoch": 15, "training_loss": 3694.456298828125, "training_acc": 45.0, "val_loss": 1348.0369873046875, "val_acc": 60.0}
{"epoch": 16, "training_loss": 1429.3124938964843, "training_acc": 55.0, "val_loss": 3040.084228515625, "val_acc": 40.0}
{"epoch": 17, "training_loss": 2355.13134765625, "training_acc": 55.0, "val_loss": 2258.856201171875, "val_acc": 40.0}
{"epoch": 18, "training_loss": 1131.3215713500977, "training_acc": 65.0, "val_loss": 1066.0228271484375, "val_acc": 60.0}
{"epoch": 19, "training_loss": 1452.310205078125, "training_acc": 45.0, "val_loss": 341.2828674316406, "val_acc": 60.0}
{"epoch": 20, "training_loss": 650.6752197265625, "training_acc": 45.0, "val_loss": 2159.53759765625, "val_acc": 40.0}
{"epoch": 21, "training_loss": 1480.331884765625, "training_acc": 55.0, "val_loss": 506.47607421875, "val_acc": 60.0}
{"epoch": 22, "training_loss": 963.2017578125, "training_acc": 45.0, "val_loss": 172.1706085205078, "val_acc": 40.0}
{"epoch": 23, "training_loss": 228.0590087890625, "training_acc": 55.0, "val_loss": 58.71441650390625, "val_acc": 40.0}
{"epoch": 24, "training_loss": 147.52130737304688, "training_acc": 65.0, "val_loss": 1275.9141845703125, "val_acc": 60.0}
{"epoch": 25, "training_loss": 1552.8763916015625, "training_acc": 45.0, "val_loss": 1644.6373291015625, "val_acc": 40.0}
{"epoch": 26, "training_loss": 1469.1869140625, "training_acc": 55.0, "val_loss": 1197.2484130859375, "val_acc": 40.0}
{"epoch": 27, "training_loss": 1162.2208984375, "training_acc": 45.0, "val_loss": 1220.0179443359375, "val_acc": 60.0}
{"epoch": 28, "training_loss": 1452.5596923828125, "training_acc": 45.0, "val_loss": 1995.435546875, "val_acc": 40.0}
{"epoch": 29, "training_loss": 1550.85, "training_acc": 55.0, "val_loss": 2073.295166015625, "val_acc": 40.0}
{"epoch": 30, "training_loss": 1400.2315307617187, "training_acc": 45.0, "val_loss": 150.97531127929688, "val_acc": 60.0}
{"epoch": 31, "training_loss": 223.57960205078126, "training_acc": 55.0, "val_loss": 1077.4515380859375, "val_acc": 40.0}
{"epoch": 32, "training_loss": 763.0416198730469, "training_acc": 45.0, "val_loss": 537.9547119140625, "val_acc": 40.0}
{"epoch": 33, "training_loss": 314.38981885910033, "training_acc": 55.0, "val_loss": 1133.06005859375, "val_acc": 60.0}
{"epoch": 34, "training_loss": 1538.4320068359375, "training_acc": 45.0, "val_loss": 658.9866943359375, "val_acc": 40.0}
{"epoch": 35, "training_loss": 740.5451171875, "training_acc": 55.0, "val_loss": 297.04486083984375, "val_acc": 40.0}
{"epoch": 36, "training_loss": 309.1474609375, "training_acc": 65.0, "val_loss": 1911.8768310546875, "val_acc": 60.0}
{"epoch": 37, "training_loss": 2421.76669921875, "training_acc": 45.0, "val_loss": 1131.3218994140625, "val_acc": 40.0}
{"epoch": 38, "training_loss": 1168.18974609375, "training_acc": 55.0, "val_loss": 1092.316650390625, "val_acc": 40.0}
{"epoch": 39, "training_loss": 655.53525390625, "training_acc": 65.0, "val_loss": 1695.280517578125, "val_acc": 60.0}
{"epoch": 40, "training_loss": 2132.837646484375, "training_acc": 45.0, "val_loss": 1309.7073974609375, "val_acc": 40.0}
{"epoch": 41, "training_loss": 1202.2404296875, "training_acc": 55.0, "val_loss": 1893.8773193359375, "val_acc": 40.0}
{"epoch": 42, "training_loss": 1395.25556640625, "training_acc": 45.0, "val_loss": 422.7205505371094, "val_acc": 60.0}
