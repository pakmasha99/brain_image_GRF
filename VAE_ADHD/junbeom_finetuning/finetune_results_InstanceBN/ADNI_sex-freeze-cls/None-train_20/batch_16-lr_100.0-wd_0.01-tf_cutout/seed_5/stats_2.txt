"main_modify.py --pretrained_path None --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 5 --task ADNI_sex --input_option yAware --learning_rate 1e2 --batch_size 16 --weight_decay 1e-2 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 4288.910311412811, "training_acc": 50.0, "val_loss": 4464.82861328125, "val_acc": 60.0}
{"epoch": 1, "training_loss": 4978.12861328125, "training_acc": 60.0, "val_loss": 20918.896484375, "val_acc": 40.0}
{"epoch": 2, "training_loss": 17194.79755859375, "training_acc": 50.0, "val_loss": 10306.556640625, "val_acc": 40.0}
{"epoch": 3, "training_loss": 6886.962060546875, "training_acc": 50.0, "val_loss": 5253.89697265625, "val_acc": 60.0}
{"epoch": 4, "training_loss": 7180.407421875, "training_acc": 50.0, "val_loss": 7238.13232421875, "val_acc": 60.0}
{"epoch": 5, "training_loss": 8716.436376953125, "training_acc": 50.0, "val_loss": 782.9325561523438, "val_acc": 60.0}
{"epoch": 6, "training_loss": 1649.96640625, "training_acc": 50.0, "val_loss": 8711.111328125, "val_acc": 40.0}
{"epoch": 7, "training_loss": 7443.7609375, "training_acc": 50.0, "val_loss": 5891.85107421875, "val_acc": 40.0}
{"epoch": 8, "training_loss": 3645.57529296875, "training_acc": 50.0, "val_loss": 3608.51171875, "val_acc": 60.0}
{"epoch": 9, "training_loss": 4801.80009765625, "training_acc": 50.0, "val_loss": 6475.08447265625, "val_acc": 60.0}
{"epoch": 10, "training_loss": 7625.3263671875, "training_acc": 50.0, "val_loss": 2105.65771484375, "val_acc": 60.0}
{"epoch": 11, "training_loss": 2546.7876953125, "training_acc": 50.0, "val_loss": 6367.48193359375, "val_acc": 40.0}
{"epoch": 12, "training_loss": 5500.766796875, "training_acc": 50.0, "val_loss": 6175.59033203125, "val_acc": 40.0}
{"epoch": 13, "training_loss": 4580.90322265625, "training_acc": 50.0, "val_loss": 1197.308837890625, "val_acc": 60.0}
{"epoch": 14, "training_loss": 1966.2076171875, "training_acc": 50.0, "val_loss": 3489.849365234375, "val_acc": 60.0}
{"epoch": 15, "training_loss": 4236.819116210938, "training_acc": 50.0, "val_loss": 676.7582397460938, "val_acc": 60.0}
{"epoch": 16, "training_loss": 1116.191845703125, "training_acc": 50.0, "val_loss": 4370.921875, "val_acc": 40.0}
{"epoch": 17, "training_loss": 3590.20283203125, "training_acc": 50.0, "val_loss": 1582.915283203125, "val_acc": 40.0}
{"epoch": 18, "training_loss": 2119.176806640625, "training_acc": 30.0, "val_loss": 2250.60009765625, "val_acc": 60.0}
{"epoch": 19, "training_loss": 2735.2428955078126, "training_acc": 50.0, "val_loss": 330.49468994140625, "val_acc": 60.0}
{"epoch": 20, "training_loss": 1010.253759765625, "training_acc": 40.0, "val_loss": 3160.451416015625, "val_acc": 40.0}
{"epoch": 21, "training_loss": 2371.297265625, "training_acc": 50.0, "val_loss": 606.0521850585938, "val_acc": 60.0}
{"epoch": 22, "training_loss": 1334.8572265625, "training_acc": 50.0, "val_loss": 955.7999877929688, "val_acc": 60.0}
{"epoch": 23, "training_loss": 1376.85556640625, "training_acc": 40.0, "val_loss": 1656.9810791015625, "val_acc": 40.0}
{"epoch": 24, "training_loss": 1152.01669921875, "training_acc": 50.0, "val_loss": 1286.8973388671875, "val_acc": 60.0}
{"epoch": 25, "training_loss": 1672.8617919921876, "training_acc": 50.0, "val_loss": 1465.5550537109375, "val_acc": 60.0}
{"epoch": 26, "training_loss": 1876.3962768554688, "training_acc": 30.0, "val_loss": 69.7464370727539, "val_acc": 60.0}
{"epoch": 27, "training_loss": 121.24918823242187, "training_acc": 60.0, "val_loss": 730.5042114257812, "val_acc": 40.0}
{"epoch": 28, "training_loss": 586.6993347167969, "training_acc": 50.0, "val_loss": 324.52734375, "val_acc": 60.0}
{"epoch": 29, "training_loss": 630.714013671875, "training_acc": 40.0, "val_loss": 432.58349609375, "val_acc": 40.0}
{"epoch": 30, "training_loss": 527.225537109375, "training_acc": 50.0, "val_loss": 1061.7509765625, "val_acc": 60.0}
{"epoch": 31, "training_loss": 1009.3532958984375, "training_acc": 50.0, "val_loss": 2740.26953125, "val_acc": 40.0}
{"epoch": 32, "training_loss": 2347.2186767578123, "training_acc": 50.0, "val_loss": 2781.487548828125, "val_acc": 40.0}
{"epoch": 33, "training_loss": 2094.885553741455, "training_acc": 50.0, "val_loss": 1971.33203125, "val_acc": 60.0}
{"epoch": 34, "training_loss": 2608.624755859375, "training_acc": 50.0, "val_loss": 1617.03369140625, "val_acc": 60.0}
{"epoch": 35, "training_loss": 1723.6693969726562, "training_acc": 50.0, "val_loss": 1985.914306640625, "val_acc": 40.0}
{"epoch": 36, "training_loss": 1568.0505859375, "training_acc": 50.0, "val_loss": 639.9137573242188, "val_acc": 60.0}
{"epoch": 37, "training_loss": 859.0676879882812, "training_acc": 50.0, "val_loss": 832.3453369140625, "val_acc": 60.0}
{"epoch": 38, "training_loss": 773.8048126220704, "training_acc": 60.0, "val_loss": 1379.8973388671875, "val_acc": 40.0}
{"epoch": 39, "training_loss": 1004.6938720703125, "training_acc": 50.0, "val_loss": 1133.5355224609375, "val_acc": 60.0}
{"epoch": 40, "training_loss": 1527.973388671875, "training_acc": 50.0, "val_loss": 35.13166427612305, "val_acc": 60.0}
{"epoch": 41, "training_loss": 872.3945861816406, "training_acc": 40.0, "val_loss": 3586.868896484375, "val_acc": 40.0}
{"epoch": 42, "training_loss": 2661.61591796875, "training_acc": 50.0, "val_loss": 1238.464599609375, "val_acc": 60.0}
{"epoch": 43, "training_loss": 1650.8566162109375, "training_acc": 50.0, "val_loss": 1814.0936279296875, "val_acc": 60.0}
{"epoch": 44, "training_loss": 1886.3536743164063, "training_acc": 50.0, "val_loss": 3114.46533203125, "val_acc": 40.0}
{"epoch": 45, "training_loss": 2903.719921875, "training_acc": 50.0, "val_loss": 2370.93505859375, "val_acc": 40.0}
{"epoch": 46, "training_loss": 2155.1846923828125, "training_acc": 40.0, "val_loss": 1742.3013916015625, "val_acc": 60.0}
{"epoch": 47, "training_loss": 2014.4745361328125, "training_acc": 50.0, "val_loss": 1040.3892822265625, "val_acc": 40.0}
{"epoch": 48, "training_loss": 1105.7357421875, "training_acc": 50.0, "val_loss": 323.04180908203125, "val_acc": 40.0}
{"epoch": 49, "training_loss": 653.9497802734375, "training_acc": 50.0, "val_loss": 2174.708740234375, "val_acc": 60.0}
{"epoch": 50, "training_loss": 2573.8303344726564, "training_acc": 50.0, "val_loss": 1188.540283203125, "val_acc": 40.0}
{"epoch": 51, "training_loss": 1037.3107299804688, "training_acc": 50.0, "val_loss": 1120.8056640625, "val_acc": 40.0}
{"epoch": 52, "training_loss": 933.6655151367188, "training_acc": 50.0, "val_loss": 975.4638671875, "val_acc": 60.0}
{"epoch": 53, "training_loss": 978.6916271209717, "training_acc": 50.0, "val_loss": 2702.927734375, "val_acc": 40.0}
{"epoch": 54, "training_loss": 2383.064501953125, "training_acc": 50.0, "val_loss": 774.3414306640625, "val_acc": 40.0}
{"epoch": 55, "training_loss": 1022.84375, "training_acc": 50.0, "val_loss": 2853.5322265625, "val_acc": 60.0}
{"epoch": 56, "training_loss": 3441.5203857421875, "training_acc": 50.0, "val_loss": 106.0220947265625, "val_acc": 40.0}
{"epoch": 57, "training_loss": 88.244873046875, "training_acc": 50.0, "val_loss": 1316.607421875, "val_acc": 40.0}
{"epoch": 58, "training_loss": 1041.9418701171876, "training_acc": 40.0, "val_loss": 585.8323974609375, "val_acc": 40.0}
{"epoch": 59, "training_loss": 695.7206298828125, "training_acc": 30.0, "val_loss": 1295.5296630859375, "val_acc": 40.0}
