"main_modify.py --pretrained_path None --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 5 --task ADNI_sex --input_option yAware --learning_rate 1e2 --batch_size 16 --weight_decay 1e-2 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 8540.330659389496, "training_acc": 25.0, "val_loss": 7569.8125, "val_acc": 40.0}
{"epoch": 1, "training_loss": 3155.208203125, "training_acc": 75.0, "val_loss": 13848.9794921875, "val_acc": 60.0}
{"epoch": 2, "training_loss": 18955.5765625, "training_acc": 45.0, "val_loss": 8584.4765625, "val_acc": 60.0}
{"epoch": 3, "training_loss": 11802.7796875, "training_acc": 45.0, "val_loss": 7615.9619140625, "val_acc": 40.0}
{"epoch": 4, "training_loss": 6208.61201171875, "training_acc": 55.0, "val_loss": 15407.3310546875, "val_acc": 40.0}
{"epoch": 5, "training_loss": 11375.7875, "training_acc": 55.0, "val_loss": 8368.4091796875, "val_acc": 40.0}
{"epoch": 6, "training_loss": 5722.230493164063, "training_acc": 55.0, "val_loss": 3405.318115234375, "val_acc": 60.0}
{"epoch": 7, "training_loss": 6138.8845703125, "training_acc": 45.0, "val_loss": 6544.3017578125, "val_acc": 60.0}
{"epoch": 8, "training_loss": 8792.526513671875, "training_acc": 45.0, "val_loss": 2291.282958984375, "val_acc": 60.0}
{"epoch": 9, "training_loss": 2422.9285522460937, "training_acc": 55.0, "val_loss": 5403.92236328125, "val_acc": 40.0}
{"epoch": 10, "training_loss": 4188.3830078125, "training_acc": 55.0, "val_loss": 6823.20947265625, "val_acc": 40.0}
{"epoch": 11, "training_loss": 5120.798828125, "training_acc": 55.0, "val_loss": 1531.1649169921875, "val_acc": 40.0}
{"epoch": 12, "training_loss": 1261.1903564453125, "training_acc": 55.0, "val_loss": 2847.51416015625, "val_acc": 60.0}
{"epoch": 13, "training_loss": 3925.8716796875, "training_acc": 45.0, "val_loss": 1777.5582275390625, "val_acc": 60.0}
{"epoch": 14, "training_loss": 2064.209844970703, "training_acc": 45.0, "val_loss": 2126.263427734375, "val_acc": 40.0}
{"epoch": 15, "training_loss": 1614.5962036132812, "training_acc": 55.0, "val_loss": 1640.951171875, "val_acc": 40.0}
{"epoch": 16, "training_loss": 986.6558532714844, "training_acc": 55.0, "val_loss": 527.9390869140625, "val_acc": 60.0}
{"epoch": 17, "training_loss": 605.8848266601562, "training_acc": 45.0, "val_loss": 1610.3837890625, "val_acc": 40.0}
{"epoch": 18, "training_loss": 1401.47197265625, "training_acc": 55.0, "val_loss": 241.19224548339844, "val_acc": 40.0}
{"epoch": 19, "training_loss": 813.7161376953125, "training_acc": 45.0, "val_loss": 2081.306640625, "val_acc": 60.0}
{"epoch": 20, "training_loss": 2641.563232421875, "training_acc": 45.0, "val_loss": 796.8378295898438, "val_acc": 40.0}
{"epoch": 21, "training_loss": 693.0864135742188, "training_acc": 55.0, "val_loss": 2053.7578125, "val_acc": 40.0}
{"epoch": 22, "training_loss": 1426.0232238769531, "training_acc": 55.0, "val_loss": 845.2843017578125, "val_acc": 60.0}
{"epoch": 23, "training_loss": 1206.442431640625, "training_acc": 45.0, "val_loss": 238.6527862548828, "val_acc": 60.0}
{"epoch": 24, "training_loss": 396.21875, "training_acc": 55.0, "val_loss": 2977.8671875, "val_acc": 40.0}
{"epoch": 25, "training_loss": 2234.7595703125, "training_acc": 55.0, "val_loss": 808.548828125, "val_acc": 40.0}
{"epoch": 26, "training_loss": 518.6233032226562, "training_acc": 65.0, "val_loss": 1645.4771728515625, "val_acc": 60.0}
{"epoch": 27, "training_loss": 2123.3516845703125, "training_acc": 45.0, "val_loss": 653.2802124023438, "val_acc": 40.0}
{"epoch": 28, "training_loss": 640.1489990234375, "training_acc": 55.0, "val_loss": 842.5617065429688, "val_acc": 40.0}
{"epoch": 29, "training_loss": 855.3420654296875, "training_acc": 45.0, "val_loss": 631.2603759765625, "val_acc": 60.0}
{"epoch": 30, "training_loss": 1029.39169921875, "training_acc": 35.0, "val_loss": 668.1117553710938, "val_acc": 40.0}
{"epoch": 31, "training_loss": 388.4479248046875, "training_acc": 65.0, "val_loss": 729.7784423828125, "val_acc": 60.0}
{"epoch": 32, "training_loss": 842.5868774414063, "training_acc": 45.0, "val_loss": 13.306475639343262, "val_acc": 60.0}
{"epoch": 33, "training_loss": 221.49883270263672, "training_acc": 45.0, "val_loss": 849.6343994140625, "val_acc": 40.0}
{"epoch": 34, "training_loss": 1004.8121337890625, "training_acc": 35.0, "val_loss": 75.52190399169922, "val_acc": 60.0}
{"epoch": 35, "training_loss": 454.20623779296875, "training_acc": 45.0, "val_loss": 2544.156982421875, "val_acc": 40.0}
{"epoch": 36, "training_loss": 1675.0427490234374, "training_acc": 55.0, "val_loss": 1111.072265625, "val_acc": 60.0}
{"epoch": 37, "training_loss": 1646.3716796875, "training_acc": 45.0, "val_loss": 781.3258056640625, "val_acc": 60.0}
{"epoch": 38, "training_loss": 1424.4654296875, "training_acc": 35.0, "val_loss": 2112.5107421875, "val_acc": 40.0}
{"epoch": 39, "training_loss": 1460.4162170410157, "training_acc": 55.0, "val_loss": 1030.0506591796875, "val_acc": 60.0}
{"epoch": 40, "training_loss": 1435.9046875, "training_acc": 45.0, "val_loss": 37.7140007019043, "val_acc": 60.0}
{"epoch": 41, "training_loss": 263.7156951904297, "training_acc": 55.0, "val_loss": 3892.740966796875, "val_acc": 40.0}
{"epoch": 42, "training_loss": 2701.284033203125, "training_acc": 55.0, "val_loss": 324.5137634277344, "val_acc": 60.0}
{"epoch": 43, "training_loss": 562.4936401367188, "training_acc": 45.0, "val_loss": 1338.2408447265625, "val_acc": 60.0}
{"epoch": 44, "training_loss": 1527.2753875732421, "training_acc": 45.0, "val_loss": 2935.769287109375, "val_acc": 40.0}
{"epoch": 45, "training_loss": 2346.79716796875, "training_acc": 55.0, "val_loss": 2282.2626953125, "val_acc": 40.0}
{"epoch": 46, "training_loss": 1196.5573791503907, "training_acc": 65.0, "val_loss": 1659.3797607421875, "val_acc": 60.0}
{"epoch": 47, "training_loss": 2196.815283203125, "training_acc": 45.0, "val_loss": 335.0302429199219, "val_acc": 40.0}
{"epoch": 48, "training_loss": 497.9110107421875, "training_acc": 55.0, "val_loss": 114.48359680175781, "val_acc": 60.0}
{"epoch": 49, "training_loss": 141.609765625, "training_acc": 45.0, "val_loss": 2032.3406982421875, "val_acc": 40.0}
{"epoch": 50, "training_loss": 1559.2375, "training_acc": 55.0, "val_loss": 472.9322814941406, "val_acc": 40.0}
{"epoch": 51, "training_loss": 685.362646484375, "training_acc": 55.0, "val_loss": 2049.61572265625, "val_acc": 60.0}
