"main_modify.py --pretrained_path None --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 1 --task ADNI_sex --input_option yAware --learning_rate 1e2 --batch_size 16 --weight_decay 1e-2 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 6402.248815917968, "training_acc": 40.0, "val_loss": 7306.81103515625, "val_acc": 40.0}
{"epoch": 1, "training_loss": 6818.351171875, "training_acc": 50.0, "val_loss": 12927.037109375, "val_acc": 60.0}
{"epoch": 2, "training_loss": 15733.32578125, "training_acc": 50.0, "val_loss": 6643.83447265625, "val_acc": 60.0}
{"epoch": 3, "training_loss": 6664.126211547851, "training_acc": 50.0, "val_loss": 7731.27587890625, "val_acc": 40.0}
{"epoch": 4, "training_loss": 6737.5533203125, "training_acc": 50.0, "val_loss": 11386.5, "val_acc": 40.0}
{"epoch": 5, "training_loss": 8941.001953125, "training_acc": 50.0, "val_loss": 2572.005859375, "val_acc": 40.0}
{"epoch": 6, "training_loss": 2941.5123046875, "training_acc": 40.0, "val_loss": 5069.0185546875, "val_acc": 60.0}
{"epoch": 7, "training_loss": 6379.150927734375, "training_acc": 50.0, "val_loss": 4411.14794921875, "val_acc": 60.0}
{"epoch": 8, "training_loss": 4910.3671875, "training_acc": 50.0, "val_loss": 1827.701416015625, "val_acc": 40.0}
{"epoch": 9, "training_loss": 2024.211328125, "training_acc": 50.0, "val_loss": 5633.1630859375, "val_acc": 40.0}
{"epoch": 10, "training_loss": 4469.548876953125, "training_acc": 50.0, "val_loss": 1258.399658203125, "val_acc": 40.0}
{"epoch": 11, "training_loss": 2043.854296875, "training_acc": 30.0, "val_loss": 2805.144287109375, "val_acc": 60.0}
{"epoch": 12, "training_loss": 3363.44521484375, "training_acc": 50.0, "val_loss": 618.6448974609375, "val_acc": 60.0}
{"epoch": 13, "training_loss": 1073.21533203125, "training_acc": 50.0, "val_loss": 4489.6103515625, "val_acc": 40.0}
{"epoch": 14, "training_loss": 3691.59580078125, "training_acc": 50.0, "val_loss": 2087.806396484375, "val_acc": 40.0}
{"epoch": 15, "training_loss": 1312.8275024414063, "training_acc": 60.0, "val_loss": 2215.053955078125, "val_acc": 60.0}
{"epoch": 16, "training_loss": 2778.069287109375, "training_acc": 50.0, "val_loss": 1565.8831787109375, "val_acc": 60.0}
{"epoch": 17, "training_loss": 1373.8730598449706, "training_acc": 60.0, "val_loss": 1698.8416748046875, "val_acc": 40.0}
{"epoch": 18, "training_loss": 1415.357421875, "training_acc": 50.0, "val_loss": 952.1124877929688, "val_acc": 40.0}
{"epoch": 19, "training_loss": 772.9196533203125, "training_acc": 50.0, "val_loss": 766.0888061523438, "val_acc": 60.0}
{"epoch": 20, "training_loss": 721.8072692871094, "training_acc": 50.0, "val_loss": 2396.98046875, "val_acc": 40.0}
{"epoch": 21, "training_loss": 2208.34296875, "training_acc": 50.0, "val_loss": 1588.7684326171875, "val_acc": 40.0}
{"epoch": 22, "training_loss": 1293.2308349609375, "training_acc": 50.0, "val_loss": 1764.049072265625, "val_acc": 60.0}
{"epoch": 23, "training_loss": 2140.421740722656, "training_acc": 50.0, "val_loss": 120.45417785644531, "val_acc": 60.0}
{"epoch": 24, "training_loss": 817.797802734375, "training_acc": 40.0, "val_loss": 2969.401123046875, "val_acc": 40.0}
{"epoch": 25, "training_loss": 2325.488037109375, "training_acc": 50.0, "val_loss": 867.6412353515625, "val_acc": 60.0}
{"epoch": 26, "training_loss": 1134.1629028320312, "training_acc": 50.0, "val_loss": 936.3030395507812, "val_acc": 60.0}
{"epoch": 27, "training_loss": 1034.1903503417968, "training_acc": 50.0, "val_loss": 1029.55419921875, "val_acc": 40.0}
{"epoch": 28, "training_loss": 822.2881072998047, "training_acc": 40.0, "val_loss": 596.5028686523438, "val_acc": 40.0}
{"epoch": 29, "training_loss": 503.6721435546875, "training_acc": 40.0, "val_loss": 961.9888916015625, "val_acc": 40.0}
{"epoch": 30, "training_loss": 737.9000732421875, "training_acc": 50.0, "val_loss": 1057.672119140625, "val_acc": 60.0}
{"epoch": 31, "training_loss": 1343.6826538085938, "training_acc": 50.0, "val_loss": 679.3795166015625, "val_acc": 60.0}
{"epoch": 32, "training_loss": 889.669140625, "training_acc": 50.0, "val_loss": 1736.5516357421875, "val_acc": 40.0}
{"epoch": 33, "training_loss": 1164.8254638671874, "training_acc": 50.0, "val_loss": 1672.0916748046875, "val_acc": 60.0}
{"epoch": 34, "training_loss": 2150.7396240234375, "training_acc": 50.0, "val_loss": 1640.1483154296875, "val_acc": 60.0}
{"epoch": 35, "training_loss": 1283.877618408203, "training_acc": 50.0, "val_loss": 4572.02978515625, "val_acc": 40.0}
{"epoch": 36, "training_loss": 3809.43359375, "training_acc": 50.0, "val_loss": 5921.1650390625, "val_acc": 40.0}
{"epoch": 37, "training_loss": 4451.070849609375, "training_acc": 50.0, "val_loss": 1108.4793701171875, "val_acc": 60.0}
{"epoch": 38, "training_loss": 1799.381689453125, "training_acc": 50.0, "val_loss": 2689.5625, "val_acc": 60.0}
{"epoch": 39, "training_loss": 3144.206188964844, "training_acc": 50.0, "val_loss": 1944.495361328125, "val_acc": 40.0}
{"epoch": 40, "training_loss": 1824.58349609375, "training_acc": 50.0, "val_loss": 2135.943359375, "val_acc": 40.0}
{"epoch": 41, "training_loss": 1813.708642578125, "training_acc": 40.0, "val_loss": 870.96826171875, "val_acc": 60.0}
{"epoch": 42, "training_loss": 877.6293350219727, "training_acc": 50.0, "val_loss": 2468.149169921875, "val_acc": 40.0}
