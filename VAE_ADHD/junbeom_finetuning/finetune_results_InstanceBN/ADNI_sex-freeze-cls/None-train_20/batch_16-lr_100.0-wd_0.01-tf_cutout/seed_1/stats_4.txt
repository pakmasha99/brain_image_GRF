"main_modify.py --pretrained_path None --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 1 --task ADNI_sex --input_option yAware --learning_rate 1e2 --batch_size 16 --weight_decay 1e-2 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 6445.823326492309, "training_acc": 50.0, "val_loss": 6662.66748046875, "val_acc": 40.0}
{"epoch": 1, "training_loss": 6574.9421875, "training_acc": 50.0, "val_loss": 13481.6669921875, "val_acc": 60.0}
{"epoch": 2, "training_loss": 16477.175, "training_acc": 50.0, "val_loss": 6883.06982421875, "val_acc": 60.0}
{"epoch": 3, "training_loss": 7755.662545776368, "training_acc": 50.0, "val_loss": 9577.8798828125, "val_acc": 40.0}
{"epoch": 4, "training_loss": 8387.57041015625, "training_acc": 50.0, "val_loss": 15004.390625, "val_acc": 40.0}
{"epoch": 5, "training_loss": 11666.233203125, "training_acc": 50.0, "val_loss": 5048.32177734375, "val_acc": 40.0}
{"epoch": 6, "training_loss": 4502.17392578125, "training_acc": 40.0, "val_loss": 5274.02197265625, "val_acc": 60.0}
{"epoch": 7, "training_loss": 6759.4763671875, "training_acc": 50.0, "val_loss": 6232.1318359375, "val_acc": 60.0}
{"epoch": 8, "training_loss": 7278.8021484375, "training_acc": 50.0, "val_loss": 1000.4659423828125, "val_acc": 60.0}
{"epoch": 9, "training_loss": 1204.219921875, "training_acc": 60.0, "val_loss": 7692.2578125, "val_acc": 40.0}
{"epoch": 10, "training_loss": 6587.70185546875, "training_acc": 50.0, "val_loss": 7175.3720703125, "val_acc": 40.0}
{"epoch": 11, "training_loss": 5381.3837890625, "training_acc": 50.0, "val_loss": 851.9506225585938, "val_acc": 60.0}
{"epoch": 12, "training_loss": 1322.2269287109375, "training_acc": 50.0, "val_loss": 3931.530517578125, "val_acc": 60.0}
{"epoch": 13, "training_loss": 4780.706640625, "training_acc": 50.0, "val_loss": 1481.6937255859375, "val_acc": 60.0}
{"epoch": 14, "training_loss": 1835.0786865234375, "training_acc": 50.0, "val_loss": 4690.67041015625, "val_acc": 40.0}
{"epoch": 15, "training_loss": 3938.61923828125, "training_acc": 50.0, "val_loss": 3970.774169921875, "val_acc": 40.0}
{"epoch": 16, "training_loss": 2662.710595703125, "training_acc": 50.0, "val_loss": 1812.7515869140625, "val_acc": 60.0}
{"epoch": 17, "training_loss": 2634.0390625, "training_acc": 50.0, "val_loss": 3314.49853515625, "val_acc": 60.0}
{"epoch": 18, "training_loss": 3697.954345703125, "training_acc": 50.0, "val_loss": 546.4442749023438, "val_acc": 40.0}
{"epoch": 19, "training_loss": 455.53310546875, "training_acc": 50.0, "val_loss": 3874.073974609375, "val_acc": 40.0}
{"epoch": 20, "training_loss": 3168.6513427734376, "training_acc": 50.0, "val_loss": 1354.3934326171875, "val_acc": 40.0}
{"epoch": 21, "training_loss": 1170.05185546875, "training_acc": 50.0, "val_loss": 1932.3226318359375, "val_acc": 60.0}
{"epoch": 22, "training_loss": 2366.075793457031, "training_acc": 50.0, "val_loss": 481.5987243652344, "val_acc": 60.0}
{"epoch": 23, "training_loss": 803.59169921875, "training_acc": 50.0, "val_loss": 2846.757568359375, "val_acc": 40.0}
{"epoch": 24, "training_loss": 2229.882666015625, "training_acc": 50.0, "val_loss": 212.5244903564453, "val_acc": 60.0}
{"epoch": 25, "training_loss": 328.7625671386719, "training_acc": 50.0, "val_loss": 651.4452514648438, "val_acc": 60.0}
{"epoch": 26, "training_loss": 727.7433471679688, "training_acc": 50.0, "val_loss": 517.1175537109375, "val_acc": 40.0}
{"epoch": 27, "training_loss": 597.677978515625, "training_acc": 40.0, "val_loss": 97.96810150146484, "val_acc": 60.0}
{"epoch": 28, "training_loss": 377.2918762207031, "training_acc": 50.0, "val_loss": 1795.506103515625, "val_acc": 40.0}
{"epoch": 29, "training_loss": 1252.1289184570312, "training_acc": 50.0, "val_loss": 1502.9990234375, "val_acc": 60.0}
{"epoch": 30, "training_loss": 1986.765380859375, "training_acc": 50.0, "val_loss": 1101.1812744140625, "val_acc": 60.0}
{"epoch": 31, "training_loss": 1275.7737060546874, "training_acc": 50.0, "val_loss": 2049.34765625, "val_acc": 40.0}
{"epoch": 32, "training_loss": 1552.692724609375, "training_acc": 50.0, "val_loss": 855.2973022460938, "val_acc": 60.0}
{"epoch": 33, "training_loss": 1134.844970703125, "training_acc": 50.0, "val_loss": 1126.804931640625, "val_acc": 60.0}
{"epoch": 34, "training_loss": 995.8841506958008, "training_acc": 60.0, "val_loss": 1108.41015625, "val_acc": 40.0}
{"epoch": 35, "training_loss": 809.037158203125, "training_acc": 50.0, "val_loss": 1199.2801513671875, "val_acc": 60.0}
{"epoch": 36, "training_loss": 1587.4232177734375, "training_acc": 50.0, "val_loss": 668.1351928710938, "val_acc": 60.0}
{"epoch": 37, "training_loss": 953.03173828125, "training_acc": 50.0, "val_loss": 2475.557373046875, "val_acc": 40.0}
{"epoch": 38, "training_loss": 2063.88125, "training_acc": 50.0, "val_loss": 402.190673828125, "val_acc": 60.0}
{"epoch": 39, "training_loss": 542.132958984375, "training_acc": 50.0, "val_loss": 1226.3197021484375, "val_acc": 40.0}
{"epoch": 40, "training_loss": 1112.4468017578124, "training_acc": 50.0, "val_loss": 280.9612731933594, "val_acc": 60.0}
{"epoch": 41, "training_loss": 371.32697143554685, "training_acc": 50.0, "val_loss": 38.79749298095703, "val_acc": 60.0}
{"epoch": 42, "training_loss": 171.92487182617188, "training_acc": 60.0, "val_loss": 2142.702880859375, "val_acc": 40.0}
{"epoch": 43, "training_loss": 1785.912109375, "training_acc": 50.0, "val_loss": 867.1336059570312, "val_acc": 60.0}
{"epoch": 44, "training_loss": 1060.0628173828125, "training_acc": 50.0, "val_loss": 612.7421264648438, "val_acc": 40.0}
{"epoch": 45, "training_loss": 575.318212890625, "training_acc": 50.0, "val_loss": 766.0275268554688, "val_acc": 60.0}
{"epoch": 46, "training_loss": 957.6760437011719, "training_acc": 50.0, "val_loss": 122.59258270263672, "val_acc": 60.0}
{"epoch": 47, "training_loss": 268.6979736328125, "training_acc": 60.0, "val_loss": 2673.442138671875, "val_acc": 40.0}
{"epoch": 48, "training_loss": 1995.03427734375, "training_acc": 50.0, "val_loss": 1136.4693603515625, "val_acc": 60.0}
{"epoch": 49, "training_loss": 1477.7278564453125, "training_acc": 50.0, "val_loss": 1129.4002685546875, "val_acc": 60.0}
{"epoch": 50, "training_loss": 1506.213818359375, "training_acc": 40.0, "val_loss": 974.7439575195312, "val_acc": 40.0}
{"epoch": 51, "training_loss": 608.4682403564453, "training_acc": 60.0, "val_loss": 640.1932373046875, "val_acc": 60.0}
{"epoch": 52, "training_loss": 567.8824287414551, "training_acc": 60.0, "val_loss": 305.4806823730469, "val_acc": 40.0}
{"epoch": 53, "training_loss": 525.369970703125, "training_acc": 40.0, "val_loss": 53.1873779296875, "val_acc": 60.0}
{"epoch": 54, "training_loss": 39.9335693359375, "training_acc": 70.0, "val_loss": 3373.56884765625, "val_acc": 40.0}
{"epoch": 55, "training_loss": 2704.1938720703124, "training_acc": 50.0, "val_loss": 237.65762329101562, "val_acc": 60.0}
{"epoch": 56, "training_loss": 407.1792846679688, "training_acc": 50.0, "val_loss": 116.00288391113281, "val_acc": 40.0}
{"epoch": 57, "training_loss": 135.3036865234375, "training_acc": 50.0, "val_loss": 787.41015625, "val_acc": 40.0}
{"epoch": 58, "training_loss": 539.0162719726562, "training_acc": 50.0, "val_loss": 1595.7108154296875, "val_acc": 60.0}
{"epoch": 59, "training_loss": 2049.98642578125, "training_acc": 50.0, "val_loss": 540.27587890625, "val_acc": 60.0}
{"epoch": 60, "training_loss": 974.58740234375, "training_acc": 50.0, "val_loss": 3496.98046875, "val_acc": 40.0}
