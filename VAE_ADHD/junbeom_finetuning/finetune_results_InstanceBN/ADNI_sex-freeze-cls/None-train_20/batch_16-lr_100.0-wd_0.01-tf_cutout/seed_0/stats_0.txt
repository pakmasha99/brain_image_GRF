"main_modify.py --pretrained_path None --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_sex --input_option yAware --learning_rate 1e2 --batch_size 16 --weight_decay 1e-2 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 6427.287110519409, "training_acc": 50.0, "val_loss": 6804.13623046875, "val_acc": 40.0}
{"epoch": 1, "training_loss": 6623.8982421875, "training_acc": 50.0, "val_loss": 13340.517578125, "val_acc": 60.0}
{"epoch": 2, "training_loss": 16483.046484375, "training_acc": 50.0, "val_loss": 7041.2109375, "val_acc": 60.0}
{"epoch": 3, "training_loss": 6392.99248046875, "training_acc": 50.0, "val_loss": 9546.0732421875, "val_acc": 40.0}
{"epoch": 4, "training_loss": 8898.2966796875, "training_acc": 50.0, "val_loss": 15725.7265625, "val_acc": 40.0}
{"epoch": 5, "training_loss": 12216.76171875, "training_acc": 50.0, "val_loss": 5398.43212890625, "val_acc": 40.0}
{"epoch": 6, "training_loss": 4034.73603515625, "training_acc": 50.0, "val_loss": 5561.2158203125, "val_acc": 60.0}
{"epoch": 7, "training_loss": 7388.3779296875, "training_acc": 50.0, "val_loss": 6915.55029296875, "val_acc": 60.0}
{"epoch": 8, "training_loss": 8104.49541015625, "training_acc": 50.0, "val_loss": 1371.9693603515625, "val_acc": 60.0}
{"epoch": 9, "training_loss": 1509.0876953125, "training_acc": 60.0, "val_loss": 7809.9853515625, "val_acc": 40.0}
{"epoch": 10, "training_loss": 6736.8224609375, "training_acc": 50.0, "val_loss": 7906.6337890625, "val_acc": 40.0}
{"epoch": 11, "training_loss": 6014.32294921875, "training_acc": 50.0, "val_loss": 233.3006591796875, "val_acc": 60.0}
{"epoch": 12, "training_loss": 852.3008544921875, "training_acc": 50.0, "val_loss": 3448.237548828125, "val_acc": 60.0}
{"epoch": 13, "training_loss": 4255.3703125, "training_acc": 50.0, "val_loss": 1750.0867919921875, "val_acc": 60.0}
{"epoch": 14, "training_loss": 1564.5296905517578, "training_acc": 60.0, "val_loss": 2587.703857421875, "val_acc": 40.0}
{"epoch": 15, "training_loss": 2320.49697265625, "training_acc": 50.0, "val_loss": 1766.6439208984375, "val_acc": 40.0}
{"epoch": 16, "training_loss": 1326.90712890625, "training_acc": 50.0, "val_loss": 1428.0189208984375, "val_acc": 60.0}
{"epoch": 17, "training_loss": 1738.32802734375, "training_acc": 50.0, "val_loss": 160.25096130371094, "val_acc": 60.0}
{"epoch": 18, "training_loss": 788.82578125, "training_acc": 40.0, "val_loss": 2837.548583984375, "val_acc": 40.0}
{"epoch": 19, "training_loss": 2091.66435546875, "training_acc": 50.0, "val_loss": 759.5907592773438, "val_acc": 60.0}
{"epoch": 20, "training_loss": 1318.91640625, "training_acc": 50.0, "val_loss": 1236.4583740234375, "val_acc": 60.0}
{"epoch": 21, "training_loss": 1489.9903625488282, "training_acc": 40.0, "val_loss": 752.14501953125, "val_acc": 40.0}
{"epoch": 22, "training_loss": 526.7887329101562, "training_acc": 50.0, "val_loss": 144.4313201904297, "val_acc": 40.0}
{"epoch": 23, "training_loss": 320.14306640625, "training_acc": 40.0, "val_loss": 75.54886627197266, "val_acc": 40.0}
{"epoch": 24, "training_loss": 85.57974548339844, "training_acc": 50.0, "val_loss": 687.9773559570312, "val_acc": 40.0}
{"epoch": 25, "training_loss": 495.1359924316406, "training_acc": 50.0, "val_loss": 1122.790771484375, "val_acc": 60.0}
{"epoch": 26, "training_loss": 1464.719921875, "training_acc": 50.0, "val_loss": 542.6786499023438, "val_acc": 60.0}
{"epoch": 27, "training_loss": 815.789013671875, "training_acc": 50.0, "val_loss": 2346.92041015625, "val_acc": 40.0}
{"epoch": 28, "training_loss": 1709.27451171875, "training_acc": 50.0, "val_loss": 1156.1343994140625, "val_acc": 60.0}
{"epoch": 29, "training_loss": 1851.3138671875, "training_acc": 50.0, "val_loss": 1555.6741943359375, "val_acc": 60.0}
{"epoch": 30, "training_loss": 1602.570086669922, "training_acc": 50.0, "val_loss": 1398.5799560546875, "val_acc": 40.0}
{"epoch": 31, "training_loss": 1101.82216796875, "training_acc": 50.0, "val_loss": 1075.0980224609375, "val_acc": 60.0}
{"epoch": 32, "training_loss": 1414.46845703125, "training_acc": 50.0, "val_loss": 1383.2435302734375, "val_acc": 60.0}
{"epoch": 33, "training_loss": 1810.8587707519532, "training_acc": 30.0, "val_loss": 91.89165496826172, "val_acc": 60.0}
{"epoch": 34, "training_loss": 130.9150848388672, "training_acc": 60.0, "val_loss": 535.73779296875, "val_acc": 40.0}
{"epoch": 35, "training_loss": 504.39765625, "training_acc": 50.0, "val_loss": 487.6148376464844, "val_acc": 60.0}
{"epoch": 36, "training_loss": 624.01123046875, "training_acc": 50.0, "val_loss": 782.5265502929688, "val_acc": 40.0}
{"epoch": 37, "training_loss": 797.223046875, "training_acc": 40.0, "val_loss": 151.5987091064453, "val_acc": 60.0}
{"epoch": 38, "training_loss": 426.2311767578125, "training_acc": 50.0, "val_loss": 1684.6510009765625, "val_acc": 40.0}
{"epoch": 39, "training_loss": 1290.9417449951172, "training_acc": 40.0, "val_loss": 212.0438232421875, "val_acc": 40.0}
{"epoch": 40, "training_loss": 406.20087890625, "training_acc": 40.0, "val_loss": 92.68004608154297, "val_acc": 40.0}
{"epoch": 41, "training_loss": 101.987890625, "training_acc": 50.0, "val_loss": 808.8749389648438, "val_acc": 40.0}
{"epoch": 42, "training_loss": 582.6614624023438, "training_acc": 50.0, "val_loss": 1068.5540771484375, "val_acc": 60.0}
