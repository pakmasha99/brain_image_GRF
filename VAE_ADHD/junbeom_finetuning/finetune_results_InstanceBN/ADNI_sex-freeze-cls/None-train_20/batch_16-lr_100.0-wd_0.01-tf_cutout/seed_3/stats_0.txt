"main_modify.py --pretrained_path None --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 3 --task ADNI_sex --input_option yAware --learning_rate 1e2 --batch_size 16 --weight_decay 1e-2 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 4292.1778609752655, "training_acc": 50.0, "val_loss": 4469.68310546875, "val_acc": 60.0}
{"epoch": 1, "training_loss": 4977.22353515625, "training_acc": 60.0, "val_loss": 20941.58984375, "val_acc": 40.0}
{"epoch": 2, "training_loss": 16997.8734375, "training_acc": 50.0, "val_loss": 10040.5810546875, "val_acc": 40.0}
{"epoch": 3, "training_loss": 6796.9415283203125, "training_acc": 50.0, "val_loss": 5716.61669921875, "val_acc": 60.0}
{"epoch": 4, "training_loss": 7434.60751953125, "training_acc": 50.0, "val_loss": 7857.93896484375, "val_acc": 60.0}
{"epoch": 5, "training_loss": 9498.741064453125, "training_acc": 50.0, "val_loss": 1522.9208984375, "val_acc": 60.0}
{"epoch": 6, "training_loss": 1679.2808349609375, "training_acc": 60.0, "val_loss": 8566.615234375, "val_acc": 40.0}
{"epoch": 7, "training_loss": 7445.8435546875, "training_acc": 50.0, "val_loss": 7463.35791015625, "val_acc": 40.0}
{"epoch": 8, "training_loss": 5455.98056640625, "training_acc": 50.0, "val_loss": 1845.921875, "val_acc": 60.0}
{"epoch": 9, "training_loss": 2592.545703125, "training_acc": 50.0, "val_loss": 5062.37890625, "val_acc": 60.0}
{"epoch": 10, "training_loss": 6327.41171875, "training_acc": 50.0, "val_loss": 2416.87451171875, "val_acc": 60.0}
{"epoch": 11, "training_loss": 3223.15078125, "training_acc": 30.0, "val_loss": 2231.768310546875, "val_acc": 40.0}
{"epoch": 12, "training_loss": 1848.3634399414063, "training_acc": 50.0, "val_loss": 1071.2999267578125, "val_acc": 40.0}
{"epoch": 13, "training_loss": 1119.588720703125, "training_acc": 40.0, "val_loss": 1028.3143310546875, "val_acc": 60.0}
{"epoch": 14, "training_loss": 1180.6428298950195, "training_acc": 50.0, "val_loss": 1439.6904296875, "val_acc": 40.0}
{"epoch": 15, "training_loss": 1281.7283203125, "training_acc": 50.0, "val_loss": 81.8072280883789, "val_acc": 40.0}
{"epoch": 16, "training_loss": 482.6792724609375, "training_acc": 50.0, "val_loss": 2226.387451171875, "val_acc": 60.0}
{"epoch": 17, "training_loss": 2679.5018676757813, "training_acc": 50.0, "val_loss": 24.46752166748047, "val_acc": 40.0}
{"epoch": 18, "training_loss": 253.5346237182617, "training_acc": 50.0, "val_loss": 70.37010955810547, "val_acc": 60.0}
{"epoch": 19, "training_loss": 86.77220611572265, "training_acc": 50.0, "val_loss": 597.8163452148438, "val_acc": 60.0}
{"epoch": 20, "training_loss": 671.0182556152344, "training_acc": 50.0, "val_loss": 1246.499755859375, "val_acc": 40.0}
{"epoch": 21, "training_loss": 1049.6917236328125, "training_acc": 50.0, "val_loss": 69.92766571044922, "val_acc": 60.0}
{"epoch": 22, "training_loss": 140.5170471191406, "training_acc": 50.0, "val_loss": 1377.01904296875, "val_acc": 40.0}
{"epoch": 23, "training_loss": 1186.437646484375, "training_acc": 50.0, "val_loss": 328.099853515625, "val_acc": 60.0}
{"epoch": 24, "training_loss": 493.0724731445313, "training_acc": 50.0, "val_loss": 22.118459701538086, "val_acc": 40.0}
{"epoch": 25, "training_loss": 66.5217300415039, "training_acc": 50.0, "val_loss": 712.9296875, "val_acc": 40.0}
{"epoch": 26, "training_loss": 510.0835266113281, "training_acc": 50.0, "val_loss": 1043.5826416015625, "val_acc": 60.0}
{"epoch": 27, "training_loss": 1334.71953125, "training_acc": 50.0, "val_loss": 525.6210327148438, "val_acc": 40.0}
{"epoch": 28, "training_loss": 625.1917236328125, "training_acc": 50.0, "val_loss": 194.40028381347656, "val_acc": 60.0}
{"epoch": 29, "training_loss": 233.51648406982423, "training_acc": 50.0, "val_loss": 622.2260131835938, "val_acc": 40.0}
{"epoch": 30, "training_loss": 434.5839447021484, "training_acc": 50.0, "val_loss": 562.2664794921875, "val_acc": 40.0}
{"epoch": 31, "training_loss": 295.0800064086914, "training_acc": 50.0, "val_loss": 2063.76904296875, "val_acc": 60.0}
{"epoch": 32, "training_loss": 2804.6130859375, "training_acc": 50.0, "val_loss": 1216.9664306640625, "val_acc": 60.0}
{"epoch": 33, "training_loss": 1211.315576171875, "training_acc": 60.0, "val_loss": 3896.578125, "val_acc": 40.0}
{"epoch": 34, "training_loss": 3243.9240234375, "training_acc": 50.0, "val_loss": 1706.053955078125, "val_acc": 40.0}
{"epoch": 35, "training_loss": 852.119921875, "training_acc": 70.0, "val_loss": 2198.415283203125, "val_acc": 60.0}
{"epoch": 36, "training_loss": 2717.8941162109377, "training_acc": 50.0, "val_loss": 773.3849487304688, "val_acc": 60.0}
{"epoch": 37, "training_loss": 1443.09716796875, "training_acc": 40.0, "val_loss": 2740.40087890625, "val_acc": 40.0}
{"epoch": 38, "training_loss": 1999.8263916015626, "training_acc": 50.0, "val_loss": 1425.7860107421875, "val_acc": 60.0}
{"epoch": 39, "training_loss": 2059.254296875, "training_acc": 50.0, "val_loss": 876.5828247070312, "val_acc": 60.0}
{"epoch": 40, "training_loss": 1571.6060546875, "training_acc": 40.0, "val_loss": 2927.956298828125, "val_acc": 40.0}
{"epoch": 41, "training_loss": 2287.8620178222654, "training_acc": 50.0, "val_loss": 1001.1759033203125, "val_acc": 60.0}
{"epoch": 42, "training_loss": 1437.512890625, "training_acc": 50.0, "val_loss": 142.12460327148438, "val_acc": 60.0}
{"epoch": 43, "training_loss": 367.8881103515625, "training_acc": 60.0, "val_loss": 4275.38427734375, "val_acc": 40.0}
