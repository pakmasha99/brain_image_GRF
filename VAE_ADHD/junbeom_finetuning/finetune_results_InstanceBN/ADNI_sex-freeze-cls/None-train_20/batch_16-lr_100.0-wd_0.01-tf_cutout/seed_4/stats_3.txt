"main_modify.py --pretrained_path None --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 4 --task ADNI_sex --input_option yAware --learning_rate 1e2 --batch_size 16 --weight_decay 1e-2 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 0.5477087020874023, "training_acc": 65.0, "val_loss": 6636.06396484375, "val_acc": 40.0}
{"epoch": 1, "training_loss": 6098.603515625, "training_acc": 55.0, "val_loss": 12472.0068359375, "val_acc": 60.0}
{"epoch": 2, "training_loss": 16027.13125, "training_acc": 45.0, "val_loss": 3019.128173828125, "val_acc": 60.0}
{"epoch": 3, "training_loss": 4495.3810546875, "training_acc": 45.0, "val_loss": 13057.689453125, "val_acc": 40.0}
{"epoch": 4, "training_loss": 9988.1748046875, "training_acc": 55.0, "val_loss": 10896.134765625, "val_acc": 40.0}
{"epoch": 5, "training_loss": 7140.068798828125, "training_acc": 55.0, "val_loss": 1915.4658203125, "val_acc": 60.0}
{"epoch": 6, "training_loss": 3898.7392578125, "training_acc": 45.0, "val_loss": 6101.5087890625, "val_acc": 60.0}
{"epoch": 7, "training_loss": 8072.0966796875, "training_acc": 45.0, "val_loss": 2072.560546875, "val_acc": 60.0}
{"epoch": 8, "training_loss": 2727.345458984375, "training_acc": 45.0, "val_loss": 5815.89990234375, "val_acc": 40.0}
{"epoch": 9, "training_loss": 4536.98193359375, "training_acc": 55.0, "val_loss": 5489.83935546875, "val_acc": 40.0}
{"epoch": 10, "training_loss": 3582.715869140625, "training_acc": 55.0, "val_loss": 1392.324462890625, "val_acc": 60.0}
{"epoch": 11, "training_loss": 2310.308251953125, "training_acc": 45.0, "val_loss": 3141.4033203125, "val_acc": 60.0}
{"epoch": 12, "training_loss": 3780.8162109375, "training_acc": 45.0, "val_loss": 1009.0196533203125, "val_acc": 40.0}
{"epoch": 13, "training_loss": 1444.38623046875, "training_acc": 55.0, "val_loss": 3937.210693359375, "val_acc": 40.0}
{"epoch": 14, "training_loss": 2697.201123046875, "training_acc": 55.0, "val_loss": 343.4677429199219, "val_acc": 60.0}
{"epoch": 15, "training_loss": 573.9157836914062, "training_acc": 45.0, "val_loss": 1296.281494140625, "val_acc": 60.0}
{"epoch": 16, "training_loss": 1546.6223999023437, "training_acc": 45.0, "val_loss": 1962.5172119140625, "val_acc": 40.0}
{"epoch": 17, "training_loss": 1619.990234375, "training_acc": 55.0, "val_loss": 1963.7352294921875, "val_acc": 40.0}
{"epoch": 18, "training_loss": 1400.9082153320312, "training_acc": 45.0, "val_loss": 478.8623962402344, "val_acc": 60.0}
{"epoch": 19, "training_loss": 498.87378845214846, "training_acc": 55.0, "val_loss": 500.6061706542969, "val_acc": 40.0}
{"epoch": 20, "training_loss": 356.1137939453125, "training_acc": 55.0, "val_loss": 55.87105941772461, "val_acc": 40.0}
{"epoch": 21, "training_loss": 64.13139038085937, "training_acc": 65.0, "val_loss": 128.440185546875, "val_acc": 60.0}
{"epoch": 22, "training_loss": 233.9654541015625, "training_acc": 55.0, "val_loss": 1700.9847412109375, "val_acc": 40.0}
{"epoch": 23, "training_loss": 1025.8041259765625, "training_acc": 55.0, "val_loss": 1576.0499267578125, "val_acc": 60.0}
{"epoch": 24, "training_loss": 2244.38466796875, "training_acc": 45.0, "val_loss": 1852.790283203125, "val_acc": 60.0}
{"epoch": 25, "training_loss": 1962.5608764648437, "training_acc": 45.0, "val_loss": 3626.70703125, "val_acc": 40.0}
{"epoch": 26, "training_loss": 2851.6712890625, "training_acc": 55.0, "val_loss": 4824.39599609375, "val_acc": 40.0}
{"epoch": 27, "training_loss": 3013.2205078125, "training_acc": 55.0, "val_loss": 1467.6229248046875, "val_acc": 60.0}
{"epoch": 28, "training_loss": 2868.1111328125, "training_acc": 45.0, "val_loss": 2290.1826171875, "val_acc": 60.0}
{"epoch": 29, "training_loss": 2890.346258544922, "training_acc": 35.0, "val_loss": 1415.477294921875, "val_acc": 40.0}
{"epoch": 30, "training_loss": 1019.0185302734375, "training_acc": 55.0, "val_loss": 404.64007568359375, "val_acc": 60.0}
{"epoch": 31, "training_loss": 560.6135009765625, "training_acc": 45.0, "val_loss": 765.8910522460938, "val_acc": 40.0}
{"epoch": 32, "training_loss": 567.4184814453125, "training_acc": 55.0, "val_loss": 520.23095703125, "val_acc": 60.0}
{"epoch": 33, "training_loss": 726.949755859375, "training_acc": 45.0, "val_loss": 1947.3023681640625, "val_acc": 40.0}
{"epoch": 34, "training_loss": 1520.0045654296875, "training_acc": 55.0, "val_loss": 2018.0250244140625, "val_acc": 40.0}
{"epoch": 35, "training_loss": 1013.4199020385743, "training_acc": 65.0, "val_loss": 833.6720581054688, "val_acc": 60.0}
{"epoch": 36, "training_loss": 1025.3181518554688, "training_acc": 45.0, "val_loss": 1597.1190185546875, "val_acc": 40.0}
{"epoch": 37, "training_loss": 1255.09482421875, "training_acc": 55.0, "val_loss": 421.0568542480469, "val_acc": 40.0}
{"epoch": 38, "training_loss": 1175.5365966796876, "training_acc": 35.0, "val_loss": 1288.7535400390625, "val_acc": 60.0}
{"epoch": 39, "training_loss": 1328.6618591308593, "training_acc": 55.0, "val_loss": 1875.4188232421875, "val_acc": 40.0}
