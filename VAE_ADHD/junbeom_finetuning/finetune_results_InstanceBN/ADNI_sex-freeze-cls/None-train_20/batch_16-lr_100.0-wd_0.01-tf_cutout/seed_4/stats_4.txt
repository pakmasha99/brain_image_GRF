"main_modify.py --pretrained_path None --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 4 --task ADNI_sex --input_option yAware --learning_rate 1e2 --batch_size 16 --weight_decay 1e-2 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 0.5503556728363037, "training_acc": 65.0, "val_loss": 6827.67138671875, "val_acc": 40.0}
{"epoch": 1, "training_loss": 6204.383984375, "training_acc": 55.0, "val_loss": 12516.3349609375, "val_acc": 60.0}
{"epoch": 2, "training_loss": 16103.09765625, "training_acc": 45.0, "val_loss": 3048.96826171875, "val_acc": 60.0}
{"epoch": 3, "training_loss": 5506.0224609375, "training_acc": 35.0, "val_loss": 12587.34765625, "val_acc": 40.0}
{"epoch": 4, "training_loss": 9686.65859375, "training_acc": 55.0, "val_loss": 9664.7705078125, "val_acc": 40.0}
{"epoch": 5, "training_loss": 5199.01572265625, "training_acc": 55.0, "val_loss": 3205.059326171875, "val_acc": 60.0}
{"epoch": 6, "training_loss": 5271.253515625, "training_acc": 45.0, "val_loss": 7673.91357421875, "val_acc": 60.0}
{"epoch": 7, "training_loss": 10076.3291015625, "training_acc": 45.0, "val_loss": 3108.875732421875, "val_acc": 60.0}
{"epoch": 8, "training_loss": 3245.0816650390625, "training_acc": 55.0, "val_loss": 6547.080078125, "val_acc": 40.0}
{"epoch": 9, "training_loss": 5295.18486328125, "training_acc": 55.0, "val_loss": 8283.921875, "val_acc": 40.0}
{"epoch": 10, "training_loss": 5733.196875, "training_acc": 55.0, "val_loss": 825.310546875, "val_acc": 40.0}
{"epoch": 11, "training_loss": 1669.51943359375, "training_acc": 45.0, "val_loss": 4611.0908203125, "val_acc": 60.0}
{"epoch": 12, "training_loss": 6307.88427734375, "training_acc": 45.0, "val_loss": 2882.554443359375, "val_acc": 60.0}
{"epoch": 13, "training_loss": 3963.395314043754, "training_acc": 45.0, "val_loss": 3924.56298828125, "val_acc": 40.0}
{"epoch": 14, "training_loss": 3268.043359375, "training_acc": 55.0, "val_loss": 5509.60107421875, "val_acc": 40.0}
{"epoch": 15, "training_loss": 3934.5776123046876, "training_acc": 55.0, "val_loss": 79.82775115966797, "val_acc": 60.0}
{"epoch": 16, "training_loss": 405.083984375, "training_acc": 45.0, "val_loss": 1393.92138671875, "val_acc": 60.0}
{"epoch": 17, "training_loss": 1681.9223022460938, "training_acc": 45.0, "val_loss": 1789.969970703125, "val_acc": 40.0}
{"epoch": 18, "training_loss": 1616.19921875, "training_acc": 55.0, "val_loss": 1693.1165771484375, "val_acc": 40.0}
{"epoch": 19, "training_loss": 1329.241259765625, "training_acc": 45.0, "val_loss": 846.4242553710938, "val_acc": 60.0}
{"epoch": 20, "training_loss": 932.460302734375, "training_acc": 45.0, "val_loss": 2213.666259765625, "val_acc": 40.0}
{"epoch": 21, "training_loss": 1809.78056640625, "training_acc": 55.0, "val_loss": 2170.660888671875, "val_acc": 40.0}
{"epoch": 22, "training_loss": 1510.0865112304687, "training_acc": 45.0, "val_loss": 464.08770751953125, "val_acc": 60.0}
{"epoch": 23, "training_loss": 479.42644653320315, "training_acc": 55.0, "val_loss": 370.0267028808594, "val_acc": 40.0}
{"epoch": 24, "training_loss": 307.4839660644531, "training_acc": 55.0, "val_loss": 65.32805633544922, "val_acc": 60.0}
{"epoch": 25, "training_loss": 348.95025024414065, "training_acc": 45.0, "val_loss": 1698.041015625, "val_acc": 40.0}
{"epoch": 26, "training_loss": 1147.6091857910155, "training_acc": 55.0, "val_loss": 1222.8548583984375, "val_acc": 60.0}
{"epoch": 27, "training_loss": 1692.039501953125, "training_acc": 45.0, "val_loss": 216.98974609375, "val_acc": 60.0}
{"epoch": 28, "training_loss": 667.4828857421875, "training_acc": 45.0, "val_loss": 3337.17431640625, "val_acc": 40.0}
{"epoch": 29, "training_loss": 2265.081201171875, "training_acc": 55.0, "val_loss": 570.0469360351562, "val_acc": 60.0}
{"epoch": 30, "training_loss": 1008.172998046875, "training_acc": 45.0, "val_loss": 1113.228759765625, "val_acc": 60.0}
{"epoch": 31, "training_loss": 1149.9261993408204, "training_acc": 55.0, "val_loss": 1625.238525390625, "val_acc": 40.0}
{"epoch": 32, "training_loss": 1155.956396484375, "training_acc": 55.0, "val_loss": 717.2393798828125, "val_acc": 60.0}
{"epoch": 33, "training_loss": 1017.2653076171875, "training_acc": 45.0, "val_loss": 537.2052612304688, "val_acc": 60.0}
{"epoch": 34, "training_loss": 839.4571533203125, "training_acc": 45.0, "val_loss": 1786.7196044921875, "val_acc": 40.0}
{"epoch": 35, "training_loss": 1340.1142578125, "training_acc": 55.0, "val_loss": 807.5108642578125, "val_acc": 60.0}
{"epoch": 36, "training_loss": 1035.4805419921875, "training_acc": 45.0, "val_loss": 1147.10107421875, "val_acc": 40.0}
{"epoch": 37, "training_loss": 974.619873046875, "training_acc": 55.0, "val_loss": 239.17369079589844, "val_acc": 60.0}
{"epoch": 38, "training_loss": 330.8447204589844, "training_acc": 45.0, "val_loss": 357.4010314941406, "val_acc": 40.0}
{"epoch": 39, "training_loss": 184.41637496948243, "training_acc": 65.0, "val_loss": 239.9944305419922, "val_acc": 40.0}
{"epoch": 40, "training_loss": 166.7941131591797, "training_acc": 65.0, "val_loss": 306.3610534667969, "val_acc": 60.0}
{"epoch": 41, "training_loss": 559.7350830078125, "training_acc": 45.0, "val_loss": 1168.7548828125, "val_acc": 40.0}
{"epoch": 42, "training_loss": 486.87568359375, "training_acc": 75.0, "val_loss": 819.00830078125, "val_acc": 60.0}
{"epoch": 43, "training_loss": 951.844384765625, "training_acc": 45.0, "val_loss": 2331.8896484375, "val_acc": 40.0}
