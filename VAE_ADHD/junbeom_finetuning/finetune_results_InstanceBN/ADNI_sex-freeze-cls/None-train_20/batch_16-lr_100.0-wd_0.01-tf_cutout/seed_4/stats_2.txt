"main_modify.py --pretrained_path None --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 4 --task ADNI_sex --input_option yAware --learning_rate 1e2 --batch_size 16 --weight_decay 1e-2 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 8589.003864908218, "training_acc": 50.0, "val_loss": 7050.4140625, "val_acc": 40.0}
{"epoch": 1, "training_loss": 5088.9244140625, "training_acc": 60.0, "val_loss": 13947.3505859375, "val_acc": 60.0}
{"epoch": 2, "training_loss": 17197.928125, "training_acc": 50.0, "val_loss": 8270.3515625, "val_acc": 60.0}
{"epoch": 3, "training_loss": 8604.047412109376, "training_acc": 50.0, "val_loss": 8664.2138671875, "val_acc": 40.0}
{"epoch": 4, "training_loss": 8274.89140625, "training_acc": 50.0, "val_loss": 16499.328125, "val_acc": 40.0}
{"epoch": 5, "training_loss": 13089.817578125, "training_acc": 50.0, "val_loss": 7878.72998046875, "val_acc": 40.0}
{"epoch": 6, "training_loss": 6560.2546875, "training_acc": 50.0, "val_loss": 4651.3212890625, "val_acc": 60.0}
{"epoch": 7, "training_loss": 6153.94169921875, "training_acc": 50.0, "val_loss": 8271.478515625, "val_acc": 60.0}
{"epoch": 8, "training_loss": 10051.43515625, "training_acc": 50.0, "val_loss": 4366.13818359375, "val_acc": 60.0}
{"epoch": 9, "training_loss": 4517.283996582031, "training_acc": 50.0, "val_loss": 5240.3046875, "val_acc": 40.0}
{"epoch": 10, "training_loss": 5342.783984375, "training_acc": 50.0, "val_loss": 9867.0859375, "val_acc": 40.0}
{"epoch": 11, "training_loss": 7909.99296875, "training_acc": 50.0, "val_loss": 4250.34375, "val_acc": 40.0}
{"epoch": 12, "training_loss": 2123.3419921875, "training_acc": 70.0, "val_loss": 3199.70458984375, "val_acc": 60.0}
{"epoch": 13, "training_loss": 4572.41484375, "training_acc": 50.0, "val_loss": 4441.83984375, "val_acc": 60.0}
{"epoch": 14, "training_loss": 4983.6529296875, "training_acc": 50.0, "val_loss": 192.4938201904297, "val_acc": 60.0}
{"epoch": 15, "training_loss": 524.83662109375, "training_acc": 60.0, "val_loss": 7274.1328125, "val_acc": 40.0}
{"epoch": 16, "training_loss": 6092.334619140625, "training_acc": 50.0, "val_loss": 6349.47216796875, "val_acc": 40.0}
{"epoch": 17, "training_loss": 4749.17626953125, "training_acc": 50.0, "val_loss": 844.0995483398438, "val_acc": 60.0}
{"epoch": 18, "training_loss": 1525.749072265625, "training_acc": 50.0, "val_loss": 3336.004638671875, "val_acc": 60.0}
{"epoch": 19, "training_loss": 4003.34990234375, "training_acc": 50.0, "val_loss": 969.6943359375, "val_acc": 60.0}
{"epoch": 20, "training_loss": 1639.92041015625, "training_acc": 40.0, "val_loss": 3670.015625, "val_acc": 40.0}
{"epoch": 21, "training_loss": 3020.5354248046874, "training_acc": 50.0, "val_loss": 1800.7900390625, "val_acc": 40.0}
{"epoch": 22, "training_loss": 1586.908837890625, "training_acc": 40.0, "val_loss": 1187.6888427734375, "val_acc": 60.0}
{"epoch": 23, "training_loss": 1389.1075927734375, "training_acc": 50.0, "val_loss": 534.6063232421875, "val_acc": 40.0}
{"epoch": 24, "training_loss": 523.661083984375, "training_acc": 50.0, "val_loss": 224.0730438232422, "val_acc": 40.0}
{"epoch": 25, "training_loss": 249.295068359375, "training_acc": 60.0, "val_loss": 1423.37744140625, "val_acc": 60.0}
{"epoch": 26, "training_loss": 1700.2042602539063, "training_acc": 50.0, "val_loss": 423.02008056640625, "val_acc": 40.0}
{"epoch": 27, "training_loss": 367.88782958984376, "training_acc": 50.0, "val_loss": 125.42142486572266, "val_acc": 40.0}
{"epoch": 28, "training_loss": 319.57683715820315, "training_acc": 50.0, "val_loss": 963.1732788085938, "val_acc": 60.0}
{"epoch": 29, "training_loss": 1094.0497253417968, "training_acc": 40.0, "val_loss": 174.16995239257812, "val_acc": 60.0}
{"epoch": 30, "training_loss": 384.5718994140625, "training_acc": 40.0, "val_loss": 91.70606994628906, "val_acc": 60.0}
{"epoch": 31, "training_loss": 186.5296630859375, "training_acc": 40.0, "val_loss": 656.9503784179688, "val_acc": 60.0}
{"epoch": 32, "training_loss": 798.8424560546875, "training_acc": 50.0, "val_loss": 576.7258911132812, "val_acc": 40.0}
{"epoch": 33, "training_loss": 524.58349609375, "training_acc": 50.0, "val_loss": 637.6114501953125, "val_acc": 60.0}
{"epoch": 34, "training_loss": 882.494970703125, "training_acc": 50.0, "val_loss": 397.6455993652344, "val_acc": 40.0}
{"epoch": 35, "training_loss": 440.4213623046875, "training_acc": 50.0, "val_loss": 462.3959045410156, "val_acc": 60.0}
{"epoch": 36, "training_loss": 588.92470703125, "training_acc": 50.0, "val_loss": 521.4807739257812, "val_acc": 40.0}
{"epoch": 37, "training_loss": 410.5386215209961, "training_acc": 50.0, "val_loss": 442.32421875, "val_acc": 60.0}
{"epoch": 38, "training_loss": 465.89912872314454, "training_acc": 50.0, "val_loss": 1562.8984375, "val_acc": 40.0}
{"epoch": 39, "training_loss": 1301.14345703125, "training_acc": 50.0, "val_loss": 688.2233276367188, "val_acc": 40.0}
{"epoch": 40, "training_loss": 487.76201782226565, "training_acc": 60.0, "val_loss": 1169.8441162109375, "val_acc": 60.0}
{"epoch": 41, "training_loss": 1298.662939453125, "training_acc": 50.0, "val_loss": 1518.492919921875, "val_acc": 40.0}
{"epoch": 42, "training_loss": 1345.7740234375, "training_acc": 50.0, "val_loss": 743.1845092773438, "val_acc": 40.0}
{"epoch": 43, "training_loss": 571.8585327148437, "training_acc": 60.0, "val_loss": 1883.720703125, "val_acc": 60.0}
{"epoch": 44, "training_loss": 2269.462780761719, "training_acc": 50.0, "val_loss": 170.25222778320312, "val_acc": 40.0}
{"epoch": 45, "training_loss": 300.52745361328124, "training_acc": 50.0, "val_loss": 478.9066467285156, "val_acc": 60.0}
{"epoch": 46, "training_loss": 587.2850830078125, "training_acc": 50.0, "val_loss": 843.953125, "val_acc": 40.0}
{"epoch": 47, "training_loss": 679.9361572265625, "training_acc": 50.0, "val_loss": 584.5533447265625, "val_acc": 60.0}
{"epoch": 48, "training_loss": 710.7663513183594, "training_acc": 50.0, "val_loss": 378.123779296875, "val_acc": 40.0}
{"epoch": 49, "training_loss": 268.39085693359374, "training_acc": 50.0, "val_loss": 809.2675170898438, "val_acc": 40.0}
