"main_modify.py --pretrained_path None --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 4 --task ADNI_sex --input_option yAware --learning_rate 1e1 --batch_size 16 --weight_decay 1e-6 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 429.93005523681643, "training_acc": 50.0, "val_loss": 738.15185546875, "val_acc": 40.0}
{"epoch": 1, "training_loss": 912.41826171875, "training_acc": 40.0, "val_loss": 1093.856201171875, "val_acc": 60.0}
{"epoch": 2, "training_loss": 1325.052996826172, "training_acc": 50.0, "val_loss": 290.17266845703125, "val_acc": 60.0}
{"epoch": 3, "training_loss": 492.449853515625, "training_acc": 40.0, "val_loss": 891.4845581054688, "val_acc": 40.0}
{"epoch": 4, "training_loss": 742.88896484375, "training_acc": 50.0, "val_loss": 349.16851806640625, "val_acc": 40.0}
{"epoch": 5, "training_loss": 219.32610321044922, "training_acc": 60.0, "val_loss": 325.6697082519531, "val_acc": 60.0}
{"epoch": 6, "training_loss": 396.0278625488281, "training_acc": 50.0, "val_loss": 53.76321029663086, "val_acc": 60.0}
{"epoch": 7, "training_loss": 192.279638671875, "training_acc": 40.0, "val_loss": 586.7152099609375, "val_acc": 40.0}
{"epoch": 8, "training_loss": 435.53631591796875, "training_acc": 50.0, "val_loss": 158.33111572265625, "val_acc": 60.0}
{"epoch": 9, "training_loss": 215.6771728515625, "training_acc": 50.0, "val_loss": 348.0361633300781, "val_acc": 60.0}
{"epoch": 10, "training_loss": 396.7885772705078, "training_acc": 50.0, "val_loss": 177.02549743652344, "val_acc": 40.0}
{"epoch": 11, "training_loss": 156.87140045166015, "training_acc": 50.0, "val_loss": 261.3834533691406, "val_acc": 40.0}
{"epoch": 12, "training_loss": 180.1002342224121, "training_acc": 50.0, "val_loss": 24.123319625854492, "val_acc": 60.0}
{"epoch": 13, "training_loss": 92.11574096679688, "training_acc": 40.0, "val_loss": 140.5016326904297, "val_acc": 40.0}
{"epoch": 14, "training_loss": 131.46644287109376, "training_acc": 50.0, "val_loss": 203.1642303466797, "val_acc": 60.0}
{"epoch": 15, "training_loss": 220.56502532958984, "training_acc": 50.0, "val_loss": 312.40185546875, "val_acc": 40.0}
{"epoch": 16, "training_loss": 281.1525024414062, "training_acc": 50.0, "val_loss": 299.6245422363281, "val_acc": 40.0}
{"epoch": 17, "training_loss": 295.53728637695315, "training_acc": 30.0, "val_loss": 24.955501556396484, "val_acc": 60.0}
{"epoch": 18, "training_loss": 43.28092956542969, "training_acc": 60.0, "val_loss": 426.5839538574219, "val_acc": 40.0}
{"epoch": 19, "training_loss": 343.904850769043, "training_acc": 50.0, "val_loss": 44.731956481933594, "val_acc": 40.0}
{"epoch": 20, "training_loss": 146.04002380371094, "training_acc": 40.0, "val_loss": 354.721435546875, "val_acc": 60.0}
{"epoch": 21, "training_loss": 412.0490783691406, "training_acc": 50.0, "val_loss": 40.1532096862793, "val_acc": 40.0}
{"epoch": 22, "training_loss": 52.31959838867188, "training_acc": 50.0, "val_loss": 16.869731903076172, "val_acc": 40.0}
{"epoch": 23, "training_loss": 68.91681518554688, "training_acc": 50.0, "val_loss": 294.0821228027344, "val_acc": 60.0}
{"epoch": 24, "training_loss": 330.84925537109376, "training_acc": 50.0, "val_loss": 175.8015899658203, "val_acc": 40.0}
{"epoch": 25, "training_loss": 230.10277709960937, "training_acc": 50.0, "val_loss": 178.56423950195312, "val_acc": 40.0}
{"epoch": 26, "training_loss": 88.7680419921875, "training_acc": 70.0, "val_loss": 397.5870666503906, "val_acc": 60.0}
{"epoch": 27, "training_loss": 509.285595703125, "training_acc": 50.0, "val_loss": 352.964111328125, "val_acc": 60.0}
{"epoch": 28, "training_loss": 373.75452575683596, "training_acc": 50.0, "val_loss": 441.8617858886719, "val_acc": 40.0}
{"epoch": 29, "training_loss": 388.6825256347656, "training_acc": 50.0, "val_loss": 809.2901611328125, "val_acc": 40.0}
{"epoch": 30, "training_loss": 658.5944641113281, "training_acc": 50.0, "val_loss": 358.6172790527344, "val_acc": 40.0}
{"epoch": 31, "training_loss": 307.5511993408203, "training_acc": 40.0, "val_loss": 181.27609252929688, "val_acc": 60.0}
{"epoch": 32, "training_loss": 198.63198547363282, "training_acc": 50.0, "val_loss": 249.9126434326172, "val_acc": 40.0}
{"epoch": 33, "training_loss": 212.01250915527345, "training_acc": 50.0, "val_loss": 251.20730590820312, "val_acc": 40.0}
{"epoch": 34, "training_loss": 174.4033660888672, "training_acc": 50.0, "val_loss": 51.48604965209961, "val_acc": 60.0}
{"epoch": 35, "training_loss": 71.15381164550782, "training_acc": 50.0, "val_loss": 97.41697692871094, "val_acc": 40.0}
{"epoch": 36, "training_loss": 94.90440979003907, "training_acc": 50.0, "val_loss": 134.81651306152344, "val_acc": 60.0}
{"epoch": 37, "training_loss": 106.80868759155274, "training_acc": 50.0, "val_loss": 604.7472534179688, "val_acc": 40.0}
{"epoch": 38, "training_loss": 502.58251953125, "training_acc": 50.0, "val_loss": 1117.2669677734375, "val_acc": 40.0}
{"epoch": 39, "training_loss": 925.2793273925781, "training_acc": 50.0, "val_loss": 895.8367309570312, "val_acc": 40.0}
{"epoch": 40, "training_loss": 654.0833374023438, "training_acc": 50.0, "val_loss": 106.3603286743164, "val_acc": 60.0}
{"epoch": 41, "training_loss": 275.1109619140625, "training_acc": 50.0, "val_loss": 341.65533447265625, "val_acc": 60.0}
