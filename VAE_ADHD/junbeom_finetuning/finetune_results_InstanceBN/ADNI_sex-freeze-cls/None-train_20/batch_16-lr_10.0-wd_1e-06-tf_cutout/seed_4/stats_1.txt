"main_modify.py --pretrained_path None --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 4 --task ADNI_sex --input_option yAware --learning_rate 1e1 --batch_size 16 --weight_decay 1e-6 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 429.47638149261473, "training_acc": 50.0, "val_loss": 538.6658325195312, "val_acc": 60.0}
{"epoch": 1, "training_loss": 758.560693359375, "training_acc": 50.0, "val_loss": 1874.474609375, "val_acc": 40.0}
{"epoch": 2, "training_loss": 1521.05625, "training_acc": 50.0, "val_loss": 702.7504272460938, "val_acc": 40.0}
{"epoch": 3, "training_loss": 457.12305603027346, "training_acc": 60.0, "val_loss": 964.6648559570312, "val_acc": 60.0}
{"epoch": 4, "training_loss": 1355.94638671875, "training_acc": 50.0, "val_loss": 1026.3209228515625, "val_acc": 60.0}
{"epoch": 5, "training_loss": 1177.279833984375, "training_acc": 50.0, "val_loss": 21.37863540649414, "val_acc": 60.0}
{"epoch": 6, "training_loss": 290.5843505859375, "training_acc": 40.0, "val_loss": 1566.541748046875, "val_acc": 40.0}
{"epoch": 7, "training_loss": 1353.89404296875, "training_acc": 50.0, "val_loss": 1519.9677734375, "val_acc": 40.0}
{"epoch": 8, "training_loss": 1186.900146484375, "training_acc": 50.0, "val_loss": 349.9538879394531, "val_acc": 40.0}
{"epoch": 9, "training_loss": 400.4194580078125, "training_acc": 40.0, "val_loss": 640.6205444335938, "val_acc": 60.0}
{"epoch": 10, "training_loss": 820.187353515625, "training_acc": 50.0, "val_loss": 623.08740234375, "val_acc": 60.0}
{"epoch": 11, "training_loss": 692.2488891601563, "training_acc": 50.0, "val_loss": 73.4679183959961, "val_acc": 40.0}
{"epoch": 12, "training_loss": 120.83274536132812, "training_acc": 50.0, "val_loss": 508.6921081542969, "val_acc": 40.0}
{"epoch": 13, "training_loss": 387.84193115234376, "training_acc": 50.0, "val_loss": 102.5137939453125, "val_acc": 60.0}
{"epoch": 14, "training_loss": 146.7056091308594, "training_acc": 50.0, "val_loss": 328.882080078125, "val_acc": 60.0}
{"epoch": 15, "training_loss": 386.83936767578126, "training_acc": 50.0, "val_loss": 4.785785675048828, "val_acc": 40.0}
{"epoch": 16, "training_loss": 19.525767517089843, "training_acc": 50.0, "val_loss": 36.21665954589844, "val_acc": 60.0}
{"epoch": 17, "training_loss": 57.21842651367187, "training_acc": 40.0, "val_loss": 106.44441223144531, "val_acc": 60.0}
{"epoch": 18, "training_loss": 133.74026489257812, "training_acc": 50.0, "val_loss": 164.20542907714844, "val_acc": 40.0}
{"epoch": 19, "training_loss": 149.01499633789064, "training_acc": 50.0, "val_loss": 75.8622055053711, "val_acc": 40.0}
{"epoch": 20, "training_loss": 66.77063751220703, "training_acc": 60.0, "val_loss": 311.2494812011719, "val_acc": 60.0}
{"epoch": 21, "training_loss": 380.87353515625, "training_acc": 50.0, "val_loss": 132.4305877685547, "val_acc": 60.0}
{"epoch": 22, "training_loss": 165.39359130859376, "training_acc": 50.0, "val_loss": 332.19866943359375, "val_acc": 40.0}
{"epoch": 23, "training_loss": 255.4781921386719, "training_acc": 50.0, "val_loss": 118.1128921508789, "val_acc": 60.0}
{"epoch": 24, "training_loss": 170.89401245117188, "training_acc": 50.0, "val_loss": 154.24575805664062, "val_acc": 60.0}
{"epoch": 25, "training_loss": 167.26759490966796, "training_acc": 50.0, "val_loss": 141.04978942871094, "val_acc": 40.0}
{"epoch": 26, "training_loss": 83.01854190826415, "training_acc": 60.0, "val_loss": 23.5439510345459, "val_acc": 60.0}
{"epoch": 27, "training_loss": 76.57604675292968, "training_acc": 40.0, "val_loss": 75.64092254638672, "val_acc": 40.0}
{"epoch": 28, "training_loss": 96.73018188476563, "training_acc": 50.0, "val_loss": 238.96080017089844, "val_acc": 60.0}
{"epoch": 29, "training_loss": 270.91013793945314, "training_acc": 50.0, "val_loss": 174.98826599121094, "val_acc": 40.0}
{"epoch": 30, "training_loss": 163.55992431640624, "training_acc": 50.0, "val_loss": 140.65370178222656, "val_acc": 40.0}
{"epoch": 31, "training_loss": 129.637109375, "training_acc": 50.0, "val_loss": 205.3645477294922, "val_acc": 60.0}
{"epoch": 32, "training_loss": 229.85061340332032, "training_acc": 50.0, "val_loss": 219.8479461669922, "val_acc": 40.0}
{"epoch": 33, "training_loss": 216.19476318359375, "training_acc": 50.0, "val_loss": 117.23042297363281, "val_acc": 40.0}
{"epoch": 34, "training_loss": 93.04669189453125, "training_acc": 60.0, "val_loss": 371.6353454589844, "val_acc": 60.0}
