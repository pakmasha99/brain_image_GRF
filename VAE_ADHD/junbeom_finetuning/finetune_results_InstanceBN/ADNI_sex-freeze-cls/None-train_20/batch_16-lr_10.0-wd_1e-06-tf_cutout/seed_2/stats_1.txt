"main_modify.py --pretrained_path None --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 2 --task ADNI_sex --input_option yAware --learning_rate 1e1 --batch_size 16 --weight_decay 1e-6 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 428.55710010528566, "training_acc": 50.0, "val_loss": 487.44293212890625, "val_acc": 60.0}
{"epoch": 1, "training_loss": 726.41181640625, "training_acc": 50.0, "val_loss": 2017.485595703125, "val_acc": 40.0}
{"epoch": 2, "training_loss": 1635.515966796875, "training_acc": 50.0, "val_loss": 934.8756103515625, "val_acc": 40.0}
{"epoch": 3, "training_loss": 663.4942779541016, "training_acc": 50.0, "val_loss": 480.7694396972656, "val_acc": 60.0}
{"epoch": 4, "training_loss": 592.9374084472656, "training_acc": 50.0, "val_loss": 212.08750915527344, "val_acc": 60.0}
{"epoch": 5, "training_loss": 268.78270263671874, "training_acc": 50.0, "val_loss": 521.1486206054688, "val_acc": 40.0}
{"epoch": 6, "training_loss": 393.82880859375, "training_acc": 50.0, "val_loss": 222.52017211914062, "val_acc": 60.0}
{"epoch": 7, "training_loss": 371.5284790039062, "training_acc": 50.0, "val_loss": 385.80853271484375, "val_acc": 60.0}
{"epoch": 8, "training_loss": 445.8757019042969, "training_acc": 50.0, "val_loss": 396.8558654785156, "val_acc": 40.0}
{"epoch": 9, "training_loss": 343.4184600830078, "training_acc": 50.0, "val_loss": 551.8085327148438, "val_acc": 40.0}
{"epoch": 10, "training_loss": 412.5503448486328, "training_acc": 50.0, "val_loss": 172.3907012939453, "val_acc": 60.0}
{"epoch": 11, "training_loss": 248.47080078125, "training_acc": 50.0, "val_loss": 238.0377960205078, "val_acc": 60.0}
{"epoch": 12, "training_loss": 216.39660110473633, "training_acc": 50.0, "val_loss": 648.00927734375, "val_acc": 40.0}
{"epoch": 13, "training_loss": 565.599755859375, "training_acc": 50.0, "val_loss": 1111.3419189453125, "val_acc": 40.0}
{"epoch": 14, "training_loss": 904.3127075195313, "training_acc": 50.0, "val_loss": 610.7453002929688, "val_acc": 40.0}
{"epoch": 15, "training_loss": 367.090584564209, "training_acc": 50.0, "val_loss": 556.5999145507812, "val_acc": 60.0}
{"epoch": 16, "training_loss": 838.5792236328125, "training_acc": 50.0, "val_loss": 1020.9892578125, "val_acc": 60.0}
{"epoch": 17, "training_loss": 1250.224560546875, "training_acc": 50.0, "val_loss": 641.8821411132812, "val_acc": 60.0}
{"epoch": 18, "training_loss": 691.6885986328125, "training_acc": 50.0, "val_loss": 543.7568969726562, "val_acc": 40.0}
{"epoch": 19, "training_loss": 588.5572998046875, "training_acc": 50.0, "val_loss": 1206.2625732421875, "val_acc": 40.0}
{"epoch": 20, "training_loss": 981.5272827148438, "training_acc": 50.0, "val_loss": 701.4226684570312, "val_acc": 40.0}
{"epoch": 21, "training_loss": 488.0096664428711, "training_acc": 50.0, "val_loss": 422.4926452636719, "val_acc": 60.0}
{"epoch": 22, "training_loss": 646.6617919921875, "training_acc": 50.0, "val_loss": 776.2326049804688, "val_acc": 60.0}
{"epoch": 23, "training_loss": 938.820068359375, "training_acc": 50.0, "val_loss": 374.96173095703125, "val_acc": 60.0}
{"epoch": 24, "training_loss": 441.8428894042969, "training_acc": 40.0, "val_loss": 293.38067626953125, "val_acc": 40.0}
{"epoch": 25, "training_loss": 237.11927642822266, "training_acc": 50.0, "val_loss": 27.8978328704834, "val_acc": 40.0}
{"epoch": 26, "training_loss": 81.92959594726562, "training_acc": 50.0, "val_loss": 341.4811706542969, "val_acc": 60.0}
{"epoch": 27, "training_loss": 403.5946411132812, "training_acc": 50.0, "val_loss": 25.060062408447266, "val_acc": 40.0}
{"epoch": 28, "training_loss": 46.606980895996095, "training_acc": 50.0, "val_loss": 88.99076843261719, "val_acc": 40.0}
{"epoch": 29, "training_loss": 171.703564453125, "training_acc": 30.0, "val_loss": 110.7676010131836, "val_acc": 60.0}
{"epoch": 30, "training_loss": 141.94823608398437, "training_acc": 50.0, "val_loss": 265.34063720703125, "val_acc": 40.0}
{"epoch": 31, "training_loss": 204.4372417449951, "training_acc": 50.0, "val_loss": 143.7704315185547, "val_acc": 60.0}
{"epoch": 32, "training_loss": 193.85545654296874, "training_acc": 50.0, "val_loss": 31.554718017578125, "val_acc": 40.0}
{"epoch": 33, "training_loss": 42.24071350097656, "training_acc": 50.0, "val_loss": 127.52406311035156, "val_acc": 60.0}
{"epoch": 34, "training_loss": 164.59261474609374, "training_acc": 50.0, "val_loss": 6.405330181121826, "val_acc": 60.0}
