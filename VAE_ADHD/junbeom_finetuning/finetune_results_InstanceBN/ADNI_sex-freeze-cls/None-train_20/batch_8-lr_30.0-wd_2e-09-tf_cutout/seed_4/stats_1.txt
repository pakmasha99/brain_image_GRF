"main_modify.py --pretrained_path None --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 4 --task ADNI_sex --input_option yAware --learning_rate 3e1 --batch_size 8 --weight_decay 2e-9 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 2975.8159639835358, "training_acc": 50.0, "val_loss": 3943.544189453125, "val_acc": 40.0}
{"epoch": 1, "training_loss": 5451.5296875, "training_acc": 50.0, "val_loss": 4133.3076171875, "val_acc": 40.0}
{"epoch": 2, "training_loss": 1239.172802734375, "training_acc": 60.0, "val_loss": 3802.19921875, "val_acc": 60.0}
{"epoch": 3, "training_loss": 4965.6994140625, "training_acc": 50.0, "val_loss": 3513.33447265625, "val_acc": 60.0}
{"epoch": 4, "training_loss": 2880.0448974609376, "training_acc": 50.0, "val_loss": 2784.4033203125, "val_acc": 40.0}
{"epoch": 5, "training_loss": 3541.93056640625, "training_acc": 50.0, "val_loss": 5867.28466796875, "val_acc": 40.0}
{"epoch": 6, "training_loss": 4296.660888671875, "training_acc": 50.0, "val_loss": 1100.232421875, "val_acc": 40.0}
{"epoch": 7, "training_loss": 1121.97548828125, "training_acc": 60.0, "val_loss": 2398.958251953125, "val_acc": 60.0}
{"epoch": 8, "training_loss": 2946.45107421875, "training_acc": 50.0, "val_loss": 463.97027587890625, "val_acc": 60.0}
{"epoch": 9, "training_loss": 949.72158203125, "training_acc": 60.0, "val_loss": 2256.29541015625, "val_acc": 40.0}
{"epoch": 10, "training_loss": 1242.5827697753907, "training_acc": 50.0, "val_loss": 560.4813232421875, "val_acc": 60.0}
{"epoch": 11, "training_loss": 544.690380859375, "training_acc": 50.0, "val_loss": 445.61572265625, "val_acc": 40.0}
{"epoch": 12, "training_loss": 273.34520568847654, "training_acc": 40.0, "val_loss": 484.4798889160156, "val_acc": 60.0}
{"epoch": 13, "training_loss": 449.38152770996095, "training_acc": 50.0, "val_loss": 1506.6258544921875, "val_acc": 40.0}
{"epoch": 14, "training_loss": 1464.921728515625, "training_acc": 50.0, "val_loss": 1148.9149169921875, "val_acc": 40.0}
{"epoch": 15, "training_loss": 381.5755310058594, "training_acc": 60.0, "val_loss": 381.6855163574219, "val_acc": 60.0}
{"epoch": 16, "training_loss": 351.1827075719833, "training_acc": 60.0, "val_loss": 450.9786682128906, "val_acc": 40.0}
{"epoch": 17, "training_loss": 512.5348022460937, "training_acc": 50.0, "val_loss": 227.74038696289062, "val_acc": 60.0}
{"epoch": 18, "training_loss": 1136.3106689453125, "training_acc": 30.0, "val_loss": 1123.1671142578125, "val_acc": 40.0}
{"epoch": 19, "training_loss": 394.93044033050535, "training_acc": 65.0, "val_loss": 343.5036315917969, "val_acc": 60.0}
{"epoch": 20, "training_loss": 364.005615234375, "training_acc": 50.0, "val_loss": 180.67135620117188, "val_acc": 60.0}
{"epoch": 21, "training_loss": 156.00208587646483, "training_acc": 50.0, "val_loss": 324.97027587890625, "val_acc": 60.0}
{"epoch": 22, "training_loss": 443.11610107421876, "training_acc": 40.0, "val_loss": 406.933837890625, "val_acc": 60.0}
{"epoch": 23, "training_loss": 381.67561569213865, "training_acc": 50.0, "val_loss": 154.69224548339844, "val_acc": 60.0}
{"epoch": 24, "training_loss": 165.48809432983398, "training_acc": 50.0, "val_loss": 417.0511779785156, "val_acc": 40.0}
{"epoch": 25, "training_loss": 370.364453125, "training_acc": 30.0, "val_loss": 46.993019104003906, "val_acc": 60.0}
{"epoch": 26, "training_loss": 82.57262420654297, "training_acc": 60.0, "val_loss": 385.4152526855469, "val_acc": 40.0}
{"epoch": 27, "training_loss": 365.79636535644534, "training_acc": 30.0, "val_loss": 58.879310607910156, "val_acc": 60.0}
{"epoch": 28, "training_loss": 70.85152282714844, "training_acc": 60.0, "val_loss": 731.884765625, "val_acc": 60.0}
{"epoch": 29, "training_loss": 1028.8979614257812, "training_acc": 50.0, "val_loss": 63.6176872253418, "val_acc": 40.0}
{"epoch": 30, "training_loss": 136.0910858154297, "training_acc": 60.0, "val_loss": 147.40023803710938, "val_acc": 60.0}
{"epoch": 31, "training_loss": 427.5719848632813, "training_acc": 40.0, "val_loss": 258.0674743652344, "val_acc": 60.0}
{"epoch": 32, "training_loss": 523.4089065551758, "training_acc": 30.0, "val_loss": 400.55059814453125, "val_acc": 40.0}
{"epoch": 33, "training_loss": 583.0312622070312, "training_acc": 50.0, "val_loss": 511.1310729980469, "val_acc": 60.0}
{"epoch": 34, "training_loss": 288.07696533203125, "training_acc": 60.0, "val_loss": 58.729488372802734, "val_acc": 60.0}
{"epoch": 35, "training_loss": 227.1327926635742, "training_acc": 50.0, "val_loss": 1046.82763671875, "val_acc": 40.0}
{"epoch": 36, "training_loss": 661.2728149414063, "training_acc": 50.0, "val_loss": 821.3884887695312, "val_acc": 60.0}
{"epoch": 37, "training_loss": 618.7956981658936, "training_acc": 60.0, "val_loss": 535.8280639648438, "val_acc": 40.0}
{"epoch": 38, "training_loss": 281.03369140625, "training_acc": 70.0, "val_loss": 481.48681640625, "val_acc": 60.0}
{"epoch": 39, "training_loss": 416.82614560723306, "training_acc": 60.0, "val_loss": 948.81396484375, "val_acc": 40.0}
{"epoch": 40, "training_loss": 853.8288818359375, "training_acc": 50.0, "val_loss": 489.2643127441406, "val_acc": 60.0}
{"epoch": 41, "training_loss": 1140.6469970703124, "training_acc": 50.0, "val_loss": 291.6471252441406, "val_acc": 60.0}
{"epoch": 42, "training_loss": 709.11162109375, "training_acc": 60.0, "val_loss": 2474.28271484375, "val_acc": 40.0}
{"epoch": 43, "training_loss": 1628.01640625, "training_acc": 50.0, "val_loss": 513.3654174804688, "val_acc": 60.0}
{"epoch": 44, "training_loss": 1345.2483154296874, "training_acc": 50.0, "val_loss": 994.4000244140625, "val_acc": 60.0}
