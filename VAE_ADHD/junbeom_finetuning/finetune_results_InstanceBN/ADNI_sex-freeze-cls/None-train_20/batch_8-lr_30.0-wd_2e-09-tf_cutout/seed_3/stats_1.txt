"main_modify.py --pretrained_path None --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 3 --task ADNI_sex --input_option yAware --learning_rate 3e1 --batch_size 8 --weight_decay 2e-9 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 1964.782798743248, "training_acc": 50.0, "val_loss": 4295.87353515625, "val_acc": 60.0}
{"epoch": 1, "training_loss": 6630.503125, "training_acc": 50.0, "val_loss": 4988.94482421875, "val_acc": 60.0}
{"epoch": 2, "training_loss": 4558.068817138672, "training_acc": 50.0, "val_loss": 2936.627685546875, "val_acc": 40.0}
{"epoch": 3, "training_loss": 3561.58857421875, "training_acc": 50.0, "val_loss": 5353.34326171875, "val_acc": 40.0}
{"epoch": 4, "training_loss": 3728.0570068359375, "training_acc": 50.0, "val_loss": 213.1023406982422, "val_acc": 60.0}
{"epoch": 5, "training_loss": 1846.4498901367188, "training_acc": 50.0, "val_loss": 1086.066650390625, "val_acc": 60.0}
{"epoch": 6, "training_loss": 593.5924072265625, "training_acc": 60.0, "val_loss": 3793.813232421875, "val_acc": 40.0}
{"epoch": 7, "training_loss": 3426.32265625, "training_acc": 50.0, "val_loss": 2925.038818359375, "val_acc": 40.0}
{"epoch": 8, "training_loss": 1883.28720703125, "training_acc": 50.0, "val_loss": 2281.091796875, "val_acc": 60.0}
{"epoch": 9, "training_loss": 3210.31572265625, "training_acc": 50.0, "val_loss": 1821.8387451171875, "val_acc": 60.0}
{"epoch": 10, "training_loss": 1459.9279296875, "training_acc": 50.0, "val_loss": 2690.0, "val_acc": 40.0}
{"epoch": 11, "training_loss": 2212.801965332031, "training_acc": 50.0, "val_loss": 1303.8990478515625, "val_acc": 40.0}
{"epoch": 12, "training_loss": 883.3655395507812, "training_acc": 40.0, "val_loss": 541.1286010742188, "val_acc": 60.0}
{"epoch": 13, "training_loss": 472.5317626953125, "training_acc": 50.0, "val_loss": 2109.210205078125, "val_acc": 40.0}
{"epoch": 14, "training_loss": 1648.1768310546875, "training_acc": 50.0, "val_loss": 122.13909912109375, "val_acc": 60.0}
{"epoch": 15, "training_loss": 393.0013000488281, "training_acc": 50.0, "val_loss": 28.028898239135742, "val_acc": 60.0}
{"epoch": 16, "training_loss": 522.4195568084717, "training_acc": 60.0, "val_loss": 1477.5433349609375, "val_acc": 40.0}
{"epoch": 17, "training_loss": 849.8040161132812, "training_acc": 50.0, "val_loss": 900.4594116210938, "val_acc": 60.0}
{"epoch": 18, "training_loss": 905.1491664886474, "training_acc": 40.0, "val_loss": 33.96316909790039, "val_acc": 60.0}
{"epoch": 19, "training_loss": 156.74256057739257, "training_acc": 60.0, "val_loss": 362.8852233886719, "val_acc": 60.0}
{"epoch": 20, "training_loss": 378.1656494140625, "training_acc": 50.0, "val_loss": 535.8450317382812, "val_acc": 40.0}
{"epoch": 21, "training_loss": 269.2332702636719, "training_acc": 50.0, "val_loss": 813.0562744140625, "val_acc": 40.0}
{"epoch": 22, "training_loss": 814.689208984375, "training_acc": 50.0, "val_loss": 431.11328125, "val_acc": 60.0}
{"epoch": 23, "training_loss": 563.2009979248047, "training_acc": 50.0, "val_loss": 200.10121154785156, "val_acc": 40.0}
{"epoch": 24, "training_loss": 97.96993408203124, "training_acc": 60.0, "val_loss": 465.037841796875, "val_acc": 40.0}
{"epoch": 25, "training_loss": 274.7480804443359, "training_acc": 40.0, "val_loss": 1109.3280029296875, "val_acc": 40.0}
{"epoch": 26, "training_loss": 1037.7049072265625, "training_acc": 50.0, "val_loss": 39.08185577392578, "val_acc": 60.0}
{"epoch": 27, "training_loss": 125.33690185546875, "training_acc": 35.0, "val_loss": 983.5402221679688, "val_acc": 60.0}
{"epoch": 28, "training_loss": 839.2848815917969, "training_acc": 50.0, "val_loss": 1487.4716796875, "val_acc": 40.0}
{"epoch": 29, "training_loss": 1425.1682861328125, "training_acc": 50.0, "val_loss": 1420.7213134765625, "val_acc": 40.0}
{"epoch": 30, "training_loss": 720.9889526367188, "training_acc": 45.0, "val_loss": 336.0036315917969, "val_acc": 60.0}
{"epoch": 31, "training_loss": 209.08321228027344, "training_acc": 60.0, "val_loss": 247.6592254638672, "val_acc": 60.0}
{"epoch": 32, "training_loss": 208.03962249755858, "training_acc": 60.0, "val_loss": 823.3064575195312, "val_acc": 40.0}
{"epoch": 33, "training_loss": 406.64141235351565, "training_acc": 60.0, "val_loss": 759.7279663085938, "val_acc": 60.0}
{"epoch": 34, "training_loss": 676.165251159668, "training_acc": 50.0, "val_loss": 106.46024322509766, "val_acc": 40.0}
