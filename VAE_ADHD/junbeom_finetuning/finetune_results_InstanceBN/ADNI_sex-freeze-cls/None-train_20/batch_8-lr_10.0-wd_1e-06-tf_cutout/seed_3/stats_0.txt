"main_modify.py --pretrained_path None --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 3 --task ADNI_sex --input_option yAware --learning_rate 1e1 --batch_size 8 --weight_decay 1e-6 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 1496.5057759284973, "training_acc": 50.0, "val_loss": 330.9165954589844, "val_acc": 60.0}
{"epoch": 1, "training_loss": 682.4521850585937, "training_acc": 50.0, "val_loss": 164.8037872314453, "val_acc": 60.0}
{"epoch": 2, "training_loss": 460.9326232910156, "training_acc": 60.0, "val_loss": 1293.4910888671875, "val_acc": 40.0}
{"epoch": 3, "training_loss": 801.3348205566406, "training_acc": 50.0, "val_loss": 411.1214904785156, "val_acc": 60.0}
{"epoch": 4, "training_loss": 676.9765075683594, "training_acc": 50.0, "val_loss": 585.7201538085938, "val_acc": 60.0}
{"epoch": 5, "training_loss": 555.2209838867187, "training_acc": 40.0, "val_loss": 535.4497680664062, "val_acc": 40.0}
{"epoch": 6, "training_loss": 368.70823669433594, "training_acc": 40.0, "val_loss": 30.233510971069336, "val_acc": 60.0}
{"epoch": 7, "training_loss": 160.96710205078125, "training_acc": 50.0, "val_loss": 12.05667781829834, "val_acc": 40.0}
{"epoch": 8, "training_loss": 378.45257873535155, "training_acc": 40.0, "val_loss": 497.5791015625, "val_acc": 60.0}
{"epoch": 9, "training_loss": 509.65318603515624, "training_acc": 40.0, "val_loss": 334.78143310546875, "val_acc": 40.0}
{"epoch": 10, "training_loss": 147.4756591796875, "training_acc": 70.0, "val_loss": 151.1905059814453, "val_acc": 60.0}
{"epoch": 11, "training_loss": 138.4880401611328, "training_acc": 25.0, "val_loss": 282.3155212402344, "val_acc": 60.0}
{"epoch": 12, "training_loss": 479.56427001953125, "training_acc": 50.0, "val_loss": 174.102783203125, "val_acc": 60.0}
{"epoch": 13, "training_loss": 328.1195434570312, "training_acc": 40.0, "val_loss": 628.6851806640625, "val_acc": 40.0}
{"epoch": 14, "training_loss": 364.72479858398435, "training_acc": 50.0, "val_loss": 312.5412292480469, "val_acc": 60.0}
{"epoch": 15, "training_loss": 465.1094055175781, "training_acc": 50.0, "val_loss": 418.86602783203125, "val_acc": 60.0}
{"epoch": 16, "training_loss": 345.6792053222656, "training_acc": 50.0, "val_loss": 408.1876525878906, "val_acc": 40.0}
{"epoch": 17, "training_loss": 400.1578094482422, "training_acc": 50.0, "val_loss": 119.6907958984375, "val_acc": 60.0}
{"epoch": 18, "training_loss": 224.25331115722656, "training_acc": 50.0, "val_loss": 103.05513763427734, "val_acc": 60.0}
{"epoch": 19, "training_loss": 177.62288818359374, "training_acc": 50.0, "val_loss": 193.64161682128906, "val_acc": 40.0}
{"epoch": 20, "training_loss": 213.40145874023438, "training_acc": 40.0, "val_loss": 82.24253845214844, "val_acc": 60.0}
{"epoch": 21, "training_loss": 127.56947631835938, "training_acc": 60.0, "val_loss": 169.8427734375, "val_acc": 40.0}
{"epoch": 22, "training_loss": 128.364404296875, "training_acc": 60.0, "val_loss": 30.669342041015625, "val_acc": 60.0}
{"epoch": 23, "training_loss": 200.864599609375, "training_acc": 60.0, "val_loss": 382.64959716796875, "val_acc": 40.0}
{"epoch": 24, "training_loss": 198.99280853271483, "training_acc": 40.0, "val_loss": 4.275163650512695, "val_acc": 60.0}
{"epoch": 25, "training_loss": 40.97646200656891, "training_acc": 60.0, "val_loss": 56.44741439819336, "val_acc": 60.0}
{"epoch": 26, "training_loss": 128.76585998535157, "training_acc": 50.0, "val_loss": 5.132920265197754, "val_acc": 60.0}
{"epoch": 27, "training_loss": 284.0685005187988, "training_acc": 45.0, "val_loss": 236.6631317138672, "val_acc": 60.0}
{"epoch": 28, "training_loss": 147.624613571167, "training_acc": 60.0, "val_loss": 68.0303726196289, "val_acc": 40.0}
{"epoch": 29, "training_loss": 241.6765625, "training_acc": 40.0, "val_loss": 211.59117126464844, "val_acc": 60.0}
{"epoch": 30, "training_loss": 179.14344177246093, "training_acc": 50.0, "val_loss": 675.2156982421875, "val_acc": 40.0}
{"epoch": 31, "training_loss": 572.7910278320312, "training_acc": 50.0, "val_loss": 7.279956817626953, "val_acc": 60.0}
{"epoch": 32, "training_loss": 606.3987983703613, "training_acc": 40.0, "val_loss": 964.5284423828125, "val_acc": 60.0}
{"epoch": 33, "training_loss": 1065.2563232421876, "training_acc": 50.0, "val_loss": 275.99114990234375, "val_acc": 60.0}
{"epoch": 34, "training_loss": 415.2699829101563, "training_acc": 40.0, "val_loss": 1074.7484130859375, "val_acc": 40.0}
{"epoch": 35, "training_loss": 934.5252685546875, "training_acc": 50.0, "val_loss": 577.0376586914062, "val_acc": 40.0}
{"epoch": 36, "training_loss": 136.00924987792968, "training_acc": 60.0, "val_loss": 936.8258666992188, "val_acc": 60.0}
{"epoch": 37, "training_loss": 1286.4318969726562, "training_acc": 50.0, "val_loss": 1069.7841796875, "val_acc": 60.0}
{"epoch": 38, "training_loss": 1094.0953369140625, "training_acc": 50.0, "val_loss": 72.14399719238281, "val_acc": 60.0}
{"epoch": 39, "training_loss": 272.4682678222656, "training_acc": 70.0, "val_loss": 1482.129638671875, "val_acc": 40.0}
{"epoch": 40, "training_loss": 1282.36845703125, "training_acc": 50.0, "val_loss": 1034.5306396484375, "val_acc": 40.0}
{"epoch": 41, "training_loss": 730.7159057617188, "training_acc": 40.0, "val_loss": 668.0552978515625, "val_acc": 60.0}
{"epoch": 42, "training_loss": 1061.2750671386718, "training_acc": 50.0, "val_loss": 576.8070678710938, "val_acc": 60.0}
{"epoch": 43, "training_loss": 352.4027587890625, "training_acc": 60.0, "val_loss": 906.8646850585938, "val_acc": 40.0}
