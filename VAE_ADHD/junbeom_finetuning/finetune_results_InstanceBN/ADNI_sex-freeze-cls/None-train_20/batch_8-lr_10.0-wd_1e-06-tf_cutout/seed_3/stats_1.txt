"main_modify.py --pretrained_path None --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 3 --task ADNI_sex --input_option yAware --learning_rate 1e1 --batch_size 8 --weight_decay 1e-6 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 1024.2162197113037, "training_acc": 50.0, "val_loss": 986.7877197265625, "val_acc": 40.0}
{"epoch": 1, "training_loss": 1021.33837890625, "training_acc": 50.0, "val_loss": 347.3205261230469, "val_acc": 40.0}
{"epoch": 2, "training_loss": 885.822021484375, "training_acc": 40.0, "val_loss": 1065.8182373046875, "val_acc": 60.0}
{"epoch": 3, "training_loss": 1009.4880432128906, "training_acc": 50.0, "val_loss": 452.1378479003906, "val_acc": 40.0}
{"epoch": 4, "training_loss": 627.6370422363282, "training_acc": 50.0, "val_loss": 866.40380859375, "val_acc": 40.0}
{"epoch": 5, "training_loss": 398.62062606811526, "training_acc": 60.0, "val_loss": 299.5962829589844, "val_acc": 60.0}
{"epoch": 6, "training_loss": 316.5009113311768, "training_acc": 50.0, "val_loss": 360.102294921875, "val_acc": 40.0}
{"epoch": 7, "training_loss": 306.902294921875, "training_acc": 50.0, "val_loss": 166.36715698242188, "val_acc": 60.0}
{"epoch": 8, "training_loss": 188.0562744140625, "training_acc": 50.0, "val_loss": 496.60430908203125, "val_acc": 40.0}
{"epoch": 9, "training_loss": 541.4203735351563, "training_acc": 50.0, "val_loss": 445.91192626953125, "val_acc": 40.0}
{"epoch": 10, "training_loss": 142.31794128417968, "training_acc": 60.0, "val_loss": 693.8098754882812, "val_acc": 60.0}
{"epoch": 11, "training_loss": 901.8281005859375, "training_acc": 50.0, "val_loss": 468.85772705078125, "val_acc": 60.0}
{"epoch": 12, "training_loss": 319.8669006347656, "training_acc": 50.0, "val_loss": 1110.665771484375, "val_acc": 40.0}
{"epoch": 13, "training_loss": 963.644140625, "training_acc": 50.0, "val_loss": 830.4757080078125, "val_acc": 40.0}
{"epoch": 14, "training_loss": 487.820166015625, "training_acc": 50.0, "val_loss": 606.4549560546875, "val_acc": 60.0}
{"epoch": 15, "training_loss": 758.140673828125, "training_acc": 50.0, "val_loss": 293.968505859375, "val_acc": 60.0}
{"epoch": 16, "training_loss": 431.9299682617187, "training_acc": 40.0, "val_loss": 626.9617309570312, "val_acc": 40.0}
{"epoch": 17, "training_loss": 348.97754669189453, "training_acc": 50.0, "val_loss": 205.9993133544922, "val_acc": 60.0}
{"epoch": 18, "training_loss": 201.24018478393555, "training_acc": 50.0, "val_loss": 57.373268127441406, "val_acc": 40.0}
{"epoch": 19, "training_loss": 142.9457763671875, "training_acc": 40.0, "val_loss": 154.1376190185547, "val_acc": 40.0}
{"epoch": 20, "training_loss": 144.3292678833008, "training_acc": 50.0, "val_loss": 209.08535766601562, "val_acc": 60.0}
{"epoch": 21, "training_loss": 336.034375, "training_acc": 50.0, "val_loss": 43.831024169921875, "val_acc": 40.0}
{"epoch": 22, "training_loss": 105.25066375732422, "training_acc": 50.0, "val_loss": 156.06253051757812, "val_acc": 60.0}
{"epoch": 23, "training_loss": 279.58113555908204, "training_acc": 50.0, "val_loss": 86.97256469726562, "val_acc": 40.0}
{"epoch": 24, "training_loss": 86.58380928039551, "training_acc": 50.0, "val_loss": 321.4142150878906, "val_acc": 60.0}
{"epoch": 25, "training_loss": 622.0704223632813, "training_acc": 50.0, "val_loss": 304.7718200683594, "val_acc": 60.0}
{"epoch": 26, "training_loss": 219.88680114746094, "training_acc": 50.0, "val_loss": 376.4045104980469, "val_acc": 40.0}
{"epoch": 27, "training_loss": 235.7418243408203, "training_acc": 50.0, "val_loss": 248.3405303955078, "val_acc": 60.0}
{"epoch": 28, "training_loss": 324.6890014648437, "training_acc": 30.0, "val_loss": 242.2490997314453, "val_acc": 40.0}
{"epoch": 29, "training_loss": 98.31570968627929, "training_acc": 50.0, "val_loss": 161.3164520263672, "val_acc": 40.0}
{"epoch": 30, "training_loss": 117.69830932617188, "training_acc": 50.0, "val_loss": 101.0968017578125, "val_acc": 60.0}
{"epoch": 31, "training_loss": 41.619134336709976, "training_acc": 65.0, "val_loss": 79.38001251220703, "val_acc": 60.0}
{"epoch": 32, "training_loss": 61.96339111328125, "training_acc": 60.0, "val_loss": 421.9748229980469, "val_acc": 40.0}
{"epoch": 33, "training_loss": 220.9971851348877, "training_acc": 55.0, "val_loss": 317.2809143066406, "val_acc": 60.0}
{"epoch": 34, "training_loss": 484.2912231445313, "training_acc": 50.0, "val_loss": 188.3278350830078, "val_acc": 60.0}
{"epoch": 35, "training_loss": 52.19412078857422, "training_acc": 80.0, "val_loss": 444.06256103515625, "val_acc": 40.0}
{"epoch": 36, "training_loss": 291.02619018554685, "training_acc": 50.0, "val_loss": 324.86083984375, "val_acc": 60.0}
{"epoch": 37, "training_loss": 444.3607238769531, "training_acc": 50.0, "val_loss": 242.3753204345703, "val_acc": 60.0}
{"epoch": 38, "training_loss": 299.4137390136719, "training_acc": 40.0, "val_loss": 233.33694458007812, "val_acc": 40.0}
{"epoch": 39, "training_loss": 110.3862075805664, "training_acc": 60.0, "val_loss": 32.22860336303711, "val_acc": 60.0}
{"epoch": 40, "training_loss": 254.8670440673828, "training_acc": 40.0, "val_loss": 301.7904357910156, "val_acc": 40.0}
{"epoch": 41, "training_loss": 90.36560363769532, "training_acc": 60.0, "val_loss": 4.594493389129639, "val_acc": 60.0}
{"epoch": 42, "training_loss": 155.3176694869995, "training_acc": 50.0, "val_loss": 109.52458953857422, "val_acc": 60.0}
{"epoch": 43, "training_loss": 160.88135299682617, "training_acc": 50.0, "val_loss": 138.44664001464844, "val_acc": 40.0}
{"epoch": 44, "training_loss": 151.0760940551758, "training_acc": 55.0, "val_loss": 83.67291259765625, "val_acc": 60.0}
{"epoch": 45, "training_loss": 43.08079597949982, "training_acc": 65.0, "val_loss": 82.05008697509766, "val_acc": 40.0}
{"epoch": 46, "training_loss": 25.482693672180176, "training_acc": 70.0, "val_loss": 55.135372161865234, "val_acc": 60.0}
{"epoch": 47, "training_loss": 41.21224479675293, "training_acc": 55.0, "val_loss": 194.86717224121094, "val_acc": 40.0}
{"epoch": 48, "training_loss": 133.57784729003907, "training_acc": 50.0, "val_loss": 33.02241897583008, "val_acc": 60.0}
{"epoch": 49, "training_loss": 39.452618789672854, "training_acc": 70.0, "val_loss": 68.47318267822266, "val_acc": 60.0}
{"epoch": 50, "training_loss": 76.19066162109375, "training_acc": 40.0, "val_loss": 5.129976272583008, "val_acc": 60.0}
{"epoch": 51, "training_loss": 91.13367652893066, "training_acc": 35.0, "val_loss": 63.5379638671875, "val_acc": 60.0}
{"epoch": 52, "training_loss": 166.15219116210938, "training_acc": 50.0, "val_loss": 118.53136444091797, "val_acc": 40.0}
{"epoch": 53, "training_loss": 147.8390625, "training_acc": 60.0, "val_loss": 160.39439392089844, "val_acc": 60.0}
{"epoch": 54, "training_loss": 337.0352355957031, "training_acc": 30.0, "val_loss": 102.17573547363281, "val_acc": 40.0}
{"epoch": 55, "training_loss": 282.7185577392578, "training_acc": 50.0, "val_loss": 421.12652587890625, "val_acc": 60.0}
{"epoch": 56, "training_loss": 294.7544826507568, "training_acc": 60.0, "val_loss": 285.5309143066406, "val_acc": 40.0}
{"epoch": 57, "training_loss": 224.78170166015624, "training_acc": 50.0, "val_loss": 255.45860290527344, "val_acc": 60.0}
{"epoch": 58, "training_loss": 520.5957092285156, "training_acc": 50.0, "val_loss": 244.3073272705078, "val_acc": 60.0}
{"epoch": 59, "training_loss": 245.0064208984375, "training_acc": 50.0, "val_loss": 592.2469482421875, "val_acc": 40.0}
{"epoch": 60, "training_loss": 398.6645084381104, "training_acc": 50.0, "val_loss": 274.83135986328125, "val_acc": 60.0}
