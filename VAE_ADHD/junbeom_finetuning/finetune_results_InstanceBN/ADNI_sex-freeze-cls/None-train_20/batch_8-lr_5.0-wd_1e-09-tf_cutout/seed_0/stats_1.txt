"main_modify.py --pretrained_path None --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_sex --input_option yAware --learning_rate 5e0 --batch_size 8 --weight_decay 1e-9 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 579.8362676382064, "training_acc": 40.0, "val_loss": 257.8031921386719, "val_acc": 60.0}
{"epoch": 1, "training_loss": 581.4251647949219, "training_acc": 50.0, "val_loss": 330.420654296875, "val_acc": 60.0}
{"epoch": 2, "training_loss": 252.3662124633789, "training_acc": 60.0, "val_loss": 846.2416381835938, "val_acc": 40.0}
{"epoch": 3, "training_loss": 732.42236328125, "training_acc": 50.0, "val_loss": 541.5592651367188, "val_acc": 40.0}
{"epoch": 4, "training_loss": 342.67474365234375, "training_acc": 40.0, "val_loss": 511.4647521972656, "val_acc": 60.0}
{"epoch": 5, "training_loss": 675.5735473632812, "training_acc": 50.0, "val_loss": 389.5650939941406, "val_acc": 60.0}
{"epoch": 6, "training_loss": 331.57247467041014, "training_acc": 50.0, "val_loss": 340.1073913574219, "val_acc": 40.0}
{"epoch": 7, "training_loss": 265.3544860839844, "training_acc": 50.0, "val_loss": 34.79638671875, "val_acc": 40.0}
{"epoch": 8, "training_loss": 239.9931182861328, "training_acc": 40.0, "val_loss": 357.7132263183594, "val_acc": 60.0}
{"epoch": 9, "training_loss": 351.0454467773437, "training_acc": 50.0, "val_loss": 99.326416015625, "val_acc": 40.0}
{"epoch": 10, "training_loss": 150.2726821899414, "training_acc": 50.0, "val_loss": 234.35850524902344, "val_acc": 40.0}
{"epoch": 11, "training_loss": 189.6487808227539, "training_acc": 40.0, "val_loss": 236.73306274414062, "val_acc": 60.0}
{"epoch": 12, "training_loss": 236.0103973388672, "training_acc": 50.0, "val_loss": 151.759521484375, "val_acc": 40.0}
{"epoch": 13, "training_loss": 217.33384399414064, "training_acc": 50.0, "val_loss": 149.81668090820312, "val_acc": 40.0}
{"epoch": 14, "training_loss": 44.99355773925781, "training_acc": 70.0, "val_loss": 129.15342712402344, "val_acc": 60.0}
{"epoch": 15, "training_loss": 140.42646484375, "training_acc": 40.0, "val_loss": 110.129638671875, "val_acc": 40.0}
{"epoch": 16, "training_loss": 80.0629898071289, "training_acc": 40.0, "val_loss": 119.57820129394531, "val_acc": 40.0}
{"epoch": 17, "training_loss": 140.70097961425782, "training_acc": 50.0, "val_loss": 21.293201446533203, "val_acc": 60.0}
{"epoch": 18, "training_loss": 29.748997116088866, "training_acc": 50.0, "val_loss": 10.170610427856445, "val_acc": 60.0}
{"epoch": 19, "training_loss": 48.00430145263672, "training_acc": 40.0, "val_loss": 87.22396850585938, "val_acc": 60.0}
{"epoch": 20, "training_loss": 129.81934509277343, "training_acc": 50.0, "val_loss": 100.78614807128906, "val_acc": 40.0}
{"epoch": 21, "training_loss": 123.82652282714844, "training_acc": 50.0, "val_loss": 11.241673469543457, "val_acc": 40.0}
{"epoch": 22, "training_loss": 83.54325637817382, "training_acc": 60.0, "val_loss": 153.38546752929688, "val_acc": 60.0}
{"epoch": 23, "training_loss": 140.49269104003906, "training_acc": 50.0, "val_loss": 242.00425720214844, "val_acc": 40.0}
{"epoch": 24, "training_loss": 146.48875885009767, "training_acc": 50.0, "val_loss": 157.17796325683594, "val_acc": 60.0}
{"epoch": 25, "training_loss": 282.22169799804686, "training_acc": 50.0, "val_loss": 142.682861328125, "val_acc": 60.0}
{"epoch": 26, "training_loss": 87.49025115966796, "training_acc": 60.0, "val_loss": 158.18214416503906, "val_acc": 40.0}
{"epoch": 27, "training_loss": 82.33355026245117, "training_acc": 60.0, "val_loss": 140.29331970214844, "val_acc": 60.0}
{"epoch": 28, "training_loss": 160.74885139465331, "training_acc": 50.0, "val_loss": 148.85446166992188, "val_acc": 40.0}
{"epoch": 29, "training_loss": 124.48783721923829, "training_acc": 50.0, "val_loss": 42.89656448364258, "val_acc": 60.0}
{"epoch": 30, "training_loss": 60.23290519714355, "training_acc": 50.0, "val_loss": 177.5278778076172, "val_acc": 40.0}
{"epoch": 31, "training_loss": 144.38980712890626, "training_acc": 50.0, "val_loss": 47.431861877441406, "val_acc": 60.0}
{"epoch": 32, "training_loss": 83.51799926757812, "training_acc": 50.0, "val_loss": 31.82706642150879, "val_acc": 40.0}
{"epoch": 33, "training_loss": 43.71768035888672, "training_acc": 50.0, "val_loss": 14.180215835571289, "val_acc": 60.0}
{"epoch": 34, "training_loss": 64.3989974975586, "training_acc": 50.0, "val_loss": 0.45744943618774414, "val_acc": 80.0}
{"epoch": 35, "training_loss": 11.440050506591797, "training_acc": 55.0, "val_loss": 95.35206604003906, "val_acc": 60.0}
{"epoch": 36, "training_loss": 90.42635650634766, "training_acc": 50.0, "val_loss": 193.8306121826172, "val_acc": 40.0}
{"epoch": 37, "training_loss": 100.82946510314942, "training_acc": 60.0, "val_loss": 88.28411865234375, "val_acc": 60.0}
{"epoch": 38, "training_loss": 102.25147552490235, "training_acc": 50.0, "val_loss": 292.1052551269531, "val_acc": 40.0}
{"epoch": 39, "training_loss": 323.20908508300784, "training_acc": 50.0, "val_loss": 383.41790771484375, "val_acc": 40.0}
{"epoch": 40, "training_loss": 154.9208417892456, "training_acc": 50.0, "val_loss": 290.4079284667969, "val_acc": 60.0}
{"epoch": 41, "training_loss": 543.4486206054687, "training_acc": 50.0, "val_loss": 556.2548217773438, "val_acc": 60.0}
{"epoch": 42, "training_loss": 601.9511169433594, "training_acc": 50.0, "val_loss": 13.561795234680176, "val_acc": 60.0}
{"epoch": 43, "training_loss": 288.5370346069336, "training_acc": 40.0, "val_loss": 749.7919921875, "val_acc": 40.0}
{"epoch": 44, "training_loss": 576.1858154296875, "training_acc": 50.0, "val_loss": 303.87847900390625, "val_acc": 40.0}
{"epoch": 45, "training_loss": 176.61680297851564, "training_acc": 50.0, "val_loss": 251.69131469726562, "val_acc": 60.0}
{"epoch": 46, "training_loss": 275.6096481323242, "training_acc": 50.0, "val_loss": 98.5032958984375, "val_acc": 40.0}
{"epoch": 47, "training_loss": 120.8070915222168, "training_acc": 50.0, "val_loss": 0.18031221628189087, "val_acc": 100.0}
{"epoch": 48, "training_loss": 26.041764640808104, "training_acc": 60.0, "val_loss": 95.96788787841797, "val_acc": 40.0}
{"epoch": 49, "training_loss": 73.46960067749023, "training_acc": 50.0, "val_loss": 28.297454833984375, "val_acc": 60.0}
{"epoch": 50, "training_loss": 24.469204044342042, "training_acc": 50.0, "val_loss": 133.5196533203125, "val_acc": 40.0}
{"epoch": 51, "training_loss": 99.83138732910156, "training_acc": 40.0, "val_loss": 12.140316009521484, "val_acc": 40.0}
{"epoch": 52, "training_loss": 34.91224365234375, "training_acc": 40.0, "val_loss": 54.544830322265625, "val_acc": 60.0}
{"epoch": 53, "training_loss": 49.49170818328857, "training_acc": 45.0, "val_loss": 19.365028381347656, "val_acc": 60.0}
{"epoch": 54, "training_loss": 21.147815322875978, "training_acc": 60.0, "val_loss": 189.54222106933594, "val_acc": 40.0}
{"epoch": 55, "training_loss": 115.00557098388671, "training_acc": 50.0, "val_loss": 76.20808410644531, "val_acc": 60.0}
{"epoch": 56, "training_loss": 57.175272369384764, "training_acc": 60.0, "val_loss": 210.4951934814453, "val_acc": 40.0}
{"epoch": 57, "training_loss": 142.41854925155639, "training_acc": 40.0, "val_loss": 1.6234873533248901, "val_acc": 60.0}
{"epoch": 58, "training_loss": 20.578775119781493, "training_acc": 50.0, "val_loss": 47.419742584228516, "val_acc": 60.0}
{"epoch": 59, "training_loss": 37.42117004394531, "training_acc": 40.0, "val_loss": 180.788818359375, "val_acc": 40.0}
{"epoch": 60, "training_loss": 164.72040405273438, "training_acc": 50.0, "val_loss": 12.439373970031738, "val_acc": 60.0}
{"epoch": 61, "training_loss": 43.555966186523435, "training_acc": 40.0, "val_loss": 24.820579528808594, "val_acc": 60.0}
{"epoch": 62, "training_loss": 53.41673736572265, "training_acc": 30.0, "val_loss": 144.33377075195312, "val_acc": 60.0}
{"epoch": 63, "training_loss": 214.0937957763672, "training_acc": 50.0, "val_loss": 107.44921112060547, "val_acc": 60.0}
{"epoch": 64, "training_loss": 48.30998497009277, "training_acc": 60.0, "val_loss": 30.98663330078125, "val_acc": 40.0}
{"epoch": 65, "training_loss": 65.25999145507812, "training_acc": 50.0, "val_loss": 0.1864607334136963, "val_acc": 80.0}
{"epoch": 66, "training_loss": 87.27345304489135, "training_acc": 55.0, "val_loss": 128.06382751464844, "val_acc": 40.0}
