"main_modify.py --pretrained_path None --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 2 --task ADNI_sex --input_option yAware --learning_rate 5e0 --batch_size 8 --weight_decay 1e-9 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 317.33323380947115, "training_acc": 50.0, "val_loss": 39.16156768798828, "val_acc": 40.0}
{"epoch": 1, "training_loss": 258.60130920410154, "training_acc": 40.0, "val_loss": 36.76322555541992, "val_acc": 60.0}
{"epoch": 2, "training_loss": 192.84297943115234, "training_acc": 60.0, "val_loss": 558.2022705078125, "val_acc": 40.0}
{"epoch": 3, "training_loss": 315.85508728027344, "training_acc": 50.0, "val_loss": 309.767822265625, "val_acc": 60.0}
{"epoch": 4, "training_loss": 473.6516906738281, "training_acc": 50.0, "val_loss": 401.7768249511719, "val_acc": 60.0}
{"epoch": 5, "training_loss": 310.8620948791504, "training_acc": 50.0, "val_loss": 485.27569580078125, "val_acc": 40.0}
{"epoch": 6, "training_loss": 617.1105224609375, "training_acc": 50.0, "val_loss": 880.2418212890625, "val_acc": 40.0}
{"epoch": 7, "training_loss": 616.7984619140625, "training_acc": 50.0, "val_loss": 12.13698673248291, "val_acc": 40.0}
{"epoch": 8, "training_loss": 266.05540199279784, "training_acc": 60.0, "val_loss": 566.4420776367188, "val_acc": 60.0}
{"epoch": 9, "training_loss": 647.5998657226562, "training_acc": 50.0, "val_loss": 200.46885681152344, "val_acc": 60.0}
{"epoch": 10, "training_loss": 299.81056518554686, "training_acc": 40.0, "val_loss": 421.7511291503906, "val_acc": 40.0}
{"epoch": 11, "training_loss": 252.94927978515625, "training_acc": 50.0, "val_loss": 159.7444305419922, "val_acc": 60.0}
{"epoch": 12, "training_loss": 254.5840270996094, "training_acc": 50.0, "val_loss": 276.8539733886719, "val_acc": 60.0}
{"epoch": 13, "training_loss": 214.96866760253906, "training_acc": 50.0, "val_loss": 304.8526611328125, "val_acc": 40.0}
{"epoch": 14, "training_loss": 396.14386596679685, "training_acc": 50.0, "val_loss": 631.9426879882812, "val_acc": 40.0}
{"epoch": 15, "training_loss": 417.7416961669922, "training_acc": 50.0, "val_loss": 106.294677734375, "val_acc": 60.0}
{"epoch": 16, "training_loss": 199.5135925292969, "training_acc": 50.0, "val_loss": 195.5806427001953, "val_acc": 60.0}
{"epoch": 17, "training_loss": 203.91573486328124, "training_acc": 40.0, "val_loss": 266.16510009765625, "val_acc": 40.0}
{"epoch": 18, "training_loss": 176.410693359375, "training_acc": 50.0, "val_loss": 125.89647674560547, "val_acc": 60.0}
{"epoch": 19, "training_loss": 188.05654296875, "training_acc": 50.0, "val_loss": 140.1997528076172, "val_acc": 60.0}
{"epoch": 20, "training_loss": 116.94118041992188, "training_acc": 50.0, "val_loss": 277.7509460449219, "val_acc": 40.0}
{"epoch": 21, "training_loss": 188.0255889892578, "training_acc": 50.0, "val_loss": 96.96776580810547, "val_acc": 60.0}
{"epoch": 22, "training_loss": 133.70105743408203, "training_acc": 50.0, "val_loss": 6.237741470336914, "val_acc": 60.0}
{"epoch": 23, "training_loss": 124.70859031677246, "training_acc": 60.0, "val_loss": 373.2596740722656, "val_acc": 40.0}
{"epoch": 24, "training_loss": 212.2082946777344, "training_acc": 50.0, "val_loss": 168.2122802734375, "val_acc": 60.0}
{"epoch": 25, "training_loss": 343.17271118164064, "training_acc": 50.0, "val_loss": 362.03692626953125, "val_acc": 60.0}
{"epoch": 26, "training_loss": 323.9064880371094, "training_acc": 50.0, "val_loss": 192.2414093017578, "val_acc": 40.0}
{"epoch": 27, "training_loss": 246.19119567871093, "training_acc": 50.0, "val_loss": 440.1007385253906, "val_acc": 40.0}
{"epoch": 28, "training_loss": 310.1027099609375, "training_acc": 50.0, "val_loss": 142.48326110839844, "val_acc": 60.0}
{"epoch": 29, "training_loss": 243.0172119140625, "training_acc": 50.0, "val_loss": 126.1950912475586, "val_acc": 60.0}
{"epoch": 30, "training_loss": 74.51258697509766, "training_acc": 60.0, "val_loss": 162.68032836914062, "val_acc": 40.0}
{"epoch": 31, "training_loss": 78.5191535949707, "training_acc": 60.0, "val_loss": 127.48394012451172, "val_acc": 60.0}
{"epoch": 32, "training_loss": 121.82721824645996, "training_acc": 50.0, "val_loss": 232.8130645751953, "val_acc": 40.0}
{"epoch": 33, "training_loss": 242.18262329101563, "training_acc": 50.0, "val_loss": 167.9200897216797, "val_acc": 40.0}
{"epoch": 34, "training_loss": 114.1803955078125, "training_acc": 50.0, "val_loss": 107.54133605957031, "val_acc": 60.0}
{"epoch": 35, "training_loss": 122.67559509277343, "training_acc": 40.0, "val_loss": 312.8311767578125, "val_acc": 40.0}
{"epoch": 36, "training_loss": 197.20986633300782, "training_acc": 50.0, "val_loss": 137.4750518798828, "val_acc": 60.0}
{"epoch": 37, "training_loss": 261.5291351318359, "training_acc": 50.0, "val_loss": 146.12612915039062, "val_acc": 60.0}
{"epoch": 38, "training_loss": 93.08079071044922, "training_acc": 60.0, "val_loss": 358.5277404785156, "val_acc": 40.0}
{"epoch": 39, "training_loss": 298.58311767578124, "training_acc": 50.0, "val_loss": 91.38903045654297, "val_acc": 40.0}
{"epoch": 40, "training_loss": 205.1693878173828, "training_acc": 50.0, "val_loss": 307.6411437988281, "val_acc": 60.0}
{"epoch": 41, "training_loss": 298.19137115478514, "training_acc": 50.0, "val_loss": 174.04295349121094, "val_acc": 40.0}
