"main_modify.py --pretrained_path None --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 1 --task ADNI_sex --input_option yAware --learning_rate 5e0 --batch_size 8 --weight_decay 1e-9 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 505.2771700620651, "training_acc": 50.0, "val_loss": 366.1044616699219, "val_acc": 60.0}
{"epoch": 1, "training_loss": 664.0777465820313, "training_acc": 50.0, "val_loss": 253.14794921875, "val_acc": 60.0}
{"epoch": 2, "training_loss": 277.60175170898435, "training_acc": 60.0, "val_loss": 572.7042846679688, "val_acc": 40.0}
{"epoch": 3, "training_loss": 287.61435928344724, "training_acc": 50.0, "val_loss": 333.6928405761719, "val_acc": 60.0}
{"epoch": 4, "training_loss": 553.389501953125, "training_acc": 50.0, "val_loss": 514.8614501953125, "val_acc": 60.0}
{"epoch": 5, "training_loss": 493.5342254638672, "training_acc": 50.0, "val_loss": 324.72357177734375, "val_acc": 40.0}
{"epoch": 6, "training_loss": 379.047265625, "training_acc": 50.0, "val_loss": 518.2536010742188, "val_acc": 40.0}
{"epoch": 7, "training_loss": 236.2192578315735, "training_acc": 50.0, "val_loss": 308.91021728515625, "val_acc": 60.0}
{"epoch": 8, "training_loss": 532.9733764648438, "training_acc": 50.0, "val_loss": 561.3219604492188, "val_acc": 60.0}
{"epoch": 9, "training_loss": 551.6151123046875, "training_acc": 50.0, "val_loss": 45.45191192626953, "val_acc": 60.0}
{"epoch": 10, "training_loss": 505.9628204345703, "training_acc": 20.0, "val_loss": 978.6962890625, "val_acc": 40.0}
{"epoch": 11, "training_loss": 804.4764892578125, "training_acc": 50.0, "val_loss": 639.9772338867188, "val_acc": 40.0}
{"epoch": 12, "training_loss": 346.92394256591797, "training_acc": 50.0, "val_loss": 228.92529296875, "val_acc": 60.0}
{"epoch": 13, "training_loss": 438.02330322265624, "training_acc": 50.0, "val_loss": 487.1817321777344, "val_acc": 60.0}
{"epoch": 14, "training_loss": 507.04564208984374, "training_acc": 50.0, "val_loss": 67.29280853271484, "val_acc": 60.0}
{"epoch": 15, "training_loss": 264.8868103027344, "training_acc": 40.0, "val_loss": 741.1935424804688, "val_acc": 40.0}
{"epoch": 16, "training_loss": 601.0521606445312, "training_acc": 50.0, "val_loss": 457.47125244140625, "val_acc": 40.0}
{"epoch": 17, "training_loss": 289.11531219482424, "training_acc": 50.0, "val_loss": 314.0530700683594, "val_acc": 60.0}
{"epoch": 18, "training_loss": 410.83509521484376, "training_acc": 50.0, "val_loss": 222.63194274902344, "val_acc": 60.0}
{"epoch": 19, "training_loss": 278.2031967163086, "training_acc": 30.0, "val_loss": 528.3036499023438, "val_acc": 40.0}
{"epoch": 20, "training_loss": 432.0222595214844, "training_acc": 50.0, "val_loss": 251.3205108642578, "val_acc": 40.0}
{"epoch": 21, "training_loss": 103.31289215087891, "training_acc": 50.0, "val_loss": 145.68179321289062, "val_acc": 60.0}
{"epoch": 22, "training_loss": 144.82708435058595, "training_acc": 40.0, "val_loss": 1.8278887271881104, "val_acc": 40.0}
{"epoch": 23, "training_loss": 21.491883087158204, "training_acc": 50.0, "val_loss": 97.66426849365234, "val_acc": 60.0}
{"epoch": 24, "training_loss": 125.11049194335938, "training_acc": 50.0, "val_loss": 80.75946807861328, "val_acc": 40.0}
{"epoch": 25, "training_loss": 84.2808708190918, "training_acc": 50.0, "val_loss": 65.18183898925781, "val_acc": 60.0}
{"epoch": 26, "training_loss": 77.93329315185547, "training_acc": 40.0, "val_loss": 7.806432247161865, "val_acc": 60.0}
{"epoch": 27, "training_loss": 12.571352767944337, "training_acc": 60.0, "val_loss": 35.06906509399414, "val_acc": 40.0}
{"epoch": 28, "training_loss": 22.905258178710938, "training_acc": 50.0, "val_loss": 7.857885837554932, "val_acc": 60.0}
{"epoch": 29, "training_loss": 41.39313507080078, "training_acc": 40.0, "val_loss": 99.00363159179688, "val_acc": 60.0}
{"epoch": 30, "training_loss": 110.01005210876465, "training_acc": 50.0, "val_loss": 69.28755950927734, "val_acc": 40.0}
{"epoch": 31, "training_loss": 49.75193405151367, "training_acc": 50.0, "val_loss": 40.572689056396484, "val_acc": 60.0}
{"epoch": 32, "training_loss": 76.95188598632812, "training_acc": 40.0, "val_loss": 19.69810676574707, "val_acc": 60.0}
{"epoch": 33, "training_loss": 51.07646179199219, "training_acc": 50.0, "val_loss": 48.18025207519531, "val_acc": 40.0}
{"epoch": 34, "training_loss": 23.989833864569665, "training_acc": 60.0, "val_loss": 2.84451961517334, "val_acc": 40.0}
{"epoch": 35, "training_loss": 8.823309755325317, "training_acc": 75.0, "val_loss": 58.63671875, "val_acc": 40.0}
{"epoch": 36, "training_loss": 28.777134513854982, "training_acc": 60.0, "val_loss": 152.6820831298828, "val_acc": 60.0}
{"epoch": 37, "training_loss": 143.00249671936035, "training_acc": 50.0, "val_loss": 220.8358612060547, "val_acc": 40.0}
{"epoch": 38, "training_loss": 217.3732177734375, "training_acc": 50.0, "val_loss": 169.6440887451172, "val_acc": 40.0}
{"epoch": 39, "training_loss": 104.90758590698242, "training_acc": 40.0, "val_loss": 15.003059387207031, "val_acc": 40.0}
{"epoch": 40, "training_loss": 31.485942840576172, "training_acc": 50.0, "val_loss": 67.62993621826172, "val_acc": 60.0}
{"epoch": 41, "training_loss": 37.21950442283414, "training_acc": 60.0, "val_loss": 7.104928016662598, "val_acc": 60.0}
