"main_modify.py --pretrained_path None --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 3 --task ADNI_sex --input_option yAware --learning_rate 5e0 --batch_size 8 --weight_decay 1e-9 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 467.7632637500763, "training_acc": 55.0, "val_loss": 311.8653869628906, "val_acc": 60.0}
{"epoch": 1, "training_loss": 341.9538631439209, "training_acc": 45.0, "val_loss": 571.4332275390625, "val_acc": 40.0}
{"epoch": 2, "training_loss": 509.9671264648438, "training_acc": 55.0, "val_loss": 529.5485229492188, "val_acc": 40.0}
{"epoch": 3, "training_loss": 189.0157928466797, "training_acc": 65.0, "val_loss": 319.3044128417969, "val_acc": 60.0}
{"epoch": 4, "training_loss": 433.2434936523438, "training_acc": 45.0, "val_loss": 20.445249557495117, "val_acc": 40.0}
{"epoch": 5, "training_loss": 109.4339038848877, "training_acc": 55.0, "val_loss": 0.7421757578849792, "val_acc": 60.0}
{"epoch": 6, "training_loss": 120.23611520528793, "training_acc": 55.0, "val_loss": 83.2110824584961, "val_acc": 40.0}
{"epoch": 7, "training_loss": 62.21568412780762, "training_acc": 55.0, "val_loss": 160.5304718017578, "val_acc": 60.0}
{"epoch": 8, "training_loss": 229.00542907714845, "training_acc": 45.0, "val_loss": 62.8127555847168, "val_acc": 40.0}
{"epoch": 9, "training_loss": 49.597268676757814, "training_acc": 55.0, "val_loss": 117.3512191772461, "val_acc": 60.0}
{"epoch": 10, "training_loss": 165.59979248046875, "training_acc": 45.0, "val_loss": 169.65000915527344, "val_acc": 40.0}
{"epoch": 11, "training_loss": 131.75426635742187, "training_acc": 55.0, "val_loss": 44.971046447753906, "val_acc": 40.0}
{"epoch": 12, "training_loss": 73.92641906738281, "training_acc": 55.0, "val_loss": 7.06648588180542, "val_acc": 60.0}
{"epoch": 13, "training_loss": 76.87710437774658, "training_acc": 65.0, "val_loss": 305.9698486328125, "val_acc": 40.0}
{"epoch": 14, "training_loss": 142.27053527832032, "training_acc": 55.0, "val_loss": 205.04751586914062, "val_acc": 60.0}
{"epoch": 15, "training_loss": 349.27882080078126, "training_acc": 45.0, "val_loss": 283.82427978515625, "val_acc": 60.0}
{"epoch": 16, "training_loss": 299.7329833984375, "training_acc": 35.0, "val_loss": 173.3871307373047, "val_acc": 40.0}
{"epoch": 17, "training_loss": 89.0999563217163, "training_acc": 55.0, "val_loss": 16.1652774810791, "val_acc": 60.0}
{"epoch": 18, "training_loss": 74.27739105224609, "training_acc": 45.0, "val_loss": 11.466144561767578, "val_acc": 60.0}
{"epoch": 19, "training_loss": 38.70050811767578, "training_acc": 45.0, "val_loss": 101.26305389404297, "val_acc": 40.0}
{"epoch": 20, "training_loss": 35.068233251571655, "training_acc": 65.0, "val_loss": 108.71700286865234, "val_acc": 60.0}
{"epoch": 21, "training_loss": 94.7181282043457, "training_acc": 55.0, "val_loss": 225.4254913330078, "val_acc": 40.0}
{"epoch": 22, "training_loss": 181.7663673400879, "training_acc": 55.0, "val_loss": 50.70955276489258, "val_acc": 60.0}
{"epoch": 23, "training_loss": 61.23069343566895, "training_acc": 45.0, "val_loss": 14.213824272155762, "val_acc": 40.0}
{"epoch": 24, "training_loss": 116.96586723327637, "training_acc": 35.0, "val_loss": 0.7292988896369934, "val_acc": 60.0}
{"epoch": 25, "training_loss": 98.84667716026306, "training_acc": 60.0, "val_loss": 306.7707214355469, "val_acc": 40.0}
{"epoch": 26, "training_loss": 145.53474884033204, "training_acc": 55.0, "val_loss": 192.68423461914062, "val_acc": 60.0}
{"epoch": 27, "training_loss": 345.1687347412109, "training_acc": 45.0, "val_loss": 235.4643096923828, "val_acc": 60.0}
{"epoch": 28, "training_loss": 224.55196838378907, "training_acc": 45.0, "val_loss": 381.5773010253906, "val_acc": 40.0}
{"epoch": 29, "training_loss": 293.708203125, "training_acc": 55.0, "val_loss": 157.00967407226562, "val_acc": 40.0}
{"epoch": 30, "training_loss": 71.35077819824218, "training_acc": 55.0, "val_loss": 15.467658042907715, "val_acc": 60.0}
{"epoch": 31, "training_loss": 82.29398345947266, "training_acc": 55.0, "val_loss": 203.4803009033203, "val_acc": 40.0}
{"epoch": 32, "training_loss": 127.87481079101562, "training_acc": 45.0, "val_loss": 124.6888427734375, "val_acc": 60.0}
{"epoch": 33, "training_loss": 109.43652954101563, "training_acc": 55.0, "val_loss": 196.16607666015625, "val_acc": 40.0}
{"epoch": 34, "training_loss": 115.873583984375, "training_acc": 55.0, "val_loss": 105.5151596069336, "val_acc": 60.0}
{"epoch": 35, "training_loss": 156.754248046875, "training_acc": 45.0, "val_loss": 27.431884765625, "val_acc": 40.0}
{"epoch": 36, "training_loss": 34.92440414428711, "training_acc": 45.0, "val_loss": 63.63788604736328, "val_acc": 40.0}
{"epoch": 37, "training_loss": 81.40582275390625, "training_acc": 35.0, "val_loss": 50.3810920715332, "val_acc": 60.0}
{"epoch": 38, "training_loss": 154.58323364257814, "training_acc": 35.0, "val_loss": 204.7496337890625, "val_acc": 40.0}
{"epoch": 39, "training_loss": 124.62673950195312, "training_acc": 45.0, "val_loss": 170.8345947265625, "val_acc": 60.0}
{"epoch": 40, "training_loss": 168.75345726013182, "training_acc": 45.0, "val_loss": 97.02483367919922, "val_acc": 40.0}
{"epoch": 41, "training_loss": 54.71531982421875, "training_acc": 55.0, "val_loss": 73.62699890136719, "val_acc": 60.0}
{"epoch": 42, "training_loss": 75.65014934539795, "training_acc": 50.0, "val_loss": 289.2587585449219, "val_acc": 40.0}
{"epoch": 43, "training_loss": 174.47680053710937, "training_acc": 55.0, "val_loss": 88.6063232421875, "val_acc": 60.0}
