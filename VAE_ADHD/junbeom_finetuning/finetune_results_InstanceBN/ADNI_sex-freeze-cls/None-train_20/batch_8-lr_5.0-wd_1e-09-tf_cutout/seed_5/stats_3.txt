"main_modify.py --pretrained_path None --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 5 --task ADNI_sex --input_option yAware --learning_rate 5e0 --batch_size 8 --weight_decay 1e-9 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 913.2231944084167, "training_acc": 20.0, "val_loss": 432.8173522949219, "val_acc": 40.0}
{"epoch": 1, "training_loss": 397.4741577148437, "training_acc": 50.0, "val_loss": 593.635009765625, "val_acc": 60.0}
{"epoch": 2, "training_loss": 635.5360717773438, "training_acc": 50.0, "val_loss": 32.941463470458984, "val_acc": 60.0}
{"epoch": 3, "training_loss": 207.28094100952148, "training_acc": 60.0, "val_loss": 801.6029663085938, "val_acc": 40.0}
{"epoch": 4, "training_loss": 632.845834350586, "training_acc": 50.0, "val_loss": 285.6683654785156, "val_acc": 40.0}
{"epoch": 5, "training_loss": 155.47405548095702, "training_acc": 50.0, "val_loss": 213.80674743652344, "val_acc": 60.0}
{"epoch": 6, "training_loss": 217.200528717041, "training_acc": 40.0, "val_loss": 52.69483184814453, "val_acc": 40.0}
{"epoch": 7, "training_loss": 58.12972869873047, "training_acc": 50.0, "val_loss": 83.7144546508789, "val_acc": 40.0}
{"epoch": 8, "training_loss": 89.15869903564453, "training_acc": 50.0, "val_loss": 111.17781066894531, "val_acc": 60.0}
{"epoch": 9, "training_loss": 140.82066040039064, "training_acc": 50.0, "val_loss": 47.18031692504883, "val_acc": 40.0}
{"epoch": 10, "training_loss": 37.92065582275391, "training_acc": 40.0, "val_loss": 56.684688568115234, "val_acc": 40.0}
{"epoch": 11, "training_loss": 102.69584350585937, "training_acc": 40.0, "val_loss": 12.772087097167969, "val_acc": 60.0}
{"epoch": 12, "training_loss": 124.85382308959962, "training_acc": 50.0, "val_loss": 304.24359130859375, "val_acc": 40.0}
{"epoch": 13, "training_loss": 168.56445438861846, "training_acc": 55.0, "val_loss": 117.24195861816406, "val_acc": 60.0}
{"epoch": 14, "training_loss": 177.77080993652345, "training_acc": 50.0, "val_loss": 38.70786666870117, "val_acc": 40.0}
{"epoch": 15, "training_loss": 86.20305023193359, "training_acc": 50.0, "val_loss": 13.73009967803955, "val_acc": 40.0}
{"epoch": 16, "training_loss": 110.75971031188965, "training_acc": 50.0, "val_loss": 134.2668914794922, "val_acc": 60.0}
{"epoch": 17, "training_loss": 146.81075134277344, "training_acc": 40.0, "val_loss": 359.3885192871094, "val_acc": 40.0}
{"epoch": 18, "training_loss": 284.144189453125, "training_acc": 50.0, "val_loss": 16.84502410888672, "val_acc": 60.0}
{"epoch": 19, "training_loss": 92.45634155273437, "training_acc": 50.0, "val_loss": 45.95457077026367, "val_acc": 60.0}
{"epoch": 20, "training_loss": 153.78170776367188, "training_acc": 40.0, "val_loss": 191.1483917236328, "val_acc": 40.0}
{"epoch": 21, "training_loss": 82.99175381660461, "training_acc": 60.0, "val_loss": 262.9562072753906, "val_acc": 60.0}
{"epoch": 22, "training_loss": 366.7582275390625, "training_acc": 50.0, "val_loss": 111.6324462890625, "val_acc": 60.0}
{"epoch": 23, "training_loss": 191.34507446289064, "training_acc": 40.0, "val_loss": 340.75787353515625, "val_acc": 40.0}
{"epoch": 24, "training_loss": 244.25554810762407, "training_acc": 50.0, "val_loss": 154.06253051757812, "val_acc": 60.0}
{"epoch": 25, "training_loss": 216.1086669921875, "training_acc": 50.0, "val_loss": 89.9387435913086, "val_acc": 60.0}
{"epoch": 26, "training_loss": 83.43998870849609, "training_acc": 60.0, "val_loss": 161.00894165039062, "val_acc": 40.0}
{"epoch": 27, "training_loss": 146.76834869384766, "training_acc": 20.0, "val_loss": 57.5312385559082, "val_acc": 40.0}
{"epoch": 28, "training_loss": 47.402296447753905, "training_acc": 50.0, "val_loss": 3.458559036254883, "val_acc": 40.0}
{"epoch": 29, "training_loss": 45.87768783569336, "training_acc": 50.0, "val_loss": 115.2531509399414, "val_acc": 40.0}
{"epoch": 30, "training_loss": 128.0453323364258, "training_acc": 50.0, "val_loss": 3.1037168502807617, "val_acc": 60.0}
{"epoch": 31, "training_loss": 1.6046820163726807, "training_acc": 65.0, "val_loss": 27.256656646728516, "val_acc": 60.0}
{"epoch": 32, "training_loss": 46.83424682617188, "training_acc": 40.0, "val_loss": 101.99476623535156, "val_acc": 60.0}
{"epoch": 33, "training_loss": 166.75863342285157, "training_acc": 50.0, "val_loss": 0.9946454167366028, "val_acc": 60.0}
{"epoch": 34, "training_loss": 55.784675455093385, "training_acc": 60.0, "val_loss": 15.848825454711914, "val_acc": 60.0}
{"epoch": 35, "training_loss": 29.734745025634766, "training_acc": 50.0, "val_loss": 84.53544616699219, "val_acc": 40.0}
{"epoch": 36, "training_loss": 46.184991455078126, "training_acc": 50.0, "val_loss": 81.3576889038086, "val_acc": 40.0}
{"epoch": 37, "training_loss": 57.89056549072266, "training_acc": 50.0, "val_loss": 32.16852951049805, "val_acc": 60.0}
{"epoch": 38, "training_loss": 82.03236694335938, "training_acc": 40.0, "val_loss": 25.46321678161621, "val_acc": 60.0}
{"epoch": 39, "training_loss": 47.054389572143556, "training_acc": 50.0, "val_loss": 17.529190063476562, "val_acc": 60.0}
{"epoch": 40, "training_loss": 56.880531311035156, "training_acc": 40.0, "val_loss": 64.07878875732422, "val_acc": 60.0}
{"epoch": 41, "training_loss": 60.72790842056274, "training_acc": 50.0, "val_loss": 12.431568145751953, "val_acc": 60.0}
{"epoch": 42, "training_loss": 39.06963844299317, "training_acc": 50.0, "val_loss": 78.12348937988281, "val_acc": 60.0}
{"epoch": 43, "training_loss": 108.94410362243653, "training_acc": 50.0, "val_loss": 93.61956787109375, "val_acc": 40.0}
{"epoch": 44, "training_loss": 80.46146850585937, "training_acc": 40.0, "val_loss": 45.813751220703125, "val_acc": 40.0}
{"epoch": 45, "training_loss": 32.766127014160155, "training_acc": 60.0, "val_loss": 123.16407775878906, "val_acc": 60.0}
{"epoch": 46, "training_loss": 146.54741973876952, "training_acc": 50.0, "val_loss": 217.87242126464844, "val_acc": 40.0}
{"epoch": 47, "training_loss": 349.35101928710935, "training_acc": 50.0, "val_loss": 340.7762756347656, "val_acc": 40.0}
{"epoch": 48, "training_loss": 239.83040618896484, "training_acc": 40.0, "val_loss": 338.31719970703125, "val_acc": 60.0}
{"epoch": 49, "training_loss": 424.61700439453125, "training_acc": 50.0, "val_loss": 175.59234619140625, "val_acc": 60.0}
{"epoch": 50, "training_loss": 203.19329833984375, "training_acc": 40.0, "val_loss": 280.3538818359375, "val_acc": 40.0}
{"epoch": 51, "training_loss": 156.55971450805663, "training_acc": 50.0, "val_loss": 89.04869842529297, "val_acc": 60.0}
{"epoch": 52, "training_loss": 84.16363677978515, "training_acc": 50.0, "val_loss": 109.7154312133789, "val_acc": 40.0}
