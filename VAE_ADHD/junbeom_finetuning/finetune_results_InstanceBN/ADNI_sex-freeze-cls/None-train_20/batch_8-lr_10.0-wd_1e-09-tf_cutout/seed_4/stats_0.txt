"main_modify.py --pretrained_path None --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 4 --task ADNI_sex --input_option yAware --learning_rate 1e1 --batch_size 8 --weight_decay 1e-9 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 1495.8726777791976, "training_acc": 50.0, "val_loss": 509.4655456542969, "val_acc": 40.0}
{"epoch": 1, "training_loss": 847.6585205078125, "training_acc": 50.0, "val_loss": 425.9154968261719, "val_acc": 40.0}
{"epoch": 2, "training_loss": 287.61863403320314, "training_acc": 60.0, "val_loss": 393.014892578125, "val_acc": 60.0}
{"epoch": 3, "training_loss": 311.07225799560547, "training_acc": 30.0, "val_loss": 261.2825622558594, "val_acc": 60.0}
{"epoch": 4, "training_loss": 332.4153564453125, "training_acc": 50.0, "val_loss": 266.42315673828125, "val_acc": 40.0}
{"epoch": 5, "training_loss": 325.7833679199219, "training_acc": 50.0, "val_loss": 191.7100830078125, "val_acc": 40.0}
{"epoch": 6, "training_loss": 133.4635467529297, "training_acc": 70.0, "val_loss": 338.43939208984375, "val_acc": 60.0}
{"epoch": 7, "training_loss": 344.38463134765624, "training_acc": 40.0, "val_loss": 249.91796875, "val_acc": 40.0}
{"epoch": 8, "training_loss": 125.24600677490234, "training_acc": 60.0, "val_loss": 277.6769714355469, "val_acc": 60.0}
{"epoch": 9, "training_loss": 305.2321645736694, "training_acc": 50.0, "val_loss": 455.6659851074219, "val_acc": 40.0}
{"epoch": 10, "training_loss": 451.9338317871094, "training_acc": 50.0, "val_loss": 210.1922149658203, "val_acc": 40.0}
{"epoch": 11, "training_loss": 312.53676147460936, "training_acc": 50.0, "val_loss": 363.08612060546875, "val_acc": 60.0}
{"epoch": 12, "training_loss": 293.96697998046875, "training_acc": 50.0, "val_loss": 529.0386352539062, "val_acc": 40.0}
{"epoch": 13, "training_loss": 412.184521484375, "training_acc": 50.0, "val_loss": 125.28337860107422, "val_acc": 60.0}
{"epoch": 14, "training_loss": 277.30857543945314, "training_acc": 50.0, "val_loss": 110.48294830322266, "val_acc": 60.0}
{"epoch": 15, "training_loss": 177.0711181640625, "training_acc": 60.0, "val_loss": 371.9126281738281, "val_acc": 40.0}
{"epoch": 16, "training_loss": 211.26292724609374, "training_acc": 50.0, "val_loss": 393.6219177246094, "val_acc": 60.0}
{"epoch": 17, "training_loss": 495.33611450195315, "training_acc": 50.0, "val_loss": 107.5909423828125, "val_acc": 40.0}
{"epoch": 18, "training_loss": 248.8202331542969, "training_acc": 50.0, "val_loss": 287.9312438964844, "val_acc": 40.0}
{"epoch": 19, "training_loss": 112.7759051322937, "training_acc": 60.0, "val_loss": 67.20271301269531, "val_acc": 40.0}
{"epoch": 20, "training_loss": 45.98571701049805, "training_acc": 50.0, "val_loss": 146.2615966796875, "val_acc": 40.0}
{"epoch": 21, "training_loss": 79.48310775756836, "training_acc": 50.0, "val_loss": 240.05064392089844, "val_acc": 40.0}
{"epoch": 22, "training_loss": 198.3760971069336, "training_acc": 50.0, "val_loss": 264.5939636230469, "val_acc": 60.0}
{"epoch": 23, "training_loss": 397.4050048828125, "training_acc": 50.0, "val_loss": 103.7955322265625, "val_acc": 60.0}
{"epoch": 24, "training_loss": 187.52940063476564, "training_acc": 60.0, "val_loss": 550.13232421875, "val_acc": 40.0}
{"epoch": 25, "training_loss": 250.96661682128905, "training_acc": 70.0, "val_loss": 201.0318145751953, "val_acc": 60.0}
{"epoch": 26, "training_loss": 262.0705993652344, "training_acc": 30.0, "val_loss": 24.399059295654297, "val_acc": 60.0}
{"epoch": 27, "training_loss": 45.058154296875, "training_acc": 50.0, "val_loss": 7.502410888671875, "val_acc": 40.0}
{"epoch": 28, "training_loss": 50.23293228149414, "training_acc": 50.0, "val_loss": 317.2644348144531, "val_acc": 40.0}
{"epoch": 29, "training_loss": 244.3320083618164, "training_acc": 50.0, "val_loss": 172.0827178955078, "val_acc": 60.0}
{"epoch": 30, "training_loss": 245.05823974609376, "training_acc": 50.0, "val_loss": 247.12942504882812, "val_acc": 40.0}
{"epoch": 31, "training_loss": 249.34195556640626, "training_acc": 50.0, "val_loss": 22.79379653930664, "val_acc": 40.0}
{"epoch": 32, "training_loss": 185.59902381896973, "training_acc": 60.0, "val_loss": 304.1256103515625, "val_acc": 60.0}
{"epoch": 33, "training_loss": 196.99866943359376, "training_acc": 60.0, "val_loss": 618.9716186523438, "val_acc": 40.0}
{"epoch": 34, "training_loss": 496.3715393066406, "training_acc": 50.0, "val_loss": 2.8354527950286865, "val_acc": 40.0}
{"epoch": 35, "training_loss": 208.51818523406982, "training_acc": 65.0, "val_loss": 365.41583251953125, "val_acc": 60.0}
{"epoch": 36, "training_loss": 303.98431396484375, "training_acc": 50.0, "val_loss": 541.5682983398438, "val_acc": 40.0}
{"epoch": 37, "training_loss": 429.9383056640625, "training_acc": 50.0, "val_loss": 189.08995056152344, "val_acc": 60.0}
{"epoch": 38, "training_loss": 254.60220947265626, "training_acc": 50.0, "val_loss": 226.8162384033203, "val_acc": 40.0}
{"epoch": 39, "training_loss": 298.46966247558595, "training_acc": 50.0, "val_loss": 160.79502868652344, "val_acc": 40.0}
{"epoch": 40, "training_loss": 133.71301727294923, "training_acc": 60.0, "val_loss": 175.31065368652344, "val_acc": 60.0}
{"epoch": 41, "training_loss": 164.42836990356446, "training_acc": 20.0, "val_loss": 355.64434814453125, "val_acc": 40.0}
{"epoch": 42, "training_loss": 368.9368377685547, "training_acc": 50.0, "val_loss": 19.1345272064209, "val_acc": 60.0}
{"epoch": 43, "training_loss": 31.172525119781493, "training_acc": 55.0, "val_loss": 19.486804962158203, "val_acc": 40.0}
{"epoch": 44, "training_loss": 178.95136947631835, "training_acc": 50.0, "val_loss": 145.2429656982422, "val_acc": 60.0}
{"epoch": 45, "training_loss": 81.36637496948242, "training_acc": 70.0, "val_loss": 87.84221649169922, "val_acc": 40.0}
{"epoch": 46, "training_loss": 117.8572280883789, "training_acc": 60.0, "val_loss": 79.09701538085938, "val_acc": 60.0}
{"epoch": 47, "training_loss": 125.20415496826172, "training_acc": 60.0, "val_loss": 219.82945251464844, "val_acc": 40.0}
{"epoch": 48, "training_loss": 197.34453125, "training_acc": 40.0, "val_loss": 52.5612678527832, "val_acc": 40.0}
{"epoch": 49, "training_loss": 83.92618865966797, "training_acc": 30.0, "val_loss": 218.7926483154297, "val_acc": 40.0}
{"epoch": 50, "training_loss": 90.63290481567383, "training_acc": 50.0, "val_loss": 270.847900390625, "val_acc": 40.0}
{"epoch": 51, "training_loss": 228.8549377441406, "training_acc": 30.0, "val_loss": 113.3365478515625, "val_acc": 40.0}
{"epoch": 52, "training_loss": 94.43006896972656, "training_acc": 50.0, "val_loss": 163.33433532714844, "val_acc": 60.0}
{"epoch": 53, "training_loss": 116.50831551551819, "training_acc": 45.0, "val_loss": 107.5584716796875, "val_acc": 60.0}
