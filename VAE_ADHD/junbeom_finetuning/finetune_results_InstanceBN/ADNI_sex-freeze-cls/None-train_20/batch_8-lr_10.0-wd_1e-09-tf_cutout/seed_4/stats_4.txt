"main_modify.py --pretrained_path None --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 4 --task ADNI_sex --input_option yAware --learning_rate 1e1 --batch_size 8 --weight_decay 1e-9 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 1399.6160591602325, "training_acc": 45.0, "val_loss": 1413.688232421875, "val_acc": 40.0}
{"epoch": 1, "training_loss": 1250.6378662109375, "training_acc": 55.0, "val_loss": 1703.924072265625, "val_acc": 40.0}
{"epoch": 2, "training_loss": 868.1647338867188, "training_acc": 55.0, "val_loss": 284.0559997558594, "val_acc": 60.0}
{"epoch": 3, "training_loss": 314.77589111328126, "training_acc": 45.0, "val_loss": 353.25048828125, "val_acc": 40.0}
{"epoch": 4, "training_loss": 262.8361785888672, "training_acc": 45.0, "val_loss": 279.439208984375, "val_acc": 60.0}
{"epoch": 5, "training_loss": 272.30633850097655, "training_acc": 45.0, "val_loss": 807.7854614257812, "val_acc": 40.0}
{"epoch": 6, "training_loss": 579.9289611816406, "training_acc": 55.0, "val_loss": 81.45597076416016, "val_acc": 40.0}
{"epoch": 7, "training_loss": 249.69859161376954, "training_acc": 65.0, "val_loss": 573.5712890625, "val_acc": 60.0}
{"epoch": 8, "training_loss": 568.8039470672608, "training_acc": 45.0, "val_loss": 679.6456909179688, "val_acc": 40.0}
{"epoch": 9, "training_loss": 616.7823486328125, "training_acc": 55.0, "val_loss": 987.3715209960938, "val_acc": 40.0}
{"epoch": 10, "training_loss": 514.7143676757812, "training_acc": 55.0, "val_loss": 292.2921142578125, "val_acc": 60.0}
{"epoch": 11, "training_loss": 530.7475341796875, "training_acc": 45.0, "val_loss": 433.0057678222656, "val_acc": 60.0}
{"epoch": 12, "training_loss": 395.5507507324219, "training_acc": 45.0, "val_loss": 671.7608642578125, "val_acc": 40.0}
{"epoch": 13, "training_loss": 493.754345703125, "training_acc": 55.0, "val_loss": 103.12773895263672, "val_acc": 40.0}
{"epoch": 14, "training_loss": 145.7958953857422, "training_acc": 65.0, "val_loss": 165.61782836914062, "val_acc": 60.0}
{"epoch": 15, "training_loss": 254.7681854248047, "training_acc": 45.0, "val_loss": 212.05056762695312, "val_acc": 40.0}
{"epoch": 16, "training_loss": 131.3259262084961, "training_acc": 55.0, "val_loss": 32.7557258605957, "val_acc": 60.0}
{"epoch": 17, "training_loss": 254.54027862548827, "training_acc": 45.0, "val_loss": 354.2046813964844, "val_acc": 40.0}
{"epoch": 18, "training_loss": 102.15672721862794, "training_acc": 55.0, "val_loss": 55.136165618896484, "val_acc": 40.0}
{"epoch": 19, "training_loss": 72.64940338134765, "training_acc": 45.0, "val_loss": 16.979764938354492, "val_acc": 60.0}
{"epoch": 20, "training_loss": 189.52306518554687, "training_acc": 35.0, "val_loss": 60.33138656616211, "val_acc": 60.0}
{"epoch": 21, "training_loss": 184.29236450195313, "training_acc": 45.0, "val_loss": 312.1423034667969, "val_acc": 40.0}
{"epoch": 22, "training_loss": 274.808349609375, "training_acc": 55.0, "val_loss": 178.0403289794922, "val_acc": 40.0}
{"epoch": 23, "training_loss": 233.32896118164064, "training_acc": 45.0, "val_loss": 184.68260192871094, "val_acc": 60.0}
{"epoch": 24, "training_loss": 162.16362991333008, "training_acc": 45.0, "val_loss": 16.90569496154785, "val_acc": 40.0}
{"epoch": 25, "training_loss": 129.37616996765138, "training_acc": 55.0, "val_loss": 4.121664524078369, "val_acc": 60.0}
{"epoch": 26, "training_loss": 374.26537284851076, "training_acc": 35.0, "val_loss": 749.5113525390625, "val_acc": 40.0}
{"epoch": 27, "training_loss": 376.5036651611328, "training_acc": 55.0, "val_loss": 373.9918212890625, "val_acc": 60.0}
{"epoch": 28, "training_loss": 709.8021728515625, "training_acc": 45.0, "val_loss": 432.1402893066406, "val_acc": 60.0}
{"epoch": 29, "training_loss": 297.9200958251953, "training_acc": 55.0, "val_loss": 906.7388916015625, "val_acc": 40.0}
{"epoch": 30, "training_loss": 723.4966064453125, "training_acc": 55.0, "val_loss": 788.0562744140625, "val_acc": 40.0}
{"epoch": 31, "training_loss": 364.3738429069519, "training_acc": 55.0, "val_loss": 149.41233825683594, "val_acc": 60.0}
{"epoch": 32, "training_loss": 175.71612854003905, "training_acc": 45.0, "val_loss": 251.6252899169922, "val_acc": 40.0}
{"epoch": 33, "training_loss": 143.07821655273438, "training_acc": 55.0, "val_loss": 193.62271118164062, "val_acc": 60.0}
{"epoch": 34, "training_loss": 161.33028717041014, "training_acc": 55.0, "val_loss": 598.0804443359375, "val_acc": 40.0}
{"epoch": 35, "training_loss": 418.9368896484375, "training_acc": 55.0, "val_loss": 79.30834197998047, "val_acc": 60.0}
{"epoch": 36, "training_loss": 115.8090431213379, "training_acc": 55.0, "val_loss": 120.9933090209961, "val_acc": 40.0}
{"epoch": 37, "training_loss": 89.53127021789551, "training_acc": 55.0, "val_loss": 260.5748291015625, "val_acc": 60.0}
{"epoch": 38, "training_loss": 319.4724609375, "training_acc": 35.0, "val_loss": 519.0443725585938, "val_acc": 40.0}
{"epoch": 39, "training_loss": 294.5192565917969, "training_acc": 55.0, "val_loss": 283.32275390625, "val_acc": 60.0}
{"epoch": 40, "training_loss": 430.2298645019531, "training_acc": 45.0, "val_loss": 82.20936584472656, "val_acc": 60.0}
{"epoch": 41, "training_loss": 238.1193603515625, "training_acc": 55.0, "val_loss": 910.6588745117188, "val_acc": 40.0}
{"epoch": 42, "training_loss": 618.9850952148438, "training_acc": 55.0, "val_loss": 143.3607940673828, "val_acc": 40.0}
{"epoch": 43, "training_loss": 582.1302490234375, "training_acc": 35.0, "val_loss": 572.8391723632812, "val_acc": 60.0}
{"epoch": 44, "training_loss": 705.2424194335938, "training_acc": 25.0, "val_loss": 530.7761840820312, "val_acc": 40.0}
