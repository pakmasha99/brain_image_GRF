"main_modify.py --pretrained_path None --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 2 --task ADNI_sex --input_option yAware --learning_rate 1e1 --batch_size 16 --weight_decay 5e-4 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 215.1863790512085, "training_acc": 55.0, "val_loss": 741.8908081054688, "val_acc": 40.0}
{"epoch": 1, "training_loss": 1004.8099609375, "training_acc": 35.0, "val_loss": 650.8775634765625, "val_acc": 60.0}
{"epoch": 2, "training_loss": 746.0784301757812, "training_acc": 45.0, "val_loss": 1108.814697265625, "val_acc": 40.0}
{"epoch": 3, "training_loss": 932.0924072265625, "training_acc": 55.0, "val_loss": 1797.5289306640625, "val_acc": 40.0}
{"epoch": 4, "training_loss": 1321.5852783203125, "training_acc": 55.0, "val_loss": 1003.8764038085938, "val_acc": 40.0}
{"epoch": 5, "training_loss": 688.5332138061524, "training_acc": 55.0, "val_loss": 419.15655517578125, "val_acc": 60.0}
{"epoch": 6, "training_loss": 635.364501953125, "training_acc": 45.0, "val_loss": 644.99072265625, "val_acc": 60.0}
{"epoch": 7, "training_loss": 852.1803771972657, "training_acc": 45.0, "val_loss": 21.213842391967773, "val_acc": 60.0}
{"epoch": 8, "training_loss": 226.08923950195313, "training_acc": 35.0, "val_loss": 1080.463134765625, "val_acc": 40.0}
{"epoch": 9, "training_loss": 809.794091796875, "training_acc": 55.0, "val_loss": 943.4198608398438, "val_acc": 40.0}
{"epoch": 10, "training_loss": 678.6808227539062, "training_acc": 55.0, "val_loss": 152.51014709472656, "val_acc": 40.0}
{"epoch": 11, "training_loss": 171.24403686523436, "training_acc": 55.0, "val_loss": 530.5020751953125, "val_acc": 60.0}
{"epoch": 12, "training_loss": 721.17529296875, "training_acc": 45.0, "val_loss": 294.4733581542969, "val_acc": 60.0}
{"epoch": 13, "training_loss": 257.266064453125, "training_acc": 65.0, "val_loss": 546.8837890625, "val_acc": 40.0}
{"epoch": 14, "training_loss": 440.00836181640625, "training_acc": 55.0, "val_loss": 619.5440673828125, "val_acc": 40.0}
{"epoch": 15, "training_loss": 432.92469177246096, "training_acc": 55.0, "val_loss": 149.45095825195312, "val_acc": 60.0}
{"epoch": 16, "training_loss": 211.55228576660156, "training_acc": 45.0, "val_loss": 164.4932861328125, "val_acc": 60.0}
{"epoch": 17, "training_loss": 170.25529708862305, "training_acc": 55.0, "val_loss": 237.83775329589844, "val_acc": 40.0}
{"epoch": 18, "training_loss": 161.63143920898438, "training_acc": 55.0, "val_loss": 144.8754425048828, "val_acc": 60.0}
{"epoch": 19, "training_loss": 211.1017578125, "training_acc": 45.0, "val_loss": 87.8176040649414, "val_acc": 40.0}
{"epoch": 20, "training_loss": 69.55626983642578, "training_acc": 55.0, "val_loss": 55.2545280456543, "val_acc": 40.0}
{"epoch": 21, "training_loss": 108.55021362304687, "training_acc": 45.0, "val_loss": 133.31675720214844, "val_acc": 60.0}
{"epoch": 22, "training_loss": 115.96619873046875, "training_acc": 65.0, "val_loss": 394.336669921875, "val_acc": 40.0}
{"epoch": 23, "training_loss": 293.9105926513672, "training_acc": 55.0, "val_loss": 237.11807250976562, "val_acc": 40.0}
{"epoch": 24, "training_loss": 159.29161834716797, "training_acc": 55.0, "val_loss": 126.85330963134766, "val_acc": 60.0}
{"epoch": 25, "training_loss": 128.05025482177734, "training_acc": 55.0, "val_loss": 80.69795989990234, "val_acc": 40.0}
{"epoch": 26, "training_loss": 63.37913818359375, "training_acc": 55.0, "val_loss": 1.7487764358520508, "val_acc": 20.0}
{"epoch": 27, "training_loss": 9.238016128540039, "training_acc": 60.0, "val_loss": 332.6088562011719, "val_acc": 40.0}
{"epoch": 28, "training_loss": 264.849169921875, "training_acc": 55.0, "val_loss": 248.8135223388672, "val_acc": 40.0}
{"epoch": 29, "training_loss": 169.30184326171874, "training_acc": 55.0, "val_loss": 159.60256958007812, "val_acc": 60.0}
{"epoch": 30, "training_loss": 181.8905195236206, "training_acc": 45.0, "val_loss": 443.7933654785156, "val_acc": 40.0}
{"epoch": 31, "training_loss": 362.6076904296875, "training_acc": 55.0, "val_loss": 524.4207763671875, "val_acc": 40.0}
{"epoch": 32, "training_loss": 362.2242935180664, "training_acc": 55.0, "val_loss": 196.7025909423828, "val_acc": 60.0}
{"epoch": 33, "training_loss": 305.39849853515625, "training_acc": 45.0, "val_loss": 114.93916320800781, "val_acc": 60.0}
{"epoch": 34, "training_loss": 241.52366943359374, "training_acc": 35.0, "val_loss": 513.0628051757812, "val_acc": 40.0}
{"epoch": 35, "training_loss": 383.9614013671875, "training_acc": 55.0, "val_loss": 150.4168701171875, "val_acc": 40.0}
{"epoch": 36, "training_loss": 166.30780029296875, "training_acc": 45.0, "val_loss": 167.56826782226562, "val_acc": 60.0}
{"epoch": 37, "training_loss": 148.03911151885987, "training_acc": 45.0, "val_loss": 715.6920776367188, "val_acc": 40.0}
{"epoch": 38, "training_loss": 568.4366638183594, "training_acc": 55.0, "val_loss": 1336.7886962890625, "val_acc": 40.0}
{"epoch": 39, "training_loss": 997.0898071289063, "training_acc": 55.0, "val_loss": 1101.3726806640625, "val_acc": 40.0}
{"epoch": 40, "training_loss": 716.110791015625, "training_acc": 55.0, "val_loss": 15.707135200500488, "val_acc": 60.0}
{"epoch": 41, "training_loss": 53.40803833007813, "training_acc": 45.0, "val_loss": 437.7550964355469, "val_acc": 60.0}
{"epoch": 42, "training_loss": 587.3872253417969, "training_acc": 45.0, "val_loss": 172.20944213867188, "val_acc": 60.0}
{"epoch": 43, "training_loss": 300.47227783203124, "training_acc": 35.0, "val_loss": 512.7582397460938, "val_acc": 40.0}
{"epoch": 44, "training_loss": 374.8999420166016, "training_acc": 55.0, "val_loss": 188.8031463623047, "val_acc": 40.0}
{"epoch": 45, "training_loss": 147.69344482421874, "training_acc": 55.0, "val_loss": 238.70762634277344, "val_acc": 60.0}
