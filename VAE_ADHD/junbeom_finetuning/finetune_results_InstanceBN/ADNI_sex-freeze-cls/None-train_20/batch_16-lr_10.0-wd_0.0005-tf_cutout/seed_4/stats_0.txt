"main_modify.py --pretrained_path None --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 4 --task ADNI_sex --input_option yAware --learning_rate 1e1 --batch_size 16 --weight_decay 5e-4 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 429.93005523681643, "training_acc": 50.0, "val_loss": 736.2706909179688, "val_acc": 40.0}
{"epoch": 1, "training_loss": 911.631396484375, "training_acc": 40.0, "val_loss": 1099.6131591796875, "val_acc": 60.0}
{"epoch": 2, "training_loss": 1332.5374755859375, "training_acc": 50.0, "val_loss": 298.6246643066406, "val_acc": 60.0}
{"epoch": 3, "training_loss": 497.9231689453125, "training_acc": 40.0, "val_loss": 877.1375122070312, "val_acc": 40.0}
{"epoch": 4, "training_loss": 730.935400390625, "training_acc": 50.0, "val_loss": 337.81341552734375, "val_acc": 40.0}
{"epoch": 5, "training_loss": 213.50779571533204, "training_acc": 60.0, "val_loss": 331.62255859375, "val_acc": 60.0}
{"epoch": 6, "training_loss": 403.5878509521484, "training_acc": 50.0, "val_loss": 61.08944320678711, "val_acc": 60.0}
{"epoch": 7, "training_loss": 197.02521362304688, "training_acc": 40.0, "val_loss": 571.79833984375, "val_acc": 40.0}
{"epoch": 8, "training_loss": 422.9959716796875, "training_acc": 50.0, "val_loss": 167.78927612304688, "val_acc": 60.0}
{"epoch": 9, "training_loss": 227.61154479980468, "training_acc": 50.0, "val_loss": 357.6117858886719, "val_acc": 60.0}
{"epoch": 10, "training_loss": 408.90081787109375, "training_acc": 50.0, "val_loss": 161.52737426757812, "val_acc": 40.0}
{"epoch": 11, "training_loss": 144.04864654541015, "training_acc": 50.0, "val_loss": 247.01329040527344, "val_acc": 40.0}
{"epoch": 12, "training_loss": 172.75964813232423, "training_acc": 50.0, "val_loss": 32.855987548828125, "val_acc": 60.0}
{"epoch": 13, "training_loss": 98.48821105957032, "training_acc": 40.0, "val_loss": 125.87761688232422, "val_acc": 40.0}
{"epoch": 14, "training_loss": 124.106201171875, "training_acc": 50.0, "val_loss": 212.16246032714844, "val_acc": 60.0}
{"epoch": 15, "training_loss": 232.16904907226564, "training_acc": 50.0, "val_loss": 297.53216552734375, "val_acc": 40.0}
{"epoch": 16, "training_loss": 268.77861938476565, "training_acc": 50.0, "val_loss": 283.9051208496094, "val_acc": 40.0}
{"epoch": 17, "training_loss": 287.7992431640625, "training_acc": 30.0, "val_loss": 36.044124603271484, "val_acc": 60.0}
{"epoch": 18, "training_loss": 51.67234802246094, "training_acc": 60.0, "val_loss": 406.0621032714844, "val_acc": 40.0}
{"epoch": 19, "training_loss": 326.72718811035156, "training_acc": 50.0, "val_loss": 21.17814064025879, "val_acc": 40.0}
{"epoch": 20, "training_loss": 134.5468017578125, "training_acc": 40.0, "val_loss": 371.0309753417969, "val_acc": 60.0}
{"epoch": 21, "training_loss": 433.1531555175781, "training_acc": 50.0, "val_loss": 15.003976821899414, "val_acc": 40.0}
{"epoch": 22, "training_loss": 31.57637939453125, "training_acc": 50.0, "val_loss": 4.74847412109375, "val_acc": 60.0}
{"epoch": 23, "training_loss": 21.98364677429199, "training_acc": 50.0, "val_loss": 16.774728775024414, "val_acc": 60.0}
{"epoch": 24, "training_loss": 18.770176696777344, "training_acc": 60.0, "val_loss": 24.31317710876465, "val_acc": 40.0}
{"epoch": 25, "training_loss": 11.46490249633789, "training_acc": 70.0, "val_loss": 266.422607421875, "val_acc": 60.0}
{"epoch": 26, "training_loss": 330.892919921875, "training_acc": 50.0, "val_loss": 100.55831146240234, "val_acc": 60.0}
{"epoch": 27, "training_loss": 133.31555786132813, "training_acc": 50.0, "val_loss": 278.0551452636719, "val_acc": 40.0}
{"epoch": 28, "training_loss": 199.98375854492187, "training_acc": 50.0, "val_loss": 218.51194763183594, "val_acc": 60.0}
{"epoch": 29, "training_loss": 310.2783203125, "training_acc": 50.0, "val_loss": 168.1241455078125, "val_acc": 60.0}
{"epoch": 30, "training_loss": 160.36974029541017, "training_acc": 60.0, "val_loss": 439.2279968261719, "val_acc": 40.0}
{"epoch": 31, "training_loss": 361.1525939941406, "training_acc": 50.0, "val_loss": 224.1828155517578, "val_acc": 40.0}
{"epoch": 32, "training_loss": 178.8204345703125, "training_acc": 50.0, "val_loss": 194.6168975830078, "val_acc": 60.0}
{"epoch": 33, "training_loss": 210.94879760742188, "training_acc": 50.0, "val_loss": 312.21826171875, "val_acc": 40.0}
{"epoch": 34, "training_loss": 290.3285278320312, "training_acc": 50.0, "val_loss": 411.0091247558594, "val_acc": 40.0}
{"epoch": 35, "training_loss": 287.0617446899414, "training_acc": 50.0, "val_loss": 308.4329528808594, "val_acc": 60.0}
{"epoch": 36, "training_loss": 423.6615234375, "training_acc": 50.0, "val_loss": 443.7529296875, "val_acc": 60.0}
{"epoch": 37, "training_loss": 478.188525390625, "training_acc": 50.0, "val_loss": 248.46177673339844, "val_acc": 40.0}
{"epoch": 38, "training_loss": 206.403466796875, "training_acc": 50.0, "val_loss": 842.3583374023438, "val_acc": 40.0}
{"epoch": 39, "training_loss": 699.1090759277344, "training_acc": 50.0, "val_loss": 665.6402587890625, "val_acc": 40.0}
{"epoch": 40, "training_loss": 465.56804809570315, "training_acc": 50.0, "val_loss": 251.4751434326172, "val_acc": 60.0}
{"epoch": 41, "training_loss": 456.9308227539062, "training_acc": 50.0, "val_loss": 471.29547119140625, "val_acc": 60.0}
