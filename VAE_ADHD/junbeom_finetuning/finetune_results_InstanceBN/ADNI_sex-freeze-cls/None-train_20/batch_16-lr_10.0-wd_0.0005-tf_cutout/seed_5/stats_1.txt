"main_modify.py --pretrained_path None --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 5 --task ADNI_sex --input_option yAware --learning_rate 1e1 --batch_size 16 --weight_decay 5e-4 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 428.2188878059387, "training_acc": 45.0, "val_loss": 955.9652709960938, "val_acc": 40.0}
{"epoch": 1, "training_loss": 562.5727478027344, "training_acc": 65.0, "val_loss": 1314.3074951171875, "val_acc": 60.0}
{"epoch": 2, "training_loss": 1776.54453125, "training_acc": 45.0, "val_loss": 644.9573364257812, "val_acc": 60.0}
{"epoch": 3, "training_loss": 655.83837890625, "training_acc": 55.0, "val_loss": 798.314453125, "val_acc": 40.0}
{"epoch": 4, "training_loss": 600.4628967285156, "training_acc": 55.0, "val_loss": 589.48291015625, "val_acc": 40.0}
{"epoch": 5, "training_loss": 303.04509353637695, "training_acc": 55.0, "val_loss": 676.1224975585938, "val_acc": 60.0}
{"epoch": 6, "training_loss": 961.5524780273438, "training_acc": 45.0, "val_loss": 1046.6649169921875, "val_acc": 60.0}
{"epoch": 7, "training_loss": 1392.69169921875, "training_acc": 45.0, "val_loss": 477.6554870605469, "val_acc": 60.0}
{"epoch": 8, "training_loss": 488.11884994506835, "training_acc": 55.0, "val_loss": 726.6124267578125, "val_acc": 40.0}
{"epoch": 9, "training_loss": 584.41904296875, "training_acc": 55.0, "val_loss": 844.9400634765625, "val_acc": 40.0}
{"epoch": 10, "training_loss": 598.2158416748047, "training_acc": 55.0, "val_loss": 79.83272552490234, "val_acc": 60.0}
{"epoch": 11, "training_loss": 109.169921875, "training_acc": 45.0, "val_loss": 141.52182006835938, "val_acc": 60.0}
{"epoch": 12, "training_loss": 173.46277618408203, "training_acc": 45.0, "val_loss": 59.54669952392578, "val_acc": 40.0}
{"epoch": 13, "training_loss": 105.62324523925781, "training_acc": 45.0, "val_loss": 75.91875457763672, "val_acc": 60.0}
{"epoch": 14, "training_loss": 66.50842895507813, "training_acc": 65.0, "val_loss": 617.6980590820312, "val_acc": 40.0}
{"epoch": 15, "training_loss": 465.15845947265626, "training_acc": 55.0, "val_loss": 516.2571411132812, "val_acc": 40.0}
{"epoch": 16, "training_loss": 353.46244659423826, "training_acc": 55.0, "val_loss": 260.0429382324219, "val_acc": 60.0}
{"epoch": 17, "training_loss": 378.5354736328125, "training_acc": 45.0, "val_loss": 232.38365173339844, "val_acc": 60.0}
{"epoch": 18, "training_loss": 328.123876953125, "training_acc": 35.0, "val_loss": 183.9955291748047, "val_acc": 40.0}
{"epoch": 19, "training_loss": 93.08957290649414, "training_acc": 55.0, "val_loss": 346.3275451660156, "val_acc": 60.0}
{"epoch": 20, "training_loss": 525.3073974609375, "training_acc": 45.0, "val_loss": 330.5484924316406, "val_acc": 60.0}
{"epoch": 21, "training_loss": 371.2187234997749, "training_acc": 50.0, "val_loss": 376.9195861816406, "val_acc": 40.0}
{"epoch": 22, "training_loss": 339.7950927734375, "training_acc": 55.0, "val_loss": 178.66209411621094, "val_acc": 40.0}
{"epoch": 23, "training_loss": 221.9577880859375, "training_acc": 45.0, "val_loss": 368.5508728027344, "val_acc": 60.0}
{"epoch": 24, "training_loss": 473.53382568359376, "training_acc": 45.0, "val_loss": 123.99382781982422, "val_acc": 40.0}
{"epoch": 25, "training_loss": 143.73114013671875, "training_acc": 55.0, "val_loss": 457.5503845214844, "val_acc": 40.0}
{"epoch": 26, "training_loss": 310.40595092773435, "training_acc": 55.0, "val_loss": 107.2307357788086, "val_acc": 60.0}
{"epoch": 27, "training_loss": 146.7787109375, "training_acc": 45.0, "val_loss": 157.19166564941406, "val_acc": 60.0}
{"epoch": 28, "training_loss": 161.14036560058594, "training_acc": 45.0, "val_loss": 545.7151489257812, "val_acc": 40.0}
{"epoch": 29, "training_loss": 457.3107177734375, "training_acc": 55.0, "val_loss": 850.30712890625, "val_acc": 40.0}
{"epoch": 30, "training_loss": 617.0851501464844, "training_acc": 55.0, "val_loss": 270.888427734375, "val_acc": 40.0}
{"epoch": 31, "training_loss": 199.8530029296875, "training_acc": 55.0, "val_loss": 318.891845703125, "val_acc": 60.0}
{"epoch": 32, "training_loss": 424.6228393554687, "training_acc": 45.0, "val_loss": 49.84554672241211, "val_acc": 60.0}
{"epoch": 33, "training_loss": 138.49700927734375, "training_acc": 45.0, "val_loss": 757.9866943359375, "val_acc": 40.0}
{"epoch": 34, "training_loss": 570.68583984375, "training_acc": 55.0, "val_loss": 539.9493408203125, "val_acc": 40.0}
{"epoch": 35, "training_loss": 303.7980682373047, "training_acc": 55.0, "val_loss": 394.8285827636719, "val_acc": 60.0}
{"epoch": 36, "training_loss": 605.8018188476562, "training_acc": 45.0, "val_loss": 705.7355346679688, "val_acc": 60.0}
{"epoch": 37, "training_loss": 970.50234375, "training_acc": 45.0, "val_loss": 371.33770751953125, "val_acc": 60.0}
{"epoch": 38, "training_loss": 365.0293701171875, "training_acc": 45.0, "val_loss": 750.4761962890625, "val_acc": 40.0}
{"epoch": 39, "training_loss": 712.870263671875, "training_acc": 55.0, "val_loss": 1525.0018310546875, "val_acc": 40.0}
{"epoch": 40, "training_loss": 1134.644287109375, "training_acc": 55.0, "val_loss": 1221.7791748046875, "val_acc": 40.0}
{"epoch": 41, "training_loss": 847.437890625, "training_acc": 55.0, "val_loss": 201.6822967529297, "val_acc": 40.0}
{"epoch": 42, "training_loss": 211.76915893554687, "training_acc": 55.0, "val_loss": 673.19873046875, "val_acc": 60.0}
{"epoch": 43, "training_loss": 962.762744140625, "training_acc": 45.0, "val_loss": 618.5758666992188, "val_acc": 60.0}
{"epoch": 44, "training_loss": 769.14775390625, "training_acc": 45.0, "val_loss": 241.8184814453125, "val_acc": 40.0}
{"epoch": 45, "training_loss": 211.4239959716797, "training_acc": 55.0, "val_loss": 824.0320434570312, "val_acc": 40.0}
{"epoch": 46, "training_loss": 612.8691528320312, "training_acc": 55.0, "val_loss": 525.273193359375, "val_acc": 40.0}
{"epoch": 47, "training_loss": 285.21422119140624, "training_acc": 55.0, "val_loss": 439.111083984375, "val_acc": 60.0}
{"epoch": 48, "training_loss": 634.780419921875, "training_acc": 45.0, "val_loss": 824.7467041015625, "val_acc": 60.0}
{"epoch": 49, "training_loss": 1118.6364990234374, "training_acc": 45.0, "val_loss": 543.7223510742188, "val_acc": 60.0}
{"epoch": 50, "training_loss": 651.6989074707031, "training_acc": 45.0, "val_loss": 521.2490234375, "val_acc": 40.0}
{"epoch": 51, "training_loss": 389.7736083984375, "training_acc": 55.0, "val_loss": 1299.4744873046875, "val_acc": 40.0}
