"main_modify.py --pretrained_path None --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 1 --task ADNI_sex --input_option yAware --learning_rate 1e2 --batch_size 16 --weight_decay 1e-6 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 4282.287011623383, "training_acc": 50.0, "val_loss": 8214.8583984375, "val_acc": 40.0}
{"epoch": 1, "training_loss": 7630.1048828125, "training_acc": 50.0, "val_loss": 12311.1337890625, "val_acc": 60.0}
{"epoch": 2, "training_loss": 14908.802734375, "training_acc": 50.0, "val_loss": 4844.04345703125, "val_acc": 60.0}
{"epoch": 3, "training_loss": 6708.6044921875, "training_acc": 40.0, "val_loss": 7768.92822265625, "val_acc": 40.0}
{"epoch": 4, "training_loss": 6177.636328125, "training_acc": 50.0, "val_loss": 655.3688354492188, "val_acc": 40.0}
{"epoch": 5, "training_loss": 1699.14541015625, "training_acc": 50.0, "val_loss": 7437.54541015625, "val_acc": 60.0}
{"epoch": 6, "training_loss": 9502.584765625, "training_acc": 50.0, "val_loss": 4133.875, "val_acc": 60.0}
{"epoch": 7, "training_loss": 4406.004370117187, "training_acc": 50.0, "val_loss": 5637.5927734375, "val_acc": 40.0}
{"epoch": 8, "training_loss": 4968.508203125, "training_acc": 50.0, "val_loss": 3554.630126953125, "val_acc": 40.0}
{"epoch": 9, "training_loss": 2693.8187255859375, "training_acc": 50.0, "val_loss": 2784.822998046875, "val_acc": 60.0}
{"epoch": 10, "training_loss": 3401.00234375, "training_acc": 50.0, "val_loss": 248.68594360351562, "val_acc": 40.0}
{"epoch": 11, "training_loss": 573.150830078125, "training_acc": 50.0, "val_loss": 491.53839111328125, "val_acc": 60.0}
{"epoch": 12, "training_loss": 561.3697410583496, "training_acc": 50.0, "val_loss": 1621.3690185546875, "val_acc": 40.0}
{"epoch": 13, "training_loss": 1203.5400512695312, "training_acc": 50.0, "val_loss": 1681.1441650390625, "val_acc": 60.0}
{"epoch": 14, "training_loss": 2095.412109375, "training_acc": 50.0, "val_loss": 1493.7205810546875, "val_acc": 60.0}
{"epoch": 15, "training_loss": 1302.9636093139648, "training_acc": 60.0, "val_loss": 867.8826293945312, "val_acc": 40.0}
{"epoch": 16, "training_loss": 435.703125, "training_acc": 70.0, "val_loss": 863.1160278320312, "val_acc": 60.0}
{"epoch": 17, "training_loss": 902.2903991699219, "training_acc": 50.0, "val_loss": 518.5797729492188, "val_acc": 60.0}
{"epoch": 18, "training_loss": 636.2038818359375, "training_acc": 50.0, "val_loss": 243.0120086669922, "val_acc": 60.0}
{"epoch": 19, "training_loss": 424.5544189453125, "training_acc": 50.0, "val_loss": 23.855833053588867, "val_acc": 60.0}
{"epoch": 20, "training_loss": 80.96795043945312, "training_acc": 65.0, "val_loss": 278.83734130859375, "val_acc": 40.0}
{"epoch": 21, "training_loss": 638.4599243164063, "training_acc": 50.0, "val_loss": 1928.2506103515625, "val_acc": 60.0}
{"epoch": 22, "training_loss": 1880.347216796875, "training_acc": 50.0, "val_loss": 4815.4443359375, "val_acc": 40.0}
{"epoch": 23, "training_loss": 4436.8359375, "training_acc": 50.0, "val_loss": 7134.82275390625, "val_acc": 40.0}
{"epoch": 24, "training_loss": 5694.001708984375, "training_acc": 50.0, "val_loss": 89.6451644897461, "val_acc": 40.0}
{"epoch": 25, "training_loss": 521.255093383789, "training_acc": 60.0, "val_loss": 6499.46826171875, "val_acc": 60.0}
{"epoch": 26, "training_loss": 8287.1123046875, "training_acc": 50.0, "val_loss": 6145.44677734375, "val_acc": 60.0}
{"epoch": 27, "training_loss": 7010.02138671875, "training_acc": 50.0, "val_loss": 888.7638549804688, "val_acc": 40.0}
{"epoch": 28, "training_loss": 1237.465234375, "training_acc": 50.0, "val_loss": 3984.439453125, "val_acc": 40.0}
{"epoch": 29, "training_loss": 3322.3046875, "training_acc": 50.0, "val_loss": 1232.158203125, "val_acc": 60.0}
{"epoch": 30, "training_loss": 1583.0763671875, "training_acc": 50.0, "val_loss": 1449.9083251953125, "val_acc": 40.0}
{"epoch": 31, "training_loss": 1322.071533203125, "training_acc": 50.0, "val_loss": 194.1873779296875, "val_acc": 40.0}
{"epoch": 32, "training_loss": 797.7953857421875, "training_acc": 50.0, "val_loss": 3586.481201171875, "val_acc": 60.0}
{"epoch": 33, "training_loss": 4327.053076171875, "training_acc": 50.0, "val_loss": 612.9807739257812, "val_acc": 60.0}
{"epoch": 34, "training_loss": 1784.090087890625, "training_acc": 40.0, "val_loss": 5442.42724609375, "val_acc": 40.0}
{"epoch": 35, "training_loss": 4373.43369140625, "training_acc": 50.0, "val_loss": 501.7568054199219, "val_acc": 40.0}
{"epoch": 36, "training_loss": 2188.45380859375, "training_acc": 30.0, "val_loss": 3701.85791015625, "val_acc": 60.0}
{"epoch": 37, "training_loss": 4227.1146484375, "training_acc": 50.0, "val_loss": 1226.4569091796875, "val_acc": 40.0}
{"epoch": 38, "training_loss": 1129.4808349609375, "training_acc": 50.0, "val_loss": 2430.61279296875, "val_acc": 40.0}
