"main_modify.py --pretrained_path None --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 1 --task ADNI_sex --input_option yAware --learning_rate 1e2 --batch_size 16 --weight_decay 1e-6 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 2149.089481830597, "training_acc": 55.0, "val_loss": 7892.9072265625, "val_acc": 40.0}
{"epoch": 1, "training_loss": 5069.1123046875, "training_acc": 65.0, "val_loss": 14344.2529296875, "val_acc": 60.0}
{"epoch": 2, "training_loss": 18760.0294921875, "training_acc": 45.0, "val_loss": 2803.142578125, "val_acc": 60.0}
{"epoch": 3, "training_loss": 5023.6865234375, "training_acc": 45.0, "val_loss": 18141.685546875, "val_acc": 40.0}
{"epoch": 4, "training_loss": 14109.9578125, "training_acc": 55.0, "val_loss": 15272.6240234375, "val_acc": 40.0}
{"epoch": 5, "training_loss": 10762.734130859375, "training_acc": 55.0, "val_loss": 1488.3203125, "val_acc": 60.0}
{"epoch": 6, "training_loss": 2653.0935546875, "training_acc": 45.0, "val_loss": 3598.290771484375, "val_acc": 60.0}
{"epoch": 7, "training_loss": 3781.9375, "training_acc": 45.0, "val_loss": 7047.1953125, "val_acc": 40.0}
{"epoch": 8, "training_loss": 5684.00810546875, "training_acc": 55.0, "val_loss": 14767.4794921875, "val_acc": 40.0}
{"epoch": 9, "training_loss": 11294.10390625, "training_acc": 55.0, "val_loss": 10458.1044921875, "val_acc": 40.0}
{"epoch": 10, "training_loss": 6200.11044921875, "training_acc": 55.0, "val_loss": 3860.051513671875, "val_acc": 60.0}
{"epoch": 11, "training_loss": 6249.77265625, "training_acc": 45.0, "val_loss": 9243.1708984375, "val_acc": 60.0}
{"epoch": 12, "training_loss": 12603.9625, "training_acc": 45.0, "val_loss": 6169.98974609375, "val_acc": 60.0}
{"epoch": 13, "training_loss": 7393.0099609375, "training_acc": 45.0, "val_loss": 5681.43798828125, "val_acc": 40.0}
{"epoch": 14, "training_loss": 5673.478515625, "training_acc": 55.0, "val_loss": 12696.2099609375, "val_acc": 40.0}
{"epoch": 15, "training_loss": 9404.22138671875, "training_acc": 55.0, "val_loss": 9033.4150390625, "val_acc": 40.0}
{"epoch": 16, "training_loss": 6042.84365234375, "training_acc": 55.0, "val_loss": 1105.8212890625, "val_acc": 60.0}
{"epoch": 17, "training_loss": 2337.1421875, "training_acc": 45.0, "val_loss": 2753.496826171875, "val_acc": 60.0}
{"epoch": 18, "training_loss": 3218.327099609375, "training_acc": 45.0, "val_loss": 4808.59716796875, "val_acc": 40.0}
{"epoch": 19, "training_loss": 4384.7451171875, "training_acc": 55.0, "val_loss": 7162.67578125, "val_acc": 40.0}
{"epoch": 20, "training_loss": 4884.760595703125, "training_acc": 55.0, "val_loss": 425.48876953125, "val_acc": 60.0}
{"epoch": 21, "training_loss": 715.84130859375, "training_acc": 45.0, "val_loss": 1458.569580078125, "val_acc": 60.0}
{"epoch": 22, "training_loss": 2005.2742431640625, "training_acc": 35.0, "val_loss": 159.6384735107422, "val_acc": 60.0}
{"epoch": 23, "training_loss": 447.1883178710938, "training_acc": 45.0, "val_loss": 782.9067993164062, "val_acc": 40.0}
{"epoch": 24, "training_loss": 522.1408447265625, "training_acc": 65.0, "val_loss": 1820.2109375, "val_acc": 60.0}
{"epoch": 25, "training_loss": 2344.541632080078, "training_acc": 45.0, "val_loss": 2404.91943359375, "val_acc": 40.0}
{"epoch": 26, "training_loss": 2033.056640625, "training_acc": 55.0, "val_loss": 619.4987182617188, "val_acc": 40.0}
{"epoch": 27, "training_loss": 1467.3284423828125, "training_acc": 45.0, "val_loss": 3348.66650390625, "val_acc": 60.0}
{"epoch": 28, "training_loss": 4191.5556640625, "training_acc": 45.0, "val_loss": 1722.6253662109375, "val_acc": 40.0}
{"epoch": 29, "training_loss": 1459.8064453125, "training_acc": 55.0, "val_loss": 4710.36865234375, "val_acc": 40.0}
{"epoch": 30, "training_loss": 3244.02490234375, "training_acc": 55.0, "val_loss": 593.6994018554688, "val_acc": 60.0}
{"epoch": 31, "training_loss": 1056.596875, "training_acc": 45.0, "val_loss": 785.3078002929688, "val_acc": 60.0}
{"epoch": 32, "training_loss": 967.7631713867188, "training_acc": 55.0, "val_loss": 4064.965576171875, "val_acc": 40.0}
{"epoch": 33, "training_loss": 2976.1115478515626, "training_acc": 55.0, "val_loss": 1500.4000244140625, "val_acc": 40.0}
{"epoch": 34, "training_loss": 1628.89990234375, "training_acc": 45.0, "val_loss": 1738.603515625, "val_acc": 60.0}
{"epoch": 35, "training_loss": 2259.740234375, "training_acc": 35.0, "val_loss": 392.62542724609375, "val_acc": 60.0}
{"epoch": 36, "training_loss": 643.7135620117188, "training_acc": 45.0, "val_loss": 500.5850524902344, "val_acc": 40.0}
{"epoch": 37, "training_loss": 949.3696533203125, "training_acc": 45.0, "val_loss": 1110.1162109375, "val_acc": 60.0}
{"epoch": 38, "training_loss": 1545.0682373046875, "training_acc": 45.0, "val_loss": 2436.045654296875, "val_acc": 40.0}
{"epoch": 39, "training_loss": 1662.023876953125, "training_acc": 55.0, "val_loss": 1346.9658203125, "val_acc": 60.0}
{"epoch": 40, "training_loss": 1891.18779296875, "training_acc": 45.0, "val_loss": 1322.8349609375, "val_acc": 40.0}
{"epoch": 41, "training_loss": 1305.453564453125, "training_acc": 55.0, "val_loss": 334.0567932128906, "val_acc": 40.0}
