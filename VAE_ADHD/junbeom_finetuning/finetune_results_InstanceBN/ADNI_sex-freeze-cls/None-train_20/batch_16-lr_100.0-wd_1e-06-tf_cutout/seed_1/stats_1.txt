"main_modify.py --pretrained_path None --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 1 --task ADNI_sex --input_option yAware --learning_rate 1e2 --batch_size 16 --weight_decay 1e-6 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 1941.72023730278, "training_acc": 55.0, "val_loss": 4555.5947265625, "val_acc": 40.0}
{"epoch": 1, "training_loss": 3696.75546875, "training_acc": 65.0, "val_loss": 16905.263671875, "val_acc": 60.0}
{"epoch": 2, "training_loss": 22292.1234375, "training_acc": 45.0, "val_loss": 5609.38427734375, "val_acc": 60.0}
{"epoch": 3, "training_loss": 8778.823828125, "training_acc": 35.0, "val_loss": 11256.390625, "val_acc": 40.0}
{"epoch": 4, "training_loss": 8352.03466796875, "training_acc": 55.0, "val_loss": 7382.82763671875, "val_acc": 40.0}
{"epoch": 5, "training_loss": 5532.172265625, "training_acc": 55.0, "val_loss": 3856.219482421875, "val_acc": 60.0}
{"epoch": 6, "training_loss": 5701.047265625, "training_acc": 45.0, "val_loss": 2299.887451171875, "val_acc": 60.0}
{"epoch": 7, "training_loss": 2570.01142578125, "training_acc": 55.0, "val_loss": 7660.23583984375, "val_acc": 40.0}
{"epoch": 8, "training_loss": 6094.526953125, "training_acc": 55.0, "val_loss": 5643.3369140625, "val_acc": 40.0}
{"epoch": 9, "training_loss": 2866.71298828125, "training_acc": 55.0, "val_loss": 5820.03076171875, "val_acc": 60.0}
{"epoch": 10, "training_loss": 9270.02734375, "training_acc": 45.0, "val_loss": 9393.2978515625, "val_acc": 60.0}
{"epoch": 11, "training_loss": 12434.5537109375, "training_acc": 45.0, "val_loss": 3990.285888671875, "val_acc": 60.0}
{"epoch": 12, "training_loss": 4099.742517089844, "training_acc": 55.0, "val_loss": 6698.81787109375, "val_acc": 40.0}
{"epoch": 13, "training_loss": 5706.584765625, "training_acc": 55.0, "val_loss": 7941.70654296875, "val_acc": 40.0}
{"epoch": 14, "training_loss": 5607.192797851562, "training_acc": 55.0, "val_loss": 648.3343505859375, "val_acc": 60.0}
{"epoch": 15, "training_loss": 982.7552490234375, "training_acc": 45.0, "val_loss": 1210.829833984375, "val_acc": 60.0}
{"epoch": 16, "training_loss": 1292.1048400878906, "training_acc": 55.0, "val_loss": 2334.048583984375, "val_acc": 40.0}
{"epoch": 17, "training_loss": 1615.5090087890626, "training_acc": 55.0, "val_loss": 1188.090087890625, "val_acc": 60.0}
{"epoch": 18, "training_loss": 1553.1844055175782, "training_acc": 45.0, "val_loss": 1255.3424072265625, "val_acc": 40.0}
{"epoch": 19, "training_loss": 859.8462646484375, "training_acc": 55.0, "val_loss": 1396.314697265625, "val_acc": 60.0}
{"epoch": 20, "training_loss": 1880.6735595703126, "training_acc": 45.0, "val_loss": 1047.1376953125, "val_acc": 40.0}
{"epoch": 21, "training_loss": 918.289697265625, "training_acc": 55.0, "val_loss": 1094.995849609375, "val_acc": 60.0}
{"epoch": 22, "training_loss": 1609.97705078125, "training_acc": 45.0, "val_loss": 1390.6011962890625, "val_acc": 40.0}
{"epoch": 23, "training_loss": 1023.653125, "training_acc": 55.0, "val_loss": 1857.86328125, "val_acc": 40.0}
{"epoch": 24, "training_loss": 1346.0143798828126, "training_acc": 45.0, "val_loss": 1185.0235595703125, "val_acc": 40.0}
{"epoch": 25, "training_loss": 771.0683959960937, "training_acc": 55.0, "val_loss": 2186.828369140625, "val_acc": 60.0}
{"epoch": 26, "training_loss": 3506.9271484375, "training_acc": 45.0, "val_loss": 789.01806640625, "val_acc": 60.0}
{"epoch": 27, "training_loss": 1166.8663818359375, "training_acc": 55.0, "val_loss": 8409.98046875, "val_acc": 40.0}
{"epoch": 28, "training_loss": 6518.6810546875, "training_acc": 55.0, "val_loss": 8528.642578125, "val_acc": 40.0}
{"epoch": 29, "training_loss": 5815.26474609375, "training_acc": 55.0, "val_loss": 140.11798095703125, "val_acc": 60.0}
{"epoch": 30, "training_loss": 552.8968872070312, "training_acc": 45.0, "val_loss": 1161.5263671875, "val_acc": 60.0}
{"epoch": 31, "training_loss": 1562.193994140625, "training_acc": 45.0, "val_loss": 2048.369873046875, "val_acc": 40.0}
{"epoch": 32, "training_loss": 1150.2213134765625, "training_acc": 55.0, "val_loss": 2870.00244140625, "val_acc": 60.0}
{"epoch": 33, "training_loss": 4456.89150390625, "training_acc": 45.0, "val_loss": 2944.233154296875, "val_acc": 60.0}
{"epoch": 34, "training_loss": 3775.3741943359373, "training_acc": 35.0, "val_loss": 907.716796875, "val_acc": 40.0}
{"epoch": 35, "training_loss": 366.067529296875, "training_acc": 75.0, "val_loss": 617.2592163085938, "val_acc": 60.0}
{"epoch": 36, "training_loss": 845.2499755859375, "training_acc": 45.0, "val_loss": 318.7908630371094, "val_acc": 40.0}
{"epoch": 37, "training_loss": 313.7300659179688, "training_acc": 65.0, "val_loss": 2077.338623046875, "val_acc": 60.0}
{"epoch": 38, "training_loss": 2684.53515625, "training_acc": 45.0, "val_loss": 2261.58544921875, "val_acc": 40.0}
{"epoch": 39, "training_loss": 1930.00068359375, "training_acc": 55.0, "val_loss": 534.0735473632812, "val_acc": 40.0}
{"epoch": 40, "training_loss": 956.858740234375, "training_acc": 55.0, "val_loss": 3881.870361328125, "val_acc": 60.0}
{"epoch": 41, "training_loss": 5134.717431640625, "training_acc": 45.0, "val_loss": 677.4943237304688, "val_acc": 60.0}
{"epoch": 42, "training_loss": 1570.449462890625, "training_acc": 45.0, "val_loss": 7870.890625, "val_acc": 40.0}
{"epoch": 43, "training_loss": 6074.4837890625, "training_acc": 55.0, "val_loss": 5666.4892578125, "val_acc": 40.0}
{"epoch": 44, "training_loss": 3408.206640625, "training_acc": 55.0, "val_loss": 3992.659423828125, "val_acc": 60.0}
{"epoch": 45, "training_loss": 5735.10703125, "training_acc": 45.0, "val_loss": 7054.8642578125, "val_acc": 60.0}
{"epoch": 46, "training_loss": 9467.97392578125, "training_acc": 45.0, "val_loss": 3634.330078125, "val_acc": 60.0}
{"epoch": 47, "training_loss": 3680.5642517089846, "training_acc": 55.0, "val_loss": 4371.46826171875, "val_acc": 40.0}
{"epoch": 48, "training_loss": 3674.56953125, "training_acc": 55.0, "val_loss": 4013.665283203125, "val_acc": 40.0}
