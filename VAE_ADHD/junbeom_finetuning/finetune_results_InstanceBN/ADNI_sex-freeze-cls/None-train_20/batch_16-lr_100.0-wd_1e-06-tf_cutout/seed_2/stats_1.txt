"main_modify.py --pretrained_path None --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 2 --task ADNI_sex --input_option yAware --learning_rate 1e2 --batch_size 16 --weight_decay 1e-6 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 6432.977816104889, "training_acc": 40.0, "val_loss": 5753.87841796875, "val_acc": 60.0}
{"epoch": 1, "training_loss": 9427.281640625, "training_acc": 40.0, "val_loss": 15556.8427734375, "val_acc": 40.0}
{"epoch": 2, "training_loss": 12711.40458984375, "training_acc": 50.0, "val_loss": 7384.6533203125, "val_acc": 40.0}
{"epoch": 3, "training_loss": 5141.845068359375, "training_acc": 50.0, "val_loss": 2915.724609375, "val_acc": 60.0}
{"epoch": 4, "training_loss": 3420.017333984375, "training_acc": 50.0, "val_loss": 1836.183837890625, "val_acc": 40.0}
{"epoch": 5, "training_loss": 1545.3167236328125, "training_acc": 50.0, "val_loss": 452.5356140136719, "val_acc": 40.0}
{"epoch": 6, "training_loss": 1493.8498046875, "training_acc": 40.0, "val_loss": 2835.383056640625, "val_acc": 60.0}
{"epoch": 7, "training_loss": 2988.4301513671876, "training_acc": 50.0, "val_loss": 4981.13427734375, "val_acc": 40.0}
{"epoch": 8, "training_loss": 4820.5328125, "training_acc": 50.0, "val_loss": 5806.85302734375, "val_acc": 40.0}
{"epoch": 9, "training_loss": 4444.188586425781, "training_acc": 50.0, "val_loss": 3022.88818359375, "val_acc": 60.0}
{"epoch": 10, "training_loss": 4441.29921875, "training_acc": 50.0, "val_loss": 3700.185302734375, "val_acc": 60.0}
{"epoch": 11, "training_loss": 3946.2392822265624, "training_acc": 50.0, "val_loss": 4764.04541015625, "val_acc": 40.0}
{"epoch": 12, "training_loss": 4801.983984375, "training_acc": 50.0, "val_loss": 7246.69921875, "val_acc": 40.0}
{"epoch": 13, "training_loss": 5490.36025390625, "training_acc": 50.0, "val_loss": 989.9208984375, "val_acc": 60.0}
{"epoch": 14, "training_loss": 1637.6599609375, "training_acc": 50.0, "val_loss": 2354.8759765625, "val_acc": 60.0}
{"epoch": 15, "training_loss": 2321.90751953125, "training_acc": 50.0, "val_loss": 4834.84423828125, "val_acc": 40.0}
{"epoch": 16, "training_loss": 4499.025, "training_acc": 50.0, "val_loss": 7773.27099609375, "val_acc": 40.0}
{"epoch": 17, "training_loss": 5961.2248046875, "training_acc": 50.0, "val_loss": 293.1161804199219, "val_acc": 40.0}
{"epoch": 18, "training_loss": 2037.344677734375, "training_acc": 40.0, "val_loss": 6967.3203125, "val_acc": 60.0}
{"epoch": 19, "training_loss": 8786.97265625, "training_acc": 50.0, "val_loss": 5998.37060546875, "val_acc": 60.0}
{"epoch": 20, "training_loss": 6541.0515625, "training_acc": 50.0, "val_loss": 1768.9637451171875, "val_acc": 40.0}
{"epoch": 21, "training_loss": 2119.1001953125, "training_acc": 50.0, "val_loss": 6815.51953125, "val_acc": 40.0}
{"epoch": 22, "training_loss": 5674.99296875, "training_acc": 50.0, "val_loss": 3182.476318359375, "val_acc": 40.0}
{"epoch": 23, "training_loss": 2239.4731201171876, "training_acc": 50.0, "val_loss": 1276.6845703125, "val_acc": 60.0}
{"epoch": 24, "training_loss": 1339.2615478515625, "training_acc": 50.0, "val_loss": 3577.462890625, "val_acc": 40.0}
{"epoch": 25, "training_loss": 3087.36044921875, "training_acc": 50.0, "val_loss": 4978.34619140625, "val_acc": 40.0}
{"epoch": 26, "training_loss": 3631.17431640625, "training_acc": 50.0, "val_loss": 1621.3211669921875, "val_acc": 60.0}
{"epoch": 27, "training_loss": 2439.00341796875, "training_acc": 50.0, "val_loss": 3176.890625, "val_acc": 60.0}
{"epoch": 28, "training_loss": 3420.91708984375, "training_acc": 50.0, "val_loss": 2929.780517578125, "val_acc": 40.0}
{"epoch": 29, "training_loss": 2868.246875, "training_acc": 50.0, "val_loss": 5504.8095703125, "val_acc": 40.0}
{"epoch": 30, "training_loss": 4061.01953125, "training_acc": 50.0, "val_loss": 1316.5380859375, "val_acc": 60.0}
{"epoch": 31, "training_loss": 1829.945947265625, "training_acc": 50.0, "val_loss": 3336.867919921875, "val_acc": 60.0}
{"epoch": 32, "training_loss": 4010.947314453125, "training_acc": 50.0, "val_loss": 109.79741668701172, "val_acc": 60.0}
{"epoch": 33, "training_loss": 1405.7915283203124, "training_acc": 40.0, "val_loss": 6329.45458984375, "val_acc": 40.0}
{"epoch": 34, "training_loss": 5022.40234375, "training_acc": 50.0, "val_loss": 935.5466918945312, "val_acc": 40.0}
{"epoch": 35, "training_loss": 1510.21552734375, "training_acc": 50.0, "val_loss": 5814.24072265625, "val_acc": 60.0}
{"epoch": 36, "training_loss": 7508.4123046875, "training_acc": 50.0, "val_loss": 4668.06201171875, "val_acc": 60.0}
{"epoch": 37, "training_loss": 5834.857421875, "training_acc": 50.0, "val_loss": 3137.6845703125, "val_acc": 40.0}
{"epoch": 38, "training_loss": 2935.336328125, "training_acc": 50.0, "val_loss": 4551.087890625, "val_acc": 40.0}
{"epoch": 39, "training_loss": 3309.199462890625, "training_acc": 50.0, "val_loss": 2189.084716796875, "val_acc": 60.0}
{"epoch": 40, "training_loss": 2884.61552734375, "training_acc": 50.0, "val_loss": 3684.04541015625, "val_acc": 60.0}
{"epoch": 41, "training_loss": 4416.922436523438, "training_acc": 50.0, "val_loss": 7.640004634857178, "val_acc": 60.0}
{"epoch": 42, "training_loss": 1109.3131717681886, "training_acc": 50.0, "val_loss": 4815.09716796875, "val_acc": 40.0}
{"epoch": 43, "training_loss": 3665.834814453125, "training_acc": 50.0, "val_loss": 955.9467163085938, "val_acc": 60.0}
{"epoch": 44, "training_loss": 1623.88974609375, "training_acc": 50.0, "val_loss": 740.3392944335938, "val_acc": 60.0}
{"epoch": 45, "training_loss": 1248.494091796875, "training_acc": 50.0, "val_loss": 4510.65087890625, "val_acc": 40.0}
{"epoch": 46, "training_loss": 3561.3935546875, "training_acc": 50.0, "val_loss": 9.25586223602295, "val_acc": 40.0}
{"epoch": 47, "training_loss": 258.9103462219238, "training_acc": 75.0, "val_loss": 3094.168701171875, "val_acc": 60.0}
{"epoch": 48, "training_loss": 3706.18349609375, "training_acc": 50.0, "val_loss": 228.0500946044922, "val_acc": 60.0}
{"epoch": 49, "training_loss": 1072.370361328125, "training_acc": 50.0, "val_loss": 7485.89697265625, "val_acc": 40.0}
{"epoch": 50, "training_loss": 6355.9869140625, "training_acc": 50.0, "val_loss": 3429.985595703125, "val_acc": 40.0}
{"epoch": 51, "training_loss": 2769.64306640625, "training_acc": 50.0, "val_loss": 4211.1796875, "val_acc": 60.0}
{"epoch": 52, "training_loss": 5372.85, "training_acc": 50.0, "val_loss": 3411.783935546875, "val_acc": 60.0}
{"epoch": 53, "training_loss": 3330.9203125, "training_acc": 50.0, "val_loss": 5573.50537109375, "val_acc": 40.0}
{"epoch": 54, "training_loss": 5673.256640625, "training_acc": 50.0, "val_loss": 9896.345703125, "val_acc": 40.0}
{"epoch": 55, "training_loss": 8019.62548828125, "training_acc": 50.0, "val_loss": 3866.471923828125, "val_acc": 40.0}
{"epoch": 56, "training_loss": 2361.4764404296875, "training_acc": 60.0, "val_loss": 3269.132080078125, "val_acc": 60.0}
{"epoch": 57, "training_loss": 4352.6123046875, "training_acc": 50.0, "val_loss": 2235.42626953125, "val_acc": 60.0}
{"epoch": 58, "training_loss": 2044.3147888183594, "training_acc": 60.0, "val_loss": 3947.015625, "val_acc": 40.0}
{"epoch": 59, "training_loss": 3298.94970703125, "training_acc": 50.0, "val_loss": 1802.5452880859375, "val_acc": 40.0}
{"epoch": 60, "training_loss": 2085.524658203125, "training_acc": 40.0, "val_loss": 2420.672607421875, "val_acc": 60.0}
