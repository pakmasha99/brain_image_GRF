"main_modify.py --pretrained_path None --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 5 --task ADNI_sex --input_option yAware --learning_rate 1e2 --batch_size 16 --weight_decay 1e-6 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 1683.5758162498473, "training_acc": 50.0, "val_loss": 8159.0390625, "val_acc": 60.0}
{"epoch": 1, "training_loss": 11397.90234375, "training_acc": 50.0, "val_loss": 6482.92431640625, "val_acc": 60.0}
{"epoch": 2, "training_loss": 5782.250823974609, "training_acc": 60.0, "val_loss": 6887.72802734375, "val_acc": 40.0}
{"epoch": 3, "training_loss": 5909.46875, "training_acc": 50.0, "val_loss": 2063.154052734375, "val_acc": 40.0}
{"epoch": 4, "training_loss": 1694.2958984375, "training_acc": 60.0, "val_loss": 7648.3056640625, "val_acc": 60.0}
{"epoch": 5, "training_loss": 9797.37109375, "training_acc": 50.0, "val_loss": 6400.94482421875, "val_acc": 60.0}
{"epoch": 6, "training_loss": 6717.53388671875, "training_acc": 50.0, "val_loss": 5009.6220703125, "val_acc": 40.0}
{"epoch": 7, "training_loss": 4953.463671875, "training_acc": 50.0, "val_loss": 11474.2119140625, "val_acc": 40.0}
{"epoch": 8, "training_loss": 9511.1125, "training_acc": 50.0, "val_loss": 6845.19091796875, "val_acc": 40.0}
{"epoch": 9, "training_loss": 4529.01220703125, "training_acc": 50.0, "val_loss": 3756.96484375, "val_acc": 60.0}
{"epoch": 10, "training_loss": 5104.436181640625, "training_acc": 50.0, "val_loss": 7986.4296875, "val_acc": 60.0}
{"epoch": 11, "training_loss": 9958.421484375, "training_acc": 50.0, "val_loss": 5304.81005859375, "val_acc": 60.0}
{"epoch": 12, "training_loss": 5764.108203125, "training_acc": 50.0, "val_loss": 5329.45068359375, "val_acc": 40.0}
{"epoch": 13, "training_loss": 5102.64501953125, "training_acc": 50.0, "val_loss": 10776.126953125, "val_acc": 40.0}
{"epoch": 14, "training_loss": 8621.269921875, "training_acc": 50.0, "val_loss": 4560.24951171875, "val_acc": 40.0}
{"epoch": 15, "training_loss": 3423.74912109375, "training_acc": 50.0, "val_loss": 4053.298095703125, "val_acc": 60.0}
{"epoch": 16, "training_loss": 5288.94453125, "training_acc": 50.0, "val_loss": 3365.27978515625, "val_acc": 60.0}
{"epoch": 17, "training_loss": 3318.597705078125, "training_acc": 50.0, "val_loss": 5911.44677734375, "val_acc": 40.0}
{"epoch": 18, "training_loss": 5183.234716796875, "training_acc": 50.0, "val_loss": 11593.8369140625, "val_acc": 40.0}
{"epoch": 19, "training_loss": 9503.6625, "training_acc": 50.0, "val_loss": 7176.72216796875, "val_acc": 40.0}
{"epoch": 20, "training_loss": 4933.679663085937, "training_acc": 50.0, "val_loss": 4547.80078125, "val_acc": 60.0}
{"epoch": 21, "training_loss": 6151.1951171875, "training_acc": 50.0, "val_loss": 9296.4970703125, "val_acc": 60.0}
{"epoch": 22, "training_loss": 11679.20400390625, "training_acc": 50.0, "val_loss": 8021.59521484375, "val_acc": 60.0}
{"epoch": 23, "training_loss": 9475.13359375, "training_acc": 50.0, "val_loss": 1389.0789794921875, "val_acc": 60.0}
{"epoch": 24, "training_loss": 1749.9349609375, "training_acc": 60.0, "val_loss": 11087.462890625, "val_acc": 40.0}
{"epoch": 25, "training_loss": 9403.169140625, "training_acc": 50.0, "val_loss": 14088.2001953125, "val_acc": 40.0}
{"epoch": 26, "training_loss": 11289.04375, "training_acc": 50.0, "val_loss": 6819.68994140625, "val_acc": 40.0}
{"epoch": 27, "training_loss": 6195.96259765625, "training_acc": 30.0, "val_loss": 2793.714599609375, "val_acc": 60.0}
{"epoch": 28, "training_loss": 3570.121484375, "training_acc": 50.0, "val_loss": 1557.54736328125, "val_acc": 60.0}
{"epoch": 29, "training_loss": 1824.592578125, "training_acc": 50.0, "val_loss": 2308.356689453125, "val_acc": 40.0}
{"epoch": 30, "training_loss": 1734.7773315429688, "training_acc": 50.0, "val_loss": 1522.7203369140625, "val_acc": 60.0}
{"epoch": 31, "training_loss": 2039.151220703125, "training_acc": 50.0, "val_loss": 93.81837463378906, "val_acc": 60.0}
{"epoch": 32, "training_loss": 864.0130615234375, "training_acc": 50.0, "val_loss": 5862.74755859375, "val_acc": 40.0}
{"epoch": 33, "training_loss": 4677.589990234375, "training_acc": 50.0, "val_loss": 1534.191650390625, "val_acc": 40.0}
{"epoch": 34, "training_loss": 1642.84208984375, "training_acc": 50.0, "val_loss": 4164.42529296875, "val_acc": 60.0}
{"epoch": 35, "training_loss": 5291.2322265625, "training_acc": 50.0, "val_loss": 1812.0511474609375, "val_acc": 60.0}
{"epoch": 36, "training_loss": 1861.5009765625, "training_acc": 60.0, "val_loss": 6171.7939453125, "val_acc": 40.0}
{"epoch": 37, "training_loss": 5164.01552734375, "training_acc": 50.0, "val_loss": 5914.474609375, "val_acc": 40.0}
{"epoch": 38, "training_loss": 4581.088598632812, "training_acc": 50.0, "val_loss": 1191.2017822265625, "val_acc": 60.0}
{"epoch": 39, "training_loss": 2037.4505859375, "training_acc": 50.0, "val_loss": 964.4483642578125, "val_acc": 60.0}
{"epoch": 40, "training_loss": 1490.252685546875, "training_acc": 50.0, "val_loss": 4247.6748046875, "val_acc": 40.0}
{"epoch": 41, "training_loss": 3382.5060302734373, "training_acc": 50.0, "val_loss": 238.4746551513672, "val_acc": 40.0}
{"epoch": 42, "training_loss": 1343.2132446289063, "training_acc": 40.0, "val_loss": 3701.65478515625, "val_acc": 60.0}
{"epoch": 43, "training_loss": 4443.58818359375, "training_acc": 50.0, "val_loss": 3.896380662918091, "val_acc": 80.0}
{"epoch": 44, "training_loss": 826.6535629272461, "training_acc": 60.0, "val_loss": 6949.64697265625, "val_acc": 40.0}
{"epoch": 45, "training_loss": 5661.344140625, "training_acc": 50.0, "val_loss": 2578.37939453125, "val_acc": 40.0}
{"epoch": 46, "training_loss": 2278.2638671875, "training_acc": 50.0, "val_loss": 4233.96142578125, "val_acc": 60.0}
{"epoch": 47, "training_loss": 5373.031640625, "training_acc": 50.0, "val_loss": 3760.580078125, "val_acc": 60.0}
{"epoch": 48, "training_loss": 4554.816821289062, "training_acc": 50.0, "val_loss": 1310.3291015625, "val_acc": 40.0}
{"epoch": 49, "training_loss": 1391.01064453125, "training_acc": 50.0, "val_loss": 368.054443359375, "val_acc": 40.0}
{"epoch": 50, "training_loss": 1391.90205078125, "training_acc": 40.0, "val_loss": 3426.439208984375, "val_acc": 60.0}
{"epoch": 51, "training_loss": 4100.272900390625, "training_acc": 50.0, "val_loss": 565.6923217773438, "val_acc": 40.0}
{"epoch": 52, "training_loss": 607.2572998046875, "training_acc": 50.0, "val_loss": 407.03668212890625, "val_acc": 40.0}
{"epoch": 53, "training_loss": 772.90322265625, "training_acc": 50.0, "val_loss": 2659.241943359375, "val_acc": 60.0}
{"epoch": 54, "training_loss": 3138.7220703125, "training_acc": 50.0, "val_loss": 1505.619384765625, "val_acc": 40.0}
{"epoch": 55, "training_loss": 1558.773779296875, "training_acc": 50.0, "val_loss": 529.9274291992188, "val_acc": 40.0}
{"epoch": 56, "training_loss": 997.652783203125, "training_acc": 50.0, "val_loss": 3747.453857421875, "val_acc": 60.0}
{"epoch": 57, "training_loss": 4706.830419921875, "training_acc": 50.0, "val_loss": 1366.8929443359375, "val_acc": 60.0}
{"epoch": 58, "training_loss": 1071.247265625, "training_acc": 70.0, "val_loss": 5325.66650390625, "val_acc": 40.0}
{"epoch": 59, "training_loss": 4684.56552734375, "training_acc": 50.0, "val_loss": 3623.703125, "val_acc": 40.0}
{"epoch": 60, "training_loss": 2143.70869140625, "training_acc": 60.0, "val_loss": 2540.430908203125, "val_acc": 60.0}
{"epoch": 61, "training_loss": 3280.1276611328126, "training_acc": 50.0, "val_loss": 1546.470947265625, "val_acc": 60.0}
{"epoch": 62, "training_loss": 1212.465625, "training_acc": 70.0, "val_loss": 3398.28125, "val_acc": 40.0}
