"main_modify.py --pretrained_path None --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 4 --task ADNI_sex --input_option yAware --learning_rate 1e2 --batch_size 16 --weight_decay 1e-6 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 4294.385231018066, "training_acc": 50.0, "val_loss": 7381.67333984375, "val_acc": 40.0}
{"epoch": 1, "training_loss": 9124.280859375, "training_acc": 40.0, "val_loss": 10939.3037109375, "val_acc": 60.0}
{"epoch": 2, "training_loss": 13251.5029296875, "training_acc": 50.0, "val_loss": 2902.978271484375, "val_acc": 60.0}
{"epoch": 3, "training_loss": 4925.27265625, "training_acc": 40.0, "val_loss": 8912.6318359375, "val_acc": 40.0}
{"epoch": 4, "training_loss": 7427.0375, "training_acc": 50.0, "val_loss": 3489.94140625, "val_acc": 40.0}
{"epoch": 5, "training_loss": 2192.364599609375, "training_acc": 60.0, "val_loss": 3257.630126953125, "val_acc": 60.0}
{"epoch": 6, "training_loss": 3961.46875, "training_acc": 50.0, "val_loss": 538.8690795898438, "val_acc": 60.0}
{"epoch": 7, "training_loss": 1923.58125, "training_acc": 40.0, "val_loss": 5864.51611328125, "val_acc": 40.0}
{"epoch": 8, "training_loss": 4353.1318359375, "training_acc": 50.0, "val_loss": 1585.0506591796875, "val_acc": 60.0}
{"epoch": 9, "training_loss": 2158.9647216796875, "training_acc": 50.0, "val_loss": 3482.187255859375, "val_acc": 60.0}
{"epoch": 10, "training_loss": 3970.207421875, "training_acc": 50.0, "val_loss": 1767.2249755859375, "val_acc": 40.0}
{"epoch": 11, "training_loss": 1566.19140625, "training_acc": 50.0, "val_loss": 2610.902099609375, "val_acc": 40.0}
{"epoch": 12, "training_loss": 1799.5041748046874, "training_acc": 50.0, "val_loss": 243.11758422851562, "val_acc": 60.0}
{"epoch": 13, "training_loss": 922.5300537109375, "training_acc": 40.0, "val_loss": 1401.818359375, "val_acc": 40.0}
{"epoch": 14, "training_loss": 1313.0591064453124, "training_acc": 50.0, "val_loss": 2033.7210693359375, "val_acc": 60.0}
{"epoch": 15, "training_loss": 2208.323583984375, "training_acc": 50.0, "val_loss": 3120.556396484375, "val_acc": 40.0}
{"epoch": 16, "training_loss": 2808.61845703125, "training_acc": 50.0, "val_loss": 2992.51611328125, "val_acc": 40.0}
{"epoch": 17, "training_loss": 2953.5443359375, "training_acc": 30.0, "val_loss": 252.2353057861328, "val_acc": 60.0}
{"epoch": 18, "training_loss": 434.83505859375, "training_acc": 60.0, "val_loss": 4261.01171875, "val_acc": 40.0}
{"epoch": 19, "training_loss": 3434.999169921875, "training_acc": 50.0, "val_loss": 441.8155212402344, "val_acc": 40.0}
{"epoch": 20, "training_loss": 1457.71904296875, "training_acc": 40.0, "val_loss": 3551.092529296875, "val_acc": 60.0}
{"epoch": 21, "training_loss": 4125.48916015625, "training_acc": 50.0, "val_loss": 395.45391845703125, "val_acc": 40.0}
{"epoch": 22, "training_loss": 518.1541015625, "training_acc": 50.0, "val_loss": 162.7816925048828, "val_acc": 40.0}
{"epoch": 23, "training_loss": 686.20908203125, "training_acc": 50.0, "val_loss": 2944.423828125, "val_acc": 60.0}
{"epoch": 24, "training_loss": 3313.14345703125, "training_acc": 50.0, "val_loss": 1752.9359130859375, "val_acc": 40.0}
{"epoch": 25, "training_loss": 2296.88837890625, "training_acc": 50.0, "val_loss": 1780.9547119140625, "val_acc": 40.0}
{"epoch": 26, "training_loss": 885.3638671875, "training_acc": 70.0, "val_loss": 3978.572265625, "val_acc": 60.0}
{"epoch": 27, "training_loss": 5096.394140625, "training_acc": 50.0, "val_loss": 3531.764892578125, "val_acc": 60.0}
{"epoch": 28, "training_loss": 3740.389453125, "training_acc": 50.0, "val_loss": 4416.2109375, "val_acc": 40.0}
{"epoch": 29, "training_loss": 3884.879931640625, "training_acc": 50.0, "val_loss": 8090.859375, "val_acc": 40.0}
{"epoch": 30, "training_loss": 6584.33330078125, "training_acc": 50.0, "val_loss": 3583.765625, "val_acc": 40.0}
{"epoch": 31, "training_loss": 3074.56689453125, "training_acc": 40.0, "val_loss": 1814.690673828125, "val_acc": 60.0}
{"epoch": 32, "training_loss": 1989.129833984375, "training_acc": 50.0, "val_loss": 2495.347412109375, "val_acc": 40.0}
{"epoch": 33, "training_loss": 2117.0865234375, "training_acc": 50.0, "val_loss": 2507.627197265625, "val_acc": 40.0}
{"epoch": 34, "training_loss": 1741.9756286621093, "training_acc": 50.0, "val_loss": 518.171875, "val_acc": 60.0}
{"epoch": 35, "training_loss": 714.366748046875, "training_acc": 50.0, "val_loss": 968.3204956054688, "val_acc": 40.0}
{"epoch": 36, "training_loss": 946.269970703125, "training_acc": 50.0, "val_loss": 1352.2548828125, "val_acc": 60.0}
{"epoch": 37, "training_loss": 1073.782244873047, "training_acc": 50.0, "val_loss": 6040.4970703125, "val_acc": 40.0}
{"epoch": 38, "training_loss": 5020.15, "training_acc": 50.0, "val_loss": 11164.3935546875, "val_acc": 40.0}
{"epoch": 39, "training_loss": 9245.9771484375, "training_acc": 50.0, "val_loss": 8947.791015625, "val_acc": 40.0}
{"epoch": 40, "training_loss": 6531.804296875, "training_acc": 50.0, "val_loss": 1072.2926025390625, "val_acc": 60.0}
{"epoch": 41, "training_loss": 2762.9982421875, "training_acc": 50.0, "val_loss": 3426.737548828125, "val_acc": 60.0}
