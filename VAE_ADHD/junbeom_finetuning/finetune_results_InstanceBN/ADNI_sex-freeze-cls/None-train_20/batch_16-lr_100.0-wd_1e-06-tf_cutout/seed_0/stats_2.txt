"main_modify.py --pretrained_path None --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_sex --input_option yAware --learning_rate 1e2 --batch_size 16 --weight_decay 1e-6 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 8574.828137493134, "training_acc": 45.0, "val_loss": 8817.74609375, "val_acc": 40.0}
{"epoch": 1, "training_loss": 7578.31328125, "training_acc": 50.0, "val_loss": 12251.2392578125, "val_acc": 60.0}
{"epoch": 2, "training_loss": 15738.3890625, "training_acc": 50.0, "val_loss": 9864.38671875, "val_acc": 60.0}
{"epoch": 3, "training_loss": 10281.092578125, "training_acc": 50.0, "val_loss": 5335.78662109375, "val_acc": 40.0}
{"epoch": 4, "training_loss": 4963.70361328125, "training_acc": 50.0, "val_loss": 15399.009765625, "val_acc": 40.0}
{"epoch": 5, "training_loss": 12935.2375, "training_acc": 50.0, "val_loss": 11672.478515625, "val_acc": 40.0}
{"epoch": 6, "training_loss": 9144.017602539063, "training_acc": 50.0, "val_loss": 1986.361328125, "val_acc": 60.0}
{"epoch": 7, "training_loss": 3129.082421875, "training_acc": 50.0, "val_loss": 5021.955078125, "val_acc": 60.0}
{"epoch": 8, "training_loss": 6052.920556640625, "training_acc": 50.0, "val_loss": 882.9636840820312, "val_acc": 60.0}
{"epoch": 9, "training_loss": 1655.28603515625, "training_acc": 50.0, "val_loss": 7292.6640625, "val_acc": 40.0}
{"epoch": 10, "training_loss": 6073.3109375, "training_acc": 50.0, "val_loss": 3414.242919921875, "val_acc": 40.0}
{"epoch": 11, "training_loss": 2181.4660766601564, "training_acc": 60.0, "val_loss": 4167.06982421875, "val_acc": 60.0}
{"epoch": 12, "training_loss": 5344.2654296875, "training_acc": 50.0, "val_loss": 3597.546875, "val_acc": 60.0}
{"epoch": 13, "training_loss": 3521.607666015625, "training_acc": 50.0, "val_loss": 5588.1689453125, "val_acc": 40.0}
{"epoch": 14, "training_loss": 5301.129296875, "training_acc": 50.0, "val_loss": 10488.0693359375, "val_acc": 40.0}
{"epoch": 15, "training_loss": 8468.1880859375, "training_acc": 50.0, "val_loss": 4960.00390625, "val_acc": 40.0}
{"epoch": 16, "training_loss": 2955.865093994141, "training_acc": 60.0, "val_loss": 3140.0283203125, "val_acc": 60.0}
{"epoch": 17, "training_loss": 3962.31044921875, "training_acc": 50.0, "val_loss": 3206.35205078125, "val_acc": 60.0}
{"epoch": 18, "training_loss": 3475.668798828125, "training_acc": 50.0, "val_loss": 3550.56494140625, "val_acc": 40.0}
{"epoch": 19, "training_loss": 3593.31259765625, "training_acc": 50.0, "val_loss": 4636.6337890625, "val_acc": 40.0}
{"epoch": 20, "training_loss": 2980.20419921875, "training_acc": 50.0, "val_loss": 3779.224365234375, "val_acc": 60.0}
{"epoch": 21, "training_loss": 5304.55615234375, "training_acc": 50.0, "val_loss": 6777.74072265625, "val_acc": 60.0}
{"epoch": 22, "training_loss": 8156.5005859375, "training_acc": 50.0, "val_loss": 2978.376220703125, "val_acc": 60.0}
{"epoch": 23, "training_loss": 3789.3521484375, "training_acc": 40.0, "val_loss": 3891.966064453125, "val_acc": 40.0}
{"epoch": 24, "training_loss": 3160.190283203125, "training_acc": 50.0, "val_loss": 917.1513671875, "val_acc": 40.0}
{"epoch": 25, "training_loss": 1587.16806640625, "training_acc": 40.0, "val_loss": 2764.501220703125, "val_acc": 60.0}
{"epoch": 26, "training_loss": 3232.4921264648438, "training_acc": 50.0, "val_loss": 1428.9107666015625, "val_acc": 40.0}
{"epoch": 27, "training_loss": 1277.600048828125, "training_acc": 50.0, "val_loss": 14.926874160766602, "val_acc": 60.0}
{"epoch": 28, "training_loss": 630.9567642211914, "training_acc": 45.0, "val_loss": 3158.564697265625, "val_acc": 60.0}
{"epoch": 29, "training_loss": 3653.550341796875, "training_acc": 50.0, "val_loss": 697.46142578125, "val_acc": 40.0}
{"epoch": 30, "training_loss": 918.22734375, "training_acc": 50.0, "val_loss": 282.2799987792969, "val_acc": 60.0}
{"epoch": 31, "training_loss": 336.015673828125, "training_acc": 50.0, "val_loss": 3047.118896484375, "val_acc": 40.0}
{"epoch": 32, "training_loss": 2578.3306884765625, "training_acc": 50.0, "val_loss": 2739.4140625, "val_acc": 40.0}
{"epoch": 33, "training_loss": 1880.3785766601563, "training_acc": 50.0, "val_loss": 529.0811767578125, "val_acc": 60.0}
{"epoch": 34, "training_loss": 1243.517919921875, "training_acc": 30.0, "val_loss": 339.6915283203125, "val_acc": 60.0}
{"epoch": 35, "training_loss": 340.6549438476562, "training_acc": 50.0, "val_loss": 2305.6787109375, "val_acc": 40.0}
{"epoch": 36, "training_loss": 1890.4888916015625, "training_acc": 50.0, "val_loss": 428.5520935058594, "val_acc": 40.0}
{"epoch": 37, "training_loss": 824.9028076171875, "training_acc": 50.0, "val_loss": 2896.7021484375, "val_acc": 60.0}
{"epoch": 38, "training_loss": 3266.0439453125, "training_acc": 50.0, "val_loss": 1525.1854248046875, "val_acc": 40.0}
{"epoch": 39, "training_loss": 1796.26171875, "training_acc": 50.0, "val_loss": 1945.6190185546875, "val_acc": 40.0}
{"epoch": 40, "training_loss": 1274.9950073242187, "training_acc": 60.0, "val_loss": 2489.373779296875, "val_acc": 60.0}
{"epoch": 41, "training_loss": 2973.8966796875, "training_acc": 50.0, "val_loss": 205.9514923095703, "val_acc": 60.0}
{"epoch": 42, "training_loss": 941.9274169921875, "training_acc": 50.0, "val_loss": 6798.76708984375, "val_acc": 40.0}
{"epoch": 43, "training_loss": 5597.154052734375, "training_acc": 50.0, "val_loss": 4038.082763671875, "val_acc": 40.0}
{"epoch": 44, "training_loss": 2706.789013671875, "training_acc": 50.0, "val_loss": 983.1724853515625, "val_acc": 60.0}
{"epoch": 45, "training_loss": 972.9913146972656, "training_acc": 50.0, "val_loss": 3262.262451171875, "val_acc": 40.0}
{"epoch": 46, "training_loss": 3171.0111328125, "training_acc": 50.0, "val_loss": 1024.4779052734375, "val_acc": 40.0}
