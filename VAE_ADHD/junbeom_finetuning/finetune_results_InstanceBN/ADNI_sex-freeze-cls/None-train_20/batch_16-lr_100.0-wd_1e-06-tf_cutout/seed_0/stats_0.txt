"main_modify.py --pretrained_path None --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_sex --input_option yAware --learning_rate 1e2 --batch_size 16 --weight_decay 1e-6 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 6427.287110519409, "training_acc": 50.0, "val_loss": 7535.19677734375, "val_acc": 40.0}
{"epoch": 1, "training_loss": 7235.2001953125, "training_acc": 50.0, "val_loss": 13941.5810546875, "val_acc": 60.0}
{"epoch": 2, "training_loss": 17341.30546875, "training_acc": 50.0, "val_loss": 10794.5771484375, "val_acc": 60.0}
{"epoch": 3, "training_loss": 11622.2130859375, "training_acc": 50.0, "val_loss": 3426.38720703125, "val_acc": 40.0}
{"epoch": 4, "training_loss": 3887.0828125, "training_acc": 50.0, "val_loss": 11078.3603515625, "val_acc": 40.0}
{"epoch": 5, "training_loss": 8747.262890625, "training_acc": 50.0, "val_loss": 2543.889404296875, "val_acc": 40.0}
{"epoch": 6, "training_loss": 2764.81640625, "training_acc": 50.0, "val_loss": 7425.18603515625, "val_acc": 60.0}
{"epoch": 7, "training_loss": 9454.474609375, "training_acc": 50.0, "val_loss": 6779.8486328125, "val_acc": 60.0}
{"epoch": 8, "training_loss": 7677.8822265625, "training_acc": 50.0, "val_loss": 1640.8316650390625, "val_acc": 40.0}
{"epoch": 9, "training_loss": 1623.9103271484375, "training_acc": 50.0, "val_loss": 6046.1416015625, "val_acc": 40.0}
{"epoch": 10, "training_loss": 4770.92880859375, "training_acc": 50.0, "val_loss": 241.816650390625, "val_acc": 40.0}
{"epoch": 11, "training_loss": 1196.298193359375, "training_acc": 50.0, "val_loss": 6205.87158203125, "val_acc": 60.0}
{"epoch": 12, "training_loss": 7750.2205078125, "training_acc": 50.0, "val_loss": 4473.673828125, "val_acc": 60.0}
{"epoch": 13, "training_loss": 5130.190185546875, "training_acc": 50.0, "val_loss": 4797.4580078125, "val_acc": 40.0}
{"epoch": 14, "training_loss": 4211.5697265625, "training_acc": 50.0, "val_loss": 8280.671875, "val_acc": 40.0}
{"epoch": 15, "training_loss": 6533.4859375, "training_acc": 50.0, "val_loss": 1592.0416259765625, "val_acc": 40.0}
{"epoch": 16, "training_loss": 2012.46591796875, "training_acc": 50.0, "val_loss": 6407.90869140625, "val_acc": 60.0}
{"epoch": 17, "training_loss": 8147.58125, "training_acc": 50.0, "val_loss": 5885.1513671875, "val_acc": 60.0}
{"epoch": 18, "training_loss": 6967.39775390625, "training_acc": 50.0, "val_loss": 923.96142578125, "val_acc": 40.0}
{"epoch": 19, "training_loss": 1409.47685546875, "training_acc": 50.0, "val_loss": 1865.3472900390625, "val_acc": 40.0}
{"epoch": 20, "training_loss": 2001.76484375, "training_acc": 40.0, "val_loss": 1629.590576171875, "val_acc": 60.0}
{"epoch": 21, "training_loss": 1882.1361267089844, "training_acc": 40.0, "val_loss": 607.9674682617188, "val_acc": 60.0}
{"epoch": 22, "training_loss": 658.2759887695313, "training_acc": 50.0, "val_loss": 540.6845703125, "val_acc": 60.0}
{"epoch": 23, "training_loss": 477.99244384765626, "training_acc": 60.0, "val_loss": 56.5274658203125, "val_acc": 60.0}
{"epoch": 24, "training_loss": 340.93597412109375, "training_acc": 55.0, "val_loss": 1028.8800048828125, "val_acc": 40.0}
{"epoch": 25, "training_loss": 763.3356323242188, "training_acc": 60.0, "val_loss": 2138.602783203125, "val_acc": 60.0}
{"epoch": 26, "training_loss": 2421.12392578125, "training_acc": 50.0, "val_loss": 1748.18359375, "val_acc": 40.0}
{"epoch": 27, "training_loss": 1592.391796875, "training_acc": 50.0, "val_loss": 735.2019653320312, "val_acc": 40.0}
{"epoch": 28, "training_loss": 370.749853515625, "training_acc": 70.0, "val_loss": 3986.126953125, "val_acc": 60.0}
{"epoch": 29, "training_loss": 5118.1384765625, "training_acc": 50.0, "val_loss": 2279.637451171875, "val_acc": 60.0}
{"epoch": 30, "training_loss": 2585.348681640625, "training_acc": 50.0, "val_loss": 4335.85693359375, "val_acc": 40.0}
{"epoch": 31, "training_loss": 3685.2646484375, "training_acc": 50.0, "val_loss": 134.8650665283203, "val_acc": 60.0}
{"epoch": 32, "training_loss": 253.379736328125, "training_acc": 50.0, "val_loss": 1207.154541015625, "val_acc": 60.0}
{"epoch": 33, "training_loss": 1862.884619140625, "training_acc": 30.0, "val_loss": 682.5108642578125, "val_acc": 60.0}
{"epoch": 34, "training_loss": 776.7669189453125, "training_acc": 50.0, "val_loss": 2838.385498046875, "val_acc": 40.0}
{"epoch": 35, "training_loss": 2539.23828125, "training_acc": 50.0, "val_loss": 2218.929443359375, "val_acc": 40.0}
{"epoch": 36, "training_loss": 1742.021435546875, "training_acc": 50.0, "val_loss": 1756.37109375, "val_acc": 60.0}
{"epoch": 37, "training_loss": 1854.94453125, "training_acc": 50.0, "val_loss": 3239.84228515625, "val_acc": 40.0}
{"epoch": 38, "training_loss": 3018.98134765625, "training_acc": 50.0, "val_loss": 4257.3125, "val_acc": 40.0}
{"epoch": 39, "training_loss": 3267.986602783203, "training_acc": 50.0, "val_loss": 2316.954833984375, "val_acc": 60.0}
{"epoch": 40, "training_loss": 3296.2728515625, "training_acc": 50.0, "val_loss": 2124.895263671875, "val_acc": 60.0}
{"epoch": 41, "training_loss": 2271.8205078125, "training_acc": 50.0, "val_loss": 2486.901611328125, "val_acc": 40.0}
{"epoch": 42, "training_loss": 1896.60859375, "training_acc": 50.0, "val_loss": 1394.03125, "val_acc": 60.0}
