"main_modify.py --pretrained_path None --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_sex --input_option yAware --learning_rate 1e2 --batch_size 16 --weight_decay 1e-6 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 4284.884644889831, "training_acc": 50.0, "val_loss": 7579.58154296875, "val_acc": 40.0}
{"epoch": 1, "training_loss": 5572.473828125, "training_acc": 60.0, "val_loss": 16587.853515625, "val_acc": 60.0}
{"epoch": 2, "training_loss": 20674.825, "training_acc": 50.0, "val_loss": 11649.5625, "val_acc": 60.0}
{"epoch": 3, "training_loss": 12685.79443359375, "training_acc": 50.0, "val_loss": 8097.96875, "val_acc": 40.0}
{"epoch": 4, "training_loss": 7274.32880859375, "training_acc": 50.0, "val_loss": 17617.263671875, "val_acc": 40.0}
{"epoch": 5, "training_loss": 14432.4453125, "training_acc": 50.0, "val_loss": 10778.017578125, "val_acc": 40.0}
{"epoch": 6, "training_loss": 6986.805322265625, "training_acc": 50.0, "val_loss": 6017.93212890625, "val_acc": 60.0}
{"epoch": 7, "training_loss": 8058.11982421875, "training_acc": 50.0, "val_loss": 12990.3974609375, "val_acc": 60.0}
{"epoch": 8, "training_loss": 16285.76953125, "training_acc": 50.0, "val_loss": 11215.9365234375, "val_acc": 60.0}
{"epoch": 9, "training_loss": 13066.5033203125, "training_acc": 50.0, "val_loss": 1966.8050537109375, "val_acc": 60.0}
{"epoch": 10, "training_loss": 5084.590625, "training_acc": 30.0, "val_loss": 11357.2880859375, "val_acc": 40.0}
{"epoch": 11, "training_loss": 9528.13984375, "training_acc": 50.0, "val_loss": 9392.1103515625, "val_acc": 40.0}
{"epoch": 12, "training_loss": 7029.6697265625, "training_acc": 50.0, "val_loss": 1540.7664794921875, "val_acc": 60.0}
{"epoch": 13, "training_loss": 2527.76953125, "training_acc": 50.0, "val_loss": 4283.4140625, "val_acc": 60.0}
{"epoch": 14, "training_loss": 5157.949462890625, "training_acc": 50.0, "val_loss": 298.2369384765625, "val_acc": 60.0}
{"epoch": 15, "training_loss": 1191.332177734375, "training_acc": 50.0, "val_loss": 7902.96728515625, "val_acc": 40.0}
{"epoch": 16, "training_loss": 6592.693359375, "training_acc": 50.0, "val_loss": 4126.58447265625, "val_acc": 40.0}
{"epoch": 17, "training_loss": 3627.49677734375, "training_acc": 40.0, "val_loss": 2616.294189453125, "val_acc": 60.0}
{"epoch": 18, "training_loss": 3138.967578125, "training_acc": 50.0, "val_loss": 838.1566772460938, "val_acc": 40.0}
{"epoch": 19, "training_loss": 1341.34296875, "training_acc": 50.0, "val_loss": 192.6663055419922, "val_acc": 60.0}
{"epoch": 20, "training_loss": 422.4913818359375, "training_acc": 50.0, "val_loss": 1936.66015625, "val_acc": 40.0}
{"epoch": 21, "training_loss": 1749.7576171875, "training_acc": 50.0, "val_loss": 321.25494384765625, "val_acc": 60.0}
{"epoch": 22, "training_loss": 476.8605224609375, "training_acc": 50.0, "val_loss": 1155.51708984375, "val_acc": 40.0}
{"epoch": 23, "training_loss": 894.16025390625, "training_acc": 50.0, "val_loss": 1852.634033203125, "val_acc": 60.0}
{"epoch": 24, "training_loss": 2502.0251953125, "training_acc": 50.0, "val_loss": 1567.4407958984375, "val_acc": 60.0}
{"epoch": 25, "training_loss": 2168.1881103515625, "training_acc": 40.0, "val_loss": 1569.8212890625, "val_acc": 40.0}
{"epoch": 26, "training_loss": 1419.4870361328126, "training_acc": 40.0, "val_loss": 114.1632308959961, "val_acc": 40.0}
{"epoch": 27, "training_loss": 134.40553588867186, "training_acc": 60.0, "val_loss": 384.3296813964844, "val_acc": 60.0}
{"epoch": 28, "training_loss": 721.6385498046875, "training_acc": 50.0, "val_loss": 1936.3013916015625, "val_acc": 40.0}
{"epoch": 29, "training_loss": 1612.4454345703125, "training_acc": 40.0, "val_loss": 402.0262451171875, "val_acc": 40.0}
{"epoch": 30, "training_loss": 594.5265869140625, "training_acc": 40.0, "val_loss": 811.4664306640625, "val_acc": 40.0}
{"epoch": 31, "training_loss": 613.9963745117187, "training_acc": 50.0, "val_loss": 1975.444580078125, "val_acc": 60.0}
{"epoch": 32, "training_loss": 2654.077734375, "training_acc": 50.0, "val_loss": 1665.2938232421875, "val_acc": 60.0}
{"epoch": 33, "training_loss": 1534.8223266601562, "training_acc": 60.0, "val_loss": 2602.58984375, "val_acc": 40.0}
{"epoch": 34, "training_loss": 2044.50419921875, "training_acc": 50.0, "val_loss": 633.9054565429688, "val_acc": 60.0}
{"epoch": 35, "training_loss": 962.35966796875, "training_acc": 50.0, "val_loss": 1338.424072265625, "val_acc": 40.0}
{"epoch": 36, "training_loss": 1109.3299682617187, "training_acc": 50.0, "val_loss": 246.4757537841797, "val_acc": 40.0}
{"epoch": 37, "training_loss": 664.507666015625, "training_acc": 50.0, "val_loss": 2494.337158203125, "val_acc": 60.0}
{"epoch": 38, "training_loss": 2762.4482421875, "training_acc": 50.0, "val_loss": 2976.721435546875, "val_acc": 40.0}
{"epoch": 39, "training_loss": 2930.023046875, "training_acc": 50.0, "val_loss": 5910.43896484375, "val_acc": 40.0}
{"epoch": 40, "training_loss": 4439.631640625, "training_acc": 50.0, "val_loss": 700.2626953125, "val_acc": 60.0}
{"epoch": 41, "training_loss": 901.29140625, "training_acc": 50.0, "val_loss": 2908.905517578125, "val_acc": 60.0}
{"epoch": 42, "training_loss": 3564.3266357421876, "training_acc": 50.0, "val_loss": 620.2940673828125, "val_acc": 60.0}
{"epoch": 43, "training_loss": 811.26865234375, "training_acc": 60.0, "val_loss": 5577.48583984375, "val_acc": 40.0}
{"epoch": 44, "training_loss": 4616.9580078125, "training_acc": 50.0, "val_loss": 3049.262451171875, "val_acc": 40.0}
{"epoch": 45, "training_loss": 2728.21728515625, "training_acc": 40.0, "val_loss": 1694.6070556640625, "val_acc": 60.0}
