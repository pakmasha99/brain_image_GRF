"main_modify.py --pretrained_path None --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 2 --task ADNI_sex --input_option yAware --learning_rate 5e0 --batch_size 16 --weight_decay 1e-9 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 215.6065800189972, "training_acc": 45.0, "val_loss": 478.31158447265625, "val_acc": 40.0}
{"epoch": 1, "training_loss": 455.6923095703125, "training_acc": 45.0, "val_loss": 387.4289855957031, "val_acc": 60.0}
{"epoch": 2, "training_loss": 462.257958984375, "training_acc": 45.0, "val_loss": 270.760498046875, "val_acc": 40.0}
{"epoch": 3, "training_loss": 223.53023376464844, "training_acc": 55.0, "val_loss": 619.2107543945312, "val_acc": 40.0}
{"epoch": 4, "training_loss": 464.74384765625, "training_acc": 55.0, "val_loss": 358.4092102050781, "val_acc": 40.0}
{"epoch": 5, "training_loss": 244.5106288909912, "training_acc": 55.0, "val_loss": 191.9236297607422, "val_acc": 60.0}
{"epoch": 6, "training_loss": 280.77125244140626, "training_acc": 45.0, "val_loss": 207.9668426513672, "val_acc": 60.0}
{"epoch": 7, "training_loss": 226.84330139160156, "training_acc": 45.0, "val_loss": 352.19268798828125, "val_acc": 40.0}
{"epoch": 8, "training_loss": 305.34917602539065, "training_acc": 55.0, "val_loss": 668.6820678710938, "val_acc": 40.0}
{"epoch": 9, "training_loss": 494.29937438964845, "training_acc": 55.0, "val_loss": 431.73663330078125, "val_acc": 40.0}
{"epoch": 10, "training_loss": 279.88367614746096, "training_acc": 55.0, "val_loss": 140.2135467529297, "val_acc": 60.0}
{"epoch": 11, "training_loss": 221.38753662109374, "training_acc": 45.0, "val_loss": 267.0818786621094, "val_acc": 60.0}
{"epoch": 12, "training_loss": 342.5966369628906, "training_acc": 45.0, "val_loss": 7.657402038574219, "val_acc": 40.0}
{"epoch": 13, "training_loss": 24.83660125732422, "training_acc": 55.0, "val_loss": 94.03873443603516, "val_acc": 40.0}
{"epoch": 14, "training_loss": 79.53544158935547, "training_acc": 45.0, "val_loss": 10.602213859558105, "val_acc": 60.0}
{"epoch": 15, "training_loss": 23.712893676757812, "training_acc": 55.0, "val_loss": 263.2347412109375, "val_acc": 40.0}
{"epoch": 16, "training_loss": 193.84500732421876, "training_acc": 55.0, "val_loss": 45.69178771972656, "val_acc": 40.0}
{"epoch": 17, "training_loss": 128.4353454589844, "training_acc": 35.0, "val_loss": 214.61709594726562, "val_acc": 60.0}
{"epoch": 18, "training_loss": 271.2316162109375, "training_acc": 45.0, "val_loss": 35.887264251708984, "val_acc": 40.0}
{"epoch": 19, "training_loss": 26.2381103515625, "training_acc": 55.0, "val_loss": 227.4479522705078, "val_acc": 40.0}
{"epoch": 20, "training_loss": 166.42478637695314, "training_acc": 55.0, "val_loss": 86.66548919677734, "val_acc": 40.0}
{"epoch": 21, "training_loss": 88.89029846191406, "training_acc": 45.0, "val_loss": 89.96585845947266, "val_acc": 60.0}
{"epoch": 22, "training_loss": 131.55211181640624, "training_acc": 25.0, "val_loss": 45.41521453857422, "val_acc": 60.0}
{"epoch": 23, "training_loss": 56.04023897647858, "training_acc": 45.0, "val_loss": 111.0344009399414, "val_acc": 40.0}
{"epoch": 24, "training_loss": 82.31199493408204, "training_acc": 55.0, "val_loss": 6.475653171539307, "val_acc": 60.0}
{"epoch": 25, "training_loss": 14.96236572265625, "training_acc": 35.0, "val_loss": 71.7619857788086, "val_acc": 60.0}
{"epoch": 26, "training_loss": 99.1336181640625, "training_acc": 45.0, "val_loss": 54.67232131958008, "val_acc": 40.0}
{"epoch": 27, "training_loss": 48.03893127441406, "training_acc": 55.0, "val_loss": 31.09333610534668, "val_acc": 40.0}
{"epoch": 28, "training_loss": 40.47221374511719, "training_acc": 55.0, "val_loss": 116.05205535888672, "val_acc": 60.0}
{"epoch": 29, "training_loss": 140.8936309814453, "training_acc": 45.0, "val_loss": 139.48411560058594, "val_acc": 40.0}
{"epoch": 30, "training_loss": 117.68087158203124, "training_acc": 55.0, "val_loss": 183.9138641357422, "val_acc": 40.0}
{"epoch": 31, "training_loss": 104.9772216796875, "training_acc": 55.0, "val_loss": 156.6351776123047, "val_acc": 60.0}
{"epoch": 32, "training_loss": 235.19373779296876, "training_acc": 45.0, "val_loss": 240.4523162841797, "val_acc": 60.0}
{"epoch": 33, "training_loss": 306.2172424316406, "training_acc": 45.0, "val_loss": 17.015134811401367, "val_acc": 40.0}
{"epoch": 34, "training_loss": 11.110130310058594, "training_acc": 55.0, "val_loss": 175.1605987548828, "val_acc": 40.0}
{"epoch": 35, "training_loss": 124.33480834960938, "training_acc": 55.0, "val_loss": 30.7844295501709, "val_acc": 60.0}
{"epoch": 36, "training_loss": 65.1323974609375, "training_acc": 45.0, "val_loss": 50.66505432128906, "val_acc": 40.0}
{"epoch": 37, "training_loss": 44.059190368652345, "training_acc": 55.0, "val_loss": 26.922269821166992, "val_acc": 40.0}
{"epoch": 38, "training_loss": 75.52755889892578, "training_acc": 35.0, "val_loss": 78.32630920410156, "val_acc": 60.0}
{"epoch": 39, "training_loss": 97.27191314697265, "training_acc": 45.0, "val_loss": 112.35509490966797, "val_acc": 40.0}
{"epoch": 40, "training_loss": 71.36883087158203, "training_acc": 55.0, "val_loss": 99.1232681274414, "val_acc": 60.0}
{"epoch": 41, "training_loss": 153.43071899414062, "training_acc": 45.0, "val_loss": 80.94478607177734, "val_acc": 60.0}
{"epoch": 42, "training_loss": 106.26575622558593, "training_acc": 45.0, "val_loss": 190.07151794433594, "val_acc": 40.0}
{"epoch": 43, "training_loss": 140.59906005859375, "training_acc": 55.0, "val_loss": 89.95169830322266, "val_acc": 40.0}
