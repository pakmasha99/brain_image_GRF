"main_modify.py --pretrained_path None --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 1 --task ADNI_sex --input_option yAware --learning_rate 1e1 --batch_size 8 --weight_decay 5e-4 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 1128.8569874048233, "training_acc": 50.0, "val_loss": 817.1150512695312, "val_acc": 60.0}
{"epoch": 1, "training_loss": 1587.2726196289063, "training_acc": 50.0, "val_loss": 568.9093017578125, "val_acc": 60.0}
{"epoch": 2, "training_loss": 584.7964965820313, "training_acc": 60.0, "val_loss": 1238.6519775390625, "val_acc": 40.0}
{"epoch": 3, "training_loss": 858.4971725463868, "training_acc": 30.0, "val_loss": 70.02083587646484, "val_acc": 60.0}
{"epoch": 4, "training_loss": 64.72438049316406, "training_acc": 50.0, "val_loss": 270.4257507324219, "val_acc": 40.0}
{"epoch": 5, "training_loss": 211.1479522705078, "training_acc": 40.0, "val_loss": 14.44983196258545, "val_acc": 60.0}
{"epoch": 6, "training_loss": 198.22573013305663, "training_acc": 50.0, "val_loss": 175.5385284423828, "val_acc": 40.0}
{"epoch": 7, "training_loss": 314.1564514160156, "training_acc": 40.0, "val_loss": 309.12457275390625, "val_acc": 60.0}
{"epoch": 8, "training_loss": 265.475341796875, "training_acc": 50.0, "val_loss": 584.3280639648438, "val_acc": 40.0}
{"epoch": 9, "training_loss": 397.1534118652344, "training_acc": 50.0, "val_loss": 160.4624481201172, "val_acc": 60.0}
{"epoch": 10, "training_loss": 241.50694580078124, "training_acc": 50.0, "val_loss": 95.32244873046875, "val_acc": 60.0}
{"epoch": 11, "training_loss": 139.7253677368164, "training_acc": 50.0, "val_loss": 77.13909149169922, "val_acc": 40.0}
{"epoch": 12, "training_loss": 223.07233276367188, "training_acc": 40.0, "val_loss": 130.03294372558594, "val_acc": 60.0}
{"epoch": 13, "training_loss": 111.89520721435547, "training_acc": 60.0, "val_loss": 151.77932739257812, "val_acc": 40.0}
{"epoch": 14, "training_loss": 31.31574363708496, "training_acc": 60.0, "val_loss": 211.56631469726562, "val_acc": 60.0}
{"epoch": 15, "training_loss": 302.0119201660156, "training_acc": 50.0, "val_loss": 153.23080444335938, "val_acc": 40.0}
{"epoch": 16, "training_loss": 220.3553466796875, "training_acc": 50.0, "val_loss": 91.265869140625, "val_acc": 60.0}
{"epoch": 17, "training_loss": 127.87507019042968, "training_acc": 50.0, "val_loss": 221.4910430908203, "val_acc": 40.0}
{"epoch": 18, "training_loss": 223.67479858398437, "training_acc": 50.0, "val_loss": 165.3655548095703, "val_acc": 60.0}
{"epoch": 19, "training_loss": 247.16931762695313, "training_acc": 50.0, "val_loss": 10.593398094177246, "val_acc": 60.0}
{"epoch": 20, "training_loss": 313.5239646911621, "training_acc": 50.0, "val_loss": 645.1597900390625, "val_acc": 40.0}
{"epoch": 21, "training_loss": 356.15264892578125, "training_acc": 50.0, "val_loss": 315.106689453125, "val_acc": 60.0}
{"epoch": 22, "training_loss": 377.0257629394531, "training_acc": 50.0, "val_loss": 199.7025146484375, "val_acc": 40.0}
{"epoch": 23, "training_loss": 177.698876953125, "training_acc": 50.0, "val_loss": 56.76554489135742, "val_acc": 60.0}
{"epoch": 24, "training_loss": 81.60429382324219, "training_acc": 50.0, "val_loss": 57.38356399536133, "val_acc": 40.0}
{"epoch": 25, "training_loss": 83.48459167480469, "training_acc": 60.0, "val_loss": 43.6387825012207, "val_acc": 40.0}
{"epoch": 26, "training_loss": 60.145131301879886, "training_acc": 50.0, "val_loss": 181.55979919433594, "val_acc": 60.0}
{"epoch": 27, "training_loss": 140.47248001098632, "training_acc": 30.0, "val_loss": 196.96051025390625, "val_acc": 40.0}
{"epoch": 28, "training_loss": 170.91128540039062, "training_acc": 40.0, "val_loss": 9.978377342224121, "val_acc": 40.0}
{"epoch": 29, "training_loss": 69.3034688949585, "training_acc": 50.0, "val_loss": 65.3698501586914, "val_acc": 60.0}
{"epoch": 30, "training_loss": 80.76366748809815, "training_acc": 50.0, "val_loss": 139.97654724121094, "val_acc": 40.0}
{"epoch": 31, "training_loss": 119.58227233886718, "training_acc": 50.0, "val_loss": 52.79987716674805, "val_acc": 40.0}
{"epoch": 32, "training_loss": 64.17823791503906, "training_acc": 50.0, "val_loss": 175.41567993164062, "val_acc": 60.0}
{"epoch": 33, "training_loss": 216.25560607910157, "training_acc": 40.0, "val_loss": 553.9412841796875, "val_acc": 40.0}
{"epoch": 34, "training_loss": 326.1375644683838, "training_acc": 50.0, "val_loss": 350.2488708496094, "val_acc": 60.0}
{"epoch": 35, "training_loss": 529.0283569335937, "training_acc": 50.0, "val_loss": 358.7268981933594, "val_acc": 60.0}
{"epoch": 36, "training_loss": 195.7709762573242, "training_acc": 70.0, "val_loss": 862.0441284179688, "val_acc": 40.0}
{"epoch": 37, "training_loss": 792.8317993164062, "training_acc": 50.0, "val_loss": 647.5017700195312, "val_acc": 40.0}
{"epoch": 38, "training_loss": 263.5039489746094, "training_acc": 60.0, "val_loss": 619.7677612304688, "val_acc": 60.0}
{"epoch": 39, "training_loss": 850.7814697265625, "training_acc": 50.0, "val_loss": 482.0184631347656, "val_acc": 60.0}
{"epoch": 40, "training_loss": 281.55785217285154, "training_acc": 60.0, "val_loss": 812.6769409179688, "val_acc": 40.0}
{"epoch": 41, "training_loss": 766.4612548828125, "training_acc": 50.0, "val_loss": 612.252197265625, "val_acc": 40.0}
{"epoch": 42, "training_loss": 235.16242065429688, "training_acc": 60.0, "val_loss": 750.7211303710938, "val_acc": 60.0}
{"epoch": 43, "training_loss": 1092.2721923828126, "training_acc": 50.0, "val_loss": 711.2435913085938, "val_acc": 60.0}
{"epoch": 44, "training_loss": 798.6143676757813, "training_acc": 30.0, "val_loss": 592.0611572265625, "val_acc": 40.0}
{"epoch": 45, "training_loss": 454.2098907470703, "training_acc": 50.0, "val_loss": 107.20757293701172, "val_acc": 60.0}
{"epoch": 46, "training_loss": 154.64821166992186, "training_acc": 30.0, "val_loss": 139.66067504882812, "val_acc": 60.0}
{"epoch": 47, "training_loss": 142.91286582946776, "training_acc": 50.0, "val_loss": 5.37275505065918, "val_acc": 60.0}
{"epoch": 48, "training_loss": 95.70169792175292, "training_acc": 50.0, "val_loss": 79.42925262451172, "val_acc": 60.0}
{"epoch": 49, "training_loss": 91.47754364013672, "training_acc": 50.0, "val_loss": 103.76554107666016, "val_acc": 40.0}
{"epoch": 50, "training_loss": 89.07293701171875, "training_acc": 60.0, "val_loss": 105.58100891113281, "val_acc": 40.0}
{"epoch": 51, "training_loss": 83.86383056640625, "training_acc": 50.0, "val_loss": 59.857643127441406, "val_acc": 60.0}
{"epoch": 52, "training_loss": 73.37800445556641, "training_acc": 60.0, "val_loss": 39.602691650390625, "val_acc": 60.0}
{"epoch": 53, "training_loss": 91.15960159301758, "training_acc": 50.0, "val_loss": 327.11871337890625, "val_acc": 40.0}
{"epoch": 54, "training_loss": 247.66055297851562, "training_acc": 40.0, "val_loss": 241.1393280029297, "val_acc": 60.0}
{"epoch": 55, "training_loss": 265.1693542480469, "training_acc": 40.0, "val_loss": 355.83953857421875, "val_acc": 40.0}
{"epoch": 56, "training_loss": 213.5330810546875, "training_acc": 50.0, "val_loss": 228.9831085205078, "val_acc": 60.0}
{"epoch": 57, "training_loss": 208.93014221191407, "training_acc": 50.0, "val_loss": 214.6332244873047, "val_acc": 40.0}
{"epoch": 58, "training_loss": 106.49835052490235, "training_acc": 40.0, "val_loss": 44.04270935058594, "val_acc": 60.0}
{"epoch": 59, "training_loss": 21.823445892333986, "training_acc": 70.0, "val_loss": 381.0918273925781, "val_acc": 40.0}
{"epoch": 60, "training_loss": 266.62855224609376, "training_acc": 40.0, "val_loss": 33.33613204956055, "val_acc": 60.0}
{"epoch": 61, "training_loss": 83.1727066040039, "training_acc": 60.0, "val_loss": 27.95256996154785, "val_acc": 60.0}
{"epoch": 62, "training_loss": 58.691189765930176, "training_acc": 50.0, "val_loss": 262.505859375, "val_acc": 40.0}
{"epoch": 63, "training_loss": 138.1206802368164, "training_acc": 30.0, "val_loss": 144.0848388671875, "val_acc": 60.0}
{"epoch": 64, "training_loss": 176.4790069580078, "training_acc": 40.0, "val_loss": 59.73187255859375, "val_acc": 40.0}
{"epoch": 65, "training_loss": 245.27403564453124, "training_acc": 40.0, "val_loss": 129.3868408203125, "val_acc": 60.0}
{"epoch": 66, "training_loss": 133.89333801269532, "training_acc": 60.0, "val_loss": 334.8328552246094, "val_acc": 40.0}
