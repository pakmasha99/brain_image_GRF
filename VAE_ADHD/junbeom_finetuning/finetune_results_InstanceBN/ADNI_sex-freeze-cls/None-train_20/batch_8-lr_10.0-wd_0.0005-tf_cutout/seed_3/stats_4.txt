"main_modify.py --pretrained_path None --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 3 --task ADNI_sex --input_option yAware --learning_rate 1e1 --batch_size 8 --weight_decay 5e-4 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 1089.4876685619354, "training_acc": 45.0, "val_loss": 1143.659423828125, "val_acc": 40.0}
{"epoch": 1, "training_loss": 1372.4371826171875, "training_acc": 55.0, "val_loss": 1762.2645263671875, "val_acc": 40.0}
{"epoch": 2, "training_loss": 815.3599899291992, "training_acc": 65.0, "val_loss": 531.3140869140625, "val_acc": 60.0}
{"epoch": 3, "training_loss": 723.7044250488282, "training_acc": 45.0, "val_loss": 205.7975616455078, "val_acc": 40.0}
{"epoch": 4, "training_loss": 408.9975219726563, "training_acc": 55.0, "val_loss": 235.2228546142578, "val_acc": 40.0}
{"epoch": 5, "training_loss": 260.4969177246094, "training_acc": 55.0, "val_loss": 253.6054229736328, "val_acc": 60.0}
{"epoch": 6, "training_loss": 226.5808120727539, "training_acc": 45.0, "val_loss": 123.4036636352539, "val_acc": 40.0}
{"epoch": 7, "training_loss": 52.094512367248534, "training_acc": 55.0, "val_loss": 195.7587890625, "val_acc": 60.0}
{"epoch": 8, "training_loss": 260.3688232421875, "training_acc": 35.0, "val_loss": 168.1287078857422, "val_acc": 40.0}
{"epoch": 9, "training_loss": 62.47166666984558, "training_acc": 60.0, "val_loss": 222.17051696777344, "val_acc": 40.0}
{"epoch": 10, "training_loss": 102.79880542755127, "training_acc": 65.0, "val_loss": 42.064605712890625, "val_acc": 60.0}
{"epoch": 11, "training_loss": 139.63668365478514, "training_acc": 55.0, "val_loss": 51.168025970458984, "val_acc": 60.0}
{"epoch": 12, "training_loss": 155.15093994140625, "training_acc": 25.0, "val_loss": 111.5130615234375, "val_acc": 40.0}
{"epoch": 13, "training_loss": 158.6193603515625, "training_acc": 55.0, "val_loss": 86.97561645507812, "val_acc": 60.0}
{"epoch": 14, "training_loss": 247.90562133789064, "training_acc": 45.0, "val_loss": 417.284912109375, "val_acc": 40.0}
{"epoch": 15, "training_loss": 164.63164215087892, "training_acc": 65.0, "val_loss": 346.48101806640625, "val_acc": 60.0}
{"epoch": 16, "training_loss": 401.15673828125, "training_acc": 45.0, "val_loss": 354.81646728515625, "val_acc": 40.0}
{"epoch": 17, "training_loss": 388.608642578125, "training_acc": 55.0, "val_loss": 571.2318725585938, "val_acc": 40.0}
{"epoch": 18, "training_loss": 339.9274536132813, "training_acc": 45.0, "val_loss": 190.13572692871094, "val_acc": 60.0}
{"epoch": 19, "training_loss": 122.59583129882813, "training_acc": 65.0, "val_loss": 530.4064331054688, "val_acc": 40.0}
{"epoch": 20, "training_loss": 368.89769287109374, "training_acc": 55.0, "val_loss": 22.11842155456543, "val_acc": 60.0}
{"epoch": 21, "training_loss": 66.59177703857422, "training_acc": 35.0, "val_loss": 95.93791961669922, "val_acc": 60.0}
{"epoch": 22, "training_loss": 134.3461135864258, "training_acc": 55.0, "val_loss": 9.131722450256348, "val_acc": 40.0}
{"epoch": 23, "training_loss": 314.18968467712403, "training_acc": 45.0, "val_loss": 288.1357116699219, "val_acc": 60.0}
{"epoch": 24, "training_loss": 228.81907320022583, "training_acc": 60.0, "val_loss": 723.3594970703125, "val_acc": 40.0}
{"epoch": 25, "training_loss": 506.8172973632812, "training_acc": 55.0, "val_loss": 32.10871887207031, "val_acc": 40.0}
{"epoch": 26, "training_loss": 310.05288925170896, "training_acc": 55.0, "val_loss": 589.01708984375, "val_acc": 60.0}
{"epoch": 27, "training_loss": 648.8255744934082, "training_acc": 45.0, "val_loss": 459.7989196777344, "val_acc": 40.0}
{"epoch": 28, "training_loss": 549.9347412109375, "training_acc": 55.0, "val_loss": 675.8609619140625, "val_acc": 40.0}
{"epoch": 29, "training_loss": 295.7407287597656, "training_acc": 55.0, "val_loss": 422.5081481933594, "val_acc": 60.0}
{"epoch": 30, "training_loss": 557.8119262695312, "training_acc": 45.0, "val_loss": 90.71835327148438, "val_acc": 40.0}
{"epoch": 31, "training_loss": 194.73093872070314, "training_acc": 55.0, "val_loss": 75.6374740600586, "val_acc": 40.0}
{"epoch": 32, "training_loss": 197.14864654541014, "training_acc": 55.0, "val_loss": 232.72879028320312, "val_acc": 60.0}
{"epoch": 33, "training_loss": 356.54944763183596, "training_acc": 25.0, "val_loss": 14.167929649353027, "val_acc": 40.0}
{"epoch": 34, "training_loss": 226.46973457336426, "training_acc": 65.0, "val_loss": 324.59271240234375, "val_acc": 60.0}
{"epoch": 35, "training_loss": 297.6005798339844, "training_acc": 45.0, "val_loss": 867.14599609375, "val_acc": 40.0}
{"epoch": 36, "training_loss": 732.1146240234375, "training_acc": 55.0, "val_loss": 516.5792846679688, "val_acc": 40.0}
{"epoch": 37, "training_loss": 288.9513793945313, "training_acc": 45.0, "val_loss": 268.3865661621094, "val_acc": 60.0}
{"epoch": 38, "training_loss": 174.3789489746094, "training_acc": 65.0, "val_loss": 597.2011108398438, "val_acc": 40.0}
{"epoch": 39, "training_loss": 435.2609436035156, "training_acc": 55.0, "val_loss": 164.76968383789062, "val_acc": 40.0}
{"epoch": 40, "training_loss": 235.3319580078125, "training_acc": 55.0, "val_loss": 304.3207092285156, "val_acc": 60.0}
{"epoch": 41, "training_loss": 232.67149047851564, "training_acc": 55.0, "val_loss": 722.8634033203125, "val_acc": 40.0}
