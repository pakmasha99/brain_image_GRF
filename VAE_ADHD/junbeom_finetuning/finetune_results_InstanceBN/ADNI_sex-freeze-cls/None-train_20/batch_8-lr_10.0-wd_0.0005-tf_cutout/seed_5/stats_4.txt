"main_modify.py --pretrained_path None --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 5 --task ADNI_sex --input_option yAware --learning_rate 1e1 --batch_size 8 --weight_decay 5e-4 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 1018.4893956899643, "training_acc": 50.0, "val_loss": 1039.1214599609375, "val_acc": 40.0}
{"epoch": 1, "training_loss": 940.6804992675782, "training_acc": 50.0, "val_loss": 172.42263793945312, "val_acc": 40.0}
{"epoch": 2, "training_loss": 766.9938171386718, "training_acc": 40.0, "val_loss": 823.7810668945312, "val_acc": 60.0}
{"epoch": 3, "training_loss": 841.7627868652344, "training_acc": 40.0, "val_loss": 651.3453979492188, "val_acc": 40.0}
{"epoch": 4, "training_loss": 475.614599609375, "training_acc": 50.0, "val_loss": 244.49063110351562, "val_acc": 60.0}
{"epoch": 5, "training_loss": 336.50001220703126, "training_acc": 50.0, "val_loss": 101.48567962646484, "val_acc": 60.0}
{"epoch": 6, "training_loss": 175.25609436035157, "training_acc": 60.0, "val_loss": 302.2677307128906, "val_acc": 40.0}
{"epoch": 7, "training_loss": 221.04765625, "training_acc": 40.0, "val_loss": 6.03444766998291, "val_acc": 60.0}
{"epoch": 8, "training_loss": 413.65988998413087, "training_acc": 30.0, "val_loss": 517.6175537109375, "val_acc": 40.0}
{"epoch": 9, "training_loss": 270.9111389160156, "training_acc": 50.0, "val_loss": 547.6864624023438, "val_acc": 60.0}
{"epoch": 10, "training_loss": 716.4900024414062, "training_acc": 50.0, "val_loss": 205.44371032714844, "val_acc": 60.0}
{"epoch": 11, "training_loss": 353.78667602539065, "training_acc": 50.0, "val_loss": 673.1998291015625, "val_acc": 40.0}
{"epoch": 12, "training_loss": 440.15021362304685, "training_acc": 40.0, "val_loss": 184.97105407714844, "val_acc": 60.0}
{"epoch": 13, "training_loss": 158.753178024292, "training_acc": 60.0, "val_loss": 206.03848266601562, "val_acc": 40.0}
{"epoch": 14, "training_loss": 182.24476318359376, "training_acc": 40.0, "val_loss": 196.48550415039062, "val_acc": 60.0}
{"epoch": 15, "training_loss": 126.94717472195626, "training_acc": 50.0, "val_loss": 5.043047904968262, "val_acc": 40.0}
{"epoch": 16, "training_loss": 169.0870788574219, "training_acc": 40.0, "val_loss": 24.903982162475586, "val_acc": 40.0}
{"epoch": 17, "training_loss": 68.95522842407226, "training_acc": 30.0, "val_loss": 305.2969665527344, "val_acc": 40.0}
{"epoch": 18, "training_loss": 186.51092529296875, "training_acc": 50.0, "val_loss": 285.99200439453125, "val_acc": 60.0}
{"epoch": 19, "training_loss": 290.82186431884764, "training_acc": 40.0, "val_loss": 63.05868148803711, "val_acc": 40.0}
{"epoch": 20, "training_loss": 94.45559844970703, "training_acc": 50.0, "val_loss": 106.28524017333984, "val_acc": 40.0}
{"epoch": 21, "training_loss": 45.925491428375246, "training_acc": 65.0, "val_loss": 32.28449249267578, "val_acc": 40.0}
{"epoch": 22, "training_loss": 104.24328079223633, "training_acc": 50.0, "val_loss": 131.07571411132812, "val_acc": 40.0}
{"epoch": 23, "training_loss": 91.44394226074219, "training_acc": 50.0, "val_loss": 8.868637084960938, "val_acc": 40.0}
{"epoch": 24, "training_loss": 57.94411964416504, "training_acc": 50.0, "val_loss": 266.68878173828125, "val_acc": 40.0}
{"epoch": 25, "training_loss": 247.81904296875, "training_acc": 50.0, "val_loss": 167.44058227539062, "val_acc": 60.0}
{"epoch": 26, "training_loss": 172.92806243896484, "training_acc": 50.0, "val_loss": 398.0827941894531, "val_acc": 40.0}
{"epoch": 27, "training_loss": 390.28748779296876, "training_acc": 50.0, "val_loss": 252.88003540039062, "val_acc": 40.0}
{"epoch": 28, "training_loss": 141.51177062988282, "training_acc": 60.0, "val_loss": 206.9983367919922, "val_acc": 60.0}
{"epoch": 29, "training_loss": 252.78741073608398, "training_acc": 40.0, "val_loss": 555.653564453125, "val_acc": 40.0}
{"epoch": 30, "training_loss": 358.9543930053711, "training_acc": 40.0, "val_loss": 45.08292770385742, "val_acc": 60.0}
{"epoch": 31, "training_loss": 184.01109924316407, "training_acc": 30.0, "val_loss": 73.8526382446289, "val_acc": 60.0}
{"epoch": 32, "training_loss": 164.43330078125, "training_acc": 30.0, "val_loss": 2.517913579940796, "val_acc": 40.0}
{"epoch": 33, "training_loss": 128.95255262851714, "training_acc": 70.0, "val_loss": 163.8359832763672, "val_acc": 60.0}
{"epoch": 34, "training_loss": 201.94602661132814, "training_acc": 50.0, "val_loss": 157.3355712890625, "val_acc": 40.0}
{"epoch": 35, "training_loss": 185.96570434570313, "training_acc": 50.0, "val_loss": 152.6784210205078, "val_acc": 60.0}
{"epoch": 36, "training_loss": 193.82238006591797, "training_acc": 50.0, "val_loss": 12.758147239685059, "val_acc": 40.0}
{"epoch": 37, "training_loss": 251.3763870239258, "training_acc": 50.0, "val_loss": 429.03570556640625, "val_acc": 60.0}
{"epoch": 38, "training_loss": 472.63798828125, "training_acc": 30.0, "val_loss": 166.35134887695312, "val_acc": 40.0}
{"epoch": 39, "training_loss": 118.81630249023438, "training_acc": 40.0, "val_loss": 205.5561981201172, "val_acc": 40.0}
{"epoch": 40, "training_loss": 170.92156677246095, "training_acc": 40.0, "val_loss": 38.01738357543945, "val_acc": 40.0}
{"epoch": 41, "training_loss": 88.53211975097656, "training_acc": 40.0, "val_loss": 262.7399597167969, "val_acc": 40.0}
{"epoch": 42, "training_loss": 175.58775329589844, "training_acc": 50.0, "val_loss": 212.06382751464844, "val_acc": 60.0}
{"epoch": 43, "training_loss": 269.07133331298826, "training_acc": 50.0, "val_loss": 11.443343162536621, "val_acc": 60.0}
{"epoch": 44, "training_loss": 160.20128173828124, "training_acc": 60.0, "val_loss": 447.337158203125, "val_acc": 40.0}
{"epoch": 45, "training_loss": 256.8763732910156, "training_acc": 50.0, "val_loss": 273.3559265136719, "val_acc": 60.0}
{"epoch": 46, "training_loss": 254.95543899536133, "training_acc": 50.0, "val_loss": 443.26708984375, "val_acc": 40.0}
{"epoch": 47, "training_loss": 530.4362548828125, "training_acc": 50.0, "val_loss": 399.0852966308594, "val_acc": 40.0}
{"epoch": 48, "training_loss": 170.0193115234375, "training_acc": 60.0, "val_loss": 211.8207550048828, "val_acc": 60.0}
{"epoch": 49, "training_loss": 240.90720825195314, "training_acc": 40.0, "val_loss": 505.2658386230469, "val_acc": 40.0}
{"epoch": 50, "training_loss": 277.2474624633789, "training_acc": 50.0, "val_loss": 358.5501403808594, "val_acc": 60.0}
{"epoch": 51, "training_loss": 674.6033935546875, "training_acc": 50.0, "val_loss": 521.7738647460938, "val_acc": 60.0}
