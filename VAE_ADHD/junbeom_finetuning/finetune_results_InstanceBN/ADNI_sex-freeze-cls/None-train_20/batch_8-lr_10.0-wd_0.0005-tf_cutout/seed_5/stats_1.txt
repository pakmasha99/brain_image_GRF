"main_modify.py --pretrained_path None --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 5 --task ADNI_sex --input_option yAware --learning_rate 1e1 --batch_size 8 --weight_decay 5e-4 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 1326.4061403274536, "training_acc": 45.0, "val_loss": 1021.2844848632812, "val_acc": 40.0}
{"epoch": 1, "training_loss": 1891.2619567871093, "training_acc": 55.0, "val_loss": 2333.871826171875, "val_acc": 40.0}
{"epoch": 2, "training_loss": 1323.9286849975585, "training_acc": 55.0, "val_loss": 658.0990600585938, "val_acc": 60.0}
{"epoch": 3, "training_loss": 1572.1836547851562, "training_acc": 45.0, "val_loss": 1173.330078125, "val_acc": 60.0}
{"epoch": 4, "training_loss": 1149.4106689453124, "training_acc": 45.0, "val_loss": 435.23785400390625, "val_acc": 40.0}
{"epoch": 5, "training_loss": 851.821142578125, "training_acc": 55.0, "val_loss": 1641.470703125, "val_acc": 40.0}
{"epoch": 6, "training_loss": 1070.6662841796874, "training_acc": 55.0, "val_loss": 397.7012634277344, "val_acc": 40.0}
{"epoch": 7, "training_loss": 345.9705017089844, "training_acc": 55.0, "val_loss": 588.25830078125, "val_acc": 60.0}
{"epoch": 8, "training_loss": 624.8670166015625, "training_acc": 45.0, "val_loss": 436.74395751953125, "val_acc": 40.0}
{"epoch": 9, "training_loss": 510.6894287109375, "training_acc": 55.0, "val_loss": 732.2417602539062, "val_acc": 40.0}
{"epoch": 10, "training_loss": 339.21441040039065, "training_acc": 55.0, "val_loss": 350.2989196777344, "val_acc": 60.0}
{"epoch": 11, "training_loss": 455.105810546875, "training_acc": 45.0, "val_loss": 308.1160583496094, "val_acc": 40.0}
{"epoch": 12, "training_loss": 268.52222900390626, "training_acc": 55.0, "val_loss": 15.341351509094238, "val_acc": 60.0}
{"epoch": 13, "training_loss": 84.61809921264648, "training_acc": 35.0, "val_loss": 229.3291015625, "val_acc": 60.0}
{"epoch": 14, "training_loss": 331.97939453125, "training_acc": 45.0, "val_loss": 119.84840393066406, "val_acc": 40.0}
{"epoch": 15, "training_loss": 249.2271759033203, "training_acc": 55.0, "val_loss": 91.0344467163086, "val_acc": 40.0}
{"epoch": 16, "training_loss": 213.14884185791016, "training_acc": 55.0, "val_loss": 246.8908233642578, "val_acc": 60.0}
{"epoch": 17, "training_loss": 170.59155960083007, "training_acc": 45.0, "val_loss": 16.11414337158203, "val_acc": 40.0}
{"epoch": 18, "training_loss": 164.04437255859375, "training_acc": 45.0, "val_loss": 14.08800983428955, "val_acc": 40.0}
{"epoch": 19, "training_loss": 97.41701889038086, "training_acc": 45.0, "val_loss": 19.051977157592773, "val_acc": 40.0}
{"epoch": 20, "training_loss": 61.26673927307129, "training_acc": 45.0, "val_loss": 26.980640411376953, "val_acc": 40.0}
{"epoch": 21, "training_loss": 156.69229431152343, "training_acc": 45.0, "val_loss": 20.23770523071289, "val_acc": 40.0}
{"epoch": 22, "training_loss": 37.95758399963379, "training_acc": 65.0, "val_loss": 95.93707275390625, "val_acc": 60.0}
{"epoch": 23, "training_loss": 169.1266326904297, "training_acc": 35.0, "val_loss": 59.53228759765625, "val_acc": 60.0}
{"epoch": 24, "training_loss": 114.77044372558593, "training_acc": 25.0, "val_loss": 6.555641174316406, "val_acc": 60.0}
{"epoch": 25, "training_loss": 18.438489627838134, "training_acc": 85.0, "val_loss": 97.5871810913086, "val_acc": 40.0}
{"epoch": 26, "training_loss": 29.05654067993164, "training_acc": 65.0, "val_loss": 93.19746398925781, "val_acc": 60.0}
{"epoch": 27, "training_loss": 159.68203353881836, "training_acc": 35.0, "val_loss": 414.2187194824219, "val_acc": 40.0}
{"epoch": 28, "training_loss": 210.38255310058594, "training_acc": 55.0, "val_loss": 143.69752502441406, "val_acc": 60.0}
{"epoch": 29, "training_loss": 211.1610595703125, "training_acc": 35.0, "val_loss": 453.8434753417969, "val_acc": 40.0}
{"epoch": 30, "training_loss": 268.6820404052734, "training_acc": 45.0, "val_loss": 45.435333251953125, "val_acc": 60.0}
{"epoch": 31, "training_loss": 141.44077758789064, "training_acc": 45.0, "val_loss": 28.117521286010742, "val_acc": 40.0}
{"epoch": 32, "training_loss": 215.65430221557617, "training_acc": 55.0, "val_loss": 186.95172119140625, "val_acc": 60.0}
{"epoch": 33, "training_loss": 166.36542358398438, "training_acc": 55.0, "val_loss": 315.74755859375, "val_acc": 40.0}
{"epoch": 34, "training_loss": 221.04832153320314, "training_acc": 45.0, "val_loss": 251.12271118164062, "val_acc": 60.0}
{"epoch": 35, "training_loss": 206.84842529296876, "training_acc": 55.0, "val_loss": 459.8053894042969, "val_acc": 40.0}
{"epoch": 36, "training_loss": 296.13722534179686, "training_acc": 55.0, "val_loss": 106.60967254638672, "val_acc": 60.0}
{"epoch": 37, "training_loss": 228.6750518798828, "training_acc": 45.0, "val_loss": 285.1172790527344, "val_acc": 40.0}
{"epoch": 38, "training_loss": 309.2031555175781, "training_acc": 55.0, "val_loss": 233.2775115966797, "val_acc": 40.0}
{"epoch": 39, "training_loss": 178.10836791992188, "training_acc": 55.0, "val_loss": 207.4024658203125, "val_acc": 60.0}
{"epoch": 40, "training_loss": 204.68045043945312, "training_acc": 45.0, "val_loss": 658.8640747070312, "val_acc": 40.0}
{"epoch": 41, "training_loss": 449.06884765625, "training_acc": 55.0, "val_loss": 13.350607872009277, "val_acc": 40.0}
{"epoch": 42, "training_loss": 407.63775100708006, "training_acc": 45.0, "val_loss": 671.1068115234375, "val_acc": 60.0}
{"epoch": 43, "training_loss": 727.082421875, "training_acc": 45.0, "val_loss": 252.1215057373047, "val_acc": 40.0}
