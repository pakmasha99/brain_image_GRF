"main_modify.py --pretrained_path None --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 2 --task ADNI_sex --input_option yAware --learning_rate 1e1 --batch_size 8 --weight_decay 5e-4 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 976.1174214363098, "training_acc": 50.0, "val_loss": 970.2738647460938, "val_acc": 60.0}
{"epoch": 1, "training_loss": 1316.562109375, "training_acc": 50.0, "val_loss": 512.0560913085938, "val_acc": 60.0}
{"epoch": 2, "training_loss": 726.185009765625, "training_acc": 40.0, "val_loss": 847.6668090820312, "val_acc": 40.0}
{"epoch": 3, "training_loss": 533.1045166015625, "training_acc": 40.0, "val_loss": 463.7099609375, "val_acc": 60.0}
{"epoch": 4, "training_loss": 445.03210601806643, "training_acc": 50.0, "val_loss": 480.2071228027344, "val_acc": 40.0}
{"epoch": 5, "training_loss": 587.6541748046875, "training_acc": 50.0, "val_loss": 442.917236328125, "val_acc": 40.0}
{"epoch": 6, "training_loss": 306.01212921142576, "training_acc": 40.0, "val_loss": 701.2758178710938, "val_acc": 60.0}
{"epoch": 7, "training_loss": 833.7641357421875, "training_acc": 50.0, "val_loss": 208.9096221923828, "val_acc": 60.0}
{"epoch": 8, "training_loss": 537.9609497070312, "training_acc": 40.0, "val_loss": 838.7125244140625, "val_acc": 40.0}
{"epoch": 9, "training_loss": 464.80588684082034, "training_acc": 50.0, "val_loss": 368.5611267089844, "val_acc": 60.0}
{"epoch": 10, "training_loss": 578.8165405273437, "training_acc": 50.0, "val_loss": 656.0275268554688, "val_acc": 60.0}
{"epoch": 11, "training_loss": 595.5999267578125, "training_acc": 50.0, "val_loss": 306.99053955078125, "val_acc": 40.0}
{"epoch": 12, "training_loss": 512.6980834960938, "training_acc": 50.0, "val_loss": 874.6636962890625, "val_acc": 40.0}
{"epoch": 13, "training_loss": 516.8299530029296, "training_acc": 50.0, "val_loss": 140.90008544921875, "val_acc": 60.0}
{"epoch": 14, "training_loss": 176.08761291503907, "training_acc": 40.0, "val_loss": 143.0809783935547, "val_acc": 40.0}
{"epoch": 15, "training_loss": 66.31797790527344, "training_acc": 60.0, "val_loss": 86.80067443847656, "val_acc": 40.0}
{"epoch": 16, "training_loss": 54.33516998291016, "training_acc": 60.0, "val_loss": 242.48452758789062, "val_acc": 60.0}
{"epoch": 17, "training_loss": 327.5086608886719, "training_acc": 30.0, "val_loss": 235.3437042236328, "val_acc": 40.0}
{"epoch": 18, "training_loss": 164.63670654296874, "training_acc": 40.0, "val_loss": 69.01949310302734, "val_acc": 40.0}
{"epoch": 19, "training_loss": 68.0112091064453, "training_acc": 40.0, "val_loss": 106.3580322265625, "val_acc": 40.0}
{"epoch": 20, "training_loss": 58.551020812988284, "training_acc": 70.0, "val_loss": 115.30645751953125, "val_acc": 40.0}
{"epoch": 21, "training_loss": 89.18675384521484, "training_acc": 50.0, "val_loss": 76.27303314208984, "val_acc": 60.0}
{"epoch": 22, "training_loss": 262.9686584472656, "training_acc": 30.0, "val_loss": 9.725669860839844, "val_acc": 40.0}
{"epoch": 23, "training_loss": 312.5088115692139, "training_acc": 50.0, "val_loss": 536.9540405273438, "val_acc": 60.0}
{"epoch": 24, "training_loss": 485.12403564453126, "training_acc": 50.0, "val_loss": 394.9247131347656, "val_acc": 40.0}
{"epoch": 25, "training_loss": 467.74034423828124, "training_acc": 50.0, "val_loss": 721.9799194335938, "val_acc": 40.0}
{"epoch": 26, "training_loss": 502.2549987792969, "training_acc": 30.0, "val_loss": 117.22676086425781, "val_acc": 60.0}
{"epoch": 27, "training_loss": 88.48652572631836, "training_acc": 60.0, "val_loss": 429.84619140625, "val_acc": 40.0}
{"epoch": 28, "training_loss": 289.98702545166014, "training_acc": 40.0, "val_loss": 21.79072380065918, "val_acc": 60.0}
{"epoch": 29, "training_loss": 179.57877502441406, "training_acc": 40.0, "val_loss": 18.67960548400879, "val_acc": 40.0}
{"epoch": 30, "training_loss": 275.7850860595703, "training_acc": 50.0, "val_loss": 433.83056640625, "val_acc": 60.0}
{"epoch": 31, "training_loss": 358.6407745361328, "training_acc": 50.0, "val_loss": 236.0878448486328, "val_acc": 40.0}
{"epoch": 32, "training_loss": 154.26441650390626, "training_acc": 50.0, "val_loss": 85.16979217529297, "val_acc": 60.0}
{"epoch": 33, "training_loss": 43.748793029785155, "training_acc": 60.0, "val_loss": 189.82339477539062, "val_acc": 60.0}
{"epoch": 34, "training_loss": 278.2650421142578, "training_acc": 50.0, "val_loss": 154.9530029296875, "val_acc": 40.0}
{"epoch": 35, "training_loss": 154.8722183227539, "training_acc": 50.0, "val_loss": 154.4430694580078, "val_acc": 60.0}
{"epoch": 36, "training_loss": 327.73919067382815, "training_acc": 50.0, "val_loss": 69.87215423583984, "val_acc": 60.0}
{"epoch": 37, "training_loss": 331.9381927490234, "training_acc": 50.0, "val_loss": 699.8046264648438, "val_acc": 40.0}
{"epoch": 38, "training_loss": 435.66546936035155, "training_acc": 40.0, "val_loss": 160.7637176513672, "val_acc": 60.0}
{"epoch": 39, "training_loss": 162.93179016113282, "training_acc": 50.0, "val_loss": 187.69752502441406, "val_acc": 40.0}
{"epoch": 40, "training_loss": 140.0577628135681, "training_acc": 30.0, "val_loss": 293.35699462890625, "val_acc": 40.0}
{"epoch": 41, "training_loss": 283.0083251953125, "training_acc": 50.0, "val_loss": 121.67396545410156, "val_acc": 60.0}
