"main_modify.py --pretrained_path None --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 3 --task ADNI_sex --input_option yAware --learning_rate 5e0 --batch_size 8 --weight_decay 5e-4 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 594.5646052360535, "training_acc": 40.0, "val_loss": 193.54698181152344, "val_acc": 60.0}
{"epoch": 1, "training_loss": 405.5190063476563, "training_acc": 50.0, "val_loss": 182.20614624023438, "val_acc": 60.0}
{"epoch": 2, "training_loss": 135.62184829711913, "training_acc": 50.0, "val_loss": 741.0519409179688, "val_acc": 40.0}
{"epoch": 3, "training_loss": 662.1877685546875, "training_acc": 50.0, "val_loss": 360.508056640625, "val_acc": 40.0}
{"epoch": 4, "training_loss": 228.95541534423828, "training_acc": 40.0, "val_loss": 242.972412109375, "val_acc": 60.0}
{"epoch": 5, "training_loss": 246.79121856689454, "training_acc": 50.0, "val_loss": 239.8968048095703, "val_acc": 40.0}
{"epoch": 6, "training_loss": 227.44794921875, "training_acc": 50.0, "val_loss": 125.98709869384766, "val_acc": 40.0}
{"epoch": 7, "training_loss": 138.4554443359375, "training_acc": 50.0, "val_loss": 161.3316192626953, "val_acc": 60.0}
{"epoch": 8, "training_loss": 140.58812808990479, "training_acc": 60.0, "val_loss": 350.0380554199219, "val_acc": 40.0}
{"epoch": 9, "training_loss": 263.08112182617185, "training_acc": 50.0, "val_loss": 35.429039001464844, "val_acc": 60.0}
{"epoch": 10, "training_loss": 65.86397252082824, "training_acc": 50.0, "val_loss": 156.0650634765625, "val_acc": 40.0}
{"epoch": 11, "training_loss": 103.74977607727051, "training_acc": 50.0, "val_loss": 130.39244079589844, "val_acc": 60.0}
{"epoch": 12, "training_loss": 217.15721130371094, "training_acc": 50.0, "val_loss": 38.44394302368164, "val_acc": 60.0}
{"epoch": 13, "training_loss": 198.18310546875, "training_acc": 40.0, "val_loss": 385.5240783691406, "val_acc": 40.0}
{"epoch": 14, "training_loss": 238.03261108398436, "training_acc": 40.0, "val_loss": 53.585693359375, "val_acc": 60.0}
{"epoch": 15, "training_loss": 42.43988380432129, "training_acc": 60.0, "val_loss": 220.4613800048828, "val_acc": 40.0}
{"epoch": 16, "training_loss": 129.80333862304687, "training_acc": 50.0, "val_loss": 174.27723693847656, "val_acc": 60.0}
{"epoch": 17, "training_loss": 293.0157531738281, "training_acc": 50.0, "val_loss": 260.3687438964844, "val_acc": 60.0}
{"epoch": 18, "training_loss": 177.72194213867186, "training_acc": 60.0, "val_loss": 222.34033203125, "val_acc": 40.0}
{"epoch": 19, "training_loss": 188.49732666015626, "training_acc": 50.0, "val_loss": 17.215274810791016, "val_acc": 60.0}
{"epoch": 20, "training_loss": 24.53968505859375, "training_acc": 50.0, "val_loss": 15.676773071289062, "val_acc": 60.0}
{"epoch": 21, "training_loss": 38.6450342297554, "training_acc": 50.0, "val_loss": 35.750728607177734, "val_acc": 60.0}
{"epoch": 22, "training_loss": 30.737116241455077, "training_acc": 60.0, "val_loss": 229.68882751464844, "val_acc": 40.0}
{"epoch": 23, "training_loss": 155.55779113769532, "training_acc": 40.0, "val_loss": 25.407962799072266, "val_acc": 60.0}
{"epoch": 24, "training_loss": 13.404809021949768, "training_acc": 65.0, "val_loss": 88.40350341796875, "val_acc": 40.0}
{"epoch": 25, "training_loss": 60.46653060913086, "training_acc": 60.0, "val_loss": 64.8064193725586, "val_acc": 60.0}
{"epoch": 26, "training_loss": 79.53195395469666, "training_acc": 50.0, "val_loss": 100.74977111816406, "val_acc": 40.0}
{"epoch": 27, "training_loss": 46.05771942138672, "training_acc": 60.0, "val_loss": 24.384366989135742, "val_acc": 40.0}
{"epoch": 28, "training_loss": 35.288753509521484, "training_acc": 40.0, "val_loss": 6.618391513824463, "val_acc": 40.0}
{"epoch": 29, "training_loss": 54.14235653877258, "training_acc": 60.0, "val_loss": 21.763612747192383, "val_acc": 60.0}
{"epoch": 30, "training_loss": 249.4132507324219, "training_acc": 20.0, "val_loss": 271.94293212890625, "val_acc": 40.0}
{"epoch": 31, "training_loss": 184.28441009521484, "training_acc": 40.0, "val_loss": 273.2342224121094, "val_acc": 60.0}
{"epoch": 32, "training_loss": 313.7484985351563, "training_acc": 50.0, "val_loss": 5.7955546379089355, "val_acc": 60.0}
{"epoch": 33, "training_loss": 89.1351942062378, "training_acc": 70.0, "val_loss": 418.06494140625, "val_acc": 40.0}
{"epoch": 34, "training_loss": 282.7040672302246, "training_acc": 50.0, "val_loss": 108.68535614013672, "val_acc": 60.0}
{"epoch": 35, "training_loss": 188.3136428833008, "training_acc": 50.0, "val_loss": 68.89298248291016, "val_acc": 60.0}
{"epoch": 36, "training_loss": 76.38389129638672, "training_acc": 60.0, "val_loss": 121.97100067138672, "val_acc": 40.0}
{"epoch": 37, "training_loss": 63.22892189025879, "training_acc": 50.0, "val_loss": 19.940418243408203, "val_acc": 40.0}
{"epoch": 38, "training_loss": 27.453102111816406, "training_acc": 50.0, "val_loss": 14.757407188415527, "val_acc": 60.0}
{"epoch": 39, "training_loss": 49.33999481201172, "training_acc": 30.0, "val_loss": 12.901552200317383, "val_acc": 60.0}
{"epoch": 40, "training_loss": 137.660555267334, "training_acc": 40.0, "val_loss": 144.1371612548828, "val_acc": 40.0}
{"epoch": 41, "training_loss": 94.43473052978516, "training_acc": 50.0, "val_loss": 83.96752166748047, "val_acc": 60.0}
{"epoch": 42, "training_loss": 106.3902084350586, "training_acc": 40.0, "val_loss": 314.68212890625, "val_acc": 40.0}
{"epoch": 43, "training_loss": 209.2513000488281, "training_acc": 50.0, "val_loss": 137.51727294921875, "val_acc": 60.0}
{"epoch": 44, "training_loss": 221.0236373901367, "training_acc": 50.0, "val_loss": 89.53502655029297, "val_acc": 60.0}
{"epoch": 45, "training_loss": 101.33566284179688, "training_acc": 50.0, "val_loss": 121.0184555053711, "val_acc": 40.0}
{"epoch": 46, "training_loss": 40.60542373657226, "training_acc": 60.0, "val_loss": 48.35274887084961, "val_acc": 40.0}
{"epoch": 47, "training_loss": 24.997237777709962, "training_acc": 60.0, "val_loss": 109.31074523925781, "val_acc": 60.0}
{"epoch": 48, "training_loss": 128.45804748535156, "training_acc": 40.0, "val_loss": 173.8201141357422, "val_acc": 40.0}
{"epoch": 49, "training_loss": 106.25206861495971, "training_acc": 45.0, "val_loss": 20.148719787597656, "val_acc": 40.0}
{"epoch": 50, "training_loss": 21.02141456604004, "training_acc": 50.0, "val_loss": 53.51619338989258, "val_acc": 40.0}
{"epoch": 51, "training_loss": 108.04302368164062, "training_acc": 40.0, "val_loss": 19.232254028320312, "val_acc": 60.0}
