"main_modify.py --pretrained_path None --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 1 --task ADNI_sex --input_option yAware --learning_rate 5e0 --batch_size 8 --weight_decay 5e-4 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 599.3439226865769, "training_acc": 50.0, "val_loss": 459.71044921875, "val_acc": 60.0}
{"epoch": 1, "training_loss": 734.37265625, "training_acc": 50.0, "val_loss": 411.8185729980469, "val_acc": 60.0}
{"epoch": 2, "training_loss": 367.92075500488284, "training_acc": 50.0, "val_loss": 804.4421997070312, "val_acc": 40.0}
{"epoch": 3, "training_loss": 666.11044921875, "training_acc": 50.0, "val_loss": 389.0799865722656, "val_acc": 40.0}
{"epoch": 4, "training_loss": 247.45809936523438, "training_acc": 40.0, "val_loss": 272.2314147949219, "val_acc": 60.0}
{"epoch": 5, "training_loss": 263.60420684814454, "training_acc": 50.0, "val_loss": 221.34056091308594, "val_acc": 40.0}
{"epoch": 6, "training_loss": 276.2728637695312, "training_acc": 50.0, "val_loss": 207.76304626464844, "val_acc": 40.0}
{"epoch": 7, "training_loss": 197.14073181152344, "training_acc": 40.0, "val_loss": 205.9937286376953, "val_acc": 60.0}
{"epoch": 8, "training_loss": 151.53208618164064, "training_acc": 60.0, "val_loss": 129.40216064453125, "val_acc": 40.0}
{"epoch": 9, "training_loss": 84.12794189453125, "training_acc": 50.0, "val_loss": 43.424957275390625, "val_acc": 60.0}
{"epoch": 10, "training_loss": 28.697479057312012, "training_acc": 60.0, "val_loss": 327.6752014160156, "val_acc": 40.0}
{"epoch": 11, "training_loss": 253.50894165039062, "training_acc": 50.0, "val_loss": 39.4952507019043, "val_acc": 60.0}
{"epoch": 12, "training_loss": 144.9406997680664, "training_acc": 50.0, "val_loss": 57.66500473022461, "val_acc": 60.0}
{"epoch": 13, "training_loss": 159.27102966308593, "training_acc": 40.0, "val_loss": 233.24502563476562, "val_acc": 40.0}
{"epoch": 14, "training_loss": 103.88542556762695, "training_acc": 60.0, "val_loss": 198.01866149902344, "val_acc": 60.0}
{"epoch": 15, "training_loss": 214.00255126953124, "training_acc": 50.0, "val_loss": 69.02584075927734, "val_acc": 40.0}
{"epoch": 16, "training_loss": 102.84640502929688, "training_acc": 50.0, "val_loss": 6.5607590675354, "val_acc": 60.0}
{"epoch": 17, "training_loss": 45.79148483276367, "training_acc": 30.0, "val_loss": 16.34956169128418, "val_acc": 60.0}
{"epoch": 18, "training_loss": 23.820992279052735, "training_acc": 70.0, "val_loss": 32.494117736816406, "val_acc": 60.0}
{"epoch": 19, "training_loss": 35.4276967048645, "training_acc": 40.0, "val_loss": 33.26731491088867, "val_acc": 60.0}
{"epoch": 20, "training_loss": 160.27802124023438, "training_acc": 30.0, "val_loss": 67.95611572265625, "val_acc": 40.0}
{"epoch": 21, "training_loss": 125.1999298095703, "training_acc": 50.0, "val_loss": 222.8225860595703, "val_acc": 60.0}
{"epoch": 22, "training_loss": 239.08949590325355, "training_acc": 50.0, "val_loss": 200.8726806640625, "val_acc": 40.0}
{"epoch": 23, "training_loss": 245.95691833496093, "training_acc": 50.0, "val_loss": 90.99710083007812, "val_acc": 40.0}
{"epoch": 24, "training_loss": 147.5796630859375, "training_acc": 50.0, "val_loss": 263.08758544921875, "val_acc": 60.0}
{"epoch": 25, "training_loss": 268.12077102661135, "training_acc": 50.0, "val_loss": 186.54946899414062, "val_acc": 40.0}
{"epoch": 26, "training_loss": 272.6450500488281, "training_acc": 50.0, "val_loss": 161.5240936279297, "val_acc": 40.0}
{"epoch": 27, "training_loss": 175.82589111328124, "training_acc": 50.0, "val_loss": 223.0212860107422, "val_acc": 60.0}
{"epoch": 28, "training_loss": 184.0172646522522, "training_acc": 50.0, "val_loss": 320.3190612792969, "val_acc": 40.0}
{"epoch": 29, "training_loss": 335.3592163085938, "training_acc": 50.0, "val_loss": 430.0102233886719, "val_acc": 40.0}
{"epoch": 30, "training_loss": 231.28477630615234, "training_acc": 50.0, "val_loss": 130.3484344482422, "val_acc": 60.0}
{"epoch": 31, "training_loss": 136.3248420715332, "training_acc": 50.0, "val_loss": 145.97430419921875, "val_acc": 40.0}
{"epoch": 32, "training_loss": 153.53943481445313, "training_acc": 50.0, "val_loss": 0.6577441096305847, "val_acc": 40.0}
{"epoch": 33, "training_loss": 231.47105054855348, "training_acc": 45.0, "val_loss": 198.2480010986328, "val_acc": 60.0}
{"epoch": 34, "training_loss": 124.25250701904297, "training_acc": 60.0, "val_loss": 395.3316650390625, "val_acc": 40.0}
{"epoch": 35, "training_loss": 337.36028442382815, "training_acc": 50.0, "val_loss": 207.72195434570312, "val_acc": 40.0}
{"epoch": 36, "training_loss": 103.05434799194336, "training_acc": 50.0, "val_loss": 70.28203582763672, "val_acc": 60.0}
{"epoch": 37, "training_loss": 85.29890441894531, "training_acc": 40.0, "val_loss": 21.506410598754883, "val_acc": 60.0}
{"epoch": 38, "training_loss": 34.915143966674805, "training_acc": 50.0, "val_loss": 125.64022064208984, "val_acc": 40.0}
{"epoch": 39, "training_loss": 78.65813293457032, "training_acc": 50.0, "val_loss": 181.35801696777344, "val_acc": 60.0}
{"epoch": 40, "training_loss": 180.1989567756653, "training_acc": 50.0, "val_loss": 212.3070068359375, "val_acc": 40.0}
{"epoch": 41, "training_loss": 235.880859375, "training_acc": 50.0, "val_loss": 117.66877746582031, "val_acc": 40.0}
{"epoch": 42, "training_loss": 132.7942626953125, "training_acc": 50.0, "val_loss": 169.85403442382812, "val_acc": 60.0}
{"epoch": 43, "training_loss": 130.51801605224608, "training_acc": 60.0, "val_loss": 236.5244598388672, "val_acc": 40.0}
{"epoch": 44, "training_loss": 188.2207794189453, "training_acc": 50.0, "val_loss": 73.84029388427734, "val_acc": 60.0}
{"epoch": 45, "training_loss": 97.51097869873047, "training_acc": 50.0, "val_loss": 32.5350227355957, "val_acc": 40.0}
{"epoch": 46, "training_loss": 33.65284881591797, "training_acc": 60.0, "val_loss": 13.95105266571045, "val_acc": 60.0}
{"epoch": 47, "training_loss": 62.50128021240234, "training_acc": 50.0, "val_loss": 55.08980178833008, "val_acc": 60.0}
{"epoch": 48, "training_loss": 83.56233193129302, "training_acc": 50.0, "val_loss": 91.96529388427734, "val_acc": 40.0}
{"epoch": 49, "training_loss": 89.93063659667969, "training_acc": 40.0, "val_loss": 57.77651596069336, "val_acc": 60.0}
{"epoch": 50, "training_loss": 118.19929504394531, "training_acc": 30.0, "val_loss": 20.906402587890625, "val_acc": 60.0}
{"epoch": 51, "training_loss": 35.159967041015626, "training_acc": 50.0, "val_loss": 11.608795166015625, "val_acc": 40.0}
