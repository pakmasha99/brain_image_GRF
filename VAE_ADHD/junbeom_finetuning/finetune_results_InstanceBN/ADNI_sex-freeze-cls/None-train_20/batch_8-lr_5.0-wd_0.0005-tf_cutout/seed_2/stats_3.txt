"main_modify.py --pretrained_path None --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 2 --task ADNI_sex --input_option yAware --learning_rate 5e0 --batch_size 8 --weight_decay 5e-4 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 676.9832308530807, "training_acc": 35.0, "val_loss": 450.1210632324219, "val_acc": 40.0}
{"epoch": 1, "training_loss": 704.4651000976562, "training_acc": 55.0, "val_loss": 921.3515625, "val_acc": 40.0}
{"epoch": 2, "training_loss": 467.07040824890134, "training_acc": 55.0, "val_loss": 160.4269256591797, "val_acc": 60.0}
{"epoch": 3, "training_loss": 168.86297073364258, "training_acc": 45.0, "val_loss": 68.72523498535156, "val_acc": 40.0}
{"epoch": 4, "training_loss": 69.4149398803711, "training_acc": 35.0, "val_loss": 59.19929122924805, "val_acc": 60.0}
{"epoch": 5, "training_loss": 101.72749633789063, "training_acc": 35.0, "val_loss": 182.43785095214844, "val_acc": 40.0}
{"epoch": 6, "training_loss": 100.56384582519532, "training_acc": 55.0, "val_loss": 141.28285217285156, "val_acc": 60.0}
{"epoch": 7, "training_loss": 173.66863098144532, "training_acc": 35.0, "val_loss": 203.89804077148438, "val_acc": 40.0}
{"epoch": 8, "training_loss": 125.93021545410156, "training_acc": 45.0, "val_loss": 42.780513763427734, "val_acc": 60.0}
{"epoch": 9, "training_loss": 13.830384254455566, "training_acc": 65.0, "val_loss": 369.2431640625, "val_acc": 40.0}
{"epoch": 10, "training_loss": 365.14055786132815, "training_acc": 55.0, "val_loss": 266.9818420410156, "val_acc": 40.0}
{"epoch": 11, "training_loss": 108.22515258789062, "training_acc": 55.0, "val_loss": 137.07687377929688, "val_acc": 60.0}
{"epoch": 12, "training_loss": 137.08746185302735, "training_acc": 45.0, "val_loss": 243.5885772705078, "val_acc": 40.0}
{"epoch": 13, "training_loss": 149.44722595214844, "training_acc": 55.0, "val_loss": 103.0528793334961, "val_acc": 60.0}
{"epoch": 14, "training_loss": 155.39525756835937, "training_acc": 45.0, "val_loss": 98.38783264160156, "val_acc": 40.0}
{"epoch": 15, "training_loss": 111.54659271240234, "training_acc": 55.0, "val_loss": 79.33155822753906, "val_acc": 40.0}
{"epoch": 16, "training_loss": 93.78253631591797, "training_acc": 55.0, "val_loss": 17.24245262145996, "val_acc": 60.0}
{"epoch": 17, "training_loss": 180.7354476928711, "training_acc": 45.0, "val_loss": 399.4000549316406, "val_acc": 40.0}
{"epoch": 18, "training_loss": 221.73515453338624, "training_acc": 55.0, "val_loss": 171.43594360351562, "val_acc": 60.0}
{"epoch": 19, "training_loss": 282.8611572265625, "training_acc": 45.0, "val_loss": 130.54946899414062, "val_acc": 60.0}
{"epoch": 20, "training_loss": 77.61395149230957, "training_acc": 65.0, "val_loss": 156.49490356445312, "val_acc": 40.0}
{"epoch": 21, "training_loss": 119.96515979766846, "training_acc": 45.0, "val_loss": 151.744873046875, "val_acc": 60.0}
{"epoch": 22, "training_loss": 125.07893600463868, "training_acc": 55.0, "val_loss": 210.55564880371094, "val_acc": 40.0}
{"epoch": 23, "training_loss": 132.31851196289062, "training_acc": 55.0, "val_loss": 72.71166229248047, "val_acc": 60.0}
{"epoch": 24, "training_loss": 99.57008819580078, "training_acc": 45.0, "val_loss": 154.9406280517578, "val_acc": 40.0}
{"epoch": 25, "training_loss": 136.7017822265625, "training_acc": 55.0, "val_loss": 34.116973876953125, "val_acc": 40.0}
{"epoch": 26, "training_loss": 108.48931579589843, "training_acc": 55.0, "val_loss": 153.83303833007812, "val_acc": 60.0}
{"epoch": 27, "training_loss": 151.7972625732422, "training_acc": 45.0, "val_loss": 317.2039794921875, "val_acc": 40.0}
{"epoch": 28, "training_loss": 245.60723876953125, "training_acc": 55.0, "val_loss": 33.35454177856445, "val_acc": 40.0}
{"epoch": 29, "training_loss": 314.8846801757812, "training_acc": 35.0, "val_loss": 344.65087890625, "val_acc": 60.0}
{"epoch": 30, "training_loss": 379.12860946655275, "training_acc": 35.0, "val_loss": 140.1805877685547, "val_acc": 40.0}
{"epoch": 31, "training_loss": 87.64444007873536, "training_acc": 55.0, "val_loss": 127.55736541748047, "val_acc": 60.0}
{"epoch": 32, "training_loss": 210.02742919921874, "training_acc": 45.0, "val_loss": 8.026297569274902, "val_acc": 60.0}
{"epoch": 33, "training_loss": 145.48963356018066, "training_acc": 55.0, "val_loss": 473.5481872558594, "val_acc": 40.0}
{"epoch": 34, "training_loss": 308.125959777832, "training_acc": 55.0, "val_loss": 20.94819450378418, "val_acc": 60.0}
{"epoch": 35, "training_loss": 58.83871765136719, "training_acc": 25.0, "val_loss": 62.0501594543457, "val_acc": 60.0}
{"epoch": 36, "training_loss": 73.2004493713379, "training_acc": 45.0, "val_loss": 81.01171112060547, "val_acc": 40.0}
{"epoch": 37, "training_loss": 65.89134368896484, "training_acc": 35.0, "val_loss": 158.8086395263672, "val_acc": 40.0}
{"epoch": 38, "training_loss": 157.09486541748046, "training_acc": 55.0, "val_loss": 59.75251388549805, "val_acc": 40.0}
{"epoch": 39, "training_loss": 173.78684692382814, "training_acc": 35.0, "val_loss": 115.58745574951172, "val_acc": 60.0}
{"epoch": 40, "training_loss": 119.18378295898438, "training_acc": 45.0, "val_loss": 129.537353515625, "val_acc": 40.0}
{"epoch": 41, "training_loss": 78.08268852233887, "training_acc": 35.0, "val_loss": 111.21308898925781, "val_acc": 40.0}
{"epoch": 42, "training_loss": 85.49904022216796, "training_acc": 55.0, "val_loss": 90.16280364990234, "val_acc": 60.0}
{"epoch": 43, "training_loss": 147.4524211883545, "training_acc": 45.0, "val_loss": 95.95244598388672, "val_acc": 40.0}
{"epoch": 44, "training_loss": 66.99000358581543, "training_acc": 55.0, "val_loss": 74.79914855957031, "val_acc": 60.0}
{"epoch": 45, "training_loss": 94.17906951904297, "training_acc": 45.0, "val_loss": 253.90574645996094, "val_acc": 40.0}
{"epoch": 46, "training_loss": 226.3569091796875, "training_acc": 55.0, "val_loss": 316.67510986328125, "val_acc": 40.0}
{"epoch": 47, "training_loss": 157.23817749023436, "training_acc": 55.0, "val_loss": 118.3579330444336, "val_acc": 60.0}
{"epoch": 48, "training_loss": 107.73672351837158, "training_acc": 55.0, "val_loss": 111.70588684082031, "val_acc": 40.0}
{"epoch": 49, "training_loss": 78.27608489990234, "training_acc": 45.0, "val_loss": 15.465530395507812, "val_acc": 40.0}
{"epoch": 50, "training_loss": 21.053111267089843, "training_acc": 55.0, "val_loss": 18.758298873901367, "val_acc": 40.0}
{"epoch": 51, "training_loss": 116.95516967773438, "training_acc": 35.0, "val_loss": 19.851367950439453, "val_acc": 60.0}
