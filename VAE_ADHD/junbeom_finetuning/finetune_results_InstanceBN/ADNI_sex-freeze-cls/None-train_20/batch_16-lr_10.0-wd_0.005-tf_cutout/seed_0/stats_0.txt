"main_modify.py --pretrained_path None --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_sex --input_option yAware --learning_rate 1e1 --batch_size 16 --weight_decay 5e-3 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 643.2359386444092, "training_acc": 50.0, "val_loss": 740.1537475585938, "val_acc": 40.0}
{"epoch": 1, "training_loss": 714.482666015625, "training_acc": 50.0, "val_loss": 1391.5648193359375, "val_acc": 60.0}
{"epoch": 2, "training_loss": 1728.7038208007812, "training_acc": 50.0, "val_loss": 1010.5601806640625, "val_acc": 60.0}
{"epoch": 3, "training_loss": 1060.352880859375, "training_acc": 50.0, "val_loss": 525.2338256835938, "val_acc": 40.0}
{"epoch": 4, "training_loss": 548.3298828125, "training_acc": 50.0, "val_loss": 1376.133056640625, "val_acc": 40.0}
{"epoch": 5, "training_loss": 1104.9876708984375, "training_acc": 50.0, "val_loss": 587.5252685546875, "val_acc": 40.0}
{"epoch": 6, "training_loss": 435.49513549804686, "training_acc": 50.0, "val_loss": 479.624755859375, "val_acc": 60.0}
{"epoch": 7, "training_loss": 616.6801513671875, "training_acc": 50.0, "val_loss": 415.6639709472656, "val_acc": 60.0}
{"epoch": 8, "training_loss": 442.5522888183594, "training_acc": 50.0, "val_loss": 513.4275512695312, "val_acc": 40.0}
{"epoch": 9, "training_loss": 452.3788635253906, "training_acc": 50.0, "val_loss": 923.5409545898438, "val_acc": 40.0}
{"epoch": 10, "training_loss": 740.1340576171875, "training_acc": 50.0, "val_loss": 319.1812438964844, "val_acc": 40.0}
{"epoch": 11, "training_loss": 266.5677124023438, "training_acc": 50.0, "val_loss": 426.615966796875, "val_acc": 60.0}
{"epoch": 12, "training_loss": 536.12548828125, "training_acc": 50.0, "val_loss": 275.9002990722656, "val_acc": 60.0}
{"epoch": 13, "training_loss": 332.5974380493164, "training_acc": 40.0, "val_loss": 172.1744384765625, "val_acc": 40.0}
{"epoch": 14, "training_loss": 135.92362365722656, "training_acc": 40.0, "val_loss": 149.29197692871094, "val_acc": 40.0}
{"epoch": 15, "training_loss": 112.02658386230469, "training_acc": 50.0, "val_loss": 196.0266571044922, "val_acc": 60.0}
{"epoch": 16, "training_loss": 264.1843200683594, "training_acc": 50.0, "val_loss": 183.4618682861328, "val_acc": 60.0}
{"epoch": 17, "training_loss": 197.19298706054687, "training_acc": 50.0, "val_loss": 173.6663360595703, "val_acc": 40.0}
{"epoch": 18, "training_loss": 113.5044158935547, "training_acc": 50.0, "val_loss": 272.06964111328125, "val_acc": 60.0}
{"epoch": 19, "training_loss": 351.84507141113284, "training_acc": 50.0, "val_loss": 370.49566650390625, "val_acc": 60.0}
{"epoch": 20, "training_loss": 410.1668701171875, "training_acc": 50.0, "val_loss": 192.5430908203125, "val_acc": 40.0}
{"epoch": 21, "training_loss": 230.74217529296874, "training_acc": 50.0, "val_loss": 372.98468017578125, "val_acc": 40.0}
{"epoch": 22, "training_loss": 256.70433654785154, "training_acc": 50.0, "val_loss": 316.115234375, "val_acc": 60.0}
{"epoch": 23, "training_loss": 460.27833251953126, "training_acc": 50.0, "val_loss": 409.7079772949219, "val_acc": 60.0}
{"epoch": 24, "training_loss": 454.0280700683594, "training_acc": 50.0, "val_loss": 278.58929443359375, "val_acc": 40.0}
{"epoch": 25, "training_loss": 304.2163330078125, "training_acc": 50.0, "val_loss": 473.6188049316406, "val_acc": 40.0}
{"epoch": 26, "training_loss": 341.51873779296875, "training_acc": 50.0, "val_loss": 241.29173278808594, "val_acc": 60.0}
{"epoch": 27, "training_loss": 339.98467407226565, "training_acc": 50.0, "val_loss": 376.3426208496094, "val_acc": 60.0}
{"epoch": 28, "training_loss": 470.11787109375, "training_acc": 50.0, "val_loss": 51.071937561035156, "val_acc": 40.0}
{"epoch": 29, "training_loss": 43.3669246673584, "training_acc": 50.0, "val_loss": 31.593719482421875, "val_acc": 60.0}
{"epoch": 30, "training_loss": 45.674005126953126, "training_acc": 50.0, "val_loss": 16.99613380432129, "val_acc": 60.0}
{"epoch": 31, "training_loss": 74.67408447265625, "training_acc": 30.0, "val_loss": 84.5333480834961, "val_acc": 60.0}
{"epoch": 32, "training_loss": 105.64573516845704, "training_acc": 50.0, "val_loss": 11.60771369934082, "val_acc": 60.0}
{"epoch": 33, "training_loss": 136.473388671875, "training_acc": 30.0, "val_loss": 254.7697296142578, "val_acc": 40.0}
{"epoch": 34, "training_loss": 216.46471252441407, "training_acc": 40.0, "val_loss": 58.3559684753418, "val_acc": 60.0}
{"epoch": 35, "training_loss": 82.94881286621094, "training_acc": 50.0, "val_loss": 136.83163452148438, "val_acc": 40.0}
{"epoch": 36, "training_loss": 107.6878662109375, "training_acc": 50.0, "val_loss": 58.21523666381836, "val_acc": 60.0}
{"epoch": 37, "training_loss": 60.71265182495117, "training_acc": 60.0, "val_loss": 194.04434204101562, "val_acc": 40.0}
{"epoch": 38, "training_loss": 134.70018920898437, "training_acc": 50.0, "val_loss": 227.705322265625, "val_acc": 60.0}
{"epoch": 39, "training_loss": 317.312109375, "training_acc": 50.0, "val_loss": 162.6563720703125, "val_acc": 60.0}
{"epoch": 40, "training_loss": 155.77969207763672, "training_acc": 60.0, "val_loss": 418.02886962890625, "val_acc": 40.0}
{"epoch": 41, "training_loss": 347.1776916503906, "training_acc": 50.0, "val_loss": 168.70516967773438, "val_acc": 40.0}
{"epoch": 42, "training_loss": 159.12303161621094, "training_acc": 50.0, "val_loss": 300.5760803222656, "val_acc": 60.0}
{"epoch": 43, "training_loss": 361.734619140625, "training_acc": 50.0, "val_loss": 38.4798583984375, "val_acc": 60.0}
{"epoch": 44, "training_loss": 68.8400390625, "training_acc": 60.0, "val_loss": 734.3224487304688, "val_acc": 40.0}
{"epoch": 45, "training_loss": 612.3094299316406, "training_acc": 50.0, "val_loss": 615.6019287109375, "val_acc": 40.0}
{"epoch": 46, "training_loss": 431.05166015625, "training_acc": 50.0, "val_loss": 237.10696411132812, "val_acc": 60.0}
{"epoch": 47, "training_loss": 353.495166015625, "training_acc": 50.0, "val_loss": 508.1540222167969, "val_acc": 60.0}
{"epoch": 48, "training_loss": 595.2452270507813, "training_acc": 50.0, "val_loss": 68.98030853271484, "val_acc": 60.0}
{"epoch": 49, "training_loss": 165.10771484375, "training_acc": 50.0, "val_loss": 949.5538330078125, "val_acc": 40.0}
{"epoch": 50, "training_loss": 805.4437377929687, "training_acc": 50.0, "val_loss": 859.8694458007812, "val_acc": 40.0}
{"epoch": 51, "training_loss": 680.2030364990235, "training_acc": 50.0, "val_loss": 59.5938720703125, "val_acc": 60.0}
