"main_modify.py --pretrained_path None --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 5 --task ADNI_sex --input_option yAware --learning_rate 1e1 --batch_size 16 --weight_decay 5e-3 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 428.2189366340637, "training_acc": 45.0, "val_loss": 901.5051879882812, "val_acc": 40.0}
{"epoch": 1, "training_loss": 540.5256286621094, "training_acc": 65.0, "val_loss": 1355.8275146484375, "val_acc": 60.0}
{"epoch": 2, "training_loss": 1835.6600341796875, "training_acc": 45.0, "val_loss": 694.26806640625, "val_acc": 60.0}
{"epoch": 3, "training_loss": 697.7759395599365, "training_acc": 55.0, "val_loss": 736.3076171875, "val_acc": 40.0}
{"epoch": 4, "training_loss": 558.8740539550781, "training_acc": 55.0, "val_loss": 635.9794921875, "val_acc": 40.0}
{"epoch": 5, "training_loss": 352.60533447265624, "training_acc": 55.0, "val_loss": 549.1200561523438, "val_acc": 60.0}
{"epoch": 6, "training_loss": 783.0117492675781, "training_acc": 45.0, "val_loss": 844.5932006835938, "val_acc": 60.0}
{"epoch": 7, "training_loss": 1106.6604125976562, "training_acc": 45.0, "val_loss": 213.2369842529297, "val_acc": 60.0}
{"epoch": 8, "training_loss": 258.5642425537109, "training_acc": 55.0, "val_loss": 1156.4403076171875, "val_acc": 40.0}
{"epoch": 9, "training_loss": 907.4453125, "training_acc": 55.0, "val_loss": 1274.4661865234375, "val_acc": 40.0}
{"epoch": 10, "training_loss": 919.2946960449219, "training_acc": 55.0, "val_loss": 282.119873046875, "val_acc": 40.0}
{"epoch": 11, "training_loss": 117.4938232421875, "training_acc": 75.0, "val_loss": 688.4302368164062, "val_acc": 60.0}
{"epoch": 12, "training_loss": 978.435009765625, "training_acc": 45.0, "val_loss": 721.44775390625, "val_acc": 60.0}
{"epoch": 13, "training_loss": 882.0452026367187, "training_acc": 45.0, "val_loss": 159.9030303955078, "val_acc": 40.0}
{"epoch": 14, "training_loss": 119.7462890625, "training_acc": 55.0, "val_loss": 929.1969604492188, "val_acc": 40.0}
{"epoch": 15, "training_loss": 698.8036804199219, "training_acc": 55.0, "val_loss": 822.07373046875, "val_acc": 40.0}
{"epoch": 16, "training_loss": 581.9487213134765, "training_acc": 55.0, "val_loss": 71.44721221923828, "val_acc": 60.0}
{"epoch": 17, "training_loss": 124.537548828125, "training_acc": 45.0, "val_loss": 86.69522094726562, "val_acc": 60.0}
{"epoch": 18, "training_loss": 189.47628173828124, "training_acc": 35.0, "val_loss": 326.9619140625, "val_acc": 40.0}
{"epoch": 19, "training_loss": 194.75653381347655, "training_acc": 55.0, "val_loss": 292.639892578125, "val_acc": 60.0}
{"epoch": 20, "training_loss": 462.5009521484375, "training_acc": 45.0, "val_loss": 333.8233947753906, "val_acc": 60.0}
{"epoch": 21, "training_loss": 383.1428848266602, "training_acc": 45.0, "val_loss": 612.3261108398438, "val_acc": 40.0}
{"epoch": 22, "training_loss": 600.7621337890625, "training_acc": 55.0, "val_loss": 898.2154541015625, "val_acc": 40.0}
{"epoch": 23, "training_loss": 641.0265869140625, "training_acc": 55.0, "val_loss": 24.739599227905273, "val_acc": 40.0}
{"epoch": 24, "training_loss": 246.83018951416017, "training_acc": 35.0, "val_loss": 545.6763916015625, "val_acc": 60.0}
{"epoch": 25, "training_loss": 722.4759521484375, "training_acc": 45.0, "val_loss": 169.59498596191406, "val_acc": 60.0}
{"epoch": 26, "training_loss": 252.91385498046876, "training_acc": 45.0, "val_loss": 697.6617431640625, "val_acc": 40.0}
{"epoch": 27, "training_loss": 565.6687744140625, "training_acc": 55.0, "val_loss": 456.9635314941406, "val_acc": 40.0}
{"epoch": 28, "training_loss": 333.8192565917969, "training_acc": 45.0, "val_loss": 187.77171325683594, "val_acc": 60.0}
{"epoch": 29, "training_loss": 238.60863647460937, "training_acc": 45.0, "val_loss": 173.17120361328125, "val_acc": 40.0}
{"epoch": 30, "training_loss": 135.56995544433593, "training_acc": 55.0, "val_loss": 187.412841796875, "val_acc": 40.0}
{"epoch": 31, "training_loss": 120.95531311035157, "training_acc": 55.0, "val_loss": 46.43450164794922, "val_acc": 60.0}
{"epoch": 32, "training_loss": 84.44222412109374, "training_acc": 45.0, "val_loss": 196.3267059326172, "val_acc": 40.0}
{"epoch": 33, "training_loss": 116.12922973632813, "training_acc": 55.0, "val_loss": 36.37239456176758, "val_acc": 40.0}
{"epoch": 34, "training_loss": 42.13126068115234, "training_acc": 55.0, "val_loss": 24.136798858642578, "val_acc": 60.0}
{"epoch": 35, "training_loss": 114.73631591796875, "training_acc": 35.0, "val_loss": 317.13873291015625, "val_acc": 40.0}
{"epoch": 36, "training_loss": 199.1962860107422, "training_acc": 55.0, "val_loss": 236.9399871826172, "val_acc": 60.0}
{"epoch": 37, "training_loss": 325.843408203125, "training_acc": 45.0, "val_loss": 318.9143981933594, "val_acc": 60.0}
{"epoch": 38, "training_loss": 382.7577392578125, "training_acc": 45.0, "val_loss": 305.4021911621094, "val_acc": 40.0}
{"epoch": 39, "training_loss": 322.897802734375, "training_acc": 55.0, "val_loss": 659.2302856445312, "val_acc": 40.0}
{"epoch": 40, "training_loss": 472.0992431640625, "training_acc": 55.0, "val_loss": 30.660364151000977, "val_acc": 40.0}
{"epoch": 41, "training_loss": 101.22008972167968, "training_acc": 55.0, "val_loss": 491.3405456542969, "val_acc": 60.0}
{"epoch": 42, "training_loss": 664.6448608398438, "training_acc": 45.0, "val_loss": 245.32266235351562, "val_acc": 60.0}
{"epoch": 43, "training_loss": 257.35805435180663, "training_acc": 55.0, "val_loss": 491.43780517578125, "val_acc": 40.0}
{"epoch": 44, "training_loss": 384.44878540039065, "training_acc": 55.0, "val_loss": 427.723876953125, "val_acc": 40.0}
{"epoch": 45, "training_loss": 288.4004764556885, "training_acc": 55.0, "val_loss": 285.1249694824219, "val_acc": 60.0}
{"epoch": 46, "training_loss": 416.4003051757812, "training_acc": 45.0, "val_loss": 307.482421875, "val_acc": 60.0}
{"epoch": 47, "training_loss": 388.6255023956299, "training_acc": 45.0, "val_loss": 429.5005798339844, "val_acc": 40.0}
{"epoch": 48, "training_loss": 384.9205810546875, "training_acc": 55.0, "val_loss": 539.4633178710938, "val_acc": 40.0}
{"epoch": 49, "training_loss": 347.13453063964846, "training_acc": 55.0, "val_loss": 237.0490264892578, "val_acc": 60.0}
{"epoch": 50, "training_loss": 362.8937255859375, "training_acc": 45.0, "val_loss": 354.0036315917969, "val_acc": 60.0}
{"epoch": 51, "training_loss": 399.8286987304688, "training_acc": 45.0, "val_loss": 431.34527587890625, "val_acc": 40.0}
{"epoch": 52, "training_loss": 393.1935546875, "training_acc": 55.0, "val_loss": 978.2115478515625, "val_acc": 40.0}
{"epoch": 53, "training_loss": 712.713134765625, "training_acc": 55.0, "val_loss": 455.61767578125, "val_acc": 40.0}
