"main_modify.py --pretrained_path None --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 3 --task ADNI_sex --input_option yAware --learning_rate 1e1 --batch_size 16 --weight_decay 5e-3 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 855.2310185909271, "training_acc": 55.0, "val_loss": 864.8738403320312, "val_acc": 40.0}
{"epoch": 1, "training_loss": 1003.64150390625, "training_acc": 35.0, "val_loss": 893.9332275390625, "val_acc": 60.0}
{"epoch": 2, "training_loss": 1201.4947204589844, "training_acc": 45.0, "val_loss": 349.9010314941406, "val_acc": 60.0}
{"epoch": 3, "training_loss": 305.7730712890625, "training_acc": 65.0, "val_loss": 856.94921875, "val_acc": 40.0}
{"epoch": 4, "training_loss": 714.8127685546875, "training_acc": 55.0, "val_loss": 897.8837280273438, "val_acc": 40.0}
{"epoch": 5, "training_loss": 630.0299499511718, "training_acc": 55.0, "val_loss": 165.622802734375, "val_acc": 60.0}
{"epoch": 6, "training_loss": 292.6292236328125, "training_acc": 45.0, "val_loss": 214.80015563964844, "val_acc": 60.0}
{"epoch": 7, "training_loss": 223.84060287475586, "training_acc": 55.0, "val_loss": 366.49615478515625, "val_acc": 40.0}
{"epoch": 8, "training_loss": 271.71962890625, "training_acc": 55.0, "val_loss": 160.53662109375, "val_acc": 40.0}
{"epoch": 9, "training_loss": 129.81454467773438, "training_acc": 55.0, "val_loss": 198.3834686279297, "val_acc": 60.0}
{"epoch": 10, "training_loss": 236.463818359375, "training_acc": 45.0, "val_loss": 362.6652526855469, "val_acc": 40.0}
{"epoch": 11, "training_loss": 300.9069885253906, "training_acc": 55.0, "val_loss": 434.09307861328125, "val_acc": 40.0}
{"epoch": 12, "training_loss": 273.0626022338867, "training_acc": 55.0, "val_loss": 274.9817199707031, "val_acc": 60.0}
{"epoch": 13, "training_loss": 409.8912109375, "training_acc": 45.0, "val_loss": 347.5151062011719, "val_acc": 60.0}
{"epoch": 14, "training_loss": 395.9536437988281, "training_acc": 45.0, "val_loss": 451.2066345214844, "val_acc": 40.0}
{"epoch": 15, "training_loss": 437.66630859375, "training_acc": 55.0, "val_loss": 830.8248901367188, "val_acc": 40.0}
{"epoch": 16, "training_loss": 583.9838623046875, "training_acc": 55.0, "val_loss": 136.93374633789062, "val_acc": 40.0}
{"epoch": 17, "training_loss": 106.27921142578126, "training_acc": 65.0, "val_loss": 576.723388671875, "val_acc": 60.0}
{"epoch": 18, "training_loss": 797.4674865722657, "training_acc": 45.0, "val_loss": 554.3064575195312, "val_acc": 60.0}
{"epoch": 19, "training_loss": 701.5961059570312, "training_acc": 45.0, "val_loss": 99.38427734375, "val_acc": 40.0}
{"epoch": 20, "training_loss": 125.57305297851562, "training_acc": 55.0, "val_loss": 437.050048828125, "val_acc": 40.0}
{"epoch": 21, "training_loss": 296.63499755859374, "training_acc": 55.0, "val_loss": 106.46923828125, "val_acc": 60.0}
{"epoch": 22, "training_loss": 162.894482421875, "training_acc": 45.0, "val_loss": 72.10135650634766, "val_acc": 60.0}
{"epoch": 23, "training_loss": 130.10205078125, "training_acc": 45.0, "val_loss": 415.1486511230469, "val_acc": 40.0}
{"epoch": 24, "training_loss": 293.734033203125, "training_acc": 55.0, "val_loss": 19.70763397216797, "val_acc": 60.0}
{"epoch": 25, "training_loss": 33.434485626220706, "training_acc": 45.0, "val_loss": 134.1570587158203, "val_acc": 40.0}
{"epoch": 26, "training_loss": 96.00685119628906, "training_acc": 55.0, "val_loss": 104.345703125, "val_acc": 60.0}
{"epoch": 27, "training_loss": 142.6112487792969, "training_acc": 45.0, "val_loss": 204.876708984375, "val_acc": 40.0}
{"epoch": 28, "training_loss": 211.15640258789062, "training_acc": 55.0, "val_loss": 58.2969856262207, "val_acc": 40.0}
{"epoch": 29, "training_loss": 106.16015014648437, "training_acc": 55.0, "val_loss": 423.80078125, "val_acc": 60.0}
{"epoch": 30, "training_loss": 566.9367919921875, "training_acc": 45.0, "val_loss": 143.2450714111328, "val_acc": 60.0}
{"epoch": 31, "training_loss": 272.3263854980469, "training_acc": 35.0, "val_loss": 545.3097534179688, "val_acc": 40.0}
{"epoch": 32, "training_loss": 402.196728515625, "training_acc": 55.0, "val_loss": 137.1511688232422, "val_acc": 40.0}
{"epoch": 33, "training_loss": 148.18677978515626, "training_acc": 55.0, "val_loss": 442.3429870605469, "val_acc": 60.0}
{"epoch": 34, "training_loss": 604.2682861328125, "training_acc": 45.0, "val_loss": 185.705322265625, "val_acc": 60.0}
{"epoch": 35, "training_loss": 261.6658935546875, "training_acc": 45.0, "val_loss": 617.1968994140625, "val_acc": 40.0}
{"epoch": 36, "training_loss": 472.97021484375, "training_acc": 55.0, "val_loss": 484.2900390625, "val_acc": 40.0}
{"epoch": 37, "training_loss": 274.63946533203125, "training_acc": 55.0, "val_loss": 356.1866149902344, "val_acc": 60.0}
{"epoch": 38, "training_loss": 514.5464233398437, "training_acc": 45.0, "val_loss": 648.2156982421875, "val_acc": 60.0}
{"epoch": 39, "training_loss": 875.6967834472656, "training_acc": 45.0, "val_loss": 329.4463806152344, "val_acc": 60.0}
{"epoch": 40, "training_loss": 377.1908416748047, "training_acc": 45.0, "val_loss": 292.07611083984375, "val_acc": 40.0}
{"epoch": 41, "training_loss": 219.1001953125, "training_acc": 55.0, "val_loss": 213.87754821777344, "val_acc": 40.0}
{"epoch": 42, "training_loss": 129.59589462280275, "training_acc": 55.0, "val_loss": 10.795706748962402, "val_acc": 60.0}
{"epoch": 43, "training_loss": 29.666357421875, "training_acc": 55.0, "val_loss": 326.8192443847656, "val_acc": 40.0}
{"epoch": 44, "training_loss": 224.90233459472657, "training_acc": 55.0, "val_loss": 94.87492370605469, "val_acc": 60.0}
{"epoch": 45, "training_loss": 149.40897216796876, "training_acc": 45.0, "val_loss": 66.48458099365234, "val_acc": 40.0}
{"epoch": 46, "training_loss": 70.05050048828124, "training_acc": 55.0, "val_loss": 87.19178771972656, "val_acc": 60.0}
{"epoch": 47, "training_loss": 117.56142578125, "training_acc": 45.0, "val_loss": 128.99339294433594, "val_acc": 40.0}
{"epoch": 48, "training_loss": 99.292236328125, "training_acc": 55.0, "val_loss": 50.57046127319336, "val_acc": 60.0}
{"epoch": 49, "training_loss": 58.6981143951416, "training_acc": 45.0, "val_loss": 279.69818115234375, "val_acc": 40.0}
{"epoch": 50, "training_loss": 230.2339111328125, "training_acc": 55.0, "val_loss": 77.87723541259766, "val_acc": 40.0}
{"epoch": 51, "training_loss": 204.85416259765626, "training_acc": 35.0, "val_loss": 288.30487060546875, "val_acc": 60.0}
{"epoch": 52, "training_loss": 350.40134887695314, "training_acc": 45.0, "val_loss": 322.3158874511719, "val_acc": 40.0}
{"epoch": 53, "training_loss": 279.2100463867188, "training_acc": 55.0, "val_loss": 507.0736389160156, "val_acc": 40.0}
{"epoch": 54, "training_loss": 325.3273986816406, "training_acc": 55.0, "val_loss": 173.8085174560547, "val_acc": 60.0}
{"epoch": 55, "training_loss": 276.7728271484375, "training_acc": 45.0, "val_loss": 303.52960205078125, "val_acc": 60.0}
{"epoch": 56, "training_loss": 367.0609985351563, "training_acc": 45.0, "val_loss": 346.58306884765625, "val_acc": 40.0}
{"epoch": 57, "training_loss": 360.382470703125, "training_acc": 55.0, "val_loss": 447.7623596191406, "val_acc": 40.0}
{"epoch": 58, "training_loss": 224.6508056640625, "training_acc": 55.0, "val_loss": 426.0773620605469, "val_acc": 60.0}
{"epoch": 59, "training_loss": 653.5972412109375, "training_acc": 45.0, "val_loss": 778.6990356445312, "val_acc": 60.0}
{"epoch": 60, "training_loss": 1053.3982849121094, "training_acc": 45.0, "val_loss": 435.9269714355469, "val_acc": 60.0}
{"epoch": 61, "training_loss": 550.9805316925049, "training_acc": 45.0, "val_loss": 563.4308471679688, "val_acc": 40.0}
