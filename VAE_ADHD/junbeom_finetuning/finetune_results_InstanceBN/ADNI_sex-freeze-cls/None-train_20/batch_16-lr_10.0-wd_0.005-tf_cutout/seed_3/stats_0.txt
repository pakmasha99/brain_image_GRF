"main_modify.py --pretrained_path None --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 3 --task ADNI_sex --input_option yAware --learning_rate 1e1 --batch_size 16 --weight_decay 5e-3 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 429.7109664440155, "training_acc": 50.0, "val_loss": 475.72686767578125, "val_acc": 60.0}
{"epoch": 1, "training_loss": 535.2591552734375, "training_acc": 60.0, "val_loss": 2490.112060546875, "val_acc": 40.0}
{"epoch": 2, "training_loss": 2055.221435546875, "training_acc": 50.0, "val_loss": 1619.85546875, "val_acc": 40.0}
{"epoch": 3, "training_loss": 1154.89091796875, "training_acc": 50.0, "val_loss": 640.729736328125, "val_acc": 60.0}
{"epoch": 4, "training_loss": 856.6705932617188, "training_acc": 50.0, "val_loss": 1304.307373046875, "val_acc": 60.0}
{"epoch": 5, "training_loss": 1613.7012329101562, "training_acc": 50.0, "val_loss": 895.6215209960938, "val_acc": 60.0}
{"epoch": 6, "training_loss": 944.8275390625, "training_acc": 50.0, "val_loss": 426.37451171875, "val_acc": 40.0}
{"epoch": 7, "training_loss": 520.7781982421875, "training_acc": 50.0, "val_loss": 1185.0611572265625, "val_acc": 40.0}
{"epoch": 8, "training_loss": 948.375927734375, "training_acc": 50.0, "val_loss": 451.2408142089844, "val_acc": 40.0}
{"epoch": 9, "training_loss": 283.722395324707, "training_acc": 60.0, "val_loss": 492.0145568847656, "val_acc": 60.0}
{"epoch": 10, "training_loss": 614.908056640625, "training_acc": 50.0, "val_loss": 573.9887084960938, "val_acc": 60.0}
{"epoch": 11, "training_loss": 717.5181640625, "training_acc": 50.0, "val_loss": 169.85325622558594, "val_acc": 60.0}
{"epoch": 12, "training_loss": 169.35740661621094, "training_acc": 60.0, "val_loss": 568.4520874023438, "val_acc": 40.0}
{"epoch": 13, "training_loss": 470.6962890625, "training_acc": 50.0, "val_loss": 362.4639587402344, "val_acc": 40.0}
{"epoch": 14, "training_loss": 214.42272911071777, "training_acc": 60.0, "val_loss": 176.3802490234375, "val_acc": 60.0}
{"epoch": 15, "training_loss": 211.91081848144532, "training_acc": 50.0, "val_loss": 71.2581558227539, "val_acc": 40.0}
{"epoch": 16, "training_loss": 49.122803115844725, "training_acc": 50.0, "val_loss": 207.414794921875, "val_acc": 60.0}
{"epoch": 17, "training_loss": 257.78432312011716, "training_acc": 50.0, "val_loss": 90.77758026123047, "val_acc": 60.0}
{"epoch": 18, "training_loss": 178.28467407226563, "training_acc": 40.0, "val_loss": 298.583740234375, "val_acc": 40.0}
{"epoch": 19, "training_loss": 203.16460952758788, "training_acc": 50.0, "val_loss": 318.4141845703125, "val_acc": 60.0}
{"epoch": 20, "training_loss": 428.5621826171875, "training_acc": 50.0, "val_loss": 368.1413269042969, "val_acc": 60.0}
{"epoch": 21, "training_loss": 398.8914520263672, "training_acc": 50.0, "val_loss": 406.25927734375, "val_acc": 40.0}
{"epoch": 22, "training_loss": 357.4753173828125, "training_acc": 50.0, "val_loss": 706.4854736328125, "val_acc": 40.0}
{"epoch": 23, "training_loss": 542.6994018554688, "training_acc": 50.0, "val_loss": 18.92902183532715, "val_acc": 60.0}
{"epoch": 24, "training_loss": 64.1247314453125, "training_acc": 50.0, "val_loss": 154.32241821289062, "val_acc": 60.0}
{"epoch": 25, "training_loss": 164.70111999511718, "training_acc": 50.0, "val_loss": 74.16365814208984, "val_acc": 40.0}
{"epoch": 26, "training_loss": 77.7700408935547, "training_acc": 50.0, "val_loss": 89.57008361816406, "val_acc": 60.0}
{"epoch": 27, "training_loss": 88.45318145751953, "training_acc": 60.0, "val_loss": 226.12405395507812, "val_acc": 40.0}
{"epoch": 28, "training_loss": 154.22953186035156, "training_acc": 50.0, "val_loss": 275.0392761230469, "val_acc": 60.0}
{"epoch": 29, "training_loss": 356.782080078125, "training_acc": 50.0, "val_loss": 382.18280029296875, "val_acc": 60.0}
{"epoch": 30, "training_loss": 433.53282470703124, "training_acc": 50.0, "val_loss": 188.8163604736328, "val_acc": 40.0}
{"epoch": 31, "training_loss": 242.24390869140626, "training_acc": 50.0, "val_loss": 161.70559692382812, "val_acc": 40.0}
{"epoch": 32, "training_loss": 214.49383544921875, "training_acc": 40.0, "val_loss": 316.5592956542969, "val_acc": 60.0}
{"epoch": 33, "training_loss": 361.92009887695315, "training_acc": 50.0, "val_loss": 152.0111083984375, "val_acc": 40.0}
{"epoch": 34, "training_loss": 126.6806396484375, "training_acc": 50.0, "val_loss": 403.44610595703125, "val_acc": 40.0}
{"epoch": 35, "training_loss": 306.64122314453124, "training_acc": 50.0, "val_loss": 168.01731872558594, "val_acc": 60.0}
{"epoch": 36, "training_loss": 229.3380126953125, "training_acc": 50.0, "val_loss": 377.1495056152344, "val_acc": 60.0}
{"epoch": 37, "training_loss": 453.6444885253906, "training_acc": 50.0, "val_loss": 21.655607223510742, "val_acc": 60.0}
{"epoch": 38, "training_loss": 104.79413452148438, "training_acc": 50.0, "val_loss": 725.0470581054688, "val_acc": 40.0}
{"epoch": 39, "training_loss": 596.6867126464844, "training_acc": 50.0, "val_loss": 423.25128173828125, "val_acc": 40.0}
{"epoch": 40, "training_loss": 248.5443489074707, "training_acc": 50.0, "val_loss": 486.140625, "val_acc": 60.0}
{"epoch": 41, "training_loss": 716.2290283203125, "training_acc": 50.0, "val_loss": 777.1331176757812, "val_acc": 60.0}
{"epoch": 42, "training_loss": 912.5532470703125, "training_acc": 50.0, "val_loss": 227.17588806152344, "val_acc": 60.0}
