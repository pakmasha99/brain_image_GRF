"main_modify.py --pretrained_path None --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 3 --task ADNI_sex --input_option yAware --learning_rate 1e1 --batch_size 16 --weight_decay 5e-3 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 431.22301664352415, "training_acc": 50.0, "val_loss": 863.6359252929688, "val_acc": 40.0}
{"epoch": 1, "training_loss": 957.843017578125, "training_acc": 40.0, "val_loss": 983.3401489257812, "val_acc": 60.0}
{"epoch": 2, "training_loss": 1137.69931640625, "training_acc": 50.0, "val_loss": 81.08809661865234, "val_acc": 60.0}
{"epoch": 3, "training_loss": 160.27049560546874, "training_acc": 60.0, "val_loss": 1863.7015380859375, "val_acc": 40.0}
{"epoch": 4, "training_loss": 1623.3015625, "training_acc": 50.0, "val_loss": 1801.1654052734375, "val_acc": 40.0}
{"epoch": 5, "training_loss": 1344.8424560546875, "training_acc": 50.0, "val_loss": 182.52745056152344, "val_acc": 40.0}
{"epoch": 6, "training_loss": 284.32470703125, "training_acc": 50.0, "val_loss": 1127.9453125, "val_acc": 60.0}
{"epoch": 7, "training_loss": 1462.90712890625, "training_acc": 50.0, "val_loss": 1309.4202880859375, "val_acc": 60.0}
{"epoch": 8, "training_loss": 1581.474755859375, "training_acc": 50.0, "val_loss": 686.3709106445312, "val_acc": 60.0}
{"epoch": 9, "training_loss": 789.7730361938477, "training_acc": 50.0, "val_loss": 679.853515625, "val_acc": 40.0}
{"epoch": 10, "training_loss": 606.8238830566406, "training_acc": 50.0, "val_loss": 1456.6502685546875, "val_acc": 40.0}
{"epoch": 11, "training_loss": 1215.9666015625, "training_acc": 50.0, "val_loss": 1082.3489990234375, "val_acc": 40.0}
{"epoch": 12, "training_loss": 849.0513763427734, "training_acc": 50.0, "val_loss": 168.58493041992188, "val_acc": 60.0}
{"epoch": 13, "training_loss": 315.806591796875, "training_acc": 50.0, "val_loss": 449.4340515136719, "val_acc": 60.0}
{"epoch": 14, "training_loss": 539.5935272216797, "training_acc": 50.0, "val_loss": 17.61998748779297, "val_acc": 60.0}
{"epoch": 15, "training_loss": 108.7922348022461, "training_acc": 50.0, "val_loss": 812.8993530273438, "val_acc": 40.0}
{"epoch": 16, "training_loss": 682.11083984375, "training_acc": 50.0, "val_loss": 483.5509948730469, "val_acc": 40.0}
{"epoch": 17, "training_loss": 285.59326591491697, "training_acc": 60.0, "val_loss": 268.54638671875, "val_acc": 60.0}
{"epoch": 18, "training_loss": 364.09796142578125, "training_acc": 50.0, "val_loss": 171.34825134277344, "val_acc": 60.0}
{"epoch": 19, "training_loss": 252.65732421875, "training_acc": 40.0, "val_loss": 333.45111083984375, "val_acc": 40.0}
{"epoch": 20, "training_loss": 247.2100830078125, "training_acc": 50.0, "val_loss": 159.1170196533203, "val_acc": 60.0}
{"epoch": 21, "training_loss": 211.49397888183594, "training_acc": 50.0, "val_loss": 264.539306640625, "val_acc": 60.0}
{"epoch": 22, "training_loss": 281.7382019042969, "training_acc": 50.0, "val_loss": 320.6861267089844, "val_acc": 40.0}
{"epoch": 23, "training_loss": 333.015673828125, "training_acc": 50.0, "val_loss": 471.085693359375, "val_acc": 40.0}
{"epoch": 24, "training_loss": 335.9053680419922, "training_acc": 50.0, "val_loss": 265.5752868652344, "val_acc": 60.0}
{"epoch": 25, "training_loss": 373.41492919921876, "training_acc": 50.0, "val_loss": 417.3966979980469, "val_acc": 60.0}
{"epoch": 26, "training_loss": 498.6778564453125, "training_acc": 50.0, "val_loss": 34.1566162109375, "val_acc": 40.0}
{"epoch": 27, "training_loss": 63.08695068359375, "training_acc": 50.0, "val_loss": 28.74298667907715, "val_acc": 60.0}
{"epoch": 28, "training_loss": 35.609703826904294, "training_acc": 50.0, "val_loss": 301.4933776855469, "val_acc": 40.0}
{"epoch": 29, "training_loss": 263.36475830078126, "training_acc": 50.0, "val_loss": 211.6630859375, "val_acc": 40.0}
{"epoch": 30, "training_loss": 207.3228271484375, "training_acc": 40.0, "val_loss": 146.81236267089844, "val_acc": 60.0}
{"epoch": 31, "training_loss": 197.95029296875, "training_acc": 30.0, "val_loss": 110.42923736572266, "val_acc": 60.0}
{"epoch": 32, "training_loss": 133.23616714477538, "training_acc": 50.0, "val_loss": 68.58460235595703, "val_acc": 40.0}
{"epoch": 33, "training_loss": 58.09212036132813, "training_acc": 40.0, "val_loss": 216.0762176513672, "val_acc": 40.0}
{"epoch": 34, "training_loss": 178.62688293457032, "training_acc": 50.0, "val_loss": 13.007132530212402, "val_acc": 60.0}
{"epoch": 35, "training_loss": 20.416287231445313, "training_acc": 40.0, "val_loss": 180.64869689941406, "val_acc": 60.0}
{"epoch": 36, "training_loss": 232.64666137695312, "training_acc": 50.0, "val_loss": 76.9295883178711, "val_acc": 60.0}
{"epoch": 37, "training_loss": 164.3725341796875, "training_acc": 40.0, "val_loss": 354.60748291015625, "val_acc": 40.0}
{"epoch": 38, "training_loss": 263.65028991699216, "training_acc": 50.0, "val_loss": 151.65090942382812, "val_acc": 60.0}
{"epoch": 39, "training_loss": 211.593994140625, "training_acc": 50.0, "val_loss": 162.5410919189453, "val_acc": 60.0}
{"epoch": 40, "training_loss": 147.17797660827637, "training_acc": 60.0, "val_loss": 217.089599609375, "val_acc": 40.0}
{"epoch": 41, "training_loss": 166.470751953125, "training_acc": 50.0, "val_loss": 151.99453735351562, "val_acc": 60.0}
{"epoch": 42, "training_loss": 198.20751953125, "training_acc": 50.0, "val_loss": 192.16983032226562, "val_acc": 60.0}
{"epoch": 43, "training_loss": 197.09649124145508, "training_acc": 50.0, "val_loss": 433.2745666503906, "val_acc": 40.0}
{"epoch": 44, "training_loss": 391.05926513671875, "training_acc": 50.0, "val_loss": 539.07470703125, "val_acc": 40.0}
{"epoch": 45, "training_loss": 421.4067687988281, "training_acc": 50.0, "val_loss": 140.56344604492188, "val_acc": 60.0}
{"epoch": 46, "training_loss": 219.516650390625, "training_acc": 50.0, "val_loss": 129.421875, "val_acc": 60.0}
{"epoch": 47, "training_loss": 164.25208129882813, "training_acc": 50.0, "val_loss": 339.1693420410156, "val_acc": 40.0}
{"epoch": 48, "training_loss": 263.221044921875, "training_acc": 50.0, "val_loss": 73.92906951904297, "val_acc": 60.0}
{"epoch": 49, "training_loss": 117.97142944335937, "training_acc": 50.0, "val_loss": 41.19437026977539, "val_acc": 40.0}
{"epoch": 50, "training_loss": 34.05541915893555, "training_acc": 50.0, "val_loss": 123.1502456665039, "val_acc": 60.0}
{"epoch": 51, "training_loss": 149.92655029296876, "training_acc": 50.0, "val_loss": 95.83589935302734, "val_acc": 40.0}
{"epoch": 52, "training_loss": 77.10663185119628, "training_acc": 50.0, "val_loss": 49.578155517578125, "val_acc": 60.0}
{"epoch": 53, "training_loss": 69.9500717163086, "training_acc": 40.0, "val_loss": 112.4593276977539, "val_acc": 60.0}
