"main_modify.py --pretrained_path None --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 2 --task ADNI_sex --input_option yAware --learning_rate 1e1 --batch_size 16 --weight_decay 5e-3 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 641.4191078662873, "training_acc": 45.0, "val_loss": 473.8122253417969, "val_acc": 60.0}
{"epoch": 1, "training_loss": 765.78076171875, "training_acc": 45.0, "val_loss": 2214.702392578125, "val_acc": 40.0}
{"epoch": 2, "training_loss": 1659.009716796875, "training_acc": 55.0, "val_loss": 1847.3505859375, "val_acc": 40.0}
{"epoch": 3, "training_loss": 1260.586328125, "training_acc": 55.0, "val_loss": 36.31624984741211, "val_acc": 40.0}
{"epoch": 4, "training_loss": 222.61428833007812, "training_acc": 55.0, "val_loss": 1240.3572998046875, "val_acc": 60.0}
{"epoch": 5, "training_loss": 1723.06962890625, "training_acc": 45.0, "val_loss": 1126.666015625, "val_acc": 60.0}
{"epoch": 6, "training_loss": 1493.451434326172, "training_acc": 45.0, "val_loss": 172.968017578125, "val_acc": 60.0}
{"epoch": 7, "training_loss": 408.759814453125, "training_acc": 35.0, "val_loss": 1222.66552734375, "val_acc": 40.0}
{"epoch": 8, "training_loss": 939.606884765625, "training_acc": 55.0, "val_loss": 1183.1953125, "val_acc": 40.0}
{"epoch": 9, "training_loss": 791.5975830078125, "training_acc": 55.0, "val_loss": 75.01457977294922, "val_acc": 40.0}
{"epoch": 10, "training_loss": 256.2657836914062, "training_acc": 45.0, "val_loss": 818.9931030273438, "val_acc": 60.0}
{"epoch": 11, "training_loss": 1166.64853515625, "training_acc": 45.0, "val_loss": 649.232177734375, "val_acc": 60.0}
{"epoch": 12, "training_loss": 892.09677734375, "training_acc": 45.0, "val_loss": 298.1611022949219, "val_acc": 40.0}
{"epoch": 13, "training_loss": 281.07471923828126, "training_acc": 55.0, "val_loss": 713.4406127929688, "val_acc": 40.0}
{"epoch": 14, "training_loss": 509.9228271484375, "training_acc": 55.0, "val_loss": 190.780517578125, "val_acc": 40.0}
{"epoch": 15, "training_loss": 220.8281494140625, "training_acc": 45.0, "val_loss": 356.44451904296875, "val_acc": 60.0}
{"epoch": 16, "training_loss": 467.2647216796875, "training_acc": 45.0, "val_loss": 17.27928352355957, "val_acc": 60.0}
{"epoch": 17, "training_loss": 64.89598083496094, "training_acc": 55.0, "val_loss": 992.1205444335938, "val_acc": 40.0}
{"epoch": 18, "training_loss": 743.754541015625, "training_acc": 55.0, "val_loss": 1174.2449951171875, "val_acc": 40.0}
{"epoch": 19, "training_loss": 848.8874267578125, "training_acc": 55.0, "val_loss": 582.44677734375, "val_acc": 40.0}
{"epoch": 20, "training_loss": 406.08338623046876, "training_acc": 45.0, "val_loss": 215.4540557861328, "val_acc": 60.0}
{"epoch": 21, "training_loss": 291.5525604248047, "training_acc": 45.0, "val_loss": 29.257659912109375, "val_acc": 60.0}
{"epoch": 22, "training_loss": 104.76296691894531, "training_acc": 45.0, "val_loss": 629.6243286132812, "val_acc": 40.0}
{"epoch": 23, "training_loss": 467.4003448486328, "training_acc": 55.0, "val_loss": 401.90557861328125, "val_acc": 40.0}
{"epoch": 24, "training_loss": 269.01985187530516, "training_acc": 55.0, "val_loss": 299.2106018066406, "val_acc": 60.0}
{"epoch": 25, "training_loss": 437.2720581054688, "training_acc": 45.0, "val_loss": 337.2564392089844, "val_acc": 60.0}
{"epoch": 26, "training_loss": 405.104150390625, "training_acc": 45.0, "val_loss": 390.43017578125, "val_acc": 40.0}
{"epoch": 27, "training_loss": 340.3658203125, "training_acc": 55.0, "val_loss": 695.3208618164062, "val_acc": 40.0}
{"epoch": 28, "training_loss": 479.248583984375, "training_acc": 55.0, "val_loss": 28.624343872070312, "val_acc": 40.0}
{"epoch": 29, "training_loss": 119.82911224365235, "training_acc": 55.0, "val_loss": 643.0957641601562, "val_acc": 60.0}
{"epoch": 30, "training_loss": 884.5123718261718, "training_acc": 45.0, "val_loss": 563.5743408203125, "val_acc": 60.0}
{"epoch": 31, "training_loss": 664.185498046875, "training_acc": 45.0, "val_loss": 235.05078125, "val_acc": 40.0}
{"epoch": 32, "training_loss": 302.2103515625, "training_acc": 55.0, "val_loss": 841.4853515625, "val_acc": 40.0}
{"epoch": 33, "training_loss": 610.8285522460938, "training_acc": 55.0, "val_loss": 374.5213317871094, "val_acc": 40.0}
{"epoch": 34, "training_loss": 241.90318298339844, "training_acc": 55.0, "val_loss": 253.4416046142578, "val_acc": 60.0}
{"epoch": 35, "training_loss": 340.721875, "training_acc": 45.0, "val_loss": 41.85934066772461, "val_acc": 60.0}
