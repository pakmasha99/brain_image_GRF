"main_modify.py --pretrained_path None --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 2 --task ADNI_sex --input_option yAware --learning_rate 1e1 --batch_size 16 --weight_decay 5e-3 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 639.8794348716735, "training_acc": 50.0, "val_loss": 771.2418212890625, "val_acc": 40.0}
{"epoch": 1, "training_loss": 1082.14599609375, "training_acc": 30.0, "val_loss": 1005.3709106445312, "val_acc": 60.0}
{"epoch": 2, "training_loss": 1200.4492797851562, "training_acc": 50.0, "val_loss": 307.8013610839844, "val_acc": 60.0}
{"epoch": 3, "training_loss": 392.34593505859374, "training_acc": 50.0, "val_loss": 969.69921875, "val_acc": 40.0}
{"epoch": 4, "training_loss": 829.691162109375, "training_acc": 50.0, "val_loss": 650.82958984375, "val_acc": 40.0}
{"epoch": 5, "training_loss": 386.5344802856445, "training_acc": 50.0, "val_loss": 606.2681884765625, "val_acc": 60.0}
{"epoch": 6, "training_loss": 799.6527221679687, "training_acc": 50.0, "val_loss": 1124.8641357421875, "val_acc": 60.0}
{"epoch": 7, "training_loss": 1406.038671875, "training_acc": 50.0, "val_loss": 957.49169921875, "val_acc": 60.0}
{"epoch": 8, "training_loss": 1129.61572265625, "training_acc": 50.0, "val_loss": 266.9628601074219, "val_acc": 60.0}
{"epoch": 9, "training_loss": 335.79810791015626, "training_acc": 50.0, "val_loss": 888.6716918945312, "val_acc": 40.0}
{"epoch": 10, "training_loss": 752.1372619628906, "training_acc": 50.0, "val_loss": 1001.7166137695312, "val_acc": 40.0}
{"epoch": 11, "training_loss": 788.480712890625, "training_acc": 50.0, "val_loss": 221.1364288330078, "val_acc": 40.0}
{"epoch": 12, "training_loss": 110.58232421875, "training_acc": 70.0, "val_loss": 656.1652221679688, "val_acc": 60.0}
{"epoch": 13, "training_loss": 861.989404296875, "training_acc": 50.0, "val_loss": 795.1126098632812, "val_acc": 60.0}
{"epoch": 14, "training_loss": 926.72724609375, "training_acc": 50.0, "val_loss": 209.87998962402344, "val_acc": 60.0}
{"epoch": 15, "training_loss": 220.5733428955078, "training_acc": 60.0, "val_loss": 1003.1854858398438, "val_acc": 40.0}
{"epoch": 16, "training_loss": 836.5044921875, "training_acc": 50.0, "val_loss": 1334.899658203125, "val_acc": 40.0}
{"epoch": 17, "training_loss": 1099.0835266113281, "training_acc": 50.0, "val_loss": 881.203125, "val_acc": 40.0}
{"epoch": 18, "training_loss": 689.3309173583984, "training_acc": 50.0, "val_loss": 187.3065185546875, "val_acc": 60.0}
{"epoch": 19, "training_loss": 257.9910034179687, "training_acc": 50.0, "val_loss": 461.2409362792969, "val_acc": 60.0}
{"epoch": 20, "training_loss": 553.5845581054688, "training_acc": 50.0, "val_loss": 119.6175765991211, "val_acc": 60.0}
{"epoch": 21, "training_loss": 186.0696533203125, "training_acc": 50.0, "val_loss": 672.2530517578125, "val_acc": 40.0}
{"epoch": 22, "training_loss": 559.2818725585937, "training_acc": 50.0, "val_loss": 410.952392578125, "val_acc": 40.0}
{"epoch": 23, "training_loss": 242.71995449066162, "training_acc": 60.0, "val_loss": 215.13992309570312, "val_acc": 60.0}
{"epoch": 24, "training_loss": 270.780517578125, "training_acc": 50.0, "val_loss": 64.1228256225586, "val_acc": 60.0}
{"epoch": 25, "training_loss": 218.9329345703125, "training_acc": 30.0, "val_loss": 392.9371032714844, "val_acc": 40.0}
{"epoch": 26, "training_loss": 303.1767997741699, "training_acc": 50.0, "val_loss": 186.81631469726562, "val_acc": 60.0}
{"epoch": 27, "training_loss": 239.7649719238281, "training_acc": 50.0, "val_loss": 198.49488830566406, "val_acc": 60.0}
{"epoch": 28, "training_loss": 182.01099853515626, "training_acc": 50.0, "val_loss": 554.1394653320312, "val_acc": 40.0}
{"epoch": 29, "training_loss": 509.020703125, "training_acc": 50.0, "val_loss": 839.4027709960938, "val_acc": 40.0}
{"epoch": 30, "training_loss": 657.924853515625, "training_acc": 50.0, "val_loss": 116.9115982055664, "val_acc": 40.0}
{"epoch": 31, "training_loss": 231.11871337890625, "training_acc": 40.0, "val_loss": 552.9580688476562, "val_acc": 60.0}
{"epoch": 32, "training_loss": 693.7282958984375, "training_acc": 50.0, "val_loss": 322.214111328125, "val_acc": 60.0}
{"epoch": 33, "training_loss": 335.2989898681641, "training_acc": 50.0, "val_loss": 351.59747314453125, "val_acc": 40.0}
{"epoch": 34, "training_loss": 302.1638244628906, "training_acc": 50.0, "val_loss": 67.79850006103516, "val_acc": 40.0}
{"epoch": 35, "training_loss": 170.96136474609375, "training_acc": 40.0, "val_loss": 412.0367736816406, "val_acc": 60.0}
{"epoch": 36, "training_loss": 492.888525390625, "training_acc": 50.0, "val_loss": 64.1771011352539, "val_acc": 60.0}
{"epoch": 37, "training_loss": 151.39932861328126, "training_acc": 50.0, "val_loss": 841.8234252929688, "val_acc": 40.0}
{"epoch": 38, "training_loss": 719.1878662109375, "training_acc": 50.0, "val_loss": 614.590576171875, "val_acc": 40.0}
{"epoch": 39, "training_loss": 427.80048217773435, "training_acc": 50.0, "val_loss": 386.2375793457031, "val_acc": 60.0}
{"epoch": 40, "training_loss": 545.998681640625, "training_acc": 50.0, "val_loss": 700.8448486328125, "val_acc": 60.0}
{"epoch": 41, "training_loss": 841.7647705078125, "training_acc": 50.0, "val_loss": 287.5340270996094, "val_acc": 60.0}
{"epoch": 42, "training_loss": 327.4834014892578, "training_acc": 50.0, "val_loss": 610.5731811523438, "val_acc": 40.0}
{"epoch": 43, "training_loss": 539.8713500976562, "training_acc": 50.0, "val_loss": 489.8813171386719, "val_acc": 40.0}
