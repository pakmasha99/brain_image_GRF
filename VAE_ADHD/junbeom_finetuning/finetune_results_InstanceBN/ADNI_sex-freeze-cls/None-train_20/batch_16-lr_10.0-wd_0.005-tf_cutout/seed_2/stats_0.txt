"main_modify.py --pretrained_path None --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 2 --task ADNI_sex --input_option yAware --learning_rate 1e1 --batch_size 16 --weight_decay 5e-3 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 430.08587589263914, "training_acc": 50.0, "val_loss": 552.8115234375, "val_acc": 60.0}
{"epoch": 1, "training_loss": 943.2927490234375, "training_acc": 40.0, "val_loss": 1525.7508544921875, "val_acc": 40.0}
{"epoch": 2, "training_loss": 1200.4294677734374, "training_acc": 50.0, "val_loss": 238.8539581298828, "val_acc": 40.0}
{"epoch": 3, "training_loss": 310.652294921875, "training_acc": 50.0, "val_loss": 953.0784301757812, "val_acc": 60.0}
{"epoch": 4, "training_loss": 1207.6111083984374, "training_acc": 50.0, "val_loss": 666.6376953125, "val_acc": 60.0}
{"epoch": 5, "training_loss": 648.3241088867187, "training_acc": 50.0, "val_loss": 814.6220092773438, "val_acc": 40.0}
{"epoch": 6, "training_loss": 727.7935546875, "training_acc": 50.0, "val_loss": 1743.0438232421875, "val_acc": 40.0}
{"epoch": 7, "training_loss": 1448.40654296875, "training_acc": 50.0, "val_loss": 1455.2701416015625, "val_acc": 40.0}
{"epoch": 8, "training_loss": 1168.203192138672, "training_acc": 50.0, "val_loss": 275.0777282714844, "val_acc": 40.0}
{"epoch": 9, "training_loss": 436.2966796875, "training_acc": 30.0, "val_loss": 581.787109375, "val_acc": 60.0}
{"epoch": 10, "training_loss": 726.0799072265625, "training_acc": 50.0, "val_loss": 326.6563720703125, "val_acc": 60.0}
{"epoch": 11, "training_loss": 397.2937316894531, "training_acc": 40.0, "val_loss": 309.80804443359375, "val_acc": 40.0}
{"epoch": 12, "training_loss": 247.79538269042968, "training_acc": 50.0, "val_loss": 27.36931800842285, "val_acc": 60.0}
{"epoch": 13, "training_loss": 34.58723411560059, "training_acc": 50.0, "val_loss": 67.5144271850586, "val_acc": 40.0}
{"epoch": 14, "training_loss": 95.19103088378907, "training_acc": 30.0, "val_loss": 162.3592987060547, "val_acc": 40.0}
{"epoch": 15, "training_loss": 140.1683349609375, "training_acc": 50.0, "val_loss": 2.9822888374328613, "val_acc": 60.0}
{"epoch": 16, "training_loss": 9.329719161987304, "training_acc": 50.0, "val_loss": 96.4498519897461, "val_acc": 60.0}
{"epoch": 17, "training_loss": 120.62607421875, "training_acc": 50.0, "val_loss": 71.3420639038086, "val_acc": 40.0}
{"epoch": 18, "training_loss": 57.32161636352539, "training_acc": 50.0, "val_loss": 47.475467681884766, "val_acc": 40.0}
{"epoch": 19, "training_loss": 62.54435729980469, "training_acc": 40.0, "val_loss": 85.77296447753906, "val_acc": 40.0}
{"epoch": 20, "training_loss": 63.589271545410156, "training_acc": 50.0, "val_loss": 150.61912536621094, "val_acc": 60.0}
{"epoch": 21, "training_loss": 198.26726684570312, "training_acc": 50.0, "val_loss": 32.73635482788086, "val_acc": 40.0}
{"epoch": 22, "training_loss": 29.093498611450194, "training_acc": 50.0, "val_loss": 25.75264549255371, "val_acc": 60.0}
{"epoch": 23, "training_loss": 60.827291870117186, "training_acc": 40.0, "val_loss": 37.095035552978516, "val_acc": 60.0}
{"epoch": 24, "training_loss": 37.03836350440979, "training_acc": 50.0, "val_loss": 6.7488694190979, "val_acc": 40.0}
{"epoch": 25, "training_loss": 39.555371856689455, "training_acc": 50.0, "val_loss": 119.26671600341797, "val_acc": 60.0}
{"epoch": 26, "training_loss": 160.0610137939453, "training_acc": 40.0, "val_loss": 22.65505027770996, "val_acc": 40.0}
{"epoch": 27, "training_loss": 60.604681396484374, "training_acc": 50.0, "val_loss": 208.50283813476562, "val_acc": 60.0}
{"epoch": 28, "training_loss": 228.2622329711914, "training_acc": 50.0, "val_loss": 281.60211181640625, "val_acc": 40.0}
{"epoch": 29, "training_loss": 243.5263916015625, "training_acc": 50.0, "val_loss": 357.9405822753906, "val_acc": 40.0}
{"epoch": 30, "training_loss": 231.34375, "training_acc": 50.0, "val_loss": 311.9358215332031, "val_acc": 60.0}
{"epoch": 31, "training_loss": 445.460205078125, "training_acc": 50.0, "val_loss": 572.5856323242188, "val_acc": 60.0}
{"epoch": 32, "training_loss": 684.7646484375, "training_acc": 50.0, "val_loss": 178.70614624023438, "val_acc": 60.0}
{"epoch": 33, "training_loss": 181.3655578613281, "training_acc": 60.0, "val_loss": 691.7992553710938, "val_acc": 40.0}
{"epoch": 34, "training_loss": 612.544873046875, "training_acc": 50.0, "val_loss": 610.5584106445312, "val_acc": 40.0}
