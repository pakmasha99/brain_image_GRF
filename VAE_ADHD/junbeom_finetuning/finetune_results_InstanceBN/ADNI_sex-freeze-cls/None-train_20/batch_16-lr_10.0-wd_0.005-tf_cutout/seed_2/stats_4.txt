"main_modify.py --pretrained_path None --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 2 --task ADNI_sex --input_option yAware --learning_rate 1e1 --batch_size 16 --weight_decay 5e-3 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 214.37061080932617, "training_acc": 55.0, "val_loss": 845.1508178710938, "val_acc": 40.0}
{"epoch": 1, "training_loss": 527.8267578125, "training_acc": 65.0, "val_loss": 1366.8323974609375, "val_acc": 60.0}
{"epoch": 2, "training_loss": 1787.512109375, "training_acc": 45.0, "val_loss": 265.2787170410156, "val_acc": 60.0}
{"epoch": 3, "training_loss": 231.91396484375, "training_acc": 65.0, "val_loss": 2178.807373046875, "val_acc": 40.0}
{"epoch": 4, "training_loss": 1705.12109375, "training_acc": 55.0, "val_loss": 2407.394287109375, "val_acc": 40.0}
{"epoch": 5, "training_loss": 1751.4910278320312, "training_acc": 55.0, "val_loss": 927.9808959960938, "val_acc": 40.0}
{"epoch": 6, "training_loss": 386.4807861328125, "training_acc": 75.0, "val_loss": 648.8837890625, "val_acc": 60.0}
{"epoch": 7, "training_loss": 946.20263671875, "training_acc": 45.0, "val_loss": 796.8517456054688, "val_acc": 60.0}
{"epoch": 8, "training_loss": 1095.0130859375, "training_acc": 45.0, "val_loss": 64.19274139404297, "val_acc": 60.0}
{"epoch": 9, "training_loss": 193.15574951171874, "training_acc": 45.0, "val_loss": 1120.7103271484375, "val_acc": 40.0}
{"epoch": 10, "training_loss": 884.116015625, "training_acc": 55.0, "val_loss": 770.114990234375, "val_acc": 40.0}
{"epoch": 11, "training_loss": 462.49685821533205, "training_acc": 55.0, "val_loss": 541.5609741210938, "val_acc": 60.0}
{"epoch": 12, "training_loss": 780.3092895507813, "training_acc": 45.0, "val_loss": 977.5275268554688, "val_acc": 60.0}
{"epoch": 13, "training_loss": 1320.5796875, "training_acc": 45.0, "val_loss": 610.6633911132812, "val_acc": 60.0}
{"epoch": 14, "training_loss": 779.9996337890625, "training_acc": 45.0, "val_loss": 573.6936645507812, "val_acc": 40.0}
{"epoch": 15, "training_loss": 465.69761352539064, "training_acc": 55.0, "val_loss": 1231.158447265625, "val_acc": 40.0}
{"epoch": 16, "training_loss": 922.9197265625, "training_acc": 55.0, "val_loss": 989.8250122070312, "val_acc": 40.0}
{"epoch": 17, "training_loss": 681.0040649414062, "training_acc": 55.0, "val_loss": 19.72977638244629, "val_acc": 40.0}
{"epoch": 18, "training_loss": 136.56828689575195, "training_acc": 55.0, "val_loss": 777.2171630859375, "val_acc": 60.0}
{"epoch": 19, "training_loss": 1089.788671875, "training_acc": 45.0, "val_loss": 614.8508911132812, "val_acc": 60.0}
{"epoch": 20, "training_loss": 702.980615234375, "training_acc": 45.0, "val_loss": 529.7407836914062, "val_acc": 40.0}
{"epoch": 21, "training_loss": 491.656494140625, "training_acc": 55.0, "val_loss": 1333.5611572265625, "val_acc": 40.0}
{"epoch": 22, "training_loss": 1000.03583984375, "training_acc": 55.0, "val_loss": 933.3707885742188, "val_acc": 40.0}
{"epoch": 23, "training_loss": 559.0872009277343, "training_acc": 55.0, "val_loss": 334.3017578125, "val_acc": 60.0}
{"epoch": 24, "training_loss": 646.330322265625, "training_acc": 45.0, "val_loss": 709.5323486328125, "val_acc": 60.0}
{"epoch": 25, "training_loss": 910.9207397460938, "training_acc": 45.0, "val_loss": 139.89378356933594, "val_acc": 60.0}
{"epoch": 26, "training_loss": 255.69176025390624, "training_acc": 45.0, "val_loss": 1068.33837890625, "val_acc": 40.0}
{"epoch": 27, "training_loss": 834.7728515625, "training_acc": 55.0, "val_loss": 1194.6685791015625, "val_acc": 40.0}
{"epoch": 28, "training_loss": 896.1087890625, "training_acc": 55.0, "val_loss": 497.81884765625, "val_acc": 40.0}
{"epoch": 29, "training_loss": 294.59922752380373, "training_acc": 55.0, "val_loss": 175.27252197265625, "val_acc": 60.0}
{"epoch": 30, "training_loss": 233.79652709960936, "training_acc": 45.0, "val_loss": 143.99595642089844, "val_acc": 40.0}
{"epoch": 31, "training_loss": 148.6818420410156, "training_acc": 55.0, "val_loss": 100.0417251586914, "val_acc": 40.0}
{"epoch": 32, "training_loss": 147.0798583984375, "training_acc": 45.0, "val_loss": 230.8341522216797, "val_acc": 60.0}
{"epoch": 33, "training_loss": 276.0767456054688, "training_acc": 45.0, "val_loss": 353.6371765136719, "val_acc": 40.0}
{"epoch": 34, "training_loss": 279.18799743652346, "training_acc": 55.0, "val_loss": 550.8863525390625, "val_acc": 40.0}
{"epoch": 35, "training_loss": 394.59730834960936, "training_acc": 55.0, "val_loss": 7.319729804992676, "val_acc": 40.0}
{"epoch": 36, "training_loss": 134.2806381225586, "training_acc": 45.0, "val_loss": 419.1720886230469, "val_acc": 60.0}
{"epoch": 37, "training_loss": 536.7667724609375, "training_acc": 45.0, "val_loss": 63.67637252807617, "val_acc": 40.0}
{"epoch": 38, "training_loss": 71.53106689453125, "training_acc": 55.0, "val_loss": 485.869140625, "val_acc": 40.0}
{"epoch": 39, "training_loss": 349.3574279785156, "training_acc": 55.0, "val_loss": 75.20922088623047, "val_acc": 40.0}
{"epoch": 40, "training_loss": 161.86881103515626, "training_acc": 45.0, "val_loss": 373.1767272949219, "val_acc": 60.0}
{"epoch": 41, "training_loss": 484.450390625, "training_acc": 45.0, "val_loss": 1.3730971813201904, "val_acc": 40.0}
{"epoch": 42, "training_loss": 15.478088855743408, "training_acc": 55.0, "val_loss": 212.45201110839844, "val_acc": 40.0}
{"epoch": 43, "training_loss": 130.29207916259764, "training_acc": 55.0, "val_loss": 235.3264923095703, "val_acc": 60.0}
{"epoch": 44, "training_loss": 336.820068359375, "training_acc": 45.0, "val_loss": 178.02468872070312, "val_acc": 60.0}
{"epoch": 45, "training_loss": 225.19531860351563, "training_acc": 45.0, "val_loss": 292.6103515625, "val_acc": 40.0}
{"epoch": 46, "training_loss": 205.33139343261718, "training_acc": 55.0, "val_loss": 69.53670501708984, "val_acc": 60.0}
{"epoch": 47, "training_loss": 106.89701232910156, "training_acc": 45.0, "val_loss": 160.07858276367188, "val_acc": 40.0}
{"epoch": 48, "training_loss": 123.49697723388672, "training_acc": 55.0, "val_loss": 121.30268859863281, "val_acc": 40.0}
{"epoch": 49, "training_loss": 71.47878646850586, "training_acc": 65.0, "val_loss": 159.35467529296875, "val_acc": 60.0}
{"epoch": 50, "training_loss": 180.57231750488282, "training_acc": 45.0, "val_loss": 445.669189453125, "val_acc": 40.0}
{"epoch": 51, "training_loss": 356.66192626953125, "training_acc": 55.0, "val_loss": 827.9137573242188, "val_acc": 40.0}
{"epoch": 52, "training_loss": 620.959033203125, "training_acc": 55.0, "val_loss": 470.18408203125, "val_acc": 40.0}
{"epoch": 53, "training_loss": 318.7592998504639, "training_acc": 55.0, "val_loss": 279.9930114746094, "val_acc": 60.0}
{"epoch": 54, "training_loss": 432.515771484375, "training_acc": 45.0, "val_loss": 278.6116638183594, "val_acc": 60.0}
{"epoch": 55, "training_loss": 411.5252349853516, "training_acc": 25.0, "val_loss": 71.29627227783203, "val_acc": 40.0}
{"epoch": 56, "training_loss": 45.352404022216795, "training_acc": 65.0, "val_loss": 113.96990203857422, "val_acc": 60.0}
{"epoch": 57, "training_loss": 136.02673873901367, "training_acc": 45.0, "val_loss": 10.798502922058105, "val_acc": 40.0}
{"epoch": 58, "training_loss": 21.78330307006836, "training_acc": 65.0, "val_loss": 176.66152954101562, "val_acc": 60.0}
{"epoch": 59, "training_loss": 197.6636993408203, "training_acc": 45.0, "val_loss": 428.3805236816406, "val_acc": 40.0}
{"epoch": 60, "training_loss": 362.60771484375, "training_acc": 55.0, "val_loss": 651.9560546875, "val_acc": 40.0}
