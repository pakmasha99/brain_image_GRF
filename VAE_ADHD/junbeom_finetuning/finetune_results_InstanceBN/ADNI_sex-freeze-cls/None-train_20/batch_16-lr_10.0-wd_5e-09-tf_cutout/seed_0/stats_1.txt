"main_modify.py --pretrained_path None --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_sex --input_option yAware --learning_rate 1e1 --batch_size 16 --weight_decay 5e-9 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 428.9779066085815, "training_acc": 50.0, "val_loss": 757.94580078125, "val_acc": 40.0}
{"epoch": 1, "training_loss": 557.2428466796875, "training_acc": 60.0, "val_loss": 1658.8939208984375, "val_acc": 60.0}
{"epoch": 2, "training_loss": 2067.6469482421876, "training_acc": 50.0, "val_loss": 1165.2830810546875, "val_acc": 60.0}
{"epoch": 3, "training_loss": 1269.002587890625, "training_acc": 50.0, "val_loss": 809.2188110351562, "val_acc": 40.0}
{"epoch": 4, "training_loss": 726.9405517578125, "training_acc": 50.0, "val_loss": 1760.9549560546875, "val_acc": 40.0}
{"epoch": 5, "training_loss": 1442.593408203125, "training_acc": 50.0, "val_loss": 1076.9356689453125, "val_acc": 40.0}
{"epoch": 6, "training_loss": 697.9421508789062, "training_acc": 50.0, "val_loss": 602.507080078125, "val_acc": 60.0}
{"epoch": 7, "training_loss": 806.7098999023438, "training_acc": 50.0, "val_loss": 1299.8822021484375, "val_acc": 60.0}
{"epoch": 8, "training_loss": 1629.652734375, "training_acc": 50.0, "val_loss": 1122.63427734375, "val_acc": 60.0}
{"epoch": 9, "training_loss": 1307.97587890625, "training_acc": 50.0, "val_loss": 197.8975372314453, "val_acc": 60.0}
{"epoch": 10, "training_loss": 509.358642578125, "training_acc": 30.0, "val_loss": 1133.7279052734375, "val_acc": 40.0}
{"epoch": 11, "training_loss": 951.1254150390625, "training_acc": 50.0, "val_loss": 936.9728393554688, "val_acc": 40.0}
{"epoch": 12, "training_loss": 701.082763671875, "training_acc": 50.0, "val_loss": 155.7285614013672, "val_acc": 60.0}
{"epoch": 13, "training_loss": 254.8550231933594, "training_acc": 50.0, "val_loss": 430.06427001953125, "val_acc": 60.0}
{"epoch": 14, "training_loss": 517.9497009277344, "training_acc": 50.0, "val_loss": 31.548200607299805, "val_acc": 60.0}
{"epoch": 15, "training_loss": 120.43299255371093, "training_acc": 50.0, "val_loss": 787.7709350585938, "val_acc": 40.0}
{"epoch": 16, "training_loss": 657.1648193359375, "training_acc": 50.0, "val_loss": 410.1205749511719, "val_acc": 40.0}
{"epoch": 17, "training_loss": 361.49041137695315, "training_acc": 40.0, "val_loss": 263.3402099609375, "val_acc": 60.0}
{"epoch": 18, "training_loss": 316.03155517578125, "training_acc": 50.0, "val_loss": 81.34466552734375, "val_acc": 40.0}
{"epoch": 19, "training_loss": 132.08382873535157, "training_acc": 50.0, "val_loss": 20.89788818359375, "val_acc": 60.0}
{"epoch": 20, "training_loss": 44.2908447265625, "training_acc": 50.0, "val_loss": 191.2638397216797, "val_acc": 40.0}
{"epoch": 21, "training_loss": 172.97606811523437, "training_acc": 50.0, "val_loss": 33.70864486694336, "val_acc": 60.0}
{"epoch": 22, "training_loss": 49.669212341308594, "training_acc": 50.0, "val_loss": 113.2206039428711, "val_acc": 40.0}
{"epoch": 23, "training_loss": 87.47001342773437, "training_acc": 50.0, "val_loss": 186.80960083007812, "val_acc": 60.0}
{"epoch": 24, "training_loss": 252.1447998046875, "training_acc": 50.0, "val_loss": 158.2872772216797, "val_acc": 60.0}
{"epoch": 25, "training_loss": 217.98704528808594, "training_acc": 40.0, "val_loss": 154.66275024414062, "val_acc": 40.0}
{"epoch": 26, "training_loss": 140.78518676757812, "training_acc": 40.0, "val_loss": 9.0706205368042, "val_acc": 40.0}
{"epoch": 27, "training_loss": 12.261984252929688, "training_acc": 60.0, "val_loss": 39.930389404296875, "val_acc": 60.0}
{"epoch": 28, "training_loss": 73.29722290039062, "training_acc": 50.0, "val_loss": 191.4464874267578, "val_acc": 40.0}
{"epoch": 29, "training_loss": 160.13418426513672, "training_acc": 40.0, "val_loss": 38.07442092895508, "val_acc": 40.0}
{"epoch": 30, "training_loss": 58.376895141601565, "training_acc": 40.0, "val_loss": 79.0761489868164, "val_acc": 40.0}
{"epoch": 31, "training_loss": 59.66770782470703, "training_acc": 50.0, "val_loss": 198.8894805908203, "val_acc": 60.0}
{"epoch": 32, "training_loss": 267.1098266601563, "training_acc": 50.0, "val_loss": 167.86888122558594, "val_acc": 60.0}
{"epoch": 33, "training_loss": 154.49602355957032, "training_acc": 60.0, "val_loss": 258.2223815917969, "val_acc": 40.0}
{"epoch": 34, "training_loss": 202.73837890625, "training_acc": 50.0, "val_loss": 64.7318115234375, "val_acc": 60.0}
{"epoch": 35, "training_loss": 97.93148193359374, "training_acc": 50.0, "val_loss": 131.7987518310547, "val_acc": 40.0}
{"epoch": 36, "training_loss": 109.22015914916992, "training_acc": 50.0, "val_loss": 22.603971481323242, "val_acc": 40.0}
{"epoch": 37, "training_loss": 65.4126983642578, "training_acc": 50.0, "val_loss": 250.77685546875, "val_acc": 60.0}
{"epoch": 38, "training_loss": 277.954248046875, "training_acc": 50.0, "val_loss": 295.60137939453125, "val_acc": 40.0}
{"epoch": 39, "training_loss": 291.2621215820312, "training_acc": 50.0, "val_loss": 588.995361328125, "val_acc": 40.0}
{"epoch": 40, "training_loss": 442.2371337890625, "training_acc": 50.0, "val_loss": 71.32527160644531, "val_acc": 60.0}
{"epoch": 41, "training_loss": 91.78717041015625, "training_acc": 50.0, "val_loss": 292.1627502441406, "val_acc": 60.0}
{"epoch": 42, "training_loss": 358.0568878173828, "training_acc": 50.0, "val_loss": 63.28504180908203, "val_acc": 60.0}
{"epoch": 43, "training_loss": 82.07996368408203, "training_acc": 60.0, "val_loss": 555.8231811523438, "val_acc": 40.0}
{"epoch": 44, "training_loss": 460.07073974609375, "training_acc": 50.0, "val_loss": 303.0506896972656, "val_acc": 40.0}
{"epoch": 45, "training_loss": 271.8703369140625, "training_acc": 40.0, "val_loss": 170.61329650878906, "val_acc": 60.0}
