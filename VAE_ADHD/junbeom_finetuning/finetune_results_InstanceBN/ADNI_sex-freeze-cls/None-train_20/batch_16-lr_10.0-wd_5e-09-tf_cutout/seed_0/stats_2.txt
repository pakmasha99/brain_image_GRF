"main_modify.py --pretrained_path None --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_sex --input_option yAware --learning_rate 1e1 --batch_size 16 --weight_decay 5e-9 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 857.9836062431335, "training_acc": 45.0, "val_loss": 881.8363647460938, "val_acc": 40.0}
{"epoch": 1, "training_loss": 757.8596313476562, "training_acc": 50.0, "val_loss": 1225.0499267578125, "val_acc": 60.0}
{"epoch": 2, "training_loss": 1573.762890625, "training_acc": 50.0, "val_loss": 986.43798828125, "val_acc": 60.0}
{"epoch": 3, "training_loss": 1028.1257080078126, "training_acc": 50.0, "val_loss": 533.5130615234375, "val_acc": 40.0}
{"epoch": 4, "training_loss": 496.31097412109375, "training_acc": 50.0, "val_loss": 1539.770751953125, "val_acc": 40.0}
{"epoch": 5, "training_loss": 1293.421875, "training_acc": 50.0, "val_loss": 1167.1605224609375, "val_acc": 40.0}
{"epoch": 6, "training_loss": 914.3312408447266, "training_acc": 50.0, "val_loss": 198.6848602294922, "val_acc": 60.0}
{"epoch": 7, "training_loss": 312.9622436523438, "training_acc": 50.0, "val_loss": 502.1673278808594, "val_acc": 60.0}
{"epoch": 8, "training_loss": 605.2520141601562, "training_acc": 50.0, "val_loss": 88.16744995117188, "val_acc": 60.0}
{"epoch": 9, "training_loss": 165.4512451171875, "training_acc": 50.0, "val_loss": 729.6293334960938, "val_acc": 40.0}
{"epoch": 10, "training_loss": 607.646533203125, "training_acc": 50.0, "val_loss": 341.8548583984375, "val_acc": 40.0}
{"epoch": 11, "training_loss": 218.3621795654297, "training_acc": 60.0, "val_loss": 416.4211120605469, "val_acc": 60.0}
{"epoch": 12, "training_loss": 534.0661376953125, "training_acc": 50.0, "val_loss": 359.44097900390625, "val_acc": 60.0}
{"epoch": 13, "training_loss": 351.7597351074219, "training_acc": 50.0, "val_loss": 559.39501953125, "val_acc": 40.0}
{"epoch": 14, "training_loss": 530.603466796875, "training_acc": 50.0, "val_loss": 1049.4964599609375, "val_acc": 40.0}
{"epoch": 15, "training_loss": 847.40380859375, "training_acc": 50.0, "val_loss": 496.8067932128906, "val_acc": 40.0}
{"epoch": 16, "training_loss": 295.9884307861328, "training_acc": 60.0, "val_loss": 313.4012145996094, "val_acc": 60.0}
{"epoch": 17, "training_loss": 395.4691528320312, "training_acc": 50.0, "val_loss": 319.94976806640625, "val_acc": 60.0}
{"epoch": 18, "training_loss": 346.6945495605469, "training_acc": 50.0, "val_loss": 356.23663330078125, "val_acc": 40.0}
{"epoch": 19, "training_loss": 360.330908203125, "training_acc": 50.0, "val_loss": 464.93682861328125, "val_acc": 40.0}
{"epoch": 20, "training_loss": 299.0834655761719, "training_acc": 50.0, "val_loss": 377.0777282714844, "val_acc": 60.0}
{"epoch": 21, "training_loss": 529.3941162109375, "training_acc": 50.0, "val_loss": 676.9560546875, "val_acc": 60.0}
{"epoch": 22, "training_loss": 814.6254638671875, "training_acc": 50.0, "val_loss": 297.0665588378906, "val_acc": 60.0}
{"epoch": 23, "training_loss": 378.3401245117187, "training_acc": 40.0, "val_loss": 390.2816162109375, "val_acc": 40.0}
{"epoch": 24, "training_loss": 316.9146041870117, "training_acc": 50.0, "val_loss": 92.66969299316406, "val_acc": 40.0}
{"epoch": 25, "training_loss": 159.2032958984375, "training_acc": 40.0, "val_loss": 275.90374755859375, "val_acc": 60.0}
{"epoch": 26, "training_loss": 322.55379486083984, "training_acc": 50.0, "val_loss": 143.66407775878906, "val_acc": 40.0}
{"epoch": 27, "training_loss": 128.3958740234375, "training_acc": 50.0, "val_loss": 2.028002977371216, "val_acc": 40.0}
{"epoch": 28, "training_loss": 62.684686279296876, "training_acc": 50.0, "val_loss": 309.164794921875, "val_acc": 60.0}
{"epoch": 29, "training_loss": 356.2962127685547, "training_acc": 50.0, "val_loss": 87.66462707519531, "val_acc": 40.0}
{"epoch": 30, "training_loss": 107.58399047851563, "training_acc": 50.0, "val_loss": 12.168926239013672, "val_acc": 60.0}
{"epoch": 31, "training_loss": 12.850558853149414, "training_acc": 50.0, "val_loss": 333.9240417480469, "val_acc": 40.0}
{"epoch": 32, "training_loss": 282.3372741699219, "training_acc": 50.0, "val_loss": 307.2250671386719, "val_acc": 40.0}
{"epoch": 33, "training_loss": 204.56746649742126, "training_acc": 50.0, "val_loss": 153.2571563720703, "val_acc": 60.0}
{"epoch": 34, "training_loss": 186.7798828125, "training_acc": 50.0, "val_loss": 22.055418014526367, "val_acc": 60.0}
{"epoch": 35, "training_loss": 67.53603668212891, "training_acc": 50.0, "val_loss": 348.758544921875, "val_acc": 40.0}
{"epoch": 36, "training_loss": 271.2235466003418, "training_acc": 50.0, "val_loss": 143.0865020751953, "val_acc": 60.0}
{"epoch": 37, "training_loss": 182.45775756835937, "training_acc": 50.0, "val_loss": 44.36946487426758, "val_acc": 60.0}
{"epoch": 38, "training_loss": 62.102133178710936, "training_acc": 60.0, "val_loss": 566.0424194335938, "val_acc": 40.0}
{"epoch": 39, "training_loss": 469.7658935546875, "training_acc": 50.0, "val_loss": 181.71875, "val_acc": 40.0}
{"epoch": 40, "training_loss": 137.3998992919922, "training_acc": 60.0, "val_loss": 504.3273620605469, "val_acc": 60.0}
{"epoch": 41, "training_loss": 640.527392578125, "training_acc": 50.0, "val_loss": 455.0547790527344, "val_acc": 60.0}
{"epoch": 42, "training_loss": 496.0503845214844, "training_acc": 50.0, "val_loss": 327.31353759765625, "val_acc": 40.0}
{"epoch": 43, "training_loss": 295.04795227050784, "training_acc": 50.0, "val_loss": 710.9486694335938, "val_acc": 40.0}
{"epoch": 44, "training_loss": 568.220947265625, "training_acc": 50.0, "val_loss": 183.0560760498047, "val_acc": 40.0}
{"epoch": 45, "training_loss": 189.09132080078126, "training_acc": 50.0, "val_loss": 464.8731994628906, "val_acc": 60.0}
{"epoch": 46, "training_loss": 574.52666015625, "training_acc": 50.0, "val_loss": 392.163330078125, "val_acc": 60.0}
