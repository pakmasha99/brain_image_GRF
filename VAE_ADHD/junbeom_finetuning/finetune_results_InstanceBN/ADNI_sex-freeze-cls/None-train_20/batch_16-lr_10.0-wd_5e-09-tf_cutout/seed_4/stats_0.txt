"main_modify.py --pretrained_path None --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 4 --task ADNI_sex --input_option yAware --learning_rate 1e1 --batch_size 16 --weight_decay 5e-9 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 429.93005523681643, "training_acc": 50.0, "val_loss": 738.1557006835938, "val_acc": 40.0}
{"epoch": 1, "training_loss": 912.419873046875, "training_acc": 40.0, "val_loss": 1093.8443603515625, "val_acc": 60.0}
{"epoch": 2, "training_loss": 1325.0375549316407, "training_acc": 50.0, "val_loss": 290.1551818847656, "val_acc": 60.0}
{"epoch": 3, "training_loss": 492.4385131835937, "training_acc": 40.0, "val_loss": 891.5146484375, "val_acc": 40.0}
{"epoch": 4, "training_loss": 742.9140625, "training_acc": 50.0, "val_loss": 349.1935119628906, "val_acc": 40.0}
{"epoch": 5, "training_loss": 219.3388442993164, "training_acc": 60.0, "val_loss": 325.6556701660156, "val_acc": 60.0}
{"epoch": 6, "training_loss": 396.01001892089846, "training_acc": 50.0, "val_loss": 53.74577713012695, "val_acc": 60.0}
{"epoch": 7, "training_loss": 192.2681884765625, "training_acc": 40.0, "val_loss": 586.7501831054688, "val_acc": 40.0}
{"epoch": 8, "training_loss": 435.56580810546876, "training_acc": 50.0, "val_loss": 158.30804443359375, "val_acc": 60.0}
{"epoch": 9, "training_loss": 215.6480682373047, "training_acc": 50.0, "val_loss": 348.01214599609375, "val_acc": 60.0}
{"epoch": 10, "training_loss": 396.7581359863281, "training_acc": 50.0, "val_loss": 177.0650177001953, "val_acc": 40.0}
{"epoch": 11, "training_loss": 156.90416870117187, "training_acc": 50.0, "val_loss": 261.42193603515625, "val_acc": 40.0}
{"epoch": 12, "training_loss": 180.11967010498046, "training_acc": 50.0, "val_loss": 24.09853172302246, "val_acc": 60.0}
{"epoch": 13, "training_loss": 92.09762268066406, "training_acc": 40.0, "val_loss": 140.54312133789062, "val_acc": 40.0}
{"epoch": 14, "training_loss": 131.487158203125, "training_acc": 50.0, "val_loss": 203.13723754882812, "val_acc": 60.0}
{"epoch": 15, "training_loss": 220.5303756713867, "training_acc": 50.0, "val_loss": 312.4463806152344, "val_acc": 40.0}
{"epoch": 16, "training_loss": 281.1896240234375, "training_acc": 50.0, "val_loss": 299.6720275878906, "val_acc": 40.0}
{"epoch": 17, "training_loss": 295.5605407714844, "training_acc": 30.0, "val_loss": 24.9217586517334, "val_acc": 60.0}
{"epoch": 18, "training_loss": 43.25545654296875, "training_acc": 60.0, "val_loss": 426.6437072753906, "val_acc": 40.0}
{"epoch": 19, "training_loss": 343.9548110961914, "training_acc": 50.0, "val_loss": 44.799232482910156, "val_acc": 40.0}
{"epoch": 20, "training_loss": 146.0728302001953, "training_acc": 40.0, "val_loss": 354.6743469238281, "val_acc": 60.0}
{"epoch": 21, "training_loss": 411.9883972167969, "training_acc": 50.0, "val_loss": 40.2269287109375, "val_acc": 40.0}
{"epoch": 22, "training_loss": 52.380712890625, "training_acc": 50.0, "val_loss": 16.941709518432617, "val_acc": 40.0}
{"epoch": 23, "training_loss": 68.9526351928711, "training_acc": 50.0, "val_loss": 294.0379943847656, "val_acc": 60.0}
{"epoch": 24, "training_loss": 330.7924072265625, "training_acc": 50.0, "val_loss": 175.8644256591797, "val_acc": 40.0}
{"epoch": 25, "training_loss": 230.154052734375, "training_acc": 50.0, "val_loss": 178.62278747558594, "val_acc": 40.0}
{"epoch": 26, "training_loss": 88.79696044921874, "training_acc": 70.0, "val_loss": 397.5527648925781, "val_acc": 60.0}
{"epoch": 27, "training_loss": 509.241015625, "training_acc": 50.0, "val_loss": 352.9361267089844, "val_acc": 60.0}
{"epoch": 28, "training_loss": 373.7174346923828, "training_acc": 50.0, "val_loss": 441.8952331542969, "val_acc": 40.0}
{"epoch": 29, "training_loss": 388.7095947265625, "training_acc": 50.0, "val_loss": 809.319580078125, "val_acc": 40.0}
{"epoch": 30, "training_loss": 658.6178771972657, "training_acc": 50.0, "val_loss": 358.65087890625, "val_acc": 40.0}
{"epoch": 31, "training_loss": 307.5651031494141, "training_acc": 40.0, "val_loss": 181.2501983642578, "val_acc": 60.0}
{"epoch": 32, "training_loss": 198.5952163696289, "training_acc": 50.0, "val_loss": 249.96142578125, "val_acc": 40.0}
{"epoch": 33, "training_loss": 212.05189514160156, "training_acc": 50.0, "val_loss": 251.2634735107422, "val_acc": 40.0}
{"epoch": 34, "training_loss": 174.42961578369142, "training_acc": 50.0, "val_loss": 51.444820404052734, "val_acc": 60.0}
{"epoch": 35, "training_loss": 71.11898040771484, "training_acc": 50.0, "val_loss": 97.48877716064453, "val_acc": 40.0}
{"epoch": 36, "training_loss": 94.9385498046875, "training_acc": 50.0, "val_loss": 134.7666015625, "val_acc": 60.0}
{"epoch": 37, "training_loss": 106.73975830078125, "training_acc": 50.0, "val_loss": 604.8316040039062, "val_acc": 40.0}
{"epoch": 38, "training_loss": 502.651171875, "training_acc": 50.0, "val_loss": 1117.36572265625, "val_acc": 40.0}
{"epoch": 39, "training_loss": 925.3605346679688, "training_acc": 50.0, "val_loss": 895.9609375, "val_acc": 40.0}
{"epoch": 40, "training_loss": 654.1892211914062, "training_acc": 50.0, "val_loss": 106.2594223022461, "val_acc": 60.0}
{"epoch": 41, "training_loss": 274.97340698242186, "training_acc": 50.0, "val_loss": 341.537841796875, "val_acc": 60.0}
