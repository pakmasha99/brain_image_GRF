"main_modify.py --pretrained_path None --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 5 --task ADNI_sex --input_option yAware --learning_rate 1e1 --batch_size 16 --weight_decay 5e-9 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 168.87931966781616, "training_acc": 50.0, "val_loss": 815.8307495117188, "val_acc": 60.0}
{"epoch": 1, "training_loss": 1139.7396484375, "training_acc": 50.0, "val_loss": 648.4308471679688, "val_acc": 60.0}
{"epoch": 2, "training_loss": 578.3191585540771, "training_acc": 60.0, "val_loss": 688.2587280273438, "val_acc": 40.0}
{"epoch": 3, "training_loss": 590.4788330078125, "training_acc": 50.0, "val_loss": 205.5245819091797, "val_acc": 40.0}
{"epoch": 4, "training_loss": 169.04165649414062, "training_acc": 60.0, "val_loss": 765.5341186523438, "val_acc": 60.0}
{"epoch": 5, "training_loss": 980.665869140625, "training_acc": 50.0, "val_loss": 641.00244140625, "val_acc": 60.0}
{"epoch": 6, "training_loss": 672.951904296875, "training_acc": 50.0, "val_loss": 499.3119812011719, "val_acc": 40.0}
{"epoch": 7, "training_loss": 493.9247192382812, "training_acc": 50.0, "val_loss": 1145.600830078125, "val_acc": 40.0}
{"epoch": 8, "training_loss": 949.565625, "training_acc": 50.0, "val_loss": 682.6520385742188, "val_acc": 40.0}
{"epoch": 9, "training_loss": 451.3172668457031, "training_acc": 50.0, "val_loss": 376.9107971191406, "val_acc": 60.0}
{"epoch": 10, "training_loss": 512.0094482421875, "training_acc": 50.0, "val_loss": 799.8954467773438, "val_acc": 60.0}
{"epoch": 11, "training_loss": 997.4864990234375, "training_acc": 50.0, "val_loss": 531.82666015625, "val_acc": 60.0}
{"epoch": 12, "training_loss": 578.1675720214844, "training_acc": 50.0, "val_loss": 530.7123413085938, "val_acc": 40.0}
{"epoch": 13, "training_loss": 508.3469482421875, "training_acc": 50.0, "val_loss": 1075.298583984375, "val_acc": 40.0}
{"epoch": 14, "training_loss": 860.140966796875, "training_acc": 50.0, "val_loss": 453.6910705566406, "val_acc": 40.0}
{"epoch": 15, "training_loss": 341.1779846191406, "training_acc": 50.0, "val_loss": 406.8074645996094, "val_acc": 60.0}
{"epoch": 16, "training_loss": 530.8404907226562, "training_acc": 50.0, "val_loss": 337.9878845214844, "val_acc": 60.0}
{"epoch": 17, "training_loss": 333.78338317871095, "training_acc": 50.0, "val_loss": 588.86865234375, "val_acc": 40.0}
{"epoch": 18, "training_loss": 516.3556396484375, "training_acc": 50.0, "val_loss": 1157.2078857421875, "val_acc": 40.0}
{"epoch": 19, "training_loss": 948.46484375, "training_acc": 50.0, "val_loss": 715.66015625, "val_acc": 40.0}
{"epoch": 20, "training_loss": 491.65556640625, "training_acc": 50.0, "val_loss": 455.9173278808594, "val_acc": 60.0}
{"epoch": 21, "training_loss": 616.6956665039063, "training_acc": 50.0, "val_loss": 930.7527465820312, "val_acc": 60.0}
{"epoch": 22, "training_loss": 1169.4419189453124, "training_acc": 50.0, "val_loss": 803.3239135742188, "val_acc": 60.0}
{"epoch": 23, "training_loss": 949.1583740234375, "training_acc": 50.0, "val_loss": 140.18017578125, "val_acc": 60.0}
{"epoch": 24, "training_loss": 176.0786376953125, "training_acc": 60.0, "val_loss": 1106.5106201171875, "val_acc": 40.0}
{"epoch": 25, "training_loss": 938.3965454101562, "training_acc": 50.0, "val_loss": 1406.586181640625, "val_acc": 40.0}
{"epoch": 26, "training_loss": 1126.9703125, "training_acc": 50.0, "val_loss": 679.8469848632812, "val_acc": 40.0}
{"epoch": 27, "training_loss": 618.4173400878906, "training_acc": 30.0, "val_loss": 280.521240234375, "val_acc": 60.0}
{"epoch": 28, "training_loss": 358.6741088867187, "training_acc": 50.0, "val_loss": 156.77528381347656, "val_acc": 60.0}
{"epoch": 29, "training_loss": 183.29024658203124, "training_acc": 50.0, "val_loss": 229.1780242919922, "val_acc": 40.0}
{"epoch": 30, "training_loss": 171.99678802490234, "training_acc": 50.0, "val_loss": 153.1360626220703, "val_acc": 60.0}
{"epoch": 31, "training_loss": 205.25787658691405, "training_acc": 50.0, "val_loss": 10.180543899536133, "val_acc": 60.0}
{"epoch": 32, "training_loss": 87.11822509765625, "training_acc": 50.0, "val_loss": 584.8755493164062, "val_acc": 40.0}
{"epoch": 33, "training_loss": 466.4746520996094, "training_acc": 50.0, "val_loss": 152.10044860839844, "val_acc": 40.0}
{"epoch": 34, "training_loss": 163.51620483398438, "training_acc": 50.0, "val_loss": 417.0604553222656, "val_acc": 60.0}
{"epoch": 35, "training_loss": 530.0606567382813, "training_acc": 50.0, "val_loss": 181.78701782226562, "val_acc": 60.0}
{"epoch": 36, "training_loss": 186.74515228271486, "training_acc": 60.0, "val_loss": 615.9993286132812, "val_acc": 40.0}
{"epoch": 37, "training_loss": 515.3321838378906, "training_acc": 50.0, "val_loss": 590.3305053710938, "val_acc": 40.0}
{"epoch": 38, "training_loss": 456.9837921142578, "training_acc": 50.0, "val_loss": 119.55268859863281, "val_acc": 60.0}
{"epoch": 39, "training_loss": 204.61044921875, "training_acc": 50.0, "val_loss": 96.8018569946289, "val_acc": 60.0}
{"epoch": 40, "training_loss": 149.4275390625, "training_acc": 50.0, "val_loss": 423.93511962890625, "val_acc": 40.0}
{"epoch": 41, "training_loss": 337.43295135498045, "training_acc": 50.0, "val_loss": 23.0860652923584, "val_acc": 40.0}
{"epoch": 42, "training_loss": 133.78644714355468, "training_acc": 40.0, "val_loss": 370.3486633300781, "val_acc": 60.0}
{"epoch": 43, "training_loss": 444.9245361328125, "training_acc": 50.0, "val_loss": 0.28726842999458313, "val_acc": 80.0}
{"epoch": 44, "training_loss": 87.04702415466309, "training_acc": 55.0, "val_loss": 742.15234375, "val_acc": 40.0}
{"epoch": 45, "training_loss": 610.4707885742188, "training_acc": 50.0, "val_loss": 344.4466552734375, "val_acc": 40.0}
{"epoch": 46, "training_loss": 268.22040405273435, "training_acc": 50.0, "val_loss": 343.8677673339844, "val_acc": 60.0}
{"epoch": 47, "training_loss": 438.1615234375, "training_acc": 50.0, "val_loss": 279.4914245605469, "val_acc": 60.0}
{"epoch": 48, "training_loss": 334.23490753173826, "training_acc": 50.0, "val_loss": 295.7192077636719, "val_acc": 40.0}
{"epoch": 49, "training_loss": 278.24940185546876, "training_acc": 50.0, "val_loss": 218.34927368164062, "val_acc": 40.0}
{"epoch": 50, "training_loss": 228.0456970214844, "training_acc": 40.0, "val_loss": 212.04527282714844, "val_acc": 60.0}
{"epoch": 51, "training_loss": 246.25167083740234, "training_acc": 50.0, "val_loss": 262.4919738769531, "val_acc": 40.0}
{"epoch": 52, "training_loss": 232.78914794921874, "training_acc": 50.0, "val_loss": 255.43162536621094, "val_acc": 40.0}
{"epoch": 53, "training_loss": 183.86163940429688, "training_acc": 50.0, "val_loss": 117.48664855957031, "val_acc": 60.0}
{"epoch": 54, "training_loss": 128.223091506958, "training_acc": 50.0, "val_loss": 378.0950927734375, "val_acc": 40.0}
{"epoch": 55, "training_loss": 345.7779052734375, "training_acc": 50.0, "val_loss": 285.21051025390625, "val_acc": 40.0}
{"epoch": 56, "training_loss": 215.39238891601562, "training_acc": 50.0, "val_loss": 216.83056640625, "val_acc": 60.0}
{"epoch": 57, "training_loss": 273.6418060302734, "training_acc": 50.0, "val_loss": 17.453855514526367, "val_acc": 40.0}
{"epoch": 58, "training_loss": 37.24343414306641, "training_acc": 30.0, "val_loss": 322.716796875, "val_acc": 40.0}
{"epoch": 59, "training_loss": 304.1689086914063, "training_acc": 50.0, "val_loss": 241.13291931152344, "val_acc": 40.0}
{"epoch": 60, "training_loss": 149.6761932373047, "training_acc": 60.0, "val_loss": 278.09381103515625, "val_acc": 60.0}
{"epoch": 61, "training_loss": 356.1744079589844, "training_acc": 50.0, "val_loss": 143.2483367919922, "val_acc": 60.0}
{"epoch": 62, "training_loss": 112.94815673828126, "training_acc": 70.0, "val_loss": 390.1873474121094, "val_acc": 40.0}
