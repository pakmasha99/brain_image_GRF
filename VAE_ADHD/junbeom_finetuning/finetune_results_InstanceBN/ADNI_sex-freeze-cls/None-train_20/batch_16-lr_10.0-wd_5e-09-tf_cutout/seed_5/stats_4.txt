"main_modify.py --pretrained_path None --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 5 --task ADNI_sex --input_option yAware --learning_rate 1e1 --batch_size 16 --weight_decay 5e-9 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 215.37343873977662, "training_acc": 60.0, "val_loss": 731.8565673828125, "val_acc": 60.0}
{"epoch": 1, "training_loss": 548.405029296875, "training_acc": 70.0, "val_loss": 2553.314208984375, "val_acc": 40.0}
{"epoch": 2, "training_loss": 2133.3396484375, "training_acc": 50.0, "val_loss": 1557.8316650390625, "val_acc": 40.0}
{"epoch": 3, "training_loss": 1066.9246856689454, "training_acc": 50.0, "val_loss": 980.6771850585938, "val_acc": 60.0}
{"epoch": 4, "training_loss": 1459.945654296875, "training_acc": 50.0, "val_loss": 1671.009765625, "val_acc": 60.0}
{"epoch": 5, "training_loss": 2034.123193359375, "training_acc": 50.0, "val_loss": 1027.3499755859375, "val_acc": 60.0}
{"epoch": 6, "training_loss": 1000.7395263671875, "training_acc": 50.0, "val_loss": 600.4097290039062, "val_acc": 40.0}
{"epoch": 7, "training_loss": 565.13525390625, "training_acc": 50.0, "val_loss": 1927.4482421875, "val_acc": 40.0}
{"epoch": 8, "training_loss": 1617.5342407226562, "training_acc": 50.0, "val_loss": 2048.671875, "val_acc": 40.0}
{"epoch": 9, "training_loss": 1637.15615234375, "training_acc": 50.0, "val_loss": 1105.6676025390625, "val_acc": 40.0}
{"epoch": 10, "training_loss": 775.6934143066406, "training_acc": 50.0, "val_loss": 545.0715942382812, "val_acc": 60.0}
{"epoch": 11, "training_loss": 791.1740966796875, "training_acc": 50.0, "val_loss": 1201.7015380859375, "val_acc": 60.0}
{"epoch": 12, "training_loss": 1503.410791015625, "training_acc": 50.0, "val_loss": 1043.9537353515625, "val_acc": 60.0}
{"epoch": 13, "training_loss": 1260.2422119140624, "training_acc": 50.0, "val_loss": 288.4803161621094, "val_acc": 60.0}
{"epoch": 14, "training_loss": 350.92518310546876, "training_acc": 50.0, "val_loss": 840.7955322265625, "val_acc": 40.0}
{"epoch": 15, "training_loss": 724.7907958984375, "training_acc": 50.0, "val_loss": 862.4517822265625, "val_acc": 40.0}
{"epoch": 16, "training_loss": 683.7246124267579, "training_acc": 50.0, "val_loss": 32.67348861694336, "val_acc": 60.0}
{"epoch": 17, "training_loss": 95.99004516601562, "training_acc": 50.0, "val_loss": 53.35516357421875, "val_acc": 60.0}
{"epoch": 18, "training_loss": 154.085009765625, "training_acc": 40.0, "val_loss": 408.0379943847656, "val_acc": 40.0}
{"epoch": 19, "training_loss": 301.0957855224609, "training_acc": 50.0, "val_loss": 183.80052185058594, "val_acc": 60.0}
{"epoch": 20, "training_loss": 239.32740173339843, "training_acc": 50.0, "val_loss": 260.6965026855469, "val_acc": 60.0}
{"epoch": 21, "training_loss": 281.11749267578125, "training_acc": 50.0, "val_loss": 362.2049865722656, "val_acc": 40.0}
{"epoch": 22, "training_loss": 331.58201904296874, "training_acc": 50.0, "val_loss": 466.0097351074219, "val_acc": 40.0}
{"epoch": 23, "training_loss": 312.759521484375, "training_acc": 50.0, "val_loss": 314.1007995605469, "val_acc": 60.0}
{"epoch": 24, "training_loss": 445.712109375, "training_acc": 50.0, "val_loss": 560.0636596679688, "val_acc": 60.0}
{"epoch": 25, "training_loss": 663.7076904296875, "training_acc": 50.0, "val_loss": 124.93293762207031, "val_acc": 60.0}
{"epoch": 26, "training_loss": 260.77349853515625, "training_acc": 40.0, "val_loss": 720.6083984375, "val_acc": 40.0}
{"epoch": 27, "training_loss": 593.1609741210938, "training_acc": 50.0, "val_loss": 463.7148132324219, "val_acc": 40.0}
{"epoch": 28, "training_loss": 347.85451726913453, "training_acc": 50.0, "val_loss": 342.06005859375, "val_acc": 60.0}
{"epoch": 29, "training_loss": 490.94171142578125, "training_acc": 50.0, "val_loss": 421.31524658203125, "val_acc": 60.0}
{"epoch": 30, "training_loss": 463.13547668457034, "training_acc": 50.0, "val_loss": 326.7987976074219, "val_acc": 40.0}
{"epoch": 31, "training_loss": 291.75255126953124, "training_acc": 50.0, "val_loss": 672.9628295898438, "val_acc": 40.0}
{"epoch": 32, "training_loss": 531.9009399414062, "training_acc": 50.0, "val_loss": 118.73815155029297, "val_acc": 40.0}
{"epoch": 33, "training_loss": 158.08414306640626, "training_acc": 50.0, "val_loss": 519.4244384765625, "val_acc": 60.0}
{"epoch": 34, "training_loss": 646.237548828125, "training_acc": 50.0, "val_loss": 415.8634338378906, "val_acc": 60.0}
{"epoch": 35, "training_loss": 484.76511840820314, "training_acc": 50.0, "val_loss": 276.3314514160156, "val_acc": 40.0}
