"main_modify.py --pretrained_path None --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 2 --task ADNI_sex --input_option yAware --learning_rate 1e1 --batch_size 16 --weight_decay 5e-9 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 426.9829555511475, "training_acc": 50.0, "val_loss": 755.3485107421875, "val_acc": 60.0}
{"epoch": 1, "training_loss": 1053.847509765625, "training_acc": 40.0, "val_loss": 912.52001953125, "val_acc": 40.0}
{"epoch": 2, "training_loss": 647.0340454101563, "training_acc": 50.0, "val_loss": 398.71856689453125, "val_acc": 60.0}
{"epoch": 3, "training_loss": 619.7780029296875, "training_acc": 50.0, "val_loss": 587.0889892578125, "val_acc": 60.0}
{"epoch": 4, "training_loss": 642.8105834960937, "training_acc": 50.0, "val_loss": 473.4671936035156, "val_acc": 40.0}
{"epoch": 5, "training_loss": 394.520263671875, "training_acc": 50.0, "val_loss": 998.4535522460938, "val_acc": 40.0}
{"epoch": 6, "training_loss": 816.8523193359375, "training_acc": 50.0, "val_loss": 435.5906677246094, "val_acc": 40.0}
{"epoch": 7, "training_loss": 339.8911987304688, "training_acc": 50.0, "val_loss": 439.12939453125, "val_acc": 60.0}
{"epoch": 8, "training_loss": 548.2930297851562, "training_acc": 50.0, "val_loss": 347.7779846191406, "val_acc": 60.0}
{"epoch": 9, "training_loss": 367.4148406982422, "training_acc": 50.0, "val_loss": 507.64483642578125, "val_acc": 40.0}
{"epoch": 10, "training_loss": 444.1195861816406, "training_acc": 50.0, "val_loss": 856.5319213867188, "val_acc": 40.0}
{"epoch": 11, "training_loss": 695.8003295898437, "training_acc": 50.0, "val_loss": 310.6921081542969, "val_acc": 40.0}
{"epoch": 12, "training_loss": 199.53505249023436, "training_acc": 60.0, "val_loss": 377.8396911621094, "val_acc": 60.0}
{"epoch": 13, "training_loss": 471.72792663574216, "training_acc": 50.0, "val_loss": 298.3912658691406, "val_acc": 60.0}
{"epoch": 14, "training_loss": 284.64866943359374, "training_acc": 50.0, "val_loss": 600.8858032226562, "val_acc": 40.0}
{"epoch": 15, "training_loss": 528.3581298828125, "training_acc": 50.0, "val_loss": 1102.798095703125, "val_acc": 40.0}
{"epoch": 16, "training_loss": 900.95, "training_acc": 50.0, "val_loss": 637.0432739257812, "val_acc": 40.0}
{"epoch": 17, "training_loss": 479.83467864990234, "training_acc": 50.0, "val_loss": 439.33428955078125, "val_acc": 60.0}
{"epoch": 18, "training_loss": 574.8595336914062, "training_acc": 50.0, "val_loss": 760.4329223632812, "val_acc": 60.0}
{"epoch": 19, "training_loss": 929.4315307617187, "training_acc": 50.0, "val_loss": 438.8706970214844, "val_acc": 60.0}
{"epoch": 20, "training_loss": 449.2711975097656, "training_acc": 50.0, "val_loss": 719.1473999023438, "val_acc": 40.0}
{"epoch": 21, "training_loss": 673.903515625, "training_acc": 50.0, "val_loss": 1313.6903076171875, "val_acc": 40.0}
{"epoch": 22, "training_loss": 1073.6794921875, "training_acc": 50.0, "val_loss": 811.75732421875, "val_acc": 40.0}
{"epoch": 23, "training_loss": 624.5780426025391, "training_acc": 50.0, "val_loss": 339.9458312988281, "val_acc": 60.0}
{"epoch": 24, "training_loss": 451.4418151855469, "training_acc": 50.0, "val_loss": 677.5160522460938, "val_acc": 60.0}
{"epoch": 25, "training_loss": 827.7963745117188, "training_acc": 50.0, "val_loss": 371.00628662109375, "val_acc": 60.0}
{"epoch": 26, "training_loss": 373.7180572509766, "training_acc": 50.0, "val_loss": 282.8296813964844, "val_acc": 40.0}
{"epoch": 27, "training_loss": 230.91969299316406, "training_acc": 50.0, "val_loss": 42.963775634765625, "val_acc": 40.0}
{"epoch": 28, "training_loss": 135.06445922851563, "training_acc": 40.0, "val_loss": 289.2586975097656, "val_acc": 60.0}
{"epoch": 29, "training_loss": 338.1264190673828, "training_acc": 50.0, "val_loss": 209.0343475341797, "val_acc": 40.0}
{"epoch": 30, "training_loss": 202.20406494140624, "training_acc": 50.0, "val_loss": 35.2573356628418, "val_acc": 40.0}
{"epoch": 31, "training_loss": 57.21419830322266, "training_acc": 60.0, "val_loss": 501.0461120605469, "val_acc": 60.0}
{"epoch": 32, "training_loss": 623.8484436035156, "training_acc": 50.0, "val_loss": 397.08721923828125, "val_acc": 60.0}
{"epoch": 33, "training_loss": 430.43662109375, "training_acc": 50.0, "val_loss": 395.8381042480469, "val_acc": 40.0}
{"epoch": 34, "training_loss": 409.96904296875, "training_acc": 50.0, "val_loss": 616.1492309570312, "val_acc": 40.0}
{"epoch": 35, "training_loss": 482.06656036376955, "training_acc": 50.0, "val_loss": 152.9034423828125, "val_acc": 60.0}
{"epoch": 36, "training_loss": 217.5988525390625, "training_acc": 50.0, "val_loss": 191.00079345703125, "val_acc": 60.0}
{"epoch": 37, "training_loss": 201.6412612915039, "training_acc": 50.0, "val_loss": 128.8412322998047, "val_acc": 40.0}
{"epoch": 38, "training_loss": 122.45869445800781, "training_acc": 40.0, "val_loss": 68.4044418334961, "val_acc": 40.0}
{"epoch": 39, "training_loss": 65.94647369384765, "training_acc": 40.0, "val_loss": 199.91558837890625, "val_acc": 40.0}
{"epoch": 40, "training_loss": 163.84390258789062, "training_acc": 50.0, "val_loss": 55.34870147705078, "val_acc": 60.0}
{"epoch": 41, "training_loss": 64.43178977966309, "training_acc": 50.0, "val_loss": 125.01686096191406, "val_acc": 40.0}
{"epoch": 42, "training_loss": 86.42987213134765, "training_acc": 50.0, "val_loss": 259.3562927246094, "val_acc": 60.0}
{"epoch": 43, "training_loss": 347.20030517578124, "training_acc": 50.0, "val_loss": 277.1681213378906, "val_acc": 60.0}
{"epoch": 44, "training_loss": 285.417219543457, "training_acc": 50.0, "val_loss": 518.0946655273438, "val_acc": 40.0}
{"epoch": 45, "training_loss": 451.37779541015624, "training_acc": 50.0, "val_loss": 837.7330322265625, "val_acc": 40.0}
{"epoch": 46, "training_loss": 662.99326171875, "training_acc": 50.0, "val_loss": 188.64488220214844, "val_acc": 40.0}
{"epoch": 47, "training_loss": 212.3689697265625, "training_acc": 50.0, "val_loss": 600.642578125, "val_acc": 60.0}
{"epoch": 48, "training_loss": 764.9849487304688, "training_acc": 50.0, "val_loss": 552.9583129882812, "val_acc": 60.0}
{"epoch": 49, "training_loss": 576.4649780273437, "training_acc": 50.0, "val_loss": 305.43701171875, "val_acc": 40.0}
