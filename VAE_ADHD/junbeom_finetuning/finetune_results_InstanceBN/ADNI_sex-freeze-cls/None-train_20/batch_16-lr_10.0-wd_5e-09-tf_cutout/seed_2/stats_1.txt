"main_modify.py --pretrained_path None --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 2 --task ADNI_sex --input_option yAware --learning_rate 1e1 --batch_size 16 --weight_decay 5e-9 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 430.46491837501526, "training_acc": 50.0, "val_loss": 471.8859558105469, "val_acc": 60.0}
{"epoch": 1, "training_loss": 718.470263671875, "training_acc": 50.0, "val_loss": 2075.524658203125, "val_acc": 40.0}
{"epoch": 2, "training_loss": 1685.095166015625, "training_acc": 50.0, "val_loss": 1002.0142822265625, "val_acc": 40.0}
{"epoch": 3, "training_loss": 805.2461975097656, "training_acc": 40.0, "val_loss": 318.4480895996094, "val_acc": 60.0}
{"epoch": 4, "training_loss": 363.0629638671875, "training_acc": 50.0, "val_loss": 325.39703369140625, "val_acc": 40.0}
{"epoch": 5, "training_loss": 307.5129638671875, "training_acc": 50.0, "val_loss": 396.2268981933594, "val_acc": 40.0}
{"epoch": 6, "training_loss": 232.74914894104003, "training_acc": 60.0, "val_loss": 154.91629028320312, "val_acc": 60.0}
{"epoch": 7, "training_loss": 169.66597900390624, "training_acc": 50.0, "val_loss": 396.6282653808594, "val_acc": 40.0}
{"epoch": 8, "training_loss": 341.54006042480466, "training_acc": 50.0, "val_loss": 509.6978454589844, "val_acc": 40.0}
{"epoch": 9, "training_loss": 372.61810913085935, "training_acc": 50.0, "val_loss": 241.92149353027344, "val_acc": 60.0}
{"epoch": 10, "training_loss": 317.45314331054686, "training_acc": 50.0, "val_loss": 377.0629577636719, "val_acc": 60.0}
{"epoch": 11, "training_loss": 427.63698120117186, "training_acc": 50.0, "val_loss": 202.1977996826172, "val_acc": 40.0}
{"epoch": 12, "training_loss": 197.92046508789062, "training_acc": 50.0, "val_loss": 268.8735046386719, "val_acc": 40.0}
{"epoch": 13, "training_loss": 234.70933227539064, "training_acc": 40.0, "val_loss": 62.79094314575195, "val_acc": 60.0}
{"epoch": 14, "training_loss": 96.42192993164062, "training_acc": 50.0, "val_loss": 209.1614227294922, "val_acc": 40.0}
{"epoch": 15, "training_loss": 122.76996526718139, "training_acc": 60.0, "val_loss": 55.77631759643555, "val_acc": 60.0}
{"epoch": 16, "training_loss": 55.64725341796875, "training_acc": 60.0, "val_loss": 101.4617919921875, "val_acc": 40.0}
{"epoch": 17, "training_loss": 91.31444702148437, "training_acc": 50.0, "val_loss": 69.49566650390625, "val_acc": 60.0}
{"epoch": 18, "training_loss": 74.82956237792969, "training_acc": 60.0, "val_loss": 274.04364013671875, "val_acc": 40.0}
{"epoch": 19, "training_loss": 199.59494323730468, "training_acc": 50.0, "val_loss": 203.8312225341797, "val_acc": 60.0}
{"epoch": 20, "training_loss": 312.703857421875, "training_acc": 50.0, "val_loss": 79.95745849609375, "val_acc": 60.0}
{"epoch": 21, "training_loss": 156.61024780273436, "training_acc": 50.0, "val_loss": 724.8446655273438, "val_acc": 40.0}
{"epoch": 22, "training_loss": 599.3951049804688, "training_acc": 50.0, "val_loss": 504.92999267578125, "val_acc": 40.0}
{"epoch": 23, "training_loss": 383.11676635742185, "training_acc": 50.0, "val_loss": 310.63018798828125, "val_acc": 60.0}
{"epoch": 24, "training_loss": 403.66465454101564, "training_acc": 50.0, "val_loss": 460.94219970703125, "val_acc": 60.0}
{"epoch": 25, "training_loss": 539.1410949707031, "training_acc": 50.0, "val_loss": 6.305400371551514, "val_acc": 60.0}
{"epoch": 26, "training_loss": 58.09668388366699, "training_acc": 60.0, "val_loss": 1080.35302734375, "val_acc": 40.0}
{"epoch": 27, "training_loss": 923.8482421875, "training_acc": 50.0, "val_loss": 1093.7239990234375, "val_acc": 40.0}
{"epoch": 28, "training_loss": 823.8002685546875, "training_acc": 50.0, "val_loss": 53.35404586791992, "val_acc": 40.0}
{"epoch": 29, "training_loss": 97.0490234375, "training_acc": 60.0, "val_loss": 960.6386108398438, "val_acc": 60.0}
{"epoch": 30, "training_loss": 1224.2709106445313, "training_acc": 50.0, "val_loss": 1235.2730712890625, "val_acc": 60.0}
{"epoch": 31, "training_loss": 1528.8187255859375, "training_acc": 50.0, "val_loss": 921.4359741210938, "val_acc": 60.0}
{"epoch": 32, "training_loss": 1105.0532287597657, "training_acc": 50.0, "val_loss": 127.5173110961914, "val_acc": 60.0}
{"epoch": 33, "training_loss": 234.62698974609376, "training_acc": 50.0, "val_loss": 1129.2388916015625, "val_acc": 40.0}
{"epoch": 34, "training_loss": 951.6184936523438, "training_acc": 50.0, "val_loss": 1270.44189453125, "val_acc": 40.0}
{"epoch": 35, "training_loss": 991.148095703125, "training_acc": 50.0, "val_loss": 379.01751708984375, "val_acc": 40.0}
{"epoch": 36, "training_loss": 335.496875, "training_acc": 50.0, "val_loss": 690.7138061523438, "val_acc": 60.0}
{"epoch": 37, "training_loss": 900.128759765625, "training_acc": 50.0, "val_loss": 801.2501831054688, "val_acc": 60.0}
{"epoch": 38, "training_loss": 973.4904235839844, "training_acc": 50.0, "val_loss": 281.7882385253906, "val_acc": 60.0}
{"epoch": 39, "training_loss": 382.398193359375, "training_acc": 40.0, "val_loss": 487.698974609375, "val_acc": 40.0}
{"epoch": 40, "training_loss": 399.9286376953125, "training_acc": 50.0, "val_loss": 66.75616455078125, "val_acc": 40.0}
{"epoch": 41, "training_loss": 135.04562683105468, "training_acc": 50.0, "val_loss": 564.9002685546875, "val_acc": 60.0}
{"epoch": 42, "training_loss": 717.576806640625, "training_acc": 50.0, "val_loss": 370.0594177246094, "val_acc": 60.0}
{"epoch": 43, "training_loss": 370.21550166606903, "training_acc": 45.0, "val_loss": 406.04595947265625, "val_acc": 40.0}
{"epoch": 44, "training_loss": 355.35439453125, "training_acc": 50.0, "val_loss": 357.1571350097656, "val_acc": 40.0}
