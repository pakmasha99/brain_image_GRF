"main_modify.py --pretrained_path None --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 1 --task ADNI_sex --input_option yAware --learning_rate 1e1 --batch_size 16 --weight_decay 5e-9 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 428.71386709213255, "training_acc": 50.0, "val_loss": 821.4688720703125, "val_acc": 40.0}
{"epoch": 1, "training_loss": 763.0000244140625, "training_acc": 50.0, "val_loss": 1231.0615234375, "val_acc": 60.0}
{"epoch": 2, "training_loss": 1490.8099609375, "training_acc": 50.0, "val_loss": 484.31622314453125, "val_acc": 60.0}
{"epoch": 3, "training_loss": 670.8135009765625, "training_acc": 40.0, "val_loss": 777.0217895507812, "val_acc": 40.0}
{"epoch": 4, "training_loss": 617.8558044433594, "training_acc": 50.0, "val_loss": 65.45537567138672, "val_acc": 40.0}
{"epoch": 5, "training_loss": 169.899267578125, "training_acc": 50.0, "val_loss": 743.9860229492188, "val_acc": 60.0}
{"epoch": 6, "training_loss": 950.5902099609375, "training_acc": 50.0, "val_loss": 413.7496032714844, "val_acc": 60.0}
{"epoch": 7, "training_loss": 440.8636810302734, "training_acc": 50.0, "val_loss": 563.084716796875, "val_acc": 40.0}
{"epoch": 8, "training_loss": 496.2682861328125, "training_acc": 50.0, "val_loss": 354.6092224121094, "val_acc": 40.0}
{"epoch": 9, "training_loss": 268.9726806640625, "training_acc": 50.0, "val_loss": 279.16357421875, "val_acc": 60.0}
{"epoch": 10, "training_loss": 340.9636535644531, "training_acc": 50.0, "val_loss": 23.787429809570312, "val_acc": 40.0}
{"epoch": 11, "training_loss": 56.404214477539064, "training_acc": 50.0, "val_loss": 49.9436149597168, "val_acc": 60.0}
{"epoch": 12, "training_loss": 57.12814912796021, "training_acc": 50.0, "val_loss": 160.8992156982422, "val_acc": 40.0}
{"epoch": 13, "training_loss": 119.31712341308594, "training_acc": 50.0, "val_loss": 168.99656677246094, "val_acc": 60.0}
{"epoch": 14, "training_loss": 210.6416015625, "training_acc": 50.0, "val_loss": 150.29600524902344, "val_acc": 60.0}
{"epoch": 15, "training_loss": 130.98622612953187, "training_acc": 60.0, "val_loss": 88.00470733642578, "val_acc": 40.0}
{"epoch": 16, "training_loss": 44.17886047363281, "training_acc": 70.0, "val_loss": 82.53099822998047, "val_acc": 60.0}
{"epoch": 17, "training_loss": 87.71530151367188, "training_acc": 50.0, "val_loss": 45.634185791015625, "val_acc": 60.0}
{"epoch": 18, "training_loss": 59.210514831542966, "training_acc": 50.0, "val_loss": 16.105417251586914, "val_acc": 60.0}
{"epoch": 19, "training_loss": 36.51770172119141, "training_acc": 50.0, "val_loss": 10.363924980163574, "val_acc": 40.0}
{"epoch": 20, "training_loss": 101.02668762207031, "training_acc": 40.0, "val_loss": 231.56285095214844, "val_acc": 60.0}
{"epoch": 21, "training_loss": 243.24064712524415, "training_acc": 50.0, "val_loss": 417.8814392089844, "val_acc": 40.0}
{"epoch": 22, "training_loss": 361.88312377929685, "training_acc": 50.0, "val_loss": 607.92626953125, "val_acc": 40.0}
{"epoch": 23, "training_loss": 468.77496337890625, "training_acc": 50.0, "val_loss": 46.819122314453125, "val_acc": 60.0}
{"epoch": 24, "training_loss": 104.88486938476562, "training_acc": 50.0, "val_loss": 39.71690368652344, "val_acc": 60.0}
{"epoch": 25, "training_loss": 143.37142333984374, "training_acc": 40.0, "val_loss": 438.3641662597656, "val_acc": 40.0}
{"epoch": 26, "training_loss": 331.01270751953126, "training_acc": 50.0, "val_loss": 130.5355987548828, "val_acc": 60.0}
{"epoch": 27, "training_loss": 185.77406616210936, "training_acc": 50.0, "val_loss": 148.64920043945312, "val_acc": 60.0}
{"epoch": 28, "training_loss": 168.34293212890626, "training_acc": 50.0, "val_loss": 192.98403930664062, "val_acc": 40.0}
{"epoch": 29, "training_loss": 177.42540588378907, "training_acc": 30.0, "val_loss": 213.7881317138672, "val_acc": 40.0}
{"epoch": 30, "training_loss": 175.84146118164062, "training_acc": 50.0, "val_loss": 34.58960723876953, "val_acc": 40.0}
{"epoch": 31, "training_loss": 78.45501098632812, "training_acc": 50.0, "val_loss": 288.7762756347656, "val_acc": 60.0}
{"epoch": 32, "training_loss": 333.577001953125, "training_acc": 50.0, "val_loss": 97.30876922607422, "val_acc": 40.0}
{"epoch": 33, "training_loss": 114.33875122070313, "training_acc": 50.0, "val_loss": 8.413997650146484, "val_acc": 60.0}
{"epoch": 34, "training_loss": 17.563706970214845, "training_acc": 40.0, "val_loss": 180.817138671875, "val_acc": 60.0}
{"epoch": 35, "training_loss": 242.3594970703125, "training_acc": 50.0, "val_loss": 34.72518539428711, "val_acc": 60.0}
{"epoch": 36, "training_loss": 24.743081665039064, "training_acc": 70.0, "val_loss": 786.7830200195312, "val_acc": 40.0}
{"epoch": 37, "training_loss": 675.6978881835937, "training_acc": 50.0, "val_loss": 777.03662109375, "val_acc": 40.0}
{"epoch": 38, "training_loss": 615.2302825927734, "training_acc": 50.0, "val_loss": 51.74859619140625, "val_acc": 60.0}
{"epoch": 39, "training_loss": 74.51368255615235, "training_acc": 50.0, "val_loss": 164.40191650390625, "val_acc": 60.0}
{"epoch": 40, "training_loss": 165.7331615447998, "training_acc": 50.0, "val_loss": 423.3627014160156, "val_acc": 40.0}
{"epoch": 41, "training_loss": 400.403857421875, "training_acc": 50.0, "val_loss": 421.9358825683594, "val_acc": 40.0}
{"epoch": 42, "training_loss": 256.0062683105469, "training_acc": 50.0, "val_loss": 441.5137634277344, "val_acc": 60.0}
{"epoch": 43, "training_loss": 655.76787109375, "training_acc": 50.0, "val_loss": 737.5032958984375, "val_acc": 60.0}
{"epoch": 44, "training_loss": 899.3063720703125, "training_acc": 50.0, "val_loss": 340.5957946777344, "val_acc": 60.0}
{"epoch": 45, "training_loss": 344.94400253295896, "training_acc": 50.0, "val_loss": 294.63629150390625, "val_acc": 40.0}
{"epoch": 46, "training_loss": 241.99072875976563, "training_acc": 50.0, "val_loss": 98.72920227050781, "val_acc": 40.0}
{"epoch": 47, "training_loss": 150.54754028320312, "training_acc": 40.0, "val_loss": 213.64134216308594, "val_acc": 60.0}
{"epoch": 48, "training_loss": 242.8753391265869, "training_acc": 50.0, "val_loss": 293.9378967285156, "val_acc": 40.0}
{"epoch": 49, "training_loss": 273.4751831054688, "training_acc": 50.0, "val_loss": 142.844482421875, "val_acc": 40.0}
{"epoch": 50, "training_loss": 150.6120178222656, "training_acc": 50.0, "val_loss": 344.7289733886719, "val_acc": 60.0}
{"epoch": 51, "training_loss": 419.51787719726565, "training_acc": 50.0, "val_loss": 136.24429321289062, "val_acc": 60.0}
{"epoch": 52, "training_loss": 215.52568359375, "training_acc": 40.0, "val_loss": 308.1509704589844, "val_acc": 40.0}
