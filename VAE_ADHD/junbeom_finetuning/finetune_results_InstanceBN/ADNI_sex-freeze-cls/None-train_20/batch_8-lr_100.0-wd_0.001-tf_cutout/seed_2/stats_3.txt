"main_modify.py --pretrained_path None --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 2 --task ADNI_sex --input_option yAware --learning_rate 1e2 --batch_size 8 --weight_decay 1e-3 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 14439.211019706727, "training_acc": 35.0, "val_loss": 9719.697265625, "val_acc": 40.0}
{"epoch": 1, "training_loss": 10348.586328125, "training_acc": 55.0, "val_loss": 11795.546875, "val_acc": 40.0}
{"epoch": 2, "training_loss": 4367.724169921875, "training_acc": 65.0, "val_loss": 9090.1162109375, "val_acc": 60.0}
{"epoch": 3, "training_loss": 12098.12734375, "training_acc": 45.0, "val_loss": 2452.454833984375, "val_acc": 60.0}
{"epoch": 4, "training_loss": 7024.0544921875, "training_acc": 35.0, "val_loss": 12598.2880859375, "val_acc": 40.0}
{"epoch": 5, "training_loss": 8342.46484375, "training_acc": 55.0, "val_loss": 1306.3626708984375, "val_acc": 60.0}
{"epoch": 6, "training_loss": 1828.547186279297, "training_acc": 45.0, "val_loss": 1575.101806640625, "val_acc": 40.0}
{"epoch": 7, "training_loss": 1072.0246517181397, "training_acc": 55.0, "val_loss": 488.1610412597656, "val_acc": 40.0}
{"epoch": 8, "training_loss": 776.455827331543, "training_acc": 45.0, "val_loss": 3316.574951171875, "val_acc": 40.0}
{"epoch": 9, "training_loss": 2542.375634765625, "training_acc": 55.0, "val_loss": 633.2772827148438, "val_acc": 60.0}
{"epoch": 10, "training_loss": 731.3274948120118, "training_acc": 55.0, "val_loss": 429.98419189453125, "val_acc": 40.0}
{"epoch": 11, "training_loss": 798.0057739257812, "training_acc": 45.0, "val_loss": 912.9602661132812, "val_acc": 60.0}
{"epoch": 12, "training_loss": 1174.755517578125, "training_acc": 45.0, "val_loss": 1622.4549560546875, "val_acc": 40.0}
{"epoch": 13, "training_loss": 1413.9966552734375, "training_acc": 35.0, "val_loss": 2698.82275390625, "val_acc": 40.0}
{"epoch": 14, "training_loss": 2638.8321044921877, "training_acc": 55.0, "val_loss": 53.13481521606445, "val_acc": 60.0}
{"epoch": 15, "training_loss": 472.55091857910156, "training_acc": 55.0, "val_loss": 2140.362548828125, "val_acc": 40.0}
{"epoch": 16, "training_loss": 1259.9031005859374, "training_acc": 55.0, "val_loss": 1882.3671875, "val_acc": 60.0}
{"epoch": 17, "training_loss": 1984.253955078125, "training_acc": 45.0, "val_loss": 4844.87939453125, "val_acc": 40.0}
{"epoch": 18, "training_loss": 3015.52763671875, "training_acc": 55.0, "val_loss": 2044.12890625, "val_acc": 60.0}
{"epoch": 19, "training_loss": 3788.0794921875, "training_acc": 45.0, "val_loss": 121.13996887207031, "val_acc": 60.0}
{"epoch": 20, "training_loss": 1623.790756225586, "training_acc": 65.0, "val_loss": 6745.51171875, "val_acc": 40.0}
{"epoch": 21, "training_loss": 3905.6685546875, "training_acc": 45.0, "val_loss": 571.4719848632812, "val_acc": 60.0}
{"epoch": 22, "training_loss": 349.93332824707034, "training_acc": 55.0, "val_loss": 2893.046142578125, "val_acc": 40.0}
{"epoch": 23, "training_loss": 1999.3504150390625, "training_acc": 55.0, "val_loss": 1567.4200439453125, "val_acc": 60.0}
{"epoch": 24, "training_loss": 2394.790478515625, "training_acc": 45.0, "val_loss": 2969.375732421875, "val_acc": 40.0}
{"epoch": 25, "training_loss": 2984.14052734375, "training_acc": 55.0, "val_loss": 2188.656005859375, "val_acc": 40.0}
{"epoch": 26, "training_loss": 1424.615966796875, "training_acc": 55.0, "val_loss": 492.55401611328125, "val_acc": 60.0}
{"epoch": 27, "training_loss": 1291.34111328125, "training_acc": 65.0, "val_loss": 3105.850341796875, "val_acc": 40.0}
{"epoch": 28, "training_loss": 1235.5269958496094, "training_acc": 45.0, "val_loss": 1805.60546875, "val_acc": 40.0}
{"epoch": 29, "training_loss": 1101.7852294921875, "training_acc": 55.0, "val_loss": 505.66729736328125, "val_acc": 60.0}
{"epoch": 30, "training_loss": 1131.6044189453125, "training_acc": 55.0, "val_loss": 1036.3826904296875, "val_acc": 40.0}
{"epoch": 31, "training_loss": 1920.23291015625, "training_acc": 45.0, "val_loss": 17.592336654663086, "val_acc": 40.0}
{"epoch": 32, "training_loss": 946.1538888931275, "training_acc": 45.0, "val_loss": 1077.0150146484375, "val_acc": 40.0}
{"epoch": 33, "training_loss": 838.5968017578125, "training_acc": 55.0, "val_loss": 1315.024658203125, "val_acc": 60.0}
{"epoch": 34, "training_loss": 1970.5263916015624, "training_acc": 35.0, "val_loss": 222.6511688232422, "val_acc": 60.0}
{"epoch": 35, "training_loss": 614.4233413696289, "training_acc": 45.0, "val_loss": 121.1414566040039, "val_acc": 60.0}
{"epoch": 36, "training_loss": 1105.3218811035156, "training_acc": 65.0, "val_loss": 4075.327392578125, "val_acc": 40.0}
{"epoch": 37, "training_loss": 3038.7306640625, "training_acc": 45.0, "val_loss": 2460.93603515625, "val_acc": 60.0}
{"epoch": 38, "training_loss": 1564.82158203125, "training_acc": 65.0, "val_loss": 6025.7294921875, "val_acc": 40.0}
{"epoch": 39, "training_loss": 4455.56318359375, "training_acc": 55.0, "val_loss": 902.2976684570312, "val_acc": 40.0}
{"epoch": 40, "training_loss": 4510.914306640625, "training_acc": 35.0, "val_loss": 4710.61279296875, "val_acc": 60.0}
{"epoch": 41, "training_loss": 6087.39912109375, "training_acc": 25.0, "val_loss": 5876.13427734375, "val_acc": 40.0}
{"epoch": 42, "training_loss": 3565.703955078125, "training_acc": 55.0, "val_loss": 2042.9859619140625, "val_acc": 60.0}
{"epoch": 43, "training_loss": 4535.8482421875, "training_acc": 45.0, "val_loss": 729.0458374023438, "val_acc": 60.0}
{"epoch": 44, "training_loss": 2705.081640625, "training_acc": 55.0, "val_loss": 9230.2578125, "val_acc": 40.0}
{"epoch": 45, "training_loss": 5815.6900390625, "training_acc": 55.0, "val_loss": 723.2965698242188, "val_acc": 60.0}
{"epoch": 46, "training_loss": 2136.17744140625, "training_acc": 45.0, "val_loss": 35.21211624145508, "val_acc": 40.0}
{"epoch": 47, "training_loss": 390.4823287963867, "training_acc": 45.0, "val_loss": 921.1144409179688, "val_acc": 40.0}
{"epoch": 48, "training_loss": 776.6465698242188, "training_acc": 55.0, "val_loss": 485.9814453125, "val_acc": 60.0}
{"epoch": 49, "training_loss": 1341.10830078125, "training_acc": 55.0, "val_loss": 573.40478515625, "val_acc": 40.0}
{"epoch": 50, "training_loss": 4527.90126953125, "training_acc": 25.0, "val_loss": 2871.845703125, "val_acc": 60.0}
