"main_modify.py --pretrained_path None --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 2 --task ADNI_sex --input_option yAware --learning_rate 1e2 --batch_size 8 --weight_decay 1e-3 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 6711.004474496842, "training_acc": 50.0, "val_loss": 18007.369140625, "val_acc": 40.0}
{"epoch": 1, "training_loss": 15647.469140625, "training_acc": 50.0, "val_loss": 11723.3466796875, "val_acc": 40.0}
{"epoch": 2, "training_loss": 4402.09638671875, "training_acc": 60.0, "val_loss": 12241.8798828125, "val_acc": 60.0}
{"epoch": 3, "training_loss": 15661.42412109375, "training_acc": 50.0, "val_loss": 7947.4765625, "val_acc": 60.0}
{"epoch": 4, "training_loss": 7828.1421875, "training_acc": 40.0, "val_loss": 11196.658203125, "val_acc": 40.0}
{"epoch": 5, "training_loss": 10404.9455078125, "training_acc": 50.0, "val_loss": 6027.11279296875, "val_acc": 40.0}
{"epoch": 6, "training_loss": 4755.2763671875, "training_acc": 40.0, "val_loss": 5890.83544921875, "val_acc": 60.0}
{"epoch": 7, "training_loss": 6451.93271484375, "training_acc": 50.0, "val_loss": 836.1865234375, "val_acc": 40.0}
{"epoch": 8, "training_loss": 3268.2044189453127, "training_acc": 50.0, "val_loss": 2548.539306640625, "val_acc": 40.0}
{"epoch": 9, "training_loss": 2265.9080078125, "training_acc": 40.0, "val_loss": 1081.8140869140625, "val_acc": 60.0}
{"epoch": 10, "training_loss": 3170.265380859375, "training_acc": 30.0, "val_loss": 1598.697509765625, "val_acc": 40.0}
{"epoch": 11, "training_loss": 2377.037841796875, "training_acc": 50.0, "val_loss": 3049.487060546875, "val_acc": 60.0}
{"epoch": 12, "training_loss": 2094.8278930664064, "training_acc": 60.0, "val_loss": 4257.53466796875, "val_acc": 40.0}
{"epoch": 13, "training_loss": 3148.126989746094, "training_acc": 50.0, "val_loss": 1524.7037353515625, "val_acc": 60.0}
{"epoch": 14, "training_loss": 1990.5220703125, "training_acc": 50.0, "val_loss": 2048.469970703125, "val_acc": 40.0}
{"epoch": 15, "training_loss": 2558.012548828125, "training_acc": 50.0, "val_loss": 749.5433959960938, "val_acc": 40.0}
{"epoch": 16, "training_loss": 2995.9025390625, "training_acc": 40.0, "val_loss": 2652.706787109375, "val_acc": 60.0}
{"epoch": 17, "training_loss": 2262.3132080078126, "training_acc": 40.0, "val_loss": 419.2644958496094, "val_acc": 40.0}
{"epoch": 18, "training_loss": 1876.2342163085937, "training_acc": 50.0, "val_loss": 1865.673095703125, "val_acc": 60.0}
{"epoch": 19, "training_loss": 1397.4450439453126, "training_acc": 50.0, "val_loss": 271.9518737792969, "val_acc": 40.0}
{"epoch": 20, "training_loss": 1723.2729614257812, "training_acc": 50.0, "val_loss": 1437.2694091796875, "val_acc": 60.0}
{"epoch": 21, "training_loss": 1374.875830078125, "training_acc": 60.0, "val_loss": 937.7657470703125, "val_acc": 40.0}
{"epoch": 22, "training_loss": 2515.578857421875, "training_acc": 40.0, "val_loss": 2031.947265625, "val_acc": 60.0}
{"epoch": 23, "training_loss": 2899.0882568359375, "training_acc": 30.0, "val_loss": 7438.62060546875, "val_acc": 40.0}
{"epoch": 24, "training_loss": 5117.201184082031, "training_acc": 50.0, "val_loss": 1988.901611328125, "val_acc": 60.0}
{"epoch": 25, "training_loss": 3399.2800537109374, "training_acc": 50.0, "val_loss": 1212.7315673828125, "val_acc": 60.0}
{"epoch": 26, "training_loss": 1833.4368896484375, "training_acc": 50.0, "val_loss": 2946.695068359375, "val_acc": 40.0}
{"epoch": 27, "training_loss": 1300.0824890136719, "training_acc": 40.0, "val_loss": 1865.0638427734375, "val_acc": 40.0}
{"epoch": 28, "training_loss": 1324.1542541503907, "training_acc": 50.0, "val_loss": 1204.746337890625, "val_acc": 60.0}
{"epoch": 29, "training_loss": 1281.0003570556642, "training_acc": 40.0, "val_loss": 937.2543334960938, "val_acc": 60.0}
{"epoch": 30, "training_loss": 783.3391723632812, "training_acc": 60.0, "val_loss": 2706.968994140625, "val_acc": 40.0}
{"epoch": 31, "training_loss": 1694.8939453125, "training_acc": 50.0, "val_loss": 2289.486083984375, "val_acc": 60.0}
{"epoch": 32, "training_loss": 2494.65224609375, "training_acc": 40.0, "val_loss": 2341.702392578125, "val_acc": 40.0}
{"epoch": 33, "training_loss": 1949.841943359375, "training_acc": 40.0, "val_loss": 2890.49462890625, "val_acc": 60.0}
{"epoch": 34, "training_loss": 2157.914031982422, "training_acc": 60.0, "val_loss": 2390.453857421875, "val_acc": 40.0}
{"epoch": 35, "training_loss": 1653.6676635742188, "training_acc": 50.0, "val_loss": 637.3927001953125, "val_acc": 60.0}
{"epoch": 36, "training_loss": 767.0129150390625, "training_acc": 50.0, "val_loss": 1593.2738037109375, "val_acc": 60.0}
{"epoch": 37, "training_loss": 2059.33212890625, "training_acc": 50.0, "val_loss": 2332.76318359375, "val_acc": 40.0}
{"epoch": 38, "training_loss": 2271.4595947265625, "training_acc": 50.0, "val_loss": 910.9592895507812, "val_acc": 60.0}
