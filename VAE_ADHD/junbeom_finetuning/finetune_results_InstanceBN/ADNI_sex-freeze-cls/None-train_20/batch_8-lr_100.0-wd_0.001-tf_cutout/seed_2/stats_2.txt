"main_modify.py --pretrained_path None --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 2 --task ADNI_sex --input_option yAware --learning_rate 1e2 --batch_size 8 --weight_decay 1e-3 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 10353.57155404091, "training_acc": 50.0, "val_loss": 9069.9951171875, "val_acc": 40.0}
{"epoch": 1, "training_loss": 10184.93896484375, "training_acc": 50.0, "val_loss": 4575.17529296875, "val_acc": 40.0}
{"epoch": 2, "training_loss": 5533.66953125, "training_acc": 50.0, "val_loss": 5646.39208984375, "val_acc": 60.0}
{"epoch": 3, "training_loss": 5890.76484375, "training_acc": 40.0, "val_loss": 9161.830078125, "val_acc": 40.0}
{"epoch": 4, "training_loss": 6712.5140380859375, "training_acc": 50.0, "val_loss": 1540.41259765625, "val_acc": 60.0}
{"epoch": 5, "training_loss": 2949.888427734375, "training_acc": 50.0, "val_loss": 275.3090515136719, "val_acc": 60.0}
{"epoch": 6, "training_loss": 2165.155651855469, "training_acc": 60.0, "val_loss": 6326.96533203125, "val_acc": 40.0}
{"epoch": 7, "training_loss": 3982.85166015625, "training_acc": 50.0, "val_loss": 2930.068115234375, "val_acc": 60.0}
{"epoch": 8, "training_loss": 3472.794567871094, "training_acc": 50.0, "val_loss": 4503.16845703125, "val_acc": 40.0}
{"epoch": 9, "training_loss": 5077.297265625, "training_acc": 50.0, "val_loss": 2501.332763671875, "val_acc": 40.0}
{"epoch": 10, "training_loss": 1818.690380859375, "training_acc": 60.0, "val_loss": 2388.336669921875, "val_acc": 60.0}
{"epoch": 11, "training_loss": 1559.251708984375, "training_acc": 60.0, "val_loss": 6437.17431640625, "val_acc": 40.0}
{"epoch": 12, "training_loss": 5091.5583984375, "training_acc": 50.0, "val_loss": 713.11865234375, "val_acc": 60.0}
{"epoch": 13, "training_loss": 2834.695068359375, "training_acc": 50.0, "val_loss": 1102.8084716796875, "val_acc": 60.0}
{"epoch": 14, "training_loss": 3155.74130859375, "training_acc": 40.0, "val_loss": 4479.029296875, "val_acc": 40.0}
{"epoch": 15, "training_loss": 2077.3490234375, "training_acc": 60.0, "val_loss": 4615.046875, "val_acc": 60.0}
{"epoch": 16, "training_loss": 5164.582421875, "training_acc": 50.0, "val_loss": 748.5792846679688, "val_acc": 40.0}
{"epoch": 17, "training_loss": 638.1165588378906, "training_acc": 40.0, "val_loss": 2271.533935546875, "val_acc": 40.0}
{"epoch": 18, "training_loss": 1872.3023193359375, "training_acc": 40.0, "val_loss": 733.9796752929688, "val_acc": 60.0}
{"epoch": 19, "training_loss": 2024.170703125, "training_acc": 40.0, "val_loss": 859.2501831054688, "val_acc": 40.0}
{"epoch": 20, "training_loss": 1608.6962158203125, "training_acc": 60.0, "val_loss": 2023.8875732421875, "val_acc": 60.0}
{"epoch": 21, "training_loss": 1972.7271484375, "training_acc": 40.0, "val_loss": 37.57096481323242, "val_acc": 40.0}
{"epoch": 22, "training_loss": 2700.1034606933595, "training_acc": 40.0, "val_loss": 2378.789306640625, "val_acc": 60.0}
{"epoch": 23, "training_loss": 1585.085693359375, "training_acc": 50.0, "val_loss": 404.91949462890625, "val_acc": 40.0}
{"epoch": 24, "training_loss": 2237.477685546875, "training_acc": 50.0, "val_loss": 1123.6541748046875, "val_acc": 60.0}
{"epoch": 25, "training_loss": 1778.0075439453126, "training_acc": 60.0, "val_loss": 4892.34033203125, "val_acc": 40.0}
{"epoch": 26, "training_loss": 2526.4552734375, "training_acc": 60.0, "val_loss": 2634.269775390625, "val_acc": 60.0}
{"epoch": 27, "training_loss": 2855.769677734375, "training_acc": 50.0, "val_loss": 3932.794677734375, "val_acc": 40.0}
{"epoch": 28, "training_loss": 4181.3162109375, "training_acc": 50.0, "val_loss": 2092.361328125, "val_acc": 40.0}
{"epoch": 29, "training_loss": 2421.9451171875, "training_acc": 50.0, "val_loss": 3363.553466796875, "val_acc": 60.0}
{"epoch": 30, "training_loss": 2846.72333984375, "training_acc": 50.0, "val_loss": 3195.9580078125, "val_acc": 40.0}
{"epoch": 31, "training_loss": 1820.5578125, "training_acc": 50.0, "val_loss": 3762.745849609375, "val_acc": 60.0}
{"epoch": 32, "training_loss": 7008.4654296875, "training_acc": 50.0, "val_loss": 4829.6337890625, "val_acc": 60.0}
{"epoch": 33, "training_loss": 4399.6669921875, "training_acc": 40.0, "val_loss": 7479.85791015625, "val_acc": 40.0}
{"epoch": 34, "training_loss": 5592.12958984375, "training_acc": 50.0, "val_loss": 33.82794952392578, "val_acc": 60.0}
{"epoch": 35, "training_loss": 2514.4942932128906, "training_acc": 50.0, "val_loss": 389.775390625, "val_acc": 60.0}
{"epoch": 36, "training_loss": 2932.4522216796877, "training_acc": 50.0, "val_loss": 6525.837890625, "val_acc": 40.0}
{"epoch": 37, "training_loss": 5635.60361328125, "training_acc": 30.0, "val_loss": 3166.127197265625, "val_acc": 60.0}
{"epoch": 38, "training_loss": 3293.71416015625, "training_acc": 40.0, "val_loss": 2678.122314453125, "val_acc": 40.0}
{"epoch": 39, "training_loss": 1780.863232421875, "training_acc": 50.0, "val_loss": 2253.42236328125, "val_acc": 60.0}
{"epoch": 40, "training_loss": 2534.9440185546873, "training_acc": 40.0, "val_loss": 1446.5343017578125, "val_acc": 40.0}
{"epoch": 41, "training_loss": 738.6289611816406, "training_acc": 50.0, "val_loss": 2296.022216796875, "val_acc": 40.0}
{"epoch": 42, "training_loss": 1800.827685546875, "training_acc": 40.0, "val_loss": 140.9976043701172, "val_acc": 60.0}
{"epoch": 43, "training_loss": 1445.3606201171874, "training_acc": 50.0, "val_loss": 1204.79345703125, "val_acc": 40.0}
{"epoch": 44, "training_loss": 1585.6439697265625, "training_acc": 50.0, "val_loss": 1106.120849609375, "val_acc": 60.0}
{"epoch": 45, "training_loss": 2145.585107421875, "training_acc": 40.0, "val_loss": 542.0994262695312, "val_acc": 40.0}
{"epoch": 46, "training_loss": 3414.2213623046873, "training_acc": 40.0, "val_loss": 3369.600830078125, "val_acc": 60.0}
{"epoch": 47, "training_loss": 2130.239453125, "training_acc": 60.0, "val_loss": 7149.55322265625, "val_acc": 40.0}
{"epoch": 48, "training_loss": 5689.51416015625, "training_acc": 50.0, "val_loss": 1252.644287109375, "val_acc": 40.0}
{"epoch": 49, "training_loss": 3678.536328125, "training_acc": 50.0, "val_loss": 5192.60888671875, "val_acc": 60.0}
{"epoch": 50, "training_loss": 4810.275244140625, "training_acc": 40.0, "val_loss": 2596.39892578125, "val_acc": 40.0}
{"epoch": 51, "training_loss": 1667.9297119140624, "training_acc": 50.0, "val_loss": 1055.4149169921875, "val_acc": 60.0}
{"epoch": 52, "training_loss": 1120.1842651367188, "training_acc": 50.0, "val_loss": 5002.54150390625, "val_acc": 40.0}
{"epoch": 53, "training_loss": 2910.108320617676, "training_acc": 50.0, "val_loss": 3565.65625, "val_acc": 60.0}
