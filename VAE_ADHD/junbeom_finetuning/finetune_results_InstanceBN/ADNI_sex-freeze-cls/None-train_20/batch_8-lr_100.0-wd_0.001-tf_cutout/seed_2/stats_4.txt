"main_modify.py --pretrained_path None --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 2 --task ADNI_sex --input_option yAware --learning_rate 1e2 --batch_size 8 --weight_decay 1e-3 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 11775.543439459801, "training_acc": 45.0, "val_loss": 11033.619140625, "val_acc": 40.0}
{"epoch": 1, "training_loss": 10904.0935546875, "training_acc": 55.0, "val_loss": 17349.45703125, "val_acc": 40.0}
{"epoch": 2, "training_loss": 8433.8431640625, "training_acc": 55.0, "val_loss": 6179.4462890625, "val_acc": 60.0}
{"epoch": 3, "training_loss": 12085.81875, "training_acc": 45.0, "val_loss": 8507.8671875, "val_acc": 60.0}
{"epoch": 4, "training_loss": 7783.600170898438, "training_acc": 45.0, "val_loss": 7415.93115234375, "val_acc": 40.0}
{"epoch": 5, "training_loss": 6081.26416015625, "training_acc": 55.0, "val_loss": 4645.22021484375, "val_acc": 40.0}
{"epoch": 6, "training_loss": 2141.7984130859377, "training_acc": 55.0, "val_loss": 1458.0980224609375, "val_acc": 60.0}
{"epoch": 7, "training_loss": 3245.7444091796874, "training_acc": 25.0, "val_loss": 2571.952880859375, "val_acc": 40.0}
{"epoch": 8, "training_loss": 981.9390838623046, "training_acc": 65.0, "val_loss": 4088.012939453125, "val_acc": 60.0}
{"epoch": 9, "training_loss": 4587.1451171875, "training_acc": 45.0, "val_loss": 3094.90673828125, "val_acc": 40.0}
{"epoch": 10, "training_loss": 3001.298291015625, "training_acc": 55.0, "val_loss": 5890.39306640625, "val_acc": 40.0}
{"epoch": 11, "training_loss": 4520.977783203125, "training_acc": 35.0, "val_loss": 2346.021240234375, "val_acc": 60.0}
{"epoch": 12, "training_loss": 2115.6486083984373, "training_acc": 55.0, "val_loss": 5534.8271484375, "val_acc": 40.0}
{"epoch": 13, "training_loss": 3813.869091796875, "training_acc": 55.0, "val_loss": 575.5453491210938, "val_acc": 60.0}
{"epoch": 14, "training_loss": 1513.48251953125, "training_acc": 25.0, "val_loss": 168.63841247558594, "val_acc": 60.0}
{"epoch": 15, "training_loss": 338.78208312988284, "training_acc": 45.0, "val_loss": 2363.609130859375, "val_acc": 60.0}
{"epoch": 16, "training_loss": 3262.411572265625, "training_acc": 45.0, "val_loss": 1249.5272216796875, "val_acc": 40.0}
{"epoch": 17, "training_loss": 1770.0045166015625, "training_acc": 55.0, "val_loss": 330.90277099609375, "val_acc": 60.0}
{"epoch": 18, "training_loss": 1560.5727416992188, "training_acc": 45.0, "val_loss": 3470.74072265625, "val_acc": 40.0}
{"epoch": 19, "training_loss": 4803.643408203125, "training_acc": 55.0, "val_loss": 3850.870361328125, "val_acc": 40.0}
{"epoch": 20, "training_loss": 1996.1328125, "training_acc": 45.0, "val_loss": 1009.3154296875, "val_acc": 60.0}
{"epoch": 21, "training_loss": 2286.91435546875, "training_acc": 35.0, "val_loss": 1736.9969482421875, "val_acc": 40.0}
{"epoch": 22, "training_loss": 1138.6009765625, "training_acc": 55.0, "val_loss": 45.42989730834961, "val_acc": 60.0}
{"epoch": 23, "training_loss": 2577.237713623047, "training_acc": 45.0, "val_loss": 4514.7431640625, "val_acc": 40.0}
{"epoch": 24, "training_loss": 2189.292431640625, "training_acc": 55.0, "val_loss": 4003.21484375, "val_acc": 60.0}
{"epoch": 25, "training_loss": 4802.12919921875, "training_acc": 45.0, "val_loss": 2479.10986328125, "val_acc": 40.0}
{"epoch": 26, "training_loss": 2829.03544921875, "training_acc": 55.0, "val_loss": 3226.04296875, "val_acc": 40.0}
{"epoch": 27, "training_loss": 1252.8714233398437, "training_acc": 65.0, "val_loss": 3644.01806640625, "val_acc": 60.0}
{"epoch": 28, "training_loss": 4444.35185546875, "training_acc": 45.0, "val_loss": 2817.682373046875, "val_acc": 40.0}
{"epoch": 29, "training_loss": 3770.8345703125, "training_acc": 55.0, "val_loss": 6244.3330078125, "val_acc": 40.0}
{"epoch": 30, "training_loss": 4940.332543945313, "training_acc": 35.0, "val_loss": 3373.52587890625, "val_acc": 60.0}
{"epoch": 31, "training_loss": 3255.5123779296873, "training_acc": 45.0, "val_loss": 2436.206787109375, "val_acc": 40.0}
{"epoch": 32, "training_loss": 1533.803076171875, "training_acc": 55.0, "val_loss": 2774.407958984375, "val_acc": 60.0}
{"epoch": 33, "training_loss": 4548.10791015625, "training_acc": 45.0, "val_loss": 1172.1790771484375, "val_acc": 60.0}
{"epoch": 34, "training_loss": 2705.50615234375, "training_acc": 55.0, "val_loss": 7548.59375, "val_acc": 40.0}
{"epoch": 35, "training_loss": 4835.944140625, "training_acc": 55.0, "val_loss": 2243.944091796875, "val_acc": 60.0}
{"epoch": 36, "training_loss": 3751.14560546875, "training_acc": 45.0, "val_loss": 242.85813903808594, "val_acc": 40.0}
{"epoch": 37, "training_loss": 866.1131530761719, "training_acc": 55.0, "val_loss": 381.6388854980469, "val_acc": 60.0}
{"epoch": 38, "training_loss": 341.8005310058594, "training_acc": 55.0, "val_loss": 1505.751220703125, "val_acc": 40.0}
{"epoch": 39, "training_loss": 957.0636962890625, "training_acc": 55.0, "val_loss": 1037.232666015625, "val_acc": 60.0}
{"epoch": 40, "training_loss": 1293.0370788574219, "training_acc": 45.0, "val_loss": 110.93682861328125, "val_acc": 60.0}
{"epoch": 41, "training_loss": 626.5553649902344, "training_acc": 45.0, "val_loss": 1600.5067138671875, "val_acc": 60.0}
