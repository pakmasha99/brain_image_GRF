"main_modify.py --pretrained_path None --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 2 --task ADNI_sex --input_option yAware --learning_rate 1e2 --batch_size 8 --weight_decay 1e-3 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 12072.150565934182, "training_acc": 50.0, "val_loss": 8381.541015625, "val_acc": 60.0}
{"epoch": 1, "training_loss": 12337.3970703125, "training_acc": 50.0, "val_loss": 6052.04638671875, "val_acc": 60.0}
{"epoch": 2, "training_loss": 5042.216650390625, "training_acc": 40.0, "val_loss": 4318.92041015625, "val_acc": 40.0}
{"epoch": 3, "training_loss": 2594.9692138671876, "training_acc": 50.0, "val_loss": 5703.828125, "val_acc": 60.0}
{"epoch": 4, "training_loss": 5829.23369140625, "training_acc": 50.0, "val_loss": 3322.104248046875, "val_acc": 40.0}
{"epoch": 5, "training_loss": 4048.11337890625, "training_acc": 50.0, "val_loss": 4570.1103515625, "val_acc": 40.0}
{"epoch": 6, "training_loss": 3294.45791015625, "training_acc": 40.0, "val_loss": 5785.54052734375, "val_acc": 60.0}
{"epoch": 7, "training_loss": 5877.022998046875, "training_acc": 50.0, "val_loss": 2067.481201171875, "val_acc": 40.0}
{"epoch": 8, "training_loss": 2707.8238525390625, "training_acc": 50.0, "val_loss": 2634.909423828125, "val_acc": 40.0}
{"epoch": 9, "training_loss": 2206.1920532226563, "training_acc": 50.0, "val_loss": 534.9785766601562, "val_acc": 60.0}
{"epoch": 10, "training_loss": 2258.5599609375, "training_acc": 50.0, "val_loss": 4766.23046875, "val_acc": 40.0}
{"epoch": 11, "training_loss": 2292.1185302734375, "training_acc": 60.0, "val_loss": 2975.283203125, "val_acc": 60.0}
{"epoch": 12, "training_loss": 2905.2383666992187, "training_acc": 50.0, "val_loss": 3595.481689453125, "val_acc": 40.0}
{"epoch": 13, "training_loss": 4124.293359375, "training_acc": 50.0, "val_loss": 1209.1087646484375, "val_acc": 40.0}
{"epoch": 14, "training_loss": 4846.571435546875, "training_acc": 40.0, "val_loss": 5250.90380859375, "val_acc": 60.0}
{"epoch": 15, "training_loss": 4513.230322265625, "training_acc": 50.0, "val_loss": 4454.86962890625, "val_acc": 40.0}
{"epoch": 16, "training_loss": 3168.9248046875, "training_acc": 50.0, "val_loss": 1584.512939453125, "val_acc": 60.0}
{"epoch": 17, "training_loss": 2390.21494140625, "training_acc": 50.0, "val_loss": 432.61163330078125, "val_acc": 40.0}
{"epoch": 18, "training_loss": 447.15491638183596, "training_acc": 50.0, "val_loss": 848.4931030273438, "val_acc": 40.0}
{"epoch": 19, "training_loss": 2059.2943359375, "training_acc": 40.0, "val_loss": 454.7884826660156, "val_acc": 60.0}
{"epoch": 20, "training_loss": 3959.6952392578123, "training_acc": 30.0, "val_loss": 5738.31982421875, "val_acc": 40.0}
{"epoch": 21, "training_loss": 3960.56826171875, "training_acc": 40.0, "val_loss": 3534.78125, "val_acc": 60.0}
{"epoch": 22, "training_loss": 3353.183203125, "training_acc": 50.0, "val_loss": 3701.141845703125, "val_acc": 40.0}
{"epoch": 23, "training_loss": 4168.96865234375, "training_acc": 50.0, "val_loss": 3722.58984375, "val_acc": 40.0}
{"epoch": 24, "training_loss": 2873.978125, "training_acc": 40.0, "val_loss": 2262.277099609375, "val_acc": 60.0}
{"epoch": 25, "training_loss": 2016.834130859375, "training_acc": 50.0, "val_loss": 5557.42578125, "val_acc": 40.0}
{"epoch": 26, "training_loss": 3631.138671875, "training_acc": 50.0, "val_loss": 2154.591552734375, "val_acc": 60.0}
{"epoch": 27, "training_loss": 3622.7189453125, "training_acc": 50.0, "val_loss": 2192.78857421875, "val_acc": 60.0}
{"epoch": 28, "training_loss": 1892.239208984375, "training_acc": 50.0, "val_loss": 1969.0947265625, "val_acc": 40.0}
{"epoch": 29, "training_loss": 1372.46083984375, "training_acc": 50.0, "val_loss": 539.8778686523438, "val_acc": 40.0}
{"epoch": 30, "training_loss": 273.88084716796874, "training_acc": 70.0, "val_loss": 996.4535522460938, "val_acc": 60.0}
{"epoch": 31, "training_loss": 1091.7285949707032, "training_acc": 50.0, "val_loss": 4104.26171875, "val_acc": 40.0}
{"epoch": 32, "training_loss": 2418.3060791015623, "training_acc": 50.0, "val_loss": 1447.6151123046875, "val_acc": 60.0}
{"epoch": 33, "training_loss": 1310.2618713378906, "training_acc": 60.0, "val_loss": 2266.5498046875, "val_acc": 40.0}
{"epoch": 34, "training_loss": 1250.4580078125, "training_acc": 60.0, "val_loss": 1415.0384521484375, "val_acc": 60.0}
{"epoch": 35, "training_loss": 1870.9808959960938, "training_acc": 40.0, "val_loss": 3365.202880859375, "val_acc": 40.0}
{"epoch": 36, "training_loss": 2530.4350341796876, "training_acc": 40.0, "val_loss": 3371.508544921875, "val_acc": 60.0}
