"main_modify.py --pretrained_path None --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 4 --task ADNI_sex --input_option yAware --learning_rate 1e2 --batch_size 8 --weight_decay 1e-3 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 14709.551046919823, "training_acc": 50.0, "val_loss": 7275.34521484375, "val_acc": 40.0}
{"epoch": 1, "training_loss": 10968.0365234375, "training_acc": 50.0, "val_loss": 8821.5546875, "val_acc": 40.0}
{"epoch": 2, "training_loss": 3321.5247802734375, "training_acc": 60.0, "val_loss": 10621.9150390625, "val_acc": 60.0}
{"epoch": 3, "training_loss": 12844.87470703125, "training_acc": 50.0, "val_loss": 4488.35009765625, "val_acc": 60.0}
{"epoch": 4, "training_loss": 2797.77607421875, "training_acc": 50.0, "val_loss": 5709.59521484375, "val_acc": 40.0}
{"epoch": 5, "training_loss": 3230.87451171875, "training_acc": 50.0, "val_loss": 3859.513427734375, "val_acc": 60.0}
{"epoch": 6, "training_loss": 5354.899951171875, "training_acc": 50.0, "val_loss": 3221.804443359375, "val_acc": 60.0}
{"epoch": 7, "training_loss": 3200.09931640625, "training_acc": 40.0, "val_loss": 8646.4755859375, "val_acc": 40.0}
{"epoch": 8, "training_loss": 6601.3486328125, "training_acc": 50.0, "val_loss": 170.171142578125, "val_acc": 40.0}
{"epoch": 9, "training_loss": 5005.920361328125, "training_acc": 40.0, "val_loss": 8754.5810546875, "val_acc": 60.0}
{"epoch": 10, "training_loss": 9666.1115234375, "training_acc": 50.0, "val_loss": 1393.0640869140625, "val_acc": 60.0}
{"epoch": 11, "training_loss": 3790.463037109375, "training_acc": 50.0, "val_loss": 11461.7548828125, "val_acc": 40.0}
{"epoch": 12, "training_loss": 8437.79130859375, "training_acc": 50.0, "val_loss": 1429.6494140625, "val_acc": 40.0}
{"epoch": 13, "training_loss": 2804.3340576171877, "training_acc": 60.0, "val_loss": 6952.47119140625, "val_acc": 60.0}
{"epoch": 14, "training_loss": 7561.0658203125, "training_acc": 50.0, "val_loss": 111.4389419555664, "val_acc": 60.0}
{"epoch": 15, "training_loss": 3490.5223022460937, "training_acc": 60.0, "val_loss": 11877.6025390625, "val_acc": 40.0}
{"epoch": 16, "training_loss": 8760.54609375, "training_acc": 50.0, "val_loss": 535.7264404296875, "val_acc": 40.0}
{"epoch": 17, "training_loss": 7784.778515625, "training_acc": 30.0, "val_loss": 9422.8720703125, "val_acc": 60.0}
{"epoch": 18, "training_loss": 9346.3798828125, "training_acc": 50.0, "val_loss": 396.1144104003906, "val_acc": 40.0}
{"epoch": 19, "training_loss": 3407.669482421875, "training_acc": 50.0, "val_loss": 6398.64208984375, "val_acc": 40.0}
{"epoch": 20, "training_loss": 4212.496923828125, "training_acc": 40.0, "val_loss": 2134.741943359375, "val_acc": 60.0}
{"epoch": 21, "training_loss": 1952.13955078125, "training_acc": 50.0, "val_loss": 1728.4471435546875, "val_acc": 40.0}
{"epoch": 22, "training_loss": 1208.177734375, "training_acc": 50.0, "val_loss": 2679.734130859375, "val_acc": 60.0}
{"epoch": 23, "training_loss": 2362.08642578125, "training_acc": 50.0, "val_loss": 1833.1165771484375, "val_acc": 40.0}
{"epoch": 24, "training_loss": 816.5399230957031, "training_acc": 50.0, "val_loss": 205.468017578125, "val_acc": 60.0}
{"epoch": 25, "training_loss": 489.9722045898437, "training_acc": 60.0, "val_loss": 2005.5570068359375, "val_acc": 60.0}
{"epoch": 26, "training_loss": 2853.23046875, "training_acc": 50.0, "val_loss": 249.9066162109375, "val_acc": 40.0}
{"epoch": 27, "training_loss": 412.5557495117188, "training_acc": 50.0, "val_loss": 1063.8553466796875, "val_acc": 40.0}
{"epoch": 28, "training_loss": 1253.2131103515626, "training_acc": 50.0, "val_loss": 92.84640502929688, "val_acc": 40.0}
{"epoch": 29, "training_loss": 357.6560546875, "training_acc": 50.0, "val_loss": 772.1480712890625, "val_acc": 40.0}
{"epoch": 30, "training_loss": 1439.647216796875, "training_acc": 40.0, "val_loss": 1310.2266845703125, "val_acc": 40.0}
{"epoch": 31, "training_loss": 1197.51337890625, "training_acc": 40.0, "val_loss": 757.0385131835938, "val_acc": 40.0}
{"epoch": 32, "training_loss": 797.4, "training_acc": 50.0, "val_loss": 2180.517822265625, "val_acc": 60.0}
{"epoch": 33, "training_loss": 1591.073779296875, "training_acc": 60.0, "val_loss": 3531.719970703125, "val_acc": 40.0}
{"epoch": 34, "training_loss": 2176.330731201172, "training_acc": 50.0, "val_loss": 3144.9658203125, "val_acc": 60.0}
{"epoch": 35, "training_loss": 4376.65419921875, "training_acc": 50.0, "val_loss": 1529.791015625, "val_acc": 60.0}
{"epoch": 36, "training_loss": 2538.26298828125, "training_acc": 50.0, "val_loss": 4625.90869140625, "val_acc": 40.0}
{"epoch": 37, "training_loss": 3820.266796875, "training_acc": 30.0, "val_loss": 3195.266845703125, "val_acc": 60.0}
{"epoch": 38, "training_loss": 2169.4497497558596, "training_acc": 50.0, "val_loss": 6711.13232421875, "val_acc": 40.0}
{"epoch": 39, "training_loss": 7490.62177734375, "training_acc": 50.0, "val_loss": 9354.8828125, "val_acc": 40.0}
{"epoch": 40, "training_loss": 4572.24033203125, "training_acc": 50.0, "val_loss": 4901.537109375, "val_acc": 60.0}
{"epoch": 41, "training_loss": 8845.73076171875, "training_acc": 50.0, "val_loss": 8032.7041015625, "val_acc": 60.0}
{"epoch": 42, "training_loss": 6265.234399414063, "training_acc": 50.0, "val_loss": 8308.357421875, "val_acc": 40.0}
{"epoch": 43, "training_loss": 10768.6771484375, "training_acc": 50.0, "val_loss": 15467.7998046875, "val_acc": 40.0}
{"epoch": 44, "training_loss": 10097.736328125, "training_acc": 50.0, "val_loss": 1169.460693359375, "val_acc": 60.0}
{"epoch": 45, "training_loss": 5606.300317382813, "training_acc": 50.0, "val_loss": 5451.2705078125, "val_acc": 60.0}
{"epoch": 46, "training_loss": 4652.2712890625, "training_acc": 50.0, "val_loss": 3767.697265625, "val_acc": 40.0}
{"epoch": 47, "training_loss": 2703.6537689208985, "training_acc": 50.0, "val_loss": 2037.560791015625, "val_acc": 60.0}
