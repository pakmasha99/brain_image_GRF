"main_modify.py --pretrained_path None --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 4 --task ADNI_sex --input_option yAware --learning_rate 1e2 --batch_size 8 --weight_decay 1e-3 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 12541.243700766563, "training_acc": 45.0, "val_loss": 14271.8515625, "val_acc": 40.0}
{"epoch": 1, "training_loss": 14274.452734375, "training_acc": 55.0, "val_loss": 18755.216796875, "val_acc": 40.0}
{"epoch": 2, "training_loss": 9896.457958984374, "training_acc": 45.0, "val_loss": 3264.202880859375, "val_acc": 60.0}
{"epoch": 3, "training_loss": 4109.900634765625, "training_acc": 45.0, "val_loss": 4296.23974609375, "val_acc": 40.0}
{"epoch": 4, "training_loss": 5333.1978515625, "training_acc": 55.0, "val_loss": 4200.373046875, "val_acc": 40.0}
{"epoch": 5, "training_loss": 2918.760546875, "training_acc": 45.0, "val_loss": 1590.5316162109375, "val_acc": 60.0}
{"epoch": 6, "training_loss": 1743.186181640625, "training_acc": 55.0, "val_loss": 2300.74462890625, "val_acc": 40.0}
{"epoch": 7, "training_loss": 1009.6003295898438, "training_acc": 35.0, "val_loss": 1991.4344482421875, "val_acc": 60.0}
{"epoch": 8, "training_loss": 2302.6017822265626, "training_acc": 45.0, "val_loss": 3245.322021484375, "val_acc": 40.0}
{"epoch": 9, "training_loss": 2864.3235107421874, "training_acc": 55.0, "val_loss": 960.5613403320312, "val_acc": 40.0}
{"epoch": 10, "training_loss": 3163.3146728515626, "training_acc": 35.0, "val_loss": 2218.191162109375, "val_acc": 60.0}
{"epoch": 11, "training_loss": 2071.2512451171874, "training_acc": 45.0, "val_loss": 1594.9656982421875, "val_acc": 40.0}
{"epoch": 12, "training_loss": 1871.0764709472655, "training_acc": 35.0, "val_loss": 510.9435729980469, "val_acc": 40.0}
{"epoch": 13, "training_loss": 1033.7211669921876, "training_acc": 45.0, "val_loss": 728.0580444335938, "val_acc": 60.0}
{"epoch": 14, "training_loss": 1113.3976196289063, "training_acc": 55.0, "val_loss": 1251.0670166015625, "val_acc": 40.0}
{"epoch": 15, "training_loss": 1387.842529296875, "training_acc": 45.0, "val_loss": 700.54150390625, "val_acc": 40.0}
{"epoch": 16, "training_loss": 841.9576538085937, "training_acc": 45.0, "val_loss": 538.4695434570312, "val_acc": 60.0}
{"epoch": 17, "training_loss": 954.5978759765625, "training_acc": 65.0, "val_loss": 2502.811767578125, "val_acc": 40.0}
{"epoch": 18, "training_loss": 1429.3651123046875, "training_acc": 35.0, "val_loss": 2280.83837890625, "val_acc": 40.0}
{"epoch": 19, "training_loss": 1443.574365234375, "training_acc": 55.0, "val_loss": 2072.73486328125, "val_acc": 60.0}
{"epoch": 20, "training_loss": 3111.61962890625, "training_acc": 45.0, "val_loss": 1888.119140625, "val_acc": 40.0}
{"epoch": 21, "training_loss": 2208.31708984375, "training_acc": 55.0, "val_loss": 1362.5423583984375, "val_acc": 40.0}
{"epoch": 22, "training_loss": 1791.0819091796875, "training_acc": 55.0, "val_loss": 1596.2083740234375, "val_acc": 60.0}
{"epoch": 23, "training_loss": 2904.25009765625, "training_acc": 35.0, "val_loss": 2148.24365234375, "val_acc": 40.0}
{"epoch": 24, "training_loss": 787.30390625, "training_acc": 65.0, "val_loss": 45.32483673095703, "val_acc": 60.0}
{"epoch": 25, "training_loss": 1074.331478881836, "training_acc": 65.0, "val_loss": 3424.51806640625, "val_acc": 40.0}
{"epoch": 26, "training_loss": 1328.987451171875, "training_acc": 65.0, "val_loss": 2871.72705078125, "val_acc": 60.0}
{"epoch": 27, "training_loss": 3323.15185546875, "training_acc": 35.0, "val_loss": 963.6689453125, "val_acc": 40.0}
{"epoch": 28, "training_loss": 978.0074829101562, "training_acc": 45.0, "val_loss": 2394.962646484375, "val_acc": 40.0}
{"epoch": 29, "training_loss": 1843.9074951171874, "training_acc": 35.0, "val_loss": 1809.4168701171875, "val_acc": 40.0}
{"epoch": 30, "training_loss": 1455.71669921875, "training_acc": 55.0, "val_loss": 2513.91845703125, "val_acc": 60.0}
{"epoch": 31, "training_loss": 3693.125378417969, "training_acc": 45.0, "val_loss": 797.4268798828125, "val_acc": 40.0}
{"epoch": 32, "training_loss": 1016.9269287109375, "training_acc": 55.0, "val_loss": 1820.75, "val_acc": 60.0}
{"epoch": 33, "training_loss": 2671.9297119140624, "training_acc": 45.0, "val_loss": 2051.705078125, "val_acc": 40.0}
{"epoch": 34, "training_loss": 1914.853369140625, "training_acc": 55.0, "val_loss": 1162.654541015625, "val_acc": 60.0}
{"epoch": 35, "training_loss": 2163.357958984375, "training_acc": 45.0, "val_loss": 2229.5888671875, "val_acc": 40.0}
{"epoch": 36, "training_loss": 2987.9011962890627, "training_acc": 55.0, "val_loss": 7.935642242431641, "val_acc": 60.0}
{"epoch": 37, "training_loss": 1450.873680496216, "training_acc": 45.0, "val_loss": 2303.76611328125, "val_acc": 40.0}
{"epoch": 38, "training_loss": 1888.303271484375, "training_acc": 55.0, "val_loss": 209.76048278808594, "val_acc": 60.0}
{"epoch": 39, "training_loss": 1031.1179931640625, "training_acc": 35.0, "val_loss": 1819.9527587890625, "val_acc": 40.0}
{"epoch": 40, "training_loss": 812.14404296875, "training_acc": 55.0, "val_loss": 2077.8447265625, "val_acc": 40.0}
{"epoch": 41, "training_loss": 1784.1848876953125, "training_acc": 55.0, "val_loss": 1401.7786865234375, "val_acc": 60.0}
{"epoch": 42, "training_loss": 1547.3767120361329, "training_acc": 45.0, "val_loss": 3872.678955078125, "val_acc": 40.0}
{"epoch": 43, "training_loss": 3604.17958984375, "training_acc": 55.0, "val_loss": 1396.656005859375, "val_acc": 40.0}
{"epoch": 44, "training_loss": 2993.199072265625, "training_acc": 45.0, "val_loss": 3127.785888671875, "val_acc": 60.0}
{"epoch": 45, "training_loss": 2285.4865234375, "training_acc": 55.0, "val_loss": 6784.7197265625, "val_acc": 40.0}
{"epoch": 46, "training_loss": 5113.734375, "training_acc": 55.0, "val_loss": 1999.5667724609375, "val_acc": 40.0}
{"epoch": 47, "training_loss": 1671.920751953125, "training_acc": 55.0, "val_loss": 1241.3248291015625, "val_acc": 60.0}
{"epoch": 48, "training_loss": 1534.367333984375, "training_acc": 55.0, "val_loss": 1891.694580078125, "val_acc": 40.0}
{"epoch": 49, "training_loss": 964.384521484375, "training_acc": 55.0, "val_loss": 993.86962890625, "val_acc": 40.0}
{"epoch": 50, "training_loss": 1125.65205078125, "training_acc": 45.0, "val_loss": 378.3199768066406, "val_acc": 60.0}
{"epoch": 51, "training_loss": 830.8392333984375, "training_acc": 65.0, "val_loss": 2006.6053466796875, "val_acc": 40.0}
{"epoch": 52, "training_loss": 1448.9078735351563, "training_acc": 35.0, "val_loss": 2802.706787109375, "val_acc": 40.0}
{"epoch": 53, "training_loss": 2619.948681640625, "training_acc": 55.0, "val_loss": 259.6089782714844, "val_acc": 60.0}
{"epoch": 54, "training_loss": 928.7513671875, "training_acc": 35.0, "val_loss": 891.89697265625, "val_acc": 40.0}
{"epoch": 55, "training_loss": 1165.5704833984375, "training_acc": 55.0, "val_loss": 281.0959167480469, "val_acc": 40.0}
