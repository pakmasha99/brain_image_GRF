"main_modify.py --pretrained_path None --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 3 --task ADNI_sex --input_option yAware --learning_rate 1e2 --batch_size 8 --weight_decay 1e-3 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 10535.815586304665, "training_acc": 50.0, "val_loss": 13595.8876953125, "val_acc": 40.0}
{"epoch": 1, "training_loss": 15379.526953125, "training_acc": 50.0, "val_loss": 14496.861328125, "val_acc": 40.0}
{"epoch": 2, "training_loss": 8381.9521484375, "training_acc": 50.0, "val_loss": 10577.7939453125, "val_acc": 60.0}
{"epoch": 3, "training_loss": 13933.1673828125, "training_acc": 50.0, "val_loss": 6875.8359375, "val_acc": 60.0}
{"epoch": 4, "training_loss": 6888.91943359375, "training_acc": 40.0, "val_loss": 11121.4052734375, "val_acc": 40.0}
{"epoch": 5, "training_loss": 9863.0705078125, "training_acc": 50.0, "val_loss": 5650.69140625, "val_acc": 40.0}
{"epoch": 6, "training_loss": 1828.1114055395126, "training_acc": 70.0, "val_loss": 5397.08203125, "val_acc": 60.0}
{"epoch": 7, "training_loss": 6539.58095703125, "training_acc": 50.0, "val_loss": 596.76953125, "val_acc": 60.0}
{"epoch": 8, "training_loss": 3082.244384765625, "training_acc": 60.0, "val_loss": 7794.47412109375, "val_acc": 40.0}
{"epoch": 9, "training_loss": 4821.5491943359375, "training_acc": 40.0, "val_loss": 1813.2750244140625, "val_acc": 60.0}
{"epoch": 10, "training_loss": 2108.5222412109374, "training_acc": 40.0, "val_loss": 1339.920166015625, "val_acc": 40.0}
{"epoch": 11, "training_loss": 967.1730834960938, "training_acc": 50.0, "val_loss": 1249.8306884765625, "val_acc": 40.0}
{"epoch": 12, "training_loss": 1124.1435546875, "training_acc": 50.0, "val_loss": 582.3184204101562, "val_acc": 60.0}
{"epoch": 13, "training_loss": 1033.9649658203125, "training_acc": 50.0, "val_loss": 954.4381713867188, "val_acc": 60.0}
{"epoch": 14, "training_loss": 1277.0426025390625, "training_acc": 40.0, "val_loss": 284.4275817871094, "val_acc": 60.0}
{"epoch": 15, "training_loss": 452.7009643554687, "training_acc": 60.0, "val_loss": 3493.41015625, "val_acc": 40.0}
{"epoch": 16, "training_loss": 2108.2115478515625, "training_acc": 50.0, "val_loss": 1245.8577880859375, "val_acc": 60.0}
{"epoch": 17, "training_loss": 944.94140625, "training_acc": 60.0, "val_loss": 3976.344970703125, "val_acc": 40.0}
{"epoch": 18, "training_loss": 3130.2782958984376, "training_acc": 50.0, "val_loss": 2720.903076171875, "val_acc": 60.0}
{"epoch": 19, "training_loss": 5169.45068359375, "training_acc": 50.0, "val_loss": 4246.59716796875, "val_acc": 60.0}
{"epoch": 20, "training_loss": 2762.4841796875, "training_acc": 60.0, "val_loss": 5003.8046875, "val_acc": 40.0}
{"epoch": 21, "training_loss": 3979.565673828125, "training_acc": 50.0, "val_loss": 254.8160400390625, "val_acc": 60.0}
{"epoch": 22, "training_loss": 1240.41494140625, "training_acc": 50.0, "val_loss": 2334.994140625, "val_acc": 40.0}
{"epoch": 23, "training_loss": 1648.2042266845704, "training_acc": 50.0, "val_loss": 2667.282470703125, "val_acc": 60.0}
{"epoch": 24, "training_loss": 3897.989404296875, "training_acc": 50.0, "val_loss": 523.8414306640625, "val_acc": 60.0}
{"epoch": 25, "training_loss": 2014.2733520507813, "training_acc": 60.0, "val_loss": 4929.8818359375, "val_acc": 40.0}
{"epoch": 26, "training_loss": 2704.01484375, "training_acc": 50.0, "val_loss": 3393.843017578125, "val_acc": 60.0}
{"epoch": 27, "training_loss": 3730.388037109375, "training_acc": 50.0, "val_loss": 2805.306396484375, "val_acc": 40.0}
{"epoch": 28, "training_loss": 4992.86025390625, "training_acc": 50.0, "val_loss": 3602.818115234375, "val_acc": 40.0}
{"epoch": 29, "training_loss": 2300.5980712890623, "training_acc": 50.0, "val_loss": 2927.38427734375, "val_acc": 60.0}
{"epoch": 30, "training_loss": 2547.148876953125, "training_acc": 50.0, "val_loss": 2773.409912109375, "val_acc": 40.0}
{"epoch": 31, "training_loss": 1828.1415771484376, "training_acc": 50.0, "val_loss": 1190.1544189453125, "val_acc": 60.0}
{"epoch": 32, "training_loss": 886.1794677734375, "training_acc": 60.0, "val_loss": 4468.89306640625, "val_acc": 40.0}
{"epoch": 33, "training_loss": 3149.2686767578125, "training_acc": 40.0, "val_loss": 690.9953002929688, "val_acc": 60.0}
{"epoch": 34, "training_loss": 1583.770458984375, "training_acc": 40.0, "val_loss": 440.431884765625, "val_acc": 60.0}
{"epoch": 35, "training_loss": 867.35517578125, "training_acc": 50.0, "val_loss": 1084.8934326171875, "val_acc": 40.0}
{"epoch": 36, "training_loss": 1675.403076171875, "training_acc": 40.0, "val_loss": 868.3404541015625, "val_acc": 40.0}
{"epoch": 37, "training_loss": 1517.7285461425781, "training_acc": 50.0, "val_loss": 2349.2109375, "val_acc": 60.0}
{"epoch": 38, "training_loss": 3347.35126953125, "training_acc": 50.0, "val_loss": 176.5116424560547, "val_acc": 40.0}
{"epoch": 39, "training_loss": 751.5525695800782, "training_acc": 40.0, "val_loss": 786.2420043945312, "val_acc": 40.0}
{"epoch": 40, "training_loss": 791.0706039428711, "training_acc": 40.0, "val_loss": 446.8890075683594, "val_acc": 40.0}
{"epoch": 41, "training_loss": 2446.5170654296876, "training_acc": 40.0, "val_loss": 2073.86083984375, "val_acc": 60.0}
{"epoch": 42, "training_loss": 1736.109619140625, "training_acc": 40.0, "val_loss": 123.98396301269531, "val_acc": 60.0}
{"epoch": 43, "training_loss": 409.0425537109375, "training_acc": 60.0, "val_loss": 1518.1395263671875, "val_acc": 60.0}
{"epoch": 44, "training_loss": 1569.42001953125, "training_acc": 50.0, "val_loss": 4111.96875, "val_acc": 40.0}
{"epoch": 45, "training_loss": 3995.1396484375, "training_acc": 50.0, "val_loss": 1765.4422607421875, "val_acc": 40.0}
{"epoch": 46, "training_loss": 3334.2966796875, "training_acc": 50.0, "val_loss": 4217.994140625, "val_acc": 60.0}
{"epoch": 47, "training_loss": 3976.718798828125, "training_acc": 40.0, "val_loss": 4083.25244140625, "val_acc": 40.0}
{"epoch": 48, "training_loss": 2820.487255859375, "training_acc": 40.0, "val_loss": 100.63932037353516, "val_acc": 60.0}
{"epoch": 49, "training_loss": 1112.4344177246094, "training_acc": 50.0, "val_loss": 353.3030700683594, "val_acc": 60.0}
{"epoch": 50, "training_loss": 1128.748779296875, "training_acc": 40.0, "val_loss": 978.4654541015625, "val_acc": 40.0}
{"epoch": 51, "training_loss": 1409.1197509765625, "training_acc": 50.0, "val_loss": 300.2923889160156, "val_acc": 60.0}
{"epoch": 52, "training_loss": 1998.422119140625, "training_acc": 50.0, "val_loss": 3597.859375, "val_acc": 40.0}
{"epoch": 53, "training_loss": 2860.541583251953, "training_acc": 40.0, "val_loss": 4469.212890625, "val_acc": 60.0}
{"epoch": 54, "training_loss": 4809.71787109375, "training_acc": 50.0, "val_loss": 3086.424560546875, "val_acc": 40.0}
{"epoch": 55, "training_loss": 5156.4517578125, "training_acc": 50.0, "val_loss": 4443.70654296875, "val_acc": 40.0}
{"epoch": 56, "training_loss": 1776.329052734375, "training_acc": 60.0, "val_loss": 5596.04052734375, "val_acc": 60.0}
{"epoch": 57, "training_loss": 7025.9015625, "training_acc": 50.0, "val_loss": 1889.9443359375, "val_acc": 60.0}
{"epoch": 58, "training_loss": 4416.70078125, "training_acc": 40.0, "val_loss": 7325.90625, "val_acc": 40.0}
{"epoch": 59, "training_loss": 4066.34501953125, "training_acc": 50.0, "val_loss": 4046.888671875, "val_acc": 60.0}
{"epoch": 60, "training_loss": 7441.2158203125, "training_acc": 50.0, "val_loss": 6726.078125, "val_acc": 60.0}
{"epoch": 61, "training_loss": 6308.235375976563, "training_acc": 40.0, "val_loss": 3675.115234375, "val_acc": 40.0}
{"epoch": 62, "training_loss": 2554.425048828125, "training_acc": 50.0, "val_loss": 2242.613037109375, "val_acc": 60.0}
{"epoch": 63, "training_loss": 3546.65283203125, "training_acc": 50.0, "val_loss": 1231.375, "val_acc": 60.0}
{"epoch": 64, "training_loss": 5092.99541015625, "training_acc": 30.0, "val_loss": 6244.51171875, "val_acc": 40.0}
{"epoch": 65, "training_loss": 2715.78173828125, "training_acc": 60.0, "val_loss": 4177.1181640625, "val_acc": 60.0}
{"epoch": 66, "training_loss": 5346.4603515625, "training_acc": 50.0, "val_loss": 871.9281616210938, "val_acc": 60.0}
{"epoch": 67, "training_loss": 4380.24208984375, "training_acc": 40.0, "val_loss": 9293.5078125, "val_acc": 40.0}
