"main_modify.py --pretrained_path None --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 3 --task ADNI_sex --input_option yAware --learning_rate 1e2 --batch_size 8 --weight_decay 1e-3 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 14712.71400346756, "training_acc": 50.0, "val_loss": 4785.84765625, "val_acc": 60.0}
{"epoch": 1, "training_loss": 9567.316796875, "training_acc": 50.0, "val_loss": 5108.53271484375, "val_acc": 60.0}
{"epoch": 2, "training_loss": 3396.646826171875, "training_acc": 60.0, "val_loss": 7071.23828125, "val_acc": 40.0}
{"epoch": 3, "training_loss": 3949.511572265625, "training_acc": 50.0, "val_loss": 2669.3603515625, "val_acc": 60.0}
{"epoch": 4, "training_loss": 2965.8576171875, "training_acc": 40.0, "val_loss": 1929.6177978515625, "val_acc": 40.0}
{"epoch": 5, "training_loss": 1094.0194732666016, "training_acc": 50.0, "val_loss": 1497.4781494140625, "val_acc": 40.0}
{"epoch": 6, "training_loss": 1056.983871459961, "training_acc": 40.0, "val_loss": 334.9233703613281, "val_acc": 40.0}
{"epoch": 7, "training_loss": 1181.3028076171875, "training_acc": 50.0, "val_loss": 464.993408203125, "val_acc": 40.0}
{"epoch": 8, "training_loss": 697.1515258789062, "training_acc": 40.0, "val_loss": 370.97662353515625, "val_acc": 40.0}
{"epoch": 9, "training_loss": 537.9941040039063, "training_acc": 70.0, "val_loss": 115.39517974853516, "val_acc": 40.0}
{"epoch": 10, "training_loss": 1062.8616271972655, "training_acc": 30.0, "val_loss": 532.6307983398438, "val_acc": 60.0}
{"epoch": 11, "training_loss": 894.6361328125, "training_acc": 40.0, "val_loss": 788.8517456054688, "val_acc": 60.0}
{"epoch": 12, "training_loss": 642.59814453125, "training_acc": 60.0, "val_loss": 4019.791748046875, "val_acc": 40.0}
{"epoch": 13, "training_loss": 2873.7328369140623, "training_acc": 40.0, "val_loss": 526.236572265625, "val_acc": 60.0}
{"epoch": 14, "training_loss": 935.3369140625, "training_acc": 50.0, "val_loss": 1242.3477783203125, "val_acc": 60.0}
{"epoch": 15, "training_loss": 1464.198876953125, "training_acc": 40.0, "val_loss": 462.49658203125, "val_acc": 60.0}
{"epoch": 16, "training_loss": 499.5887817382812, "training_acc": 50.0, "val_loss": 53.08486557006836, "val_acc": 60.0}
{"epoch": 17, "training_loss": 3740.443490600586, "training_acc": 20.0, "val_loss": 2715.691162109375, "val_acc": 40.0}
{"epoch": 18, "training_loss": 1428.7675537109376, "training_acc": 60.0, "val_loss": 2177.3505859375, "val_acc": 60.0}
{"epoch": 19, "training_loss": 1969.4361572265625, "training_acc": 50.0, "val_loss": 4440.74560546875, "val_acc": 40.0}
{"epoch": 20, "training_loss": 2622.858264160156, "training_acc": 50.0, "val_loss": 750.44970703125, "val_acc": 60.0}
{"epoch": 21, "training_loss": 915.5972320556641, "training_acc": 50.0, "val_loss": 4664.5244140625, "val_acc": 40.0}
{"epoch": 22, "training_loss": 3169.3467529296877, "training_acc": 40.0, "val_loss": 774.2255249023438, "val_acc": 60.0}
{"epoch": 23, "training_loss": 301.2144435882568, "training_acc": 60.0, "val_loss": 2202.493408203125, "val_acc": 60.0}
{"epoch": 24, "training_loss": 3147.9431640625, "training_acc": 50.0, "val_loss": 1341.2176513671875, "val_acc": 40.0}
{"epoch": 25, "training_loss": 1591.7945556640625, "training_acc": 50.0, "val_loss": 1168.5797119140625, "val_acc": 60.0}
{"epoch": 26, "training_loss": 1513.341259765625, "training_acc": 50.0, "val_loss": 3089.329345703125, "val_acc": 40.0}
{"epoch": 27, "training_loss": 2625.650036621094, "training_acc": 50.0, "val_loss": 831.1785278320312, "val_acc": 60.0}
{"epoch": 28, "training_loss": 1504.89931640625, "training_acc": 40.0, "val_loss": 354.6770324707031, "val_acc": 60.0}
{"epoch": 29, "training_loss": 188.24393463134766, "training_acc": 70.0, "val_loss": 588.2694091796875, "val_acc": 40.0}
{"epoch": 30, "training_loss": 1004.8526245117188, "training_acc": 40.0, "val_loss": 2478.68603515625, "val_acc": 40.0}
{"epoch": 31, "training_loss": 2784.782177734375, "training_acc": 50.0, "val_loss": 1618.9808349609375, "val_acc": 60.0}
{"epoch": 32, "training_loss": 3968.742626953125, "training_acc": 50.0, "val_loss": 1819.1151123046875, "val_acc": 60.0}
{"epoch": 33, "training_loss": 2335.90859375, "training_acc": 50.0, "val_loss": 4769.830078125, "val_acc": 40.0}
{"epoch": 34, "training_loss": 3799.311669921875, "training_acc": 30.0, "val_loss": 1677.553955078125, "val_acc": 60.0}
{"epoch": 35, "training_loss": 1290.3735054016113, "training_acc": 40.0, "val_loss": 2080.408935546875, "val_acc": 60.0}
