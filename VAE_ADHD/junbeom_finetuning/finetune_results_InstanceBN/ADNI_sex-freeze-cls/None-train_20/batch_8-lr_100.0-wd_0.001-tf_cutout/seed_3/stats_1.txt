"main_modify.py --pretrained_path None --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 3 --task ADNI_sex --input_option yAware --learning_rate 1e2 --batch_size 8 --weight_decay 1e-3 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 11380.570236873627, "training_acc": 50.0, "val_loss": 9862.6318359375, "val_acc": 40.0}
{"epoch": 1, "training_loss": 9906.099609375, "training_acc": 50.0, "val_loss": 2244.9287109375, "val_acc": 40.0}
{"epoch": 2, "training_loss": 9427.1615234375, "training_acc": 30.0, "val_loss": 9281.75, "val_acc": 60.0}
{"epoch": 3, "training_loss": 7615.70419921875, "training_acc": 50.0, "val_loss": 8389.455078125, "val_acc": 40.0}
{"epoch": 4, "training_loss": 8576.05, "training_acc": 50.0, "val_loss": 12194.33984375, "val_acc": 40.0}
{"epoch": 5, "training_loss": 6234.298486328125, "training_acc": 50.0, "val_loss": 4904.5390625, "val_acc": 60.0}
{"epoch": 6, "training_loss": 8503.1244140625, "training_acc": 50.0, "val_loss": 8864.8076171875, "val_acc": 60.0}
{"epoch": 7, "training_loss": 7842.89931640625, "training_acc": 50.0, "val_loss": 3723.447021484375, "val_acc": 40.0}
{"epoch": 8, "training_loss": 6011.402734375, "training_acc": 50.0, "val_loss": 10152.205078125, "val_acc": 40.0}
{"epoch": 9, "training_loss": 5615.5052734375, "training_acc": 50.0, "val_loss": 3690.63720703125, "val_acc": 60.0}
{"epoch": 10, "training_loss": 8031.20546875, "training_acc": 50.0, "val_loss": 7063.4765625, "val_acc": 60.0}
{"epoch": 11, "training_loss": 5678.468518066406, "training_acc": 50.0, "val_loss": 7494.30419921875, "val_acc": 40.0}
{"epoch": 12, "training_loss": 8578.4119140625, "training_acc": 50.0, "val_loss": 12242.322265625, "val_acc": 40.0}
{"epoch": 13, "training_loss": 7395.40927734375, "training_acc": 50.0, "val_loss": 2049.134521484375, "val_acc": 60.0}
{"epoch": 14, "training_loss": 3897.678466796875, "training_acc": 50.0, "val_loss": 5437.32666015625, "val_acc": 60.0}
{"epoch": 15, "training_loss": 4467.49296875, "training_acc": 50.0, "val_loss": 4780.6640625, "val_acc": 40.0}
{"epoch": 16, "training_loss": 5695.540283203125, "training_acc": 50.0, "val_loss": 9314.0927734375, "val_acc": 40.0}
{"epoch": 17, "training_loss": 5520.851220703125, "training_acc": 50.0, "val_loss": 3350.04296875, "val_acc": 60.0}
{"epoch": 18, "training_loss": 4738.414208984375, "training_acc": 50.0, "val_loss": 4476.99755859375, "val_acc": 60.0}
{"epoch": 19, "training_loss": 3424.9902465820314, "training_acc": 60.0, "val_loss": 4385.97998046875, "val_acc": 40.0}
{"epoch": 20, "training_loss": 3116.5003173828127, "training_acc": 50.0, "val_loss": 1333.8494873046875, "val_acc": 60.0}
{"epoch": 21, "training_loss": 2519.435498046875, "training_acc": 50.0, "val_loss": 704.29296875, "val_acc": 40.0}
{"epoch": 22, "training_loss": 606.7678833007812, "training_acc": 50.0, "val_loss": 522.1595458984375, "val_acc": 40.0}
{"epoch": 23, "training_loss": 184.86115493774415, "training_acc": 70.0, "val_loss": 464.696044921875, "val_acc": 60.0}
{"epoch": 24, "training_loss": 991.439892578125, "training_acc": 40.0, "val_loss": 1773.4241943359375, "val_acc": 60.0}
{"epoch": 25, "training_loss": 2476.669873046875, "training_acc": 50.0, "val_loss": 1330.4681396484375, "val_acc": 40.0}
{"epoch": 26, "training_loss": 1063.076611328125, "training_acc": 50.0, "val_loss": 1988.6195068359375, "val_acc": 60.0}
{"epoch": 27, "training_loss": 2945.009228515625, "training_acc": 50.0, "val_loss": 1394.0521240234375, "val_acc": 40.0}
{"epoch": 28, "training_loss": 1938.190625, "training_acc": 50.0, "val_loss": 312.2207946777344, "val_acc": 60.0}
{"epoch": 29, "training_loss": 617.4468627929688, "training_acc": 50.0, "val_loss": 4468.4697265625, "val_acc": 40.0}
{"epoch": 30, "training_loss": 4483.565234375, "training_acc": 50.0, "val_loss": 1933.9322509765625, "val_acc": 40.0}
{"epoch": 31, "training_loss": 3531.106640625, "training_acc": 40.0, "val_loss": 4772.44873046875, "val_acc": 60.0}
{"epoch": 32, "training_loss": 4545.086169052124, "training_acc": 50.0, "val_loss": 5203.37353515625, "val_acc": 40.0}
{"epoch": 33, "training_loss": 4678.95595703125, "training_acc": 50.0, "val_loss": 3567.0703125, "val_acc": 40.0}
{"epoch": 34, "training_loss": 2033.0659912109375, "training_acc": 50.0, "val_loss": 821.4644775390625, "val_acc": 60.0}
{"epoch": 35, "training_loss": 1250.2528564453125, "training_acc": 60.0, "val_loss": 1486.4627685546875, "val_acc": 40.0}
{"epoch": 36, "training_loss": 998.478271484375, "training_acc": 60.0, "val_loss": 778.86328125, "val_acc": 60.0}
{"epoch": 37, "training_loss": 1019.1257568359375, "training_acc": 50.0, "val_loss": 766.68603515625, "val_acc": 60.0}
{"epoch": 38, "training_loss": 952.7308837890625, "training_acc": 50.0, "val_loss": 1318.7919921875, "val_acc": 40.0}
{"epoch": 39, "training_loss": 1471.017724609375, "training_acc": 40.0, "val_loss": 1047.3565673828125, "val_acc": 40.0}
{"epoch": 40, "training_loss": 1174.90390625, "training_acc": 40.0, "val_loss": 953.8486328125, "val_acc": 60.0}
{"epoch": 41, "training_loss": 1125.3170166015625, "training_acc": 60.0, "val_loss": 70.76727294921875, "val_acc": 60.0}
{"epoch": 42, "training_loss": 186.94045867919922, "training_acc": 60.0, "val_loss": 2085.205810546875, "val_acc": 40.0}
{"epoch": 43, "training_loss": 2546.864111328125, "training_acc": 20.0, "val_loss": 2108.076171875, "val_acc": 40.0}
{"epoch": 44, "training_loss": 2710.384765625, "training_acc": 50.0, "val_loss": 327.2845764160156, "val_acc": 60.0}
{"epoch": 45, "training_loss": 474.68303833007815, "training_acc": 50.0, "val_loss": 149.50210571289062, "val_acc": 40.0}
{"epoch": 46, "training_loss": 1061.1567077636719, "training_acc": 60.0, "val_loss": 841.9488525390625, "val_acc": 60.0}
{"epoch": 47, "training_loss": 2186.526318359375, "training_acc": 40.0, "val_loss": 1495.6629638671875, "val_acc": 40.0}
{"epoch": 48, "training_loss": 1365.107080078125, "training_acc": 60.0, "val_loss": 1274.3970947265625, "val_acc": 60.0}
{"epoch": 49, "training_loss": 2319.32646484375, "training_acc": 40.0, "val_loss": 974.796875, "val_acc": 40.0}
{"epoch": 50, "training_loss": 1441.32060546875, "training_acc": 60.0, "val_loss": 2506.415283203125, "val_acc": 60.0}
{"epoch": 51, "training_loss": 2827.2101806640626, "training_acc": 40.0, "val_loss": 4262.390625, "val_acc": 40.0}
{"epoch": 52, "training_loss": 2590.5920166015626, "training_acc": 50.0, "val_loss": 1312.9647216796875, "val_acc": 60.0}
{"epoch": 53, "training_loss": 1346.6735595703126, "training_acc": 50.0, "val_loss": 2800.530517578125, "val_acc": 40.0}
{"epoch": 54, "training_loss": 2224.083203125, "training_acc": 40.0, "val_loss": 2504.582763671875, "val_acc": 60.0}
{"epoch": 55, "training_loss": 1851.7880493164062, "training_acc": 60.0, "val_loss": 2942.19189453125, "val_acc": 40.0}
{"epoch": 56, "training_loss": 1842.1826416015624, "training_acc": 50.0, "val_loss": 833.0101928710938, "val_acc": 60.0}
{"epoch": 57, "training_loss": 609.237939453125, "training_acc": 60.0, "val_loss": 5488.12890625, "val_acc": 40.0}
{"epoch": 58, "training_loss": 4016.74326171875, "training_acc": 50.0, "val_loss": 1897.6929931640625, "val_acc": 60.0}
{"epoch": 59, "training_loss": 3131.4689453125, "training_acc": 50.0, "val_loss": 909.9935913085938, "val_acc": 60.0}
{"epoch": 60, "training_loss": 2858.814501953125, "training_acc": 50.0, "val_loss": 6052.81591796875, "val_acc": 40.0}
