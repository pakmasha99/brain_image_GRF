"main_modify.py --pretrained_path None --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 1 --task ADNI_sex --input_option yAware --learning_rate 1e2 --batch_size 8 --weight_decay 1e-3 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 9160.301512908936, "training_acc": 55.0, "val_loss": 8521.0478515625, "val_acc": 60.0}
{"epoch": 1, "training_loss": 11167.155126953125, "training_acc": 45.0, "val_loss": 2253.66455078125, "val_acc": 40.0}
{"epoch": 2, "training_loss": 4141.525390625, "training_acc": 55.0, "val_loss": 455.7294921875, "val_acc": 60.0}
{"epoch": 3, "training_loss": 1700.6441772460937, "training_acc": 45.0, "val_loss": 186.2393341064453, "val_acc": 40.0}
{"epoch": 4, "training_loss": 1146.5769348144531, "training_acc": 55.0, "val_loss": 2175.201904296875, "val_acc": 40.0}
{"epoch": 5, "training_loss": 1818.85751953125, "training_acc": 45.0, "val_loss": 277.8836364746094, "val_acc": 40.0}
{"epoch": 6, "training_loss": 1132.0477783203125, "training_acc": 35.0, "val_loss": 4261.42626953125, "val_acc": 40.0}
{"epoch": 7, "training_loss": 3657.66220703125, "training_acc": 55.0, "val_loss": 727.3500366210938, "val_acc": 40.0}
{"epoch": 8, "training_loss": 3581.577685546875, "training_acc": 35.0, "val_loss": 2064.823974609375, "val_acc": 60.0}
{"epoch": 9, "training_loss": 3663.179736328125, "training_acc": 45.0, "val_loss": 4325.5283203125, "val_acc": 40.0}
{"epoch": 10, "training_loss": 1890.16375579834, "training_acc": 35.0, "val_loss": 860.765625, "val_acc": 40.0}
{"epoch": 11, "training_loss": 806.1668212890625, "training_acc": 55.0, "val_loss": 1789.8699951171875, "val_acc": 60.0}
{"epoch": 12, "training_loss": 1403.1548828125, "training_acc": 55.0, "val_loss": 5826.62646484375, "val_acc": 40.0}
{"epoch": 13, "training_loss": 3872.4236328125, "training_acc": 55.0, "val_loss": 709.1043090820312, "val_acc": 60.0}
{"epoch": 14, "training_loss": 1764.0557006835938, "training_acc": 45.0, "val_loss": 2290.517333984375, "val_acc": 40.0}
{"epoch": 15, "training_loss": 1682.564385986328, "training_acc": 55.0, "val_loss": 1662.4859619140625, "val_acc": 60.0}
{"epoch": 16, "training_loss": 2048.597085571289, "training_acc": 45.0, "val_loss": 4479.75048828125, "val_acc": 40.0}
{"epoch": 17, "training_loss": 4429.31494140625, "training_acc": 55.0, "val_loss": 3400.607177734375, "val_acc": 40.0}
{"epoch": 18, "training_loss": 1353.1218139648438, "training_acc": 55.0, "val_loss": 400.58135986328125, "val_acc": 60.0}
{"epoch": 19, "training_loss": 2398.35205078125, "training_acc": 45.0, "val_loss": 3094.773193359375, "val_acc": 40.0}
{"epoch": 20, "training_loss": 733.0980438232422, "training_acc": 65.0, "val_loss": 153.57467651367188, "val_acc": 40.0}
{"epoch": 21, "training_loss": 267.90093383789065, "training_acc": 65.0, "val_loss": 1932.2301025390625, "val_acc": 60.0}
{"epoch": 22, "training_loss": 2683.663728618622, "training_acc": 35.0, "val_loss": 5656.78076171875, "val_acc": 40.0}
{"epoch": 23, "training_loss": 3181.45927734375, "training_acc": 55.0, "val_loss": 1048.033447265625, "val_acc": 60.0}
{"epoch": 24, "training_loss": 1080.1061279296875, "training_acc": 45.0, "val_loss": 1493.3170166015625, "val_acc": 60.0}
{"epoch": 25, "training_loss": 2208.3594665527344, "training_acc": 35.0, "val_loss": 217.218994140625, "val_acc": 60.0}
{"epoch": 26, "training_loss": 1658.5980346679687, "training_acc": 35.0, "val_loss": 456.0985412597656, "val_acc": 60.0}
{"epoch": 27, "training_loss": 1568.011572265625, "training_acc": 45.0, "val_loss": 4308.88916015625, "val_acc": 40.0}
{"epoch": 28, "training_loss": 4507.642919921875, "training_acc": 55.0, "val_loss": 4260.7236328125, "val_acc": 40.0}
{"epoch": 29, "training_loss": 2510.826611328125, "training_acc": 35.0, "val_loss": 75.5080337524414, "val_acc": 40.0}
{"epoch": 30, "training_loss": 192.86375427246094, "training_acc": 65.0, "val_loss": 922.9132690429688, "val_acc": 60.0}
{"epoch": 31, "training_loss": 1269.639892578125, "training_acc": 45.0, "val_loss": 481.1570739746094, "val_acc": 60.0}
{"epoch": 32, "training_loss": 725.8541870117188, "training_acc": 55.0, "val_loss": 2860.7021484375, "val_acc": 40.0}
{"epoch": 33, "training_loss": 2056.1540771484374, "training_acc": 45.0, "val_loss": 1392.921142578125, "val_acc": 60.0}
{"epoch": 34, "training_loss": 1474.95078125, "training_acc": 45.0, "val_loss": 150.2952880859375, "val_acc": 40.0}
{"epoch": 35, "training_loss": 1284.2672973632812, "training_acc": 55.0, "val_loss": 261.9666442871094, "val_acc": 60.0}
{"epoch": 36, "training_loss": 1821.0358154296875, "training_acc": 55.0, "val_loss": 3927.926513671875, "val_acc": 40.0}
{"epoch": 37, "training_loss": 2596.2597900390624, "training_acc": 25.0, "val_loss": 1593.7264404296875, "val_acc": 40.0}
{"epoch": 38, "training_loss": 1040.6071472167969, "training_acc": 55.0, "val_loss": 2260.696044921875, "val_acc": 60.0}
{"epoch": 39, "training_loss": 2882.45908203125, "training_acc": 45.0, "val_loss": 2741.79736328125, "val_acc": 40.0}
{"epoch": 40, "training_loss": 2844.297314453125, "training_acc": 55.0, "val_loss": 2227.113037109375, "val_acc": 40.0}
{"epoch": 41, "training_loss": 698.8995788574218, "training_acc": 65.0, "val_loss": 110.29524230957031, "val_acc": 60.0}
{"epoch": 42, "training_loss": 521.1477172851562, "training_acc": 75.0, "val_loss": 1568.126220703125, "val_acc": 40.0}
{"epoch": 43, "training_loss": 1500.287939453125, "training_acc": 45.0, "val_loss": 1301.5975341796875, "val_acc": 40.0}
{"epoch": 44, "training_loss": 1066.0408020019531, "training_acc": 45.0, "val_loss": 1623.6072998046875, "val_acc": 40.0}
{"epoch": 45, "training_loss": 1204.3482177734375, "training_acc": 55.0, "val_loss": 505.7041015625, "val_acc": 60.0}
{"epoch": 46, "training_loss": 2109.108837890625, "training_acc": 35.0, "val_loss": 371.89208984375, "val_acc": 40.0}
{"epoch": 47, "training_loss": 3321.799560546875, "training_acc": 45.0, "val_loss": 3135.861083984375, "val_acc": 60.0}
{"epoch": 48, "training_loss": 2799.9651611328127, "training_acc": 45.0, "val_loss": 9649.138671875, "val_acc": 40.0}
