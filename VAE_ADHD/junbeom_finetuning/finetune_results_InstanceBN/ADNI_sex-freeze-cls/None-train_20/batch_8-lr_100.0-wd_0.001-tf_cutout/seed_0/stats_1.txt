"main_modify.py --pretrained_path None --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_sex --input_option yAware --learning_rate 1e2 --batch_size 8 --weight_decay 1e-3 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 11269.330955648422, "training_acc": 40.0, "val_loss": 6093.9267578125, "val_acc": 60.0}
{"epoch": 1, "training_loss": 13029.7353515625, "training_acc": 50.0, "val_loss": 7679.56787109375, "val_acc": 60.0}
{"epoch": 2, "training_loss": 6118.326171875, "training_acc": 50.0, "val_loss": 16126.5185546875, "val_acc": 40.0}
{"epoch": 3, "training_loss": 12843.053125, "training_acc": 50.0, "val_loss": 7427.75146484375, "val_acc": 40.0}
{"epoch": 4, "training_loss": 3187.6421875, "training_acc": 60.0, "val_loss": 5753.6171875, "val_acc": 60.0}
{"epoch": 5, "training_loss": 5952.48115234375, "training_acc": 50.0, "val_loss": 2104.482421875, "val_acc": 40.0}
{"epoch": 6, "training_loss": 3021.7642578125, "training_acc": 50.0, "val_loss": 1800.5133056640625, "val_acc": 40.0}
{"epoch": 7, "training_loss": 1583.6658203125, "training_acc": 60.0, "val_loss": 2513.716064453125, "val_acc": 60.0}
{"epoch": 8, "training_loss": 2236.204345703125, "training_acc": 50.0, "val_loss": 5107.21240234375, "val_acc": 40.0}
{"epoch": 9, "training_loss": 2942.0371826171877, "training_acc": 50.0, "val_loss": 3285.612060546875, "val_acc": 60.0}
{"epoch": 10, "training_loss": 7542.049267578125, "training_acc": 50.0, "val_loss": 4118.6640625, "val_acc": 60.0}
{"epoch": 11, "training_loss": 2721.027587890625, "training_acc": 60.0, "val_loss": 10869.2880859375, "val_acc": 40.0}
{"epoch": 12, "training_loss": 10225.06953125, "training_acc": 50.0, "val_loss": 7683.59619140625, "val_acc": 40.0}
{"epoch": 13, "training_loss": 4927.548510742187, "training_acc": 40.0, "val_loss": 8569.7421875, "val_acc": 60.0}
{"epoch": 14, "training_loss": 10682.77138671875, "training_acc": 50.0, "val_loss": 5537.3603515625, "val_acc": 60.0}
{"epoch": 15, "training_loss": 4822.5642578125, "training_acc": 50.0, "val_loss": 8272.0263671875, "val_acc": 40.0}
{"epoch": 16, "training_loss": 7186.6802734375, "training_acc": 50.0, "val_loss": 3977.17236328125, "val_acc": 40.0}
{"epoch": 17, "training_loss": 3017.865185546875, "training_acc": 50.0, "val_loss": 4247.15625, "val_acc": 60.0}
{"epoch": 18, "training_loss": 4078.3984924316405, "training_acc": 50.0, "val_loss": 4806.55029296875, "val_acc": 40.0}
{"epoch": 19, "training_loss": 5040.544189453125, "training_acc": 50.0, "val_loss": 3910.356201171875, "val_acc": 40.0}
{"epoch": 20, "training_loss": 1482.22841796875, "training_acc": 60.0, "val_loss": 6056.41796875, "val_acc": 60.0}
{"epoch": 21, "training_loss": 7380.934375, "training_acc": 50.0, "val_loss": 2322.638427734375, "val_acc": 60.0}
{"epoch": 22, "training_loss": 1917.364892578125, "training_acc": 60.0, "val_loss": 5753.12255859375, "val_acc": 40.0}
{"epoch": 23, "training_loss": 3744.747424316406, "training_acc": 40.0, "val_loss": 501.9330139160156, "val_acc": 60.0}
{"epoch": 24, "training_loss": 798.3140380859375, "training_acc": 50.0, "val_loss": 1504.0079345703125, "val_acc": 60.0}
{"epoch": 25, "training_loss": 1508.5340881347656, "training_acc": 50.0, "val_loss": 3170.5, "val_acc": 40.0}
{"epoch": 26, "training_loss": 2613.0179931640623, "training_acc": 50.0, "val_loss": 1013.3858642578125, "val_acc": 60.0}
{"epoch": 27, "training_loss": 1513.9222412109375, "training_acc": 50.0, "val_loss": 3479.313720703125, "val_acc": 40.0}
{"epoch": 28, "training_loss": 3049.683630371094, "training_acc": 50.0, "val_loss": 230.96067810058594, "val_acc": 60.0}
{"epoch": 29, "training_loss": 340.5664489746094, "training_acc": 60.0, "val_loss": 983.7451171875, "val_acc": 40.0}
{"epoch": 30, "training_loss": 846.2544921875, "training_acc": 50.0, "val_loss": 1812.7918701171875, "val_acc": 40.0}
{"epoch": 31, "training_loss": 1975.037890625, "training_acc": 30.0, "val_loss": 342.74932861328125, "val_acc": 60.0}
{"epoch": 32, "training_loss": 1886.8459716796874, "training_acc": 50.0, "val_loss": 2494.436767578125, "val_acc": 40.0}
{"epoch": 33, "training_loss": 1489.7877075195313, "training_acc": 50.0, "val_loss": 689.29443359375, "val_acc": 60.0}
{"epoch": 34, "training_loss": 2932.3716796875, "training_acc": 30.0, "val_loss": 820.2540893554688, "val_acc": 40.0}
{"epoch": 35, "training_loss": 2022.6409790039063, "training_acc": 60.0, "val_loss": 4213.12109375, "val_acc": 60.0}
{"epoch": 36, "training_loss": 3400.54296875, "training_acc": 50.0, "val_loss": 5854.5947265625, "val_acc": 40.0}
{"epoch": 37, "training_loss": 6825.84453125, "training_acc": 50.0, "val_loss": 8179.0439453125, "val_acc": 40.0}
{"epoch": 38, "training_loss": 5073.162646484375, "training_acc": 40.0, "val_loss": 3827.413330078125, "val_acc": 60.0}
{"epoch": 39, "training_loss": 4784.8056640625, "training_acc": 50.0, "val_loss": 1076.0155029296875, "val_acc": 40.0}
{"epoch": 40, "training_loss": 976.3124572753907, "training_acc": 50.0, "val_loss": 2374.890380859375, "val_acc": 60.0}
{"epoch": 41, "training_loss": 3591.4072265625, "training_acc": 50.0, "val_loss": 320.68341064453125, "val_acc": 40.0}
{"epoch": 42, "training_loss": 401.85869140625, "training_acc": 50.0, "val_loss": 1045.3612060546875, "val_acc": 40.0}
{"epoch": 43, "training_loss": 1151.5785766601562, "training_acc": 30.0, "val_loss": 3555.490234375, "val_acc": 40.0}
{"epoch": 44, "training_loss": 3825.78349609375, "training_acc": 50.0, "val_loss": 370.6435241699219, "val_acc": 40.0}
{"epoch": 45, "training_loss": 3444.553955078125, "training_acc": 50.0, "val_loss": 5823.68359375, "val_acc": 60.0}
{"epoch": 46, "training_loss": 5610.468432617187, "training_acc": 50.0, "val_loss": 4815.2001953125, "val_acc": 40.0}
{"epoch": 47, "training_loss": 5409.377734375, "training_acc": 50.0, "val_loss": 5333.20068359375, "val_acc": 40.0}
