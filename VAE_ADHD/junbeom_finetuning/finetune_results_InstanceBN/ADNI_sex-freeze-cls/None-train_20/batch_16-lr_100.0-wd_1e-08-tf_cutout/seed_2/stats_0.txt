"main_modify.py --pretrained_path None --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 2 --task ADNI_sex --input_option yAware --learning_rate 1e2 --batch_size 16 --weight_decay 1e-8 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 4296.023375892639, "training_acc": 50.0, "val_loss": 5812.8251953125, "val_acc": 60.0}
{"epoch": 1, "training_loss": 9622.2361328125, "training_acc": 40.0, "val_loss": 13997.21875, "val_acc": 40.0}
{"epoch": 2, "training_loss": 10881.9453125, "training_acc": 50.0, "val_loss": 295.87548828125, "val_acc": 40.0}
{"epoch": 3, "training_loss": 2159.934765625, "training_acc": 50.0, "val_loss": 11598.9638671875, "val_acc": 60.0}
{"epoch": 4, "training_loss": 14790.18515625, "training_acc": 50.0, "val_loss": 9313.9052734375, "val_acc": 60.0}
{"epoch": 5, "training_loss": 9872.1408203125, "training_acc": 50.0, "val_loss": 3857.29541015625, "val_acc": 40.0}
{"epoch": 6, "training_loss": 3695.61806640625, "training_acc": 50.0, "val_loss": 13234.6123046875, "val_acc": 40.0}
{"epoch": 7, "training_loss": 11012.4685546875, "training_acc": 50.0, "val_loss": 11248.5068359375, "val_acc": 40.0}
{"epoch": 8, "training_loss": 8974.243408203125, "training_acc": 50.0, "val_loss": 601.76416015625, "val_acc": 40.0}
{"epoch": 9, "training_loss": 3184.55087890625, "training_acc": 30.0, "val_loss": 6647.7236328125, "val_acc": 60.0}
{"epoch": 10, "training_loss": 8166.7828125, "training_acc": 50.0, "val_loss": 3382.36767578125, "val_acc": 60.0}
{"epoch": 11, "training_loss": 4205.62509765625, "training_acc": 40.0, "val_loss": 3774.36572265625, "val_acc": 40.0}
{"epoch": 12, "training_loss": 3061.90068359375, "training_acc": 50.0, "val_loss": 393.5947265625, "val_acc": 40.0}
{"epoch": 13, "training_loss": 589.692333984375, "training_acc": 60.0, "val_loss": 4931.2861328125, "val_acc": 60.0}
{"epoch": 14, "training_loss": 6471.1771484375, "training_acc": 50.0, "val_loss": 2920.84033203125, "val_acc": 60.0}
{"epoch": 15, "training_loss": 3175.81796875, "training_acc": 50.0, "val_loss": 4466.8515625, "val_acc": 40.0}
{"epoch": 16, "training_loss": 3769.07021484375, "training_acc": 50.0, "val_loss": 2658.627685546875, "val_acc": 40.0}
{"epoch": 17, "training_loss": 1327.10390625, "training_acc": 70.0, "val_loss": 2911.13671875, "val_acc": 60.0}
{"epoch": 18, "training_loss": 3742.9013671875, "training_acc": 50.0, "val_loss": 2087.0908203125, "val_acc": 60.0}
{"epoch": 19, "training_loss": 1881.5748657226563, "training_acc": 60.0, "val_loss": 2853.569580078125, "val_acc": 40.0}
{"epoch": 20, "training_loss": 2302.07236328125, "training_acc": 50.0, "val_loss": 269.5411071777344, "val_acc": 60.0}
{"epoch": 21, "training_loss": 440.344384765625, "training_acc": 50.0, "val_loss": 2415.604736328125, "val_acc": 40.0}
{"epoch": 22, "training_loss": 2028.4385009765624, "training_acc": 50.0, "val_loss": 1601.135986328125, "val_acc": 40.0}
{"epoch": 23, "training_loss": 1053.086181640625, "training_acc": 60.0, "val_loss": 1988.9937744140625, "val_acc": 60.0}
{"epoch": 24, "training_loss": 2308.8098388671874, "training_acc": 50.0, "val_loss": 1477.9918212890625, "val_acc": 40.0}
{"epoch": 25, "training_loss": 1330.5841796875, "training_acc": 50.0, "val_loss": 190.96360778808594, "val_acc": 40.0}
{"epoch": 26, "training_loss": 417.220068359375, "training_acc": 60.0, "val_loss": 3957.364501953125, "val_acc": 60.0}
{"epoch": 27, "training_loss": 4872.01630859375, "training_acc": 50.0, "val_loss": 1753.157470703125, "val_acc": 60.0}
{"epoch": 28, "training_loss": 2152.97822265625, "training_acc": 50.0, "val_loss": 4505.927734375, "val_acc": 40.0}
{"epoch": 29, "training_loss": 3677.276953125, "training_acc": 50.0, "val_loss": 1502.4019775390625, "val_acc": 40.0}
{"epoch": 30, "training_loss": 749.3376953125, "training_acc": 70.0, "val_loss": 3772.481201171875, "val_acc": 60.0}
{"epoch": 31, "training_loss": 4807.047265625, "training_acc": 50.0, "val_loss": 2780.459716796875, "val_acc": 60.0}
{"epoch": 32, "training_loss": 2807.1117736816404, "training_acc": 50.0, "val_loss": 1572.4019775390625, "val_acc": 40.0}
{"epoch": 33, "training_loss": 1179.768077468872, "training_acc": 35.0, "val_loss": 1077.637939453125, "val_acc": 40.0}
{"epoch": 34, "training_loss": 636.7111213684082, "training_acc": 60.0, "val_loss": 4.162423610687256, "val_acc": 40.0}
{"epoch": 35, "training_loss": 74.31712169647217, "training_acc": 80.0, "val_loss": 231.8266143798828, "val_acc": 60.0}
{"epoch": 36, "training_loss": 394.990576171875, "training_acc": 60.0, "val_loss": 3509.347412109375, "val_acc": 40.0}
{"epoch": 37, "training_loss": 2663.454931640625, "training_acc": 50.0, "val_loss": 1343.9539794921875, "val_acc": 60.0}
{"epoch": 38, "training_loss": 2225.33759765625, "training_acc": 50.0, "val_loss": 21.669384002685547, "val_acc": 60.0}
{"epoch": 39, "training_loss": 471.46453552246095, "training_acc": 60.0, "val_loss": 9164.740234375, "val_acc": 40.0}
{"epoch": 40, "training_loss": 7764.8171875, "training_acc": 50.0, "val_loss": 8063.8408203125, "val_acc": 40.0}
{"epoch": 41, "training_loss": 6007.2837890625, "training_acc": 50.0, "val_loss": 1702.6063232421875, "val_acc": 60.0}
{"epoch": 42, "training_loss": 2362.1595703125, "training_acc": 50.0, "val_loss": 4470.30712890625, "val_acc": 60.0}
{"epoch": 43, "training_loss": 5581.4625, "training_acc": 50.0, "val_loss": 1885.4215087890625, "val_acc": 60.0}
{"epoch": 44, "training_loss": 1738.927294921875, "training_acc": 60.0, "val_loss": 3328.348388671875, "val_acc": 40.0}
{"epoch": 45, "training_loss": 2794.5283203125, "training_acc": 50.0, "val_loss": 1087.5086669921875, "val_acc": 60.0}
{"epoch": 46, "training_loss": 1353.7943359375, "training_acc": 50.0, "val_loss": 2792.578369140625, "val_acc": 60.0}
{"epoch": 47, "training_loss": 3193.13779296875, "training_acc": 50.0, "val_loss": 1796.5093994140625, "val_acc": 40.0}
{"epoch": 48, "training_loss": 1609.7033203125, "training_acc": 50.0, "val_loss": 3360.466552734375, "val_acc": 40.0}
{"epoch": 49, "training_loss": 2379.6490234375, "training_acc": 50.0, "val_loss": 2614.0859375, "val_acc": 60.0}
{"epoch": 50, "training_loss": 3779.4111328125, "training_acc": 50.0, "val_loss": 2707.244873046875, "val_acc": 60.0}
{"epoch": 51, "training_loss": 2377.568620300293, "training_acc": 50.0, "val_loss": 7267.22900390625, "val_acc": 40.0}
{"epoch": 52, "training_loss": 6732.27421875, "training_acc": 50.0, "val_loss": 12506.4013671875, "val_acc": 40.0}
{"epoch": 53, "training_loss": 10163.3236328125, "training_acc": 50.0, "val_loss": 7133.82763671875, "val_acc": 40.0}
