"main_modify.py --pretrained_path None --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 2 --task ADNI_sex --input_option yAware --learning_rate 1e2 --batch_size 16 --weight_decay 1e-8 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 4280.651338386536, "training_acc": 50.0, "val_loss": 4874.75732421875, "val_acc": 60.0}
{"epoch": 1, "training_loss": 7264.3609375, "training_acc": 50.0, "val_loss": 20174.33984375, "val_acc": 40.0}
{"epoch": 2, "training_loss": 16354.725390625, "training_acc": 50.0, "val_loss": 9348.2841796875, "val_acc": 40.0}
{"epoch": 3, "training_loss": 6634.697119140625, "training_acc": 50.0, "val_loss": 4807.9619140625, "val_acc": 60.0}
{"epoch": 4, "training_loss": 5929.69521484375, "training_acc": 50.0, "val_loss": 2120.964111328125, "val_acc": 60.0}
{"epoch": 5, "training_loss": 2687.918017578125, "training_acc": 50.0, "val_loss": 5211.59912109375, "val_acc": 40.0}
{"epoch": 6, "training_loss": 3938.3900390625, "training_acc": 50.0, "val_loss": 2225.111083984375, "val_acc": 60.0}
{"epoch": 7, "training_loss": 3715.1724609375, "training_acc": 50.0, "val_loss": 3857.975830078125, "val_acc": 60.0}
{"epoch": 8, "training_loss": 4458.625012207031, "training_acc": 50.0, "val_loss": 3968.806396484375, "val_acc": 40.0}
{"epoch": 9, "training_loss": 3434.385595703125, "training_acc": 50.0, "val_loss": 5518.37255859375, "val_acc": 40.0}
{"epoch": 10, "training_loss": 4125.741357421875, "training_acc": 50.0, "val_loss": 1723.716064453125, "val_acc": 60.0}
{"epoch": 11, "training_loss": 2484.46982421875, "training_acc": 50.0, "val_loss": 2380.161865234375, "val_acc": 60.0}
{"epoch": 12, "training_loss": 2163.692834472656, "training_acc": 50.0, "val_loss": 6480.515625, "val_acc": 40.0}
{"epoch": 13, "training_loss": 5656.340087890625, "training_acc": 50.0, "val_loss": 11113.9755859375, "val_acc": 40.0}
{"epoch": 14, "training_loss": 9043.59609375, "training_acc": 50.0, "val_loss": 6108.19873046875, "val_acc": 40.0}
{"epoch": 15, "training_loss": 3671.538427734375, "training_acc": 50.0, "val_loss": 5565.41748046875, "val_acc": 60.0}
{"epoch": 16, "training_loss": 8385.059765625, "training_acc": 50.0, "val_loss": 10209.2919921875, "val_acc": 60.0}
{"epoch": 17, "training_loss": 12501.521875, "training_acc": 50.0, "val_loss": 6418.27880859375, "val_acc": 60.0}
{"epoch": 18, "training_loss": 6916.220263671875, "training_acc": 50.0, "val_loss": 5438.29296875, "val_acc": 40.0}
{"epoch": 19, "training_loss": 5886.16796875, "training_acc": 50.0, "val_loss": 12063.2880859375, "val_acc": 40.0}
{"epoch": 20, "training_loss": 9815.8123046875, "training_acc": 50.0, "val_loss": 7014.89794921875, "val_acc": 40.0}
{"epoch": 21, "training_loss": 4880.63994140625, "training_acc": 50.0, "val_loss": 4224.48291015625, "val_acc": 60.0}
{"epoch": 22, "training_loss": 6466.060546875, "training_acc": 50.0, "val_loss": 7761.89990234375, "val_acc": 60.0}
{"epoch": 23, "training_loss": 9387.676171875, "training_acc": 50.0, "val_loss": 3749.239013671875, "val_acc": 60.0}
{"epoch": 24, "training_loss": 4418.131176757813, "training_acc": 40.0, "val_loss": 2934.28759765625, "val_acc": 40.0}
{"epoch": 25, "training_loss": 2371.5730712890627, "training_acc": 50.0, "val_loss": 279.3107604980469, "val_acc": 40.0}
{"epoch": 26, "training_loss": 819.4718505859375, "training_acc": 50.0, "val_loss": 3414.699951171875, "val_acc": 60.0}
{"epoch": 27, "training_loss": 4035.824609375, "training_acc": 50.0, "val_loss": 250.6753692626953, "val_acc": 40.0}
{"epoch": 28, "training_loss": 466.10484619140624, "training_acc": 50.0, "val_loss": 889.8598022460938, "val_acc": 40.0}
{"epoch": 29, "training_loss": 1717.03525390625, "training_acc": 30.0, "val_loss": 1107.7957763671875, "val_acc": 60.0}
{"epoch": 30, "training_loss": 1419.571337890625, "training_acc": 50.0, "val_loss": 2653.173828125, "val_acc": 40.0}
{"epoch": 31, "training_loss": 2044.151385498047, "training_acc": 50.0, "val_loss": 1437.9248046875, "val_acc": 60.0}
{"epoch": 32, "training_loss": 1938.826513671875, "training_acc": 50.0, "val_loss": 315.1768493652344, "val_acc": 40.0}
{"epoch": 33, "training_loss": 422.0712158203125, "training_acc": 50.0, "val_loss": 1275.5394287109375, "val_acc": 60.0}
{"epoch": 34, "training_loss": 1646.3112548828126, "training_acc": 50.0, "val_loss": 64.38429260253906, "val_acc": 60.0}
{"epoch": 35, "training_loss": 378.75262451171875, "training_acc": 60.0, "val_loss": 6234.44677734375, "val_acc": 40.0}
{"epoch": 36, "training_loss": 5152.2896484375, "training_acc": 50.0, "val_loss": 3457.634765625, "val_acc": 40.0}
{"epoch": 37, "training_loss": 2083.0730590820312, "training_acc": 60.0, "val_loss": 2467.997314453125, "val_acc": 60.0}
{"epoch": 38, "training_loss": 3073.3680419921875, "training_acc": 50.0, "val_loss": 1431.8670654296875, "val_acc": 60.0}
{"epoch": 39, "training_loss": 2054.0412109375, "training_acc": 40.0, "val_loss": 1710.1800537109375, "val_acc": 40.0}
{"epoch": 40, "training_loss": 1025.855288696289, "training_acc": 60.0, "val_loss": 777.7107543945312, "val_acc": 60.0}
{"epoch": 41, "training_loss": 1093.2431640625, "training_acc": 40.0, "val_loss": 595.2999877929688, "val_acc": 60.0}
{"epoch": 42, "training_loss": 616.3408355712891, "training_acc": 50.0, "val_loss": 3011.8544921875, "val_acc": 40.0}
{"epoch": 43, "training_loss": 2509.1885498046877, "training_acc": 50.0, "val_loss": 2029.007080078125, "val_acc": 40.0}
{"epoch": 44, "training_loss": 1009.48876953125, "training_acc": 70.0, "val_loss": 2189.863037109375, "val_acc": 60.0}
{"epoch": 45, "training_loss": 2718.06416015625, "training_acc": 50.0, "val_loss": 397.1549377441406, "val_acc": 60.0}
{"epoch": 46, "training_loss": 1082.54150390625, "training_acc": 50.0, "val_loss": 5939.98388671875, "val_acc": 40.0}
{"epoch": 47, "training_loss": 4820.6826171875, "training_acc": 50.0, "val_loss": 1408.6873779296875, "val_acc": 40.0}
{"epoch": 48, "training_loss": 1176.79306640625, "training_acc": 60.0, "val_loss": 5568.84326171875, "val_acc": 60.0}
{"epoch": 49, "training_loss": 7040.7099609375, "training_acc": 50.0, "val_loss": 5855.16357421875, "val_acc": 60.0}
{"epoch": 50, "training_loss": 6851.6814453125, "training_acc": 50.0, "val_loss": 639.7349853515625, "val_acc": 60.0}
{"epoch": 51, "training_loss": 1031.62548828125, "training_acc": 60.0, "val_loss": 10442.8173828125, "val_acc": 40.0}
{"epoch": 52, "training_loss": 8994.81796875, "training_acc": 50.0, "val_loss": 11488.009765625, "val_acc": 40.0}
{"epoch": 53, "training_loss": 9028.3189453125, "training_acc": 50.0, "val_loss": 3000.2265625, "val_acc": 40.0}
