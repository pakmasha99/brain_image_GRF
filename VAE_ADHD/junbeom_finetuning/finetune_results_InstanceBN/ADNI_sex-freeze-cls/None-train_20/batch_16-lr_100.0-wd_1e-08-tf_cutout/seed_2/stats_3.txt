"main_modify.py --pretrained_path None --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 2 --task ADNI_sex --input_option yAware --learning_rate 1e2 --batch_size 16 --weight_decay 1e-8 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 8596.39321937561, "training_acc": 35.0, "val_loss": 5682.12646484375, "val_acc": 60.0}
{"epoch": 1, "training_loss": 8254.0478515625, "training_acc": 45.0, "val_loss": 19981.634765625, "val_acc": 40.0}
{"epoch": 2, "training_loss": 15137.4681640625, "training_acc": 55.0, "val_loss": 20704.822265625, "val_acc": 40.0}
{"epoch": 3, "training_loss": 15095.528125, "training_acc": 55.0, "val_loss": 8668.6015625, "val_acc": 40.0}
{"epoch": 4, "training_loss": 6044.6669921875, "training_acc": 45.0, "val_loss": 2297.255615234375, "val_acc": 60.0}
{"epoch": 5, "training_loss": 2860.097412109375, "training_acc": 45.0, "val_loss": 3186.393798828125, "val_acc": 40.0}
{"epoch": 6, "training_loss": 2633.16064453125, "training_acc": 55.0, "val_loss": 2775.216064453125, "val_acc": 40.0}
{"epoch": 7, "training_loss": 2325.1615234375, "training_acc": 45.0, "val_loss": 1036.47802734375, "val_acc": 60.0}
{"epoch": 8, "training_loss": 906.58896484375, "training_acc": 65.0, "val_loss": 3771.526611328125, "val_acc": 40.0}
{"epoch": 9, "training_loss": 2782.6793212890625, "training_acc": 55.0, "val_loss": 1248.1546630859375, "val_acc": 40.0}
{"epoch": 10, "training_loss": 2138.56865234375, "training_acc": 35.0, "val_loss": 1653.12109375, "val_acc": 60.0}
{"epoch": 11, "training_loss": 2093.774560546875, "training_acc": 45.0, "val_loss": 2336.058349609375, "val_acc": 40.0}
{"epoch": 12, "training_loss": 1521.4007080078125, "training_acc": 55.0, "val_loss": 1898.2672119140625, "val_acc": 60.0}
{"epoch": 13, "training_loss": 2607.9466796875, "training_acc": 45.0, "val_loss": 1798.135009765625, "val_acc": 60.0}
{"epoch": 14, "training_loss": 2050.0961639404295, "training_acc": 45.0, "val_loss": 269.97222900390625, "val_acc": 40.0}
{"epoch": 15, "training_loss": 715.7403198242188, "training_acc": 45.0, "val_loss": 401.933349609375, "val_acc": 60.0}
{"epoch": 16, "training_loss": 667.4990234375, "training_acc": 55.0, "val_loss": 5464.11474609375, "val_acc": 40.0}
{"epoch": 17, "training_loss": 4078.455078125, "training_acc": 55.0, "val_loss": 2731.068115234375, "val_acc": 40.0}
{"epoch": 18, "training_loss": 2338.50595703125, "training_acc": 45.0, "val_loss": 1783.2020263671875, "val_acc": 60.0}
{"epoch": 19, "training_loss": 1974.8842529296876, "training_acc": 45.0, "val_loss": 4476.8447265625, "val_acc": 40.0}
{"epoch": 20, "training_loss": 3802.7001953125, "training_acc": 55.0, "val_loss": 7114.3095703125, "val_acc": 40.0}
{"epoch": 21, "training_loss": 4883.226171875, "training_acc": 55.0, "val_loss": 72.59574127197266, "val_acc": 40.0}
{"epoch": 22, "training_loss": 1799.8822448730468, "training_acc": 45.0, "val_loss": 6514.4716796875, "val_acc": 60.0}
{"epoch": 23, "training_loss": 8924.683203125, "training_acc": 45.0, "val_loss": 4709.14794921875, "val_acc": 60.0}
{"epoch": 24, "training_loss": 5649.224096679687, "training_acc": 45.0, "val_loss": 4673.7548828125, "val_acc": 40.0}
{"epoch": 25, "training_loss": 4187.3357421875, "training_acc": 55.0, "val_loss": 10038.3564453125, "val_acc": 40.0}
{"epoch": 26, "training_loss": 7437.09716796875, "training_acc": 55.0, "val_loss": 6526.56201171875, "val_acc": 40.0}
{"epoch": 27, "training_loss": 4205.2533203125, "training_acc": 55.0, "val_loss": 2540.070556640625, "val_acc": 60.0}
{"epoch": 28, "training_loss": 4273.03359375, "training_acc": 45.0, "val_loss": 4123.98779296875, "val_acc": 60.0}
{"epoch": 29, "training_loss": 5103.844775390625, "training_acc": 45.0, "val_loss": 2614.323974609375, "val_acc": 40.0}
{"epoch": 30, "training_loss": 1965.8619140625, "training_acc": 55.0, "val_loss": 6810.97900390625, "val_acc": 40.0}
{"epoch": 31, "training_loss": 5061.9365234375, "training_acc": 55.0, "val_loss": 3814.34619140625, "val_acc": 40.0}
{"epoch": 32, "training_loss": 2345.019482421875, "training_acc": 55.0, "val_loss": 1594.1669921875, "val_acc": 60.0}
{"epoch": 33, "training_loss": 1954.9497802734375, "training_acc": 45.0, "val_loss": 2947.1201171875, "val_acc": 40.0}
{"epoch": 34, "training_loss": 2761.67216796875, "training_acc": 55.0, "val_loss": 3499.468017578125, "val_acc": 40.0}
{"epoch": 35, "training_loss": 2426.2068481445312, "training_acc": 45.0, "val_loss": 168.2194366455078, "val_acc": 60.0}
{"epoch": 36, "training_loss": 348.47442626953125, "training_acc": 55.0, "val_loss": 3274.607666015625, "val_acc": 40.0}
{"epoch": 37, "training_loss": 2267.787744140625, "training_acc": 55.0, "val_loss": 877.5422973632812, "val_acc": 60.0}
{"epoch": 38, "training_loss": 1267.3248046875, "training_acc": 45.0, "val_loss": 326.6697998046875, "val_acc": 40.0}
{"epoch": 39, "training_loss": 204.34924926757813, "training_acc": 55.0, "val_loss": 1715.100830078125, "val_acc": 60.0}
{"epoch": 40, "training_loss": 2294.09169921875, "training_acc": 45.0, "val_loss": 459.36016845703125, "val_acc": 40.0}
{"epoch": 41, "training_loss": 347.9564453125, "training_acc": 55.0, "val_loss": 34.55553436279297, "val_acc": 60.0}
{"epoch": 42, "training_loss": 715.6721801757812, "training_acc": 35.0, "val_loss": 1640.7470703125, "val_acc": 40.0}
{"epoch": 43, "training_loss": 1907.67421875, "training_acc": 35.0, "val_loss": 385.4461364746094, "val_acc": 60.0}
{"epoch": 44, "training_loss": 634.379638671875, "training_acc": 55.0, "val_loss": 5248.1259765625, "val_acc": 40.0}
{"epoch": 45, "training_loss": 3914.95107421875, "training_acc": 55.0, "val_loss": 2567.37109375, "val_acc": 40.0}
{"epoch": 46, "training_loss": 1413.430224609375, "training_acc": 65.0, "val_loss": 2654.630126953125, "val_acc": 60.0}
{"epoch": 47, "training_loss": 3558.129443359375, "training_acc": 45.0, "val_loss": 448.600341796875, "val_acc": 60.0}
{"epoch": 48, "training_loss": 1260.8134765625, "training_acc": 45.0, "val_loss": 6894.59375, "val_acc": 40.0}
{"epoch": 49, "training_loss": 5150.553125, "training_acc": 55.0, "val_loss": 5084.06201171875, "val_acc": 40.0}
{"epoch": 50, "training_loss": 3508.136926269531, "training_acc": 55.0, "val_loss": 2191.932861328125, "val_acc": 60.0}
{"epoch": 51, "training_loss": 3677.9025390625, "training_acc": 45.0, "val_loss": 1546.4488525390625, "val_acc": 60.0}
{"epoch": 52, "training_loss": 1346.555078125, "training_acc": 65.0, "val_loss": 6831.38037109375, "val_acc": 40.0}
{"epoch": 53, "training_loss": 5429.43369140625, "training_acc": 55.0, "val_loss": 7834.8798828125, "val_acc": 40.0}
{"epoch": 54, "training_loss": 5411.5884765625, "training_acc": 55.0, "val_loss": 10.244287490844727, "val_acc": 80.0}
{"epoch": 55, "training_loss": 1509.7165756225586, "training_acc": 60.0, "val_loss": 5190.6142578125, "val_acc": 60.0}
{"epoch": 56, "training_loss": 6918.9923828125, "training_acc": 45.0, "val_loss": 1711.2626953125, "val_acc": 60.0}
{"epoch": 57, "training_loss": 1486.5763671875, "training_acc": 65.0, "val_loss": 8962.5302734375, "val_acc": 40.0}
{"epoch": 58, "training_loss": 7201.2580078125, "training_acc": 55.0, "val_loss": 11868.173828125, "val_acc": 40.0}
{"epoch": 59, "training_loss": 8566.7978515625, "training_acc": 55.0, "val_loss": 5536.296875, "val_acc": 40.0}
{"epoch": 60, "training_loss": 3303.0810791015624, "training_acc": 55.0, "val_loss": 2267.172607421875, "val_acc": 60.0}
{"epoch": 61, "training_loss": 3097.540625, "training_acc": 45.0, "val_loss": 522.2097778320312, "val_acc": 60.0}
{"epoch": 62, "training_loss": 1278.7705078125, "training_acc": 45.0, "val_loss": 6298.328125, "val_acc": 40.0}
{"epoch": 63, "training_loss": 4683.91953125, "training_acc": 55.0, "val_loss": 3339.71484375, "val_acc": 40.0}
{"epoch": 64, "training_loss": 1746.9641723632812, "training_acc": 65.0, "val_loss": 2353.087646484375, "val_acc": 60.0}
{"epoch": 65, "training_loss": 3158.72421875, "training_acc": 45.0, "val_loss": 192.78770446777344, "val_acc": 60.0}
{"epoch": 66, "training_loss": 1044.1857666015626, "training_acc": 45.0, "val_loss": 7324.5859375, "val_acc": 40.0}
{"epoch": 67, "training_loss": 5490.83720703125, "training_acc": 55.0, "val_loss": 4741.1650390625, "val_acc": 40.0}
{"epoch": 68, "training_loss": 3160.58323135376, "training_acc": 55.0, "val_loss": 3654.387939453125, "val_acc": 60.0}
{"epoch": 69, "training_loss": 5636.5015625, "training_acc": 45.0, "val_loss": 4335.70068359375, "val_acc": 60.0}
{"epoch": 70, "training_loss": 5000.956201171875, "training_acc": 45.0, "val_loss": 4332.6357421875, "val_acc": 40.0}
{"epoch": 71, "training_loss": 3961.678125, "training_acc": 55.0, "val_loss": 9901.5693359375, "val_acc": 40.0}
{"epoch": 72, "training_loss": 7273.1056640625, "training_acc": 55.0, "val_loss": 5656.76708984375, "val_acc": 40.0}
{"epoch": 73, "training_loss": 3803.7793045043945, "training_acc": 55.0, "val_loss": 3935.876708984375, "val_acc": 60.0}
