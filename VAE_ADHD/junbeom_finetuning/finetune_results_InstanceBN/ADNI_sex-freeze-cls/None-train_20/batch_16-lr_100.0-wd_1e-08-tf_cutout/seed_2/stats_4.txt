"main_modify.py --pretrained_path None --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 2 --task ADNI_sex --input_option yAware --learning_rate 1e2 --batch_size 16 --weight_decay 1e-8 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 6426.541331768036, "training_acc": 45.0, "val_loss": 4733.9189453125, "val_acc": 60.0}
{"epoch": 1, "training_loss": 9527.02421875, "training_acc": 35.0, "val_loss": 19314.984375, "val_acc": 40.0}
{"epoch": 2, "training_loss": 14370.39052734375, "training_acc": 55.0, "val_loss": 14167.8486328125, "val_acc": 40.0}
{"epoch": 3, "training_loss": 8977.780078125, "training_acc": 55.0, "val_loss": 2375.5849609375, "val_acc": 60.0}
{"epoch": 4, "training_loss": 4677.4474609375, "training_acc": 45.0, "val_loss": 5811.02880859375, "val_acc": 60.0}
{"epoch": 5, "training_loss": 7054.73515625, "training_acc": 45.0, "val_loss": 2655.21533203125, "val_acc": 40.0}
{"epoch": 6, "training_loss": 2300.04423828125, "training_acc": 55.0, "val_loss": 8287.759765625, "val_acc": 40.0}
{"epoch": 7, "training_loss": 6086.14609375, "training_acc": 55.0, "val_loss": 3193.990478515625, "val_acc": 40.0}
{"epoch": 8, "training_loss": 3687.7498046875, "training_acc": 35.0, "val_loss": 3203.24658203125, "val_acc": 60.0}
{"epoch": 9, "training_loss": 3967.89345703125, "training_acc": 45.0, "val_loss": 2006.6561279296875, "val_acc": 40.0}
{"epoch": 10, "training_loss": 1677.0537353515624, "training_acc": 55.0, "val_loss": 4918.5751953125, "val_acc": 40.0}
{"epoch": 11, "training_loss": 3536.8728759765627, "training_acc": 55.0, "val_loss": 390.9993591308594, "val_acc": 40.0}
{"epoch": 12, "training_loss": 927.8308837890625, "training_acc": 55.0, "val_loss": 4002.314208984375, "val_acc": 60.0}
{"epoch": 13, "training_loss": 5291.01611328125, "training_acc": 45.0, "val_loss": 950.5114135742188, "val_acc": 60.0}
{"epoch": 14, "training_loss": 2324.10595703125, "training_acc": 35.0, "val_loss": 6448.57177734375, "val_acc": 40.0}
{"epoch": 15, "training_loss": 4766.59130859375, "training_acc": 55.0, "val_loss": 3953.139892578125, "val_acc": 40.0}
{"epoch": 16, "training_loss": 3050.3078491210936, "training_acc": 35.0, "val_loss": 524.4345092773438, "val_acc": 40.0}
{"epoch": 17, "training_loss": 589.8044677734375, "training_acc": 45.0, "val_loss": 1015.1637573242188, "val_acc": 40.0}
{"epoch": 18, "training_loss": 774.3714111328125, "training_acc": 55.0, "val_loss": 1408.8424072265625, "val_acc": 60.0}
{"epoch": 19, "training_loss": 2079.938427734375, "training_acc": 45.0, "val_loss": 50.12569046020508, "val_acc": 60.0}
{"epoch": 20, "training_loss": 418.3340576171875, "training_acc": 55.0, "val_loss": 7739.9345703125, "val_acc": 40.0}
{"epoch": 21, "training_loss": 6067.49609375, "training_acc": 55.0, "val_loss": 6543.0146484375, "val_acc": 40.0}
{"epoch": 22, "training_loss": 4528.499658203125, "training_acc": 55.0, "val_loss": 1930.094970703125, "val_acc": 60.0}
{"epoch": 23, "training_loss": 2960.423193359375, "training_acc": 45.0, "val_loss": 2993.645263671875, "val_acc": 60.0}
{"epoch": 24, "training_loss": 3420.61806640625, "training_acc": 45.0, "val_loss": 3923.01611328125, "val_acc": 40.0}
{"epoch": 25, "training_loss": 3159.8736328125, "training_acc": 55.0, "val_loss": 8357.2724609375, "val_acc": 40.0}
{"epoch": 26, "training_loss": 6171.883349609375, "training_acc": 55.0, "val_loss": 5493.58349609375, "val_acc": 40.0}
{"epoch": 27, "training_loss": 3468.2966796875, "training_acc": 55.0, "val_loss": 2686.410888671875, "val_acc": 60.0}
{"epoch": 28, "training_loss": 4367.48828125, "training_acc": 45.0, "val_loss": 3990.518798828125, "val_acc": 60.0}
{"epoch": 29, "training_loss": 4886.33681640625, "training_acc": 45.0, "val_loss": 2743.917724609375, "val_acc": 40.0}
{"epoch": 30, "training_loss": 2498.1005859375, "training_acc": 55.0, "val_loss": 5760.75537109375, "val_acc": 40.0}
{"epoch": 31, "training_loss": 3985.601171875, "training_acc": 55.0, "val_loss": 33.77677917480469, "val_acc": 40.0}
{"epoch": 32, "training_loss": 261.7567443847656, "training_acc": 65.0, "val_loss": 3048.803466796875, "val_acc": 60.0}
{"epoch": 33, "training_loss": 3940.94892578125, "training_acc": 45.0, "val_loss": 192.133056640625, "val_acc": 40.0}
{"epoch": 34, "training_loss": 175.66942749023437, "training_acc": 55.0, "val_loss": 496.6173400878906, "val_acc": 40.0}
{"epoch": 35, "training_loss": 1195.5138427734375, "training_acc": 35.0, "val_loss": 484.7792663574219, "val_acc": 60.0}
{"epoch": 36, "training_loss": 1109.457080078125, "training_acc": 45.0, "val_loss": 5223.40380859375, "val_acc": 40.0}
{"epoch": 37, "training_loss": 3782.127490234375, "training_acc": 55.0, "val_loss": 1729.3348388671875, "val_acc": 40.0}
{"epoch": 38, "training_loss": 1054.66884765625, "training_acc": 65.0, "val_loss": 3634.858642578125, "val_acc": 60.0}
{"epoch": 39, "training_loss": 4975.621484375, "training_acc": 45.0, "val_loss": 1476.301025390625, "val_acc": 60.0}
{"epoch": 40, "training_loss": 1705.09189453125, "training_acc": 55.0, "val_loss": 6927.61279296875, "val_acc": 40.0}
{"epoch": 41, "training_loss": 5546.3015625, "training_acc": 55.0, "val_loss": 6377.27099609375, "val_acc": 40.0}
{"epoch": 42, "training_loss": 4386.603503417969, "training_acc": 55.0, "val_loss": 1983.143798828125, "val_acc": 60.0}
{"epoch": 43, "training_loss": 2976.3703125, "training_acc": 45.0, "val_loss": 2781.084228515625, "val_acc": 60.0}
{"epoch": 44, "training_loss": 3019.31943359375, "training_acc": 45.0, "val_loss": 5054.7900390625, "val_acc": 40.0}
{"epoch": 45, "training_loss": 4708.090234375, "training_acc": 55.0, "val_loss": 8769.2490234375, "val_acc": 40.0}
{"epoch": 46, "training_loss": 6170.20595703125, "training_acc": 55.0, "val_loss": 2328.580078125, "val_acc": 40.0}
{"epoch": 47, "training_loss": 1911.71064453125, "training_acc": 55.0, "val_loss": 4441.63671875, "val_acc": 60.0}
{"epoch": 48, "training_loss": 6039.25234375, "training_acc": 45.0, "val_loss": 3735.496826171875, "val_acc": 60.0}
{"epoch": 49, "training_loss": 4545.586767578125, "training_acc": 45.0, "val_loss": 2752.327880859375, "val_acc": 40.0}
{"epoch": 50, "training_loss": 2452.80908203125, "training_acc": 55.0, "val_loss": 5292.93505859375, "val_acc": 40.0}
