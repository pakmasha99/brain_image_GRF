"main_modify.py --pretrained_path None --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 3 --task ADNI_sex --input_option yAware --learning_rate 1e2 --batch_size 16 --weight_decay 1e-8 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 4292.1778609752655, "training_acc": 50.0, "val_loss": 4846.388671875, "val_acc": 60.0}
{"epoch": 1, "training_loss": 5433.914453125, "training_acc": 60.0, "val_loss": 25607.22265625, "val_acc": 40.0}
{"epoch": 2, "training_loss": 21268.99921875, "training_acc": 50.0, "val_loss": 18341.50390625, "val_acc": 40.0}
{"epoch": 3, "training_loss": 13392.81552734375, "training_acc": 50.0, "val_loss": 4799.64794921875, "val_acc": 60.0}
{"epoch": 4, "training_loss": 6520.9375, "training_acc": 50.0, "val_loss": 11111.375, "val_acc": 60.0}
{"epoch": 5, "training_loss": 13717.67099609375, "training_acc": 50.0, "val_loss": 7150.3955078125, "val_acc": 60.0}
{"epoch": 6, "training_loss": 7227.0265625, "training_acc": 50.0, "val_loss": 7069.57275390625, "val_acc": 40.0}
{"epoch": 7, "training_loss": 7527.086328125, "training_acc": 50.0, "val_loss": 14219.6689453125, "val_acc": 40.0}
{"epoch": 8, "training_loss": 11396.367578125, "training_acc": 50.0, "val_loss": 6111.57763671875, "val_acc": 40.0}
{"epoch": 9, "training_loss": 3679.7988037109376, "training_acc": 60.0, "val_loss": 4439.1259765625, "val_acc": 60.0}
{"epoch": 10, "training_loss": 5545.856640625, "training_acc": 50.0, "val_loss": 5525.72216796875, "val_acc": 60.0}
{"epoch": 11, "training_loss": 6903.234375, "training_acc": 50.0, "val_loss": 1711.2625732421875, "val_acc": 60.0}
{"epoch": 12, "training_loss": 1694.7076171875, "training_acc": 60.0, "val_loss": 5509.2431640625, "val_acc": 40.0}
{"epoch": 13, "training_loss": 4539.851708984375, "training_acc": 50.0, "val_loss": 2922.08984375, "val_acc": 40.0}
{"epoch": 14, "training_loss": 1826.0727661132812, "training_acc": 60.0, "val_loss": 2600.810791015625, "val_acc": 60.0}
{"epoch": 15, "training_loss": 3159.183984375, "training_acc": 50.0, "val_loss": 240.4856414794922, "val_acc": 60.0}
{"epoch": 16, "training_loss": 1020.7400390625, "training_acc": 50.0, "val_loss": 6408.2255859375, "val_acc": 40.0}
{"epoch": 17, "training_loss": 5082.9642578125, "training_acc": 50.0, "val_loss": 223.0950164794922, "val_acc": 40.0}
{"epoch": 18, "training_loss": 701.271484375, "training_acc": 60.0, "val_loss": 7902.75341796875, "val_acc": 60.0}
{"epoch": 19, "training_loss": 10150.137109375, "training_acc": 50.0, "val_loss": 8121.6337890625, "val_acc": 60.0}
{"epoch": 20, "training_loss": 9478.89619140625, "training_acc": 50.0, "val_loss": 1187.603759765625, "val_acc": 60.0}
{"epoch": 21, "training_loss": 2298.316015625, "training_acc": 50.0, "val_loss": 11593.5107421875, "val_acc": 40.0}
{"epoch": 22, "training_loss": 9754.6798828125, "training_acc": 50.0, "val_loss": 12563.3486328125, "val_acc": 40.0}
{"epoch": 23, "training_loss": 9788.91640625, "training_acc": 50.0, "val_loss": 3385.364013671875, "val_acc": 40.0}
{"epoch": 24, "training_loss": 3113.1169921875, "training_acc": 50.0, "val_loss": 6732.21044921875, "val_acc": 60.0}
{"epoch": 25, "training_loss": 8691.928125, "training_acc": 50.0, "val_loss": 7108.31103515625, "val_acc": 60.0}
{"epoch": 26, "training_loss": 8248.4458984375, "training_acc": 50.0, "val_loss": 531.1599731445312, "val_acc": 60.0}
{"epoch": 27, "training_loss": 1036.93046875, "training_acc": 60.0, "val_loss": 12804.1806640625, "val_acc": 40.0}
{"epoch": 28, "training_loss": 11368.843359375, "training_acc": 50.0, "val_loss": 14026.9013671875, "val_acc": 40.0}
{"epoch": 29, "training_loss": 10742.112109375, "training_acc": 50.0, "val_loss": 2865.899169921875, "val_acc": 40.0}
{"epoch": 30, "training_loss": 2990.3560546875, "training_acc": 50.0, "val_loss": 8038.78125, "val_acc": 60.0}
{"epoch": 31, "training_loss": 10033.2703125, "training_acc": 50.0, "val_loss": 10296.7060546875, "val_acc": 60.0}
{"epoch": 32, "training_loss": 12636.5828125, "training_acc": 50.0, "val_loss": 6531.81396484375, "val_acc": 60.0}
{"epoch": 33, "training_loss": 6502.7392578125, "training_acc": 50.0, "val_loss": 6571.85546875, "val_acc": 40.0}
{"epoch": 34, "training_loss": 5475.392578125, "training_acc": 50.0, "val_loss": 17127.4609375, "val_acc": 40.0}
{"epoch": 35, "training_loss": 15124.91953125, "training_acc": 50.0, "val_loss": 16753.150390625, "val_acc": 40.0}
{"epoch": 36, "training_loss": 12729.748046875, "training_acc": 50.0, "val_loss": 3636.878662109375, "val_acc": 40.0}
