"main_modify.py --pretrained_path None --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_sex --input_option yAware --learning_rate 1e2 --batch_size 16 --weight_decay 1e-8 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 8574.828137493134, "training_acc": 45.0, "val_loss": 8818.2998046875, "val_acc": 40.0}
{"epoch": 1, "training_loss": 7578.56796875, "training_acc": 50.0, "val_loss": 12250.5615234375, "val_acc": 60.0}
{"epoch": 2, "training_loss": 15737.6875, "training_acc": 50.0, "val_loss": 9864.435546875, "val_acc": 60.0}
{"epoch": 3, "training_loss": 10281.3130859375, "training_acc": 50.0, "val_loss": 5335.078125, "val_acc": 40.0}
{"epoch": 4, "training_loss": 4963.06689453125, "training_acc": 50.0, "val_loss": 15397.6611328125, "val_acc": 40.0}
{"epoch": 5, "training_loss": 12934.18125, "training_acc": 50.0, "val_loss": 11671.556640625, "val_acc": 40.0}
{"epoch": 6, "training_loss": 9143.256420898437, "training_acc": 50.0, "val_loss": 1986.8970947265625, "val_acc": 60.0}
{"epoch": 7, "training_loss": 3129.66240234375, "training_acc": 50.0, "val_loss": 5021.72900390625, "val_acc": 60.0}
{"epoch": 8, "training_loss": 6052.56416015625, "training_acc": 50.0, "val_loss": 881.7394409179688, "val_acc": 60.0}
{"epoch": 9, "training_loss": 1654.53701171875, "training_acc": 50.0, "val_loss": 7296.2041015625, "val_acc": 40.0}
{"epoch": 10, "training_loss": 6076.387109375, "training_acc": 50.0, "val_loss": 3418.452392578125, "val_acc": 40.0}
{"epoch": 11, "training_loss": 2183.567102050781, "training_acc": 60.0, "val_loss": 4164.29052734375, "val_acc": 60.0}
{"epoch": 12, "training_loss": 5340.74345703125, "training_acc": 50.0, "val_loss": 3594.491455078125, "val_acc": 60.0}
{"epoch": 13, "training_loss": 3517.68349609375, "training_acc": 50.0, "val_loss": 5593.83935546875, "val_acc": 40.0}
{"epoch": 14, "training_loss": 5305.93388671875, "training_acc": 50.0, "val_loss": 10494.8427734375, "val_acc": 40.0}
{"epoch": 15, "training_loss": 8473.925, "training_acc": 50.0, "val_loss": 4967.93505859375, "val_acc": 40.0}
{"epoch": 16, "training_loss": 2959.7977600097656, "training_acc": 60.0, "val_loss": 3134.12255859375, "val_acc": 60.0}
{"epoch": 17, "training_loss": 3954.812255859375, "training_acc": 50.0, "val_loss": 3199.61572265625, "val_acc": 60.0}
{"epoch": 18, "training_loss": 3467.078076171875, "training_acc": 50.0, "val_loss": 3562.197265625, "val_acc": 40.0}
{"epoch": 19, "training_loss": 3603.15625, "training_acc": 50.0, "val_loss": 4649.19091796875, "val_acc": 40.0}
{"epoch": 20, "training_loss": 2990.67900390625, "training_acc": 50.0, "val_loss": 3770.910888671875, "val_acc": 60.0}
{"epoch": 21, "training_loss": 5294.0873046875, "training_acc": 50.0, "val_loss": 6769.69140625, "val_acc": 60.0}
{"epoch": 22, "training_loss": 8146.39453125, "training_acc": 50.0, "val_loss": 2970.792724609375, "val_acc": 60.0}
{"epoch": 23, "training_loss": 3783.48359375, "training_acc": 40.0, "val_loss": 3902.656005859375, "val_acc": 40.0}
{"epoch": 24, "training_loss": 3169.009765625, "training_acc": 50.0, "val_loss": 926.54833984375, "val_acc": 40.0}
{"epoch": 25, "training_loss": 1591.962646484375, "training_acc": 40.0, "val_loss": 2759.143310546875, "val_acc": 60.0}
{"epoch": 26, "training_loss": 3225.641564941406, "training_acc": 50.0, "val_loss": 1436.5091552734375, "val_acc": 40.0}
{"epoch": 27, "training_loss": 1283.84921875, "training_acc": 50.0, "val_loss": 16.776134490966797, "val_acc": 40.0}
{"epoch": 28, "training_loss": 702.4826034545898, "training_acc": 50.0, "val_loss": 3679.55126953125, "val_acc": 60.0}
{"epoch": 29, "training_loss": 4361.20537109375, "training_acc": 50.0, "val_loss": 501.6919860839844, "val_acc": 60.0}
{"epoch": 30, "training_loss": 1823.338818359375, "training_acc": 40.0, "val_loss": 6830.1533203125, "val_acc": 40.0}
{"epoch": 31, "training_loss": 5586.495361328125, "training_acc": 50.0, "val_loss": 3290.726318359375, "val_acc": 40.0}
{"epoch": 32, "training_loss": 2840.815380859375, "training_acc": 40.0, "val_loss": 1480.4591064453125, "val_acc": 60.0}
{"epoch": 33, "training_loss": 1514.3911071777343, "training_acc": 50.0, "val_loss": 3582.033203125, "val_acc": 40.0}
{"epoch": 34, "training_loss": 3587.93515625, "training_acc": 50.0, "val_loss": 2248.741943359375, "val_acc": 40.0}
{"epoch": 35, "training_loss": 1988.0744140625, "training_acc": 50.0, "val_loss": 3526.491943359375, "val_acc": 60.0}
{"epoch": 36, "training_loss": 4348.8783203125, "training_acc": 50.0, "val_loss": 1167.7216796875, "val_acc": 60.0}
{"epoch": 37, "training_loss": 1765.781591796875, "training_acc": 50.0, "val_loss": 6458.01318359375, "val_acc": 40.0}
{"epoch": 38, "training_loss": 5354.9009765625, "training_acc": 50.0, "val_loss": 4702.56201171875, "val_acc": 40.0}
{"epoch": 39, "training_loss": 3064.52529296875, "training_acc": 50.0, "val_loss": 3552.50634765625, "val_acc": 60.0}
{"epoch": 40, "training_loss": 4656.2173828125, "training_acc": 50.0, "val_loss": 6921.51416015625, "val_acc": 60.0}
{"epoch": 41, "training_loss": 8466.51875, "training_acc": 50.0, "val_loss": 4325.78271484375, "val_acc": 60.0}
{"epoch": 42, "training_loss": 4483.079248046875, "training_acc": 50.0, "val_loss": 5774.26123046875, "val_acc": 40.0}
{"epoch": 43, "training_loss": 5117.415380859375, "training_acc": 50.0, "val_loss": 11552.1767578125, "val_acc": 40.0}
{"epoch": 44, "training_loss": 9542.695703125, "training_acc": 50.0, "val_loss": 8186.94091796875, "val_acc": 40.0}
{"epoch": 45, "training_loss": 5986.3396484375, "training_acc": 50.0, "val_loss": 2472.502685546875, "val_acc": 60.0}
{"epoch": 46, "training_loss": 3030.0671875, "training_acc": 50.0, "val_loss": 6528.158203125, "val_acc": 60.0}
