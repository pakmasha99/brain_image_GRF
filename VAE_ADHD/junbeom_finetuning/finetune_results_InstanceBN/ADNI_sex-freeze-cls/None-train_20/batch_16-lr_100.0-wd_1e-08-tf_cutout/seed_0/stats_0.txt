"main_modify.py --pretrained_path None --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_sex --input_option yAware --learning_rate 1e2 --batch_size 16 --weight_decay 1e-8 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 6427.287110519409, "training_acc": 50.0, "val_loss": 7535.50732421875, "val_acc": 40.0}
{"epoch": 1, "training_loss": 7235.4013671875, "training_acc": 50.0, "val_loss": 13941.59375, "val_acc": 60.0}
{"epoch": 2, "training_loss": 17341.371875, "training_acc": 50.0, "val_loss": 10796.119140625, "val_acc": 60.0}
{"epoch": 3, "training_loss": 11624.528125, "training_acc": 50.0, "val_loss": 3421.984130859375, "val_acc": 40.0}
{"epoch": 4, "training_loss": 3883.19345703125, "training_acc": 50.0, "val_loss": 11071.2890625, "val_acc": 40.0}
{"epoch": 5, "training_loss": 8741.085546875, "training_acc": 50.0, "val_loss": 2534.283447265625, "val_acc": 40.0}
{"epoch": 6, "training_loss": 2760.27958984375, "training_acc": 50.0, "val_loss": 7433.4453125, "val_acc": 60.0}
{"epoch": 7, "training_loss": 9464.965625, "training_acc": 50.0, "val_loss": 6789.48828125, "val_acc": 60.0}
{"epoch": 8, "training_loss": 7690.0677734375, "training_acc": 50.0, "val_loss": 1624.943359375, "val_acc": 40.0}
{"epoch": 9, "training_loss": 1610.5897216796875, "training_acc": 50.0, "val_loss": 6028.30029296875, "val_acc": 40.0}
{"epoch": 10, "training_loss": 4755.90009765625, "training_acc": 50.0, "val_loss": 221.812744140625, "val_acc": 40.0}
{"epoch": 11, "training_loss": 1186.5190063476562, "training_acc": 50.0, "val_loss": 6220.91162109375, "val_acc": 60.0}
{"epoch": 12, "training_loss": 7769.1521484375, "training_acc": 50.0, "val_loss": 4490.03759765625, "val_acc": 60.0}
{"epoch": 13, "training_loss": 5150.648657226562, "training_acc": 50.0, "val_loss": 4771.70166015625, "val_acc": 40.0}
{"epoch": 14, "training_loss": 4190.054248046875, "training_acc": 50.0, "val_loss": 8253.7548828125, "val_acc": 40.0}
{"epoch": 15, "training_loss": 6510.97109375, "training_acc": 50.0, "val_loss": 1564.132080078125, "val_acc": 40.0}
{"epoch": 16, "training_loss": 1998.66298828125, "training_acc": 50.0, "val_loss": 6427.4658203125, "val_acc": 60.0}
{"epoch": 17, "training_loss": 8172.031640625, "training_acc": 50.0, "val_loss": 5905.58740234375, "val_acc": 60.0}
{"epoch": 18, "training_loss": 6992.893017578125, "training_acc": 50.0, "val_loss": 892.10498046875, "val_acc": 40.0}
{"epoch": 19, "training_loss": 1382.771337890625, "training_acc": 50.0, "val_loss": 1831.583984375, "val_acc": 40.0}
{"epoch": 20, "training_loss": 1985.205859375, "training_acc": 40.0, "val_loss": 1653.4051513671875, "val_acc": 60.0}
{"epoch": 21, "training_loss": 1899.6876342773437, "training_acc": 40.0, "val_loss": 632.5906372070312, "val_acc": 60.0}
{"epoch": 22, "training_loss": 676.4994995117188, "training_acc": 50.0, "val_loss": 566.0852661132812, "val_acc": 60.0}
{"epoch": 23, "training_loss": 496.90428924560547, "training_acc": 60.0, "val_loss": 82.5366439819336, "val_acc": 60.0}
{"epoch": 24, "training_loss": 410.1571838378906, "training_acc": 50.0, "val_loss": 1577.142822265625, "val_acc": 40.0}
{"epoch": 25, "training_loss": 1016.0289916992188, "training_acc": 60.0, "val_loss": 1447.0311279296875, "val_acc": 60.0}
{"epoch": 26, "training_loss": 1522.6713928222657, "training_acc": 50.0, "val_loss": 3166.416748046875, "val_acc": 40.0}
{"epoch": 27, "training_loss": 2801.5087890625, "training_acc": 50.0, "val_loss": 2471.88623046875, "val_acc": 40.0}
{"epoch": 28, "training_loss": 1238.90107421875, "training_acc": 70.0, "val_loss": 2647.99267578125, "val_acc": 60.0}
{"epoch": 29, "training_loss": 3416.5833984375, "training_acc": 50.0, "val_loss": 805.4085083007812, "val_acc": 60.0}
{"epoch": 30, "training_loss": 1491.995849609375, "training_acc": 50.0, "val_loss": 6702.14990234375, "val_acc": 40.0}
{"epoch": 31, "training_loss": 5680.693359375, "training_acc": 50.0, "val_loss": 2293.034912109375, "val_acc": 40.0}
{"epoch": 32, "training_loss": 1675.3941650390625, "training_acc": 60.0, "val_loss": 5769.10302734375, "val_acc": 60.0}
{"epoch": 33, "training_loss": 7170.48828125, "training_acc": 50.0, "val_loss": 7007.15966796875, "val_acc": 60.0}
{"epoch": 34, "training_loss": 8362.8103515625, "training_acc": 50.0, "val_loss": 2754.749755859375, "val_acc": 60.0}
{"epoch": 35, "training_loss": 3200.435498046875, "training_acc": 50.0, "val_loss": 6616.73974609375, "val_acc": 40.0}
{"epoch": 36, "training_loss": 5676.972265625, "training_acc": 50.0, "val_loss": 5865.43896484375, "val_acc": 40.0}
{"epoch": 37, "training_loss": 4544.859460449219, "training_acc": 50.0, "val_loss": 2374.734375, "val_acc": 60.0}
{"epoch": 38, "training_loss": 3273.1462890625, "training_acc": 50.0, "val_loss": 3398.203125, "val_acc": 60.0}
{"epoch": 39, "training_loss": 3519.53896484375, "training_acc": 50.0, "val_loss": 3786.845458984375, "val_acc": 40.0}
{"epoch": 40, "training_loss": 3396.820849609375, "training_acc": 50.0, "val_loss": 7777.22412109375, "val_acc": 40.0}
{"epoch": 41, "training_loss": 6268.2927734375, "training_acc": 50.0, "val_loss": 2638.412109375, "val_acc": 40.0}
{"epoch": 42, "training_loss": 2293.2458984375, "training_acc": 50.0, "val_loss": 4007.1953125, "val_acc": 60.0}
