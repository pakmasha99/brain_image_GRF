"main_modify.py --pretrained_path None --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_sex --input_option yAware --learning_rate 1e2 --batch_size 16 --weight_decay 1e-8 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 4284.884644889831, "training_acc": 50.0, "val_loss": 7580.06982421875, "val_acc": 40.0}
{"epoch": 1, "training_loss": 5572.7349609375, "training_acc": 60.0, "val_loss": 16588.51953125, "val_acc": 60.0}
{"epoch": 2, "training_loss": 20675.941796875, "training_acc": 50.0, "val_loss": 11652.390625, "val_acc": 60.0}
{"epoch": 3, "training_loss": 12689.4841796875, "training_acc": 50.0, "val_loss": 8092.85302734375, "val_acc": 40.0}
{"epoch": 4, "training_loss": 7269.9541015625, "training_acc": 50.0, "val_loss": 17610.234375, "val_acc": 40.0}
{"epoch": 5, "training_loss": 14426.5025390625, "training_acc": 50.0, "val_loss": 10770.0498046875, "val_acc": 40.0}
{"epoch": 6, "training_loss": 6979.999169921875, "training_acc": 50.0, "val_loss": 6024.5927734375, "val_acc": 60.0}
{"epoch": 7, "training_loss": 8066.50888671875, "training_acc": 50.0, "val_loss": 12998.3310546875, "val_acc": 60.0}
{"epoch": 8, "training_loss": 16295.9234375, "training_acc": 50.0, "val_loss": 11225.833984375, "val_acc": 60.0}
{"epoch": 9, "training_loss": 13079.1255859375, "training_acc": 50.0, "val_loss": 1978.4495849609375, "val_acc": 60.0}
{"epoch": 10, "training_loss": 5093.2044921875, "training_acc": 30.0, "val_loss": 11338.080078125, "val_acc": 40.0}
{"epoch": 11, "training_loss": 9511.91953125, "training_acc": 50.0, "val_loss": 9370.55078125, "val_acc": 40.0}
{"epoch": 12, "training_loss": 7011.5107421875, "training_acc": 50.0, "val_loss": 1556.7181396484375, "val_acc": 60.0}
{"epoch": 13, "training_loss": 2547.8439453125, "training_acc": 50.0, "val_loss": 4300.06787109375, "val_acc": 60.0}
{"epoch": 14, "training_loss": 5178.787158203125, "training_acc": 50.0, "val_loss": 314.9072265625, "val_acc": 60.0}
{"epoch": 15, "training_loss": 1203.91865234375, "training_acc": 50.0, "val_loss": 7878.56103515625, "val_acc": 40.0}
{"epoch": 16, "training_loss": 6572.358984375, "training_acc": 50.0, "val_loss": 4102.06005859375, "val_acc": 40.0}
{"epoch": 17, "training_loss": 3615.33671875, "training_acc": 40.0, "val_loss": 2632.827880859375, "val_acc": 60.0}
{"epoch": 18, "training_loss": 3159.60908203125, "training_acc": 50.0, "val_loss": 814.2947387695312, "val_acc": 40.0}
{"epoch": 19, "training_loss": 1321.54599609375, "training_acc": 50.0, "val_loss": 208.4117431640625, "val_acc": 60.0}
{"epoch": 20, "training_loss": 442.201904296875, "training_acc": 50.0, "val_loss": 1913.4808349609375, "val_acc": 40.0}
{"epoch": 21, "training_loss": 1730.454931640625, "training_acc": 50.0, "val_loss": 336.52349853515625, "val_acc": 60.0}
{"epoch": 22, "training_loss": 495.99541015625, "training_acc": 50.0, "val_loss": 1133.0418701171875, "val_acc": 40.0}
{"epoch": 23, "training_loss": 875.397412109375, "training_acc": 50.0, "val_loss": 1867.536376953125, "val_acc": 60.0}
{"epoch": 24, "training_loss": 2520.760009765625, "training_acc": 50.0, "val_loss": 1582.313232421875, "val_acc": 60.0}
{"epoch": 25, "training_loss": 2179.46171875, "training_acc": 40.0, "val_loss": 1547.4627685546875, "val_acc": 40.0}
{"epoch": 26, "training_loss": 1408.270166015625, "training_acc": 40.0, "val_loss": 91.54414367675781, "val_acc": 40.0}
{"epoch": 27, "training_loss": 123.07743530273437, "training_acc": 60.0, "val_loss": 399.35528564453125, "val_acc": 60.0}
{"epoch": 28, "training_loss": 732.953466796875, "training_acc": 50.0, "val_loss": 1913.6275634765625, "val_acc": 40.0}
{"epoch": 29, "training_loss": 1601.004150390625, "training_acc": 40.0, "val_loss": 379.30621337890625, "val_acc": 40.0}
{"epoch": 30, "training_loss": 583.11630859375, "training_acc": 40.0, "val_loss": 788.8349609375, "val_acc": 40.0}
{"epoch": 31, "training_loss": 595.0200927734375, "training_acc": 50.0, "val_loss": 1990.4332275390625, "val_acc": 60.0}
{"epoch": 32, "training_loss": 2673.056298828125, "training_acc": 50.0, "val_loss": 1680.4378662109375, "val_acc": 60.0}
{"epoch": 33, "training_loss": 1546.2631958007812, "training_acc": 60.0, "val_loss": 2579.329833984375, "val_acc": 40.0}
{"epoch": 34, "training_loss": 2024.9505615234375, "training_acc": 50.0, "val_loss": 649.3800659179688, "val_acc": 60.0}
{"epoch": 35, "training_loss": 981.920654296875, "training_acc": 50.0, "val_loss": 1314.7191162109375, "val_acc": 40.0}
{"epoch": 36, "training_loss": 1089.4735717773438, "training_acc": 50.0, "val_loss": 222.6366729736328, "val_acc": 40.0}
{"epoch": 37, "training_loss": 652.433544921875, "training_acc": 50.0, "val_loss": 2510.10498046875, "val_acc": 60.0}
{"epoch": 38, "training_loss": 2782.48681640625, "training_acc": 50.0, "val_loss": 2952.407470703125, "val_acc": 40.0}
{"epoch": 39, "training_loss": 2909.607421875, "training_acc": 50.0, "val_loss": 5886.26708984375, "val_acc": 40.0}
{"epoch": 40, "training_loss": 4419.28740234375, "training_acc": 50.0, "val_loss": 715.7443237304688, "val_acc": 60.0}
{"epoch": 41, "training_loss": 920.9890625, "training_acc": 50.0, "val_loss": 2924.149169921875, "val_acc": 60.0}
{"epoch": 42, "training_loss": 3583.73154296875, "training_acc": 50.0, "val_loss": 635.4036254882812, "val_acc": 60.0}
{"epoch": 43, "training_loss": 822.71376953125, "training_acc": 60.0, "val_loss": 5554.359375, "val_acc": 40.0}
{"epoch": 44, "training_loss": 4597.4771484375, "training_acc": 50.0, "val_loss": 3026.608154296875, "val_acc": 40.0}
{"epoch": 45, "training_loss": 2716.758154296875, "training_acc": 40.0, "val_loss": 1708.7457275390625, "val_acc": 60.0}
