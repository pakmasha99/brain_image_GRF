"main_modify.py --pretrained_path None --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 5 --task ADNI_sex --input_option yAware --learning_rate 1e2 --batch_size 16 --weight_decay 1e-8 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 1683.5119490623474, "training_acc": 50.0, "val_loss": 8159.1923828125, "val_acc": 60.0}
{"epoch": 1, "training_loss": 11398.510546875, "training_acc": 50.0, "val_loss": 6485.17333984375, "val_acc": 60.0}
{"epoch": 2, "training_loss": 5783.847875976562, "training_acc": 60.0, "val_loss": 6881.29541015625, "val_acc": 40.0}
{"epoch": 3, "training_loss": 5903.714453125, "training_acc": 50.0, "val_loss": 2053.980224609375, "val_acc": 40.0}
{"epoch": 4, "training_loss": 1689.77353515625, "training_acc": 60.0, "val_loss": 7656.15185546875, "val_acc": 60.0}
{"epoch": 5, "training_loss": 9807.676953125, "training_acc": 50.0, "val_loss": 6410.81640625, "val_acc": 60.0}
{"epoch": 6, "training_loss": 6730.5154296875, "training_acc": 50.0, "val_loss": 4991.935546875, "val_acc": 40.0}
{"epoch": 7, "training_loss": 4938.268359375, "training_acc": 50.0, "val_loss": 11454.8408203125, "val_acc": 40.0}
{"epoch": 8, "training_loss": 9494.6859375, "training_acc": 50.0, "val_loss": 6825.35693359375, "val_acc": 40.0}
{"epoch": 9, "training_loss": 4512.20712890625, "training_acc": 50.0, "val_loss": 3769.87109375, "val_acc": 60.0}
{"epoch": 10, "training_loss": 5121.05029296875, "training_acc": 50.0, "val_loss": 7999.71435546875, "val_acc": 60.0}
{"epoch": 11, "training_loss": 9975.812109375, "training_acc": 50.0, "val_loss": 5319.01708984375, "val_acc": 60.0}
{"epoch": 12, "training_loss": 5782.6192626953125, "training_acc": 50.0, "val_loss": 5305.99365234375, "val_acc": 40.0}
{"epoch": 13, "training_loss": 5082.5337890625, "training_acc": 50.0, "val_loss": 10751.8642578125, "val_acc": 40.0}
{"epoch": 14, "training_loss": 8600.483984375, "training_acc": 50.0, "val_loss": 4535.79150390625, "val_acc": 40.0}
{"epoch": 15, "training_loss": 3411.21748046875, "training_acc": 50.0, "val_loss": 4068.813232421875, "val_acc": 60.0}
{"epoch": 16, "training_loss": 5309.321484375, "training_acc": 50.0, "val_loss": 3380.618896484375, "val_acc": 60.0}
{"epoch": 17, "training_loss": 3338.7608154296877, "training_acc": 50.0, "val_loss": 5887.5615234375, "val_acc": 40.0}
{"epoch": 18, "training_loss": 5162.6224609375, "training_acc": 50.0, "val_loss": 11570.9453125, "val_acc": 40.0}
{"epoch": 19, "training_loss": 9483.706640625, "training_acc": 50.0, "val_loss": 7155.45166015625, "val_acc": 40.0}
{"epoch": 20, "training_loss": 4915.5919189453125, "training_acc": 50.0, "val_loss": 4559.94384765625, "val_acc": 60.0}
{"epoch": 21, "training_loss": 6167.92119140625, "training_acc": 50.0, "val_loss": 9308.3017578125, "val_acc": 60.0}
{"epoch": 22, "training_loss": 11695.39052734375, "training_acc": 50.0, "val_loss": 8034.00634765625, "val_acc": 60.0}
{"epoch": 23, "training_loss": 9492.532421875, "training_acc": 50.0, "val_loss": 1402.5589599609375, "val_acc": 60.0}
{"epoch": 24, "training_loss": 1761.33349609375, "training_acc": 60.0, "val_loss": 11063.9794921875, "val_acc": 40.0}
{"epoch": 25, "training_loss": 9383.02724609375, "training_acc": 50.0, "val_loss": 14064.7333984375, "val_acc": 40.0}
{"epoch": 26, "training_loss": 11268.77265625, "training_acc": 50.0, "val_loss": 6797.3330078125, "val_acc": 40.0}
{"epoch": 27, "training_loss": 6183.60341796875, "training_acc": 30.0, "val_loss": 2805.980224609375, "val_acc": 60.0}
{"epoch": 28, "training_loss": 3587.6848876953127, "training_acc": 50.0, "val_loss": 1568.5330810546875, "val_acc": 60.0}
{"epoch": 29, "training_loss": 1833.483642578125, "training_acc": 50.0, "val_loss": 2290.598388671875, "val_acc": 40.0}
{"epoch": 30, "training_loss": 1718.991275024414, "training_acc": 50.0, "val_loss": 1532.1558837890625, "val_acc": 60.0}
{"epoch": 31, "training_loss": 2053.541796875, "training_acc": 50.0, "val_loss": 102.60649871826172, "val_acc": 60.0}
{"epoch": 32, "training_loss": 871.7796997070312, "training_acc": 50.0, "val_loss": 5847.62939453125, "val_acc": 40.0}
{"epoch": 33, "training_loss": 4663.82314453125, "training_acc": 50.0, "val_loss": 1519.9375, "val_acc": 40.0}
{"epoch": 34, "training_loss": 1634.6390625, "training_acc": 50.0, "val_loss": 4171.2890625, "val_acc": 60.0}
{"epoch": 35, "training_loss": 5301.45400390625, "training_acc": 50.0, "val_loss": 1818.529296875, "val_acc": 60.0}
{"epoch": 36, "training_loss": 1867.93212890625, "training_acc": 60.0, "val_loss": 6159.0439453125, "val_acc": 40.0}
{"epoch": 37, "training_loss": 5152.5341796875, "training_acc": 50.0, "val_loss": 5902.37841796875, "val_acc": 40.0}
{"epoch": 38, "training_loss": 4569.077282714844, "training_acc": 50.0, "val_loss": 1196.142578125, "val_acc": 60.0}
{"epoch": 39, "training_loss": 2046.8416015625, "training_acc": 50.0, "val_loss": 968.6290283203125, "val_acc": 60.0}
{"epoch": 40, "training_loss": 1494.72861328125, "training_acc": 50.0, "val_loss": 4238.455078125, "val_acc": 40.0}
{"epoch": 41, "training_loss": 3373.582177734375, "training_acc": 50.0, "val_loss": 229.97073364257812, "val_acc": 40.0}
{"epoch": 42, "training_loss": 1337.422216796875, "training_acc": 40.0, "val_loss": 3704.090576171875, "val_acc": 60.0}
{"epoch": 43, "training_loss": 4449.979541015625, "training_acc": 50.0, "val_loss": 1.7810086011886597, "val_acc": 80.0}
{"epoch": 44, "training_loss": 857.844873046875, "training_acc": 55.0, "val_loss": 7279.24365234375, "val_acc": 40.0}
{"epoch": 45, "training_loss": 5970.833203125, "training_acc": 50.0, "val_loss": 3185.679443359375, "val_acc": 40.0}
{"epoch": 46, "training_loss": 2561.13642578125, "training_acc": 50.0, "val_loss": 3674.715576171875, "val_acc": 60.0}
{"epoch": 47, "training_loss": 4676.730859375, "training_acc": 50.0, "val_loss": 3081.323974609375, "val_acc": 60.0}
{"epoch": 48, "training_loss": 3703.1864013671875, "training_acc": 50.0, "val_loss": 2467.442626953125, "val_acc": 40.0}
{"epoch": 49, "training_loss": 2367.812109375, "training_acc": 50.0, "val_loss": 1643.6695556640625, "val_acc": 40.0}
{"epoch": 50, "training_loss": 2015.948388671875, "training_acc": 40.0, "val_loss": 2507.837158203125, "val_acc": 60.0}
{"epoch": 51, "training_loss": 2949.631640625, "training_acc": 50.0, "val_loss": 2012.479736328125, "val_acc": 40.0}
{"epoch": 52, "training_loss": 1815.2134765625, "training_acc": 50.0, "val_loss": 1915.537353515625, "val_acc": 40.0}
{"epoch": 53, "training_loss": 1520.9831787109374, "training_acc": 50.0, "val_loss": 1615.5010986328125, "val_acc": 60.0}
{"epoch": 54, "training_loss": 1834.50146484375, "training_acc": 50.0, "val_loss": 3103.74267578125, "val_acc": 40.0}
{"epoch": 55, "training_loss": 2891.77529296875, "training_acc": 50.0, "val_loss": 2160.79345703125, "val_acc": 40.0}
{"epoch": 56, "training_loss": 1809.236279296875, "training_acc": 50.0, "val_loss": 2637.419677734375, "val_acc": 60.0}
{"epoch": 57, "training_loss": 3323.3468994140626, "training_acc": 50.0, "val_loss": 243.74974060058594, "val_acc": 60.0}
{"epoch": 58, "training_loss": 230.41044921875, "training_acc": 70.0, "val_loss": 7018.4296875, "val_acc": 40.0}
{"epoch": 59, "training_loss": 6096.2296875, "training_acc": 50.0, "val_loss": 5331.00634765625, "val_acc": 40.0}
{"epoch": 60, "training_loss": 3221.337646484375, "training_acc": 50.0, "val_loss": 4652.20556640625, "val_acc": 60.0}
{"epoch": 61, "training_loss": 6295.5865234375, "training_acc": 50.0, "val_loss": 9273.0791015625, "val_acc": 60.0}
{"epoch": 62, "training_loss": 11891.293359375, "training_acc": 50.0, "val_loss": 6684.54248046875, "val_acc": 60.0}
