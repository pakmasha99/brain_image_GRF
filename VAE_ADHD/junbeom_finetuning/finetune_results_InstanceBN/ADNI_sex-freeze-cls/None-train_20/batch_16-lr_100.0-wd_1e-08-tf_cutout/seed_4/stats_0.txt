"main_modify.py --pretrained_path None --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 4 --task ADNI_sex --input_option yAware --learning_rate 1e2 --batch_size 16 --weight_decay 1e-8 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 4294.385231018066, "training_acc": 50.0, "val_loss": 7382.0556640625, "val_acc": 40.0}
{"epoch": 1, "training_loss": 9124.437109375, "training_acc": 40.0, "val_loss": 10938.1298828125, "val_acc": 60.0}
{"epoch": 2, "training_loss": 13249.97685546875, "training_acc": 50.0, "val_loss": 2901.24462890625, "val_acc": 60.0}
{"epoch": 3, "training_loss": 4924.15, "training_acc": 40.0, "val_loss": 8915.619140625, "val_acc": 40.0}
{"epoch": 4, "training_loss": 7429.52578125, "training_acc": 50.0, "val_loss": 3492.411376953125, "val_acc": 40.0}
{"epoch": 5, "training_loss": 2193.623889160156, "training_acc": 60.0, "val_loss": 3256.24658203125, "val_acc": 60.0}
{"epoch": 6, "training_loss": 3959.7114501953124, "training_acc": 50.0, "val_loss": 537.1510620117188, "val_acc": 60.0}
{"epoch": 7, "training_loss": 1922.45322265625, "training_acc": 40.0, "val_loss": 5867.96875, "val_acc": 40.0}
{"epoch": 8, "training_loss": 4356.04296875, "training_acc": 50.0, "val_loss": 1582.779296875, "val_acc": 60.0}
{"epoch": 9, "training_loss": 2156.0977294921877, "training_acc": 50.0, "val_loss": 3479.821044921875, "val_acc": 60.0}
{"epoch": 10, "training_loss": 3967.21083984375, "training_acc": 50.0, "val_loss": 1771.111328125, "val_acc": 40.0}
{"epoch": 11, "training_loss": 1569.4158203125, "training_acc": 50.0, "val_loss": 2614.68115234375, "val_acc": 40.0}
{"epoch": 12, "training_loss": 1801.4133056640626, "training_acc": 50.0, "val_loss": 240.6860809326172, "val_acc": 60.0}
{"epoch": 13, "training_loss": 920.7533203125, "training_acc": 40.0, "val_loss": 1405.8905029296875, "val_acc": 40.0}
{"epoch": 14, "training_loss": 1315.092138671875, "training_acc": 50.0, "val_loss": 2031.075439453125, "val_acc": 60.0}
{"epoch": 15, "training_loss": 2204.9287841796877, "training_acc": 50.0, "val_loss": 3124.92041015625, "val_acc": 40.0}
{"epoch": 16, "training_loss": 2812.25927734375, "training_acc": 50.0, "val_loss": 2997.17431640625, "val_acc": 40.0}
{"epoch": 17, "training_loss": 2955.821630859375, "training_acc": 30.0, "val_loss": 248.92698669433594, "val_acc": 60.0}
{"epoch": 18, "training_loss": 432.3374755859375, "training_acc": 60.0, "val_loss": 4266.87841796875, "val_acc": 40.0}
{"epoch": 19, "training_loss": 3439.90732421875, "training_acc": 50.0, "val_loss": 448.426513671875, "val_acc": 40.0}
{"epoch": 20, "training_loss": 1460.943359375, "training_acc": 40.0, "val_loss": 3546.465576171875, "val_acc": 60.0}
{"epoch": 21, "training_loss": 4119.52724609375, "training_acc": 50.0, "val_loss": 402.6974182128906, "val_acc": 40.0}
{"epoch": 22, "training_loss": 524.1576416015625, "training_acc": 50.0, "val_loss": 169.8469696044922, "val_acc": 40.0}
{"epoch": 23, "training_loss": 689.7258544921875, "training_acc": 50.0, "val_loss": 2940.099609375, "val_acc": 60.0}
{"epoch": 24, "training_loss": 3307.571533203125, "training_acc": 50.0, "val_loss": 1759.0828857421875, "val_acc": 40.0}
{"epoch": 25, "training_loss": 2301.900390625, "training_acc": 50.0, "val_loss": 1786.6708984375, "val_acc": 40.0}
{"epoch": 26, "training_loss": 888.187109375, "training_acc": 70.0, "val_loss": 3975.237548828125, "val_acc": 60.0}
{"epoch": 27, "training_loss": 5092.05078125, "training_acc": 50.0, "val_loss": 3529.065673828125, "val_acc": 60.0}
{"epoch": 28, "training_loss": 3736.801171875, "training_acc": 50.0, "val_loss": 4419.4189453125, "val_acc": 40.0}
{"epoch": 29, "training_loss": 3887.470703125, "training_acc": 50.0, "val_loss": 8093.66650390625, "val_acc": 40.0}
{"epoch": 30, "training_loss": 6586.563671875, "training_acc": 50.0, "val_loss": 3586.974609375, "val_acc": 40.0}
{"epoch": 31, "training_loss": 3075.881640625, "training_acc": 40.0, "val_loss": 1812.2041015625, "val_acc": 60.0}
{"epoch": 32, "training_loss": 1985.58330078125, "training_acc": 50.0, "val_loss": 2500.065673828125, "val_acc": 40.0}
{"epoch": 33, "training_loss": 2120.891845703125, "training_acc": 50.0, "val_loss": 2513.079345703125, "val_acc": 40.0}
{"epoch": 34, "training_loss": 1744.5177490234375, "training_acc": 50.0, "val_loss": 514.1653442382812, "val_acc": 60.0}
{"epoch": 35, "training_loss": 710.974462890625, "training_acc": 50.0, "val_loss": 975.3175048828125, "val_acc": 40.0}
{"epoch": 36, "training_loss": 949.594287109375, "training_acc": 50.0, "val_loss": 1347.391357421875, "val_acc": 60.0}
{"epoch": 37, "training_loss": 1067.0541748046876, "training_acc": 50.0, "val_loss": 6048.7333984375, "val_acc": 40.0}
{"epoch": 38, "training_loss": 5026.8546875, "training_acc": 50.0, "val_loss": 11174.0615234375, "val_acc": 40.0}
{"epoch": 39, "training_loss": 9253.93359375, "training_acc": 50.0, "val_loss": 8959.9892578125, "val_acc": 40.0}
{"epoch": 40, "training_loss": 6542.1958984375, "training_acc": 50.0, "val_loss": 1062.3685302734375, "val_acc": 60.0}
{"epoch": 41, "training_loss": 2749.463232421875, "training_acc": 50.0, "val_loss": 3415.168701171875, "val_acc": 60.0}
