"main_modify.py --pretrained_path None --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 1 --task ADNI_sex --input_option yAware --learning_rate 1e2 --batch_size 16 --weight_decay 1e-8 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 1941.72023730278, "training_acc": 55.0, "val_loss": 4555.9228515625, "val_acc": 40.0}
{"epoch": 1, "training_loss": 3696.7947265625, "training_acc": 65.0, "val_loss": 16905.505859375, "val_acc": 60.0}
{"epoch": 2, "training_loss": 22292.649609375, "training_acc": 45.0, "val_loss": 5610.81201171875, "val_acc": 60.0}
{"epoch": 3, "training_loss": 8780.1142578125, "training_acc": 35.0, "val_loss": 11252.5986328125, "val_acc": 40.0}
{"epoch": 4, "training_loss": 8349.01298828125, "training_acc": 55.0, "val_loss": 7376.2705078125, "val_acc": 40.0}
{"epoch": 5, "training_loss": 5527.23984375, "training_acc": 55.0, "val_loss": 3862.234375, "val_acc": 60.0}
{"epoch": 6, "training_loss": 5709.5005859375, "training_acc": 45.0, "val_loss": 2306.22509765625, "val_acc": 60.0}
{"epoch": 7, "training_loss": 2575.57978515625, "training_acc": 55.0, "val_loss": 7651.26171875, "val_acc": 40.0}
{"epoch": 8, "training_loss": 6087.813671875, "training_acc": 55.0, "val_loss": 5634.5244140625, "val_acc": 40.0}
{"epoch": 9, "training_loss": 2859.9606506347654, "training_acc": 55.0, "val_loss": 5826.3134765625, "val_acc": 60.0}
{"epoch": 10, "training_loss": 9278.824609375, "training_acc": 45.0, "val_loss": 9400.43359375, "val_acc": 60.0}
{"epoch": 11, "training_loss": 12444.56171875, "training_acc": 45.0, "val_loss": 3998.509033203125, "val_acc": 60.0}
{"epoch": 12, "training_loss": 4106.846887207032, "training_acc": 55.0, "val_loss": 6684.80615234375, "val_acc": 40.0}
{"epoch": 13, "training_loss": 5695.820703125, "training_acc": 55.0, "val_loss": 7926.30615234375, "val_acc": 40.0}
{"epoch": 14, "training_loss": 5595.456201171875, "training_acc": 55.0, "val_loss": 659.2224731445312, "val_acc": 60.0}
{"epoch": 15, "training_loss": 997.7175537109375, "training_acc": 45.0, "val_loss": 1221.7672119140625, "val_acc": 60.0}
{"epoch": 16, "training_loss": 1301.6292419433594, "training_acc": 55.0, "val_loss": 2317.629638671875, "val_acc": 40.0}
{"epoch": 17, "training_loss": 1603.0833740234375, "training_acc": 55.0, "val_loss": 1199.03125, "val_acc": 60.0}
{"epoch": 18, "training_loss": 1568.1914611816405, "training_acc": 45.0, "val_loss": 1238.7908935546875, "val_acc": 40.0}
{"epoch": 19, "training_loss": 847.2386474609375, "training_acc": 55.0, "val_loss": 1407.2672119140625, "val_acc": 60.0}
{"epoch": 20, "training_loss": 1895.9180908203125, "training_acc": 45.0, "val_loss": 1030.347412109375, "val_acc": 40.0}
{"epoch": 21, "training_loss": 905.415380859375, "training_acc": 55.0, "val_loss": 1106.0784912109375, "val_acc": 60.0}
{"epoch": 22, "training_loss": 1625.33349609375, "training_acc": 45.0, "val_loss": 1373.464111328125, "val_acc": 40.0}
{"epoch": 23, "training_loss": 1010.559375, "training_acc": 55.0, "val_loss": 1840.6636962890625, "val_acc": 40.0}
{"epoch": 24, "training_loss": 1338.589404296875, "training_acc": 45.0, "val_loss": 1167.8541259765625, "val_acc": 40.0}
{"epoch": 25, "training_loss": 757.8732421875, "training_acc": 55.0, "val_loss": 2197.972412109375, "val_acc": 60.0}
{"epoch": 26, "training_loss": 3522.4060546875, "training_acc": 45.0, "val_loss": 800.23681640625, "val_acc": 60.0}
{"epoch": 27, "training_loss": 1176.7564453125, "training_acc": 55.0, "val_loss": 8392.9453125, "val_acc": 40.0}
{"epoch": 28, "training_loss": 6505.75859375, "training_acc": 55.0, "val_loss": 8512.673828125, "val_acc": 40.0}
{"epoch": 29, "training_loss": 5802.91669921875, "training_acc": 55.0, "val_loss": 149.295654296875, "val_acc": 60.0}
{"epoch": 30, "training_loss": 565.6247314453125, "training_acc": 45.0, "val_loss": 1169.5211181640625, "val_acc": 60.0}
{"epoch": 31, "training_loss": 1569.3015625, "training_acc": 45.0, "val_loss": 2037.2421875, "val_acc": 40.0}
{"epoch": 32, "training_loss": 1141.4353149414062, "training_acc": 55.0, "val_loss": 2876.315673828125, "val_acc": 60.0}
{"epoch": 33, "training_loss": 4465.8765625, "training_acc": 45.0, "val_loss": 2950.247314453125, "val_acc": 60.0}
{"epoch": 34, "training_loss": 3781.165576171875, "training_acc": 35.0, "val_loss": 897.9684448242188, "val_acc": 40.0}
{"epoch": 35, "training_loss": 361.8384765625, "training_acc": 75.0, "val_loss": 623.332763671875, "val_acc": 60.0}
{"epoch": 36, "training_loss": 850.085009765625, "training_acc": 45.0, "val_loss": 308.6561279296875, "val_acc": 40.0}
{"epoch": 37, "training_loss": 308.9951416015625, "training_acc": 65.0, "val_loss": 2083.73779296875, "val_acc": 60.0}
{"epoch": 38, "training_loss": 2693.7458618164064, "training_acc": 45.0, "val_loss": 2250.85302734375, "val_acc": 40.0}
{"epoch": 39, "training_loss": 1921.49580078125, "training_acc": 55.0, "val_loss": 523.0433959960938, "val_acc": 40.0}
{"epoch": 40, "training_loss": 951.315673828125, "training_acc": 55.0, "val_loss": 3888.9375, "val_acc": 60.0}
{"epoch": 41, "training_loss": 5144.70634765625, "training_acc": 45.0, "val_loss": 684.9713745117188, "val_acc": 60.0}
{"epoch": 42, "training_loss": 1576.47265625, "training_acc": 45.0, "val_loss": 7858.37353515625, "val_acc": 40.0}
{"epoch": 43, "training_loss": 6064.6205078125, "training_acc": 55.0, "val_loss": 5654.34619140625, "val_acc": 40.0}
{"epoch": 44, "training_loss": 3398.373571777344, "training_acc": 55.0, "val_loss": 3999.703857421875, "val_acc": 60.0}
{"epoch": 45, "training_loss": 5744.668603515625, "training_acc": 45.0, "val_loss": 7062.03271484375, "val_acc": 60.0}
{"epoch": 46, "training_loss": 9478.17421875, "training_acc": 45.0, "val_loss": 3642.270263671875, "val_acc": 60.0}
{"epoch": 47, "training_loss": 3688.0892944335938, "training_acc": 55.0, "val_loss": 4356.97509765625, "val_acc": 40.0}
{"epoch": 48, "training_loss": 3662.421484375, "training_acc": 55.0, "val_loss": 3998.058349609375, "val_acc": 40.0}
