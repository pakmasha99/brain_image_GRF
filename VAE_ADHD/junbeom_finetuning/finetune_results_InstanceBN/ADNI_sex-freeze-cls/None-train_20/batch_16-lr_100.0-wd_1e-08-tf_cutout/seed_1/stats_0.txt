"main_modify.py --pretrained_path None --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 1 --task ADNI_sex --input_option yAware --learning_rate 1e2 --batch_size 16 --weight_decay 1e-8 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 2149.089481830597, "training_acc": 55.0, "val_loss": 7894.17529296875, "val_acc": 40.0}
{"epoch": 1, "training_loss": 5069.52783203125, "training_acc": 65.0, "val_loss": 14342.291015625, "val_acc": 60.0}
{"epoch": 2, "training_loss": 18757.1943359375, "training_acc": 45.0, "val_loss": 2799.960205078125, "val_acc": 60.0}
{"epoch": 3, "training_loss": 5021.153515625, "training_acc": 45.0, "val_loss": 18148.666015625, "val_acc": 40.0}
{"epoch": 4, "training_loss": 14115.5140625, "training_acc": 55.0, "val_loss": 15281.7138671875, "val_acc": 40.0}
{"epoch": 5, "training_loss": 10769.607861328124, "training_acc": 55.0, "val_loss": 1481.380615234375, "val_acc": 60.0}
{"epoch": 6, "training_loss": 2643.28896484375, "training_acc": 45.0, "val_loss": 3589.013427734375, "val_acc": 60.0}
{"epoch": 7, "training_loss": 3768.51748046875, "training_acc": 45.0, "val_loss": 7065.5361328125, "val_acc": 40.0}
{"epoch": 8, "training_loss": 5697.9142578125, "training_acc": 55.0, "val_loss": 14790.001953125, "val_acc": 40.0}
{"epoch": 9, "training_loss": 11311.800390625, "training_acc": 55.0, "val_loss": 10484.927734375, "val_acc": 40.0}
{"epoch": 10, "training_loss": 6220.66015625, "training_acc": 55.0, "val_loss": 3840.18017578125, "val_acc": 60.0}
{"epoch": 11, "training_loss": 6222.2478515625, "training_acc": 45.0, "val_loss": 9221.7880859375, "val_acc": 60.0}
{"epoch": 12, "training_loss": 12574.420703125, "training_acc": 45.0, "val_loss": 6147.7734375, "val_acc": 60.0}
{"epoch": 13, "training_loss": 7362.38935546875, "training_acc": 45.0, "val_loss": 5716.06884765625, "val_acc": 40.0}
{"epoch": 14, "training_loss": 5699.57578125, "training_acc": 55.0, "val_loss": 12731.970703125, "val_acc": 40.0}
{"epoch": 15, "training_loss": 9431.05361328125, "training_acc": 55.0, "val_loss": 9070.6513671875, "val_acc": 40.0}
{"epoch": 16, "training_loss": 6070.869775390625, "training_acc": 55.0, "val_loss": 1080.0281982421875, "val_acc": 60.0}
{"epoch": 17, "training_loss": 2301.48125, "training_acc": 45.0, "val_loss": 2726.393310546875, "val_acc": 60.0}
{"epoch": 18, "training_loss": 3180.892138671875, "training_acc": 45.0, "val_loss": 4851.83056640625, "val_acc": 40.0}
{"epoch": 19, "training_loss": 4417.4201171875, "training_acc": 55.0, "val_loss": 7208.04248046875, "val_acc": 40.0}
{"epoch": 20, "training_loss": 4918.85224609375, "training_acc": 55.0, "val_loss": 394.2350769042969, "val_acc": 60.0}
{"epoch": 21, "training_loss": 672.846875, "training_acc": 45.0, "val_loss": 1426.0611572265625, "val_acc": 60.0}
{"epoch": 22, "training_loss": 1977.093896484375, "training_acc": 35.0, "val_loss": 125.97846984863281, "val_acc": 60.0}
{"epoch": 23, "training_loss": 417.9336181640625, "training_acc": 45.0, "val_loss": 834.65283203125, "val_acc": 40.0}
{"epoch": 24, "training_loss": 543.5846069335937, "training_acc": 65.0, "val_loss": 1785.2066650390625, "val_acc": 60.0}
{"epoch": 25, "training_loss": 2296.4694763183593, "training_acc": 45.0, "val_loss": 2458.44921875, "val_acc": 40.0}
{"epoch": 26, "training_loss": 2073.2185546875, "training_acc": 55.0, "val_loss": 673.5779418945312, "val_acc": 40.0}
{"epoch": 27, "training_loss": 1489.778271484375, "training_acc": 45.0, "val_loss": 3312.526123046875, "val_acc": 60.0}
{"epoch": 28, "training_loss": 4141.9314453125, "training_acc": 45.0, "val_loss": 1777.1663818359375, "val_acc": 40.0}
{"epoch": 29, "training_loss": 1500.578662109375, "training_acc": 55.0, "val_loss": 4765.22314453125, "val_acc": 40.0}
{"epoch": 30, "training_loss": 3285.041015625, "training_acc": 55.0, "val_loss": 556.92333984375, "val_acc": 60.0}
{"epoch": 31, "training_loss": 1006.0696533203125, "training_acc": 45.0, "val_loss": 748.1930541992188, "val_acc": 60.0}
{"epoch": 32, "training_loss": 935.31279296875, "training_acc": 55.0, "val_loss": 4121.2705078125, "val_acc": 40.0}
{"epoch": 33, "training_loss": 3018.2340087890625, "training_acc": 55.0, "val_loss": 1557.2811279296875, "val_acc": 40.0}
{"epoch": 34, "training_loss": 1652.38193359375, "training_acc": 45.0, "val_loss": 1700.212158203125, "val_acc": 60.0}
{"epoch": 35, "training_loss": 2226.292102050781, "training_acc": 35.0, "val_loss": 353.8467712402344, "val_acc": 60.0}
{"epoch": 36, "training_loss": 609.7637573242188, "training_acc": 45.0, "val_loss": 558.8395385742188, "val_acc": 40.0}
{"epoch": 37, "training_loss": 973.477294921875, "training_acc": 45.0, "val_loss": 1071.02685546875, "val_acc": 60.0}
{"epoch": 38, "training_loss": 1510.91494140625, "training_acc": 45.0, "val_loss": 2494.708740234375, "val_acc": 40.0}
{"epoch": 39, "training_loss": 1705.7621704101562, "training_acc": 55.0, "val_loss": 1307.64794921875, "val_acc": 60.0}
{"epoch": 40, "training_loss": 1837.31875, "training_acc": 45.0, "val_loss": 1381.7186279296875, "val_acc": 40.0}
{"epoch": 41, "training_loss": 1349.314501953125, "training_acc": 55.0, "val_loss": 393.010009765625, "val_acc": 40.0}
