"main_modify.py --pretrained_path None --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 4 --task ADNI_sex --input_option yAware --learning_rate 2e1 --batch_size 8 --weight_decay 4e-9 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 2991.4399141073227, "training_acc": 50.0, "val_loss": 1018.9873046875, "val_acc": 40.0}
{"epoch": 1, "training_loss": 1695.3639892578126, "training_acc": 50.0, "val_loss": 851.8883056640625, "val_acc": 40.0}
{"epoch": 2, "training_loss": 575.2282348632813, "training_acc": 60.0, "val_loss": 785.9921875, "val_acc": 60.0}
{"epoch": 3, "training_loss": 622.134419631958, "training_acc": 30.0, "val_loss": 522.61669921875, "val_acc": 60.0}
{"epoch": 4, "training_loss": 664.9385131835937, "training_acc": 50.0, "val_loss": 532.6160888671875, "val_acc": 40.0}
{"epoch": 5, "training_loss": 651.350244140625, "training_acc": 50.0, "val_loss": 383.09649658203125, "val_acc": 40.0}
{"epoch": 6, "training_loss": 266.9892944335937, "training_acc": 70.0, "val_loss": 677.1350708007812, "val_acc": 60.0}
{"epoch": 7, "training_loss": 688.96123046875, "training_acc": 40.0, "val_loss": 499.3981018066406, "val_acc": 40.0}
{"epoch": 8, "training_loss": 250.26999206542968, "training_acc": 60.0, "val_loss": 555.66552734375, "val_acc": 60.0}
{"epoch": 9, "training_loss": 610.8591901779175, "training_acc": 50.0, "val_loss": 910.8351440429688, "val_acc": 40.0}
{"epoch": 10, "training_loss": 903.4485107421875, "training_acc": 50.0, "val_loss": 419.8714294433594, "val_acc": 40.0}
{"epoch": 11, "training_loss": 625.1603881835938, "training_acc": 50.0, "val_loss": 726.5204467773438, "val_acc": 60.0}
{"epoch": 12, "training_loss": 588.1955261230469, "training_acc": 50.0, "val_loss": 1057.5408935546875, "val_acc": 40.0}
{"epoch": 13, "training_loss": 823.918701171875, "training_acc": 50.0, "val_loss": 250.9273223876953, "val_acc": 60.0}
{"epoch": 14, "training_loss": 555.068994140625, "training_acc": 50.0, "val_loss": 221.32981872558594, "val_acc": 60.0}
{"epoch": 15, "training_loss": 354.04990234375, "training_acc": 60.0, "val_loss": 743.2745971679688, "val_acc": 40.0}
{"epoch": 16, "training_loss": 422.249951171875, "training_acc": 50.0, "val_loss": 787.6107177734375, "val_acc": 60.0}
{"epoch": 17, "training_loss": 991.1312377929687, "training_acc": 50.0, "val_loss": 214.6284637451172, "val_acc": 40.0}
{"epoch": 18, "training_loss": 497.17778930664065, "training_acc": 50.0, "val_loss": 575.3070068359375, "val_acc": 40.0}
{"epoch": 19, "training_loss": 225.64354667663574, "training_acc": 60.0, "val_loss": 133.8517303466797, "val_acc": 40.0}
{"epoch": 20, "training_loss": 91.8790298461914, "training_acc": 50.0, "val_loss": 291.9706115722656, "val_acc": 40.0}
{"epoch": 21, "training_loss": 159.0581069946289, "training_acc": 50.0, "val_loss": 479.54931640625, "val_acc": 40.0}
{"epoch": 22, "training_loss": 396.29075012207034, "training_acc": 50.0, "val_loss": 529.5549926757812, "val_acc": 60.0}
{"epoch": 23, "training_loss": 795.2687866210938, "training_acc": 50.0, "val_loss": 207.9582977294922, "val_acc": 60.0}
{"epoch": 24, "training_loss": 374.9661499023438, "training_acc": 60.0, "val_loss": 1099.713623046875, "val_acc": 40.0}
{"epoch": 25, "training_loss": 501.6570983886719, "training_acc": 70.0, "val_loss": 402.43017578125, "val_acc": 60.0}
{"epoch": 26, "training_loss": 524.4156555175781, "training_acc": 30.0, "val_loss": 49.16511917114258, "val_acc": 60.0}
{"epoch": 27, "training_loss": 90.20873260498047, "training_acc": 50.0, "val_loss": 14.447081565856934, "val_acc": 40.0}
{"epoch": 28, "training_loss": 105.35228271484375, "training_acc": 50.0, "val_loss": 613.7760620117188, "val_acc": 40.0}
{"epoch": 29, "training_loss": 468.7202003479004, "training_acc": 50.0, "val_loss": 367.6530456542969, "val_acc": 60.0}
{"epoch": 30, "training_loss": 522.664404296875, "training_acc": 50.0, "val_loss": 448.1459655761719, "val_acc": 40.0}
{"epoch": 31, "training_loss": 458.8218566894531, "training_acc": 50.0, "val_loss": 7.97607421875, "val_acc": 60.0}
{"epoch": 32, "training_loss": 46.82411708831787, "training_acc": 65.0, "val_loss": 190.4769744873047, "val_acc": 60.0}
{"epoch": 33, "training_loss": 157.78580322265626, "training_acc": 60.0, "val_loss": 672.1220092773438, "val_acc": 40.0}
{"epoch": 34, "training_loss": 409.5751678466797, "training_acc": 50.0, "val_loss": 301.6865539550781, "val_acc": 60.0}
{"epoch": 35, "training_loss": 218.2492202758789, "training_acc": 40.0, "val_loss": 181.86817932128906, "val_acc": 40.0}
{"epoch": 36, "training_loss": 67.10085697174073, "training_acc": 60.0, "val_loss": 257.4617614746094, "val_acc": 60.0}
{"epoch": 37, "training_loss": 167.35274963378907, "training_acc": 70.0, "val_loss": 383.0243225097656, "val_acc": 40.0}
{"epoch": 38, "training_loss": 462.6597473144531, "training_acc": 30.0, "val_loss": 428.38848876953125, "val_acc": 60.0}
{"epoch": 39, "training_loss": 271.89780855178833, "training_acc": 65.0, "val_loss": 1283.5113525390625, "val_acc": 40.0}
{"epoch": 40, "training_loss": 989.941845703125, "training_acc": 50.0, "val_loss": 157.9685516357422, "val_acc": 60.0}
{"epoch": 41, "training_loss": 431.399658203125, "training_acc": 50.0, "val_loss": 76.77791595458984, "val_acc": 60.0}
{"epoch": 42, "training_loss": 766.3899078369141, "training_acc": 40.0, "val_loss": 1776.241455078125, "val_acc": 40.0}
{"epoch": 43, "training_loss": 1199.619775390625, "training_acc": 50.0, "val_loss": 345.4696350097656, "val_acc": 60.0}
{"epoch": 44, "training_loss": 739.3059692382812, "training_acc": 50.0, "val_loss": 513.91357421875, "val_acc": 60.0}
{"epoch": 45, "training_loss": 379.41026611328124, "training_acc": 50.0, "val_loss": 1860.7769775390625, "val_acc": 40.0}
{"epoch": 46, "training_loss": 1622.966650390625, "training_acc": 50.0, "val_loss": 879.1393432617188, "val_acc": 40.0}
{"epoch": 47, "training_loss": 826.3140625, "training_acc": 40.0, "val_loss": 779.7870483398438, "val_acc": 60.0}
{"epoch": 48, "training_loss": 537.3858421325683, "training_acc": 60.0, "val_loss": 681.1625366210938, "val_acc": 40.0}
{"epoch": 49, "training_loss": 410.9344821929932, "training_acc": 50.0, "val_loss": 36.817283630371094, "val_acc": 40.0}
{"epoch": 50, "training_loss": 201.1654541015625, "training_acc": 50.0, "val_loss": 310.7238464355469, "val_acc": 40.0}
