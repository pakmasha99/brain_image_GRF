"main_modify.py --pretrained_path None --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 5 --task ADNI_sex --input_option yAware --learning_rate 2e1 --batch_size 8 --weight_decay 4e-9 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 3103.0153066396715, "training_acc": 25.0, "val_loss": 1031.8641357421875, "val_acc": 40.0}
{"epoch": 1, "training_loss": 1424.342431640625, "training_acc": 55.0, "val_loss": 2775.89453125, "val_acc": 60.0}
{"epoch": 2, "training_loss": 3489.02421875, "training_acc": 45.0, "val_loss": 932.84814453125, "val_acc": 60.0}
{"epoch": 3, "training_loss": 1679.324365234375, "training_acc": 45.0, "val_loss": 3137.5146484375, "val_acc": 40.0}
{"epoch": 4, "training_loss": 2236.1141357421875, "training_acc": 55.0, "val_loss": 1327.1136474609375, "val_acc": 40.0}
{"epoch": 5, "training_loss": 634.9574012756348, "training_acc": 45.0, "val_loss": 389.34033203125, "val_acc": 60.0}
{"epoch": 6, "training_loss": 214.7379913330078, "training_acc": 55.0, "val_loss": 55.78091049194336, "val_acc": 60.0}
{"epoch": 7, "training_loss": 150.9874496459961, "training_acc": 35.0, "val_loss": 568.561767578125, "val_acc": 40.0}
{"epoch": 8, "training_loss": 511.3484252929687, "training_acc": 55.0, "val_loss": 82.89974212646484, "val_acc": 60.0}
{"epoch": 9, "training_loss": 308.5526428222656, "training_acc": 45.0, "val_loss": 595.5402221679688, "val_acc": 40.0}
{"epoch": 10, "training_loss": 761.1679931640625, "training_acc": 55.0, "val_loss": 624.2879028320312, "val_acc": 40.0}
{"epoch": 11, "training_loss": 424.8376831054687, "training_acc": 45.0, "val_loss": 19.299230575561523, "val_acc": 40.0}
{"epoch": 12, "training_loss": 56.522782516479495, "training_acc": 55.0, "val_loss": 4.067595481872559, "val_acc": 60.0}
{"epoch": 13, "training_loss": 201.10273571014403, "training_acc": 65.0, "val_loss": 467.445556640625, "val_acc": 40.0}
{"epoch": 14, "training_loss": 242.85095977783203, "training_acc": 55.0, "val_loss": 919.2294921875, "val_acc": 60.0}
{"epoch": 15, "training_loss": 1241.3823974609375, "training_acc": 45.0, "val_loss": 167.7798309326172, "val_acc": 40.0}
{"epoch": 16, "training_loss": 508.90150146484376, "training_acc": 55.0, "val_loss": 778.3590698242188, "val_acc": 40.0}
{"epoch": 17, "training_loss": 424.32220153808595, "training_acc": 55.0, "val_loss": 900.5866088867188, "val_acc": 60.0}
{"epoch": 18, "training_loss": 1113.320361328125, "training_acc": 45.0, "val_loss": 530.7782592773438, "val_acc": 40.0}
{"epoch": 19, "training_loss": 466.13463134765624, "training_acc": 55.0, "val_loss": 32.3454475402832, "val_acc": 40.0}
{"epoch": 20, "training_loss": 536.2170417785644, "training_acc": 45.0, "val_loss": 529.9711303710938, "val_acc": 60.0}
{"epoch": 21, "training_loss": 357.3693786621094, "training_acc": 55.0, "val_loss": 1673.7691650390625, "val_acc": 40.0}
{"epoch": 22, "training_loss": 1498.4270263671874, "training_acc": 55.0, "val_loss": 1364.9443359375, "val_acc": 40.0}
{"epoch": 23, "training_loss": 627.7455200195312, "training_acc": 55.0, "val_loss": 809.7338256835938, "val_acc": 60.0}
{"epoch": 24, "training_loss": 1230.9916748046876, "training_acc": 45.0, "val_loss": 2.4043891429901123, "val_acc": 60.0}
{"epoch": 25, "training_loss": 568.1095267295838, "training_acc": 65.0, "val_loss": 1748.2584228515625, "val_acc": 40.0}
{"epoch": 26, "training_loss": 1150.49345703125, "training_acc": 55.0, "val_loss": 115.34233856201172, "val_acc": 40.0}
{"epoch": 27, "training_loss": 940.643408203125, "training_acc": 45.0, "val_loss": 1503.7674560546875, "val_acc": 60.0}
{"epoch": 28, "training_loss": 1709.6778076171875, "training_acc": 45.0, "val_loss": 257.806884765625, "val_acc": 40.0}
{"epoch": 29, "training_loss": 578.0208740234375, "training_acc": 55.0, "val_loss": 968.876953125, "val_acc": 40.0}
{"epoch": 30, "training_loss": 386.6048126220703, "training_acc": 65.0, "val_loss": 538.0133056640625, "val_acc": 60.0}
{"epoch": 31, "training_loss": 621.7856903076172, "training_acc": 35.0, "val_loss": 49.436012268066406, "val_acc": 40.0}
{"epoch": 32, "training_loss": 260.92665100097656, "training_acc": 45.0, "val_loss": 248.3226776123047, "val_acc": 40.0}
{"epoch": 33, "training_loss": 145.73917236328126, "training_acc": 55.0, "val_loss": 102.11544036865234, "val_acc": 40.0}
{"epoch": 34, "training_loss": 105.74508666992188, "training_acc": 45.0, "val_loss": 945.8358764648438, "val_acc": 40.0}
{"epoch": 35, "training_loss": 901.3686767578125, "training_acc": 55.0, "val_loss": 1038.6988525390625, "val_acc": 40.0}
{"epoch": 36, "training_loss": 541.2705810546875, "training_acc": 55.0, "val_loss": 985.46337890625, "val_acc": 60.0}
{"epoch": 37, "training_loss": 1199.7670043945313, "training_acc": 45.0, "val_loss": 193.64476013183594, "val_acc": 40.0}
{"epoch": 38, "training_loss": 547.7661071777344, "training_acc": 55.0, "val_loss": 354.1168518066406, "val_acc": 40.0}
{"epoch": 39, "training_loss": 609.5182250976562, "training_acc": 45.0, "val_loss": 538.8195190429688, "val_acc": 60.0}
{"epoch": 40, "training_loss": 539.102880859375, "training_acc": 35.0, "val_loss": 267.76348876953125, "val_acc": 40.0}
{"epoch": 41, "training_loss": 227.80889282226562, "training_acc": 55.0, "val_loss": 188.1715087890625, "val_acc": 40.0}
{"epoch": 42, "training_loss": 169.70375061035156, "training_acc": 55.0, "val_loss": 474.1034851074219, "val_acc": 60.0}
{"epoch": 43, "training_loss": 799.1430206298828, "training_acc": 45.0, "val_loss": 4.788965225219727, "val_acc": 60.0}
