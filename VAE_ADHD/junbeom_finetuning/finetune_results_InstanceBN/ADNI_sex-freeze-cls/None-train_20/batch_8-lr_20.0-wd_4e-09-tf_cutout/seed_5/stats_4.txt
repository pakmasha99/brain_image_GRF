"main_modify.py --pretrained_path None --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 5 --task ADNI_sex --input_option yAware --learning_rate 2e1 --batch_size 8 --weight_decay 4e-9 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 1879.0289976119996, "training_acc": 50.0, "val_loss": 542.0885620117188, "val_acc": 40.0}
{"epoch": 1, "training_loss": 834.3726806640625, "training_acc": 50.0, "val_loss": 448.4300231933594, "val_acc": 40.0}
{"epoch": 2, "training_loss": 328.5660766601562, "training_acc": 70.0, "val_loss": 523.4385375976562, "val_acc": 60.0}
{"epoch": 3, "training_loss": 601.2498779296875, "training_acc": 40.0, "val_loss": 165.22813415527344, "val_acc": 60.0}
{"epoch": 4, "training_loss": 293.93523559570315, "training_acc": 40.0, "val_loss": 270.6075134277344, "val_acc": 40.0}
{"epoch": 5, "training_loss": 451.8299560546875, "training_acc": 50.0, "val_loss": 214.72708129882812, "val_acc": 60.0}
{"epoch": 6, "training_loss": 644.7630859375, "training_acc": 40.0, "val_loss": 1018.96337890625, "val_acc": 40.0}
{"epoch": 7, "training_loss": 731.4078857421875, "training_acc": 40.0, "val_loss": 691.6857299804688, "val_acc": 60.0}
{"epoch": 8, "training_loss": 648.603288269043, "training_acc": 50.0, "val_loss": 1033.171875, "val_acc": 40.0}
{"epoch": 9, "training_loss": 1039.48955078125, "training_acc": 50.0, "val_loss": 1050.8924560546875, "val_acc": 40.0}
{"epoch": 10, "training_loss": 493.9461151123047, "training_acc": 60.0, "val_loss": 803.5805053710938, "val_acc": 60.0}
{"epoch": 11, "training_loss": 969.900537109375, "training_acc": 50.0, "val_loss": 13.295035362243652, "val_acc": 40.0}
{"epoch": 12, "training_loss": 139.97703552246094, "training_acc": 40.0, "val_loss": 373.7539978027344, "val_acc": 40.0}
{"epoch": 13, "training_loss": 262.82139282226564, "training_acc": 50.0, "val_loss": 233.5653533935547, "val_acc": 60.0}
{"epoch": 14, "training_loss": 92.04359970092773, "training_acc": 70.0, "val_loss": 1233.6478271484375, "val_acc": 40.0}
{"epoch": 15, "training_loss": 950.0046600341797, "training_acc": 50.0, "val_loss": 94.81492614746094, "val_acc": 60.0}
{"epoch": 16, "training_loss": 157.2006042480469, "training_acc": 50.0, "val_loss": 795.4345092773438, "val_acc": 40.0}
{"epoch": 17, "training_loss": 1028.4484130859375, "training_acc": 50.0, "val_loss": 482.0468444824219, "val_acc": 40.0}
{"epoch": 18, "training_loss": 351.7433288574219, "training_acc": 70.0, "val_loss": 810.3987426757812, "val_acc": 60.0}
{"epoch": 19, "training_loss": 679.501065826416, "training_acc": 50.0, "val_loss": 359.4293518066406, "val_acc": 40.0}
{"epoch": 20, "training_loss": 302.81077880859374, "training_acc": 50.0, "val_loss": 341.6075744628906, "val_acc": 60.0}
{"epoch": 21, "training_loss": 440.6158805847168, "training_acc": 40.0, "val_loss": 949.3132934570312, "val_acc": 40.0}
{"epoch": 22, "training_loss": 544.3860748291015, "training_acc": 50.0, "val_loss": 336.77081298828125, "val_acc": 60.0}
{"epoch": 23, "training_loss": 333.9496765136719, "training_acc": 50.0, "val_loss": 626.9840698242188, "val_acc": 40.0}
{"epoch": 24, "training_loss": 500.8920867919922, "training_acc": 40.0, "val_loss": 617.798583984375, "val_acc": 60.0}
{"epoch": 25, "training_loss": 456.24709968566896, "training_acc": 60.0, "val_loss": 458.6859436035156, "val_acc": 40.0}
{"epoch": 26, "training_loss": 336.773664855957, "training_acc": 50.0, "val_loss": 729.000244140625, "val_acc": 60.0}
{"epoch": 27, "training_loss": 1102.8958251953125, "training_acc": 50.0, "val_loss": 759.1370849609375, "val_acc": 60.0}
{"epoch": 28, "training_loss": 881.7251152992249, "training_acc": 45.0, "val_loss": 1651.798828125, "val_acc": 40.0}
{"epoch": 29, "training_loss": 1177.0558715820312, "training_acc": 50.0, "val_loss": 112.8020248413086, "val_acc": 60.0}
{"epoch": 30, "training_loss": 433.7719787597656, "training_acc": 50.0, "val_loss": 3.7422311305999756, "val_acc": 60.0}
{"epoch": 31, "training_loss": 742.4187602996826, "training_acc": 40.0, "val_loss": 853.3162231445312, "val_acc": 40.0}
{"epoch": 32, "training_loss": 445.7363708496094, "training_acc": 50.0, "val_loss": 1258.9608154296875, "val_acc": 60.0}
{"epoch": 33, "training_loss": 1655.198388671875, "training_acc": 50.0, "val_loss": 630.416015625, "val_acc": 60.0}
{"epoch": 34, "training_loss": 626.95908203125, "training_acc": 50.0, "val_loss": 949.1951293945312, "val_acc": 40.0}
{"epoch": 35, "training_loss": 681.8871154785156, "training_acc": 40.0, "val_loss": 677.2177734375, "val_acc": 60.0}
{"epoch": 36, "training_loss": 674.4129028320312, "training_acc": 50.0, "val_loss": 893.5274658203125, "val_acc": 40.0}
{"epoch": 37, "training_loss": 970.4794677734375, "training_acc": 50.0, "val_loss": 1228.719970703125, "val_acc": 40.0}
{"epoch": 38, "training_loss": 654.6982666015625, "training_acc": 50.0, "val_loss": 636.7355346679688, "val_acc": 60.0}
{"epoch": 39, "training_loss": 755.0249633789062, "training_acc": 50.0, "val_loss": 382.4931640625, "val_acc": 40.0}
{"epoch": 40, "training_loss": 390.73243408203126, "training_acc": 50.0, "val_loss": 94.19628143310547, "val_acc": 40.0}
{"epoch": 41, "training_loss": 500.627001953125, "training_acc": 50.0, "val_loss": 688.8779296875, "val_acc": 60.0}
{"epoch": 42, "training_loss": 694.1352294921875, "training_acc": 40.0, "val_loss": 1060.634033203125, "val_acc": 40.0}
{"epoch": 43, "training_loss": 653.6207153320313, "training_acc": 50.0, "val_loss": 561.1106567382812, "val_acc": 60.0}
{"epoch": 44, "training_loss": 1207.6607666015625, "training_acc": 50.0, "val_loss": 766.000244140625, "val_acc": 60.0}
{"epoch": 45, "training_loss": 497.8443313598633, "training_acc": 60.0, "val_loss": 2271.221435546875, "val_acc": 40.0}
{"epoch": 46, "training_loss": 1926.944140625, "training_acc": 50.0, "val_loss": 1784.9598388671875, "val_acc": 40.0}
{"epoch": 47, "training_loss": 953.2940124511719, "training_acc": 50.0, "val_loss": 865.2584228515625, "val_acc": 60.0}
{"epoch": 48, "training_loss": 1152.5640380859375, "training_acc": 50.0, "val_loss": 280.21929931640625, "val_acc": 60.0}
{"epoch": 49, "training_loss": 662.4477172851563, "training_acc": 50.0, "val_loss": 1952.9422607421875, "val_acc": 40.0}
