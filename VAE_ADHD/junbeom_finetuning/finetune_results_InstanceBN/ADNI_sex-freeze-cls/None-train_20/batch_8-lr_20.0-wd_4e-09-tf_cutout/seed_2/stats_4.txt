"main_modify.py --pretrained_path None --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 2 --task ADNI_sex --input_option yAware --learning_rate 2e1 --batch_size 8 --weight_decay 4e-9 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 2314.3731890678405, "training_acc": 45.0, "val_loss": 829.2158203125, "val_acc": 60.0}
{"epoch": 1, "training_loss": 1143.31044921875, "training_acc": 45.0, "val_loss": 1733.4595947265625, "val_acc": 40.0}
{"epoch": 2, "training_loss": 1545.4776123046875, "training_acc": 55.0, "val_loss": 1807.4527587890625, "val_acc": 40.0}
{"epoch": 3, "training_loss": 1123.381201171875, "training_acc": 45.0, "val_loss": 1419.5384521484375, "val_acc": 60.0}
{"epoch": 4, "training_loss": 1602.24228515625, "training_acc": 45.0, "val_loss": 482.33642578125, "val_acc": 40.0}
{"epoch": 5, "training_loss": 689.375, "training_acc": 55.0, "val_loss": 1164.5977783203125, "val_acc": 40.0}
{"epoch": 6, "training_loss": 924.6430541992188, "training_acc": 35.0, "val_loss": 738.6754760742188, "val_acc": 60.0}
{"epoch": 7, "training_loss": 609.8628829956054, "training_acc": 55.0, "val_loss": 790.4329223632812, "val_acc": 40.0}
{"epoch": 8, "training_loss": 584.5998779296875, "training_acc": 55.0, "val_loss": 238.95327758789062, "val_acc": 60.0}
{"epoch": 9, "training_loss": 418.4152526855469, "training_acc": 45.0, "val_loss": 602.5404663085938, "val_acc": 40.0}
{"epoch": 10, "training_loss": 807.5457458496094, "training_acc": 55.0, "val_loss": 641.2799682617188, "val_acc": 40.0}
{"epoch": 11, "training_loss": 657.6089233398437, "training_acc": 35.0, "val_loss": 290.4617614746094, "val_acc": 60.0}
{"epoch": 12, "training_loss": 493.8255126953125, "training_acc": 45.0, "val_loss": 738.2096557617188, "val_acc": 40.0}
{"epoch": 13, "training_loss": 405.7262268066406, "training_acc": 55.0, "val_loss": 735.5925903320312, "val_acc": 60.0}
{"epoch": 14, "training_loss": 735.6179405212403, "training_acc": 45.0, "val_loss": 1079.5792236328125, "val_acc": 40.0}
{"epoch": 15, "training_loss": 1060.0611083984375, "training_acc": 55.0, "val_loss": 1422.9110107421875, "val_acc": 40.0}
{"epoch": 16, "training_loss": 778.4292114257812, "training_acc": 45.0, "val_loss": 555.0682983398438, "val_acc": 60.0}
{"epoch": 17, "training_loss": 528.607502746582, "training_acc": 55.0, "val_loss": 512.5086059570312, "val_acc": 40.0}
{"epoch": 18, "training_loss": 230.65814552307128, "training_acc": 65.0, "val_loss": 153.3811492919922, "val_acc": 60.0}
{"epoch": 19, "training_loss": 184.03956909179686, "training_acc": 35.0, "val_loss": 467.76495361328125, "val_acc": 40.0}
{"epoch": 20, "training_loss": 293.275989151001, "training_acc": 55.0, "val_loss": 334.8373107910156, "val_acc": 60.0}
{"epoch": 21, "training_loss": 511.5859741210937, "training_acc": 45.0, "val_loss": 897.2169189453125, "val_acc": 40.0}
{"epoch": 22, "training_loss": 1206.932080078125, "training_acc": 55.0, "val_loss": 1787.1766357421875, "val_acc": 40.0}
{"epoch": 23, "training_loss": 1006.75732421875, "training_acc": 55.0, "val_loss": 631.9611206054688, "val_acc": 60.0}
{"epoch": 24, "training_loss": 1078.102197265625, "training_acc": 45.0, "val_loss": 523.2516479492188, "val_acc": 60.0}
{"epoch": 25, "training_loss": 455.434130859375, "training_acc": 45.0, "val_loss": 135.46388244628906, "val_acc": 40.0}
{"epoch": 26, "training_loss": 318.12623901367186, "training_acc": 55.0, "val_loss": 198.0408477783203, "val_acc": 60.0}
{"epoch": 27, "training_loss": 545.5761840820312, "training_acc": 45.0, "val_loss": 810.3681030273438, "val_acc": 40.0}
{"epoch": 28, "training_loss": 549.1367309570312, "training_acc": 25.0, "val_loss": 248.7439422607422, "val_acc": 40.0}
{"epoch": 29, "training_loss": 376.51768951416017, "training_acc": 55.0, "val_loss": 339.3344421386719, "val_acc": 60.0}
{"epoch": 30, "training_loss": 535.520068359375, "training_acc": 45.0, "val_loss": 420.590087890625, "val_acc": 40.0}
{"epoch": 31, "training_loss": 564.6206604003906, "training_acc": 55.0, "val_loss": 159.71299743652344, "val_acc": 40.0}
{"epoch": 32, "training_loss": 456.9644317626953, "training_acc": 55.0, "val_loss": 605.364013671875, "val_acc": 60.0}
{"epoch": 33, "training_loss": 707.7059814453125, "training_acc": 35.0, "val_loss": 1496.95703125, "val_acc": 40.0}
{"epoch": 34, "training_loss": 1054.2882568359375, "training_acc": 55.0, "val_loss": 220.56663513183594, "val_acc": 40.0}
{"epoch": 35, "training_loss": 755.630712890625, "training_acc": 45.0, "val_loss": 1059.1868896484375, "val_acc": 60.0}
{"epoch": 36, "training_loss": 927.2795166015625, "training_acc": 45.0, "val_loss": 1236.4898681640625, "val_acc": 40.0}
{"epoch": 37, "training_loss": 1626.9907470703124, "training_acc": 55.0, "val_loss": 2853.047119140625, "val_acc": 40.0}
{"epoch": 38, "training_loss": 1903.64443359375, "training_acc": 55.0, "val_loss": 107.96112060546875, "val_acc": 40.0}
{"epoch": 39, "training_loss": 860.5969970703125, "training_acc": 45.0, "val_loss": 1321.82373046875, "val_acc": 60.0}
{"epoch": 40, "training_loss": 1458.9382568359374, "training_acc": 45.0, "val_loss": 443.6330261230469, "val_acc": 40.0}
{"epoch": 41, "training_loss": 799.69697265625, "training_acc": 55.0, "val_loss": 1873.578125, "val_acc": 40.0}
{"epoch": 42, "training_loss": 1084.90361328125, "training_acc": 55.0, "val_loss": 253.16136169433594, "val_acc": 60.0}
{"epoch": 43, "training_loss": 680.254736328125, "training_acc": 45.0, "val_loss": 431.9883728027344, "val_acc": 60.0}
{"epoch": 44, "training_loss": 411.3747192382813, "training_acc": 55.0, "val_loss": 775.2543334960938, "val_acc": 40.0}
{"epoch": 45, "training_loss": 610.0563232421875, "training_acc": 35.0, "val_loss": 481.04180908203125, "val_acc": 60.0}
{"epoch": 46, "training_loss": 364.3908996582031, "training_acc": 55.0, "val_loss": 1230.2220458984375, "val_acc": 40.0}
{"epoch": 47, "training_loss": 932.876708984375, "training_acc": 55.0, "val_loss": 271.24114990234375, "val_acc": 40.0}
{"epoch": 48, "training_loss": 487.2286682128906, "training_acc": 45.0, "val_loss": 405.4398193359375, "val_acc": 60.0}
{"epoch": 49, "training_loss": 284.23078002929685, "training_acc": 55.0, "val_loss": 177.66970825195312, "val_acc": 40.0}
{"epoch": 50, "training_loss": 256.4210174560547, "training_acc": 55.0, "val_loss": 73.94075775146484, "val_acc": 40.0}
{"epoch": 51, "training_loss": 104.25119171142578, "training_acc": 55.0, "val_loss": 110.5130386352539, "val_acc": 40.0}
{"epoch": 52, "training_loss": 86.08304748535156, "training_acc": 55.0, "val_loss": 29.311933517456055, "val_acc": 20.0}
{"epoch": 53, "training_loss": 201.24566860198973, "training_acc": 60.0, "val_loss": 279.3272399902344, "val_acc": 40.0}
{"epoch": 54, "training_loss": 291.2225708007812, "training_acc": 55.0, "val_loss": 256.8826599121094, "val_acc": 60.0}
{"epoch": 55, "training_loss": 276.4773712158203, "training_acc": 45.0, "val_loss": 91.14925384521484, "val_acc": 40.0}
{"epoch": 56, "training_loss": 285.72260131835935, "training_acc": 45.0, "val_loss": 229.32144165039062, "val_acc": 40.0}
{"epoch": 57, "training_loss": 354.2941040039062, "training_acc": 55.0, "val_loss": 224.86668395996094, "val_acc": 60.0}
{"epoch": 58, "training_loss": 499.0683654785156, "training_acc": 45.0, "val_loss": 481.2735290527344, "val_acc": 40.0}
{"epoch": 59, "training_loss": 658.1185302734375, "training_acc": 55.0, "val_loss": 735.90869140625, "val_acc": 40.0}
{"epoch": 60, "training_loss": 325.87804260253904, "training_acc": 45.0, "val_loss": 52.1825065612793, "val_acc": 40.0}
{"epoch": 61, "training_loss": 108.58567657470704, "training_acc": 45.0, "val_loss": 204.5735626220703, "val_acc": 40.0}
{"epoch": 62, "training_loss": 142.0821548461914, "training_acc": 55.0, "val_loss": 385.18463134765625, "val_acc": 40.0}
{"epoch": 63, "training_loss": 278.8446838378906, "training_acc": 45.0, "val_loss": 61.044097900390625, "val_acc": 60.0}
{"epoch": 64, "training_loss": 345.5858093261719, "training_acc": 55.0, "val_loss": 548.8062744140625, "val_acc": 40.0}
{"epoch": 65, "training_loss": 278.5265747070313, "training_acc": 55.0, "val_loss": 27.583662033081055, "val_acc": 20.0}
{"epoch": 66, "training_loss": 103.98995304107666, "training_acc": 70.0, "val_loss": 233.026611328125, "val_acc": 60.0}
{"epoch": 67, "training_loss": 184.80229539871215, "training_acc": 55.0, "val_loss": 327.52423095703125, "val_acc": 40.0}
{"epoch": 68, "training_loss": 106.87419147491455, "training_acc": 70.0, "val_loss": 230.9028778076172, "val_acc": 60.0}
{"epoch": 69, "training_loss": 98.1358856201172, "training_acc": 65.0, "val_loss": 1393.7423095703125, "val_acc": 40.0}
{"epoch": 70, "training_loss": 1142.8670776367187, "training_acc": 55.0, "val_loss": 783.42578125, "val_acc": 40.0}
{"epoch": 71, "training_loss": 623.0854248046875, "training_acc": 35.0, "val_loss": 232.2377471923828, "val_acc": 60.0}
{"epoch": 72, "training_loss": 323.4955200195312, "training_acc": 55.0, "val_loss": 730.3397827148438, "val_acc": 40.0}
{"epoch": 73, "training_loss": 364.589794921875, "training_acc": 55.0, "val_loss": 420.77716064453125, "val_acc": 60.0}
{"epoch": 74, "training_loss": 549.4274078369141, "training_acc": 45.0, "val_loss": 418.582275390625, "val_acc": 40.0}
{"epoch": 75, "training_loss": 186.52332305908203, "training_acc": 65.0, "val_loss": 212.7528076171875, "val_acc": 60.0}
{"epoch": 76, "training_loss": 141.06329040527345, "training_acc": 45.0, "val_loss": 415.0334167480469, "val_acc": 40.0}
{"epoch": 77, "training_loss": 345.3601928710938, "training_acc": 35.0, "val_loss": 291.673828125, "val_acc": 40.0}
{"epoch": 78, "training_loss": 237.3972595214844, "training_acc": 45.0, "val_loss": 105.6688003540039, "val_acc": 60.0}
{"epoch": 79, "training_loss": 592.9530883789063, "training_acc": 35.0, "val_loss": 712.1328125, "val_acc": 40.0}
{"epoch": 80, "training_loss": 303.8096880912781, "training_acc": 65.0, "val_loss": 211.34121704101562, "val_acc": 60.0}
{"epoch": 81, "training_loss": 266.1496215820313, "training_acc": 55.0, "val_loss": 446.33154296875, "val_acc": 40.0}
{"epoch": 82, "training_loss": 208.88484725952148, "training_acc": 35.0, "val_loss": 319.8919677734375, "val_acc": 60.0}
{"epoch": 83, "training_loss": 279.4556968688965, "training_acc": 55.0, "val_loss": 299.7982482910156, "val_acc": 40.0}
{"epoch": 84, "training_loss": 142.08326110839843, "training_acc": 45.0, "val_loss": 97.86477661132812, "val_acc": 40.0}
