"main_modify.py --pretrained_path None --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 2 --task ADNI_sex --input_option yAware --learning_rate 2e1 --batch_size 8 --weight_decay 4e-9 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 1273.746246957779, "training_acc": 60.0, "val_loss": 994.68017578125, "val_acc": 40.0}
{"epoch": 1, "training_loss": 1428.8822998046876, "training_acc": 50.0, "val_loss": 930.8946533203125, "val_acc": 40.0}
{"epoch": 2, "training_loss": 1022.843017578125, "training_acc": 40.0, "val_loss": 1003.2705078125, "val_acc": 60.0}
{"epoch": 3, "training_loss": 1159.4208740234376, "training_acc": 30.0, "val_loss": 556.1686401367188, "val_acc": 40.0}
{"epoch": 4, "training_loss": 231.46801300048827, "training_acc": 40.0, "val_loss": 333.39813232421875, "val_acc": 60.0}
{"epoch": 5, "training_loss": 434.6596313476563, "training_acc": 50.0, "val_loss": 703.6349487304688, "val_acc": 40.0}
{"epoch": 6, "training_loss": 899.227197265625, "training_acc": 50.0, "val_loss": 596.5626831054688, "val_acc": 40.0}
{"epoch": 7, "training_loss": 605.3841674804687, "training_acc": 40.0, "val_loss": 520.2859497070312, "val_acc": 60.0}
{"epoch": 8, "training_loss": 349.4232940673828, "training_acc": 60.0, "val_loss": 1008.1123046875, "val_acc": 40.0}
{"epoch": 9, "training_loss": 763.5982971191406, "training_acc": 50.0, "val_loss": 212.952392578125, "val_acc": 60.0}
{"epoch": 10, "training_loss": 383.35304565429686, "training_acc": 50.0, "val_loss": 461.37451171875, "val_acc": 40.0}
{"epoch": 11, "training_loss": 444.14686279296876, "training_acc": 50.0, "val_loss": 214.9512176513672, "val_acc": 60.0}
{"epoch": 12, "training_loss": 241.54358367919923, "training_acc": 50.0, "val_loss": 651.1588134765625, "val_acc": 40.0}
{"epoch": 13, "training_loss": 496.44629821777346, "training_acc": 50.0, "val_loss": 241.2489776611328, "val_acc": 60.0}
{"epoch": 14, "training_loss": 257.4766772404313, "training_acc": 60.0, "val_loss": 323.6125183105469, "val_acc": 40.0}
{"epoch": 15, "training_loss": 237.4431396484375, "training_acc": 50.0, "val_loss": 409.0509338378906, "val_acc": 60.0}
{"epoch": 16, "training_loss": 474.7324584960937, "training_acc": 40.0, "val_loss": 742.4076538085938, "val_acc": 40.0}
{"epoch": 17, "training_loss": 552.7216796875, "training_acc": 40.0, "val_loss": 462.60382080078125, "val_acc": 60.0}
{"epoch": 18, "training_loss": 530.9208435058594, "training_acc": 40.0, "val_loss": 844.3170166015625, "val_acc": 40.0}
{"epoch": 19, "training_loss": 418.00788536071775, "training_acc": 60.0, "val_loss": 298.4132385253906, "val_acc": 60.0}
{"epoch": 20, "training_loss": 294.98683471679686, "training_acc": 50.0, "val_loss": 411.4972839355469, "val_acc": 40.0}
{"epoch": 21, "training_loss": 128.10594177246094, "training_acc": 70.0, "val_loss": 744.1197509765625, "val_acc": 60.0}
{"epoch": 22, "training_loss": 879.8344116210938, "training_acc": 50.0, "val_loss": 161.66990661621094, "val_acc": 40.0}
{"epoch": 23, "training_loss": 403.30449829101565, "training_acc": 50.0, "val_loss": 247.6149139404297, "val_acc": 40.0}
{"epoch": 24, "training_loss": 512.4396850585938, "training_acc": 50.0, "val_loss": 522.3899536132812, "val_acc": 60.0}
{"epoch": 25, "training_loss": 349.51165771484375, "training_acc": 60.0, "val_loss": 1695.7496337890625, "val_acc": 40.0}
{"epoch": 26, "training_loss": 1509.94287109375, "training_acc": 50.0, "val_loss": 806.2164306640625, "val_acc": 40.0}
{"epoch": 27, "training_loss": 723.4587646484375, "training_acc": 50.0, "val_loss": 902.4130859375, "val_acc": 60.0}
{"epoch": 28, "training_loss": 747.9433506011962, "training_acc": 50.0, "val_loss": 1257.6055908203125, "val_acc": 40.0}
{"epoch": 29, "training_loss": 1276.4327880859375, "training_acc": 50.0, "val_loss": 1602.135009765625, "val_acc": 40.0}
{"epoch": 30, "training_loss": 976.0538879394531, "training_acc": 50.0, "val_loss": 570.5924682617188, "val_acc": 60.0}
{"epoch": 31, "training_loss": 779.8640502929687, "training_acc": 50.0, "val_loss": 447.4953308105469, "val_acc": 40.0}
{"epoch": 32, "training_loss": 571.0090484619141, "training_acc": 50.0, "val_loss": 60.6264533996582, "val_acc": 60.0}
{"epoch": 33, "training_loss": 41.7559736251831, "training_acc": 55.0, "val_loss": 272.5002136230469, "val_acc": 60.0}
{"epoch": 34, "training_loss": 246.42816779613494, "training_acc": 60.0, "val_loss": 641.18505859375, "val_acc": 40.0}
{"epoch": 35, "training_loss": 584.5731079101563, "training_acc": 50.0, "val_loss": 285.4389343261719, "val_acc": 60.0}
{"epoch": 36, "training_loss": 633.646484375, "training_acc": 50.0, "val_loss": 148.54318237304688, "val_acc": 60.0}
{"epoch": 37, "training_loss": 698.5442504882812, "training_acc": 40.0, "val_loss": 1250.6632080078125, "val_acc": 40.0}
{"epoch": 38, "training_loss": 602.0757720947265, "training_acc": 60.0, "val_loss": 503.8671875, "val_acc": 60.0}
{"epoch": 39, "training_loss": 496.86431579589845, "training_acc": 50.0, "val_loss": 725.6653442382812, "val_acc": 40.0}
{"epoch": 40, "training_loss": 570.8930847167969, "training_acc": 50.0, "val_loss": 55.105140686035156, "val_acc": 60.0}
{"epoch": 41, "training_loss": 136.44462051391602, "training_acc": 60.0, "val_loss": 291.6794738769531, "val_acc": 40.0}
{"epoch": 42, "training_loss": 220.91083374023438, "training_acc": 50.0, "val_loss": 686.40576171875, "val_acc": 60.0}
{"epoch": 43, "training_loss": 594.4430923461914, "training_acc": 50.0, "val_loss": 217.30862426757812, "val_acc": 40.0}
{"epoch": 44, "training_loss": 80.52798042297363, "training_acc": 60.0, "val_loss": 138.67767333984375, "val_acc": 60.0}
{"epoch": 45, "training_loss": 193.53967895507813, "training_acc": 50.0, "val_loss": 622.3074340820312, "val_acc": 40.0}
{"epoch": 46, "training_loss": 382.22789306640624, "training_acc": 50.0, "val_loss": 599.3428955078125, "val_acc": 60.0}
{"epoch": 47, "training_loss": 458.0664306640625, "training_acc": 50.0, "val_loss": 1217.7589111328125, "val_acc": 40.0}
{"epoch": 48, "training_loss": 1289.132421875, "training_acc": 50.0, "val_loss": 1793.4417724609375, "val_acc": 40.0}
{"epoch": 49, "training_loss": 946.008023071289, "training_acc": 50.0, "val_loss": 972.0617065429688, "val_acc": 60.0}
{"epoch": 50, "training_loss": 1863.924951171875, "training_acc": 50.0, "val_loss": 1755.5347900390625, "val_acc": 60.0}
{"epoch": 51, "training_loss": 1669.2433471679688, "training_acc": 50.0, "val_loss": 588.3632202148438, "val_acc": 40.0}
{"epoch": 52, "training_loss": 998.0089721679688, "training_acc": 50.0, "val_loss": 1410.7227783203125, "val_acc": 40.0}
{"epoch": 53, "training_loss": 823.92568359375, "training_acc": 50.0, "val_loss": 939.8771362304688, "val_acc": 60.0}
{"epoch": 54, "training_loss": 1139.794677734375, "training_acc": 50.0, "val_loss": 73.85997772216797, "val_acc": 60.0}
{"epoch": 55, "training_loss": 425.76743469238284, "training_acc": 60.0, "val_loss": 1150.822265625, "val_acc": 40.0}
{"epoch": 56, "training_loss": 588.2175140380859, "training_acc": 60.0, "val_loss": 641.4625854492188, "val_acc": 60.0}
{"epoch": 57, "training_loss": 802.912142944336, "training_acc": 50.0, "val_loss": 377.38861083984375, "val_acc": 40.0}
{"epoch": 58, "training_loss": 279.4072111129761, "training_acc": 45.0, "val_loss": 228.8875274658203, "val_acc": 60.0}
{"epoch": 59, "training_loss": 237.76060791015624, "training_acc": 50.0, "val_loss": 625.7213134765625, "val_acc": 40.0}
