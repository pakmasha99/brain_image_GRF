"main_modify.py --pretrained_path None --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_sex --input_option yAware --learning_rate 2e1 --batch_size 8 --weight_decay 4e-9 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 3397.180193901062, "training_acc": 45.0, "val_loss": 1147.4215087890625, "val_acc": 40.0}
{"epoch": 1, "training_loss": 1378.98115234375, "training_acc": 55.0, "val_loss": 1638.2298583984375, "val_acc": 40.0}
{"epoch": 2, "training_loss": 768.3501831054688, "training_acc": 35.0, "val_loss": 532.825439453125, "val_acc": 40.0}
{"epoch": 3, "training_loss": 375.37827758789064, "training_acc": 45.0, "val_loss": 184.54261779785156, "val_acc": 40.0}
{"epoch": 4, "training_loss": 261.9313598632813, "training_acc": 45.0, "val_loss": 387.8151550292969, "val_acc": 60.0}
{"epoch": 5, "training_loss": 553.4966064453125, "training_acc": 35.0, "val_loss": 115.9847640991211, "val_acc": 40.0}
{"epoch": 6, "training_loss": 610.0786926269532, "training_acc": 45.0, "val_loss": 516.7543334960938, "val_acc": 60.0}
{"epoch": 7, "training_loss": 676.4099975585938, "training_acc": 35.0, "val_loss": 523.0137329101562, "val_acc": 40.0}
{"epoch": 8, "training_loss": 165.4199203491211, "training_acc": 55.0, "val_loss": 290.8347473144531, "val_acc": 40.0}
{"epoch": 9, "training_loss": 181.73965454101562, "training_acc": 55.0, "val_loss": 110.19432830810547, "val_acc": 60.0}
{"epoch": 10, "training_loss": 223.474072265625, "training_acc": 55.0, "val_loss": 144.8289031982422, "val_acc": 40.0}
{"epoch": 11, "training_loss": 357.6438507080078, "training_acc": 55.0, "val_loss": 200.93955993652344, "val_acc": 60.0}
{"epoch": 12, "training_loss": 341.596923828125, "training_acc": 55.0, "val_loss": 1006.6635131835938, "val_acc": 40.0}
{"epoch": 13, "training_loss": 529.8133544921875, "training_acc": 55.0, "val_loss": 608.9396362304688, "val_acc": 60.0}
{"epoch": 14, "training_loss": 839.8183959960937, "training_acc": 45.0, "val_loss": 178.08460998535156, "val_acc": 60.0}
{"epoch": 15, "training_loss": 427.72520141601564, "training_acc": 55.0, "val_loss": 1338.2242431640625, "val_acc": 40.0}
{"epoch": 16, "training_loss": 789.3796234130859, "training_acc": 55.0, "val_loss": 516.4439086914062, "val_acc": 60.0}
{"epoch": 17, "training_loss": 788.1753601074219, "training_acc": 45.0, "val_loss": 31.223974227905273, "val_acc": 60.0}
{"epoch": 18, "training_loss": 863.6094696044922, "training_acc": 35.0, "val_loss": 1677.8406982421875, "val_acc": 40.0}
{"epoch": 19, "training_loss": 863.7718231201172, "training_acc": 55.0, "val_loss": 652.6876220703125, "val_acc": 60.0}
{"epoch": 20, "training_loss": 1458.764306640625, "training_acc": 45.0, "val_loss": 885.2593994140625, "val_acc": 60.0}
{"epoch": 21, "training_loss": 976.6766845703125, "training_acc": 35.0, "val_loss": 2076.663330078125, "val_acc": 40.0}
{"epoch": 22, "training_loss": 1673.8666381835938, "training_acc": 55.0, "val_loss": 1549.7860107421875, "val_acc": 40.0}
{"epoch": 23, "training_loss": 833.1128723144532, "training_acc": 55.0, "val_loss": 848.1633911132812, "val_acc": 60.0}
{"epoch": 24, "training_loss": 1045.8898193359375, "training_acc": 45.0, "val_loss": 230.3171844482422, "val_acc": 40.0}
{"epoch": 25, "training_loss": 581.5849212646484, "training_acc": 55.0, "val_loss": 271.16082763671875, "val_acc": 40.0}
{"epoch": 26, "training_loss": 344.3403656005859, "training_acc": 65.0, "val_loss": 741.0862426757812, "val_acc": 60.0}
{"epoch": 27, "training_loss": 709.2404479980469, "training_acc": 45.0, "val_loss": 688.0338134765625, "val_acc": 40.0}
{"epoch": 28, "training_loss": 559.7486572265625, "training_acc": 55.0, "val_loss": 378.689453125, "val_acc": 60.0}
{"epoch": 29, "training_loss": 609.8402160644531, "training_acc": 45.0, "val_loss": 102.38323211669922, "val_acc": 40.0}
{"epoch": 30, "training_loss": 173.7298969268799, "training_acc": 40.0, "val_loss": 131.66050720214844, "val_acc": 40.0}
{"epoch": 31, "training_loss": 225.47110748291016, "training_acc": 45.0, "val_loss": 206.1741485595703, "val_acc": 40.0}
{"epoch": 32, "training_loss": 149.9797576904297, "training_acc": 55.0, "val_loss": 324.8262939453125, "val_acc": 60.0}
{"epoch": 33, "training_loss": 435.1016357421875, "training_acc": 35.0, "val_loss": 1330.1409912109375, "val_acc": 40.0}
{"epoch": 34, "training_loss": 786.3468811035157, "training_acc": 55.0, "val_loss": 310.996337890625, "val_acc": 60.0}
{"epoch": 35, "training_loss": 707.5848388671875, "training_acc": 45.0, "val_loss": 15.570709228515625, "val_acc": 40.0}
{"epoch": 36, "training_loss": 434.57226181030273, "training_acc": 60.0, "val_loss": 1538.5679931640625, "val_acc": 40.0}
{"epoch": 37, "training_loss": 918.8622924804688, "training_acc": 55.0, "val_loss": 287.0379333496094, "val_acc": 60.0}
{"epoch": 38, "training_loss": 650.4456420898438, "training_acc": 45.0, "val_loss": 132.0789337158203, "val_acc": 60.0}
{"epoch": 39, "training_loss": 502.44524536132815, "training_acc": 45.0, "val_loss": 1194.13671875, "val_acc": 40.0}
{"epoch": 40, "training_loss": 545.8009185791016, "training_acc": 55.0, "val_loss": 753.3960571289062, "val_acc": 60.0}
{"epoch": 41, "training_loss": 1476.27626953125, "training_acc": 45.0, "val_loss": 811.6240234375, "val_acc": 60.0}
{"epoch": 42, "training_loss": 702.8455627441406, "training_acc": 45.0, "val_loss": 2027.8280029296875, "val_acc": 40.0}
{"epoch": 43, "training_loss": 1605.3687744140625, "training_acc": 55.0, "val_loss": 1639.686767578125, "val_acc": 40.0}
{"epoch": 44, "training_loss": 1099.0056884765625, "training_acc": 45.0, "val_loss": 935.15625, "val_acc": 60.0}
{"epoch": 45, "training_loss": 1074.301953125, "training_acc": 45.0, "val_loss": 384.93951416015625, "val_acc": 40.0}
{"epoch": 46, "training_loss": 672.86142578125, "training_acc": 55.0, "val_loss": 842.9308471679688, "val_acc": 40.0}
{"epoch": 47, "training_loss": 385.81676788330077, "training_acc": 45.0, "val_loss": 15.326056480407715, "val_acc": 40.0}
{"epoch": 48, "training_loss": 166.83060302734376, "training_acc": 65.0, "val_loss": 124.37153625488281, "val_acc": 60.0}
{"epoch": 49, "training_loss": 121.52429885864258, "training_acc": 50.0, "val_loss": 987.7149658203125, "val_acc": 40.0}
{"epoch": 50, "training_loss": 884.3146728515625, "training_acc": 55.0, "val_loss": 994.6685791015625, "val_acc": 40.0}
{"epoch": 51, "training_loss": 582.2358032226563, "training_acc": 45.0, "val_loss": 780.390625, "val_acc": 60.0}
{"epoch": 52, "training_loss": 798.966943359375, "training_acc": 45.0, "val_loss": 888.6578979492188, "val_acc": 40.0}
{"epoch": 53, "training_loss": 1150.9774169921875, "training_acc": 55.0, "val_loss": 1953.5726318359375, "val_acc": 40.0}
{"epoch": 54, "training_loss": 1048.0670593261718, "training_acc": 55.0, "val_loss": 649.8064575195312, "val_acc": 60.0}
{"epoch": 55, "training_loss": 1303.62822265625, "training_acc": 45.0, "val_loss": 817.75634765625, "val_acc": 60.0}
{"epoch": 56, "training_loss": 530.6162109375, "training_acc": 55.0, "val_loss": 2029.434814453125, "val_acc": 40.0}
{"epoch": 57, "training_loss": 1766.5341552734376, "training_acc": 55.0, "val_loss": 2156.99609375, "val_acc": 40.0}
{"epoch": 58, "training_loss": 1098.5457397460937, "training_acc": 55.0, "val_loss": 657.4260864257812, "val_acc": 60.0}
{"epoch": 59, "training_loss": 1189.55380859375, "training_acc": 45.0, "val_loss": 916.8510131835938, "val_acc": 60.0}
{"epoch": 60, "training_loss": 939.6463623046875, "training_acc": 35.0, "val_loss": 1671.085205078125, "val_acc": 40.0}
{"epoch": 61, "training_loss": 1232.482373046875, "training_acc": 55.0, "val_loss": 824.6580200195312, "val_acc": 40.0}
{"epoch": 62, "training_loss": 655.3786865234375, "training_acc": 35.0, "val_loss": 455.6293029785156, "val_acc": 60.0}
{"epoch": 63, "training_loss": 319.5957576751709, "training_acc": 50.0, "val_loss": 73.29647064208984, "val_acc": 40.0}
{"epoch": 64, "training_loss": 293.5261825561523, "training_acc": 55.0, "val_loss": 51.24658203125, "val_acc": 60.0}
{"epoch": 65, "training_loss": 392.0918197631836, "training_acc": 55.0, "val_loss": 1496.276611328125, "val_acc": 40.0}
{"epoch": 66, "training_loss": 1006.57685546875, "training_acc": 55.0, "val_loss": 175.48876953125, "val_acc": 60.0}
