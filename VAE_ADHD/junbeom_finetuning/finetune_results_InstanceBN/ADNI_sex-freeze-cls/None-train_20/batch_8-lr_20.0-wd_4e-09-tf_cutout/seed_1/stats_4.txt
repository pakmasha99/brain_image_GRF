"main_modify.py --pretrained_path None --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 1 --task ADNI_sex --input_option yAware --learning_rate 2e1 --batch_size 8 --weight_decay 4e-9 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 2315.3736474752427, "training_acc": 50.0, "val_loss": 1519.643798828125, "val_acc": 40.0}
{"epoch": 1, "training_loss": 1710.361083984375, "training_acc": 50.0, "val_loss": 337.3255920410156, "val_acc": 60.0}
{"epoch": 2, "training_loss": 694.3196044921875, "training_acc": 50.0, "val_loss": 702.3567504882812, "val_acc": 40.0}
{"epoch": 3, "training_loss": 467.99644775390624, "training_acc": 50.0, "val_loss": 328.1117858886719, "val_acc": 60.0}
{"epoch": 4, "training_loss": 258.65552978515626, "training_acc": 40.0, "val_loss": 715.3768920898438, "val_acc": 40.0}
{"epoch": 5, "training_loss": 457.8023742675781, "training_acc": 50.0, "val_loss": 676.4703369140625, "val_acc": 60.0}
{"epoch": 6, "training_loss": 1261.3201171875, "training_acc": 50.0, "val_loss": 418.1459655761719, "val_acc": 60.0}
{"epoch": 7, "training_loss": 966.70009765625, "training_acc": 40.0, "val_loss": 1589.794921875, "val_acc": 40.0}
{"epoch": 8, "training_loss": 905.7987899780273, "training_acc": 50.0, "val_loss": 360.2892150878906, "val_acc": 60.0}
{"epoch": 9, "training_loss": 350.1994689941406, "training_acc": 50.0, "val_loss": 400.6185302734375, "val_acc": 40.0}
{"epoch": 10, "training_loss": 183.79682464599608, "training_acc": 60.0, "val_loss": 801.6973876953125, "val_acc": 60.0}
{"epoch": 11, "training_loss": 783.571337890625, "training_acc": 50.0, "val_loss": 675.7619018554688, "val_acc": 40.0}
{"epoch": 12, "training_loss": 806.48984375, "training_acc": 50.0, "val_loss": 643.2756958007812, "val_acc": 40.0}
{"epoch": 13, "training_loss": 333.10145874023436, "training_acc": 50.0, "val_loss": 1260.1004638671875, "val_acc": 60.0}
{"epoch": 14, "training_loss": 1732.06162109375, "training_acc": 50.0, "val_loss": 619.2534790039062, "val_acc": 60.0}
{"epoch": 15, "training_loss": 765.37041015625, "training_acc": 40.0, "val_loss": 1202.31884765625, "val_acc": 40.0}
{"epoch": 16, "training_loss": 682.9861328125, "training_acc": 50.0, "val_loss": 736.7384033203125, "val_acc": 60.0}
{"epoch": 17, "training_loss": 1361.4291015625, "training_acc": 50.0, "val_loss": 1425.4158935546875, "val_acc": 60.0}
{"epoch": 18, "training_loss": 1557.25712890625, "training_acc": 50.0, "val_loss": 437.2113342285156, "val_acc": 40.0}
{"epoch": 19, "training_loss": 783.8613647460937, "training_acc": 50.0, "val_loss": 310.6805419921875, "val_acc": 40.0}
{"epoch": 20, "training_loss": 553.9003540039063, "training_acc": 50.0, "val_loss": 943.6585083007812, "val_acc": 60.0}
{"epoch": 21, "training_loss": 925.2748031616211, "training_acc": 40.0, "val_loss": 116.85725402832031, "val_acc": 40.0}
{"epoch": 22, "training_loss": 125.62505645751953, "training_acc": 50.0, "val_loss": 252.1179962158203, "val_acc": 60.0}
{"epoch": 23, "training_loss": 308.2977600097656, "training_acc": 50.0, "val_loss": 674.94091796875, "val_acc": 40.0}
{"epoch": 24, "training_loss": 643.8770629882813, "training_acc": 50.0, "val_loss": 203.4023895263672, "val_acc": 40.0}
{"epoch": 25, "training_loss": 680.7495239257812, "training_acc": 40.0, "val_loss": 818.5587158203125, "val_acc": 60.0}
{"epoch": 26, "training_loss": 680.7623718261718, "training_acc": 50.0, "val_loss": 696.5839233398438, "val_acc": 40.0}
{"epoch": 27, "training_loss": 490.2163146972656, "training_acc": 50.0, "val_loss": 574.8466796875, "val_acc": 60.0}
{"epoch": 28, "training_loss": 908.5729125976562, "training_acc": 50.0, "val_loss": 433.6139831542969, "val_acc": 60.0}
{"epoch": 29, "training_loss": 113.81418304443359, "training_acc": 70.0, "val_loss": 1944.1380615234375, "val_acc": 40.0}
{"epoch": 30, "training_loss": 1701.1120727539062, "training_acc": 50.0, "val_loss": 1461.7581787109375, "val_acc": 40.0}
{"epoch": 31, "training_loss": 993.6838623046875, "training_acc": 40.0, "val_loss": 997.5362548828125, "val_acc": 60.0}
{"epoch": 32, "training_loss": 1165.6118041992188, "training_acc": 50.0, "val_loss": 86.8321304321289, "val_acc": 60.0}
{"epoch": 33, "training_loss": 906.6626586914062, "training_acc": 40.0, "val_loss": 2067.93359375, "val_acc": 40.0}
{"epoch": 34, "training_loss": 1407.5510498046874, "training_acc": 50.0, "val_loss": 201.78489685058594, "val_acc": 60.0}
{"epoch": 35, "training_loss": 461.32349853515626, "training_acc": 50.0, "val_loss": 305.52276611328125, "val_acc": 60.0}
{"epoch": 36, "training_loss": 577.8633666992188, "training_acc": 40.0, "val_loss": 527.23388671875, "val_acc": 40.0}
{"epoch": 37, "training_loss": 237.9659881591797, "training_acc": 60.0, "val_loss": 116.718017578125, "val_acc": 60.0}
{"epoch": 38, "training_loss": 340.6835144042969, "training_acc": 50.0, "val_loss": 324.1376953125, "val_acc": 40.0}
{"epoch": 39, "training_loss": 314.2428771972656, "training_acc": 60.0, "val_loss": 211.7371368408203, "val_acc": 60.0}
{"epoch": 40, "training_loss": 543.6464599609375, "training_acc": 40.0, "val_loss": 641.8488159179688, "val_acc": 40.0}
{"epoch": 41, "training_loss": 353.2416748046875, "training_acc": 50.0, "val_loss": 995.94873046875, "val_acc": 60.0}
{"epoch": 42, "training_loss": 1143.3222045898438, "training_acc": 50.0, "val_loss": 27.983280181884766, "val_acc": 60.0}
{"epoch": 43, "training_loss": 839.7059181213378, "training_acc": 50.0, "val_loss": 1703.6258544921875, "val_acc": 40.0}
{"epoch": 44, "training_loss": 802.3276794433593, "training_acc": 50.0, "val_loss": 969.0281372070312, "val_acc": 60.0}
{"epoch": 45, "training_loss": 1759.4695068359374, "training_acc": 50.0, "val_loss": 1926.8695068359375, "val_acc": 60.0}
{"epoch": 46, "training_loss": 2026.9343811035155, "training_acc": 50.0, "val_loss": 303.4458312988281, "val_acc": 40.0}
{"epoch": 47, "training_loss": 593.1285827636718, "training_acc": 50.0, "val_loss": 671.4317626953125, "val_acc": 40.0}
{"epoch": 48, "training_loss": 189.5793727874756, "training_acc": 60.0, "val_loss": 108.31404113769531, "val_acc": 60.0}
{"epoch": 49, "training_loss": 22.8291996717453, "training_acc": 80.0, "val_loss": 265.4488220214844, "val_acc": 60.0}
{"epoch": 50, "training_loss": 430.9082885742188, "training_acc": 30.0, "val_loss": 318.2008972167969, "val_acc": 40.0}
{"epoch": 51, "training_loss": 793.1104248046875, "training_acc": 20.0, "val_loss": 326.79925537109375, "val_acc": 60.0}
{"epoch": 52, "training_loss": 382.8129028320312, "training_acc": 50.0, "val_loss": 620.0296020507812, "val_acc": 40.0}
{"epoch": 53, "training_loss": 376.81556701660156, "training_acc": 50.0, "val_loss": 764.9971313476562, "val_acc": 60.0}
{"epoch": 54, "training_loss": 834.231005859375, "training_acc": 50.0, "val_loss": 702.8012084960938, "val_acc": 40.0}
{"epoch": 55, "training_loss": 655.3615173339844, "training_acc": 50.0, "val_loss": 67.7964096069336, "val_acc": 60.0}
{"epoch": 56, "training_loss": 123.71120910644531, "training_acc": 50.0, "val_loss": 130.01300048828125, "val_acc": 40.0}
{"epoch": 57, "training_loss": 255.55440673828124, "training_acc": 50.0, "val_loss": 35.42684555053711, "val_acc": 60.0}
{"epoch": 58, "training_loss": 301.34751892089844, "training_acc": 50.0, "val_loss": 303.4386901855469, "val_acc": 40.0}
{"epoch": 59, "training_loss": 567.9586669921875, "training_acc": 30.0, "val_loss": 285.9573669433594, "val_acc": 60.0}
{"epoch": 60, "training_loss": 442.18125, "training_acc": 40.0, "val_loss": 99.41263580322266, "val_acc": 40.0}
{"epoch": 61, "training_loss": 452.6933197021484, "training_acc": 50.0, "val_loss": 682.100341796875, "val_acc": 60.0}
