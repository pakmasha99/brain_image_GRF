"main_modify.py --pretrained_path None --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 4 --task ADNI_sex --input_option yAware --learning_rate 4e1 --batch_size 8 --weight_decay 1e-9 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 3967.6790499210356, "training_acc": 50.0, "val_loss": 5258.0244140625, "val_acc": 40.0}
{"epoch": 1, "training_loss": 7268.677734375, "training_acc": 50.0, "val_loss": 5511.04248046875, "val_acc": 40.0}
{"epoch": 2, "training_loss": 1652.213720703125, "training_acc": 60.0, "val_loss": 5069.62109375, "val_acc": 60.0}
{"epoch": 3, "training_loss": 6620.96025390625, "training_acc": 50.0, "val_loss": 4684.4677734375, "val_acc": 60.0}
{"epoch": 4, "training_loss": 3840.087939453125, "training_acc": 50.0, "val_loss": 3712.504638671875, "val_acc": 40.0}
{"epoch": 5, "training_loss": 4722.54658203125, "training_acc": 50.0, "val_loss": 7823.0126953125, "val_acc": 40.0}
{"epoch": 6, "training_loss": 5728.854174804687, "training_acc": 50.0, "val_loss": 1466.944091796875, "val_acc": 40.0}
{"epoch": 7, "training_loss": 1495.97275390625, "training_acc": 60.0, "val_loss": 3198.63134765625, "val_acc": 60.0}
{"epoch": 8, "training_loss": 3928.628125, "training_acc": 50.0, "val_loss": 618.6475830078125, "val_acc": 60.0}
{"epoch": 9, "training_loss": 1266.2904296875, "training_acc": 60.0, "val_loss": 3008.36181640625, "val_acc": 40.0}
{"epoch": 10, "training_loss": 1656.7613189697265, "training_acc": 50.0, "val_loss": 747.3285522460938, "val_acc": 60.0}
{"epoch": 11, "training_loss": 726.2697631835938, "training_acc": 50.0, "val_loss": 594.12255859375, "val_acc": 40.0}
{"epoch": 12, "training_loss": 364.4551239013672, "training_acc": 40.0, "val_loss": 645.9931640625, "val_acc": 60.0}
{"epoch": 13, "training_loss": 599.2013610839844, "training_acc": 50.0, "val_loss": 2008.802734375, "val_acc": 40.0}
{"epoch": 14, "training_loss": 1953.203076171875, "training_acc": 50.0, "val_loss": 1531.855224609375, "val_acc": 40.0}
{"epoch": 15, "training_loss": 508.77232666015624, "training_acc": 60.0, "val_loss": 508.9338073730469, "val_acc": 60.0}
{"epoch": 16, "training_loss": 473.6915915727615, "training_acc": 60.0, "val_loss": 642.7929077148438, "val_acc": 40.0}
{"epoch": 17, "training_loss": 664.8444946289062, "training_acc": 50.0, "val_loss": 244.00735473632812, "val_acc": 60.0}
{"epoch": 18, "training_loss": 1540.9913208007813, "training_acc": 30.0, "val_loss": 1620.958740234375, "val_acc": 40.0}
{"epoch": 19, "training_loss": 860.6812530517578, "training_acc": 50.0, "val_loss": 2552.787841796875, "val_acc": 60.0}
{"epoch": 20, "training_loss": 3166.00244140625, "training_acc": 50.0, "val_loss": 1058.009033203125, "val_acc": 60.0}
{"epoch": 21, "training_loss": 1701.0598388671874, "training_acc": 40.0, "val_loss": 2504.98583984375, "val_acc": 40.0}
{"epoch": 22, "training_loss": 1182.4240188598633, "training_acc": 60.0, "val_loss": 789.71533203125, "val_acc": 60.0}
{"epoch": 23, "training_loss": 737.4111389160156, "training_acc": 50.0, "val_loss": 101.97753143310547, "val_acc": 40.0}
{"epoch": 24, "training_loss": 529.499658203125, "training_acc": 50.0, "val_loss": 28.018680572509766, "val_acc": 60.0}
{"epoch": 25, "training_loss": 493.97222290039065, "training_acc": 75.0, "val_loss": 1325.86328125, "val_acc": 40.0}
{"epoch": 26, "training_loss": 766.02353515625, "training_acc": 40.0, "val_loss": 216.22618103027344, "val_acc": 40.0}
{"epoch": 27, "training_loss": 418.5687561035156, "training_acc": 30.0, "val_loss": 53.833839416503906, "val_acc": 60.0}
{"epoch": 28, "training_loss": 161.3147735595703, "training_acc": 60.0, "val_loss": 793.2890625, "val_acc": 60.0}
{"epoch": 29, "training_loss": 1105.4324035644531, "training_acc": 50.0, "val_loss": 556.7772827148438, "val_acc": 40.0}
{"epoch": 30, "training_loss": 550.7764770507813, "training_acc": 50.0, "val_loss": 1101.243408203125, "val_acc": 60.0}
{"epoch": 31, "training_loss": 1576.57119140625, "training_acc": 50.0, "val_loss": 581.7660522460938, "val_acc": 60.0}
{"epoch": 32, "training_loss": 1942.41591796875, "training_acc": 30.0, "val_loss": 2117.872802734375, "val_acc": 40.0}
{"epoch": 33, "training_loss": 1183.3500244140625, "training_acc": 50.0, "val_loss": 2183.192138671875, "val_acc": 60.0}
{"epoch": 34, "training_loss": 2814.805078125, "training_acc": 50.0, "val_loss": 752.9714965820312, "val_acc": 60.0}
{"epoch": 35, "training_loss": 712.1468627929687, "training_acc": 70.0, "val_loss": 2503.823486328125, "val_acc": 40.0}
{"epoch": 36, "training_loss": 1437.285220336914, "training_acc": 50.0, "val_loss": 396.2377014160156, "val_acc": 60.0}
{"epoch": 37, "training_loss": 289.9115577697754, "training_acc": 65.0, "val_loss": 1505.344970703125, "val_acc": 40.0}
{"epoch": 38, "training_loss": 869.3713012695313, "training_acc": 50.0, "val_loss": 1619.4730224609375, "val_acc": 60.0}
{"epoch": 39, "training_loss": 3261.975341796875, "training_acc": 50.0, "val_loss": 2752.07421875, "val_acc": 60.0}
{"epoch": 40, "training_loss": 2572.2830322265627, "training_acc": 40.0, "val_loss": 1578.5107421875, "val_acc": 40.0}
{"epoch": 41, "training_loss": 1242.7709106445313, "training_acc": 30.0, "val_loss": 397.3809509277344, "val_acc": 40.0}
{"epoch": 42, "training_loss": 244.8854835510254, "training_acc": 50.0, "val_loss": 25.24735450744629, "val_acc": 60.0}
{"epoch": 43, "training_loss": 230.154305267334, "training_acc": 55.0, "val_loss": 838.3875122070312, "val_acc": 60.0}
{"epoch": 44, "training_loss": 1367.926611328125, "training_acc": 50.0, "val_loss": 6.470306396484375, "val_acc": 60.0}
{"epoch": 45, "training_loss": 1093.438611984253, "training_acc": 55.0, "val_loss": 1569.9267578125, "val_acc": 40.0}
{"epoch": 46, "training_loss": 788.5591674804688, "training_acc": 40.0, "val_loss": 110.56682586669922, "val_acc": 40.0}
{"epoch": 47, "training_loss": 231.38098754882813, "training_acc": 40.0, "val_loss": 1658.33203125, "val_acc": 40.0}
{"epoch": 48, "training_loss": 2087.273876953125, "training_acc": 50.0, "val_loss": 1026.9071044921875, "val_acc": 40.0}
{"epoch": 49, "training_loss": 2040.25712890625, "training_acc": 30.0, "val_loss": 1995.337158203125, "val_acc": 60.0}
{"epoch": 50, "training_loss": 1833.614892578125, "training_acc": 40.0, "val_loss": 827.0616455078125, "val_acc": 40.0}
{"epoch": 51, "training_loss": 564.7344360351562, "training_acc": 50.0, "val_loss": 945.76171875, "val_acc": 60.0}
{"epoch": 52, "training_loss": 835.2435302734375, "training_acc": 50.0, "val_loss": 1366.175537109375, "val_acc": 40.0}
{"epoch": 53, "training_loss": 990.5787460327149, "training_acc": 50.0, "val_loss": 932.8831176757812, "val_acc": 60.0}
{"epoch": 54, "training_loss": 681.5332397460937, "training_acc": 60.0, "val_loss": 1410.1522216796875, "val_acc": 40.0}
{"epoch": 55, "training_loss": 907.1537719726563, "training_acc": 50.0, "val_loss": 1260.546875, "val_acc": 60.0}
{"epoch": 56, "training_loss": 2122.892333984375, "training_acc": 50.0, "val_loss": 1457.6693115234375, "val_acc": 60.0}
{"epoch": 57, "training_loss": 887.746240234375, "training_acc": 60.0, "val_loss": 3237.802490234375, "val_acc": 40.0}
{"epoch": 58, "training_loss": 3104.629248046875, "training_acc": 50.0, "val_loss": 1984.1390380859375, "val_acc": 40.0}
{"epoch": 59, "training_loss": 1241.110302734375, "training_acc": 50.0, "val_loss": 1705.9078369140625, "val_acc": 60.0}
{"epoch": 60, "training_loss": 1669.1401000976562, "training_acc": 40.0, "val_loss": 278.9111022949219, "val_acc": 40.0}
{"epoch": 61, "training_loss": 336.83179931640626, "training_acc": 50.0, "val_loss": 682.2584228515625, "val_acc": 40.0}
{"epoch": 62, "training_loss": 487.8749237060547, "training_acc": 50.0, "val_loss": 28.580469131469727, "val_acc": 60.0}
{"epoch": 63, "training_loss": 307.18273124694826, "training_acc": 60.0, "val_loss": 126.24176025390625, "val_acc": 60.0}
