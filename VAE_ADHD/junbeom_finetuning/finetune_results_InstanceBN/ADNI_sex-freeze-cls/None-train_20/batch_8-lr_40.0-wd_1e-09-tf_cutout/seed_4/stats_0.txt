"main_modify.py --pretrained_path None --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 4 --task ADNI_sex --input_option yAware --learning_rate 4e1 --batch_size 8 --weight_decay 1e-9 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 5982.575070357323, "training_acc": 50.0, "val_loss": 2038.0296630859375, "val_acc": 40.0}
{"epoch": 1, "training_loss": 3390.7736328125, "training_acc": 50.0, "val_loss": 1703.829345703125, "val_acc": 40.0}
{"epoch": 2, "training_loss": 1150.4485107421874, "training_acc": 60.0, "val_loss": 1571.9510498046875, "val_acc": 60.0}
{"epoch": 3, "training_loss": 1244.276919555664, "training_acc": 30.0, "val_loss": 1045.2008056640625, "val_acc": 60.0}
{"epoch": 4, "training_loss": 1329.8359375, "training_acc": 50.0, "val_loss": 1065.2816162109375, "val_acc": 40.0}
{"epoch": 5, "training_loss": 1302.74072265625, "training_acc": 50.0, "val_loss": 766.2418823242188, "val_acc": 40.0}
{"epoch": 6, "training_loss": 533.9705688476563, "training_acc": 70.0, "val_loss": 1354.2388916015625, "val_acc": 60.0}
{"epoch": 7, "training_loss": 1377.89892578125, "training_acc": 40.0, "val_loss": 998.8445434570312, "val_acc": 40.0}
{"epoch": 8, "training_loss": 500.56318359375, "training_acc": 60.0, "val_loss": 1111.3001708984375, "val_acc": 60.0}
{"epoch": 9, "training_loss": 1221.6787265777589, "training_acc": 50.0, "val_loss": 1821.718017578125, "val_acc": 40.0}
{"epoch": 10, "training_loss": 1806.936328125, "training_acc": 50.0, "val_loss": 839.7906494140625, "val_acc": 40.0}
{"epoch": 11, "training_loss": 1250.313232421875, "training_acc": 50.0, "val_loss": 1453.0101318359375, "val_acc": 60.0}
{"epoch": 12, "training_loss": 1176.368310546875, "training_acc": 50.0, "val_loss": 2115.12890625, "val_acc": 40.0}
{"epoch": 13, "training_loss": 1647.875341796875, "training_acc": 50.0, "val_loss": 501.82427978515625, "val_acc": 60.0}
{"epoch": 14, "training_loss": 1110.100634765625, "training_acc": 50.0, "val_loss": 442.6293029785156, "val_acc": 60.0}
{"epoch": 15, "training_loss": 708.1076904296875, "training_acc": 60.0, "val_loss": 1486.596435546875, "val_acc": 40.0}
{"epoch": 16, "training_loss": 844.523193359375, "training_acc": 50.0, "val_loss": 1575.1912841796875, "val_acc": 60.0}
{"epoch": 17, "training_loss": 1982.2244140625, "training_acc": 50.0, "val_loss": 429.3039245605469, "val_acc": 40.0}
{"epoch": 18, "training_loss": 994.3942138671875, "training_acc": 50.0, "val_loss": 1150.6610107421875, "val_acc": 40.0}
{"epoch": 19, "training_loss": 451.2790809631348, "training_acc": 60.0, "val_loss": 267.7503662109375, "val_acc": 40.0}
{"epoch": 20, "training_loss": 183.76567993164062, "training_acc": 50.0, "val_loss": 583.9881591796875, "val_acc": 40.0}
{"epoch": 21, "training_loss": 318.10870971679685, "training_acc": 50.0, "val_loss": 959.1456298828125, "val_acc": 40.0}
{"epoch": 22, "training_loss": 792.6188232421875, "training_acc": 50.0, "val_loss": 1059.0797119140625, "val_acc": 60.0}
{"epoch": 23, "training_loss": 1590.4997802734374, "training_acc": 50.0, "val_loss": 415.8864440917969, "val_acc": 60.0}
{"epoch": 24, "training_loss": 749.9397705078125, "training_acc": 60.0, "val_loss": 2199.474365234375, "val_acc": 40.0}
{"epoch": 25, "training_loss": 1003.3366638183594, "training_acc": 70.0, "val_loss": 804.8300170898438, "val_acc": 60.0}
{"epoch": 26, "training_loss": 1048.8081787109375, "training_acc": 30.0, "val_loss": 98.29985809326172, "val_acc": 60.0}
{"epoch": 27, "training_loss": 180.41053771972656, "training_acc": 50.0, "val_loss": 28.940933227539062, "val_acc": 40.0}
{"epoch": 28, "training_loss": 212.888916015625, "training_acc": 50.0, "val_loss": 1218.3720703125, "val_acc": 40.0}
{"epoch": 29, "training_loss": 928.5794372558594, "training_acc": 50.0, "val_loss": 745.8352661132812, "val_acc": 60.0}
{"epoch": 30, "training_loss": 1059.9458740234375, "training_acc": 50.0, "val_loss": 875.5294799804688, "val_acc": 40.0}
{"epoch": 31, "training_loss": 899.6859008789063, "training_acc": 50.0, "val_loss": 32.1477165222168, "val_acc": 60.0}
{"epoch": 32, "training_loss": 208.0036834716797, "training_acc": 45.0, "val_loss": 689.9413452148438, "val_acc": 60.0}
{"epoch": 33, "training_loss": 453.5445983886719, "training_acc": 60.0, "val_loss": 2311.54638671875, "val_acc": 40.0}
{"epoch": 34, "training_loss": 1686.7472412109375, "training_acc": 50.0, "val_loss": 557.271240234375, "val_acc": 60.0}
{"epoch": 35, "training_loss": 847.9210205078125, "training_acc": 50.0, "val_loss": 135.88328552246094, "val_acc": 40.0}
{"epoch": 36, "training_loss": 226.65848388671876, "training_acc": 50.0, "val_loss": 298.745361328125, "val_acc": 60.0}
{"epoch": 37, "training_loss": 493.90107421875, "training_acc": 50.0, "val_loss": 76.89444732666016, "val_acc": 60.0}
{"epoch": 38, "training_loss": 405.56007690429686, "training_acc": 30.0, "val_loss": 760.8855590820312, "val_acc": 40.0}
{"epoch": 39, "training_loss": 670.7165893554687, "training_acc": 40.0, "val_loss": 51.97620391845703, "val_acc": 40.0}
{"epoch": 40, "training_loss": 185.6619445800781, "training_acc": 50.0, "val_loss": 362.63555908203125, "val_acc": 60.0}
{"epoch": 41, "training_loss": 216.38169784545897, "training_acc": 70.0, "val_loss": 1074.581298828125, "val_acc": 40.0}
{"epoch": 42, "training_loss": 879.1980712890625, "training_acc": 40.0, "val_loss": 564.3053588867188, "val_acc": 60.0}
{"epoch": 43, "training_loss": 504.1362640380859, "training_acc": 40.0, "val_loss": 610.0696411132812, "val_acc": 60.0}
{"epoch": 44, "training_loss": 597.0538188934327, "training_acc": 50.0, "val_loss": 69.24129486083984, "val_acc": 60.0}
{"epoch": 45, "training_loss": 81.81417388916016, "training_acc": 70.0, "val_loss": 635.2627563476562, "val_acc": 60.0}
{"epoch": 46, "training_loss": 585.80087890625, "training_acc": 50.0, "val_loss": 89.2129135131836, "val_acc": 40.0}
