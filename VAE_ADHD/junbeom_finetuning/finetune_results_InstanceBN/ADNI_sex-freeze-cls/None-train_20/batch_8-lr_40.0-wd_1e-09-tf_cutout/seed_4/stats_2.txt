"main_modify.py --pretrained_path None --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 4 --task ADNI_sex --input_option yAware --learning_rate 4e1 --batch_size 8 --weight_decay 1e-9 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 3431.8237438678743, "training_acc": 50.0, "val_loss": 4862.17041015625, "val_acc": 40.0}
{"epoch": 1, "training_loss": 4329.82666015625, "training_acc": 50.0, "val_loss": 3109.3701171875, "val_acc": 40.0}
{"epoch": 2, "training_loss": 839.187296295166, "training_acc": 60.0, "val_loss": 254.22207641601562, "val_acc": 60.0}
{"epoch": 3, "training_loss": 567.5093566894532, "training_acc": 60.0, "val_loss": 123.58680725097656, "val_acc": 60.0}
{"epoch": 4, "training_loss": 586.6647094726562, "training_acc": 30.0, "val_loss": 397.166748046875, "val_acc": 40.0}
{"epoch": 5, "training_loss": 393.47844848632815, "training_acc": 40.0, "val_loss": 32.39439010620117, "val_acc": 60.0}
{"epoch": 6, "training_loss": 120.54866790771484, "training_acc": 60.0, "val_loss": 689.5682983398438, "val_acc": 40.0}
{"epoch": 7, "training_loss": 746.4445190429688, "training_acc": 40.0, "val_loss": 860.1041870117188, "val_acc": 60.0}
{"epoch": 8, "training_loss": 1004.0677734375, "training_acc": 40.0, "val_loss": 2239.759765625, "val_acc": 40.0}
{"epoch": 9, "training_loss": 1542.930810546875, "training_acc": 40.0, "val_loss": 376.4785461425781, "val_acc": 60.0}
{"epoch": 10, "training_loss": 502.1942657470703, "training_acc": 50.0, "val_loss": 2185.82080078125, "val_acc": 40.0}
{"epoch": 11, "training_loss": 1565.964697265625, "training_acc": 50.0, "val_loss": 820.82666015625, "val_acc": 60.0}
{"epoch": 12, "training_loss": 1679.8521484375, "training_acc": 50.0, "val_loss": 783.3275756835938, "val_acc": 60.0}
{"epoch": 13, "training_loss": 554.6555603027343, "training_acc": 60.0, "val_loss": 1121.0458984375, "val_acc": 40.0}
{"epoch": 14, "training_loss": 714.6982177734375, "training_acc": 50.0, "val_loss": 1249.94482421875, "val_acc": 60.0}
{"epoch": 15, "training_loss": 1116.6548934936523, "training_acc": 50.0, "val_loss": 2001.7572021484375, "val_acc": 40.0}
{"epoch": 16, "training_loss": 1791.44697265625, "training_acc": 50.0, "val_loss": 1274.8865966796875, "val_acc": 40.0}
{"epoch": 17, "training_loss": 1147.9562744140626, "training_acc": 40.0, "val_loss": 851.9935913085938, "val_acc": 60.0}
{"epoch": 18, "training_loss": 773.5377975463867, "training_acc": 50.0, "val_loss": 2910.563232421875, "val_acc": 40.0}
{"epoch": 19, "training_loss": 2241.818884277344, "training_acc": 50.0, "val_loss": 157.6405487060547, "val_acc": 60.0}
{"epoch": 20, "training_loss": 388.6116455078125, "training_acc": 50.0, "val_loss": 1060.2884521484375, "val_acc": 40.0}
{"epoch": 21, "training_loss": 1067.8109130859375, "training_acc": 50.0, "val_loss": 515.413330078125, "val_acc": 60.0}
{"epoch": 22, "training_loss": 803.7763916015625, "training_acc": 50.0, "val_loss": 676.2520751953125, "val_acc": 40.0}
{"epoch": 23, "training_loss": 552.82763671875, "training_acc": 40.0, "val_loss": 311.63299560546875, "val_acc": 40.0}
{"epoch": 24, "training_loss": 232.90246200561523, "training_acc": 50.0, "val_loss": 24.36012077331543, "val_acc": 40.0}
{"epoch": 25, "training_loss": 112.41587533950806, "training_acc": 60.0, "val_loss": 942.3218994140625, "val_acc": 60.0}
{"epoch": 26, "training_loss": 1068.9527587890625, "training_acc": 50.0, "val_loss": 585.8279418945312, "val_acc": 40.0}
{"epoch": 27, "training_loss": 745.8858276367188, "training_acc": 50.0, "val_loss": 708.093994140625, "val_acc": 60.0}
{"epoch": 28, "training_loss": 1011.262255859375, "training_acc": 50.0, "val_loss": 936.9584350585938, "val_acc": 40.0}
{"epoch": 29, "training_loss": 1125.51474609375, "training_acc": 50.0, "val_loss": 261.9777526855469, "val_acc": 40.0}
{"epoch": 30, "training_loss": 1405.8096313476562, "training_acc": 40.0, "val_loss": 1757.931640625, "val_acc": 60.0}
{"epoch": 31, "training_loss": 1306.3783081054687, "training_acc": 50.0, "val_loss": 2828.927001953125, "val_acc": 40.0}
{"epoch": 32, "training_loss": 3031.3522705078126, "training_acc": 50.0, "val_loss": 4702.21728515625, "val_acc": 40.0}
{"epoch": 33, "training_loss": 3034.25615234375, "training_acc": 50.0, "val_loss": 464.8127136230469, "val_acc": 60.0}
{"epoch": 34, "training_loss": 1512.971630859375, "training_acc": 50.0, "val_loss": 1666.0672607421875, "val_acc": 60.0}
{"epoch": 35, "training_loss": 1470.740234375, "training_acc": 50.0, "val_loss": 2229.569091796875, "val_acc": 40.0}
{"epoch": 36, "training_loss": 1758.5942626953124, "training_acc": 50.0, "val_loss": 370.5400085449219, "val_acc": 60.0}
{"epoch": 37, "training_loss": 939.4927734375, "training_acc": 50.0, "val_loss": 301.5048522949219, "val_acc": 60.0}
{"epoch": 38, "training_loss": 1707.678125, "training_acc": 30.0, "val_loss": 2199.120849609375, "val_acc": 40.0}
{"epoch": 39, "training_loss": 1229.3152099609374, "training_acc": 50.0, "val_loss": 1788.9566650390625, "val_acc": 60.0}
{"epoch": 40, "training_loss": 1996.1191650390624, "training_acc": 50.0, "val_loss": 281.97076416015625, "val_acc": 40.0}
{"epoch": 41, "training_loss": 236.16882934570313, "training_acc": 50.0, "val_loss": 27.204824447631836, "val_acc": 40.0}
{"epoch": 42, "training_loss": 192.39435424804688, "training_acc": 50.0, "val_loss": 1265.806396484375, "val_acc": 40.0}
{"epoch": 43, "training_loss": 1658.3093872070312, "training_acc": 50.0, "val_loss": 133.5074005126953, "val_acc": 60.0}
