"main_modify.py --pretrained_path None --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 4 --task ADNI_sex --input_option yAware --learning_rate 4e1 --batch_size 8 --weight_decay 1e-9 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 3692.705118727684, "training_acc": 55.0, "val_loss": 2678.91015625, "val_acc": 60.0}
{"epoch": 1, "training_loss": 3032.3160888671873, "training_acc": 45.0, "val_loss": 4086.712646484375, "val_acc": 40.0}
{"epoch": 2, "training_loss": 3730.41064453125, "training_acc": 55.0, "val_loss": 3674.841796875, "val_acc": 40.0}
{"epoch": 3, "training_loss": 2619.9751525878905, "training_acc": 45.0, "val_loss": 3796.741455078125, "val_acc": 60.0}
{"epoch": 4, "training_loss": 4591.749609375, "training_acc": 45.0, "val_loss": 418.58233642578125, "val_acc": 60.0}
{"epoch": 5, "training_loss": 1768.8685546875, "training_acc": 55.0, "val_loss": 7017.14990234375, "val_acc": 40.0}
{"epoch": 6, "training_loss": 5181.8853515625, "training_acc": 55.0, "val_loss": 4544.63330078125, "val_acc": 40.0}
{"epoch": 7, "training_loss": 1733.8011352539063, "training_acc": 65.0, "val_loss": 2192.662841796875, "val_acc": 60.0}
{"epoch": 8, "training_loss": 3191.85107421875, "training_acc": 45.0, "val_loss": 1055.1668701171875, "val_acc": 60.0}
{"epoch": 9, "training_loss": 1879.12421875, "training_acc": 35.0, "val_loss": 3051.30126953125, "val_acc": 40.0}
{"epoch": 10, "training_loss": 1806.3827392578125, "training_acc": 55.0, "val_loss": 955.8810424804688, "val_acc": 60.0}
{"epoch": 11, "training_loss": 2023.914697265625, "training_acc": 45.0, "val_loss": 794.9755249023438, "val_acc": 60.0}
{"epoch": 12, "training_loss": 877.4765380859375, "training_acc": 55.0, "val_loss": 2767.82666015625, "val_acc": 40.0}
{"epoch": 13, "training_loss": 1757.3205322265626, "training_acc": 55.0, "val_loss": 405.5009460449219, "val_acc": 60.0}
{"epoch": 14, "training_loss": 735.0286178588867, "training_acc": 45.0, "val_loss": 942.42578125, "val_acc": 40.0}
{"epoch": 15, "training_loss": 946.3311767578125, "training_acc": 55.0, "val_loss": 556.5231323242188, "val_acc": 60.0}
{"epoch": 16, "training_loss": 851.904736328125, "training_acc": 45.0, "val_loss": 932.1181640625, "val_acc": 40.0}
{"epoch": 17, "training_loss": 608.57333984375, "training_acc": 55.0, "val_loss": 1135.0755615234375, "val_acc": 60.0}
{"epoch": 18, "training_loss": 1777.3795532226563, "training_acc": 45.0, "val_loss": 679.89306640625, "val_acc": 60.0}
{"epoch": 19, "training_loss": 1800.66953125, "training_acc": 25.0, "val_loss": 1917.165283203125, "val_acc": 40.0}
{"epoch": 20, "training_loss": 705.6353881835937, "training_acc": 65.0, "val_loss": 1361.2972412109375, "val_acc": 60.0}
{"epoch": 21, "training_loss": 1679.364096069336, "training_acc": 45.0, "val_loss": 1141.3968505859375, "val_acc": 40.0}
{"epoch": 22, "training_loss": 1210.106103515625, "training_acc": 55.0, "val_loss": 505.1213073730469, "val_acc": 40.0}
{"epoch": 23, "training_loss": 1273.05537109375, "training_acc": 45.0, "val_loss": 1155.8460693359375, "val_acc": 60.0}
{"epoch": 24, "training_loss": 809.2573791503906, "training_acc": 55.0, "val_loss": 3886.15478515625, "val_acc": 40.0}
{"epoch": 25, "training_loss": 3083.357080078125, "training_acc": 55.0, "val_loss": 2988.90771484375, "val_acc": 40.0}
{"epoch": 26, "training_loss": 1630.564453125, "training_acc": 45.0, "val_loss": 1421.0853271484375, "val_acc": 60.0}
{"epoch": 27, "training_loss": 1576.32255859375, "training_acc": 45.0, "val_loss": 1593.6318359375, "val_acc": 40.0}
{"epoch": 28, "training_loss": 1586.841552734375, "training_acc": 55.0, "val_loss": 2409.360595703125, "val_acc": 40.0}
{"epoch": 29, "training_loss": 896.8173126220703, "training_acc": 65.0, "val_loss": 1156.235595703125, "val_acc": 60.0}
{"epoch": 30, "training_loss": 1438.4237060546875, "training_acc": 45.0, "val_loss": 1241.1214599609375, "val_acc": 40.0}
{"epoch": 31, "training_loss": 1387.020654296875, "training_acc": 55.0, "val_loss": 1694.2572021484375, "val_acc": 40.0}
{"epoch": 32, "training_loss": 626.4226989746094, "training_acc": 65.0, "val_loss": 2098.994384765625, "val_acc": 60.0}
{"epoch": 33, "training_loss": 2702.292724609375, "training_acc": 45.0, "val_loss": 169.75474548339844, "val_acc": 60.0}
{"epoch": 34, "training_loss": 1912.9688720703125, "training_acc": 35.0, "val_loss": 5002.46875, "val_acc": 40.0}
{"epoch": 35, "training_loss": 3451.5361572265624, "training_acc": 55.0, "val_loss": 1614.7684326171875, "val_acc": 40.0}
{"epoch": 36, "training_loss": 702.8722351074218, "training_acc": 65.0, "val_loss": 821.7080078125, "val_acc": 60.0}
{"epoch": 37, "training_loss": 359.66337890625, "training_acc": 65.0, "val_loss": 3505.11181640625, "val_acc": 40.0}
{"epoch": 38, "training_loss": 2691.352001953125, "training_acc": 55.0, "val_loss": 2507.1240234375, "val_acc": 40.0}
{"epoch": 39, "training_loss": 1169.5187255859375, "training_acc": 55.0, "val_loss": 1732.66015625, "val_acc": 60.0}
{"epoch": 40, "training_loss": 2038.851416015625, "training_acc": 45.0, "val_loss": 847.6764526367188, "val_acc": 40.0}
{"epoch": 41, "training_loss": 1328.45263671875, "training_acc": 55.0, "val_loss": 1616.3287353515625, "val_acc": 40.0}
{"epoch": 42, "training_loss": 979.75078125, "training_acc": 45.0, "val_loss": 1863.0836181640625, "val_acc": 60.0}
{"epoch": 43, "training_loss": 2183.3130737304687, "training_acc": 45.0, "val_loss": 1124.4578857421875, "val_acc": 40.0}
{"epoch": 44, "training_loss": 1265.241162109375, "training_acc": 55.0, "val_loss": 1634.5623779296875, "val_acc": 40.0}
{"epoch": 45, "training_loss": 1310.3411987304687, "training_acc": 35.0, "val_loss": 1645.444580078125, "val_acc": 60.0}
{"epoch": 46, "training_loss": 1769.8199951171875, "training_acc": 35.0, "val_loss": 666.4677124023438, "val_acc": 40.0}
{"epoch": 47, "training_loss": 416.085546875, "training_acc": 55.0, "val_loss": 799.18212890625, "val_acc": 60.0}
{"epoch": 48, "training_loss": 826.3636047363282, "training_acc": 45.0, "val_loss": 2465.51806640625, "val_acc": 40.0}
{"epoch": 49, "training_loss": 1486.9285278320312, "training_acc": 55.0, "val_loss": 605.2332153320312, "val_acc": 60.0}
{"epoch": 50, "training_loss": 946.68896484375, "training_acc": 45.0, "val_loss": 676.2867431640625, "val_acc": 40.0}
{"epoch": 51, "training_loss": 466.90021057128905, "training_acc": 55.0, "val_loss": 585.8233032226562, "val_acc": 60.0}
{"epoch": 52, "training_loss": 783.2771057128906, "training_acc": 45.0, "val_loss": 333.4039001464844, "val_acc": 40.0}
