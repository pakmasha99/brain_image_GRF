"main_modify.py --pretrained_path None --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 5 --task ADNI_sex --input_option yAware --learning_rate 4e1 --batch_size 8 --weight_decay 1e-9 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 3369.4767406225205, "training_acc": 50.0, "val_loss": 5079.32275390625, "val_acc": 40.0}
{"epoch": 1, "training_loss": 4937.26982421875, "training_acc": 50.0, "val_loss": 4041.202880859375, "val_acc": 40.0}
{"epoch": 2, "training_loss": 2285.3202270507813, "training_acc": 30.0, "val_loss": 196.77134704589844, "val_acc": 60.0}
{"epoch": 3, "training_loss": 420.133251953125, "training_acc": 70.0, "val_loss": 738.8727416992188, "val_acc": 40.0}
{"epoch": 4, "training_loss": 604.8134521484375, "training_acc": 50.0, "val_loss": 474.4542541503906, "val_acc": 40.0}
{"epoch": 5, "training_loss": 273.3191940307617, "training_acc": 60.0, "val_loss": 1232.8521728515625, "val_acc": 60.0}
{"epoch": 6, "training_loss": 1141.2424682617188, "training_acc": 50.0, "val_loss": 1366.8330078125, "val_acc": 40.0}
{"epoch": 7, "training_loss": 977.8727317810059, "training_acc": 50.0, "val_loss": 1462.185302734375, "val_acc": 60.0}
{"epoch": 8, "training_loss": 1287.3503375053406, "training_acc": 50.0, "val_loss": 2657.4130859375, "val_acc": 40.0}
{"epoch": 9, "training_loss": 2728.95439453125, "training_acc": 50.0, "val_loss": 2795.031005859375, "val_acc": 40.0}
{"epoch": 10, "training_loss": 1533.15, "training_acc": 50.0, "val_loss": 2682.279296875, "val_acc": 60.0}
{"epoch": 11, "training_loss": 3325.701220703125, "training_acc": 50.0, "val_loss": 1317.7791748046875, "val_acc": 60.0}
{"epoch": 12, "training_loss": 1318.8153198242187, "training_acc": 40.0, "val_loss": 1891.0946044921875, "val_acc": 40.0}
{"epoch": 13, "training_loss": 1301.02529296875, "training_acc": 40.0, "val_loss": 676.5694580078125, "val_acc": 60.0}
{"epoch": 14, "training_loss": 862.41630859375, "training_acc": 40.0, "val_loss": 1971.918212890625, "val_acc": 40.0}
{"epoch": 15, "training_loss": 1133.4225952148438, "training_acc": 50.0, "val_loss": 595.7717895507812, "val_acc": 60.0}
{"epoch": 16, "training_loss": 506.01768646240237, "training_acc": 40.0, "val_loss": 3.269291400909424, "val_acc": 40.0}
{"epoch": 17, "training_loss": 270.1490462303162, "training_acc": 45.0, "val_loss": 390.2174377441406, "val_acc": 60.0}
{"epoch": 18, "training_loss": 453.20081787109376, "training_acc": 50.0, "val_loss": 935.5338745117188, "val_acc": 40.0}
{"epoch": 19, "training_loss": 812.435791015625, "training_acc": 40.0, "val_loss": 1489.1763916015625, "val_acc": 60.0}
{"epoch": 20, "training_loss": 1221.5468994140624, "training_acc": 50.0, "val_loss": 2283.20703125, "val_acc": 40.0}
{"epoch": 21, "training_loss": 2845.54755859375, "training_acc": 50.0, "val_loss": 3240.107421875, "val_acc": 40.0}
{"epoch": 22, "training_loss": 2488.23251953125, "training_acc": 30.0, "val_loss": 2092.607666015625, "val_acc": 60.0}
{"epoch": 23, "training_loss": 2638.7963989257814, "training_acc": 50.0, "val_loss": 388.1973571777344, "val_acc": 60.0}
{"epoch": 24, "training_loss": 1245.785693359375, "training_acc": 50.0, "val_loss": 3004.181396484375, "val_acc": 40.0}
{"epoch": 25, "training_loss": 2001.4967498779297, "training_acc": 50.0, "val_loss": 1099.7916259765625, "val_acc": 60.0}
{"epoch": 26, "training_loss": 1912.000341796875, "training_acc": 50.0, "val_loss": 1185.8568115234375, "val_acc": 60.0}
{"epoch": 27, "training_loss": 963.2224670410156, "training_acc": 40.0, "val_loss": 458.3796081542969, "val_acc": 40.0}
{"epoch": 28, "training_loss": 579.0898071289063, "training_acc": 50.0, "val_loss": 149.6266632080078, "val_acc": 60.0}
{"epoch": 29, "training_loss": 283.8002593994141, "training_acc": 80.0, "val_loss": 848.2103881835938, "val_acc": 40.0}
{"epoch": 30, "training_loss": 630.918408203125, "training_acc": 50.0, "val_loss": 46.34853744506836, "val_acc": 40.0}
{"epoch": 31, "training_loss": 375.93065643310547, "training_acc": 40.0, "val_loss": 471.6545104980469, "val_acc": 60.0}
{"epoch": 32, "training_loss": 270.41219635009764, "training_acc": 60.0, "val_loss": 235.91795349121094, "val_acc": 60.0}
{"epoch": 33, "training_loss": 220.82725830078124, "training_acc": 60.0, "val_loss": 1559.556640625, "val_acc": 40.0}
{"epoch": 34, "training_loss": 1099.5358276367188, "training_acc": 40.0, "val_loss": 299.2403259277344, "val_acc": 60.0}
{"epoch": 35, "training_loss": 199.23340454101563, "training_acc": 60.0, "val_loss": 555.0186767578125, "val_acc": 60.0}
