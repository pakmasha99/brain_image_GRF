"main_modify.py --pretrained_path None --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 2 --task ADNI_sex --input_option yAware --learning_rate 4e1 --batch_size 8 --weight_decay 1e-9 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 5741.628249740601, "training_acc": 45.0, "val_loss": 4293.11376953125, "val_acc": 40.0}
{"epoch": 1, "training_loss": 3849.26171875, "training_acc": 55.0, "val_loss": 4633.87060546875, "val_acc": 40.0}
{"epoch": 2, "training_loss": 3008.468310546875, "training_acc": 45.0, "val_loss": 2752.61572265625, "val_acc": 60.0}
{"epoch": 3, "training_loss": 3010.776806640625, "training_acc": 45.0, "val_loss": 2177.62841796875, "val_acc": 40.0}
{"epoch": 4, "training_loss": 2683.129833984375, "training_acc": 55.0, "val_loss": 3694.551513671875, "val_acc": 40.0}
{"epoch": 5, "training_loss": 1458.9085571289063, "training_acc": 65.0, "val_loss": 1351.483642578125, "val_acc": 60.0}
{"epoch": 6, "training_loss": 1557.480224609375, "training_acc": 45.0, "val_loss": 1598.6082763671875, "val_acc": 40.0}
{"epoch": 7, "training_loss": 2642.379992675781, "training_acc": 55.0, "val_loss": 2721.137451171875, "val_acc": 40.0}
{"epoch": 8, "training_loss": 922.3915649414063, "training_acc": 65.0, "val_loss": 2270.566162109375, "val_acc": 60.0}
{"epoch": 9, "training_loss": 3116.562890625, "training_acc": 45.0, "val_loss": 711.5265502929688, "val_acc": 60.0}
{"epoch": 10, "training_loss": 1017.8260009765625, "training_acc": 55.0, "val_loss": 3628.93359375, "val_acc": 40.0}
{"epoch": 11, "training_loss": 2417.9408447265623, "training_acc": 55.0, "val_loss": 380.71630859375, "val_acc": 40.0}
{"epoch": 12, "training_loss": 1852.0444580078124, "training_acc": 45.0, "val_loss": 2323.401123046875, "val_acc": 60.0}
{"epoch": 13, "training_loss": 2663.6294921875, "training_acc": 25.0, "val_loss": 1254.0770263671875, "val_acc": 40.0}
{"epoch": 14, "training_loss": 671.0993713378906, "training_acc": 55.0, "val_loss": 266.0987243652344, "val_acc": 60.0}
{"epoch": 15, "training_loss": 730.7518676757812, "training_acc": 45.0, "val_loss": 50.85309982299805, "val_acc": 60.0}
{"epoch": 16, "training_loss": 266.88766021728514, "training_acc": 45.0, "val_loss": 379.3114013671875, "val_acc": 40.0}
{"epoch": 17, "training_loss": 291.9937377929688, "training_acc": 45.0, "val_loss": 581.32958984375, "val_acc": 60.0}
{"epoch": 18, "training_loss": 764.966650390625, "training_acc": 45.0, "val_loss": 1647.4261474609375, "val_acc": 40.0}
{"epoch": 19, "training_loss": 1924.63564453125, "training_acc": 55.0, "val_loss": 1595.0870361328125, "val_acc": 40.0}
{"epoch": 20, "training_loss": 666.2624633789062, "training_acc": 55.0, "val_loss": 536.5184936523438, "val_acc": 60.0}
{"epoch": 21, "training_loss": 1006.676806640625, "training_acc": 35.0, "val_loss": 440.04052734375, "val_acc": 40.0}
{"epoch": 22, "training_loss": 822.1091674804687, "training_acc": 55.0, "val_loss": 660.8068237304688, "val_acc": 60.0}
{"epoch": 23, "training_loss": 841.4323486328125, "training_acc": 45.0, "val_loss": 1425.5501708984375, "val_acc": 40.0}
{"epoch": 24, "training_loss": 734.4280700683594, "training_acc": 55.0, "val_loss": 456.9493713378906, "val_acc": 60.0}
{"epoch": 25, "training_loss": 373.19834594726564, "training_acc": 45.0, "val_loss": 617.7520751953125, "val_acc": 60.0}
{"epoch": 26, "training_loss": 750.2825500488282, "training_acc": 45.0, "val_loss": 2062.86767578125, "val_acc": 40.0}
{"epoch": 27, "training_loss": 2450.7009033203126, "training_acc": 55.0, "val_loss": 3186.430419921875, "val_acc": 40.0}
{"epoch": 28, "training_loss": 1632.4852081298827, "training_acc": 55.0, "val_loss": 707.5974731445312, "val_acc": 60.0}
{"epoch": 29, "training_loss": 924.5597900390625, "training_acc": 35.0, "val_loss": 1069.8035888671875, "val_acc": 40.0}
{"epoch": 30, "training_loss": 439.08766479492186, "training_acc": 65.0, "val_loss": 956.5894775390625, "val_acc": 60.0}
{"epoch": 31, "training_loss": 938.7825561523438, "training_acc": 45.0, "val_loss": 2350.06005859375, "val_acc": 40.0}
{"epoch": 32, "training_loss": 2218.2770263671873, "training_acc": 55.0, "val_loss": 4075.349365234375, "val_acc": 40.0}
{"epoch": 33, "training_loss": 2584.5557861328125, "training_acc": 55.0, "val_loss": 189.353271484375, "val_acc": 60.0}
{"epoch": 34, "training_loss": 958.7616333007812, "training_acc": 45.0, "val_loss": 328.9962463378906, "val_acc": 60.0}
