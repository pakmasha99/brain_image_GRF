"main_modify.py --pretrained_path None --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 3 --task ADNI_sex --input_option yAware --learning_rate 4e1 --batch_size 8 --weight_decay 1e-9 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 3955.058569765091, "training_acc": 55.0, "val_loss": 3668.51171875, "val_acc": 60.0}
{"epoch": 1, "training_loss": 5064.9712890625, "training_acc": 45.0, "val_loss": 634.8604736328125, "val_acc": 60.0}
{"epoch": 2, "training_loss": 2923.014892578125, "training_acc": 45.0, "val_loss": 5977.80322265625, "val_acc": 40.0}
{"epoch": 3, "training_loss": 3281.997119140625, "training_acc": 55.0, "val_loss": 1357.257080078125, "val_acc": 60.0}
{"epoch": 4, "training_loss": 2960.9281005859375, "training_acc": 45.0, "val_loss": 1845.87890625, "val_acc": 60.0}
{"epoch": 5, "training_loss": 2336.106982421875, "training_acc": 25.0, "val_loss": 3867.71875, "val_acc": 40.0}
{"epoch": 6, "training_loss": 2927.38076171875, "training_acc": 55.0, "val_loss": 1310.88671875, "val_acc": 40.0}
{"epoch": 7, "training_loss": 1388.242138671875, "training_acc": 55.0, "val_loss": 2438.376708984375, "val_acc": 60.0}
{"epoch": 8, "training_loss": 2672.58203125, "training_acc": 45.0, "val_loss": 1288.728515625, "val_acc": 40.0}
{"epoch": 9, "training_loss": 1879.04423828125, "training_acc": 55.0, "val_loss": 2565.900634765625, "val_acc": 40.0}
{"epoch": 10, "training_loss": 1549.555615234375, "training_acc": 45.0, "val_loss": 1657.7845458984375, "val_acc": 60.0}
{"epoch": 11, "training_loss": 1863.525390625, "training_acc": 45.0, "val_loss": 1197.4566650390625, "val_acc": 40.0}
{"epoch": 12, "training_loss": 1521.122607421875, "training_acc": 55.0, "val_loss": 2879.112548828125, "val_acc": 40.0}
{"epoch": 13, "training_loss": 1800.2646850585938, "training_acc": 35.0, "val_loss": 164.40406799316406, "val_acc": 60.0}
{"epoch": 14, "training_loss": 184.2288589477539, "training_acc": 65.0, "val_loss": 146.9161834716797, "val_acc": 60.0}
{"epoch": 15, "training_loss": 431.3760009765625, "training_acc": 35.0, "val_loss": 594.2147216796875, "val_acc": 60.0}
{"epoch": 16, "training_loss": 861.7166168212891, "training_acc": 35.0, "val_loss": 113.43562316894531, "val_acc": 60.0}
{"epoch": 17, "training_loss": 224.08914184570312, "training_acc": 55.0, "val_loss": 389.7319641113281, "val_acc": 60.0}
{"epoch": 18, "training_loss": 495.8666748046875, "training_acc": 45.0, "val_loss": 1295.5474853515625, "val_acc": 40.0}
{"epoch": 19, "training_loss": 685.8955078125, "training_acc": 55.0, "val_loss": 407.79010009765625, "val_acc": 60.0}
{"epoch": 20, "training_loss": 439.0572998046875, "training_acc": 45.0, "val_loss": 509.5311584472656, "val_acc": 60.0}
{"epoch": 21, "training_loss": 723.6633117675781, "training_acc": 35.0, "val_loss": 105.59905242919922, "val_acc": 40.0}
{"epoch": 22, "training_loss": 421.5683029174805, "training_acc": 55.0, "val_loss": 108.3178482055664, "val_acc": 40.0}
{"epoch": 23, "training_loss": 247.07882690429688, "training_acc": 55.0, "val_loss": 445.4142761230469, "val_acc": 60.0}
{"epoch": 24, "training_loss": 355.1346862792969, "training_acc": 55.0, "val_loss": 231.9493408203125, "val_acc": 60.0}
{"epoch": 25, "training_loss": 245.32515869140624, "training_acc": 45.0, "val_loss": 34.17014694213867, "val_acc": 40.0}
{"epoch": 26, "training_loss": 270.4927322387695, "training_acc": 45.0, "val_loss": 85.6258773803711, "val_acc": 40.0}
{"epoch": 27, "training_loss": 225.69001998901368, "training_acc": 75.0, "val_loss": 113.26423645019531, "val_acc": 60.0}
{"epoch": 28, "training_loss": 904.276123046875, "training_acc": 35.0, "val_loss": 1036.7117919921875, "val_acc": 40.0}
{"epoch": 29, "training_loss": 494.10841064453126, "training_acc": 45.0, "val_loss": 623.8286743164062, "val_acc": 40.0}
{"epoch": 30, "training_loss": 518.7760681152344, "training_acc": 55.0, "val_loss": 1034.0093994140625, "val_acc": 60.0}
{"epoch": 31, "training_loss": 1819.116943359375, "training_acc": 45.0, "val_loss": 418.2637634277344, "val_acc": 60.0}
{"epoch": 32, "training_loss": 816.11962890625, "training_acc": 55.0, "val_loss": 2876.064208984375, "val_acc": 40.0}
{"epoch": 33, "training_loss": 1799.157275390625, "training_acc": 55.0, "val_loss": 309.0060729980469, "val_acc": 60.0}
{"epoch": 34, "training_loss": 564.385693359375, "training_acc": 45.0, "val_loss": 984.4421997070312, "val_acc": 40.0}
{"epoch": 35, "training_loss": 817.6774230957031, "training_acc": 55.0, "val_loss": 244.58047485351562, "val_acc": 60.0}
{"epoch": 36, "training_loss": 398.1245483398437, "training_acc": 45.0, "val_loss": 900.4738159179688, "val_acc": 40.0}
{"epoch": 37, "training_loss": 490.2769805908203, "training_acc": 35.0, "val_loss": 165.71128845214844, "val_acc": 60.0}
{"epoch": 38, "training_loss": 145.35487670898436, "training_acc": 55.0, "val_loss": 570.6410522460938, "val_acc": 40.0}
{"epoch": 39, "training_loss": 353.2757278442383, "training_acc": 50.0, "val_loss": 305.8795471191406, "val_acc": 60.0}
{"epoch": 40, "training_loss": 953.906396484375, "training_acc": 35.0, "val_loss": 831.28369140625, "val_acc": 40.0}
{"epoch": 41, "training_loss": 538.9330078125, "training_acc": 55.0, "val_loss": 60.22652816772461, "val_acc": 40.0}
{"epoch": 42, "training_loss": 129.14506607055665, "training_acc": 55.0, "val_loss": 245.0874481201172, "val_acc": 60.0}
{"epoch": 43, "training_loss": 679.9009887695313, "training_acc": 45.0, "val_loss": 816.4029541015625, "val_acc": 40.0}
{"epoch": 44, "training_loss": 297.3960578918457, "training_acc": 65.0, "val_loss": 563.9452514648438, "val_acc": 60.0}
