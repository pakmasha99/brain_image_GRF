"main_modify.py --pretrained_path None --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 3 --task ADNI_sex --input_option yAware --learning_rate 4e1 --batch_size 8 --weight_decay 1e-9 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 2619.5630630254745, "training_acc": 50.0, "val_loss": 5727.89794921875, "val_acc": 60.0}
{"epoch": 1, "training_loss": 8840.7544921875, "training_acc": 50.0, "val_loss": 6651.9921875, "val_acc": 60.0}
{"epoch": 2, "training_loss": 6077.508288574219, "training_acc": 50.0, "val_loss": 3915.40087890625, "val_acc": 40.0}
{"epoch": 3, "training_loss": 4748.699365234375, "training_acc": 50.0, "val_loss": 7137.68701171875, "val_acc": 40.0}
{"epoch": 4, "training_loss": 4970.656958007812, "training_acc": 50.0, "val_loss": 284.2041320800781, "val_acc": 60.0}
{"epoch": 5, "training_loss": 2462.0183074951174, "training_acc": 50.0, "val_loss": 1448.15625, "val_acc": 60.0}
{"epoch": 6, "training_loss": 791.5067291259766, "training_acc": 60.0, "val_loss": 5058.31494140625, "val_acc": 40.0}
{"epoch": 7, "training_loss": 4568.34443359375, "training_acc": 50.0, "val_loss": 3899.948486328125, "val_acc": 40.0}
{"epoch": 8, "training_loss": 2510.9981201171877, "training_acc": 50.0, "val_loss": 3041.52294921875, "val_acc": 60.0}
{"epoch": 9, "training_loss": 4280.5052734375, "training_acc": 50.0, "val_loss": 2429.185302734375, "val_acc": 60.0}
{"epoch": 10, "training_loss": 1946.6206787109375, "training_acc": 50.0, "val_loss": 3586.564208984375, "val_acc": 40.0}
{"epoch": 11, "training_loss": 2950.317578125, "training_acc": 50.0, "val_loss": 1738.428955078125, "val_acc": 40.0}
{"epoch": 12, "training_loss": 1177.8371337890626, "training_acc": 40.0, "val_loss": 721.5720825195312, "val_acc": 60.0}
{"epoch": 13, "training_loss": 630.0932739257812, "training_acc": 50.0, "val_loss": 2812.177490234375, "val_acc": 40.0}
{"epoch": 14, "training_loss": 2197.483837890625, "training_acc": 50.0, "val_loss": 162.91912841796875, "val_acc": 60.0}
{"epoch": 15, "training_loss": 524.0860534667969, "training_acc": 50.0, "val_loss": 37.43875503540039, "val_acc": 60.0}
{"epoch": 16, "training_loss": 700.2065185546875, "training_acc": 60.0, "val_loss": 1990.423095703125, "val_acc": 40.0}
{"epoch": 17, "training_loss": 1143.3240356445312, "training_acc": 50.0, "val_loss": 1176.680419921875, "val_acc": 60.0}
{"epoch": 18, "training_loss": 1189.1008529663086, "training_acc": 40.0, "val_loss": 14.141901016235352, "val_acc": 60.0}
{"epoch": 19, "training_loss": 226.87225799560548, "training_acc": 60.0, "val_loss": 61.2076530456543, "val_acc": 60.0}
{"epoch": 20, "training_loss": 844.7940948486328, "training_acc": 50.0, "val_loss": 1381.750244140625, "val_acc": 40.0}
{"epoch": 21, "training_loss": 661.5848892211914, "training_acc": 50.0, "val_loss": 181.232177734375, "val_acc": 40.0}
{"epoch": 22, "training_loss": 193.71250610351564, "training_acc": 60.0, "val_loss": 616.1693115234375, "val_acc": 60.0}
{"epoch": 23, "training_loss": 575.9639770507813, "training_acc": 30.0, "val_loss": 996.4904174804688, "val_acc": 60.0}
{"epoch": 24, "training_loss": 1615.0896240234374, "training_acc": 50.0, "val_loss": 71.94441986083984, "val_acc": 60.0}
{"epoch": 25, "training_loss": 1145.4030151367188, "training_acc": 60.0, "val_loss": 4435.88623046875, "val_acc": 40.0}
{"epoch": 26, "training_loss": 3320.6728515625, "training_acc": 50.0, "val_loss": 687.3732299804688, "val_acc": 40.0}
{"epoch": 27, "training_loss": 530.9688415527344, "training_acc": 80.0, "val_loss": 2508.178466796875, "val_acc": 60.0}
{"epoch": 28, "training_loss": 2677.6958984375, "training_acc": 50.0, "val_loss": 18.678449630737305, "val_acc": 60.0}
{"epoch": 29, "training_loss": 914.9530616760254, "training_acc": 70.0, "val_loss": 3692.926513671875, "val_acc": 40.0}
{"epoch": 30, "training_loss": 2388.7021240234376, "training_acc": 50.0, "val_loss": 959.697265625, "val_acc": 60.0}
{"epoch": 31, "training_loss": 2069.442578125, "training_acc": 50.0, "val_loss": 1419.8916015625, "val_acc": 60.0}
{"epoch": 32, "training_loss": 1082.5470825195312, "training_acc": 60.0, "val_loss": 3891.873779296875, "val_acc": 40.0}
{"epoch": 33, "training_loss": 3574.933203125, "training_acc": 50.0, "val_loss": 2426.959716796875, "val_acc": 40.0}
{"epoch": 34, "training_loss": 1101.687725830078, "training_acc": 50.0, "val_loss": 1197.2259521484375, "val_acc": 60.0}
{"epoch": 35, "training_loss": 1025.5921325683594, "training_acc": 50.0, "val_loss": 997.2523803710938, "val_acc": 40.0}
{"epoch": 36, "training_loss": 840.4467468261719, "training_acc": 40.0, "val_loss": 927.5907592773438, "val_acc": 60.0}
{"epoch": 37, "training_loss": 807.7674438476563, "training_acc": 50.0, "val_loss": 2145.887451171875, "val_acc": 40.0}
