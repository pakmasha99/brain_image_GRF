"main_modify.py --pretrained_path None --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_sex --input_option yAware --learning_rate 4e1 --batch_size 8 --weight_decay 1e-9 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 4636.870093321801, "training_acc": 40.0, "val_loss": 2062.291748046875, "val_acc": 60.0}
{"epoch": 1, "training_loss": 4651.211669921875, "training_acc": 50.0, "val_loss": 2643.23193359375, "val_acc": 60.0}
{"epoch": 2, "training_loss": 2018.8236938476562, "training_acc": 60.0, "val_loss": 6770.16259765625, "val_acc": 40.0}
{"epoch": 3, "training_loss": 5859.5779296875, "training_acc": 50.0, "val_loss": 4332.7041015625, "val_acc": 40.0}
{"epoch": 4, "training_loss": 2741.512890625, "training_acc": 40.0, "val_loss": 4091.585693359375, "val_acc": 60.0}
{"epoch": 5, "training_loss": 5404.39912109375, "training_acc": 50.0, "val_loss": 3116.38818359375, "val_acc": 60.0}
{"epoch": 6, "training_loss": 2652.473095703125, "training_acc": 50.0, "val_loss": 2721.08837890625, "val_acc": 40.0}
{"epoch": 7, "training_loss": 2123.039208984375, "training_acc": 50.0, "val_loss": 278.6012268066406, "val_acc": 40.0}
{"epoch": 8, "training_loss": 1919.9073364257813, "training_acc": 40.0, "val_loss": 2861.572265625, "val_acc": 60.0}
{"epoch": 9, "training_loss": 2808.1662109375, "training_acc": 50.0, "val_loss": 794.8427734375, "val_acc": 40.0}
{"epoch": 10, "training_loss": 1202.37724609375, "training_acc": 50.0, "val_loss": 1875.099853515625, "val_acc": 40.0}
{"epoch": 11, "training_loss": 1517.315591430664, "training_acc": 40.0, "val_loss": 1893.729736328125, "val_acc": 60.0}
{"epoch": 12, "training_loss": 1887.8981689453126, "training_acc": 50.0, "val_loss": 1214.308837890625, "val_acc": 40.0}
{"epoch": 13, "training_loss": 1738.8662353515624, "training_acc": 50.0, "val_loss": 1198.7659912109375, "val_acc": 40.0}
{"epoch": 14, "training_loss": 359.91370849609376, "training_acc": 70.0, "val_loss": 1033.092529296875, "val_acc": 60.0}
{"epoch": 15, "training_loss": 1123.3032958984375, "training_acc": 40.0, "val_loss": 881.27001953125, "val_acc": 40.0}
{"epoch": 16, "training_loss": 640.469091796875, "training_acc": 40.0, "val_loss": 956.8585205078125, "val_acc": 40.0}
{"epoch": 17, "training_loss": 1125.8140747070313, "training_acc": 50.0, "val_loss": 170.2105712890625, "val_acc": 60.0}
{"epoch": 18, "training_loss": 237.87869262695312, "training_acc": 50.0, "val_loss": 81.22989654541016, "val_acc": 60.0}
{"epoch": 19, "training_loss": 384.07919921875, "training_acc": 40.0, "val_loss": 697.6567993164062, "val_acc": 60.0}
{"epoch": 20, "training_loss": 1038.359619140625, "training_acc": 50.0, "val_loss": 806.5220947265625, "val_acc": 40.0}
{"epoch": 21, "training_loss": 990.813427734375, "training_acc": 50.0, "val_loss": 90.166259765625, "val_acc": 40.0}
{"epoch": 22, "training_loss": 668.3085052490235, "training_acc": 60.0, "val_loss": 1226.9488525390625, "val_acc": 60.0}
{"epoch": 23, "training_loss": 1123.8262939453125, "training_acc": 50.0, "val_loss": 1936.2669677734375, "val_acc": 40.0}
{"epoch": 24, "training_loss": 1172.1051483154297, "training_acc": 50.0, "val_loss": 1257.2886962890625, "val_acc": 60.0}
{"epoch": 25, "training_loss": 2257.57919921875, "training_acc": 50.0, "val_loss": 1141.32763671875, "val_acc": 60.0}
{"epoch": 26, "training_loss": 699.9668090820312, "training_acc": 60.0, "val_loss": 1265.690673828125, "val_acc": 40.0}
{"epoch": 27, "training_loss": 658.7905151367188, "training_acc": 60.0, "val_loss": 1122.211181640625, "val_acc": 60.0}
{"epoch": 28, "training_loss": 1285.804281616211, "training_acc": 50.0, "val_loss": 1191.0694580078125, "val_acc": 40.0}
{"epoch": 29, "training_loss": 996.1052734375, "training_acc": 50.0, "val_loss": 343.036865234375, "val_acc": 60.0}
{"epoch": 30, "training_loss": 481.6680252075195, "training_acc": 50.0, "val_loss": 1420.45703125, "val_acc": 40.0}
{"epoch": 31, "training_loss": 1155.325, "training_acc": 50.0, "val_loss": 379.3192138671875, "val_acc": 60.0}
{"epoch": 32, "training_loss": 667.9496948242188, "training_acc": 50.0, "val_loss": 254.85049438476562, "val_acc": 40.0}
{"epoch": 33, "training_loss": 349.86476440429686, "training_acc": 50.0, "val_loss": 113.3060531616211, "val_acc": 60.0}
{"epoch": 34, "training_loss": 515.2361572265625, "training_acc": 50.0, "val_loss": 2.310033082962036, "val_acc": 80.0}
{"epoch": 35, "training_loss": 97.63923492431641, "training_acc": 55.0, "val_loss": 697.9926147460938, "val_acc": 60.0}
{"epoch": 36, "training_loss": 674.189208984375, "training_acc": 50.0, "val_loss": 1718.09375, "val_acc": 40.0}
{"epoch": 37, "training_loss": 890.4772308349609, "training_acc": 60.0, "val_loss": 559.9382934570312, "val_acc": 60.0}
{"epoch": 38, "training_loss": 643.7467796325684, "training_acc": 60.0, "val_loss": 655.1320190429688, "val_acc": 40.0}
{"epoch": 39, "training_loss": 646.7560302734375, "training_acc": 40.0, "val_loss": 917.7706909179688, "val_acc": 60.0}
{"epoch": 40, "training_loss": 1356.409490966797, "training_acc": 30.0, "val_loss": 2281.323486328125, "val_acc": 40.0}
{"epoch": 41, "training_loss": 1476.4552368164063, "training_acc": 40.0, "val_loss": 531.9488525390625, "val_acc": 60.0}
{"epoch": 42, "training_loss": 566.04580078125, "training_acc": 30.0, "val_loss": 915.0730590820312, "val_acc": 60.0}
{"epoch": 43, "training_loss": 1161.3986206054688, "training_acc": 50.0, "val_loss": 301.9668884277344, "val_acc": 40.0}
{"epoch": 44, "training_loss": 296.88385620117185, "training_acc": 50.0, "val_loss": 1056.3060302734375, "val_acc": 60.0}
{"epoch": 45, "training_loss": 1609.524609375, "training_acc": 50.0, "val_loss": 442.921875, "val_acc": 60.0}
{"epoch": 46, "training_loss": 1215.5688720703124, "training_acc": 50.0, "val_loss": 2180.951904296875, "val_acc": 40.0}
{"epoch": 47, "training_loss": 1448.383544921875, "training_acc": 40.0, "val_loss": 1411.4971923828125, "val_acc": 60.0}
{"epoch": 48, "training_loss": 1417.8230010986329, "training_acc": 50.0, "val_loss": 1654.484375, "val_acc": 40.0}
{"epoch": 49, "training_loss": 1828.823828125, "training_acc": 50.0, "val_loss": 882.4197387695312, "val_acc": 40.0}
{"epoch": 50, "training_loss": 1500.66552734375, "training_acc": 40.0, "val_loss": 1480.7672119140625, "val_acc": 60.0}
{"epoch": 51, "training_loss": 1001.7729675292969, "training_acc": 60.0, "val_loss": 1921.681640625, "val_acc": 40.0}
{"epoch": 52, "training_loss": 1526.3837158203125, "training_acc": 50.0, "val_loss": 269.2896423339844, "val_acc": 60.0}
{"epoch": 53, "training_loss": 422.856787109375, "training_acc": 50.0, "val_loss": 556.9487915039062, "val_acc": 40.0}
