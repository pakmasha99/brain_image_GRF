"main_modify.py --pretrained_path None --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_sex --input_option yAware --learning_rate 4e1 --batch_size 8 --weight_decay 1e-9 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 4237.934457969665, "training_acc": 45.0, "val_loss": 1753.757080078125, "val_acc": 60.0}
{"epoch": 1, "training_loss": 4982.34189453125, "training_acc": 45.0, "val_loss": 712.109619140625, "val_acc": 60.0}
{"epoch": 2, "training_loss": 2194.514111328125, "training_acc": 65.0, "val_loss": 8929.4638671875, "val_acc": 40.0}
{"epoch": 3, "training_loss": 6952.888037109375, "training_acc": 55.0, "val_loss": 5620.4931640625, "val_acc": 40.0}
{"epoch": 4, "training_loss": 1738.9349609375, "training_acc": 75.0, "val_loss": 3600.80322265625, "val_acc": 60.0}
{"epoch": 5, "training_loss": 6000.8921875, "training_acc": 45.0, "val_loss": 4010.18994140625, "val_acc": 60.0}
{"epoch": 6, "training_loss": 3410.7768798828124, "training_acc": 45.0, "val_loss": 3799.12890625, "val_acc": 40.0}
{"epoch": 7, "training_loss": 4516.69384765625, "training_acc": 55.0, "val_loss": 8719.5576171875, "val_acc": 40.0}
{"epoch": 8, "training_loss": 5994.7646484375, "training_acc": 55.0, "val_loss": 3959.792236328125, "val_acc": 40.0}
{"epoch": 9, "training_loss": 1426.763232421875, "training_acc": 65.0, "val_loss": 3717.6484375, "val_acc": 60.0}
{"epoch": 10, "training_loss": 5728.6556640625, "training_acc": 45.0, "val_loss": 3703.450927734375, "val_acc": 60.0}
{"epoch": 11, "training_loss": 3196.287973022461, "training_acc": 45.0, "val_loss": 3766.64453125, "val_acc": 40.0}
{"epoch": 12, "training_loss": 4691.183984375, "training_acc": 55.0, "val_loss": 8480.3095703125, "val_acc": 40.0}
{"epoch": 13, "training_loss": 5848.8119140625, "training_acc": 55.0, "val_loss": 3111.396728515625, "val_acc": 40.0}
{"epoch": 14, "training_loss": 1549.2598434448241, "training_acc": 35.0, "val_loss": 1050.361572265625, "val_acc": 60.0}
{"epoch": 15, "training_loss": 859.8914489746094, "training_acc": 55.0, "val_loss": 2014.508056640625, "val_acc": 40.0}
{"epoch": 16, "training_loss": 1352.089404296875, "training_acc": 55.0, "val_loss": 358.6679382324219, "val_acc": 60.0}
{"epoch": 17, "training_loss": 1107.126953125, "training_acc": 45.0, "val_loss": 490.57989501953125, "val_acc": 40.0}
{"epoch": 18, "training_loss": 612.4089599609375, "training_acc": 55.0, "val_loss": 143.94070434570312, "val_acc": 60.0}
{"epoch": 19, "training_loss": 125.28634033203124, "training_acc": 55.0, "val_loss": 987.5568237304688, "val_acc": 60.0}
{"epoch": 20, "training_loss": 1319.4267822265624, "training_acc": 45.0, "val_loss": 851.1261596679688, "val_acc": 40.0}
{"epoch": 21, "training_loss": 703.8369262695312, "training_acc": 55.0, "val_loss": 136.15399169921875, "val_acc": 60.0}
{"epoch": 22, "training_loss": 331.6563720703125, "training_acc": 45.0, "val_loss": 944.5911254882812, "val_acc": 40.0}
{"epoch": 23, "training_loss": 624.5711791992187, "training_acc": 25.0, "val_loss": 269.4341735839844, "val_acc": 60.0}
{"epoch": 24, "training_loss": 252.90821533203126, "training_acc": 65.0, "val_loss": 1291.1942138671875, "val_acc": 40.0}
{"epoch": 25, "training_loss": 713.2273651123047, "training_acc": 55.0, "val_loss": 1107.4149169921875, "val_acc": 60.0}
{"epoch": 26, "training_loss": 1660.8298461914062, "training_acc": 45.0, "val_loss": 11.013483047485352, "val_acc": 60.0}
{"epoch": 27, "training_loss": 627.7735209481791, "training_acc": 65.0, "val_loss": 146.5662841796875, "val_acc": 60.0}
{"epoch": 28, "training_loss": 284.6406311035156, "training_acc": 45.0, "val_loss": 1117.499267578125, "val_acc": 40.0}
{"epoch": 29, "training_loss": 455.2760986328125, "training_acc": 65.0, "val_loss": 1115.0950927734375, "val_acc": 60.0}
{"epoch": 30, "training_loss": 1034.073989868164, "training_acc": 45.0, "val_loss": 2531.943359375, "val_acc": 40.0}
{"epoch": 31, "training_loss": 2647.62470703125, "training_acc": 55.0, "val_loss": 3848.53955078125, "val_acc": 40.0}
{"epoch": 32, "training_loss": 1775.114077758789, "training_acc": 55.0, "val_loss": 1843.9947509765625, "val_acc": 60.0}
{"epoch": 33, "training_loss": 3377.022705078125, "training_acc": 45.0, "val_loss": 2723.8154296875, "val_acc": 60.0}
{"epoch": 34, "training_loss": 2161.850048828125, "training_acc": 45.0, "val_loss": 3215.815673828125, "val_acc": 40.0}
{"epoch": 35, "training_loss": 4580.46005859375, "training_acc": 55.0, "val_loss": 8026.27490234375, "val_acc": 40.0}
{"epoch": 36, "training_loss": 5378.8861328125, "training_acc": 55.0, "val_loss": 3227.912841796875, "val_acc": 40.0}
{"epoch": 37, "training_loss": 1139.7216796875, "training_acc": 55.0, "val_loss": 3328.251220703125, "val_acc": 60.0}
{"epoch": 38, "training_loss": 4780.10712890625, "training_acc": 45.0, "val_loss": 2782.634521484375, "val_acc": 60.0}
{"epoch": 39, "training_loss": 2290.5477600097656, "training_acc": 55.0, "val_loss": 2867.51171875, "val_acc": 40.0}
{"epoch": 40, "training_loss": 2468.53271484375, "training_acc": 55.0, "val_loss": 2788.855224609375, "val_acc": 40.0}
{"epoch": 41, "training_loss": 1239.5418823242187, "training_acc": 55.0, "val_loss": 1047.0731201171875, "val_acc": 60.0}
{"epoch": 42, "training_loss": 1284.493212890625, "training_acc": 50.0, "val_loss": 1368.9705810546875, "val_acc": 40.0}
{"epoch": 43, "training_loss": 1053.1747985839843, "training_acc": 55.0, "val_loss": 191.87539672851562, "val_acc": 60.0}
{"epoch": 44, "training_loss": 214.6264221191406, "training_acc": 45.0, "val_loss": 349.09381103515625, "val_acc": 60.0}
{"epoch": 45, "training_loss": 353.12351684570314, "training_acc": 55.0, "val_loss": 249.77432250976562, "val_acc": 60.0}
