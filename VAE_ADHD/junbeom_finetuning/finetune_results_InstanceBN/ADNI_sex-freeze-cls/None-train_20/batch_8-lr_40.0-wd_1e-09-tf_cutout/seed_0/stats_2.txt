"main_modify.py --pretrained_path None --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_sex --input_option yAware --learning_rate 4e1 --batch_size 8 --weight_decay 1e-9 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 6844.974218130112, "training_acc": 20.0, "val_loss": 240.20164489746094, "val_acc": 60.0}
{"epoch": 1, "training_loss": 3067.94990234375, "training_acc": 60.0, "val_loss": 11354.7294921875, "val_acc": 40.0}
{"epoch": 2, "training_loss": 8730.46552734375, "training_acc": 50.0, "val_loss": 5029.5771484375, "val_acc": 40.0}
{"epoch": 3, "training_loss": 1683.9112548828125, "training_acc": 60.0, "val_loss": 4835.28466796875, "val_acc": 60.0}
{"epoch": 4, "training_loss": 7337.945703125, "training_acc": 50.0, "val_loss": 5666.00732421875, "val_acc": 60.0}
{"epoch": 5, "training_loss": 5652.0662841796875, "training_acc": 50.0, "val_loss": 621.9752807617188, "val_acc": 40.0}
{"epoch": 6, "training_loss": 1297.9771240234375, "training_acc": 50.0, "val_loss": 2656.948974609375, "val_acc": 40.0}
{"epoch": 7, "training_loss": 1280.4403442382813, "training_acc": 60.0, "val_loss": 1292.81689453125, "val_acc": 60.0}
{"epoch": 8, "training_loss": 1547.390625, "training_acc": 50.0, "val_loss": 1098.4970703125, "val_acc": 40.0}
{"epoch": 9, "training_loss": 1420.763671875, "training_acc": 50.0, "val_loss": 883.4564819335938, "val_acc": 40.0}
{"epoch": 10, "training_loss": 418.8879028320313, "training_acc": 70.0, "val_loss": 450.9834899902344, "val_acc": 60.0}
{"epoch": 11, "training_loss": 699.703515625, "training_acc": 50.0, "val_loss": 304.9274597167969, "val_acc": 40.0}
{"epoch": 12, "training_loss": 884.7576904296875, "training_acc": 50.0, "val_loss": 1026.598876953125, "val_acc": 60.0}
{"epoch": 13, "training_loss": 705.968017578125, "training_acc": 60.0, "val_loss": 3061.585693359375, "val_acc": 40.0}
{"epoch": 14, "training_loss": 2409.58427734375, "training_acc": 50.0, "val_loss": 82.41527557373047, "val_acc": 40.0}
{"epoch": 15, "training_loss": 1868.0489685058594, "training_acc": 50.0, "val_loss": 3053.2265625, "val_acc": 60.0}
{"epoch": 16, "training_loss": 2812.241064453125, "training_acc": 50.0, "val_loss": 1615.439697265625, "val_acc": 40.0}
{"epoch": 17, "training_loss": 2246.1625732421876, "training_acc": 50.0, "val_loss": 3359.07470703125, "val_acc": 40.0}
{"epoch": 18, "training_loss": 1706.206356048584, "training_acc": 60.0, "val_loss": 906.0914916992188, "val_acc": 60.0}
{"epoch": 19, "training_loss": 1101.3122314453126, "training_acc": 50.0, "val_loss": 1379.197265625, "val_acc": 40.0}
{"epoch": 20, "training_loss": 1431.489990234375, "training_acc": 50.0, "val_loss": 814.4984741210938, "val_acc": 40.0}
{"epoch": 21, "training_loss": 945.3434814453125, "training_acc": 50.0, "val_loss": 1229.5323486328125, "val_acc": 60.0}
{"epoch": 22, "training_loss": 1128.1440307617188, "training_acc": 50.0, "val_loss": 2147.11181640625, "val_acc": 40.0}
{"epoch": 23, "training_loss": 1308.019140625, "training_acc": 50.0, "val_loss": 1309.36181640625, "val_acc": 60.0}
{"epoch": 24, "training_loss": 1858.1017333984375, "training_acc": 50.0, "val_loss": 1347.24658203125, "val_acc": 60.0}
{"epoch": 25, "training_loss": 1071.2539306640624, "training_acc": 50.0, "val_loss": 2981.964599609375, "val_acc": 40.0}
{"epoch": 26, "training_loss": 2296.873645019531, "training_acc": 50.0, "val_loss": 56.377681732177734, "val_acc": 60.0}
{"epoch": 27, "training_loss": 143.38745727539063, "training_acc": 50.0, "val_loss": 65.34679412841797, "val_acc": 60.0}
{"epoch": 28, "training_loss": 113.23797912597657, "training_acc": 60.0, "val_loss": 417.9866638183594, "val_acc": 40.0}
{"epoch": 29, "training_loss": 358.3224578857422, "training_acc": 40.0, "val_loss": 35.25920867919922, "val_acc": 40.0}
{"epoch": 30, "training_loss": 1152.7705627441405, "training_acc": 40.0, "val_loss": 1249.8951416015625, "val_acc": 60.0}
{"epoch": 31, "training_loss": 1031.31083984375, "training_acc": 50.0, "val_loss": 2342.935791015625, "val_acc": 40.0}
{"epoch": 32, "training_loss": 1784.5568359375, "training_acc": 50.0, "val_loss": 566.7064819335938, "val_acc": 60.0}
{"epoch": 33, "training_loss": 852.9072814941406, "training_acc": 50.0, "val_loss": 335.2623596191406, "val_acc": 60.0}
{"epoch": 34, "training_loss": 819.1176635742188, "training_acc": 50.0, "val_loss": 1046.8980712890625, "val_acc": 40.0}
{"epoch": 35, "training_loss": 647.774462890625, "training_acc": 50.0, "val_loss": 134.7399139404297, "val_acc": 60.0}
{"epoch": 36, "training_loss": 1217.6877746582031, "training_acc": 40.0, "val_loss": 1443.9451904296875, "val_acc": 40.0}
{"epoch": 37, "training_loss": 884.7547668457031, "training_acc": 50.0, "val_loss": 381.0699157714844, "val_acc": 60.0}
{"epoch": 38, "training_loss": 1010.9250122070313, "training_acc": 40.0, "val_loss": 1203.4759521484375, "val_acc": 40.0}
{"epoch": 39, "training_loss": 507.6988891601562, "training_acc": 60.0, "val_loss": 2032.1112060546875, "val_acc": 60.0}
{"epoch": 40, "training_loss": 2301.5501953125, "training_acc": 50.0, "val_loss": 159.00521850585938, "val_acc": 60.0}
{"epoch": 41, "training_loss": 1835.8733947753906, "training_acc": 40.0, "val_loss": 4151.0712890625, "val_acc": 40.0}
{"epoch": 42, "training_loss": 2751.42783203125, "training_acc": 50.0, "val_loss": 693.8600463867188, "val_acc": 60.0}
{"epoch": 43, "training_loss": 1484.2927978515625, "training_acc": 50.0, "val_loss": 1159.2410888671875, "val_acc": 60.0}
{"epoch": 44, "training_loss": 767.9076263427735, "training_acc": 60.0, "val_loss": 3312.113037109375, "val_acc": 40.0}
{"epoch": 45, "training_loss": 2607.785400390625, "training_acc": 50.0, "val_loss": 688.0927124023438, "val_acc": 40.0}
{"epoch": 46, "training_loss": 1167.0159423828125, "training_acc": 50.0, "val_loss": 1680.4898681640625, "val_acc": 60.0}
{"epoch": 47, "training_loss": 2025.797265625, "training_acc": 30.0, "val_loss": 1693.228515625, "val_acc": 40.0}
{"epoch": 48, "training_loss": 1046.30048828125, "training_acc": 50.0, "val_loss": 1120.2857666015625, "val_acc": 60.0}
