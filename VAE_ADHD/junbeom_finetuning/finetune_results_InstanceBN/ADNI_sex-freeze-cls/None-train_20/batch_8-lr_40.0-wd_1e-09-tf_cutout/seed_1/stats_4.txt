"main_modify.py --pretrained_path None --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 1 --task ADNI_sex --input_option yAware --learning_rate 4e1 --batch_size 8 --weight_decay 1e-9 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 4630.5962304830555, "training_acc": 50.0, "val_loss": 3039.018310546875, "val_acc": 40.0}
{"epoch": 1, "training_loss": 3420.496484375, "training_acc": 50.0, "val_loss": 674.8322143554688, "val_acc": 60.0}
{"epoch": 2, "training_loss": 1388.866943359375, "training_acc": 50.0, "val_loss": 1404.4422607421875, "val_acc": 40.0}
{"epoch": 3, "training_loss": 935.857666015625, "training_acc": 50.0, "val_loss": 656.4055786132812, "val_acc": 60.0}
{"epoch": 4, "training_loss": 517.3577110290528, "training_acc": 40.0, "val_loss": 1430.481201171875, "val_acc": 40.0}
{"epoch": 5, "training_loss": 915.3774154663085, "training_acc": 50.0, "val_loss": 1353.123291015625, "val_acc": 60.0}
{"epoch": 6, "training_loss": 2522.86962890625, "training_acc": 50.0, "val_loss": 836.4750366210938, "val_acc": 60.0}
{"epoch": 7, "training_loss": 1933.354248046875, "training_acc": 40.0, "val_loss": 3179.315673828125, "val_acc": 40.0}
{"epoch": 8, "training_loss": 1811.460791015625, "training_acc": 50.0, "val_loss": 720.76171875, "val_acc": 60.0}
{"epoch": 9, "training_loss": 700.5367553710937, "training_acc": 50.0, "val_loss": 800.9633178710938, "val_acc": 40.0}
{"epoch": 10, "training_loss": 367.45806274414065, "training_acc": 60.0, "val_loss": 1603.577880859375, "val_acc": 60.0}
{"epoch": 11, "training_loss": 1567.372314453125, "training_acc": 50.0, "val_loss": 1351.25, "val_acc": 40.0}
{"epoch": 12, "training_loss": 1612.7517578125, "training_acc": 50.0, "val_loss": 1286.277587890625, "val_acc": 40.0}
{"epoch": 13, "training_loss": 666.0657043457031, "training_acc": 50.0, "val_loss": 2520.384033203125, "val_acc": 60.0}
{"epoch": 14, "training_loss": 3464.352490234375, "training_acc": 50.0, "val_loss": 1238.6904296875, "val_acc": 60.0}
{"epoch": 15, "training_loss": 1530.695263671875, "training_acc": 40.0, "val_loss": 2404.36328125, "val_acc": 40.0}
{"epoch": 16, "training_loss": 1365.74306640625, "training_acc": 50.0, "val_loss": 1473.6605224609375, "val_acc": 60.0}
{"epoch": 17, "training_loss": 2723.087890625, "training_acc": 50.0, "val_loss": 2851.015625, "val_acc": 60.0}
{"epoch": 18, "training_loss": 3114.7451171875, "training_acc": 50.0, "val_loss": 874.1472778320312, "val_acc": 40.0}
{"epoch": 19, "training_loss": 1567.493701171875, "training_acc": 50.0, "val_loss": 621.0852661132812, "val_acc": 40.0}
{"epoch": 20, "training_loss": 1107.8472412109375, "training_acc": 50.0, "val_loss": 1887.5018310546875, "val_acc": 60.0}
{"epoch": 21, "training_loss": 1850.6894287109376, "training_acc": 40.0, "val_loss": 233.43801879882812, "val_acc": 40.0}
{"epoch": 22, "training_loss": 251.20472717285156, "training_acc": 50.0, "val_loss": 504.4212951660156, "val_acc": 60.0}
{"epoch": 23, "training_loss": 616.8271484375, "training_acc": 50.0, "val_loss": 1349.604736328125, "val_acc": 40.0}
{"epoch": 24, "training_loss": 1287.5227294921874, "training_acc": 50.0, "val_loss": 406.5274353027344, "val_acc": 40.0}
{"epoch": 25, "training_loss": 1361.54716796875, "training_acc": 40.0, "val_loss": 1637.3031005859375, "val_acc": 60.0}
{"epoch": 26, "training_loss": 1361.6649780273438, "training_acc": 50.0, "val_loss": 1392.8900146484375, "val_acc": 40.0}
{"epoch": 27, "training_loss": 980.2003448486328, "training_acc": 50.0, "val_loss": 1149.8792724609375, "val_acc": 60.0}
{"epoch": 28, "training_loss": 1817.3787353515625, "training_acc": 50.0, "val_loss": 867.4140625, "val_acc": 60.0}
{"epoch": 29, "training_loss": 227.76888122558594, "training_acc": 70.0, "val_loss": 3887.997802734375, "val_acc": 40.0}
{"epoch": 30, "training_loss": 3401.9921630859376, "training_acc": 50.0, "val_loss": 2923.238525390625, "val_acc": 40.0}
{"epoch": 31, "training_loss": 1987.228955078125, "training_acc": 40.0, "val_loss": 1995.2581787109375, "val_acc": 60.0}
{"epoch": 32, "training_loss": 2331.45673828125, "training_acc": 50.0, "val_loss": 173.84996032714844, "val_acc": 60.0}
{"epoch": 33, "training_loss": 1813.2797119140625, "training_acc": 40.0, "val_loss": 4135.58984375, "val_acc": 40.0}
{"epoch": 34, "training_loss": 2814.870361328125, "training_acc": 50.0, "val_loss": 403.7550964355469, "val_acc": 60.0}
{"epoch": 35, "training_loss": 922.8799560546875, "training_acc": 50.0, "val_loss": 611.23046875, "val_acc": 60.0}
{"epoch": 36, "training_loss": 1155.6808349609375, "training_acc": 40.0, "val_loss": 1054.191650390625, "val_acc": 40.0}
{"epoch": 37, "training_loss": 475.9784240722656, "training_acc": 60.0, "val_loss": 233.62060546875, "val_acc": 60.0}
{"epoch": 38, "training_loss": 681.3211669921875, "training_acc": 50.0, "val_loss": 647.999755859375, "val_acc": 40.0}
{"epoch": 39, "training_loss": 628.5319458007813, "training_acc": 60.0, "val_loss": 423.6585998535156, "val_acc": 60.0}
{"epoch": 40, "training_loss": 1087.2467041015625, "training_acc": 40.0, "val_loss": 1283.42236328125, "val_acc": 40.0}
{"epoch": 41, "training_loss": 706.3458129882813, "training_acc": 50.0, "val_loss": 1992.0816650390625, "val_acc": 60.0}
{"epoch": 42, "training_loss": 2286.875866699219, "training_acc": 50.0, "val_loss": 56.150691986083984, "val_acc": 60.0}
{"epoch": 43, "training_loss": 1679.3669189453126, "training_acc": 50.0, "val_loss": 3406.9765625, "val_acc": 40.0}
{"epoch": 44, "training_loss": 1604.4252685546876, "training_acc": 50.0, "val_loss": 1938.240234375, "val_acc": 60.0}
{"epoch": 45, "training_loss": 3519.168994140625, "training_acc": 50.0, "val_loss": 3853.923583984375, "val_acc": 60.0}
{"epoch": 46, "training_loss": 4054.1002807617188, "training_acc": 50.0, "val_loss": 606.6159057617188, "val_acc": 40.0}
{"epoch": 47, "training_loss": 1186.0271362304688, "training_acc": 50.0, "val_loss": 1342.587158203125, "val_acc": 40.0}
{"epoch": 48, "training_loss": 375.25355072021483, "training_acc": 60.0, "val_loss": 157.28147888183594, "val_acc": 60.0}
{"epoch": 49, "training_loss": 75.75100326538086, "training_acc": 80.0, "val_loss": 402.410888671875, "val_acc": 60.0}
{"epoch": 50, "training_loss": 771.3561157226562, "training_acc": 30.0, "val_loss": 903.9171752929688, "val_acc": 40.0}
{"epoch": 51, "training_loss": 1521.655322265625, "training_acc": 20.0, "val_loss": 438.9867858886719, "val_acc": 60.0}
{"epoch": 52, "training_loss": 827.4068603515625, "training_acc": 50.0, "val_loss": 1600.68359375, "val_acc": 40.0}
{"epoch": 53, "training_loss": 934.0134643554687, "training_acc": 50.0, "val_loss": 1269.870361328125, "val_acc": 60.0}
{"epoch": 54, "training_loss": 1442.6923461914062, "training_acc": 30.0, "val_loss": 42.07896041870117, "val_acc": 60.0}
{"epoch": 55, "training_loss": 246.2337158203125, "training_acc": 40.0, "val_loss": 717.7960815429688, "val_acc": 40.0}
{"epoch": 56, "training_loss": 506.19965209960935, "training_acc": 50.0, "val_loss": 410.5495300292969, "val_acc": 60.0}
{"epoch": 57, "training_loss": 433.5712158203125, "training_acc": 50.0, "val_loss": 648.0243530273438, "val_acc": 60.0}
{"epoch": 58, "training_loss": 961.38759765625, "training_acc": 50.0, "val_loss": 437.1315612792969, "val_acc": 40.0}
{"epoch": 59, "training_loss": 351.3191833496094, "training_acc": 50.0, "val_loss": 788.2595825195312, "val_acc": 60.0}
{"epoch": 60, "training_loss": 1000.921337890625, "training_acc": 50.0, "val_loss": 424.5303649902344, "val_acc": 40.0}
{"epoch": 61, "training_loss": 276.1844337463379, "training_acc": 60.0, "val_loss": 145.3439483642578, "val_acc": 60.0}
{"epoch": 62, "training_loss": 777.7073120117187, "training_acc": 30.0, "val_loss": 157.29928588867188, "val_acc": 60.0}
{"epoch": 63, "training_loss": 254.5141174316406, "training_acc": 50.0, "val_loss": 981.2379150390625, "val_acc": 40.0}
{"epoch": 64, "training_loss": 459.8791060447693, "training_acc": 45.0, "val_loss": 238.11318969726562, "val_acc": 60.0}
{"epoch": 65, "training_loss": 204.53110961914064, "training_acc": 50.0, "val_loss": 480.2547912597656, "val_acc": 40.0}
{"epoch": 66, "training_loss": 427.3048522949219, "training_acc": 30.0, "val_loss": 40.44954299926758, "val_acc": 40.0}
{"epoch": 67, "training_loss": 680.2393218994141, "training_acc": 60.0, "val_loss": 756.9777221679688, "val_acc": 60.0}
{"epoch": 68, "training_loss": 1069.0154052734374, "training_acc": 40.0, "val_loss": 737.1168823242188, "val_acc": 40.0}
{"epoch": 69, "training_loss": 1707.9046875, "training_acc": 20.0, "val_loss": 912.75, "val_acc": 60.0}
{"epoch": 70, "training_loss": 1034.6201049804688, "training_acc": 40.0, "val_loss": 549.8402099609375, "val_acc": 40.0}
{"epoch": 71, "training_loss": 525.2635986328125, "training_acc": 60.0, "val_loss": 515.8601684570312, "val_acc": 60.0}
{"epoch": 72, "training_loss": 539.9383728027344, "training_acc": 50.0, "val_loss": 219.1142578125, "val_acc": 40.0}
{"epoch": 73, "training_loss": 272.18662109375, "training_acc": 70.0, "val_loss": 137.8434600830078, "val_acc": 60.0}
{"epoch": 74, "training_loss": 408.6011962890625, "training_acc": 70.0, "val_loss": 870.2401733398438, "val_acc": 40.0}
{"epoch": 75, "training_loss": 516.0175933837891, "training_acc": 50.0, "val_loss": 90.74857330322266, "val_acc": 60.0}
{"epoch": 76, "training_loss": 620.811279296875, "training_acc": 50.0, "val_loss": 717.4539794921875, "val_acc": 40.0}
{"epoch": 77, "training_loss": 661.348046875, "training_acc": 40.0, "val_loss": 202.63560485839844, "val_acc": 40.0}
{"epoch": 78, "training_loss": 448.3878875732422, "training_acc": 40.0, "val_loss": 516.5167846679688, "val_acc": 60.0}
{"epoch": 79, "training_loss": 494.54486083984375, "training_acc": 50.0, "val_loss": 291.7937927246094, "val_acc": 60.0}
{"epoch": 80, "training_loss": 329.7923217773438, "training_acc": 50.0, "val_loss": 387.47247314453125, "val_acc": 40.0}
{"epoch": 81, "training_loss": 524.7627197265625, "training_acc": 50.0, "val_loss": 170.48635864257812, "val_acc": 40.0}
{"epoch": 82, "training_loss": 514.4070068359375, "training_acc": 30.0, "val_loss": 223.79673767089844, "val_acc": 60.0}
{"epoch": 83, "training_loss": 494.67454833984374, "training_acc": 60.0, "val_loss": 976.8831176757812, "val_acc": 40.0}
{"epoch": 84, "training_loss": 600.0402587890625, "training_acc": 50.0, "val_loss": 1706.5457763671875, "val_acc": 60.0}
{"epoch": 85, "training_loss": 1842.8678771972657, "training_acc": 50.0, "val_loss": 675.22802734375, "val_acc": 40.0}
