"main_modify.py --pretrained_path None --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 5 --task ADNI_sex --input_option yAware --learning_rate 1e0 --batch_size 16 --weight_decay 1e-7 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 17.416154384613037, "training_acc": 50.0, "val_loss": 81.4943618774414, "val_acc": 60.0}
{"epoch": 1, "training_loss": 113.86180419921875, "training_acc": 50.0, "val_loss": 64.75435638427734, "val_acc": 60.0}
{"epoch": 2, "training_loss": 57.764660882949826, "training_acc": 60.0, "val_loss": 68.96432495117188, "val_acc": 40.0}
{"epoch": 3, "training_loss": 59.16392211914062, "training_acc": 50.0, "val_loss": 20.694761276245117, "val_acc": 40.0}
{"epoch": 4, "training_loss": 16.97617530822754, "training_acc": 60.0, "val_loss": 76.4585189819336, "val_acc": 60.0}
{"epoch": 5, "training_loss": 97.94674682617188, "training_acc": 50.0, "val_loss": 64.00394439697266, "val_acc": 60.0}
{"epoch": 6, "training_loss": 67.17333221435547, "training_acc": 50.0, "val_loss": 50.079830169677734, "val_acc": 40.0}
{"epoch": 7, "training_loss": 49.51612854003906, "training_acc": 50.0, "val_loss": 114.70997619628906, "val_acc": 40.0}
{"epoch": 8, "training_loss": 95.081591796875, "training_acc": 50.0, "val_loss": 68.4159164428711, "val_acc": 40.0}
{"epoch": 9, "training_loss": 45.257347106933594, "training_acc": 50.0, "val_loss": 37.591835021972656, "val_acc": 60.0}
{"epoch": 10, "training_loss": 51.076165771484376, "training_acc": 50.0, "val_loss": 79.88997650146484, "val_acc": 60.0}
{"epoch": 11, "training_loss": 99.62354583740235, "training_acc": 50.0, "val_loss": 53.0827751159668, "val_acc": 60.0}
{"epoch": 12, "training_loss": 57.69055709838867, "training_acc": 50.0, "val_loss": 53.22391891479492, "val_acc": 40.0}
{"epoch": 13, "training_loss": 50.961978149414065, "training_acc": 50.0, "val_loss": 107.68287658691406, "val_acc": 40.0}
{"epoch": 14, "training_loss": 86.14122467041015, "training_acc": 50.0, "val_loss": 45.52229690551758, "val_acc": 40.0}
{"epoch": 15, "training_loss": 34.194946670532225, "training_acc": 50.0, "val_loss": 40.58015823364258, "val_acc": 60.0}
{"epoch": 16, "training_loss": 52.9579475402832, "training_acc": 50.0, "val_loss": 33.69809341430664, "val_acc": 60.0}
{"epoch": 17, "training_loss": 33.251261138916014, "training_acc": 50.0, "val_loss": 59.04047775268555, "val_acc": 40.0}
{"epoch": 18, "training_loss": 51.76386947631836, "training_acc": 50.0, "val_loss": 115.87451171875, "val_acc": 40.0}
{"epoch": 19, "training_loss": 94.97510986328125, "training_acc": 50.0, "val_loss": 71.71978759765625, "val_acc": 40.0}
{"epoch": 20, "training_loss": 49.294672298431394, "training_acc": 50.0, "val_loss": 45.490821838378906, "val_acc": 60.0}
{"epoch": 21, "training_loss": 61.54174270629883, "training_acc": 50.0, "val_loss": 92.97434997558594, "val_acc": 60.0}
{"epoch": 22, "training_loss": 116.8162841796875, "training_acc": 50.0, "val_loss": 80.2314224243164, "val_acc": 60.0}
{"epoch": 23, "training_loss": 94.78878631591797, "training_acc": 50.0, "val_loss": 13.916986465454102, "val_acc": 60.0}
{"epoch": 24, "training_loss": 17.532925033569335, "training_acc": 60.0, "val_loss": 110.80510711669922, "val_acc": 40.0}
{"epoch": 25, "training_loss": 93.96841430664062, "training_acc": 50.0, "val_loss": 140.8126983642578, "val_acc": 40.0}
{"epoch": 26, "training_loss": 112.82523193359376, "training_acc": 50.0, "val_loss": 68.1387710571289, "val_acc": 40.0}
{"epoch": 27, "training_loss": 61.920020294189456, "training_acc": 30.0, "val_loss": 27.951038360595703, "val_acc": 60.0}
{"epoch": 28, "training_loss": 35.7404670715332, "training_acc": 50.0, "val_loss": 15.576436042785645, "val_acc": 60.0}
{"epoch": 29, "training_loss": 18.252956581115722, "training_acc": 50.0, "val_loss": 23.071857452392578, "val_acc": 40.0}
{"epoch": 30, "training_loss": 17.32837541103363, "training_acc": 50.0, "val_loss": 15.18647289276123, "val_acc": 60.0}
{"epoch": 31, "training_loss": 20.36150131225586, "training_acc": 50.0, "val_loss": 0.9521150588989258, "val_acc": 60.0}
{"epoch": 32, "training_loss": 8.260088348388672, "training_acc": 50.0, "val_loss": 54.5279655456543, "val_acc": 40.0}
{"epoch": 33, "training_loss": 43.040689086914064, "training_acc": 50.0, "val_loss": 7.709384441375732, "val_acc": 40.0}
{"epoch": 34, "training_loss": 12.861660766601563, "training_acc": 50.0, "val_loss": 48.65639114379883, "val_acc": 60.0}
{"epoch": 35, "training_loss": 61.99739074707031, "training_acc": 50.0, "val_loss": 26.626264572143555, "val_acc": 60.0}
{"epoch": 36, "training_loss": 24.93676061630249, "training_acc": 60.0, "val_loss": 47.17945098876953, "val_acc": 40.0}
{"epoch": 37, "training_loss": 39.44927864074707, "training_acc": 50.0, "val_loss": 43.10188674926758, "val_acc": 40.0}
{"epoch": 38, "training_loss": 32.36473722457886, "training_acc": 50.0, "val_loss": 23.451257705688477, "val_acc": 60.0}
{"epoch": 39, "training_loss": 34.965206909179685, "training_acc": 50.0, "val_loss": 21.83656883239746, "val_acc": 60.0}
{"epoch": 40, "training_loss": 23.999707984924317, "training_acc": 50.0, "val_loss": 23.417781829833984, "val_acc": 40.0}
{"epoch": 41, "training_loss": 17.90141067504883, "training_acc": 50.0, "val_loss": 10.585491180419922, "val_acc": 60.0}
{"epoch": 42, "training_loss": 14.736029052734375, "training_acc": 50.0, "val_loss": 16.62959098815918, "val_acc": 40.0}
{"epoch": 43, "training_loss": 14.480183410644532, "training_acc": 50.0, "val_loss": 5.891047954559326, "val_acc": 40.0}
{"epoch": 44, "training_loss": 9.327572631835938, "training_acc": 50.0, "val_loss": 30.499303817749023, "val_acc": 60.0}
{"epoch": 45, "training_loss": 37.70545558929443, "training_acc": 50.0, "val_loss": 0.983227550983429, "val_acc": 60.0}
{"epoch": 46, "training_loss": 9.304582405090333, "training_acc": 50.0, "val_loss": 64.8246841430664, "val_acc": 40.0}
{"epoch": 47, "training_loss": 52.91437530517578, "training_acc": 50.0, "val_loss": 12.87271785736084, "val_acc": 40.0}
{"epoch": 48, "training_loss": 11.592631530761718, "training_acc": 60.0, "val_loss": 67.0765609741211, "val_acc": 60.0}
{"epoch": 49, "training_loss": 86.21762313842774, "training_acc": 50.0, "val_loss": 78.55427551269531, "val_acc": 60.0}
{"epoch": 50, "training_loss": 94.25507202148438, "training_acc": 50.0, "val_loss": 28.422821044921875, "val_acc": 60.0}
