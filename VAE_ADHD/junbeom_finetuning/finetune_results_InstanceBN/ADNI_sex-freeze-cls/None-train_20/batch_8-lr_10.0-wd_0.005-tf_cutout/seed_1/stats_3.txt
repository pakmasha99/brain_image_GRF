"main_modify.py --pretrained_path None --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 1 --task ADNI_sex --input_option yAware --learning_rate 1e1 --batch_size 8 --weight_decay 5e-3 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 1171.2247534275054, "training_acc": 40.0, "val_loss": 426.4813537597656, "val_acc": 60.0}
{"epoch": 1, "training_loss": 1076.2326904296874, "training_acc": 50.0, "val_loss": 596.1317749023438, "val_acc": 60.0}
{"epoch": 2, "training_loss": 275.8387420654297, "training_acc": 60.0, "val_loss": 588.4472045898438, "val_acc": 40.0}
{"epoch": 3, "training_loss": 346.5905029296875, "training_acc": 50.0, "val_loss": 263.7389831542969, "val_acc": 60.0}
{"epoch": 4, "training_loss": 169.20554809570314, "training_acc": 70.0, "val_loss": 375.25848388671875, "val_acc": 40.0}
{"epoch": 5, "training_loss": 218.034228515625, "training_acc": 50.0, "val_loss": 422.1454162597656, "val_acc": 60.0}
{"epoch": 6, "training_loss": 675.552490234375, "training_acc": 50.0, "val_loss": 381.99884033203125, "val_acc": 60.0}
{"epoch": 7, "training_loss": 262.5829681396484, "training_acc": 60.0, "val_loss": 883.4812622070312, "val_acc": 40.0}
{"epoch": 8, "training_loss": 730.0850830078125, "training_acc": 50.0, "val_loss": 225.5752410888672, "val_acc": 40.0}
{"epoch": 9, "training_loss": 512.2856262207031, "training_acc": 40.0, "val_loss": 610.1446533203125, "val_acc": 60.0}
{"epoch": 10, "training_loss": 568.1598617553711, "training_acc": 50.0, "val_loss": 607.7254638671875, "val_acc": 40.0}
{"epoch": 11, "training_loss": 701.8914306640625, "training_acc": 50.0, "val_loss": 745.8811645507812, "val_acc": 40.0}
{"epoch": 12, "training_loss": 451.21361083984374, "training_acc": 40.0, "val_loss": 564.5343627929688, "val_acc": 60.0}
{"epoch": 13, "training_loss": 674.926156616211, "training_acc": 50.0, "val_loss": 122.0661849975586, "val_acc": 60.0}
{"epoch": 14, "training_loss": 273.6842895507813, "training_acc": 60.0, "val_loss": 622.824462890625, "val_acc": 40.0}
{"epoch": 15, "training_loss": 288.28489379882814, "training_acc": 60.0, "val_loss": 268.9170227050781, "val_acc": 60.0}
{"epoch": 16, "training_loss": 281.7456115722656, "training_acc": 50.0, "val_loss": 294.1679992675781, "val_acc": 40.0}
{"epoch": 17, "training_loss": 306.6603515625, "training_acc": 50.0, "val_loss": 109.55726623535156, "val_acc": 40.0}
{"epoch": 18, "training_loss": 39.56532363891601, "training_acc": 80.0, "val_loss": 67.22047424316406, "val_acc": 60.0}
{"epoch": 19, "training_loss": 84.97974853515625, "training_acc": 60.0, "val_loss": 17.317031860351562, "val_acc": 60.0}
{"epoch": 20, "training_loss": 114.94990310668945, "training_acc": 40.0, "val_loss": 152.90354919433594, "val_acc": 60.0}
{"epoch": 21, "training_loss": 184.17484588623046, "training_acc": 50.0, "val_loss": 345.903076171875, "val_acc": 40.0}
{"epoch": 22, "training_loss": 302.2904571533203, "training_acc": 50.0, "val_loss": 45.54386520385742, "val_acc": 60.0}
{"epoch": 23, "training_loss": 43.96727828979492, "training_acc": 60.0, "val_loss": 146.37667846679688, "val_acc": 40.0}
{"epoch": 24, "training_loss": 139.93108673095702, "training_acc": 40.0, "val_loss": 184.34617614746094, "val_acc": 40.0}
{"epoch": 25, "training_loss": 129.39877700805664, "training_acc": 50.0, "val_loss": 71.21377563476562, "val_acc": 60.0}
{"epoch": 26, "training_loss": 179.7167221069336, "training_acc": 40.0, "val_loss": 4.655796051025391, "val_acc": 40.0}
{"epoch": 27, "training_loss": 142.08641910552979, "training_acc": 60.0, "val_loss": 216.843994140625, "val_acc": 60.0}
{"epoch": 28, "training_loss": 199.05425109863282, "training_acc": 50.0, "val_loss": 597.567138671875, "val_acc": 40.0}
{"epoch": 29, "training_loss": 374.9648803710937, "training_acc": 50.0, "val_loss": 272.9358215332031, "val_acc": 60.0}
{"epoch": 30, "training_loss": 469.68263549804686, "training_acc": 50.0, "val_loss": 407.88653564453125, "val_acc": 60.0}
{"epoch": 31, "training_loss": 531.7890747070312, "training_acc": 30.0, "val_loss": 666.5035400390625, "val_acc": 40.0}
{"epoch": 32, "training_loss": 417.24991607666016, "training_acc": 50.0, "val_loss": 299.4540100097656, "val_acc": 60.0}
{"epoch": 33, "training_loss": 527.8249267578125, "training_acc": 50.0, "val_loss": 308.449462890625, "val_acc": 60.0}
{"epoch": 34, "training_loss": 344.06304321289065, "training_acc": 40.0, "val_loss": 332.3871765136719, "val_acc": 40.0}
{"epoch": 35, "training_loss": 179.53909912109376, "training_acc": 40.0, "val_loss": 79.0979232788086, "val_acc": 40.0}
{"epoch": 36, "training_loss": 77.48380012512207, "training_acc": 50.0, "val_loss": 204.9612579345703, "val_acc": 60.0}
{"epoch": 37, "training_loss": 251.93155517578126, "training_acc": 40.0, "val_loss": 530.5853881835938, "val_acc": 40.0}
{"epoch": 38, "training_loss": 348.47803649902346, "training_acc": 50.0, "val_loss": 344.6853332519531, "val_acc": 60.0}
{"epoch": 39, "training_loss": 691.4792236328125, "training_acc": 50.0, "val_loss": 550.8103637695312, "val_acc": 60.0}
{"epoch": 40, "training_loss": 475.2629669189453, "training_acc": 50.0, "val_loss": 581.4523315429688, "val_acc": 40.0}
{"epoch": 41, "training_loss": 425.00678100585935, "training_acc": 50.0, "val_loss": 76.0359115600586, "val_acc": 60.0}
{"epoch": 42, "training_loss": 115.89450378417969, "training_acc": 50.0, "val_loss": 229.4702911376953, "val_acc": 40.0}
{"epoch": 43, "training_loss": 225.53460083007812, "training_acc": 30.0, "val_loss": 15.00761890411377, "val_acc": 60.0}
{"epoch": 44, "training_loss": 281.6796615600586, "training_acc": 40.0, "val_loss": 325.5604553222656, "val_acc": 40.0}
{"epoch": 45, "training_loss": 192.51663818359376, "training_acc": 50.0, "val_loss": 125.94610595703125, "val_acc": 60.0}
