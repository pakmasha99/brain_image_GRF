"main_modify.py --pretrained_path None --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 1 --task ADNI_sex --input_option yAware --learning_rate 1e1 --batch_size 8 --weight_decay 5e-3 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 1579.317538523674, "training_acc": 45.0, "val_loss": 737.8786010742188, "val_acc": 40.0}
{"epoch": 1, "training_loss": 779.54365234375, "training_acc": 55.0, "val_loss": 1279.7791748046875, "val_acc": 40.0}
{"epoch": 2, "training_loss": 509.0913375854492, "training_acc": 65.0, "val_loss": 365.618408203125, "val_acc": 60.0}
{"epoch": 3, "training_loss": 437.1645874023437, "training_acc": 45.0, "val_loss": 528.0475463867188, "val_acc": 40.0}
{"epoch": 4, "training_loss": 617.2420166015625, "training_acc": 55.0, "val_loss": 708.7465209960938, "val_acc": 40.0}
{"epoch": 5, "training_loss": 387.000341796875, "training_acc": 45.0, "val_loss": 516.64697265625, "val_acc": 60.0}
{"epoch": 6, "training_loss": 637.6696533203125, "training_acc": 45.0, "val_loss": 322.3877868652344, "val_acc": 40.0}
{"epoch": 7, "training_loss": 293.99839477539064, "training_acc": 55.0, "val_loss": 47.723182678222656, "val_acc": 40.0}
{"epoch": 8, "training_loss": 458.59289398193357, "training_acc": 35.0, "val_loss": 495.5978698730469, "val_acc": 60.0}
{"epoch": 9, "training_loss": 528.4184509277344, "training_acc": 35.0, "val_loss": 462.838623046875, "val_acc": 40.0}
{"epoch": 10, "training_loss": 326.80118865966796, "training_acc": 55.0, "val_loss": 131.03712463378906, "val_acc": 60.0}
{"epoch": 11, "training_loss": 261.4616455078125, "training_acc": 45.0, "val_loss": 253.94839477539062, "val_acc": 40.0}
{"epoch": 12, "training_loss": 292.7386749267578, "training_acc": 55.0, "val_loss": 357.7763366699219, "val_acc": 40.0}
{"epoch": 13, "training_loss": 202.7180145263672, "training_acc": 35.0, "val_loss": 126.4509048461914, "val_acc": 40.0}
{"epoch": 14, "training_loss": 135.78598022460938, "training_acc": 55.0, "val_loss": 208.5725555419922, "val_acc": 60.0}
{"epoch": 15, "training_loss": 328.3211730957031, "training_acc": 45.0, "val_loss": 37.95069122314453, "val_acc": 40.0}
{"epoch": 16, "training_loss": 67.4824447631836, "training_acc": 45.0, "val_loss": 30.805500030517578, "val_acc": 40.0}
{"epoch": 17, "training_loss": 56.63738174438477, "training_acc": 45.0, "val_loss": 119.45218658447266, "val_acc": 40.0}
{"epoch": 18, "training_loss": 244.6161865234375, "training_acc": 25.0, "val_loss": 91.73664855957031, "val_acc": 40.0}
{"epoch": 19, "training_loss": 93.36423950195312, "training_acc": 55.0, "val_loss": 152.80105590820312, "val_acc": 60.0}
{"epoch": 20, "training_loss": 204.32756958007812, "training_acc": 45.0, "val_loss": 285.308349609375, "val_acc": 40.0}
{"epoch": 21, "training_loss": 386.1536437988281, "training_acc": 55.0, "val_loss": 277.14825439453125, "val_acc": 40.0}
{"epoch": 22, "training_loss": 363.1104248046875, "training_acc": 35.0, "val_loss": 255.61758422851562, "val_acc": 60.0}
{"epoch": 23, "training_loss": 181.74527130126953, "training_acc": 55.0, "val_loss": 843.0305786132812, "val_acc": 40.0}
{"epoch": 24, "training_loss": 731.5176513671875, "training_acc": 55.0, "val_loss": 571.283203125, "val_acc": 40.0}
{"epoch": 25, "training_loss": 247.8277717590332, "training_acc": 45.0, "val_loss": 197.40835571289062, "val_acc": 60.0}
{"epoch": 26, "training_loss": 196.82060546875, "training_acc": 45.0, "val_loss": 583.8522338867188, "val_acc": 40.0}
{"epoch": 27, "training_loss": 463.6831085205078, "training_acc": 55.0, "val_loss": 4.112054347991943, "val_acc": 60.0}
{"epoch": 28, "training_loss": 263.3418372154236, "training_acc": 45.0, "val_loss": 19.72871208190918, "val_acc": 40.0}
{"epoch": 29, "training_loss": 78.32698516845703, "training_acc": 35.0, "val_loss": 203.74722290039062, "val_acc": 40.0}
{"epoch": 30, "training_loss": 173.46826362609863, "training_acc": 55.0, "val_loss": 151.61013793945312, "val_acc": 60.0}
{"epoch": 31, "training_loss": 216.55951919555665, "training_acc": 35.0, "val_loss": 33.04767608642578, "val_acc": 60.0}
{"epoch": 32, "training_loss": 26.01409602165222, "training_acc": 55.0, "val_loss": 333.2978210449219, "val_acc": 40.0}
{"epoch": 33, "training_loss": 264.5839050292969, "training_acc": 55.0, "val_loss": 84.28585052490234, "val_acc": 40.0}
{"epoch": 34, "training_loss": 173.53228759765625, "training_acc": 55.0, "val_loss": 154.3422393798828, "val_acc": 60.0}
{"epoch": 35, "training_loss": 104.8340850830078, "training_acc": 65.0, "val_loss": 132.45701599121094, "val_acc": 40.0}
{"epoch": 36, "training_loss": 89.56365051269532, "training_acc": 55.0, "val_loss": 114.51122283935547, "val_acc": 40.0}
{"epoch": 37, "training_loss": 105.19212980270386, "training_acc": 55.0, "val_loss": 266.52069091796875, "val_acc": 60.0}
{"epoch": 38, "training_loss": 386.13841400146487, "training_acc": 45.0, "val_loss": 57.78167724609375, "val_acc": 40.0}
{"epoch": 39, "training_loss": 72.08182373046876, "training_acc": 45.0, "val_loss": 124.0766372680664, "val_acc": 40.0}
{"epoch": 40, "training_loss": 65.12547416687012, "training_acc": 65.0, "val_loss": 71.34901428222656, "val_acc": 60.0}
{"epoch": 41, "training_loss": 145.71615142822264, "training_acc": 45.0, "val_loss": 82.53136444091797, "val_acc": 60.0}
{"epoch": 42, "training_loss": 101.38303833007812, "training_acc": 45.0, "val_loss": 10.0075044631958, "val_acc": 40.0}
{"epoch": 43, "training_loss": 28.863006687164308, "training_acc": 75.0, "val_loss": 144.9030303955078, "val_acc": 40.0}
{"epoch": 44, "training_loss": 87.06047296524048, "training_acc": 65.0, "val_loss": 43.176918029785156, "val_acc": 60.0}
{"epoch": 45, "training_loss": 226.74322509765625, "training_acc": 25.0, "val_loss": 20.825435638427734, "val_acc": 60.0}
{"epoch": 46, "training_loss": 72.29971618652344, "training_acc": 45.0, "val_loss": 93.82327270507812, "val_acc": 40.0}
