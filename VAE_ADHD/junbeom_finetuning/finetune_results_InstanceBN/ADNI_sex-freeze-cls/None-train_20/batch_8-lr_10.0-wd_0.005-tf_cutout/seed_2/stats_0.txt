"main_modify.py --pretrained_path None --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 2 --task ADNI_sex --input_option yAware --learning_rate 1e1 --batch_size 8 --weight_decay 5e-3 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 1211.3652387857437, "training_acc": 50.0, "val_loss": 827.9185791015625, "val_acc": 60.0}
{"epoch": 1, "training_loss": 1205.755029296875, "training_acc": 50.0, "val_loss": 578.0187377929688, "val_acc": 60.0}
{"epoch": 2, "training_loss": 506.0479675292969, "training_acc": 40.0, "val_loss": 366.540771484375, "val_acc": 40.0}
{"epoch": 3, "training_loss": 179.87138977050782, "training_acc": 50.0, "val_loss": 126.58642578125, "val_acc": 40.0}
{"epoch": 4, "training_loss": 73.05179977416992, "training_acc": 50.0, "val_loss": 143.19837951660156, "val_acc": 40.0}
{"epoch": 5, "training_loss": 199.653515625, "training_acc": 40.0, "val_loss": 124.37818908691406, "val_acc": 40.0}
{"epoch": 6, "training_loss": 141.46461791992186, "training_acc": 40.0, "val_loss": 69.67049407958984, "val_acc": 40.0}
{"epoch": 7, "training_loss": 142.60587158203126, "training_acc": 40.0, "val_loss": 242.4546356201172, "val_acc": 60.0}
{"epoch": 8, "training_loss": 170.6798126220703, "training_acc": 60.0, "val_loss": 459.3279724121094, "val_acc": 40.0}
{"epoch": 9, "training_loss": 365.851806640625, "training_acc": 50.0, "val_loss": 216.07188415527344, "val_acc": 60.0}
{"epoch": 10, "training_loss": 278.96751098632814, "training_acc": 50.0, "val_loss": 179.5206298828125, "val_acc": 40.0}
{"epoch": 11, "training_loss": 232.48635864257812, "training_acc": 50.0, "val_loss": 28.90827751159668, "val_acc": 60.0}
{"epoch": 12, "training_loss": 42.671879577636716, "training_acc": 50.0, "val_loss": 18.855167388916016, "val_acc": 60.0}
{"epoch": 13, "training_loss": 82.71523742675781, "training_acc": 40.0, "val_loss": 217.7190399169922, "val_acc": 60.0}
{"epoch": 14, "training_loss": 378.7943115234375, "training_acc": 50.0, "val_loss": 22.824337005615234, "val_acc": 60.0}
{"epoch": 15, "training_loss": 460.6607894897461, "training_acc": 40.0, "val_loss": 1064.7596435546875, "val_acc": 40.0}
{"epoch": 16, "training_loss": 716.9335815429688, "training_acc": 50.0, "val_loss": 125.8708267211914, "val_acc": 60.0}
{"epoch": 17, "training_loss": 263.8633178710937, "training_acc": 50.0, "val_loss": 216.9971160888672, "val_acc": 60.0}
{"epoch": 18, "training_loss": 195.75093994140624, "training_acc": 50.0, "val_loss": 646.5250854492188, "val_acc": 40.0}
{"epoch": 19, "training_loss": 463.11448669433594, "training_acc": 50.0, "val_loss": 153.9252166748047, "val_acc": 60.0}
{"epoch": 20, "training_loss": 190.60297241210938, "training_acc": 50.0, "val_loss": 125.2337417602539, "val_acc": 40.0}
{"epoch": 21, "training_loss": 121.16781921386719, "training_acc": 40.0, "val_loss": 6.770745754241943, "val_acc": 40.0}
{"epoch": 22, "training_loss": 35.91347408294678, "training_acc": 50.0, "val_loss": 372.92364501953125, "val_acc": 40.0}
{"epoch": 23, "training_loss": 327.4314880371094, "training_acc": 50.0, "val_loss": 2.917496681213379, "val_acc": 60.0}
{"epoch": 24, "training_loss": 93.80187225341797, "training_acc": 50.0, "val_loss": 256.9592590332031, "val_acc": 40.0}
{"epoch": 25, "training_loss": 219.60095672607423, "training_acc": 50.0, "val_loss": 154.30178833007812, "val_acc": 60.0}
{"epoch": 26, "training_loss": 234.727880859375, "training_acc": 50.0, "val_loss": 127.91082763671875, "val_acc": 40.0}
{"epoch": 27, "training_loss": 120.77521332502366, "training_acc": 50.0, "val_loss": 52.17437744140625, "val_acc": 60.0}
{"epoch": 28, "training_loss": 54.260221529006955, "training_acc": 50.0, "val_loss": 147.12579345703125, "val_acc": 40.0}
{"epoch": 29, "training_loss": 151.38724365234376, "training_acc": 40.0, "val_loss": 209.826416015625, "val_acc": 60.0}
{"epoch": 30, "training_loss": 304.5291412353516, "training_acc": 30.0, "val_loss": 539.0369873046875, "val_acc": 40.0}
{"epoch": 31, "training_loss": 305.061222076416, "training_acc": 50.0, "val_loss": 144.7944793701172, "val_acc": 60.0}
{"epoch": 32, "training_loss": 147.75242462158204, "training_acc": 50.0, "val_loss": 301.7894287109375, "val_acc": 40.0}
{"epoch": 33, "training_loss": 253.42606048583986, "training_acc": 40.0, "val_loss": 285.93609619140625, "val_acc": 60.0}
{"epoch": 34, "training_loss": 310.34100341796875, "training_acc": 40.0, "val_loss": 396.9803161621094, "val_acc": 40.0}
{"epoch": 35, "training_loss": 199.5464771270752, "training_acc": 60.0, "val_loss": 141.1109161376953, "val_acc": 60.0}
{"epoch": 36, "training_loss": 113.98631286621094, "training_acc": 60.0, "val_loss": 189.3471221923828, "val_acc": 40.0}
{"epoch": 37, "training_loss": 99.13508453369141, "training_acc": 40.0, "val_loss": 30.289276123046875, "val_acc": 60.0}
{"epoch": 38, "training_loss": 91.41656475067138, "training_acc": 40.0, "val_loss": 6.910647869110107, "val_acc": 40.0}
{"epoch": 39, "training_loss": 31.237600326538086, "training_acc": 50.0, "val_loss": 149.96414184570312, "val_acc": 40.0}
{"epoch": 40, "training_loss": 66.21224565505982, "training_acc": 50.0, "val_loss": 117.05256652832031, "val_acc": 60.0}
{"epoch": 41, "training_loss": 125.01555786132812, "training_acc": 50.0, "val_loss": 214.94497680664062, "val_acc": 40.0}
{"epoch": 42, "training_loss": 102.98946800231934, "training_acc": 60.0, "val_loss": 363.97015380859375, "val_acc": 60.0}
