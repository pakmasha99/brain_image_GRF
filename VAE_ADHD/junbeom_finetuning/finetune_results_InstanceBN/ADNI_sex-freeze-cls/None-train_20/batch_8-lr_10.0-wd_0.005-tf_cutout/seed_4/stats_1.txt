"main_modify.py --pretrained_path None --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 4 --task ADNI_sex --input_option yAware --learning_rate 1e1 --batch_size 8 --weight_decay 5e-3 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 986.3725960731506, "training_acc": 50.0, "val_loss": 1386.6673583984375, "val_acc": 40.0}
{"epoch": 1, "training_loss": 1638.782861328125, "training_acc": 50.0, "val_loss": 1219.9241943359375, "val_acc": 40.0}
{"epoch": 2, "training_loss": 428.3450225830078, "training_acc": 60.0, "val_loss": 1552.113037109375, "val_acc": 60.0}
{"epoch": 3, "training_loss": 2167.50078125, "training_acc": 50.0, "val_loss": 1482.3892822265625, "val_acc": 60.0}
{"epoch": 4, "training_loss": 1256.5090881347655, "training_acc": 50.0, "val_loss": 868.1232299804688, "val_acc": 40.0}
{"epoch": 5, "training_loss": 1449.611865234375, "training_acc": 50.0, "val_loss": 2189.564208984375, "val_acc": 40.0}
{"epoch": 6, "training_loss": 1578.8815673828126, "training_acc": 50.0, "val_loss": 667.6957397460938, "val_acc": 40.0}
{"epoch": 7, "training_loss": 300.4874328613281, "training_acc": 70.0, "val_loss": 848.9733276367188, "val_acc": 60.0}
{"epoch": 8, "training_loss": 1032.0168701171874, "training_acc": 50.0, "val_loss": 445.1611328125, "val_acc": 60.0}
{"epoch": 9, "training_loss": 287.8543508529663, "training_acc": 50.0, "val_loss": 496.9559631347656, "val_acc": 40.0}
{"epoch": 10, "training_loss": 328.000553894043, "training_acc": 40.0, "val_loss": 51.800453186035156, "val_acc": 60.0}
{"epoch": 11, "training_loss": 123.47990570068359, "training_acc": 40.0, "val_loss": 101.76203918457031, "val_acc": 60.0}
{"epoch": 12, "training_loss": 200.62010192871094, "training_acc": 30.0, "val_loss": 39.86820983886719, "val_acc": 60.0}
{"epoch": 13, "training_loss": 108.46283264160157, "training_acc": 40.0, "val_loss": 295.1117248535156, "val_acc": 40.0}
{"epoch": 14, "training_loss": 179.05725708007813, "training_acc": 50.0, "val_loss": 342.6839294433594, "val_acc": 60.0}
{"epoch": 15, "training_loss": 341.40517272949216, "training_acc": 50.0, "val_loss": 331.7310485839844, "val_acc": 40.0}
{"epoch": 16, "training_loss": 387.0369018554687, "training_acc": 50.0, "val_loss": 248.91844177246094, "val_acc": 40.0}
{"epoch": 17, "training_loss": 280.9118408203125, "training_acc": 50.0, "val_loss": 310.9245300292969, "val_acc": 60.0}
{"epoch": 18, "training_loss": 254.94359130859374, "training_acc": 50.0, "val_loss": 471.77880859375, "val_acc": 40.0}
{"epoch": 19, "training_loss": 357.3046936035156, "training_acc": 50.0, "val_loss": 143.950439453125, "val_acc": 60.0}
{"epoch": 20, "training_loss": 346.34222717285155, "training_acc": 50.0, "val_loss": 176.3142852783203, "val_acc": 60.0}
{"epoch": 21, "training_loss": 168.04986572265625, "training_acc": 50.0, "val_loss": 135.16079711914062, "val_acc": 40.0}
{"epoch": 22, "training_loss": 49.691802978515625, "training_acc": 70.0, "val_loss": 5.955756664276123, "val_acc": 60.0}
{"epoch": 23, "training_loss": 213.71852416992186, "training_acc": 40.0, "val_loss": 193.7999267578125, "val_acc": 40.0}
{"epoch": 24, "training_loss": 189.99236450195312, "training_acc": 50.0, "val_loss": 155.57225036621094, "val_acc": 60.0}
{"epoch": 25, "training_loss": 210.9962127685547, "training_acc": 40.0, "val_loss": 28.97540855407715, "val_acc": 40.0}
{"epoch": 26, "training_loss": 161.47384033203124, "training_acc": 60.0, "val_loss": 291.7441101074219, "val_acc": 60.0}
{"epoch": 27, "training_loss": 291.9132255554199, "training_acc": 50.0, "val_loss": 528.3580322265625, "val_acc": 40.0}
{"epoch": 28, "training_loss": 345.5367065429688, "training_acc": 50.0, "val_loss": 249.7767791748047, "val_acc": 60.0}
{"epoch": 29, "training_loss": 529.2411987304688, "training_acc": 50.0, "val_loss": 254.8896026611328, "val_acc": 60.0}
{"epoch": 30, "training_loss": 152.27247772216796, "training_acc": 60.0, "val_loss": 232.66392517089844, "val_acc": 40.0}
{"epoch": 31, "training_loss": 209.2657897949219, "training_acc": 30.0, "val_loss": 95.27447509765625, "val_acc": 40.0}
{"epoch": 32, "training_loss": 56.435581588745116, "training_acc": 60.0, "val_loss": 137.02061462402344, "val_acc": 60.0}
{"epoch": 33, "training_loss": 184.3722686767578, "training_acc": 40.0, "val_loss": 495.3910827636719, "val_acc": 40.0}
{"epoch": 34, "training_loss": 252.01884765625, "training_acc": 50.0, "val_loss": 419.10302734375, "val_acc": 60.0}
{"epoch": 35, "training_loss": 657.0145263671875, "training_acc": 50.0, "val_loss": 541.57373046875, "val_acc": 60.0}
{"epoch": 36, "training_loss": 637.6634643554687, "training_acc": 30.0, "val_loss": 561.8497314453125, "val_acc": 40.0}
{"epoch": 37, "training_loss": 373.8656799316406, "training_acc": 50.0, "val_loss": 225.747802734375, "val_acc": 60.0}
{"epoch": 38, "training_loss": 439.6471313476562, "training_acc": 50.0, "val_loss": 207.1872100830078, "val_acc": 60.0}
{"epoch": 39, "training_loss": 104.6145004272461, "training_acc": 70.0, "val_loss": 227.20401000976562, "val_acc": 40.0}
{"epoch": 40, "training_loss": 150.0179901123047, "training_acc": 40.0, "val_loss": 123.5409927368164, "val_acc": 40.0}
{"epoch": 41, "training_loss": 134.20663146972657, "training_acc": 40.0, "val_loss": 98.8893814086914, "val_acc": 60.0}
