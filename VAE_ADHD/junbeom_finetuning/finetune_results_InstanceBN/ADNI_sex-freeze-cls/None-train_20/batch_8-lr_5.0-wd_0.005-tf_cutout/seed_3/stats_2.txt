"main_modify.py --pretrained_path None --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 3 --task ADNI_sex --input_option yAware --learning_rate 5e0 --batch_size 8 --weight_decay 5e-3 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 600.1182106256485, "training_acc": 50.0, "val_loss": 644.208984375, "val_acc": 40.0}
{"epoch": 1, "training_loss": 785.951953125, "training_acc": 50.0, "val_loss": 647.9384765625, "val_acc": 40.0}
{"epoch": 2, "training_loss": 447.5786926269531, "training_acc": 40.0, "val_loss": 577.5324096679688, "val_acc": 60.0}
{"epoch": 3, "training_loss": 713.67353515625, "training_acc": 50.0, "val_loss": 299.9882507324219, "val_acc": 60.0}
{"epoch": 4, "training_loss": 275.9999481201172, "training_acc": 30.0, "val_loss": 259.2146911621094, "val_acc": 40.0}
{"epoch": 5, "training_loss": 149.51884841918945, "training_acc": 50.0, "val_loss": 80.59080505371094, "val_acc": 60.0}
{"epoch": 6, "training_loss": 65.87294654846191, "training_acc": 60.0, "val_loss": 144.0113525390625, "val_acc": 40.0}
{"epoch": 7, "training_loss": 116.21422576904297, "training_acc": 40.0, "val_loss": 102.5228042602539, "val_acc": 60.0}
{"epoch": 8, "training_loss": 72.77894821166993, "training_acc": 60.0, "val_loss": 253.073486328125, "val_acc": 40.0}
{"epoch": 9, "training_loss": 218.0645294189453, "training_acc": 50.0, "val_loss": 55.106056213378906, "val_acc": 60.0}
{"epoch": 10, "training_loss": 108.15266723632813, "training_acc": 50.0, "val_loss": 40.1014518737793, "val_acc": 60.0}
{"epoch": 11, "training_loss": 133.18036193847655, "training_acc": 40.0, "val_loss": 155.1903839111328, "val_acc": 40.0}
{"epoch": 12, "training_loss": 104.2130844116211, "training_acc": 40.0, "val_loss": 12.543242454528809, "val_acc": 60.0}
{"epoch": 13, "training_loss": 130.72972106933594, "training_acc": 40.0, "val_loss": 168.47305297851562, "val_acc": 40.0}
{"epoch": 14, "training_loss": 64.16866455078124, "training_acc": 60.0, "val_loss": 248.026611328125, "val_acc": 60.0}
{"epoch": 15, "training_loss": 316.4255676269531, "training_acc": 50.0, "val_loss": 85.22344970703125, "val_acc": 60.0}
{"epoch": 16, "training_loss": 231.75646362304687, "training_acc": 40.0, "val_loss": 418.60888671875, "val_acc": 40.0}
{"epoch": 17, "training_loss": 270.55997610092163, "training_acc": 40.0, "val_loss": 38.344783782958984, "val_acc": 60.0}
{"epoch": 18, "training_loss": 32.401693725585936, "training_acc": 60.0, "val_loss": 197.37147521972656, "val_acc": 40.0}
{"epoch": 19, "training_loss": 105.36341133117676, "training_acc": 50.0, "val_loss": 185.4258575439453, "val_acc": 60.0}
{"epoch": 20, "training_loss": 335.5199401855469, "training_acc": 50.0, "val_loss": 231.97048950195312, "val_acc": 60.0}
{"epoch": 21, "training_loss": 223.072412109375, "training_acc": 40.0, "val_loss": 347.06451416015625, "val_acc": 40.0}
{"epoch": 22, "training_loss": 283.93829345703125, "training_acc": 50.0, "val_loss": 31.773895263671875, "val_acc": 40.0}
{"epoch": 23, "training_loss": 183.05696563720704, "training_acc": 60.0, "val_loss": 357.06329345703125, "val_acc": 60.0}
{"epoch": 24, "training_loss": 375.48130187988284, "training_acc": 50.0, "val_loss": 88.52733612060547, "val_acc": 40.0}
{"epoch": 25, "training_loss": 142.65377502441407, "training_acc": 50.0, "val_loss": 88.29351043701172, "val_acc": 40.0}
{"epoch": 26, "training_loss": 154.84718475341796, "training_acc": 40.0, "val_loss": 186.90484619140625, "val_acc": 60.0}
{"epoch": 27, "training_loss": 137.9852165222168, "training_acc": 60.0, "val_loss": 121.32545471191406, "val_acc": 40.0}
{"epoch": 28, "training_loss": 66.07249927520752, "training_acc": 60.0, "val_loss": 39.70493698120117, "val_acc": 60.0}
{"epoch": 29, "training_loss": 30.251148414611816, "training_acc": 50.0, "val_loss": 10.027167320251465, "val_acc": 40.0}
{"epoch": 30, "training_loss": 14.151610565185546, "training_acc": 60.0, "val_loss": 13.414794921875, "val_acc": 60.0}
{"epoch": 31, "training_loss": 18.71515312194824, "training_acc": 50.0, "val_loss": 132.1195526123047, "val_acc": 60.0}
{"epoch": 32, "training_loss": 173.53054122924806, "training_acc": 50.0, "val_loss": 5.762998580932617, "val_acc": 60.0}
{"epoch": 33, "training_loss": 66.24184150695801, "training_acc": 70.0, "val_loss": 258.1012878417969, "val_acc": 40.0}
{"epoch": 34, "training_loss": 147.07296600341797, "training_acc": 50.0, "val_loss": 110.4276351928711, "val_acc": 60.0}
{"epoch": 35, "training_loss": 94.49384460449218, "training_acc": 50.0, "val_loss": 287.6531677246094, "val_acc": 40.0}
{"epoch": 36, "training_loss": 438.78131713867185, "training_acc": 50.0, "val_loss": 396.6904296875, "val_acc": 40.0}
{"epoch": 37, "training_loss": 178.97025146484376, "training_acc": 60.0, "val_loss": 337.5733947753906, "val_acc": 60.0}
{"epoch": 38, "training_loss": 532.7273071289062, "training_acc": 50.0, "val_loss": 319.12066650390625, "val_acc": 60.0}
{"epoch": 39, "training_loss": 237.91533203125, "training_acc": 50.0, "val_loss": 403.07891845703125, "val_acc": 40.0}
{"epoch": 40, "training_loss": 354.36521606445314, "training_acc": 50.0, "val_loss": 246.02061462402344, "val_acc": 40.0}
{"epoch": 41, "training_loss": 131.99192504882814, "training_acc": 50.0, "val_loss": 141.68309020996094, "val_acc": 60.0}
{"epoch": 42, "training_loss": 149.6994659423828, "training_acc": 40.0, "val_loss": 183.6498260498047, "val_acc": 40.0}
{"epoch": 43, "training_loss": 113.72510375976563, "training_acc": 50.0, "val_loss": 110.4171371459961, "val_acc": 60.0}
{"epoch": 44, "training_loss": 104.47755584716796, "training_acc": 50.0, "val_loss": 163.36415100097656, "val_acc": 40.0}
{"epoch": 45, "training_loss": 126.24043579101563, "training_acc": 40.0, "val_loss": 118.0775375366211, "val_acc": 60.0}
{"epoch": 46, "training_loss": 147.36473846435547, "training_acc": 40.0, "val_loss": 253.5084991455078, "val_acc": 40.0}
{"epoch": 47, "training_loss": 125.7036644935608, "training_acc": 60.0, "val_loss": 67.12284088134766, "val_acc": 60.0}
{"epoch": 48, "training_loss": 74.73166351318359, "training_acc": 50.0, "val_loss": 71.63118743896484, "val_acc": 40.0}
{"epoch": 49, "training_loss": 18.677057528495787, "training_acc": 60.0, "val_loss": 71.63885498046875, "val_acc": 60.0}
{"epoch": 50, "training_loss": 69.34412250518798, "training_acc": 50.0, "val_loss": 264.5567626953125, "val_acc": 40.0}
{"epoch": 51, "training_loss": 239.89745330810547, "training_acc": 50.0, "val_loss": 210.23240661621094, "val_acc": 40.0}
