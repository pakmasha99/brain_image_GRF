"main_modify.py --pretrained_path None --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 5 --task ADNI_sex --input_option yAware --learning_rate 5e0 --batch_size 8 --weight_decay 5e-3 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 650.1967972517014, "training_acc": 40.0, "val_loss": 116.97466278076172, "val_acc": 60.0}
{"epoch": 1, "training_loss": 187.71297607421874, "training_acc": 50.0, "val_loss": 156.43931579589844, "val_acc": 40.0}
{"epoch": 2, "training_loss": 143.26940231323243, "training_acc": 40.0, "val_loss": 82.24260711669922, "val_acc": 40.0}
{"epoch": 3, "training_loss": 135.2609405517578, "training_acc": 30.0, "val_loss": 170.2302703857422, "val_acc": 60.0}
{"epoch": 4, "training_loss": 141.317919921875, "training_acc": 50.0, "val_loss": 291.8366394042969, "val_acc": 40.0}
{"epoch": 5, "training_loss": 214.02632904052734, "training_acc": 50.0, "val_loss": 101.96721649169922, "val_acc": 60.0}
{"epoch": 6, "training_loss": 156.964453125, "training_acc": 50.0, "val_loss": 3.5193030834198, "val_acc": 40.0}
{"epoch": 7, "training_loss": 49.30566053390503, "training_acc": 40.0, "val_loss": 18.39753532409668, "val_acc": 40.0}
{"epoch": 8, "training_loss": 8.166255950927734, "training_acc": 70.0, "val_loss": 1.3014204502105713, "val_acc": 40.0}
{"epoch": 9, "training_loss": 84.8793719291687, "training_acc": 40.0, "val_loss": 24.17767333984375, "val_acc": 40.0}
{"epoch": 10, "training_loss": 44.409361743927, "training_acc": 50.0, "val_loss": 128.2584228515625, "val_acc": 60.0}
{"epoch": 11, "training_loss": 224.7567352294922, "training_acc": 50.0, "val_loss": 29.444355010986328, "val_acc": 60.0}
{"epoch": 12, "training_loss": 184.1554153442383, "training_acc": 40.0, "val_loss": 406.47607421875, "val_acc": 40.0}
{"epoch": 13, "training_loss": 268.1286315917969, "training_acc": 50.0, "val_loss": 107.4334487915039, "val_acc": 60.0}
{"epoch": 14, "training_loss": 189.5212158203125, "training_acc": 50.0, "val_loss": 138.4875030517578, "val_acc": 60.0}
{"epoch": 15, "training_loss": 82.05305252075195, "training_acc": 60.0, "val_loss": 442.3951110839844, "val_acc": 40.0}
{"epoch": 16, "training_loss": 376.7779174804688, "training_acc": 50.0, "val_loss": 206.3217315673828, "val_acc": 40.0}
{"epoch": 17, "training_loss": 77.23958835601806, "training_acc": 60.0, "val_loss": 337.5576171875, "val_acc": 60.0}
{"epoch": 18, "training_loss": 445.2937805175781, "training_acc": 50.0, "val_loss": 211.95848083496094, "val_acc": 60.0}
{"epoch": 19, "training_loss": 174.47570190429687, "training_acc": 50.0, "val_loss": 497.4264831542969, "val_acc": 40.0}
{"epoch": 20, "training_loss": 475.3459777832031, "training_acc": 50.0, "val_loss": 323.5980224609375, "val_acc": 40.0}
{"epoch": 21, "training_loss": 185.71568069458007, "training_acc": 40.0, "val_loss": 115.45784759521484, "val_acc": 60.0}
{"epoch": 22, "training_loss": 81.47466278076172, "training_acc": 60.0, "val_loss": 306.6695556640625, "val_acc": 40.0}
{"epoch": 23, "training_loss": 228.27840270996094, "training_acc": 50.0, "val_loss": 43.33198165893555, "val_acc": 60.0}
{"epoch": 24, "training_loss": 71.75366287231445, "training_acc": 50.0, "val_loss": 0.7111881375312805, "val_acc": 40.0}
{"epoch": 25, "training_loss": 33.719122767448425, "training_acc": 50.0, "val_loss": 87.88118743896484, "val_acc": 40.0}
{"epoch": 26, "training_loss": 68.94107513427734, "training_acc": 50.0, "val_loss": 48.85226058959961, "val_acc": 60.0}
{"epoch": 27, "training_loss": 108.49266357421875, "training_acc": 30.0, "val_loss": 56.901893615722656, "val_acc": 60.0}
{"epoch": 28, "training_loss": 119.05655212402344, "training_acc": 50.0, "val_loss": 46.49899673461914, "val_acc": 40.0}
{"epoch": 29, "training_loss": 51.42948913574219, "training_acc": 40.0, "val_loss": 19.666858673095703, "val_acc": 40.0}
{"epoch": 30, "training_loss": 14.802422046661377, "training_acc": 60.0, "val_loss": 1.6747292280197144, "val_acc": 60.0}
{"epoch": 31, "training_loss": 66.27843933105468, "training_acc": 40.0, "val_loss": 42.178035736083984, "val_acc": 60.0}
{"epoch": 32, "training_loss": 63.76804656982422, "training_acc": 50.0, "val_loss": 213.725830078125, "val_acc": 40.0}
{"epoch": 33, "training_loss": 239.94190368652343, "training_acc": 50.0, "val_loss": 219.51158142089844, "val_acc": 40.0}
{"epoch": 34, "training_loss": 125.71995048522949, "training_acc": 50.0, "val_loss": 286.3648986816406, "val_acc": 60.0}
{"epoch": 35, "training_loss": 352.0318771362305, "training_acc": 50.0, "val_loss": 75.4524917602539, "val_acc": 60.0}
{"epoch": 36, "training_loss": 251.57354125976562, "training_acc": 30.0, "val_loss": 361.1605529785156, "val_acc": 40.0}
{"epoch": 37, "training_loss": 197.5430877685547, "training_acc": 50.0, "val_loss": 102.95763397216797, "val_acc": 60.0}
{"epoch": 38, "training_loss": 112.92515258789062, "training_acc": 40.0, "val_loss": 20.28133201599121, "val_acc": 40.0}
{"epoch": 39, "training_loss": 67.16626205444337, "training_acc": 50.0, "val_loss": 22.3866024017334, "val_acc": 60.0}
{"epoch": 40, "training_loss": 45.11327705383301, "training_acc": 70.0, "val_loss": 75.79782104492188, "val_acc": 40.0}
{"epoch": 41, "training_loss": 58.512875366210935, "training_acc": 60.0, "val_loss": 32.51934814453125, "val_acc": 60.0}
{"epoch": 42, "training_loss": 117.3490966796875, "training_acc": 40.0, "val_loss": 139.4231414794922, "val_acc": 40.0}
{"epoch": 43, "training_loss": 83.94491882324219, "training_acc": 50.0, "val_loss": 198.1929168701172, "val_acc": 60.0}
