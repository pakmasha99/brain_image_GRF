"main_modify.py --pretrained_path None --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 4 --task ADNI_sex --input_option yAware --learning_rate 3e1 --batch_size 16 --weight_decay 2e-9 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 1288.6978286743165, "training_acc": 50.0, "val_loss": 2214.5791015625, "val_acc": 40.0}
{"epoch": 1, "training_loss": 2737.3130859375, "training_acc": 40.0, "val_loss": 3281.460693359375, "val_acc": 60.0}
{"epoch": 2, "training_loss": 3975.0202392578126, "training_acc": 50.0, "val_loss": 870.3935546875, "val_acc": 60.0}
{"epoch": 3, "training_loss": 1477.2609375, "training_acc": 40.0, "val_loss": 2674.655029296875, "val_acc": 40.0}
{"epoch": 4, "training_loss": 2228.8330078125, "training_acc": 50.0, "val_loss": 1047.691650390625, "val_acc": 40.0}
{"epoch": 5, "training_loss": 658.0715362548829, "training_acc": 60.0, "val_loss": 976.8952026367188, "val_acc": 60.0}
{"epoch": 6, "training_loss": 1187.9401245117188, "training_acc": 50.0, "val_loss": 161.16566467285156, "val_acc": 60.0}
{"epoch": 7, "training_loss": 576.751416015625, "training_acc": 40.0, "val_loss": 1760.361328125, "val_acc": 40.0}
{"epoch": 8, "training_loss": 1306.7888671875, "training_acc": 50.0, "val_loss": 474.8525390625, "val_acc": 60.0}
{"epoch": 9, "training_loss": 646.85322265625, "training_acc": 50.0, "val_loss": 1043.96484375, "val_acc": 60.0}
{"epoch": 10, "training_loss": 1190.1859252929687, "training_acc": 50.0, "val_loss": 531.3054809570312, "val_acc": 40.0}
{"epoch": 11, "training_loss": 470.8022155761719, "training_acc": 50.0, "val_loss": 784.3761596679688, "val_acc": 40.0}
{"epoch": 12, "training_loss": 540.4110504150391, "training_acc": 50.0, "val_loss": 72.22415924072266, "val_acc": 60.0}
{"epoch": 13, "training_loss": 276.23975830078126, "training_acc": 40.0, "val_loss": 421.73980712890625, "val_acc": 40.0}
{"epoch": 14, "training_loss": 394.51463623046874, "training_acc": 50.0, "val_loss": 609.3402709960938, "val_acc": 60.0}
{"epoch": 15, "training_loss": 661.5007995605469, "training_acc": 50.0, "val_loss": 937.44970703125, "val_acc": 40.0}
{"epoch": 16, "training_loss": 843.6571044921875, "training_acc": 50.0, "val_loss": 899.1266479492188, "val_acc": 40.0}
{"epoch": 17, "training_loss": 886.7344360351562, "training_acc": 30.0, "val_loss": 74.69377899169922, "val_acc": 60.0}
{"epoch": 18, "training_loss": 129.71290283203126, "training_acc": 60.0, "val_loss": 1280.0416259765625, "val_acc": 40.0}
{"epoch": 19, "training_loss": 1031.95458984375, "training_acc": 50.0, "val_loss": 134.50808715820312, "val_acc": 40.0}
{"epoch": 20, "training_loss": 438.273046875, "training_acc": 40.0, "val_loss": 1063.9515380859375, "val_acc": 60.0}
{"epoch": 21, "training_loss": 1235.8734008789063, "training_acc": 50.0, "val_loss": 120.7911376953125, "val_acc": 40.0}
{"epoch": 22, "training_loss": 157.23262939453124, "training_acc": 50.0, "val_loss": 50.935523986816406, "val_acc": 40.0}
{"epoch": 23, "training_loss": 206.90964965820314, "training_acc": 50.0, "val_loss": 882.0426025390625, "val_acc": 60.0}
{"epoch": 24, "training_loss": 992.287158203125, "training_acc": 50.0, "val_loss": 527.70361328125, "val_acc": 40.0}
{"epoch": 25, "training_loss": 690.5526123046875, "training_acc": 50.0, "val_loss": 535.978759765625, "val_acc": 40.0}
{"epoch": 26, "training_loss": 266.4451171875, "training_acc": 70.0, "val_loss": 1192.5867919921875, "val_acc": 60.0}
{"epoch": 27, "training_loss": 1527.6339599609375, "training_acc": 50.0, "val_loss": 1058.7369384765625, "val_acc": 60.0}
{"epoch": 28, "training_loss": 1121.0618530273437, "training_acc": 50.0, "val_loss": 1325.796142578125, "val_acc": 40.0}
{"epoch": 29, "training_loss": 1166.217529296875, "training_acc": 50.0, "val_loss": 2428.069091796875, "val_acc": 40.0}
{"epoch": 30, "training_loss": 1975.943701171875, "training_acc": 50.0, "val_loss": 1076.0628662109375, "val_acc": 40.0}
{"epoch": 31, "training_loss": 922.7493041992187, "training_acc": 40.0, "val_loss": 543.67919921875, "val_acc": 60.0}
{"epoch": 32, "training_loss": 595.6962036132812, "training_acc": 50.0, "val_loss": 749.9945678710938, "val_acc": 40.0}
{"epoch": 33, "training_loss": 636.24658203125, "training_acc": 50.0, "val_loss": 753.9006958007812, "val_acc": 40.0}
{"epoch": 34, "training_loss": 523.3433959960937, "training_acc": 50.0, "val_loss": 154.26318359375, "val_acc": 60.0}
{"epoch": 35, "training_loss": 213.30196533203124, "training_acc": 50.0, "val_loss": 292.5765380859375, "val_acc": 40.0}
{"epoch": 36, "training_loss": 284.86904296875, "training_acc": 50.0, "val_loss": 404.228515625, "val_acc": 60.0}
{"epoch": 37, "training_loss": 320.12880249023436, "training_acc": 50.0, "val_loss": 1814.6048583984375, "val_acc": 40.0}
{"epoch": 38, "training_loss": 1508.04384765625, "training_acc": 50.0, "val_loss": 3352.20751953125, "val_acc": 40.0}
{"epoch": 39, "training_loss": 2776.1714111328124, "training_acc": 50.0, "val_loss": 2687.992919921875, "val_acc": 40.0}
{"epoch": 40, "training_loss": 1962.6571044921875, "training_acc": 50.0, "val_loss": 318.7072448730469, "val_acc": 60.0}
{"epoch": 41, "training_loss": 824.8314697265625, "training_acc": 50.0, "val_loss": 1024.5423583984375, "val_acc": 60.0}
