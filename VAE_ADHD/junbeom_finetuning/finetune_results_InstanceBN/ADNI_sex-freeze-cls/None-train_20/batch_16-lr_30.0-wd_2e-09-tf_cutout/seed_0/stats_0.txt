"main_modify.py --pretrained_path None --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_sex --input_option yAware --learning_rate 3e1 --batch_size 16 --weight_decay 2e-9 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 1928.580665206909, "training_acc": 50.0, "val_loss": 2260.689697265625, "val_acc": 40.0}
{"epoch": 1, "training_loss": 2170.639599609375, "training_acc": 50.0, "val_loss": 4182.45361328125, "val_acc": 60.0}
{"epoch": 2, "training_loss": 5202.380322265625, "training_acc": 50.0, "val_loss": 3238.815185546875, "val_acc": 60.0}
{"epoch": 3, "training_loss": 3487.333642578125, "training_acc": 50.0, "val_loss": 1026.6199951171875, "val_acc": 40.0}
{"epoch": 4, "training_loss": 1164.978125, "training_acc": 50.0, "val_loss": 3321.404296875, "val_acc": 40.0}
{"epoch": 5, "training_loss": 2622.33984375, "training_acc": 50.0, "val_loss": 760.2953491210938, "val_acc": 40.0}
{"epoch": 6, "training_loss": 828.0900390625, "training_acc": 50.0, "val_loss": 2230.031982421875, "val_acc": 60.0}
{"epoch": 7, "training_loss": 2839.4875, "training_acc": 50.0, "val_loss": 2036.8486328125, "val_acc": 60.0}
{"epoch": 8, "training_loss": 2307.0228759765623, "training_acc": 50.0, "val_loss": 487.4754943847656, "val_acc": 40.0}
{"epoch": 9, "training_loss": 483.17047119140625, "training_acc": 50.0, "val_loss": 1808.4771728515625, "val_acc": 40.0}
{"epoch": 10, "training_loss": 1426.758251953125, "training_acc": 50.0, "val_loss": 66.52474212646484, "val_acc": 40.0}
{"epoch": 11, "training_loss": 355.94642944335936, "training_acc": 50.0, "val_loss": 1866.2908935546875, "val_acc": 60.0}
{"epoch": 12, "training_loss": 2330.76796875, "training_acc": 50.0, "val_loss": 1347.032470703125, "val_acc": 60.0}
{"epoch": 13, "training_loss": 1545.2206024169923, "training_acc": 50.0, "val_loss": 1431.4752197265625, "val_acc": 40.0}
{"epoch": 14, "training_loss": 1256.98671875, "training_acc": 50.0, "val_loss": 2476.087646484375, "val_acc": 40.0}
{"epoch": 15, "training_loss": 1953.258740234375, "training_acc": 50.0, "val_loss": 469.197998046875, "val_acc": 40.0}
{"epoch": 16, "training_loss": 599.5778564453125, "training_acc": 50.0, "val_loss": 1928.2698974609375, "val_acc": 60.0}
{"epoch": 17, "training_loss": 2451.64736328125, "training_acc": 50.0, "val_loss": 1771.7093505859375, "val_acc": 60.0}
{"epoch": 18, "training_loss": 2097.9086303710938, "training_acc": 50.0, "val_loss": 267.57843017578125, "val_acc": 40.0}
{"epoch": 19, "training_loss": 414.78643798828125, "training_acc": 50.0, "val_loss": 549.4166259765625, "val_acc": 40.0}
{"epoch": 20, "training_loss": 595.5329833984375, "training_acc": 40.0, "val_loss": 496.0641784667969, "val_acc": 60.0}
{"epoch": 21, "training_loss": 569.9366516113281, "training_acc": 40.0, "val_loss": 189.82225036621094, "val_acc": 60.0}
{"epoch": 22, "training_loss": 202.98324890136718, "training_acc": 50.0, "val_loss": 169.8728790283203, "val_acc": 60.0}
{"epoch": 23, "training_loss": 149.10663528442382, "training_acc": 60.0, "val_loss": 24.810073852539062, "val_acc": 60.0}
{"epoch": 24, "training_loss": 123.082666015625, "training_acc": 50.0, "val_loss": 473.0662536621094, "val_acc": 40.0}
{"epoch": 25, "training_loss": 304.77097473144534, "training_acc": 60.0, "val_loss": 434.162109375, "val_acc": 60.0}
{"epoch": 26, "training_loss": 456.8665008544922, "training_acc": 50.0, "val_loss": 949.8445434570312, "val_acc": 40.0}
{"epoch": 27, "training_loss": 840.38525390625, "training_acc": 50.0, "val_loss": 741.484619140625, "val_acc": 40.0}
{"epoch": 28, "training_loss": 371.6294189453125, "training_acc": 70.0, "val_loss": 794.4524536132812, "val_acc": 60.0}
{"epoch": 29, "training_loss": 1025.042236328125, "training_acc": 50.0, "val_loss": 241.67752075195312, "val_acc": 60.0}
{"epoch": 30, "training_loss": 447.6385498046875, "training_acc": 50.0, "val_loss": 2010.5628662109375, "val_acc": 40.0}
{"epoch": 31, "training_loss": 1704.140380859375, "training_acc": 50.0, "val_loss": 687.8292236328125, "val_acc": 40.0}
{"epoch": 32, "training_loss": 502.57761840820314, "training_acc": 60.0, "val_loss": 1730.7850341796875, "val_acc": 60.0}
{"epoch": 33, "training_loss": 2151.21171875, "training_acc": 50.0, "val_loss": 2102.20361328125, "val_acc": 60.0}
{"epoch": 34, "training_loss": 2508.91181640625, "training_acc": 50.0, "val_loss": 826.4835815429688, "val_acc": 60.0}
{"epoch": 35, "training_loss": 960.1732421875, "training_acc": 50.0, "val_loss": 1984.9295654296875, "val_acc": 40.0}
{"epoch": 36, "training_loss": 1703.01474609375, "training_acc": 50.0, "val_loss": 1759.536376953125, "val_acc": 40.0}
{"epoch": 37, "training_loss": 1363.3790466308594, "training_acc": 50.0, "val_loss": 712.4848022460938, "val_acc": 60.0}
{"epoch": 38, "training_loss": 982.022705078125, "training_acc": 50.0, "val_loss": 1019.5263671875, "val_acc": 60.0}
{"epoch": 39, "training_loss": 1055.9416259765626, "training_acc": 50.0, "val_loss": 1135.9539794921875, "val_acc": 40.0}
{"epoch": 40, "training_loss": 1018.9638793945312, "training_acc": 50.0, "val_loss": 2333.068115234375, "val_acc": 40.0}
{"epoch": 41, "training_loss": 1880.4062255859376, "training_acc": 50.0, "val_loss": 791.4254760742188, "val_acc": 40.0}
{"epoch": 42, "training_loss": 687.923828125, "training_acc": 50.0, "val_loss": 1202.222900390625, "val_acc": 60.0}
