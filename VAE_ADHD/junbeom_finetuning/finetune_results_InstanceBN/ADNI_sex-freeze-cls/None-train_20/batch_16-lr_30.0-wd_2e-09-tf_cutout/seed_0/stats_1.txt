"main_modify.py --pretrained_path None --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_sex --input_option yAware --learning_rate 3e1 --batch_size 16 --weight_decay 2e-9 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 1285.8459730148315, "training_acc": 50.0, "val_loss": 2273.974609375, "val_acc": 40.0}
{"epoch": 1, "training_loss": 1671.79736328125, "training_acc": 60.0, "val_loss": 4976.58935546875, "val_acc": 60.0}
{"epoch": 2, "training_loss": 6202.8255859375, "training_acc": 50.0, "val_loss": 3495.756591796875, "val_acc": 60.0}
{"epoch": 3, "training_loss": 3806.89462890625, "training_acc": 50.0, "val_loss": 2427.793701171875, "val_acc": 40.0}
{"epoch": 4, "training_loss": 2180.9347412109373, "training_acc": 50.0, "val_loss": 5283.00244140625, "val_acc": 40.0}
{"epoch": 5, "training_loss": 4327.894140625, "training_acc": 50.0, "val_loss": 3230.945068359375, "val_acc": 40.0}
{"epoch": 6, "training_loss": 2093.941064453125, "training_acc": 50.0, "val_loss": 1807.4285888671875, "val_acc": 60.0}
{"epoch": 7, "training_loss": 2420.015673828125, "training_acc": 50.0, "val_loss": 3899.553955078125, "val_acc": 60.0}
{"epoch": 8, "training_loss": 4888.844921875, "training_acc": 50.0, "val_loss": 3367.810302734375, "val_acc": 60.0}
{"epoch": 9, "training_loss": 3923.812744140625, "training_acc": 50.0, "val_loss": 593.5997924804688, "val_acc": 60.0}
{"epoch": 10, "training_loss": 1528.0087890625, "training_acc": 30.0, "val_loss": 3401.322021484375, "val_acc": 40.0}
{"epoch": 11, "training_loss": 2853.49072265625, "training_acc": 50.0, "val_loss": 2811.056884765625, "val_acc": 40.0}
{"epoch": 12, "training_loss": 2103.362646484375, "training_acc": 50.0, "val_loss": 467.0927429199219, "val_acc": 60.0}
{"epoch": 13, "training_loss": 764.44990234375, "training_acc": 50.0, "val_loss": 1290.0999755859375, "val_acc": 60.0}
{"epoch": 14, "training_loss": 1553.73486328125, "training_acc": 50.0, "val_loss": 94.55168914794922, "val_acc": 60.0}
{"epoch": 15, "training_loss": 361.233837890625, "training_acc": 50.0, "val_loss": 2363.451171875, "val_acc": 40.0}
{"epoch": 16, "training_loss": 1971.60986328125, "training_acc": 50.0, "val_loss": 1230.5001220703125, "val_acc": 40.0}
{"epoch": 17, "training_loss": 1084.541943359375, "training_acc": 40.0, "val_loss": 789.9276733398438, "val_acc": 60.0}
{"epoch": 18, "training_loss": 947.98095703125, "training_acc": 50.0, "val_loss": 244.17222595214844, "val_acc": 40.0}
{"epoch": 19, "training_loss": 396.367041015625, "training_acc": 50.0, "val_loss": 62.60083770751953, "val_acc": 60.0}
{"epoch": 20, "training_loss": 132.75709228515626, "training_acc": 50.0, "val_loss": 573.9297485351562, "val_acc": 40.0}
{"epoch": 21, "training_loss": 519.0416748046875, "training_acc": 50.0, "val_loss": 101.03313446044922, "val_acc": 60.0}
{"epoch": 22, "training_loss": 148.89332275390626, "training_acc": 50.0, "val_loss": 339.79986572265625, "val_acc": 40.0}
{"epoch": 23, "training_loss": 262.52520751953125, "training_acc": 50.0, "val_loss": 560.3360595703125, "val_acc": 60.0}
{"epoch": 24, "training_loss": 756.3213134765625, "training_acc": 50.0, "val_loss": 474.76904296875, "val_acc": 60.0}
{"epoch": 25, "training_loss": 653.8941772460937, "training_acc": 40.0, "val_loss": 464.1263732910156, "val_acc": 40.0}
{"epoch": 26, "training_loss": 422.4246826171875, "training_acc": 40.0, "val_loss": 27.350000381469727, "val_acc": 40.0}
{"epoch": 27, "training_loss": 36.86661376953125, "training_acc": 60.0, "val_loss": 119.88219451904297, "val_acc": 60.0}
{"epoch": 28, "training_loss": 219.9420593261719, "training_acc": 50.0, "val_loss": 573.9747314453125, "val_acc": 40.0}
{"epoch": 29, "training_loss": 480.2439819335938, "training_acc": 40.0, "val_loss": 113.6781005859375, "val_acc": 40.0}
{"epoch": 30, "training_loss": 174.87769165039063, "training_acc": 40.0, "val_loss": 236.53697204589844, "val_acc": 40.0}
{"epoch": 31, "training_loss": 178.41107788085938, "training_acc": 50.0, "val_loss": 597.2056884765625, "val_acc": 60.0}
{"epoch": 32, "training_loss": 802.0114013671875, "training_acc": 50.0, "val_loss": 504.20751953125, "val_acc": 60.0}
{"epoch": 33, "training_loss": 463.93602142333987, "training_acc": 60.0, "val_loss": 773.6835327148438, "val_acc": 40.0}
{"epoch": 34, "training_loss": 607.3887268066406, "training_acc": 50.0, "val_loss": 194.8911590576172, "val_acc": 60.0}
{"epoch": 35, "training_loss": 294.6726318359375, "training_acc": 50.0, "val_loss": 394.2989196777344, "val_acc": 40.0}
{"epoch": 36, "training_loss": 326.7443908691406, "training_acc": 50.0, "val_loss": 66.67378234863281, "val_acc": 40.0}
{"epoch": 37, "training_loss": 195.67104797363282, "training_acc": 50.0, "val_loss": 753.1095581054688, "val_acc": 60.0}
{"epoch": 38, "training_loss": 834.84384765625, "training_acc": 50.0, "val_loss": 885.6034545898438, "val_acc": 40.0}
{"epoch": 39, "training_loss": 872.782958984375, "training_acc": 50.0, "val_loss": 1765.76171875, "val_acc": 40.0}
{"epoch": 40, "training_loss": 1325.68720703125, "training_acc": 50.0, "val_loss": 214.80068969726562, "val_acc": 60.0}
{"epoch": 41, "training_loss": 276.3941162109375, "training_acc": 50.0, "val_loss": 877.3214111328125, "val_acc": 60.0}
{"epoch": 42, "training_loss": 1075.2154724121094, "training_acc": 50.0, "val_loss": 190.69749450683594, "val_acc": 60.0}
{"epoch": 43, "training_loss": 246.87158813476563, "training_acc": 60.0, "val_loss": 1666.1922607421875, "val_acc": 40.0}
