"main_modify.py --pretrained_path None --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 2 --task ADNI_sex --input_option yAware --learning_rate 3e1 --batch_size 16 --weight_decay 2e-9 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 1928.3075032234192, "training_acc": 40.0, "val_loss": 1644.7708740234375, "val_acc": 60.0}
{"epoch": 1, "training_loss": 2249.82958984375, "training_acc": 50.0, "val_loss": 5841.89208984375, "val_acc": 40.0}
{"epoch": 2, "training_loss": 4971.3607421875, "training_acc": 50.0, "val_loss": 3641.6015625, "val_acc": 40.0}
{"epoch": 3, "training_loss": 2480.2845825195313, "training_acc": 50.0, "val_loss": 2429.4638671875, "val_acc": 60.0}
{"epoch": 4, "training_loss": 3642.2162109375, "training_acc": 50.0, "val_loss": 4358.69482421875, "val_acc": 60.0}
{"epoch": 5, "training_loss": 5334.78955078125, "training_acc": 50.0, "val_loss": 2909.032958984375, "val_acc": 60.0}
{"epoch": 6, "training_loss": 2899.5400390625, "training_acc": 50.0, "val_loss": 1252.810546875, "val_acc": 40.0}
{"epoch": 7, "training_loss": 1219.02509765625, "training_acc": 50.0, "val_loss": 4871.53076171875, "val_acc": 40.0}
{"epoch": 8, "training_loss": 4095.53037109375, "training_acc": 50.0, "val_loss": 5355.19775390625, "val_acc": 40.0}
{"epoch": 9, "training_loss": 4294.88037109375, "training_acc": 50.0, "val_loss": 3006.16455078125, "val_acc": 40.0}
{"epoch": 10, "training_loss": 2126.7503173828127, "training_acc": 50.0, "val_loss": 1340.3118896484375, "val_acc": 60.0}
{"epoch": 11, "training_loss": 1963.3033203125, "training_acc": 50.0, "val_loss": 3044.800537109375, "val_acc": 60.0}
{"epoch": 12, "training_loss": 3805.54248046875, "training_acc": 50.0, "val_loss": 2569.3369140625, "val_acc": 60.0}
{"epoch": 13, "training_loss": 3089.6417846679688, "training_acc": 50.0, "val_loss": 473.42901611328125, "val_acc": 60.0}
{"epoch": 14, "training_loss": 728.686279296875, "training_acc": 50.0, "val_loss": 2820.85546875, "val_acc": 40.0}
{"epoch": 15, "training_loss": 2554.70341796875, "training_acc": 50.0, "val_loss": 2571.49462890625, "val_acc": 40.0}
{"epoch": 16, "training_loss": 2010.3874145507812, "training_acc": 50.0, "val_loss": 510.64654541015625, "val_acc": 60.0}
{"epoch": 17, "training_loss": 704.832373046875, "training_acc": 50.0, "val_loss": 1291.9378662109375, "val_acc": 60.0}
{"epoch": 18, "training_loss": 1541.780859375, "training_acc": 50.0, "val_loss": 228.6360626220703, "val_acc": 60.0}
{"epoch": 19, "training_loss": 484.621484375, "training_acc": 50.0, "val_loss": 2527.95166015625, "val_acc": 40.0}
{"epoch": 20, "training_loss": 2134.739697265625, "training_acc": 50.0, "val_loss": 2180.072998046875, "val_acc": 40.0}
{"epoch": 21, "training_loss": 1708.9056518554687, "training_acc": 50.0, "val_loss": 402.4873962402344, "val_acc": 60.0}
{"epoch": 22, "training_loss": 687.611328125, "training_acc": 50.0, "val_loss": 631.7874145507812, "val_acc": 60.0}
{"epoch": 23, "training_loss": 649.565640258789, "training_acc": 50.0, "val_loss": 367.0941467285156, "val_acc": 40.0}
{"epoch": 24, "training_loss": 214.8672441482544, "training_acc": 60.0, "val_loss": 16.015335083007812, "val_acc": 60.0}
{"epoch": 25, "training_loss": 64.29412231445312, "training_acc": 60.0, "val_loss": 811.8368530273438, "val_acc": 40.0}
{"epoch": 26, "training_loss": 622.9070907592774, "training_acc": 50.0, "val_loss": 493.03369140625, "val_acc": 60.0}
{"epoch": 27, "training_loss": 634.8059448242187, "training_acc": 50.0, "val_loss": 147.3742218017578, "val_acc": 60.0}
{"epoch": 28, "training_loss": 453.9708740234375, "training_acc": 40.0, "val_loss": 1313.7030029296875, "val_acc": 40.0}
{"epoch": 29, "training_loss": 995.1308837890625, "training_acc": 50.0, "val_loss": 341.2844543457031, "val_acc": 60.0}
{"epoch": 30, "training_loss": 492.3044921875, "training_acc": 50.0, "val_loss": 366.4611511230469, "val_acc": 60.0}
{"epoch": 31, "training_loss": 354.1849395751953, "training_acc": 60.0, "val_loss": 915.5974731445312, "val_acc": 40.0}
{"epoch": 32, "training_loss": 714.166357421875, "training_acc": 50.0, "val_loss": 223.3978729248047, "val_acc": 60.0}
{"epoch": 33, "training_loss": 283.17430419921874, "training_acc": 50.0, "val_loss": 52.624446868896484, "val_acc": 60.0}
{"epoch": 34, "training_loss": 115.6039794921875, "training_acc": 60.0, "val_loss": 1316.8316650390625, "val_acc": 40.0}
{"epoch": 35, "training_loss": 1042.1230712890624, "training_acc": 50.0, "val_loss": 16.005615234375, "val_acc": 60.0}
{"epoch": 36, "training_loss": 88.32769165039062, "training_acc": 50.0, "val_loss": 558.4588012695312, "val_acc": 40.0}
{"epoch": 37, "training_loss": 467.2344604492188, "training_acc": 50.0, "val_loss": 73.8150634765625, "val_acc": 60.0}
{"epoch": 38, "training_loss": 118.72142333984375, "training_acc": 50.0, "val_loss": 1187.4632568359375, "val_acc": 40.0}
{"epoch": 39, "training_loss": 1070.450634765625, "training_acc": 50.0, "val_loss": 1440.25830078125, "val_acc": 40.0}
{"epoch": 40, "training_loss": 1109.7924377441407, "training_acc": 50.0, "val_loss": 620.8677978515625, "val_acc": 60.0}
{"epoch": 41, "training_loss": 913.68896484375, "training_acc": 50.0, "val_loss": 586.43603515625, "val_acc": 60.0}
