"main_modify.py --pretrained_path None --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 2 --task ADNI_sex --input_option yAware --learning_rate 3e1 --batch_size 16 --weight_decay 2e-9 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 1289.1831415176391, "training_acc": 50.0, "val_loss": 1743.7840576171875, "val_acc": 60.0}
{"epoch": 1, "training_loss": 2886.623828125, "training_acc": 40.0, "val_loss": 4199.25439453125, "val_acc": 40.0}
{"epoch": 2, "training_loss": 3264.656689453125, "training_acc": 50.0, "val_loss": 88.84490203857422, "val_acc": 40.0}
{"epoch": 3, "training_loss": 648.0221374511718, "training_acc": 50.0, "val_loss": 3479.639892578125, "val_acc": 60.0}
{"epoch": 4, "training_loss": 4436.9958984375, "training_acc": 50.0, "val_loss": 2794.128662109375, "val_acc": 60.0}
{"epoch": 5, "training_loss": 2961.590283203125, "training_acc": 50.0, "val_loss": 1157.2454833984375, "val_acc": 40.0}
{"epoch": 6, "training_loss": 1108.7326904296874, "training_acc": 50.0, "val_loss": 3970.43359375, "val_acc": 40.0}
{"epoch": 7, "training_loss": 3303.7821044921875, "training_acc": 50.0, "val_loss": 3374.599609375, "val_acc": 40.0}
{"epoch": 8, "training_loss": 2692.312951660156, "training_acc": 50.0, "val_loss": 180.57627868652344, "val_acc": 40.0}
{"epoch": 9, "training_loss": 955.3892944335937, "training_acc": 30.0, "val_loss": 1994.2867431640625, "val_acc": 60.0}
{"epoch": 10, "training_loss": 2449.996728515625, "training_acc": 50.0, "val_loss": 1014.6798095703125, "val_acc": 60.0}
{"epoch": 11, "training_loss": 1261.66484375, "training_acc": 40.0, "val_loss": 1132.3553466796875, "val_acc": 40.0}
{"epoch": 12, "training_loss": 918.6075317382813, "training_acc": 50.0, "val_loss": 118.12139129638672, "val_acc": 40.0}
{"epoch": 13, "training_loss": 176.929150390625, "training_acc": 60.0, "val_loss": 1479.360107421875, "val_acc": 60.0}
{"epoch": 14, "training_loss": 1941.3216796875, "training_acc": 50.0, "val_loss": 876.2283325195312, "val_acc": 60.0}
{"epoch": 15, "training_loss": 952.727685546875, "training_acc": 50.0, "val_loss": 1340.089111328125, "val_acc": 40.0}
{"epoch": 16, "training_loss": 1130.749072265625, "training_acc": 50.0, "val_loss": 797.6190795898438, "val_acc": 40.0}
{"epoch": 17, "training_loss": 398.14638671875, "training_acc": 70.0, "val_loss": 873.32275390625, "val_acc": 60.0}
{"epoch": 18, "training_loss": 1122.84755859375, "training_acc": 50.0, "val_loss": 626.1103515625, "val_acc": 60.0}
{"epoch": 19, "training_loss": 564.4598251342774, "training_acc": 60.0, "val_loss": 856.0947265625, "val_acc": 40.0}
{"epoch": 20, "training_loss": 690.641015625, "training_acc": 50.0, "val_loss": 80.84801483154297, "val_acc": 60.0}
{"epoch": 21, "training_loss": 132.0857666015625, "training_acc": 50.0, "val_loss": 724.7024536132812, "val_acc": 40.0}
{"epoch": 22, "training_loss": 608.5492919921875, "training_acc": 50.0, "val_loss": 480.3614196777344, "val_acc": 40.0}
{"epoch": 23, "training_loss": 315.93601684570314, "training_acc": 60.0, "val_loss": 596.6849975585938, "val_acc": 60.0}
{"epoch": 24, "training_loss": 692.6267639160156, "training_acc": 50.0, "val_loss": 443.4176940917969, "val_acc": 40.0}
{"epoch": 25, "training_loss": 399.19166259765626, "training_acc": 50.0, "val_loss": 57.308570861816406, "val_acc": 40.0}
{"epoch": 26, "training_loss": 125.17594604492187, "training_acc": 60.0, "val_loss": 1187.1976318359375, "val_acc": 60.0}
{"epoch": 27, "training_loss": 1461.5908935546875, "training_acc": 50.0, "val_loss": 525.9367065429688, "val_acc": 60.0}
{"epoch": 28, "training_loss": 645.8857666015625, "training_acc": 50.0, "val_loss": 1351.7923583984375, "val_acc": 40.0}
{"epoch": 29, "training_loss": 1103.1945373535157, "training_acc": 50.0, "val_loss": 450.7330017089844, "val_acc": 40.0}
{"epoch": 30, "training_loss": 224.807666015625, "training_acc": 70.0, "val_loss": 1131.7374267578125, "val_acc": 60.0}
{"epoch": 31, "training_loss": 1442.106298828125, "training_acc": 50.0, "val_loss": 834.1324462890625, "val_acc": 60.0}
{"epoch": 32, "training_loss": 842.1297554016113, "training_acc": 50.0, "val_loss": 471.7264099121094, "val_acc": 40.0}
{"epoch": 33, "training_loss": 353.96721024513243, "training_acc": 35.0, "val_loss": 230.6642608642578, "val_acc": 40.0}
{"epoch": 34, "training_loss": 151.73854217529296, "training_acc": 60.0, "val_loss": 166.60391235351562, "val_acc": 60.0}
{"epoch": 35, "training_loss": 331.187255859375, "training_acc": 40.0, "val_loss": 187.0749969482422, "val_acc": 40.0}
{"epoch": 36, "training_loss": 393.491845703125, "training_acc": 40.0, "val_loss": 641.5236206054688, "val_acc": 60.0}
{"epoch": 37, "training_loss": 666.7367309570312, "training_acc": 50.0, "val_loss": 1292.629638671875, "val_acc": 40.0}
{"epoch": 38, "training_loss": 1076.81923828125, "training_acc": 50.0, "val_loss": 2015.8759765625, "val_acc": 40.0}
{"epoch": 39, "training_loss": 1635.676513671875, "training_acc": 50.0, "val_loss": 618.6066284179688, "val_acc": 40.0}
{"epoch": 40, "training_loss": 564.100244140625, "training_acc": 50.0, "val_loss": 1021.5939331054688, "val_acc": 60.0}
{"epoch": 41, "training_loss": 1242.3546142578125, "training_acc": 50.0, "val_loss": 272.3677673339844, "val_acc": 60.0}
{"epoch": 42, "training_loss": 623.8490478515625, "training_acc": 40.0, "val_loss": 1656.8162841796875, "val_acc": 40.0}
{"epoch": 43, "training_loss": 1305.42744140625, "training_acc": 50.0, "val_loss": 155.5545654296875, "val_acc": 60.0}
{"epoch": 44, "training_loss": 408.151806640625, "training_acc": 50.0, "val_loss": 506.3102722167969, "val_acc": 60.0}
