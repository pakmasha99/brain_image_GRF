"main_modify.py --pretrained_path None --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 1 --task ADNI_sex --input_option yAware --learning_rate 3e1 --batch_size 16 --weight_decay 2e-9 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 645.1130169868469, "training_acc": 55.0, "val_loss": 2368.225830078125, "val_acc": 40.0}
{"epoch": 1, "training_loss": 1520.8468017578125, "training_acc": 65.0, "val_loss": 4302.70263671875, "val_acc": 60.0}
{"epoch": 2, "training_loss": 5627.178369140625, "training_acc": 45.0, "val_loss": 839.9996948242188, "val_acc": 60.0}
{"epoch": 3, "training_loss": 1506.357373046875, "training_acc": 45.0, "val_loss": 5444.5888671875, "val_acc": 40.0}
{"epoch": 4, "training_loss": 4234.64775390625, "training_acc": 55.0, "val_loss": 4584.51025390625, "val_acc": 40.0}
{"epoch": 5, "training_loss": 3230.87978515625, "training_acc": 55.0, "val_loss": 444.4152526855469, "val_acc": 60.0}
{"epoch": 6, "training_loss": 792.987255859375, "training_acc": 45.0, "val_loss": 1076.6983642578125, "val_acc": 60.0}
{"epoch": 7, "training_loss": 1130.5458862304688, "training_acc": 45.0, "val_loss": 2119.682373046875, "val_acc": 40.0}
{"epoch": 8, "training_loss": 1709.3918701171874, "training_acc": 55.0, "val_loss": 4437.033203125, "val_acc": 40.0}
{"epoch": 9, "training_loss": 3393.567578125, "training_acc": 55.0, "val_loss": 3145.523681640625, "val_acc": 40.0}
{"epoch": 10, "training_loss": 1866.2335693359375, "training_acc": 55.0, "val_loss": 1152.0184326171875, "val_acc": 60.0}
{"epoch": 11, "training_loss": 1866.6248046875, "training_acc": 45.0, "val_loss": 2766.496826171875, "val_acc": 60.0}
{"epoch": 12, "training_loss": 3772.27041015625, "training_acc": 45.0, "val_loss": 1844.2894287109375, "val_acc": 60.0}
{"epoch": 13, "training_loss": 2208.65771484375, "training_acc": 45.0, "val_loss": 1714.888671875, "val_acc": 40.0}
{"epoch": 14, "training_loss": 1709.92470703125, "training_acc": 55.0, "val_loss": 3819.66259765625, "val_acc": 40.0}
{"epoch": 15, "training_loss": 2829.370263671875, "training_acc": 55.0, "val_loss": 2721.270751953125, "val_acc": 40.0}
{"epoch": 16, "training_loss": 1821.318212890625, "training_acc": 55.0, "val_loss": 323.95562744140625, "val_acc": 60.0}
{"epoch": 17, "training_loss": 690.3712158203125, "training_acc": 45.0, "val_loss": 817.8615112304688, "val_acc": 60.0}
{"epoch": 18, "training_loss": 954.1893859863281, "training_acc": 45.0, "val_loss": 1455.64208984375, "val_acc": 40.0}
{"epoch": 19, "training_loss": 1325.296875, "training_acc": 55.0, "val_loss": 2162.51171875, "val_acc": 40.0}
{"epoch": 20, "training_loss": 1475.730908203125, "training_acc": 55.0, "val_loss": 118.2020263671875, "val_acc": 60.0}
{"epoch": 21, "training_loss": 201.75948181152344, "training_acc": 45.0, "val_loss": 427.7461853027344, "val_acc": 60.0}
{"epoch": 22, "training_loss": 593.0657348632812, "training_acc": 35.0, "val_loss": 37.71805191040039, "val_acc": 60.0}
{"epoch": 23, "training_loss": 125.31393432617188, "training_acc": 45.0, "val_loss": 250.51329040527344, "val_acc": 40.0}
{"epoch": 24, "training_loss": 163.12420043945312, "training_acc": 65.0, "val_loss": 535.4825439453125, "val_acc": 60.0}
{"epoch": 25, "training_loss": 688.8309692382812, "training_acc": 45.0, "val_loss": 737.6575317382812, "val_acc": 40.0}
{"epoch": 26, "training_loss": 622.058447265625, "training_acc": 55.0, "val_loss": 202.1978302001953, "val_acc": 40.0}
{"epoch": 27, "training_loss": 446.98582763671874, "training_acc": 45.0, "val_loss": 993.6749267578125, "val_acc": 60.0}
{"epoch": 28, "training_loss": 1242.46533203125, "training_acc": 45.0, "val_loss": 533.2759399414062, "val_acc": 40.0}
{"epoch": 29, "training_loss": 450.2680969238281, "training_acc": 55.0, "val_loss": 1429.6939697265625, "val_acc": 40.0}
{"epoch": 30, "training_loss": 985.6072509765625, "training_acc": 55.0, "val_loss": 166.9921112060547, "val_acc": 60.0}
{"epoch": 31, "training_loss": 301.7044189453125, "training_acc": 45.0, "val_loss": 224.37197875976562, "val_acc": 60.0}
{"epoch": 32, "training_loss": 280.5189514160156, "training_acc": 55.0, "val_loss": 1236.5125732421875, "val_acc": 40.0}
{"epoch": 33, "training_loss": 905.568310546875, "training_acc": 55.0, "val_loss": 467.3175354003906, "val_acc": 40.0}
{"epoch": 34, "training_loss": 495.7696533203125, "training_acc": 45.0, "val_loss": 509.9737243652344, "val_acc": 60.0}
{"epoch": 35, "training_loss": 667.8096801757813, "training_acc": 35.0, "val_loss": 106.06294250488281, "val_acc": 60.0}
{"epoch": 36, "training_loss": 182.84884643554688, "training_acc": 45.0, "val_loss": 167.78941345214844, "val_acc": 40.0}
{"epoch": 37, "training_loss": 292.1004638671875, "training_acc": 45.0, "val_loss": 321.2159729003906, "val_acc": 60.0}
{"epoch": 38, "training_loss": 453.19434814453126, "training_acc": 45.0, "val_loss": 748.5515747070312, "val_acc": 40.0}
{"epoch": 39, "training_loss": 511.83255767822266, "training_acc": 55.0, "val_loss": 392.2014465332031, "val_acc": 60.0}
{"epoch": 40, "training_loss": 551.0678466796875, "training_acc": 45.0, "val_loss": 414.6553649902344, "val_acc": 40.0}
{"epoch": 41, "training_loss": 404.8989013671875, "training_acc": 55.0, "val_loss": 118.04312896728516, "val_acc": 40.0}
