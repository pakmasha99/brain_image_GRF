"main_modify.py --pretrained_path None --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 2 --task ADNI_sex --input_option yAware --learning_rate 5e0 --batch_size 16 --weight_decay 5e-3 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 215.31155948638917, "training_acc": 50.0, "val_loss": 282.6733093261719, "val_acc": 60.0}
{"epoch": 1, "training_loss": 475.972900390625, "training_acc": 40.0, "val_loss": 735.21533203125, "val_acc": 40.0}
{"epoch": 2, "training_loss": 575.6255859375, "training_acc": 50.0, "val_loss": 74.31560516357422, "val_acc": 40.0}
{"epoch": 3, "training_loss": 134.90980834960936, "training_acc": 50.0, "val_loss": 519.7745361328125, "val_acc": 60.0}
{"epoch": 4, "training_loss": 659.950244140625, "training_acc": 50.0, "val_loss": 385.020751953125, "val_acc": 60.0}
{"epoch": 5, "training_loss": 389.5372619628906, "training_acc": 50.0, "val_loss": 331.1976013183594, "val_acc": 40.0}
{"epoch": 6, "training_loss": 300.72588500976565, "training_acc": 50.0, "val_loss": 808.8715209960938, "val_acc": 40.0}
{"epoch": 7, "training_loss": 673.1107971191407, "training_acc": 50.0, "val_loss": 698.3927612304688, "val_acc": 40.0}
{"epoch": 8, "training_loss": 561.3114562988281, "training_acc": 50.0, "val_loss": 146.6566619873047, "val_acc": 40.0}
{"epoch": 9, "training_loss": 218.77716674804688, "training_acc": 30.0, "val_loss": 265.157470703125, "val_acc": 60.0}
{"epoch": 10, "training_loss": 327.0327880859375, "training_acc": 50.0, "val_loss": 117.42424774169922, "val_acc": 60.0}
{"epoch": 11, "training_loss": 168.02350463867188, "training_acc": 40.0, "val_loss": 245.06846618652344, "val_acc": 40.0}
{"epoch": 12, "training_loss": 199.34824829101564, "training_acc": 50.0, "val_loss": 69.30559539794922, "val_acc": 40.0}
{"epoch": 13, "training_loss": 54.2763916015625, "training_acc": 60.0, "val_loss": 212.62559509277344, "val_acc": 60.0}
{"epoch": 14, "training_loss": 280.895263671875, "training_acc": 50.0, "val_loss": 113.6901626586914, "val_acc": 60.0}
{"epoch": 15, "training_loss": 133.78639373779296, "training_acc": 50.0, "val_loss": 265.4932556152344, "val_acc": 40.0}
{"epoch": 16, "training_loss": 223.57081909179686, "training_acc": 50.0, "val_loss": 174.67263793945312, "val_acc": 40.0}
{"epoch": 17, "training_loss": 87.29221819043153, "training_acc": 70.0, "val_loss": 116.38335418701172, "val_acc": 60.0}
{"epoch": 18, "training_loss": 150.8772216796875, "training_acc": 50.0, "val_loss": 77.2884521484375, "val_acc": 60.0}
{"epoch": 19, "training_loss": 73.44782829284668, "training_acc": 60.0, "val_loss": 177.02581787109375, "val_acc": 40.0}
{"epoch": 20, "training_loss": 143.7785217285156, "training_acc": 50.0, "val_loss": 14.79949951171875, "val_acc": 40.0}
{"epoch": 21, "training_loss": 71.91616592407226, "training_acc": 40.0, "val_loss": 197.24349975585938, "val_acc": 60.0}
{"epoch": 22, "training_loss": 232.10938720703126, "training_acc": 50.0, "val_loss": 7.082841396331787, "val_acc": 60.0}
{"epoch": 23, "training_loss": 88.92258987426757, "training_acc": 40.0, "val_loss": 447.0270690917969, "val_acc": 40.0}
{"epoch": 24, "training_loss": 371.28953857421874, "training_acc": 50.0, "val_loss": 312.0561218261719, "val_acc": 40.0}
{"epoch": 25, "training_loss": 221.44396057128907, "training_acc": 50.0, "val_loss": 163.44656372070312, "val_acc": 60.0}
{"epoch": 26, "training_loss": 217.66778564453125, "training_acc": 50.0, "val_loss": 326.13800048828125, "val_acc": 60.0}
{"epoch": 27, "training_loss": 400.09180908203126, "training_acc": 50.0, "val_loss": 187.88726806640625, "val_acc": 60.0}
{"epoch": 28, "training_loss": 190.7558567047119, "training_acc": 50.0, "val_loss": 337.3746337890625, "val_acc": 40.0}
{"epoch": 29, "training_loss": 296.79454040527344, "training_acc": 50.0, "val_loss": 625.4532470703125, "val_acc": 40.0}
{"epoch": 30, "training_loss": 520.95634765625, "training_acc": 50.0, "val_loss": 386.5345153808594, "val_acc": 40.0}
{"epoch": 31, "training_loss": 266.74031829833984, "training_acc": 50.0, "val_loss": 241.4276885986328, "val_acc": 60.0}
{"epoch": 32, "training_loss": 344.349951171875, "training_acc": 50.0, "val_loss": 484.0326232910156, "val_acc": 60.0}
{"epoch": 33, "training_loss": 602.6232666015625, "training_acc": 50.0, "val_loss": 350.26702880859375, "val_acc": 60.0}
{"epoch": 34, "training_loss": 412.3923965454102, "training_acc": 50.0, "val_loss": 115.4237060546875, "val_acc": 40.0}
{"epoch": 35, "training_loss": 146.460009765625, "training_acc": 50.0, "val_loss": 320.30133056640625, "val_acc": 40.0}
{"epoch": 36, "training_loss": 256.2764923095703, "training_acc": 50.0, "val_loss": 14.761453628540039, "val_acc": 40.0}
{"epoch": 37, "training_loss": 53.13802490234375, "training_acc": 50.0, "val_loss": 259.3746643066406, "val_acc": 60.0}
{"epoch": 38, "training_loss": 332.78858642578126, "training_acc": 50.0, "val_loss": 136.04946899414062, "val_acc": 60.0}
{"epoch": 39, "training_loss": 126.28969268798828, "training_acc": 60.0, "val_loss": 293.9760437011719, "val_acc": 40.0}
{"epoch": 40, "training_loss": 256.18134765625, "training_acc": 50.0, "val_loss": 302.24884033203125, "val_acc": 40.0}
{"epoch": 41, "training_loss": 223.2402099609375, "training_acc": 50.0, "val_loss": 94.06624603271484, "val_acc": 60.0}
