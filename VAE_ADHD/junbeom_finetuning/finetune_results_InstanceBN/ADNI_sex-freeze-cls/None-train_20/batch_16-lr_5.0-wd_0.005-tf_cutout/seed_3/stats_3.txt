"main_modify.py --pretrained_path None --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 3 --task ADNI_sex --input_option yAware --learning_rate 5e0 --batch_size 16 --weight_decay 5e-3 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 214.7014907836914, "training_acc": 45.0, "val_loss": 583.5720825195312, "val_acc": 40.0}
{"epoch": 1, "training_loss": 564.9115844726563, "training_acc": 35.0, "val_loss": 200.58311462402344, "val_acc": 60.0}
{"epoch": 2, "training_loss": 233.05279998779298, "training_acc": 45.0, "val_loss": 104.4666976928711, "val_acc": 40.0}
{"epoch": 3, "training_loss": 82.49720611572266, "training_acc": 45.0, "val_loss": 94.72074127197266, "val_acc": 40.0}
{"epoch": 4, "training_loss": 66.69288711547851, "training_acc": 55.0, "val_loss": 52.549903869628906, "val_acc": 60.0}
{"epoch": 5, "training_loss": 59.17560005187988, "training_acc": 45.0, "val_loss": 245.1934814453125, "val_acc": 40.0}
{"epoch": 6, "training_loss": 214.61103515625, "training_acc": 55.0, "val_loss": 263.2607421875, "val_acc": 40.0}
{"epoch": 7, "training_loss": 160.39534530639648, "training_acc": 55.0, "val_loss": 189.98101806640625, "val_acc": 60.0}
{"epoch": 8, "training_loss": 300.3283447265625, "training_acc": 45.0, "val_loss": 251.56993103027344, "val_acc": 60.0}
{"epoch": 9, "training_loss": 288.91815795898435, "training_acc": 45.0, "val_loss": 180.16639709472656, "val_acc": 40.0}
{"epoch": 10, "training_loss": 174.46055908203124, "training_acc": 55.0, "val_loss": 513.4378662109375, "val_acc": 40.0}
{"epoch": 11, "training_loss": 380.96893615722655, "training_acc": 55.0, "val_loss": 372.3695983886719, "val_acc": 40.0}
{"epoch": 12, "training_loss": 245.48251647949218, "training_acc": 55.0, "val_loss": 82.368896484375, "val_acc": 60.0}
{"epoch": 13, "training_loss": 135.77689514160156, "training_acc": 45.0, "val_loss": 170.79302978515625, "val_acc": 60.0}
{"epoch": 14, "training_loss": 212.71165771484374, "training_acc": 45.0, "val_loss": 116.50927734375, "val_acc": 40.0}
{"epoch": 15, "training_loss": 105.41402282714844, "training_acc": 55.0, "val_loss": 210.09423828125, "val_acc": 40.0}
{"epoch": 16, "training_loss": 136.7560836791992, "training_acc": 55.0, "val_loss": 91.62718963623047, "val_acc": 60.0}
{"epoch": 17, "training_loss": 138.1047790527344, "training_acc": 45.0, "val_loss": 102.0617904663086, "val_acc": 60.0}
{"epoch": 18, "training_loss": 119.7981330871582, "training_acc": 45.0, "val_loss": 75.87421417236328, "val_acc": 40.0}
{"epoch": 19, "training_loss": 46.441515350341795, "training_acc": 55.0, "val_loss": 103.58843231201172, "val_acc": 60.0}
{"epoch": 20, "training_loss": 146.0834228515625, "training_acc": 45.0, "val_loss": 50.833736419677734, "val_acc": 60.0}
{"epoch": 21, "training_loss": 61.85412826538086, "training_acc": 55.0, "val_loss": 259.39642333984375, "val_acc": 40.0}
{"epoch": 22, "training_loss": 200.08642578125, "training_acc": 55.0, "val_loss": 126.8887939453125, "val_acc": 40.0}
{"epoch": 23, "training_loss": 93.46998596191406, "training_acc": 55.0, "val_loss": 147.42222595214844, "val_acc": 60.0}
{"epoch": 24, "training_loss": 198.07335510253907, "training_acc": 45.0, "val_loss": 34.4520378112793, "val_acc": 60.0}
{"epoch": 25, "training_loss": 69.25084838867187, "training_acc": 45.0, "val_loss": 273.3609619140625, "val_acc": 40.0}
{"epoch": 26, "training_loss": 200.4623291015625, "training_acc": 55.0, "val_loss": 106.42584228515625, "val_acc": 40.0}
{"epoch": 27, "training_loss": 105.9650634765625, "training_acc": 45.0, "val_loss": 123.47014617919922, "val_acc": 60.0}
{"epoch": 28, "training_loss": 160.74916954040526, "training_acc": 45.0, "val_loss": 82.58588409423828, "val_acc": 40.0}
{"epoch": 29, "training_loss": 84.47799072265624, "training_acc": 55.0, "val_loss": 14.351452827453613, "val_acc": 60.0}
{"epoch": 30, "training_loss": 20.7484188079834, "training_acc": 45.0, "val_loss": 17.16702651977539, "val_acc": 40.0}
{"epoch": 31, "training_loss": 10.562098503112793, "training_acc": 65.0, "val_loss": 4.093605995178223, "val_acc": 60.0}
{"epoch": 32, "training_loss": 28.829664611816405, "training_acc": 45.0, "val_loss": 160.190185546875, "val_acc": 40.0}
{"epoch": 33, "training_loss": 104.60653076171874, "training_acc": 55.0, "val_loss": 86.91607666015625, "val_acc": 60.0}
{"epoch": 34, "training_loss": 134.8682647705078, "training_acc": 45.0, "val_loss": 44.59831237792969, "val_acc": 60.0}
{"epoch": 35, "training_loss": 58.27947845458984, "training_acc": 55.0, "val_loss": 310.4693908691406, "val_acc": 40.0}
{"epoch": 36, "training_loss": 233.24000244140626, "training_acc": 55.0, "val_loss": 268.54266357421875, "val_acc": 40.0}
{"epoch": 37, "training_loss": 175.01583557128907, "training_acc": 55.0, "val_loss": 97.6551742553711, "val_acc": 60.0}
{"epoch": 38, "training_loss": 150.86514282226562, "training_acc": 45.0, "val_loss": 140.68975830078125, "val_acc": 60.0}
{"epoch": 39, "training_loss": 178.50069465637208, "training_acc": 45.0, "val_loss": 194.368896484375, "val_acc": 40.0}
{"epoch": 40, "training_loss": 161.1181610107422, "training_acc": 55.0, "val_loss": 252.3195037841797, "val_acc": 40.0}
{"epoch": 41, "training_loss": 157.09149780273438, "training_acc": 55.0, "val_loss": 112.00886535644531, "val_acc": 60.0}
{"epoch": 42, "training_loss": 190.04747314453124, "training_acc": 45.0, "val_loss": 171.60963439941406, "val_acc": 60.0}
{"epoch": 43, "training_loss": 205.39431457519532, "training_acc": 45.0, "val_loss": 213.52830505371094, "val_acc": 40.0}
{"epoch": 44, "training_loss": 201.291748046875, "training_acc": 55.0, "val_loss": 347.13916015625, "val_acc": 40.0}
{"epoch": 45, "training_loss": 223.81871337890624, "training_acc": 55.0, "val_loss": 62.13966751098633, "val_acc": 60.0}
{"epoch": 46, "training_loss": 113.50671081542968, "training_acc": 45.0, "val_loss": 192.9008331298828, "val_acc": 60.0}
{"epoch": 47, "training_loss": 247.44383544921874, "training_acc": 45.0, "val_loss": 36.0299072265625, "val_acc": 40.0}
{"epoch": 48, "training_loss": 53.395361328125, "training_acc": 55.0, "val_loss": 62.42009353637695, "val_acc": 40.0}
{"epoch": 49, "training_loss": 73.18329772949218, "training_acc": 45.0, "val_loss": 81.63811492919922, "val_acc": 60.0}
{"epoch": 50, "training_loss": 94.42507190704346, "training_acc": 45.0, "val_loss": 21.77199363708496, "val_acc": 40.0}
