"main_modify.py --pretrained_path None --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 4 --task ADNI_sex --input_option yAware --learning_rate 1e2 --batch_size 8 --weight_decay 1e-8 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 14955.975851607323, "training_acc": 50.0, "val_loss": 5095.1884765625, "val_acc": 40.0}
{"epoch": 1, "training_loss": 8477.0404296875, "training_acc": 50.0, "val_loss": 4259.73681640625, "val_acc": 40.0}
{"epoch": 2, "training_loss": 2876.088818359375, "training_acc": 60.0, "val_loss": 3929.75439453125, "val_acc": 60.0}
{"epoch": 3, "training_loss": 3110.72433013916, "training_acc": 30.0, "val_loss": 2612.866943359375, "val_acc": 60.0}
{"epoch": 4, "training_loss": 3324.413427734375, "training_acc": 50.0, "val_loss": 2663.427734375, "val_acc": 40.0}
{"epoch": 5, "training_loss": 3257.0396484375, "training_acc": 50.0, "val_loss": 1915.8402099609375, "val_acc": 40.0}
{"epoch": 6, "training_loss": 1334.88583984375, "training_acc": 70.0, "val_loss": 3385.435302734375, "val_acc": 60.0}
{"epoch": 7, "training_loss": 3444.625390625, "training_acc": 40.0, "val_loss": 2497.365478515625, "val_acc": 40.0}
{"epoch": 8, "training_loss": 1251.5344116210938, "training_acc": 60.0, "val_loss": 2778.073486328125, "val_acc": 60.0}
{"epoch": 9, "training_loss": 3053.971923828125, "training_acc": 50.0, "val_loss": 4554.57080078125, "val_acc": 40.0}
{"epoch": 10, "training_loss": 4517.57099609375, "training_acc": 50.0, "val_loss": 2099.75439453125, "val_acc": 40.0}
{"epoch": 11, "training_loss": 3125.73759765625, "training_acc": 50.0, "val_loss": 3632.33984375, "val_acc": 60.0}
{"epoch": 12, "training_loss": 2940.78251953125, "training_acc": 50.0, "val_loss": 5288.10546875, "val_acc": 40.0}
{"epoch": 13, "training_loss": 4119.92197265625, "training_acc": 50.0, "val_loss": 1254.3734130859375, "val_acc": 60.0}
{"epoch": 14, "training_loss": 2775.020263671875, "training_acc": 50.0, "val_loss": 1106.3870849609375, "val_acc": 60.0}
{"epoch": 15, "training_loss": 1770.31611328125, "training_acc": 60.0, "val_loss": 3716.76953125, "val_acc": 40.0}
{"epoch": 16, "training_loss": 2111.446875, "training_acc": 50.0, "val_loss": 3937.793701171875, "val_acc": 60.0}
{"epoch": 17, "training_loss": 4955.330859375, "training_acc": 50.0, "val_loss": 1073.5433349609375, "val_acc": 40.0}
{"epoch": 18, "training_loss": 2486.223193359375, "training_acc": 50.0, "val_loss": 2876.942138671875, "val_acc": 40.0}
{"epoch": 19, "training_loss": 1128.1501602172852, "training_acc": 60.0, "val_loss": 669.6657104492188, "val_acc": 40.0}
{"epoch": 20, "training_loss": 459.4641479492187, "training_acc": 50.0, "val_loss": 1460.2581787109375, "val_acc": 40.0}
{"epoch": 21, "training_loss": 795.2269165039063, "training_acc": 50.0, "val_loss": 2398.148193359375, "val_acc": 40.0}
{"epoch": 22, "training_loss": 1981.781298828125, "training_acc": 50.0, "val_loss": 2647.512939453125, "val_acc": 60.0}
{"epoch": 23, "training_loss": 3976.0220703125, "training_acc": 50.0, "val_loss": 1039.527587890625, "val_acc": 60.0}
{"epoch": 24, "training_loss": 1874.89755859375, "training_acc": 60.0, "val_loss": 5498.97021484375, "val_acc": 40.0}
{"epoch": 25, "training_loss": 2508.4843017578123, "training_acc": 70.0, "val_loss": 2011.888671875, "val_acc": 60.0}
{"epoch": 26, "training_loss": 2621.88642578125, "training_acc": 30.0, "val_loss": 245.56619262695312, "val_acc": 60.0}
{"epoch": 27, "training_loss": 450.9861328125, "training_acc": 50.0, "val_loss": 72.62548065185547, "val_acc": 40.0}
{"epoch": 28, "training_loss": 532.2572998046875, "training_acc": 50.0, "val_loss": 3045.8916015625, "val_acc": 40.0}
{"epoch": 29, "training_loss": 2321.376184082031, "training_acc": 50.0, "val_loss": 1864.763671875, "val_acc": 60.0}
{"epoch": 30, "training_loss": 2650.143994140625, "training_acc": 50.0, "val_loss": 2188.392333984375, "val_acc": 40.0}
{"epoch": 31, "training_loss": 2248.834716796875, "training_acc": 50.0, "val_loss": 80.73601531982422, "val_acc": 60.0}
{"epoch": 32, "training_loss": 520.0586212158203, "training_acc": 45.0, "val_loss": 1725.2786865234375, "val_acc": 60.0}
{"epoch": 33, "training_loss": 1134.1932373046875, "training_acc": 60.0, "val_loss": 5778.15478515625, "val_acc": 40.0}
{"epoch": 34, "training_loss": 4216.2654296875, "training_acc": 50.0, "val_loss": 1393.6865234375, "val_acc": 60.0}
{"epoch": 35, "training_loss": 2120.459765625, "training_acc": 50.0, "val_loss": 338.89971923828125, "val_acc": 40.0}
{"epoch": 36, "training_loss": 566.2453369140625, "training_acc": 50.0, "val_loss": 747.4190063476562, "val_acc": 60.0}
{"epoch": 37, "training_loss": 1234.614208984375, "training_acc": 50.0, "val_loss": 192.8055877685547, "val_acc": 60.0}
{"epoch": 38, "training_loss": 1014.0546203613281, "training_acc": 30.0, "val_loss": 1901.3397216796875, "val_acc": 40.0}
{"epoch": 39, "training_loss": 1676.3595703125, "training_acc": 40.0, "val_loss": 129.0524444580078, "val_acc": 40.0}
{"epoch": 40, "training_loss": 464.01142578125, "training_acc": 50.0, "val_loss": 907.1857299804688, "val_acc": 60.0}
{"epoch": 41, "training_loss": 541.4141220092773, "training_acc": 70.0, "val_loss": 2685.543701171875, "val_acc": 40.0}
{"epoch": 42, "training_loss": 2197.54912109375, "training_acc": 40.0, "val_loss": 1411.3717041015625, "val_acc": 60.0}
{"epoch": 43, "training_loss": 1260.1967529296876, "training_acc": 40.0, "val_loss": 1525.785888671875, "val_acc": 60.0}
{"epoch": 44, "training_loss": 1493.1079935073853, "training_acc": 50.0, "val_loss": 182.3190155029297, "val_acc": 60.0}
{"epoch": 45, "training_loss": 196.5915496826172, "training_acc": 70.0, "val_loss": 1618.4266357421875, "val_acc": 60.0}
{"epoch": 46, "training_loss": 1486.6405883789062, "training_acc": 50.0, "val_loss": 154.42787170410156, "val_acc": 40.0}
