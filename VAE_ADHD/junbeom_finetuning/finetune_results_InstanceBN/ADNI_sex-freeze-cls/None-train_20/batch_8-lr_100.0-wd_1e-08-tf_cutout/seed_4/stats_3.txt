"main_modify.py --pretrained_path None --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 4 --task ADNI_sex --input_option yAware --learning_rate 1e2 --batch_size 8 --weight_decay 1e-8 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 13435.333925437928, "training_acc": 35.0, "val_loss": 1047.5853271484375, "val_acc": 40.0}
{"epoch": 1, "training_loss": 13664.565673828125, "training_acc": 45.0, "val_loss": 15842.9111328125, "val_acc": 60.0}
{"epoch": 2, "training_loss": 16064.3625, "training_acc": 45.0, "val_loss": 5891.08349609375, "val_acc": 40.0}
{"epoch": 3, "training_loss": 9688.280859375, "training_acc": 55.0, "val_loss": 17888.822265625, "val_acc": 40.0}
{"epoch": 4, "training_loss": 10756.8908203125, "training_acc": 55.0, "val_loss": 1774.6204833984375, "val_acc": 40.0}
{"epoch": 5, "training_loss": 3401.059765625, "training_acc": 65.0, "val_loss": 10768.658203125, "val_acc": 60.0}
{"epoch": 6, "training_loss": 14905.16875, "training_acc": 45.0, "val_loss": 6093.9853515625, "val_acc": 60.0}
{"epoch": 7, "training_loss": 6932.69951171875, "training_acc": 35.0, "val_loss": 10304.0810546875, "val_acc": 40.0}
{"epoch": 8, "training_loss": 9516.693359375, "training_acc": 55.0, "val_loss": 8550.0771484375, "val_acc": 40.0}
{"epoch": 9, "training_loss": 2889.76328125, "training_acc": 65.0, "val_loss": 5567.41552734375, "val_acc": 60.0}
{"epoch": 10, "training_loss": 8219.55556640625, "training_acc": 45.0, "val_loss": 3478.242919921875, "val_acc": 60.0}
{"epoch": 11, "training_loss": 2754.655969238281, "training_acc": 45.0, "val_loss": 2771.199951171875, "val_acc": 40.0}
{"epoch": 12, "training_loss": 2107.6666870117188, "training_acc": 45.0, "val_loss": 3354.82275390625, "val_acc": 60.0}
{"epoch": 13, "training_loss": 2804.23466796875, "training_acc": 55.0, "val_loss": 3381.183349609375, "val_acc": 40.0}
{"epoch": 14, "training_loss": 2242.1783142089844, "training_acc": 55.0, "val_loss": 1941.569580078125, "val_acc": 60.0}
{"epoch": 15, "training_loss": 2317.8392578125, "training_acc": 45.0, "val_loss": 3725.782958984375, "val_acc": 40.0}
{"epoch": 16, "training_loss": 3662.533544921875, "training_acc": 55.0, "val_loss": 3880.688232421875, "val_acc": 40.0}
{"epoch": 17, "training_loss": 2055.7512329101564, "training_acc": 35.0, "val_loss": 1081.730712890625, "val_acc": 40.0}
{"epoch": 18, "training_loss": 759.2985916137695, "training_acc": 65.0, "val_loss": 356.402587890625, "val_acc": 60.0}
{"epoch": 19, "training_loss": 743.2314758300781, "training_acc": 55.0, "val_loss": 583.66845703125, "val_acc": 60.0}
{"epoch": 20, "training_loss": 790.3381649017334, "training_acc": 40.0, "val_loss": 3345.653076171875, "val_acc": 40.0}
{"epoch": 21, "training_loss": 1394.65810546875, "training_acc": 65.0, "val_loss": 2156.558349609375, "val_acc": 60.0}
{"epoch": 22, "training_loss": 2260.2463134765626, "training_acc": 45.0, "val_loss": 3216.273193359375, "val_acc": 40.0}
{"epoch": 23, "training_loss": 2242.1063720703123, "training_acc": 45.0, "val_loss": 677.504638671875, "val_acc": 60.0}
{"epoch": 24, "training_loss": 544.4200378417969, "training_acc": 65.0, "val_loss": 333.29547119140625, "val_acc": 60.0}
{"epoch": 25, "training_loss": 1278.067855834961, "training_acc": 35.0, "val_loss": 1296.2894287109375, "val_acc": 60.0}
{"epoch": 26, "training_loss": 1358.8737182617188, "training_acc": 45.0, "val_loss": 6426.744140625, "val_acc": 40.0}
{"epoch": 27, "training_loss": 5872.691796875, "training_acc": 55.0, "val_loss": 9864.1865234375, "val_acc": 40.0}
{"epoch": 28, "training_loss": 5522.466650390625, "training_acc": 55.0, "val_loss": 2194.902099609375, "val_acc": 60.0}
{"epoch": 29, "training_loss": 4528.62255859375, "training_acc": 45.0, "val_loss": 2391.200927734375, "val_acc": 60.0}
{"epoch": 30, "training_loss": 3056.8044921875, "training_acc": 45.0, "val_loss": 5114.3955078125, "val_acc": 40.0}
{"epoch": 31, "training_loss": 3102.047830200195, "training_acc": 45.0, "val_loss": 499.42486572265625, "val_acc": 60.0}
{"epoch": 32, "training_loss": 671.1543212890625, "training_acc": 55.0, "val_loss": 1028.4783935546875, "val_acc": 60.0}
{"epoch": 33, "training_loss": 1059.912530517578, "training_acc": 55.0, "val_loss": 2240.849609375, "val_acc": 40.0}
{"epoch": 34, "training_loss": 2228.97958984375, "training_acc": 35.0, "val_loss": 1415.4393310546875, "val_acc": 60.0}
{"epoch": 35, "training_loss": 1539.1670166015624, "training_acc": 55.0, "val_loss": 667.6023559570312, "val_acc": 40.0}
{"epoch": 36, "training_loss": 1803.1524291992187, "training_acc": 55.0, "val_loss": 1568.8919677734375, "val_acc": 60.0}
{"epoch": 37, "training_loss": 2245.0109375, "training_acc": 45.0, "val_loss": 2667.854248046875, "val_acc": 40.0}
{"epoch": 38, "training_loss": 1869.6273071289063, "training_acc": 35.0, "val_loss": 1380.7928466796875, "val_acc": 40.0}
{"epoch": 39, "training_loss": 944.2319610595703, "training_acc": 55.0, "val_loss": 431.30133056640625, "val_acc": 40.0}
{"epoch": 40, "training_loss": 1304.795556640625, "training_acc": 35.0, "val_loss": 3032.774169921875, "val_acc": 40.0}
{"epoch": 41, "training_loss": 2463.9029296875, "training_acc": 55.0, "val_loss": 735.9188842773438, "val_acc": 40.0}
{"epoch": 42, "training_loss": 3140.310595703125, "training_acc": 45.0, "val_loss": 2899.567138671875, "val_acc": 60.0}
{"epoch": 43, "training_loss": 3975.620166015625, "training_acc": 25.0, "val_loss": 2027.4217529296875, "val_acc": 40.0}
