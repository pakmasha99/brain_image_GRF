"main_modify.py --pretrained_path None --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 4 --task ADNI_sex --input_option yAware --learning_rate 1e2 --batch_size 8 --weight_decay 1e-8 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 11783.343967342376, "training_acc": 45.0, "val_loss": 1239.4407958984375, "val_acc": 60.0}
{"epoch": 1, "training_loss": 2147.0291015625, "training_acc": 45.0, "val_loss": 5891.3486328125, "val_acc": 40.0}
{"epoch": 2, "training_loss": 2594.771057891846, "training_acc": 45.0, "val_loss": 1029.775634765625, "val_acc": 60.0}
{"epoch": 3, "training_loss": 485.07174644470217, "training_acc": 65.0, "val_loss": 2669.171630859375, "val_acc": 40.0}
{"epoch": 4, "training_loss": 1465.8775390625, "training_acc": 55.0, "val_loss": 4452.79541015625, "val_acc": 60.0}
{"epoch": 5, "training_loss": 8304.4634765625, "training_acc": 45.0, "val_loss": 4265.58837890625, "val_acc": 60.0}
{"epoch": 6, "training_loss": 3303.1868408203127, "training_acc": 45.0, "val_loss": 14086.2919921875, "val_acc": 40.0}
{"epoch": 7, "training_loss": 11471.4625, "training_acc": 55.0, "val_loss": 13613.119140625, "val_acc": 40.0}
{"epoch": 8, "training_loss": 7430.516015625, "training_acc": 55.0, "val_loss": 1664.9683837890625, "val_acc": 60.0}
{"epoch": 9, "training_loss": 5186.908984375, "training_acc": 45.0, "val_loss": 4329.49755859375, "val_acc": 60.0}
{"epoch": 10, "training_loss": 4446.202880859375, "training_acc": 45.0, "val_loss": 8749.779296875, "val_acc": 40.0}
{"epoch": 11, "training_loss": 6640.838623046875, "training_acc": 55.0, "val_loss": 4315.51953125, "val_acc": 40.0}
{"epoch": 12, "training_loss": 1307.4650756835938, "training_acc": 65.0, "val_loss": 6787.7548828125, "val_acc": 60.0}
{"epoch": 13, "training_loss": 9668.228125, "training_acc": 45.0, "val_loss": 3243.50390625, "val_acc": 60.0}
{"epoch": 14, "training_loss": 2161.4711730957033, "training_acc": 55.0, "val_loss": 2819.163330078125, "val_acc": 40.0}
{"epoch": 15, "training_loss": 2086.906494140625, "training_acc": 25.0, "val_loss": 3190.1640625, "val_acc": 40.0}
{"epoch": 16, "training_loss": 2419.27314453125, "training_acc": 55.0, "val_loss": 182.9950714111328, "val_acc": 60.0}
{"epoch": 17, "training_loss": 558.2790313720703, "training_acc": 45.0, "val_loss": 2478.603271484375, "val_acc": 40.0}
{"epoch": 18, "training_loss": 1373.503594970703, "training_acc": 35.0, "val_loss": 940.2326049804688, "val_acc": 60.0}
{"epoch": 19, "training_loss": 629.2703170776367, "training_acc": 55.0, "val_loss": 476.9377136230469, "val_acc": 40.0}
{"epoch": 20, "training_loss": 828.0579986572266, "training_acc": 55.0, "val_loss": 2417.38037109375, "val_acc": 60.0}
{"epoch": 21, "training_loss": 2429.75126953125, "training_acc": 45.0, "val_loss": 4443.32080078125, "val_acc": 40.0}
{"epoch": 22, "training_loss": 2931.774035644531, "training_acc": 55.0, "val_loss": 2154.97900390625, "val_acc": 60.0}
{"epoch": 23, "training_loss": 2806.845587158203, "training_acc": 45.0, "val_loss": 2294.47705078125, "val_acc": 40.0}
{"epoch": 24, "training_loss": 1543.049951171875, "training_acc": 55.0, "val_loss": 1745.3734130859375, "val_acc": 60.0}
{"epoch": 25, "training_loss": 2889.549072265625, "training_acc": 45.0, "val_loss": 1800.2021484375, "val_acc": 40.0}
{"epoch": 26, "training_loss": 2135.64052734375, "training_acc": 55.0, "val_loss": 193.80239868164062, "val_acc": 60.0}
{"epoch": 27, "training_loss": 562.3750122070312, "training_acc": 45.0, "val_loss": 2435.22314453125, "val_acc": 40.0}
{"epoch": 28, "training_loss": 1554.9052490234376, "training_acc": 35.0, "val_loss": 3429.952392578125, "val_acc": 40.0}
{"epoch": 29, "training_loss": 3202.110546875, "training_acc": 55.0, "val_loss": 2026.1497802734375, "val_acc": 40.0}
{"epoch": 30, "training_loss": 2098.337353515625, "training_acc": 55.0, "val_loss": 1602.0633544921875, "val_acc": 60.0}
{"epoch": 31, "training_loss": 2666.045703125, "training_acc": 45.0, "val_loss": 3055.327392578125, "val_acc": 40.0}
{"epoch": 32, "training_loss": 1025.257373046875, "training_acc": 65.0, "val_loss": 4766.4462890625, "val_acc": 60.0}
{"epoch": 33, "training_loss": 6196.1455078125, "training_acc": 45.0, "val_loss": 154.06651306152344, "val_acc": 40.0}
{"epoch": 34, "training_loss": 780.9286987304688, "training_acc": 55.0, "val_loss": 906.65625, "val_acc": 40.0}
{"epoch": 35, "training_loss": 2349.5927978515624, "training_acc": 35.0, "val_loss": 704.34521484375, "val_acc": 40.0}
{"epoch": 36, "training_loss": 669.1447219848633, "training_acc": 55.0, "val_loss": 1298.8701171875, "val_acc": 60.0}
{"epoch": 37, "training_loss": 1188.5420288085938, "training_acc": 55.0, "val_loss": 2869.898681640625, "val_acc": 40.0}
{"epoch": 38, "training_loss": 1464.7091430664063, "training_acc": 55.0, "val_loss": 3705.298583984375, "val_acc": 60.0}
{"epoch": 39, "training_loss": 7315.87548828125, "training_acc": 45.0, "val_loss": 3816.00634765625, "val_acc": 60.0}
{"epoch": 40, "training_loss": 3329.394189453125, "training_acc": 45.0, "val_loss": 10916.4189453125, "val_acc": 40.0}
{"epoch": 41, "training_loss": 8727.03701171875, "training_acc": 55.0, "val_loss": 9161.8759765625, "val_acc": 40.0}
{"epoch": 42, "training_loss": 3717.7107666015627, "training_acc": 55.0, "val_loss": 5027.4306640625, "val_acc": 60.0}
{"epoch": 43, "training_loss": 11599.2583984375, "training_acc": 45.0, "val_loss": 9072.392578125, "val_acc": 60.0}
{"epoch": 44, "training_loss": 9286.124114990234, "training_acc": 45.0, "val_loss": 6997.13916015625, "val_acc": 40.0}
{"epoch": 45, "training_loss": 7686.8525390625, "training_acc": 55.0, "val_loss": 14282.283203125, "val_acc": 40.0}
{"epoch": 46, "training_loss": 9011.58515625, "training_acc": 55.0, "val_loss": 1726.0804443359375, "val_acc": 40.0}
{"epoch": 47, "training_loss": 3850.877392578125, "training_acc": 55.0, "val_loss": 7262.54638671875, "val_acc": 60.0}
{"epoch": 48, "training_loss": 8272.1693359375, "training_acc": 45.0, "val_loss": 614.1447143554688, "val_acc": 40.0}
{"epoch": 49, "training_loss": 3235.0162963867188, "training_acc": 55.0, "val_loss": 6862.84716796875, "val_acc": 40.0}
{"epoch": 50, "training_loss": 4706.04912109375, "training_acc": 35.0, "val_loss": 1625.3345947265625, "val_acc": 60.0}
{"epoch": 51, "training_loss": 1165.5977661132813, "training_acc": 45.0, "val_loss": 1220.2691650390625, "val_acc": 60.0}
{"epoch": 52, "training_loss": 1503.34638671875, "training_acc": 45.0, "val_loss": 2273.595458984375, "val_acc": 40.0}
