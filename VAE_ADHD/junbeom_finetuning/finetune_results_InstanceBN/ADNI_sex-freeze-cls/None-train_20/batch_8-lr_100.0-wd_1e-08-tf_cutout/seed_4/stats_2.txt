"main_modify.py --pretrained_path None --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 4 --task ADNI_sex --input_option yAware --learning_rate 1e2 --batch_size 8 --weight_decay 1e-8 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 11303.27701306343, "training_acc": 50.0, "val_loss": 12160.9130859375, "val_acc": 40.0}
{"epoch": 1, "training_loss": 13234.4515625, "training_acc": 50.0, "val_loss": 5312.7431640625, "val_acc": 40.0}
{"epoch": 2, "training_loss": 6930.9171875, "training_acc": 50.0, "val_loss": 10491.712890625, "val_acc": 60.0}
{"epoch": 3, "training_loss": 10086.15048828125, "training_acc": 50.0, "val_loss": 3347.35546875, "val_acc": 40.0}
{"epoch": 4, "training_loss": 5490.0763671875, "training_acc": 50.0, "val_loss": 7337.41748046875, "val_acc": 40.0}
{"epoch": 5, "training_loss": 6056.715087890625, "training_acc": 30.0, "val_loss": 5747.94482421875, "val_acc": 60.0}
{"epoch": 6, "training_loss": 6256.442407226563, "training_acc": 50.0, "val_loss": 1889.501953125, "val_acc": 40.0}
{"epoch": 7, "training_loss": 2994.445361328125, "training_acc": 50.0, "val_loss": 415.7041931152344, "val_acc": 40.0}
{"epoch": 8, "training_loss": 2383.4403076171875, "training_acc": 60.0, "val_loss": 4438.78173828125, "val_acc": 60.0}
{"epoch": 9, "training_loss": 4261.588720703125, "training_acc": 40.0, "val_loss": 3100.624755859375, "val_acc": 40.0}
{"epoch": 10, "training_loss": 1584.9277770996093, "training_acc": 60.0, "val_loss": 1805.355712890625, "val_acc": 60.0}
{"epoch": 11, "training_loss": 2181.390869140625, "training_acc": 40.0, "val_loss": 2506.6015625, "val_acc": 40.0}
{"epoch": 12, "training_loss": 1568.29990234375, "training_acc": 50.0, "val_loss": 3846.714111328125, "val_acc": 60.0}
{"epoch": 13, "training_loss": 4516.888671875, "training_acc": 50.0, "val_loss": 2424.880126953125, "val_acc": 40.0}
{"epoch": 14, "training_loss": 3307.467578125, "training_acc": 50.0, "val_loss": 1903.0775146484375, "val_acc": 40.0}
{"epoch": 15, "training_loss": 2747.133251953125, "training_acc": 50.0, "val_loss": 3754.9765625, "val_acc": 60.0}
{"epoch": 16, "training_loss": 2696.231595611572, "training_acc": 60.0, "val_loss": 2704.638427734375, "val_acc": 40.0}
{"epoch": 17, "training_loss": 2112.85458984375, "training_acc": 50.0, "val_loss": 2634.65234375, "val_acc": 60.0}
{"epoch": 18, "training_loss": 4428.8669921875, "training_acc": 50.0, "val_loss": 2266.392578125, "val_acc": 60.0}
{"epoch": 19, "training_loss": 1518.27265625, "training_acc": 60.0, "val_loss": 2167.42626953125, "val_acc": 40.0}
{"epoch": 20, "training_loss": 1108.929898071289, "training_acc": 50.0, "val_loss": 994.5667114257812, "val_acc": 40.0}
{"epoch": 21, "training_loss": 1098.8029907226562, "training_acc": 30.0, "val_loss": 4164.7685546875, "val_acc": 40.0}
{"epoch": 22, "training_loss": 3769.4788818359375, "training_acc": 50.0, "val_loss": 1170.3538818359375, "val_acc": 40.0}
{"epoch": 23, "training_loss": 3165.577294921875, "training_acc": 40.0, "val_loss": 3356.72119140625, "val_acc": 60.0}
{"epoch": 24, "training_loss": 2747.3962890625, "training_acc": 50.0, "val_loss": 5168.40673828125, "val_acc": 40.0}
{"epoch": 25, "training_loss": 3679.643243408203, "training_acc": 50.0, "val_loss": 1985.3572998046875, "val_acc": 60.0}
{"epoch": 26, "training_loss": 2889.107470703125, "training_acc": 50.0, "val_loss": 575.9796752929688, "val_acc": 40.0}
{"epoch": 27, "training_loss": 1205.1462280273438, "training_acc": 30.0, "val_loss": 225.85562133789062, "val_acc": 60.0}
{"epoch": 28, "training_loss": 1111.497802734375, "training_acc": 70.0, "val_loss": 3860.86572265625, "val_acc": 40.0}
{"epoch": 29, "training_loss": 1782.3707641601563, "training_acc": 60.0, "val_loss": 3214.146240234375, "val_acc": 60.0}
{"epoch": 30, "training_loss": 3790.556640625, "training_acc": 50.0, "val_loss": 2053.3310546875, "val_acc": 40.0}
{"epoch": 31, "training_loss": 3423.0657470703127, "training_acc": 50.0, "val_loss": 2232.385986328125, "val_acc": 40.0}
{"epoch": 32, "training_loss": 2639.460595703125, "training_acc": 40.0, "val_loss": 1764.78125, "val_acc": 60.0}
{"epoch": 33, "training_loss": 903.5785095214844, "training_acc": 60.0, "val_loss": 392.3888244628906, "val_acc": 60.0}
{"epoch": 34, "training_loss": 1015.462548828125, "training_acc": 30.0, "val_loss": 222.3525848388672, "val_acc": 40.0}
{"epoch": 35, "training_loss": 957.1646606445313, "training_acc": 30.0, "val_loss": 528.4210815429688, "val_acc": 60.0}
{"epoch": 36, "training_loss": 700.8619873046875, "training_acc": 60.0, "val_loss": 2904.922607421875, "val_acc": 40.0}
{"epoch": 37, "training_loss": 1938.933511352539, "training_acc": 20.0, "val_loss": 254.5190887451172, "val_acc": 40.0}
{"epoch": 38, "training_loss": 1185.6208251953126, "training_acc": 60.0, "val_loss": 938.6959838867188, "val_acc": 60.0}
{"epoch": 39, "training_loss": 1348.310498046875, "training_acc": 60.0, "val_loss": 1898.1490478515625, "val_acc": 40.0}
{"epoch": 40, "training_loss": 2374.47587890625, "training_acc": 40.0, "val_loss": 749.17919921875, "val_acc": 60.0}
{"epoch": 41, "training_loss": 3812.32470703125, "training_acc": 30.0, "val_loss": 5107.4541015625, "val_acc": 40.0}
{"epoch": 42, "training_loss": 2765.34716796875, "training_acc": 50.0, "val_loss": 3468.282470703125, "val_acc": 60.0}
{"epoch": 43, "training_loss": 4542.02490234375, "training_acc": 50.0, "val_loss": 1120.2147216796875, "val_acc": 40.0}
{"epoch": 44, "training_loss": 1371.049609375, "training_acc": 50.0, "val_loss": 682.4390869140625, "val_acc": 60.0}
{"epoch": 45, "training_loss": 885.2360107421875, "training_acc": 50.0, "val_loss": 423.100830078125, "val_acc": 40.0}
{"epoch": 46, "training_loss": 1449.6787109375, "training_acc": 50.0, "val_loss": 65.52180480957031, "val_acc": 60.0}
{"epoch": 47, "training_loss": 2802.0313385009767, "training_acc": 50.0, "val_loss": 6512.83203125, "val_acc": 40.0}
{"epoch": 48, "training_loss": 3523.0248413085938, "training_acc": 50.0, "val_loss": 1748.514892578125, "val_acc": 60.0}
{"epoch": 49, "training_loss": 1682.594677734375, "training_acc": 50.0, "val_loss": 859.5711059570312, "val_acc": 40.0}
{"epoch": 50, "training_loss": 2098.62177734375, "training_acc": 30.0, "val_loss": 831.6500854492188, "val_acc": 40.0}
{"epoch": 51, "training_loss": 967.5275390625, "training_acc": 40.0, "val_loss": 321.5028381347656, "val_acc": 40.0}
{"epoch": 52, "training_loss": 498.0135101318359, "training_acc": 70.0, "val_loss": 2044.2398681640625, "val_acc": 60.0}
{"epoch": 53, "training_loss": 1969.6913330078125, "training_acc": 50.0, "val_loss": 1465.5323486328125, "val_acc": 40.0}
{"epoch": 54, "training_loss": 505.577392578125, "training_acc": 60.0, "val_loss": 2701.668212890625, "val_acc": 40.0}
{"epoch": 55, "training_loss": 2036.8963973999023, "training_acc": 50.0, "val_loss": 2009.507080078125, "val_acc": 60.0}
{"epoch": 56, "training_loss": 2510.5505859375, "training_acc": 50.0, "val_loss": 2093.294189453125, "val_acc": 40.0}
{"epoch": 57, "training_loss": 1800.45478515625, "training_acc": 50.0, "val_loss": 1283.561767578125, "val_acc": 60.0}
{"epoch": 58, "training_loss": 2575.651416015625, "training_acc": 50.0, "val_loss": 1980.7135009765625, "val_acc": 40.0}
{"epoch": 59, "training_loss": 2058.706091308594, "training_acc": 50.0, "val_loss": 226.1487274169922, "val_acc": 60.0}
{"epoch": 60, "training_loss": 382.2192626953125, "training_acc": 50.0, "val_loss": 863.0208129882812, "val_acc": 60.0}
{"epoch": 61, "training_loss": 751.8179321289062, "training_acc": 50.0, "val_loss": 1557.133544921875, "val_acc": 60.0}
{"epoch": 62, "training_loss": 1473.2752685546875, "training_acc": 50.0, "val_loss": 11.854292869567871, "val_acc": 80.0}
{"epoch": 63, "training_loss": 1027.2159172058105, "training_acc": 45.0, "val_loss": 1720.9088134765625, "val_acc": 60.0}
{"epoch": 64, "training_loss": 2563.0380859375, "training_acc": 50.0, "val_loss": 819.2487182617188, "val_acc": 40.0}
{"epoch": 65, "training_loss": 1680.1703857421876, "training_acc": 50.0, "val_loss": 2042.9898681640625, "val_acc": 60.0}
{"epoch": 66, "training_loss": 3315.16923828125, "training_acc": 50.0, "val_loss": 728.6138916015625, "val_acc": 60.0}
{"epoch": 67, "training_loss": 4647.3818359375, "training_acc": 30.0, "val_loss": 6724.30224609375, "val_acc": 40.0}
{"epoch": 68, "training_loss": 4229.738720703125, "training_acc": 50.0, "val_loss": 3639.585693359375, "val_acc": 60.0}
{"epoch": 69, "training_loss": 3990.716943359375, "training_acc": 50.0, "val_loss": 1930.151611328125, "val_acc": 40.0}
{"epoch": 70, "training_loss": 4246.936462402344, "training_acc": 50.0, "val_loss": 1430.5875244140625, "val_acc": 40.0}
{"epoch": 71, "training_loss": 3917.963330078125, "training_acc": 40.0, "val_loss": 5228.34521484375, "val_acc": 60.0}
{"epoch": 72, "training_loss": 4656.38603515625, "training_acc": 50.0, "val_loss": 4996.51318359375, "val_acc": 40.0}
{"epoch": 73, "training_loss": 6114.5091796875, "training_acc": 50.0, "val_loss": 7044.44384765625, "val_acc": 40.0}
{"epoch": 74, "training_loss": 3826.4890625, "training_acc": 50.0, "val_loss": 4960.13134765625, "val_acc": 60.0}
{"epoch": 75, "training_loss": 6669.905078125, "training_acc": 50.0, "val_loss": 2084.71484375, "val_acc": 60.0}
{"epoch": 76, "training_loss": 3704.7751953125, "training_acc": 40.0, "val_loss": 6419.6416015625, "val_acc": 40.0}
{"epoch": 77, "training_loss": 3962.303515625, "training_acc": 50.0, "val_loss": 3251.07421875, "val_acc": 60.0}
{"epoch": 78, "training_loss": 5456.30419921875, "training_acc": 50.0, "val_loss": 6268.73681640625, "val_acc": 60.0}
{"epoch": 79, "training_loss": 5938.117016601563, "training_acc": 50.0, "val_loss": 4893.7919921875, "val_acc": 40.0}
{"epoch": 80, "training_loss": 5213.395068359375, "training_acc": 50.0, "val_loss": 6600.22021484375, "val_acc": 40.0}
{"epoch": 81, "training_loss": 4779.433984375, "training_acc": 30.0, "val_loss": 2613.247802734375, "val_acc": 60.0}
