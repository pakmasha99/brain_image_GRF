"main_modify.py --pretrained_path None --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_sex --input_option yAware --learning_rate 1e2 --batch_size 8 --weight_decay 1e-8 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 17112.05253844261, "training_acc": 20.0, "val_loss": 600.5255126953125, "val_acc": 60.0}
{"epoch": 1, "training_loss": 7669.871337890625, "training_acc": 60.0, "val_loss": 28386.78125, "val_acc": 40.0}
{"epoch": 2, "training_loss": 21826.108984375, "training_acc": 50.0, "val_loss": 12573.8193359375, "val_acc": 40.0}
{"epoch": 3, "training_loss": 4209.709375, "training_acc": 60.0, "val_loss": 12088.330078125, "val_acc": 60.0}
{"epoch": 4, "training_loss": 18345.01796875, "training_acc": 50.0, "val_loss": 14165.1396484375, "val_acc": 60.0}
{"epoch": 5, "training_loss": 14130.3158203125, "training_acc": 50.0, "val_loss": 1554.7620849609375, "val_acc": 40.0}
{"epoch": 6, "training_loss": 3244.802685546875, "training_acc": 50.0, "val_loss": 6642.23779296875, "val_acc": 40.0}
{"epoch": 7, "training_loss": 3201.0344970703127, "training_acc": 60.0, "val_loss": 3232.099609375, "val_acc": 60.0}
{"epoch": 8, "training_loss": 3868.5439453125, "training_acc": 50.0, "val_loss": 2746.1640625, "val_acc": 40.0}
{"epoch": 9, "training_loss": 3551.8436279296875, "training_acc": 50.0, "val_loss": 2208.57666015625, "val_acc": 40.0}
{"epoch": 10, "training_loss": 1047.2270751953124, "training_acc": 70.0, "val_loss": 1127.4925537109375, "val_acc": 60.0}
{"epoch": 11, "training_loss": 1749.247265625, "training_acc": 50.0, "val_loss": 762.2645263671875, "val_acc": 40.0}
{"epoch": 12, "training_loss": 2211.898876953125, "training_acc": 50.0, "val_loss": 2566.52294921875, "val_acc": 60.0}
{"epoch": 13, "training_loss": 1764.9426025390626, "training_acc": 60.0, "val_loss": 7653.9140625, "val_acc": 40.0}
{"epoch": 14, "training_loss": 6023.9185546875, "training_acc": 50.0, "val_loss": 205.9871826171875, "val_acc": 40.0}
{"epoch": 15, "training_loss": 4670.129608154297, "training_acc": 50.0, "val_loss": 7633.08984375, "val_acc": 60.0}
{"epoch": 16, "training_loss": 7030.63505859375, "training_acc": 50.0, "val_loss": 4038.567138671875, "val_acc": 40.0}
{"epoch": 17, "training_loss": 5615.3810546875, "training_acc": 50.0, "val_loss": 8397.6591796875, "val_acc": 40.0}
{"epoch": 18, "training_loss": 4265.504354858398, "training_acc": 60.0, "val_loss": 2265.243896484375, "val_acc": 60.0}
{"epoch": 19, "training_loss": 2753.30986328125, "training_acc": 50.0, "val_loss": 3447.953125, "val_acc": 40.0}
{"epoch": 20, "training_loss": 3578.6890625, "training_acc": 50.0, "val_loss": 2036.196533203125, "val_acc": 40.0}
{"epoch": 21, "training_loss": 2363.3717041015625, "training_acc": 50.0, "val_loss": 3073.864013671875, "val_acc": 60.0}
{"epoch": 22, "training_loss": 2820.387890625, "training_acc": 50.0, "val_loss": 5367.71484375, "val_acc": 40.0}
{"epoch": 23, "training_loss": 3269.993310546875, "training_acc": 50.0, "val_loss": 3273.4453125, "val_acc": 60.0}
{"epoch": 24, "training_loss": 4645.3140625, "training_acc": 50.0, "val_loss": 3368.15478515625, "val_acc": 60.0}
{"epoch": 25, "training_loss": 2678.172900390625, "training_acc": 50.0, "val_loss": 7454.84912109375, "val_acc": 40.0}
{"epoch": 26, "training_loss": 5742.130810546875, "training_acc": 50.0, "val_loss": 140.9825897216797, "val_acc": 60.0}
{"epoch": 27, "training_loss": 358.50489501953126, "training_acc": 50.0, "val_loss": 163.4132080078125, "val_acc": 60.0}
{"epoch": 28, "training_loss": 283.1111267089844, "training_acc": 60.0, "val_loss": 1044.8831787109375, "val_acc": 40.0}
{"epoch": 29, "training_loss": 895.7958801269531, "training_acc": 40.0, "val_loss": 88.05741119384766, "val_acc": 40.0}
{"epoch": 30, "training_loss": 2881.9450134277345, "training_acc": 40.0, "val_loss": 3124.792724609375, "val_acc": 60.0}
{"epoch": 31, "training_loss": 2578.325634765625, "training_acc": 50.0, "val_loss": 5857.25439453125, "val_acc": 40.0}
{"epoch": 32, "training_loss": 4461.31982421875, "training_acc": 50.0, "val_loss": 1416.8206787109375, "val_acc": 60.0}
{"epoch": 33, "training_loss": 2132.354736328125, "training_acc": 50.0, "val_loss": 838.2136840820312, "val_acc": 60.0}
{"epoch": 34, "training_loss": 2047.780322265625, "training_acc": 50.0, "val_loss": 2617.148193359375, "val_acc": 40.0}
{"epoch": 35, "training_loss": 1619.4618896484376, "training_acc": 50.0, "val_loss": 336.9144592285156, "val_acc": 60.0}
{"epoch": 36, "training_loss": 3044.205358886719, "training_acc": 40.0, "val_loss": 3609.748779296875, "val_acc": 40.0}
{"epoch": 37, "training_loss": 2211.915283203125, "training_acc": 50.0, "val_loss": 952.7545166015625, "val_acc": 60.0}
{"epoch": 38, "training_loss": 2527.2982666015623, "training_acc": 40.0, "val_loss": 3008.55126953125, "val_acc": 40.0}
{"epoch": 39, "training_loss": 1269.1743774414062, "training_acc": 60.0, "val_loss": 5080.37060546875, "val_acc": 60.0}
{"epoch": 40, "training_loss": 5754.01494140625, "training_acc": 50.0, "val_loss": 397.60260009765625, "val_acc": 60.0}
{"epoch": 41, "training_loss": 4589.674609375, "training_acc": 40.0, "val_loss": 10377.5341796875, "val_acc": 40.0}
{"epoch": 42, "training_loss": 6878.44296875, "training_acc": 50.0, "val_loss": 1734.7537841796875, "val_acc": 60.0}
{"epoch": 43, "training_loss": 3710.89296875, "training_acc": 50.0, "val_loss": 2898.215576171875, "val_acc": 60.0}
{"epoch": 44, "training_loss": 1919.8710205078125, "training_acc": 60.0, "val_loss": 8280.09375, "val_acc": 40.0}
{"epoch": 45, "training_loss": 6519.297509765625, "training_acc": 50.0, "val_loss": 1720.0262451171875, "val_acc": 40.0}
{"epoch": 46, "training_loss": 2917.59140625, "training_acc": 50.0, "val_loss": 4201.3671875, "val_acc": 60.0}
{"epoch": 47, "training_loss": 5064.63154296875, "training_acc": 30.0, "val_loss": 4232.8427734375, "val_acc": 40.0}
{"epoch": 48, "training_loss": 2615.635107421875, "training_acc": 50.0, "val_loss": 2800.86376953125, "val_acc": 60.0}
