"main_modify.py --pretrained_path None --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_sex --input_option yAware --learning_rate 1e2 --batch_size 8 --weight_decay 1e-8 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 16984.700726127623, "training_acc": 45.0, "val_loss": 5737.2744140625, "val_acc": 40.0}
{"epoch": 1, "training_loss": 6895.0435546875, "training_acc": 55.0, "val_loss": 8191.34912109375, "val_acc": 40.0}
{"epoch": 2, "training_loss": 3841.696179199219, "training_acc": 35.0, "val_loss": 2664.32373046875, "val_acc": 40.0}
{"epoch": 3, "training_loss": 1876.9771484375, "training_acc": 45.0, "val_loss": 922.8982543945312, "val_acc": 40.0}
{"epoch": 4, "training_loss": 1309.738037109375, "training_acc": 45.0, "val_loss": 1938.958251953125, "val_acc": 60.0}
{"epoch": 5, "training_loss": 2767.497705078125, "training_acc": 35.0, "val_loss": 580.0993041992188, "val_acc": 40.0}
{"epoch": 6, "training_loss": 3050.3516357421877, "training_acc": 45.0, "val_loss": 2583.654541015625, "val_acc": 60.0}
{"epoch": 7, "training_loss": 3382.066943359375, "training_acc": 35.0, "val_loss": 2615.251220703125, "val_acc": 40.0}
{"epoch": 8, "training_loss": 827.0522766113281, "training_acc": 55.0, "val_loss": 1454.357421875, "val_acc": 40.0}
{"epoch": 9, "training_loss": 908.7759887695313, "training_acc": 55.0, "val_loss": 550.8512573242188, "val_acc": 60.0}
{"epoch": 10, "training_loss": 1117.3869873046874, "training_acc": 55.0, "val_loss": 724.326171875, "val_acc": 40.0}
{"epoch": 11, "training_loss": 1788.175, "training_acc": 55.0, "val_loss": 1004.5785522460938, "val_acc": 60.0}
{"epoch": 12, "training_loss": 1708.002294921875, "training_acc": 55.0, "val_loss": 5033.49755859375, "val_acc": 40.0}
{"epoch": 13, "training_loss": 2649.2041137695314, "training_acc": 55.0, "val_loss": 3044.584716796875, "val_acc": 60.0}
{"epoch": 14, "training_loss": 4198.936572265625, "training_acc": 45.0, "val_loss": 890.3101806640625, "val_acc": 60.0}
{"epoch": 15, "training_loss": 2138.64150390625, "training_acc": 55.0, "val_loss": 6691.2890625, "val_acc": 40.0}
{"epoch": 16, "training_loss": 3947.0288330078124, "training_acc": 55.0, "val_loss": 2582.11474609375, "val_acc": 60.0}
{"epoch": 17, "training_loss": 3940.7328369140623, "training_acc": 45.0, "val_loss": 156.0185546875, "val_acc": 60.0}
{"epoch": 18, "training_loss": 4318.0607421875, "training_acc": 35.0, "val_loss": 8389.345703125, "val_acc": 40.0}
{"epoch": 19, "training_loss": 4318.9701171875, "training_acc": 55.0, "val_loss": 3263.356201171875, "val_acc": 60.0}
{"epoch": 20, "training_loss": 7293.70869140625, "training_acc": 45.0, "val_loss": 4426.21923828125, "val_acc": 60.0}
{"epoch": 21, "training_loss": 4883.317822265625, "training_acc": 35.0, "val_loss": 10383.43359375, "val_acc": 40.0}
{"epoch": 22, "training_loss": 8369.4248046875, "training_acc": 55.0, "val_loss": 7749.02734375, "val_acc": 40.0}
{"epoch": 23, "training_loss": 4165.61611328125, "training_acc": 55.0, "val_loss": 4240.76904296875, "val_acc": 60.0}
{"epoch": 24, "training_loss": 5229.386865234375, "training_acc": 45.0, "val_loss": 1151.6419677734375, "val_acc": 40.0}
{"epoch": 25, "training_loss": 2907.9731689453124, "training_acc": 55.0, "val_loss": 1355.8499755859375, "val_acc": 40.0}
{"epoch": 26, "training_loss": 1721.690869140625, "training_acc": 65.0, "val_loss": 3705.403076171875, "val_acc": 60.0}
{"epoch": 27, "training_loss": 3546.182861328125, "training_acc": 45.0, "val_loss": 3440.210205078125, "val_acc": 40.0}
{"epoch": 28, "training_loss": 2798.785205078125, "training_acc": 55.0, "val_loss": 1893.4176025390625, "val_acc": 60.0}
{"epoch": 29, "training_loss": 3049.162353515625, "training_acc": 45.0, "val_loss": 511.95806884765625, "val_acc": 40.0}
{"epoch": 30, "training_loss": 868.6928237915039, "training_acc": 40.0, "val_loss": 658.2551879882812, "val_acc": 40.0}
{"epoch": 31, "training_loss": 1127.3458923339845, "training_acc": 45.0, "val_loss": 1030.7181396484375, "val_acc": 40.0}
{"epoch": 32, "training_loss": 749.84921875, "training_acc": 55.0, "val_loss": 1624.2802734375, "val_acc": 60.0}
{"epoch": 33, "training_loss": 2175.6431640625, "training_acc": 35.0, "val_loss": 6650.41748046875, "val_acc": 40.0}
{"epoch": 34, "training_loss": 3931.528857421875, "training_acc": 55.0, "val_loss": 1555.2025146484375, "val_acc": 60.0}
{"epoch": 35, "training_loss": 3538.2412109375, "training_acc": 45.0, "val_loss": 77.58597564697266, "val_acc": 40.0}
{"epoch": 36, "training_loss": 2142.060905456543, "training_acc": 60.0, "val_loss": 7522.21435546875, "val_acc": 40.0}
{"epoch": 37, "training_loss": 4435.9392578125, "training_acc": 55.0, "val_loss": 1633.8779296875, "val_acc": 60.0}
{"epoch": 38, "training_loss": 3547.976318359375, "training_acc": 45.0, "val_loss": 920.1394653320312, "val_acc": 60.0}
{"epoch": 39, "training_loss": 2465.91552734375, "training_acc": 45.0, "val_loss": 5515.25, "val_acc": 40.0}
{"epoch": 40, "training_loss": 2477.355584716797, "training_acc": 65.0, "val_loss": 1237.5634765625, "val_acc": 60.0}
{"epoch": 41, "training_loss": 1514.463671875, "training_acc": 45.0, "val_loss": 3564.951171875, "val_acc": 40.0}
{"epoch": 42, "training_loss": 1812.0761840820312, "training_acc": 55.0, "val_loss": 789.0131225585938, "val_acc": 60.0}
{"epoch": 43, "training_loss": 721.9842041015625, "training_acc": 55.0, "val_loss": 881.48388671875, "val_acc": 60.0}
{"epoch": 44, "training_loss": 1310.9151428222656, "training_acc": 55.0, "val_loss": 1948.3504638671875, "val_acc": 40.0}
{"epoch": 45, "training_loss": 1485.723583984375, "training_acc": 45.0, "val_loss": 1237.3333740234375, "val_acc": 60.0}
{"epoch": 46, "training_loss": 1742.052392578125, "training_acc": 45.0, "val_loss": 307.3069152832031, "val_acc": 40.0}
{"epoch": 47, "training_loss": 2986.1029296875, "training_acc": 45.0, "val_loss": 2761.692138671875, "val_acc": 60.0}
{"epoch": 48, "training_loss": 2279.5782257080077, "training_acc": 55.0, "val_loss": 3623.761474609375, "val_acc": 40.0}
{"epoch": 49, "training_loss": 2988.34208984375, "training_acc": 35.0, "val_loss": 2830.189208984375, "val_acc": 60.0}
{"epoch": 50, "training_loss": 2176.4615234375, "training_acc": 55.0, "val_loss": 5515.28271484375, "val_acc": 40.0}
{"epoch": 51, "training_loss": 4253.539965820312, "training_acc": 55.0, "val_loss": 902.6799926757812, "val_acc": 40.0}
{"epoch": 52, "training_loss": 3780.8990966796873, "training_acc": 45.0, "val_loss": 3527.92822265625, "val_acc": 60.0}
{"epoch": 53, "training_loss": 3305.00869140625, "training_acc": 45.0, "val_loss": 9915.63671875, "val_acc": 40.0}
{"epoch": 54, "training_loss": 7293.8064453125, "training_acc": 55.0, "val_loss": 6258.37451171875, "val_acc": 40.0}
