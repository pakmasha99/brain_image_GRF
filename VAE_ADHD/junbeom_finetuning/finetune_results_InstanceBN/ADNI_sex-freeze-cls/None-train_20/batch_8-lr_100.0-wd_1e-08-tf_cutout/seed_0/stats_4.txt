"main_modify.py --pretrained_path None --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_sex --input_option yAware --learning_rate 1e2 --batch_size 8 --weight_decay 1e-8 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 10594.451157188416, "training_acc": 45.0, "val_loss": 4384.36279296875, "val_acc": 60.0}
{"epoch": 1, "training_loss": 12455.8271484375, "training_acc": 45.0, "val_loss": 1780.273681640625, "val_acc": 60.0}
{"epoch": 2, "training_loss": 5486.27763671875, "training_acc": 65.0, "val_loss": 22323.607421875, "val_acc": 40.0}
{"epoch": 3, "training_loss": 17382.1494140625, "training_acc": 55.0, "val_loss": 14051.087890625, "val_acc": 40.0}
{"epoch": 4, "training_loss": 4347.2705078125, "training_acc": 75.0, "val_loss": 9002.154296875, "val_acc": 60.0}
{"epoch": 5, "training_loss": 15002.441796875, "training_acc": 45.0, "val_loss": 10025.6474609375, "val_acc": 60.0}
{"epoch": 6, "training_loss": 8527.182885742188, "training_acc": 45.0, "val_loss": 9497.541015625, "val_acc": 40.0}
{"epoch": 7, "training_loss": 11291.510546875, "training_acc": 55.0, "val_loss": 21798.572265625, "val_acc": 40.0}
{"epoch": 8, "training_loss": 14986.650390625, "training_acc": 55.0, "val_loss": 9899.0966796875, "val_acc": 40.0}
{"epoch": 9, "training_loss": 3566.744482421875, "training_acc": 65.0, "val_loss": 9294.4091796875, "val_acc": 60.0}
{"epoch": 10, "training_loss": 14322.041015625, "training_acc": 45.0, "val_loss": 9258.931640625, "val_acc": 60.0}
{"epoch": 11, "training_loss": 7991.141137695313, "training_acc": 45.0, "val_loss": 9416.1357421875, "val_acc": 40.0}
{"epoch": 12, "training_loss": 11727.59140625, "training_acc": 55.0, "val_loss": 21200.2578125, "val_acc": 40.0}
{"epoch": 13, "training_loss": 14621.63525390625, "training_acc": 55.0, "val_loss": 7777.93115234375, "val_acc": 40.0}
{"epoch": 14, "training_loss": 3873.3024047851563, "training_acc": 35.0, "val_loss": 2626.317626953125, "val_acc": 60.0}
{"epoch": 15, "training_loss": 2150.0932739257814, "training_acc": 55.0, "val_loss": 5035.587890625, "val_acc": 40.0}
{"epoch": 16, "training_loss": 3379.69814453125, "training_acc": 55.0, "val_loss": 897.1544189453125, "val_acc": 60.0}
{"epoch": 17, "training_loss": 2768.49140625, "training_acc": 45.0, "val_loss": 1225.6912841796875, "val_acc": 40.0}
{"epoch": 18, "training_loss": 1530.44658203125, "training_acc": 55.0, "val_loss": 360.3765563964844, "val_acc": 60.0}
{"epoch": 19, "training_loss": 313.1441589355469, "training_acc": 55.0, "val_loss": 2469.426513671875, "val_acc": 60.0}
{"epoch": 20, "training_loss": 3299.301904296875, "training_acc": 45.0, "val_loss": 2127.005859375, "val_acc": 40.0}
{"epoch": 21, "training_loss": 1758.982666015625, "training_acc": 55.0, "val_loss": 340.93145751953125, "val_acc": 60.0}
{"epoch": 22, "training_loss": 829.6172607421875, "training_acc": 45.0, "val_loss": 2360.654541015625, "val_acc": 40.0}
{"epoch": 23, "training_loss": 1561.35888671875, "training_acc": 25.0, "val_loss": 674.1432495117188, "val_acc": 60.0}
{"epoch": 24, "training_loss": 632.7574951171875, "training_acc": 65.0, "val_loss": 3227.146484375, "val_acc": 40.0}
{"epoch": 25, "training_loss": 1782.43701171875, "training_acc": 55.0, "val_loss": 2769.103515625, "val_acc": 60.0}
{"epoch": 26, "training_loss": 4152.849462890625, "training_acc": 45.0, "val_loss": 26.969863891601562, "val_acc": 60.0}
{"epoch": 27, "training_loss": 1571.222656273842, "training_acc": 65.0, "val_loss": 361.3619079589844, "val_acc": 60.0}
{"epoch": 28, "training_loss": 707.1418090820313, "training_acc": 45.0, "val_loss": 2807.46337890625, "val_acc": 40.0}
{"epoch": 29, "training_loss": 1144.055859375, "training_acc": 65.0, "val_loss": 2775.601318359375, "val_acc": 60.0}
{"epoch": 30, "training_loss": 2567.5193115234374, "training_acc": 45.0, "val_loss": 6351.35791015625, "val_acc": 40.0}
{"epoch": 31, "training_loss": 6635.7486328125, "training_acc": 55.0, "val_loss": 9645.2197265625, "val_acc": 40.0}
{"epoch": 32, "training_loss": 4456.159094238281, "training_acc": 55.0, "val_loss": 4592.93408203125, "val_acc": 60.0}
{"epoch": 33, "training_loss": 8418.8025390625, "training_acc": 45.0, "val_loss": 6791.6455078125, "val_acc": 60.0}
{"epoch": 34, "training_loss": 5379.69130859375, "training_acc": 45.0, "val_loss": 8067.3203125, "val_acc": 40.0}
{"epoch": 35, "training_loss": 11472.176171875, "training_acc": 55.0, "val_loss": 20094.115234375, "val_acc": 40.0}
{"epoch": 36, "training_loss": 13468.62578125, "training_acc": 55.0, "val_loss": 8098.63818359375, "val_acc": 40.0}
{"epoch": 37, "training_loss": 2861.34599609375, "training_acc": 55.0, "val_loss": 8301.197265625, "val_acc": 60.0}
{"epoch": 38, "training_loss": 11923.5017578125, "training_acc": 45.0, "val_loss": 6936.99853515625, "val_acc": 60.0}
{"epoch": 39, "training_loss": 5709.219616699219, "training_acc": 55.0, "val_loss": 7198.359375, "val_acc": 40.0}
{"epoch": 40, "training_loss": 6193.54208984375, "training_acc": 55.0, "val_loss": 7001.8486328125, "val_acc": 40.0}
{"epoch": 41, "training_loss": 3111.23828125, "training_acc": 55.0, "val_loss": 2597.829833984375, "val_acc": 60.0}
{"epoch": 42, "training_loss": 3186.4060546875, "training_acc": 50.0, "val_loss": 3452.277099609375, "val_acc": 40.0}
{"epoch": 43, "training_loss": 2655.3373779296876, "training_acc": 55.0, "val_loss": 459.772216796875, "val_acc": 60.0}
{"epoch": 44, "training_loss": 529.1127624511719, "training_acc": 45.0, "val_loss": 852.8009643554688, "val_acc": 60.0}
{"epoch": 45, "training_loss": 885.3162109375, "training_acc": 55.0, "val_loss": 604.4893798828125, "val_acc": 60.0}
