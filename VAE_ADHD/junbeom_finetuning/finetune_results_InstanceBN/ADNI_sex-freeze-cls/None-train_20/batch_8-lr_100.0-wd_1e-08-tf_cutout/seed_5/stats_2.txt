"main_modify.py --pretrained_path None --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 5 --task ADNI_sex --input_option yAware --learning_rate 1e2 --batch_size 8 --weight_decay 1e-8 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 13571.366973352433, "training_acc": 50.0, "val_loss": 5679.79296875, "val_acc": 60.0}
{"epoch": 1, "training_loss": 8780.47421875, "training_acc": 50.0, "val_loss": 611.0515747070312, "val_acc": 60.0}
{"epoch": 2, "training_loss": 7187.285473632813, "training_acc": 40.0, "val_loss": 13337.494140625, "val_acc": 40.0}
{"epoch": 3, "training_loss": 7889.949966430664, "training_acc": 50.0, "val_loss": 2064.843017578125, "val_acc": 60.0}
{"epoch": 4, "training_loss": 2219.059375, "training_acc": 50.0, "val_loss": 1247.91796875, "val_acc": 40.0}
{"epoch": 5, "training_loss": 1666.9086853027343, "training_acc": 40.0, "val_loss": 1819.6304931640625, "val_acc": 40.0}
{"epoch": 6, "training_loss": 1362.756640625, "training_acc": 50.0, "val_loss": 1278.99755859375, "val_acc": 60.0}
{"epoch": 7, "training_loss": 1517.4653198242188, "training_acc": 40.0, "val_loss": 1349.2449951171875, "val_acc": 60.0}
{"epoch": 8, "training_loss": 1115.3649536132812, "training_acc": 60.0, "val_loss": 712.8280639648438, "val_acc": 40.0}
{"epoch": 9, "training_loss": 1050.4360595703124, "training_acc": 50.0, "val_loss": 2036.149658203125, "val_acc": 40.0}
{"epoch": 10, "training_loss": 1802.36083984375, "training_acc": 50.0, "val_loss": 2088.77197265625, "val_acc": 60.0}
{"epoch": 11, "training_loss": 3375.225439453125, "training_acc": 50.0, "val_loss": 551.0613403320312, "val_acc": 60.0}
{"epoch": 12, "training_loss": 4940.219921875, "training_acc": 30.0, "val_loss": 7463.35498046875, "val_acc": 40.0}
{"epoch": 13, "training_loss": 3572.339984130859, "training_acc": 60.0, "val_loss": 2638.635498046875, "val_acc": 60.0}
{"epoch": 14, "training_loss": 3184.88037109375, "training_acc": 50.0, "val_loss": 1870.30859375, "val_acc": 40.0}
{"epoch": 15, "training_loss": 2115.135693359375, "training_acc": 50.0, "val_loss": 865.8718872070312, "val_acc": 60.0}
{"epoch": 16, "training_loss": 815.2245239257812, "training_acc": 60.0, "val_loss": 665.5902709960938, "val_acc": 40.0}
{"epoch": 17, "training_loss": 1046.5331909179688, "training_acc": 30.0, "val_loss": 1967.2498779296875, "val_acc": 60.0}
{"epoch": 18, "training_loss": 2860.343798828125, "training_acc": 50.0, "val_loss": 2071.25, "val_acc": 40.0}
{"epoch": 19, "training_loss": 2660.9953125, "training_acc": 50.0, "val_loss": 1504.60888671875, "val_acc": 40.0}
{"epoch": 20, "training_loss": 2645.67060546875, "training_acc": 50.0, "val_loss": 3604.48291015625, "val_acc": 60.0}
{"epoch": 21, "training_loss": 2780.2216674804686, "training_acc": 60.0, "val_loss": 4468.98583984375, "val_acc": 40.0}
{"epoch": 22, "training_loss": 3277.30546875, "training_acc": 50.0, "val_loss": 1754.2076416015625, "val_acc": 60.0}
{"epoch": 23, "training_loss": 2560.677294921875, "training_acc": 50.0, "val_loss": 0.9995409250259399, "val_acc": 80.0}
{"epoch": 24, "training_loss": 2171.250576877594, "training_acc": 60.0, "val_loss": 3760.397216796875, "val_acc": 40.0}
{"epoch": 25, "training_loss": 3484.251904296875, "training_acc": 20.0, "val_loss": 306.4047546386719, "val_acc": 60.0}
{"epoch": 26, "training_loss": 1933.796826171875, "training_acc": 50.0, "val_loss": 3408.705810546875, "val_acc": 40.0}
{"epoch": 27, "training_loss": 2526.83642578125, "training_acc": 40.0, "val_loss": 4042.314208984375, "val_acc": 60.0}
{"epoch": 28, "training_loss": 4168.35712890625, "training_acc": 50.0, "val_loss": 2893.930419921875, "val_acc": 40.0}
{"epoch": 29, "training_loss": 3405.81767578125, "training_acc": 50.0, "val_loss": 3789.672607421875, "val_acc": 40.0}
{"epoch": 30, "training_loss": 2835.4675170898436, "training_acc": 40.0, "val_loss": 5213.62744140625, "val_acc": 60.0}
{"epoch": 31, "training_loss": 6068.461328125, "training_acc": 50.0, "val_loss": 13.622702598571777, "val_acc": 80.0}
{"epoch": 32, "training_loss": 1910.649437522888, "training_acc": 75.0, "val_loss": 9168.2490234375, "val_acc": 40.0}
{"epoch": 33, "training_loss": 6599.037866210938, "training_acc": 50.0, "val_loss": 1411.5877685546875, "val_acc": 60.0}
{"epoch": 34, "training_loss": 2157.3896484375, "training_acc": 50.0, "val_loss": 318.5587463378906, "val_acc": 40.0}
{"epoch": 35, "training_loss": 561.0548706054688, "training_acc": 50.0, "val_loss": 583.722900390625, "val_acc": 60.0}
{"epoch": 36, "training_loss": 1443.4072998046875, "training_acc": 50.0, "val_loss": 105.08414459228516, "val_acc": 60.0}
{"epoch": 37, "training_loss": 481.4286743164063, "training_acc": 50.0, "val_loss": 1330.7784423828125, "val_acc": 40.0}
{"epoch": 38, "training_loss": 731.0042785644531, "training_acc": 40.0, "val_loss": 2352.778076171875, "val_acc": 60.0}
{"epoch": 39, "training_loss": 2989.6057983398437, "training_acc": 50.0, "val_loss": 800.9404296875, "val_acc": 40.0}
{"epoch": 40, "training_loss": 567.2357208251954, "training_acc": 60.0, "val_loss": 388.7564392089844, "val_acc": 60.0}
{"epoch": 41, "training_loss": 316.93483276367186, "training_acc": 60.0, "val_loss": 2278.427978515625, "val_acc": 40.0}
{"epoch": 42, "training_loss": 1590.2290313720703, "training_acc": 50.0, "val_loss": 2808.111572265625, "val_acc": 60.0}
