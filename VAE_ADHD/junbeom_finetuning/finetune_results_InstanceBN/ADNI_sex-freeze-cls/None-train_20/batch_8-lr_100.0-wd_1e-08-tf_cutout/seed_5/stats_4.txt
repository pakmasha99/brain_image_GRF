"main_modify.py --pretrained_path None --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 5 --task ADNI_sex --input_option yAware --learning_rate 1e2 --batch_size 8 --weight_decay 1e-8 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 8808.717643117905, "training_acc": 50.0, "val_loss": 11761.52734375, "val_acc": 60.0}
{"epoch": 1, "training_loss": 22120.86171875, "training_acc": 50.0, "val_loss": 16491.130859375, "val_acc": 60.0}
{"epoch": 2, "training_loss": 14417.498364257812, "training_acc": 50.0, "val_loss": 12006.244140625, "val_acc": 40.0}
{"epoch": 3, "training_loss": 14482.078125, "training_acc": 50.0, "val_loss": 22852.857421875, "val_acc": 40.0}
{"epoch": 4, "training_loss": 16686.9111328125, "training_acc": 50.0, "val_loss": 4732.65625, "val_acc": 40.0}
{"epoch": 5, "training_loss": 5021.01552734375, "training_acc": 50.0, "val_loss": 8592.189453125, "val_acc": 60.0}
{"epoch": 6, "training_loss": 9819.843359375, "training_acc": 50.0, "val_loss": 2065.751708984375, "val_acc": 60.0}
{"epoch": 7, "training_loss": 3426.35751953125, "training_acc": 60.0, "val_loss": 13538.7255859375, "val_acc": 40.0}
{"epoch": 8, "training_loss": 11110.34580078125, "training_acc": 50.0, "val_loss": 6619.67822265625, "val_acc": 40.0}
{"epoch": 9, "training_loss": 2261.940771484375, "training_acc": 60.0, "val_loss": 7840.91748046875, "val_acc": 60.0}
{"epoch": 10, "training_loss": 10115.7775390625, "training_acc": 50.0, "val_loss": 6592.5791015625, "val_acc": 60.0}
{"epoch": 11, "training_loss": 5272.84658203125, "training_acc": 50.0, "val_loss": 6132.70947265625, "val_acc": 40.0}
{"epoch": 12, "training_loss": 6237.2787109375, "training_acc": 50.0, "val_loss": 2238.8955078125, "val_acc": 40.0}
{"epoch": 13, "training_loss": 2213.105126953125, "training_acc": 60.0, "val_loss": 4770.6689453125, "val_acc": 60.0}
{"epoch": 14, "training_loss": 4376.363330078125, "training_acc": 50.0, "val_loss": 5048.1435546875, "val_acc": 40.0}
{"epoch": 15, "training_loss": 6266.9314453125, "training_acc": 50.0, "val_loss": 6074.58349609375, "val_acc": 40.0}
{"epoch": 16, "training_loss": 4405.453198242188, "training_acc": 40.0, "val_loss": 6436.4228515625, "val_acc": 60.0}
{"epoch": 17, "training_loss": 7956.606640625, "training_acc": 50.0, "val_loss": 2042.802978515625, "val_acc": 60.0}
{"epoch": 18, "training_loss": 6272.88740234375, "training_acc": 30.0, "val_loss": 10416.75, "val_acc": 40.0}
{"epoch": 19, "training_loss": 7095.461962890625, "training_acc": 50.0, "val_loss": 1128.2529296875, "val_acc": 60.0}
{"epoch": 20, "training_loss": 2078.1807373046877, "training_acc": 50.0, "val_loss": 1711.645751953125, "val_acc": 60.0}
{"epoch": 21, "training_loss": 892.4123168945313, "training_acc": 60.0, "val_loss": 406.8119812011719, "val_acc": 60.0}
{"epoch": 22, "training_loss": 763.5115966796875, "training_acc": 50.0, "val_loss": 3491.611083984375, "val_acc": 40.0}
{"epoch": 23, "training_loss": 1798.5394348144532, "training_acc": 60.0, "val_loss": 2123.5185546875, "val_acc": 60.0}
{"epoch": 24, "training_loss": 1940.2687255859375, "training_acc": 50.0, "val_loss": 959.1282348632812, "val_acc": 40.0}
{"epoch": 25, "training_loss": 1472.987158203125, "training_acc": 40.0, "val_loss": 1221.7562255859375, "val_acc": 40.0}
{"epoch": 26, "training_loss": 752.0671569824219, "training_acc": 60.0, "val_loss": 552.1737670898438, "val_acc": 60.0}
{"epoch": 27, "training_loss": 516.7426147460938, "training_acc": 50.0, "val_loss": 2308.162841796875, "val_acc": 40.0}
{"epoch": 28, "training_loss": 1844.3423828125, "training_acc": 40.0, "val_loss": 612.5968017578125, "val_acc": 60.0}
{"epoch": 29, "training_loss": 970.810400390625, "training_acc": 60.0, "val_loss": 599.4904174804688, "val_acc": 40.0}
{"epoch": 30, "training_loss": 1258.6271606445312, "training_acc": 60.0, "val_loss": 935.8139038085938, "val_acc": 60.0}
{"epoch": 31, "training_loss": 1235.518017578125, "training_acc": 60.0, "val_loss": 1945.6439208984375, "val_acc": 40.0}
{"epoch": 32, "training_loss": 2576.76484375, "training_acc": 30.0, "val_loss": 188.20774841308594, "val_acc": 60.0}
{"epoch": 33, "training_loss": 2450.381732177734, "training_acc": 50.0, "val_loss": 4848.73388671875, "val_acc": 40.0}
{"epoch": 34, "training_loss": 2226.7133056640623, "training_acc": 60.0, "val_loss": 4457.58154296875, "val_acc": 60.0}
{"epoch": 35, "training_loss": 5503.873681640625, "training_acc": 50.0, "val_loss": 384.3826599121094, "val_acc": 60.0}
{"epoch": 36, "training_loss": 2047.6181518554688, "training_acc": 60.0, "val_loss": 7694.97998046875, "val_acc": 40.0}
{"epoch": 37, "training_loss": 5422.649267578125, "training_acc": 50.0, "val_loss": 1878.2742919921875, "val_acc": 60.0}
{"epoch": 38, "training_loss": 4397.2146484375, "training_acc": 50.0, "val_loss": 1418.93115234375, "val_acc": 60.0}
{"epoch": 39, "training_loss": 2689.4658203125, "training_acc": 50.0, "val_loss": 5237.96044921875, "val_acc": 40.0}
{"epoch": 40, "training_loss": 4184.15654296875, "training_acc": 30.0, "val_loss": 3074.58642578125, "val_acc": 60.0}
{"epoch": 41, "training_loss": 2270.547412109375, "training_acc": 60.0, "val_loss": 2725.989013671875, "val_acc": 40.0}
{"epoch": 42, "training_loss": 1742.22099609375, "training_acc": 50.0, "val_loss": 1316.97265625, "val_acc": 60.0}
{"epoch": 43, "training_loss": 1284.2531982421874, "training_acc": 40.0, "val_loss": 1803.7984619140625, "val_acc": 60.0}
{"epoch": 44, "training_loss": 2089.898321533203, "training_acc": 50.0, "val_loss": 2690.19482421875, "val_acc": 40.0}
{"epoch": 45, "training_loss": 2233.911013793945, "training_acc": 50.0, "val_loss": 2036.5047607421875, "val_acc": 60.0}
{"epoch": 46, "training_loss": 2087.1900024414062, "training_acc": 50.0, "val_loss": 2990.026123046875, "val_acc": 40.0}
{"epoch": 47, "training_loss": 2899.171337890625, "training_acc": 50.0, "val_loss": 878.7777709960938, "val_acc": 60.0}
{"epoch": 48, "training_loss": 1422.2340209960937, "training_acc": 50.0, "val_loss": 923.5568237304688, "val_acc": 40.0}
{"epoch": 49, "training_loss": 737.284716796875, "training_acc": 50.0, "val_loss": 2950.492919921875, "val_acc": 60.0}
{"epoch": 50, "training_loss": 4461.97529296875, "training_acc": 50.0, "val_loss": 1582.8603515625, "val_acc": 60.0}
{"epoch": 51, "training_loss": 3413.753564453125, "training_acc": 50.0, "val_loss": 4696.54638671875, "val_acc": 40.0}
