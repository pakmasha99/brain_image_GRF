"main_modify.py --pretrained_path None --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 3 --task ADNI_sex --input_option yAware --learning_rate 1e2 --batch_size 8 --weight_decay 1e-8 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 17255.700081586838, "training_acc": 25.0, "val_loss": 2998.899658203125, "val_acc": 40.0}
{"epoch": 1, "training_loss": 8160.948291015625, "training_acc": 55.0, "val_loss": 7800.76416015625, "val_acc": 40.0}
{"epoch": 2, "training_loss": 3231.7268798828127, "training_acc": 55.0, "val_loss": 11081.5302734375, "val_acc": 60.0}
{"epoch": 3, "training_loss": 15023.31748046875, "training_acc": 45.0, "val_loss": 5126.08447265625, "val_acc": 60.0}
{"epoch": 4, "training_loss": 4814.130297851562, "training_acc": 45.0, "val_loss": 5739.7705078125, "val_acc": 40.0}
{"epoch": 5, "training_loss": 2823.512255859375, "training_acc": 55.0, "val_loss": 1405.1365966796875, "val_acc": 60.0}
{"epoch": 6, "training_loss": 1636.1283645629883, "training_acc": 45.0, "val_loss": 5852.3876953125, "val_acc": 40.0}
{"epoch": 7, "training_loss": 3179.4137573242188, "training_acc": 55.0, "val_loss": 3178.35205078125, "val_acc": 60.0}
{"epoch": 8, "training_loss": 4309.5931640625, "training_acc": 45.0, "val_loss": 470.7157287597656, "val_acc": 60.0}
{"epoch": 9, "training_loss": 2764.4294921875, "training_acc": 55.0, "val_loss": 8234.17578125, "val_acc": 40.0}
{"epoch": 10, "training_loss": 4590.538720703125, "training_acc": 55.0, "val_loss": 2591.985107421875, "val_acc": 60.0}
{"epoch": 11, "training_loss": 5165.328515625, "training_acc": 45.0, "val_loss": 2217.151611328125, "val_acc": 60.0}
{"epoch": 12, "training_loss": 3004.91904296875, "training_acc": 45.0, "val_loss": 4970.91796875, "val_acc": 40.0}
{"epoch": 13, "training_loss": 3223.007470703125, "training_acc": 45.0, "val_loss": 2158.994140625, "val_acc": 60.0}
{"epoch": 14, "training_loss": 3546.211218261719, "training_acc": 25.0, "val_loss": 6139.9462890625, "val_acc": 40.0}
{"epoch": 15, "training_loss": 3334.40302734375, "training_acc": 55.0, "val_loss": 2828.48193359375, "val_acc": 60.0}
{"epoch": 16, "training_loss": 5341.68798828125, "training_acc": 45.0, "val_loss": 2339.689697265625, "val_acc": 60.0}
{"epoch": 17, "training_loss": 3201.85009765625, "training_acc": 45.0, "val_loss": 4430.5830078125, "val_acc": 40.0}
{"epoch": 18, "training_loss": 1770.395068359375, "training_acc": 65.0, "val_loss": 2703.82568359375, "val_acc": 60.0}
{"epoch": 19, "training_loss": 3024.94677734375, "training_acc": 45.0, "val_loss": 4578.25390625, "val_acc": 40.0}
{"epoch": 20, "training_loss": 4378.36572265625, "training_acc": 55.0, "val_loss": 5259.50341796875, "val_acc": 40.0}
{"epoch": 21, "training_loss": 2710.569921875, "training_acc": 55.0, "val_loss": 3759.874267578125, "val_acc": 60.0}
{"epoch": 22, "training_loss": 4110.236474609375, "training_acc": 45.0, "val_loss": 3993.90234375, "val_acc": 40.0}
{"epoch": 23, "training_loss": 5340.100439453125, "training_acc": 55.0, "val_loss": 5733.59228515625, "val_acc": 40.0}
{"epoch": 24, "training_loss": 2149.4263671875, "training_acc": 65.0, "val_loss": 5477.44873046875, "val_acc": 60.0}
{"epoch": 25, "training_loss": 7294.3578125, "training_acc": 45.0, "val_loss": 1491.9554443359375, "val_acc": 60.0}
{"epoch": 26, "training_loss": 1982.90341796875, "training_acc": 65.0, "val_loss": 6344.0986328125, "val_acc": 40.0}
{"epoch": 27, "training_loss": 4066.7800170898436, "training_acc": 35.0, "val_loss": 8.808670043945312, "val_acc": 80.0}
{"epoch": 28, "training_loss": 412.2872859954834, "training_acc": 65.0, "val_loss": 1725.4222412109375, "val_acc": 40.0}
{"epoch": 29, "training_loss": 1137.408642578125, "training_acc": 45.0, "val_loss": 2484.47021484375, "val_acc": 40.0}
{"epoch": 30, "training_loss": 2817.893994140625, "training_acc": 55.0, "val_loss": 95.21569061279297, "val_acc": 60.0}
{"epoch": 31, "training_loss": 667.1088119506836, "training_acc": 55.0, "val_loss": 705.224609375, "val_acc": 40.0}
{"epoch": 32, "training_loss": 687.7261352539062, "training_acc": 45.0, "val_loss": 657.074951171875, "val_acc": 60.0}
{"epoch": 33, "training_loss": 621.8572387695312, "training_acc": 45.0, "val_loss": 157.4359588623047, "val_acc": 40.0}
{"epoch": 34, "training_loss": 395.643701171875, "training_acc": 55.0, "val_loss": 569.3261108398438, "val_acc": 40.0}
{"epoch": 35, "training_loss": 1593.841162109375, "training_acc": 45.0, "val_loss": 297.11676025390625, "val_acc": 40.0}
{"epoch": 36, "training_loss": 1021.2069915771484, "training_acc": 55.0, "val_loss": 2831.72265625, "val_acc": 60.0}
{"epoch": 37, "training_loss": 5616.85478515625, "training_acc": 45.0, "val_loss": 1311.517578125, "val_acc": 60.0}
{"epoch": 38, "training_loss": 4172.7912109375, "training_acc": 45.0, "val_loss": 10921.400390625, "val_acc": 40.0}
{"epoch": 39, "training_loss": 7232.42158203125, "training_acc": 55.0, "val_loss": 2037.3709716796875, "val_acc": 40.0}
{"epoch": 40, "training_loss": 2057.1015625, "training_acc": 65.0, "val_loss": 4977.59228515625, "val_acc": 60.0}
{"epoch": 41, "training_loss": 5637.677954101562, "training_acc": 45.0, "val_loss": 3706.534423828125, "val_acc": 40.0}
{"epoch": 42, "training_loss": 3824.6361328125, "training_acc": 55.0, "val_loss": 6078.58154296875, "val_acc": 40.0}
{"epoch": 43, "training_loss": 1934.9700439453125, "training_acc": 55.0, "val_loss": 5512.67919921875, "val_acc": 60.0}
{"epoch": 44, "training_loss": 8692.3875, "training_acc": 45.0, "val_loss": 8588.4423828125, "val_acc": 60.0}
{"epoch": 45, "training_loss": 9788.5748046875, "training_acc": 45.0, "val_loss": 700.6852416992188, "val_acc": 40.0}
{"epoch": 46, "training_loss": 3042.5463623046876, "training_acc": 55.0, "val_loss": 4830.4345703125, "val_acc": 40.0}
