"main_modify.py --pretrained_path None --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 3 --task ADNI_sex --input_option yAware --learning_rate 1e2 --batch_size 8 --weight_decay 1e-8 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 14962.36478471756, "training_acc": 50.0, "val_loss": 3309.257080078125, "val_acc": 60.0}
{"epoch": 1, "training_loss": 6824.4919921875, "training_acc": 50.0, "val_loss": 1647.7850341796875, "val_acc": 60.0}
{"epoch": 2, "training_loss": 4609.47060546875, "training_acc": 60.0, "val_loss": 12935.7099609375, "val_acc": 40.0}
{"epoch": 3, "training_loss": 8014.12646484375, "training_acc": 50.0, "val_loss": 4110.4541015625, "val_acc": 60.0}
{"epoch": 4, "training_loss": 6768.76357421875, "training_acc": 50.0, "val_loss": 5856.30615234375, "val_acc": 60.0}
{"epoch": 5, "training_loss": 5551.550439453125, "training_acc": 40.0, "val_loss": 5355.91162109375, "val_acc": 40.0}
{"epoch": 6, "training_loss": 3687.800732421875, "training_acc": 40.0, "val_loss": 301.40740966796875, "val_acc": 60.0}
{"epoch": 7, "training_loss": 1609.9177612304688, "training_acc": 50.0, "val_loss": 121.98381805419922, "val_acc": 40.0}
{"epoch": 8, "training_loss": 3784.2869720458984, "training_acc": 40.0, "val_loss": 4974.88037109375, "val_acc": 60.0}
{"epoch": 9, "training_loss": 5095.83525390625, "training_acc": 40.0, "val_loss": 3349.069091796875, "val_acc": 40.0}
{"epoch": 10, "training_loss": 1475.3816650390625, "training_acc": 70.0, "val_loss": 1511.1263427734375, "val_acc": 60.0}
{"epoch": 11, "training_loss": 1329.4469871520996, "training_acc": 45.0, "val_loss": 353.6968994140625, "val_acc": 60.0}
{"epoch": 12, "training_loss": 469.60240440368653, "training_acc": 50.0, "val_loss": 313.8412780761719, "val_acc": 40.0}
{"epoch": 13, "training_loss": 622.5254821777344, "training_acc": 60.0, "val_loss": 2103.150146484375, "val_acc": 40.0}
{"epoch": 14, "training_loss": 1824.003125, "training_acc": 50.0, "val_loss": 1992.2152099609375, "val_acc": 60.0}
{"epoch": 15, "training_loss": 2569.394140625, "training_acc": 50.0, "val_loss": 25.27655029296875, "val_acc": 60.0}
{"epoch": 16, "training_loss": 414.41772918701173, "training_acc": 55.0, "val_loss": 844.60595703125, "val_acc": 60.0}
{"epoch": 17, "training_loss": 3365.681298828125, "training_acc": 20.0, "val_loss": 859.19873046875, "val_acc": 40.0}
{"epoch": 18, "training_loss": 1844.6193115234375, "training_acc": 60.0, "val_loss": 3748.572998046875, "val_acc": 60.0}
{"epoch": 19, "training_loss": 3162.248291015625, "training_acc": 50.0, "val_loss": 2070.982421875, "val_acc": 40.0}
{"epoch": 20, "training_loss": 1454.9684448242188, "training_acc": 50.0, "val_loss": 2306.856201171875, "val_acc": 60.0}
{"epoch": 21, "training_loss": 2077.8872314453124, "training_acc": 50.0, "val_loss": 3188.90087890625, "val_acc": 40.0}
{"epoch": 22, "training_loss": 2458.3027587890624, "training_acc": 40.0, "val_loss": 1086.0482177734375, "val_acc": 60.0}
{"epoch": 23, "training_loss": 792.963398361206, "training_acc": 60.0, "val_loss": 455.3864440917969, "val_acc": 60.0}
{"epoch": 24, "training_loss": 845.2123413085938, "training_acc": 50.0, "val_loss": 1943.6890869140625, "val_acc": 40.0}
{"epoch": 25, "training_loss": 727.193338394165, "training_acc": 55.0, "val_loss": 552.5333862304688, "val_acc": 60.0}
{"epoch": 26, "training_loss": 522.4143676757812, "training_acc": 50.0, "val_loss": 1263.6851806640625, "val_acc": 40.0}
{"epoch": 27, "training_loss": 664.2653442382813, "training_acc": 50.0, "val_loss": 212.47183227539062, "val_acc": 40.0}
{"epoch": 28, "training_loss": 1808.5677001953125, "training_acc": 40.0, "val_loss": 463.59033203125, "val_acc": 60.0}
{"epoch": 29, "training_loss": 1720.1059204101562, "training_acc": 60.0, "val_loss": 2510.875732421875, "val_acc": 40.0}
{"epoch": 30, "training_loss": 2524.371728515625, "training_acc": 40.0, "val_loss": 1473.0240478515625, "val_acc": 60.0}
{"epoch": 31, "training_loss": 3326.124609375, "training_acc": 30.0, "val_loss": 1174.1522216796875, "val_acc": 40.0}
{"epoch": 32, "training_loss": 3765.71728515625, "training_acc": 40.0, "val_loss": 4146.39306640625, "val_acc": 60.0}
{"epoch": 33, "training_loss": 2939.13330078125, "training_acc": 60.0, "val_loss": 4774.3212890625, "val_acc": 40.0}
{"epoch": 34, "training_loss": 4577.430078125, "training_acc": 50.0, "val_loss": 184.2711944580078, "val_acc": 60.0}
