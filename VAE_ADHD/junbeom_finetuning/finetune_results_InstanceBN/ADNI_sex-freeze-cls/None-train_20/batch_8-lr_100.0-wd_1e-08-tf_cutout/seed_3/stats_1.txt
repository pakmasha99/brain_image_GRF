"main_modify.py --pretrained_path None --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 3 --task ADNI_sex --input_option yAware --learning_rate 1e2 --batch_size 8 --weight_decay 1e-8 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 12956.1690158844, "training_acc": 40.0, "val_loss": 4165.54248046875, "val_acc": 40.0}
{"epoch": 1, "training_loss": 4028.653515625, "training_acc": 50.0, "val_loss": 2629.96875, "val_acc": 60.0}
{"epoch": 2, "training_loss": 3343.6022216796873, "training_acc": 50.0, "val_loss": 5418.02294921875, "val_acc": 40.0}
{"epoch": 3, "training_loss": 4315.317138671875, "training_acc": 50.0, "val_loss": 896.6580200195312, "val_acc": 60.0}
{"epoch": 4, "training_loss": 1471.2186767578125, "training_acc": 50.0, "val_loss": 529.0773315429688, "val_acc": 40.0}
{"epoch": 5, "training_loss": 3121.31025390625, "training_acc": 30.0, "val_loss": 802.1503295898438, "val_acc": 60.0}
{"epoch": 6, "training_loss": 3986.237646484375, "training_acc": 40.0, "val_loss": 5860.76318359375, "val_acc": 40.0}
{"epoch": 7, "training_loss": 3115.58720703125, "training_acc": 50.0, "val_loss": 4603.421875, "val_acc": 60.0}
{"epoch": 8, "training_loss": 5763.43193359375, "training_acc": 50.0, "val_loss": 366.6986389160156, "val_acc": 60.0}
{"epoch": 9, "training_loss": 4219.677587890625, "training_acc": 50.0, "val_loss": 11960.8720703125, "val_acc": 40.0}
{"epoch": 10, "training_loss": 8464.421484375, "training_acc": 50.0, "val_loss": 936.0362548828125, "val_acc": 40.0}
{"epoch": 11, "training_loss": 6314.329321289062, "training_acc": 40.0, "val_loss": 9732.912109375, "val_acc": 60.0}
{"epoch": 12, "training_loss": 10956.1576171875, "training_acc": 50.0, "val_loss": 2905.160888671875, "val_acc": 60.0}
{"epoch": 13, "training_loss": 3243.079541015625, "training_acc": 50.0, "val_loss": 8705.537109375, "val_acc": 40.0}
{"epoch": 14, "training_loss": 6723.32607421875, "training_acc": 50.0, "val_loss": 797.4862670898438, "val_acc": 40.0}
{"epoch": 15, "training_loss": 2301.805310058594, "training_acc": 70.0, "val_loss": 7838.5390625, "val_acc": 60.0}
{"epoch": 16, "training_loss": 9403.6279296875, "training_acc": 50.0, "val_loss": 2853.166259765625, "val_acc": 60.0}
{"epoch": 17, "training_loss": 2710.68193359375, "training_acc": 60.0, "val_loss": 9963.9560546875, "val_acc": 40.0}
{"epoch": 18, "training_loss": 7874.66484375, "training_acc": 50.0, "val_loss": 2783.642333984375, "val_acc": 40.0}
{"epoch": 19, "training_loss": 985.1974365234375, "training_acc": 80.0, "val_loss": 4532.87255859375, "val_acc": 60.0}
{"epoch": 20, "training_loss": 4279.484228515625, "training_acc": 50.0, "val_loss": 3650.65869140625, "val_acc": 40.0}
{"epoch": 21, "training_loss": 3704.7955078125, "training_acc": 50.0, "val_loss": 3738.34765625, "val_acc": 40.0}
{"epoch": 22, "training_loss": 2466.72958984375, "training_acc": 40.0, "val_loss": 922.3646850585938, "val_acc": 60.0}
{"epoch": 23, "training_loss": 1093.419775390625, "training_acc": 60.0, "val_loss": 531.8642578125, "val_acc": 40.0}
{"epoch": 24, "training_loss": 1789.0670166015625, "training_acc": 60.0, "val_loss": 1813.552734375, "val_acc": 60.0}
{"epoch": 25, "training_loss": 2849.41650390625, "training_acc": 40.0, "val_loss": 2143.7578125, "val_acc": 40.0}
{"epoch": 26, "training_loss": 1904.246630859375, "training_acc": 50.0, "val_loss": 1392.09375, "val_acc": 60.0}
{"epoch": 27, "training_loss": 1013.4879638671875, "training_acc": 60.0, "val_loss": 22.33137321472168, "val_acc": 60.0}
{"epoch": 28, "training_loss": 249.21265106201173, "training_acc": 55.0, "val_loss": 2598.516845703125, "val_acc": 40.0}
{"epoch": 29, "training_loss": 1692.576953125, "training_acc": 50.0, "val_loss": 3030.26953125, "val_acc": 60.0}
{"epoch": 30, "training_loss": 2516.46943359375, "training_acc": 50.0, "val_loss": 5940.68896484375, "val_acc": 40.0}
{"epoch": 31, "training_loss": 6981.1146484375, "training_acc": 50.0, "val_loss": 7988.2548828125, "val_acc": 40.0}
{"epoch": 32, "training_loss": 4036.7236572265624, "training_acc": 60.0, "val_loss": 5251.85498046875, "val_acc": 60.0}
{"epoch": 33, "training_loss": 6706.7830078125, "training_acc": 50.0, "val_loss": 2666.525390625, "val_acc": 60.0}
{"epoch": 34, "training_loss": 1196.3447387695312, "training_acc": 65.0, "val_loss": 9880.958984375, "val_acc": 40.0}
{"epoch": 35, "training_loss": 8670.412939453125, "training_acc": 50.0, "val_loss": 5894.78564453125, "val_acc": 40.0}
{"epoch": 36, "training_loss": 3260.029560852051, "training_acc": 50.0, "val_loss": 4321.69482421875, "val_acc": 60.0}
{"epoch": 37, "training_loss": 4711.15703125, "training_acc": 50.0, "val_loss": 3730.90625, "val_acc": 40.0}
{"epoch": 38, "training_loss": 3462.7712890625, "training_acc": 50.0, "val_loss": 219.70413208007812, "val_acc": 60.0}
{"epoch": 39, "training_loss": 575.0623962402344, "training_acc": 50.0, "val_loss": 386.45391845703125, "val_acc": 60.0}
{"epoch": 40, "training_loss": 315.6730590820313, "training_acc": 60.0, "val_loss": 964.98193359375, "val_acc": 40.0}
{"epoch": 41, "training_loss": 608.7631912231445, "training_acc": 50.0, "val_loss": 43.97309494018555, "val_acc": 60.0}
{"epoch": 42, "training_loss": 676.0701202392578, "training_acc": 60.0, "val_loss": 1356.834228515625, "val_acc": 60.0}
{"epoch": 43, "training_loss": 1745.4893798828125, "training_acc": 50.0, "val_loss": 3215.08447265625, "val_acc": 40.0}
{"epoch": 44, "training_loss": 2682.807861328125, "training_acc": 50.0, "val_loss": 286.3366394042969, "val_acc": 60.0}
{"epoch": 45, "training_loss": 728.6115539550781, "training_acc": 40.0, "val_loss": 345.6130065917969, "val_acc": 40.0}
{"epoch": 46, "training_loss": 103.13521881103516, "training_acc": 75.0, "val_loss": 646.4276733398438, "val_acc": 40.0}
