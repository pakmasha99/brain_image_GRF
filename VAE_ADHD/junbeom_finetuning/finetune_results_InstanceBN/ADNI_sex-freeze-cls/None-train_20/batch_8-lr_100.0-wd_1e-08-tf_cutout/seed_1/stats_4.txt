"main_modify.py --pretrained_path None --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 1 --task ADNI_sex --input_option yAware --learning_rate 1e2 --batch_size 8 --weight_decay 1e-8 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 11576.261879897118, "training_acc": 50.0, "val_loss": 7597.1650390625, "val_acc": 40.0}
{"epoch": 1, "training_loss": 8550.940234375, "training_acc": 50.0, "val_loss": 1687.289306640625, "val_acc": 60.0}
{"epoch": 2, "training_loss": 3472.42626953125, "training_acc": 50.0, "val_loss": 3510.798583984375, "val_acc": 40.0}
{"epoch": 3, "training_loss": 2339.490380859375, "training_acc": 50.0, "val_loss": 1641.2115478515625, "val_acc": 60.0}
{"epoch": 4, "training_loss": 1293.4441467285155, "training_acc": 40.0, "val_loss": 3575.90869140625, "val_acc": 40.0}
{"epoch": 5, "training_loss": 2288.198376464844, "training_acc": 50.0, "val_loss": 3383.00244140625, "val_acc": 60.0}
{"epoch": 6, "training_loss": 6307.4150390625, "training_acc": 50.0, "val_loss": 2091.37353515625, "val_acc": 60.0}
{"epoch": 7, "training_loss": 4833.3416015625, "training_acc": 40.0, "val_loss": 7948.01904296875, "val_acc": 40.0}
{"epoch": 8, "training_loss": 4528.516772460937, "training_acc": 50.0, "val_loss": 1802.0859375, "val_acc": 60.0}
{"epoch": 9, "training_loss": 1751.478564453125, "training_acc": 50.0, "val_loss": 2002.128173828125, "val_acc": 40.0}
{"epoch": 10, "training_loss": 918.5068115234375, "training_acc": 60.0, "val_loss": 4009.132080078125, "val_acc": 60.0}
{"epoch": 11, "training_loss": 3918.6654541015623, "training_acc": 50.0, "val_loss": 3377.848876953125, "val_acc": 40.0}
{"epoch": 12, "training_loss": 4031.649853515625, "training_acc": 50.0, "val_loss": 3215.417236328125, "val_acc": 40.0}
{"epoch": 13, "training_loss": 1665.0248046875, "training_acc": 50.0, "val_loss": 6301.14453125, "val_acc": 60.0}
{"epoch": 14, "training_loss": 8661.1080078125, "training_acc": 50.0, "val_loss": 3096.897216796875, "val_acc": 60.0}
{"epoch": 15, "training_loss": 3826.70048828125, "training_acc": 40.0, "val_loss": 6010.6728515625, "val_acc": 40.0}
{"epoch": 16, "training_loss": 3414.16376953125, "training_acc": 50.0, "val_loss": 3684.30126953125, "val_acc": 60.0}
{"epoch": 17, "training_loss": 6807.90546875, "training_acc": 50.0, "val_loss": 7127.67529296875, "val_acc": 60.0}
{"epoch": 18, "training_loss": 7787.0296875, "training_acc": 50.0, "val_loss": 2185.199951171875, "val_acc": 40.0}
{"epoch": 19, "training_loss": 3918.604052734375, "training_acc": 50.0, "val_loss": 1552.5726318359375, "val_acc": 40.0}
{"epoch": 20, "training_loss": 2769.638232421875, "training_acc": 50.0, "val_loss": 4718.83251953125, "val_acc": 60.0}
{"epoch": 21, "training_loss": 4626.787396240235, "training_acc": 40.0, "val_loss": 583.5045166015625, "val_acc": 40.0}
{"epoch": 22, "training_loss": 628.0011291503906, "training_acc": 50.0, "val_loss": 1261.098876953125, "val_acc": 60.0}
{"epoch": 23, "training_loss": 1542.1220458984376, "training_acc": 50.0, "val_loss": 3373.96142578125, "val_acc": 40.0}
{"epoch": 24, "training_loss": 3218.766015625, "training_acc": 50.0, "val_loss": 1016.2770385742188, "val_acc": 40.0}
{"epoch": 25, "training_loss": 3403.877294921875, "training_acc": 40.0, "val_loss": 4093.27978515625, "val_acc": 60.0}
{"epoch": 26, "training_loss": 3404.18212890625, "training_acc": 50.0, "val_loss": 3482.20751953125, "val_acc": 40.0}
{"epoch": 27, "training_loss": 2450.488171386719, "training_acc": 50.0, "val_loss": 2874.703369140625, "val_acc": 60.0}
{"epoch": 28, "training_loss": 4543.453955078125, "training_acc": 50.0, "val_loss": 2168.530517578125, "val_acc": 60.0}
{"epoch": 29, "training_loss": 569.4211547851562, "training_acc": 70.0, "val_loss": 9720.015625, "val_acc": 40.0}
{"epoch": 30, "training_loss": 8504.997314453125, "training_acc": 50.0, "val_loss": 7308.10498046875, "val_acc": 40.0}
{"epoch": 31, "training_loss": 4968.0796875, "training_acc": 40.0, "val_loss": 4988.154296875, "val_acc": 60.0}
{"epoch": 32, "training_loss": 5828.66181640625, "training_acc": 50.0, "val_loss": 434.6380920410156, "val_acc": 60.0}
{"epoch": 33, "training_loss": 4533.197607421875, "training_acc": 40.0, "val_loss": 10338.9453125, "val_acc": 40.0}
{"epoch": 34, "training_loss": 7037.146484375, "training_acc": 50.0, "val_loss": 1009.4252319335938, "val_acc": 60.0}
{"epoch": 35, "training_loss": 2307.259521484375, "training_acc": 50.0, "val_loss": 1528.12890625, "val_acc": 60.0}
{"epoch": 36, "training_loss": 2889.188671875, "training_acc": 40.0, "val_loss": 2635.38525390625, "val_acc": 40.0}
{"epoch": 37, "training_loss": 1189.968701171875, "training_acc": 60.0, "val_loss": 584.1251831054688, "val_acc": 60.0}
{"epoch": 38, "training_loss": 1703.285498046875, "training_acc": 50.0, "val_loss": 1619.8785400390625, "val_acc": 40.0}
{"epoch": 39, "training_loss": 1571.3554931640624, "training_acc": 60.0, "val_loss": 1059.2357177734375, "val_acc": 60.0}
{"epoch": 40, "training_loss": 2718.092919921875, "training_acc": 40.0, "val_loss": 3208.414794921875, "val_acc": 40.0}
{"epoch": 41, "training_loss": 1765.795703125, "training_acc": 50.0, "val_loss": 4980.3046875, "val_acc": 60.0}
{"epoch": 42, "training_loss": 5717.3259765625, "training_acc": 50.0, "val_loss": 140.47491455078125, "val_acc": 60.0}
{"epoch": 43, "training_loss": 4198.403039550782, "training_acc": 50.0, "val_loss": 8517.2958984375, "val_acc": 40.0}
{"epoch": 44, "training_loss": 4010.934765625, "training_acc": 50.0, "val_loss": 4845.7080078125, "val_acc": 60.0}
{"epoch": 45, "training_loss": 8798.0658203125, "training_acc": 50.0, "val_loss": 9634.908203125, "val_acc": 60.0}
{"epoch": 46, "training_loss": 10135.384790039063, "training_acc": 50.0, "val_loss": 1516.4287109375, "val_acc": 40.0}
{"epoch": 47, "training_loss": 2964.9828125, "training_acc": 50.0, "val_loss": 3356.388427734375, "val_acc": 40.0}
{"epoch": 48, "training_loss": 930.6367004394531, "training_acc": 60.0, "val_loss": 279.31842041015625, "val_acc": 60.0}
{"epoch": 49, "training_loss": 247.08592529296874, "training_acc": 80.0, "val_loss": 759.4912109375, "val_acc": 60.0}
{"epoch": 50, "training_loss": 772.713842844963, "training_acc": 55.0, "val_loss": 1931.9078369140625, "val_acc": 60.0}
{"epoch": 51, "training_loss": 4304.219995117188, "training_acc": 50.0, "val_loss": 247.03173828125, "val_acc": 60.0}
{"epoch": 52, "training_loss": 3316.845080566406, "training_acc": 50.0, "val_loss": 10082.484375, "val_acc": 40.0}
{"epoch": 53, "training_loss": 7210.5587890625, "training_acc": 50.0, "val_loss": 82.27316284179688, "val_acc": 60.0}
{"epoch": 54, "training_loss": 884.2392272949219, "training_acc": 50.0, "val_loss": 149.0440216064453, "val_acc": 40.0}
{"epoch": 55, "training_loss": 532.3641845703125, "training_acc": 50.0, "val_loss": 3303.732177734375, "val_acc": 40.0}
{"epoch": 56, "training_loss": 3183.308984375, "training_acc": 50.0, "val_loss": 135.85269165039062, "val_acc": 60.0}
{"epoch": 57, "training_loss": 1124.589373779297, "training_acc": 30.0, "val_loss": 182.11277770996094, "val_acc": 60.0}
{"epoch": 58, "training_loss": 711.835888671875, "training_acc": 40.0, "val_loss": 809.330078125, "val_acc": 60.0}
{"epoch": 59, "training_loss": 913.1380981445312, "training_acc": 70.0, "val_loss": 288.1198425292969, "val_acc": 40.0}
{"epoch": 60, "training_loss": 1587.2378173828124, "training_acc": 60.0, "val_loss": 2841.051513671875, "val_acc": 60.0}
{"epoch": 61, "training_loss": 2976.122314453125, "training_acc": 40.0, "val_loss": 4855.1328125, "val_acc": 40.0}
{"epoch": 62, "training_loss": 3636.379217529297, "training_acc": 50.0, "val_loss": 2953.6640625, "val_acc": 60.0}
{"epoch": 63, "training_loss": 4627.626953125, "training_acc": 50.0, "val_loss": 2203.602294921875, "val_acc": 60.0}
{"epoch": 64, "training_loss": 1571.0555908203125, "training_acc": 60.0, "val_loss": 2550.00830078125, "val_acc": 40.0}
{"epoch": 65, "training_loss": 984.1972473144531, "training_acc": 50.0, "val_loss": 1780.768798828125, "val_acc": 40.0}
{"epoch": 66, "training_loss": 966.9587585449219, "training_acc": 60.0, "val_loss": 1264.4031982421875, "val_acc": 60.0}
{"epoch": 67, "training_loss": 1217.6950927734374, "training_acc": 30.0, "val_loss": 1302.82177734375, "val_acc": 40.0}
{"epoch": 68, "training_loss": 896.3987426757812, "training_acc": 60.0, "val_loss": 849.1345825195312, "val_acc": 60.0}
{"epoch": 69, "training_loss": 918.6118774414062, "training_acc": 60.0, "val_loss": 4130.1005859375, "val_acc": 40.0}
{"epoch": 70, "training_loss": 2847.44599609375, "training_acc": 50.0, "val_loss": 2675.3203125, "val_acc": 60.0}
{"epoch": 71, "training_loss": 4226.3908203125, "training_acc": 50.0, "val_loss": 2756.094970703125, "val_acc": 60.0}
{"epoch": 72, "training_loss": 1571.3473266601563, "training_acc": 50.0, "val_loss": 894.5287475585938, "val_acc": 40.0}
