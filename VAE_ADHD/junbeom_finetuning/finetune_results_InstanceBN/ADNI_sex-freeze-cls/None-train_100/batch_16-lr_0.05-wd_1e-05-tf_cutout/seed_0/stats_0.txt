"main_modify.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_sex --input_option yAware --learning_rate 5e-2 --batch_size 16 --weight_decay 1e-5 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 4.848082799911499, "training_acc": 55.0, "val_loss": 3.526168041229248, "val_acc": 48.0}
{"epoch": 1, "training_loss": 3.8692397403717043, "training_acc": 53.0, "val_loss": 4.506725406646728, "val_acc": 52.0}
{"epoch": 2, "training_loss": 3.2719803714752196, "training_acc": 49.0, "val_loss": 0.8524255323410034, "val_acc": 52.0}
{"epoch": 3, "training_loss": 1.5487236833572389, "training_acc": 55.0, "val_loss": 2.4653529739379882, "val_acc": 48.0}
{"epoch": 4, "training_loss": 1.7317848539352416, "training_acc": 49.0, "val_loss": 1.157991042137146, "val_acc": 48.0}
{"epoch": 5, "training_loss": 1.0359609413146973, "training_acc": 50.0, "val_loss": 1.5609507131576539, "val_acc": 48.0}
{"epoch": 6, "training_loss": 0.9682401084899902, "training_acc": 55.0, "val_loss": 1.8571519708633424, "val_acc": 48.0}
{"epoch": 7, "training_loss": 1.1605069732666016, "training_acc": 49.0, "val_loss": 0.7310931062698365, "val_acc": 48.0}
{"epoch": 8, "training_loss": 0.8863551950454712, "training_acc": 47.0, "val_loss": 1.0619807457923889, "val_acc": 52.0}
{"epoch": 9, "training_loss": 0.9993335914611816, "training_acc": 43.0, "val_loss": 1.5444105577468872, "val_acc": 48.0}
{"epoch": 10, "training_loss": 1.7198970413208008, "training_acc": 43.0, "val_loss": 1.3619454145431518, "val_acc": 48.0}
{"epoch": 11, "training_loss": 0.9495553779602051, "training_acc": 55.0, "val_loss": 1.230263533592224, "val_acc": 48.0}
{"epoch": 12, "training_loss": 1.3257476782798767, "training_acc": 47.0, "val_loss": 0.9562964725494385, "val_acc": 48.0}
{"epoch": 13, "training_loss": 0.7451713132858276, "training_acc": 55.0, "val_loss": 0.9173638463020325, "val_acc": 52.0}
{"epoch": 14, "training_loss": 1.0114974451065064, "training_acc": 49.0, "val_loss": 0.9906158494949341, "val_acc": 52.0}
{"epoch": 15, "training_loss": 0.9679863703250885, "training_acc": 55.0, "val_loss": 1.0377862215042115, "val_acc": 52.0}
{"epoch": 16, "training_loss": 0.9130792665481567, "training_acc": 49.0, "val_loss": 1.5691694355010986, "val_acc": 48.0}
{"epoch": 17, "training_loss": 1.243252136707306, "training_acc": 52.0, "val_loss": 1.4755353546142578, "val_acc": 48.0}
{"epoch": 18, "training_loss": 0.9465981125831604, "training_acc": 47.0, "val_loss": 0.8718485569953919, "val_acc": 48.0}
{"epoch": 19, "training_loss": 1.170332546234131, "training_acc": 47.0, "val_loss": 0.6891298413276672, "val_acc": 52.0}
{"epoch": 20, "training_loss": 1.0921571016311646, "training_acc": 45.0, "val_loss": 0.7471538996696472, "val_acc": 52.0}
{"epoch": 21, "training_loss": 0.8278274917602539, "training_acc": 51.0, "val_loss": 0.8629222345352173, "val_acc": 48.0}
{"epoch": 22, "training_loss": 0.9527129271626472, "training_acc": 49.0, "val_loss": 1.8213695812225341, "val_acc": 48.0}
{"epoch": 23, "training_loss": 1.1987060356140136, "training_acc": 53.0, "val_loss": 0.9182621002197265, "val_acc": 48.0}
{"epoch": 24, "training_loss": 1.3073613333702088, "training_acc": 51.0, "val_loss": 0.7021024680137634, "val_acc": 44.0}
{"epoch": 25, "training_loss": 1.4114117574691774, "training_acc": 50.0, "val_loss": 0.8605926585197449, "val_acc": 52.0}
{"epoch": 26, "training_loss": 0.9242328929901124, "training_acc": 65.0, "val_loss": 0.8279620099067688, "val_acc": 52.0}
{"epoch": 27, "training_loss": 1.3397843790054322, "training_acc": 47.0, "val_loss": 1.34513370513916, "val_acc": 52.0}
{"epoch": 28, "training_loss": 1.4311226558685304, "training_acc": 48.0, "val_loss": 1.481609992980957, "val_acc": 52.0}
{"epoch": 29, "training_loss": 1.00671859562397, "training_acc": 55.0, "val_loss": 1.6257635498046874, "val_acc": 52.0}
{"epoch": 30, "training_loss": 1.1588531303405762, "training_acc": 53.0, "val_loss": 0.9791389179229736, "val_acc": 52.0}
{"epoch": 31, "training_loss": 0.7595398968458176, "training_acc": 60.0, "val_loss": 1.6424301528930665, "val_acc": 52.0}
{"epoch": 32, "training_loss": 1.086723666191101, "training_acc": 49.0, "val_loss": 0.722645308971405, "val_acc": 52.0}
{"epoch": 33, "training_loss": 0.7665396642684936, "training_acc": 58.0, "val_loss": 1.2244652175903321, "val_acc": 48.0}
{"epoch": 34, "training_loss": 1.0235799217224122, "training_acc": 43.0, "val_loss": 0.8244391202926635, "val_acc": 48.0}
{"epoch": 35, "training_loss": 0.6898339509963989, "training_acc": 56.0, "val_loss": 0.8868108510971069, "val_acc": 48.0}
{"epoch": 36, "training_loss": 0.8708996558189392, "training_acc": 48.0, "val_loss": 0.9706008100509643, "val_acc": 52.0}
{"epoch": 37, "training_loss": 0.9069203948974609, "training_acc": 49.0, "val_loss": 0.6940848278999329, "val_acc": 48.0}
{"epoch": 38, "training_loss": 1.2166214656829835, "training_acc": 61.0, "val_loss": 0.6882648873329162, "val_acc": 52.0}
{"epoch": 39, "training_loss": 1.2189011454582215, "training_acc": 51.0, "val_loss": 1.5642468929290771, "val_acc": 48.0}
{"epoch": 40, "training_loss": 1.4443842625617982, "training_acc": 60.0, "val_loss": 0.7365736865997314, "val_acc": 48.0}
{"epoch": 41, "training_loss": 1.4402662467956544, "training_acc": 52.0, "val_loss": 0.8984164047241211, "val_acc": 48.0}
{"epoch": 42, "training_loss": 1.4248807621002197, "training_acc": 48.0, "val_loss": 1.3245740222930908, "val_acc": 48.0}
{"epoch": 43, "training_loss": 0.9126043277978897, "training_acc": 57.0, "val_loss": 3.084188532829285, "val_acc": 48.0}
{"epoch": 44, "training_loss": 1.8652265858650208, "training_acc": 55.0, "val_loss": 1.689761152267456, "val_acc": 48.0}
{"epoch": 45, "training_loss": 1.516817674636841, "training_acc": 47.0, "val_loss": 1.7571631574630737, "val_acc": 48.0}
{"epoch": 46, "training_loss": 1.5369607067108155, "training_acc": 45.0, "val_loss": 1.241288528442383, "val_acc": 48.0}
{"epoch": 47, "training_loss": 1.5911609315872193, "training_acc": 39.0, "val_loss": 0.9419800043106079, "val_acc": 52.0}
{"epoch": 48, "training_loss": 0.7642736387252808, "training_acc": 58.0, "val_loss": 0.686960175037384, "val_acc": 56.0}
{"epoch": 49, "training_loss": 0.7877088356018066, "training_acc": 49.0, "val_loss": 0.9976090574264527, "val_acc": 48.0}
{"epoch": 50, "training_loss": 0.6932513093948365, "training_acc": 63.0, "val_loss": 1.0418459033966065, "val_acc": 48.0}
{"epoch": 51, "training_loss": 0.9675093698501587, "training_acc": 52.0, "val_loss": 0.6878838682174683, "val_acc": 60.0}
{"epoch": 52, "training_loss": 0.8707007741928101, "training_acc": 50.0, "val_loss": 1.4257848596572875, "val_acc": 48.0}
{"epoch": 53, "training_loss": 1.6119491004943847, "training_acc": 47.0, "val_loss": 1.6123994255065919, "val_acc": 48.0}
{"epoch": 54, "training_loss": 0.8992254662513733, "training_acc": 55.0, "val_loss": 1.5498519086837768, "val_acc": 48.0}
{"epoch": 55, "training_loss": 1.1844810955226421, "training_acc": 47.0, "val_loss": 2.0113296127319336, "val_acc": 48.0}
{"epoch": 56, "training_loss": 1.5854448366165161, "training_acc": 47.0, "val_loss": 2.6834112453460692, "val_acc": 48.0}
{"epoch": 57, "training_loss": 1.321046462059021, "training_acc": 59.0, "val_loss": 0.7997263383865356, "val_acc": 48.0}
{"epoch": 58, "training_loss": 0.9057659006118775, "training_acc": 48.0, "val_loss": 1.972934274673462, "val_acc": 52.0}
{"epoch": 59, "training_loss": 2.192193212509155, "training_acc": 49.0, "val_loss": 2.2201563262939454, "val_acc": 52.0}
{"epoch": 60, "training_loss": 3.3509279823303224, "training_acc": 51.0, "val_loss": 4.287786827087403, "val_acc": 48.0}
{"epoch": 61, "training_loss": 2.3482348251342775, "training_acc": 53.0, "val_loss": 1.4532847833633422, "val_acc": 48.0}
{"epoch": 62, "training_loss": 2.3848963928222657, "training_acc": 54.0, "val_loss": 2.433513059616089, "val_acc": 52.0}
{"epoch": 63, "training_loss": 2.5556897163391112, "training_acc": 43.0, "val_loss": 2.9367243385314943, "val_acc": 52.0}
{"epoch": 64, "training_loss": 1.7972619199752808, "training_acc": 57.0, "val_loss": 1.3612993228435517, "val_acc": 52.0}
{"epoch": 65, "training_loss": 1.2763371205329894, "training_acc": 54.0, "val_loss": 2.3998911571502686, "val_acc": 52.0}
{"epoch": 66, "training_loss": 2.022605755329132, "training_acc": 51.0, "val_loss": 1.3125362253189088, "val_acc": 52.0}
{"epoch": 67, "training_loss": 0.9231524658203125, "training_acc": 53.0, "val_loss": 0.6929514074325561, "val_acc": 56.0}
