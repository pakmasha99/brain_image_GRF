"main_modify.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 7 --task ADNI_sex --input_option yAware --learning_rate 1e0 --batch_size 16 --weight_decay 1e-2 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 117.83363937377929, "training_acc": 51.0, "val_loss": 20.14241226196289, "val_acc": 48.0}
{"epoch": 1, "training_loss": 24.40483938217163, "training_acc": 49.0, "val_loss": 20.617765045166017, "val_acc": 52.0}
{"epoch": 2, "training_loss": 20.694999771118162, "training_acc": 47.0, "val_loss": 56.17751937866211, "val_acc": 48.0}
{"epoch": 3, "training_loss": 63.5298422241211, "training_acc": 45.0, "val_loss": 28.63085620880127, "val_acc": 52.0}
{"epoch": 4, "training_loss": 16.84212426185608, "training_acc": 43.0, "val_loss": 7.742758750915527, "val_acc": 48.0}
{"epoch": 5, "training_loss": 12.730525550842286, "training_acc": 53.0, "val_loss": 36.616318740844726, "val_acc": 52.0}
{"epoch": 6, "training_loss": 45.10287094116211, "training_acc": 45.0, "val_loss": 12.738265953063966, "val_acc": 52.0}
{"epoch": 7, "training_loss": 24.504783630371094, "training_acc": 55.0, "val_loss": 25.686778717041015, "val_acc": 48.0}
{"epoch": 8, "training_loss": 26.624791259765626, "training_acc": 55.0, "val_loss": 40.440166015625, "val_acc": 48.0}
{"epoch": 9, "training_loss": 30.602469329833983, "training_acc": 53.0, "val_loss": 38.84242919921875, "val_acc": 48.0}
{"epoch": 10, "training_loss": 43.40277214050293, "training_acc": 51.0, "val_loss": 63.29766265869141, "val_acc": 52.0}
{"epoch": 11, "training_loss": 54.12978858947754, "training_acc": 47.0, "val_loss": 4.549098901748657, "val_acc": 48.0}
{"epoch": 12, "training_loss": 63.695495471954345, "training_acc": 51.0, "val_loss": 71.65809112548828, "val_acc": 48.0}
{"epoch": 13, "training_loss": 119.0797543334961, "training_acc": 51.0, "val_loss": 43.0203076171875, "val_acc": 52.0}
{"epoch": 14, "training_loss": 93.65309143066406, "training_acc": 49.0, "val_loss": 70.7539045715332, "val_acc": 48.0}
{"epoch": 15, "training_loss": 118.25646018981934, "training_acc": 51.0, "val_loss": 15.654360237121582, "val_acc": 52.0}
{"epoch": 16, "training_loss": 38.45019561767578, "training_acc": 47.0, "val_loss": 73.07269271850586, "val_acc": 48.0}
{"epoch": 17, "training_loss": 62.91199470520019, "training_acc": 51.0, "val_loss": 46.31946197509765, "val_acc": 52.0}
{"epoch": 18, "training_loss": 28.034423599243166, "training_acc": 49.0, "val_loss": 31.117668762207032, "val_acc": 52.0}
{"epoch": 19, "training_loss": 28.878160095214845, "training_acc": 39.0, "val_loss": 17.249066123962404, "val_acc": 52.0}
{"epoch": 20, "training_loss": 23.983873291015627, "training_acc": 51.0, "val_loss": 42.97711334228516, "val_acc": 52.0}
{"epoch": 21, "training_loss": 37.60501403808594, "training_acc": 41.0, "val_loss": 28.652597427368164, "val_acc": 52.0}
{"epoch": 22, "training_loss": 30.508795166015624, "training_acc": 47.0, "val_loss": 32.37496726989746, "val_acc": 52.0}
{"epoch": 23, "training_loss": 23.08654178619385, "training_acc": 45.0, "val_loss": 27.28191390991211, "val_acc": 52.0}
{"epoch": 24, "training_loss": 25.675195541381836, "training_acc": 51.0, "val_loss": 28.877335205078126, "val_acc": 52.0}
{"epoch": 25, "training_loss": 18.500858318805694, "training_acc": 51.0, "val_loss": 2.8815393543243406, "val_acc": 52.0}
{"epoch": 26, "training_loss": 13.980587387084961, "training_acc": 43.0, "val_loss": 13.329195022583008, "val_acc": 52.0}
{"epoch": 27, "training_loss": 16.997563858032226, "training_acc": 43.0, "val_loss": 54.10516799926758, "val_acc": 52.0}
{"epoch": 28, "training_loss": 40.30006252288818, "training_acc": 45.0, "val_loss": 29.759562377929687, "val_acc": 52.0}
{"epoch": 29, "training_loss": 33.99286773681641, "training_acc": 51.0, "val_loss": 21.00296730041504, "val_acc": 48.0}
{"epoch": 30, "training_loss": 22.242081413269045, "training_acc": 57.0, "val_loss": 52.33405548095703, "val_acc": 48.0}
{"epoch": 31, "training_loss": 36.13471370697022, "training_acc": 47.0, "val_loss": 37.184450759887696, "val_acc": 48.0}
{"epoch": 32, "training_loss": 36.86259246826172, "training_acc": 49.0, "val_loss": 7.812082061767578, "val_acc": 48.0}
{"epoch": 33, "training_loss": 17.169767150878908, "training_acc": 43.0, "val_loss": 10.239927711486816, "val_acc": 52.0}
{"epoch": 34, "training_loss": 8.350707912445069, "training_acc": 41.0, "val_loss": 14.399093284606934, "val_acc": 52.0}
{"epoch": 35, "training_loss": 20.752408065795898, "training_acc": 45.0, "val_loss": 42.5139111328125, "val_acc": 52.0}
{"epoch": 36, "training_loss": 19.725814590454103, "training_acc": 55.0, "val_loss": 10.94257038116455, "val_acc": 48.0}
{"epoch": 37, "training_loss": 21.671199111938478, "training_acc": 45.0, "val_loss": 35.810287933349606, "val_acc": 48.0}
{"epoch": 38, "training_loss": 42.05034177780151, "training_acc": 55.0, "val_loss": 26.168584289550783, "val_acc": 48.0}
{"epoch": 39, "training_loss": 24.48788055419922, "training_acc": 53.0, "val_loss": 6.398336563110352, "val_acc": 48.0}
{"epoch": 40, "training_loss": 11.138484649658203, "training_acc": 47.0, "val_loss": 7.634042854309082, "val_acc": 48.0}
{"epoch": 41, "training_loss": 7.131653442382812, "training_acc": 47.0, "val_loss": 24.109439086914062, "val_acc": 52.0}
{"epoch": 42, "training_loss": 21.59064910888672, "training_acc": 53.0, "val_loss": 48.00457229614258, "val_acc": 52.0}
{"epoch": 43, "training_loss": 49.08306106567383, "training_acc": 47.0, "val_loss": 12.392522735595703, "val_acc": 48.0}
{"epoch": 44, "training_loss": 53.82465316772461, "training_acc": 49.0, "val_loss": 48.98091697692871, "val_acc": 48.0}
