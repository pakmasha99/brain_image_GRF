"main_modify.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 6 --task ADNI_sex --input_option yAware --learning_rate 1e0 --batch_size 16 --weight_decay 1e-2 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 103.46667688369752, "training_acc": 53.0, "val_loss": 24.238321533203123, "val_acc": 48.0}
{"epoch": 1, "training_loss": 59.012656936645506, "training_acc": 48.0, "val_loss": 33.11653656005859, "val_acc": 52.0}
{"epoch": 2, "training_loss": 28.58338026046753, "training_acc": 63.0, "val_loss": 13.43527946472168, "val_acc": 52.0}
{"epoch": 3, "training_loss": 20.190630416870118, "training_acc": 43.0, "val_loss": 28.42089096069336, "val_acc": 48.0}
{"epoch": 4, "training_loss": 37.12890907287598, "training_acc": 47.0, "val_loss": 41.082571487426755, "val_acc": 48.0}
{"epoch": 5, "training_loss": 34.99530364990235, "training_acc": 53.0, "val_loss": 19.111672668457032, "val_acc": 48.0}
{"epoch": 6, "training_loss": 30.382302551269532, "training_acc": 49.0, "val_loss": 15.659090461730957, "val_acc": 52.0}
{"epoch": 7, "training_loss": 27.10862014770508, "training_acc": 53.0, "val_loss": 30.297547607421876, "val_acc": 52.0}
{"epoch": 8, "training_loss": 38.75300624847412, "training_acc": 49.0, "val_loss": 15.89276912689209, "val_acc": 52.0}
{"epoch": 9, "training_loss": 16.776851615905763, "training_acc": 53.0, "val_loss": 7.585335578918457, "val_acc": 52.0}
{"epoch": 10, "training_loss": 38.229481582641604, "training_acc": 45.0, "val_loss": 32.924443054199216, "val_acc": 52.0}
{"epoch": 11, "training_loss": 39.23795907974243, "training_acc": 51.0, "val_loss": 60.358056640625, "val_acc": 52.0}
{"epoch": 12, "training_loss": 88.59592960357666, "training_acc": 51.0, "val_loss": 62.758446502685544, "val_acc": 48.0}
{"epoch": 13, "training_loss": 54.31822265625, "training_acc": 53.0, "val_loss": 65.654326171875, "val_acc": 52.0}
{"epoch": 14, "training_loss": 46.48937545776367, "training_acc": 53.0, "val_loss": 21.203531494140623, "val_acc": 48.0}
{"epoch": 15, "training_loss": 38.150396270751955, "training_acc": 49.0, "val_loss": 81.14312469482422, "val_acc": 48.0}
{"epoch": 16, "training_loss": 57.924530792236325, "training_acc": 47.0, "val_loss": 31.987538986206054, "val_acc": 52.0}
{"epoch": 17, "training_loss": 58.53747062683105, "training_acc": 45.0, "val_loss": 17.45637222290039, "val_acc": 52.0}
{"epoch": 18, "training_loss": 42.34561584472656, "training_acc": 51.0, "val_loss": 73.04249816894531, "val_acc": 48.0}
{"epoch": 19, "training_loss": 30.938144149780275, "training_acc": 43.0, "val_loss": 8.694594116210938, "val_acc": 48.0}
{"epoch": 20, "training_loss": 33.65318481445313, "training_acc": 45.0, "val_loss": 64.00010162353516, "val_acc": 48.0}
{"epoch": 21, "training_loss": 43.46731391906738, "training_acc": 55.0, "val_loss": 14.159305953979493, "val_acc": 52.0}
{"epoch": 22, "training_loss": 41.36823486328125, "training_acc": 51.0, "val_loss": 73.53260314941406, "val_acc": 52.0}
{"epoch": 23, "training_loss": 55.82366271972656, "training_acc": 53.0, "val_loss": 111.37764556884765, "val_acc": 48.0}
{"epoch": 24, "training_loss": 69.06464904785156, "training_acc": 49.0, "val_loss": 35.97624206542969, "val_acc": 52.0}
{"epoch": 25, "training_loss": 17.34960361480713, "training_acc": 41.0, "val_loss": 16.928909072875978, "val_acc": 48.0}
{"epoch": 26, "training_loss": 20.163706130981446, "training_acc": 45.0, "val_loss": 4.048285980224609, "val_acc": 48.0}
{"epoch": 27, "training_loss": 16.447238006591796, "training_acc": 43.0, "val_loss": 29.936905670166016, "val_acc": 48.0}
{"epoch": 28, "training_loss": 39.63241333007812, "training_acc": 47.0, "val_loss": 83.33335845947266, "val_acc": 52.0}
{"epoch": 29, "training_loss": 48.25446350097656, "training_acc": 61.0, "val_loss": 112.47555480957031, "val_acc": 48.0}
{"epoch": 30, "training_loss": 55.48177932739258, "training_acc": 57.0, "val_loss": 94.1759243774414, "val_acc": 52.0}
{"epoch": 31, "training_loss": 71.86170402526855, "training_acc": 51.0, "val_loss": 58.93598541259766, "val_acc": 48.0}
{"epoch": 32, "training_loss": 34.35521417617798, "training_acc": 41.0, "val_loss": 1.392621202468872, "val_acc": 48.0}
{"epoch": 33, "training_loss": 21.126006660461425, "training_acc": 45.0, "val_loss": 13.065166091918945, "val_acc": 48.0}
{"epoch": 34, "training_loss": 13.308811073303223, "training_acc": 47.0, "val_loss": 12.366723937988281, "val_acc": 52.0}
{"epoch": 35, "training_loss": 12.409735908508301, "training_acc": 45.0, "val_loss": 19.821463623046874, "val_acc": 52.0}
{"epoch": 36, "training_loss": 25.013150215148926, "training_acc": 47.0, "val_loss": 4.74346923828125, "val_acc": 52.0}
{"epoch": 37, "training_loss": 28.39691291809082, "training_acc": 43.0, "val_loss": 12.544683876037597, "val_acc": 52.0}
{"epoch": 38, "training_loss": 29.478013916015627, "training_acc": 49.0, "val_loss": 18.96440788269043, "val_acc": 52.0}
{"epoch": 39, "training_loss": 12.382204360961914, "training_acc": 49.0, "val_loss": 14.88453399658203, "val_acc": 48.0}
{"epoch": 40, "training_loss": 20.913079223632813, "training_acc": 49.0, "val_loss": 16.918112106323242, "val_acc": 52.0}
{"epoch": 41, "training_loss": 19.957836990356444, "training_acc": 49.0, "val_loss": 14.53149471282959, "val_acc": 52.0}
{"epoch": 42, "training_loss": 6.949789829254151, "training_acc": 53.0, "val_loss": 22.017910385131835, "val_acc": 48.0}
{"epoch": 43, "training_loss": 21.51118724822998, "training_acc": 51.0, "val_loss": 39.133983764648434, "val_acc": 48.0}
{"epoch": 44, "training_loss": 29.40208793640137, "training_acc": 55.0, "val_loss": 13.04400032043457, "val_acc": 52.0}
{"epoch": 45, "training_loss": 12.335193939208985, "training_acc": 51.0, "val_loss": 38.0016586303711, "val_acc": 48.0}
{"epoch": 46, "training_loss": 19.785545196533203, "training_acc": 55.0, "val_loss": 64.60787887573242, "val_acc": 48.0}
{"epoch": 47, "training_loss": 45.40745498657227, "training_acc": 53.0, "val_loss": 26.114469146728517, "val_acc": 52.0}
{"epoch": 48, "training_loss": 20.799321212768554, "training_acc": 57.0, "val_loss": 27.869582061767577, "val_acc": 52.0}
{"epoch": 49, "training_loss": 25.10308578491211, "training_acc": 45.0, "val_loss": 2.7304742908477784, "val_acc": 48.0}
{"epoch": 50, "training_loss": 3.4766681957244874, "training_acc": 51.0, "val_loss": 19.03139148712158, "val_acc": 52.0}
{"epoch": 51, "training_loss": 24.626092636585234, "training_acc": 51.0, "val_loss": 19.284945373535155, "val_acc": 52.0}
