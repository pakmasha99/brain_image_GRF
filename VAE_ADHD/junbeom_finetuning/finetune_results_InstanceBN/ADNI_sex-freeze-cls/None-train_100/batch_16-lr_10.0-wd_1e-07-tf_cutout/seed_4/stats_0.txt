"main_modify.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 4 --task ADNI_sex --input_option yAware --learning_rate 1e1 --batch_size 16 --weight_decay 1e-7 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 1045.3946687698365, "training_acc": 51.0, "val_loss": 482.1446264648437, "val_acc": 48.0}
{"epoch": 1, "training_loss": 310.7154852294922, "training_acc": 47.0, "val_loss": 148.0850665283203, "val_acc": 52.0}
{"epoch": 2, "training_loss": 130.77779510498047, "training_acc": 53.0, "val_loss": 181.29516418457033, "val_acc": 48.0}
{"epoch": 3, "training_loss": 153.27442932128906, "training_acc": 49.0, "val_loss": 325.77928833007815, "val_acc": 52.0}
{"epoch": 4, "training_loss": 483.72107177734375, "training_acc": 35.0, "val_loss": 446.96196533203124, "val_acc": 52.0}
{"epoch": 5, "training_loss": 338.90521850585935, "training_acc": 53.0, "val_loss": 212.01117065429688, "val_acc": 52.0}
{"epoch": 6, "training_loss": 418.49853515625, "training_acc": 49.0, "val_loss": 955.09044921875, "val_acc": 48.0}
{"epoch": 7, "training_loss": 399.7382305908203, "training_acc": 53.0, "val_loss": 234.99499877929688, "val_acc": 48.0}
{"epoch": 8, "training_loss": 211.47668758392334, "training_acc": 47.0, "val_loss": 493.9020947265625, "val_acc": 48.0}
{"epoch": 9, "training_loss": 256.0174609375, "training_acc": 55.0, "val_loss": 384.62365356445315, "val_acc": 48.0}
{"epoch": 10, "training_loss": 410.85888427734375, "training_acc": 55.0, "val_loss": 581.7195263671875, "val_acc": 52.0}
{"epoch": 11, "training_loss": 302.78954437255857, "training_acc": 43.0, "val_loss": 114.13825134277344, "val_acc": 52.0}
{"epoch": 12, "training_loss": 248.545380859375, "training_acc": 43.0, "val_loss": 186.26758056640625, "val_acc": 48.0}
{"epoch": 13, "training_loss": 165.0012548828125, "training_acc": 51.0, "val_loss": 522.9901879882813, "val_acc": 48.0}
{"epoch": 14, "training_loss": 281.88473541259765, "training_acc": 43.0, "val_loss": 366.65941528320315, "val_acc": 48.0}
{"epoch": 15, "training_loss": 216.00169128417969, "training_acc": 49.0, "val_loss": 15.209561920166015, "val_acc": 48.0}
{"epoch": 16, "training_loss": 329.58303619384765, "training_acc": 51.0, "val_loss": 268.35470703125, "val_acc": 48.0}
{"epoch": 17, "training_loss": 181.5378546142578, "training_acc": 55.0, "val_loss": 117.23406311035156, "val_acc": 48.0}
{"epoch": 18, "training_loss": 122.68294036865234, "training_acc": 51.0, "val_loss": 64.16441802978515, "val_acc": 52.0}
{"epoch": 19, "training_loss": 141.32176109313966, "training_acc": 55.0, "val_loss": 282.6588562011719, "val_acc": 48.0}
{"epoch": 20, "training_loss": 219.5666796875, "training_acc": 51.0, "val_loss": 327.465888671875, "val_acc": 48.0}
{"epoch": 21, "training_loss": 246.45729370117186, "training_acc": 43.0, "val_loss": 528.7477600097657, "val_acc": 48.0}
{"epoch": 22, "training_loss": 207.82102478027343, "training_acc": 53.0, "val_loss": 139.55393981933594, "val_acc": 48.0}
{"epoch": 23, "training_loss": 113.43986450195312, "training_acc": 53.0, "val_loss": 18.86912742614746, "val_acc": 52.0}
{"epoch": 24, "training_loss": 283.5278024291992, "training_acc": 49.0, "val_loss": 615.724140625, "val_acc": 52.0}
{"epoch": 25, "training_loss": 478.6782116699219, "training_acc": 51.0, "val_loss": 48.96268707275391, "val_acc": 48.0}
{"epoch": 26, "training_loss": 751.4115020751954, "training_acc": 49.0, "val_loss": 549.1624194335938, "val_acc": 48.0}
{"epoch": 27, "training_loss": 810.2097220993041, "training_acc": 53.0, "val_loss": 413.88803955078123, "val_acc": 52.0}
{"epoch": 28, "training_loss": 331.58324340820315, "training_acc": 55.0, "val_loss": 9.286159496307373, "val_acc": 56.0}
{"epoch": 29, "training_loss": 426.7437461853027, "training_acc": 50.0, "val_loss": 1029.613271484375, "val_acc": 48.0}
{"epoch": 30, "training_loss": 742.0110601806641, "training_acc": 53.0, "val_loss": 390.69907348632813, "val_acc": 52.0}
{"epoch": 31, "training_loss": 180.10367795944214, "training_acc": 54.0, "val_loss": 140.42862854003906, "val_acc": 48.0}
{"epoch": 32, "training_loss": 242.91012023925782, "training_acc": 57.0, "val_loss": 493.2233825683594, "val_acc": 52.0}
{"epoch": 33, "training_loss": 264.5100160217285, "training_acc": 45.0, "val_loss": 335.79991821289065, "val_acc": 48.0}
{"epoch": 34, "training_loss": 479.4054296875, "training_acc": 45.0, "val_loss": 345.2883770751953, "val_acc": 52.0}
{"epoch": 35, "training_loss": 170.33440368652344, "training_acc": 61.0, "val_loss": 218.26665100097657, "val_acc": 52.0}
{"epoch": 36, "training_loss": 116.84196395874024, "training_acc": 45.0, "val_loss": 364.4702197265625, "val_acc": 48.0}
{"epoch": 37, "training_loss": 390.2406274414063, "training_acc": 45.0, "val_loss": 27.804807510375976, "val_acc": 48.0}
{"epoch": 38, "training_loss": 106.5377505493164, "training_acc": 51.0, "val_loss": 247.41922485351563, "val_acc": 52.0}
{"epoch": 39, "training_loss": 333.9202136230469, "training_acc": 57.0, "val_loss": 424.78425537109376, "val_acc": 48.0}
{"epoch": 40, "training_loss": 207.84366180419923, "training_acc": 55.0, "val_loss": 658.3953100585937, "val_acc": 48.0}
{"epoch": 41, "training_loss": 502.01869384765627, "training_acc": 47.0, "val_loss": 82.0178907775879, "val_acc": 48.0}
{"epoch": 42, "training_loss": 312.33201171875, "training_acc": 47.0, "val_loss": 18.462675971984865, "val_acc": 52.0}
{"epoch": 43, "training_loss": 96.08431549072266, "training_acc": 52.0, "val_loss": 159.7878839111328, "val_acc": 52.0}
{"epoch": 44, "training_loss": 96.46056701660156, "training_acc": 49.0, "val_loss": 14.276660041809082, "val_acc": 52.0}
{"epoch": 45, "training_loss": 301.69637481689455, "training_acc": 53.0, "val_loss": 456.93767333984374, "val_acc": 52.0}
{"epoch": 46, "training_loss": 284.72381103515625, "training_acc": 57.0, "val_loss": 242.65942993164063, "val_acc": 52.0}
{"epoch": 47, "training_loss": 371.150419921875, "training_acc": 47.0, "val_loss": 133.56127563476562, "val_acc": 52.0}
