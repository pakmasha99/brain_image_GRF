"main_modify.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 2 --task ADNI_sex --input_option yAware --learning_rate 1e1 --batch_size 16 --weight_decay 1e-7 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 1152.59355052948, "training_acc": 50.0, "val_loss": 82.85214324951171, "val_acc": 48.0}
{"epoch": 1, "training_loss": 1135.9458862304687, "training_acc": 48.0, "val_loss": 868.1794604492187, "val_acc": 48.0}
{"epoch": 2, "training_loss": 1183.93042263031, "training_acc": 52.0, "val_loss": 492.4805029296875, "val_acc": 52.0}
{"epoch": 3, "training_loss": 447.86262451171876, "training_acc": 60.0, "val_loss": 1139.1027001953125, "val_acc": 48.0}
{"epoch": 4, "training_loss": 667.6640322875977, "training_acc": 52.0, "val_loss": 151.2473114013672, "val_acc": 52.0}
{"epoch": 5, "training_loss": 391.265498046875, "training_acc": 44.0, "val_loss": 330.58223999023437, "val_acc": 52.0}
{"epoch": 6, "training_loss": 436.86563522338867, "training_acc": 50.0, "val_loss": 558.76017578125, "val_acc": 52.0}
{"epoch": 7, "training_loss": 703.2806762695312, "training_acc": 44.0, "val_loss": 438.4016357421875, "val_acc": 48.0}
{"epoch": 8, "training_loss": 261.31615966796875, "training_acc": 50.0, "val_loss": 590.5864990234375, "val_acc": 48.0}
{"epoch": 9, "training_loss": 522.7772668457031, "training_acc": 48.0, "val_loss": 904.8034619140625, "val_acc": 52.0}
{"epoch": 10, "training_loss": 690.1570751953125, "training_acc": 44.0, "val_loss": 387.7153161621094, "val_acc": 48.0}
{"epoch": 11, "training_loss": 99.4059260559082, "training_acc": 58.0, "val_loss": 128.60915649414062, "val_acc": 52.0}
{"epoch": 12, "training_loss": 80.25049255371094, "training_acc": 54.0, "val_loss": 219.43075073242187, "val_acc": 48.0}
{"epoch": 13, "training_loss": 216.41996704101564, "training_acc": 48.0, "val_loss": 145.80858825683595, "val_acc": 48.0}
{"epoch": 14, "training_loss": 240.42391357421874, "training_acc": 46.0, "val_loss": 255.87001586914062, "val_acc": 48.0}
{"epoch": 15, "training_loss": 326.096748046875, "training_acc": 44.0, "val_loss": 645.2378662109375, "val_acc": 48.0}
{"epoch": 16, "training_loss": 378.71331298828125, "training_acc": 54.0, "val_loss": 20.092998847961425, "val_acc": 48.0}
{"epoch": 17, "training_loss": 278.507646484375, "training_acc": 54.0, "val_loss": 202.96690673828124, "val_acc": 52.0}
{"epoch": 18, "training_loss": 195.4384324645996, "training_acc": 56.0, "val_loss": 550.686640625, "val_acc": 52.0}
{"epoch": 19, "training_loss": 387.1069128417969, "training_acc": 44.0, "val_loss": 433.6048388671875, "val_acc": 52.0}
{"epoch": 20, "training_loss": 292.1745587158203, "training_acc": 50.0, "val_loss": 48.11530380249023, "val_acc": 48.0}
{"epoch": 21, "training_loss": 69.45153633117675, "training_acc": 60.0, "val_loss": 10.57980037689209, "val_acc": 52.0}
{"epoch": 22, "training_loss": 138.21665451049805, "training_acc": 47.0, "val_loss": 117.1817919921875, "val_acc": 52.0}
{"epoch": 23, "training_loss": 92.95023330688477, "training_acc": 50.0, "val_loss": 11.408607559204102, "val_acc": 48.0}
{"epoch": 24, "training_loss": 92.88942291259765, "training_acc": 48.0, "val_loss": 213.45758911132813, "val_acc": 48.0}
{"epoch": 25, "training_loss": 175.7796615600586, "training_acc": 44.0, "val_loss": 591.8435961914063, "val_acc": 52.0}
{"epoch": 26, "training_loss": 557.37326171875, "training_acc": 48.0, "val_loss": 516.2149584960938, "val_acc": 48.0}
{"epoch": 27, "training_loss": 649.8071478271485, "training_acc": 48.0, "val_loss": 67.41039093017578, "val_acc": 52.0}
{"epoch": 28, "training_loss": 484.1447344970703, "training_acc": 50.0, "val_loss": 443.88579711914065, "val_acc": 52.0}
{"epoch": 29, "training_loss": 210.87407135009767, "training_acc": 53.0, "val_loss": 169.40517150878907, "val_acc": 52.0}
{"epoch": 30, "training_loss": 88.76006774902343, "training_acc": 56.0, "val_loss": 110.75023498535157, "val_acc": 48.0}
{"epoch": 31, "training_loss": 161.65110733032228, "training_acc": 55.0, "val_loss": 18.401990203857423, "val_acc": 52.0}
{"epoch": 32, "training_loss": 111.87646926879883, "training_acc": 49.0, "val_loss": 285.8407305908203, "val_acc": 48.0}
{"epoch": 33, "training_loss": 342.56331909179687, "training_acc": 52.0, "val_loss": 404.79957885742186, "val_acc": 52.0}
{"epoch": 34, "training_loss": 419.5380682373047, "training_acc": 52.0, "val_loss": 292.44829833984375, "val_acc": 52.0}
{"epoch": 35, "training_loss": 204.789833984375, "training_acc": 48.0, "val_loss": 72.46922225952149, "val_acc": 52.0}
{"epoch": 36, "training_loss": 154.02125, "training_acc": 44.0, "val_loss": 160.14136657714843, "val_acc": 48.0}
{"epoch": 37, "training_loss": 117.51589935302735, "training_acc": 53.0, "val_loss": 460.8695007324219, "val_acc": 52.0}
{"epoch": 38, "training_loss": 455.74862182617187, "training_acc": 44.0, "val_loss": 152.45822265625, "val_acc": 52.0}
{"epoch": 39, "training_loss": 272.4580300331116, "training_acc": 45.0, "val_loss": 512.0233837890624, "val_acc": 52.0}
{"epoch": 40, "training_loss": 502.58625, "training_acc": 52.0, "val_loss": 526.0456274414063, "val_acc": 48.0}
