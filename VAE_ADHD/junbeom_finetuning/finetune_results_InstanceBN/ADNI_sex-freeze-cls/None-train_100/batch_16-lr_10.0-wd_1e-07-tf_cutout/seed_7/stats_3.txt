"main_modify.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 7 --task ADNI_sex --input_option yAware --learning_rate 1e1 --batch_size 16 --weight_decay 1e-7 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 1416.8277011299133, "training_acc": 42.0, "val_loss": 72.44402313232422, "val_acc": 52.0}
{"epoch": 1, "training_loss": 1489.7937561035155, "training_acc": 50.0, "val_loss": 453.2569421386719, "val_acc": 48.0}
{"epoch": 2, "training_loss": 1184.0271533203124, "training_acc": 44.0, "val_loss": 381.94456665039064, "val_acc": 52.0}
{"epoch": 3, "training_loss": 528.3638497924804, "training_acc": 58.0, "val_loss": 235.65221496582032, "val_acc": 52.0}
{"epoch": 4, "training_loss": 244.23623779296875, "training_acc": 58.0, "val_loss": 11.500867309570312, "val_acc": 48.0}
{"epoch": 5, "training_loss": 343.2681771850586, "training_acc": 48.0, "val_loss": 549.5845825195313, "val_acc": 48.0}
{"epoch": 6, "training_loss": 545.5906359481811, "training_acc": 42.0, "val_loss": 523.7213464355468, "val_acc": 48.0}
{"epoch": 7, "training_loss": 471.0344934082031, "training_acc": 54.0, "val_loss": 534.3854675292969, "val_acc": 52.0}
{"epoch": 8, "training_loss": 499.060498046875, "training_acc": 46.0, "val_loss": 6.1921414947509765, "val_acc": 48.0}
{"epoch": 9, "training_loss": 447.11841537475584, "training_acc": 42.0, "val_loss": 62.98646194458008, "val_acc": 52.0}
{"epoch": 10, "training_loss": 154.32622924804687, "training_acc": 44.0, "val_loss": 338.8413916015625, "val_acc": 48.0}
{"epoch": 11, "training_loss": 435.68804931640625, "training_acc": 44.0, "val_loss": 52.98409423828125, "val_acc": 52.0}
{"epoch": 12, "training_loss": 542.4923864746094, "training_acc": 48.0, "val_loss": 473.9192041015625, "val_acc": 52.0}
{"epoch": 13, "training_loss": 477.2897283935547, "training_acc": 50.0, "val_loss": 614.9273010253906, "val_acc": 48.0}
{"epoch": 14, "training_loss": 608.8927136230469, "training_acc": 46.0, "val_loss": 74.76294372558594, "val_acc": 48.0}
{"epoch": 15, "training_loss": 206.16479858398438, "training_acc": 56.0, "val_loss": 113.96827117919922, "val_acc": 48.0}
{"epoch": 16, "training_loss": 150.23893951416017, "training_acc": 56.0, "val_loss": 3.236347646713257, "val_acc": 48.0}
{"epoch": 17, "training_loss": 210.93960021972657, "training_acc": 48.0, "val_loss": 104.88894500732422, "val_acc": 52.0}
{"epoch": 18, "training_loss": 170.7373126220703, "training_acc": 46.0, "val_loss": 497.7944775390625, "val_acc": 52.0}
{"epoch": 19, "training_loss": 311.5406512451172, "training_acc": 46.0, "val_loss": 120.19636596679688, "val_acc": 52.0}
{"epoch": 20, "training_loss": 101.93303623199463, "training_acc": 53.0, "val_loss": 35.05795928955078, "val_acc": 52.0}
{"epoch": 21, "training_loss": 136.3347605895996, "training_acc": 45.0, "val_loss": 32.63981666564941, "val_acc": 48.0}
{"epoch": 22, "training_loss": 100.98640702724457, "training_acc": 50.0, "val_loss": 262.0693603515625, "val_acc": 48.0}
{"epoch": 23, "training_loss": 268.094150390625, "training_acc": 50.0, "val_loss": 475.7105334472656, "val_acc": 48.0}
{"epoch": 24, "training_loss": 530.6579846191406, "training_acc": 48.0, "val_loss": 577.7878637695312, "val_acc": 52.0}
{"epoch": 25, "training_loss": 447.7998284912109, "training_acc": 54.0, "val_loss": 180.081474609375, "val_acc": 48.0}
{"epoch": 26, "training_loss": 528.547593383789, "training_acc": 46.0, "val_loss": 480.54014892578124, "val_acc": 48.0}
{"epoch": 27, "training_loss": 335.3007556152344, "training_acc": 48.0, "val_loss": 576.7387841796875, "val_acc": 48.0}
{"epoch": 28, "training_loss": 767.9296368408203, "training_acc": 48.0, "val_loss": 790.4909106445313, "val_acc": 52.0}
{"epoch": 29, "training_loss": 491.80610248565677, "training_acc": 56.0, "val_loss": 131.36350494384766, "val_acc": 48.0}
{"epoch": 30, "training_loss": 375.29279541015626, "training_acc": 46.0, "val_loss": 322.697265625, "val_acc": 48.0}
{"epoch": 31, "training_loss": 499.1751739501953, "training_acc": 50.0, "val_loss": 282.4128527832031, "val_acc": 48.0}
{"epoch": 32, "training_loss": 422.2724182128906, "training_acc": 48.0, "val_loss": 582.6871215820313, "val_acc": 52.0}
{"epoch": 33, "training_loss": 289.0551599121094, "training_acc": 44.0, "val_loss": 282.006767578125, "val_acc": 48.0}
{"epoch": 34, "training_loss": 249.3633770751953, "training_acc": 60.0, "val_loss": 211.47284423828125, "val_acc": 52.0}
{"epoch": 35, "training_loss": 117.35726692199707, "training_acc": 38.0, "val_loss": 86.70536529541016, "val_acc": 52.0}
