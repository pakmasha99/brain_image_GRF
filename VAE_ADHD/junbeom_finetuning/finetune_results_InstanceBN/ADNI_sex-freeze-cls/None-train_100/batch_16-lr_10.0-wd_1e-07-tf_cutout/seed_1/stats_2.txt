"main_modify.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 1 --task ADNI_sex --input_option yAware --learning_rate 1e1 --batch_size 16 --weight_decay 1e-7 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 1454.3449627304078, "training_acc": 42.0, "val_loss": 130.7587045288086, "val_acc": 48.0}
{"epoch": 1, "training_loss": 987.4510705566406, "training_acc": 44.0, "val_loss": 657.91306640625, "val_acc": 48.0}
{"epoch": 2, "training_loss": 1157.494158935547, "training_acc": 50.0, "val_loss": 718.0677270507813, "val_acc": 52.0}
{"epoch": 3, "training_loss": 1112.9706268310547, "training_acc": 50.0, "val_loss": 470.23936157226564, "val_acc": 48.0}
{"epoch": 4, "training_loss": 520.6565063476562, "training_acc": 54.0, "val_loss": 994.6019189453125, "val_acc": 52.0}
{"epoch": 5, "training_loss": 958.6464517211914, "training_acc": 52.0, "val_loss": 790.8018395996094, "val_acc": 48.0}
{"epoch": 6, "training_loss": 634.1644799804687, "training_acc": 50.0, "val_loss": 1096.5535595703125, "val_acc": 52.0}
{"epoch": 7, "training_loss": 963.6902258300781, "training_acc": 48.0, "val_loss": 1129.1478271484375, "val_acc": 48.0}
{"epoch": 8, "training_loss": 847.4378686523437, "training_acc": 50.0, "val_loss": 616.4931225585938, "val_acc": 52.0}
{"epoch": 9, "training_loss": 514.9431164550781, "training_acc": 50.0, "val_loss": 876.7840625, "val_acc": 48.0}
{"epoch": 10, "training_loss": 645.6105590820313, "training_acc": 52.0, "val_loss": 438.0530529785156, "val_acc": 52.0}
{"epoch": 11, "training_loss": 178.33817993164064, "training_acc": 52.0, "val_loss": 278.1339599609375, "val_acc": 48.0}
{"epoch": 12, "training_loss": 325.8552621459961, "training_acc": 52.0, "val_loss": 154.76433715820312, "val_acc": 48.0}
{"epoch": 13, "training_loss": 285.88090087890623, "training_acc": 52.0, "val_loss": 245.57815368652345, "val_acc": 52.0}
{"epoch": 14, "training_loss": 160.31080627441406, "training_acc": 56.0, "val_loss": 229.04074340820313, "val_acc": 48.0}
{"epoch": 15, "training_loss": 313.9193639755249, "training_acc": 44.0, "val_loss": 636.7952197265626, "val_acc": 48.0}
{"epoch": 16, "training_loss": 741.41412109375, "training_acc": 54.0, "val_loss": 809.7730932617187, "val_acc": 52.0}
{"epoch": 17, "training_loss": 908.2453643798829, "training_acc": 52.0, "val_loss": 920.5386791992188, "val_acc": 48.0}
{"epoch": 18, "training_loss": 800.1541717529296, "training_acc": 48.0, "val_loss": 494.085380859375, "val_acc": 52.0}
{"epoch": 19, "training_loss": 487.19728881835937, "training_acc": 48.0, "val_loss": 20.27159767150879, "val_acc": 52.0}
{"epoch": 20, "training_loss": 138.37540435791016, "training_acc": 46.0, "val_loss": 666.3895324707031, "val_acc": 52.0}
{"epoch": 21, "training_loss": 407.74059631347654, "training_acc": 58.0, "val_loss": 157.35903381347657, "val_acc": 48.0}
{"epoch": 22, "training_loss": 188.57899627685546, "training_acc": 50.0, "val_loss": 142.6240948486328, "val_acc": 52.0}
{"epoch": 23, "training_loss": 155.00811920166015, "training_acc": 48.0, "val_loss": 470.0538696289062, "val_acc": 48.0}
{"epoch": 24, "training_loss": 364.1945742797852, "training_acc": 48.0, "val_loss": 260.3289050292969, "val_acc": 48.0}
{"epoch": 25, "training_loss": 211.3140512084961, "training_acc": 44.0, "val_loss": 301.66161865234375, "val_acc": 52.0}
{"epoch": 26, "training_loss": 326.07696838378905, "training_acc": 56.0, "val_loss": 378.67406860351565, "val_acc": 48.0}
{"epoch": 27, "training_loss": 496.06312561035156, "training_acc": 44.0, "val_loss": 126.62763977050781, "val_acc": 48.0}
{"epoch": 28, "training_loss": 162.37942993164063, "training_acc": 45.0, "val_loss": 468.77080078125, "val_acc": 52.0}
{"epoch": 29, "training_loss": 265.65000732421873, "training_acc": 46.0, "val_loss": 313.21443359375, "val_acc": 52.0}
{"epoch": 30, "training_loss": 414.61611022949216, "training_acc": 48.0, "val_loss": 599.5134033203125, "val_acc": 52.0}
{"epoch": 31, "training_loss": 759.2044519042969, "training_acc": 50.0, "val_loss": 717.7576123046875, "val_acc": 48.0}
{"epoch": 32, "training_loss": 468.3948565673828, "training_acc": 50.0, "val_loss": 1.2539657266810535, "val_acc": 76.0}
{"epoch": 33, "training_loss": 188.62943733215332, "training_acc": 41.0, "val_loss": 26.748740234375, "val_acc": 48.0}
{"epoch": 34, "training_loss": 289.93085998535156, "training_acc": 52.0, "val_loss": 384.23331665039063, "val_acc": 48.0}
{"epoch": 35, "training_loss": 627.8581259155274, "training_acc": 42.0, "val_loss": 489.90592529296873, "val_acc": 48.0}
{"epoch": 36, "training_loss": 827.183974609375, "training_acc": 46.0, "val_loss": 489.78699096679685, "val_acc": 52.0}
{"epoch": 37, "training_loss": 296.3274865722656, "training_acc": 48.0, "val_loss": 94.48061920166016, "val_acc": 48.0}
{"epoch": 38, "training_loss": 122.26669792175294, "training_acc": 45.0, "val_loss": 111.68423828125, "val_acc": 48.0}
{"epoch": 39, "training_loss": 324.10827392578125, "training_acc": 48.0, "val_loss": 448.73564697265624, "val_acc": 48.0}
{"epoch": 40, "training_loss": 385.1178820800781, "training_acc": 50.0, "val_loss": 139.99716217041015, "val_acc": 48.0}
{"epoch": 41, "training_loss": 98.21823226928711, "training_acc": 55.0, "val_loss": 112.45136810302735, "val_acc": 48.0}
{"epoch": 42, "training_loss": 140.89435668945313, "training_acc": 42.0, "val_loss": 89.45631744384765, "val_acc": 48.0}
{"epoch": 43, "training_loss": 191.76620025634764, "training_acc": 48.0, "val_loss": 203.830419921875, "val_acc": 48.0}
{"epoch": 44, "training_loss": 265.3347576904297, "training_acc": 48.0, "val_loss": 180.03069152832032, "val_acc": 48.0}
{"epoch": 45, "training_loss": 457.5355642700195, "training_acc": 52.0, "val_loss": 507.0992797851562, "val_acc": 48.0}
{"epoch": 46, "training_loss": 275.35145614624025, "training_acc": 42.0, "val_loss": 98.3423388671875, "val_acc": 48.0}
{"epoch": 47, "training_loss": 241.12380859375, "training_acc": 42.0, "val_loss": 141.18212768554687, "val_acc": 48.0}
{"epoch": 48, "training_loss": 338.78609741210937, "training_acc": 44.0, "val_loss": 600.8313696289063, "val_acc": 48.0}
{"epoch": 49, "training_loss": 298.53285827636716, "training_acc": 42.0, "val_loss": 272.84275146484373, "val_acc": 48.0}
{"epoch": 50, "training_loss": 235.6816015625, "training_acc": 54.0, "val_loss": 287.0272265625, "val_acc": 48.0}
{"epoch": 51, "training_loss": 370.30005249023435, "training_acc": 46.0, "val_loss": 482.80682861328125, "val_acc": 48.0}
