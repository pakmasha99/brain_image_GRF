"main_modify.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 6 --task ADNI_sex --input_option yAware --learning_rate 1e1 --batch_size 16 --weight_decay 1e-7 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 981.9372246742248, "training_acc": 54.0, "val_loss": 232.7677264404297, "val_acc": 52.0}
{"epoch": 1, "training_loss": 375.4220764160156, "training_acc": 44.0, "val_loss": 390.24361328125, "val_acc": 52.0}
{"epoch": 2, "training_loss": 295.8907977294922, "training_acc": 48.0, "val_loss": 119.51739959716797, "val_acc": 48.0}
{"epoch": 3, "training_loss": 311.9260064697266, "training_acc": 50.0, "val_loss": 227.7179748535156, "val_acc": 48.0}
{"epoch": 4, "training_loss": 209.0281381225586, "training_acc": 42.0, "val_loss": 121.93634887695312, "val_acc": 52.0}
{"epoch": 5, "training_loss": 132.12896484375, "training_acc": 56.0, "val_loss": 385.04923828125, "val_acc": 52.0}
{"epoch": 6, "training_loss": 155.56081159591676, "training_acc": 48.0, "val_loss": 521.0111767578124, "val_acc": 48.0}
{"epoch": 7, "training_loss": 388.56130554199217, "training_acc": 58.0, "val_loss": 543.36205078125, "val_acc": 52.0}
{"epoch": 8, "training_loss": 265.26135986328126, "training_acc": 54.0, "val_loss": 493.9716479492188, "val_acc": 52.0}
{"epoch": 9, "training_loss": 408.0782620239258, "training_acc": 56.0, "val_loss": 737.5579614257813, "val_acc": 48.0}
{"epoch": 10, "training_loss": 361.2272645568848, "training_acc": 52.0, "val_loss": 365.96588012695315, "val_acc": 48.0}
{"epoch": 11, "training_loss": 290.9450763320923, "training_acc": 57.0, "val_loss": 141.0509228515625, "val_acc": 52.0}
{"epoch": 12, "training_loss": 151.05522811889648, "training_acc": 56.0, "val_loss": 166.36348693847657, "val_acc": 48.0}
{"epoch": 13, "training_loss": 147.20953125, "training_acc": 60.0, "val_loss": 98.40724151611329, "val_acc": 48.0}
{"epoch": 14, "training_loss": 104.90160827636718, "training_acc": 54.0, "val_loss": 227.9487811279297, "val_acc": 48.0}
{"epoch": 15, "training_loss": 313.91823913574217, "training_acc": 48.0, "val_loss": 263.46115234375, "val_acc": 48.0}
{"epoch": 16, "training_loss": 299.7426513671875, "training_acc": 56.0, "val_loss": 296.7935046386719, "val_acc": 52.0}
{"epoch": 17, "training_loss": 198.71898719787598, "training_acc": 46.0, "val_loss": 10.309038848876954, "val_acc": 48.0}
{"epoch": 18, "training_loss": 171.3396481323242, "training_acc": 58.0, "val_loss": 38.60907424926758, "val_acc": 52.0}
{"epoch": 19, "training_loss": 87.4343782043457, "training_acc": 56.0, "val_loss": 56.723822326660155, "val_acc": 52.0}
{"epoch": 20, "training_loss": 131.21491134643554, "training_acc": 50.0, "val_loss": 206.30089111328124, "val_acc": 52.0}
{"epoch": 21, "training_loss": 263.8619873046875, "training_acc": 46.0, "val_loss": 69.58676513671875, "val_acc": 52.0}
{"epoch": 22, "training_loss": 148.37486694335936, "training_acc": 44.0, "val_loss": 63.58075286865235, "val_acc": 52.0}
{"epoch": 23, "training_loss": 98.08195190429687, "training_acc": 64.0, "val_loss": 10.14392147064209, "val_acc": 48.0}
{"epoch": 24, "training_loss": 217.880107421875, "training_acc": 38.0, "val_loss": 139.52347595214843, "val_acc": 52.0}
{"epoch": 25, "training_loss": 93.22073745727539, "training_acc": 57.0, "val_loss": 65.75146087646485, "val_acc": 48.0}
{"epoch": 26, "training_loss": 263.98645263671875, "training_acc": 48.0, "val_loss": 118.46568023681641, "val_acc": 52.0}
{"epoch": 27, "training_loss": 312.58990966796875, "training_acc": 48.0, "val_loss": 114.83475067138671, "val_acc": 52.0}
{"epoch": 28, "training_loss": 152.87951049804687, "training_acc": 52.0, "val_loss": 319.41668701171875, "val_acc": 52.0}
{"epoch": 29, "training_loss": 135.58508682250977, "training_acc": 48.0, "val_loss": 56.43462371826172, "val_acc": 48.0}
{"epoch": 30, "training_loss": 103.53946411132813, "training_acc": 46.0, "val_loss": 198.26447387695313, "val_acc": 48.0}
{"epoch": 31, "training_loss": 213.11224853515625, "training_acc": 34.0, "val_loss": 556.8347119140625, "val_acc": 52.0}
{"epoch": 32, "training_loss": 489.4986767578125, "training_acc": 46.0, "val_loss": 79.26071807861328, "val_acc": 52.0}
{"epoch": 33, "training_loss": 180.22877014160156, "training_acc": 52.0, "val_loss": 230.803681640625, "val_acc": 52.0}
{"epoch": 34, "training_loss": 179.4658233642578, "training_acc": 52.0, "val_loss": 176.75705200195313, "val_acc": 52.0}
{"epoch": 35, "training_loss": 76.04817467689514, "training_acc": 57.0, "val_loss": 84.64679443359375, "val_acc": 48.0}
{"epoch": 36, "training_loss": 148.70232482910157, "training_acc": 46.0, "val_loss": 65.18848541259766, "val_acc": 48.0}
{"epoch": 37, "training_loss": 133.03644355773926, "training_acc": 43.0, "val_loss": 300.6780090332031, "val_acc": 48.0}
{"epoch": 38, "training_loss": 160.26754676818848, "training_acc": 54.0, "val_loss": 152.15785217285156, "val_acc": 52.0}
{"epoch": 39, "training_loss": 206.73395202636718, "training_acc": 46.0, "val_loss": 409.5596398925781, "val_acc": 52.0}
{"epoch": 40, "training_loss": 510.34616744995117, "training_acc": 43.0, "val_loss": 453.473955078125, "val_acc": 52.0}
{"epoch": 41, "training_loss": 421.64837890625, "training_acc": 46.0, "val_loss": 6.235952072143554, "val_acc": 76.0}
{"epoch": 42, "training_loss": 105.3665026473999, "training_acc": 50.0, "val_loss": 332.35259399414065, "val_acc": 48.0}
{"epoch": 43, "training_loss": 342.53139526367187, "training_acc": 52.0, "val_loss": 308.3232391357422, "val_acc": 48.0}
{"epoch": 44, "training_loss": 248.26148681640626, "training_acc": 46.0, "val_loss": 184.27600952148438, "val_acc": 48.0}
{"epoch": 45, "training_loss": 232.55285148620607, "training_acc": 46.0, "val_loss": 290.7856140136719, "val_acc": 52.0}
{"epoch": 46, "training_loss": 289.78664459228514, "training_acc": 52.0, "val_loss": 34.809548950195314, "val_acc": 48.0}
