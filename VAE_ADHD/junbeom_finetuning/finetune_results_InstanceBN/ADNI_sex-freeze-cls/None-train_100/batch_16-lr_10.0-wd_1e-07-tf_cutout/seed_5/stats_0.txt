"main_modify.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 5 --task ADNI_sex --input_option yAware --learning_rate 1e1 --batch_size 16 --weight_decay 1e-7 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 753.8485869979859, "training_acc": 54.0, "val_loss": 795.208330078125, "val_acc": 52.0}
{"epoch": 1, "training_loss": 763.5494384765625, "training_acc": 50.0, "val_loss": 549.6450366210937, "val_acc": 48.0}
{"epoch": 2, "training_loss": 400.5328076171875, "training_acc": 46.0, "val_loss": 152.56991027832032, "val_acc": 48.0}
{"epoch": 3, "training_loss": 185.49310974121093, "training_acc": 54.0, "val_loss": 123.17568237304687, "val_acc": 52.0}
{"epoch": 4, "training_loss": 190.72495544433593, "training_acc": 50.0, "val_loss": 235.10625793457032, "val_acc": 52.0}
{"epoch": 5, "training_loss": 198.1169761657715, "training_acc": 54.0, "val_loss": 11.491282234191894, "val_acc": 48.0}
{"epoch": 6, "training_loss": 66.88107391357421, "training_acc": 56.0, "val_loss": 93.44560073852539, "val_acc": 48.0}
{"epoch": 7, "training_loss": 117.1913924407959, "training_acc": 50.0, "val_loss": 251.037333984375, "val_acc": 48.0}
{"epoch": 8, "training_loss": 242.77501770019532, "training_acc": 48.0, "val_loss": 26.462995376586914, "val_acc": 48.0}
{"epoch": 9, "training_loss": 138.0166744995117, "training_acc": 56.0, "val_loss": 17.788238525390625, "val_acc": 52.0}
{"epoch": 10, "training_loss": 119.11433441162109, "training_acc": 52.0, "val_loss": 140.5845782470703, "val_acc": 48.0}
{"epoch": 11, "training_loss": 128.29381408691407, "training_acc": 60.0, "val_loss": 3.9252684783935545, "val_acc": 56.0}
{"epoch": 12, "training_loss": 79.9743994140625, "training_acc": 52.0, "val_loss": 200.71254638671874, "val_acc": 52.0}
{"epoch": 13, "training_loss": 219.50409301757813, "training_acc": 48.0, "val_loss": 14.394331130981445, "val_acc": 48.0}
{"epoch": 14, "training_loss": 37.77613975524903, "training_acc": 53.0, "val_loss": 103.80665100097656, "val_acc": 52.0}
{"epoch": 15, "training_loss": 102.82742279052735, "training_acc": 54.0, "val_loss": 286.5286560058594, "val_acc": 52.0}
{"epoch": 16, "training_loss": 243.9739712524414, "training_acc": 48.0, "val_loss": 371.32286254882814, "val_acc": 52.0}
{"epoch": 17, "training_loss": 373.2895520019531, "training_acc": 50.0, "val_loss": 171.55494079589843, "val_acc": 52.0}
{"epoch": 18, "training_loss": 327.91034423828125, "training_acc": 50.0, "val_loss": 92.7152685546875, "val_acc": 48.0}
{"epoch": 19, "training_loss": 383.55560791015625, "training_acc": 52.0, "val_loss": 784.4135278320313, "val_acc": 48.0}
{"epoch": 20, "training_loss": 507.383369140625, "training_acc": 50.0, "val_loss": 69.13775939941407, "val_acc": 52.0}
{"epoch": 21, "training_loss": 273.9382763671875, "training_acc": 44.0, "val_loss": 124.557685546875, "val_acc": 52.0}
{"epoch": 22, "training_loss": 209.63778594970702, "training_acc": 46.0, "val_loss": 69.41995513916015, "val_acc": 48.0}
{"epoch": 23, "training_loss": 147.054677734375, "training_acc": 60.0, "val_loss": 40.22991409301758, "val_acc": 52.0}
{"epoch": 24, "training_loss": 116.08291648864746, "training_acc": 48.0, "val_loss": 3.676528491973877, "val_acc": 60.0}
{"epoch": 25, "training_loss": 52.73757827758789, "training_acc": 55.0, "val_loss": 383.24158935546876, "val_acc": 48.0}
{"epoch": 26, "training_loss": 396.59697326660154, "training_acc": 42.0, "val_loss": 767.4185229492188, "val_acc": 48.0}
{"epoch": 27, "training_loss": 452.4100009918213, "training_acc": 58.0, "val_loss": 362.514853515625, "val_acc": 52.0}
{"epoch": 28, "training_loss": 313.2873278808594, "training_acc": 54.0, "val_loss": 304.22460571289065, "val_acc": 52.0}
{"epoch": 29, "training_loss": 163.59362976074217, "training_acc": 44.0, "val_loss": 130.20440826416015, "val_acc": 48.0}
{"epoch": 30, "training_loss": 209.5512158203125, "training_acc": 48.0, "val_loss": 278.4813513183594, "val_acc": 52.0}
{"epoch": 31, "training_loss": 270.1509820556641, "training_acc": 56.0, "val_loss": 18.8986173248291, "val_acc": 52.0}
{"epoch": 32, "training_loss": 119.08077239990234, "training_acc": 48.0, "val_loss": 48.092508697509764, "val_acc": 48.0}
{"epoch": 33, "training_loss": 177.6472998046875, "training_acc": 56.0, "val_loss": 179.71644775390624, "val_acc": 48.0}
{"epoch": 34, "training_loss": 219.82422424316405, "training_acc": 58.0, "val_loss": 408.33428833007815, "val_acc": 48.0}
{"epoch": 35, "training_loss": 380.22608642578126, "training_acc": 44.0, "val_loss": 688.6805090332032, "val_acc": 48.0}
{"epoch": 36, "training_loss": 600.6047961425782, "training_acc": 48.0, "val_loss": 943.1879248046876, "val_acc": 52.0}
{"epoch": 37, "training_loss": 616.1162170410156, "training_acc": 56.0, "val_loss": 571.8758386230469, "val_acc": 48.0}
{"epoch": 38, "training_loss": 431.4870941162109, "training_acc": 52.0, "val_loss": 355.7411840820312, "val_acc": 48.0}
{"epoch": 39, "training_loss": 302.9927325439453, "training_acc": 52.0, "val_loss": 265.39054321289063, "val_acc": 48.0}
{"epoch": 40, "training_loss": 347.2070373535156, "training_acc": 52.0, "val_loss": 515.5788500976563, "val_acc": 52.0}
{"epoch": 41, "training_loss": 461.007099609375, "training_acc": 52.0, "val_loss": 190.75747375488282, "val_acc": 52.0}
{"epoch": 42, "training_loss": 291.12226806640626, "training_acc": 50.0, "val_loss": 10.36779417037964, "val_acc": 56.0}
{"epoch": 43, "training_loss": 230.67739486694336, "training_acc": 52.0, "val_loss": 191.24372924804686, "val_acc": 48.0}
