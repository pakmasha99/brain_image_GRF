"main_modify.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_sex --input_option yAware --learning_rate 5e0 --batch_size 16 --weight_decay 1e-5 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 419.7435517311096, "training_acc": 56.0, "val_loss": 300.59211303710936, "val_acc": 52.0}
{"epoch": 1, "training_loss": 244.12932342529297, "training_acc": 60.0, "val_loss": 139.59277587890625, "val_acc": 48.0}
{"epoch": 2, "training_loss": 77.43386024475097, "training_acc": 54.0, "val_loss": 29.232037658691407, "val_acc": 48.0}
{"epoch": 3, "training_loss": 41.13251617431641, "training_acc": 58.0, "val_loss": 75.85373931884766, "val_acc": 52.0}
{"epoch": 4, "training_loss": 97.62251762390137, "training_acc": 40.0, "val_loss": 92.63838287353515, "val_acc": 52.0}
{"epoch": 5, "training_loss": 72.57105651855468, "training_acc": 46.0, "val_loss": 55.913257446289066, "val_acc": 48.0}
{"epoch": 6, "training_loss": 103.87043182373047, "training_acc": 52.0, "val_loss": 35.31115249633789, "val_acc": 52.0}
{"epoch": 7, "training_loss": 33.15949905395508, "training_acc": 50.0, "val_loss": 12.708566970825196, "val_acc": 48.0}
{"epoch": 8, "training_loss": 133.18546508789063, "training_acc": 44.0, "val_loss": 108.9154150390625, "val_acc": 52.0}
{"epoch": 9, "training_loss": 184.63591995239258, "training_acc": 50.0, "val_loss": 271.51642578125, "val_acc": 48.0}
{"epoch": 10, "training_loss": 178.68779518127442, "training_acc": 56.0, "val_loss": 84.80513549804688, "val_acc": 48.0}
{"epoch": 11, "training_loss": 111.93444633483887, "training_acc": 48.0, "val_loss": 3.9916340923309326, "val_acc": 48.0}
{"epoch": 12, "training_loss": 139.72116458892822, "training_acc": 42.0, "val_loss": 24.400186080932617, "val_acc": 52.0}
{"epoch": 13, "training_loss": 45.44354736328125, "training_acc": 54.0, "val_loss": 106.4218017578125, "val_acc": 52.0}
{"epoch": 14, "training_loss": 66.71211090087891, "training_acc": 50.0, "val_loss": 23.70296012878418, "val_acc": 52.0}
{"epoch": 15, "training_loss": 65.82512298583984, "training_acc": 60.0, "val_loss": 175.7279345703125, "val_acc": 52.0}
{"epoch": 16, "training_loss": 202.37090347290038, "training_acc": 50.0, "val_loss": 67.56414291381836, "val_acc": 52.0}
{"epoch": 17, "training_loss": 50.52593948364258, "training_acc": 48.0, "val_loss": 13.822650718688966, "val_acc": 52.0}
{"epoch": 18, "training_loss": 78.92006393432617, "training_acc": 54.0, "val_loss": 10.814943332672119, "val_acc": 52.0}
{"epoch": 19, "training_loss": 43.97735221862793, "training_acc": 58.0, "val_loss": 257.71744750976563, "val_acc": 48.0}
{"epoch": 20, "training_loss": 237.9241278076172, "training_acc": 44.0, "val_loss": 129.56974029541016, "val_acc": 48.0}
{"epoch": 21, "training_loss": 149.87568298339843, "training_acc": 50.0, "val_loss": 93.88734039306641, "val_acc": 48.0}
{"epoch": 22, "training_loss": 119.62713989257813, "training_acc": 46.0, "val_loss": 16.358591194152833, "val_acc": 48.0}
{"epoch": 23, "training_loss": 94.72899795532227, "training_acc": 52.0, "val_loss": 2.462532334327698, "val_acc": 44.0}
{"epoch": 24, "training_loss": 98.84727840423584, "training_acc": 57.0, "val_loss": 47.77786407470703, "val_acc": 52.0}
{"epoch": 25, "training_loss": 67.2825958442688, "training_acc": 50.0, "val_loss": 73.7020571899414, "val_acc": 52.0}
{"epoch": 26, "training_loss": 97.26806823730469, "training_acc": 48.0, "val_loss": 131.6849072265625, "val_acc": 52.0}
{"epoch": 27, "training_loss": 66.56848609924316, "training_acc": 48.0, "val_loss": 69.08645233154297, "val_acc": 52.0}
{"epoch": 28, "training_loss": 100.62558441162109, "training_acc": 62.0, "val_loss": 159.5498468017578, "val_acc": 48.0}
{"epoch": 29, "training_loss": 276.57282600402834, "training_acc": 44.0, "val_loss": 239.47120971679686, "val_acc": 48.0}
{"epoch": 30, "training_loss": 278.9596887207031, "training_acc": 50.0, "val_loss": 235.39513427734374, "val_acc": 52.0}
{"epoch": 31, "training_loss": 180.07807739257814, "training_acc": 48.0, "val_loss": 226.38037719726563, "val_acc": 52.0}
{"epoch": 32, "training_loss": 194.38533294677734, "training_acc": 50.0, "val_loss": 107.15242553710938, "val_acc": 52.0}
{"epoch": 33, "training_loss": 132.81993591308594, "training_acc": 54.0, "val_loss": 74.01973205566406, "val_acc": 48.0}
{"epoch": 34, "training_loss": 51.843946838378905, "training_acc": 60.0, "val_loss": 10.318929443359375, "val_acc": 56.0}
{"epoch": 35, "training_loss": 43.3648543548584, "training_acc": 58.0, "val_loss": 39.46111877441406, "val_acc": 52.0}
{"epoch": 36, "training_loss": 51.65144989013672, "training_acc": 50.0, "val_loss": 101.39617980957031, "val_acc": 48.0}
{"epoch": 37, "training_loss": 98.65167510986328, "training_acc": 50.0, "val_loss": 75.8139421081543, "val_acc": 48.0}
{"epoch": 38, "training_loss": 48.019124298095704, "training_acc": 44.0, "val_loss": 20.287203369140624, "val_acc": 52.0}
{"epoch": 39, "training_loss": 104.73395965576172, "training_acc": 50.0, "val_loss": 6.102260665893555, "val_acc": 48.0}
{"epoch": 40, "training_loss": 26.375199851989745, "training_acc": 51.0, "val_loss": 121.88005493164063, "val_acc": 52.0}
{"epoch": 41, "training_loss": 107.72743881225585, "training_acc": 52.0, "val_loss": 53.75969741821289, "val_acc": 52.0}
{"epoch": 42, "training_loss": 88.7345841217041, "training_acc": 53.0, "val_loss": 107.77820526123047, "val_acc": 52.0}
