"main_modify.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 4 --task ADNI_sex --input_option yAware --learning_rate 5e0 --batch_size 16 --weight_decay 1e-5 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 522.7647752761841, "training_acc": 51.0, "val_loss": 241.0096301269531, "val_acc": 48.0}
{"epoch": 1, "training_loss": 155.33363037109376, "training_acc": 47.0, "val_loss": 74.0704150390625, "val_acc": 52.0}
{"epoch": 2, "training_loss": 65.39667449951172, "training_acc": 53.0, "val_loss": 90.5990786743164, "val_acc": 48.0}
{"epoch": 3, "training_loss": 76.61857559204101, "training_acc": 49.0, "val_loss": 162.9671368408203, "val_acc": 52.0}
{"epoch": 4, "training_loss": 241.8202978515625, "training_acc": 35.0, "val_loss": 223.62196655273436, "val_acc": 52.0}
{"epoch": 5, "training_loss": 169.43887573242188, "training_acc": 53.0, "val_loss": 106.1929214477539, "val_acc": 52.0}
{"epoch": 6, "training_loss": 209.37262268066405, "training_acc": 49.0, "val_loss": 477.32191650390627, "val_acc": 48.0}
{"epoch": 7, "training_loss": 199.91088592529297, "training_acc": 53.0, "val_loss": 117.14755279541015, "val_acc": 48.0}
{"epoch": 8, "training_loss": 106.01375808715821, "training_acc": 47.0, "val_loss": 244.42243896484376, "val_acc": 48.0}
{"epoch": 9, "training_loss": 128.67799530029296, "training_acc": 55.0, "val_loss": 187.56644653320313, "val_acc": 48.0}
{"epoch": 10, "training_loss": 202.63058959960938, "training_acc": 55.0, "val_loss": 296.31144287109373, "val_acc": 52.0}
{"epoch": 11, "training_loss": 149.39699398040773, "training_acc": 46.0, "val_loss": 103.17561981201172, "val_acc": 48.0}
{"epoch": 12, "training_loss": 205.78023498535157, "training_acc": 41.0, "val_loss": 214.90095581054686, "val_acc": 48.0}
{"epoch": 13, "training_loss": 345.0545385742187, "training_acc": 47.0, "val_loss": 285.1660803222656, "val_acc": 52.0}
{"epoch": 14, "training_loss": 244.22504531860352, "training_acc": 51.0, "val_loss": 520.4462744140625, "val_acc": 48.0}
{"epoch": 15, "training_loss": 455.4528173828125, "training_acc": 39.0, "val_loss": 255.14641357421874, "val_acc": 52.0}
{"epoch": 16, "training_loss": 353.7943560791016, "training_acc": 49.0, "val_loss": 232.942861328125, "val_acc": 48.0}
{"epoch": 17, "training_loss": 118.86396301269531, "training_acc": 47.0, "val_loss": 197.40292236328125, "val_acc": 48.0}
{"epoch": 18, "training_loss": 82.16606689453126, "training_acc": 57.0, "val_loss": 56.05285705566406, "val_acc": 52.0}
{"epoch": 19, "training_loss": 49.49194580078125, "training_acc": 51.0, "val_loss": 8.982580490112305, "val_acc": 48.0}
{"epoch": 20, "training_loss": 120.53947662353515, "training_acc": 47.0, "val_loss": 82.90530944824219, "val_acc": 48.0}
{"epoch": 21, "training_loss": 145.0092623901367, "training_acc": 51.0, "val_loss": 314.36039306640623, "val_acc": 48.0}
{"epoch": 22, "training_loss": 224.80230346679687, "training_acc": 49.0, "val_loss": 50.50901901245117, "val_acc": 48.0}
{"epoch": 23, "training_loss": 118.46552856445312, "training_acc": 57.0, "val_loss": 6.579277219772339, "val_acc": 48.0}
{"epoch": 24, "training_loss": 51.80054573059082, "training_acc": 50.0, "val_loss": 166.59332702636718, "val_acc": 52.0}
{"epoch": 25, "training_loss": 171.87817436218262, "training_acc": 53.0, "val_loss": 192.68295654296875, "val_acc": 48.0}
{"epoch": 26, "training_loss": 135.78583923339843, "training_acc": 51.0, "val_loss": 212.24070190429688, "val_acc": 48.0}
{"epoch": 27, "training_loss": 126.63154602050781, "training_acc": 45.0, "val_loss": 19.09452407836914, "val_acc": 52.0}
{"epoch": 28, "training_loss": 69.25209649562835, "training_acc": 47.0, "val_loss": 165.727568359375, "val_acc": 48.0}
{"epoch": 29, "training_loss": 126.0703549194336, "training_acc": 47.0, "val_loss": 230.00984985351562, "val_acc": 48.0}
{"epoch": 30, "training_loss": 155.21895156860353, "training_acc": 47.0, "val_loss": 54.97526214599609, "val_acc": 48.0}
{"epoch": 31, "training_loss": 49.59725030899048, "training_acc": 47.0, "val_loss": 78.64653839111328, "val_acc": 48.0}
{"epoch": 32, "training_loss": 50.05038787841797, "training_acc": 59.0, "val_loss": 1.5622525119781494, "val_acc": 52.0}
{"epoch": 33, "training_loss": 53.43033979415893, "training_acc": 45.0, "val_loss": 192.46304809570313, "val_acc": 48.0}
{"epoch": 34, "training_loss": 158.34650482177733, "training_acc": 51.0, "val_loss": 227.34791137695314, "val_acc": 48.0}
{"epoch": 35, "training_loss": 205.5924658203125, "training_acc": 57.0, "val_loss": 229.9427355957031, "val_acc": 52.0}
{"epoch": 36, "training_loss": 134.00982421875, "training_acc": 43.0, "val_loss": 49.111884918212894, "val_acc": 48.0}
{"epoch": 37, "training_loss": 114.93569274902343, "training_acc": 45.0, "val_loss": 138.53342224121093, "val_acc": 48.0}
{"epoch": 38, "training_loss": 110.78533447265625, "training_acc": 45.0, "val_loss": 168.50511169433594, "val_acc": 48.0}
{"epoch": 39, "training_loss": 109.90150299072266, "training_acc": 51.0, "val_loss": 22.453748931884764, "val_acc": 48.0}
{"epoch": 40, "training_loss": 253.84564727783203, "training_acc": 49.0, "val_loss": 304.106259765625, "val_acc": 48.0}
{"epoch": 41, "training_loss": 225.04553649902343, "training_acc": 49.0, "val_loss": 78.8059309387207, "val_acc": 48.0}
{"epoch": 42, "training_loss": 91.3719221496582, "training_acc": 51.0, "val_loss": 214.10650146484375, "val_acc": 48.0}
{"epoch": 43, "training_loss": 140.94561356298627, "training_acc": 53.0, "val_loss": 116.86765228271484, "val_acc": 48.0}
{"epoch": 44, "training_loss": 185.39274307250977, "training_acc": 43.0, "val_loss": 188.42814086914063, "val_acc": 48.0}
{"epoch": 45, "training_loss": 309.7490524291992, "training_acc": 53.0, "val_loss": 404.0883215332031, "val_acc": 52.0}
{"epoch": 46, "training_loss": 414.3085791015625, "training_acc": 45.0, "val_loss": 483.88126708984373, "val_acc": 48.0}
{"epoch": 47, "training_loss": 302.88691772460936, "training_acc": 55.0, "val_loss": 490.5874926757813, "val_acc": 52.0}
{"epoch": 48, "training_loss": 383.98127685546876, "training_acc": 41.0, "val_loss": 108.40642791748047, "val_acc": 48.0}
{"epoch": 49, "training_loss": 213.07446044921875, "training_acc": 45.0, "val_loss": 446.6279663085937, "val_acc": 48.0}
{"epoch": 50, "training_loss": 323.33861938476565, "training_acc": 47.0, "val_loss": 442.64453369140625, "val_acc": 52.0}
{"epoch": 51, "training_loss": 315.6515704345703, "training_acc": 49.0, "val_loss": 420.06939453125, "val_acc": 48.0}
