"main_modify.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 6 --task ADNI_sex --input_option yAware --learning_rate 5e0 --batch_size 16 --weight_decay 1e-5 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 510.5692812538147, "training_acc": 53.0, "val_loss": 138.0008410644531, "val_acc": 48.0}
{"epoch": 1, "training_loss": 338.18435012817383, "training_acc": 49.0, "val_loss": 516.4049658203126, "val_acc": 52.0}
{"epoch": 2, "training_loss": 302.3765087890625, "training_acc": 57.0, "val_loss": 802.2521411132813, "val_acc": 48.0}
{"epoch": 3, "training_loss": 477.6708154296875, "training_acc": 47.0, "val_loss": 551.6481616210938, "val_acc": 52.0}
{"epoch": 4, "training_loss": 367.50258544921877, "training_acc": 51.0, "val_loss": 523.5480261230468, "val_acc": 48.0}
{"epoch": 5, "training_loss": 335.3090673828125, "training_acc": 53.0, "val_loss": 278.85326782226565, "val_acc": 52.0}
{"epoch": 6, "training_loss": 377.4544311523438, "training_acc": 47.0, "val_loss": 126.03814697265625, "val_acc": 48.0}
{"epoch": 7, "training_loss": 302.8639450073242, "training_acc": 45.0, "val_loss": 155.52955078125, "val_acc": 48.0}
{"epoch": 8, "training_loss": 128.61256591796874, "training_acc": 51.0, "val_loss": 265.46716552734375, "val_acc": 48.0}
{"epoch": 9, "training_loss": 211.0522903442383, "training_acc": 43.0, "val_loss": 183.64573791503906, "val_acc": 48.0}
{"epoch": 10, "training_loss": 261.98963134765626, "training_acc": 39.0, "val_loss": 121.7641259765625, "val_acc": 52.0}
{"epoch": 11, "training_loss": 165.82974731445313, "training_acc": 57.0, "val_loss": 342.71443603515627, "val_acc": 52.0}
{"epoch": 12, "training_loss": 297.0807208251953, "training_acc": 43.0, "val_loss": 30.481675186157226, "val_acc": 48.0}
{"epoch": 13, "training_loss": 89.6603706741333, "training_acc": 44.0, "val_loss": 131.5816828918457, "val_acc": 52.0}
{"epoch": 14, "training_loss": 119.04826263427735, "training_acc": 53.0, "val_loss": 236.97258178710936, "val_acc": 52.0}
{"epoch": 15, "training_loss": 134.17960494995117, "training_acc": 55.0, "val_loss": 165.098740234375, "val_acc": 52.0}
{"epoch": 16, "training_loss": 182.6211071777344, "training_acc": 53.0, "val_loss": 41.456740875244144, "val_acc": 48.0}
{"epoch": 17, "training_loss": 166.94185485839844, "training_acc": 45.0, "val_loss": 210.85333984375, "val_acc": 48.0}
{"epoch": 18, "training_loss": 206.53090759277345, "training_acc": 43.0, "val_loss": 175.27623352050782, "val_acc": 48.0}
{"epoch": 19, "training_loss": 91.84180465698242, "training_acc": 41.0, "val_loss": 97.1551611328125, "val_acc": 52.0}
{"epoch": 20, "training_loss": 86.43571269989013, "training_acc": 57.0, "val_loss": 257.85078125, "val_acc": 52.0}
{"epoch": 21, "training_loss": 226.19959106445313, "training_acc": 45.0, "val_loss": 82.58111511230469, "val_acc": 52.0}
{"epoch": 22, "training_loss": 182.3988592529297, "training_acc": 43.0, "val_loss": 92.22164489746093, "val_acc": 48.0}
{"epoch": 23, "training_loss": 168.81197235107422, "training_acc": 51.0, "val_loss": 398.16489501953123, "val_acc": 48.0}
{"epoch": 24, "training_loss": 323.97238891601563, "training_acc": 47.0, "val_loss": 441.92182006835935, "val_acc": 52.0}
{"epoch": 25, "training_loss": 279.4461669921875, "training_acc": 53.0, "val_loss": 493.92875732421874, "val_acc": 48.0}
{"epoch": 26, "training_loss": 326.307802734375, "training_acc": 51.0, "val_loss": 231.1198974609375, "val_acc": 52.0}
{"epoch": 27, "training_loss": 139.05855041503906, "training_acc": 47.0, "val_loss": 46.47880737304688, "val_acc": 52.0}
{"epoch": 28, "training_loss": 153.16490478515624, "training_acc": 49.0, "val_loss": 151.59522399902343, "val_acc": 52.0}
{"epoch": 29, "training_loss": 68.19260070800782, "training_acc": 59.0, "val_loss": 86.50509246826172, "val_acc": 48.0}
{"epoch": 30, "training_loss": 36.87491226196289, "training_acc": 69.0, "val_loss": 174.29369262695312, "val_acc": 48.0}
{"epoch": 31, "training_loss": 200.36806213378907, "training_acc": 49.0, "val_loss": 30.110343627929687, "val_acc": 52.0}
{"epoch": 32, "training_loss": 170.1459182739258, "training_acc": 57.0, "val_loss": 302.96925537109377, "val_acc": 52.0}
{"epoch": 33, "training_loss": 261.8108187866211, "training_acc": 47.0, "val_loss": 192.89421020507814, "val_acc": 48.0}
{"epoch": 34, "training_loss": 160.49514587402345, "training_acc": 53.0, "val_loss": 189.50362365722657, "val_acc": 48.0}
{"epoch": 35, "training_loss": 181.48900466918946, "training_acc": 51.0, "val_loss": 57.63239669799805, "val_acc": 48.0}
{"epoch": 36, "training_loss": 71.46394287109375, "training_acc": 53.0, "val_loss": 224.1732421875, "val_acc": 48.0}
{"epoch": 37, "training_loss": 158.13042366027832, "training_acc": 49.0, "val_loss": 212.90154541015625, "val_acc": 48.0}
{"epoch": 38, "training_loss": 187.83873657226562, "training_acc": 49.0, "val_loss": 36.801092376708986, "val_acc": 48.0}
{"epoch": 39, "training_loss": 64.21859237670898, "training_acc": 47.0, "val_loss": 115.65373229980469, "val_acc": 52.0}
{"epoch": 40, "training_loss": 90.27818969726563, "training_acc": 51.0, "val_loss": 153.54307922363282, "val_acc": 52.0}
{"epoch": 41, "training_loss": 119.39485290527344, "training_acc": 45.0, "val_loss": 34.949754333496095, "val_acc": 52.0}
{"epoch": 42, "training_loss": 139.70177368164062, "training_acc": 54.0, "val_loss": 399.97666137695313, "val_acc": 52.0}
{"epoch": 43, "training_loss": 321.46532745361327, "training_acc": 45.0, "val_loss": 214.45501342773437, "val_acc": 48.0}
{"epoch": 44, "training_loss": 196.8284765625, "training_acc": 47.0, "val_loss": 169.38105590820314, "val_acc": 48.0}
{"epoch": 45, "training_loss": 181.95558502197267, "training_acc": 43.0, "val_loss": 425.9821496582031, "val_acc": 48.0}
{"epoch": 46, "training_loss": 389.954541015625, "training_acc": 43.0, "val_loss": 421.24111328125, "val_acc": 52.0}
{"epoch": 47, "training_loss": 271.1242007446289, "training_acc": 53.0, "val_loss": 126.91223205566406, "val_acc": 48.0}
{"epoch": 48, "training_loss": 167.93729248046876, "training_acc": 43.0, "val_loss": 284.4198028564453, "val_acc": 48.0}
{"epoch": 49, "training_loss": 255.12099822998047, "training_acc": 47.0, "val_loss": 262.1669079589844, "val_acc": 48.0}
{"epoch": 50, "training_loss": 275.6954522705078, "training_acc": 53.0, "val_loss": 449.7865264892578, "val_acc": 52.0}
