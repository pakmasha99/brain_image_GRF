"main_modify.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 1 --task ADNI_sex --input_option yAware --learning_rate 5e0 --batch_size 16 --weight_decay 1e-5 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 506.76391330718997, "training_acc": 50.0, "val_loss": 253.43514282226562, "val_acc": 52.0}
{"epoch": 1, "training_loss": 324.1899462890625, "training_acc": 44.0, "val_loss": 90.93188232421875, "val_acc": 48.0}
{"epoch": 2, "training_loss": 198.9773779296875, "training_acc": 48.0, "val_loss": 182.00445251464845, "val_acc": 48.0}
{"epoch": 3, "training_loss": 147.5574853515625, "training_acc": 48.0, "val_loss": 310.3169970703125, "val_acc": 48.0}
{"epoch": 4, "training_loss": 211.68965759277344, "training_acc": 46.0, "val_loss": 109.83373901367187, "val_acc": 48.0}
{"epoch": 5, "training_loss": 160.07104919433593, "training_acc": 42.0, "val_loss": 288.3105078125, "val_acc": 48.0}
{"epoch": 6, "training_loss": 513.246876373291, "training_acc": 50.0, "val_loss": 252.84885925292969, "val_acc": 52.0}
{"epoch": 7, "training_loss": 360.82352630615236, "training_acc": 52.0, "val_loss": 267.67435791015623, "val_acc": 48.0}
{"epoch": 8, "training_loss": 236.31518646240235, "training_acc": 54.0, "val_loss": 459.7838403320313, "val_acc": 52.0}
{"epoch": 9, "training_loss": 326.3815618896484, "training_acc": 50.0, "val_loss": 495.67054443359376, "val_acc": 48.0}
{"epoch": 10, "training_loss": 304.39942932128906, "training_acc": 54.0, "val_loss": 608.8082861328126, "val_acc": 52.0}
{"epoch": 11, "training_loss": 309.83095123291014, "training_acc": 52.0, "val_loss": 88.52849197387695, "val_acc": 48.0}
{"epoch": 12, "training_loss": 191.9870314025879, "training_acc": 48.0, "val_loss": 448.42140869140627, "val_acc": 48.0}
{"epoch": 13, "training_loss": 331.0240490722656, "training_acc": 52.0, "val_loss": 495.7380889892578, "val_acc": 52.0}
{"epoch": 14, "training_loss": 306.39868896484376, "training_acc": 50.0, "val_loss": 279.79258117675784, "val_acc": 48.0}
{"epoch": 15, "training_loss": 220.72238647460938, "training_acc": 44.0, "val_loss": 122.43038391113281, "val_acc": 48.0}
{"epoch": 16, "training_loss": 67.36596069335937, "training_acc": 60.0, "val_loss": 31.98244152069092, "val_acc": 48.0}
{"epoch": 17, "training_loss": 119.29562835693359, "training_acc": 54.0, "val_loss": 353.52791259765627, "val_acc": 48.0}
{"epoch": 18, "training_loss": 181.15143737792968, "training_acc": 54.0, "val_loss": 141.5797607421875, "val_acc": 48.0}
{"epoch": 19, "training_loss": 178.8926171875, "training_acc": 46.0, "val_loss": 39.15925750732422, "val_acc": 52.0}
{"epoch": 20, "training_loss": 159.4208233642578, "training_acc": 48.0, "val_loss": 209.01920654296876, "val_acc": 52.0}
{"epoch": 21, "training_loss": 124.61190269470215, "training_acc": 52.0, "val_loss": 215.85822875976564, "val_acc": 52.0}
{"epoch": 22, "training_loss": 140.15573486328125, "training_acc": 60.0, "val_loss": 63.75404693603516, "val_acc": 52.0}
{"epoch": 23, "training_loss": 58.21878875732422, "training_acc": 58.0, "val_loss": 266.96080078125, "val_acc": 52.0}
{"epoch": 24, "training_loss": 214.92243041992188, "training_acc": 40.0, "val_loss": 294.5846533203125, "val_acc": 52.0}
{"epoch": 25, "training_loss": 177.78773780822755, "training_acc": 48.0, "val_loss": 93.6787680053711, "val_acc": 52.0}
{"epoch": 26, "training_loss": 92.92533782958985, "training_acc": 50.0, "val_loss": 178.31093688964845, "val_acc": 52.0}
{"epoch": 27, "training_loss": 88.71173583984375, "training_acc": 54.0, "val_loss": 79.1123989868164, "val_acc": 48.0}
{"epoch": 28, "training_loss": 166.41236877441406, "training_acc": 48.0, "val_loss": 202.041513671875, "val_acc": 52.0}
{"epoch": 29, "training_loss": 86.12641021728516, "training_acc": 48.0, "val_loss": 9.731775817871094, "val_acc": 48.0}
{"epoch": 30, "training_loss": 117.31042129516601, "training_acc": 46.0, "val_loss": 117.88561645507812, "val_acc": 52.0}
{"epoch": 31, "training_loss": 112.57884704589844, "training_acc": 58.0, "val_loss": 132.64249938964844, "val_acc": 48.0}
{"epoch": 32, "training_loss": 79.42938354492188, "training_acc": 54.0, "val_loss": 111.71561584472656, "val_acc": 52.0}
{"epoch": 33, "training_loss": 192.88807189941406, "training_acc": 50.0, "val_loss": 224.27200256347658, "val_acc": 48.0}
{"epoch": 34, "training_loss": 159.66882873535155, "training_acc": 46.0, "val_loss": 236.8811828613281, "val_acc": 48.0}
{"epoch": 35, "training_loss": 211.95700012207033, "training_acc": 46.0, "val_loss": 162.0591827392578, "val_acc": 48.0}
{"epoch": 36, "training_loss": 92.50113845825196, "training_acc": 56.0, "val_loss": 30.719051208496094, "val_acc": 48.0}
{"epoch": 37, "training_loss": 68.8160595703125, "training_acc": 48.0, "val_loss": 68.34282653808594, "val_acc": 52.0}
{"epoch": 38, "training_loss": 83.9457551574707, "training_acc": 54.0, "val_loss": 123.88126220703126, "val_acc": 48.0}
{"epoch": 39, "training_loss": 146.06920455932618, "training_acc": 42.0, "val_loss": 207.70989685058595, "val_acc": 48.0}
{"epoch": 40, "training_loss": 123.5890771484375, "training_acc": 48.0, "val_loss": 144.02542907714843, "val_acc": 48.0}
{"epoch": 41, "training_loss": 64.07186431884766, "training_acc": 54.0, "val_loss": 47.23491355895996, "val_acc": 48.0}
{"epoch": 42, "training_loss": 38.786710510253904, "training_acc": 52.0, "val_loss": 11.485052375793456, "val_acc": 52.0}
{"epoch": 43, "training_loss": 54.72251724243164, "training_acc": 48.0, "val_loss": 148.22827758789063, "val_acc": 48.0}
{"epoch": 44, "training_loss": 107.54878540039063, "training_acc": 50.0, "val_loss": 73.29849853515626, "val_acc": 48.0}
{"epoch": 45, "training_loss": 75.42495807647705, "training_acc": 53.0, "val_loss": 85.51649078369141, "val_acc": 52.0}
{"epoch": 46, "training_loss": 94.48894409179688, "training_acc": 42.0, "val_loss": 178.0640249633789, "val_acc": 48.0}
{"epoch": 47, "training_loss": 193.0080010986328, "training_acc": 46.0, "val_loss": 8.852971076965332, "val_acc": 52.0}
{"epoch": 48, "training_loss": 94.12527725219726, "training_acc": 54.0, "val_loss": 38.65740348815918, "val_acc": 48.0}
{"epoch": 49, "training_loss": 116.27607299804687, "training_acc": 46.0, "val_loss": 5.573376873731613, "val_acc": 60.0}
{"epoch": 50, "training_loss": 83.49259641647339, "training_acc": 56.0, "val_loss": 110.68206207275391, "val_acc": 52.0}
{"epoch": 51, "training_loss": 114.31492126464843, "training_acc": 60.0, "val_loss": 193.1430142211914, "val_acc": 48.0}
{"epoch": 52, "training_loss": 52.10879261016846, "training_acc": 57.0, "val_loss": 11.550195617675781, "val_acc": 48.0}
{"epoch": 53, "training_loss": 55.93037071228027, "training_acc": 42.0, "val_loss": 11.473062782287597, "val_acc": 52.0}
{"epoch": 54, "training_loss": 56.43387634277344, "training_acc": 44.0, "val_loss": 142.6010107421875, "val_acc": 52.0}
{"epoch": 55, "training_loss": 192.44692749023437, "training_acc": 46.0, "val_loss": 226.54219543457032, "val_acc": 48.0}
{"epoch": 56, "training_loss": 279.46071823120116, "training_acc": 52.0, "val_loss": 83.80778106689453, "val_acc": 48.0}
{"epoch": 57, "training_loss": 121.20437522888183, "training_acc": 47.0, "val_loss": 148.30825073242187, "val_acc": 48.0}
{"epoch": 58, "training_loss": 121.831396484375, "training_acc": 46.0, "val_loss": 173.2763592529297, "val_acc": 48.0}
{"epoch": 59, "training_loss": 92.32306701660156, "training_acc": 50.0, "val_loss": 126.37989410400391, "val_acc": 48.0}
{"epoch": 60, "training_loss": 42.375589294433595, "training_acc": 49.0, "val_loss": 138.50181274414064, "val_acc": 52.0}
{"epoch": 61, "training_loss": 137.51695922851562, "training_acc": 42.0, "val_loss": 152.16133178710936, "val_acc": 52.0}
{"epoch": 62, "training_loss": 91.15184692382813, "training_acc": 52.0, "val_loss": 337.65365234375, "val_acc": 52.0}
{"epoch": 63, "training_loss": 280.77290771484377, "training_acc": 46.0, "val_loss": 122.95494384765625, "val_acc": 48.0}
{"epoch": 64, "training_loss": 124.2396484375, "training_acc": 54.0, "val_loss": 171.46001220703124, "val_acc": 48.0}
{"epoch": 65, "training_loss": 124.44517669677734, "training_acc": 45.0, "val_loss": 62.173683166503906, "val_acc": 52.0}
{"epoch": 66, "training_loss": 92.75627075195312, "training_acc": 48.0, "val_loss": 149.2344140625, "val_acc": 52.0}
{"epoch": 67, "training_loss": 138.05995498657228, "training_acc": 56.0, "val_loss": 189.86919067382811, "val_acc": 52.0}
{"epoch": 68, "training_loss": 119.56031982421875, "training_acc": 50.0, "val_loss": 19.89921447753906, "val_acc": 52.0}
