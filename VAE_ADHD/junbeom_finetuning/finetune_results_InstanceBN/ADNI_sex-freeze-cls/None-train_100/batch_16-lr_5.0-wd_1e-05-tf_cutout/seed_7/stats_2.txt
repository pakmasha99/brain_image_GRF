"main_modify.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 7 --task ADNI_sex --input_option yAware --learning_rate 5e0 --batch_size 16 --weight_decay 1e-5 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 529.7473569107055, "training_acc": 52.0, "val_loss": 217.72208129882813, "val_acc": 52.0}
{"epoch": 1, "training_loss": 299.34223022460935, "training_acc": 58.0, "val_loss": 656.7730981445312, "val_acc": 48.0}
{"epoch": 2, "training_loss": 419.560302734375, "training_acc": 56.0, "val_loss": 724.1246826171875, "val_acc": 52.0}
{"epoch": 3, "training_loss": 473.2523388671875, "training_acc": 48.0, "val_loss": 323.3945556640625, "val_acc": 48.0}
{"epoch": 4, "training_loss": 267.14581115722655, "training_acc": 46.0, "val_loss": 307.1334069824219, "val_acc": 48.0}
{"epoch": 5, "training_loss": 343.01136962890627, "training_acc": 48.0, "val_loss": 425.9312487792969, "val_acc": 52.0}
{"epoch": 6, "training_loss": 304.5292663574219, "training_acc": 50.0, "val_loss": 159.473994140625, "val_acc": 48.0}
{"epoch": 7, "training_loss": 125.23772720336915, "training_acc": 54.0, "val_loss": 348.81476623535156, "val_acc": 48.0}
{"epoch": 8, "training_loss": 233.3290222167969, "training_acc": 38.0, "val_loss": 276.5635333251953, "val_acc": 48.0}
{"epoch": 9, "training_loss": 169.3713066101074, "training_acc": 48.0, "val_loss": 17.442139930725098, "val_acc": 52.0}
{"epoch": 10, "training_loss": 48.96751041412354, "training_acc": 40.0, "val_loss": 178.40882263183593, "val_acc": 48.0}
{"epoch": 11, "training_loss": 92.46481567382813, "training_acc": 52.0, "val_loss": 25.33130485534668, "val_acc": 52.0}
{"epoch": 12, "training_loss": 40.44590553283692, "training_acc": 54.0, "val_loss": 66.28592834472656, "val_acc": 52.0}
{"epoch": 13, "training_loss": 106.92756927490234, "training_acc": 48.0, "val_loss": 360.5796643066406, "val_acc": 52.0}
{"epoch": 14, "training_loss": 278.7505596923828, "training_acc": 48.0, "val_loss": 73.60240203857421, "val_acc": 48.0}
{"epoch": 15, "training_loss": 148.64857833862305, "training_acc": 50.0, "val_loss": 295.2960244750977, "val_acc": 48.0}
{"epoch": 16, "training_loss": 137.40893737792967, "training_acc": 46.0, "val_loss": 58.537233428955076, "val_acc": 52.0}
{"epoch": 17, "training_loss": 159.0658171081543, "training_acc": 38.0, "val_loss": 56.8493310546875, "val_acc": 52.0}
{"epoch": 18, "training_loss": 129.4494659423828, "training_acc": 48.0, "val_loss": 301.4890783691406, "val_acc": 52.0}
{"epoch": 19, "training_loss": 287.67923828125, "training_acc": 44.0, "val_loss": 252.99778198242188, "val_acc": 48.0}
{"epoch": 20, "training_loss": 260.2103002929687, "training_acc": 54.0, "val_loss": 48.324460906982424, "val_acc": 48.0}
{"epoch": 21, "training_loss": 131.36076599121094, "training_acc": 50.0, "val_loss": 11.20620174407959, "val_acc": 48.0}
{"epoch": 22, "training_loss": 101.27889953613281, "training_acc": 48.0, "val_loss": 91.77533752441406, "val_acc": 48.0}
{"epoch": 23, "training_loss": 107.43131256103516, "training_acc": 44.0, "val_loss": 139.7025631713867, "val_acc": 48.0}
{"epoch": 24, "training_loss": 195.25784362792967, "training_acc": 44.0, "val_loss": 125.95210266113281, "val_acc": 48.0}
{"epoch": 25, "training_loss": 48.89242256641388, "training_acc": 51.0, "val_loss": 63.11315185546875, "val_acc": 52.0}
{"epoch": 26, "training_loss": 53.70432689666748, "training_acc": 58.0, "val_loss": 37.0109748840332, "val_acc": 52.0}
{"epoch": 27, "training_loss": 181.39757934570312, "training_acc": 46.0, "val_loss": 233.51859497070313, "val_acc": 52.0}
{"epoch": 28, "training_loss": 115.81505363464356, "training_acc": 54.0, "val_loss": 315.1496862792969, "val_acc": 52.0}
{"epoch": 29, "training_loss": 234.15893798828125, "training_acc": 48.0, "val_loss": 168.2374688720703, "val_acc": 48.0}
{"epoch": 30, "training_loss": 153.47595581054688, "training_acc": 48.0, "val_loss": 235.29317199707032, "val_acc": 48.0}
{"epoch": 31, "training_loss": 148.48429275512694, "training_acc": 58.0, "val_loss": 7.072495231628418, "val_acc": 48.0}
{"epoch": 32, "training_loss": 34.48673146247864, "training_acc": 63.0, "val_loss": 69.39362823486329, "val_acc": 52.0}
{"epoch": 33, "training_loss": 72.19050888061524, "training_acc": 44.0, "val_loss": 32.8031184387207, "val_acc": 52.0}
{"epoch": 34, "training_loss": 69.19696914672852, "training_acc": 46.0, "val_loss": 153.80532470703125, "val_acc": 48.0}
{"epoch": 35, "training_loss": 155.88283142089844, "training_acc": 48.0, "val_loss": 246.74992553710936, "val_acc": 48.0}
{"epoch": 36, "training_loss": 139.46917228698732, "training_acc": 48.0, "val_loss": 163.85657257080078, "val_acc": 48.0}
{"epoch": 37, "training_loss": 67.01143402099609, "training_acc": 48.0, "val_loss": 192.00177673339843, "val_acc": 52.0}
{"epoch": 38, "training_loss": 168.37747650146486, "training_acc": 52.0, "val_loss": 68.3684994506836, "val_acc": 52.0}
{"epoch": 39, "training_loss": 99.48470447540284, "training_acc": 54.0, "val_loss": 193.47948852539062, "val_acc": 52.0}
{"epoch": 40, "training_loss": 245.92568359375, "training_acc": 50.0, "val_loss": 443.62658203125, "val_acc": 48.0}
{"epoch": 41, "training_loss": 207.10742942810057, "training_acc": 50.0, "val_loss": 184.99499877929688, "val_acc": 48.0}
{"epoch": 42, "training_loss": 181.42197265625, "training_acc": 52.0, "val_loss": 116.26253723144531, "val_acc": 52.0}
{"epoch": 43, "training_loss": 147.36435913085938, "training_acc": 50.0, "val_loss": 51.15877899169922, "val_acc": 52.0}
{"epoch": 44, "training_loss": 57.87422088623047, "training_acc": 52.0, "val_loss": 23.14759811401367, "val_acc": 52.0}
{"epoch": 45, "training_loss": 76.66485244750976, "training_acc": 52.0, "val_loss": 159.70727111816407, "val_acc": 52.0}
{"epoch": 46, "training_loss": 79.9810870361328, "training_acc": 46.0, "val_loss": 193.19184204101563, "val_acc": 48.0}
{"epoch": 47, "training_loss": 114.08110303878784, "training_acc": 58.0, "val_loss": 57.303053283691405, "val_acc": 48.0}
{"epoch": 48, "training_loss": 82.03333709716797, "training_acc": 46.0, "val_loss": 158.42089294433595, "val_acc": 52.0}
{"epoch": 49, "training_loss": 82.89137126922607, "training_acc": 54.0, "val_loss": 37.548621063232424, "val_acc": 52.0}
{"epoch": 50, "training_loss": 106.72927124023437, "training_acc": 48.0, "val_loss": 80.3558773803711, "val_acc": 48.0}
