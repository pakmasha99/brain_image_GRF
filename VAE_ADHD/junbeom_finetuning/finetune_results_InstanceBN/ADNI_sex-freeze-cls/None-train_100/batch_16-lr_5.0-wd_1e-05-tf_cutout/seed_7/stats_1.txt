"main_modify.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 7 --task ADNI_sex --input_option yAware --learning_rate 5e0 --batch_size 16 --weight_decay 1e-5 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 536.6958420562744, "training_acc": 55.0, "val_loss": 69.7337092590332, "val_acc": 48.0}
{"epoch": 1, "training_loss": 420.6909130859375, "training_acc": 51.0, "val_loss": 485.610419921875, "val_acc": 48.0}
{"epoch": 2, "training_loss": 394.6759045410156, "training_acc": 47.0, "val_loss": 461.4955480957031, "val_acc": 52.0}
{"epoch": 3, "training_loss": 195.7412481689453, "training_acc": 53.0, "val_loss": 67.24771545410157, "val_acc": 52.0}
{"epoch": 4, "training_loss": 63.855506134033206, "training_acc": 47.0, "val_loss": 338.28642517089844, "val_acc": 48.0}
{"epoch": 5, "training_loss": 284.9044519042969, "training_acc": 47.0, "val_loss": 291.7695324707031, "val_acc": 52.0}
{"epoch": 6, "training_loss": 372.6293359375, "training_acc": 47.0, "val_loss": 128.45543762207032, "val_acc": 48.0}
{"epoch": 7, "training_loss": 337.9274849700928, "training_acc": 45.0, "val_loss": 326.0235607910156, "val_acc": 48.0}
{"epoch": 8, "training_loss": 420.1355777740479, "training_acc": 51.0, "val_loss": 186.59991638183592, "val_acc": 52.0}
{"epoch": 9, "training_loss": 179.9835302734375, "training_acc": 53.0, "val_loss": 176.41384643554687, "val_acc": 48.0}
{"epoch": 10, "training_loss": 97.27846313476563, "training_acc": 47.0, "val_loss": 193.52394836425782, "val_acc": 52.0}
{"epoch": 11, "training_loss": 258.4730322265625, "training_acc": 41.0, "val_loss": 55.57902328491211, "val_acc": 48.0}
{"epoch": 12, "training_loss": 396.23282760620117, "training_acc": 43.0, "val_loss": 213.3927197265625, "val_acc": 48.0}
{"epoch": 13, "training_loss": 280.71735717773436, "training_acc": 47.0, "val_loss": 180.17232482910157, "val_acc": 52.0}
{"epoch": 14, "training_loss": 176.3475469970703, "training_acc": 45.0, "val_loss": 163.5668096923828, "val_acc": 52.0}
{"epoch": 15, "training_loss": 194.56447326660157, "training_acc": 49.0, "val_loss": 18.861791877746583, "val_acc": 52.0}
{"epoch": 16, "training_loss": 99.18429748535156, "training_acc": 53.0, "val_loss": 91.3346954345703, "val_acc": 48.0}
{"epoch": 17, "training_loss": 80.72620202064515, "training_acc": 51.0, "val_loss": 137.19787567138673, "val_acc": 52.0}
{"epoch": 18, "training_loss": 149.9224694824219, "training_acc": 57.0, "val_loss": 257.000771484375, "val_acc": 48.0}
{"epoch": 19, "training_loss": 351.25962783813475, "training_acc": 45.0, "val_loss": 40.14031227111816, "val_acc": 48.0}
{"epoch": 20, "training_loss": 187.87924224853515, "training_acc": 51.0, "val_loss": 89.63797576904297, "val_acc": 52.0}
{"epoch": 21, "training_loss": 39.47602554321289, "training_acc": 53.0, "val_loss": 50.3159748840332, "val_acc": 52.0}
{"epoch": 22, "training_loss": 63.175788192749025, "training_acc": 45.0, "val_loss": 32.61116676330566, "val_acc": 52.0}
{"epoch": 23, "training_loss": 117.26872100830079, "training_acc": 59.0, "val_loss": 356.1343151855469, "val_acc": 52.0}
{"epoch": 24, "training_loss": 265.074765625, "training_acc": 49.0, "val_loss": 160.05589965820312, "val_acc": 48.0}
{"epoch": 25, "training_loss": 124.921396484375, "training_acc": 53.0, "val_loss": 312.3967541503906, "val_acc": 48.0}
{"epoch": 26, "training_loss": 254.48819030761717, "training_acc": 47.0, "val_loss": 127.05701965332031, "val_acc": 52.0}
{"epoch": 27, "training_loss": 136.9330792236328, "training_acc": 49.0, "val_loss": 160.23680419921874, "val_acc": 52.0}
{"epoch": 28, "training_loss": 226.70065107345582, "training_acc": 45.0, "val_loss": 118.0842333984375, "val_acc": 52.0}
{"epoch": 29, "training_loss": 112.44948028564453, "training_acc": 55.0, "val_loss": 189.92783325195313, "val_acc": 52.0}
{"epoch": 30, "training_loss": 225.43026336669922, "training_acc": 53.0, "val_loss": 348.3897412109375, "val_acc": 48.0}
{"epoch": 31, "training_loss": 235.68318664550782, "training_acc": 53.0, "val_loss": 353.36575988769533, "val_acc": 52.0}
{"epoch": 32, "training_loss": 176.060446395874, "training_acc": 41.0, "val_loss": 222.93796020507813, "val_acc": 52.0}
{"epoch": 33, "training_loss": 202.90492126464844, "training_acc": 55.0, "val_loss": 209.94924926757812, "val_acc": 48.0}
{"epoch": 34, "training_loss": 165.42010600483044, "training_acc": 57.0, "val_loss": 163.70816772460938, "val_acc": 48.0}
