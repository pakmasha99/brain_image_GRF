"main_modify.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_sex --input_option yAware --learning_rate 1e2 --batch_size 16 --weight_decay 1e-3 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 6400.772369003296, "training_acc": 50.0, "val_loss": 7438.484375, "val_acc": 40.0}
{"epoch": 1, "training_loss": 7102.890234375, "training_acc": 50.0, "val_loss": 13662.1611328125, "val_acc": 60.0}
{"epoch": 2, "training_loss": 16941.10185546875, "training_acc": 50.0, "val_loss": 9378.529296875, "val_acc": 60.0}
{"epoch": 3, "training_loss": 9586.88076171875, "training_acc": 50.0, "val_loss": 6686.61083984375, "val_acc": 40.0}
{"epoch": 4, "training_loss": 6675.081640625, "training_acc": 50.0, "val_loss": 15352.765625, "val_acc": 40.0}
{"epoch": 5, "training_loss": 12321.0609375, "training_acc": 50.0, "val_loss": 7348.8955078125, "val_acc": 40.0}
{"epoch": 6, "training_loss": 5068.871240234375, "training_acc": 50.0, "val_loss": 3938.6015625, "val_acc": 60.0}
{"epoch": 7, "training_loss": 5143.5671875, "training_acc": 50.0, "val_loss": 3864.607421875, "val_acc": 60.0}
{"epoch": 8, "training_loss": 4141.614477539062, "training_acc": 50.0, "val_loss": 4416.05322265625, "val_acc": 40.0}
{"epoch": 9, "training_loss": 3879.044189453125, "training_acc": 50.0, "val_loss": 7776.75390625, "val_acc": 40.0}
{"epoch": 10, "training_loss": 6131.716015625, "training_acc": 50.0, "val_loss": 1406.97998046875, "val_acc": 40.0}
{"epoch": 11, "training_loss": 1748.258349609375, "training_acc": 50.0, "val_loss": 5347.35302734375, "val_acc": 60.0}
{"epoch": 12, "training_loss": 6698.9923828125, "training_acc": 50.0, "val_loss": 3762.770263671875, "val_acc": 60.0}
{"epoch": 13, "training_loss": 4273.382162475586, "training_acc": 50.0, "val_loss": 5148.40576171875, "val_acc": 40.0}
{"epoch": 14, "training_loss": 4484.572509765625, "training_acc": 50.0, "val_loss": 8186.39697265625, "val_acc": 40.0}
{"epoch": 15, "training_loss": 6373.1716796875, "training_acc": 50.0, "val_loss": 1245.7210693359375, "val_acc": 40.0}
{"epoch": 16, "training_loss": 1779.35859375, "training_acc": 50.0, "val_loss": 6338.8759765625, "val_acc": 60.0}
{"epoch": 17, "training_loss": 8033.348828125, "training_acc": 50.0, "val_loss": 5535.59716796875, "val_acc": 60.0}
{"epoch": 18, "training_loss": 6521.909643554687, "training_acc": 50.0, "val_loss": 1752.6326904296875, "val_acc": 40.0}
{"epoch": 19, "training_loss": 2180.32177734375, "training_acc": 50.0, "val_loss": 3687.341064453125, "val_acc": 40.0}
{"epoch": 20, "training_loss": 2772.1099212646486, "training_acc": 50.0, "val_loss": 2740.233154296875, "val_acc": 60.0}
{"epoch": 21, "training_loss": 3512.805224609375, "training_acc": 50.0, "val_loss": 3349.332763671875, "val_acc": 60.0}
{"epoch": 22, "training_loss": 3729.9371337890625, "training_acc": 50.0, "val_loss": 2465.920654296875, "val_acc": 40.0}
{"epoch": 23, "training_loss": 2188.0682373046875, "training_acc": 50.0, "val_loss": 4338.45556640625, "val_acc": 40.0}
{"epoch": 24, "training_loss": 3222.337109375, "training_acc": 50.0, "val_loss": 1551.9761962890625, "val_acc": 60.0}
{"epoch": 25, "training_loss": 2043.2686279296875, "training_acc": 50.0, "val_loss": 2348.937744140625, "val_acc": 60.0}
{"epoch": 26, "training_loss": 2507.3013916015625, "training_acc": 50.0, "val_loss": 3621.497802734375, "val_acc": 40.0}
{"epoch": 27, "training_loss": 3290.5345703125, "training_acc": 50.0, "val_loss": 4357.00927734375, "val_acc": 40.0}
{"epoch": 28, "training_loss": 2694.68447265625, "training_acc": 50.0, "val_loss": 3641.375, "val_acc": 60.0}
{"epoch": 29, "training_loss": 5570.051953125, "training_acc": 50.0, "val_loss": 6356.39208984375, "val_acc": 60.0}
{"epoch": 30, "training_loss": 7482.16708984375, "training_acc": 50.0, "val_loss": 1284.6318359375, "val_acc": 60.0}
{"epoch": 31, "training_loss": 3372.9572265625, "training_acc": 30.0, "val_loss": 7231.50341796875, "val_acc": 40.0}
{"epoch": 32, "training_loss": 5878.8896484375, "training_acc": 50.0, "val_loss": 2694.751953125, "val_acc": 40.0}
{"epoch": 33, "training_loss": 1350.4455078125, "training_acc": 70.0, "val_loss": 4951.90234375, "val_acc": 60.0}
{"epoch": 34, "training_loss": 6688.2060546875, "training_acc": 50.0, "val_loss": 5108.75, "val_acc": 60.0}
