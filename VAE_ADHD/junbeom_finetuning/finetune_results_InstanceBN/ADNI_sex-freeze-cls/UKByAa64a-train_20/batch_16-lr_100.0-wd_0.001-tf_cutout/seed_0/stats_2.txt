"main_modify.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_sex --input_option yAware --learning_rate 1e2 --batch_size 16 --weight_decay 1e-3 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 4025.0932359218596, "training_acc": 50.0, "val_loss": 3642.543701171875, "val_acc": 60.0}
{"epoch": 1, "training_loss": 6231.8908203125, "training_acc": 50.0, "val_loss": 21502.140625, "val_acc": 40.0}
{"epoch": 2, "training_loss": 17371.650390625, "training_acc": 50.0, "val_loss": 9603.9365234375, "val_acc": 40.0}
{"epoch": 3, "training_loss": 5751.281665039062, "training_acc": 60.0, "val_loss": 6405.48291015625, "val_acc": 60.0}
{"epoch": 4, "training_loss": 8641.9447265625, "training_acc": 50.0, "val_loss": 5775.57958984375, "val_acc": 60.0}
{"epoch": 5, "training_loss": 6091.254150390625, "training_acc": 50.0, "val_loss": 7007.96435546875, "val_acc": 40.0}
{"epoch": 6, "training_loss": 6157.80087890625, "training_acc": 50.0, "val_loss": 12676.4013671875, "val_acc": 40.0}
{"epoch": 7, "training_loss": 10350.50078125, "training_acc": 50.0, "val_loss": 6299.55712890625, "val_acc": 40.0}
{"epoch": 8, "training_loss": 4848.421911621093, "training_acc": 40.0, "val_loss": 1712.8037109375, "val_acc": 60.0}
{"epoch": 9, "training_loss": 2049.6514404296877, "training_acc": 50.0, "val_loss": 928.1273803710938, "val_acc": 40.0}
{"epoch": 10, "training_loss": 705.6365447998047, "training_acc": 50.0, "val_loss": 1190.0677490234375, "val_acc": 60.0}
{"epoch": 11, "training_loss": 1332.8582275390625, "training_acc": 50.0, "val_loss": 2322.900634765625, "val_acc": 40.0}
{"epoch": 12, "training_loss": 2106.96767578125, "training_acc": 50.0, "val_loss": 113.6436767578125, "val_acc": 60.0}
{"epoch": 13, "training_loss": 188.05191040039062, "training_acc": 50.0, "val_loss": 1428.0838623046875, "val_acc": 40.0}
{"epoch": 14, "training_loss": 1120.586669921875, "training_acc": 50.0, "val_loss": 1848.2811279296875, "val_acc": 60.0}
{"epoch": 15, "training_loss": 2340.6399169921874, "training_acc": 50.0, "val_loss": 1871.5765380859375, "val_acc": 60.0}
{"epoch": 16, "training_loss": 1899.2415710449218, "training_acc": 50.0, "val_loss": 685.9732666015625, "val_acc": 40.0}
{"epoch": 17, "training_loss": 919.3094970703125, "training_acc": 40.0, "val_loss": 85.71361541748047, "val_acc": 60.0}
{"epoch": 18, "training_loss": 663.521484375, "training_acc": 50.0, "val_loss": 4358.0185546875, "val_acc": 40.0}
{"epoch": 19, "training_loss": 3337.543115234375, "training_acc": 50.0, "val_loss": 952.08447265625, "val_acc": 60.0}
{"epoch": 20, "training_loss": 1257.7507934570312, "training_acc": 50.0, "val_loss": 1326.2254638671875, "val_acc": 60.0}
{"epoch": 21, "training_loss": 1744.227978515625, "training_acc": 40.0, "val_loss": 299.462158203125, "val_acc": 40.0}
{"epoch": 22, "training_loss": 647.2984130859375, "training_acc": 50.0, "val_loss": 2018.4305419921875, "val_acc": 60.0}
{"epoch": 23, "training_loss": 2301.8641693115233, "training_acc": 50.0, "val_loss": 2839.167236328125, "val_acc": 40.0}
{"epoch": 24, "training_loss": 2593.0728515625, "training_acc": 50.0, "val_loss": 963.8078002929688, "val_acc": 40.0}
{"epoch": 25, "training_loss": 1289.426806640625, "training_acc": 50.0, "val_loss": 3875.353271484375, "val_acc": 60.0}
{"epoch": 26, "training_loss": 4674.56083984375, "training_acc": 50.0, "val_loss": 1141.7728271484375, "val_acc": 60.0}
{"epoch": 27, "training_loss": 2232.306640625, "training_acc": 40.0, "val_loss": 5262.85791015625, "val_acc": 40.0}
{"epoch": 28, "training_loss": 4258.4380859375, "training_acc": 50.0, "val_loss": 1048.8616943359375, "val_acc": 40.0}
{"epoch": 29, "training_loss": 1780.06201171875, "training_acc": 40.0, "val_loss": 3275.201904296875, "val_acc": 60.0}
{"epoch": 30, "training_loss": 3900.873828125, "training_acc": 50.0, "val_loss": 8.674236297607422, "val_acc": 40.0}
{"epoch": 31, "training_loss": 80.92964477539063, "training_acc": 50.0, "val_loss": 1002.8143920898438, "val_acc": 60.0}
{"epoch": 32, "training_loss": 1138.1210571289062, "training_acc": 50.0, "val_loss": 1986.0015869140625, "val_acc": 40.0}
{"epoch": 33, "training_loss": 1691.7663818359374, "training_acc": 50.0, "val_loss": 10.42929458618164, "val_acc": 40.0}
{"epoch": 34, "training_loss": 341.36426162719727, "training_acc": 60.0, "val_loss": 4175.3603515625, "val_acc": 60.0}
{"epoch": 35, "training_loss": 5137.4119140625, "training_acc": 50.0, "val_loss": 1403.05029296875, "val_acc": 60.0}
{"epoch": 36, "training_loss": 1511.395166015625, "training_acc": 60.0, "val_loss": 7303.40478515625, "val_acc": 40.0}
{"epoch": 37, "training_loss": 6217.5958984375, "training_acc": 50.0, "val_loss": 6110.1103515625, "val_acc": 40.0}
{"epoch": 38, "training_loss": 3832.44921875, "training_acc": 50.0, "val_loss": 3782.925048828125, "val_acc": 60.0}
{"epoch": 39, "training_loss": 5491.0572265625, "training_acc": 50.0, "val_loss": 7910.6064453125, "val_acc": 60.0}
{"epoch": 40, "training_loss": 9566.436328125, "training_acc": 50.0, "val_loss": 3880.03759765625, "val_acc": 60.0}
{"epoch": 41, "training_loss": 4048.615380859375, "training_acc": 50.0, "val_loss": 4987.10107421875, "val_acc": 40.0}
{"epoch": 42, "training_loss": 4223.726220703125, "training_acc": 50.0, "val_loss": 5036.8759765625, "val_acc": 40.0}
{"epoch": 43, "training_loss": 3486.8505859375, "training_acc": 50.0, "val_loss": 2570.489501953125, "val_acc": 60.0}
{"epoch": 44, "training_loss": 3412.491015625, "training_acc": 50.0, "val_loss": 5104.55810546875, "val_acc": 60.0}
{"epoch": 45, "training_loss": 6073.0203125, "training_acc": 50.0, "val_loss": 1332.235595703125, "val_acc": 60.0}
{"epoch": 46, "training_loss": 1985.42451171875, "training_acc": 50.0, "val_loss": 6917.72509765625, "val_acc": 40.0}
{"epoch": 47, "training_loss": 5738.620849609375, "training_acc": 50.0, "val_loss": 5070.181640625, "val_acc": 40.0}
{"epoch": 48, "training_loss": 3558.1186279296876, "training_acc": 50.0, "val_loss": 3201.84130859375, "val_acc": 60.0}
{"epoch": 49, "training_loss": 4452.46865234375, "training_acc": 50.0, "val_loss": 5036.6552734375, "val_acc": 60.0}
