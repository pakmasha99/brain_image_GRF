"main_modify.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_sex --input_option yAware --learning_rate 1e2 --batch_size 16 --weight_decay 1e-3 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 3031.5383569717405, "training_acc": 45.0, "val_loss": 424.3272399902344, "val_acc": 60.0}
{"epoch": 1, "training_loss": 522.7837890625, "training_acc": 50.0, "val_loss": 133.11814880371094, "val_acc": 60.0}
{"epoch": 2, "training_loss": 1865.8950927734375, "training_acc": 40.0, "val_loss": 4023.173583984375, "val_acc": 40.0}
{"epoch": 3, "training_loss": 4645.2025390625, "training_acc": 30.0, "val_loss": 1611.9404296875, "val_acc": 60.0}
{"epoch": 4, "training_loss": 1996.593017578125, "training_acc": 50.0, "val_loss": 2983.36669921875, "val_acc": 40.0}
{"epoch": 5, "training_loss": 2082.4235656738283, "training_acc": 50.0, "val_loss": 3101.54150390625, "val_acc": 60.0}
{"epoch": 6, "training_loss": 4106.43896484375, "training_acc": 50.0, "val_loss": 2800.332763671875, "val_acc": 60.0}
{"epoch": 7, "training_loss": 2462.7001293182375, "training_acc": 50.0, "val_loss": 5111.22802734375, "val_acc": 40.0}
{"epoch": 8, "training_loss": 4378.24619140625, "training_acc": 50.0, "val_loss": 5919.9150390625, "val_acc": 40.0}
{"epoch": 9, "training_loss": 4199.57880859375, "training_acc": 50.0, "val_loss": 2370.072998046875, "val_acc": 60.0}
{"epoch": 10, "training_loss": 3487.4626953125, "training_acc": 50.0, "val_loss": 4496.67333984375, "val_acc": 60.0}
{"epoch": 11, "training_loss": 5163.010888671875, "training_acc": 50.0, "val_loss": 956.9562377929688, "val_acc": 40.0}
{"epoch": 12, "training_loss": 936.21513671875, "training_acc": 50.0, "val_loss": 2903.33447265625, "val_acc": 40.0}
{"epoch": 13, "training_loss": 2021.694677734375, "training_acc": 50.0, "val_loss": 2631.669921875, "val_acc": 60.0}
{"epoch": 14, "training_loss": 3383.447802734375, "training_acc": 50.0, "val_loss": 3196.424560546875, "val_acc": 60.0}
{"epoch": 15, "training_loss": 3725.1513671875, "training_acc": 50.0, "val_loss": 2573.311767578125, "val_acc": 40.0}
{"epoch": 16, "training_loss": 2354.7501953125, "training_acc": 50.0, "val_loss": 2364.108154296875, "val_acc": 40.0}
{"epoch": 17, "training_loss": 1814.821240234375, "training_acc": 50.0, "val_loss": 1590.8592529296875, "val_acc": 60.0}
{"epoch": 18, "training_loss": 1982.1642578125, "training_acc": 50.0, "val_loss": 1820.8717041015625, "val_acc": 40.0}
{"epoch": 19, "training_loss": 1416.0398681640625, "training_acc": 50.0, "val_loss": 1256.482666015625, "val_acc": 60.0}
{"epoch": 20, "training_loss": 1617.21357421875, "training_acc": 50.0, "val_loss": 89.30608367919922, "val_acc": 40.0}
{"epoch": 21, "training_loss": 106.33093872070313, "training_acc": 50.0, "val_loss": 1790.803955078125, "val_acc": 40.0}
{"epoch": 22, "training_loss": 1423.25224609375, "training_acc": 50.0, "val_loss": 1596.775390625, "val_acc": 60.0}
{"epoch": 23, "training_loss": 2165.8451171875, "training_acc": 50.0, "val_loss": 1216.3543701171875, "val_acc": 60.0}
{"epoch": 24, "training_loss": 1953.92919921875, "training_acc": 40.0, "val_loss": 2439.352783203125, "val_acc": 40.0}
{"epoch": 25, "training_loss": 1879.135791015625, "training_acc": 40.0, "val_loss": 922.7191772460938, "val_acc": 40.0}
{"epoch": 26, "training_loss": 870.8688720703125, "training_acc": 40.0, "val_loss": 1285.8511962890625, "val_acc": 40.0}
{"epoch": 27, "training_loss": 1080.089990234375, "training_acc": 50.0, "val_loss": 2156.080322265625, "val_acc": 60.0}
{"epoch": 28, "training_loss": 3194.0193359375, "training_acc": 50.0, "val_loss": 2289.103515625, "val_acc": 60.0}
{"epoch": 29, "training_loss": 2777.4983154296874, "training_acc": 40.0, "val_loss": 1277.1697998046875, "val_acc": 40.0}
{"epoch": 30, "training_loss": 944.6602600097656, "training_acc": 50.0, "val_loss": 22.182296752929688, "val_acc": 60.0}
{"epoch": 31, "training_loss": 766.4588806152344, "training_acc": 40.0, "val_loss": 2236.39111328125, "val_acc": 40.0}
{"epoch": 32, "training_loss": 1612.89990234375, "training_acc": 50.0, "val_loss": 776.5648803710938, "val_acc": 60.0}
{"epoch": 33, "training_loss": 1119.946337890625, "training_acc": 40.0, "val_loss": 280.97174072265625, "val_acc": 60.0}
{"epoch": 34, "training_loss": 265.80274200439453, "training_acc": 60.0, "val_loss": 174.474853515625, "val_acc": 60.0}
{"epoch": 35, "training_loss": 645.2252685546875, "training_acc": 40.0, "val_loss": 217.06040954589844, "val_acc": 40.0}
{"epoch": 36, "training_loss": 721.9607421875, "training_acc": 50.0, "val_loss": 2894.233642578125, "val_acc": 60.0}
{"epoch": 37, "training_loss": 3288.0771484375, "training_acc": 50.0, "val_loss": 1570.1832275390625, "val_acc": 40.0}
{"epoch": 38, "training_loss": 1449.5360595703125, "training_acc": 50.0, "val_loss": 3354.159423828125, "val_acc": 40.0}
{"epoch": 39, "training_loss": 2322.6305908203126, "training_acc": 50.0, "val_loss": 2439.045166015625, "val_acc": 60.0}
{"epoch": 40, "training_loss": 3419.0263671875, "training_acc": 50.0, "val_loss": 3609.919189453125, "val_acc": 60.0}
{"epoch": 41, "training_loss": 3866.3248046875, "training_acc": 50.0, "val_loss": 2957.568603515625, "val_acc": 40.0}
{"epoch": 42, "training_loss": 2943.2955078125, "training_acc": 50.0, "val_loss": 5923.45263671875, "val_acc": 40.0}
{"epoch": 43, "training_loss": 4732.878393554687, "training_acc": 50.0, "val_loss": 227.44261169433594, "val_acc": 60.0}
{"epoch": 44, "training_loss": 607.9716552734375, "training_acc": 50.0, "val_loss": 556.5748901367188, "val_acc": 40.0}
{"epoch": 45, "training_loss": 425.4564636230469, "training_acc": 50.0, "val_loss": 1444.0125732421875, "val_acc": 60.0}
{"epoch": 46, "training_loss": 1965.3166015625, "training_acc": 50.0, "val_loss": 1474.24462890625, "val_acc": 40.0}
{"epoch": 47, "training_loss": 1463.9890625, "training_acc": 50.0, "val_loss": 1875.5301513671875, "val_acc": 40.0}
{"epoch": 48, "training_loss": 1184.7462951660157, "training_acc": 60.0, "val_loss": 1723.153564453125, "val_acc": 60.0}
{"epoch": 49, "training_loss": 2152.38984375, "training_acc": 50.0, "val_loss": 370.7852478027344, "val_acc": 40.0}
