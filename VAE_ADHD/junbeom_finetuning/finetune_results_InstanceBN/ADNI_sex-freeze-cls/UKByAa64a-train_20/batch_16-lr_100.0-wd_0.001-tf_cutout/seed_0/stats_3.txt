"main_modify.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_sex --input_option yAware --learning_rate 1e2 --batch_size 16 --weight_decay 1e-3 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 1199.858461856842, "training_acc": 60.0, "val_loss": 2001.203125, "val_acc": 60.0}
{"epoch": 1, "training_loss": 2006.6689910888672, "training_acc": 55.0, "val_loss": 1167.4488525390625, "val_acc": 60.0}
{"epoch": 2, "training_loss": 1002.2783203125, "training_acc": 65.0, "val_loss": 7753.30712890625, "val_acc": 40.0}
{"epoch": 3, "training_loss": 5266.0212890625, "training_acc": 55.0, "val_loss": 2783.054443359375, "val_acc": 60.0}
{"epoch": 4, "training_loss": 3978.63486328125, "training_acc": 45.0, "val_loss": 521.8603515625, "val_acc": 60.0}
{"epoch": 5, "training_loss": 1123.21318359375, "training_acc": 55.0, "val_loss": 11114.4599609375, "val_acc": 40.0}
{"epoch": 6, "training_loss": 8261.67890625, "training_acc": 55.0, "val_loss": 6992.6845703125, "val_acc": 40.0}
{"epoch": 7, "training_loss": 3744.47392578125, "training_acc": 55.0, "val_loss": 5936.8681640625, "val_acc": 60.0}
{"epoch": 8, "training_loss": 8508.50625, "training_acc": 45.0, "val_loss": 9520.1240234375, "val_acc": 60.0}
{"epoch": 9, "training_loss": 12575.8814453125, "training_acc": 45.0, "val_loss": 3507.572998046875, "val_acc": 60.0}
{"epoch": 10, "training_loss": 3758.717041015625, "training_acc": 55.0, "val_loss": 9262.798828125, "val_acc": 40.0}
{"epoch": 11, "training_loss": 7614.354296875, "training_acc": 55.0, "val_loss": 9835.4990234375, "val_acc": 40.0}
{"epoch": 12, "training_loss": 6927.493481445313, "training_acc": 55.0, "val_loss": 955.4403686523438, "val_acc": 60.0}
{"epoch": 13, "training_loss": 1709.96875, "training_acc": 45.0, "val_loss": 2238.542724609375, "val_acc": 60.0}
{"epoch": 14, "training_loss": 2528.325848388672, "training_acc": 45.0, "val_loss": 789.8497314453125, "val_acc": 40.0}
{"epoch": 15, "training_loss": 329.8173828125, "training_acc": 75.0, "val_loss": 857.2289428710938, "val_acc": 60.0}
{"epoch": 16, "training_loss": 1345.1935302734375, "training_acc": 35.0, "val_loss": 389.3074645996094, "val_acc": 60.0}
{"epoch": 17, "training_loss": 564.016455078125, "training_acc": 45.0, "val_loss": 403.6954040527344, "val_acc": 60.0}
{"epoch": 18, "training_loss": 627.0663696289063, "training_acc": 45.0, "val_loss": 38.36202621459961, "val_acc": 60.0}
{"epoch": 19, "training_loss": 569.4942443847656, "training_acc": 35.0, "val_loss": 205.3249053955078, "val_acc": 40.0}
{"epoch": 20, "training_loss": 1552.704052734375, "training_acc": 35.0, "val_loss": 2093.125732421875, "val_acc": 60.0}
{"epoch": 21, "training_loss": 2116.8886108398438, "training_acc": 55.0, "val_loss": 2190.519775390625, "val_acc": 40.0}
{"epoch": 22, "training_loss": 1561.98134765625, "training_acc": 55.0, "val_loss": 730.0093994140625, "val_acc": 60.0}
{"epoch": 23, "training_loss": 961.6868774414063, "training_acc": 45.0, "val_loss": 991.0443725585938, "val_acc": 40.0}
{"epoch": 24, "training_loss": 625.5899719238281, "training_acc": 55.0, "val_loss": 1765.458984375, "val_acc": 60.0}
{"epoch": 25, "training_loss": 2399.109375, "training_acc": 45.0, "val_loss": 69.5678482055664, "val_acc": 40.0}
{"epoch": 26, "training_loss": 38.13877158164978, "training_acc": 55.0, "val_loss": 811.2147827148438, "val_acc": 60.0}
{"epoch": 27, "training_loss": 979.3911071777344, "training_acc": 45.0, "val_loss": 342.9400329589844, "val_acc": 60.0}
{"epoch": 28, "training_loss": 836.35673828125, "training_acc": 35.0, "val_loss": 24.907766342163086, "val_acc": 60.0}
{"epoch": 29, "training_loss": 88.52925567626953, "training_acc": 55.0, "val_loss": 359.0352478027344, "val_acc": 40.0}
{"epoch": 30, "training_loss": 332.3790649414062, "training_acc": 65.0, "val_loss": 1716.1180419921875, "val_acc": 60.0}
{"epoch": 31, "training_loss": 1990.3249206542969, "training_acc": 45.0, "val_loss": 3982.835693359375, "val_acc": 40.0}
{"epoch": 32, "training_loss": 3255.1259765625, "training_acc": 55.0, "val_loss": 4482.59716796875, "val_acc": 40.0}
{"epoch": 33, "training_loss": 2795.7584594726563, "training_acc": 55.0, "val_loss": 2908.64697265625, "val_acc": 60.0}
{"epoch": 34, "training_loss": 4575.2482421875, "training_acc": 45.0, "val_loss": 3254.202880859375, "val_acc": 60.0}
{"epoch": 35, "training_loss": 3412.9295043945312, "training_acc": 45.0, "val_loss": 6733.67138671875, "val_acc": 40.0}
{"epoch": 36, "training_loss": 6166.8203125, "training_acc": 55.0, "val_loss": 11375.623046875, "val_acc": 40.0}
{"epoch": 37, "training_loss": 8263.447021484375, "training_acc": 55.0, "val_loss": 4512.103515625, "val_acc": 40.0}
{"epoch": 38, "training_loss": 2338.486364746094, "training_acc": 65.0, "val_loss": 3339.169677734375, "val_acc": 60.0}
{"epoch": 39, "training_loss": 4977.623828125, "training_acc": 45.0, "val_loss": 1520.84033203125, "val_acc": 60.0}
{"epoch": 40, "training_loss": 1820.846044921875, "training_acc": 55.0, "val_loss": 7735.53466796875, "val_acc": 40.0}
{"epoch": 41, "training_loss": 5857.718310546875, "training_acc": 55.0, "val_loss": 8002.74169921875, "val_acc": 40.0}
{"epoch": 42, "training_loss": 5983.236328125, "training_acc": 55.0, "val_loss": 906.2530517578125, "val_acc": 40.0}
{"epoch": 43, "training_loss": 1245.97861328125, "training_acc": 55.0, "val_loss": 4329.93359375, "val_acc": 60.0}
{"epoch": 44, "training_loss": 5771.7732421875, "training_acc": 45.0, "val_loss": 1317.02685546875, "val_acc": 60.0}
{"epoch": 45, "training_loss": 1614.2574951171875, "training_acc": 55.0, "val_loss": 7362.0048828125, "val_acc": 40.0}
{"epoch": 46, "training_loss": 5564.2921875, "training_acc": 55.0, "val_loss": 7053.90771484375, "val_acc": 40.0}
{"epoch": 47, "training_loss": 4983.7822265625, "training_acc": 55.0, "val_loss": 713.5885620117188, "val_acc": 60.0}
