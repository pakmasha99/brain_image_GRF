"main_modify.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 1 --task ADNI_sex --input_option yAware --learning_rate 1e2 --batch_size 16 --weight_decay 1e-3 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 6408.37742729187, "training_acc": 40.0, "val_loss": 9217.611328125, "val_acc": 40.0}
{"epoch": 1, "training_loss": 9509.8, "training_acc": 40.0, "val_loss": 9804.6669921875, "val_acc": 60.0}
{"epoch": 2, "training_loss": 12031.87802734375, "training_acc": 50.0, "val_loss": 4578.02099609375, "val_acc": 60.0}
{"epoch": 3, "training_loss": 4833.077734375, "training_acc": 50.0, "val_loss": 5138.162109375, "val_acc": 40.0}
{"epoch": 4, "training_loss": 4202.6859375, "training_acc": 50.0, "val_loss": 686.9937744140625, "val_acc": 40.0}
{"epoch": 5, "training_loss": 1413.60029296875, "training_acc": 50.0, "val_loss": 5417.93212890625, "val_acc": 60.0}
{"epoch": 6, "training_loss": 6599.8982421875, "training_acc": 50.0, "val_loss": 1157.353271484375, "val_acc": 60.0}
{"epoch": 7, "training_loss": 1487.280615234375, "training_acc": 60.0, "val_loss": 11031.6826171875, "val_acc": 40.0}
{"epoch": 8, "training_loss": 9500.948828125, "training_acc": 50.0, "val_loss": 11085.28515625, "val_acc": 40.0}
{"epoch": 9, "training_loss": 8554.7236328125, "training_acc": 50.0, "val_loss": 337.63360595703125, "val_acc": 40.0}
{"epoch": 10, "training_loss": 836.0255615234375, "training_acc": 60.0, "val_loss": 8788.90625, "val_acc": 60.0}
{"epoch": 11, "training_loss": 11152.32587890625, "training_acc": 50.0, "val_loss": 9813.6279296875, "val_acc": 60.0}
{"epoch": 12, "training_loss": 11561.391796875, "training_acc": 50.0, "val_loss": 3623.159423828125, "val_acc": 60.0}
{"epoch": 13, "training_loss": 2716.25625, "training_acc": 70.0, "val_loss": 9166.244140625, "val_acc": 40.0}
{"epoch": 14, "training_loss": 8255.9701171875, "training_acc": 50.0, "val_loss": 13043.3701171875, "val_acc": 40.0}
{"epoch": 15, "training_loss": 10670.3345703125, "training_acc": 50.0, "val_loss": 6261.7900390625, "val_acc": 40.0}
{"epoch": 16, "training_loss": 3774.044580078125, "training_acc": 50.0, "val_loss": 5466.77099609375, "val_acc": 60.0}
{"epoch": 17, "training_loss": 7692.42109375, "training_acc": 50.0, "val_loss": 10132.0615234375, "val_acc": 60.0}
{"epoch": 18, "training_loss": 12556.20810546875, "training_acc": 50.0, "val_loss": 7173.67529296875, "val_acc": 60.0}
{"epoch": 19, "training_loss": 8501.128076171875, "training_acc": 50.0, "val_loss": 1219.596923828125, "val_acc": 40.0}
{"epoch": 20, "training_loss": 1291.080419921875, "training_acc": 50.0, "val_loss": 6021.99609375, "val_acc": 40.0}
{"epoch": 21, "training_loss": 4850.2310546875, "training_acc": 50.0, "val_loss": 1064.4107666015625, "val_acc": 40.0}
{"epoch": 22, "training_loss": 1544.9091796875, "training_acc": 50.0, "val_loss": 5343.44091796875, "val_acc": 60.0}
{"epoch": 23, "training_loss": 6789.0919921875, "training_acc": 50.0, "val_loss": 3490.236083984375, "val_acc": 60.0}
{"epoch": 24, "training_loss": 3091.5404663085938, "training_acc": 50.0, "val_loss": 7612.9970703125, "val_acc": 40.0}
{"epoch": 25, "training_loss": 7567.274609375, "training_acc": 50.0, "val_loss": 12960.6142578125, "val_acc": 40.0}
{"epoch": 26, "training_loss": 10370.396484375, "training_acc": 50.0, "val_loss": 5674.25390625, "val_acc": 40.0}
{"epoch": 27, "training_loss": 4053.0818115234374, "training_acc": 50.0, "val_loss": 3875.194580078125, "val_acc": 60.0}
{"epoch": 28, "training_loss": 4933.2115234375, "training_acc": 50.0, "val_loss": 4505.38671875, "val_acc": 60.0}
{"epoch": 29, "training_loss": 5381.8984375, "training_acc": 50.0, "val_loss": 83.24413299560547, "val_acc": 40.0}
{"epoch": 30, "training_loss": 72.26890869140625, "training_acc": 50.0, "val_loss": 1566.1644287109375, "val_acc": 40.0}
{"epoch": 31, "training_loss": 1510.0243408203125, "training_acc": 30.0, "val_loss": 1797.1448974609375, "val_acc": 40.0}
{"epoch": 32, "training_loss": 1495.052978515625, "training_acc": 50.0, "val_loss": 351.83856201171875, "val_acc": 60.0}
{"epoch": 33, "training_loss": 410.94345703125, "training_acc": 50.0, "val_loss": 1898.4183349609375, "val_acc": 40.0}
{"epoch": 34, "training_loss": 1611.252734375, "training_acc": 50.0, "val_loss": 807.6242065429688, "val_acc": 60.0}
{"epoch": 35, "training_loss": 1117.319580078125, "training_acc": 50.0, "val_loss": 181.37266540527344, "val_acc": 60.0}
{"epoch": 36, "training_loss": 414.2489013671875, "training_acc": 60.0, "val_loss": 4935.2548828125, "val_acc": 40.0}
{"epoch": 37, "training_loss": 4005.84091796875, "training_acc": 50.0, "val_loss": 1193.1358642578125, "val_acc": 40.0}
{"epoch": 38, "training_loss": 1423.24951171875, "training_acc": 50.0, "val_loss": 3922.54296875, "val_acc": 60.0}
{"epoch": 39, "training_loss": 4824.5658203125, "training_acc": 50.0, "val_loss": 1633.505126953125, "val_acc": 60.0}
{"epoch": 40, "training_loss": 1610.427490234375, "training_acc": 60.0, "val_loss": 5189.1806640625, "val_acc": 40.0}
{"epoch": 41, "training_loss": 4347.884716796875, "training_acc": 50.0, "val_loss": 3869.54345703125, "val_acc": 40.0}
{"epoch": 42, "training_loss": 2918.2648231506346, "training_acc": 50.0, "val_loss": 3045.80126953125, "val_acc": 60.0}
{"epoch": 43, "training_loss": 4303.76796875, "training_acc": 50.0, "val_loss": 3163.81494140625, "val_acc": 60.0}
{"epoch": 44, "training_loss": 3590.629702758789, "training_acc": 50.0, "val_loss": 4627.3251953125, "val_acc": 40.0}
{"epoch": 45, "training_loss": 4228.783203125, "training_acc": 50.0, "val_loss": 6147.9453125, "val_acc": 40.0}
{"epoch": 46, "training_loss": 4638.69423828125, "training_acc": 50.0, "val_loss": 1308.7076416015625, "val_acc": 60.0}
{"epoch": 47, "training_loss": 2008.53056640625, "training_acc": 50.0, "val_loss": 2574.841064453125, "val_acc": 60.0}
{"epoch": 48, "training_loss": 2956.7605224609374, "training_acc": 50.0, "val_loss": 3031.172607421875, "val_acc": 40.0}
