"main_modify.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 1 --task ADNI_sex --input_option yAware --learning_rate 1e2 --batch_size 16 --weight_decay 1e-3 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 6414.222981023789, "training_acc": 55.0, "val_loss": 8578.7548828125, "val_acc": 40.0}
{"epoch": 1, "training_loss": 6792.131640625, "training_acc": 55.0, "val_loss": 11720.5205078125, "val_acc": 60.0}
{"epoch": 2, "training_loss": 15900.1064453125, "training_acc": 45.0, "val_loss": 6490.3330078125, "val_acc": 60.0}
{"epoch": 3, "training_loss": 6638.54111328125, "training_acc": 45.0, "val_loss": 11859.7373046875, "val_acc": 40.0}
{"epoch": 4, "training_loss": 8884.246875, "training_acc": 55.0, "val_loss": 22272.232421875, "val_acc": 40.0}
{"epoch": 5, "training_loss": 16646.9814453125, "training_acc": 55.0, "val_loss": 18529.58984375, "val_acc": 40.0}
{"epoch": 6, "training_loss": 12424.6646484375, "training_acc": 55.0, "val_loss": 3177.017578125, "val_acc": 40.0}
{"epoch": 7, "training_loss": 5113.3126953125, "training_acc": 35.0, "val_loss": 8338.1005859375, "val_acc": 60.0}
{"epoch": 8, "training_loss": 11680.037890625, "training_acc": 45.0, "val_loss": 6924.75, "val_acc": 60.0}
{"epoch": 9, "training_loss": 8566.730859375, "training_acc": 45.0, "val_loss": 2623.161865234375, "val_acc": 40.0}
{"epoch": 10, "training_loss": 2741.68291015625, "training_acc": 55.0, "val_loss": 8950.7412109375, "val_acc": 40.0}
{"epoch": 11, "training_loss": 6589.784765625, "training_acc": 55.0, "val_loss": 5063.73779296875, "val_acc": 40.0}
{"epoch": 12, "training_loss": 2971.875881958008, "training_acc": 55.0, "val_loss": 4298.20751953125, "val_acc": 60.0}
{"epoch": 13, "training_loss": 6131.44345703125, "training_acc": 45.0, "val_loss": 7091.5791015625, "val_acc": 60.0}
{"epoch": 14, "training_loss": 9372.7541015625, "training_acc": 45.0, "val_loss": 2931.821044921875, "val_acc": 60.0}
{"epoch": 15, "training_loss": 4315.3412109375, "training_acc": 35.0, "val_loss": 5761.8759765625, "val_acc": 40.0}
{"epoch": 16, "training_loss": 4735.012890625, "training_acc": 55.0, "val_loss": 3838.34228515625, "val_acc": 40.0}
{"epoch": 17, "training_loss": 2386.74033203125, "training_acc": 55.0, "val_loss": 2171.909912109375, "val_acc": 60.0}
{"epoch": 18, "training_loss": 2918.34453125, "training_acc": 45.0, "val_loss": 652.3378295898438, "val_acc": 60.0}
{"epoch": 19, "training_loss": 1585.508154296875, "training_acc": 35.0, "val_loss": 3612.2734375, "val_acc": 40.0}
{"epoch": 20, "training_loss": 2390.53232421875, "training_acc": 55.0, "val_loss": 1221.4617919921875, "val_acc": 60.0}
{"epoch": 21, "training_loss": 1915.0525390625, "training_acc": 45.0, "val_loss": 1626.9676513671875, "val_acc": 60.0}
{"epoch": 22, "training_loss": 1940.8194946289063, "training_acc": 45.0, "val_loss": 1444.5859375, "val_acc": 40.0}
{"epoch": 23, "training_loss": 887.9459075927734, "training_acc": 55.0, "val_loss": 1884.060791015625, "val_acc": 60.0}
{"epoch": 24, "training_loss": 2601.9238037109376, "training_acc": 45.0, "val_loss": 1288.0057373046875, "val_acc": 60.0}
{"epoch": 25, "training_loss": 1676.8656982421876, "training_acc": 45.0, "val_loss": 2242.521484375, "val_acc": 40.0}
{"epoch": 26, "training_loss": 1466.9495849609375, "training_acc": 55.0, "val_loss": 1708.1304931640625, "val_acc": 60.0}
{"epoch": 27, "training_loss": 2537.721484375, "training_acc": 45.0, "val_loss": 1651.5673828125, "val_acc": 60.0}
{"epoch": 28, "training_loss": 1716.43642578125, "training_acc": 55.0, "val_loss": 2676.28173828125, "val_acc": 40.0}
{"epoch": 29, "training_loss": 2009.113232421875, "training_acc": 55.0, "val_loss": 370.6365051269531, "val_acc": 60.0}
{"epoch": 30, "training_loss": 702.4482421875, "training_acc": 45.0, "val_loss": 1107.972900390625, "val_acc": 40.0}
{"epoch": 31, "training_loss": 978.407763671875, "training_acc": 55.0, "val_loss": 642.6813354492188, "val_acc": 60.0}
{"epoch": 32, "training_loss": 875.3383056640625, "training_acc": 45.0, "val_loss": 1134.4674072265625, "val_acc": 40.0}
{"epoch": 33, "training_loss": 824.8068908691406, "training_acc": 55.0, "val_loss": 280.6433410644531, "val_acc": 60.0}
{"epoch": 34, "training_loss": 606.1443359375, "training_acc": 35.0, "val_loss": 550.45947265625, "val_acc": 60.0}
{"epoch": 35, "training_loss": 635.35400390625, "training_acc": 45.0, "val_loss": 3172.2666015625, "val_acc": 40.0}
{"epoch": 36, "training_loss": 2454.4275146484374, "training_acc": 55.0, "val_loss": 3804.791748046875, "val_acc": 40.0}
{"epoch": 37, "training_loss": 2249.411181640625, "training_acc": 55.0, "val_loss": 2574.03515625, "val_acc": 60.0}
{"epoch": 38, "training_loss": 3986.70478515625, "training_acc": 45.0, "val_loss": 4522.69873046875, "val_acc": 60.0}
{"epoch": 39, "training_loss": 5644.4408203125, "training_acc": 45.0, "val_loss": 790.9573364257812, "val_acc": 40.0}
{"epoch": 40, "training_loss": 1378.8737548828126, "training_acc": 55.0, "val_loss": 3564.661376953125, "val_acc": 40.0}
{"epoch": 41, "training_loss": 2438.8728210449217, "training_acc": 55.0, "val_loss": 1699.088134765625, "val_acc": 60.0}
{"epoch": 42, "training_loss": 2553.81171875, "training_acc": 45.0, "val_loss": 662.7472534179688, "val_acc": 60.0}
{"epoch": 43, "training_loss": 938.0545654296875, "training_acc": 55.0, "val_loss": 6158.37060546875, "val_acc": 40.0}
{"epoch": 44, "training_loss": 4771.6041015625, "training_acc": 55.0, "val_loss": 3950.068359375, "val_acc": 40.0}
{"epoch": 45, "training_loss": 2001.948648071289, "training_acc": 65.0, "val_loss": 2144.91162109375, "val_acc": 60.0}
{"epoch": 46, "training_loss": 2948.36875, "training_acc": 45.0, "val_loss": 669.9580078125, "val_acc": 60.0}
{"epoch": 47, "training_loss": 1326.010498046875, "training_acc": 45.0, "val_loss": 5185.5625, "val_acc": 40.0}
{"epoch": 48, "training_loss": 3811.221875, "training_acc": 55.0, "val_loss": 1876.0162353515625, "val_acc": 40.0}
{"epoch": 49, "training_loss": 1965.426513671875, "training_acc": 45.0, "val_loss": 2523.126708984375, "val_acc": 60.0}
{"epoch": 50, "training_loss": 3101.92021484375, "training_acc": 45.0, "val_loss": 2250.699951171875, "val_acc": 40.0}
{"epoch": 51, "training_loss": 2301.21171875, "training_acc": 55.0, "val_loss": 3511.895263671875, "val_acc": 40.0}
{"epoch": 52, "training_loss": 2353.4134719848635, "training_acc": 55.0, "val_loss": 2625.80908203125, "val_acc": 60.0}
