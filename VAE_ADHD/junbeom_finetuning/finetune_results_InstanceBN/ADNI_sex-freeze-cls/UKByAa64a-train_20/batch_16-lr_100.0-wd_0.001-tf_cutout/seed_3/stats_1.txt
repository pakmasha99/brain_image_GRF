"main_modify.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 3 --task ADNI_sex --input_option yAware --learning_rate 1e2 --batch_size 16 --weight_decay 1e-3 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 4280.128260707856, "training_acc": 50.0, "val_loss": 5827.62109375, "val_acc": 60.0}
{"epoch": 1, "training_loss": 7754.01328125, "training_acc": 50.0, "val_loss": 17615.041015625, "val_acc": 40.0}
{"epoch": 2, "training_loss": 14260.7421875, "training_acc": 50.0, "val_loss": 6834.37890625, "val_acc": 40.0}
{"epoch": 3, "training_loss": 6320.9765625, "training_acc": 40.0, "val_loss": 5445.2861328125, "val_acc": 60.0}
{"epoch": 4, "training_loss": 6621.4388671875, "training_acc": 50.0, "val_loss": 1798.8489990234375, "val_acc": 60.0}
{"epoch": 5, "training_loss": 2524.994287109375, "training_acc": 50.0, "val_loss": 7304.765625, "val_acc": 40.0}
{"epoch": 6, "training_loss": 6029.3337890625, "training_acc": 50.0, "val_loss": 2304.62939453125, "val_acc": 40.0}
{"epoch": 7, "training_loss": 2311.1259765625, "training_acc": 50.0, "val_loss": 5229.04833984375, "val_acc": 60.0}
{"epoch": 8, "training_loss": 6589.9716796875, "training_acc": 50.0, "val_loss": 2864.601318359375, "val_acc": 60.0}
{"epoch": 9, "training_loss": 3150.010205078125, "training_acc": 50.0, "val_loss": 4583.7890625, "val_acc": 40.0}
{"epoch": 10, "training_loss": 3901.6220703125, "training_acc": 50.0, "val_loss": 1424.1083984375, "val_acc": 40.0}
{"epoch": 11, "training_loss": 2148.4009765625, "training_acc": 40.0, "val_loss": 3880.634521484375, "val_acc": 60.0}
{"epoch": 12, "training_loss": 4632.3552734375, "training_acc": 50.0, "val_loss": 799.6019897460938, "val_acc": 60.0}
{"epoch": 13, "training_loss": 1019.2050048828125, "training_acc": 60.0, "val_loss": 7274.41552734375, "val_acc": 40.0}
{"epoch": 14, "training_loss": 6247.290234375, "training_acc": 50.0, "val_loss": 5020.00439453125, "val_acc": 40.0}
{"epoch": 15, "training_loss": 2972.1904052734376, "training_acc": 50.0, "val_loss": 4961.1416015625, "val_acc": 60.0}
{"epoch": 16, "training_loss": 7807.5578125, "training_acc": 50.0, "val_loss": 7937.56201171875, "val_acc": 60.0}
{"epoch": 17, "training_loss": 9201.1224609375, "training_acc": 50.0, "val_loss": 2159.425537109375, "val_acc": 60.0}
{"epoch": 18, "training_loss": 2868.30400390625, "training_acc": 50.0, "val_loss": 8823.71875, "val_acc": 40.0}
{"epoch": 19, "training_loss": 7846.523046875, "training_acc": 50.0, "val_loss": 8925.24609375, "val_acc": 40.0}
{"epoch": 20, "training_loss": 7089.50869140625, "training_acc": 50.0, "val_loss": 284.70782470703125, "val_acc": 60.0}
{"epoch": 21, "training_loss": 776.5418212890625, "training_acc": 50.0, "val_loss": 2000.353515625, "val_acc": 60.0}
{"epoch": 22, "training_loss": 2140.3516845703125, "training_acc": 50.0, "val_loss": 3208.064453125, "val_acc": 40.0}
{"epoch": 23, "training_loss": 2935.15888671875, "training_acc": 50.0, "val_loss": 3669.322021484375, "val_acc": 40.0}
{"epoch": 24, "training_loss": 2790.1098724365233, "training_acc": 50.0, "val_loss": 2574.67041015625, "val_acc": 60.0}
{"epoch": 25, "training_loss": 3319.970166015625, "training_acc": 50.0, "val_loss": 3255.071044921875, "val_acc": 60.0}
{"epoch": 26, "training_loss": 3647.5509521484373, "training_acc": 50.0, "val_loss": 2108.496826171875, "val_acc": 40.0}
{"epoch": 27, "training_loss": 2074.428466796875, "training_acc": 50.0, "val_loss": 3271.37744140625, "val_acc": 40.0}
{"epoch": 28, "training_loss": 2476.2381828308107, "training_acc": 50.0, "val_loss": 2545.027099609375, "val_acc": 60.0}
{"epoch": 29, "training_loss": 3374.84140625, "training_acc": 50.0, "val_loss": 2526.62890625, "val_acc": 60.0}
{"epoch": 30, "training_loss": 2345.8198364257814, "training_acc": 50.0, "val_loss": 5559.765625, "val_acc": 40.0}
{"epoch": 31, "training_loss": 5495.483984375, "training_acc": 50.0, "val_loss": 8442.1865234375, "val_acc": 40.0}
{"epoch": 32, "training_loss": 6372.1365234375, "training_acc": 50.0, "val_loss": 89.67178344726562, "val_acc": 60.0}
{"epoch": 33, "training_loss": 350.06060180664065, "training_acc": 50.0, "val_loss": 2950.589111328125, "val_acc": 60.0}
{"epoch": 34, "training_loss": 3470.98740234375, "training_acc": 50.0, "val_loss": 501.1679382324219, "val_acc": 40.0}
{"epoch": 35, "training_loss": 524.0529663085938, "training_acc": 50.0, "val_loss": 1728.0718994140625, "val_acc": 40.0}
{"epoch": 36, "training_loss": 1240.6649780273438, "training_acc": 50.0, "val_loss": 229.7837677001953, "val_acc": 60.0}
{"epoch": 37, "training_loss": 1130.05947265625, "training_acc": 30.0, "val_loss": 680.751953125, "val_acc": 40.0}
{"epoch": 38, "training_loss": 978.07451171875, "training_acc": 50.0, "val_loss": 2875.303955078125, "val_acc": 60.0}
{"epoch": 39, "training_loss": 3376.48642578125, "training_acc": 50.0, "val_loss": 367.699462890625, "val_acc": 40.0}
{"epoch": 40, "training_loss": 462.856640625, "training_acc": 50.0, "val_loss": 65.9757080078125, "val_acc": 60.0}
{"epoch": 41, "training_loss": 105.56976318359375, "training_acc": 60.0, "val_loss": 0.0035963193513453007, "val_acc": 100.0}
{"epoch": 42, "training_loss": 16.08949546813965, "training_acc": 65.0, "val_loss": 2122.57568359375, "val_acc": 60.0}
{"epoch": 43, "training_loss": 2865.38330078125, "training_acc": 50.0, "val_loss": 928.7116088867188, "val_acc": 60.0}
{"epoch": 44, "training_loss": 694.3134765625, "training_acc": 70.0, "val_loss": 6285.65966796875, "val_acc": 40.0}
{"epoch": 45, "training_loss": 5379.3068359375, "training_acc": 50.0, "val_loss": 5279.07275390625, "val_acc": 40.0}
{"epoch": 46, "training_loss": 3736.968896484375, "training_acc": 50.0, "val_loss": 3091.67041015625, "val_acc": 60.0}
{"epoch": 47, "training_loss": 4066.707666015625, "training_acc": 50.0, "val_loss": 5486.34912109375, "val_acc": 60.0}
{"epoch": 48, "training_loss": 6554.9859375, "training_acc": 50.0, "val_loss": 1673.9361572265625, "val_acc": 60.0}
{"epoch": 49, "training_loss": 2240.5357421875, "training_acc": 50.0, "val_loss": 6376.7587890625, "val_acc": 40.0}
{"epoch": 50, "training_loss": 5448.8953125, "training_acc": 50.0, "val_loss": 3684.28515625, "val_acc": 40.0}
{"epoch": 51, "training_loss": 1848.1009765625, "training_acc": 70.0, "val_loss": 3440.306640625, "val_acc": 60.0}
{"epoch": 52, "training_loss": 4380.398779296875, "training_acc": 50.0, "val_loss": 3858.063232421875, "val_acc": 60.0}
{"epoch": 53, "training_loss": 4339.1982421875, "training_acc": 50.0, "val_loss": 1988.389892578125, "val_acc": 40.0}
{"epoch": 54, "training_loss": 2022.438525390625, "training_acc": 50.0, "val_loss": 3602.721435546875, "val_acc": 40.0}
{"epoch": 55, "training_loss": 2751.6798706054688, "training_acc": 50.0, "val_loss": 2303.259765625, "val_acc": 60.0}
{"epoch": 56, "training_loss": 3239.75625, "training_acc": 50.0, "val_loss": 1758.2962646484375, "val_acc": 60.0}
{"epoch": 57, "training_loss": 2042.742138671875, "training_acc": 50.0, "val_loss": 3397.044677734375, "val_acc": 40.0}
{"epoch": 58, "training_loss": 2741.3133056640627, "training_acc": 50.0, "val_loss": 27.7749080657959, "val_acc": 60.0}
{"epoch": 59, "training_loss": 49.68070068359375, "training_acc": 50.0, "val_loss": 1295.4659423828125, "val_acc": 60.0}
{"epoch": 60, "training_loss": 1570.75185546875, "training_acc": 50.0, "val_loss": 1832.6881103515625, "val_acc": 40.0}
