"main_modify.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 2 --task ADNI_sex --input_option yAware --learning_rate 1e2 --batch_size 16 --weight_decay 1e-3 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 6418.0104887008665, "training_acc": 55.0, "val_loss": 8722.3173828125, "val_acc": 40.0}
{"epoch": 1, "training_loss": 8525.088671875, "training_acc": 45.0, "val_loss": 9914.6611328125, "val_acc": 60.0}
{"epoch": 2, "training_loss": 13154.554296875, "training_acc": 45.0, "val_loss": 3013.82275390625, "val_acc": 60.0}
{"epoch": 3, "training_loss": 4361.84677734375, "training_acc": 45.0, "val_loss": 10814.751953125, "val_acc": 40.0}
{"epoch": 4, "training_loss": 8133.24677734375, "training_acc": 55.0, "val_loss": 9427.5576171875, "val_acc": 40.0}
{"epoch": 5, "training_loss": 6641.14169921875, "training_acc": 55.0, "val_loss": 1191.1456298828125, "val_acc": 60.0}
{"epoch": 6, "training_loss": 1994.120556640625, "training_acc": 45.0, "val_loss": 1864.8006591796875, "val_acc": 60.0}
{"epoch": 7, "training_loss": 2316.125927734375, "training_acc": 45.0, "val_loss": 2249.2021484375, "val_acc": 40.0}
{"epoch": 8, "training_loss": 1424.8474853515625, "training_acc": 55.0, "val_loss": 2177.133544921875, "val_acc": 60.0}
{"epoch": 9, "training_loss": 3016.940478515625, "training_acc": 45.0, "val_loss": 1491.0250244140625, "val_acc": 60.0}
{"epoch": 10, "training_loss": 1969.249755859375, "training_acc": 45.0, "val_loss": 2776.274169921875, "val_acc": 40.0}
{"epoch": 11, "training_loss": 1813.99580078125, "training_acc": 55.0, "val_loss": 1926.9281005859375, "val_acc": 60.0}
{"epoch": 12, "training_loss": 3289.2845703125, "training_acc": 45.0, "val_loss": 1115.487548828125, "val_acc": 60.0}
{"epoch": 13, "training_loss": 2395.47265625, "training_acc": 35.0, "val_loss": 5553.79296875, "val_acc": 40.0}
{"epoch": 14, "training_loss": 4025.871875, "training_acc": 55.0, "val_loss": 1626.4439697265625, "val_acc": 40.0}
{"epoch": 15, "training_loss": 1480.33095703125, "training_acc": 55.0, "val_loss": 3467.303955078125, "val_acc": 60.0}
{"epoch": 16, "training_loss": 4626.37509765625, "training_acc": 45.0, "val_loss": 722.5126953125, "val_acc": 60.0}
{"epoch": 17, "training_loss": 1065.4982421875, "training_acc": 55.0, "val_loss": 7470.1953125, "val_acc": 40.0}
{"epoch": 18, "training_loss": 6045.170703125, "training_acc": 55.0, "val_loss": 5282.74267578125, "val_acc": 40.0}
{"epoch": 19, "training_loss": 3076.283930206299, "training_acc": 55.0, "val_loss": 1749.8951416015625, "val_acc": 60.0}
{"epoch": 20, "training_loss": 2426.22421875, "training_acc": 45.0, "val_loss": 608.6144409179688, "val_acc": 40.0}
{"epoch": 21, "training_loss": 517.4345336914063, "training_acc": 55.0, "val_loss": 955.1868286132812, "val_acc": 40.0}
{"epoch": 22, "training_loss": 1051.22255859375, "training_acc": 45.0, "val_loss": 456.51171875, "val_acc": 60.0}
{"epoch": 23, "training_loss": 957.48701171875, "training_acc": 45.0, "val_loss": 3399.575927734375, "val_acc": 40.0}
{"epoch": 24, "training_loss": 2313.798828125, "training_acc": 55.0, "val_loss": 999.78515625, "val_acc": 60.0}
{"epoch": 25, "training_loss": 1488.31162109375, "training_acc": 45.0, "val_loss": 298.9323425292969, "val_acc": 60.0}
{"epoch": 26, "training_loss": 1332.43681640625, "training_acc": 35.0, "val_loss": 4238.4560546875, "val_acc": 40.0}
{"epoch": 27, "training_loss": 3006.420520019531, "training_acc": 55.0, "val_loss": 478.691650390625, "val_acc": 60.0}
{"epoch": 28, "training_loss": 779.3793701171875, "training_acc": 45.0, "val_loss": 1707.865234375, "val_acc": 40.0}
{"epoch": 29, "training_loss": 1303.6828247070312, "training_acc": 55.0, "val_loss": 1203.8460693359375, "val_acc": 40.0}
{"epoch": 30, "training_loss": 956.2976318359375, "training_acc": 55.0, "val_loss": 1170.960205078125, "val_acc": 60.0}
{"epoch": 31, "training_loss": 1205.7920043945312, "training_acc": 55.0, "val_loss": 1102.5621337890625, "val_acc": 40.0}
{"epoch": 32, "training_loss": 851.7859130859375, "training_acc": 45.0, "val_loss": 1453.493408203125, "val_acc": 40.0}
{"epoch": 33, "training_loss": 1042.7458129882812, "training_acc": 55.0, "val_loss": 882.0224609375, "val_acc": 60.0}
{"epoch": 34, "training_loss": 1162.403759765625, "training_acc": 45.0, "val_loss": 1516.7545166015625, "val_acc": 40.0}
{"epoch": 35, "training_loss": 1181.47587890625, "training_acc": 55.0, "val_loss": 192.44229125976562, "val_acc": 60.0}
{"epoch": 36, "training_loss": 273.746142578125, "training_acc": 45.0, "val_loss": 853.8824462890625, "val_acc": 60.0}
{"epoch": 37, "training_loss": 969.4428955078125, "training_acc": 45.0, "val_loss": 3608.67578125, "val_acc": 40.0}
{"epoch": 38, "training_loss": 2812.9987548828126, "training_acc": 55.0, "val_loss": 4734.28515625, "val_acc": 40.0}
{"epoch": 39, "training_loss": 3330.5627197265626, "training_acc": 55.0, "val_loss": 958.5460815429688, "val_acc": 60.0}
{"epoch": 40, "training_loss": 1419.050390625, "training_acc": 45.0, "val_loss": 168.8839111328125, "val_acc": 60.0}
{"epoch": 41, "training_loss": 836.74853515625, "training_acc": 45.0, "val_loss": 5252.8466796875, "val_acc": 40.0}
{"epoch": 42, "training_loss": 3824.5173583984374, "training_acc": 55.0, "val_loss": 1486.6590576171875, "val_acc": 40.0}
{"epoch": 43, "training_loss": 2230.12421875, "training_acc": 35.0, "val_loss": 2021.016845703125, "val_acc": 60.0}
{"epoch": 44, "training_loss": 2119.13046875, "training_acc": 45.0, "val_loss": 5386.10986328125, "val_acc": 40.0}
{"epoch": 45, "training_loss": 4031.0515625, "training_acc": 55.0, "val_loss": 9712.5380859375, "val_acc": 40.0}
{"epoch": 46, "training_loss": 7161.67734375, "training_acc": 55.0, "val_loss": 5780.65869140625, "val_acc": 40.0}
{"epoch": 47, "training_loss": 3474.754772949219, "training_acc": 55.0, "val_loss": 4166.56591796875, "val_acc": 60.0}
{"epoch": 48, "training_loss": 5742.35, "training_acc": 45.0, "val_loss": 7509.65087890625, "val_acc": 60.0}
{"epoch": 49, "training_loss": 10172.78828125, "training_acc": 45.0, "val_loss": 4408.37890625, "val_acc": 60.0}
{"epoch": 50, "training_loss": 4622.481787109375, "training_acc": 45.0, "val_loss": 7756.76025390625, "val_acc": 40.0}
{"epoch": 51, "training_loss": 6242.7615234375, "training_acc": 55.0, "val_loss": 15928.7568359375, "val_acc": 40.0}
{"epoch": 52, "training_loss": 11941.648828125, "training_acc": 55.0, "val_loss": 13117.8857421875, "val_acc": 40.0}
{"epoch": 53, "training_loss": 9372.411376953125, "training_acc": 55.0, "val_loss": 1434.2171630859375, "val_acc": 40.0}
{"epoch": 54, "training_loss": 2596.6724609375, "training_acc": 45.0, "val_loss": 6701.02587890625, "val_acc": 60.0}
{"epoch": 55, "training_loss": 9257.871875, "training_acc": 45.0, "val_loss": 5211.1484375, "val_acc": 60.0}
{"epoch": 56, "training_loss": 6737.476879882813, "training_acc": 45.0, "val_loss": 3543.2421875, "val_acc": 40.0}
{"epoch": 57, "training_loss": 2905.662353515625, "training_acc": 55.0, "val_loss": 7957.03662109375, "val_acc": 40.0}
{"epoch": 58, "training_loss": 5774.95546875, "training_acc": 55.0, "val_loss": 3345.412109375, "val_acc": 40.0}
{"epoch": 59, "training_loss": 2269.21298828125, "training_acc": 55.0, "val_loss": 2898.006591796875, "val_acc": 60.0}
