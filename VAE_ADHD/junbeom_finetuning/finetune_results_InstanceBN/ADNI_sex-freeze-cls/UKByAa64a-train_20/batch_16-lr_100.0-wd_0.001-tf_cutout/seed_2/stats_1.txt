"main_modify.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 2 --task ADNI_sex --input_option yAware --learning_rate 1e2 --batch_size 16 --weight_decay 1e-3 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 6408.0072435379025, "training_acc": 55.0, "val_loss": 5168.99462890625, "val_acc": 60.0}
{"epoch": 1, "training_loss": 7229.41640625, "training_acc": 50.0, "val_loss": 19988.123046875, "val_acc": 40.0}
{"epoch": 2, "training_loss": 16516.7625, "training_acc": 50.0, "val_loss": 12105.3193359375, "val_acc": 40.0}
{"epoch": 3, "training_loss": 7492.305908203125, "training_acc": 50.0, "val_loss": 7635.0234375, "val_acc": 60.0}
{"epoch": 4, "training_loss": 10139.5666015625, "training_acc": 50.0, "val_loss": 14849.806640625, "val_acc": 60.0}
{"epoch": 5, "training_loss": 18564.240625, "training_acc": 50.0, "val_loss": 12308.5126953125, "val_acc": 60.0}
{"epoch": 6, "training_loss": 14456.160546875, "training_acc": 50.0, "val_loss": 3278.85009765625, "val_acc": 60.0}
{"epoch": 7, "training_loss": 4079.031103515625, "training_acc": 50.0, "val_loss": 10858.3046875, "val_acc": 40.0}
{"epoch": 8, "training_loss": 9196.6701171875, "training_acc": 50.0, "val_loss": 13073.7802734375, "val_acc": 40.0}
{"epoch": 9, "training_loss": 10406.88203125, "training_acc": 50.0, "val_loss": 4983.6181640625, "val_acc": 40.0}
{"epoch": 10, "training_loss": 2481.226171875, "training_acc": 70.0, "val_loss": 5142.25390625, "val_acc": 60.0}
{"epoch": 11, "training_loss": 6874.826171875, "training_acc": 50.0, "val_loss": 6723.45947265625, "val_acc": 60.0}
{"epoch": 12, "training_loss": 7710.1515625, "training_acc": 50.0, "val_loss": 846.3140869140625, "val_acc": 60.0}
{"epoch": 13, "training_loss": 1260.448681640625, "training_acc": 60.0, "val_loss": 11639.4267578125, "val_acc": 40.0}
{"epoch": 14, "training_loss": 9671.8796875, "training_acc": 50.0, "val_loss": 14008.5732421875, "val_acc": 40.0}
{"epoch": 15, "training_loss": 11440.51044921875, "training_acc": 50.0, "val_loss": 7922.51318359375, "val_acc": 40.0}
{"epoch": 16, "training_loss": 6068.415710449219, "training_acc": 50.0, "val_loss": 3388.20166015625, "val_acc": 60.0}
{"epoch": 17, "training_loss": 4516.252197265625, "training_acc": 50.0, "val_loss": 6669.51708984375, "val_acc": 60.0}
{"epoch": 18, "training_loss": 8118.66083984375, "training_acc": 50.0, "val_loss": 3307.075927734375, "val_acc": 60.0}
{"epoch": 19, "training_loss": 3446.628698730469, "training_acc": 50.0, "val_loss": 3868.622314453125, "val_acc": 40.0}
{"epoch": 20, "training_loss": 3256.53525390625, "training_acc": 50.0, "val_loss": 1965.3841552734375, "val_acc": 40.0}
{"epoch": 21, "training_loss": 1314.4331420898438, "training_acc": 60.0, "val_loss": 2980.00830078125, "val_acc": 60.0}
{"epoch": 22, "training_loss": 3672.9103515625, "training_acc": 50.0, "val_loss": 969.1063842773438, "val_acc": 60.0}
{"epoch": 23, "training_loss": 2499.10546875, "training_acc": 30.0, "val_loss": 3978.012451171875, "val_acc": 40.0}
{"epoch": 24, "training_loss": 3095.239501953125, "training_acc": 50.0, "val_loss": 1391.642822265625, "val_acc": 60.0}
{"epoch": 25, "training_loss": 1783.0942626953124, "training_acc": 50.0, "val_loss": 1274.4873046875, "val_acc": 60.0}
{"epoch": 26, "training_loss": 1179.5517883300781, "training_acc": 60.0, "val_loss": 2092.292724609375, "val_acc": 40.0}
{"epoch": 27, "training_loss": 1538.647509765625, "training_acc": 50.0, "val_loss": 1658.0374755859375, "val_acc": 60.0}
{"epoch": 28, "training_loss": 2177.486572265625, "training_acc": 50.0, "val_loss": 902.2115478515625, "val_acc": 60.0}
{"epoch": 29, "training_loss": 982.3386474609375, "training_acc": 60.0, "val_loss": 4433.03466796875, "val_acc": 40.0}
{"epoch": 30, "training_loss": 3607.8311279296877, "training_acc": 50.0, "val_loss": 1431.5389404296875, "val_acc": 40.0}
{"epoch": 31, "training_loss": 1421.93681640625, "training_acc": 50.0, "val_loss": 2840.324951171875, "val_acc": 60.0}
{"epoch": 32, "training_loss": 3427.763623046875, "training_acc": 50.0, "val_loss": 63.889278411865234, "val_acc": 60.0}
{"epoch": 33, "training_loss": 419.6273254394531, "training_acc": 60.0, "val_loss": 6991.65771484375, "val_acc": 40.0}
{"epoch": 34, "training_loss": 5753.340869140625, "training_acc": 50.0, "val_loss": 4489.12646484375, "val_acc": 40.0}
{"epoch": 35, "training_loss": 3017.5827362060545, "training_acc": 50.0, "val_loss": 4031.25, "val_acc": 60.0}
{"epoch": 36, "training_loss": 5262.66064453125, "training_acc": 50.0, "val_loss": 6406.51953125, "val_acc": 60.0}
{"epoch": 37, "training_loss": 7678.5111328125, "training_acc": 50.0, "val_loss": 2081.740234375, "val_acc": 60.0}
{"epoch": 38, "training_loss": 2652.52802734375, "training_acc": 50.0, "val_loss": 6789.1650390625, "val_acc": 40.0}
{"epoch": 39, "training_loss": 5643.2060546875, "training_acc": 50.0, "val_loss": 5491.248046875, "val_acc": 40.0}
{"epoch": 40, "training_loss": 3919.0848876953123, "training_acc": 50.0, "val_loss": 2841.31103515625, "val_acc": 60.0}
{"epoch": 41, "training_loss": 3753.472509765625, "training_acc": 50.0, "val_loss": 4978.421875, "val_acc": 60.0}
{"epoch": 42, "training_loss": 5787.9908203125, "training_acc": 50.0, "val_loss": 264.6170959472656, "val_acc": 60.0}
{"epoch": 43, "training_loss": 1388.920166015625, "training_acc": 50.0, "val_loss": 10604.2451171875, "val_acc": 40.0}
{"epoch": 44, "training_loss": 8842.47412109375, "training_acc": 50.0, "val_loss": 9551.74609375, "val_acc": 40.0}
{"epoch": 45, "training_loss": 7275.9466796875, "training_acc": 50.0, "val_loss": 438.72491455078125, "val_acc": 60.0}
{"epoch": 46, "training_loss": 1809.740234375, "training_acc": 50.0, "val_loss": 1988.3707275390625, "val_acc": 60.0}
{"epoch": 47, "training_loss": 2118.3758056640627, "training_acc": 50.0, "val_loss": 1842.7064208984375, "val_acc": 40.0}
{"epoch": 48, "training_loss": 1384.917275238037, "training_acc": 50.0, "val_loss": 1778.6297607421875, "val_acc": 60.0}
{"epoch": 49, "training_loss": 2296.794970703125, "training_acc": 50.0, "val_loss": 333.6445617675781, "val_acc": 40.0}
{"epoch": 50, "training_loss": 511.53839111328125, "training_acc": 50.0, "val_loss": 932.265625, "val_acc": 60.0}
{"epoch": 51, "training_loss": 1169.4073974609375, "training_acc": 50.0, "val_loss": 933.9496459960938, "val_acc": 40.0}
