"main_modify.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 3 --task ADNI_sex --input_option yAware --learning_rate 1e2 --batch_size 8 --weight_decay 1e-2 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 9705.449775218964, "training_acc": 50.0, "val_loss": 12470.3974609375, "val_acc": 40.0}
{"epoch": 1, "training_loss": 16451.52197265625, "training_acc": 50.0, "val_loss": 9662.2490234375, "val_acc": 40.0}
{"epoch": 2, "training_loss": 4989.551708984375, "training_acc": 60.0, "val_loss": 8721.2890625, "val_acc": 60.0}
{"epoch": 3, "training_loss": 9981.0943359375, "training_acc": 50.0, "val_loss": 1424.319580078125, "val_acc": 60.0}
{"epoch": 4, "training_loss": 3263.226513671875, "training_acc": 60.0, "val_loss": 10536.8603515625, "val_acc": 40.0}
{"epoch": 5, "training_loss": 7312.56640625, "training_acc": 50.0, "val_loss": 535.9758911132812, "val_acc": 60.0}
{"epoch": 6, "training_loss": 2614.584423828125, "training_acc": 50.0, "val_loss": 3613.89501953125, "val_acc": 60.0}
{"epoch": 7, "training_loss": 3474.7341796875, "training_acc": 40.0, "val_loss": 3466.319580078125, "val_acc": 40.0}
{"epoch": 8, "training_loss": 2716.059423828125, "training_acc": 50.0, "val_loss": 409.3236999511719, "val_acc": 60.0}
{"epoch": 9, "training_loss": 1424.4995849609375, "training_acc": 50.0, "val_loss": 322.493896484375, "val_acc": 60.0}
{"epoch": 10, "training_loss": 923.8249633789062, "training_acc": 60.0, "val_loss": 2111.558349609375, "val_acc": 40.0}
{"epoch": 11, "training_loss": 1219.9032104492187, "training_acc": 50.0, "val_loss": 2243.56689453125, "val_acc": 60.0}
{"epoch": 12, "training_loss": 1893.9194702148438, "training_acc": 50.0, "val_loss": 3132.4560546875, "val_acc": 40.0}
{"epoch": 13, "training_loss": 3354.47236328125, "training_acc": 50.0, "val_loss": 1623.878173828125, "val_acc": 40.0}
{"epoch": 14, "training_loss": 2349.807763671875, "training_acc": 40.0, "val_loss": 2904.622802734375, "val_acc": 60.0}
{"epoch": 15, "training_loss": 2882.6327880859376, "training_acc": 40.0, "val_loss": 2697.193359375, "val_acc": 40.0}
{"epoch": 16, "training_loss": 1905.2593994140625, "training_acc": 40.0, "val_loss": 526.2111206054688, "val_acc": 60.0}
{"epoch": 17, "training_loss": 441.1135650634766, "training_acc": 40.0, "val_loss": 1253.3992919921875, "val_acc": 40.0}
{"epoch": 18, "training_loss": 834.7388549804688, "training_acc": 50.0, "val_loss": 518.1232299804688, "val_acc": 60.0}
{"epoch": 19, "training_loss": 959.015087890625, "training_acc": 40.0, "val_loss": 701.0316772460938, "val_acc": 60.0}
{"epoch": 20, "training_loss": 1036.3916259765624, "training_acc": 50.0, "val_loss": 1563.8939208984375, "val_acc": 40.0}
{"epoch": 21, "training_loss": 1338.5937866210938, "training_acc": 50.0, "val_loss": 1166.1490478515625, "val_acc": 60.0}
{"epoch": 22, "training_loss": 1805.487158203125, "training_acc": 50.0, "val_loss": 1319.6624755859375, "val_acc": 40.0}
{"epoch": 23, "training_loss": 1264.276025390625, "training_acc": 50.0, "val_loss": 719.7304077148438, "val_acc": 60.0}
{"epoch": 24, "training_loss": 1119.3880859375, "training_acc": 40.0, "val_loss": 23.23876953125, "val_acc": 60.0}
{"epoch": 25, "training_loss": 417.9562702178955, "training_acc": 50.0, "val_loss": 980.8367309570312, "val_acc": 60.0}
{"epoch": 26, "training_loss": 1216.4609619140624, "training_acc": 50.0, "val_loss": 3515.20166015625, "val_acc": 40.0}
{"epoch": 27, "training_loss": 3833.704931640625, "training_acc": 50.0, "val_loss": 718.39599609375, "val_acc": 40.0}
{"epoch": 28, "training_loss": 1546.8019409179688, "training_acc": 70.0, "val_loss": 3093.88232421875, "val_acc": 60.0}
{"epoch": 29, "training_loss": 3202.703125, "training_acc": 40.0, "val_loss": 4897.75146484375, "val_acc": 40.0}
{"epoch": 30, "training_loss": 2958.633758544922, "training_acc": 50.0, "val_loss": 2732.362548828125, "val_acc": 60.0}
{"epoch": 31, "training_loss": 3837.21259765625, "training_acc": 50.0, "val_loss": 734.9617309570312, "val_acc": 60.0}
{"epoch": 32, "training_loss": 3275.210791015625, "training_acc": 40.0, "val_loss": 4550.220703125, "val_acc": 40.0}
{"epoch": 33, "training_loss": 1405.2952392578125, "training_acc": 70.0, "val_loss": 4355.81494140625, "val_acc": 60.0}
{"epoch": 34, "training_loss": 4967.275561523437, "training_acc": 50.0, "val_loss": 1491.8543701171875, "val_acc": 40.0}
{"epoch": 35, "training_loss": 3050.3955810546877, "training_acc": 50.0, "val_loss": 1019.4078979492188, "val_acc": 40.0}
{"epoch": 36, "training_loss": 2142.8439453125, "training_acc": 50.0, "val_loss": 2386.300537109375, "val_acc": 60.0}
{"epoch": 37, "training_loss": 1808.9573323249817, "training_acc": 60.0, "val_loss": 5668.20751953125, "val_acc": 40.0}
{"epoch": 38, "training_loss": 3802.741595458984, "training_acc": 50.0, "val_loss": 2500.636474609375, "val_acc": 60.0}
{"epoch": 39, "training_loss": 3915.9931640625, "training_acc": 50.0, "val_loss": 205.03599548339844, "val_acc": 60.0}
{"epoch": 40, "training_loss": 1469.2839721679688, "training_acc": 70.0, "val_loss": 4987.37646484375, "val_acc": 40.0}
{"epoch": 41, "training_loss": 2599.805322265625, "training_acc": 50.0, "val_loss": 3266.055908203125, "val_acc": 60.0}
{"epoch": 42, "training_loss": 3051.819384765625, "training_acc": 50.0, "val_loss": 3272.675048828125, "val_acc": 40.0}
{"epoch": 43, "training_loss": 3596.2642578125, "training_acc": 50.0, "val_loss": 1048.274169921875, "val_acc": 40.0}
