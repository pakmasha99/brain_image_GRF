"main_modify.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 3 --task ADNI_sex --input_option yAware --learning_rate 1e2 --batch_size 8 --weight_decay 1e-2 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 13465.80446267128, "training_acc": 55.0, "val_loss": 7032.6884765625, "val_acc": 60.0}
{"epoch": 1, "training_loss": 13602.4486328125, "training_acc": 45.0, "val_loss": 5567.046875, "val_acc": 60.0}
{"epoch": 2, "training_loss": 3632.5682861328123, "training_acc": 65.0, "val_loss": 11357.837890625, "val_acc": 40.0}
{"epoch": 3, "training_loss": 7572.66171875, "training_acc": 55.0, "val_loss": 574.4568481445312, "val_acc": 40.0}
{"epoch": 4, "training_loss": 4032.5710205078126, "training_acc": 55.0, "val_loss": 6289.4345703125, "val_acc": 60.0}
{"epoch": 5, "training_loss": 5966.47314453125, "training_acc": 45.0, "val_loss": 4891.51123046875, "val_acc": 40.0}
{"epoch": 6, "training_loss": 5552.6576171875, "training_acc": 55.0, "val_loss": 7031.72998046875, "val_acc": 40.0}
{"epoch": 7, "training_loss": 2906.901513671875, "training_acc": 55.0, "val_loss": 3295.750732421875, "val_acc": 60.0}
{"epoch": 8, "training_loss": 5329.3974609375, "training_acc": 45.0, "val_loss": 887.5886840820312, "val_acc": 60.0}
{"epoch": 9, "training_loss": 1583.545166015625, "training_acc": 65.0, "val_loss": 6476.5830078125, "val_acc": 40.0}
{"epoch": 10, "training_loss": 4188.7896484375, "training_acc": 55.0, "val_loss": 1646.7293701171875, "val_acc": 60.0}
{"epoch": 11, "training_loss": 2918.35302734375, "training_acc": 45.0, "val_loss": 825.8262939453125, "val_acc": 60.0}
{"epoch": 12, "training_loss": 820.066943359375, "training_acc": 65.0, "val_loss": 3104.75634765625, "val_acc": 40.0}
{"epoch": 13, "training_loss": 1364.396810913086, "training_acc": 65.0, "val_loss": 1116.434326171875, "val_acc": 60.0}
{"epoch": 14, "training_loss": 1030.2825927734375, "training_acc": 55.0, "val_loss": 1402.0684814453125, "val_acc": 40.0}
{"epoch": 15, "training_loss": 1032.4153076171874, "training_acc": 45.0, "val_loss": 880.5222778320312, "val_acc": 60.0}
{"epoch": 16, "training_loss": 608.106655883789, "training_acc": 55.0, "val_loss": 89.13744354248047, "val_acc": 40.0}
{"epoch": 17, "training_loss": 958.0745422363282, "training_acc": 45.0, "val_loss": 656.1591186523438, "val_acc": 40.0}
{"epoch": 18, "training_loss": 839.0851684570313, "training_acc": 55.0, "val_loss": 852.283203125, "val_acc": 60.0}
{"epoch": 19, "training_loss": 1006.1780792236328, "training_acc": 45.0, "val_loss": 243.6182861328125, "val_acc": 40.0}
{"epoch": 20, "training_loss": 564.4501525878907, "training_acc": 45.0, "val_loss": 1651.6484375, "val_acc": 40.0}
{"epoch": 21, "training_loss": 1429.9533935546874, "training_acc": 55.0, "val_loss": 1341.2264404296875, "val_acc": 60.0}
{"epoch": 22, "training_loss": 2323.1036865234373, "training_acc": 45.0, "val_loss": 1742.2508544921875, "val_acc": 40.0}
{"epoch": 23, "training_loss": 1705.1117065429687, "training_acc": 55.0, "val_loss": 97.6614761352539, "val_acc": 60.0}
{"epoch": 24, "training_loss": 183.04438171386718, "training_acc": 45.0, "val_loss": 821.5400390625, "val_acc": 60.0}
{"epoch": 25, "training_loss": 1212.478125, "training_acc": 35.0, "val_loss": 334.0615234375, "val_acc": 60.0}
{"epoch": 26, "training_loss": 748.4870239257813, "training_acc": 35.0, "val_loss": 1333.0504150390625, "val_acc": 40.0}
{"epoch": 27, "training_loss": 651.8245056152343, "training_acc": 55.0, "val_loss": 365.2957458496094, "val_acc": 40.0}
{"epoch": 28, "training_loss": 467.235498046875, "training_acc": 55.0, "val_loss": 844.6068725585938, "val_acc": 60.0}
{"epoch": 29, "training_loss": 1055.752734375, "training_acc": 45.0, "val_loss": 113.583251953125, "val_acc": 60.0}
{"epoch": 30, "training_loss": 507.38388671875, "training_acc": 45.0, "val_loss": 1643.8369140625, "val_acc": 40.0}
{"epoch": 31, "training_loss": 929.416357421875, "training_acc": 55.0, "val_loss": 2033.605712890625, "val_acc": 60.0}
{"epoch": 32, "training_loss": 1988.3740966796875, "training_acc": 45.0, "val_loss": 3383.22314453125, "val_acc": 40.0}
{"epoch": 33, "training_loss": 1776.52509765625, "training_acc": 55.0, "val_loss": 1027.431884765625, "val_acc": 60.0}
{"epoch": 34, "training_loss": 1117.199365234375, "training_acc": 45.0, "val_loss": 2935.778564453125, "val_acc": 40.0}
{"epoch": 35, "training_loss": 1511.191748046875, "training_acc": 55.0, "val_loss": 1767.8826904296875, "val_acc": 60.0}
