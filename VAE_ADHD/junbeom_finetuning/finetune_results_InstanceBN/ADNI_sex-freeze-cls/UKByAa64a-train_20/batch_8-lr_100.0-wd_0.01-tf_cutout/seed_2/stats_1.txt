"main_modify.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 2 --task ADNI_sex --input_option yAware --learning_rate 1e2 --batch_size 8 --weight_decay 1e-2 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 180.97778232097625, "training_acc": 70.0, "val_loss": 1462.9852294921875, "val_acc": 60.0}
{"epoch": 1, "training_loss": 1302.0178466796874, "training_acc": 45.0, "val_loss": 653.2250366210938, "val_acc": 60.0}
{"epoch": 2, "training_loss": 642.6132995605469, "training_acc": 60.0, "val_loss": 2113.76806640625, "val_acc": 40.0}
{"epoch": 3, "training_loss": 1478.9696899414062, "training_acc": 50.0, "val_loss": 1023.7080078125, "val_acc": 60.0}
{"epoch": 4, "training_loss": 1265.6374267578126, "training_acc": 40.0, "val_loss": 318.68603515625, "val_acc": 40.0}
{"epoch": 5, "training_loss": 1324.448828125, "training_acc": 60.0, "val_loss": 1645.0537109375, "val_acc": 60.0}
{"epoch": 6, "training_loss": 1464.746728515625, "training_acc": 40.0, "val_loss": 636.7020874023438, "val_acc": 40.0}
{"epoch": 7, "training_loss": 533.938720703125, "training_acc": 60.0, "val_loss": 1330.592041015625, "val_acc": 40.0}
{"epoch": 8, "training_loss": 1572.0419921875, "training_acc": 50.0, "val_loss": 955.6300659179688, "val_acc": 60.0}
{"epoch": 9, "training_loss": 1287.7171752929687, "training_acc": 50.0, "val_loss": 1444.8203125, "val_acc": 40.0}
{"epoch": 10, "training_loss": 1151.6111572265625, "training_acc": 50.0, "val_loss": 1928.7899169921875, "val_acc": 60.0}
{"epoch": 11, "training_loss": 2479.906591796875, "training_acc": 50.0, "val_loss": 510.1319885253906, "val_acc": 40.0}
{"epoch": 12, "training_loss": 1377.4415283203125, "training_acc": 50.0, "val_loss": 935.5601806640625, "val_acc": 60.0}
{"epoch": 13, "training_loss": 1843.963427734375, "training_acc": 50.0, "val_loss": 1130.8326416015625, "val_acc": 40.0}
{"epoch": 14, "training_loss": 1553.601708984375, "training_acc": 50.0, "val_loss": 387.5491027832031, "val_acc": 60.0}
{"epoch": 15, "training_loss": 1173.0045471191406, "training_acc": 50.0, "val_loss": 2177.23876953125, "val_acc": 40.0}
{"epoch": 16, "training_loss": 2087.03310546875, "training_acc": 50.0, "val_loss": 1150.012939453125, "val_acc": 60.0}
{"epoch": 17, "training_loss": 1833.330029296875, "training_acc": 50.0, "val_loss": 253.91943359375, "val_acc": 40.0}
{"epoch": 18, "training_loss": 394.22454223632815, "training_acc": 60.0, "val_loss": 182.5676727294922, "val_acc": 60.0}
{"epoch": 19, "training_loss": 1268.10556640625, "training_acc": 30.0, "val_loss": 1077.851318359375, "val_acc": 60.0}
{"epoch": 20, "training_loss": 1967.3910400390625, "training_acc": 50.0, "val_loss": 1329.9666748046875, "val_acc": 40.0}
{"epoch": 21, "training_loss": 1195.7374267578125, "training_acc": 50.0, "val_loss": 1154.478515625, "val_acc": 60.0}
{"epoch": 22, "training_loss": 1134.7793090820312, "training_acc": 50.0, "val_loss": 2627.17578125, "val_acc": 40.0}
{"epoch": 23, "training_loss": 2069.852001953125, "training_acc": 50.0, "val_loss": 1212.924072265625, "val_acc": 60.0}
{"epoch": 24, "training_loss": 1583.5265625, "training_acc": 50.0, "val_loss": 1547.65087890625, "val_acc": 40.0}
{"epoch": 25, "training_loss": 1069.2359619140625, "training_acc": 50.0, "val_loss": 761.6746826171875, "val_acc": 60.0}
{"epoch": 26, "training_loss": 396.55226135253906, "training_acc": 50.0, "val_loss": 1659.8873291015625, "val_acc": 40.0}
{"epoch": 27, "training_loss": 1357.320166015625, "training_acc": 40.0, "val_loss": 454.5005798339844, "val_acc": 60.0}
{"epoch": 28, "training_loss": 1376.4154296875, "training_acc": 40.0, "val_loss": 14.858856201171875, "val_acc": 60.0}
{"epoch": 29, "training_loss": 486.29272384643554, "training_acc": 40.0, "val_loss": 166.80606079101562, "val_acc": 40.0}
{"epoch": 30, "training_loss": 329.277571105957, "training_acc": 50.0, "val_loss": 211.4567413330078, "val_acc": 40.0}
{"epoch": 31, "training_loss": 400.7118545532227, "training_acc": 60.0, "val_loss": 1288.5670166015625, "val_acc": 40.0}
{"epoch": 32, "training_loss": 929.17685546875, "training_acc": 50.0, "val_loss": 1051.6209716796875, "val_acc": 60.0}
{"epoch": 33, "training_loss": 756.2700073242188, "training_acc": 50.0, "val_loss": 735.6334228515625, "val_acc": 60.0}
{"epoch": 34, "training_loss": 840.3740478515625, "training_acc": 50.0, "val_loss": 1428.5784912109375, "val_acc": 40.0}
{"epoch": 35, "training_loss": 1161.9571838378906, "training_acc": 40.0, "val_loss": 820.5587768554688, "val_acc": 40.0}
{"epoch": 36, "training_loss": 573.1108764648437, "training_acc": 40.0, "val_loss": 156.96484375, "val_acc": 40.0}
{"epoch": 37, "training_loss": 1618.2817016601562, "training_acc": 40.0, "val_loss": 108.27190399169922, "val_acc": 60.0}
{"epoch": 38, "training_loss": 1032.6339080810546, "training_acc": 60.0, "val_loss": 811.7893676757812, "val_acc": 40.0}
{"epoch": 39, "training_loss": 1506.2642333984375, "training_acc": 50.0, "val_loss": 767.929443359375, "val_acc": 60.0}
{"epoch": 40, "training_loss": 1478.3101928710937, "training_acc": 50.0, "val_loss": 1122.05029296875, "val_acc": 40.0}
{"epoch": 41, "training_loss": 1954.906640625, "training_acc": 40.0, "val_loss": 487.0050964355469, "val_acc": 60.0}
{"epoch": 42, "training_loss": 1056.7229125976562, "training_acc": 70.0, "val_loss": 1764.0230712890625, "val_acc": 40.0}
{"epoch": 43, "training_loss": 1461.6579833984374, "training_acc": 60.0, "val_loss": 778.1753540039062, "val_acc": 60.0}
{"epoch": 44, "training_loss": 2258.8641845703123, "training_acc": 40.0, "val_loss": 1834.3485107421875, "val_acc": 40.0}
{"epoch": 45, "training_loss": 1647.57939453125, "training_acc": 50.0, "val_loss": 810.4320678710938, "val_acc": 60.0}
{"epoch": 46, "training_loss": 1805.354248046875, "training_acc": 50.0, "val_loss": 947.3152465820312, "val_acc": 40.0}
{"epoch": 47, "training_loss": 1816.2559326171875, "training_acc": 60.0, "val_loss": 1427.8626708984375, "val_acc": 60.0}
