"main_modify.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 2 --task ADNI_sex --input_option yAware --learning_rate 1e2 --batch_size 8 --weight_decay 1e-2 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 13377.716285204888, "training_acc": 45.0, "val_loss": 11675.4609375, "val_acc": 40.0}
{"epoch": 1, "training_loss": 12376.3251953125, "training_acc": 55.0, "val_loss": 9700.5732421875, "val_acc": 40.0}
{"epoch": 2, "training_loss": 5067.822938537598, "training_acc": 45.0, "val_loss": 6601.96728515625, "val_acc": 60.0}
{"epoch": 3, "training_loss": 7782.8298828125, "training_acc": 45.0, "val_loss": 1061.467041015625, "val_acc": 40.0}
{"epoch": 4, "training_loss": 2668.5623046875, "training_acc": 55.0, "val_loss": 5586.1484375, "val_acc": 40.0}
{"epoch": 5, "training_loss": 2743.8407958984376, "training_acc": 55.0, "val_loss": 2518.142333984375, "val_acc": 60.0}
{"epoch": 6, "training_loss": 3354.553125, "training_acc": 45.0, "val_loss": 1191.7899169921875, "val_acc": 40.0}
{"epoch": 7, "training_loss": 2426.6990234375, "training_acc": 55.0, "val_loss": 2271.130859375, "val_acc": 40.0}
{"epoch": 8, "training_loss": 1863.524072265625, "training_acc": 35.0, "val_loss": 1166.6724853515625, "val_acc": 60.0}
{"epoch": 9, "training_loss": 1078.6709838867187, "training_acc": 45.0, "val_loss": 557.4371948242188, "val_acc": 40.0}
{"epoch": 10, "training_loss": 913.1237365722657, "training_acc": 45.0, "val_loss": 65.30030822753906, "val_acc": 40.0}
{"epoch": 11, "training_loss": 453.8445114135742, "training_acc": 35.0, "val_loss": 806.6314697265625, "val_acc": 40.0}
{"epoch": 12, "training_loss": 928.963330078125, "training_acc": 45.0, "val_loss": 285.0126037597656, "val_acc": 40.0}
{"epoch": 13, "training_loss": 370.0569442749023, "training_acc": 55.0, "val_loss": 1687.0775146484375, "val_acc": 60.0}
{"epoch": 14, "training_loss": 2116.607373046875, "training_acc": 45.0, "val_loss": 1938.55078125, "val_acc": 40.0}
{"epoch": 15, "training_loss": 1639.7119140625, "training_acc": 55.0, "val_loss": 605.1932983398438, "val_acc": 40.0}
{"epoch": 16, "training_loss": 369.75001220703126, "training_acc": 75.0, "val_loss": 391.2330017089844, "val_acc": 60.0}
{"epoch": 17, "training_loss": 993.906787109375, "training_acc": 45.0, "val_loss": 71.65115356445312, "val_acc": 40.0}
{"epoch": 18, "training_loss": 1228.3353958129883, "training_acc": 55.0, "val_loss": 590.3057250976562, "val_acc": 60.0}
{"epoch": 19, "training_loss": 941.8880126953125, "training_acc": 65.0, "val_loss": 2457.234130859375, "val_acc": 40.0}
{"epoch": 20, "training_loss": 1712.3410888671874, "training_acc": 45.0, "val_loss": 2505.581787109375, "val_acc": 60.0}
{"epoch": 21, "training_loss": 1985.6206298828124, "training_acc": 55.0, "val_loss": 4142.18896484375, "val_acc": 40.0}
{"epoch": 22, "training_loss": 3014.405078125, "training_acc": 55.0, "val_loss": 1586.0758056640625, "val_acc": 60.0}
{"epoch": 23, "training_loss": 2245.253515625, "training_acc": 45.0, "val_loss": 1976.4281005859375, "val_acc": 40.0}
{"epoch": 24, "training_loss": 1592.6215576171876, "training_acc": 55.0, "val_loss": 910.9724731445312, "val_acc": 60.0}
{"epoch": 25, "training_loss": 1096.2881469726562, "training_acc": 45.0, "val_loss": 462.1924743652344, "val_acc": 40.0}
{"epoch": 26, "training_loss": 975.5238647460938, "training_acc": 35.0, "val_loss": 1819.3046875, "val_acc": 40.0}
{"epoch": 27, "training_loss": 1178.9708435058594, "training_acc": 45.0, "val_loss": 634.682861328125, "val_acc": 40.0}
{"epoch": 28, "training_loss": 361.48375701904297, "training_acc": 55.0, "val_loss": 28.370807647705078, "val_acc": 40.0}
{"epoch": 29, "training_loss": 1202.1068130493163, "training_acc": 35.0, "val_loss": 1507.445556640625, "val_acc": 40.0}
{"epoch": 30, "training_loss": 1311.9042236328125, "training_acc": 55.0, "val_loss": 1359.7880859375, "val_acc": 60.0}
{"epoch": 31, "training_loss": 1912.3709228515625, "training_acc": 45.0, "val_loss": 2842.52001953125, "val_acc": 40.0}
{"epoch": 32, "training_loss": 2466.75634765625, "training_acc": 55.0, "val_loss": 757.8977661132812, "val_acc": 60.0}
{"epoch": 33, "training_loss": 1640.209375, "training_acc": 45.0, "val_loss": 1057.6068115234375, "val_acc": 40.0}
{"epoch": 34, "training_loss": 1429.8941284179687, "training_acc": 55.0, "val_loss": 1262.521484375, "val_acc": 60.0}
{"epoch": 35, "training_loss": 2379.248046875, "training_acc": 45.0, "val_loss": 2343.677978515625, "val_acc": 40.0}
{"epoch": 36, "training_loss": 3712.125036621094, "training_acc": 55.0, "val_loss": 754.8335571289062, "val_acc": 40.0}
{"epoch": 37, "training_loss": 2664.70703125, "training_acc": 55.0, "val_loss": 3076.418212890625, "val_acc": 60.0}
{"epoch": 38, "training_loss": 2617.54267578125, "training_acc": 45.0, "val_loss": 7555.78125, "val_acc": 40.0}
{"epoch": 39, "training_loss": 4278.067431640625, "training_acc": 55.0, "val_loss": 2713.83056640625, "val_acc": 60.0}
{"epoch": 40, "training_loss": 4605.770703125, "training_acc": 45.0, "val_loss": 577.0155639648438, "val_acc": 60.0}
{"epoch": 41, "training_loss": 4801.514306640625, "training_acc": 35.0, "val_loss": 6342.341796875, "val_acc": 40.0}
{"epoch": 42, "training_loss": 2855.57177734375, "training_acc": 55.0, "val_loss": 5326.90234375, "val_acc": 60.0}
{"epoch": 43, "training_loss": 5785.21181640625, "training_acc": 45.0, "val_loss": 3999.352783203125, "val_acc": 40.0}
{"epoch": 44, "training_loss": 4999.80947265625, "training_acc": 55.0, "val_loss": 4646.6279296875, "val_acc": 40.0}
{"epoch": 45, "training_loss": 3498.4126953125, "training_acc": 35.0, "val_loss": 2533.466552734375, "val_acc": 60.0}
{"epoch": 46, "training_loss": 2433.6874755859376, "training_acc": 45.0, "val_loss": 5571.0166015625, "val_acc": 40.0}
{"epoch": 47, "training_loss": 2981.077520751953, "training_acc": 55.0, "val_loss": 2858.528076171875, "val_acc": 60.0}
