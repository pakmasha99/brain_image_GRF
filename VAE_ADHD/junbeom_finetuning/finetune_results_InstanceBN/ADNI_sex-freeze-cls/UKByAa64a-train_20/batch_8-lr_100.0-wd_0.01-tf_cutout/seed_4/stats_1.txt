"main_modify.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 4 --task ADNI_sex --input_option yAware --learning_rate 1e2 --batch_size 8 --weight_decay 1e-2 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 11200.687703895568, "training_acc": 50.0, "val_loss": 8079.37646484375, "val_acc": 60.0}
{"epoch": 1, "training_loss": 14035.523046875, "training_acc": 50.0, "val_loss": 7732.11572265625, "val_acc": 60.0}
{"epoch": 2, "training_loss": 6652.444604492188, "training_acc": 50.0, "val_loss": 14538.4892578125, "val_acc": 40.0}
{"epoch": 3, "training_loss": 12224.671484375, "training_acc": 50.0, "val_loss": 6286.6474609375, "val_acc": 40.0}
{"epoch": 4, "training_loss": 2267.1626708984377, "training_acc": 70.0, "val_loss": 6336.8623046875, "val_acc": 60.0}
{"epoch": 5, "training_loss": 7616.144921875, "training_acc": 50.0, "val_loss": 1708.66796875, "val_acc": 60.0}
{"epoch": 6, "training_loss": 1537.607763671875, "training_acc": 70.0, "val_loss": 7451.65478515625, "val_acc": 40.0}
{"epoch": 7, "training_loss": 5397.985498046875, "training_acc": 50.0, "val_loss": 171.42161560058594, "val_acc": 60.0}
{"epoch": 8, "training_loss": 2282.642938232422, "training_acc": 50.0, "val_loss": 2890.89892578125, "val_acc": 60.0}
{"epoch": 9, "training_loss": 2702.806787109375, "training_acc": 40.0, "val_loss": 3669.421142578125, "val_acc": 40.0}
{"epoch": 10, "training_loss": 2727.67802734375, "training_acc": 50.0, "val_loss": 785.3102416992188, "val_acc": 60.0}
{"epoch": 11, "training_loss": 1653.392431640625, "training_acc": 50.0, "val_loss": 44.342529296875, "val_acc": 60.0}
{"epoch": 12, "training_loss": 2415.327456665039, "training_acc": 30.0, "val_loss": 2803.1416015625, "val_acc": 40.0}
{"epoch": 13, "training_loss": 1590.9823974609376, "training_acc": 40.0, "val_loss": 1130.1107177734375, "val_acc": 60.0}
{"epoch": 14, "training_loss": 970.0714134216308, "training_acc": 40.0, "val_loss": 547.9664916992188, "val_acc": 60.0}
{"epoch": 15, "training_loss": 728.7806762695312, "training_acc": 40.0, "val_loss": 26.292566299438477, "val_acc": 60.0}
{"epoch": 16, "training_loss": 515.5643203735351, "training_acc": 30.0, "val_loss": 552.6204833984375, "val_acc": 40.0}
{"epoch": 17, "training_loss": 476.92144775390625, "training_acc": 50.0, "val_loss": 494.4208984375, "val_acc": 60.0}
{"epoch": 18, "training_loss": 1210.414208984375, "training_acc": 30.0, "val_loss": 383.70513916015625, "val_acc": 60.0}
{"epoch": 19, "training_loss": 568.9599182128907, "training_acc": 40.0, "val_loss": 135.79739379882812, "val_acc": 60.0}
{"epoch": 20, "training_loss": 503.7510498046875, "training_acc": 30.0, "val_loss": 128.08116149902344, "val_acc": 60.0}
{"epoch": 21, "training_loss": 948.0552856445313, "training_acc": 40.0, "val_loss": 186.6753387451172, "val_acc": 60.0}
{"epoch": 22, "training_loss": 347.2552856445312, "training_acc": 50.0, "val_loss": 848.7599487304688, "val_acc": 40.0}
{"epoch": 23, "training_loss": 783.2591918945312, "training_acc": 50.0, "val_loss": 561.6054077148438, "val_acc": 40.0}
{"epoch": 24, "training_loss": 635.2802795410156, "training_acc": 50.0, "val_loss": 72.59884643554688, "val_acc": 60.0}
{"epoch": 25, "training_loss": 565.1303283691407, "training_acc": 60.0, "val_loss": 723.02294921875, "val_acc": 60.0}
{"epoch": 26, "training_loss": 1377.4159240722656, "training_acc": 50.0, "val_loss": 1499.7723388671875, "val_acc": 40.0}
{"epoch": 27, "training_loss": 1151.5959594726562, "training_acc": 50.0, "val_loss": 1555.1629638671875, "val_acc": 60.0}
{"epoch": 28, "training_loss": 1979.89814453125, "training_acc": 50.0, "val_loss": 1572.23779296875, "val_acc": 40.0}
{"epoch": 29, "training_loss": 1641.19931640625, "training_acc": 50.0, "val_loss": 780.8278198242188, "val_acc": 60.0}
{"epoch": 30, "training_loss": 1428.871484375, "training_acc": 50.0, "val_loss": 1074.42041015625, "val_acc": 40.0}
{"epoch": 31, "training_loss": 1048.450439453125, "training_acc": 50.0, "val_loss": 886.3443603515625, "val_acc": 60.0}
{"epoch": 32, "training_loss": 1077.4164428710938, "training_acc": 40.0, "val_loss": 247.940185546875, "val_acc": 60.0}
{"epoch": 33, "training_loss": 126.66986560821533, "training_acc": 70.0, "val_loss": 454.2008972167969, "val_acc": 40.0}
{"epoch": 34, "training_loss": 349.91511249542236, "training_acc": 50.0, "val_loss": 1893.5133056640625, "val_acc": 40.0}
