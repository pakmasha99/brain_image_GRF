"main_modify.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 4 --task ADNI_sex --input_option yAware --learning_rate 1e2 --batch_size 8 --weight_decay 1e-2 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 9847.536923265458, "training_acc": 45.0, "val_loss": 7625.73291015625, "val_acc": 60.0}
{"epoch": 1, "training_loss": 13295.738671875, "training_acc": 45.0, "val_loss": 5391.38037109375, "val_acc": 60.0}
{"epoch": 2, "training_loss": 6389.240625, "training_acc": 45.0, "val_loss": 12154.5986328125, "val_acc": 40.0}
{"epoch": 3, "training_loss": 7995.3716796875, "training_acc": 55.0, "val_loss": 176.2494659423828, "val_acc": 60.0}
{"epoch": 4, "training_loss": 2451.7212890625, "training_acc": 45.0, "val_loss": 3299.806396484375, "val_acc": 60.0}
{"epoch": 5, "training_loss": 2394.0388916015627, "training_acc": 55.0, "val_loss": 4383.81884765625, "val_acc": 40.0}
{"epoch": 6, "training_loss": 3500.769775390625, "training_acc": 55.0, "val_loss": 904.6076049804688, "val_acc": 40.0}
{"epoch": 7, "training_loss": 1928.20087890625, "training_acc": 55.0, "val_loss": 2752.111083984375, "val_acc": 60.0}
{"epoch": 8, "training_loss": 2460.6691162109373, "training_acc": 45.0, "val_loss": 3915.297607421875, "val_acc": 40.0}
{"epoch": 9, "training_loss": 2712.7871215820314, "training_acc": 55.0, "val_loss": 636.0845947265625, "val_acc": 60.0}
{"epoch": 10, "training_loss": 1691.2224609375, "training_acc": 45.0, "val_loss": 727.3277587890625, "val_acc": 40.0}
{"epoch": 11, "training_loss": 774.2133422851563, "training_acc": 55.0, "val_loss": 566.4430541992188, "val_acc": 60.0}
{"epoch": 12, "training_loss": 720.7343505859375, "training_acc": 45.0, "val_loss": 420.9678649902344, "val_acc": 40.0}
{"epoch": 13, "training_loss": 354.1132568359375, "training_acc": 55.0, "val_loss": 1390.3125, "val_acc": 40.0}
{"epoch": 14, "training_loss": 1346.60673828125, "training_acc": 55.0, "val_loss": 1454.4290771484375, "val_acc": 60.0}
{"epoch": 15, "training_loss": 2170.667138671875, "training_acc": 45.0, "val_loss": 1695.261962890625, "val_acc": 40.0}
{"epoch": 16, "training_loss": 2051.805859375, "training_acc": 55.0, "val_loss": 1035.4090576171875, "val_acc": 40.0}
{"epoch": 17, "training_loss": 1735.7122802734375, "training_acc": 55.0, "val_loss": 1915.9246826171875, "val_acc": 60.0}
{"epoch": 18, "training_loss": 1808.8193237304688, "training_acc": 45.0, "val_loss": 1349.713134765625, "val_acc": 40.0}
{"epoch": 19, "training_loss": 447.7943054199219, "training_acc": 65.0, "val_loss": 275.7895202636719, "val_acc": 40.0}
{"epoch": 20, "training_loss": 440.46661682128905, "training_acc": 55.0, "val_loss": 562.3888549804688, "val_acc": 60.0}
{"epoch": 21, "training_loss": 399.18043823242186, "training_acc": 65.0, "val_loss": 73.91999053955078, "val_acc": 60.0}
{"epoch": 22, "training_loss": 453.4007827758789, "training_acc": 35.0, "val_loss": 1110.4393310546875, "val_acc": 40.0}
{"epoch": 23, "training_loss": 697.39345703125, "training_acc": 55.0, "val_loss": 711.664306640625, "val_acc": 60.0}
{"epoch": 24, "training_loss": 1147.1015625, "training_acc": 45.0, "val_loss": 192.77792358398438, "val_acc": 60.0}
{"epoch": 25, "training_loss": 259.9960144042969, "training_acc": 55.0, "val_loss": 990.1513061523438, "val_acc": 40.0}
{"epoch": 26, "training_loss": 657.4503051757813, "training_acc": 35.0, "val_loss": 854.17138671875, "val_acc": 60.0}
{"epoch": 27, "training_loss": 1233.1138671875, "training_acc": 35.0, "val_loss": 849.6962890625, "val_acc": 40.0}
{"epoch": 28, "training_loss": 1130.9826171875, "training_acc": 45.0, "val_loss": 863.6007690429688, "val_acc": 40.0}
{"epoch": 29, "training_loss": 745.6580833435058, "training_acc": 45.0, "val_loss": 940.9852905273438, "val_acc": 40.0}
{"epoch": 30, "training_loss": 446.81128158569334, "training_acc": 65.0, "val_loss": 1142.5516357421875, "val_acc": 60.0}
{"epoch": 31, "training_loss": 922.2998550415039, "training_acc": 25.0, "val_loss": 2518.83447265625, "val_acc": 40.0}
{"epoch": 32, "training_loss": 1774.763916015625, "training_acc": 55.0, "val_loss": 1637.3465576171875, "val_acc": 60.0}
{"epoch": 33, "training_loss": 2528.4161865234373, "training_acc": 45.0, "val_loss": 1373.7994384765625, "val_acc": 40.0}
{"epoch": 34, "training_loss": 1401.208544921875, "training_acc": 55.0, "val_loss": 595.2782592773438, "val_acc": 60.0}
{"epoch": 35, "training_loss": 973.9760101318359, "training_acc": 45.0, "val_loss": 126.619384765625, "val_acc": 40.0}
{"epoch": 36, "training_loss": 1160.28642578125, "training_acc": 35.0, "val_loss": 2166.550048828125, "val_acc": 40.0}
{"epoch": 37, "training_loss": 3037.3233154296877, "training_acc": 55.0, "val_loss": 293.0633850097656, "val_acc": 60.0}
{"epoch": 38, "training_loss": 771.7603881835937, "training_acc": 35.0, "val_loss": 499.0482482910156, "val_acc": 60.0}
{"epoch": 39, "training_loss": 325.9868911743164, "training_acc": 55.0, "val_loss": 933.9619140625, "val_acc": 40.0}
{"epoch": 40, "training_loss": 660.5003845214844, "training_acc": 35.0, "val_loss": 599.2271728515625, "val_acc": 40.0}
