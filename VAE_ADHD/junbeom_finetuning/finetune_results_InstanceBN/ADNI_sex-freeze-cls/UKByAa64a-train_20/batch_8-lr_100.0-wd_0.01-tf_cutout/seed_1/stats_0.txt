"main_modify.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 1 --task ADNI_sex --input_option yAware --learning_rate 1e2 --batch_size 8 --weight_decay 1e-2 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 8519.899112677575, "training_acc": 55.0, "val_loss": 7526.3330078125, "val_acc": 60.0}
{"epoch": 1, "training_loss": 12013.36669921875, "training_acc": 45.0, "val_loss": 3879.65234375, "val_acc": 60.0}
{"epoch": 2, "training_loss": 5884.95947265625, "training_acc": 35.0, "val_loss": 10253.1396484375, "val_acc": 40.0}
{"epoch": 3, "training_loss": 5998.701806640625, "training_acc": 55.0, "val_loss": 1880.4520263671875, "val_acc": 60.0}
{"epoch": 4, "training_loss": 4159.336474609375, "training_acc": 45.0, "val_loss": 2889.684814453125, "val_acc": 60.0}
{"epoch": 5, "training_loss": 2264.4504272460936, "training_acc": 55.0, "val_loss": 6343.40869140625, "val_acc": 40.0}
{"epoch": 6, "training_loss": 4290.254638671875, "training_acc": 55.0, "val_loss": 100.03392028808594, "val_acc": 40.0}
{"epoch": 7, "training_loss": 3416.249200439453, "training_acc": 45.0, "val_loss": 3566.327392578125, "val_acc": 60.0}
{"epoch": 8, "training_loss": 2455.1808837890626, "training_acc": 55.0, "val_loss": 5681.22314453125, "val_acc": 40.0}
{"epoch": 9, "training_loss": 4333.20224609375, "training_acc": 55.0, "val_loss": 1184.4290771484375, "val_acc": 40.0}
{"epoch": 10, "training_loss": 3517.474072265625, "training_acc": 35.0, "val_loss": 4247.0205078125, "val_acc": 60.0}
{"epoch": 11, "training_loss": 4172.241857910156, "training_acc": 45.0, "val_loss": 3207.23974609375, "val_acc": 40.0}
{"epoch": 12, "training_loss": 2487.8057250976562, "training_acc": 55.0, "val_loss": 57.98794174194336, "val_acc": 60.0}
{"epoch": 13, "training_loss": 535.7514038085938, "training_acc": 45.0, "val_loss": 1561.2332763671875, "val_acc": 40.0}
{"epoch": 14, "training_loss": 1078.9333984375, "training_acc": 55.0, "val_loss": 1092.140869140625, "val_acc": 60.0}
{"epoch": 15, "training_loss": 1767.6707763671875, "training_acc": 45.0, "val_loss": 1450.0394287109375, "val_acc": 40.0}
{"epoch": 16, "training_loss": 1509.345263671875, "training_acc": 55.0, "val_loss": 131.2226104736328, "val_acc": 40.0}
{"epoch": 17, "training_loss": 1650.2581909179687, "training_acc": 55.0, "val_loss": 1335.3465576171875, "val_acc": 60.0}
{"epoch": 18, "training_loss": 1897.035400390625, "training_acc": 45.0, "val_loss": 2711.36328125, "val_acc": 40.0}
{"epoch": 19, "training_loss": 1038.237939453125, "training_acc": 65.0, "val_loss": 2480.924560546875, "val_acc": 60.0}
{"epoch": 20, "training_loss": 2520.202038574219, "training_acc": 45.0, "val_loss": 1633.7423095703125, "val_acc": 40.0}
{"epoch": 21, "training_loss": 819.4365318298339, "training_acc": 65.0, "val_loss": 634.4068603515625, "val_acc": 60.0}
{"epoch": 22, "training_loss": 691.6527587890625, "training_acc": 35.0, "val_loss": 1262.2015380859375, "val_acc": 60.0}
{"epoch": 23, "training_loss": 2002.29140625, "training_acc": 45.0, "val_loss": 2943.715576171875, "val_acc": 40.0}
{"epoch": 24, "training_loss": 2705.76787109375, "training_acc": 55.0, "val_loss": 45.19392013549805, "val_acc": 60.0}
{"epoch": 25, "training_loss": 1111.3836639404296, "training_acc": 45.0, "val_loss": 481.7640686035156, "val_acc": 40.0}
{"epoch": 26, "training_loss": 529.1827209472656, "training_acc": 55.0, "val_loss": 1867.318359375, "val_acc": 60.0}
{"epoch": 27, "training_loss": 3077.557373046875, "training_acc": 45.0, "val_loss": 2108.1328125, "val_acc": 40.0}
{"epoch": 28, "training_loss": 2688.49541015625, "training_acc": 55.0, "val_loss": 1403.0916748046875, "val_acc": 40.0}
{"epoch": 29, "training_loss": 2750.470751953125, "training_acc": 35.0, "val_loss": 1431.88427734375, "val_acc": 60.0}
{"epoch": 30, "training_loss": 2339.51796875, "training_acc": 45.0, "val_loss": 2759.787109375, "val_acc": 40.0}
{"epoch": 31, "training_loss": 901.8756378173828, "training_acc": 55.0, "val_loss": 348.7040710449219, "val_acc": 60.0}
{"epoch": 32, "training_loss": 569.97578125, "training_acc": 65.0, "val_loss": 609.5016479492188, "val_acc": 40.0}
{"epoch": 33, "training_loss": 1689.1870849609375, "training_acc": 35.0, "val_loss": 340.55694580078125, "val_acc": 40.0}
{"epoch": 34, "training_loss": 749.6368713378906, "training_acc": 55.0, "val_loss": 944.0064697265625, "val_acc": 60.0}
{"epoch": 35, "training_loss": 1361.232275390625, "training_acc": 35.0, "val_loss": 1241.385009765625, "val_acc": 40.0}
{"epoch": 36, "training_loss": 865.5287353515625, "training_acc": 45.0, "val_loss": 1091.051025390625, "val_acc": 40.0}
{"epoch": 37, "training_loss": 917.7430236816406, "training_acc": 45.0, "val_loss": 148.85670471191406, "val_acc": 60.0}
{"epoch": 38, "training_loss": 1125.9698303222656, "training_acc": 55.0, "val_loss": 1135.6507568359375, "val_acc": 40.0}
{"epoch": 39, "training_loss": 1465.435009765625, "training_acc": 55.0, "val_loss": 592.8043823242188, "val_acc": 60.0}
{"epoch": 40, "training_loss": 1472.4343505859374, "training_acc": 55.0, "val_loss": 2791.360595703125, "val_acc": 40.0}
{"epoch": 41, "training_loss": 902.1671875, "training_acc": 65.0, "val_loss": 3203.604736328125, "val_acc": 60.0}
{"epoch": 42, "training_loss": 3031.670056152344, "training_acc": 45.0, "val_loss": 5438.23046875, "val_acc": 40.0}
{"epoch": 43, "training_loss": 4883.47490234375, "training_acc": 55.0, "val_loss": 2300.318115234375, "val_acc": 40.0}
