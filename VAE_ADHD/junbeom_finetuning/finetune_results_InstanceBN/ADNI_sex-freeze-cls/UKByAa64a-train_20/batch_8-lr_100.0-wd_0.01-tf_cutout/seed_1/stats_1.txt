"main_modify.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 1 --task ADNI_sex --input_option yAware --learning_rate 1e2 --batch_size 8 --weight_decay 1e-2 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 9810.578680753708, "training_acc": 45.0, "val_loss": 7856.84716796875, "val_acc": 60.0}
{"epoch": 1, "training_loss": 13847.6875, "training_acc": 45.0, "val_loss": 5408.41162109375, "val_acc": 60.0}
{"epoch": 2, "training_loss": 4794.719580078125, "training_acc": 45.0, "val_loss": 11352.9677734375, "val_acc": 40.0}
{"epoch": 3, "training_loss": 8053.5171875, "training_acc": 55.0, "val_loss": 331.2212829589844, "val_acc": 40.0}
{"epoch": 4, "training_loss": 4045.1734985351563, "training_acc": 45.0, "val_loss": 5097.80078125, "val_acc": 60.0}
{"epoch": 5, "training_loss": 3862.3651321411135, "training_acc": 55.0, "val_loss": 4180.24365234375, "val_acc": 40.0}
{"epoch": 6, "training_loss": 4276.21728515625, "training_acc": 55.0, "val_loss": 2783.620849609375, "val_acc": 40.0}
{"epoch": 7, "training_loss": 1566.4552001953125, "training_acc": 55.0, "val_loss": 2837.219970703125, "val_acc": 60.0}
{"epoch": 8, "training_loss": 2436.4082458496096, "training_acc": 45.0, "val_loss": 4103.99169921875, "val_acc": 40.0}
{"epoch": 9, "training_loss": 3807.78525390625, "training_acc": 55.0, "val_loss": 3100.524169921875, "val_acc": 40.0}
{"epoch": 10, "training_loss": 3197.833203125, "training_acc": 25.0, "val_loss": 2146.62939453125, "val_acc": 60.0}
{"epoch": 11, "training_loss": 2291.2986328125, "training_acc": 35.0, "val_loss": 3973.30126953125, "val_acc": 40.0}
{"epoch": 12, "training_loss": 2478.4750244140623, "training_acc": 55.0, "val_loss": 1553.5869140625, "val_acc": 60.0}
{"epoch": 13, "training_loss": 2291.9077880859377, "training_acc": 45.0, "val_loss": 292.02740478515625, "val_acc": 40.0}
{"epoch": 14, "training_loss": 297.38680267333984, "training_acc": 45.0, "val_loss": 1058.03125, "val_acc": 40.0}
{"epoch": 15, "training_loss": 829.6744384765625, "training_acc": 45.0, "val_loss": 356.5245056152344, "val_acc": 60.0}
{"epoch": 16, "training_loss": 1458.877880859375, "training_acc": 35.0, "val_loss": 461.059326171875, "val_acc": 40.0}
{"epoch": 17, "training_loss": 1747.6689697265624, "training_acc": 45.0, "val_loss": 1193.3992919921875, "val_acc": 60.0}
{"epoch": 18, "training_loss": 1292.5282470703125, "training_acc": 55.0, "val_loss": 2009.0418701171875, "val_acc": 40.0}
{"epoch": 19, "training_loss": 652.4156982421875, "training_acc": 65.0, "val_loss": 2426.264404296875, "val_acc": 60.0}
{"epoch": 20, "training_loss": 2494.0192749023436, "training_acc": 45.0, "val_loss": 4067.969970703125, "val_acc": 40.0}
{"epoch": 21, "training_loss": 3861.01064453125, "training_acc": 55.0, "val_loss": 2451.3974609375, "val_acc": 40.0}
{"epoch": 22, "training_loss": 1702.4894775390626, "training_acc": 55.0, "val_loss": 1538.1119384765625, "val_acc": 60.0}
{"epoch": 23, "training_loss": 1337.786083984375, "training_acc": 55.0, "val_loss": 1077.9720458984375, "val_acc": 40.0}
{"epoch": 24, "training_loss": 2271.894775390625, "training_acc": 25.0, "val_loss": 4.249532699584961, "val_acc": 40.0}
{"epoch": 25, "training_loss": 236.90410614013672, "training_acc": 55.0, "val_loss": 536.5149536132812, "val_acc": 60.0}
{"epoch": 26, "training_loss": 432.74955024719236, "training_acc": 45.0, "val_loss": 381.1358947753906, "val_acc": 40.0}
{"epoch": 27, "training_loss": 558.4548706054687, "training_acc": 35.0, "val_loss": 445.2613220214844, "val_acc": 40.0}
{"epoch": 28, "training_loss": 567.1954345703125, "training_acc": 55.0, "val_loss": 1122.6170654296875, "val_acc": 40.0}
{"epoch": 29, "training_loss": 974.382861328125, "training_acc": 55.0, "val_loss": 1772.557861328125, "val_acc": 60.0}
{"epoch": 30, "training_loss": 2324.4889221191406, "training_acc": 45.0, "val_loss": 2423.896240234375, "val_acc": 40.0}
{"epoch": 31, "training_loss": 1931.4821899414062, "training_acc": 55.0, "val_loss": 788.3038940429688, "val_acc": 60.0}
{"epoch": 32, "training_loss": 1208.9165649414062, "training_acc": 35.0, "val_loss": 4.762876987457275, "val_acc": 60.0}
{"epoch": 33, "training_loss": 696.5412269592285, "training_acc": 45.0, "val_loss": 1119.880859375, "val_acc": 60.0}
{"epoch": 34, "training_loss": 1402.31416015625, "training_acc": 45.0, "val_loss": 2293.725341796875, "val_acc": 40.0}
{"epoch": 35, "training_loss": 2408.0279541015625, "training_acc": 55.0, "val_loss": 1093.5474853515625, "val_acc": 60.0}
{"epoch": 36, "training_loss": 1853.4284545898438, "training_acc": 45.0, "val_loss": 676.4367065429688, "val_acc": 40.0}
{"epoch": 37, "training_loss": 1204.2137878417968, "training_acc": 55.0, "val_loss": 1592.141357421875, "val_acc": 60.0}
{"epoch": 38, "training_loss": 2462.69765625, "training_acc": 45.0, "val_loss": 1970.3807373046875, "val_acc": 40.0}
{"epoch": 39, "training_loss": 1487.0291625976563, "training_acc": 55.0, "val_loss": 471.3936462402344, "val_acc": 60.0}
{"epoch": 40, "training_loss": 704.3248657226562, "training_acc": 45.0, "val_loss": 297.7723083496094, "val_acc": 40.0}
{"epoch": 41, "training_loss": 562.9840591430664, "training_acc": 55.0, "val_loss": 1341.2406005859375, "val_acc": 40.0}
{"epoch": 42, "training_loss": 865.8355590820313, "training_acc": 55.0, "val_loss": 441.2981872558594, "val_acc": 60.0}
{"epoch": 43, "training_loss": 1024.76015625, "training_acc": 45.0, "val_loss": 523.7122192382812, "val_acc": 60.0}
