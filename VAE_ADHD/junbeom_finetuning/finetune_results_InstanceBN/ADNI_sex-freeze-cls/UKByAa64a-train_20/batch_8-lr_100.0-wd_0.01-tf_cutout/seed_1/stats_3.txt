"main_modify.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 1 --task ADNI_sex --input_option yAware --learning_rate 1e2 --batch_size 8 --weight_decay 1e-2 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 10350.360334253312, "training_acc": 50.0, "val_loss": 12870.0029296875, "val_acc": 40.0}
{"epoch": 1, "training_loss": 13238.8326171875, "training_acc": 50.0, "val_loss": 9981.71484375, "val_acc": 40.0}
{"epoch": 2, "training_loss": 4629.048211669922, "training_acc": 50.0, "val_loss": 7542.41259765625, "val_acc": 60.0}
{"epoch": 3, "training_loss": 9054.269921875, "training_acc": 50.0, "val_loss": 784.8087768554688, "val_acc": 60.0}
{"epoch": 4, "training_loss": 2036.6196899414062, "training_acc": 70.0, "val_loss": 7521.56787109375, "val_acc": 40.0}
{"epoch": 5, "training_loss": 4453.22314453125, "training_acc": 50.0, "val_loss": 2388.380615234375, "val_acc": 60.0}
{"epoch": 6, "training_loss": 4371.241015625, "training_acc": 50.0, "val_loss": 3104.24951171875, "val_acc": 60.0}
{"epoch": 7, "training_loss": 1571.575537109375, "training_acc": 70.0, "val_loss": 5229.58203125, "val_acc": 40.0}
{"epoch": 8, "training_loss": 4588.594482421875, "training_acc": 50.0, "val_loss": 920.8132934570312, "val_acc": 40.0}
{"epoch": 9, "training_loss": 3182.77578125, "training_acc": 40.0, "val_loss": 3677.693359375, "val_acc": 60.0}
{"epoch": 10, "training_loss": 2446.1007873535154, "training_acc": 60.0, "val_loss": 3854.95556640625, "val_acc": 40.0}
{"epoch": 11, "training_loss": 3320.9662109375, "training_acc": 50.0, "val_loss": 128.03282165527344, "val_acc": 40.0}
{"epoch": 12, "training_loss": 3100.0963928222654, "training_acc": 40.0, "val_loss": 3010.73046875, "val_acc": 60.0}
{"epoch": 13, "training_loss": 2857.64501953125, "training_acc": 40.0, "val_loss": 5631.02001953125, "val_acc": 40.0}
{"epoch": 14, "training_loss": 3639.28388671875, "training_acc": 50.0, "val_loss": 1330.7222900390625, "val_acc": 60.0}
{"epoch": 15, "training_loss": 3217.4630859375, "training_acc": 50.0, "val_loss": 2137.899169921875, "val_acc": 60.0}
{"epoch": 16, "training_loss": 1758.80888671875, "training_acc": 50.0, "val_loss": 3094.3212890625, "val_acc": 40.0}
{"epoch": 17, "training_loss": 2167.6187744140625, "training_acc": 40.0, "val_loss": 1746.068359375, "val_acc": 60.0}
{"epoch": 18, "training_loss": 1818.8846923828125, "training_acc": 40.0, "val_loss": 1758.7703857421875, "val_acc": 40.0}
{"epoch": 19, "training_loss": 872.38505859375, "training_acc": 60.0, "val_loss": 1444.095703125, "val_acc": 60.0}
{"epoch": 20, "training_loss": 1138.9434448242187, "training_acc": 60.0, "val_loss": 1792.805908203125, "val_acc": 40.0}
{"epoch": 21, "training_loss": 930.395556640625, "training_acc": 60.0, "val_loss": 1173.8763427734375, "val_acc": 60.0}
{"epoch": 22, "training_loss": 1412.99140625, "training_acc": 40.0, "val_loss": 1391.1171875, "val_acc": 40.0}
{"epoch": 23, "training_loss": 605.2573852539062, "training_acc": 60.0, "val_loss": 2079.517578125, "val_acc": 60.0}
{"epoch": 24, "training_loss": 1627.964306640625, "training_acc": 60.0, "val_loss": 2006.420166015625, "val_acc": 40.0}
{"epoch": 25, "training_loss": 1832.215283203125, "training_acc": 30.0, "val_loss": 725.3809814453125, "val_acc": 60.0}
{"epoch": 26, "training_loss": 2168.461962890625, "training_acc": 20.0, "val_loss": 51.724700927734375, "val_acc": 40.0}
{"epoch": 27, "training_loss": 2591.1346923828123, "training_acc": 40.0, "val_loss": 1658.640625, "val_acc": 60.0}
{"epoch": 28, "training_loss": 2544.72958984375, "training_acc": 40.0, "val_loss": 3468.109375, "val_acc": 40.0}
{"epoch": 29, "training_loss": 1940.81787109375, "training_acc": 50.0, "val_loss": 2997.139892578125, "val_acc": 60.0}
{"epoch": 30, "training_loss": 2535.3615234375, "training_acc": 50.0, "val_loss": 4068.99462890625, "val_acc": 40.0}
{"epoch": 31, "training_loss": 4624.215771484375, "training_acc": 50.0, "val_loss": 1778.4793701171875, "val_acc": 40.0}
{"epoch": 32, "training_loss": 2937.3662109375, "training_acc": 40.0, "val_loss": 2964.276123046875, "val_acc": 60.0}
{"epoch": 33, "training_loss": 2169.938671875, "training_acc": 50.0, "val_loss": 4983.5703125, "val_acc": 40.0}
{"epoch": 34, "training_loss": 3735.605322265625, "training_acc": 50.0, "val_loss": 1791.5152587890625, "val_acc": 60.0}
{"epoch": 35, "training_loss": 2778.23701171875, "training_acc": 50.0, "val_loss": 370.49169921875, "val_acc": 60.0}
{"epoch": 36, "training_loss": 1685.0619140625, "training_acc": 50.0, "val_loss": 2177.60986328125, "val_acc": 40.0}
{"epoch": 37, "training_loss": 1231.982568359375, "training_acc": 50.0, "val_loss": 1159.9290771484375, "val_acc": 60.0}
{"epoch": 38, "training_loss": 991.6065795898437, "training_acc": 40.0, "val_loss": 786.0177612304688, "val_acc": 60.0}
{"epoch": 39, "training_loss": 1290.8013671875, "training_acc": 30.0, "val_loss": 357.4420166015625, "val_acc": 40.0}
{"epoch": 40, "training_loss": 1302.9296875, "training_acc": 50.0, "val_loss": 623.1852416992188, "val_acc": 60.0}
{"epoch": 41, "training_loss": 1462.96435546875, "training_acc": 50.0, "val_loss": 1849.616455078125, "val_acc": 40.0}
{"epoch": 42, "training_loss": 718.4153503417969, "training_acc": 60.0, "val_loss": 431.07574462890625, "val_acc": 60.0}
{"epoch": 43, "training_loss": 597.6514038085937, "training_acc": 60.0, "val_loss": 286.0041198730469, "val_acc": 60.0}
{"epoch": 44, "training_loss": 459.72144775390626, "training_acc": 50.0, "val_loss": 982.0004272460938, "val_acc": 40.0}
{"epoch": 45, "training_loss": 494.49041442871095, "training_acc": 60.0, "val_loss": 493.6520080566406, "val_acc": 40.0}
