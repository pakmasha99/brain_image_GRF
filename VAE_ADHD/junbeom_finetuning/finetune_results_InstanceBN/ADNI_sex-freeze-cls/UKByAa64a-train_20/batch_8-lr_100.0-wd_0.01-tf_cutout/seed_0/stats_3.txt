"main_modify.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_sex --input_option yAware --learning_rate 1e2 --batch_size 8 --weight_decay 1e-2 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 9791.865097999573, "training_acc": 45.0, "val_loss": 7951.49365234375, "val_acc": 60.0}
{"epoch": 1, "training_loss": 14422.261328125, "training_acc": 45.0, "val_loss": 5566.15283203125, "val_acc": 60.0}
{"epoch": 2, "training_loss": 5031.73076171875, "training_acc": 55.0, "val_loss": 13363.923828125, "val_acc": 40.0}
{"epoch": 3, "training_loss": 9031.467578125, "training_acc": 55.0, "val_loss": 1913.9158935546875, "val_acc": 40.0}
{"epoch": 4, "training_loss": 4920.66259765625, "training_acc": 45.0, "val_loss": 6997.9580078125, "val_acc": 60.0}
{"epoch": 5, "training_loss": 7026.07177734375, "training_acc": 45.0, "val_loss": 2490.42529296875, "val_acc": 40.0}
{"epoch": 6, "training_loss": 4607.56083984375, "training_acc": 55.0, "val_loss": 7814.90625, "val_acc": 40.0}
{"epoch": 7, "training_loss": 3012.052111816406, "training_acc": 55.0, "val_loss": 3434.077880859375, "val_acc": 60.0}
{"epoch": 8, "training_loss": 6183.0583984375, "training_acc": 45.0, "val_loss": 3989.907958984375, "val_acc": 60.0}
{"epoch": 9, "training_loss": 2643.226318359375, "training_acc": 55.0, "val_loss": 6444.515625, "val_acc": 40.0}
{"epoch": 10, "training_loss": 5242.92841796875, "training_acc": 55.0, "val_loss": 3269.348388671875, "val_acc": 40.0}
{"epoch": 11, "training_loss": 2249.3313720703127, "training_acc": 55.0, "val_loss": 3320.167236328125, "val_acc": 60.0}
{"epoch": 12, "training_loss": 3222.226123046875, "training_acc": 45.0, "val_loss": 3579.62353515625, "val_acc": 40.0}
{"epoch": 13, "training_loss": 3793.7921875, "training_acc": 55.0, "val_loss": 3570.202392578125, "val_acc": 40.0}
{"epoch": 14, "training_loss": 687.5283203125, "training_acc": 75.0, "val_loss": 4082.557373046875, "val_acc": 60.0}
{"epoch": 15, "training_loss": 5277.042797851563, "training_acc": 45.0, "val_loss": 56.66730880737305, "val_acc": 40.0}
{"epoch": 16, "training_loss": 1279.2969818115234, "training_acc": 55.0, "val_loss": 1709.4178466796875, "val_acc": 40.0}
{"epoch": 17, "training_loss": 674.429556274414, "training_acc": 55.0, "val_loss": 2850.896484375, "val_acc": 60.0}
{"epoch": 18, "training_loss": 3065.588352966309, "training_acc": 35.0, "val_loss": 1242.5286865234375, "val_acc": 40.0}
{"epoch": 19, "training_loss": 1119.1090087890625, "training_acc": 35.0, "val_loss": 212.7733917236328, "val_acc": 60.0}
{"epoch": 20, "training_loss": 1466.2286376953125, "training_acc": 35.0, "val_loss": 1407.68359375, "val_acc": 40.0}
{"epoch": 21, "training_loss": 748.3255249023438, "training_acc": 55.0, "val_loss": 165.10064697265625, "val_acc": 60.0}
{"epoch": 22, "training_loss": 1047.3853149414062, "training_acc": 55.0, "val_loss": 1122.8704833984375, "val_acc": 40.0}
{"epoch": 23, "training_loss": 1903.808935546875, "training_acc": 35.0, "val_loss": 922.1701049804688, "val_acc": 60.0}
{"epoch": 24, "training_loss": 868.64873046875, "training_acc": 65.0, "val_loss": 1674.946533203125, "val_acc": 40.0}
{"epoch": 25, "training_loss": 930.6249755859375, "training_acc": 45.0, "val_loss": 569.6934814453125, "val_acc": 40.0}
{"epoch": 26, "training_loss": 478.9558166503906, "training_acc": 55.0, "val_loss": 45.2443962097168, "val_acc": 40.0}
{"epoch": 27, "training_loss": 551.9310668945312, "training_acc": 35.0, "val_loss": 431.9132385253906, "val_acc": 60.0}
{"epoch": 28, "training_loss": 515.682080078125, "training_acc": 35.0, "val_loss": 788.0167846679688, "val_acc": 40.0}
{"epoch": 29, "training_loss": 402.75598297119143, "training_acc": 65.0, "val_loss": 487.6458435058594, "val_acc": 60.0}
{"epoch": 30, "training_loss": 361.923681640625, "training_acc": 65.0, "val_loss": 352.372802734375, "val_acc": 60.0}
{"epoch": 31, "training_loss": 554.7762939453125, "training_acc": 45.0, "val_loss": 1845.1881103515625, "val_acc": 40.0}
{"epoch": 32, "training_loss": 1052.2691436767577, "training_acc": 55.0, "val_loss": 1905.1741943359375, "val_acc": 60.0}
{"epoch": 33, "training_loss": 1524.755810546875, "training_acc": 55.0, "val_loss": 3513.925537109375, "val_acc": 40.0}
{"epoch": 34, "training_loss": 2370.337548828125, "training_acc": 55.0, "val_loss": 1601.8662109375, "val_acc": 60.0}
{"epoch": 35, "training_loss": 2352.9760620117186, "training_acc": 45.0, "val_loss": 1522.0306396484375, "val_acc": 40.0}
{"epoch": 36, "training_loss": 1306.66904296875, "training_acc": 55.0, "val_loss": 811.3326416015625, "val_acc": 60.0}
{"epoch": 37, "training_loss": 1318.0721435546875, "training_acc": 35.0, "val_loss": 549.4303588867188, "val_acc": 40.0}
{"epoch": 38, "training_loss": 947.900390625, "training_acc": 45.0, "val_loss": 1494.1119384765625, "val_acc": 40.0}
{"epoch": 39, "training_loss": 1371.9444458007813, "training_acc": 55.0, "val_loss": 626.1279296875, "val_acc": 60.0}
{"epoch": 40, "training_loss": 642.7407073974609, "training_acc": 55.0, "val_loss": 907.93212890625, "val_acc": 40.0}
{"epoch": 41, "training_loss": 523.7488647460938, "training_acc": 45.0, "val_loss": 2532.632080078125, "val_acc": 40.0}
{"epoch": 42, "training_loss": 2098.2716796875, "training_acc": 55.0, "val_loss": 886.7032470703125, "val_acc": 60.0}
{"epoch": 43, "training_loss": 1992.64931640625, "training_acc": 45.0, "val_loss": 1768.3218994140625, "val_acc": 40.0}
{"epoch": 44, "training_loss": 1605.7587036132813, "training_acc": 55.0, "val_loss": 564.1324462890625, "val_acc": 60.0}
{"epoch": 45, "training_loss": 880.6797531127929, "training_acc": 45.0, "val_loss": 3516.850830078125, "val_acc": 40.0}
