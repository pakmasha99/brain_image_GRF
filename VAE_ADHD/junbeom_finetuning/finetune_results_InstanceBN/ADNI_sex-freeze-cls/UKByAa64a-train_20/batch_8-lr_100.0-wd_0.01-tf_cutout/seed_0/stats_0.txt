"main_modify.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_sex --input_option yAware --learning_rate 1e2 --batch_size 8 --weight_decay 1e-2 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 9341.392188024522, "training_acc": 50.0, "val_loss": 10079.3427734375, "val_acc": 40.0}
{"epoch": 1, "training_loss": 9422.570703125, "training_acc": 50.0, "val_loss": 6174.94482421875, "val_acc": 40.0}
{"epoch": 2, "training_loss": 2605.44912109375, "training_acc": 60.0, "val_loss": 5779.6494140625, "val_acc": 60.0}
{"epoch": 3, "training_loss": 5836.497265625, "training_acc": 50.0, "val_loss": 1518.076416015625, "val_acc": 40.0}
{"epoch": 4, "training_loss": 2860.0240234375, "training_acc": 50.0, "val_loss": 4632.35400390625, "val_acc": 40.0}
{"epoch": 5, "training_loss": 1763.393505859375, "training_acc": 60.0, "val_loss": 3142.512939453125, "val_acc": 60.0}
{"epoch": 6, "training_loss": 3732.108349609375, "training_acc": 50.0, "val_loss": 380.8402404785156, "val_acc": 40.0}
{"epoch": 7, "training_loss": 1569.3975402832032, "training_acc": 50.0, "val_loss": 898.4576416015625, "val_acc": 40.0}
{"epoch": 8, "training_loss": 1067.0177001953125, "training_acc": 60.0, "val_loss": 1297.4508056640625, "val_acc": 60.0}
{"epoch": 9, "training_loss": 840.2660522460938, "training_acc": 50.0, "val_loss": 473.5809631347656, "val_acc": 40.0}
{"epoch": 10, "training_loss": 1001.2881713867188, "training_acc": 40.0, "val_loss": 237.94009399414062, "val_acc": 40.0}
{"epoch": 11, "training_loss": 436.85101318359375, "training_acc": 50.0, "val_loss": 204.1321258544922, "val_acc": 60.0}
{"epoch": 12, "training_loss": 255.84096069335936, "training_acc": 70.0, "val_loss": 449.6203308105469, "val_acc": 60.0}
{"epoch": 13, "training_loss": 465.156640625, "training_acc": 40.0, "val_loss": 474.7896423339844, "val_acc": 60.0}
{"epoch": 14, "training_loss": 567.0381759643554, "training_acc": 50.0, "val_loss": 614.728271484375, "val_acc": 60.0}
{"epoch": 15, "training_loss": 924.1653198242187, "training_acc": 40.0, "val_loss": 1316.8905029296875, "val_acc": 40.0}
{"epoch": 16, "training_loss": 1192.11123046875, "training_acc": 40.0, "val_loss": 205.8093719482422, "val_acc": 40.0}
{"epoch": 17, "training_loss": 432.8847290039063, "training_acc": 50.0, "val_loss": 596.0338745117188, "val_acc": 60.0}
{"epoch": 18, "training_loss": 1143.3595458984375, "training_acc": 40.0, "val_loss": 522.5536499023438, "val_acc": 60.0}
{"epoch": 19, "training_loss": 779.2505004882812, "training_acc": 40.0, "val_loss": 148.1887969970703, "val_acc": 60.0}
{"epoch": 20, "training_loss": 460.76165771484375, "training_acc": 40.0, "val_loss": 383.93017578125, "val_acc": 40.0}
{"epoch": 21, "training_loss": 484.2000427246094, "training_acc": 40.0, "val_loss": 125.95928192138672, "val_acc": 40.0}
{"epoch": 22, "training_loss": 1699.090625, "training_acc": 40.0, "val_loss": 542.0233764648438, "val_acc": 60.0}
{"epoch": 23, "training_loss": 1255.8447998046875, "training_acc": 60.0, "val_loss": 2315.772216796875, "val_acc": 40.0}
{"epoch": 24, "training_loss": 1141.779608154297, "training_acc": 50.0, "val_loss": 3434.325927734375, "val_acc": 60.0}
{"epoch": 25, "training_loss": 3441.1701904296874, "training_acc": 40.0, "val_loss": 2435.943115234375, "val_acc": 40.0}
{"epoch": 26, "training_loss": 1511.122265625, "training_acc": 50.0, "val_loss": 1277.6488037109375, "val_acc": 60.0}
{"epoch": 27, "training_loss": 1200.983056640625, "training_acc": 50.0, "val_loss": 2773.17822265625, "val_acc": 40.0}
{"epoch": 28, "training_loss": 1064.42119140625, "training_acc": 70.0, "val_loss": 2184.0732421875, "val_acc": 60.0}
{"epoch": 29, "training_loss": 1876.2081909179688, "training_acc": 50.0, "val_loss": 4090.791015625, "val_acc": 40.0}
{"epoch": 30, "training_loss": 4110.019921875, "training_acc": 50.0, "val_loss": 251.3793182373047, "val_acc": 60.0}
{"epoch": 31, "training_loss": 825.0799072265625, "training_acc": 50.0, "val_loss": 220.95718383789062, "val_acc": 60.0}
{"epoch": 32, "training_loss": 1290.4601440429688, "training_acc": 50.0, "val_loss": 28.60675621032715, "val_acc": 40.0}
{"epoch": 33, "training_loss": 1026.1694915771484, "training_acc": 70.0, "val_loss": 1888.9058837890625, "val_acc": 60.0}
{"epoch": 34, "training_loss": 1029.5719604492188, "training_acc": 50.0, "val_loss": 369.1928405761719, "val_acc": 40.0}
{"epoch": 35, "training_loss": 591.260693359375, "training_acc": 60.0, "val_loss": 797.9053955078125, "val_acc": 40.0}
{"epoch": 36, "training_loss": 915.47470703125, "training_acc": 20.0, "val_loss": 1018.7496337890625, "val_acc": 40.0}
{"epoch": 37, "training_loss": 1394.068115234375, "training_acc": 40.0, "val_loss": 762.1757202148438, "val_acc": 40.0}
{"epoch": 38, "training_loss": 713.6460235595703, "training_acc": 50.0, "val_loss": 181.7404022216797, "val_acc": 40.0}
{"epoch": 39, "training_loss": 569.5215637207032, "training_acc": 50.0, "val_loss": 2019.0145263671875, "val_acc": 40.0}
{"epoch": 40, "training_loss": 1703.6992797851562, "training_acc": 50.0, "val_loss": 1832.0699462890625, "val_acc": 60.0}
{"epoch": 41, "training_loss": 2027.046435546875, "training_acc": 50.0, "val_loss": 3116.105224609375, "val_acc": 40.0}
{"epoch": 42, "training_loss": 2744.214990234375, "training_acc": 50.0, "val_loss": 1223.6492919921875, "val_acc": 60.0}
{"epoch": 43, "training_loss": 2754.681103515625, "training_acc": 50.0, "val_loss": 1260.446533203125, "val_acc": 40.0}
{"epoch": 44, "training_loss": 1018.519320678711, "training_acc": 50.0, "val_loss": 938.4080200195312, "val_acc": 60.0}
{"epoch": 45, "training_loss": 882.5358245849609, "training_acc": 60.0, "val_loss": 1332.856689453125, "val_acc": 40.0}
{"epoch": 46, "training_loss": 653.7124084472656, "training_acc": 60.0, "val_loss": 1950.1995849609375, "val_acc": 60.0}
{"epoch": 47, "training_loss": 1850.8217895507812, "training_acc": 50.0, "val_loss": 3558.246826171875, "val_acc": 40.0}
{"epoch": 48, "training_loss": 2785.3616943359375, "training_acc": 40.0, "val_loss": 2372.01171875, "val_acc": 60.0}
{"epoch": 49, "training_loss": 1971.256884765625, "training_acc": 50.0, "val_loss": 4363.97802734375, "val_acc": 40.0}
{"epoch": 50, "training_loss": 2775.4005126953125, "training_acc": 50.0, "val_loss": 1846.4207763671875, "val_acc": 60.0}
{"epoch": 51, "training_loss": 1440.413592529297, "training_acc": 60.0, "val_loss": 2904.782470703125, "val_acc": 40.0}
