"main_modify.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 5 --task ADNI_sex --input_option yAware --learning_rate 1e2 --batch_size 8 --weight_decay 1e-2 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 12732.365849614143, "training_acc": 30.0, "val_loss": 11218.0107421875, "val_acc": 40.0}
{"epoch": 1, "training_loss": 12305.064453125, "training_acc": 50.0, "val_loss": 10729.9423828125, "val_acc": 40.0}
{"epoch": 2, "training_loss": 5398.697729492187, "training_acc": 50.0, "val_loss": 9756.3671875, "val_acc": 60.0}
{"epoch": 3, "training_loss": 11725.12734375, "training_acc": 50.0, "val_loss": 3483.255615234375, "val_acc": 60.0}
{"epoch": 4, "training_loss": 4003.20478515625, "training_acc": 40.0, "val_loss": 9941.1015625, "val_acc": 40.0}
{"epoch": 5, "training_loss": 7784.043603515625, "training_acc": 50.0, "val_loss": 1753.911376953125, "val_acc": 40.0}
{"epoch": 6, "training_loss": 2609.0970703125, "training_acc": 50.0, "val_loss": 5050.87255859375, "val_acc": 60.0}
{"epoch": 7, "training_loss": 5109.85166015625, "training_acc": 50.0, "val_loss": 1451.5751953125, "val_acc": 40.0}
{"epoch": 8, "training_loss": 3631.4276123046875, "training_acc": 50.0, "val_loss": 4024.199951171875, "val_acc": 40.0}
{"epoch": 9, "training_loss": 1796.50029296875, "training_acc": 60.0, "val_loss": 3537.88916015625, "val_acc": 60.0}
{"epoch": 10, "training_loss": 4224.3880859375, "training_acc": 50.0, "val_loss": 230.80101013183594, "val_acc": 60.0}
{"epoch": 11, "training_loss": 2140.2709716796876, "training_acc": 50.0, "val_loss": 5512.708984375, "val_acc": 40.0}
{"epoch": 12, "training_loss": 3358.2285278320314, "training_acc": 40.0, "val_loss": 1431.438232421875, "val_acc": 60.0}
{"epoch": 13, "training_loss": 1890.71064453125, "training_acc": 50.0, "val_loss": 1274.1151123046875, "val_acc": 40.0}
{"epoch": 14, "training_loss": 1158.2964111328124, "training_acc": 30.0, "val_loss": 524.9928588867188, "val_acc": 40.0}
{"epoch": 15, "training_loss": 520.5492797851563, "training_acc": 30.0, "val_loss": 81.99837493896484, "val_acc": 60.0}
{"epoch": 16, "training_loss": 214.09765625, "training_acc": 50.0, "val_loss": 136.46575927734375, "val_acc": 60.0}
{"epoch": 17, "training_loss": 1022.8249206542969, "training_acc": 40.0, "val_loss": 147.3440399169922, "val_acc": 40.0}
{"epoch": 18, "training_loss": 1156.3959228515625, "training_acc": 50.0, "val_loss": 788.1551513671875, "val_acc": 60.0}
{"epoch": 19, "training_loss": 1619.53955078125, "training_acc": 40.0, "val_loss": 1495.5291748046875, "val_acc": 40.0}
{"epoch": 20, "training_loss": 1085.85302734375, "training_acc": 50.0, "val_loss": 579.2133178710938, "val_acc": 60.0}
{"epoch": 21, "training_loss": 294.59776916503904, "training_acc": 80.0, "val_loss": 347.2328186035156, "val_acc": 40.0}
{"epoch": 22, "training_loss": 1079.8007568359376, "training_acc": 50.0, "val_loss": 205.3225555419922, "val_acc": 60.0}
{"epoch": 23, "training_loss": 1917.1602661132813, "training_acc": 40.0, "val_loss": 2424.06982421875, "val_acc": 40.0}
{"epoch": 24, "training_loss": 1704.1064819335938, "training_acc": 40.0, "val_loss": 566.1573486328125, "val_acc": 60.0}
{"epoch": 25, "training_loss": 785.7105346679688, "training_acc": 60.0, "val_loss": 988.6295166015625, "val_acc": 40.0}
{"epoch": 26, "training_loss": 1076.9471435546875, "training_acc": 50.0, "val_loss": 68.2386245727539, "val_acc": 60.0}
{"epoch": 27, "training_loss": 1174.7883178710938, "training_acc": 60.0, "val_loss": 1809.1226806640625, "val_acc": 40.0}
{"epoch": 28, "training_loss": 2426.80009765625, "training_acc": 30.0, "val_loss": 962.0992431640625, "val_acc": 60.0}
{"epoch": 29, "training_loss": 381.858349609375, "training_acc": 80.0, "val_loss": 1673.1990966796875, "val_acc": 40.0}
{"epoch": 30, "training_loss": 969.276904296875, "training_acc": 50.0, "val_loss": 2395.707275390625, "val_acc": 60.0}
{"epoch": 31, "training_loss": 2081.453271484375, "training_acc": 50.0, "val_loss": 2572.427001953125, "val_acc": 40.0}
{"epoch": 32, "training_loss": 1331.8237609863281, "training_acc": 60.0, "val_loss": 1092.2359619140625, "val_acc": 60.0}
{"epoch": 33, "training_loss": 1075.4310302734375, "training_acc": 50.0, "val_loss": 1615.5616455078125, "val_acc": 40.0}
{"epoch": 34, "training_loss": 519.0044799804688, "training_acc": 70.0, "val_loss": 2170.248779296875, "val_acc": 60.0}
{"epoch": 35, "training_loss": 2279.7684326171875, "training_acc": 40.0, "val_loss": 1308.9197998046875, "val_acc": 40.0}
{"epoch": 36, "training_loss": 578.0299621582031, "training_acc": 40.0, "val_loss": 893.2957153320312, "val_acc": 60.0}
{"epoch": 37, "training_loss": 1031.2713500976563, "training_acc": 50.0, "val_loss": 3625.337646484375, "val_acc": 40.0}
{"epoch": 38, "training_loss": 3233.456396484375, "training_acc": 50.0, "val_loss": 549.3451538085938, "val_acc": 60.0}
{"epoch": 39, "training_loss": 1461.63046875, "training_acc": 50.0, "val_loss": 414.435302734375, "val_acc": 40.0}
{"epoch": 40, "training_loss": 503.496411895752, "training_acc": 50.0, "val_loss": 399.4548034667969, "val_acc": 40.0}
{"epoch": 41, "training_loss": 405.80395965576173, "training_acc": 50.0, "val_loss": 1878.663330078125, "val_acc": 40.0}
{"epoch": 42, "training_loss": 1082.6805694580078, "training_acc": 50.0, "val_loss": 2417.141357421875, "val_acc": 60.0}
{"epoch": 43, "training_loss": 3431.941162109375, "training_acc": 50.0, "val_loss": 1135.5885009765625, "val_acc": 40.0}
{"epoch": 44, "training_loss": 1554.8595703125, "training_acc": 50.0, "val_loss": 268.74169921875, "val_acc": 60.0}
{"epoch": 45, "training_loss": 840.6594848632812, "training_acc": 50.0, "val_loss": 2063.196533203125, "val_acc": 40.0}
