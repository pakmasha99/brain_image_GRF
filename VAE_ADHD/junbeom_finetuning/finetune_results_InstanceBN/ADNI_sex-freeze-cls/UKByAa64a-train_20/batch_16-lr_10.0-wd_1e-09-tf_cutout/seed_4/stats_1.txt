"main_modify.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 4 --task ADNI_sex --input_option yAware --learning_rate 1e1 --batch_size 16 --weight_decay 1e-9 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 428.3348587989807, "training_acc": 50.0, "val_loss": 536.3234252929688, "val_acc": 60.0}
{"epoch": 1, "training_loss": 756.47421875, "training_acc": 50.0, "val_loss": 1869.7005615234375, "val_acc": 40.0}
{"epoch": 2, "training_loss": 1516.12294921875, "training_acc": 50.0, "val_loss": 699.35986328125, "val_acc": 40.0}
{"epoch": 3, "training_loss": 455.35118713378904, "training_acc": 60.0, "val_loss": 963.0336303710938, "val_acc": 60.0}
{"epoch": 4, "training_loss": 1353.66845703125, "training_acc": 50.0, "val_loss": 1024.2564697265625, "val_acc": 60.0}
{"epoch": 5, "training_loss": 1174.1006469726562, "training_acc": 50.0, "val_loss": 20.68659782409668, "val_acc": 60.0}
{"epoch": 6, "training_loss": 288.28126220703126, "training_acc": 40.0, "val_loss": 1561.2406005859375, "val_acc": 40.0}
{"epoch": 7, "training_loss": 1346.465625, "training_acc": 50.0, "val_loss": 1516.027099609375, "val_acc": 40.0}
{"epoch": 8, "training_loss": 1184.3096923828125, "training_acc": 50.0, "val_loss": 349.8548583984375, "val_acc": 40.0}
{"epoch": 9, "training_loss": 397.2061767578125, "training_acc": 40.0, "val_loss": 636.5276489257812, "val_acc": 60.0}
{"epoch": 10, "training_loss": 813.608935546875, "training_acc": 50.0, "val_loss": 619.0037231445312, "val_acc": 60.0}
{"epoch": 11, "training_loss": 686.0005859375, "training_acc": 50.0, "val_loss": 74.7475814819336, "val_acc": 40.0}
{"epoch": 12, "training_loss": 121.43481750488282, "training_acc": 50.0, "val_loss": 509.482421875, "val_acc": 40.0}
{"epoch": 13, "training_loss": 385.303173828125, "training_acc": 50.0, "val_loss": 97.96417236328125, "val_acc": 60.0}
{"epoch": 14, "training_loss": 139.71963500976562, "training_acc": 50.0, "val_loss": 322.5174255371094, "val_acc": 60.0}
{"epoch": 15, "training_loss": 375.4897705078125, "training_acc": 50.0, "val_loss": 13.180292129516602, "val_acc": 40.0}
{"epoch": 16, "training_loss": 28.888050079345703, "training_acc": 55.0, "val_loss": 8.822354316711426, "val_acc": 40.0}
{"epoch": 17, "training_loss": 27.56840934753418, "training_acc": 65.0, "val_loss": 282.4162292480469, "val_acc": 60.0}
{"epoch": 18, "training_loss": 329.590234375, "training_acc": 50.0, "val_loss": 61.93367385864258, "val_acc": 40.0}
{"epoch": 19, "training_loss": 73.21912841796875, "training_acc": 50.0, "val_loss": 97.16213989257812, "val_acc": 40.0}
{"epoch": 20, "training_loss": 69.45176544189454, "training_acc": 60.0, "val_loss": 233.90420532226562, "val_acc": 60.0}
{"epoch": 21, "training_loss": 277.4414520263672, "training_acc": 50.0, "val_loss": 4.6411004066467285, "val_acc": 60.0}
{"epoch": 22, "training_loss": 14.822772407531739, "training_acc": 65.0, "val_loss": 66.43577575683594, "val_acc": 60.0}
{"epoch": 23, "training_loss": 69.79037699699401, "training_acc": 40.0, "val_loss": 113.59481048583984, "val_acc": 60.0}
{"epoch": 24, "training_loss": 124.03666687011719, "training_acc": 50.0, "val_loss": 208.0670928955078, "val_acc": 40.0}
{"epoch": 25, "training_loss": 175.4343719482422, "training_acc": 50.0, "val_loss": 43.09012985229492, "val_acc": 40.0}
{"epoch": 26, "training_loss": 49.25361022949219, "training_acc": 60.0, "val_loss": 385.6130065917969, "val_acc": 60.0}
{"epoch": 27, "training_loss": 472.42926025390625, "training_acc": 50.0, "val_loss": 229.072509765625, "val_acc": 60.0}
{"epoch": 28, "training_loss": 231.30743484497071, "training_acc": 50.0, "val_loss": 166.1544189453125, "val_acc": 40.0}
{"epoch": 29, "training_loss": 112.56767768859864, "training_acc": 50.0, "val_loss": 218.457763671875, "val_acc": 60.0}
{"epoch": 30, "training_loss": 281.9686767578125, "training_acc": 50.0, "val_loss": 165.201904296875, "val_acc": 60.0}
{"epoch": 31, "training_loss": 182.97252197265624, "training_acc": 50.0, "val_loss": 246.7100830078125, "val_acc": 40.0}
{"epoch": 32, "training_loss": 177.25950317382814, "training_acc": 50.0, "val_loss": 174.1558380126953, "val_acc": 60.0}
{"epoch": 33, "training_loss": 219.19178771972656, "training_acc": 50.0, "val_loss": 171.62957763671875, "val_acc": 60.0}
{"epoch": 34, "training_loss": 204.2436294555664, "training_acc": 40.0, "val_loss": 2.186707019805908, "val_acc": 80.0}
{"epoch": 35, "training_loss": 7.593206357955933, "training_acc": 85.0, "val_loss": 65.10140991210938, "val_acc": 60.0}
{"epoch": 36, "training_loss": 84.81083221435547, "training_acc": 50.0, "val_loss": 133.07933044433594, "val_acc": 40.0}
{"epoch": 37, "training_loss": 63.26312255859375, "training_acc": 70.0, "val_loss": 154.8696746826172, "val_acc": 60.0}
{"epoch": 38, "training_loss": 173.06204833984376, "training_acc": 50.0, "val_loss": 169.6740264892578, "val_acc": 40.0}
{"epoch": 39, "training_loss": 142.8837890625, "training_acc": 50.0, "val_loss": 8.420534133911133, "val_acc": 40.0}
{"epoch": 40, "training_loss": 68.92691574096679, "training_acc": 55.0, "val_loss": 326.94659423828125, "val_acc": 60.0}
{"epoch": 41, "training_loss": 380.3223510742188, "training_acc": 50.0, "val_loss": 29.50693130493164, "val_acc": 40.0}
{"epoch": 42, "training_loss": 24.899537658691408, "training_acc": 50.0, "val_loss": 26.796478271484375, "val_acc": 40.0}
{"epoch": 43, "training_loss": 9.290227508544922, "training_acc": 75.0, "val_loss": 229.995849609375, "val_acc": 60.0}
{"epoch": 44, "training_loss": 265.47337646484374, "training_acc": 50.0, "val_loss": 126.8828353881836, "val_acc": 40.0}
{"epoch": 45, "training_loss": 144.21376342773436, "training_acc": 50.0, "val_loss": 65.61985778808594, "val_acc": 40.0}
{"epoch": 46, "training_loss": 186.179736328125, "training_acc": 30.0, "val_loss": 267.82940673828125, "val_acc": 60.0}
{"epoch": 47, "training_loss": 266.5398803710938, "training_acc": 50.0, "val_loss": 419.1681823730469, "val_acc": 40.0}
{"epoch": 48, "training_loss": 422.4153076171875, "training_acc": 50.0, "val_loss": 651.9168090820312, "val_acc": 40.0}
{"epoch": 49, "training_loss": 488.00855712890626, "training_acc": 50.0, "val_loss": 121.99226379394531, "val_acc": 60.0}
{"epoch": 50, "training_loss": 182.4462158203125, "training_acc": 50.0, "val_loss": 254.2896728515625, "val_acc": 60.0}
{"epoch": 51, "training_loss": 270.7278579711914, "training_acc": 50.0, "val_loss": 372.3021545410156, "val_acc": 40.0}
{"epoch": 52, "training_loss": 316.4274963378906, "training_acc": 50.0, "val_loss": 571.7089233398438, "val_acc": 40.0}
{"epoch": 53, "training_loss": 421.1105224609375, "training_acc": 50.0, "val_loss": 87.88602447509766, "val_acc": 60.0}
