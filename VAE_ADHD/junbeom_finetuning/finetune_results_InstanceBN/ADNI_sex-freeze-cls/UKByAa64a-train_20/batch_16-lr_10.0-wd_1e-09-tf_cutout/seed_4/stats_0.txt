"main_modify.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 4 --task ADNI_sex --input_option yAware --learning_rate 1e1 --batch_size 16 --weight_decay 1e-9 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 426.5123805999756, "training_acc": 50.0, "val_loss": 721.1969604492188, "val_acc": 40.0}
{"epoch": 1, "training_loss": 900.4852294921875, "training_acc": 40.0, "val_loss": 1103.9354248046875, "val_acc": 60.0}
{"epoch": 2, "training_loss": 1333.5769897460937, "training_acc": 50.0, "val_loss": 303.7321472167969, "val_acc": 60.0}
{"epoch": 3, "training_loss": 499.21942138671875, "training_acc": 40.0, "val_loss": 864.7015991210938, "val_acc": 40.0}
{"epoch": 4, "training_loss": 719.470703125, "training_acc": 50.0, "val_loss": 322.5453796386719, "val_acc": 40.0}
{"epoch": 5, "training_loss": 204.92050170898438, "training_acc": 60.0, "val_loss": 344.285400390625, "val_acc": 60.0}
{"epoch": 6, "training_loss": 413.5608245849609, "training_acc": 50.0, "val_loss": 75.3025894165039, "val_acc": 60.0}
{"epoch": 7, "training_loss": 202.50307006835936, "training_acc": 40.0, "val_loss": 551.9513549804688, "val_acc": 40.0}
{"epoch": 8, "training_loss": 404.3522094726562, "training_acc": 50.0, "val_loss": 181.0457000732422, "val_acc": 60.0}
{"epoch": 9, "training_loss": 236.5439208984375, "training_acc": 50.0, "val_loss": 370.03057861328125, "val_acc": 60.0}
{"epoch": 10, "training_loss": 415.88759765625, "training_acc": 50.0, "val_loss": 145.19081115722656, "val_acc": 40.0}
{"epoch": 11, "training_loss": 127.93256530761718, "training_acc": 50.0, "val_loss": 229.6460418701172, "val_acc": 40.0}
{"epoch": 12, "training_loss": 160.54595184326172, "training_acc": 50.0, "val_loss": 46.08062744140625, "val_acc": 60.0}
{"epoch": 13, "training_loss": 99.40670776367188, "training_acc": 40.0, "val_loss": 112.04705047607422, "val_acc": 40.0}
{"epoch": 14, "training_loss": 115.59884643554688, "training_acc": 50.0, "val_loss": 222.4912872314453, "val_acc": 60.0}
{"epoch": 15, "training_loss": 234.49429779052736, "training_acc": 50.0, "val_loss": 287.091552734375, "val_acc": 40.0}
{"epoch": 16, "training_loss": 256.0602661132813, "training_acc": 50.0, "val_loss": 277.2062683105469, "val_acc": 40.0}
{"epoch": 17, "training_loss": 274.9008422851563, "training_acc": 30.0, "val_loss": 40.325138092041016, "val_acc": 60.0}
{"epoch": 18, "training_loss": 48.41087646484375, "training_acc": 60.0, "val_loss": 407.0924072265625, "val_acc": 40.0}
{"epoch": 19, "training_loss": 324.67989959716795, "training_acc": 50.0, "val_loss": 28.49285888671875, "val_acc": 40.0}
{"epoch": 20, "training_loss": 133.11485443115234, "training_acc": 40.0, "val_loss": 366.6332092285156, "val_acc": 60.0}
{"epoch": 21, "training_loss": 410.56903076171875, "training_acc": 50.0, "val_loss": 26.107059478759766, "val_acc": 40.0}
{"epoch": 22, "training_loss": 36.33310775756836, "training_acc": 50.0, "val_loss": 10.77541446685791, "val_acc": 60.0}
{"epoch": 23, "training_loss": 17.317032241821288, "training_acc": 70.0, "val_loss": 12.800920486450195, "val_acc": 40.0}
{"epoch": 24, "training_loss": 21.902149200439453, "training_acc": 75.0, "val_loss": 307.3760070800781, "val_acc": 40.0}
{"epoch": 25, "training_loss": 213.50565185546876, "training_acc": 50.0, "val_loss": 258.27093505859375, "val_acc": 60.0}
{"epoch": 26, "training_loss": 302.4587890625, "training_acc": 50.0, "val_loss": 536.0322265625, "val_acc": 60.0}
{"epoch": 27, "training_loss": 639.4011474609375, "training_acc": 50.0, "val_loss": 289.3006286621094, "val_acc": 60.0}
{"epoch": 28, "training_loss": 281.90750885009766, "training_acc": 50.0, "val_loss": 311.11712646484375, "val_acc": 40.0}
{"epoch": 29, "training_loss": 245.279833984375, "training_acc": 50.0, "val_loss": 43.53107452392578, "val_acc": 40.0}
{"epoch": 30, "training_loss": 120.03798370361328, "training_acc": 40.0, "val_loss": 297.9598083496094, "val_acc": 60.0}
{"epoch": 31, "training_loss": 301.99005737304685, "training_acc": 50.0, "val_loss": 266.9264831542969, "val_acc": 40.0}
{"epoch": 32, "training_loss": 258.8330383300781, "training_acc": 50.0, "val_loss": 462.66656494140625, "val_acc": 40.0}
{"epoch": 33, "training_loss": 352.52858276367186, "training_acc": 50.0, "val_loss": 161.9941864013672, "val_acc": 60.0}
{"epoch": 34, "training_loss": 199.2379577636719, "training_acc": 50.0, "val_loss": 142.41519165039062, "val_acc": 60.0}
{"epoch": 35, "training_loss": 142.93280639648438, "training_acc": 50.0, "val_loss": 257.4983825683594, "val_acc": 40.0}
{"epoch": 36, "training_loss": 177.62212295532225, "training_acc": 50.0, "val_loss": 199.1053924560547, "val_acc": 60.0}
{"epoch": 37, "training_loss": 278.8957763671875, "training_acc": 50.0, "val_loss": 88.2489242553711, "val_acc": 60.0}
{"epoch": 38, "training_loss": 47.683023071289064, "training_acc": 70.0, "val_loss": 793.3549194335938, "val_acc": 40.0}
{"epoch": 39, "training_loss": 655.1524658203125, "training_acc": 50.0, "val_loss": 899.37890625, "val_acc": 40.0}
{"epoch": 40, "training_loss": 679.7440063476563, "training_acc": 50.0, "val_loss": 106.1156234741211, "val_acc": 40.0}
{"epoch": 41, "training_loss": 306.105126953125, "training_acc": 30.0, "val_loss": 638.388671875, "val_acc": 60.0}
