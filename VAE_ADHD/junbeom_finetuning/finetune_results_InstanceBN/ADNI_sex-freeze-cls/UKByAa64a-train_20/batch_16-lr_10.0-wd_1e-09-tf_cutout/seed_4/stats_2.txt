"main_modify.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 4 --task ADNI_sex --input_option yAware --learning_rate 1e1 --batch_size 16 --weight_decay 1e-9 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 641.9835894584655, "training_acc": 40.0, "val_loss": 611.4779663085938, "val_acc": 60.0}
{"epoch": 1, "training_loss": 785.7253662109375, "training_acc": 50.0, "val_loss": 1738.013916015625, "val_acc": 40.0}
{"epoch": 2, "training_loss": 1448.11376953125, "training_acc": 50.0, "val_loss": 983.0053100585938, "val_acc": 40.0}
{"epoch": 3, "training_loss": 668.7405563354492, "training_acc": 50.0, "val_loss": 364.9947204589844, "val_acc": 60.0}
{"epoch": 4, "training_loss": 469.008203125, "training_acc": 50.0, "val_loss": 73.65846252441406, "val_acc": 60.0}
{"epoch": 5, "training_loss": 251.8187744140625, "training_acc": 40.0, "val_loss": 882.5945434570312, "val_acc": 40.0}
{"epoch": 6, "training_loss": 713.907861328125, "training_acc": 50.0, "val_loss": 345.13360595703125, "val_acc": 40.0}
{"epoch": 7, "training_loss": 279.3179656982422, "training_acc": 50.0, "val_loss": 394.0002136230469, "val_acc": 60.0}
{"epoch": 8, "training_loss": 485.3815582275391, "training_acc": 50.0, "val_loss": 229.7243194580078, "val_acc": 60.0}
{"epoch": 9, "training_loss": 204.29889640808105, "training_acc": 60.0, "val_loss": 297.19287109375, "val_acc": 40.0}
{"epoch": 10, "training_loss": 238.7093933105469, "training_acc": 50.0, "val_loss": 19.798999786376953, "val_acc": 60.0}
{"epoch": 11, "training_loss": 21.470465850830077, "training_acc": 50.0, "val_loss": 112.80742645263672, "val_acc": 60.0}
{"epoch": 12, "training_loss": 122.92285461425782, "training_acc": 50.0, "val_loss": 250.284912109375, "val_acc": 40.0}
{"epoch": 13, "training_loss": 207.27980194091796, "training_acc": 50.0, "val_loss": 130.30975341796875, "val_acc": 40.0}
{"epoch": 14, "training_loss": 123.62847900390625, "training_acc": 50.0, "val_loss": 214.283203125, "val_acc": 60.0}
{"epoch": 15, "training_loss": 218.49619750976564, "training_acc": 50.0, "val_loss": 419.43585205078125, "val_acc": 40.0}
{"epoch": 16, "training_loss": 366.979052734375, "training_acc": 50.0, "val_loss": 804.7936401367188, "val_acc": 40.0}
{"epoch": 17, "training_loss": 640.6302001953125, "training_acc": 50.0, "val_loss": 219.23046875, "val_acc": 40.0}
{"epoch": 18, "training_loss": 281.9597534179687, "training_acc": 40.0, "val_loss": 490.9375, "val_acc": 60.0}
{"epoch": 19, "training_loss": 609.48115234375, "training_acc": 50.0, "val_loss": 273.7530822753906, "val_acc": 60.0}
{"epoch": 20, "training_loss": 290.3549285888672, "training_acc": 50.0, "val_loss": 392.91455078125, "val_acc": 40.0}
{"epoch": 21, "training_loss": 324.28688354492186, "training_acc": 50.0, "val_loss": 131.67726135253906, "val_acc": 40.0}
{"epoch": 22, "training_loss": 183.72923583984374, "training_acc": 40.0, "val_loss": 297.08404541015625, "val_acc": 60.0}
{"epoch": 23, "training_loss": 342.42496185302736, "training_acc": 50.0, "val_loss": 37.65729522705078, "val_acc": 40.0}
{"epoch": 24, "training_loss": 30.097761344909667, "training_acc": 50.0, "val_loss": 60.09580612182617, "val_acc": 60.0}
{"epoch": 25, "training_loss": 53.733259963989255, "training_acc": 50.0, "val_loss": 57.51152420043945, "val_acc": 60.0}
{"epoch": 26, "training_loss": 52.308903503417966, "training_acc": 50.0, "val_loss": 54.49319076538086, "val_acc": 60.0}
{"epoch": 27, "training_loss": 48.56617965698242, "training_acc": 50.0, "val_loss": 51.278480529785156, "val_acc": 60.0}
{"epoch": 28, "training_loss": 34.67328655719757, "training_acc": 60.0, "val_loss": 6.238717555999756, "val_acc": 40.0}
{"epoch": 29, "training_loss": 2.4150971814990045, "training_acc": 90.0, "val_loss": 194.09030151367188, "val_acc": 40.0}
{"epoch": 30, "training_loss": 149.4922332763672, "training_acc": 50.0, "val_loss": 88.28565979003906, "val_acc": 60.0}
{"epoch": 31, "training_loss": 92.33638305664063, "training_acc": 50.0, "val_loss": 94.05914306640625, "val_acc": 40.0}
{"epoch": 32, "training_loss": 72.61662902832032, "training_acc": 50.0, "val_loss": 142.2707061767578, "val_acc": 60.0}
{"epoch": 33, "training_loss": 160.35634155273436, "training_acc": 50.0, "val_loss": 29.1502685546875, "val_acc": 40.0}
{"epoch": 34, "training_loss": 19.7478759765625, "training_acc": 55.0, "val_loss": 41.906097412109375, "val_acc": 60.0}
{"epoch": 35, "training_loss": 46.39817352294922, "training_acc": 50.0, "val_loss": 84.62352752685547, "val_acc": 40.0}
{"epoch": 36, "training_loss": 82.53860168457031, "training_acc": 50.0, "val_loss": 160.72520446777344, "val_acc": 60.0}
{"epoch": 37, "training_loss": 146.3952762901783, "training_acc": 55.0, "val_loss": 85.96212005615234, "val_acc": 40.0}
{"epoch": 38, "training_loss": 80.8233428955078, "training_acc": 40.0, "val_loss": 97.3575668334961, "val_acc": 40.0}
{"epoch": 39, "training_loss": 71.93073468208313, "training_acc": 50.0, "val_loss": 136.22801208496094, "val_acc": 60.0}
{"epoch": 40, "training_loss": 149.9724365234375, "training_acc": 50.0, "val_loss": 33.932708740234375, "val_acc": 40.0}
{"epoch": 41, "training_loss": 35.27724914550781, "training_acc": 50.0, "val_loss": 12.822253227233887, "val_acc": 40.0}
{"epoch": 42, "training_loss": 19.993172454833985, "training_acc": 55.0, "val_loss": 221.74954223632812, "val_acc": 40.0}
{"epoch": 43, "training_loss": 180.71207275390626, "training_acc": 50.0, "val_loss": 78.72530364990234, "val_acc": 40.0}
{"epoch": 44, "training_loss": 95.10470886230469, "training_acc": 50.0, "val_loss": 248.49462890625, "val_acc": 60.0}
{"epoch": 45, "training_loss": 253.1744873046875, "training_acc": 50.0, "val_loss": 209.5630645751953, "val_acc": 40.0}
{"epoch": 46, "training_loss": 185.87301940917968, "training_acc": 50.0, "val_loss": 247.0167999267578, "val_acc": 40.0}
{"epoch": 47, "training_loss": 192.88457336425782, "training_acc": 40.0, "val_loss": 15.064981460571289, "val_acc": 40.0}
