"main_modify.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_sex --input_option yAware --learning_rate 1e1 --batch_size 16 --weight_decay 1e-9 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 643.606387424469, "training_acc": 35.0, "val_loss": 996.8649291992188, "val_acc": 40.0}
{"epoch": 1, "training_loss": 728.811328125, "training_acc": 55.0, "val_loss": 967.7306518554688, "val_acc": 60.0}
{"epoch": 2, "training_loss": 1303.7255004882813, "training_acc": 45.0, "val_loss": 403.1269226074219, "val_acc": 60.0}
{"epoch": 3, "training_loss": 429.8802764892578, "training_acc": 55.0, "val_loss": 884.5206298828125, "val_acc": 40.0}
{"epoch": 4, "training_loss": 667.5041442871094, "training_acc": 55.0, "val_loss": 729.1757202148438, "val_acc": 40.0}
{"epoch": 5, "training_loss": 460.712744140625, "training_acc": 55.0, "val_loss": 409.8275451660156, "val_acc": 60.0}
{"epoch": 6, "training_loss": 612.1064086914063, "training_acc": 45.0, "val_loss": 540.4923706054688, "val_acc": 60.0}
{"epoch": 7, "training_loss": 700.862515258789, "training_acc": 45.0, "val_loss": 303.7288818359375, "val_acc": 40.0}
{"epoch": 8, "training_loss": 300.6287475585938, "training_acc": 55.0, "val_loss": 393.50323486328125, "val_acc": 40.0}
{"epoch": 9, "training_loss": 196.4821081161499, "training_acc": 65.0, "val_loss": 163.75254821777344, "val_acc": 60.0}
{"epoch": 10, "training_loss": 202.3722137451172, "training_acc": 45.0, "val_loss": 313.5621032714844, "val_acc": 40.0}
{"epoch": 11, "training_loss": 249.77719116210938, "training_acc": 55.0, "val_loss": 245.5999755859375, "val_acc": 40.0}
{"epoch": 12, "training_loss": 209.8644287109375, "training_acc": 45.0, "val_loss": 121.332275390625, "val_acc": 60.0}
{"epoch": 13, "training_loss": 131.43290786743165, "training_acc": 55.0, "val_loss": 240.559814453125, "val_acc": 40.0}
{"epoch": 14, "training_loss": 148.49859619140625, "training_acc": 55.0, "val_loss": 223.30654907226562, "val_acc": 60.0}
{"epoch": 15, "training_loss": 319.1482208251953, "training_acc": 45.0, "val_loss": 258.5843200683594, "val_acc": 60.0}
{"epoch": 16, "training_loss": 326.3370290756226, "training_acc": 45.0, "val_loss": 451.8081970214844, "val_acc": 40.0}
{"epoch": 17, "training_loss": 329.358642578125, "training_acc": 55.0, "val_loss": 684.24462890625, "val_acc": 40.0}
{"epoch": 18, "training_loss": 478.7881591796875, "training_acc": 55.0, "val_loss": 98.10228729248047, "val_acc": 40.0}
{"epoch": 19, "training_loss": 85.9847412109375, "training_acc": 65.0, "val_loss": 654.6869506835938, "val_acc": 60.0}
{"epoch": 20, "training_loss": 916.6811157226563, "training_acc": 45.0, "val_loss": 603.2164916992188, "val_acc": 60.0}
{"epoch": 21, "training_loss": 788.9637878417968, "training_acc": 45.0, "val_loss": 150.29856872558594, "val_acc": 40.0}
{"epoch": 22, "training_loss": 146.90911254882812, "training_acc": 55.0, "val_loss": 423.6420593261719, "val_acc": 40.0}
{"epoch": 23, "training_loss": 304.69130859375, "training_acc": 55.0, "val_loss": 102.505859375, "val_acc": 60.0}
{"epoch": 24, "training_loss": 150.77874145507812, "training_acc": 45.0, "val_loss": 324.60113525390625, "val_acc": 40.0}
{"epoch": 25, "training_loss": 266.518212890625, "training_acc": 55.0, "val_loss": 495.17626953125, "val_acc": 40.0}
{"epoch": 26, "training_loss": 297.73778076171874, "training_acc": 55.0, "val_loss": 229.41506958007812, "val_acc": 60.0}
{"epoch": 27, "training_loss": 318.57080078125, "training_acc": 45.0, "val_loss": 468.321533203125, "val_acc": 60.0}
{"epoch": 28, "training_loss": 619.4044921875, "training_acc": 45.0, "val_loss": 127.3200454711914, "val_acc": 60.0}
{"epoch": 29, "training_loss": 162.12808837890626, "training_acc": 55.0, "val_loss": 804.4508666992188, "val_acc": 40.0}
{"epoch": 30, "training_loss": 634.2523681640625, "training_acc": 55.0, "val_loss": 754.8834228515625, "val_acc": 40.0}
{"epoch": 31, "training_loss": 479.6328857421875, "training_acc": 55.0, "val_loss": 203.66189575195312, "val_acc": 60.0}
{"epoch": 32, "training_loss": 303.22401733398436, "training_acc": 45.0, "val_loss": 443.3678894042969, "val_acc": 60.0}
{"epoch": 33, "training_loss": 572.569140625, "training_acc": 45.0, "val_loss": 19.4849853515625, "val_acc": 40.0}
{"epoch": 34, "training_loss": 81.72664642333984, "training_acc": 70.0, "val_loss": 677.7652587890625, "val_acc": 40.0}
{"epoch": 35, "training_loss": 481.4442626953125, "training_acc": 55.0, "val_loss": 239.7427978515625, "val_acc": 40.0}
{"epoch": 36, "training_loss": 236.60233154296876, "training_acc": 45.0, "val_loss": 368.85064697265625, "val_acc": 60.0}
{"epoch": 37, "training_loss": 496.09917602539065, "training_acc": 45.0, "val_loss": 44.3994255065918, "val_acc": 60.0}
{"epoch": 38, "training_loss": 88.66717224121093, "training_acc": 55.0, "val_loss": 896.2831420898438, "val_acc": 40.0}
{"epoch": 39, "training_loss": 692.3652587890625, "training_acc": 55.0, "val_loss": 834.4642944335938, "val_acc": 40.0}
{"epoch": 40, "training_loss": 567.79638671875, "training_acc": 55.0, "val_loss": 101.80522918701172, "val_acc": 60.0}
{"epoch": 41, "training_loss": 226.74853515625, "training_acc": 45.0, "val_loss": 103.20609283447266, "val_acc": 60.0}
{"epoch": 42, "training_loss": 212.37158203125, "training_acc": 35.0, "val_loss": 499.5888366699219, "val_acc": 40.0}
{"epoch": 43, "training_loss": 334.08232421875, "training_acc": 55.0, "val_loss": 45.87704086303711, "val_acc": 40.0}
{"epoch": 44, "training_loss": 80.66608581542968, "training_acc": 65.0, "val_loss": 399.9429626464844, "val_acc": 60.0}
{"epoch": 45, "training_loss": 532.603759765625, "training_acc": 45.0, "val_loss": 85.95341491699219, "val_acc": 60.0}
{"epoch": 46, "training_loss": 225.2592041015625, "training_acc": 35.0, "val_loss": 675.3123779296875, "val_acc": 40.0}
{"epoch": 47, "training_loss": 482.39326171875, "training_acc": 55.0, "val_loss": 477.83648681640625, "val_acc": 40.0}
{"epoch": 48, "training_loss": 280.34911193847654, "training_acc": 55.0, "val_loss": 219.30406188964844, "val_acc": 60.0}
{"epoch": 49, "training_loss": 319.97686157226565, "training_acc": 45.0, "val_loss": 336.8047790527344, "val_acc": 60.0}
{"epoch": 50, "training_loss": 422.2757873535156, "training_acc": 45.0, "val_loss": 225.88108825683594, "val_acc": 40.0}
{"epoch": 51, "training_loss": 176.32119140625, "training_acc": 55.0, "val_loss": 390.556884765625, "val_acc": 40.0}
{"epoch": 52, "training_loss": 204.0694580078125, "training_acc": 55.0, "val_loss": 273.11920166015625, "val_acc": 60.0}
