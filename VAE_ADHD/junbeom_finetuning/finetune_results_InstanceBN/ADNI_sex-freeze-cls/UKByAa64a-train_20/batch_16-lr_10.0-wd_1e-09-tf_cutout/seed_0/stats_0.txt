"main_modify.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_sex --input_option yAware --learning_rate 1e1 --batch_size 16 --weight_decay 1e-9 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 640.5814022064209, "training_acc": 50.0, "val_loss": 772.8222045898438, "val_acc": 40.0}
{"epoch": 1, "training_loss": 728.7261474609375, "training_acc": 50.0, "val_loss": 1363.1158447265625, "val_acc": 60.0}
{"epoch": 2, "training_loss": 1693.3703735351562, "training_acc": 50.0, "val_loss": 1041.5357666015625, "val_acc": 60.0}
{"epoch": 3, "training_loss": 1112.1515258789063, "training_acc": 50.0, "val_loss": 402.53759765625, "val_acc": 40.0}
{"epoch": 4, "training_loss": 436.8179443359375, "training_acc": 50.0, "val_loss": 1172.7662353515625, "val_acc": 40.0}
{"epoch": 5, "training_loss": 927.1603759765625, "training_acc": 50.0, "val_loss": 326.2795715332031, "val_acc": 40.0}
{"epoch": 6, "training_loss": 309.50023193359374, "training_acc": 50.0, "val_loss": 689.9074096679688, "val_acc": 60.0}
{"epoch": 7, "training_loss": 873.7019775390625, "training_acc": 50.0, "val_loss": 623.5789184570312, "val_acc": 60.0}
{"epoch": 8, "training_loss": 695.1027099609375, "training_acc": 50.0, "val_loss": 245.2682647705078, "val_acc": 40.0}
{"epoch": 9, "training_loss": 225.90626220703126, "training_acc": 50.0, "val_loss": 686.2815551757812, "val_acc": 40.0}
{"epoch": 10, "training_loss": 540.6006103515625, "training_acc": 50.0, "val_loss": 108.3995590209961, "val_acc": 40.0}
{"epoch": 11, "training_loss": 158.1725830078125, "training_acc": 50.0, "val_loss": 562.5347900390625, "val_acc": 60.0}
{"epoch": 12, "training_loss": 695.2251098632812, "training_acc": 50.0, "val_loss": 388.88433837890625, "val_acc": 60.0}
{"epoch": 13, "training_loss": 432.41283798217773, "training_acc": 50.0, "val_loss": 567.4449462890625, "val_acc": 40.0}
{"epoch": 14, "training_loss": 490.21917724609375, "training_acc": 50.0, "val_loss": 917.21435546875, "val_acc": 40.0}
{"epoch": 15, "training_loss": 721.542822265625, "training_acc": 50.0, "val_loss": 252.19859313964844, "val_acc": 40.0}
{"epoch": 16, "training_loss": 243.09068603515624, "training_acc": 50.0, "val_loss": 576.1942749023438, "val_acc": 60.0}
{"epoch": 17, "training_loss": 723.176123046875, "training_acc": 50.0, "val_loss": 524.669921875, "val_acc": 60.0}
{"epoch": 18, "training_loss": 606.4386383056641, "training_acc": 50.0, "val_loss": 183.5381317138672, "val_acc": 40.0}
{"epoch": 19, "training_loss": 215.3223388671875, "training_acc": 50.0, "val_loss": 276.6707458496094, "val_acc": 40.0}
{"epoch": 20, "training_loss": 235.7443817138672, "training_acc": 40.0, "val_loss": 101.2323226928711, "val_acc": 60.0}
{"epoch": 21, "training_loss": 127.73398132324219, "training_acc": 40.0, "val_loss": 15.17265510559082, "val_acc": 60.0}
{"epoch": 22, "training_loss": 38.42983818054199, "training_acc": 70.0, "val_loss": 130.00230407714844, "val_acc": 60.0}
{"epoch": 23, "training_loss": 110.95209884643555, "training_acc": 60.0, "val_loss": 154.66819763183594, "val_acc": 40.0}
{"epoch": 24, "training_loss": 99.9567124247551, "training_acc": 55.0, "val_loss": 175.03115844726562, "val_acc": 60.0}
{"epoch": 25, "training_loss": 197.72210845947265, "training_acc": 50.0, "val_loss": 30.18861198425293, "val_acc": 60.0}
{"epoch": 26, "training_loss": 75.76466064453125, "training_acc": 50.0, "val_loss": 468.615966796875, "val_acc": 40.0}
{"epoch": 27, "training_loss": 357.7452697753906, "training_acc": 50.0, "val_loss": 47.71012496948242, "val_acc": 60.0}
{"epoch": 28, "training_loss": 38.93251953125, "training_acc": 50.0, "val_loss": 92.17723846435547, "val_acc": 60.0}
{"epoch": 29, "training_loss": 71.66873111724854, "training_acc": 60.0, "val_loss": 99.45295715332031, "val_acc": 40.0}
{"epoch": 30, "training_loss": 76.13359146118164, "training_acc": 50.0, "val_loss": 29.851825714111328, "val_acc": 60.0}
{"epoch": 31, "training_loss": 111.3429946899414, "training_acc": 35.0, "val_loss": 108.4745101928711, "val_acc": 40.0}
{"epoch": 32, "training_loss": 79.2387466430664, "training_acc": 60.0, "val_loss": 337.2701110839844, "val_acc": 60.0}
{"epoch": 33, "training_loss": 394.84091796875, "training_acc": 50.0, "val_loss": 199.342529296875, "val_acc": 60.0}
{"epoch": 34, "training_loss": 162.08828125, "training_acc": 65.0, "val_loss": 286.6029052734375, "val_acc": 40.0}
{"epoch": 35, "training_loss": 239.50165100097655, "training_acc": 50.0, "val_loss": 27.619007110595703, "val_acc": 40.0}
{"epoch": 36, "training_loss": 87.21070098876953, "training_acc": 55.0, "val_loss": 384.78936767578125, "val_acc": 60.0}
{"epoch": 37, "training_loss": 436.9463623046875, "training_acc": 50.0, "val_loss": 26.4090633392334, "val_acc": 60.0}
{"epoch": 38, "training_loss": 113.05292587280273, "training_acc": 50.0, "val_loss": 942.1680908203125, "val_acc": 40.0}
{"epoch": 39, "training_loss": 778.5934387207031, "training_acc": 50.0, "val_loss": 843.4470825195312, "val_acc": 40.0}
{"epoch": 40, "training_loss": 666.4684051513672, "training_acc": 50.0, "val_loss": 23.39055824279785, "val_acc": 60.0}
