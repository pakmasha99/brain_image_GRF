"main_modify.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 3 --task ADNI_sex --input_option yAware --learning_rate 1e1 --batch_size 16 --weight_decay 1e-9 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 427.20402135848997, "training_acc": 50.0, "val_loss": 977.3226928710938, "val_acc": 40.0}
{"epoch": 1, "training_loss": 998.1081298828125, "training_acc": 40.0, "val_loss": 793.533447265625, "val_acc": 60.0}
{"epoch": 2, "training_loss": 992.2458984375, "training_acc": 50.0, "val_loss": 34.12622833251953, "val_acc": 60.0}
{"epoch": 3, "training_loss": 264.3855407714844, "training_acc": 40.0, "val_loss": 1025.3563232421875, "val_acc": 40.0}
{"epoch": 4, "training_loss": 824.9925598144531, "training_acc": 50.0, "val_loss": 230.4323272705078, "val_acc": 40.0}
{"epoch": 5, "training_loss": 237.99271240234376, "training_acc": 50.0, "val_loss": 559.847900390625, "val_acc": 60.0}
{"epoch": 6, "training_loss": 695.2357238769531, "training_acc": 50.0, "val_loss": 330.580322265625, "val_acc": 60.0}
{"epoch": 7, "training_loss": 337.2022575378418, "training_acc": 50.0, "val_loss": 189.64915466308594, "val_acc": 40.0}
{"epoch": 8, "training_loss": 118.84654846191407, "training_acc": 50.0, "val_loss": 308.63458251953125, "val_acc": 60.0}
{"epoch": 9, "training_loss": 423.7043212890625, "training_acc": 50.0, "val_loss": 363.5625915527344, "val_acc": 60.0}
{"epoch": 10, "training_loss": 399.37208251953126, "training_acc": 50.0, "val_loss": 425.6908264160156, "val_acc": 40.0}
{"epoch": 11, "training_loss": 363.61689453125, "training_acc": 50.0, "val_loss": 737.416015625, "val_acc": 40.0}
{"epoch": 12, "training_loss": 560.1322143554687, "training_acc": 50.0, "val_loss": 29.872161865234375, "val_acc": 40.0}
{"epoch": 13, "training_loss": 67.25502243041993, "training_acc": 60.0, "val_loss": 793.5429077148438, "val_acc": 60.0}
{"epoch": 14, "training_loss": 1031.98212890625, "training_acc": 50.0, "val_loss": 869.4269409179688, "val_acc": 60.0}
{"epoch": 15, "training_loss": 1039.068408203125, "training_acc": 50.0, "val_loss": 268.2441711425781, "val_acc": 60.0}
{"epoch": 16, "training_loss": 269.3268280029297, "training_acc": 60.0, "val_loss": 854.4349975585938, "val_acc": 40.0}
{"epoch": 17, "training_loss": 711.4285400390625, "training_acc": 50.0, "val_loss": 1077.2034912109375, "val_acc": 40.0}
{"epoch": 18, "training_loss": 839.51845703125, "training_acc": 50.0, "val_loss": 382.0290222167969, "val_acc": 40.0}
{"epoch": 19, "training_loss": 286.7214752197266, "training_acc": 50.0, "val_loss": 421.61968994140625, "val_acc": 60.0}
{"epoch": 20, "training_loss": 559.3470581054687, "training_acc": 50.0, "val_loss": 272.52484130859375, "val_acc": 60.0}
{"epoch": 21, "training_loss": 293.81634826660155, "training_acc": 50.0, "val_loss": 335.1119689941406, "val_acc": 40.0}
{"epoch": 22, "training_loss": 248.93084716796875, "training_acc": 50.0, "val_loss": 2.511899709701538, "val_acc": 80.0}
{"epoch": 23, "training_loss": 30.030759429931642, "training_acc": 50.0, "val_loss": 261.7697448730469, "val_acc": 40.0}
{"epoch": 24, "training_loss": 210.64033203125, "training_acc": 50.0, "val_loss": 37.44276809692383, "val_acc": 40.0}
{"epoch": 25, "training_loss": 33.68060150146484, "training_acc": 80.0, "val_loss": 349.67803955078125, "val_acc": 60.0}
{"epoch": 26, "training_loss": 448.07867431640625, "training_acc": 50.0, "val_loss": 13.407938003540039, "val_acc": 60.0}
{"epoch": 27, "training_loss": 124.95176391601562, "training_acc": 50.0, "val_loss": 1039.5992431640625, "val_acc": 40.0}
{"epoch": 28, "training_loss": 844.0844482421875, "training_acc": 50.0, "val_loss": 1035.8790283203125, "val_acc": 40.0}
{"epoch": 29, "training_loss": 759.8486083984375, "training_acc": 50.0, "val_loss": 137.75564575195312, "val_acc": 40.0}
{"epoch": 30, "training_loss": 246.4795654296875, "training_acc": 40.0, "val_loss": 701.9100341796875, "val_acc": 60.0}
{"epoch": 31, "training_loss": 902.0178161621094, "training_acc": 50.0, "val_loss": 699.9736328125, "val_acc": 60.0}
{"epoch": 32, "training_loss": 820.2644409179687, "training_acc": 50.0, "val_loss": 105.98563385009766, "val_acc": 60.0}
{"epoch": 33, "training_loss": 215.6576904296875, "training_acc": 50.0, "val_loss": 1087.7425537109375, "val_acc": 40.0}
{"epoch": 34, "training_loss": 919.1642578125, "training_acc": 50.0, "val_loss": 1125.629638671875, "val_acc": 40.0}
{"epoch": 35, "training_loss": 830.7818725585937, "training_acc": 50.0, "val_loss": 120.5135269165039, "val_acc": 40.0}
{"epoch": 36, "training_loss": 237.2427001953125, "training_acc": 40.0, "val_loss": 694.0155639648438, "val_acc": 60.0}
{"epoch": 37, "training_loss": 915.70869140625, "training_acc": 50.0, "val_loss": 604.1517944335938, "val_acc": 60.0}
{"epoch": 38, "training_loss": 699.7191162109375, "training_acc": 50.0, "val_loss": 202.212646484375, "val_acc": 40.0}
{"epoch": 39, "training_loss": 148.86886291503907, "training_acc": 50.0, "val_loss": 702.1148681640625, "val_acc": 40.0}
{"epoch": 40, "training_loss": 526.9056518554687, "training_acc": 50.0, "val_loss": 235.6630096435547, "val_acc": 40.0}
{"epoch": 41, "training_loss": 176.1323669433594, "training_acc": 50.0, "val_loss": 439.4896545410156, "val_acc": 60.0}
