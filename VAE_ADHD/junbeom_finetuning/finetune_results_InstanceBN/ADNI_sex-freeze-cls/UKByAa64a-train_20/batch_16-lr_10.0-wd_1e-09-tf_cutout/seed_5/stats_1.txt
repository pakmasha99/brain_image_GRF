"main_modify.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 5 --task ADNI_sex --input_option yAware --learning_rate 1e1 --batch_size 16 --weight_decay 1e-9 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 428.284849691391, "training_acc": 45.0, "val_loss": 935.2725830078125, "val_acc": 40.0}
{"epoch": 1, "training_loss": 556.9690551757812, "training_acc": 65.0, "val_loss": 1342.9949951171875, "val_acc": 60.0}
{"epoch": 2, "training_loss": 1813.9851684570312, "training_acc": 45.0, "val_loss": 678.0867309570312, "val_acc": 60.0}
{"epoch": 3, "training_loss": 683.5297058105468, "training_acc": 55.0, "val_loss": 740.1322631835938, "val_acc": 40.0}
{"epoch": 4, "training_loss": 557.3438537597656, "training_acc": 55.0, "val_loss": 517.9869384765625, "val_acc": 40.0}
{"epoch": 5, "training_loss": 264.19640655517577, "training_acc": 65.0, "val_loss": 203.68544006347656, "val_acc": 60.0}
{"epoch": 6, "training_loss": 253.46462783813476, "training_acc": 35.0, "val_loss": 202.4711456298828, "val_acc": 60.0}
{"epoch": 7, "training_loss": 251.41369018554687, "training_acc": 45.0, "val_loss": 296.0503845214844, "val_acc": 40.0}
{"epoch": 8, "training_loss": 228.20841369628906, "training_acc": 55.0, "val_loss": 258.45556640625, "val_acc": 40.0}
{"epoch": 9, "training_loss": 171.55679626464843, "training_acc": 55.0, "val_loss": 93.09227752685547, "val_acc": 60.0}
{"epoch": 10, "training_loss": 104.26522064208984, "training_acc": 55.0, "val_loss": 278.609130859375, "val_acc": 40.0}
{"epoch": 11, "training_loss": 177.3119140625, "training_acc": 55.0, "val_loss": 320.3253479003906, "val_acc": 60.0}
{"epoch": 12, "training_loss": 479.1466796875, "training_acc": 45.0, "val_loss": 465.4423828125, "val_acc": 60.0}
{"epoch": 13, "training_loss": 553.769482421875, "training_acc": 45.0, "val_loss": 319.63739013671875, "val_acc": 40.0}
{"epoch": 14, "training_loss": 239.0293212890625, "training_acc": 55.0, "val_loss": 917.7064819335938, "val_acc": 40.0}
{"epoch": 15, "training_loss": 686.0481750488282, "training_acc": 55.0, "val_loss": 748.0791015625, "val_acc": 40.0}
{"epoch": 16, "training_loss": 526.5567901611328, "training_acc": 55.0, "val_loss": 112.19840240478516, "val_acc": 60.0}
{"epoch": 17, "training_loss": 172.55072021484375, "training_acc": 45.0, "val_loss": 117.95391082763672, "val_acc": 60.0}
{"epoch": 18, "training_loss": 210.7989013671875, "training_acc": 35.0, "val_loss": 289.1777038574219, "val_acc": 40.0}
{"epoch": 19, "training_loss": 167.95400848388672, "training_acc": 55.0, "val_loss": 301.20758056640625, "val_acc": 60.0}
{"epoch": 20, "training_loss": 469.00408935546875, "training_acc": 45.0, "val_loss": 348.2006530761719, "val_acc": 60.0}
{"epoch": 21, "training_loss": 396.18321380615237, "training_acc": 45.0, "val_loss": 558.6666259765625, "val_acc": 40.0}
{"epoch": 22, "training_loss": 561.00283203125, "training_acc": 55.0, "val_loss": 862.46875, "val_acc": 40.0}
{"epoch": 23, "training_loss": 617.1859466552735, "training_acc": 55.0, "val_loss": 55.24812698364258, "val_acc": 40.0}
{"epoch": 24, "training_loss": 244.36485900878907, "training_acc": 35.0, "val_loss": 491.2228088378906, "val_acc": 60.0}
{"epoch": 25, "training_loss": 639.9262451171875, "training_acc": 45.0, "val_loss": 113.98357391357422, "val_acc": 60.0}
{"epoch": 26, "training_loss": 197.02708740234374, "training_acc": 45.0, "val_loss": 766.9163208007812, "val_acc": 40.0}
{"epoch": 27, "training_loss": 621.52890625, "training_acc": 55.0, "val_loss": 555.3759155273438, "val_acc": 40.0}
{"epoch": 28, "training_loss": 370.53669858349315, "training_acc": 60.0, "val_loss": 327.4684753417969, "val_acc": 60.0}
{"epoch": 29, "training_loss": 471.16419677734376, "training_acc": 45.0, "val_loss": 399.9595642089844, "val_acc": 60.0}
{"epoch": 30, "training_loss": 465.2262817382813, "training_acc": 45.0, "val_loss": 325.71942138671875, "val_acc": 40.0}
{"epoch": 31, "training_loss": 302.8947509765625, "training_acc": 55.0, "val_loss": 770.3856811523438, "val_acc": 40.0}
{"epoch": 32, "training_loss": 554.0723510742188, "training_acc": 55.0, "val_loss": 280.3110046386719, "val_acc": 40.0}
{"epoch": 33, "training_loss": 200.8019287109375, "training_acc": 55.0, "val_loss": 318.9711608886719, "val_acc": 60.0}
{"epoch": 34, "training_loss": 421.204248046875, "training_acc": 45.0, "val_loss": 88.35784149169922, "val_acc": 60.0}
{"epoch": 35, "training_loss": 205.79735717773437, "training_acc": 35.0, "val_loss": 552.1608276367188, "val_acc": 40.0}
{"epoch": 36, "training_loss": 401.3077392578125, "training_acc": 55.0, "val_loss": 159.0310516357422, "val_acc": 40.0}
{"epoch": 37, "training_loss": 62.98729248046875, "training_acc": 75.0, "val_loss": 433.240234375, "val_acc": 60.0}
{"epoch": 38, "training_loss": 631.943701171875, "training_acc": 45.0, "val_loss": 293.3853454589844, "val_acc": 60.0}
{"epoch": 39, "training_loss": 395.4092163085937, "training_acc": 35.0, "val_loss": 345.6108703613281, "val_acc": 40.0}
{"epoch": 40, "training_loss": 253.21201171875, "training_acc": 55.0, "val_loss": 105.49848937988281, "val_acc": 40.0}
{"epoch": 41, "training_loss": 96.6061279296875, "training_acc": 55.0, "val_loss": 224.3573760986328, "val_acc": 60.0}
{"epoch": 42, "training_loss": 268.3228302001953, "training_acc": 45.0, "val_loss": 234.5663604736328, "val_acc": 40.0}
