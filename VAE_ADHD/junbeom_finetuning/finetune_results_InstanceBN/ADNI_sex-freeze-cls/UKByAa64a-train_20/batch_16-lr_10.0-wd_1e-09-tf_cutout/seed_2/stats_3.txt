"main_modify.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 2 --task ADNI_sex --input_option yAware --learning_rate 1e1 --batch_size 16 --weight_decay 1e-9 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 633.375784111023, "training_acc": 45.0, "val_loss": 446.84228515625, "val_acc": 60.0}
{"epoch": 1, "training_loss": 747.296630859375, "training_acc": 45.0, "val_loss": 2311.927001953125, "val_acc": 40.0}
{"epoch": 2, "training_loss": 1734.11123046875, "training_acc": 55.0, "val_loss": 2115.828125, "val_acc": 40.0}
{"epoch": 3, "training_loss": 1476.306103515625, "training_acc": 55.0, "val_loss": 474.9486999511719, "val_acc": 40.0}
{"epoch": 4, "training_loss": 400.3462280273437, "training_acc": 55.0, "val_loss": 910.0160522460938, "val_acc": 60.0}
{"epoch": 5, "training_loss": 1269.530126953125, "training_acc": 45.0, "val_loss": 783.5079956054688, "val_acc": 60.0}
{"epoch": 6, "training_loss": 1024.089370727539, "training_acc": 45.0, "val_loss": 254.69810485839844, "val_acc": 40.0}
{"epoch": 7, "training_loss": 297.76051025390626, "training_acc": 55.0, "val_loss": 575.6712036132812, "val_acc": 40.0}
{"epoch": 8, "training_loss": 368.8043273925781, "training_acc": 55.0, "val_loss": 274.4769592285156, "val_acc": 60.0}
{"epoch": 9, "training_loss": 394.4343963623047, "training_acc": 45.0, "val_loss": 403.23486328125, "val_acc": 60.0}
{"epoch": 10, "training_loss": 485.72564697265625, "training_acc": 45.0, "val_loss": 321.91455078125, "val_acc": 40.0}
{"epoch": 11, "training_loss": 241.793359375, "training_acc": 55.0, "val_loss": 844.3173217773438, "val_acc": 40.0}
{"epoch": 12, "training_loss": 648.446484375, "training_acc": 55.0, "val_loss": 415.0787658691406, "val_acc": 40.0}
{"epoch": 13, "training_loss": 280.1752960205078, "training_acc": 55.0, "val_loss": 380.3856506347656, "val_acc": 60.0}
{"epoch": 14, "training_loss": 519.866064453125, "training_acc": 45.0, "val_loss": 218.2554168701172, "val_acc": 60.0}
{"epoch": 15, "training_loss": 227.99410705566407, "training_acc": 55.0, "val_loss": 456.0038146972656, "val_acc": 40.0}
{"epoch": 16, "training_loss": 342.0244445800781, "training_acc": 55.0, "val_loss": 360.8160705566406, "val_acc": 40.0}
{"epoch": 17, "training_loss": 238.78720159891526, "training_acc": 60.0, "val_loss": 216.96792602539062, "val_acc": 60.0}
{"epoch": 18, "training_loss": 316.02275390625, "training_acc": 45.0, "val_loss": 49.67094039916992, "val_acc": 40.0}
{"epoch": 19, "training_loss": 89.23494262695313, "training_acc": 55.0, "val_loss": 79.33746337890625, "val_acc": 40.0}
{"epoch": 20, "training_loss": 135.1786865234375, "training_acc": 45.0, "val_loss": 220.61473083496094, "val_acc": 60.0}
{"epoch": 21, "training_loss": 249.84974670410156, "training_acc": 45.0, "val_loss": 435.0345764160156, "val_acc": 40.0}
{"epoch": 22, "training_loss": 362.06346435546874, "training_acc": 55.0, "val_loss": 626.8801879882812, "val_acc": 40.0}
{"epoch": 23, "training_loss": 441.7477081298828, "training_acc": 55.0, "val_loss": 19.455854415893555, "val_acc": 60.0}
{"epoch": 24, "training_loss": 42.21565551757813, "training_acc": 45.0, "val_loss": 159.9554901123047, "val_acc": 40.0}
{"epoch": 25, "training_loss": 124.89837646484375, "training_acc": 55.0, "val_loss": 4.7507429122924805, "val_acc": 60.0}
{"epoch": 26, "training_loss": 35.60214099287987, "training_acc": 90.0, "val_loss": 107.71870422363281, "val_acc": 60.0}
{"epoch": 27, "training_loss": 138.51513671875, "training_acc": 45.0, "val_loss": 209.16111755371094, "val_acc": 40.0}
{"epoch": 28, "training_loss": 119.61746520996094, "training_acc": 55.0, "val_loss": 284.24664306640625, "val_acc": 60.0}
{"epoch": 29, "training_loss": 407.278076171875, "training_acc": 45.0, "val_loss": 335.8581237792969, "val_acc": 60.0}
{"epoch": 30, "training_loss": 419.62947235107424, "training_acc": 45.0, "val_loss": 355.208740234375, "val_acc": 40.0}
{"epoch": 31, "training_loss": 261.5024658203125, "training_acc": 55.0, "val_loss": 641.6911010742188, "val_acc": 40.0}
{"epoch": 32, "training_loss": 461.71461181640626, "training_acc": 55.0, "val_loss": 150.23374938964844, "val_acc": 40.0}
{"epoch": 33, "training_loss": 157.16739501953126, "training_acc": 55.0, "val_loss": 492.4717712402344, "val_acc": 60.0}
{"epoch": 34, "training_loss": 667.4727172851562, "training_acc": 45.0, "val_loss": 311.1890563964844, "val_acc": 60.0}
{"epoch": 35, "training_loss": 350.29533767700195, "training_acc": 45.0, "val_loss": 251.7895050048828, "val_acc": 40.0}
{"epoch": 36, "training_loss": 179.39591064453126, "training_acc": 55.0, "val_loss": 23.112380981445312, "val_acc": 40.0}
{"epoch": 37, "training_loss": 4.091027069091797, "training_acc": 80.0, "val_loss": 334.6585998535156, "val_acc": 60.0}
{"epoch": 38, "training_loss": 439.14208984375, "training_acc": 45.0, "val_loss": 97.64363098144531, "val_acc": 60.0}
{"epoch": 39, "training_loss": 121.34114685058594, "training_acc": 55.0, "val_loss": 718.4672241210938, "val_acc": 40.0}
{"epoch": 40, "training_loss": 536.8427856445312, "training_acc": 55.0, "val_loss": 704.1945190429688, "val_acc": 40.0}
{"epoch": 41, "training_loss": 496.3898071289062, "training_acc": 55.0, "val_loss": 18.95798110961914, "val_acc": 60.0}
{"epoch": 42, "training_loss": 38.96487731933594, "training_acc": 55.0, "val_loss": 40.331825256347656, "val_acc": 60.0}
{"epoch": 43, "training_loss": 86.84859008789063, "training_acc": 45.0, "val_loss": 429.1958923339844, "val_acc": 40.0}
{"epoch": 44, "training_loss": 293.9430847167969, "training_acc": 55.0, "val_loss": 50.90837097167969, "val_acc": 60.0}
