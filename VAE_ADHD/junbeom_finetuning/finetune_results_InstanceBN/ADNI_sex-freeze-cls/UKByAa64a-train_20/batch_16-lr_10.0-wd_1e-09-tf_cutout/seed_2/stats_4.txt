"main_modify.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 2 --task ADNI_sex --input_option yAware --learning_rate 1e1 --batch_size 16 --weight_decay 1e-9 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 640.6747815132142, "training_acc": 35.0, "val_loss": 1040.5238037109375, "val_acc": 40.0}
{"epoch": 1, "training_loss": 432.39169921875, "training_acc": 75.0, "val_loss": 1387.872802734375, "val_acc": 60.0}
{"epoch": 2, "training_loss": 1938.519287109375, "training_acc": 45.0, "val_loss": 1212.8333740234375, "val_acc": 60.0}
{"epoch": 3, "training_loss": 1582.378594970703, "training_acc": 45.0, "val_loss": 257.01324462890625, "val_acc": 40.0}
{"epoch": 4, "training_loss": 275.053515625, "training_acc": 55.0, "val_loss": 786.6351928710938, "val_acc": 40.0}
{"epoch": 5, "training_loss": 509.47388916015626, "training_acc": 55.0, "val_loss": 208.19558715820312, "val_acc": 60.0}
{"epoch": 6, "training_loss": 365.18809814453124, "training_acc": 45.0, "val_loss": 288.4914245605469, "val_acc": 60.0}
{"epoch": 7, "training_loss": 249.74482421875, "training_acc": 65.0, "val_loss": 465.8983459472656, "val_acc": 40.0}
{"epoch": 8, "training_loss": 356.6885131835937, "training_acc": 55.0, "val_loss": 341.55230712890625, "val_acc": 40.0}
{"epoch": 9, "training_loss": 212.6093994140625, "training_acc": 55.0, "val_loss": 164.05752563476562, "val_acc": 60.0}
{"epoch": 10, "training_loss": 168.31631774902343, "training_acc": 45.0, "val_loss": 558.7584228515625, "val_acc": 40.0}
{"epoch": 11, "training_loss": 427.226025390625, "training_acc": 55.0, "val_loss": 893.1842041015625, "val_acc": 40.0}
{"epoch": 12, "training_loss": 626.7275634765625, "training_acc": 55.0, "val_loss": 292.02081298828125, "val_acc": 40.0}
{"epoch": 13, "training_loss": 162.23155517578124, "training_acc": 65.0, "val_loss": 481.97686767578125, "val_acc": 60.0}
{"epoch": 14, "training_loss": 652.3242309570312, "training_acc": 45.0, "val_loss": 403.1979064941406, "val_acc": 60.0}
{"epoch": 15, "training_loss": 424.41143798828125, "training_acc": 45.0, "val_loss": 605.2943725585938, "val_acc": 40.0}
{"epoch": 16, "training_loss": 474.58363647460936, "training_acc": 55.0, "val_loss": 1397.9539794921875, "val_acc": 40.0}
{"epoch": 17, "training_loss": 1036.816064453125, "training_acc": 55.0, "val_loss": 1219.4996337890625, "val_acc": 40.0}
{"epoch": 18, "training_loss": 820.859912109375, "training_acc": 55.0, "val_loss": 135.95079040527344, "val_acc": 40.0}
{"epoch": 19, "training_loss": 328.7863037109375, "training_acc": 35.0, "val_loss": 678.7606811523438, "val_acc": 60.0}
{"epoch": 20, "training_loss": 906.9444580078125, "training_acc": 45.0, "val_loss": 442.7940368652344, "val_acc": 60.0}
{"epoch": 21, "training_loss": 461.8555480957031, "training_acc": 45.0, "val_loss": 716.4992065429688, "val_acc": 40.0}
{"epoch": 22, "training_loss": 654.3366943359375, "training_acc": 55.0, "val_loss": 1420.63623046875, "val_acc": 40.0}
{"epoch": 23, "training_loss": 1029.2896728515625, "training_acc": 55.0, "val_loss": 1060.5220947265625, "val_acc": 40.0}
{"epoch": 24, "training_loss": 696.0581909179688, "training_acc": 55.0, "val_loss": 24.434696197509766, "val_acc": 60.0}
{"epoch": 25, "training_loss": 103.5295181274414, "training_acc": 50.0, "val_loss": 226.558349609375, "val_acc": 60.0}
{"epoch": 26, "training_loss": 218.25745849609376, "training_acc": 45.0, "val_loss": 614.0343017578125, "val_acc": 40.0}
{"epoch": 27, "training_loss": 454.9978820800781, "training_acc": 55.0, "val_loss": 1104.968017578125, "val_acc": 40.0}
{"epoch": 28, "training_loss": 793.046435546875, "training_acc": 55.0, "val_loss": 867.8351440429688, "val_acc": 40.0}
{"epoch": 29, "training_loss": 585.9223480224609, "training_acc": 55.0, "val_loss": 77.44474029541016, "val_acc": 40.0}
{"epoch": 30, "training_loss": 110.12855529785156, "training_acc": 55.0, "val_loss": 586.8676147460938, "val_acc": 60.0}
{"epoch": 31, "training_loss": 786.263037109375, "training_acc": 45.0, "val_loss": 371.689453125, "val_acc": 60.0}
{"epoch": 32, "training_loss": 401.3271360397339, "training_acc": 45.0, "val_loss": 358.2555847167969, "val_acc": 40.0}
{"epoch": 33, "training_loss": 232.76006164550782, "training_acc": 55.0, "val_loss": 252.5835418701172, "val_acc": 40.0}
{"epoch": 34, "training_loss": 129.70331573486328, "training_acc": 55.0, "val_loss": 103.60859680175781, "val_acc": 60.0}
{"epoch": 35, "training_loss": 102.38613204956054, "training_acc": 45.0, "val_loss": 99.32308959960938, "val_acc": 40.0}
{"epoch": 36, "training_loss": 47.14998168945313, "training_acc": 55.0, "val_loss": 111.3808364868164, "val_acc": 60.0}
{"epoch": 37, "training_loss": 120.42294616699219, "training_acc": 45.0, "val_loss": 211.3638153076172, "val_acc": 40.0}
{"epoch": 38, "training_loss": 107.01397247314453, "training_acc": 45.0, "val_loss": 155.2486114501953, "val_acc": 40.0}
{"epoch": 39, "training_loss": 66.53720703125, "training_acc": 60.0, "val_loss": 51.7107048034668, "val_acc": 60.0}
{"epoch": 40, "training_loss": 69.47536926269531, "training_acc": 35.0, "val_loss": 58.430294036865234, "val_acc": 20.0}
{"epoch": 41, "training_loss": 49.50733337402344, "training_acc": 65.0, "val_loss": 203.02586364746094, "val_acc": 40.0}
{"epoch": 42, "training_loss": 102.61492309570312, "training_acc": 55.0, "val_loss": 183.27903747558594, "val_acc": 40.0}
{"epoch": 43, "training_loss": 139.20167236328126, "training_acc": 35.0, "val_loss": 46.85429763793945, "val_acc": 0.0}
