"main_modify.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 2 --task ADNI_sex --input_option yAware --learning_rate 1e1 --batch_size 16 --weight_decay 1e-9 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 428.576068687439, "training_acc": 50.0, "val_loss": 572.9990234375, "val_acc": 60.0}
{"epoch": 1, "training_loss": 955.928466796875, "training_acc": 40.0, "val_loss": 1405.4598388671875, "val_acc": 40.0}
{"epoch": 2, "training_loss": 1096.4361572265625, "training_acc": 50.0, "val_loss": 49.738914489746094, "val_acc": 40.0}
{"epoch": 3, "training_loss": 224.16576538085937, "training_acc": 50.0, "val_loss": 1137.9713134765625, "val_acc": 60.0}
{"epoch": 4, "training_loss": 1452.5939453125, "training_acc": 50.0, "val_loss": 909.7888793945312, "val_acc": 60.0}
{"epoch": 5, "training_loss": 962.0698486328125, "training_acc": 50.0, "val_loss": 406.10357666015625, "val_acc": 40.0}
{"epoch": 6, "training_loss": 386.44712524414064, "training_acc": 50.0, "val_loss": 1337.9835205078125, "val_acc": 40.0}
{"epoch": 7, "training_loss": 1112.4212158203125, "training_acc": 50.0, "val_loss": 1143.6820068359375, "val_acc": 40.0}
{"epoch": 8, "training_loss": 915.5176574707032, "training_acc": 50.0, "val_loss": 89.87367248535156, "val_acc": 40.0}
{"epoch": 9, "training_loss": 327.49530029296875, "training_acc": 30.0, "val_loss": 635.4913940429688, "val_acc": 60.0}
{"epoch": 10, "training_loss": 781.690966796875, "training_acc": 50.0, "val_loss": 308.0214538574219, "val_acc": 60.0}
{"epoch": 11, "training_loss": 398.0792602539062, "training_acc": 40.0, "val_loss": 413.96978759765625, "val_acc": 40.0}
{"epoch": 12, "training_loss": 335.37802734375, "training_acc": 50.0, "val_loss": 81.3219985961914, "val_acc": 40.0}
{"epoch": 13, "training_loss": 77.68883056640625, "training_acc": 60.0, "val_loss": 454.10919189453125, "val_acc": 60.0}
{"epoch": 14, "training_loss": 600.91484375, "training_acc": 50.0, "val_loss": 252.033447265625, "val_acc": 60.0}
{"epoch": 15, "training_loss": 286.68071899414065, "training_acc": 50.0, "val_loss": 492.015625, "val_acc": 40.0}
{"epoch": 16, "training_loss": 413.132080078125, "training_acc": 50.0, "val_loss": 313.0843200683594, "val_acc": 40.0}
{"epoch": 17, "training_loss": 155.53697509765624, "training_acc": 70.0, "val_loss": 248.5635223388672, "val_acc": 60.0}
{"epoch": 18, "training_loss": 323.5898010253906, "training_acc": 50.0, "val_loss": 165.01010131835938, "val_acc": 60.0}
{"epoch": 19, "training_loss": 157.50671310424804, "training_acc": 60.0, "val_loss": 337.256591796875, "val_acc": 40.0}
{"epoch": 20, "training_loss": 272.49029541015625, "training_acc": 50.0, "val_loss": 15.805917739868164, "val_acc": 40.0}
{"epoch": 21, "training_loss": 128.8295639038086, "training_acc": 40.0, "val_loss": 388.2024841308594, "val_acc": 60.0}
{"epoch": 22, "training_loss": 459.449609375, "training_acc": 50.0, "val_loss": 3.656341314315796, "val_acc": 60.0}
{"epoch": 23, "training_loss": 138.30432147979735, "training_acc": 60.0, "val_loss": 702.896240234375, "val_acc": 40.0}
{"epoch": 24, "training_loss": 564.8788208007812, "training_acc": 50.0, "val_loss": 276.9463195800781, "val_acc": 40.0}
{"epoch": 25, "training_loss": 227.01443176269532, "training_acc": 50.0, "val_loss": 319.4346618652344, "val_acc": 60.0}
{"epoch": 26, "training_loss": 397.0814453125, "training_acc": 50.0, "val_loss": 176.41061401367188, "val_acc": 60.0}
{"epoch": 27, "training_loss": 194.3091827392578, "training_acc": 50.0, "val_loss": 215.6130828857422, "val_acc": 40.0}
{"epoch": 28, "training_loss": 151.82763748168946, "training_acc": 50.0, "val_loss": 181.7081756591797, "val_acc": 60.0}
{"epoch": 29, "training_loss": 259.4403991699219, "training_acc": 50.0, "val_loss": 94.67622375488281, "val_acc": 60.0}
{"epoch": 30, "training_loss": 238.6935546875, "training_acc": 30.0, "val_loss": 352.724365234375, "val_acc": 40.0}
{"epoch": 31, "training_loss": 249.80582275390626, "training_acc": 50.0, "val_loss": 210.17295837402344, "val_acc": 60.0}
{"epoch": 32, "training_loss": 293.73558349609374, "training_acc": 50.0, "val_loss": 269.91845703125, "val_acc": 60.0}
{"epoch": 33, "training_loss": 271.7193969726562, "training_acc": 50.0, "val_loss": 449.1358337402344, "val_acc": 40.0}
{"epoch": 34, "training_loss": 456.9187744140625, "training_acc": 50.0, "val_loss": 735.6221313476562, "val_acc": 40.0}
{"epoch": 35, "training_loss": 548.791162109375, "training_acc": 50.0, "val_loss": 37.557071685791016, "val_acc": 60.0}
{"epoch": 36, "training_loss": 128.5220153808594, "training_acc": 50.0, "val_loss": 197.43765258789062, "val_acc": 60.0}
{"epoch": 37, "training_loss": 204.25940256118776, "training_acc": 50.0, "val_loss": 455.7215270996094, "val_acc": 40.0}
{"epoch": 38, "training_loss": 373.758447265625, "training_acc": 50.0, "val_loss": 729.6651611328125, "val_acc": 40.0}
{"epoch": 39, "training_loss": 591.9458435058593, "training_acc": 50.0, "val_loss": 340.9591979980469, "val_acc": 40.0}
{"epoch": 40, "training_loss": 241.70433197021484, "training_acc": 50.0, "val_loss": 177.8334503173828, "val_acc": 60.0}
{"epoch": 41, "training_loss": 216.1205596923828, "training_acc": 50.0, "val_loss": 87.96019744873047, "val_acc": 40.0}
