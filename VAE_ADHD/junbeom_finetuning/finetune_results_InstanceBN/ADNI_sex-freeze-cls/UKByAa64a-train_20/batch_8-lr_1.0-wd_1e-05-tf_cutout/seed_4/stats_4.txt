"main_modify.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 4 --task ADNI_sex --input_option yAware --learning_rate 1e0 --batch_size 8 --weight_decay 1e-5 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 111.94260187149048, "training_acc": 45.0, "val_loss": 6.1192240715026855, "val_acc": 60.0}
{"epoch": 1, "training_loss": 16.426296997070313, "training_acc": 45.0, "val_loss": 28.540241241455078, "val_acc": 40.0}
{"epoch": 2, "training_loss": 25.375738525390624, "training_acc": 45.0, "val_loss": 26.450489044189453, "val_acc": 40.0}
{"epoch": 3, "training_loss": 19.39515495300293, "training_acc": 45.0, "val_loss": 6.8430352210998535, "val_acc": 40.0}
{"epoch": 4, "training_loss": 7.673468565940857, "training_acc": 35.0, "val_loss": 57.12894821166992, "val_acc": 40.0}
{"epoch": 5, "training_loss": 58.159602355957034, "training_acc": 55.0, "val_loss": 59.790283203125, "val_acc": 40.0}
{"epoch": 6, "training_loss": 31.496854782104492, "training_acc": 55.0, "val_loss": 60.66938018798828, "val_acc": 60.0}
{"epoch": 7, "training_loss": 77.0837188720703, "training_acc": 45.0, "val_loss": 3.8492496013641357, "val_acc": 60.0}
{"epoch": 8, "training_loss": 41.29771766662598, "training_acc": 45.0, "val_loss": 131.35694885253906, "val_acc": 40.0}
{"epoch": 9, "training_loss": 94.28514099121094, "training_acc": 55.0, "val_loss": 51.20504379272461, "val_acc": 40.0}
{"epoch": 10, "training_loss": 32.31622657775879, "training_acc": 35.0, "val_loss": 9.345778465270996, "val_acc": 60.0}
{"epoch": 11, "training_loss": 23.14761734008789, "training_acc": 45.0, "val_loss": 36.22724151611328, "val_acc": 40.0}
{"epoch": 12, "training_loss": 13.757455444335937, "training_acc": 65.0, "val_loss": 38.63875961303711, "val_acc": 60.0}
{"epoch": 13, "training_loss": 44.889035034179685, "training_acc": 45.0, "val_loss": 29.806394577026367, "val_acc": 40.0}
{"epoch": 14, "training_loss": 41.80170783996582, "training_acc": 55.0, "val_loss": 41.860382080078125, "val_acc": 40.0}
{"epoch": 15, "training_loss": 34.05455913543701, "training_acc": 35.0, "val_loss": 43.26202392578125, "val_acc": 60.0}
{"epoch": 16, "training_loss": 41.71870698928833, "training_acc": 45.0, "val_loss": 58.856441497802734, "val_acc": 40.0}
{"epoch": 17, "training_loss": 52.415625, "training_acc": 55.0, "val_loss": 84.5136947631836, "val_acc": 40.0}
{"epoch": 18, "training_loss": 46.127540588378906, "training_acc": 55.0, "val_loss": 18.83929443359375, "val_acc": 60.0}
{"epoch": 19, "training_loss": 38.582644653320315, "training_acc": 45.0, "val_loss": 35.76218032836914, "val_acc": 60.0}
{"epoch": 20, "training_loss": 40.015122985839845, "training_acc": 35.0, "val_loss": 49.732608795166016, "val_acc": 40.0}
{"epoch": 21, "training_loss": 30.818083190917967, "training_acc": 55.0, "val_loss": 15.924975395202637, "val_acc": 60.0}
{"epoch": 22, "training_loss": 31.659584045410156, "training_acc": 45.0, "val_loss": 3.3249523639678955, "val_acc": 40.0}
{"epoch": 23, "training_loss": 11.548781800270081, "training_acc": 55.0, "val_loss": 3.669004440307617, "val_acc": 60.0}
{"epoch": 24, "training_loss": 7.177939987182617, "training_acc": 55.0, "val_loss": 17.581602096557617, "val_acc": 40.0}
{"epoch": 25, "training_loss": 9.587457656860352, "training_acc": 35.0, "val_loss": 0.26716169714927673, "val_acc": 100.0}
{"epoch": 26, "training_loss": 4.124558520317078, "training_acc": 55.0, "val_loss": 13.833706855773926, "val_acc": 60.0}
{"epoch": 27, "training_loss": 19.225931549072264, "training_acc": 45.0, "val_loss": 35.02694320678711, "val_acc": 40.0}
{"epoch": 28, "training_loss": 31.012351989746094, "training_acc": 55.0, "val_loss": 31.043577194213867, "val_acc": 40.0}
{"epoch": 29, "training_loss": 22.34790916442871, "training_acc": 45.0, "val_loss": 1.9975874423980713, "val_acc": 60.0}
{"epoch": 30, "training_loss": 26.647185611724854, "training_acc": 55.0, "val_loss": 52.1729850769043, "val_acc": 40.0}
{"epoch": 31, "training_loss": 25.99487190246582, "training_acc": 55.0, "val_loss": 33.88167953491211, "val_acc": 60.0}
{"epoch": 32, "training_loss": 34.672819995880126, "training_acc": 45.0, "val_loss": 45.91067123413086, "val_acc": 40.0}
{"epoch": 33, "training_loss": 42.41853790283203, "training_acc": 55.0, "val_loss": 50.42554473876953, "val_acc": 40.0}
{"epoch": 34, "training_loss": 18.045089149475096, "training_acc": 65.0, "val_loss": 32.28300094604492, "val_acc": 60.0}
{"epoch": 35, "training_loss": 42.7610199034214, "training_acc": 45.0, "val_loss": 24.374351501464844, "val_acc": 40.0}
{"epoch": 36, "training_loss": 18.333677291870117, "training_acc": 55.0, "val_loss": 7.938614845275879, "val_acc": 60.0}
{"epoch": 37, "training_loss": 19.625401115417482, "training_acc": 45.0, "val_loss": 38.4029426574707, "val_acc": 40.0}
{"epoch": 38, "training_loss": 33.84217300415039, "training_acc": 55.0, "val_loss": 39.40678787231445, "val_acc": 40.0}
{"epoch": 39, "training_loss": 18.125561666488647, "training_acc": 55.0, "val_loss": 50.44792556762695, "val_acc": 60.0}
{"epoch": 40, "training_loss": 67.07380523681641, "training_acc": 45.0, "val_loss": 0.2948223650455475, "val_acc": 80.0}
{"epoch": 41, "training_loss": 27.26935032606125, "training_acc": 70.0, "val_loss": 54.53669357299805, "val_acc": 40.0}
{"epoch": 42, "training_loss": 23.628743743896486, "training_acc": 55.0, "val_loss": 25.80299186706543, "val_acc": 60.0}
{"epoch": 43, "training_loss": 27.542057228088378, "training_acc": 45.0, "val_loss": 45.958412170410156, "val_acc": 40.0}
{"epoch": 44, "training_loss": 47.310309982299806, "training_acc": 55.0, "val_loss": 56.298011779785156, "val_acc": 40.0}
