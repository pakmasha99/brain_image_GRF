"main_modify.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 5 --task ADNI_sex --input_option yAware --learning_rate 5e0 --batch_size 8 --weight_decay 5e-4 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 769.4818321228028, "training_acc": 40.0, "val_loss": 227.55776977539062, "val_acc": 40.0}
{"epoch": 1, "training_loss": 368.06373291015626, "training_acc": 55.0, "val_loss": 723.8150634765625, "val_acc": 60.0}
{"epoch": 2, "training_loss": 915.0386962890625, "training_acc": 45.0, "val_loss": 261.9097595214844, "val_acc": 60.0}
{"epoch": 3, "training_loss": 416.8347503662109, "training_acc": 45.0, "val_loss": 743.4638061523438, "val_acc": 40.0}
{"epoch": 4, "training_loss": 527.3037811279297, "training_acc": 55.0, "val_loss": 290.0116271972656, "val_acc": 40.0}
{"epoch": 5, "training_loss": 168.04561614990234, "training_acc": 45.0, "val_loss": 126.0040054321289, "val_acc": 60.0}
{"epoch": 6, "training_loss": 92.52434921264648, "training_acc": 55.0, "val_loss": 398.9674987792969, "val_acc": 40.0}
{"epoch": 7, "training_loss": 311.607177734375, "training_acc": 55.0, "val_loss": 200.5998077392578, "val_acc": 40.0}
{"epoch": 8, "training_loss": 72.68062572479248, "training_acc": 65.0, "val_loss": 288.805908203125, "val_acc": 60.0}
{"epoch": 9, "training_loss": 416.985595703125, "training_acc": 45.0, "val_loss": 96.1913833618164, "val_acc": 60.0}
{"epoch": 10, "training_loss": 240.00135192871093, "training_acc": 35.0, "val_loss": 566.6988525390625, "val_acc": 40.0}
{"epoch": 11, "training_loss": 416.1786865234375, "training_acc": 55.0, "val_loss": 241.81103515625, "val_acc": 40.0}
{"epoch": 12, "training_loss": 97.02780866622925, "training_acc": 45.0, "val_loss": 46.709930419921875, "val_acc": 60.0}
{"epoch": 13, "training_loss": 40.1883041381836, "training_acc": 65.0, "val_loss": 19.04726219177246, "val_acc": 40.0}
{"epoch": 14, "training_loss": 51.486599159240725, "training_acc": 65.0, "val_loss": 26.052366256713867, "val_acc": 60.0}
{"epoch": 15, "training_loss": 39.19656982421875, "training_acc": 75.0, "val_loss": 188.69464111328125, "val_acc": 40.0}
{"epoch": 16, "training_loss": 94.87007446289063, "training_acc": 55.0, "val_loss": 108.3934555053711, "val_acc": 60.0}
{"epoch": 17, "training_loss": 111.28862152099609, "training_acc": 45.0, "val_loss": 199.40013122558594, "val_acc": 40.0}
{"epoch": 18, "training_loss": 118.11832275390626, "training_acc": 55.0, "val_loss": 140.4580078125, "val_acc": 60.0}
{"epoch": 19, "training_loss": 296.7558898925781, "training_acc": 45.0, "val_loss": 168.36424255371094, "val_acc": 60.0}
{"epoch": 20, "training_loss": 109.48673496246337, "training_acc": 55.0, "val_loss": 163.41964721679688, "val_acc": 40.0}
{"epoch": 21, "training_loss": 119.42319984436035, "training_acc": 45.0, "val_loss": 143.21630859375, "val_acc": 60.0}
{"epoch": 22, "training_loss": 125.67465744018554, "training_acc": 55.0, "val_loss": 291.2665710449219, "val_acc": 40.0}
{"epoch": 23, "training_loss": 210.48425903320313, "training_acc": 55.0, "val_loss": 8.00140380859375, "val_acc": 60.0}
{"epoch": 24, "training_loss": 305.22167510986327, "training_acc": 25.0, "val_loss": 304.732666015625, "val_acc": 60.0}
{"epoch": 25, "training_loss": 241.8260612487793, "training_acc": 45.0, "val_loss": 410.7657165527344, "val_acc": 40.0}
{"epoch": 26, "training_loss": 507.62830810546876, "training_acc": 55.0, "val_loss": 906.3668823242188, "val_acc": 40.0}
{"epoch": 27, "training_loss": 588.3072387695313, "training_acc": 55.0, "val_loss": 277.5677185058594, "val_acc": 40.0}
{"epoch": 28, "training_loss": 141.41874084472656, "training_acc": 55.0, "val_loss": 236.65074157714844, "val_acc": 60.0}
{"epoch": 29, "training_loss": 236.1775131225586, "training_acc": 45.0, "val_loss": 232.137451171875, "val_acc": 40.0}
{"epoch": 30, "training_loss": 297.89581298828125, "training_acc": 55.0, "val_loss": 449.9010314941406, "val_acc": 40.0}
{"epoch": 31, "training_loss": 184.40161514282227, "training_acc": 55.0, "val_loss": 238.4170379638672, "val_acc": 60.0}
{"epoch": 32, "training_loss": 473.5774780273438, "training_acc": 45.0, "val_loss": 398.4678955078125, "val_acc": 60.0}
{"epoch": 33, "training_loss": 396.2797821044922, "training_acc": 45.0, "val_loss": 248.88304138183594, "val_acc": 40.0}
{"epoch": 34, "training_loss": 279.2966369628906, "training_acc": 55.0, "val_loss": 610.9458618164062, "val_acc": 40.0}
{"epoch": 35, "training_loss": 400.467138671875, "training_acc": 55.0, "val_loss": 138.81480407714844, "val_acc": 40.0}
{"epoch": 36, "training_loss": 192.21890258789062, "training_acc": 45.0, "val_loss": 266.0797119140625, "val_acc": 60.0}
{"epoch": 37, "training_loss": 262.28920288085936, "training_acc": 45.0, "val_loss": 280.0299377441406, "val_acc": 40.0}
{"epoch": 38, "training_loss": 364.60552368164065, "training_acc": 55.0, "val_loss": 510.44659423828125, "val_acc": 40.0}
{"epoch": 39, "training_loss": 266.55922504663465, "training_acc": 55.0, "val_loss": 147.33445739746094, "val_acc": 60.0}
{"epoch": 40, "training_loss": 196.164111328125, "training_acc": 45.0, "val_loss": 12.7753267288208, "val_acc": 40.0}
{"epoch": 41, "training_loss": 56.26977653503418, "training_acc": 60.0, "val_loss": 15.213648796081543, "val_acc": 60.0}
{"epoch": 42, "training_loss": 13.77773457467556, "training_acc": 60.0, "val_loss": 24.04401206970215, "val_acc": 60.0}
