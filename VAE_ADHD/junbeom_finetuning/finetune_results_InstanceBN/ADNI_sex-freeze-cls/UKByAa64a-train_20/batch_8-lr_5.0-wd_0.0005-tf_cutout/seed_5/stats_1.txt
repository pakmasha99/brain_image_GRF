"main_modify.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 5 --task ADNI_sex --input_option yAware --learning_rate 5e0 --batch_size 8 --weight_decay 5e-4 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 201.69640913009644, "training_acc": 55.0, "val_loss": 126.5767593383789, "val_acc": 60.0}
{"epoch": 1, "training_loss": 191.3556335449219, "training_acc": 65.0, "val_loss": 323.4753112792969, "val_acc": 40.0}
{"epoch": 2, "training_loss": 126.37936401367188, "training_acc": 55.0, "val_loss": 59.415138244628906, "val_acc": 40.0}
{"epoch": 3, "training_loss": 61.432579803466794, "training_acc": 45.0, "val_loss": 307.7010192871094, "val_acc": 40.0}
{"epoch": 4, "training_loss": 236.9274658203125, "training_acc": 55.0, "val_loss": 119.4681625366211, "val_acc": 40.0}
{"epoch": 5, "training_loss": 117.62823486328125, "training_acc": 45.0, "val_loss": 7.0727996826171875, "val_acc": 60.0}
{"epoch": 6, "training_loss": 133.7379535675049, "training_acc": 55.0, "val_loss": 360.1118469238281, "val_acc": 40.0}
{"epoch": 7, "training_loss": 155.268603515625, "training_acc": 55.0, "val_loss": 242.6837921142578, "val_acc": 60.0}
{"epoch": 8, "training_loss": 552.754736328125, "training_acc": 45.0, "val_loss": 432.1871032714844, "val_acc": 60.0}
{"epoch": 9, "training_loss": 398.4823394775391, "training_acc": 45.0, "val_loss": 348.5801696777344, "val_acc": 40.0}
{"epoch": 10, "training_loss": 355.5592041015625, "training_acc": 55.0, "val_loss": 786.6510620117188, "val_acc": 40.0}
{"epoch": 11, "training_loss": 553.726611328125, "training_acc": 55.0, "val_loss": 318.8990783691406, "val_acc": 40.0}
{"epoch": 12, "training_loss": 169.74142456054688, "training_acc": 45.0, "val_loss": 184.26528930664062, "val_acc": 60.0}
{"epoch": 13, "training_loss": 173.67615661621093, "training_acc": 45.0, "val_loss": 158.91079711914062, "val_acc": 40.0}
{"epoch": 14, "training_loss": 88.84437294006348, "training_acc": 55.0, "val_loss": 160.57839965820312, "val_acc": 60.0}
{"epoch": 15, "training_loss": 266.3607635498047, "training_acc": 45.0, "val_loss": 62.66732406616211, "val_acc": 60.0}
{"epoch": 16, "training_loss": 153.25808410644532, "training_acc": 45.0, "val_loss": 322.4938049316406, "val_acc": 40.0}
{"epoch": 17, "training_loss": 145.77183532714844, "training_acc": 55.0, "val_loss": 191.635986328125, "val_acc": 60.0}
{"epoch": 18, "training_loss": 416.6232421875, "training_acc": 45.0, "val_loss": 302.5340270996094, "val_acc": 60.0}
{"epoch": 19, "training_loss": 332.05259094238284, "training_acc": 35.0, "val_loss": 431.6537170410156, "val_acc": 40.0}
{"epoch": 20, "training_loss": 353.18212890625, "training_acc": 55.0, "val_loss": 290.5264587402344, "val_acc": 40.0}
{"epoch": 21, "training_loss": 125.53336791992187, "training_acc": 55.0, "val_loss": 236.970703125, "val_acc": 60.0}
{"epoch": 22, "training_loss": 296.6645202636719, "training_acc": 45.0, "val_loss": 0.2076803743839264, "val_acc": 80.0}
{"epoch": 23, "training_loss": 104.14806058965624, "training_acc": 70.0, "val_loss": 213.4269256591797, "val_acc": 40.0}
{"epoch": 24, "training_loss": 112.25993041992187, "training_acc": 55.0, "val_loss": 148.7927703857422, "val_acc": 60.0}
{"epoch": 25, "training_loss": 128.85423545837403, "training_acc": 55.0, "val_loss": 121.38555145263672, "val_acc": 40.0}
{"epoch": 26, "training_loss": 66.94281234741212, "training_acc": 55.0, "val_loss": 31.40797233581543, "val_acc": 60.0}
{"epoch": 27, "training_loss": 54.594374084472655, "training_acc": 55.0, "val_loss": 6.9392409324646, "val_acc": 60.0}
{"epoch": 28, "training_loss": 12.118619346618653, "training_acc": 50.0, "val_loss": 57.801300048828125, "val_acc": 60.0}
{"epoch": 29, "training_loss": 78.66832580566407, "training_acc": 35.0, "val_loss": 35.56136703491211, "val_acc": 60.0}
{"epoch": 30, "training_loss": 53.59533843994141, "training_acc": 25.0, "val_loss": 6.4110002517700195, "val_acc": 60.0}
{"epoch": 31, "training_loss": 7.07221474647522, "training_acc": 85.0, "val_loss": 40.981239318847656, "val_acc": 40.0}
{"epoch": 32, "training_loss": 11.49581241607666, "training_acc": 65.0, "val_loss": 46.37032699584961, "val_acc": 60.0}
{"epoch": 33, "training_loss": 38.93898894512095, "training_acc": 60.0, "val_loss": 39.68598556518555, "val_acc": 60.0}
{"epoch": 34, "training_loss": 31.234460735321044, "training_acc": 45.0, "val_loss": 72.97261810302734, "val_acc": 40.0}
{"epoch": 35, "training_loss": 33.8826229095459, "training_acc": 65.0, "val_loss": 42.353397369384766, "val_acc": 60.0}
{"epoch": 36, "training_loss": 50.83820819854736, "training_acc": 45.0, "val_loss": 34.24165344238281, "val_acc": 60.0}
{"epoch": 37, "training_loss": 29.145378875732423, "training_acc": 45.0, "val_loss": 24.189376831054688, "val_acc": 40.0}
{"epoch": 38, "training_loss": 13.78160120844841, "training_acc": 65.0, "val_loss": 90.00395965576172, "val_acc": 40.0}
{"epoch": 39, "training_loss": 61.79967088699341, "training_acc": 45.0, "val_loss": 34.288143157958984, "val_acc": 40.0}
{"epoch": 40, "training_loss": 19.945197677612306, "training_acc": 55.0, "val_loss": 15.489232063293457, "val_acc": 40.0}
{"epoch": 41, "training_loss": 90.67189559936523, "training_acc": 35.0, "val_loss": 54.009395599365234, "val_acc": 40.0}
