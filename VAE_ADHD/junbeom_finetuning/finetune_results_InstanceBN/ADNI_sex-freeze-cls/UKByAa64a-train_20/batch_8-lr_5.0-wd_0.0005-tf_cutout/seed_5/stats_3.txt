"main_modify.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 5 --task ADNI_sex --input_option yAware --learning_rate 5e0 --batch_size 8 --weight_decay 5e-4 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 641.4135287046432, "training_acc": 50.0, "val_loss": 186.5747528076172, "val_acc": 60.0}
{"epoch": 1, "training_loss": 210.35010452270507, "training_acc": 50.0, "val_loss": 484.3448791503906, "val_acc": 40.0}
{"epoch": 2, "training_loss": 462.8019714355469, "training_acc": 50.0, "val_loss": 227.0735321044922, "val_acc": 40.0}
{"epoch": 3, "training_loss": 311.5845947265625, "training_acc": 40.0, "val_loss": 300.40478515625, "val_acc": 60.0}
{"epoch": 4, "training_loss": 236.4304656982422, "training_acc": 50.0, "val_loss": 239.6499481201172, "val_acc": 40.0}
{"epoch": 5, "training_loss": 194.67816619873048, "training_acc": 50.0, "val_loss": 127.1043701171875, "val_acc": 60.0}
{"epoch": 6, "training_loss": 247.74268188476563, "training_acc": 50.0, "val_loss": 40.1630973815918, "val_acc": 60.0}
{"epoch": 7, "training_loss": 116.22881774902343, "training_acc": 70.0, "val_loss": 453.0591735839844, "val_acc": 40.0}
{"epoch": 8, "training_loss": 310.9097389221191, "training_acc": 50.0, "val_loss": 128.1107940673828, "val_acc": 60.0}
{"epoch": 9, "training_loss": 175.9648208618164, "training_acc": 50.0, "val_loss": 91.192138671875, "val_acc": 60.0}
{"epoch": 10, "training_loss": 122.76564254760743, "training_acc": 40.0, "val_loss": 99.736572265625, "val_acc": 40.0}
{"epoch": 11, "training_loss": 30.949022483825683, "training_acc": 70.0, "val_loss": 30.265348434448242, "val_acc": 60.0}
{"epoch": 12, "training_loss": 80.60194854736328, "training_acc": 50.0, "val_loss": 48.49713897705078, "val_acc": 40.0}
{"epoch": 13, "training_loss": 127.138720703125, "training_acc": 50.0, "val_loss": 125.3135986328125, "val_acc": 60.0}
{"epoch": 14, "training_loss": 171.07213439941407, "training_acc": 30.0, "val_loss": 72.82413482666016, "val_acc": 40.0}
{"epoch": 15, "training_loss": 97.60109100341796, "training_acc": 50.0, "val_loss": 111.0353775024414, "val_acc": 60.0}
{"epoch": 16, "training_loss": 90.40850982666015, "training_acc": 50.0, "val_loss": 312.6452331542969, "val_acc": 40.0}
{"epoch": 17, "training_loss": 213.8819107055664, "training_acc": 50.0, "val_loss": 110.63679504394531, "val_acc": 60.0}
{"epoch": 18, "training_loss": 192.27078247070312, "training_acc": 50.0, "val_loss": 23.64179039001465, "val_acc": 60.0}
{"epoch": 19, "training_loss": 74.4196231842041, "training_acc": 60.0, "val_loss": 189.70852661132812, "val_acc": 40.0}
{"epoch": 20, "training_loss": 135.96341247558593, "training_acc": 40.0, "val_loss": 198.95864868164062, "val_acc": 60.0}
{"epoch": 21, "training_loss": 170.89847717285156, "training_acc": 50.0, "val_loss": 233.787841796875, "val_acc": 40.0}
{"epoch": 22, "training_loss": 318.2809692382813, "training_acc": 50.0, "val_loss": 344.4587707519531, "val_acc": 40.0}
{"epoch": 23, "training_loss": 225.27274322509766, "training_acc": 50.0, "val_loss": 318.0481872558594, "val_acc": 60.0}
{"epoch": 24, "training_loss": 394.5857421875, "training_acc": 50.0, "val_loss": 153.7465057373047, "val_acc": 60.0}
{"epoch": 25, "training_loss": 133.00348052978515, "training_acc": 50.0, "val_loss": 234.0958709716797, "val_acc": 40.0}
{"epoch": 26, "training_loss": 129.33639221191407, "training_acc": 50.0, "val_loss": 118.1468505859375, "val_acc": 60.0}
{"epoch": 27, "training_loss": 123.16394958496093, "training_acc": 40.0, "val_loss": 69.83740997314453, "val_acc": 40.0}
{"epoch": 28, "training_loss": 21.7116418838501, "training_acc": 70.0, "val_loss": 132.2884979248047, "val_acc": 60.0}
{"epoch": 29, "training_loss": 134.60749053955078, "training_acc": 40.0, "val_loss": 106.8862533569336, "val_acc": 40.0}
{"epoch": 30, "training_loss": 40.44854326248169, "training_acc": 60.0, "val_loss": 41.68720626831055, "val_acc": 40.0}
{"epoch": 31, "training_loss": 25.65547709465027, "training_acc": 65.0, "val_loss": 20.524276733398438, "val_acc": 60.0}
{"epoch": 32, "training_loss": 55.04882583618164, "training_acc": 60.0, "val_loss": 40.86942672729492, "val_acc": 40.0}
{"epoch": 33, "training_loss": 187.25592193603515, "training_acc": 30.0, "val_loss": 143.1752166748047, "val_acc": 60.0}
{"epoch": 34, "training_loss": 67.41190148890018, "training_acc": 80.0, "val_loss": 372.46490478515625, "val_acc": 40.0}
{"epoch": 35, "training_loss": 326.99969482421875, "training_acc": 50.0, "val_loss": 132.2016143798828, "val_acc": 40.0}
{"epoch": 36, "training_loss": 216.35220947265626, "training_acc": 40.0, "val_loss": 252.19639587402344, "val_acc": 60.0}
{"epoch": 37, "training_loss": 207.12932777404785, "training_acc": 50.0, "val_loss": 136.27069091796875, "val_acc": 40.0}
{"epoch": 38, "training_loss": 82.77614898681641, "training_acc": 50.0, "val_loss": 60.80646514892578, "val_acc": 60.0}
{"epoch": 39, "training_loss": 70.88837356567383, "training_acc": 40.0, "val_loss": 83.59698486328125, "val_acc": 60.0}
{"epoch": 40, "training_loss": 172.9794479370117, "training_acc": 50.0, "val_loss": 3.446474075317383, "val_acc": 60.0}
{"epoch": 41, "training_loss": 120.59359613656997, "training_acc": 70.0, "val_loss": 197.04299926757812, "val_acc": 40.0}
{"epoch": 42, "training_loss": 145.25219116210937, "training_acc": 30.0, "val_loss": 44.72113037109375, "val_acc": 60.0}
{"epoch": 43, "training_loss": 16.69860734939575, "training_acc": 80.0, "val_loss": 2.4213433265686035, "val_acc": 80.0}
{"epoch": 44, "training_loss": 29.79477541297674, "training_acc": 70.0, "val_loss": 130.81927490234375, "val_acc": 40.0}
{"epoch": 45, "training_loss": 92.62929840087891, "training_acc": 40.0, "val_loss": 7.30713415145874, "val_acc": 60.0}
{"epoch": 46, "training_loss": 60.786701393127444, "training_acc": 50.0, "val_loss": 44.62411880493164, "val_acc": 60.0}
{"epoch": 47, "training_loss": 39.06033029556274, "training_acc": 50.0, "val_loss": 29.7761173248291, "val_acc": 40.0}
{"epoch": 48, "training_loss": 68.11929244995117, "training_acc": 50.0, "val_loss": 28.2607421875, "val_acc": 60.0}
{"epoch": 49, "training_loss": 51.901770782470706, "training_acc": 70.0, "val_loss": 137.5203857421875, "val_acc": 40.0}
{"epoch": 50, "training_loss": 100.6718963623047, "training_acc": 40.0, "val_loss": 11.02155590057373, "val_acc": 40.0}
{"epoch": 51, "training_loss": 8.169212055206298, "training_acc": 60.0, "val_loss": 110.4205093383789, "val_acc": 40.0}
{"epoch": 52, "training_loss": 115.4742317199707, "training_acc": 30.0, "val_loss": 46.36505889892578, "val_acc": 40.0}
{"epoch": 53, "training_loss": 21.863085556030274, "training_acc": 60.0, "val_loss": 134.60244750976562, "val_acc": 60.0}
{"epoch": 54, "training_loss": 113.51964797973633, "training_acc": 50.0, "val_loss": 57.91908645629883, "val_acc": 40.0}
{"epoch": 55, "training_loss": 44.680810546875, "training_acc": 40.0, "val_loss": 140.24815368652344, "val_acc": 40.0}
{"epoch": 56, "training_loss": 170.18839416503906, "training_acc": 50.0, "val_loss": 13.502402305603027, "val_acc": 60.0}
{"epoch": 57, "training_loss": 16.162807083129884, "training_acc": 50.0, "val_loss": 22.133224487304688, "val_acc": 60.0}
{"epoch": 58, "training_loss": 27.332518768310546, "training_acc": 40.0, "val_loss": 43.10564041137695, "val_acc": 40.0}
{"epoch": 59, "training_loss": 79.66835861206054, "training_acc": 30.0, "val_loss": 77.94464874267578, "val_acc": 60.0}
{"epoch": 60, "training_loss": 38.6140214920044, "training_acc": 65.0, "val_loss": 10.187520980834961, "val_acc": 40.0}
{"epoch": 61, "training_loss": 82.70091972351074, "training_acc": 55.0, "val_loss": 47.619441986083984, "val_acc": 60.0}
{"epoch": 62, "training_loss": 114.22899780273437, "training_acc": 50.0, "val_loss": 222.08877563476562, "val_acc": 40.0}
