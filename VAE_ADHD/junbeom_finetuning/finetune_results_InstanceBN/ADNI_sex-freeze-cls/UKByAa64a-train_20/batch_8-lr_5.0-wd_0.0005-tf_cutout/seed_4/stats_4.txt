"main_modify.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 4 --task ADNI_sex --input_option yAware --learning_rate 5e0 --batch_size 8 --weight_decay 5e-4 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 625.0434730529785, "training_acc": 45.0, "val_loss": 711.0685424804688, "val_acc": 40.0}
{"epoch": 1, "training_loss": 942.0052001953125, "training_acc": 55.0, "val_loss": 1317.9271240234375, "val_acc": 40.0}
{"epoch": 2, "training_loss": 786.9791473388672, "training_acc": 55.0, "val_loss": 105.08338928222656, "val_acc": 60.0}
{"epoch": 3, "training_loss": 372.85118408203124, "training_acc": 45.0, "val_loss": 222.84263610839844, "val_acc": 60.0}
{"epoch": 4, "training_loss": 169.06833724975587, "training_acc": 45.0, "val_loss": 130.7450714111328, "val_acc": 40.0}
{"epoch": 5, "training_loss": 99.2474935054779, "training_acc": 35.0, "val_loss": 119.2664794921875, "val_acc": 40.0}
{"epoch": 6, "training_loss": 103.5798731803894, "training_acc": 55.0, "val_loss": 134.9073486328125, "val_acc": 60.0}
{"epoch": 7, "training_loss": 196.46587524414062, "training_acc": 45.0, "val_loss": 88.85613250732422, "val_acc": 40.0}
{"epoch": 8, "training_loss": 112.13464965820313, "training_acc": 55.0, "val_loss": 76.75379943847656, "val_acc": 40.0}
{"epoch": 9, "training_loss": 177.68677368164063, "training_acc": 35.0, "val_loss": 108.54573822021484, "val_acc": 60.0}
{"epoch": 10, "training_loss": 54.936614990234375, "training_acc": 65.0, "val_loss": 116.7115249633789, "val_acc": 40.0}
{"epoch": 11, "training_loss": 64.23341369628906, "training_acc": 35.0, "val_loss": 29.33323097229004, "val_acc": 60.0}
{"epoch": 12, "training_loss": 19.883441543579103, "training_acc": 55.0, "val_loss": 52.1004638671875, "val_acc": 40.0}
{"epoch": 13, "training_loss": 55.731885242462155, "training_acc": 45.0, "val_loss": 73.21798706054688, "val_acc": 60.0}
{"epoch": 14, "training_loss": 61.66936416625977, "training_acc": 55.0, "val_loss": 16.49393081665039, "val_acc": 40.0}
{"epoch": 15, "training_loss": 76.07275924682617, "training_acc": 55.0, "val_loss": 40.28428268432617, "val_acc": 60.0}
{"epoch": 16, "training_loss": 180.8169403076172, "training_acc": 35.0, "val_loss": 259.556640625, "val_acc": 40.0}
{"epoch": 17, "training_loss": 118.16739807128906, "training_acc": 55.0, "val_loss": 155.6024932861328, "val_acc": 60.0}
{"epoch": 18, "training_loss": 188.396337890625, "training_acc": 45.0, "val_loss": 186.9539031982422, "val_acc": 40.0}
{"epoch": 19, "training_loss": 280.52732238769534, "training_acc": 55.0, "val_loss": 358.002685546875, "val_acc": 40.0}
{"epoch": 20, "training_loss": 129.45037918090821, "training_acc": 65.0, "val_loss": 165.21591186523438, "val_acc": 60.0}
{"epoch": 21, "training_loss": 232.2718536376953, "training_acc": 45.0, "val_loss": 36.29466247558594, "val_acc": 40.0}
{"epoch": 22, "training_loss": 41.47371826171875, "training_acc": 55.0, "val_loss": 36.83344268798828, "val_acc": 60.0}
{"epoch": 23, "training_loss": 51.573600959777835, "training_acc": 35.0, "val_loss": 92.28700256347656, "val_acc": 60.0}
{"epoch": 24, "training_loss": 114.84996490478515, "training_acc": 35.0, "val_loss": 10.805366516113281, "val_acc": 60.0}
{"epoch": 25, "training_loss": 52.24278030395508, "training_acc": 45.0, "val_loss": 37.15882110595703, "val_acc": 60.0}
{"epoch": 26, "training_loss": 65.51802215576171, "training_acc": 35.0, "val_loss": 38.66949462890625, "val_acc": 40.0}
{"epoch": 27, "training_loss": 47.0441780090332, "training_acc": 55.0, "val_loss": 27.6491756439209, "val_acc": 40.0}
{"epoch": 28, "training_loss": 17.74150104522705, "training_acc": 55.0, "val_loss": 9.759307861328125, "val_acc": 60.0}
{"epoch": 29, "training_loss": 65.9558837890625, "training_acc": 35.0, "val_loss": 63.95882797241211, "val_acc": 60.0}
{"epoch": 30, "training_loss": 145.53077239990233, "training_acc": 45.0, "val_loss": 57.30964279174805, "val_acc": 40.0}
{"epoch": 31, "training_loss": 54.86253967285156, "training_acc": 55.0, "val_loss": 17.14667320251465, "val_acc": 60.0}
{"epoch": 32, "training_loss": 54.25211410522461, "training_acc": 35.0, "val_loss": 130.84373474121094, "val_acc": 40.0}
{"epoch": 33, "training_loss": 91.36771392822266, "training_acc": 45.0, "val_loss": 158.7165069580078, "val_acc": 60.0}
{"epoch": 34, "training_loss": 153.63841705322267, "training_acc": 45.0, "val_loss": 156.6159210205078, "val_acc": 40.0}
{"epoch": 35, "training_loss": 98.23946990966797, "training_acc": 55.0, "val_loss": 130.2151336669922, "val_acc": 60.0}
{"epoch": 36, "training_loss": 199.1337463378906, "training_acc": 45.0, "val_loss": 30.129194259643555, "val_acc": 60.0}
{"epoch": 37, "training_loss": 124.35696334838867, "training_acc": 55.0, "val_loss": 384.67364501953125, "val_acc": 40.0}
{"epoch": 38, "training_loss": 225.63053092956542, "training_acc": 55.0, "val_loss": 121.79408264160156, "val_acc": 60.0}
{"epoch": 39, "training_loss": 250.72013244628906, "training_acc": 45.0, "val_loss": 54.75709915161133, "val_acc": 60.0}
{"epoch": 40, "training_loss": 197.4241912841797, "training_acc": 45.0, "val_loss": 532.7570190429688, "val_acc": 40.0}
{"epoch": 41, "training_loss": 347.84613037109375, "training_acc": 55.0, "val_loss": 93.730712890625, "val_acc": 40.0}
{"epoch": 42, "training_loss": 150.63080749511718, "training_acc": 55.0, "val_loss": 260.20849609375, "val_acc": 60.0}
{"epoch": 43, "training_loss": 244.58458557128907, "training_acc": 45.0, "val_loss": 277.6067810058594, "val_acc": 40.0}
{"epoch": 44, "training_loss": 260.78453369140624, "training_acc": 55.0, "val_loss": 519.8397827148438, "val_acc": 40.0}
{"epoch": 45, "training_loss": 331.5557205200195, "training_acc": 55.0, "val_loss": 12.123217582702637, "val_acc": 60.0}
{"epoch": 46, "training_loss": 35.248762893676755, "training_acc": 45.0, "val_loss": 148.1902618408203, "val_acc": 40.0}
{"epoch": 47, "training_loss": 133.81436767578126, "training_acc": 55.0, "val_loss": 7.177690029144287, "val_acc": 60.0}
{"epoch": 48, "training_loss": 31.388849639892577, "training_acc": 50.0, "val_loss": 136.5924072265625, "val_acc": 40.0}
{"epoch": 49, "training_loss": 143.87746200561523, "training_acc": 55.0, "val_loss": 5.133852481842041, "val_acc": 60.0}
{"epoch": 50, "training_loss": 21.989250564575194, "training_acc": 55.0, "val_loss": 237.43936157226562, "val_acc": 40.0}
{"epoch": 51, "training_loss": 229.8222229003906, "training_acc": 55.0, "val_loss": 285.7524719238281, "val_acc": 40.0}
{"epoch": 52, "training_loss": 222.3965057373047, "training_acc": 35.0, "val_loss": 222.8507080078125, "val_acc": 60.0}
{"epoch": 53, "training_loss": 262.1478332519531, "training_acc": 25.0, "val_loss": 32.308841705322266, "val_acc": 40.0}
{"epoch": 54, "training_loss": 30.170186614990236, "training_acc": 45.0, "val_loss": 57.73041915893555, "val_acc": 60.0}
{"epoch": 55, "training_loss": 78.80174713134765, "training_acc": 35.0, "val_loss": 35.156455993652344, "val_acc": 40.0}
{"epoch": 56, "training_loss": 43.1102897644043, "training_acc": 55.0, "val_loss": 48.08417510986328, "val_acc": 40.0}
{"epoch": 57, "training_loss": 43.05959777832031, "training_acc": 45.0, "val_loss": 5.839476585388184, "val_acc": 60.0}
{"epoch": 58, "training_loss": 72.10580558776856, "training_acc": 55.0, "val_loss": 68.49732971191406, "val_acc": 40.0}
{"epoch": 59, "training_loss": 143.44840087890626, "training_acc": 35.0, "val_loss": 70.4683837890625, "val_acc": 60.0}
{"epoch": 60, "training_loss": 69.51999969482422, "training_acc": 65.0, "val_loss": 185.12368774414062, "val_acc": 40.0}
{"epoch": 61, "training_loss": 56.27314376831055, "training_acc": 75.0, "val_loss": 125.27777099609375, "val_acc": 60.0}
{"epoch": 62, "training_loss": 138.3304870605469, "training_acc": 45.0, "val_loss": 197.21719360351562, "val_acc": 40.0}
{"epoch": 63, "training_loss": 183.19162292480468, "training_acc": 55.0, "val_loss": 251.07359313964844, "val_acc": 40.0}
{"epoch": 64, "training_loss": 184.32437744140626, "training_acc": 35.0, "val_loss": 207.09622192382812, "val_acc": 60.0}
{"epoch": 65, "training_loss": 213.5542588710785, "training_acc": 40.0, "val_loss": 102.41522216796875, "val_acc": 40.0}
{"epoch": 66, "training_loss": 52.657142639160156, "training_acc": 55.0, "val_loss": 27.255512237548828, "val_acc": 60.0}
{"epoch": 67, "training_loss": 97.3033233642578, "training_acc": 35.0, "val_loss": 59.71271514892578, "val_acc": 40.0}
{"epoch": 68, "training_loss": 114.90552215576172, "training_acc": 45.0, "val_loss": 66.32189178466797, "val_acc": 60.0}
