"main_modify.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 4 --task ADNI_sex --input_option yAware --learning_rate 5e0 --batch_size 8 --weight_decay 5e-4 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 579.075728225708, "training_acc": 40.0, "val_loss": 366.7313537597656, "val_acc": 40.0}
{"epoch": 1, "training_loss": 810.8476959228516, "training_acc": 50.0, "val_loss": 697.7879028320312, "val_acc": 40.0}
{"epoch": 2, "training_loss": 369.9701232910156, "training_acc": 50.0, "val_loss": 444.61114501953125, "val_acc": 60.0}
{"epoch": 3, "training_loss": 551.4456665039063, "training_acc": 50.0, "val_loss": 224.34239196777344, "val_acc": 60.0}
{"epoch": 4, "training_loss": 214.7985107421875, "training_acc": 40.0, "val_loss": 252.1618194580078, "val_acc": 40.0}
{"epoch": 5, "training_loss": 146.7636917114258, "training_acc": 50.0, "val_loss": 128.54287719726562, "val_acc": 60.0}
{"epoch": 6, "training_loss": 125.13669290542603, "training_acc": 50.0, "val_loss": 284.88409423828125, "val_acc": 40.0}
{"epoch": 7, "training_loss": 253.4843322753906, "training_acc": 50.0, "val_loss": 198.54974365234375, "val_acc": 40.0}
{"epoch": 8, "training_loss": 71.61477966308594, "training_acc": 60.0, "val_loss": 292.9505310058594, "val_acc": 60.0}
{"epoch": 9, "training_loss": 386.0112670898437, "training_acc": 50.0, "val_loss": 152.49546813964844, "val_acc": 60.0}
{"epoch": 10, "training_loss": 176.03513793945314, "training_acc": 50.0, "val_loss": 294.3958435058594, "val_acc": 40.0}
{"epoch": 11, "training_loss": 198.5279052734375, "training_acc": 40.0, "val_loss": 119.96648406982422, "val_acc": 60.0}
{"epoch": 12, "training_loss": 110.45181579589844, "training_acc": 50.0, "val_loss": 94.6871337890625, "val_acc": 40.0}
{"epoch": 13, "training_loss": 54.23694076538086, "training_acc": 60.0, "val_loss": 113.57601165771484, "val_acc": 60.0}
{"epoch": 14, "training_loss": 108.76401793598197, "training_acc": 60.0, "val_loss": 146.94285583496094, "val_acc": 40.0}
{"epoch": 15, "training_loss": 125.98850708007812, "training_acc": 50.0, "val_loss": 101.856689453125, "val_acc": 60.0}
{"epoch": 16, "training_loss": 170.44908294677734, "training_acc": 50.0, "val_loss": 106.0587387084961, "val_acc": 60.0}
{"epoch": 17, "training_loss": 64.90650939941406, "training_acc": 50.0, "val_loss": 17.51966094970703, "val_acc": 40.0}
{"epoch": 18, "training_loss": 55.76767196655273, "training_acc": 50.0, "val_loss": 26.61527442932129, "val_acc": 40.0}
{"epoch": 19, "training_loss": 37.780881023406984, "training_acc": 60.0, "val_loss": 31.663976669311523, "val_acc": 60.0}
{"epoch": 20, "training_loss": 118.36873779296874, "training_acc": 20.0, "val_loss": 48.0460090637207, "val_acc": 60.0}
{"epoch": 21, "training_loss": 46.3467257976532, "training_acc": 55.0, "val_loss": 113.35515594482422, "val_acc": 40.0}
{"epoch": 22, "training_loss": 99.14005088806152, "training_acc": 40.0, "val_loss": 7.211924076080322, "val_acc": 40.0}
{"epoch": 23, "training_loss": 18.159323310852052, "training_acc": 60.0, "val_loss": 29.756977081298828, "val_acc": 40.0}
{"epoch": 24, "training_loss": 79.01493301391602, "training_acc": 50.0, "val_loss": 18.40874671936035, "val_acc": 60.0}
{"epoch": 25, "training_loss": 164.0050277709961, "training_acc": 40.0, "val_loss": 295.2742004394531, "val_acc": 40.0}
{"epoch": 26, "training_loss": 131.1448890686035, "training_acc": 70.0, "val_loss": 159.4862518310547, "val_acc": 60.0}
{"epoch": 27, "training_loss": 226.2860565185547, "training_acc": 50.0, "val_loss": 10.820947647094727, "val_acc": 60.0}
{"epoch": 28, "training_loss": 148.63089752197266, "training_acc": 50.0, "val_loss": 366.3798522949219, "val_acc": 40.0}
{"epoch": 29, "training_loss": 199.68401031494142, "training_acc": 50.0, "val_loss": 213.53892517089844, "val_acc": 60.0}
{"epoch": 30, "training_loss": 355.68080139160156, "training_acc": 50.0, "val_loss": 303.4278259277344, "val_acc": 60.0}
{"epoch": 31, "training_loss": 232.69034423828126, "training_acc": 50.0, "val_loss": 346.6476745605469, "val_acc": 40.0}
{"epoch": 32, "training_loss": 390.34991455078125, "training_acc": 50.0, "val_loss": 614.0526733398438, "val_acc": 40.0}
{"epoch": 33, "training_loss": 379.8514038085938, "training_acc": 50.0, "val_loss": 80.94506072998047, "val_acc": 60.0}
{"epoch": 34, "training_loss": 255.2903564453125, "training_acc": 50.0, "val_loss": 279.947021484375, "val_acc": 60.0}
{"epoch": 35, "training_loss": 242.26463623046874, "training_acc": 50.0, "val_loss": 282.3432312011719, "val_acc": 40.0}
{"epoch": 36, "training_loss": 412.6602416992188, "training_acc": 50.0, "val_loss": 472.20758056640625, "val_acc": 40.0}
{"epoch": 37, "training_loss": 238.75945281982422, "training_acc": 50.0, "val_loss": 151.0262908935547, "val_acc": 60.0}
{"epoch": 38, "training_loss": 192.28218994140624, "training_acc": 50.0, "val_loss": 12.10688304901123, "val_acc": 40.0}
{"epoch": 39, "training_loss": 49.37170963287353, "training_acc": 50.0, "val_loss": 102.03936767578125, "val_acc": 60.0}
{"epoch": 40, "training_loss": 138.79974975585938, "training_acc": 50.0, "val_loss": 5.044364929199219, "val_acc": 40.0}
{"epoch": 41, "training_loss": 40.24010109901428, "training_acc": 50.0, "val_loss": 30.114166259765625, "val_acc": 60.0}
{"epoch": 42, "training_loss": 48.77885131835937, "training_acc": 50.0, "val_loss": 33.62014389038086, "val_acc": 60.0}
{"epoch": 43, "training_loss": 62.84448890686035, "training_acc": 50.0, "val_loss": 21.349363327026367, "val_acc": 40.0}
{"epoch": 44, "training_loss": 76.43963470458985, "training_acc": 40.0, "val_loss": 18.216766357421875, "val_acc": 40.0}
{"epoch": 45, "training_loss": 38.538360595703125, "training_acc": 30.0, "val_loss": 76.32855224609375, "val_acc": 40.0}
{"epoch": 46, "training_loss": 68.63402423858642, "training_acc": 40.0, "val_loss": 53.54000473022461, "val_acc": 40.0}
{"epoch": 47, "training_loss": 28.39654083251953, "training_acc": 60.0, "val_loss": 94.9552001953125, "val_acc": 60.0}
{"epoch": 48, "training_loss": 111.34991607666015, "training_acc": 40.0, "val_loss": 185.5501708984375, "val_acc": 40.0}
{"epoch": 49, "training_loss": 106.97197875976562, "training_acc": 50.0, "val_loss": 117.70305633544922, "val_acc": 60.0}
{"epoch": 50, "training_loss": 157.34725646972657, "training_acc": 30.0, "val_loss": 101.51854705810547, "val_acc": 40.0}
{"epoch": 51, "training_loss": 59.76323013305664, "training_acc": 50.0, "val_loss": 23.454206466674805, "val_acc": 40.0}
{"epoch": 52, "training_loss": 28.571967315673827, "training_acc": 40.0, "val_loss": 27.48052978515625, "val_acc": 40.0}
{"epoch": 53, "training_loss": 126.70420303344727, "training_acc": 30.0, "val_loss": 45.062347412109375, "val_acc": 60.0}
{"epoch": 54, "training_loss": 75.04972229003906, "training_acc": 60.0, "val_loss": 147.21310424804688, "val_acc": 40.0}
{"epoch": 55, "training_loss": 76.23874244689941, "training_acc": 60.0, "val_loss": 20.974384307861328, "val_acc": 60.0}
{"epoch": 56, "training_loss": 185.6412841796875, "training_acc": 30.0, "val_loss": 173.3933868408203, "val_acc": 40.0}
{"epoch": 57, "training_loss": 156.53380126953124, "training_acc": 40.0, "val_loss": 103.7851791381836, "val_acc": 60.0}
{"epoch": 58, "training_loss": 101.5957260131836, "training_acc": 40.0, "val_loss": 5.495213985443115, "val_acc": 60.0}
{"epoch": 59, "training_loss": 9.494367218017578, "training_acc": 70.0, "val_loss": 98.93183898925781, "val_acc": 40.0}
