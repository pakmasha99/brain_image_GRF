"main_modify.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 1 --task ADNI_sex --input_option yAware --learning_rate 5e0 --batch_size 8 --weight_decay 5e-4 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 332.6934016942978, "training_acc": 50.0, "val_loss": 195.45455932617188, "val_acc": 60.0}
{"epoch": 1, "training_loss": 159.58568420410157, "training_acc": 50.0, "val_loss": 160.61953735351562, "val_acc": 60.0}
{"epoch": 2, "training_loss": 281.9745666503906, "training_acc": 50.0, "val_loss": 19.812192916870117, "val_acc": 60.0}
{"epoch": 3, "training_loss": 210.1311279296875, "training_acc": 50.0, "val_loss": 567.8092041015625, "val_acc": 40.0}
{"epoch": 4, "training_loss": 368.53465576171874, "training_acc": 50.0, "val_loss": 148.63294982910156, "val_acc": 60.0}
{"epoch": 5, "training_loss": 371.40300903320315, "training_acc": 50.0, "val_loss": 244.01016235351562, "val_acc": 60.0}
{"epoch": 6, "training_loss": 253.33629913330077, "training_acc": 40.0, "val_loss": 529.3702392578125, "val_acc": 40.0}
{"epoch": 7, "training_loss": 424.58502197265625, "training_acc": 50.0, "val_loss": 192.0419464111328, "val_acc": 40.0}
{"epoch": 8, "training_loss": 114.373779296875, "training_acc": 60.0, "val_loss": 193.07627868652344, "val_acc": 60.0}
{"epoch": 9, "training_loss": 189.8081268310547, "training_acc": 40.0, "val_loss": 108.88089752197266, "val_acc": 40.0}
{"epoch": 10, "training_loss": 104.08322143554688, "training_acc": 40.0, "val_loss": 122.79671478271484, "val_acc": 60.0}
{"epoch": 11, "training_loss": 86.63634757995605, "training_acc": 60.0, "val_loss": 153.94676208496094, "val_acc": 40.0}
{"epoch": 12, "training_loss": 124.20422058105468, "training_acc": 50.0, "val_loss": 150.4332275390625, "val_acc": 60.0}
{"epoch": 13, "training_loss": 294.89036560058594, "training_acc": 50.0, "val_loss": 159.23020935058594, "val_acc": 60.0}
{"epoch": 14, "training_loss": 131.23262786865234, "training_acc": 40.0, "val_loss": 89.10570526123047, "val_acc": 40.0}
{"epoch": 15, "training_loss": 21.773693466186522, "training_acc": 75.0, "val_loss": 209.9869842529297, "val_acc": 60.0}
{"epoch": 16, "training_loss": 266.35072021484376, "training_acc": 50.0, "val_loss": 18.793045043945312, "val_acc": 60.0}
{"epoch": 17, "training_loss": 204.63234100341796, "training_acc": 40.0, "val_loss": 313.0634460449219, "val_acc": 40.0}
{"epoch": 18, "training_loss": 132.462642288208, "training_acc": 60.0, "val_loss": 187.79684448242188, "val_acc": 60.0}
{"epoch": 19, "training_loss": 246.66983489990236, "training_acc": 50.0, "val_loss": 52.362060546875, "val_acc": 60.0}
{"epoch": 20, "training_loss": 223.97412719726563, "training_acc": 30.0, "val_loss": 301.1039733886719, "val_acc": 40.0}
{"epoch": 21, "training_loss": 121.6250244140625, "training_acc": 70.0, "val_loss": 138.85028076171875, "val_acc": 60.0}
{"epoch": 22, "training_loss": 187.14302978515624, "training_acc": 50.0, "val_loss": 10.299565315246582, "val_acc": 60.0}
{"epoch": 23, "training_loss": 117.5589584350586, "training_acc": 65.0, "val_loss": 360.41851806640625, "val_acc": 40.0}
{"epoch": 24, "training_loss": 207.14670934677125, "training_acc": 55.0, "val_loss": 172.3402862548828, "val_acc": 60.0}
{"epoch": 25, "training_loss": 264.10430908203125, "training_acc": 50.0, "val_loss": 145.4187774658203, "val_acc": 60.0}
{"epoch": 26, "training_loss": 135.01517333984376, "training_acc": 40.0, "val_loss": 105.73552703857422, "val_acc": 40.0}
{"epoch": 27, "training_loss": 47.85516223907471, "training_acc": 50.0, "val_loss": 44.13541793823242, "val_acc": 40.0}
{"epoch": 28, "training_loss": 53.722713470458984, "training_acc": 30.0, "val_loss": 199.59764099121094, "val_acc": 40.0}
{"epoch": 29, "training_loss": 199.69603118896484, "training_acc": 50.0, "val_loss": 128.7321014404297, "val_acc": 40.0}
{"epoch": 30, "training_loss": 130.07305297851562, "training_acc": 40.0, "val_loss": 70.5922622680664, "val_acc": 60.0}
{"epoch": 31, "training_loss": 85.94427947998047, "training_acc": 50.0, "val_loss": 78.36993408203125, "val_acc": 40.0}
{"epoch": 32, "training_loss": 49.39067153930664, "training_acc": 60.0, "val_loss": 10.369257926940918, "val_acc": 60.0}
{"epoch": 33, "training_loss": 79.80086612701416, "training_acc": 55.0, "val_loss": 84.11052703857422, "val_acc": 40.0}
{"epoch": 34, "training_loss": 61.28423919677734, "training_acc": 60.0, "val_loss": 49.34925079345703, "val_acc": 60.0}
{"epoch": 35, "training_loss": 118.18888549804687, "training_acc": 40.0, "val_loss": 63.92509841918945, "val_acc": 40.0}
{"epoch": 36, "training_loss": 78.2890869140625, "training_acc": 60.0, "val_loss": 112.9111328125, "val_acc": 60.0}
{"epoch": 37, "training_loss": 84.65606098175049, "training_acc": 60.0, "val_loss": 238.7380828857422, "val_acc": 40.0}
{"epoch": 38, "training_loss": 167.61355562210082, "training_acc": 50.0, "val_loss": 83.39114379882812, "val_acc": 60.0}
{"epoch": 39, "training_loss": 73.93645248413085, "training_acc": 50.0, "val_loss": 5.33387565612793, "val_acc": 60.0}
{"epoch": 40, "training_loss": 16.796077537536622, "training_acc": 70.0, "val_loss": 49.9761848449707, "val_acc": 40.0}
{"epoch": 41, "training_loss": 39.680375289916995, "training_acc": 60.0, "val_loss": 43.95753860473633, "val_acc": 60.0}
{"epoch": 42, "training_loss": 32.06379699707031, "training_acc": 50.0, "val_loss": 121.6512222290039, "val_acc": 60.0}
{"epoch": 43, "training_loss": 166.5972473144531, "training_acc": 50.0, "val_loss": 21.114347457885742, "val_acc": 60.0}
{"epoch": 44, "training_loss": 131.62631378173828, "training_acc": 40.0, "val_loss": 192.178955078125, "val_acc": 40.0}
{"epoch": 45, "training_loss": 84.34968185424805, "training_acc": 60.0, "val_loss": 178.09271240234375, "val_acc": 60.0}
{"epoch": 46, "training_loss": 202.31649169921874, "training_acc": 50.0, "val_loss": 42.83916091918945, "val_acc": 40.0}
{"epoch": 47, "training_loss": 94.65880432128907, "training_acc": 50.0, "val_loss": 41.66313171386719, "val_acc": 60.0}
{"epoch": 48, "training_loss": 146.28693237304688, "training_acc": 50.0, "val_loss": 36.78986358642578, "val_acc": 40.0}
{"epoch": 49, "training_loss": 76.46878662109376, "training_acc": 50.0, "val_loss": 98.06143188476562, "val_acc": 60.0}
{"epoch": 50, "training_loss": 266.8546875, "training_acc": 50.0, "val_loss": 112.70574188232422, "val_acc": 60.0}
{"epoch": 51, "training_loss": 112.89662017822266, "training_acc": 50.0, "val_loss": 239.7425994873047, "val_acc": 40.0}
{"epoch": 52, "training_loss": 138.19669570922852, "training_acc": 50.0, "val_loss": 65.53227996826172, "val_acc": 60.0}
{"epoch": 53, "training_loss": 64.74405064915481, "training_acc": 55.0, "val_loss": 51.5883674621582, "val_acc": 60.0}
{"epoch": 54, "training_loss": 55.80896072387695, "training_acc": 50.0, "val_loss": 188.50621032714844, "val_acc": 40.0}
{"epoch": 55, "training_loss": 203.45449829101562, "training_acc": 50.0, "val_loss": 100.44551849365234, "val_acc": 40.0}
{"epoch": 56, "training_loss": 106.15105895996093, "training_acc": 50.0, "val_loss": 157.31468200683594, "val_acc": 60.0}
{"epoch": 57, "training_loss": 111.49070846543182, "training_acc": 65.0, "val_loss": 140.599853515625, "val_acc": 40.0}
{"epoch": 58, "training_loss": 83.98802490234375, "training_acc": 50.0, "val_loss": 143.07919311523438, "val_acc": 60.0}
