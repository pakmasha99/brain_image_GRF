"main_modify.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 2 --task ADNI_sex --input_option yAware --learning_rate 5e0 --batch_size 8 --weight_decay 5e-4 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 268.71239881515504, "training_acc": 50.0, "val_loss": 137.3678741455078, "val_acc": 60.0}
{"epoch": 1, "training_loss": 268.04920654296876, "training_acc": 40.0, "val_loss": 33.377376556396484, "val_acc": 40.0}
{"epoch": 2, "training_loss": 178.31036987304688, "training_acc": 60.0, "val_loss": 327.2778015136719, "val_acc": 60.0}
{"epoch": 3, "training_loss": 250.91491775512696, "training_acc": 60.0, "val_loss": 296.2115783691406, "val_acc": 40.0}
{"epoch": 4, "training_loss": 227.12377014160157, "training_acc": 50.0, "val_loss": 143.72103881835938, "val_acc": 60.0}
{"epoch": 5, "training_loss": 216.61615600585938, "training_acc": 50.0, "val_loss": 46.5370979309082, "val_acc": 60.0}
{"epoch": 6, "training_loss": 221.32437133789062, "training_acc": 40.0, "val_loss": 476.6603088378906, "val_acc": 40.0}
{"epoch": 7, "training_loss": 298.92882537841797, "training_acc": 50.0, "val_loss": 142.78355407714844, "val_acc": 60.0}
{"epoch": 8, "training_loss": 237.92208251953124, "training_acc": 50.0, "val_loss": 176.4530029296875, "val_acc": 60.0}
{"epoch": 9, "training_loss": 209.42342147827148, "training_acc": 40.0, "val_loss": 356.8318786621094, "val_acc": 40.0}
{"epoch": 10, "training_loss": 258.98658447265626, "training_acc": 50.0, "val_loss": 73.38668823242188, "val_acc": 60.0}
{"epoch": 11, "training_loss": 235.97569580078124, "training_acc": 50.0, "val_loss": 146.7727508544922, "val_acc": 60.0}
{"epoch": 12, "training_loss": 118.49644165039062, "training_acc": 50.0, "val_loss": 172.7809600830078, "val_acc": 40.0}
{"epoch": 13, "training_loss": 87.84321736358106, "training_acc": 40.0, "val_loss": 9.705233573913574, "val_acc": 40.0}
{"epoch": 14, "training_loss": 19.830359172821044, "training_acc": 55.0, "val_loss": 41.94877243041992, "val_acc": 60.0}
{"epoch": 15, "training_loss": 68.84649543762207, "training_acc": 40.0, "val_loss": 119.1393814086914, "val_acc": 40.0}
{"epoch": 16, "training_loss": 41.14006786346435, "training_acc": 65.0, "val_loss": 124.72338104248047, "val_acc": 60.0}
{"epoch": 17, "training_loss": 166.99565734863282, "training_acc": 30.0, "val_loss": 137.2391815185547, "val_acc": 40.0}
{"epoch": 18, "training_loss": 73.14556007385254, "training_acc": 40.0, "val_loss": 67.42626953125, "val_acc": 40.0}
{"epoch": 19, "training_loss": 47.88823623657227, "training_acc": 50.0, "val_loss": 70.3883056640625, "val_acc": 60.0}
{"epoch": 20, "training_loss": 87.69504804611206, "training_acc": 30.0, "val_loss": 51.44629669189453, "val_acc": 60.0}
{"epoch": 21, "training_loss": 62.06174240112305, "training_acc": 50.0, "val_loss": 70.31389617919922, "val_acc": 40.0}
{"epoch": 22, "training_loss": 16.064084625244142, "training_acc": 70.0, "val_loss": 182.1592254638672, "val_acc": 60.0}
{"epoch": 23, "training_loss": 214.79808349609374, "training_acc": 50.0, "val_loss": 32.90276336669922, "val_acc": 40.0}
{"epoch": 24, "training_loss": 33.98673897981557, "training_acc": 55.0, "val_loss": 40.74003219604492, "val_acc": 60.0}
{"epoch": 25, "training_loss": 33.931880950927734, "training_acc": 60.0, "val_loss": 176.07981872558594, "val_acc": 40.0}
{"epoch": 26, "training_loss": 151.3642333984375, "training_acc": 30.0, "val_loss": 31.88204002380371, "val_acc": 60.0}
{"epoch": 27, "training_loss": 54.977521133422854, "training_acc": 50.0, "val_loss": 1.4071016311645508, "val_acc": 60.0}
{"epoch": 28, "training_loss": 34.549249219894406, "training_acc": 55.0, "val_loss": 175.4506378173828, "val_acc": 40.0}
{"epoch": 29, "training_loss": 195.61469116210938, "training_acc": 50.0, "val_loss": 62.310726165771484, "val_acc": 40.0}
{"epoch": 30, "training_loss": 157.65753173828125, "training_acc": 50.0, "val_loss": 259.8929138183594, "val_acc": 60.0}
{"epoch": 31, "training_loss": 236.925244140625, "training_acc": 50.0, "val_loss": 232.4420623779297, "val_acc": 40.0}
{"epoch": 32, "training_loss": 272.6256591796875, "training_acc": 50.0, "val_loss": 324.3653259277344, "val_acc": 40.0}
{"epoch": 33, "training_loss": 162.25550384521483, "training_acc": 60.0, "val_loss": 238.6443328857422, "val_acc": 60.0}
{"epoch": 34, "training_loss": 329.9902587890625, "training_acc": 50.0, "val_loss": 107.1881332397461, "val_acc": 60.0}
{"epoch": 35, "training_loss": 146.18989334106445, "training_acc": 60.0, "val_loss": 253.5473175048828, "val_acc": 40.0}
{"epoch": 36, "training_loss": 177.83844604492188, "training_acc": 40.0, "val_loss": 210.90782165527344, "val_acc": 60.0}
{"epoch": 37, "training_loss": 228.33673324584962, "training_acc": 50.0, "val_loss": 129.87962341308594, "val_acc": 40.0}
{"epoch": 38, "training_loss": 139.5560302734375, "training_acc": 50.0, "val_loss": 19.522602081298828, "val_acc": 40.0}
{"epoch": 39, "training_loss": 158.3179416656494, "training_acc": 40.0, "val_loss": 185.0458984375, "val_acc": 60.0}
{"epoch": 40, "training_loss": 148.8667205810547, "training_acc": 50.0, "val_loss": 200.55133056640625, "val_acc": 40.0}
{"epoch": 41, "training_loss": 160.83738021850587, "training_acc": 50.0, "val_loss": 92.5608901977539, "val_acc": 60.0}
{"epoch": 42, "training_loss": 120.92732849121094, "training_acc": 50.0, "val_loss": 52.26982498168945, "val_acc": 40.0}
{"epoch": 43, "training_loss": 60.69719696044922, "training_acc": 50.0, "val_loss": 74.20895385742188, "val_acc": 60.0}
{"epoch": 44, "training_loss": 101.1766357421875, "training_acc": 50.0, "val_loss": 124.812255859375, "val_acc": 40.0}
{"epoch": 45, "training_loss": 123.14751739501953, "training_acc": 50.0, "val_loss": 74.7996826171875, "val_acc": 60.0}
{"epoch": 46, "training_loss": 96.11407470703125, "training_acc": 50.0, "val_loss": 130.7307891845703, "val_acc": 40.0}
