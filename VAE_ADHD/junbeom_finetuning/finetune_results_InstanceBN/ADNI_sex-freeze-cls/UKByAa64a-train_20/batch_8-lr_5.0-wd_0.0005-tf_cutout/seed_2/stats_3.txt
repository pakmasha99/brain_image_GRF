"main_modify.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 2 --task ADNI_sex --input_option yAware --learning_rate 5e0 --batch_size 8 --weight_decay 5e-4 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 472.49313662052157, "training_acc": 55.0, "val_loss": 80.0406265258789, "val_acc": 60.0}
{"epoch": 1, "training_loss": 293.8020874023438, "training_acc": 45.0, "val_loss": 46.206634521484375, "val_acc": 60.0}
{"epoch": 2, "training_loss": 375.68365173339845, "training_acc": 35.0, "val_loss": 691.3987426757812, "val_acc": 40.0}
{"epoch": 3, "training_loss": 406.5557388305664, "training_acc": 55.0, "val_loss": 126.900390625, "val_acc": 60.0}
{"epoch": 4, "training_loss": 383.092919921875, "training_acc": 45.0, "val_loss": 170.33128356933594, "val_acc": 60.0}
{"epoch": 5, "training_loss": 341.946142578125, "training_acc": 25.0, "val_loss": 391.3138122558594, "val_acc": 40.0}
{"epoch": 6, "training_loss": 201.3093994140625, "training_acc": 55.0, "val_loss": 161.8835906982422, "val_acc": 60.0}
{"epoch": 7, "training_loss": 287.569873046875, "training_acc": 45.0, "val_loss": 177.2178192138672, "val_acc": 60.0}
{"epoch": 8, "training_loss": 117.91287078857422, "training_acc": 55.0, "val_loss": 451.8704528808594, "val_acc": 40.0}
{"epoch": 9, "training_loss": 370.5430908203125, "training_acc": 55.0, "val_loss": 405.95367431640625, "val_acc": 40.0}
{"epoch": 10, "training_loss": 224.11510467529297, "training_acc": 45.0, "val_loss": 119.5208969116211, "val_acc": 60.0}
{"epoch": 11, "training_loss": 95.09550819396972, "training_acc": 45.0, "val_loss": 309.6204528808594, "val_acc": 40.0}
{"epoch": 12, "training_loss": 358.49580078125, "training_acc": 55.0, "val_loss": 537.7389526367188, "val_acc": 40.0}
{"epoch": 13, "training_loss": 303.2247547149658, "training_acc": 55.0, "val_loss": 149.28587341308594, "val_acc": 60.0}
{"epoch": 14, "training_loss": 272.9769348144531, "training_acc": 45.0, "val_loss": 175.0658416748047, "val_acc": 60.0}
{"epoch": 15, "training_loss": 145.51790466308594, "training_acc": 45.0, "val_loss": 427.4421081542969, "val_acc": 40.0}
{"epoch": 16, "training_loss": 321.1981689453125, "training_acc": 55.0, "val_loss": 275.9496154785156, "val_acc": 40.0}
{"epoch": 17, "training_loss": 171.54434661865236, "training_acc": 45.0, "val_loss": 235.6259307861328, "val_acc": 60.0}
{"epoch": 18, "training_loss": 302.05596923828125, "training_acc": 45.0, "val_loss": 49.07661056518555, "val_acc": 40.0}
{"epoch": 19, "training_loss": 112.15569305419922, "training_acc": 55.0, "val_loss": 117.64041900634766, "val_acc": 40.0}
{"epoch": 20, "training_loss": 91.87943725585937, "training_acc": 45.0, "val_loss": 28.454736709594727, "val_acc": 60.0}
{"epoch": 21, "training_loss": 126.18419189453125, "training_acc": 45.0, "val_loss": 200.27236938476562, "val_acc": 40.0}
{"epoch": 22, "training_loss": 98.48945922851563, "training_acc": 55.0, "val_loss": 210.91250610351562, "val_acc": 60.0}
{"epoch": 23, "training_loss": 242.33350257873536, "training_acc": 45.0, "val_loss": 144.26980590820312, "val_acc": 40.0}
{"epoch": 24, "training_loss": 124.33051147460938, "training_acc": 55.0, "val_loss": 66.42413330078125, "val_acc": 40.0}
{"epoch": 25, "training_loss": 9.413394939899444, "training_acc": 75.0, "val_loss": 34.72633361816406, "val_acc": 40.0}
{"epoch": 26, "training_loss": 19.988145446777345, "training_acc": 55.0, "val_loss": 5.666494846343994, "val_acc": 60.0}
{"epoch": 27, "training_loss": 91.06641387939453, "training_acc": 45.0, "val_loss": 28.23025894165039, "val_acc": 60.0}
{"epoch": 28, "training_loss": 104.50644073486328, "training_acc": 55.0, "val_loss": 274.0856018066406, "val_acc": 40.0}
{"epoch": 29, "training_loss": 154.0664321899414, "training_acc": 45.0, "val_loss": 74.22209167480469, "val_acc": 60.0}
{"epoch": 30, "training_loss": 81.67329483032226, "training_acc": 35.0, "val_loss": 87.48863983154297, "val_acc": 60.0}
{"epoch": 31, "training_loss": 116.29048156738281, "training_acc": 45.0, "val_loss": 114.10124969482422, "val_acc": 40.0}
{"epoch": 32, "training_loss": 89.16548690795898, "training_acc": 55.0, "val_loss": 20.074708938598633, "val_acc": 60.0}
{"epoch": 33, "training_loss": 35.67921943664551, "training_acc": 35.0, "val_loss": 9.384263038635254, "val_acc": 60.0}
{"epoch": 34, "training_loss": 54.12617301940918, "training_acc": 65.0, "val_loss": 188.6199493408203, "val_acc": 40.0}
{"epoch": 35, "training_loss": 93.53009033203125, "training_acc": 55.0, "val_loss": 117.88787841796875, "val_acc": 60.0}
{"epoch": 36, "training_loss": 121.34275817871094, "training_acc": 45.0, "val_loss": 115.6214828491211, "val_acc": 40.0}
{"epoch": 37, "training_loss": 63.946363830566405, "training_acc": 55.0, "val_loss": 47.42353439331055, "val_acc": 60.0}
{"epoch": 38, "training_loss": 44.96802520751953, "training_acc": 55.0, "val_loss": 47.6600341796875, "val_acc": 60.0}
{"epoch": 39, "training_loss": 62.086419677734376, "training_acc": 55.0, "val_loss": 155.1629180908203, "val_acc": 40.0}
{"epoch": 40, "training_loss": 104.9119384765625, "training_acc": 55.0, "val_loss": 56.75558090209961, "val_acc": 60.0}
{"epoch": 41, "training_loss": 73.19987545013427, "training_acc": 45.0, "val_loss": 262.4585266113281, "val_acc": 40.0}
{"epoch": 42, "training_loss": 254.35104370117188, "training_acc": 55.0, "val_loss": 329.8457336425781, "val_acc": 40.0}
{"epoch": 43, "training_loss": 190.43121948242188, "training_acc": 45.0, "val_loss": 177.16497802734375, "val_acc": 60.0}
{"epoch": 44, "training_loss": 181.68024291992188, "training_acc": 45.0, "val_loss": 228.6025848388672, "val_acc": 40.0}
{"epoch": 45, "training_loss": 273.05955200195314, "training_acc": 55.0, "val_loss": 404.6643981933594, "val_acc": 40.0}
