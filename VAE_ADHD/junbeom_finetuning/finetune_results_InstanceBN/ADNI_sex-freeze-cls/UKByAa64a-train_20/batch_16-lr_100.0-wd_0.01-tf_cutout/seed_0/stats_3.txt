"main_modify.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_sex --input_option yAware --learning_rate 1e2 --batch_size 16 --weight_decay 1e-2 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 6406.846157550812, "training_acc": 50.0, "val_loss": 7260.54248046875, "val_acc": 40.0}
{"epoch": 1, "training_loss": 6153.540625, "training_acc": 55.0, "val_loss": 12798.7138671875, "val_acc": 60.0}
{"epoch": 2, "training_loss": 17215.757421875, "training_acc": 45.0, "val_loss": 6420.13671875, "val_acc": 60.0}
{"epoch": 3, "training_loss": 7266.509649658203, "training_acc": 45.0, "val_loss": 7757.1455078125, "val_acc": 40.0}
{"epoch": 4, "training_loss": 6090.837890625, "training_acc": 55.0, "val_loss": 11235.8017578125, "val_acc": 40.0}
{"epoch": 5, "training_loss": 8125.06904296875, "training_acc": 55.0, "val_loss": 2671.73388671875, "val_acc": 40.0}
{"epoch": 6, "training_loss": 1610.0498779296875, "training_acc": 65.0, "val_loss": 4965.23046875, "val_acc": 60.0}
{"epoch": 7, "training_loss": 7102.59921875, "training_acc": 45.0, "val_loss": 4247.0009765625, "val_acc": 60.0}
{"epoch": 8, "training_loss": 5460.789929199219, "training_acc": 45.0, "val_loss": 3025.31396484375, "val_acc": 40.0}
{"epoch": 9, "training_loss": 2260.3078125, "training_acc": 55.0, "val_loss": 7065.0390625, "val_acc": 40.0}
{"epoch": 10, "training_loss": 5183.6939453125, "training_acc": 55.0, "val_loss": 3144.103271484375, "val_acc": 40.0}
{"epoch": 11, "training_loss": 2333.0443115234375, "training_acc": 45.0, "val_loss": 1951.8590087890625, "val_acc": 60.0}
{"epoch": 12, "training_loss": 2778.01767578125, "training_acc": 45.0, "val_loss": 499.2320251464844, "val_acc": 60.0}
{"epoch": 13, "training_loss": 1029.7880859375, "training_acc": 45.0, "val_loss": 4426.09521484375, "val_acc": 40.0}
{"epoch": 14, "training_loss": 3253.7142578125, "training_acc": 55.0, "val_loss": 1891.6910400390625, "val_acc": 40.0}
{"epoch": 15, "training_loss": 1640.2272216796875, "training_acc": 45.0, "val_loss": 1810.41796875, "val_acc": 60.0}
{"epoch": 16, "training_loss": 2344.262158203125, "training_acc": 45.0, "val_loss": 429.2509765625, "val_acc": 40.0}
{"epoch": 17, "training_loss": 417.1743530273437, "training_acc": 55.0, "val_loss": 1755.9176025390625, "val_acc": 40.0}
{"epoch": 18, "training_loss": 1117.92666015625, "training_acc": 55.0, "val_loss": 1167.52734375, "val_acc": 60.0}
{"epoch": 19, "training_loss": 1754.75673828125, "training_acc": 45.0, "val_loss": 455.5084533691406, "val_acc": 60.0}
{"epoch": 20, "training_loss": 1169.7216796875, "training_acc": 35.0, "val_loss": 2952.755615234375, "val_acc": 40.0}
{"epoch": 21, "training_loss": 2017.988232421875, "training_acc": 55.0, "val_loss": 523.0460205078125, "val_acc": 60.0}
{"epoch": 22, "training_loss": 859.6520751953125, "training_acc": 45.0, "val_loss": 595.4088745117188, "val_acc": 60.0}
{"epoch": 23, "training_loss": 887.7630859375, "training_acc": 45.0, "val_loss": 1833.8817138671875, "val_acc": 40.0}
{"epoch": 24, "training_loss": 1278.5927307128907, "training_acc": 55.0, "val_loss": 729.99072265625, "val_acc": 60.0}
{"epoch": 25, "training_loss": 1106.378564453125, "training_acc": 45.0, "val_loss": 1063.9503173828125, "val_acc": 40.0}
{"epoch": 26, "training_loss": 795.69794921875, "training_acc": 55.0, "val_loss": 1858.1771240234375, "val_acc": 40.0}
{"epoch": 27, "training_loss": 1040.204931640625, "training_acc": 55.0, "val_loss": 1860.6484375, "val_acc": 60.0}
{"epoch": 28, "training_loss": 3064.6287109375, "training_acc": 45.0, "val_loss": 1463.4100341796875, "val_acc": 60.0}
{"epoch": 29, "training_loss": 1583.4606567382812, "training_acc": 55.0, "val_loss": 3818.192138671875, "val_acc": 40.0}
{"epoch": 30, "training_loss": 2852.8953369140627, "training_acc": 55.0, "val_loss": 2251.713623046875, "val_acc": 40.0}
{"epoch": 31, "training_loss": 1729.926708984375, "training_acc": 45.0, "val_loss": 1125.663330078125, "val_acc": 60.0}
{"epoch": 32, "training_loss": 1353.6144897460938, "training_acc": 45.0, "val_loss": 1917.224609375, "val_acc": 40.0}
{"epoch": 33, "training_loss": 1538.97265625, "training_acc": 55.0, "val_loss": 1218.4368896484375, "val_acc": 40.0}
{"epoch": 34, "training_loss": 1200.8565673828125, "training_acc": 45.0, "val_loss": 1174.1683349609375, "val_acc": 60.0}
{"epoch": 35, "training_loss": 1498.9816650390626, "training_acc": 35.0, "val_loss": 100.0768051147461, "val_acc": 60.0}
{"epoch": 36, "training_loss": 442.175634765625, "training_acc": 35.0, "val_loss": 281.0472412109375, "val_acc": 40.0}
{"epoch": 37, "training_loss": 278.98402099609376, "training_acc": 65.0, "val_loss": 1582.2235107421875, "val_acc": 60.0}
{"epoch": 38, "training_loss": 1930.20166015625, "training_acc": 45.0, "val_loss": 1972.2855224609375, "val_acc": 40.0}
{"epoch": 39, "training_loss": 1630.9892578125, "training_acc": 55.0, "val_loss": 1695.3143310546875, "val_acc": 40.0}
{"epoch": 40, "training_loss": 1154.4701782226562, "training_acc": 55.0, "val_loss": 1229.5689697265625, "val_acc": 60.0}
{"epoch": 41, "training_loss": 1571.9539764404296, "training_acc": 45.0, "val_loss": 1647.7005615234375, "val_acc": 40.0}
{"epoch": 42, "training_loss": 1239.068994140625, "training_acc": 55.0, "val_loss": 677.1277465820312, "val_acc": 40.0}
{"epoch": 43, "training_loss": 667.4579345703125, "training_acc": 55.0, "val_loss": 1298.0677490234375, "val_acc": 60.0}
{"epoch": 44, "training_loss": 1481.7215789794923, "training_acc": 45.0, "val_loss": 2919.085693359375, "val_acc": 40.0}
{"epoch": 45, "training_loss": 2312.2498046875, "training_acc": 55.0, "val_loss": 2041.763671875, "val_acc": 40.0}
{"epoch": 46, "training_loss": 1703.6060546875, "training_acc": 45.0, "val_loss": 1342.6663818359375, "val_acc": 60.0}
{"epoch": 47, "training_loss": 1503.0713745117187, "training_acc": 45.0, "val_loss": 2878.12158203125, "val_acc": 40.0}
{"epoch": 48, "training_loss": 2351.20166015625, "training_acc": 55.0, "val_loss": 2649.206298828125, "val_acc": 40.0}
{"epoch": 49, "training_loss": 1631.2653076171875, "training_acc": 55.0, "val_loss": 1257.287353515625, "val_acc": 60.0}
{"epoch": 50, "training_loss": 1637.7458740234374, "training_acc": 45.0, "val_loss": 1104.6273193359375, "val_acc": 40.0}
{"epoch": 51, "training_loss": 826.0123046875, "training_acc": 55.0, "val_loss": 510.54443359375, "val_acc": 40.0}
{"epoch": 52, "training_loss": 344.87635498046876, "training_acc": 65.0, "val_loss": 1003.7272338867188, "val_acc": 60.0}
{"epoch": 53, "training_loss": 1009.0038887023926, "training_acc": 45.0, "val_loss": 3494.661865234375, "val_acc": 40.0}
{"epoch": 54, "training_loss": 2768.787109375, "training_acc": 55.0, "val_loss": 2641.4130859375, "val_acc": 40.0}
