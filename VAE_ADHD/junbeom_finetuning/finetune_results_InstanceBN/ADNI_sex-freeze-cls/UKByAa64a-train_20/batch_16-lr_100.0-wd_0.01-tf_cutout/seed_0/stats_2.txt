"main_modify.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_sex --input_option yAware --learning_rate 1e2 --batch_size 16 --weight_decay 1e-2 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 4254.738616752625, "training_acc": 50.0, "val_loss": 4572.390625, "val_acc": 60.0}
{"epoch": 1, "training_loss": 6673.8142578125, "training_acc": 50.0, "val_loss": 19631.896484375, "val_acc": 40.0}
{"epoch": 2, "training_loss": 15883.52265625, "training_acc": 50.0, "val_loss": 8766.9296875, "val_acc": 40.0}
{"epoch": 3, "training_loss": 6985.4810546875, "training_acc": 40.0, "val_loss": 5587.16357421875, "val_acc": 60.0}
{"epoch": 4, "training_loss": 7407.7142578125, "training_acc": 50.0, "val_loss": 6519.9736328125, "val_acc": 60.0}
{"epoch": 5, "training_loss": 7424.1728515625, "training_acc": 50.0, "val_loss": 453.3036193847656, "val_acc": 40.0}
{"epoch": 6, "training_loss": 1864.179296875, "training_acc": 50.0, "val_loss": 5703.779296875, "val_acc": 40.0}
{"epoch": 7, "training_loss": 4508.15185546875, "training_acc": 50.0, "val_loss": 1044.2572021484375, "val_acc": 40.0}
{"epoch": 8, "training_loss": 1587.98017578125, "training_acc": 40.0, "val_loss": 3236.68994140625, "val_acc": 60.0}
{"epoch": 9, "training_loss": 3942.183984375, "training_acc": 50.0, "val_loss": 943.9679565429688, "val_acc": 60.0}
{"epoch": 10, "training_loss": 1401.6607421875, "training_acc": 50.0, "val_loss": 4959.0458984375, "val_acc": 40.0}
{"epoch": 11, "training_loss": 4117.988549804688, "training_acc": 50.0, "val_loss": 3214.535888671875, "val_acc": 40.0}
{"epoch": 12, "training_loss": 1929.3501953125, "training_acc": 50.0, "val_loss": 2740.91748046875, "val_acc": 60.0}
{"epoch": 13, "training_loss": 3575.706298828125, "training_acc": 50.0, "val_loss": 4009.501220703125, "val_acc": 60.0}
{"epoch": 14, "training_loss": 4462.6056640625, "training_acc": 50.0, "val_loss": 394.9726257324219, "val_acc": 40.0}
{"epoch": 15, "training_loss": 786.83544921875, "training_acc": 50.0, "val_loss": 3886.45361328125, "val_acc": 40.0}
{"epoch": 16, "training_loss": 3040.3251953125, "training_acc": 50.0, "val_loss": 7.657237529754639, "val_acc": 60.0}
{"epoch": 17, "training_loss": 111.61694946289063, "training_acc": 50.0, "val_loss": 1031.4970703125, "val_acc": 60.0}
{"epoch": 18, "training_loss": 1093.5579223632812, "training_acc": 50.0, "val_loss": 1882.4921875, "val_acc": 40.0}
{"epoch": 19, "training_loss": 1655.010205078125, "training_acc": 50.0, "val_loss": 1207.676025390625, "val_acc": 40.0}
{"epoch": 20, "training_loss": 801.8269958496094, "training_acc": 60.0, "val_loss": 1631.42919921875, "val_acc": 60.0}
{"epoch": 21, "training_loss": 1936.545068359375, "training_acc": 50.0, "val_loss": 491.5244140625, "val_acc": 40.0}
{"epoch": 22, "training_loss": 581.166552734375, "training_acc": 50.0, "val_loss": 917.23486328125, "val_acc": 40.0}
{"epoch": 23, "training_loss": 608.3733154296875, "training_acc": 60.0, "val_loss": 1144.5135498046875, "val_acc": 60.0}
{"epoch": 24, "training_loss": 1283.8516357421875, "training_acc": 50.0, "val_loss": 1336.21875, "val_acc": 40.0}
{"epoch": 25, "training_loss": 1185.909033203125, "training_acc": 50.0, "val_loss": 541.1963500976562, "val_acc": 40.0}
{"epoch": 26, "training_loss": 932.7138427734375, "training_acc": 40.0, "val_loss": 1436.3494873046875, "val_acc": 60.0}
{"epoch": 27, "training_loss": 1501.2605712890625, "training_acc": 50.0, "val_loss": 2502.885986328125, "val_acc": 40.0}
{"epoch": 28, "training_loss": 2216.52431640625, "training_acc": 50.0, "val_loss": 1939.4832763671875, "val_acc": 40.0}
{"epoch": 29, "training_loss": 1460.96435546875, "training_acc": 50.0, "val_loss": 1449.772705078125, "val_acc": 60.0}
{"epoch": 30, "training_loss": 1678.6966064453125, "training_acc": 50.0, "val_loss": 928.9152221679688, "val_acc": 40.0}
{"epoch": 31, "training_loss": 958.721337890625, "training_acc": 50.0, "val_loss": 19.94080924987793, "val_acc": 60.0}
{"epoch": 32, "training_loss": 60.93168640136719, "training_acc": 50.0, "val_loss": 930.6873168945312, "val_acc": 40.0}
{"epoch": 33, "training_loss": 695.720458984375, "training_acc": 50.0, "val_loss": 1227.860595703125, "val_acc": 60.0}
{"epoch": 34, "training_loss": 1549.295947265625, "training_acc": 50.0, "val_loss": 746.3922119140625, "val_acc": 60.0}
{"epoch": 35, "training_loss": 973.77255859375, "training_acc": 50.0, "val_loss": 1948.1177978515625, "val_acc": 40.0}
