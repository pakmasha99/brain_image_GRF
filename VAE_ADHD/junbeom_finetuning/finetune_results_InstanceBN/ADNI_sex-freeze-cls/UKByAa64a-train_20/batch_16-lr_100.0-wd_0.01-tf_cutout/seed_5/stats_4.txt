"main_modify.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 5 --task ADNI_sex --input_option yAware --learning_rate 1e2 --batch_size 16 --weight_decay 1e-2 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 2135.549694252014, "training_acc": 60.0, "val_loss": 4535.31005859375, "val_acc": 60.0}
{"epoch": 1, "training_loss": 3395.1421875, "training_acc": 70.0, "val_loss": 21611.974609375, "val_acc": 40.0}
{"epoch": 2, "training_loss": 17750.9720703125, "training_acc": 50.0, "val_loss": 9993.455078125, "val_acc": 40.0}
{"epoch": 3, "training_loss": 6829.558068847657, "training_acc": 50.0, "val_loss": 5975.99267578125, "val_acc": 60.0}
{"epoch": 4, "training_loss": 7728.87587890625, "training_acc": 50.0, "val_loss": 7740.015625, "val_acc": 60.0}
{"epoch": 5, "training_loss": 9312.019287109375, "training_acc": 50.0, "val_loss": 917.8447265625, "val_acc": 60.0}
{"epoch": 6, "training_loss": 1238.940966796875, "training_acc": 60.0, "val_loss": 9451.865234375, "val_acc": 40.0}
{"epoch": 7, "training_loss": 8005.886328125, "training_acc": 50.0, "val_loss": 7651.34228515625, "val_acc": 40.0}
{"epoch": 8, "training_loss": 4868.9708984375, "training_acc": 50.0, "val_loss": 2405.814453125, "val_acc": 60.0}
{"epoch": 9, "training_loss": 4115.811328125, "training_acc": 50.0, "val_loss": 5927.400390625, "val_acc": 60.0}
{"epoch": 10, "training_loss": 7224.324658203125, "training_acc": 50.0, "val_loss": 2083.8427734375, "val_acc": 60.0}
{"epoch": 11, "training_loss": 2387.561767578125, "training_acc": 50.0, "val_loss": 4913.72607421875, "val_acc": 40.0}
{"epoch": 12, "training_loss": 4460.749609375, "training_acc": 50.0, "val_loss": 3771.956298828125, "val_acc": 40.0}
{"epoch": 13, "training_loss": 2239.309844970703, "training_acc": 50.0, "val_loss": 3142.47314453125, "val_acc": 60.0}
{"epoch": 14, "training_loss": 3916.93046875, "training_acc": 50.0, "val_loss": 5029.734375, "val_acc": 60.0}
{"epoch": 15, "training_loss": 5958.31669921875, "training_acc": 50.0, "val_loss": 1183.749267578125, "val_acc": 60.0}
{"epoch": 16, "training_loss": 1284.244677734375, "training_acc": 60.0, "val_loss": 6185.4375, "val_acc": 40.0}
{"epoch": 17, "training_loss": 5260.26513671875, "training_acc": 50.0, "val_loss": 4936.34716796875, "val_acc": 40.0}
{"epoch": 18, "training_loss": 3215.7058349609374, "training_acc": 50.0, "val_loss": 2502.221923828125, "val_acc": 60.0}
{"epoch": 19, "training_loss": 3346.7990234375, "training_acc": 50.0, "val_loss": 4663.04833984375, "val_acc": 60.0}
{"epoch": 20, "training_loss": 5366.4275390625, "training_acc": 50.0, "val_loss": 582.9514770507812, "val_acc": 60.0}
{"epoch": 21, "training_loss": 1294.26171875, "training_acc": 50.0, "val_loss": 6966.74169921875, "val_acc": 40.0}
{"epoch": 22, "training_loss": 5796.95703125, "training_acc": 50.0, "val_loss": 4324.8154296875, "val_acc": 40.0}
{"epoch": 23, "training_loss": 2564.307513427734, "training_acc": 50.0, "val_loss": 3517.468017578125, "val_acc": 60.0}
{"epoch": 24, "training_loss": 4844.55712890625, "training_acc": 50.0, "val_loss": 5142.2802734375, "val_acc": 60.0}
{"epoch": 25, "training_loss": 6162.531982421875, "training_acc": 50.0, "val_loss": 233.72314453125, "val_acc": 60.0}
{"epoch": 26, "training_loss": 1474.5333984375, "training_acc": 40.0, "val_loss": 6863.44873046875, "val_acc": 40.0}
{"epoch": 27, "training_loss": 5607.4982421875, "training_acc": 50.0, "val_loss": 3101.661376953125, "val_acc": 40.0}
{"epoch": 28, "training_loss": 2304.905615234375, "training_acc": 50.0, "val_loss": 2721.919189453125, "val_acc": 60.0}
{"epoch": 29, "training_loss": 3539.78984375, "training_acc": 50.0, "val_loss": 1661.6483154296875, "val_acc": 60.0}
{"epoch": 30, "training_loss": 2181.75927734375, "training_acc": 40.0, "val_loss": 2670.913330078125, "val_acc": 40.0}
{"epoch": 31, "training_loss": 2156.55, "training_acc": 50.0, "val_loss": 61.61027908325195, "val_acc": 60.0}
{"epoch": 32, "training_loss": 257.23419189453125, "training_acc": 50.0, "val_loss": 492.611083984375, "val_acc": 60.0}
{"epoch": 33, "training_loss": 654.570068359375, "training_acc": 50.0, "val_loss": 1144.556640625, "val_acc": 40.0}
{"epoch": 34, "training_loss": 925.9963439941406, "training_acc": 40.0, "val_loss": 266.16943359375, "val_acc": 40.0}
{"epoch": 35, "training_loss": 358.5304321289062, "training_acc": 40.0, "val_loss": 468.21533203125, "val_acc": 40.0}
{"epoch": 36, "training_loss": 354.0736511230469, "training_acc": 50.0, "val_loss": 1125.2816162109375, "val_acc": 60.0}
{"epoch": 37, "training_loss": 1495.74453125, "training_acc": 50.0, "val_loss": 94.4186782836914, "val_acc": 60.0}
{"epoch": 38, "training_loss": 854.5702880859375, "training_acc": 40.0, "val_loss": 3316.544677734375, "val_acc": 40.0}
{"epoch": 39, "training_loss": 2608.9529296875, "training_acc": 50.0, "val_loss": 740.61474609375, "val_acc": 60.0}
{"epoch": 40, "training_loss": 1071.434619140625, "training_acc": 50.0, "val_loss": 722.1368408203125, "val_acc": 60.0}
{"epoch": 41, "training_loss": 922.8901123046875, "training_acc": 50.0, "val_loss": 1769.3228759765625, "val_acc": 40.0}
{"epoch": 42, "training_loss": 1282.5079833984375, "training_acc": 50.0, "val_loss": 1219.410400390625, "val_acc": 60.0}
{"epoch": 43, "training_loss": 1605.26298828125, "training_acc": 50.0, "val_loss": 677.3075561523438, "val_acc": 60.0}
{"epoch": 44, "training_loss": 718.3142211914062, "training_acc": 60.0, "val_loss": 2838.3427734375, "val_acc": 40.0}
{"epoch": 45, "training_loss": 2289.172412109375, "training_acc": 50.0, "val_loss": 21.740100860595703, "val_acc": 60.0}
{"epoch": 46, "training_loss": 183.89793090820314, "training_acc": 50.0, "val_loss": 876.0929565429688, "val_acc": 40.0}
{"epoch": 47, "training_loss": 738.38271484375, "training_acc": 50.0, "val_loss": 808.5702514648438, "val_acc": 60.0}
{"epoch": 48, "training_loss": 1063.634130859375, "training_acc": 50.0, "val_loss": 107.52302551269531, "val_acc": 60.0}
{"epoch": 49, "training_loss": 768.3348876953125, "training_acc": 40.0, "val_loss": 2478.09423828125, "val_acc": 40.0}
{"epoch": 50, "training_loss": 1603.819580078125, "training_acc": 50.0, "val_loss": 2120.767333984375, "val_acc": 60.0}
{"epoch": 51, "training_loss": 2864.355712890625, "training_acc": 50.0, "val_loss": 2194.684326171875, "val_acc": 60.0}
{"epoch": 52, "training_loss": 1974.9359375, "training_acc": 50.0, "val_loss": 4572.09228515625, "val_acc": 40.0}
{"epoch": 53, "training_loss": 4121.9615234375, "training_acc": 50.0, "val_loss": 5209.79541015625, "val_acc": 40.0}
{"epoch": 54, "training_loss": 4020.128210449219, "training_acc": 50.0, "val_loss": 2101.820556640625, "val_acc": 60.0}
{"epoch": 55, "training_loss": 2775.633447265625, "training_acc": 50.0, "val_loss": 3090.769287109375, "val_acc": 60.0}
{"epoch": 56, "training_loss": 3615.554650878906, "training_acc": 50.0, "val_loss": 1988.5657958984375, "val_acc": 40.0}
{"epoch": 57, "training_loss": 2080.01171875, "training_acc": 50.0, "val_loss": 2273.7197265625, "val_acc": 40.0}
{"epoch": 58, "training_loss": 1970.79482421875, "training_acc": 40.0, "val_loss": 1202.1112060546875, "val_acc": 60.0}
{"epoch": 59, "training_loss": 1501.63974609375, "training_acc": 50.0, "val_loss": 1066.218505859375, "val_acc": 40.0}
{"epoch": 60, "training_loss": 829.1692993164063, "training_acc": 50.0, "val_loss": 755.7346801757812, "val_acc": 60.0}
{"epoch": 61, "training_loss": 993.1485595703125, "training_acc": 50.0, "val_loss": 872.416015625, "val_acc": 40.0}
{"epoch": 62, "training_loss": 872.28681640625, "training_acc": 50.0, "val_loss": 303.4355773925781, "val_acc": 60.0}
{"epoch": 63, "training_loss": 416.0090576171875, "training_acc": 50.0, "val_loss": 646.9057006835938, "val_acc": 40.0}
{"epoch": 64, "training_loss": 481.03233642578124, "training_acc": 50.0, "val_loss": 971.2304077148438, "val_acc": 60.0}
