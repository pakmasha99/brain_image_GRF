"main_modify.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 5 --task ADNI_sex --input_option yAware --learning_rate 1e2 --batch_size 16 --weight_decay 1e-2 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 8537.916845417023, "training_acc": 40.0, "val_loss": 7541.7744140625, "val_acc": 40.0}
{"epoch": 1, "training_loss": 3143.583203125, "training_acc": 75.0, "val_loss": 13875.291015625, "val_acc": 60.0}
{"epoch": 2, "training_loss": 19025.725, "training_acc": 45.0, "val_loss": 8576.9140625, "val_acc": 60.0}
{"epoch": 3, "training_loss": 11825.4140625, "training_acc": 45.0, "val_loss": 7666.02880859375, "val_acc": 40.0}
{"epoch": 4, "training_loss": 6251.4833984375, "training_acc": 55.0, "val_loss": 15465.53125, "val_acc": 40.0}
{"epoch": 5, "training_loss": 11415.02001953125, "training_acc": 55.0, "val_loss": 8396.9287109375, "val_acc": 40.0}
{"epoch": 6, "training_loss": 5740.432580566407, "training_acc": 55.0, "val_loss": 3407.378173828125, "val_acc": 60.0}
{"epoch": 7, "training_loss": 6148.134375, "training_acc": 45.0, "val_loss": 6562.90185546875, "val_acc": 60.0}
{"epoch": 8, "training_loss": 8828.077490234375, "training_acc": 45.0, "val_loss": 2322.47998046875, "val_acc": 60.0}
{"epoch": 9, "training_loss": 2453.25263671875, "training_acc": 55.0, "val_loss": 5371.787109375, "val_acc": 40.0}
{"epoch": 10, "training_loss": 4162.353125, "training_acc": 55.0, "val_loss": 6828.94287109375, "val_acc": 40.0}
{"epoch": 11, "training_loss": 5120.26796875, "training_acc": 55.0, "val_loss": 1567.1011962890625, "val_acc": 40.0}
{"epoch": 12, "training_loss": 1274.885302734375, "training_acc": 55.0, "val_loss": 2816.722900390625, "val_acc": 60.0}
{"epoch": 13, "training_loss": 3892.27216796875, "training_acc": 45.0, "val_loss": 1760.4808349609375, "val_acc": 60.0}
{"epoch": 14, "training_loss": 2048.901721191406, "training_acc": 45.0, "val_loss": 2122.54150390625, "val_acc": 40.0}
{"epoch": 15, "training_loss": 1610.1917724609375, "training_acc": 55.0, "val_loss": 1619.5133056640625, "val_acc": 40.0}
{"epoch": 16, "training_loss": 978.8505493164063, "training_acc": 55.0, "val_loss": 542.9389038085938, "val_acc": 60.0}
{"epoch": 17, "training_loss": 625.3895385742187, "training_acc": 45.0, "val_loss": 1607.6234130859375, "val_acc": 40.0}
{"epoch": 18, "training_loss": 1401.212060546875, "training_acc": 55.0, "val_loss": 263.5644226074219, "val_acc": 40.0}
{"epoch": 19, "training_loss": 820.4990478515625, "training_acc": 45.0, "val_loss": 2056.37548828125, "val_acc": 60.0}
{"epoch": 20, "training_loss": 2611.862939453125, "training_acc": 45.0, "val_loss": 815.53955078125, "val_acc": 40.0}
{"epoch": 21, "training_loss": 706.7534301757812, "training_acc": 55.0, "val_loss": 2044.1890869140625, "val_acc": 40.0}
{"epoch": 22, "training_loss": 1419.1138549804687, "training_acc": 55.0, "val_loss": 864.30615234375, "val_acc": 60.0}
{"epoch": 23, "training_loss": 1234.45927734375, "training_acc": 45.0, "val_loss": 253.333740234375, "val_acc": 60.0}
{"epoch": 24, "training_loss": 410.6525024414062, "training_acc": 55.0, "val_loss": 2983.202880859375, "val_acc": 40.0}
{"epoch": 25, "training_loss": 2236.534375, "training_acc": 55.0, "val_loss": 830.28955078125, "val_acc": 40.0}
{"epoch": 26, "training_loss": 527.0178588867187, "training_acc": 65.0, "val_loss": 1630.255615234375, "val_acc": 60.0}
{"epoch": 27, "training_loss": 2106.4754638671875, "training_acc": 45.0, "val_loss": 658.687255859375, "val_acc": 40.0}
{"epoch": 28, "training_loss": 643.1556396484375, "training_acc": 55.0, "val_loss": 831.0655517578125, "val_acc": 40.0}
{"epoch": 29, "training_loss": 852.3506591796875, "training_acc": 45.0, "val_loss": 640.9481811523438, "val_acc": 60.0}
{"epoch": 30, "training_loss": 1039.30068359375, "training_acc": 35.0, "val_loss": 666.5906372070312, "val_acc": 40.0}
{"epoch": 31, "training_loss": 386.1711181640625, "training_acc": 65.0, "val_loss": 718.083984375, "val_acc": 60.0}
{"epoch": 32, "training_loss": 835.2956481933594, "training_acc": 45.0, "val_loss": 5.009817600250244, "val_acc": 40.0}
{"epoch": 33, "training_loss": 199.33214282989502, "training_acc": 55.0, "val_loss": 486.32257080078125, "val_acc": 60.0}
{"epoch": 34, "training_loss": 426.6830078125, "training_acc": 65.0, "val_loss": 2235.72119140625, "val_acc": 40.0}
{"epoch": 35, "training_loss": 1600.41376953125, "training_acc": 55.0, "val_loss": 223.137451171875, "val_acc": 60.0}
{"epoch": 36, "training_loss": 372.45531005859374, "training_acc": 45.0, "val_loss": 380.0605163574219, "val_acc": 40.0}
{"epoch": 37, "training_loss": 247.68363342285156, "training_acc": 55.0, "val_loss": 913.7724609375, "val_acc": 60.0}
{"epoch": 38, "training_loss": 1211.8868286132813, "training_acc": 45.0, "val_loss": 569.3090209960938, "val_acc": 40.0}
{"epoch": 39, "training_loss": 408.2733612060547, "training_acc": 55.0, "val_loss": 391.3283386230469, "val_acc": 60.0}
{"epoch": 40, "training_loss": 473.7289093017578, "training_acc": 45.0, "val_loss": 312.5666198730469, "val_acc": 60.0}
{"epoch": 41, "training_loss": 345.1733673095703, "training_acc": 55.0, "val_loss": 383.83892822265625, "val_acc": 40.0}
{"epoch": 42, "training_loss": 251.90203857421875, "training_acc": 65.0, "val_loss": 573.9472045898438, "val_acc": 60.0}
{"epoch": 43, "training_loss": 952.005078125, "training_acc": 35.0, "val_loss": 276.8358459472656, "val_acc": 40.0}
{"epoch": 44, "training_loss": 425.7737060546875, "training_acc": 55.0, "val_loss": 993.1904296875, "val_acc": 60.0}
{"epoch": 45, "training_loss": 1207.285626220703, "training_acc": 45.0, "val_loss": 842.01708984375, "val_acc": 40.0}
{"epoch": 46, "training_loss": 432.41765823364256, "training_acc": 65.0, "val_loss": 190.2173309326172, "val_acc": 60.0}
{"epoch": 47, "training_loss": 419.7987548828125, "training_acc": 45.0, "val_loss": 868.9063720703125, "val_acc": 40.0}
{"epoch": 48, "training_loss": 498.23882446289065, "training_acc": 65.0, "val_loss": 860.1603393554688, "val_acc": 60.0}
{"epoch": 49, "training_loss": 868.1207782745362, "training_acc": 45.0, "val_loss": 3260.080322265625, "val_acc": 40.0}
{"epoch": 50, "training_loss": 2584.78603515625, "training_acc": 55.0, "val_loss": 2349.523193359375, "val_acc": 40.0}
{"epoch": 51, "training_loss": 1558.9262939453124, "training_acc": 55.0, "val_loss": 1666.6678466796875, "val_acc": 60.0}
