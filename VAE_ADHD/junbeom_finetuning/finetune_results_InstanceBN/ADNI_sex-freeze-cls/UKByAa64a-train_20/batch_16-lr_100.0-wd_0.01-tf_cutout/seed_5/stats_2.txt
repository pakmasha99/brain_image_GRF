"main_modify.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 5 --task ADNI_sex --input_option yAware --learning_rate 1e2 --batch_size 16 --weight_decay 1e-2 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 6416.970253801346, "training_acc": 40.0, "val_loss": 6911.02587890625, "val_acc": 40.0}
{"epoch": 1, "training_loss": 5035.88056640625, "training_acc": 60.0, "val_loss": 13844.5224609375, "val_acc": 60.0}
{"epoch": 2, "training_loss": 17158.7546875, "training_acc": 50.0, "val_loss": 7786.6376953125, "val_acc": 60.0}
{"epoch": 3, "training_loss": 8900.4595703125, "training_acc": 50.0, "val_loss": 8283.4052734375, "val_acc": 40.0}
{"epoch": 4, "training_loss": 6893.315625, "training_acc": 50.0, "val_loss": 15033.017578125, "val_acc": 40.0}
{"epoch": 5, "training_loss": 11861.181640625, "training_acc": 50.0, "val_loss": 6292.986328125, "val_acc": 40.0}
{"epoch": 6, "training_loss": 3772.7768493652343, "training_acc": 60.0, "val_loss": 4835.6650390625, "val_acc": 60.0}
{"epoch": 7, "training_loss": 6291.6189453125, "training_acc": 50.0, "val_loss": 6893.171875, "val_acc": 60.0}
{"epoch": 8, "training_loss": 8636.53046875, "training_acc": 50.0, "val_loss": 2340.052001953125, "val_acc": 60.0}
{"epoch": 9, "training_loss": 2180.6379272460936, "training_acc": 60.0, "val_loss": 5365.466796875, "val_acc": 40.0}
{"epoch": 10, "training_loss": 4718.9091796875, "training_acc": 50.0, "val_loss": 5951.64794921875, "val_acc": 40.0}
{"epoch": 11, "training_loss": 4269.934716796875, "training_acc": 50.0, "val_loss": 874.9434814453125, "val_acc": 60.0}
{"epoch": 12, "training_loss": 1578.19521484375, "training_acc": 50.0, "val_loss": 3341.9140625, "val_acc": 60.0}
{"epoch": 13, "training_loss": 3919.32763671875, "training_acc": 50.0, "val_loss": 541.7969970703125, "val_acc": 60.0}
{"epoch": 14, "training_loss": 731.323486328125, "training_acc": 60.0, "val_loss": 5553.0302734375, "val_acc": 40.0}
{"epoch": 15, "training_loss": 4627.031591796875, "training_acc": 50.0, "val_loss": 4035.376953125, "val_acc": 40.0}
{"epoch": 16, "training_loss": 2830.62841796875, "training_acc": 50.0, "val_loss": 2165.34228515625, "val_acc": 60.0}
{"epoch": 17, "training_loss": 3049.27978515625, "training_acc": 50.0, "val_loss": 3363.416748046875, "val_acc": 60.0}
{"epoch": 18, "training_loss": 4012.6913330078123, "training_acc": 50.0, "val_loss": 526.12646484375, "val_acc": 40.0}
{"epoch": 19, "training_loss": 907.3123046875, "training_acc": 50.0, "val_loss": 2013.2728271484375, "val_acc": 40.0}
{"epoch": 20, "training_loss": 1515.0649375915527, "training_acc": 50.0, "val_loss": 1531.605224609375, "val_acc": 60.0}
{"epoch": 21, "training_loss": 2010.736865234375, "training_acc": 50.0, "val_loss": 1120.6728515625, "val_acc": 60.0}
{"epoch": 22, "training_loss": 1040.051416015625, "training_acc": 60.0, "val_loss": 2168.433837890625, "val_acc": 40.0}
{"epoch": 23, "training_loss": 1779.54150390625, "training_acc": 50.0, "val_loss": 117.5716323852539, "val_acc": 60.0}
{"epoch": 24, "training_loss": 289.0713256835937, "training_acc": 50.0, "val_loss": 280.52008056640625, "val_acc": 60.0}
{"epoch": 25, "training_loss": 694.7241943359375, "training_acc": 40.0, "val_loss": 1197.4539794921875, "val_acc": 40.0}
{"epoch": 26, "training_loss": 881.3838806152344, "training_acc": 50.0, "val_loss": 518.0325317382812, "val_acc": 60.0}
{"epoch": 27, "training_loss": 702.6536499023438, "training_acc": 40.0, "val_loss": 176.39219665527344, "val_acc": 60.0}
{"epoch": 28, "training_loss": 167.34032592773437, "training_acc": 60.0, "val_loss": 59.2978630065918, "val_acc": 60.0}
{"epoch": 29, "training_loss": 211.579443359375, "training_acc": 50.0, "val_loss": 390.97412109375, "val_acc": 40.0}
{"epoch": 30, "training_loss": 332.114697265625, "training_acc": 60.0, "val_loss": 1210.3770751953125, "val_acc": 60.0}
{"epoch": 31, "training_loss": 1325.7833740234375, "training_acc": 50.0, "val_loss": 1750.4989013671875, "val_acc": 40.0}
{"epoch": 32, "training_loss": 1632.0060546875, "training_acc": 50.0, "val_loss": 610.9487915039062, "val_acc": 40.0}
{"epoch": 33, "training_loss": 1110.79833984375, "training_acc": 40.0, "val_loss": 1993.9498291015625, "val_acc": 60.0}
{"epoch": 34, "training_loss": 2225.651025390625, "training_acc": 50.0, "val_loss": 1679.181640625, "val_acc": 40.0}
{"epoch": 35, "training_loss": 1579.403662109375, "training_acc": 50.0, "val_loss": 1811.7703857421875, "val_acc": 40.0}
{"epoch": 36, "training_loss": 1107.138604736328, "training_acc": 60.0, "val_loss": 1339.4893798828125, "val_acc": 60.0}
{"epoch": 37, "training_loss": 1590.47158203125, "training_acc": 50.0, "val_loss": 638.3046875, "val_acc": 40.0}
{"epoch": 38, "training_loss": 688.3706787109375, "training_acc": 50.0, "val_loss": 298.3175964355469, "val_acc": 60.0}
{"epoch": 39, "training_loss": 524.320166015625, "training_acc": 50.0, "val_loss": 1551.8724365234375, "val_acc": 40.0}
{"epoch": 40, "training_loss": 1320.447119140625, "training_acc": 50.0, "val_loss": 1075.91064453125, "val_acc": 40.0}
{"epoch": 41, "training_loss": 1428.5412109375, "training_acc": 30.0, "val_loss": 626.3440551757812, "val_acc": 60.0}
{"epoch": 42, "training_loss": 831.4744140625, "training_acc": 50.0, "val_loss": 1525.9564208984375, "val_acc": 40.0}
{"epoch": 43, "training_loss": 1163.7624786376953, "training_acc": 40.0, "val_loss": 496.4901428222656, "val_acc": 40.0}
{"epoch": 44, "training_loss": 314.03873748779296, "training_acc": 60.0, "val_loss": 158.7400665283203, "val_acc": 60.0}
{"epoch": 45, "training_loss": 526.1823120117188, "training_acc": 40.0, "val_loss": 468.67340087890625, "val_acc": 40.0}
{"epoch": 46, "training_loss": 623.8060302734375, "training_acc": 50.0, "val_loss": 1403.6815185546875, "val_acc": 60.0}
{"epoch": 47, "training_loss": 1757.925, "training_acc": 50.0, "val_loss": 1778.6966552734375, "val_acc": 40.0}
