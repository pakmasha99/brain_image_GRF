"main_modify.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 1 --task ADNI_sex --input_option yAware --learning_rate 1e2 --batch_size 16 --weight_decay 1e-2 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 6402.767984771728, "training_acc": 40.0, "val_loss": 7344.8564453125, "val_acc": 40.0}
{"epoch": 1, "training_loss": 6848.491015625, "training_acc": 50.0, "val_loss": 12887.0419921875, "val_acc": 60.0}
{"epoch": 2, "training_loss": 15711.2890625, "training_acc": 50.0, "val_loss": 6636.22021484375, "val_acc": 60.0}
{"epoch": 3, "training_loss": 6660.895004272461, "training_acc": 50.0, "val_loss": 7688.89453125, "val_acc": 40.0}
{"epoch": 4, "training_loss": 6722.15537109375, "training_acc": 50.0, "val_loss": 11315.712890625, "val_acc": 40.0}
{"epoch": 5, "training_loss": 8908.1626953125, "training_acc": 50.0, "val_loss": 2529.493896484375, "val_acc": 40.0}
{"epoch": 6, "training_loss": 2924.622265625, "training_acc": 40.0, "val_loss": 5075.66650390625, "val_acc": 60.0}
{"epoch": 7, "training_loss": 6398.414794921875, "training_acc": 50.0, "val_loss": 4390.10791015625, "val_acc": 60.0}
{"epoch": 8, "training_loss": 4890.99091796875, "training_acc": 50.0, "val_loss": 1876.0224609375, "val_acc": 40.0}
{"epoch": 9, "training_loss": 2071.97802734375, "training_acc": 50.0, "val_loss": 5645.427734375, "val_acc": 40.0}
{"epoch": 10, "training_loss": 4500.19189453125, "training_acc": 50.0, "val_loss": 1228.3436279296875, "val_acc": 40.0}
{"epoch": 11, "training_loss": 2040.2912109375, "training_acc": 30.0, "val_loss": 2844.11865234375, "val_acc": 60.0}
{"epoch": 12, "training_loss": 3420.307421875, "training_acc": 50.0, "val_loss": 639.5949096679688, "val_acc": 60.0}
{"epoch": 13, "training_loss": 1097.40537109375, "training_acc": 50.0, "val_loss": 4485.84326171875, "val_acc": 40.0}
{"epoch": 14, "training_loss": 3707.15478515625, "training_acc": 50.0, "val_loss": 2109.87890625, "val_acc": 40.0}
{"epoch": 15, "training_loss": 1329.0736450195313, "training_acc": 60.0, "val_loss": 2202.671630859375, "val_acc": 60.0}
{"epoch": 16, "training_loss": 2764.9886962890623, "training_acc": 50.0, "val_loss": 1566.53466796875, "val_acc": 60.0}
{"epoch": 17, "training_loss": 1374.8567878723145, "training_acc": 60.0, "val_loss": 1683.2239990234375, "val_acc": 40.0}
{"epoch": 18, "training_loss": 1405.8408203125, "training_acc": 50.0, "val_loss": 938.8582153320312, "val_acc": 40.0}
{"epoch": 19, "training_loss": 767.0155883789063, "training_acc": 50.0, "val_loss": 764.5494384765625, "val_acc": 60.0}
{"epoch": 20, "training_loss": 719.9272888183593, "training_acc": 50.0, "val_loss": 2405.83154296875, "val_acc": 40.0}
{"epoch": 21, "training_loss": 2226.582568359375, "training_acc": 50.0, "val_loss": 1595.511962890625, "val_acc": 40.0}
{"epoch": 22, "training_loss": 1301.964306640625, "training_acc": 50.0, "val_loss": 1767.729736328125, "val_acc": 60.0}
{"epoch": 23, "training_loss": 2146.3062377929687, "training_acc": 50.0, "val_loss": 129.5552215576172, "val_acc": 60.0}
{"epoch": 24, "training_loss": 825.447705078125, "training_acc": 40.0, "val_loss": 2954.957763671875, "val_acc": 40.0}
{"epoch": 25, "training_loss": 2321.1301147460936, "training_acc": 50.0, "val_loss": 862.9308471679688, "val_acc": 60.0}
{"epoch": 26, "training_loss": 1130.0808959960937, "training_acc": 50.0, "val_loss": 924.8900756835938, "val_acc": 60.0}
{"epoch": 27, "training_loss": 1027.151513671875, "training_acc": 50.0, "val_loss": 1040.6138916015625, "val_acc": 40.0}
{"epoch": 28, "training_loss": 831.7832061767579, "training_acc": 40.0, "val_loss": 596.5167236328125, "val_acc": 40.0}
{"epoch": 29, "training_loss": 506.3139282226563, "training_acc": 40.0, "val_loss": 952.1994018554688, "val_acc": 40.0}
{"epoch": 30, "training_loss": 732.499609375, "training_acc": 50.0, "val_loss": 1063.9910888671875, "val_acc": 60.0}
{"epoch": 31, "training_loss": 1351.3192260742187, "training_acc": 50.0, "val_loss": 680.7023315429688, "val_acc": 60.0}
{"epoch": 32, "training_loss": 892.672900390625, "training_acc": 50.0, "val_loss": 1739.1580810546875, "val_acc": 40.0}
{"epoch": 33, "training_loss": 1172.5168823242188, "training_acc": 50.0, "val_loss": 1668.7977294921875, "val_acc": 60.0}
{"epoch": 34, "training_loss": 2153.914404296875, "training_acc": 50.0, "val_loss": 1634.4176025390625, "val_acc": 60.0}
{"epoch": 35, "training_loss": 1278.9992462158202, "training_acc": 50.0, "val_loss": 4567.962890625, "val_acc": 40.0}
{"epoch": 36, "training_loss": 3819.654296875, "training_acc": 50.0, "val_loss": 5904.234375, "val_acc": 40.0}
{"epoch": 37, "training_loss": 4453.23603515625, "training_acc": 50.0, "val_loss": 1117.0716552734375, "val_acc": 60.0}
{"epoch": 38, "training_loss": 1812.8005859375, "training_acc": 50.0, "val_loss": 2700.408203125, "val_acc": 60.0}
{"epoch": 39, "training_loss": 3162.93466796875, "training_acc": 50.0, "val_loss": 1936.947265625, "val_acc": 40.0}
{"epoch": 40, "training_loss": 1824.54990234375, "training_acc": 50.0, "val_loss": 2143.05078125, "val_acc": 40.0}
{"epoch": 41, "training_loss": 1820.134423828125, "training_acc": 40.0, "val_loss": 855.9366455078125, "val_acc": 60.0}
{"epoch": 42, "training_loss": 857.4388320922851, "training_acc": 50.0, "val_loss": 2477.52587890625, "val_acc": 40.0}
