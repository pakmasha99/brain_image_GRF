"main_modify.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 1 --task ADNI_sex --input_option yAware --learning_rate 1e2 --batch_size 16 --weight_decay 1e-2 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 6015.264541721344, "training_acc": 50.0, "val_loss": 6229.7158203125, "val_acc": 40.0}
{"epoch": 1, "training_loss": 6163.34296875, "training_acc": 50.0, "val_loss": 12629.65234375, "val_acc": 60.0}
{"epoch": 2, "training_loss": 15414.595703125, "training_acc": 50.0, "val_loss": 6453.93896484375, "val_acc": 60.0}
{"epoch": 3, "training_loss": 7268.630016517639, "training_acc": 50.0, "val_loss": 9055.0693359375, "val_acc": 40.0}
{"epoch": 4, "training_loss": 7927.46591796875, "training_acc": 50.0, "val_loss": 14051.5302734375, "val_acc": 40.0}
{"epoch": 5, "training_loss": 10930.216796875, "training_acc": 50.0, "val_loss": 4634.37451171875, "val_acc": 40.0}
{"epoch": 6, "training_loss": 4199.276513671875, "training_acc": 40.0, "val_loss": 5025.626953125, "val_acc": 60.0}
{"epoch": 7, "training_loss": 6426.88046875, "training_acc": 50.0, "val_loss": 5726.70458984375, "val_acc": 60.0}
{"epoch": 8, "training_loss": 6673.357421875, "training_acc": 50.0, "val_loss": 755.6324462890625, "val_acc": 60.0}
{"epoch": 9, "training_loss": 993.751318359375, "training_acc": 60.0, "val_loss": 7329.6064453125, "val_acc": 40.0}
{"epoch": 10, "training_loss": 6235.39755859375, "training_acc": 50.0, "val_loss": 6434.287109375, "val_acc": 40.0}
{"epoch": 11, "training_loss": 4787.3513671875, "training_acc": 50.0, "val_loss": 1081.8509521484375, "val_acc": 60.0}
{"epoch": 12, "training_loss": 1573.398291015625, "training_acc": 50.0, "val_loss": 3683.287109375, "val_acc": 60.0}
{"epoch": 13, "training_loss": 4389.4615234375, "training_acc": 50.0, "val_loss": 1017.10400390625, "val_acc": 60.0}
{"epoch": 14, "training_loss": 1469.67958984375, "training_acc": 50.0, "val_loss": 4961.2734375, "val_acc": 40.0}
{"epoch": 15, "training_loss": 4131.679541015625, "training_acc": 50.0, "val_loss": 3568.02783203125, "val_acc": 40.0}
{"epoch": 16, "training_loss": 2278.7220458984375, "training_acc": 50.0, "val_loss": 2226.106689453125, "val_acc": 60.0}
{"epoch": 17, "training_loss": 3116.7314453125, "training_acc": 50.0, "val_loss": 3477.134033203125, "val_acc": 60.0}
{"epoch": 18, "training_loss": 3829.0203125, "training_acc": 50.0, "val_loss": 812.0995483398438, "val_acc": 40.0}
{"epoch": 19, "training_loss": 677.0248046875, "training_acc": 50.0, "val_loss": 4340.693359375, "val_acc": 40.0}
{"epoch": 20, "training_loss": 3552.461328125, "training_acc": 50.0, "val_loss": 1641.119140625, "val_acc": 40.0}
{"epoch": 21, "training_loss": 1337.81826171875, "training_acc": 50.0, "val_loss": 1970.8133544921875, "val_acc": 60.0}
{"epoch": 22, "training_loss": 2423.98291015625, "training_acc": 50.0, "val_loss": 691.56787109375, "val_acc": 60.0}
{"epoch": 23, "training_loss": 952.863818359375, "training_acc": 50.0, "val_loss": 2530.60986328125, "val_acc": 40.0}
{"epoch": 24, "training_loss": 1983.7681640625, "training_acc": 50.0, "val_loss": 243.0249481201172, "val_acc": 60.0}
{"epoch": 25, "training_loss": 353.9954528808594, "training_acc": 50.0, "val_loss": 525.9747924804688, "val_acc": 60.0}
{"epoch": 26, "training_loss": 642.8278686523438, "training_acc": 50.0, "val_loss": 752.4052124023438, "val_acc": 40.0}
{"epoch": 27, "training_loss": 724.4271728515625, "training_acc": 40.0, "val_loss": 32.11970138549805, "val_acc": 60.0}
{"epoch": 28, "training_loss": 308.34880981445315, "training_acc": 50.0, "val_loss": 1678.147705078125, "val_acc": 40.0}
{"epoch": 29, "training_loss": 1145.1993408203125, "training_acc": 50.0, "val_loss": 1612.9896240234375, "val_acc": 60.0}
{"epoch": 30, "training_loss": 2115.582421875, "training_acc": 50.0, "val_loss": 1161.7369384765625, "val_acc": 60.0}
{"epoch": 31, "training_loss": 1328.492041015625, "training_acc": 50.0, "val_loss": 2071.28125, "val_acc": 40.0}
{"epoch": 32, "training_loss": 1585.304833984375, "training_acc": 50.0, "val_loss": 764.7993774414062, "val_acc": 60.0}
{"epoch": 33, "training_loss": 1019.5476196289062, "training_acc": 50.0, "val_loss": 1049.838134765625, "val_acc": 60.0}
{"epoch": 34, "training_loss": 930.2019882202148, "training_acc": 60.0, "val_loss": 1102.1666259765625, "val_acc": 40.0}
{"epoch": 35, "training_loss": 792.65654296875, "training_acc": 50.0, "val_loss": 1239.486572265625, "val_acc": 60.0}
{"epoch": 36, "training_loss": 1636.14326171875, "training_acc": 50.0, "val_loss": 709.8230590820312, "val_acc": 60.0}
{"epoch": 37, "training_loss": 982.108740234375, "training_acc": 50.0, "val_loss": 2449.222412109375, "val_acc": 40.0}
{"epoch": 38, "training_loss": 2041.7064453125, "training_acc": 50.0, "val_loss": 360.1610412597656, "val_acc": 60.0}
{"epoch": 39, "training_loss": 486.429541015625, "training_acc": 50.0, "val_loss": 1275.796630859375, "val_acc": 40.0}
{"epoch": 40, "training_loss": 1146.75, "training_acc": 50.0, "val_loss": 271.4646911621094, "val_acc": 60.0}
{"epoch": 41, "training_loss": 361.02924194335935, "training_acc": 50.0, "val_loss": 63.4999885559082, "val_acc": 60.0}
{"epoch": 42, "training_loss": 189.205517578125, "training_acc": 60.0, "val_loss": 2076.581787109375, "val_acc": 40.0}
{"epoch": 43, "training_loss": 1728.387109375, "training_acc": 50.0, "val_loss": 869.3038940429688, "val_acc": 60.0}
{"epoch": 44, "training_loss": 1058.55341796875, "training_acc": 50.0, "val_loss": 637.1497192382812, "val_acc": 40.0}
{"epoch": 45, "training_loss": 599.47607421875, "training_acc": 50.0, "val_loss": 733.2849731445312, "val_acc": 60.0}
{"epoch": 46, "training_loss": 916.32060546875, "training_acc": 50.0, "val_loss": 112.1985855102539, "val_acc": 60.0}
