"main_modify.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 4 --task ADNI_sex --input_option yAware --learning_rate 1e2 --batch_size 16 --weight_decay 1e-2 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 6430.137036180497, "training_acc": 50.0, "val_loss": 6870.66748046875, "val_acc": 40.0}
{"epoch": 1, "training_loss": 6641.352734375, "training_acc": 50.0, "val_loss": 13240.728515625, "val_acc": 60.0}
{"epoch": 2, "training_loss": 16225.21640625, "training_acc": 50.0, "val_loss": 6824.24365234375, "val_acc": 60.0}
{"epoch": 3, "training_loss": 6871.598156738281, "training_acc": 50.0, "val_loss": 9803.9140625, "val_acc": 40.0}
{"epoch": 4, "training_loss": 9055.0388671875, "training_acc": 50.0, "val_loss": 15324.6162109375, "val_acc": 40.0}
{"epoch": 5, "training_loss": 12436.4544921875, "training_acc": 50.0, "val_loss": 5350.9365234375, "val_acc": 40.0}
{"epoch": 6, "training_loss": 3278.0867309570312, "training_acc": 60.0, "val_loss": 5084.69091796875, "val_acc": 60.0}
{"epoch": 7, "training_loss": 7065.484375, "training_acc": 50.0, "val_loss": 6383.7197265625, "val_acc": 60.0}
{"epoch": 8, "training_loss": 7695.4390625, "training_acc": 50.0, "val_loss": 914.4415893554688, "val_acc": 60.0}
{"epoch": 9, "training_loss": 1129.1246826171875, "training_acc": 60.0, "val_loss": 7609.6484375, "val_acc": 40.0}
{"epoch": 10, "training_loss": 6500.8419921875, "training_acc": 50.0, "val_loss": 6973.95947265625, "val_acc": 40.0}
{"epoch": 11, "training_loss": 4936.5763671875, "training_acc": 50.0, "val_loss": 1137.381103515625, "val_acc": 60.0}
{"epoch": 12, "training_loss": 1999.73857421875, "training_acc": 50.0, "val_loss": 4253.75, "val_acc": 60.0}
{"epoch": 13, "training_loss": 5320.125, "training_acc": 50.0, "val_loss": 2076.742919921875, "val_acc": 60.0}
{"epoch": 14, "training_loss": 2434.6169616699217, "training_acc": 40.0, "val_loss": 2026.957275390625, "val_acc": 40.0}
{"epoch": 15, "training_loss": 1685.7017578125, "training_acc": 50.0, "val_loss": 1454.53857421875, "val_acc": 40.0}
{"epoch": 16, "training_loss": 1010.2395690917969, "training_acc": 50.0, "val_loss": 475.9377136230469, "val_acc": 60.0}
{"epoch": 17, "training_loss": 570.0266479492187, "training_acc": 40.0, "val_loss": 440.6235046386719, "val_acc": 60.0}
{"epoch": 18, "training_loss": 502.92433166503906, "training_acc": 50.0, "val_loss": 973.81787109375, "val_acc": 40.0}
{"epoch": 19, "training_loss": 763.8578979492188, "training_acc": 50.0, "val_loss": 515.1683349609375, "val_acc": 60.0}
{"epoch": 20, "training_loss": 701.3564208984375, "training_acc": 50.0, "val_loss": 613.3112182617188, "val_acc": 40.0}
{"epoch": 21, "training_loss": 552.0920166015625, "training_acc": 50.0, "val_loss": 120.58507537841797, "val_acc": 60.0}
{"epoch": 22, "training_loss": 136.49309387207032, "training_acc": 50.0, "val_loss": 1626.5472412109375, "val_acc": 40.0}
{"epoch": 23, "training_loss": 1377.940869140625, "training_acc": 50.0, "val_loss": 362.62225341796875, "val_acc": 40.0}
{"epoch": 24, "training_loss": 181.0250732421875, "training_acc": 70.0, "val_loss": 2282.915283203125, "val_acc": 60.0}
{"epoch": 25, "training_loss": 2802.785693359375, "training_acc": 50.0, "val_loss": 737.2869262695312, "val_acc": 60.0}
{"epoch": 26, "training_loss": 1048.54599609375, "training_acc": 50.0, "val_loss": 2977.577392578125, "val_acc": 40.0}
{"epoch": 27, "training_loss": 2339.4594970703124, "training_acc": 50.0, "val_loss": 183.6414031982422, "val_acc": 60.0}
{"epoch": 28, "training_loss": 294.5274719238281, "training_acc": 50.0, "val_loss": 620.0487670898438, "val_acc": 60.0}
{"epoch": 29, "training_loss": 580.2441223144531, "training_acc": 60.0, "val_loss": 1004.2219848632812, "val_acc": 40.0}
{"epoch": 30, "training_loss": 676.0485687255859, "training_acc": 50.0, "val_loss": 1375.5838623046875, "val_acc": 60.0}
{"epoch": 31, "training_loss": 1724.6711669921874, "training_acc": 50.0, "val_loss": 674.0704956054688, "val_acc": 60.0}
{"epoch": 32, "training_loss": 1163.056884765625, "training_acc": 40.0, "val_loss": 1726.7098388671875, "val_acc": 40.0}
{"epoch": 33, "training_loss": 1177.2344940185546, "training_acc": 50.0, "val_loss": 1709.0516357421875, "val_acc": 60.0}
{"epoch": 34, "training_loss": 2171.4302001953124, "training_acc": 50.0, "val_loss": 1339.4068603515625, "val_acc": 60.0}
{"epoch": 35, "training_loss": 1443.040869140625, "training_acc": 50.0, "val_loss": 1582.1253662109375, "val_acc": 40.0}
{"epoch": 36, "training_loss": 1182.2282958984374, "training_acc": 50.0, "val_loss": 972.9851684570312, "val_acc": 60.0}
{"epoch": 37, "training_loss": 1232.6383056640625, "training_acc": 50.0, "val_loss": 500.18756103515625, "val_acc": 60.0}
{"epoch": 38, "training_loss": 994.63173828125, "training_acc": 40.0, "val_loss": 1545.5712890625, "val_acc": 40.0}
{"epoch": 39, "training_loss": 1082.4524536132812, "training_acc": 50.0, "val_loss": 396.6495056152344, "val_acc": 60.0}
{"epoch": 40, "training_loss": 502.75865478515624, "training_acc": 50.0, "val_loss": 263.90771484375, "val_acc": 40.0}
