"main_modify.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 4 --task ADNI_sex --input_option yAware --learning_rate 1e2 --batch_size 16 --weight_decay 1e-2 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 6418.350146913528, "training_acc": 50.0, "val_loss": 6765.0859375, "val_acc": 40.0}
{"epoch": 1, "training_loss": 6591.5765625, "training_acc": 50.0, "val_loss": 13316.4052734375, "val_acc": 60.0}
{"epoch": 2, "training_loss": 16302.9306640625, "training_acc": 50.0, "val_loss": 6831.8046875, "val_acc": 60.0}
{"epoch": 3, "training_loss": 7697.296963500977, "training_acc": 50.0, "val_loss": 9468.748046875, "val_acc": 40.0}
{"epoch": 4, "training_loss": 9167.186328125, "training_acc": 50.0, "val_loss": 14227.796875, "val_acc": 40.0}
{"epoch": 5, "training_loss": 11512.176953125, "training_acc": 50.0, "val_loss": 3962.587158203125, "val_acc": 40.0}
{"epoch": 6, "training_loss": 3173.112890625, "training_acc": 50.0, "val_loss": 5358.67919921875, "val_acc": 60.0}
{"epoch": 7, "training_loss": 6841.355859375, "training_acc": 50.0, "val_loss": 6016.20654296875, "val_acc": 60.0}
{"epoch": 8, "training_loss": 7246.914697265625, "training_acc": 50.0, "val_loss": 801.5736694335938, "val_acc": 60.0}
{"epoch": 9, "training_loss": 1943.275390625, "training_acc": 40.0, "val_loss": 6783.84912109375, "val_acc": 40.0}
{"epoch": 10, "training_loss": 5686.57421875, "training_acc": 50.0, "val_loss": 4956.29443359375, "val_acc": 40.0}
{"epoch": 11, "training_loss": 3244.516552734375, "training_acc": 50.0, "val_loss": 2326.147705078125, "val_acc": 60.0}
{"epoch": 12, "training_loss": 3649.89052734375, "training_acc": 50.0, "val_loss": 4338.7255859375, "val_acc": 60.0}
{"epoch": 13, "training_loss": 5244.895166015625, "training_acc": 50.0, "val_loss": 704.5596313476562, "val_acc": 60.0}
{"epoch": 14, "training_loss": 1215.478564453125, "training_acc": 50.0, "val_loss": 5259.61572265625, "val_acc": 40.0}
{"epoch": 15, "training_loss": 4377.509814453125, "training_acc": 50.0, "val_loss": 3626.557861328125, "val_acc": 40.0}
{"epoch": 16, "training_loss": 2516.4796813964845, "training_acc": 50.0, "val_loss": 2224.349853515625, "val_acc": 60.0}
{"epoch": 17, "training_loss": 3493.4892578125, "training_acc": 50.0, "val_loss": 2898.109130859375, "val_acc": 60.0}
{"epoch": 18, "training_loss": 3375.3672729492187, "training_acc": 50.0, "val_loss": 2118.462890625, "val_acc": 40.0}
{"epoch": 19, "training_loss": 2053.2646484375, "training_acc": 50.0, "val_loss": 3619.41796875, "val_acc": 40.0}
{"epoch": 20, "training_loss": 2693.8989013671876, "training_acc": 50.0, "val_loss": 973.9963989257812, "val_acc": 60.0}
{"epoch": 21, "training_loss": 1334.629150390625, "training_acc": 50.0, "val_loss": 1984.2489013671875, "val_acc": 60.0}
{"epoch": 22, "training_loss": 2343.9824829101562, "training_acc": 50.0, "val_loss": 1008.3057861328125, "val_acc": 40.0}
{"epoch": 23, "training_loss": 1078.189990234375, "training_acc": 50.0, "val_loss": 771.0198364257812, "val_acc": 40.0}
{"epoch": 24, "training_loss": 774.381640625, "training_acc": 50.0, "val_loss": 1497.3863525390625, "val_acc": 60.0}
{"epoch": 25, "training_loss": 1711.49638671875, "training_acc": 50.0, "val_loss": 980.8150634765625, "val_acc": 40.0}
{"epoch": 26, "training_loss": 1030.640625, "training_acc": 50.0, "val_loss": 528.43896484375, "val_acc": 40.0}
{"epoch": 27, "training_loss": 670.26787109375, "training_acc": 50.0, "val_loss": 1705.8974609375, "val_acc": 60.0}
{"epoch": 28, "training_loss": 1890.2234375, "training_acc": 50.0, "val_loss": 1368.685546875, "val_acc": 40.0}
{"epoch": 29, "training_loss": 1480.563037109375, "training_acc": 50.0, "val_loss": 1611.6214599609375, "val_acc": 40.0}
{"epoch": 30, "training_loss": 1229.1163330078125, "training_acc": 50.0, "val_loss": 1221.4871826171875, "val_acc": 60.0}
{"epoch": 31, "training_loss": 1399.6052001953126, "training_acc": 50.0, "val_loss": 1060.40283203125, "val_acc": 40.0}
{"epoch": 32, "training_loss": 1042.59990234375, "training_acc": 50.0, "val_loss": 92.83843994140625, "val_acc": 40.0}
{"epoch": 33, "training_loss": 754.6430541992188, "training_acc": 40.0, "val_loss": 1901.3746337890625, "val_acc": 60.0}
{"epoch": 34, "training_loss": 1977.02080078125, "training_acc": 50.0, "val_loss": 2302.359375, "val_acc": 40.0}
{"epoch": 35, "training_loss": 2165.01259765625, "training_acc": 50.0, "val_loss": 3003.86474609375, "val_acc": 40.0}
{"epoch": 36, "training_loss": 2071.3896240234376, "training_acc": 50.0, "val_loss": 2189.96728515625, "val_acc": 60.0}
{"epoch": 37, "training_loss": 3110.68154296875, "training_acc": 50.0, "val_loss": 2098.865478515625, "val_acc": 60.0}
{"epoch": 38, "training_loss": 2149.3774749755858, "training_acc": 50.0, "val_loss": 2068.029296875, "val_acc": 40.0}
{"epoch": 39, "training_loss": 1725.7265625, "training_acc": 50.0, "val_loss": 861.6646728515625, "val_acc": 40.0}
{"epoch": 40, "training_loss": 1011.4309326171875, "training_acc": 40.0, "val_loss": 875.5724487304688, "val_acc": 60.0}
{"epoch": 41, "training_loss": 1123.4291259765625, "training_acc": 40.0, "val_loss": 206.40982055664062, "val_acc": 40.0}
{"epoch": 42, "training_loss": 553.1226928710937, "training_acc": 40.0, "val_loss": 609.9576416015625, "val_acc": 60.0}
{"epoch": 43, "training_loss": 620.67041015625, "training_acc": 60.0, "val_loss": 1907.244384765625, "val_acc": 40.0}
{"epoch": 44, "training_loss": 1430.1312866210938, "training_acc": 50.0, "val_loss": 975.0860595703125, "val_acc": 60.0}
{"epoch": 45, "training_loss": 1305.65224609375, "training_acc": 50.0, "val_loss": 429.92486572265625, "val_acc": 60.0}
{"epoch": 46, "training_loss": 532.2619018554688, "training_acc": 60.0, "val_loss": 3008.433837890625, "val_acc": 40.0}
{"epoch": 47, "training_loss": 2291.93095703125, "training_acc": 50.0, "val_loss": 755.2305908203125, "val_acc": 60.0}
{"epoch": 48, "training_loss": 1325.259765625, "training_acc": 50.0, "val_loss": 919.1875, "val_acc": 60.0}
{"epoch": 49, "training_loss": 1159.288427734375, "training_acc": 50.0, "val_loss": 2312.231201171875, "val_acc": 40.0}
{"epoch": 50, "training_loss": 1737.3369384765624, "training_acc": 50.0, "val_loss": 982.7462768554688, "val_acc": 60.0}
{"epoch": 51, "training_loss": 1343.8662109375, "training_acc": 50.0, "val_loss": 585.9552612304688, "val_acc": 60.0}
