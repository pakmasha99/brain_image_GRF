"main_modify.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 4 --task ADNI_sex --input_option yAware --learning_rate 1e2 --batch_size 16 --weight_decay 1e-2 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 2140.872346496582, "training_acc": 55.0, "val_loss": 7233.02685546875, "val_acc": 40.0}
{"epoch": 1, "training_loss": 6249.095703125, "training_acc": 55.0, "val_loss": 12411.2685546875, "val_acc": 60.0}
{"epoch": 2, "training_loss": 16284.375390625, "training_acc": 45.0, "val_loss": 4222.1708984375, "val_acc": 60.0}
{"epoch": 3, "training_loss": 5503.18642578125, "training_acc": 45.0, "val_loss": 11349.9794921875, "val_acc": 40.0}
{"epoch": 4, "training_loss": 9321.322265625, "training_acc": 55.0, "val_loss": 10559.6162109375, "val_acc": 40.0}
{"epoch": 5, "training_loss": 6918.1435546875, "training_acc": 55.0, "val_loss": 1741.1268310546875, "val_acc": 60.0}
{"epoch": 6, "training_loss": 3622.88046875, "training_acc": 45.0, "val_loss": 5819.85498046875, "val_acc": 60.0}
{"epoch": 7, "training_loss": 7747.5275390625, "training_acc": 45.0, "val_loss": 2106.53125, "val_acc": 60.0}
{"epoch": 8, "training_loss": 2720.446484375, "training_acc": 45.0, "val_loss": 5350.41796875, "val_acc": 40.0}
{"epoch": 9, "training_loss": 4310.6119140625, "training_acc": 55.0, "val_loss": 4906.11279296875, "val_acc": 40.0}
{"epoch": 10, "training_loss": 3392.46064453125, "training_acc": 55.0, "val_loss": 1583.9530029296875, "val_acc": 60.0}
{"epoch": 11, "training_loss": 2694.4322265625, "training_acc": 45.0, "val_loss": 2597.050048828125, "val_acc": 60.0}
{"epoch": 12, "training_loss": 3187.224951171875, "training_acc": 45.0, "val_loss": 1901.1180419921875, "val_acc": 40.0}
{"epoch": 13, "training_loss": 1568.6673095703125, "training_acc": 55.0, "val_loss": 3987.846435546875, "val_acc": 40.0}
{"epoch": 14, "training_loss": 2863.1904541015624, "training_acc": 55.0, "val_loss": 98.22502899169922, "val_acc": 40.0}
{"epoch": 15, "training_loss": 559.7076599121094, "training_acc": 55.0, "val_loss": 2762.82666015625, "val_acc": 60.0}
{"epoch": 16, "training_loss": 3649.59326171875, "training_acc": 45.0, "val_loss": 347.4345397949219, "val_acc": 60.0}
{"epoch": 17, "training_loss": 602.968603515625, "training_acc": 55.0, "val_loss": 5139.32373046875, "val_acc": 40.0}
{"epoch": 18, "training_loss": 3826.77177734375, "training_acc": 55.0, "val_loss": 2717.09765625, "val_acc": 40.0}
{"epoch": 19, "training_loss": 1728.461767578125, "training_acc": 55.0, "val_loss": 1882.6500244140625, "val_acc": 60.0}
{"epoch": 20, "training_loss": 2577.17314453125, "training_acc": 45.0, "val_loss": 835.2877197265625, "val_acc": 60.0}
{"epoch": 21, "training_loss": 1195.0113525390625, "training_acc": 45.0, "val_loss": 2538.11328125, "val_acc": 40.0}
{"epoch": 22, "training_loss": 1836.5069091796875, "training_acc": 55.0, "val_loss": 90.8423843383789, "val_acc": 40.0}
{"epoch": 23, "training_loss": 240.11253967285157, "training_acc": 65.0, "val_loss": 2270.239013671875, "val_acc": 60.0}
{"epoch": 24, "training_loss": 3026.501989746094, "training_acc": 45.0, "val_loss": 84.1470718383789, "val_acc": 40.0}
{"epoch": 25, "training_loss": 220.998583984375, "training_acc": 55.0, "val_loss": 435.04888916015625, "val_acc": 40.0}
{"epoch": 26, "training_loss": 853.876025390625, "training_acc": 35.0, "val_loss": 391.3255615234375, "val_acc": 60.0}
{"epoch": 27, "training_loss": 746.95283203125, "training_acc": 45.0, "val_loss": 2360.815673828125, "val_acc": 40.0}
{"epoch": 28, "training_loss": 1517.910107421875, "training_acc": 55.0, "val_loss": 1143.502685546875, "val_acc": 60.0}
{"epoch": 29, "training_loss": 1646.758544921875, "training_acc": 45.0, "val_loss": 1364.8514404296875, "val_acc": 60.0}
{"epoch": 30, "training_loss": 1821.8067260742187, "training_acc": 35.0, "val_loss": 697.181640625, "val_acc": 40.0}
{"epoch": 31, "training_loss": 364.331282043457, "training_acc": 65.0, "val_loss": 209.26980590820312, "val_acc": 60.0}
{"epoch": 32, "training_loss": 419.7749755859375, "training_acc": 45.0, "val_loss": 822.3549194335938, "val_acc": 40.0}
{"epoch": 33, "training_loss": 342.539306640625, "training_acc": 75.0, "val_loss": 994.1925659179688, "val_acc": 60.0}
{"epoch": 34, "training_loss": 1186.7435668945313, "training_acc": 45.0, "val_loss": 2098.2890625, "val_acc": 40.0}
{"epoch": 35, "training_loss": 1721.97099609375, "training_acc": 55.0, "val_loss": 1719.067626953125, "val_acc": 40.0}
{"epoch": 36, "training_loss": 930.7955383300781, "training_acc": 65.0, "val_loss": 1537.596923828125, "val_acc": 60.0}
{"epoch": 37, "training_loss": 1964.5505859375, "training_acc": 45.0, "val_loss": 1324.0572509765625, "val_acc": 40.0}
{"epoch": 38, "training_loss": 1191.109619140625, "training_acc": 55.0, "val_loss": 1607.9349365234375, "val_acc": 40.0}
{"epoch": 39, "training_loss": 1074.95712890625, "training_acc": 55.0, "val_loss": 959.3839721679688, "val_acc": 60.0}
{"epoch": 40, "training_loss": 1096.593962097168, "training_acc": 45.0, "val_loss": 2549.131591796875, "val_acc": 40.0}
{"epoch": 41, "training_loss": 1994.667822265625, "training_acc": 55.0, "val_loss": 1328.4395751953125, "val_acc": 40.0}
{"epoch": 42, "training_loss": 1376.396484375, "training_acc": 45.0, "val_loss": 1547.24951171875, "val_acc": 60.0}
{"epoch": 43, "training_loss": 1634.9213134765625, "training_acc": 45.0, "val_loss": 3526.81494140625, "val_acc": 40.0}
