"main_modify.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 3 --task ADNI_sex --input_option yAware --learning_rate 1e2 --batch_size 16 --weight_decay 1e-2 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 4196.207613039017, "training_acc": 50.0, "val_loss": 4377.65771484375, "val_acc": 60.0}
{"epoch": 1, "training_loss": 4876.28154296875, "training_acc": 60.0, "val_loss": 20428.97265625, "val_acc": 40.0}
{"epoch": 2, "training_loss": 16608.521484375, "training_acc": 50.0, "val_loss": 9785.7958984375, "val_acc": 40.0}
{"epoch": 3, "training_loss": 6640.270922851562, "training_acc": 50.0, "val_loss": 5590.720703125, "val_acc": 60.0}
{"epoch": 4, "training_loss": 7258.3888671875, "training_acc": 50.0, "val_loss": 7647.8828125, "val_acc": 60.0}
{"epoch": 5, "training_loss": 9238.48916015625, "training_acc": 50.0, "val_loss": 1456.3697509765625, "val_acc": 60.0}
{"epoch": 6, "training_loss": 1615.933544921875, "training_acc": 60.0, "val_loss": 8355.634765625, "val_acc": 40.0}
{"epoch": 7, "training_loss": 7264.935546875, "training_acc": 50.0, "val_loss": 7184.45703125, "val_acc": 40.0}
{"epoch": 8, "training_loss": 5251.5599609375, "training_acc": 50.0, "val_loss": 1890.96875, "val_acc": 60.0}
{"epoch": 9, "training_loss": 2633.856103515625, "training_acc": 50.0, "val_loss": 4942.49365234375, "val_acc": 60.0}
{"epoch": 10, "training_loss": 6167.97578125, "training_acc": 50.0, "val_loss": 2255.47607421875, "val_acc": 60.0}
{"epoch": 11, "training_loss": 3072.5261474609374, "training_acc": 30.0, "val_loss": 2297.921875, "val_acc": 40.0}
{"epoch": 12, "training_loss": 1895.4866333007812, "training_acc": 50.0, "val_loss": 960.34228515625, "val_acc": 40.0}
{"epoch": 13, "training_loss": 1077.10634765625, "training_acc": 40.0, "val_loss": 1136.0927734375, "val_acc": 60.0}
{"epoch": 14, "training_loss": 1312.003469848633, "training_acc": 50.0, "val_loss": 1341.9393310546875, "val_acc": 40.0}
{"epoch": 15, "training_loss": 1217.88818359375, "training_acc": 50.0, "val_loss": 127.7606201171875, "val_acc": 40.0}
{"epoch": 16, "training_loss": 493.6728271484375, "training_acc": 50.0, "val_loss": 2128.06884765625, "val_acc": 60.0}
{"epoch": 17, "training_loss": 2555.6633544921874, "training_acc": 50.0, "val_loss": 129.0082244873047, "val_acc": 40.0}
{"epoch": 18, "training_loss": 327.7779235839844, "training_acc": 50.0, "val_loss": 62.02132797241211, "val_acc": 60.0}
{"epoch": 19, "training_loss": 71.35597229003906, "training_acc": 50.0, "val_loss": 647.6621704101562, "val_acc": 60.0}
{"epoch": 20, "training_loss": 734.22802734375, "training_acc": 50.0, "val_loss": 1143.732421875, "val_acc": 40.0}
{"epoch": 21, "training_loss": 969.4082275390625, "training_acc": 50.0, "val_loss": 87.71955871582031, "val_acc": 60.0}
{"epoch": 22, "training_loss": 151.53714599609376, "training_acc": 50.0, "val_loss": 1417.5501708984375, "val_acc": 40.0}
{"epoch": 23, "training_loss": 1224.7984375, "training_acc": 50.0, "val_loss": 273.8011779785156, "val_acc": 60.0}
{"epoch": 24, "training_loss": 425.97755126953126, "training_acc": 50.0, "val_loss": 55.336952209472656, "val_acc": 40.0}
{"epoch": 25, "training_loss": 88.92033386230469, "training_acc": 50.0, "val_loss": 678.5676879882812, "val_acc": 40.0}
{"epoch": 26, "training_loss": 481.3451721191406, "training_acc": 50.0, "val_loss": 1069.6116943359375, "val_acc": 60.0}
{"epoch": 27, "training_loss": 1362.36845703125, "training_acc": 50.0, "val_loss": 509.5599670410156, "val_acc": 40.0}
{"epoch": 28, "training_loss": 615.9010986328125, "training_acc": 50.0, "val_loss": 166.91946411132812, "val_acc": 60.0}
{"epoch": 29, "training_loss": 197.43521575927736, "training_acc": 50.0, "val_loss": 668.7493286132812, "val_acc": 40.0}
{"epoch": 30, "training_loss": 457.6142105102539, "training_acc": 50.0, "val_loss": 579.9559326171875, "val_acc": 40.0}
{"epoch": 31, "training_loss": 304.4589309692383, "training_acc": 50.0, "val_loss": 2068.2119140625, "val_acc": 60.0}
{"epoch": 32, "training_loss": 2808.08759765625, "training_acc": 50.0, "val_loss": 1235.359375, "val_acc": 60.0}
{"epoch": 33, "training_loss": 1222.1960083007812, "training_acc": 60.0, "val_loss": 3851.966796875, "val_acc": 40.0}
{"epoch": 34, "training_loss": 3208.115625, "training_acc": 50.0, "val_loss": 1708.4622802734375, "val_acc": 40.0}
{"epoch": 35, "training_loss": 855.5033203125, "training_acc": 70.0, "val_loss": 2173.854736328125, "val_acc": 60.0}
{"epoch": 36, "training_loss": 2683.2578125, "training_acc": 50.0, "val_loss": 763.98193359375, "val_acc": 60.0}
{"epoch": 37, "training_loss": 1429.63876953125, "training_acc": 40.0, "val_loss": 2708.552734375, "val_acc": 40.0}
{"epoch": 38, "training_loss": 1977.8755615234375, "training_acc": 50.0, "val_loss": 1429.886474609375, "val_acc": 60.0}
{"epoch": 39, "training_loss": 2057.893359375, "training_acc": 50.0, "val_loss": 870.7050170898438, "val_acc": 60.0}
{"epoch": 40, "training_loss": 1562.95283203125, "training_acc": 40.0, "val_loss": 2922.698974609375, "val_acc": 40.0}
{"epoch": 41, "training_loss": 2288.1883911132813, "training_acc": 50.0, "val_loss": 986.9762573242188, "val_acc": 60.0}
{"epoch": 42, "training_loss": 1419.643017578125, "training_acc": 50.0, "val_loss": 142.47630310058594, "val_acc": 60.0}
{"epoch": 43, "training_loss": 364.34093017578124, "training_acc": 60.0, "val_loss": 4229.515625, "val_acc": 40.0}
