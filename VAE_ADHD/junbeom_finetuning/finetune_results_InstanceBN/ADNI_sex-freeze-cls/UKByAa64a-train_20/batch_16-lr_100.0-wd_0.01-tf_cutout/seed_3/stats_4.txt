"main_modify.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 3 --task ADNI_sex --input_option yAware --learning_rate 1e2 --batch_size 16 --weight_decay 1e-2 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 1765.6245420455932, "training_acc": 55.0, "val_loss": 2781.031005859375, "val_acc": 40.0}
{"epoch": 1, "training_loss": 3494.765625, "training_acc": 45.0, "val_loss": 4768.3642578125, "val_acc": 60.0}
{"epoch": 2, "training_loss": 6042.8498046875, "training_acc": 45.0, "val_loss": 477.9057312011719, "val_acc": 60.0}
{"epoch": 3, "training_loss": 437.410546875, "training_acc": 65.0, "val_loss": 6593.5078125, "val_acc": 40.0}
{"epoch": 4, "training_loss": 4908.2166015625, "training_acc": 55.0, "val_loss": 3658.77587890625, "val_acc": 40.0}
{"epoch": 5, "training_loss": 2683.727388000488, "training_acc": 35.0, "val_loss": 513.5518188476562, "val_acc": 60.0}
{"epoch": 6, "training_loss": 679.9562316894531, "training_acc": 35.0, "val_loss": 483.2731628417969, "val_acc": 60.0}
{"epoch": 7, "training_loss": 626.6932983398438, "training_acc": 45.0, "val_loss": 1354.08984375, "val_acc": 40.0}
{"epoch": 8, "training_loss": 1065.1183349609375, "training_acc": 55.0, "val_loss": 331.2647399902344, "val_acc": 40.0}
{"epoch": 9, "training_loss": 675.659765625, "training_acc": 45.0, "val_loss": 1040.2677001953125, "val_acc": 60.0}
{"epoch": 10, "training_loss": 1039.0240341186523, "training_acc": 50.0, "val_loss": 1493.5845947265625, "val_acc": 40.0}
{"epoch": 11, "training_loss": 1096.31669921875, "training_acc": 55.0, "val_loss": 390.0072021484375, "val_acc": 40.0}
{"epoch": 12, "training_loss": 486.2012939453125, "training_acc": 55.0, "val_loss": 1429.9954833984375, "val_acc": 60.0}
{"epoch": 13, "training_loss": 1745.900927734375, "training_acc": 45.0, "val_loss": 1631.673095703125, "val_acc": 40.0}
{"epoch": 14, "training_loss": 1391.210595703125, "training_acc": 55.0, "val_loss": 1539.7694091796875, "val_acc": 40.0}
{"epoch": 15, "training_loss": 1022.9088500976562, "training_acc": 55.0, "val_loss": 888.7033081054688, "val_acc": 60.0}
{"epoch": 16, "training_loss": 1021.132080078125, "training_acc": 45.0, "val_loss": 2035.2222900390625, "val_acc": 40.0}
{"epoch": 17, "training_loss": 1767.03515625, "training_acc": 55.0, "val_loss": 1577.5511474609375, "val_acc": 40.0}
{"epoch": 18, "training_loss": 1089.3852783203124, "training_acc": 55.0, "val_loss": 1412.200927734375, "val_acc": 60.0}
{"epoch": 19, "training_loss": 1845.997216796875, "training_acc": 45.0, "val_loss": 709.5050659179688, "val_acc": 40.0}
{"epoch": 20, "training_loss": 686.163623046875, "training_acc": 55.0, "val_loss": 242.8672637939453, "val_acc": 60.0}
{"epoch": 21, "training_loss": 348.5747863769531, "training_acc": 45.0, "val_loss": 898.9275512695312, "val_acc": 40.0}
{"epoch": 22, "training_loss": 659.8933837890625, "training_acc": 55.0, "val_loss": 508.2318420410156, "val_acc": 60.0}
{"epoch": 23, "training_loss": 661.1348510742188, "training_acc": 45.0, "val_loss": 1007.30908203125, "val_acc": 40.0}
{"epoch": 24, "training_loss": 756.823828125, "training_acc": 55.0, "val_loss": 239.2130889892578, "val_acc": 60.0}
{"epoch": 25, "training_loss": 287.18133544921875, "training_acc": 45.0, "val_loss": 1375.6170654296875, "val_acc": 40.0}
{"epoch": 26, "training_loss": 1022.057373046875, "training_acc": 55.0, "val_loss": 288.50567626953125, "val_acc": 60.0}
{"epoch": 27, "training_loss": 396.7435302734375, "training_acc": 45.0, "val_loss": 1037.4132080078125, "val_acc": 40.0}
{"epoch": 28, "training_loss": 764.1479125976563, "training_acc": 55.0, "val_loss": 497.3553771972656, "val_acc": 60.0}
{"epoch": 29, "training_loss": 675.0966796875, "training_acc": 45.0, "val_loss": 1490.6151123046875, "val_acc": 40.0}
{"epoch": 30, "training_loss": 1377.5013671875, "training_acc": 55.0, "val_loss": 191.61834716796875, "val_acc": 60.0}
{"epoch": 31, "training_loss": 381.1287353515625, "training_acc": 45.0, "val_loss": 38.45219802856445, "val_acc": 60.0}
{"epoch": 32, "training_loss": 436.67186279296874, "training_acc": 45.0, "val_loss": 2556.768798828125, "val_acc": 40.0}
{"epoch": 33, "training_loss": 1548.252783203125, "training_acc": 55.0, "val_loss": 1763.578125, "val_acc": 60.0}
{"epoch": 34, "training_loss": 2502.608154296875, "training_acc": 45.0, "val_loss": 1860.19921875, "val_acc": 60.0}
{"epoch": 35, "training_loss": 2118.8754699707033, "training_acc": 45.0, "val_loss": 1445.6644287109375, "val_acc": 40.0}
{"epoch": 36, "training_loss": 1029.0712585449219, "training_acc": 55.0, "val_loss": 469.712890625, "val_acc": 60.0}
{"epoch": 37, "training_loss": 572.4064270019531, "training_acc": 45.0, "val_loss": 1577.371337890625, "val_acc": 40.0}
{"epoch": 38, "training_loss": 1189.306494140625, "training_acc": 55.0, "val_loss": 159.38790893554688, "val_acc": 60.0}
{"epoch": 39, "training_loss": 205.21839447021483, "training_acc": 45.0, "val_loss": 857.8199462890625, "val_acc": 40.0}
{"epoch": 40, "training_loss": 520.8322387695313, "training_acc": 55.0, "val_loss": 1574.2086181640625, "val_acc": 60.0}
{"epoch": 41, "training_loss": 2158.2189453125, "training_acc": 45.0, "val_loss": 658.4404296875, "val_acc": 60.0}
{"epoch": 42, "training_loss": 1096.33447265625, "training_acc": 45.0, "val_loss": 2941.0, "val_acc": 40.0}
{"epoch": 43, "training_loss": 2209.680859375, "training_acc": 55.0, "val_loss": 484.9335021972656, "val_acc": 60.0}
{"epoch": 44, "training_loss": 643.2921752929688, "training_acc": 45.0, "val_loss": 1164.6820068359375, "val_acc": 40.0}
{"epoch": 45, "training_loss": 858.4927673339844, "training_acc": 55.0, "val_loss": 178.61126708984375, "val_acc": 60.0}
{"epoch": 46, "training_loss": 267.23793334960936, "training_acc": 45.0, "val_loss": 408.4555969238281, "val_acc": 60.0}
{"epoch": 47, "training_loss": 420.2769317626953, "training_acc": 55.0, "val_loss": 49.23893356323242, "val_acc": 40.0}
{"epoch": 48, "training_loss": 124.04100341796875, "training_acc": 65.0, "val_loss": 823.646484375, "val_acc": 60.0}
{"epoch": 49, "training_loss": 1059.635009765625, "training_acc": 45.0, "val_loss": 890.5115356445312, "val_acc": 40.0}
{"epoch": 50, "training_loss": 628.0641357421875, "training_acc": 55.0, "val_loss": 204.4033660888672, "val_acc": 60.0}
