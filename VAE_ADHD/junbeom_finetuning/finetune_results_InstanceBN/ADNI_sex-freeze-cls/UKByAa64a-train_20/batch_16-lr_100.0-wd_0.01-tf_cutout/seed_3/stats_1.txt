"main_modify.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 3 --task ADNI_sex --input_option yAware --learning_rate 1e2 --batch_size 16 --weight_decay 1e-2 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 4275.271302032471, "training_acc": 50.0, "val_loss": 4782.48291015625, "val_acc": 60.0}
{"epoch": 1, "training_loss": 8468.773828125, "training_acc": 40.0, "val_loss": 18318.59375, "val_acc": 40.0}
{"epoch": 2, "training_loss": 15034.61767578125, "training_acc": 50.0, "val_loss": 7935.6728515625, "val_acc": 40.0}
{"epoch": 3, "training_loss": 5560.463525390625, "training_acc": 50.0, "val_loss": 5490.27587890625, "val_acc": 60.0}
{"epoch": 4, "training_loss": 7505.544140625, "training_acc": 50.0, "val_loss": 6022.82666015625, "val_acc": 60.0}
{"epoch": 5, "training_loss": 7101.442724609375, "training_acc": 50.0, "val_loss": 1547.169189453125, "val_acc": 40.0}
{"epoch": 6, "training_loss": 2253.03623046875, "training_acc": 50.0, "val_loss": 6027.18505859375, "val_acc": 40.0}
{"epoch": 7, "training_loss": 5030.001171875, "training_acc": 50.0, "val_loss": 1431.8570556640625, "val_acc": 40.0}
{"epoch": 8, "training_loss": 1686.766064453125, "training_acc": 40.0, "val_loss": 2531.009765625, "val_acc": 60.0}
{"epoch": 9, "training_loss": 3046.60966796875, "training_acc": 50.0, "val_loss": 600.4223022460938, "val_acc": 60.0}
{"epoch": 10, "training_loss": 1311.0365234375, "training_acc": 40.0, "val_loss": 3510.85400390625, "val_acc": 40.0}
{"epoch": 11, "training_loss": 2845.6427978515626, "training_acc": 50.0, "val_loss": 451.272705078125, "val_acc": 40.0}
{"epoch": 12, "training_loss": 728.802490234375, "training_acc": 50.0, "val_loss": 2446.283935546875, "val_acc": 60.0}
{"epoch": 13, "training_loss": 2896.93955078125, "training_acc": 50.0, "val_loss": 190.06072998046875, "val_acc": 60.0}
{"epoch": 14, "training_loss": 716.5458984375, "training_acc": 50.0, "val_loss": 4465.15869140625, "val_acc": 40.0}
{"epoch": 15, "training_loss": 3645.2087158203126, "training_acc": 50.0, "val_loss": 1184.435791015625, "val_acc": 40.0}
{"epoch": 16, "training_loss": 869.7620971679687, "training_acc": 60.0, "val_loss": 2724.401123046875, "val_acc": 60.0}
{"epoch": 17, "training_loss": 3349.05859375, "training_acc": 50.0, "val_loss": 1024.4349365234375, "val_acc": 60.0}
{"epoch": 18, "training_loss": 1359.8688232421875, "training_acc": 50.0, "val_loss": 3614.411865234375, "val_acc": 40.0}
{"epoch": 19, "training_loss": 2957.8650146484374, "training_acc": 50.0, "val_loss": 1022.9775390625, "val_acc": 40.0}
{"epoch": 20, "training_loss": 1038.9078125, "training_acc": 50.0, "val_loss": 2196.786376953125, "val_acc": 60.0}
{"epoch": 21, "training_loss": 2540.14345703125, "training_acc": 50.0, "val_loss": 580.9393920898438, "val_acc": 40.0}
{"epoch": 22, "training_loss": 883.926171875, "training_acc": 50.0, "val_loss": 1260.8453369140625, "val_acc": 40.0}
{"epoch": 23, "training_loss": 815.5107788085937, "training_acc": 60.0, "val_loss": 1402.290283203125, "val_acc": 60.0}
{"epoch": 24, "training_loss": 1676.4302001953124, "training_acc": 50.0, "val_loss": 471.8955078125, "val_acc": 40.0}
{"epoch": 25, "training_loss": 395.9104797363281, "training_acc": 50.0, "val_loss": 186.10049438476562, "val_acc": 60.0}
{"epoch": 26, "training_loss": 182.68898315429686, "training_acc": 60.0, "val_loss": 5.226891994476318, "val_acc": 60.0}
{"epoch": 27, "training_loss": 187.03486022949218, "training_acc": 50.0, "val_loss": 489.8183288574219, "val_acc": 40.0}
{"epoch": 28, "training_loss": 244.51806640625, "training_acc": 70.0, "val_loss": 1597.5128173828125, "val_acc": 60.0}
{"epoch": 29, "training_loss": 1848.24365234375, "training_acc": 50.0, "val_loss": 977.9246215820312, "val_acc": 40.0}
{"epoch": 30, "training_loss": 927.4489013671875, "training_acc": 50.0, "val_loss": 458.4274597167969, "val_acc": 40.0}
{"epoch": 31, "training_loss": 656.167041015625, "training_acc": 50.0, "val_loss": 1667.9554443359375, "val_acc": 60.0}
{"epoch": 32, "training_loss": 1703.97333984375, "training_acc": 50.0, "val_loss": 2673.77978515625, "val_acc": 40.0}
{"epoch": 33, "training_loss": 2584.79462890625, "training_acc": 50.0, "val_loss": 2217.298095703125, "val_acc": 40.0}
{"epoch": 34, "training_loss": 2064.943359375, "training_acc": 40.0, "val_loss": 1707.3994140625, "val_acc": 60.0}
{"epoch": 35, "training_loss": 1841.85986328125, "training_acc": 50.0, "val_loss": 2287.202392578125, "val_acc": 40.0}
{"epoch": 36, "training_loss": 2177.27314453125, "training_acc": 50.0, "val_loss": 2931.113525390625, "val_acc": 40.0}
{"epoch": 37, "training_loss": 1974.181706237793, "training_acc": 50.0, "val_loss": 937.2744140625, "val_acc": 60.0}
{"epoch": 38, "training_loss": 1106.0422424316407, "training_acc": 50.0, "val_loss": 933.9396362304688, "val_acc": 40.0}
{"epoch": 39, "training_loss": 739.4275512695312, "training_acc": 50.0, "val_loss": 764.9999389648438, "val_acc": 60.0}
{"epoch": 40, "training_loss": 939.0695434570313, "training_acc": 50.0, "val_loss": 727.7511596679688, "val_acc": 40.0}
{"epoch": 41, "training_loss": 647.4279296875, "training_acc": 50.0, "val_loss": 915.0082397460938, "val_acc": 60.0}
{"epoch": 42, "training_loss": 1139.60419921875, "training_acc": 50.0, "val_loss": 514.2259521484375, "val_acc": 60.0}
{"epoch": 43, "training_loss": 950.499951171875, "training_acc": 40.0, "val_loss": 932.82421875, "val_acc": 40.0}
{"epoch": 44, "training_loss": 840.027880859375, "training_acc": 50.0, "val_loss": 984.6549072265625, "val_acc": 60.0}
{"epoch": 45, "training_loss": 1022.0297485351563, "training_acc": 50.0, "val_loss": 244.03916931152344, "val_acc": 40.0}
