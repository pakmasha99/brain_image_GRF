"main_modify.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 2 --task ADNI_sex --input_option yAware --learning_rate 1e2 --batch_size 16 --weight_decay 1e-2 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 6024.2411551475525, "training_acc": 45.0, "val_loss": 4161.48388671875, "val_acc": 60.0}
{"epoch": 1, "training_loss": 6730.00234375, "training_acc": 45.0, "val_loss": 19323.15625, "val_acc": 40.0}
{"epoch": 2, "training_loss": 14147.523828125, "training_acc": 55.0, "val_loss": 10312.5068359375, "val_acc": 40.0}
{"epoch": 3, "training_loss": 6141.708422851562, "training_acc": 55.0, "val_loss": 5899.86474609375, "val_acc": 60.0}
{"epoch": 4, "training_loss": 8532.31748046875, "training_acc": 45.0, "val_loss": 9728.40625, "val_acc": 60.0}
{"epoch": 5, "training_loss": 12860.871875, "training_acc": 45.0, "val_loss": 3655.81103515625, "val_acc": 60.0}
{"epoch": 6, "training_loss": 5064.68134765625, "training_acc": 35.0, "val_loss": 6749.05322265625, "val_acc": 40.0}
{"epoch": 7, "training_loss": 5051.903125, "training_acc": 55.0, "val_loss": 8934.005859375, "val_acc": 40.0}
{"epoch": 8, "training_loss": 6187.4453125, "training_acc": 55.0, "val_loss": 2511.929931640625, "val_acc": 40.0}
{"epoch": 9, "training_loss": 1914.35595703125, "training_acc": 55.0, "val_loss": 3945.747802734375, "val_acc": 60.0}
{"epoch": 10, "training_loss": 5562.78017578125, "training_acc": 45.0, "val_loss": 3525.239501953125, "val_acc": 60.0}
{"epoch": 11, "training_loss": 4318.320092773438, "training_acc": 45.0, "val_loss": 2047.596923828125, "val_acc": 40.0}
{"epoch": 12, "training_loss": 1730.4947265625, "training_acc": 55.0, "val_loss": 5295.51123046875, "val_acc": 40.0}
{"epoch": 13, "training_loss": 3702.7974609375, "training_acc": 55.0, "val_loss": 1099.560791015625, "val_acc": 40.0}
{"epoch": 14, "training_loss": 1136.96103515625, "training_acc": 55.0, "val_loss": 3384.092529296875, "val_acc": 60.0}
{"epoch": 15, "training_loss": 4655.9521484375, "training_acc": 45.0, "val_loss": 1724.8472900390625, "val_acc": 60.0}
{"epoch": 16, "training_loss": 1820.9040405273438, "training_acc": 55.0, "val_loss": 3675.009765625, "val_acc": 40.0}
{"epoch": 17, "training_loss": 2806.31640625, "training_acc": 55.0, "val_loss": 3517.154052734375, "val_acc": 40.0}
{"epoch": 18, "training_loss": 2256.3666015625, "training_acc": 55.0, "val_loss": 1391.3414306640625, "val_acc": 60.0}
{"epoch": 19, "training_loss": 2160.386865234375, "training_acc": 45.0, "val_loss": 2051.906005859375, "val_acc": 60.0}
{"epoch": 20, "training_loss": 2469.251818847656, "training_acc": 45.0, "val_loss": 2332.698974609375, "val_acc": 40.0}
{"epoch": 21, "training_loss": 2160.8509765625, "training_acc": 55.0, "val_loss": 3098.0791015625, "val_acc": 40.0}
{"epoch": 22, "training_loss": 2109.34543762207, "training_acc": 55.0, "val_loss": 1556.9390869140625, "val_acc": 60.0}
{"epoch": 23, "training_loss": 2417.36162109375, "training_acc": 45.0, "val_loss": 1389.728759765625, "val_acc": 60.0}
{"epoch": 24, "training_loss": 1447.0060668945312, "training_acc": 55.0, "val_loss": 2454.16259765625, "val_acc": 40.0}
{"epoch": 25, "training_loss": 1862.1638671875, "training_acc": 55.0, "val_loss": 1072.303955078125, "val_acc": 40.0}
{"epoch": 26, "training_loss": 1131.571630859375, "training_acc": 45.0, "val_loss": 1392.0740966796875, "val_acc": 60.0}
{"epoch": 27, "training_loss": 1620.897021484375, "training_acc": 45.0, "val_loss": 2088.64453125, "val_acc": 40.0}
{"epoch": 28, "training_loss": 1771.944287109375, "training_acc": 55.0, "val_loss": 2598.158203125, "val_acc": 40.0}
{"epoch": 29, "training_loss": 1570.9678344726562, "training_acc": 55.0, "val_loss": 1946.0771484375, "val_acc": 60.0}
{"epoch": 30, "training_loss": 2845.851220703125, "training_acc": 45.0, "val_loss": 1865.79296875, "val_acc": 60.0}
{"epoch": 31, "training_loss": 2126.813201904297, "training_acc": 45.0, "val_loss": 1606.49755859375, "val_acc": 40.0}
{"epoch": 32, "training_loss": 1182.76591796875, "training_acc": 55.0, "val_loss": 257.8153076171875, "val_acc": 40.0}
{"epoch": 33, "training_loss": 676.790625, "training_acc": 45.0, "val_loss": 1200.893798828125, "val_acc": 60.0}
{"epoch": 34, "training_loss": 1203.3065598726273, "training_acc": 55.0, "val_loss": 1041.38671875, "val_acc": 40.0}
{"epoch": 35, "training_loss": 715.3522827148438, "training_acc": 55.0, "val_loss": 708.5582885742188, "val_acc": 60.0}
{"epoch": 36, "training_loss": 962.5610107421875, "training_acc": 45.0, "val_loss": 562.5025024414062, "val_acc": 40.0}
{"epoch": 37, "training_loss": 422.8976623535156, "training_acc": 55.0, "val_loss": 110.9518051147461, "val_acc": 60.0}
{"epoch": 38, "training_loss": 95.64356079101563, "training_acc": 65.0, "val_loss": 667.6083374023438, "val_acc": 40.0}
{"epoch": 39, "training_loss": 556.8113525390625, "training_acc": 45.0, "val_loss": 582.7072143554688, "val_acc": 40.0}
{"epoch": 40, "training_loss": 461.9555999755859, "training_acc": 35.0, "val_loss": 1926.783447265625, "val_acc": 40.0}
{"epoch": 41, "training_loss": 1476.2826171875, "training_acc": 55.0, "val_loss": 512.64453125, "val_acc": 40.0}
{"epoch": 42, "training_loss": 666.29267578125, "training_acc": 55.0, "val_loss": 1886.2640380859375, "val_acc": 60.0}
{"epoch": 43, "training_loss": 2599.9873046875, "training_acc": 45.0, "val_loss": 1068.031005859375, "val_acc": 40.0}
{"epoch": 44, "training_loss": 860.1790283203125, "training_acc": 55.0, "val_loss": 79.3216552734375, "val_acc": 40.0}
{"epoch": 45, "training_loss": 676.0865173339844, "training_acc": 45.0, "val_loss": 1457.2706298828125, "val_acc": 60.0}
{"epoch": 46, "training_loss": 1469.299378967285, "training_acc": 45.0, "val_loss": 3924.126708984375, "val_acc": 40.0}
{"epoch": 47, "training_loss": 3172.2384765625, "training_acc": 55.0, "val_loss": 3948.857177734375, "val_acc": 40.0}
{"epoch": 48, "training_loss": 2655.6892517089846, "training_acc": 55.0, "val_loss": 2417.259033203125, "val_acc": 60.0}
{"epoch": 49, "training_loss": 3670.3529296875, "training_acc": 45.0, "val_loss": 1939.8817138671875, "val_acc": 60.0}
{"epoch": 50, "training_loss": 2385.6928466796876, "training_acc": 45.0, "val_loss": 3239.695068359375, "val_acc": 40.0}
{"epoch": 51, "training_loss": 2430.898291015625, "training_acc": 55.0, "val_loss": 429.8443298339844, "val_acc": 40.0}
{"epoch": 52, "training_loss": 1185.0337890625, "training_acc": 45.0, "val_loss": 2835.969482421875, "val_acc": 60.0}
{"epoch": 53, "training_loss": 3572.064111328125, "training_acc": 45.0, "val_loss": 1458.3306884765625, "val_acc": 40.0}
{"epoch": 54, "training_loss": 1392.6482421875, "training_acc": 55.0, "val_loss": 2703.183349609375, "val_acc": 40.0}
{"epoch": 55, "training_loss": 1624.0662902832032, "training_acc": 55.0, "val_loss": 2191.606201171875, "val_acc": 60.0}
{"epoch": 56, "training_loss": 3278.5869140625, "training_acc": 45.0, "val_loss": 1404.20654296875, "val_acc": 60.0}
{"epoch": 57, "training_loss": 1915.1903564453125, "training_acc": 45.0, "val_loss": 3784.954833984375, "val_acc": 40.0}
{"epoch": 58, "training_loss": 2773.9562744140626, "training_acc": 55.0, "val_loss": 944.6161499023438, "val_acc": 40.0}
{"epoch": 59, "training_loss": 952.193896484375, "training_acc": 55.0, "val_loss": 2293.364013671875, "val_acc": 60.0}
{"epoch": 60, "training_loss": 2762.9638671875, "training_acc": 45.0, "val_loss": 2147.543701171875, "val_acc": 40.0}
{"epoch": 61, "training_loss": 1979.07392578125, "training_acc": 55.0, "val_loss": 3833.399169921875, "val_acc": 40.0}
{"epoch": 62, "training_loss": 2423.9861328125, "training_acc": 55.0, "val_loss": 1965.4755859375, "val_acc": 60.0}
{"epoch": 63, "training_loss": 3095.78583984375, "training_acc": 45.0, "val_loss": 1749.9652099609375, "val_acc": 60.0}
