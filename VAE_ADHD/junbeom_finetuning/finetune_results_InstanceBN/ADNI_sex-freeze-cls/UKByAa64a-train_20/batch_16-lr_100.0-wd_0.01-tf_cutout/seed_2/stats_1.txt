"main_modify.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 2 --task ADNI_sex --input_option yAware --learning_rate 1e2 --batch_size 16 --weight_decay 1e-2 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 2660.3720255851745, "training_acc": 45.0, "val_loss": 4107.12744140625, "val_acc": 40.0}
{"epoch": 1, "training_loss": 2056.04609375, "training_acc": 70.0, "val_loss": 9904.1015625, "val_acc": 60.0}
{"epoch": 2, "training_loss": 12277.963671875, "training_acc": 50.0, "val_loss": 5226.78662109375, "val_acc": 60.0}
{"epoch": 3, "training_loss": 5920.990487670899, "training_acc": 50.0, "val_loss": 7021.73779296875, "val_acc": 40.0}
{"epoch": 4, "training_loss": 5844.47734375, "training_acc": 50.0, "val_loss": 10850.98046875, "val_acc": 40.0}
{"epoch": 5, "training_loss": 8646.64951171875, "training_acc": 50.0, "val_loss": 3919.728515625, "val_acc": 40.0}
{"epoch": 6, "training_loss": 2914.5943115234377, "training_acc": 50.0, "val_loss": 3574.861083984375, "val_acc": 60.0}
{"epoch": 7, "training_loss": 4547.478125, "training_acc": 50.0, "val_loss": 3697.797607421875, "val_acc": 60.0}
{"epoch": 8, "training_loss": 4441.666479492187, "training_acc": 50.0, "val_loss": 157.29417419433594, "val_acc": 60.0}
{"epoch": 9, "training_loss": 1031.737353515625, "training_acc": 40.0, "val_loss": 4167.92041015625, "val_acc": 40.0}
{"epoch": 10, "training_loss": 3201.55146484375, "training_acc": 50.0, "val_loss": 76.76004791259766, "val_acc": 40.0}
{"epoch": 11, "training_loss": 615.5166870117188, "training_acc": 50.0, "val_loss": 2909.209716796875, "val_acc": 60.0}
{"epoch": 12, "training_loss": 3440.9826171875, "training_acc": 50.0, "val_loss": 341.5511169433594, "val_acc": 60.0}
{"epoch": 13, "training_loss": 552.0217041015625, "training_acc": 60.0, "val_loss": 4529.47021484375, "val_acc": 40.0}
{"epoch": 14, "training_loss": 3642.42734375, "training_acc": 50.0, "val_loss": 1378.2767333984375, "val_acc": 40.0}
{"epoch": 15, "training_loss": 678.9203125, "training_acc": 70.0, "val_loss": 3072.1181640625, "val_acc": 60.0}
{"epoch": 16, "training_loss": 3880.2201171875, "training_acc": 50.0, "val_loss": 2034.7711181640625, "val_acc": 60.0}
{"epoch": 17, "training_loss": 1779.4148056030274, "training_acc": 60.0, "val_loss": 2615.220458984375, "val_acc": 40.0}
{"epoch": 18, "training_loss": 2212.586181640625, "training_acc": 50.0, "val_loss": 2256.744873046875, "val_acc": 40.0}
{"epoch": 19, "training_loss": 1991.277392578125, "training_acc": 30.0, "val_loss": 250.67100524902344, "val_acc": 60.0}
{"epoch": 20, "training_loss": 287.7377685546875, "training_acc": 60.0, "val_loss": 835.3422241210938, "val_acc": 40.0}
{"epoch": 21, "training_loss": 740.9644653320313, "training_acc": 40.0, "val_loss": 180.96743774414062, "val_acc": 40.0}
{"epoch": 22, "training_loss": 125.35203247070312, "training_acc": 60.0, "val_loss": 31.660696029663086, "val_acc": 60.0}
{"epoch": 23, "training_loss": 249.70968170166014, "training_acc": 50.0, "val_loss": 1162.4476318359375, "val_acc": 40.0}
{"epoch": 24, "training_loss": 846.606201171875, "training_acc": 50.0, "val_loss": 398.0101318359375, "val_acc": 60.0}
{"epoch": 25, "training_loss": 498.077099609375, "training_acc": 50.0, "val_loss": 341.1271667480469, "val_acc": 40.0}
{"epoch": 26, "training_loss": 286.992578125, "training_acc": 60.0, "val_loss": 975.9757690429688, "val_acc": 60.0}
{"epoch": 27, "training_loss": 1020.3518676757812, "training_acc": 50.0, "val_loss": 2130.663818359375, "val_acc": 40.0}
{"epoch": 28, "training_loss": 2007.73447265625, "training_acc": 50.0, "val_loss": 336.7826843261719, "val_acc": 40.0}
{"epoch": 29, "training_loss": 1107.176708984375, "training_acc": 40.0, "val_loss": 2735.924560546875, "val_acc": 60.0}
{"epoch": 30, "training_loss": 3267.7802490234376, "training_acc": 50.0, "val_loss": 432.3241271972656, "val_acc": 40.0}
{"epoch": 31, "training_loss": 442.7100341796875, "training_acc": 50.0, "val_loss": 1335.3460693359375, "val_acc": 40.0}
{"epoch": 32, "training_loss": 945.6187561035156, "training_acc": 50.0, "val_loss": 332.86553955078125, "val_acc": 60.0}
{"epoch": 33, "training_loss": 465.17503662109374, "training_acc": 50.0, "val_loss": 447.1434631347656, "val_acc": 40.0}
{"epoch": 34, "training_loss": 695.3028076171875, "training_acc": 40.0, "val_loss": 550.0145874023438, "val_acc": 60.0}
{"epoch": 35, "training_loss": 573.0853942871094, "training_acc": 60.0, "val_loss": 1905.501220703125, "val_acc": 40.0}
{"epoch": 36, "training_loss": 1404.4580810546875, "training_acc": 50.0, "val_loss": 1123.0296630859375, "val_acc": 60.0}
{"epoch": 37, "training_loss": 1429.5854614257812, "training_acc": 50.0, "val_loss": 768.8751220703125, "val_acc": 60.0}
{"epoch": 38, "training_loss": 765.9966552734375, "training_acc": 60.0, "val_loss": 2201.658935546875, "val_acc": 40.0}
{"epoch": 39, "training_loss": 1735.8315734863281, "training_acc": 50.0, "val_loss": 600.3605346679688, "val_acc": 60.0}
{"epoch": 40, "training_loss": 780.99736328125, "training_acc": 50.0, "val_loss": 431.1351623535156, "val_acc": 40.0}
{"epoch": 41, "training_loss": 366.89923095703125, "training_acc": 50.0, "val_loss": 1137.171142578125, "val_acc": 60.0}
