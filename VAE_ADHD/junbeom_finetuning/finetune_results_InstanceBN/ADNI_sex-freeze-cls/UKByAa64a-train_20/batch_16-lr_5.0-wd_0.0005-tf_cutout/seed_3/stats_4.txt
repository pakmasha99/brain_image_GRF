"main_modify.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 3 --task ADNI_sex --input_option yAware --learning_rate 5e0 --batch_size 16 --weight_decay 5e-4 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 320.63923583030703, "training_acc": 45.0, "val_loss": 276.8457946777344, "val_acc": 60.0}
{"epoch": 1, "training_loss": 413.129638671875, "training_acc": 45.0, "val_loss": 1001.0842895507812, "val_acc": 40.0}
{"epoch": 2, "training_loss": 759.177490234375, "training_acc": 55.0, "val_loss": 802.0888671875, "val_acc": 40.0}
{"epoch": 3, "training_loss": 566.2354125976562, "training_acc": 55.0, "val_loss": 80.6810302734375, "val_acc": 60.0}
{"epoch": 4, "training_loss": 137.84684143066406, "training_acc": 45.0, "val_loss": 155.66075134277344, "val_acc": 60.0}
{"epoch": 5, "training_loss": 154.36071494817733, "training_acc": 55.0, "val_loss": 300.2295837402344, "val_acc": 40.0}
{"epoch": 6, "training_loss": 241.27852783203124, "training_acc": 55.0, "val_loss": 320.8847351074219, "val_acc": 40.0}
{"epoch": 7, "training_loss": 219.5082000732422, "training_acc": 55.0, "val_loss": 145.44277954101562, "val_acc": 60.0}
{"epoch": 8, "training_loss": 222.43056640625, "training_acc": 45.0, "val_loss": 115.7494888305664, "val_acc": 60.0}
{"epoch": 9, "training_loss": 99.41754760742188, "training_acc": 65.0, "val_loss": 323.4153747558594, "val_acc": 40.0}
{"epoch": 10, "training_loss": 264.3730102539063, "training_acc": 55.0, "val_loss": 287.1624450683594, "val_acc": 40.0}
{"epoch": 11, "training_loss": 213.01860961280835, "training_acc": 55.0, "val_loss": 163.53184509277344, "val_acc": 60.0}
{"epoch": 12, "training_loss": 225.08110961914062, "training_acc": 45.0, "val_loss": 176.27964782714844, "val_acc": 60.0}
{"epoch": 13, "training_loss": 196.5383560180664, "training_acc": 45.0, "val_loss": 249.99668884277344, "val_acc": 40.0}
{"epoch": 14, "training_loss": 199.5423126220703, "training_acc": 55.0, "val_loss": 517.7971801757812, "val_acc": 40.0}
{"epoch": 15, "training_loss": 380.6385772705078, "training_acc": 55.0, "val_loss": 343.690185546875, "val_acc": 40.0}
{"epoch": 16, "training_loss": 234.21933975219727, "training_acc": 55.0, "val_loss": 125.69417572021484, "val_acc": 60.0}
{"epoch": 17, "training_loss": 185.18673706054688, "training_acc": 45.0, "val_loss": 168.99717712402344, "val_acc": 60.0}
{"epoch": 18, "training_loss": 196.4898422241211, "training_acc": 45.0, "val_loss": 235.86643981933594, "val_acc": 40.0}
{"epoch": 19, "training_loss": 198.99222412109376, "training_acc": 55.0, "val_loss": 394.71142578125, "val_acc": 40.0}
{"epoch": 20, "training_loss": 273.9687866210937, "training_acc": 55.0, "val_loss": 43.60349655151367, "val_acc": 40.0}
{"epoch": 21, "training_loss": 68.18184356689453, "training_acc": 55.0, "val_loss": 299.2244567871094, "val_acc": 60.0}
{"epoch": 22, "training_loss": 408.20716552734376, "training_acc": 45.0, "val_loss": 183.3357696533203, "val_acc": 60.0}
{"epoch": 23, "training_loss": 234.0808563232422, "training_acc": 35.0, "val_loss": 151.42706298828125, "val_acc": 40.0}
{"epoch": 24, "training_loss": 105.36644134521484, "training_acc": 55.0, "val_loss": 12.901564598083496, "val_acc": 60.0}
{"epoch": 25, "training_loss": 12.598003053665161, "training_acc": 45.0, "val_loss": 26.974802017211914, "val_acc": 60.0}
{"epoch": 26, "training_loss": 42.685205078125, "training_acc": 35.0, "val_loss": 5.499416828155518, "val_acc": 60.0}
{"epoch": 27, "training_loss": 15.778444290161133, "training_acc": 75.0, "val_loss": 31.094812393188477, "val_acc": 60.0}
{"epoch": 28, "training_loss": 50.08548126220703, "training_acc": 45.0, "val_loss": 174.12490844726562, "val_acc": 40.0}
{"epoch": 29, "training_loss": 112.25288238525391, "training_acc": 55.0, "val_loss": 64.71466827392578, "val_acc": 60.0}
{"epoch": 30, "training_loss": 88.7964080810547, "training_acc": 45.0, "val_loss": 23.012243270874023, "val_acc": 60.0}
{"epoch": 31, "training_loss": 49.71420745849609, "training_acc": 45.0, "val_loss": 270.3356628417969, "val_acc": 40.0}
{"epoch": 32, "training_loss": 190.4498718261719, "training_acc": 55.0, "val_loss": 65.89530181884766, "val_acc": 40.0}
{"epoch": 33, "training_loss": 66.84782104492187, "training_acc": 55.0, "val_loss": 197.5956573486328, "val_acc": 60.0}
{"epoch": 34, "training_loss": 257.0491088867187, "training_acc": 45.0, "val_loss": 51.12871170043945, "val_acc": 60.0}
{"epoch": 35, "training_loss": 61.08983459472656, "training_acc": 55.0, "val_loss": 391.3089294433594, "val_acc": 40.0}
{"epoch": 36, "training_loss": 317.54490966796874, "training_acc": 55.0, "val_loss": 309.8967590332031, "val_acc": 40.0}
{"epoch": 37, "training_loss": 181.40586166381837, "training_acc": 55.0, "val_loss": 212.744384765625, "val_acc": 60.0}
{"epoch": 38, "training_loss": 315.49738159179685, "training_acc": 45.0, "val_loss": 365.202880859375, "val_acc": 60.0}
{"epoch": 39, "training_loss": 484.34894104003905, "training_acc": 45.0, "val_loss": 170.08335876464844, "val_acc": 60.0}
{"epoch": 40, "training_loss": 215.31973114013672, "training_acc": 35.0, "val_loss": 144.04031372070312, "val_acc": 40.0}
{"epoch": 41, "training_loss": 96.15469970703126, "training_acc": 55.0, "val_loss": 20.353458404541016, "val_acc": 60.0}
{"epoch": 42, "training_loss": 23.50222396850586, "training_acc": 45.0, "val_loss": 131.4597625732422, "val_acc": 40.0}
{"epoch": 43, "training_loss": 100.2568115234375, "training_acc": 55.0, "val_loss": 100.87097930908203, "val_acc": 40.0}
{"epoch": 44, "training_loss": 69.09149780273438, "training_acc": 55.0, "val_loss": 77.3122329711914, "val_acc": 60.0}
{"epoch": 45, "training_loss": 86.63833770751953, "training_acc": 45.0, "val_loss": 47.65163040161133, "val_acc": 40.0}
