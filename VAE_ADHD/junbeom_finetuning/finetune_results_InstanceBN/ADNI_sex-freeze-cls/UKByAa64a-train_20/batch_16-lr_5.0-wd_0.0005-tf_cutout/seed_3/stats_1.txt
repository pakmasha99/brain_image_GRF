"main_modify.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 3 --task ADNI_sex --input_option yAware --learning_rate 5e0 --batch_size 16 --weight_decay 5e-4 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 214.51253805160522, "training_acc": 50.0, "val_loss": 326.634521484375, "val_acc": 60.0}
{"epoch": 1, "training_loss": 412.65634765625, "training_acc": 50.0, "val_loss": 773.1019897460938, "val_acc": 40.0}
{"epoch": 2, "training_loss": 619.1186157226563, "training_acc": 50.0, "val_loss": 187.1721649169922, "val_acc": 40.0}
{"epoch": 3, "training_loss": 248.80333251953124, "training_acc": 40.0, "val_loss": 385.7855529785156, "val_acc": 60.0}
{"epoch": 4, "training_loss": 467.36162109375, "training_acc": 50.0, "val_loss": 157.2328643798828, "val_acc": 60.0}
{"epoch": 5, "training_loss": 184.86040649414062, "training_acc": 50.0, "val_loss": 339.8822326660156, "val_acc": 40.0}
{"epoch": 6, "training_loss": 286.1689208984375, "training_acc": 50.0, "val_loss": 113.6492919921875, "val_acc": 40.0}
{"epoch": 7, "training_loss": 116.94824829101563, "training_acc": 50.0, "val_loss": 266.5061950683594, "val_acc": 60.0}
{"epoch": 8, "training_loss": 337.18056640625, "training_acc": 50.0, "val_loss": 143.8853759765625, "val_acc": 60.0}
{"epoch": 9, "training_loss": 161.28402862548828, "training_acc": 50.0, "val_loss": 232.91665649414062, "val_acc": 40.0}
{"epoch": 10, "training_loss": 199.24610595703126, "training_acc": 50.0, "val_loss": 51.4384880065918, "val_acc": 40.0}
{"epoch": 11, "training_loss": 105.50369262695312, "training_acc": 40.0, "val_loss": 227.31494140625, "val_acc": 60.0}
{"epoch": 12, "training_loss": 276.3612854003906, "training_acc": 50.0, "val_loss": 82.10914611816406, "val_acc": 60.0}
{"epoch": 13, "training_loss": 84.4523910522461, "training_acc": 60.0, "val_loss": 300.400634765625, "val_acc": 40.0}
{"epoch": 14, "training_loss": 265.2988037109375, "training_acc": 50.0, "val_loss": 201.4973602294922, "val_acc": 40.0}
{"epoch": 15, "training_loss": 122.19765548706054, "training_acc": 60.0, "val_loss": 120.5606918334961, "val_acc": 60.0}
{"epoch": 16, "training_loss": 165.92994995117186, "training_acc": 50.0, "val_loss": 16.46315574645996, "val_acc": 60.0}
{"epoch": 17, "training_loss": 35.15819244384765, "training_acc": 60.0, "val_loss": 449.6603698730469, "val_acc": 40.0}
{"epoch": 18, "training_loss": 387.34853515625, "training_acc": 50.0, "val_loss": 437.2915954589844, "val_acc": 40.0}
{"epoch": 19, "training_loss": 324.56298828125, "training_acc": 50.0, "val_loss": 34.152427673339844, "val_acc": 60.0}
{"epoch": 20, "training_loss": 91.4651123046875, "training_acc": 50.0, "val_loss": 158.7340545654297, "val_acc": 60.0}
{"epoch": 21, "training_loss": 177.10359802246094, "training_acc": 50.0, "val_loss": 107.157958984375, "val_acc": 40.0}
{"epoch": 22, "training_loss": 107.80811462402343, "training_acc": 50.0, "val_loss": 157.74949645996094, "val_acc": 40.0}
{"epoch": 23, "training_loss": 108.27855725288391, "training_acc": 50.0, "val_loss": 148.5521697998047, "val_acc": 60.0}
{"epoch": 24, "training_loss": 213.38055419921875, "training_acc": 50.0, "val_loss": 168.8487548828125, "val_acc": 60.0}
{"epoch": 25, "training_loss": 194.47148666381835, "training_acc": 50.0, "val_loss": 184.06346130371094, "val_acc": 40.0}
{"epoch": 26, "training_loss": 173.385107421875, "training_acc": 50.0, "val_loss": 257.54718017578125, "val_acc": 40.0}
{"epoch": 27, "training_loss": 193.95374145507813, "training_acc": 50.0, "val_loss": 81.68936157226562, "val_acc": 60.0}
{"epoch": 28, "training_loss": 132.98092041015624, "training_acc": 50.0, "val_loss": 114.5438232421875, "val_acc": 60.0}
{"epoch": 29, "training_loss": 113.76182953119277, "training_acc": 55.0, "val_loss": 138.10130310058594, "val_acc": 40.0}
{"epoch": 30, "training_loss": 118.54182586669921, "training_acc": 50.0, "val_loss": 64.88814544677734, "val_acc": 40.0}
{"epoch": 31, "training_loss": 48.94703369140625, "training_acc": 60.0, "val_loss": 114.54670715332031, "val_acc": 60.0}
{"epoch": 32, "training_loss": 140.25976181030273, "training_acc": 50.0, "val_loss": 2.673241138458252, "val_acc": 80.0}
{"epoch": 33, "training_loss": 41.272224044799806, "training_acc": 60.0, "val_loss": 94.5930404663086, "val_acc": 40.0}
{"epoch": 34, "training_loss": 90.67703552246094, "training_acc": 40.0, "val_loss": 24.64086151123047, "val_acc": 60.0}
{"epoch": 35, "training_loss": 32.429978942871095, "training_acc": 60.0, "val_loss": 127.09600830078125, "val_acc": 40.0}
{"epoch": 36, "training_loss": 97.79392700195312, "training_acc": 50.0, "val_loss": 75.32589721679688, "val_acc": 60.0}
{"epoch": 37, "training_loss": 94.626123046875, "training_acc": 50.0, "val_loss": 95.2666015625, "val_acc": 60.0}
{"epoch": 38, "training_loss": 100.70673904418945, "training_acc": 50.0, "val_loss": 169.8561553955078, "val_acc": 40.0}
{"epoch": 39, "training_loss": 159.01104125976562, "training_acc": 50.0, "val_loss": 193.41270446777344, "val_acc": 40.0}
{"epoch": 40, "training_loss": 137.01275177001952, "training_acc": 50.0, "val_loss": 156.97415161132812, "val_acc": 60.0}
{"epoch": 41, "training_loss": 232.6904296875, "training_acc": 50.0, "val_loss": 213.1129913330078, "val_acc": 60.0}
{"epoch": 42, "training_loss": 250.20524978637695, "training_acc": 50.0, "val_loss": 83.92606353759766, "val_acc": 40.0}
{"epoch": 43, "training_loss": 78.80600967407227, "training_acc": 50.0, "val_loss": 158.5152130126953, "val_acc": 40.0}
{"epoch": 44, "training_loss": 137.61772465109823, "training_acc": 50.0, "val_loss": 72.15074157714844, "val_acc": 60.0}
{"epoch": 45, "training_loss": 91.3564453125, "training_acc": 50.0, "val_loss": 2.1686952114105225, "val_acc": 80.0}
{"epoch": 46, "training_loss": 12.161261749267577, "training_acc": 70.0, "val_loss": 13.0880708694458, "val_acc": 60.0}
{"epoch": 47, "training_loss": 21.715647506713868, "training_acc": 40.0, "val_loss": 54.32561111450195, "val_acc": 60.0}
{"epoch": 48, "training_loss": 67.56364135742187, "training_acc": 50.0, "val_loss": 38.19184494018555, "val_acc": 40.0}
{"epoch": 49, "training_loss": 35.70778045654297, "training_acc": 50.0, "val_loss": 47.70365524291992, "val_acc": 60.0}
{"epoch": 50, "training_loss": 59.392991638183595, "training_acc": 50.0, "val_loss": 12.863700866699219, "val_acc": 40.0}
{"epoch": 51, "training_loss": 10.269265937805176, "training_acc": 60.0, "val_loss": 83.7535629272461, "val_acc": 60.0}
{"epoch": 52, "training_loss": 105.81351242065429, "training_acc": 50.0, "val_loss": 28.379850387573242, "val_acc": 60.0}
{"epoch": 53, "training_loss": 51.10548858642578, "training_acc": 50.0, "val_loss": 169.49449157714844, "val_acc": 40.0}
{"epoch": 54, "training_loss": 132.35752868652344, "training_acc": 50.0, "val_loss": 60.4606819152832, "val_acc": 60.0}
{"epoch": 55, "training_loss": 95.41948547363282, "training_acc": 50.0, "val_loss": 25.54378890991211, "val_acc": 60.0}
{"epoch": 56, "training_loss": 35.274026489257814, "training_acc": 60.0, "val_loss": 293.09130859375, "val_acc": 40.0}
{"epoch": 57, "training_loss": 248.8324462890625, "training_acc": 50.0, "val_loss": 163.0616912841797, "val_acc": 40.0}
{"epoch": 58, "training_loss": 140.78931274414063, "training_acc": 40.0, "val_loss": 73.59957122802734, "val_acc": 60.0}
{"epoch": 59, "training_loss": 78.7781494140625, "training_acc": 50.0, "val_loss": 153.48008728027344, "val_acc": 40.0}
{"epoch": 60, "training_loss": 135.04758911132814, "training_acc": 50.0, "val_loss": 170.6486053466797, "val_acc": 40.0}
{"epoch": 61, "training_loss": 123.81216049194336, "training_acc": 50.0, "val_loss": 138.72068786621094, "val_acc": 60.0}
{"epoch": 62, "training_loss": 192.4201904296875, "training_acc": 50.0, "val_loss": 189.91212463378906, "val_acc": 60.0}
{"epoch": 63, "training_loss": 239.72314453125, "training_acc": 50.0, "val_loss": 37.778926849365234, "val_acc": 40.0}
{"epoch": 64, "training_loss": 41.40843200683594, "training_acc": 50.0, "val_loss": 10.088160514831543, "val_acc": 60.0}
