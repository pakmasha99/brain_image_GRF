"main_modify.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_sex --input_option yAware --learning_rate 5e0 --batch_size 16 --weight_decay 5e-4 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 320.5707576751709, "training_acc": 50.0, "val_loss": 385.94775390625, "val_acc": 40.0}
{"epoch": 1, "training_loss": 364.08392333984375, "training_acc": 50.0, "val_loss": 681.7140502929688, "val_acc": 60.0}
{"epoch": 2, "training_loss": 846.8347900390625, "training_acc": 50.0, "val_loss": 519.2168579101562, "val_acc": 60.0}
{"epoch": 3, "training_loss": 553.7088195800782, "training_acc": 50.0, "val_loss": 205.88291931152344, "val_acc": 40.0}
{"epoch": 4, "training_loss": 222.48838500976564, "training_acc": 50.0, "val_loss": 593.81884765625, "val_acc": 40.0}
{"epoch": 5, "training_loss": 470.0484130859375, "training_acc": 50.0, "val_loss": 173.1004180908203, "val_acc": 40.0}
{"epoch": 6, "training_loss": 159.474609375, "training_acc": 50.0, "val_loss": 336.4673156738281, "val_acc": 60.0}
{"epoch": 7, "training_loss": 426.19849853515626, "training_acc": 50.0, "val_loss": 302.1382141113281, "val_acc": 60.0}
{"epoch": 8, "training_loss": 335.5008117675781, "training_acc": 50.0, "val_loss": 137.99330139160156, "val_acc": 40.0}
{"epoch": 9, "training_loss": 125.87509613037109, "training_acc": 50.0, "val_loss": 359.9240417480469, "val_acc": 40.0}
{"epoch": 10, "training_loss": 284.4792144775391, "training_acc": 50.0, "val_loss": 72.57130432128906, "val_acc": 40.0}
{"epoch": 11, "training_loss": 88.158447265625, "training_acc": 50.0, "val_loss": 267.6549987792969, "val_acc": 60.0}
{"epoch": 12, "training_loss": 330.8005737304687, "training_acc": 50.0, "val_loss": 180.00384521484375, "val_acc": 60.0}
{"epoch": 13, "training_loss": 198.5064978301525, "training_acc": 50.0, "val_loss": 293.0839538574219, "val_acc": 40.0}
{"epoch": 14, "training_loss": 252.1453826904297, "training_acc": 50.0, "val_loss": 446.2912292480469, "val_acc": 40.0}
{"epoch": 15, "training_loss": 348.3920043945312, "training_acc": 50.0, "val_loss": 95.5725326538086, "val_acc": 40.0}
{"epoch": 16, "training_loss": 107.7226806640625, "training_acc": 50.0, "val_loss": 317.80999755859375, "val_acc": 60.0}
{"epoch": 17, "training_loss": 400.3336242675781, "training_acc": 50.0, "val_loss": 299.102294921875, "val_acc": 60.0}
{"epoch": 18, "training_loss": 350.2587692260742, "training_acc": 50.0, "val_loss": 28.647418975830078, "val_acc": 40.0}
{"epoch": 19, "training_loss": 54.5180908203125, "training_acc": 50.0, "val_loss": 69.71471405029297, "val_acc": 40.0}
{"epoch": 20, "training_loss": 84.92131958007812, "training_acc": 40.0, "val_loss": 98.92889404296875, "val_acc": 60.0}
{"epoch": 21, "training_loss": 105.62089242935181, "training_acc": 50.0, "val_loss": 172.9835205078125, "val_acc": 40.0}
{"epoch": 22, "training_loss": 151.53500366210938, "training_acc": 50.0, "val_loss": 127.51080322265625, "val_acc": 40.0}
{"epoch": 23, "training_loss": 112.45744171142579, "training_acc": 40.0, "val_loss": 67.09661865234375, "val_acc": 60.0}
{"epoch": 24, "training_loss": 64.49328308105468, "training_acc": 50.0, "val_loss": 6.610915660858154, "val_acc": 60.0}
{"epoch": 25, "training_loss": 0.9348623534664512, "training_acc": 80.0, "val_loss": 6.805491924285889, "val_acc": 60.0}
{"epoch": 26, "training_loss": 12.354592895507812, "training_acc": 65.0, "val_loss": 9.802495002746582, "val_acc": 60.0}
{"epoch": 27, "training_loss": 28.770253372192382, "training_acc": 55.0, "val_loss": 164.2567901611328, "val_acc": 40.0}
{"epoch": 28, "training_loss": 109.45465393066407, "training_acc": 50.0, "val_loss": 153.42300415039062, "val_acc": 60.0}
{"epoch": 29, "training_loss": 228.7188232421875, "training_acc": 50.0, "val_loss": 253.3978271484375, "val_acc": 60.0}
{"epoch": 30, "training_loss": 283.31505126953124, "training_acc": 50.0, "val_loss": 22.21109962463379, "val_acc": 40.0}
{"epoch": 31, "training_loss": 61.78392791748047, "training_acc": 50.0, "val_loss": 42.119537353515625, "val_acc": 40.0}
{"epoch": 32, "training_loss": 35.87340240478515, "training_acc": 60.0, "val_loss": 201.13352966308594, "val_acc": 60.0}
{"epoch": 33, "training_loss": 241.3601318359375, "training_acc": 50.0, "val_loss": 157.98611450195312, "val_acc": 60.0}
{"epoch": 34, "training_loss": 154.61214904785157, "training_acc": 50.0, "val_loss": 200.4744873046875, "val_acc": 40.0}
{"epoch": 35, "training_loss": 192.0366455078125, "training_acc": 50.0, "val_loss": 365.60736083984375, "val_acc": 40.0}
{"epoch": 36, "training_loss": 286.12505493164065, "training_acc": 50.0, "val_loss": 34.10152053833008, "val_acc": 40.0}
{"epoch": 37, "training_loss": 98.29903106689453, "training_acc": 40.0, "val_loss": 279.2912292480469, "val_acc": 60.0}
{"epoch": 38, "training_loss": 337.8147216796875, "training_acc": 50.0, "val_loss": 179.48545837402344, "val_acc": 60.0}
{"epoch": 39, "training_loss": 158.3118865966797, "training_acc": 50.0, "val_loss": 342.4635925292969, "val_acc": 40.0}
{"epoch": 40, "training_loss": 301.2319061279297, "training_acc": 50.0, "val_loss": 681.5219116210938, "val_acc": 40.0}
{"epoch": 41, "training_loss": 566.0843017578125, "training_acc": 50.0, "val_loss": 547.5503540039062, "val_acc": 40.0}
{"epoch": 42, "training_loss": 412.87384643554685, "training_acc": 50.0, "val_loss": 15.784802436828613, "val_acc": 60.0}
{"epoch": 43, "training_loss": 42.28847122192383, "training_acc": 55.0, "val_loss": 181.30374145507812, "val_acc": 60.0}
