"main_modify.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 2 --task ADNI_sex --input_option yAware --learning_rate 5e0 --batch_size 16 --weight_decay 5e-4 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 214.55751399993898, "training_acc": 50.0, "val_loss": 285.6119384765625, "val_acc": 60.0}
{"epoch": 1, "training_loss": 477.40654296875, "training_acc": 40.0, "val_loss": 706.6223754882812, "val_acc": 40.0}
{"epoch": 2, "training_loss": 551.7004211425781, "training_acc": 50.0, "val_loss": 31.454818725585938, "val_acc": 40.0}
{"epoch": 3, "training_loss": 115.07493438720704, "training_acc": 50.0, "val_loss": 562.2052612304688, "val_acc": 60.0}
{"epoch": 4, "training_loss": 717.2658203125, "training_acc": 50.0, "val_loss": 445.43414306640625, "val_acc": 60.0}
{"epoch": 5, "training_loss": 468.73485107421874, "training_acc": 50.0, "val_loss": 220.06089782714844, "val_acc": 40.0}
{"epoch": 6, "training_loss": 207.56778869628906, "training_acc": 50.0, "val_loss": 688.3389892578125, "val_acc": 40.0}
{"epoch": 7, "training_loss": 572.4477844238281, "training_acc": 50.0, "val_loss": 591.7669067382812, "val_acc": 40.0}
{"epoch": 8, "training_loss": 474.43775634765626, "training_acc": 50.0, "val_loss": 64.67955780029297, "val_acc": 40.0}
{"epoch": 9, "training_loss": 173.61465454101562, "training_acc": 30.0, "val_loss": 304.5968322753906, "val_acc": 60.0}
{"epoch": 10, "training_loss": 374.41895751953126, "training_acc": 50.0, "val_loss": 141.36155700683594, "val_acc": 60.0}
{"epoch": 11, "training_loss": 189.3874267578125, "training_acc": 40.0, "val_loss": 225.47398376464844, "val_acc": 40.0}
{"epoch": 12, "training_loss": 183.289794921875, "training_acc": 50.0, "val_loss": 59.711883544921875, "val_acc": 40.0}
{"epoch": 13, "training_loss": 48.42562561035156, "training_acc": 60.0, "val_loss": 213.81260681152344, "val_acc": 60.0}
{"epoch": 14, "training_loss": 283.5817138671875, "training_acc": 50.0, "val_loss": 112.3896484375, "val_acc": 60.0}
{"epoch": 15, "training_loss": 133.15184020996094, "training_acc": 50.0, "val_loss": 266.955810546875, "val_acc": 40.0}
{"epoch": 16, "training_loss": 224.2961883544922, "training_acc": 50.0, "val_loss": 178.0078887939453, "val_acc": 40.0}
{"epoch": 17, "training_loss": 88.59755994868465, "training_acc": 70.0, "val_loss": 110.26068115234375, "val_acc": 60.0}
{"epoch": 18, "training_loss": 144.1864990234375, "training_acc": 50.0, "val_loss": 68.9889144897461, "val_acc": 60.0}
{"epoch": 19, "training_loss": 68.40670394897461, "training_acc": 60.0, "val_loss": 188.72789001464844, "val_acc": 40.0}
{"epoch": 20, "training_loss": 153.2063232421875, "training_acc": 50.0, "val_loss": 27.73419761657715, "val_acc": 40.0}
{"epoch": 21, "training_loss": 76.02506561279297, "training_acc": 40.0, "val_loss": 187.3734588623047, "val_acc": 60.0}
{"epoch": 22, "training_loss": 221.9118408203125, "training_acc": 50.0, "val_loss": 2.090660572052002, "val_acc": 80.0}
{"epoch": 23, "training_loss": 54.843611812591554, "training_acc": 70.0, "val_loss": 244.20689392089844, "val_acc": 40.0}
{"epoch": 24, "training_loss": 185.5153350830078, "training_acc": 50.0, "val_loss": 35.373992919921875, "val_acc": 60.0}
{"epoch": 25, "training_loss": 56.330712890625, "training_acc": 50.0, "val_loss": 41.39582061767578, "val_acc": 60.0}
{"epoch": 26, "training_loss": 75.15081787109375, "training_acc": 40.0, "val_loss": 106.86437225341797, "val_acc": 40.0}
{"epoch": 27, "training_loss": 72.68450889587402, "training_acc": 50.0, "val_loss": 6.75902795791626, "val_acc": 60.0}
{"epoch": 28, "training_loss": 23.920045471191408, "training_acc": 50.0, "val_loss": 94.71084594726562, "val_acc": 40.0}
{"epoch": 29, "training_loss": 81.15039520263672, "training_acc": 40.0, "val_loss": 5.0449700355529785, "val_acc": 60.0}
{"epoch": 30, "training_loss": 1.8120031416416165, "training_acc": 80.0, "val_loss": 16.44938087463379, "val_acc": 60.0}
{"epoch": 31, "training_loss": 28.509043884277343, "training_acc": 50.0, "val_loss": 47.23582077026367, "val_acc": 40.0}
{"epoch": 32, "training_loss": 45.04183349609375, "training_acc": 50.0, "val_loss": 63.60170364379883, "val_acc": 60.0}
{"epoch": 33, "training_loss": 56.783536958694455, "training_acc": 55.0, "val_loss": 90.8926773071289, "val_acc": 40.0}
{"epoch": 34, "training_loss": 71.07347412109375, "training_acc": 50.0, "val_loss": 77.11872863769531, "val_acc": 60.0}
{"epoch": 35, "training_loss": 101.73988800048828, "training_acc": 50.0, "val_loss": 89.5963363647461, "val_acc": 60.0}
{"epoch": 36, "training_loss": 81.58544311523437, "training_acc": 50.0, "val_loss": 277.0084228515625, "val_acc": 40.0}
{"epoch": 37, "training_loss": 252.9407958984375, "training_acc": 50.0, "val_loss": 429.035888671875, "val_acc": 40.0}
{"epoch": 38, "training_loss": 356.42197265625, "training_acc": 50.0, "val_loss": 158.84747314453125, "val_acc": 40.0}
{"epoch": 39, "training_loss": 140.0569641113281, "training_acc": 40.0, "val_loss": 87.07331848144531, "val_acc": 60.0}
{"epoch": 40, "training_loss": 96.09269943237305, "training_acc": 50.0, "val_loss": 132.61851501464844, "val_acc": 40.0}
{"epoch": 41, "training_loss": 117.73693542480468, "training_acc": 50.0, "val_loss": 111.78076171875, "val_acc": 40.0}
