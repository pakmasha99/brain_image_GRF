"main_modify.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 4 --task ADNI_sex --input_option yAware --learning_rate 1e1 --batch_size 16 --weight_decay 5e-4 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 214.189120388031, "training_acc": 55.0, "val_loss": 1345.181396484375, "val_acc": 40.0}
{"epoch": 1, "training_loss": 874.3161193847657, "training_acc": 55.0, "val_loss": 419.6227722167969, "val_acc": 60.0}
{"epoch": 2, "training_loss": 429.99608993530273, "training_acc": 55.0, "val_loss": 349.88873291015625, "val_acc": 40.0}
{"epoch": 3, "training_loss": 206.54508895874022, "training_acc": 55.0, "val_loss": 252.3813018798828, "val_acc": 40.0}
{"epoch": 4, "training_loss": 149.68242301940919, "training_acc": 55.0, "val_loss": 422.7259826660156, "val_acc": 60.0}
{"epoch": 5, "training_loss": 582.8420532226562, "training_acc": 45.0, "val_loss": 284.23565673828125, "val_acc": 60.0}
{"epoch": 6, "training_loss": 350.93876953125, "training_acc": 45.0, "val_loss": 347.4598693847656, "val_acc": 40.0}
{"epoch": 7, "training_loss": 239.69516830444337, "training_acc": 55.0, "val_loss": 172.0731201171875, "val_acc": 60.0}
{"epoch": 8, "training_loss": 228.35252075195314, "training_acc": 45.0, "val_loss": 100.7999496459961, "val_acc": 40.0}
{"epoch": 9, "training_loss": 67.77221984863282, "training_acc": 55.0, "val_loss": 273.3345642089844, "val_acc": 60.0}
{"epoch": 10, "training_loss": 391.129833984375, "training_acc": 45.0, "val_loss": 175.5504608154297, "val_acc": 60.0}
{"epoch": 11, "training_loss": 154.25076904296876, "training_acc": 65.0, "val_loss": 634.4939575195312, "val_acc": 40.0}
{"epoch": 12, "training_loss": 492.48984375, "training_acc": 55.0, "val_loss": 552.1808471679688, "val_acc": 40.0}
{"epoch": 13, "training_loss": 309.2900817871094, "training_acc": 55.0, "val_loss": 421.3734436035156, "val_acc": 60.0}
{"epoch": 14, "training_loss": 607.2540588378906, "training_acc": 45.0, "val_loss": 751.0344848632812, "val_acc": 60.0}
{"epoch": 15, "training_loss": 1018.9565246582031, "training_acc": 45.0, "val_loss": 387.02197265625, "val_acc": 60.0}
{"epoch": 16, "training_loss": 499.0174819946289, "training_acc": 35.0, "val_loss": 222.42349243164062, "val_acc": 40.0}
{"epoch": 17, "training_loss": 148.97989349365236, "training_acc": 55.0, "val_loss": 146.36273193359375, "val_acc": 60.0}
{"epoch": 18, "training_loss": 199.60189208984374, "training_acc": 45.0, "val_loss": 78.66392517089844, "val_acc": 60.0}
{"epoch": 19, "training_loss": 93.89329223632812, "training_acc": 55.0, "val_loss": 338.96728515625, "val_acc": 40.0}
{"epoch": 20, "training_loss": 231.77764892578125, "training_acc": 55.0, "val_loss": 85.12518310546875, "val_acc": 60.0}
{"epoch": 21, "training_loss": 114.1835807800293, "training_acc": 45.0, "val_loss": 21.203201293945312, "val_acc": 40.0}
{"epoch": 22, "training_loss": 38.62286911010742, "training_acc": 45.0, "val_loss": 153.1545867919922, "val_acc": 40.0}
{"epoch": 23, "training_loss": 113.12389526367187, "training_acc": 55.0, "val_loss": 55.2922248840332, "val_acc": 60.0}
{"epoch": 24, "training_loss": 61.88274049758911, "training_acc": 50.0, "val_loss": 223.32749938964844, "val_acc": 40.0}
{"epoch": 25, "training_loss": 160.47349853515624, "training_acc": 55.0, "val_loss": 46.33328628540039, "val_acc": 60.0}
{"epoch": 26, "training_loss": 54.05022621154785, "training_acc": 45.0, "val_loss": 275.6392517089844, "val_acc": 40.0}
{"epoch": 27, "training_loss": 202.72743377685546, "training_acc": 55.0, "val_loss": 159.01226806640625, "val_acc": 40.0}
{"epoch": 28, "training_loss": 196.23145751953126, "training_acc": 35.0, "val_loss": 59.443031311035156, "val_acc": 60.0}
{"epoch": 29, "training_loss": 123.111474609375, "training_acc": 45.0, "val_loss": 462.7503967285156, "val_acc": 40.0}
{"epoch": 30, "training_loss": 325.25140380859375, "training_acc": 55.0, "val_loss": 0.1653306931257248, "val_acc": 100.0}
{"epoch": 31, "training_loss": 48.283773517608644, "training_acc": 85.0, "val_loss": 191.0355224609375, "val_acc": 60.0}
{"epoch": 32, "training_loss": 196.5989082336426, "training_acc": 45.0, "val_loss": 579.1849975585938, "val_acc": 40.0}
{"epoch": 33, "training_loss": 431.452978515625, "training_acc": 55.0, "val_loss": 1078.643798828125, "val_acc": 40.0}
{"epoch": 34, "training_loss": 800.6094848632813, "training_acc": 55.0, "val_loss": 856.8598022460938, "val_acc": 40.0}
{"epoch": 35, "training_loss": 575.0295043945313, "training_acc": 55.0, "val_loss": 87.18827056884766, "val_acc": 60.0}
{"epoch": 36, "training_loss": 137.8216552734375, "training_acc": 45.0, "val_loss": 281.1130065917969, "val_acc": 60.0}
{"epoch": 37, "training_loss": 347.38148193359376, "training_acc": 45.0, "val_loss": 263.3844299316406, "val_acc": 40.0}
{"epoch": 38, "training_loss": 207.09129028320314, "training_acc": 55.0, "val_loss": 433.74560546875, "val_acc": 40.0}
{"epoch": 39, "training_loss": 321.693505859375, "training_acc": 55.0, "val_loss": 64.90679168701172, "val_acc": 60.0}
{"epoch": 40, "training_loss": 77.4978759765625, "training_acc": 45.0, "val_loss": 276.9777526855469, "val_acc": 40.0}
{"epoch": 41, "training_loss": 204.29959716796876, "training_acc": 55.0, "val_loss": 260.8224792480469, "val_acc": 40.0}
{"epoch": 42, "training_loss": 135.2250183105469, "training_acc": 55.0, "val_loss": 379.177734375, "val_acc": 60.0}
{"epoch": 43, "training_loss": 523.670263671875, "training_acc": 45.0, "val_loss": 685.7218017578125, "val_acc": 60.0}
{"epoch": 44, "training_loss": 934.7313598632812, "training_acc": 45.0, "val_loss": 437.47125244140625, "val_acc": 60.0}
{"epoch": 45, "training_loss": 514.6831787109375, "training_acc": 45.0, "val_loss": 565.9611206054688, "val_acc": 40.0}
{"epoch": 46, "training_loss": 454.64198608398436, "training_acc": 55.0, "val_loss": 1173.3121337890625, "val_acc": 40.0}
{"epoch": 47, "training_loss": 870.7789794921875, "training_acc": 55.0, "val_loss": 851.3740234375, "val_acc": 40.0}
{"epoch": 48, "training_loss": 591.9591583251953, "training_acc": 55.0, "val_loss": 176.4141387939453, "val_acc": 60.0}
{"epoch": 49, "training_loss": 283.15626220703126, "training_acc": 45.0, "val_loss": 318.103759765625, "val_acc": 60.0}
