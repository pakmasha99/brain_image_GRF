"main_modify.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 1 --task ADNI_sex --input_option yAware --learning_rate 1e1 --batch_size 16 --weight_decay 5e-4 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 211.950053691864, "training_acc": 55.0, "val_loss": 774.2064819335938, "val_acc": 40.0}
{"epoch": 1, "training_loss": 498.0144775390625, "training_acc": 65.0, "val_loss": 1426.2484130859375, "val_acc": 60.0}
{"epoch": 2, "training_loss": 1871.3250244140625, "training_acc": 45.0, "val_loss": 284.3506774902344, "val_acc": 60.0}
{"epoch": 3, "training_loss": 503.39537353515624, "training_acc": 45.0, "val_loss": 1784.766845703125, "val_acc": 40.0}
{"epoch": 4, "training_loss": 1385.908935546875, "training_acc": 55.0, "val_loss": 1488.6068115234375, "val_acc": 40.0}
{"epoch": 5, "training_loss": 1045.90205078125, "training_acc": 55.0, "val_loss": 171.61827087402344, "val_acc": 60.0}
{"epoch": 6, "training_loss": 298.8087524414062, "training_acc": 45.0, "val_loss": 393.084228515625, "val_acc": 60.0}
{"epoch": 7, "training_loss": 428.7931640625, "training_acc": 45.0, "val_loss": 620.0341796875, "val_acc": 40.0}
{"epoch": 8, "training_loss": 500.5674743652344, "training_acc": 55.0, "val_loss": 1363.8431396484375, "val_acc": 40.0}
{"epoch": 9, "training_loss": 1035.62197265625, "training_acc": 55.0, "val_loss": 910.8466796875, "val_acc": 40.0}
{"epoch": 10, "training_loss": 512.2809448242188, "training_acc": 55.0, "val_loss": 476.8126525878906, "val_acc": 60.0}
{"epoch": 11, "training_loss": 751.289306640625, "training_acc": 45.0, "val_loss": 1018.6752319335938, "val_acc": 60.0}
{"epoch": 12, "training_loss": 1397.242041015625, "training_acc": 45.0, "val_loss": 717.0667724609375, "val_acc": 60.0}
{"epoch": 13, "training_loss": 881.7868408203125, "training_acc": 45.0, "val_loss": 396.7646789550781, "val_acc": 40.0}
{"epoch": 14, "training_loss": 428.584423828125, "training_acc": 55.0, "val_loss": 1091.5394287109375, "val_acc": 40.0}
{"epoch": 15, "training_loss": 798.5338195800781, "training_acc": 55.0, "val_loss": 722.1984252929688, "val_acc": 40.0}
{"epoch": 16, "training_loss": 457.7998962402344, "training_acc": 55.0, "val_loss": 224.8739013671875, "val_acc": 60.0}
{"epoch": 17, "training_loss": 395.225146484375, "training_acc": 45.0, "val_loss": 391.5369567871094, "val_acc": 60.0}
{"epoch": 18, "training_loss": 487.6952239990234, "training_acc": 45.0, "val_loss": 284.8533630371094, "val_acc": 40.0}
{"epoch": 19, "training_loss": 276.1722412109375, "training_acc": 55.0, "val_loss": 512.3607788085938, "val_acc": 40.0}
{"epoch": 20, "training_loss": 323.61695251464846, "training_acc": 55.0, "val_loss": 172.5916290283203, "val_acc": 60.0}
{"epoch": 21, "training_loss": 258.7509033203125, "training_acc": 45.0, "val_loss": 278.8809509277344, "val_acc": 60.0}
{"epoch": 22, "training_loss": 369.7507148742676, "training_acc": 45.0, "val_loss": 239.3785400390625, "val_acc": 40.0}
{"epoch": 23, "training_loss": 185.96353759765626, "training_acc": 55.0, "val_loss": 248.9148712158203, "val_acc": 40.0}
{"epoch": 24, "training_loss": 117.37554206848145, "training_acc": 65.0, "val_loss": 118.07970428466797, "val_acc": 60.0}
{"epoch": 25, "training_loss": 160.7858615875244, "training_acc": 45.0, "val_loss": 269.2426452636719, "val_acc": 40.0}
{"epoch": 26, "training_loss": 202.4551025390625, "training_acc": 55.0, "val_loss": 35.19428634643555, "val_acc": 40.0}
{"epoch": 27, "training_loss": 110.57753143310546, "training_acc": 55.0, "val_loss": 293.2188720703125, "val_acc": 60.0}
{"epoch": 28, "training_loss": 365.0826782226562, "training_acc": 45.0, "val_loss": 306.4056091308594, "val_acc": 40.0}
{"epoch": 29, "training_loss": 234.81281433105468, "training_acc": 55.0, "val_loss": 664.5046997070312, "val_acc": 40.0}
{"epoch": 30, "training_loss": 457.908154296875, "training_acc": 55.0, "val_loss": 135.54136657714844, "val_acc": 40.0}
{"epoch": 31, "training_loss": 140.05625610351564, "training_acc": 55.0, "val_loss": 511.8839416503906, "val_acc": 60.0}
{"epoch": 32, "training_loss": 721.41572265625, "training_acc": 45.0, "val_loss": 313.01080322265625, "val_acc": 60.0}
{"epoch": 33, "training_loss": 319.31834802627566, "training_acc": 55.0, "val_loss": 427.385498046875, "val_acc": 40.0}
{"epoch": 34, "training_loss": 310.17054138183596, "training_acc": 55.0, "val_loss": 474.111328125, "val_acc": 40.0}
{"epoch": 35, "training_loss": 283.9309936523438, "training_acc": 55.0, "val_loss": 199.74993896484375, "val_acc": 60.0}
{"epoch": 36, "training_loss": 321.0076843261719, "training_acc": 45.0, "val_loss": 332.97027587890625, "val_acc": 60.0}
{"epoch": 37, "training_loss": 394.77568359375, "training_acc": 45.0, "val_loss": 366.2155456542969, "val_acc": 40.0}
{"epoch": 38, "training_loss": 313.1252807617187, "training_acc": 55.0, "val_loss": 757.692626953125, "val_acc": 40.0}
{"epoch": 39, "training_loss": 535.3493377685547, "training_acc": 55.0, "val_loss": 270.7543640136719, "val_acc": 40.0}
{"epoch": 40, "training_loss": 226.8474365234375, "training_acc": 45.0, "val_loss": 214.1235809326172, "val_acc": 60.0}
{"epoch": 41, "training_loss": 282.4616195678711, "training_acc": 45.0, "val_loss": 201.02462768554688, "val_acc": 40.0}
{"epoch": 42, "training_loss": 138.32626037597657, "training_acc": 55.0, "val_loss": 161.61354064941406, "val_acc": 40.0}
{"epoch": 43, "training_loss": 130.33507080078124, "training_acc": 45.0, "val_loss": 44.618446350097656, "val_acc": 60.0}
{"epoch": 44, "training_loss": 65.05772247314454, "training_acc": 55.0, "val_loss": 393.6664123535156, "val_acc": 40.0}
{"epoch": 45, "training_loss": 264.7259765625, "training_acc": 55.0, "val_loss": 16.214658737182617, "val_acc": 40.0}
{"epoch": 46, "training_loss": 16.82276134490967, "training_acc": 70.0, "val_loss": 161.98890686035156, "val_acc": 60.0}
{"epoch": 47, "training_loss": 182.78473052978515, "training_acc": 45.0, "val_loss": 470.1156311035156, "val_acc": 40.0}
{"epoch": 48, "training_loss": 381.1598876953125, "training_acc": 55.0, "val_loss": 732.0240478515625, "val_acc": 40.0}
{"epoch": 49, "training_loss": 483.76451416015624, "training_acc": 55.0, "val_loss": 6.629130840301514, "val_acc": 60.0}
{"epoch": 50, "training_loss": 32.96891708374024, "training_acc": 60.0, "val_loss": 345.6988220214844, "val_acc": 60.0}
{"epoch": 51, "training_loss": 465.05201416015626, "training_acc": 45.0, "val_loss": 45.134254455566406, "val_acc": 60.0}
{"epoch": 52, "training_loss": 47.55668640136719, "training_acc": 65.0, "val_loss": 921.2562866210938, "val_acc": 40.0}
{"epoch": 53, "training_loss": 689.3503173828125, "training_acc": 55.0, "val_loss": 1132.1448974609375, "val_acc": 40.0}
{"epoch": 54, "training_loss": 801.0325927734375, "training_acc": 55.0, "val_loss": 519.146240234375, "val_acc": 40.0}
{"epoch": 55, "training_loss": 416.9379150390625, "training_acc": 35.0, "val_loss": 150.4113006591797, "val_acc": 60.0}
{"epoch": 56, "training_loss": 195.70772438049318, "training_acc": 45.0, "val_loss": 306.04962158203125, "val_acc": 40.0}
{"epoch": 57, "training_loss": 226.228076171875, "training_acc": 55.0, "val_loss": 200.5676727294922, "val_acc": 40.0}
{"epoch": 58, "training_loss": 171.42459106445312, "training_acc": 45.0, "val_loss": 129.83128356933594, "val_acc": 60.0}
{"epoch": 59, "training_loss": 159.61883621215821, "training_acc": 45.0, "val_loss": 76.8843002319336, "val_acc": 40.0}
{"epoch": 60, "training_loss": 54.264852905273436, "training_acc": 55.0, "val_loss": 44.1242561340332, "val_acc": 60.0}
{"epoch": 61, "training_loss": 91.65174255371093, "training_acc": 45.0, "val_loss": 296.1822509765625, "val_acc": 40.0}
{"epoch": 62, "training_loss": 206.7903564453125, "training_acc": 55.0, "val_loss": 93.07073211669922, "val_acc": 60.0}
{"epoch": 63, "training_loss": 123.1832706451416, "training_acc": 45.0, "val_loss": 195.16615295410156, "val_acc": 40.0}
{"epoch": 64, "training_loss": 131.91570434570312, "training_acc": 55.0, "val_loss": 40.908714294433594, "val_acc": 60.0}
{"epoch": 65, "training_loss": 58.7402099609375, "training_acc": 50.0, "val_loss": 74.87017822265625, "val_acc": 40.0}
{"epoch": 66, "training_loss": 35.51353492736816, "training_acc": 65.0, "val_loss": 15.879165649414062, "val_acc": 60.0}
{"epoch": 67, "training_loss": 91.94793395996093, "training_acc": 35.0, "val_loss": 204.0565185546875, "val_acc": 40.0}
{"epoch": 68, "training_loss": 120.65523071289063, "training_acc": 55.0, "val_loss": 62.165645599365234, "val_acc": 60.0}
