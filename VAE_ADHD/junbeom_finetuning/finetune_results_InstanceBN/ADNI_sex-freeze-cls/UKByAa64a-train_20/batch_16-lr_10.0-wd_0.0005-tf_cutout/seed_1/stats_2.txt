"main_modify.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 1 --task ADNI_sex --input_option yAware --learning_rate 1e1 --batch_size 16 --weight_decay 5e-4 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 190.7683811187744, "training_acc": 60.0, "val_loss": 449.1517639160156, "val_acc": 40.0}
{"epoch": 1, "training_loss": 572.392822265625, "training_acc": 50.0, "val_loss": 1282.597412109375, "val_acc": 60.0}
{"epoch": 2, "training_loss": 1505.8838134765624, "training_acc": 50.0, "val_loss": 175.46841430664062, "val_acc": 60.0}
{"epoch": 3, "training_loss": 128.772021484375, "training_acc": 70.0, "val_loss": 2215.597900390625, "val_acc": 40.0}
{"epoch": 4, "training_loss": 1882.6551513671875, "training_acc": 50.0, "val_loss": 2608.458740234375, "val_acc": 40.0}
{"epoch": 5, "training_loss": 2112.6172119140624, "training_acc": 50.0, "val_loss": 1406.8104248046875, "val_acc": 40.0}
{"epoch": 6, "training_loss": 1001.0116455078125, "training_acc": 50.0, "val_loss": 636.8888549804688, "val_acc": 60.0}
{"epoch": 7, "training_loss": 849.5246459960938, "training_acc": 50.0, "val_loss": 1402.5465087890625, "val_acc": 60.0}
{"epoch": 8, "training_loss": 1744.4616333007812, "training_acc": 50.0, "val_loss": 1268.8861083984375, "val_acc": 60.0}
{"epoch": 9, "training_loss": 1463.483544921875, "training_acc": 50.0, "val_loss": 371.9320373535156, "val_acc": 60.0}
{"epoch": 10, "training_loss": 270.717431640625, "training_acc": 70.0, "val_loss": 1380.387451171875, "val_acc": 40.0}
{"epoch": 11, "training_loss": 1244.4916015625, "training_acc": 50.0, "val_loss": 2016.685546875, "val_acc": 40.0}
{"epoch": 12, "training_loss": 1673.1985107421874, "training_acc": 50.0, "val_loss": 1426.3642578125, "val_acc": 40.0}
{"epoch": 13, "training_loss": 1048.9500732421875, "training_acc": 50.0, "val_loss": 70.43462371826172, "val_acc": 60.0}
{"epoch": 14, "training_loss": 171.7109130859375, "training_acc": 50.0, "val_loss": 586.3269653320312, "val_acc": 60.0}
{"epoch": 15, "training_loss": 712.4209594726562, "training_acc": 50.0, "val_loss": 322.34814453125, "val_acc": 60.0}
{"epoch": 16, "training_loss": 373.6458038330078, "training_acc": 40.0, "val_loss": 133.5826416015625, "val_acc": 40.0}
{"epoch": 17, "training_loss": 128.07329406738282, "training_acc": 40.0, "val_loss": 81.01439666748047, "val_acc": 40.0}
{"epoch": 18, "training_loss": 55.144554901123044, "training_acc": 50.0, "val_loss": 280.0928955078125, "val_acc": 60.0}
{"epoch": 19, "training_loss": 363.0179931640625, "training_acc": 50.0, "val_loss": 283.09747314453125, "val_acc": 60.0}
{"epoch": 20, "training_loss": 255.27937774658204, "training_acc": 50.0, "val_loss": 612.0572509765625, "val_acc": 40.0}
{"epoch": 21, "training_loss": 545.9496643066407, "training_acc": 50.0, "val_loss": 1121.5247802734375, "val_acc": 40.0}
{"epoch": 22, "training_loss": 920.7771240234375, "training_acc": 50.0, "val_loss": 607.9351806640625, "val_acc": 40.0}
{"epoch": 23, "training_loss": 356.3198511123657, "training_acc": 60.0, "val_loss": 466.4883728027344, "val_acc": 60.0}
{"epoch": 24, "training_loss": 634.494091796875, "training_acc": 50.0, "val_loss": 758.7328491210938, "val_acc": 60.0}
{"epoch": 25, "training_loss": 918.57763671875, "training_acc": 50.0, "val_loss": 384.3344421386719, "val_acc": 60.0}
{"epoch": 26, "training_loss": 425.00924530029295, "training_acc": 40.0, "val_loss": 175.42747497558594, "val_acc": 40.0}
{"epoch": 27, "training_loss": 154.886083984375, "training_acc": 50.0, "val_loss": 81.74429321289062, "val_acc": 60.0}
{"epoch": 28, "training_loss": 69.0504653930664, "training_acc": 50.0, "val_loss": 475.8337097167969, "val_acc": 40.0}
{"epoch": 29, "training_loss": 442.6418701171875, "training_acc": 50.0, "val_loss": 691.6826171875, "val_acc": 40.0}
{"epoch": 30, "training_loss": 537.2263916015625, "training_acc": 50.0, "val_loss": 48.534366607666016, "val_acc": 60.0}
{"epoch": 31, "training_loss": 61.997178649902345, "training_acc": 50.0, "val_loss": 179.47161865234375, "val_acc": 60.0}
{"epoch": 32, "training_loss": 172.77746200561523, "training_acc": 50.0, "val_loss": 399.0903015136719, "val_acc": 40.0}
{"epoch": 33, "training_loss": 351.6944213867188, "training_acc": 50.0, "val_loss": 511.51904296875, "val_acc": 40.0}
{"epoch": 34, "training_loss": 387.31244506835935, "training_acc": 50.0, "val_loss": 153.5901336669922, "val_acc": 60.0}
{"epoch": 35, "training_loss": 210.26490478515626, "training_acc": 50.0, "val_loss": 224.4263153076172, "val_acc": 60.0}
{"epoch": 36, "training_loss": 214.9545412898057, "training_acc": 60.0, "val_loss": 274.8461608886719, "val_acc": 40.0}
{"epoch": 37, "training_loss": 231.29974517822265, "training_acc": 50.0, "val_loss": 111.63604736328125, "val_acc": 40.0}
{"epoch": 38, "training_loss": 162.7876953125, "training_acc": 40.0, "val_loss": 190.64089965820312, "val_acc": 60.0}
{"epoch": 39, "training_loss": 167.62987518310547, "training_acc": 50.0, "val_loss": 510.1645202636719, "val_acc": 40.0}
{"epoch": 40, "training_loss": 454.7598876953125, "training_acc": 50.0, "val_loss": 835.5452270507812, "val_acc": 40.0}
{"epoch": 41, "training_loss": 665.9930908203125, "training_acc": 50.0, "val_loss": 191.61228942871094, "val_acc": 40.0}
{"epoch": 42, "training_loss": 215.03914794921874, "training_acc": 50.0, "val_loss": 587.7584838867188, "val_acc": 60.0}
{"epoch": 43, "training_loss": 739.8047973632813, "training_acc": 50.0, "val_loss": 535.8486938476562, "val_acc": 60.0}
{"epoch": 44, "training_loss": 590.1798706054688, "training_acc": 50.0, "val_loss": 204.1283721923828, "val_acc": 40.0}
{"epoch": 45, "training_loss": 260.418505859375, "training_acc": 50.0, "val_loss": 464.2099609375, "val_acc": 40.0}
{"epoch": 46, "training_loss": 339.7901580810547, "training_acc": 50.0, "val_loss": 248.4060516357422, "val_acc": 60.0}
{"epoch": 47, "training_loss": 314.6523895263672, "training_acc": 50.0, "val_loss": 417.080078125, "val_acc": 60.0}
{"epoch": 48, "training_loss": 465.210888671875, "training_acc": 50.0, "val_loss": 60.543701171875, "val_acc": 40.0}
{"epoch": 49, "training_loss": 121.08853759765626, "training_acc": 50.0, "val_loss": 177.2261962890625, "val_acc": 40.0}
