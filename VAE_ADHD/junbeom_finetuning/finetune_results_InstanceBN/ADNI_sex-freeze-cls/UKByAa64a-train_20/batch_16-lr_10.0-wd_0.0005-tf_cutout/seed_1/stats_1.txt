"main_modify.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 1 --task ADNI_sex --input_option yAware --learning_rate 1e1 --batch_size 16 --weight_decay 5e-4 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 428.81485891342163, "training_acc": 55.0, "val_loss": 814.7643432617188, "val_acc": 40.0}
{"epoch": 1, "training_loss": 689.396533203125, "training_acc": 55.0, "val_loss": 1172.0086669921875, "val_acc": 60.0}
{"epoch": 2, "training_loss": 1537.297607421875, "training_acc": 45.0, "val_loss": 248.7568359375, "val_acc": 60.0}
{"epoch": 3, "training_loss": 435.64842529296874, "training_acc": 45.0, "val_loss": 1542.4345703125, "val_acc": 40.0}
{"epoch": 4, "training_loss": 1177.0234130859376, "training_acc": 55.0, "val_loss": 1352.4176025390625, "val_acc": 40.0}
{"epoch": 5, "training_loss": 870.313525390625, "training_acc": 55.0, "val_loss": 144.21981811523438, "val_acc": 60.0}
{"epoch": 6, "training_loss": 328.73975830078126, "training_acc": 45.0, "val_loss": 464.83624267578125, "val_acc": 60.0}
{"epoch": 7, "training_loss": 601.6738220214844, "training_acc": 45.0, "val_loss": 243.2810516357422, "val_acc": 40.0}
{"epoch": 8, "training_loss": 274.0780334472656, "training_acc": 55.0, "val_loss": 205.3274383544922, "val_acc": 40.0}
{"epoch": 9, "training_loss": 170.08814697265626, "training_acc": 55.0, "val_loss": 344.1395263671875, "val_acc": 60.0}
{"epoch": 10, "training_loss": 456.175048828125, "training_acc": 45.0, "val_loss": 56.79059982299805, "val_acc": 60.0}
{"epoch": 11, "training_loss": 186.16522827148438, "training_acc": 35.0, "val_loss": 599.8903198242188, "val_acc": 40.0}
{"epoch": 12, "training_loss": 424.2598876953125, "training_acc": 55.0, "val_loss": 65.70842742919922, "val_acc": 40.0}
{"epoch": 13, "training_loss": 126.5732666015625, "training_acc": 55.0, "val_loss": 575.3344116210938, "val_acc": 60.0}
{"epoch": 14, "training_loss": 783.69580078125, "training_acc": 45.0, "val_loss": 410.37603759765625, "val_acc": 60.0}
{"epoch": 15, "training_loss": 477.32520599365233, "training_acc": 45.0, "val_loss": 568.9699096679688, "val_acc": 40.0}
{"epoch": 16, "training_loss": 528.3906005859375, "training_acc": 55.0, "val_loss": 1033.5662841796875, "val_acc": 40.0}
{"epoch": 17, "training_loss": 737.0105224609375, "training_acc": 55.0, "val_loss": 431.8151550292969, "val_acc": 40.0}
{"epoch": 18, "training_loss": 221.30425949096679, "training_acc": 65.0, "val_loss": 336.9041442871094, "val_acc": 60.0}
{"epoch": 19, "training_loss": 467.03436889648435, "training_acc": 45.0, "val_loss": 260.97003173828125, "val_acc": 60.0}
{"epoch": 20, "training_loss": 257.6443082809448, "training_acc": 55.0, "val_loss": 265.2559509277344, "val_acc": 40.0}
{"epoch": 21, "training_loss": 202.34693603515626, "training_acc": 55.0, "val_loss": 17.41157341003418, "val_acc": 60.0}
{"epoch": 22, "training_loss": 32.53963928222656, "training_acc": 45.0, "val_loss": 232.2733154296875, "val_acc": 40.0}
{"epoch": 23, "training_loss": 190.989453125, "training_acc": 55.0, "val_loss": 63.2917594909668, "val_acc": 40.0}
{"epoch": 24, "training_loss": 94.68221435546874, "training_acc": 55.0, "val_loss": 371.57696533203125, "val_acc": 60.0}
{"epoch": 25, "training_loss": 481.36488037109376, "training_acc": 45.0, "val_loss": 22.40917205810547, "val_acc": 60.0}
{"epoch": 26, "training_loss": 180.02442321777343, "training_acc": 35.0, "val_loss": 908.23486328125, "val_acc": 40.0}
{"epoch": 27, "training_loss": 673.5648498535156, "training_acc": 55.0, "val_loss": 779.1057739257812, "val_acc": 40.0}
{"epoch": 28, "training_loss": 547.3336212158204, "training_acc": 55.0, "val_loss": 4.354110240936279, "val_acc": 60.0}
{"epoch": 29, "training_loss": 3.8721736907958983, "training_acc": 80.0, "val_loss": 332.4549255371094, "val_acc": 60.0}
{"epoch": 30, "training_loss": 440.87672119140626, "training_acc": 45.0, "val_loss": 92.74785614013672, "val_acc": 60.0}
{"epoch": 31, "training_loss": 118.09385986328125, "training_acc": 55.0, "val_loss": 707.132080078125, "val_acc": 40.0}
{"epoch": 32, "training_loss": 554.0139404296875, "training_acc": 55.0, "val_loss": 572.7702026367188, "val_acc": 40.0}
{"epoch": 33, "training_loss": 381.2841209411621, "training_acc": 55.0, "val_loss": 300.2786560058594, "val_acc": 60.0}
{"epoch": 34, "training_loss": 466.63125, "training_acc": 45.0, "val_loss": 375.6707763671875, "val_acc": 60.0}
{"epoch": 35, "training_loss": 417.2182983398437, "training_acc": 45.0, "val_loss": 492.0372619628906, "val_acc": 40.0}
{"epoch": 36, "training_loss": 470.053857421875, "training_acc": 55.0, "val_loss": 966.341796875, "val_acc": 40.0}
{"epoch": 37, "training_loss": 677.9819580078125, "training_acc": 55.0, "val_loss": 316.46783447265625, "val_acc": 40.0}
{"epoch": 38, "training_loss": 236.226171875, "training_acc": 55.0, "val_loss": 461.9356384277344, "val_acc": 60.0}
{"epoch": 39, "training_loss": 633.2827392578125, "training_acc": 45.0, "val_loss": 362.6720886230469, "val_acc": 60.0}
{"epoch": 40, "training_loss": 412.98707275390626, "training_acc": 45.0, "val_loss": 543.0421142578125, "val_acc": 40.0}
{"epoch": 41, "training_loss": 425.57822875976564, "training_acc": 55.0, "val_loss": 1063.2564697265625, "val_acc": 40.0}
{"epoch": 42, "training_loss": 780.9863586425781, "training_acc": 55.0, "val_loss": 789.8290405273438, "val_acc": 40.0}
{"epoch": 43, "training_loss": 493.24912109375, "training_acc": 55.0, "val_loss": 167.57373046875, "val_acc": 60.0}
{"epoch": 44, "training_loss": 319.8277587890625, "training_acc": 45.0, "val_loss": 400.48516845703125, "val_acc": 60.0}
{"epoch": 45, "training_loss": 477.3557189941406, "training_acc": 45.0, "val_loss": 256.7681884765625, "val_acc": 40.0}
{"epoch": 46, "training_loss": 270.62677001953125, "training_acc": 55.0, "val_loss": 574.3666381835938, "val_acc": 40.0}
{"epoch": 47, "training_loss": 380.24730224609374, "training_acc": 55.0, "val_loss": 87.80579376220703, "val_acc": 60.0}
