"main_modify.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 1 --task ADNI_sex --input_option yAware --learning_rate 1e1 --batch_size 16 --weight_decay 5e-4 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 225.46327123641967, "training_acc": 50.0, "val_loss": 997.1643676757812, "val_acc": 40.0}
{"epoch": 1, "training_loss": 821.18232421875, "training_acc": 50.0, "val_loss": 1131.124267578125, "val_acc": 40.0}
{"epoch": 2, "training_loss": 881.2279968261719, "training_acc": 50.0, "val_loss": 245.35647583007812, "val_acc": 60.0}
{"epoch": 3, "training_loss": 322.1427429199219, "training_acc": 50.0, "val_loss": 125.89277648925781, "val_acc": 60.0}
{"epoch": 4, "training_loss": 205.031298828125, "training_acc": 50.0, "val_loss": 719.9663696289062, "val_acc": 40.0}
{"epoch": 5, "training_loss": 547.6315185546875, "training_acc": 50.0, "val_loss": 103.90056610107422, "val_acc": 60.0}
{"epoch": 6, "training_loss": 209.03310546875, "training_acc": 50.0, "val_loss": 269.3689880371094, "val_acc": 60.0}
{"epoch": 7, "training_loss": 230.22505416870118, "training_acc": 60.0, "val_loss": 459.1852722167969, "val_acc": 40.0}
{"epoch": 8, "training_loss": 394.9659057617188, "training_acc": 50.0, "val_loss": 435.9683532714844, "val_acc": 40.0}
{"epoch": 9, "training_loss": 290.1051897525787, "training_acc": 55.0, "val_loss": 344.7517395019531, "val_acc": 60.0}
{"epoch": 10, "training_loss": 473.0461059570313, "training_acc": 50.0, "val_loss": 354.48077392578125, "val_acc": 60.0}
{"epoch": 11, "training_loss": 388.8703462600708, "training_acc": 50.0, "val_loss": 530.9918823242188, "val_acc": 40.0}
{"epoch": 12, "training_loss": 445.3031433105469, "training_acc": 50.0, "val_loss": 804.87255859375, "val_acc": 40.0}
{"epoch": 13, "training_loss": 627.1195251464844, "training_acc": 50.0, "val_loss": 133.0330047607422, "val_acc": 40.0}
{"epoch": 14, "training_loss": 168.68242797851562, "training_acc": 50.0, "val_loss": 584.552001953125, "val_acc": 60.0}
{"epoch": 15, "training_loss": 727.38466796875, "training_acc": 50.0, "val_loss": 462.2974548339844, "val_acc": 60.0}
{"epoch": 16, "training_loss": 432.9433959960937, "training_acc": 50.0, "val_loss": 547.0850219726562, "val_acc": 40.0}
{"epoch": 17, "training_loss": 528.11650390625, "training_acc": 50.0, "val_loss": 1262.044921875, "val_acc": 40.0}
{"epoch": 18, "training_loss": 1026.2659057617188, "training_acc": 50.0, "val_loss": 887.6550903320312, "val_acc": 40.0}
{"epoch": 19, "training_loss": 643.5682373046875, "training_acc": 50.0, "val_loss": 238.62413024902344, "val_acc": 60.0}
{"epoch": 20, "training_loss": 396.6014038085938, "training_acc": 50.0, "val_loss": 539.3478393554688, "val_acc": 60.0}
{"epoch": 21, "training_loss": 623.2171508789063, "training_acc": 50.0, "val_loss": 78.34932708740234, "val_acc": 60.0}
{"epoch": 22, "training_loss": 99.09131469726563, "training_acc": 60.0, "val_loss": 946.9089965820312, "val_acc": 40.0}
{"epoch": 23, "training_loss": 788.1688110351563, "training_acc": 50.0, "val_loss": 1046.588623046875, "val_acc": 40.0}
{"epoch": 24, "training_loss": 859.33359375, "training_acc": 50.0, "val_loss": 418.1454772949219, "val_acc": 40.0}
{"epoch": 25, "training_loss": 330.27259216308596, "training_acc": 40.0, "val_loss": 165.15896606445312, "val_acc": 60.0}
{"epoch": 26, "training_loss": 166.719677734375, "training_acc": 50.0, "val_loss": 375.6675720214844, "val_acc": 40.0}
{"epoch": 27, "training_loss": 342.7156066894531, "training_acc": 50.0, "val_loss": 615.5267333984375, "val_acc": 40.0}
{"epoch": 28, "training_loss": 461.547314453125, "training_acc": 50.0, "val_loss": 71.91215515136719, "val_acc": 60.0}
{"epoch": 29, "training_loss": 131.48836669921874, "training_acc": 50.0, "val_loss": 100.4419937133789, "val_acc": 60.0}
{"epoch": 30, "training_loss": 125.8504638671875, "training_acc": 50.0, "val_loss": 355.8240661621094, "val_acc": 40.0}
{"epoch": 31, "training_loss": 258.72529296875, "training_acc": 50.0, "val_loss": 95.72551727294922, "val_acc": 60.0}
{"epoch": 32, "training_loss": 123.46672973632812, "training_acc": 50.0, "val_loss": 45.5745964050293, "val_acc": 60.0}
{"epoch": 33, "training_loss": 56.40661773681641, "training_acc": 60.0, "val_loss": 489.7687072753906, "val_acc": 40.0}
{"epoch": 34, "training_loss": 389.56113891601564, "training_acc": 50.0, "val_loss": 127.77225494384766, "val_acc": 40.0}
{"epoch": 35, "training_loss": 98.7612060546875, "training_acc": 60.0, "val_loss": 447.3431091308594, "val_acc": 60.0}
{"epoch": 36, "training_loss": 562.2272216796875, "training_acc": 50.0, "val_loss": 286.7806091308594, "val_acc": 60.0}
{"epoch": 37, "training_loss": 246.13733596801757, "training_acc": 60.0, "val_loss": 382.6061096191406, "val_acc": 40.0}
{"epoch": 38, "training_loss": 333.75159912109376, "training_acc": 50.0, "val_loss": 155.3134307861328, "val_acc": 40.0}
{"epoch": 39, "training_loss": 195.4942626953125, "training_acc": 40.0, "val_loss": 341.3731384277344, "val_acc": 60.0}
{"epoch": 40, "training_loss": 385.08787841796874, "training_acc": 50.0, "val_loss": 46.79591369628906, "val_acc": 40.0}
{"epoch": 41, "training_loss": 83.83713989257812, "training_acc": 50.0, "val_loss": 62.52352523803711, "val_acc": 40.0}
{"epoch": 42, "training_loss": 50.558056640625, "training_acc": 60.0, "val_loss": 353.937255859375, "val_acc": 60.0}
{"epoch": 43, "training_loss": 423.2724609375, "training_acc": 50.0, "val_loss": 88.73052978515625, "val_acc": 60.0}
{"epoch": 44, "training_loss": 104.15409240722656, "training_acc": 60.0, "val_loss": 797.0548706054688, "val_acc": 40.0}
{"epoch": 45, "training_loss": 660.864990234375, "training_acc": 50.0, "val_loss": 736.5694580078125, "val_acc": 40.0}
{"epoch": 46, "training_loss": 569.2402847290039, "training_acc": 50.0, "val_loss": 117.6895980834961, "val_acc": 60.0}
{"epoch": 47, "training_loss": 167.6389953613281, "training_acc": 50.0, "val_loss": 213.1724853515625, "val_acc": 60.0}
{"epoch": 48, "training_loss": 201.12450103759767, "training_acc": 50.0, "val_loss": 494.4976501464844, "val_acc": 40.0}
{"epoch": 49, "training_loss": 440.3262939453125, "training_acc": 50.0, "val_loss": 663.0870361328125, "val_acc": 40.0}
{"epoch": 50, "training_loss": 490.1939697265625, "training_acc": 50.0, "val_loss": 87.97002410888672, "val_acc": 60.0}
{"epoch": 51, "training_loss": 130.32986450195312, "training_acc": 50.0, "val_loss": 191.81285095214844, "val_acc": 60.0}
