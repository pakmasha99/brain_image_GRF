"main_modify.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 2 --task ADNI_sex --input_option yAware --learning_rate 1e1 --batch_size 16 --weight_decay 5e-4 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 641.839226102829, "training_acc": 50.0, "val_loss": 789.2252807617188, "val_acc": 40.0}
{"epoch": 1, "training_loss": 734.625830078125, "training_acc": 50.0, "val_loss": 1339.0765380859375, "val_acc": 60.0}
{"epoch": 2, "training_loss": 1666.772314453125, "training_acc": 50.0, "val_loss": 921.25244140625, "val_acc": 60.0}
{"epoch": 3, "training_loss": 923.992822265625, "training_acc": 50.0, "val_loss": 842.966796875, "val_acc": 40.0}
{"epoch": 4, "training_loss": 820.15595703125, "training_acc": 50.0, "val_loss": 1808.8199462890625, "val_acc": 40.0}
{"epoch": 5, "training_loss": 1476.43076171875, "training_acc": 50.0, "val_loss": 1128.2210693359375, "val_acc": 40.0}
{"epoch": 6, "training_loss": 864.8085784912109, "training_acc": 50.0, "val_loss": 425.82647705078125, "val_acc": 60.0}
{"epoch": 7, "training_loss": 615.6712158203125, "training_acc": 50.0, "val_loss": 855.4620971679688, "val_acc": 60.0}
{"epoch": 8, "training_loss": 1035.3741455078125, "training_acc": 50.0, "val_loss": 413.2783203125, "val_acc": 60.0}
{"epoch": 9, "training_loss": 369.5518226623535, "training_acc": 60.0, "val_loss": 605.7623291015625, "val_acc": 40.0}
{"epoch": 10, "training_loss": 531.1197143554688, "training_acc": 50.0, "val_loss": 672.7826538085938, "val_acc": 40.0}
{"epoch": 11, "training_loss": 454.3840087890625, "training_acc": 50.0, "val_loss": 263.5125427246094, "val_acc": 60.0}
{"epoch": 12, "training_loss": 362.75440673828126, "training_acc": 50.0, "val_loss": 682.806396484375, "val_acc": 60.0}
{"epoch": 13, "training_loss": 846.6813171386718, "training_acc": 50.0, "val_loss": 496.2828063964844, "val_acc": 60.0}
{"epoch": 14, "training_loss": 495.18970947265626, "training_acc": 50.0, "val_loss": 434.14923095703125, "val_acc": 40.0}
{"epoch": 15, "training_loss": 438.1938110351563, "training_acc": 50.0, "val_loss": 1107.410888671875, "val_acc": 40.0}
{"epoch": 16, "training_loss": 905.3744873046875, "training_acc": 50.0, "val_loss": 724.2913818359375, "val_acc": 40.0}
{"epoch": 17, "training_loss": 474.6643493652344, "training_acc": 50.0, "val_loss": 372.4122619628906, "val_acc": 60.0}
{"epoch": 18, "training_loss": 502.305615234375, "training_acc": 50.0, "val_loss": 855.0780639648438, "val_acc": 60.0}
{"epoch": 19, "training_loss": 1066.195166015625, "training_acc": 50.0, "val_loss": 747.2692260742188, "val_acc": 60.0}
{"epoch": 20, "training_loss": 932.9611328125, "training_acc": 50.0, "val_loss": 200.396728515625, "val_acc": 60.0}
{"epoch": 21, "training_loss": 245.73170166015626, "training_acc": 50.0, "val_loss": 584.9686889648438, "val_acc": 40.0}
{"epoch": 22, "training_loss": 484.00224609375, "training_acc": 50.0, "val_loss": 380.8888854980469, "val_acc": 40.0}
{"epoch": 23, "training_loss": 305.1206359863281, "training_acc": 40.0, "val_loss": 100.95696258544922, "val_acc": 60.0}
{"epoch": 24, "training_loss": 105.18721466064453, "training_acc": 50.0, "val_loss": 27.426084518432617, "val_acc": 60.0}
{"epoch": 25, "training_loss": 94.08257751464843, "training_acc": 30.0, "val_loss": 47.05067825317383, "val_acc": 60.0}
{"epoch": 26, "training_loss": 59.935488891601565, "training_acc": 50.0, "val_loss": 152.47564697265625, "val_acc": 40.0}
{"epoch": 27, "training_loss": 115.90197677612305, "training_acc": 50.0, "val_loss": 43.46792221069336, "val_acc": 60.0}
{"epoch": 28, "training_loss": 40.278554916381836, "training_acc": 50.0, "val_loss": 386.62750244140625, "val_acc": 40.0}
{"epoch": 29, "training_loss": 316.79755859375, "training_acc": 50.0, "val_loss": 515.0504150390625, "val_acc": 40.0}
{"epoch": 30, "training_loss": 405.2178237915039, "training_acc": 50.0, "val_loss": 1.7556358575820923, "val_acc": 80.0}
{"epoch": 31, "training_loss": 42.31920738220215, "training_acc": 65.0, "val_loss": 41.76203536987305, "val_acc": 40.0}
{"epoch": 32, "training_loss": 24.327501678466795, "training_acc": 50.0, "val_loss": 226.16470336914062, "val_acc": 60.0}
{"epoch": 33, "training_loss": 298.4920654296875, "training_acc": 50.0, "val_loss": 188.9065399169922, "val_acc": 60.0}
{"epoch": 34, "training_loss": 202.3190071105957, "training_acc": 50.0, "val_loss": 185.41329956054688, "val_acc": 40.0}
{"epoch": 35, "training_loss": 124.64616508483887, "training_acc": 50.0, "val_loss": 216.5028076171875, "val_acc": 60.0}
{"epoch": 36, "training_loss": 273.85264282226564, "training_acc": 50.0, "val_loss": 217.71597290039062, "val_acc": 60.0}
{"epoch": 37, "training_loss": 221.71480140686035, "training_acc": 50.0, "val_loss": 469.2210998535156, "val_acc": 40.0}
{"epoch": 38, "training_loss": 474.1003173828125, "training_acc": 50.0, "val_loss": 516.4405517578125, "val_acc": 40.0}
{"epoch": 39, "training_loss": 385.9489322662354, "training_acc": 50.0, "val_loss": 329.7272033691406, "val_acc": 60.0}
{"epoch": 40, "training_loss": 432.7939086914063, "training_acc": 50.0, "val_loss": 533.2696533203125, "val_acc": 60.0}
{"epoch": 41, "training_loss": 632.3223999023437, "training_acc": 50.0, "val_loss": 123.41104888916016, "val_acc": 60.0}
{"epoch": 42, "training_loss": 203.65590209960936, "training_acc": 50.0, "val_loss": 842.1602783203125, "val_acc": 40.0}
{"epoch": 43, "training_loss": 709.7101684570313, "training_acc": 50.0, "val_loss": 771.1228637695312, "val_acc": 40.0}
{"epoch": 44, "training_loss": 602.4173126220703, "training_acc": 50.0, "val_loss": 85.60939025878906, "val_acc": 60.0}
{"epoch": 45, "training_loss": 166.06760864257814, "training_acc": 50.0, "val_loss": 143.6865692138672, "val_acc": 60.0}
{"epoch": 46, "training_loss": 167.5904327392578, "training_acc": 50.0, "val_loss": 245.889892578125, "val_acc": 40.0}
{"epoch": 47, "training_loss": 168.92568359375, "training_acc": 50.0, "val_loss": 224.25071716308594, "val_acc": 60.0}
{"epoch": 48, "training_loss": 331.0593017578125, "training_acc": 50.0, "val_loss": 252.65283203125, "val_acc": 60.0}
{"epoch": 49, "training_loss": 226.6577220916748, "training_acc": 50.0, "val_loss": 650.7191772460938, "val_acc": 40.0}
