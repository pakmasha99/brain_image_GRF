"main_modify.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 3 --task ADNI_sex --input_option yAware --learning_rate 1e1 --batch_size 16 --weight_decay 5e-4 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 856.2662284374237, "training_acc": 55.0, "val_loss": 833.9216918945312, "val_acc": 40.0}
{"epoch": 1, "training_loss": 829.4271484375, "training_acc": 45.0, "val_loss": 1053.7406005859375, "val_acc": 60.0}
{"epoch": 2, "training_loss": 1427.8717041015625, "training_acc": 45.0, "val_loss": 640.63232421875, "val_acc": 60.0}
{"epoch": 3, "training_loss": 809.9289695739747, "training_acc": 45.0, "val_loss": 769.57177734375, "val_acc": 40.0}
{"epoch": 4, "training_loss": 652.282958984375, "training_acc": 55.0, "val_loss": 1268.5208740234375, "val_acc": 40.0}
{"epoch": 5, "training_loss": 895.242431640625, "training_acc": 55.0, "val_loss": 395.0892639160156, "val_acc": 40.0}
{"epoch": 6, "training_loss": 162.33616943359374, "training_acc": 75.0, "val_loss": 720.1381225585938, "val_acc": 60.0}
{"epoch": 7, "training_loss": 984.74326171875, "training_acc": 45.0, "val_loss": 962.1449584960938, "val_acc": 60.0}
{"epoch": 8, "training_loss": 1287.741943359375, "training_acc": 45.0, "val_loss": 546.8876953125, "val_acc": 60.0}
{"epoch": 9, "training_loss": 629.4567474365234, "training_acc": 45.0, "val_loss": 784.89013671875, "val_acc": 40.0}
{"epoch": 10, "training_loss": 733.8755859375, "training_acc": 55.0, "val_loss": 1510.8826904296875, "val_acc": 40.0}
{"epoch": 11, "training_loss": 1119.0946411132813, "training_acc": 55.0, "val_loss": 1080.8834228515625, "val_acc": 40.0}
{"epoch": 12, "training_loss": 806.375439453125, "training_acc": 55.0, "val_loss": 46.86967086791992, "val_acc": 40.0}
{"epoch": 13, "training_loss": 189.61575317382812, "training_acc": 45.0, "val_loss": 593.8375854492188, "val_acc": 60.0}
{"epoch": 14, "training_loss": 805.8099365234375, "training_acc": 45.0, "val_loss": 249.6264190673828, "val_acc": 60.0}
{"epoch": 15, "training_loss": 268.3128463745117, "training_acc": 55.0, "val_loss": 824.4527587890625, "val_acc": 40.0}
{"epoch": 16, "training_loss": 649.9303466796875, "training_acc": 55.0, "val_loss": 1032.0272216796875, "val_acc": 40.0}
{"epoch": 17, "training_loss": 712.89970703125, "training_acc": 55.0, "val_loss": 259.92266845703125, "val_acc": 40.0}
{"epoch": 18, "training_loss": 283.8310180664063, "training_acc": 45.0, "val_loss": 523.7388916015625, "val_acc": 60.0}
{"epoch": 19, "training_loss": 715.0793212890625, "training_acc": 45.0, "val_loss": 364.51611328125, "val_acc": 60.0}
{"epoch": 20, "training_loss": 411.08357696533204, "training_acc": 45.0, "val_loss": 609.5386352539062, "val_acc": 40.0}
{"epoch": 21, "training_loss": 556.2287841796875, "training_acc": 55.0, "val_loss": 1061.0916748046875, "val_acc": 40.0}
{"epoch": 22, "training_loss": 749.0998779296875, "training_acc": 55.0, "val_loss": 406.4496765136719, "val_acc": 40.0}
{"epoch": 23, "training_loss": 212.6329116821289, "training_acc": 65.0, "val_loss": 445.93194580078125, "val_acc": 60.0}
{"epoch": 24, "training_loss": 623.1345703125, "training_acc": 45.0, "val_loss": 458.84307861328125, "val_acc": 60.0}
{"epoch": 25, "training_loss": 560.3103179931641, "training_acc": 45.0, "val_loss": 258.2311096191406, "val_acc": 40.0}
{"epoch": 26, "training_loss": 233.9605712890625, "training_acc": 55.0, "val_loss": 604.378662109375, "val_acc": 40.0}
{"epoch": 27, "training_loss": 406.6702392578125, "training_acc": 55.0, "val_loss": 19.054367065429688, "val_acc": 60.0}
{"epoch": 28, "training_loss": 14.870625305175782, "training_acc": 50.0, "val_loss": 196.94378662109375, "val_acc": 60.0}
{"epoch": 29, "training_loss": 229.0195068359375, "training_acc": 45.0, "val_loss": 295.51593017578125, "val_acc": 40.0}
{"epoch": 30, "training_loss": 249.12920532226562, "training_acc": 55.0, "val_loss": 461.8490295410156, "val_acc": 40.0}
{"epoch": 31, "training_loss": 278.3437194824219, "training_acc": 55.0, "val_loss": 208.5392303466797, "val_acc": 60.0}
{"epoch": 32, "training_loss": 315.16990966796874, "training_acc": 45.0, "val_loss": 343.9169616699219, "val_acc": 60.0}
{"epoch": 33, "training_loss": 384.6140991210938, "training_acc": 45.0, "val_loss": 390.181884765625, "val_acc": 40.0}
{"epoch": 34, "training_loss": 349.24345703125, "training_acc": 55.0, "val_loss": 917.12158203125, "val_acc": 40.0}
{"epoch": 35, "training_loss": 660.9314697265625, "training_acc": 55.0, "val_loss": 502.06744384765625, "val_acc": 40.0}
{"epoch": 36, "training_loss": 321.95881071090696, "training_acc": 50.0, "val_loss": 174.0690155029297, "val_acc": 60.0}
{"epoch": 37, "training_loss": 220.53162231445313, "training_acc": 45.0, "val_loss": 65.94544982910156, "val_acc": 40.0}
{"epoch": 38, "training_loss": 44.11448974609375, "training_acc": 55.0, "val_loss": 54.252479553222656, "val_acc": 60.0}
{"epoch": 39, "training_loss": 46.691022109985354, "training_acc": 50.0, "val_loss": 208.023193359375, "val_acc": 40.0}
{"epoch": 40, "training_loss": 138.2445861816406, "training_acc": 55.0, "val_loss": 52.0975341796875, "val_acc": 60.0}
{"epoch": 41, "training_loss": 53.62489318847656, "training_acc": 45.0, "val_loss": 217.33042907714844, "val_acc": 40.0}
{"epoch": 42, "training_loss": 149.59833221435548, "training_acc": 55.0, "val_loss": 99.49327087402344, "val_acc": 40.0}
{"epoch": 43, "training_loss": 80.64855346679687, "training_acc": 55.0, "val_loss": 174.14109802246094, "val_acc": 60.0}
{"epoch": 44, "training_loss": 177.56672210693358, "training_acc": 45.0, "val_loss": 472.06866455078125, "val_acc": 40.0}
{"epoch": 45, "training_loss": 388.99326171875, "training_acc": 55.0, "val_loss": 749.2218627929688, "val_acc": 40.0}
{"epoch": 46, "training_loss": 529.6099304199219, "training_acc": 55.0, "val_loss": 175.560791015625, "val_acc": 40.0}
