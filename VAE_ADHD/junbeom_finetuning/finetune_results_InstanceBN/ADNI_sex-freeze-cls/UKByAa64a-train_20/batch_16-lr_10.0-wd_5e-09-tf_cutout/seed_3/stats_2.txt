"main_modify.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 3 --task ADNI_sex --input_option yAware --learning_rate 1e1 --batch_size 16 --weight_decay 5e-9 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 428.7998945236206, "training_acc": 50.0, "val_loss": 982.0296020507812, "val_acc": 40.0}
{"epoch": 1, "training_loss": 1000.06435546875, "training_acc": 40.0, "val_loss": 788.853271484375, "val_acc": 60.0}
{"epoch": 2, "training_loss": 940.8733520507812, "training_acc": 50.0, "val_loss": 108.5429916381836, "val_acc": 40.0}
{"epoch": 3, "training_loss": 130.66962890625, "training_acc": 50.0, "val_loss": 142.16229248046875, "val_acc": 60.0}
{"epoch": 4, "training_loss": 184.32909545898437, "training_acc": 50.0, "val_loss": 109.20745086669922, "val_acc": 40.0}
{"epoch": 5, "training_loss": 77.6365951538086, "training_acc": 50.0, "val_loss": 216.16201782226562, "val_acc": 60.0}
{"epoch": 6, "training_loss": 275.26829223632814, "training_acc": 50.0, "val_loss": 8.174897193908691, "val_acc": 60.0}
{"epoch": 7, "training_loss": 161.95926055908203, "training_acc": 40.0, "val_loss": 690.7818603515625, "val_acc": 40.0}
{"epoch": 8, "training_loss": 545.2704956054688, "training_acc": 50.0, "val_loss": 91.84587860107422, "val_acc": 40.0}
{"epoch": 9, "training_loss": 87.524462890625, "training_acc": 60.0, "val_loss": 557.5003051757812, "val_acc": 60.0}
{"epoch": 10, "training_loss": 726.7884765625, "training_acc": 50.0, "val_loss": 392.5142517089844, "val_acc": 60.0}
{"epoch": 11, "training_loss": 366.5484161376953, "training_acc": 50.0, "val_loss": 789.0211181640625, "val_acc": 40.0}
{"epoch": 12, "training_loss": 781.5841796875, "training_acc": 50.0, "val_loss": 1422.552734375, "val_acc": 40.0}
{"epoch": 13, "training_loss": 1142.7694580078125, "training_acc": 50.0, "val_loss": 848.81201171875, "val_acc": 40.0}
{"epoch": 14, "training_loss": 548.1029052734375, "training_acc": 50.0, "val_loss": 404.18853759765625, "val_acc": 60.0}
{"epoch": 15, "training_loss": 560.9552978515625, "training_acc": 50.0, "val_loss": 978.0470581054688, "val_acc": 60.0}
{"epoch": 16, "training_loss": 1258.807177734375, "training_acc": 50.0, "val_loss": 850.6082153320312, "val_acc": 60.0}
{"epoch": 17, "training_loss": 1030.222149658203, "training_acc": 50.0, "val_loss": 97.47692108154297, "val_acc": 60.0}
{"epoch": 18, "training_loss": 284.120751953125, "training_acc": 40.0, "val_loss": 1010.8843994140625, "val_acc": 40.0}
{"epoch": 19, "training_loss": 850.5752685546875, "training_acc": 50.0, "val_loss": 871.7120361328125, "val_acc": 40.0}
{"epoch": 20, "training_loss": 661.9034454345704, "training_acc": 50.0, "val_loss": 116.9654541015625, "val_acc": 60.0}
{"epoch": 21, "training_loss": 183.6570068359375, "training_acc": 50.0, "val_loss": 344.86669921875, "val_acc": 60.0}
{"epoch": 22, "training_loss": 421.09873046875, "training_acc": 50.0, "val_loss": 5.302174091339111, "val_acc": 80.0}
{"epoch": 23, "training_loss": 74.66724853515625, "training_acc": 60.0, "val_loss": 623.6256103515625, "val_acc": 40.0}
{"epoch": 24, "training_loss": 475.15703125, "training_acc": 50.0, "val_loss": 149.5934600830078, "val_acc": 40.0}
{"epoch": 25, "training_loss": 98.89382934570312, "training_acc": 60.0, "val_loss": 552.8171997070312, "val_acc": 60.0}
{"epoch": 26, "training_loss": 750.0116455078125, "training_acc": 50.0, "val_loss": 505.93701171875, "val_acc": 60.0}
{"epoch": 27, "training_loss": 576.123291015625, "training_acc": 50.0, "val_loss": 312.4248962402344, "val_acc": 40.0}
{"epoch": 28, "training_loss": 246.59139709472657, "training_acc": 50.0, "val_loss": 773.6532592773438, "val_acc": 40.0}
{"epoch": 29, "training_loss": 592.8250732421875, "training_acc": 50.0, "val_loss": 215.3651885986328, "val_acc": 40.0}
{"epoch": 30, "training_loss": 140.5919219970703, "training_acc": 60.0, "val_loss": 621.01611328125, "val_acc": 60.0}
{"epoch": 31, "training_loss": 854.624462890625, "training_acc": 50.0, "val_loss": 672.97314453125, "val_acc": 60.0}
{"epoch": 32, "training_loss": 796.6054321289063, "training_acc": 50.0, "val_loss": 32.15953826904297, "val_acc": 60.0}
{"epoch": 33, "training_loss": 219.685107421875, "training_acc": 40.0, "val_loss": 1072.5162353515625, "val_acc": 40.0}
{"epoch": 34, "training_loss": 865.246630859375, "training_acc": 50.0, "val_loss": 981.8448486328125, "val_acc": 40.0}
{"epoch": 35, "training_loss": 682.5678833007812, "training_acc": 50.0, "val_loss": 21.35019302368164, "val_acc": 60.0}
{"epoch": 36, "training_loss": 110.8697509765625, "training_acc": 50.0, "val_loss": 335.8916931152344, "val_acc": 60.0}
{"epoch": 37, "training_loss": 417.5818664550781, "training_acc": 50.0, "val_loss": 8.601534843444824, "val_acc": 80.0}
{"epoch": 38, "training_loss": 30.64313621520996, "training_acc": 75.0, "val_loss": 631.9437866210938, "val_acc": 40.0}
{"epoch": 39, "training_loss": 486.0438232421875, "training_acc": 50.0, "val_loss": 283.64483642578125, "val_acc": 40.0}
{"epoch": 40, "training_loss": 150.68122253417968, "training_acc": 60.0, "val_loss": 384.5249938964844, "val_acc": 60.0}
{"epoch": 41, "training_loss": 516.7324340820312, "training_acc": 50.0, "val_loss": 324.9599609375, "val_acc": 60.0}
