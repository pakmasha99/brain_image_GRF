"main_modify.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 3 --task ADNI_sex --input_option yAware --learning_rate 1e1 --batch_size 16 --weight_decay 5e-9 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 642.2970999717712, "training_acc": 40.0, "val_loss": 712.3532104492188, "val_acc": 60.0}
{"epoch": 1, "training_loss": 842.894921875, "training_acc": 50.0, "val_loss": 1425.372314453125, "val_acc": 40.0}
{"epoch": 2, "training_loss": 1170.387451171875, "training_acc": 50.0, "val_loss": 671.2127075195312, "val_acc": 40.0}
{"epoch": 3, "training_loss": 415.13634796142577, "training_acc": 60.0, "val_loss": 573.2205200195312, "val_acc": 60.0}
{"epoch": 4, "training_loss": 724.68369140625, "training_acc": 50.0, "val_loss": 367.9281311035156, "val_acc": 60.0}
{"epoch": 5, "training_loss": 329.17228240966796, "training_acc": 60.0, "val_loss": 480.4593811035156, "val_acc": 40.0}
{"epoch": 6, "training_loss": 395.73460693359374, "training_acc": 50.0, "val_loss": 63.45144271850586, "val_acc": 40.0}
{"epoch": 7, "training_loss": 84.8928436279297, "training_acc": 60.0, "val_loss": 645.8241577148438, "val_acc": 60.0}
{"epoch": 8, "training_loss": 820.4775634765625, "training_acc": 50.0, "val_loss": 400.6598815917969, "val_acc": 60.0}
{"epoch": 9, "training_loss": 413.64413299560545, "training_acc": 50.0, "val_loss": 372.84576416015625, "val_acc": 40.0}
{"epoch": 10, "training_loss": 306.32378845214845, "training_acc": 50.0, "val_loss": 92.6790542602539, "val_acc": 40.0}
{"epoch": 11, "training_loss": 84.60519409179688, "training_acc": 60.0, "val_loss": 398.9609680175781, "val_acc": 60.0}
{"epoch": 12, "training_loss": 490.04005126953126, "training_acc": 50.0, "val_loss": 168.81883239746094, "val_acc": 60.0}
{"epoch": 13, "training_loss": 126.5279052734375, "training_acc": 70.0, "val_loss": 563.7076416015625, "val_acc": 40.0}
{"epoch": 14, "training_loss": 476.57757263183595, "training_acc": 50.0, "val_loss": 458.5412292480469, "val_acc": 40.0}
{"epoch": 15, "training_loss": 318.8725242614746, "training_acc": 50.0, "val_loss": 389.82745361328125, "val_acc": 60.0}
{"epoch": 16, "training_loss": 508.52736206054686, "training_acc": 50.0, "val_loss": 621.9879760742188, "val_acc": 60.0}
{"epoch": 17, "training_loss": 732.2638427734375, "training_acc": 50.0, "val_loss": 121.62141418457031, "val_acc": 60.0}
{"epoch": 18, "training_loss": 219.4672119140625, "training_acc": 50.0, "val_loss": 1020.8474731445312, "val_acc": 40.0}
{"epoch": 19, "training_loss": 875.226123046875, "training_acc": 50.0, "val_loss": 952.7865600585938, "val_acc": 40.0}
{"epoch": 20, "training_loss": 730.4216918945312, "training_acc": 50.0, "val_loss": 79.80109405517578, "val_acc": 60.0}
{"epoch": 21, "training_loss": 192.5965576171875, "training_acc": 50.0, "val_loss": 258.92645263671875, "val_acc": 60.0}
{"epoch": 22, "training_loss": 293.559326171875, "training_acc": 55.0, "val_loss": 310.13330078125, "val_acc": 40.0}
{"epoch": 23, "training_loss": 271.6416015625, "training_acc": 50.0, "val_loss": 117.34281158447266, "val_acc": 40.0}
{"epoch": 24, "training_loss": 141.041943359375, "training_acc": 50.0, "val_loss": 324.84942626953125, "val_acc": 60.0}
{"epoch": 25, "training_loss": 387.2275146484375, "training_acc": 50.0, "val_loss": 46.9867057800293, "val_acc": 40.0}
{"epoch": 26, "training_loss": 75.74593505859374, "training_acc": 50.0, "val_loss": 95.9906234741211, "val_acc": 40.0}
{"epoch": 27, "training_loss": 146.7341796875, "training_acc": 40.0, "val_loss": 151.4989013671875, "val_acc": 60.0}
{"epoch": 28, "training_loss": 185.41637268066407, "training_acc": 40.0, "val_loss": 5.110151290893555, "val_acc": 80.0}
{"epoch": 29, "training_loss": 31.591990661621093, "training_acc": 55.0, "val_loss": 124.19142150878906, "val_acc": 60.0}
{"epoch": 30, "training_loss": 159.84253997802733, "training_acc": 50.0, "val_loss": 9.156128883361816, "val_acc": 80.0}
{"epoch": 31, "training_loss": 34.00585098266602, "training_acc": 65.0, "val_loss": 430.0927429199219, "val_acc": 40.0}
{"epoch": 32, "training_loss": 356.7896362304688, "training_acc": 50.0, "val_loss": 31.575565338134766, "val_acc": 40.0}
{"epoch": 33, "training_loss": 108.36026000976562, "training_acc": 50.0, "val_loss": 390.359619140625, "val_acc": 60.0}
{"epoch": 34, "training_loss": 492.211572265625, "training_acc": 50.0, "val_loss": 185.228271484375, "val_acc": 60.0}
{"epoch": 35, "training_loss": 208.8576416015625, "training_acc": 50.0, "val_loss": 144.80650329589844, "val_acc": 40.0}
{"epoch": 36, "training_loss": 111.866015625, "training_acc": 60.0, "val_loss": 89.17138671875, "val_acc": 60.0}
{"epoch": 37, "training_loss": 96.17514095306396, "training_acc": 50.0, "val_loss": 285.1133117675781, "val_acc": 40.0}
{"epoch": 38, "training_loss": 252.97413330078126, "training_acc": 50.0, "val_loss": 216.77207946777344, "val_acc": 40.0}
{"epoch": 39, "training_loss": 132.718927192688, "training_acc": 60.0, "val_loss": 132.46543884277344, "val_acc": 60.0}
{"epoch": 40, "training_loss": 149.7973846435547, "training_acc": 50.0, "val_loss": 297.33599853515625, "val_acc": 40.0}
{"epoch": 41, "training_loss": 262.38251953125, "training_acc": 50.0, "val_loss": 482.98974609375, "val_acc": 40.0}
{"epoch": 42, "training_loss": 390.9358154296875, "training_acc": 50.0, "val_loss": 38.31919860839844, "val_acc": 60.0}
{"epoch": 43, "training_loss": 72.3696044921875, "training_acc": 50.0, "val_loss": 16.432157516479492, "val_acc": 80.0}
{"epoch": 44, "training_loss": 83.44736175537109, "training_acc": 55.0, "val_loss": 152.26853942871094, "val_acc": 40.0}
{"epoch": 45, "training_loss": 133.07017364501954, "training_acc": 50.0, "val_loss": 109.45256805419922, "val_acc": 60.0}
{"epoch": 46, "training_loss": 115.60171432495117, "training_acc": 50.0, "val_loss": 178.48635864257812, "val_acc": 40.0}
{"epoch": 47, "training_loss": 157.62855529785156, "training_acc": 50.0, "val_loss": 157.30616760253906, "val_acc": 60.0}
