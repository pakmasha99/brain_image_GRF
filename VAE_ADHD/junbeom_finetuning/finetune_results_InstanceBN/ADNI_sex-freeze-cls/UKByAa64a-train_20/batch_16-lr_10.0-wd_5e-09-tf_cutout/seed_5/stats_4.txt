"main_modify.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 5 --task ADNI_sex --input_option yAware --learning_rate 1e1 --batch_size 16 --weight_decay 5e-9 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 214.02925968170166, "training_acc": 60.0, "val_loss": 614.708984375, "val_acc": 60.0}
{"epoch": 1, "training_loss": 460.0671875, "training_acc": 70.0, "val_loss": 2839.805419921875, "val_acc": 40.0}
{"epoch": 2, "training_loss": 2350.187353515625, "training_acc": 50.0, "val_loss": 2048.110595703125, "val_acc": 40.0}
{"epoch": 3, "training_loss": 1515.1786987304688, "training_acc": 50.0, "val_loss": 400.1321716308594, "val_acc": 60.0}
{"epoch": 4, "training_loss": 546.7035888671875, "training_acc": 50.0, "val_loss": 947.5236206054688, "val_acc": 60.0}
{"epoch": 5, "training_loss": 1155.3118103027343, "training_acc": 50.0, "val_loss": 389.65521240234375, "val_acc": 60.0}
{"epoch": 6, "training_loss": 358.89440002441404, "training_acc": 60.0, "val_loss": 750.7123413085938, "val_acc": 40.0}
{"epoch": 7, "training_loss": 626.473974609375, "training_acc": 50.0, "val_loss": 418.48468017578125, "val_acc": 40.0}
{"epoch": 8, "training_loss": 204.94423828125, "training_acc": 70.0, "val_loss": 496.310546875, "val_acc": 60.0}
{"epoch": 9, "training_loss": 655.275732421875, "training_acc": 50.0, "val_loss": 336.83477783203125, "val_acc": 60.0}
{"epoch": 10, "training_loss": 428.3599914550781, "training_acc": 40.0, "val_loss": 355.6991882324219, "val_acc": 40.0}
{"epoch": 11, "training_loss": 257.06235961914064, "training_acc": 50.0, "val_loss": 212.2823486328125, "val_acc": 60.0}
{"epoch": 12, "training_loss": 261.8614013671875, "training_acc": 50.0, "val_loss": 269.6726989746094, "val_acc": 60.0}
{"epoch": 13, "training_loss": 306.6305061340332, "training_acc": 50.0, "val_loss": 318.3371276855469, "val_acc": 40.0}
{"epoch": 14, "training_loss": 309.0244384765625, "training_acc": 50.0, "val_loss": 39.884361267089844, "val_acc": 40.0}
{"epoch": 15, "training_loss": 122.94398956298828, "training_acc": 50.0, "val_loss": 631.1954345703125, "val_acc": 60.0}
{"epoch": 16, "training_loss": 795.38623046875, "training_acc": 50.0, "val_loss": 415.14532470703125, "val_acc": 60.0}
{"epoch": 17, "training_loss": 412.56836261749265, "training_acc": 55.0, "val_loss": 668.7166137695312, "val_acc": 40.0}
{"epoch": 18, "training_loss": 643.4047119140625, "training_acc": 50.0, "val_loss": 994.2169799804688, "val_acc": 40.0}
{"epoch": 19, "training_loss": 746.074609375, "training_acc": 50.0, "val_loss": 62.124610900878906, "val_acc": 40.0}
{"epoch": 20, "training_loss": 237.55325317382812, "training_acc": 40.0, "val_loss": 798.4262084960938, "val_acc": 60.0}
{"epoch": 21, "training_loss": 1005.961328125, "training_acc": 50.0, "val_loss": 745.8736572265625, "val_acc": 60.0}
{"epoch": 22, "training_loss": 856.6174438476562, "training_acc": 50.0, "val_loss": 56.30457305908203, "val_acc": 60.0}
{"epoch": 23, "training_loss": 241.56185913085938, "training_acc": 40.0, "val_loss": 1136.03466796875, "val_acc": 40.0}
{"epoch": 24, "training_loss": 947.8125854492188, "training_acc": 50.0, "val_loss": 1048.177978515625, "val_acc": 40.0}
{"epoch": 25, "training_loss": 763.85029296875, "training_acc": 50.0, "val_loss": 24.81351089477539, "val_acc": 60.0}
{"epoch": 26, "training_loss": 51.803469848632815, "training_acc": 50.0, "val_loss": 396.1971740722656, "val_acc": 60.0}
{"epoch": 27, "training_loss": 473.66588134765624, "training_acc": 50.0, "val_loss": 140.45700073242188, "val_acc": 60.0}
{"epoch": 28, "training_loss": 182.5876220703125, "training_acc": 50.0, "val_loss": 548.9271850585938, "val_acc": 40.0}
{"epoch": 29, "training_loss": 431.5920166015625, "training_acc": 50.0, "val_loss": 278.76495361328125, "val_acc": 40.0}
{"epoch": 30, "training_loss": 152.32143020629883, "training_acc": 60.0, "val_loss": 232.7539520263672, "val_acc": 60.0}
{"epoch": 31, "training_loss": 276.6827392578125, "training_acc": 50.0, "val_loss": 51.96113204956055, "val_acc": 60.0}
{"epoch": 32, "training_loss": 99.14826049804688, "training_acc": 50.0, "val_loss": 484.2810974121094, "val_acc": 40.0}
{"epoch": 33, "training_loss": 357.8486328125, "training_acc": 50.0, "val_loss": 20.362211227416992, "val_acc": 40.0}
{"epoch": 34, "training_loss": 46.97123413085937, "training_acc": 50.0, "val_loss": 129.70822143554688, "val_acc": 40.0}
{"epoch": 35, "training_loss": 80.27985954284668, "training_acc": 50.0, "val_loss": 47.12815475463867, "val_acc": 60.0}
{"epoch": 36, "training_loss": 56.5572006225586, "training_acc": 40.0, "val_loss": 122.10832977294922, "val_acc": 60.0}
{"epoch": 37, "training_loss": 146.57242431640626, "training_acc": 50.0, "val_loss": 177.0338134765625, "val_acc": 40.0}
{"epoch": 38, "training_loss": 147.75363159179688, "training_acc": 50.0, "val_loss": 20.896989822387695, "val_acc": 40.0}
{"epoch": 39, "training_loss": 71.56335477828979, "training_acc": 75.0, "val_loss": 133.5544891357422, "val_acc": 60.0}
{"epoch": 40, "training_loss": 143.4836212158203, "training_acc": 50.0, "val_loss": 185.88217163085938, "val_acc": 40.0}
{"epoch": 41, "training_loss": 106.21109218597412, "training_acc": 55.0, "val_loss": 48.9208984375, "val_acc": 60.0}
{"epoch": 42, "training_loss": 54.34695281982422, "training_acc": 50.0, "val_loss": 53.898067474365234, "val_acc": 40.0}
{"epoch": 43, "training_loss": 42.9968765258789, "training_acc": 55.0, "val_loss": 163.14601135253906, "val_acc": 60.0}
{"epoch": 44, "training_loss": 138.60245685577394, "training_acc": 60.0, "val_loss": 281.5992126464844, "val_acc": 40.0}
{"epoch": 45, "training_loss": 208.07232971191405, "training_acc": 50.0, "val_loss": 157.91830444335938, "val_acc": 40.0}
{"epoch": 46, "training_loss": 151.375732421875, "training_acc": 40.0, "val_loss": 144.37376403808594, "val_acc": 60.0}
{"epoch": 47, "training_loss": 168.7953887939453, "training_acc": 40.0, "val_loss": 25.158109664916992, "val_acc": 60.0}
{"epoch": 48, "training_loss": 14.954645538330078, "training_acc": 60.0, "val_loss": 60.87917709350586, "val_acc": 60.0}
{"epoch": 49, "training_loss": 58.11208534240723, "training_acc": 50.0, "val_loss": 34.43897247314453, "val_acc": 40.0}
{"epoch": 50, "training_loss": 7.612601470947266, "training_acc": 75.0, "val_loss": 57.8302116394043, "val_acc": 60.0}
{"epoch": 51, "training_loss": 68.48353424072266, "training_acc": 50.0, "val_loss": 153.13873291015625, "val_acc": 40.0}
{"epoch": 52, "training_loss": 120.06121826171875, "training_acc": 40.0, "val_loss": 29.900390625, "val_acc": 40.0}
