"main_modify.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 2 --task ADNI_sex --input_option yAware --learning_rate 1e1 --batch_size 16 --weight_decay 5e-9 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 428.576068687439, "training_acc": 50.0, "val_loss": 572.9990234375, "val_acc": 60.0}
{"epoch": 1, "training_loss": 955.928515625, "training_acc": 40.0, "val_loss": 1405.4598388671875, "val_acc": 40.0}
{"epoch": 2, "training_loss": 1096.4361572265625, "training_acc": 50.0, "val_loss": 49.73896026611328, "val_acc": 40.0}
{"epoch": 3, "training_loss": 224.1657928466797, "training_acc": 50.0, "val_loss": 1137.9713134765625, "val_acc": 60.0}
{"epoch": 4, "training_loss": 1452.59384765625, "training_acc": 50.0, "val_loss": 909.7886962890625, "val_acc": 60.0}
{"epoch": 5, "training_loss": 962.06962890625, "training_acc": 50.0, "val_loss": 406.1038513183594, "val_acc": 40.0}
{"epoch": 6, "training_loss": 386.44736938476564, "training_acc": 50.0, "val_loss": 1337.9840087890625, "val_acc": 40.0}
{"epoch": 7, "training_loss": 1112.4215454101563, "training_acc": 50.0, "val_loss": 1143.682373046875, "val_acc": 40.0}
{"epoch": 8, "training_loss": 915.5179809570312, "training_acc": 50.0, "val_loss": 89.8740463256836, "val_acc": 40.0}
{"epoch": 9, "training_loss": 327.49547119140624, "training_acc": 30.0, "val_loss": 635.4911499023438, "val_acc": 60.0}
{"epoch": 10, "training_loss": 781.690673828125, "training_acc": 50.0, "val_loss": 308.0212097167969, "val_acc": 60.0}
{"epoch": 11, "training_loss": 398.07908325195314, "training_acc": 40.0, "val_loss": 413.9701843261719, "val_acc": 40.0}
{"epoch": 12, "training_loss": 335.3783386230469, "training_acc": 50.0, "val_loss": 81.3224105834961, "val_acc": 40.0}
{"epoch": 13, "training_loss": 77.68904113769531, "training_acc": 60.0, "val_loss": 454.10888671875, "val_acc": 60.0}
{"epoch": 14, "training_loss": 600.914453125, "training_acc": 50.0, "val_loss": 252.03311157226562, "val_acc": 60.0}
{"epoch": 15, "training_loss": 286.68048706054685, "training_acc": 50.0, "val_loss": 492.01617431640625, "val_acc": 40.0}
{"epoch": 16, "training_loss": 413.132568359375, "training_acc": 50.0, "val_loss": 313.08489990234375, "val_acc": 40.0}
{"epoch": 17, "training_loss": 155.537255859375, "training_acc": 70.0, "val_loss": 248.56314086914062, "val_acc": 60.0}
{"epoch": 18, "training_loss": 323.5893127441406, "training_acc": 50.0, "val_loss": 165.0096893310547, "val_acc": 60.0}
{"epoch": 19, "training_loss": 157.5064224243164, "training_acc": 60.0, "val_loss": 337.2572326660156, "val_acc": 40.0}
{"epoch": 20, "training_loss": 272.4908447265625, "training_acc": 50.0, "val_loss": 15.806475639343262, "val_acc": 40.0}
{"epoch": 21, "training_loss": 128.83219985961915, "training_acc": 40.0, "val_loss": 388.21392822265625, "val_acc": 60.0}
{"epoch": 22, "training_loss": 459.46588134765625, "training_acc": 50.0, "val_loss": 3.6538169384002686, "val_acc": 60.0}
{"epoch": 23, "training_loss": 138.32787857055663, "training_acc": 60.0, "val_loss": 703.0033569335938, "val_acc": 40.0}
{"epoch": 24, "training_loss": 564.9783935546875, "training_acc": 50.0, "val_loss": 277.1703796386719, "val_acc": 40.0}
{"epoch": 25, "training_loss": 227.11812744140624, "training_acc": 50.0, "val_loss": 319.2203063964844, "val_acc": 60.0}
{"epoch": 26, "training_loss": 396.80967712402344, "training_acc": 50.0, "val_loss": 176.14617919921875, "val_acc": 60.0}
{"epoch": 27, "training_loss": 194.11562805175782, "training_acc": 50.0, "val_loss": 216.06884765625, "val_acc": 40.0}
{"epoch": 28, "training_loss": 152.21282348632812, "training_acc": 50.0, "val_loss": 181.3689422607422, "val_acc": 60.0}
{"epoch": 29, "training_loss": 259.0105346679687, "training_acc": 50.0, "val_loss": 94.31017303466797, "val_acc": 60.0}
{"epoch": 30, "training_loss": 238.42451171875, "training_acc": 30.0, "val_loss": 353.3029479980469, "val_acc": 40.0}
{"epoch": 31, "training_loss": 250.29132995605468, "training_acc": 50.0, "val_loss": 209.7676239013672, "val_acc": 60.0}
{"epoch": 32, "training_loss": 293.2259155273438, "training_acc": 50.0, "val_loss": 269.49884033203125, "val_acc": 60.0}
{"epoch": 33, "training_loss": 271.1920471191406, "training_acc": 50.0, "val_loss": 449.778564453125, "val_acc": 40.0}
{"epoch": 34, "training_loss": 457.457373046875, "training_acc": 50.0, "val_loss": 736.2776489257812, "val_acc": 40.0}
{"epoch": 35, "training_loss": 549.3412231445312, "training_acc": 50.0, "val_loss": 37.11024856567383, "val_acc": 60.0}
{"epoch": 36, "training_loss": 127.96045532226563, "training_acc": 50.0, "val_loss": 196.984375, "val_acc": 60.0}
{"epoch": 37, "training_loss": 203.70288829803468, "training_acc": 50.0, "val_loss": 435.77569580078125, "val_acc": 40.0}
{"epoch": 38, "training_loss": 357.089794921875, "training_acc": 50.0, "val_loss": 673.9006958007812, "val_acc": 40.0}
{"epoch": 39, "training_loss": 544.0920837402343, "training_acc": 50.0, "val_loss": 255.4781036376953, "val_acc": 40.0}
{"epoch": 40, "training_loss": 201.03919677734376, "training_acc": 50.0, "val_loss": 251.30332946777344, "val_acc": 60.0}
{"epoch": 41, "training_loss": 309.700048828125, "training_acc": 50.0, "val_loss": 11.930070877075195, "val_acc": 60.0}
