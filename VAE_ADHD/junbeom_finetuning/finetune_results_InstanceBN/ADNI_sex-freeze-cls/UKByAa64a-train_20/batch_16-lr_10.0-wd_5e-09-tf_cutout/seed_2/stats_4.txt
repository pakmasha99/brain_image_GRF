"main_modify.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 2 --task ADNI_sex --input_option yAware --learning_rate 1e1 --batch_size 16 --weight_decay 5e-9 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 640.6747815132142, "training_acc": 35.0, "val_loss": 1040.5238037109375, "val_acc": 40.0}
{"epoch": 1, "training_loss": 432.391650390625, "training_acc": 75.0, "val_loss": 1387.8729248046875, "val_acc": 60.0}
{"epoch": 2, "training_loss": 1938.5193115234374, "training_acc": 45.0, "val_loss": 1212.83349609375, "val_acc": 60.0}
{"epoch": 3, "training_loss": 1582.37890625, "training_acc": 45.0, "val_loss": 257.0129699707031, "val_acc": 40.0}
{"epoch": 4, "training_loss": 275.0532958984375, "training_acc": 55.0, "val_loss": 786.6350708007812, "val_acc": 40.0}
{"epoch": 5, "training_loss": 509.47373046875, "training_acc": 55.0, "val_loss": 208.1956329345703, "val_acc": 60.0}
{"epoch": 6, "training_loss": 365.1881591796875, "training_acc": 45.0, "val_loss": 288.4914245605469, "val_acc": 60.0}
{"epoch": 7, "training_loss": 249.74482421875, "training_acc": 65.0, "val_loss": 465.8983459472656, "val_acc": 40.0}
{"epoch": 8, "training_loss": 356.68848876953126, "training_acc": 55.0, "val_loss": 341.55230712890625, "val_acc": 40.0}
{"epoch": 9, "training_loss": 212.6093963623047, "training_acc": 55.0, "val_loss": 164.05752563476562, "val_acc": 60.0}
{"epoch": 10, "training_loss": 168.31631774902343, "training_acc": 45.0, "val_loss": 558.75830078125, "val_acc": 40.0}
{"epoch": 11, "training_loss": 427.22601318359375, "training_acc": 55.0, "val_loss": 893.1840209960938, "val_acc": 40.0}
{"epoch": 12, "training_loss": 626.727490234375, "training_acc": 55.0, "val_loss": 292.0206298828125, "val_acc": 40.0}
{"epoch": 13, "training_loss": 162.23150024414062, "training_acc": 65.0, "val_loss": 481.9770202636719, "val_acc": 60.0}
{"epoch": 14, "training_loss": 652.3243957519531, "training_acc": 45.0, "val_loss": 403.19805908203125, "val_acc": 60.0}
{"epoch": 15, "training_loss": 424.411669921875, "training_acc": 45.0, "val_loss": 605.2940063476562, "val_acc": 40.0}
{"epoch": 16, "training_loss": 474.58344116210935, "training_acc": 55.0, "val_loss": 1397.9537353515625, "val_acc": 40.0}
{"epoch": 17, "training_loss": 1036.8158447265625, "training_acc": 55.0, "val_loss": 1219.499267578125, "val_acc": 40.0}
{"epoch": 18, "training_loss": 820.8596435546875, "training_acc": 55.0, "val_loss": 135.9501190185547, "val_acc": 40.0}
{"epoch": 19, "training_loss": 328.78612060546874, "training_acc": 35.0, "val_loss": 678.7611694335938, "val_acc": 60.0}
{"epoch": 20, "training_loss": 906.9451171875, "training_acc": 45.0, "val_loss": 442.7945251464844, "val_acc": 60.0}
{"epoch": 21, "training_loss": 461.8562377929687, "training_acc": 45.0, "val_loss": 716.4983520507812, "val_acc": 40.0}
{"epoch": 22, "training_loss": 654.3361328125, "training_acc": 55.0, "val_loss": 1420.63525390625, "val_acc": 40.0}
{"epoch": 23, "training_loss": 1029.289013671875, "training_acc": 55.0, "val_loss": 1060.52099609375, "val_acc": 40.0}
{"epoch": 24, "training_loss": 696.0574890136719, "training_acc": 55.0, "val_loss": 24.435422897338867, "val_acc": 60.0}
{"epoch": 25, "training_loss": 103.53051986694337, "training_acc": 50.0, "val_loss": 226.5591278076172, "val_acc": 60.0}
{"epoch": 26, "training_loss": 218.25865745544434, "training_acc": 45.0, "val_loss": 614.0327758789062, "val_acc": 40.0}
{"epoch": 27, "training_loss": 454.9968627929687, "training_acc": 55.0, "val_loss": 1104.9664306640625, "val_acc": 40.0}
{"epoch": 28, "training_loss": 793.045361328125, "training_acc": 55.0, "val_loss": 867.8334350585938, "val_acc": 40.0}
{"epoch": 29, "training_loss": 585.9211883544922, "training_acc": 55.0, "val_loss": 77.44281768798828, "val_acc": 40.0}
{"epoch": 30, "training_loss": 110.12787170410157, "training_acc": 55.0, "val_loss": 586.8688354492188, "val_acc": 60.0}
{"epoch": 31, "training_loss": 786.264892578125, "training_acc": 45.0, "val_loss": 371.69073486328125, "val_acc": 60.0}
{"epoch": 32, "training_loss": 401.32835960388184, "training_acc": 45.0, "val_loss": 358.2533874511719, "val_acc": 40.0}
{"epoch": 33, "training_loss": 232.75858154296876, "training_acc": 55.0, "val_loss": 252.581298828125, "val_acc": 40.0}
{"epoch": 34, "training_loss": 129.7025360107422, "training_acc": 55.0, "val_loss": 103.6099624633789, "val_acc": 60.0}
{"epoch": 35, "training_loss": 102.38746795654296, "training_acc": 45.0, "val_loss": 99.32079315185547, "val_acc": 40.0}
{"epoch": 36, "training_loss": 47.149200439453125, "training_acc": 55.0, "val_loss": 111.382080078125, "val_acc": 60.0}
{"epoch": 37, "training_loss": 120.42418518066407, "training_acc": 45.0, "val_loss": 211.36184692382812, "val_acc": 40.0}
{"epoch": 38, "training_loss": 107.01336288452148, "training_acc": 45.0, "val_loss": 155.2467498779297, "val_acc": 40.0}
{"epoch": 39, "training_loss": 66.53618774414062, "training_acc": 60.0, "val_loss": 51.7116813659668, "val_acc": 60.0}
{"epoch": 40, "training_loss": 69.47642822265625, "training_acc": 35.0, "val_loss": 58.42900466918945, "val_acc": 20.0}
{"epoch": 41, "training_loss": 49.50772323608398, "training_acc": 65.0, "val_loss": 203.02420043945312, "val_acc": 40.0}
{"epoch": 42, "training_loss": 102.61404266357422, "training_acc": 55.0, "val_loss": 183.2774200439453, "val_acc": 40.0}
{"epoch": 43, "training_loss": 139.20131225585936, "training_acc": 35.0, "val_loss": 46.853511810302734, "val_acc": 0.0}
