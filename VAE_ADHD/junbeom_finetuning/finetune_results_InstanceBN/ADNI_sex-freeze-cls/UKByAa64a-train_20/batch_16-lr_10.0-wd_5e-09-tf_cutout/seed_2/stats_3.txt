"main_modify.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 2 --task ADNI_sex --input_option yAware --learning_rate 1e1 --batch_size 16 --weight_decay 5e-9 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 633.375784111023, "training_acc": 45.0, "val_loss": 446.84228515625, "val_acc": 60.0}
{"epoch": 1, "training_loss": 747.296630859375, "training_acc": 45.0, "val_loss": 2311.927001953125, "val_acc": 40.0}
{"epoch": 2, "training_loss": 1734.11123046875, "training_acc": 55.0, "val_loss": 2115.828125, "val_acc": 40.0}
{"epoch": 3, "training_loss": 1476.3060546875, "training_acc": 55.0, "val_loss": 474.94854736328125, "val_acc": 40.0}
{"epoch": 4, "training_loss": 400.3461181640625, "training_acc": 55.0, "val_loss": 910.0162353515625, "val_acc": 60.0}
{"epoch": 5, "training_loss": 1269.53037109375, "training_acc": 45.0, "val_loss": 783.5082397460938, "val_acc": 60.0}
{"epoch": 6, "training_loss": 1024.0897033691406, "training_acc": 45.0, "val_loss": 254.6976318359375, "val_acc": 40.0}
{"epoch": 7, "training_loss": 297.76015625, "training_acc": 55.0, "val_loss": 575.6707763671875, "val_acc": 40.0}
{"epoch": 8, "training_loss": 368.80401611328125, "training_acc": 55.0, "val_loss": 274.4771728515625, "val_acc": 60.0}
{"epoch": 9, "training_loss": 394.434716796875, "training_acc": 45.0, "val_loss": 403.2350769042969, "val_acc": 60.0}
{"epoch": 10, "training_loss": 485.7259216308594, "training_acc": 45.0, "val_loss": 321.91424560546875, "val_acc": 40.0}
{"epoch": 11, "training_loss": 241.793115234375, "training_acc": 55.0, "val_loss": 844.31689453125, "val_acc": 40.0}
{"epoch": 12, "training_loss": 648.44619140625, "training_acc": 55.0, "val_loss": 415.07843017578125, "val_acc": 40.0}
{"epoch": 13, "training_loss": 280.17510986328125, "training_acc": 55.0, "val_loss": 380.3858947753906, "val_acc": 60.0}
{"epoch": 14, "training_loss": 519.8663696289062, "training_acc": 45.0, "val_loss": 218.25572204589844, "val_acc": 60.0}
{"epoch": 15, "training_loss": 227.99433975219728, "training_acc": 55.0, "val_loss": 456.0033264160156, "val_acc": 40.0}
{"epoch": 16, "training_loss": 342.0241180419922, "training_acc": 55.0, "val_loss": 360.8156433105469, "val_acc": 40.0}
{"epoch": 17, "training_loss": 238.78688415661455, "training_acc": 60.0, "val_loss": 216.9681396484375, "val_acc": 60.0}
{"epoch": 18, "training_loss": 316.02294921875, "training_acc": 45.0, "val_loss": 49.670955657958984, "val_acc": 40.0}
{"epoch": 19, "training_loss": 89.23497619628907, "training_acc": 55.0, "val_loss": 79.33770751953125, "val_acc": 40.0}
{"epoch": 20, "training_loss": 135.17876586914062, "training_acc": 45.0, "val_loss": 220.6144561767578, "val_acc": 60.0}
{"epoch": 21, "training_loss": 249.84934692382814, "training_acc": 45.0, "val_loss": 435.03521728515625, "val_acc": 40.0}
{"epoch": 22, "training_loss": 362.063916015625, "training_acc": 55.0, "val_loss": 626.8809204101562, "val_acc": 40.0}
{"epoch": 23, "training_loss": 441.7482116699219, "training_acc": 55.0, "val_loss": 19.455368041992188, "val_acc": 60.0}
{"epoch": 24, "training_loss": 42.21500244140625, "training_acc": 45.0, "val_loss": 159.95628356933594, "val_acc": 40.0}
{"epoch": 25, "training_loss": 124.89896240234376, "training_acc": 55.0, "val_loss": 4.750661373138428, "val_acc": 60.0}
{"epoch": 26, "training_loss": 35.60630677342415, "training_acc": 90.0, "val_loss": 107.75041961669922, "val_acc": 60.0}
{"epoch": 27, "training_loss": 138.53952331542968, "training_acc": 45.0, "val_loss": 209.073974609375, "val_acc": 40.0}
{"epoch": 28, "training_loss": 119.5480728149414, "training_acc": 55.0, "val_loss": 284.32550048828125, "val_acc": 60.0}
{"epoch": 29, "training_loss": 407.3890014648438, "training_acc": 45.0, "val_loss": 335.95391845703125, "val_acc": 60.0}
{"epoch": 30, "training_loss": 419.7626091003418, "training_acc": 45.0, "val_loss": 355.04351806640625, "val_acc": 40.0}
{"epoch": 31, "training_loss": 261.378662109375, "training_acc": 55.0, "val_loss": 641.5089111328125, "val_acc": 40.0}
{"epoch": 32, "training_loss": 461.5762939453125, "training_acc": 55.0, "val_loss": 150.03790283203125, "val_acc": 40.0}
{"epoch": 33, "training_loss": 157.08699951171874, "training_acc": 55.0, "val_loss": 492.6091003417969, "val_acc": 60.0}
{"epoch": 34, "training_loss": 667.662744140625, "training_acc": 45.0, "val_loss": 311.3322448730469, "val_acc": 60.0}
{"epoch": 35, "training_loss": 350.42060737609864, "training_acc": 45.0, "val_loss": 251.5663299560547, "val_acc": 40.0}
{"epoch": 36, "training_loss": 179.22860717773438, "training_acc": 55.0, "val_loss": 22.883384704589844, "val_acc": 40.0}
{"epoch": 37, "training_loss": 4.017616653442383, "training_acc": 80.0, "val_loss": 332.7703552246094, "val_acc": 60.0}
{"epoch": 38, "training_loss": 436.3205810546875, "training_acc": 45.0, "val_loss": 94.07806396484375, "val_acc": 60.0}
{"epoch": 39, "training_loss": 118.30500183105468, "training_acc": 55.0, "val_loss": 725.9187622070312, "val_acc": 40.0}
{"epoch": 40, "training_loss": 542.4909729003906, "training_acc": 55.0, "val_loss": 713.30810546875, "val_acc": 40.0}
{"epoch": 41, "training_loss": 503.26576232910156, "training_acc": 55.0, "val_loss": 12.279754638671875, "val_acc": 40.0}
{"epoch": 42, "training_loss": 40.47883682250976, "training_acc": 65.0, "val_loss": 102.08343505859375, "val_acc": 60.0}
{"epoch": 43, "training_loss": 133.85462341308593, "training_acc": 45.0, "val_loss": 253.4468231201172, "val_acc": 40.0}
{"epoch": 44, "training_loss": 156.23426513671876, "training_acc": 55.0, "val_loss": 213.19444274902344, "val_acc": 60.0}
