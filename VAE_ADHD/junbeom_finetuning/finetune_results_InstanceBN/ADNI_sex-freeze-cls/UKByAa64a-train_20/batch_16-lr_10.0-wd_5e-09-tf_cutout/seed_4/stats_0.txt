"main_modify.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 4 --task ADNI_sex --input_option yAware --learning_rate 1e1 --batch_size 16 --weight_decay 5e-9 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 426.5123805999756, "training_acc": 50.0, "val_loss": 721.1969604492188, "val_acc": 40.0}
{"epoch": 1, "training_loss": 900.4852783203125, "training_acc": 40.0, "val_loss": 1103.9354248046875, "val_acc": 60.0}
{"epoch": 2, "training_loss": 1333.5770935058595, "training_acc": 50.0, "val_loss": 303.7321472167969, "val_acc": 60.0}
{"epoch": 3, "training_loss": 499.2193969726562, "training_acc": 40.0, "val_loss": 864.7015991210938, "val_acc": 40.0}
{"epoch": 4, "training_loss": 719.470703125, "training_acc": 50.0, "val_loss": 322.54547119140625, "val_acc": 40.0}
{"epoch": 5, "training_loss": 204.92053833007813, "training_acc": 60.0, "val_loss": 344.2852783203125, "val_acc": 60.0}
{"epoch": 6, "training_loss": 413.5607147216797, "training_acc": 50.0, "val_loss": 75.302490234375, "val_acc": 60.0}
{"epoch": 7, "training_loss": 202.5030029296875, "training_acc": 40.0, "val_loss": 551.9514770507812, "val_acc": 40.0}
{"epoch": 8, "training_loss": 404.3523315429687, "training_acc": 50.0, "val_loss": 181.0456085205078, "val_acc": 60.0}
{"epoch": 9, "training_loss": 236.54381408691407, "training_acc": 50.0, "val_loss": 370.0304870605469, "val_acc": 60.0}
{"epoch": 10, "training_loss": 415.8874755859375, "training_acc": 50.0, "val_loss": 145.19097900390625, "val_acc": 40.0}
{"epoch": 11, "training_loss": 127.93271484375, "training_acc": 50.0, "val_loss": 229.646240234375, "val_acc": 40.0}
{"epoch": 12, "training_loss": 160.5460418701172, "training_acc": 50.0, "val_loss": 46.080482482910156, "val_acc": 60.0}
{"epoch": 13, "training_loss": 99.40661926269532, "training_acc": 40.0, "val_loss": 112.0472640991211, "val_acc": 40.0}
{"epoch": 14, "training_loss": 115.59895629882813, "training_acc": 50.0, "val_loss": 222.49111938476562, "val_acc": 60.0}
{"epoch": 15, "training_loss": 234.4941177368164, "training_acc": 50.0, "val_loss": 287.091796875, "val_acc": 40.0}
{"epoch": 16, "training_loss": 256.0604675292969, "training_acc": 50.0, "val_loss": 277.2065124511719, "val_acc": 40.0}
{"epoch": 17, "training_loss": 274.9009979248047, "training_acc": 30.0, "val_loss": 40.32497787475586, "val_acc": 60.0}
{"epoch": 18, "training_loss": 48.41077575683594, "training_acc": 60.0, "val_loss": 407.09259033203125, "val_acc": 40.0}
{"epoch": 19, "training_loss": 324.68005828857423, "training_acc": 50.0, "val_loss": 28.4930362701416, "val_acc": 40.0}
{"epoch": 20, "training_loss": 133.11495513916014, "training_acc": 40.0, "val_loss": 366.633056640625, "val_acc": 60.0}
{"epoch": 21, "training_loss": 410.56891479492185, "training_acc": 50.0, "val_loss": 26.107229232788086, "val_acc": 40.0}
{"epoch": 22, "training_loss": 36.33326873779297, "training_acc": 50.0, "val_loss": 10.775382041931152, "val_acc": 60.0}
{"epoch": 23, "training_loss": 17.31774787902832, "training_acc": 70.0, "val_loss": 12.804107666015625, "val_acc": 40.0}
{"epoch": 24, "training_loss": 21.903971481323243, "training_acc": 75.0, "val_loss": 307.3639831542969, "val_acc": 40.0}
{"epoch": 25, "training_loss": 213.49509887695314, "training_acc": 50.0, "val_loss": 258.28106689453125, "val_acc": 60.0}
{"epoch": 26, "training_loss": 302.4715087890625, "training_acc": 50.0, "val_loss": 536.0440673828125, "val_acc": 60.0}
{"epoch": 27, "training_loss": 639.4161376953125, "training_acc": 50.0, "val_loss": 289.3138122558594, "val_acc": 60.0}
{"epoch": 28, "training_loss": 281.91734313964844, "training_acc": 50.0, "val_loss": 311.0956726074219, "val_acc": 40.0}
{"epoch": 29, "training_loss": 245.26195068359374, "training_acc": 50.0, "val_loss": 43.50830078125, "val_acc": 40.0}
{"epoch": 30, "training_loss": 120.02680053710938, "training_acc": 40.0, "val_loss": 297.9756774902344, "val_acc": 60.0}
{"epoch": 31, "training_loss": 302.0101013183594, "training_acc": 50.0, "val_loss": 266.9017639160156, "val_acc": 40.0}
{"epoch": 32, "training_loss": 258.8123840332031, "training_acc": 50.0, "val_loss": 462.64111328125, "val_acc": 40.0}
{"epoch": 33, "training_loss": 352.5074493408203, "training_acc": 50.0, "val_loss": 162.011474609375, "val_acc": 60.0}
{"epoch": 34, "training_loss": 199.25971069335938, "training_acc": 50.0, "val_loss": 142.4327850341797, "val_acc": 60.0}
{"epoch": 35, "training_loss": 142.94613647460938, "training_acc": 50.0, "val_loss": 257.4715881347656, "val_acc": 40.0}
{"epoch": 36, "training_loss": 177.59985961914063, "training_acc": 50.0, "val_loss": 199.1234588623047, "val_acc": 60.0}
{"epoch": 37, "training_loss": 278.9184814453125, "training_acc": 50.0, "val_loss": 88.26712799072266, "val_acc": 60.0}
{"epoch": 38, "training_loss": 47.69679565429688, "training_acc": 70.0, "val_loss": 793.3273315429688, "val_acc": 40.0}
{"epoch": 39, "training_loss": 655.1295837402344, "training_acc": 50.0, "val_loss": 899.3511962890625, "val_acc": 40.0}
{"epoch": 40, "training_loss": 679.720947265625, "training_acc": 50.0, "val_loss": 106.08772277832031, "val_acc": 40.0}
{"epoch": 41, "training_loss": 306.0913146972656, "training_acc": 30.0, "val_loss": 638.4074096679688, "val_acc": 60.0}
