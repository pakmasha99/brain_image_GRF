"main_modify.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 4 --task ADNI_sex --input_option yAware --learning_rate 1e1 --batch_size 16 --weight_decay 5e-9 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 641.3217275619506, "training_acc": 35.0, "val_loss": 1224.4329833984375, "val_acc": 40.0}
{"epoch": 1, "training_loss": 947.778759765625, "training_acc": 45.0, "val_loss": 475.41162109375, "val_acc": 60.0}
{"epoch": 2, "training_loss": 612.2609359741211, "training_acc": 45.0, "val_loss": 476.8785095214844, "val_acc": 40.0}
{"epoch": 3, "training_loss": 413.611865234375, "training_acc": 55.0, "val_loss": 289.4280090332031, "val_acc": 40.0}
{"epoch": 4, "training_loss": 120.06513671875, "training_acc": 75.0, "val_loss": 564.9699096679688, "val_acc": 60.0}
{"epoch": 5, "training_loss": 787.7896606445313, "training_acc": 45.0, "val_loss": 400.8716735839844, "val_acc": 60.0}
{"epoch": 6, "training_loss": 404.66299686431887, "training_acc": 45.0, "val_loss": 947.3330078125, "val_acc": 40.0}
{"epoch": 7, "training_loss": 753.1376708984375, "training_acc": 55.0, "val_loss": 1823.5906982421875, "val_acc": 40.0}
{"epoch": 8, "training_loss": 1371.566552734375, "training_acc": 55.0, "val_loss": 1601.4586181640625, "val_acc": 40.0}
{"epoch": 9, "training_loss": 1116.621142578125, "training_acc": 55.0, "val_loss": 402.7852478027344, "val_acc": 40.0}
{"epoch": 10, "training_loss": 394.7150390625, "training_acc": 45.0, "val_loss": 597.0326538085938, "val_acc": 60.0}
{"epoch": 11, "training_loss": 828.2628051757813, "training_acc": 45.0, "val_loss": 475.16552734375, "val_acc": 60.0}
{"epoch": 12, "training_loss": 653.263427734375, "training_acc": 45.0, "val_loss": 345.2195739746094, "val_acc": 40.0}
{"epoch": 13, "training_loss": 293.9229797363281, "training_acc": 55.0, "val_loss": 511.9173889160156, "val_acc": 40.0}
{"epoch": 14, "training_loss": 354.7112579345703, "training_acc": 55.0, "val_loss": 142.56207275390625, "val_acc": 60.0}
{"epoch": 15, "training_loss": 205.3096923828125, "training_acc": 45.0, "val_loss": 69.76025390625, "val_acc": 60.0}
{"epoch": 16, "training_loss": 133.5752380371094, "training_acc": 45.0, "val_loss": 505.6980895996094, "val_acc": 40.0}
{"epoch": 17, "training_loss": 361.54039306640624, "training_acc": 55.0, "val_loss": 23.7452449798584, "val_acc": 40.0}
{"epoch": 18, "training_loss": 164.08832855224608, "training_acc": 45.0, "val_loss": 532.3733520507812, "val_acc": 60.0}
{"epoch": 19, "training_loss": 709.49716796875, "training_acc": 45.0, "val_loss": 193.03599548339844, "val_acc": 60.0}
{"epoch": 20, "training_loss": 272.5512451171875, "training_acc": 45.0, "val_loss": 724.5470581054688, "val_acc": 40.0}
{"epoch": 21, "training_loss": 545.4587768554687, "training_acc": 55.0, "val_loss": 741.8317260742188, "val_acc": 40.0}
{"epoch": 22, "training_loss": 528.0967010498047, "training_acc": 55.0, "val_loss": 51.641883850097656, "val_acc": 40.0}
{"epoch": 23, "training_loss": 111.97230834960938, "training_acc": 55.0, "val_loss": 519.1129150390625, "val_acc": 60.0}
{"epoch": 24, "training_loss": 704.559716796875, "training_acc": 45.0, "val_loss": 304.567626953125, "val_acc": 60.0}
{"epoch": 25, "training_loss": 305.0549615859985, "training_acc": 55.0, "val_loss": 368.9783020019531, "val_acc": 40.0}
{"epoch": 26, "training_loss": 286.6938110351563, "training_acc": 55.0, "val_loss": 268.9928894042969, "val_acc": 40.0}
{"epoch": 27, "training_loss": 170.08802947998046, "training_acc": 55.0, "val_loss": 131.64166259765625, "val_acc": 60.0}
{"epoch": 28, "training_loss": 162.70825805664063, "training_acc": 35.0, "val_loss": 87.99983978271484, "val_acc": 60.0}
{"epoch": 29, "training_loss": 95.59658470153809, "training_acc": 50.0, "val_loss": 232.1531219482422, "val_acc": 40.0}
{"epoch": 30, "training_loss": 166.54796295166017, "training_acc": 55.0, "val_loss": 47.11206817626953, "val_acc": 40.0}
{"epoch": 31, "training_loss": 41.70229644775391, "training_acc": 65.0, "val_loss": 292.2000427246094, "val_acc": 60.0}
{"epoch": 32, "training_loss": 385.4955352783203, "training_acc": 45.0, "val_loss": 2.487929105758667, "val_acc": 80.0}
{"epoch": 33, "training_loss": 55.787270641326906, "training_acc": 75.0, "val_loss": 381.3504638671875, "val_acc": 40.0}
{"epoch": 34, "training_loss": 281.6009765625, "training_acc": 55.0, "val_loss": 42.086936950683594, "val_acc": 60.0}
{"epoch": 35, "training_loss": 45.79010410308838, "training_acc": 50.0, "val_loss": 12.602640151977539, "val_acc": 60.0}
{"epoch": 36, "training_loss": 63.21568145751953, "training_acc": 40.0, "val_loss": 53.46343994140625, "val_acc": 40.0}
{"epoch": 37, "training_loss": 42.602761840820314, "training_acc": 65.0, "val_loss": 298.9310607910156, "val_acc": 60.0}
{"epoch": 38, "training_loss": 388.5021240234375, "training_acc": 45.0, "val_loss": 10.20848274230957, "val_acc": 60.0}
{"epoch": 39, "training_loss": 123.4225845336914, "training_acc": 45.0, "val_loss": 524.23486328125, "val_acc": 40.0}
{"epoch": 40, "training_loss": 359.03271484375, "training_acc": 55.0, "val_loss": 31.3947811126709, "val_acc": 60.0}
{"epoch": 41, "training_loss": 34.288720703125, "training_acc": 45.0, "val_loss": 53.82074737548828, "val_acc": 60.0}
{"epoch": 42, "training_loss": 57.83437271118164, "training_acc": 55.0, "val_loss": 238.44883728027344, "val_acc": 40.0}
{"epoch": 43, "training_loss": 145.25782318115233, "training_acc": 55.0, "val_loss": 188.85731506347656, "val_acc": 60.0}
{"epoch": 44, "training_loss": 251.5106643676758, "training_acc": 45.0, "val_loss": 139.5459747314453, "val_acc": 60.0}
{"epoch": 45, "training_loss": 142.02407150268556, "training_acc": 55.0, "val_loss": 314.28082275390625, "val_acc": 40.0}
{"epoch": 46, "training_loss": 218.10358276367188, "training_acc": 55.0, "val_loss": 28.647451400756836, "val_acc": 60.0}
{"epoch": 47, "training_loss": 33.035193252563474, "training_acc": 45.0, "val_loss": 225.2517547607422, "val_acc": 40.0}
{"epoch": 48, "training_loss": 164.82960205078126, "training_acc": 55.0, "val_loss": 0.0415998250246048, "val_acc": 100.0}
{"epoch": 49, "training_loss": 43.27708683013916, "training_acc": 80.0, "val_loss": 174.58384704589844, "val_acc": 60.0}
{"epoch": 50, "training_loss": 168.2880511111347, "training_acc": 60.0, "val_loss": 228.590576171875, "val_acc": 40.0}
{"epoch": 51, "training_loss": 161.719091796875, "training_acc": 55.0, "val_loss": 80.98441314697266, "val_acc": 40.0}
{"epoch": 52, "training_loss": 70.9560302734375, "training_acc": 55.0, "val_loss": 130.1411895751953, "val_acc": 60.0}
{"epoch": 53, "training_loss": 151.94574127197265, "training_acc": 45.0, "val_loss": 84.96080017089844, "val_acc": 40.0}
{"epoch": 54, "training_loss": 57.81510620117187, "training_acc": 55.0, "val_loss": 43.631526947021484, "val_acc": 60.0}
{"epoch": 55, "training_loss": 51.063829040527345, "training_acc": 55.0, "val_loss": 384.03564453125, "val_acc": 40.0}
{"epoch": 56, "training_loss": 277.2377685546875, "training_acc": 55.0, "val_loss": 82.6285171508789, "val_acc": 40.0}
{"epoch": 57, "training_loss": 115.05442810058594, "training_acc": 45.0, "val_loss": 164.8849334716797, "val_acc": 60.0}
{"epoch": 58, "training_loss": 187.4356014251709, "training_acc": 45.0, "val_loss": 101.24840545654297, "val_acc": 40.0}
{"epoch": 59, "training_loss": 46.78541753292084, "training_acc": 65.0, "val_loss": 38.92924499511719, "val_acc": 60.0}
{"epoch": 60, "training_loss": 70.76470031738282, "training_acc": 45.0, "val_loss": 189.84751892089844, "val_acc": 40.0}
{"epoch": 61, "training_loss": 125.94760665893554, "training_acc": 45.0, "val_loss": 64.45845794677734, "val_acc": 40.0}
{"epoch": 62, "training_loss": 58.010260009765624, "training_acc": 35.0, "val_loss": 275.5556335449219, "val_acc": 40.0}
{"epoch": 63, "training_loss": 216.17198486328124, "training_acc": 55.0, "val_loss": 226.6648406982422, "val_acc": 40.0}
{"epoch": 64, "training_loss": 219.48757934570312, "training_acc": 35.0, "val_loss": 39.34780502319336, "val_acc": 60.0}
{"epoch": 65, "training_loss": 168.8042236328125, "training_acc": 25.0, "val_loss": 287.234130859375, "val_acc": 40.0}
{"epoch": 66, "training_loss": 121.05682983398438, "training_acc": 60.0, "val_loss": 344.3481140136719, "val_acc": 60.0}
{"epoch": 67, "training_loss": 483.1891662597656, "training_acc": 45.0, "val_loss": 536.3184814453125, "val_acc": 60.0}
