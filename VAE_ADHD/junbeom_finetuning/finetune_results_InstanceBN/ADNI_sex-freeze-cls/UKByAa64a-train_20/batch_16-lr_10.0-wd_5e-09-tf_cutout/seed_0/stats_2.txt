"main_modify.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_sex --input_option yAware --learning_rate 1e1 --batch_size 16 --weight_decay 5e-9 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 424.1563847541809, "training_acc": 50.0, "val_loss": 471.2066955566406, "val_acc": 60.0}
{"epoch": 1, "training_loss": 893.817822265625, "training_acc": 40.0, "val_loss": 1664.2222900390625, "val_acc": 40.0}
{"epoch": 2, "training_loss": 1293.0786376953124, "training_acc": 50.0, "val_loss": 289.1357727050781, "val_acc": 40.0}
{"epoch": 3, "training_loss": 354.8341552734375, "training_acc": 50.0, "val_loss": 1083.512939453125, "val_acc": 60.0}
{"epoch": 4, "training_loss": 1399.24287109375, "training_acc": 50.0, "val_loss": 983.7550659179688, "val_acc": 60.0}
{"epoch": 5, "training_loss": 1113.250927734375, "training_acc": 50.0, "val_loss": 55.7231559753418, "val_acc": 40.0}
{"epoch": 6, "training_loss": 124.12541809082032, "training_acc": 50.0, "val_loss": 606.4598999023438, "val_acc": 40.0}
{"epoch": 7, "training_loss": 462.68603515625, "training_acc": 50.0, "val_loss": 101.97000885009766, "val_acc": 60.0}
{"epoch": 8, "training_loss": 135.4023406982422, "training_acc": 50.0, "val_loss": 260.146484375, "val_acc": 60.0}
{"epoch": 9, "training_loss": 274.9419219970703, "training_acc": 50.0, "val_loss": 333.4992370605469, "val_acc": 40.0}
{"epoch": 10, "training_loss": 329.60460205078124, "training_acc": 50.0, "val_loss": 310.0130310058594, "val_acc": 40.0}
{"epoch": 11, "training_loss": 191.17605514526366, "training_acc": 60.0, "val_loss": 246.13499450683594, "val_acc": 60.0}
{"epoch": 12, "training_loss": 288.8530639648437, "training_acc": 50.0, "val_loss": 31.34846305847168, "val_acc": 60.0}
{"epoch": 13, "training_loss": 101.0719207763672, "training_acc": 50.0, "val_loss": 674.7061767578125, "val_acc": 40.0}
{"epoch": 14, "training_loss": 556.322265625, "training_acc": 50.0, "val_loss": 226.26663208007812, "val_acc": 40.0}
{"epoch": 15, "training_loss": 270.795654296875, "training_acc": 40.0, "val_loss": 417.3844299316406, "val_acc": 60.0}
{"epoch": 16, "training_loss": 497.12794189453126, "training_acc": 50.0, "val_loss": 139.91111755371094, "val_acc": 60.0}
{"epoch": 17, "training_loss": 242.30384521484376, "training_acc": 40.0, "val_loss": 595.0910034179688, "val_acc": 40.0}
{"epoch": 18, "training_loss": 487.40284423828126, "training_acc": 50.0, "val_loss": 234.05198669433594, "val_acc": 40.0}
{"epoch": 19, "training_loss": 201.01173706054686, "training_acc": 50.0, "val_loss": 322.66265869140625, "val_acc": 60.0}
{"epoch": 20, "training_loss": 375.23560791015626, "training_acc": 50.0, "val_loss": 109.52928924560547, "val_acc": 60.0}
{"epoch": 21, "training_loss": 193.34716796875, "training_acc": 40.0, "val_loss": 454.3358459472656, "val_acc": 40.0}
{"epoch": 22, "training_loss": 368.1496047973633, "training_acc": 50.0, "val_loss": 16.97792625427246, "val_acc": 40.0}
{"epoch": 23, "training_loss": 132.82944030761718, "training_acc": 40.0, "val_loss": 392.65509033203125, "val_acc": 60.0}
{"epoch": 24, "training_loss": 442.5109069824219, "training_acc": 50.0, "val_loss": 56.10174560546875, "val_acc": 60.0}
{"epoch": 25, "training_loss": 225.17197875976564, "training_acc": 30.0, "val_loss": 613.4765014648438, "val_acc": 40.0}
{"epoch": 26, "training_loss": 492.4524353027344, "training_acc": 50.0, "val_loss": 100.61790466308594, "val_acc": 40.0}
{"epoch": 27, "training_loss": 190.9786804199219, "training_acc": 40.0, "val_loss": 439.658203125, "val_acc": 60.0}
{"epoch": 28, "training_loss": 508.69805908203125, "training_acc": 50.0, "val_loss": 206.2853240966797, "val_acc": 60.0}
{"epoch": 29, "training_loss": 171.65225143432616, "training_acc": 60.0, "val_loss": 439.373046875, "val_acc": 40.0}
{"epoch": 30, "training_loss": 395.3381591796875, "training_acc": 50.0, "val_loss": 224.58824157714844, "val_acc": 40.0}
{"epoch": 31, "training_loss": 154.2621276855469, "training_acc": 60.0, "val_loss": 348.35333251953125, "val_acc": 60.0}
{"epoch": 32, "training_loss": 408.4366027832031, "training_acc": 50.0, "val_loss": 240.50244140625, "val_acc": 60.0}
{"epoch": 33, "training_loss": 218.6077907562256, "training_acc": 50.0, "val_loss": 181.12583923339844, "val_acc": 40.0}
{"epoch": 34, "training_loss": 151.42435417175292, "training_acc": 50.0, "val_loss": 125.28936004638672, "val_acc": 60.0}
{"epoch": 35, "training_loss": 120.40311889648437, "training_acc": 50.0, "val_loss": 67.73966979980469, "val_acc": 40.0}
{"epoch": 36, "training_loss": 65.42572631835938, "training_acc": 50.0, "val_loss": 119.2705078125, "val_acc": 60.0}
{"epoch": 37, "training_loss": 114.342626953125, "training_acc": 50.0, "val_loss": 26.638519287109375, "val_acc": 60.0}
{"epoch": 38, "training_loss": 19.338990020751954, "training_acc": 70.0, "val_loss": 38.75617980957031, "val_acc": 60.0}
{"epoch": 39, "training_loss": 14.62879295349121, "training_acc": 70.0, "val_loss": 105.83504486083984, "val_acc": 40.0}
{"epoch": 40, "training_loss": 111.47380828857422, "training_acc": 40.0, "val_loss": 24.946577072143555, "val_acc": 40.0}
{"epoch": 41, "training_loss": 45.23064270019531, "training_acc": 50.0, "val_loss": 19.835119247436523, "val_acc": 60.0}
