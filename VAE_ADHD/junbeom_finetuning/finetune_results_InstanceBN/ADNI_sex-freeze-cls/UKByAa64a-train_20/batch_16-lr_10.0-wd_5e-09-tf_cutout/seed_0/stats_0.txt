"main_modify.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_sex --input_option yAware --learning_rate 1e1 --batch_size 16 --weight_decay 5e-9 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 640.5814022064209, "training_acc": 50.0, "val_loss": 772.8220825195312, "val_acc": 40.0}
{"epoch": 1, "training_loss": 728.7260986328125, "training_acc": 50.0, "val_loss": 1363.1158447265625, "val_acc": 60.0}
{"epoch": 2, "training_loss": 1693.3703857421874, "training_acc": 50.0, "val_loss": 1041.5357666015625, "val_acc": 60.0}
{"epoch": 3, "training_loss": 1112.1515258789063, "training_acc": 50.0, "val_loss": 402.53759765625, "val_acc": 40.0}
{"epoch": 4, "training_loss": 436.81796875, "training_acc": 50.0, "val_loss": 1172.766357421875, "val_acc": 40.0}
{"epoch": 5, "training_loss": 927.160498046875, "training_acc": 50.0, "val_loss": 326.27972412109375, "val_acc": 40.0}
{"epoch": 6, "training_loss": 309.50029907226565, "training_acc": 50.0, "val_loss": 689.9072875976562, "val_acc": 60.0}
{"epoch": 7, "training_loss": 873.7017333984375, "training_acc": 50.0, "val_loss": 623.5787353515625, "val_acc": 60.0}
{"epoch": 8, "training_loss": 695.1024169921875, "training_acc": 50.0, "val_loss": 245.26858520507812, "val_acc": 40.0}
{"epoch": 9, "training_loss": 225.9065368652344, "training_acc": 50.0, "val_loss": 686.2819213867188, "val_acc": 40.0}
{"epoch": 10, "training_loss": 540.6009765625, "training_acc": 50.0, "val_loss": 108.4000015258789, "val_acc": 40.0}
{"epoch": 11, "training_loss": 158.17279663085938, "training_acc": 50.0, "val_loss": 562.5343627929688, "val_acc": 60.0}
{"epoch": 12, "training_loss": 695.2247314453125, "training_acc": 50.0, "val_loss": 388.8839416503906, "val_acc": 60.0}
{"epoch": 13, "training_loss": 432.41235008239744, "training_acc": 50.0, "val_loss": 567.4454956054688, "val_acc": 40.0}
{"epoch": 14, "training_loss": 490.21961669921876, "training_acc": 50.0, "val_loss": 917.2149658203125, "val_acc": 40.0}
{"epoch": 15, "training_loss": 721.543359375, "training_acc": 50.0, "val_loss": 252.19920349121094, "val_acc": 40.0}
{"epoch": 16, "training_loss": 243.09100341796875, "training_acc": 50.0, "val_loss": 576.1937866210938, "val_acc": 60.0}
{"epoch": 17, "training_loss": 723.1756225585938, "training_acc": 50.0, "val_loss": 524.66943359375, "val_acc": 60.0}
{"epoch": 18, "training_loss": 606.4380950927734, "training_acc": 50.0, "val_loss": 183.53883361816406, "val_acc": 40.0}
{"epoch": 19, "training_loss": 215.32293701171875, "training_acc": 50.0, "val_loss": 276.6714782714844, "val_acc": 40.0}
{"epoch": 20, "training_loss": 235.74478149414062, "training_acc": 40.0, "val_loss": 101.2317886352539, "val_acc": 60.0}
{"epoch": 21, "training_loss": 127.73362731933594, "training_acc": 40.0, "val_loss": 15.17260456085205, "val_acc": 60.0}
{"epoch": 22, "training_loss": 38.43041515350342, "training_acc": 70.0, "val_loss": 130.00509643554688, "val_acc": 60.0}
{"epoch": 23, "training_loss": 110.95403671264648, "training_acc": 60.0, "val_loss": 154.6598358154297, "val_acc": 40.0}
{"epoch": 24, "training_loss": 99.95040016174316, "training_acc": 55.0, "val_loss": 174.95310974121094, "val_acc": 60.0}
{"epoch": 25, "training_loss": 197.61507110595704, "training_acc": 50.0, "val_loss": 29.963485717773438, "val_acc": 60.0}
{"epoch": 26, "training_loss": 75.60225524902344, "training_acc": 50.0, "val_loss": 469.01861572265625, "val_acc": 40.0}
{"epoch": 27, "training_loss": 358.08375244140626, "training_acc": 50.0, "val_loss": 47.41289138793945, "val_acc": 60.0}
{"epoch": 28, "training_loss": 38.561328125, "training_acc": 50.0, "val_loss": 91.854248046875, "val_acc": 60.0}
{"epoch": 29, "training_loss": 71.42836017608643, "training_acc": 60.0, "val_loss": 99.97216796875, "val_acc": 40.0}
{"epoch": 30, "training_loss": 76.38987503051757, "training_acc": 50.0, "val_loss": 29.489612579345703, "val_acc": 60.0}
{"epoch": 31, "training_loss": 108.8490982055664, "training_acc": 35.0, "val_loss": 95.9225845336914, "val_acc": 40.0}
{"epoch": 32, "training_loss": 73.45467224121094, "training_acc": 60.0, "val_loss": 352.88555908203125, "val_acc": 60.0}
{"epoch": 33, "training_loss": 414.3583984375, "training_acc": 50.0, "val_loss": 220.6288604736328, "val_acc": 60.0}
{"epoch": 34, "training_loss": 180.69399855658412, "training_acc": 65.0, "val_loss": 257.49560546875, "val_acc": 40.0}
{"epoch": 35, "training_loss": 216.2169677734375, "training_acc": 50.0, "val_loss": 22.136398315429688, "val_acc": 60.0}
{"epoch": 36, "training_loss": 69.49840621948242, "training_acc": 65.0, "val_loss": 311.03106689453125, "val_acc": 60.0}
{"epoch": 37, "training_loss": 330.8709411621094, "training_acc": 50.0, "val_loss": 173.1083221435547, "val_acc": 40.0}
{"epoch": 38, "training_loss": 181.442724609375, "training_acc": 50.0, "val_loss": 300.1278381347656, "val_acc": 40.0}
{"epoch": 39, "training_loss": 220.8717819213867, "training_acc": 45.0, "val_loss": 38.96332931518555, "val_acc": 60.0}
{"epoch": 40, "training_loss": 28.880282592773437, "training_acc": 60.0, "val_loss": 209.7689666748047, "val_acc": 40.0}
