"main_modify.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_sex --input_option yAware --learning_rate 1e2 --batch_size 16 --weight_decay 1e-8 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 4235.979581260681, "training_acc": 50.0, "val_loss": 4881.76025390625, "val_acc": 60.0}
{"epoch": 1, "training_loss": 7230.3333984375, "training_acc": 50.0, "val_loss": 19912.337890625, "val_acc": 40.0}
{"epoch": 2, "training_loss": 16103.5203125, "training_acc": 50.0, "val_loss": 8966.7080078125, "val_acc": 40.0}
{"epoch": 3, "training_loss": 7519.391015625, "training_acc": 40.0, "val_loss": 3940.35595703125, "val_acc": 60.0}
{"epoch": 4, "training_loss": 4581.0154296875, "training_acc": 50.0, "val_loss": 1291.6851806640625, "val_acc": 40.0}
{"epoch": 5, "training_loss": 1438.290380859375, "training_acc": 50.0, "val_loss": 754.4619140625, "val_acc": 60.0}
{"epoch": 6, "training_loss": 920.411865234375, "training_acc": 50.0, "val_loss": 1793.2132568359375, "val_acc": 40.0}
{"epoch": 7, "training_loss": 1498.122412109375, "training_acc": 50.0, "val_loss": 1736.2158203125, "val_acc": 60.0}
{"epoch": 8, "training_loss": 2448.9076171875, "training_acc": 50.0, "val_loss": 677.3724975585938, "val_acc": 60.0}
{"epoch": 9, "training_loss": 1849.688671875, "training_acc": 40.0, "val_loss": 5607.56494140625, "val_acc": 40.0}
{"epoch": 10, "training_loss": 4521.95810546875, "training_acc": 50.0, "val_loss": 490.40313720703125, "val_acc": 40.0}
{"epoch": 11, "training_loss": 1638.875390625, "training_acc": 40.0, "val_loss": 4230.53662109375, "val_acc": 60.0}
{"epoch": 12, "training_loss": 4959.5634765625, "training_acc": 50.0, "val_loss": 829.5154418945312, "val_acc": 60.0}
{"epoch": 13, "training_loss": 1515.426318359375, "training_acc": 50.0, "val_loss": 7222.7734375, "val_acc": 40.0}
{"epoch": 14, "training_loss": 6126.326953125, "training_acc": 50.0, "val_loss": 4208.35888671875, "val_acc": 40.0}
{"epoch": 15, "training_loss": 3535.488720703125, "training_acc": 40.0, "val_loss": 1933.1376953125, "val_acc": 60.0}
{"epoch": 16, "training_loss": 2140.71328125, "training_acc": 50.0, "val_loss": 1306.4754638671875, "val_acc": 40.0}
{"epoch": 17, "training_loss": 1122.9711547851562, "training_acc": 50.0, "val_loss": 656.4840698242188, "val_acc": 40.0}
{"epoch": 18, "training_loss": 1199.9673828125, "training_acc": 40.0, "val_loss": 1584.8668212890625, "val_acc": 60.0}
{"epoch": 19, "training_loss": 1311.7357051849365, "training_acc": 60.0, "val_loss": 932.2257690429688, "val_acc": 40.0}
{"epoch": 20, "training_loss": 573.533935546875, "training_acc": 65.0, "val_loss": 828.8155517578125, "val_acc": 60.0}
{"epoch": 21, "training_loss": 651.7592742919921, "training_acc": 60.0, "val_loss": 2040.715087890625, "val_acc": 40.0}
{"epoch": 22, "training_loss": 1641.091650390625, "training_acc": 50.0, "val_loss": 709.9260864257812, "val_acc": 60.0}
{"epoch": 23, "training_loss": 739.4162445068359, "training_acc": 50.0, "val_loss": 471.8959655761719, "val_acc": 40.0}
{"epoch": 24, "training_loss": 411.53668212890625, "training_acc": 50.0, "val_loss": 674.7907104492188, "val_acc": 40.0}
{"epoch": 25, "training_loss": 417.31962890625, "training_acc": 65.0, "val_loss": 624.7975463867188, "val_acc": 60.0}
{"epoch": 26, "training_loss": 845.428076171875, "training_acc": 40.0, "val_loss": 487.58941650390625, "val_acc": 60.0}
{"epoch": 27, "training_loss": 383.317667388916, "training_acc": 50.0, "val_loss": 1127.4285888671875, "val_acc": 60.0}
{"epoch": 28, "training_loss": 1108.4736083984376, "training_acc": 50.0, "val_loss": 2899.908203125, "val_acc": 40.0}
{"epoch": 29, "training_loss": 2700.71162109375, "training_acc": 50.0, "val_loss": 2941.679443359375, "val_acc": 40.0}
{"epoch": 30, "training_loss": 2064.6872314453126, "training_acc": 50.0, "val_loss": 863.2236328125, "val_acc": 60.0}
{"epoch": 31, "training_loss": 998.9005249023437, "training_acc": 40.0, "val_loss": 720.9589233398438, "val_acc": 60.0}
{"epoch": 32, "training_loss": 618.9732157237828, "training_acc": 55.0, "val_loss": 602.2680053710938, "val_acc": 40.0}
{"epoch": 33, "training_loss": 501.423974609375, "training_acc": 50.0, "val_loss": 151.51121520996094, "val_acc": 60.0}
{"epoch": 34, "training_loss": 406.8424530029297, "training_acc": 70.0, "val_loss": 474.23126220703125, "val_acc": 60.0}
{"epoch": 35, "training_loss": 342.2229248046875, "training_acc": 45.0, "val_loss": 1086.6785888671875, "val_acc": 60.0}
{"epoch": 36, "training_loss": 962.5768676757813, "training_acc": 50.0, "val_loss": 2348.852294921875, "val_acc": 40.0}
{"epoch": 37, "training_loss": 2123.4306640625, "training_acc": 50.0, "val_loss": 816.1659545898438, "val_acc": 40.0}
{"epoch": 38, "training_loss": 772.3695556640625, "training_acc": 60.0, "val_loss": 3565.563720703125, "val_acc": 60.0}
{"epoch": 39, "training_loss": 4195.276171875, "training_acc": 50.0, "val_loss": 1080.943115234375, "val_acc": 60.0}
{"epoch": 40, "training_loss": 1120.0829345703125, "training_acc": 60.0, "val_loss": 7425.9501953125, "val_acc": 40.0}
{"epoch": 41, "training_loss": 6567.7482421875, "training_acc": 50.0, "val_loss": 6012.6796875, "val_acc": 40.0}
{"epoch": 42, "training_loss": 4309.3880615234375, "training_acc": 50.0, "val_loss": 3634.78369140625, "val_acc": 60.0}
{"epoch": 43, "training_loss": 4875.5732421875, "training_acc": 50.0, "val_loss": 6634.36474609375, "val_acc": 60.0}
{"epoch": 44, "training_loss": 7666.28984375, "training_acc": 50.0, "val_loss": 2852.351318359375, "val_acc": 60.0}
{"epoch": 45, "training_loss": 3427.1740234375, "training_acc": 40.0, "val_loss": 3955.100830078125, "val_acc": 40.0}
{"epoch": 46, "training_loss": 3290.7726318359373, "training_acc": 50.0, "val_loss": 959.66650390625, "val_acc": 40.0}
{"epoch": 47, "training_loss": 1611.74384765625, "training_acc": 40.0, "val_loss": 2677.773681640625, "val_acc": 60.0}
{"epoch": 48, "training_loss": 2677.32236328125, "training_acc": 50.0, "val_loss": 2105.67236328125, "val_acc": 40.0}
{"epoch": 49, "training_loss": 2510.646484375, "training_acc": 50.0, "val_loss": 1032.0235595703125, "val_acc": 40.0}
{"epoch": 50, "training_loss": 1424.563671875, "training_acc": 50.0, "val_loss": 4175.86865234375, "val_acc": 60.0}
{"epoch": 51, "training_loss": 4831.0759765625, "training_acc": 50.0, "val_loss": 1650.5032958984375, "val_acc": 60.0}
{"epoch": 52, "training_loss": 1857.0953125, "training_acc": 50.0, "val_loss": 5886.52734375, "val_acc": 40.0}
