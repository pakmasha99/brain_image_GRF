"main_modify.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 4 --task ADNI_sex --input_option yAware --learning_rate 1e2 --batch_size 16 --weight_decay 1e-8 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 4260.217165756226, "training_acc": 50.0, "val_loss": 7212.46435546875, "val_acc": 40.0}
{"epoch": 1, "training_loss": 9005.06484375, "training_acc": 40.0, "val_loss": 11039.080078125, "val_acc": 60.0}
{"epoch": 2, "training_loss": 13335.41826171875, "training_acc": 50.0, "val_loss": 3037.0517578125, "val_acc": 60.0}
{"epoch": 3, "training_loss": 4991.966015625, "training_acc": 40.0, "val_loss": 8647.4873046875, "val_acc": 40.0}
{"epoch": 4, "training_loss": 7195.07421875, "training_acc": 50.0, "val_loss": 3225.931884765625, "val_acc": 40.0}
{"epoch": 5, "training_loss": 2049.411669921875, "training_acc": 60.0, "val_loss": 3442.576904296875, "val_acc": 60.0}
{"epoch": 6, "training_loss": 4135.244091796875, "training_acc": 50.0, "val_loss": 752.7510375976562, "val_acc": 60.0}
{"epoch": 7, "training_loss": 2024.826025390625, "training_acc": 40.0, "val_loss": 5519.98828125, "val_acc": 40.0}
{"epoch": 8, "training_loss": 4043.87890625, "training_acc": 50.0, "val_loss": 1810.184814453125, "val_acc": 60.0}
{"epoch": 9, "training_loss": 2365.06181640625, "training_acc": 50.0, "val_loss": 3700.032958984375, "val_acc": 60.0}
{"epoch": 10, "training_loss": 4158.5005859375, "training_acc": 50.0, "val_loss": 1452.3856201171875, "val_acc": 40.0}
{"epoch": 11, "training_loss": 1279.6862548828126, "training_acc": 50.0, "val_loss": 2296.941650390625, "val_acc": 40.0}
{"epoch": 12, "training_loss": 1605.662744140625, "training_acc": 50.0, "val_loss": 460.5283203125, "val_acc": 60.0}
{"epoch": 13, "training_loss": 993.838671875, "training_acc": 40.0, "val_loss": 1120.953857421875, "val_acc": 40.0}
{"epoch": 14, "training_loss": 1156.2296875, "training_acc": 50.0, "val_loss": 2224.633544921875, "val_acc": 60.0}
{"epoch": 15, "training_loss": 2344.5796508789062, "training_acc": 50.0, "val_loss": 2871.4013671875, "val_acc": 40.0}
{"epoch": 16, "training_loss": 2561.00341796875, "training_acc": 50.0, "val_loss": 2772.547607421875, "val_acc": 40.0}
{"epoch": 17, "training_loss": 2749.25419921875, "training_acc": 30.0, "val_loss": 402.97296142578125, "val_acc": 60.0}
{"epoch": 18, "training_loss": 483.86884765625, "training_acc": 60.0, "val_loss": 4071.401123046875, "val_acc": 40.0}
{"epoch": 19, "training_loss": 3247.1826171875, "training_acc": 50.0, "val_loss": 285.40045166015625, "val_acc": 40.0}
{"epoch": 20, "training_loss": 1331.3885498046875, "training_acc": 40.0, "val_loss": 3666.062255859375, "val_acc": 60.0}
{"epoch": 21, "training_loss": 4105.32998046875, "training_acc": 50.0, "val_loss": 261.5400390625, "val_acc": 40.0}
{"epoch": 22, "training_loss": 363.707958984375, "training_acc": 50.0, "val_loss": 107.68145751953125, "val_acc": 60.0}
{"epoch": 23, "training_loss": 155.00212936401368, "training_acc": 70.0, "val_loss": 119.17952728271484, "val_acc": 40.0}
{"epoch": 24, "training_loss": 38.03824157714844, "training_acc": 65.0, "val_loss": 847.0924072265625, "val_acc": 60.0}
{"epoch": 25, "training_loss": 1124.9649169921875, "training_acc": 30.0, "val_loss": 1610.039306640625, "val_acc": 60.0}
{"epoch": 26, "training_loss": 1811.244921875, "training_acc": 50.0, "val_loss": 1330.1510009765625, "val_acc": 60.0}
{"epoch": 27, "training_loss": 1266.3684631347655, "training_acc": 50.0, "val_loss": 587.7332763671875, "val_acc": 40.0}
{"epoch": 28, "training_loss": 610.8234619140625, "training_acc": 50.0, "val_loss": 1205.2164306640625, "val_acc": 60.0}
{"epoch": 29, "training_loss": 940.5394439697266, "training_acc": 60.0, "val_loss": 1380.753662109375, "val_acc": 40.0}
{"epoch": 30, "training_loss": 1050.6437866210938, "training_acc": 40.0, "val_loss": 1244.80859375, "val_acc": 40.0}
{"epoch": 31, "training_loss": 878.3608139038085, "training_acc": 50.0, "val_loss": 1367.10888671875, "val_acc": 60.0}
{"epoch": 32, "training_loss": 1416.118798828125, "training_acc": 50.0, "val_loss": 1365.564697265625, "val_acc": 40.0}
{"epoch": 33, "training_loss": 1051.9201538085938, "training_acc": 50.0, "val_loss": 149.0960235595703, "val_acc": 40.0}
{"epoch": 34, "training_loss": 36.26781463623047, "training_acc": 75.0, "val_loss": 1085.0858154296875, "val_acc": 40.0}
{"epoch": 35, "training_loss": 701.1861389160156, "training_acc": 50.0, "val_loss": 962.6871337890625, "val_acc": 40.0}
{"epoch": 36, "training_loss": 637.4132720947266, "training_acc": 55.0, "val_loss": 288.4500427246094, "val_acc": 60.0}
{"epoch": 37, "training_loss": 85.17222900390625, "training_acc": 80.0, "val_loss": 2036.081298828125, "val_acc": 40.0}
{"epoch": 38, "training_loss": 1592.2622283935548, "training_acc": 45.0, "val_loss": 515.2904663085938, "val_acc": 60.0}
{"epoch": 39, "training_loss": 309.7174133300781, "training_acc": 60.0, "val_loss": 1119.758056640625, "val_acc": 40.0}
{"epoch": 40, "training_loss": 643.7269592285156, "training_acc": 60.0, "val_loss": 1017.6578369140625, "val_acc": 60.0}
{"epoch": 41, "training_loss": 595.0435546875, "training_acc": 70.0, "val_loss": 1228.466796875, "val_acc": 40.0}
