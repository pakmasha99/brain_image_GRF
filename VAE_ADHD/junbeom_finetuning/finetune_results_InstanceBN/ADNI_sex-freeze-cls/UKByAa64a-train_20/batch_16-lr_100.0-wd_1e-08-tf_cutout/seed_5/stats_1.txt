"main_modify.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 5 --task ADNI_sex --input_option yAware --learning_rate 1e2 --batch_size 16 --weight_decay 1e-8 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 4277.854283285141, "training_acc": 45.0, "val_loss": 9353.0498046875, "val_acc": 40.0}
{"epoch": 1, "training_loss": 5569.803515625, "training_acc": 65.0, "val_loss": 13429.7841796875, "val_acc": 60.0}
{"epoch": 2, "training_loss": 18139.6009765625, "training_acc": 45.0, "val_loss": 6780.70654296875, "val_acc": 60.0}
{"epoch": 3, "training_loss": 6835.14917602539, "training_acc": 55.0, "val_loss": 7401.63916015625, "val_acc": 40.0}
{"epoch": 4, "training_loss": 5573.599267578125, "training_acc": 55.0, "val_loss": 5180.21044921875, "val_acc": 40.0}
{"epoch": 5, "training_loss": 2642.0839660644533, "training_acc": 65.0, "val_loss": 2036.662109375, "val_acc": 60.0}
{"epoch": 6, "training_loss": 2534.429379272461, "training_acc": 35.0, "val_loss": 2024.5941162109375, "val_acc": 60.0}
{"epoch": 7, "training_loss": 2513.982080078125, "training_acc": 45.0, "val_loss": 2960.522216796875, "val_acc": 40.0}
{"epoch": 8, "training_loss": 2282.04111328125, "training_acc": 55.0, "val_loss": 2584.4169921875, "val_acc": 40.0}
{"epoch": 9, "training_loss": 1715.4921997070312, "training_acc": 55.0, "val_loss": 931.1400756835938, "val_acc": 60.0}
{"epoch": 10, "training_loss": 1042.8366577148438, "training_acc": 55.0, "val_loss": 2785.724365234375, "val_acc": 40.0}
{"epoch": 11, "training_loss": 1772.81513671875, "training_acc": 55.0, "val_loss": 3203.588623046875, "val_acc": 60.0}
{"epoch": 12, "training_loss": 4791.87353515625, "training_acc": 45.0, "val_loss": 4654.79052734375, "val_acc": 60.0}
{"epoch": 13, "training_loss": 5538.1541015625, "training_acc": 45.0, "val_loss": 3195.840576171875, "val_acc": 40.0}
{"epoch": 14, "training_loss": 2389.8396484375, "training_acc": 55.0, "val_loss": 9176.486328125, "val_acc": 40.0}
{"epoch": 15, "training_loss": 6859.9796875, "training_acc": 55.0, "val_loss": 7480.17724609375, "val_acc": 40.0}
{"epoch": 16, "training_loss": 5265.070849609375, "training_acc": 55.0, "val_loss": 1122.4617919921875, "val_acc": 60.0}
{"epoch": 17, "training_loss": 1726.14228515625, "training_acc": 45.0, "val_loss": 1180.040283203125, "val_acc": 60.0}
{"epoch": 18, "training_loss": 2108.39462890625, "training_acc": 35.0, "val_loss": 2891.06982421875, "val_acc": 40.0}
{"epoch": 19, "training_loss": 1678.9579345703125, "training_acc": 55.0, "val_loss": 3012.608642578125, "val_acc": 60.0}
{"epoch": 20, "training_loss": 4690.7216796875, "training_acc": 45.0, "val_loss": 3482.546875, "val_acc": 60.0}
{"epoch": 21, "training_loss": 3962.557507324219, "training_acc": 45.0, "val_loss": 5585.9140625, "val_acc": 40.0}
{"epoch": 22, "training_loss": 5609.387890625, "training_acc": 55.0, "val_loss": 8623.919921875, "val_acc": 40.0}
{"epoch": 23, "training_loss": 6171.2130859375, "training_acc": 55.0, "val_loss": 551.705078125, "val_acc": 40.0}
{"epoch": 24, "training_loss": 2443.291943359375, "training_acc": 35.0, "val_loss": 4912.8056640625, "val_acc": 60.0}
{"epoch": 25, "training_loss": 6400.0146484375, "training_acc": 45.0, "val_loss": 1140.4215087890625, "val_acc": 60.0}
{"epoch": 26, "training_loss": 1970.75009765625, "training_acc": 45.0, "val_loss": 7668.35498046875, "val_acc": 40.0}
{"epoch": 27, "training_loss": 6214.630078125, "training_acc": 55.0, "val_loss": 5552.94140625, "val_acc": 40.0}
{"epoch": 28, "training_loss": 3704.77734375, "training_acc": 60.0, "val_loss": 3274.83203125, "val_acc": 60.0}
{"epoch": 29, "training_loss": 4711.70966796875, "training_acc": 45.0, "val_loss": 3998.96484375, "val_acc": 60.0}
{"epoch": 30, "training_loss": 4651.253515625, "training_acc": 45.0, "val_loss": 3259.154541015625, "val_acc": 40.0}
{"epoch": 31, "training_loss": 3030.4638671875, "training_acc": 55.0, "val_loss": 7706.57275390625, "val_acc": 40.0}
{"epoch": 32, "training_loss": 5542.78515625, "training_acc": 55.0, "val_loss": 2806.43994140625, "val_acc": 40.0}
{"epoch": 33, "training_loss": 2009.3215576171874, "training_acc": 55.0, "val_loss": 3187.206787109375, "val_acc": 60.0}
{"epoch": 34, "training_loss": 4208.52314453125, "training_acc": 45.0, "val_loss": 880.8076171875, "val_acc": 60.0}
{"epoch": 35, "training_loss": 2055.55166015625, "training_acc": 35.0, "val_loss": 5526.15625, "val_acc": 40.0}
{"epoch": 36, "training_loss": 4016.4802734375, "training_acc": 55.0, "val_loss": 1595.1190185546875, "val_acc": 40.0}
{"epoch": 37, "training_loss": 631.86552734375, "training_acc": 75.0, "val_loss": 4329.10009765625, "val_acc": 60.0}
{"epoch": 38, "training_loss": 6314.87734375, "training_acc": 45.0, "val_loss": 2930.43603515625, "val_acc": 60.0}
{"epoch": 39, "training_loss": 3951.1109375, "training_acc": 35.0, "val_loss": 3461.448486328125, "val_acc": 40.0}
{"epoch": 40, "training_loss": 2536.09150390625, "training_acc": 55.0, "val_loss": 1060.4437255859375, "val_acc": 40.0}
{"epoch": 41, "training_loss": 968.3008056640625, "training_acc": 55.0, "val_loss": 2239.921142578125, "val_acc": 60.0}
{"epoch": 42, "training_loss": 2678.152490234375, "training_acc": 45.0, "val_loss": 2351.294189453125, "val_acc": 40.0}
