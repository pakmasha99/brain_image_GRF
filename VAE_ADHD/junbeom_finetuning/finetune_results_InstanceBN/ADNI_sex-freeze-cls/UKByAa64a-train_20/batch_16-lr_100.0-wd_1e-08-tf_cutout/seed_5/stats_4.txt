"main_modify.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 5 --task ADNI_sex --input_option yAware --learning_rate 1e2 --batch_size 16 --weight_decay 1e-8 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 4291.579056930542, "training_acc": 50.0, "val_loss": 7205.7861328125, "val_acc": 60.0}
{"epoch": 1, "training_loss": 7003.209814453125, "training_acc": 60.0, "val_loss": 18244.96484375, "val_acc": 40.0}
{"epoch": 2, "training_loss": 15039.59892578125, "training_acc": 50.0, "val_loss": 10742.220703125, "val_acc": 40.0}
{"epoch": 3, "training_loss": 7265.17255859375, "training_acc": 50.0, "val_loss": 8639.3388671875, "val_acc": 60.0}
{"epoch": 4, "training_loss": 11213.8724609375, "training_acc": 50.0, "val_loss": 13900.140625, "val_acc": 60.0}
{"epoch": 5, "training_loss": 16856.94453125, "training_acc": 50.0, "val_loss": 7886.7470703125, "val_acc": 60.0}
{"epoch": 6, "training_loss": 8968.769738769532, "training_acc": 50.0, "val_loss": 9417.6005859375, "val_acc": 40.0}
{"epoch": 7, "training_loss": 8867.593359375, "training_acc": 50.0, "val_loss": 17266.822265625, "val_acc": 40.0}
{"epoch": 8, "training_loss": 14206.66630859375, "training_acc": 50.0, "val_loss": 11613.619140625, "val_acc": 40.0}
{"epoch": 9, "training_loss": 8183.3548828125, "training_acc": 50.0, "val_loss": 2681.043212890625, "val_acc": 60.0}
{"epoch": 10, "training_loss": 3738.25107421875, "training_acc": 50.0, "val_loss": 8223.697265625, "val_acc": 60.0}
{"epoch": 11, "training_loss": 10181.091796875, "training_acc": 50.0, "val_loss": 6562.29541015625, "val_acc": 60.0}
{"epoch": 12, "training_loss": 7052.573046875, "training_acc": 50.0, "val_loss": 2477.07080078125, "val_acc": 40.0}
{"epoch": 13, "training_loss": 2355.6935546875, "training_acc": 50.0, "val_loss": 8615.052734375, "val_acc": 40.0}
{"epoch": 14, "training_loss": 7031.906787109375, "training_acc": 50.0, "val_loss": 4922.74853515625, "val_acc": 40.0}
{"epoch": 15, "training_loss": 3255.655895996094, "training_acc": 50.0, "val_loss": 1182.2293701171875, "val_acc": 60.0}
{"epoch": 16, "training_loss": 1247.68349609375, "training_acc": 50.0, "val_loss": 4501.79052734375, "val_acc": 40.0}
{"epoch": 17, "training_loss": 4381.0154296875, "training_acc": 50.0, "val_loss": 6008.72607421875, "val_acc": 40.0}
{"epoch": 18, "training_loss": 4300.08232421875, "training_acc": 50.0, "val_loss": 2510.053466796875, "val_acc": 60.0}
{"epoch": 19, "training_loss": 3858.78203125, "training_acc": 50.0, "val_loss": 3921.937255859375, "val_acc": 60.0}
{"epoch": 20, "training_loss": 4269.718017578125, "training_acc": 50.0, "val_loss": 3211.935302734375, "val_acc": 40.0}
{"epoch": 21, "training_loss": 2577.204296875, "training_acc": 50.0, "val_loss": 6835.91650390625, "val_acc": 40.0}
{"epoch": 22, "training_loss": 5495.195556640625, "training_acc": 50.0, "val_loss": 3060.83642578125, "val_acc": 40.0}
{"epoch": 23, "training_loss": 2681.892919921875, "training_acc": 40.0, "val_loss": 1819.1673583984375, "val_acc": 60.0}
{"epoch": 24, "training_loss": 2046.4789031982423, "training_acc": 50.0, "val_loss": 2617.234619140625, "val_acc": 40.0}
{"epoch": 25, "training_loss": 2095.81064453125, "training_acc": 50.0, "val_loss": 796.1693115234375, "val_acc": 40.0}
{"epoch": 26, "training_loss": 977.79541015625, "training_acc": 50.0, "val_loss": 3474.09619140625, "val_acc": 60.0}
{"epoch": 27, "training_loss": 4076.89267578125, "training_acc": 50.0, "val_loss": 348.7870788574219, "val_acc": 60.0}
{"epoch": 28, "training_loss": 1636.784228515625, "training_acc": 40.0, "val_loss": 7072.5126953125, "val_acc": 40.0}
{"epoch": 29, "training_loss": 5593.01689453125, "training_acc": 50.0, "val_loss": 2601.414794921875, "val_acc": 40.0}
{"epoch": 30, "training_loss": 2106.354296875, "training_acc": 50.0, "val_loss": 3659.05712890625, "val_acc": 60.0}
{"epoch": 31, "training_loss": 4505.4869140625, "training_acc": 50.0, "val_loss": 1303.6431884765625, "val_acc": 60.0}
{"epoch": 32, "training_loss": 1366.420947265625, "training_acc": 60.0, "val_loss": 7137.5986328125, "val_acc": 40.0}
{"epoch": 33, "training_loss": 6033.410546875, "training_acc": 50.0, "val_loss": 5556.90625, "val_acc": 40.0}
{"epoch": 34, "training_loss": 3611.5843505859375, "training_acc": 50.0, "val_loss": 4174.21630859375, "val_acc": 60.0}
{"epoch": 35, "training_loss": 5417.402001953125, "training_acc": 50.0, "val_loss": 7705.86279296875, "val_acc": 60.0}
{"epoch": 36, "training_loss": 9364.589453125, "training_acc": 50.0, "val_loss": 5005.482421875, "val_acc": 60.0}
{"epoch": 37, "training_loss": 5245.569580078125, "training_acc": 50.0, "val_loss": 5221.52099609375, "val_acc": 40.0}
{"epoch": 38, "training_loss": 5259.6931640625, "training_acc": 50.0, "val_loss": 9914.888671875, "val_acc": 40.0}
{"epoch": 39, "training_loss": 7668.59345703125, "training_acc": 50.0, "val_loss": 3133.100341796875, "val_acc": 40.0}
{"epoch": 40, "training_loss": 2505.749560546875, "training_acc": 50.0, "val_loss": 4546.28369140625, "val_acc": 60.0}
{"epoch": 41, "training_loss": 5565.85009765625, "training_acc": 50.0, "val_loss": 4069.03515625, "val_acc": 60.0}
{"epoch": 42, "training_loss": 4188.13095703125, "training_acc": 50.0, "val_loss": 3429.650390625, "val_acc": 40.0}
{"epoch": 43, "training_loss": 2880.388671875, "training_acc": 50.0, "val_loss": 7952.21240234375, "val_acc": 40.0}
{"epoch": 44, "training_loss": 6264.799267578125, "training_acc": 50.0, "val_loss": 3922.014892578125, "val_acc": 40.0}
{"epoch": 45, "training_loss": 2530.7662353515625, "training_acc": 50.0, "val_loss": 1807.2503662109375, "val_acc": 60.0}
{"epoch": 46, "training_loss": 2010.085693359375, "training_acc": 50.0, "val_loss": 2000.930908203125, "val_acc": 40.0}
