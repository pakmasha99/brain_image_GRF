"main_modify.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 3 --task ADNI_sex --input_option yAware --learning_rate 1e2 --batch_size 16 --weight_decay 1e-8 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 4283.243156242371, "training_acc": 50.0, "val_loss": 9822.193359375, "val_acc": 40.0}
{"epoch": 1, "training_loss": 10001.625390625, "training_acc": 40.0, "val_loss": 7887.2978515625, "val_acc": 60.0}
{"epoch": 2, "training_loss": 9407.202001953125, "training_acc": 50.0, "val_loss": 1087.2684326171875, "val_acc": 40.0}
{"epoch": 3, "training_loss": 1308.265576171875, "training_acc": 50.0, "val_loss": 1420.4072265625, "val_acc": 60.0}
{"epoch": 4, "training_loss": 1841.795458984375, "training_acc": 50.0, "val_loss": 1093.9114990234375, "val_acc": 40.0}
{"epoch": 5, "training_loss": 777.9236389160156, "training_acc": 50.0, "val_loss": 2160.403076171875, "val_acc": 60.0}
{"epoch": 6, "training_loss": 2751.16884765625, "training_acc": 50.0, "val_loss": 80.53081512451172, "val_acc": 60.0}
{"epoch": 7, "training_loss": 1618.7106201171875, "training_acc": 40.0, "val_loss": 6909.65869140625, "val_acc": 40.0}
{"epoch": 8, "training_loss": 5454.278491210937, "training_acc": 50.0, "val_loss": 920.29541015625, "val_acc": 40.0}
{"epoch": 9, "training_loss": 876.18564453125, "training_acc": 60.0, "val_loss": 5573.79150390625, "val_acc": 60.0}
{"epoch": 10, "training_loss": 7266.3734375, "training_acc": 50.0, "val_loss": 3923.927490234375, "val_acc": 60.0}
{"epoch": 11, "training_loss": 3663.9612548828127, "training_acc": 50.0, "val_loss": 7892.05712890625, "val_acc": 40.0}
{"epoch": 12, "training_loss": 7817.41953125, "training_acc": 50.0, "val_loss": 14227.3662109375, "val_acc": 40.0}
{"epoch": 13, "training_loss": 11429.27421875, "training_acc": 50.0, "val_loss": 8489.9404296875, "val_acc": 40.0}
{"epoch": 14, "training_loss": 5482.551611328125, "training_acc": 50.0, "val_loss": 4040.69775390625, "val_acc": 60.0}
{"epoch": 15, "training_loss": 5608.0568359375, "training_acc": 50.0, "val_loss": 9779.2890625, "val_acc": 60.0}
{"epoch": 16, "training_loss": 12586.59453125, "training_acc": 50.0, "val_loss": 8504.8974609375, "val_acc": 60.0}
{"epoch": 17, "training_loss": 10300.7443359375, "training_acc": 50.0, "val_loss": 973.5746459960938, "val_acc": 60.0}
{"epoch": 18, "training_loss": 2840.291015625, "training_acc": 40.0, "val_loss": 10110.673828125, "val_acc": 40.0}
{"epoch": 19, "training_loss": 8507.3328125, "training_acc": 50.0, "val_loss": 8718.9541015625, "val_acc": 40.0}
{"epoch": 20, "training_loss": 6620.632153320313, "training_acc": 50.0, "val_loss": 1168.4510498046875, "val_acc": 60.0}
{"epoch": 21, "training_loss": 1835.0151123046876, "training_acc": 50.0, "val_loss": 3447.466064453125, "val_acc": 60.0}
{"epoch": 22, "training_loss": 4209.46796875, "training_acc": 50.0, "val_loss": 53.62589645385742, "val_acc": 80.0}
{"epoch": 23, "training_loss": 756.1553283691406, "training_acc": 60.0, "val_loss": 6351.22119140625, "val_acc": 40.0}
{"epoch": 24, "training_loss": 4859.6814453125, "training_acc": 50.0, "val_loss": 1704.561767578125, "val_acc": 40.0}
{"epoch": 25, "training_loss": 1089.9775146484376, "training_acc": 60.0, "val_loss": 5337.12109375, "val_acc": 60.0}
{"epoch": 26, "training_loss": 7253.03828125, "training_acc": 50.0, "val_loss": 4827.68603515625, "val_acc": 60.0}
{"epoch": 27, "training_loss": 5467.3330078125, "training_acc": 50.0, "val_loss": 3517.841064453125, "val_acc": 40.0}
{"epoch": 28, "training_loss": 2796.245849609375, "training_acc": 50.0, "val_loss": 8169.1181640625, "val_acc": 40.0}
{"epoch": 29, "training_loss": 6295.030078125, "training_acc": 50.0, "val_loss": 2619.4404296875, "val_acc": 40.0}
{"epoch": 30, "training_loss": 1637.8425537109374, "training_acc": 60.0, "val_loss": 5880.10791015625, "val_acc": 60.0}
{"epoch": 31, "training_loss": 8131.2451171875, "training_acc": 50.0, "val_loss": 6385.51123046875, "val_acc": 60.0}
{"epoch": 32, "training_loss": 7534.686328125, "training_acc": 50.0, "val_loss": 34.243408203125, "val_acc": 80.0}
{"epoch": 33, "training_loss": 1751.637255859375, "training_acc": 55.0, "val_loss": 9610.009765625, "val_acc": 40.0}
{"epoch": 34, "training_loss": 7603.9166015625, "training_acc": 50.0, "val_loss": 7327.67041015625, "val_acc": 40.0}
{"epoch": 35, "training_loss": 4600.2029296875, "training_acc": 50.0, "val_loss": 2651.560302734375, "val_acc": 60.0}
{"epoch": 36, "training_loss": 4231.54111328125, "training_acc": 50.0, "val_loss": 6410.18017578125, "val_acc": 60.0}
{"epoch": 37, "training_loss": 8045.61953125, "training_acc": 50.0, "val_loss": 3390.376953125, "val_acc": 60.0}
{"epoch": 38, "training_loss": 3188.885693359375, "training_acc": 55.0, "val_loss": 6877.23779296875, "val_acc": 40.0}
{"epoch": 39, "training_loss": 6378.240234375, "training_acc": 50.0, "val_loss": 11371.3232421875, "val_acc": 40.0}
{"epoch": 40, "training_loss": 8521.08515625, "training_acc": 50.0, "val_loss": 4235.8681640625, "val_acc": 40.0}
{"epoch": 41, "training_loss": 2962.3111328125, "training_acc": 50.0, "val_loss": 4418.0205078125, "val_acc": 60.0}
{"epoch": 42, "training_loss": 5979.73759765625, "training_acc": 50.0, "val_loss": 4390.0634765625, "val_acc": 60.0}
{"epoch": 43, "training_loss": 4909.76572265625, "training_acc": 50.0, "val_loss": 2843.29736328125, "val_acc": 40.0}
{"epoch": 44, "training_loss": 2098.8384765625, "training_acc": 50.0, "val_loss": 7637.74853515625, "val_acc": 40.0}
{"epoch": 45, "training_loss": 5681.88876953125, "training_acc": 50.0, "val_loss": 3534.565673828125, "val_acc": 40.0}
{"epoch": 46, "training_loss": 2132.0893310546876, "training_acc": 50.0, "val_loss": 2499.5, "val_acc": 60.0}
{"epoch": 47, "training_loss": 3361.31884765625, "training_acc": 50.0, "val_loss": 121.0989990234375, "val_acc": 60.0}
{"epoch": 48, "training_loss": 978.7048828125, "training_acc": 55.0, "val_loss": 7165.08740234375, "val_acc": 40.0}
{"epoch": 49, "training_loss": 5410.1986328125, "training_acc": 50.0, "val_loss": 4335.07177734375, "val_acc": 40.0}
{"epoch": 50, "training_loss": 3024.43466796875, "training_acc": 40.0, "val_loss": 829.3341674804688, "val_acc": 60.0}
{"epoch": 51, "training_loss": 1175.6822875976563, "training_acc": 50.0, "val_loss": 3054.68408203125, "val_acc": 40.0}
