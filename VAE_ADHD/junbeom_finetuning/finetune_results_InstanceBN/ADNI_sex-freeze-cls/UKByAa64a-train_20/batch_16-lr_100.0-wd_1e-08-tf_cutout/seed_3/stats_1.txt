"main_modify.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 3 --task ADNI_sex --input_option yAware --learning_rate 1e2 --batch_size 16 --weight_decay 1e-8 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 6418.210332393646, "training_acc": 40.0, "val_loss": 7125.04833984375, "val_acc": 60.0}
{"epoch": 1, "training_loss": 8430.0580078125, "training_acc": 50.0, "val_loss": 14251.4970703125, "val_acc": 40.0}
{"epoch": 2, "training_loss": 11702.050390625, "training_acc": 50.0, "val_loss": 6709.91943359375, "val_acc": 40.0}
{"epoch": 3, "training_loss": 4150.272436523437, "training_acc": 60.0, "val_loss": 5733.68701171875, "val_acc": 60.0}
{"epoch": 4, "training_loss": 7248.6265625, "training_acc": 50.0, "val_loss": 3680.76220703125, "val_acc": 60.0}
{"epoch": 5, "training_loss": 3292.7798400878905, "training_acc": 60.0, "val_loss": 4802.39892578125, "val_acc": 40.0}
{"epoch": 6, "training_loss": 3955.57216796875, "training_acc": 50.0, "val_loss": 632.3307495117188, "val_acc": 40.0}
{"epoch": 7, "training_loss": 847.85322265625, "training_acc": 60.0, "val_loss": 6459.7041015625, "val_acc": 60.0}
{"epoch": 8, "training_loss": 8206.5806640625, "training_acc": 50.0, "val_loss": 4008.050537109375, "val_acc": 60.0}
{"epoch": 9, "training_loss": 4137.504296875, "training_acc": 50.0, "val_loss": 3726.323486328125, "val_acc": 40.0}
{"epoch": 10, "training_loss": 3061.523046875, "training_acc": 50.0, "val_loss": 924.6767578125, "val_acc": 40.0}
{"epoch": 11, "training_loss": 845.0150146484375, "training_acc": 60.0, "val_loss": 3991.026123046875, "val_acc": 60.0}
{"epoch": 12, "training_loss": 4902.123046875, "training_acc": 50.0, "val_loss": 1689.594970703125, "val_acc": 60.0}
{"epoch": 13, "training_loss": 1266.3025390625, "training_acc": 70.0, "val_loss": 5635.0087890625, "val_acc": 40.0}
{"epoch": 14, "training_loss": 4764.095703125, "training_acc": 50.0, "val_loss": 4583.35400390625, "val_acc": 40.0}
{"epoch": 15, "training_loss": 3187.0476928710937, "training_acc": 50.0, "val_loss": 3899.663818359375, "val_acc": 60.0}
{"epoch": 16, "training_loss": 5086.9677734375, "training_acc": 50.0, "val_loss": 6221.26171875, "val_acc": 60.0}
{"epoch": 17, "training_loss": 7324.306640625, "training_acc": 50.0, "val_loss": 1217.5872802734375, "val_acc": 60.0}
{"epoch": 18, "training_loss": 2195.7001953125, "training_acc": 50.0, "val_loss": 10206.462890625, "val_acc": 40.0}
{"epoch": 19, "training_loss": 8750.6310546875, "training_acc": 50.0, "val_loss": 9525.8544921875, "val_acc": 40.0}
{"epoch": 20, "training_loss": 7302.6091796875, "training_acc": 50.0, "val_loss": 799.3851318359375, "val_acc": 60.0}
{"epoch": 21, "training_loss": 1927.6455078125, "training_acc": 50.0, "val_loss": 2590.645751953125, "val_acc": 60.0}
{"epoch": 22, "training_loss": 2937.11171875, "training_acc": 55.0, "val_loss": 3099.29833984375, "val_acc": 40.0}
{"epoch": 23, "training_loss": 2714.76376953125, "training_acc": 50.0, "val_loss": 1171.388427734375, "val_acc": 40.0}
{"epoch": 24, "training_loss": 1409.42705078125, "training_acc": 50.0, "val_loss": 3249.891845703125, "val_acc": 60.0}
{"epoch": 25, "training_loss": 3873.9630859375, "training_acc": 50.0, "val_loss": 467.8247985839844, "val_acc": 40.0}
{"epoch": 26, "training_loss": 755.7706787109375, "training_acc": 50.0, "val_loss": 957.8663940429688, "val_acc": 40.0}
{"epoch": 27, "training_loss": 1466.350048828125, "training_acc": 40.0, "val_loss": 1516.3900146484375, "val_acc": 60.0}
{"epoch": 28, "training_loss": 1855.2041015625, "training_acc": 40.0, "val_loss": 51.79824447631836, "val_acc": 80.0}
{"epoch": 29, "training_loss": 321.5444091796875, "training_acc": 55.0, "val_loss": 1217.0155029296875, "val_acc": 60.0}
{"epoch": 30, "training_loss": 1566.0171997070313, "training_acc": 50.0, "val_loss": 68.63526153564453, "val_acc": 80.0}
{"epoch": 31, "training_loss": 244.01537475585937, "training_acc": 70.0, "val_loss": 2618.1923828125, "val_acc": 40.0}
{"epoch": 32, "training_loss": 2098.6008392333983, "training_acc": 50.0, "val_loss": 1505.5750732421875, "val_acc": 60.0}
{"epoch": 33, "training_loss": 1975.50732421875, "training_acc": 50.0, "val_loss": 170.66209411621094, "val_acc": 60.0}
{"epoch": 34, "training_loss": 1626.3497314453125, "training_acc": 40.0, "val_loss": 2863.466796875, "val_acc": 40.0}
{"epoch": 35, "training_loss": 1966.326682472229, "training_acc": 55.0, "val_loss": 1175.1719970703125, "val_acc": 60.0}
{"epoch": 36, "training_loss": 1359.281494140625, "training_acc": 50.0, "val_loss": 1953.1942138671875, "val_acc": 40.0}
{"epoch": 37, "training_loss": 1839.1189453125, "training_acc": 50.0, "val_loss": 327.7839050292969, "val_acc": 40.0}
{"epoch": 38, "training_loss": 1315.66552734375, "training_acc": 40.0, "val_loss": 2855.455810546875, "val_acc": 60.0}
{"epoch": 39, "training_loss": 3440.6262084960936, "training_acc": 50.0, "val_loss": 947.1054077148438, "val_acc": 40.0}
{"epoch": 40, "training_loss": 977.6688293457031, "training_acc": 50.0, "val_loss": 161.0606231689453, "val_acc": 60.0}
{"epoch": 41, "training_loss": 1317.6863525390625, "training_acc": 35.0, "val_loss": 887.10205078125, "val_acc": 60.0}
{"epoch": 42, "training_loss": 1233.77373046875, "training_acc": 50.0, "val_loss": 3010.036865234375, "val_acc": 40.0}
{"epoch": 43, "training_loss": 2435.4865234375, "training_acc": 50.0, "val_loss": 1109.4666748046875, "val_acc": 60.0}
{"epoch": 44, "training_loss": 1476.5945556640625, "training_acc": 50.0, "val_loss": 1117.7911376953125, "val_acc": 60.0}
{"epoch": 45, "training_loss": 1215.8763061523437, "training_acc": 50.0, "val_loss": 949.5343627929688, "val_acc": 40.0}
{"epoch": 46, "training_loss": 883.7689208984375, "training_acc": 50.0, "val_loss": 111.4774398803711, "val_acc": 80.0}
{"epoch": 47, "training_loss": 379.1915283203125, "training_acc": 65.0, "val_loss": 372.3176574707031, "val_acc": 60.0}
