"main_modify.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 1 --task ADNI_sex --input_option yAware --learning_rate 1e2 --batch_size 16 --weight_decay 1e-8 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 2114.538725566864, "training_acc": 55.0, "val_loss": 7815.22021484375, "val_acc": 40.0}
{"epoch": 1, "training_loss": 5004.9443359375, "training_acc": 65.0, "val_loss": 14161.546875, "val_acc": 60.0}
{"epoch": 2, "training_loss": 18568.458203125, "training_acc": 45.0, "val_loss": 2686.810546875, "val_acc": 60.0}
{"epoch": 3, "training_loss": 4908.5447265625, "training_acc": 45.0, "val_loss": 18185.701171875, "val_acc": 40.0}
{"epoch": 4, "training_loss": 14125.15, "training_acc": 55.0, "val_loss": 15321.2236328125, "val_acc": 40.0}
{"epoch": 5, "training_loss": 10784.714892578126, "training_acc": 55.0, "val_loss": 1386.302978515625, "val_acc": 60.0}
{"epoch": 6, "training_loss": 2522.571484375, "training_acc": 45.0, "val_loss": 3492.553955078125, "val_acc": 60.0}
{"epoch": 7, "training_loss": 3654.83359375, "training_acc": 45.0, "val_loss": 7059.78125, "val_acc": 40.0}
{"epoch": 8, "training_loss": 5650.341796875, "training_acc": 55.0, "val_loss": 14685.7734375, "val_acc": 40.0}
{"epoch": 9, "training_loss": 11168.951953125, "training_acc": 55.0, "val_loss": 10344.0732421875, "val_acc": 40.0}
{"epoch": 10, "training_loss": 6056.92861328125, "training_acc": 55.0, "val_loss": 3860.094482421875, "val_acc": 60.0}
{"epoch": 11, "training_loss": 6256.38984375, "training_acc": 45.0, "val_loss": 9227.7158203125, "val_acc": 60.0}
{"epoch": 12, "training_loss": 12655.8671875, "training_acc": 45.0, "val_loss": 6199.02294921875, "val_acc": 60.0}
{"epoch": 13, "training_loss": 7484.6279296875, "training_acc": 45.0, "val_loss": 5430.69873046875, "val_acc": 40.0}
{"epoch": 14, "training_loss": 5364.671875, "training_acc": 55.0, "val_loss": 12379.6875, "val_acc": 40.0}
{"epoch": 15, "training_loss": 9064.04453125, "training_acc": 55.0, "val_loss": 8700.33203125, "val_acc": 40.0}
{"epoch": 16, "training_loss": 5665.49326171875, "training_acc": 55.0, "val_loss": 1243.780517578125, "val_acc": 60.0}
{"epoch": 17, "training_loss": 2572.226171875, "training_acc": 45.0, "val_loss": 2887.848388671875, "val_acc": 60.0}
{"epoch": 18, "training_loss": 3466.7609619140626, "training_acc": 45.0, "val_loss": 4427.04248046875, "val_acc": 40.0}
{"epoch": 19, "training_loss": 3910.9779296875, "training_acc": 55.0, "val_loss": 6735.42333984375, "val_acc": 40.0}
{"epoch": 20, "training_loss": 4408.22666015625, "training_acc": 55.0, "val_loss": 631.0245361328125, "val_acc": 60.0}
{"epoch": 21, "training_loss": 1104.3115966796875, "training_acc": 45.0, "val_loss": 1681.999267578125, "val_acc": 60.0}
{"epoch": 22, "training_loss": 2243.421925354004, "training_acc": 45.0, "val_loss": 1635.08740234375, "val_acc": 40.0}
{"epoch": 23, "training_loss": 871.2529296875, "training_acc": 55.0, "val_loss": 1494.7476806640625, "val_acc": 60.0}
{"epoch": 24, "training_loss": 2163.2532958984375, "training_acc": 45.0, "val_loss": 478.28302001953125, "val_acc": 60.0}
{"epoch": 25, "training_loss": 1489.28369140625, "training_acc": 35.0, "val_loss": 3555.64306640625, "val_acc": 40.0}
{"epoch": 26, "training_loss": 2006.9729736328125, "training_acc": 55.0, "val_loss": 1968.59375, "val_acc": 60.0}
{"epoch": 27, "training_loss": 3350.8611328125, "training_acc": 45.0, "val_loss": 2311.859375, "val_acc": 60.0}
{"epoch": 28, "training_loss": 2475.8596618652346, "training_acc": 55.0, "val_loss": 4863.78125, "val_acc": 40.0}
{"epoch": 29, "training_loss": 3540.05048828125, "training_acc": 55.0, "val_loss": 7126.80859375, "val_acc": 40.0}
{"epoch": 30, "training_loss": 4687.11083984375, "training_acc": 55.0, "val_loss": 859.1342163085938, "val_acc": 40.0}
{"epoch": 31, "training_loss": 1134.1934814453125, "training_acc": 55.0, "val_loss": 5891.00390625, "val_acc": 60.0}
{"epoch": 32, "training_loss": 8443.50078125, "training_acc": 45.0, "val_loss": 4380.162109375, "val_acc": 60.0}
{"epoch": 33, "training_loss": 4857.61123046875, "training_acc": 45.0, "val_loss": 6335.22216796875, "val_acc": 40.0}
{"epoch": 34, "training_loss": 4831.69794921875, "training_acc": 55.0, "val_loss": 14463.1845703125, "val_acc": 40.0}
{"epoch": 35, "training_loss": 10825.62890625, "training_acc": 55.0, "val_loss": 13006.1357421875, "val_acc": 40.0}
{"epoch": 36, "training_loss": 8720.10458984375, "training_acc": 55.0, "val_loss": 2220.843505859375, "val_acc": 40.0}
{"epoch": 37, "training_loss": 2641.7287109375, "training_acc": 45.0, "val_loss": 6239.09619140625, "val_acc": 60.0}
{"epoch": 38, "training_loss": 8889.20234375, "training_acc": 45.0, "val_loss": 5498.92529296875, "val_acc": 60.0}
{"epoch": 39, "training_loss": 6788.297265625, "training_acc": 45.0, "val_loss": 2571.722412109375, "val_acc": 40.0}
{"epoch": 40, "training_loss": 1899.414599609375, "training_acc": 55.0, "val_loss": 9065.6298828125, "val_acc": 40.0}
{"epoch": 41, "training_loss": 6509.774609375, "training_acc": 55.0, "val_loss": 6322.14404296875, "val_acc": 40.0}
{"epoch": 42, "training_loss": 3937.976904296875, "training_acc": 55.0, "val_loss": 3043.046142578125, "val_acc": 60.0}
{"epoch": 43, "training_loss": 5027.028125, "training_acc": 45.0, "val_loss": 4392.6064453125, "val_acc": 60.0}
