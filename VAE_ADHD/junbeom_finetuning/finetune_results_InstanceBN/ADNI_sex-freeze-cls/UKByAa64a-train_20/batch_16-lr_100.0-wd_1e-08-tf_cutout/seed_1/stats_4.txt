"main_modify.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 1 --task ADNI_sex --input_option yAware --learning_rate 1e2 --batch_size 16 --weight_decay 1e-8 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 8528.889673042297, "training_acc": 50.0, "val_loss": 8052.734375, "val_acc": 40.0}
{"epoch": 1, "training_loss": 4019.40859375, "training_acc": 70.0, "val_loss": 17054.396484375, "val_acc": 60.0}
{"epoch": 2, "training_loss": 21314.396875, "training_acc": 50.0, "val_loss": 21962.109375, "val_acc": 60.0}
{"epoch": 3, "training_loss": 27019.38125, "training_acc": 50.0, "val_loss": 15943.3310546875, "val_acc": 60.0}
{"epoch": 4, "training_loss": 19012.5458984375, "training_acc": 50.0, "val_loss": 1356.7001953125, "val_acc": 60.0}
{"epoch": 5, "training_loss": 3214.62138671875, "training_acc": 50.0, "val_loss": 19135.392578125, "val_acc": 40.0}
{"epoch": 6, "training_loss": 16941.003125, "training_acc": 50.0, "val_loss": 21791.087890625, "val_acc": 40.0}
{"epoch": 7, "training_loss": 17470.0939453125, "training_acc": 50.0, "val_loss": 10827.578125, "val_acc": 40.0}
{"epoch": 8, "training_loss": 6284.8654296875, "training_acc": 50.0, "val_loss": 6352.33740234375, "val_acc": 60.0}
{"epoch": 9, "training_loss": 10047.173828125, "training_acc": 50.0, "val_loss": 14383.4609375, "val_acc": 60.0}
{"epoch": 10, "training_loss": 18149.97890625, "training_acc": 50.0, "val_loss": 12963.041015625, "val_acc": 60.0}
{"epoch": 11, "training_loss": 15288.3587890625, "training_acc": 50.0, "val_loss": 4752.0361328125, "val_acc": 60.0}
{"epoch": 12, "training_loss": 6654.4232421875, "training_acc": 30.0, "val_loss": 5532.47607421875, "val_acc": 40.0}
{"epoch": 13, "training_loss": 4662.0900390625, "training_acc": 50.0, "val_loss": 5155.7919921875, "val_acc": 40.0}
{"epoch": 14, "training_loss": 3839.866650390625, "training_acc": 50.0, "val_loss": 1898.9136962890625, "val_acc": 60.0}
{"epoch": 15, "training_loss": 2328.776953125, "training_acc": 50.0, "val_loss": 3988.492919921875, "val_acc": 60.0}
{"epoch": 16, "training_loss": 4760.7048828125, "training_acc": 50.0, "val_loss": 758.2001342773438, "val_acc": 60.0}
{"epoch": 17, "training_loss": 2083.139794921875, "training_acc": 40.0, "val_loss": 7194.51123046875, "val_acc": 40.0}
{"epoch": 18, "training_loss": 6047.81484375, "training_acc": 50.0, "val_loss": 3726.487548828125, "val_acc": 40.0}
{"epoch": 19, "training_loss": 2279.9933532714845, "training_acc": 60.0, "val_loss": 3115.182373046875, "val_acc": 60.0}
{"epoch": 20, "training_loss": 4104.091796875, "training_acc": 50.0, "val_loss": 2236.270751953125, "val_acc": 60.0}
{"epoch": 21, "training_loss": 2340.0716064453127, "training_acc": 50.0, "val_loss": 2697.301513671875, "val_acc": 40.0}
{"epoch": 22, "training_loss": 2141.81904296875, "training_acc": 50.0, "val_loss": 506.2633361816406, "val_acc": 60.0}
{"epoch": 23, "training_loss": 632.193359375, "training_acc": 50.0, "val_loss": 706.5795288085938, "val_acc": 40.0}
{"epoch": 24, "training_loss": 559.4397216796875, "training_acc": 50.0, "val_loss": 1949.828369140625, "val_acc": 60.0}
{"epoch": 25, "training_loss": 2692.938671875, "training_acc": 50.0, "val_loss": 1253.5067138671875, "val_acc": 60.0}
{"epoch": 26, "training_loss": 2026.572265625, "training_acc": 40.0, "val_loss": 3255.214111328125, "val_acc": 40.0}
{"epoch": 27, "training_loss": 2601.543420410156, "training_acc": 50.0, "val_loss": 813.2468872070312, "val_acc": 60.0}
{"epoch": 28, "training_loss": 924.7098571777344, "training_acc": 50.0, "val_loss": 68.30553436279297, "val_acc": 80.0}
{"epoch": 29, "training_loss": 169.0095567703247, "training_acc": 85.0, "val_loss": 7.661770820617676, "val_acc": 80.0}
{"epoch": 30, "training_loss": 472.02159423828124, "training_acc": 70.0, "val_loss": 31.603958129882812, "val_acc": 80.0}
{"epoch": 31, "training_loss": 144.90471801757812, "training_acc": 65.0, "val_loss": 578.1521606445312, "val_acc": 60.0}
{"epoch": 32, "training_loss": 509.5950496673584, "training_acc": 55.0, "val_loss": 296.5659484863281, "val_acc": 60.0}
{"epoch": 33, "training_loss": 619.4006103515625, "training_acc": 40.0, "val_loss": 107.7418212890625, "val_acc": 60.0}
{"epoch": 34, "training_loss": 1261.7290283203124, "training_acc": 40.0, "val_loss": 1288.7449951171875, "val_acc": 60.0}
{"epoch": 35, "training_loss": 1451.219873046875, "training_acc": 50.0, "val_loss": 2177.9658203125, "val_acc": 40.0}
{"epoch": 36, "training_loss": 1726.219464111328, "training_acc": 50.0, "val_loss": 1407.767822265625, "val_acc": 60.0}
{"epoch": 37, "training_loss": 1700.5158569335938, "training_acc": 50.0, "val_loss": 506.072265625, "val_acc": 60.0}
{"epoch": 38, "training_loss": 884.227880859375, "training_acc": 50.0, "val_loss": 3166.0966796875, "val_acc": 40.0}
{"epoch": 39, "training_loss": 2499.2171875, "training_acc": 50.0, "val_loss": 884.4611206054688, "val_acc": 60.0}
{"epoch": 40, "training_loss": 1246.789794921875, "training_acc": 50.0, "val_loss": 1378.6697998046875, "val_acc": 40.0}
{"epoch": 41, "training_loss": 1272.6028930664063, "training_acc": 50.0, "val_loss": 1900.0140380859375, "val_acc": 40.0}
{"epoch": 42, "training_loss": 1375.106201171875, "training_acc": 50.0, "val_loss": 307.6099548339844, "val_acc": 60.0}
{"epoch": 43, "training_loss": 742.7784423828125, "training_acc": 40.0, "val_loss": 585.1030883789062, "val_acc": 40.0}
{"epoch": 44, "training_loss": 822.893701171875, "training_acc": 50.0, "val_loss": 2109.26806640625, "val_acc": 60.0}
{"epoch": 45, "training_loss": 2324.715283203125, "training_acc": 50.0, "val_loss": 1977.7835693359375, "val_acc": 40.0}
{"epoch": 46, "training_loss": 2102.63369140625, "training_acc": 50.0, "val_loss": 1180.9747314453125, "val_acc": 40.0}
{"epoch": 47, "training_loss": 1266.424755859375, "training_acc": 50.0, "val_loss": 2876.292724609375, "val_acc": 60.0}
{"epoch": 48, "training_loss": 3261.211328125, "training_acc": 50.0, "val_loss": 57.70774459838867, "val_acc": 60.0}
