"main_modify.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 1 --task ADNI_sex --input_option yAware --learning_rate 1e2 --batch_size 16 --weight_decay 1e-8 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 4286.086913871765, "training_acc": 50.0, "val_loss": 8857.5537109375, "val_acc": 40.0}
{"epoch": 1, "training_loss": 7897.77578125, "training_acc": 50.0, "val_loss": 11408.439453125, "val_acc": 60.0}
{"epoch": 2, "training_loss": 13766.784765625, "training_acc": 50.0, "val_loss": 3761.464111328125, "val_acc": 60.0}
{"epoch": 3, "training_loss": 2821.135546875, "training_acc": 70.0, "val_loss": 15085.84375, "val_acc": 40.0}
{"epoch": 4, "training_loss": 13115.016015625, "training_acc": 50.0, "val_loss": 16212.6767578125, "val_acc": 40.0}
{"epoch": 5, "training_loss": 12221.653515625, "training_acc": 50.0, "val_loss": 831.5711059570312, "val_acc": 40.0}
{"epoch": 6, "training_loss": 2459.3935546875, "training_acc": 50.0, "val_loss": 12352.65625, "val_acc": 60.0}
{"epoch": 7, "training_loss": 16246.05390625, "training_acc": 50.0, "val_loss": 13181.3408203125, "val_acc": 60.0}
{"epoch": 8, "training_loss": 16040.90390625, "training_acc": 50.0, "val_loss": 5506.9921875, "val_acc": 60.0}
{"epoch": 9, "training_loss": 6306.660095214844, "training_acc": 40.0, "val_loss": 3886.235107421875, "val_acc": 40.0}
{"epoch": 10, "training_loss": 3283.80703125, "training_acc": 50.0, "val_loss": 1327.3309326171875, "val_acc": 40.0}
{"epoch": 11, "training_loss": 679.65087890625, "training_acc": 70.0, "val_loss": 4821.12841796875, "val_acc": 60.0}
{"epoch": 12, "training_loss": 6269.200390625, "training_acc": 50.0, "val_loss": 3607.5078125, "val_acc": 60.0}
{"epoch": 13, "training_loss": 4602.607470703125, "training_acc": 30.0, "val_loss": 624.5652465820312, "val_acc": 40.0}
{"epoch": 14, "training_loss": 728.252978515625, "training_acc": 50.0, "val_loss": 953.0654296875, "val_acc": 60.0}
{"epoch": 15, "training_loss": 1077.669189453125, "training_acc": 50.0, "val_loss": 1269.3094482421875, "val_acc": 40.0}
{"epoch": 16, "training_loss": 1003.0266967773438, "training_acc": 50.0, "val_loss": 583.4224243164062, "val_acc": 60.0}
{"epoch": 17, "training_loss": 558.95927734375, "training_acc": 60.0, "val_loss": 2357.7119140625, "val_acc": 40.0}
{"epoch": 18, "training_loss": 1775.7630981445313, "training_acc": 50.0, "val_loss": 2151.314208984375, "val_acc": 60.0}
{"epoch": 19, "training_loss": 2926.995703125, "training_acc": 50.0, "val_loss": 1463.7978515625, "val_acc": 60.0}
{"epoch": 20, "training_loss": 1714.05068359375, "training_acc": 50.0, "val_loss": 4103.1171875, "val_acc": 40.0}
{"epoch": 21, "training_loss": 3367.564599609375, "training_acc": 50.0, "val_loss": 550.6564331054688, "val_acc": 40.0}
{"epoch": 22, "training_loss": 596.0953857421875, "training_acc": 60.0, "val_loss": 4165.67724609375, "val_acc": 60.0}
{"epoch": 23, "training_loss": 5021.8892578125, "training_acc": 50.0, "val_loss": 2308.49267578125, "val_acc": 60.0}
{"epoch": 24, "training_loss": 2385.4930419921875, "training_acc": 50.0, "val_loss": 3165.681396484375, "val_acc": 40.0}
{"epoch": 25, "training_loss": 2608.97080078125, "training_acc": 50.0, "val_loss": 485.2323303222656, "val_acc": 60.0}
{"epoch": 26, "training_loss": 720.172900390625, "training_acc": 50.0, "val_loss": 2066.737548828125, "val_acc": 40.0}
{"epoch": 27, "training_loss": 1899.446728515625, "training_acc": 50.0, "val_loss": 2425.346435546875, "val_acc": 40.0}
{"epoch": 28, "training_loss": 1692.0986053466797, "training_acc": 55.0, "val_loss": 2774.1318359375, "val_acc": 60.0}
{"epoch": 29, "training_loss": 3389.447607421875, "training_acc": 50.0, "val_loss": 2370.737060546875, "val_acc": 60.0}
{"epoch": 30, "training_loss": 2556.8893310546873, "training_acc": 40.0, "val_loss": 567.256591796875, "val_acc": 40.0}
{"epoch": 31, "training_loss": 462.96405029296875, "training_acc": 60.0, "val_loss": 1318.9178466796875, "val_acc": 60.0}
{"epoch": 32, "training_loss": 982.1758178710937, "training_acc": 55.0, "val_loss": 3334.499267578125, "val_acc": 40.0}
{"epoch": 33, "training_loss": 2834.955078125, "training_acc": 50.0, "val_loss": 4130.13037109375, "val_acc": 40.0}
{"epoch": 34, "training_loss": 3199.1154296875, "training_acc": 50.0, "val_loss": 1492.4251708984375, "val_acc": 60.0}
{"epoch": 35, "training_loss": 2021.00302734375, "training_acc": 50.0, "val_loss": 1283.446533203125, "val_acc": 60.0}
{"epoch": 36, "training_loss": 1889.55771484375, "training_acc": 40.0, "val_loss": 3034.193359375, "val_acc": 40.0}
{"epoch": 37, "training_loss": 2305.9052734375, "training_acc": 50.0, "val_loss": 2005.349609375, "val_acc": 60.0}
{"epoch": 38, "training_loss": 2300.833349609375, "training_acc": 50.0, "val_loss": 2535.539794921875, "val_acc": 60.0}
{"epoch": 39, "training_loss": 2623.9113611221314, "training_acc": 50.0, "val_loss": 2949.60400390625, "val_acc": 40.0}
{"epoch": 40, "training_loss": 2779.087841796875, "training_acc": 50.0, "val_loss": 3191.702880859375, "val_acc": 40.0}
{"epoch": 41, "training_loss": 2182.6365966796875, "training_acc": 50.0, "val_loss": 3546.13916015625, "val_acc": 60.0}
{"epoch": 42, "training_loss": 4602.74541015625, "training_acc": 50.0, "val_loss": 5708.64111328125, "val_acc": 60.0}
{"epoch": 43, "training_loss": 6272.75048828125, "training_acc": 50.0, "val_loss": 754.4224243164062, "val_acc": 60.0}
{"epoch": 44, "training_loss": 988.293310546875, "training_acc": 60.0, "val_loss": 10830.7548828125, "val_acc": 40.0}
