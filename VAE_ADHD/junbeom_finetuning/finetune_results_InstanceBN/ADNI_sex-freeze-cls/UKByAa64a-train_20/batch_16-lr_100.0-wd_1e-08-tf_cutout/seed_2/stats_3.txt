"main_modify.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 2 --task ADNI_sex --input_option yAware --learning_rate 1e2 --batch_size 16 --weight_decay 1e-8 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 6427.783297157288, "training_acc": 45.0, "val_loss": 4873.96630859375, "val_acc": 60.0}
{"epoch": 1, "training_loss": 6010.66689453125, "training_acc": 55.0, "val_loss": 26091.076171875, "val_acc": 40.0}
{"epoch": 2, "training_loss": 20138.3140625, "training_acc": 55.0, "val_loss": 26715.380859375, "val_acc": 40.0}
{"epoch": 3, "training_loss": 19360.94287109375, "training_acc": 55.0, "val_loss": 10014.7021484375, "val_acc": 40.0}
{"epoch": 4, "training_loss": 7176.1669921875, "training_acc": 45.0, "val_loss": 3691.508544921875, "val_acc": 60.0}
{"epoch": 5, "training_loss": 4856.731396484375, "training_acc": 45.0, "val_loss": 368.2435607910156, "val_acc": 40.0}
{"epoch": 6, "training_loss": 441.96474609375, "training_acc": 55.0, "val_loss": 703.2974853515625, "val_acc": 60.0}
{"epoch": 7, "training_loss": 832.7859741210938, "training_acc": 45.0, "val_loss": 916.5536499023438, "val_acc": 60.0}
{"epoch": 8, "training_loss": 1088.9014526367187, "training_acc": 45.0, "val_loss": 601.7081298828125, "val_acc": 60.0}
{"epoch": 9, "training_loss": 640.993505859375, "training_acc": 55.0, "val_loss": 926.9190673828125, "val_acc": 40.0}
{"epoch": 10, "training_loss": 1091.272314453125, "training_acc": 45.0, "val_loss": 111.7470703125, "val_acc": 60.0}
{"epoch": 11, "training_loss": 428.83619384765626, "training_acc": 55.0, "val_loss": 6673.62646484375, "val_acc": 40.0}
{"epoch": 12, "training_loss": 4951.8517578125, "training_acc": 55.0, "val_loss": 3594.26416015625, "val_acc": 40.0}
{"epoch": 13, "training_loss": 2300.62900390625, "training_acc": 55.0, "val_loss": 2111.768798828125, "val_acc": 60.0}
{"epoch": 14, "training_loss": 2578.54697265625, "training_acc": 45.0, "val_loss": 2935.748291015625, "val_acc": 40.0}
{"epoch": 15, "training_loss": 2187.6423828125, "training_acc": 55.0, "val_loss": 5776.001953125, "val_acc": 40.0}
{"epoch": 16, "training_loss": 4183.811694335937, "training_acc": 55.0, "val_loss": 1710.6884765625, "val_acc": 40.0}
{"epoch": 17, "training_loss": 2442.8162109375, "training_acc": 35.0, "val_loss": 2092.11328125, "val_acc": 60.0}
{"epoch": 18, "training_loss": 2316.199546813965, "training_acc": 45.0, "val_loss": 508.1861267089844, "val_acc": 40.0}
{"epoch": 19, "training_loss": 491.1572509765625, "training_acc": 55.0, "val_loss": 297.9687194824219, "val_acc": 60.0}
{"epoch": 20, "training_loss": 1572.455126953125, "training_acc": 25.0, "val_loss": 2580.57421875, "val_acc": 40.0}
{"epoch": 21, "training_loss": 1567.3163452148438, "training_acc": 55.0, "val_loss": 656.4277954101562, "val_acc": 60.0}
{"epoch": 22, "training_loss": 695.791064453125, "training_acc": 55.0, "val_loss": 1656.2681884765625, "val_acc": 40.0}
{"epoch": 23, "training_loss": 1102.1760375976562, "training_acc": 45.0, "val_loss": 1730.6259765625, "val_acc": 40.0}
{"epoch": 24, "training_loss": 1218.858251953125, "training_acc": 55.0, "val_loss": 900.4620971679688, "val_acc": 60.0}
{"epoch": 25, "training_loss": 1167.2217041015624, "training_acc": 45.0, "val_loss": 2110.09423828125, "val_acc": 40.0}
{"epoch": 26, "training_loss": 1626.1982666015624, "training_acc": 55.0, "val_loss": 2414.49560546875, "val_acc": 40.0}
{"epoch": 27, "training_loss": 1384.280299949646, "training_acc": 55.0, "val_loss": 67.5682601928711, "val_acc": 60.0}
{"epoch": 28, "training_loss": 235.28855743408204, "training_acc": 70.0, "val_loss": 1184.08447265625, "val_acc": 60.0}
{"epoch": 29, "training_loss": 1542.513037109375, "training_acc": 45.0, "val_loss": 1702.9752197265625, "val_acc": 40.0}
{"epoch": 30, "training_loss": 1431.12265625, "training_acc": 55.0, "val_loss": 1394.9486083984375, "val_acc": 40.0}
{"epoch": 31, "training_loss": 1089.3697265625, "training_acc": 55.0, "val_loss": 1731.8521728515625, "val_acc": 60.0}
{"epoch": 32, "training_loss": 1922.8239501953126, "training_acc": 45.0, "val_loss": 3864.604248046875, "val_acc": 40.0}
{"epoch": 33, "training_loss": 2978.002978515625, "training_acc": 55.0, "val_loss": 5508.51904296875, "val_acc": 40.0}
{"epoch": 34, "training_loss": 3747.77646484375, "training_acc": 55.0, "val_loss": 484.3838806152344, "val_acc": 60.0}
{"epoch": 35, "training_loss": 910.6966796875, "training_acc": 45.0, "val_loss": 247.6016082763672, "val_acc": 40.0}
{"epoch": 36, "training_loss": 161.3200439453125, "training_acc": 55.0, "val_loss": 1375.38720703125, "val_acc": 60.0}
{"epoch": 37, "training_loss": 1775.53466796875, "training_acc": 45.0, "val_loss": 2632.911376953125, "val_acc": 40.0}
{"epoch": 38, "training_loss": 2297.1400390625, "training_acc": 55.0, "val_loss": 4410.94287109375, "val_acc": 40.0}
{"epoch": 39, "training_loss": 2843.17265625, "training_acc": 55.0, "val_loss": 1791.1334228515625, "val_acc": 60.0}
{"epoch": 40, "training_loss": 2788.9578125, "training_acc": 45.0, "val_loss": 1641.517822265625, "val_acc": 60.0}
{"epoch": 41, "training_loss": 2482.304443359375, "training_acc": 35.0, "val_loss": 2988.33056640625, "val_acc": 40.0}
{"epoch": 42, "training_loss": 2059.182165527344, "training_acc": 55.0, "val_loss": 960.7899780273438, "val_acc": 60.0}
{"epoch": 43, "training_loss": 1234.625537109375, "training_acc": 45.0, "val_loss": 1912.107666015625, "val_acc": 40.0}
{"epoch": 44, "training_loss": 1558.62314453125, "training_acc": 55.0, "val_loss": 1559.0377197265625, "val_acc": 40.0}
{"epoch": 45, "training_loss": 1141.8059326171874, "training_acc": 55.0, "val_loss": 1602.8868408203125, "val_acc": 60.0}
{"epoch": 46, "training_loss": 1710.5708389282227, "training_acc": 45.0, "val_loss": 3923.404052734375, "val_acc": 40.0}
