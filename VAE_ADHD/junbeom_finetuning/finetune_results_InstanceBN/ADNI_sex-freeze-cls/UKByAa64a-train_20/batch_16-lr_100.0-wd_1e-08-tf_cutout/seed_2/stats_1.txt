"main_modify.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 2 --task ADNI_sex --input_option yAware --learning_rate 1e2 --batch_size 16 --weight_decay 1e-8 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 6417.0219383716585, "training_acc": 40.0, "val_loss": 5646.87548828125, "val_acc": 60.0}
{"epoch": 1, "training_loss": 5864.38740234375, "training_acc": 60.0, "val_loss": 22756.46484375, "val_acc": 40.0}
{"epoch": 2, "training_loss": 18992.9107421875, "training_acc": 50.0, "val_loss": 21231.921875, "val_acc": 40.0}
{"epoch": 3, "training_loss": 16407.11484375, "training_acc": 50.0, "val_loss": 3143.25634765625, "val_acc": 40.0}
{"epoch": 4, "training_loss": 2653.1935546875, "training_acc": 60.0, "val_loss": 12787.625, "val_acc": 60.0}
{"epoch": 5, "training_loss": 17030.15859375, "training_acc": 50.0, "val_loss": 14065.7060546875, "val_acc": 60.0}
{"epoch": 6, "training_loss": 16284.59375, "training_acc": 50.0, "val_loss": 4410.833984375, "val_acc": 60.0}
{"epoch": 7, "training_loss": 5196.8703125, "training_acc": 50.0, "val_loss": 11528.8427734375, "val_acc": 40.0}
{"epoch": 8, "training_loss": 10385.63203125, "training_acc": 50.0, "val_loss": 13241.7763671875, "val_acc": 40.0}
{"epoch": 9, "training_loss": 10268.915625, "training_acc": 50.0, "val_loss": 2229.140869140625, "val_acc": 40.0}
{"epoch": 10, "training_loss": 2546.52490234375, "training_acc": 50.0, "val_loss": 7658.3720703125, "val_acc": 60.0}
{"epoch": 11, "training_loss": 10103.116015625, "training_acc": 50.0, "val_loss": 7527.72802734375, "val_acc": 60.0}
{"epoch": 12, "training_loss": 8627.133203125, "training_acc": 50.0, "val_loss": 156.66403198242188, "val_acc": 40.0}
{"epoch": 13, "training_loss": 1073.2613037109375, "training_acc": 50.0, "val_loss": 3496.382080078125, "val_acc": 40.0}
{"epoch": 14, "training_loss": 2593.7329666137693, "training_acc": 50.0, "val_loss": 2693.400634765625, "val_acc": 60.0}
{"epoch": 15, "training_loss": 3587.5384765625, "training_acc": 50.0, "val_loss": 2602.223388671875, "val_acc": 60.0}
{"epoch": 16, "training_loss": 2369.4797973632812, "training_acc": 50.0, "val_loss": 6424.046875, "val_acc": 40.0}
{"epoch": 17, "training_loss": 5929.286328125, "training_acc": 50.0, "val_loss": 10895.2353515625, "val_acc": 40.0}
{"epoch": 18, "training_loss": 9018.4078125, "training_acc": 50.0, "val_loss": 6304.263671875, "val_acc": 40.0}
{"epoch": 19, "training_loss": 4464.818310546875, "training_acc": 50.0, "val_loss": 3075.1591796875, "val_acc": 60.0}
{"epoch": 20, "training_loss": 4773.021484375, "training_acc": 50.0, "val_loss": 5231.08251953125, "val_acc": 60.0}
{"epoch": 21, "training_loss": 5879.5314453125, "training_acc": 50.0, "val_loss": 616.7855834960938, "val_acc": 40.0}
{"epoch": 22, "training_loss": 1322.009619140625, "training_acc": 50.0, "val_loss": 3107.022216796875, "val_acc": 40.0}
{"epoch": 23, "training_loss": 2075.7946960449217, "training_acc": 50.0, "val_loss": 1810.8560791015625, "val_acc": 60.0}
{"epoch": 24, "training_loss": 2366.28681640625, "training_acc": 50.0, "val_loss": 77.32981872558594, "val_acc": 60.0}
{"epoch": 25, "training_loss": 430.0882965087891, "training_acc": 70.0, "val_loss": 1908.0238037109375, "val_acc": 40.0}
{"epoch": 26, "training_loss": 1052.4711883544921, "training_acc": 60.0, "val_loss": 1039.9398193359375, "val_acc": 60.0}
{"epoch": 27, "training_loss": 1250.3819213867187, "training_acc": 45.0, "val_loss": 363.202392578125, "val_acc": 60.0}
{"epoch": 28, "training_loss": 764.215576171875, "training_acc": 40.0, "val_loss": 229.1845245361328, "val_acc": 60.0}
{"epoch": 29, "training_loss": 418.58017578125, "training_acc": 40.0, "val_loss": 1271.5230712890625, "val_acc": 60.0}
{"epoch": 30, "training_loss": 1547.8690551757813, "training_acc": 50.0, "val_loss": 43.689151763916016, "val_acc": 80.0}
{"epoch": 31, "training_loss": 498.4115295410156, "training_acc": 60.0, "val_loss": 2334.759765625, "val_acc": 40.0}
{"epoch": 32, "training_loss": 1765.8703735351562, "training_acc": 40.0, "val_loss": 595.59130859375, "val_acc": 40.0}
{"epoch": 33, "training_loss": 259.28125, "training_acc": 70.0, "val_loss": 554.2227783203125, "val_acc": 60.0}
{"epoch": 34, "training_loss": 715.26328125, "training_acc": 50.0, "val_loss": 5.68410587310791, "val_acc": 80.0}
{"epoch": 35, "training_loss": 210.1188995361328, "training_acc": 65.0, "val_loss": 409.6514587402344, "val_acc": 40.0}
{"epoch": 36, "training_loss": 266.7464141845703, "training_acc": 60.0, "val_loss": 134.82427978515625, "val_acc": 40.0}
{"epoch": 37, "training_loss": 98.77392883300782, "training_acc": 75.0, "val_loss": 15.271638870239258, "val_acc": 80.0}
{"epoch": 38, "training_loss": 298.7333038330078, "training_acc": 65.0, "val_loss": 1031.9097900390625, "val_acc": 60.0}
{"epoch": 39, "training_loss": 1284.3049560546874, "training_acc": 50.0, "val_loss": 938.2294921875, "val_acc": 40.0}
{"epoch": 40, "training_loss": 643.9246425628662, "training_acc": 50.0, "val_loss": 786.8945922851562, "val_acc": 60.0}
{"epoch": 41, "training_loss": 814.63154296875, "training_acc": 50.0, "val_loss": 3081.065673828125, "val_acc": 40.0}
{"epoch": 42, "training_loss": 2574.8525390625, "training_acc": 50.0, "val_loss": 1584.1859130859375, "val_acc": 40.0}
{"epoch": 43, "training_loss": 1067.524658203125, "training_acc": 60.0, "val_loss": 3152.79736328125, "val_acc": 60.0}
{"epoch": 44, "training_loss": 3840.03623046875, "training_acc": 50.0, "val_loss": 945.8740234375, "val_acc": 60.0}
{"epoch": 45, "training_loss": 1533.744921875, "training_acc": 50.0, "val_loss": 5739.46044921875, "val_acc": 40.0}
{"epoch": 46, "training_loss": 4677.08828125, "training_acc": 50.0, "val_loss": 697.1979370117188, "val_acc": 40.0}
{"epoch": 47, "training_loss": 1420.158251953125, "training_acc": 50.0, "val_loss": 6687.12646484375, "val_acc": 60.0}
{"epoch": 48, "training_loss": 8516.373828125, "training_acc": 50.0, "val_loss": 6172.24609375, "val_acc": 60.0}
{"epoch": 49, "training_loss": 6756.720703125, "training_acc": 50.0, "val_loss": 1443.87353515625, "val_acc": 40.0}
{"epoch": 50, "training_loss": 2157.6109375, "training_acc": 50.0, "val_loss": 5680.5439453125, "val_acc": 40.0}
{"epoch": 51, "training_loss": 4381.48828125, "training_acc": 50.0, "val_loss": 480.2635803222656, "val_acc": 60.0}
{"epoch": 52, "training_loss": 629.7440185546875, "training_acc": 50.0, "val_loss": 363.06915283203125, "val_acc": 60.0}
{"epoch": 53, "training_loss": 476.633935546875, "training_acc": 60.0, "val_loss": 3511.749267578125, "val_acc": 40.0}
