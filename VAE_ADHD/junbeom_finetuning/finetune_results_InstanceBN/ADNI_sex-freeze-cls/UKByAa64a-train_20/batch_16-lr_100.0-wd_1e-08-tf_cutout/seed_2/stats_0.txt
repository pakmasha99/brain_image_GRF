"main_modify.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 2 --task ADNI_sex --input_option yAware --learning_rate 1e2 --batch_size 16 --weight_decay 1e-8 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 4280.910931968689, "training_acc": 50.0, "val_loss": 5730.81201171875, "val_acc": 60.0}
{"epoch": 1, "training_loss": 9559.86484375, "training_acc": 40.0, "val_loss": 14053.3779296875, "val_acc": 40.0}
{"epoch": 2, "training_loss": 10963.34443359375, "training_acc": 50.0, "val_loss": 496.19024658203125, "val_acc": 40.0}
{"epoch": 3, "training_loss": 2241.0544921875, "training_acc": 50.0, "val_loss": 11380.4873046875, "val_acc": 60.0}
{"epoch": 4, "training_loss": 14526.88671875, "training_acc": 50.0, "val_loss": 9098.6396484375, "val_acc": 60.0}
{"epoch": 5, "training_loss": 9621.6125, "training_acc": 50.0, "val_loss": 4059.921875, "val_acc": 40.0}
{"epoch": 6, "training_loss": 3863.562109375, "training_acc": 50.0, "val_loss": 13378.7421875, "val_acc": 40.0}
{"epoch": 7, "training_loss": 11123.30654296875, "training_acc": 50.0, "val_loss": 11435.7333984375, "val_acc": 40.0}
{"epoch": 8, "training_loss": 9154.300048828125, "training_acc": 50.0, "val_loss": 897.6515502929688, "val_acc": 40.0}
{"epoch": 9, "training_loss": 3274.43818359375, "training_acc": 30.0, "val_loss": 6355.6298828125, "val_acc": 60.0}
{"epoch": 10, "training_loss": 7817.774609375, "training_acc": 50.0, "val_loss": 3080.93212890625, "val_acc": 60.0}
{"epoch": 11, "training_loss": 3981.289013671875, "training_acc": 40.0, "val_loss": 4138.61083984375, "val_acc": 40.0}
{"epoch": 12, "training_loss": 3352.891845703125, "training_acc": 50.0, "val_loss": 812.1412353515625, "val_acc": 40.0}
{"epoch": 13, "training_loss": 776.373291015625, "training_acc": 60.0, "val_loss": 4541.79833984375, "val_acc": 60.0}
{"epoch": 14, "training_loss": 6010.0279296875, "training_acc": 50.0, "val_loss": 2521.035888671875, "val_acc": 60.0}
{"epoch": 15, "training_loss": 2867.303125, "training_acc": 50.0, "val_loss": 4919.10302734375, "val_acc": 40.0}
{"epoch": 16, "training_loss": 4130.4623046875, "training_acc": 50.0, "val_loss": 3129.796875, "val_acc": 40.0}
{"epoch": 17, "training_loss": 1554.85361328125, "training_acc": 70.0, "val_loss": 2486.32470703125, "val_acc": 60.0}
{"epoch": 18, "training_loss": 3236.74462890625, "training_acc": 50.0, "val_loss": 1650.788330078125, "val_acc": 60.0}
{"epoch": 19, "training_loss": 1575.556982421875, "training_acc": 60.0, "val_loss": 3371.532958984375, "val_acc": 40.0}
{"epoch": 20, "training_loss": 2724.072265625, "training_acc": 50.0, "val_loss": 155.9927978515625, "val_acc": 40.0}
{"epoch": 21, "training_loss": 1311.1603881835938, "training_acc": 40.0, "val_loss": 4003.90625, "val_acc": 60.0}
{"epoch": 22, "training_loss": 4767.153515625, "training_acc": 50.0, "val_loss": 219.5791015625, "val_acc": 60.0}
{"epoch": 23, "training_loss": 1796.3978515625, "training_acc": 40.0, "val_loss": 8764.7587890625, "val_acc": 40.0}
{"epoch": 24, "training_loss": 7251.805078125, "training_acc": 50.0, "val_loss": 6265.2744140625, "val_acc": 40.0}
{"epoch": 25, "training_loss": 4459.876245117188, "training_acc": 50.0, "val_loss": 3011.822265625, "val_acc": 60.0}
{"epoch": 26, "training_loss": 4048.0740234375, "training_acc": 50.0, "val_loss": 6202.81591796875, "val_acc": 60.0}
{"epoch": 27, "training_loss": 7639.2185546875, "training_acc": 50.0, "val_loss": 3514.200927734375, "val_acc": 60.0}
{"epoch": 28, "training_loss": 3566.7474517822266, "training_acc": 50.0, "val_loss": 6830.0986328125, "val_acc": 40.0}
{"epoch": 29, "training_loss": 6020.29931640625, "training_acc": 50.0, "val_loss": 12656.11328125, "val_acc": 40.0}
{"epoch": 30, "training_loss": 10627.6328125, "training_acc": 50.0, "val_loss": 8223.4111328125, "val_acc": 40.0}
{"epoch": 31, "training_loss": 5742.524243164063, "training_acc": 50.0, "val_loss": 4155.82177734375, "val_acc": 60.0}
{"epoch": 32, "training_loss": 6066.2376953125, "training_acc": 50.0, "val_loss": 8943.0087890625, "val_acc": 60.0}
{"epoch": 33, "training_loss": 11202.26953125, "training_acc": 50.0, "val_loss": 6438.75634765625, "val_acc": 60.0}
{"epoch": 34, "training_loss": 7607.025439453125, "training_acc": 50.0, "val_loss": 2569.970458984375, "val_acc": 40.0}
{"epoch": 35, "training_loss": 3066.73671875, "training_acc": 50.0, "val_loss": 6268.23291015625, "val_acc": 40.0}
{"epoch": 36, "training_loss": 5010.04794921875, "training_acc": 50.0, "val_loss": 70.76504516601562, "val_acc": 80.0}
{"epoch": 37, "training_loss": 385.72454223632815, "training_acc": 70.0, "val_loss": 1062.100830078125, "val_acc": 60.0}
{"epoch": 38, "training_loss": 806.870703125, "training_acc": 70.0, "val_loss": 2376.610107421875, "val_acc": 40.0}
{"epoch": 39, "training_loss": 1868.8069458007812, "training_acc": 50.0, "val_loss": 208.4829559326172, "val_acc": 60.0}
{"epoch": 40, "training_loss": 236.8773681640625, "training_acc": 60.0, "val_loss": 593.4049682617188, "val_acc": 40.0}
{"epoch": 41, "training_loss": 580.506298828125, "training_acc": 50.0, "val_loss": 288.0030212402344, "val_acc": 60.0}
{"epoch": 42, "training_loss": 1045.421484375, "training_acc": 40.0, "val_loss": 2052.745361328125, "val_acc": 40.0}
{"epoch": 43, "training_loss": 1014.60380859375, "training_acc": 70.0, "val_loss": 1494.8541259765625, "val_acc": 60.0}
{"epoch": 44, "training_loss": 1890.331005859375, "training_acc": 50.0, "val_loss": 1515.0594482421875, "val_acc": 40.0}
{"epoch": 45, "training_loss": 1782.1296875, "training_acc": 50.0, "val_loss": 51.54824447631836, "val_acc": 60.0}
{"epoch": 46, "training_loss": 57.334356689453124, "training_acc": 65.0, "val_loss": 1185.0921630859375, "val_acc": 60.0}
{"epoch": 47, "training_loss": 1180.1976135253906, "training_acc": 50.0, "val_loss": 4151.2626953125, "val_acc": 40.0}
{"epoch": 48, "training_loss": 3525.682666015625, "training_acc": 50.0, "val_loss": 6051.50341796875, "val_acc": 40.0}
{"epoch": 49, "training_loss": 4650.675732421875, "training_acc": 50.0, "val_loss": 160.65625, "val_acc": 60.0}
{"epoch": 50, "training_loss": 687.4268188476562, "training_acc": 50.0, "val_loss": 81.78187561035156, "val_acc": 40.0}
{"epoch": 51, "training_loss": 277.27430725097656, "training_acc": 75.0, "val_loss": 4138.28076171875, "val_acc": 40.0}
{"epoch": 52, "training_loss": 3223.74423828125, "training_acc": 50.0, "val_loss": 82.4052963256836, "val_acc": 40.0}
{"epoch": 53, "training_loss": 283.3867431640625, "training_acc": 55.0, "val_loss": 319.87542724609375, "val_acc": 60.0}
{"epoch": 54, "training_loss": 155.9463317871094, "training_acc": 60.0, "val_loss": 252.9161376953125, "val_acc": 60.0}
{"epoch": 55, "training_loss": 91.02112426757813, "training_acc": 70.0, "val_loss": 78.80332946777344, "val_acc": 80.0}
{"epoch": 56, "training_loss": 250.70460205078126, "training_acc": 70.0, "val_loss": 440.83013916015625, "val_acc": 40.0}
{"epoch": 57, "training_loss": 918.3855224609375, "training_acc": 45.0, "val_loss": 1337.2781982421875, "val_acc": 60.0}
{"epoch": 58, "training_loss": 1301.46923828125, "training_acc": 60.0, "val_loss": 1716.5299072265625, "val_acc": 40.0}
{"epoch": 59, "training_loss": 1096.370458984375, "training_acc": 50.0, "val_loss": 2030.003173828125, "val_acc": 60.0}
{"epoch": 60, "training_loss": 2646.648828125, "training_acc": 50.0, "val_loss": 1879.423095703125, "val_acc": 60.0}
{"epoch": 61, "training_loss": 1678.3255767822266, "training_acc": 50.0, "val_loss": 6025.2353515625, "val_acc": 40.0}
{"epoch": 62, "training_loss": 5785.361328125, "training_acc": 50.0, "val_loss": 8933.501953125, "val_acc": 40.0}
{"epoch": 63, "training_loss": 6863.18359375, "training_acc": 50.0, "val_loss": 805.7091674804688, "val_acc": 40.0}
{"epoch": 64, "training_loss": 1473.551806640625, "training_acc": 50.0, "val_loss": 6625.375, "val_acc": 60.0}
