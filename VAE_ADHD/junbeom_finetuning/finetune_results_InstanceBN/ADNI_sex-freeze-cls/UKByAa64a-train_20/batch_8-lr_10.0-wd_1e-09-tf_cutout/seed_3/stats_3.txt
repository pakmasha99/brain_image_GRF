"main_modify.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 3 --task ADNI_sex --input_option yAware --learning_rate 1e1 --batch_size 8 --weight_decay 1e-9 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 1092.6784611225128, "training_acc": 45.0, "val_loss": 222.41299438476562, "val_acc": 60.0}
{"epoch": 1, "training_loss": 420.79688262939453, "training_acc": 45.0, "val_loss": 867.4557495117188, "val_acc": 40.0}
{"epoch": 2, "training_loss": 867.0239501953125, "training_acc": 55.0, "val_loss": 695.4647827148438, "val_acc": 40.0}
{"epoch": 3, "training_loss": 410.10707397460936, "training_acc": 45.0, "val_loss": 301.5826416015625, "val_acc": 60.0}
{"epoch": 4, "training_loss": 278.2838958740234, "training_acc": 55.0, "val_loss": 191.4045867919922, "val_acc": 40.0}
{"epoch": 5, "training_loss": 315.47044677734374, "training_acc": 35.0, "val_loss": 63.6347770690918, "val_acc": 60.0}
{"epoch": 6, "training_loss": 391.21669921875, "training_acc": 35.0, "val_loss": 848.9949340820312, "val_acc": 40.0}
{"epoch": 7, "training_loss": 508.6360595703125, "training_acc": 55.0, "val_loss": 130.92681884765625, "val_acc": 60.0}
{"epoch": 8, "training_loss": 405.41461181640625, "training_acc": 45.0, "val_loss": 116.55065155029297, "val_acc": 60.0}
{"epoch": 9, "training_loss": 204.39742431640624, "training_acc": 55.0, "val_loss": 631.7637939453125, "val_acc": 40.0}
{"epoch": 10, "training_loss": 337.3661865234375, "training_acc": 55.0, "val_loss": 229.7426300048828, "val_acc": 60.0}
{"epoch": 11, "training_loss": 450.5780487060547, "training_acc": 45.0, "val_loss": 236.9562225341797, "val_acc": 60.0}
{"epoch": 12, "training_loss": 206.9150161743164, "training_acc": 45.0, "val_loss": 193.64022827148438, "val_acc": 40.0}
{"epoch": 13, "training_loss": 156.02008056640625, "training_acc": 45.0, "val_loss": 150.92832946777344, "val_acc": 40.0}
{"epoch": 14, "training_loss": 143.40096435546874, "training_acc": 55.0, "val_loss": 54.369197845458984, "val_acc": 60.0}
{"epoch": 15, "training_loss": 76.14541465044022, "training_acc": 55.0, "val_loss": 334.9498596191406, "val_acc": 40.0}
{"epoch": 16, "training_loss": 270.2081832885742, "training_acc": 55.0, "val_loss": 62.679847717285156, "val_acc": 60.0}
{"epoch": 17, "training_loss": 129.3885841369629, "training_acc": 45.0, "val_loss": 490.9294128417969, "val_acc": 40.0}
{"epoch": 18, "training_loss": 442.81943359375, "training_acc": 55.0, "val_loss": 548.8793334960938, "val_acc": 40.0}
{"epoch": 19, "training_loss": 207.62229614257814, "training_acc": 55.0, "val_loss": 505.422607421875, "val_acc": 60.0}
{"epoch": 20, "training_loss": 691.2443603515625, "training_acc": 45.0, "val_loss": 67.8058853149414, "val_acc": 60.0}
{"epoch": 21, "training_loss": 269.73524169921876, "training_acc": 55.0, "val_loss": 1246.5418701171875, "val_acc": 40.0}
{"epoch": 22, "training_loss": 951.0639892578125, "training_acc": 55.0, "val_loss": 870.26708984375, "val_acc": 40.0}
{"epoch": 23, "training_loss": 393.9224060058594, "training_acc": 45.0, "val_loss": 461.8661804199219, "val_acc": 60.0}
{"epoch": 24, "training_loss": 611.2940002441406, "training_acc": 45.0, "val_loss": 21.269222259521484, "val_acc": 60.0}
{"epoch": 25, "training_loss": 398.45900268554686, "training_acc": 45.0, "val_loss": 1169.4364013671875, "val_acc": 40.0}
{"epoch": 26, "training_loss": 707.3970458984375, "training_acc": 55.0, "val_loss": 222.7353057861328, "val_acc": 40.0}
{"epoch": 27, "training_loss": 311.7891906738281, "training_acc": 55.0, "val_loss": 535.1107788085938, "val_acc": 60.0}
{"epoch": 28, "training_loss": 599.978466796875, "training_acc": 45.0, "val_loss": 431.1918029785156, "val_acc": 40.0}
{"epoch": 29, "training_loss": 378.429052734375, "training_acc": 55.0, "val_loss": 763.3735961914062, "val_acc": 40.0}
{"epoch": 30, "training_loss": 292.2818852424622, "training_acc": 55.0, "val_loss": 135.1702880859375, "val_acc": 60.0}
{"epoch": 31, "training_loss": 180.26897697448732, "training_acc": 50.0, "val_loss": 320.2575378417969, "val_acc": 40.0}
{"epoch": 32, "training_loss": 118.4330883026123, "training_acc": 60.0, "val_loss": 70.2105484008789, "val_acc": 60.0}
{"epoch": 33, "training_loss": 50.88028411865234, "training_acc": 65.0, "val_loss": 198.1259002685547, "val_acc": 40.0}
{"epoch": 34, "training_loss": 54.84197006225586, "training_acc": 45.0, "val_loss": 96.23657989501953, "val_acc": 40.0}
{"epoch": 35, "training_loss": 21.152036285400392, "training_acc": 65.0, "val_loss": 54.82073974609375, "val_acc": 60.0}
{"epoch": 36, "training_loss": 155.68914947509765, "training_acc": 25.0, "val_loss": 105.35601043701172, "val_acc": 60.0}
{"epoch": 37, "training_loss": 198.21526184082032, "training_acc": 45.0, "val_loss": 378.8802795410156, "val_acc": 40.0}
{"epoch": 38, "training_loss": 261.43247680664064, "training_acc": 55.0, "val_loss": 190.9457244873047, "val_acc": 40.0}
{"epoch": 39, "training_loss": 281.22955017089845, "training_acc": 45.0, "val_loss": 220.19725036621094, "val_acc": 60.0}
{"epoch": 40, "training_loss": 216.13422775268555, "training_acc": 50.0, "val_loss": 314.42657470703125, "val_acc": 40.0}
{"epoch": 41, "training_loss": 50.27162857055664, "training_acc": 70.0, "val_loss": 198.6542510986328, "val_acc": 60.0}
{"epoch": 42, "training_loss": 264.62254638671874, "training_acc": 35.0, "val_loss": 369.13623046875, "val_acc": 40.0}
{"epoch": 43, "training_loss": 99.44235763549804, "training_acc": 65.0, "val_loss": 179.0311737060547, "val_acc": 60.0}
