"main_modify.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 3 --task ADNI_sex --input_option yAware --learning_rate 1e1 --batch_size 8 --weight_decay 1e-9 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 1490.2555088996887, "training_acc": 50.0, "val_loss": 337.908203125, "val_acc": 60.0}
{"epoch": 1, "training_loss": 691.4184814453125, "training_acc": 50.0, "val_loss": 177.62368774414062, "val_acc": 60.0}
{"epoch": 2, "training_loss": 451.8791870117187, "training_acc": 60.0, "val_loss": 1261.8731689453125, "val_acc": 40.0}
{"epoch": 3, "training_loss": 780.0115600585938, "training_acc": 50.0, "val_loss": 419.07452392578125, "val_acc": 60.0}
{"epoch": 4, "training_loss": 681.0079895019531, "training_acc": 50.0, "val_loss": 587.5274047851562, "val_acc": 60.0}
{"epoch": 5, "training_loss": 552.0703552246093, "training_acc": 40.0, "val_loss": 523.7449951171875, "val_acc": 40.0}
{"epoch": 6, "training_loss": 360.06762237548827, "training_acc": 40.0, "val_loss": 24.899831771850586, "val_acc": 60.0}
{"epoch": 7, "training_loss": 157.64297409057616, "training_acc": 50.0, "val_loss": 15.064946174621582, "val_acc": 40.0}
{"epoch": 8, "training_loss": 321.66638336181643, "training_acc": 45.0, "val_loss": 374.6651916503906, "val_acc": 60.0}
{"epoch": 9, "training_loss": 422.3198944091797, "training_acc": 40.0, "val_loss": 633.1016845703125, "val_acc": 40.0}
{"epoch": 10, "training_loss": 418.576220703125, "training_acc": 50.0, "val_loss": 185.40341186523438, "val_acc": 60.0}
{"epoch": 11, "training_loss": 262.56793212890625, "training_acc": 50.0, "val_loss": 266.8607482910156, "val_acc": 60.0}
{"epoch": 12, "training_loss": 174.75176696777345, "training_acc": 60.0, "val_loss": 425.0948791503906, "val_acc": 40.0}
{"epoch": 13, "training_loss": 362.8112335205078, "training_acc": 50.0, "val_loss": 131.7736053466797, "val_acc": 60.0}
{"epoch": 14, "training_loss": 197.8040313720703, "training_acc": 50.0, "val_loss": 130.45950317382812, "val_acc": 40.0}
{"epoch": 15, "training_loss": 167.38728942871094, "training_acc": 50.0, "val_loss": 250.2039031982422, "val_acc": 60.0}
{"epoch": 16, "training_loss": 397.6169494628906, "training_acc": 50.0, "val_loss": 189.58157348632812, "val_acc": 60.0}
{"epoch": 17, "training_loss": 469.4206787109375, "training_acc": 20.0, "val_loss": 427.2458190917969, "val_acc": 40.0}
{"epoch": 18, "training_loss": 180.74445190429688, "training_acc": 60.0, "val_loss": 440.80078125, "val_acc": 60.0}
{"epoch": 19, "training_loss": 537.6005126953125, "training_acc": 50.0, "val_loss": 114.3055648803711, "val_acc": 60.0}
{"epoch": 20, "training_loss": 221.36181030273437, "training_acc": 60.0, "val_loss": 648.1952514648438, "val_acc": 40.0}
{"epoch": 21, "training_loss": 383.90038948059083, "training_acc": 55.0, "val_loss": 162.0417022705078, "val_acc": 60.0}
{"epoch": 22, "training_loss": 117.55292663574218, "training_acc": 55.0, "val_loss": 126.77880859375, "val_acc": 40.0}
{"epoch": 23, "training_loss": 64.66293239593506, "training_acc": 60.0, "val_loss": 87.36514282226562, "val_acc": 60.0}
{"epoch": 24, "training_loss": 40.67671012878418, "training_acc": 65.0, "val_loss": 81.25997161865234, "val_acc": 60.0}
{"epoch": 25, "training_loss": 73.29635925292969, "training_acc": 55.0, "val_loss": 100.3493881225586, "val_acc": 40.0}
{"epoch": 26, "training_loss": 86.22077026367188, "training_acc": 50.0, "val_loss": 72.31075286865234, "val_acc": 40.0}
{"epoch": 27, "training_loss": 85.45745391845703, "training_acc": 50.0, "val_loss": 7.884868144989014, "val_acc": 80.0}
{"epoch": 28, "training_loss": 64.5933391571045, "training_acc": 65.0, "val_loss": 110.8507308959961, "val_acc": 60.0}
{"epoch": 29, "training_loss": 165.87274808883666, "training_acc": 50.0, "val_loss": 252.8130340576172, "val_acc": 40.0}
{"epoch": 30, "training_loss": 191.88162689208986, "training_acc": 50.0, "val_loss": 188.59085083007812, "val_acc": 60.0}
{"epoch": 31, "training_loss": 213.2149387239515, "training_acc": 50.0, "val_loss": 144.8119659423828, "val_acc": 40.0}
{"epoch": 32, "training_loss": 140.3575408935547, "training_acc": 40.0, "val_loss": 130.56419372558594, "val_acc": 60.0}
{"epoch": 33, "training_loss": 83.6456470489502, "training_acc": 50.0, "val_loss": 57.75927734375, "val_acc": 60.0}
{"epoch": 34, "training_loss": 57.15880088806152, "training_acc": 45.0, "val_loss": 217.9471435546875, "val_acc": 40.0}
{"epoch": 35, "training_loss": 285.30609741210935, "training_acc": 50.0, "val_loss": 76.63412475585938, "val_acc": 60.0}
{"epoch": 36, "training_loss": 65.16482086181641, "training_acc": 55.0, "val_loss": 11.647651672363281, "val_acc": 80.0}
{"epoch": 37, "training_loss": 95.84408226013184, "training_acc": 55.0, "val_loss": 194.51895141601562, "val_acc": 60.0}
{"epoch": 38, "training_loss": 314.1875244140625, "training_acc": 50.0, "val_loss": 23.038232803344727, "val_acc": 80.0}
{"epoch": 39, "training_loss": 97.64779698187485, "training_acc": 80.0, "val_loss": 309.5325622558594, "val_acc": 40.0}
{"epoch": 40, "training_loss": 144.96236724853514, "training_acc": 60.0, "val_loss": 366.1831359863281, "val_acc": 60.0}
{"epoch": 41, "training_loss": 452.30902709960935, "training_acc": 50.0, "val_loss": 27.552963256835938, "val_acc": 60.0}
{"epoch": 42, "training_loss": 86.85839538574218, "training_acc": 60.0, "val_loss": 162.89793395996094, "val_acc": 40.0}
{"epoch": 43, "training_loss": 173.7023468017578, "training_acc": 40.0, "val_loss": 10.355188369750977, "val_acc": 60.0}
{"epoch": 44, "training_loss": 79.08181858062744, "training_acc": 70.0, "val_loss": 36.227535247802734, "val_acc": 60.0}
{"epoch": 45, "training_loss": 57.1987907409668, "training_acc": 70.0, "val_loss": 37.57514953613281, "val_acc": 60.0}
{"epoch": 46, "training_loss": 70.8406852722168, "training_acc": 45.0, "val_loss": 154.7806854248047, "val_acc": 40.0}
