"main_modify.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 1 --task ADNI_sex --input_option yAware --learning_rate 1e1 --batch_size 8 --weight_decay 1e-9 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 1144.32506172657, "training_acc": 50.0, "val_loss": 924.7263793945312, "val_acc": 40.0}
{"epoch": 1, "training_loss": 1019.7586669921875, "training_acc": 50.0, "val_loss": 77.8043212890625, "val_acc": 40.0}
{"epoch": 2, "training_loss": 1009.0705718994141, "training_acc": 40.0, "val_loss": 1402.5413818359375, "val_acc": 60.0}
{"epoch": 3, "training_loss": 1504.0259765625, "training_acc": 50.0, "val_loss": 70.50904846191406, "val_acc": 60.0}
{"epoch": 4, "training_loss": 563.5665634155273, "training_acc": 60.0, "val_loss": 1693.912109375, "val_acc": 40.0}
{"epoch": 5, "training_loss": 1229.2692138671875, "training_acc": 50.0, "val_loss": 289.9721984863281, "val_acc": 40.0}
{"epoch": 6, "training_loss": 585.5201904296875, "training_acc": 40.0, "val_loss": 882.1060791015625, "val_acc": 60.0}
{"epoch": 7, "training_loss": 1031.9610900878906, "training_acc": 50.0, "val_loss": 200.03248596191406, "val_acc": 60.0}
{"epoch": 8, "training_loss": 430.11810302734375, "training_acc": 50.0, "val_loss": 917.2891845703125, "val_acc": 40.0}
{"epoch": 9, "training_loss": 589.0310272216797, "training_acc": 50.0, "val_loss": 254.0869598388672, "val_acc": 60.0}
{"epoch": 10, "training_loss": 485.7398315429688, "training_acc": 50.0, "val_loss": 402.9733581542969, "val_acc": 60.0}
{"epoch": 11, "training_loss": 376.2724365234375, "training_acc": 40.0, "val_loss": 529.3258056640625, "val_acc": 40.0}
{"epoch": 12, "training_loss": 393.9989868164063, "training_acc": 50.0, "val_loss": 186.59274291992188, "val_acc": 60.0}
{"epoch": 13, "training_loss": 336.5598205566406, "training_acc": 50.0, "val_loss": 125.94667053222656, "val_acc": 60.0}
{"epoch": 14, "training_loss": 108.8078857421875, "training_acc": 60.0, "val_loss": 62.15690231323242, "val_acc": 40.0}
{"epoch": 15, "training_loss": 208.73360290527344, "training_acc": 50.0, "val_loss": 157.80528259277344, "val_acc": 60.0}
{"epoch": 16, "training_loss": 136.25379638671876, "training_acc": 60.0, "val_loss": 196.7858123779297, "val_acc": 40.0}
{"epoch": 17, "training_loss": 277.0668884277344, "training_acc": 30.0, "val_loss": 40.765228271484375, "val_acc": 60.0}
{"epoch": 18, "training_loss": 357.18646545410155, "training_acc": 40.0, "val_loss": 570.81640625, "val_acc": 40.0}
{"epoch": 19, "training_loss": 334.8061218261719, "training_acc": 50.0, "val_loss": 421.4911193847656, "val_acc": 60.0}
{"epoch": 20, "training_loss": 449.4890625, "training_acc": 50.0, "val_loss": 92.03759765625, "val_acc": 40.0}
{"epoch": 21, "training_loss": 215.01680908203124, "training_acc": 50.0, "val_loss": 49.24799728393555, "val_acc": 60.0}
{"epoch": 22, "training_loss": 33.2689254347235, "training_acc": 65.0, "val_loss": 39.33147430419922, "val_acc": 40.0}
{"epoch": 23, "training_loss": 53.9844253540039, "training_acc": 50.0, "val_loss": 257.7178649902344, "val_acc": 40.0}
{"epoch": 24, "training_loss": 340.899658203125, "training_acc": 50.0, "val_loss": 21.30889892578125, "val_acc": 60.0}
{"epoch": 25, "training_loss": 139.33274002075194, "training_acc": 50.0, "val_loss": 243.18896484375, "val_acc": 40.0}
{"epoch": 26, "training_loss": 282.0193603515625, "training_acc": 50.0, "val_loss": 58.58488082885742, "val_acc": 60.0}
{"epoch": 27, "training_loss": 109.61617431640624, "training_acc": 30.0, "val_loss": 35.7765007019043, "val_acc": 60.0}
{"epoch": 28, "training_loss": 132.91595611572265, "training_acc": 30.0, "val_loss": 155.3608856201172, "val_acc": 40.0}
{"epoch": 29, "training_loss": 76.25672302246093, "training_acc": 60.0, "val_loss": 41.97216033935547, "val_acc": 60.0}
{"epoch": 30, "training_loss": 205.54396057128906, "training_acc": 30.0, "val_loss": 3.613065719604492, "val_acc": 80.0}
{"epoch": 31, "training_loss": 115.6416015625, "training_acc": 70.0, "val_loss": 38.87897872924805, "val_acc": 60.0}
{"epoch": 32, "training_loss": 314.0699920654297, "training_acc": 30.0, "val_loss": 311.7192077636719, "val_acc": 40.0}
{"epoch": 33, "training_loss": 55.9452823638916, "training_acc": 70.0, "val_loss": 615.3585815429688, "val_acc": 60.0}
{"epoch": 34, "training_loss": 841.026416015625, "training_acc": 50.0, "val_loss": 491.396484375, "val_acc": 60.0}
{"epoch": 35, "training_loss": 344.151708984375, "training_acc": 50.0, "val_loss": 880.6798095703125, "val_acc": 40.0}
{"epoch": 36, "training_loss": 767.8332763671875, "training_acc": 50.0, "val_loss": 584.2367553710938, "val_acc": 40.0}
{"epoch": 37, "training_loss": 314.9099609375, "training_acc": 50.0, "val_loss": 642.2423706054688, "val_acc": 60.0}
{"epoch": 38, "training_loss": 789.13369140625, "training_acc": 50.0, "val_loss": 372.3676452636719, "val_acc": 60.0}
{"epoch": 39, "training_loss": 327.7691577911377, "training_acc": 55.0, "val_loss": 737.3404541015625, "val_acc": 40.0}
{"epoch": 40, "training_loss": 571.8023071289062, "training_acc": 50.0, "val_loss": 85.67662811279297, "val_acc": 60.0}
{"epoch": 41, "training_loss": 145.30431213378907, "training_acc": 50.0, "val_loss": 231.79922485351562, "val_acc": 40.0}
{"epoch": 42, "training_loss": 234.11763610839844, "training_acc": 50.0, "val_loss": 6.176747798919678, "val_acc": 80.0}
{"epoch": 43, "training_loss": 39.51769847869873, "training_acc": 70.0, "val_loss": 107.37825012207031, "val_acc": 40.0}
{"epoch": 44, "training_loss": 83.96766510009766, "training_acc": 50.0, "val_loss": 99.4413833618164, "val_acc": 60.0}
{"epoch": 45, "training_loss": 56.70914535522461, "training_acc": 60.0, "val_loss": 28.15768814086914, "val_acc": 60.0}
{"epoch": 46, "training_loss": 19.751687622070314, "training_acc": 75.0, "val_loss": 11.2582426071167, "val_acc": 80.0}
{"epoch": 47, "training_loss": 38.312895965576175, "training_acc": 70.0, "val_loss": 17.94084358215332, "val_acc": 80.0}
{"epoch": 48, "training_loss": 16.689110612869264, "training_acc": 70.0, "val_loss": 4.98626184463501, "val_acc": 80.0}
{"epoch": 49, "training_loss": 95.86037750244141, "training_acc": 55.0, "val_loss": 51.4868049621582, "val_acc": 40.0}
