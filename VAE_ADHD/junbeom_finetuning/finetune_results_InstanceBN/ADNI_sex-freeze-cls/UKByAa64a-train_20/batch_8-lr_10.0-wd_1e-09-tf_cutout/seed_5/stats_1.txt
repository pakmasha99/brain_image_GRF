"main_modify.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 5 --task ADNI_sex --input_option yAware --learning_rate 1e1 --batch_size 8 --weight_decay 1e-9 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 1432.5933619976045, "training_acc": 45.0, "val_loss": 1068.6929931640625, "val_acc": 40.0}
{"epoch": 1, "training_loss": 1780.2760803222657, "training_acc": 55.0, "val_loss": 2033.509033203125, "val_acc": 40.0}
{"epoch": 2, "training_loss": 823.6301147460938, "training_acc": 55.0, "val_loss": 727.4274291992188, "val_acc": 60.0}
{"epoch": 3, "training_loss": 1722.5246826171874, "training_acc": 45.0, "val_loss": 1503.0201416015625, "val_acc": 60.0}
{"epoch": 4, "training_loss": 1684.8053955078126, "training_acc": 45.0, "val_loss": 111.39912414550781, "val_acc": 60.0}
{"epoch": 5, "training_loss": 877.4494384765625, "training_acc": 45.0, "val_loss": 2172.798583984375, "val_acc": 40.0}
{"epoch": 6, "training_loss": 1598.6463989257813, "training_acc": 55.0, "val_loss": 1496.0057373046875, "val_acc": 40.0}
{"epoch": 7, "training_loss": 950.724665260315, "training_acc": 35.0, "val_loss": 216.23159790039062, "val_acc": 60.0}
{"epoch": 8, "training_loss": 279.5760223388672, "training_acc": 45.0, "val_loss": 335.1579895019531, "val_acc": 40.0}
{"epoch": 9, "training_loss": 323.0138916015625, "training_acc": 55.0, "val_loss": 252.4491729736328, "val_acc": 40.0}
{"epoch": 10, "training_loss": 27.97509002685547, "training_acc": 75.0, "val_loss": 41.182334899902344, "val_acc": 60.0}
{"epoch": 11, "training_loss": 44.08340148925781, "training_acc": 65.0, "val_loss": 53.18304443359375, "val_acc": 60.0}
{"epoch": 12, "training_loss": 115.55166244506836, "training_acc": 45.0, "val_loss": 436.1709899902344, "val_acc": 40.0}
{"epoch": 13, "training_loss": 266.6781723022461, "training_acc": 45.0, "val_loss": 26.573938369750977, "val_acc": 60.0}
{"epoch": 14, "training_loss": 230.29969177246093, "training_acc": 35.0, "val_loss": 227.7576446533203, "val_acc": 40.0}
{"epoch": 15, "training_loss": 175.83445434570314, "training_acc": 45.0, "val_loss": 29.12473487854004, "val_acc": 60.0}
{"epoch": 16, "training_loss": 243.18204650878906, "training_acc": 45.0, "val_loss": 487.7231140136719, "val_acc": 40.0}
{"epoch": 17, "training_loss": 235.2302032470703, "training_acc": 55.0, "val_loss": 256.3688659667969, "val_acc": 60.0}
{"epoch": 18, "training_loss": 300.450666809082, "training_acc": 35.0, "val_loss": 123.16816711425781, "val_acc": 40.0}
{"epoch": 19, "training_loss": 44.272413635253905, "training_acc": 55.0, "val_loss": 72.75426483154297, "val_acc": 60.0}
{"epoch": 20, "training_loss": 53.4997013092041, "training_acc": 45.0, "val_loss": 270.73077392578125, "val_acc": 60.0}
{"epoch": 21, "training_loss": 461.87706298828124, "training_acc": 45.0, "val_loss": 62.84212875366211, "val_acc": 60.0}
{"epoch": 22, "training_loss": 539.0867095947266, "training_acc": 35.0, "val_loss": 1178.049072265625, "val_acc": 40.0}
{"epoch": 23, "training_loss": 802.8313659667969, "training_acc": 55.0, "val_loss": 245.3660125732422, "val_acc": 40.0}
{"epoch": 24, "training_loss": 198.01956481933593, "training_acc": 65.0, "val_loss": 406.1098327636719, "val_acc": 60.0}
{"epoch": 25, "training_loss": 378.1828903198242, "training_acc": 45.0, "val_loss": 255.02587890625, "val_acc": 40.0}
{"epoch": 26, "training_loss": 170.83250274658204, "training_acc": 45.0, "val_loss": 21.905179977416992, "val_acc": 40.0}
{"epoch": 27, "training_loss": 55.49304027557373, "training_acc": 50.0, "val_loss": 16.95334815979004, "val_acc": 40.0}
{"epoch": 28, "training_loss": 18.57771053314209, "training_acc": 65.0, "val_loss": 302.19891357421875, "val_acc": 40.0}
{"epoch": 29, "training_loss": 255.9784912109375, "training_acc": 55.0, "val_loss": 8.66689682006836, "val_acc": 60.0}
{"epoch": 30, "training_loss": 287.5795959472656, "training_acc": 45.0, "val_loss": 386.9046325683594, "val_acc": 60.0}
{"epoch": 31, "training_loss": 432.87763061523435, "training_acc": 35.0, "val_loss": 469.1585998535156, "val_acc": 40.0}
{"epoch": 32, "training_loss": 320.13941650390626, "training_acc": 55.0, "val_loss": 151.6055908203125, "val_acc": 60.0}
{"epoch": 33, "training_loss": 187.34939575195312, "training_acc": 45.0, "val_loss": 139.90208435058594, "val_acc": 40.0}
{"epoch": 34, "training_loss": 139.57424049377443, "training_acc": 35.0, "val_loss": 58.793453216552734, "val_acc": 40.0}
{"epoch": 35, "training_loss": 84.71891398429871, "training_acc": 60.0, "val_loss": 166.7187957763672, "val_acc": 60.0}
{"epoch": 36, "training_loss": 202.78873291015626, "training_acc": 35.0, "val_loss": 29.0903263092041, "val_acc": 40.0}
{"epoch": 37, "training_loss": 41.98879776000977, "training_acc": 65.0, "val_loss": 140.56253051757812, "val_acc": 40.0}
{"epoch": 38, "training_loss": 75.70454406738281, "training_acc": 60.0, "val_loss": 193.7159881591797, "val_acc": 60.0}
{"epoch": 39, "training_loss": 217.94259033203124, "training_acc": 45.0, "val_loss": 313.05743408203125, "val_acc": 40.0}
{"epoch": 40, "training_loss": 373.69090576171874, "training_acc": 55.0, "val_loss": 369.2083435058594, "val_acc": 40.0}
{"epoch": 41, "training_loss": 214.3160842895508, "training_acc": 55.0, "val_loss": 396.99542236328125, "val_acc": 60.0}
{"epoch": 42, "training_loss": 369.6681610107422, "training_acc": 45.0, "val_loss": 516.5025024414062, "val_acc": 40.0}
{"epoch": 43, "training_loss": 549.2428283691406, "training_acc": 55.0, "val_loss": 947.6868286132812, "val_acc": 40.0}
{"epoch": 44, "training_loss": 573.1299743652344, "training_acc": 55.0, "val_loss": 214.46939086914062, "val_acc": 60.0}
{"epoch": 45, "training_loss": 469.9623107910156, "training_acc": 45.0, "val_loss": 163.9989013671875, "val_acc": 60.0}
{"epoch": 46, "training_loss": 137.28103942871093, "training_acc": 65.0, "val_loss": 481.2279357910156, "val_acc": 40.0}
{"epoch": 47, "training_loss": 232.18296813964844, "training_acc": 55.0, "val_loss": 317.8600158691406, "val_acc": 60.0}
{"epoch": 48, "training_loss": 528.3629577636718, "training_acc": 45.0, "val_loss": 285.232421875, "val_acc": 60.0}
