"main_modify.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_sex --input_option yAware --learning_rate 1e1 --batch_size 8 --weight_decay 1e-9 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 1151.9061184167863, "training_acc": 55.0, "val_loss": 500.3609313964844, "val_acc": 60.0}
{"epoch": 1, "training_loss": 733.4257202148438, "training_acc": 45.0, "val_loss": 711.41650390625, "val_acc": 40.0}
{"epoch": 2, "training_loss": 798.5428955078125, "training_acc": 55.0, "val_loss": 660.4620971679688, "val_acc": 40.0}
{"epoch": 3, "training_loss": 638.9515380859375, "training_acc": 35.0, "val_loss": 336.13555908203125, "val_acc": 60.0}
{"epoch": 4, "training_loss": 197.501513671875, "training_acc": 55.0, "val_loss": 225.47373962402344, "val_acc": 40.0}
{"epoch": 5, "training_loss": 105.68411102294922, "training_acc": 45.0, "val_loss": 82.97032928466797, "val_acc": 60.0}
{"epoch": 6, "training_loss": 76.02306365966797, "training_acc": 45.0, "val_loss": 108.4689712524414, "val_acc": 40.0}
{"epoch": 7, "training_loss": 43.85959339141846, "training_acc": 60.0, "val_loss": 45.43134689331055, "val_acc": 40.0}
{"epoch": 8, "training_loss": 187.92853164672852, "training_acc": 45.0, "val_loss": 98.47893524169922, "val_acc": 40.0}
{"epoch": 9, "training_loss": 160.16643524169922, "training_acc": 55.0, "val_loss": 42.41566848754883, "val_acc": 60.0}
{"epoch": 10, "training_loss": 35.93236961364746, "training_acc": 55.0, "val_loss": 25.897790908813477, "val_acc": 60.0}
{"epoch": 11, "training_loss": 248.69412689208986, "training_acc": 35.0, "val_loss": 203.0260772705078, "val_acc": 40.0}
{"epoch": 12, "training_loss": 302.8366668701172, "training_acc": 35.0, "val_loss": 217.1120147705078, "val_acc": 60.0}
{"epoch": 13, "training_loss": 154.16429138183594, "training_acc": 55.0, "val_loss": 745.5451049804688, "val_acc": 40.0}
{"epoch": 14, "training_loss": 566.45966796875, "training_acc": 55.0, "val_loss": 346.248046875, "val_acc": 40.0}
{"epoch": 15, "training_loss": 264.4986572265625, "training_acc": 55.0, "val_loss": 291.3690185546875, "val_acc": 60.0}
{"epoch": 16, "training_loss": 329.15446720123293, "training_acc": 25.0, "val_loss": 38.13462448120117, "val_acc": 60.0}
{"epoch": 17, "training_loss": 47.91309509277344, "training_acc": 55.0, "val_loss": 218.8647918701172, "val_acc": 40.0}
{"epoch": 18, "training_loss": 119.10501708984376, "training_acc": 55.0, "val_loss": 199.39425659179688, "val_acc": 60.0}
{"epoch": 19, "training_loss": 249.60637817382812, "training_acc": 35.0, "val_loss": 453.102294921875, "val_acc": 40.0}
{"epoch": 20, "training_loss": 265.8724594116211, "training_acc": 45.0, "val_loss": 36.45442199707031, "val_acc": 60.0}
{"epoch": 21, "training_loss": 22.73377914428711, "training_acc": 75.0, "val_loss": 7.072153568267822, "val_acc": 80.0}
{"epoch": 22, "training_loss": 41.98595123291015, "training_acc": 60.0, "val_loss": 48.84473419189453, "val_acc": 60.0}
{"epoch": 23, "training_loss": 34.65982286924755, "training_acc": 65.0, "val_loss": 8.82439136505127, "val_acc": 80.0}
{"epoch": 24, "training_loss": 55.43169631958008, "training_acc": 60.0, "val_loss": 113.19459533691406, "val_acc": 60.0}
{"epoch": 25, "training_loss": 156.05018615722656, "training_acc": 35.0, "val_loss": 57.422340393066406, "val_acc": 40.0}
{"epoch": 26, "training_loss": 220.37781677246093, "training_acc": 35.0, "val_loss": 49.334068298339844, "val_acc": 60.0}
{"epoch": 27, "training_loss": 170.668212890625, "training_acc": 55.0, "val_loss": 408.3827819824219, "val_acc": 40.0}
{"epoch": 28, "training_loss": 187.68472290039062, "training_acc": 55.0, "val_loss": 304.19720458984375, "val_acc": 60.0}
{"epoch": 29, "training_loss": 324.64113464355466, "training_acc": 45.0, "val_loss": 497.47222900390625, "val_acc": 40.0}
{"epoch": 30, "training_loss": 495.68720092773435, "training_acc": 55.0, "val_loss": 837.05517578125, "val_acc": 40.0}
{"epoch": 31, "training_loss": 407.46522216796876, "training_acc": 55.0, "val_loss": 281.077880859375, "val_acc": 60.0}
{"epoch": 32, "training_loss": 500.3525024414063, "training_acc": 45.0, "val_loss": 409.705078125, "val_acc": 60.0}
{"epoch": 33, "training_loss": 435.7057800292969, "training_acc": 35.0, "val_loss": 629.1138305664062, "val_acc": 40.0}
{"epoch": 34, "training_loss": 419.2334350585937, "training_acc": 55.0, "val_loss": 35.41468048095703, "val_acc": 60.0}
{"epoch": 35, "training_loss": 46.92909126281738, "training_acc": 50.0, "val_loss": 55.877967834472656, "val_acc": 60.0}
{"epoch": 36, "training_loss": 136.0107650756836, "training_acc": 35.0, "val_loss": 275.5528869628906, "val_acc": 40.0}
{"epoch": 37, "training_loss": 123.52506103515626, "training_acc": 55.0, "val_loss": 264.358154296875, "val_acc": 60.0}
{"epoch": 38, "training_loss": 291.898779296875, "training_acc": 35.0, "val_loss": 250.7581024169922, "val_acc": 40.0}
{"epoch": 39, "training_loss": 99.76890144348144, "training_acc": 55.0, "val_loss": 81.91876220703125, "val_acc": 40.0}
{"epoch": 40, "training_loss": 44.242698669433594, "training_acc": 60.0, "val_loss": 281.11138916015625, "val_acc": 40.0}
