"main_modify.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 3 --task ADNI_sex --input_option yAware --learning_rate 5e0 --batch_size 16 --weight_decay 5e-9 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 210.32943921089174, "training_acc": 50.0, "val_loss": 226.71707153320312, "val_acc": 60.0}
{"epoch": 1, "training_loss": 259.843798828125, "training_acc": 60.0, "val_loss": 1290.234619140625, "val_acc": 40.0}
{"epoch": 2, "training_loss": 1072.0871826171874, "training_acc": 50.0, "val_loss": 928.6486206054688, "val_acc": 40.0}
{"epoch": 3, "training_loss": 679.7281127929688, "training_acc": 50.0, "val_loss": 226.1134490966797, "val_acc": 60.0}
{"epoch": 4, "training_loss": 307.4931213378906, "training_acc": 50.0, "val_loss": 538.93603515625, "val_acc": 60.0}
{"epoch": 5, "training_loss": 663.9328430175781, "training_acc": 50.0, "val_loss": 339.526123046875, "val_acc": 60.0}
{"epoch": 6, "training_loss": 337.3924255371094, "training_acc": 50.0, "val_loss": 376.5065002441406, "val_acc": 40.0}
{"epoch": 7, "training_loss": 396.0688720703125, "training_acc": 50.0, "val_loss": 733.8627319335938, "val_acc": 40.0}
{"epoch": 8, "training_loss": 589.2343688964844, "training_acc": 50.0, "val_loss": 333.2579040527344, "val_acc": 40.0}
{"epoch": 9, "training_loss": 196.45035209655762, "training_acc": 60.0, "val_loss": 197.1736297607422, "val_acc": 60.0}
{"epoch": 10, "training_loss": 243.97412109375, "training_acc": 50.0, "val_loss": 249.5299835205078, "val_acc": 60.0}
{"epoch": 11, "training_loss": 309.1849609375, "training_acc": 50.0, "val_loss": 57.83814239501953, "val_acc": 60.0}
{"epoch": 12, "training_loss": 60.59854278564453, "training_acc": 60.0, "val_loss": 312.32098388671875, "val_acc": 40.0}
{"epoch": 13, "training_loss": 257.5263336181641, "training_acc": 50.0, "val_loss": 185.5150604248047, "val_acc": 40.0}
{"epoch": 14, "training_loss": 112.34229030609131, "training_acc": 60.0, "val_loss": 98.87367248535156, "val_acc": 60.0}
{"epoch": 15, "training_loss": 115.91846313476563, "training_acc": 50.0, "val_loss": 21.284326553344727, "val_acc": 40.0}
{"epoch": 16, "training_loss": 15.72997350692749, "training_acc": 55.0, "val_loss": 25.659170150756836, "val_acc": 40.0}
{"epoch": 17, "training_loss": 20.354266357421874, "training_acc": 60.0, "val_loss": 44.95954132080078, "val_acc": 60.0}
{"epoch": 18, "training_loss": 67.13383178710937, "training_acc": 40.0, "val_loss": 4.978880405426025, "val_acc": 60.0}
{"epoch": 19, "training_loss": 28.22127285003662, "training_acc": 60.0, "val_loss": 115.23870849609375, "val_acc": 60.0}
{"epoch": 20, "training_loss": 118.68738098144532, "training_acc": 50.0, "val_loss": 206.22500610351562, "val_acc": 40.0}
{"epoch": 21, "training_loss": 187.52100219726563, "training_acc": 50.0, "val_loss": 238.2408447265625, "val_acc": 40.0}
{"epoch": 22, "training_loss": 181.39021186828614, "training_acc": 50.0, "val_loss": 147.24351501464844, "val_acc": 60.0}
{"epoch": 23, "training_loss": 185.6466491699219, "training_acc": 50.0, "val_loss": 196.0259552001953, "val_acc": 60.0}
{"epoch": 24, "training_loss": 215.74963836669923, "training_acc": 50.0, "val_loss": 105.38801574707031, "val_acc": 40.0}
{"epoch": 25, "training_loss": 105.23170471191406, "training_acc": 50.0, "val_loss": 156.76339721679688, "val_acc": 40.0}
{"epoch": 26, "training_loss": 108.28119473457336, "training_acc": 55.0, "val_loss": 72.52192687988281, "val_acc": 60.0}
{"epoch": 27, "training_loss": 74.5168960571289, "training_acc": 50.0, "val_loss": 158.77215576171875, "val_acc": 40.0}
{"epoch": 28, "training_loss": 159.25560913085937, "training_acc": 50.0, "val_loss": 137.1925811767578, "val_acc": 40.0}
{"epoch": 29, "training_loss": 88.04911193847656, "training_acc": 60.0, "val_loss": 140.7526397705078, "val_acc": 60.0}
{"epoch": 30, "training_loss": 165.96768493652343, "training_acc": 50.0, "val_loss": 29.995763778686523, "val_acc": 60.0}
{"epoch": 31, "training_loss": 114.235888671875, "training_acc": 30.0, "val_loss": 248.66665649414062, "val_acc": 40.0}
{"epoch": 32, "training_loss": 196.2793846130371, "training_acc": 50.0, "val_loss": 54.690773010253906, "val_acc": 60.0}
{"epoch": 33, "training_loss": 74.60072631835938, "training_acc": 50.0, "val_loss": 4.457021713256836, "val_acc": 80.0}
{"epoch": 34, "training_loss": 1.2552520751953125, "training_acc": 85.0, "val_loss": 197.00633239746094, "val_acc": 40.0}
{"epoch": 35, "training_loss": 163.84544677734374, "training_acc": 50.0, "val_loss": 43.68302536010742, "val_acc": 60.0}
{"epoch": 36, "training_loss": 51.892401123046874, "training_acc": 50.0, "val_loss": 119.78840637207031, "val_acc": 60.0}
{"epoch": 37, "training_loss": 128.61706676483155, "training_acc": 50.0, "val_loss": 116.37682342529297, "val_acc": 40.0}
{"epoch": 38, "training_loss": 105.18412170410156, "training_acc": 50.0, "val_loss": 47.909053802490234, "val_acc": 40.0}
{"epoch": 39, "training_loss": 78.04279479980468, "training_acc": 40.0, "val_loss": 127.2945556640625, "val_acc": 60.0}
{"epoch": 40, "training_loss": 136.2679147720337, "training_acc": 50.0, "val_loss": 103.88298797607422, "val_acc": 40.0}
{"epoch": 41, "training_loss": 88.72863845825195, "training_acc": 50.0, "val_loss": 72.56340789794922, "val_acc": 40.0}
{"epoch": 42, "training_loss": 72.58057861328125, "training_acc": 40.0, "val_loss": 49.81880187988281, "val_acc": 60.0}
{"epoch": 43, "training_loss": 36.2133451461792, "training_acc": 60.0, "val_loss": 96.9636001586914, "val_acc": 40.0}
{"epoch": 44, "training_loss": 72.39977645874023, "training_acc": 50.0, "val_loss": 107.62029266357422, "val_acc": 60.0}
{"epoch": 45, "training_loss": 129.6162353515625, "training_acc": 50.0, "val_loss": 84.90999603271484, "val_acc": 60.0}
{"epoch": 46, "training_loss": 57.9973388671875, "training_acc": 70.0, "val_loss": 181.6929168701172, "val_acc": 40.0}
{"epoch": 47, "training_loss": 159.9707794189453, "training_acc": 50.0, "val_loss": 105.74857330322266, "val_acc": 40.0}
{"epoch": 48, "training_loss": 103.02377014160156, "training_acc": 40.0, "val_loss": 49.454750061035156, "val_acc": 60.0}
{"epoch": 49, "training_loss": 39.73281478881836, "training_acc": 50.0, "val_loss": 31.718189239501953, "val_acc": 40.0}
{"epoch": 50, "training_loss": 34.57744216918945, "training_acc": 50.0, "val_loss": 48.43943405151367, "val_acc": 60.0}
{"epoch": 51, "training_loss": 41.193169021606444, "training_acc": 50.0, "val_loss": 33.21383285522461, "val_acc": 40.0}
{"epoch": 52, "training_loss": 26.561931228637697, "training_acc": 60.0, "val_loss": 68.58367919921875, "val_acc": 60.0}
