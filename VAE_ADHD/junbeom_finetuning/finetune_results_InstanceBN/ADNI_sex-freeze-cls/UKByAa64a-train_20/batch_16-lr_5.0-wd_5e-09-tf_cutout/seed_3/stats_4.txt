"main_modify.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 3 --task ADNI_sex --input_option yAware --learning_rate 5e0 --batch_size 16 --weight_decay 5e-9 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 136.5150215625763, "training_acc": 55.0, "val_loss": 118.7823257446289, "val_acc": 40.0}
{"epoch": 1, "training_loss": 103.3771484375, "training_acc": 55.0, "val_loss": 213.0234375, "val_acc": 60.0}
{"epoch": 2, "training_loss": 293.91356201171874, "training_acc": 45.0, "val_loss": 75.64462280273438, "val_acc": 60.0}
{"epoch": 3, "training_loss": 62.7661865234375, "training_acc": 65.0, "val_loss": 669.4234008789062, "val_acc": 40.0}
{"epoch": 4, "training_loss": 514.872900390625, "training_acc": 55.0, "val_loss": 660.3062133789062, "val_acc": 40.0}
{"epoch": 5, "training_loss": 441.6478515625, "training_acc": 55.0, "val_loss": 32.38720703125, "val_acc": 60.0}
{"epoch": 6, "training_loss": 86.68719787597657, "training_acc": 45.0, "val_loss": 92.68439483642578, "val_acc": 60.0}
{"epoch": 7, "training_loss": 116.05154113769531, "training_acc": 45.0, "val_loss": 200.4396209716797, "val_acc": 40.0}
{"epoch": 8, "training_loss": 129.8951873779297, "training_acc": 55.0, "val_loss": 54.56694412231445, "val_acc": 60.0}
{"epoch": 9, "training_loss": 73.65614166259766, "training_acc": 45.0, "val_loss": 23.853412628173828, "val_acc": 40.0}
{"epoch": 10, "training_loss": 14.423970794677734, "training_acc": 65.0, "val_loss": 49.849239349365234, "val_acc": 60.0}
{"epoch": 11, "training_loss": 54.11977043151855, "training_acc": 45.0, "val_loss": 159.60279846191406, "val_acc": 40.0}
{"epoch": 12, "training_loss": 109.65003509521485, "training_acc": 55.0, "val_loss": 139.31431579589844, "val_acc": 40.0}
{"epoch": 13, "training_loss": 76.25578603744506, "training_acc": 55.0, "val_loss": 22.287593841552734, "val_acc": 60.0}
{"epoch": 14, "training_loss": 18.572236633300783, "training_acc": 55.0, "val_loss": 138.5857391357422, "val_acc": 40.0}
{"epoch": 15, "training_loss": 80.5938606262207, "training_acc": 55.0, "val_loss": 98.94563293457031, "val_acc": 60.0}
{"epoch": 16, "training_loss": 138.03253173828125, "training_acc": 45.0, "val_loss": 28.385236740112305, "val_acc": 60.0}
{"epoch": 17, "training_loss": 40.23531799316406, "training_acc": 55.0, "val_loss": 408.7429504394531, "val_acc": 40.0}
{"epoch": 18, "training_loss": 294.528564453125, "training_acc": 55.0, "val_loss": 429.13555908203125, "val_acc": 40.0}
{"epoch": 19, "training_loss": 288.85662841796875, "training_acc": 55.0, "val_loss": 54.055824279785156, "val_acc": 40.0}
{"epoch": 20, "training_loss": 142.3076385498047, "training_acc": 35.0, "val_loss": 291.7012023925781, "val_acc": 60.0}
{"epoch": 21, "training_loss": 385.2228118896484, "training_acc": 45.0, "val_loss": 153.3877716064453, "val_acc": 60.0}
{"epoch": 22, "training_loss": 147.59101486206055, "training_acc": 50.0, "val_loss": 235.89573669433594, "val_acc": 40.0}
{"epoch": 23, "training_loss": 171.92290344238282, "training_acc": 55.0, "val_loss": 309.3800964355469, "val_acc": 40.0}
{"epoch": 24, "training_loss": 207.4006317138672, "training_acc": 55.0, "val_loss": 11.032264709472656, "val_acc": 60.0}
{"epoch": 25, "training_loss": 49.848606491088866, "training_acc": 75.0, "val_loss": 108.82952880859375, "val_acc": 60.0}
{"epoch": 26, "training_loss": 113.5150104522705, "training_acc": 40.0, "val_loss": 87.90001678466797, "val_acc": 40.0}
{"epoch": 27, "training_loss": 47.51470260620117, "training_acc": 55.0, "val_loss": 69.9253158569336, "val_acc": 60.0}
{"epoch": 28, "training_loss": 87.47812957763672, "training_acc": 45.0, "val_loss": 22.995534896850586, "val_acc": 40.0}
{"epoch": 29, "training_loss": 20.85028839111328, "training_acc": 75.0, "val_loss": 24.565723419189453, "val_acc": 40.0}
{"epoch": 30, "training_loss": 24.523499298095704, "training_acc": 70.0, "val_loss": 50.67185592651367, "val_acc": 60.0}
{"epoch": 31, "training_loss": 51.82241592407227, "training_acc": 55.0, "val_loss": 137.26156616210938, "val_acc": 40.0}
{"epoch": 32, "training_loss": 75.33730621337891, "training_acc": 55.0, "val_loss": 84.9685287475586, "val_acc": 60.0}
{"epoch": 33, "training_loss": 117.93235778808594, "training_acc": 45.0, "val_loss": 74.21947479248047, "val_acc": 60.0}
{"epoch": 34, "training_loss": 113.13899841308594, "training_acc": 35.0, "val_loss": 128.34646606445312, "val_acc": 40.0}
{"epoch": 35, "training_loss": 60.90885639190674, "training_acc": 65.0, "val_loss": 63.72445297241211, "val_acc": 60.0}
{"epoch": 36, "training_loss": 69.93519287109375, "training_acc": 45.0, "val_loss": 63.97335433959961, "val_acc": 40.0}
{"epoch": 37, "training_loss": 32.75783157348633, "training_acc": 55.0, "val_loss": 19.052217483520508, "val_acc": 60.0}
{"epoch": 38, "training_loss": 11.605233907699585, "training_acc": 55.0, "val_loss": 108.76824951171875, "val_acc": 40.0}
{"epoch": 39, "training_loss": 65.88139038085937, "training_acc": 55.0, "val_loss": 13.193730354309082, "val_acc": 60.0}
{"epoch": 40, "training_loss": 17.808248901367186, "training_acc": 75.0, "val_loss": 37.75172424316406, "val_acc": 60.0}
{"epoch": 41, "training_loss": 46.95984802246094, "training_acc": 45.0, "val_loss": 162.6363983154297, "val_acc": 40.0}
{"epoch": 42, "training_loss": 90.70137634277344, "training_acc": 55.0, "val_loss": 79.46065521240234, "val_acc": 60.0}
{"epoch": 43, "training_loss": 103.56602783203125, "training_acc": 45.0, "val_loss": 38.58937454223633, "val_acc": 60.0}
