"main_modify.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_sex --input_option yAware --learning_rate 5e0 --batch_size 16 --weight_decay 5e-9 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 320.54918146133423, "training_acc": 65.0, "val_loss": 480.4977111816406, "val_acc": 40.0}
{"epoch": 1, "training_loss": 275.89417724609376, "training_acc": 65.0, "val_loss": 633.5944213867188, "val_acc": 60.0}
{"epoch": 2, "training_loss": 876.518017578125, "training_acc": 45.0, "val_loss": 403.39801025390625, "val_acc": 60.0}
{"epoch": 3, "training_loss": 459.99319610595705, "training_acc": 45.0, "val_loss": 645.7186889648438, "val_acc": 40.0}
{"epoch": 4, "training_loss": 482.60048828125, "training_acc": 55.0, "val_loss": 1296.4549560546875, "val_acc": 40.0}
{"epoch": 5, "training_loss": 1000.248974609375, "training_acc": 55.0, "val_loss": 1260.7489013671875, "val_acc": 40.0}
{"epoch": 6, "training_loss": 917.36044921875, "training_acc": 55.0, "val_loss": 597.5413208007812, "val_acc": 40.0}
{"epoch": 7, "training_loss": 336.5144470214844, "training_acc": 55.0, "val_loss": 295.336181640625, "val_acc": 60.0}
{"epoch": 8, "training_loss": 498.92353515625, "training_acc": 45.0, "val_loss": 621.1446533203125, "val_acc": 60.0}
{"epoch": 9, "training_loss": 840.699755859375, "training_acc": 45.0, "val_loss": 431.4772644042969, "val_acc": 60.0}
{"epoch": 10, "training_loss": 504.18324584960936, "training_acc": 45.0, "val_loss": 198.28854370117188, "val_acc": 40.0}
{"epoch": 11, "training_loss": 172.94766540527343, "training_acc": 55.0, "val_loss": 736.9550170898438, "val_acc": 40.0}
{"epoch": 12, "training_loss": 574.9468017578125, "training_acc": 55.0, "val_loss": 740.4887084960938, "val_acc": 40.0}
{"epoch": 13, "training_loss": 533.9390899658204, "training_acc": 55.0, "val_loss": 267.3173522949219, "val_acc": 40.0}
{"epoch": 14, "training_loss": 135.5450824737549, "training_acc": 65.0, "val_loss": 196.7144775390625, "val_acc": 60.0}
{"epoch": 15, "training_loss": 279.60120849609376, "training_acc": 45.0, "val_loss": 195.19566345214844, "val_acc": 60.0}
{"epoch": 16, "training_loss": 232.17464904785157, "training_acc": 45.0, "val_loss": 219.06228637695312, "val_acc": 40.0}
{"epoch": 17, "training_loss": 188.2976806640625, "training_acc": 55.0, "val_loss": 412.5307312011719, "val_acc": 40.0}
{"epoch": 18, "training_loss": 296.4193939208984, "training_acc": 55.0, "val_loss": 152.24476623535156, "val_acc": 40.0}
{"epoch": 19, "training_loss": 152.81441650390624, "training_acc": 35.0, "val_loss": 88.40130615234375, "val_acc": 60.0}
{"epoch": 20, "training_loss": 97.31461017131805, "training_acc": 50.0, "val_loss": 64.0174789428711, "val_acc": 40.0}
{"epoch": 21, "training_loss": 35.78378047943115, "training_acc": 55.0, "val_loss": 104.64934539794922, "val_acc": 60.0}
{"epoch": 22, "training_loss": 146.1016082763672, "training_acc": 45.0, "val_loss": 19.6497859954834, "val_acc": 60.0}
{"epoch": 23, "training_loss": 36.09068298339844, "training_acc": 55.0, "val_loss": 410.25341796875, "val_acc": 40.0}
{"epoch": 24, "training_loss": 318.67132568359375, "training_acc": 55.0, "val_loss": 356.16583251953125, "val_acc": 40.0}
{"epoch": 25, "training_loss": 211.3695556640625, "training_acc": 55.0, "val_loss": 138.11021423339844, "val_acc": 60.0}
{"epoch": 26, "training_loss": 217.63592529296875, "training_acc": 45.0, "val_loss": 296.3923645019531, "val_acc": 60.0}
{"epoch": 27, "training_loss": 381.67840576171875, "training_acc": 45.0, "val_loss": 79.33170318603516, "val_acc": 60.0}
{"epoch": 28, "training_loss": 158.055322265625, "training_acc": 35.0, "val_loss": 408.19830322265625, "val_acc": 40.0}
{"epoch": 29, "training_loss": 301.49021301269534, "training_acc": 55.0, "val_loss": 388.1286315917969, "val_acc": 40.0}
{"epoch": 30, "training_loss": 260.3507385253906, "training_acc": 55.0, "val_loss": 5.1101202964782715, "val_acc": 60.0}
{"epoch": 31, "training_loss": 35.67565746307373, "training_acc": 75.0, "val_loss": 184.03550720214844, "val_acc": 60.0}
{"epoch": 32, "training_loss": 246.966943359375, "training_acc": 45.0, "val_loss": 49.38125228881836, "val_acc": 60.0}
{"epoch": 33, "training_loss": 96.86591796875, "training_acc": 35.0, "val_loss": 195.9942626953125, "val_acc": 40.0}
{"epoch": 34, "training_loss": 126.30338745117187, "training_acc": 55.0, "val_loss": 45.09675216674805, "val_acc": 60.0}
{"epoch": 35, "training_loss": 62.02089080810547, "training_acc": 45.0, "val_loss": 8.23490047454834, "val_acc": 60.0}
{"epoch": 36, "training_loss": 51.398780822753906, "training_acc": 45.0, "val_loss": 187.8671112060547, "val_acc": 40.0}
{"epoch": 37, "training_loss": 133.14932861328126, "training_acc": 55.0, "val_loss": 45.3382682800293, "val_acc": 60.0}
{"epoch": 38, "training_loss": 53.613006591796875, "training_acc": 45.0, "val_loss": 130.8640899658203, "val_acc": 40.0}
{"epoch": 39, "training_loss": 101.24956359863282, "training_acc": 55.0, "val_loss": 135.0936279296875, "val_acc": 40.0}
{"epoch": 40, "training_loss": 63.96695833117701, "training_acc": 70.0, "val_loss": 93.95941925048828, "val_acc": 60.0}
{"epoch": 41, "training_loss": 118.3638671875, "training_acc": 45.0, "val_loss": 14.621454238891602, "val_acc": 40.0}
{"epoch": 42, "training_loss": 15.839215087890626, "training_acc": 70.0, "val_loss": 12.788779258728027, "val_acc": 40.0}
{"epoch": 43, "training_loss": 28.09661293029785, "training_acc": 65.0, "val_loss": 21.163137435913086, "val_acc": 60.0}
{"epoch": 44, "training_loss": 45.11830139160156, "training_acc": 45.0, "val_loss": 233.03271484375, "val_acc": 40.0}
{"epoch": 45, "training_loss": 157.6436767578125, "training_acc": 55.0, "val_loss": 10.248321533203125, "val_acc": 60.0}
{"epoch": 46, "training_loss": 29.040803527832033, "training_acc": 45.0, "val_loss": 14.694602012634277, "val_acc": 40.0}
{"epoch": 47, "training_loss": 18.911912155151366, "training_acc": 70.0, "val_loss": 40.771209716796875, "val_acc": 60.0}
{"epoch": 48, "training_loss": 45.20298805236816, "training_acc": 45.0, "val_loss": 89.7370834350586, "val_acc": 40.0}
{"epoch": 49, "training_loss": 62.07633056640625, "training_acc": 55.0, "val_loss": 6.941720485687256, "val_acc": 60.0}
