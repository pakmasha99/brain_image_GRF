"main_modify.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_sex --input_option yAware --learning_rate 5e0 --batch_size 16 --weight_decay 5e-9 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 320.5707576751709, "training_acc": 50.0, "val_loss": 386.4262390136719, "val_acc": 40.0}
{"epoch": 1, "training_loss": 364.3703125, "training_acc": 50.0, "val_loss": 681.5488891601562, "val_acc": 60.0}
{"epoch": 2, "training_loss": 846.6744201660156, "training_acc": 50.0, "val_loss": 520.7589111328125, "val_acc": 60.0}
{"epoch": 3, "training_loss": 556.0654357910156, "training_acc": 50.0, "val_loss": 201.2838897705078, "val_acc": 40.0}
{"epoch": 4, "training_loss": 218.42193603515625, "training_acc": 50.0, "val_loss": 586.398193359375, "val_acc": 40.0}
{"epoch": 5, "training_loss": 463.59295654296875, "training_acc": 50.0, "val_loss": 163.1548614501953, "val_acc": 40.0}
{"epoch": 6, "training_loss": 154.75765991210938, "training_acc": 50.0, "val_loss": 344.9447326660156, "val_acc": 60.0}
{"epoch": 7, "training_loss": 436.8383422851563, "training_acc": 50.0, "val_loss": 311.7804870605469, "val_acc": 60.0}
{"epoch": 8, "training_loss": 347.5394287109375, "training_acc": 50.0, "val_loss": 122.64922332763672, "val_acc": 40.0}
{"epoch": 9, "training_loss": 112.96621856689453, "training_acc": 50.0, "val_loss": 343.1558532714844, "val_acc": 40.0}
{"epoch": 10, "training_loss": 270.31317749023435, "training_acc": 50.0, "val_loss": 54.21491241455078, "val_acc": 40.0}
{"epoch": 11, "training_loss": 79.09415893554687, "training_acc": 50.0, "val_loss": 281.2583923339844, "val_acc": 60.0}
{"epoch": 12, "training_loss": 347.6004699707031, "training_acc": 50.0, "val_loss": 194.4331512451172, "val_acc": 60.0}
{"epoch": 13, "training_loss": 216.1942211151123, "training_acc": 50.0, "val_loss": 283.7376403808594, "val_acc": 40.0}
{"epoch": 14, "training_loss": 245.1221893310547, "training_acc": 50.0, "val_loss": 458.622314453125, "val_acc": 40.0}
{"epoch": 15, "training_loss": 360.7856689453125, "training_acc": 50.0, "val_loss": 126.11446380615234, "val_acc": 40.0}
{"epoch": 16, "training_loss": 121.5521026611328, "training_acc": 50.0, "val_loss": 288.08807373046875, "val_acc": 60.0}
{"epoch": 17, "training_loss": 361.57611083984375, "training_acc": 50.0, "val_loss": 262.325927734375, "val_acc": 60.0}
{"epoch": 18, "training_loss": 303.2072250366211, "training_acc": 50.0, "val_loss": 91.78425598144531, "val_acc": 40.0}
{"epoch": 19, "training_loss": 107.674951171875, "training_acc": 50.0, "val_loss": 138.35057067871094, "val_acc": 40.0}
{"epoch": 20, "training_loss": 117.87903747558593, "training_acc": 40.0, "val_loss": 50.60710144042969, "val_acc": 60.0}
{"epoch": 21, "training_loss": 63.85905456542969, "training_acc": 40.0, "val_loss": 7.584035396575928, "val_acc": 60.0}
{"epoch": 22, "training_loss": 18.953000831604005, "training_acc": 70.0, "val_loss": 62.831787109375, "val_acc": 60.0}
{"epoch": 23, "training_loss": 53.96847801208496, "training_acc": 60.0, "val_loss": 83.27394104003906, "val_acc": 40.0}
{"epoch": 24, "training_loss": 54.768330574035645, "training_acc": 50.0, "val_loss": 125.4635009765625, "val_acc": 60.0}
{"epoch": 25, "training_loss": 151.13085327148437, "training_acc": 50.0, "val_loss": 127.6658935546875, "val_acc": 60.0}
{"epoch": 26, "training_loss": 124.7182487487793, "training_acc": 50.0, "val_loss": 224.96719360351562, "val_acc": 40.0}
{"epoch": 27, "training_loss": 202.40613403320313, "training_acc": 50.0, "val_loss": 312.4217529296875, "val_acc": 40.0}
{"epoch": 28, "training_loss": 219.7115478515625, "training_acc": 50.0, "val_loss": 101.2700424194336, "val_acc": 60.0}
{"epoch": 29, "training_loss": 169.0460693359375, "training_acc": 50.0, "val_loss": 239.83860778808594, "val_acc": 60.0}
{"epoch": 30, "training_loss": 268.22149047851565, "training_acc": 50.0, "val_loss": 9.9813871383667, "val_acc": 60.0}
{"epoch": 31, "training_loss": 77.31487445831299, "training_acc": 65.0, "val_loss": 213.7551727294922, "val_acc": 40.0}
{"epoch": 32, "training_loss": 141.46710815429688, "training_acc": 50.0, "val_loss": 136.6114959716797, "val_acc": 60.0}
{"epoch": 33, "training_loss": 157.261865234375, "training_acc": 50.0, "val_loss": 281.0865173339844, "val_acc": 60.0}
{"epoch": 34, "training_loss": 335.96644287109376, "training_acc": 50.0, "val_loss": 145.3030242919922, "val_acc": 60.0}
{"epoch": 35, "training_loss": 149.65084686279297, "training_acc": 50.0, "val_loss": 215.0360107421875, "val_acc": 40.0}
{"epoch": 36, "training_loss": 180.57506713867187, "training_acc": 50.0, "val_loss": 110.50337219238281, "val_acc": 40.0}
{"epoch": 37, "training_loss": 110.37433471679688, "training_acc": 40.0, "val_loss": 104.47956848144531, "val_acc": 60.0}
{"epoch": 38, "training_loss": 102.7551139831543, "training_acc": 50.0, "val_loss": 132.47886657714844, "val_acc": 40.0}
{"epoch": 39, "training_loss": 110.17368774414062, "training_acc": 50.0, "val_loss": 160.3617401123047, "val_acc": 40.0}
{"epoch": 40, "training_loss": 118.82267456054687, "training_acc": 50.0, "val_loss": 124.47259521484375, "val_acc": 60.0}
