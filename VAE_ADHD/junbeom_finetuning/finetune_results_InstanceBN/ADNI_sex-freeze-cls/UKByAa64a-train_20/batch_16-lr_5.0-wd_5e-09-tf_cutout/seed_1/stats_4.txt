"main_modify.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 1 --task ADNI_sex --input_option yAware --learning_rate 5e0 --batch_size 16 --weight_decay 5e-9 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 319.91277303695676, "training_acc": 50.0, "val_loss": 364.0831604003906, "val_acc": 40.0}
{"epoch": 1, "training_loss": 355.9341186523437, "training_acc": 50.0, "val_loss": 711.0462036132812, "val_acc": 60.0}
{"epoch": 2, "training_loss": 884.3926818847656, "training_acc": 50.0, "val_loss": 554.4890747070312, "val_acc": 60.0}
{"epoch": 3, "training_loss": 657.3552703857422, "training_acc": 50.0, "val_loss": 70.91572570800781, "val_acc": 40.0}
{"epoch": 4, "training_loss": 72.30052490234375, "training_acc": 50.0, "val_loss": 254.54165649414062, "val_acc": 40.0}
{"epoch": 5, "training_loss": 183.9814010620117, "training_acc": 50.0, "val_loss": 167.02821350097656, "val_acc": 60.0}
{"epoch": 6, "training_loss": 215.14142456054688, "training_acc": 50.0, "val_loss": 214.81558227539062, "val_acc": 60.0}
{"epoch": 7, "training_loss": 250.29882736206054, "training_acc": 50.0, "val_loss": 142.50518798828125, "val_acc": 40.0}
{"epoch": 8, "training_loss": 141.96987915039062, "training_acc": 50.0, "val_loss": 74.37531280517578, "val_acc": 40.0}
{"epoch": 9, "training_loss": 114.87967529296876, "training_acc": 40.0, "val_loss": 185.29421997070312, "val_acc": 60.0}
{"epoch": 10, "training_loss": 209.79672241210938, "training_acc": 50.0, "val_loss": 77.9566650390625, "val_acc": 40.0}
{"epoch": 11, "training_loss": 67.17086181640624, "training_acc": 50.0, "val_loss": 224.3195037841797, "val_acc": 40.0}
{"epoch": 12, "training_loss": 180.3204147338867, "training_acc": 50.0, "val_loss": 4.876915454864502, "val_acc": 60.0}
{"epoch": 13, "training_loss": 6.603476715087891, "training_acc": 55.0, "val_loss": 100.33438873291016, "val_acc": 40.0}
{"epoch": 14, "training_loss": 81.9990478515625, "training_acc": 50.0, "val_loss": 44.144412994384766, "val_acc": 60.0}
{"epoch": 15, "training_loss": 52.24086303710938, "training_acc": 50.0, "val_loss": 16.838340759277344, "val_acc": 40.0}
{"epoch": 16, "training_loss": 17.46564178466797, "training_acc": 50.0, "val_loss": 30.789417266845703, "val_acc": 40.0}
{"epoch": 17, "training_loss": 26.736387634277342, "training_acc": 50.0, "val_loss": 42.367431640625, "val_acc": 40.0}
{"epoch": 18, "training_loss": 40.47013854980469, "training_acc": 40.0, "val_loss": 84.07514190673828, "val_acc": 40.0}
{"epoch": 19, "training_loss": 72.061376953125, "training_acc": 50.0, "val_loss": 67.21378326416016, "val_acc": 60.0}
{"epoch": 20, "training_loss": 97.39111328125, "training_acc": 50.0, "val_loss": 20.584531784057617, "val_acc": 60.0}
{"epoch": 21, "training_loss": 76.61145782470703, "training_acc": 40.0, "val_loss": 262.88592529296875, "val_acc": 40.0}
{"epoch": 22, "training_loss": 207.23043212890624, "training_acc": 50.0, "val_loss": 3.8443379402160645, "val_acc": 80.0}
{"epoch": 23, "training_loss": 21.17651424407959, "training_acc": 70.0, "val_loss": 68.38426971435547, "val_acc": 60.0}
{"epoch": 24, "training_loss": 87.46081848144532, "training_acc": 40.0, "val_loss": 0.40421244502067566, "val_acc": 80.0}
{"epoch": 25, "training_loss": 10.632069396972657, "training_acc": 80.0, "val_loss": 1.6991357803344727, "val_acc": 80.0}
{"epoch": 26, "training_loss": 12.152369451522826, "training_acc": 85.0, "val_loss": 11.845582962036133, "val_acc": 40.0}
{"epoch": 27, "training_loss": 69.09791793823243, "training_acc": 30.0, "val_loss": 79.60371398925781, "val_acc": 60.0}
{"epoch": 28, "training_loss": 83.70697326660157, "training_acc": 50.0, "val_loss": 85.47673797607422, "val_acc": 40.0}
{"epoch": 29, "training_loss": 65.01731729507446, "training_acc": 50.0, "val_loss": 39.53837966918945, "val_acc": 60.0}
{"epoch": 30, "training_loss": 53.5239990234375, "training_acc": 30.0, "val_loss": 69.30440521240234, "val_acc": 60.0}
{"epoch": 31, "training_loss": 82.4455696105957, "training_acc": 50.0, "val_loss": 27.465280532836914, "val_acc": 60.0}
{"epoch": 32, "training_loss": 61.84043579101562, "training_acc": 40.0, "val_loss": 126.8393325805664, "val_acc": 40.0}
{"epoch": 33, "training_loss": 97.91342477798462, "training_acc": 50.0, "val_loss": 46.176570892333984, "val_acc": 60.0}
{"epoch": 34, "training_loss": 48.918117022514345, "training_acc": 50.0, "val_loss": 0.5234245657920837, "val_acc": 80.0}
{"epoch": 35, "training_loss": 5.478396415710449, "training_acc": 75.0, "val_loss": 122.89971923828125, "val_acc": 40.0}
{"epoch": 36, "training_loss": 113.35827026367187, "training_acc": 50.0, "val_loss": 9.430787086486816, "val_acc": 40.0}
{"epoch": 37, "training_loss": 67.99954757690429, "training_acc": 40.0, "val_loss": 199.5065155029297, "val_acc": 60.0}
{"epoch": 38, "training_loss": 230.03112182617187, "training_acc": 50.0, "val_loss": 16.389799118041992, "val_acc": 60.0}
{"epoch": 39, "training_loss": 58.860296630859374, "training_acc": 50.0, "val_loss": 448.9122009277344, "val_acc": 40.0}
{"epoch": 40, "training_loss": 385.1000610351563, "training_acc": 50.0, "val_loss": 365.5830993652344, "val_acc": 40.0}
{"epoch": 41, "training_loss": 269.66016082763673, "training_acc": 50.0, "val_loss": 125.45037841796875, "val_acc": 60.0}
{"epoch": 42, "training_loss": 198.183935546875, "training_acc": 50.0, "val_loss": 254.951904296875, "val_acc": 60.0}
{"epoch": 43, "training_loss": 287.02891845703124, "training_acc": 50.0, "val_loss": 6.91942834854126, "val_acc": 80.0}
