"main_modify.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 1 --task ADNI_sex --input_option yAware --learning_rate 5e0 --batch_size 16 --weight_decay 5e-9 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 321.6462881088257, "training_acc": 55.0, "val_loss": 465.71612548828125, "val_acc": 40.0}
{"epoch": 1, "training_loss": 271.56101989746094, "training_acc": 65.0, "val_loss": 655.5922241210938, "val_acc": 60.0}
{"epoch": 2, "training_loss": 896.4768493652343, "training_acc": 45.0, "val_loss": 499.260986328125, "val_acc": 60.0}
{"epoch": 3, "training_loss": 611.6817047119141, "training_acc": 45.0, "val_loss": 288.85308837890625, "val_acc": 40.0}
{"epoch": 4, "training_loss": 267.45238037109374, "training_acc": 55.0, "val_loss": 649.9208374023438, "val_acc": 40.0}
{"epoch": 5, "training_loss": 465.5244873046875, "training_acc": 55.0, "val_loss": 220.071533203125, "val_acc": 40.0}
{"epoch": 6, "training_loss": 123.74716339111328, "training_acc": 65.0, "val_loss": 299.5320129394531, "val_acc": 60.0}
{"epoch": 7, "training_loss": 416.44269409179685, "training_acc": 45.0, "val_loss": 228.8359375, "val_acc": 60.0}
{"epoch": 8, "training_loss": 286.0175136566162, "training_acc": 45.0, "val_loss": 349.2688903808594, "val_acc": 40.0}
{"epoch": 9, "training_loss": 291.84266967773436, "training_acc": 55.0, "val_loss": 549.4966430664062, "val_acc": 40.0}
{"epoch": 10, "training_loss": 397.8716217041016, "training_acc": 55.0, "val_loss": 197.00421142578125, "val_acc": 40.0}
{"epoch": 11, "training_loss": 106.42436981201172, "training_acc": 65.0, "val_loss": 199.98721313476562, "val_acc": 60.0}
{"epoch": 12, "training_loss": 277.6990966796875, "training_acc": 45.0, "val_loss": 79.48037719726562, "val_acc": 60.0}
{"epoch": 13, "training_loss": 153.02774047851562, "training_acc": 35.0, "val_loss": 340.0242614746094, "val_acc": 40.0}
{"epoch": 14, "training_loss": 248.4434783935547, "training_acc": 55.0, "val_loss": 146.6530303955078, "val_acc": 40.0}
{"epoch": 15, "training_loss": 127.48888244628907, "training_acc": 45.0, "val_loss": 123.8474349975586, "val_acc": 60.0}
{"epoch": 16, "training_loss": 157.57860298156737, "training_acc": 45.0, "val_loss": 110.6056900024414, "val_acc": 40.0}
{"epoch": 17, "training_loss": 81.69500732421875, "training_acc": 55.0, "val_loss": 91.94998168945312, "val_acc": 40.0}
{"epoch": 18, "training_loss": 77.66148071289062, "training_acc": 45.0, "val_loss": 23.673965454101562, "val_acc": 60.0}
{"epoch": 19, "training_loss": 85.39459228515625, "training_acc": 25.0, "val_loss": 116.29182434082031, "val_acc": 40.0}
{"epoch": 20, "training_loss": 72.39030113220215, "training_acc": 55.0, "val_loss": 46.54117965698242, "val_acc": 60.0}
{"epoch": 21, "training_loss": 45.03678207397461, "training_acc": 55.0, "val_loss": 60.97014236450195, "val_acc": 40.0}
{"epoch": 22, "training_loss": 28.389399695396424, "training_acc": 65.0, "val_loss": 1.9901663064956665, "val_acc": 80.0}
{"epoch": 23, "training_loss": 1.3254547595977784, "training_acc": 80.0, "val_loss": 18.265127182006836, "val_acc": 60.0}
{"epoch": 24, "training_loss": 14.903897094726563, "training_acc": 55.0, "val_loss": 70.6012191772461, "val_acc": 40.0}
{"epoch": 25, "training_loss": 56.54780731201172, "training_acc": 45.0, "val_loss": 41.360347747802734, "val_acc": 40.0}
{"epoch": 26, "training_loss": 21.050486183166505, "training_acc": 55.0, "val_loss": 119.14527893066406, "val_acc": 60.0}
{"epoch": 27, "training_loss": 159.61788177490234, "training_acc": 45.0, "val_loss": 110.3278579711914, "val_acc": 60.0}
{"epoch": 28, "training_loss": 118.05437051057706, "training_acc": 55.0, "val_loss": 171.5232391357422, "val_acc": 40.0}
{"epoch": 29, "training_loss": 129.29630126953126, "training_acc": 55.0, "val_loss": 106.86785888671875, "val_acc": 40.0}
{"epoch": 30, "training_loss": 71.06817932128907, "training_acc": 55.0, "val_loss": 95.63917541503906, "val_acc": 60.0}
{"epoch": 31, "training_loss": 102.77693176269531, "training_acc": 45.0, "val_loss": 196.77993774414062, "val_acc": 40.0}
{"epoch": 32, "training_loss": 147.69097290039062, "training_acc": 55.0, "val_loss": 340.856201171875, "val_acc": 40.0}
{"epoch": 33, "training_loss": 234.7328674316406, "training_acc": 55.0, "val_loss": 26.872806549072266, "val_acc": 40.0}
{"epoch": 34, "training_loss": 93.40219116210938, "training_acc": 45.0, "val_loss": 296.2471923828125, "val_acc": 60.0}
{"epoch": 35, "training_loss": 400.3781372070313, "training_acc": 45.0, "val_loss": 153.70176696777344, "val_acc": 60.0}
{"epoch": 36, "training_loss": 209.03027954101563, "training_acc": 35.0, "val_loss": 214.5672607421875, "val_acc": 40.0}
{"epoch": 37, "training_loss": 153.74110717773436, "training_acc": 55.0, "val_loss": 79.6015853881836, "val_acc": 40.0}
{"epoch": 38, "training_loss": 46.09823150634766, "training_acc": 65.0, "val_loss": 169.92819213867188, "val_acc": 60.0}
{"epoch": 39, "training_loss": 218.53040161132813, "training_acc": 45.0, "val_loss": 54.387184143066406, "val_acc": 60.0}
{"epoch": 40, "training_loss": 78.39909973144532, "training_acc": 45.0, "val_loss": 309.6756896972656, "val_acc": 40.0}
{"epoch": 41, "training_loss": 222.92735595703124, "training_acc": 55.0, "val_loss": 183.5886993408203, "val_acc": 40.0}
