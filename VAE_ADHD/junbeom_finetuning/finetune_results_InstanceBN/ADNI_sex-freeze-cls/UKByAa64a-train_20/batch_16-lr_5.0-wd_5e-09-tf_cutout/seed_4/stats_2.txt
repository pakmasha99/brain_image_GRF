"main_modify.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 4 --task ADNI_sex --input_option yAware --learning_rate 5e0 --batch_size 16 --weight_decay 5e-9 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 427.80917329788207, "training_acc": 50.0, "val_loss": 423.1405334472656, "val_acc": 40.0}
{"epoch": 1, "training_loss": 289.7343353271484, "training_acc": 60.0, "val_loss": 729.3373413085938, "val_acc": 60.0}
{"epoch": 2, "training_loss": 922.3369140625, "training_acc": 50.0, "val_loss": 797.09765625, "val_acc": 60.0}
{"epoch": 3, "training_loss": 973.2204284667969, "training_acc": 50.0, "val_loss": 372.9212341308594, "val_acc": 60.0}
{"epoch": 4, "training_loss": 380.95584869384766, "training_acc": 50.0, "val_loss": 571.1427612304688, "val_acc": 40.0}
{"epoch": 5, "training_loss": 569.521630859375, "training_acc": 50.0, "val_loss": 996.9349975585938, "val_acc": 40.0}
{"epoch": 6, "training_loss": 821.6099853515625, "training_acc": 50.0, "val_loss": 649.0255737304688, "val_acc": 40.0}
{"epoch": 7, "training_loss": 460.22158203125, "training_acc": 50.0, "val_loss": 113.41167449951172, "val_acc": 60.0}
{"epoch": 8, "training_loss": 187.90970458984376, "training_acc": 50.0, "val_loss": 383.9419860839844, "val_acc": 60.0}
{"epoch": 9, "training_loss": 471.71966552734375, "training_acc": 50.0, "val_loss": 217.43997192382812, "val_acc": 60.0}
{"epoch": 10, "training_loss": 216.58587894439697, "training_acc": 50.0, "val_loss": 175.96800231933594, "val_acc": 40.0}
{"epoch": 11, "training_loss": 147.82037353515625, "training_acc": 50.0, "val_loss": 141.0156707763672, "val_acc": 40.0}
{"epoch": 12, "training_loss": 84.67910270690918, "training_acc": 50.0, "val_loss": 198.8391571044922, "val_acc": 60.0}
{"epoch": 13, "training_loss": 269.3314147949219, "training_acc": 50.0, "val_loss": 299.7294616699219, "val_acc": 60.0}
{"epoch": 14, "training_loss": 349.371826171875, "training_acc": 50.0, "val_loss": 57.8762092590332, "val_acc": 60.0}
{"epoch": 15, "training_loss": 127.61617431640624, "training_acc": 40.0, "val_loss": 396.1011657714844, "val_acc": 40.0}
{"epoch": 16, "training_loss": 331.9788757324219, "training_acc": 50.0, "val_loss": 226.5216827392578, "val_acc": 40.0}
{"epoch": 17, "training_loss": 134.84241695404052, "training_acc": 60.0, "val_loss": 146.0748748779297, "val_acc": 60.0}
{"epoch": 18, "training_loss": 182.9834777832031, "training_acc": 50.0, "val_loss": 113.0549545288086, "val_acc": 60.0}
{"epoch": 19, "training_loss": 113.33627395629883, "training_acc": 50.0, "val_loss": 91.73480224609375, "val_acc": 40.0}
{"epoch": 20, "training_loss": 63.137481689453125, "training_acc": 50.0, "val_loss": 128.3020782470703, "val_acc": 60.0}
{"epoch": 21, "training_loss": 167.43032531738282, "training_acc": 50.0, "val_loss": 155.8048858642578, "val_acc": 60.0}
{"epoch": 22, "training_loss": 151.23068237304688, "training_acc": 50.0, "val_loss": 224.2676544189453, "val_acc": 40.0}
{"epoch": 23, "training_loss": 231.95550537109375, "training_acc": 50.0, "val_loss": 376.494384765625, "val_acc": 40.0}
{"epoch": 24, "training_loss": 291.7911834716797, "training_acc": 50.0, "val_loss": 6.792749881744385, "val_acc": 60.0}
{"epoch": 25, "training_loss": 30.227200508117676, "training_acc": 75.0, "val_loss": 145.79501342773438, "val_acc": 60.0}
{"epoch": 26, "training_loss": 164.70772399902344, "training_acc": 50.0, "val_loss": 40.45135498046875, "val_acc": 40.0}
{"epoch": 27, "training_loss": 33.43012962341309, "training_acc": 50.0, "val_loss": 9.951024055480957, "val_acc": 60.0}
{"epoch": 28, "training_loss": 4.229920482635498, "training_acc": 70.0, "val_loss": 20.841413497924805, "val_acc": 60.0}
{"epoch": 29, "training_loss": 22.4263916015625, "training_acc": 50.0, "val_loss": 11.426772117614746, "val_acc": 40.0}
{"epoch": 30, "training_loss": 30.345108032226562, "training_acc": 50.0, "val_loss": 113.6302261352539, "val_acc": 60.0}
{"epoch": 31, "training_loss": 110.71872253417969, "training_acc": 50.0, "val_loss": 183.81362915039062, "val_acc": 40.0}
{"epoch": 32, "training_loss": 171.33026123046875, "training_acc": 50.0, "val_loss": 279.67169189453125, "val_acc": 40.0}
{"epoch": 33, "training_loss": 230.426953125, "training_acc": 50.0, "val_loss": 30.60529136657715, "val_acc": 60.0}
{"epoch": 34, "training_loss": 35.42176513671875, "training_acc": 50.0, "val_loss": 79.69154357910156, "val_acc": 40.0}
{"epoch": 35, "training_loss": 74.83549194335937, "training_acc": 50.0, "val_loss": 26.422290802001953, "val_acc": 60.0}
{"epoch": 36, "training_loss": 27.344314575195312, "training_acc": 50.0, "val_loss": 84.5391616821289, "val_acc": 40.0}
{"epoch": 37, "training_loss": 70.72129440307617, "training_acc": 50.0, "val_loss": 29.081262588500977, "val_acc": 40.0}
{"epoch": 38, "training_loss": 42.68479461669922, "training_acc": 50.0, "val_loss": 119.9504623413086, "val_acc": 60.0}
{"epoch": 39, "training_loss": 122.7036361694336, "training_acc": 50.0, "val_loss": 114.89961242675781, "val_acc": 40.0}
{"epoch": 40, "training_loss": 100.23671875, "training_acc": 50.0, "val_loss": 141.1763458251953, "val_acc": 40.0}
{"epoch": 41, "training_loss": 89.8017463684082, "training_acc": 50.0, "val_loss": 186.67698669433594, "val_acc": 60.0}
{"epoch": 42, "training_loss": 259.5127807617188, "training_acc": 50.0, "val_loss": 266.7974548339844, "val_acc": 60.0}
{"epoch": 43, "training_loss": 292.531787109375, "training_acc": 50.0, "val_loss": 20.27603530883789, "val_acc": 40.0}
