"main_modify.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 4 --task ADNI_sex --input_option yAware --learning_rate 5e0 --batch_size 16 --weight_decay 5e-9 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 107.56609649658203, "training_acc": 55.0, "val_loss": 715.7802124023438, "val_acc": 40.0}
{"epoch": 1, "training_loss": 451.97771606445315, "training_acc": 55.0, "val_loss": 157.6422576904297, "val_acc": 60.0}
{"epoch": 2, "training_loss": 170.46295547485352, "training_acc": 55.0, "val_loss": 277.1026306152344, "val_acc": 40.0}
{"epoch": 3, "training_loss": 178.04193115234375, "training_acc": 55.0, "val_loss": 213.9474639892578, "val_acc": 60.0}
{"epoch": 4, "training_loss": 295.72861328125, "training_acc": 45.0, "val_loss": 204.65322875976562, "val_acc": 60.0}
{"epoch": 5, "training_loss": 240.94449768066406, "training_acc": 45.0, "val_loss": 353.58599853515625, "val_acc": 40.0}
{"epoch": 6, "training_loss": 278.4348388671875, "training_acc": 55.0, "val_loss": 562.7947998046875, "val_acc": 40.0}
{"epoch": 7, "training_loss": 400.916064453125, "training_acc": 55.0, "val_loss": 156.30825805664062, "val_acc": 40.0}
{"epoch": 8, "training_loss": 131.94544372558593, "training_acc": 55.0, "val_loss": 285.2267761230469, "val_acc": 60.0}
{"epoch": 9, "training_loss": 389.07529296875, "training_acc": 45.0, "val_loss": 171.17486572265625, "val_acc": 60.0}
{"epoch": 10, "training_loss": 172.107577419281, "training_acc": 55.0, "val_loss": 175.16983032226562, "val_acc": 40.0}
{"epoch": 11, "training_loss": 129.4628692626953, "training_acc": 55.0, "val_loss": 68.31270599365234, "val_acc": 40.0}
{"epoch": 12, "training_loss": 64.18969268798828, "training_acc": 55.0, "val_loss": 126.98847961425781, "val_acc": 60.0}
{"epoch": 13, "training_loss": 144.81828765869142, "training_acc": 45.0, "val_loss": 249.47569274902344, "val_acc": 40.0}
{"epoch": 14, "training_loss": 197.33061828613282, "training_acc": 55.0, "val_loss": 446.4285583496094, "val_acc": 40.0}
{"epoch": 15, "training_loss": 320.4632507324219, "training_acc": 55.0, "val_loss": 148.77438354492188, "val_acc": 40.0}
{"epoch": 16, "training_loss": 113.69322814941407, "training_acc": 55.0, "val_loss": 209.43374633789062, "val_acc": 60.0}
{"epoch": 17, "training_loss": 284.724951171875, "training_acc": 45.0, "val_loss": 50.71772384643555, "val_acc": 60.0}
{"epoch": 18, "training_loss": 102.14261474609376, "training_acc": 45.0, "val_loss": 457.16607666015625, "val_acc": 40.0}
{"epoch": 19, "training_loss": 347.58291015625, "training_acc": 55.0, "val_loss": 397.4657287597656, "val_acc": 40.0}
{"epoch": 20, "training_loss": 247.32418212890624, "training_acc": 55.0, "val_loss": 112.67845916748047, "val_acc": 60.0}
{"epoch": 21, "training_loss": 185.27305908203124, "training_acc": 45.0, "val_loss": 255.84288024902344, "val_acc": 60.0}
{"epoch": 22, "training_loss": 325.50006103515625, "training_acc": 45.0, "val_loss": 9.347212791442871, "val_acc": 40.0}
{"epoch": 23, "training_loss": 50.96594123840332, "training_acc": 60.0, "val_loss": 156.65548706054688, "val_acc": 40.0}
{"epoch": 24, "training_loss": 82.98728828430175, "training_acc": 55.0, "val_loss": 184.8406982421875, "val_acc": 60.0}
{"epoch": 25, "training_loss": 276.29295654296874, "training_acc": 45.0, "val_loss": 266.7973327636719, "val_acc": 60.0}
{"epoch": 26, "training_loss": 327.521142578125, "training_acc": 45.0, "val_loss": 72.003662109375, "val_acc": 40.0}
{"epoch": 27, "training_loss": 87.23369140625, "training_acc": 55.0, "val_loss": 350.4544372558594, "val_acc": 40.0}
{"epoch": 28, "training_loss": 250.77509765625, "training_acc": 55.0, "val_loss": 94.9233627319336, "val_acc": 40.0}
{"epoch": 29, "training_loss": 61.43085479736328, "training_acc": 65.0, "val_loss": 260.5933532714844, "val_acc": 60.0}
{"epoch": 30, "training_loss": 361.10552673339845, "training_acc": 45.0, "val_loss": 247.9613800048828, "val_acc": 60.0}
{"epoch": 31, "training_loss": 324.4922607421875, "training_acc": 45.0, "val_loss": 55.710914611816406, "val_acc": 40.0}
{"epoch": 32, "training_loss": 56.86187744140625, "training_acc": 55.0, "val_loss": 129.3542938232422, "val_acc": 40.0}
{"epoch": 33, "training_loss": 57.46380081176758, "training_acc": 55.0, "val_loss": 211.50625610351562, "val_acc": 60.0}
{"epoch": 34, "training_loss": 338.0781494140625, "training_acc": 45.0, "val_loss": 322.0392761230469, "val_acc": 60.0}
{"epoch": 35, "training_loss": 418.45989379882815, "training_acc": 45.0, "val_loss": 41.54235076904297, "val_acc": 60.0}
{"epoch": 36, "training_loss": 129.96705017089843, "training_acc": 35.0, "val_loss": 489.5128479003906, "val_acc": 40.0}
{"epoch": 37, "training_loss": 366.1583526611328, "training_acc": 55.0, "val_loss": 480.00244140625, "val_acc": 40.0}
{"epoch": 38, "training_loss": 332.3750244140625, "training_acc": 55.0, "val_loss": 87.72814178466797, "val_acc": 40.0}
{"epoch": 39, "training_loss": 88.38494262695312, "training_acc": 55.0, "val_loss": 276.95770263671875, "val_acc": 60.0}
{"epoch": 40, "training_loss": 382.212255859375, "training_acc": 45.0, "val_loss": 220.63858032226562, "val_acc": 60.0}
{"epoch": 41, "training_loss": 265.8893081665039, "training_acc": 45.0, "val_loss": 228.8424835205078, "val_acc": 40.0}
