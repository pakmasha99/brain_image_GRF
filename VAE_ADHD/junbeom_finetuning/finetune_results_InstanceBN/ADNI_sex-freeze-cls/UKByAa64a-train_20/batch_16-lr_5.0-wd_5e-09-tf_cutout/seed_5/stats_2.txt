"main_modify.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 5 --task ADNI_sex --input_option yAware --learning_rate 5e0 --batch_size 16 --weight_decay 5e-9 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 427.7483515739441, "training_acc": 25.0, "val_loss": 295.76177978515625, "val_acc": 60.0}
{"epoch": 1, "training_loss": 379.18829345703125, "training_acc": 50.0, "val_loss": 904.6085815429688, "val_acc": 40.0}
{"epoch": 2, "training_loss": 761.9607177734375, "training_acc": 50.0, "val_loss": 763.2807006835938, "val_acc": 40.0}
{"epoch": 3, "training_loss": 546.6685791015625, "training_acc": 50.0, "val_loss": 103.04866790771484, "val_acc": 60.0}
{"epoch": 4, "training_loss": 178.108935546875, "training_acc": 50.0, "val_loss": 358.8291015625, "val_acc": 60.0}
{"epoch": 5, "training_loss": 448.833935546875, "training_acc": 50.0, "val_loss": 193.29965209960938, "val_acc": 60.0}
{"epoch": 6, "training_loss": 217.54242010116576, "training_acc": 50.0, "val_loss": 310.92144775390625, "val_acc": 40.0}
{"epoch": 7, "training_loss": 297.902490234375, "training_acc": 50.0, "val_loss": 380.7570495605469, "val_acc": 40.0}
{"epoch": 8, "training_loss": 297.94833145141604, "training_acc": 50.0, "val_loss": 86.46064758300781, "val_acc": 60.0}
{"epoch": 9, "training_loss": 123.67346801757813, "training_acc": 50.0, "val_loss": 132.00987243652344, "val_acc": 60.0}
{"epoch": 10, "training_loss": 134.90741500854492, "training_acc": 50.0, "val_loss": 259.4142150878906, "val_acc": 40.0}
{"epoch": 11, "training_loss": 237.2742492675781, "training_acc": 50.0, "val_loss": 360.059814453125, "val_acc": 40.0}
{"epoch": 12, "training_loss": 275.2262359619141, "training_acc": 50.0, "val_loss": 37.24178695678711, "val_acc": 60.0}
{"epoch": 13, "training_loss": 52.31396713256836, "training_acc": 50.0, "val_loss": 109.73589324951172, "val_acc": 60.0}
{"epoch": 14, "training_loss": 115.0955093383789, "training_acc": 50.0, "val_loss": 178.40145874023438, "val_acc": 40.0}
{"epoch": 15, "training_loss": 173.0596435546875, "training_acc": 50.0, "val_loss": 166.94241333007812, "val_acc": 40.0}
{"epoch": 16, "training_loss": 164.41946105957032, "training_acc": 30.0, "val_loss": 39.101806640625, "val_acc": 60.0}
{"epoch": 17, "training_loss": 64.35472412109375, "training_acc": 40.0, "val_loss": 55.52214431762695, "val_acc": 40.0}
{"epoch": 18, "training_loss": 38.53725891113281, "training_acc": 60.0, "val_loss": 97.8847885131836, "val_acc": 60.0}
{"epoch": 19, "training_loss": 112.38267250061035, "training_acc": 50.0, "val_loss": 52.131072998046875, "val_acc": 40.0}
{"epoch": 20, "training_loss": 43.487841796875, "training_acc": 50.0, "val_loss": 7.923961162567139, "val_acc": 60.0}
{"epoch": 21, "training_loss": 24.596929168701173, "training_acc": 45.0, "val_loss": 5.315144062042236, "val_acc": 60.0}
{"epoch": 22, "training_loss": 5.678366088867188, "training_acc": 50.0, "val_loss": 98.5544662475586, "val_acc": 60.0}
{"epoch": 23, "training_loss": 120.03866882324219, "training_acc": 50.0, "val_loss": 72.30384063720703, "val_acc": 60.0}
{"epoch": 24, "training_loss": 113.12802124023438, "training_acc": 30.0, "val_loss": 18.392065048217773, "val_acc": 40.0}
{"epoch": 25, "training_loss": 54.18720703125, "training_acc": 40.0, "val_loss": 104.3359603881836, "val_acc": 60.0}
{"epoch": 26, "training_loss": 106.36104164123535, "training_acc": 50.0, "val_loss": 182.4995574951172, "val_acc": 40.0}
{"epoch": 27, "training_loss": 176.570068359375, "training_acc": 50.0, "val_loss": 200.57383728027344, "val_acc": 40.0}
{"epoch": 28, "training_loss": 135.55722312927247, "training_acc": 50.0, "val_loss": 178.9210662841797, "val_acc": 60.0}
{"epoch": 29, "training_loss": 258.15198974609376, "training_acc": 50.0, "val_loss": 262.0782775878906, "val_acc": 60.0}
{"epoch": 30, "training_loss": 290.5521606445312, "training_acc": 50.0, "val_loss": 16.323923110961914, "val_acc": 40.0}
{"epoch": 31, "training_loss": 25.92941665649414, "training_acc": 50.0, "val_loss": 206.0294647216797, "val_acc": 40.0}
{"epoch": 32, "training_loss": 161.16803741455078, "training_acc": 50.0, "val_loss": 12.349557876586914, "val_acc": 60.0}
{"epoch": 33, "training_loss": 16.732547760009766, "training_acc": 50.0, "val_loss": 16.85865020751953, "val_acc": 40.0}
{"epoch": 34, "training_loss": 9.254471523547545, "training_acc": 65.0, "val_loss": 20.18463706970215, "val_acc": 60.0}
{"epoch": 35, "training_loss": 36.35939331054688, "training_acc": 40.0, "val_loss": 0.6708759069442749, "val_acc": 80.0}
{"epoch": 36, "training_loss": 21.92547149658203, "training_acc": 75.0, "val_loss": 5.215058326721191, "val_acc": 60.0}
{"epoch": 37, "training_loss": 24.128620529174803, "training_acc": 65.0, "val_loss": 156.46458435058594, "val_acc": 40.0}
{"epoch": 38, "training_loss": 120.99839668273925, "training_acc": 50.0, "val_loss": 73.7627944946289, "val_acc": 60.0}
{"epoch": 39, "training_loss": 86.83468170166016, "training_acc": 50.0, "val_loss": 51.4295539855957, "val_acc": 60.0}
{"epoch": 40, "training_loss": 57.771121215820315, "training_acc": 50.0, "val_loss": 101.47148895263672, "val_acc": 40.0}
{"epoch": 41, "training_loss": 66.68446502685546, "training_acc": 50.0, "val_loss": 145.06983947753906, "val_acc": 60.0}
{"epoch": 42, "training_loss": 191.18209838867188, "training_acc": 50.0, "val_loss": 199.95608520507812, "val_acc": 60.0}
{"epoch": 43, "training_loss": 230.29810028076173, "training_acc": 50.0, "val_loss": 42.3897590637207, "val_acc": 40.0}
{"epoch": 44, "training_loss": 40.01877975463867, "training_acc": 50.0, "val_loss": 68.3302993774414, "val_acc": 40.0}
{"epoch": 45, "training_loss": 55.87413558959961, "training_acc": 50.0, "val_loss": 41.374691009521484, "val_acc": 60.0}
{"epoch": 46, "training_loss": 53.567010498046876, "training_acc": 40.0, "val_loss": 0.6069019436836243, "val_acc": 60.0}
{"epoch": 47, "training_loss": 11.395160675048828, "training_acc": 70.0, "val_loss": 14.685978889465332, "val_acc": 60.0}
{"epoch": 48, "training_loss": 47.164666748046876, "training_acc": 40.0, "val_loss": 126.8619613647461, "val_acc": 40.0}
{"epoch": 49, "training_loss": 97.77622604370117, "training_acc": 40.0, "val_loss": 15.165755271911621, "val_acc": 40.0}
{"epoch": 50, "training_loss": 15.768949127197265, "training_acc": 50.0, "val_loss": 10.431434631347656, "val_acc": 60.0}
{"epoch": 51, "training_loss": 18.82309799194336, "training_acc": 65.0, "val_loss": 71.16503143310547, "val_acc": 40.0}
{"epoch": 52, "training_loss": 42.36101608276367, "training_acc": 60.0, "val_loss": 57.41365432739258, "val_acc": 60.0}
{"epoch": 53, "training_loss": 50.348097038269046, "training_acc": 50.0, "val_loss": 138.8024139404297, "val_acc": 40.0}
{"epoch": 54, "training_loss": 127.76884155273437, "training_acc": 50.0, "val_loss": 31.7167911529541, "val_acc": 40.0}
{"epoch": 55, "training_loss": 102.44141235351563, "training_acc": 30.0, "val_loss": 166.3949737548828, "val_acc": 60.0}
{"epoch": 56, "training_loss": 175.583642578125, "training_acc": 50.0, "val_loss": 88.75164794921875, "val_acc": 40.0}
{"epoch": 57, "training_loss": 74.31268920898438, "training_acc": 50.0, "val_loss": 250.94131469726562, "val_acc": 40.0}
{"epoch": 58, "training_loss": 202.95867614746095, "training_acc": 50.0, "val_loss": 40.37295150756836, "val_acc": 40.0}
{"epoch": 59, "training_loss": 80.47984313964844, "training_acc": 40.0, "val_loss": 199.8244171142578, "val_acc": 60.0}
{"epoch": 60, "training_loss": 235.59874725341797, "training_acc": 50.0, "val_loss": 77.44393920898438, "val_acc": 60.0}
{"epoch": 61, "training_loss": 104.98287048339844, "training_acc": 40.0, "val_loss": 148.4473876953125, "val_acc": 40.0}
{"epoch": 62, "training_loss": 107.5282196044922, "training_acc": 50.0, "val_loss": 76.92935943603516, "val_acc": 60.0}
{"epoch": 63, "training_loss": 87.79114990234375, "training_acc": 50.0, "val_loss": 110.0576171875, "val_acc": 60.0}
{"epoch": 64, "training_loss": 119.36904239654541, "training_acc": 50.0, "val_loss": 92.15802001953125, "val_acc": 40.0}
{"epoch": 65, "training_loss": 76.28109130859374, "training_acc": 50.0, "val_loss": 83.57960510253906, "val_acc": 40.0}
