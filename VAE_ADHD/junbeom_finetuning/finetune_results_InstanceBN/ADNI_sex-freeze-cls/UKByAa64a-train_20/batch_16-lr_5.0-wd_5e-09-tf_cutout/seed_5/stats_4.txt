"main_modify.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 5 --task ADNI_sex --input_option yAware --learning_rate 5e0 --batch_size 16 --weight_decay 5e-9 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 426.7111277580261, "training_acc": 30.0, "val_loss": 345.0992736816406, "val_acc": 60.0}
{"epoch": 1, "training_loss": 330.45399780273436, "training_acc": 60.0, "val_loss": 877.4237670898438, "val_acc": 40.0}
{"epoch": 2, "training_loss": 773.253076171875, "training_acc": 50.0, "val_loss": 809.806640625, "val_acc": 40.0}
{"epoch": 3, "training_loss": 606.9248657226562, "training_acc": 50.0, "val_loss": 89.52069091796875, "val_acc": 60.0}
{"epoch": 4, "training_loss": 111.50003662109376, "training_acc": 50.0, "val_loss": 363.019287109375, "val_acc": 60.0}
{"epoch": 5, "training_loss": 450.4906402587891, "training_acc": 50.0, "val_loss": 270.14654541015625, "val_acc": 60.0}
{"epoch": 6, "training_loss": 336.640380859375, "training_acc": 50.0, "val_loss": 156.223876953125, "val_acc": 40.0}
{"epoch": 7, "training_loss": 142.66013793945314, "training_acc": 50.0, "val_loss": 145.49319458007812, "val_acc": 40.0}
{"epoch": 8, "training_loss": 132.5879699707031, "training_acc": 40.0, "val_loss": 62.4793586730957, "val_acc": 60.0}
{"epoch": 9, "training_loss": 69.72774658203124, "training_acc": 50.0, "val_loss": 38.10087203979492, "val_acc": 40.0}
{"epoch": 10, "training_loss": 28.250901794433595, "training_acc": 60.0, "val_loss": 92.46443939208984, "val_acc": 60.0}
{"epoch": 11, "training_loss": 104.76749172210694, "training_acc": 50.0, "val_loss": 138.4912567138672, "val_acc": 40.0}
{"epoch": 12, "training_loss": 113.64902725219727, "training_acc": 50.0, "val_loss": 65.01397705078125, "val_acc": 40.0}
{"epoch": 13, "training_loss": 64.0265106201172, "training_acc": 50.0, "val_loss": 116.71302795410156, "val_acc": 60.0}
{"epoch": 14, "training_loss": 128.65862579345702, "training_acc": 50.0, "val_loss": 137.57725524902344, "val_acc": 40.0}
{"epoch": 15, "training_loss": 132.08633422851562, "training_acc": 50.0, "val_loss": 92.35906982421875, "val_acc": 40.0}
{"epoch": 16, "training_loss": 83.3331283569336, "training_acc": 50.0, "val_loss": 157.78013610839844, "val_acc": 60.0}
{"epoch": 17, "training_loss": 189.095703125, "training_acc": 50.0, "val_loss": 31.64466667175293, "val_acc": 60.0}
{"epoch": 18, "training_loss": 84.971533203125, "training_acc": 40.0, "val_loss": 243.17259216308594, "val_acc": 40.0}
{"epoch": 19, "training_loss": 183.15126037597656, "training_acc": 50.0, "val_loss": 40.54644775390625, "val_acc": 60.0}
{"epoch": 20, "training_loss": 58.65003204345703, "training_acc": 50.0, "val_loss": 37.07115936279297, "val_acc": 60.0}
{"epoch": 21, "training_loss": 40.9849136352539, "training_acc": 60.0, "val_loss": 209.4744873046875, "val_acc": 40.0}
{"epoch": 22, "training_loss": 162.67603149414063, "training_acc": 50.0, "val_loss": 20.3172664642334, "val_acc": 60.0}
{"epoch": 23, "training_loss": 25.487623977661134, "training_acc": 50.0, "val_loss": 42.3360710144043, "val_acc": 60.0}
{"epoch": 24, "training_loss": 51.523170471191406, "training_acc": 50.0, "val_loss": 79.31673431396484, "val_acc": 40.0}
{"epoch": 25, "training_loss": 54.381934356689456, "training_acc": 50.0, "val_loss": 20.7362060546875, "val_acc": 60.0}
{"epoch": 26, "training_loss": 22.551093292236327, "training_acc": 60.0, "val_loss": 138.73818969726562, "val_acc": 40.0}
{"epoch": 27, "training_loss": 102.04090328216553, "training_acc": 50.0, "val_loss": 77.0023422241211, "val_acc": 60.0}
{"epoch": 28, "training_loss": 93.18284225463867, "training_acc": 50.0, "val_loss": 28.20488929748535, "val_acc": 60.0}
{"epoch": 29, "training_loss": 34.07542419433594, "training_acc": 60.0, "val_loss": 224.1753387451172, "val_acc": 40.0}
{"epoch": 30, "training_loss": 173.15628051757812, "training_acc": 50.0, "val_loss": 15.702715873718262, "val_acc": 60.0}
{"epoch": 31, "training_loss": 38.24280014038086, "training_acc": 50.0, "val_loss": 6.597859859466553, "val_acc": 60.0}
{"epoch": 32, "training_loss": 14.47380667924881, "training_acc": 85.0, "val_loss": 38.496376037597656, "val_acc": 40.0}
{"epoch": 33, "training_loss": 39.666082763671874, "training_acc": 50.0, "val_loss": 110.0403060913086, "val_acc": 60.0}
{"epoch": 34, "training_loss": 116.13551483154296, "training_acc": 50.0, "val_loss": 155.24635314941406, "val_acc": 40.0}
{"epoch": 35, "training_loss": 133.36599426269532, "training_acc": 50.0, "val_loss": 159.0685272216797, "val_acc": 40.0}
{"epoch": 36, "training_loss": 120.4485076904297, "training_acc": 40.0, "val_loss": 22.714048385620117, "val_acc": 60.0}
{"epoch": 37, "training_loss": 21.878409576416015, "training_acc": 60.0, "val_loss": 127.6374282836914, "val_acc": 40.0}
{"epoch": 38, "training_loss": 90.1963978767395, "training_acc": 50.0, "val_loss": 88.97308349609375, "val_acc": 60.0}
{"epoch": 39, "training_loss": 105.61328582763672, "training_acc": 50.0, "val_loss": 43.937744140625, "val_acc": 60.0}
{"epoch": 40, "training_loss": 60.323089599609375, "training_acc": 50.0, "val_loss": 160.1458740234375, "val_acc": 40.0}
{"epoch": 41, "training_loss": 104.23925018310547, "training_acc": 50.0, "val_loss": 116.8935546875, "val_acc": 60.0}
{"epoch": 42, "training_loss": 148.3786590576172, "training_acc": 50.0, "val_loss": 189.03282165527344, "val_acc": 60.0}
{"epoch": 43, "training_loss": 209.73452758789062, "training_acc": 50.0, "val_loss": 55.971900939941406, "val_acc": 40.0}
{"epoch": 44, "training_loss": 41.369204711914065, "training_acc": 50.0, "val_loss": 108.84803771972656, "val_acc": 40.0}
{"epoch": 45, "training_loss": 66.32812156677247, "training_acc": 55.0, "val_loss": 55.06165313720703, "val_acc": 60.0}
{"epoch": 46, "training_loss": 44.643510055541995, "training_acc": 50.0, "val_loss": 226.52012634277344, "val_acc": 40.0}
{"epoch": 47, "training_loss": 205.85848999023438, "training_acc": 50.0, "val_loss": 245.96983337402344, "val_acc": 40.0}
{"epoch": 48, "training_loss": 147.5430877685547, "training_acc": 50.0, "val_loss": 207.9143524169922, "val_acc": 60.0}
{"epoch": 49, "training_loss": 267.01246337890626, "training_acc": 50.0, "val_loss": 400.6440734863281, "val_acc": 60.0}
{"epoch": 50, "training_loss": 488.1955322265625, "training_acc": 50.0, "val_loss": 251.3907470703125, "val_acc": 60.0}
