"main_modify.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 2 --task ADNI_sex --input_option yAware --learning_rate 5e0 --batch_size 16 --weight_decay 5e-9 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 214.55751399993898, "training_acc": 50.0, "val_loss": 286.4535217285156, "val_acc": 60.0}
{"epoch": 1, "training_loss": 477.9318359375, "training_acc": 40.0, "val_loss": 702.7994995117188, "val_acc": 40.0}
{"epoch": 2, "training_loss": 548.276171875, "training_acc": 50.0, "val_loss": 24.939054489135742, "val_acc": 40.0}
{"epoch": 3, "training_loss": 112.11775817871094, "training_acc": 50.0, "val_loss": 568.9396362304688, "val_acc": 60.0}
{"epoch": 4, "training_loss": 726.2403076171875, "training_acc": 50.0, "val_loss": 454.8482971191406, "val_acc": 60.0}
{"epoch": 5, "training_loss": 480.97841796875, "training_acc": 50.0, "val_loss": 203.1215057373047, "val_acc": 40.0}
{"epoch": 6, "training_loss": 193.28069152832032, "training_acc": 50.0, "val_loss": 669.0615844726562, "val_acc": 40.0}
{"epoch": 7, "training_loss": 556.2684692382812, "training_acc": 50.0, "val_loss": 571.9107666015625, "val_acc": 40.0}
{"epoch": 8, "training_loss": 457.8153869628906, "training_acc": 50.0, "val_loss": 45.00663757324219, "val_acc": 40.0}
{"epoch": 9, "training_loss": 163.78097534179688, "training_acc": 30.0, "val_loss": 317.6994934082031, "val_acc": 60.0}
{"epoch": 10, "training_loss": 390.7893432617187, "training_acc": 50.0, "val_loss": 153.9645233154297, "val_acc": 60.0}
{"epoch": 11, "training_loss": 199.00723571777343, "training_acc": 40.0, "val_loss": 207.0546875, "val_acc": 40.0}
{"epoch": 12, "training_loss": 167.74637451171876, "training_acc": 50.0, "val_loss": 40.7308235168457, "val_acc": 40.0}
{"epoch": 13, "training_loss": 38.8780014038086, "training_acc": 60.0, "val_loss": 227.0083770751953, "val_acc": 60.0}
{"epoch": 14, "training_loss": 300.3996826171875, "training_acc": 50.0, "val_loss": 125.97051239013672, "val_acc": 60.0}
{"epoch": 15, "training_loss": 143.30740051269532, "training_acc": 50.0, "val_loss": 246.0776824951172, "val_acc": 40.0}
{"epoch": 16, "training_loss": 206.6233367919922, "training_acc": 50.0, "val_loss": 156.6120147705078, "val_acc": 40.0}
{"epoch": 17, "training_loss": 77.80306396484374, "training_acc": 70.0, "val_loss": 124.23552703857422, "val_acc": 60.0}
{"epoch": 18, "training_loss": 161.73788146972657, "training_acc": 50.0, "val_loss": 82.45881652832031, "val_acc": 60.0}
{"epoch": 19, "training_loss": 78.72003059387207, "training_acc": 60.0, "val_loss": 168.69815063476562, "val_acc": 40.0}
{"epoch": 20, "training_loss": 136.30182189941405, "training_acc": 50.0, "val_loss": 8.030997276306152, "val_acc": 40.0}
{"epoch": 21, "training_loss": 63.239488220214845, "training_acc": 40.0, "val_loss": 187.679443359375, "val_acc": 60.0}
{"epoch": 22, "training_loss": 220.63063354492186, "training_acc": 50.0, "val_loss": 11.422505378723145, "val_acc": 40.0}
{"epoch": 23, "training_loss": 34.16906661987305, "training_acc": 50.0, "val_loss": 39.93003463745117, "val_acc": 40.0}
{"epoch": 24, "training_loss": 49.62927398681641, "training_acc": 50.0, "val_loss": 130.45211791992188, "val_acc": 60.0}
{"epoch": 25, "training_loss": 152.75616455078125, "training_acc": 50.0, "val_loss": 48.713722229003906, "val_acc": 40.0}
{"epoch": 26, "training_loss": 54.57527160644531, "training_acc": 50.0, "val_loss": 3.8868470191955566, "val_acc": 60.0}
{"epoch": 27, "training_loss": 5.979521179199219, "training_acc": 50.0, "val_loss": 105.74073791503906, "val_acc": 40.0}
{"epoch": 28, "training_loss": 83.66716613769532, "training_acc": 50.0, "val_loss": 16.749975204467773, "val_acc": 60.0}
{"epoch": 29, "training_loss": 25.242340087890625, "training_acc": 50.0, "val_loss": 119.8961181640625, "val_acc": 40.0}
{"epoch": 30, "training_loss": 119.54171142578124, "training_acc": 50.0, "val_loss": 5.865122318267822, "val_acc": 80.0}
{"epoch": 31, "training_loss": 32.367747688293456, "training_acc": 80.0, "val_loss": 160.4442596435547, "val_acc": 60.0}
{"epoch": 32, "training_loss": 191.45140380859374, "training_acc": 50.0, "val_loss": 2.7550837993621826, "val_acc": 60.0}
{"epoch": 33, "training_loss": 19.39556770324707, "training_acc": 75.0, "val_loss": 329.119384765625, "val_acc": 40.0}
{"epoch": 34, "training_loss": 276.80657958984375, "training_acc": 50.0, "val_loss": 178.4544219970703, "val_acc": 40.0}
{"epoch": 35, "training_loss": 108.10985984802247, "training_acc": 60.0, "val_loss": 154.85040283203125, "val_acc": 60.0}
{"epoch": 36, "training_loss": 208.2819396972656, "training_acc": 50.0, "val_loss": 96.3251953125, "val_acc": 60.0}
{"epoch": 37, "training_loss": 112.79805755615234, "training_acc": 50.0, "val_loss": 183.92510986328125, "val_acc": 40.0}
{"epoch": 38, "training_loss": 149.5878173828125, "training_acc": 50.0, "val_loss": 69.64418029785156, "val_acc": 40.0}
{"epoch": 39, "training_loss": 76.5762725830078, "training_acc": 40.0, "val_loss": 59.3556022644043, "val_acc": 60.0}
{"epoch": 40, "training_loss": 64.89750328063965, "training_acc": 50.0, "val_loss": 32.186824798583984, "val_acc": 40.0}
{"epoch": 41, "training_loss": 32.890771484375, "training_acc": 50.0, "val_loss": 43.2657585144043, "val_acc": 60.0}
{"epoch": 42, "training_loss": 68.53155517578125, "training_acc": 40.0, "val_loss": 21.152305603027344, "val_acc": 40.0}
{"epoch": 43, "training_loss": 8.911558532714844, "training_acc": 70.0, "val_loss": 146.8315887451172, "val_acc": 60.0}
{"epoch": 44, "training_loss": 188.20391845703125, "training_acc": 50.0, "val_loss": 32.53095626831055, "val_acc": 60.0}
{"epoch": 45, "training_loss": 124.37344055175781, "training_acc": 30.0, "val_loss": 282.11224365234375, "val_acc": 40.0}
{"epoch": 46, "training_loss": 212.92843017578124, "training_acc": 50.0, "val_loss": 27.49277114868164, "val_acc": 60.0}
{"epoch": 47, "training_loss": 74.47826538085937, "training_acc": 50.0, "val_loss": 102.9228744506836, "val_acc": 60.0}
{"epoch": 48, "training_loss": 97.58473625183106, "training_acc": 50.0, "val_loss": 263.5921325683594, "val_acc": 40.0}
{"epoch": 49, "training_loss": 241.0208312988281, "training_acc": 50.0, "val_loss": 432.0494689941406, "val_acc": 40.0}
{"epoch": 50, "training_loss": 346.8374786376953, "training_acc": 50.0, "val_loss": 160.4419708251953, "val_acc": 40.0}
{"epoch": 51, "training_loss": 142.41678161621093, "training_acc": 40.0, "val_loss": 115.94438934326172, "val_acc": 60.0}
