"main_modify.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 2 --task ADNI_sex --input_option yAware --learning_rate 5e0 --batch_size 16 --weight_decay 5e-9 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 214.03691444396972, "training_acc": 50.0, "val_loss": 248.5080108642578, "val_acc": 60.0}
{"epoch": 1, "training_loss": 275.0689270019531, "training_acc": 60.0, "val_loss": 1258.487548828125, "val_acc": 40.0}
{"epoch": 2, "training_loss": 1053.8004150390625, "training_acc": 50.0, "val_loss": 867.9006958007812, "val_acc": 40.0}
{"epoch": 3, "training_loss": 619.9007720947266, "training_acc": 50.0, "val_loss": 313.9510803222656, "val_acc": 60.0}
{"epoch": 4, "training_loss": 456.454296875, "training_acc": 50.0, "val_loss": 650.7130737304688, "val_acc": 60.0}
{"epoch": 5, "training_loss": 796.510693359375, "training_acc": 50.0, "val_loss": 408.2004089355469, "val_acc": 60.0}
{"epoch": 6, "training_loss": 473.82411041259763, "training_acc": 50.0, "val_loss": 286.6435241699219, "val_acc": 40.0}
{"epoch": 7, "training_loss": 277.3801635742187, "training_acc": 50.0, "val_loss": 571.2076416015625, "val_acc": 40.0}
{"epoch": 8, "training_loss": 445.65205078125, "training_acc": 50.0, "val_loss": 128.12803649902344, "val_acc": 40.0}
{"epoch": 9, "training_loss": 182.47948608398437, "training_acc": 40.0, "val_loss": 369.42535400390625, "val_acc": 60.0}
{"epoch": 10, "training_loss": 463.64190979003905, "training_acc": 50.0, "val_loss": 361.8309020996094, "val_acc": 60.0}
{"epoch": 11, "training_loss": 412.9387451171875, "training_acc": 50.0, "val_loss": 37.01471710205078, "val_acc": 60.0}
{"epoch": 12, "training_loss": 98.2168212890625, "training_acc": 50.0, "val_loss": 623.7931518554688, "val_acc": 40.0}
{"epoch": 13, "training_loss": 534.662744140625, "training_acc": 50.0, "val_loss": 680.5966796875, "val_acc": 40.0}
{"epoch": 14, "training_loss": 549.8531127929688, "training_acc": 50.0, "val_loss": 273.3155517578125, "val_acc": 40.0}
{"epoch": 15, "training_loss": 221.68234558105468, "training_acc": 40.0, "val_loss": 126.7760238647461, "val_acc": 60.0}
{"epoch": 16, "training_loss": 155.22638854980468, "training_acc": 50.0, "val_loss": 20.492952346801758, "val_acc": 60.0}
{"epoch": 17, "training_loss": 80.80600128173828, "training_acc": 40.0, "val_loss": 285.6211242675781, "val_acc": 40.0}
{"epoch": 18, "training_loss": 228.03209075927734, "training_acc": 50.0, "val_loss": 53.372833251953125, "val_acc": 40.0}
{"epoch": 19, "training_loss": 91.11884765625, "training_acc": 40.0, "val_loss": 175.9273223876953, "val_acc": 60.0}
{"epoch": 20, "training_loss": 206.7054656982422, "training_acc": 50.0, "val_loss": 4.313645362854004, "val_acc": 60.0}
{"epoch": 21, "training_loss": 76.6554458618164, "training_acc": 40.0, "val_loss": 382.0632019042969, "val_acc": 40.0}
{"epoch": 22, "training_loss": 308.27734375, "training_acc": 50.0, "val_loss": 189.821044921875, "val_acc": 40.0}
{"epoch": 23, "training_loss": 135.28871002197266, "training_acc": 50.0, "val_loss": 118.45599365234375, "val_acc": 60.0}
{"epoch": 24, "training_loss": 146.08506469726564, "training_acc": 50.0, "val_loss": 2.797785997390747, "val_acc": 40.0}
{"epoch": 25, "training_loss": 18.569236183166502, "training_acc": 70.0, "val_loss": 92.2739486694336, "val_acc": 40.0}
{"epoch": 26, "training_loss": 53.07779970169067, "training_acc": 60.0, "val_loss": 52.290283203125, "val_acc": 60.0}
{"epoch": 27, "training_loss": 49.83074188232422, "training_acc": 50.0, "val_loss": 211.8520965576172, "val_acc": 40.0}
{"epoch": 28, "training_loss": 188.3214111328125, "training_acc": 50.0, "val_loss": 263.635986328125, "val_acc": 40.0}
{"epoch": 29, "training_loss": 202.3116714477539, "training_acc": 50.0, "val_loss": 77.4835205078125, "val_acc": 60.0}
{"epoch": 30, "training_loss": 108.88091430664062, "training_acc": 50.0, "val_loss": 87.31929779052734, "val_acc": 60.0}
{"epoch": 31, "training_loss": 64.6089367983368, "training_acc": 70.0, "val_loss": 136.2956085205078, "val_acc": 40.0}
{"epoch": 32, "training_loss": 109.09065246582031, "training_acc": 50.0, "val_loss": 2.445577383041382, "val_acc": 40.0}
{"epoch": 33, "training_loss": 36.10466079711914, "training_acc": 65.0, "val_loss": 60.347389221191406, "val_acc": 60.0}
{"epoch": 34, "training_loss": 57.454566955566406, "training_acc": 60.0, "val_loss": 134.65382385253906, "val_acc": 40.0}
{"epoch": 35, "training_loss": 99.77778778076171, "training_acc": 50.0, "val_loss": 78.2955551147461, "val_acc": 60.0}
{"epoch": 36, "training_loss": 108.57757873535157, "training_acc": 50.0, "val_loss": 89.7487564086914, "val_acc": 60.0}
{"epoch": 37, "training_loss": 79.57997331619262, "training_acc": 60.0, "val_loss": 100.2747573852539, "val_acc": 40.0}
{"epoch": 38, "training_loss": 72.67415161132813, "training_acc": 50.0, "val_loss": 75.55970764160156, "val_acc": 60.0}
{"epoch": 39, "training_loss": 95.11091842651368, "training_acc": 50.0, "val_loss": 50.08903121948242, "val_acc": 60.0}
{"epoch": 40, "training_loss": 81.23736267089843, "training_acc": 40.0, "val_loss": 85.60005950927734, "val_acc": 40.0}
{"epoch": 41, "training_loss": 47.86776618957519, "training_acc": 60.0, "val_loss": 56.294898986816406, "val_acc": 60.0}
{"epoch": 42, "training_loss": 63.35412178039551, "training_acc": 45.0, "val_loss": 19.53132438659668, "val_acc": 60.0}
{"epoch": 43, "training_loss": 37.43978424072266, "training_acc": 40.0, "val_loss": 10.172396659851074, "val_acc": 60.0}
{"epoch": 44, "training_loss": 12.5499267578125, "training_acc": 50.0, "val_loss": 39.56404495239258, "val_acc": 60.0}
{"epoch": 45, "training_loss": 41.09543304443359, "training_acc": 50.0, "val_loss": 176.9830780029297, "val_acc": 40.0}
{"epoch": 46, "training_loss": 174.39895629882812, "training_acc": 50.0, "val_loss": 121.82292938232422, "val_acc": 40.0}
{"epoch": 47, "training_loss": 97.30583801269532, "training_acc": 50.0, "val_loss": 163.1255340576172, "val_acc": 60.0}
{"epoch": 48, "training_loss": 199.9575439453125, "training_acc": 50.0, "val_loss": 56.76455307006836, "val_acc": 60.0}
{"epoch": 49, "training_loss": 102.32839660644531, "training_acc": 40.0, "val_loss": 224.77334594726562, "val_acc": 40.0}
{"epoch": 50, "training_loss": 166.73403625488282, "training_acc": 50.0, "val_loss": 37.978477478027344, "val_acc": 60.0}
{"epoch": 51, "training_loss": 53.9480339050293, "training_acc": 50.0, "val_loss": 89.67433166503906, "val_acc": 60.0}
