"main_modify.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 2 --task ADNI_sex --input_option yAware --learning_rate 5e0 --batch_size 16 --weight_decay 5e-9 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 107.53695483207703, "training_acc": 60.0, "val_loss": 393.5377502441406, "val_acc": 60.0}
{"epoch": 1, "training_loss": 537.5009704589844, "training_acc": 40.0, "val_loss": 308.9283752441406, "val_acc": 40.0}
{"epoch": 2, "training_loss": 216.07886276245117, "training_acc": 50.0, "val_loss": 50.91204833984375, "val_acc": 60.0}
{"epoch": 3, "training_loss": 134.0945068359375, "training_acc": 30.0, "val_loss": 40.61250686645508, "val_acc": 40.0}
{"epoch": 4, "training_loss": 74.00234985351562, "training_acc": 50.0, "val_loss": 261.4913024902344, "val_acc": 60.0}
{"epoch": 5, "training_loss": 318.8691375732422, "training_acc": 50.0, "val_loss": 94.74259185791016, "val_acc": 60.0}
{"epoch": 6, "training_loss": 148.4917236328125, "training_acc": 40.0, "val_loss": 216.4114227294922, "val_acc": 40.0}
{"epoch": 7, "training_loss": 170.1080322265625, "training_acc": 50.0, "val_loss": 50.66102600097656, "val_acc": 60.0}
{"epoch": 8, "training_loss": 65.45027770996094, "training_acc": 50.0, "val_loss": 26.93433952331543, "val_acc": 40.0}
{"epoch": 9, "training_loss": 32.40102920532227, "training_acc": 30.0, "val_loss": 165.84397888183594, "val_acc": 40.0}
{"epoch": 10, "training_loss": 155.22356567382812, "training_acc": 50.0, "val_loss": 115.85847473144531, "val_acc": 40.0}
{"epoch": 11, "training_loss": 95.4260040283203, "training_acc": 50.0, "val_loss": 129.31455993652344, "val_acc": 60.0}
{"epoch": 12, "training_loss": 154.71252822875977, "training_acc": 50.0, "val_loss": 14.298848152160645, "val_acc": 60.0}
{"epoch": 13, "training_loss": 46.074981689453125, "training_acc": 50.0, "val_loss": 278.3155212402344, "val_acc": 40.0}
{"epoch": 14, "training_loss": 226.34404907226562, "training_acc": 50.0, "val_loss": 99.93590545654297, "val_acc": 40.0}
{"epoch": 15, "training_loss": 108.88134155273437, "training_acc": 40.0, "val_loss": 114.0769271850586, "val_acc": 60.0}
{"epoch": 16, "training_loss": 132.35045051574707, "training_acc": 50.0, "val_loss": 78.15691375732422, "val_acc": 40.0}
{"epoch": 17, "training_loss": 71.43699951171875, "training_acc": 50.0, "val_loss": 22.597013473510742, "val_acc": 60.0}
{"epoch": 18, "training_loss": 33.25651550292969, "training_acc": 50.0, "val_loss": 80.95040130615234, "val_acc": 40.0}
{"epoch": 19, "training_loss": 66.48044052124024, "training_acc": 50.0, "val_loss": 27.055917739868164, "val_acc": 40.0}
{"epoch": 20, "training_loss": 38.16383361816406, "training_acc": 50.0, "val_loss": 113.98286437988281, "val_acc": 60.0}
{"epoch": 21, "training_loss": 121.63126525878906, "training_acc": 50.0, "val_loss": 135.99790954589844, "val_acc": 40.0}
{"epoch": 22, "training_loss": 140.70298461914064, "training_acc": 50.0, "val_loss": 178.0388641357422, "val_acc": 40.0}
{"epoch": 23, "training_loss": 117.94664613064378, "training_acc": 60.0, "val_loss": 109.5122299194336, "val_acc": 60.0}
{"epoch": 24, "training_loss": 139.77574768066407, "training_acc": 50.0, "val_loss": 73.904052734375, "val_acc": 60.0}
{"epoch": 25, "training_loss": 85.32220458984375, "training_acc": 50.0, "val_loss": 139.2530517578125, "val_acc": 40.0}
{"epoch": 26, "training_loss": 104.55471801757812, "training_acc": 50.0, "val_loss": 64.28665924072266, "val_acc": 60.0}
{"epoch": 27, "training_loss": 91.4400390625, "training_acc": 50.0, "val_loss": 17.3804874420166, "val_acc": 60.0}
{"epoch": 28, "training_loss": 69.71622924804687, "training_acc": 40.0, "val_loss": 258.7065124511719, "val_acc": 40.0}
{"epoch": 29, "training_loss": 200.60110778808593, "training_acc": 50.0, "val_loss": 0.6097099184989929, "val_acc": 80.0}
{"epoch": 30, "training_loss": 29.508431148529052, "training_acc": 85.0, "val_loss": 142.24119567871094, "val_acc": 60.0}
{"epoch": 31, "training_loss": 157.6856719970703, "training_acc": 50.0, "val_loss": 81.55786895751953, "val_acc": 40.0}
{"epoch": 32, "training_loss": 72.01916961669922, "training_acc": 50.0, "val_loss": 173.421142578125, "val_acc": 40.0}
{"epoch": 33, "training_loss": 121.34424743652343, "training_acc": 50.0, "val_loss": 113.1900405883789, "val_acc": 60.0}
{"epoch": 34, "training_loss": 147.0308410644531, "training_acc": 50.0, "val_loss": 200.66722106933594, "val_acc": 60.0}
{"epoch": 35, "training_loss": 238.78146362304688, "training_acc": 50.0, "val_loss": 29.545612335205078, "val_acc": 60.0}
{"epoch": 36, "training_loss": 87.23773803710938, "training_acc": 40.0, "val_loss": 286.91534423828125, "val_acc": 40.0}
{"epoch": 37, "training_loss": 228.39418334960936, "training_acc": 50.0, "val_loss": 59.0103645324707, "val_acc": 40.0}
{"epoch": 38, "training_loss": 46.51015930175781, "training_acc": 60.0, "val_loss": 242.60081481933594, "val_acc": 60.0}
{"epoch": 39, "training_loss": 312.42982177734376, "training_acc": 50.0, "val_loss": 189.2390594482422, "val_acc": 60.0}
{"epoch": 40, "training_loss": 194.2574264526367, "training_acc": 50.0, "val_loss": 278.6203308105469, "val_acc": 40.0}
{"epoch": 41, "training_loss": 258.1754943847656, "training_acc": 50.0, "val_loss": 503.05596923828125, "val_acc": 40.0}
{"epoch": 42, "training_loss": 407.93041076660154, "training_acc": 50.0, "val_loss": 265.7234191894531, "val_acc": 40.0}
{"epoch": 43, "training_loss": 198.58812055587768, "training_acc": 50.0, "val_loss": 193.0763397216797, "val_acc": 60.0}
{"epoch": 44, "training_loss": 261.528369140625, "training_acc": 50.0, "val_loss": 301.3503112792969, "val_acc": 60.0}
{"epoch": 45, "training_loss": 362.4369140625, "training_acc": 50.0, "val_loss": 106.3301773071289, "val_acc": 60.0}
{"epoch": 46, "training_loss": 147.5397155761719, "training_acc": 40.0, "val_loss": 202.65220642089844, "val_acc": 40.0}
{"epoch": 47, "training_loss": 156.52583923339844, "training_acc": 50.0, "val_loss": 2.076798915863037, "val_acc": 80.0}
{"epoch": 48, "training_loss": 22.225954914093016, "training_acc": 85.0, "val_loss": 80.62899017333984, "val_acc": 60.0}
