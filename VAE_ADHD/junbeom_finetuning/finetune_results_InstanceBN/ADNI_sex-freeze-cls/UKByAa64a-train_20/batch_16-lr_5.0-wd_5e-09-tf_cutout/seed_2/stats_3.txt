"main_modify.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 2 --task ADNI_sex --input_option yAware --learning_rate 5e0 --batch_size 16 --weight_decay 5e-9 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 214.69140062332153, "training_acc": 55.0, "val_loss": 369.8403015136719, "val_acc": 40.0}
{"epoch": 1, "training_loss": 423.078662109375, "training_acc": 45.0, "val_loss": 515.2572631835938, "val_acc": 60.0}
{"epoch": 2, "training_loss": 645.7464477539063, "training_acc": 45.0, "val_loss": 31.560510635375977, "val_acc": 40.0}
{"epoch": 3, "training_loss": 66.689990234375, "training_acc": 55.0, "val_loss": 300.46868896484375, "val_acc": 40.0}
{"epoch": 4, "training_loss": 196.5910202026367, "training_acc": 55.0, "val_loss": 129.89297485351562, "val_acc": 60.0}
{"epoch": 5, "training_loss": 193.1292755126953, "training_acc": 45.0, "val_loss": 117.1769790649414, "val_acc": 60.0}
{"epoch": 6, "training_loss": 147.5808135986328, "training_acc": 45.0, "val_loss": 167.47181701660156, "val_acc": 40.0}
{"epoch": 7, "training_loss": 117.31328506469727, "training_acc": 55.0, "val_loss": 48.159812927246094, "val_acc": 60.0}
{"epoch": 8, "training_loss": 63.5439697265625, "training_acc": 45.0, "val_loss": 166.79098510742188, "val_acc": 40.0}
{"epoch": 9, "training_loss": 129.10948028564454, "training_acc": 55.0, "val_loss": 210.0442352294922, "val_acc": 40.0}
{"epoch": 10, "training_loss": 133.16393508911133, "training_acc": 55.0, "val_loss": 124.9381332397461, "val_acc": 60.0}
{"epoch": 11, "training_loss": 185.388330078125, "training_acc": 45.0, "val_loss": 132.92379760742188, "val_acc": 60.0}
{"epoch": 12, "training_loss": 135.03606796264648, "training_acc": 45.0, "val_loss": 358.10772705078125, "val_acc": 40.0}
{"epoch": 13, "training_loss": 267.240185546875, "training_acc": 55.0, "val_loss": 702.6613159179688, "val_acc": 40.0}
{"epoch": 14, "training_loss": 525.9064147949218, "training_acc": 55.0, "val_loss": 667.8517456054688, "val_acc": 40.0}
{"epoch": 15, "training_loss": 498.31630859375, "training_acc": 55.0, "val_loss": 299.3108215332031, "val_acc": 40.0}
{"epoch": 16, "training_loss": 177.24218711853027, "training_acc": 55.0, "val_loss": 232.83023071289062, "val_acc": 60.0}
{"epoch": 17, "training_loss": 351.61961059570314, "training_acc": 45.0, "val_loss": 385.95751953125, "val_acc": 60.0}
{"epoch": 18, "training_loss": 530.92578125, "training_acc": 45.0, "val_loss": 206.63487243652344, "val_acc": 60.0}
{"epoch": 19, "training_loss": 239.56227951049806, "training_acc": 45.0, "val_loss": 311.5741882324219, "val_acc": 40.0}
{"epoch": 20, "training_loss": 248.89926147460938, "training_acc": 55.0, "val_loss": 623.9559326171875, "val_acc": 40.0}
{"epoch": 21, "training_loss": 463.6256805419922, "training_acc": 55.0, "val_loss": 505.8567810058594, "val_acc": 40.0}
{"epoch": 22, "training_loss": 344.659912109375, "training_acc": 55.0, "val_loss": 2.0775575637817383, "val_acc": 80.0}
{"epoch": 23, "training_loss": 75.81412615776063, "training_acc": 80.0, "val_loss": 250.0812530517578, "val_acc": 60.0}
{"epoch": 24, "training_loss": 328.1228515625, "training_acc": 45.0, "val_loss": 42.295406341552734, "val_acc": 60.0}
{"epoch": 25, "training_loss": 97.83527526855468, "training_acc": 45.0, "val_loss": 505.6558532714844, "val_acc": 40.0}
{"epoch": 26, "training_loss": 398.9567504882813, "training_acc": 55.0, "val_loss": 479.0504455566406, "val_acc": 40.0}
{"epoch": 27, "training_loss": 337.6325485229492, "training_acc": 55.0, "val_loss": 13.43262004852295, "val_acc": 60.0}
{"epoch": 28, "training_loss": 32.07025375366211, "training_acc": 45.0, "val_loss": 55.39461898803711, "val_acc": 60.0}
{"epoch": 29, "training_loss": 74.05583953857422, "training_acc": 45.0, "val_loss": 122.99443817138672, "val_acc": 40.0}
{"epoch": 30, "training_loss": 76.03984298706055, "training_acc": 55.0, "val_loss": 107.1487045288086, "val_acc": 60.0}
{"epoch": 31, "training_loss": 158.10712890625, "training_acc": 45.0, "val_loss": 50.24198532104492, "val_acc": 60.0}
{"epoch": 32, "training_loss": 85.0036834716797, "training_acc": 45.0, "val_loss": 306.10858154296875, "val_acc": 40.0}
{"epoch": 33, "training_loss": 224.88491973876953, "training_acc": 55.0, "val_loss": 200.1598358154297, "val_acc": 40.0}
{"epoch": 34, "training_loss": 115.480029296875, "training_acc": 55.0, "val_loss": 186.05899047851562, "val_acc": 60.0}
{"epoch": 35, "training_loss": 306.5896240234375, "training_acc": 45.0, "val_loss": 213.3131103515625, "val_acc": 60.0}
{"epoch": 36, "training_loss": 250.49394836425782, "training_acc": 45.0, "val_loss": 261.6651306152344, "val_acc": 40.0}
{"epoch": 37, "training_loss": 226.47353515625, "training_acc": 55.0, "val_loss": 516.4627685546875, "val_acc": 40.0}
{"epoch": 38, "training_loss": 377.1723937988281, "training_acc": 55.0, "val_loss": 310.0030212402344, "val_acc": 40.0}
{"epoch": 39, "training_loss": 175.31878662109375, "training_acc": 55.0, "val_loss": 184.7607879638672, "val_acc": 60.0}
{"epoch": 40, "training_loss": 305.40791015625, "training_acc": 45.0, "val_loss": 331.24127197265625, "val_acc": 60.0}
{"epoch": 41, "training_loss": 423.694775390625, "training_acc": 45.0, "val_loss": 58.60405349731445, "val_acc": 60.0}
