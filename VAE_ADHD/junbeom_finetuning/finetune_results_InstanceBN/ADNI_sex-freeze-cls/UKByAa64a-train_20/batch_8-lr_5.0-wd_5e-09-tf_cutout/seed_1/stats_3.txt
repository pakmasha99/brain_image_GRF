"main_modify.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 1 --task ADNI_sex --input_option yAware --learning_rate 5e0 --batch_size 8 --weight_decay 5e-9 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 175.36192173957824, "training_acc": 60.0, "val_loss": 333.7080993652344, "val_acc": 60.0}
{"epoch": 1, "training_loss": 288.6217491149902, "training_acc": 50.0, "val_loss": 919.0189819335938, "val_acc": 40.0}
{"epoch": 2, "training_loss": 626.8040649414063, "training_acc": 50.0, "val_loss": 94.04561614990234, "val_acc": 60.0}
{"epoch": 3, "training_loss": 313.24884643554685, "training_acc": 50.0, "val_loss": 158.7978515625, "val_acc": 60.0}
{"epoch": 4, "training_loss": 276.35956420898435, "training_acc": 40.0, "val_loss": 427.45361328125, "val_acc": 40.0}
{"epoch": 5, "training_loss": 241.02254333496094, "training_acc": 50.0, "val_loss": 133.9817352294922, "val_acc": 60.0}
{"epoch": 6, "training_loss": 131.96423950195313, "training_acc": 40.0, "val_loss": 45.85316848754883, "val_acc": 40.0}
{"epoch": 7, "training_loss": 116.01252746582031, "training_acc": 40.0, "val_loss": 14.50281810760498, "val_acc": 40.0}
{"epoch": 8, "training_loss": 153.74237060546875, "training_acc": 50.0, "val_loss": 271.36944580078125, "val_acc": 40.0}
{"epoch": 9, "training_loss": 173.67267761230468, "training_acc": 40.0, "val_loss": 184.81578063964844, "val_acc": 60.0}
{"epoch": 10, "training_loss": 175.3641830444336, "training_acc": 50.0, "val_loss": 175.1709747314453, "val_acc": 40.0}
{"epoch": 11, "training_loss": 195.4738555908203, "training_acc": 50.0, "val_loss": 143.4801025390625, "val_acc": 40.0}
{"epoch": 12, "training_loss": 46.973868179321286, "training_acc": 60.0, "val_loss": 37.162689208984375, "val_acc": 60.0}
{"epoch": 13, "training_loss": 51.4180908203125, "training_acc": 50.0, "val_loss": 15.4658203125, "val_acc": 40.0}
{"epoch": 14, "training_loss": 6.6624813507078215, "training_acc": 70.0, "val_loss": 11.522294044494629, "val_acc": 80.0}
{"epoch": 15, "training_loss": 32.31949119567871, "training_acc": 50.0, "val_loss": 185.62576293945312, "val_acc": 40.0}
{"epoch": 16, "training_loss": 173.8006622314453, "training_acc": 50.0, "val_loss": 40.82160186767578, "val_acc": 40.0}
{"epoch": 17, "training_loss": 114.76440658569337, "training_acc": 60.0, "val_loss": 217.38980102539062, "val_acc": 60.0}
{"epoch": 18, "training_loss": 170.16611022949218, "training_acc": 50.0, "val_loss": 306.6603698730469, "val_acc": 40.0}
{"epoch": 19, "training_loss": 299.9845916748047, "training_acc": 50.0, "val_loss": 544.7083129882812, "val_acc": 40.0}
{"epoch": 20, "training_loss": 335.1945434570313, "training_acc": 50.0, "val_loss": 152.54052734375, "val_acc": 60.0}
{"epoch": 21, "training_loss": 311.291455078125, "training_acc": 50.0, "val_loss": 266.5815124511719, "val_acc": 60.0}
{"epoch": 22, "training_loss": 233.82858581542968, "training_acc": 40.0, "val_loss": 234.20327758789062, "val_acc": 40.0}
{"epoch": 23, "training_loss": 164.98837890625, "training_acc": 50.0, "val_loss": 90.8346176147461, "val_acc": 60.0}
{"epoch": 24, "training_loss": 184.70167846679686, "training_acc": 50.0, "val_loss": 146.46678161621094, "val_acc": 60.0}
{"epoch": 25, "training_loss": 87.95981159210206, "training_acc": 70.0, "val_loss": 337.6012268066406, "val_acc": 40.0}
{"epoch": 26, "training_loss": 246.22730102539063, "training_acc": 50.0, "val_loss": 9.449952125549316, "val_acc": 60.0}
{"epoch": 27, "training_loss": 63.25277309417724, "training_acc": 65.0, "val_loss": 65.11796569824219, "val_acc": 60.0}
{"epoch": 28, "training_loss": 66.41913681030273, "training_acc": 60.0, "val_loss": 59.66009521484375, "val_acc": 40.0}
{"epoch": 29, "training_loss": 92.41239776611329, "training_acc": 50.0, "val_loss": 105.75640106201172, "val_acc": 60.0}
{"epoch": 30, "training_loss": 84.20376052856446, "training_acc": 55.0, "val_loss": 211.5813446044922, "val_acc": 40.0}
{"epoch": 31, "training_loss": 118.56644592285156, "training_acc": 50.0, "val_loss": 131.58018493652344, "val_acc": 60.0}
{"epoch": 32, "training_loss": 104.087481880188, "training_acc": 55.0, "val_loss": 112.9410629272461, "val_acc": 40.0}
{"epoch": 33, "training_loss": 73.54215183258057, "training_acc": 55.0, "val_loss": 71.29242706298828, "val_acc": 60.0}
{"epoch": 34, "training_loss": 66.80813140869141, "training_acc": 45.0, "val_loss": 89.6247329711914, "val_acc": 40.0}
{"epoch": 35, "training_loss": 77.2375259399414, "training_acc": 40.0, "val_loss": 10.061982154846191, "val_acc": 60.0}
{"epoch": 36, "training_loss": 51.142111492156985, "training_acc": 65.0, "val_loss": 12.525612831115723, "val_acc": 40.0}
{"epoch": 37, "training_loss": 10.042208051681518, "training_acc": 55.0, "val_loss": 67.84862518310547, "val_acc": 60.0}
{"epoch": 38, "training_loss": 88.46565246582031, "training_acc": 50.0, "val_loss": 195.4025421142578, "val_acc": 40.0}
{"epoch": 39, "training_loss": 206.15682678222657, "training_acc": 50.0, "val_loss": 113.40400695800781, "val_acc": 40.0}
{"epoch": 40, "training_loss": 96.61294250488281, "training_acc": 50.0, "val_loss": 171.4651336669922, "val_acc": 60.0}
{"epoch": 41, "training_loss": 127.5373031616211, "training_acc": 50.0, "val_loss": 280.2455749511719, "val_acc": 40.0}
{"epoch": 42, "training_loss": 361.62592163085935, "training_acc": 50.0, "val_loss": 508.3276062011719, "val_acc": 40.0}
{"epoch": 43, "training_loss": 298.2216278076172, "training_acc": 40.0, "val_loss": 73.36846160888672, "val_acc": 60.0}
{"epoch": 44, "training_loss": 56.759262114763246, "training_acc": 65.0, "val_loss": 120.51268768310547, "val_acc": 40.0}
{"epoch": 45, "training_loss": 66.49038696289062, "training_acc": 50.0, "val_loss": 27.6476993560791, "val_acc": 60.0}
