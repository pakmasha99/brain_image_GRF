"main_modify.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 2 --task ADNI_sex --input_option yAware --learning_rate 5e0 --batch_size 8 --weight_decay 5e-9 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 606.1016554832458, "training_acc": 50.0, "val_loss": 400.1229553222656, "val_acc": 60.0}
{"epoch": 1, "training_loss": 574.12705078125, "training_acc": 50.0, "val_loss": 253.11318969726562, "val_acc": 60.0}
{"epoch": 2, "training_loss": 261.7300231933594, "training_acc": 40.0, "val_loss": 192.4955291748047, "val_acc": 40.0}
{"epoch": 3, "training_loss": 106.3095687866211, "training_acc": 50.0, "val_loss": 22.829870223999023, "val_acc": 40.0}
{"epoch": 4, "training_loss": 32.25159683227539, "training_acc": 50.0, "val_loss": 9.487692832946777, "val_acc": 40.0}
{"epoch": 5, "training_loss": 117.52616806030274, "training_acc": 40.0, "val_loss": 9.270474433898926, "val_acc": 60.0}
{"epoch": 6, "training_loss": 160.80203742980956, "training_acc": 50.0, "val_loss": 421.3065490722656, "val_acc": 40.0}
{"epoch": 7, "training_loss": 296.94984970092776, "training_acc": 50.0, "val_loss": 134.629638671875, "val_acc": 60.0}
{"epoch": 8, "training_loss": 283.1866760253906, "training_acc": 50.0, "val_loss": 163.90420532226562, "val_acc": 60.0}
{"epoch": 9, "training_loss": 95.71473083496093, "training_acc": 50.0, "val_loss": 133.15370178222656, "val_acc": 40.0}
{"epoch": 10, "training_loss": 107.92188415527343, "training_acc": 40.0, "val_loss": 123.2239761352539, "val_acc": 60.0}
{"epoch": 11, "training_loss": 137.59530639648438, "training_acc": 40.0, "val_loss": 204.68101501464844, "val_acc": 40.0}
{"epoch": 12, "training_loss": 124.43923912048339, "training_acc": 50.0, "val_loss": 48.20211410522461, "val_acc": 60.0}
{"epoch": 13, "training_loss": 37.07019882202148, "training_acc": 50.0, "val_loss": 9.956674575805664, "val_acc": 40.0}
{"epoch": 14, "training_loss": 73.53575820922852, "training_acc": 40.0, "val_loss": 81.55575561523438, "val_acc": 40.0}
{"epoch": 15, "training_loss": 119.42744140625, "training_acc": 50.0, "val_loss": 10.45650577545166, "val_acc": 60.0}
{"epoch": 16, "training_loss": 40.51184024810791, "training_acc": 50.0, "val_loss": 8.02977466583252, "val_acc": 60.0}
{"epoch": 17, "training_loss": 68.5389617919922, "training_acc": 40.0, "val_loss": 60.269989013671875, "val_acc": 60.0}
{"epoch": 18, "training_loss": 108.51389770507812, "training_acc": 50.0, "val_loss": 25.546499252319336, "val_acc": 40.0}
{"epoch": 19, "training_loss": 37.73286819458008, "training_acc": 40.0, "val_loss": 14.002490043640137, "val_acc": 60.0}
{"epoch": 20, "training_loss": 148.3207565307617, "training_acc": 30.0, "val_loss": 155.3159942626953, "val_acc": 40.0}
{"epoch": 21, "training_loss": 112.36650695800782, "training_acc": 40.0, "val_loss": 19.47698974609375, "val_acc": 60.0}
{"epoch": 22, "training_loss": 91.36720733642578, "training_acc": 50.0, "val_loss": 182.77645874023438, "val_acc": 40.0}
{"epoch": 23, "training_loss": 91.14035396575927, "training_acc": 60.0, "val_loss": 193.13226318359375, "val_acc": 60.0}
{"epoch": 24, "training_loss": 241.41083374023438, "training_acc": 50.0, "val_loss": 15.185988426208496, "val_acc": 40.0}
{"epoch": 25, "training_loss": 45.535575485229494, "training_acc": 50.0, "val_loss": 50.328285217285156, "val_acc": 60.0}
{"epoch": 26, "training_loss": 72.73588485717774, "training_acc": 40.0, "val_loss": 17.05950927734375, "val_acc": 60.0}
{"epoch": 27, "training_loss": 31.382699298858643, "training_acc": 45.0, "val_loss": 4.555907726287842, "val_acc": 80.0}
{"epoch": 28, "training_loss": 17.96404175758362, "training_acc": 55.0, "val_loss": 9.808423042297363, "val_acc": 60.0}
{"epoch": 29, "training_loss": 6.931009721755982, "training_acc": 65.0, "val_loss": 13.109702110290527, "val_acc": 60.0}
{"epoch": 30, "training_loss": 39.07990456521511, "training_acc": 55.0, "val_loss": 50.39873504638672, "val_acc": 40.0}
{"epoch": 31, "training_loss": 24.14973373413086, "training_acc": 50.0, "val_loss": 21.679258346557617, "val_acc": 60.0}
{"epoch": 32, "training_loss": 32.42054824829101, "training_acc": 40.0, "val_loss": 16.837890625, "val_acc": 40.0}
{"epoch": 33, "training_loss": 68.38192520141601, "training_acc": 30.0, "val_loss": 119.69384002685547, "val_acc": 40.0}
{"epoch": 34, "training_loss": 142.57899475097656, "training_acc": 50.0, "val_loss": 4.723145961761475, "val_acc": 40.0}
{"epoch": 35, "training_loss": 28.23943567276001, "training_acc": 55.0, "val_loss": 103.51069641113281, "val_acc": 40.0}
{"epoch": 36, "training_loss": 79.15109252929688, "training_acc": 40.0, "val_loss": 11.660807609558105, "val_acc": 60.0}
{"epoch": 37, "training_loss": 45.12398071289063, "training_acc": 60.0, "val_loss": 9.646036148071289, "val_acc": 60.0}
{"epoch": 38, "training_loss": 56.16552200317383, "training_acc": 60.0, "val_loss": 113.94679260253906, "val_acc": 40.0}
{"epoch": 39, "training_loss": 108.26146621704102, "training_acc": 50.0, "val_loss": 4.798990726470947, "val_acc": 60.0}
{"epoch": 40, "training_loss": 20.43313808441162, "training_acc": 60.0, "val_loss": 8.019551277160645, "val_acc": 60.0}
{"epoch": 41, "training_loss": 23.90501160621643, "training_acc": 55.0, "val_loss": 50.56270980834961, "val_acc": 60.0}
{"epoch": 42, "training_loss": 72.31232604980468, "training_acc": 40.0, "val_loss": 90.00948333740234, "val_acc": 40.0}
{"epoch": 43, "training_loss": 24.622832107543946, "training_acc": 70.0, "val_loss": 8.843318939208984, "val_acc": 60.0}
{"epoch": 44, "training_loss": 21.727778053283693, "training_acc": 60.0, "val_loss": 46.1743278503418, "val_acc": 60.0}
{"epoch": 45, "training_loss": 86.91330642700196, "training_acc": 30.0, "val_loss": 102.09552001953125, "val_acc": 40.0}
{"epoch": 46, "training_loss": 32.929315185546876, "training_acc": 60.0, "val_loss": 5.212016582489014, "val_acc": 60.0}
