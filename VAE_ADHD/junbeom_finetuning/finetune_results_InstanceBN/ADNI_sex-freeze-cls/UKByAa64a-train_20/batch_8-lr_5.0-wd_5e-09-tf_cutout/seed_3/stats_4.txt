"main_modify.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 3 --task ADNI_sex --input_option yAware --learning_rate 5e0 --batch_size 8 --weight_decay 5e-9 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 691.525794839859, "training_acc": 35.0, "val_loss": 314.07391357421875, "val_acc": 40.0}
{"epoch": 1, "training_loss": 395.77330322265624, "training_acc": 55.0, "val_loss": 521.1386108398438, "val_acc": 40.0}
{"epoch": 2, "training_loss": 295.8648315429688, "training_acc": 45.0, "val_loss": 371.0591735839844, "val_acc": 60.0}
{"epoch": 3, "training_loss": 415.5886596679687, "training_acc": 45.0, "val_loss": 175.9944610595703, "val_acc": 40.0}
{"epoch": 4, "training_loss": 152.03064422607423, "training_acc": 55.0, "val_loss": 181.4003448486328, "val_acc": 40.0}
{"epoch": 5, "training_loss": 126.18988037109375, "training_acc": 35.0, "val_loss": 62.17974853515625, "val_acc": 40.0}
{"epoch": 6, "training_loss": 73.41819763183594, "training_acc": 35.0, "val_loss": 47.599510192871094, "val_acc": 40.0}
{"epoch": 7, "training_loss": 26.584284114837647, "training_acc": 65.0, "val_loss": 15.19766902923584, "val_acc": 60.0}
{"epoch": 8, "training_loss": 22.30859442352794, "training_acc": 65.0, "val_loss": 19.569900512695312, "val_acc": 60.0}
{"epoch": 9, "training_loss": 33.875057220458984, "training_acc": 55.0, "val_loss": 66.76311492919922, "val_acc": 60.0}
{"epoch": 10, "training_loss": 59.011591243743894, "training_acc": 55.0, "val_loss": 30.650060653686523, "val_acc": 40.0}
{"epoch": 11, "training_loss": 41.93971328735351, "training_acc": 45.0, "val_loss": 154.42796325683594, "val_acc": 40.0}
{"epoch": 12, "training_loss": 133.5820343017578, "training_acc": 55.0, "val_loss": 35.85238265991211, "val_acc": 40.0}
{"epoch": 13, "training_loss": 138.00164718627929, "training_acc": 45.0, "val_loss": 111.79976654052734, "val_acc": 60.0}
{"epoch": 14, "training_loss": 116.80248413085937, "training_acc": 45.0, "val_loss": 141.49630737304688, "val_acc": 40.0}
{"epoch": 15, "training_loss": 71.91290740966797, "training_acc": 55.0, "val_loss": 185.64878845214844, "val_acc": 60.0}
{"epoch": 16, "training_loss": 190.2684783935547, "training_acc": 45.0, "val_loss": 245.04092407226562, "val_acc": 40.0}
{"epoch": 17, "training_loss": 302.70899658203126, "training_acc": 55.0, "val_loss": 389.2410888671875, "val_acc": 40.0}
{"epoch": 18, "training_loss": 200.15111846923827, "training_acc": 55.0, "val_loss": 154.45962524414062, "val_acc": 60.0}
{"epoch": 19, "training_loss": 165.14575805664063, "training_acc": 45.0, "val_loss": 197.88290405273438, "val_acc": 40.0}
{"epoch": 20, "training_loss": 276.251953125, "training_acc": 55.0, "val_loss": 349.0936584472656, "val_acc": 40.0}
{"epoch": 21, "training_loss": 144.82889709472656, "training_acc": 55.0, "val_loss": 180.69578552246094, "val_acc": 60.0}
{"epoch": 22, "training_loss": 220.9236831665039, "training_acc": 45.0, "val_loss": 102.63439178466797, "val_acc": 40.0}
{"epoch": 23, "training_loss": 115.96997375488282, "training_acc": 55.0, "val_loss": 8.5032377243042, "val_acc": 60.0}
{"epoch": 24, "training_loss": 89.17023515701294, "training_acc": 70.0, "val_loss": 152.45240783691406, "val_acc": 60.0}
{"epoch": 25, "training_loss": 136.8910400390625, "training_acc": 45.0, "val_loss": 387.0790710449219, "val_acc": 40.0}
{"epoch": 26, "training_loss": 258.7838897705078, "training_acc": 55.0, "val_loss": 82.53497314453125, "val_acc": 40.0}
{"epoch": 27, "training_loss": 61.36707763671875, "training_acc": 75.0, "val_loss": 159.1554412841797, "val_acc": 60.0}
{"epoch": 28, "training_loss": 141.0515884399414, "training_acc": 45.0, "val_loss": 274.28076171875, "val_acc": 40.0}
{"epoch": 29, "training_loss": 171.6810516357422, "training_acc": 55.0, "val_loss": 38.5963249206543, "val_acc": 60.0}
{"epoch": 30, "training_loss": 73.01393203735351, "training_acc": 45.0, "val_loss": 149.5836944580078, "val_acc": 40.0}
{"epoch": 31, "training_loss": 139.38538208007813, "training_acc": 55.0, "val_loss": 33.5445556640625, "val_acc": 40.0}
{"epoch": 32, "training_loss": 143.10501403808593, "training_acc": 45.0, "val_loss": 85.74835205078125, "val_acc": 60.0}
{"epoch": 33, "training_loss": 200.76876831054688, "training_acc": 35.0, "val_loss": 256.0117492675781, "val_acc": 40.0}
{"epoch": 34, "training_loss": 105.07196197509765, "training_acc": 55.0, "val_loss": 197.26963806152344, "val_acc": 60.0}
{"epoch": 35, "training_loss": 224.38582458496094, "training_acc": 45.0, "val_loss": 132.19662475585938, "val_acc": 40.0}
{"epoch": 36, "training_loss": 169.99478302001953, "training_acc": 55.0, "val_loss": 179.87451171875, "val_acc": 40.0}
{"epoch": 37, "training_loss": 58.27067565917969, "training_acc": 65.0, "val_loss": 110.07984924316406, "val_acc": 60.0}
{"epoch": 38, "training_loss": 96.93053436279297, "training_acc": 45.0, "val_loss": 245.7792510986328, "val_acc": 40.0}
{"epoch": 39, "training_loss": 140.71305618286132, "training_acc": 55.0, "val_loss": 98.58841705322266, "val_acc": 60.0}
{"epoch": 40, "training_loss": 141.52022705078124, "training_acc": 45.0, "val_loss": 86.9688949584961, "val_acc": 40.0}
{"epoch": 41, "training_loss": 92.3684799194336, "training_acc": 55.0, "val_loss": 14.999651908874512, "val_acc": 60.0}
{"epoch": 42, "training_loss": 49.382918167114255, "training_acc": 65.0, "val_loss": 51.756019592285156, "val_acc": 60.0}
