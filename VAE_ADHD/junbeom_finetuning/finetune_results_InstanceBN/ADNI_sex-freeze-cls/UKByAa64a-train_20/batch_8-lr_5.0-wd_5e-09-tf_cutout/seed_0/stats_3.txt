"main_modify.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_sex --input_option yAware --learning_rate 5e0 --batch_size 8 --weight_decay 5e-9 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 484.85575289726256, "training_acc": 55.0, "val_loss": 193.940673828125, "val_acc": 60.0}
{"epoch": 1, "training_loss": 520.900439453125, "training_acc": 45.0, "val_loss": 98.97866821289062, "val_acc": 60.0}
{"epoch": 2, "training_loss": 182.97373657226564, "training_acc": 65.0, "val_loss": 593.7473754882812, "val_acc": 40.0}
{"epoch": 3, "training_loss": 313.6096527099609, "training_acc": 55.0, "val_loss": 236.5012664794922, "val_acc": 60.0}
{"epoch": 4, "training_loss": 441.7769714355469, "training_acc": 45.0, "val_loss": 230.2078857421875, "val_acc": 60.0}
{"epoch": 5, "training_loss": 132.3905456542969, "training_acc": 55.0, "val_loss": 670.5839233398438, "val_acc": 40.0}
{"epoch": 6, "training_loss": 584.1682739257812, "training_acc": 55.0, "val_loss": 706.7369384765625, "val_acc": 40.0}
{"epoch": 7, "training_loss": 352.1901550292969, "training_acc": 55.0, "val_loss": 171.2063446044922, "val_acc": 60.0}
{"epoch": 8, "training_loss": 419.02220458984374, "training_acc": 45.0, "val_loss": 352.1288146972656, "val_acc": 60.0}
{"epoch": 9, "training_loss": 344.87315979003904, "training_acc": 35.0, "val_loss": 263.3258056640625, "val_acc": 40.0}
{"epoch": 10, "training_loss": 201.62590942382812, "training_acc": 55.0, "val_loss": 7.680392742156982, "val_acc": 40.0}
{"epoch": 11, "training_loss": 135.82875213623046, "training_acc": 50.0, "val_loss": 91.54100799560547, "val_acc": 60.0}
{"epoch": 12, "training_loss": 127.77080383300782, "training_acc": 45.0, "val_loss": 241.50381469726562, "val_acc": 40.0}
{"epoch": 13, "training_loss": 168.08555908203124, "training_acc": 35.0, "val_loss": 62.7905158996582, "val_acc": 60.0}
{"epoch": 14, "training_loss": 74.42732543945313, "training_acc": 45.0, "val_loss": 11.893311500549316, "val_acc": 40.0}
{"epoch": 15, "training_loss": 119.79132232666015, "training_acc": 40.0, "val_loss": 47.05269241333008, "val_acc": 60.0}
{"epoch": 16, "training_loss": 91.77779846191406, "training_acc": 55.0, "val_loss": 249.5705108642578, "val_acc": 40.0}
{"epoch": 17, "training_loss": 150.83164978027344, "training_acc": 45.0, "val_loss": 68.49359130859375, "val_acc": 60.0}
{"epoch": 18, "training_loss": 50.35434303879738, "training_acc": 45.0, "val_loss": 30.757184982299805, "val_acc": 60.0}
{"epoch": 19, "training_loss": 32.202345275878905, "training_acc": 45.0, "val_loss": 82.6042251586914, "val_acc": 60.0}
{"epoch": 20, "training_loss": 73.1958625793457, "training_acc": 55.0, "val_loss": 65.86099243164062, "val_acc": 40.0}
{"epoch": 21, "training_loss": 44.50830574035645, "training_acc": 35.0, "val_loss": 5.538266181945801, "val_acc": 60.0}
{"epoch": 22, "training_loss": 31.908887213468553, "training_acc": 65.0, "val_loss": 5.629196643829346, "val_acc": 60.0}
{"epoch": 23, "training_loss": 24.372579193115236, "training_acc": 50.0, "val_loss": 127.78741455078125, "val_acc": 40.0}
{"epoch": 24, "training_loss": 65.94857482910156, "training_acc": 55.0, "val_loss": 134.36062622070312, "val_acc": 60.0}
{"epoch": 25, "training_loss": 111.49827346801757, "training_acc": 55.0, "val_loss": 175.75662231445312, "val_acc": 40.0}
{"epoch": 26, "training_loss": 117.80058898925782, "training_acc": 35.0, "val_loss": 51.30745315551758, "val_acc": 40.0}
{"epoch": 27, "training_loss": 43.43196368217468, "training_acc": 50.0, "val_loss": 52.67612838745117, "val_acc": 40.0}
{"epoch": 28, "training_loss": 47.13097381591797, "training_acc": 55.0, "val_loss": 112.44990539550781, "val_acc": 60.0}
{"epoch": 29, "training_loss": 213.99475708007813, "training_acc": 45.0, "val_loss": 44.196712493896484, "val_acc": 60.0}
{"epoch": 30, "training_loss": 127.8230484008789, "training_acc": 55.0, "val_loss": 508.62548828125, "val_acc": 40.0}
{"epoch": 31, "training_loss": 345.8120635986328, "training_acc": 55.0, "val_loss": 143.84034729003906, "val_acc": 40.0}
{"epoch": 32, "training_loss": 150.91644592285155, "training_acc": 45.0, "val_loss": 156.1342315673828, "val_acc": 60.0}
{"epoch": 33, "training_loss": 139.55491561889647, "training_acc": 45.0, "val_loss": 379.2684631347656, "val_acc": 40.0}
{"epoch": 34, "training_loss": 299.9610107421875, "training_acc": 55.0, "val_loss": 173.3810272216797, "val_acc": 40.0}
{"epoch": 35, "training_loss": 235.00245971679686, "training_acc": 25.0, "val_loss": 170.28857421875, "val_acc": 60.0}
{"epoch": 36, "training_loss": 175.712451171875, "training_acc": 35.0, "val_loss": 333.06329345703125, "val_acc": 40.0}
{"epoch": 37, "training_loss": 245.89647216796874, "training_acc": 55.0, "val_loss": 62.12894821166992, "val_acc": 40.0}
{"epoch": 38, "training_loss": 100.05678329467773, "training_acc": 65.0, "val_loss": 268.2216491699219, "val_acc": 60.0}
{"epoch": 39, "training_loss": 277.8506805419922, "training_acc": 45.0, "val_loss": 171.7777862548828, "val_acc": 40.0}
{"epoch": 40, "training_loss": 212.23509216308594, "training_acc": 55.0, "val_loss": 315.3090515136719, "val_acc": 40.0}
