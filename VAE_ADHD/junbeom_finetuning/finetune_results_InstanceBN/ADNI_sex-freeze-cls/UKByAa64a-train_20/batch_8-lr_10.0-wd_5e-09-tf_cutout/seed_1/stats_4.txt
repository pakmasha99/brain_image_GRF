"main_modify.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 1 --task ADNI_sex --input_option yAware --learning_rate 1e1 --batch_size 8 --weight_decay 5e-9 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 1144.3250556230546, "training_acc": 50.0, "val_loss": 924.7265625, "val_acc": 40.0}
{"epoch": 1, "training_loss": 1019.758837890625, "training_acc": 50.0, "val_loss": 77.80464935302734, "val_acc": 40.0}
{"epoch": 2, "training_loss": 1009.0704650878906, "training_acc": 40.0, "val_loss": 1402.5408935546875, "val_acc": 60.0}
{"epoch": 3, "training_loss": 1504.0255249023437, "training_acc": 50.0, "val_loss": 70.50848388671875, "val_acc": 60.0}
{"epoch": 4, "training_loss": 563.5667541503906, "training_acc": 60.0, "val_loss": 1693.9130859375, "val_acc": 40.0}
{"epoch": 5, "training_loss": 1229.27001953125, "training_acc": 50.0, "val_loss": 289.97320556640625, "val_acc": 40.0}
{"epoch": 6, "training_loss": 585.5200073242188, "training_acc": 40.0, "val_loss": 882.1052856445312, "val_acc": 60.0}
{"epoch": 7, "training_loss": 1031.9601135253906, "training_acc": 50.0, "val_loss": 200.03175354003906, "val_acc": 60.0}
{"epoch": 8, "training_loss": 430.1182861328125, "training_acc": 50.0, "val_loss": 917.2903442382812, "val_acc": 40.0}
{"epoch": 9, "training_loss": 589.0320068359375, "training_acc": 50.0, "val_loss": 254.08616638183594, "val_acc": 60.0}
{"epoch": 10, "training_loss": 485.738818359375, "training_acc": 50.0, "val_loss": 402.9725341796875, "val_acc": 60.0}
{"epoch": 11, "training_loss": 376.2718078613281, "training_acc": 40.0, "val_loss": 529.3270874023438, "val_acc": 40.0}
{"epoch": 12, "training_loss": 394.00005493164065, "training_acc": 50.0, "val_loss": 186.5918731689453, "val_acc": 60.0}
{"epoch": 13, "training_loss": 336.5587524414062, "training_acc": 50.0, "val_loss": 125.9457778930664, "val_acc": 60.0}
{"epoch": 14, "training_loss": 108.80813598632812, "training_acc": 60.0, "val_loss": 62.15829086303711, "val_acc": 40.0}
{"epoch": 15, "training_loss": 208.73339080810547, "training_acc": 50.0, "val_loss": 157.80435180664062, "val_acc": 60.0}
{"epoch": 16, "training_loss": 136.2540740966797, "training_acc": 60.0, "val_loss": 196.7873077392578, "val_acc": 40.0}
{"epoch": 17, "training_loss": 277.0666564941406, "training_acc": 30.0, "val_loss": 40.76426696777344, "val_acc": 60.0}
{"epoch": 18, "training_loss": 357.18668975830076, "training_acc": 40.0, "val_loss": 570.8179321289062, "val_acc": 40.0}
{"epoch": 19, "training_loss": 334.8068878173828, "training_acc": 50.0, "val_loss": 421.4902038574219, "val_acc": 60.0}
{"epoch": 20, "training_loss": 449.487939453125, "training_acc": 50.0, "val_loss": 92.03914642333984, "val_acc": 40.0}
{"epoch": 21, "training_loss": 215.0180236816406, "training_acc": 50.0, "val_loss": 49.2470588684082, "val_acc": 60.0}
{"epoch": 22, "training_loss": 33.26813644506037, "training_acc": 65.0, "val_loss": 39.31418991088867, "val_acc": 40.0}
{"epoch": 23, "training_loss": 53.999810791015626, "training_acc": 50.0, "val_loss": 257.654541015625, "val_acc": 40.0}
{"epoch": 24, "training_loss": 340.83677062988284, "training_acc": 50.0, "val_loss": 21.37367820739746, "val_acc": 60.0}
{"epoch": 25, "training_loss": 139.42111473083497, "training_acc": 50.0, "val_loss": 243.06777954101562, "val_acc": 40.0}
{"epoch": 26, "training_loss": 281.9135406494141, "training_acc": 50.0, "val_loss": 58.677894592285156, "val_acc": 60.0}
{"epoch": 27, "training_loss": 109.68450469970703, "training_acc": 30.0, "val_loss": 35.878108978271484, "val_acc": 60.0}
{"epoch": 28, "training_loss": 132.9919090270996, "training_acc": 30.0, "val_loss": 155.2008056640625, "val_acc": 40.0}
{"epoch": 29, "training_loss": 76.2844451904297, "training_acc": 60.0, "val_loss": 42.08295822143555, "val_acc": 60.0}
{"epoch": 30, "training_loss": 205.51555786132812, "training_acc": 30.0, "val_loss": 3.5521187782287598, "val_acc": 80.0}
{"epoch": 31, "training_loss": 115.72727813720704, "training_acc": 70.0, "val_loss": 38.994441986083984, "val_acc": 60.0}
{"epoch": 32, "training_loss": 314.04102325439453, "training_acc": 30.0, "val_loss": 311.5445251464844, "val_acc": 40.0}
{"epoch": 33, "training_loss": 55.85786170959473, "training_acc": 70.0, "val_loss": 615.4765625, "val_acc": 60.0}
{"epoch": 34, "training_loss": 841.1741943359375, "training_acc": 50.0, "val_loss": 491.51513671875, "val_acc": 60.0}
{"epoch": 35, "training_loss": 344.2410095214844, "training_acc": 50.0, "val_loss": 880.5017700195312, "val_acc": 40.0}
{"epoch": 36, "training_loss": 767.6847778320313, "training_acc": 50.0, "val_loss": 584.05810546875, "val_acc": 40.0}
{"epoch": 37, "training_loss": 314.82090148925784, "training_acc": 50.0, "val_loss": 642.3622436523438, "val_acc": 60.0}
{"epoch": 38, "training_loss": 789.2837768554688, "training_acc": 50.0, "val_loss": 372.4876708984375, "val_acc": 60.0}
{"epoch": 39, "training_loss": 327.8144138336182, "training_acc": 55.0, "val_loss": 737.1610717773438, "val_acc": 40.0}
{"epoch": 40, "training_loss": 571.6525634765625, "training_acc": 50.0, "val_loss": 85.79692840576172, "val_acc": 60.0}
{"epoch": 41, "training_loss": 145.45460662841796, "training_acc": 50.0, "val_loss": 231.6195831298828, "val_acc": 40.0}
{"epoch": 42, "training_loss": 233.96788482666017, "training_acc": 50.0, "val_loss": 6.2367262840271, "val_acc": 80.0}
{"epoch": 43, "training_loss": 39.60413780212402, "training_acc": 70.0, "val_loss": 107.21977996826172, "val_acc": 40.0}
{"epoch": 44, "training_loss": 83.88929595947266, "training_acc": 50.0, "val_loss": 99.5372314453125, "val_acc": 60.0}
{"epoch": 45, "training_loss": 56.94053916931152, "training_acc": 60.0, "val_loss": 26.652673721313477, "val_acc": 80.0}
{"epoch": 46, "training_loss": 19.194139099121095, "training_acc": 75.0, "val_loss": 10.85831356048584, "val_acc": 80.0}
{"epoch": 47, "training_loss": 38.04798431396485, "training_acc": 70.0, "val_loss": 20.1547794342041, "val_acc": 80.0}
{"epoch": 48, "training_loss": 25.486008071899413, "training_acc": 60.0, "val_loss": 11.666667938232422, "val_acc": 80.0}
{"epoch": 49, "training_loss": 63.77950325012207, "training_acc": 65.0, "val_loss": 189.17080688476562, "val_acc": 40.0}
