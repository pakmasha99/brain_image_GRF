"main_modify.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_sex --input_option yAware --learning_rate 1e1 --batch_size 8 --weight_decay 5e-9 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 1151.9061123132706, "training_acc": 55.0, "val_loss": 500.3610534667969, "val_acc": 60.0}
{"epoch": 1, "training_loss": 733.42587890625, "training_acc": 45.0, "val_loss": 711.416015625, "val_acc": 40.0}
{"epoch": 2, "training_loss": 798.542431640625, "training_acc": 55.0, "val_loss": 660.4613647460938, "val_acc": 40.0}
{"epoch": 3, "training_loss": 638.9517211914062, "training_acc": 35.0, "val_loss": 336.1361999511719, "val_acc": 60.0}
{"epoch": 4, "training_loss": 197.5014175415039, "training_acc": 55.0, "val_loss": 225.47268676757812, "val_acc": 40.0}
{"epoch": 5, "training_loss": 105.68401947021485, "training_acc": 45.0, "val_loss": 82.9710693359375, "val_acc": 60.0}
{"epoch": 6, "training_loss": 76.02334136962891, "training_acc": 45.0, "val_loss": 108.4677734375, "val_acc": 40.0}
{"epoch": 7, "training_loss": 43.85970497131348, "training_acc": 60.0, "val_loss": 45.43716049194336, "val_acc": 40.0}
{"epoch": 8, "training_loss": 187.92433319091796, "training_acc": 45.0, "val_loss": 98.49271392822266, "val_acc": 40.0}
{"epoch": 9, "training_loss": 160.17801208496093, "training_acc": 55.0, "val_loss": 42.40263748168945, "val_acc": 60.0}
{"epoch": 10, "training_loss": 35.927625274658205, "training_acc": 55.0, "val_loss": 25.882049560546875, "val_acc": 60.0}
{"epoch": 11, "training_loss": 248.696923828125, "training_acc": 35.0, "val_loss": 203.0523681640625, "val_acc": 40.0}
{"epoch": 12, "training_loss": 302.82945861816404, "training_acc": 35.0, "val_loss": 217.09292602539062, "val_acc": 60.0}
{"epoch": 13, "training_loss": 154.1474609375, "training_acc": 55.0, "val_loss": 745.5748901367188, "val_acc": 40.0}
{"epoch": 14, "training_loss": 566.48232421875, "training_acc": 55.0, "val_loss": 346.2789001464844, "val_acc": 40.0}
{"epoch": 15, "training_loss": 264.4906494140625, "training_acc": 55.0, "val_loss": 291.3477783203125, "val_acc": 60.0}
{"epoch": 16, "training_loss": 329.15725440979, "training_acc": 25.0, "val_loss": 38.11326599121094, "val_acc": 60.0}
{"epoch": 17, "training_loss": 47.894378662109375, "training_acc": 55.0, "val_loss": 218.8966827392578, "val_acc": 40.0}
{"epoch": 18, "training_loss": 119.11841125488282, "training_acc": 55.0, "val_loss": 199.372802734375, "val_acc": 60.0}
{"epoch": 19, "training_loss": 249.58762817382814, "training_acc": 35.0, "val_loss": 453.1342468261719, "val_acc": 40.0}
{"epoch": 20, "training_loss": 265.88586883544923, "training_acc": 45.0, "val_loss": 36.432987213134766, "val_acc": 60.0}
{"epoch": 21, "training_loss": 22.736508560180663, "training_acc": 75.0, "val_loss": 7.0614190101623535, "val_acc": 80.0}
{"epoch": 22, "training_loss": 41.96152877807617, "training_acc": 60.0, "val_loss": 48.95730209350586, "val_acc": 60.0}
{"epoch": 23, "training_loss": 34.66037668583631, "training_acc": 65.0, "val_loss": 8.92933464050293, "val_acc": 80.0}
{"epoch": 24, "training_loss": 59.606719207763675, "training_acc": 60.0, "val_loss": 101.46343994140625, "val_acc": 60.0}
{"epoch": 25, "training_loss": 146.4576416015625, "training_acc": 35.0, "val_loss": 87.66921997070312, "val_acc": 40.0}
{"epoch": 26, "training_loss": 210.19355010986328, "training_acc": 35.0, "val_loss": 22.82657814025879, "val_acc": 60.0}
{"epoch": 27, "training_loss": 175.3673522949219, "training_acc": 55.0, "val_loss": 454.55084228515625, "val_acc": 40.0}
{"epoch": 28, "training_loss": 207.06397094726563, "training_acc": 55.0, "val_loss": 269.7763366699219, "val_acc": 60.0}
{"epoch": 29, "training_loss": 276.1697265625, "training_acc": 45.0, "val_loss": 552.2047729492188, "val_acc": 40.0}
{"epoch": 30, "training_loss": 537.4355590820312, "training_acc": 55.0, "val_loss": 894.3474731445312, "val_acc": 40.0}
{"epoch": 31, "training_loss": 451.3081848144531, "training_acc": 55.0, "val_loss": 241.1826629638672, "val_acc": 60.0}
{"epoch": 32, "training_loss": 445.2114196777344, "training_acc": 45.0, "val_loss": 368.8453063964844, "val_acc": 60.0}
{"epoch": 33, "training_loss": 400.0160766601563, "training_acc": 35.0, "val_loss": 690.8165893554688, "val_acc": 40.0}
{"epoch": 34, "training_loss": 465.8919677734375, "training_acc": 55.0, "val_loss": 11.13326644897461, "val_acc": 40.0}
{"epoch": 35, "training_loss": 88.89125366210938, "training_acc": 55.0, "val_loss": 138.37176513671875, "val_acc": 40.0}
{"epoch": 36, "training_loss": 51.86186256408691, "training_acc": 70.0, "val_loss": 12.040535926818848, "val_acc": 40.0}
{"epoch": 37, "training_loss": 82.97423706054687, "training_acc": 55.0, "val_loss": 64.6445083618164, "val_acc": 60.0}
{"epoch": 38, "training_loss": 123.68638916015625, "training_acc": 35.0, "val_loss": 178.95950317382812, "val_acc": 40.0}
{"epoch": 39, "training_loss": 159.0094223022461, "training_acc": 35.0, "val_loss": 175.85073852539062, "val_acc": 40.0}
{"epoch": 40, "training_loss": 129.56855163574218, "training_acc": 35.0, "val_loss": 134.20225524902344, "val_acc": 40.0}
