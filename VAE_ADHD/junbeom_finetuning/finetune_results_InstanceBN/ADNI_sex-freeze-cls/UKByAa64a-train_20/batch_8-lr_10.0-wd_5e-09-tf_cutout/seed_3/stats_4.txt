"main_modify.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 3 --task ADNI_sex --input_option yAware --learning_rate 1e1 --batch_size 8 --weight_decay 5e-9 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 1382.870570230484, "training_acc": 35.0, "val_loss": 627.9727783203125, "val_acc": 40.0}
{"epoch": 1, "training_loss": 791.4184814453125, "training_acc": 55.0, "val_loss": 1042.102294921875, "val_acc": 40.0}
{"epoch": 2, "training_loss": 591.65693359375, "training_acc": 45.0, "val_loss": 742.23583984375, "val_acc": 60.0}
{"epoch": 3, "training_loss": 831.3390197753906, "training_acc": 45.0, "val_loss": 351.8142395019531, "val_acc": 40.0}
{"epoch": 4, "training_loss": 303.9344085693359, "training_acc": 55.0, "val_loss": 362.6260681152344, "val_acc": 40.0}
{"epoch": 5, "training_loss": 252.42530517578126, "training_acc": 35.0, "val_loss": 124.18495178222656, "val_acc": 40.0}
{"epoch": 6, "training_loss": 146.764794921875, "training_acc": 35.0, "val_loss": 95.02449798583984, "val_acc": 40.0}
{"epoch": 7, "training_loss": 53.09903364181518, "training_acc": 65.0, "val_loss": 30.5125732421875, "val_acc": 60.0}
{"epoch": 8, "training_loss": 44.60503158569336, "training_acc": 65.0, "val_loss": 39.258026123046875, "val_acc": 60.0}
{"epoch": 9, "training_loss": 67.73506164550781, "training_acc": 55.0, "val_loss": 133.64707946777344, "val_acc": 60.0}
{"epoch": 10, "training_loss": 118.13022575378417, "training_acc": 55.0, "val_loss": 61.11592483520508, "val_acc": 40.0}
{"epoch": 11, "training_loss": 83.92717132568359, "training_acc": 45.0, "val_loss": 308.6658935546875, "val_acc": 40.0}
{"epoch": 12, "training_loss": 267.0224853515625, "training_acc": 55.0, "val_loss": 71.51057434082031, "val_acc": 40.0}
{"epoch": 13, "training_loss": 276.05592956542966, "training_acc": 45.0, "val_loss": 223.7320098876953, "val_acc": 60.0}
{"epoch": 14, "training_loss": 233.5880096435547, "training_acc": 45.0, "val_loss": 282.79315185546875, "val_acc": 40.0}
{"epoch": 15, "training_loss": 143.74393463134766, "training_acc": 55.0, "val_loss": 371.4325866699219, "val_acc": 60.0}
{"epoch": 16, "training_loss": 380.72303314208983, "training_acc": 45.0, "val_loss": 489.8795471191406, "val_acc": 40.0}
{"epoch": 17, "training_loss": 605.2697387695313, "training_acc": 55.0, "val_loss": 778.2789916992188, "val_acc": 40.0}
{"epoch": 18, "training_loss": 400.22032165527344, "training_acc": 55.0, "val_loss": 309.05609130859375, "val_acc": 60.0}
{"epoch": 19, "training_loss": 330.47899169921874, "training_acc": 45.0, "val_loss": 395.5614929199219, "val_acc": 40.0}
{"epoch": 20, "training_loss": 552.35146484375, "training_acc": 55.0, "val_loss": 697.9826049804688, "val_acc": 40.0}
{"epoch": 21, "training_loss": 289.5737731933594, "training_acc": 55.0, "val_loss": 361.5291442871094, "val_acc": 60.0}
{"epoch": 22, "training_loss": 442.03322143554686, "training_acc": 45.0, "val_loss": 205.0635986328125, "val_acc": 40.0}
{"epoch": 23, "training_loss": 231.78807983398437, "training_acc": 55.0, "val_loss": 16.543058395385742, "val_acc": 60.0}
{"epoch": 24, "training_loss": 178.41001358032227, "training_acc": 70.0, "val_loss": 305.04473876953125, "val_acc": 60.0}
{"epoch": 25, "training_loss": 273.9031524658203, "training_acc": 45.0, "val_loss": 773.9474487304688, "val_acc": 40.0}
{"epoch": 26, "training_loss": 517.4103149414062, "training_acc": 55.0, "val_loss": 164.85777282714844, "val_acc": 40.0}
{"epoch": 27, "training_loss": 122.78655853271485, "training_acc": 75.0, "val_loss": 318.45416259765625, "val_acc": 60.0}
{"epoch": 28, "training_loss": 282.2307922363281, "training_acc": 45.0, "val_loss": 548.34716796875, "val_acc": 40.0}
{"epoch": 29, "training_loss": 343.2029266357422, "training_acc": 55.0, "val_loss": 77.33696746826172, "val_acc": 60.0}
{"epoch": 30, "training_loss": 146.22369842529298, "training_acc": 45.0, "val_loss": 298.9519348144531, "val_acc": 40.0}
{"epoch": 31, "training_loss": 278.6119750976562, "training_acc": 55.0, "val_loss": 66.87333679199219, "val_acc": 40.0}
{"epoch": 32, "training_loss": 286.21769256591796, "training_acc": 45.0, "val_loss": 171.46861267089844, "val_acc": 60.0}
{"epoch": 33, "training_loss": 401.60716552734374, "training_acc": 35.0, "val_loss": 512.2559814453125, "val_acc": 40.0}
{"epoch": 34, "training_loss": 210.2459228515625, "training_acc": 55.0, "val_loss": 394.2961120605469, "val_acc": 60.0}
{"epoch": 35, "training_loss": 448.40977172851564, "training_acc": 45.0, "val_loss": 264.85943603515625, "val_acc": 40.0}
{"epoch": 36, "training_loss": 340.36078491210935, "training_acc": 55.0, "val_loss": 360.2876892089844, "val_acc": 40.0}
{"epoch": 37, "training_loss": 117.23780136108398, "training_acc": 65.0, "val_loss": 231.4195556640625, "val_acc": 60.0}
{"epoch": 38, "training_loss": 204.45130004882813, "training_acc": 45.0, "val_loss": 454.8385925292969, "val_acc": 40.0}
{"epoch": 39, "training_loss": 251.13798446655272, "training_acc": 55.0, "val_loss": 231.61392211914062, "val_acc": 60.0}
{"epoch": 40, "training_loss": 333.2498718261719, "training_acc": 45.0, "val_loss": 111.7951431274414, "val_acc": 40.0}
{"epoch": 41, "training_loss": 136.18592681884766, "training_acc": 55.0, "val_loss": 39.76981735229492, "val_acc": 60.0}
{"epoch": 42, "training_loss": 37.70542755126953, "training_acc": 55.0, "val_loss": 34.20185089111328, "val_acc": 80.0}
