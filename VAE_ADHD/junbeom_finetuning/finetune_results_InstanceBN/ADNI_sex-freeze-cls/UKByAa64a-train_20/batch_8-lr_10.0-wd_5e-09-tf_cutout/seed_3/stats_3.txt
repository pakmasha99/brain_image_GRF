"main_modify.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 3 --task ADNI_sex --input_option yAware --learning_rate 1e1 --batch_size 8 --weight_decay 5e-9 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 1092.6784611225128, "training_acc": 45.0, "val_loss": 222.41311645507812, "val_acc": 60.0}
{"epoch": 1, "training_loss": 420.79715728759766, "training_acc": 45.0, "val_loss": 867.455078125, "val_acc": 40.0}
{"epoch": 2, "training_loss": 867.0234375, "training_acc": 55.0, "val_loss": 695.4636840820312, "val_acc": 40.0}
{"epoch": 3, "training_loss": 410.1074157714844, "training_acc": 45.0, "val_loss": 301.58355712890625, "val_acc": 60.0}
{"epoch": 4, "training_loss": 278.28716373443604, "training_acc": 55.0, "val_loss": 191.4263916015625, "val_acc": 40.0}
{"epoch": 5, "training_loss": 315.457177734375, "training_acc": 35.0, "val_loss": 63.604461669921875, "val_acc": 60.0}
{"epoch": 6, "training_loss": 391.2245788574219, "training_acc": 35.0, "val_loss": 849.0564575195312, "val_acc": 40.0}
{"epoch": 7, "training_loss": 508.68536376953125, "training_acc": 55.0, "val_loss": 130.8785858154297, "val_acc": 60.0}
{"epoch": 8, "training_loss": 405.3459716796875, "training_acc": 45.0, "val_loss": 116.49714660644531, "val_acc": 60.0}
{"epoch": 9, "training_loss": 204.4053741455078, "training_acc": 55.0, "val_loss": 631.8502197265625, "val_acc": 40.0}
{"epoch": 10, "training_loss": 337.43231201171875, "training_acc": 55.0, "val_loss": 229.6825408935547, "val_acc": 60.0}
{"epoch": 11, "training_loss": 450.4948455810547, "training_acc": 45.0, "val_loss": 236.89414978027344, "val_acc": 60.0}
{"epoch": 12, "training_loss": 206.9236328125, "training_acc": 45.0, "val_loss": 193.73585510253906, "val_acc": 40.0}
{"epoch": 13, "training_loss": 155.99596557617187, "training_acc": 45.0, "val_loss": 151.0255126953125, "val_acc": 40.0}
{"epoch": 14, "training_loss": 143.47425842285156, "training_acc": 55.0, "val_loss": 54.3038215637207, "val_acc": 60.0}
{"epoch": 15, "training_loss": 76.07270722389221, "training_acc": 55.0, "val_loss": 332.9549255371094, "val_acc": 40.0}
{"epoch": 16, "training_loss": 267.45946197509767, "training_acc": 55.0, "val_loss": 67.46776580810547, "val_acc": 60.0}
{"epoch": 17, "training_loss": 137.21791076660156, "training_acc": 45.0, "val_loss": 479.9945983886719, "val_acc": 40.0}
{"epoch": 18, "training_loss": 433.9832275390625, "training_acc": 55.0, "val_loss": 535.2110595703125, "val_acc": 40.0}
{"epoch": 19, "training_loss": 201.8531066894531, "training_acc": 55.0, "val_loss": 515.8954467773438, "val_acc": 60.0}
{"epoch": 20, "training_loss": 706.0616333007813, "training_acc": 45.0, "val_loss": 79.22322845458984, "val_acc": 60.0}
{"epoch": 21, "training_loss": 268.155615234375, "training_acc": 55.0, "val_loss": 1228.39208984375, "val_acc": 40.0}
{"epoch": 22, "training_loss": 937.2551025390625, "training_acc": 55.0, "val_loss": 851.3212280273438, "val_acc": 40.0}
{"epoch": 23, "training_loss": 386.0068298339844, "training_acc": 45.0, "val_loss": 474.8968200683594, "val_acc": 60.0}
{"epoch": 24, "training_loss": 629.3248962402344, "training_acc": 45.0, "val_loss": 26.812116622924805, "val_acc": 60.0}
{"epoch": 25, "training_loss": 396.73194580078126, "training_acc": 45.0, "val_loss": 1149.2235107421875, "val_acc": 40.0}
{"epoch": 26, "training_loss": 692.1782653808593, "training_acc": 55.0, "val_loss": 202.2641143798828, "val_acc": 40.0}
{"epoch": 27, "training_loss": 316.9517028808594, "training_acc": 55.0, "val_loss": 548.8635864257812, "val_acc": 60.0}
{"epoch": 28, "training_loss": 618.9057739257812, "training_acc": 45.0, "val_loss": 410.44970703125, "val_acc": 40.0}
{"epoch": 29, "training_loss": 362.8752685546875, "training_acc": 55.0, "val_loss": 742.5592041015625, "val_acc": 40.0}
{"epoch": 30, "training_loss": 283.59638633728025, "training_acc": 55.0, "val_loss": 142.885986328125, "val_acc": 60.0}
{"epoch": 31, "training_loss": 185.13696365356446, "training_acc": 50.0, "val_loss": 330.9526062011719, "val_acc": 40.0}
{"epoch": 32, "training_loss": 123.79177341461181, "training_acc": 60.0, "val_loss": 52.04518508911133, "val_acc": 60.0}
{"epoch": 33, "training_loss": 44.81382598876953, "training_acc": 65.0, "val_loss": 237.38760375976562, "val_acc": 40.0}
{"epoch": 34, "training_loss": 57.517347717285155, "training_acc": 60.0, "val_loss": 78.3226547241211, "val_acc": 40.0}
{"epoch": 35, "training_loss": 24.811012268066406, "training_acc": 65.0, "val_loss": 28.377843856811523, "val_acc": 60.0}
{"epoch": 36, "training_loss": 87.83922119140625, "training_acc": 50.0, "val_loss": 34.02838134765625, "val_acc": 40.0}
{"epoch": 37, "training_loss": 30.02146759033203, "training_acc": 70.0, "val_loss": 81.15913391113281, "val_acc": 40.0}
{"epoch": 38, "training_loss": 30.201805114746094, "training_acc": 70.0, "val_loss": 58.76620101928711, "val_acc": 60.0}
{"epoch": 39, "training_loss": 30.790742874145508, "training_acc": 65.0, "val_loss": 282.73095703125, "val_acc": 40.0}
{"epoch": 40, "training_loss": 96.64151754379273, "training_acc": 65.0, "val_loss": 113.52276611328125, "val_acc": 60.0}
{"epoch": 41, "training_loss": 217.89910278320312, "training_acc": 25.0, "val_loss": 181.59825134277344, "val_acc": 40.0}
{"epoch": 42, "training_loss": 22.30260810852051, "training_acc": 70.0, "val_loss": 61.62704086303711, "val_acc": 60.0}
{"epoch": 43, "training_loss": 37.046448135375975, "training_acc": 70.0, "val_loss": 31.299299240112305, "val_acc": 80.0}
