"main_modify.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 5 --task ADNI_sex --input_option yAware --learning_rate 1e1 --batch_size 8 --weight_decay 5e-4 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 1564.6388181209563, "training_acc": 45.0, "val_loss": 899.0851440429688, "val_acc": 40.0}
{"epoch": 1, "training_loss": 882.991455078125, "training_acc": 55.0, "val_loss": 783.8966064453125, "val_acc": 40.0}
{"epoch": 2, "training_loss": 333.0675567626953, "training_acc": 45.0, "val_loss": 74.45198059082031, "val_acc": 40.0}
{"epoch": 3, "training_loss": 112.72498931884766, "training_acc": 65.0, "val_loss": 138.9393768310547, "val_acc": 60.0}
{"epoch": 4, "training_loss": 311.1610046386719, "training_acc": 25.0, "val_loss": 76.9831314086914, "val_acc": 60.0}
{"epoch": 5, "training_loss": 153.84813232421874, "training_acc": 45.0, "val_loss": 536.3749389648438, "val_acc": 40.0}
{"epoch": 6, "training_loss": 471.5043212890625, "training_acc": 55.0, "val_loss": 534.727294921875, "val_acc": 40.0}
{"epoch": 7, "training_loss": 155.36915435791016, "training_acc": 75.0, "val_loss": 545.2036743164062, "val_acc": 60.0}
{"epoch": 8, "training_loss": 790.4881958007812, "training_acc": 45.0, "val_loss": 199.21385192871094, "val_acc": 60.0}
{"epoch": 9, "training_loss": 121.30084838867188, "training_acc": 75.0, "val_loss": 939.0123901367188, "val_acc": 40.0}
{"epoch": 10, "training_loss": 679.4984130859375, "training_acc": 55.0, "val_loss": 336.2371520996094, "val_acc": 40.0}
{"epoch": 11, "training_loss": 330.9927917480469, "training_acc": 45.0, "val_loss": 353.022705078125, "val_acc": 60.0}
{"epoch": 12, "training_loss": 525.1608428955078, "training_acc": 25.0, "val_loss": 692.81640625, "val_acc": 40.0}
{"epoch": 13, "training_loss": 418.45565032958984, "training_acc": 55.0, "val_loss": 234.2670440673828, "val_acc": 60.0}
{"epoch": 14, "training_loss": 513.0497375488281, "training_acc": 45.0, "val_loss": 68.11865997314453, "val_acc": 60.0}
{"epoch": 15, "training_loss": 188.12722778320312, "training_acc": 65.0, "val_loss": 856.6389770507812, "val_acc": 40.0}
{"epoch": 16, "training_loss": 596.7996887207031, "training_acc": 55.0, "val_loss": 45.213409423828125, "val_acc": 40.0}
{"epoch": 17, "training_loss": 452.29994201660156, "training_acc": 45.0, "val_loss": 695.9346923828125, "val_acc": 60.0}
{"epoch": 18, "training_loss": 742.7161285400391, "training_acc": 45.0, "val_loss": 357.4654235839844, "val_acc": 40.0}
{"epoch": 19, "training_loss": 503.8812255859375, "training_acc": 55.0, "val_loss": 793.0549926757812, "val_acc": 40.0}
{"epoch": 20, "training_loss": 336.90870199799537, "training_acc": 65.0, "val_loss": 214.1289520263672, "val_acc": 60.0}
{"epoch": 21, "training_loss": 233.2288959503174, "training_acc": 45.0, "val_loss": 448.52935791015625, "val_acc": 40.0}
{"epoch": 22, "training_loss": 498.3442749023437, "training_acc": 55.0, "val_loss": 408.60943603515625, "val_acc": 40.0}
{"epoch": 23, "training_loss": 362.0587890625, "training_acc": 45.0, "val_loss": 256.2422790527344, "val_acc": 60.0}
{"epoch": 24, "training_loss": 312.39813232421875, "training_acc": 35.0, "val_loss": 162.1349639892578, "val_acc": 40.0}
{"epoch": 25, "training_loss": 143.0901306152344, "training_acc": 55.0, "val_loss": 10.53674602508545, "val_acc": 60.0}
{"epoch": 26, "training_loss": 364.41140899658205, "training_acc": 35.0, "val_loss": 746.0497436523438, "val_acc": 40.0}
{"epoch": 27, "training_loss": 383.9125579833984, "training_acc": 55.0, "val_loss": 332.6342468261719, "val_acc": 60.0}
{"epoch": 28, "training_loss": 597.7920532226562, "training_acc": 45.0, "val_loss": 341.1862487792969, "val_acc": 60.0}
{"epoch": 29, "training_loss": 252.92905406355857, "training_acc": 65.0, "val_loss": 727.0185546875, "val_acc": 40.0}
{"epoch": 30, "training_loss": 568.9607238769531, "training_acc": 55.0, "val_loss": 146.8693389892578, "val_acc": 40.0}
{"epoch": 31, "training_loss": 326.94533081054686, "training_acc": 45.0, "val_loss": 402.34051513671875, "val_acc": 60.0}
{"epoch": 32, "training_loss": 426.71270141601565, "training_acc": 35.0, "val_loss": 448.354736328125, "val_acc": 40.0}
{"epoch": 33, "training_loss": 314.80730590820315, "training_acc": 55.0, "val_loss": 144.18370056152344, "val_acc": 60.0}
{"epoch": 34, "training_loss": 232.68338623046876, "training_acc": 45.0, "val_loss": 17.058515548706055, "val_acc": 40.0}
{"epoch": 35, "training_loss": 126.58146886825561, "training_acc": 55.0, "val_loss": 208.26708984375, "val_acc": 60.0}
{"epoch": 36, "training_loss": 489.36024780273436, "training_acc": 45.0, "val_loss": 38.55546951293945, "val_acc": 40.0}
{"epoch": 37, "training_loss": 261.5202911376953, "training_acc": 55.0, "val_loss": 284.3183898925781, "val_acc": 40.0}
{"epoch": 38, "training_loss": 97.92780685424805, "training_acc": 55.0, "val_loss": 19.557924270629883, "val_acc": 40.0}
{"epoch": 39, "training_loss": 16.968507254123686, "training_acc": 75.0, "val_loss": 80.2837905883789, "val_acc": 40.0}
{"epoch": 40, "training_loss": 33.34913412332532, "training_acc": 75.0, "val_loss": 17.084121704101562, "val_acc": 60.0}
{"epoch": 41, "training_loss": 158.43909759521483, "training_acc": 45.0, "val_loss": 202.0740203857422, "val_acc": 40.0}
{"epoch": 42, "training_loss": 85.23887634277344, "training_acc": 55.0, "val_loss": 137.4354248046875, "val_acc": 40.0}
{"epoch": 43, "training_loss": 126.77322692871094, "training_acc": 45.0, "val_loss": 0.6262608170509338, "val_acc": 80.0}
{"epoch": 44, "training_loss": 41.19324376732111, "training_acc": 65.0, "val_loss": 163.6425018310547, "val_acc": 40.0}
{"epoch": 45, "training_loss": 127.97785339355468, "training_acc": 45.0, "val_loss": 19.79569435119629, "val_acc": 60.0}
{"epoch": 46, "training_loss": 89.92695007324218, "training_acc": 65.0, "val_loss": 252.66128540039062, "val_acc": 40.0}
{"epoch": 47, "training_loss": 152.43671646118165, "training_acc": 35.0, "val_loss": 225.7141571044922, "val_acc": 40.0}
{"epoch": 48, "training_loss": 147.29529571533203, "training_acc": 45.0, "val_loss": 113.74311828613281, "val_acc": 40.0}
{"epoch": 49, "training_loss": 54.83763961791992, "training_acc": 65.0, "val_loss": 160.47605895996094, "val_acc": 60.0}
{"epoch": 50, "training_loss": 149.97212547920645, "training_acc": 60.0, "val_loss": 50.63800811767578, "val_acc": 40.0}
{"epoch": 51, "training_loss": 277.5834686279297, "training_acc": 35.0, "val_loss": 142.0150146484375, "val_acc": 60.0}
{"epoch": 52, "training_loss": 215.91171264648438, "training_acc": 55.0, "val_loss": 333.1893005371094, "val_acc": 40.0}
{"epoch": 53, "training_loss": 129.80317987203597, "training_acc": 70.0, "val_loss": 220.1715087890625, "val_acc": 60.0}
{"epoch": 54, "training_loss": 184.18588409423828, "training_acc": 55.0, "val_loss": 470.1029357910156, "val_acc": 40.0}
{"epoch": 55, "training_loss": 297.2575927734375, "training_acc": 55.0, "val_loss": 148.37451171875, "val_acc": 60.0}
{"epoch": 56, "training_loss": 225.19716186523436, "training_acc": 45.0, "val_loss": 210.2929229736328, "val_acc": 40.0}
{"epoch": 57, "training_loss": 218.167578125, "training_acc": 55.0, "val_loss": 60.15576934814453, "val_acc": 40.0}
{"epoch": 58, "training_loss": 357.7871124267578, "training_acc": 35.0, "val_loss": 320.53448486328125, "val_acc": 60.0}
{"epoch": 59, "training_loss": 282.58128051757814, "training_acc": 45.0, "val_loss": 740.625, "val_acc": 40.0}
{"epoch": 60, "training_loss": 551.712841796875, "training_acc": 55.0, "val_loss": 277.2171325683594, "val_acc": 40.0}
{"epoch": 61, "training_loss": 218.01137084960936, "training_acc": 55.0, "val_loss": 266.773193359375, "val_acc": 60.0}
{"epoch": 62, "training_loss": 197.34817962646486, "training_acc": 55.0, "val_loss": 636.7084350585938, "val_acc": 40.0}
