"main_modify.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 3 --task ADNI_sex --input_option yAware --learning_rate 1e1 --batch_size 8 --weight_decay 5e-4 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 1488.6526036262512, "training_acc": 50.0, "val_loss": 347.7564392089844, "val_acc": 60.0}
{"epoch": 1, "training_loss": 711.1908935546875, "training_acc": 50.0, "val_loss": 205.57957458496094, "val_acc": 60.0}
{"epoch": 2, "training_loss": 440.25177612304685, "training_acc": 60.0, "val_loss": 1198.2027587890625, "val_acc": 40.0}
{"epoch": 3, "training_loss": 722.064794921875, "training_acc": 50.0, "val_loss": 470.893798828125, "val_acc": 60.0}
{"epoch": 4, "training_loss": 747.6428588867187, "training_acc": 50.0, "val_loss": 643.5369262695312, "val_acc": 60.0}
{"epoch": 5, "training_loss": 594.0654602050781, "training_acc": 40.0, "val_loss": 440.75885009765625, "val_acc": 40.0}
{"epoch": 6, "training_loss": 317.8942810058594, "training_acc": 40.0, "val_loss": 75.80577850341797, "val_acc": 60.0}
{"epoch": 7, "training_loss": 145.59292602539062, "training_acc": 50.0, "val_loss": 30.066587448120117, "val_acc": 60.0}
{"epoch": 8, "training_loss": 80.729833984375, "training_acc": 50.0, "val_loss": 41.13889694213867, "val_acc": 40.0}
{"epoch": 9, "training_loss": 36.109473037719724, "training_acc": 70.0, "val_loss": 86.6557846069336, "val_acc": 40.0}
{"epoch": 10, "training_loss": 32.907367420196536, "training_acc": 60.0, "val_loss": 79.66173553466797, "val_acc": 60.0}
{"epoch": 11, "training_loss": 210.1087890625, "training_acc": 20.0, "val_loss": 196.0086669921875, "val_acc": 60.0}
{"epoch": 12, "training_loss": 393.1339477539062, "training_acc": 50.0, "val_loss": 129.1902313232422, "val_acc": 60.0}
{"epoch": 13, "training_loss": 332.5534606933594, "training_acc": 40.0, "val_loss": 668.1974487304688, "val_acc": 40.0}
{"epoch": 14, "training_loss": 382.1650390625, "training_acc": 50.0, "val_loss": 327.5984802246094, "val_acc": 60.0}
{"epoch": 15, "training_loss": 484.26669921875, "training_acc": 50.0, "val_loss": 449.9921875, "val_acc": 60.0}
{"epoch": 16, "training_loss": 360.1490676879883, "training_acc": 50.0, "val_loss": 373.2763671875, "val_acc": 40.0}
{"epoch": 17, "training_loss": 372.45508728027346, "training_acc": 50.0, "val_loss": 148.02207946777344, "val_acc": 60.0}
{"epoch": 18, "training_loss": 255.61036376953126, "training_acc": 50.0, "val_loss": 131.9279327392578, "val_acc": 60.0}
{"epoch": 19, "training_loss": 167.01263427734375, "training_acc": 50.0, "val_loss": 150.56907653808594, "val_acc": 40.0}
{"epoch": 20, "training_loss": 215.38275756835938, "training_acc": 40.0, "val_loss": 106.21581268310547, "val_acc": 60.0}
{"epoch": 21, "training_loss": 118.08680419921875, "training_acc": 60.0, "val_loss": 132.41958618164062, "val_acc": 40.0}
{"epoch": 22, "training_loss": 132.6196044921875, "training_acc": 60.0, "val_loss": 49.6740837097168, "val_acc": 60.0}
{"epoch": 23, "training_loss": 196.30799713134766, "training_acc": 60.0, "val_loss": 352.38385009765625, "val_acc": 40.0}
{"epoch": 24, "training_loss": 198.69143371582032, "training_acc": 40.0, "val_loss": 12.182374954223633, "val_acc": 60.0}
{"epoch": 25, "training_loss": 178.88924713134764, "training_acc": 50.0, "val_loss": 214.774169921875, "val_acc": 40.0}
{"epoch": 26, "training_loss": 163.92486877441405, "training_acc": 50.0, "val_loss": 93.53316497802734, "val_acc": 60.0}
{"epoch": 27, "training_loss": 99.20484924316406, "training_acc": 60.0, "val_loss": 87.08858489990234, "val_acc": 40.0}
{"epoch": 28, "training_loss": 192.69801177978516, "training_acc": 40.0, "val_loss": 86.01478576660156, "val_acc": 60.0}
{"epoch": 29, "training_loss": 134.1503662109375, "training_acc": 60.0, "val_loss": 88.265380859375, "val_acc": 40.0}
{"epoch": 30, "training_loss": 285.8240539550781, "training_acc": 40.0, "val_loss": 291.3509826660156, "val_acc": 60.0}
{"epoch": 31, "training_loss": 323.66699981689453, "training_acc": 35.0, "val_loss": 139.94784545898438, "val_acc": 40.0}
{"epoch": 32, "training_loss": 269.3932800292969, "training_acc": 40.0, "val_loss": 192.19053649902344, "val_acc": 60.0}
{"epoch": 33, "training_loss": 150.35277862548827, "training_acc": 50.0, "val_loss": 131.3846893310547, "val_acc": 40.0}
{"epoch": 34, "training_loss": 106.71434211730957, "training_acc": 60.0, "val_loss": 109.7782974243164, "val_acc": 40.0}
{"epoch": 35, "training_loss": 153.99755859375, "training_acc": 50.0, "val_loss": 211.4660186767578, "val_acc": 60.0}
{"epoch": 36, "training_loss": 260.4924087524414, "training_acc": 50.0, "val_loss": 86.4363021850586, "val_acc": 60.0}
{"epoch": 37, "training_loss": 275.17396850585936, "training_acc": 40.0, "val_loss": 280.4195251464844, "val_acc": 40.0}
{"epoch": 38, "training_loss": 236.04055786132812, "training_acc": 40.0, "val_loss": 118.29731750488281, "val_acc": 60.0}
{"epoch": 39, "training_loss": 40.75710792541504, "training_acc": 70.0, "val_loss": 16.249910354614258, "val_acc": 60.0}
{"epoch": 40, "training_loss": 51.65029239654541, "training_acc": 50.0, "val_loss": 199.2056884765625, "val_acc": 60.0}
{"epoch": 41, "training_loss": 318.8648742675781, "training_acc": 50.0, "val_loss": 121.86732482910156, "val_acc": 40.0}
{"epoch": 42, "training_loss": 102.78713569641113, "training_acc": 50.0, "val_loss": 100.73375701904297, "val_acc": 60.0}
{"epoch": 43, "training_loss": 85.57296562194824, "training_acc": 60.0, "val_loss": 129.39486694335938, "val_acc": 40.0}
