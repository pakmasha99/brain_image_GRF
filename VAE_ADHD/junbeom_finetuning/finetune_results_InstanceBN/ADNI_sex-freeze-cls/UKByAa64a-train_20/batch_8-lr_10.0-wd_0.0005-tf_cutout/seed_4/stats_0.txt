"main_modify.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 4 --task ADNI_sex --input_option yAware --learning_rate 1e1 --batch_size 8 --weight_decay 5e-4 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 1489.2089050292968, "training_acc": 50.0, "val_loss": 512.6649169921875, "val_acc": 40.0}
{"epoch": 1, "training_loss": 851.7303466796875, "training_acc": 50.0, "val_loss": 450.2322692871094, "val_acc": 40.0}
{"epoch": 2, "training_loss": 278.50804443359374, "training_acc": 60.0, "val_loss": 368.127685546875, "val_acc": 60.0}
{"epoch": 3, "training_loss": 314.48070831298827, "training_acc": 30.0, "val_loss": 230.54075622558594, "val_acc": 60.0}
{"epoch": 4, "training_loss": 285.73671875, "training_acc": 50.0, "val_loss": 321.7637023925781, "val_acc": 40.0}
{"epoch": 5, "training_loss": 370.10345458984375, "training_acc": 50.0, "val_loss": 251.5087127685547, "val_acc": 40.0}
{"epoch": 6, "training_loss": 121.24176025390625, "training_acc": 70.0, "val_loss": 297.39251708984375, "val_acc": 60.0}
{"epoch": 7, "training_loss": 307.4431396484375, "training_acc": 40.0, "val_loss": 310.8125915527344, "val_acc": 40.0}
{"epoch": 8, "training_loss": 155.02179183959962, "training_acc": 60.0, "val_loss": 236.1162109375, "val_acc": 60.0}
{"epoch": 9, "training_loss": 259.677774810791, "training_acc": 40.0, "val_loss": 21.845718383789062, "val_acc": 40.0}
{"epoch": 10, "training_loss": 117.3667709350586, "training_acc": 50.0, "val_loss": 12.676301002502441, "val_acc": 40.0}
{"epoch": 11, "training_loss": 73.87036991119385, "training_acc": 40.0, "val_loss": 120.02911376953125, "val_acc": 60.0}
{"epoch": 12, "training_loss": 86.54669799804688, "training_acc": 60.0, "val_loss": 25.577590942382812, "val_acc": 60.0}
{"epoch": 13, "training_loss": 39.72758178710937, "training_acc": 50.0, "val_loss": 10.481472969055176, "val_acc": 40.0}
{"epoch": 14, "training_loss": 38.667135047912595, "training_acc": 60.0, "val_loss": 124.5595932006836, "val_acc": 40.0}
{"epoch": 15, "training_loss": 81.58374328613282, "training_acc": 40.0, "val_loss": 35.36872100830078, "val_acc": 60.0}
{"epoch": 16, "training_loss": 128.90691909790038, "training_acc": 30.0, "val_loss": 191.2935333251953, "val_acc": 60.0}
{"epoch": 17, "training_loss": 340.7416748046875, "training_acc": 50.0, "val_loss": 89.21123504638672, "val_acc": 40.0}
{"epoch": 18, "training_loss": 177.16007385253906, "training_acc": 50.0, "val_loss": 46.72102737426758, "val_acc": 40.0}
{"epoch": 19, "training_loss": 180.52099075317383, "training_acc": 60.0, "val_loss": 219.9942169189453, "val_acc": 60.0}
{"epoch": 20, "training_loss": 92.83601226806641, "training_acc": 65.0, "val_loss": 131.14772033691406, "val_acc": 40.0}
{"epoch": 21, "training_loss": 89.9972137451172, "training_acc": 50.0, "val_loss": 163.55838012695312, "val_acc": 40.0}
{"epoch": 22, "training_loss": 127.18971900939941, "training_acc": 50.0, "val_loss": 20.16929054260254, "val_acc": 60.0}
{"epoch": 23, "training_loss": 104.50886383056641, "training_acc": 50.0, "val_loss": 43.690101623535156, "val_acc": 60.0}
{"epoch": 24, "training_loss": 55.197557067871095, "training_acc": 60.0, "val_loss": 133.73814392089844, "val_acc": 40.0}
{"epoch": 25, "training_loss": 135.80216522216796, "training_acc": 20.0, "val_loss": 152.7108612060547, "val_acc": 60.0}
{"epoch": 26, "training_loss": 200.57571411132812, "training_acc": 30.0, "val_loss": 46.286128997802734, "val_acc": 60.0}
{"epoch": 27, "training_loss": 18.99387936592102, "training_acc": 65.0, "val_loss": 144.4395751953125, "val_acc": 60.0}
{"epoch": 28, "training_loss": 135.6587677001953, "training_acc": 50.0, "val_loss": 81.52217102050781, "val_acc": 40.0}
{"epoch": 29, "training_loss": 149.03113403320313, "training_acc": 40.0, "val_loss": 89.15156555175781, "val_acc": 40.0}
{"epoch": 30, "training_loss": 93.62237854003907, "training_acc": 40.0, "val_loss": 9.130789756774902, "val_acc": 60.0}
{"epoch": 31, "training_loss": 42.77317304611206, "training_acc": 50.0, "val_loss": 61.284278869628906, "val_acc": 40.0}
{"epoch": 32, "training_loss": 70.39006958007812, "training_acc": 50.0, "val_loss": 184.4853515625, "val_acc": 60.0}
{"epoch": 33, "training_loss": 119.33457641601562, "training_acc": 60.0, "val_loss": 442.951171875, "val_acc": 40.0}
{"epoch": 34, "training_loss": 299.8791900634766, "training_acc": 50.0, "val_loss": 238.49546813964844, "val_acc": 60.0}
{"epoch": 35, "training_loss": 334.55592041015626, "training_acc": 50.0, "val_loss": 112.84614562988281, "val_acc": 60.0}
{"epoch": 36, "training_loss": 243.835546875, "training_acc": 50.0, "val_loss": 465.8292541503906, "val_acc": 40.0}
{"epoch": 37, "training_loss": 379.63164672851565, "training_acc": 30.0, "val_loss": 333.17425537109375, "val_acc": 60.0}
{"epoch": 38, "training_loss": 230.561328125, "training_acc": 50.0, "val_loss": 629.18310546875, "val_acc": 40.0}
{"epoch": 39, "training_loss": 721.55234375, "training_acc": 50.0, "val_loss": 1035.795654296875, "val_acc": 40.0}
{"epoch": 40, "training_loss": 616.9129150390625, "training_acc": 50.0, "val_loss": 245.0677490234375, "val_acc": 60.0}
{"epoch": 41, "training_loss": 541.2081176757813, "training_acc": 50.0, "val_loss": 541.6233520507812, "val_acc": 60.0}
{"epoch": 42, "training_loss": 399.09327697753906, "training_acc": 60.0, "val_loss": 593.2406616210938, "val_acc": 40.0}
{"epoch": 43, "training_loss": 566.8607421875, "training_acc": 50.0, "val_loss": 265.6600036621094, "val_acc": 40.0}
{"epoch": 44, "training_loss": 266.2888427734375, "training_acc": 50.0, "val_loss": 375.90203857421875, "val_acc": 60.0}
{"epoch": 45, "training_loss": 311.3966186642647, "training_acc": 60.0, "val_loss": 397.41729736328125, "val_acc": 40.0}
{"epoch": 46, "training_loss": 414.65220336914064, "training_acc": 50.0, "val_loss": 121.11238098144531, "val_acc": 40.0}
{"epoch": 47, "training_loss": 395.1410400390625, "training_acc": 40.0, "val_loss": 474.1827087402344, "val_acc": 60.0}
{"epoch": 48, "training_loss": 326.2380331039429, "training_acc": 55.0, "val_loss": 621.0651245117188, "val_acc": 40.0}
{"epoch": 49, "training_loss": 598.9645263671875, "training_acc": 50.0, "val_loss": 772.279296875, "val_acc": 40.0}
