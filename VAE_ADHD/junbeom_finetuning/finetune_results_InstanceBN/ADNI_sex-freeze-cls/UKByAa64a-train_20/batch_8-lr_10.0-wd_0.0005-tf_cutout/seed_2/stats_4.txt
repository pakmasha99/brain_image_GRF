"main_modify.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 2 --task ADNI_sex --input_option yAware --learning_rate 1e1 --batch_size 8 --weight_decay 5e-4 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 663.0278912544251, "training_acc": 55.0, "val_loss": 1098.3515625, "val_acc": 60.0}
{"epoch": 1, "training_loss": 1883.632080078125, "training_acc": 45.0, "val_loss": 551.3117065429688, "val_acc": 60.0}
{"epoch": 2, "training_loss": 648.908203125, "training_acc": 55.0, "val_loss": 1694.9697265625, "val_acc": 40.0}
{"epoch": 3, "training_loss": 1139.0151000976562, "training_acc": 55.0, "val_loss": 386.23236083984375, "val_acc": 40.0}
{"epoch": 4, "training_loss": 404.7146728515625, "training_acc": 55.0, "val_loss": 744.923095703125, "val_acc": 60.0}
{"epoch": 5, "training_loss": 759.1478271484375, "training_acc": 45.0, "val_loss": 495.0560607910156, "val_acc": 40.0}
{"epoch": 6, "training_loss": 879.9981323242188, "training_acc": 55.0, "val_loss": 1214.9349365234375, "val_acc": 40.0}
{"epoch": 7, "training_loss": 548.9673583984375, "training_acc": 55.0, "val_loss": 433.36474609375, "val_acc": 60.0}
{"epoch": 8, "training_loss": 846.247265625, "training_acc": 45.0, "val_loss": 777.3189086914062, "val_acc": 60.0}
{"epoch": 9, "training_loss": 654.4705444335938, "training_acc": 45.0, "val_loss": 711.0980834960938, "val_acc": 40.0}
{"epoch": 10, "training_loss": 755.9063232421875, "training_acc": 55.0, "val_loss": 1688.3883056640625, "val_acc": 40.0}
{"epoch": 11, "training_loss": 1135.6123352050781, "training_acc": 55.0, "val_loss": 582.7816772460938, "val_acc": 40.0}
{"epoch": 12, "training_loss": 263.4062133789063, "training_acc": 45.0, "val_loss": 343.6376953125, "val_acc": 60.0}
{"epoch": 13, "training_loss": 340.31347236633303, "training_acc": 45.0, "val_loss": 571.3576049804688, "val_acc": 40.0}
{"epoch": 14, "training_loss": 645.425927734375, "training_acc": 55.0, "val_loss": 795.354736328125, "val_acc": 40.0}
{"epoch": 15, "training_loss": 379.925439453125, "training_acc": 55.0, "val_loss": 505.6193542480469, "val_acc": 60.0}
{"epoch": 16, "training_loss": 650.916943359375, "training_acc": 45.0, "val_loss": 38.886966705322266, "val_acc": 60.0}
{"epoch": 17, "training_loss": 254.3041244506836, "training_acc": 55.0, "val_loss": 793.8051147460938, "val_acc": 40.0}
{"epoch": 18, "training_loss": 426.33734741210935, "training_acc": 55.0, "val_loss": 230.83389282226562, "val_acc": 60.0}
{"epoch": 19, "training_loss": 449.290283203125, "training_acc": 45.0, "val_loss": 300.3022155761719, "val_acc": 60.0}
{"epoch": 20, "training_loss": 340.6422821044922, "training_acc": 35.0, "val_loss": 263.3379821777344, "val_acc": 40.0}
{"epoch": 21, "training_loss": 98.63391036987305, "training_acc": 55.0, "val_loss": 168.50364685058594, "val_acc": 40.0}
{"epoch": 22, "training_loss": 156.83505249023438, "training_acc": 35.0, "val_loss": 161.8083953857422, "val_acc": 40.0}
{"epoch": 23, "training_loss": 89.82212677001954, "training_acc": 55.0, "val_loss": 29.414081573486328, "val_acc": 60.0}
{"epoch": 24, "training_loss": 122.94098587036133, "training_acc": 50.0, "val_loss": 27.89908790588379, "val_acc": 20.0}
{"epoch": 25, "training_loss": 156.1643575668335, "training_acc": 55.0, "val_loss": 205.3094940185547, "val_acc": 40.0}
{"epoch": 26, "training_loss": 261.4553527832031, "training_acc": 55.0, "val_loss": 71.34635162353516, "val_acc": 40.0}
{"epoch": 27, "training_loss": 329.9188537597656, "training_acc": 35.0, "val_loss": 289.3893127441406, "val_acc": 60.0}
{"epoch": 28, "training_loss": 263.11334190368655, "training_acc": 50.0, "val_loss": 376.1150817871094, "val_acc": 40.0}
{"epoch": 29, "training_loss": 137.46675338745118, "training_acc": 65.0, "val_loss": 221.62393188476562, "val_acc": 60.0}
{"epoch": 30, "training_loss": 207.20206298828126, "training_acc": 45.0, "val_loss": 602.1072998046875, "val_acc": 40.0}
{"epoch": 31, "training_loss": 540.673828125, "training_acc": 55.0, "val_loss": 995.9521484375, "val_acc": 40.0}
{"epoch": 32, "training_loss": 596.3350524902344, "training_acc": 55.0, "val_loss": 112.83711242675781, "val_acc": 60.0}
{"epoch": 33, "training_loss": 324.0176025390625, "training_acc": 45.0, "val_loss": 170.73777770996094, "val_acc": 60.0}
{"epoch": 34, "training_loss": 160.28784790039063, "training_acc": 55.0, "val_loss": 430.8124694824219, "val_acc": 40.0}
{"epoch": 35, "training_loss": 212.04560089111328, "training_acc": 55.0, "val_loss": 99.8461685180664, "val_acc": 60.0}
{"epoch": 36, "training_loss": 155.17567977905273, "training_acc": 35.0, "val_loss": 48.4267692565918, "val_acc": 60.0}
{"epoch": 37, "training_loss": 38.59296989440918, "training_acc": 45.0, "val_loss": 262.84130859375, "val_acc": 60.0}
{"epoch": 38, "training_loss": 380.1187255859375, "training_acc": 45.0, "val_loss": 95.9437026977539, "val_acc": 40.0}
{"epoch": 39, "training_loss": 88.41950073242188, "training_acc": 55.0, "val_loss": 38.60380554199219, "val_acc": 60.0}
{"epoch": 40, "training_loss": 26.293436813354493, "training_acc": 60.0, "val_loss": 236.8100128173828, "val_acc": 40.0}
{"epoch": 41, "training_loss": 159.1514404296875, "training_acc": 45.0, "val_loss": 232.1149444580078, "val_acc": 60.0}
{"epoch": 42, "training_loss": 162.4575927734375, "training_acc": 55.0, "val_loss": 618.4542846679688, "val_acc": 40.0}
{"epoch": 43, "training_loss": 423.8418701171875, "training_acc": 55.0, "val_loss": 35.85651397705078, "val_acc": 20.0}
