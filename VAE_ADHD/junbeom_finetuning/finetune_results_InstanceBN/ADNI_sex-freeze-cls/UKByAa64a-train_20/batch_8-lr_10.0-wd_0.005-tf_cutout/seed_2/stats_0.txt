"main_modify.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 2 --task ADNI_sex --input_option yAware --learning_rate 1e1 --batch_size 8 --weight_decay 5e-3 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 1206.3464491844177, "training_acc": 50.0, "val_loss": 819.9986572265625, "val_acc": 60.0}
{"epoch": 1, "training_loss": 1195.772021484375, "training_acc": 50.0, "val_loss": 566.8085327148438, "val_acc": 60.0}
{"epoch": 2, "training_loss": 506.0664794921875, "training_acc": 40.0, "val_loss": 380.3475036621094, "val_acc": 40.0}
{"epoch": 3, "training_loss": 174.62852935791017, "training_acc": 50.0, "val_loss": 143.77163696289062, "val_acc": 40.0}
{"epoch": 4, "training_loss": 74.72739372253417, "training_acc": 50.0, "val_loss": 159.04054260253906, "val_acc": 40.0}
{"epoch": 5, "training_loss": 195.8576171875, "training_acc": 40.0, "val_loss": 135.54429626464844, "val_acc": 40.0}
{"epoch": 6, "training_loss": 145.8498977661133, "training_acc": 40.0, "val_loss": 76.32845306396484, "val_acc": 40.0}
{"epoch": 7, "training_loss": 143.96437606811523, "training_acc": 40.0, "val_loss": 237.8671417236328, "val_acc": 60.0}
{"epoch": 8, "training_loss": 168.66680145263672, "training_acc": 60.0, "val_loss": 455.9390563964844, "val_acc": 40.0}
{"epoch": 9, "training_loss": 363.10003662109375, "training_acc": 50.0, "val_loss": 216.33462524414062, "val_acc": 60.0}
{"epoch": 10, "training_loss": 281.0936706542969, "training_acc": 50.0, "val_loss": 172.1352996826172, "val_acc": 40.0}
{"epoch": 11, "training_loss": 225.61532592773438, "training_acc": 50.0, "val_loss": 32.90087127685547, "val_acc": 60.0}
{"epoch": 12, "training_loss": 45.81555938720703, "training_acc": 50.0, "val_loss": 21.85760498046875, "val_acc": 60.0}
{"epoch": 13, "training_loss": 82.14057312011718, "training_acc": 40.0, "val_loss": 217.1652374267578, "val_acc": 60.0}
{"epoch": 14, "training_loss": 376.2792236328125, "training_acc": 50.0, "val_loss": 20.27614402770996, "val_acc": 60.0}
{"epoch": 15, "training_loss": 459.66858978271483, "training_acc": 40.0, "val_loss": 1064.720458984375, "val_acc": 40.0}
{"epoch": 16, "training_loss": 721.2479248046875, "training_acc": 50.0, "val_loss": 118.19747161865234, "val_acc": 60.0}
{"epoch": 17, "training_loss": 253.94180908203126, "training_acc": 50.0, "val_loss": 207.5566864013672, "val_acc": 60.0}
{"epoch": 18, "training_loss": 188.2314666748047, "training_acc": 50.0, "val_loss": 655.452880859375, "val_acc": 40.0}
{"epoch": 19, "training_loss": 471.2885543823242, "training_acc": 50.0, "val_loss": 142.0281524658203, "val_acc": 60.0}
{"epoch": 20, "training_loss": 176.20608520507812, "training_acc": 50.0, "val_loss": 140.83331298828125, "val_acc": 40.0}
{"epoch": 21, "training_loss": 128.051904296875, "training_acc": 40.0, "val_loss": 22.330890655517578, "val_acc": 40.0}
{"epoch": 22, "training_loss": 32.80313262939453, "training_acc": 50.0, "val_loss": 385.0257873535156, "val_acc": 40.0}
{"epoch": 23, "training_loss": 337.8197082519531, "training_acc": 50.0, "val_loss": 7.68175745010376, "val_acc": 40.0}
{"epoch": 24, "training_loss": 414.91098365783694, "training_acc": 40.0, "val_loss": 607.5123901367188, "val_acc": 60.0}
{"epoch": 25, "training_loss": 566.8597778320312, "training_acc": 50.0, "val_loss": 406.61669921875, "val_acc": 40.0}
{"epoch": 26, "training_loss": 540.3982666015625, "training_acc": 50.0, "val_loss": 622.7860107421875, "val_acc": 40.0}
{"epoch": 27, "training_loss": 319.141552734375, "training_acc": 50.0, "val_loss": 514.0070190429688, "val_acc": 60.0}
{"epoch": 28, "training_loss": 650.340771484375, "training_acc": 50.0, "val_loss": 179.0736846923828, "val_acc": 60.0}
{"epoch": 29, "training_loss": 269.38776245117185, "training_acc": 50.0, "val_loss": 655.3093872070312, "val_acc": 40.0}
{"epoch": 30, "training_loss": 382.17999267578125, "training_acc": 50.0, "val_loss": 298.4718322753906, "val_acc": 60.0}
{"epoch": 31, "training_loss": 583.361083984375, "training_acc": 50.0, "val_loss": 526.4866333007812, "val_acc": 60.0}
{"epoch": 32, "training_loss": 453.3280792236328, "training_acc": 50.0, "val_loss": 482.48876953125, "val_acc": 40.0}
{"epoch": 33, "training_loss": 348.54857177734374, "training_acc": 50.0, "val_loss": 151.81394958496094, "val_acc": 60.0}
{"epoch": 34, "training_loss": 186.43621368408202, "training_acc": 50.0, "val_loss": 240.4599609375, "val_acc": 40.0}
{"epoch": 35, "training_loss": 217.38743896484374, "training_acc": 50.0, "val_loss": 194.4834442138672, "val_acc": 60.0}
{"epoch": 36, "training_loss": 341.9499572753906, "training_acc": 50.0, "val_loss": 90.38890838623047, "val_acc": 60.0}
{"epoch": 37, "training_loss": 225.34886779785157, "training_acc": 60.0, "val_loss": 613.6456298828125, "val_acc": 40.0}
{"epoch": 38, "training_loss": 468.1223571777344, "training_acc": 30.0, "val_loss": 189.9178924560547, "val_acc": 60.0}
{"epoch": 39, "training_loss": 137.92635345458984, "training_acc": 60.0, "val_loss": 399.3190612792969, "val_acc": 40.0}
{"epoch": 40, "training_loss": 258.35169677734376, "training_acc": 50.0, "val_loss": 280.1167297363281, "val_acc": 60.0}
{"epoch": 41, "training_loss": 440.39808959960936, "training_acc": 50.0, "val_loss": 176.13841247558594, "val_acc": 60.0}
{"epoch": 42, "training_loss": 271.8304931640625, "training_acc": 50.0, "val_loss": 397.192626953125, "val_acc": 40.0}
