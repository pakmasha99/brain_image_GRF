"main_modify.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 2 --task ADNI_sex --input_option yAware --learning_rate 1e1 --batch_size 8 --weight_decay 5e-3 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 1294.4878870725631, "training_acc": 40.0, "val_loss": 380.882080078125, "val_acc": 40.0}
{"epoch": 1, "training_loss": 432.8502197265625, "training_acc": 50.0, "val_loss": 79.3451919555664, "val_acc": 60.0}
{"epoch": 2, "training_loss": 132.94035797119142, "training_acc": 50.0, "val_loss": 46.806495666503906, "val_acc": 40.0}
{"epoch": 3, "training_loss": 290.5973358154297, "training_acc": 50.0, "val_loss": 92.3283920288086, "val_acc": 60.0}
{"epoch": 4, "training_loss": 272.85617980957034, "training_acc": 60.0, "val_loss": 852.2211303710938, "val_acc": 40.0}
{"epoch": 5, "training_loss": 464.3604797363281, "training_acc": 50.0, "val_loss": 468.7931823730469, "val_acc": 60.0}
{"epoch": 6, "training_loss": 881.51376953125, "training_acc": 50.0, "val_loss": 687.9230346679688, "val_acc": 60.0}
{"epoch": 7, "training_loss": 551.5513427734375, "training_acc": 50.0, "val_loss": 520.4922485351562, "val_acc": 40.0}
{"epoch": 8, "training_loss": 431.16431884765626, "training_acc": 50.0, "val_loss": 36.50191879272461, "val_acc": 60.0}
{"epoch": 9, "training_loss": 188.2097396850586, "training_acc": 50.0, "val_loss": 64.3116226196289, "val_acc": 40.0}
{"epoch": 10, "training_loss": 79.52396850585937, "training_acc": 50.0, "val_loss": 324.59771728515625, "val_acc": 60.0}
{"epoch": 11, "training_loss": 582.6731567382812, "training_acc": 50.0, "val_loss": 326.17413330078125, "val_acc": 60.0}
{"epoch": 12, "training_loss": 319.0992965698242, "training_acc": 40.0, "val_loss": 986.6283569335938, "val_acc": 40.0}
{"epoch": 13, "training_loss": 764.0597778320313, "training_acc": 50.0, "val_loss": 272.8638000488281, "val_acc": 40.0}
{"epoch": 14, "training_loss": 586.8321166992188, "training_acc": 30.0, "val_loss": 641.697998046875, "val_acc": 60.0}
{"epoch": 15, "training_loss": 619.9483032226562, "training_acc": 50.0, "val_loss": 307.708251953125, "val_acc": 40.0}
{"epoch": 16, "training_loss": 295.20460205078126, "training_acc": 50.0, "val_loss": 404.4710998535156, "val_acc": 40.0}
{"epoch": 17, "training_loss": 183.72406616210938, "training_acc": 60.0, "val_loss": 316.0108947753906, "val_acc": 60.0}
{"epoch": 18, "training_loss": 320.6376724243164, "training_acc": 50.0, "val_loss": 292.5854187011719, "val_acc": 40.0}
{"epoch": 19, "training_loss": 276.5194946289063, "training_acc": 50.0, "val_loss": 6.798165798187256, "val_acc": 60.0}
{"epoch": 20, "training_loss": 44.63361701965332, "training_acc": 50.0, "val_loss": 67.93496704101562, "val_acc": 60.0}
{"epoch": 21, "training_loss": 56.89908218383789, "training_acc": 60.0, "val_loss": 409.239013671875, "val_acc": 40.0}
{"epoch": 22, "training_loss": 282.6863159179687, "training_acc": 40.0, "val_loss": 55.8572883605957, "val_acc": 60.0}
{"epoch": 23, "training_loss": 106.12776489257813, "training_acc": 50.0, "val_loss": 95.63729095458984, "val_acc": 60.0}
{"epoch": 24, "training_loss": 128.67027587890624, "training_acc": 40.0, "val_loss": 30.196945190429688, "val_acc": 60.0}
{"epoch": 25, "training_loss": 56.2288722038269, "training_acc": 50.0, "val_loss": 2.667201042175293, "val_acc": 40.0}
{"epoch": 26, "training_loss": 34.233737564086915, "training_acc": 55.0, "val_loss": 85.53105926513672, "val_acc": 40.0}
{"epoch": 27, "training_loss": 131.82183532714845, "training_acc": 40.0, "val_loss": 138.11370849609375, "val_acc": 40.0}
{"epoch": 28, "training_loss": 139.3677947998047, "training_acc": 40.0, "val_loss": 13.328607559204102, "val_acc": 60.0}
{"epoch": 29, "training_loss": 178.45266876220703, "training_acc": 50.0, "val_loss": 149.69911193847656, "val_acc": 40.0}
{"epoch": 30, "training_loss": 230.3557922363281, "training_acc": 50.0, "val_loss": 265.0364074707031, "val_acc": 60.0}
{"epoch": 31, "training_loss": 221.09734497070312, "training_acc": 50.0, "val_loss": 586.0399780273438, "val_acc": 40.0}
{"epoch": 32, "training_loss": 424.692236328125, "training_acc": 50.0, "val_loss": 130.2147216796875, "val_acc": 60.0}
{"epoch": 33, "training_loss": 212.24793090820313, "training_acc": 50.0, "val_loss": 3.42901349067688, "val_acc": 60.0}
{"epoch": 34, "training_loss": 320.2128623962402, "training_acc": 40.0, "val_loss": 646.570068359375, "val_acc": 40.0}
{"epoch": 35, "training_loss": 329.30668487548826, "training_acc": 60.0, "val_loss": 199.8564910888672, "val_acc": 60.0}
{"epoch": 36, "training_loss": 183.4769666671753, "training_acc": 50.0, "val_loss": 4.405250549316406, "val_acc": 40.0}
{"epoch": 37, "training_loss": 67.86486148834229, "training_acc": 60.0, "val_loss": 98.81688690185547, "val_acc": 40.0}
{"epoch": 38, "training_loss": 137.46077575683594, "training_acc": 40.0, "val_loss": 51.17495346069336, "val_acc": 60.0}
{"epoch": 39, "training_loss": 86.530126953125, "training_acc": 60.0, "val_loss": 19.712589263916016, "val_acc": 40.0}
{"epoch": 40, "training_loss": 171.19480781555177, "training_acc": 50.0, "val_loss": 159.13999938964844, "val_acc": 60.0}
{"epoch": 41, "training_loss": 362.534521484375, "training_acc": 20.0, "val_loss": 108.8060531616211, "val_acc": 40.0}
{"epoch": 42, "training_loss": 161.7671142578125, "training_acc": 60.0, "val_loss": 281.5385437011719, "val_acc": 60.0}
{"epoch": 43, "training_loss": 311.56329956054685, "training_acc": 40.0, "val_loss": 480.21142578125, "val_acc": 40.0}
{"epoch": 44, "training_loss": 283.5341278076172, "training_acc": 50.0, "val_loss": 122.6106185913086, "val_acc": 60.0}
