"main_modify.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 1 --task ADNI_sex --input_option yAware --learning_rate 1e1 --batch_size 8 --weight_decay 5e-3 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 979.7051565408707, "training_acc": 50.0, "val_loss": 1379.267822265625, "val_acc": 40.0}
{"epoch": 1, "training_loss": 1599.63427734375, "training_acc": 50.0, "val_loss": 1082.2513427734375, "val_acc": 40.0}
{"epoch": 2, "training_loss": 514.4963928222656, "training_acc": 50.0, "val_loss": 1255.8388671875, "val_acc": 60.0}
{"epoch": 3, "training_loss": 1506.758154296875, "training_acc": 50.0, "val_loss": 642.7439575195312, "val_acc": 60.0}
{"epoch": 4, "training_loss": 677.385122680664, "training_acc": 40.0, "val_loss": 1538.72021484375, "val_acc": 40.0}
{"epoch": 5, "training_loss": 1319.482470703125, "training_acc": 50.0, "val_loss": 1001.9454345703125, "val_acc": 40.0}
{"epoch": 6, "training_loss": 317.72705078125, "training_acc": 70.0, "val_loss": 899.5693359375, "val_acc": 60.0}
{"epoch": 7, "training_loss": 1296.99638671875, "training_acc": 50.0, "val_loss": 1037.6337890625, "val_acc": 60.0}
{"epoch": 8, "training_loss": 1026.899217224121, "training_acc": 50.0, "val_loss": 613.5978393554688, "val_acc": 40.0}
{"epoch": 9, "training_loss": 778.46982421875, "training_acc": 50.0, "val_loss": 1149.774658203125, "val_acc": 40.0}
{"epoch": 10, "training_loss": 658.539404296875, "training_acc": 50.0, "val_loss": 307.67779541015625, "val_acc": 60.0}
{"epoch": 11, "training_loss": 909.3929443359375, "training_acc": 50.0, "val_loss": 795.1276245117188, "val_acc": 60.0}
{"epoch": 12, "training_loss": 827.5158203125, "training_acc": 50.0, "val_loss": 435.2374572753906, "val_acc": 40.0}
{"epoch": 13, "training_loss": 394.62449645996094, "training_acc": 50.0, "val_loss": 430.7828063964844, "val_acc": 40.0}
{"epoch": 14, "training_loss": 305.7393005371094, "training_acc": 40.0, "val_loss": 462.33477783203125, "val_acc": 60.0}
{"epoch": 15, "training_loss": 493.1603759765625, "training_acc": 50.0, "val_loss": 162.24522399902344, "val_acc": 40.0}
{"epoch": 16, "training_loss": 322.4566345214844, "training_acc": 50.0, "val_loss": 130.62242126464844, "val_acc": 40.0}
{"epoch": 17, "training_loss": 345.29754638671875, "training_acc": 50.0, "val_loss": 488.54541015625, "val_acc": 60.0}
{"epoch": 18, "training_loss": 399.23837699890134, "training_acc": 50.0, "val_loss": 218.58132934570312, "val_acc": 40.0}
{"epoch": 19, "training_loss": 113.73385620117188, "training_acc": 50.0, "val_loss": 357.6410217285156, "val_acc": 60.0}
{"epoch": 20, "training_loss": 605.7150024414062, "training_acc": 50.0, "val_loss": 408.721435546875, "val_acc": 60.0}
{"epoch": 21, "training_loss": 359.69122924804685, "training_acc": 40.0, "val_loss": 789.782958984375, "val_acc": 40.0}
{"epoch": 22, "training_loss": 681.2920043945312, "training_acc": 50.0, "val_loss": 284.28704833984375, "val_acc": 40.0}
{"epoch": 23, "training_loss": 296.8973388671875, "training_acc": 50.0, "val_loss": 535.8529663085938, "val_acc": 60.0}
{"epoch": 24, "training_loss": 536.2108673095703, "training_acc": 50.0, "val_loss": 214.5490264892578, "val_acc": 40.0}
{"epoch": 25, "training_loss": 326.2466979980469, "training_acc": 50.0, "val_loss": 324.0699157714844, "val_acc": 40.0}
{"epoch": 26, "training_loss": 235.94349975585936, "training_acc": 40.0, "val_loss": 116.9600601196289, "val_acc": 60.0}
{"epoch": 27, "training_loss": 134.56864318847656, "training_acc": 50.0, "val_loss": 18.922910690307617, "val_acc": 40.0}
{"epoch": 28, "training_loss": 247.5529006958008, "training_acc": 40.0, "val_loss": 250.9783935546875, "val_acc": 60.0}
{"epoch": 29, "training_loss": 193.955224609375, "training_acc": 60.0, "val_loss": 661.3580932617188, "val_acc": 40.0}
{"epoch": 30, "training_loss": 542.6427368164062, "training_acc": 50.0, "val_loss": 43.584564208984375, "val_acc": 40.0}
{"epoch": 31, "training_loss": 714.0863693237304, "training_acc": 20.0, "val_loss": 800.6094970703125, "val_acc": 60.0}
{"epoch": 32, "training_loss": 839.6512268066406, "training_acc": 50.0, "val_loss": 129.92735290527344, "val_acc": 40.0}
{"epoch": 33, "training_loss": 311.6533966064453, "training_acc": 50.0, "val_loss": 287.9136962890625, "val_acc": 40.0}
{"epoch": 34, "training_loss": 205.46085205078126, "training_acc": 50.0, "val_loss": 112.5260009765625, "val_acc": 60.0}
{"epoch": 35, "training_loss": 293.9959411621094, "training_acc": 30.0, "val_loss": 235.44883728027344, "val_acc": 40.0}
{"epoch": 36, "training_loss": 276.9115936279297, "training_acc": 30.0, "val_loss": 104.14678955078125, "val_acc": 60.0}
{"epoch": 37, "training_loss": 185.8677978515625, "training_acc": 50.0, "val_loss": 147.65774536132812, "val_acc": 40.0}
{"epoch": 38, "training_loss": 252.6012390136719, "training_acc": 50.0, "val_loss": 176.54701232910156, "val_acc": 60.0}
{"epoch": 39, "training_loss": 135.41576232910157, "training_acc": 60.0, "val_loss": 196.8112335205078, "val_acc": 40.0}
{"epoch": 40, "training_loss": 86.47050285339355, "training_acc": 60.0, "val_loss": 109.57730865478516, "val_acc": 40.0}
{"epoch": 41, "training_loss": 68.32277030944825, "training_acc": 60.0, "val_loss": 65.45047760009766, "val_acc": 60.0}
{"epoch": 42, "training_loss": 111.01549987792968, "training_acc": 40.0, "val_loss": 131.09771728515625, "val_acc": 60.0}
{"epoch": 43, "training_loss": 139.17144775390625, "training_acc": 50.0, "val_loss": 384.33935546875, "val_acc": 40.0}
{"epoch": 44, "training_loss": 414.8245849609375, "training_acc": 50.0, "val_loss": 244.2793731689453, "val_acc": 40.0}
{"epoch": 45, "training_loss": 245.08575439453125, "training_acc": 40.0, "val_loss": 96.75973510742188, "val_acc": 60.0}
{"epoch": 46, "training_loss": 329.63914794921874, "training_acc": 30.0, "val_loss": 352.9469909667969, "val_acc": 40.0}
