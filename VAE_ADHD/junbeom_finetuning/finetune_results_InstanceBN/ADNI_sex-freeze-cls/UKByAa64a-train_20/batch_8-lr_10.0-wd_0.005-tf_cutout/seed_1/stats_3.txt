"main_modify.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 1 --task ADNI_sex --input_option yAware --learning_rate 1e1 --batch_size 8 --weight_decay 5e-3 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 1000.7997562885284, "training_acc": 50.0, "val_loss": 785.4151611328125, "val_acc": 60.0}
{"epoch": 1, "training_loss": 1401.475341796875, "training_acc": 50.0, "val_loss": 584.48779296875, "val_acc": 60.0}
{"epoch": 2, "training_loss": 568.0066528320312, "training_acc": 50.0, "val_loss": 1058.6600341796875, "val_acc": 40.0}
{"epoch": 3, "training_loss": 745.9471252441406, "training_acc": 30.0, "val_loss": 69.30013275146484, "val_acc": 60.0}
{"epoch": 4, "training_loss": 116.54915771484374, "training_acc": 50.0, "val_loss": 132.7725830078125, "val_acc": 60.0}
{"epoch": 5, "training_loss": 213.85045166015624, "training_acc": 30.0, "val_loss": 103.42473602294922, "val_acc": 60.0}
{"epoch": 6, "training_loss": 85.82434921264648, "training_acc": 60.0, "val_loss": 213.19956970214844, "val_acc": 40.0}
{"epoch": 7, "training_loss": 140.96079711914064, "training_acc": 50.0, "val_loss": 282.1349792480469, "val_acc": 60.0}
{"epoch": 8, "training_loss": 215.19626655578614, "training_acc": 50.0, "val_loss": 618.6142578125, "val_acc": 40.0}
{"epoch": 9, "training_loss": 650.5428344726563, "training_acc": 50.0, "val_loss": 730.6735229492188, "val_acc": 40.0}
{"epoch": 10, "training_loss": 335.86317138671876, "training_acc": 60.0, "val_loss": 510.1857604980469, "val_acc": 60.0}
{"epoch": 11, "training_loss": 655.28486328125, "training_acc": 50.0, "val_loss": 260.5256042480469, "val_acc": 60.0}
{"epoch": 12, "training_loss": 396.67755737304685, "training_acc": 40.0, "val_loss": 579.359130859375, "val_acc": 40.0}
{"epoch": 13, "training_loss": 294.52675476074216, "training_acc": 60.0, "val_loss": 247.9379425048828, "val_acc": 60.0}
{"epoch": 14, "training_loss": 256.6075399398804, "training_acc": 50.0, "val_loss": 351.9823303222656, "val_acc": 40.0}
{"epoch": 15, "training_loss": 368.5179244995117, "training_acc": 50.0, "val_loss": 10.99600887298584, "val_acc": 40.0}
{"epoch": 16, "training_loss": 422.78342361450194, "training_acc": 40.0, "val_loss": 454.10430908203125, "val_acc": 60.0}
{"epoch": 17, "training_loss": 536.0411163330078, "training_acc": 40.0, "val_loss": 695.1425170898438, "val_acc": 40.0}
{"epoch": 18, "training_loss": 538.1808837890625, "training_acc": 50.0, "val_loss": 70.4236068725586, "val_acc": 60.0}
{"epoch": 19, "training_loss": 76.96775064468383, "training_acc": 50.0, "val_loss": 58.10748291015625, "val_acc": 60.0}
{"epoch": 20, "training_loss": 52.55771331787109, "training_acc": 50.0, "val_loss": 92.99351501464844, "val_acc": 40.0}
{"epoch": 21, "training_loss": 59.57941999435425, "training_acc": 50.0, "val_loss": 11.112016677856445, "val_acc": 60.0}
{"epoch": 22, "training_loss": 128.31595840454102, "training_acc": 40.0, "val_loss": 71.79534149169922, "val_acc": 60.0}
{"epoch": 23, "training_loss": 102.26078491210937, "training_acc": 50.0, "val_loss": 123.60289764404297, "val_acc": 40.0}
{"epoch": 24, "training_loss": 190.056005859375, "training_acc": 30.0, "val_loss": 94.76226043701172, "val_acc": 40.0}
{"epoch": 25, "training_loss": 131.12759857177736, "training_acc": 40.0, "val_loss": 15.386003494262695, "val_acc": 60.0}
{"epoch": 26, "training_loss": 249.9078285217285, "training_acc": 40.0, "val_loss": 161.2646026611328, "val_acc": 40.0}
{"epoch": 27, "training_loss": 260.62131958007814, "training_acc": 50.0, "val_loss": 364.8399963378906, "val_acc": 60.0}
{"epoch": 28, "training_loss": 414.36578369140625, "training_acc": 30.0, "val_loss": 325.0442199707031, "val_acc": 40.0}
{"epoch": 29, "training_loss": 160.42596588134765, "training_acc": 60.0, "val_loss": 193.88636779785156, "val_acc": 60.0}
{"epoch": 30, "training_loss": 266.1015197753906, "training_acc": 30.0, "val_loss": 146.5404815673828, "val_acc": 40.0}
{"epoch": 31, "training_loss": 138.53417053222657, "training_acc": 50.0, "val_loss": 40.25503158569336, "val_acc": 60.0}
{"epoch": 32, "training_loss": 175.72684478759766, "training_acc": 50.0, "val_loss": 291.64697265625, "val_acc": 40.0}
{"epoch": 33, "training_loss": 122.56948852539062, "training_acc": 60.0, "val_loss": 421.1939392089844, "val_acc": 60.0}
{"epoch": 34, "training_loss": 522.1058349609375, "training_acc": 50.0, "val_loss": 19.03081703186035, "val_acc": 60.0}
