"main_modify.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 1 --task ADNI_sex --input_option yAware --learning_rate 1e1 --batch_size 8 --weight_decay 5e-3 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 1570.7357099056244, "training_acc": 45.0, "val_loss": 737.9714965820312, "val_acc": 40.0}
{"epoch": 1, "training_loss": 778.1262329101562, "training_acc": 55.0, "val_loss": 1268.8074951171875, "val_acc": 40.0}
{"epoch": 2, "training_loss": 503.1351947784424, "training_acc": 65.0, "val_loss": 373.99322509765625, "val_acc": 60.0}
{"epoch": 3, "training_loss": 449.54096069335935, "training_acc": 45.0, "val_loss": 508.6421813964844, "val_acc": 40.0}
{"epoch": 4, "training_loss": 600.5531372070312, "training_acc": 55.0, "val_loss": 687.21826171875, "val_acc": 40.0}
{"epoch": 5, "training_loss": 376.016748046875, "training_acc": 45.0, "val_loss": 529.2362060546875, "val_acc": 60.0}
{"epoch": 6, "training_loss": 653.7636474609375, "training_acc": 45.0, "val_loss": 300.8883972167969, "val_acc": 40.0}
{"epoch": 7, "training_loss": 276.5088745117188, "training_acc": 55.0, "val_loss": 30.797956466674805, "val_acc": 40.0}
{"epoch": 8, "training_loss": 459.82704162597656, "training_acc": 35.0, "val_loss": 505.0621032714844, "val_acc": 60.0}
{"epoch": 9, "training_loss": 533.9547973632813, "training_acc": 35.0, "val_loss": 448.78009033203125, "val_acc": 40.0}
{"epoch": 10, "training_loss": 314.29687957763673, "training_acc": 55.0, "val_loss": 138.37774658203125, "val_acc": 60.0}
{"epoch": 11, "training_loss": 267.7839294433594, "training_acc": 45.0, "val_loss": 245.18260192871094, "val_acc": 40.0}
{"epoch": 12, "training_loss": 284.1167877197266, "training_acc": 55.0, "val_loss": 348.1822509765625, "val_acc": 40.0}
{"epoch": 13, "training_loss": 202.39582366943358, "training_acc": 35.0, "val_loss": 117.6338119506836, "val_acc": 40.0}
{"epoch": 14, "training_loss": 128.34777221679687, "training_acc": 55.0, "val_loss": 212.1269989013672, "val_acc": 60.0}
{"epoch": 15, "training_loss": 332.4359130859375, "training_acc": 45.0, "val_loss": 29.290578842163086, "val_acc": 40.0}
{"epoch": 16, "training_loss": 62.582689666748045, "training_acc": 45.0, "val_loss": 22.02858543395996, "val_acc": 40.0}
{"epoch": 17, "training_loss": 54.45894927978516, "training_acc": 45.0, "val_loss": 110.27159881591797, "val_acc": 40.0}
{"epoch": 18, "training_loss": 243.11801147460938, "training_acc": 25.0, "val_loss": 84.0477523803711, "val_acc": 40.0}
{"epoch": 19, "training_loss": 87.115966796875, "training_acc": 55.0, "val_loss": 156.3788604736328, "val_acc": 60.0}
{"epoch": 20, "training_loss": 208.14302978515624, "training_acc": 45.0, "val_loss": 278.70855712890625, "val_acc": 40.0}
{"epoch": 21, "training_loss": 380.0968780517578, "training_acc": 55.0, "val_loss": 272.2359313964844, "val_acc": 40.0}
{"epoch": 22, "training_loss": 361.11627197265625, "training_acc": 35.0, "val_loss": 257.2012634277344, "val_acc": 60.0}
{"epoch": 23, "training_loss": 181.92677154541016, "training_acc": 55.0, "val_loss": 836.2667846679688, "val_acc": 40.0}
{"epoch": 24, "training_loss": 723.5924072265625, "training_acc": 55.0, "val_loss": 561.99755859375, "val_acc": 40.0}
{"epoch": 25, "training_loss": 248.65068359375, "training_acc": 45.0, "val_loss": 204.99534606933594, "val_acc": 60.0}
{"epoch": 26, "training_loss": 202.36312255859374, "training_acc": 45.0, "val_loss": 568.388671875, "val_acc": 40.0}
{"epoch": 27, "training_loss": 449.76854248046874, "training_acc": 55.0, "val_loss": 13.805521965026855, "val_acc": 60.0}
{"epoch": 28, "training_loss": 274.54038429260254, "training_acc": 45.0, "val_loss": 4.386475086212158, "val_acc": 40.0}
{"epoch": 29, "training_loss": 71.46713504791259, "training_acc": 35.0, "val_loss": 189.16871643066406, "val_acc": 40.0}
{"epoch": 30, "training_loss": 162.3455394744873, "training_acc": 55.0, "val_loss": 157.7386474609375, "val_acc": 60.0}
{"epoch": 31, "training_loss": 220.04105825424193, "training_acc": 35.0, "val_loss": 38.63035202026367, "val_acc": 60.0}
{"epoch": 32, "training_loss": 11.794575500488282, "training_acc": 65.0, "val_loss": 587.8202514648438, "val_acc": 40.0}
{"epoch": 33, "training_loss": 411.4585876464844, "training_acc": 55.0, "val_loss": 47.978302001953125, "val_acc": 40.0}
{"epoch": 34, "training_loss": 233.75936737060547, "training_acc": 55.0, "val_loss": 317.86712646484375, "val_acc": 60.0}
{"epoch": 35, "training_loss": 286.913720703125, "training_acc": 45.0, "val_loss": 605.2700805664062, "val_acc": 40.0}
{"epoch": 36, "training_loss": 459.0462890625, "training_acc": 55.0, "val_loss": 118.40612030029297, "val_acc": 40.0}
{"epoch": 37, "training_loss": 202.17481689453126, "training_acc": 65.0, "val_loss": 381.60748291015625, "val_acc": 60.0}
{"epoch": 38, "training_loss": 420.99952392578126, "training_acc": 35.0, "val_loss": 448.8324890136719, "val_acc": 40.0}
{"epoch": 39, "training_loss": 273.9778434753418, "training_acc": 55.0, "val_loss": 223.63243103027344, "val_acc": 60.0}
{"epoch": 40, "training_loss": 320.2340362548828, "training_acc": 45.0, "val_loss": 142.3076629638672, "val_acc": 40.0}
{"epoch": 41, "training_loss": 160.55079040527343, "training_acc": 55.0, "val_loss": 141.76145935058594, "val_acc": 60.0}
{"epoch": 42, "training_loss": 208.60016784667968, "training_acc": 45.0, "val_loss": 131.54495239257812, "val_acc": 40.0}
{"epoch": 43, "training_loss": 230.51481018066406, "training_acc": 55.0, "val_loss": 87.27531433105469, "val_acc": 60.0}
{"epoch": 44, "training_loss": 126.4224479675293, "training_acc": 35.0, "val_loss": 85.55838775634766, "val_acc": 60.0}
{"epoch": 45, "training_loss": 138.34752807617187, "training_acc": 25.0, "val_loss": 212.0296173095703, "val_acc": 60.0}
{"epoch": 46, "training_loss": 328.4520629882812, "training_acc": 45.0, "val_loss": 129.12698364257812, "val_acc": 40.0}
{"epoch": 47, "training_loss": 91.48588943481445, "training_acc": 55.0, "val_loss": 109.4156494140625, "val_acc": 60.0}
