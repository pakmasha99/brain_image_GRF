"main_modify.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_sex --input_option yAware --learning_rate 1e1 --batch_size 8 --weight_decay 5e-3 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 718.4390035152435, "training_acc": 55.0, "val_loss": 1024.9833984375, "val_acc": 60.0}
{"epoch": 1, "training_loss": 1829.4211059570312, "training_acc": 45.0, "val_loss": 479.8138732910156, "val_acc": 60.0}
{"epoch": 2, "training_loss": 547.4890625, "training_acc": 55.0, "val_loss": 1260.400390625, "val_acc": 40.0}
{"epoch": 3, "training_loss": 742.8635620117187, "training_acc": 55.0, "val_loss": 255.80899047851562, "val_acc": 60.0}
{"epoch": 4, "training_loss": 678.3669372558594, "training_acc": 45.0, "val_loss": 269.7760314941406, "val_acc": 60.0}
{"epoch": 5, "training_loss": 289.6091064453125, "training_acc": 55.0, "val_loss": 782.5979614257812, "val_acc": 40.0}
{"epoch": 6, "training_loss": 489.0065551757813, "training_acc": 55.0, "val_loss": 175.1200408935547, "val_acc": 60.0}
{"epoch": 7, "training_loss": 321.3460388183594, "training_acc": 45.0, "val_loss": 122.9482421875, "val_acc": 60.0}
{"epoch": 8, "training_loss": 303.2040222167969, "training_acc": 45.0, "val_loss": 421.308837890625, "val_acc": 40.0}
{"epoch": 9, "training_loss": 250.5911849975586, "training_acc": 35.0, "val_loss": 131.62974548339844, "val_acc": 40.0}
{"epoch": 10, "training_loss": 138.08297119140624, "training_acc": 55.0, "val_loss": 161.96609497070312, "val_acc": 60.0}
{"epoch": 11, "training_loss": 336.25696563720703, "training_acc": 45.0, "val_loss": 119.55211639404297, "val_acc": 40.0}
{"epoch": 12, "training_loss": 129.34700469970704, "training_acc": 55.0, "val_loss": 150.49542236328125, "val_acc": 60.0}
{"epoch": 13, "training_loss": 228.28967151641845, "training_acc": 45.0, "val_loss": 348.5351867675781, "val_acc": 40.0}
{"epoch": 14, "training_loss": 259.5587158203125, "training_acc": 55.0, "val_loss": 10.346080780029297, "val_acc": 60.0}
{"epoch": 15, "training_loss": 23.8847297668457, "training_acc": 65.0, "val_loss": 169.80850219726562, "val_acc": 40.0}
{"epoch": 16, "training_loss": 122.06452713012695, "training_acc": 25.0, "val_loss": 496.60968017578125, "val_acc": 40.0}
{"epoch": 17, "training_loss": 432.98193359375, "training_acc": 55.0, "val_loss": 464.2560729980469, "val_acc": 40.0}
{"epoch": 18, "training_loss": 148.60184020996093, "training_acc": 65.0, "val_loss": 462.6993103027344, "val_acc": 60.0}
{"epoch": 19, "training_loss": 645.8883056640625, "training_acc": 45.0, "val_loss": 42.355316162109375, "val_acc": 60.0}
{"epoch": 20, "training_loss": 255.27088623046876, "training_acc": 55.0, "val_loss": 736.0391845703125, "val_acc": 40.0}
{"epoch": 21, "training_loss": 415.39280967712403, "training_acc": 55.0, "val_loss": 328.9911804199219, "val_acc": 60.0}
{"epoch": 22, "training_loss": 578.1479583740235, "training_acc": 45.0, "val_loss": 210.4148712158203, "val_acc": 60.0}
{"epoch": 23, "training_loss": 355.0007690429687, "training_acc": 35.0, "val_loss": 476.2007751464844, "val_acc": 40.0}
{"epoch": 24, "training_loss": 193.93510208129882, "training_acc": 65.0, "val_loss": 211.780029296875, "val_acc": 60.0}
{"epoch": 25, "training_loss": 190.17168045043945, "training_acc": 55.0, "val_loss": 184.4575958251953, "val_acc": 40.0}
{"epoch": 26, "training_loss": 118.15818493366241, "training_acc": 55.0, "val_loss": 155.96054077148438, "val_acc": 60.0}
{"epoch": 27, "training_loss": 160.77159729003907, "training_acc": 45.0, "val_loss": 55.50380325317383, "val_acc": 60.0}
{"epoch": 28, "training_loss": 119.1557544708252, "training_acc": 55.0, "val_loss": 150.80776977539062, "val_acc": 40.0}
{"epoch": 29, "training_loss": 106.93178100585938, "training_acc": 35.0, "val_loss": 41.338104248046875, "val_acc": 40.0}
{"epoch": 30, "training_loss": 178.61038208007812, "training_acc": 45.0, "val_loss": 17.361392974853516, "val_acc": 40.0}
{"epoch": 31, "training_loss": 19.32844123840332, "training_acc": 55.0, "val_loss": 268.0911560058594, "val_acc": 60.0}
{"epoch": 32, "training_loss": 458.3202270507812, "training_acc": 45.0, "val_loss": 27.774005889892578, "val_acc": 40.0}
{"epoch": 33, "training_loss": 103.74601516723632, "training_acc": 55.0, "val_loss": 5.612191677093506, "val_acc": 40.0}
{"epoch": 34, "training_loss": 184.46130504608155, "training_acc": 45.0, "val_loss": 56.064144134521484, "val_acc": 60.0}
{"epoch": 35, "training_loss": 245.86651611328125, "training_acc": 45.0, "val_loss": 433.1112976074219, "val_acc": 40.0}
{"epoch": 36, "training_loss": 258.7683219909668, "training_acc": 55.0, "val_loss": 396.8350830078125, "val_acc": 60.0}
{"epoch": 37, "training_loss": 432.1542907714844, "training_acc": 45.0, "val_loss": 445.12457275390625, "val_acc": 40.0}
{"epoch": 38, "training_loss": 438.2628234863281, "training_acc": 55.0, "val_loss": 532.1823120117188, "val_acc": 40.0}
{"epoch": 39, "training_loss": 450.733806848526, "training_acc": 35.0, "val_loss": 546.9664306640625, "val_acc": 60.0}
{"epoch": 40, "training_loss": 610.1855285644531, "training_acc": 45.0, "val_loss": 324.1071472167969, "val_acc": 40.0}
{"epoch": 41, "training_loss": 463.1642822265625, "training_acc": 55.0, "val_loss": 600.7997436523438, "val_acc": 40.0}
{"epoch": 42, "training_loss": 265.50983276367185, "training_acc": 55.0, "val_loss": 426.3994140625, "val_acc": 60.0}
{"epoch": 43, "training_loss": 525.6448364257812, "training_acc": 45.0, "val_loss": 142.2962646484375, "val_acc": 40.0}
{"epoch": 44, "training_loss": 246.53121948242188, "training_acc": 55.0, "val_loss": 139.24365234375, "val_acc": 40.0}
{"epoch": 45, "training_loss": 319.2983032226563, "training_acc": 45.0, "val_loss": 292.3245849609375, "val_acc": 60.0}
{"epoch": 46, "training_loss": 331.42535400390625, "training_acc": 35.0, "val_loss": 884.3534545898438, "val_acc": 40.0}
{"epoch": 47, "training_loss": 689.3555053710937, "training_acc": 55.0, "val_loss": 329.5063171386719, "val_acc": 40.0}
{"epoch": 48, "training_loss": 252.28477172851564, "training_acc": 55.0, "val_loss": 363.96392822265625, "val_acc": 60.0}
{"epoch": 49, "training_loss": 261.5354858398438, "training_acc": 65.0, "val_loss": 363.2268981933594, "val_acc": 40.0}
{"epoch": 50, "training_loss": 369.5317687988281, "training_acc": 55.0, "val_loss": 72.58773803710938, "val_acc": 40.0}
{"epoch": 51, "training_loss": 377.8251190185547, "training_acc": 45.0, "val_loss": 506.6845703125, "val_acc": 60.0}
{"epoch": 52, "training_loss": 528.7799041748046, "training_acc": 45.0, "val_loss": 425.935546875, "val_acc": 40.0}
