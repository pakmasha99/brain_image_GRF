"main_modify.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 4 --task ADNI_sex --input_option yAware --learning_rate 1e1 --batch_size 8 --weight_decay 5e-3 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 1221.33802113533, "training_acc": 50.0, "val_loss": 716.2352294921875, "val_acc": 60.0}
{"epoch": 1, "training_loss": 1185.6088134765625, "training_acc": 50.0, "val_loss": 547.1881103515625, "val_acc": 60.0}
{"epoch": 2, "training_loss": 548.5450256347656, "training_acc": 40.0, "val_loss": 687.8611450195312, "val_acc": 40.0}
{"epoch": 3, "training_loss": 394.6539733886719, "training_acc": 50.0, "val_loss": 292.8488464355469, "val_acc": 60.0}
{"epoch": 4, "training_loss": 223.85287170410157, "training_acc": 50.0, "val_loss": 733.0175170898438, "val_acc": 40.0}
{"epoch": 5, "training_loss": 854.3794189453125, "training_acc": 50.0, "val_loss": 993.4635009765625, "val_acc": 40.0}
{"epoch": 6, "training_loss": 501.16547241210935, "training_acc": 50.0, "val_loss": 433.296630859375, "val_acc": 60.0}
{"epoch": 7, "training_loss": 533.201953125, "training_acc": 50.0, "val_loss": 96.88318634033203, "val_acc": 60.0}
{"epoch": 8, "training_loss": 361.8726867675781, "training_acc": 50.0, "val_loss": 733.84326171875, "val_acc": 40.0}
{"epoch": 9, "training_loss": 354.62282218933103, "training_acc": 60.0, "val_loss": 233.83580017089844, "val_acc": 60.0}
{"epoch": 10, "training_loss": 282.168310546875, "training_acc": 50.0, "val_loss": 274.6303405761719, "val_acc": 40.0}
{"epoch": 11, "training_loss": 289.0809020996094, "training_acc": 50.0, "val_loss": 89.62035369873047, "val_acc": 60.0}
{"epoch": 12, "training_loss": 241.8272933959961, "training_acc": 50.0, "val_loss": 165.2573699951172, "val_acc": 40.0}
{"epoch": 13, "training_loss": 165.7577362060547, "training_acc": 50.0, "val_loss": 173.0812225341797, "val_acc": 60.0}
{"epoch": 14, "training_loss": 273.61285705566405, "training_acc": 50.0, "val_loss": 31.272113800048828, "val_acc": 40.0}
{"epoch": 15, "training_loss": 40.828372955322266, "training_acc": 40.0, "val_loss": 331.9793701171875, "val_acc": 40.0}
{"epoch": 16, "training_loss": 170.55516967773437, "training_acc": 60.0, "val_loss": 167.77830505371094, "val_acc": 60.0}
{"epoch": 17, "training_loss": 163.8582000732422, "training_acc": 50.0, "val_loss": 198.7613983154297, "val_acc": 40.0}
{"epoch": 18, "training_loss": 107.50864744186401, "training_acc": 40.0, "val_loss": 114.75591278076172, "val_acc": 60.0}
{"epoch": 19, "training_loss": 163.90292053222657, "training_acc": 40.0, "val_loss": 244.3882293701172, "val_acc": 40.0}
{"epoch": 20, "training_loss": 220.5201416015625, "training_acc": 30.0, "val_loss": 126.39556884765625, "val_acc": 40.0}
{"epoch": 21, "training_loss": 122.13951416015625, "training_acc": 40.0, "val_loss": 2.756788492202759, "val_acc": 60.0}
{"epoch": 22, "training_loss": 130.29029788970948, "training_acc": 60.0, "val_loss": 192.1886749267578, "val_acc": 40.0}
{"epoch": 23, "training_loss": 240.08846435546874, "training_acc": 40.0, "val_loss": 137.90892028808594, "val_acc": 60.0}
{"epoch": 24, "training_loss": 96.24893722534179, "training_acc": 60.0, "val_loss": 64.77774810791016, "val_acc": 40.0}
{"epoch": 25, "training_loss": 145.3574432373047, "training_acc": 50.0, "val_loss": 47.0575065612793, "val_acc": 60.0}
{"epoch": 26, "training_loss": 88.67475280761718, "training_acc": 70.0, "val_loss": 292.9407653808594, "val_acc": 40.0}
{"epoch": 27, "training_loss": 172.704296875, "training_acc": 30.0, "val_loss": 295.6142272949219, "val_acc": 40.0}
{"epoch": 28, "training_loss": 290.0246643066406, "training_acc": 50.0, "val_loss": 112.0558853149414, "val_acc": 60.0}
{"epoch": 29, "training_loss": 274.779345703125, "training_acc": 50.0, "val_loss": 10.817032814025879, "val_acc": 60.0}
{"epoch": 30, "training_loss": 378.60266799926757, "training_acc": 40.0, "val_loss": 860.2145385742188, "val_acc": 40.0}
{"epoch": 31, "training_loss": 539.7258544921875, "training_acc": 50.0, "val_loss": 287.9391174316406, "val_acc": 60.0}
{"epoch": 32, "training_loss": 579.7810791015625, "training_acc": 50.0, "val_loss": 403.90362548828125, "val_acc": 60.0}
{"epoch": 33, "training_loss": 308.47679443359374, "training_acc": 60.0, "val_loss": 855.8058471679688, "val_acc": 40.0}
{"epoch": 34, "training_loss": 706.2685180664063, "training_acc": 50.0, "val_loss": 351.66656494140625, "val_acc": 40.0}
{"epoch": 35, "training_loss": 539.5880126953125, "training_acc": 30.0, "val_loss": 513.4871215820312, "val_acc": 60.0}
{"epoch": 36, "training_loss": 492.3890625, "training_acc": 50.0, "val_loss": 485.7744140625, "val_acc": 40.0}
{"epoch": 37, "training_loss": 667.9492309570312, "training_acc": 50.0, "val_loss": 815.3641967773438, "val_acc": 40.0}
{"epoch": 38, "training_loss": 468.297314453125, "training_acc": 50.0, "val_loss": 361.3238220214844, "val_acc": 60.0}
{"epoch": 39, "training_loss": 461.807275390625, "training_acc": 50.0, "val_loss": 28.8691349029541, "val_acc": 40.0}
{"epoch": 40, "training_loss": 238.9946216583252, "training_acc": 50.0, "val_loss": 34.56144332885742, "val_acc": 40.0}
