"main_modify.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 4 --task ADNI_sex --input_option yAware --learning_rate 1e1 --batch_size 8 --weight_decay 5e-3 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 982.6727964878082, "training_acc": 50.0, "val_loss": 1357.230712890625, "val_acc": 40.0}
{"epoch": 1, "training_loss": 1611.0635986328125, "training_acc": 50.0, "val_loss": 1194.0706787109375, "val_acc": 40.0}
{"epoch": 2, "training_loss": 417.08954734802245, "training_acc": 60.0, "val_loss": 1547.21533203125, "val_acc": 60.0}
{"epoch": 3, "training_loss": 2155.417578125, "training_acc": 50.0, "val_loss": 1469.1629638671875, "val_acc": 60.0}
{"epoch": 4, "training_loss": 1241.267724609375, "training_acc": 50.0, "val_loss": 872.9514770507812, "val_acc": 40.0}
{"epoch": 5, "training_loss": 1448.2883544921874, "training_acc": 50.0, "val_loss": 2187.5341796875, "val_acc": 40.0}
{"epoch": 6, "training_loss": 1579.8137573242188, "training_acc": 50.0, "val_loss": 677.5458374023438, "val_acc": 40.0}
{"epoch": 7, "training_loss": 295.98349609375, "training_acc": 70.0, "val_loss": 835.78515625, "val_acc": 60.0}
{"epoch": 8, "training_loss": 1015.885498046875, "training_acc": 50.0, "val_loss": 438.5541687011719, "val_acc": 60.0}
{"epoch": 9, "training_loss": 284.59122200012206, "training_acc": 50.0, "val_loss": 486.802734375, "val_acc": 40.0}
{"epoch": 10, "training_loss": 322.00220642089846, "training_acc": 40.0, "val_loss": 62.64764404296875, "val_acc": 60.0}
{"epoch": 11, "training_loss": 117.50034790039062, "training_acc": 40.0, "val_loss": 115.45861053466797, "val_acc": 60.0}
{"epoch": 12, "training_loss": 209.95377655029296, "training_acc": 30.0, "val_loss": 52.87813186645508, "val_acc": 60.0}
{"epoch": 13, "training_loss": 116.93641510009766, "training_acc": 40.0, "val_loss": 275.8504333496094, "val_acc": 40.0}
{"epoch": 14, "training_loss": 169.10126800537108, "training_acc": 50.0, "val_loss": 346.3859558105469, "val_acc": 60.0}
{"epoch": 15, "training_loss": 344.61809997558595, "training_acc": 50.0, "val_loss": 324.3318786621094, "val_acc": 40.0}
{"epoch": 16, "training_loss": 381.36376953125, "training_acc": 50.0, "val_loss": 246.0941925048828, "val_acc": 40.0}
{"epoch": 17, "training_loss": 276.97789306640624, "training_acc": 50.0, "val_loss": 304.95294189453125, "val_acc": 60.0}
{"epoch": 18, "training_loss": 250.04844360351564, "training_acc": 50.0, "val_loss": 475.08624267578125, "val_acc": 40.0}
{"epoch": 19, "training_loss": 360.9076416015625, "training_acc": 50.0, "val_loss": 135.4517364501953, "val_acc": 60.0}
{"epoch": 20, "training_loss": 335.08815002441406, "training_acc": 50.0, "val_loss": 167.61387634277344, "val_acc": 60.0}
{"epoch": 21, "training_loss": 166.90280151367188, "training_acc": 50.0, "val_loss": 142.87644958496094, "val_acc": 40.0}
{"epoch": 22, "training_loss": 47.52647933959961, "training_acc": 70.0, "val_loss": 0.4216260612010956, "val_acc": 100.0}
{"epoch": 23, "training_loss": 57.383773279190066, "training_acc": 55.0, "val_loss": 0.900245189666748, "val_acc": 60.0}
{"epoch": 24, "training_loss": 96.82918586730958, "training_acc": 55.0, "val_loss": 61.67902755737305, "val_acc": 60.0}
{"epoch": 25, "training_loss": 108.76441802978516, "training_acc": 40.0, "val_loss": 117.6046371459961, "val_acc": 40.0}
{"epoch": 26, "training_loss": 88.95932693481446, "training_acc": 60.0, "val_loss": 27.967817306518555, "val_acc": 60.0}
{"epoch": 27, "training_loss": 288.10059509277346, "training_acc": 30.0, "val_loss": 246.570068359375, "val_acc": 40.0}
{"epoch": 28, "training_loss": 180.60894165039062, "training_acc": 50.0, "val_loss": 117.40691375732422, "val_acc": 60.0}
{"epoch": 29, "training_loss": 55.01737060546875, "training_acc": 70.0, "val_loss": 25.442602157592773, "val_acc": 60.0}
{"epoch": 30, "training_loss": 63.120245361328124, "training_acc": 50.0, "val_loss": 346.5335388183594, "val_acc": 40.0}
{"epoch": 31, "training_loss": 237.33340606689453, "training_acc": 50.0, "val_loss": 306.0530700683594, "val_acc": 60.0}
{"epoch": 32, "training_loss": 313.67249298095703, "training_acc": 40.0, "val_loss": 65.02423095703125, "val_acc": 40.0}
{"epoch": 33, "training_loss": 77.01477355957032, "training_acc": 50.0, "val_loss": 187.40760803222656, "val_acc": 40.0}
{"epoch": 34, "training_loss": 115.98843088150025, "training_acc": 60.0, "val_loss": 63.04634475708008, "val_acc": 60.0}
{"epoch": 35, "training_loss": 90.76471481323242, "training_acc": 40.0, "val_loss": 193.9518280029297, "val_acc": 60.0}
{"epoch": 36, "training_loss": 241.57518005371094, "training_acc": 30.0, "val_loss": 83.54796600341797, "val_acc": 60.0}
{"epoch": 37, "training_loss": 98.59316711425781, "training_acc": 50.0, "val_loss": 224.9381103515625, "val_acc": 40.0}
{"epoch": 38, "training_loss": 110.69328285902739, "training_acc": 50.0, "val_loss": 78.10347747802734, "val_acc": 40.0}
{"epoch": 39, "training_loss": 146.78802490234375, "training_acc": 30.0, "val_loss": 227.80381774902344, "val_acc": 40.0}
{"epoch": 40, "training_loss": 160.52874832153321, "training_acc": 50.0, "val_loss": 215.7704620361328, "val_acc": 60.0}
{"epoch": 41, "training_loss": 306.1857971191406, "training_acc": 50.0, "val_loss": 55.92988967895508, "val_acc": 40.0}
