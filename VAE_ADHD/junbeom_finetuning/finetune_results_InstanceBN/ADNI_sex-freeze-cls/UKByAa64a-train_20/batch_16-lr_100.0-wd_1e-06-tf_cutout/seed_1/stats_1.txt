"main_modify.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 1 --task ADNI_sex --input_option yAware --learning_rate 1e2 --batch_size 16 --weight_decay 1e-6 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 4272.432287406921, "training_acc": 45.0, "val_loss": 9718.8876953125, "val_acc": 40.0}
{"epoch": 1, "training_loss": 5680.68974609375, "training_acc": 65.0, "val_loss": 12924.5673828125, "val_acc": 60.0}
{"epoch": 2, "training_loss": 17311.046875, "training_acc": 45.0, "val_loss": 4933.7353515625, "val_acc": 60.0}
{"epoch": 3, "training_loss": 4304.418359375, "training_acc": 65.0, "val_loss": 16920.71875, "val_acc": 40.0}
{"epoch": 4, "training_loss": 13053.48359375, "training_acc": 55.0, "val_loss": 23118.32421875, "val_acc": 40.0}
{"epoch": 5, "training_loss": 17066.5484375, "training_acc": 55.0, "val_loss": 15378.775390625, "val_acc": 40.0}
{"epoch": 6, "training_loss": 9692.32578125, "training_acc": 55.0, "val_loss": 2240.373291015625, "val_acc": 60.0}
{"epoch": 7, "training_loss": 3489.73037109375, "training_acc": 45.0, "val_loss": 7810.21435546875, "val_acc": 60.0}
{"epoch": 8, "training_loss": 10503.478125, "training_acc": 45.0, "val_loss": 3732.31494140625, "val_acc": 60.0}
{"epoch": 9, "training_loss": 4588.0576171875, "training_acc": 45.0, "val_loss": 6781.6572265625, "val_acc": 40.0}
{"epoch": 10, "training_loss": 5117.090087890625, "training_acc": 55.0, "val_loss": 6675.58447265625, "val_acc": 40.0}
{"epoch": 11, "training_loss": 4228.043359375, "training_acc": 55.0, "val_loss": 2137.620361328125, "val_acc": 60.0}
{"epoch": 12, "training_loss": 3692.61298828125, "training_acc": 45.0, "val_loss": 3500.860595703125, "val_acc": 60.0}
{"epoch": 13, "training_loss": 4375.985260009766, "training_acc": 45.0, "val_loss": 4641.54931640625, "val_acc": 40.0}
{"epoch": 14, "training_loss": 3633.2443359375, "training_acc": 55.0, "val_loss": 7378.29833984375, "val_acc": 40.0}
{"epoch": 15, "training_loss": 5300.1873046875, "training_acc": 55.0, "val_loss": 1817.464111328125, "val_acc": 40.0}
{"epoch": 16, "training_loss": 1134.126708984375, "training_acc": 65.0, "val_loss": 4345.4921875, "val_acc": 60.0}
{"epoch": 17, "training_loss": 5851.4265625, "training_acc": 45.0, "val_loss": 2288.090576171875, "val_acc": 60.0}
{"epoch": 18, "training_loss": 2878.924267578125, "training_acc": 45.0, "val_loss": 4574.8828125, "val_acc": 40.0}
{"epoch": 19, "training_loss": 3388.6109375, "training_acc": 55.0, "val_loss": 758.4403076171875, "val_acc": 40.0}
{"epoch": 20, "training_loss": 1768.3080078125, "training_acc": 45.0, "val_loss": 4637.94775390625, "val_acc": 60.0}
{"epoch": 21, "training_loss": 5962.0546875, "training_acc": 45.0, "val_loss": 161.4735870361328, "val_acc": 60.0}
{"epoch": 22, "training_loss": 698.1576782226563, "training_acc": 60.0, "val_loss": 12723.38671875, "val_acc": 40.0}
{"epoch": 23, "training_loss": 10210.737109375, "training_acc": 55.0, "val_loss": 14677.7236328125, "val_acc": 40.0}
{"epoch": 24, "training_loss": 10918.865625, "training_acc": 55.0, "val_loss": 7406.56005859375, "val_acc": 40.0}
{"epoch": 25, "training_loss": 4977.056958007813, "training_acc": 55.0, "val_loss": 3116.28125, "val_acc": 60.0}
{"epoch": 26, "training_loss": 4610.863671875, "training_acc": 45.0, "val_loss": 5067.56982421875, "val_acc": 60.0}
{"epoch": 27, "training_loss": 6370.024072265625, "training_acc": 45.0, "val_loss": 303.5348205566406, "val_acc": 40.0}
{"epoch": 28, "training_loss": 498.84515380859375, "training_acc": 55.0, "val_loss": 2201.31591796875, "val_acc": 40.0}
{"epoch": 29, "training_loss": 1243.8217834472657, "training_acc": 55.0, "val_loss": 188.27500915527344, "val_acc": 60.0}
{"epoch": 30, "training_loss": 765.1533569335937, "training_acc": 40.0, "val_loss": 1683.125244140625, "val_acc": 40.0}
{"epoch": 31, "training_loss": 1409.558642578125, "training_acc": 45.0, "val_loss": 810.6524047851562, "val_acc": 60.0}
{"epoch": 32, "training_loss": 1450.723046875, "training_acc": 35.0, "val_loss": 2074.3623046875, "val_acc": 40.0}
{"epoch": 33, "training_loss": 782.94033203125, "training_acc": 75.0, "val_loss": 1104.1771240234375, "val_acc": 60.0}
{"epoch": 34, "training_loss": 1116.9822082519531, "training_acc": 50.0, "val_loss": 1985.4417724609375, "val_acc": 40.0}
{"epoch": 35, "training_loss": 1354.99833984375, "training_acc": 55.0, "val_loss": 896.6046752929688, "val_acc": 60.0}
{"epoch": 36, "training_loss": 1058.6127807617188, "training_acc": 45.0, "val_loss": 135.44032287597656, "val_acc": 60.0}
{"epoch": 37, "training_loss": 626.1951782226563, "training_acc": 60.0, "val_loss": 1146.9661865234375, "val_acc": 40.0}
{"epoch": 38, "training_loss": 903.0356201171875, "training_acc": 55.0, "val_loss": 1952.4022216796875, "val_acc": 60.0}
{"epoch": 39, "training_loss": 2102.184649658203, "training_acc": 45.0, "val_loss": 3971.546142578125, "val_acc": 40.0}
{"epoch": 40, "training_loss": 3086.40146484375, "training_acc": 55.0, "val_loss": 5106.27685546875, "val_acc": 40.0}
{"epoch": 41, "training_loss": 2973.16953125, "training_acc": 55.0, "val_loss": 2404.652099609375, "val_acc": 60.0}
{"epoch": 42, "training_loss": 3573.86875, "training_acc": 45.0, "val_loss": 4089.342529296875, "val_acc": 60.0}
{"epoch": 43, "training_loss": 5194.41787109375, "training_acc": 45.0, "val_loss": 1292.8935546875, "val_acc": 40.0}
{"epoch": 44, "training_loss": 993.376953125, "training_acc": 55.0, "val_loss": 1739.767822265625, "val_acc": 40.0}
{"epoch": 45, "training_loss": 1364.33916015625, "training_acc": 45.0, "val_loss": 839.83544921875, "val_acc": 60.0}
{"epoch": 46, "training_loss": 1403.774560546875, "training_acc": 35.0, "val_loss": 2029.3704833984375, "val_acc": 40.0}
{"epoch": 47, "training_loss": 1307.3343017578125, "training_acc": 45.0, "val_loss": 254.49661254882812, "val_acc": 40.0}
{"epoch": 48, "training_loss": 30.533963012695313, "training_acc": 85.0, "val_loss": 379.479248046875, "val_acc": 40.0}
{"epoch": 49, "training_loss": 160.79537353515624, "training_acc": 70.0, "val_loss": 605.7111206054688, "val_acc": 40.0}
{"epoch": 50, "training_loss": 302.711328125, "training_acc": 45.0, "val_loss": 2006.6571044921875, "val_acc": 40.0}
{"epoch": 51, "training_loss": 1356.07744140625, "training_acc": 55.0, "val_loss": 566.8143310546875, "val_acc": 60.0}
{"epoch": 52, "training_loss": 719.0876708984375, "training_acc": 45.0, "val_loss": 2037.2398681640625, "val_acc": 40.0}
{"epoch": 53, "training_loss": 1270.840771484375, "training_acc": 55.0, "val_loss": 1701.620361328125, "val_acc": 40.0}
{"epoch": 54, "training_loss": 558.64423828125, "training_acc": 75.0, "val_loss": 1823.5299072265625, "val_acc": 60.0}
{"epoch": 55, "training_loss": 2011.009765625, "training_acc": 45.0, "val_loss": 1622.4462890625, "val_acc": 40.0}
