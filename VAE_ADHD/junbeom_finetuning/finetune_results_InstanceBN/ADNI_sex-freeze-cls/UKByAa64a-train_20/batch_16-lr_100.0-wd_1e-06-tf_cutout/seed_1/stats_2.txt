"main_modify.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 1 --task ADNI_sex --input_option yAware --learning_rate 1e2 --batch_size 16 --weight_decay 1e-6 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 2118.787166261673, "training_acc": 60.0, "val_loss": 7953.36865234375, "val_acc": 40.0}
{"epoch": 1, "training_loss": 9100.929296875, "training_acc": 40.0, "val_loss": 7721.25732421875, "val_acc": 60.0}
{"epoch": 2, "training_loss": 9005.21357421875, "training_acc": 50.0, "val_loss": 5404.80224609375, "val_acc": 40.0}
{"epoch": 3, "training_loss": 5275.7693359375, "training_acc": 50.0, "val_loss": 4078.20703125, "val_acc": 40.0}
{"epoch": 4, "training_loss": 3331.606494140625, "training_acc": 50.0, "val_loss": 4218.0009765625, "val_acc": 60.0}
{"epoch": 5, "training_loss": 5222.6609375, "training_acc": 50.0, "val_loss": 1372.4097900390625, "val_acc": 60.0}
{"epoch": 6, "training_loss": 1375.5920654296874, "training_acc": 60.0, "val_loss": 5268.2431640625, "val_acc": 40.0}
{"epoch": 7, "training_loss": 4328.3353515625, "training_acc": 50.0, "val_loss": 796.2196044921875, "val_acc": 60.0}
{"epoch": 8, "training_loss": 1343.86767578125, "training_acc": 50.0, "val_loss": 2068.842529296875, "val_acc": 60.0}
{"epoch": 9, "training_loss": 2021.0878479003907, "training_acc": 50.0, "val_loss": 490.92724609375, "val_acc": 40.0}
{"epoch": 10, "training_loss": 645.7776123046875, "training_acc": 50.0, "val_loss": 1038.1434326171875, "val_acc": 60.0}
{"epoch": 11, "training_loss": 937.9409912109375, "training_acc": 60.0, "val_loss": 2333.37939453125, "val_acc": 40.0}
{"epoch": 12, "training_loss": 1743.134619140625, "training_acc": 50.0, "val_loss": 2337.657958984375, "val_acc": 60.0}
{"epoch": 13, "training_loss": 3163.69541015625, "training_acc": 50.0, "val_loss": 1487.066650390625, "val_acc": 60.0}
{"epoch": 14, "training_loss": 1801.81376953125, "training_acc": 50.0, "val_loss": 4630.63720703125, "val_acc": 40.0}
{"epoch": 15, "training_loss": 3823.0812255859373, "training_acc": 50.0, "val_loss": 1041.8157958984375, "val_acc": 40.0}
{"epoch": 16, "training_loss": 884.774462890625, "training_acc": 60.0, "val_loss": 4004.475341796875, "val_acc": 60.0}
{"epoch": 17, "training_loss": 4825.251953125, "training_acc": 50.0, "val_loss": 2015.2059326171875, "val_acc": 60.0}
{"epoch": 18, "training_loss": 2242.178564453125, "training_acc": 50.0, "val_loss": 3969.346435546875, "val_acc": 40.0}
{"epoch": 19, "training_loss": 3249.9080078125, "training_acc": 50.0, "val_loss": 60.26161575317383, "val_acc": 80.0}
{"epoch": 20, "training_loss": 1331.0890533447266, "training_acc": 65.0, "val_loss": 1657.4383544921875, "val_acc": 60.0}
{"epoch": 21, "training_loss": 1377.7342590332032, "training_acc": 60.0, "val_loss": 3048.41845703125, "val_acc": 40.0}
{"epoch": 22, "training_loss": 2509.1835205078123, "training_acc": 50.0, "val_loss": 501.3020935058594, "val_acc": 60.0}
{"epoch": 23, "training_loss": 484.656689453125, "training_acc": 50.0, "val_loss": 1027.050048828125, "val_acc": 40.0}
{"epoch": 24, "training_loss": 888.672021484375, "training_acc": 50.0, "val_loss": 1998.194580078125, "val_acc": 60.0}
{"epoch": 25, "training_loss": 2352.959912109375, "training_acc": 50.0, "val_loss": 2071.461181640625, "val_acc": 60.0}
{"epoch": 26, "training_loss": 1675.0186706542968, "training_acc": 50.0, "val_loss": 5732.125, "val_acc": 40.0}
{"epoch": 27, "training_loss": 4881.21640625, "training_acc": 50.0, "val_loss": 10420.9677734375, "val_acc": 40.0}
{"epoch": 28, "training_loss": 8753.418359375, "training_acc": 50.0, "val_loss": 6956.64208984375, "val_acc": 40.0}
{"epoch": 29, "training_loss": 5495.154760742187, "training_acc": 50.0, "val_loss": 3059.325439453125, "val_acc": 60.0}
{"epoch": 30, "training_loss": 3814.348046875, "training_acc": 50.0, "val_loss": 5721.1865234375, "val_acc": 60.0}
{"epoch": 31, "training_loss": 6662.0857421875, "training_acc": 50.0, "val_loss": 2215.021240234375, "val_acc": 60.0}
{"epoch": 32, "training_loss": 2984.46982421875, "training_acc": 40.0, "val_loss": 4611.23095703125, "val_acc": 40.0}
{"epoch": 33, "training_loss": 3810.4955078125, "training_acc": 50.0, "val_loss": 44.7003059387207, "val_acc": 80.0}
{"epoch": 34, "training_loss": 1200.330078125, "training_acc": 70.0, "val_loss": 3485.940185546875, "val_acc": 60.0}
{"epoch": 35, "training_loss": 3880.4252197265623, "training_acc": 50.0, "val_loss": 261.5592346191406, "val_acc": 40.0}
{"epoch": 36, "training_loss": 436.4160400390625, "training_acc": 50.0, "val_loss": 684.0598754882812, "val_acc": 60.0}
{"epoch": 37, "training_loss": 482.99085693359376, "training_acc": 50.0, "val_loss": 3183.418701171875, "val_acc": 40.0}
{"epoch": 38, "training_loss": 2865.2510986328125, "training_acc": 50.0, "val_loss": 3566.181640625, "val_acc": 40.0}
{"epoch": 39, "training_loss": 2435.14755859375, "training_acc": 50.0, "val_loss": 3239.383056640625, "val_acc": 60.0}
{"epoch": 40, "training_loss": 3982.024462890625, "training_acc": 50.0, "val_loss": 5773.96240234375, "val_acc": 60.0}
{"epoch": 41, "training_loss": 6731.115625, "training_acc": 50.0, "val_loss": 2272.998046875, "val_acc": 60.0}
{"epoch": 42, "training_loss": 2938.066015625, "training_acc": 40.0, "val_loss": 4401.1396484375, "val_acc": 40.0}
{"epoch": 43, "training_loss": 3755.488671875, "training_acc": 50.0, "val_loss": 62.98772048950195, "val_acc": 80.0}
{"epoch": 44, "training_loss": 1617.0435180664062, "training_acc": 60.0, "val_loss": 2908.691162109375, "val_acc": 60.0}
{"epoch": 45, "training_loss": 2571.40634765625, "training_acc": 50.0, "val_loss": 4507.45654296875, "val_acc": 40.0}
{"epoch": 46, "training_loss": 4538.11474609375, "training_acc": 50.0, "val_loss": 9244.52734375, "val_acc": 40.0}
{"epoch": 47, "training_loss": 7559.3806640625, "training_acc": 50.0, "val_loss": 3969.55712890625, "val_acc": 40.0}
{"epoch": 48, "training_loss": 2539.965124511719, "training_acc": 60.0, "val_loss": 3354.77392578125, "val_acc": 60.0}
{"epoch": 49, "training_loss": 4031.13779296875, "training_acc": 50.0, "val_loss": 2958.552001953125, "val_acc": 60.0}
{"epoch": 50, "training_loss": 2494.3747375488283, "training_acc": 50.0, "val_loss": 5598.69580078125, "val_acc": 40.0}
{"epoch": 51, "training_loss": 5453.89931640625, "training_acc": 50.0, "val_loss": 10213.4755859375, "val_acc": 40.0}
{"epoch": 52, "training_loss": 8488.52763671875, "training_acc": 50.0, "val_loss": 4779.4228515625, "val_acc": 40.0}
