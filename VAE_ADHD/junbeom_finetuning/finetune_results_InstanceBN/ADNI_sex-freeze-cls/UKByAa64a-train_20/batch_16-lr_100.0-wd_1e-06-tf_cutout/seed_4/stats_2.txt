"main_modify.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 4 --task ADNI_sex --input_option yAware --learning_rate 1e2 --batch_size 16 --weight_decay 1e-6 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 8554.436663866043, "training_acc": 30.0, "val_loss": 6190.11279296875, "val_acc": 60.0}
{"epoch": 1, "training_loss": 9397.5705078125, "training_acc": 40.0, "val_loss": 14686.328125, "val_acc": 40.0}
{"epoch": 2, "training_loss": 12111.3548828125, "training_acc": 50.0, "val_loss": 8839.8125, "val_acc": 40.0}
{"epoch": 3, "training_loss": 5432.998803710938, "training_acc": 50.0, "val_loss": 6985.51416015625, "val_acc": 60.0}
{"epoch": 4, "training_loss": 10464.786328125, "training_acc": 50.0, "val_loss": 12317.2724609375, "val_acc": 60.0}
{"epoch": 5, "training_loss": 15174.27109375, "training_acc": 50.0, "val_loss": 8159.01806640625, "val_acc": 60.0}
{"epoch": 6, "training_loss": 9142.51796875, "training_acc": 50.0, "val_loss": 2213.538818359375, "val_acc": 40.0}
{"epoch": 7, "training_loss": 2174.323388671875, "training_acc": 50.0, "val_loss": 8683.439453125, "val_acc": 40.0}
{"epoch": 8, "training_loss": 7116.6234375, "training_acc": 50.0, "val_loss": 4780.41796875, "val_acc": 40.0}
{"epoch": 9, "training_loss": 4420.2482421875, "training_acc": 30.0, "val_loss": 1088.6878662109375, "val_acc": 60.0}
{"epoch": 10, "training_loss": 1392.3291259765624, "training_acc": 40.0, "val_loss": 324.2919616699219, "val_acc": 60.0}
{"epoch": 11, "training_loss": 394.0078125, "training_acc": 50.0, "val_loss": 436.28179931640625, "val_acc": 60.0}
{"epoch": 12, "training_loss": 462.7940673828125, "training_acc": 50.0, "val_loss": 529.9743041992188, "val_acc": 60.0}
{"epoch": 13, "training_loss": 700.5904418945313, "training_acc": 40.0, "val_loss": 989.3751831054688, "val_acc": 60.0}
{"epoch": 14, "training_loss": 1118.4634216308593, "training_acc": 50.0, "val_loss": 880.2473754882812, "val_acc": 40.0}
{"epoch": 15, "training_loss": 620.2429077148438, "training_acc": 50.0, "val_loss": 2267.49560546875, "val_acc": 60.0}
{"epoch": 16, "training_loss": 2942.11884765625, "training_acc": 50.0, "val_loss": 2234.10400390625, "val_acc": 60.0}
{"epoch": 17, "training_loss": 2174.9693283081056, "training_acc": 50.0, "val_loss": 788.10107421875, "val_acc": 40.0}
{"epoch": 18, "training_loss": 480.62583618164064, "training_acc": 60.0, "val_loss": 375.0801696777344, "val_acc": 60.0}
{"epoch": 19, "training_loss": 559.4060302734375, "training_acc": 50.0, "val_loss": 1448.4827880859375, "val_acc": 40.0}
{"epoch": 20, "training_loss": 1382.456884765625, "training_acc": 40.0, "val_loss": 319.378173828125, "val_acc": 60.0}
{"epoch": 21, "training_loss": 979.6971923828125, "training_acc": 40.0, "val_loss": 2507.18408203125, "val_acc": 40.0}
{"epoch": 22, "training_loss": 1673.665060043335, "training_acc": 55.0, "val_loss": 888.2646484375, "val_acc": 60.0}
{"epoch": 23, "training_loss": 805.3141792297363, "training_acc": 55.0, "val_loss": 2051.671142578125, "val_acc": 40.0}
{"epoch": 24, "training_loss": 1693.163671875, "training_acc": 50.0, "val_loss": 947.5502319335938, "val_acc": 60.0}
{"epoch": 25, "training_loss": 1328.20732421875, "training_acc": 50.0, "val_loss": 58.9658203125, "val_acc": 60.0}
{"epoch": 26, "training_loss": 227.79484224319458, "training_acc": 85.0, "val_loss": 4065.379638671875, "val_acc": 40.0}
{"epoch": 27, "training_loss": 3188.460546875, "training_acc": 50.0, "val_loss": 211.5826416015625, "val_acc": 60.0}
{"epoch": 28, "training_loss": 262.1380859375, "training_acc": 50.0, "val_loss": 770.1467895507812, "val_acc": 40.0}
{"epoch": 29, "training_loss": 564.3823516845703, "training_acc": 40.0, "val_loss": 2253.282958984375, "val_acc": 40.0}
{"epoch": 30, "training_loss": 1835.729931640625, "training_acc": 50.0, "val_loss": 78.43596649169922, "val_acc": 60.0}
{"epoch": 31, "training_loss": 513.6159880638122, "training_acc": 70.0, "val_loss": 1434.6356201171875, "val_acc": 40.0}
{"epoch": 32, "training_loss": 1202.01376953125, "training_acc": 50.0, "val_loss": 790.7077026367188, "val_acc": 40.0}
{"epoch": 33, "training_loss": 585.8134155273438, "training_acc": 60.0, "val_loss": 2302.059814453125, "val_acc": 60.0}
{"epoch": 34, "training_loss": 2521.3658203125, "training_acc": 50.0, "val_loss": 1474.7626953125, "val_acc": 40.0}
{"epoch": 35, "training_loss": 1291.46708984375, "training_acc": 50.0, "val_loss": 2483.290771484375, "val_acc": 40.0}
{"epoch": 36, "training_loss": 1617.2978492736815, "training_acc": 50.0, "val_loss": 3008.612548828125, "val_acc": 60.0}
{"epoch": 37, "training_loss": 3858.5689453125, "training_acc": 50.0, "val_loss": 3679.553955078125, "val_acc": 60.0}
{"epoch": 38, "training_loss": 3726.747021484375, "training_acc": 50.0, "val_loss": 3162.371826171875, "val_acc": 40.0}
{"epoch": 39, "training_loss": 3447.31748046875, "training_acc": 50.0, "val_loss": 5978.41162109375, "val_acc": 40.0}
{"epoch": 40, "training_loss": 4693.4205078125, "training_acc": 50.0, "val_loss": 683.759765625, "val_acc": 60.0}
{"epoch": 41, "training_loss": 834.989404296875, "training_acc": 50.0, "val_loss": 660.0231323242188, "val_acc": 60.0}
{"epoch": 42, "training_loss": 906.76064453125, "training_acc": 50.0, "val_loss": 3241.602294921875, "val_acc": 40.0}
{"epoch": 43, "training_loss": 2417.528515625, "training_acc": 50.0, "val_loss": 1493.0516357421875, "val_acc": 60.0}
{"epoch": 44, "training_loss": 1982.18349609375, "training_acc": 50.0, "val_loss": 912.0720825195312, "val_acc": 60.0}
