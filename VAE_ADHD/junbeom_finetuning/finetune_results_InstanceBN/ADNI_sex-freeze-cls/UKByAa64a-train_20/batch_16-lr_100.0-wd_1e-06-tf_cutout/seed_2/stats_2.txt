"main_modify.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 2 --task ADNI_sex --input_option yAware --learning_rate 1e2 --batch_size 16 --weight_decay 1e-6 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 6421.984368610382, "training_acc": 40.0, "val_loss": 7629.95947265625, "val_acc": 60.0}
{"epoch": 1, "training_loss": 8745.67392578125, "training_acc": 50.0, "val_loss": 12635.2607421875, "val_acc": 40.0}
{"epoch": 2, "training_loss": 10257.1923828125, "training_acc": 50.0, "val_loss": 4686.66943359375, "val_acc": 40.0}
{"epoch": 3, "training_loss": 4010.679296875, "training_acc": 50.0, "val_loss": 6156.4423828125, "val_acc": 60.0}
{"epoch": 4, "training_loss": 7557.19375, "training_acc": 50.0, "val_loss": 2553.4775390625, "val_acc": 60.0}
{"epoch": 5, "training_loss": 3180.48818359375, "training_acc": 50.0, "val_loss": 6770.8408203125, "val_acc": 40.0}
{"epoch": 6, "training_loss": 5616.743359375, "training_acc": 50.0, "val_loss": 3752.862548828125, "val_acc": 40.0}
{"epoch": 7, "training_loss": 3064.37802734375, "training_acc": 40.0, "val_loss": 442.16748046875, "val_acc": 60.0}
{"epoch": 8, "training_loss": 1243.91083984375, "training_acc": 40.0, "val_loss": 1959.8623046875, "val_acc": 40.0}
{"epoch": 9, "training_loss": 1565.77841796875, "training_acc": 50.0, "val_loss": 1492.734375, "val_acc": 60.0}
{"epoch": 10, "training_loss": 1504.6044155120849, "training_acc": 50.0, "val_loss": 4598.58056640625, "val_acc": 40.0}
{"epoch": 11, "training_loss": 4253.61513671875, "training_acc": 50.0, "val_loss": 4175.57568359375, "val_acc": 40.0}
{"epoch": 12, "training_loss": 2816.8261657714843, "training_acc": 50.0, "val_loss": 1277.1368408203125, "val_acc": 60.0}
{"epoch": 13, "training_loss": 1608.697265625, "training_acc": 50.0, "val_loss": 1440.0213623046875, "val_acc": 40.0}
{"epoch": 14, "training_loss": 979.5924194335937, "training_acc": 50.0, "val_loss": 2068.35888671875, "val_acc": 60.0}
{"epoch": 15, "training_loss": 2619.549853515625, "training_acc": 50.0, "val_loss": 1606.487548828125, "val_acc": 60.0}
{"epoch": 16, "training_loss": 2121.8029296875, "training_acc": 40.0, "val_loss": 849.36328125, "val_acc": 40.0}
{"epoch": 17, "training_loss": 1157.14169921875, "training_acc": 40.0, "val_loss": 903.7178955078125, "val_acc": 60.0}
{"epoch": 18, "training_loss": 1193.9224365234375, "training_acc": 50.0, "val_loss": 2239.437255859375, "val_acc": 40.0}
{"epoch": 19, "training_loss": 1926.8762939453125, "training_acc": 30.0, "val_loss": 2044.9774169921875, "val_acc": 40.0}
{"epoch": 20, "training_loss": 1710.80810546875, "training_acc": 50.0, "val_loss": 744.2976684570312, "val_acc": 60.0}
{"epoch": 21, "training_loss": 1054.8631103515625, "training_acc": 50.0, "val_loss": 92.88277435302734, "val_acc": 60.0}
{"epoch": 22, "training_loss": 1063.2670104980468, "training_acc": 40.0, "val_loss": 4134.82275390625, "val_acc": 40.0}
{"epoch": 23, "training_loss": 3048.2791015625, "training_acc": 50.0, "val_loss": 1376.7083740234375, "val_acc": 60.0}
{"epoch": 24, "training_loss": 2177.75859375, "training_acc": 50.0, "val_loss": 1305.5701904296875, "val_acc": 60.0}
{"epoch": 25, "training_loss": 1275.3306274414062, "training_acc": 60.0, "val_loss": 3843.493896484375, "val_acc": 40.0}
{"epoch": 26, "training_loss": 3118.28544921875, "training_acc": 50.0, "val_loss": 288.792236328125, "val_acc": 40.0}
{"epoch": 27, "training_loss": 536.4226318359375, "training_acc": 60.0, "val_loss": 5545.81494140625, "val_acc": 60.0}
{"epoch": 28, "training_loss": 7230.7494140625, "training_acc": 50.0, "val_loss": 4665.29443359375, "val_acc": 60.0}
{"epoch": 29, "training_loss": 4775.70029296875, "training_acc": 50.0, "val_loss": 4409.4970703125, "val_acc": 40.0}
{"epoch": 30, "training_loss": 4305.615234375, "training_acc": 50.0, "val_loss": 10155.3984375, "val_acc": 40.0}
{"epoch": 31, "training_loss": 8281.54833984375, "training_acc": 50.0, "val_loss": 6616.11181640625, "val_acc": 40.0}
{"epoch": 32, "training_loss": 4404.62158203125, "training_acc": 50.0, "val_loss": 3006.24755859375, "val_acc": 60.0}
{"epoch": 33, "training_loss": 4453.018359375, "training_acc": 50.0, "val_loss": 6669.76416015625, "val_acc": 60.0}
{"epoch": 34, "training_loss": 8171.967578125, "training_acc": 50.0, "val_loss": 3739.380615234375, "val_acc": 60.0}
{"epoch": 35, "training_loss": 3797.4352294921873, "training_acc": 50.0, "val_loss": 6676.71875, "val_acc": 40.0}
{"epoch": 36, "training_loss": 6184.34921875, "training_acc": 50.0, "val_loss": 12079.9833984375, "val_acc": 40.0}
{"epoch": 37, "training_loss": 9849.1638671875, "training_acc": 50.0, "val_loss": 8163.85693359375, "val_acc": 40.0}
{"epoch": 38, "training_loss": 5647.25224609375, "training_acc": 50.0, "val_loss": 2215.015380859375, "val_acc": 60.0}
{"epoch": 39, "training_loss": 3498.7416015625, "training_acc": 50.0, "val_loss": 6072.08251953125, "val_acc": 60.0}
{"epoch": 40, "training_loss": 7432.175390625, "training_acc": 50.0, "val_loss": 3234.084716796875, "val_acc": 60.0}
