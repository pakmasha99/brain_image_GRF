"main_modify.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 3 --task ADNI_sex --input_option yAware --learning_rate 1e2 --batch_size 16 --weight_decay 1e-6 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 4283.243156242371, "training_acc": 50.0, "val_loss": 9820.548828125, "val_acc": 40.0}
{"epoch": 1, "training_loss": 10000.950390625, "training_acc": 40.0, "val_loss": 7890.2392578125, "val_acc": 60.0}
{"epoch": 2, "training_loss": 9411.017724609375, "training_acc": 50.0, "val_loss": 1079.744873046875, "val_acc": 40.0}
{"epoch": 3, "training_loss": 1301.938427734375, "training_acc": 50.0, "val_loss": 1425.292236328125, "val_acc": 60.0}
{"epoch": 4, "training_loss": 1847.87919921875, "training_acc": 50.0, "val_loss": 1086.3409423828125, "val_acc": 40.0}
{"epoch": 5, "training_loss": 771.6886535644531, "training_acc": 50.0, "val_loss": 2165.126220703125, "val_acc": 60.0}
{"epoch": 6, "training_loss": 2756.98251953125, "training_acc": 50.0, "val_loss": 85.09644317626953, "val_acc": 60.0}
{"epoch": 7, "training_loss": 1622.06474609375, "training_acc": 40.0, "val_loss": 6902.5546875, "val_acc": 40.0}
{"epoch": 8, "training_loss": 5448.53310546875, "training_acc": 50.0, "val_loss": 912.7734375, "val_acc": 40.0}
{"epoch": 9, "training_loss": 872.54775390625, "training_acc": 60.0, "val_loss": 5578.982421875, "val_acc": 60.0}
{"epoch": 10, "training_loss": 7272.57109375, "training_acc": 50.0, "val_loss": 3928.78564453125, "val_acc": 60.0}
{"epoch": 11, "training_loss": 3669.6940063476563, "training_acc": 50.0, "val_loss": 7885.45458984375, "val_acc": 40.0}
{"epoch": 12, "training_loss": 7812.225, "training_acc": 50.0, "val_loss": 14220.1376953125, "val_acc": 40.0}
{"epoch": 13, "training_loss": 11423.652734375, "training_acc": 50.0, "val_loss": 8480.8740234375, "val_acc": 40.0}
{"epoch": 14, "training_loss": 5475.212548828125, "training_acc": 50.0, "val_loss": 4048.42822265625, "val_acc": 60.0}
{"epoch": 15, "training_loss": 5617.21044921875, "training_acc": 50.0, "val_loss": 9787.6591796875, "val_acc": 60.0}
{"epoch": 16, "training_loss": 12596.376953125, "training_acc": 50.0, "val_loss": 8512.80859375, "val_acc": 60.0}
{"epoch": 17, "training_loss": 10309.889111328124, "training_acc": 50.0, "val_loss": 980.5187377929688, "val_acc": 60.0}
{"epoch": 18, "training_loss": 2845.187890625, "training_acc": 40.0, "val_loss": 10102.447265625, "val_acc": 40.0}
{"epoch": 19, "training_loss": 8501.620703125, "training_acc": 50.0, "val_loss": 8711.2568359375, "val_acc": 40.0}
{"epoch": 20, "training_loss": 6615.540063476563, "training_acc": 50.0, "val_loss": 1174.4188232421875, "val_acc": 60.0}
{"epoch": 21, "training_loss": 1841.2394775390626, "training_acc": 50.0, "val_loss": 3453.715576171875, "val_acc": 60.0}
{"epoch": 22, "training_loss": 4216.095751953125, "training_acc": 50.0, "val_loss": 50.30666732788086, "val_acc": 80.0}
{"epoch": 23, "training_loss": 757.7467895507813, "training_acc": 60.0, "val_loss": 6342.4384765625, "val_acc": 40.0}
{"epoch": 24, "training_loss": 4854.42353515625, "training_acc": 50.0, "val_loss": 1695.4039306640625, "val_acc": 40.0}
{"epoch": 25, "training_loss": 1087.4503662109375, "training_acc": 60.0, "val_loss": 5344.5419921875, "val_acc": 60.0}
{"epoch": 26, "training_loss": 7260.2146484375, "training_acc": 50.0, "val_loss": 4834.91552734375, "val_acc": 60.0}
{"epoch": 27, "training_loss": 5474.422265625, "training_acc": 50.0, "val_loss": 3509.603271484375, "val_acc": 40.0}
{"epoch": 28, "training_loss": 2793.076025390625, "training_acc": 50.0, "val_loss": 8161.13232421875, "val_acc": 40.0}
{"epoch": 29, "training_loss": 6292.0978515625, "training_acc": 50.0, "val_loss": 2611.3505859375, "val_acc": 40.0}
{"epoch": 30, "training_loss": 1636.1881103515625, "training_acc": 60.0, "val_loss": 5887.20849609375, "val_acc": 60.0}
{"epoch": 31, "training_loss": 8137.3544921875, "training_acc": 50.0, "val_loss": 6392.23828125, "val_acc": 60.0}
{"epoch": 32, "training_loss": 7540.48876953125, "training_acc": 50.0, "val_loss": 33.49018859863281, "val_acc": 60.0}
{"epoch": 33, "training_loss": 1754.21748046875, "training_acc": 55.0, "val_loss": 9606.025390625, "val_acc": 40.0}
{"epoch": 34, "training_loss": 7605.778515625, "training_acc": 50.0, "val_loss": 7324.99169921875, "val_acc": 40.0}
{"epoch": 35, "training_loss": 4603.79853515625, "training_acc": 50.0, "val_loss": 2655.167724609375, "val_acc": 60.0}
{"epoch": 36, "training_loss": 4232.85859375, "training_acc": 50.0, "val_loss": 6413.28076171875, "val_acc": 60.0}
{"epoch": 37, "training_loss": 8045.949609375, "training_acc": 50.0, "val_loss": 3392.757080078125, "val_acc": 60.0}
{"epoch": 38, "training_loss": 3187.8263671875, "training_acc": 55.0, "val_loss": 6878.6220703125, "val_acc": 40.0}
{"epoch": 39, "training_loss": 6385.427734375, "training_acc": 50.0, "val_loss": 11372.91796875, "val_acc": 40.0}
{"epoch": 40, "training_loss": 8529.8095703125, "training_acc": 50.0, "val_loss": 4237.00927734375, "val_acc": 40.0}
{"epoch": 41, "training_loss": 2968.10556640625, "training_acc": 50.0, "val_loss": 4420.8212890625, "val_acc": 60.0}
{"epoch": 42, "training_loss": 5978.818359375, "training_acc": 50.0, "val_loss": 4393.2314453125, "val_acc": 60.0}
{"epoch": 43, "training_loss": 4909.45029296875, "training_acc": 50.0, "val_loss": 2843.4130859375, "val_acc": 40.0}
{"epoch": 44, "training_loss": 2107.99638671875, "training_acc": 50.0, "val_loss": 7637.58544921875, "val_acc": 40.0}
{"epoch": 45, "training_loss": 5691.1552734375, "training_acc": 50.0, "val_loss": 3533.85986328125, "val_acc": 40.0}
{"epoch": 46, "training_loss": 2141.09677734375, "training_acc": 50.0, "val_loss": 2504.400390625, "val_acc": 60.0}
{"epoch": 47, "training_loss": 3362.92421875, "training_acc": 50.0, "val_loss": 126.77042388916016, "val_acc": 60.0}
{"epoch": 48, "training_loss": 981.55087890625, "training_acc": 55.0, "val_loss": 7161.7470703125, "val_acc": 40.0}
{"epoch": 49, "training_loss": 5417.4005859375, "training_acc": 50.0, "val_loss": 4330.5576171875, "val_acc": 40.0}
{"epoch": 50, "training_loss": 3029.9888427734377, "training_acc": 40.0, "val_loss": 838.0023803710938, "val_acc": 60.0}
{"epoch": 51, "training_loss": 1180.521388244629, "training_acc": 50.0, "val_loss": 3047.13330078125, "val_acc": 40.0}
