"main_modify.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_sex --input_option yAware --learning_rate 1e2 --batch_size 16 --weight_decay 1e-6 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 6400.296457624436, "training_acc": 40.0, "val_loss": 8066.33349609375, "val_acc": 40.0}
{"epoch": 1, "training_loss": 9198.81640625, "training_acc": 40.0, "val_loss": 11053.701171875, "val_acc": 60.0}
{"epoch": 2, "training_loss": 13360.8765625, "training_acc": 50.0, "val_loss": 4575.6767578125, "val_acc": 60.0}
{"epoch": 3, "training_loss": 4286.2071533203125, "training_acc": 60.0, "val_loss": 10542.96875, "val_acc": 40.0}
{"epoch": 4, "training_loss": 9452.6796875, "training_acc": 50.0, "val_loss": 10061.1279296875, "val_acc": 40.0}
{"epoch": 5, "training_loss": 7858.319555664062, "training_acc": 50.0, "val_loss": 2383.8779296875, "val_acc": 60.0}
{"epoch": 6, "training_loss": 3497.3828125, "training_acc": 50.0, "val_loss": 4344.0576171875, "val_acc": 60.0}
{"epoch": 7, "training_loss": 5103.2884521484375, "training_acc": 50.0, "val_loss": 1766.712158203125, "val_acc": 40.0}
{"epoch": 8, "training_loss": 1685.33525390625, "training_acc": 50.0, "val_loss": 1229.427001953125, "val_acc": 40.0}
{"epoch": 9, "training_loss": 962.6299072265625, "training_acc": 60.0, "val_loss": 3384.160888671875, "val_acc": 60.0}
{"epoch": 10, "training_loss": 4084.37236328125, "training_acc": 50.0, "val_loss": 968.4177856445312, "val_acc": 60.0}
{"epoch": 11, "training_loss": 1516.2869140625, "training_acc": 50.0, "val_loss": 5152.48828125, "val_acc": 40.0}
{"epoch": 12, "training_loss": 4182.973852539062, "training_acc": 50.0, "val_loss": 735.8561401367188, "val_acc": 40.0}
{"epoch": 13, "training_loss": 1255.697119140625, "training_acc": 50.0, "val_loss": 4327.77978515625, "val_acc": 60.0}
{"epoch": 14, "training_loss": 5158.21298828125, "training_acc": 50.0, "val_loss": 1380.6712646484375, "val_acc": 60.0}
{"epoch": 15, "training_loss": 2478.94716796875, "training_acc": 40.0, "val_loss": 5495.45751953125, "val_acc": 40.0}
{"epoch": 16, "training_loss": 4369.16533203125, "training_acc": 50.0, "val_loss": 47.0183219909668, "val_acc": 60.0}
{"epoch": 17, "training_loss": 577.9134979248047, "training_acc": 70.0, "val_loss": 2890.9814453125, "val_acc": 60.0}
{"epoch": 18, "training_loss": 3299.413708496094, "training_acc": 50.0, "val_loss": 1263.7874755859375, "val_acc": 40.0}
{"epoch": 19, "training_loss": 1301.243359375, "training_acc": 50.0, "val_loss": 717.6008911132812, "val_acc": 60.0}
{"epoch": 20, "training_loss": 799.0591430664062, "training_acc": 50.0, "val_loss": 885.7447509765625, "val_acc": 40.0}
{"epoch": 21, "training_loss": 693.933447265625, "training_acc": 50.0, "val_loss": 1677.7750244140625, "val_acc": 60.0}
{"epoch": 22, "training_loss": 1923.1530883789062, "training_acc": 50.0, "val_loss": 583.8933715820312, "val_acc": 60.0}
{"epoch": 23, "training_loss": 626.2656494140625, "training_acc": 60.0, "val_loss": 4543.24365234375, "val_acc": 40.0}
{"epoch": 24, "training_loss": 3722.7366943359375, "training_acc": 50.0, "val_loss": 1054.99755859375, "val_acc": 40.0}
{"epoch": 25, "training_loss": 918.7787841796875, "training_acc": 60.0, "val_loss": 3955.97265625, "val_acc": 60.0}
{"epoch": 26, "training_loss": 4722.086328125, "training_acc": 50.0, "val_loss": 1974.2308349609375, "val_acc": 60.0}
{"epoch": 27, "training_loss": 2182.221826171875, "training_acc": 50.0, "val_loss": 4049.109375, "val_acc": 40.0}
{"epoch": 28, "training_loss": 3272.3265625, "training_acc": 50.0, "val_loss": 19.6820125579834, "val_acc": 60.0}
{"epoch": 29, "training_loss": 364.0343963623047, "training_acc": 75.0, "val_loss": 4628.50341796875, "val_acc": 60.0}
{"epoch": 30, "training_loss": 5572.2037109375, "training_acc": 50.0, "val_loss": 2072.43798828125, "val_acc": 60.0}
{"epoch": 31, "training_loss": 1866.115966796875, "training_acc": 60.0, "val_loss": 6481.9755859375, "val_acc": 40.0}
{"epoch": 32, "training_loss": 5631.32734375, "training_acc": 50.0, "val_loss": 5566.36474609375, "val_acc": 40.0}
{"epoch": 33, "training_loss": 3500.727783203125, "training_acc": 50.0, "val_loss": 4163.53857421875, "val_acc": 60.0}
{"epoch": 34, "training_loss": 5769.674609375, "training_acc": 50.0, "val_loss": 8657.810546875, "val_acc": 60.0}
{"epoch": 35, "training_loss": 10403.1671875, "training_acc": 50.0, "val_loss": 5359.18212890625, "val_acc": 60.0}
{"epoch": 36, "training_loss": 5362.9365234375, "training_acc": 50.0, "val_loss": 6659.73046875, "val_acc": 40.0}
{"epoch": 37, "training_loss": 6076.8517578125, "training_acc": 50.0, "val_loss": 14210.7841796875, "val_acc": 40.0}
{"epoch": 38, "training_loss": 12029.97734375, "training_acc": 50.0, "val_loss": 11138.439453125, "val_acc": 40.0}
{"epoch": 39, "training_loss": 8018.437109375, "training_acc": 50.0, "val_loss": 1745.7996826171875, "val_acc": 60.0}
{"epoch": 40, "training_loss": 2760.97265625, "training_acc": 50.0, "val_loss": 6625.82177734375, "val_acc": 60.0}
{"epoch": 41, "training_loss": 7867.12021484375, "training_acc": 50.0, "val_loss": 4182.34716796875, "val_acc": 60.0}
{"epoch": 42, "training_loss": 3684.977001953125, "training_acc": 50.0, "val_loss": 6752.45068359375, "val_acc": 40.0}
{"epoch": 43, "training_loss": 6574.714453125, "training_acc": 50.0, "val_loss": 13482.6435546875, "val_acc": 40.0}
{"epoch": 44, "training_loss": 11235.9193359375, "training_acc": 50.0, "val_loss": 9390.59375, "val_acc": 40.0}
{"epoch": 45, "training_loss": 6333.2875, "training_acc": 50.0, "val_loss": 3027.126953125, "val_acc": 60.0}
{"epoch": 46, "training_loss": 4417.525, "training_acc": 50.0, "val_loss": 8793.8466796875, "val_acc": 60.0}
{"epoch": 47, "training_loss": 10701.14140625, "training_acc": 50.0, "val_loss": 6758.85888671875, "val_acc": 60.0}
