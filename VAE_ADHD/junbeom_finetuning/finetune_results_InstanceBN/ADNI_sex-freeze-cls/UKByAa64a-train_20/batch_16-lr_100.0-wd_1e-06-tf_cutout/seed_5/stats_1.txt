"main_modify.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 5 --task ADNI_sex --input_option yAware --learning_rate 1e2 --batch_size 16 --weight_decay 1e-6 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 4277.854283285141, "training_acc": 45.0, "val_loss": 9351.6435546875, "val_acc": 40.0}
{"epoch": 1, "training_loss": 5569.23583984375, "training_acc": 65.0, "val_loss": 13430.9912109375, "val_acc": 60.0}
{"epoch": 2, "training_loss": 18141.32060546875, "training_acc": 45.0, "val_loss": 6782.27099609375, "val_acc": 60.0}
{"epoch": 3, "training_loss": 6836.486590576172, "training_acc": 55.0, "val_loss": 7399.3837890625, "val_acc": 40.0}
{"epoch": 4, "training_loss": 5572.013037109375, "training_acc": 55.0, "val_loss": 5180.42138671875, "val_acc": 40.0}
{"epoch": 5, "training_loss": 2642.046221923828, "training_acc": 65.0, "val_loss": 2035.1209716796875, "val_acc": 60.0}
{"epoch": 6, "training_loss": 2533.021676635742, "training_acc": 35.0, "val_loss": 2022.872314453125, "val_acc": 60.0}
{"epoch": 7, "training_loss": 2511.6662841796874, "training_acc": 45.0, "val_loss": 2963.021484375, "val_acc": 40.0}
{"epoch": 8, "training_loss": 2283.914501953125, "training_acc": 55.0, "val_loss": 2587.091064453125, "val_acc": 40.0}
{"epoch": 9, "training_loss": 1716.565087890625, "training_acc": 55.0, "val_loss": 929.2686767578125, "val_acc": 60.0}
{"epoch": 10, "training_loss": 1041.2567260742187, "training_acc": 55.0, "val_loss": 2787.968017578125, "val_acc": 40.0}
{"epoch": 11, "training_loss": 1774.41015625, "training_acc": 55.0, "val_loss": 3202.039306640625, "val_acc": 60.0}
{"epoch": 12, "training_loss": 4789.9298828125, "training_acc": 45.0, "val_loss": 4652.88037109375, "val_acc": 60.0}
{"epoch": 13, "training_loss": 5535.66552734375, "training_acc": 45.0, "val_loss": 3199.326904296875, "val_acc": 40.0}
{"epoch": 14, "training_loss": 2392.4732421875, "training_acc": 55.0, "val_loss": 9180.119140625, "val_acc": 40.0}
{"epoch": 15, "training_loss": 6862.735302734375, "training_acc": 55.0, "val_loss": 7482.94140625, "val_acc": 40.0}
{"epoch": 16, "training_loss": 5267.125146484375, "training_acc": 55.0, "val_loss": 1121.6082763671875, "val_acc": 60.0}
{"epoch": 17, "training_loss": 1725.5693359375, "training_acc": 45.0, "val_loss": 1180.2467041015625, "val_acc": 60.0}
{"epoch": 18, "training_loss": 2109.0265625, "training_acc": 35.0, "val_loss": 2889.579345703125, "val_acc": 40.0}
{"epoch": 19, "training_loss": 1677.79716796875, "training_acc": 55.0, "val_loss": 3014.295654296875, "val_acc": 60.0}
{"epoch": 20, "training_loss": 4693.6279296875, "training_acc": 45.0, "val_loss": 3484.4375, "val_acc": 60.0}
{"epoch": 21, "training_loss": 3965.881970214844, "training_acc": 45.0, "val_loss": 5583.17578125, "val_acc": 40.0}
{"epoch": 22, "training_loss": 5607.3283203125, "training_acc": 55.0, "val_loss": 8620.4638671875, "val_acc": 40.0}
{"epoch": 23, "training_loss": 6168.675341796875, "training_acc": 55.0, "val_loss": 547.1824951171875, "val_acc": 40.0}
{"epoch": 24, "training_loss": 2442.023779296875, "training_acc": 35.0, "val_loss": 4916.75537109375, "val_acc": 60.0}
{"epoch": 25, "training_loss": 6406.226953125, "training_acc": 45.0, "val_loss": 1144.7042236328125, "val_acc": 60.0}
{"epoch": 26, "training_loss": 1975.12705078125, "training_acc": 45.0, "val_loss": 7662.125, "val_acc": 40.0}
{"epoch": 27, "training_loss": 6209.9126953125, "training_acc": 55.0, "val_loss": 5545.84619140625, "val_acc": 40.0}
{"epoch": 28, "training_loss": 3700.116796875, "training_acc": 60.0, "val_loss": 3280.7421875, "val_acc": 60.0}
{"epoch": 29, "training_loss": 4721.009375, "training_acc": 45.0, "val_loss": 4005.290771484375, "val_acc": 60.0}
{"epoch": 30, "training_loss": 4660.90244140625, "training_acc": 45.0, "val_loss": 3250.376708984375, "val_acc": 40.0}
{"epoch": 31, "training_loss": 3024.0408203125, "training_acc": 55.0, "val_loss": 7697.3125, "val_acc": 40.0}
{"epoch": 32, "training_loss": 5535.9939453125, "training_acc": 55.0, "val_loss": 2796.30712890625, "val_acc": 40.0}
{"epoch": 33, "training_loss": 2005.6368896484375, "training_acc": 55.0, "val_loss": 3195.46484375, "val_acc": 60.0}
{"epoch": 34, "training_loss": 4221.062109375, "training_acc": 45.0, "val_loss": 889.6265869140625, "val_acc": 60.0}
{"epoch": 35, "training_loss": 2064.89873046875, "training_acc": 35.0, "val_loss": 5513.72412109375, "val_acc": 40.0}
{"epoch": 36, "training_loss": 4007.233740234375, "training_acc": 55.0, "val_loss": 1582.000244140625, "val_acc": 40.0}
{"epoch": 37, "training_loss": 626.936328125, "training_acc": 75.0, "val_loss": 4339.3955078125, "val_acc": 60.0}
{"epoch": 38, "training_loss": 6330.772265625, "training_acc": 45.0, "val_loss": 2940.79345703125, "val_acc": 60.0}
{"epoch": 39, "training_loss": 3962.185400390625, "training_acc": 35.0, "val_loss": 3448.1875, "val_acc": 40.0}
{"epoch": 40, "training_loss": 2526.437890625, "training_acc": 55.0, "val_loss": 1047.5692138671875, "val_acc": 40.0}
{"epoch": 41, "training_loss": 964.243408203125, "training_acc": 55.0, "val_loss": 2249.900146484375, "val_acc": 60.0}
{"epoch": 42, "training_loss": 2693.6780517578127, "training_acc": 45.0, "val_loss": 2338.95556640625, "val_acc": 40.0}
