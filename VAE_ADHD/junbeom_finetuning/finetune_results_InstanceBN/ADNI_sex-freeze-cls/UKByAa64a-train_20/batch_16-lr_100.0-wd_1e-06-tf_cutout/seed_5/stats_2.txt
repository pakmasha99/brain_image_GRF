"main_modify.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 5 --task ADNI_sex --input_option yAware --learning_rate 1e2 --batch_size 16 --weight_decay 1e-6 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 6411.698546695709, "training_acc": 40.0, "val_loss": 5889.72509765625, "val_acc": 60.0}
{"epoch": 1, "training_loss": 7727.49453125, "training_acc": 50.0, "val_loss": 18098.25390625, "val_acc": 40.0}
{"epoch": 2, "training_loss": 14947.0904296875, "training_acc": 50.0, "val_loss": 11456.0888671875, "val_acc": 40.0}
{"epoch": 3, "training_loss": 7246.23154296875, "training_acc": 50.0, "val_loss": 7317.8134765625, "val_acc": 60.0}
{"epoch": 4, "training_loss": 10378.2607421875, "training_acc": 50.0, "val_loss": 13838.509765625, "val_acc": 60.0}
{"epoch": 5, "training_loss": 17110.432421875, "training_acc": 50.0, "val_loss": 9856.7431640625, "val_acc": 60.0}
{"epoch": 6, "training_loss": 10620.2734375, "training_acc": 50.0, "val_loss": 2507.541748046875, "val_acc": 40.0}
{"epoch": 7, "training_loss": 2534.922412109375, "training_acc": 50.0, "val_loss": 11896.203125, "val_acc": 40.0}
{"epoch": 8, "training_loss": 10046.53203125, "training_acc": 50.0, "val_loss": 8936.8779296875, "val_acc": 40.0}
{"epoch": 9, "training_loss": 6413.050048828125, "training_acc": 50.0, "val_loss": 3379.714599609375, "val_acc": 60.0}
{"epoch": 10, "training_loss": 4560.097802734375, "training_acc": 50.0, "val_loss": 7685.56787109375, "val_acc": 60.0}
{"epoch": 11, "training_loss": 9529.809765625, "training_acc": 50.0, "val_loss": 5650.88720703125, "val_acc": 60.0}
{"epoch": 12, "training_loss": 6291.01015625, "training_acc": 50.0, "val_loss": 2823.577880859375, "val_acc": 40.0}
{"epoch": 13, "training_loss": 2584.8751953125, "training_acc": 50.0, "val_loss": 7345.92431640625, "val_acc": 40.0}
{"epoch": 14, "training_loss": 5958.120458984375, "training_acc": 50.0, "val_loss": 2872.781005859375, "val_acc": 40.0}
{"epoch": 15, "training_loss": 1424.3888671875, "training_acc": 70.0, "val_loss": 3821.23291015625, "val_acc": 60.0}
{"epoch": 16, "training_loss": 5325.5349609375, "training_acc": 50.0, "val_loss": 2520.50634765625, "val_acc": 60.0}
{"epoch": 17, "training_loss": 3370.713037109375, "training_acc": 40.0, "val_loss": 3988.04296875, "val_acc": 40.0}
{"epoch": 18, "training_loss": 3130.031591796875, "training_acc": 50.0, "val_loss": 218.47744750976562, "val_acc": 60.0}
{"epoch": 19, "training_loss": 441.720166015625, "training_acc": 50.0, "val_loss": 1686.580078125, "val_acc": 40.0}
{"epoch": 20, "training_loss": 1413.712646484375, "training_acc": 50.0, "val_loss": 251.4561767578125, "val_acc": 60.0}
{"epoch": 21, "training_loss": 215.7972412109375, "training_acc": 60.0, "val_loss": 288.1285095214844, "val_acc": 40.0}
{"epoch": 22, "training_loss": 452.3914306640625, "training_acc": 50.0, "val_loss": 852.6314697265625, "val_acc": 60.0}
{"epoch": 23, "training_loss": 1072.014453125, "training_acc": 50.0, "val_loss": 1786.4739990234375, "val_acc": 40.0}
{"epoch": 24, "training_loss": 1497.7551025390626, "training_acc": 40.0, "val_loss": 482.3251647949219, "val_acc": 40.0}
{"epoch": 25, "training_loss": 555.425, "training_acc": 40.0, "val_loss": 1176.0474853515625, "val_acc": 40.0}
{"epoch": 26, "training_loss": 882.7314331054688, "training_acc": 50.0, "val_loss": 863.3002319335938, "val_acc": 60.0}
{"epoch": 27, "training_loss": 891.450146484375, "training_acc": 50.0, "val_loss": 3120.853271484375, "val_acc": 40.0}
{"epoch": 28, "training_loss": 2649.36435546875, "training_acc": 50.0, "val_loss": 3632.114990234375, "val_acc": 40.0}
{"epoch": 29, "training_loss": 2557.71181640625, "training_acc": 50.0, "val_loss": 2675.15625, "val_acc": 60.0}
{"epoch": 30, "training_loss": 3849.0529296875, "training_acc": 50.0, "val_loss": 3187.052490234375, "val_acc": 60.0}
{"epoch": 31, "training_loss": 3011.6517578125, "training_acc": 50.0, "val_loss": 5413.97998046875, "val_acc": 40.0}
{"epoch": 32, "training_loss": 5095.81875, "training_acc": 50.0, "val_loss": 10014.990234375, "val_acc": 40.0}
{"epoch": 33, "training_loss": 8026.319140625, "training_acc": 50.0, "val_loss": 4573.189453125, "val_acc": 40.0}
{"epoch": 34, "training_loss": 2703.954132080078, "training_acc": 60.0, "val_loss": 3157.021240234375, "val_acc": 60.0}
{"epoch": 35, "training_loss": 4051.5240234375, "training_acc": 50.0, "val_loss": 2828.374267578125, "val_acc": 60.0}
{"epoch": 36, "training_loss": 3427.4556816101076, "training_acc": 45.0, "val_loss": 2783.96142578125, "val_acc": 40.0}
{"epoch": 37, "training_loss": 2374.79892578125, "training_acc": 50.0, "val_loss": 69.89305877685547, "val_acc": 60.0}
{"epoch": 38, "training_loss": 162.31160888671874, "training_acc": 70.0, "val_loss": 1048.7440185546875, "val_acc": 60.0}
{"epoch": 39, "training_loss": 880.5336334228516, "training_acc": 60.0, "val_loss": 1076.62841796875, "val_acc": 40.0}
{"epoch": 40, "training_loss": 770.8504028320312, "training_acc": 50.0, "val_loss": 24.693283081054688, "val_acc": 60.0}
{"epoch": 41, "training_loss": 97.6546615600586, "training_acc": 85.0, "val_loss": 1043.8065185546875, "val_acc": 60.0}
{"epoch": 42, "training_loss": 1101.0502685546876, "training_acc": 50.0, "val_loss": 1914.9683837890625, "val_acc": 40.0}
{"epoch": 43, "training_loss": 1564.04169921875, "training_acc": 50.0, "val_loss": 19.471332550048828, "val_acc": 80.0}
{"epoch": 44, "training_loss": 126.59680786132813, "training_acc": 70.0, "val_loss": 603.6560668945312, "val_acc": 60.0}
{"epoch": 45, "training_loss": 776.95107421875, "training_acc": 50.0, "val_loss": 1651.946533203125, "val_acc": 40.0}
{"epoch": 46, "training_loss": 951.9320129394531, "training_acc": 60.0, "val_loss": 823.3525390625, "val_acc": 60.0}
{"epoch": 47, "training_loss": 575.1061874389649, "training_acc": 60.0, "val_loss": 3461.882080078125, "val_acc": 40.0}
{"epoch": 48, "training_loss": 3043.0060546875, "training_acc": 50.0, "val_loss": 1651.259033203125, "val_acc": 40.0}
{"epoch": 49, "training_loss": 1165.4424560546875, "training_acc": 60.0, "val_loss": 4024.57080078125, "val_acc": 60.0}
{"epoch": 50, "training_loss": 4916.9869140625, "training_acc": 50.0, "val_loss": 3038.849365234375, "val_acc": 60.0}
{"epoch": 51, "training_loss": 2670.9259765625, "training_acc": 50.0, "val_loss": 6258.91552734375, "val_acc": 40.0}
{"epoch": 52, "training_loss": 6373.590625, "training_acc": 50.0, "val_loss": 11686.7919921875, "val_acc": 40.0}
{"epoch": 53, "training_loss": 9235.13359375, "training_acc": 50.0, "val_loss": 4782.056640625, "val_acc": 40.0}
{"epoch": 54, "training_loss": 2847.44072265625, "training_acc": 60.0, "val_loss": 4623.35400390625, "val_acc": 60.0}
{"epoch": 55, "training_loss": 5662.5140625, "training_acc": 50.0, "val_loss": 6332.84765625, "val_acc": 60.0}
{"epoch": 56, "training_loss": 7528.965234375, "training_acc": 50.0, "val_loss": 2446.384521484375, "val_acc": 60.0}
{"epoch": 57, "training_loss": 2795.375634765625, "training_acc": 50.0, "val_loss": 6519.66943359375, "val_acc": 40.0}
{"epoch": 58, "training_loss": 5610.338671875, "training_acc": 50.0, "val_loss": 4770.5869140625, "val_acc": 40.0}
{"epoch": 59, "training_loss": 3137.483653259277, "training_acc": 55.0, "val_loss": 2210.616943359375, "val_acc": 60.0}
{"epoch": 60, "training_loss": 2822.47509765625, "training_acc": 50.0, "val_loss": 669.0611572265625, "val_acc": 60.0}
{"epoch": 61, "training_loss": 822.3197265625, "training_acc": 60.0, "val_loss": 6963.1328125, "val_acc": 40.0}
{"epoch": 62, "training_loss": 5710.0873046875, "training_acc": 50.0, "val_loss": 5848.85107421875, "val_acc": 40.0}
