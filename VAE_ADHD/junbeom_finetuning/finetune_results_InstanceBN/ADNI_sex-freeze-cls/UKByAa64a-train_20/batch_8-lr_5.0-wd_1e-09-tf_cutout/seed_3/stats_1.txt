"main_modify.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 3 --task ADNI_sex --input_option yAware --learning_rate 5e0 --batch_size 8 --weight_decay 1e-9 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 195.549441075325, "training_acc": 60.0, "val_loss": 511.2500915527344, "val_acc": 60.0}
{"epoch": 1, "training_loss": 426.6198425292969, "training_acc": 50.0, "val_loss": 300.2746276855469, "val_acc": 40.0}
{"epoch": 2, "training_loss": 151.19576873779297, "training_acc": 60.0, "val_loss": 253.97691345214844, "val_acc": 60.0}
{"epoch": 3, "training_loss": 205.54739837646486, "training_acc": 50.0, "val_loss": 438.1639709472656, "val_acc": 40.0}
{"epoch": 4, "training_loss": 535.4180358886719, "training_acc": 50.0, "val_loss": 586.5040893554688, "val_acc": 40.0}
{"epoch": 5, "training_loss": 425.4554840087891, "training_acc": 40.0, "val_loss": 197.3224639892578, "val_acc": 60.0}
{"epoch": 6, "training_loss": 207.209716796875, "training_acc": 50.0, "val_loss": 170.1233673095703, "val_acc": 40.0}
{"epoch": 7, "training_loss": 239.32566528320314, "training_acc": 50.0, "val_loss": 205.81594848632812, "val_acc": 40.0}
{"epoch": 8, "training_loss": 199.58370666503907, "training_acc": 30.0, "val_loss": 129.6194610595703, "val_acc": 60.0}
{"epoch": 9, "training_loss": 106.45540771484374, "training_acc": 50.0, "val_loss": 286.0121154785156, "val_acc": 40.0}
{"epoch": 10, "training_loss": 211.4260009765625, "training_acc": 50.0, "val_loss": 77.12325286865234, "val_acc": 60.0}
{"epoch": 11, "training_loss": 203.58847045898438, "training_acc": 50.0, "val_loss": 60.466773986816406, "val_acc": 60.0}
{"epoch": 12, "training_loss": 111.62015533447266, "training_acc": 60.0, "val_loss": 298.4961853027344, "val_acc": 40.0}
{"epoch": 13, "training_loss": 187.74016418457032, "training_acc": 50.0, "val_loss": 103.26131439208984, "val_acc": 60.0}
{"epoch": 14, "training_loss": 112.80719604492188, "training_acc": 40.0, "val_loss": 97.53153228759766, "val_acc": 40.0}
{"epoch": 15, "training_loss": 70.09482498168946, "training_acc": 50.0, "val_loss": 201.3368377685547, "val_acc": 60.0}
{"epoch": 16, "training_loss": 212.43422241210936, "training_acc": 50.0, "val_loss": 103.27275848388672, "val_acc": 40.0}
{"epoch": 17, "training_loss": 167.71536560058593, "training_acc": 50.0, "val_loss": 147.00071716308594, "val_acc": 40.0}
{"epoch": 18, "training_loss": 80.43340606689453, "training_acc": 50.0, "val_loss": 51.06034469604492, "val_acc": 60.0}
{"epoch": 19, "training_loss": 21.04674631357193, "training_acc": 60.0, "val_loss": 19.91969871520996, "val_acc": 40.0}
{"epoch": 20, "training_loss": 25.48563575744629, "training_acc": 50.0, "val_loss": 23.749977111816406, "val_acc": 40.0}
{"epoch": 21, "training_loss": 19.644424819946288, "training_acc": 55.0, "val_loss": 68.7959213256836, "val_acc": 40.0}
{"epoch": 22, "training_loss": 49.14941148757934, "training_acc": 60.0, "val_loss": 31.882308959960938, "val_acc": 60.0}
{"epoch": 23, "training_loss": 68.33210754394531, "training_acc": 30.0, "val_loss": 79.9996337890625, "val_acc": 60.0}
{"epoch": 24, "training_loss": 144.46325073242187, "training_acc": 50.0, "val_loss": 25.611621856689453, "val_acc": 40.0}
{"epoch": 25, "training_loss": 56.266205596923825, "training_acc": 50.0, "val_loss": 20.016159057617188, "val_acc": 60.0}
{"epoch": 26, "training_loss": 24.946474456787108, "training_acc": 60.0, "val_loss": 33.91950607299805, "val_acc": 40.0}
{"epoch": 27, "training_loss": 8.797331857681275, "training_acc": 80.0, "val_loss": 77.57765197753906, "val_acc": 60.0}
{"epoch": 28, "training_loss": 54.131335735321045, "training_acc": 55.0, "val_loss": 87.5832748413086, "val_acc": 40.0}
{"epoch": 29, "training_loss": 74.97332553863525, "training_acc": 35.0, "val_loss": 46.4886589050293, "val_acc": 40.0}
{"epoch": 30, "training_loss": 30.729267406463624, "training_acc": 60.0, "val_loss": 41.99434280395508, "val_acc": 40.0}
{"epoch": 31, "training_loss": 36.38458070755005, "training_acc": 55.0, "val_loss": 0.42495080828666687, "val_acc": 80.0}
{"epoch": 32, "training_loss": 31.6490047454834, "training_acc": 45.0, "val_loss": 7.999387264251709, "val_acc": 60.0}
{"epoch": 33, "training_loss": 78.99533824920654, "training_acc": 50.0, "val_loss": 6.245118618011475, "val_acc": 80.0}
{"epoch": 34, "training_loss": 22.789477109909058, "training_acc": 60.0, "val_loss": 90.50568389892578, "val_acc": 40.0}
{"epoch": 35, "training_loss": 65.85293807983399, "training_acc": 50.0, "val_loss": 27.266523361206055, "val_acc": 60.0}
{"epoch": 36, "training_loss": 26.01648712158203, "training_acc": 65.0, "val_loss": 7.3392181396484375, "val_acc": 80.0}
{"epoch": 37, "training_loss": 12.126820683479309, "training_acc": 70.0, "val_loss": 8.041979789733887, "val_acc": 80.0}
{"epoch": 38, "training_loss": 81.0489559173584, "training_acc": 45.0, "val_loss": 1.9727064371109009, "val_acc": 80.0}
{"epoch": 39, "training_loss": 89.89100799560546, "training_acc": 60.0, "val_loss": 28.066329956054688, "val_acc": 40.0}
{"epoch": 40, "training_loss": 154.9546691894531, "training_acc": 40.0, "val_loss": 200.55508422851562, "val_acc": 60.0}
{"epoch": 41, "training_loss": 194.58857421875, "training_acc": 40.0, "val_loss": 123.9512710571289, "val_acc": 40.0}
{"epoch": 42, "training_loss": 99.57268943786622, "training_acc": 40.0, "val_loss": 63.38220977783203, "val_acc": 60.0}
{"epoch": 43, "training_loss": 48.37096252441406, "training_acc": 50.0, "val_loss": 9.251301765441895, "val_acc": 80.0}
{"epoch": 44, "training_loss": 9.069814491271973, "training_acc": 75.0, "val_loss": 6.41998291015625, "val_acc": 80.0}
{"epoch": 45, "training_loss": 20.819026374816893, "training_acc": 45.0, "val_loss": 74.35038757324219, "val_acc": 60.0}
{"epoch": 46, "training_loss": 88.08335494995117, "training_acc": 50.0, "val_loss": 127.10591125488281, "val_acc": 40.0}
{"epoch": 47, "training_loss": 136.16509246826172, "training_acc": 50.0, "val_loss": 5.599277019500732, "val_acc": 80.0}
{"epoch": 48, "training_loss": 33.84100255966187, "training_acc": 55.0, "val_loss": 6.797687530517578, "val_acc": 80.0}
{"epoch": 49, "training_loss": 16.72345495223999, "training_acc": 70.0, "val_loss": 25.89814567565918, "val_acc": 40.0}
{"epoch": 50, "training_loss": 14.239979934692382, "training_acc": 65.0, "val_loss": 36.17389678955078, "val_acc": 60.0}
