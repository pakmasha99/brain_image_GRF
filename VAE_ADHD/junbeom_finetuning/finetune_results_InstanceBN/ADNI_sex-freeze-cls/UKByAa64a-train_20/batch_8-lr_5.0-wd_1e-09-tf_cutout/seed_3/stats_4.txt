"main_modify.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 3 --task ADNI_sex --input_option yAware --learning_rate 5e0 --batch_size 8 --weight_decay 1e-9 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 502.8448491334915, "training_acc": 55.0, "val_loss": 388.97833251953125, "val_acc": 60.0}
{"epoch": 1, "training_loss": 905.2093139648438, "training_acc": 45.0, "val_loss": 316.94183349609375, "val_acc": 60.0}
{"epoch": 2, "training_loss": 187.16202697753906, "training_acc": 65.0, "val_loss": 643.7301635742188, "val_acc": 40.0}
{"epoch": 3, "training_loss": 461.6427001953125, "training_acc": 55.0, "val_loss": 62.7576789855957, "val_acc": 40.0}
{"epoch": 4, "training_loss": 168.81326599121093, "training_acc": 55.0, "val_loss": 251.0741729736328, "val_acc": 60.0}
{"epoch": 5, "training_loss": 171.0501953125, "training_acc": 65.0, "val_loss": 298.7085876464844, "val_acc": 40.0}
{"epoch": 6, "training_loss": 242.100732421875, "training_acc": 55.0, "val_loss": 81.22607421875, "val_acc": 40.0}
{"epoch": 7, "training_loss": 154.86399154663087, "training_acc": 65.0, "val_loss": 249.7880859375, "val_acc": 60.0}
{"epoch": 8, "training_loss": 191.8165054321289, "training_acc": 55.0, "val_loss": 350.9645080566406, "val_acc": 40.0}
{"epoch": 9, "training_loss": 271.960107421875, "training_acc": 55.0, "val_loss": 126.44244384765625, "val_acc": 40.0}
{"epoch": 10, "training_loss": 164.4673278808594, "training_acc": 45.0, "val_loss": 120.98259735107422, "val_acc": 60.0}
{"epoch": 11, "training_loss": 130.17147369384764, "training_acc": 45.0, "val_loss": 136.49624633789062, "val_acc": 40.0}
{"epoch": 12, "training_loss": 59.69207248687744, "training_acc": 60.0, "val_loss": 106.04203033447266, "val_acc": 60.0}
{"epoch": 13, "training_loss": 96.68519172668456, "training_acc": 45.0, "val_loss": 385.4554748535156, "val_acc": 40.0}
{"epoch": 14, "training_loss": 286.5532653808594, "training_acc": 55.0, "val_loss": 38.541194915771484, "val_acc": 40.0}
{"epoch": 15, "training_loss": 270.94835662841797, "training_acc": 35.0, "val_loss": 342.2875061035156, "val_acc": 60.0}
{"epoch": 16, "training_loss": 328.53863525390625, "training_acc": 45.0, "val_loss": 271.8402099609375, "val_acc": 40.0}
{"epoch": 17, "training_loss": 413.47084655761716, "training_acc": 55.0, "val_loss": 665.1310424804688, "val_acc": 40.0}
{"epoch": 18, "training_loss": 378.8642150878906, "training_acc": 55.0, "val_loss": 64.21509552001953, "val_acc": 60.0}
{"epoch": 19, "training_loss": 162.87267456054687, "training_acc": 45.0, "val_loss": 130.18817138671875, "val_acc": 60.0}
{"epoch": 20, "training_loss": 108.89550094604492, "training_acc": 50.0, "val_loss": 72.2306900024414, "val_acc": 40.0}
{"epoch": 21, "training_loss": 36.26883392333984, "training_acc": 65.0, "val_loss": 16.85948944091797, "val_acc": 40.0}
{"epoch": 22, "training_loss": 28.327734559765396, "training_acc": 75.0, "val_loss": 38.555625915527344, "val_acc": 60.0}
{"epoch": 23, "training_loss": 38.77891845703125, "training_acc": 50.0, "val_loss": 209.98452758789062, "val_acc": 40.0}
{"epoch": 24, "training_loss": 121.74988327026367, "training_acc": 60.0, "val_loss": 140.0230255126953, "val_acc": 60.0}
{"epoch": 25, "training_loss": 214.07687072753907, "training_acc": 45.0, "val_loss": 10.860796928405762, "val_acc": 60.0}
{"epoch": 26, "training_loss": 66.87270278930664, "training_acc": 60.0, "val_loss": 106.64354705810547, "val_acc": 40.0}
{"epoch": 27, "training_loss": 90.20484619140625, "training_acc": 45.0, "val_loss": 20.128467559814453, "val_acc": 60.0}
{"epoch": 28, "training_loss": 108.41300964355469, "training_acc": 50.0, "val_loss": 195.8771514892578, "val_acc": 40.0}
{"epoch": 29, "training_loss": 113.03405923843384, "training_acc": 50.0, "val_loss": 53.693115234375, "val_acc": 60.0}
{"epoch": 30, "training_loss": 171.21038513183595, "training_acc": 35.0, "val_loss": 181.5498809814453, "val_acc": 40.0}
{"epoch": 31, "training_loss": 68.32287712097168, "training_acc": 65.0, "val_loss": 93.11552429199219, "val_acc": 60.0}
{"epoch": 32, "training_loss": 69.51263456344604, "training_acc": 65.0, "val_loss": 171.2429656982422, "val_acc": 40.0}
{"epoch": 33, "training_loss": 58.60282211303711, "training_acc": 65.0, "val_loss": 112.85597229003906, "val_acc": 60.0}
{"epoch": 34, "training_loss": 130.3632843017578, "training_acc": 35.0, "val_loss": 155.2332000732422, "val_acc": 40.0}
{"epoch": 35, "training_loss": 67.58072357177734, "training_acc": 65.0, "val_loss": 54.24980545043945, "val_acc": 60.0}
{"epoch": 36, "training_loss": 39.13617477416992, "training_acc": 65.0, "val_loss": 91.02252960205078, "val_acc": 40.0}
{"epoch": 37, "training_loss": 40.145250701904295, "training_acc": 50.0, "val_loss": 104.64739990234375, "val_acc": 40.0}
{"epoch": 38, "training_loss": 66.55457763671875, "training_acc": 65.0, "val_loss": 36.40050506591797, "val_acc": 60.0}
{"epoch": 39, "training_loss": 38.55158462524414, "training_acc": 40.0, "val_loss": 86.5072021484375, "val_acc": 60.0}
{"epoch": 40, "training_loss": 98.12662544250489, "training_acc": 40.0, "val_loss": 141.68528747558594, "val_acc": 40.0}
{"epoch": 41, "training_loss": 109.34109191894531, "training_acc": 55.0, "val_loss": 89.19955444335938, "val_acc": 60.0}
{"epoch": 42, "training_loss": 189.00810852050782, "training_acc": 45.0, "val_loss": 15.565693855285645, "val_acc": 60.0}
{"epoch": 43, "training_loss": 80.27624435424805, "training_acc": 55.0, "val_loss": 307.6665954589844, "val_acc": 40.0}
{"epoch": 44, "training_loss": 152.4145820617676, "training_acc": 55.0, "val_loss": 141.57957458496094, "val_acc": 60.0}
