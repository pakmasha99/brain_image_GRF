"main_modify.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_sex --input_option yAware --learning_rate 5e0 --batch_size 8 --weight_decay 1e-9 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 458.74366507530215, "training_acc": 50.0, "val_loss": 832.3187866210938, "val_acc": 40.0}
{"epoch": 1, "training_loss": 655.5740478515625, "training_acc": 50.0, "val_loss": 190.0652618408203, "val_acc": 40.0}
{"epoch": 2, "training_loss": 218.6096618652344, "training_acc": 60.0, "val_loss": 436.1347351074219, "val_acc": 60.0}
{"epoch": 3, "training_loss": 430.7297668457031, "training_acc": 50.0, "val_loss": 220.26016235351562, "val_acc": 40.0}
{"epoch": 4, "training_loss": 286.21416015625, "training_acc": 50.0, "val_loss": 408.44244384765625, "val_acc": 40.0}
{"epoch": 5, "training_loss": 173.89671783447267, "training_acc": 60.0, "val_loss": 233.6092987060547, "val_acc": 60.0}
{"epoch": 6, "training_loss": 296.4685485839844, "training_acc": 50.0, "val_loss": 36.44660568237305, "val_acc": 60.0}
{"epoch": 7, "training_loss": 245.26897125244142, "training_acc": 40.0, "val_loss": 518.760986328125, "val_acc": 40.0}
{"epoch": 8, "training_loss": 330.7244018554687, "training_acc": 50.0, "val_loss": 132.05154418945312, "val_acc": 60.0}
{"epoch": 9, "training_loss": 271.51146240234374, "training_acc": 50.0, "val_loss": 214.787841796875, "val_acc": 60.0}
{"epoch": 10, "training_loss": 161.06688537597657, "training_acc": 50.0, "val_loss": 458.3127136230469, "val_acc": 40.0}
{"epoch": 11, "training_loss": 409.97694091796876, "training_acc": 50.0, "val_loss": 227.81130981445312, "val_acc": 40.0}
{"epoch": 12, "training_loss": 230.287939453125, "training_acc": 30.0, "val_loss": 204.39540100097656, "val_acc": 60.0}
{"epoch": 13, "training_loss": 210.098193359375, "training_acc": 40.0, "val_loss": 164.10643005371094, "val_acc": 40.0}
{"epoch": 14, "training_loss": 118.29198608398437, "training_acc": 40.0, "val_loss": 110.87911224365234, "val_acc": 60.0}
{"epoch": 15, "training_loss": 115.73557586669922, "training_acc": 40.0, "val_loss": 205.7790069580078, "val_acc": 40.0}
{"epoch": 16, "training_loss": 121.24506530761718, "training_acc": 50.0, "val_loss": 104.7016830444336, "val_acc": 60.0}
{"epoch": 17, "training_loss": 89.91529769897461, "training_acc": 50.0, "val_loss": 154.9181365966797, "val_acc": 40.0}
{"epoch": 18, "training_loss": 74.20787086486817, "training_acc": 60.0, "val_loss": 101.56678771972656, "val_acc": 60.0}
{"epoch": 19, "training_loss": 104.66736450195313, "training_acc": 40.0, "val_loss": 77.2109603881836, "val_acc": 40.0}
{"epoch": 20, "training_loss": 49.21368255615234, "training_acc": 50.0, "val_loss": 62.46733474731445, "val_acc": 40.0}
{"epoch": 21, "training_loss": 38.792501068115236, "training_acc": 60.0, "val_loss": 81.4128189086914, "val_acc": 60.0}
{"epoch": 22, "training_loss": 86.01234149932861, "training_acc": 50.0, "val_loss": 205.60459899902344, "val_acc": 40.0}
{"epoch": 23, "training_loss": 182.91336517333986, "training_acc": 50.0, "val_loss": 77.91703033447266, "val_acc": 40.0}
{"epoch": 24, "training_loss": 54.41947784423828, "training_acc": 70.0, "val_loss": 95.1473388671875, "val_acc": 60.0}
{"epoch": 25, "training_loss": 80.41851348876953, "training_acc": 40.0, "val_loss": 32.88559341430664, "val_acc": 60.0}
{"epoch": 26, "training_loss": 29.438903045654296, "training_acc": 50.0, "val_loss": 43.15420913696289, "val_acc": 40.0}
{"epoch": 27, "training_loss": 75.67146759033203, "training_acc": 40.0, "val_loss": 15.774374961853027, "val_acc": 60.0}
{"epoch": 28, "training_loss": 70.98849066793919, "training_acc": 65.0, "val_loss": 59.28377914428711, "val_acc": 60.0}
{"epoch": 29, "training_loss": 94.34683532714844, "training_acc": 50.0, "val_loss": 28.661563873291016, "val_acc": 40.0}
{"epoch": 30, "training_loss": 53.958055877685545, "training_acc": 50.0, "val_loss": 97.09026336669922, "val_acc": 60.0}
{"epoch": 31, "training_loss": 101.19514770507813, "training_acc": 50.0, "val_loss": 107.90290832519531, "val_acc": 40.0}
{"epoch": 32, "training_loss": 54.570147290290336, "training_acc": 65.0, "val_loss": 66.19536590576172, "val_acc": 60.0}
{"epoch": 33, "training_loss": 45.95176315307617, "training_acc": 40.0, "val_loss": 127.48243713378906, "val_acc": 60.0}
{"epoch": 34, "training_loss": 172.49036865234376, "training_acc": 50.0, "val_loss": 28.74485206604004, "val_acc": 60.0}
{"epoch": 35, "training_loss": 170.14862976074218, "training_acc": 45.0, "val_loss": 368.1337890625, "val_acc": 40.0}
{"epoch": 36, "training_loss": 231.56842880249025, "training_acc": 50.0, "val_loss": 98.98613739013672, "val_acc": 60.0}
{"epoch": 37, "training_loss": 65.59435729980468, "training_acc": 65.0, "val_loss": 112.4203109741211, "val_acc": 40.0}
{"epoch": 38, "training_loss": 63.86146240234375, "training_acc": 60.0, "val_loss": 96.59049224853516, "val_acc": 60.0}
{"epoch": 39, "training_loss": 68.883136177063, "training_acc": 55.0, "val_loss": 180.94964599609375, "val_acc": 40.0}
{"epoch": 40, "training_loss": 170.91421661376953, "training_acc": 50.0, "val_loss": 28.604581832885742, "val_acc": 40.0}
{"epoch": 41, "training_loss": 118.0278106689453, "training_acc": 50.0, "val_loss": 186.91578674316406, "val_acc": 60.0}
{"epoch": 42, "training_loss": 140.65914611816407, "training_acc": 50.0, "val_loss": 230.16148376464844, "val_acc": 40.0}
{"epoch": 43, "training_loss": 130.64844150543212, "training_acc": 55.0, "val_loss": 111.5303955078125, "val_acc": 60.0}
{"epoch": 44, "training_loss": 201.98628616333008, "training_acc": 50.0, "val_loss": 23.89525604248047, "val_acc": 60.0}
{"epoch": 45, "training_loss": 99.61903731822967, "training_acc": 70.0, "val_loss": 361.317626953125, "val_acc": 40.0}
{"epoch": 46, "training_loss": 201.755078125, "training_acc": 50.0, "val_loss": 169.12014770507812, "val_acc": 60.0}
