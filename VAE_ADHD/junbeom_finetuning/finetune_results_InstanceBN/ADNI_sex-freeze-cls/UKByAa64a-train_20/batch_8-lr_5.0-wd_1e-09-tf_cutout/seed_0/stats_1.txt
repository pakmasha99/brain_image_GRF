"main_modify.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_sex --input_option yAware --learning_rate 5e0 --batch_size 8 --weight_decay 1e-9 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 586.5393917083741, "training_acc": 40.0, "val_loss": 215.4041290283203, "val_acc": 60.0}
{"epoch": 1, "training_loss": 518.3521240234375, "training_acc": 50.0, "val_loss": 268.9349670410156, "val_acc": 60.0}
{"epoch": 2, "training_loss": 420.9391357421875, "training_acc": 20.0, "val_loss": 274.91644287109375, "val_acc": 40.0}
{"epoch": 3, "training_loss": 124.42692260742187, "training_acc": 60.0, "val_loss": 346.4694519042969, "val_acc": 60.0}
{"epoch": 4, "training_loss": 460.3743896484375, "training_acc": 50.0, "val_loss": 159.72093200683594, "val_acc": 60.0}
{"epoch": 5, "training_loss": 166.6342346191406, "training_acc": 50.0, "val_loss": 311.11126708984375, "val_acc": 40.0}
{"epoch": 6, "training_loss": 154.7740234375, "training_acc": 70.0, "val_loss": 117.4998550415039, "val_acc": 60.0}
{"epoch": 7, "training_loss": 110.966019821167, "training_acc": 50.0, "val_loss": 228.6380615234375, "val_acc": 40.0}
{"epoch": 8, "training_loss": 252.90640869140626, "training_acc": 50.0, "val_loss": 124.79396057128906, "val_acc": 40.0}
{"epoch": 9, "training_loss": 141.00267639160157, "training_acc": 50.0, "val_loss": 181.59976196289062, "val_acc": 60.0}
{"epoch": 10, "training_loss": 189.082470703125, "training_acc": 40.0, "val_loss": 224.85972595214844, "val_acc": 40.0}
{"epoch": 11, "training_loss": 128.9925979614258, "training_acc": 50.0, "val_loss": 46.337032318115234, "val_acc": 60.0}
{"epoch": 12, "training_loss": 76.93264617919922, "training_acc": 40.0, "val_loss": 229.7631378173828, "val_acc": 40.0}
{"epoch": 13, "training_loss": 183.12424087524414, "training_acc": 40.0, "val_loss": 135.6765594482422, "val_acc": 60.0}
{"epoch": 14, "training_loss": 99.37938613891602, "training_acc": 60.0, "val_loss": 151.39849853515625, "val_acc": 40.0}
{"epoch": 15, "training_loss": 90.69489440917968, "training_acc": 50.0, "val_loss": 166.15362548828125, "val_acc": 60.0}
{"epoch": 16, "training_loss": 305.3442077636719, "training_acc": 50.0, "val_loss": 238.307861328125, "val_acc": 60.0}
{"epoch": 17, "training_loss": 260.1305725097656, "training_acc": 40.0, "val_loss": 383.3721618652344, "val_acc": 40.0}
{"epoch": 18, "training_loss": 314.79954223632814, "training_acc": 50.0, "val_loss": 80.81697845458984, "val_acc": 40.0}
{"epoch": 19, "training_loss": 147.64080505371095, "training_acc": 50.0, "val_loss": 286.263916015625, "val_acc": 60.0}
{"epoch": 20, "training_loss": 301.69138793945314, "training_acc": 50.0, "val_loss": 52.72938919067383, "val_acc": 40.0}
{"epoch": 21, "training_loss": 106.0556884765625, "training_acc": 50.0, "val_loss": 48.18731689453125, "val_acc": 40.0}
{"epoch": 22, "training_loss": 147.20782165527345, "training_acc": 50.0, "val_loss": 194.5538787841797, "val_acc": 60.0}
{"epoch": 23, "training_loss": 196.0422790527344, "training_acc": 40.0, "val_loss": 252.22036743164062, "val_acc": 40.0}
{"epoch": 24, "training_loss": 172.020068359375, "training_acc": 50.0, "val_loss": 109.2459487915039, "val_acc": 60.0}
{"epoch": 25, "training_loss": 222.35044555664064, "training_acc": 50.0, "val_loss": 107.50428771972656, "val_acc": 60.0}
{"epoch": 26, "training_loss": 67.76510009765624, "training_acc": 60.0, "val_loss": 179.81163024902344, "val_acc": 40.0}
{"epoch": 27, "training_loss": 85.26411743164063, "training_acc": 60.0, "val_loss": 116.03252410888672, "val_acc": 60.0}
{"epoch": 28, "training_loss": 106.68822784423828, "training_acc": 50.0, "val_loss": 49.8026008605957, "val_acc": 40.0}
{"epoch": 29, "training_loss": 65.40684661865234, "training_acc": 40.0, "val_loss": 66.97100067138672, "val_acc": 40.0}
{"epoch": 30, "training_loss": 37.94206237792969, "training_acc": 55.0, "val_loss": 12.788414001464844, "val_acc": 60.0}
{"epoch": 31, "training_loss": 14.862024784088135, "training_acc": 55.0, "val_loss": 52.31184005737305, "val_acc": 40.0}
{"epoch": 32, "training_loss": 15.500276374816895, "training_acc": 50.0, "val_loss": 113.05858612060547, "val_acc": 40.0}
{"epoch": 33, "training_loss": 73.22956352233886, "training_acc": 55.0, "val_loss": 83.65082550048828, "val_acc": 60.0}
{"epoch": 34, "training_loss": 121.4984375, "training_acc": 50.0, "val_loss": 127.91606903076172, "val_acc": 40.0}
{"epoch": 35, "training_loss": 161.6152557373047, "training_acc": 50.0, "val_loss": 134.09739685058594, "val_acc": 40.0}
{"epoch": 36, "training_loss": 84.66781921386719, "training_acc": 50.0, "val_loss": 84.74178314208984, "val_acc": 60.0}
{"epoch": 37, "training_loss": 101.32403717041015, "training_acc": 30.0, "val_loss": 56.474822998046875, "val_acc": 60.0}
{"epoch": 38, "training_loss": 74.80986557006835, "training_acc": 50.0, "val_loss": 111.95735931396484, "val_acc": 40.0}
{"epoch": 39, "training_loss": 77.4708351135254, "training_acc": 40.0, "val_loss": 16.675575256347656, "val_acc": 60.0}
{"epoch": 40, "training_loss": 11.194313716888427, "training_acc": 70.0, "val_loss": 12.810434341430664, "val_acc": 60.0}
{"epoch": 41, "training_loss": 10.21850872039795, "training_acc": 65.0, "val_loss": 153.56399536132812, "val_acc": 40.0}
{"epoch": 42, "training_loss": 126.81563110351563, "training_acc": 50.0, "val_loss": 55.963233947753906, "val_acc": 60.0}
{"epoch": 43, "training_loss": 124.68379516601563, "training_acc": 50.0, "val_loss": 39.162654876708984, "val_acc": 60.0}
{"epoch": 44, "training_loss": 79.26450042724609, "training_acc": 60.0, "val_loss": 195.79676818847656, "val_acc": 40.0}
{"epoch": 45, "training_loss": 108.49287719726563, "training_acc": 55.0, "val_loss": 156.8134307861328, "val_acc": 60.0}
{"epoch": 46, "training_loss": 157.39199523925782, "training_acc": 50.0, "val_loss": 210.47390747070312, "val_acc": 40.0}
{"epoch": 47, "training_loss": 291.4553466796875, "training_acc": 50.0, "val_loss": 326.0894470214844, "val_acc": 40.0}
{"epoch": 48, "training_loss": 175.01406860351562, "training_acc": 50.0, "val_loss": 266.5083923339844, "val_acc": 60.0}
{"epoch": 49, "training_loss": 344.89069213867185, "training_acc": 50.0, "val_loss": 115.10725402832031, "val_acc": 60.0}
