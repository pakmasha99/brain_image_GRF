"main_modify.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 1 --task ADNI_sex --input_option yAware --learning_rate 5e0 --batch_size 8 --weight_decay 1e-9 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 469.70860905647277, "training_acc": 55.0, "val_loss": 252.805419921875, "val_acc": 60.0}
{"epoch": 1, "training_loss": 507.49169006347654, "training_acc": 45.0, "val_loss": 99.09431457519531, "val_acc": 60.0}
{"epoch": 2, "training_loss": 270.3596466064453, "training_acc": 45.0, "val_loss": 613.9249267578125, "val_acc": 40.0}
{"epoch": 3, "training_loss": 370.36707763671876, "training_acc": 55.0, "val_loss": 77.94103240966797, "val_acc": 60.0}
{"epoch": 4, "training_loss": 291.8424407958984, "training_acc": 45.0, "val_loss": 146.93508911132812, "val_acc": 60.0}
{"epoch": 5, "training_loss": 124.63601226806641, "training_acc": 55.0, "val_loss": 289.04827880859375, "val_acc": 40.0}
{"epoch": 6, "training_loss": 159.50814514160157, "training_acc": 55.0, "val_loss": 163.8399658203125, "val_acc": 60.0}
{"epoch": 7, "training_loss": 321.03802490234375, "training_acc": 45.0, "val_loss": 176.82725524902344, "val_acc": 60.0}
{"epoch": 8, "training_loss": 146.48821659088134, "training_acc": 50.0, "val_loss": 535.9761962890625, "val_acc": 40.0}
{"epoch": 9, "training_loss": 481.73875122070314, "training_acc": 55.0, "val_loss": 412.7560729980469, "val_acc": 40.0}
{"epoch": 10, "training_loss": 303.0774383544922, "training_acc": 45.0, "val_loss": 371.8123474121094, "val_acc": 60.0}
{"epoch": 11, "training_loss": 511.138671875, "training_acc": 45.0, "val_loss": 167.6654510498047, "val_acc": 60.0}
{"epoch": 12, "training_loss": 195.42830810546874, "training_acc": 45.0, "val_loss": 503.20245361328125, "val_acc": 40.0}
{"epoch": 13, "training_loss": 361.7091796875, "training_acc": 55.0, "val_loss": 225.4492950439453, "val_acc": 40.0}
{"epoch": 14, "training_loss": 287.5773193359375, "training_acc": 25.0, "val_loss": 190.3013153076172, "val_acc": 60.0}
{"epoch": 15, "training_loss": 140.01990280151367, "training_acc": 55.0, "val_loss": 299.4284973144531, "val_acc": 40.0}
{"epoch": 16, "training_loss": 250.8351257324219, "training_acc": 55.0, "val_loss": 181.80816650390625, "val_acc": 40.0}
{"epoch": 17, "training_loss": 148.55802001953126, "training_acc": 35.0, "val_loss": 93.81993865966797, "val_acc": 60.0}
{"epoch": 18, "training_loss": 78.24042282104492, "training_acc": 45.0, "val_loss": 13.533990859985352, "val_acc": 40.0}
{"epoch": 19, "training_loss": 49.3361328125, "training_acc": 65.0, "val_loss": 26.8735294342041, "val_acc": 60.0}
{"epoch": 20, "training_loss": 133.80863189697266, "training_acc": 45.0, "val_loss": 240.603515625, "val_acc": 40.0}
{"epoch": 21, "training_loss": 144.8912811279297, "training_acc": 45.0, "val_loss": 186.91989135742188, "val_acc": 60.0}
{"epoch": 22, "training_loss": 198.99027652740477, "training_acc": 40.0, "val_loss": 88.4557113647461, "val_acc": 40.0}
{"epoch": 23, "training_loss": 31.5368945479383, "training_acc": 75.0, "val_loss": 44.04995346069336, "val_acc": 60.0}
{"epoch": 24, "training_loss": 44.870389943541525, "training_acc": 45.0, "val_loss": 20.355649948120117, "val_acc": 60.0}
{"epoch": 25, "training_loss": 99.72263793945312, "training_acc": 25.0, "val_loss": 14.00542163848877, "val_acc": 60.0}
{"epoch": 26, "training_loss": 26.295397186279295, "training_acc": 40.0, "val_loss": 3.648620367050171, "val_acc": 40.0}
{"epoch": 27, "training_loss": 4.7030497789382935, "training_acc": 75.0, "val_loss": 22.0489444732666, "val_acc": 40.0}
{"epoch": 28, "training_loss": 24.347018814086915, "training_acc": 50.0, "val_loss": 5.533429145812988, "val_acc": 60.0}
{"epoch": 29, "training_loss": 40.11352615356445, "training_acc": 50.0, "val_loss": 188.10488891601562, "val_acc": 40.0}
{"epoch": 30, "training_loss": 86.22398662567139, "training_acc": 60.0, "val_loss": 69.3377914428711, "val_acc": 60.0}
{"epoch": 31, "training_loss": 94.38857727050781, "training_acc": 35.0, "val_loss": 185.61795043945312, "val_acc": 40.0}
{"epoch": 32, "training_loss": 85.38976364135742, "training_acc": 55.0, "val_loss": 84.9871597290039, "val_acc": 60.0}
{"epoch": 33, "training_loss": 103.50317001342773, "training_acc": 35.0, "val_loss": 245.066162109375, "val_acc": 40.0}
{"epoch": 34, "training_loss": 119.2592041015625, "training_acc": 55.0, "val_loss": 158.61692810058594, "val_acc": 60.0}
{"epoch": 35, "training_loss": 305.61701049804685, "training_acc": 45.0, "val_loss": 132.6243896484375, "val_acc": 60.0}
{"epoch": 36, "training_loss": 172.71289978027343, "training_acc": 45.0, "val_loss": 297.3020935058594, "val_acc": 40.0}
{"epoch": 37, "training_loss": 155.5925308227539, "training_acc": 45.0, "val_loss": 47.388343811035156, "val_acc": 60.0}
{"epoch": 38, "training_loss": 49.50663681030274, "training_acc": 45.0, "val_loss": 54.55462646484375, "val_acc": 60.0}
{"epoch": 39, "training_loss": 51.697533416748044, "training_acc": 45.0, "val_loss": 38.724769592285156, "val_acc": 40.0}
{"epoch": 40, "training_loss": 27.83860855102539, "training_acc": 55.0, "val_loss": 123.3726577758789, "val_acc": 40.0}
{"epoch": 41, "training_loss": 127.68583374023437, "training_acc": 55.0, "val_loss": 6.721843719482422, "val_acc": 40.0}
{"epoch": 42, "training_loss": 111.59296327531338, "training_acc": 60.0, "val_loss": 28.488073348999023, "val_acc": 60.0}
{"epoch": 43, "training_loss": 68.02882690429688, "training_acc": 65.0, "val_loss": 351.37744140625, "val_acc": 40.0}
{"epoch": 44, "training_loss": 192.47099914550782, "training_acc": 55.0, "val_loss": 73.0546646118164, "val_acc": 60.0}
{"epoch": 45, "training_loss": 168.4167053222656, "training_acc": 45.0, "val_loss": 107.02436828613281, "val_acc": 60.0}
