"main_modify.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 1 --task ADNI_sex --input_option yAware --learning_rate 5e0 --batch_size 8 --weight_decay 1e-9 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 539.7728828430176, "training_acc": 50.0, "val_loss": 394.5408630371094, "val_acc": 60.0}
{"epoch": 1, "training_loss": 676.9675048828125, "training_acc": 50.0, "val_loss": 453.0088806152344, "val_acc": 60.0}
{"epoch": 2, "training_loss": 393.35791015625, "training_acc": 50.0, "val_loss": 588.6533203125, "val_acc": 40.0}
{"epoch": 3, "training_loss": 485.71416015625, "training_acc": 50.0, "val_loss": 134.81698608398438, "val_acc": 40.0}
{"epoch": 4, "training_loss": 272.52329406738284, "training_acc": 50.0, "val_loss": 312.68634033203125, "val_acc": 60.0}
{"epoch": 5, "training_loss": 212.95869731903076, "training_acc": 60.0, "val_loss": 222.99014282226562, "val_acc": 40.0}
{"epoch": 6, "training_loss": 241.42635498046874, "training_acc": 50.0, "val_loss": 11.200736045837402, "val_acc": 60.0}
{"epoch": 7, "training_loss": 32.92995262145996, "training_acc": 40.0, "val_loss": 48.0393180847168, "val_acc": 60.0}
{"epoch": 8, "training_loss": 55.75955657958984, "training_acc": 50.0, "val_loss": 121.0218505859375, "val_acc": 40.0}
{"epoch": 9, "training_loss": 81.38440856933593, "training_acc": 50.0, "val_loss": 166.5417022705078, "val_acc": 60.0}
{"epoch": 10, "training_loss": 162.50040168762206, "training_acc": 40.0, "val_loss": 8.6566801071167, "val_acc": 40.0}
{"epoch": 11, "training_loss": 58.00353927612305, "training_acc": 50.0, "val_loss": 9.142678260803223, "val_acc": 40.0}
{"epoch": 12, "training_loss": 21.38112077713013, "training_acc": 55.0, "val_loss": 45.52143859863281, "val_acc": 40.0}
{"epoch": 13, "training_loss": 50.45016937255859, "training_acc": 50.0, "val_loss": 48.00423812866211, "val_acc": 60.0}
{"epoch": 14, "training_loss": 63.77270660400391, "training_acc": 40.0, "val_loss": 50.800514221191406, "val_acc": 60.0}
{"epoch": 15, "training_loss": 50.675340270996095, "training_acc": 50.0, "val_loss": 40.969417572021484, "val_acc": 40.0}
{"epoch": 16, "training_loss": 52.392295837402344, "training_acc": 50.0, "val_loss": 25.505170822143555, "val_acc": 40.0}
{"epoch": 17, "training_loss": 35.62890281677246, "training_acc": 60.0, "val_loss": 38.820457458496094, "val_acc": 60.0}
{"epoch": 18, "training_loss": 48.93098907470703, "training_acc": 40.0, "val_loss": 96.42980194091797, "val_acc": 60.0}
{"epoch": 19, "training_loss": 152.25978393554686, "training_acc": 50.0, "val_loss": 25.564311981201172, "val_acc": 40.0}
{"epoch": 20, "training_loss": 60.871647644042966, "training_acc": 50.0, "val_loss": 63.12932205200195, "val_acc": 60.0}
{"epoch": 21, "training_loss": 90.78892211914062, "training_acc": 50.0, "val_loss": 84.49571990966797, "val_acc": 40.0}
{"epoch": 22, "training_loss": 102.60428924560547, "training_acc": 50.0, "val_loss": 68.2708969116211, "val_acc": 60.0}
{"epoch": 23, "training_loss": 152.40298614501953, "training_acc": 50.0, "val_loss": 34.82979965209961, "val_acc": 40.0}
{"epoch": 24, "training_loss": 80.9986701965332, "training_acc": 50.0, "val_loss": 2.178309440612793, "val_acc": 80.0}
{"epoch": 25, "training_loss": 29.54791979789734, "training_acc": 50.0, "val_loss": 6.083870887756348, "val_acc": 80.0}
{"epoch": 26, "training_loss": 9.44368543624878, "training_acc": 65.0, "val_loss": 77.64668273925781, "val_acc": 60.0}
{"epoch": 27, "training_loss": 89.62837219238281, "training_acc": 50.0, "val_loss": 174.85635375976562, "val_acc": 40.0}
{"epoch": 28, "training_loss": 185.56832885742188, "training_acc": 50.0, "val_loss": 116.5303726196289, "val_acc": 40.0}
{"epoch": 29, "training_loss": 64.93838958740234, "training_acc": 50.0, "val_loss": 5.692499160766602, "val_acc": 80.0}
{"epoch": 30, "training_loss": 46.464293479919434, "training_acc": 60.0, "val_loss": 86.34101867675781, "val_acc": 60.0}
{"epoch": 31, "training_loss": 123.27316665649414, "training_acc": 50.0, "val_loss": 25.331113815307617, "val_acc": 40.0}
{"epoch": 32, "training_loss": 35.92507438659668, "training_acc": 30.0, "val_loss": 88.31098175048828, "val_acc": 40.0}
{"epoch": 33, "training_loss": 62.908572387695315, "training_acc": 50.0, "val_loss": 138.1526336669922, "val_acc": 60.0}
{"epoch": 34, "training_loss": 131.79192199707032, "training_acc": 40.0, "val_loss": 75.53804779052734, "val_acc": 40.0}
{"epoch": 35, "training_loss": 33.910807037353514, "training_acc": 60.0, "val_loss": 182.0973358154297, "val_acc": 60.0}
{"epoch": 36, "training_loss": 188.9292724609375, "training_acc": 50.0, "val_loss": 105.58619689941406, "val_acc": 40.0}
{"epoch": 37, "training_loss": 99.40460014343262, "training_acc": 50.0, "val_loss": 47.379398345947266, "val_acc": 60.0}
{"epoch": 38, "training_loss": 37.50324974060059, "training_acc": 60.0, "val_loss": 21.12837028503418, "val_acc": 40.0}
{"epoch": 39, "training_loss": 47.73214340209961, "training_acc": 50.0, "val_loss": 79.3684310913086, "val_acc": 40.0}
{"epoch": 40, "training_loss": 85.76341400146484, "training_acc": 50.0, "val_loss": 58.120582580566406, "val_acc": 60.0}
{"epoch": 41, "training_loss": 46.83664474487305, "training_acc": 50.0, "val_loss": 7.906070709228516, "val_acc": 60.0}
{"epoch": 42, "training_loss": 54.43405456542969, "training_acc": 50.0, "val_loss": 2.747133255004883, "val_acc": 80.0}
{"epoch": 43, "training_loss": 11.89569620192051, "training_acc": 75.0, "val_loss": 26.05814552307129, "val_acc": 60.0}
