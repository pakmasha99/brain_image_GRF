"main_modify.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 4 --task ADNI_sex --input_option yAware --learning_rate 5e0 --batch_size 8 --weight_decay 1e-9 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 698.680101776123, "training_acc": 50.0, "val_loss": 179.874755859375, "val_acc": 60.0}
{"epoch": 1, "training_loss": 391.6558319091797, "training_acc": 50.0, "val_loss": 219.68882751464844, "val_acc": 60.0}
{"epoch": 2, "training_loss": 95.45864067077636, "training_acc": 60.0, "val_loss": 39.332881927490234, "val_acc": 40.0}
{"epoch": 3, "training_loss": 159.39555969238282, "training_acc": 40.0, "val_loss": 56.75068283081055, "val_acc": 60.0}
{"epoch": 4, "training_loss": 270.4546142578125, "training_acc": 30.0, "val_loss": 321.6150817871094, "val_acc": 40.0}
{"epoch": 5, "training_loss": 194.22486877441406, "training_acc": 50.0, "val_loss": 295.4789733886719, "val_acc": 60.0}
{"epoch": 6, "training_loss": 360.562255859375, "training_acc": 50.0, "val_loss": 47.83827590942383, "val_acc": 60.0}
{"epoch": 7, "training_loss": 201.52752380371095, "training_acc": 40.0, "val_loss": 321.6513366699219, "val_acc": 40.0}
{"epoch": 8, "training_loss": 242.49581909179688, "training_acc": 30.0, "val_loss": 163.15109252929688, "val_acc": 60.0}
{"epoch": 9, "training_loss": 142.8728012084961, "training_acc": 50.0, "val_loss": 258.279296875, "val_acc": 40.0}
{"epoch": 10, "training_loss": 346.8382263183594, "training_acc": 50.0, "val_loss": 318.59503173828125, "val_acc": 40.0}
{"epoch": 11, "training_loss": 117.0875473022461, "training_acc": 60.0, "val_loss": 261.4889221191406, "val_acc": 60.0}
{"epoch": 12, "training_loss": 334.77980346679686, "training_acc": 50.0, "val_loss": 176.90130615234375, "val_acc": 60.0}
{"epoch": 13, "training_loss": 127.4813873052597, "training_acc": 60.0, "val_loss": 313.3703308105469, "val_acc": 40.0}
{"epoch": 14, "training_loss": 236.05664672851563, "training_acc": 50.0, "val_loss": 25.12030601501465, "val_acc": 60.0}
{"epoch": 15, "training_loss": 72.92491760253907, "training_acc": 50.0, "val_loss": 58.426971435546875, "val_acc": 40.0}
{"epoch": 16, "training_loss": 80.28542785644531, "training_acc": 50.0, "val_loss": 79.55391693115234, "val_acc": 60.0}
{"epoch": 17, "training_loss": 145.50060424804687, "training_acc": 50.0, "val_loss": 45.16817855834961, "val_acc": 40.0}
{"epoch": 18, "training_loss": 25.779442453384398, "training_acc": 60.0, "val_loss": 68.39276123046875, "val_acc": 60.0}
{"epoch": 19, "training_loss": 64.9216194152832, "training_acc": 55.0, "val_loss": 208.38235473632812, "val_acc": 40.0}
{"epoch": 20, "training_loss": 120.74547424316407, "training_acc": 50.0, "val_loss": 72.2665786743164, "val_acc": 60.0}
{"epoch": 21, "training_loss": 92.80103454589843, "training_acc": 40.0, "val_loss": 181.14663696289062, "val_acc": 40.0}
{"epoch": 22, "training_loss": 128.62410888671874, "training_acc": 40.0, "val_loss": 133.32728576660156, "val_acc": 60.0}
{"epoch": 23, "training_loss": 115.84050140380859, "training_acc": 50.0, "val_loss": 91.72969055175781, "val_acc": 40.0}
{"epoch": 24, "training_loss": 45.62259140014648, "training_acc": 60.0, "val_loss": 110.367431640625, "val_acc": 60.0}
{"epoch": 25, "training_loss": 122.66981506347656, "training_acc": 40.0, "val_loss": 36.35352325439453, "val_acc": 40.0}
{"epoch": 26, "training_loss": 47.05175094604492, "training_acc": 50.0, "val_loss": 53.89917755126953, "val_acc": 40.0}
{"epoch": 27, "training_loss": 55.26674461364746, "training_acc": 50.0, "val_loss": 160.7326202392578, "val_acc": 60.0}
{"epoch": 28, "training_loss": 235.61295166015626, "training_acc": 50.0, "val_loss": 132.80410766601562, "val_acc": 60.0}
{"epoch": 29, "training_loss": 88.55159759521484, "training_acc": 50.0, "val_loss": 72.35428619384766, "val_acc": 40.0}
{"epoch": 30, "training_loss": 32.12031154632568, "training_acc": 60.0, "val_loss": 24.56667137145996, "val_acc": 40.0}
{"epoch": 31, "training_loss": 5.221087772841566, "training_acc": 75.0, "val_loss": 13.367042541503906, "val_acc": 60.0}
{"epoch": 32, "training_loss": 91.81009521484376, "training_acc": 30.0, "val_loss": 16.3364200592041, "val_acc": 60.0}
{"epoch": 33, "training_loss": 27.22882843017578, "training_acc": 50.0, "val_loss": 40.94503402709961, "val_acc": 40.0}
{"epoch": 34, "training_loss": 113.28091278076172, "training_acc": 30.0, "val_loss": 12.621500968933105, "val_acc": 60.0}
{"epoch": 35, "training_loss": 84.56899070739746, "training_acc": 60.0, "val_loss": 215.52659606933594, "val_acc": 40.0}
{"epoch": 36, "training_loss": 137.28301127254963, "training_acc": 55.0, "val_loss": 174.59043884277344, "val_acc": 60.0}
{"epoch": 37, "training_loss": 185.59724082946778, "training_acc": 50.0, "val_loss": 194.55662536621094, "val_acc": 40.0}
{"epoch": 38, "training_loss": 206.99828491210937, "training_acc": 50.0, "val_loss": 113.96327209472656, "val_acc": 40.0}
{"epoch": 39, "training_loss": 87.37705841064454, "training_acc": 60.0, "val_loss": 175.15530395507812, "val_acc": 60.0}
{"epoch": 40, "training_loss": 148.84663009643555, "training_acc": 50.0, "val_loss": 90.39703369140625, "val_acc": 40.0}
{"epoch": 41, "training_loss": 39.179925537109376, "training_acc": 70.0, "val_loss": 97.27182006835938, "val_acc": 60.0}
{"epoch": 42, "training_loss": 91.80538940429688, "training_acc": 60.0, "val_loss": 110.8764877319336, "val_acc": 40.0}
{"epoch": 43, "training_loss": 73.06258926391601, "training_acc": 50.0, "val_loss": 22.759735107421875, "val_acc": 60.0}
{"epoch": 44, "training_loss": 8.745087814331054, "training_acc": 75.0, "val_loss": 20.99627113342285, "val_acc": 60.0}
{"epoch": 45, "training_loss": 22.591264152526854, "training_acc": 60.0, "val_loss": 59.16314697265625, "val_acc": 40.0}
{"epoch": 46, "training_loss": 61.993116760253905, "training_acc": 50.0, "val_loss": 12.607559204101562, "val_acc": 40.0}
{"epoch": 47, "training_loss": 65.93718250989915, "training_acc": 55.0, "val_loss": 112.84392547607422, "val_acc": 60.0}
{"epoch": 48, "training_loss": 234.44794311523438, "training_acc": 50.0, "val_loss": 113.58556365966797, "val_acc": 60.0}
{"epoch": 49, "training_loss": 178.08241271972656, "training_acc": 40.0, "val_loss": 219.1285858154297, "val_acc": 40.0}
{"epoch": 50, "training_loss": 179.29224548339843, "training_acc": 35.0, "val_loss": 184.04244995117188, "val_acc": 60.0}
{"epoch": 51, "training_loss": 144.70992584228514, "training_acc": 50.0, "val_loss": 297.87677001953125, "val_acc": 40.0}
{"epoch": 52, "training_loss": 357.78662109375, "training_acc": 50.0, "val_loss": 460.26123046875, "val_acc": 40.0}
{"epoch": 53, "training_loss": 257.1231628417969, "training_acc": 50.0, "val_loss": 159.24813842773438, "val_acc": 60.0}
{"epoch": 54, "training_loss": 182.91680603027345, "training_acc": 50.0, "val_loss": 45.324886322021484, "val_acc": 40.0}
{"epoch": 55, "training_loss": 40.87392044067383, "training_acc": 50.0, "val_loss": 85.66680145263672, "val_acc": 60.0}
{"epoch": 56, "training_loss": 131.68386535644532, "training_acc": 50.0, "val_loss": 79.78663635253906, "val_acc": 40.0}
{"epoch": 57, "training_loss": 163.94635772705078, "training_acc": 50.0, "val_loss": 25.231937408447266, "val_acc": 40.0}
{"epoch": 58, "training_loss": 249.99394989013672, "training_acc": 30.0, "val_loss": 285.6510314941406, "val_acc": 60.0}
{"epoch": 59, "training_loss": 259.0036828011274, "training_acc": 55.0, "val_loss": 235.51611328125, "val_acc": 40.0}
{"epoch": 60, "training_loss": 219.19427185058595, "training_acc": 50.0, "val_loss": 160.33084106445312, "val_acc": 40.0}
{"epoch": 61, "training_loss": 97.99541015625, "training_acc": 50.0, "val_loss": 83.5755844116211, "val_acc": 60.0}
{"epoch": 62, "training_loss": 77.64042510986329, "training_acc": 50.0, "val_loss": 287.0949401855469, "val_acc": 40.0}
{"epoch": 63, "training_loss": 217.6466323852539, "training_acc": 50.0, "val_loss": 49.90987777709961, "val_acc": 60.0}
{"epoch": 64, "training_loss": 69.3643593788147, "training_acc": 50.0, "val_loss": 88.78689575195312, "val_acc": 40.0}
{"epoch": 65, "training_loss": 56.797577667236325, "training_acc": 50.0, "val_loss": 1.40900438054814e-05, "val_acc": 100.0}
{"epoch": 66, "training_loss": 3.946738141775131, "training_acc": 80.0, "val_loss": 7.656463623046875, "val_acc": 40.0}
{"epoch": 67, "training_loss": 1.5641431927680969, "training_acc": 85.0, "val_loss": 34.66274642944336, "val_acc": 60.0}
{"epoch": 68, "training_loss": 19.416464233398436, "training_acc": 60.0, "val_loss": 42.48124313354492, "val_acc": 60.0}
{"epoch": 69, "training_loss": 42.297923469543456, "training_acc": 50.0, "val_loss": 41.49049758911133, "val_acc": 60.0}
{"epoch": 70, "training_loss": 43.3120620727539, "training_acc": 50.0, "val_loss": 17.037996292114258, "val_acc": 40.0}
{"epoch": 71, "training_loss": 15.962511539459229, "training_acc": 65.0, "val_loss": 0.0001650605845497921, "val_acc": 100.0}
{"epoch": 72, "training_loss": 3.4953870296478273, "training_acc": 85.0, "val_loss": 29.875349044799805, "val_acc": 60.0}
{"epoch": 73, "training_loss": 31.296685791015626, "training_acc": 60.0, "val_loss": 173.73928833007812, "val_acc": 40.0}
{"epoch": 74, "training_loss": 95.3694629070742, "training_acc": 60.0, "val_loss": 100.8099136352539, "val_acc": 60.0}
{"epoch": 75, "training_loss": 130.550537109375, "training_acc": 50.0, "val_loss": 119.2471923828125, "val_acc": 40.0}
{"epoch": 76, "training_loss": 123.16376953125, "training_acc": 50.0, "val_loss": 38.6381950378418, "val_acc": 40.0}
{"epoch": 77, "training_loss": 103.52008056640625, "training_acc": 40.0, "val_loss": 82.99333953857422, "val_acc": 60.0}
{"epoch": 78, "training_loss": 88.67375793457032, "training_acc": 40.0, "val_loss": 4.248649597167969, "val_acc": 60.0}
{"epoch": 79, "training_loss": 52.50556988716126, "training_acc": 60.0, "val_loss": 142.2344512939453, "val_acc": 40.0}
{"epoch": 80, "training_loss": 186.4657470703125, "training_acc": 50.0, "val_loss": 97.6545639038086, "val_acc": 40.0}
{"epoch": 81, "training_loss": 187.9825866699219, "training_acc": 40.0, "val_loss": 212.92967224121094, "val_acc": 60.0}
{"epoch": 82, "training_loss": 205.21564025878905, "training_acc": 40.0, "val_loss": 207.3778076171875, "val_acc": 40.0}
{"epoch": 83, "training_loss": 162.23998413085937, "training_acc": 30.0, "val_loss": 22.911598205566406, "val_acc": 60.0}
{"epoch": 84, "training_loss": 54.587606048583986, "training_acc": 50.0, "val_loss": 10.255404472351074, "val_acc": 40.0}
