"main_modify.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 4 --task ADNI_sex --input_option yAware --learning_rate 1e0 --batch_size 16 --weight_decay 1e-5 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 43.141915512084964, "training_acc": 50.0, "val_loss": 72.06952667236328, "val_acc": 40.0}
{"epoch": 1, "training_loss": 90.02703857421875, "training_acc": 40.0, "val_loss": 110.42327117919922, "val_acc": 60.0}
{"epoch": 2, "training_loss": 133.39582138061525, "training_acc": 50.0, "val_loss": 30.403411865234375, "val_acc": 60.0}
{"epoch": 3, "training_loss": 49.94683990478516, "training_acc": 40.0, "val_loss": 86.41767883300781, "val_acc": 40.0}
{"epoch": 4, "training_loss": 71.90599365234375, "training_acc": 50.0, "val_loss": 32.20273971557617, "val_acc": 40.0}
{"epoch": 5, "training_loss": 20.469365882873536, "training_acc": 60.0, "val_loss": 34.45804977416992, "val_acc": 60.0}
{"epoch": 6, "training_loss": 41.39498748779297, "training_acc": 50.0, "val_loss": 7.559957981109619, "val_acc": 60.0}
{"epoch": 7, "training_loss": 20.272359466552736, "training_acc": 40.0, "val_loss": 55.14297103881836, "val_acc": 40.0}
{"epoch": 8, "training_loss": 40.39572448730469, "training_acc": 50.0, "val_loss": 18.13451385498047, "val_acc": 60.0}
{"epoch": 9, "training_loss": 23.69586753845215, "training_acc": 50.0, "val_loss": 37.032928466796875, "val_acc": 60.0}
{"epoch": 10, "training_loss": 41.62994194030762, "training_acc": 50.0, "val_loss": 14.467187881469727, "val_acc": 40.0}
{"epoch": 11, "training_loss": 12.753964805603028, "training_acc": 50.0, "val_loss": 22.913076400756836, "val_acc": 40.0}
{"epoch": 12, "training_loss": 16.032745265960692, "training_acc": 50.0, "val_loss": 4.639567852020264, "val_acc": 60.0}
{"epoch": 13, "training_loss": 9.964190673828124, "training_acc": 40.0, "val_loss": 11.128019332885742, "val_acc": 40.0}
{"epoch": 14, "training_loss": 11.523320770263672, "training_acc": 50.0, "val_loss": 22.30778694152832, "val_acc": 60.0}
{"epoch": 15, "training_loss": 23.52631607055664, "training_acc": 50.0, "val_loss": 28.600500106811523, "val_acc": 40.0}
{"epoch": 16, "training_loss": 25.515374755859376, "training_acc": 50.0, "val_loss": 27.600269317626953, "val_acc": 40.0}
{"epoch": 17, "training_loss": 27.432369995117188, "training_acc": 30.0, "val_loss": 4.114696502685547, "val_acc": 60.0}
{"epoch": 18, "training_loss": 4.904081726074219, "training_acc": 60.0, "val_loss": 40.5142707824707, "val_acc": 40.0}
{"epoch": 19, "training_loss": 32.304955673217776, "training_acc": 50.0, "val_loss": 2.653099775314331, "val_acc": 40.0}
{"epoch": 20, "training_loss": 12.90733757019043, "training_acc": 40.0, "val_loss": 35.27339172363281, "val_acc": 60.0}
{"epoch": 21, "training_loss": 39.15789222717285, "training_acc": 50.0, "val_loss": 6.680690765380859, "val_acc": 40.0}
{"epoch": 22, "training_loss": 7.168344879150391, "training_acc": 50.0, "val_loss": 5.881660461425781, "val_acc": 40.0}
{"epoch": 23, "training_loss": 7.916299819946289, "training_acc": 50.0, "val_loss": 26.064167022705078, "val_acc": 60.0}
{"epoch": 24, "training_loss": 27.3536376953125, "training_acc": 50.0, "val_loss": 23.98910140991211, "val_acc": 40.0}
{"epoch": 25, "training_loss": 27.936611938476563, "training_acc": 50.0, "val_loss": 25.26789665222168, "val_acc": 40.0}
{"epoch": 26, "training_loss": 12.29036865234375, "training_acc": 70.0, "val_loss": 34.539466857910156, "val_acc": 60.0}
{"epoch": 27, "training_loss": 42.65462951660156, "training_acc": 50.0, "val_loss": 29.74273681640625, "val_acc": 60.0}
{"epoch": 28, "training_loss": 28.25092363357544, "training_acc": 50.0, "val_loss": 52.841461181640625, "val_acc": 40.0}
{"epoch": 29, "training_loss": 45.33934631347656, "training_acc": 50.0, "val_loss": 89.37574005126953, "val_acc": 40.0}
{"epoch": 30, "training_loss": 72.0268497467041, "training_acc": 50.0, "val_loss": 44.41048812866211, "val_acc": 40.0}
{"epoch": 31, "training_loss": 33.70783653259277, "training_acc": 40.0, "val_loss": 12.844290733337402, "val_acc": 60.0}
{"epoch": 32, "training_loss": 11.434818077087403, "training_acc": 50.0, "val_loss": 31.0185489654541, "val_acc": 40.0}
{"epoch": 33, "training_loss": 25.453242111206055, "training_acc": 50.0, "val_loss": 27.560956954956055, "val_acc": 40.0}
{"epoch": 34, "training_loss": 18.32331712245941, "training_acc": 55.0, "val_loss": 11.93073844909668, "val_acc": 60.0}
{"epoch": 35, "training_loss": 10.3234432220459, "training_acc": 50.0, "val_loss": 30.857397079467773, "val_acc": 40.0}
{"epoch": 36, "training_loss": 25.974948120117187, "training_acc": 50.0, "val_loss": 21.042804718017578, "val_acc": 40.0}
{"epoch": 37, "training_loss": 23.80321350097656, "training_acc": 30.0, "val_loss": 12.514592170715332, "val_acc": 60.0}
{"epoch": 38, "training_loss": 7.51593652343181, "training_acc": 70.0, "val_loss": 28.29396629333496, "val_acc": 40.0}
{"epoch": 39, "training_loss": 21.490070343017578, "training_acc": 50.0, "val_loss": 2.4859707355499268, "val_acc": 20.0}
{"epoch": 40, "training_loss": 2.9005582332611084, "training_acc": 70.0, "val_loss": 30.4019718170166, "val_acc": 60.0}
{"epoch": 41, "training_loss": 33.6735122680664, "training_acc": 50.0, "val_loss": 11.309798240661621, "val_acc": 40.0}
{"epoch": 42, "training_loss": 10.067908096313477, "training_acc": 50.0, "val_loss": 36.55936813354492, "val_acc": 40.0}
{"epoch": 43, "training_loss": 26.307678031921387, "training_acc": 50.0, "val_loss": 16.682388305664062, "val_acc": 60.0}
{"epoch": 44, "training_loss": 20.533379364013673, "training_acc": 50.0, "val_loss": 17.16614532470703, "val_acc": 60.0}
{"epoch": 45, "training_loss": 16.30674800872803, "training_acc": 50.0, "val_loss": 18.291887283325195, "val_acc": 40.0}
{"epoch": 46, "training_loss": 11.480514299869537, "training_acc": 55.0, "val_loss": 17.874591827392578, "val_acc": 60.0}
{"epoch": 47, "training_loss": 20.09912109375, "training_acc": 50.0, "val_loss": 5.230509281158447, "val_acc": 40.0}
{"epoch": 48, "training_loss": 3.5086898803710938, "training_acc": 50.0, "val_loss": 2.0322394371032715, "val_acc": 60.0}
{"epoch": 49, "training_loss": 1.6210914134979248, "training_acc": 70.0, "val_loss": 3.481726884841919, "val_acc": 40.0}
{"epoch": 50, "training_loss": 2.258519744873047, "training_acc": 45.0, "val_loss": 17.292367935180664, "val_acc": 40.0}
{"epoch": 51, "training_loss": 13.927301174402032, "training_acc": 50.0, "val_loss": 2.075416326522827, "val_acc": 60.0}
{"epoch": 52, "training_loss": 1.5428614377975465, "training_acc": 70.0, "val_loss": 7.023977756500244, "val_acc": 40.0}
{"epoch": 53, "training_loss": 4.370203852653503, "training_acc": 60.0, "val_loss": 2.9802377223968506, "val_acc": 60.0}
{"epoch": 54, "training_loss": 2.1502789497375487, "training_acc": 70.0, "val_loss": 3.5508415699005127, "val_acc": 60.0}
{"epoch": 55, "training_loss": 1.4801605552434922, "training_acc": 65.0, "val_loss": 2.2727110385894775, "val_acc": 40.0}
{"epoch": 56, "training_loss": 2.00920090675354, "training_acc": 60.0, "val_loss": 24.517858505249023, "val_acc": 60.0}
{"epoch": 57, "training_loss": 28.126777267456056, "training_acc": 50.0, "val_loss": 28.913305282592773, "val_acc": 60.0}
{"epoch": 58, "training_loss": 28.498801231384277, "training_acc": 50.0, "val_loss": 35.78607177734375, "val_acc": 40.0}
{"epoch": 59, "training_loss": 30.14999122619629, "training_acc": 50.0, "val_loss": 55.90093994140625, "val_acc": 40.0}
{"epoch": 60, "training_loss": 42.070757675170896, "training_acc": 50.0, "val_loss": 8.288548469543457, "val_acc": 60.0}
{"epoch": 61, "training_loss": 9.173707962036133, "training_acc": 50.0, "val_loss": 11.431467056274414, "val_acc": 60.0}
{"epoch": 62, "training_loss": 8.32648458480835, "training_acc": 60.0, "val_loss": 31.707794189453125, "val_acc": 40.0}
{"epoch": 63, "training_loss": 22.32604217529297, "training_acc": 50.0, "val_loss": 13.760171890258789, "val_acc": 60.0}
{"epoch": 64, "training_loss": 15.759878540039063, "training_acc": 50.0, "val_loss": 15.607696533203125, "val_acc": 60.0}
{"epoch": 65, "training_loss": 11.53532691001892, "training_acc": 60.0, "val_loss": 26.983469009399414, "val_acc": 40.0}
{"epoch": 66, "training_loss": 20.15761947631836, "training_acc": 50.0, "val_loss": 16.12273406982422, "val_acc": 60.0}
{"epoch": 67, "training_loss": 20.470569610595703, "training_acc": 50.0, "val_loss": 13.074984550476074, "val_acc": 60.0}
