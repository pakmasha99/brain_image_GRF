"main_modify.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 2 --task ADNI_sex --input_option yAware --learning_rate 1e0 --batch_size 16 --weight_decay 1e-5 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 43.34260921478271, "training_acc": 50.0, "val_loss": 57.216426849365234, "val_acc": 60.0}
{"epoch": 1, "training_loss": 95.53407592773438, "training_acc": 40.0, "val_loss": 140.67420959472656, "val_acc": 40.0}
{"epoch": 2, "training_loss": 109.75085144042968, "training_acc": 50.0, "val_loss": 5.104480743408203, "val_acc": 40.0}
{"epoch": 3, "training_loss": 22.479832458496094, "training_acc": 50.0, "val_loss": 113.69255828857422, "val_acc": 60.0}
{"epoch": 4, "training_loss": 145.12673950195312, "training_acc": 50.0, "val_loss": 90.8561019897461, "val_acc": 60.0}
{"epoch": 5, "training_loss": 96.05245819091797, "training_acc": 50.0, "val_loss": 40.81876754760742, "val_acc": 40.0}
{"epoch": 6, "training_loss": 38.81759796142578, "training_acc": 50.0, "val_loss": 134.0229949951172, "val_acc": 40.0}
{"epoch": 7, "training_loss": 111.4294647216797, "training_acc": 50.0, "val_loss": 114.60243225097656, "val_acc": 40.0}
{"epoch": 8, "training_loss": 91.7446849822998, "training_acc": 50.0, "val_loss": 9.22696590423584, "val_acc": 40.0}
{"epoch": 9, "training_loss": 32.86612243652344, "training_acc": 30.0, "val_loss": 63.3871955871582, "val_acc": 60.0}
{"epoch": 10, "training_loss": 77.96885375976562, "training_acc": 50.0, "val_loss": 30.637113571166992, "val_acc": 60.0}
{"epoch": 11, "training_loss": 39.68867797851563, "training_acc": 40.0, "val_loss": 41.64954376220703, "val_acc": 40.0}
{"epoch": 12, "training_loss": 33.747500610351565, "training_acc": 50.0, "val_loss": 8.387763023376465, "val_acc": 40.0}
{"epoch": 13, "training_loss": 7.89434928894043, "training_acc": 60.0, "val_loss": 45.23942184448242, "val_acc": 60.0}
{"epoch": 14, "training_loss": 59.87660217285156, "training_acc": 50.0, "val_loss": 25.029951095581055, "val_acc": 60.0}
{"epoch": 15, "training_loss": 28.54135208129883, "training_acc": 50.0, "val_loss": 49.465267181396484, "val_acc": 40.0}
{"epoch": 16, "training_loss": 41.531961059570314, "training_acc": 50.0, "val_loss": 31.573850631713867, "val_acc": 40.0}
{"epoch": 17, "training_loss": 15.686050820274977, "training_acc": 70.0, "val_loss": 24.68581199645996, "val_acc": 60.0}
{"epoch": 18, "training_loss": 32.14821853637695, "training_acc": 50.0, "val_loss": 16.340627670288086, "val_acc": 60.0}
{"epoch": 19, "training_loss": 15.632131195068359, "training_acc": 60.0, "val_loss": 33.95536804199219, "val_acc": 40.0}
{"epoch": 20, "training_loss": 27.437176132202147, "training_acc": 50.0, "val_loss": 1.9211758375167847, "val_acc": 40.0}
{"epoch": 21, "training_loss": 11.955663776397705, "training_acc": 40.0, "val_loss": 32.77326202392578, "val_acc": 60.0}
{"epoch": 22, "training_loss": 37.402687072753906, "training_acc": 50.0, "val_loss": 15.292335510253906, "val_acc": 40.0}
{"epoch": 23, "training_loss": 18.321737670898436, "training_acc": 50.0, "val_loss": 25.592975616455078, "val_acc": 40.0}
{"epoch": 24, "training_loss": 18.44531831741333, "training_acc": 50.0, "val_loss": 11.94501781463623, "val_acc": 60.0}
{"epoch": 25, "training_loss": 12.585007762908935, "training_acc": 50.0, "val_loss": 33.887001037597656, "val_acc": 40.0}
{"epoch": 26, "training_loss": 31.384113311767578, "training_acc": 50.0, "val_loss": 23.60651206970215, "val_acc": 40.0}
{"epoch": 27, "training_loss": 18.740296173095704, "training_acc": 50.0, "val_loss": 24.19866371154785, "val_acc": 60.0}
{"epoch": 28, "training_loss": 29.242045974731447, "training_acc": 50.0, "val_loss": 2.217679738998413, "val_acc": 40.0}
{"epoch": 29, "training_loss": 2.090248775482178, "training_acc": 50.0, "val_loss": 1.1385407447814941, "val_acc": 80.0}
{"epoch": 30, "training_loss": 0.33197894096374514, "training_acc": 85.0, "val_loss": 14.76069164276123, "val_acc": 60.0}
{"epoch": 31, "training_loss": 16.449465942382812, "training_acc": 50.0, "val_loss": 26.979257583618164, "val_acc": 40.0}
{"epoch": 32, "training_loss": 23.464429092407226, "training_acc": 50.0, "val_loss": 19.685760498046875, "val_acc": 40.0}
{"epoch": 33, "training_loss": 19.617851638793944, "training_acc": 40.0, "val_loss": 14.434382438659668, "val_acc": 60.0}
{"epoch": 34, "training_loss": 17.443701457977294, "training_acc": 40.0, "val_loss": 5.427639007568359, "val_acc": 60.0}
{"epoch": 35, "training_loss": 7.9006952285766605, "training_acc": 40.0, "val_loss": 9.427103996276855, "val_acc": 60.0}
{"epoch": 36, "training_loss": 11.781452941894532, "training_acc": 50.0, "val_loss": 22.009668350219727, "val_acc": 40.0}
{"epoch": 37, "training_loss": 19.08016357421875, "training_acc": 50.0, "val_loss": 16.14468002319336, "val_acc": 40.0}
{"epoch": 38, "training_loss": 21.339647674560545, "training_acc": 30.0, "val_loss": 11.29541015625, "val_acc": 60.0}
{"epoch": 39, "training_loss": 10.715574169158936, "training_acc": 60.0, "val_loss": 22.499547958374023, "val_acc": 40.0}
{"epoch": 40, "training_loss": 16.34493818283081, "training_acc": 50.0, "val_loss": 13.603304862976074, "val_acc": 60.0}
{"epoch": 41, "training_loss": 18.62795181274414, "training_acc": 50.0, "val_loss": 6.5022125244140625, "val_acc": 60.0}
{"epoch": 42, "training_loss": 15.270394897460937, "training_acc": 40.0, "val_loss": 32.91862869262695, "val_acc": 40.0}
{"epoch": 43, "training_loss": 21.926947784423827, "training_acc": 50.0, "val_loss": 26.56353759765625, "val_acc": 60.0}
{"epoch": 44, "training_loss": 42.248854064941405, "training_acc": 50.0, "val_loss": 45.95138931274414, "val_acc": 60.0}
{"epoch": 45, "training_loss": 57.874505615234376, "training_acc": 50.0, "val_loss": 4.229696273803711, "val_acc": 60.0}
{"epoch": 46, "training_loss": 21.179865646362305, "training_acc": 30.0, "val_loss": 50.749114990234375, "val_acc": 40.0}
{"epoch": 47, "training_loss": 39.81494083404541, "training_acc": 50.0, "val_loss": 1.0088094472885132, "val_acc": 40.0}
{"epoch": 48, "training_loss": 4.6371557235717775, "training_acc": 50.0, "val_loss": 5.802797794342041, "val_acc": 40.0}
{"epoch": 49, "training_loss": 3.7371498107910157, "training_acc": 50.0, "val_loss": 12.366819381713867, "val_acc": 60.0}
{"epoch": 50, "training_loss": 16.225762176513673, "training_acc": 50.0, "val_loss": 10.709118843078613, "val_acc": 40.0}
{"epoch": 51, "training_loss": 8.424668216705323, "training_acc": 50.0, "val_loss": 6.830451965332031, "val_acc": 40.0}
{"epoch": 52, "training_loss": 7.4990589141845705, "training_acc": 50.0, "val_loss": 16.58717155456543, "val_acc": 60.0}
{"epoch": 53, "training_loss": 18.088994216918945, "training_acc": 50.0, "val_loss": 32.56120681762695, "val_acc": 40.0}
{"epoch": 54, "training_loss": 30.50850830078125, "training_acc": 50.0, "val_loss": 29.0089054107666, "val_acc": 40.0}
{"epoch": 55, "training_loss": 16.79883189201355, "training_acc": 60.0, "val_loss": 19.569608688354492, "val_acc": 60.0}
{"epoch": 56, "training_loss": 24.50546340942383, "training_acc": 50.0, "val_loss": 1.1332056522369385, "val_acc": 40.0}
{"epoch": 57, "training_loss": 3.8296625137329103, "training_acc": 75.0, "val_loss": 56.09624099731445, "val_acc": 40.0}
{"epoch": 58, "training_loss": 45.68912544250488, "training_acc": 50.0, "val_loss": 32.7241325378418, "val_acc": 40.0}
{"epoch": 59, "training_loss": 21.516869211196898, "training_acc": 50.0, "val_loss": 10.02701473236084, "val_acc": 60.0}
{"epoch": 60, "training_loss": 11.943197644501925, "training_acc": 55.0, "val_loss": 13.053847312927246, "val_acc": 40.0}
{"epoch": 61, "training_loss": 8.972964942455292, "training_acc": 50.0, "val_loss": 2.1438632011413574, "val_acc": 60.0}
{"epoch": 62, "training_loss": 0.2928259015083313, "training_acc": 90.0, "val_loss": 10.82269287109375, "val_acc": 60.0}
{"epoch": 63, "training_loss": 12.741018867492675, "training_acc": 50.0, "val_loss": 18.58026123046875, "val_acc": 40.0}
{"epoch": 64, "training_loss": 15.115924835205078, "training_acc": 50.0, "val_loss": 2.3416965007781982, "val_acc": 60.0}
{"epoch": 65, "training_loss": 6.975524282455444, "training_acc": 65.0, "val_loss": 11.666369438171387, "val_acc": 60.0}
{"epoch": 66, "training_loss": 17.1330078125, "training_acc": 40.0, "val_loss": 9.15747356414795, "val_acc": 40.0}
