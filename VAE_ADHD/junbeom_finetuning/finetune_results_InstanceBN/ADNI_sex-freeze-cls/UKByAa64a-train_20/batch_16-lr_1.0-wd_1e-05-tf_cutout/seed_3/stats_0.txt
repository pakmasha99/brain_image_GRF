"main_modify.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 3 --task ADNI_sex --input_option yAware --learning_rate 1e0 --batch_size 16 --weight_decay 1e-5 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 42.5030170917511, "training_acc": 50.0, "val_loss": 45.314632415771484, "val_acc": 60.0}
{"epoch": 1, "training_loss": 51.95003128051758, "training_acc": 60.0, "val_loss": 258.0883483886719, "val_acc": 40.0}
{"epoch": 2, "training_loss": 214.4475524902344, "training_acc": 50.0, "val_loss": 185.7670135498047, "val_acc": 40.0}
{"epoch": 3, "training_loss": 135.97399139404297, "training_acc": 50.0, "val_loss": 45.199092864990234, "val_acc": 60.0}
{"epoch": 4, "training_loss": 61.468963623046875, "training_acc": 50.0, "val_loss": 107.76564025878906, "val_acc": 60.0}
{"epoch": 5, "training_loss": 132.76049041748047, "training_acc": 50.0, "val_loss": 67.88494110107422, "val_acc": 60.0}
{"epoch": 6, "training_loss": 67.45490951538086, "training_acc": 50.0, "val_loss": 75.32958221435547, "val_acc": 40.0}
{"epoch": 7, "training_loss": 79.235205078125, "training_acc": 50.0, "val_loss": 146.7992706298828, "val_acc": 40.0}
{"epoch": 8, "training_loss": 117.86551818847656, "training_acc": 50.0, "val_loss": 66.67736053466797, "val_acc": 40.0}
{"epoch": 9, "training_loss": 39.30095458030701, "training_acc": 60.0, "val_loss": 39.41896438598633, "val_acc": 60.0}
{"epoch": 10, "training_loss": 48.777001953125, "training_acc": 50.0, "val_loss": 49.892333984375, "val_acc": 60.0}
{"epoch": 11, "training_loss": 61.822381591796876, "training_acc": 50.0, "val_loss": 11.555709838867188, "val_acc": 60.0}
{"epoch": 12, "training_loss": 12.10998306274414, "training_acc": 60.0, "val_loss": 62.4802360534668, "val_acc": 40.0}
{"epoch": 13, "training_loss": 51.514457321166994, "training_acc": 50.0, "val_loss": 37.11775588989258, "val_acc": 40.0}
{"epoch": 14, "training_loss": 22.476135754585265, "training_acc": 60.0, "val_loss": 19.79056167602539, "val_acc": 60.0}
{"epoch": 15, "training_loss": 23.208513069152833, "training_acc": 50.0, "val_loss": 4.173442363739014, "val_acc": 40.0}
{"epoch": 16, "training_loss": 3.0995858669281007, "training_acc": 55.0, "val_loss": 7.573487758636475, "val_acc": 40.0}
{"epoch": 17, "training_loss": 5.104960632324219, "training_acc": 60.0, "val_loss": 4.544069290161133, "val_acc": 60.0}
{"epoch": 18, "training_loss": 10.525872802734375, "training_acc": 40.0, "val_loss": 10.815342903137207, "val_acc": 40.0}
{"epoch": 19, "training_loss": 11.528481674194335, "training_acc": 50.0, "val_loss": 24.254064559936523, "val_acc": 60.0}
{"epoch": 20, "training_loss": 26.123431396484374, "training_acc": 50.0, "val_loss": 29.109365463256836, "val_acc": 40.0}
{"epoch": 21, "training_loss": 26.706966400146484, "training_acc": 50.0, "val_loss": 27.651037216186523, "val_acc": 40.0}
{"epoch": 22, "training_loss": 24.351786804199218, "training_acc": 40.0, "val_loss": 9.38048267364502, "val_acc": 60.0}
{"epoch": 23, "training_loss": 13.716444396972657, "training_acc": 40.0, "val_loss": 3.5435683727264404, "val_acc": 40.0}
{"epoch": 24, "training_loss": 7.428419494628907, "training_acc": 50.0, "val_loss": 25.31664276123047, "val_acc": 60.0}
{"epoch": 25, "training_loss": 26.959335708618163, "training_acc": 50.0, "val_loss": 25.422740936279297, "val_acc": 40.0}
{"epoch": 26, "training_loss": 23.938879013061523, "training_acc": 50.0, "val_loss": 25.618642807006836, "val_acc": 40.0}
{"epoch": 27, "training_loss": 22.80942306518555, "training_acc": 40.0, "val_loss": 8.117369651794434, "val_acc": 60.0}
{"epoch": 28, "training_loss": 11.946808624267579, "training_acc": 40.0, "val_loss": 5.304058074951172, "val_acc": 40.0}
{"epoch": 29, "training_loss": 5.48908805847168, "training_acc": 60.0, "val_loss": 27.16106605529785, "val_acc": 60.0}
{"epoch": 30, "training_loss": 30.612156295776366, "training_acc": 50.0, "val_loss": 3.8100411891937256, "val_acc": 40.0}
{"epoch": 31, "training_loss": 7.63352861404419, "training_acc": 50.0, "val_loss": 12.4020357131958, "val_acc": 60.0}
{"epoch": 32, "training_loss": 17.164634704589844, "training_acc": 50.0, "val_loss": 3.3370583057403564, "val_acc": 60.0}
{"epoch": 33, "training_loss": 4.719594955444336, "training_acc": 60.0, "val_loss": 60.31418991088867, "val_acc": 40.0}
{"epoch": 34, "training_loss": 50.69927978515625, "training_acc": 50.0, "val_loss": 44.355220794677734, "val_acc": 40.0}
{"epoch": 35, "training_loss": 28.969807815551757, "training_acc": 50.0, "val_loss": 34.225608825683594, "val_acc": 60.0}
{"epoch": 36, "training_loss": 43.72151641845703, "training_acc": 50.0, "val_loss": 73.33715057373047, "val_acc": 60.0}
{"epoch": 37, "training_loss": 88.78566360473633, "training_acc": 50.0, "val_loss": 53.34206771850586, "val_acc": 60.0}
{"epoch": 38, "training_loss": 57.22293701171875, "training_acc": 50.0, "val_loss": 25.07476234436035, "val_acc": 40.0}
{"epoch": 39, "training_loss": 23.758428192138673, "training_acc": 50.0, "val_loss": 69.21471405029297, "val_acc": 40.0}
{"epoch": 40, "training_loss": 56.35036926269531, "training_acc": 50.0, "val_loss": 14.104156494140625, "val_acc": 40.0}
{"epoch": 41, "training_loss": 21.954243469238282, "training_acc": 40.0, "val_loss": 50.81950759887695, "val_acc": 60.0}
{"epoch": 42, "training_loss": 61.44219055175781, "training_acc": 50.0, "val_loss": 26.458099365234375, "val_acc": 60.0}
{"epoch": 43, "training_loss": 21.852896404266357, "training_acc": 60.0, "val_loss": 48.22354507446289, "val_acc": 40.0}
{"epoch": 44, "training_loss": 42.65921249389648, "training_acc": 50.0, "val_loss": 39.468353271484375, "val_acc": 40.0}
{"epoch": 45, "training_loss": 27.56054346561432, "training_acc": 50.0, "val_loss": 35.5394401550293, "val_acc": 60.0}
{"epoch": 46, "training_loss": 52.70169372558594, "training_acc": 50.0, "val_loss": 43.364036560058594, "val_acc": 60.0}
{"epoch": 47, "training_loss": 41.48114700317383, "training_acc": 50.0, "val_loss": 43.379966735839844, "val_acc": 40.0}
{"epoch": 48, "training_loss": 40.12367706298828, "training_acc": 50.0, "val_loss": 103.18995666503906, "val_acc": 40.0}
{"epoch": 49, "training_loss": 86.62063903808594, "training_acc": 50.0, "val_loss": 69.34812927246094, "val_acc": 40.0}
{"epoch": 50, "training_loss": 50.711804962158205, "training_acc": 50.0, "val_loss": 31.131017684936523, "val_acc": 60.0}
{"epoch": 51, "training_loss": 43.216619873046874, "training_acc": 50.0, "val_loss": 63.6630859375, "val_acc": 60.0}
