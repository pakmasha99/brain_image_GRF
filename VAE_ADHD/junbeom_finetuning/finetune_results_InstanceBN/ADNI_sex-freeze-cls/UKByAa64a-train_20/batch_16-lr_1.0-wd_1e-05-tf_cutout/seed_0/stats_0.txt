"main_modify.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_sex --input_option yAware --learning_rate 1e0 --batch_size 16 --weight_decay 1e-5 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 64.56227378845215, "training_acc": 50.0, "val_loss": 77.30912017822266, "val_acc": 40.0}
{"epoch": 1, "training_loss": 72.8854736328125, "training_acc": 50.0, "val_loss": 136.29550170898438, "val_acc": 60.0}
{"epoch": 2, "training_loss": 169.31786499023437, "training_acc": 50.0, "val_loss": 104.13612365722656, "val_acc": 60.0}
{"epoch": 3, "training_loss": 111.19458618164063, "training_acc": 50.0, "val_loss": 40.28470993041992, "val_acc": 40.0}
{"epoch": 4, "training_loss": 43.708465576171875, "training_acc": 50.0, "val_loss": 117.30987548828125, "val_acc": 40.0}
{"epoch": 5, "training_loss": 92.74430541992187, "training_acc": 50.0, "val_loss": 32.66329574584961, "val_acc": 40.0}
{"epoch": 6, "training_loss": 30.967500305175783, "training_acc": 50.0, "val_loss": 68.96760559082031, "val_acc": 60.0}
{"epoch": 7, "training_loss": 87.33865051269531, "training_acc": 50.0, "val_loss": 62.3337287902832, "val_acc": 60.0}
{"epoch": 8, "training_loss": 69.47879791259766, "training_acc": 50.0, "val_loss": 24.566831588745117, "val_acc": 40.0}
{"epoch": 9, "training_loss": 22.62497482299805, "training_acc": 50.0, "val_loss": 68.66948699951172, "val_acc": 40.0}
{"epoch": 10, "training_loss": 54.095158386230466, "training_acc": 50.0, "val_loss": 10.882770538330078, "val_acc": 40.0}
{"epoch": 11, "training_loss": 15.839102172851563, "training_acc": 50.0, "val_loss": 56.22562789916992, "val_acc": 60.0}
{"epoch": 12, "training_loss": 69.48639221191407, "training_acc": 50.0, "val_loss": 38.85974884033203, "val_acc": 60.0}
{"epoch": 13, "training_loss": 43.20409872531891, "training_acc": 50.0, "val_loss": 56.778175354003906, "val_acc": 40.0}
{"epoch": 14, "training_loss": 49.04917984008789, "training_acc": 50.0, "val_loss": 91.7332534790039, "val_acc": 40.0}
{"epoch": 15, "training_loss": 72.16491088867187, "training_acc": 50.0, "val_loss": 25.21320152282715, "val_acc": 40.0}
{"epoch": 16, "training_loss": 24.305718994140626, "training_acc": 50.0, "val_loss": 57.63551712036133, "val_acc": 60.0}
{"epoch": 17, "training_loss": 72.33805084228516, "training_acc": 50.0, "val_loss": 52.49050521850586, "val_acc": 60.0}
{"epoch": 18, "training_loss": 60.67278060913086, "training_acc": 50.0, "val_loss": 18.312917709350586, "val_acc": 40.0}
{"epoch": 19, "training_loss": 21.499508666992188, "training_acc": 50.0, "val_loss": 27.61966323852539, "val_acc": 40.0}
{"epoch": 20, "training_loss": 23.55079879760742, "training_acc": 40.0, "val_loss": 10.160168647766113, "val_acc": 60.0}
{"epoch": 21, "training_loss": 12.799452590942384, "training_acc": 40.0, "val_loss": 1.5621012449264526, "val_acc": 60.0}
{"epoch": 22, "training_loss": 3.5530279636383058, "training_acc": 70.0, "val_loss": 9.811500549316406, "val_acc": 60.0}
{"epoch": 23, "training_loss": 8.88262710571289, "training_acc": 60.0, "val_loss": 24.255069732666016, "val_acc": 40.0}
{"epoch": 24, "training_loss": 17.516633605957033, "training_acc": 50.0, "val_loss": 18.250083923339844, "val_acc": 60.0}
{"epoch": 25, "training_loss": 21.581562805175782, "training_acc": 50.0, "val_loss": 17.272380828857422, "val_acc": 60.0}
{"epoch": 26, "training_loss": 16.76421899795532, "training_acc": 50.0, "val_loss": 8.835646629333496, "val_acc": 40.0}
{"epoch": 27, "training_loss": 6.964149475097656, "training_acc": 50.0, "val_loss": 5.113946914672852, "val_acc": 60.0}
{"epoch": 28, "training_loss": 13.819021606445313, "training_acc": 30.0, "val_loss": 10.829379081726074, "val_acc": 40.0}
{"epoch": 29, "training_loss": 15.297113800048828, "training_acc": 40.0, "val_loss": 22.551361083984375, "val_acc": 60.0}
{"epoch": 30, "training_loss": 22.26426010131836, "training_acc": 50.0, "val_loss": 32.423973083496094, "val_acc": 40.0}
{"epoch": 31, "training_loss": 33.380819702148436, "training_acc": 50.0, "val_loss": 25.986621856689453, "val_acc": 40.0}
{"epoch": 32, "training_loss": 16.051216793060302, "training_acc": 60.0, "val_loss": 33.29222869873047, "val_acc": 60.0}
{"epoch": 33, "training_loss": 38.951715087890626, "training_acc": 50.0, "val_loss": 29.428089141845703, "val_acc": 60.0}
{"epoch": 34, "training_loss": 28.541463470458986, "training_acc": 50.0, "val_loss": 36.15205001831055, "val_acc": 40.0}
{"epoch": 35, "training_loss": 34.6333366394043, "training_acc": 50.0, "val_loss": 64.1628646850586, "val_acc": 40.0}
{"epoch": 36, "training_loss": 49.46118927001953, "training_acc": 50.0, "val_loss": 2.9287269115448, "val_acc": 60.0}
{"epoch": 37, "training_loss": 8.30303201675415, "training_acc": 60.0, "val_loss": 13.35538387298584, "val_acc": 60.0}
{"epoch": 38, "training_loss": 14.261122894287109, "training_acc": 50.0, "val_loss": 20.92188835144043, "val_acc": 40.0}
{"epoch": 39, "training_loss": 14.884755063056947, "training_acc": 50.0, "val_loss": 19.04336929321289, "val_acc": 60.0}
{"epoch": 40, "training_loss": 22.81256103515625, "training_acc": 50.0, "val_loss": 2.554069995880127, "val_acc": 60.0}
