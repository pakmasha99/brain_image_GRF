"main_modify.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 5 --task ADNI_sex --input_option yAware --learning_rate 1e0 --batch_size 16 --weight_decay 1e-5 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 21.898114681243896, "training_acc": 60.0, "val_loss": 138.8766326904297, "val_acc": 40.0}
{"epoch": 1, "training_loss": 100.48992919921875, "training_acc": 50.0, "val_loss": 43.37925720214844, "val_acc": 60.0}
{"epoch": 2, "training_loss": 43.34653912782669, "training_acc": 50.0, "val_loss": 10.152983665466309, "val_acc": 40.0}
{"epoch": 3, "training_loss": 19.612249755859374, "training_acc": 40.0, "val_loss": 13.661005020141602, "val_acc": 60.0}
{"epoch": 4, "training_loss": 21.189229583740236, "training_acc": 50.0, "val_loss": 62.66196823120117, "val_acc": 40.0}
{"epoch": 5, "training_loss": 47.83404006958008, "training_acc": 50.0, "val_loss": 14.733288764953613, "val_acc": 60.0}
{"epoch": 6, "training_loss": 22.73436508178711, "training_acc": 50.0, "val_loss": 6.0594987869262695, "val_acc": 60.0}
{"epoch": 7, "training_loss": 4.136371612548828, "training_acc": 70.0, "val_loss": 93.62129974365234, "val_acc": 40.0}
{"epoch": 8, "training_loss": 81.30997314453126, "training_acc": 50.0, "val_loss": 75.67876434326172, "val_acc": 40.0}
{"epoch": 9, "training_loss": 49.00161590576172, "training_acc": 50.0, "val_loss": 47.35627365112305, "val_acc": 60.0}
{"epoch": 10, "training_loss": 66.74207000732422, "training_acc": 50.0, "val_loss": 94.72501373291016, "val_acc": 60.0}
{"epoch": 11, "training_loss": 115.247412109375, "training_acc": 50.0, "val_loss": 62.4003791809082, "val_acc": 60.0}
{"epoch": 12, "training_loss": 62.31949157714844, "training_acc": 50.0, "val_loss": 54.044593811035156, "val_acc": 40.0}
{"epoch": 13, "training_loss": 48.60951156616211, "training_acc": 50.0, "val_loss": 136.9128875732422, "val_acc": 40.0}
{"epoch": 14, "training_loss": 115.23287963867188, "training_acc": 50.0, "val_loss": 109.7072525024414, "val_acc": 40.0}
{"epoch": 15, "training_loss": 77.95137786865234, "training_acc": 50.0, "val_loss": 18.30787467956543, "val_acc": 60.0}
{"epoch": 16, "training_loss": 34.98866271972656, "training_acc": 50.0, "val_loss": 61.05546188354492, "val_acc": 60.0}
{"epoch": 17, "training_loss": 72.12721252441406, "training_acc": 50.0, "val_loss": 24.78230857849121, "val_acc": 60.0}
{"epoch": 18, "training_loss": 38.831668090820315, "training_acc": 30.0, "val_loss": 37.78066635131836, "val_acc": 40.0}
{"epoch": 19, "training_loss": 28.483129501342773, "training_acc": 50.0, "val_loss": 10.499635696411133, "val_acc": 60.0}
{"epoch": 20, "training_loss": 15.031402587890625, "training_acc": 50.0, "val_loss": 3.458799362182617, "val_acc": 60.0}
{"epoch": 21, "training_loss": 5.151586532592773, "training_acc": 60.0, "val_loss": 63.257240295410156, "val_acc": 40.0}
{"epoch": 22, "training_loss": 51.85789566040039, "training_acc": 50.0, "val_loss": 38.918270111083984, "val_acc": 40.0}
{"epoch": 23, "training_loss": 35.279669189453124, "training_acc": 30.0, "val_loss": 7.647252082824707, "val_acc": 60.0}
{"epoch": 24, "training_loss": 6.448272705078125, "training_acc": 60.0, "val_loss": 18.23724365234375, "val_acc": 40.0}
{"epoch": 25, "training_loss": 11.466676950454712, "training_acc": 55.0, "val_loss": 19.534229278564453, "val_acc": 60.0}
{"epoch": 26, "training_loss": 22.714357376098633, "training_acc": 50.0, "val_loss": 13.038907051086426, "val_acc": 60.0}
{"epoch": 27, "training_loss": 17.40631217956543, "training_acc": 40.0, "val_loss": 14.45018196105957, "val_acc": 40.0}
{"epoch": 28, "training_loss": 10.623904991149903, "training_acc": 50.0, "val_loss": 7.890860080718994, "val_acc": 60.0}
{"epoch": 29, "training_loss": 10.577764129638672, "training_acc": 40.0, "val_loss": 3.745448350906372, "val_acc": 40.0}
{"epoch": 30, "training_loss": 3.5726396560668947, "training_acc": 60.0, "val_loss": 28.521549224853516, "val_acc": 60.0}
{"epoch": 31, "training_loss": 32.022640228271484, "training_acc": 50.0, "val_loss": 1.001153826713562, "val_acc": 60.0}
{"epoch": 32, "training_loss": 5.242483448982239, "training_acc": 70.0, "val_loss": 33.63735580444336, "val_acc": 40.0}
{"epoch": 33, "training_loss": 26.95322920679946, "training_acc": 50.0, "val_loss": 11.471598625183105, "val_acc": 60.0}
{"epoch": 34, "training_loss": 11.586495971679687, "training_acc": 50.0, "val_loss": 11.89001750946045, "val_acc": 40.0}
{"epoch": 35, "training_loss": 8.876845169067384, "training_acc": 50.0, "val_loss": 9.059636116027832, "val_acc": 60.0}
{"epoch": 36, "training_loss": 8.957947158813477, "training_acc": 50.0, "val_loss": 20.941308975219727, "val_acc": 40.0}
{"epoch": 37, "training_loss": 17.828418350219728, "training_acc": 50.0, "val_loss": 11.208086013793945, "val_acc": 40.0}
{"epoch": 38, "training_loss": 18.788205718994142, "training_acc": 30.0, "val_loss": 18.709003448486328, "val_acc": 60.0}
{"epoch": 39, "training_loss": 14.614921426773071, "training_acc": 55.0, "val_loss": 35.63785171508789, "val_acc": 40.0}
{"epoch": 40, "training_loss": 28.72795181274414, "training_acc": 50.0, "val_loss": 35.21006393432617, "val_acc": 40.0}
{"epoch": 41, "training_loss": 21.230605125427246, "training_acc": 50.0, "val_loss": 34.4232063293457, "val_acc": 60.0}
{"epoch": 42, "training_loss": 45.11670837402344, "training_acc": 50.0, "val_loss": 56.40760040283203, "val_acc": 60.0}
{"epoch": 43, "training_loss": 63.94855270385742, "training_acc": 50.0, "val_loss": 13.946280479431152, "val_acc": 60.0}
{"epoch": 44, "training_loss": 17.88340530395508, "training_acc": 50.0, "val_loss": 74.06320190429688, "val_acc": 40.0}
{"epoch": 45, "training_loss": 60.469154357910156, "training_acc": 50.0, "val_loss": 59.9061279296875, "val_acc": 40.0}
{"epoch": 46, "training_loss": 41.66239433288574, "training_acc": 50.0, "val_loss": 28.864904403686523, "val_acc": 60.0}
{"epoch": 47, "training_loss": 35.017618560791014, "training_acc": 50.0, "val_loss": 56.64211654663086, "val_acc": 60.0}
{"epoch": 48, "training_loss": 65.30093536376953, "training_acc": 50.0, "val_loss": 25.500228881835938, "val_acc": 60.0}
{"epoch": 49, "training_loss": 25.0340274810791, "training_acc": 50.0, "val_loss": 43.69662857055664, "val_acc": 40.0}
{"epoch": 50, "training_loss": 34.92494659423828, "training_acc": 50.0, "val_loss": 17.72467803955078, "val_acc": 40.0}
