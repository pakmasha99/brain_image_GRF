"main_modify.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 1 --task ADNI_sex --input_option yAware --learning_rate 1e0 --batch_size 16 --weight_decay 1e-5 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 21.69119291305542, "training_acc": 55.0, "val_loss": 78.09894561767578, "val_acc": 40.0}
{"epoch": 1, "training_loss": 50.02939224243164, "training_acc": 65.0, "val_loss": 141.653564453125, "val_acc": 60.0}
{"epoch": 2, "training_loss": 185.73611145019532, "training_acc": 45.0, "val_loss": 26.90726661682129, "val_acc": 60.0}
{"epoch": 3, "training_loss": 49.11708068847656, "training_acc": 45.0, "val_loss": 181.79859924316406, "val_acc": 40.0}
{"epoch": 4, "training_loss": 141.20947265625, "training_acc": 55.0, "val_loss": 153.15188598632812, "val_acc": 40.0}
{"epoch": 5, "training_loss": 107.80381126403809, "training_acc": 55.0, "val_loss": 13.905684471130371, "val_acc": 60.0}
{"epoch": 6, "training_loss": 25.27748260498047, "training_acc": 45.0, "val_loss": 34.970375061035156, "val_acc": 60.0}
{"epoch": 7, "training_loss": 36.6072021484375, "training_acc": 45.0, "val_loss": 70.52889251708984, "val_acc": 40.0}
{"epoch": 8, "training_loss": 56.45331344604492, "training_acc": 55.0, "val_loss": 146.78497314453125, "val_acc": 40.0}
{"epoch": 9, "training_loss": 111.63451538085937, "training_acc": 55.0, "val_loss": 103.3640365600586, "val_acc": 40.0}
{"epoch": 10, "training_loss": 60.51346435546875, "training_acc": 55.0, "val_loss": 38.65553665161133, "val_acc": 60.0}
{"epoch": 11, "training_loss": 62.631901550292966, "training_acc": 45.0, "val_loss": 92.3331298828125, "val_acc": 60.0}
{"epoch": 12, "training_loss": 126.63232421875, "training_acc": 45.0, "val_loss": 62.04696273803711, "val_acc": 60.0}
{"epoch": 13, "training_loss": 74.91730346679688, "training_acc": 45.0, "val_loss": 54.22331619262695, "val_acc": 40.0}
{"epoch": 14, "training_loss": 53.5855224609375, "training_acc": 55.0, "val_loss": 123.71229553222656, "val_acc": 40.0}
{"epoch": 15, "training_loss": 90.57631225585938, "training_acc": 55.0, "val_loss": 86.91751861572266, "val_acc": 40.0}
{"epoch": 16, "training_loss": 56.58844833374023, "training_acc": 55.0, "val_loss": 12.497611999511719, "val_acc": 60.0}
{"epoch": 17, "training_loss": 25.796540832519533, "training_acc": 45.0, "val_loss": 28.939407348632812, "val_acc": 60.0}
{"epoch": 18, "training_loss": 34.74431114196777, "training_acc": 45.0, "val_loss": 44.1796760559082, "val_acc": 40.0}
{"epoch": 19, "training_loss": 39.040837097167966, "training_acc": 55.0, "val_loss": 67.26176452636719, "val_acc": 40.0}
{"epoch": 20, "training_loss": 44.018336868286134, "training_acc": 55.0, "val_loss": 6.374633312225342, "val_acc": 60.0}
{"epoch": 21, "training_loss": 11.122694778442384, "training_acc": 45.0, "val_loss": 16.885400772094727, "val_acc": 60.0}
{"epoch": 22, "training_loss": 22.541476452350615, "training_acc": 45.0, "val_loss": 14.336008071899414, "val_acc": 40.0}
{"epoch": 23, "training_loss": 6.918485879898071, "training_acc": 55.0, "val_loss": 18.38311195373535, "val_acc": 60.0}
{"epoch": 24, "training_loss": 26.468914794921876, "training_acc": 45.0, "val_loss": 9.884982109069824, "val_acc": 60.0}
{"epoch": 25, "training_loss": 19.086611175537108, "training_acc": 35.0, "val_loss": 25.837411880493164, "val_acc": 40.0}
{"epoch": 26, "training_loss": 12.569284248352051, "training_acc": 55.0, "val_loss": 27.030797958374023, "val_acc": 60.0}
{"epoch": 27, "training_loss": 43.73378295898438, "training_acc": 45.0, "val_loss": 31.033878326416016, "val_acc": 60.0}
{"epoch": 28, "training_loss": 35.523552894592285, "training_acc": 45.0, "val_loss": 58.7862548828125, "val_acc": 40.0}
{"epoch": 29, "training_loss": 44.733795928955075, "training_acc": 55.0, "val_loss": 120.8376235961914, "val_acc": 40.0}
{"epoch": 30, "training_loss": 88.30799560546875, "training_acc": 55.0, "val_loss": 91.4046630859375, "val_acc": 40.0}
{"epoch": 31, "training_loss": 57.07362594604492, "training_acc": 55.0, "val_loss": 17.05153465270996, "val_acc": 60.0}
{"epoch": 32, "training_loss": 34.627987670898435, "training_acc": 45.0, "val_loss": 41.82810592651367, "val_acc": 60.0}
{"epoch": 33, "training_loss": 52.32350387573242, "training_acc": 45.0, "val_loss": 16.54735565185547, "val_acc": 40.0}
{"epoch": 34, "training_loss": 11.481625366210938, "training_acc": 55.0, "val_loss": 57.83991622924805, "val_acc": 40.0}
{"epoch": 35, "training_loss": 39.0301513671875, "training_acc": 55.0, "val_loss": 11.778778076171875, "val_acc": 40.0}
{"epoch": 36, "training_loss": 12.799659729003906, "training_acc": 55.0, "val_loss": 47.12742233276367, "val_acc": 60.0}
{"epoch": 37, "training_loss": 66.13113708496094, "training_acc": 45.0, "val_loss": 25.52312660217285, "val_acc": 60.0}
{"epoch": 38, "training_loss": 32.25795974731445, "training_acc": 45.0, "val_loss": 43.98181915283203, "val_acc": 40.0}
{"epoch": 39, "training_loss": 29.677586364746094, "training_acc": 55.0, "val_loss": 34.925682067871094, "val_acc": 40.0}
