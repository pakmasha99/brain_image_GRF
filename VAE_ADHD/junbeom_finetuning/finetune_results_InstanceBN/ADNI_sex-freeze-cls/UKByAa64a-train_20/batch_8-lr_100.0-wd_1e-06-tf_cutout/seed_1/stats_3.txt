"main_modify.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 1 --task ADNI_sex --input_option yAware --learning_rate 1e2 --batch_size 8 --weight_decay 1e-6 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 12086.633279705047, "training_acc": 50.0, "val_loss": 12387.9130859375, "val_acc": 40.0}
{"epoch": 1, "training_loss": 15312.0439453125, "training_acc": 50.0, "val_loss": 12723.0703125, "val_acc": 40.0}
{"epoch": 2, "training_loss": 10005.35673828125, "training_acc": 30.0, "val_loss": 9488.2841796875, "val_acc": 60.0}
{"epoch": 3, "training_loss": 10662.31572265625, "training_acc": 50.0, "val_loss": 967.20751953125, "val_acc": 60.0}
{"epoch": 4, "training_loss": 2649.7770751953126, "training_acc": 60.0, "val_loss": 10194.677734375, "val_acc": 40.0}
{"epoch": 5, "training_loss": 7725.087890625, "training_acc": 50.0, "val_loss": 339.50177001953125, "val_acc": 40.0}
{"epoch": 6, "training_loss": 4637.197155761719, "training_acc": 50.0, "val_loss": 9002.58984375, "val_acc": 60.0}
{"epoch": 7, "training_loss": 9850.7037109375, "training_acc": 50.0, "val_loss": 1649.333984375, "val_acc": 60.0}
{"epoch": 8, "training_loss": 5208.92216796875, "training_acc": 40.0, "val_loss": 13763.796875, "val_acc": 40.0}
{"epoch": 9, "training_loss": 10705.7556640625, "training_acc": 50.0, "val_loss": 6059.1923828125, "val_acc": 40.0}
{"epoch": 10, "training_loss": 4533.451904296875, "training_acc": 30.0, "val_loss": 3623.184326171875, "val_acc": 60.0}
{"epoch": 11, "training_loss": 2716.7320037841796, "training_acc": 60.0, "val_loss": 2253.9453125, "val_acc": 40.0}
{"epoch": 12, "training_loss": 1170.298162841797, "training_acc": 50.0, "val_loss": 4023.4453125, "val_acc": 60.0}
{"epoch": 13, "training_loss": 6718.9513671875, "training_acc": 50.0, "val_loss": 5581.95703125, "val_acc": 60.0}
{"epoch": 14, "training_loss": 5697.408154296875, "training_acc": 30.0, "val_loss": 4068.067626953125, "val_acc": 40.0}
{"epoch": 15, "training_loss": 2467.611474609375, "training_acc": 50.0, "val_loss": 2849.900146484375, "val_acc": 60.0}
{"epoch": 16, "training_loss": 3992.17578125, "training_acc": 50.0, "val_loss": 3001.376953125, "val_acc": 60.0}
{"epoch": 17, "training_loss": 2445.419091796875, "training_acc": 50.0, "val_loss": 5310.09619140625, "val_acc": 40.0}
{"epoch": 18, "training_loss": 3867.393176269531, "training_acc": 50.0, "val_loss": 1467.0740966796875, "val_acc": 60.0}
{"epoch": 19, "training_loss": 1858.4810791015625, "training_acc": 50.0, "val_loss": 1161.1207275390625, "val_acc": 40.0}
{"epoch": 20, "training_loss": 787.1113891601562, "training_acc": 50.0, "val_loss": 781.6100463867188, "val_acc": 60.0}
{"epoch": 21, "training_loss": 956.7347900390625, "training_acc": 50.0, "val_loss": 569.0829467773438, "val_acc": 60.0}
{"epoch": 22, "training_loss": 708.9353034973144, "training_acc": 50.0, "val_loss": 133.66232299804688, "val_acc": 80.0}
{"epoch": 23, "training_loss": 156.32741088867186, "training_acc": 70.0, "val_loss": 738.5787353515625, "val_acc": 40.0}
{"epoch": 24, "training_loss": 590.8702056884765, "training_acc": 40.0, "val_loss": 278.5975646972656, "val_acc": 60.0}
{"epoch": 25, "training_loss": 438.83929443359375, "training_acc": 45.0, "val_loss": 139.9127655029297, "val_acc": 80.0}
{"epoch": 26, "training_loss": 171.0739013671875, "training_acc": 70.0, "val_loss": 1597.4512939453125, "val_acc": 60.0}
{"epoch": 27, "training_loss": 1546.5800048828125, "training_acc": 40.0, "val_loss": 161.3297576904297, "val_acc": 40.0}
{"epoch": 28, "training_loss": 68.89146728515625, "training_acc": 90.0, "val_loss": 322.1374206542969, "val_acc": 40.0}
{"epoch": 29, "training_loss": 207.0494140625, "training_acc": 65.0, "val_loss": 889.7435913085938, "val_acc": 60.0}
{"epoch": 30, "training_loss": 562.89921875, "training_acc": 60.0, "val_loss": 1045.108154296875, "val_acc": 40.0}
{"epoch": 31, "training_loss": 2104.70009765625, "training_acc": 40.0, "val_loss": 135.3603515625, "val_acc": 40.0}
{"epoch": 32, "training_loss": 1839.394757080078, "training_acc": 65.0, "val_loss": 6112.49169921875, "val_acc": 40.0}
{"epoch": 33, "training_loss": 3273.0512756347657, "training_acc": 55.0, "val_loss": 3425.112548828125, "val_acc": 60.0}
{"epoch": 34, "training_loss": 5125.419921875, "training_acc": 50.0, "val_loss": 2859.618408203125, "val_acc": 60.0}
{"epoch": 35, "training_loss": 3238.8337158203126, "training_acc": 40.0, "val_loss": 2316.923828125, "val_acc": 40.0}
{"epoch": 36, "training_loss": 1459.7868286132812, "training_acc": 60.0, "val_loss": 949.36376953125, "val_acc": 60.0}
{"epoch": 37, "training_loss": 2064.9951904296877, "training_acc": 40.0, "val_loss": 2899.949462890625, "val_acc": 40.0}
{"epoch": 38, "training_loss": 1661.3703674316407, "training_acc": 55.0, "val_loss": 1443.051025390625, "val_acc": 60.0}
{"epoch": 39, "training_loss": 1465.3912841796875, "training_acc": 40.0, "val_loss": 540.4674072265625, "val_acc": 60.0}
{"epoch": 40, "training_loss": 204.81405181884764, "training_acc": 70.0, "val_loss": 145.6882781982422, "val_acc": 80.0}
{"epoch": 41, "training_loss": 164.697607421875, "training_acc": 85.0, "val_loss": 199.68511962890625, "val_acc": 80.0}
