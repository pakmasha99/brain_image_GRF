"main_modify.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 2 --task ADNI_sex --input_option yAware --learning_rate 1e2 --batch_size 8 --weight_decay 1e-6 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 10820.488263559342, "training_acc": 45.0, "val_loss": 2926.56640625, "val_acc": 60.0}
{"epoch": 1, "training_loss": 5157.0685546875, "training_acc": 45.0, "val_loss": 6883.61962890625, "val_acc": 40.0}
{"epoch": 2, "training_loss": 8065.090234375, "training_acc": 55.0, "val_loss": 8100.63916015625, "val_acc": 40.0}
{"epoch": 3, "training_loss": 5299.857861328125, "training_acc": 35.0, "val_loss": 1464.4036865234375, "val_acc": 60.0}
{"epoch": 4, "training_loss": 1859.769384765625, "training_acc": 65.0, "val_loss": 5080.38671875, "val_acc": 40.0}
{"epoch": 5, "training_loss": 1990.1479370117188, "training_acc": 65.0, "val_loss": 3173.767822265625, "val_acc": 60.0}
{"epoch": 6, "training_loss": 3270.730241394043, "training_acc": 50.0, "val_loss": 4872.984375, "val_acc": 40.0}
{"epoch": 7, "training_loss": 4589.28740234375, "training_acc": 55.0, "val_loss": 3280.01025390625, "val_acc": 40.0}
{"epoch": 8, "training_loss": 3859.8615234375, "training_acc": 35.0, "val_loss": 2421.354248046875, "val_acc": 60.0}
{"epoch": 9, "training_loss": 1146.8919677734375, "training_acc": 80.0, "val_loss": 5156.95849609375, "val_acc": 40.0}
{"epoch": 10, "training_loss": 2882.7245849609376, "training_acc": 45.0, "val_loss": 510.5160827636719, "val_acc": 40.0}
{"epoch": 11, "training_loss": 416.8352478027344, "training_acc": 55.0, "val_loss": 651.197998046875, "val_acc": 60.0}
{"epoch": 12, "training_loss": 595.1598770141602, "training_acc": 60.0, "val_loss": 2249.2421875, "val_acc": 40.0}
{"epoch": 13, "training_loss": 551.1620971679688, "training_acc": 60.0, "val_loss": 2496.880859375, "val_acc": 40.0}
{"epoch": 14, "training_loss": 1430.6776794433595, "training_acc": 55.0, "val_loss": 2961.431884765625, "val_acc": 60.0}
{"epoch": 15, "training_loss": 5153.6271484375, "training_acc": 45.0, "val_loss": 387.7106018066406, "val_acc": 60.0}
{"epoch": 16, "training_loss": 2717.5950561523437, "training_acc": 60.0, "val_loss": 12500.416015625, "val_acc": 40.0}
{"epoch": 17, "training_loss": 8682.569921875, "training_acc": 55.0, "val_loss": 5703.7587890625, "val_acc": 40.0}
{"epoch": 18, "training_loss": 3338.8830078125, "training_acc": 35.0, "val_loss": 1410.3804931640625, "val_acc": 60.0}
{"epoch": 19, "training_loss": 1585.36357421875, "training_acc": 55.0, "val_loss": 2615.18603515625, "val_acc": 40.0}
{"epoch": 20, "training_loss": 750.1483520507812, "training_acc": 55.0, "val_loss": 2144.815185546875, "val_acc": 40.0}
{"epoch": 21, "training_loss": 1009.9112182617188, "training_acc": 55.0, "val_loss": 3197.935302734375, "val_acc": 60.0}
{"epoch": 22, "training_loss": 4662.9447265625, "training_acc": 45.0, "val_loss": 1127.7738037109375, "val_acc": 60.0}
{"epoch": 23, "training_loss": 5986.639208984375, "training_acc": 25.0, "val_loss": 10936.1708984375, "val_acc": 40.0}
{"epoch": 24, "training_loss": 6219.0826171875, "training_acc": 55.0, "val_loss": 735.8493041992188, "val_acc": 60.0}
{"epoch": 25, "training_loss": 2217.534326171875, "training_acc": 45.0, "val_loss": 1603.876220703125, "val_acc": 60.0}
{"epoch": 26, "training_loss": 1477.380810546875, "training_acc": 55.0, "val_loss": 4143.50146484375, "val_acc": 40.0}
{"epoch": 27, "training_loss": 1928.1778076171875, "training_acc": 55.0, "val_loss": 1772.9925537109375, "val_acc": 60.0}
{"epoch": 28, "training_loss": 902.183560180664, "training_acc": 70.0, "val_loss": 3157.084716796875, "val_acc": 40.0}
{"epoch": 29, "training_loss": 915.4210266113281, "training_acc": 75.0, "val_loss": 2072.591796875, "val_acc": 60.0}
{"epoch": 30, "training_loss": 1829.23623046875, "training_acc": 45.0, "val_loss": 3051.4033203125, "val_acc": 40.0}
{"epoch": 31, "training_loss": 839.989013671875, "training_acc": 75.0, "val_loss": 1850.852783203125, "val_acc": 60.0}
{"epoch": 32, "training_loss": 1606.359619140625, "training_acc": 45.0, "val_loss": 3334.313232421875, "val_acc": 40.0}
{"epoch": 33, "training_loss": 1019.5414245605468, "training_acc": 70.0, "val_loss": 2291.36962890625, "val_acc": 60.0}
{"epoch": 34, "training_loss": 2432.677685546875, "training_acc": 45.0, "val_loss": 4535.25927734375, "val_acc": 40.0}
