"main_modify.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_sex --input_option yAware --learning_rate 1e2 --batch_size 8 --weight_decay 1e-6 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 5220.987013936043, "training_acc": 50.0, "val_loss": 19694.072265625, "val_acc": 40.0}
{"epoch": 1, "training_loss": 20187.60703125, "training_acc": 50.0, "val_loss": 20078.978515625, "val_acc": 40.0}
{"epoch": 2, "training_loss": 10503.462353515624, "training_acc": 50.0, "val_loss": 7253.62646484375, "val_acc": 60.0}
{"epoch": 3, "training_loss": 9089.276953125, "training_acc": 50.0, "val_loss": 3652.720458984375, "val_acc": 60.0}
{"epoch": 4, "training_loss": 4340.26796875, "training_acc": 40.0, "val_loss": 5716.3330078125, "val_acc": 40.0}
{"epoch": 5, "training_loss": 4098.54453125, "training_acc": 40.0, "val_loss": 3816.593017578125, "val_acc": 60.0}
{"epoch": 6, "training_loss": 3370.4701721191404, "training_acc": 50.0, "val_loss": 5545.1943359375, "val_acc": 40.0}
{"epoch": 7, "training_loss": 6237.7345703125, "training_acc": 50.0, "val_loss": 6094.71630859375, "val_acc": 40.0}
{"epoch": 8, "training_loss": 3099.910400390625, "training_acc": 60.0, "val_loss": 6561.2626953125, "val_acc": 60.0}
{"epoch": 9, "training_loss": 7725.50810546875, "training_acc": 50.0, "val_loss": 3300.279052734375, "val_acc": 60.0}
{"epoch": 10, "training_loss": 4880.92880859375, "training_acc": 30.0, "val_loss": 4205.37255859375, "val_acc": 40.0}
{"epoch": 11, "training_loss": 1821.6197021484375, "training_acc": 60.0, "val_loss": 5134.8642578125, "val_acc": 60.0}
{"epoch": 12, "training_loss": 6216.305078125, "training_acc": 50.0, "val_loss": 1873.490234375, "val_acc": 60.0}
{"epoch": 13, "training_loss": 1898.6925048828125, "training_acc": 60.0, "val_loss": 5907.55029296875, "val_acc": 40.0}
{"epoch": 14, "training_loss": 3851.1726806640627, "training_acc": 50.0, "val_loss": 3247.398193359375, "val_acc": 60.0}
{"epoch": 15, "training_loss": 5794.7548828125, "training_acc": 50.0, "val_loss": 4154.9765625, "val_acc": 60.0}
{"epoch": 16, "training_loss": 2386.324169921875, "training_acc": 60.0, "val_loss": 7849.61865234375, "val_acc": 40.0}
{"epoch": 17, "training_loss": 6741.878125, "training_acc": 50.0, "val_loss": 3710.025146484375, "val_acc": 40.0}
{"epoch": 18, "training_loss": 951.6662963867187, "training_acc": 75.0, "val_loss": 3226.8544921875, "val_acc": 60.0}
{"epoch": 19, "training_loss": 2665.1933263778687, "training_acc": 55.0, "val_loss": 1792.454345703125, "val_acc": 40.0}
{"epoch": 20, "training_loss": 1069.8000061035157, "training_acc": 60.0, "val_loss": 1732.5960693359375, "val_acc": 60.0}
{"epoch": 21, "training_loss": 1039.6162231445312, "training_acc": 60.0, "val_loss": 3999.3984375, "val_acc": 40.0}
{"epoch": 22, "training_loss": 2409.9876220703127, "training_acc": 50.0, "val_loss": 3790.579833984375, "val_acc": 60.0}
{"epoch": 23, "training_loss": 6664.704296875, "training_acc": 50.0, "val_loss": 4686.0830078125, "val_acc": 60.0}
{"epoch": 24, "training_loss": 2933.1822021484377, "training_acc": 60.0, "val_loss": 9894.267578125, "val_acc": 40.0}
{"epoch": 25, "training_loss": 10223.7505859375, "training_acc": 50.0, "val_loss": 8334.822265625, "val_acc": 40.0}
{"epoch": 26, "training_loss": 4506.062646484375, "training_acc": 50.0, "val_loss": 6324.27783203125, "val_acc": 60.0}
{"epoch": 27, "training_loss": 7957.24765625, "training_acc": 50.0, "val_loss": 3944.595458984375, "val_acc": 60.0}
{"epoch": 28, "training_loss": 2178.2296520233153, "training_acc": 70.0, "val_loss": 8341.8359375, "val_acc": 40.0}
{"epoch": 29, "training_loss": 7140.9216796875, "training_acc": 50.0, "val_loss": 2621.32080078125, "val_acc": 40.0}
{"epoch": 30, "training_loss": 3525.888232421875, "training_acc": 50.0, "val_loss": 4970.4267578125, "val_acc": 60.0}
{"epoch": 31, "training_loss": 3502.137176513672, "training_acc": 60.0, "val_loss": 3156.842529296875, "val_acc": 40.0}
{"epoch": 32, "training_loss": 2503.846144104004, "training_acc": 50.0, "val_loss": 3026.2216796875, "val_acc": 60.0}
{"epoch": 33, "training_loss": 4223.701684570313, "training_acc": 50.0, "val_loss": 761.0791625976562, "val_acc": 60.0}
{"epoch": 34, "training_loss": 1776.70732421875, "training_acc": 60.0, "val_loss": 5663.8896484375, "val_acc": 40.0}
{"epoch": 35, "training_loss": 3425.789599609375, "training_acc": 50.0, "val_loss": 2301.861083984375, "val_acc": 60.0}
{"epoch": 36, "training_loss": 2166.84189453125, "training_acc": 40.0, "val_loss": 1898.7991943359375, "val_acc": 40.0}
{"epoch": 37, "training_loss": 1097.9120361328125, "training_acc": 60.0, "val_loss": 2962.681884765625, "val_acc": 60.0}
{"epoch": 38, "training_loss": 2628.966748046875, "training_acc": 40.0, "val_loss": 2852.349609375, "val_acc": 40.0}
{"epoch": 39, "training_loss": 1581.98017578125, "training_acc": 60.0, "val_loss": 2687.770751953125, "val_acc": 60.0}
{"epoch": 40, "training_loss": 2294.9396789550783, "training_acc": 55.0, "val_loss": 3013.288818359375, "val_acc": 40.0}
{"epoch": 41, "training_loss": 2771.4406616210936, "training_acc": 50.0, "val_loss": 1204.9324951171875, "val_acc": 60.0}
{"epoch": 42, "training_loss": 627.1546348053031, "training_acc": 65.0, "val_loss": 1410.6063232421875, "val_acc": 40.0}
{"epoch": 43, "training_loss": 771.1473754882812, "training_acc": 50.0, "val_loss": 37.97348403930664, "val_acc": 40.0}
{"epoch": 44, "training_loss": 224.7823944091797, "training_acc": 65.0, "val_loss": 1997.6923828125, "val_acc": 60.0}
{"epoch": 45, "training_loss": 1795.1900390625, "training_acc": 40.0, "val_loss": 77.11185455322266, "val_acc": 60.0}
{"epoch": 46, "training_loss": 911.6900604248046, "training_acc": 50.0, "val_loss": 1885.1890869140625, "val_acc": 40.0}
{"epoch": 47, "training_loss": 2167.2919921875, "training_acc": 50.0, "val_loss": 2364.3984375, "val_acc": 60.0}
{"epoch": 48, "training_loss": 2430.9323608398436, "training_acc": 50.0, "val_loss": 544.3170776367188, "val_acc": 60.0}
{"epoch": 49, "training_loss": 1515.6257690429688, "training_acc": 60.0, "val_loss": 862.1611328125, "val_acc": 40.0}
{"epoch": 50, "training_loss": 1881.4531494140624, "training_acc": 50.0, "val_loss": 2559.99658203125, "val_acc": 60.0}
{"epoch": 51, "training_loss": 1972.214794921875, "training_acc": 40.0, "val_loss": 555.9351196289062, "val_acc": 60.0}
{"epoch": 52, "training_loss": 795.0127777099609, "training_acc": 65.0, "val_loss": 1809.6910400390625, "val_acc": 40.0}
{"epoch": 53, "training_loss": 2579.024658203125, "training_acc": 50.0, "val_loss": 1187.4832763671875, "val_acc": 60.0}
{"epoch": 54, "training_loss": 942.993017578125, "training_acc": 40.0, "val_loss": 61.276058197021484, "val_acc": 40.0}
{"epoch": 55, "training_loss": 525.2949645996093, "training_acc": 60.0, "val_loss": 1057.3602294921875, "val_acc": 40.0}
{"epoch": 56, "training_loss": 1206.4630767822266, "training_acc": 55.0, "val_loss": 1374.7857666015625, "val_acc": 60.0}
{"epoch": 57, "training_loss": 885.0280578613281, "training_acc": 65.0, "val_loss": 749.0997314453125, "val_acc": 40.0}
{"epoch": 58, "training_loss": 1079.2992614746095, "training_acc": 50.0, "val_loss": 345.24444580078125, "val_acc": 60.0}
{"epoch": 59, "training_loss": 788.3593078613281, "training_acc": 55.0, "val_loss": 1576.357666015625, "val_acc": 60.0}
{"epoch": 60, "training_loss": 1244.44365234375, "training_acc": 55.0, "val_loss": 3618.921875, "val_acc": 40.0}
{"epoch": 61, "training_loss": 3755.37568359375, "training_acc": 50.0, "val_loss": 535.792724609375, "val_acc": 40.0}
{"epoch": 62, "training_loss": 1120.791943359375, "training_acc": 70.0, "val_loss": 4520.2548828125, "val_acc": 60.0}
