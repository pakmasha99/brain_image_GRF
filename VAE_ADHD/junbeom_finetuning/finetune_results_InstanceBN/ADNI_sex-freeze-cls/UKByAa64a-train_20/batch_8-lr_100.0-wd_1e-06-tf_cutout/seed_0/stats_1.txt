"main_modify.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_sex --input_option yAware --learning_rate 1e2 --batch_size 8 --weight_decay 1e-6 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 11410.96034450531, "training_acc": 45.0, "val_loss": 5502.4287109375, "val_acc": 60.0}
{"epoch": 1, "training_loss": 10186.8083984375, "training_acc": 50.0, "val_loss": 5693.22607421875, "val_acc": 60.0}
{"epoch": 2, "training_loss": 4435.322607421875, "training_acc": 40.0, "val_loss": 1186.58251953125, "val_acc": 40.0}
{"epoch": 3, "training_loss": 4355.532958984375, "training_acc": 30.0, "val_loss": 2766.97607421875, "val_acc": 60.0}
{"epoch": 4, "training_loss": 2280.6652099609373, "training_acc": 50.0, "val_loss": 9377.4091796875, "val_acc": 40.0}
{"epoch": 5, "training_loss": 7516.8232421875, "training_acc": 50.0, "val_loss": 1372.2943115234375, "val_acc": 40.0}
{"epoch": 6, "training_loss": 4948.87978515625, "training_acc": 40.0, "val_loss": 6166.81591796875, "val_acc": 60.0}
{"epoch": 7, "training_loss": 5384.70390625, "training_acc": 50.0, "val_loss": 4881.67041015625, "val_acc": 40.0}
{"epoch": 8, "training_loss": 7338.9404296875, "training_acc": 50.0, "val_loss": 10551.6435546875, "val_acc": 40.0}
{"epoch": 9, "training_loss": 5923.821337890625, "training_acc": 50.0, "val_loss": 3338.845703125, "val_acc": 60.0}
{"epoch": 10, "training_loss": 5338.169921875, "training_acc": 50.0, "val_loss": 6687.29833984375, "val_acc": 60.0}
{"epoch": 11, "training_loss": 7034.154321289063, "training_acc": 50.0, "val_loss": 1815.046142578125, "val_acc": 40.0}
{"epoch": 12, "training_loss": 2169.2306640625, "training_acc": 50.0, "val_loss": 792.5856323242188, "val_acc": 40.0}
{"epoch": 13, "training_loss": 1207.5394775390625, "training_acc": 60.0, "val_loss": 913.2900390625, "val_acc": 60.0}
{"epoch": 14, "training_loss": 2425.19775390625, "training_acc": 40.0, "val_loss": 2458.114501953125, "val_acc": 40.0}
{"epoch": 15, "training_loss": 1044.0905517578126, "training_acc": 60.0, "val_loss": 102.92986297607422, "val_acc": 60.0}
{"epoch": 16, "training_loss": 1250.5116241455078, "training_acc": 60.0, "val_loss": 2440.45654296875, "val_acc": 40.0}
{"epoch": 17, "training_loss": 1418.8593017578125, "training_acc": 50.0, "val_loss": 877.9441528320312, "val_acc": 40.0}
{"epoch": 18, "training_loss": 716.8821960449219, "training_acc": 60.0, "val_loss": 525.173583984375, "val_acc": 60.0}
{"epoch": 19, "training_loss": 1157.7000732421875, "training_acc": 40.0, "val_loss": 1306.105224609375, "val_acc": 60.0}
{"epoch": 20, "training_loss": 1810.1358154296875, "training_acc": 50.0, "val_loss": 3594.834716796875, "val_acc": 40.0}
{"epoch": 21, "training_loss": 3161.320556640625, "training_acc": 50.0, "val_loss": 244.2176055908203, "val_acc": 40.0}
{"epoch": 22, "training_loss": 2410.5600402832033, "training_acc": 50.0, "val_loss": 1945.7506103515625, "val_acc": 60.0}
{"epoch": 23, "training_loss": 4061.176171875, "training_acc": 20.0, "val_loss": 2151.778076171875, "val_acc": 40.0}
{"epoch": 24, "training_loss": 1795.8595458984375, "training_acc": 50.0, "val_loss": 1738.293212890625, "val_acc": 60.0}
{"epoch": 25, "training_loss": 1556.6875244140624, "training_acc": 50.0, "val_loss": 6288.28125, "val_acc": 40.0}
{"epoch": 26, "training_loss": 4377.585546875, "training_acc": 50.0, "val_loss": 1390.271240234375, "val_acc": 60.0}
{"epoch": 27, "training_loss": 3938.591796875, "training_acc": 50.0, "val_loss": 1345.0731201171875, "val_acc": 60.0}
{"epoch": 28, "training_loss": 2312.91337890625, "training_acc": 40.0, "val_loss": 1790.1346435546875, "val_acc": 40.0}
{"epoch": 29, "training_loss": 1030.9256103515625, "training_acc": 60.0, "val_loss": 472.50054931640625, "val_acc": 60.0}
{"epoch": 30, "training_loss": 1758.3200927734374, "training_acc": 50.0, "val_loss": 2271.858642578125, "val_acc": 40.0}
{"epoch": 31, "training_loss": 843.0155395507812, "training_acc": 60.0, "val_loss": 288.8556823730469, "val_acc": 60.0}
{"epoch": 32, "training_loss": 1390.0080078125, "training_acc": 50.0, "val_loss": 863.3825073242188, "val_acc": 40.0}
{"epoch": 33, "training_loss": 2569.4990234375, "training_acc": 40.0, "val_loss": 2712.303955078125, "val_acc": 60.0}
{"epoch": 34, "training_loss": 1906.6626525878905, "training_acc": 60.0, "val_loss": 4340.9814453125, "val_acc": 40.0}
