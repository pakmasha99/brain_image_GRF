"main_modify.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 1 --task ADNI_sex --input_option yAware --learning_rate 5e0 --batch_size 16 --weight_decay 1e-9 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 319.91277303695676, "training_acc": 50.0, "val_loss": 364.0831604003906, "val_acc": 40.0}
{"epoch": 1, "training_loss": 355.9341186523437, "training_acc": 50.0, "val_loss": 711.0462036132812, "val_acc": 60.0}
{"epoch": 2, "training_loss": 884.3926879882813, "training_acc": 50.0, "val_loss": 554.4891357421875, "val_acc": 60.0}
{"epoch": 3, "training_loss": 657.355322265625, "training_acc": 50.0, "val_loss": 70.91565704345703, "val_acc": 40.0}
{"epoch": 4, "training_loss": 72.30046234130859, "training_acc": 50.0, "val_loss": 254.5415496826172, "val_acc": 40.0}
{"epoch": 5, "training_loss": 183.98130493164064, "training_acc": 50.0, "val_loss": 167.02835083007812, "val_acc": 60.0}
{"epoch": 6, "training_loss": 215.14157409667968, "training_acc": 50.0, "val_loss": 214.8157196044922, "val_acc": 60.0}
{"epoch": 7, "training_loss": 250.2989929199219, "training_acc": 50.0, "val_loss": 142.5049285888672, "val_acc": 40.0}
{"epoch": 8, "training_loss": 141.969677734375, "training_acc": 50.0, "val_loss": 74.37503814697266, "val_acc": 40.0}
{"epoch": 9, "training_loss": 114.879541015625, "training_acc": 40.0, "val_loss": 185.29441833496094, "val_acc": 60.0}
{"epoch": 10, "training_loss": 209.79698486328124, "training_acc": 50.0, "val_loss": 77.95633697509766, "val_acc": 40.0}
{"epoch": 11, "training_loss": 67.1705810546875, "training_acc": 50.0, "val_loss": 224.3191680908203, "val_acc": 40.0}
{"epoch": 12, "training_loss": 180.32012863159179, "training_acc": 50.0, "val_loss": 4.877142906188965, "val_acc": 60.0}
{"epoch": 13, "training_loss": 6.6030889511108395, "training_acc": 55.0, "val_loss": 100.34136199951172, "val_acc": 40.0}
{"epoch": 14, "training_loss": 82.0053924560547, "training_acc": 50.0, "val_loss": 44.135650634765625, "val_acc": 60.0}
{"epoch": 15, "training_loss": 52.229698944091794, "training_acc": 50.0, "val_loss": 16.856159210205078, "val_acc": 40.0}
{"epoch": 16, "training_loss": 17.474180603027342, "training_acc": 50.0, "val_loss": 30.811105728149414, "val_acc": 40.0}
{"epoch": 17, "training_loss": 26.746950531005858, "training_acc": 50.0, "val_loss": 42.39223861694336, "val_acc": 40.0}
{"epoch": 18, "training_loss": 40.482182312011716, "training_acc": 40.0, "val_loss": 84.10240936279297, "val_acc": 40.0}
{"epoch": 19, "training_loss": 72.084375, "training_acc": 50.0, "val_loss": 67.19414520263672, "val_acc": 60.0}
{"epoch": 20, "training_loss": 97.36635131835938, "training_acc": 50.0, "val_loss": 20.563840866088867, "val_acc": 60.0}
{"epoch": 21, "training_loss": 76.59607849121093, "training_acc": 40.0, "val_loss": 262.9179382324219, "val_acc": 40.0}
{"epoch": 22, "training_loss": 207.25720825195313, "training_acc": 50.0, "val_loss": 3.833242177963257, "val_acc": 80.0}
{"epoch": 23, "training_loss": 21.23440017700195, "training_acc": 70.0, "val_loss": 68.92439270019531, "val_acc": 60.0}
{"epoch": 24, "training_loss": 87.77751083374024, "training_acc": 40.0, "val_loss": 0.3349590003490448, "val_acc": 80.0}
{"epoch": 25, "training_loss": 8.988773357868194, "training_acc": 85.0, "val_loss": 9.703219413757324, "val_acc": 40.0}
{"epoch": 26, "training_loss": 12.952158355712891, "training_acc": 50.0, "val_loss": 20.93834686279297, "val_acc": 40.0}
{"epoch": 27, "training_loss": 35.55734558105469, "training_acc": 30.0, "val_loss": 91.14293670654297, "val_acc": 40.0}
{"epoch": 28, "training_loss": 82.51615295410156, "training_acc": 50.0, "val_loss": 18.107501983642578, "val_acc": 40.0}
{"epoch": 29, "training_loss": 60.80256652832031, "training_acc": 40.0, "val_loss": 142.3697967529297, "val_acc": 60.0}
{"epoch": 30, "training_loss": 171.4388427734375, "training_acc": 50.0, "val_loss": 23.468122482299805, "val_acc": 40.0}
{"epoch": 31, "training_loss": 19.95428009033203, "training_acc": 50.0, "val_loss": 92.65589904785156, "val_acc": 60.0}
{"epoch": 32, "training_loss": 112.37510147094727, "training_acc": 50.0, "val_loss": 83.84027099609375, "val_acc": 60.0}
{"epoch": 33, "training_loss": 69.56637668609619, "training_acc": 60.0, "val_loss": 65.67464447021484, "val_acc": 40.0}
{"epoch": 34, "training_loss": 47.45319023132324, "training_acc": 50.0, "val_loss": 126.0788803100586, "val_acc": 60.0}
{"epoch": 35, "training_loss": 177.22921142578124, "training_acc": 50.0, "val_loss": 125.8791275024414, "val_acc": 60.0}
{"epoch": 36, "training_loss": 139.08159561157225, "training_acc": 40.0, "val_loss": 34.86933135986328, "val_acc": 40.0}
{"epoch": 37, "training_loss": 44.126356506347655, "training_acc": 40.0, "val_loss": 1.7448511123657227, "val_acc": 80.0}
{"epoch": 38, "training_loss": 6.591604900360108, "training_acc": 90.0, "val_loss": 83.21227264404297, "val_acc": 40.0}
{"epoch": 39, "training_loss": 58.78953304290771, "training_acc": 55.0, "val_loss": 28.615604400634766, "val_acc": 60.0}
{"epoch": 40, "training_loss": 36.75658264160156, "training_acc": 40.0, "val_loss": 16.263399124145508, "val_acc": 60.0}
{"epoch": 41, "training_loss": 12.969521141052246, "training_acc": 50.0, "val_loss": 42.27152633666992, "val_acc": 60.0}
{"epoch": 42, "training_loss": 38.08829803466797, "training_acc": 50.0, "val_loss": 156.84519958496094, "val_acc": 40.0}
{"epoch": 43, "training_loss": 138.99659729003906, "training_acc": 50.0, "val_loss": 196.0954132080078, "val_acc": 40.0}
