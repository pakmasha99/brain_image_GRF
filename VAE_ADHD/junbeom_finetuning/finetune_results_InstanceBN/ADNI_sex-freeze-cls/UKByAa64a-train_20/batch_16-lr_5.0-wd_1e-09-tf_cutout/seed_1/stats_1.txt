"main_modify.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 1 --task ADNI_sex --input_option yAware --learning_rate 5e0 --batch_size 16 --weight_decay 1e-9 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 321.6462881088257, "training_acc": 55.0, "val_loss": 465.7161560058594, "val_acc": 40.0}
{"epoch": 1, "training_loss": 271.56101989746094, "training_acc": 65.0, "val_loss": 655.5922241210938, "val_acc": 60.0}
{"epoch": 2, "training_loss": 896.4767883300781, "training_acc": 45.0, "val_loss": 499.260986328125, "val_acc": 60.0}
{"epoch": 3, "training_loss": 611.6816528320312, "training_acc": 45.0, "val_loss": 288.8531188964844, "val_acc": 40.0}
{"epoch": 4, "training_loss": 267.4524169921875, "training_acc": 55.0, "val_loss": 649.9208374023438, "val_acc": 40.0}
{"epoch": 5, "training_loss": 465.5245422363281, "training_acc": 55.0, "val_loss": 220.0715789794922, "val_acc": 40.0}
{"epoch": 6, "training_loss": 123.74717407226562, "training_acc": 65.0, "val_loss": 299.531982421875, "val_acc": 60.0}
{"epoch": 7, "training_loss": 416.4426635742187, "training_acc": 45.0, "val_loss": 228.8358917236328, "val_acc": 60.0}
{"epoch": 8, "training_loss": 286.01746063232423, "training_acc": 45.0, "val_loss": 349.2689514160156, "val_acc": 40.0}
{"epoch": 9, "training_loss": 291.842724609375, "training_acc": 55.0, "val_loss": 549.4967651367188, "val_acc": 40.0}
{"epoch": 10, "training_loss": 397.8717010498047, "training_acc": 55.0, "val_loss": 197.00430297851562, "val_acc": 40.0}
{"epoch": 11, "training_loss": 106.42441635131836, "training_acc": 65.0, "val_loss": 199.9871368408203, "val_acc": 60.0}
{"epoch": 12, "training_loss": 277.6989990234375, "training_acc": 45.0, "val_loss": 79.48028564453125, "val_acc": 60.0}
{"epoch": 13, "training_loss": 153.02765502929688, "training_acc": 35.0, "val_loss": 340.0244140625, "val_acc": 40.0}
{"epoch": 14, "training_loss": 248.443603515625, "training_acc": 55.0, "val_loss": 146.6531982421875, "val_acc": 40.0}
{"epoch": 15, "training_loss": 127.48895263671875, "training_acc": 45.0, "val_loss": 123.84730529785156, "val_acc": 60.0}
{"epoch": 16, "training_loss": 157.57842674255372, "training_acc": 45.0, "val_loss": 110.60591125488281, "val_acc": 40.0}
{"epoch": 17, "training_loss": 81.69517211914062, "training_acc": 55.0, "val_loss": 91.9502182006836, "val_acc": 40.0}
{"epoch": 18, "training_loss": 77.66156921386718, "training_acc": 45.0, "val_loss": 23.673805236816406, "val_acc": 60.0}
{"epoch": 19, "training_loss": 85.39444580078126, "training_acc": 25.0, "val_loss": 116.29207611083984, "val_acc": 40.0}
{"epoch": 20, "training_loss": 72.39040069580078, "training_acc": 55.0, "val_loss": 46.54099655151367, "val_acc": 60.0}
{"epoch": 21, "training_loss": 45.036617279052734, "training_acc": 55.0, "val_loss": 60.97042465209961, "val_acc": 40.0}
{"epoch": 22, "training_loss": 28.389510416984557, "training_acc": 65.0, "val_loss": 1.990182876586914, "val_acc": 80.0}
{"epoch": 23, "training_loss": 1.3254698753356933, "training_acc": 80.0, "val_loss": 18.264928817749023, "val_acc": 60.0}
{"epoch": 24, "training_loss": 14.903718185424804, "training_acc": 55.0, "val_loss": 70.60179138183594, "val_acc": 40.0}
{"epoch": 25, "training_loss": 56.548011779785156, "training_acc": 45.0, "val_loss": 41.36114501953125, "val_acc": 40.0}
{"epoch": 26, "training_loss": 21.051099395751955, "training_acc": 55.0, "val_loss": 119.14461517333984, "val_acc": 60.0}
{"epoch": 27, "training_loss": 159.61696166992186, "training_acc": 45.0, "val_loss": 110.32710266113281, "val_acc": 60.0}
{"epoch": 28, "training_loss": 118.05351601838956, "training_acc": 55.0, "val_loss": 171.5244598388672, "val_acc": 40.0}
{"epoch": 29, "training_loss": 129.297216796875, "training_acc": 55.0, "val_loss": 106.86919403076172, "val_acc": 40.0}
{"epoch": 30, "training_loss": 71.06871643066407, "training_acc": 55.0, "val_loss": 95.63823699951172, "val_acc": 60.0}
{"epoch": 31, "training_loss": 102.77562408447265, "training_acc": 45.0, "val_loss": 196.78140258789062, "val_acc": 40.0}
{"epoch": 32, "training_loss": 147.69205627441406, "training_acc": 55.0, "val_loss": 340.85772705078125, "val_acc": 40.0}
{"epoch": 33, "training_loss": 234.73399047851564, "training_acc": 55.0, "val_loss": 26.874378204345703, "val_acc": 40.0}
{"epoch": 34, "training_loss": 93.40283508300782, "training_acc": 45.0, "val_loss": 296.2461242675781, "val_acc": 60.0}
{"epoch": 35, "training_loss": 400.37664794921875, "training_acc": 45.0, "val_loss": 153.70066833496094, "val_acc": 60.0}
{"epoch": 36, "training_loss": 209.0292999267578, "training_acc": 35.0, "val_loss": 214.5689239501953, "val_acc": 40.0}
{"epoch": 37, "training_loss": 153.74232788085936, "training_acc": 55.0, "val_loss": 79.6032485961914, "val_acc": 40.0}
{"epoch": 38, "training_loss": 46.09890899658203, "training_acc": 65.0, "val_loss": 169.92706298828125, "val_acc": 60.0}
{"epoch": 39, "training_loss": 218.5288513183594, "training_acc": 45.0, "val_loss": 54.38605499267578, "val_acc": 60.0}
{"epoch": 40, "training_loss": 78.39806823730468, "training_acc": 45.0, "val_loss": 309.6773681640625, "val_acc": 40.0}
{"epoch": 41, "training_loss": 222.92857360839844, "training_acc": 55.0, "val_loss": 183.5903778076172, "val_acc": 40.0}
