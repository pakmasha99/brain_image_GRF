"main_modify.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_sex --input_option yAware --learning_rate 5e0 --batch_size 16 --weight_decay 1e-9 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 107.2537335395813, "training_acc": 55.0, "val_loss": 421.22216796875, "val_acc": 40.0}
{"epoch": 1, "training_loss": 433.2964233398437, "training_acc": 45.0, "val_loss": 342.5390319824219, "val_acc": 60.0}
{"epoch": 2, "training_loss": 370.7210968017578, "training_acc": 45.0, "val_loss": 548.3926391601562, "val_acc": 40.0}
{"epoch": 3, "training_loss": 508.2523193359375, "training_acc": 55.0, "val_loss": 908.0521850585938, "val_acc": 40.0}
{"epoch": 4, "training_loss": 643.8919555664063, "training_acc": 55.0, "val_loss": 350.90924072265625, "val_acc": 40.0}
{"epoch": 5, "training_loss": 185.93854827880858, "training_acc": 65.0, "val_loss": 308.7813415527344, "val_acc": 60.0}
{"epoch": 6, "training_loss": 475.0427001953125, "training_acc": 45.0, "val_loss": 296.3238830566406, "val_acc": 60.0}
{"epoch": 7, "training_loss": 380.1730186462402, "training_acc": 45.0, "val_loss": 241.49990844726562, "val_acc": 40.0}
{"epoch": 8, "training_loss": 235.20963134765626, "training_acc": 55.0, "val_loss": 446.93438720703125, "val_acc": 40.0}
{"epoch": 9, "training_loss": 313.518408203125, "training_acc": 55.0, "val_loss": 73.61144256591797, "val_acc": 40.0}
{"epoch": 10, "training_loss": 56.53651428222656, "training_acc": 65.0, "val_loss": 312.5115661621094, "val_acc": 60.0}
{"epoch": 11, "training_loss": 439.88865966796874, "training_acc": 45.0, "val_loss": 290.7005310058594, "val_acc": 60.0}
{"epoch": 12, "training_loss": 338.4726318359375, "training_acc": 45.0, "val_loss": 156.7057647705078, "val_acc": 40.0}
{"epoch": 13, "training_loss": 115.57001953125, "training_acc": 55.0, "val_loss": 586.444580078125, "val_acc": 40.0}
{"epoch": 14, "training_loss": 452.0107666015625, "training_acc": 55.0, "val_loss": 609.3181762695312, "val_acc": 40.0}
{"epoch": 15, "training_loss": 420.33583984375, "training_acc": 55.0, "val_loss": 161.59304809570312, "val_acc": 40.0}
{"epoch": 16, "training_loss": 65.2818359375, "training_acc": 75.0, "val_loss": 342.7965393066406, "val_acc": 60.0}
{"epoch": 17, "training_loss": 496.65711669921876, "training_acc": 45.0, "val_loss": 452.429931640625, "val_acc": 60.0}
{"epoch": 18, "training_loss": 594.912109375, "training_acc": 45.0, "val_loss": 190.5116729736328, "val_acc": 60.0}
{"epoch": 19, "training_loss": 266.67222900390624, "training_acc": 35.0, "val_loss": 289.39105224609375, "val_acc": 40.0}
{"epoch": 20, "training_loss": 222.5369140625, "training_acc": 55.0, "val_loss": 277.2468566894531, "val_acc": 40.0}
{"epoch": 21, "training_loss": 165.42198486328124, "training_acc": 55.0, "val_loss": 122.2436752319336, "val_acc": 60.0}
{"epoch": 22, "training_loss": 211.14591064453126, "training_acc": 45.0, "val_loss": 211.1167449951172, "val_acc": 60.0}
{"epoch": 23, "training_loss": 264.66671295166014, "training_acc": 45.0, "val_loss": 99.6312255859375, "val_acc": 40.0}
{"epoch": 24, "training_loss": 105.2257080078125, "training_acc": 55.0, "val_loss": 203.18992614746094, "val_acc": 40.0}
{"epoch": 25, "training_loss": 133.84045085906982, "training_acc": 55.0, "val_loss": 99.26041412353516, "val_acc": 60.0}
{"epoch": 26, "training_loss": 144.368798828125, "training_acc": 45.0, "val_loss": 81.61278533935547, "val_acc": 60.0}
{"epoch": 27, "training_loss": 84.68060722351075, "training_acc": 55.0, "val_loss": 165.1921844482422, "val_acc": 40.0}
{"epoch": 28, "training_loss": 118.44959716796875, "training_acc": 55.0, "val_loss": 4.856924533843994, "val_acc": 60.0}
{"epoch": 29, "training_loss": 28.1523136138916, "training_acc": 60.0, "val_loss": 16.50518798828125, "val_acc": 60.0}
{"epoch": 30, "training_loss": 16.54908142089844, "training_acc": 65.0, "val_loss": 301.3360900878906, "val_acc": 40.0}
{"epoch": 31, "training_loss": 231.4400634765625, "training_acc": 55.0, "val_loss": 222.5990753173828, "val_acc": 40.0}
{"epoch": 32, "training_loss": 123.57673721313476, "training_acc": 55.0, "val_loss": 131.07876586914062, "val_acc": 60.0}
{"epoch": 33, "training_loss": 190.31832580566407, "training_acc": 45.0, "val_loss": 109.99885559082031, "val_acc": 60.0}
{"epoch": 34, "training_loss": 128.6643859863281, "training_acc": 45.0, "val_loss": 98.91261291503906, "val_acc": 40.0}
{"epoch": 35, "training_loss": 57.09836120605469, "training_acc": 55.0, "val_loss": 89.5740966796875, "val_acc": 60.0}
{"epoch": 36, "training_loss": 154.1837585449219, "training_acc": 45.0, "val_loss": 36.43746566772461, "val_acc": 60.0}
{"epoch": 37, "training_loss": 77.23192138671875, "training_acc": 45.0, "val_loss": 348.7641296386719, "val_acc": 40.0}
{"epoch": 38, "training_loss": 260.95079345703124, "training_acc": 55.0, "val_loss": 231.08775329589844, "val_acc": 40.0}
{"epoch": 39, "training_loss": 126.11119117736817, "training_acc": 60.0, "val_loss": 103.41338348388672, "val_acc": 60.0}
{"epoch": 40, "training_loss": 145.701220703125, "training_acc": 45.0, "val_loss": 33.1437873840332, "val_acc": 60.0}
{"epoch": 41, "training_loss": 88.8562255859375, "training_acc": 35.0, "val_loss": 236.8115692138672, "val_acc": 40.0}
{"epoch": 42, "training_loss": 158.74542541503905, "training_acc": 55.0, "val_loss": 32.63303756713867, "val_acc": 40.0}
{"epoch": 43, "training_loss": 21.075701904296874, "training_acc": 65.0, "val_loss": 194.15528869628906, "val_acc": 60.0}
{"epoch": 44, "training_loss": 265.7474731445312, "training_acc": 45.0, "val_loss": 88.1046371459961, "val_acc": 60.0}
{"epoch": 45, "training_loss": 116.34495544433594, "training_acc": 45.0, "val_loss": 231.0236053466797, "val_acc": 40.0}
{"epoch": 46, "training_loss": 158.50531005859375, "training_acc": 55.0, "val_loss": 168.5946502685547, "val_acc": 40.0}
{"epoch": 47, "training_loss": 82.71082916259766, "training_acc": 55.0, "val_loss": 150.58985900878906, "val_acc": 60.0}
