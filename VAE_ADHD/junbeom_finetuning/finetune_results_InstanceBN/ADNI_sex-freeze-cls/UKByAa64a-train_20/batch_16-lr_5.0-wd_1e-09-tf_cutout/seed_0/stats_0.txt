"main_modify.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_sex --input_option yAware --learning_rate 5e0 --batch_size 16 --weight_decay 1e-9 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 320.5707576751709, "training_acc": 50.0, "val_loss": 386.4262390136719, "val_acc": 40.0}
{"epoch": 1, "training_loss": 364.3703125, "training_acc": 50.0, "val_loss": 681.5488891601562, "val_acc": 60.0}
{"epoch": 2, "training_loss": 846.6744262695313, "training_acc": 50.0, "val_loss": 520.7589111328125, "val_acc": 60.0}
{"epoch": 3, "training_loss": 556.0654418945312, "training_acc": 50.0, "val_loss": 201.2838897705078, "val_acc": 40.0}
{"epoch": 4, "training_loss": 218.42193603515625, "training_acc": 50.0, "val_loss": 586.398193359375, "val_acc": 40.0}
{"epoch": 5, "training_loss": 463.5929443359375, "training_acc": 50.0, "val_loss": 163.1548309326172, "val_acc": 40.0}
{"epoch": 6, "training_loss": 154.757666015625, "training_acc": 50.0, "val_loss": 344.9447937011719, "val_acc": 60.0}
{"epoch": 7, "training_loss": 436.83836669921874, "training_acc": 50.0, "val_loss": 311.7804870605469, "val_acc": 60.0}
{"epoch": 8, "training_loss": 347.5394622802734, "training_acc": 50.0, "val_loss": 122.64916229248047, "val_acc": 40.0}
{"epoch": 9, "training_loss": 112.96617126464844, "training_acc": 50.0, "val_loss": 343.15576171875, "val_acc": 40.0}
{"epoch": 10, "training_loss": 270.31309204101564, "training_acc": 50.0, "val_loss": 54.21480941772461, "val_acc": 40.0}
{"epoch": 11, "training_loss": 79.09411010742187, "training_acc": 50.0, "val_loss": 281.2584533691406, "val_acc": 60.0}
{"epoch": 12, "training_loss": 347.6005615234375, "training_acc": 50.0, "val_loss": 194.4332275390625, "val_acc": 60.0}
{"epoch": 13, "training_loss": 216.19433002471925, "training_acc": 50.0, "val_loss": 283.7375183105469, "val_acc": 40.0}
{"epoch": 14, "training_loss": 245.12208251953126, "training_acc": 50.0, "val_loss": 458.6222229003906, "val_acc": 40.0}
{"epoch": 15, "training_loss": 360.7855590820312, "training_acc": 50.0, "val_loss": 126.11433410644531, "val_acc": 40.0}
{"epoch": 16, "training_loss": 121.55204467773437, "training_acc": 50.0, "val_loss": 288.08819580078125, "val_acc": 60.0}
{"epoch": 17, "training_loss": 361.576220703125, "training_acc": 50.0, "val_loss": 262.3260192871094, "val_acc": 60.0}
{"epoch": 18, "training_loss": 303.2073348999023, "training_acc": 50.0, "val_loss": 91.78408813476562, "val_acc": 40.0}
{"epoch": 19, "training_loss": 107.6748046875, "training_acc": 50.0, "val_loss": 138.3503875732422, "val_acc": 40.0}
{"epoch": 20, "training_loss": 117.87894439697266, "training_acc": 40.0, "val_loss": 50.607234954833984, "val_acc": 60.0}
{"epoch": 21, "training_loss": 63.85914306640625, "training_acc": 40.0, "val_loss": 7.584050178527832, "val_acc": 60.0}
{"epoch": 22, "training_loss": 18.95268440246582, "training_acc": 70.0, "val_loss": 62.82976150512695, "val_acc": 60.0}
{"epoch": 23, "training_loss": 53.967075729370116, "training_acc": 60.0, "val_loss": 83.27965545654297, "val_acc": 40.0}
{"epoch": 24, "training_loss": 54.7732647895813, "training_acc": 50.0, "val_loss": 125.46112060546875, "val_acc": 60.0}
{"epoch": 25, "training_loss": 151.12813415527344, "training_acc": 50.0, "val_loss": 127.6673812866211, "val_acc": 60.0}
{"epoch": 26, "training_loss": 124.7205249786377, "training_acc": 50.0, "val_loss": 224.96006774902344, "val_acc": 40.0}
{"epoch": 27, "training_loss": 202.39984741210938, "training_acc": 50.0, "val_loss": 312.4107666015625, "val_acc": 40.0}
{"epoch": 28, "training_loss": 219.70186767578124, "training_acc": 50.0, "val_loss": 101.2792739868164, "val_acc": 60.0}
{"epoch": 29, "training_loss": 169.05786743164063, "training_acc": 50.0, "val_loss": 239.84939575195312, "val_acc": 60.0}
{"epoch": 30, "training_loss": 268.23512878417966, "training_acc": 50.0, "val_loss": 9.981378555297852, "val_acc": 60.0}
{"epoch": 31, "training_loss": 77.38347206115722, "training_acc": 65.0, "val_loss": 214.1420440673828, "val_acc": 40.0}
{"epoch": 32, "training_loss": 141.83194427490236, "training_acc": 50.0, "val_loss": 136.1346893310547, "val_acc": 60.0}
{"epoch": 33, "training_loss": 156.66629638671876, "training_acc": 50.0, "val_loss": 280.43353271484375, "val_acc": 60.0}
{"epoch": 34, "training_loss": 335.12333984375, "training_acc": 50.0, "val_loss": 144.50877380371094, "val_acc": 60.0}
{"epoch": 35, "training_loss": 149.07131958007812, "training_acc": 50.0, "val_loss": 216.3976593017578, "val_acc": 40.0}
{"epoch": 36, "training_loss": 181.72031860351564, "training_acc": 50.0, "val_loss": 112.0056381225586, "val_acc": 40.0}
{"epoch": 37, "training_loss": 111.10909729003906, "training_acc": 40.0, "val_loss": 103.40225982666016, "val_acc": 60.0}
{"epoch": 38, "training_loss": 101.40035934448242, "training_acc": 50.0, "val_loss": 134.18533325195312, "val_acc": 40.0}
{"epoch": 39, "training_loss": 111.59707794189453, "training_acc": 50.0, "val_loss": 162.1421356201172, "val_acc": 40.0}
{"epoch": 40, "training_loss": 120.3068380355835, "training_acc": 50.0, "val_loss": 123.244873046875, "val_acc": 60.0}
