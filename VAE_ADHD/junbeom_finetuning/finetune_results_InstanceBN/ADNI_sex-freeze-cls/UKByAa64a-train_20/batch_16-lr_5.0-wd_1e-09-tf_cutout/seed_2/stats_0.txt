"main_modify.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 2 --task ADNI_sex --input_option yAware --learning_rate 5e0 --batch_size 16 --weight_decay 1e-9 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 214.55751399993898, "training_acc": 50.0, "val_loss": 286.45355224609375, "val_acc": 60.0}
{"epoch": 1, "training_loss": 477.93182373046875, "training_acc": 40.0, "val_loss": 702.79931640625, "val_acc": 40.0}
{"epoch": 2, "training_loss": 548.2760498046875, "training_acc": 50.0, "val_loss": 24.93890953063965, "val_acc": 40.0}
{"epoch": 3, "training_loss": 112.11769561767578, "training_acc": 50.0, "val_loss": 568.9397583007812, "val_acc": 60.0}
{"epoch": 4, "training_loss": 726.240478515625, "training_acc": 50.0, "val_loss": 454.8484802246094, "val_acc": 60.0}
{"epoch": 5, "training_loss": 480.978662109375, "training_acc": 50.0, "val_loss": 203.12120056152344, "val_acc": 40.0}
{"epoch": 6, "training_loss": 193.280419921875, "training_acc": 50.0, "val_loss": 669.0612182617188, "val_acc": 40.0}
{"epoch": 7, "training_loss": 556.2681884765625, "training_acc": 50.0, "val_loss": 571.9103393554688, "val_acc": 40.0}
{"epoch": 8, "training_loss": 457.8151123046875, "training_acc": 50.0, "val_loss": 45.00624465942383, "val_acc": 40.0}
{"epoch": 9, "training_loss": 163.78078002929686, "training_acc": 30.0, "val_loss": 317.69976806640625, "val_acc": 60.0}
{"epoch": 10, "training_loss": 390.78968505859376, "training_acc": 50.0, "val_loss": 153.9647979736328, "val_acc": 60.0}
{"epoch": 11, "training_loss": 199.00743408203124, "training_acc": 40.0, "val_loss": 207.05430603027344, "val_acc": 40.0}
{"epoch": 12, "training_loss": 167.74602661132812, "training_acc": 50.0, "val_loss": 40.73042678833008, "val_acc": 40.0}
{"epoch": 13, "training_loss": 38.877803039550784, "training_acc": 60.0, "val_loss": 227.0086212158203, "val_acc": 60.0}
{"epoch": 14, "training_loss": 300.4000244140625, "training_acc": 50.0, "val_loss": 125.97077941894531, "val_acc": 60.0}
{"epoch": 15, "training_loss": 143.30760040283204, "training_acc": 50.0, "val_loss": 246.07725524902344, "val_acc": 40.0}
{"epoch": 16, "training_loss": 206.6229736328125, "training_acc": 50.0, "val_loss": 156.61160278320312, "val_acc": 40.0}
{"epoch": 17, "training_loss": 77.8028564453125, "training_acc": 70.0, "val_loss": 124.23580169677734, "val_acc": 60.0}
{"epoch": 18, "training_loss": 161.738232421875, "training_acc": 50.0, "val_loss": 82.45909881591797, "val_acc": 60.0}
{"epoch": 19, "training_loss": 78.7202522277832, "training_acc": 60.0, "val_loss": 168.69772338867188, "val_acc": 40.0}
{"epoch": 20, "training_loss": 136.30145874023438, "training_acc": 50.0, "val_loss": 8.030630111694336, "val_acc": 40.0}
{"epoch": 21, "training_loss": 63.237928771972655, "training_acc": 40.0, "val_loss": 187.67274475097656, "val_acc": 60.0}
{"epoch": 22, "training_loss": 220.62111206054686, "training_acc": 50.0, "val_loss": 11.441399574279785, "val_acc": 40.0}
{"epoch": 23, "training_loss": 34.18570404052734, "training_acc": 50.0, "val_loss": 39.95507049560547, "val_acc": 40.0}
{"epoch": 24, "training_loss": 49.641412353515626, "training_acc": 50.0, "val_loss": 130.43223571777344, "val_acc": 60.0}
{"epoch": 25, "training_loss": 152.73094177246094, "training_acc": 50.0, "val_loss": 48.74762725830078, "val_acc": 40.0}
{"epoch": 26, "training_loss": 54.60404052734375, "training_acc": 50.0, "val_loss": 3.866839647293091, "val_acc": 60.0}
{"epoch": 27, "training_loss": 6.006530380249023, "training_acc": 50.0, "val_loss": 105.1384048461914, "val_acc": 40.0}
{"epoch": 28, "training_loss": 83.11817321777343, "training_acc": 50.0, "val_loss": 17.50606346130371, "val_acc": 60.0}
{"epoch": 29, "training_loss": 26.24357376098633, "training_acc": 50.0, "val_loss": 118.34785461425781, "val_acc": 40.0}
{"epoch": 30, "training_loss": 118.18651123046875, "training_acc": 50.0, "val_loss": 5.213085651397705, "val_acc": 80.0}
{"epoch": 31, "training_loss": 30.003957176208495, "training_acc": 85.0, "val_loss": 143.36094665527344, "val_acc": 60.0}
{"epoch": 32, "training_loss": 168.09021911621093, "training_acc": 50.0, "val_loss": 38.31148910522461, "val_acc": 40.0}
{"epoch": 33, "training_loss": 33.00051422119141, "training_acc": 50.0, "val_loss": 47.458953857421875, "val_acc": 40.0}
{"epoch": 34, "training_loss": 31.061585998535158, "training_acc": 60.0, "val_loss": 83.70185852050781, "val_acc": 60.0}
{"epoch": 35, "training_loss": 101.33646659851074, "training_acc": 50.0, "val_loss": 83.1886978149414, "val_acc": 40.0}
{"epoch": 36, "training_loss": 67.06453819274903, "training_acc": 50.0, "val_loss": 5.505196571350098, "val_acc": 80.0}
{"epoch": 37, "training_loss": 8.765906143188477, "training_acc": 80.0, "val_loss": 14.182428359985352, "val_acc": 40.0}
{"epoch": 38, "training_loss": 27.42242889404297, "training_acc": 30.0, "val_loss": 101.30311584472656, "val_acc": 40.0}
{"epoch": 39, "training_loss": 82.79588317871094, "training_acc": 50.0, "val_loss": 74.24058532714844, "val_acc": 40.0}
{"epoch": 40, "training_loss": 60.92195434570313, "training_acc": 50.0, "val_loss": 65.2095947265625, "val_acc": 60.0}
{"epoch": 41, "training_loss": 68.20150108337403, "training_acc": 50.0, "val_loss": 197.4357147216797, "val_acc": 40.0}
{"epoch": 42, "training_loss": 180.90260620117186, "training_acc": 50.0, "val_loss": 175.73046875, "val_acc": 40.0}
{"epoch": 43, "training_loss": 86.5008355257989, "training_acc": 70.0, "val_loss": 108.93053436279297, "val_acc": 60.0}
{"epoch": 44, "training_loss": 151.48598022460936, "training_acc": 50.0, "val_loss": 45.91571044921875, "val_acc": 60.0}
{"epoch": 45, "training_loss": 124.37431640625, "training_acc": 30.0, "val_loss": 201.6790313720703, "val_acc": 40.0}
