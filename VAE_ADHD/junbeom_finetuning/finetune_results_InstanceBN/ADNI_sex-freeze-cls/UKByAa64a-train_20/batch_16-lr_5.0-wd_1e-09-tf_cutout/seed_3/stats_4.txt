"main_modify.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 3 --task ADNI_sex --input_option yAware --learning_rate 5e0 --batch_size 16 --weight_decay 1e-9 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 136.5150215625763, "training_acc": 55.0, "val_loss": 118.7823257446289, "val_acc": 40.0}
{"epoch": 1, "training_loss": 103.37713012695312, "training_acc": 55.0, "val_loss": 213.0234832763672, "val_acc": 60.0}
{"epoch": 2, "training_loss": 293.913623046875, "training_acc": 45.0, "val_loss": 75.6446762084961, "val_acc": 60.0}
{"epoch": 3, "training_loss": 62.7662353515625, "training_acc": 65.0, "val_loss": 669.4232788085938, "val_acc": 40.0}
{"epoch": 4, "training_loss": 514.8728149414062, "training_acc": 55.0, "val_loss": 660.3060913085938, "val_acc": 40.0}
{"epoch": 5, "training_loss": 441.6477905273438, "training_acc": 55.0, "val_loss": 32.38724899291992, "val_acc": 60.0}
{"epoch": 6, "training_loss": 86.68724975585937, "training_acc": 45.0, "val_loss": 92.68441009521484, "val_acc": 60.0}
{"epoch": 7, "training_loss": 116.05155792236329, "training_acc": 45.0, "val_loss": 200.43959045410156, "val_acc": 40.0}
{"epoch": 8, "training_loss": 129.89516906738282, "training_acc": 55.0, "val_loss": 54.56696701049805, "val_acc": 60.0}
{"epoch": 9, "training_loss": 73.65615844726562, "training_acc": 45.0, "val_loss": 23.853384017944336, "val_acc": 40.0}
{"epoch": 10, "training_loss": 14.423949050903321, "training_acc": 65.0, "val_loss": 49.84926223754883, "val_acc": 60.0}
{"epoch": 11, "training_loss": 54.11979446411133, "training_acc": 45.0, "val_loss": 159.60276794433594, "val_acc": 40.0}
{"epoch": 12, "training_loss": 109.64998474121094, "training_acc": 55.0, "val_loss": 139.3142547607422, "val_acc": 40.0}
{"epoch": 13, "training_loss": 76.25575242042541, "training_acc": 55.0, "val_loss": 22.287595748901367, "val_acc": 60.0}
{"epoch": 14, "training_loss": 18.572217559814455, "training_acc": 55.0, "val_loss": 138.58583068847656, "val_acc": 40.0}
{"epoch": 15, "training_loss": 80.59391555786132, "training_acc": 55.0, "val_loss": 98.94551849365234, "val_acc": 60.0}
{"epoch": 16, "training_loss": 138.03236389160156, "training_acc": 45.0, "val_loss": 28.385099411010742, "val_acc": 60.0}
{"epoch": 17, "training_loss": 40.23518371582031, "training_acc": 55.0, "val_loss": 408.7431945800781, "val_acc": 40.0}
{"epoch": 18, "training_loss": 294.5287109375, "training_acc": 55.0, "val_loss": 429.1358337402344, "val_acc": 40.0}
{"epoch": 19, "training_loss": 288.8568115234375, "training_acc": 55.0, "val_loss": 54.0561408996582, "val_acc": 40.0}
{"epoch": 20, "training_loss": 142.30772399902344, "training_acc": 35.0, "val_loss": 291.70098876953125, "val_acc": 60.0}
{"epoch": 21, "training_loss": 385.2224822998047, "training_acc": 45.0, "val_loss": 153.3875274658203, "val_acc": 60.0}
{"epoch": 22, "training_loss": 147.59075450897217, "training_acc": 50.0, "val_loss": 235.8960723876953, "val_acc": 40.0}
{"epoch": 23, "training_loss": 171.92312622070312, "training_acc": 55.0, "val_loss": 309.38037109375, "val_acc": 40.0}
{"epoch": 24, "training_loss": 207.40082092285155, "training_acc": 55.0, "val_loss": 11.032297134399414, "val_acc": 60.0}
{"epoch": 25, "training_loss": 49.84918022155762, "training_acc": 75.0, "val_loss": 108.83232879638672, "val_acc": 60.0}
{"epoch": 26, "training_loss": 113.517626953125, "training_acc": 40.0, "val_loss": 87.8921127319336, "val_acc": 40.0}
{"epoch": 27, "training_loss": 47.508470153808595, "training_acc": 55.0, "val_loss": 69.93255615234375, "val_acc": 60.0}
{"epoch": 28, "training_loss": 87.4882598876953, "training_acc": 45.0, "val_loss": 22.98227882385254, "val_acc": 40.0}
{"epoch": 29, "training_loss": 20.844580078125, "training_acc": 75.0, "val_loss": 24.55051612854004, "val_acc": 40.0}
{"epoch": 30, "training_loss": 24.509671020507813, "training_acc": 70.0, "val_loss": 50.59346008300781, "val_acc": 60.0}
{"epoch": 31, "training_loss": 51.75869369506836, "training_acc": 55.0, "val_loss": 137.48782348632812, "val_acc": 40.0}
{"epoch": 32, "training_loss": 75.51923828125, "training_acc": 55.0, "val_loss": 84.75969696044922, "val_acc": 60.0}
{"epoch": 33, "training_loss": 117.63966064453125, "training_acc": 45.0, "val_loss": 73.96363830566406, "val_acc": 60.0}
{"epoch": 34, "training_loss": 112.92339477539062, "training_acc": 35.0, "val_loss": 128.7868194580078, "val_acc": 40.0}
{"epoch": 35, "training_loss": 61.168430376052854, "training_acc": 65.0, "val_loss": 63.40208053588867, "val_acc": 60.0}
{"epoch": 36, "training_loss": 69.48968276977538, "training_acc": 45.0, "val_loss": 64.4892578125, "val_acc": 40.0}
{"epoch": 37, "training_loss": 33.1481689453125, "training_acc": 55.0, "val_loss": 18.69021224975586, "val_acc": 60.0}
{"epoch": 38, "training_loss": 12.799590301513671, "training_acc": 60.0, "val_loss": 93.55652618408203, "val_acc": 40.0}
{"epoch": 39, "training_loss": 53.48986663818359, "training_acc": 55.0, "val_loss": 20.41856575012207, "val_acc": 60.0}
{"epoch": 40, "training_loss": 14.00185489654541, "training_acc": 60.0, "val_loss": 25.62837791442871, "val_acc": 40.0}
{"epoch": 41, "training_loss": 11.196416854858398, "training_acc": 75.0, "val_loss": 35.63010025024414, "val_acc": 60.0}
{"epoch": 42, "training_loss": 28.72321572303772, "training_acc": 45.0, "val_loss": 97.67019653320312, "val_acc": 40.0}
{"epoch": 43, "training_loss": 49.182315063476565, "training_acc": 60.0, "val_loss": 40.5184440612793, "val_acc": 60.0}
