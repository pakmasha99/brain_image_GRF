"main_modify.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 4 --task ADNI_sex --input_option yAware --learning_rate 5e0 --batch_size 16 --weight_decay 1e-9 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 213.52878684997557, "training_acc": 50.0, "val_loss": 360.57080078125, "val_acc": 40.0}
{"epoch": 1, "training_loss": 450.2307373046875, "training_acc": 40.0, "val_loss": 551.9835815429688, "val_acc": 60.0}
{"epoch": 2, "training_loss": 666.8088165283203, "training_acc": 50.0, "val_loss": 151.8819122314453, "val_acc": 60.0}
{"epoch": 3, "training_loss": 249.62293090820313, "training_acc": 40.0, "val_loss": 432.3231506347656, "val_acc": 40.0}
{"epoch": 4, "training_loss": 359.7137939453125, "training_acc": 50.0, "val_loss": 161.24505615234375, "val_acc": 40.0}
{"epoch": 5, "training_loss": 102.44822692871094, "training_acc": 60.0, "val_loss": 172.1585235595703, "val_acc": 60.0}
{"epoch": 6, "training_loss": 206.8012954711914, "training_acc": 50.0, "val_loss": 37.66713333129883, "val_acc": 60.0}
{"epoch": 7, "training_loss": 101.26331787109375, "training_acc": 40.0, "val_loss": 275.94805908203125, "val_acc": 40.0}
{"epoch": 8, "training_loss": 202.15526123046874, "training_acc": 50.0, "val_loss": 90.5386962890625, "val_acc": 60.0}
{"epoch": 9, "training_loss": 118.29391326904297, "training_acc": 50.0, "val_loss": 185.03114318847656, "val_acc": 60.0}
{"epoch": 10, "training_loss": 207.9656219482422, "training_acc": 50.0, "val_loss": 72.56778717041016, "val_acc": 40.0}
{"epoch": 11, "training_loss": 63.94540786743164, "training_acc": 50.0, "val_loss": 114.79541015625, "val_acc": 40.0}
{"epoch": 12, "training_loss": 80.26128463745117, "training_acc": 50.0, "val_loss": 23.05615234375, "val_acc": 60.0}
{"epoch": 13, "training_loss": 49.71651916503906, "training_acc": 40.0, "val_loss": 55.99591064453125, "val_acc": 40.0}
{"epoch": 14, "training_loss": 57.78565368652344, "training_acc": 50.0, "val_loss": 111.2614974975586, "val_acc": 60.0}
{"epoch": 15, "training_loss": 117.26799850463867, "training_acc": 50.0, "val_loss": 143.51817321777344, "val_acc": 40.0}
{"epoch": 16, "training_loss": 128.0074462890625, "training_acc": 50.0, "val_loss": 138.5755157470703, "val_acc": 40.0}
{"epoch": 17, "training_loss": 137.43667297363282, "training_acc": 30.0, "val_loss": 20.178409576416016, "val_acc": 60.0}
{"epoch": 18, "training_loss": 24.219261169433594, "training_acc": 60.0, "val_loss": 203.51858520507812, "val_acc": 40.0}
{"epoch": 19, "training_loss": 162.31781692504882, "training_acc": 50.0, "val_loss": 14.218831062316895, "val_acc": 40.0}
{"epoch": 20, "training_loss": 66.54354095458984, "training_acc": 40.0, "val_loss": 183.3323516845703, "val_acc": 60.0}
{"epoch": 21, "training_loss": 205.3061767578125, "training_acc": 50.0, "val_loss": 13.026412010192871, "val_acc": 40.0}
{"epoch": 22, "training_loss": 18.15104446411133, "training_acc": 50.0, "val_loss": 5.4228434562683105, "val_acc": 60.0}
{"epoch": 23, "training_loss": 9.646625328063966, "training_acc": 70.0, "val_loss": 13.268951416015625, "val_acc": 60.0}
{"epoch": 24, "training_loss": 18.54993591308594, "training_acc": 60.0, "val_loss": 221.6118927001953, "val_acc": 40.0}
{"epoch": 25, "training_loss": 174.66673583984374, "training_acc": 50.0, "val_loss": 39.98564147949219, "val_acc": 60.0}
{"epoch": 26, "training_loss": 39.999700927734374, "training_acc": 50.0, "val_loss": 144.1355438232422, "val_acc": 60.0}
{"epoch": 27, "training_loss": 161.63250732421875, "training_acc": 50.0, "val_loss": 12.696820259094238, "val_acc": 40.0}
{"epoch": 28, "training_loss": 12.61098403930664, "training_acc": 55.0, "val_loss": 23.896718978881836, "val_acc": 60.0}
{"epoch": 29, "training_loss": 13.239874839782715, "training_acc": 60.0, "val_loss": 85.4330062866211, "val_acc": 40.0}
{"epoch": 30, "training_loss": 61.52822494506836, "training_acc": 50.0, "val_loss": 61.109222412109375, "val_acc": 60.0}
{"epoch": 31, "training_loss": 62.85906219482422, "training_acc": 50.0, "val_loss": 104.4819564819336, "val_acc": 40.0}
{"epoch": 32, "training_loss": 93.77769622802734, "training_acc": 50.0, "val_loss": 69.86346435546875, "val_acc": 40.0}
{"epoch": 33, "training_loss": 80.93934020996093, "training_acc": 40.0, "val_loss": 100.09612274169922, "val_acc": 60.0}
{"epoch": 34, "training_loss": 94.47629432678222, "training_acc": 50.0, "val_loss": 197.2733154296875, "val_acc": 40.0}
{"epoch": 35, "training_loss": 172.76819763183593, "training_acc": 50.0, "val_loss": 232.376708984375, "val_acc": 40.0}
{"epoch": 36, "training_loss": 161.26028060913086, "training_acc": 50.0, "val_loss": 137.52622985839844, "val_acc": 60.0}
{"epoch": 37, "training_loss": 209.4250732421875, "training_acc": 50.0, "val_loss": 168.35008239746094, "val_acc": 60.0}
{"epoch": 38, "training_loss": 134.74771423339843, "training_acc": 50.0, "val_loss": 340.83514404296875, "val_acc": 40.0}
{"epoch": 39, "training_loss": 295.36407165527345, "training_acc": 50.0, "val_loss": 717.0360717773438, "val_acc": 40.0}
{"epoch": 40, "training_loss": 598.1291015625, "training_acc": 50.0, "val_loss": 592.2322998046875, "val_acc": 40.0}
{"epoch": 41, "training_loss": 489.16259765625, "training_acc": 50.0, "val_loss": 47.090511322021484, "val_acc": 40.0}
