"main_modify.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 4 --task ADNI_sex --input_option yAware --learning_rate 5e0 --batch_size 16 --weight_decay 1e-9 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 427.80917329788207, "training_acc": 50.0, "val_loss": 423.1405334472656, "val_acc": 40.0}
{"epoch": 1, "training_loss": 289.7343353271484, "training_acc": 60.0, "val_loss": 729.3373413085938, "val_acc": 60.0}
{"epoch": 2, "training_loss": 922.3369201660156, "training_acc": 50.0, "val_loss": 797.09765625, "val_acc": 60.0}
{"epoch": 3, "training_loss": 973.2204284667969, "training_acc": 50.0, "val_loss": 372.9212341308594, "val_acc": 60.0}
{"epoch": 4, "training_loss": 380.95587768554685, "training_acc": 50.0, "val_loss": 571.1427612304688, "val_acc": 40.0}
{"epoch": 5, "training_loss": 569.521630859375, "training_acc": 50.0, "val_loss": 996.9349975585938, "val_acc": 40.0}
{"epoch": 6, "training_loss": 821.6099365234375, "training_acc": 50.0, "val_loss": 649.0255737304688, "val_acc": 40.0}
{"epoch": 7, "training_loss": 460.22158203125, "training_acc": 50.0, "val_loss": 113.41167449951172, "val_acc": 60.0}
{"epoch": 8, "training_loss": 187.90970458984376, "training_acc": 50.0, "val_loss": 383.9419860839844, "val_acc": 60.0}
{"epoch": 9, "training_loss": 471.7196533203125, "training_acc": 50.0, "val_loss": 217.4399871826172, "val_acc": 60.0}
{"epoch": 10, "training_loss": 216.58588714599608, "training_acc": 50.0, "val_loss": 175.9680633544922, "val_acc": 40.0}
{"epoch": 11, "training_loss": 147.82042236328124, "training_acc": 50.0, "val_loss": 141.01571655273438, "val_acc": 40.0}
{"epoch": 12, "training_loss": 84.67913856506348, "training_acc": 50.0, "val_loss": 198.83914184570312, "val_acc": 60.0}
{"epoch": 13, "training_loss": 269.331396484375, "training_acc": 50.0, "val_loss": 299.7294616699219, "val_acc": 60.0}
{"epoch": 14, "training_loss": 349.371826171875, "training_acc": 50.0, "val_loss": 57.8762092590332, "val_acc": 60.0}
{"epoch": 15, "training_loss": 127.61617431640624, "training_acc": 40.0, "val_loss": 396.1011657714844, "val_acc": 40.0}
{"epoch": 16, "training_loss": 331.9788818359375, "training_acc": 50.0, "val_loss": 226.5216827392578, "val_acc": 40.0}
{"epoch": 17, "training_loss": 134.84240608215333, "training_acc": 60.0, "val_loss": 146.0749053955078, "val_acc": 60.0}
{"epoch": 18, "training_loss": 182.98348388671874, "training_acc": 50.0, "val_loss": 113.05498504638672, "val_acc": 60.0}
{"epoch": 19, "training_loss": 113.33626937866211, "training_acc": 50.0, "val_loss": 91.73477935791016, "val_acc": 40.0}
{"epoch": 20, "training_loss": 63.137457275390624, "training_acc": 50.0, "val_loss": 128.30210876464844, "val_acc": 60.0}
{"epoch": 21, "training_loss": 167.43035583496095, "training_acc": 50.0, "val_loss": 155.80491638183594, "val_acc": 60.0}
{"epoch": 22, "training_loss": 151.23073120117186, "training_acc": 50.0, "val_loss": 224.267578125, "val_acc": 40.0}
{"epoch": 23, "training_loss": 231.95545654296876, "training_acc": 50.0, "val_loss": 376.4943542480469, "val_acc": 40.0}
{"epoch": 24, "training_loss": 291.79112548828124, "training_acc": 50.0, "val_loss": 6.792794227600098, "val_acc": 60.0}
{"epoch": 25, "training_loss": 30.22706413269043, "training_acc": 75.0, "val_loss": 145.79385375976562, "val_acc": 60.0}
{"epoch": 26, "training_loss": 164.70616912841797, "training_acc": 50.0, "val_loss": 40.454586029052734, "val_acc": 40.0}
{"epoch": 27, "training_loss": 33.4328670501709, "training_acc": 50.0, "val_loss": 9.94806957244873, "val_acc": 60.0}
{"epoch": 28, "training_loss": 4.228481674194336, "training_acc": 70.0, "val_loss": 20.837818145751953, "val_acc": 60.0}
{"epoch": 29, "training_loss": 22.423745727539064, "training_acc": 50.0, "val_loss": 11.432916641235352, "val_acc": 40.0}
{"epoch": 30, "training_loss": 30.35242614746094, "training_acc": 50.0, "val_loss": 113.6594467163086, "val_acc": 60.0}
{"epoch": 31, "training_loss": 110.76070861816406, "training_acc": 50.0, "val_loss": 183.72775268554688, "val_acc": 40.0}
{"epoch": 32, "training_loss": 171.25578918457032, "training_acc": 50.0, "val_loss": 279.5525207519531, "val_acc": 40.0}
{"epoch": 33, "training_loss": 230.3276611328125, "training_acc": 50.0, "val_loss": 30.701984405517578, "val_acc": 60.0}
{"epoch": 34, "training_loss": 35.545449829101564, "training_acc": 50.0, "val_loss": 79.52450561523438, "val_acc": 40.0}
{"epoch": 35, "training_loss": 74.69400024414062, "training_acc": 50.0, "val_loss": 26.54514503479004, "val_acc": 60.0}
{"epoch": 36, "training_loss": 27.499871826171876, "training_acc": 50.0, "val_loss": 84.340576171875, "val_acc": 40.0}
{"epoch": 37, "training_loss": 70.5552490234375, "training_acc": 50.0, "val_loss": 28.871444702148438, "val_acc": 40.0}
{"epoch": 38, "training_loss": 42.580633544921874, "training_acc": 50.0, "val_loss": 120.0962142944336, "val_acc": 60.0}
{"epoch": 39, "training_loss": 122.88643875122071, "training_acc": 50.0, "val_loss": 114.6728286743164, "val_acc": 40.0}
{"epoch": 40, "training_loss": 100.04738311767578, "training_acc": 50.0, "val_loss": 140.9434356689453, "val_acc": 40.0}
{"epoch": 41, "training_loss": 89.60678482055664, "training_acc": 50.0, "val_loss": 186.83499145507812, "val_acc": 60.0}
{"epoch": 42, "training_loss": 259.7106201171875, "training_acc": 50.0, "val_loss": 266.9578552246094, "val_acc": 60.0}
{"epoch": 43, "training_loss": 292.73253479003904, "training_acc": 50.0, "val_loss": 20.03131103515625, "val_acc": 40.0}
