"main_modify.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 4 --task ADNI_sex --input_option yAware --learning_rate 5e0 --batch_size 16 --weight_decay 1e-9 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 107.56609649658203, "training_acc": 55.0, "val_loss": 715.7802734375, "val_acc": 40.0}
{"epoch": 1, "training_loss": 451.9777526855469, "training_acc": 55.0, "val_loss": 157.6421661376953, "val_acc": 60.0}
{"epoch": 2, "training_loss": 170.46289749145507, "training_acc": 55.0, "val_loss": 277.10284423828125, "val_acc": 40.0}
{"epoch": 3, "training_loss": 178.04209594726564, "training_acc": 55.0, "val_loss": 213.9473114013672, "val_acc": 60.0}
{"epoch": 4, "training_loss": 295.7283203125, "training_acc": 45.0, "val_loss": 204.6530303955078, "val_acc": 60.0}
{"epoch": 5, "training_loss": 240.9441993713379, "training_acc": 45.0, "val_loss": 353.5863342285156, "val_acc": 40.0}
{"epoch": 6, "training_loss": 278.43511657714845, "training_acc": 55.0, "val_loss": 562.795166015625, "val_acc": 40.0}
{"epoch": 7, "training_loss": 400.9163757324219, "training_acc": 55.0, "val_loss": 156.3086700439453, "val_acc": 40.0}
{"epoch": 8, "training_loss": 131.94561462402345, "training_acc": 55.0, "val_loss": 285.2264709472656, "val_acc": 60.0}
{"epoch": 9, "training_loss": 389.07483825683596, "training_acc": 45.0, "val_loss": 171.17454528808594, "val_acc": 60.0}
{"epoch": 10, "training_loss": 172.10728979110718, "training_acc": 55.0, "val_loss": 175.17031860351562, "val_acc": 40.0}
{"epoch": 11, "training_loss": 129.4632537841797, "training_acc": 55.0, "val_loss": 68.31322479248047, "val_acc": 40.0}
{"epoch": 12, "training_loss": 64.18990936279297, "training_acc": 55.0, "val_loss": 126.98811340332031, "val_acc": 60.0}
{"epoch": 13, "training_loss": 144.81781158447265, "training_acc": 45.0, "val_loss": 249.47622680664062, "val_acc": 40.0}
{"epoch": 14, "training_loss": 197.33104248046874, "training_acc": 55.0, "val_loss": 446.4291687011719, "val_acc": 40.0}
{"epoch": 15, "training_loss": 320.4636596679687, "training_acc": 55.0, "val_loss": 148.77496337890625, "val_acc": 40.0}
{"epoch": 16, "training_loss": 113.69346923828125, "training_acc": 55.0, "val_loss": 209.43333435058594, "val_acc": 60.0}
{"epoch": 17, "training_loss": 284.7244018554687, "training_acc": 45.0, "val_loss": 50.71731185913086, "val_acc": 60.0}
{"epoch": 18, "training_loss": 102.14224243164062, "training_acc": 45.0, "val_loss": 457.1667175292969, "val_acc": 40.0}
{"epoch": 19, "training_loss": 347.5834106445312, "training_acc": 55.0, "val_loss": 397.4664001464844, "val_acc": 40.0}
{"epoch": 20, "training_loss": 247.3246826171875, "training_acc": 55.0, "val_loss": 112.677978515625, "val_acc": 60.0}
{"epoch": 21, "training_loss": 185.2723876953125, "training_acc": 45.0, "val_loss": 255.84239196777344, "val_acc": 60.0}
{"epoch": 22, "training_loss": 325.4993896484375, "training_acc": 45.0, "val_loss": 9.34795093536377, "val_acc": 40.0}
{"epoch": 23, "training_loss": 50.96638641357422, "training_acc": 60.0, "val_loss": 156.6559295654297, "val_acc": 40.0}
{"epoch": 24, "training_loss": 82.98758087158203, "training_acc": 55.0, "val_loss": 184.84056091308594, "val_acc": 60.0}
{"epoch": 25, "training_loss": 276.2927612304687, "training_acc": 45.0, "val_loss": 266.7973327636719, "val_acc": 60.0}
{"epoch": 26, "training_loss": 327.521142578125, "training_acc": 45.0, "val_loss": 72.00347900390625, "val_acc": 40.0}
{"epoch": 27, "training_loss": 87.23353271484375, "training_acc": 55.0, "val_loss": 350.45416259765625, "val_acc": 40.0}
{"epoch": 28, "training_loss": 250.7748291015625, "training_acc": 55.0, "val_loss": 94.92293548583984, "val_acc": 40.0}
{"epoch": 29, "training_loss": 61.43067474365235, "training_acc": 65.0, "val_loss": 260.5937194824219, "val_acc": 60.0}
{"epoch": 30, "training_loss": 361.1059600830078, "training_acc": 45.0, "val_loss": 247.96177673339844, "val_acc": 60.0}
{"epoch": 31, "training_loss": 324.4927734375, "training_acc": 45.0, "val_loss": 55.710262298583984, "val_acc": 40.0}
{"epoch": 32, "training_loss": 56.86137390136719, "training_acc": 55.0, "val_loss": 129.35357666015625, "val_acc": 40.0}
{"epoch": 33, "training_loss": 57.4632453918457, "training_acc": 55.0, "val_loss": 211.5067596435547, "val_acc": 60.0}
{"epoch": 34, "training_loss": 338.078857421875, "training_acc": 45.0, "val_loss": 322.0398254394531, "val_acc": 60.0}
{"epoch": 35, "training_loss": 418.46064453125, "training_acc": 45.0, "val_loss": 41.54291534423828, "val_acc": 60.0}
{"epoch": 36, "training_loss": 129.96752319335937, "training_acc": 35.0, "val_loss": 489.5119323730469, "val_acc": 40.0}
{"epoch": 37, "training_loss": 366.1576385498047, "training_acc": 55.0, "val_loss": 480.00152587890625, "val_acc": 40.0}
{"epoch": 38, "training_loss": 332.37427978515626, "training_acc": 55.0, "val_loss": 87.72718048095703, "val_acc": 40.0}
{"epoch": 39, "training_loss": 88.38453674316406, "training_acc": 55.0, "val_loss": 276.95831298828125, "val_acc": 60.0}
{"epoch": 40, "training_loss": 382.2131042480469, "training_acc": 45.0, "val_loss": 220.63919067382812, "val_acc": 60.0}
{"epoch": 41, "training_loss": 265.8901763916016, "training_acc": 45.0, "val_loss": 228.8414764404297, "val_acc": 40.0}
