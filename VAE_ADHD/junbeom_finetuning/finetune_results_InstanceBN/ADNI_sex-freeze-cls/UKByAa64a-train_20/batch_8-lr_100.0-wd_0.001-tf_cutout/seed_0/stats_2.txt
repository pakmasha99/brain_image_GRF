"main_modify.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_sex --input_option yAware --learning_rate 1e2 --batch_size 8 --weight_decay 1e-3 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 11191.313684988021, "training_acc": 50.0, "val_loss": 11970.1083984375, "val_acc": 40.0}
{"epoch": 1, "training_loss": 13224.610546875, "training_acc": 50.0, "val_loss": 6119.5224609375, "val_acc": 40.0}
{"epoch": 2, "training_loss": 4986.28125, "training_acc": 60.0, "val_loss": 9085.5732421875, "val_acc": 60.0}
{"epoch": 3, "training_loss": 8656.661181640626, "training_acc": 50.0, "val_loss": 5271.13525390625, "val_acc": 40.0}
{"epoch": 4, "training_loss": 6654.3865234375, "training_acc": 50.0, "val_loss": 7161.4609375, "val_acc": 40.0}
{"epoch": 5, "training_loss": 3239.158056640625, "training_acc": 60.0, "val_loss": 6856.515625, "val_acc": 60.0}
{"epoch": 6, "training_loss": 8705.9212890625, "training_acc": 50.0, "val_loss": 2889.573974609375, "val_acc": 60.0}
{"epoch": 7, "training_loss": 1739.52880859375, "training_acc": 70.0, "val_loss": 7860.11474609375, "val_acc": 40.0}
{"epoch": 8, "training_loss": 5343.26240234375, "training_acc": 50.0, "val_loss": 2058.91748046875, "val_acc": 60.0}
{"epoch": 9, "training_loss": 3073.41474609375, "training_acc": 50.0, "val_loss": 1428.5267333984375, "val_acc": 60.0}
{"epoch": 10, "training_loss": 1069.0923095703124, "training_acc": 60.0, "val_loss": 94.78654479980469, "val_acc": 40.0}
{"epoch": 11, "training_loss": 2999.975970458984, "training_acc": 40.0, "val_loss": 2288.71484375, "val_acc": 60.0}
{"epoch": 12, "training_loss": 2115.32880859375, "training_acc": 50.0, "val_loss": 2369.686279296875, "val_acc": 40.0}
{"epoch": 13, "training_loss": 2041.938671875, "training_acc": 40.0, "val_loss": 305.2170715332031, "val_acc": 40.0}
{"epoch": 14, "training_loss": 468.895751953125, "training_acc": 60.0, "val_loss": 781.1389770507812, "val_acc": 60.0}
{"epoch": 15, "training_loss": 447.2799072265625, "training_acc": 60.0, "val_loss": 2006.845703125, "val_acc": 60.0}
{"epoch": 16, "training_loss": 2473.882958984375, "training_acc": 50.0, "val_loss": 2515.384765625, "val_acc": 40.0}
{"epoch": 17, "training_loss": 2522.78828125, "training_acc": 50.0, "val_loss": 801.9716186523438, "val_acc": 60.0}
{"epoch": 18, "training_loss": 1187.925390625, "training_acc": 50.0, "val_loss": 3438.173583984375, "val_acc": 40.0}
{"epoch": 19, "training_loss": 3086.626611328125, "training_acc": 50.0, "val_loss": 89.63838958740234, "val_acc": 60.0}
{"epoch": 20, "training_loss": 345.89344482421876, "training_acc": 50.0, "val_loss": 298.5396423339844, "val_acc": 40.0}
{"epoch": 21, "training_loss": 634.4191223144531, "training_acc": 70.0, "val_loss": 390.654296875, "val_acc": 60.0}
{"epoch": 22, "training_loss": 1394.3469482421874, "training_acc": 50.0, "val_loss": 134.0395965576172, "val_acc": 40.0}
{"epoch": 23, "training_loss": 4221.34517211914, "training_acc": 30.0, "val_loss": 3526.717529296875, "val_acc": 60.0}
{"epoch": 24, "training_loss": 1650.60166015625, "training_acc": 70.0, "val_loss": 8720.341796875, "val_acc": 40.0}
{"epoch": 25, "training_loss": 7387.157421875, "training_acc": 50.0, "val_loss": 4185.3603515625, "val_acc": 40.0}
{"epoch": 26, "training_loss": 3285.180859375, "training_acc": 50.0, "val_loss": 3441.16796875, "val_acc": 60.0}
{"epoch": 27, "training_loss": 3500.26826171875, "training_acc": 40.0, "val_loss": 5055.67529296875, "val_acc": 40.0}
{"epoch": 28, "training_loss": 3368.244287109375, "training_acc": 50.0, "val_loss": 3076.97607421875, "val_acc": 60.0}
{"epoch": 29, "training_loss": 6947.9673828125, "training_acc": 50.0, "val_loss": 4311.77490234375, "val_acc": 60.0}
{"epoch": 30, "training_loss": 2999.5189453125, "training_acc": 50.0, "val_loss": 9550.4775390625, "val_acc": 40.0}
{"epoch": 31, "training_loss": 8187.81748046875, "training_acc": 50.0, "val_loss": 4477.0234375, "val_acc": 40.0}
{"epoch": 32, "training_loss": 2669.7748046875, "training_acc": 50.0, "val_loss": 3895.956298828125, "val_acc": 60.0}
{"epoch": 33, "training_loss": 4336.996337890625, "training_acc": 50.0, "val_loss": 4080.977294921875, "val_acc": 40.0}
{"epoch": 34, "training_loss": 4899.86787109375, "training_acc": 50.0, "val_loss": 4612.71337890625, "val_acc": 40.0}
{"epoch": 35, "training_loss": 1762.1517333984375, "training_acc": 60.0, "val_loss": 6539.80810546875, "val_acc": 60.0}
{"epoch": 36, "training_loss": 8695.3888671875, "training_acc": 50.0, "val_loss": 3222.280029296875, "val_acc": 60.0}
{"epoch": 37, "training_loss": 3413.02275390625, "training_acc": 50.0, "val_loss": 7320.64404296875, "val_acc": 40.0}
{"epoch": 38, "training_loss": 4845.38515625, "training_acc": 50.0, "val_loss": 2448.1640625, "val_acc": 60.0}
