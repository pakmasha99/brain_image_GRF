"main_modify.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_sex --input_option yAware --learning_rate 1e2 --batch_size 8 --weight_decay 1e-3 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 12815.986676406861, "training_acc": 45.0, "val_loss": 12144.3408203125, "val_acc": 40.0}
{"epoch": 1, "training_loss": 13271.290625, "training_acc": 55.0, "val_loss": 17080.9375, "val_acc": 40.0}
{"epoch": 2, "training_loss": 8936.935107421876, "training_acc": 55.0, "val_loss": 6384.84521484375, "val_acc": 60.0}
{"epoch": 3, "training_loss": 9140.1091796875, "training_acc": 45.0, "val_loss": 1845.0238037109375, "val_acc": 60.0}
{"epoch": 4, "training_loss": 1651.13837890625, "training_acc": 75.0, "val_loss": 12919.9873046875, "val_acc": 40.0}
{"epoch": 5, "training_loss": 9203.20078125, "training_acc": 55.0, "val_loss": 5360.03857421875, "val_acc": 40.0}
{"epoch": 6, "training_loss": 1123.6013580322265, "training_acc": 65.0, "val_loss": 8590.2685546875, "val_acc": 60.0}
{"epoch": 7, "training_loss": 12437.33828125, "training_acc": 45.0, "val_loss": 5358.693359375, "val_acc": 60.0}
{"epoch": 8, "training_loss": 4624.22421875, "training_acc": 45.0, "val_loss": 9600.4853515625, "val_acc": 40.0}
{"epoch": 9, "training_loss": 7696.294677734375, "training_acc": 55.0, "val_loss": 6749.97802734375, "val_acc": 40.0}
{"epoch": 10, "training_loss": 2881.8422119140623, "training_acc": 65.0, "val_loss": 5324.080078125, "val_acc": 60.0}
{"epoch": 11, "training_loss": 6880.1369140625, "training_acc": 45.0, "val_loss": 791.740478515625, "val_acc": 60.0}
{"epoch": 12, "training_loss": 4349.46650390625, "training_acc": 45.0, "val_loss": 9838.4453125, "val_acc": 40.0}
{"epoch": 13, "training_loss": 6011.08662109375, "training_acc": 55.0, "val_loss": 1762.1683349609375, "val_acc": 60.0}
{"epoch": 14, "training_loss": 4541.332861328125, "training_acc": 45.0, "val_loss": 1647.5146484375, "val_acc": 60.0}
{"epoch": 15, "training_loss": 3322.243408203125, "training_acc": 45.0, "val_loss": 5468.51904296875, "val_acc": 40.0}
{"epoch": 16, "training_loss": 3843.354150390625, "training_acc": 45.0, "val_loss": 2902.62890625, "val_acc": 60.0}
{"epoch": 17, "training_loss": 2926.928759765625, "training_acc": 45.0, "val_loss": 2403.548828125, "val_acc": 40.0}
{"epoch": 18, "training_loss": 1677.7664306640625, "training_acc": 45.0, "val_loss": 473.1122741699219, "val_acc": 60.0}
{"epoch": 19, "training_loss": 1414.272509765625, "training_acc": 55.0, "val_loss": 1168.342041015625, "val_acc": 40.0}
{"epoch": 20, "training_loss": 3192.122607421875, "training_acc": 35.0, "val_loss": 1853.125, "val_acc": 60.0}
{"epoch": 21, "training_loss": 1508.69970703125, "training_acc": 55.0, "val_loss": 3279.805908203125, "val_acc": 40.0}
{"epoch": 22, "training_loss": 1455.9275634765625, "training_acc": 65.0, "val_loss": 1295.8642578125, "val_acc": 60.0}
{"epoch": 23, "training_loss": 1472.1366333007813, "training_acc": 45.0, "val_loss": 4578.5546875, "val_acc": 40.0}
{"epoch": 24, "training_loss": 2414.317590332031, "training_acc": 55.0, "val_loss": 551.5950317382812, "val_acc": 60.0}
{"epoch": 25, "training_loss": 669.52685546875, "training_acc": 55.0, "val_loss": 936.1734619140625, "val_acc": 60.0}
{"epoch": 26, "training_loss": 1842.069775390625, "training_acc": 35.0, "val_loss": 1676.48046875, "val_acc": 40.0}
{"epoch": 27, "training_loss": 1661.884130859375, "training_acc": 35.0, "val_loss": 2378.811279296875, "val_acc": 40.0}
{"epoch": 28, "training_loss": 2267.49443359375, "training_acc": 55.0, "val_loss": 414.04376220703125, "val_acc": 40.0}
{"epoch": 29, "training_loss": 2059.7095642089844, "training_acc": 55.0, "val_loss": 2782.46875, "val_acc": 60.0}
{"epoch": 30, "training_loss": 2967.131640625, "training_acc": 45.0, "val_loss": 7066.25390625, "val_acc": 40.0}
{"epoch": 31, "training_loss": 4967.73984375, "training_acc": 55.0, "val_loss": 252.0785675048828, "val_acc": 40.0}
{"epoch": 32, "training_loss": 3007.8948669433594, "training_acc": 55.0, "val_loss": 5531.9541015625, "val_acc": 60.0}
{"epoch": 33, "training_loss": 5334.590576171875, "training_acc": 45.0, "val_loss": 5220.5361328125, "val_acc": 40.0}
{"epoch": 34, "training_loss": 6195.58876953125, "training_acc": 55.0, "val_loss": 9686.8310546875, "val_acc": 40.0}
{"epoch": 35, "training_loss": 4507.33017578125, "training_acc": 55.0, "val_loss": 4467.52099609375, "val_acc": 60.0}
{"epoch": 36, "training_loss": 8114.345703125, "training_acc": 45.0, "val_loss": 6065.9345703125, "val_acc": 60.0}
{"epoch": 37, "training_loss": 4020.0232421875, "training_acc": 65.0, "val_loss": 5863.5859375, "val_acc": 40.0}
{"epoch": 38, "training_loss": 6533.6216796875, "training_acc": 55.0, "val_loss": 6460.0, "val_acc": 40.0}
{"epoch": 39, "training_loss": 3349.0620849609377, "training_acc": 55.0, "val_loss": 6042.044921875, "val_acc": 60.0}
{"epoch": 40, "training_loss": 7539.153125, "training_acc": 45.0, "val_loss": 659.9931030273438, "val_acc": 60.0}
{"epoch": 41, "training_loss": 4885.37880859375, "training_acc": 35.0, "val_loss": 10819.673828125, "val_acc": 40.0}
{"epoch": 42, "training_loss": 7062.939990234375, "training_acc": 55.0, "val_loss": 215.44163513183594, "val_acc": 60.0}
{"epoch": 43, "training_loss": 1793.215576171875, "training_acc": 45.0, "val_loss": 518.0932006835938, "val_acc": 40.0}
{"epoch": 44, "training_loss": 1343.7972473144532, "training_acc": 55.0, "val_loss": 1238.9814453125, "val_acc": 60.0}
{"epoch": 45, "training_loss": 1946.1479064941407, "training_acc": 35.0, "val_loss": 310.75103759765625, "val_acc": 60.0}
{"epoch": 46, "training_loss": 511.51985397338865, "training_acc": 55.0, "val_loss": 1152.2181396484375, "val_acc": 60.0}
{"epoch": 47, "training_loss": 1790.994514465332, "training_acc": 35.0, "val_loss": 3482.830078125, "val_acc": 40.0}
{"epoch": 48, "training_loss": 1896.76171875, "training_acc": 55.0, "val_loss": 2698.94921875, "val_acc": 60.0}
{"epoch": 49, "training_loss": 2439.492236328125, "training_acc": 55.0, "val_loss": 3450.725830078125, "val_acc": 40.0}
{"epoch": 50, "training_loss": 2259.5873123168944, "training_acc": 55.0, "val_loss": 2404.380126953125, "val_acc": 60.0}
{"epoch": 51, "training_loss": 3010.3284423828127, "training_acc": 45.0, "val_loss": 2066.803955078125, "val_acc": 40.0}
{"epoch": 52, "training_loss": 1775.5427734375, "training_acc": 55.0, "val_loss": 399.4548034667969, "val_acc": 60.0}
{"epoch": 53, "training_loss": 373.9761047363281, "training_acc": 55.0, "val_loss": 632.6622924804688, "val_acc": 40.0}
{"epoch": 54, "training_loss": 985.7368774414062, "training_acc": 45.0, "val_loss": 1604.00146484375, "val_acc": 60.0}
{"epoch": 55, "training_loss": 3083.59599609375, "training_acc": 25.0, "val_loss": 870.9330444335938, "val_acc": 40.0}
{"epoch": 56, "training_loss": 1208.1115600585938, "training_acc": 65.0, "val_loss": 1621.1434326171875, "val_acc": 60.0}
{"epoch": 57, "training_loss": 2458.64072265625, "training_acc": 35.0, "val_loss": 642.607666015625, "val_acc": 40.0}
{"epoch": 58, "training_loss": 2692.654638671875, "training_acc": 45.0, "val_loss": 1934.0731201171875, "val_acc": 60.0}
{"epoch": 59, "training_loss": 1908.952880859375, "training_acc": 55.0, "val_loss": 3125.669677734375, "val_acc": 40.0}
{"epoch": 60, "training_loss": 1428.7450561523438, "training_acc": 35.0, "val_loss": 2843.939697265625, "val_acc": 40.0}
{"epoch": 61, "training_loss": 2133.0101318359375, "training_acc": 55.0, "val_loss": 962.568359375, "val_acc": 60.0}
