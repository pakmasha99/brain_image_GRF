"main_modify.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 5 --task ADNI_sex --input_option yAware --learning_rate 1e2 --batch_size 8 --weight_decay 1e-3 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 10234.0247307539, "training_acc": 45.0, "val_loss": 6326.0986328125, "val_acc": 60.0}
{"epoch": 1, "training_loss": 11463.56328125, "training_acc": 45.0, "val_loss": 2046.903564453125, "val_acc": 60.0}
{"epoch": 2, "training_loss": 3690.32060546875, "training_acc": 65.0, "val_loss": 14626.9951171875, "val_acc": 40.0}
{"epoch": 3, "training_loss": 8799.67998046875, "training_acc": 55.0, "val_loss": 1809.239501953125, "val_acc": 60.0}
{"epoch": 4, "training_loss": 5886.27412109375, "training_acc": 45.0, "val_loss": 2263.2265625, "val_acc": 60.0}
{"epoch": 5, "training_loss": 5164.10478515625, "training_acc": 45.0, "val_loss": 8077.33984375, "val_acc": 40.0}
{"epoch": 6, "training_loss": 3755.9939453125, "training_acc": 55.0, "val_loss": 2090.97607421875, "val_acc": 60.0}
{"epoch": 7, "training_loss": 1985.6338317871093, "training_acc": 45.0, "val_loss": 5906.4130859375, "val_acc": 40.0}
{"epoch": 8, "training_loss": 6115.1853515625, "training_acc": 55.0, "val_loss": 7255.23828125, "val_acc": 40.0}
{"epoch": 9, "training_loss": 4430.1072265625, "training_acc": 45.0, "val_loss": 2646.9501953125, "val_acc": 60.0}
{"epoch": 10, "training_loss": 2321.46155090332, "training_acc": 55.0, "val_loss": 2274.87890625, "val_acc": 40.0}
{"epoch": 11, "training_loss": 1290.6383056640625, "training_acc": 55.0, "val_loss": 405.52252197265625, "val_acc": 60.0}
{"epoch": 12, "training_loss": 2828.1640869140624, "training_acc": 25.0, "val_loss": 1363.72314453125, "val_acc": 40.0}
{"epoch": 13, "training_loss": 801.5983276367188, "training_acc": 75.0, "val_loss": 1798.973876953125, "val_acc": 60.0}
{"epoch": 14, "training_loss": 1285.67470703125, "training_acc": 55.0, "val_loss": 6828.62451171875, "val_acc": 40.0}
{"epoch": 15, "training_loss": 4658.00048828125, "training_acc": 55.0, "val_loss": 376.525390625, "val_acc": 40.0}
{"epoch": 16, "training_loss": 2622.8759643554686, "training_acc": 55.0, "val_loss": 4815.18310546875, "val_acc": 60.0}
{"epoch": 17, "training_loss": 4538.15537109375, "training_acc": 45.0, "val_loss": 5796.99365234375, "val_acc": 40.0}
{"epoch": 18, "training_loss": 5043.531640625, "training_acc": 55.0, "val_loss": 8993.876953125, "val_acc": 40.0}
{"epoch": 19, "training_loss": 4946.283740234375, "training_acc": 55.0, "val_loss": 2809.959716796875, "val_acc": 60.0}
{"epoch": 20, "training_loss": 5669.4923828125, "training_acc": 45.0, "val_loss": 2873.170654296875, "val_acc": 60.0}
{"epoch": 21, "training_loss": 5224.47587890625, "training_acc": 25.0, "val_loss": 4416.2705078125, "val_acc": 40.0}
{"epoch": 22, "training_loss": 3209.3042907714844, "training_acc": 45.0, "val_loss": 4448.6767578125, "val_acc": 60.0}
{"epoch": 23, "training_loss": 5321.5529296875, "training_acc": 45.0, "val_loss": 3573.84814453125, "val_acc": 40.0}
{"epoch": 24, "training_loss": 3570.110107421875, "training_acc": 55.0, "val_loss": 5516.86865234375, "val_acc": 40.0}
{"epoch": 25, "training_loss": 2558.3599609375, "training_acc": 55.0, "val_loss": 2468.833740234375, "val_acc": 60.0}
{"epoch": 26, "training_loss": 2590.2873153209684, "training_acc": 50.0, "val_loss": 1893.439697265625, "val_acc": 40.0}
{"epoch": 27, "training_loss": 1173.0018188476563, "training_acc": 55.0, "val_loss": 210.60220336914062, "val_acc": 60.0}
{"epoch": 28, "training_loss": 1478.5796997070313, "training_acc": 45.0, "val_loss": 798.8341674804688, "val_acc": 40.0}
{"epoch": 29, "training_loss": 2225.424072265625, "training_acc": 45.0, "val_loss": 1688.3719482421875, "val_acc": 60.0}
{"epoch": 30, "training_loss": 1889.511865234375, "training_acc": 45.0, "val_loss": 1166.9422607421875, "val_acc": 40.0}
{"epoch": 31, "training_loss": 1141.373583984375, "training_acc": 55.0, "val_loss": 62.4329833984375, "val_acc": 60.0}
{"epoch": 32, "training_loss": 1216.0330535888672, "training_acc": 55.0, "val_loss": 2235.589599609375, "val_acc": 40.0}
{"epoch": 33, "training_loss": 857.8378173828125, "training_acc": 65.0, "val_loss": 3344.25, "val_acc": 60.0}
{"epoch": 34, "training_loss": 3255.1121826171875, "training_acc": 45.0, "val_loss": 5185.93896484375, "val_acc": 40.0}
{"epoch": 35, "training_loss": 6387.0013671875, "training_acc": 55.0, "val_loss": 7547.5791015625, "val_acc": 40.0}
{"epoch": 36, "training_loss": 3486.600732421875, "training_acc": 55.0, "val_loss": 3735.585205078125, "val_acc": 60.0}
{"epoch": 37, "training_loss": 4425.876171875, "training_acc": 45.0, "val_loss": 2386.504638671875, "val_acc": 40.0}
{"epoch": 38, "training_loss": 2935.91240234375, "training_acc": 55.0, "val_loss": 3274.198974609375, "val_acc": 40.0}
{"epoch": 39, "training_loss": 2131.6087036132812, "training_acc": 45.0, "val_loss": 5415.326171875, "val_acc": 60.0}
{"epoch": 40, "training_loss": 6296.276318359375, "training_acc": 45.0, "val_loss": 2449.3193359375, "val_acc": 40.0}
{"epoch": 41, "training_loss": 3392.6009765625, "training_acc": 55.0, "val_loss": 4170.35595703125, "val_acc": 40.0}
{"epoch": 42, "training_loss": 1311.4224853515625, "training_acc": 65.0, "val_loss": 5669.73486328125, "val_acc": 60.0}
{"epoch": 43, "training_loss": 7155.1419921875, "training_acc": 45.0, "val_loss": 520.7442016601562, "val_acc": 60.0}
{"epoch": 44, "training_loss": 6000.56181640625, "training_acc": 25.0, "val_loss": 11658.9599609375, "val_acc": 40.0}
{"epoch": 45, "training_loss": 8127.9408203125, "training_acc": 55.0, "val_loss": 1044.6549072265625, "val_acc": 60.0}
{"epoch": 46, "training_loss": 1518.7744018554688, "training_acc": 45.0, "val_loss": 2248.92724609375, "val_acc": 40.0}
{"epoch": 47, "training_loss": 2120.784521484375, "training_acc": 55.0, "val_loss": 899.9892578125, "val_acc": 60.0}
{"epoch": 48, "training_loss": 1112.4115356445313, "training_acc": 45.0, "val_loss": 3386.649658203125, "val_acc": 40.0}
{"epoch": 49, "training_loss": 2758.0001953125, "training_acc": 55.0, "val_loss": 199.86630249023438, "val_acc": 60.0}
{"epoch": 50, "training_loss": 415.7107696533203, "training_acc": 45.0, "val_loss": 4159.98779296875, "val_acc": 40.0}
