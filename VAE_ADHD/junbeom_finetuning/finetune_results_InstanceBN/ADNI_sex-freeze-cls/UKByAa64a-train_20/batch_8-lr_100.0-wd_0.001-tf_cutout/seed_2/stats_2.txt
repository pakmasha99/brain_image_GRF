"main_modify.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 2 --task ADNI_sex --input_option yAware --learning_rate 1e2 --batch_size 8 --weight_decay 1e-3 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 7627.697453546524, "training_acc": 60.0, "val_loss": 14072.4736328125, "val_acc": 40.0}
{"epoch": 1, "training_loss": 12399.4025390625, "training_acc": 50.0, "val_loss": 5165.98828125, "val_acc": 40.0}
{"epoch": 2, "training_loss": 8354.453125, "training_acc": 40.0, "val_loss": 9263.5244140625, "val_acc": 60.0}
{"epoch": 3, "training_loss": 8900.979174804688, "training_acc": 50.0, "val_loss": 6876.93603515625, "val_acc": 40.0}
{"epoch": 4, "training_loss": 8785.8744140625, "training_acc": 50.0, "val_loss": 9112.2001953125, "val_acc": 40.0}
{"epoch": 5, "training_loss": 4507.74521484375, "training_acc": 50.0, "val_loss": 5987.00830078125, "val_acc": 60.0}
{"epoch": 6, "training_loss": 7755.40703125, "training_acc": 50.0, "val_loss": 2739.29345703125, "val_acc": 60.0}
{"epoch": 7, "training_loss": 1799.549560546875, "training_acc": 50.0, "val_loss": 2620.97265625, "val_acc": 40.0}
{"epoch": 8, "training_loss": 1664.2417236328124, "training_acc": 50.0, "val_loss": 2598.676513671875, "val_acc": 60.0}
{"epoch": 9, "training_loss": 1969.7326721191407, "training_acc": 60.0, "val_loss": 2473.963623046875, "val_acc": 40.0}
{"epoch": 10, "training_loss": 2008.807177734375, "training_acc": 40.0, "val_loss": 1261.020263671875, "val_acc": 60.0}
{"epoch": 11, "training_loss": 1562.1005859375, "training_acc": 40.0, "val_loss": 918.1744995117188, "val_acc": 60.0}
{"epoch": 12, "training_loss": 1005.902880859375, "training_acc": 50.0, "val_loss": 4125.72900390625, "val_acc": 40.0}
{"epoch": 13, "training_loss": 4142.309765625, "training_acc": 50.0, "val_loss": 1762.5845947265625, "val_acc": 40.0}
{"epoch": 14, "training_loss": 3709.97158203125, "training_acc": 40.0, "val_loss": 3745.503173828125, "val_acc": 60.0}
{"epoch": 15, "training_loss": 2947.517333984375, "training_acc": 50.0, "val_loss": 4738.78125, "val_acc": 40.0}
{"epoch": 16, "training_loss": 3175.963525390625, "training_acc": 50.0, "val_loss": 1851.9390869140625, "val_acc": 60.0}
{"epoch": 17, "training_loss": 2964.22734375, "training_acc": 50.0, "val_loss": 723.3154296875, "val_acc": 60.0}
{"epoch": 18, "training_loss": 3508.673583984375, "training_acc": 40.0, "val_loss": 6504.66064453125, "val_acc": 40.0}
{"epoch": 19, "training_loss": 4275.00595703125, "training_acc": 40.0, "val_loss": 2240.1298828125, "val_acc": 60.0}
{"epoch": 20, "training_loss": 2444.2447265625, "training_acc": 40.0, "val_loss": 1747.052978515625, "val_acc": 40.0}
{"epoch": 21, "training_loss": 1246.748828125, "training_acc": 40.0, "val_loss": 1616.72021484375, "val_acc": 40.0}
{"epoch": 22, "training_loss": 1311.4680633544922, "training_acc": 50.0, "val_loss": 89.56526184082031, "val_acc": 60.0}
{"epoch": 23, "training_loss": 1141.0532836914062, "training_acc": 50.0, "val_loss": 430.493408203125, "val_acc": 60.0}
{"epoch": 24, "training_loss": 589.4774658203125, "training_acc": 50.0, "val_loss": 233.8022003173828, "val_acc": 40.0}
{"epoch": 25, "training_loss": 3376.3299194335937, "training_acc": 20.0, "val_loss": 1248.7845458984375, "val_acc": 60.0}
{"epoch": 26, "training_loss": 1057.9325927734376, "training_acc": 70.0, "val_loss": 3808.0859375, "val_acc": 40.0}
{"epoch": 27, "training_loss": 2206.038916015625, "training_acc": 50.0, "val_loss": 2167.63818359375, "val_acc": 60.0}
{"epoch": 28, "training_loss": 2005.580859375, "training_acc": 50.0, "val_loss": 1776.5467529296875, "val_acc": 40.0}
{"epoch": 29, "training_loss": 1212.86142578125, "training_acc": 50.0, "val_loss": 2946.03662109375, "val_acc": 60.0}
{"epoch": 30, "training_loss": 2644.922985839844, "training_acc": 50.0, "val_loss": 5274.85302734375, "val_acc": 40.0}
{"epoch": 31, "training_loss": 5573.75986328125, "training_acc": 50.0, "val_loss": 4742.06103515625, "val_acc": 40.0}
{"epoch": 32, "training_loss": 2710.161683654785, "training_acc": 50.0, "val_loss": 1191.0054931640625, "val_acc": 60.0}
{"epoch": 33, "training_loss": 1039.7797729492188, "training_acc": 60.0, "val_loss": 1259.73828125, "val_acc": 40.0}
{"epoch": 34, "training_loss": 1712.3046020507813, "training_acc": 40.0, "val_loss": 188.5833740234375, "val_acc": 60.0}
{"epoch": 35, "training_loss": 1343.4068420410156, "training_acc": 60.0, "val_loss": 2127.704833984375, "val_acc": 40.0}
{"epoch": 36, "training_loss": 1620.6966796875, "training_acc": 50.0, "val_loss": 738.7317504882812, "val_acc": 60.0}
{"epoch": 37, "training_loss": 1920.6633544921874, "training_acc": 50.0, "val_loss": 1623.3857421875, "val_acc": 40.0}
{"epoch": 38, "training_loss": 2749.5609375, "training_acc": 40.0, "val_loss": 2314.317626953125, "val_acc": 60.0}
{"epoch": 39, "training_loss": 2296.1513732910157, "training_acc": 40.0, "val_loss": 371.8575134277344, "val_acc": 60.0}
{"epoch": 40, "training_loss": 829.2153259277344, "training_acc": 50.0, "val_loss": 160.49484252929688, "val_acc": 40.0}
{"epoch": 41, "training_loss": 1723.245361328125, "training_acc": 40.0, "val_loss": 393.2568359375, "val_acc": 60.0}
