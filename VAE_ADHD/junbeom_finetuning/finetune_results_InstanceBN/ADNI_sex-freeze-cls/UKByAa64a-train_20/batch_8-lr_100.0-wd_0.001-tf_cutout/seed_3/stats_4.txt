"main_modify.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 3 --task ADNI_sex --input_option yAware --learning_rate 1e2 --batch_size 8 --weight_decay 1e-3 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 11944.582190322875, "training_acc": 45.0, "val_loss": 12936.1337890625, "val_acc": 40.0}
{"epoch": 1, "training_loss": 13960.0623046875, "training_acc": 55.0, "val_loss": 13866.3828125, "val_acc": 40.0}
{"epoch": 2, "training_loss": 6928.4892578125, "training_acc": 55.0, "val_loss": 9849.5576171875, "val_acc": 60.0}
{"epoch": 3, "training_loss": 13166.47353515625, "training_acc": 45.0, "val_loss": 2945.927001953125, "val_acc": 60.0}
{"epoch": 4, "training_loss": 5441.876171875, "training_acc": 45.0, "val_loss": 10314.138671875, "val_acc": 40.0}
{"epoch": 5, "training_loss": 5827.6052734375, "training_acc": 55.0, "val_loss": 2561.186767578125, "val_acc": 60.0}
{"epoch": 6, "training_loss": 5557.286328125, "training_acc": 45.0, "val_loss": 2600.766357421875, "val_acc": 60.0}
{"epoch": 7, "training_loss": 2601.827490234375, "training_acc": 55.0, "val_loss": 5538.6044921875, "val_acc": 40.0}
{"epoch": 8, "training_loss": 2705.7163024902343, "training_acc": 55.0, "val_loss": 3868.372802734375, "val_acc": 60.0}
{"epoch": 9, "training_loss": 5833.100048828125, "training_acc": 45.0, "val_loss": 2417.1376953125, "val_acc": 60.0}
{"epoch": 10, "training_loss": 3013.17666015625, "training_acc": 45.0, "val_loss": 3546.188232421875, "val_acc": 40.0}
{"epoch": 11, "training_loss": 1295.6890380859375, "training_acc": 65.0, "val_loss": 3575.061767578125, "val_acc": 60.0}
{"epoch": 12, "training_loss": 4625.253369140625, "training_acc": 45.0, "val_loss": 2749.78955078125, "val_acc": 40.0}
{"epoch": 13, "training_loss": 3052.13037109375, "training_acc": 55.0, "val_loss": 3289.007080078125, "val_acc": 40.0}
{"epoch": 14, "training_loss": 1701.4752319335937, "training_acc": 55.0, "val_loss": 3988.94384765625, "val_acc": 60.0}
{"epoch": 15, "training_loss": 4140.389697265625, "training_acc": 45.0, "val_loss": 4554.97998046875, "val_acc": 40.0}
{"epoch": 16, "training_loss": 6146.3927734375, "training_acc": 55.0, "val_loss": 7819.1484375, "val_acc": 40.0}
{"epoch": 17, "training_loss": 4801.499462890625, "training_acc": 45.0, "val_loss": 3545.712890625, "val_acc": 60.0}
{"epoch": 18, "training_loss": 3965.9535064697266, "training_acc": 45.0, "val_loss": 4453.00341796875, "val_acc": 40.0}
{"epoch": 19, "training_loss": 4473.642578125, "training_acc": 55.0, "val_loss": 3614.93994140625, "val_acc": 40.0}
{"epoch": 20, "training_loss": 1580.072314453125, "training_acc": 55.0, "val_loss": 1116.238525390625, "val_acc": 60.0}
{"epoch": 21, "training_loss": 1303.42412109375, "training_acc": 55.0, "val_loss": 933.8358764648438, "val_acc": 40.0}
{"epoch": 22, "training_loss": 409.0513916015625, "training_acc": 75.0, "val_loss": 211.98709106445312, "val_acc": 40.0}
{"epoch": 23, "training_loss": 900.4969482421875, "training_acc": 35.0, "val_loss": 4382.96044921875, "val_acc": 40.0}
{"epoch": 24, "training_loss": 4702.6759765625, "training_acc": 55.0, "val_loss": 4553.234375, "val_acc": 40.0}
{"epoch": 25, "training_loss": 1919.9072875976562, "training_acc": 45.0, "val_loss": 500.5364685058594, "val_acc": 60.0}
{"epoch": 26, "training_loss": 2814.8649658203126, "training_acc": 35.0, "val_loss": 2753.27197265625, "val_acc": 40.0}
{"epoch": 27, "training_loss": 2771.77216796875, "training_acc": 35.0, "val_loss": 1168.0045166015625, "val_acc": 60.0}
{"epoch": 28, "training_loss": 1146.6587890625, "training_acc": 65.0, "val_loss": 1955.8306884765625, "val_acc": 40.0}
{"epoch": 29, "training_loss": 306.3617309570312, "training_acc": 75.0, "val_loss": 4246.51611328125, "val_acc": 60.0}
{"epoch": 30, "training_loss": 5356.5875, "training_acc": 45.0, "val_loss": 2170.687255859375, "val_acc": 40.0}
{"epoch": 31, "training_loss": 2061.5271484375, "training_acc": 55.0, "val_loss": 905.2530517578125, "val_acc": 60.0}
{"epoch": 32, "training_loss": 1497.846533203125, "training_acc": 35.0, "val_loss": 15.99836254119873, "val_acc": 60.0}
{"epoch": 33, "training_loss": 1367.3784561157227, "training_acc": 35.0, "val_loss": 936.1549072265625, "val_acc": 60.0}
{"epoch": 34, "training_loss": 1501.6385375976563, "training_acc": 45.0, "val_loss": 3770.266845703125, "val_acc": 40.0}
{"epoch": 35, "training_loss": 3683.38720703125, "training_acc": 55.0, "val_loss": 1524.6392822265625, "val_acc": 40.0}
{"epoch": 36, "training_loss": 3335.223828125, "training_acc": 45.0, "val_loss": 3951.608642578125, "val_acc": 60.0}
{"epoch": 37, "training_loss": 2708.0595703125, "training_acc": 65.0, "val_loss": 5526.32373046875, "val_acc": 40.0}
{"epoch": 38, "training_loss": 4000.81171875, "training_acc": 55.0, "val_loss": 1454.973876953125, "val_acc": 40.0}
{"epoch": 39, "training_loss": 4019.35439453125, "training_acc": 35.0, "val_loss": 3216.727783203125, "val_acc": 60.0}
{"epoch": 40, "training_loss": 2747.600439453125, "training_acc": 45.0, "val_loss": 8408.8232421875, "val_acc": 40.0}
{"epoch": 41, "training_loss": 6619.343359375, "training_acc": 55.0, "val_loss": 3588.27001953125, "val_acc": 40.0}
{"epoch": 42, "training_loss": 1728.908203125, "training_acc": 55.0, "val_loss": 2178.17578125, "val_acc": 60.0}
{"epoch": 43, "training_loss": 2710.356884765625, "training_acc": 35.0, "val_loss": 5222.62646484375, "val_acc": 40.0}
{"epoch": 44, "training_loss": 3282.593426513672, "training_acc": 55.0, "val_loss": 2278.423095703125, "val_acc": 60.0}
{"epoch": 45, "training_loss": 3365.77431640625, "training_acc": 45.0, "val_loss": 849.4794921875, "val_acc": 40.0}
{"epoch": 46, "training_loss": 966.5315765380859, "training_acc": 55.0, "val_loss": 1197.153564453125, "val_acc": 60.0}
{"epoch": 47, "training_loss": 1692.4430908203126, "training_acc": 45.0, "val_loss": 1490.412353515625, "val_acc": 40.0}
{"epoch": 48, "training_loss": 1390.1780212402343, "training_acc": 45.0, "val_loss": 2561.3740234375, "val_acc": 60.0}
{"epoch": 49, "training_loss": 2110.8183349609376, "training_acc": 55.0, "val_loss": 6078.10107421875, "val_acc": 40.0}
{"epoch": 50, "training_loss": 4119.7891845703125, "training_acc": 55.0, "val_loss": 482.5651550292969, "val_acc": 60.0}
{"epoch": 51, "training_loss": 1296.2260620117188, "training_acc": 45.0, "val_loss": 4291.8359375, "val_acc": 40.0}
