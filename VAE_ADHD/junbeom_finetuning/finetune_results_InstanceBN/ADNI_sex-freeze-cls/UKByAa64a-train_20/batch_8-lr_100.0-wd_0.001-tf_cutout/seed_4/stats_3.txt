"main_modify.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 4 --task ADNI_sex --input_option yAware --learning_rate 1e2 --batch_size 8 --weight_decay 1e-3 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 15376.77711429596, "training_acc": 45.0, "val_loss": 9262.3115234375, "val_acc": 40.0}
{"epoch": 1, "training_loss": 9634.6814453125, "training_acc": 55.0, "val_loss": 14665.9658203125, "val_acc": 40.0}
{"epoch": 2, "training_loss": 7056.43359375, "training_acc": 55.0, "val_loss": 4826.2978515625, "val_acc": 60.0}
{"epoch": 3, "training_loss": 5939.37861328125, "training_acc": 45.0, "val_loss": 2513.7451171875, "val_acc": 40.0}
{"epoch": 4, "training_loss": 3407.37177734375, "training_acc": 55.0, "val_loss": 2281.91259765625, "val_acc": 40.0}
{"epoch": 5, "training_loss": 940.2872924804688, "training_acc": 75.0, "val_loss": 1356.8607177734375, "val_acc": 60.0}
{"epoch": 6, "training_loss": 1374.0388671875, "training_acc": 55.0, "val_loss": 1626.7099609375, "val_acc": 40.0}
{"epoch": 7, "training_loss": 1153.6511962890625, "training_acc": 35.0, "val_loss": 1373.232177734375, "val_acc": 60.0}
{"epoch": 8, "training_loss": 1583.7288818359375, "training_acc": 45.0, "val_loss": 2561.939697265625, "val_acc": 40.0}
{"epoch": 9, "training_loss": 1083.4111694335938, "training_acc": 65.0, "val_loss": 2460.6640625, "val_acc": 60.0}
{"epoch": 10, "training_loss": 2604.641943359375, "training_acc": 45.0, "val_loss": 3522.83203125, "val_acc": 40.0}
{"epoch": 11, "training_loss": 1937.7061279296875, "training_acc": 55.0, "val_loss": 714.5457763671875, "val_acc": 60.0}
{"epoch": 12, "training_loss": 449.7783142089844, "training_acc": 55.0, "val_loss": 2267.52783203125, "val_acc": 40.0}
{"epoch": 13, "training_loss": 1871.0419677734376, "training_acc": 55.0, "val_loss": 1829.1356201171875, "val_acc": 60.0}
{"epoch": 14, "training_loss": 2405.601611328125, "training_acc": 45.0, "val_loss": 4004.751220703125, "val_acc": 40.0}
{"epoch": 15, "training_loss": 4163.35322265625, "training_acc": 55.0, "val_loss": 2568.632080078125, "val_acc": 40.0}
{"epoch": 16, "training_loss": 2715.0462890625, "training_acc": 55.0, "val_loss": 2939.080322265625, "val_acc": 60.0}
{"epoch": 17, "training_loss": 4258.413598632813, "training_acc": 25.0, "val_loss": 8388.5673828125, "val_acc": 40.0}
{"epoch": 18, "training_loss": 5534.73486328125, "training_acc": 55.0, "val_loss": 307.7904357910156, "val_acc": 60.0}
{"epoch": 19, "training_loss": 2382.120227050781, "training_acc": 45.0, "val_loss": 657.9623413085938, "val_acc": 60.0}
{"epoch": 20, "training_loss": 2196.924462890625, "training_acc": 55.0, "val_loss": 6809.08544921875, "val_acc": 40.0}
{"epoch": 21, "training_loss": 3471.8389404296877, "training_acc": 55.0, "val_loss": 3066.781982421875, "val_acc": 60.0}
{"epoch": 22, "training_loss": 5837.7947265625, "training_acc": 45.0, "val_loss": 2842.78076171875, "val_acc": 60.0}
{"epoch": 23, "training_loss": 3871.7458984375, "training_acc": 45.0, "val_loss": 6320.333984375, "val_acc": 40.0}
{"epoch": 24, "training_loss": 3143.5396240234377, "training_acc": 55.0, "val_loss": 3612.421142578125, "val_acc": 60.0}
{"epoch": 25, "training_loss": 6534.9873046875, "training_acc": 45.0, "val_loss": 3162.500244140625, "val_acc": 60.0}
{"epoch": 26, "training_loss": 2211.547015380859, "training_acc": 55.0, "val_loss": 3566.935302734375, "val_acc": 40.0}
{"epoch": 27, "training_loss": 3020.5500244140626, "training_acc": 35.0, "val_loss": 2211.49658203125, "val_acc": 60.0}
{"epoch": 28, "training_loss": 2573.754278564453, "training_acc": 25.0, "val_loss": 82.26876068115234, "val_acc": 60.0}
{"epoch": 29, "training_loss": 793.1249755859375, "training_acc": 45.0, "val_loss": 1336.058837890625, "val_acc": 60.0}
{"epoch": 30, "training_loss": 1984.0001953125, "training_acc": 45.0, "val_loss": 3232.06640625, "val_acc": 40.0}
{"epoch": 31, "training_loss": 2594.7982421875, "training_acc": 55.0, "val_loss": 731.7171630859375, "val_acc": 40.0}
{"epoch": 32, "training_loss": 3381.250439453125, "training_acc": 45.0, "val_loss": 2706.37890625, "val_acc": 60.0}
{"epoch": 33, "training_loss": 2295.1751708984375, "training_acc": 45.0, "val_loss": 3102.2509765625, "val_acc": 40.0}
{"epoch": 34, "training_loss": 1699.1183349609375, "training_acc": 55.0, "val_loss": 2025.0172119140625, "val_acc": 60.0}
{"epoch": 35, "training_loss": 2550.79853515625, "training_acc": 35.0, "val_loss": 4085.970703125, "val_acc": 40.0}
{"epoch": 36, "training_loss": 1889.9717041015624, "training_acc": 55.0, "val_loss": 3497.578857421875, "val_acc": 60.0}
{"epoch": 37, "training_loss": 6864.20087890625, "training_acc": 45.0, "val_loss": 3200.482666015625, "val_acc": 60.0}
{"epoch": 38, "training_loss": 1924.9051208496094, "training_acc": 55.0, "val_loss": 3737.85791015625, "val_acc": 40.0}
{"epoch": 39, "training_loss": 2076.5509033203125, "training_acc": 55.0, "val_loss": 3196.33984375, "val_acc": 60.0}
{"epoch": 40, "training_loss": 5023.2822265625, "training_acc": 45.0, "val_loss": 1439.8365478515625, "val_acc": 60.0}
{"epoch": 41, "training_loss": 2188.001123046875, "training_acc": 55.0, "val_loss": 6299.6376953125, "val_acc": 40.0}
{"epoch": 42, "training_loss": 3316.77451171875, "training_acc": 55.0, "val_loss": 2710.871826171875, "val_acc": 60.0}
{"epoch": 43, "training_loss": 5480.4150390625, "training_acc": 45.0, "val_loss": 2494.08544921875, "val_acc": 60.0}
{"epoch": 44, "training_loss": 1850.5323608398437, "training_acc": 65.0, "val_loss": 4954.91552734375, "val_acc": 40.0}
{"epoch": 45, "training_loss": 2860.6980834960937, "training_acc": 45.0, "val_loss": 595.2465209960938, "val_acc": 60.0}
{"epoch": 46, "training_loss": 1112.392529296875, "training_acc": 45.0, "val_loss": 589.8709106445312, "val_acc": 60.0}
{"epoch": 47, "training_loss": 1143.488330078125, "training_acc": 45.0, "val_loss": 2059.252685546875, "val_acc": 40.0}
