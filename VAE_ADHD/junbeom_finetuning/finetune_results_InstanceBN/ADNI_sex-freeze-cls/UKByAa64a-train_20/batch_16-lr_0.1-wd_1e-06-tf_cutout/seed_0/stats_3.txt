"main_modify.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_sex --input_option yAware --learning_rate 1e-1 --batch_size 16 --weight_decay 1e-6 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 4.81818265914917, "training_acc": 45.0, "val_loss": 9.777396202087402, "val_acc": 40.0}
{"epoch": 1, "training_loss": 9.105943870544433, "training_acc": 45.0, "val_loss": 7.353359222412109, "val_acc": 60.0}
{"epoch": 2, "training_loss": 9.064640235900878, "training_acc": 45.0, "val_loss": 5.421367645263672, "val_acc": 40.0}
{"epoch": 3, "training_loss": 5.272140693664551, "training_acc": 55.0, "val_loss": 7.8353190422058105, "val_acc": 40.0}
{"epoch": 4, "training_loss": 4.92824273109436, "training_acc": 55.0, "val_loss": 4.047338962554932, "val_acc": 60.0}
{"epoch": 5, "training_loss": 6.079310607910156, "training_acc": 45.0, "val_loss": 5.63001012802124, "val_acc": 60.0}
{"epoch": 6, "training_loss": 6.758521556854248, "training_acc": 45.0, "val_loss": 3.294661045074463, "val_acc": 40.0}
{"epoch": 7, "training_loss": 3.164804744720459, "training_acc": 55.0, "val_loss": 8.522040367126465, "val_acc": 40.0}
{"epoch": 8, "training_loss": 6.001947593688965, "training_acc": 55.0, "val_loss": 1.7865028381347656, "val_acc": 40.0}
{"epoch": 9, "training_loss": 2.535327339172363, "training_acc": 45.0, "val_loss": 5.196567058563232, "val_acc": 60.0}
{"epoch": 10, "training_loss": 7.025445508956909, "training_acc": 45.0, "val_loss": 2.7727463245391846, "val_acc": 60.0}
{"epoch": 11, "training_loss": 3.268425703048706, "training_acc": 45.0, "val_loss": 3.846459150314331, "val_acc": 40.0}
{"epoch": 12, "training_loss": 2.9076864242553713, "training_acc": 55.0, "val_loss": 2.1072957515716553, "val_acc": 40.0}
{"epoch": 13, "training_loss": 1.520827341079712, "training_acc": 55.0, "val_loss": 2.1596992015838623, "val_acc": 60.0}
{"epoch": 14, "training_loss": 2.6091753005981446, "training_acc": 45.0, "val_loss": 2.9025418758392334, "val_acc": 40.0}
{"epoch": 15, "training_loss": 2.2794646978378297, "training_acc": 55.0, "val_loss": 5.122069358825684, "val_acc": 40.0}
{"epoch": 16, "training_loss": 3.386468505859375, "training_acc": 55.0, "val_loss": 1.0536245107650757, "val_acc": 60.0}
{"epoch": 17, "training_loss": 2.0112661361694335, "training_acc": 45.0, "val_loss": 1.6098631620407104, "val_acc": 60.0}
{"epoch": 18, "training_loss": 2.4495778560638426, "training_acc": 35.0, "val_loss": 2.368924617767334, "val_acc": 40.0}
{"epoch": 19, "training_loss": 1.8117587924003602, "training_acc": 55.0, "val_loss": 0.6795429587364197, "val_acc": 60.0}
{"epoch": 20, "training_loss": 0.6258646607398987, "training_acc": 80.0, "val_loss": 1.215311884880066, "val_acc": 40.0}
{"epoch": 21, "training_loss": 0.866604208946228, "training_acc": 55.0, "val_loss": 0.7011726498603821, "val_acc": 40.0}
{"epoch": 22, "training_loss": 0.7477769374847412, "training_acc": 55.0, "val_loss": 2.2906484603881836, "val_acc": 40.0}
{"epoch": 23, "training_loss": 1.759574794769287, "training_acc": 55.0, "val_loss": 1.060542106628418, "val_acc": 40.0}
{"epoch": 24, "training_loss": 0.9450074911117554, "training_acc": 55.0, "val_loss": 1.6063984632492065, "val_acc": 60.0}
{"epoch": 25, "training_loss": 1.694362711906433, "training_acc": 45.0, "val_loss": 3.1593029499053955, "val_acc": 40.0}
{"epoch": 26, "training_loss": 2.352775239944458, "training_acc": 55.0, "val_loss": 3.0218217372894287, "val_acc": 40.0}
{"epoch": 27, "training_loss": 2.0828168034553527, "training_acc": 55.0, "val_loss": 1.1142479181289673, "val_acc": 60.0}
{"epoch": 28, "training_loss": 1.3007092952728272, "training_acc": 45.0, "val_loss": 1.502828598022461, "val_acc": 40.0}
{"epoch": 29, "training_loss": 1.0356276154518127, "training_acc": 55.0, "val_loss": 0.669800877571106, "val_acc": 40.0}
{"epoch": 30, "training_loss": 0.5729405403137207, "training_acc": 85.0, "val_loss": 0.947770893573761, "val_acc": 60.0}
{"epoch": 31, "training_loss": 1.1295139908790588, "training_acc": 50.0, "val_loss": 1.0277512073516846, "val_acc": 40.0}
{"epoch": 32, "training_loss": 0.6796589851379394, "training_acc": 55.0, "val_loss": 0.7622790336608887, "val_acc": 60.0}
{"epoch": 33, "training_loss": 0.843196702003479, "training_acc": 55.0, "val_loss": 1.1751363277435303, "val_acc": 40.0}
{"epoch": 34, "training_loss": 0.8343939542770386, "training_acc": 60.0, "val_loss": 0.7114741206169128, "val_acc": 40.0}
{"epoch": 35, "training_loss": 0.6454217195510864, "training_acc": 50.0, "val_loss": 2.225459575653076, "val_acc": 40.0}
{"epoch": 36, "training_loss": 1.5464334599673748, "training_acc": 55.0, "val_loss": 1.3970040082931519, "val_acc": 40.0}
{"epoch": 37, "training_loss": 0.6550256729125976, "training_acc": 75.0, "val_loss": 2.3176417350769043, "val_acc": 60.0}
{"epoch": 38, "training_loss": 3.249380874633789, "training_acc": 45.0, "val_loss": 0.9688875079154968, "val_acc": 40.0}
{"epoch": 39, "training_loss": 0.8799989938735961, "training_acc": 55.0, "val_loss": 5.168485641479492, "val_acc": 40.0}
{"epoch": 40, "training_loss": 3.605932378768921, "training_acc": 55.0, "val_loss": 1.0683492422103882, "val_acc": 40.0}
{"epoch": 41, "training_loss": 1.3912115097045898, "training_acc": 45.0, "val_loss": 1.8519943952560425, "val_acc": 60.0}
{"epoch": 42, "training_loss": 2.1010971546173094, "training_acc": 50.0, "val_loss": 2.601889133453369, "val_acc": 40.0}
{"epoch": 43, "training_loss": 1.729345941543579, "training_acc": 55.0, "val_loss": 0.7653300166130066, "val_acc": 60.0}
{"epoch": 44, "training_loss": 1.0806256771087646, "training_acc": 45.0, "val_loss": 1.128980278968811, "val_acc": 40.0}
{"epoch": 45, "training_loss": 1.099815845489502, "training_acc": 55.0, "val_loss": 0.6442140936851501, "val_acc": 60.0}
{"epoch": 46, "training_loss": 0.5873886108398437, "training_acc": 75.0, "val_loss": 1.4031673669815063, "val_acc": 60.0}
{"epoch": 47, "training_loss": 1.839468002319336, "training_acc": 35.0, "val_loss": 0.8745192885398865, "val_acc": 40.0}
{"epoch": 48, "training_loss": 0.6136417269706727, "training_acc": 60.0, "val_loss": 0.6313006281852722, "val_acc": 80.0}
{"epoch": 49, "training_loss": 0.5736799001693725, "training_acc": 70.0, "val_loss": 0.6812820434570312, "val_acc": 40.0}
{"epoch": 50, "training_loss": 0.5305736064910889, "training_acc": 80.0, "val_loss": 0.6706792712211609, "val_acc": 40.0}
{"epoch": 51, "training_loss": 0.5995462298393249, "training_acc": 70.0, "val_loss": 0.8178914189338684, "val_acc": 60.0}
{"epoch": 52, "training_loss": 0.9008968353271485, "training_acc": 45.0, "val_loss": 2.328031301498413, "val_acc": 40.0}
{"epoch": 53, "training_loss": 1.6762990474700927, "training_acc": 55.0, "val_loss": 0.9219935536384583, "val_acc": 40.0}
{"epoch": 54, "training_loss": 0.810149073600769, "training_acc": 60.0, "val_loss": 1.5212002992630005, "val_acc": 60.0}
{"epoch": 55, "training_loss": 1.694705104827881, "training_acc": 45.0, "val_loss": 2.056772470474243, "val_acc": 40.0}
{"epoch": 56, "training_loss": 1.2619848906993867, "training_acc": 55.0, "val_loss": 0.7056394219398499, "val_acc": 60.0}
{"epoch": 57, "training_loss": 0.6942889451980591, "training_acc": 55.0, "val_loss": 1.96663498878479, "val_acc": 40.0}
{"epoch": 58, "training_loss": 1.2160234928131104, "training_acc": 55.0, "val_loss": 0.6806569695472717, "val_acc": 60.0}
{"epoch": 59, "training_loss": 0.708497142791748, "training_acc": 50.0, "val_loss": 0.7356753349304199, "val_acc": 60.0}
{"epoch": 60, "training_loss": 0.7472082614898682, "training_acc": 65.0, "val_loss": 0.6863881349563599, "val_acc": 60.0}
{"epoch": 61, "training_loss": 0.9528072834014892, "training_acc": 50.0, "val_loss": 2.4729933738708496, "val_acc": 40.0}
{"epoch": 62, "training_loss": 2.0536077499389647, "training_acc": 55.0, "val_loss": 1.6427034139633179, "val_acc": 40.0}
{"epoch": 63, "training_loss": 1.6229973793029786, "training_acc": 45.0, "val_loss": 2.0955910682678223, "val_acc": 60.0}
{"epoch": 64, "training_loss": 2.3020452320575715, "training_acc": 50.0, "val_loss": 2.478685140609741, "val_acc": 40.0}
{"epoch": 65, "training_loss": 1.6434576511383057, "training_acc": 55.0, "val_loss": 0.6410825848579407, "val_acc": 60.0}
{"epoch": 66, "training_loss": 0.8946161270141602, "training_acc": 70.0, "val_loss": 0.6559139490127563, "val_acc": 60.0}
{"epoch": 67, "training_loss": 0.5735684394836426, "training_acc": 80.0, "val_loss": 2.8347482681274414, "val_acc": 40.0}
