"main_modify.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 2 --task ADNI_sex --input_option yAware --learning_rate 1e0 --batch_size 16 --weight_decay 1e-7 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 64.58981437683106, "training_acc": 45.0, "val_loss": 51.40576171875, "val_acc": 60.0}
{"epoch": 1, "training_loss": 62.32640609741211, "training_acc": 55.0, "val_loss": 251.93138122558594, "val_acc": 40.0}
{"epoch": 2, "training_loss": 190.8617385864258, "training_acc": 55.0, "val_loss": 267.67864990234375, "val_acc": 40.0}
{"epoch": 3, "training_loss": 195.03629608154296, "training_acc": 55.0, "val_loss": 126.3001937866211, "val_acc": 40.0}
{"epoch": 4, "training_loss": 76.4070213317871, "training_acc": 55.0, "val_loss": 77.98062896728516, "val_acc": 60.0}
{"epoch": 5, "training_loss": 118.68795776367188, "training_acc": 45.0, "val_loss": 133.07473754882812, "val_acc": 60.0}
{"epoch": 6, "training_loss": 177.78529052734376, "training_acc": 45.0, "val_loss": 71.60457611083984, "val_acc": 60.0}
{"epoch": 7, "training_loss": 68.76692695617676, "training_acc": 45.0, "val_loss": 114.265869140625, "val_acc": 40.0}
{"epoch": 8, "training_loss": 92.64412536621094, "training_acc": 55.0, "val_loss": 265.6574401855469, "val_acc": 40.0}
{"epoch": 9, "training_loss": 198.6770263671875, "training_acc": 55.0, "val_loss": 312.173583984375, "val_acc": 40.0}
{"epoch": 10, "training_loss": 232.73400268554687, "training_acc": 55.0, "val_loss": 273.91729736328125, "val_acc": 40.0}
{"epoch": 11, "training_loss": 195.91426696777344, "training_acc": 55.0, "val_loss": 143.64944458007812, "val_acc": 40.0}
{"epoch": 12, "training_loss": 78.68875122070312, "training_acc": 55.0, "val_loss": 44.64512634277344, "val_acc": 60.0}
{"epoch": 13, "training_loss": 75.24211120605469, "training_acc": 45.0, "val_loss": 131.20962524414062, "val_acc": 60.0}
{"epoch": 14, "training_loss": 185.07013549804688, "training_acc": 45.0, "val_loss": 127.74652099609375, "val_acc": 60.0}
{"epoch": 15, "training_loss": 164.73868408203126, "training_acc": 45.0, "val_loss": 46.56490707397461, "val_acc": 60.0}
{"epoch": 16, "training_loss": 56.983697509765626, "training_acc": 45.0, "val_loss": 87.99088287353516, "val_acc": 40.0}
{"epoch": 17, "training_loss": 68.30672302246094, "training_acc": 55.0, "val_loss": 135.8516082763672, "val_acc": 40.0}
{"epoch": 18, "training_loss": 100.67877960205078, "training_acc": 55.0, "val_loss": 104.38570404052734, "val_acc": 40.0}
{"epoch": 19, "training_loss": 71.24033737182617, "training_acc": 55.0, "val_loss": 1.3928499221801758, "val_acc": 40.0}
{"epoch": 20, "training_loss": 5.931300449371338, "training_acc": 70.0, "val_loss": 76.27259826660156, "val_acc": 60.0}
{"epoch": 21, "training_loss": 109.4408447265625, "training_acc": 45.0, "val_loss": 74.74654388427734, "val_acc": 60.0}
{"epoch": 22, "training_loss": 94.94709777832031, "training_acc": 45.0, "val_loss": 1.1318323612213135, "val_acc": 60.0}
{"epoch": 23, "training_loss": 9.082802248001098, "training_acc": 70.0, "val_loss": 72.25674438476562, "val_acc": 40.0}
{"epoch": 24, "training_loss": 53.35710144042969, "training_acc": 55.0, "val_loss": 40.619564056396484, "val_acc": 40.0}
{"epoch": 25, "training_loss": 29.205446243286133, "training_acc": 45.0, "val_loss": 11.435711860656738, "val_acc": 60.0}
{"epoch": 26, "training_loss": 12.995665121078492, "training_acc": 45.0, "val_loss": 1.4626165628433228, "val_acc": 60.0}
{"epoch": 27, "training_loss": 1.5518939971923829, "training_acc": 65.0, "val_loss": 6.818271160125732, "val_acc": 40.0}
{"epoch": 28, "training_loss": 6.371807479858399, "training_acc": 55.0, "val_loss": 8.688056945800781, "val_acc": 60.0}
{"epoch": 29, "training_loss": 6.836515808105469, "training_acc": 65.0, "val_loss": 34.800540924072266, "val_acc": 40.0}
{"epoch": 30, "training_loss": 25.502075958251954, "training_acc": 55.0, "val_loss": 6.35902738571167, "val_acc": 40.0}
{"epoch": 31, "training_loss": 9.909682464599609, "training_acc": 55.0, "val_loss": 37.259971618652344, "val_acc": 60.0}
{"epoch": 32, "training_loss": 47.88832244873047, "training_acc": 45.0, "val_loss": 2.051452398300171, "val_acc": 40.0}
{"epoch": 33, "training_loss": 7.890552806854248, "training_acc": 55.0, "val_loss": 13.886443138122559, "val_acc": 40.0}
{"epoch": 34, "training_loss": 14.213180541992188, "training_acc": 45.0, "val_loss": 13.580804824829102, "val_acc": 60.0}
{"epoch": 35, "training_loss": 13.321058654785157, "training_acc": 55.0, "val_loss": 20.21463966369629, "val_acc": 40.0}
{"epoch": 36, "training_loss": 13.124744415283203, "training_acc": 55.0, "val_loss": 16.136869430541992, "val_acc": 60.0}
{"epoch": 37, "training_loss": 21.63672790527344, "training_acc": 45.0, "val_loss": 2.897791624069214, "val_acc": 60.0}
{"epoch": 38, "training_loss": 8.975098800659179, "training_acc": 45.0, "val_loss": 60.564361572265625, "val_acc": 40.0}
{"epoch": 39, "training_loss": 43.95397186279297, "training_acc": 55.0, "val_loss": 23.663562774658203, "val_acc": 40.0}
{"epoch": 40, "training_loss": 27.30799560546875, "training_acc": 35.0, "val_loss": 21.297386169433594, "val_acc": 60.0}
{"epoch": 41, "training_loss": 25.495119285583495, "training_acc": 45.0, "val_loss": 32.86567306518555, "val_acc": 40.0}
