"main_modify.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 4 --task ADNI_sex --input_option yAware --learning_rate 1e0 --batch_size 16 --weight_decay 1e-7 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 43.3399142742157, "training_acc": 45.0, "val_loss": 125.98917388916016, "val_acc": 40.0}
{"epoch": 1, "training_loss": 82.84248199462891, "training_acc": 55.0, "val_loss": 59.07049560546875, "val_acc": 60.0}
{"epoch": 2, "training_loss": 69.62656478881836, "training_acc": 45.0, "val_loss": 72.29235076904297, "val_acc": 40.0}
{"epoch": 3, "training_loss": 57.78520050048828, "training_acc": 55.0, "val_loss": 129.7168731689453, "val_acc": 40.0}
{"epoch": 4, "training_loss": 92.78519897460937, "training_acc": 55.0, "val_loss": 39.320892333984375, "val_acc": 40.0}
{"epoch": 5, "training_loss": 31.068753051757813, "training_acc": 55.0, "val_loss": 58.823158264160156, "val_acc": 60.0}
{"epoch": 6, "training_loss": 80.8574432373047, "training_acc": 45.0, "val_loss": 23.113630294799805, "val_acc": 60.0}
{"epoch": 7, "training_loss": 33.898684692382815, "training_acc": 45.0, "val_loss": 84.75055694580078, "val_acc": 40.0}
{"epoch": 8, "training_loss": 68.86123046875, "training_acc": 55.0, "val_loss": 58.15275955200195, "val_acc": 40.0}
{"epoch": 9, "training_loss": 34.554755210876465, "training_acc": 55.0, "val_loss": 21.12767219543457, "val_acc": 60.0}
{"epoch": 10, "training_loss": 28.525212860107423, "training_acc": 45.0, "val_loss": 10.852561950683594, "val_acc": 40.0}
{"epoch": 11, "training_loss": 10.421826171875, "training_acc": 55.0, "val_loss": 11.499295234680176, "val_acc": 40.0}
{"epoch": 12, "training_loss": 10.312177658081055, "training_acc": 55.0, "val_loss": 18.48369026184082, "val_acc": 60.0}
{"epoch": 13, "training_loss": 23.185203778743745, "training_acc": 45.0, "val_loss": 30.510786056518555, "val_acc": 40.0}
{"epoch": 14, "training_loss": 22.80002365112305, "training_acc": 55.0, "val_loss": 23.217092514038086, "val_acc": 40.0}
{"epoch": 15, "training_loss": 18.17489242553711, "training_acc": 45.0, "val_loss": 2.703165292739868, "val_acc": 60.0}
{"epoch": 16, "training_loss": 7.73158073425293, "training_acc": 45.0, "val_loss": 35.59059524536133, "val_acc": 40.0}
{"epoch": 17, "training_loss": 24.780628776550294, "training_acc": 55.0, "val_loss": 9.153579711914062, "val_acc": 60.0}
{"epoch": 18, "training_loss": 13.002272415161134, "training_acc": 45.0, "val_loss": 18.368701934814453, "val_acc": 40.0}
{"epoch": 19, "training_loss": 15.159972381591796, "training_acc": 55.0, "val_loss": 12.517149925231934, "val_acc": 40.0}
{"epoch": 20, "training_loss": 10.961360931396484, "training_acc": 55.0, "val_loss": 19.95560646057129, "val_acc": 60.0}
{"epoch": 21, "training_loss": 23.10302391052246, "training_acc": 45.0, "val_loss": 39.8014030456543, "val_acc": 40.0}
{"epoch": 22, "training_loss": 33.749822998046874, "training_acc": 55.0, "val_loss": 64.98531341552734, "val_acc": 40.0}
{"epoch": 23, "training_loss": 44.558109283447266, "training_acc": 55.0, "val_loss": 0.9029882550239563, "val_acc": 60.0}
{"epoch": 24, "training_loss": 2.4795313835144044, "training_acc": 45.0, "val_loss": 11.348390579223633, "val_acc": 60.0}
{"epoch": 25, "training_loss": 14.571796703338624, "training_acc": 45.0, "val_loss": 8.316258430480957, "val_acc": 40.0}
{"epoch": 26, "training_loss": 9.390700531005859, "training_acc": 45.0, "val_loss": 0.937282383441925, "val_acc": 60.0}
{"epoch": 27, "training_loss": 10.449690246582032, "training_acc": 35.0, "val_loss": 36.12014389038086, "val_acc": 40.0}
{"epoch": 28, "training_loss": 21.860274887084962, "training_acc": 55.0, "val_loss": 23.476882934570312, "val_acc": 60.0}
{"epoch": 29, "training_loss": 35.31388168334961, "training_acc": 45.0, "val_loss": 33.68843460083008, "val_acc": 60.0}
{"epoch": 30, "training_loss": 37.40109710693359, "training_acc": 45.0, "val_loss": 44.552284240722656, "val_acc": 40.0}
{"epoch": 31, "training_loss": 40.143310546875, "training_acc": 55.0, "val_loss": 101.85311126708984, "val_acc": 40.0}
{"epoch": 32, "training_loss": 74.58433532714844, "training_acc": 55.0, "val_loss": 57.37446975708008, "val_acc": 40.0}
{"epoch": 33, "training_loss": 28.901224088668823, "training_acc": 55.0, "val_loss": 51.83195877075195, "val_acc": 60.0}
{"epoch": 34, "training_loss": 74.64878540039062, "training_acc": 45.0, "val_loss": 100.90758514404297, "val_acc": 60.0}
{"epoch": 35, "training_loss": 138.72071228027343, "training_acc": 45.0, "val_loss": 88.37775421142578, "val_acc": 60.0}
{"epoch": 36, "training_loss": 114.42050476074219, "training_acc": 45.0, "val_loss": 21.54360008239746, "val_acc": 60.0}
{"epoch": 37, "training_loss": 46.865237426757815, "training_acc": 25.0, "val_loss": 83.05791473388672, "val_acc": 40.0}
{"epoch": 38, "training_loss": 61.52558212280273, "training_acc": 55.0, "val_loss": 78.53178405761719, "val_acc": 40.0}
{"epoch": 39, "training_loss": 53.4207260131836, "training_acc": 55.0, "val_loss": 1.5404587984085083, "val_acc": 40.0}
{"epoch": 40, "training_loss": 4.445025777816772, "training_acc": 80.0, "val_loss": 58.641578674316406, "val_acc": 60.0}
{"epoch": 41, "training_loss": 82.59425659179688, "training_acc": 45.0, "val_loss": 47.0946159362793, "val_acc": 60.0}
{"epoch": 42, "training_loss": 55.3954381942749, "training_acc": 45.0, "val_loss": 48.053131103515625, "val_acc": 40.0}
