"main_modify.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 5 --task ADNI_sex --input_option yAware --learning_rate 1e1 --batch_size 16 --weight_decay 5e-3 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 213.4540237426758, "training_acc": 60.0, "val_loss": 785.1847534179688, "val_acc": 40.0}
{"epoch": 1, "training_loss": 746.397314453125, "training_acc": 50.0, "val_loss": 1130.3179931640625, "val_acc": 60.0}
{"epoch": 2, "training_loss": 1289.72294921875, "training_acc": 50.0, "val_loss": 43.276344299316406, "val_acc": 60.0}
{"epoch": 3, "training_loss": 393.5903045654297, "training_acc": 40.0, "val_loss": 1846.099609375, "val_acc": 40.0}
{"epoch": 4, "training_loss": 1538.2845703125, "training_acc": 50.0, "val_loss": 1311.9188232421875, "val_acc": 40.0}
{"epoch": 5, "training_loss": 956.0261779785156, "training_acc": 50.0, "val_loss": 353.032470703125, "val_acc": 60.0}
{"epoch": 6, "training_loss": 596.2701904296875, "training_acc": 50.0, "val_loss": 832.3357543945312, "val_acc": 60.0}
{"epoch": 7, "training_loss": 1034.80810546875, "training_acc": 50.0, "val_loss": 450.8653259277344, "val_acc": 60.0}
{"epoch": 8, "training_loss": 435.8278503417969, "training_acc": 50.0, "val_loss": 644.2150268554688, "val_acc": 40.0}
{"epoch": 9, "training_loss": 571.0989379882812, "training_acc": 50.0, "val_loss": 1307.7916259765625, "val_acc": 40.0}
{"epoch": 10, "training_loss": 1079.417822265625, "training_acc": 50.0, "val_loss": 966.5582275390625, "val_acc": 40.0}
{"epoch": 11, "training_loss": 689.1326293945312, "training_acc": 50.0, "val_loss": 172.81024169921875, "val_acc": 60.0}
{"epoch": 12, "training_loss": 288.16004638671876, "training_acc": 50.0, "val_loss": 566.8366088867188, "val_acc": 60.0}
{"epoch": 13, "training_loss": 683.3527099609375, "training_acc": 50.0, "val_loss": 238.43272399902344, "val_acc": 60.0}
{"epoch": 14, "training_loss": 271.82543029785154, "training_acc": 50.0, "val_loss": 489.7956237792969, "val_acc": 40.0}
{"epoch": 15, "training_loss": 406.6370483398438, "training_acc": 50.0, "val_loss": 246.30520629882812, "val_acc": 40.0}
{"epoch": 16, "training_loss": 158.27281036376954, "training_acc": 60.0, "val_loss": 304.490234375, "val_acc": 60.0}
{"epoch": 17, "training_loss": 375.3457427978516, "training_acc": 50.0, "val_loss": 175.9463348388672, "val_acc": 60.0}
{"epoch": 18, "training_loss": 233.96038208007812, "training_acc": 40.0, "val_loss": 165.62814331054688, "val_acc": 40.0}
{"epoch": 19, "training_loss": 120.14543151855469, "training_acc": 50.0, "val_loss": 18.83121681213379, "val_acc": 60.0}
{"epoch": 20, "training_loss": 57.35790100097656, "training_acc": 50.0, "val_loss": 231.6201171875, "val_acc": 40.0}
{"epoch": 21, "training_loss": 155.09850883483887, "training_acc": 50.0, "val_loss": 5.2962846755981445, "val_acc": 40.0}
{"epoch": 22, "training_loss": 64.05192527770996, "training_acc": 40.0, "val_loss": 74.449951171875, "val_acc": 60.0}
{"epoch": 23, "training_loss": 54.7145263671875, "training_acc": 70.0, "val_loss": 450.1708068847656, "val_acc": 40.0}
{"epoch": 24, "training_loss": 372.9478271484375, "training_acc": 50.0, "val_loss": 191.6444091796875, "val_acc": 40.0}
{"epoch": 25, "training_loss": 218.74658203125, "training_acc": 40.0, "val_loss": 259.8190612792969, "val_acc": 60.0}
{"epoch": 26, "training_loss": 294.1333953857422, "training_acc": 50.0, "val_loss": 164.2674102783203, "val_acc": 40.0}
{"epoch": 27, "training_loss": 155.25413513183594, "training_acc": 50.0, "val_loss": 135.78749084472656, "val_acc": 40.0}
{"epoch": 28, "training_loss": 68.13165283203125, "training_acc": 70.0, "val_loss": 296.5973815917969, "val_acc": 60.0}
{"epoch": 29, "training_loss": 374.639208984375, "training_acc": 50.0, "val_loss": 90.56896209716797, "val_acc": 60.0}
{"epoch": 30, "training_loss": 208.08388671875, "training_acc": 40.0, "val_loss": 585.7665405273438, "val_acc": 40.0}
{"epoch": 31, "training_loss": 468.20128173828124, "training_acc": 50.0, "val_loss": 130.9380645751953, "val_acc": 40.0}
{"epoch": 32, "training_loss": 155.62225952148438, "training_acc": 50.0, "val_loss": 444.35986328125, "val_acc": 60.0}
{"epoch": 33, "training_loss": 547.3900024414063, "training_acc": 50.0, "val_loss": 247.4237823486328, "val_acc": 60.0}
{"epoch": 34, "training_loss": 222.00079574584962, "training_acc": 60.0, "val_loss": 382.06939697265625, "val_acc": 40.0}
{"epoch": 35, "training_loss": 320.6304931640625, "training_acc": 50.0, "val_loss": 173.6943817138672, "val_acc": 40.0}
{"epoch": 36, "training_loss": 160.1796875, "training_acc": 50.0, "val_loss": 288.6186218261719, "val_acc": 60.0}
{"epoch": 37, "training_loss": 341.280859375, "training_acc": 50.0, "val_loss": 7.893975257873535, "val_acc": 40.0}
{"epoch": 38, "training_loss": 16.83284683227539, "training_acc": 50.0, "val_loss": 70.9276351928711, "val_acc": 60.0}
{"epoch": 39, "training_loss": 76.1404525756836, "training_acc": 50.0, "val_loss": 339.7583312988281, "val_acc": 40.0}
{"epoch": 40, "training_loss": 288.91590881347656, "training_acc": 50.0, "val_loss": 372.3536071777344, "val_acc": 40.0}
