"main_modify.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 4 --task ADNI_sex --input_option yAware --learning_rate 1e1 --batch_size 16 --weight_decay 5e-3 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 412.1996458053589, "training_acc": 50.0, "val_loss": 406.7111511230469, "val_acc": 60.0}
{"epoch": 1, "training_loss": 662.4982177734375, "training_acc": 50.0, "val_loss": 2128.538818359375, "val_acc": 40.0}
{"epoch": 2, "training_loss": 1724.038818359375, "training_acc": 50.0, "val_loss": 997.0247192382812, "val_acc": 40.0}
{"epoch": 3, "training_loss": 694.0311676025391, "training_acc": 50.0, "val_loss": 476.53857421875, "val_acc": 60.0}
{"epoch": 4, "training_loss": 617.04326171875, "training_acc": 50.0, "val_loss": 203.4097442626953, "val_acc": 60.0}
{"epoch": 5, "training_loss": 353.7756103515625, "training_acc": 40.0, "val_loss": 686.384521484375, "val_acc": 40.0}
{"epoch": 6, "training_loss": 555.5622802734375, "training_acc": 50.0, "val_loss": 168.1962890625, "val_acc": 40.0}
{"epoch": 7, "training_loss": 129.70313415527343, "training_acc": 60.0, "val_loss": 480.75421142578125, "val_acc": 60.0}
{"epoch": 8, "training_loss": 610.0680297851562, "training_acc": 50.0, "val_loss": 236.66616821289062, "val_acc": 60.0}
{"epoch": 9, "training_loss": 282.6707244873047, "training_acc": 50.0, "val_loss": 563.951416015625, "val_acc": 40.0}
{"epoch": 10, "training_loss": 473.45079345703124, "training_acc": 50.0, "val_loss": 197.73748779296875, "val_acc": 40.0}
{"epoch": 11, "training_loss": 197.5735595703125, "training_acc": 50.0, "val_loss": 448.2494201660156, "val_acc": 60.0}
{"epoch": 12, "training_loss": 560.573388671875, "training_acc": 50.0, "val_loss": 335.8735046386719, "val_acc": 60.0}
{"epoch": 13, "training_loss": 389.03690032958986, "training_acc": 50.0, "val_loss": 323.4574279785156, "val_acc": 40.0}
{"epoch": 14, "training_loss": 269.35244140625, "training_acc": 50.0, "val_loss": 495.6474304199219, "val_acc": 40.0}
{"epoch": 15, "training_loss": 381.03114929199216, "training_acc": 50.0, "val_loss": 78.638427734375, "val_acc": 60.0}
{"epoch": 16, "training_loss": 106.60017852783203, "training_acc": 50.0, "val_loss": 120.312255859375, "val_acc": 60.0}
{"epoch": 17, "training_loss": 168.91973266601562, "training_acc": 40.0, "val_loss": 46.092464447021484, "val_acc": 40.0}
{"epoch": 18, "training_loss": 77.24743957519532, "training_acc": 50.0, "val_loss": 211.3578643798828, "val_acc": 60.0}
{"epoch": 19, "training_loss": 218.81288146972656, "training_acc": 50.0, "val_loss": 387.2489929199219, "val_acc": 40.0}
{"epoch": 20, "training_loss": 360.0132568359375, "training_acc": 50.0, "val_loss": 558.3900146484375, "val_acc": 40.0}
{"epoch": 21, "training_loss": 438.3127151489258, "training_acc": 50.0, "val_loss": 127.0442123413086, "val_acc": 60.0}
{"epoch": 22, "training_loss": 181.19677124023437, "training_acc": 50.0, "val_loss": 133.58045959472656, "val_acc": 60.0}
{"epoch": 23, "training_loss": 238.58194580078126, "training_acc": 30.0, "val_loss": 109.359130859375, "val_acc": 40.0}
{"epoch": 24, "training_loss": 79.41971130371094, "training_acc": 60.0, "val_loss": 229.35289001464844, "val_acc": 60.0}
{"epoch": 25, "training_loss": 269.0781982421875, "training_acc": 50.0, "val_loss": 98.4630355834961, "val_acc": 40.0}
{"epoch": 26, "training_loss": 92.527392578125, "training_acc": 50.0, "val_loss": 10.410353660583496, "val_acc": 60.0}
{"epoch": 27, "training_loss": 32.998538208007815, "training_acc": 40.0, "val_loss": 115.1567611694336, "val_acc": 60.0}
{"epoch": 28, "training_loss": 150.56025390625, "training_acc": 50.0, "val_loss": 130.0030059814453, "val_acc": 40.0}
{"epoch": 29, "training_loss": 118.22311096191406, "training_acc": 50.0, "val_loss": 10.887738227844238, "val_acc": 40.0}
{"epoch": 30, "training_loss": 35.84261131286621, "training_acc": 60.0, "val_loss": 375.0747985839844, "val_acc": 60.0}
{"epoch": 31, "training_loss": 461.9352966308594, "training_acc": 50.0, "val_loss": 174.08946228027344, "val_acc": 60.0}
{"epoch": 32, "training_loss": 202.49618530273438, "training_acc": 50.0, "val_loss": 318.074951171875, "val_acc": 40.0}
{"epoch": 33, "training_loss": 245.23259887695312, "training_acc": 50.0, "val_loss": 127.57891845703125, "val_acc": 60.0}
{"epoch": 34, "training_loss": 184.2667724609375, "training_acc": 50.0, "val_loss": 151.9248504638672, "val_acc": 60.0}
{"epoch": 35, "training_loss": 170.7142562866211, "training_acc": 50.0, "val_loss": 181.80210876464844, "val_acc": 40.0}
{"epoch": 36, "training_loss": 114.34368209838867, "training_acc": 50.0, "val_loss": 300.7474365234375, "val_acc": 60.0}
{"epoch": 37, "training_loss": 389.83380126953125, "training_acc": 50.0, "val_loss": 419.86920166015625, "val_acc": 60.0}
{"epoch": 38, "training_loss": 485.7188354492188, "training_acc": 50.0, "val_loss": 61.41823959350586, "val_acc": 40.0}
{"epoch": 39, "training_loss": 79.82344970703124, "training_acc": 50.0, "val_loss": 151.51402282714844, "val_acc": 40.0}
{"epoch": 40, "training_loss": 128.175732421875, "training_acc": 50.0, "val_loss": 137.0231170654297, "val_acc": 60.0}
{"epoch": 41, "training_loss": 138.55085835456848, "training_acc": 50.0, "val_loss": 413.3289489746094, "val_acc": 40.0}
{"epoch": 42, "training_loss": 365.6129150390625, "training_acc": 50.0, "val_loss": 411.51641845703125, "val_acc": 40.0}
{"epoch": 43, "training_loss": 258.3027053833008, "training_acc": 50.0, "val_loss": 386.9749755859375, "val_acc": 60.0}
{"epoch": 44, "training_loss": 510.3077026367188, "training_acc": 50.0, "val_loss": 691.3734741210938, "val_acc": 60.0}
{"epoch": 45, "training_loss": 853.0312194824219, "training_acc": 50.0, "val_loss": 395.57269287109375, "val_acc": 60.0}
