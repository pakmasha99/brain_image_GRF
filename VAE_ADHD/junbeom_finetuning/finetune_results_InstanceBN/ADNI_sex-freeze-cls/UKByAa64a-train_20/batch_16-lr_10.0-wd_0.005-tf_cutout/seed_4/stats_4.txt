"main_modify.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 4 --task ADNI_sex --input_option yAware --learning_rate 1e1 --batch_size 16 --weight_decay 5e-3 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 428.2306392669678, "training_acc": 45.0, "val_loss": 1170.0155029296875, "val_acc": 40.0}
{"epoch": 1, "training_loss": 1124.053759765625, "training_acc": 35.0, "val_loss": 422.34674072265625, "val_acc": 60.0}
{"epoch": 2, "training_loss": 477.88642292022706, "training_acc": 45.0, "val_loss": 103.17549133300781, "val_acc": 40.0}
{"epoch": 3, "training_loss": 87.91548461914063, "training_acc": 55.0, "val_loss": 12.156402587890625, "val_acc": 60.0}
{"epoch": 4, "training_loss": 95.5704360961914, "training_acc": 45.0, "val_loss": 601.3064575195312, "val_acc": 40.0}
{"epoch": 5, "training_loss": 429.2598480224609, "training_acc": 55.0, "val_loss": 27.850759506225586, "val_acc": 60.0}
{"epoch": 6, "training_loss": 61.17813415527344, "training_acc": 45.0, "val_loss": 383.8114929199219, "val_acc": 40.0}
{"epoch": 7, "training_loss": 300.31744995117185, "training_acc": 55.0, "val_loss": 535.8688354492188, "val_acc": 40.0}
{"epoch": 8, "training_loss": 359.68829345703125, "training_acc": 55.0, "val_loss": 143.21636962890625, "val_acc": 60.0}
{"epoch": 9, "training_loss": 204.8717498779297, "training_acc": 45.0, "val_loss": 190.22422790527344, "val_acc": 60.0}
{"epoch": 10, "training_loss": 220.3829032897949, "training_acc": 45.0, "val_loss": 79.13912200927734, "val_acc": 40.0}
{"epoch": 11, "training_loss": 87.067724609375, "training_acc": 45.0, "val_loss": 36.973262786865234, "val_acc": 40.0}
{"epoch": 12, "training_loss": 53.150146484375, "training_acc": 35.0, "val_loss": 288.1421813964844, "val_acc": 40.0}
{"epoch": 13, "training_loss": 235.48123168945312, "training_acc": 55.0, "val_loss": 277.6596374511719, "val_acc": 40.0}
{"epoch": 14, "training_loss": 242.5132568359375, "training_acc": 35.0, "val_loss": 8.430377006530762, "val_acc": 40.0}
{"epoch": 15, "training_loss": 3.2395793914794924, "training_acc": 75.0, "val_loss": 40.41688919067383, "val_acc": 60.0}
{"epoch": 16, "training_loss": 127.9635498046875, "training_acc": 25.0, "val_loss": 24.19711685180664, "val_acc": 40.0}
{"epoch": 17, "training_loss": 37.768917846679685, "training_acc": 65.0, "val_loss": 337.5849304199219, "val_acc": 60.0}
{"epoch": 18, "training_loss": 452.38145751953124, "training_acc": 45.0, "val_loss": 77.90913391113281, "val_acc": 60.0}
{"epoch": 19, "training_loss": 110.4016326904297, "training_acc": 55.0, "val_loss": 713.52783203125, "val_acc": 40.0}
{"epoch": 20, "training_loss": 549.5584716796875, "training_acc": 55.0, "val_loss": 645.3991088867188, "val_acc": 40.0}
{"epoch": 21, "training_loss": 451.4500442504883, "training_acc": 55.0, "val_loss": 129.69163513183594, "val_acc": 60.0}
{"epoch": 22, "training_loss": 207.67613525390624, "training_acc": 45.0, "val_loss": 175.00157165527344, "val_acc": 60.0}
{"epoch": 23, "training_loss": 285.47479858398435, "training_acc": 25.0, "val_loss": 35.26734161376953, "val_acc": 40.0}
{"epoch": 24, "training_loss": 90.9514389038086, "training_acc": 45.0, "val_loss": 137.1569061279297, "val_acc": 60.0}
{"epoch": 25, "training_loss": 171.3820785522461, "training_acc": 45.0, "val_loss": 150.1178741455078, "val_acc": 40.0}
{"epoch": 26, "training_loss": 128.8876983642578, "training_acc": 35.0, "val_loss": 203.87017822265625, "val_acc": 40.0}
{"epoch": 27, "training_loss": 168.36253051757814, "training_acc": 55.0, "val_loss": 2.035250425338745, "val_acc": 60.0}
{"epoch": 28, "training_loss": 6.332400798797607, "training_acc": 45.0, "val_loss": 159.45077514648438, "val_acc": 40.0}
{"epoch": 29, "training_loss": 115.46251068115234, "training_acc": 55.0, "val_loss": 66.51189422607422, "val_acc": 60.0}
{"epoch": 30, "training_loss": 88.47471618652344, "training_acc": 45.0, "val_loss": 237.392822265625, "val_acc": 40.0}
{"epoch": 31, "training_loss": 210.0353759765625, "training_acc": 55.0, "val_loss": 154.87075805664062, "val_acc": 40.0}
{"epoch": 32, "training_loss": 64.09146118164062, "training_acc": 75.0, "val_loss": 316.29095458984375, "val_acc": 60.0}
{"epoch": 33, "training_loss": 437.0874877929688, "training_acc": 45.0, "val_loss": 179.48252868652344, "val_acc": 60.0}
{"epoch": 34, "training_loss": 191.60587997436522, "training_acc": 55.0, "val_loss": 419.9624938964844, "val_acc": 40.0}
{"epoch": 35, "training_loss": 320.7948974609375, "training_acc": 55.0, "val_loss": 264.0806579589844, "val_acc": 40.0}
{"epoch": 36, "training_loss": 172.2045440673828, "training_acc": 55.0, "val_loss": 150.55491638183594, "val_acc": 60.0}
{"epoch": 37, "training_loss": 182.45801544189453, "training_acc": 45.0, "val_loss": 287.2414245605469, "val_acc": 40.0}
{"epoch": 38, "training_loss": 253.04974365234375, "training_acc": 55.0, "val_loss": 235.3286590576172, "val_acc": 40.0}
{"epoch": 39, "training_loss": 161.7465087890625, "training_acc": 55.0, "val_loss": 178.4787139892578, "val_acc": 60.0}
{"epoch": 40, "training_loss": 222.51978607177733, "training_acc": 45.0, "val_loss": 239.0447235107422, "val_acc": 40.0}
{"epoch": 41, "training_loss": 187.00075988769532, "training_acc": 55.0, "val_loss": 300.9020690917969, "val_acc": 40.0}
{"epoch": 42, "training_loss": 173.93941345214844, "training_acc": 55.0, "val_loss": 284.24127197265625, "val_acc": 60.0}
{"epoch": 43, "training_loss": 407.8299896240234, "training_acc": 45.0, "val_loss": 429.80224609375, "val_acc": 60.0}
{"epoch": 44, "training_loss": 554.8250610351563, "training_acc": 45.0, "val_loss": 28.58078384399414, "val_acc": 40.0}
{"epoch": 45, "training_loss": 55.1348388671875, "training_acc": 55.0, "val_loss": 181.7296905517578, "val_acc": 40.0}
{"epoch": 46, "training_loss": 116.47337951660157, "training_acc": 55.0, "val_loss": 37.7464599609375, "val_acc": 60.0}
