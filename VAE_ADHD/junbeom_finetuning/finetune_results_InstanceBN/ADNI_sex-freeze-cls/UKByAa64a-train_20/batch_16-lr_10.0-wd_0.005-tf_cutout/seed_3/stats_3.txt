"main_modify.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 3 --task ADNI_sex --input_option yAware --learning_rate 1e1 --batch_size 16 --weight_decay 5e-3 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 427.68197736740115, "training_acc": 45.0, "val_loss": 951.3302612304688, "val_acc": 40.0}
{"epoch": 1, "training_loss": 726.7827880859375, "training_acc": 55.0, "val_loss": 1015.1885986328125, "val_acc": 60.0}
{"epoch": 2, "training_loss": 1305.09951171875, "training_acc": 45.0, "val_loss": 86.67881774902344, "val_acc": 60.0}
{"epoch": 3, "training_loss": 416.5432373046875, "training_acc": 35.0, "val_loss": 1690.6663818359375, "val_acc": 40.0}
{"epoch": 4, "training_loss": 1267.615576171875, "training_acc": 55.0, "val_loss": 1360.4984130859375, "val_acc": 40.0}
{"epoch": 5, "training_loss": 866.71513671875, "training_acc": 55.0, "val_loss": 127.91790008544922, "val_acc": 60.0}
{"epoch": 6, "training_loss": 262.0781982421875, "training_acc": 45.0, "val_loss": 564.3878173828125, "val_acc": 60.0}
{"epoch": 7, "training_loss": 744.9482177734375, "training_acc": 45.0, "val_loss": 130.32582092285156, "val_acc": 60.0}
{"epoch": 8, "training_loss": 170.46871337890624, "training_acc": 55.0, "val_loss": 936.5372924804688, "val_acc": 40.0}
{"epoch": 9, "training_loss": 745.607177734375, "training_acc": 55.0, "val_loss": 897.37451171875, "val_acc": 40.0}
{"epoch": 10, "training_loss": 537.3200927734375, "training_acc": 55.0, "val_loss": 204.6144256591797, "val_acc": 60.0}
{"epoch": 11, "training_loss": 318.3044677734375, "training_acc": 45.0, "val_loss": 654.8697509765625, "val_acc": 60.0}
{"epoch": 12, "training_loss": 893.3625610351562, "training_acc": 45.0, "val_loss": 452.9247131347656, "val_acc": 60.0}
{"epoch": 13, "training_loss": 546.4779113769531, "training_acc": 45.0, "val_loss": 444.74664306640625, "val_acc": 40.0}
{"epoch": 14, "training_loss": 392.5915283203125, "training_acc": 55.0, "val_loss": 916.22119140625, "val_acc": 40.0}
{"epoch": 15, "training_loss": 668.5952941894532, "training_acc": 55.0, "val_loss": 463.2022399902344, "val_acc": 40.0}
{"epoch": 16, "training_loss": 314.4979393005371, "training_acc": 45.0, "val_loss": 88.53961181640625, "val_acc": 60.0}
{"epoch": 17, "training_loss": 90.02741622924805, "training_acc": 55.0, "val_loss": 23.05808448791504, "val_acc": 40.0}
{"epoch": 18, "training_loss": 40.173310089111325, "training_acc": 55.0, "val_loss": 68.52210998535156, "val_acc": 60.0}
{"epoch": 19, "training_loss": 113.03892517089844, "training_acc": 45.0, "val_loss": 269.0765686035156, "val_acc": 40.0}
{"epoch": 20, "training_loss": 166.5072814941406, "training_acc": 55.0, "val_loss": 219.63487243652344, "val_acc": 60.0}
{"epoch": 21, "training_loss": 327.3931579589844, "training_acc": 45.0, "val_loss": 253.99693298339844, "val_acc": 60.0}
{"epoch": 22, "training_loss": 317.64767174720765, "training_acc": 35.0, "val_loss": 58.260406494140625, "val_acc": 40.0}
{"epoch": 23, "training_loss": 67.43729553222656, "training_acc": 45.0, "val_loss": 58.96696090698242, "val_acc": 40.0}
{"epoch": 24, "training_loss": 35.65142593383789, "training_acc": 55.0, "val_loss": 159.2985382080078, "val_acc": 60.0}
{"epoch": 25, "training_loss": 215.0727294921875, "training_acc": 45.0, "val_loss": 12.525171279907227, "val_acc": 60.0}
{"epoch": 26, "training_loss": 163.77110137939454, "training_acc": 25.0, "val_loss": 396.2591247558594, "val_acc": 40.0}
{"epoch": 27, "training_loss": 252.0966339111328, "training_acc": 55.0, "val_loss": 198.8501434326172, "val_acc": 60.0}
{"epoch": 28, "training_loss": 298.26478271484376, "training_acc": 45.0, "val_loss": 228.90966796875, "val_acc": 60.0}
{"epoch": 29, "training_loss": 293.08849411010743, "training_acc": 35.0, "val_loss": 36.13093948364258, "val_acc": 40.0}
{"epoch": 30, "training_loss": 65.08738861083984, "training_acc": 45.0, "val_loss": 30.81930923461914, "val_acc": 60.0}
{"epoch": 31, "training_loss": 89.69278869628906, "training_acc": 45.0, "val_loss": 435.7814636230469, "val_acc": 40.0}
{"epoch": 32, "training_loss": 302.73536376953126, "training_acc": 55.0, "val_loss": 5.45465612411499, "val_acc": 60.0}
{"epoch": 33, "training_loss": 54.18544282913208, "training_acc": 75.0, "val_loss": 254.59263610839844, "val_acc": 60.0}
{"epoch": 34, "training_loss": 307.71641235351564, "training_acc": 45.0, "val_loss": 288.7138671875, "val_acc": 40.0}
{"epoch": 35, "training_loss": 252.4096923828125, "training_acc": 55.0, "val_loss": 520.1254272460938, "val_acc": 40.0}
{"epoch": 36, "training_loss": 347.9572387695313, "training_acc": 55.0, "val_loss": 87.11734771728516, "val_acc": 60.0}
{"epoch": 37, "training_loss": 142.86614990234375, "training_acc": 45.0, "val_loss": 99.95803833007812, "val_acc": 60.0}
{"epoch": 38, "training_loss": 146.4976348876953, "training_acc": 45.0, "val_loss": 299.4745788574219, "val_acc": 40.0}
{"epoch": 39, "training_loss": 200.87645568847657, "training_acc": 55.0, "val_loss": 107.05013275146484, "val_acc": 60.0}
{"epoch": 40, "training_loss": 167.06082153320312, "training_acc": 45.0, "val_loss": 39.072349548339844, "val_acc": 40.0}
{"epoch": 41, "training_loss": 25.78900146484375, "training_acc": 55.0, "val_loss": 26.04115867614746, "val_acc": 40.0}
{"epoch": 42, "training_loss": 42.66380615234375, "training_acc": 55.0, "val_loss": 88.0941390991211, "val_acc": 60.0}
{"epoch": 43, "training_loss": 195.3735107421875, "training_acc": 25.0, "val_loss": 87.0228500366211, "val_acc": 40.0}
{"epoch": 44, "training_loss": 87.31994018554687, "training_acc": 55.0, "val_loss": 195.608154296875, "val_acc": 60.0}
{"epoch": 45, "training_loss": 235.54114379882813, "training_acc": 45.0, "val_loss": 323.1914978027344, "val_acc": 40.0}
{"epoch": 46, "training_loss": 250.85173950195312, "training_acc": 55.0, "val_loss": 464.62725830078125, "val_acc": 40.0}
{"epoch": 47, "training_loss": 325.38891143798827, "training_acc": 55.0, "val_loss": 66.53779602050781, "val_acc": 60.0}
{"epoch": 48, "training_loss": 109.09649353027343, "training_acc": 45.0, "val_loss": 114.72335052490234, "val_acc": 40.0}
{"epoch": 49, "training_loss": 84.87919082641602, "training_acc": 55.0, "val_loss": 46.73149490356445, "val_acc": 40.0}
{"epoch": 50, "training_loss": 64.15305023193359, "training_acc": 55.0, "val_loss": 174.1224365234375, "val_acc": 60.0}
{"epoch": 51, "training_loss": 186.94048461914062, "training_acc": 45.0, "val_loss": 487.3410339355469, "val_acc": 40.0}
