"main_modify.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 3 --task ADNI_sex --input_option yAware --learning_rate 1e1 --batch_size 16 --weight_decay 5e-3 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 640.3704433441162, "training_acc": 40.0, "val_loss": 985.8673095703125, "val_acc": 40.0}
{"epoch": 1, "training_loss": 647.8121948242188, "training_acc": 60.0, "val_loss": 1278.5853271484375, "val_acc": 60.0}
{"epoch": 2, "training_loss": 1640.06943359375, "training_acc": 50.0, "val_loss": 934.8046875, "val_acc": 60.0}
{"epoch": 3, "training_loss": 998.6636840820313, "training_acc": 50.0, "val_loss": 874.80322265625, "val_acc": 40.0}
{"epoch": 4, "training_loss": 905.7676513671875, "training_acc": 50.0, "val_loss": 1630.3939208984375, "val_acc": 40.0}
{"epoch": 5, "training_loss": 1301.90751953125, "training_acc": 50.0, "val_loss": 683.1807861328125, "val_acc": 40.0}
{"epoch": 6, "training_loss": 408.35588760375975, "training_acc": 60.0, "val_loss": 479.9201354980469, "val_acc": 60.0}
{"epoch": 7, "training_loss": 636.8929809570312, "training_acc": 50.0, "val_loss": 540.7403564453125, "val_acc": 60.0}
{"epoch": 8, "training_loss": 610.953466796875, "training_acc": 50.0, "val_loss": 217.1227264404297, "val_acc": 40.0}
{"epoch": 9, "training_loss": 199.29509582519532, "training_acc": 50.0, "val_loss": 560.728759765625, "val_acc": 40.0}
{"epoch": 10, "training_loss": 424.1542236328125, "training_acc": 50.0, "val_loss": 91.93901824951172, "val_acc": 60.0}
{"epoch": 11, "training_loss": 131.52723693847656, "training_acc": 50.0, "val_loss": 242.9462432861328, "val_acc": 60.0}
{"epoch": 12, "training_loss": 266.6979034423828, "training_acc": 50.0, "val_loss": 318.1724548339844, "val_acc": 40.0}
{"epoch": 13, "training_loss": 289.389501953125, "training_acc": 50.0, "val_loss": 348.0851135253906, "val_acc": 40.0}
{"epoch": 14, "training_loss": 271.06349716186526, "training_acc": 40.0, "val_loss": 19.677915573120117, "val_acc": 60.0}
{"epoch": 15, "training_loss": 33.862796020507815, "training_acc": 60.0, "val_loss": 274.5715026855469, "val_acc": 40.0}
{"epoch": 16, "training_loss": 197.24991149902343, "training_acc": 50.0, "val_loss": 205.451171875, "val_acc": 60.0}
{"epoch": 17, "training_loss": 276.53095703125, "training_acc": 50.0, "val_loss": 182.1885223388672, "val_acc": 60.0}
{"epoch": 18, "training_loss": 166.4244827270508, "training_acc": 60.0, "val_loss": 276.3035888671875, "val_acc": 40.0}
{"epoch": 19, "training_loss": 215.23912963867187, "training_acc": 50.0, "val_loss": 74.98473358154297, "val_acc": 60.0}
{"epoch": 20, "training_loss": 101.49438781738282, "training_acc": 50.0, "val_loss": 64.039794921875, "val_acc": 40.0}
{"epoch": 21, "training_loss": 50.86289291381836, "training_acc": 40.0, "val_loss": 269.9334716796875, "val_acc": 40.0}
{"epoch": 22, "training_loss": 233.18202514648436, "training_acc": 50.0, "val_loss": 6.939521789550781, "val_acc": 60.0}
{"epoch": 23, "training_loss": 12.836073875427246, "training_acc": 50.0, "val_loss": 59.72091293334961, "val_acc": 40.0}
{"epoch": 24, "training_loss": 97.87775573730468, "training_acc": 30.0, "val_loss": 131.4211883544922, "val_acc": 40.0}
{"epoch": 25, "training_loss": 109.5204574584961, "training_acc": 50.0, "val_loss": 44.343994140625, "val_acc": 60.0}
{"epoch": 26, "training_loss": 54.90237121582031, "training_acc": 50.0, "val_loss": 298.2625427246094, "val_acc": 40.0}
{"epoch": 27, "training_loss": 273.7704833984375, "training_acc": 50.0, "val_loss": 158.2071533203125, "val_acc": 40.0}
{"epoch": 28, "training_loss": 199.21793212890626, "training_acc": 40.0, "val_loss": 279.0957946777344, "val_acc": 60.0}
{"epoch": 29, "training_loss": 335.16705932617185, "training_acc": 50.0, "val_loss": 57.265296936035156, "val_acc": 40.0}
{"epoch": 30, "training_loss": 44.90037651062012, "training_acc": 50.0, "val_loss": 36.246726989746094, "val_acc": 60.0}
{"epoch": 31, "training_loss": 49.87148895263672, "training_acc": 50.0, "val_loss": 28.644758224487305, "val_acc": 60.0}
{"epoch": 32, "training_loss": 61.1164794921875, "training_acc": 40.0, "val_loss": 61.973793029785156, "val_acc": 60.0}
{"epoch": 33, "training_loss": 72.08277587890625, "training_acc": 50.0, "val_loss": 224.73301696777344, "val_acc": 40.0}
{"epoch": 34, "training_loss": 182.29856567382814, "training_acc": 50.0, "val_loss": 72.291259765625, "val_acc": 40.0}
{"epoch": 35, "training_loss": 129.84949340820313, "training_acc": 40.0, "val_loss": 200.5005340576172, "val_acc": 60.0}
{"epoch": 36, "training_loss": 211.43617630004883, "training_acc": 50.0, "val_loss": 395.2218322753906, "val_acc": 40.0}
{"epoch": 37, "training_loss": 338.01060791015624, "training_acc": 50.0, "val_loss": 532.67919921875, "val_acc": 40.0}
{"epoch": 38, "training_loss": 385.95020751953126, "training_acc": 50.0, "val_loss": 151.83644104003906, "val_acc": 60.0}
{"epoch": 39, "training_loss": 233.59862670898437, "training_acc": 50.0, "val_loss": 314.5065612792969, "val_acc": 60.0}
{"epoch": 40, "training_loss": 370.605810546875, "training_acc": 50.0, "val_loss": 184.0619354248047, "val_acc": 40.0}
{"epoch": 41, "training_loss": 183.88543701171875, "training_acc": 50.0, "val_loss": 77.92049407958984, "val_acc": 40.0}
