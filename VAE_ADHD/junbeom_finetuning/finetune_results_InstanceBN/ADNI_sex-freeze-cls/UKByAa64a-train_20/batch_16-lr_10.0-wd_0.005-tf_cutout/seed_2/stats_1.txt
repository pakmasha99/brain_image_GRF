"main_modify.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 2 --task ADNI_sex --input_option yAware --learning_rate 1e1 --batch_size 16 --weight_decay 5e-3 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 641.8978370666504, "training_acc": 55.0, "val_loss": 769.10302734375, "val_acc": 40.0}
{"epoch": 1, "training_loss": 1083.969775390625, "training_acc": 30.0, "val_loss": 1015.0324096679688, "val_acc": 60.0}
{"epoch": 2, "training_loss": 1212.0530639648437, "training_acc": 50.0, "val_loss": 313.5963439941406, "val_acc": 60.0}
{"epoch": 3, "training_loss": 396.2745849609375, "training_acc": 50.0, "val_loss": 969.66357421875, "val_acc": 40.0}
{"epoch": 4, "training_loss": 827.25107421875, "training_acc": 50.0, "val_loss": 655.0160522460938, "val_acc": 40.0}
{"epoch": 5, "training_loss": 386.6755088806152, "training_acc": 50.0, "val_loss": 602.9844970703125, "val_acc": 60.0}
{"epoch": 6, "training_loss": 795.5990478515625, "training_acc": 50.0, "val_loss": 1120.2802734375, "val_acc": 60.0}
{"epoch": 7, "training_loss": 1399.45390625, "training_acc": 50.0, "val_loss": 950.8015747070312, "val_acc": 60.0}
{"epoch": 8, "training_loss": 1120.8459838867188, "training_acc": 50.0, "val_loss": 257.07568359375, "val_acc": 60.0}
{"epoch": 9, "training_loss": 328.700634765625, "training_acc": 50.0, "val_loss": 907.8154296875, "val_acc": 40.0}
{"epoch": 10, "training_loss": 764.290283203125, "training_acc": 50.0, "val_loss": 1022.0855712890625, "val_acc": 40.0}
{"epoch": 11, "training_loss": 802.8587036132812, "training_acc": 50.0, "val_loss": 238.91751098632812, "val_acc": 40.0}
{"epoch": 12, "training_loss": 118.744091796875, "training_acc": 70.0, "val_loss": 646.5458374023438, "val_acc": 60.0}
{"epoch": 13, "training_loss": 849.9044799804688, "training_acc": 50.0, "val_loss": 786.8336181640625, "val_acc": 60.0}
{"epoch": 14, "training_loss": 915.7833251953125, "training_acc": 50.0, "val_loss": 200.5170440673828, "val_acc": 60.0}
{"epoch": 15, "training_loss": 213.4871063232422, "training_acc": 60.0, "val_loss": 1021.5465087890625, "val_acc": 40.0}
{"epoch": 16, "training_loss": 848.44853515625, "training_acc": 50.0, "val_loss": 1354.1962890625, "val_acc": 40.0}
{"epoch": 17, "training_loss": 1109.9186157226563, "training_acc": 50.0, "val_loss": 897.9732666015625, "val_acc": 40.0}
{"epoch": 18, "training_loss": 700.8560821533204, "training_acc": 50.0, "val_loss": 180.08016967773438, "val_acc": 60.0}
{"epoch": 19, "training_loss": 248.86270141601562, "training_acc": 50.0, "val_loss": 455.55859375, "val_acc": 60.0}
{"epoch": 20, "training_loss": 546.5504150390625, "training_acc": 50.0, "val_loss": 113.4310531616211, "val_acc": 60.0}
{"epoch": 21, "training_loss": 180.99891357421876, "training_acc": 50.0, "val_loss": 685.341796875, "val_acc": 40.0}
{"epoch": 22, "training_loss": 567.5510986328125, "training_acc": 50.0, "val_loss": 424.0243225097656, "val_acc": 40.0}
{"epoch": 23, "training_loss": 247.68181285858154, "training_acc": 60.0, "val_loss": 207.0991668701172, "val_acc": 60.0}
{"epoch": 24, "training_loss": 260.6452270507813, "training_acc": 50.0, "val_loss": 54.52370071411133, "val_acc": 60.0}
{"epoch": 25, "training_loss": 212.21339721679686, "training_acc": 30.0, "val_loss": 408.9617614746094, "val_acc": 40.0}
{"epoch": 26, "training_loss": 314.24153366088865, "training_acc": 50.0, "val_loss": 179.50059509277344, "val_acc": 60.0}
{"epoch": 27, "training_loss": 230.3834014892578, "training_acc": 50.0, "val_loss": 193.3472900390625, "val_acc": 60.0}
{"epoch": 28, "training_loss": 175.3432815551758, "training_acc": 50.0, "val_loss": 562.08349609375, "val_acc": 40.0}
{"epoch": 29, "training_loss": 513.645556640625, "training_acc": 50.0, "val_loss": 846.10595703125, "val_acc": 40.0}
{"epoch": 30, "training_loss": 660.6103393554688, "training_acc": 50.0, "val_loss": 119.02264404296875, "val_acc": 40.0}
{"epoch": 31, "training_loss": 232.31519775390626, "training_acc": 40.0, "val_loss": 554.2731323242188, "val_acc": 60.0}
{"epoch": 32, "training_loss": 694.246484375, "training_acc": 50.0, "val_loss": 322.257568359375, "val_acc": 60.0}
{"epoch": 33, "training_loss": 334.88751220703125, "training_acc": 50.0, "val_loss": 355.8514099121094, "val_acc": 40.0}
{"epoch": 34, "training_loss": 304.50848388671875, "training_acc": 50.0, "val_loss": 71.47396850585938, "val_acc": 40.0}
{"epoch": 35, "training_loss": 172.0111572265625, "training_acc": 40.0, "val_loss": 410.4562683105469, "val_acc": 60.0}
{"epoch": 36, "training_loss": 489.8874755859375, "training_acc": 50.0, "val_loss": 60.78300094604492, "val_acc": 60.0}
{"epoch": 37, "training_loss": 148.853369140625, "training_acc": 50.0, "val_loss": 850.8362426757812, "val_acc": 40.0}
{"epoch": 38, "training_loss": 724.521044921875, "training_acc": 50.0, "val_loss": 622.4118041992188, "val_acc": 40.0}
{"epoch": 39, "training_loss": 432.48102416992185, "training_acc": 50.0, "val_loss": 383.3284606933594, "val_acc": 60.0}
{"epoch": 40, "training_loss": 541.73037109375, "training_acc": 50.0, "val_loss": 699.1549682617188, "val_acc": 60.0}
{"epoch": 41, "training_loss": 838.9977294921875, "training_acc": 50.0, "val_loss": 284.4190979003906, "val_acc": 60.0}
{"epoch": 42, "training_loss": 324.911865234375, "training_acc": 50.0, "val_loss": 619.22998046875, "val_acc": 40.0}
{"epoch": 43, "training_loss": 545.7052124023437, "training_acc": 50.0, "val_loss": 500.3999938964844, "val_acc": 40.0}
