"main_modify.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_sex --input_option yAware --learning_rate 1e1 --batch_size 16 --weight_decay 5e-3 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 640.5814510345459, "training_acc": 50.0, "val_loss": 756.2811889648438, "val_acc": 40.0}
{"epoch": 1, "training_loss": 718.493603515625, "training_acc": 50.0, "val_loss": 1366.6448974609375, "val_acc": 60.0}
{"epoch": 2, "training_loss": 1696.0648559570313, "training_acc": 50.0, "val_loss": 984.6070556640625, "val_acc": 60.0}
{"epoch": 3, "training_loss": 1026.746630859375, "training_acc": 50.0, "val_loss": 558.991943359375, "val_acc": 40.0}
{"epoch": 4, "training_loss": 573.6880249023437, "training_acc": 50.0, "val_loss": 1403.7698974609375, "val_acc": 40.0}
{"epoch": 5, "training_loss": 1124.6587646484375, "training_acc": 50.0, "val_loss": 609.6961669921875, "val_acc": 40.0}
{"epoch": 6, "training_loss": 445.2813720703125, "training_acc": 50.0, "val_loss": 467.7915954589844, "val_acc": 60.0}
{"epoch": 7, "training_loss": 599.4529174804687, "training_acc": 50.0, "val_loss": 408.9051208496094, "val_acc": 60.0}
{"epoch": 8, "training_loss": 432.9972747802734, "training_acc": 50.0, "val_loss": 514.28173828125, "val_acc": 40.0}
{"epoch": 9, "training_loss": 450.4320373535156, "training_acc": 50.0, "val_loss": 917.6632690429688, "val_acc": 40.0}
{"epoch": 10, "training_loss": 732.396240234375, "training_acc": 50.0, "val_loss": 310.0999450683594, "val_acc": 40.0}
{"epoch": 11, "training_loss": 260.6473754882812, "training_acc": 50.0, "val_loss": 433.0563049316406, "val_acc": 60.0}
{"epoch": 12, "training_loss": 542.6708984375, "training_acc": 50.0, "val_loss": 283.2874755859375, "val_acc": 60.0}
{"epoch": 13, "training_loss": 335.9315185546875, "training_acc": 40.0, "val_loss": 161.3204803466797, "val_acc": 40.0}
{"epoch": 14, "training_loss": 129.57691040039063, "training_acc": 40.0, "val_loss": 142.00302124023438, "val_acc": 40.0}
{"epoch": 15, "training_loss": 106.07696838378907, "training_acc": 50.0, "val_loss": 196.97242736816406, "val_acc": 60.0}
{"epoch": 16, "training_loss": 263.1008239746094, "training_acc": 50.0, "val_loss": 182.3794708251953, "val_acc": 60.0}
{"epoch": 17, "training_loss": 194.94192962646486, "training_acc": 50.0, "val_loss": 176.0223846435547, "val_acc": 40.0}
{"epoch": 18, "training_loss": 115.97908630371094, "training_acc": 50.0, "val_loss": 267.39337158203125, "val_acc": 60.0}
{"epoch": 19, "training_loss": 344.1486022949219, "training_acc": 50.0, "val_loss": 364.4154968261719, "val_acc": 60.0}
{"epoch": 20, "training_loss": 401.0716796875, "training_acc": 50.0, "val_loss": 200.48997497558594, "val_acc": 40.0}
{"epoch": 21, "training_loss": 236.38079833984375, "training_acc": 50.0, "val_loss": 381.1003112792969, "val_acc": 40.0}
{"epoch": 22, "training_loss": 263.5566970825195, "training_acc": 50.0, "val_loss": 309.58148193359375, "val_acc": 60.0}
{"epoch": 23, "training_loss": 450.3823608398437, "training_acc": 50.0, "val_loss": 403.9565124511719, "val_acc": 60.0}
{"epoch": 24, "training_loss": 445.9068298339844, "training_acc": 50.0, "val_loss": 282.7303771972656, "val_acc": 40.0}
{"epoch": 25, "training_loss": 306.2456787109375, "training_acc": 50.0, "val_loss": 476.706787109375, "val_acc": 40.0}
{"epoch": 26, "training_loss": 343.46144104003906, "training_acc": 50.0, "val_loss": 238.46031188964844, "val_acc": 60.0}
{"epoch": 27, "training_loss": 335.1112487792969, "training_acc": 50.0, "val_loss": 374.50079345703125, "val_acc": 60.0}
{"epoch": 28, "training_loss": 466.4138671875, "training_acc": 50.0, "val_loss": 50.82394790649414, "val_acc": 40.0}
{"epoch": 29, "training_loss": 43.09501342773437, "training_acc": 50.0, "val_loss": 31.8976993560791, "val_acc": 60.0}
{"epoch": 30, "training_loss": 44.714883422851564, "training_acc": 50.0, "val_loss": 18.06477165222168, "val_acc": 60.0}
{"epoch": 31, "training_loss": 73.66239318847656, "training_acc": 30.0, "val_loss": 84.70332336425781, "val_acc": 60.0}
{"epoch": 32, "training_loss": 104.72201766967774, "training_acc": 50.0, "val_loss": 10.708378791809082, "val_acc": 60.0}
{"epoch": 33, "training_loss": 133.6067337036133, "training_acc": 30.0, "val_loss": 256.3144226074219, "val_acc": 40.0}
{"epoch": 34, "training_loss": 215.9394775390625, "training_acc": 40.0, "val_loss": 56.42546463012695, "val_acc": 60.0}
{"epoch": 35, "training_loss": 80.50818939208985, "training_acc": 50.0, "val_loss": 138.2444610595703, "val_acc": 40.0}
{"epoch": 36, "training_loss": 108.07265014648438, "training_acc": 50.0, "val_loss": 57.80990219116211, "val_acc": 60.0}
{"epoch": 37, "training_loss": 58.85319900512695, "training_acc": 60.0, "val_loss": 191.2872772216797, "val_acc": 40.0}
{"epoch": 38, "training_loss": 132.22685356140136, "training_acc": 50.0, "val_loss": 230.08506774902344, "val_acc": 60.0}
{"epoch": 39, "training_loss": 318.5528198242188, "training_acc": 50.0, "val_loss": 166.59671020507812, "val_acc": 60.0}
{"epoch": 40, "training_loss": 157.5161346435547, "training_acc": 60.0, "val_loss": 408.260986328125, "val_acc": 40.0}
{"epoch": 41, "training_loss": 338.2836547851563, "training_acc": 50.0, "val_loss": 157.473388671875, "val_acc": 40.0}
{"epoch": 42, "training_loss": 152.6138916015625, "training_acc": 50.0, "val_loss": 307.7845153808594, "val_acc": 60.0}
{"epoch": 43, "training_loss": 369.53843994140624, "training_acc": 50.0, "val_loss": 46.36767578125, "val_acc": 60.0}
{"epoch": 44, "training_loss": 74.01387023925781, "training_acc": 60.0, "val_loss": 720.3817138671875, "val_acc": 40.0}
{"epoch": 45, "training_loss": 598.7098815917968, "training_acc": 50.0, "val_loss": 603.052734375, "val_acc": 40.0}
{"epoch": 46, "training_loss": 419.8752807617187, "training_acc": 50.0, "val_loss": 242.59585571289062, "val_acc": 60.0}
{"epoch": 47, "training_loss": 359.597412109375, "training_acc": 50.0, "val_loss": 510.8810729980469, "val_acc": 60.0}
{"epoch": 48, "training_loss": 596.7931640625, "training_acc": 50.0, "val_loss": 70.65009307861328, "val_acc": 60.0}
{"epoch": 49, "training_loss": 165.33681030273436, "training_acc": 50.0, "val_loss": 948.4779663085938, "val_acc": 40.0}
{"epoch": 50, "training_loss": 803.6859619140625, "training_acc": 50.0, "val_loss": 860.8135986328125, "val_acc": 40.0}
{"epoch": 51, "training_loss": 678.3293853759766, "training_acc": 50.0, "val_loss": 56.64937210083008, "val_acc": 60.0}
