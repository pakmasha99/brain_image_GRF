"main_modify.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 1 --task ADNI_sex --input_option yAware --learning_rate 5e0 --batch_size 16 --weight_decay 5e-3 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 106.02616453170776, "training_acc": 55.0, "val_loss": 372.9844665527344, "val_acc": 40.0}
{"epoch": 1, "training_loss": 243.91971435546876, "training_acc": 65.0, "val_loss": 727.9137573242188, "val_acc": 60.0}
{"epoch": 2, "training_loss": 956.8052612304688, "training_acc": 45.0, "val_loss": 165.4253692626953, "val_acc": 60.0}
{"epoch": 3, "training_loss": 269.9304443359375, "training_acc": 45.0, "val_loss": 841.560546875, "val_acc": 40.0}
{"epoch": 4, "training_loss": 653.356689453125, "training_acc": 55.0, "val_loss": 683.1500854492188, "val_acc": 40.0}
{"epoch": 5, "training_loss": 477.4436782836914, "training_acc": 55.0, "val_loss": 128.007080078125, "val_acc": 60.0}
{"epoch": 6, "training_loss": 208.79478759765624, "training_acc": 45.0, "val_loss": 251.70913696289062, "val_acc": 60.0}
{"epoch": 7, "training_loss": 293.94199829101564, "training_acc": 45.0, "val_loss": 200.4412841796875, "val_acc": 40.0}
{"epoch": 8, "training_loss": 168.20237731933594, "training_acc": 55.0, "val_loss": 551.0439453125, "val_acc": 40.0}
{"epoch": 9, "training_loss": 416.777880859375, "training_acc": 55.0, "val_loss": 306.423828125, "val_acc": 40.0}
{"epoch": 10, "training_loss": 155.0513463973999, "training_acc": 65.0, "val_loss": 176.17764282226562, "val_acc": 60.0}
{"epoch": 11, "training_loss": 252.59017944335938, "training_acc": 45.0, "val_loss": 162.24356079101562, "val_acc": 60.0}
{"epoch": 12, "training_loss": 173.62128067016602, "training_acc": 45.0, "val_loss": 326.85345458984375, "val_acc": 40.0}
{"epoch": 13, "training_loss": 279.02772216796876, "training_acc": 55.0, "val_loss": 606.9484252929688, "val_acc": 40.0}
{"epoch": 14, "training_loss": 441.28052978515626, "training_acc": 55.0, "val_loss": 333.521728515625, "val_acc": 40.0}
{"epoch": 15, "training_loss": 221.054442691803, "training_acc": 50.0, "val_loss": 115.62005615234375, "val_acc": 60.0}
{"epoch": 16, "training_loss": 164.24608764648437, "training_acc": 45.0, "val_loss": 58.850643157958984, "val_acc": 60.0}
{"epoch": 17, "training_loss": 69.52424697875976, "training_acc": 55.0, "val_loss": 262.1600341796875, "val_acc": 40.0}
{"epoch": 18, "training_loss": 196.1023712158203, "training_acc": 55.0, "val_loss": 158.7472686767578, "val_acc": 40.0}
{"epoch": 19, "training_loss": 80.97603015899658, "training_acc": 65.0, "val_loss": 103.23883056640625, "val_acc": 60.0}
{"epoch": 20, "training_loss": 137.5344482421875, "training_acc": 45.0, "val_loss": 35.56283187866211, "val_acc": 40.0}
{"epoch": 21, "training_loss": 36.444889831542966, "training_acc": 55.0, "val_loss": 37.6024284362793, "val_acc": 60.0}
{"epoch": 22, "training_loss": 50.93569831848144, "training_acc": 45.0, "val_loss": 53.77112579345703, "val_acc": 40.0}
{"epoch": 23, "training_loss": 33.199531173706056, "training_acc": 55.0, "val_loss": 84.89866638183594, "val_acc": 60.0}
{"epoch": 24, "training_loss": 116.2648796081543, "training_acc": 45.0, "val_loss": 19.36190414428711, "val_acc": 60.0}
{"epoch": 25, "training_loss": 73.2495620727539, "training_acc": 35.0, "val_loss": 210.93943786621094, "val_acc": 40.0}
{"epoch": 26, "training_loss": 136.99199523925782, "training_acc": 55.0, "val_loss": 79.6678466796875, "val_acc": 60.0}
{"epoch": 27, "training_loss": 136.72357788085938, "training_acc": 45.0, "val_loss": 91.68671417236328, "val_acc": 60.0}
{"epoch": 28, "training_loss": 97.32683410644532, "training_acc": 55.0, "val_loss": 180.77003479003906, "val_acc": 40.0}
{"epoch": 29, "training_loss": 132.78209686279297, "training_acc": 55.0, "val_loss": 90.55303955078125, "val_acc": 40.0}
{"epoch": 30, "training_loss": 49.85185508728027, "training_acc": 65.0, "val_loss": 101.27803802490234, "val_acc": 60.0}
{"epoch": 31, "training_loss": 129.71553497314454, "training_acc": 45.0, "val_loss": 91.25501251220703, "val_acc": 40.0}
{"epoch": 32, "training_loss": 69.99616317749023, "training_acc": 55.0, "val_loss": 103.17430877685547, "val_acc": 40.0}
{"epoch": 33, "training_loss": 78.57044525146485, "training_acc": 45.0, "val_loss": 4.590368747711182, "val_acc": 40.0}
{"epoch": 34, "training_loss": 13.68228816986084, "training_acc": 50.0, "val_loss": 89.08776092529297, "val_acc": 40.0}
{"epoch": 35, "training_loss": 72.81233215332031, "training_acc": 55.0, "val_loss": 22.711824417114258, "val_acc": 60.0}
{"epoch": 36, "training_loss": 32.545126342773436, "training_acc": 45.0, "val_loss": 79.48085021972656, "val_acc": 40.0}
{"epoch": 37, "training_loss": 56.67665672302246, "training_acc": 55.0, "val_loss": 6.919275760650635, "val_acc": 60.0}
{"epoch": 38, "training_loss": 17.66896286010742, "training_acc": 45.0, "val_loss": 1.198764681816101, "val_acc": 60.0}
{"epoch": 39, "training_loss": 6.119197082519531, "training_acc": 55.0, "val_loss": 46.16276931762695, "val_acc": 40.0}
{"epoch": 40, "training_loss": 50.94303588867187, "training_acc": 45.0, "val_loss": 12.324792861938477, "val_acc": 60.0}
{"epoch": 41, "training_loss": 62.968170166015625, "training_acc": 35.0, "val_loss": 196.60488891601562, "val_acc": 40.0}
{"epoch": 42, "training_loss": 136.1934616088867, "training_acc": 55.0, "val_loss": 58.8720703125, "val_acc": 60.0}
{"epoch": 43, "training_loss": 88.62343139648438, "training_acc": 45.0, "val_loss": 36.81709289550781, "val_acc": 40.0}
{"epoch": 44, "training_loss": 27.62850914001465, "training_acc": 55.0, "val_loss": 12.233495712280273, "val_acc": 40.0}
{"epoch": 45, "training_loss": 27.618844985961914, "training_acc": 55.0, "val_loss": 94.24837493896484, "val_acc": 60.0}
{"epoch": 46, "training_loss": 119.60516867637634, "training_acc": 45.0, "val_loss": 59.0698127746582, "val_acc": 40.0}
{"epoch": 47, "training_loss": 40.713995933532715, "training_acc": 45.0, "val_loss": 106.75835418701172, "val_acc": 40.0}
{"epoch": 48, "training_loss": 78.49269409179688, "training_acc": 55.0, "val_loss": 10.505114555358887, "val_acc": 60.0}
{"epoch": 49, "training_loss": 19.1956428527832, "training_acc": 35.0, "val_loss": 78.8022232055664, "val_acc": 60.0}
{"epoch": 50, "training_loss": 107.8153465270996, "training_acc": 45.0, "val_loss": 9.494921684265137, "val_acc": 60.0}
{"epoch": 51, "training_loss": 42.84848175048828, "training_acc": 45.0, "val_loss": 258.9476623535156, "val_acc": 40.0}
{"epoch": 52, "training_loss": 192.65865478515624, "training_acc": 55.0, "val_loss": 104.80517578125, "val_acc": 40.0}
{"epoch": 53, "training_loss": 89.52213592529297, "training_acc": 45.0, "val_loss": 46.837615966796875, "val_acc": 60.0}
{"epoch": 54, "training_loss": 65.4911491394043, "training_acc": 45.0, "val_loss": 87.49718475341797, "val_acc": 40.0}
{"epoch": 55, "training_loss": 76.41250457763672, "training_acc": 35.0, "val_loss": 88.01374816894531, "val_acc": 40.0}
{"epoch": 56, "training_loss": 70.3733123779297, "training_acc": 55.0, "val_loss": 30.048383712768555, "val_acc": 60.0}
{"epoch": 57, "training_loss": 42.94108276367187, "training_acc": 45.0, "val_loss": 57.201839447021484, "val_acc": 40.0}
