"main_modify.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 1 --task ADNI_sex --input_option yAware --learning_rate 5e0 --batch_size 16 --weight_decay 5e-3 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 320.6460172653198, "training_acc": 55.0, "val_loss": 445.6734313964844, "val_acc": 40.0}
{"epoch": 1, "training_loss": 431.9186767578125, "training_acc": 45.0, "val_loss": 470.46807861328125, "val_acc": 60.0}
{"epoch": 2, "training_loss": 629.8386535644531, "training_acc": 45.0, "val_loss": 132.3627166748047, "val_acc": 60.0}
{"epoch": 3, "training_loss": 196.2311279296875, "training_acc": 45.0, "val_loss": 493.0181579589844, "val_acc": 40.0}
{"epoch": 4, "training_loss": 369.61004638671875, "training_acc": 55.0, "val_loss": 314.5711975097656, "val_acc": 40.0}
{"epoch": 5, "training_loss": 161.90802688598632, "training_acc": 55.0, "val_loss": 305.6817932128906, "val_acc": 60.0}
{"epoch": 6, "training_loss": 483.3095947265625, "training_acc": 45.0, "val_loss": 474.5628356933594, "val_acc": 60.0}
{"epoch": 7, "training_loss": 604.42822265625, "training_acc": 45.0, "val_loss": 132.2142333984375, "val_acc": 60.0}
{"epoch": 8, "training_loss": 153.68508911132812, "training_acc": 55.0, "val_loss": 617.7794189453125, "val_acc": 40.0}
{"epoch": 9, "training_loss": 515.4706298828125, "training_acc": 55.0, "val_loss": 823.5107421875, "val_acc": 40.0}
{"epoch": 10, "training_loss": 616.197021484375, "training_acc": 55.0, "val_loss": 524.9281005859375, "val_acc": 40.0}
{"epoch": 11, "training_loss": 370.7369674682617, "training_acc": 55.0, "val_loss": 20.627256393432617, "val_acc": 60.0}
{"epoch": 12, "training_loss": 49.31543731689453, "training_acc": 45.0, "val_loss": 102.4942626953125, "val_acc": 60.0}
{"epoch": 13, "training_loss": 116.84480628967285, "training_acc": 45.0, "val_loss": 235.8218536376953, "val_acc": 40.0}
{"epoch": 14, "training_loss": 194.99656982421874, "training_acc": 55.0, "val_loss": 332.1034851074219, "val_acc": 40.0}
{"epoch": 15, "training_loss": 227.32516174316407, "training_acc": 55.0, "val_loss": 19.396324157714844, "val_acc": 60.0}
{"epoch": 16, "training_loss": 31.08895797729492, "training_acc": 45.0, "val_loss": 57.51591110229492, "val_acc": 60.0}
{"epoch": 17, "training_loss": 60.274260902404784, "training_acc": 55.0, "val_loss": 90.67696380615234, "val_acc": 40.0}
{"epoch": 18, "training_loss": 55.933223724365234, "training_acc": 55.0, "val_loss": 115.10481262207031, "val_acc": 60.0}
{"epoch": 19, "training_loss": 157.17679443359376, "training_acc": 45.0, "val_loss": 152.69627380371094, "val_acc": 60.0}
{"epoch": 20, "training_loss": 190.27364654541014, "training_acc": 45.0, "val_loss": 107.20159912109375, "val_acc": 40.0}
{"epoch": 21, "training_loss": 107.03822021484375, "training_acc": 55.0, "val_loss": 135.72146606445312, "val_acc": 40.0}
{"epoch": 22, "training_loss": 69.53375759124756, "training_acc": 65.0, "val_loss": 79.50350189208984, "val_acc": 60.0}
{"epoch": 23, "training_loss": 102.40898818969727, "training_acc": 45.0, "val_loss": 75.89257049560547, "val_acc": 40.0}
{"epoch": 24, "training_loss": 56.28719787597656, "training_acc": 55.0, "val_loss": 23.91208267211914, "val_acc": 60.0}
{"epoch": 25, "training_loss": 26.63593645095825, "training_acc": 45.0, "val_loss": 145.04405212402344, "val_acc": 40.0}
{"epoch": 26, "training_loss": 112.00751342773438, "training_acc": 55.0, "val_loss": 73.03031921386719, "val_acc": 40.0}
{"epoch": 27, "training_loss": 44.3305160522461, "training_acc": 65.0, "val_loss": 140.58103942871094, "val_acc": 60.0}
{"epoch": 28, "training_loss": 184.70984497070313, "training_acc": 45.0, "val_loss": 4.890664100646973, "val_acc": 40.0}
{"epoch": 29, "training_loss": 17.742150497436523, "training_acc": 55.0, "val_loss": 43.653446197509766, "val_acc": 60.0}
{"epoch": 30, "training_loss": 55.05278549194336, "training_acc": 45.0, "val_loss": 95.13805389404297, "val_acc": 40.0}
{"epoch": 31, "training_loss": 70.96440200805664, "training_acc": 55.0, "val_loss": 40.1026496887207, "val_acc": 40.0}
{"epoch": 32, "training_loss": 28.55924301147461, "training_acc": 65.0, "val_loss": 116.11638641357422, "val_acc": 60.0}
{"epoch": 33, "training_loss": 142.63785705566406, "training_acc": 45.0, "val_loss": 131.06915283203125, "val_acc": 40.0}
{"epoch": 34, "training_loss": 128.5468017578125, "training_acc": 55.0, "val_loss": 181.2808380126953, "val_acc": 40.0}
{"epoch": 35, "training_loss": 105.54163827896119, "training_acc": 55.0, "val_loss": 182.78384399414062, "val_acc": 60.0}
{"epoch": 36, "training_loss": 281.475537109375, "training_acc": 45.0, "val_loss": 217.92568969726562, "val_acc": 60.0}
{"epoch": 37, "training_loss": 279.6025749206543, "training_acc": 45.0, "val_loss": 154.29856872558594, "val_acc": 40.0}
{"epoch": 38, "training_loss": 124.35399017333984, "training_acc": 55.0, "val_loss": 302.7725524902344, "val_acc": 40.0}
{"epoch": 39, "training_loss": 218.44374389648436, "training_acc": 55.0, "val_loss": 62.67243194580078, "val_acc": 40.0}
{"epoch": 40, "training_loss": 25.75994873046875, "training_acc": 75.0, "val_loss": 224.8184051513672, "val_acc": 60.0}
{"epoch": 41, "training_loss": 312.7564392089844, "training_acc": 45.0, "val_loss": 173.81712341308594, "val_acc": 60.0}
{"epoch": 42, "training_loss": 182.6033592224121, "training_acc": 45.0, "val_loss": 340.37091064453125, "val_acc": 40.0}
{"epoch": 43, "training_loss": 316.582470703125, "training_acc": 55.0, "val_loss": 618.5592041015625, "val_acc": 40.0}
{"epoch": 44, "training_loss": 454.4500305175781, "training_acc": 55.0, "val_loss": 356.6348571777344, "val_acc": 40.0}
{"epoch": 45, "training_loss": 243.61836624145508, "training_acc": 55.0, "val_loss": 147.6486053466797, "val_acc": 60.0}
{"epoch": 46, "training_loss": 240.25955810546876, "training_acc": 45.0, "val_loss": 212.4171600341797, "val_acc": 60.0}
{"epoch": 47, "training_loss": 274.531884765625, "training_acc": 45.0, "val_loss": 133.29196166992188, "val_acc": 40.0}
