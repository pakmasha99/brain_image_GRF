"main_modify.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_sex --input_option yAware --learning_rate 5e0 --batch_size 16 --weight_decay 5e-3 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 212.9718261241913, "training_acc": 50.0, "val_loss": 359.4109802246094, "val_acc": 40.0}
{"epoch": 1, "training_loss": 359.6027099609375, "training_acc": 50.0, "val_loss": 672.5217895507812, "val_acc": 60.0}
{"epoch": 2, "training_loss": 816.9298828125, "training_acc": 50.0, "val_loss": 306.4490661621094, "val_acc": 60.0}
{"epoch": 3, "training_loss": 276.4434196472168, "training_acc": 60.0, "val_loss": 466.50665283203125, "val_acc": 40.0}
{"epoch": 4, "training_loss": 393.88274841308595, "training_acc": 50.0, "val_loss": 426.8533630371094, "val_acc": 40.0}
{"epoch": 5, "training_loss": 293.43543701171876, "training_acc": 50.0, "val_loss": 201.7188720703125, "val_acc": 60.0}
{"epoch": 6, "training_loss": 290.45831298828125, "training_acc": 50.0, "val_loss": 377.23193359375, "val_acc": 60.0}
{"epoch": 7, "training_loss": 446.29892578125, "training_acc": 50.0, "val_loss": 87.3862533569336, "val_acc": 60.0}
{"epoch": 8, "training_loss": 97.71767578125, "training_acc": 60.0, "val_loss": 533.3627319335938, "val_acc": 40.0}
{"epoch": 9, "training_loss": 459.6318603515625, "training_acc": 50.0, "val_loss": 530.6854248046875, "val_acc": 40.0}
{"epoch": 10, "training_loss": 390.6735412597656, "training_acc": 50.0, "val_loss": 49.67926025390625, "val_acc": 60.0}
{"epoch": 11, "training_loss": 77.57270812988281, "training_acc": 50.0, "val_loss": 249.3172607421875, "val_acc": 60.0}
{"epoch": 12, "training_loss": 302.7484069824219, "training_acc": 50.0, "val_loss": 93.3714370727539, "val_acc": 60.0}
{"epoch": 13, "training_loss": 119.30001525878906, "training_acc": 50.0, "val_loss": 293.1891784667969, "val_acc": 40.0}
{"epoch": 14, "training_loss": 249.6873046875, "training_acc": 50.0, "val_loss": 63.97517776489258, "val_acc": 40.0}
{"epoch": 15, "training_loss": 89.22546691894532, "training_acc": 50.0, "val_loss": 310.4042053222656, "val_acc": 60.0}
{"epoch": 16, "training_loss": 392.70721435546875, "training_acc": 50.0, "val_loss": 262.9928283691406, "val_acc": 60.0}
{"epoch": 17, "training_loss": 291.3660888671875, "training_acc": 50.0, "val_loss": 154.14337158203125, "val_acc": 40.0}
{"epoch": 18, "training_loss": 174.3174560546875, "training_acc": 50.0, "val_loss": 310.83380126953125, "val_acc": 40.0}
{"epoch": 19, "training_loss": 234.0019104003906, "training_acc": 50.0, "val_loss": 65.25233459472656, "val_acc": 60.0}
{"epoch": 20, "training_loss": 89.06396789550782, "training_acc": 50.0, "val_loss": 143.078369140625, "val_acc": 60.0}
{"epoch": 21, "training_loss": 155.79160766601564, "training_acc": 50.0, "val_loss": 139.4375457763672, "val_acc": 40.0}
{"epoch": 22, "training_loss": 124.08311920166015, "training_acc": 50.0, "val_loss": 264.15240478515625, "val_acc": 40.0}
{"epoch": 23, "training_loss": 196.350244140625, "training_acc": 50.0, "val_loss": 73.95482635498047, "val_acc": 60.0}
{"epoch": 24, "training_loss": 134.62267456054687, "training_acc": 50.0, "val_loss": 166.3715362548828, "val_acc": 60.0}
{"epoch": 25, "training_loss": 193.94020919799806, "training_acc": 50.0, "val_loss": 120.74250793457031, "val_acc": 40.0}
{"epoch": 26, "training_loss": 111.30692443847656, "training_acc": 50.0, "val_loss": 126.886474609375, "val_acc": 40.0}
{"epoch": 27, "training_loss": 76.75192508697509, "training_acc": 60.0, "val_loss": 78.91513061523438, "val_acc": 60.0}
{"epoch": 28, "training_loss": 91.2098487854004, "training_acc": 50.0, "val_loss": 87.0255126953125, "val_acc": 40.0}
{"epoch": 29, "training_loss": 81.9777587890625, "training_acc": 50.0, "val_loss": 12.292472839355469, "val_acc": 60.0}
{"epoch": 30, "training_loss": 21.80215072631836, "training_acc": 50.0, "val_loss": 109.74466705322266, "val_acc": 40.0}
{"epoch": 31, "training_loss": 100.53592529296876, "training_acc": 50.0, "val_loss": 1.891527533531189, "val_acc": 60.0}
{"epoch": 32, "training_loss": 6.10870590209961, "training_acc": 50.0, "val_loss": 69.78988647460938, "val_acc": 40.0}
{"epoch": 33, "training_loss": 54.15992984771729, "training_acc": 50.0, "val_loss": 52.1582145690918, "val_acc": 60.0}
{"epoch": 34, "training_loss": 61.32537841796875, "training_acc": 50.0, "val_loss": 125.34671783447266, "val_acc": 40.0}
{"epoch": 35, "training_loss": 121.22528686523438, "training_acc": 50.0, "val_loss": 71.37489318847656, "val_acc": 40.0}
{"epoch": 36, "training_loss": 73.33758850097657, "training_acc": 50.0, "val_loss": 160.574951171875, "val_acc": 60.0}
{"epoch": 37, "training_loss": 192.21405029296875, "training_acc": 50.0, "val_loss": 2.9742836952209473, "val_acc": 60.0}
{"epoch": 38, "training_loss": 51.75723934173584, "training_acc": 50.0, "val_loss": 449.3011779785156, "val_acc": 40.0}
{"epoch": 39, "training_loss": 375.21897583007814, "training_acc": 50.0, "val_loss": 382.3782043457031, "val_acc": 40.0}
{"epoch": 40, "training_loss": 303.935237121582, "training_acc": 50.0, "val_loss": 35.5170783996582, "val_acc": 60.0}
{"epoch": 41, "training_loss": 59.252288818359375, "training_acc": 50.0, "val_loss": 76.96570587158203, "val_acc": 60.0}
{"epoch": 42, "training_loss": 56.99745635388708, "training_acc": 70.0, "val_loss": 116.35994720458984, "val_acc": 40.0}
{"epoch": 43, "training_loss": 93.46315002441406, "training_acc": 50.0, "val_loss": 31.7779598236084, "val_acc": 60.0}
{"epoch": 44, "training_loss": 38.01993942260742, "training_acc": 50.0, "val_loss": 28.853687286376953, "val_acc": 40.0}
{"epoch": 45, "training_loss": 14.530418241024018, "training_acc": 70.0, "val_loss": 38.73917770385742, "val_acc": 60.0}
{"epoch": 46, "training_loss": 49.87205429077149, "training_acc": 40.0, "val_loss": 51.674354553222656, "val_acc": 60.0}
{"epoch": 47, "training_loss": 61.14282989501953, "training_acc": 50.0, "val_loss": 127.01822662353516, "val_acc": 40.0}
{"epoch": 48, "training_loss": 114.34421997070312, "training_acc": 50.0, "val_loss": 101.59899139404297, "val_acc": 40.0}
{"epoch": 49, "training_loss": 102.05756530761718, "training_acc": 40.0, "val_loss": 71.696044921875, "val_acc": 60.0}
{"epoch": 50, "training_loss": 102.69600524902344, "training_acc": 30.0, "val_loss": 43.613887786865234, "val_acc": 60.0}
