"main_modify.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 2 --task ADNI_sex --input_option yAware --learning_rate 5e0 --batch_size 16 --weight_decay 5e-3 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 214.55751399993898, "training_acc": 50.0, "val_loss": 278.8808288574219, "val_acc": 60.0}
{"epoch": 1, "training_loss": 473.0561279296875, "training_acc": 40.0, "val_loss": 736.9810791015625, "val_acc": 40.0}
{"epoch": 2, "training_loss": 578.8421630859375, "training_acc": 50.0, "val_loss": 82.27745056152344, "val_acc": 40.0}
{"epoch": 3, "training_loss": 138.1560302734375, "training_acc": 50.0, "val_loss": 511.01397705078125, "val_acc": 60.0}
{"epoch": 4, "training_loss": 649.6208374023438, "training_acc": 50.0, "val_loss": 377.4654235839844, "val_acc": 60.0}
{"epoch": 5, "training_loss": 381.0944519042969, "training_acc": 50.0, "val_loss": 335.2209167480469, "val_acc": 40.0}
{"epoch": 6, "training_loss": 304.3482604980469, "training_acc": 50.0, "val_loss": 808.5888061523438, "val_acc": 40.0}
{"epoch": 7, "training_loss": 672.8238647460937, "training_acc": 50.0, "val_loss": 698.8582153320312, "val_acc": 40.0}
{"epoch": 8, "training_loss": 563.3527374267578, "training_acc": 50.0, "val_loss": 151.1861114501953, "val_acc": 40.0}
{"epoch": 9, "training_loss": 219.53370971679686, "training_acc": 30.0, "val_loss": 259.05670166015625, "val_acc": 60.0}
{"epoch": 10, "training_loss": 320.01154174804685, "training_acc": 50.0, "val_loss": 111.85013580322266, "val_acc": 60.0}
{"epoch": 11, "training_loss": 163.78778686523438, "training_acc": 40.0, "val_loss": 249.5069122314453, "val_acc": 40.0}
{"epoch": 12, "training_loss": 203.23492431640625, "training_acc": 50.0, "val_loss": 75.25200653076172, "val_acc": 40.0}
{"epoch": 13, "training_loss": 56.81002960205078, "training_acc": 60.0, "val_loss": 205.7471466064453, "val_acc": 60.0}
{"epoch": 14, "training_loss": 272.82244873046875, "training_acc": 50.0, "val_loss": 107.3884506225586, "val_acc": 60.0}
{"epoch": 15, "training_loss": 128.7944305419922, "training_acc": 50.0, "val_loss": 269.3431091308594, "val_acc": 40.0}
{"epoch": 16, "training_loss": 226.9966796875, "training_acc": 50.0, "val_loss": 178.2137451171875, "val_acc": 40.0}
{"epoch": 17, "training_loss": 89.06924090636895, "training_acc": 70.0, "val_loss": 112.37975311279297, "val_acc": 60.0}
{"epoch": 18, "training_loss": 146.612744140625, "training_acc": 50.0, "val_loss": 74.28690338134766, "val_acc": 60.0}
{"epoch": 19, "training_loss": 71.23898658752441, "training_acc": 60.0, "val_loss": 177.49119567871094, "val_acc": 40.0}
{"epoch": 20, "training_loss": 144.50255737304687, "training_acc": 50.0, "val_loss": 16.158557891845703, "val_acc": 40.0}
{"epoch": 21, "training_loss": 71.56012802124023, "training_acc": 40.0, "val_loss": 194.7543182373047, "val_acc": 60.0}
{"epoch": 22, "training_loss": 229.1914306640625, "training_acc": 50.0, "val_loss": 5.609282970428467, "val_acc": 60.0}
{"epoch": 23, "training_loss": 87.09389228820801, "training_acc": 40.0, "val_loss": 445.3591003417969, "val_acc": 40.0}
{"epoch": 24, "training_loss": 370.40126953125, "training_acc": 50.0, "val_loss": 311.4476013183594, "val_acc": 40.0}
{"epoch": 25, "training_loss": 221.78079071044922, "training_acc": 50.0, "val_loss": 160.79246520996094, "val_acc": 60.0}
{"epoch": 26, "training_loss": 214.288232421875, "training_acc": 50.0, "val_loss": 322.1904296875, "val_acc": 60.0}
{"epoch": 27, "training_loss": 395.16920776367186, "training_acc": 50.0, "val_loss": 184.12840270996094, "val_acc": 60.0}
{"epoch": 28, "training_loss": 186.4048759460449, "training_acc": 50.0, "val_loss": 338.70257568359375, "val_acc": 40.0}
{"epoch": 29, "training_loss": 299.0717376708984, "training_acc": 50.0, "val_loss": 625.14501953125, "val_acc": 40.0}
{"epoch": 30, "training_loss": 522.83251953125, "training_acc": 50.0, "val_loss": 387.5780029296875, "val_acc": 40.0}
{"epoch": 31, "training_loss": 268.36159362792966, "training_acc": 50.0, "val_loss": 237.17808532714844, "val_acc": 60.0}
{"epoch": 32, "training_loss": 339.570654296875, "training_acc": 50.0, "val_loss": 478.736572265625, "val_acc": 60.0}
{"epoch": 33, "training_loss": 596.7031616210937, "training_acc": 50.0, "val_loss": 345.5943908691406, "val_acc": 60.0}
{"epoch": 34, "training_loss": 407.33621673583986, "training_acc": 50.0, "val_loss": 117.91422271728516, "val_acc": 40.0}
{"epoch": 35, "training_loss": 148.46190185546874, "training_acc": 50.0, "val_loss": 321.2841796875, "val_acc": 40.0}
{"epoch": 36, "training_loss": 257.9474639892578, "training_acc": 50.0, "val_loss": 17.54045295715332, "val_acc": 40.0}
{"epoch": 37, "training_loss": 54.07756805419922, "training_acc": 50.0, "val_loss": 255.82192993164062, "val_acc": 60.0}
{"epoch": 38, "training_loss": 328.9862915039063, "training_acc": 50.0, "val_loss": 133.21055603027344, "val_acc": 60.0}
{"epoch": 39, "training_loss": 124.16751708984376, "training_acc": 60.0, "val_loss": 294.4082946777344, "val_acc": 40.0}
{"epoch": 40, "training_loss": 256.85817260742186, "training_acc": 50.0, "val_loss": 302.91400146484375, "val_acc": 40.0}
{"epoch": 41, "training_loss": 224.11834716796875, "training_acc": 50.0, "val_loss": 90.99163818359375, "val_acc": 60.0}
