"main_modify.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 4 --task ADNI_sex --input_option yAware --learning_rate 5e0 --batch_size 16 --weight_decay 5e-3 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 213.0953395843506, "training_acc": 50.0, "val_loss": 353.9428405761719, "val_acc": 40.0}
{"epoch": 1, "training_loss": 447.022265625, "training_acc": 40.0, "val_loss": 565.9929809570312, "val_acc": 60.0}
{"epoch": 2, "training_loss": 684.8297424316406, "training_acc": 50.0, "val_loss": 170.4160614013672, "val_acc": 60.0}
{"epoch": 3, "training_loss": 261.7932067871094, "training_acc": 40.0, "val_loss": 404.4668273925781, "val_acc": 40.0}
{"epoch": 4, "training_loss": 336.6492919921875, "training_acc": 50.0, "val_loss": 145.88587951660156, "val_acc": 40.0}
{"epoch": 5, "training_loss": 94.35124969482422, "training_acc": 60.0, "val_loss": 174.77574157714844, "val_acc": 60.0}
{"epoch": 6, "training_loss": 210.70521545410156, "training_acc": 50.0, "val_loss": 40.302669525146484, "val_acc": 60.0}
{"epoch": 7, "training_loss": 102.81221923828124, "training_acc": 40.0, "val_loss": 266.54937744140625, "val_acc": 40.0}
{"epoch": 8, "training_loss": 195.13760375976562, "training_acc": 50.0, "val_loss": 92.43310546875, "val_acc": 60.0}
{"epoch": 9, "training_loss": 122.296435546875, "training_acc": 50.0, "val_loss": 184.5080108642578, "val_acc": 60.0}
{"epoch": 10, "training_loss": 209.12266235351564, "training_acc": 50.0, "val_loss": 73.4453353881836, "val_acc": 40.0}
{"epoch": 11, "training_loss": 65.69998321533203, "training_acc": 50.0, "val_loss": 121.525390625, "val_acc": 40.0}
{"epoch": 12, "training_loss": 84.00482635498047, "training_acc": 50.0, "val_loss": 14.101969718933105, "val_acc": 60.0}
{"epoch": 13, "training_loss": 45.43332977294922, "training_acc": 40.0, "val_loss": 66.47301483154297, "val_acc": 40.0}
{"epoch": 14, "training_loss": 63.091424560546876, "training_acc": 50.0, "val_loss": 100.6859130859375, "val_acc": 60.0}
{"epoch": 15, "training_loss": 107.88955459594726, "training_acc": 50.0, "val_loss": 155.3491973876953, "val_acc": 40.0}
{"epoch": 16, "training_loss": 139.1707794189453, "training_acc": 50.0, "val_loss": 148.5481414794922, "val_acc": 40.0}
{"epoch": 17, "training_loss": 145.4775604248047, "training_acc": 30.0, "val_loss": 13.97270393371582, "val_acc": 60.0}
{"epoch": 18, "training_loss": 21.94254379272461, "training_acc": 60.0, "val_loss": 201.2852020263672, "val_acc": 40.0}
{"epoch": 19, "training_loss": 161.21533966064453, "training_acc": 50.0, "val_loss": 4.3773088455200195, "val_acc": 40.0}
{"epoch": 20, "training_loss": 63.31559677124024, "training_acc": 40.0, "val_loss": 188.8558807373047, "val_acc": 60.0}
{"epoch": 21, "training_loss": 219.3155731201172, "training_acc": 50.0, "val_loss": 3.0682694911956787, "val_acc": 40.0}
{"epoch": 22, "training_loss": 12.867250633239745, "training_acc": 50.0, "val_loss": 6.27832555770874, "val_acc": 40.0}
{"epoch": 23, "training_loss": 31.47241973876953, "training_acc": 50.0, "val_loss": 136.8036346435547, "val_acc": 60.0}
{"epoch": 24, "training_loss": 150.84880676269532, "training_acc": 50.0, "val_loss": 115.21659088134766, "val_acc": 40.0}
{"epoch": 25, "training_loss": 139.02860107421876, "training_acc": 50.0, "val_loss": 128.1011505126953, "val_acc": 40.0}
{"epoch": 26, "training_loss": 63.748870849609375, "training_acc": 70.0, "val_loss": 164.61289978027344, "val_acc": 60.0}
{"epoch": 27, "training_loss": 210.662109375, "training_acc": 50.0, "val_loss": 134.47608947753906, "val_acc": 60.0}
{"epoch": 28, "training_loss": 133.36185693740845, "training_acc": 50.0, "val_loss": 288.68902587890625, "val_acc": 40.0}
{"epoch": 29, "training_loss": 249.93450317382812, "training_acc": 50.0, "val_loss": 468.6346740722656, "val_acc": 40.0}
{"epoch": 30, "training_loss": 381.8026641845703, "training_acc": 50.0, "val_loss": 229.934326171875, "val_acc": 40.0}
{"epoch": 31, "training_loss": 180.74175109863282, "training_acc": 40.0, "val_loss": 67.50896453857422, "val_acc": 60.0}
{"epoch": 32, "training_loss": 72.66613464355468, "training_acc": 50.0, "val_loss": 138.6545867919922, "val_acc": 40.0}
{"epoch": 33, "training_loss": 116.77485046386718, "training_acc": 50.0, "val_loss": 123.00172424316406, "val_acc": 40.0}
{"epoch": 34, "training_loss": 87.0345230102539, "training_acc": 50.0, "val_loss": 36.243385314941406, "val_acc": 60.0}
{"epoch": 35, "training_loss": 42.93847808837891, "training_acc": 50.0, "val_loss": 18.44142723083496, "val_acc": 40.0}
{"epoch": 36, "training_loss": 32.9243766784668, "training_acc": 50.0, "val_loss": 91.02989959716797, "val_acc": 60.0}
{"epoch": 37, "training_loss": 84.91343383789062, "training_acc": 50.0, "val_loss": 255.60691833496094, "val_acc": 40.0}
{"epoch": 38, "training_loss": 212.3112548828125, "training_acc": 50.0, "val_loss": 494.7236328125, "val_acc": 40.0}
{"epoch": 39, "training_loss": 407.8813110351563, "training_acc": 50.0, "val_loss": 357.45391845703125, "val_acc": 40.0}
{"epoch": 40, "training_loss": 247.76104736328125, "training_acc": 50.0, "val_loss": 130.7462158203125, "val_acc": 60.0}
