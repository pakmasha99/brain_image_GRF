"main_modify.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 3 --task ADNI_sex --input_option yAware --learning_rate 5e0 --batch_size 16 --weight_decay 5e-3 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 210.32943921089174, "training_acc": 50.0, "val_loss": 224.0087432861328, "val_acc": 60.0}
{"epoch": 1, "training_loss": 257.49912719726564, "training_acc": 60.0, "val_loss": 1270.5906982421875, "val_acc": 40.0}
{"epoch": 2, "training_loss": 1051.831396484375, "training_acc": 50.0, "val_loss": 863.7705078125, "val_acc": 40.0}
{"epoch": 3, "training_loss": 623.8006134033203, "training_acc": 50.0, "val_loss": 279.16595458984375, "val_acc": 60.0}
{"epoch": 4, "training_loss": 375.30107421875, "training_acc": 50.0, "val_loss": 608.0296020507812, "val_acc": 60.0}
{"epoch": 5, "training_loss": 751.1018676757812, "training_acc": 50.0, "val_loss": 413.536376953125, "val_acc": 60.0}
{"epoch": 6, "training_loss": 430.65699462890626, "training_acc": 50.0, "val_loss": 253.18809509277344, "val_acc": 40.0}
{"epoch": 7, "training_loss": 292.746533203125, "training_acc": 50.0, "val_loss": 611.4180908203125, "val_acc": 40.0}
{"epoch": 8, "training_loss": 488.7917846679687, "training_acc": 50.0, "val_loss": 221.2541046142578, "val_acc": 40.0}
{"epoch": 9, "training_loss": 140.5761589050293, "training_acc": 60.0, "val_loss": 263.1922607421875, "val_acc": 60.0}
{"epoch": 10, "training_loss": 327.1984375, "training_acc": 50.0, "val_loss": 311.8013916015625, "val_acc": 60.0}
{"epoch": 11, "training_loss": 387.9859375, "training_acc": 50.0, "val_loss": 115.4293441772461, "val_acc": 60.0}
{"epoch": 12, "training_loss": 105.84841232299804, "training_acc": 60.0, "val_loss": 234.15982055664062, "val_acc": 40.0}
{"epoch": 13, "training_loss": 193.7461669921875, "training_acc": 50.0, "val_loss": 124.40419006347656, "val_acc": 40.0}
{"epoch": 14, "training_loss": 80.21703186035157, "training_acc": 60.0, "val_loss": 129.2030792236328, "val_acc": 60.0}
{"epoch": 15, "training_loss": 155.6960876464844, "training_acc": 50.0, "val_loss": 9.767203330993652, "val_acc": 60.0}
{"epoch": 16, "training_loss": 47.27884368896484, "training_acc": 50.0, "val_loss": 314.8072204589844, "val_acc": 40.0}
{"epoch": 17, "training_loss": 250.12915649414063, "training_acc": 50.0, "val_loss": 13.709967613220215, "val_acc": 40.0}
{"epoch": 18, "training_loss": 35.10572052001953, "training_acc": 60.0, "val_loss": 378.85107421875, "val_acc": 60.0}
{"epoch": 19, "training_loss": 484.3696533203125, "training_acc": 50.0, "val_loss": 374.63800048828125, "val_acc": 60.0}
{"epoch": 20, "training_loss": 431.369970703125, "training_acc": 50.0, "val_loss": 14.953940391540527, "val_acc": 60.0}
{"epoch": 21, "training_loss": 81.49291076660157, "training_acc": 50.0, "val_loss": 650.4298095703125, "val_acc": 40.0}
{"epoch": 22, "training_loss": 547.3620727539062, "training_acc": 50.0, "val_loss": 696.0953979492188, "val_acc": 40.0}
{"epoch": 23, "training_loss": 544.77109375, "training_acc": 50.0, "val_loss": 227.60110473632812, "val_acc": 40.0}
{"epoch": 24, "training_loss": 185.13317260742187, "training_acc": 50.0, "val_loss": 301.21624755859375, "val_acc": 60.0}
{"epoch": 25, "training_loss": 390.19138793945314, "training_acc": 50.0, "val_loss": 324.8008117675781, "val_acc": 60.0}
{"epoch": 26, "training_loss": 373.43871154785154, "training_acc": 50.0, "val_loss": 0.9029448628425598, "val_acc": 80.0}
{"epoch": 27, "training_loss": 24.399753475189208, "training_acc": 75.0, "val_loss": 480.9902038574219, "val_acc": 40.0}
{"epoch": 28, "training_loss": 415.05023193359375, "training_acc": 50.0, "val_loss": 380.5940856933594, "val_acc": 40.0}
{"epoch": 29, "training_loss": 254.27772521972656, "training_acc": 50.0, "val_loss": 198.00816345214844, "val_acc": 60.0}
{"epoch": 30, "training_loss": 287.4010986328125, "training_acc": 50.0, "val_loss": 422.08349609375, "val_acc": 60.0}
{"epoch": 31, "training_loss": 526.11240234375, "training_acc": 50.0, "val_loss": 304.5870666503906, "val_acc": 60.0}
{"epoch": 32, "training_loss": 329.9142761230469, "training_acc": 50.0, "val_loss": 107.63575744628906, "val_acc": 40.0}
{"epoch": 33, "training_loss": 106.42001800537109, "training_acc": 50.0, "val_loss": 396.8154296875, "val_acc": 40.0}
{"epoch": 34, "training_loss": 331.4739013671875, "training_acc": 50.0, "val_loss": 255.3840789794922, "val_acc": 40.0}
{"epoch": 35, "training_loss": 160.1945373535156, "training_acc": 50.0, "val_loss": 200.12152099609375, "val_acc": 60.0}
{"epoch": 36, "training_loss": 265.72047424316406, "training_acc": 50.0, "val_loss": 421.45709228515625, "val_acc": 60.0}
{"epoch": 37, "training_loss": 521.4503631591797, "training_acc": 50.0, "val_loss": 322.8910217285156, "val_acc": 60.0}
{"epoch": 38, "training_loss": 363.2546020507813, "training_acc": 50.0, "val_loss": 76.52896881103516, "val_acc": 40.0}
{"epoch": 39, "training_loss": 77.91257171630859, "training_acc": 50.0, "val_loss": 311.2401428222656, "val_acc": 40.0}
{"epoch": 40, "training_loss": 249.95059814453126, "training_acc": 50.0, "val_loss": 32.60036849975586, "val_acc": 40.0}
{"epoch": 41, "training_loss": 103.51435089111328, "training_acc": 40.0, "val_loss": 292.5992736816406, "val_acc": 60.0}
{"epoch": 42, "training_loss": 362.69617919921876, "training_acc": 50.0, "val_loss": 159.7042694091797, "val_acc": 60.0}
{"epoch": 43, "training_loss": 141.35491905212402, "training_acc": 60.0, "val_loss": 241.1142578125, "val_acc": 40.0}
{"epoch": 44, "training_loss": 210.87666015625, "training_acc": 50.0, "val_loss": 206.8746337890625, "val_acc": 40.0}
{"epoch": 45, "training_loss": 140.73315420150757, "training_acc": 50.0, "val_loss": 199.9154052734375, "val_acc": 60.0}
