"main_modify.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 2 --task ADNI_sex --input_option yAware --learning_rate 1e2 --batch_size 8 --weight_decay 1e-8 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 12379.37088112831, "training_acc": 55.0, "val_loss": 1766.4256591796875, "val_acc": 60.0}
{"epoch": 1, "training_loss": 2423.8650512695312, "training_acc": 35.0, "val_loss": 2348.85546875, "val_acc": 60.0}
{"epoch": 2, "training_loss": 2621.33505859375, "training_acc": 45.0, "val_loss": 4337.72802734375, "val_acc": 40.0}
{"epoch": 3, "training_loss": 2360.961328125, "training_acc": 55.0, "val_loss": 2577.821533203125, "val_acc": 60.0}
{"epoch": 4, "training_loss": 2621.354638671875, "training_acc": 45.0, "val_loss": 6024.07666015625, "val_acc": 40.0}
{"epoch": 5, "training_loss": 4039.732556152344, "training_acc": 55.0, "val_loss": 1819.1800537109375, "val_acc": 60.0}
{"epoch": 6, "training_loss": 2623.0964965820312, "training_acc": 25.0, "val_loss": 1261.29248046875, "val_acc": 60.0}
{"epoch": 7, "training_loss": 1467.1481201171875, "training_acc": 45.0, "val_loss": 3058.822509765625, "val_acc": 40.0}
{"epoch": 8, "training_loss": 2237.353564453125, "training_acc": 45.0, "val_loss": 2220.6484375, "val_acc": 60.0}
{"epoch": 9, "training_loss": 1817.052734375, "training_acc": 55.0, "val_loss": 6631.86083984375, "val_acc": 40.0}
{"epoch": 10, "training_loss": 4611.1163330078125, "training_acc": 55.0, "val_loss": 947.7833862304688, "val_acc": 40.0}
{"epoch": 11, "training_loss": 2308.039453125, "training_acc": 55.0, "val_loss": 3077.298583984375, "val_acc": 60.0}
{"epoch": 12, "training_loss": 2772.01630859375, "training_acc": 45.0, "val_loss": 6370.041015625, "val_acc": 40.0}
{"epoch": 13, "training_loss": 4849.666796875, "training_acc": 55.0, "val_loss": 1590.6983642578125, "val_acc": 40.0}
{"epoch": 14, "training_loss": 3089.9052734375, "training_acc": 45.0, "val_loss": 4197.310546875, "val_acc": 60.0}
{"epoch": 15, "training_loss": 3703.921728515625, "training_acc": 45.0, "val_loss": 6637.55712890625, "val_acc": 40.0}
{"epoch": 16, "training_loss": 6258.755859375, "training_acc": 55.0, "val_loss": 11985.1953125, "val_acc": 40.0}
{"epoch": 17, "training_loss": 7674.438647460937, "training_acc": 55.0, "val_loss": 69.81710815429688, "val_acc": 40.0}
{"epoch": 18, "training_loss": 2445.2093818664553, "training_acc": 60.0, "val_loss": 1874.6937255859375, "val_acc": 60.0}
{"epoch": 19, "training_loss": 1525.4240234375, "training_acc": 55.0, "val_loss": 2415.6572265625, "val_acc": 40.0}
{"epoch": 20, "training_loss": 1492.757781791687, "training_acc": 60.0, "val_loss": 1180.1943359375, "val_acc": 60.0}
{"epoch": 21, "training_loss": 1972.2271484375, "training_acc": 45.0, "val_loss": 1954.1121826171875, "val_acc": 40.0}
{"epoch": 22, "training_loss": 2245.8001953125, "training_acc": 35.0, "val_loss": 147.06692504882812, "val_acc": 60.0}
{"epoch": 23, "training_loss": 2082.8497680664063, "training_acc": 55.0, "val_loss": 5787.35986328125, "val_acc": 40.0}
{"epoch": 24, "training_loss": 3044.777392578125, "training_acc": 55.0, "val_loss": 2190.151611328125, "val_acc": 60.0}
{"epoch": 25, "training_loss": 1840.9147338867188, "training_acc": 55.0, "val_loss": 2994.56982421875, "val_acc": 40.0}
{"epoch": 26, "training_loss": 1902.1061279296875, "training_acc": 45.0, "val_loss": 67.11829376220703, "val_acc": 80.0}
{"epoch": 27, "training_loss": 566.2743507385254, "training_acc": 60.0, "val_loss": 332.85479736328125, "val_acc": 60.0}
{"epoch": 28, "training_loss": 2277.0638427734375, "training_acc": 45.0, "val_loss": 4389.34033203125, "val_acc": 40.0}
{"epoch": 29, "training_loss": 2035.0542724609375, "training_acc": 55.0, "val_loss": 3032.798828125, "val_acc": 60.0}
{"epoch": 30, "training_loss": 2996.502001953125, "training_acc": 45.0, "val_loss": 5165.35107421875, "val_acc": 40.0}
{"epoch": 31, "training_loss": 4655.51171875, "training_acc": 55.0, "val_loss": 7690.68505859375, "val_acc": 40.0}
{"epoch": 32, "training_loss": 4504.417810058594, "training_acc": 45.0, "val_loss": 503.59814453125, "val_acc": 60.0}
{"epoch": 33, "training_loss": 674.295654296875, "training_acc": 55.0, "val_loss": 641.6234741210938, "val_acc": 60.0}
{"epoch": 34, "training_loss": 345.86180114746094, "training_acc": 60.0, "val_loss": 619.6669311523438, "val_acc": 40.0}
{"epoch": 35, "training_loss": 990.3076442718506, "training_acc": 40.0, "val_loss": 2364.29345703125, "val_acc": 40.0}
{"epoch": 36, "training_loss": 2078.182666015625, "training_acc": 55.0, "val_loss": 1833.845703125, "val_acc": 60.0}
{"epoch": 37, "training_loss": 3354.892578125, "training_acc": 45.0, "val_loss": 774.8238525390625, "val_acc": 60.0}
{"epoch": 38, "training_loss": 1484.9754150390625, "training_acc": 65.0, "val_loss": 6196.1171875, "val_acc": 40.0}
{"epoch": 39, "training_loss": 3523.250668334961, "training_acc": 55.0, "val_loss": 2751.51123046875, "val_acc": 60.0}
{"epoch": 40, "training_loss": 4113.124169921875, "training_acc": 45.0, "val_loss": 355.3816833496094, "val_acc": 60.0}
{"epoch": 41, "training_loss": 3106.9946044921876, "training_acc": 45.0, "val_loss": 9317.7705078125, "val_acc": 40.0}
{"epoch": 42, "training_loss": 5903.335424804687, "training_acc": 55.0, "val_loss": 502.15313720703125, "val_acc": 60.0}
{"epoch": 43, "training_loss": 782.6315795898438, "training_acc": 45.0, "val_loss": 3422.806640625, "val_acc": 40.0}
{"epoch": 44, "training_loss": 2778.338427734375, "training_acc": 55.0, "val_loss": 173.5069122314453, "val_acc": 80.0}
{"epoch": 45, "training_loss": 4106.664141845703, "training_acc": 40.0, "val_loss": 2475.69384765625, "val_acc": 60.0}
