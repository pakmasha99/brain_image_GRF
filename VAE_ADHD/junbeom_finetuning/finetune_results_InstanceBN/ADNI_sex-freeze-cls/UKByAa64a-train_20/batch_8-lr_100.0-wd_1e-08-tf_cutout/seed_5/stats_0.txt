"main_modify.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 5 --task ADNI_sex --input_option yAware --learning_rate 1e2 --batch_size 8 --weight_decay 1e-8 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 15432.432711029052, "training_acc": 40.0, "val_loss": 4747.1474609375, "val_acc": 40.0}
{"epoch": 1, "training_loss": 7295.9978515625, "training_acc": 55.0, "val_loss": 14304.5341796875, "val_acc": 60.0}
{"epoch": 2, "training_loss": 18094.434765625, "training_acc": 45.0, "val_loss": 5130.91259765625, "val_acc": 60.0}
{"epoch": 3, "training_loss": 8337.102978515624, "training_acc": 45.0, "val_loss": 14974.8818359375, "val_acc": 40.0}
{"epoch": 4, "training_loss": 10617.56103515625, "training_acc": 55.0, "val_loss": 5881.82861328125, "val_acc": 40.0}
{"epoch": 5, "training_loss": 3341.907958984375, "training_acc": 45.0, "val_loss": 2454.978271484375, "val_acc": 60.0}
{"epoch": 6, "training_loss": 1789.7116577148438, "training_acc": 55.0, "val_loss": 8150.27197265625, "val_acc": 40.0}
{"epoch": 7, "training_loss": 6367.02734375, "training_acc": 55.0, "val_loss": 4243.25048828125, "val_acc": 40.0}
{"epoch": 8, "training_loss": 1550.2018798828126, "training_acc": 65.0, "val_loss": 5601.81591796875, "val_acc": 60.0}
{"epoch": 9, "training_loss": 8095.5197265625, "training_acc": 45.0, "val_loss": 1742.197265625, "val_acc": 60.0}
{"epoch": 10, "training_loss": 4826.18525390625, "training_acc": 35.0, "val_loss": 11636.8154296875, "val_acc": 40.0}
{"epoch": 11, "training_loss": 8551.158984375, "training_acc": 55.0, "val_loss": 5187.7734375, "val_acc": 40.0}
{"epoch": 12, "training_loss": 2734.3053344726563, "training_acc": 55.0, "val_loss": 6259.06298828125, "val_acc": 60.0}
{"epoch": 13, "training_loss": 8939.75986328125, "training_acc": 45.0, "val_loss": 2324.5185546875, "val_acc": 60.0}
{"epoch": 14, "training_loss": 4731.96484375, "training_acc": 35.0, "val_loss": 9192.201171875, "val_acc": 40.0}
{"epoch": 15, "training_loss": 5953.230419921875, "training_acc": 55.0, "val_loss": 498.0133972167969, "val_acc": 60.0}
{"epoch": 16, "training_loss": 782.2521060045444, "training_acc": 55.0, "val_loss": 1405.52294921875, "val_acc": 40.0}
{"epoch": 17, "training_loss": 866.8049926757812, "training_acc": 55.0, "val_loss": 1644.545166015625, "val_acc": 60.0}
{"epoch": 18, "training_loss": 2141.4917724609377, "training_acc": 35.0, "val_loss": 725.71533203125, "val_acc": 60.0}
{"epoch": 19, "training_loss": 957.2820373535156, "training_acc": 45.0, "val_loss": 4672.7119140625, "val_acc": 40.0}
{"epoch": 20, "training_loss": 4351.00908203125, "training_acc": 55.0, "val_loss": 4807.4853515625, "val_acc": 40.0}
{"epoch": 21, "training_loss": 3186.8516805648806, "training_acc": 55.0, "val_loss": 3944.08203125, "val_acc": 60.0}
{"epoch": 22, "training_loss": 3450.837060546875, "training_acc": 60.0, "val_loss": 3338.237060546875, "val_acc": 40.0}
{"epoch": 23, "training_loss": 2723.2669921875, "training_acc": 55.0, "val_loss": 258.947021484375, "val_acc": 60.0}
{"epoch": 24, "training_loss": 1336.2721252441406, "training_acc": 45.0, "val_loss": 4284.0888671875, "val_acc": 40.0}
{"epoch": 25, "training_loss": 4478.896484375, "training_acc": 55.0, "val_loss": 5177.96337890625, "val_acc": 40.0}
{"epoch": 26, "training_loss": 1964.5203247070312, "training_acc": 65.0, "val_loss": 2641.174560546875, "val_acc": 60.0}
{"epoch": 27, "training_loss": 2956.0397216796873, "training_acc": 45.0, "val_loss": 4266.8984375, "val_acc": 40.0}
{"epoch": 28, "training_loss": 4479.0669921875, "training_acc": 55.0, "val_loss": 5080.86083984375, "val_acc": 40.0}
{"epoch": 29, "training_loss": 2899.926171875, "training_acc": 45.0, "val_loss": 4787.2900390625, "val_acc": 60.0}
{"epoch": 30, "training_loss": 5643.319616699218, "training_acc": 45.0, "val_loss": 2353.204833984375, "val_acc": 40.0}
{"epoch": 31, "training_loss": 2892.5302734375, "training_acc": 55.0, "val_loss": 2047.734375, "val_acc": 40.0}
{"epoch": 32, "training_loss": 2582.49033203125, "training_acc": 45.0, "val_loss": 2701.768798828125, "val_acc": 60.0}
{"epoch": 33, "training_loss": 2326.091943359375, "training_acc": 45.0, "val_loss": 7051.3828125, "val_acc": 40.0}
{"epoch": 34, "training_loss": 5170.922265625, "training_acc": 55.0, "val_loss": 1950.3726806640625, "val_acc": 40.0}
{"epoch": 35, "training_loss": 2154.583154296875, "training_acc": 45.0, "val_loss": 1682.2352294921875, "val_acc": 60.0}
{"epoch": 36, "training_loss": 1306.63251953125, "training_acc": 55.0, "val_loss": 1263.5477294921875, "val_acc": 40.0}
{"epoch": 37, "training_loss": 895.471337890625, "training_acc": 55.0, "val_loss": 627.4577026367188, "val_acc": 40.0}
{"epoch": 38, "training_loss": 453.2599853515625, "training_acc": 70.0, "val_loss": 1030.9796142578125, "val_acc": 60.0}
{"epoch": 39, "training_loss": 685.2957580566406, "training_acc": 60.0, "val_loss": 3591.824951171875, "val_acc": 40.0}
{"epoch": 40, "training_loss": 1939.9435638427735, "training_acc": 60.0, "val_loss": 2291.060302734375, "val_acc": 60.0}
{"epoch": 41, "training_loss": 2929.26884765625, "training_acc": 45.0, "val_loss": 2149.40771484375, "val_acc": 40.0}
{"epoch": 42, "training_loss": 2765.466015625, "training_acc": 55.0, "val_loss": 1931.3968505859375, "val_acc": 40.0}
