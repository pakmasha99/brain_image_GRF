"main_modify.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 5 --task ADNI_sex --input_option yAware --learning_rate 1e2 --batch_size 8 --weight_decay 1e-8 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 14909.361213111877, "training_acc": 50.0, "val_loss": 4789.02783203125, "val_acc": 40.0}
{"epoch": 1, "training_loss": 8318.57607421875, "training_acc": 50.0, "val_loss": 4125.169921875, "val_acc": 40.0}
{"epoch": 2, "training_loss": 5069.51923828125, "training_acc": 50.0, "val_loss": 7894.4189453125, "val_acc": 60.0}
{"epoch": 3, "training_loss": 8066.66015625, "training_acc": 50.0, "val_loss": 3178.8125, "val_acc": 40.0}
{"epoch": 4, "training_loss": 5209.4314453125, "training_acc": 50.0, "val_loss": 6983.49609375, "val_acc": 40.0}
{"epoch": 5, "training_loss": 3864.393115234375, "training_acc": 50.0, "val_loss": 5544.05810546875, "val_acc": 60.0}
{"epoch": 6, "training_loss": 6632.1734375, "training_acc": 50.0, "val_loss": 659.281982421875, "val_acc": 60.0}
{"epoch": 7, "training_loss": 3998.7666748046877, "training_acc": 50.0, "val_loss": 10530.34375, "val_acc": 40.0}
{"epoch": 8, "training_loss": 6743.95478515625, "training_acc": 50.0, "val_loss": 1727.7371826171875, "val_acc": 60.0}
{"epoch": 9, "training_loss": 4959.610791015625, "training_acc": 50.0, "val_loss": 4207.1953125, "val_acc": 60.0}
{"epoch": 10, "training_loss": 3936.24052734375, "training_acc": 40.0, "val_loss": 6325.69189453125, "val_acc": 40.0}
{"epoch": 11, "training_loss": 5066.951171875, "training_acc": 50.0, "val_loss": 968.7531127929688, "val_acc": 60.0}
{"epoch": 12, "training_loss": 1261.9162841796874, "training_acc": 40.0, "val_loss": 601.3853759765625, "val_acc": 60.0}
{"epoch": 13, "training_loss": 611.3656880676747, "training_acc": 60.0, "val_loss": 624.7528686523438, "val_acc": 60.0}
{"epoch": 14, "training_loss": 982.6368637084961, "training_acc": 45.0, "val_loss": 1080.5770263671875, "val_acc": 40.0}
{"epoch": 15, "training_loss": 3419.3328125, "training_acc": 30.0, "val_loss": 1566.9930419921875, "val_acc": 60.0}
{"epoch": 16, "training_loss": 2664.475, "training_acc": 50.0, "val_loss": 4295.205078125, "val_acc": 40.0}
{"epoch": 17, "training_loss": 1834.01142578125, "training_acc": 60.0, "val_loss": 3898.603515625, "val_acc": 60.0}
{"epoch": 18, "training_loss": 4304.877709960938, "training_acc": 50.0, "val_loss": 891.1951293945312, "val_acc": 40.0}
{"epoch": 19, "training_loss": 2236.1157348632814, "training_acc": 50.0, "val_loss": 1764.146728515625, "val_acc": 60.0}
{"epoch": 20, "training_loss": 2697.024951171875, "training_acc": 50.0, "val_loss": 1119.9559326171875, "val_acc": 60.0}
{"epoch": 21, "training_loss": 2370.90712890625, "training_acc": 50.0, "val_loss": 4738.11767578125, "val_acc": 40.0}
{"epoch": 22, "training_loss": 2197.6260314941405, "training_acc": 60.0, "val_loss": 2319.180908203125, "val_acc": 60.0}
{"epoch": 23, "training_loss": 2466.47646484375, "training_acc": 50.0, "val_loss": 2831.71484375, "val_acc": 40.0}
{"epoch": 24, "training_loss": 3002.8908203125, "training_acc": 50.0, "val_loss": 453.8409118652344, "val_acc": 40.0}
{"epoch": 25, "training_loss": 4056.37802734375, "training_acc": 30.0, "val_loss": 3919.1015625, "val_acc": 60.0}
{"epoch": 26, "training_loss": 2652.260876464844, "training_acc": 60.0, "val_loss": 5820.41796875, "val_acc": 40.0}
{"epoch": 27, "training_loss": 4582.69873046875, "training_acc": 50.0, "val_loss": 459.960693359375, "val_acc": 40.0}
{"epoch": 28, "training_loss": 3142.8777465820312, "training_acc": 50.0, "val_loss": 5454.9580078125, "val_acc": 60.0}
{"epoch": 29, "training_loss": 5228.055267333984, "training_acc": 50.0, "val_loss": 4088.232177734375, "val_acc": 40.0}
{"epoch": 30, "training_loss": 5400.01083984375, "training_acc": 50.0, "val_loss": 4866.35302734375, "val_acc": 40.0}
{"epoch": 31, "training_loss": 2863.720458984375, "training_acc": 40.0, "val_loss": 1510.1917724609375, "val_acc": 60.0}
{"epoch": 32, "training_loss": 1136.5465087890625, "training_acc": 50.0, "val_loss": 148.8074188232422, "val_acc": 60.0}
{"epoch": 33, "training_loss": 552.9176300048828, "training_acc": 65.0, "val_loss": 1136.373779296875, "val_acc": 40.0}
{"epoch": 34, "training_loss": 519.7028991699219, "training_acc": 50.0, "val_loss": 909.0517578125, "val_acc": 60.0}
{"epoch": 35, "training_loss": 949.9354248046875, "training_acc": 50.0, "val_loss": 2348.6416015625, "val_acc": 40.0}
{"epoch": 36, "training_loss": 1076.5885620117188, "training_acc": 60.0, "val_loss": 3179.6748046875, "val_acc": 60.0}
{"epoch": 37, "training_loss": 2813.879022216797, "training_acc": 50.0, "val_loss": 3979.577392578125, "val_acc": 40.0}
{"epoch": 38, "training_loss": 4847.10087890625, "training_acc": 50.0, "val_loss": 3143.934814453125, "val_acc": 40.0}
{"epoch": 39, "training_loss": 2807.85458984375, "training_acc": 50.0, "val_loss": 3155.1943359375, "val_acc": 60.0}
{"epoch": 40, "training_loss": 2493.560595703125, "training_acc": 50.0, "val_loss": 5188.78662109375, "val_acc": 40.0}
{"epoch": 41, "training_loss": 3246.5794921875, "training_acc": 50.0, "val_loss": 2395.014892578125, "val_acc": 60.0}
{"epoch": 42, "training_loss": 3584.73076171875, "training_acc": 50.0, "val_loss": 1979.6107177734375, "val_acc": 60.0}
{"epoch": 43, "training_loss": 2156.810107421875, "training_acc": 50.0, "val_loss": 2164.837646484375, "val_acc": 40.0}
{"epoch": 44, "training_loss": 1639.909716796875, "training_acc": 50.0, "val_loss": 425.5653381347656, "val_acc": 60.0}
{"epoch": 45, "training_loss": 2081.3630615234374, "training_acc": 50.0, "val_loss": 3888.424560546875, "val_acc": 40.0}
{"epoch": 46, "training_loss": 2068.893896484375, "training_acc": 50.0, "val_loss": 4234.8046875, "val_acc": 60.0}
{"epoch": 47, "training_loss": 4390.992578125, "training_acc": 50.0, "val_loss": 1530.635498046875, "val_acc": 40.0}
{"epoch": 48, "training_loss": 1570.4367919921874, "training_acc": 50.0, "val_loss": 1364.9998779296875, "val_acc": 60.0}
{"epoch": 49, "training_loss": 1712.6446472167968, "training_acc": 50.0, "val_loss": 2115.3671875, "val_acc": 40.0}
{"epoch": 50, "training_loss": 1820.1745849609374, "training_acc": 30.0, "val_loss": 367.6947937011719, "val_acc": 40.0}
{"epoch": 51, "training_loss": 224.758935546875, "training_acc": 50.0, "val_loss": 669.2023315429688, "val_acc": 40.0}
