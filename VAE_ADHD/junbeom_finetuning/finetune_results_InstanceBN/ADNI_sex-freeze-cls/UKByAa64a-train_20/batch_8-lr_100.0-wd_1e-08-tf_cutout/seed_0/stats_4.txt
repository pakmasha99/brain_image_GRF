"main_modify.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_sex --input_option yAware --learning_rate 1e2 --batch_size 8 --weight_decay 1e-8 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 13419.366158294677, "training_acc": 35.0, "val_loss": 8817.455078125, "val_acc": 40.0}
{"epoch": 1, "training_loss": 8553.589453125, "training_acc": 55.0, "val_loss": 12600.3076171875, "val_acc": 40.0}
{"epoch": 2, "training_loss": 6143.914477539062, "training_acc": 55.0, "val_loss": 2270.49365234375, "val_acc": 60.0}
{"epoch": 3, "training_loss": 3199.3380859375, "training_acc": 35.0, "val_loss": 6558.06396484375, "val_acc": 40.0}
{"epoch": 4, "training_loss": 3508.8935546875, "training_acc": 55.0, "val_loss": 4285.43994140625, "val_acc": 60.0}
{"epoch": 5, "training_loss": 7096.58203125, "training_acc": 45.0, "val_loss": 3496.39111328125, "val_acc": 60.0}
{"epoch": 6, "training_loss": 3545.587744140625, "training_acc": 45.0, "val_loss": 3762.760986328125, "val_acc": 40.0}
{"epoch": 7, "training_loss": 2645.4672607421876, "training_acc": 45.0, "val_loss": 4163.78759765625, "val_acc": 60.0}
{"epoch": 8, "training_loss": 4477.322793579102, "training_acc": 35.0, "val_loss": 1018.3129272460938, "val_acc": 40.0}
{"epoch": 9, "training_loss": 802.0575927734375, "training_acc": 55.0, "val_loss": 2339.581787109375, "val_acc": 60.0}
{"epoch": 10, "training_loss": 2369.957763671875, "training_acc": 45.0, "val_loss": 4868.490234375, "val_acc": 40.0}
{"epoch": 11, "training_loss": 3154.630126953125, "training_acc": 35.0, "val_loss": 1115.39013671875, "val_acc": 40.0}
{"epoch": 12, "training_loss": 581.3840576171875, "training_acc": 65.0, "val_loss": 1208.8363037109375, "val_acc": 60.0}
{"epoch": 13, "training_loss": 1333.6020263671876, "training_acc": 45.0, "val_loss": 5408.11279296875, "val_acc": 40.0}
{"epoch": 14, "training_loss": 4026.938134765625, "training_acc": 55.0, "val_loss": 808.5263671875, "val_acc": 60.0}
{"epoch": 15, "training_loss": 1345.7031616210938, "training_acc": 45.0, "val_loss": 2006.5142822265625, "val_acc": 40.0}
{"epoch": 16, "training_loss": 1767.059130859375, "training_acc": 55.0, "val_loss": 983.7662963867188, "val_acc": 60.0}
{"epoch": 17, "training_loss": 1091.9041717529296, "training_acc": 50.0, "val_loss": 2203.27685546875, "val_acc": 40.0}
{"epoch": 18, "training_loss": 1382.786674118042, "training_acc": 60.0, "val_loss": 2003.6011962890625, "val_acc": 60.0}
{"epoch": 19, "training_loss": 2974.9336791992187, "training_acc": 45.0, "val_loss": 2932.33251953125, "val_acc": 40.0}
{"epoch": 20, "training_loss": 2343.139050292969, "training_acc": 55.0, "val_loss": 132.54556274414062, "val_acc": 60.0}
{"epoch": 21, "training_loss": 513.2925537109375, "training_acc": 50.0, "val_loss": 186.9437713623047, "val_acc": 60.0}
{"epoch": 22, "training_loss": 145.42738729715342, "training_acc": 70.0, "val_loss": 452.93707275390625, "val_acc": 60.0}
{"epoch": 23, "training_loss": 1411.7164001464844, "training_acc": 35.0, "val_loss": 149.2122039794922, "val_acc": 60.0}
{"epoch": 24, "training_loss": 551.1505249023437, "training_acc": 35.0, "val_loss": 1014.8093872070312, "val_acc": 40.0}
{"epoch": 25, "training_loss": 668.111962890625, "training_acc": 55.0, "val_loss": 461.0143737792969, "val_acc": 60.0}
{"epoch": 26, "training_loss": 475.54893798828124, "training_acc": 65.0, "val_loss": 79.14511108398438, "val_acc": 80.0}
{"epoch": 27, "training_loss": 81.33701934814454, "training_acc": 80.0, "val_loss": 383.244140625, "val_acc": 60.0}
{"epoch": 28, "training_loss": 842.9939392089843, "training_acc": 45.0, "val_loss": 473.1217346191406, "val_acc": 60.0}
{"epoch": 29, "training_loss": 1062.9437377929687, "training_acc": 25.0, "val_loss": 2150.120361328125, "val_acc": 60.0}
{"epoch": 30, "training_loss": 2939.5328369140625, "training_acc": 45.0, "val_loss": 1733.5223388671875, "val_acc": 40.0}
{"epoch": 31, "training_loss": 1735.42822265625, "training_acc": 55.0, "val_loss": 1211.2081298828125, "val_acc": 60.0}
{"epoch": 32, "training_loss": 2352.176318359375, "training_acc": 45.0, "val_loss": 1882.3406982421875, "val_acc": 40.0}
{"epoch": 33, "training_loss": 1738.506396484375, "training_acc": 55.0, "val_loss": 475.5013732910156, "val_acc": 40.0}
{"epoch": 34, "training_loss": 2669.4827575683594, "training_acc": 45.0, "val_loss": 1040.4541015625, "val_acc": 60.0}
{"epoch": 35, "training_loss": 2167.13056640625, "training_acc": 55.0, "val_loss": 5897.8125, "val_acc": 40.0}
{"epoch": 36, "training_loss": 3586.67646484375, "training_acc": 35.0, "val_loss": 528.6486206054688, "val_acc": 60.0}
{"epoch": 37, "training_loss": 826.1410888671875, "training_acc": 55.0, "val_loss": 114.3218994140625, "val_acc": 40.0}
{"epoch": 38, "training_loss": 516.3210479736329, "training_acc": 65.0, "val_loss": 1287.1177978515625, "val_acc": 40.0}
{"epoch": 39, "training_loss": 318.1550354003906, "training_acc": 70.0, "val_loss": 1052.5482177734375, "val_acc": 60.0}
{"epoch": 40, "training_loss": 1020.40205078125, "training_acc": 50.0, "val_loss": 263.80291748046875, "val_acc": 60.0}
{"epoch": 41, "training_loss": 455.0429321289063, "training_acc": 65.0, "val_loss": 3682.26953125, "val_acc": 40.0}
{"epoch": 42, "training_loss": 2092.0765625, "training_acc": 55.0, "val_loss": 1734.673828125, "val_acc": 60.0}
{"epoch": 43, "training_loss": 4714.719775390625, "training_acc": 45.0, "val_loss": 795.2111206054688, "val_acc": 60.0}
{"epoch": 44, "training_loss": 1894.942529296875, "training_acc": 65.0, "val_loss": 9042.2685546875, "val_acc": 40.0}
{"epoch": 45, "training_loss": 5716.969213867187, "training_acc": 55.0, "val_loss": 686.5062866210938, "val_acc": 40.0}
