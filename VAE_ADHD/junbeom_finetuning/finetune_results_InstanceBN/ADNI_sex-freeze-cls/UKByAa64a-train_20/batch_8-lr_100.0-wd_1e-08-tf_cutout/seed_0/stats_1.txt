"main_modify.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_sex --input_option yAware --learning_rate 1e2 --batch_size 8 --weight_decay 1e-8 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 12150.056869006157, "training_acc": 50.0, "val_loss": 11666.7734375, "val_acc": 40.0}
{"epoch": 1, "training_loss": 14612.4818359375, "training_acc": 50.0, "val_loss": 11445.1826171875, "val_acc": 40.0}
{"epoch": 2, "training_loss": 6179.235791015625, "training_acc": 50.0, "val_loss": 13092.109375, "val_acc": 60.0}
{"epoch": 3, "training_loss": 16484.2384765625, "training_acc": 50.0, "val_loss": 8742.142578125, "val_acc": 60.0}
{"epoch": 4, "training_loss": 6939.01474609375, "training_acc": 50.0, "val_loss": 9159.6142578125, "val_acc": 40.0}
{"epoch": 5, "training_loss": 7621.166015625, "training_acc": 50.0, "val_loss": 3353.231689453125, "val_acc": 40.0}
{"epoch": 6, "training_loss": 7433.54375, "training_acc": 20.0, "val_loss": 6495.7607421875, "val_acc": 60.0}
{"epoch": 7, "training_loss": 5576.744677734375, "training_acc": 50.0, "val_loss": 5131.68115234375, "val_acc": 40.0}
{"epoch": 8, "training_loss": 8077.07021484375, "training_acc": 50.0, "val_loss": 10306.291015625, "val_acc": 40.0}
{"epoch": 9, "training_loss": 6101.63056640625, "training_acc": 40.0, "val_loss": 2714.91357421875, "val_acc": 60.0}
{"epoch": 10, "training_loss": 2840.442367553711, "training_acc": 50.0, "val_loss": 2887.749755859375, "val_acc": 40.0}
{"epoch": 11, "training_loss": 2936.141943359375, "training_acc": 50.0, "val_loss": 675.6168823242188, "val_acc": 60.0}
{"epoch": 12, "training_loss": 1218.1079025268555, "training_acc": 50.0, "val_loss": 2603.5234375, "val_acc": 40.0}
{"epoch": 13, "training_loss": 1908.585791015625, "training_acc": 50.0, "val_loss": 2214.513916015625, "val_acc": 60.0}
{"epoch": 14, "training_loss": 3359.9181640625, "training_acc": 50.0, "val_loss": 362.7904052734375, "val_acc": 60.0}
{"epoch": 15, "training_loss": 2292.661279296875, "training_acc": 50.0, "val_loss": 5333.1806640625, "val_acc": 40.0}
{"epoch": 16, "training_loss": 2499.2760986328126, "training_acc": 60.0, "val_loss": 1814.3485107421875, "val_acc": 60.0}
{"epoch": 17, "training_loss": 1677.8038696289063, "training_acc": 50.0, "val_loss": 372.3494567871094, "val_acc": 40.0}
{"epoch": 18, "training_loss": 1724.4783203125, "training_acc": 40.0, "val_loss": 103.01717376708984, "val_acc": 60.0}
{"epoch": 19, "training_loss": 421.0246520996094, "training_acc": 50.0, "val_loss": 2111.568115234375, "val_acc": 40.0}
{"epoch": 20, "training_loss": 1095.6615478515625, "training_acc": 65.0, "val_loss": 1299.171142578125, "val_acc": 60.0}
{"epoch": 21, "training_loss": 1334.8009986877441, "training_acc": 55.0, "val_loss": 1836.1551513671875, "val_acc": 40.0}
{"epoch": 22, "training_loss": 1569.38828125, "training_acc": 40.0, "val_loss": 1084.692138671875, "val_acc": 40.0}
{"epoch": 23, "training_loss": 753.1945678710938, "training_acc": 50.0, "val_loss": 232.2018280029297, "val_acc": 60.0}
{"epoch": 24, "training_loss": 766.135546875, "training_acc": 60.0, "val_loss": 129.3128662109375, "val_acc": 60.0}
{"epoch": 25, "training_loss": 780.2526335716248, "training_acc": 65.0, "val_loss": 1945.3568115234375, "val_acc": 40.0}
{"epoch": 26, "training_loss": 1694.233349609375, "training_acc": 50.0, "val_loss": 1623.9583740234375, "val_acc": 60.0}
{"epoch": 27, "training_loss": 2890.484765625, "training_acc": 50.0, "val_loss": 1099.629150390625, "val_acc": 40.0}
{"epoch": 28, "training_loss": 1795.933984375, "training_acc": 50.0, "val_loss": 75.49898529052734, "val_acc": 60.0}
{"epoch": 29, "training_loss": 1824.752487373352, "training_acc": 60.0, "val_loss": 2029.0413818359375, "val_acc": 60.0}
{"epoch": 30, "training_loss": 2644.8769775390624, "training_acc": 30.0, "val_loss": 337.06207275390625, "val_acc": 60.0}
{"epoch": 31, "training_loss": 709.8651000976563, "training_acc": 40.0, "val_loss": 97.00520324707031, "val_acc": 60.0}
{"epoch": 32, "training_loss": 1345.5814178466796, "training_acc": 55.0, "val_loss": 1184.1539306640625, "val_acc": 40.0}
{"epoch": 33, "training_loss": 969.6839965820312, "training_acc": 50.0, "val_loss": 2045.4603271484375, "val_acc": 60.0}
{"epoch": 34, "training_loss": 2870.5884765625, "training_acc": 50.0, "val_loss": 826.6049194335938, "val_acc": 40.0}
{"epoch": 35, "training_loss": 1360.285498046875, "training_acc": 50.0, "val_loss": 1222.2147216796875, "val_acc": 60.0}
{"epoch": 36, "training_loss": 2292.106201171875, "training_acc": 50.0, "val_loss": 126.1205062866211, "val_acc": 60.0}
{"epoch": 37, "training_loss": 1190.656640625, "training_acc": 75.0, "val_loss": 1791.9677734375, "val_acc": 40.0}
{"epoch": 38, "training_loss": 2338.18720703125, "training_acc": 40.0, "val_loss": 1486.1929931640625, "val_acc": 60.0}
{"epoch": 39, "training_loss": 656.5621505737305, "training_acc": 75.0, "val_loss": 5201.8017578125, "val_acc": 40.0}
{"epoch": 40, "training_loss": 3404.9630859375, "training_acc": 50.0, "val_loss": 1993.326171875, "val_acc": 60.0}
{"epoch": 41, "training_loss": 3978.81953125, "training_acc": 50.0, "val_loss": 2530.738037109375, "val_acc": 60.0}
{"epoch": 42, "training_loss": 1837.9610717773437, "training_acc": 50.0, "val_loss": 881.09912109375, "val_acc": 40.0}
{"epoch": 43, "training_loss": 1965.5227416992188, "training_acc": 50.0, "val_loss": 1619.2010498046875, "val_acc": 60.0}
{"epoch": 44, "training_loss": 1388.85791015625, "training_acc": 50.0, "val_loss": 1975.1474609375, "val_acc": 40.0}
{"epoch": 45, "training_loss": 937.7916076660156, "training_acc": 60.0, "val_loss": 2115.115966796875, "val_acc": 60.0}
{"epoch": 46, "training_loss": 1790.67431640625, "training_acc": 50.0, "val_loss": 3430.443115234375, "val_acc": 40.0}
{"epoch": 47, "training_loss": 1654.9845169067382, "training_acc": 60.0, "val_loss": 805.91650390625, "val_acc": 60.0}
