"main_modify.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_sex --input_option yAware --learning_rate 1e2 --batch_size 8 --weight_decay 1e-8 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 9169.834302282334, "training_acc": 50.0, "val_loss": 16645.794921875, "val_acc": 40.0}
{"epoch": 1, "training_loss": 13110.997265625, "training_acc": 50.0, "val_loss": 3800.719970703125, "val_acc": 40.0}
{"epoch": 2, "training_loss": 4372.2654296875, "training_acc": 60.0, "val_loss": 8723.0458984375, "val_acc": 60.0}
{"epoch": 3, "training_loss": 8615.018359375, "training_acc": 50.0, "val_loss": 4404.62109375, "val_acc": 40.0}
{"epoch": 4, "training_loss": 5723.781640625, "training_acc": 50.0, "val_loss": 8168.2734375, "val_acc": 40.0}
{"epoch": 5, "training_loss": 3477.704211425781, "training_acc": 60.0, "val_loss": 4672.52685546875, "val_acc": 60.0}
{"epoch": 6, "training_loss": 5929.836328125, "training_acc": 50.0, "val_loss": 729.275390625, "val_acc": 60.0}
{"epoch": 7, "training_loss": 4905.255078125, "training_acc": 40.0, "val_loss": 10374.6318359375, "val_acc": 40.0}
{"epoch": 8, "training_loss": 6613.95068359375, "training_acc": 50.0, "val_loss": 2641.39306640625, "val_acc": 60.0}
{"epoch": 9, "training_loss": 5430.6865234375, "training_acc": 50.0, "val_loss": 4296.12646484375, "val_acc": 60.0}
{"epoch": 10, "training_loss": 3221.68046875, "training_acc": 50.0, "val_loss": 9165.6298828125, "val_acc": 40.0}
{"epoch": 11, "training_loss": 8199.01015625, "training_acc": 50.0, "val_loss": 4555.58447265625, "val_acc": 40.0}
{"epoch": 12, "training_loss": 4605.87314453125, "training_acc": 30.0, "val_loss": 4088.309326171875, "val_acc": 60.0}
{"epoch": 13, "training_loss": 4202.237841796875, "training_acc": 40.0, "val_loss": 3281.454345703125, "val_acc": 40.0}
{"epoch": 14, "training_loss": 2365.4421875, "training_acc": 40.0, "val_loss": 2217.998046875, "val_acc": 60.0}
{"epoch": 15, "training_loss": 2315.08173828125, "training_acc": 40.0, "val_loss": 4114.89208984375, "val_acc": 40.0}
{"epoch": 16, "training_loss": 2424.5564208984374, "training_acc": 50.0, "val_loss": 2094.45947265625, "val_acc": 60.0}
{"epoch": 17, "training_loss": 1798.6073974609376, "training_acc": 50.0, "val_loss": 3097.66259765625, "val_acc": 40.0}
{"epoch": 18, "training_loss": 1483.7963134765625, "training_acc": 60.0, "val_loss": 2031.7711181640625, "val_acc": 60.0}
{"epoch": 19, "training_loss": 2093.73642578125, "training_acc": 40.0, "val_loss": 1543.5081787109375, "val_acc": 40.0}
{"epoch": 20, "training_loss": 984.3673950195313, "training_acc": 50.0, "val_loss": 1248.6322021484375, "val_acc": 40.0}
{"epoch": 21, "training_loss": 775.3440673828125, "training_acc": 60.0, "val_loss": 1587.5965576171875, "val_acc": 60.0}
{"epoch": 22, "training_loss": 1632.3291580200196, "training_acc": 55.0, "val_loss": 3139.196533203125, "val_acc": 40.0}
{"epoch": 23, "training_loss": 2337.209020996094, "training_acc": 50.0, "val_loss": 1463.273681640625, "val_acc": 60.0}
{"epoch": 24, "training_loss": 1183.341607952118, "training_acc": 55.0, "val_loss": 687.2068481445312, "val_acc": 40.0}
{"epoch": 25, "training_loss": 346.495458984375, "training_acc": 50.0, "val_loss": 1420.6072998046875, "val_acc": 60.0}
{"epoch": 26, "training_loss": 1167.5232543945312, "training_acc": 55.0, "val_loss": 1440.1177978515625, "val_acc": 40.0}
{"epoch": 27, "training_loss": 733.7994384765625, "training_acc": 40.0, "val_loss": 561.2584838867188, "val_acc": 60.0}
{"epoch": 28, "training_loss": 544.6349243164062, "training_acc": 40.0, "val_loss": 2824.9345703125, "val_acc": 60.0}
{"epoch": 29, "training_loss": 4220.7421875, "training_acc": 50.0, "val_loss": 1919.815673828125, "val_acc": 60.0}
{"epoch": 30, "training_loss": 3187.05234375, "training_acc": 40.0, "val_loss": 5633.8046875, "val_acc": 40.0}
{"epoch": 31, "training_loss": 2514.9495239257812, "training_acc": 50.0, "val_loss": 4671.7138671875, "val_acc": 60.0}
{"epoch": 32, "training_loss": 8004.670703125, "training_acc": 50.0, "val_loss": 8688.8212890625, "val_acc": 60.0}
{"epoch": 33, "training_loss": 9217.289453125, "training_acc": 50.0, "val_loss": 1012.0291137695312, "val_acc": 40.0}
{"epoch": 34, "training_loss": 1701.804736328125, "training_acc": 50.0, "val_loss": 387.9744567871094, "val_acc": 60.0}
{"epoch": 35, "training_loss": 937.1392532348633, "training_acc": 70.0, "val_loss": 612.039306640625, "val_acc": 60.0}
{"epoch": 36, "training_loss": 587.9952209472656, "training_acc": 80.0, "val_loss": 1949.6619873046875, "val_acc": 40.0}
{"epoch": 37, "training_loss": 1900.383203125, "training_acc": 40.0, "val_loss": 415.02447509765625, "val_acc": 60.0}
{"epoch": 38, "training_loss": 1098.213442993164, "training_acc": 65.0, "val_loss": 565.3665161132812, "val_acc": 40.0}
{"epoch": 39, "training_loss": 2384.196630859375, "training_acc": 50.0, "val_loss": 2782.91796875, "val_acc": 60.0}
{"epoch": 40, "training_loss": 1308.52919921875, "training_acc": 65.0, "val_loss": 3010.799560546875, "val_acc": 40.0}
{"epoch": 41, "training_loss": 1605.970849609375, "training_acc": 50.0, "val_loss": 2293.04931640625, "val_acc": 60.0}
{"epoch": 42, "training_loss": 1757.9199951171875, "training_acc": 50.0, "val_loss": 2734.617919921875, "val_acc": 40.0}
{"epoch": 43, "training_loss": 1594.79169921875, "training_acc": 60.0, "val_loss": 1524.5142822265625, "val_acc": 60.0}
{"epoch": 44, "training_loss": 934.0512451171875, "training_acc": 60.0, "val_loss": 5497.32373046875, "val_acc": 40.0}
{"epoch": 45, "training_loss": 3786.3953125, "training_acc": 50.0, "val_loss": 1308.4832763671875, "val_acc": 60.0}
{"epoch": 46, "training_loss": 1487.6865234375, "training_acc": 55.0, "val_loss": 863.5582275390625, "val_acc": 40.0}
{"epoch": 47, "training_loss": 720.4639404296875, "training_acc": 50.0, "val_loss": 1889.524658203125, "val_acc": 60.0}
{"epoch": 48, "training_loss": 971.3746215820313, "training_acc": 60.0, "val_loss": 4014.476318359375, "val_acc": 40.0}
{"epoch": 49, "training_loss": 2315.435317993164, "training_acc": 55.0, "val_loss": 2377.795654296875, "val_acc": 60.0}
{"epoch": 50, "training_loss": 3559.3727294921873, "training_acc": 50.0, "val_loss": 516.82421875, "val_acc": 60.0}
{"epoch": 51, "training_loss": 915.9627014160156, "training_acc": 70.0, "val_loss": 1829.9146728515625, "val_acc": 40.0}
{"epoch": 52, "training_loss": 844.4641845703125, "training_acc": 50.0, "val_loss": 528.4215698242188, "val_acc": 60.0}
{"epoch": 53, "training_loss": 253.81771545410157, "training_acc": 65.0, "val_loss": 2645.085205078125, "val_acc": 60.0}
