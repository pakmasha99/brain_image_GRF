"main_modify.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 3 --task ADNI_sex --input_option yAware --learning_rate 1e2 --batch_size 8 --weight_decay 1e-8 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 14899.840128040314, "training_acc": 50.0, "val_loss": 3379.423583984375, "val_acc": 60.0}
{"epoch": 1, "training_loss": 6914.608984375, "training_acc": 50.0, "val_loss": 1776.6168212890625, "val_acc": 60.0}
{"epoch": 2, "training_loss": 4518.718994140625, "training_acc": 60.0, "val_loss": 12618.1103515625, "val_acc": 40.0}
{"epoch": 3, "training_loss": 7799.606689453125, "training_acc": 50.0, "val_loss": 4191.1796875, "val_acc": 60.0}
{"epoch": 4, "training_loss": 6810.63447265625, "training_acc": 50.0, "val_loss": 5875.72216796875, "val_acc": 60.0}
{"epoch": 5, "training_loss": 5521.06875, "training_acc": 40.0, "val_loss": 5236.76904296875, "val_acc": 40.0}
{"epoch": 6, "training_loss": 3600.3423828125, "training_acc": 40.0, "val_loss": 249.4480438232422, "val_acc": 60.0}
{"epoch": 7, "training_loss": 1576.3236938476562, "training_acc": 50.0, "val_loss": 149.73313903808594, "val_acc": 40.0}
{"epoch": 8, "training_loss": 3213.824084472656, "training_acc": 45.0, "val_loss": 3739.487060546875, "val_acc": 60.0}
{"epoch": 9, "training_loss": 4218.583349609375, "training_acc": 40.0, "val_loss": 6350.64453125, "val_acc": 40.0}
{"epoch": 10, "training_loss": 4203.82744140625, "training_acc": 50.0, "val_loss": 1837.2288818359375, "val_acc": 60.0}
{"epoch": 11, "training_loss": 2604.371484375, "training_acc": 50.0, "val_loss": 2649.054443359375, "val_acc": 60.0}
{"epoch": 12, "training_loss": 1732.6883544921875, "training_acc": 60.0, "val_loss": 4283.6455078125, "val_acc": 40.0}
{"epoch": 13, "training_loss": 3655.9447998046876, "training_acc": 50.0, "val_loss": 1294.54052734375, "val_acc": 60.0}
{"epoch": 14, "training_loss": 1948.772393798828, "training_acc": 50.0, "val_loss": 1341.1151123046875, "val_acc": 40.0}
{"epoch": 15, "training_loss": 1704.7485107421876, "training_acc": 50.0, "val_loss": 2476.956787109375, "val_acc": 60.0}
{"epoch": 16, "training_loss": 3944.6796875, "training_acc": 50.0, "val_loss": 1870.125, "val_acc": 60.0}
{"epoch": 17, "training_loss": 4701.0236328125, "training_acc": 20.0, "val_loss": 4311.78662109375, "val_acc": 40.0}
{"epoch": 18, "training_loss": 1827.1324951171875, "training_acc": 60.0, "val_loss": 4381.63818359375, "val_acc": 60.0}
{"epoch": 19, "training_loss": 5343.05087890625, "training_acc": 50.0, "val_loss": 1116.3785400390625, "val_acc": 60.0}
{"epoch": 20, "training_loss": 2220.42021484375, "training_acc": 60.0, "val_loss": 6522.3896484375, "val_acc": 40.0}
{"epoch": 21, "training_loss": 3862.5729919433593, "training_acc": 55.0, "val_loss": 1593.4549560546875, "val_acc": 60.0}
{"epoch": 22, "training_loss": 1151.9446166992188, "training_acc": 55.0, "val_loss": 1308.4232177734375, "val_acc": 40.0}
{"epoch": 23, "training_loss": 660.2102935791015, "training_acc": 60.0, "val_loss": 846.5209350585938, "val_acc": 60.0}
{"epoch": 24, "training_loss": 410.174755859375, "training_acc": 65.0, "val_loss": 785.44580078125, "val_acc": 60.0}
{"epoch": 25, "training_loss": 613.9205078125, "training_acc": 60.0, "val_loss": 70.38006591796875, "val_acc": 60.0}
{"epoch": 26, "training_loss": 326.8304779052734, "training_acc": 75.0, "val_loss": 713.35595703125, "val_acc": 40.0}
{"epoch": 27, "training_loss": 677.9354736328125, "training_acc": 40.0, "val_loss": 2821.925048828125, "val_acc": 40.0}
{"epoch": 28, "training_loss": 2270.60146484375, "training_acc": 50.0, "val_loss": 1471.6336669921875, "val_acc": 60.0}
{"epoch": 29, "training_loss": 2759.42216796875, "training_acc": 50.0, "val_loss": 199.05288696289062, "val_acc": 80.0}
{"epoch": 30, "training_loss": 917.0731781005859, "training_acc": 65.0, "val_loss": 89.9083480834961, "val_acc": 40.0}
{"epoch": 31, "training_loss": 763.8955444335937, "training_acc": 75.0, "val_loss": 1290.5064697265625, "val_acc": 60.0}
{"epoch": 32, "training_loss": 531.137419128418, "training_acc": 70.0, "val_loss": 168.9007110595703, "val_acc": 80.0}
{"epoch": 33, "training_loss": 212.829150390625, "training_acc": 70.0, "val_loss": 2618.811279296875, "val_acc": 40.0}
{"epoch": 34, "training_loss": 3192.3759765625, "training_acc": 50.0, "val_loss": 770.2736206054688, "val_acc": 60.0}
{"epoch": 35, "training_loss": 1135.7213623046875, "training_acc": 35.0, "val_loss": 208.21047973632812, "val_acc": 60.0}
{"epoch": 36, "training_loss": 488.6988250732422, "training_acc": 80.0, "val_loss": 1874.4676513671875, "val_acc": 60.0}
{"epoch": 37, "training_loss": 1497.157568359375, "training_acc": 40.0, "val_loss": 1400.0458984375, "val_acc": 60.0}
{"epoch": 38, "training_loss": 1770.08349609375, "training_acc": 50.0, "val_loss": 3000.240966796875, "val_acc": 40.0}
{"epoch": 39, "training_loss": 2521.2705688476562, "training_acc": 50.0, "val_loss": 379.0391540527344, "val_acc": 60.0}
{"epoch": 40, "training_loss": 297.6385559082031, "training_acc": 50.0, "val_loss": 413.8499450683594, "val_acc": 60.0}
{"epoch": 41, "training_loss": 595.9034210205078, "training_acc": 65.0, "val_loss": 1903.130859375, "val_acc": 40.0}
{"epoch": 42, "training_loss": 1524.3997314453125, "training_acc": 30.0, "val_loss": 1074.7679443359375, "val_acc": 40.0}
{"epoch": 43, "training_loss": 1354.3546630859375, "training_acc": 40.0, "val_loss": 1075.1661376953125, "val_acc": 60.0}
{"epoch": 44, "training_loss": 589.5215454101562, "training_acc": 60.0, "val_loss": 372.7104187011719, "val_acc": 60.0}
