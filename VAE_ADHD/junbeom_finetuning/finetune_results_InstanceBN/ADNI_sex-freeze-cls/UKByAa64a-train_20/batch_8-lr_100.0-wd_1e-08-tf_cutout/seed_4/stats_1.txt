"main_modify.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 4 --task ADNI_sex --input_option yAware --learning_rate 1e2 --batch_size 8 --weight_decay 1e-8 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 11305.184143400193, "training_acc": 50.0, "val_loss": 11543.7001953125, "val_acc": 40.0}
{"epoch": 1, "training_loss": 8947.317822265624, "training_acc": 50.0, "val_loss": 1385.1068115234375, "val_acc": 60.0}
{"epoch": 2, "training_loss": 1848.8197509765625, "training_acc": 30.0, "val_loss": 2814.80419921875, "val_acc": 60.0}
{"epoch": 3, "training_loss": 2083.3631103515627, "training_acc": 60.0, "val_loss": 5878.98193359375, "val_acc": 40.0}
{"epoch": 4, "training_loss": 3439.623779296875, "training_acc": 50.0, "val_loss": 4252.40478515625, "val_acc": 60.0}
{"epoch": 5, "training_loss": 8138.525, "training_acc": 50.0, "val_loss": 5486.90576171875, "val_acc": 60.0}
{"epoch": 6, "training_loss": 4138.08017578125, "training_acc": 50.0, "val_loss": 9650.9677734375, "val_acc": 40.0}
{"epoch": 7, "training_loss": 9555.83935546875, "training_acc": 50.0, "val_loss": 6444.20458984375, "val_acc": 40.0}
{"epoch": 8, "training_loss": 3830.355126953125, "training_acc": 40.0, "val_loss": 3366.591064453125, "val_acc": 60.0}
{"epoch": 9, "training_loss": 4084.734375, "training_acc": 30.0, "val_loss": 2884.05419921875, "val_acc": 40.0}
{"epoch": 10, "training_loss": 1295.1136962890625, "training_acc": 60.0, "val_loss": 3591.669677734375, "val_acc": 60.0}
{"epoch": 11, "training_loss": 3913.14677734375, "training_acc": 50.0, "val_loss": 1966.7855224609375, "val_acc": 40.0}
{"epoch": 12, "training_loss": 3149.961572265625, "training_acc": 50.0, "val_loss": 3178.218505859375, "val_acc": 40.0}
{"epoch": 13, "training_loss": 1036.5631408691406, "training_acc": 60.0, "val_loss": 6258.76904296875, "val_acc": 60.0}
{"epoch": 14, "training_loss": 7494.013916015625, "training_acc": 50.0, "val_loss": 2930.459716796875, "val_acc": 60.0}
{"epoch": 15, "training_loss": 3420.81513671875, "training_acc": 30.0, "val_loss": 2583.473876953125, "val_acc": 40.0}
{"epoch": 16, "training_loss": 1883.568798828125, "training_acc": 45.0, "val_loss": 3822.65234375, "val_acc": 60.0}
{"epoch": 17, "training_loss": 3458.5889526367187, "training_acc": 50.0, "val_loss": 4603.486328125, "val_acc": 40.0}
{"epoch": 18, "training_loss": 5095.226806640625, "training_acc": 50.0, "val_loss": 5107.19384765625, "val_acc": 40.0}
{"epoch": 19, "training_loss": 2657.515234375, "training_acc": 50.0, "val_loss": 4466.22705078125, "val_acc": 60.0}
{"epoch": 20, "training_loss": 6017.5046875, "training_acc": 50.0, "val_loss": 851.9135131835938, "val_acc": 60.0}
{"epoch": 21, "training_loss": 2281.740087890625, "training_acc": 60.0, "val_loss": 4952.36279296875, "val_acc": 40.0}
{"epoch": 22, "training_loss": 2734.42197265625, "training_acc": 50.0, "val_loss": 3815.322265625, "val_acc": 60.0}
{"epoch": 23, "training_loss": 4180.84814453125, "training_acc": 50.0, "val_loss": 1584.2117919921875, "val_acc": 40.0}
{"epoch": 24, "training_loss": 2173.101416015625, "training_acc": 50.0, "val_loss": 128.23069763183594, "val_acc": 60.0}
{"epoch": 25, "training_loss": 330.85357971191405, "training_acc": 55.0, "val_loss": 2893.419921875, "val_acc": 40.0}
{"epoch": 26, "training_loss": 2069.0817138671873, "training_acc": 50.0, "val_loss": 1912.6488037109375, "val_acc": 60.0}
{"epoch": 27, "training_loss": 2461.763330078125, "training_acc": 50.0, "val_loss": 900.8571166992188, "val_acc": 40.0}
{"epoch": 28, "training_loss": 515.5705383300781, "training_acc": 60.0, "val_loss": 821.7271728515625, "val_acc": 60.0}
{"epoch": 29, "training_loss": 652.7333251953125, "training_acc": 50.0, "val_loss": 1516.1287841796875, "val_acc": 60.0}
{"epoch": 30, "training_loss": 1735.589990234375, "training_acc": 40.0, "val_loss": 336.33251953125, "val_acc": 40.0}
{"epoch": 31, "training_loss": 1067.0072631835938, "training_acc": 60.0, "val_loss": 809.826904296875, "val_acc": 60.0}
{"epoch": 32, "training_loss": 1910.615234375, "training_acc": 50.0, "val_loss": 2463.60205078125, "val_acc": 40.0}
{"epoch": 33, "training_loss": 729.5084075927734, "training_acc": 60.0, "val_loss": 106.88314056396484, "val_acc": 40.0}
{"epoch": 34, "training_loss": 396.4099822998047, "training_acc": 50.0, "val_loss": 885.1740112304688, "val_acc": 60.0}
{"epoch": 35, "training_loss": 760.2711242675781, "training_acc": 40.0, "val_loss": 672.7869873046875, "val_acc": 40.0}
{"epoch": 36, "training_loss": 480.8434265136719, "training_acc": 50.0, "val_loss": 89.8542251586914, "val_acc": 40.0}
{"epoch": 37, "training_loss": 1947.5598999023437, "training_acc": 40.0, "val_loss": 239.7484893798828, "val_acc": 40.0}
{"epoch": 38, "training_loss": 309.8535888671875, "training_acc": 55.0, "val_loss": 0.0, "val_acc": 100.0}
{"epoch": 39, "training_loss": 168.2466247558594, "training_acc": 80.0, "val_loss": 1538.1893310546875, "val_acc": 60.0}
{"epoch": 40, "training_loss": 2011.7943134307861, "training_acc": 50.0, "val_loss": 3686.882568359375, "val_acc": 40.0}
{"epoch": 41, "training_loss": 3351.7876953125, "training_acc": 50.0, "val_loss": 158.6035614013672, "val_acc": 60.0}
{"epoch": 42, "training_loss": 468.50705871582034, "training_acc": 40.0, "val_loss": 1150.9339599609375, "val_acc": 60.0}
{"epoch": 43, "training_loss": 1123.02734375, "training_acc": 50.0, "val_loss": 1959.4381103515625, "val_acc": 40.0}
{"epoch": 44, "training_loss": 523.147216796875, "training_acc": 70.0, "val_loss": 3703.122802734375, "val_acc": 60.0}
{"epoch": 45, "training_loss": 4368.4818359375, "training_acc": 50.0, "val_loss": 269.8476257324219, "val_acc": 40.0}
{"epoch": 46, "training_loss": 655.7833831787109, "training_acc": 55.0, "val_loss": 969.3025512695312, "val_acc": 60.0}
{"epoch": 47, "training_loss": 1648.4059753417969, "training_acc": 50.0, "val_loss": 3942.468505859375, "val_acc": 40.0}
{"epoch": 48, "training_loss": 3546.578515625, "training_acc": 50.0, "val_loss": 1017.7379760742188, "val_acc": 40.0}
{"epoch": 49, "training_loss": 3043.7072265625, "training_acc": 50.0, "val_loss": 3992.864013671875, "val_acc": 60.0}
{"epoch": 50, "training_loss": 4976.515478515625, "training_acc": 30.0, "val_loss": 5857.98388671875, "val_acc": 40.0}
{"epoch": 51, "training_loss": 3639.343475341797, "training_acc": 40.0, "val_loss": 347.1638488769531, "val_acc": 60.0}
{"epoch": 52, "training_loss": 1301.8073974609374, "training_acc": 40.0, "val_loss": 754.1757202148438, "val_acc": 60.0}
{"epoch": 53, "training_loss": 1437.5508056640624, "training_acc": 50.0, "val_loss": 3085.78369140625, "val_acc": 40.0}
{"epoch": 54, "training_loss": 3189.3231689453123, "training_acc": 50.0, "val_loss": 2182.001220703125, "val_acc": 40.0}
{"epoch": 55, "training_loss": 1466.3156127929688, "training_acc": 50.0, "val_loss": 1166.8316650390625, "val_acc": 60.0}
{"epoch": 56, "training_loss": 605.1460205078125, "training_acc": 60.0, "val_loss": 865.9142456054688, "val_acc": 60.0}
{"epoch": 57, "training_loss": 658.3288070678711, "training_acc": 60.0, "val_loss": 56.4295539855957, "val_acc": 60.0}
