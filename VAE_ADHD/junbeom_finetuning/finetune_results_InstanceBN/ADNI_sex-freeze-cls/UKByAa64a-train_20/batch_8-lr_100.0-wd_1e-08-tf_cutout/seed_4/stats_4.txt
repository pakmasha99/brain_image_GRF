"main_modify.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 4 --task ADNI_sex --input_option yAware --learning_rate 1e2 --batch_size 8 --weight_decay 1e-8 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 8261.416848301888, "training_acc": 55.0, "val_loss": 5841.27685546875, "val_acc": 60.0}
{"epoch": 1, "training_loss": 7085.988494873047, "training_acc": 45.0, "val_loss": 8006.36572265625, "val_acc": 40.0}
{"epoch": 2, "training_loss": 6399.75751953125, "training_acc": 55.0, "val_loss": 1307.1434326171875, "val_acc": 40.0}
{"epoch": 3, "training_loss": 8127.45703125, "training_acc": 35.0, "val_loss": 7273.54638671875, "val_acc": 60.0}
{"epoch": 4, "training_loss": 7208.480419921875, "training_acc": 45.0, "val_loss": 8959.955078125, "val_acc": 40.0}
{"epoch": 5, "training_loss": 7484.21953125, "training_acc": 55.0, "val_loss": 5602.29638671875, "val_acc": 40.0}
{"epoch": 6, "training_loss": 1859.457421875, "training_acc": 55.0, "val_loss": 2146.656982421875, "val_acc": 60.0}
{"epoch": 7, "training_loss": 2815.3603393554686, "training_acc": 35.0, "val_loss": 6577.64306640625, "val_acc": 40.0}
{"epoch": 8, "training_loss": 3879.813037109375, "training_acc": 55.0, "val_loss": 1855.9984130859375, "val_acc": 60.0}
{"epoch": 9, "training_loss": 4148.6884765625, "training_acc": 45.0, "val_loss": 1598.4564208984375, "val_acc": 60.0}
{"epoch": 10, "training_loss": 4552.3953125, "training_acc": 35.0, "val_loss": 5989.8330078125, "val_acc": 40.0}
{"epoch": 11, "training_loss": 3817.63154296875, "training_acc": 45.0, "val_loss": 3354.78759765625, "val_acc": 60.0}
{"epoch": 12, "training_loss": 3642.906457519531, "training_acc": 45.0, "val_loss": 4822.42236328125, "val_acc": 40.0}
{"epoch": 13, "training_loss": 5128.4322265625, "training_acc": 55.0, "val_loss": 6984.0908203125, "val_acc": 40.0}
{"epoch": 14, "training_loss": 3774.91953125, "training_acc": 45.0, "val_loss": 3190.370849609375, "val_acc": 60.0}
{"epoch": 15, "training_loss": 3312.1073364257813, "training_acc": 45.0, "val_loss": 4322.67724609375, "val_acc": 40.0}
{"epoch": 16, "training_loss": 5246.16220703125, "training_acc": 55.0, "val_loss": 6022.6064453125, "val_acc": 40.0}
{"epoch": 17, "training_loss": 2798.906103515625, "training_acc": 55.0, "val_loss": 3749.925537109375, "val_acc": 60.0}
{"epoch": 18, "training_loss": 4696.82998046875, "training_acc": 45.0, "val_loss": 1802.8304443359375, "val_acc": 40.0}
{"epoch": 19, "training_loss": 1741.0619873046876, "training_acc": 55.0, "val_loss": 1295.6353759765625, "val_acc": 40.0}
{"epoch": 20, "training_loss": 2879.061181640625, "training_acc": 35.0, "val_loss": 853.1596069335938, "val_acc": 60.0}
{"epoch": 21, "training_loss": 3115.47939453125, "training_acc": 45.0, "val_loss": 7483.97998046875, "val_acc": 40.0}
{"epoch": 22, "training_loss": 4127.462622070312, "training_acc": 55.0, "val_loss": 2313.033935546875, "val_acc": 60.0}
{"epoch": 23, "training_loss": 4071.2970703125, "training_acc": 45.0, "val_loss": 1608.01806640625, "val_acc": 60.0}
{"epoch": 24, "training_loss": 2505.439697265625, "training_acc": 45.0, "val_loss": 5218.63525390625, "val_acc": 40.0}
{"epoch": 25, "training_loss": 3541.23681640625, "training_acc": 35.0, "val_loss": 591.499267578125, "val_acc": 60.0}
{"epoch": 26, "training_loss": 619.501318359375, "training_acc": 65.0, "val_loss": 714.0009765625, "val_acc": 40.0}
{"epoch": 27, "training_loss": 956.873095703125, "training_acc": 55.0, "val_loss": 608.7779541015625, "val_acc": 40.0}
{"epoch": 28, "training_loss": 330.6307006835938, "training_acc": 70.0, "val_loss": 1041.98046875, "val_acc": 60.0}
{"epoch": 29, "training_loss": 648.09423828125, "training_acc": 60.0, "val_loss": 44.78924560546875, "val_acc": 60.0}
{"epoch": 30, "training_loss": 769.6998672485352, "training_acc": 40.0, "val_loss": 1113.2320556640625, "val_acc": 40.0}
{"epoch": 31, "training_loss": 1476.81318359375, "training_acc": 35.0, "val_loss": 1286.212158203125, "val_acc": 60.0}
{"epoch": 32, "training_loss": 1406.39248046875, "training_acc": 55.0, "val_loss": 1931.60546875, "val_acc": 40.0}
{"epoch": 33, "training_loss": 2254.40380859375, "training_acc": 35.0, "val_loss": 613.2164916992188, "val_acc": 40.0}
{"epoch": 34, "training_loss": 1644.296124267578, "training_acc": 55.0, "val_loss": 972.0244140625, "val_acc": 60.0}
{"epoch": 35, "training_loss": 1477.6740234375, "training_acc": 35.0, "val_loss": 51.412818908691406, "val_acc": 40.0}
{"epoch": 36, "training_loss": 64.7513198852539, "training_acc": 80.0, "val_loss": 1728.167236328125, "val_acc": 60.0}
{"epoch": 37, "training_loss": 1787.9563514709473, "training_acc": 50.0, "val_loss": 3157.913330078125, "val_acc": 40.0}
{"epoch": 38, "training_loss": 2390.0996948242187, "training_acc": 55.0, "val_loss": 286.2728576660156, "val_acc": 60.0}
{"epoch": 39, "training_loss": 131.52640380859376, "training_acc": 65.0, "val_loss": 955.0090942382812, "val_acc": 60.0}
{"epoch": 40, "training_loss": 951.7894409179687, "training_acc": 55.0, "val_loss": 2850.3798828125, "val_acc": 40.0}
{"epoch": 41, "training_loss": 1452.70712890625, "training_acc": 55.0, "val_loss": 864.5780639648438, "val_acc": 60.0}
{"epoch": 42, "training_loss": 1609.21787109375, "training_acc": 45.0, "val_loss": 204.757568359375, "val_acc": 60.0}
{"epoch": 43, "training_loss": 579.4495300292969, "training_acc": 50.0, "val_loss": 4012.292724609375, "val_acc": 40.0}
{"epoch": 44, "training_loss": 3281.082177734375, "training_acc": 55.0, "val_loss": 2680.388427734375, "val_acc": 40.0}
{"epoch": 45, "training_loss": 2479.80859375, "training_acc": 45.0, "val_loss": 944.7605590820312, "val_acc": 60.0}
{"epoch": 46, "training_loss": 3034.39306640625, "training_acc": 45.0, "val_loss": 5811.4736328125, "val_acc": 40.0}
{"epoch": 47, "training_loss": 2760.48447265625, "training_acc": 55.0, "val_loss": 2177.345458984375, "val_acc": 60.0}
{"epoch": 48, "training_loss": 2149.5283203125, "training_acc": 45.0, "val_loss": 2800.493896484375, "val_acc": 40.0}
