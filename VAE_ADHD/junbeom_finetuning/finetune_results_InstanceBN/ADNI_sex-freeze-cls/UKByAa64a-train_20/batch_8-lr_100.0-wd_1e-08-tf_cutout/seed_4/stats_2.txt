"main_modify.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 4 --task ADNI_sex --input_option yAware --learning_rate 1e2 --batch_size 8 --weight_decay 1e-8 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 11360.146130752564, "training_acc": 50.0, "val_loss": 10999.4912109375, "val_acc": 40.0}
{"epoch": 1, "training_loss": 10196.3935546875, "training_acc": 50.0, "val_loss": 1141.1942138671875, "val_acc": 40.0}
{"epoch": 2, "training_loss": 6957.420336914062, "training_acc": 50.0, "val_loss": 13142.041015625, "val_acc": 60.0}
{"epoch": 3, "training_loss": 14246.6201171875, "training_acc": 50.0, "val_loss": 1886.75390625, "val_acc": 60.0}
{"epoch": 4, "training_loss": 3692.675, "training_acc": 70.0, "val_loss": 15064.3876953125, "val_acc": 40.0}
{"epoch": 5, "training_loss": 10887.8533203125, "training_acc": 50.0, "val_loss": 1959.1239013671875, "val_acc": 40.0}
{"epoch": 6, "training_loss": 5625.819775390625, "training_acc": 50.0, "val_loss": 10721.5048828125, "val_acc": 60.0}
{"epoch": 7, "training_loss": 12936.2646484375, "training_acc": 50.0, "val_loss": 4338.04736328125, "val_acc": 60.0}
{"epoch": 8, "training_loss": 5892.12578125, "training_acc": 40.0, "val_loss": 9939.0615234375, "val_acc": 40.0}
{"epoch": 9, "training_loss": 6799.82939453125, "training_acc": 50.0, "val_loss": 1279.734619140625, "val_acc": 60.0}
{"epoch": 10, "training_loss": 3688.6681640625, "training_acc": 50.0, "val_loss": 2075.990966796875, "val_acc": 60.0}
{"epoch": 11, "training_loss": 2482.73017578125, "training_acc": 50.0, "val_loss": 2497.564208984375, "val_acc": 40.0}
{"epoch": 12, "training_loss": 3333.5056640625, "training_acc": 30.0, "val_loss": 1285.0283203125, "val_acc": 60.0}
{"epoch": 13, "training_loss": 1356.532861328125, "training_acc": 60.0, "val_loss": 2745.25830078125, "val_acc": 40.0}
{"epoch": 14, "training_loss": 1356.6558471679687, "training_acc": 40.0, "val_loss": 2066.246826171875, "val_acc": 40.0}
{"epoch": 15, "training_loss": 1351.1287109375, "training_acc": 50.0, "val_loss": 689.83935546875, "val_acc": 60.0}
{"epoch": 16, "training_loss": 558.7017074584961, "training_acc": 60.0, "val_loss": 1029.457763671875, "val_acc": 60.0}
{"epoch": 17, "training_loss": 1083.0906372070312, "training_acc": 50.0, "val_loss": 2860.124267578125, "val_acc": 40.0}
{"epoch": 18, "training_loss": 1791.3747192382812, "training_acc": 30.0, "val_loss": 3367.043701171875, "val_acc": 40.0}
{"epoch": 19, "training_loss": 2762.300671386719, "training_acc": 50.0, "val_loss": 238.62271118164062, "val_acc": 60.0}
{"epoch": 20, "training_loss": 286.2590087890625, "training_acc": 50.0, "val_loss": 1234.5992431640625, "val_acc": 60.0}
{"epoch": 21, "training_loss": 741.0148986816406, "training_acc": 60.0, "val_loss": 5424.34912109375, "val_acc": 40.0}
{"epoch": 22, "training_loss": 4267.9341796875, "training_acc": 50.0, "val_loss": 1560.7537841796875, "val_acc": 60.0}
{"epoch": 23, "training_loss": 2841.887158203125, "training_acc": 50.0, "val_loss": 69.23778533935547, "val_acc": 40.0}
{"epoch": 24, "training_loss": 770.6079986572265, "training_acc": 65.0, "val_loss": 503.07177734375, "val_acc": 60.0}
{"epoch": 25, "training_loss": 242.02194381952262, "training_acc": 70.0, "val_loss": 120.00701904296875, "val_acc": 60.0}
{"epoch": 26, "training_loss": 830.1812896728516, "training_acc": 40.0, "val_loss": 939.2394409179688, "val_acc": 60.0}
{"epoch": 27, "training_loss": 926.6768798828125, "training_acc": 60.0, "val_loss": 2078.529052734375, "val_acc": 40.0}
{"epoch": 28, "training_loss": 1700.1154235839845, "training_acc": 20.0, "val_loss": 562.3741455078125, "val_acc": 60.0}
{"epoch": 29, "training_loss": 643.5236465454102, "training_acc": 45.0, "val_loss": 1611.4393310546875, "val_acc": 60.0}
{"epoch": 30, "training_loss": 1548.57216796875, "training_acc": 60.0, "val_loss": 2566.250244140625, "val_acc": 40.0}
{"epoch": 31, "training_loss": 1864.2391357421875, "training_acc": 40.0, "val_loss": 316.37994384765625, "val_acc": 60.0}
{"epoch": 32, "training_loss": 2217.4314453125, "training_acc": 35.0, "val_loss": 395.8863220214844, "val_acc": 40.0}
{"epoch": 33, "training_loss": 1830.3517822265626, "training_acc": 60.0, "val_loss": 3346.446044921875, "val_acc": 60.0}
{"epoch": 34, "training_loss": 2519.372412109375, "training_acc": 50.0, "val_loss": 4292.60546875, "val_acc": 40.0}
{"epoch": 35, "training_loss": 2742.0944580078126, "training_acc": 50.0, "val_loss": 2716.65576171875, "val_acc": 60.0}
{"epoch": 36, "training_loss": 3937.7486328125, "training_acc": 50.0, "val_loss": 1493.775146484375, "val_acc": 60.0}
{"epoch": 37, "training_loss": 2197.8021240234375, "training_acc": 50.0, "val_loss": 4761.19189453125, "val_acc": 40.0}
{"epoch": 38, "training_loss": 2650.31728515625, "training_acc": 50.0, "val_loss": 2218.68115234375, "val_acc": 60.0}
{"epoch": 39, "training_loss": 1824.987158203125, "training_acc": 50.0, "val_loss": 2138.445556640625, "val_acc": 40.0}
{"epoch": 40, "training_loss": 1176.2298278808594, "training_acc": 55.0, "val_loss": 2736.688720703125, "val_acc": 60.0}
{"epoch": 41, "training_loss": 1946.423193359375, "training_acc": 65.0, "val_loss": 3070.835693359375, "val_acc": 40.0}
{"epoch": 42, "training_loss": 2184.02802734375, "training_acc": 55.0, "val_loss": 1400.341796875, "val_acc": 60.0}
