"main_modify.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 4 --task ADNI_sex --input_option yAware --learning_rate 1e2 --batch_size 8 --weight_decay 1e-8 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 14905.595184326172, "training_acc": 50.0, "val_loss": 4977.96240234375, "val_acc": 40.0}
{"epoch": 1, "training_loss": 8334.452783203125, "training_acc": 50.0, "val_loss": 4112.14599609375, "val_acc": 40.0}
{"epoch": 2, "training_loss": 2879.9486328125, "training_acc": 60.0, "val_loss": 4015.34423828125, "val_acc": 60.0}
{"epoch": 3, "training_loss": 4967.959060668945, "training_acc": 40.0, "val_loss": 9365.3701171875, "val_acc": 40.0}
{"epoch": 4, "training_loss": 6804.4419921875, "training_acc": 50.0, "val_loss": 3039.950927734375, "val_acc": 60.0}
{"epoch": 5, "training_loss": 5176.681787109375, "training_acc": 50.0, "val_loss": 1443.573486328125, "val_acc": 60.0}
{"epoch": 6, "training_loss": 4854.15712890625, "training_acc": 30.0, "val_loss": 5885.5, "val_acc": 40.0}
{"epoch": 7, "training_loss": 3010.3069580078127, "training_acc": 60.0, "val_loss": 5193.84716796875, "val_acc": 60.0}
{"epoch": 8, "training_loss": 6181.049609375, "training_acc": 50.0, "val_loss": 1176.4852294921875, "val_acc": 60.0}
{"epoch": 9, "training_loss": 2636.7923828125, "training_acc": 60.0, "val_loss": 5961.306640625, "val_acc": 40.0}
{"epoch": 10, "training_loss": 3295.61826171875, "training_acc": 50.0, "val_loss": 3437.109130859375, "val_acc": 60.0}
{"epoch": 11, "training_loss": 3414.720654296875, "training_acc": 50.0, "val_loss": 3183.153076171875, "val_acc": 40.0}
{"epoch": 12, "training_loss": 3455.8087890625, "training_acc": 50.0, "val_loss": 2656.712890625, "val_acc": 40.0}
{"epoch": 13, "training_loss": 1326.3226806640625, "training_acc": 60.0, "val_loss": 1742.1776123046875, "val_acc": 60.0}
{"epoch": 14, "training_loss": 998.057260131836, "training_acc": 60.0, "val_loss": 246.07046508789062, "val_acc": 60.0}
{"epoch": 15, "training_loss": 247.0543212890625, "training_acc": 60.0, "val_loss": 123.92572021484375, "val_acc": 40.0}
{"epoch": 16, "training_loss": 27.525771737098687, "training_acc": 85.0, "val_loss": 1021.0919189453125, "val_acc": 40.0}
{"epoch": 17, "training_loss": 1518.084228515625, "training_acc": 30.0, "val_loss": 3338.452392578125, "val_acc": 40.0}
{"epoch": 18, "training_loss": 3629.3864501953126, "training_acc": 50.0, "val_loss": 1705.129150390625, "val_acc": 40.0}
{"epoch": 19, "training_loss": 1918.0337890625, "training_acc": 60.0, "val_loss": 2142.556396484375, "val_acc": 60.0}
{"epoch": 20, "training_loss": 849.2664398193359, "training_acc": 60.0, "val_loss": 158.55300903320312, "val_acc": 40.0}
{"epoch": 21, "training_loss": 313.78494720458986, "training_acc": 60.0, "val_loss": 609.2628784179688, "val_acc": 40.0}
{"epoch": 22, "training_loss": 1061.423388671875, "training_acc": 60.0, "val_loss": 474.6529235839844, "val_acc": 60.0}
{"epoch": 23, "training_loss": 2201.7215087890627, "training_acc": 50.0, "val_loss": 3901.450927734375, "val_acc": 40.0}
{"epoch": 24, "training_loss": 2001.6770935058594, "training_acc": 40.0, "val_loss": 821.3064575195312, "val_acc": 40.0}
{"epoch": 25, "training_loss": 362.3944438934326, "training_acc": 45.0, "val_loss": 2877.751708984375, "val_acc": 60.0}
{"epoch": 26, "training_loss": 3782.8185546875, "training_acc": 50.0, "val_loss": 851.4013671875, "val_acc": 60.0}
{"epoch": 27, "training_loss": 1989.5762451171875, "training_acc": 50.0, "val_loss": 3072.21484375, "val_acc": 40.0}
{"epoch": 28, "training_loss": 1250.867120361328, "training_acc": 50.0, "val_loss": 394.7630310058594, "val_acc": 40.0}
{"epoch": 29, "training_loss": 259.20647583007815, "training_acc": 55.0, "val_loss": 1381.1903076171875, "val_acc": 40.0}
{"epoch": 30, "training_loss": 1370.8253662109375, "training_acc": 40.0, "val_loss": 1975.315673828125, "val_acc": 40.0}
{"epoch": 31, "training_loss": 1437.8465576171875, "training_acc": 50.0, "val_loss": 768.7474975585938, "val_acc": 60.0}
{"epoch": 32, "training_loss": 776.2674835205078, "training_acc": 45.0, "val_loss": 1343.9879150390625, "val_acc": 60.0}
{"epoch": 33, "training_loss": 951.702685546875, "training_acc": 65.0, "val_loss": 2581.947509765625, "val_acc": 40.0}
{"epoch": 34, "training_loss": 1585.47607421875, "training_acc": 50.0, "val_loss": 809.1304931640625, "val_acc": 60.0}
