"main_modify.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 1 --task ADNI_sex --input_option yAware --learning_rate 1e2 --batch_size 8 --weight_decay 1e-8 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 14560.319073987008, "training_acc": 30.0, "val_loss": 1157.8875732421875, "val_acc": 60.0}
{"epoch": 1, "training_loss": 4362.483447265625, "training_acc": 50.0, "val_loss": 821.1984252929688, "val_acc": 60.0}
{"epoch": 2, "training_loss": 6348.9921875, "training_acc": 50.0, "val_loss": 11025.314453125, "val_acc": 40.0}
{"epoch": 3, "training_loss": 4867.661608886719, "training_acc": 60.0, "val_loss": 4679.36669921875, "val_acc": 60.0}
{"epoch": 4, "training_loss": 5723.7806640625, "training_acc": 50.0, "val_loss": 500.7290954589844, "val_acc": 60.0}
{"epoch": 5, "training_loss": 2887.10009765625, "training_acc": 50.0, "val_loss": 5550.60888671875, "val_acc": 40.0}
{"epoch": 6, "training_loss": 3757.993505859375, "training_acc": 40.0, "val_loss": 4532.58154296875, "val_acc": 60.0}
{"epoch": 7, "training_loss": 4622.30464477539, "training_acc": 50.0, "val_loss": 3613.51806640625, "val_acc": 40.0}
{"epoch": 8, "training_loss": 3314.0974609375, "training_acc": 50.0, "val_loss": 601.3610229492188, "val_acc": 40.0}
{"epoch": 9, "training_loss": 2956.0232421875, "training_acc": 50.0, "val_loss": 4615.0126953125, "val_acc": 60.0}
{"epoch": 10, "training_loss": 4476.83359375, "training_acc": 40.0, "val_loss": 3310.176513671875, "val_acc": 40.0}
{"epoch": 11, "training_loss": 2271.2631103515623, "training_acc": 50.0, "val_loss": 3784.012451171875, "val_acc": 60.0}
{"epoch": 12, "training_loss": 7014.5546875, "training_acc": 50.0, "val_loss": 5567.91259765625, "val_acc": 60.0}
{"epoch": 13, "training_loss": 4734.7979736328125, "training_acc": 50.0, "val_loss": 5246.44677734375, "val_acc": 40.0}
{"epoch": 14, "training_loss": 3658.190478515625, "training_acc": 50.0, "val_loss": 1119.99609375, "val_acc": 60.0}
{"epoch": 15, "training_loss": 1465.7754760742187, "training_acc": 50.0, "val_loss": 1947.1763916015625, "val_acc": 40.0}
{"epoch": 16, "training_loss": 1961.7013671875, "training_acc": 30.0, "val_loss": 221.0314483642578, "val_acc": 60.0}
{"epoch": 17, "training_loss": 1777.1687438964843, "training_acc": 50.0, "val_loss": 517.0405883789062, "val_acc": 40.0}
{"epoch": 18, "training_loss": 2591.633154296875, "training_acc": 50.0, "val_loss": 4087.462890625, "val_acc": 60.0}
{"epoch": 19, "training_loss": 2517.7331298828126, "training_acc": 50.0, "val_loss": 7383.27880859375, "val_acc": 40.0}
{"epoch": 20, "training_loss": 7906.14248046875, "training_acc": 50.0, "val_loss": 13163.6630859375, "val_acc": 40.0}
{"epoch": 21, "training_loss": 9181.744140625, "training_acc": 50.0, "val_loss": 1062.7215576171875, "val_acc": 40.0}
{"epoch": 22, "training_loss": 4367.166479492187, "training_acc": 50.0, "val_loss": 9056.0927734375, "val_acc": 60.0}
{"epoch": 23, "training_loss": 10700.012109375, "training_acc": 50.0, "val_loss": 3352.544677734375, "val_acc": 60.0}
{"epoch": 24, "training_loss": 2565.89462890625, "training_acc": 40.0, "val_loss": 3568.765380859375, "val_acc": 40.0}
{"epoch": 25, "training_loss": 2318.449267578125, "training_acc": 40.0, "val_loss": 1750.16015625, "val_acc": 60.0}
{"epoch": 26, "training_loss": 1476.745654296875, "training_acc": 50.0, "val_loss": 3735.00830078125, "val_acc": 40.0}
{"epoch": 27, "training_loss": 2098.689498901367, "training_acc": 55.0, "val_loss": 1409.491455078125, "val_acc": 60.0}
{"epoch": 28, "training_loss": 963.6356628417968, "training_acc": 60.0, "val_loss": 2009.0457763671875, "val_acc": 40.0}
{"epoch": 29, "training_loss": 881.4950439453125, "training_acc": 60.0, "val_loss": 2619.51416015625, "val_acc": 60.0}
{"epoch": 30, "training_loss": 2343.78525390625, "training_acc": 50.0, "val_loss": 4515.97314453125, "val_acc": 40.0}
{"epoch": 31, "training_loss": 4585.9892578125, "training_acc": 50.0, "val_loss": 4979.62109375, "val_acc": 40.0}
{"epoch": 32, "training_loss": 2384.1123046875, "training_acc": 50.0, "val_loss": 5439.3447265625, "val_acc": 60.0}
{"epoch": 33, "training_loss": 6291.8287109375, "training_acc": 50.0, "val_loss": 1549.0628662109375, "val_acc": 60.0}
{"epoch": 34, "training_loss": 1058.537841796875, "training_acc": 70.0, "val_loss": 6038.80810546875, "val_acc": 40.0}
{"epoch": 35, "training_loss": 3825.101025390625, "training_acc": 50.0, "val_loss": 2012.2991943359375, "val_acc": 60.0}
