"main_modify.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_sex --input_option yAware --learning_rate 5e0 --batch_size 8 --weight_decay 5e-3 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 563.9217458724976, "training_acc": 45.0, "val_loss": 301.28472900390625, "val_acc": 60.0}
{"epoch": 1, "training_loss": 550.6878234863282, "training_acc": 50.0, "val_loss": 327.1371154785156, "val_acc": 60.0}
{"epoch": 2, "training_loss": 299.1261642456055, "training_acc": 50.0, "val_loss": 787.8995971679688, "val_acc": 40.0}
{"epoch": 3, "training_loss": 608.4813293457031, "training_acc": 50.0, "val_loss": 267.6185607910156, "val_acc": 40.0}
{"epoch": 4, "training_loss": 276.53697509765624, "training_acc": 40.0, "val_loss": 338.7021484375, "val_acc": 60.0}
{"epoch": 5, "training_loss": 328.39720458984374, "training_acc": 50.0, "val_loss": 140.9803924560547, "val_acc": 40.0}
{"epoch": 6, "training_loss": 184.4332077026367, "training_acc": 50.0, "val_loss": 251.8277130126953, "val_acc": 40.0}
{"epoch": 7, "training_loss": 202.09369316101075, "training_acc": 40.0, "val_loss": 253.9007568359375, "val_acc": 60.0}
{"epoch": 8, "training_loss": 257.80511779785155, "training_acc": 50.0, "val_loss": 122.81011199951172, "val_acc": 40.0}
{"epoch": 9, "training_loss": 192.4116241455078, "training_acc": 50.0, "val_loss": 115.51081848144531, "val_acc": 40.0}
{"epoch": 10, "training_loss": 50.630044555664064, "training_acc": 70.0, "val_loss": 155.38916015625, "val_acc": 60.0}
{"epoch": 11, "training_loss": 158.53841247558594, "training_acc": 40.0, "val_loss": 66.19478607177734, "val_acc": 40.0}
{"epoch": 12, "training_loss": 83.55557861328126, "training_acc": 40.0, "val_loss": 77.2401351928711, "val_acc": 40.0}
{"epoch": 13, "training_loss": 105.46208801269532, "training_acc": 50.0, "val_loss": 46.67864990234375, "val_acc": 60.0}
{"epoch": 14, "training_loss": 51.15650653839111, "training_acc": 50.0, "val_loss": 170.7223663330078, "val_acc": 40.0}
{"epoch": 15, "training_loss": 173.95715942382813, "training_acc": 50.0, "val_loss": 9.717744827270508, "val_acc": 60.0}
{"epoch": 16, "training_loss": 49.275786590576175, "training_acc": 50.0, "val_loss": 153.05894470214844, "val_acc": 40.0}
{"epoch": 17, "training_loss": 157.08736724853514, "training_acc": 50.0, "val_loss": 15.448715209960938, "val_acc": 40.0}
{"epoch": 18, "training_loss": 87.79127502441406, "training_acc": 60.0, "val_loss": 171.37701416015625, "val_acc": 60.0}
{"epoch": 19, "training_loss": 152.78079528808593, "training_acc": 50.0, "val_loss": 191.37646484375, "val_acc": 40.0}
{"epoch": 20, "training_loss": 115.08390884399414, "training_acc": 50.0, "val_loss": 40.277496337890625, "val_acc": 60.0}
{"epoch": 21, "training_loss": 29.108151054382326, "training_acc": 50.0, "val_loss": 74.26726531982422, "val_acc": 40.0}
{"epoch": 22, "training_loss": 53.680853271484374, "training_acc": 50.0, "val_loss": 46.18037033081055, "val_acc": 60.0}
{"epoch": 23, "training_loss": 149.78067321777343, "training_acc": 20.0, "val_loss": 0.5836398005485535, "val_acc": 60.0}
{"epoch": 24, "training_loss": 53.75923743247986, "training_acc": 60.0, "val_loss": 22.273662567138672, "val_acc": 40.0}
{"epoch": 25, "training_loss": 32.62033920288086, "training_acc": 40.0, "val_loss": 24.679706573486328, "val_acc": 40.0}
{"epoch": 26, "training_loss": 69.6547248840332, "training_acc": 50.0, "val_loss": 19.086156845092773, "val_acc": 60.0}
{"epoch": 27, "training_loss": 91.38475723266602, "training_acc": 70.0, "val_loss": 147.44642639160156, "val_acc": 40.0}
{"epoch": 28, "training_loss": 66.77902908325196, "training_acc": 60.0, "val_loss": 54.16035079956055, "val_acc": 60.0}
{"epoch": 29, "training_loss": 95.81875610351562, "training_acc": 40.0, "val_loss": 19.675113677978516, "val_acc": 40.0}
{"epoch": 30, "training_loss": 110.08923873901367, "training_acc": 50.0, "val_loss": 130.40841674804688, "val_acc": 60.0}
{"epoch": 31, "training_loss": 114.25624258518219, "training_acc": 55.0, "val_loss": 68.83109283447266, "val_acc": 40.0}
{"epoch": 32, "training_loss": 79.2864990234375, "training_acc": 50.0, "val_loss": 35.91050338745117, "val_acc": 60.0}
{"epoch": 33, "training_loss": 80.80943145751954, "training_acc": 60.0, "val_loss": 100.2839584350586, "val_acc": 40.0}
{"epoch": 34, "training_loss": 220.986962890625, "training_acc": 20.0, "val_loss": 117.97975158691406, "val_acc": 60.0}
{"epoch": 35, "training_loss": 75.07794227600098, "training_acc": 50.0, "val_loss": 44.790443420410156, "val_acc": 40.0}
{"epoch": 36, "training_loss": 36.42689819335938, "training_acc": 60.0, "val_loss": 31.517383575439453, "val_acc": 40.0}
{"epoch": 37, "training_loss": 27.805094909667968, "training_acc": 50.0, "val_loss": 163.45018005371094, "val_acc": 40.0}
{"epoch": 38, "training_loss": 198.45275268554687, "training_acc": 50.0, "val_loss": 9.91796875, "val_acc": 40.0}
{"epoch": 39, "training_loss": 143.67066707611085, "training_acc": 60.0, "val_loss": 311.8043518066406, "val_acc": 60.0}
{"epoch": 40, "training_loss": 322.43226318359376, "training_acc": 50.0, "val_loss": 131.135009765625, "val_acc": 40.0}
{"epoch": 41, "training_loss": 171.549169921875, "training_acc": 50.0, "val_loss": 128.70191955566406, "val_acc": 40.0}
{"epoch": 42, "training_loss": 97.09367065429687, "training_acc": 50.0, "val_loss": 101.6391372680664, "val_acc": 60.0}
