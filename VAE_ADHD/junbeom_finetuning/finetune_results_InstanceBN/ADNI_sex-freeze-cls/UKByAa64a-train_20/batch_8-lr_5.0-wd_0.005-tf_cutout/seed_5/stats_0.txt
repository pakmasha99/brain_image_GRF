"main_modify.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 5 --task ADNI_sex --input_option yAware --learning_rate 5e0 --batch_size 8 --weight_decay 5e-3 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 749.5586387634278, "training_acc": 40.0, "val_loss": 146.32177734375, "val_acc": 40.0}
{"epoch": 1, "training_loss": 394.4490692138672, "training_acc": 55.0, "val_loss": 787.2001342773438, "val_acc": 60.0}
{"epoch": 2, "training_loss": 983.2091064453125, "training_acc": 45.0, "val_loss": 285.3586120605469, "val_acc": 60.0}
{"epoch": 3, "training_loss": 423.208642578125, "training_acc": 45.0, "val_loss": 745.4005737304688, "val_acc": 40.0}
{"epoch": 4, "training_loss": 534.3317901611329, "training_acc": 55.0, "val_loss": 313.0961608886719, "val_acc": 40.0}
{"epoch": 5, "training_loss": 159.51424102783204, "training_acc": 45.0, "val_loss": 111.48237609863281, "val_acc": 60.0}
{"epoch": 6, "training_loss": 81.1458023071289, "training_acc": 55.0, "val_loss": 390.21563720703125, "val_acc": 40.0}
{"epoch": 7, "training_loss": 302.10751953125, "training_acc": 55.0, "val_loss": 167.9208984375, "val_acc": 40.0}
{"epoch": 8, "training_loss": 58.932691192626955, "training_acc": 55.0, "val_loss": 19.152896881103516, "val_acc": 60.0}
{"epoch": 9, "training_loss": 36.84233703613281, "training_acc": 65.0, "val_loss": 59.36947250366211, "val_acc": 40.0}
{"epoch": 10, "training_loss": 35.18620071411133, "training_acc": 65.0, "val_loss": 76.75520324707031, "val_acc": 40.0}
{"epoch": 11, "training_loss": 77.34481201171874, "training_acc": 35.0, "val_loss": 71.5119400024414, "val_acc": 40.0}
{"epoch": 12, "training_loss": 44.53970565795898, "training_acc": 55.0, "val_loss": 10.911859512329102, "val_acc": 60.0}
{"epoch": 13, "training_loss": 42.05497665405274, "training_acc": 65.0, "val_loss": 53.32135009765625, "val_acc": 40.0}
{"epoch": 14, "training_loss": 47.06288146972656, "training_acc": 65.0, "val_loss": 12.881636619567871, "val_acc": 60.0}
{"epoch": 15, "training_loss": 39.68722305297852, "training_acc": 75.0, "val_loss": 191.4873809814453, "val_acc": 40.0}
{"epoch": 16, "training_loss": 98.35847778320313, "training_acc": 55.0, "val_loss": 115.6192398071289, "val_acc": 60.0}
{"epoch": 17, "training_loss": 120.3552032470703, "training_acc": 45.0, "val_loss": 174.89028930664062, "val_acc": 40.0}
{"epoch": 18, "training_loss": 98.37147216796875, "training_acc": 55.0, "val_loss": 162.4217071533203, "val_acc": 60.0}
{"epoch": 19, "training_loss": 329.2235168457031, "training_acc": 45.0, "val_loss": 186.19754028320312, "val_acc": 60.0}
{"epoch": 20, "training_loss": 160.9452392578125, "training_acc": 45.0, "val_loss": 599.3772583007812, "val_acc": 40.0}
{"epoch": 21, "training_loss": 460.3810272216797, "training_acc": 55.0, "val_loss": 480.7779846191406, "val_acc": 40.0}
{"epoch": 22, "training_loss": 241.2342170715332, "training_acc": 45.0, "val_loss": 93.88423919677734, "val_acc": 60.0}
{"epoch": 23, "training_loss": 101.08490982055665, "training_acc": 45.0, "val_loss": 79.49901580810547, "val_acc": 40.0}
{"epoch": 24, "training_loss": 88.20172882080078, "training_acc": 25.0, "val_loss": 164.50704956054688, "val_acc": 40.0}
{"epoch": 25, "training_loss": 171.46507568359374, "training_acc": 55.0, "val_loss": 90.14934539794922, "val_acc": 40.0}
{"epoch": 26, "training_loss": 58.75621299743652, "training_acc": 55.0, "val_loss": 9.009099960327148, "val_acc": 60.0}
{"epoch": 27, "training_loss": 79.96259994506836, "training_acc": 55.0, "val_loss": 158.32749938964844, "val_acc": 40.0}
{"epoch": 28, "training_loss": 82.31699676513672, "training_acc": 55.0, "val_loss": 227.98095703125, "val_acc": 60.0}
{"epoch": 29, "training_loss": 249.23736267089845, "training_acc": 45.0, "val_loss": 166.3765411376953, "val_acc": 40.0}
{"epoch": 30, "training_loss": 236.0651611328125, "training_acc": 55.0, "val_loss": 317.0278015136719, "val_acc": 40.0}
{"epoch": 31, "training_loss": 121.3298355102539, "training_acc": 65.0, "val_loss": 212.6962890625, "val_acc": 60.0}
{"epoch": 32, "training_loss": 295.42201538085936, "training_acc": 45.0, "val_loss": 7.330737590789795, "val_acc": 60.0}
{"epoch": 33, "training_loss": 131.23993759155275, "training_acc": 65.0, "val_loss": 545.7245483398438, "val_acc": 40.0}
{"epoch": 34, "training_loss": 377.8343872070312, "training_acc": 55.0, "val_loss": 49.7697639465332, "val_acc": 40.0}
{"epoch": 35, "training_loss": 182.88335876464845, "training_acc": 45.0, "val_loss": 235.96853637695312, "val_acc": 60.0}
{"epoch": 36, "training_loss": 217.8142852783203, "training_acc": 45.0, "val_loss": 191.21290588378906, "val_acc": 40.0}
{"epoch": 37, "training_loss": 138.16163330078126, "training_acc": 55.0, "val_loss": 63.97610092163086, "val_acc": 60.0}
{"epoch": 38, "training_loss": 84.00407485961914, "training_acc": 35.0, "val_loss": 47.21583557128906, "val_acc": 60.0}
{"epoch": 39, "training_loss": 41.62081069946289, "training_acc": 55.0, "val_loss": 230.6376190185547, "val_acc": 40.0}
{"epoch": 40, "training_loss": 158.52227478027345, "training_acc": 55.0, "val_loss": 90.6258544921875, "val_acc": 60.0}
{"epoch": 41, "training_loss": 151.33001708984375, "training_acc": 45.0, "val_loss": 32.0870361328125, "val_acc": 40.0}
{"epoch": 42, "training_loss": 70.80845260620117, "training_acc": 55.0, "val_loss": 38.2127799987793, "val_acc": 60.0}
{"epoch": 43, "training_loss": 78.1712158203125, "training_acc": 35.0, "val_loss": 11.857599258422852, "val_acc": 60.0}
{"epoch": 44, "training_loss": 66.74794921875, "training_acc": 35.0, "val_loss": 46.0743522644043, "val_acc": 60.0}
{"epoch": 45, "training_loss": 95.11292774677277, "training_acc": 45.0, "val_loss": 228.7324981689453, "val_acc": 40.0}
{"epoch": 46, "training_loss": 232.4866149902344, "training_acc": 55.0, "val_loss": 191.1698760986328, "val_acc": 40.0}
{"epoch": 47, "training_loss": 89.20523834228516, "training_acc": 55.0, "val_loss": 80.69293212890625, "val_acc": 60.0}
{"epoch": 48, "training_loss": 124.31213989257813, "training_acc": 35.0, "val_loss": 28.791248321533203, "val_acc": 40.0}
{"epoch": 49, "training_loss": 143.57355728149415, "training_acc": 45.0, "val_loss": 115.29449462890625, "val_acc": 60.0}
{"epoch": 50, "training_loss": 63.931316471099855, "training_acc": 65.0, "val_loss": 94.53176879882812, "val_acc": 40.0}
{"epoch": 51, "training_loss": 52.42816925048828, "training_acc": 45.0, "val_loss": 116.24967193603516, "val_acc": 40.0}
