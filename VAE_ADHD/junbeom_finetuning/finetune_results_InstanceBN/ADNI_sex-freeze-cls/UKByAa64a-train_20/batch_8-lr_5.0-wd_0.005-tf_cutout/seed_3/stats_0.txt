"main_modify.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 3 --task ADNI_sex --input_option yAware --learning_rate 5e0 --batch_size 8 --weight_decay 5e-3 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 741.5093174934387, "training_acc": 50.0, "val_loss": 191.8839111328125, "val_acc": 60.0}
{"epoch": 1, "training_loss": 390.87689208984375, "training_acc": 50.0, "val_loss": 150.9779052734375, "val_acc": 60.0}
{"epoch": 2, "training_loss": 201.2045654296875, "training_acc": 60.0, "val_loss": 498.9327087402344, "val_acc": 40.0}
{"epoch": 3, "training_loss": 273.4878752708435, "training_acc": 50.0, "val_loss": 305.2347412109375, "val_acc": 60.0}
{"epoch": 4, "training_loss": 459.99016723632815, "training_acc": 50.0, "val_loss": 380.5085144042969, "val_acc": 60.0}
{"epoch": 5, "training_loss": 341.598161315918, "training_acc": 40.0, "val_loss": 161.9186248779297, "val_acc": 40.0}
{"epoch": 6, "training_loss": 126.13831329345703, "training_acc": 40.0, "val_loss": 51.31721878051758, "val_acc": 60.0}
{"epoch": 7, "training_loss": 75.39671020507812, "training_acc": 50.0, "val_loss": 13.297131538391113, "val_acc": 60.0}
{"epoch": 8, "training_loss": 38.59826774597168, "training_acc": 50.0, "val_loss": 41.17051315307617, "val_acc": 40.0}
{"epoch": 9, "training_loss": 14.737250995635986, "training_acc": 70.0, "val_loss": 73.9617919921875, "val_acc": 40.0}
{"epoch": 10, "training_loss": 28.764202880859376, "training_acc": 70.0, "val_loss": 118.16796875, "val_acc": 60.0}
{"epoch": 11, "training_loss": 168.90920639038086, "training_acc": 30.0, "val_loss": 110.01482391357422, "val_acc": 40.0}
{"epoch": 12, "training_loss": 110.27642211914062, "training_acc": 40.0, "val_loss": 14.289624214172363, "val_acc": 60.0}
{"epoch": 13, "training_loss": 148.38723449707032, "training_acc": 40.0, "val_loss": 273.1282958984375, "val_acc": 40.0}
{"epoch": 14, "training_loss": 132.23866424560546, "training_acc": 60.0, "val_loss": 125.4455337524414, "val_acc": 60.0}
{"epoch": 15, "training_loss": 128.89171333312987, "training_acc": 40.0, "val_loss": 16.686925888061523, "val_acc": 60.0}
{"epoch": 16, "training_loss": 24.748614406585695, "training_acc": 50.0, "val_loss": 102.04462432861328, "val_acc": 60.0}
{"epoch": 17, "training_loss": 108.89890632629394, "training_acc": 40.0, "val_loss": 29.505781173706055, "val_acc": 60.0}
{"epoch": 18, "training_loss": 29.536896753311158, "training_acc": 50.0, "val_loss": 9.419692039489746, "val_acc": 40.0}
{"epoch": 19, "training_loss": 42.03992614746094, "training_acc": 50.0, "val_loss": 75.47179412841797, "val_acc": 40.0}
{"epoch": 20, "training_loss": 54.010379028320315, "training_acc": 50.0, "val_loss": 15.936545372009277, "val_acc": 60.0}
{"epoch": 21, "training_loss": 40.56827239990234, "training_acc": 60.0, "val_loss": 12.561734199523926, "val_acc": 60.0}
{"epoch": 22, "training_loss": 45.24023361206055, "training_acc": 30.0, "val_loss": 31.061925888061523, "val_acc": 60.0}
{"epoch": 23, "training_loss": 65.65570831298828, "training_acc": 60.0, "val_loss": 38.76222610473633, "val_acc": 40.0}
{"epoch": 24, "training_loss": 149.6701232910156, "training_acc": 40.0, "val_loss": 157.8168182373047, "val_acc": 60.0}
{"epoch": 25, "training_loss": 133.5035858154297, "training_acc": 50.0, "val_loss": 302.7206726074219, "val_acc": 40.0}
{"epoch": 26, "training_loss": 225.08138122558594, "training_acc": 50.0, "val_loss": 46.74358367919922, "val_acc": 60.0}
{"epoch": 27, "training_loss": 127.33569793701172, "training_acc": 50.0, "val_loss": 2.0737931728363037, "val_acc": 60.0}
{"epoch": 28, "training_loss": 139.56358065605164, "training_acc": 60.0, "val_loss": 361.1628112792969, "val_acc": 40.0}
{"epoch": 29, "training_loss": 183.91873111724854, "training_acc": 60.0, "val_loss": 121.4984359741211, "val_acc": 60.0}
{"epoch": 30, "training_loss": 154.32966156005858, "training_acc": 50.0, "val_loss": 111.5376205444336, "val_acc": 40.0}
{"epoch": 31, "training_loss": 188.78428649902344, "training_acc": 50.0, "val_loss": 27.483261108398438, "val_acc": 40.0}
{"epoch": 32, "training_loss": 247.1503807067871, "training_acc": 40.0, "val_loss": 344.15313720703125, "val_acc": 60.0}
{"epoch": 33, "training_loss": 316.23980712890625, "training_acc": 50.0, "val_loss": 163.6618194580078, "val_acc": 40.0}
{"epoch": 34, "training_loss": 273.24757080078126, "training_acc": 50.0, "val_loss": 399.01513671875, "val_acc": 40.0}
{"epoch": 35, "training_loss": 222.72890625, "training_acc": 50.0, "val_loss": 164.68507385253906, "val_acc": 60.0}
{"epoch": 36, "training_loss": 245.45989685058595, "training_acc": 50.0, "val_loss": 301.7607421875, "val_acc": 60.0}
{"epoch": 37, "training_loss": 292.0542560577393, "training_acc": 50.0, "val_loss": 232.7586212158203, "val_acc": 40.0}
{"epoch": 38, "training_loss": 244.05596313476562, "training_acc": 50.0, "val_loss": 244.84658813476562, "val_acc": 40.0}
{"epoch": 39, "training_loss": 162.84027481079102, "training_acc": 30.0, "val_loss": 29.174718856811523, "val_acc": 60.0}
{"epoch": 40, "training_loss": 137.6635772705078, "training_acc": 40.0, "val_loss": 146.75816345214844, "val_acc": 40.0}
{"epoch": 41, "training_loss": 172.42029418945313, "training_acc": 30.0, "val_loss": 79.79495239257812, "val_acc": 60.0}
{"epoch": 42, "training_loss": 36.24204940795899, "training_acc": 60.0, "val_loss": 433.1005859375, "val_acc": 40.0}
{"epoch": 43, "training_loss": 360.70277099609376, "training_acc": 50.0, "val_loss": 196.31024169921875, "val_acc": 40.0}
{"epoch": 44, "training_loss": 146.988525390625, "training_acc": 40.0, "val_loss": 116.5291748046875, "val_acc": 60.0}
{"epoch": 45, "training_loss": 110.9328224182129, "training_acc": 50.0, "val_loss": 299.083984375, "val_acc": 40.0}
{"epoch": 46, "training_loss": 223.32617797851563, "training_acc": 50.0, "val_loss": 98.08387756347656, "val_acc": 60.0}
