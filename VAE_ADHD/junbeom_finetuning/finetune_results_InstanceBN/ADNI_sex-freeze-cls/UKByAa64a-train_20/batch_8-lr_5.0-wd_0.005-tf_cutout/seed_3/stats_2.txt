"main_modify.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 20 --layer_control freeze --stratify strat --random_seed 3 --task ADNI_sex --input_option yAware --learning_rate 5e0 --batch_size 8 --weight_decay 5e-3 --BN inst --save_path finetune_results_InstanceBN"
{"epoch": 0, "training_loss": 685.9160381555557, "training_acc": 50.0, "val_loss": 356.3124694824219, "val_acc": 40.0}
{"epoch": 1, "training_loss": 416.6044555664063, "training_acc": 50.0, "val_loss": 408.77911376953125, "val_acc": 40.0}
{"epoch": 2, "training_loss": 225.22244415283203, "training_acc": 40.0, "val_loss": 84.80757904052734, "val_acc": 60.0}
{"epoch": 3, "training_loss": 136.60217895507813, "training_acc": 40.0, "val_loss": 32.16783905029297, "val_acc": 40.0}
{"epoch": 4, "training_loss": 157.14190826416015, "training_acc": 50.0, "val_loss": 162.0336151123047, "val_acc": 60.0}
{"epoch": 5, "training_loss": 109.98228931427002, "training_acc": 60.0, "val_loss": 512.5830078125, "val_acc": 40.0}
{"epoch": 6, "training_loss": 459.52056884765625, "training_acc": 50.0, "val_loss": 270.71258544921875, "val_acc": 40.0}
{"epoch": 7, "training_loss": 139.68155670166016, "training_acc": 60.0, "val_loss": 254.7777862548828, "val_acc": 60.0}
{"epoch": 8, "training_loss": 261.3717498779297, "training_acc": 50.0, "val_loss": 127.9913101196289, "val_acc": 40.0}
{"epoch": 9, "training_loss": 191.6701690673828, "training_acc": 50.0, "val_loss": 219.70193481445312, "val_acc": 40.0}
{"epoch": 10, "training_loss": 108.12481079101562, "training_acc": 50.0, "val_loss": 274.1850280761719, "val_acc": 60.0}
{"epoch": 11, "training_loss": 324.25580444335935, "training_acc": 50.0, "val_loss": 60.7549934387207, "val_acc": 60.0}
{"epoch": 12, "training_loss": 110.95272216796874, "training_acc": 60.0, "val_loss": 379.5502624511719, "val_acc": 40.0}
{"epoch": 13, "training_loss": 253.38778266906738, "training_acc": 50.0, "val_loss": 126.07915496826172, "val_acc": 60.0}
{"epoch": 14, "training_loss": 270.7872375488281, "training_acc": 50.0, "val_loss": 111.29399871826172, "val_acc": 60.0}
{"epoch": 15, "training_loss": 238.5716125488281, "training_acc": 30.0, "val_loss": 300.6114807128906, "val_acc": 40.0}
{"epoch": 16, "training_loss": 136.91715888977052, "training_acc": 60.0, "val_loss": 129.3092498779297, "val_acc": 60.0}
{"epoch": 17, "training_loss": 138.73536682128906, "training_acc": 50.0, "val_loss": 140.15951538085938, "val_acc": 40.0}
{"epoch": 18, "training_loss": 122.9069595336914, "training_acc": 50.0, "val_loss": 21.419219970703125, "val_acc": 60.0}
{"epoch": 19, "training_loss": 31.2840217590332, "training_acc": 50.0, "val_loss": 14.994589805603027, "val_acc": 40.0}
{"epoch": 20, "training_loss": 13.437300205230713, "training_acc": 80.0, "val_loss": 13.541083335876465, "val_acc": 40.0}
{"epoch": 21, "training_loss": 21.268299102783203, "training_acc": 50.0, "val_loss": 192.50901794433594, "val_acc": 40.0}
{"epoch": 22, "training_loss": 204.9896667480469, "training_acc": 50.0, "val_loss": 38.88887405395508, "val_acc": 40.0}
{"epoch": 23, "training_loss": 284.23582458496094, "training_acc": 30.0, "val_loss": 327.126220703125, "val_acc": 60.0}
{"epoch": 24, "training_loss": 286.8717987060547, "training_acc": 50.0, "val_loss": 224.9152069091797, "val_acc": 40.0}
{"epoch": 25, "training_loss": 322.3393310546875, "training_acc": 50.0, "val_loss": 466.1335144042969, "val_acc": 40.0}
{"epoch": 26, "training_loss": 262.1846069335937, "training_acc": 50.0, "val_loss": 138.304443359375, "val_acc": 60.0}
{"epoch": 27, "training_loss": 169.97711029052735, "training_acc": 50.0, "val_loss": 95.46488952636719, "val_acc": 40.0}
{"epoch": 28, "training_loss": 107.77597045898438, "training_acc": 50.0, "val_loss": 69.3093490600586, "val_acc": 60.0}
{"epoch": 29, "training_loss": 106.77260131835938, "training_acc": 50.0, "val_loss": 42.9589958190918, "val_acc": 40.0}
{"epoch": 30, "training_loss": 69.31619110107422, "training_acc": 50.0, "val_loss": 90.57987213134766, "val_acc": 60.0}
{"epoch": 31, "training_loss": 146.70851287841796, "training_acc": 50.0, "val_loss": 0.45339536666870117, "val_acc": 80.0}
{"epoch": 32, "training_loss": 106.42647471427918, "training_acc": 65.0, "val_loss": 221.0746612548828, "val_acc": 40.0}
{"epoch": 33, "training_loss": 155.42941360473634, "training_acc": 40.0, "val_loss": 263.1065368652344, "val_acc": 60.0}
{"epoch": 34, "training_loss": 304.2252853393555, "training_acc": 50.0, "val_loss": 16.654342651367188, "val_acc": 40.0}
{"epoch": 35, "training_loss": 42.21058883666992, "training_acc": 50.0, "val_loss": 75.64032745361328, "val_acc": 60.0}
{"epoch": 36, "training_loss": 79.65517044067383, "training_acc": 50.0, "val_loss": 179.60618591308594, "val_acc": 40.0}
{"epoch": 37, "training_loss": 168.9245849609375, "training_acc": 50.0, "val_loss": 2.147597074508667, "val_acc": 60.0}
{"epoch": 38, "training_loss": 25.591535568237305, "training_acc": 40.0, "val_loss": 47.0339469909668, "val_acc": 60.0}
{"epoch": 39, "training_loss": 57.03284006118774, "training_acc": 60.0, "val_loss": 56.662696838378906, "val_acc": 40.0}
{"epoch": 40, "training_loss": 28.581021118164063, "training_acc": 50.0, "val_loss": 27.36983299255371, "val_acc": 60.0}
{"epoch": 41, "training_loss": 27.493609619140624, "training_acc": 60.0, "val_loss": 185.20433044433594, "val_acc": 40.0}
{"epoch": 42, "training_loss": 129.79356994628907, "training_acc": 50.0, "val_loss": 174.81251525878906, "val_acc": 60.0}
{"epoch": 43, "training_loss": 318.54248046875, "training_acc": 50.0, "val_loss": 289.3735656738281, "val_acc": 60.0}
{"epoch": 44, "training_loss": 232.4214324951172, "training_acc": 50.0, "val_loss": 309.8941345214844, "val_acc": 40.0}
{"epoch": 45, "training_loss": 356.95126953125, "training_acc": 50.0, "val_loss": 567.1552734375, "val_acc": 40.0}
{"epoch": 46, "training_loss": 332.4525970458984, "training_acc": 50.0, "val_loss": 162.4545440673828, "val_acc": 60.0}
{"epoch": 47, "training_loss": 332.3037109375, "training_acc": 50.0, "val_loss": 338.58740234375, "val_acc": 60.0}
{"epoch": 48, "training_loss": 315.90351181030275, "training_acc": 50.0, "val_loss": 287.97076416015625, "val_acc": 40.0}
{"epoch": 49, "training_loss": 305.20498046875, "training_acc": 50.0, "val_loss": 385.8988037109375, "val_acc": 40.0}
{"epoch": 50, "training_loss": 199.21395874023438, "training_acc": 50.0, "val_loss": 162.0571746826172, "val_acc": 60.0}
