{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2487ace6",
   "metadata": {},
   "outputs": [],
   "source": [
    "##step0 : dcm2niix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f95a13de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/bin/bash\n",
    "\n",
    "####################################################################################################################\n",
    "##########NOW that the proper inputs (extracted inputs) are made, let's change them into NIfTI and do BIDS###########\n",
    "#####################################################################################################################\n",
    "\n",
    "#MUST BE DONE ON NODE1(with no conda activation)! (NODE2에서 dwMRI conda activate해서 하면 이상하게 FSGPR이 안나옴... \n",
    "year=19\n",
    "input_dir=/storage/bigdata/CHA_bigdata/1.raw_MRI/20${year}_MRI\n",
    "output_dir=/storage/bigdata/CHA_bigdata/2.dcm2niix/20${year}_MRI_BIDS #output directory\n",
    "\n",
    "mkdir $output_dir\n",
    "\n",
    "for sub in $input_dir/*         #possible because we already made subject folders in the output\n",
    "do\n",
    "    sub_idx=\"${year}${sub:(-4)}\"\n",
    "    mkdir \"${output_dir}/sub-${sub_idx}\" #sub_idx : subject number #extracts the last ten (ex : 2019-C0018 from the whole /storage/bigdata/CHA_bigdata/2019-C0018 ))\n",
    "\n",
    "#####################\n",
    "    echo $sub\t\t\t# this sub folder has the absolute path for each stuff!\n",
    "\n",
    "    sub_out=\"${output_dir}/sub-${sub_idx}\" #output directory for this specific subject\n",
    "    mkdir \"${sub_out}/anat\"\n",
    "    mkdir \"${sub_out}/dwi\"\n",
    "    mkdir \"${sub_out}/tmp\"\n",
    "######################\n",
    "\n",
    "    echo `dcm2niix -b y -ba n -o ${sub_out}/tmp -z y \"${sub}/\"` #save to the sub_out folder\n",
    "\n",
    "    for files in $sub_out/tmp/* #do DICOM to niix for EACH SUBJECT\n",
    "    do\n",
    "    echo $files\n",
    "###################### anat ######################\n",
    "\n",
    "    # && : if the one in the front is successful, proceed to the next\n",
    "    # conditional statement [ $a == $b ] requires spaces between all stuff\n",
    "\n",
    "    # t1\n",
    "    if [[ \"${files}\" == *\"FSPGR\"* ]] && [[ \"${files}\" == *\".json\"* ]]\n",
    "    then\n",
    "        mv $files \"${sub_out}/anat/sub-${sub_idx}_T1w.json\"\n",
    "\n",
    "    elif [[ \"${files}\" == *\"FSPGR\"* ]] && [[ \"${files}\" == *\".nii.gz\"* ]]\n",
    "    then\n",
    "        mv $files \"${sub_out}/anat/sub-${sub_idx}_T1w.nii.gz\"\n",
    "\n",
    "###################### dwi ######################\n",
    "    ################multishell####### (move the previous things to the tmp folder thing)\n",
    "    elif [[ \"${files}\" == *\"DTI\"* ]] && [[ \"${files}\" == *\".json\"* ]]\n",
    "    then\n",
    "        mv $files \"${sub_out}/dwi/sub-${sub_idx}_dwi.json\"\n",
    "\n",
    "    elif [[ \"${files}\" == *\"DTI\"* ]] && [[ \"${files}\" == *\".nii.gz\"* ]]\n",
    "    then\n",
    "        mv $files \"${sub_out}/dwi/sub-${sub_idx}_dwi.nii.gz\"\n",
    "\n",
    "    elif [[ \"${files}\" == *\"bval\" ]]\n",
    "    then\n",
    "        mv $files \"${sub_out}/dwi/sub-${sub_idx}_dwi.bval\"\n",
    "\n",
    "    elif [[ \"${files}\" == *\"bvec\" ]]\n",
    "    then\n",
    "        mv $files \"${sub_out}/dwi/sub-${sub_idx}_dwi.bvec\"\n",
    "    fi\n",
    "    done\n",
    "\n",
    "rm -r ${sub_out}/tmp\n",
    "\n",
    "done\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3f669b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#! /bin/bash\n",
    "\n",
    "year=21\n",
    "input_dir=/temp_storage/bigdata/CHA_bigdata/test_one_sub/2.dcm2niix/20${year}_MRI_BIDS\n",
    "save_dir=/temp_storage/bigdata/CHA_bigdata/test_one_sub/save_dir\n",
    "json_dir=/temp_storage/bigdata/CHA_bigdata/2.dcm2niix/dataset_description.json\n",
    "\n",
    "echo $files_dir\n",
    "\n",
    "#mkdir save_dir\n",
    "\n",
    "for sub in $input_dir/sub-*\n",
    "do\n",
    "    echo $sub\n",
    "    sub_name=\"${sub:(-10)}\"\n",
    "    one_BIDS=$save_dir/$sub_name\n",
    "    mkdir $one_BIDS\n",
    "    cp $json_dir $one_BIDS\n",
    "    cp -r $sub $one_BIDS\n",
    "\n",
    "\n",
    "done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e29e9f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "#! /bin/bash\n",
    "\n",
    "#SBATCH --job-name one_BIDS_ALL  #job name을 다르게 하기 위해서\n",
    "#SBATCH --nodes=1\n",
    "#SBATCH --nodelist=node1 #used node2\n",
    "#SBATCH -t 800:00:00 # Time for running job #길게 10일넘게 잡음\n",
    "#SBATCH -o ./step1_qsiprep_results/output_%A-%a.out #%J : job id 가 들어가는 것\n",
    "#SBATCH -e ./step1_qsiprep_results/error_%A-%a.error\n",
    "#SBATCH --ntasks=1\n",
    "#SBATCH --mem-per-cpu=1GB\n",
    "#SBATCH --cpus-per-task=1\n",
    "#SBATCH --array=1-100%15\n",
    "\n",
    "\n",
    "# uses older versino of qsiprep because new versino of qsiprep doesn't have reconall, and doing reconall seperately results in dwi T1 registration errors.... \n",
    "\n",
    "#sub_list=`ls ./save_dir` #이것하면 다 나오지 않아서 그냥 sublist를 cat하기로함\n",
    "\n",
    "sub=`cat sub_list.txt | awk -v var=${SLURM_ARRAY_TASK_ID} 'NR==var'`\n",
    "\n",
    "#total 235, but will only do the first 10\n",
    "\n",
    "echo $sub\n",
    "mkdir ./3.qsiprep_results/$sub\n",
    "\n",
    "docker run --rm --name SUB_${SLURM_ARRAY_TASK_ID}_node1_upto100 \\\n",
    "-v /storage/bigdata/CHA_bigdata/test_one_sub/save_dir/$sub/:/data:ro \\\n",
    "-v /storage/bigdata/CHA_bigdata/test_one_sub/3.qsiprep_results/$sub/:/out \\\n",
    "-v /storage/bigdata/CHA_bigdata:/freesurfer \\\n",
    "pennbbl/qsiprep:0.14.3 \\\n",
    "/data \\\n",
    "/out \\\n",
    "participant \\\n",
    "-w /out/tmp \\\n",
    "--output_resolution 1.2 \\\n",
    "--denoise_after_combining \\\n",
    "--unringing_method mrdegibbs \\\n",
    "--b0_to_t1w_transform Affine \\\n",
    "--intramodal_template_transform SyN \\\n",
    "--do_reconall \\\n",
    "--fs-license-file /freesurfer/license.txt \\\n",
    "--skip_bids_validation \\\n",
    "--nthreads 1 \\\n",
    "--infant \\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77fb19ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/bin/bash\n",
    "\n",
    "#SBATCH --job-name ONE_RECON__only #job name을 다르게 하기 위해서\n",
    "#SBATCH --nodes=1\n",
    "#SBATCH --nodelist=node3\n",
    "#SBATCH -t 800:00:00 # Time for running job\n",
    "#SBATCH -o ./step2_with_reconstruction/output_%A-%a.out #%J : job id 가 들어가는 것\n",
    "#SBATCH -e ./step2_with_reconstruction/error_%A-%a.error\n",
    "#SBATCH --ntasks=1\n",
    "#SBATCH --mem-per-cpu=1GB\n",
    "#SBATCH --cpus-per-task=4\n",
    "#SBATCH --array=212-236%8\n",
    "\n",
    "sub=`cat sub_list.txt | awk -v var=${SLURM_ARRAY_TASK_ID} 'NR==var'`\n",
    "\n",
    "#total 235, but will only do the first 10\n",
    "\n",
    "echo $sub\n",
    "\n",
    "\n",
    "docker run --rm -v /scratch/connectome/dyhan316/dwMRI/license.txt:/opt/freesurfer/license.txt:ro\\\n",
    " -v /storage/bigdata/CHA_bigdata/test_one_sub/save_dir/$sub/:/data:ro\\\n",
    " -v /storage/bigdata/CHA_bigdata/test_one_sub/3.qsiprep_results/$sub/:/qsiprep-output:ro\\\n",
    " -v /storage/bigdata/CHA_bigdata/test_one_sub/3.qsiprep_results/$sub//freesurfer:/sngl/freesurfer-input:ro\\\n",
    " -v /storage/bigdata/CHA_bigdata/test_one_sub/3.qsiprep_results/$sub/:/out pennbbl/qsiprep:0.15.4\\\n",
    " /data /out participant --recon-input /qsiprep-output --freesurfer-input /sngl/freesurfer-input\\\n",
    " --recon-spec mrtrix_multishell_msmt_ACT-hsvs --output_resolution 1.2 --denoise_after_combining\\\n",
    " --unringing_method mrdegibbs --b0_to_t1w_transform Affine --intramodal_template_transform SyN\\\n",
    " --nthreads 4 --skip_bids_validation --recon_only --infant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "988ce76e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12ea56d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "##++++BACKUP###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ec9b56a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8551536b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/bin/bash\n",
    "\n",
    "####################################################################################################################\n",
    "##########NOW that the proper inputs (extracted inputs) are made, let's change them into NIfTI and do BIDS###########\n",
    "#####################################################################################################################\n",
    "\n",
    "#MUST BE DONE ON NODE1(with no conda activation)! (NODE2에서 dwMRI conda activate해서 하면 이상하게 FSGPR이 안나옴... \n",
    "year=19\n",
    "input_dir=/storage/bigdata/CHA_bigdata/1.raw_MRI/20${year}_MRI\n",
    "output_dir=/storage/bigdata/CHA_bigdata/2.dcm2niix/20${year}_MRI_BIDS #output directory\n",
    "\n",
    "mkdir $output_dir\n",
    "\n",
    "for sub in $input_dir/*         #possible because we already made subject folders in the output\n",
    "do\n",
    "    sub_idx=\"${year}${sub:(-4)}\"\n",
    "    mkdir \"${output_dir}/sub-${sub_idx}\" #sub_idx : subject number #extracts the last ten (ex : 2019-C0018 from the whole /storage/bigdata/CHA_bigdata/2019-C0018 ))\n",
    "\n",
    "#####################\n",
    "    echo $sub\t\t\t# this sub folder has the absolute path for each stuff!\n",
    "\n",
    "    sub_out=\"${output_dir}/sub-${sub_idx}\" #output directory for this specific subject\n",
    "    mkdir \"${sub_out}/anat\"\n",
    "    mkdir \"${sub_out}/dwi\"\n",
    "    mkdir \"${sub_out}/tmp\"\n",
    "######################\n",
    "\n",
    "    echo `dcm2niix -b y -ba n -o ${sub_out}/tmp -z y \"${sub}/\"` #save to the sub_out folder\n",
    "\n",
    "    for files in $sub_out/tmp/* #do DICOM to niix for EACH SUBJECT\n",
    "    do\n",
    "    echo $files\n",
    "###################### anat ######################\n",
    "\n",
    "    # && : if the one in the front is successful, proceed to the next\n",
    "    # conditional statement [ $a == $b ] requires spaces between all stuff\n",
    "\n",
    "    # t1\n",
    "    if [[ \"${files}\" == *\"FSPGR\"* ]] && [[ \"${files}\" == *\".json\"* ]]\n",
    "    then\n",
    "        mv $files \"${sub_out}/anat/sub-${sub_idx}_T1w.json\"\n",
    "\n",
    "    elif [[ \"${files}\" == *\"FSPGR\"* ]] && [[ \"${files}\" == *\".nii.gz\"* ]]\n",
    "    then\n",
    "        mv $files \"${sub_out}/anat/sub-${sub_idx}_T1w.nii.gz\"\n",
    "\n",
    "###################### dwi ######################\n",
    "    ################multishell####### (move the previous things to the tmp folder thing)\n",
    "    elif [[ \"${files}\" == *\"DTI\"* ]] && [[ \"${files}\" == *\".json\"* ]]\n",
    "    then\n",
    "        mv $files \"${sub_out}/dwi/sub-${sub_idx}_dwi.json\"\n",
    "\n",
    "    elif [[ \"${files}\" == *\"DTI\"* ]] && [[ \"${files}\" == *\".nii.gz\"* ]]\n",
    "    then\n",
    "        mv $files \"${sub_out}/dwi/sub-${sub_idx}_dwi.nii.gz\"\n",
    "\n",
    "    elif [[ \"${files}\" == *\"bval\" ]]\n",
    "    then\n",
    "        mv $files \"${sub_out}/dwi/sub-${sub_idx}_dwi.bval\"\n",
    "\n",
    "    elif [[ \"${files}\" == *\"bvec\" ]]\n",
    "    then\n",
    "        mv $files \"${sub_out}/dwi/sub-${sub_idx}_dwi.bvec\"\n",
    "    fi\n",
    "    done\n",
    "\n",
    "rm -r ${sub_out}/tmp\n",
    "\n",
    "done\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12c51d46",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d836d05",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e3b94dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a865248",
   "metadata": {},
   "outputs": [],
   "source": [
    "#! /bin/bash\n",
    "\n",
    "year=21\n",
    "input_dir=/temp_storage/bigdata/CHA_bigdata/test_one_sub/2.dcm2niix/20${year}_MRI_BIDS\n",
    "save_dir=/temp_storage/bigdata/CHA_bigdata/test_one_sub/save_dir\n",
    "json_dir=/temp_storage/bigdata/CHA_bigdata/2.dcm2niix/dataset_description.json\n",
    "\n",
    "echo $files_dir\n",
    "\n",
    "#mkdir save_dir\n",
    "\n",
    "for sub in $input_dir/sub-*\n",
    "do\n",
    "    echo $sub\n",
    "    sub_name=\"${sub:(-10)}\"\n",
    "    one_BIDS=$save_dir/$sub_name\n",
    "    mkdir $one_BIDS\n",
    "    cp $json_dir $one_BIDS\n",
    "    cp -r $sub $one_BIDS\n",
    "\n",
    "\n",
    "done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0b6d6f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#! /bin/bash\n",
    "\n",
    "#SBATCH --job-name one_BIDS_ALL  #job name을 다르게 하기 위해서\n",
    "#SBATCH --nodes=1\n",
    "#SBATCH --nodelist=node1 #used node2\n",
    "#SBATCH -t 800:00:00 # Time for running job #길게 10일넘게 잡음\n",
    "#SBATCH -o ./step1_qsiprep_results/output_%A-%a.out #%J : job id 가 들어가는 것\n",
    "#SBATCH -e ./step1_qsiprep_results/error_%A-%a.error\n",
    "#SBATCH --ntasks=1\n",
    "#SBATCH --mem-per-cpu=1GB\n",
    "#SBATCH --cpus-per-task=1\n",
    "#SBATCH --array=1-100%15\n",
    "\n",
    "\n",
    "# uses older versino of qsiprep because new versino of qsiprep doesn't have reconall, and doing reconall seperately results in dwi T1 registration errors.... \n",
    "\n",
    "#sub_list=`ls ./save_dir` #이것하면 다 나오지 않아서 그냥 sublist를 cat하기로함\n",
    "\n",
    "sub=`cat sub_list.txt | awk -v var=${SLURM_ARRAY_TASK_ID} 'NR==var'`\n",
    "\n",
    "#total 235, but will only do the first 10\n",
    "\n",
    "echo $sub\n",
    "mkdir ./3.qsiprep_results/$sub\n",
    "\n",
    "docker run --rm --name SUB_${SLURM_ARRAY_TASK_ID}_node1_upto100 \\\n",
    "-v /storage/bigdata/CHA_bigdata/test_one_sub/save_dir/$sub/:/data:ro \\\n",
    "-v /storage/bigdata/CHA_bigdata/test_one_sub/3.qsiprep_results/$sub/:/out \\\n",
    "-v /storage/bigdata/CHA_bigdata:/freesurfer \\\n",
    "pennbbl/qsiprep:0.14.3 \\\n",
    "/data \\\n",
    "/out \\\n",
    "participant \\\n",
    "-w /out/tmp \\\n",
    "--output_resolution 1.2 \\\n",
    "--denoise_after_combining \\\n",
    "--unringing_method mrdegibbs \\\n",
    "--b0_to_t1w_transform Affine \\\n",
    "--intramodal_template_transform SyN \\\n",
    "--do_reconall \\\n",
    "--fs-license-file /freesurfer/license.txt \\\n",
    "--skip_bids_validation \\\n",
    "--nthreads 1 \\\n",
    "--infant \\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0742305a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/bin/bash\n",
    "\n",
    "#SBATCH --job-name ONE_RECON__only #job name을 다르게 하기 위해서\n",
    "#SBATCH --nodes=1\n",
    "#SBATCH --nodelist=node3\n",
    "#SBATCH -t 800:00:00 # Time for running job\n",
    "#SBATCH -o ./step2_with_reconstruction/output_%A-%a.out #%J : job id 가 들어가는 것\n",
    "#SBATCH -e ./step2_with_reconstruction/error_%A-%a.error\n",
    "#SBATCH --ntasks=1\n",
    "#SBATCH --mem-per-cpu=1GB\n",
    "#SBATCH --cpus-per-task=4\n",
    "#SBATCH --array=212-236%8\n",
    "\n",
    "sub=`cat sub_list.txt | awk -v var=${SLURM_ARRAY_TASK_ID} 'NR==var'`\n",
    "\n",
    "#total 235, but will only do the first 10\n",
    "\n",
    "echo $sub\n",
    "\n",
    "\n",
    "docker run --rm -v /scratch/connectome/dyhan316/dwMRI/license.txt:/opt/freesurfer/license.txt:ro\\\n",
    " -v /storage/bigdata/CHA_bigdata/test_one_sub/save_dir/$sub/:/data:ro\\\n",
    " -v /storage/bigdata/CHA_bigdata/test_one_sub/3.qsiprep_results/$sub/:/qsiprep-output:ro\\\n",
    " -v /storage/bigdata/CHA_bigdata/test_one_sub/3.qsiprep_results/$sub//freesurfer:/sngl/freesurfer-input:ro\\\n",
    " -v /storage/bigdata/CHA_bigdata/test_one_sub/3.qsiprep_results/$sub/:/out pennbbl/qsiprep:0.15.4\\\n",
    " /data /out participant --recon-input /qsiprep-output --freesurfer-input /sngl/freesurfer-input\\\n",
    " --recon-spec mrtrix_multishell_msmt_ACT-hsvs --output_resolution 1.2 --denoise_after_combining\\\n",
    " --unringing_method mrdegibbs --b0_to_t1w_transform Affine --intramodal_template_transform SyN\\\n",
    " --nthreads 4 --skip_bids_validation --recon_only --infant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70442c4b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e199db4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ede10a18",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3354a8be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7661eedc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "facb91e0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
